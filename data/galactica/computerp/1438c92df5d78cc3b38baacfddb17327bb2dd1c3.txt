Understanding the complexity of human activities solely through an individual’s data can be challenging. However, in many situations, surrounding individuals are likely performing similar activities, while existing human activity recognition approaches focus almost exclusively on individual measurements and largely ignore the context of the activity. Consider two activities: attending a small group meeting and working at an office desk. From solely an individual’s perspective, it can be difficult to differentiate between these activities as they may appear very similar, even though they are markedly different. Yet, by observing others nearby, it can be possible to distinguish between these activities. In this paper, we propose an approach to enhance the prediction accuracy of an individual’s activities by incorporating insights from surrounding individuals. We have collected a real-world dataset from 20 participants with over 58 hours of data including activities such as attending lectures, having meetings, working in the office, and eating together. Compared to observing a single person in isolation, our proposed approach significantly improves accuracy. We regard this work as a first step in collaborative activity recognition, opening new possibilities for understanding human activity in group settings. model takes as input the locally sensed IMU data and generates a set of probabilities that indicate the likelihood that the local IMU data corresponds to each of a set of different activities. Ordinarily, each device would then use its local results to independently identify the most likely activity. We employ a sliding window approach, where each device continuously collects raw data, but generates a set of probabilities for the dictionary of activities every 5 seconds, using the raw data from the previous 10 seconds. These settings were based on empirical observations to achieve a balance of responsiveness and overhead, but of course, these are tunable parameters for specific application deployments. They could also adjust dynamically in response to changing conditions, e.g., rapidly changing activity. Activity Sharing. Each device periodically broadcasts its computed probabilities to other nearby clients over lightweight deviceto-device communication [5, 18]. In our prototype system, the updated probabilities are shared immediately (i.e., every five seconds) with neighboring devices. In practice, the broadcast frequency could be tuned according to the rate at which we expect individuals’ activity to change, the rate at which we expect a device’s neighbor set to change, concerns about energy consumption of communication and computation, or some combination of these factors. By sharing the probabilities rather than the raw data, we can reduce the amount of data that needs to be transmitted and lower the computational load on the devices because they only perform activity recognition on their own raw data. An additional important benefit of this approach is that it allows each device to use a machine-learning model that is best suited to its computational resources or appropriate for its particular sensing data. By allowing different devices to select different models, we can optimize the trade-off between model accuracy and computational complexity. For example, a high-end device with ample computational resources can use a more complex model that achieves higher accuracy, while a low-end device with limited computational resources can use a simpler model that still achieves reasonable accuracy. Instead of synchronizing on a specific model architecture, the system has devices synchronize on the output representation of a set of activity probabilities. This flexibility enables us to achieve real-time activity recognition across a range of devices in a distributed setting with varying capabilities and constraints. 5 a prototype evaluation To evaluate our approach, we implemented the system described above using two backbone HAR models: a Random Forest classifier (RF) and DeepConvLSTM (DCL). For each, we conducted a hyperparameter search to identify the combination of hyperparameters that achieved the best balance between accuracy and computational efficiency. For DCL, we found that a network architecture with 2 convolutional layers, each with 64 filters of size 5, connected to 1 layer of LSTM with 128 hidden nodes, and ending with a fully connected layer, provided the best performance. We chose these hyperparameters based on their ability to effectively capture the temporal and spatial dynamics of the sensor data. For RF, we used 100 decision trees in the forest, with the gini criterion and a minimum number of samples required to split an internal node of 2. As described above, we apply a sliding window approach to process the raw IMU data. In the case of DCL, we feed in the raw IMU data and obtain the resulting probabilities for each activity. In the case of the RF, we first extract features such as the mean and variance from each window3 and feed these features into the RF classifier for human activity recognition. For testing, we randomly selected 20% of the windows for testing and used the remaining windows as the data used to train. The dataset is imbalanced, so SMOTE technique is applied to balance the training set before training the model. SMOTE creates synthetic samples of the minority class by interpolating between existing samples [6]. This approach helped to mitigate the class imbalance and improve the model’s ability to generalize to new data. The Group Work and Study (GWS) Dataset includes four activities: attending a lecture, participating in an in-person meeting, working in a shared office space, and eating in a group. Table 3 and Figure 2 show the accuracy of the activity recognition models
3We use the following features in this paper: mean, variance, maximum, minimum, skewness, kurtosis, total energy, signal magnitude area (SMA), and zero-crossing rate. for the GWS Dataset, both with and without using corroborating information shared by the devices of other nearby individuals. Comparing the performance of the DCL and RFmodels, we found that RF achieved higher accuracy for this dataset. More importantly for our contribution, however, when comparing the same backbone model with and without corroborating information from neighbors, we observed significant improvements in accuracy for both models. Specifically, for DCL, the corroborating information improved accuracy by 19.02%, while for RF, it improved accuracy by 10.52%. These results demonstrate the potential of neighborhood corroboration in improving the accuracy and robustness of machine-learning models applied in complex settings. From Figure 2, as expected, we can observe that the model struggles to differentiate between activities such as listening to a lecture, having a meeting, and working in an office when the information from others nearby is not used. 6 conclusion and futurework We explored a new approach to activity recognition by leveraging information from nearby individuals to corroborate a local prediction.We collected a novel dataset and tested our approach using two models commonly applied to HAR: DeepConvLSTM and Random Forest. Our results demonstrated that corroboration with the activity of others nearby can significantly improve activity recognition accuracy, with a minimum improvement of 10.52%. These results suggest that activity recognition with corroboration has the potential to enable more robust and accurate machine-learning models in complex settings. Moreover, our approach is computationally efficient and requires minimal data transmission, making it well-suited for resource-constrained devices and distributed systems. The basic approach described here provides a foundational step in addressing this more complex problem, where the novel insights required are in how to aggregate diverse prediction probabilities in to a higher level situation prediction. Undoubtedly, the substantial increase in activity recognition accuracy we achieved by leveraging nearby individual activities opens up new possibilities for the development of highly effective and efficient machine learning system for human activity recognition.