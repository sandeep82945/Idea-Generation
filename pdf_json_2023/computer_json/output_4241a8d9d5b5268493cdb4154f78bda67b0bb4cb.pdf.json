{
    "abstractText": "Personalized federated learning, as a variant of federated learning, trains customized models for clients using their heterogeneously distributed data. However, it is still inconclusive about how to design personalized models with better representation of shared global knowledge and personalized pattern. To bridge the gap, we in this paper explore personalized models with low-rank and sparse decomposition. Specifically, we employ proper regularization to extract a low-rank global knowledge representation (GKR), so as to distill global knowledge into a compact representation. Subsequently, we employ a sparse component over the obtained GKR to fuse the personalized pattern into the global knowledge. As a solution, we propose a two-stage proximal-based algorithm named Federated learning with mixed Sparse and Low-Rank representation (FedSLR) to efficiently search for the mixed models. Theoretically, under proper assumptions, we show that the GKR trained by FedSLR can at least sub-linearly converge to a stationary point of the regularized problem, and that the sparse component being fused can converge to its stationary point under proper settings. Extensive experiments also demonstrate the superior empirical performance of FedSLR. Moreover, FedSLR reduces the number of parameters, and lowers the down-link communication complexity, which are all desirable for federated learning algorithms. Source code is available in https://github.com/huangtiansheng/fedslr.",
    "authors": [
        {
            "affiliations": [],
            "name": "Tiansheng Huang"
        },
        {
            "affiliations": [],
            "name": "Li Shen"
        },
        {
            "affiliations": [],
            "name": "Yan Sun"
        },
        {
            "affiliations": [],
            "name": "Weiwei Lin"
        },
        {
            "affiliations": [],
            "name": "Dacheng Tao"
        }
    ],
    "id": "SP:3e9940e49fc9b63534ff07deb37aa61c4ee72919",
    "references": [
        {
            "authors": [
                "Durmus Alp Emre Acar",
                "Yue Zhao",
                "Ramon Matas Navarro",
                "Matthew Mattina",
                "Paul N Whatmough",
                "Venkatesh Saligrama"
            ],
            "title": "Federated learning based on dynamic regularization",
            "venue": "arXiv preprint arXiv:2111.04263,",
            "year": 2021
        },
        {
            "authors": [
                "Manoj Ghuhan Arivazhagan",
                "Vinay Aggarwal",
                "Aaditya Kumar Singh",
                "Sunav Choudhary"
            ],
            "title": "Federated learning with personalization layers",
            "venue": "arXiv preprint arXiv:1912.00818,",
            "year": 2019
        },
        {
            "authors": [
                "H\u00e9dy Attouch",
                "J\u00e9r\u00f4me Bolte",
                "Patrick Redont",
                "Antoine Soubeyran"
            ],
            "title": "Proximal alternating minimization and projection methods for nonconvex problems: An approach based on the kurdyka-\u0142ojasiewicz inequality",
            "venue": "Mathematics of operations research,",
            "year": 2010
        },
        {
            "authors": [
                "Eugene Bagdasaryan",
                "Andreas Veit",
                "Yiqing Hua",
                "Deborah Estrin",
                "Vitaly Shmatikov"
            ],
            "title": "How to backdoor federated learning",
            "venue": "arXiv preprint arXiv:1807.00459,",
            "year": 2018
        },
        {
            "authors": [
                "Keith Bonawitz",
                "Vladimir Ivanov",
                "Ben Kreuter",
                "Antonio Marcedone",
                "H Brendan McMahan",
                "Sarvar Patel",
                "Daniel Ramage",
                "Aaron Segal",
                "Karn Seth"
            ],
            "title": "Practical secure aggregation for federated learning on user-held data",
            "venue": "arXiv preprint arXiv:1611.04482,",
            "year": 2016
        },
        {
            "authors": [
                "Emmanuel J Cand\u00e8s",
                "Xiaodong Li",
                "Yi Ma",
                "John Wright"
            ],
            "title": "Robust principal component analysis",
            "venue": "Journal of the ACM (JACM),",
            "year": 2011
        },
        {
            "authors": [
                "Beidi Chen",
                "Tri Dao",
                "Kaizhao Liang",
                "Jiaming Yang",
                "Zhao Song",
                "Atri Rudra",
                "Christopher Re"
            ],
            "title": "Pixelated butterfly: Simple and efficient sparse training for neural network models",
            "venue": "arXiv preprint arXiv:2112.00029,",
            "year": 2021
        },
        {
            "authors": [
                "Beidi Chen",
                "Tri Dao",
                "Eric Winsor",
                "Zhao Song",
                "Atri Rudra",
                "Christopher R\u00e9"
            ],
            "title": "Scatterbrain: Unifying sparse and low-rank attention approximation",
            "venue": "arXiv preprint arXiv:2110.15343,",
            "year": 2021
        },
        {
            "authors": [
                "Ziyi Chen",
                "Yi Zhou",
                "Tengyu Xu",
                "Yingbin Liang"
            ],
            "title": "Proximal gradient descent-ascent: Variable convergence under k {\\L} geometry",
            "venue": "arXiv preprint arXiv:2102.04653,",
            "year": 2021
        },
        {
            "authors": [
                "Yae Jee Cho",
                "Jianyu Wang",
                "Gauri Joshi"
            ],
            "title": "Client selection in federated learning: Convergence analysis and power-of-choice selection strategies",
            "venue": "arXiv preprint arXiv:2010.01243,",
            "year": 2020
        },
        {
            "authors": [
                "Liam Collins",
                "Hamed Hassani",
                "Aryan Mokhtari",
                "Sanjay Shakkottai"
            ],
            "title": "Exploiting shared representations for personalized federated learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Rong Dai",
                "Li Shen",
                "Fengxiang He",
                "Xinmei Tian",
                "Dacheng Tao"
            ],
            "title": "Dispfl: Towards communication-efficient personalized federated learning via decentralized sparse training",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Shuiguang Deng",
                "Hailiang Zhao",
                "Jianwei Yin",
                "Schahram Dustdar",
                "Albert Y. Zomaya"
            ],
            "title": "Edge Intelligence: the Confluence of Edge Computing and Artificial Intelligence. arXiv:1909.00560 [cs], September 2019",
            "venue": "URL http://arxiv.org/abs/1909.00560",
            "year": 1909
        },
        {
            "authors": [
                "Yuyang Deng",
                "Mohammad Mahdi Kamani",
                "Mehrdad Mahdavi"
            ],
            "title": "Adaptive personalized federated learning, 2020",
            "year": 2020
        },
        {
            "authors": [
                "Alireza Fallah",
                "Aryan Mokhtari",
                "Asuman Ozdaglar"
            ],
            "title": "Personalized federated learning with theoretical guarantees: A model-agnostic meta-learning approach",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Elnur Gasanov",
                "Ahmed Khaled",
                "Samuel Horv\u00e1th",
                "Peter Richt\u00e1rik"
            ],
            "title": "Flix: A simple and communicationefficient alternative to local methods in federated learning",
            "venue": "arXiv preprint arXiv:2111.11556,",
            "year": 2021
        },
        {
            "authors": [
                "Jonas Geiping",
                "Liam Fowl",
                "Gowthami Somepalli",
                "Micah Goldblum",
                "Michael Moeller",
                "Tom Goldstein"
            ],
            "title": "What doesn\u2019t kill you makes you robust (er): Adversarial training against poisons and backdoors",
            "venue": "arXiv preprint arXiv:2102.13624,",
            "year": 2021
        },
        {
            "authors": [
                "Saeed Ghadimi",
                "Guanghui Lan",
                "Hongchao Zhang"
            ],
            "title": "Mini-batch stochastic approximation methods for nonconvex stochastic composite optimization",
            "venue": "Mathematical Programming,",
            "year": 2016
        },
        {
            "authors": [
                "Yonghai Gong",
                "Yichuan Li",
                "Nikolaos M Freris"
            ],
            "title": "Fedadmm: A robust federated deep learning framework with adaptivity to system heterogeneity",
            "venue": "arXiv preprint arXiv:2204.03529,",
            "year": 2022
        },
        {
            "authors": [
                "Tzu-Ming Harry Hsu",
                "Hang Qi",
                "Matthew Brown"
            ],
            "title": "Measuring the effects of non-identical data distribution for federated visual classification",
            "year": 1909
        },
        {
            "authors": [
                "Tiansheng Huang",
                "Weiwei Lin",
                "Wentai Wu",
                "Ligang He",
                "Keqin Li",
                "Albert Y Zomaya"
            ],
            "title": "An efficiencyboosting client selection scheme for federated learning with fairness guarantee",
            "venue": "IEEE Transactions on Parallel and Distributed Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Tiansheng Huang",
                "Weiwei Lin",
                "Li Shen",
                "Keqin Li",
                "Albert Y Zomaya"
            ],
            "title": "Stochastic client selection for federated learning with volatile clients",
            "venue": "IEEE Internet of Things Journal,",
            "year": 2022
        },
        {
            "authors": [
                "Tiansheng Huang",
                "Shiwei Liu",
                "Li Shen",
                "Fengxiang He",
                "Weiwei Lin",
                "Dacheng Tao"
            ],
            "title": "Achieving personalized federated learning with sparse local models",
            "venue": "arXiv preprint arXiv:2201.11380,",
            "year": 2022
        },
        {
            "authors": [
                "Yerlan Idelbayev",
                "Miguel A Carreira-Perpin\u00e1n"
            ],
            "title": "Low-rank compression of neural nets: Learning the rank of each layer",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Wonyong Jeong",
                "Sung Ju Hwang"
            ],
            "title": "Factorized-fl: Agnostic personalized federated learning with kernel factorization & similarity matching",
            "venue": "arXiv preprint arXiv:2202.00270,",
            "year": 2022
        },
        {
            "authors": [
                "Hamed Karimi",
                "Julie Nutini",
                "Mark Schmidt"
            ],
            "title": "Linear convergence of gradient and proximal-gradient methods under the polyak-\u0142ojasiewicz condition",
            "venue": "In Joint European conference on machine learning and knowledge discovery in databases,",
            "year": 2016
        },
        {
            "authors": [
                "Sai Praneeth Karimireddy",
                "Satyen Kale",
                "Mehryar Mohri",
                "Sashank Reddi",
                "Sebastian Stich",
                "Ananda Theertha Suresh"
            ],
            "title": "Scaffold: Stochastic controlled averaging for federated learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Ang Li",
                "Jingwei Sun",
                "Binghui Wang",
                "Lin Duan",
                "Sicheng Li",
                "Yiran Chen",
                "Hai Li"
            ],
            "title": "Lotteryfl: Personalized and communication-efficient federated learning with lottery ticket hypothesis on non-iid",
            "year": 2008
        },
        {
            "authors": [
                "Ang Li",
                "Jingwei Sun",
                "Xiao Zeng",
                "Mi Zhang",
                "Hai Li",
                "Yiran Chen"
            ],
            "title": "Fedmask: Joint computation and communication-efficient personalized federated learning via heterogeneous masking",
            "venue": "In Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Guoyin Li",
                "Ting Kei Pong"
            ],
            "title": "Douglas\u2013rachford splitting for nonconvex optimization with application to nonconvex feasibility problems",
            "venue": "Mathematical programming,",
            "year": 2016
        },
        {
            "authors": [
                "Qinbin Li",
                "Bingsheng He",
                "Dawn Song"
            ],
            "title": "Model-contrastive federated learning",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Tian Li",
                "Anit Kumar Sahu",
                "Manzil Zaheer",
                "Maziar Sanjabi",
                "Ameet Talwalkar",
                "Virginia Smith"
            ],
            "title": "Federated optimization in heterogeneous networks",
            "venue": "arXiv preprint arXiv:1812.06127,",
            "year": 2018
        },
        {
            "authors": [
                "Tian Li",
                "Shengyuan Hu",
                "Ahmad Beirami",
                "Virginia Smith"
            ],
            "title": "Ditto: Fair and robust federated learning through personalization, 2021c",
            "year": 2021
        },
        {
            "authors": [
                "Xiang Li",
                "Kaixuan Huang",
                "Wenhao Yang",
                "Shusen Wang",
                "Zhihua Zhang"
            ],
            "title": "On the convergence of fedavg on non-iid data",
            "year": 1907
        },
        {
            "authors": [
                "Zhize Li",
                "Jian Li"
            ],
            "title": "A simple proximal stochastic gradient method for nonsmooth nonconvex optimization",
            "venue": "Advances in neural information processing systems,",
            "year": 2018
        },
        {
            "authors": [
                "Paul Pu Liang",
                "Terrance Liu",
                "Liu Ziyin",
                "Nicholas B Allen",
                "Randy P Auerbach",
                "David Brent",
                "Ruslan Salakhutdinov",
                "Louis-Philippe Morency"
            ],
            "title": "Think locally, act globally: Federated learning with local and global representations",
            "venue": "arXiv preprint arXiv:2001.01523,",
            "year": 2020
        },
        {
            "authors": [
                "Jie Ma",
                "Ming Xie",
                "Guodong Long"
            ],
            "title": "Personalized federated learning with robust clustering against model poisoning",
            "venue": "In International Conference on Advanced Data Mining and Applications,",
            "year": 2022
        },
        {
            "authors": [
                "Yishay Mansour",
                "Mehryar Mohri",
                "Jae Ro",
                "Ananda Theertha Suresh"
            ],
            "title": "Three approaches for personalization with applications to federated learning",
            "venue": "arXiv preprint arXiv:2002.10619,",
            "year": 2020
        },
        {
            "authors": [
                "H Brendan McMahan",
                "Eider Moore",
                "Daniel Ramage",
                "Seth Hampson"
            ],
            "title": "Communication-efficient learning of deep networks from decentralized data",
            "venue": "arXiv preprint arXiv:1602.05629,",
            "year": 2016
        },
        {
            "authors": [
                "Michael R Metel",
                "Akiko Takeda"
            ],
            "title": "Stochastic proximal methods for non-smooth non-convex constrained sparse optimization",
            "venue": "J. Mach. Learn. Res.,",
            "year": 2021
        },
        {
            "authors": [
                "Fan Mo",
                "Hamed Haddadi",
                "Kleomenis Katevas",
                "Eduard Marin",
                "Diego Perino",
                "Nicolas Kourtellis"
            ],
            "title": "Ppfl: privacy-preserving federated learning with trusted execution environments",
            "venue": "In Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services,",
            "year": 2021
        },
        {
            "authors": [
                "Krishna Pillutla",
                "Sham M Kakade",
                "Zaid Harchaoui"
            ],
            "title": "Robust aggregation for federated learning",
            "venue": "arXiv preprint arXiv:1912.13445,",
            "year": 2019
        },
        {
            "authors": [
                "Krishna Pillutla",
                "Kshitiz Malik",
                "Abdel-Rahman Mohamed",
                "Mike Rabbat",
                "Maziar Sanjabi",
                "Lin Xiao"
            ],
            "title": "Federated learning with partial model personalization",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Jinhyun So",
                "Corey J Nolet",
                "Chien-Sheng Yang",
                "Songze Li",
                "Qian Yu",
                "Ramy E Ali",
                "Basak Guler",
                "Salman Avestimehr"
            ],
            "title": "Lightsecagg: a lightweight and versatile design for secure aggregation in federated learning",
            "venue": "Proceedings of Machine Learning and Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Pablo Sprechmann",
                "Alexander M Bronstein",
                "Guillermo Sapiro"
            ],
            "title": "Learning efficient sparse and low rank models",
            "venue": "IEEE transactions on pattern analysis and machine intelligence,",
            "year": 2015
        },
        {
            "authors": [
                "Vale Tolpegin",
                "Stacey Truex",
                "Mehmet Emre Gursoy",
                "Ling Liu"
            ],
            "title": "Data poisoning attacks against federated learning systems",
            "venue": "In European Symposium on Research in Computer Security,",
            "year": 2020
        },
        {
            "authors": [
                "Stacey Truex",
                "Ling Liu",
                "Ka-Ho Chow",
                "Mehmet Emre Gursoy",
                "Wenqi Wei"
            ],
            "title": "Ldp-fed: Federated learning with local differential privacy",
            "venue": "In Proceedings of the Third ACM International Workshop on Edge Systems, Analytics and Networking,",
            "year": 2020
        },
        {
            "authors": [
                "Dui Wang",
                "Li Shen",
                "Yong Luo",
                "Han Hu",
                "Kehua Su",
                "Yonggang Wen",
                "Dacheng Tao"
            ],
            "title": "Fedabc: Targeting fair competition in personalized federated learning",
            "venue": "arXiv preprint arXiv:2302.07450,",
            "year": 2023
        },
        {
            "authors": [
                "Fenghui Wang",
                "Wenfei Cao",
                "Zongben Xu"
            ],
            "title": "Convergence of multi-block bregman admm for nonconvex composite problems",
            "venue": "Science China Information Sciences,",
            "year": 2018
        },
        {
            "authors": [
                "Han Wang",
                "Siddartha Marella",
                "James Anderson"
            ],
            "title": "Fedadmm: A federated primal-dual algorithm allowing partial participation",
            "venue": "arXiv preprint arXiv:2203.15104,",
            "year": 2022
        },
        {
            "authors": [
                "Kang Wei",
                "Jun Li",
                "Ming Ding",
                "Chuan Ma",
                "Howard H Yang",
                "Farhad Farokhi",
                "Shi Jin",
                "Tony QS Quek",
                "H Vincent Poor"
            ],
            "title": "Federated learning with differential privacy: Algorithms and performance analysis",
            "venue": "IEEE Transactions on Information Forensics and Security,",
            "year": 2020
        },
        {
            "authors": [
                "Baoyuan Wu",
                "Li Shen",
                "Tong Zhang",
                "Bernard Ghanem"
            ],
            "title": "Map inference via `2-sphere linear program reformulation",
            "venue": "International Journal of Computer Vision,",
            "year": 1913
        },
        {
            "authors": [
                "Chulin Xie",
                "Keli Huang",
                "Pin-Yu Chen",
                "Bo Li"
            ],
            "title": "Dba: Distributed backdoor attacks against federated learning",
            "venue": "In International Conference on Learning Representations,",
            "year": 2019
        },
        {
            "authors": [
                "Chulin Xie",
                "Minghao Chen",
                "Pin-Yu Chen",
                "Bo Li"
            ],
            "title": "Crfl: Certifiably robust federated learning against backdoor attacks",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Huan Xu",
                "Constantine Caramanis",
                "Sujay Sanghavi"
            ],
            "title": "Robust pca via outlier pursuit",
            "venue": "Advances in neural information processing systems,",
            "year": 2010
        },
        {
            "authors": [
                "Jing Xu",
                "Sen Wang",
                "Liwei Wang",
                "Andrew Chi-Chih Yao"
            ],
            "title": "Fedcm: Federated learning with client-level momentum",
            "venue": "arXiv preprint arXiv:2106.10874,",
            "year": 2021
        },
        {
            "authors": [
                "Chaojian Yu",
                "Bo Han",
                "Mingming Gong",
                "Li Shen",
                "Shiming Ge",
                "Bo Du",
                "Tongliang Liu"
            ],
            "title": "Robust weight perturbation for adversarial training",
            "venue": "arXiv preprint arXiv:2205.14826,",
            "year": 2022
        },
        {
            "authors": [
                "Tao Yu",
                "Eugene Bagdasaryan",
                "Vitaly Shmatikov"
            ],
            "title": "Salvaging federated learning by local adaptation",
            "venue": "arXiv preprint arXiv:2002.04758,",
            "year": 2020
        },
        {
            "authors": [
                "Xiyu Yu",
                "Tongliang Liu",
                "Xinchao Wang",
                "Dacheng Tao"
            ],
            "title": "On compressing deep models by low rank and sparse decomposition",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Xinwei Zhang",
                "Mingyi Hong",
                "Sairaj Dhople",
                "Wotao Yin",
                "Yang Liu"
            ],
            "title": "Fedpd: A federated learning framework with adaptivity to non-iid data",
            "venue": "IEEE Transactions on Signal Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Yue Zhao",
                "Meng Li",
                "Liangzhen Lai",
                "Naveen Suda",
                "Damon Civin",
                "Vikas Chandra"
            ],
            "title": "Federated learning with non-iid data",
            "venue": "arXiv preprint arXiv:1806.00582,",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "Personalized federated learning, as a variant of federated learning, trains customized models for clients using their heterogeneously distributed data. However, it is still inconclusive about how to design personalized models with better representation of shared global knowledge and personalized pattern. To bridge the gap, we in this paper explore personalized models with low-rank and sparse decomposition. Specifically, we employ proper regularization to extract a low-rank global knowledge representation (GKR), so as to distill global knowledge into a compact representation. Subsequently, we employ a sparse component over the obtained GKR to fuse the personalized pattern into the global knowledge. As a solution, we propose a two-stage proximal-based algorithm named Federated learning with mixed Sparse and Low-Rank representation (FedSLR) to efficiently search for the mixed models. Theoretically, under proper assumptions, we show that the GKR trained by FedSLR can at least sub-linearly converge to a stationary point of the regularized problem, and that the sparse component being fused can converge to its stationary point under proper settings. Extensive experiments also demonstrate the superior empirical performance of FedSLR. Moreover, FedSLR reduces the number of parameters, and lowers the down-link communication complexity, which are all desirable for federated learning algorithms. Source code is available in https://github.com/huangtiansheng/fedslr."
        },
        {
            "heading": "1 Introduction",
            "text": "Federated Learning (FL) (McMahan et al., 2016) has emerged as a solution to exploit data on the edge in a privacy-preserving manner. In FL, clients train a global model collaboratively without sharing private data. However, the global model may not produce good accuracy performance for each client\u2019s task due to the existence of Non-IID issue (Zhao et al., 2018).\n\u2217Work was done during internships at JD Explore Academy. \u2020Li Shen is the corresponding author.\nar X\niv :2\n30 2.\n11 05\n1v 1\n[ cs\nTo bridge the gap, the concept of Personalized Federated Learning (PFL) is proposed as a remedy. PFL deploys customized models for each client, which typically incorporates a global component that represents global knowledge from all the clients, and a personalized component that represents the local knowledge. The main stream of PFL can be classified into four genres, i.e., layer-wise separation (Arivazhagan et al., 2019), linear interpolation (Deng et al., 2019), regularization (Li et al., 2021c; Wang et al., 2023), and personalized masks (Huang et al., 2022b; Li et al., 2021a; 2020; Dai et al., 2022). All of these studies either explicitly or implicitly enforce a global component and a personalized component to compose the personalized models. Despite a plethora of research on this topic having emerged in sight, PFL is still far from its maturity. Particularly, it is still unclear how to better represent the global knowledge with the global component and the personalized pattern with the local component, and more importantly, how to merge them together to produce better performance.\nMoreover, existing PFL studies usually involve additional personalized parameters in their local models, e.g., (Deng et al., 2020). However, the local knowledge should be complementary to the global knowledge, which means it does not need dominating expressiveness in the parameter space. On the other hand, the global knowledge, which represents clients\u2019 commonality, and is complemented by personalized component, may not need a large global parameter space to achieve its functionality. All in all, we are trying to explore:\nDo we need such amount of parameters to represent the local pattern, as well as the global knowledge? Can the expressiveness of local models be optimized by intersecting the parameter space of the personalized and global component?\nTo answer above questions, we utilize the idea of decomposing personalized models as a mixture of a lowrank Global Knowledge Representation (GKR) and a sparse personalized component, wherein the GKR is used to extract the core common information across the clients, and the sparse component serves as representing the personalized pattern for each client. To realize the low-rank plus sparse model, we employ proper regularization on the GKR and the sparse component in two separate optimization problems. The regularization-involved problem, for which there is not an existing solution to our best knowledge, are alternatively solved via the proposed two-stage algorithm (named FedSLR). The proposed algorithm enjoys superior performance over the personalized tasks, while simultaneously reducing the communication and model complexity. In summary, we highlight the following characteristics that FedSLR features: (i) The GKR component can better represent the global knowledge. Its accuracy performance is increased compared to general FL solution (e.g., FedAvg). (ii) The mixed personalized models, which are fused with local pattern represented by their sparse components, obtain SOTA performance for each client\u2019s task. (iii) Both the two models being generated can be compressed to have a smaller amount of parameters via factorization, which is easier to deploy in the commonality hardware. Besides, down-link communication cost in the training phase can be largely reduced according to our training mechanism.\nEmpirically, we conduct extensive experiment to validate the performance of FedSLR. Specifically, our experiments on CIFAR-100 verify that: (i) the Global Knowledge Representation (GKR) can better represent the global knowledge (GKR model achieves 7.23% higher accuracy compared to FedAvg), and the mixed models can significantly improve the model accuracy of personalized tasks (the mixed model produced by FedSLR achieves 3.52% higher accuracy to Ditto). (ii) Moreover, both GKR and the mixed models, which respectively represent the global and personalized knowledge, are more compact (GKR model achieve 50.40% less parameters while the mixed model pruned out 40.11% parameters compared to a model without pruning). (iii) The downlink communication is lowered (38.34% fewer downlink communication in one session of FL). Theoretically, we establish the convergence property of GKR and the sparse personalized component, which showcases that both components asymptotically converge to their stationary points under proper settings.\nTo the end, our contributions are summarized as follows,\n\u2022 We derive shared global knowledge with a low-rank global knowledge representation (GKR), which alone may not represent personalized knowledge covered by local data. Therefore, we propose to perform fusion of personalized pattern via merging sparse personalized components with GKR, which only incur minor extra parameters for the mixed models.\n\u2022 We propose a new methodology named FedSLR for optimizing the proposed two-stage problem. FedSLR only requires minor extra computation of proximal operator on the server, while can significantly boost performance, reduce communication size, and lighten model complexity.\n\u2022 We present convergence analysis to FedSLR, which concludes that under the assumption of KurdykaLojasiewicz condition, the GKR produced by FedSLR could at least sub-linearly converge to a stationary point. Also, the sparse components can asymptotically converge to their stationary points under proper settings. Extensive empirical experiments also demonstrate the superiority of FedSLR."
        },
        {
            "heading": "2 Related Work",
            "text": "Federated learning. FL was first proposed in (McMahan et al., 2016) to enable collaborative training of a network model without exchanging the clients\u2019 data. However, the data residing in clients are intrinsically heterogeneous (or Non-IID), which leads to performance degradation of global model (Zhao et al., 2018). Many attempts have been proposed to alleviate the data heterogeneity issue. SCAFFOLD (Karimireddy et al., 2020), for example, introduces a variance reduction technique to correct the drift of local training. Similarly, FedCM (Xu et al., 2021) uses client-level momentum to perform drift correction to the local gradient update. Another genre, the prox-based algorithm, e.g., FedProx (Li et al., 2018), incorporates a proximal term in the local loss to constrain the inconsistency of the local objective. In addition to the proximal term, a subsequent study, (Acar et al., 2021) further incorporates a linear term in its local loss to strengthen local consistency. FedPD (Zhang et al., 2021), FedSpeed (Sun et al.) and FedAdmm (Wang et al., 2022) explore the combination of the method of ADMM into FL to counter the Non-IID issue.\nPersonalized federated learning. PFL is a relaxed variant of FL. In PFL, the goal is to train customized models for each client, and each customized model is used to perform an individual task for each client. We classify the existing PFL solutions in four genres. The first genre is to separate the global layers and personalized layers, e.g., (Collins et al., 2021; Liang et al., 2020; Arivazhagan et al., 2019), which respectively contain global knowledge and personalized pattern of each specific client. The second genre is linear interpolation. To illustrate, (Deng et al., 2020; Mansour et al., 2020) and (Gasanov et al., 2021) propose to linearly interpolate personalized components and global component to produce the personalized models. The third genre, inspired by the literature on multi-task learning, is to introduce proximal regularizer to constrain the proximity of global model and personalized models, e.g., (Li et al., 2021c; Yu et al., 2020). The last genre is to personalize the global model with a sparse mask, see (Huang et al., 2022b; Li et al., 2021a).\nRobust PCA and low-rank plus sparse. In robust PCA (Cand\u00e8s et al., 2011; Xu et al., 2010), a data matrix X is decomposed to a low-rank matrix L and a sparse matrix S, in which L is the principal component that preserves the maximum amount of information of the data matrix, and S is used to represent the outlier. The low-rank plus sparse model formulation is known to increase the model expressiveness compared to the pure low-rank and pure sparse formulation. In recent years, the idea of low-rank plus sparse is also adopted in statistical model (Sprechmann et al., 2015), deep learning models, e.g., CNN (Yu et al., 2017), and more recently, Transformer (Chen et al., 2021a;b). Motivated by the existing literature, we aim to preserve the model expressiveness from compression by mixing the two compression techniques. Analogous to robust PCA, in our PFL setting, we use the low-rank component to represent the global knowledge in order to preserve the maximum amount of knowledge shared by clients, and we use the sparse component to represent the local knowledge, which is like an outlier from the global knowledge.\nIn this paper, we apply the idea of sparse plus low-rank decomposition to bridge FL and PFL. Specifically, we train the low-rank GKR via a proximal-based descent method. Then, along the optimization trajectory of GKR, each client simultaneously optimizes the personalized sparse component using their local data. In this way, the GKR shares the commonality among all user\u2019s data, and the personalized component captures the personalized pattern, which facilitates the mixed model to acquire better local performance. We emphasize that our proposed idea, that the personalized model can be decomposed to a low-rank GKR and a sparse personalized component, is novel over the existing literature."
        },
        {
            "heading": "3 Problem Setup",
            "text": "We first assume there are M clients (indexed by i) in the system. Each client hosts ni pieces of data.\nClassical FL problem. The FL problem in (McMahan et al., 2016) is formulated as follows:\nw = arg minw\n{ f(w) := 1\nM M\u2211 i=1\nfi(w) }\n(1)\nwhere fi(w) := 1ni \u2211ni j=1 Loss(w; (xj , yj)) is the the empirical loss (e.g., average of cross entropy) of the i-th client. However, the global model obtained by minimizing global consensus may not perform well in personalized tasks, in other words, is incapable of minimizing each specific fi(\u00b7).\nAlternatively, under the assumption that the model deployed in each client can be not exactly the same, our PFL formulation can be separated into two sub-problems, as follows.\nGlobal knowledge representation (GKR). To compress the global knowledge into a smaller size of model, we alternatively establish the following global knowledge representation problem.\n(P1) Find a stationary point w\u0302\u2217such that 0 \u2208 \u2202f\u0302(w\u0302\u2217), where f\u0302(w) := { f(w) := 1\nM M\u2211 i=1\nfi(w) } + { R(w) := \u03bb\nL\u2211 l=1 \u2016Wl\u2016\u2217\n} (2)\nHere, we use R(w) to impose low-rank regularizer for model with L layers, where \u2016 \u00b7 \u2016\u2217 is the nuclear norm. Prior to enter the model weights into the regularizer, we follow scheme 2 in (Idelbayev & Carreira-Perpin\u00e1n, 2020) to do the matrix transformation for different layers of a neural network, i.e., Wl \u2208 Rdl,1\u00d7dl,2 = \u03c0(wl), where \u03c0(wl) maps the original weights of l-th layer into the transformed matrix 1. By factorization, one can\n1Here we show the detailed implementation for this matrix transformation. We apply different transformations for different layer architecture of a deep neural network. For the convolutional layer, we reshape the original vector weights of convolutional layer wl \u2208 Ro\u00d7d\u00d7i\u00d7d to matrix Wl \u2208 Ro\u00d7d,i\u00d7d, where o, i, d respectively represents the output/input channel size and kernel size. For linear layer, we map vector wl \u2208 Ro\u00d7i to matrix wl \u2208 Ro,i, where o and i are the output/input neuron size.\ndecompose matrix weights of each layer Wl into Wl = UlV Tl where Ul \u2208 Rdl,1,r, Vl \u2208 Rdl,2,r and r is the rank of matrix. With sufficiently large intensity of the regularizer, r could be reduced to a sufficiently small number such that the number of parameter of the compressed model can be much smaller than that of the full size model, i.e., r\u00d7 (dl,1 + dl,2) dl,1\u00d7 dl,2. In this way, we distill the global knowledge into a compact model with fewer parameters.\nFusion of personalized pattern. Constructed upon the low-rank GKR obtained before, we further establish a formulation to merge the personalized pattern into the global knowledge, as follows:\n(P2) {p\u2217i } = arg min pi\n{ f\u0303(pi) := fi(w\u0302\u2217 + pi) } + { R\u0303(pi) := \u00b5\u2016pi\u20161 } . (3)\nIn this formulation, we use a sparse component to represent the personalized pattern, so as to complement and improve the expressiveness of GKR. Or more specifically, we use a low-rank global plus sparse personalized model to do inference for the personalized task. The sparsity of the personalized component controls the degree of local knowledge to be fused. As we show later, properly sparsifying the personalized component enables a better merge between global and local knowledge, while simply no sparsification or too much sparsification would both lead to performance degradation. Moreover, the sparse component would only introduce minor extra parameters upon GKR. Here we use L1 norm to sparsify the personalized component. Remark 1. Our proposed problem formulation is separated into two sub-problems. The objective of the first sub-problem (P1) is to train global knowledge representation, aiming to derive the global knowledge, and that of the second sub-problem (P2) is to fuse the personalized pattern into GKR that we obtain in the first problem. Our problem definition is unorthodox to the main stream of PFL research, most of which can be generalized to a bi-variable optimization problem (see the general form in Eq. (3) of (Pillutla et al., 2022) ), and therefore the methods FedSim/FedAlt in (Pillutla et al., 2022) can not be directly applied to our problems."
        },
        {
            "heading": "4 Methodology",
            "text": "We now derive our FedSLR solution, which can be separated into two phases of optimization.\nPhase I: represent the global knowledge with a low-rank component. To mitigate the communication cost and the computation overhead in the local phase, we propose to postpone the proximal operator to the global aggregation phase. Prior to that, we switch the task of local training of i-th client to solve a sub-problem as follows:\n(Local Phase) wi,t+1 = arg minw fi(w)\u2212 \u3008\u03b3i,t,w\u3009+ 1\n2\u03b7g \u2016wt \u2212w\u20162 (4)\nwhere \u03b7g is the global learning rate used in the aggregation phase, \u03b3i,t is an auxiliary variable we introduce to record the local gradient, which is essential in the aggregation phase to recover the global proximal gradient descent. This sub-problem could be solved (or inaccurately solved) via an iterative solver, e.g., SGD.\nAfter the local training is finished, the client sends back the local model after training, i.e., wi,t+1 to server2. Then, with wi,t+1 ready, we introduce an update to the auxiliary variable in each round on both server and client sides, as follows:\n(Auxiliary Variable Update) \u03b3i,t+1 = \u03b3i,t + 1 \u03b7g (wt \u2212wi,t+1) (5)\nWith auxiliary variable {\u03b3i,t+1} and local weights {wi,t+1} ready, we take a global proximal step in server,\n(Aggregation) wt+1 = Prox\u03b7g\u03bb\u2016\u00b7\u2016\u2217 ( 1 M M\u2211 i=1 wi,t+1 \u2212 \u03b7g M M\u2211 i=1 \u03b3i,t+1 ) (6)\n2The upload from clients {wi,t+1} are not sparse/low-rank, and therefore FedSLR cannot reduce the uplink communication. However, one can apply communication-reduction technique, e.g., sparsification, here. We leave this as a future work.\nRemark 2. The inspiration of our proposed method stems from the LPGD method (a direct application of proximal descent algorithm into local steps, see Appendix A.2). Firstly, observed from the optimality condition of Eq. (4) that we have \u2207fi(wi,t+1)\u2212 \u03b3i,t \u2212 1\u03b7g (wt \u2212wi,t+1) = 0. Combining this with Eq.(5), it is sufficient to show that \u03b3i,t+1 = \u2207fi(wi,t+1). Then, plugging this relation into aggregation in Eq. (6), we show that if the local iterates converge, i.e., wi,t+1 \u2192 wt, \u2207fi(wi,t+1) can indeed approximate \u2207fi(wt), and thereby the global iterative update can reduce to wt+1 = Prox\u03b7g\u03bb\u2016\u00b7\u2016\u2217 (wt \u2212 \u03b7g\u2207f(wt)), which is the update form of vanilla proximal gradient descent. In addition, our solution excels the direct application of LPGD method in two aspects: i) We postpone the proximal operator with intense computation to the aggregation phase, which only need to perform once in one global iteration, and is computed by the server with typically more sufficient computational resources. ii) The downlink communication can be saved. This can be achieved via layer-wise de-composing the low rank global weights into two smaller matrices, and send these matrices in replacement of the dense GKR.\nPhase II: Local fusion with a sparse component. After the GKR wt is updated in the first phase of optimization, we train the personalized component to acquire fusion of the personalized pattern into the global knowledge. This can be done by performing a proximal step as follows,\n(Local Fusion) pi,t,k+1 = Prox\u03b7l\u00b5\u2016\u00b7\u20161 (pi,t,k \u2212 \u03b7l\u22072fi(wt + pi,t,k; \u03be)) (7)\nwhere Prox\u03b7l\u00b5\u2016\u00b7\u20161 (\u00b7) is used to sparsify the personalized component, \u03b7l is the local stepsize, \u22072 takes the differentiation with respect to p, and \u03be is the stochastic sample from the i-th client\u2019s local data. Remark 3. Our phase II optimization relies on the classical proximal stochastic GD method. It freezes the GKR wt obtained in the previous global round, and optimize pi towards the local loss in order to absorb the local knowledge. The proximal operator for L1 regularizer is performed in every local step, but the overhead should not be large (compared to operator for low-rank regularizer), since only direct value shrinkage over model weights is needed to be performed (see Appendeix A.1).\nThe entire workflow of our FedSLR algorithm is formally captured in Algorithm 1. Note that in line 3 of Algorithm 1, the layer-wise SVD is not necessarily to be performed in real implementation. We can reuse the SVD results in line 7 to obtain {Ut,l} and {Vt,l}. We add this line of code for better readability."
        },
        {
            "heading": "5 Theoretical Analysis",
            "text": "We in this section give the following basic assumptions to characterize the non-convex optimization landscape. Before we proceed, we first set up a few notations. We use \u2016 \u00b7 \u2016 to represent the L2 norm unless otherwise specified. \u2202R(\u00b7) is a set that captures the subgradient for function R(\u00b7). dist(C,D) = inf{\u2016x \u2212 y\u2016 | x \u2208 C, y \u2208 D} captures the distance between two sets. Assumption 1 (L-smoothness). We assume L-smoothness over the client\u2019s loss function. Formally, we assume there exists a positive constant L such that \u2016\u2207fi(w)\u2212\u2207fi(w\u2032)\u2016 \u2264 L\u2016w\u2212w\u2032\u2016 holds for w,w\u2032 \u2208 Rd. Assumption 2 (Bounded gradient). Suppose the gradient of local loss is upper-bounded, i.e., there exists a positive constant B such that \u2016\u2207fi(w)\u2016 \u2264 B holds for w \u2208 Rd. Assumption 3 (Proper closed global objective). The global objective f(\u00b7) is proper 3 and closed 4. Remark 4. Assumps 1 and 2 are widely used to characterize the convergence property of federated learning algorithms, e.g.,(Xu et al., 2021; Li et al., 2019; Gong et al., 2022) . By Assumption 3, we intend to ensure that i) the global objective is lower bounded, i.e., for w \u2208 Rd, f(w) = 1M \u2211M i=1 fi(w) > \u2212\u221e, and ii) the global objective is lower semi-continuous. The assumption is widely used in analysis of proximal algorithms. e.g., (Wang et al., 2018; Li & Pong, 2016; Wu et al., 2020). Theorem 1 (Subsequence convergence). Suppose that Assumptions 1-3 hold true, the global step size is chosen as 0 < \u03b7g \u2264 12L , and that there exists a subsequence of sequence (wt,wi,t,\u03b3i,t) converging to a cluster point (w\u2217,w\u2217i ,\u03b3\u2217i ). Then, the subsequence generated by FedSLR establishes the following property:\n3A function f is proper if it never takes on the value \u2212\u221e and also is not identically equal to +\u221e. 4A function f is said to be closed if for each \u03b1 \u2208 R, the sublevel set {x \u2208 dom(f)|f(x) \u2264 \u03b1} is a closed set.\nAlgorithm 1 Federated learning with mixed Sparse and Low-Rank representation (FedSLR) Input Training iteration T ; Local stepsize \u03b7l; Global stepsize \u03b7g ; Local step K;\n1: procedure Server\u2019s Main Loop 2: for t = 0, 1, . . . , T \u2212 1 do 3: Factorize wt to {Ut,l} and {Vt,l} by applying layer-wise SVD. 4: for i \u2208 [M ] do 5: Send {Ut,l} and {Vt,l} to the i-th client, invoke its main loop and receive wi,t+1 6: \u03b3i,t+1 = \u03b3i,t + 1\u03b7g (wt \u2212wi,t+1) . Update auxiliary variable on server\n7: wt+1 = Prox\u03bb\u03b7g\u2016\u00b7\u2016\u2217 ( 1 M \u2211M i=1wi,t+1 \u2212 1 M \u2211M i=1 \u03b7g\u03b3i,t+1 ) . Apply the update\n8: procedure Client\u2019s Main Loop 9: Receive {Ut,l} and {Vt,l} from server and recover wt. 10: Call Phase I OPT to obtain wi,t+1 and \u03b3i,t+1. 11: Call Phase II OPT to obtain pi,t,K . 12: Send wi,t+1 to Server, and keep pi,t,K and \u03b3i,t+1 privately. 13: procedure Phase I OPT (GKR) 14: wi,t+1 = arg minw fi(w)\u2212 \u3008\u03b3i,t,w\u3009+ 12\u03b7g \u2016wt \u2212w\u2016\n2 . Train GKR in Local 15: \u03b3i,t+1 = \u03b3i,t + 1\u03b7g (wt \u2212wi,t+1) . Update the auxiliary variable on clients 16: Return wi,t+1 and \u03b3i,t+1 17: procedure Phase II OPT (Personalized Component) 18: pi,t,0 = pi,t\u22121,K . Warm-start from the last-called 19: for k = 0, 1, . . . ,K \u2212 1 do 20: pi,t,k+1 = Prox\u00b5\u03b7\u2016\u00b7\u20161 (pi,t,k \u2212 \u03b7l\u22072fi(wt + pi,t,k; \u03be)) . Local fusion 21: Return pi,t,K\nlim j\u2192\u221e (wtj+1, {wi,tj+1}, {\u03b3i,tj+1}) = lim j\u2192\u221e (wtj , {wi,tj}, {\u03b3i,tj}) = (w\u2217, {w\u2217i }, {\u03b3\u2217i }) (8)\nMoreover, the cluster point is indeed a stationary point of the global problem, or equivalently,\n0 \u2208 \u2202R(w\u2217) + 1 M M\u2211 i=1 \u2207fi(w\u2217). (9)\nRemark 5. Theorem 1 states that if there exist a subsequence of the produced sequence that converges to a cluster point, then this cluster point is indeed a stationary point of the global problem (P1). The additional assumption of converging subsequence holds if the sequence is bounded (per sequential compactness theorem).\nUnder the mild assumption of Kurdyka-Lojasiewicz (KL) property (Attouch et al., 2010), we show the last iterate global convergence property of the whole sequence.\nThen, we define the potential function, which serves as a keystone to characterize the convergence. Definition 1 (Potential function). The potential function is defined as follows:\nD\u03b7g (x, {yi}, {\u03b3i}) := 1 M M\u2211 i=1 fi(yi) +R(x) + 1 M M\u2211 i=1 \u3008\u03b3i,x\u2212 yi\u3009+ 1 M M\u2211 i=1 1 2\u03b7g \u2016x\u2212 yi\u20162. (10)\nWe then make an additional assumption of KL property over the above potential function. Assumption 4. The proper and closed function D\u03b7g (x, {yi}, {\u03b3i} satisfies the KL property with function \u03d5(v) = cv1\u2212\u03b8 given \u03b8 \u2208 [0, 1) . Remark 6. Given that f is proper and closed as in Assumption 3, Assumption 4 holds true as long as the local objective fi(\u00b7) is a sub-analytic function, a logarithm function, an exponential function, or a semialgebraic function (Chen et al., 2021c). This assumption is rather mild, since most of the nonconvex objective functions encountered in machine learning applications falls in this range. The definition of KL property is moved to Appendix C.1 due to space limitations.\nUnder the KL property, we showcase the convergence property for GKR in the phase I optimization. Theorem 2 (Glocal convergence of phase-one optimization). Suppose that Assumptions 1-4 hold, the global step size is chosen as 0 < \u03b7g \u2264 12L , and that there exists a subsequence of (wt,wi,t,\u03b3i,t) converging to a cluster point (w\u2217,w\u2217i ,\u03b3\u2217i ). Under different settings of \u03b8 of the KL property, the generated sequence of GKR establishes the following convergence rate:\n\u2022 Case \u03b8 = 0. For sufficiently large iteration T > t0,\ndist (\n0, 1 M M\u2211 i=1 \u2207fi(wT ) + \u2202R(wT )\n) = 0 (finite iterations) (11)\n\u2022 Case \u03b8 = (0, 12 ]. For sufficiently large iteration T > t \u2032 0,\ndist (\n0, 1 M M\u2211 i=1 \u2207fi(wT ) + \u2202R(wT )\n) \u2264 \u221a C1rt\u20320 C2 (1\u2212 C4)T\u2212t \u2032 0 (linear convergence) (12)\n\u2022 Case \u03b8 = ( 12 , 1). For all T > 0, we have:\ndist (\n0, 1 M M\u2211 i=1 \u2207fi(wT ) + \u2202R(wT )\n) \u2264 C5T\u2212(4\u03b8\u22122) (sub-linear convergence) (13)\nwhere C1 = 4(\u03b7gL2 + \u03b72gL4 + 1\u03b7g + L 2), C2 = L2\u03b7g + L2 \u2212 1 2\u03b7g , C3 = L + \u03b7gL + 1 \u03b7g + 1, C4 = C2C23c2(1\u2212\u03b8)2 , C5 = \u221a\nC1 C2\n2\u22124\u03b8 \u221a\n(2\u03b8 \u2212 1)C4 are all positive constants.\nMoreover, the iterate wt converges to the stationary point of problem (P1) with any initialization, i.e., limt\u2192\u221ewt = w\u0302\u2217, where w\u0302\u2217 satisfies 0 \u2208 \u2202R(w\u0302\u2217) + 1M \u2211M i=1\u2207fi(w\u0302\u2217).\nRemark 7. The convergence rate to a stationary point is heavily determined by parameter \u03b8 in the KL property. A smaller \u03b8 implies that the potential function is descended faster in its geometry, and therefore guaranteeing a faster convergence rate. Specifically, for \u03b8 = 0, the stationary point could be reached within finite iterations. For \u03b8 \u2208 (0, 12 ], linear convergence rate can be achieved. While for \u03b8 \u2208 ( 1 2 , 1), only sub-linear convergence rate can be achieved. In summary, as long as the potential function satisfies the KL property with \u03b8 \u2208 [0, 1), the GKR always converges to a stationary point with respect to w in Eq. (2) if T \u2192\u221e.\nThen we use Theorem 3 to characterize the convergence of local fusion phase. Here we apply gradient mapping for the personalized component as convergence criterion (same in (Li & Li, 2018),(Ghadimi et al., 2016), (Metel & Takeda, 2021)), which is formally defined as G\u03b7l(wt,pi,t,k) = 1\u03b7l (pi,t,k \u2212Prox\u00b5\u03b7l\u2016\u00b7\u20161(pi,t,k \u2212 \u03b7l\u22072fi(wt,pi,t,k))), where \u22072fi(wt,pi,t,k) is the gradient respect to the second parameter i.e., p. Assumption 5. The variance of stochastic gradient with respect to p for any w \u2208 Rd and p \u2208 Rd is bounded as follows, E \u2016\u22072fi(w + p; \u03be)\u2212\u22072fi(w + p)\u20162 \u2264 \u03c32. Theorem 3 (Convergence rate of local fusion phase). With assumptions for Theorem 2 and an extra assumption 5, suppose that local step size is chosen as 0 < \u03b7l < 2L+1 , FedSLR in its local fusion phase exhibits the following convergence guarantee:\n1 TK T\u22121\u2211 t=1 K\u22121\u2211 k=1 E[\u2016G\u03b7l(wt,pi,t,k)\u20162]\u2264C6 ( 2(\u03c6i(w\u0302\u2217,pi,0,0)\u2212\u03c6i(w\u0302\u2217,p\u2217i )) TK +C7 T +( 2 C6 +1)\u03c32 )\n(14)\nwhere C6 = 1\u03b7l\u2212L+12 \u03b72l , C7 = (N(N+1)2 + 1)\u2016w0 \u2212 w\u0302 \u2217\u20162 + N(N+1)2 \u03b7g(D\u03b7g (w0, {wi,0}, {\u03b3i,0}) \u2212 D\u03b7g (w\u2217, {w\u2217i }, {\u03b3\u2217i })) + L2 are constants, and \u03c6i(w,p) = f\u0303i(w + p) + R\u0303(p) is the loss in (P2).\nRemark 8. The gradient mapping ||G\u03b7l(wt,pi,t,k)||2 can be viewed as a projected gradient of the fusion loss in (P2). If ||G\u03b7l(wt,pi,t,k)||2 \u2264 , the personalized component pi,t,k is indeed an approximate stationary point for the loss of local fusion, i.e., \u2016\u22072f\u0303i(wt + pi,t) + \u2207R\u0303(pi,t)\u2016 = O( ). where \u2207R\u0303(pi,t) \u2208 \u2202R\u0303(pi,t), see Eq. (8) in (Metel & Takeda, 2021) . Theorem 3 showcases that both the first and second term in the upper bound diminish as T \u2192 \u221e. Therefore, if the variance \u03c32 \u2192 0, which holds if taking full batch size, the stationary point is reached at the rate of O( 1T )."
        },
        {
            "heading": "6 Experiment",
            "text": "In this section, we conduct extensive experiments to validate the efficacy of the proposed FedSLR."
        },
        {
            "heading": "6.1 Experimental Setup",
            "text": "Datasets. We conduct simulation on CIFAR10/CIFAR100/TinyImagenet, with both IID and Non-IID data splitting, respectively. Specifically, for IID splitting, data is splitted uniformly to all the 100 clients. While for Non-IID, we use \u03b1-Dirichlet distribution to split the data to all the clients. Here \u03b1 is set to 0.1 for all the Non-IID experiments. Datails of the setting are given in Appendix B.1.\nBaselines. We compare our proposed FedSLR solution with several baselines, including some general FL solutions, e.g., FedAvg (McMahan et al., 2016), FedDyn (Acar et al., 2021), SCAFFOLD (Karimireddy et al., 2020), some existing PFL solutions, e.g., FedSpa (Huang et al., 2022b) , Ditto (Li et al., 2021c), Per-FedAvg (Fallah et al., 2020), FedRep (Collins et al., 2021), APFL (Deng et al., 2020), LgFedAvg (Liang et al., 2020) and a pure Local solution. We tune the hyper-parameters of the baselines to their best states.\nModels and hyper-parameters. We consistently use ResNet18 with group norm (For CIFAR10/100, with kernel size 3 \u00d7 3 in its first conv, while for tinyimagenet, 7 \u00d7 7 instead) in all set of experiments. We use an SGD optimizer with weight decay parameter 1e\u22123 for the local solver. The learning rate is initialized as 0.1 and decayed with 0.998 after each communication round. We simulate 100 clients in total, and 10 of them are picked for local training for each round. For all the global methods (i.e., FedSLR(GKR) 5, FedDyn, FedAvg, SCAFFOLD), local epochs and batch size are fixed to 2 and 20. For FedSLR and Ditto, the local epoch used in local fusion is 1, and also with batch size 20. For FedSLR, the proximal stepsize is \u03b7g = 10, the low-rank penalty is \u03bb = 0.0001 and the sparse penalty is \u00b5 = 0.001 in our main experiment."
        },
        {
            "heading": "6.2 Main Results",
            "text": "Performance. We show the accuracy in Figure 2 and Table 1, and discuss the performance comparison by separating IID and Non-IID cases. The performance evaluation could also be interpreted by its representation visualization, see Figure 4 in Appendix B.3.1.\n5We test the performance of GKR model obtained by Phase I optimization via deploying it to all the clients.\n\u2022 Best accuracy performance in Non-IID. Our personalized solution FedSLR(mixed) significantly outperforms all the other personalized baselines in all the three datasets. Particularly, FedSLR achieves 3.52% higher accuracy to Ditto, 8.32% and 18.46% accuracy gain to FedSpa and Per-FedAvg in the Non-IID CIFAR100 task.\n\u2022 Most resilient to performance degradation in IID. We observe that all the personalized solutions experience performance degradation in the IID setting, i.e., their performance usually cannot emulate the SOTA global solution, e.g., FedDyn. However, we see that FedSLR (mixed) is the most resilient one. Though it experiences an accuracy drop (1.45% accuracy drop compared to the non-personalized GKR model), it still maintains the highest accuracy compared to other personalized baselines.\n\u2022 Competitive convergence rate. FedSLR maintains a competitive convergence rate compared to other personalized solutions, though we still observe that in some experimental groups (e.g., IID tinyimagenet) its convergence rate seems to be slower than other baselines in the initial rounds.\nCommunication and model parameters. Table 2 illustrates the communication cost and model complexity with different methods. As shown, GKR model of FedSLR has smaller model complexity with smaller communication overhead in the training phase (approximately 19% of reduction compared to fullmodel transmission). In addition, our results also corroborate that, built upon the low-rank model, FedSLR acquires personalized models with only modicum parameters added. The mixed personalizd model acquires 17.97% accuracy gain with 29% more parameters added upon the global GKR model.\nSensitivity of hyper-parameters. We postpone the ablation result to Appendix B.3.2. Our main observations are that i) properly adjusting low-rank penalty for the GKR facilitates a better knowledge representation, and that ii) properly sparsifying the local component facilitates better representation of local pattern, and thereby promoting personalized performance. These observations further verify that our choice of low-rank plus sparse models as personalized models can further boost performance. Moreover, we perform the sensitivity analysis of the local steps in Section B.3.2. The results show that a sufficiently large K, e.g., two local epochs, is required to guarantee the empirical performance of FedSLR, since our algorithm requires an accurate solution for solving the local sub-problem."
        },
        {
            "heading": "7 Conclusion",
            "text": "In this paper, we present the optimization framework of FedSLR to fuse the personalized pattern into the global knowledge, so as to achieve personalized federated learning. Empirical experiment shows that our solution acquires better representation of the global knowledge, promises higher personalized performance, but incurs smaller downlink communication cost and requires fewer parameters in its model. Theoretically, our analysis on FedSLR concludes that the last iterate of GKR could converge to the stationary point in at least sub-linear convergence rate, and the sparse component, which represents personalized pattern can also asymptotically converge under proper settings."
        },
        {
            "heading": "Acknowledgments",
            "text": "LS is supported by the Major Science and Technology Innovation 2030 \u201cBrain Science and Brain-like Research\u201d key project (No. 2021ZD0201405). WL is supported by Key-Area Research and Development Program of Guangdong Province (2021B0101420002), National Natural Science Foundation of China (62072187), the Major Key Project of PCL (PCL2021A09), and Guangzhou Development Zone Science and Technology Project (2021GH10)."
        },
        {
            "heading": "Organization of Appendix",
            "text": "A Implementation details 17\nA.1 The proximal operator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\nA.2 Alternative designs of solving problem (P1) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\nA.3 Alternative designs of sparse/low-rank formulation . . . . . . . . . . . . . . . . . . . . . . . . 18\nA.4 FedSLR under partial participation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\nA.5 FedSLR with memory-efficient refinement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\nA.6 Further consideration on privacy&robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\nA.6.1 Privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\nA.6.2 Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20"
        },
        {
            "heading": "B Missing contents in experiment 20",
            "text": "B.1 Data splitting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\nB.2 Baselines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\nB.3 Additional experimental results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\nB.3.1 Additional visualization for performance evaluation . . . . . . . . . . . . . . . . . . . . 21\nB.3.2 Hyper-parameters sensitivity of FedSLR . . . . . . . . . . . . . . . . . . . . . . . . . . 21\nB.3.3 Pure global versus pure personalization . . . . . . . . . . . . . . . . . . . . . . . . . . 23\nB.3.4 Wall time of communication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\nB.3.5 Wall time of inference latency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24"
        },
        {
            "heading": "C Missing contents in theoretical analysis 24",
            "text": "C.1 Definition of KL property . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\nC.2 Facts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\nC.3 Missing proof of Theorem 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\nC.3.1 Key lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\nC.3.2 Formal proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\nC.4 Missing proof of Theorem 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\nC.4.1 Key lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\nC.4.2 Formal proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\nC.5 Missing proof of Theorem 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\nC.5.1 Key lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\nC.5.2 Formal proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\nA Implementation details"
        },
        {
            "heading": "A.1 The proximal operator",
            "text": "The proximal operators mentioned in the main paragraph (i.e., nuclear and L1 regularizers) have the following closed-form solution.\nProximal operator for nuclear regularizer. The computation of this operator involves singular value decomposition (SVD) of the weights matrix. After SVD, the operator performs value shrinkage of the singular value. The explicit form is shown below,\nProx\u03bb\u03b7g\u2016\u00b7\u2016\u2217(X) = U diag(S\u03bb\u03b7g (d))V T (15)\nwhere X = U diag(d)V T is the SVD of the averaged matrix, \u03c3(X)) = d is the singular value, and the soft threshold operation Sa(x) is defined as follows:\n(Sa(x))i =  xi \u2212 a xi > a xi + a xi < \u2212a 0 otherwise\n(16)\nNote that the computation needed for this operator is non-trivial, since SVD over the target matrix may requires intense computation.\nProximal operator for L1 regularizer. This operator involves value shrinkage over the target vector, with closed-form as follows,\nProx\u00b5\u2016\u00b7\u20161(x) = S\u00b5(x) (17)\nwhere the S\u00b5(x) is the same soft thresholding operator defined above. This operator is used in the second phase of FedSLR, which only introduces negligible computation, since only additive on each coordinate is required.\nA.2 Alternative designs of solving problem (P1)\nProximal gradient descent is a classical solution with sufficient theoretical guarantee to solve problems with non-smooth regularizer, and specially, regularizer with nuclear norm. We now present two alternative solutions that might potentially solve problem (P1).\nDirect application of proximal gradient in local steps (LPGD). One alternative solution for problem (P1) is to merge the classical proximal gradient descent into local step of FedAvg. Explicitly, we show the following the local update rule for solving problem (P1), as follows.\nFirstly, for local step k \u2208 0, 1 . . . ,K \u2212 1, clients do\n(Local Phase) wi,t,k+1 = Prox\u03b7\u03bb\u2016\u00b7\u2016\u2217(wi,t,k \u2212 \u03b7\u2207fi(wi,t,k)) (18)\nHere, Prox\u03bb\u2016\u00b7\u2016\u2217(X) , arg minZ 12\u2016Z \u2212X\u2016 2 + \u03bb\u2016Z\u2016\u2217 is the standard proximal operator for nuclear norm, which is guaranteed to have closed-form solution (See Appendix A.1).\nAfter K steps of local training, the server performs the general average aggregation over the obtained low rank model, or formally,\n(Aggregation) wt+1 = 1 M M\u2211 i=1 wi,t,K (19)\nHowever, this intuitive solution comes with two main drawbacks: i) Proximal operator may be computationally prohibitive to perform in every step of local training, especially if the training surrogate does not have enough computation resources. ii) The method cannot produce real low-rank model until the model\nconverges. To see this, notice that the GKR wt+1 cannot be low rank unless for all possible pairs i, j \u2208 [M ], wi,t+1 = wj,t+1. In other words, the GKR distributed from server to clients cannot be compressed by factorization, and therefore the downlink communication cannot reduce. However, this solution might potentially ensure a reduced uplink communication, since the local model after training is guaranteed to be low-rank, and therefore can be factorized to smaller entities to transmit.\nDirect Application of proximal gradient in global step (GPGD). Our second alternative solution is to apply the proximal step directly in the server aggregation phase, but the client follows the same local training protocol with FedAvg (without the auxiliary parameter we introduce in FedSLR).\nFormally, for local step k \u2208 0, 1 . . . ,K \u2212 1, clients do:\n(Local Phase) wi,t,k+1 = wi,t,k \u2212 \u03b7\u2207fi(wi,t,k) (20)\nAfter local models are sent back to server, server does the following proximal step:\n(Aggregation) wt+1 = Prox\u03b7\u03bb\u2016\u00b7\u2016\u2217 ( 1 M M\u2211 i=1 wi,t,K ) (21)\nThis alternative design shares the same computation and communication efficiency with FedSLR. However, this solution might not produce the desired convergence property as the general proximal GD algorithm. To see this, first notice that the aggregation step in Eq. (21) can be re-written to wt+1 = Prox\u03b7\u03bb\u2016\u00b7\u2016\u2217 ( wt \u2212 1M \u2211M i=1 \u03b7Ui,t ) where Ui,t , \u2211K k=1\u2207fi(wi,t,k) is the gradient update from the i-th client. However, if we directly apply proximal gradient descent to the global problem (P1), the update rule should be wt+1 = Prox\u03b7\u03bb\u2016\u00b7\u2016\u2217 ( wt \u2212 1M \u2211M i=1 \u03b7\u2207fi(wt) ) . Notice that Ui,t 6= \u2207fi(wt) unless wi,t,k \u2192 wt (which is not true even t \u2192 \u221e due to the presence of client drift in local step, see (Li et al., 2018)). Therefore, the structure of proximal GD cannot be recovered, which means the convergence property of this method cannot be guaranteed using the proximal GD framework.\nA.3 Alternative designs of sparse/low-rank formulation\nIn this paper, we enforce the global component to be low-rank while enforcing the personalized component to be sparse (i.e., LR+S). However, we note that one can easily adapt our algorithm to solve other combinations of our two-stage problem, e.g., enforce Sparse global component + LR personalized component (S+LR). We now discuss some potential combinations as follows.\nS + LR / LR + LR . For enforcing the personalized component to be low-rank, we can simply replace Line 20 in Algorithm 1 with a proximal operator for the nuclear norm to project out some sub-spaces. However, to achieve this goal, we need to perform SVD towards the weights in every personalized step, which would be extremely computationally inefficient.\nS + S . To achieve a sparse global/personalized component, we can modify Line 7 in Algorithm 1 with a proximal operator for L1 norm. Though this alternative is also computationally efficient with FedSLR, its expressiveness is limited compared to our LR+S design. Recent studies (Yu et al., 2017; Jeong & Hwang, 2022) suggest that combining two compression technique could promote the expressiveness of the model. Some further studies (Chen et al., 2021a;b) show that attention matrix for transformer can only be approximated well by sparse + low-rank matrices, but not pure sparse or low-rank matrices.\nA.4 FedSLR under partial participation\nPartial participation, i.e., only a fraction of clients are selected in each round of training, is a common feature for federated learning. In Algorithm 2, we implement partial participation into the framework of FedSLR. In our experiment, we would consistently use Algorithm 2 for partial participation. Here we can apply arbitrary client selection schemes to further improve the practical performance of FedSLR, e.g., Huang et al. (2020; 2022a); Cho et al. (2020).\nAlgorithm 2 FedSLR under partial participation Input Training iteration T ; Local learning rate \u03b7l; Global learning rate \u03b7g ; Local steps K;\n1: procedure Server\u2019s Main Loop 2: for t = 0, 1, . . . , T \u2212 1 do 3: Uniformly sample a fraction of client into St 4: Factorize wt to {Ut,l} and {Vt,l} by applying layer-wise SVD. 5: for i \u2208 St do 6: Send {Ut,l} and {Vt,l} to the i-th client, invoke its main loop and receive wi,t+1 7: \u03b3i,t+1 = \u03b3i,t + 1\u03b7g (wt \u2212wi,t+1)\n8: for i /\u2208 St do 9: \u03b3i,t+1 = \u03b3i,t 10: wt+1 = Prox\u03bb\u03b7g\u2016\u2016\u2217 ( 1 |St| \u2211 i\u2208Stwi,t+1 \u2212 1 M \u2211M i=1 \u03b3i,t+1 \u03b7g ) . Apply the update\n11: procedure Client\u2019s Main Loop 12: Receive {Ut,l} and {Vt,l} from server and recover wt. 13: Call Phase I OPT to obtain wi,t+1 and \u03b3i,t+1. 14: Call Phase II OPT to obtain pi,t,K . 15: Send wi,t+1 to Server, and keep pi,t,K and \u03b3i,t+1 privately. 16: procedure Phase I OPT (GKR) 17: wi,t+1 = arg minw fi(w)\u2212 \u3008\u03b3i,t,w\u3009+ 12\u03b7g \u2016wt \u2212w\u2016\n2 . Train GKR in Local 18: \u03b3i,t+1 = \u03b3i,t + 1\u03b7g (wt \u2212wi,t+1) . Update the Auxiliary Variable 19: Return wi,t+1 and \u03b3i,t+1 20: procedure Phase II OPT (Personalized Component) 21: pi,t,0 = pi,t\u2212,K . t\u2212 is the last time the i-th client is called 22: for k = 0, 1, . . . ,K \u2212 1 do 23: pi,t,k+1 = Prox\u00b5\u03b7\u2016\u00b7\u20161(pi,t,k \u2212 \u03b7l\u22072fi(wt + pi,t,k; \u03be)) . Local Fusion with SGD 24: Return pi,t,K"
        },
        {
            "heading": "A.5 FedSLR with memory-efficient refinement",
            "text": "In algorithm 1, the server needs to track the auxiliary variable \u03b3i,t for each client, which may not be memoryefficient, especially when the number of participated clients is large. We rewrite a memory-efficient algorithm in Algorithm 3. Algorithm 3 only tracks the average of auxiliary variables on the server side (Line 6), which will then be applied in the server aggregation in Line 7. This memory-efficient implementation is identical to Algorithm 1, as they produce the same global iterates in every round."
        },
        {
            "heading": "A.6 Further consideration on privacy&robustness",
            "text": ""
        },
        {
            "heading": "A.6.1 Privacy",
            "text": "Federated learning is venerable to data leakage even though data is not directly exposed to other entities. The attacker can reverse-engineer the raw data using the gradient update transmitted from the client, especially when the adopted batch size and local training step in the local training phase are small. In our setting, the same privacy leakage issues might exist when transferring the GKR between the server and clients. Besides, notice that our FedSLR solution involves additional auxiliary parameters \u03b3i,t, which can indeed approximate the real gradient when training round t\u2192\u221e. It is interesting to investigate if using \u03b3i,t can better reverseengineer the original data with the gradient inversion technique since it is known that when the local step is large, the gradient update of the global model (GKR in our case) cannot precisely recover the real gradient from clients. We leave the evaluation of the extent of data leakage towards FedSLR a future work.\nAlgorithm 3 Memory-efficient FedSLR Input Training iteration T ; Local stepsize \u03b7l; Global stepsize \u03b7g ; Local step K;\n1: procedure Server\u2019s Main Loop 2: for t = 0, 1, . . . , T \u2212 1 do 3: Factorize wt to {Ut,l} and {Vt,l} by applying layer-wise SVD. 4: for i \u2208 [M ] do 5: Send {Ut,l} and {Vt,l} to the i-th client, invoke its main loop and receive wi,t+1 6: \u03b3t+1 = \u03b3t + 1M \u2211M i=1 1 \u03b7g\n(wt \u2212wi,t+1) . Update auxiliary variable on server 7: wt+1 = Prox\u03bb\u03b7g\u2016\u00b7\u2016\u2217 ( 1 M \u2211M i=1wi,t+1 \u2212 \u03b7g\u03b3t+1 ) . Apply the update\n8: procedure Client\u2019s Main Loop 9: Receive {Ut,l} and {Vt,l} from server and recover wt. 10: Call Phase I OPT to obtain wi,t+1 and \u03b3i,t+1. 11: Call Phase II OPT to obtain pi,t,K . 12: Send wi,t+1 to Server, and keep pi,t,K and \u03b3i,t+1 privately. 13: procedure Phase I OPT (GKR) 14: wi,t+1 = arg minw fi(w)\u2212 \u3008\u03b3i,t,w\u3009+ 12\u03b7g \u2016wt \u2212w\u2016\n2 . Train GKR in Local 15: \u03b3i,t+1 = \u03b3i,t + 1\u03b7g (wt \u2212wi,t+1) . Update the auxiliary variable 16: Return wi,t+1 and \u03b3i,t+1 17: procedure Phase II OPT (Personalized Component) 18: pi,t,0 = pi,t\u22121,K 19: for k = 0, 1, . . . ,K \u2212 1 do 20: pi,t,k+1 = Prox\u00b5\u03b7\u2016\u00b7\u20161 (pi,t,k \u2212 \u03b7l\u22072fi(wt + pi,t,k; \u03be)) . Local Fusion with SGD 21: Return pi,t,K\nTo further promote the privacy-preserving ability of our method, defense solution, e.g., differential privacy (Wei et al., 2020; Truex et al., 2020), secure aggregation (Bonawitz et al., 2016; So et al., 2022), trusted execution environment (Mo et al., 2021) can potentially be adapted and integrated into our training protocol."
        },
        {
            "heading": "A.6.2 Robustness",
            "text": "Federated learning is vulnerable to data poisoning attack (Tolpegin et al., 2020; Xie et al., 2019; Bagdasaryan et al., 2018). Malicious clients can modify the data used for training to poison the global model such that the model experiences substantial drops in classification accuracy and recall for all (or some specific) data inputs. For personalized federated learning, the poisoning attack is still effective (Ma et al., 2022) by poisoning the global component, which is shared among all the clients. It is a future work to compare the resilience of data poisoning attacks using our low-rank plus sparse formulation among existing personalized solutions.\nSome potential defense solutions, e.g., adversarial training (Geiping et al., 2021; Yu et al., 2022), certified robustness (Xie et al., 2021), robust aggregation (Pillutla et al., 2019) can potentially be applied in the training phase of the global component to further promote robustness of the personalized models."
        },
        {
            "heading": "B Missing contents in experiment",
            "text": ""
        },
        {
            "heading": "B.1 Data splitting",
            "text": "There are totally M = 100 clients in the simulation. We split the training data to these 100 clients under IID and Non-IID setting. For the IID setting, data are uniformly sampled for each client. For the Non-IID setting, we use \u03b1-Dirichlet distribution on the label ratios to ensure uneven label distributions among devices as (Hsu et al., 2019). The lower the distribution parameter \u03b1 is, the more uneven the label distribution will be, and would be more challenging for FL. After the initial splitting of training data, we sample 100 pieces of testing data from the testing set to each client, with the same label ratio of their training data. Testing is performed on each client\u2019s own testing data and the overall testing accuracy (that we refer to Top-1 Acc\nin our experiment) is calculated as the average of all the client\u2019s testing accuracy. For all the baselines, we consistently use 0.1 participation ratio, i.e., 10 out of 100 clients are randomly selected in each round."
        },
        {
            "heading": "B.2 Baselines",
            "text": "We implement three general FL solutions to compare with the proposed FedSLR, which all produce one single model that is \"versatile\" in performing tasks in all clients. Specifically, FedAvg (McMahan et al., 2016) is the earliest FL solution. SCAFFOLD (Karimireddy et al., 2020) applies variance-reduction based drift correction technique. FedDyn (Acar et al., 2021) applies dynamic regularization to maintain local consistency of the global model. We use Option 2 for the update of control variate of SCAFFOLD, and the penalty of the dynamic regularization in FedDyn is set to 0.1.\nWe also implement several PFL solutions for comparison of FedSLR. Specifically, Ditto (Li et al., 2021c) applies proximal term to constrain the distance between clients\u2019 personalized models and global model. PerFedAvg (Fallah et al., 2020) applies meta learning to search for a global model that is \"easy\" to generalize the personalized tasks. APFL (Deng et al., 2020) utilizes linear interpolation to insert personalized component into the global model. FedRep (Collins et al., 2021) and LGFedAvg (Liang et al., 2020) separate the global layers and personalized layers. In our implementation, algorithm-related hyper-parameters are tuned to their best-states. Specifically, the proximal penalty of Ditto is 0.1, the finetune step-size and local learning rate (i.e., \u03b1 and \u03b2) are set to 0.01 and 0.001, the interpolated parameter of APFL is set to 0.5. For FedRep, we fix the convolutional layers of our model to shared layers, while leaving the last linear layer as personalized layer. For Lg-FedAvg, the convolutional layers are personalized, and the linear layer is shared."
        },
        {
            "heading": "B.3 Additional experimental results",
            "text": "B.3.1 Additional visualization for performance evaluation\nWe show relative accuracy performance of different schemes in Figure 3, where the median of each violin plot demonstrates the median relative accuracy among the clients, and the shape of the violin demonstrates the distribution of their relative accuracy.\nWe also show the t-SNE 2D illustration of the local representation in Figure. 4, to further visualize how the personalized classifier and feature extractor promote classification performance."
        },
        {
            "heading": "B.3.2 Hyper-parameters sensitivity of FedSLR",
            "text": "We conduct experiment on CIFAR-100 to evaluate the hyper-parameters sensitivity of FedSLR.\nSensitivity of low-rank penalty \u03bb. We adjust different values to \u03bb while fixing proximal stepsize \u03b7g = 10 and sparse penalty \u00b5 = 0.001, whose results are available in Table 3. As shown, the communication cost and number of parameters of both the mixed and GKR model are largely lowered as the low-rank penalty escalates. Notably, there is a significant drop of accuracy if the penalty \u03bb is set too large (e.g., 0.001), however, we also see that with proper low-rank penalty (e.g., 0.0001), the accuracy performance improves for both the GKR and mixed models. This concludes that making global component to be low-rank can help better represent global knowledge across clients.\nSensitivity of sparse penalty \u00b5. Then we fix \u03b7g = 10 and low-rank penalty to \u03bb = 1e\u22124 while adjusting \u00b5. As shown in Table 4, via enlarging the sparse penalty, the number of parameters of the personalized models could be lowered, but would sacrifice some accuracy performance. However, we also observe that proper sparse regularization would induce even better performance for the personalized models. This further corroborates that the personalized component to be sparse can better capture the local pattern.\nSensitivity of proximal step size \u03b7g. We then tune the proximal step size \u03b7g while fixing \u03bb = 1e\u22124 and \u00b5 = 0.001. As can be observed, choosing \u03b7g to a proper value is vital to the accuracy performance of FedSLR. Additionally, we see that with a larger \u03b7g, the obtained model size and communication cost can be reduced, which can be explained by looking into the proximal operator. Specifically, for \u03b7g that is too large, the proximal operator would prune out most of the singular value of the model\u2019s weight matrix. Therefore the parameter number along with the communication cost would reduce with a larger \u03b7g, but the accuracy performance would probably degrade simultaneously.\nSensitivity of local steps. In algorithm 1, we requires each client to exactly solve the local sub-problem in line 14, which may not be realistic due to limited local steps. We show in Table 6 how applying different epochs would affect the empirical accuracy performance of FedSLR. Results show that with sufficiently large local epochs, e.g., 2 local epochs, the accuracy performance can be well guaranteed.\nB.3.3 Pure global versus pure personalization\nTo motivate our low-rank-plus-sparse solution, we tune the low-sparse/sparse penalty respectively to extreme cases to recover the pure global and personalized component. Specifically, we first tune the low-rank penalty to 10 (a very large value) to zero out the global component, and adjust the sparse penalty to see how the sparse intensity would affect the personalized component\u2019s performance. The results are shown in Table 7. Additionally, we tune the low-rank penalty, while fixing sparse penalty to a large value to see how the pure global component performs. The results are shown in Table 8.\nOur results show that i) too much sparsity/low-rank penalty would hurt the model\u2019s performance, and ii) pure local component cannot perform better than the pure global component due to lack of information exchange between clients, which justifies the necessity of collaborative training.\nB.3.4 Wall time of communication\nTo demonstrate the communication reduction effect of the proposed solutions. We measure the wall time of each round communication using a local WLAN, as shown in Fig. 5. Our results show that as communication round goes, the communication wall-time of FedSLR drops significantly, since the rank of the model weights is decreasing. Other two baselines, FedAvg and SCAFFOLD maintain the same scale of communication time throughout the training, and SCAFFOLD requires twice communication since it need to transmit the drift control parameters in addition to the model weights.\nB.3.5 Wall time of inference latency\nWe measure the inference latency of the low-rank GKR on a Tesla M60 GPU. The batch size of each batch of testing data is set to 20. The result is shown in Table 9. Our results indicate that factorizing model weights can indeed accelerate the GKR model\u2019s inference speed."
        },
        {
            "heading": "C Missing contents in theoretical analysis",
            "text": "In this section, we shall introduce the details of our theoretical results."
        },
        {
            "heading": "C.1 Definition of KL property",
            "text": "We first show the definition of KL property, which has been widely used to model the optimization landscape of many machine learning tasks, e.g., (Attouch et al., 2010). Definition 2 (KL property). A function g : Rn \u2192 R is said to have the Kurdyka- Lojasiewicz (KL) property at x\u0303 if there exists v \u2208 (0,+\u221e), a neighbouhood U of x\u0303, and a function \u03d5 : [0, v) \u2192 R+, such that for all x \u2208 U with {x : g(x\u0303) < g(x) < g(x\u0303) + v}, the following condition holds,\n\u03d5\u2032(g(x)\u2212 g(x\u0303)) dist(0, \u2202g(x)) > 1,\nwhere \u03d5(v) = cv1\u2212\u03b8 for \u03b8 \u2208 [0, 1) and c > 0.\nThe KL property is a useful analysis tool to characterize the local geometry around the critical points in the non-convex landscape, and could be viewed as a generalization of Polyak-\u0141ojasiewicz (PL) condition(Karimi et al., 2016) when the KL parameter is \u03b8 = 12 (Chen et al., 2021c)."
        },
        {
            "heading": "C.2 Facts",
            "text": "For sake of clearness, we first provide the following facts that can be readily obtained as per the workflow of our algorithm. Fact 1 (Property of solving local subproblem). Recall that Eq. (4) gives, for i \u2208 [M ],\nwi,t+1 = arg min w\nfi(w)\u2212 \u3008\u03b3i,t,w\u3009+ 1\n2\u03b7g \u2016wt \u2212w\u20162 (22)\nMoreover, from the optimality condition of the above equation, the following holds true for i \u2208 [M ].\n\u2207fi(wi,t+1)\u2212 \u03b3i,t \u2212 1 \u03b7g (wt \u2212wi,t+1) = 0 (23)\nFact 2 (Property of auxilliary variable). The update of auxilliary variable gives, for i \u2208 [M ],\n\u03b3i,t+1 \u2212 \u03b3i,t = 1 \u03b7g (wt \u2212wi,t+1) (24)\nMoreover, combining Eq. (23) and (24), for i \u2208 [M ],\n\u03b3i,t+1 = \u2207fi(wi,t+1) (25)\nFact 3 (Property of global aggregation). Aggregation in Eq. (6) gives:\nwt+1 = arg min w 1 2 \u2225\u2225\u2225\u2225\u2225\u2225w \u2212  1 M \u2211 i\u2208[M ] wi,t+1 \u2212 \u03b7g 1 M M\u2211 i=1 \u03b3i,t+1 \u2225\u2225\u2225\u2225\u2225\u2225 2 + \u03b7gR(w)\n= arg min w R(w) + 1 M M\u2211 i=1 \u3008\u03b3i,t+1,w\u3009+ 1 2\u03b7g \u2225\u2225\u2225\u2225\u2225w \u2212 1M M\u2211 i=1 wi,t+1 \u2225\u2225\u2225\u2225\u2225 2\n(26)\nThe optimality condition shows that:\n0 \u2208 \u2202R(wt+1) + 1 M M\u2211 i=1 \u03b3i,t+1 + 1 \u03b7g (wt+1 \u2212 1 M M\u2211 i=1 wi,t+1) (27)\nFact 4 (Global optimality condition). Combining Eq. (25) and Eq, (27), we have:\n0 \u2208 \u2202R(wt+1) + 1 M M\u2211 i=1 \u2207fi(wi,t+1) + 1 \u03b7g\n( wt+1 \u2212\n1 M M\u2211 i=1 wi,t\n) (28)\nFact 5 (Gradient mapping between steps of local fusion). Recall that the gradient mapping is defined as G\u03b7l(wt,pi,t,k) = 1\u03b7l (pi,t,k \u2212 Prox\u00b5\u03b7l\u2016\u00b7\u20161(pi,t,k \u2212 \u03b7l\u22072fi(wt,pi,t,k))). Per Eq. (7) the following holds,\nG\u03b7l(wt,pi,t,k) = 1 \u03b7l (pi,t,k \u2212 pi,t,k+1) (29)"
        },
        {
            "heading": "C.3 Missing proof of Theorem 1",
            "text": "Now we proceed to give the proof of Theorem 1.\nProof sketch. Our proof sketch can be summarized as follows: i) We showcase in Lemma 3 that the potential function is non-decreasing along the sequence, and its descent is positively related to \u2016wi,t+1 \u2212 wi,t\u2016 and \u2016wt+1 \u2212 wt\u2016. Telescoping its descent along the whole sequence to infinite, we can prove that the final converged value of the potential function is the infinite sum of the above two norms. ii) By Lemma 2, we see that converged value of the potential function can not take negatively infinite, and therefore, we further conclude that wi,t+1 \u2192 wi,t and wt+1 \u2192 wt. Combining this with Lemma 1, \u03b3i,t+1 \u2192 \u03b3i,t immediately follows, which corroborates our first claim in the theorem. iii) Then we start our proof of stationary property of the cluster point. Conditioned on the sequence convergence property obtained before, we sequentially show that the residual term in the RHS of the condition is eliminable, that the local gradient at the cluster point and iterates point are interchangeable, and that the subgradient of regularizer at iterates point is a subset of that at the cluster point. iv) Plugging these claims into the global optimality condition Eq. (28), the stationary property follows as stated."
        },
        {
            "heading": "C.3.1 Key lemmas",
            "text": "Lemma 1 (Bounded gap between global and local models). Combining Eq. (24) and L-smoothness assumption, the following relation immediately follows: \u2016wt \u2212wi,t+1\u2016 \u2264 L\u03b7g\u2016wi,t+1 \u2212wi,t\u2016|\nProof. Eq. (24), together with Eq.(25), read:\n\u2207fi(wi,t+1)\u2212\u2207fi(wi,t) = 1 \u03b7g (wt \u2212wi,t+1) (30)\nThen, we arrive at,\n\u2016wt \u2212wi,t+1\u2016 = \u03b7g\u2016\u2207fi(wi,t+1)\u2212\u2207fi(wi,t)\u2016\u2264L\u03b7g\u2016wi,t+1 \u2212wi,t\u2016 (31)\nwhere the last inequality holds by L-smoothness Assumption 1. This completes the proof.\nLemma 2 (Lower bound of potential function). If the cluster point ((w\u2217, {w\u2217i }, {\u03b3\u2217i })) exists, the potential function at the cluster point exhibits the following lower bound:\n\u2212\u221e < D\u03b7g (w\u2217, {w\u2217i }, {\u03b3\u2217i }) (32)\nProof. By definition of the potential function, we have\nD\u03b7g (w\u2217, {w\u2217i }, {\u03b3\u2217i }) = 1 M M\u2211 i=1 fi(w\u2217i ) +R(w\u2217) + 1 M M\u2211 i=1 \u3008\u03b3\u2217i ,w\u2217 \u2212w\u2217i \u3009+ 1 M M\u2211 i=1 1 2\u03b7g \u2016w\u2217 \u2212w\u2217i \u20162\n= 1 M M\u2211 i=1 fi(w\u2217i ) +R(w\u2217) + 1 M M\u2211 i=1 1 2\u03b7g \u2016w\u2217 \u2212w\u2217i + \u03b7g\u03b3\u2217i \u20162 \u2212 1 M M\u2211 i=1 \u03b7g\u2016\u03b3\u2217i \u20162 . (33)\nMoreover, by the definition of cluster point, we have limj\u2192\u221e \u03b3i,tj = \u03b3\u2217i . Combining this with Eq. (25) and Assumption 2, it follows that:\n\u2212\u03b7g\u2016\u03b3\u2217i \u20162 = lim j\u2192\u221e \u2212\u03b7g\u2016\u03b3i,tj\u20162 \u2265 lim j\u2192\u221e \u2212\u03b7g\u2016\u2207fi(wi,tj )\u20162 \u2265 \u2212\u03b7gB2 > \u2212\u221e (34)\nThis together with Assumption 3, the fact that R(\u00b7) can not be negative value, complete the proof.\nLemma 3 (Sufficient and non-increasing descent). The descent of the potential function along the sequence generated by FedSLR can be upper bounded as follows:\nD\u03b7g (wt+1, {wi,t+1}, {\u03b3i,t+1})\u2212D\u03b7g (wt, {wi,t}, {\u03b3i,t})\n\u2264 1 M M\u2211 i=1 ( (L2\u03b7g + L 2 \u2212 1 2\u03b7g )\u2016wi,t+1 \u2212wi,t\u20162 \u2212 1 2\u03b7g \u2016wt+1 \u2212wt\u20162 ) (35) Moreover, if \u03b7g is chosen as 0 < \u03b7g \u2264 12L , the descent is non-increasing along t.\nProof. To evaluate the non-increasing property of potential function along the sequence (wt, {wi,t}, {\u03b3i,t}), we first show the property of the gap between two consecutive iterates, and notice that:\nD\u03b7g (wt+1, {wi,t+1}, {\u03b3i,t+1})\u2212D\u03b7g (wt, {wi,t}, {\u03b3i,t}) = D\u03b7g (wt+1, {wi,t+1}, {\u03b3i,t+1})\u2212D\u03b7g (wt, {wi,t+1}, {\u03b3i,t+1})\ufe38 \ufe37\ufe37 \ufe38\nT1\n+D\u03b7g (wt, {wi,t+1}, {\u03b3i,t+1})\u2212D\u03b7g (wt, {wi,t+1}, {\u03b3i,t})\ufe38 \ufe37\ufe37 \ufe38 T2\n+D\u03b7g (wt, {wi,t+1}, {\u03b3i,t})\u2212D\u03b7g (wt, {wi,t}, {\u03b3i,t})\ufe38 \ufe37\ufe37 \ufe38 T3\n(36)\nBounding T1. By definition of potential function, term T1 can be expanded and upper-bounded as follows:\nD\u03b7g (wt+1, {wi,t+1}, {\u03b3i,t+1})\u2212D\u03b7g (wt, {wi,t+1}, {\u03b3i,t+1})\n=R(wt+1)\u2212R(wt) + 1 M M\u2211 i=1 \u3008\u03b3i,t+1,wt+1 \u2212wt\u3009\n+ 1 M \u2211 i\u2208M ( 12\u03b7g \u2016wt+1 \u2212wi,t+1\u20162 \u2212 1 2\u03b7g \u2016wt \u2212wi,t+1\u20162)\n=R(wt+1)\u2212R(wt) + 1 M M\u2211 i=1 \u3008\u03b3i,t+1,wt+1 \u2212wt\u3009+ 1 M \u2211 i\u2208M\n1 2\u03b7g \u3008wt+1 +wt \u2212 2wi,t+1,wt+1 \u2212wt\u3009\ufe38 \ufe37\ufe37 \ufe38 since a2\u2212b2=(a+b)(a\u2212b)\n=R(wt+1)\u2212R(wt) + \u3008 1 M M\u2211 i=1 \u03b3i,t+1 + 1 M M\u2211 i=1 \u03b7g(wt+1 \u2212wi,t+1),wt+1 \u2212wt\u3009\n\u2212 1 M M\u2211 i=1 1 2\u03b7g \u2016wt+1 \u2212wt\u20162\n=\u2212R(wt) +R(wt+1) + \u3008 g\ufe38\ufe37\ufe37\ufe38 by Eq.(27) ,wt \u2212wt+1\u3009 \u2212 1 M M\u2211 i=1 1 2\u03b7g \u2016wt+1 \u2212wt\u20162\n\u2264\u2212 1 M M\u2211 i=1 1 2\u03b7g \u2016wt+1 \u2212wt\u20162\n(37)\nwhere g \u2208 \u2202R(wt+1) is one of the sub-gradient such that equation holds for Eq. (27). The last inequality holds since for convex function f(\u00b7) and any subgradient g at point x, claim f(x) + g(y \u2212 x) \u2264 f(y) holds.\nBounding T2. Now we proceed to give upper-bound of term T2, as follows,\nD\u03b7g (wt, {wi,t+1}, {\u03b3i,t+1})\u2212D\u03b7g (wt, {wi,t+1}, {\u03b3i,t})\n= 1 M M\u2211 i=1 \u3008\u03b3i,t+1 \u2212 \u03b3i,t,wt \u2212wi,t+1\u3009 = 1 M \u2211 i\u2208[M ] \u3008\u2207fi(wi,t+1)\u2212\u2207fi(wi,t),wt \u2212wi,t+1\u3009\ufe38 \ufe37\ufe37 \ufe38 See first case of Eq. (25)\n= 1 M \u2211 i\u2208[M ] \u03b7g\u2016\u2207fi(wi,t+1)\u2212\u2207fi(wi,t)\ufe38 \ufe37\ufe37 \ufe38 See Eq. (23) \u20162\n\u2264 1 M \u2211 i\u2208[M ] L2\u03b7g\u2016wi,t+1 \u2212wi,t\u20162\ufe38 \ufe37\ufe37 \ufe38 L smoothness, Assump 1\n(38)\nBounding T3. Term T3 can be bounded as follows,\nD\u03b7g (wt, {wi,t+1}, {\u03b3i,t})\u2212D\u03b7g (wt, {wi,t}, {\u03b3i,t})\n= 1 M M\u2211 i=1 (fi(wi,t+1)\u2212 fi(wi,t)) + 1 M M\u2211 i=1 \u3008\u03b3i,t,wi,t \u2212wi,t+1\u3009\n+ 1 M M\u2211 i=1 ( 12\u03b7g \u2016wt \u2212wi,t+1\u20162 \u2212 1 2\u03b7g \u2016wt \u2212wi,t\u20162)\n= 1 M M\u2211 i=1 (fi(wi,t+1)\u2212 fi(wi,t)) + 1 M M\u2211 i=1 \u3008\u03b3i,t,wi,t \u2212wi,t+1\u3009\n+ 1 M \u2211 i\u2208M 1 2\u03b7g \u30082wt \u2212wi,t \u2212wi,t+1,wi,t \u2212wi,t+1\u3009\ufe38 \ufe37\ufe37 \ufe38\na2\u2212b2=(a+b)(a\u2212b)\n))\n= 1 M M\u2211 i=1\n(fi(wi,t+1)\u2212 fi(wi,t)) + \u3008 [\n1 M M\u2211 i=1\n(\u03b3i,t + \u03b7g(wt \u2212wi,t+1)) ] ,wi,t \u2212wi,t+1\u3009\n\u2212 1 M M\u2211 i=1 1 2\u03b7g \u2016wi,t+1 \u2212wi,t\u20162\n(39)\nBy L-smoothness, we have \u2212f(wi,t) \u2264 \u2212f(wi,t+1)\u2212\u3008\u2207f(wi,t+1),wi,t\u2212wi,t+1\u3009+ L2 \u2016wi,t\u2212wi,t+1\u2016 2. Plugging this into the above equation gives:\nD\u03b7g (wt, {wi,t+1}, {\u03b3i,t})\u2212D\u03b7g (wt, {wi,t}, {\u03b3i,t})\n\u2264 \u2329 1 M M\u2211 i=1 (\u2212\u2207fi(wi,t+1) + \u03b3i,t + \u03b7g(wt \u2212wi,t+1)) ,wi,t \u2212wi,t+1 \u232a\n+ 1 M M\u2211 i=1 (L2 \u2212 1 2\u03b7g )\u2016wi,t+1 \u2212wi,t\u20162\n\u2264 1 M M\u2211 i=1 (L2 \u2212 1 2\u03b7g )\u2016wi,t+1 \u2212wi,t\u20162\n(40)\nwhere the last inequality holds by plugging Eq.(23).\nSumming the upper bound of Eq. (40), Eq. (38) and Eq. (37), we reach the following conclusion:\nD\u03b7g (wt+1, {wi,t+1}, {\u03b3i,t+1})\u2212D\u03b7g (wt, {wi,t}, {\u03b3i,t})\n\u2264 1 M M\u2211 i=1 ( (L2\u03b7g + L 2 \u2212 1 2\u03b7g )\u2016wi,t+1 \u2212wi,t\u20162 \u2212 1 2\u03b7g \u2016wt+1 \u2212wt\u20162 ) (41) Further, if \u03b7g is chosen as 0 < \u03b7g \u2264 12L , such that L 2\u03b7g + L2 \u2212 1 2\u03b7g < 0 and \u2212 1\n2\u03b7g \u2264 0, the non-increasing property follows immediately."
        },
        {
            "heading": "C.3.2 Formal proof",
            "text": "Now we showcase the formal proof of Theorem 1. We derive the complete proof into two parts.\nThe first part is to prove claim i)\nlim j\u2192\u221e (wtj+1, {wtj+1}, {\u03b3i,tj+1}) = lim j\u2192\u221e (wtj , {wtj}, {\u03b3i,tj}) = (w\u2217, {w\u2217i }, {\u03b3\u2217i }) (42)\nTelescoping the descent. Lemma 3 shows that the descent of potential function satisfies some nice property (i.e., non-increasing) if properly choosing learning rate. To proceed from Lemma 3, we telescope the iterated descent from t = 0, . . . , T \u2212 1, which gives,\nD\u03b7g (wT , {wi,T }, {\u03b3i,T })\u2212D\u03b7g (w0, {wi,0}, {\u03b3i,0})\n\u2264 1 M T\u2211 t=0 M\u2211 i=1 ( (L2\u03b7g + L 2 \u2212 1 2\u03b7g )\u2016wi,t+1 \u2212wi,t\u20162 \u2212 1 2\u03b7g \u2016wt+1 \u2212wt\u20162 ) (43)\nOn the other hand, by assumption, a cluster point (w\u2217, {w\u2217i }, {\u03b3\u2217i }) of sequence (wt, {wi,t}, {\u03b3i,t}) exists. Then, there exists a subsequence (wtj , {wi,tj}, {\u03b3i,tj}) satisfies:\nlim j\u2192\u221e (wtj , {wi,tj}, {\u03b3i,tj}) = (w\u2217, {w\u2217i }, {\u03b3\u2217i }) (44)\nBy the lower semi-continuous property of D(\u00b7) (given that the functions f(\u00b7) and R(\u00b7) are closed), we have:\nD\u03b7g (w\u2217, {w\u2217i }, {\u03b3\u2217i }) \u2264 lim j\u2192\u221e inf D\u03b7g (wtj , {wtj}, {\u03b3i,tj}) (45)\nThis together with inequality (43) yields:\nD\u03b7g (w\u2217, {w\u2217i }, {\u03b3\u2217i })\u2212D\u03b7g (w0, {wi,0}, {\u03b3i,0}) \u2264 lim j\u2192\u221e D\u03b7g (wtj , {wtj}, {\u03b3i,tj})\u2212D\u03b7g (w0, {wi,0}, {\u03b3i,0})\n\u2264 1 M \u221e\u2211 t=1 M\u2211 i=1 ( (L2\u03b7g + L\u2212 1 2\u03b7g )\u2016wi,t+1 \u2212wi,t\u20162 \u2212 1 2\u03b7g \u2016wt+1 \u2212wt\u20162 ) (46)\nLower bound the potential function at cluster point. Since D\u03b7g (w\u2217, {w\u2217i }, {\u03b3\u2217i }) is lower bounded as per Lemma 2, the following relation follows immediately:\n\u2212\u221e < 1 M \u221e\u2211 t=1 M\u2211 i=1 ( (L2\u03b7g + L\u2212 1 2\u03b7g )\u2016wi,t+1 \u2212wi,t\u20162 \u2212 1 2\u03b7g \u2016wt+1 \u2212wt\u20162 ) (47)\nDerive the convergence property. Recall that L2\u03b7g + L\u2212 12\u03b7g \u2264 0 as per our choice of \u03b7g. It follows,\nlim t\u2192\u221e \u2016wi,t+1 \u2212wi,t\u2016 = 0\u21d2 wi,t+1 \u2192 wi,t, lim t\u2192\u221e \u2016wt+1 \u2212wt\u2016 = 0\u21d2 wt+1 \u2192 wt (48)\nCombining the above result with Lemma 1, we further obtain that,\nlim t\u2192\u221e \u2016wt \u2212wi,t+1\u2016 = 0 \u21d2 wi,t+1 \u2192 wt. (49)\nBy the update of Eq. (24), we obtain that \u2016\u03b3i,t+1 \u2212 \u03b3i,t\u2016 = \u03b7g\u2016wt \u2212wi,t+1\u2016, and therefore,\nlim t\u2192\u221e \u2016\u03b3i,t+1 \u2212 \u03b3i,t\u2016 = 0 \u21d2 \u03b3i,t+1 \u2192 \u03b3i,t. (50)\nPlugging the above results into Eq. (44), we have:\nlim j\u2192\u221e (wtj+1, {wtj+1}, {\u03b3i,tj+1}) = lim j\u2192\u221e (wtj , {wtj}, {\u03b3i,tj}) = (w\u2217, {w\u2217i }, {\u03b3\u2217i }) (51)\nThe second part of proof is to verify Claim ii): the cluster point is a stationary point of the global problem.\nStarting from the global optimality condition. Choosing t = tj in Eq.(28) and taking the limit j \u2192\u221e, it follows that:\n0 \u2208 lim j\u2192\u221e \u2202R(wtj ) + 1 M M\u2211 i=1 lim j\u2192\u221e \u2207fi(wi,tj ) + lim j\u2192\u221e 1 \u03b7g\n( wtj \u2212\n1 M M\u2211 i=1 wi,tj\n) (52)\nThe residual term is eliminable. Since limj\u2192\u221e \u2016wtj \u2212wtj\u22121\u2016 = 0 and limj\u2192\u221e \u2016wtj\u22121 \u2212wi,tj\u2016 = 0, we obtain that limj\u2192\u221ewtj = limj\u2192\u221ewi,tj . Subsequently, by eliminating the residual, we reach this conclusion:\n0 \u2208 lim j\u2192\u221e \u2202R(wtj ) + 1 M M\u2211 i=1 lim j\u2192\u221e \u2207fi(wi,tj ) (53)\n\u2207fi(wi,tj ) and \u2207fi(w\u2217i ) are interchangeable. By L-smoothness and convergence of iterates, we obtain:\nlim j\u2192\u221e \u2016\u2207fi(wi,tj )\u2212\u2207fi(w\u2217)\u2016 \u2264 L\u2016wi,tj \u2212w\u2217\u2016\n\u2264 L(\u2016wi,tj \u2212wtj\u22121\u2016+ \u2016wtj\u22121 \u2212wtj\u2016+ \u2016wtj \u2212w\u2217\u2016) = 0\n(54)\nwhere the last equation holds by Eq. (48) and Eq. (49). Subsequently, we indeed have\u2207fi(wi,tj )\u2192 \u2207fi(w\u2217), i.e., they are interchangeable within the limit, and plugging this into Eq. (53), we obtain that:\n0 \u2208 lim j\u2192\u221e \u2202R(wtj ) + 1 M M\u2211 i=1 \u2207fi(w\u2217) (55)\nSubgradients \u2202R(wtj ) is a subset of \u2202R(w\u2217t ). As per Eq. (26), we have:\nwtj = arg min w R(w) + 1 M M\u2211 i=1 \u3008\u03b3i,t+1,w\u3009+ 2 \u03b7g \u2225\u2225\u2225\u2225\u2225w \u2212 1M M\u2211 i=1 wi,t+1 \u2225\u2225\u2225\u2225\u2225 2\n(56)\nTherefore, it follows that:\nR(wtj ) + 1 M M\u2211 i=1 \u3008\u03b3i,tj ,wtj \u3009+ 1 2\u03b7g \u2225\u2225\u2225\u2225\u2225\u2225wtj \u2212 1M \u2211 i\u2208[M ] wi,tj \u2225\u2225\u2225\u2225\u2225\u2225 2\n\u2264 R(w\u2217) + 1 M M\u2211 i=1 \u3008\u03b3i,tj ,w\u2217\u3009+ 1 2\u03b7g \u2225\u2225\u2225\u2225\u2225\u2225w\u2217 \u2212 1M \u2211 i\u2208[M ] wi,tj \u2225\u2225\u2225\u2225\u2225\u2225 2 (57)\nTaking expectation over randomness, extending j \u2192\u221e to both sides, and applying wtj \u2192 w\u2217, it yields:\nlim j\u2192\u221e supR(wtj ) \u2264 R(w\u2217) (58)\nOn the other hand, since nuclear norm R(\u00b7) is lower-semi-continuous, it immediately follows that:\nlim j\u2192\u221e infR(wtj ) \u2265 R(w\u2217) (59)\nThis together with Eq. (58) , we have:\nlim j\u2192\u221e R(wtj ) = R(w\u2217) (60)\nApplying Eq. (60) into the robustness property of sub-differential, which gives:{ v \u2208 Rn : \u2203xt \u2192 x, f(xt)\u2192 f(x), vt \u2192 v, vt \u2208 \u2202f ( xt )} \u2286 \u2202f(x), (61)\nwe further obtain that lim j\u2192\u221e \u2202R(wtj ) \u2286 \u2202R(w\u2217), (62) which showcases that the subgradients at point wtj is indeed a subset of those at cluster point w\u2217.\nDerive the property at cluster point w\u2217. Plugging this into Eq. (55), we arrive at our final conclusion as follows:\n0 \u2208 lim j\u2192\u221e \u2202R(w\u2217) + 1 M M\u2211 i=1 \u2207fi(w\u2217) (63)\nThis completes the proof."
        },
        {
            "heading": "C.4 Missing proof of Theorem 2",
            "text": "Then we show the proof of Theorem 2 . Before the formal proof, we give a proof sketch for sake of readability.\nProof sketch. The milestone of the proof can be summarized as follows. i) We first define an auxiliary term called residual of the potential function, and find that it has some very nice property (Lemma 4), i.e., rt \u2192 0 and rt \u2265 0. ii) We find that the squared sub-differential of the global loss can be bounded by a term with \u2016wi,t+1 \u2212wi,t\u20162. On the other hand, we derive that rt can also be lower bounded by \u2016wi,t+1 \u2212wi,t\u2016. Combining both derivation, we connect the local loss\u2019s sub-differential with rt. iii) Then we further derive the upper bound of rt is connected with the sub-differential of the potential function, which is also related to the term \u2016wi,t+1\u2212wi,t\u2016. iv) By jointing all the derived factors, we derive the recursion rt\u2212rt+1 = C4r2\u03b8t . Jointing the property of rt, we derive the analysis of final convergence rate under three cases of \u03b8, which completes the proof of our first statement. On the other hand, we derive the global convergence of wi,t by showing that it is summable. Combining this with the convergence result between wt and wi,t, and the conclusion in Theorem 1, we show that wt can indeed converge to its stationary point."
        },
        {
            "heading": "C.4.1 Key lemmas",
            "text": "Lemma 4 (Limit of residual). Under the same assumption of Theorem 2, the residual rt := D\u03b7g (wt, {wi,t}, {\u03b3i,t}) \u2212 D\u03b7g (w\u2217, {w\u2217i }, {\u03b3\u2217i }) establishes the following property: i) rt \u2265 0 for t > 0, ii) limt\u2192\u221e rt = 0.\nProof. We first show that rt \u2265 0 for t \u2265 0. From the lower semi-continuity of D\u03b7g (\u00b7), we obtain that:\nlim j\u2192\u221e inf D\u03b7g (wtj , {wi,tj}, {\u03b3i,tj})\u2212D\u03b7g (w\u2217,w\u2217i ,\u03b3\u2217i ) \u2265 0. (64)\nFurther, by the non-increasing descent property shown by Lemma 3, for t > 0, we have\nD\u03b7g (wt, {wt}, {\u03b3i,t}) \u2265 lim j\u2192\u221e inf D\u03b7g (wtj , {wtj}, {\u03b3i,tj}) (65)\nCombining Inequality (64) and (65) , we obtain that for t > 0:\nrt = D\u03b7g (wt, {wt}, {\u03b3i,t})\u2212D\u03b7g (w\u2217,w\u2217i ,\u03b3\u2217i ) \u2265 0, (66)\nwhich shows our first claim.\nNow we show the limit of rt. Since rt is lower-bounded by 0, and is non-increasing, we see that the limitation limt\u2192\u221e rt exists. On the other hand, by Eq. (60), we have limj\u2192\u221eR(wtj ) = R(w\u2217). By the convergence of sequence Eq. (8) and the continuity of fi(\u00b7), we have limj\u2192\u221e fi(wtj ) = fi(w\u2217). Therefore, we prove that,\nlim j\u2192\u221e\n{ D\u03b7g (wtj , {wtj}, {\u03b3i,tj} =\n1 M M\u2211 i=1 fi(wtj ) +R(wtj ) + 1 M M\u2211 i=1 \u3008\u03b3i,tj ,wtj \u2212wi,tj \u3009+ 1 M M\u2211 i=1 2 \u03b7g \u2016wtj \u2212wi,tj\u20162\n}\n\u2264 { D\u03b7g (w\u2217, {w\u2217}, {\u03b3\u2217i } =\n1 M M\u2211 i=1 fi(w\u2217) +R(w\u2217) + 1 M M\u2211 i=1 \u3008\u03b3\u2217i ,w\u2217 \u2212w\u2217i \u3009+ 1 M M\u2211 i=1 2 \u03b7g \u2016w\u2217 \u2212w\u2217i \u20162 } (67)\nwhich indeed shows limj\u2192\u221e sup rtj \u2264 0. Combining this with Eq. (64), we arrive at limj\u2192\u221e rtj = 0. Given that limt\u2192\u221e rt exists, we reach the conclusion limt\u2192\u221e rt = 0."
        },
        {
            "heading": "C.4.2 Formal proof",
            "text": "Proof. Let rt = D\u03b7g (wt, {wi,t}, {\u03b3i,t}) \u2212 D\u03b7g (w\u2217, {w\u2217i }, {\u03b3\u2217i,t}) captures the residual of potential function between an iterated point (wt, {wi}, {\u03b3i,t}) and the cluster point (w\u2217,w\u2217i ,\u03b3\u2217i ).\nDerive the upper bound of subgradient. By inequality (28), we have:\n0 \u2208 \u2202R(wt) + 1 M M\u2211 i=1 \u2207fi(wi,t) + 1 \u03b7g (wt \u2212 1 M M\u2211 i=1 wi,t) (68)\nwhich in turn implies that:\n1 M M\u2211 i=1 (\u2207fi(wt)\u2212\u2207fi(wi,t))\u2212 1 \u03b7g (wt \u2212 1 M M\u2211 i=1 wi,t) \u2208 1 M M\u2211 i=1 \u2207fi(wt) + \u2202R(wt) (69)\nRecall that the definition of distance between two sets is dist(C,D) = inf{\u2016x \u2212 y\u2016|x \u2208 C, y \u2208 D}. Viewing the LHS of the above inequality as a point in the set (i.e., the RHS), the following relation follows,\ndist2 (\n0, 1 M M\u2211 i=1 \u2207fi(wt) + \u2202R(wt)\n)\n= \u2225\u2225\u2225\u2225\u2225 1M M\u2211 i=1 (\u2207fi(wt)\u2212\u2207fi(wi,t))\u2212 1 \u03b7g (wt \u2212 1 M M\u2211 i=1 wi,t) \u2225\u2225\u2225\u2225\u2225 2\n\u2264 2 M M\u2211 i=1 \u2016\u2207fi(wt)\u2212\u2207fi(wi,t)\u20162 + 2 \u03b7gM M\u2211 i=1 \u2016wt \u2212wi,t\u20162 \u2264 2 M \u2211 i\u2208M ( 1 \u03b7g + L2)\u2016wt \u2212wi,t\u20162 \u2264 4 M \u2211 i\u2208M ( 1 \u03b7g + L2)(\u2016wt \u2212wi,t+1\u20162 + \u2016wi,t+1 \u2212wi,t\u20162) \u2264 4 M \u2211 i\u2208M ((\u03b7g + \u03b72gL2)(\u2016\u2207fi(wi,t+1)\u2212\u2207fi(wi,t)\u20162 + ( 1 \u03b7g + L2)\u2016wi,t+1 \u2212wi,t\u20162) \u2264 1 M \u2211 i\u2208M C1\u2016wi,t+1 \u2212wi,t\u20162\n.\n(70)\nwhere C1 = 4(\u03b7gL2 + \u03b72gL4 + 1\u03b7g + L 2). The second-to-last inequality holds by Lemma 1.\nConnect the subdifferential with rt. On the other hand, by Lemma 3, we have:\nrt \u2212 rt+1 \u2265 1 M M\u2211 i=1 ( C2\u2016wi,t+1 \u2212wi,t\u20162 + 1 2\u03b7g \u2016wt+1 \u2212wt\u20162 ) \u2265 1 M M\u2211 i=1 C2\u2016wi,t+1 \u2212wi,t\u20162 (71)\nwhere C2 = L2\u03b7g + L2 \u2212 1 2\u03b7g is a positive constant by assumption.\nSince rt+1 \u2265 0 for any t > 0 (See Lemma 4), the following relation holds true:\ndist (\n0, 1 M M\u2211 i=1 \u2207fi(wt) + \u2202R(wt) ) \u2264 \u221a C1 C2 \u00b7 \u221a rt (72)\nNotice above that the subgradient of the global loss can be upper bound by rt. In the following, we shall introduce KL property to achieve an upper bound of rt.\nUpper bound rt with KL property of the potential function. Since the potential function satisfies KL property with \u03c6(v) = cv1\u2212\u03b8, we know for all t that satisfies rt > 0, the following relation holds true,\nc(1\u2212 \u03b8)r\u2212\u03b8t dist(0, \u2202D\u03b7g (wt, {wi,t}, {\u03b3i,t})) \u2265 1, (73)\nwith its equivalence form as follows,\nr\u03b8t \u2264 c(1\u2212 \u03b8) dist(0, \u2202D\u03b7g (wt, {wi,t}, {\u03b3i,t})), (74)\nUpper bound the subdifferential of the potential function. We now show that the subgradient of the potential function can indeed be upper bounded. Note that \u2202D\u03b7g (\u00b7, \u00b7, \u00b7) , (\u2202wtD\u03b7g (\u00b7, \u00b7, \u00b7),\u2207wi,tD\u03b7g (\u00b7, \u00b7, \u00b7),\u2207\u03b3i,tD\u03b7g (\u00b7, \u00b7, \u00b7)). Now we separately give the subdifferential with respect to different groups of variables.\n\u2202wtD\u03b7g (wt, {wi,t}, {\u03b3i,t}) = \u2202R(wt) + 1 M M\u2211 i=1 \u03b3i,t + 1 \u03b7g (wt \u2212 1 M M\u2211 i=1 wi,t) 3 0 (75)\nwhere the last inequality holds by the optimality condition (27).\nThen we proceed to show the gradient with respect to wi,t, as follows,\n\u2207wi,tD\u03b7g (wt, {wi,t}, {\u03b3i,t})\n= 1 M (\u2207fi(wi,t)\u2212 \u03b3i,t \u2212 1 \u03b7g (wt \u2212wi,t)) = 1 M (\u2207fi(wi,t+1)\u2212 \u03b3i,t \u2212 1 \u03b7g\n(wt \u2212wi,t+1)\ufe38 \ufe37\ufe37 \ufe38 =0, by Eq. (23)\n+ 1 \u03b7g (wi,t \u2212wi,t+1) +\u2207fi(wi,t)\u2212\u2207fi(wi,t+1))\n= 1 M (\u2207fi(wi,t)\u2212\u2207fi(wi,t+1) + 1 \u03b7g (wi,t \u2212wi,t+1))\n(76)\nFinally, the gradient with respect to \u03b3i,t has this equivalent form:\n\u2207\u03b3i,tD\u03b7g (wt, {wi,t}, {\u03b3i,t}) = 1 M (wt \u2212wi,t)\n= 1 M (wt \u2212wi,t+1 +wi,t+1 \u2212wi,t) = \u03b7g M (\u03b3i,t+1 \u2212 \u03b3i,t + 1 \u03b7g\n(wi,t+1 \u2212wi,t)\ufe38 \ufe37\ufe37 \ufe38 by Eq. 23 )\n= \u03b7g M (\u2207fi(wi,t+1)\u2212\u2207fi(wi,t) + 1 \u03b7g (wi,t+1 \u2212wi,t))\n(77)\nNote that dist(0, \u2202D\u03b7g (\u00b7, \u00b7, \u00b7)) = \u221a\ndist2(0, \u2202wtD\u03b7g (\u00b7, \u00b7, \u00b7)) + \u2016\u2207wi,tD\u03b7g (\u00b7, \u00b7, \u00b7)\u20162 + \u2016\u2207\u03b3i,tD\u03b7g (\u00b7, \u00b7, \u00b7)\u20162. Summing the above sub-differentials, we arrive at,\ndist(0, \u2202D\u03b7g (wt, {wi,t}, {\u03b3i,t})) \u2264 1 + \u03b7g M M\u2211 i=1 (\u2016\u2207fi(wi,t)\u2212\u2207fi(wi,t+1) + 1 \u03b7g (wi,t \u2212wi,t+1)\u2016\n\u2264 1 + \u03b7g M M\u2211 i=1 (\u2016\u2207fi(wi,t)\u2212\u2207fi(wi,t+1)\u2016+ 1 \u03b7g \u2016wi,t \u2212wi,t+1\u2016)\n= 1 M M\u2211 i=1 C3\u2016wi,t \u2212wi,t+1\u2016\n(78)\nwhere C3 = L+ \u03b7gL+ 1\u03b7g + 1.\nUpper bound to rt with the subdifferential of the potential function. This together with Eq. (74) show that, rt can be bounded as follows,\nr\u03b8t \u2264 1 M M\u2211 i=1 c(1\u2212 \u03b8)C3\u2016wi,t \u2212wi,t+1\u2016, (79)\nRecall that the norm term \u2016wi,t \u2212 wi,t+1\u20162 is bounded as Inequality (71). We first taking square of both sides of (79), yielding\nr2\u03b8t \u2264 ( 1 M M\u2211 i=1 1 c(1\u2212 \u03b8)C3\u2016wi,t \u2212wi,t+1\u2016 )2 \u2264 1 M M\u2211 i=1 c2(1\u2212 \u03b8)C23\u2016wi,t \u2212wi,t+1\u20162 (80)\nPlugging Eq. (71) into the above results, under the case that rt > 0 for all t > 0, we can ensure:\nrt \u2212 rt+1 \u2265 C2\nC23c 2(1\u2212 \u03b8)2 r\n2\u03b8 t\n= C4r2\u03b8t (81)\nwhere C4 = C2C23c2(1\u2212\u03b8)2 is a positive constant for \u03b8 \u2208 [0, 1).\nSeparate into three cases. We then separate our analysis under three different settings of \u03b8.\n\u2022 Firstly, assume D\u03b7g (x,y,\u03b3) satisfies the KL property with \u03b8 = 0. As per Eq. (81), if rt > 0 holds for all t > 0, we have rt \u2265 C4 for all t > 0. Recall from Lemma 4 that limt\u2192\u221e rt = 0, which means rT \u2265 C4 cannot be true when T is a sufficiently large number. Therefore, there must exist a t0 such that rt0 = 0. If this is the case, observed from Lemma 4 that rt \u2265 0 for all t > 0, and that rt is non-increasing. It is sufficient to conclude that for a sufficiently large number T > t0, rT = 0 must hold true. Inserting this result into RHS of Eq. (72), the desired rate follows immediately.\n\u2022 Then, consider the case D\u03b7g (x,y,\u03b3) satisfies the KL property with \u03b8 \u2208 (0, 12 ]. First we assume that rt > 0 for all t > 0. From Eq. (81), it follows that: rt+1 \u2264 rt \u2212 C4r2\u03b8t . Since limt\u2192\u221e rt = 0, there must exist a t\u20320 such that, r2\u03b8T \u2265 rT hold for all T > t\u20320, and equivalently, rT+1 \u2264 (1 \u2212 C4)rT . This further implies that rT \u2264 (1 \u2212 C4)T\u2212t \u2032 0rt\u20320 . Now consider another case that there exists a t0 such that rt = 0 for all\nT > t0, following the same analysis given in the previous case we reach the same result rT = 0 holds for all sufficiently large T \u2265 t\u20320. These together with Eq. (72) implying that for a sufficiently large T > t\u20320,\ndist ( 0, 1M \u2211M i=1\u2207fi(wT ) + \u2202R(wT ) ) \u2264 max( \u221a C1rt\u20320 C2 (1\u2212 C4)T , 0) \u2264 \u221a C1rt\u20320 C2 (1\u2212 C4)T\u2212t \u2032 0 .\n\u2022 Finally, suppose D\u03b7g (x,y,\u03b3) satisfies the KL property with \u03b8 \u2208 ( 12 , 1). We first evaluate the case that rt > 0 for all t > 0. Define a continuous non-increasing function g : (0,+\u221e) \u2192 R by g(x) = x\u22122\u03b8. Plugging this definition into Eq. (81), we have C4 \u2264 (rt \u2212 rt+1)g(rt) \u2264 \u222b rt rt+1 g(x)dx = r 1\u22122\u03b8 t+1 \u2212r 1\u22122\u03b8 t 2\u03b8\u22121\nholds for all t \u2265 0. Since 2\u03b8 \u2212 1 > 0, we have r1\u22122\u03b8t+1 \u2212 r 1\u22122\u03b8 t \u2264 (2\u03b8 \u2212 1)C4. Summing from t = 0 to t = T \u2212 1, we have rT \u2264 1\u22122\u03b8 \u221a T (2\u03b8 \u2212 1)C4. Moreover, same as the previous analysis, we have rT for all\nt \u2265 0. Thus, these together with Eq. (72) show that for T \u2265 0, dist ( 0, 1M \u2211M i=1\u2207fi(wT ) + \u2202R(wT ) ) \u2264\nmax( \u221a\nC1 C2\n2\u22124\u03b8 \u221a T (2\u03b8 \u2212 1)C4, 0) \u2264 C5T\u2212(4\u03b8\u22122) where C5 = \u221a C1 C2 2\u22124\u03b8 \u221a (2\u03b8 \u2212 1)C4.\nNow we try to showcase that the iterate wt can globally converge the the stationary point w\u0302\u2217.\nDefine D\u2217 = D\u03b7g (w\u2217, {w\u2217i }, {\u03b3\u2217i }). By construction, we derive that,\n1 M M\u2211 i=1 C3\u2016wi,t \u2212wi,t+1\u2016 \u00b7 (\u03d5(D\u03b7g (wt, {wi,t}, {\u03b3i,t})\u2212D\u2217)\u2212 \u03d5(D\u03b7g (wt+1, {wi,t+1}, {\u03b3i,t+1})\u2212D\u2217))\n\u2265dist(0, \u2202D\u03b7g (wt, {wi,t}, {\u03b3i,t})) \u00b7 (\u03d5(D\u03b7g (wt, {wi,t}, {\u03b3i,t})\u2212D\u2217) \u2212 \u03d5(D\u03b7g (wt+1, {wi,t+1}, {\u03b3i,t+1})\u2212D\u2217)) \u2265dist(0, \u2202D\u03b7g (wt, {wi,t}, {\u03b3i,t})) \u00b7 \u03d5\u2032(D\u03b7g (wt, {wi,t}, {\u03b3i,t})\u2212D\u2217) \u00b7 (D\u03b7g (wt, {wi,t}, {\u03b3i,t})\u2212D\u03b7g (wt+1, {wi,t+1}, {\u03b3i,t+1})) \u2265D\u03b7g (wt, {wi,t}, {\u03b3i,t})\u2212D\u03b7g (wt+1, {wi,t+1}, {\u03b3i,t+1}) (82)\nwhere the second to last inequality holds by concavity of \u03d5 and the last one holds by KL property. Plugging Eq. (71) into the above inequality, it yields,\n1 M M\u2211 i=1 C3\u2016wi,t \u2212wi,t+1\u2016 \u00b7 (\u03d5(D\u03b7g (wt, {wi,t}, {\u03b3i,t})\u2212D\u2217)\u2212 \u03d5(D\u03b7g (wt+1, {wi,t+1}, {\u03b3i,t+1})\u2212D\u2217))\n\u2265 1 M M\u2211 i=1 C2\u2016wi,t+1 \u2212wi,t\u20162\n(83)\nTherefore, by reorganize, we obtain that,\n1 M M\u2211 i=1 \u2016wi,t \u2212wi,t+1\u2016\n\u2264C3 C2 (\u03d5(D\u03b7g (wt, {wi,t}, {\u03b3i,t})\u2212D\u2217)\u2212 \u03d5(D\u03b7g (wt+1, {wi,t+1}, {\u03b3i,t+1})\u2212D\u2217))\n(84)\nBy telescoping from t = 1 to \u221e, we have,\n\u221e\u2211 t=1 1 M M\u2211 i=1 \u2016wi,t \u2212wi,t+1\u2016\n\u2264C3 C2 (\u03d5(D\u03b7g (w0, {wi,0}, {\u03b3i,0})\u2212D\u2217)\u2212 \u03d5(D\u03b7g (w\u221e, {wi,\u221e}, {\u03b3i,\u221e})\u2212D\u2217))\n\u2264C3 C2 (\u03d5(D\u03b7g (w0, {wi,0}, {\u03b3i,0})\u2212D\u2217)) <\u221e\n(85)\nwhere the second inequality holds by limt\u2192\u221e rt = 0, as stated in Lemma 4. Therefore \u2016wi,t \u2212 wi,t+1\u2016 is summable, which means the whole sequence wi,t is convergent to its cluster point w\u2217i , i.e., limt\u2192\u221ewi,t = w\u2217i . Moreover, based on the convergence result between wi,t+1 and wt in Eq. (49), we also see that limt\u2192\u221ewt = w\u2217. Note that in Theorem 1, we observe that the cluster point is indeed the stationary point, and therefore limt\u2192\u221ewt = w\u0302\u2217. This concludes the proof."
        },
        {
            "heading": "C.5 Missing proof of Theorem 3",
            "text": "Let a stochastic Proximal GM as G\u03b7l,\u03be(w,p) , 1\u03b7l ( p\u2212 prox\u03b7l,R\u0303(p\u2212 \u03b7l\u2207fi(w + p; \u03be) ) , which serves as an auxiliary variable in the proof.\nProof Sketch. Our proof starts with the L-smoothness expansion at the iterative point. For the linear term in the expansion, we treat it with Lemma 5 to recover the l2-norm between sequential iterates, i.e., \u2016pi,t+1 \u2212 pi,t\u20162. Then we measure the error brought by stochastic proximal gradient by constructing the term \u3008\u22072fi(wt + pi,t)\u2212\u22072fi(wt + pi,t; \u03be),pi,t+1 \u2212 pi,t\u3009 , which can indeed be bounded by the variance \u03c32. By reorganizing, the stochastic gradient mapping (GM) can be directly bounded. Finally, we leverage the smoothness of gradient mapping, i.e., Lemma 7 to track the error between stochastic/real gradient mapping."
        },
        {
            "heading": "C.5.1 Key lemmas",
            "text": "Lemma 5. The following relation holds true,\n\u3008\u22072fi(wt + pi,t; \u03be),pi,t,k \u2212 pi,t,k+1\u3009 \u2265 (R\u0303(pi,t,k+1)\u2212 R\u0303(pi,t,k)) + 1 \u03b7l \u2016pi,t,k+1 \u2212 pi,t,k\u20162 (86)\nProof. By the optimality condition of the prox function, we know that there exists a sub-gradient s \u2208 \u2202R\u0303(pi,t,k) such that pi,t,k+1 \u2212 pi,t,k + \u03b7l\u22072fi(wt + pi,t,k) + \u03b7ls = 0. Further, we obtain that, \u3008pi,t,k+1 \u2212\npi,t,k + \u03b7l\u22072fi(wt + pi,t,k; \u03be) + \u03b7ls,pi,t,k \u2212 pi,t,k+1\u3009 = 0, which further implies that,\n\u3008\u22072fi(wt + pi,t,k; \u03be),pi,t,k \u2212 pi,t,k+1\u3009 = \u3008s,pi,t,k+1 \u2212 pi,t,k\u3009+ 1 \u03b7l \u2016pi,t,k+1 \u2212 pi,t,k\u20162\n\u2265 (R\u0303(pi,t,k+1)\u2212 R\u0303(pi,t,k)) + 1 \u03b7l \u2016pi,t,k+1 \u2212 pi,t,k\u20162\n(87)\nwhere the last inequality holds by convexity of R\u0303(\u00b7).\nLemma 6 (Young Inequality). \u3008a, b\u3009 \u2264 12\u2016a\u2016 2 + 12\u2016b\u2016 2 (88) Lemma 7 (Smoothness of Gradient Mapping). The gradient mapping and a stochastic one exhibits the following smoothness property,\n\u2016G\u03b7l,\u03be(wt,pi,t,k)\u2212 G\u03b7l(wt,pi,t,k)\u2016 = \u2016 1 \u03b7l (prox\u03b7l,R\u0303(p\u2212 \u03b7l\u2207fi(w + p; \u03be))\n\u2212 prox\u03b7l,R\u0303(p\u2212 \u03b7l\u2207fi(w + p)))\u2016 \u2264 \u2016\u2207fi(w + p; \u03be)\u2212\u2207fi(w + p)\u2016\n(89)\nwhere the inequality holds due to the nonexpansivity of the proximal operator of proper closed convex functions, see Property 5 in (Metel & Takeda, 2021)."
        },
        {
            "heading": "C.5.2 Formal proof",
            "text": "Proof. By L-smoothness, we obtain that, Et,kfi (w\u0302\u2217 + pi,t,k+1)\n\u2264fi(w\u0302\u2217 + pi,t,k) + Et,k \u3008\u22072fi(w\u0302\u2217 + pi,t,k),pi,t,k+1 \u2212 pi,t,k\u3009+ L\n2 Et,k||pi,t,k+1 \u2212 pi,t,k|| 2\n\u2264fi(w\u0302\u2217 + pi,t,k) + Et,k \u3008\u22072fi(w\u0302\u2217 + pi,t,k)\u2212\u22072fi(wt + pi,t,k),pi,t,k+1 \u2212 pi,t,k\u3009\ufe38 \ufe37\ufe37 \ufe38 T1\n+ Et,k \u3008\u22072fi(wt + pi,t,k)\u2212\u22072fi(wt + pi,t,k; \u03be),pi,t,k+1 \u2212 pi,t,k\u3009\ufe38 \ufe37\ufe37 \ufe38 T2\n+ Et,k \u3008\u22072fi(wt + pi,t,k; \u03be),pi,t,k+1 \u2212 pi,t,k\u3009\ufe38 \ufe37\ufe37 \ufe38 T3 +L2 Et,k||pi,t,k+1 \u2212 pi,t,k|| 2\n(90)\nBy Young\u2019s inequality and L-smoothness, we obtain that,\nT1 \u2264 1 2Et,k\u2016\u22072fi(w\u0302 \u2217 + pi,t,k)\u2212\u22072fi(wt + pi,t,k)\u20162 + 1 2Et,k\u2016pi,t,k+1 \u2212 pi,t,k\u2016 2\n\u2264 L 2\n2 Et,k\u2016w\u0302 \u2217 \u2212wt\u20162 + 1 2Et,k\u2016pi,t,k+1 \u2212 pi,t,k\u2016\n2 (91)\nBesides, T2 can be bounded as follows,\nT2\n= Et,k \u3008\u22072fi(wt + pi,t,k; \u03be)\u2212\u22072fi(wt + pi,t,k),G\u03b7l,\u03be(wt,pi,t,k)\u3009 \u2264 Et,k \u3008\u22072fi(wt + pi,t,k; \u03be)\u2212\u22072fi(wt + pi,t,k),G\u03b7l,\u03be(wt,pi,t,k)\u2212 G\u03b7l(wt,pi,t,k) + G\u03b7l(wt,pi,t,k)\u3009 \u2264 Et,k \u3008\u22072fi(wt + pi,t,k; \u03be)\u2212\u22072fi(wt + pi,t,k),G\u03b7l(wt,pi,t,k)\u3009 + Et,k\u2016\u22072fi(wt + pi,t,k; \u03be)\u2212\u22072fi(wt + pi,t,k)\u2016\u2016G\u03b7l,\u03be(wt,pi,t,k)\u2212 G\u03b7l(wt,pi,t,k)\u2016 \u2264 Et,k \u2016\u22072fi(wt + pi,t,k; \u03be)\u2212\u22072fi(wt + pi,t)\u2016 \u2016G\u03b7l,\u03be(wt,pi,t,k)\u2212 G\u03b7l(wt,pi,t,k)\u2016 \u2264 Et,k \u2016\u22072fi(wt + pi,t,k; \u03be)\u2212\u22072fi(wt + pi,t,k)\u20162\n\u2264 \u03c32\n(92)\nwhere the second-to-last and the last inequality respectively holds by Lemma 7, and assumption 5.\nFinally, term T3 can be bounded with Lemma 5, as follows,\nT3 \u2264 R\u0303(pi,t,k)\u2212 Et,kR\u0303(pi,t,k+1)\u2212 1 \u03b7l Et,k||pi,t,k+1 \u2212 pi,t,k||2 (93)\nBy re-arranging T1 and T2 into Eq. (90), and let \u03c6i(w,p) = f\u0303i(w + p) + R\u0303(p), we have,\nEt,k\u03c6i(w\u0302\u2217,pi,t,k+1) \u2264 \u03c6i(w\u0302\u2217,pi,t,k) + ( L 2 \u2212 1 \u03b7l + 12)Et,k||pi,t,k+1 \u2212 pi,t,k|| 2\n+ L 2\n2 Et,k\u2016w\u0302 \u2217 \u2212wt\u20162 + \u03c32\n\u2264 \u03c6i(w\u0302\u2217,pi,t,k) + ( (L+ 1)\u03b72l\n2 \u2212 \u03b7l)Et,k\u2016G\u03b7l,\u03be(wt,pi,t,k)\u2016 2\n+ L 2\n2 Et,k\u2016w\u0302 \u2217 \u2212wt\u20162 + \u03c32,\n(94)\nIf 0 < \u03b7l < 2L+1 , it follows that,\nEt,k||G\u03b7l,\u03be(wt,pi,t,k)||2 \u2264 2Et,k(\u03c6i(w\u0302\u2217,pi,t,k)\u2212 \u03c6i(w\u0302\u2217,pi,t,k+1)) + L2Et,k\u2016w\u0302\u2217 \u2212wt\u20162 + \u03c32\n2\u03b7l \u2212 (L+ 1)\u03b72l (95)\nTaking expectation over the condition and telescoping the bound from k = 0 to K \u2212 1 and t = 0 to T \u2212 1, it gives,\n1 TK T\u22121\u2211 t=0 K\u22121\u2211 k=0 E||G\u03b7l,\u03be(wt,pi,t,k)||2\n\u2264 2(\u03c6i(w\u0302\u2217,pi,0,0)\u2212 \u03c6i(w\u0302\u2217,pi,T\u22121,K\u22121)) + 1T\n\u2211T\u22121 t=0 L 2\u2016w\u0302\u2217 \u2212wt\u20162 + \u03c32\n2\u03b7l \u2212 (L+ 1)\u03b72l\n\u2264 2E(\u03c6i(w\u0302\u2217,pi,0,0)\u2212 \u03c6i(w\u0302\u2217,p\u2217i )) + 1T\n\u2211T\u22121 t=0 L 2E\u2016w\u0302\u2217 \u2212wt\u20162 + \u03c32\n2\u03b7l \u2212 (L+ 1)\u03b72l\n(96)\nThen we shall expand the term 1T \u2211T t=1 L\n2\u2016w\u0302\u2217\u2212wt\u20162 using the global convergence result given by Theorem 2, and the epsilon definition of limits. Specifically, by wt \u2192 w\u0302\u2217, there exists a positive constant N such that for any t \u2265 N , \u2016wt \u2212 w\u0302\u2217\u2016 \u2264 holds for > 0. Then plugging this result into the expansion, we have:\n1 T T\u22121\u2211 t=0 EL2\u2016wt \u2212 w\u0302\u2217\u20162 = 1 T ( N\u2211 t=0 L2E\u2016wt \u2212 w\u0302\u2217\u20162 + T\u22121\u2211 t=N+1 L2\u2016wt \u2212 w\u0302\u2217\u20162)\n= 1 T ( N\u2211 t=0 L2E\u2016wt \u2212 w\u0302\u2217\u20162 + T\u22121\u2211 t=N+1 L2 2)\n(97)\nChoosing = 1\u221a T , we have:\n1 T T\u22121\u2211 t=0 L2\u2016wt \u2212 w\u0302\u2217\u20162 \u2264 \u2211N t=0 L 2E\u2016wt \u2212 w\u0302\u2217\u20162 T + L 2 T (98)\nNotice that \u2016wt+1 \u2212 wt\u20162 \u2264 2\u03b7g(D\u03b7g (wt, {wi,t}, {\u03b3i,t}) \u2212 D\u03b7g (wt+1, {wi,t+1}, {\u03b3i,t+1})) as per Inequality (41). Utilizing this fact, the following inequality holds for t \u2265 1,\n.\nE\u2016wt \u2212 w\u0302\u2217\u20162 \u2264t \u00b7 E(\u2016w0 \u2212 w\u0302\u2217\u20162 + t\u2211\nj=1 \u2016wj\u22121 \u2212wj\u20162)\n\u2264t \u00b7 E(\u2016w0 \u2212 w\u0302\u2217\u20162 + t\u2211\nj=1 \u2016wj\u22121 \u2212wj\u20162)\n\u2264t \u00b7 E(\u2016w0 \u2212 w\u0302\u2217\u20162 + \u03b7g(D\u03b7g (w0, {wi,0}, {\u03b3i,0})\u2212D\u03b7g (wt, {wi,t}, {\u03b3i,t})) \u2264t \u00b7 \u2016w0 \u2212 w\u0302\u2217\u20162 + t\u03b7g(D\u03b7g (w0, {wi,0}, {\u03b3i,0})\u2212D\u03b7g (w\u2217, {w\u2217i }, {\u03b3\u2217i })\n(99)\nwhere the last inequality holds by Inequality (66). Plugging this into Inequality (97), we obtain that,\n1 T T\u22121\u2211 t=0 L2\u2016wt \u2212 w\u0302\u2217\u20162\n\u2264 (N(N+1)2 + 1)\u2016w0 \u2212 w\u0302 \u2217\u20162 + N(N+1)2 \u03b7g(D\u03b7g (w0, {wi,0}, {\u03b3i,0})\u2212D\u03b7g (w \u2217, {w\u2217i }, {\u03b3\u2217i })) + L2\nT\n(100)\nLet C7 = (N(N+1)2 +1)\u2016w0\u2212w\u0302 \u2217\u20162+N(N+1)2 \u03b7g(D\u03b7g (w0, {wi,0}, {\u03b3i,0})\u2212D\u03b7g (w \u2217, {w\u2217i }, {\u03b3\u2217i }))+L2. Plugging Inequality (98) into RHS of (96), we arrive at,\n1 TK T\u22121\u2211 t=1 K\u22121\u2211 k=1 E||G\u03b7l,\u03be(wt,pi,t,k)||2 \u2264 2(\u03c6i(w\u0302\u2217,pi,0,0)\u2212 \u03c6i(w\u0302\u2217,p\u2217i )) + C7T + \u03c3 2 2\u03b7l \u2212 (L+ 1)\u03b72l (101)\nFurther notice that the real gradient mapping can be bounded as follows,\n1 TK T\u22121\u2211 t=1 K\u22121\u2211 k=1 E||G\u03b7l(wt,pi,t,k)||2\n\u2264 2 TK T\u22121\u2211 t=1 K\u22121\u2211 k=1 (E||G\u03b7l,\u03be(wt,pi,t,k)||2 + E||G\u03b7l(wt,pi,t,k)\u2212 G\u03b7l,\u03be(wt,pi,t,k)||2)\n\u2264 2 TK T\u22121\u2211 t=1 K\u22121\u2211 k=1 (E||G\u03b7l(wt,pi,t,k)||2 + E\u2016\u22072fi(wt + pi,t,k)\u2212\u22072fi(wt + pi,t,k; \u03be)\u20162)\n\u2264 2 TK T\u22121\u2211 t=1 K\u22121\u2211 k=1 (E||G\u03b7l(wt,pi,t,k)||2 + \u03c32) \u2264 2(\u03c6i(w\u0302\u2217,pi,0,0)\u2212 \u03c6i(w\u0302\u2217,p\u2217i )) + C7T + (2\u03b7l \u2212 (L+ 1)\u03b7 2 l + 1)\u03c32\n\u03b7l \u2212 L+12 \u03b7 2 l\n(102)\nwhere the second inequality holds by Lemma 7. This completes the proof."
        }
    ],
    "title": "Fusion of Global and Local Knowledge for Personalized Federated Learning",
    "year": 2023
}