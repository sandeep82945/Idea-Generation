{
    "abstractText": "The neuroscience community has developed many convolutional neural networks (CNNs) for the early detection of Alzheimer\u2019s disease (AD). Population graphs are thought of as nonlinear structures that capture the relationships between individual subjects represented as nodes, which allows for the simultaneous integration of imaging and non-imaging information as well as individual subjects\u2019 features. Graph convolutional networks (GCNs) generalize convolution operations to accommodate non-Euclidean data and aid in the mining of topological information from the population graph for a disease classification task. However, few studies have examined how GCNs\u2019 input properties affect AD-staging performance. Therefore, we conducted three experiments in this work. Experiment 1 examined how the inclusion of demographic information in the edgeassigning function affects the classification of AD versus cognitive normal (CN). Experiment 2 was designed to examine the effects of adding various neuropsychological tests to the edge-assigning function on the mild cognitive impairment (MCI) classification. Experiment 3 studied the impact of the edge assignment function. The best result was obtained in Experiment 2 on multi-class classification (AD, MCI, and CN). We applied a novel framework for the diagnosis of AD that integrated CNNs and GCNs into a unified network, taking advantage of the excellent feature extraction capabilities of CNNs and population-graph processing capabilities of GCNs. To learn high-level anatomical features, DenseNet was used; a set of population graphs was represented with nodes defined by imaging features and edge weights determined by different combinations of imaging or/and nonimaging information, and the generated graphs were then fed to the GCNs for classification. Both binary classification and multi-class classification showed improved performance, with an accuracy of 91.6% for AD versus CN, 91.2% for AD versus MCI, 96.8% for MCI versus CN, and 89.4% for multi-class classification. The population graph\u2019s imaging features and edge-assigning functions can both significantly affect classification accuracy.",
    "authors": [
        {
            "affiliations": [],
            "name": "Lan Lin"
        },
        {
            "affiliations": [],
            "name": "Wenjie Kang"
        },
        {
            "affiliations": [],
            "name": "Shen Sun"
        },
        {
            "affiliations": [],
            "name": "Shuicai Wu"
        }
    ],
    "id": "SP:e134327115ac5950fe53efb19c810562fbf2c5f5",
    "references": [
        {
            "authors": [
                "Y.-H. Hsiao",
                "C.-H. Chang",
                "P.-W. Gean"
            ],
            "title": "Impact of Social Relationships on Alzheimer\u2019s Memory Impairment: Mechanistic Studies",
            "venue": "J. Biomed. Sci. 2018,",
            "year": 2018
        },
        {
            "authors": [
                "M. Calabr\u00f2",
                "C. Rinaldi",
                "G. Santoro",
                "C. Crisafulli"
            ],
            "title": "The Biological Pathways of Alzheimer Disease: A Review",
            "venue": "AIMS Neurosci. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "C. Gillis",
                "F. Mirzaei",
                "M. Potashman",
                "M.A. Ikram",
                "N. Maserejian"
            ],
            "title": "The Incidence of Mild Cognitive Impairment: A Systematic Review and Data Synthesis",
            "venue": "Alzheimers Dement",
            "year": 2019
        },
        {
            "authors": [
                "S. Fathi",
                "M. Ahmadi",
                "A. Dehnad"
            ],
            "title": "Early Diagnosis of Alzheimer\u2019s Disease Based on Deep Learning: A Systematic Review",
            "venue": "Comput. Biol. Med",
            "year": 2022
        },
        {
            "authors": [
                "W. Kang",
                "L. Lin",
                "B. Zhang",
                "X. Shen",
                "S. Wu"
            ],
            "title": "Alzheimer\u2019s Disease Neuroimaging Initiative Multi-Model and Multi-Slice Ensemble Learning Architecture Based on 2D Convolutional Neural Networks for Alzheimer\u2019s Disease Diagnosis",
            "venue": "Comput. Biol. Med",
            "year": 2021
        },
        {
            "authors": [
                "M. Liu",
                "F. Li",
                "H. Yan",
                "K. Wang",
                "Y. Ma",
                "L. Shen",
                "M. Xu"
            ],
            "title": "Alzheimer\u2019s Disease Neuroimaging Initiative. A Multi-Model Deep Convolutional Neural Network for Automatic Hippocampus Segmentation and Classification in Alzheimer\u2019s Disease",
            "year": 2020
        },
        {
            "authors": [
                "R.J. Meszl\u00e9nyi",
                "K. Buza",
                "Z. Vidny\u00e1nszky"
            ],
            "title": "Resting State FMRI Functional Connectivity-Based Classification Using a Convolutional Neural Network Architecture",
            "venue": "Front. Neuroinform. 2017,",
            "year": 2017
        },
        {
            "authors": [
                "T.-A. Song",
                "S. Roy Chowdhury",
                "F. Yang",
                "H. Jacobs",
                "G. El Fakhri",
                "Q. Li",
                "K. Johnson",
                "J. Dutta"
            ],
            "title": "Graph convolutional neural networks for alzheimer\u2019s disease classification",
            "venue": "Proc. IEEE Int. Symp. Biomed. Imaging",
            "year": 2019
        },
        {
            "authors": [
                "A. Kazi",
                "S.A. Krishna",
                "S. Shekarforoush",
                "K. Kortuem",
                "N. Navab"
            ],
            "title": "Self-Attention Equipped Graph Convolutions for Disease Prediction",
            "venue": "In Proceedings of the 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI), Venice, Italy,",
            "year": 2019
        },
        {
            "authors": [
                "S. Yu",
                "G. Yue",
                "A. Elazab",
                "X. Song",
                "T. Wang",
                "B. Lei"
            ],
            "title": "Multi-Scale Graph Convolutional Network for Mild Cognitive Impairment Detection",
            "venue": "In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention; International Workshop on Graph Learning in Medical Imaging, Shenzhen, China,",
            "year": 2019
        },
        {
            "authors": [
                "H. Jiang",
                "P. Cao",
                "M. Xu",
                "J. Yang",
                "O. Zaiane"
            ],
            "title": "Hi-GCN: A Hierarchical Graph Convolution Network for Graph Embedding Learning of Brain Network and Brain Disorders Prediction",
            "venue": "Comput. Biol. Med",
            "year": 2020
        },
        {
            "authors": [
                "F. Zhao",
                "N. Li",
                "H. Pan",
                "X. Chen",
                "Y. Li",
                "H. Zhang",
                "N. Mao",
                "D. Cheng"
            ],
            "title": "Multi-View Feature Enhancement Based on Self-Attention Mechanism Graph Convolutional Network for Autism Spectrum Disorder Diagnosis",
            "venue": "Front. Hum. Neurosci",
            "year": 2022
        },
        {
            "authors": [
                "D. Zeng",
                "C. Zhao",
                "Z. Quan"
            ],
            "title": "CID-GCN: An Effective Graph Convolutional Networks for Chemical-Induced Disease Relation Extraction",
            "venue": "Front. Genet",
            "year": 2021
        },
        {
            "authors": [
                "R. Bai",
                "R. Huang",
                "L. Zheng",
                "Y. Chen",
                "Y. Qin"
            ],
            "title": "Structure Enhanced Deep Clustering Network via a Weighted Neighbourhood Auto-Encoder",
            "venue": "Neural. Netw",
            "year": 2022
        },
        {
            "authors": [
                "P.K. Crane",
                "A. Carle",
                "L.E. Gibbons",
                "P. Insel",
                "R.S. Mackin",
                "A. Gross",
                "R.N. Jones",
                "S. Mukherjee",
                "S.M. Curtis",
                "D Harvey"
            ],
            "title": "Development and Assessment of a Composite Score for Memory in the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI)",
            "venue": "Brain Imaging Behav. 2012,",
            "year": 1914
        },
        {
            "authors": [
                "L.E. Gibbons",
                "A.C. Carle",
                "R.S. Mackin",
                "D. Harvey",
                "S. Mukherjee",
                "P. Insel",
                "S.M. Curtis",
                "D. Mungas",
                "P.K. Crane"
            ],
            "title": "Alzheimer\u2019s Disease Neuroimaging Initiative A Composite Score for Executive Functioning, Validated in Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) Participants with Baseline Mild Cognitive Impairment",
            "venue": "Brain Imaging Behav",
            "year": 2012
        },
        {
            "authors": [
                "S.-E. Choi",
                "S. Mukherjee",
                "L.E. Gibbons",
                "R.E. Sanders",
                "R.N. Jones",
                "D. Tommet",
                "J. Mez",
                "E.H. Trittschuh",
                "A. Saykin",
                "M Lamar"
            ],
            "title": "Development and Validation of Language and Visuospatial Composite Scores in ADNI",
            "venue": "Alzheimers Dement. 2020,",
            "year": 2020
        },
        {
            "authors": [
                "J. Ashburner"
            ],
            "title": "Computational Anatomy with the SPM Software",
            "venue": "Magn. Reson. Imaging",
            "year": 2009
        },
        {
            "authors": [
                "A.C. Evans",
                "D.L. Collins",
                "S.R. Mills",
                "E.D. Brown",
                "T.M. Peters"
            ],
            "title": "3D Statistical Neuroanatomical Models from 305 MRI Volumes",
            "venue": "In Proceedings of the Nuclear Science Symposium and Medical Imaging Conference,",
            "year": 1993
        },
        {
            "authors": [
                "G. Huang",
                "Z. Liu",
                "V. Laurens",
                "K.Q. Weinberger"
            ],
            "title": "Densely Connected Convolutional Networks",
            "venue": "In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2017
        },
        {
            "authors": [
                "B. Zhang",
                "L. Lin",
                "S. Wu"
            ],
            "title": "A Review of Brain Atrophy Subtypes Definition and Analysis for Alzheimer\u2019s Disease Heterogeneity Studies",
            "venue": "J. Alzheimers Dis",
            "year": 2021
        },
        {
            "authors": [
                "B. Zhang",
                "L. Lin",
                "S. Wu",
                "Z.H.M.A. Al-Masqari"
            ],
            "title": "Multiple Subtypes of Alzheimer\u2019s Disease Base on Brain Atrophy Pattern",
            "venue": "Brain Sci",
            "year": 2021
        },
        {
            "authors": [
                "B. Zhang",
                "L. Lin",
                "L. Liu",
                "X. Shen",
                "S. Wu"
            ],
            "title": "Concordance of Alzheimer\u2019s Disease Subtypes Produced from Different Representative Morphological Measures: A Comparative Study",
            "venue": "Brain Sci",
            "year": 2022
        },
        {
            "authors": [
                "L. Lin",
                "Z. Fu",
                "X. Xu",
                "S. Wu"
            ],
            "title": "Mouse Brain Magnetic Resonance Microscopy: Applications in Alzheimer Disease",
            "venue": "Microsc. Res. Tech",
            "year": 2015
        },
        {
            "authors": [
                "M. Arnold",
                "K. Nho",
                "A. Kueider-Paisley",
                "T. Massaro",
                "K. Huynh",
                "B. Brauner",
                "S. MahmoudianDehkordi",
                "G. Louie",
                "M.A. Moseley",
                "J.W Thompson"
            ],
            "title": "Sex and APOE E4 Genotype Modify the Alzheimer\u2019s Disease Serum Metabolome",
            "venue": "Nat. Commun",
            "year": 2020
        },
        {
            "authors": [
                "M. Prince",
                "G.-C. Ali",
                "M. Guerchet",
                "A.M. Prina",
                "E. Albanese",
                "Y.-T. Wu"
            ],
            "title": "Recent Global Trends in the Prevalence and Incidence of Dementia, and Survival with Dementia",
            "venue": "Alzheimers Res. Ther. 2016,",
            "year": 2016
        },
        {
            "authors": [
                "R.A. Nebel",
                "N.T. Aggarwal",
                "L.L. Barnes",
                "A. Gallagher",
                "J.M. Goldstein",
                "K. Kantarci",
                "M.P. Mallampalli",
                "E.C. Mormino",
                "L. Scott",
                "W.H Yu"
            ],
            "title": "Understanding the Impact of Sex and Gender in Alzheimer\u2019s Disease: A Call to Action",
            "year": 2018
        },
        {
            "authors": [
                "Z. Li",
                "X. Jiang",
                "Y. Wang",
                "Y. Kim"
            ],
            "title": "Applied Machine Learning in Alzheimer\u2019s Disease Research: Omics, Imaging, and Clinical Data",
            "venue": "Emerg. Top. Life Sci. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "R.C. Petersen",
                "P.S. Aisen",
                "L.A. Beckett",
                "M.C. Donohue",
                "A.C. Gamst",
                "D.J. Harvey",
                "C.R. Jack",
                "W.J. Jagust",
                "L.M. Shaw",
                "A.W Toga"
            ],
            "title": "Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI): Clinical Characterization",
            "venue": "Neurology",
            "year": 2010
        },
        {
            "authors": [
                "T.N. Kipf",
                "M. Welling"
            ],
            "title": "Semi-Supervised Classification with Graph Convolutional Networks",
            "venue": "arXiv 2016,",
            "year": 2016
        },
        {
            "authors": [
                "L.A. Farrer",
                "L.A. Cupples",
                "J.L. Haines",
                "B. Hyman",
                "W.A. Kukull",
                "R. Mayeux",
                "R.H. Myers",
                "M.A. Pericak-Vance",
                "N. Risch",
                "C.M. van Duijn"
            ],
            "title": "Effects of Age, Sex, and Ethnicity on the Association between Apolipoprotein E Genotype and Alzheimer Disease. A Meta-Analysis",
            "venue": "APOE and Alzheimer Disease Meta Analysis Consortium. JAMA",
            "year": 1997
        },
        {
            "authors": [
                "J. Zhang",
                "Y. Lin",
                "X. Dai",
                "W. Fang",
                "X. Wu",
                "X. Chen"
            ],
            "title": "Metformin Treatment Improves the Spatial Memory of Aged Mice in an APOE Genotype-Dependent Manner",
            "venue": "FASEB J. 2019,",
            "year": 2019
        },
        {
            "authors": [
                "E. Ghebremedhin",
                "C. Schultz",
                "D.R. Thal",
                "U. R\u00fcb",
                "T.G. Ohm",
                "E. Braak",
                "H. Braak"
            ],
            "title": "Gender and Age Modify the Association between APOE and AD-Related Neuropathology",
            "venue": "Neurology",
            "year": 2001
        },
        {
            "authors": [
                "B.C. Riedel",
                "P.M. Thompson",
                "R.D. Brinton"
            ],
            "title": "Age, APOE and Sex: Triad of Risk of Alzheimer\u2019s Disease",
            "venue": "J. Steroid Biochem. Mol. Biol",
            "year": 2016
        },
        {
            "authors": [
                "J.S. Andrews",
                "U. Desai",
                "N.Y. Kirson",
                "M.L. Zichlin",
                "D.E. Ball",
                "B.R. Matthews"
            ],
            "title": "Disease Severity and Minimal Clinically Important Differences in Clinical Outcome Assessments for Alzheimer\u2019s Disease Clinical Trials",
            "venue": "Alzheimers Dement. 2019,",
            "year": 2019
        },
        {
            "authors": [
                "N. Coley",
                "S. Andrieu",
                "M. Jaros",
                "M. Weiner",
                "J. Cedarbaum",
                "B. Vellas"
            ],
            "title": "Suitability of the Clinical Dementia Rating-Sum of Boxes as a Single Primary Endpoint for Alzheimer\u2019s Disease Trials",
            "year": 2011
        },
        {
            "authors": [
                "J.M. Cedarbaum",
                "M. Jaros",
                "C. Hernandez",
                "N. Coley",
                "S. Andrieu",
                "M. Grundman",
                "B. Vellas"
            ],
            "title": "Alzheimer\u2019s Disease Neuroimaging Initiative Rationale for Use of the Clinical Dementia Rating Sum of Boxes as a Primary Outcome Measure for Alzheimer\u2019s Disease Clinical Trials",
            "year": 2013
        },
        {
            "authors": [
                "A.B. Tufail",
                "K. Ullah",
                "R.A. Khan",
                "M. Shakir",
                "M.A. Khan",
                "I. Ullah",
                "Y.-K. Ma",
                "M.S. Ali"
            ],
            "title": "On Improved 3D-CNN-Based Binary and Multiclass Classification of Alzheimer\u2019s Disease Using Neuroimaging Modalities and Data Augmentation Methods",
            "venue": "J. Healthc. Eng. 2022,",
            "year": 1914
        },
        {
            "authors": [
                "X. An",
                "Y. Zhou",
                "Y. Di",
                "D. Ming"
            ],
            "title": "Dynamic Functional Connectivity and Graph Convolution Network for Alzheimer\u2019s Disease Classification",
            "venue": "In Proceedings of the 2020 7th International Conference on Biomedical and Bioinformatics Engineering, Kyoto, Japan,",
            "year": 2020
        },
        {
            "authors": [
                "L. Li",
                "H. Jiang",
                "G. Wen",
                "P. Cao",
                "M. Xu",
                "X. Liu",
                "J. Yang",
                "O. Zaiane"
            ],
            "title": "TE-HI-GCN: An Ensemble of Transfer Hierarchical Graph Convolutional Networks for Disorder Diagnosis",
            "venue": "Neuroinformatics",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "Citation: Lin, L.; Xiong, M.; Zhang,\nG.; Kang, W.; Sun, S.; Wu, S.;\nInitiative Alzheimer\u2019s Disease\nNeuroimaging. A Convolutional\nNeural Network and Graph\nConvolutional Network Based\nFramework for AD Classification.\nSensors 2023, 23, 1914. https://\ndoi.org/10.3390/s23041914\nAcademic Editor: Andr\u00e9s\nOrtiz Garc\u00eda\nReceived: 24 December 2022\nRevised: 29 January 2023\nAccepted: 1 February 2023\nPublished: 8 February 2023\nCopyright: \u00a9 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: neuroimaging; Alzheimer\u2019s disease; deep learning; graph convolutional networks"
        },
        {
            "heading": "1. Introduction",
            "text": "Alzheimer\u2019s disease (AD), a progressive and irreversible neurodegenerative pathology, is manifested by progressive memory impairment and cognitive dysfunction [1]. The disease gradually leads to severe cognitive deterioration and eventual death from complications, which places a tremendous burden on patients, families, caregivers, and society. The relative risk of AD rises dramatically after the age of 65 years, and the number of people affected by the disease is expected to reach 107 million by 2050 [2]. Mild cognitive impairment (MCI) is considered an intermediate state between cognitive normal (CN) and AD. About 40% of MCI patients progress to AD within five years [3]. The average annual\nSensors 2023, 23, 1914. https://doi.org/10.3390/s23041914 https://www.mdpi.com/journal/sensors\nSensors 2023, 23, 1914 2 of 20\nconversion rate is about 10\u201315%. The etiology and pathogenesis of AD remain unclear. Accurate diagnosis of AD at an early stage is critical for timely treatment and possible delays in disease progression. Grey matter atrophy is associated with cognitive decline in chronological ageing, MCI, and AD dementia. The magnetic resonance imaging (MRI) technique has significantly increased our understanding of brain atrophy in AD and has been successful in examining the differences between AD patients and healthy controls. However, in routine clinical practice, the interpretation of MRI scans is largely based on the clinician\u2019s experience and intuition. With the rapid development of neuroimaging analysis, automatic classification based on MRI scans may be useful in improving diagnostic accuracy and reducing differences among clinicians, leading to reduced medical costs. Machine learning is widely used in medical imaging because it facilitates the identification of patterns in large datasets. Numerous algorithms have been proposed to extract features from MRI and make individual predictions. Deep learning methods, such as convolutional neural networks (CNNs) [4], have achieved favorable and competitive performance compared to the classical machine-learning algorithms for high-dimensional MRI images, as they are able to automatically extract features in different abstraction levels. Kang et al. [5] introduced a multi-slice and multi-model ensemble learning approach based on a 2D CNN for learning the various features from local brain images, which were then integrated for the final classification. It had a high discrimination power for AD versus CN, with an accuracy of 90.36%, and an accuracy of 77.19%, and 72.36% for AD versus MCI, and MCI versus CN, respectively. Liu et al. [6] used a UNet in conjunction with 3D densely connected convolutional networks (3D DenseNets) to jointly perform hippocampal segmentation and AD classification, and achieved accuracy values of 88.9% and 76.2% when classifying AD versus CN, and MCI versus CN, respectively. CNNs are suitable for extracting features from Euclidean neuroimaging data, and the convolutional layers work as filters. However, CNN-based methods cannot properly capture the complex non-grid structural and functional representations of the brain. Graph convolutional networks (GCNs) generalize convolution operations to non-Euclidean data, and some researchers have started to use them to analyze brain networks. Meszlenyi et al. [7] modeled functional connections between brain regions as graphs and used a two-layer GCN for MCI classification. When classifying MCI versus CN, the accuracy was 71.9%. Song et al. [8] used diffusion tensor imaging to build structural networks. BrainNetCNN, which is composed of edge-to-edge, edge-to-node, and node-to-graph convolutional filters, was utilized for classification tasks among CN, early MCI, late MCI, and AD. The aforementioned GCN-based studies, however, did not incorporate the similarities among the individuals in the graph architecture. The use of a population graph is beneficial for assessing relationships among subjects. The population data can be viewed as a graph, with the individual samples in the cohort acting as nodes and phenotypic data and/or pairwise similarities of imaging features between subjects acting as edges. Modeling the population data with a graph transforms the AD classification problem into a node classification problem. As shown in Figure 1, the task is to predict the diagnostic label of an unseen subject drawn from a test dataset (subjects with gray nodes). The graph is represented as G (V, E, X), with N nodes and M edges, where V is the set of nodes and each subject corresponds to a node in the graph. The edges E represent relationships between the nodes. A is the adjacency matrix with N\u00d7N elements, D is the degree matrix of A, IN is the identity matrix, and X indicates the node feature matrix. Every node vi has a corresponding feature vector xi and a true label ci \u2208 C, where C is the set of classes. GCN is used to learn the parametric function F with the inputs X, A, and D. The graph convolutional layer comprises two steps. First, it fuses each node\u2019s information with that of its neighbors based on their edge connections, and then it constructs node embeddings based on the updated features using a fully connected layer.\nSensors 2023, 23, 1914 3 of 20\nSensors 2023, 23, x FOR PEER REVIEW 3 of 20 neighbors based on their edge connections, and then it constructs node embeddings based on the updated features using a fully connected layer.\nConsequently, considerable effort has been devoted to developing GCN models with a population graph structure. Kazi et al. [9] constructed multiple population graphs with various biomarkers (MR, PET imaging, cognitive tests, and CSF biomarkers) as node features and age, gender, ApoE genotype, and other variables as edges. The features extracted by each GCN were merged for the final classification. The self-attention mechanism was used in GCN to improve the quality of information aggregation under the GCN framework. The classification accuracy of AD, MCI, and CN was 76%. Researchers [10] made use of a dynamic high-order brain functional connectivity network constructed from resting state functional magnetic resonance imaging time series. The characteristics of the brain\u2019s functional connectivity network were combined with gender and age information to build a population graph. InceptionGCN, which uses multiple scale convolution kernels, was introduced to improve the model\u2019s performance. For the task of comparing early MCI with late MCI, classification showed 79.2% accuracy. Jiang et al. [11] proposed a hierarchical GCN framework with two major components: a graph-level GCN and a node-level GCN. Individual brain functional connectivity network features were extracted using the graph-level GCN, and those features were combined with non-imaging complementary data to create a population graph. The node-level GCN was used for graph embedding learning and classification. The model obtained an accuracy of 78.5% for AD versus MCI.\nFigure 1. Process of a node classification task. (a) Input population graph (b) the first graph convolution (c) the second graph convolution (d) output layer (e) Output population graph.\nMost of the aforementioned studies focused on developing better GCN architectures and accordingly proposed various GCN variants. The function of GCN in a population graph is to build node embedding by fusing the features of the nodes in the graph struc-\nFigure 1. Process of a node classification task. (a) Input populati raph (b) the first graph convolution (c) the second graph convolution (d) o tput layer (e) Outp t opulation graph.\nConsequently, considerable effort has been devoted to developing GCN models with a population graph structure. Kazi et al. [9] constructed multiple population graphs with various biomarkers (MR, PET imaging, cognitive te ts, and CSF biomarkers) as node features and age, gender, ApoE genotype, and other variables as edges. The features extracted by each GCN were merged for the final classification. The self-attention mechanism was used in GCN to improve the quality of information aggregation under the GCN framework. The classification accuracy of AD, MCI, and CN was 76%. Researchers [10] made use of a dynamic high-order brain functional connectivity network constructed from resting state functional magnetic resonance imaging time series. The characteristics of the brain\u2019s functional connectivity network were combined with gender and age information to build a population graph. InceptionGCN, which uses multiple scale convolution kernels, was introduced to improve the model\u2019s performance. For the task of comparing early MCI with late MCI, classification showed 79.2% accuracy. Jiang et al. [11] proposed a hierarchical GCN framework with two major components: a graph-level GCN and a node-level GCN. Individual brain functional connectivity network features were extracted using the graphlevel GCN, and those features were combined with non-imaging complementary data to create a population graph. The node-level GCN was used for graph embedding learning and classification. The model obtained an accuracy of 78.5% for AD versus MCI. Most of the aforementioned studies focused on developing better GCN architectures and accordingly proposed various GCN variants. The function of GCN in a population graph is to build node embedding by fusing the features of the nodes in the graph structure\nSensors 2023, 23, 1914 4 of 20\nusing the relationships with the immediate neighbors. GCN can be viewed as a special type of Laplacian smoothing for node features over graph structures [12]. An over-smoothing problem [13,14] caused by too many layers of aggregation/propagation steps, produces indistinguishable representations of nodes, degrades the model\u2019s performance, and increases computational complexity. Thus, GCN models are commonly constrained to a shallow architecture, but shallow embedding may not sufficiently propagate node features for fusing heterogeneous information. Furthermore, the features are fused by considering the population graph\u2019s topological structure. Because the learning range of node embedding is affected by the edge-assigning function, distinct feature vectors are created. Few studies have looked into how the input properties of GCN (edges and features) influence AD staging performance. This motivated us to investigate the impact of feature importance and node interactions on GCN-based AD staging using population graphs. This study was designed to investigate how the input characteristics of GCNs affect the performance of AD staging. The research objectives were to answer the following research questions: (1) Does including demographic information in the edge-assigning function lead to better classification performance when classifying AD versus CN? (2) How does adding various neuropsychological tests to the edge-assigning function affect the classification of MCI? (3) Does the edge assignment function that performs best in MCI classification also perform well in multiclass classification? To achieve this objective, we proposed a novel framework by leveraging the superior feature extraction capabilities of CNNs and the population-graph processing capabilities of GCNs. DenseNet was used to learn high-level anatomical features. A set of population graphs with nodes defined by imaging features and edge weights determined by different combinations of imaging or/and non-imaging information were fed to GCNs for classification. The remainder of the paper is organized as follows: Section 2 covers the data source and data preprocessing, the overall framework of the experiment, the creation of the population graph, the learning principle of GCN, and the evaluation index of the model. Section 3 introduces the specific settings and results of the experiment. Section 4 provides the experimental results, and Section 5 offers a summary of our findings and some concluding comments."
        },
        {
            "heading": "2. Materials and Methods",
            "text": ""
        },
        {
            "heading": "2.1. Participant",
            "text": "The data employed in the preparation of this article were obtained from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database (http://adni.loni.usc.edu/, accessed on 15 February 2020). The ADNI was launched in 2003 as a public\u2013private partnership, led by Principal Investigator Michael W. Weiner, MD. The primary goal of ADNI has been to test whether MRI, PET, other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of MCI and AD. All ADNI participants provided written informed consent, and the institutional review board of each ADNI site approved study protocols. On 1.5 Tesla MRI scanners from Siemens (Siemens, Erlangen, Germany), Philips (Philips, Best, The Netherlands), and General Electric Health-care (General Electric Health Care, Waukesha, WI, USA), high-resolution T1-weighted structural MRI (sMRI) data at baseline were collected at multiple ADNI sites using the standard ADNI Phase 1 (ADNI-1) MRI protocol. A sagittal 3D MP-RAGE sequence was used to scan each subject, with the following acquisition parameters: inversion time/repetition time: 1000/2400 ms; flip angle: 8; 24 cm field of view; 192 \u00d7 192 \u00d7 166 acquisition matrix, and a voxel size of 1.25 \u00d7 1.25 \u00d7 1.2 mm3. In plane, zero-filled reconstruction yielded a 256 \u00d7 256 matrix for a reconstructed voxel size of 0.9375 \u00d7 0.9375 \u00d7 1.2 mm3. In order to assure uniformity among scans obtained at different sites, images were calibrated using phantom-based geometric corrections. Additional image corrections were also applied, to adjust for scannerand session-specific calibration errors. In addition to the original uncorrected image files, images with all these corrections already applied (GradWarp, B1, phantom scaling, and N3)\nSensors 2023, 23, 1914 5 of 20\nare available to the general scientific community (at www.loni.ucla.edu/ADNI, accessed on 15 February 2020). The samples included in the ADNI-1 cohort were diagnosed with 3 clinical statuses (CN, MCI, and AD), including 187 AD patients, 382 MCI patients, and 229 CNs at baseline. The neuropsychological assessments used in this study could be divided into global cognitive screening tests, the Functional Assessment Questionnaire (FAQ), and ADNI composite scores. Global tests consist of the Mini-Mental State Examination (MMSE), sum-of-box assessments of clinical dementia (CDR-SB), the 11-item AD Assessment Scale-Cognitive (ADAS-Cog11) or expanded to 13 items (ADAS-Cog13). The ADNI composite scores include four sub-domains: memory, executive function, language, and visuospatial. Gibbons et al. derived the composite scores for memory (ADNI-MEM) and executive function (ADNI-EF) from the ADNI neuropsychological battery using item response theory [15,16] and Choi et al. designed the composite scores for language (ADNILAN) and visuospatial abilities (ADNI-VS) using similar methods [17]. The demographic details and neuropsychological assessment [18] results for the three groups are provided in Table 1. The dataset was randomly split into 70% training, 10% validation, and 20% test sets. The training set was used to train the algorithm, the validation set was used to find the optimal combination of hyper-parameters, and the test set was used to evaluate the model.\nA: significant differences (p < 0.05) between AD and MCI; B: significant differences (p < 0.05) between MCI and CN; C: significant differences (p < 0.05) between AD and CN; D: The \u03c72 test was used."
        },
        {
            "heading": "2.2. Image Preprocessing",
            "text": "Brain imaging data were converted from DICOM images to Neuroimaging Informatics Technology Initiative (NIFTI) files using dcm2nii from the MRIcron package (http://people.cas. sc.edu/rorden/mricron/index.html, accessed on 20 December 2022). Images were manually reoriented with the coordinate system\u2019s origin set to the anterior commissure. Voxel-based morphometry analysis was performed on the structural imaging data with the Computational Anatomy Toolbox (CAT12) toolbox (http://www.neuro.uni-jena.de/cat/, accessed on 20 December 2022), an extended toolbox of SPM12 [15], with default settings. The preprocessing pipeline included realignment, skull stripping, segmentation by tissue type (i.e., gray matter and white matter), and finally, the segmented gray matter images were non-linearly warped to the standard Montreal Neurological Institute (MNI) template [19], modulated to account for volume changes. Modulated and warped 3D gray matter density maps (GMDMs) were smoothed using a 2-mm full width at half maximum Gaussian kernel. The GMDMs had a dimensionality of 121\u00d7 145\u00d7 121 in the voxel space (a voxel size of 1.5\u00d7 1.5\u00d7 1.5 mm7). The GMDMs were further re-sampled to an isotropic voxel size of 3 \u00d7 3 \u00d7 3 mm3 to provide an image dimension of 64\u00d7 64\u00d7 64 for an efficient computation."
        },
        {
            "heading": "2.3. Densenet for Gmdms Feature Learning",
            "text": "DenseNet, an extension of the ResNet architecture, was proposed by Huang et al. [20]. To maximize the information flow through layers, the DenseNet architecture uses a simple\nSensors 2023, 23, 1914 6 of 20\nconnectivity pattern in which each layer in a dense block obtains the feature maps from all previous layers and passes its own feature maps to all subsequent layers. With this architecture, DenseNet has several advantages, including preventing over-fitting and degradation phenomena, improving the efficiency of feature propagation, retaining the efficiency of feature reuse, and substantially reducing the model\u2019s size. The GMDMs were used as inputs for the model. DenseNet, trained from scratch, was used to investigate a binary problem (AD versus CN). To generate the optimal model for AD versus CN, we empirically tuned DenseNet\u2019s hyper-parameters using a grid-search technique, such as the learning rate (1 \u00d7 10\u22126\u20131 \u00d7 10\u22122), the number of dense blocks (2\u20135), the growth rate (8\u201324), the compression rate (0.2\u20130.8), and the batch size (32\u2013128), according to the validation results. While changing the values of the hyper-parameter, mean values for accuracy (ACC) were calculated for each value of the hyper-parameter. In the cost function calculation, balanced class weights were used to ensure that classes were weighted inversely proportional to their frequency in the training set. A schematic of the optimized 3D DenseNet architecture is shown in Figure 2. It consisted of a 3 \u00d7 3 \u00d7 3 convolutional layer, followed by three dense blocks, and a transition layer in between. The output of the last dense block is flattened, followed by two fully connected layers with 512 units and 256 units, respectively, and finally connected to the output layer. Each dense block has three repeating units: each repeating unit has one bottleneck 1 \u00d7 1 \u00d7 1 convolutional layer with 48 channels, followed by a 3 \u00d7 3 \u00d7 3 convolutional layer with 12 channels. The loss function was binary cross-entropy. The learned hyper-parameters are shown below; the learning rate, growth rate, compression rate, and batch size were set at 0.0001, 12, 0.5, and 64, respectively. A transfer learning strategy was applied to this optimized DenseNet architecture to initialize the training of the CNNs for two binary (AD versus MCI and MCI versus CN) and one multiple-class classification problem (CN, MCI, and AD). This was done primarily because of the fact that these four tasks are highly associated, and the latter jobs are substantially more demanding. Training was performed using Adam optimization. The model is implemented in Keras using Tensorflow as the backend and trained on an NVIDIA GTX 3090 GPU with 24 GB of RAM. After training, the anatomical features of the GMDMs were extracted from the first fully connected layer. The CNN model was trained for a maximum of 200 epochs, and early-stopped after 30 epochs of the validation loss not improving. Sensors 2023, 23, x FOR PEER REVIEW 7 of 20\nSensors 2023, 23, 1914 7 of 20"
        },
        {
            "heading": "2.4. Population Graph Construction",
            "text": "To consider the correlations among the subjects in a cohort, the population is regarded as a graph. Individual subjects are represented by the nodes of the population graph, which include compact anatomical feature vectors taken from 3D DenseNet, while the edges encode pairwise phenotypic similarities based on non-imaging and/or imaging data. The population graph is constructed using the set of CN and patients with MCI and AD. The subjects from the dataset are represented by the graph nodes, and similarities between the nodes\u2019 characteristics, such as demographic, imaging, and/or neuropsychological features, are treated as edges connecting the nodes. A population graph is constructed based on two important elements: (a) the node feature vector assigned to each node, and (b) the weighted adjacency matrix. More explicitly, we built an undirected weighted graph G (V, E, X) in which the set of nodes V = {v1,\u00b7 \u00b7 \u00b7 ,vn} corresponds to a set of subjects. Each node vi contains a 512-dimensional feature vector xi described in Section 2.3. The feature matrix X\u2208Rn\u00d7512 consists of stacked feature vectors of n nodes in the graph. The weighted adjacency matrix A is composed of a set of edges E \u2286 V \u00d7 V, which correspond to links between the nodes, where an edge-assigning function assigns weight S(i, j) to each edge. However, constructing a population graph is not a straightforward task, as there are multiple edge-assigning functions that map the data to the graph structure. Edge-assigning function is critical for capturing the underlying structure of a graph and explaining the similarities between the feature vectors. We computed the similarity between the pair of anatomical feature vectors xi and xj of nodes i and j. The similarity index was denoted as Simg(i, j).\nSimg(i, j) = xi \u00b7 xj \u2016xi\u2016\u2016xj\u2016\n(1)\nA similarity function Snimg(i, j) is defined as a Kronecker delta function if the nonimaging feature is categorical (e.g., subject\u2019s gender). The function is specified as a unit-step function with regard to a threshold \u03b2 if the non-imaging feature is quantitative (e.g., subject\u2019s age).\nSnimg(i, j) = { 1 i f ni=nj 0 otherwise (2)\nSnimg(i, j) = { 1 i f ni\u2212nj<\u03b2 0 otherwise (3)\nIn the equations above, ni and nj are the values of the non-imaging features for nodes i and j.\nThe combined similarity index is defined by the equation below.\nScom(P, i, j) = Simg(i, j)\u2211Pp=1 Snimg(i, j) (4)\nwhere P is the number of non-imaging features that has been used to generate edges. Equation (4) states that Scom increases when there is a high degree of similarity between two subjects\u2019 imaging feature vectors and/or their non-imaging measures. Non-imaging features and imaging features are incorporated. For clarity, we categorized the resulting graphs into three groups based on their edge-assigning functions: Baseline graphs: Graphs were constructed using the similarity between imaging feature vectors described in Section 2.3. Non-imaging graphs: Graphs were constructed using the relationships between nonimaging features. Combined graphs: Graphs that were constructed using a combination of non-imaging and imaging features. To examine how the construction of the population graph (edges and features), especially the edge-assigning function, influences AD staging performance, three experiments were implemented in this study. Experiment I was designed to explore the implications of incorporating demographic information in the edge-assigning function on the classification\nSensors 2023, 23, 1914 8 of 20\nof AD versus CN. Experiment II was designed to investigate the impact of adding various neuropsychological tests to the edge-assigning function on MCI classification. Experiment III aims to investigate the possibility of using the edge-assigning function, which produced the best outcomes in Experiment II, to perform well on multi-class classification.\n\u2022 Experiment 1: Demographic information-based population graph for AD versus CN classification\nIndividuals with AD usually demonstrate a high level of heterogeneity [21]. Some atrophic areas affected by one AD subtype may be preserved by another [22,23]. As a result, imaging features and AD risk factors should be combined in the diagnosis of AD. One of the biggest risk factors for AD is aging; more than 13% of people aged 65 and up and 43% of people aged 85 and up have been diagnosed with AD [24]. Genetic factors also play a role. Apolipoprotein E (ApoE) is a well-known risk factor for late-onset AD [25,26]. Female birth sex has been linked to an increased risk of developing AD, and two-thirds of older adults with AD are women [27,28]. Therefore, non-imaging information such as age, gender, and ApoE genotype was used to calculate the similarity of the nodes in this investigation. Based on all possible combinations, seven population graphs were created. A grid search with validation was used to determine the threshold of age;\n\u2022 Experiment 2: Neuropsychological assessments-based on the population graph for MCI classification\nOf note is the fact that distinguishing MCI patients from CN subjects or AD patients based on neuroimaging data is more difficult than distinguishing between AD and CN, and the results of the former are always less accurate [29]. The criteria for clinically categorizing ADNI-1\u2032s subjects into different disease groups were summarized as follows [30]: (a) CN subjects with normal cognition and memory, MMSE between 24\u201330, CDR = 0, non-depressed (b) MCI patients with verified memory complaint, MMSE between 24\u201330, CDR = 0.5, have objective memory loss measured by education adjusted scores on Wechsler Memory Scale Logical Memory II, absence of significant levels of impairment in other cognitive domains, essentially preserved activities of daily living, or (c) probable AD with validated memory complaint, MMSE in the range of 20\u201326 and CDR \u2265 0.5, and met NINCDS/ADRDA criteria for probable AD. Because neuropsychological tests, particularly the MMSE and CDR, were employed as major criteria in categorizing participants, they could provide complementary information for MCI classification. Non-imaging information from nine neuropsychological assessments was utilized to compute the similarity of the nodes in the population graph, and 18 population graphs were created, nine with a non-imaging similarity index as edges and nine with a combined similarity index as edges. The optimal threshold \u03b2 of each neuropsychological assessment for each task was determined through an exhaustive grid search with validation;\n\u2022 Experiment 3: Population graph for multi-class classification Most AD and MCI research normally simplifies the classification problem to a set of binary classification tasks, such as AD versus CN and/or MCI versus CN. However, AD staging should be naturally modeled as a multi-class classification problem, necessitating the examination of the entire AD spectrum. The classification of AD, CN, and MCI is difficult because a multi-class model has more interference than a two-class model. In the current study, the edge-assigning function that achieved the best result in the MCI classification was used for multi-class classification."
        },
        {
            "heading": "2.5. GCN",
            "text": "After constructing the population graph represented in Section 2.4, we learn the GCNs to predict the target labels. Various GCN frameworks have been proposed, and one of the most seminal examples was proposed by Kipf and Welling [31] in 2016. The GCN\nSensors 2023, 23, 1914 9 of 20\nmodel architecture is composed of stacked layers of graph convolution, with each layer\u2019s propagation rule described as:\nD\u0302 = D + I (5)\nA\u0302 = A + I (6)\nH(l+1) = f (Hl , A) = \u03c3(D\u0302\u22121/2 A\u0302D\u0302\u22121/2H(l)W(l)) (7)\nwhere D and A are the degree matrix and adjacency matrix, respectively, I is the identity matrix, and D\u0302 is the diagonal node degree matrix of A\u0302, W(l) are the network parameters of the lth layer to be learned, H(l+1) are the node embeddings, H(l) are generated from the previous message-passing step, and f represents a non-linear activation function. D\u0302\u22121/2 A\u0302D\u0302\u22121/2 is intended to add a self-connection to each node and keep the scale of the feature vectors. During training, the vertices connected with high edge weights become more similar as they pass through multiple layers. From the perspective of message passing, two steps were performed: (1) producing an intermediate representation by aggregating information for a node from its neighbors; and (2) transforming the aggregated representation with a linear transformation parameterized by W shared by all nodes, which was followed by non-linearity activation. In the current study, we built a GCN model (Figure 3) by stacking two graph convolutional layers with the adjacency and node feature matrices as inputs, and the activation function of the first convolutional layer is ReLU. It\u2019s worth noting that the first graph convolutional layer has 32 neurons and that the second graph convolutional layer has two neurons (for binary classification) or three neurons (for three-class classification), followed by a soft-max activation function. The loss function is defined by the difference between the predicted label and the actual label, where a cross-entropy loss function is used in our implementation. For GCN, we adopted code from the GCN in PyTorch GitHub repository (https://github.com/tkipf/pygcn (accessed on 20 December 2022)). The model was trained using a grid-search technique in order to find the optimal combination of hyper-parameters (learning rate and dropout ratio) for this architecture. The range of the hyper-parameter values was (1 \u00d7 10\u22126\u20131 \u00d7 10\u22122 for learning rate and 0.3\u20130.8 for dropout ratio). The training was conducted using the Adam optimizer implemented in PyTorch. The optimal learning rate was 0.001, 0.0001, and 0.0001 for Experiments I, II, and III, respectively, and dropout was 0.5. The maximum epoch was set at 500 for all the tasks, with a criterion to stop training if the accuracy on the validation set did not improve after 20 epochs. During the training, we use the entire set of data, including labeled training and unlabeled test samples, to construct the whole population graph. The GCNs are trained to minimize the cross-entropy loss for all training samples. After training the GCNs, the model will output a prediction for each test sample. Sensors 2023, 23, x FOR PEER REVIEW 10 of 20 the training, we use the entire set of data, including labeled training and unlabeled test samples, to construct the whole population graph. The GCNs are trained to minimize the cross-entropy loss for all training samples. After training the GCNs, the model will output a prediction for each test sample.\nFigure 3. Illustration of the overall architecture of the GCN model for binary classification between the AD and CN classes.\n2.6. Evaluation Metrics In order to evaluate the performance of the proposed model, three common metrics were used. The accuracy (ACC) gives an overview of the quality of the predictions. The precision (PRE) shows the ratio of the correct predictions out of all the predictions, the recall (REC) is the percentage of how many total positive cases there are in all positive samples, the F1 score is a harmonic mean of ACC and PRE, and the Matthews correlation coefficient (MCC) considers all elements of the confusion matrix, providing a better view of the performance of classifiers. The calculation of those metrics is based on Equations (8)\u2013(12), respectively. ACC = TP + TNTP + TN + FP + FN (8)PRE = TPTP + FP (9)REC = TPTP + FN (10)F1 = 2 \u00d7 PRE \u00d7 RECPRE + REC (11)MCC = TP \u00d7 TN \u2212 FP \u00d7 FN(TP + FN) \u00d7 (TP + FP) \u00d7 (TN + FP) \u00d7 (TN + FN) (12) where TP, TN, FP, and FN are the abbreviations for true positive, true negative, false positive, and false negative, respectively.\n3. Results 3D DenseNet achieves a relatively good performance for AD versus CN (ACC scores of 84.3%, PRE scores of 83.3%, and REC scores of 81.1%). But the performance is lowered for AD versus MCI and MCI versus CN, showing ACC scores of 70.7% and 71.9%, PRE scores of 74.1% and 58.1%, and REC scores of 81.1% and 48.6%, respectively. The anatomical features extracted from the first fully connected layer were used as node features for graph learning.\n3.1. Experiment 1\nFigure 3. Illustration of the overall architecture of the GCN model for binary classification between the AD and CN classes.\nSensors 2023, 23, 1914 10 of 20"
        },
        {
            "heading": "2.6. Evaluation Metrics",
            "text": "In order to evaluate the performance of the proposed model, three common metrics were used. The accuracy (ACC) gives an overview of the quality of the predictions. The precision (PRE) shows the ratio of the correct predictions out of all the predictions, the recall (REC) is the percentage of how many total positive cases there are in all positive samples, the F1 score is a harmonic mean of ACC and PRE, and the Matthews correlation coefficient (MCC) considers all elements of the confusion matrix, providing a better view of the performance of classifiers. The calculation of those metrics is based on Equations (8)\u2013(12), respectively.\nACC = TP + TN\nTP + TN + FP + FN (8)\nPRE = TP\nTP + FP (9)\nREC = TP\nTP + FN (10)\nF1 = 2\u00d7 PRE\u00d7 REC\nPRE + REC (11)\nMCC = TP\u00d7 TN\u2212 FP\u00d7 FN\u221a\n(TP + FN)\u00d7 (TP + FP)\u00d7 (TN + FP)\u00d7 (TN + FN) (12)\nwhere TP, TN, FP, and FN are the abbreviations for true positive, true negative, false positive, and false negative, respectively."
        },
        {
            "heading": "3. Results",
            "text": "3D DenseNet achieves a relatively good performance for AD versus CN (ACC scores of 84.3%, PRE scores of 83.3%, and REC scores of 81.1%). But the performance is lowered for AD versus MCI and MCI versus CN, showing ACC scores of 70.7% and 71.9%, PRE scores of 74.1% and 58.1%, and REC scores of 81.1% and 48.6%, respectively. The anatomical features extracted from the first fully connected layer were used as node features for graph learning."
        },
        {
            "heading": "3.1. Experiment 1",
            "text": "There is no simple way to create a population representation of the data, as the data needs to be mapped onto the graph structure. The optimal graph structure would be one that allows the clustering of AD and CN to be easily separable from each other. The goal of experiment I was to explore the effects of incorporating demographic information into the edge-assigning function on the classification of AD versus CN. Non-imaging complementary data (age, gender, and ApoE genotype) were used to estimate subjects\u2019 similarity. The validation set and grid search were used to optimize the threshold, which yielded an optimal threshold of 2 for age. The results are provided in Table 2. For instance, we investigated whether a non-imaging feature would improve performance when used alone. In the population graph with only imaging features in the edge-assigning function, we observed that the performance did not change much. Adding the ApoE4 genotype to the graph\u2019s edge-assigning function increased the performance, allowing all the graph structures with ApoE to beat the performance of the models without ApoE. The best performance was obtained when Scom was used with age, gender, and ApoE in the edgeassigning function, which showed a 91.6% accuracy. The model\u2019s good performance indicated that both the features and the structure of the population graph (i.e., using graph edges to combine demographic information and imaging data) contained useful information for classification.\nSensors 2023, 23, 1914 11 of 20"
        },
        {
            "heading": "3.2. Experiment 2",
            "text": "To investigate the effect of adding various neuropsychological tests to the edgeassigning function on MCI classification, Experiment 2 was implemented. The optimal values of the threshold parameters were determined using a grid search approach on the validation set. Table 3 shows the threshold values for AD versus MCI and MCI versus CN.\nFor a fair comparison, all GCN models were made to employ the same parameter configuration and training method as Experiment II, except for the edge-assigning function. The default graph is based on Simg, similarity between anatomical features. Nine population graphs were created based on non-imaging neuropsychological assessment scores, with Snimg as the edge-assigning function. The other nine population graphs were constructed with Scom as the edge-assigning function. The results for AD versus MCI are reported in Table 4. The classification performance of the GCN based on the default graph was relatively low. We observed a large variation between the graph structures, with a 23.7% difference in accuracy between the best- and worst-performing graphs (Snimg or Scom). The best-performing graph was the one (Snimg) that used the similarity of CDR-SB in the edge-assigning function. With regard to REC, the best-performing graph shows a relatively higher improvement (27.1%) than the default graph. It is reasonable to deduce that the improved REC enhanced by the edge-assigning function has a more pronounced effect on a more difficult classification task (i.e., AD vs. MCI).\nSensors 2023, 23, 1914 12 of 20\nThe results for the MCI versus CN are shown in Table 5. The default graph is also based on Simg. We observed a large variation between the graph structures, with a 34.2% difference in accuracy between the best- and worst-performing graphs. The best-performing graph was also the one that used the similarity of CDR-SB in the edge-assigning function."
        },
        {
            "heading": "3.3. Experiment 3",
            "text": "After determining the best-performing edge-assigning function (CDR-SB) in Experiment 2, we designed Experiment 3 to test whether CDR-SB would also work well on multi-class classification. The confusion matrix was used as a tool to assess model classification performance on the test data. Figure 4 shows the confusion matrices that give a visual representation of how well the predictions match the actual diagnoses. The darker diagonal cells can be seen in all of the plotted confusion matrices, indicating a high level of accuracy. Model misclassifications are indicated by the off-diagonal elements with light shades. There are two common misclassifications: predicting a CN diagnosis when a patient actually has MCI, and predicting an AD diagnosis when a patient actually has MCI, highlighting the difficulty of distinguishing MCI from CN or AD. The default graph with as the edge-assigning function is not sensitive (44.2%) for identifying MCI patients, but the graphs with as the edge-assigning function and the graphs with as the edge-assigning function have relative high sensitivity (85.7% and 77.9%, respectively). The default graph achieved 59.4% accuracy for the multi-class classification based on Simg. The graphs with Snimg and Scom as the edge-assigning function, respectively, achieved 89.4% and 81.3% accuracy. Based on the results, we conclude that the population graph with CDR added in the edge-assigning function can significantly outperform the population graph without it, providing a performance gain in accuracy between 21.9% and 30%."
        },
        {
            "heading": "3.4. Graph Features versus Vector Features",
            "text": "Apart from investigating how the edges of the population graph impact the classification performance, we further investigated whether the graph feature structure would allow us to extract an improved feature representation after the graph convolution compared to the vector feature. It is implemented by comparing the GCN results (both using a neuropsychological test score as the edge-assigning function or using the combined features as the edge-assigning function) to those of support vector machine (SVM) with a neuropsychological test score, and SVM with combined features. For SVM with a neuropsychological test score, we used a neuropsychological test score as input. For SVM with combined features, we used the same features as we did for GCN implementation. As shown in Figures 5 and 6, in most cases, the models with a graph feature structure as the input outperformed those with a vector feature structure as the input. Regarding classification accuracy, the GCNs with neuropsychological assessment scores in their edge-assigning function performed better in the first seven and six comparisons for AD versus MCI, and MCI versus CN, respectively.\nSensors 2023, 23, 1914 13 of 20\nSensors 2023, 23, x FOR PEER REVIEW 13 of 20\nshades. There are two common misclassifications: predicting a CN diagnosis when a patient actually has MCI, and predicting an AD diagnosis when a patient actually has MCI, highlighting the difficulty of distinguishing MCI from CN or AD. The default graph with as the edge-assigning function is not sensitive (44.2%) for identifying MCI patients, but the graphs with as the edge-assigning function and the graphs with as the edge-assigning function have relative high sensitivity (85.7% and 77.9%, respectively). The default graph achieved 59.4% accuracy for the multi-class classification based on \ud835\udc46 . The graphs with \ud835\udc46 and \ud835\udc46 as the edge-assigning function, respectively, achieved 89.4% and 81.3% accuracy. Based on the results, we conclude that the population graph with CDR added in the edge-assigning function can significantly outperform the population graph without it, providing a performance gain in accuracy between 21.9% and 30%.\nSensors 2023, 23, x FOR PEER REVIEW 14 of 20\nFigure 6. Performance comparison using graph features or vector features on the test data for MCI versus CN task.\n4. Discussion In this work, we demonstrate the value of the GNN-based graph classification framework along with the 3D DenseNet features for accurate AD categorization. First, hidden feature representations from the anatomical GMDM data were extracted using 3D DenseNet. A set of population graphs was then represented graphically, with nodes defined by imaging features and edge weights indicated by different combinations of imaging/non-\nFigur 5. Performance comparison using graph features or vector features on the test data for AD versus MCI task.\nFigure 5. Performance comparison using graph features or vector features on the test data for AD versus MCI task.\nFigure 6. Performance co i graph features or vector features on the tes data for MCI versus CN task.\n4. Discussion In this work, we demonstrate the value of the GNN-based graph classification framework along with the 3D DenseNet features for accurate AD categorization. First, hidden feature representations from the anatomical GMDM data were extracted using 3D DenseNet. A set of population graphs was then represented graphically, with nodes defined by imaging features and edge weights indicated by different combinations of imaging/non-\nFigure 6. Performance comparison using graph features or vector features on the test data for MCI versus CN task.\nSensors 2023, 23, 1914 14 of 20"
        },
        {
            "heading": "4. Discussion",
            "text": "In this work, we demonstrate the value of the GNN-based graph classification framework along with the 3D DenseNet features for accurate AD categorization. First, hidden feature representations from the anatomical GMDM data were extracted using 3D DenseNet. A set of population graphs was then represented graphically, with nodes defined by imaging features and edge weights indicated by different combinations of imaging/non-imaging information. Finally, GCNs were used to learn the graph structures. Our findings confirmed our initial hypothesis that imaging features and pairwise information are very important in the categorization process. Understanding heterogeneity in AD can greatly contribute to clinical trial designs and treatment. A structured population graph is an effective way to address heterogeneity and understand the relationships between subjects. Simply put, a graph is a non-linear data structure that represents relationships between subjects and can be used as a powerful abstraction to encode an intrinsic structure. Examining the related neighbors in a graph can reveal important details about a subject\u2019s local relationship. Detecting clusters of AD patients in a population graph necessitates an examination of the global structure, which is composed of the local relationships of many individual nodes interacting with each other. GCNs are designed to work on the relationships between subjects; they are capable of finding structures and revealing patterns in connected subjects. The traditional machine learning method analyzes complementary information in isolation and ignores neighborhood relationships and complicated network structures. The population graph divides complementary information into features and topology, which yields deeper insights into the underlying information of the data. The imaging features are now a set of embedding features, and the relationships between the subjects are encoded in the topology; this structure improves the model\u2019s predictability. Based on the graph structure, the GCN could create new, more meaningful graph embeddings and outperform traditional machine learning methods even when the same information was given as input. When compared to typical machine learning methods, GCNs are more effective at learning representations of non-Euclidean graph data. The main idea is to perform a convolutional operation on the graph, which enables the network to achieve a new representation of a given node by propagating graph topological information across the neighborhood of each node, which naturally fuses both the graph structure and node features between nodes. Different features or feature interactions inherently have various influences on the convolutional layers. Because message propagation techniques are a type of Laplacian smoothing, learning a node representation by recursively aggregating its neighbors\u2019 information could result in node representations that are indistinguishable. The representations of all nodes tend to converge on the same value as the number of layers grows, leading to over-smoothing. As a result, GCN architectures are typically shallow. GCNs, which focus on obtaining the low-dimensional embedding of the constructed graph, lack CNNs\u2019 powerful feature extraction ability. The cascading architecture of a CNN makes it simple to transfer from low-level common features to high-level complex features to achieve great expressive capability. A key contribution of this research was the use of 3D DenseNet\u2019s high-level features as node descriptors. Unlike other CNNs, which only use the last high-level feature maps, 3D DenseNet applies feature reuse to maximize the network\u2019s capability. The model is more effective when both high-level complexity and low-level common feature maps are used. Because DenseNet\u2019s channel is narrow, it performs well with a significantly reduced number of network parameters. The use of 3D DenseNet to encode graph characteristics can produce better results than the use of raw anatomical features. Due to complex graph structures, learning about graphs is challenging in that effective ways to incorporate different sources of information into edges must be found. Kipf and Welling [31] used a re-normalized first-order adjacency matrix to approximate the polynomials and combined graph node features and graph topological structural information for classification purposes. In the AD versus CN classification task, AD risk factors were used to calculate the similarity of the nodes. The results showed that using ApoE genotype\nSensors 2023, 23, 1914 15 of 20\nor gender in the edge-assigning function improved the model\u2019s performance. The graph with age, ApoE genotype, and gender information achieved the best results. ApoE is the primary carrier of cholesterol in the central nervous system, and the ApoE genotype is a strong risk determinant for developing AD. AD patients with at least one ApoE e4 allele accounted for over 60% [32] of the patients. Sex-based prevalence of AD was also well documented, with over 60% of the patients being female [33]. Ghebremedhin et al. [34] found an association between ApoE e4 and AD-related neurofibrillary tangle formation and senile plaques, which were differentially modified by age and gender. Moreover, Riedel et al. [35] found complex interactions between age, ApoE genotype, and gender and believed that the precision medicine approach for AD should be based on the convergence of such three risk factors. These findings explain why the combined similarity index achieved the best results in AD versus CN classification. MCI is the transitional state between AD and CN, and its most common manifestations are memory deficits. Various neuropsychological assessments were performed on the subjects of the ADNI cohort. Because of these neuropsychological assessments\u2019 quantitative measurements, thresholds are needed for edge-assigning. Different thresholds determine the corresponding levels of the topological structure in the population network. In other words, a larger threshold value often preserves fewer connections and thus has sparser connections. More neighborhood information promotes better node embedding learning. Nevertheless, too much neighborhood information inevitably leads to over-smoothing. If the threshold is too large, the nodes of the population network will not obtain sufficient information from the correlated nodes. Although an exhaustive grid search was used to determine the optimal threshold of each neuropsychological assessment for each task, the determined threshold could be partially clinically important differences in clinical outcome assessments revealed by Andrews et al. [36], who discovered that a 1- to 3-point decrease in MMSE, a 1- to 2-point increase in the CDR-SB, and a 3- to 5-point increase in the FAQ were indicative of a meaningful decline. In the current study, we explored 18 graph structures and divided the GCN classification performance based on the population graph into three categories. Accurate measures with known links to AD pathologies substantially increase performance. Many tools for evaluating cognition and function in AD are available, but most of them lack the sensitivity necessary to detect MCI and disease progression. Several studies [37,38] cite the CDR-SB measures as a promising candidate for AD trials. A graph structure is optimal when clusters of patients and healthy subjects can be well separated. Not surprisingly, the best result was achieved when CDR-SB was applied to the edgeassigning function. Medium-level performance was achieved when MMSE, ADAS-Cog11, ADAS-Cog13, FAQ, or ADNI-MEM were applied to the edge-assigning functions. It is likely that some low-quality graphs (e.g., ADNI-EF, ADNI-LAN, or ADNI-VS) carry noisy information, which has a negative impact on the results. The edge-assigning function in a population graph can significantly affect classification accuracy. The current study investigated the impact of feature importance and node interactions. It did not aim to obtain a superior model for AD diagnosis. However, when the GCN models were evaluated by comparing their accuracy metrics to those of other state-ofthe-art models, the proposed model achieved promising performance for binary and multi-class classification, as shown in Table 6. It is important to note that the results may differ depending on the ADNI subjects as well as the machine learning models used. Additionally, it may be challenging to conduct a fair comparison due to the variations in the test samples. Compared to the state-of-the-art methods, the proposed method has the following three main advantages: First, the 3D DenseNet can encode a more comprehensive level of feature abstraction. Second, the GCN works as a feature extractor on the population graph structure to learn graph embedding. Third, the population graph is being constructed with different sources of similarities.\nSensors 2023, 23, 1914 16 of 20\nSensors 2023, 23, 1914 17 of 20"
        },
        {
            "heading": "5. Conclusions",
            "text": "To evaluate how the input properties of a GCN affect AD staging performance, we applied a novel framework for the diagnosis of AD that integrated CNNs and GCNs into a unified network, and thereby took advantage of the outstanding feature expression of CNNs, and the good graph processing performance of GCNs. We performed three binaries: AD/CN, MCI/CN, and AD/MCI, and one multiclass AD/MCI/CN classification task. Experiments are implemented using data from ADNI-1. We achieved an accuracy of 91.6% on AD versus CN, 91.2% on AD versus MCI, 96.8% on MCI versus CN, and 89.4% on AD/MCI/CN classification tasks. Our method outperformed several other systems in the prior part. The promising performance was achieved by incorporating the following three factors: (1) The 3D DenseNet provides good feature abstractions. (2) The GNN provides a good graph embedding. (3) Rich complementary information was used in edge-assigning functions. Our findings confirmed our initial hypothesis that imaging features and pairwise information are crucial to the AD categorization process. There were limitations to the proposed method. First, the population graph is a set of nodes connected by edges. In the ADNI-1 cohort, there were around 800 subjects; therefore, the population graph consisted of approximately 800 nodes. If thousands of subjects were contained in a graph, the topological structure of the graph would differ. Each node might be connected with too many neighbors, and the over-smoothing issue would be likely to occur; in this case, an edge sub-sampling strategy is required. Second, our graph encompasses several types of non-imaging information on the same edge. For example, age, gender, and ApoE were given the same weight when a composite score was calculated. An interesting extension would be to learn the weight of non-imaging information on edgeassigning function during training. This would allow for the gathering of complementary information and would weight the influence of some measures differently. Third, the GCN that we used was based on a simple layer-wise propagation rule. Applying imaging features in an edge-assigning function can be viewed as a kind of self-attention; edges to different nodes were modulated by their imaging features\u2019 similarities. In some cases, the strategy of edge-assigning functions improved the model\u2019s performance; in other cases, it degraded it. The graph attention network, which specifies different weights for different nodes in a neighborhood, may address the shortcomings of edge-assigning functions. Fourth, this study has used structural imaging features; however, adding functional imaging features could improve the model\u2019s predictive ability, and future research could determine how to incorporate functional imaging features efficiently into a GNN architecture.\nAuthor Contributions: Conceptualization, L.L. and M.X.; methodology, L.L.; software, G.Z.; validation, M.X., G.Z. and W.K.; formal analysis, M.X., G.Z. and W.K.; investigation, L.L., M.X., G.Z. and W.K.; resources, L.L.; data curation, M.X.; writing\u2014original draft preparation, L.L.; writing\u2014review and editing, L.L.; visualization, M.X.; supervision, L.L., S.S. and S.W.; project administration, L.L.; funding acquisition, L.L. All authors have read and agreed to the published version of the manuscript.\nFunding: This research was funded by grants from National Natural Science Foundation of China (81971683) and Natural Science Foundation of Beijing Municipality (L182010).\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability Statement: The dataset is owned by a third-party organization; the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI). Data are publicly and freely available from the http: //adni.loni.usc.edu/data-samples/access-data/ (accessed on 20 December 2022), Institutional Data Access/Ethics Committee (contact via http://adni.loni.usc.edu/data-samples/access-data/, accessed on 20 December 2022) upon sending a request that includes the proposed analysis and the named lead.\nSensors 2023, 23, 1914 18 of 20\nAcknowledgments: Data collection and sharing for this project was funded by the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: AbbVie, Alzheimer\u2019s Association; Alzheimer\u2019s Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd. and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research & Development, LLC.; Johnson & Johnson Pharmaceutical Research & Development LLC.; Lumosity; Lundbeck; Merck & Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (www.fnih.org). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer\u2019s Therapeutic Research Institute at the University of Southern California. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California.\nConflicts of Interest: The authors declare no conflict of interest.\nReferences 1. Hsiao, Y.-H.; Chang, C.-H.; Gean, P.-W. Impact of Social Relationships on Alzheimer\u2019s Memory Impairment: Mechanistic Studies. J. Biomed. Sci. 2018, 25, 3. [CrossRef] [PubMed] 2. Calabr\u00f2, M.; Rinaldi, C.; Santoro, G.; Crisafulli, C. The Biological Pathways of Alzheimer Disease: A Review. AIMS Neurosci. 2021, 8, 86\u2013132. [CrossRef] [PubMed] 3. Gillis, C.; Mirzaei, F.; Potashman, M.; Ikram, M.A.; Maserejian, N. The Incidence of Mild Cognitive Impairment: A Systematic Review and Data Synthesis. Alzheimers Dement. 2019, 11, 248\u2013256. [CrossRef] 4. Fathi, S.; Ahmadi, M.; Dehnad, A. Early Diagnosis of Alzheimer\u2019s Disease Based on Deep Learning: A Systematic Review. Comput. Biol. Med. 2022, 146, 105634. [CrossRef] [PubMed] 5. Kang, W.; Lin, L.; Zhang, B.; Shen, X.; Wu, S. Alzheimer\u2019s Disease Neuroimaging Initiative Multi-Model and Multi-Slice Ensemble\nLearning Architecture Based on 2D Convolutional Neural Networks for Alzheimer\u2019s Disease Diagnosis. Comput. Biol. Med. 2021, 136, 104678. [CrossRef]\n6. Liu, M.; Li, F.; Yan, H.; Wang, K.; Ma, Y.; Shen, L.; Xu, M.; Alzheimer\u2019s Disease Neuroimaging Initiative. A Multi-Model Deep Convolutional Neural Network for Automatic Hippocampus Segmentation and Classification in Alzheimer\u2019s Disease. Neuroimage 2020, 208, 116459. [CrossRef] 7. Meszl\u00e9nyi, R.J.; Buza, K.; Vidny\u00e1nszky, Z. Resting State FMRI Functional Connectivity-Based Classification Using a Convolutional Neural Network Architecture. Front. Neuroinform. 2017, 11, 61. [CrossRef] 8. Song, T.-A.; Roy Chowdhury, S.; Yang, F.; Jacobs, H.; El Fakhri, G.; Li, Q.; Johnson, K.; Dutta, J. Graph convolutional neural networks for alzheimer\u2019s disease classification. Proc. IEEE Int. Symp. Biomed. Imaging 2019, 2019, 414\u2013417. [CrossRef] 9. Kazi, A.; Krishna, S.A.; Shekarforoush, S.; Kortuem, K.; Navab, N. Self-Attention Equipped Graph Convolutions for Disease Prediction. In Proceedings of the 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI), Venice, Italy, 8\u201311 April 2019. [CrossRef] 10. Yu, S.; Yue, G.; Elazab, A.; Song, X.; Wang, T.; Lei, B. Multi-Scale Graph Convolutional Network for Mild Cognitive Impairment Detection. In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention; International Workshop on Graph Learning in Medical Imaging, Shenzhen, China, 17 October 2019; pp. 79\u201387. [CrossRef] 11. Jiang, H.; Cao, P.; Xu, M.; Yang, J.; Zaiane, O. Hi-GCN: A Hierarchical Graph Convolution Network for Graph Embedding Learning of Brain Network and Brain Disorders Prediction. Comput. Biol. Med. 2020, 127, 104096. [CrossRef] 12. Zhao, F.; Li, N.; Pan, H.; Chen, X.; Li, Y.; Zhang, H.; Mao, N.; Cheng, D. Multi-View Feature Enhancement Based on Self-Attention Mechanism Graph Convolutional Network for Autism Spectrum Disorder Diagnosis. Front. Hum. Neurosci. 2022, 16, 918969. [CrossRef] 13. Zeng, D.; Zhao, C.; Quan, Z. CID-GCN: An Effective Graph Convolutional Networks for Chemical-Induced Disease Relation Extraction. Front. Genet. 2021, 12, 624307. [CrossRef] [PubMed] 14. Bai, R.; Huang, R.; Zheng, L.; Chen, Y.; Qin, Y. Structure Enhanced Deep Clustering Network via a Weighted Neighbourhood Auto-Encoder. Neural. Netw. 2022, 155, 144\u2013154. [CrossRef] [PubMed] 15. Crane, P.K.; Carle, A.; Gibbons, L.E.; Insel, P.; Mackin, R.S.; Gross, A.; Jones, R.N.; Mukherjee, S.; Curtis, S.M.; Harvey, D.; et al. Development and Assessment of a Composite Score for Memory in the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI). Brain Imaging Behav. 2012, 6, 502\u2013516. [CrossRef] [PubMed]\nSensors 2023, 23, 1914 19 of 20\n16. Gibbons, L.E.; Carle, A.C.; Mackin, R.S.; Harvey, D.; Mukherjee, S.; Insel, P.; Curtis, S.M.; Mungas, D.; Crane, P.K. Alzheimer\u2019s Disease Neuroimaging Initiative A Composite Score for Executive Functioning, Validated in Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) Participants with Baseline Mild Cognitive Impairment. Brain Imaging Behav. 2012, 6, 517\u2013527. [CrossRef] [PubMed] 17. Choi, S.-E.; Mukherjee, S.; Gibbons, L.E.; Sanders, R.E.; Jones, R.N.; Tommet, D.; Mez, J.; Trittschuh, E.H.; Saykin, A.; Lamar, M.; et al. Development and Validation of Language and Visuospatial Composite Scores in ADNI. Alzheimers Dement. 2020, 6, e12072. [CrossRef] 18. Ashburner, J. Computational Anatomy with the SPM Software. Magn. Reson. Imaging 2009, 27, 1163\u20131174. [CrossRef] 19. Evans, A.C.; Collins, D.L.; Mills, S.R.; Brown, E.D.; Peters, T.M. 3D Statistical Neuroanatomical Models from 305 MRI Volumes.\nIn Proceedings of the Nuclear Science Symposium and Medical Imaging Conference, San Francisco, CA, USA, 31 October\u20136 November 1993. [CrossRef]\n20. Huang, G.; Liu, Z.; Laurens, V.; Weinberger, K.Q. Densely Connected Convolutional Networks. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017. [CrossRef] 21. Zhang, B.; Lin, L.; Wu, S. A Review of Brain Atrophy Subtypes Definition and Analysis for Alzheimer\u2019s Disease Heterogeneity Studies. J. Alzheimers Dis. 2021, 80, 1339\u20131352. [CrossRef] 22. Zhang, B.; Lin, L.; Wu, S.; Al-Masqari, Z.H.M.A. Multiple Subtypes of Alzheimer\u2019s Disease Base on Brain Atrophy Pattern. Brain Sci. 2021, 11, 278. [CrossRef] 23. Zhang, B.; Lin, L.; Liu, L.; Shen, X.; Wu, S. Concordance of Alzheimer\u2019s Disease Subtypes Produced from Different Representative Morphological Measures: A Comparative Study. Brain Sci. 2022, 12, 187. [CrossRef] 24. Alzheimer\u2019s Association 2011 Alzheimer\u2019s Disease Facts and Figures. Alzheimers Dement. 2011, 7, 208\u2013244. [CrossRef] 25. Lin, L.; Fu, Z.; Xu, X.; Wu, S. Mouse Brain Magnetic Resonance Microscopy: Applications in Alzheimer Disease. Microsc. Res. Tech. 2015, 78, 416\u2013424. [CrossRef] 26. Arnold, M.; Nho, K.; Kueider-Paisley, A.; Massaro, T.; Huynh, K.; Brauner, B.; MahmoudianDehkordi, S.; Louie, G.; Moseley,\nM.A.; Thompson, J.W.; et al. Sex and APOE E4 Genotype Modify the Alzheimer\u2019s Disease Serum Metabolome. Nat. Commun. 2020, 11, 1148. [CrossRef]\n27. Prince, M.; Ali, G.-C.; Guerchet, M.; Prina, A.M.; Albanese, E.; Wu, Y.-T. Recent Global Trends in the Prevalence and Incidence of Dementia, and Survival with Dementia. Alzheimers Res. Ther. 2016, 8, 23. [CrossRef] 28. Nebel, R.A.; Aggarwal, N.T.; Barnes, L.L.; Gallagher, A.; Goldstein, J.M.; Kantarci, K.; Mallampalli, M.P.; Mormino, E.C.; Scott, L.; Yu, W.H.; et al. Understanding the Impact of Sex and Gender in Alzheimer\u2019s Disease: A Call to Action. Alzheimers Dement. 2018, 14, 1171\u20131183. [CrossRef] 29. Li, Z.; Jiang, X.; Wang, Y.; Kim, Y. Applied Machine Learning in Alzheimer\u2019s Disease Research: Omics, Imaging, and Clinical Data. Emerg. Top. Life Sci. 2021, 5, 765\u2013777. [CrossRef] 30. Petersen, R.C.; Aisen, P.S.; Beckett, L.A.; Donohue, M.C.; Gamst, A.C.; Harvey, D.J.; Jack, C.R.; Jagust, W.J.; Shaw, L.M.; Toga, A.W.; et al. Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI): Clinical Characterization. Neurology 2010, 74, 201\u2013209. [CrossRef] 31. Kipf, T.N.; Welling, M. Semi-Supervised Classification with Graph Convolutional Networks. arXiv 2016, arXiv:1609.02907. [CrossRef] 32. Farrer, L.A.; Cupples, L.A.; Haines, J.L.; Hyman, B.; Kukull, W.A.; Mayeux, R.; Myers, R.H.; Pericak-Vance, M.A.; Risch, N.; van Duijn, C.M. Effects of Age, Sex, and Ethnicity on the Association between Apolipoprotein E Genotype and Alzheimer Disease. A Meta-Analysis. APOE and Alzheimer Disease Meta Analysis Consortium. JAMA 1997, 278, 1349\u20131356. [CrossRef] 33. Zhang, J.; Lin, Y.; Dai, X.; Fang, W.; Wu, X.; Chen, X. Metformin Treatment Improves the Spatial Memory of Aged Mice in an APOE Genotype-Dependent Manner. FASEB J. 2019, 33, 7748\u20137757. [CrossRef] 34. Ghebremedhin, E.; Schultz, C.; Thal, D.R.; R\u00fcb, U.; Ohm, T.G.; Braak, E.; Braak, H. Gender and Age Modify the Association between APOE and AD-Related Neuropathology. Neurology 2001, 56, 1696\u20131701. [CrossRef] 35. Riedel, B.C.; Thompson, P.M.; Brinton, R.D. Age, APOE and Sex: Triad of Risk of Alzheimer\u2019s Disease. J. Steroid Biochem. Mol. Biol. 2016, 160, 134\u2013147. [CrossRef] [PubMed] 36. Andrews, J.S.; Desai, U.; Kirson, N.Y.; Zichlin, M.L.; Ball, D.E.; Matthews, B.R. Disease Severity and Minimal Clinically Important Differences in Clinical Outcome Assessments for Alzheimer\u2019s Disease Clinical Trials. Alzheimers Dement. 2019, 5, 354\u2013363. [CrossRef] [PubMed] 37. Coley, N.; Andrieu, S.; Jaros, M.; Weiner, M.; Cedarbaum, J.; Vellas, B. Suitability of the Clinical Dementia Rating-Sum of Boxes as a Single Primary Endpoint for Alzheimer\u2019s Disease Trials. Alzheimers Dement. 2011, 7, 602\u2013610.e2. [CrossRef] [PubMed] 38. Cedarbaum, J.M.; Jaros, M.; Hernandez, C.; Coley, N.; Andrieu, S.; Grundman, M.; Vellas, B. Alzheimer\u2019s Disease Neuroimaging Initiative Rationale for Use of the Clinical Dementia Rating Sum of Boxes as a Primary Outcome Measure for Alzheimer\u2019s Disease Clinical Trials. Alzheimers Dement. 2013, 9, S45\u2013S55. [CrossRef] 39. Tufail, A.B.; Ullah, K.; Khan, R.A.; Shakir, M.; Khan, M.A.; Ullah, I.; Ma, Y.-K.; Ali, M.S. On Improved 3D-CNN-Based Binary and Multiclass Classification of Alzheimer\u2019s Disease Using Neuroimaging Modalities and Data Augmentation Methods. J. Healthc. Eng. 2022, 2022, 1302170. [CrossRef]\nSensors 2023, 23, 1914 20 of 20\n40. An, X.; Zhou, Y.; Di, Y.; Ming, D. Dynamic Functional Connectivity and Graph Convolution Network for Alzheimer\u2019s Disease Classification. In Proceedings of the 2020 7th International Conference on Biomedical and Bioinformatics Engineering, Kyoto, Japan, 6\u20139 November 2020. [CrossRef] 41. Li, L.; Jiang, H.; Wen, G.; Cao, P.; Xu, M.; Liu, X.; Yang, J.; Zaiane, O. TE-HI-GCN: An Ensemble of Transfer Hierarchical Graph Convolutional Networks for Disorder Diagnosis. Neuroinformatics 2022, 20, 353\u2013375. [CrossRef] 42. Li, W.; Zhao, J.; Shen, C.; Zhang, J.; Hu, J.; Xiao, M.; Zhang, J.; Chen, M. Regional Brain Fusion: Graph Convolutional Network for Alzheimer\u2019s Disease Prediction and Analysis. Front. Neuroinform. 2022, 16, 886365. [CrossRef]\nDisclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."
        }
    ],
    "title": "A Convolutional Neural Network and Graph Convolutional Network Based Framework for AD Classification",
    "year": 2023
}