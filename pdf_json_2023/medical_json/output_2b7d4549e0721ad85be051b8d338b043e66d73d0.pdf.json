{
    "abstractText": "Emotion perception is essential for successful social interactions and maintaining long\u2010term relationships with friends and family. Individuals with autism spectrum disorder (ASD) experience social communication deficits and have reported difficulties in facial expression recognition. However, emotion recognition depends on more than just processing face expression; context is critically important to correctly infer the emotions of others. Whether context\u2010based emotion processing is impacted in those with Autism remains unclear. Here, we used a recently developed context\u2010 based emotion perception task, called Inferential Emotion Tracking (IET), and investigated whether individuals who scored high on the Autism Spectrum Quotient (AQ) had deficits in context\u2010based emotion perception. Using 34 videos (including Hollywood movies, home videos, and documentaries), we tested 102 participants as they continuously tracked the affect (valence and arousal) of a blurred\u2010 out, invisible character. We found that individual differences in Autism Quotient scores were more strongly correlated with IET task accuracy than they are with traditional face emotion perception tasks. This correlation remained significant even when controlling for potential covarying factors, general intelligence, and performance on traditional face perception tasks. These findings suggest that individuals with ASD may have impaired perception of contextual information, it reveals the importance of developing ecologically relevant emotion perception tasks in order to better assess and treat ASD, and it provides a new direction for further research on context\u2010based emotion perception deficits in ASD.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jefferson Ortega"
        },
        {
            "affiliations": [],
            "name": "Zhimin Chen"
        }
    ],
    "id": "SP:6032e0c63059953192c4b6d40c5776a1a48501dd",
    "references": [
        {
            "authors": [
                "M.B. Harms",
                "A. Martin",
                "G.L. Wallace"
            ],
            "title": "Facial emotion recognition in autism spectrum disorders: A review of behavioral and neuroimaging studies",
            "venue": "Neuropsychol. Rev. 20,",
            "year": 2010
        },
        {
            "authors": [
                "C. Lord",
                "M. Elsabbagh",
                "G. Baird",
                "J. Veenstra-Vanderweele"
            ],
            "title": "Autism spectrum disorder",
            "venue": "Lancet 392,",
            "year": 2018
        },
        {
            "authors": [
                "S. Baron-Cohen",
                "A.M. Leslie",
                "U. Frith"
            ],
            "title": "Does the autistic child have a \u201ctheory of mind\u201d? Cognition",
            "year": 1985
        },
        {
            "authors": [
                "S. Baron-Cohen"
            ],
            "title": "Theory of mind and autism: A review",
            "venue": "in International Review of Research in Mental Retardation",
            "year": 2000
        },
        {
            "authors": [
                "S. Baron-Cohen",
                "S. Wheelwright",
                "J. Hill",
                "Y. Raste",
                "Plumb",
                "I. The"
            ],
            "title": "Reading the Mind in the Eyes\u201d test revised version: A study with normal adults, and adults with asperger syndrome or high-functioning autism",
            "venue": "J. Child Psychol. Psychiatry",
            "year": 2001
        },
        {
            "authors": [
                "I. Pe\u00f1uelas-Calvo",
                "A. Sareen",
                "J. Sevilla-Llewellyn-Jones",
                "P. Fern\u00e1ndez-Berrocal"
            ],
            "title": "The, \u201cReading the Mind in the Eyes\u201d test in autism-spectrum disorders comparison with healthy controls: A systematic review and meta-analysis",
            "venue": "J. Autism Dev. Disord",
            "year": 2019
        },
        {
            "authors": [
                "W Sato"
            ],
            "title": "Structural correlates of reading the mind in the eyes in autism spectrum disorder",
            "venue": "Front. Hum. Neurosci. 11,",
            "year": 2017
        },
        {
            "authors": [
                "Holt",
                "R. J"
            ],
            "title": "Reading the Mind in the Eyes\u201d: An fMRI study of adolescents with autism and their siblings",
            "venue": "Psychol. Med",
            "year": 2014
        },
        {
            "authors": [
                "Z. Chen",
                "D. Whitney"
            ],
            "title": "Inferential emotion tracking (IET) reveals the critical role of context in emotion recognition. Emotion https:// doi",
            "year": 2020
        },
        {
            "authors": [
                "Z. Chen",
                "D. Whitney"
            ],
            "title": "Tracking the affective state of unseen persons",
            "venue": "Proc. Natl. Acad. Sci. USA",
            "year": 2019
        },
        {
            "authors": [
                "Z. Chen",
                "D. Whitney"
            ],
            "title": "Inferential affective tracking reveals the remarkable speed of context-based emotion perception",
            "venue": "Cognition 208,",
            "year": 2021
        },
        {
            "authors": [
                "L.F. Barrett",
                "B. Mesquita",
                "M. Gendron"
            ],
            "title": "Context in emotion perception",
            "venue": "Curr. Dir. Psychol. Sci. 20,",
            "year": 2011
        },
        {
            "authors": [
                "H. Aviezer",
                "N. Ensenberg",
                "R.R. Hassin"
            ],
            "title": "The inherently contextualized nature of facial emotion perception",
            "venue": "Curr. Opin. Psychol",
            "year": 2017
        },
        {
            "authors": [
                "D.C. Ong",
                "J. Zaki",
                "N.D. Goodman"
            ],
            "title": "Computational models of emotion inference in theory of mind: A review and roadmap",
            "venue": "Top. Cogn. Sci",
            "year": 2019
        },
        {
            "authors": [
                "J.M. Fernandes",
                "R. Caj\u00e3o",
                "R. Lopes",
                "R. Jer\u00f3nimo",
                "J.B. Barahona-Corr\u00eaa"
            ],
            "title": "Social cognition in schizophrenia and autism spectrum disorders: A systematic review and meta-analysis of direct comparisons",
            "venue": "Front. Psychiatry 9,",
            "year": 2018
        },
        {
            "authors": [
                "B.F.M. Oakley",
                "R. Brewer",
                "G. Bird",
                "C. Catmur"
            ],
            "title": "Theory of mind is not theory of emotion: A cautionary note on the Reading the Mind in the Eyes Test",
            "venue": "J. Abnorm. Psychol",
            "year": 2016
        },
        {
            "authors": [
                "S Van de Cruys"
            ],
            "title": "Precise minds in uncertain worlds: predictive coding in autism",
            "venue": "Psychol. Rev. 121,",
            "year": 2014
        },
        {
            "authors": [
                "G. Rajendran",
                "P. Mitchell"
            ],
            "title": "Cognitive theories of autism",
            "venue": "Dev. Rev. 27,",
            "year": 2007
        },
        {
            "authors": [
                "T. Velikonja",
                "Fett",
                "A.-K",
                "E. Velthorst"
            ],
            "title": "Patterns of nonsocial and social cognitive functioning in adults with autism spectrum disorder: A systematic review and meta-analysis",
            "venue": "JAMA Psychiat",
            "year": 2019
        },
        {
            "authors": [
                "J.J.A. van Boxtel",
                "H. Lu"
            ],
            "title": "A predictive coding perspective on autism spectrum disorders",
            "venue": "Front. Psychol. 4,",
            "year": 2013
        },
        {
            "authors": [
                "E. Pellicano",
                "D. Burr"
            ],
            "title": "When the world becomes \u201ctoo real\u201d: A Bayesian explanation of autistic perception",
            "venue": "Trends Cogn. Sci",
            "year": 2012
        },
        {
            "authors": [
                "J. Boucher"
            ],
            "title": "Putting theory of mind in its place: Psychological explanations of the socio-emotional-communicative impairments in autistic spectrum disorder",
            "venue": "Autism 16,",
            "year": 2012
        },
        {
            "authors": [
                "M.B. Hudepohl",
                "D.L. Robins",
                "T.Z. King",
                "C.C. Henrich"
            ],
            "title": "The role of emotion perception in adaptive functioning of people with autism spectrum disorders",
            "venue": "Autism 19,",
            "year": 2015
        },
        {
            "authors": [
                "L. Kanner"
            ],
            "title": "Autistic disturbances of affective contact",
            "venue": "Nerv. Child 2,",
            "year": 1943
        },
        {
            "authors": [
                "D.P. Kennedy",
                "R. Adolphs"
            ],
            "title": "Perception of emotions from facial expressions in high-functioning adults with autism",
            "venue": "Neuropsychologia 50,",
            "year": 2012
        },
        {
            "authors": [
                "S.M. Eack",
                "C.A. Mazefsky",
                "N.J. Minshew"
            ],
            "title": "Misinterpretation of facial expressions of emotion in verbal adults with autism spectrum disorder",
            "venue": "Autism 19,",
            "year": 2015
        },
        {
            "authors": [
                "J.A. Walsh",
                "S.E. Creighton",
                "M.D. Rutherford"
            ],
            "title": "Emotion perception or social cognitive complexity: What drives face processing deficits in autism spectrum disorder",
            "venue": "J. Autism Dev. Disord",
            "year": 2016
        },
        {
            "authors": [
                "M.K. Yeung"
            ],
            "title": "A systematic review and meta-analysis of facial emotion recognition in autism spectrum disorder: The specificity of deficits and the role of task characteristics",
            "venue": "Neurosci. Biobehav. Rev. 133,",
            "year": 2022
        },
        {
            "authors": [
                "Y He"
            ],
            "title": "The characteristics of intelligence profile and eye gaze in facial emotion recognition in mild and moderate preschoolers with autism spectrum disorder",
            "venue": "Front. Psychiatry 10,",
            "year": 2019
        },
        {
            "authors": [
                "Q. Su",
                "F. Chen",
                "H. Li",
                "N. Yan",
                "L. Wang"
            ],
            "title": "Multimodal emotion perception in children with autism spectrum disorder by eye tracking study",
            "venue": "IEEE-EMBS Conference on Biomedical Engineering and Sciences",
            "year": 2018
        },
        {
            "authors": [
                "M.C. de Jong",
                "H. van Engeland",
                "C. Kemner"
            ],
            "title": "Attentional effects of gaze shifts are influenced by emotion and spatial frequency, but not in autism",
            "venue": "J. Am. Acad. Child Adolesc. Psychiatry",
            "year": 2008
        },
        {
            "authors": [
                "S Fridenson-Hayo"
            ],
            "title": "Basic and complex emotion recognition in children with autism: cross-cultural findings",
            "venue": "Mol. Autism 7,",
            "year": 2016
        },
        {
            "authors": [
                "F. Happ\u00e9",
                "U. Frith"
            ],
            "title": "The weak coherence account: Detail-focused cognitive style in autism spectrum disorders",
            "venue": "J. Autism Dev. Disord",
            "year": 2006
        },
        {
            "authors": [
                "Teunisse",
                "J.-P"
            ],
            "title": "Face processing in adolescents with autistic disorder: The inversion and composite effects",
            "venue": "Brain Cogn",
            "year": 2003
        },
        {
            "authors": [
                "I. Gauthier",
                "C. Klaiman",
                "R.T. Schultz"
            ],
            "title": "Face composite effects reveal abnormal face processing in Autism spectrum disorders",
            "venue": "Vision Res",
            "year": 2009
        },
        {
            "authors": [
                "R. Brewer",
                "G. Bird",
                "K.L.H. Gray",
                "R. Cook"
            ],
            "title": "Face perception in autism spectrum disorder: Modulation of holistic processing by facial emotion",
            "venue": "Cognition 193,",
            "year": 2019
        },
        {
            "authors": [
                "P Ventura"
            ],
            "title": "Holistic processing of faces is intact in adults with autism spectrum disorder",
            "venue": "Vis. cogn. 26,",
            "year": 2018
        },
        {
            "authors": [
                "S. Naumann",
                "U. Senftleben",
                "M. Santhosh",
                "J. McPartland",
                "S.J. Webb"
            ],
            "title": "Neurophysiological correlates of holistic face processing in adolescents with and without autism spectrum disorder",
            "venue": "J. Neurodev. Disord. 10,",
            "year": 2018
        },
        {
            "authors": [
                "E.M. Barendse",
                "M.P.H. Hendriks",
                "G. Thoonen",
                "A.P. Aldenkamp",
                "R.P.C. Kessels"
            ],
            "title": "Social behaviour and social cognition in high-functioning adolescents with autism spectrum disorder (ASD): Two sides of the same coin",
            "venue": "Cogn. Process",
            "year": 2018
        },
        {
            "authors": [
                "A. Senju"
            ],
            "title": "Atypical development of spontaneous social cognition in autism spectrum disorders",
            "venue": "Brain Dev",
            "year": 2013
        },
        {
            "authors": [
                "S B\u00f6lte"
            ],
            "title": "The development and evaluation of a computer-based program to test and to teach the recognition of facial affect",
            "venue": "Int. J. Circumpolar Health",
            "year": 2002
        },
        {
            "authors": [
                "S. Nowicki",
                "M.P. Duke"
            ],
            "title": "Manual for the Receptive Tests of the Diagnostic Analysis of Nonverbal Accuracy 2 (DANVA2) (Department of Psychology",
            "venue": "Emory University,",
            "year": 2008
        },
        {
            "authors": [
                "R. Righart",
                "B. de Gelder"
            ],
            "title": "Rapid influence of emotional scenes on encoding of facial expressions: An ERP study",
            "venue": "Soc. Cogn. Affect. Neurosci",
            "year": 2008
        },
        {
            "authors": [
                "R. Righart",
                "B. de Gelder"
            ],
            "title": "Context influences early perceptual analysis of faces\u2014An electrophysiological study",
            "venue": "Cereb. Cortex 16,",
            "year": 2006
        },
        {
            "authors": [
                "H. Aviezer",
                "S. Bentin",
                "V. Dudarev",
                "R.R. Hassin"
            ],
            "title": "The automaticity of emotional face-context integration",
            "venue": "Emotion 11,",
            "year": 2011
        },
        {
            "authors": [
                "P. Vermeulen"
            ],
            "title": "Context blindness in autism spectrum disorder: Not using the forest to see the trees as trees",
            "venue": "Focus Autism Other Dev. Disabl",
            "year": 2015
        },
        {
            "authors": [
                "U. Frith"
            ],
            "title": "Autism: Explaining the Enigma",
            "venue": "2nd edn. 2,",
            "year": 2003
        },
        {
            "authors": [
                "D Da Fonseca"
            ],
            "title": "Can children with autistic spectrum disorders extract emotions out of contextual cues",
            "venue": "Res. Autism Spectr. Disord",
            "year": 2009
        },
        {
            "authors": [
                "J. Ortega",
                "Z. Chen",
                "D. Whitney"
            ],
            "title": "Serial dependence in emotion perception mirrors the autocorrelations in natural emotion statistics",
            "venue": "J. Vis. 23,",
            "year": 2023
        },
        {
            "authors": [
                "W.A. Cunningham",
                "K.A. Dunfield",
                "P.E. Stillman"
            ],
            "title": "Emotional states from affective dynamics",
            "venue": "Emot. Rev",
            "year": 2013
        },
        {
            "authors": [
                "L.L. Speer",
                "A.E. Cook",
                "W.M. McMahon",
                "E. Clark"
            ],
            "title": "Face processing in children with autism: Effects of stimulus contents and type",
            "venue": "Autism 11,",
            "year": 2007
        },
        {
            "authors": [
                "J Weisberg"
            ],
            "title": "Social perception in autism spectrum disorders: Impaired category selectivity for dynamic but not static images in ventral temporal cortex",
            "venue": "Cereb. Cortex",
            "year": 2014
        },
        {
            "authors": [
                "K Alaerts"
            ],
            "title": "Underconnectivity of the superior temporal sulcus predicts emotion recognition deficits in autism",
            "venue": "Soc. Cogn. Affect. Neurosci",
            "year": 2014
        },
        {
            "authors": [
                "Rahko",
                "J. S"
            ],
            "title": "Valence scaling of dynamic facial expressions is altered in high-functioning subjects with autism spectrum disorders: An fMRI study",
            "venue": "J. Autism Dev. Disord",
            "year": 2012
        },
        {
            "authors": [
                "K.A. Pelphrey",
                "J.P. Morris",
                "G. McCarthy",
                "K.S. Labar"
            ],
            "title": "Perception of dynamic changes in facial affect and identity in autism",
            "venue": "Soc. Cogn. Affect. Neurosci",
            "year": 2007
        },
        {
            "authors": [
                "S. Baron-Cohen",
                "S. Wheelwright",
                "R. Skinner",
                "J. Martin",
                "E. Clubley"
            ],
            "title": "The autism-spectrum quotient (AQ): Evidence from Asperger syndrome/high-functioning autism, males and females, scientists and mathematicians",
            "venue": "J. Autism Dev. Disord",
            "year": 2001
        },
        {
            "authors": [
                "S.C. Weller"
            ],
            "title": "Cultural consensus theory: Applications and frequently asked questions",
            "venue": "Field Methods",
            "year": 2007
        },
        {
            "authors": [
                "Batchelder",
                "Anders"
            ],
            "title": "Cultural consensus theory. of experimental psychology",
            "year": 2018
        },
        {
            "authors": [
                "A.K. Romney",
                "W.H. Batchelder",
                "S.C. Weller"
            ],
            "title": "Recent applications of cultural consensus theory",
            "venue": "Am. Behav. Sci",
            "year": 1987
        },
        {
            "authors": [
                "W.H. Batchelder",
                "R. Anders"
            ],
            "title": "Cultural Consensus Theory: Comparing different concepts of cultural truth",
            "venue": "J. Math. Psychol",
            "year": 2012
        },
        {
            "authors": [
                "Banissy",
                "M. J"
            ],
            "title": "Superior facial expression, but not identity recognition, in mirror-touch synesthesia",
            "venue": "J. Neurosci. 31,",
            "year": 2011
        },
        {
            "authors": [
                "E Bal"
            ],
            "title": "Emotion recognition in children with autism spectrum disorders: Relations to eye gaze and autonomic state",
            "venue": "J. Autism Dev. Disord",
            "year": 2010
        },
        {
            "authors": [
                "B. Corden",
                "R. Chilvers",
                "D. Skuse"
            ],
            "title": "Avoidance of emotionally arousing stimuli predicts social\u2013perceptual impairment in Asperger\u2019s syndrome",
            "venue": "Neuropsychologia 46,",
            "year": 2008
        },
        {
            "authors": [
                "S. Wallace",
                "M. Coleman",
                "A. Bailey"
            ],
            "title": "An investigation of basic facial expression recognition in autism spectrum disorders",
            "venue": "Cogn. Emot",
            "year": 2008
        },
        {
            "authors": [
                "M.D. Rutherford",
                "A.M. Towns"
            ],
            "title": "Scan path differences and similarities during emotion perception in those with and without autism spectrum disorders",
            "venue": "J. Autism Dev. Disord",
            "year": 2008
        },
        {
            "authors": [
                "D. Neumann",
                "M.L. Spezio",
                "J. Piven",
                "R. Adolphs"
            ],
            "title": "Looking you in the mouth: abnormal gaze in autism resulting from impaired top-down modulation of visual attention",
            "venue": "Soc. Cogn. Affect. Neurosci",
            "year": 2006
        },
        {
            "authors": [
                "R. Adolphs",
                "L. Sears",
                "J. Piven"
            ],
            "title": "Abnormal processing of social information from faces in autism",
            "venue": "J. Cogn. Neurosci",
            "year": 2001
        },
        {
            "authors": [
                "M Ogai"
            ],
            "title": "fMRI study of recognition of facial expressions in high-functioning autistic patients",
            "venue": "NeuroReport 14,",
            "year": 2003
        },
        {
            "authors": [
                "K.A. Loveland",
                "J.L. Steinberg",
                "D.A. Pearson",
                "R. Mansour",
                "S. Reddoch"
            ],
            "title": "Judgments of auditory\u2013visual affective congruence in adolescents with and without autism: A pilot study of a new task using fMRI",
            "venue": "Percept. Mot. Skills 107,",
            "year": 2008
        },
        {
            "authors": [
                "S. Stagg",
                "Tan",
                "L.-H",
                "F. Kodakkadan"
            ],
            "title": "Emotion recognition and context in adolescents with autism spectrum disorder",
            "venue": "J. Autism Dev. Disord",
            "year": 2022
        },
        {
            "authors": [
                "C. Ashwin",
                "E. Chapman",
                "L. Colle",
                "S. Baron-Cohen"
            ],
            "title": "Impaired recognition of negative basic emotions in autism: A test of the amygdala theory",
            "venue": "Soc. Neurosci",
            "year": 2006
        },
        {
            "authors": [
                "D. Williams",
                "F. Happ\u00e9"
            ],
            "title": "Recognising \u2018social\u2019and \u2018non-social\u2019emotions in self and others: A study of autism",
            "venue": "Autism 14,",
            "year": 2010
        },
        {
            "authors": [
                "E.F. Risko",
                "K. Laidlaw",
                "M. Freeth",
                "T. Foulsham",
                "A. Kingstone"
            ],
            "title": "Social attention with real versus reel stimuli: Toward an empirical approach to concerns about ecological validity",
            "venue": "Front. Hum. Neurosci",
            "year": 2012
        },
        {
            "authors": [
                "S. Baron-Cohen",
                "T. Jolliffe",
                "C. Mortimore",
                "M. Robertson"
            ],
            "title": "Another advanced test of theory of mind: Evidence from very high functioning adults with autism or asperger syndrome",
            "venue": "J. Child Psychol. Psychiatry",
            "year": 1997
        },
        {
            "authors": [
                "A.A. Spek",
                "E.M. Scholte",
                "I.A. Van Berckelaer-Onnes"
            ],
            "title": "Theory of mind in adults with HFA and Asperger syndrome",
            "venue": "J. Autism Dev. Disord",
            "year": 2010
        },
        {
            "authors": [
                "R. Cook",
                "R. Brewer",
                "P. Shah",
                "G. Bird"
            ],
            "title": "Alexithymia, not autism, predicts poor recognition of emotional facial expressions",
            "venue": "Psychol. Sci",
            "year": 2013
        },
        {
            "authors": [
                "G. Bird",
                "R. Cook"
            ],
            "title": "Mixed emotions: The contribution of alexithymia to the emotional symptoms of autism",
            "venue": "Transl. Psychiatry 3,",
            "year": 2013
        },
        {
            "authors": [
                "P.E. Sifneos"
            ],
            "title": "Alexithymia: Past and present",
            "venue": "Am. J. Psychiatry 153,",
            "year": 1996
        },
        {
            "authors": [
                "M Solomon"
            ],
            "title": "The neural substrates of cognitive control deficits in autism spectrum disorders",
            "venue": "Neuropsychologia 47,",
            "year": 2009
        },
        {
            "authors": [
                "Mackie",
                "M.-A",
                "J. Fan"
            ],
            "title": "Reduced efficiency and capacity of cognitive control in autism spectrum disorder",
            "venue": "Autism Res",
            "year": 2016
        },
        {
            "authors": [
                "M. Solomon",
                "S.J. Ozonoff",
                "N. Cummings",
                "C.S. Carter"
            ],
            "title": "Cognitive control in autism spectrum disorders",
            "venue": "Int. J. Dev. Neurosci",
            "year": 2008
        },
        {
            "authors": [
                "E. Poljac",
                "H. Bekkering"
            ],
            "title": "A review of intentional and cognitive control in autism",
            "venue": "Front. Psychol",
            "year": 2012
        },
        {
            "authors": [
                "G.S. Dichter",
                "A. Belger"
            ],
            "title": "Social stimuli interfere with cognitive control in autism",
            "venue": "Neuroimage 35,",
            "year": 2007
        },
        {
            "authors": [
                "R.D.L. Booth",
                "F.G.E. Happ\u00e9"
            ],
            "title": "Evidence of reduced global processing in autism spectrum disorder",
            "venue": "J. Autism Dev. Disord",
            "year": 2018
        },
        {
            "authors": [
                "R.R. Hassin",
                "H. Aviezer",
                "S. Bentin"
            ],
            "title": "Inherently ambiguous: Facial expressions of emotions",
            "venue": "Context. Emot. Rev",
            "year": 2013
        },
        {
            "authors": [
                "R. Van der Hallen",
                "K. Evers",
                "K. Brewaeys",
                "W. Van den Noortgate",
                "J. Wagemans"
            ],
            "title": "Global processing takes time: A meta-analysis on local-global visual processing in ASD",
            "year": 2015
        },
        {
            "authors": [
                "L. Wang",
                "L. Mottron",
                "D. Peng",
                "C. Berthiaume",
                "M. Dawson"
            ],
            "title": "Local bias and local-to-global interference without global deficit: A robust finding in autism under various conditions of attention, exposure",
            "venue": "time, and visual angle. Cogn. Neuropsychol",
            "year": 2007
        },
        {
            "authors": [
                "J. Posner",
                "J.A. Russell",
                "B.S. Peterson"
            ],
            "title": "The circumplex model of affect: An integrative approach to affective neuroscience, cognitive development, and psychopathology",
            "venue": "Dev. Psychopathol",
            "year": 2005
        },
        {
            "authors": [
                "A Tseng"
            ],
            "title": "Using the circumplex model of affect to study valence and arousal ratings of emotional faces by children and adults with autism spectrum disorders",
            "venue": "J. Autism Dev. Disord",
            "year": 2014
        },
        {
            "authors": [
                "Herpers",
                "P.C. M"
            ],
            "title": "Emotional valence detection in adolescents with oppositional defiant disorder/conduct disorder or autism spectrum disorder",
            "venue": "Eur. Child Adolesc. Psychiatry",
            "year": 2019
        },
        {
            "authors": [
                "G. Celani",
                "M.W. Battacchi",
                "L. Arcidiacono"
            ],
            "title": "The understanding of the emotional meaning of facial expressions in people with autism",
            "venue": "J. Autism Dev. Disord. 29,",
            "year": 1999
        },
        {
            "authors": [
                "Quinde-Zlibut",
                "J. M"
            ],
            "title": "Multifaceted empathy differences in children and adults with autism",
            "venue": "Sci. Rep. 11,",
            "year": 2021
        },
        {
            "authors": [
                "E.J. Teh",
                "M.J. Yap",
                "S.J. RickardLiow"
            ],
            "title": "Emotional processing in autism spectrum disorders: Effects of age, emotional valence, and social engagement on emotional language use",
            "venue": "J. Autism Dev. Disord",
            "year": 2018
        },
        {
            "authors": [
                "A Tseng"
            ],
            "title": "Differences in neural activity when processing emotional arousal and valence in autism spectrum disorders",
            "venue": "Hum. Brain Mapp",
            "year": 2016
        },
        {
            "authors": [
                "L.A. Downey",
                "P.J. Johnston",
                "K. Hansen"
            ],
            "title": "The relationship between emotional intelligence and depression in a clinical sample",
            "venue": "Behav. Processes",
            "year": 2008
        },
        {
            "authors": [
                "P. Fernandez-Berrocal",
                "R. Alcaide"
            ],
            "title": "The role of emotional intelligence in anxiety and depression among adolescents",
            "venue": "Individ. Differ. Res",
            "year": 2006
        },
        {
            "authors": [
                "Kee",
                "K. S"
            ],
            "title": "Emotional intelligence in schizophrenia",
            "venue": "Schizophr. Res. 107,",
            "year": 2009
        },
        {
            "authors": [
                "P.J. O\u2019Connor",
                "A. Hill",
                "M. Kaya",
                "B. Martin"
            ],
            "title": "The measurement of emotional intelligence: A critical review of the literature and recommendations for researchers and practitioners",
            "venue": "Front. Psychol",
            "year": 2019
        },
        {
            "authors": [
                "C. MacCann",
                "D.L. Joseph",
                "D.A. Newman",
                "R.D. Roberts"
            ],
            "title": "Emotional intelligence is a second-stratum factor of intelligence: Evidence from hierarchical and bifactor models",
            "venue": "Emotion 14,",
            "year": 2014
        },
        {
            "authors": [
                "C. Miao",
                "R.H. Humphrey",
                "S. Qian"
            ],
            "title": "A meta-analysis of emotional intelligence and work attitudes",
            "venue": "J. Occup. Organ. Psychol",
            "year": 2017
        },
        {
            "authors": [
                "O\u2019Boyle",
                "E.H. Jr.",
                "R.H. Humphrey",
                "J.M. Pollack",
                "T.H. Hawver",
                "P.A. Story"
            ],
            "title": "The relation between emotional intelligence and job performance: A meta-analysis",
            "venue": "J. Organ. Behav",
            "year": 2011
        },
        {
            "authors": [
                "A. Maul"
            ],
            "title": "The validity of the Mayer\u2013Salovey\u2013Caruso Emotional Intelligence Test (MSCEIT) as a measure of emotional intelligence",
            "venue": "Emot. Rev",
            "year": 2012
        },
        {
            "authors": [
                "E. Diener",
                "R.A. Emmons",
                "R.J. Larsen",
                "S. Griffin"
            ],
            "title": "The satisfaction with life scale",
            "venue": "J. Pers. Assess",
            "year": 1985
        },
        {
            "authors": [
                "M. Konings",
                "M. Bak",
                "M. Hanssen",
                "J. van Os",
                "L. Krabbendam"
            ],
            "title": "Validity and reliability of the CAPE: A self-report instrument for the measurement of psychotic experiences in the general population",
            "venue": "Acta Psychiatr",
            "year": 2006
        },
        {
            "authors": [
                "C.D. Spielberger"
            ],
            "title": "State-trait anxiety inventory for adults",
            "venue": "https:// doi. org/ 10",
            "year": 1983
        },
        {
            "authors": [
                "S. Baron-Cohen",
                "S. Wheelwright"
            ],
            "title": "The empathy quotient: An investigation of adults with Asperger syndrome or high functioning autism, and normal sex differences",
            "venue": "J. Autism Dev. Disord",
            "year": 2004
        },
        {
            "authors": [
                "N. Benson",
                "D.M. Hulac",
                "J.H. Kranzler"
            ],
            "title": "Independent examination of the Wechsler Adult Intelligence Scale\u2014Fourth Edition (WAIS-IV): What does the WAIS-IV measure",
            "venue": "Psychol. Assess",
            "year": 2010
        },
        {
            "authors": [
                "C. MacCann",
                "R.D. Roberts",
                "G. Matthews",
                "M. Zeidner"
            ],
            "title": "Consensus scoring and empirical option weighting of performancebased Emotional Intelligence (EI) tests",
            "venue": "Pers. Individ. Dif",
            "year": 2004
        },
        {
            "authors": [
                "P.J. Legree"
            ],
            "title": "Evidence for an oblique social intelligence factor established with a Likert-based testing procedure",
            "venue": "Intelligence 21,",
            "year": 1995
        },
        {
            "authors": [
                "S. Hamann",
                "T. Canli"
            ],
            "title": "Individual differences in emotion processing",
            "venue": "Curr. Opin. Neurobiol",
            "year": 2004
        }
    ],
    "sections": [
        {
            "text": "1 Vol.:(0123456789) Scientific Reports | (2023) 13:8093 | https://doi.org/10.1038/s41598-023-35371-6\nwww.nature.com/scientificreports"
        },
        {
            "heading": "Inferential Emotion Tracking",
            "text": "reveals impaired context\u2011based emotion processing in individuals with high Autism Quotient scores Jefferson Ortega 1*, Zhimin Chen 1 & David Whitney 1,2,3\nEmotion perception is essential for successful social interactions and maintaining long\u2011term relationships with friends and family. Individuals with autism spectrum disorder (ASD) experience social communication deficits and have reported difficulties in facial expression recognition. However, emotion recognition depends on more than just processing face expression; context is critically important to correctly infer the emotions of others. Whether context\u2011based emotion processing is impacted in those with Autism remains unclear. Here, we used a recently developed context\u2011 based emotion perception task, called Inferential Emotion Tracking (IET), and investigated whether individuals who scored high on the Autism Spectrum Quotient (AQ) had deficits in context\u2011based emotion perception. Using 34 videos (including Hollywood movies, home videos, and documentaries), we tested 102 participants as they continuously tracked the affect (valence and arousal) of a blurred\u2011 out, invisible character. We found that individual differences in Autism Quotient scores were more strongly correlated with IET task accuracy than they are with traditional face emotion perception tasks. This correlation remained significant even when controlling for potential covarying factors, general intelligence, and performance on traditional face perception tasks. These findings suggest that individuals with ASD may have impaired perception of contextual information, it reveals the importance of developing ecologically relevant emotion perception tasks in order to better assess and treat ASD, and it provides a new direction for further research on context\u2011based emotion perception deficits in ASD.\nEmotion recognition and processing are essential for successful social interactions. Emotions play an important role in our social lives and in our understanding of others, and thus, shape the way that we understand the world around us. For example, individuals with autism spectrum disorder (ASD) have reported impairments in facial expression recognition, which could have knock-on consequences for other perceptual and social functions and could be a contributing factor in the reported deficits in social communication1,2. ASD is a neurodevelopmental disorder with an early onset and is characterized by impairments in social interaction and repetitive behaviors2. These deficits have often been attributed to an impairment in Theory of Mind, which is the ability to infer the mental states of others3\u20135.\nOne popular measure of Theory of Mind is the Reading the Mind in the Eyes Test6, also known as the Eyes Test, which requires participants to infer the emotion of a person based on their eyes alone, without any other information about the face or context. In this task, participants choose, among a selection of mental states, a single emotion label that they believe reflects the expression in the pair of isolated eyes. The Eyes Test distinguishes between typical controls and individuals with ASD6\u20139: performance on the Eyes Test is lower in individuals diagnosed with ASD compared to controls7 and it is correlated with Autism Spectrum Quotient (AQ) scores6. However, the Eyes Test has also been criticized on several grounds: it does not mimic how emotion is experienced in the real world; it lacks spatial context that is naturally experienced alongside facial expressions10\u201314; and it lacks temporal context, including how emotions change over time and how recent events influence an individual\u2019s current emotional state 15,16. Moreover, some studies have found no difference in performance on the Eyes Test between individuals with ASD and other disorders like schizophrenia17 and alexithymia18. Additionally,\nOPEN\n1Department of Psychology, University of California, Berkeley, CA 94720, USA. 2Vision Science Program, University of California, Berkeley, CA 94720, USA. 3Helen Wills Neuroscience Institute, University of California, Berkeley, CA 94720, USA. *email: jefferson_ortega@berkeley.edu\n2 Vol:.(1234567890) Scientific Reports | (2023) 13:8093 | https://doi.org/10.1038/s41598-023-35371-6\nsome researchers argue that Theory of Mind, as operationalized by the Eyes Test, is not the key component of the underlying deficit in social communication that is normally observed in ASD. Instead, they suggest that ASD is not characterized by a single cognitive impairment but a deficit in a collection of higher-order cognitive abilities19\u201324. Specifically, alternative theories suggest that there are deficits in meta-learning19 and deficits in updating priors23 in individuals with ASD.\nDespite the debate over the Eyes Test, it is well known that individuals with ASD have emotion perception deficits1\u20133,25\u201330, and this is true especially in more ecologically valid and dynamic situations31\u201333. These deficits have been attributed to moderators like emotion complexity34 and abnormal holistic processing of faces30,35\u201337 (though more recent studies suggest that individuals with ASD are able to utilize holistic face processing38\u201340). In addition, previous studies have also found that individuals with ASD display impairments in daily tasks that involve social interaction,41,42 even when there may be no impairment in contrived, less ecologically-valid experimental tasks of social cognition. These findings raise the possibility that the current assessments of social cognition in ASD may lack some critical attributes that are normally experienced during everyday social interactions10,11,13. In particular, existing popular tests6,43,44 do not measure or capture the role of spatial and temporal context in emotion perception.\nContextual information is critical for emotion perception. It influences emotion perception even at the early stages of face processing45,46, it is unintentionally and effortlessly integrated with facial expressions47, and it is an integral part of emotion perception in the real world13,14. More surprisingly, observers have been found to accurately and rapidly infer the emotions of characters in a scene without access to facial expressions, while using only contextual information10\u201312. The idea that \u201ccontextual blindness\u201d may be a key component in ASD has been discussed before48 and has been attributed to the weak central coherence hypothesis49. Central coherence is the ability to combine individual pieces of information together into a coherent whole and has been suggested to be a key problem in ASD49. Weak central coherence in ASD could manifest as a reduced ability to integrate contextual information with face and body information when inferring the emotions of people in the real world. Previous research has found that individuals with ASD are less able to use contextual cues to infer the emotions of blurred-out faces50 supporting the idea that weak central coherence may affect how individuals with ASD integrate emotional cues in the real world.\nContextual information is not only present in the spatial properties of background scenes (e.g., background environment, scene information, surrounding faces and bodies, etc.), but there is also a temporal context which involves the integration of social information over time. Temporal context refers to the idea that information about emotions is dynamic, unfolds over time, and is subject to change15,51,52. Both spatial and temporal context can be informative in emotion perception. One example of temporal context relates to noticing when the emotion of another individual has changed. For example, when having a conversation with a friend, if you were to say something that offends them, then their emotion will change depending on the intensity of the offense. To successfully navigate the conversation, you would need to have noticed that the emotion of your friend has changed, in a timely manner, and either apologize or change the topic of conversation. Individuals with ASD may be impaired in such circumstances, because they have impairments processing dynamic complex scenes53. Moreover, many studies have reported differences in the processing of temporal context in typical individuals compared to those with ASD54\u201357. However, there is currently a dearth of research on how emotion perception of dynamic stimuli, which includes natural spatial context, is affected in individuals with ASD.\nIn the present study, we investigated whether individuals who scored high on the Autism Quotient58 (AQ) have an impaired ability to infer the emotion of a blurred-out (invisible) character using dynamic contextual information. To investigate this, we recruited a fairly large sample (n = 102) and had participants complete an Inferential Emotion Tracking10,11 (IET) task, where participants used a 2D valence-arousal rating grid to continuously track the emotion of a blurred-out (invisible) character while watching a series of short (1\u20133\u00a0min) movie clips. Each participant watched and rated a total of 35 different movie clips (which included Hollywood movies, documentaries, and home videos), and then completed a battery of questionnaires at the end of the experiment. To foreshadow the results, we found that individual differences on the IET task correlated strongly with AQ scores, suggesting that context-based emotion perception may be impaired in ASD, while the correlation between participants\u2019 scores on the Eyes Test and on the AQ questionnaire was not significant."
        },
        {
            "heading": "Results",
            "text": "All analysis scripts and datasets are available at the Open Science Framework (https:// osf. io/ zku24/). All statistical analyses were performed using Python.\nIET task performance. Descriptive statistics of all variables are presented in Table\u00a01. We first quantified the individual differences in IET task accuracy, to assess whether there was systematic variability in accuracy across observers. We calculated each participant\u2019s IET accuracy for each video (for both valence and arousal ratings) and compared the average accuracy across participants (Fig.\u00a01b; see \u201cMethods\u201d). IET task accuracy was calculated as the Pearson correlation between the participant\u2019s ratings on each video and the \u201ccorrect\u201d ratings retrieved from an Informal Cultural Consensus Model59 (see \u201cMethods\u201d). The correct response computed from the Cultural Consensus Model is found by performing principal component analysis on all ratings for a given video and selecting the first set of factor scores (a weighted, linear combination of ratings)59. The first factor of the principal component analysis will contain individual responses that are the most correlated with each other. Essentially, the Cultural Consensus Model is a measure of the consensus judgments of valence and arousal over time for each video. It is a proxy for ground truth that is well supported for situations without an objective ground truth59\u201362. We found that the participants\u2019 IET accuracy varied significantly (Fig.\u00a02a). We then investigated whether there were video-specific individual differences by performing a similar analysis on the accuracy\n3 Vol.:(0123456789) Scientific Reports | (2023) 13:8093 | https://doi.org/10.1038/s41598-023-35371-6\nVariable M Median SD Min Max Skewness Kurtosis\nReading the mind in the eyes 25.17 26.00 5.37 5.00 33 (91.7%) \u2212 1.61 3.17\nFilms facial expression test 27.53 28.00 3.45 10.00 32 (100%) \u2212 2.23 7.98\nMatrices 28.61 29.00 4.39 12.00 35 (100%) \u2212 1.33 2.27\nVocabulary 13.17 13.00 3.60 1.00 20 (100%) \u2212 0.42 0.49\nAge 20.15 20.00 3.00 18.00 42.00 4.62 29.06\nSatisfaction w/life 23.23 24.00 6.62 5.00 35 (100%) \u2212 0.55 0.06\nEmpathy quotient 43.69 44.00 12.45 15.00 68 (85%) \u2212 0.34 \u2212 0.27\nAutism quotient 18.95 18.00 5.13 9.00 33 (66%) 0.46 0.11\nState anxiety 42.54 42.50 12.08 20.00 70 (87.5%) 0.18 \u2212 0.60\nTrait anxiety 45.86 47.00 10.46 20.00 74 (92.5%) \u2212 0.15 \u2212 0.02\nBeck depression 9.64 8.00 7.89 0.00 37 (58.7%) 1.12 1.31\nCAPE psychosis 72.33 71.50 15.39 46.00 126 (75%) 0.65 0.96\nCAPE depressive 16.96 16.50 5.36 7.00 33 (75%) 0.37 \u2212 0.39\nCAPE negative psychosis 28.02 27.00 7.68 16.00 61 (89.7%) 1.61 4.21\nCAPE positive psychosis 27.35 26.00 5.81 16.00 44 (47.8%) 0.53 \u2212 0.24\nValence accuracy 0.63 0.68 0.19 \u2212 0.18 0.87 \u2212 1.85 4.12\nArousal accuracy 0.49 0.54 0.18 \u2212 0.02 0.82 \u2212 0.82 0.18\nFigure\u00a01. Inferential Emotion Tracking (IET) task paradigm. (a) One hundred and two participants rated a total of 35 different video clips, which included Hollywood movies, documentaries, and home videos. A 2D valence-arousal rating grid was superimposed on the video and participants were required to rate the emotion of the target character. The red outline indicating the target character for a given trial was only shown on a single frame before the start of the trial. (b) An example of an accurate observer (solid red line) and an inaccurate observer (dashed red line) compared to the averaged ratings (consensus rating) of the context only condition (black line). Shaded regions on the consensus rating represent 1 standard error of the mean. Videos shown in this figure and study are publicly available (https:// osf. io/ f9rxn).\n4 Vol:.(1234567890) Scientific Reports | (2023) 13:8093 | https://doi.org/10.1038/s41598-023-35371-6\nof each video. Again, we found that task accuracy for each video varied significantly (Fig.\u00a02b). To ensure that low performers in the task did not just respond randomly, we recalculated the video-specific individual differences (as shown in Fig.\u00a02b) using a leave-one-out procedure for each participant. This allows us to organize the videos by their average accuracy across participants, which we call the difficulty function, and compare the leave-one-out group-averaged difficulty function to participants\u2019 own difficulty functions. If each participant\u2019s difficulty function is correlated with the leave-one-out group-averaged difficulty function, then this suggests that the participant\u2019s accuracy on each video was correlated with the tracking difficulty of each video. That is, participants should have higher accuracy for the easier videos and lower accuracy for the harder videos. If participants have a low correlation with the group-averaged difficulty function, then this may suggest that they frequently lapsed, randomly responded, or did not actively participate in the task. We found that ~ 98% of the participants\u2019 difficulty function correlation fell outside of the permuted null distribution correlation values (Fig.\u00a02c). This indicates that the vast majority of participants actively and consistently participated in the task. While two participants\u2019 difficulty functions fell within the 95% confidence interval of the permuted null distribution, we did not remove these subjects from the main analysis. However, in a separate analysis, we removed the two participants who fell within the permuted null distribution and found no significant difference in our results (Fig.\u00a0S2).\nCorrelations between IET performance and questionnaire items. Our main goal was to investigate whether low accuracy on the IET task was correlated with high scores on the AQ in order to explore whether individuals with ASD have impaired context-based emotion processing. We also wanted to compare this relationship to that of other popular emotion perception tasks: the Eyes Test6 and the Films Facial Expression Task63. We calculated the Spearman correlation between all variables in our data (Fig.\u00a0S1), instead of the Pearson correlation to avoid any assumptions about the distribution of the data. We report both uncorrected and Bonferroni corrected significance (for 17 comparisons made in the main results; Fig.\u00a03). We found a significant negative correlation between participants\u2019 accuracy on the IET task for their valence ratings and their AQ scores (rho = \u2212 0.368, p = 0.002, Bonferroni corrected; p < 0.001, uncorrected). Negative, but non-significant, correlations were found for the Films Facial Expression Task and AQ (rho = \u2212 0.284, p = 0.065, Bonferroni corrected; p = 0.004, uncorrected), the Eyes Test and AQ (rho = \u2212 0.134, p = 0.180, uncorrected) and IET arousal accuracy and AQ (rho = \u2212 0.079 p = 0.431, uncorrected) (Fig.\u00a03). Significant positive correlations were also found between IET valence accuracy and the Empathy Quotient (rho = 0.298 p = 0.04, Bonferroni corrected; p = 0.002, uncorrected) and between the Eyes Test and the Empathy Quotient (rho = 0.383, p < 0.001; Bonferroni corrected; p < 0.001, uncorrected). We found no significant correlations between Films Facial Expression Task and the Empathy Quotient (rho = 0.176, p = 0.076, uncorrected) or IET arousal accuracy and the Empathy Quotient (rho = 0.217, p = 0.478, Bonferroni corrected; p = 0.028, uncorrected). Significant correlations were also found between Fluid Intelligence and IET valence accuracy (rho = 0.393, p < 0.001, Bonferroni corrected; p < 0.001, uncorrected), IET arousal accuracy, (rho = 0.411, p < 0.001, Bonferroni corrected; p < 0.001, uncorrected), the Eyes Test (rho = 0.335, p = 0.01, Bonferroni corrected; p < 0.001, uncorrected), but no significant correlation was found between Fluid Intelligence and Films Facial Expression Task (rho = 0.28, p = 0.075, Bonferroni corrected; p = 0.004, uncorrected). Significant correlations were also found between Crystallized Intelligence and IET valence accuracy (rho = 0.311, p = 0.025, Bonferroni corrected; p < 0.001, uncorrected) and IET arousal accuracy, (rho = 0.373, p = 0.002, Bonferroni corrected; p < 0.001, uncorrected), however, no significant correlation was present between Crystallized Intelligence and the Eyes Test (rho = 0.201, p = 0.733, Bonferroni corrected; p = 0.043, uncorrected) and Films Facial Expression Task (rho = 0.201, p = 0.723, Bonferroni corrected; p = 0. 043,\nFigure\u00a02. Individual differences in participant accuracy and video difficulty. (a) IET accuracy scores for each individual participant, ranked (b) IET accuracy scores for each individual video, ranked, which we call the difficulty function. Shaded red regions depict 95% bootstrapped confidence intervals for each individual participant or video. Shaded gray regions show 95% confidence intervals around the permuted null distribution; dashed grey line shows mean permuted IET accuracy. (c) Correlation between participants\u2019 own stimulus difficulty function and the leave-one-out group averaged difficulty function. Error bars represent bootstrapped 95% CI. Dashed red line shows bootstrapped mean permuted IET accuracy and red shaded areas show 95% confidence intervals on the permuted null distribution.\n5 Vol.:(0123456789) Scientific Reports | (2023) 13:8093 | https://doi.org/10.1038/s41598-023-35371-6\nuncorrected). We also recalculated the correlation between IET valence accuracy and AQ while removing the two subjects who fell within the permuted null in Fig.\u00a02c and found that the correlation remained significant (rho = \u2212 0.361, p = 0.004, Bonferroni corrected; p < 0.001, uncorrected).\nControlling for general intelligence and covarying factors. We further investigated the correlation between IET valence accuracy and AQ by controlling for Fluid and Crystallized Intelligence. This assures that the correlation between the two variables is not just driven by general intelligence. We computed partial correlations between IET valence accuracy and AQ while controlling for Fluid and Crystalized Intelligence and plotted the bootstrapped mean and 95% confidence intervals revealing that the correlation does not cross 0 and remains significant (m = \u2212 0.311, CI [\u2212 0.485, \u2212 0.117], 5000 iterations) (Fig.\u00a04a). The correlation between Films Facial Expression Task and AQ also remained significant when controlling for general intelligence (m = -0.232, CI [\u2212 0.413, \u2212 0.03], 5000 iterations). However, the correlation between the Eyes Test and AQ was not significant (m = \u2212 0.058, CI [\u2212 0.263, 0.154], 5000 iterations). We also calculated partial correlations for IET valence accuracy and AQ while controlling for both Films Facial Expression Task and the Eyes Test performance, which revealed that the correlation remained significant (m = \u2212 0.355, CI [\u2212 0.527, \u2212 0.157], 5000 iterations). This suggests that the correlation between IET valence accuracy and AQ is not explained by participants\u2019 emotion perception abilities as measured by other popular face recognition tests.\nIn order to control for potential covarying factors, we performed new partial correlations between all tasks and AQ while controlling for general intelligence and the Empathy Quotient which had significant correlations with IET valence accuracy and the Eyes Test. We found that the correlation between IET valence accuracy and AQ remained significant (m = \u2212 0.26, CI [\u2212 0.447, \u2212 0.057], 5000 iterations), and so did the correlation between Films Facial Expression Task and AQ (m = \u2212 0.21, CI [\u2212 0.4, \u2212 0.003], 5000 iterations) (Fig.\u00a0S3). The correlation between the Eyes Test and AQ was not significant when controlling for potential covarying factors (m = 0.05, CI [\u2212 0.15, 0.25], 5000 iterations) (Fig.\u00a0S3a). We also computed partial correlations while controlling for both IET valence and arousal accuracy between AQ and the emotion perception tasks. We found no significant correlation between AQ and the Films Facial Expression Task (m = \u2212 0.17, CI [\u2212 0.37, 0.04], 5000 iterations) and the Eyes Test (m = \u2212 0.10, CI [\u2212 0.29, 0.01], 5000 iterations) (Fig.\u00a0S3b). This indicates that these popular tests of face emotion recognition do not account for significant variance in AQ once IET accuracy is controlled. Permutation tests were also conducted as additional statistical tests and revealed significant correlations between IET valence accuracy and AQ (p = 0.001, permutation test) and Films Facial Expression Task and AQ (p = 0.023, permutation test) (Fig.\u00a04b). The correlation between the Eyes Test and AQ was not significant (p = 0.174, permutation test).\nVideo analysis: isolating the best videos for predicting AQ. Our next goal was to investigate which videos in the task were the best videos for assessing the relationship between IET and ASD. The original set of videos in this experiment were from a previous study11, and were not chosen to specifically investigate traits associated with ASD. Nevertheless, it is interesting that the correlation between IET task accuracy and AQ scores was so strong. To investigate which videos were the best for assessing ASD traits, akin to an item analysis, we\nFigure\u00a03. Correlations between IET and questionnaires. Correlations between IET valence (red hexagon) and arousal (pink circle) accuracy scores, the Eyes Test (solid circle), Films Facial Expression Task (dashed circle), and questionnaires completed by participants. Highlighted row shows the correlation between each task and Autism Quotient (AQ) scores.\n6 Vol:.(1234567890) Scientific Reports | (2023) 13:8093 | https://doi.org/10.1038/s41598-023-35371-6\ncalculated the minimum videos needed to reach 75% of the effect size of the original rho = 0.37 (i.e., threshold rho = 0.277). We first selected 5 videos at random, without replacement, from the list of videos and used these videos to calculate all participant\u2019s IET valence accuracy. We then calculated the spearman correlation between participants\u2019 IET valence accuracy for the currently chosen videos and AQ. At each step, we increased the number of videos used to calculate IET valence accuracy. This process was repeated 5000 times for each step in the analysis and the Fisher-Z mean correlation coefficient of the 5000 iterations between IET valence accuracy and AQ was used and compared to the 75% threshold. The results show that only 7 videos were needed to reach 75% of the effect size originally observed (Fig.\u00a05a). We chose the 7 videos with the highest correlation between IET valence accuracy and AQ for further analysis which revealed a significant negative correlation (AQ versus IET: rho = \u2212 0.512, p < 0.001) (Fig.\u00a05b). In order to verify the strength and reliability of this relationship, we conducted a reliability test: we first split the data, at random, into five chunks as evenly as possible and then recalculated the AQ correlation in each of the five chunks. We then calculated the average correlation, using fisher-Z transformation, of the five chunks and ran the same analysis for 5000 iterations. Using only the best videos, we found that the correlation remained significant and was significantly stronger than using all the videos in the original analysis (rho = 0.51, CI [\u2212 0.45, \u2212 0.56], p < 0.001) (Fig.\u00a05c). This reveals that the IET task has a substantial amount of power: it only takes a few videos to reveal a strong negative relationship with AQ scores. It further supports our original findings, that individuals with ASD may have deficits in context-based emotion perception.\nFinally, we further investigated the relationship between IET accuracy and AQ for the best videos by comparing IET accuracy using a split-half analysis. We split the data into two halves using the median AQ score and categorized individuals who had an AQ score less than 18 as the \u201cLow AQ\u201d group and individuals who scored higher than 18 as the \u201cHigh AQ\u201d group. We found that the high AQ group had significantly lower IET accuracy than the low AQ group (Fig.\u00a06a, p < 0.001, bootstrap test). We then wanted to explore whether the IET task is sensitive to subtle differences in AQ by splitting the data into four quartiles: the 0\u201325% AQ include scores 9\u201316 (n = 25), the 25\u201350% AQ includes scores 16\u201318 (n = 25), the 50\u201375% AQ include scores 18\u201322 (n = 25), and the 75\u2013100% AQ includes scores 22\u201333 (n = 27). The 0\u201325% group had significantly higher IET accuracy than the 25\u201350% AQ group (p = 0.037, bootstrap test), the 50\u201375% AQ group (p < 0.001, bootstrap test) and the 75\u2013100% AQ group (p < 0.001, bootstrap test) (Fig.\u00a06b). The 25\u201350% group had significantly higher IET accuracy than\nFigure\u00a04. Significance tests for AQ correlations. (a) Partial correlations between AQ and IET valence accuracy, Films Facial Expression Task, and the Eyes Test while controlling for Fluid and Crystalized intelligence (left). We also computed partial correlations for AQ and IET valence accuracy while controlling for both the Eyes Test and Films Facial Expression Task performance (right). Error bars represent bootstrapped 95% CI. (b) Permutation tests for AQ correlations showing Valence accuracy, Films Facial Expression Task, and the Eyes Test from left to right. Gray distributions represent the permuted null distributions for each relationship. The solid vertical lines (red, black) represent the observed empirical correlations for each task, respectively.\n7 Vol.:(0123456789) Scientific Reports | (2023) 13:8093 | https://doi.org/10.1038/s41598-023-35371-6\nthe 50\u201375% AQ group (p = 0.017, bootstrap test), and the 75\u2013100% AQ group (p = 0.001, bootstrap test). IET accuracy in the last two groups (50\u201375% and 75\u2013100%) was not significant (p = 0.149, bootstrap test)(Fig.\u00a06b). These results suggest that the IET task can measure subtle changes in AQ scores including in the typical range of AQ scores (9\u201333 score)58."
        },
        {
            "heading": "Discussion",
            "text": "In the present study, we investigated whether context-based emotion perception is impaired in individuals who score high on the Autism Quotient (AQ), using a recently developed context-based emotion recognition task (Inferential Emotion Tracking; IET). We also compared this relationship to that of more popular assessments that use static face stimuli isolated from context. We found that participants\u2019 accuracy in IET was significantly correlated with their AQ scores, such that high AQ scores correlated with low IET task accuracy. These results indicate that context-based emotion recognition may be specifically impacted in those with Autism. Additionally, we found that the correlation between IET and AQ was stronger than the correlation between the Eyes Test\nFigure\u00a05. Isolating the best videos for predicting AQ. (a) Example of the video analysis, showing only 100 iterations for each step. In a Monte Carlo simulation, we randomly selected N videos (abscissa) from the 35 videos and bootstrapped the correlation between IET valence accuracy and AQ (ordinate). The black dots represent the bootstrapped mean Spearman correlation for each number of videos used. The red dashed line represents 75% of the size of the original effect size observed with all the videos. Only 7 videos were needed to achieve an average effect size of 75% of the original correlation. (b) Correlation between the 7 best videos identified from the analysis in (a) and AQ scores. Green solid line represents the fitted linear regression model. (c) Cross-validated correlation between IET valence accuracy and AQ. The data were split into 5 close-to-equal chunks and the correlation between IET valence accuracy and AQ was calculated for each chunk then averaged and was calculated for 5000 iterations. Dashed black line represents the originally observed correlation with all videos used. Error bars represent bootstrapped 95% CI.\nFigure\u00a06. IET valence accuracy across different ranges of AQ scores for the best videos. (a) IET valence accuracy for low AQ scores (AQ < 18, n = 51) and high AQ scores (AQ > 18, n = 51). Each dot represents an individual participant. (b) IET accuracy as function of AQ quartiles: 0\u201325% AQ scores (9\u201316 AQ, n = 25), 25\u201350% AQ scores (16\u201318, AQ, n = 25), 50\u201375% AQ scores (18\u201322, AQ, n = 25), 75\u2013100% AQ scores (22\u201333 AQ, n = 27). Error bars represent bootstrapped 95% CI.\n8 Vol:.(1234567890) Scientific Reports | (2023) 13:8093 | https://doi.org/10.1038/s41598-023-35371-6\nand AQ, and higher than the correlation between the Films Facial Expression Task and AQ. Our results suggest that individuals with ASD may have deficits in processing emotion specifically from contextual information and they also highlight the importance of establishing ecological validity of stimuli and tasks to improve future assessments of ASD. Our result may also help explain the contradictory findings in the literature of facial emotion recognition in individuals with ASD1.\nWhether facial emotion recognition is impaired in individuals with Autism has been under debate with some studies finding clear impairments25,64\u201366 while other studies have not67\u201374. These equivocal findings in the literature may reflect the heterogeneity of social cognition impairments in ASD, or they may be due to differences in demographic characteristics, task design (e.g. ceiling effects, variables measured, low powered studies), or task demands (e.g. context-based, dynamic, or static facial emotion recognition)1,73. Alternatively, this conflict may also be due to a lack of sensitivity in the behavioral measures used to assess emotion perception deficits in individuals with ASD, as studies using eye-tracking and neuroimaging methods are much more likely to find a group difference between individuals with ASD and typical controls than behavioral methods (for review, see Harms et\u00a0al.1). Our results suggest that the inconsistent findings in the literature may be due to the lack of control or absence of contextual and dynamic information in previous studies. Moreover, our results suggest that future assessments should consider improving the ecological validity of stimuli and tasks by incorporating spatial and temporal context, thereby prioritizing the social-cognitive structure of scenes that humans typically experience in the real world75.\nThe relationship between the Eyes Tests and Autism has been extensively studied6,7,9,76. However, we found that participants\u2019 scores on the Eyes Test and the AQ questionnaire were not significantly correlated. This is consistent with some of the literature18, but may be surprising since the Eyes Test is commonly used to assess Theory of Mind in individuals with ASD and has previously been found to correlate with AQ6. While these results may be explained by the lack of clinically diagnosed individuals with ASD in the present study, it may also suggest that the Eyes Test is simply less sensitive: it was unable to differentiate between low and mid-range AQ scores and was not sensitive to subtle individual differences in emotion perception across participants. More popular tests used to assess ASD, like the Eye\u2019s Test, lack both temporal and spatial contextual emotion processing which our findings reveal to be a potential core impairment in individuals with ASD. Thus, this may suggest that previous research that found no difference in performance on the Eye\u2019s Test between healthy controls and individuals with ASD18,77 may be due to the lack of contextual information in the task. Additionally, low performance on the Eyes Test in individuals with ASD could reflect an impairment in facial emotion recognition due to alexithymia, which often co-occurs with ASD78,79.\nThe strength of the IET task, compared to more popular tests, is that it selectively removes the facial information of the character whose emotion is being inferred. Observers must therefore use the context to infer the emotion of the target characters. While some of the videos used in our study do include other faces, the information retrieved from these faces is not enough to accurately track the emotion of a blurred out character11. Consequentially, the design of the IET task and the relationship between task performance and participants\u2019 AQ scores should not be accounted for by co-occurring alexithymia in individuals with ASD. However, we did not measure alexithymia80 in our subject pool and future studies should investigate whether context-based emotion perception is impaired in individuals with alexithymia.\nAnother strength of the IET task is that it is novel. To the best of our knowledge, only one other study has used context-only stimuli while investigating emotion recognition ability in ASD and they only used static stimuli of natural photos in their experiment50. Additionally, in the IET task participants must infer emotion dynamically, in real-time, meaning that they must identify changes in emotion as it occurs. This is a fundamental component of the IET task, and it reveals a potentially critical role of dynamic information in ASD. This echoes findings from previous studies, which have reported that differences in emotion recognition found in ASD may be specific to dynamic stimuli: individuals with ASD can successfully identify emotions from static images but fail to identify emotions in dynamic stimuli53,72. This might help explain why performance on the IET task, which requires participants to dynamically infer emotions from spatial and temporal context in real time, would have a stronger relationship with AQ than the Eyes Test and Films Facial Expression Task, both of which use static stimuli isolated from context.\nLow performance on the IET task in individuals with high AQ scores may also be due to deficits in cognitive control, which is believed to be impaired in individuals with ASD81\u201384, especially when processing social stimuli85. Consequentially, the high cognitive demand that is required to actively infer both valence and arousal of a blurred-out character may be difficult for individuals with ASD. However, we found that IET arousal tracking did not significantly correlate with AQ scores. If a general deficit in cognitive control was driving the correlations, then we should have also found AQ scores correlated with low IET arousal tracking. It could be that individuals with higher AQ scores attended primarily to the arousal dimension instead of both dimensions, but it is not clear why this would occur consistently across individuals. Finally, low performance on the IET task may also reflect a lack of experience in social interactions in individuals with ASD. In other words, participants with high AQ scores potentially have less experience with a variety of social situations compared to participants with low AQ scores. This could interact with performance on the IET task because familiarity with a diverse range of contexts may be valuable when infering emotion in the videos.\nContext-based emotion perception as a core deficit in ASD could be consistent with the weak central coherence hypothesis, which states that perception in individuals with ASD is oriented towards local properties of a stimulus and leads to impaired global processing35,86. Accurate perception of emotion, though, requires global processing. For example, context often disambiguates the natural ambiguity that is present in facial expressions87. To access this kind of global information, contextual information needs to be successfully integrated with facial information, and observers must make connections between multiple visuo-social cues across scenes and over time11,12. Impaired access to this global information in ASD could therefore impair emotion processing. The IET\n9 Vol.:(0123456789) Scientific Reports | (2023) 13:8093 | https://doi.org/10.1038/s41598-023-35371-6\ntask may exacerbate the impaired central coherence in individuals with ASD, as they only have the context as a source of information when inferring the emotions of the blurred-out character in the scene. Global processing of contextual cues would be even more difficult for individuals with ASD, as they have been found to have relatively slow global processing86,88 and need long exposures to stimuli in order to improve global performance89. Thus, the dynamic nature of IET may further tax individuals with ASD, because the task not only involves spatial context (e.g., visual scene information and other faces) but also involves temporal context.\nWhile IET valence accuracy was strongly correlated with AQ scores, IET arousal accuracy had a much weaker correlation with AQ scores (Fig.\u00a03). The Affective Circumplex Model states that emotions can be described by a linear combination of two independent neurophysiological systems90; valence and arousal. Previous studies have found that the dimensional shape of valence and arousal values are constricted in individuals with ASD compared to typical controls91 and have found that individuals with ASD have deficits in detecting emotional valence92\u201395. Interestingly, Tseng et\u00a0al. (2014)91 found that while children with ASD perceived a constricted range of both valence and arousal, adults with ASD perceive only a constricted range of valence, and not arousal. These findings may explain why we found that valence, and not arousal, IET tracking was negativity correlated with AQ scores. However, previous research investigating valence and arousal processing in individuals with ASD has found contradictory results56,96. One neuroimaging study found abnormal activation and deactivation in individuals with ASD while passively viewing dynamically changing facial expressions, suggesting that processing of valence information in individuals with ASD may be impaired56. However, in a more recent study, Tseng et\u00a0al. investigated differences in neural activity for both valence and arousal in individuals with ASD while they actively rated the emotion of facial expressions and only group differences were found in neural activity for ratings of arousal but not for valence96. These contradictory results may be due to the difference in the use of static and dynamic stimuli when investigating valence and arousal perception in ASD.\nWhile the main objective of this study was to investigate whether context-based emotion perception is impaired in individuals who score high on AQ, we also investigated its relationship with a variety of cognitive and social abilities in order to control for potential covarying factors. Other than the relationship with AQ, we also found a significant relationship between IET valence accuracy and Empathy Quotient scores. More importantly, the direction of the correlations between these surveys and IET accuracy supports previous research that has found deficits in emotional intelligence in individuals with depression97,98, schizophrenia99, and anxiety 98. These relationships, and all others observed in this study, suggest that IET might also be useful to evaluate an individual\u2019s emotional intelligence. IET would have great advantages in evaluating emotional intelligence as it is considered an \u201cability\u201d based measure of emotional intelligence. Ability-based measures of emotional intelligence have strong advantages since the task is engaging and performance on the task cannot be faked like common-self report measures of emotional intelligence100. One criticism of ability-based measures is that they commonly have high correlations with general intelligence, suggesting that they may not actually be measuring emotional intelligence101. However, we controlled this and found that the correlation between IET valence accuracy and AQ remained significant even when general intelligence was factored out (Fig.\u00a04a). Another criticism of ability-based measures of emotional intelligence is that they often do not correlate with outcomes that they theoretically should correlate with 102,103. However, we found IET accuracy for both valence and arousal to be correctly correlated with measures of depression97,98, schizophrenia99, and anxiety98. Consensus-based scoring has also been criticized in measures of emotional intelligence104, however, in our study, we use an alternative measure of consensus scoring by using Cultural Consensus Theory59\u201361. While establishing IET as a measure of emotional intelligence is beyond the scope of this study, our results hint that IET may be useful as a component of emotional intelligence metrics. This is worth investigating further in the future.\nIn conclusion, we investigated whether context-based emotion perception is impaired in individuals who score high on the AQ and compared this relationship with other emotion perception tasks such as the Eyes Test and Films Facial Expression Task. Our results show that performance on IET was negatively correlated with participants\u2019 AQ scores, raising the intriguing possibility that context-based emotion perception is a core deficit in ASD. Our results bring into focus a range of previous mixed findings on the relationship between emotion perception and ASD, and they shed light on possible avenues for assessing and treating ASD in future work."
        },
        {
            "heading": "Methods",
            "text": "Participants. In total, we tested 102 healthy participants (39 men and 63 women, age range 18\u201342, M = 20.19, SD = 2.98) on an online website created for this experiment. As a priori sample size, we aimed to collect a similar sample size as Chen and Whitney11 who also used the IET task in their study which had 50 participants. However, since we were interested in investigating the relationship between task performance and AQ scores, we aimed to atleast double their sample size which led to a final sample size of 102 participants. Informed consent was obtained by all participants and the study was approved by the UC Berkeley Institutional Review Board. All methods were performed in accordance with relevant guidelines and regulations of the UC Berkeley Institutional Review Board. Participants were affiliates of UC Berkeley and participated in the experiment for course credit. All participants were naive to the purpose of the study.\nInferential Emotion Tracking. We used 35 videos used by Chen and Whitney11 in a previous study as stimuli for our experiment11 (materials available at https:// osf. io/ f9rxn). The videos consist of short 1\u20133\u00a0min clips from Hollywood movies containing single or multiple characters, home videos, and documentaries. In total, there were 25 Hollywood movies, 8 home videos, and 2 documentary clips used in the experiment. Participants used a 2D valence-arousal rating grid that was superimposed on each video clip to continuously rate the emotion of a blurred-out target character in each movie clip (Fig.\u00a01; video shown in figure is publicly available (https:// osf. io/ f9rxn)). Participants were shown who the target character is before the start of the trial and were given the\n10\nVol:.(1234567890)\nScientific Reports | (2023) 13:8093 | https://doi.org/10.1038/s41598-023-35371-6\nfollowing instructions: \u201cThe following character will be occluded by a mask and become blurred out. Your task is to track the real emotions of this character throughout the entire video (but NOT other characters NOR the general emotion of the clip) in real-time\u201d.\nEmotion perception tasks. Our main goal was to investigate the difference in the relationship between IET task accuracy and AQ, and the relationship between the Eyes Test and AQ. We used the revised version of the Eyes Test in this study which consisted of 36 questions where participants had to choose a mental state out of a group of words that best fit the pair of eyes shown6. In order to compare the results of the IET task to a general emotion perception task, we also used the Films Facial Expression Task. which investigates an individual\u2019s ability to recognize the emotional expression of others63. In this task, participants were presented with an adjective that represented an emotional state and participants had to select one of three images (of the same actor) that best displayed the emotional state for that trial. This task controls for general ability in recognizing emotion from facial expressions, allowing us to compare context-based emotion perception with facial expression recognition ability.\nQuestionnaires. Following the completion of the IET experiment, participants were asked to complete a short (20\u201325\u00a0min) questionnaire. The questionnaire included a demographic section as well as a series of surveys meant to access cognitive and social ability. The first section of the questionnaire asks about gender, age, and education level. The second section contains the Satisfaction with Life Scale105, Autism-Spectrum Quotient58, Community Assessment of Psychic Experiences106, State-Trait Anxiety Index107, Beck Depression Inventory-II108, and the Empathy Quotient109. Each section is designed to assess the satisfaction with life, autism-like tendencies or characteristics, incidence of psychotic experiences, general trait anxiety, severity of depression, and ability to empathize, respectively, of the participant. Participants also completed segments from the Wechsler Adult Intelligence Scale in order to test their fluid and crystallized intelligence110. Specifically, we used the Vocabulary and the Matrix Reasoning subsets of the scale to measure for crystalized and fluid intelligence, respectively. These tests are well known and frequently used in psychology and have been historically used for these measures.\nCultural consensus theory. One issue that arises with many emotion perception tasks like the Eyes Test is that there is no \u201ccorrect answer\u201d in emotion perception tasks and thus the consensus is often used as the correct answer for many emotion perception and emotional intelligence tasks111. For example, target words for the Eyes Test were first chosen by the authors, and a set of judges then selected which target word was the most suitable for each stimulus6. Five out of the eight judges needed to agree on a target word in order to label it as \u201ccorrect\u201d. One theory of consensus scoring is that the judgment of non-experts is equivalent to expert judgments except that the responses are more distributed and less reliable, thus the consensus of non-expert judgments should equal the responses of experts112. However, consensus scoring can be limited due to the equal weighting of participants\u2019 responses. Averaging the response of all participants assumes that all participants are equally knowledgeable, which can be invalid in emotion perception tasks113. In our study, we used Cultural Consensus Theory to calculate the consensus which estimates the correct answers to a series of questions by assessing an individual\u2019s knowledge or competency compared to that of the group59,61.\nWe measured accuracy on the IET task by calculating participants Cultural Consensus Theory accuracy on participants Context-only ratings. We used the Informal Cultural Consensus Model in our analysis as it makes fewer assumptions about the data and we do not need to correct for guessing59. Cultural Consensus Theory accuracy is calculated as the Pearson correlation between an individual observer\u2019s rating for a given video and the first set of factor scores from the principal component analysis of the Context-only ratings. We conceptualize an individual\u2019s IET accuracy as their ability to track and infer the emotions of a blurred-out character in a movie clip by using only contextual information. We computed the average IET accuracy by first applying Fisher Z transformation on all individual correlations, averaging the transformed values, and then transforming the mean back to Pearson\u2019s r."
        },
        {
            "heading": "Data availability",
            "text": "Data are available at the OSF (https:// osf. io/ zku24/)."
        },
        {
            "heading": "Code availability",
            "text": "Data analysis was conducted using Python. Code is available at the OSF (https:// osf. io/ zku24/).\nReceived: 9 February 2023; Accepted: 17 May 2023"
        },
        {
            "heading": "Author contributions",
            "text": "Testing and data collection were performed by Z.C. J.O. performed the data analysis and interpretation under the supervision of D.W. J.O. drafted the manuscript, and D.W. provided critical revisions. All authors approved the final version of the manuscript for submission. This work was supported in part by the National Institute of Health (grant no. 1R01CA236793-01) to D.W."
        },
        {
            "heading": "Funding",
            "text": "This study was funded by National Institutes of Health (1R01CA236793-01)."
        },
        {
            "heading": "Competing interests",
            "text": "The authors declare no competing interests."
        },
        {
            "heading": "Additional information",
            "text": "Supplementary Information The online version contains supplementary material available at https:// doi. org/ 10. 1038/ s41598- 023- 35371-6.\nCorrespondence and requests for materials should be addressed to J.O.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or\nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n\u00a9 The Author(s) 2023"
        }
    ],
    "title": "Inferential Emotion Tracking reveals impaired context-based emotion processing in individuals with high Autism Quotient scores",
    "year": 2023
}