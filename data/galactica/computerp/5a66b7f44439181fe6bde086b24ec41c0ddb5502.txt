CONCLUSIONS AND RECOMMENDATIONS
In this dissertation, the effectiveness of a full Bayesian approach has been observed in learning models from natural gas flaring data. The author hopes this work contributes to the understanding of the options and considerations when applying data-driven approaches to gas flaring. In closing, this chapter presents the major conclusions and recommendations for future work. 8.1 conclusions The major conclusions are:
1. Bayesian learning implemented using Hamiltonian Monte Carlo can be effectively
applied to real problems in gas flaring analytics, in both supervised and unsupervised settings. The advantages of the Bayesian approach indicate it deserves wider usage in the petroleum engineering domain in general; these advantages are listed below:
(a) Petrotechnical domain expertise can be incorporated in a principled way. (b) Model interpretability is drastically improved, facilitating communications with
petroleum engineers. (c) Quantification of uncertainty leads to more robust decision making, which is
important for oil exploration and production companies. (d) The built-in Occam’s razor makes the model less prone to overfitting, in the
context of noisy field measurements. 2. The development of a suite of models (Table 8.1), with both parametric and nonpara-
metric techniques, provides guidance on how insights can be extracted from various
117
angles. The presented models are designed and tested to be able to generalize to different entities at various levels. To investigate the heterogeneity among the different entities (such as counties or
oilfields), partial pooling is recommended, because some entities have very little data. Gaussian processes demonstrate very attractive traits in revealing the patterns and
trends from flaring time series. A set of priors with the Matérn 5/2 kernel works very well across different modeling goals, observation models, and data sources. From a distributional point of view, the negative binomial and Gaussian mixture models
are good representations of the oilfield flare counts and flared volumes, respectively. The learned parameters and structures are very interpretable. Hidden clusters are found by fitting Gaussian mixture models. 6. A nearest-neighbor-based approach for operator level monitoring and analytics is
introduced. Its performance is tested on real data and defendable results are obtained. However, better resolution satellite data is needed for the scenario of multiple operators’ wells being very close to each other. 7. All the dissertation objectives (Section 1.2) have been achieved. In particular, the flared
volumes missed from VIIRS for the state and each county are estimated via fitting the intercept parameter and reported in Table 3.1 and Table 4.2. The nighttime combustion source detection limits of Landsat 8, without being corrected for artifacts due to glow, are determined and reported in Figure 3.2(b). Correlations between financial factors, production performance, and flared volumes at a state level are computed using Spearman’s ρ and reported in Figure 3.5 and Figure 3.6 for the original data and lag-1 differences, respectively. Most pairs of the variables do not show strong correlations on the lag-1 differences. Robust Gaussian process modeling serves as a generic framework for addressing the rest of the objectives, including demonstrating operator approaches,
118
evaluating if the goals of the North Dakota regulatory policy (Order 24665) have been achieved, and predicting NDIC flared volumes. 8.2 future work 3. The models in Chapter 5 are learned from each entity’s own data. Can pooling across different entities via hierarchical Gaussian processes improve the inferences? One step further from Item 3 above, the efficacy of spatial-temporal models (which allow for pooling information across time and space) are worth investigating. Are neighboring entities exhibiting close resemblance in flaring behaviors? The model comparison for GMMs in Chapter 6 depends on specifying the potential numbers of clusters a priori. In fact, Dirichlet process, as an infinite-dimensional generalization of the Dirichlet distribution, is nonparametric and allows for automatically choosing the number of necessary clusters. 120