{
    "abstractText": "Personalized recommender systems play a crucial role in capturing users\u2019 evolving preferences over time to provide accurate and effective recommendations on various online platforms. However, many recommendation models rely on a single type of behavior learning, which limits their ability to represent the complex relationships between users and items in real-life scenarios. In such situations, users interact with items in multiple ways, including clicking, tagging as favorite, reviewing, and purchasing. To address this issue, we propose the Relation-aware Contrastive Learning (RCL) framework, which effectively models dynamic interaction heterogeneity. The RCL model incorporates a multi-relational graph encoder that captures short-term preference heterogeneity while preserving the dedicated relation semantics for different types of user-item interactions. Moreover, we design a dynamic cross-relational memory network that enables the RCL model to capture users\u2019 long-term multi-behavior preferences and the underlying evolving cross-type behavior dependencies over time. To obtain robust and informative user representations with both commonality and diversity across multi-behavior interactions, we introduce a multi-relational contrastive learning paradigm with heterogeneous shortand long-term interest modeling. Our extensive experimental studies on several real-world datasets demonstrate the superiority of the RCL recommender system over various state-of-the-art baselines in terms of recommendation accuracy and effectiveness. We provide the implementation codes for the RCL model at https://github.com/HKUDS/RCL.",
    "authors": [
        {
            "affiliations": [],
            "name": "WEI WEI"
        },
        {
            "affiliations": [],
            "name": "LIANGHAO XIA"
        },
        {
            "affiliations": [],
            "name": "CHAO HUANG"
        },
        {
            "affiliations": [],
            "name": "Wei Wei"
        },
        {
            "affiliations": [],
            "name": "Lianghao Xia"
        }
    ],
    "id": "SP:4588d9fd4f0157def0c7941b7cc3f8d0ae99d881",
    "references": [
        {
            "authors": [
                "Aviad Aberdam",
                "Ron Litman",
                "Shahar Tsiper",
                "Oron Anschel",
                "Ron Slossberg",
                "Shai Mazor",
                "R Manmatha",
                "Pietro Perona"
            ],
            "title": "Sequence-to-sequence contrastive learning for text recognition",
            "year": 2021
        },
        {
            "authors": [
                "Philip Bachman",
                "R Devon Hjelm",
                "William Buchwalter"
            ],
            "title": "Learning representations by maximizing mutual information across views",
            "venue": "NIPS",
            "year": 2019
        },
        {
            "authors": [
                "Jianxin Chang",
                "Chen Gao",
                "Yu Zheng",
                "Yiqun Hui",
                "Yanan Niu",
                "Yang Song",
                "Depeng Jin",
                "Yong Li"
            ],
            "title": "Sequential recommendation with graph neural networks",
            "venue": "In SIGIR",
            "year": 2021
        },
        {
            "authors": [
                "Chong Chen",
                "Weizhi Ma",
                "Min Zhang",
                "Zhaowei Wang",
                "Xiuqiang He",
                "Chenyang Wang",
                "Yiqun Liu",
                "Shaoping Ma"
            ],
            "title": "Graph Heterogeneous Multi-Relational Recommendation",
            "venue": "In AAAI,",
            "year": 2021
        },
        {
            "authors": [
                "Chong Chen",
                "Min Zhang",
                "Yongfeng Zhang",
                "Weizhi Ma",
                "Yiqun Liu",
                "Shaoping Ma"
            ],
            "title": "Efficient heterogeneous collaborative filtering without negative sampling for recommendation",
            "venue": "In AAAI,",
            "year": 2020
        },
        {
            "authors": [
                "Mengru Chen",
                "Chao Huang",
                "Lianghao Xia",
                "WeiWei",
                "Yong Xu",
                "Ronghua Luo"
            ],
            "title": "Heterogeneous graph contrastive learning for recommendation",
            "venue": "In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining",
            "year": 2023
        },
        {
            "authors": [
                "Ting Chen",
                "Simon Kornblith",
                "Mohammad Norouzi",
                "Geoffrey Hinton"
            ],
            "title": "A simple framework for contrastive learning of visual representations",
            "venue": "In ICML. PMLR,",
            "year": 2020
        },
        {
            "authors": [
                "Chen Gao",
                "Xiangnan He",
                "Dahua Gan",
                "Xiangning Chen",
                "Fuli Feng",
                "Yong Li",
                "Tat-Seng Chua",
                "Depeng Jin"
            ],
            "title": "Neural multi-task recommendation from multi-behavior data",
            "venue": "In ICDE",
            "year": 2019
        },
        {
            "authors": [
                "Xavier Glorot",
                "Yoshua Bengio"
            ],
            "title": "Understanding the difficulty of training deep feedforward neural networks",
            "venue": "In AISTATS. JMLR Workshop and Conference Proceedings,",
            "year": 2010
        },
        {
            "authors": [
                "Long Guo",
                "Lifeng Hua",
                "Rongfei Jia",
                "Binqiang Zhao",
                "Xiaobo Wang",
                "Bin Cui"
            ],
            "title": "Buying or Browsing?: Predicting Real-time Purchasing Intent using Attention-based Deep Network with Multiple Behavior",
            "venue": "In KDD",
            "year": 2019
        },
        {
            "authors": [
                "Kaveh Hassani",
                "Amir Hosein Khasahmadi"
            ],
            "title": "Contrastive multi-view representation learning on graphs",
            "venue": "In ICML. PMLR,",
            "year": 2020
        },
        {
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ],
            "title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification",
            "year": 2015
        },
        {
            "authors": [
                "Xiangnan He",
                "Kuan Deng",
                "Xiang Wang",
                "Yan Li",
                "Yongdong Zhang",
                "Meng Wang"
            ],
            "title": "LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation",
            "venue": "In SIGIR. ACM",
            "year": 2020
        },
        {
            "authors": [
                "Bal\u00e1zs Hidasi",
                "Alexandros Karatzoglou",
                "Linas Baltrunas",
                "Domonkos Tikk"
            ],
            "title": "Session-based recommendations with recurrent neural networks. In ICLR",
            "year": 2016
        },
        {
            "authors": [
                "R Devon Hjelm",
                "Alex Fedorov",
                "Samuel Lavoie-Marchildon",
                "Karan Grewal",
                "Phil Bachman",
                "Adam Trischler",
                "Yoshua Bengio"
            ],
            "title": "Learning deep representations by mutual information estimation and maximization",
            "year": 2018
        },
        {
            "authors": [
                "Bowen Jin",
                "Chen Gao",
                "Xiangnan He",
                "Depeng Jin"
            ],
            "title": "Multi-behavior recommendation with graph convolutional networks",
            "venue": "In SIGIR",
            "year": 2020
        },
        {
            "authors": [
                "Bowen Jin",
                "Chen Gao",
                "Xiangnan He",
                "Depeng Jin",
                "Yong Li"
            ],
            "title": "Multi-behavior recommendation with graph convolutional networks",
            "year": 2020
        },
        {
            "authors": [
                "Wang-Cheng Kang",
                "Julian McAuley"
            ],
            "title": "Self-attentive sequential recommendation",
            "venue": "In ICDM",
            "year": 2018
        },
        {
            "authors": [
                "Thomas N Kipf",
                "Max Welling"
            ],
            "title": "Semi-supervised classification with graph convolutional networks",
            "venue": "arXiv preprint arXiv:1609.02907",
            "year": 2016
        },
        {
            "authors": [
                "Jiacheng Li",
                "Yujie Wang",
                "Julian McAuley"
            ],
            "title": "Time interval aware self-attention for sequential recommendation",
            "venue": "In WSDM",
            "year": 2020
        },
        {
            "authors": [
                "Qimai Li",
                "Zhichao Han",
                "Xiao-Ming Wu"
            ],
            "title": "Deeper insights into graph convolutional networks for semi-supervised learning",
            "venue": "In AAAI,",
            "year": 2018
        },
        {
            "authors": [
                "Meng Liu",
                "Hongyang Gao",
                "Shuiwang Ji"
            ],
            "title": "Towards deeper graph neural networks",
            "venue": "In KDD",
            "year": 2020
        },
        {
            "authors": [
                "Xiao Liu",
                "Fanjin Zhang",
                "Zhenyu Hou",
                "Li Mian",
                "Zhaoyu Wang",
                "Jing Zhang",
                "Jie Tang"
            ],
            "title": "Self-supervised learning: Generative or contrastive. Transactions on Knowledge and Data Engineering (TKDE) (2021)",
            "year": 2021
        },
        {
            "authors": [
                "Zhiwei Liu",
                "Ziwei Fan",
                "Yu Wang",
                "Philip S Yu"
            ],
            "title": "Augmenting sequential recommendation with pseudo-prior items via reversely pre-training transformer",
            "venue": "In SIGIR",
            "year": 2021
        },
        {
            "authors": [
                "Ilya Loshchilov",
                "Frank Hutter"
            ],
            "title": "Decoupled weight decay regularization",
            "venue": "In ICLR",
            "year": 2017
        },
        {
            "authors": [
                "Chen Ma",
                "Peng Kang",
                "Xue Liu"
            ],
            "title": "Hierarchical gating networks for sequential recommendation",
            "venue": "In KDD",
            "year": 2019
        },
        {
            "authors": [
                "Chen Ma",
                "Liheng Ma",
                "Yingxue Zhang",
                "Jianing Sun",
                "Xue Liu",
                "Mark Coates"
            ],
            "title": "Memory augmented graph neural networks for sequential recommendation",
            "venue": "In AAAI,",
            "year": 2020
        },
        {
            "authors": [
                "Xubin Ren",
                "Lianghao Xia",
                "Yuhao Yang",
                "Wei Wei",
                "Tianle Wang",
                "Xuheng Cai",
                "Chao Huang"
            ],
            "title": "SSLRec: A Self-Supervised Learning Library for Recommendation",
            "venue": "arXiv preprint",
            "year": 2023
        },
        {
            "authors": [
                "Leslie N Smith"
            ],
            "title": "Cyclical learning rates for training neural networks",
            "venue": "In WACV",
            "year": 2017
        },
        {
            "authors": [
                "Fei Sun",
                "Jun Liu",
                "Jian Wu",
                "Changhua Pei",
                "Xiao Lin",
                "Wenwu Ou",
                "Peng Jiang"
            ],
            "title": "BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer",
            "venue": "In CIKM",
            "year": 2019
        },
        {
            "authors": [
                "Jiaxi Tang",
                "Ke Wang"
            ],
            "title": "Personalized top-n sequential recommendation via convolutional sequence embedding",
            "venue": "In WSDM",
            "year": 2018
        },
        {
            "authors": [
                "Yonglong Tian",
                "Dilip Krishnan",
                "Phillip Isola"
            ],
            "title": "Contrastive multiview coding",
            "year": 2020
        },
        {
            "authors": [
                "Yonglong Tian",
                "Chen Sun",
                "Ben Poole",
                "Dilip Krishnan",
                "Cordelia Schmid",
                "Phillip Isola"
            ],
            "title": "What makes for good views for contrastive learning",
            "venue": "In NIPS,",
            "year": 2020
        },
        {
            "authors": [
                "Aaron Van den Oord",
                "Yazhe Li",
                "Oriol Vinyals"
            ],
            "title": "Representation learning with contrastive predictive coding",
            "venue": "arXiv e-prints (2018),",
            "year": 2018
        },
        {
            "authors": [
                "Stefan Van Der Walt",
                "S Chris Colbert",
                "Gael Varoquaux"
            ],
            "title": "The NumPy array: a structure for efficient numerical computation",
            "venue": "Computing in science & engineering 13,",
            "year": 2011
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is all you need. Advances in neural information processing systems (NIPS",
            "year": 2017
        },
        {
            "authors": [
                "Petar Velickovic",
                "William Fedus",
                "William L Hamilton",
                "Pietro Li\u00f2",
                "Yoshua Bengio",
                "R Devon Hjelm"
            ],
            "title": "Deep Graph Infomax",
            "venue": "ICLR 2,",
            "year": 2019
        },
        {
            "authors": [
                "Vikas Verma",
                "Thang Luong",
                "Kenji Kawaguchi",
                "Hieu Pham",
                "Quoc Le"
            ],
            "title": "Towards domain-agnostic contrastive learning",
            "venue": "In ICML. PMLR,",
            "year": 2021
        },
        {
            "authors": [
                "Chenyang Wang",
                "Min Zhang",
                "Weizhi Ma",
                "Yiqun Liu",
                "Shaoping Ma"
            ],
            "title": "Make it a chorus: knowledge-and time-aware item modeling for sequential recommendation",
            "venue": "In SIGIR",
            "year": 2020
        },
        {
            "authors": [
                "Feng Wang",
                "Huaping Liu"
            ],
            "title": "Understanding the behaviour of contrastive loss",
            "venue": "In CVPR",
            "year": 2021
        },
        {
            "authors": [
                "Jianling Wang",
                "Kaize Ding",
                "Liangjie Hong",
                "Huan Liu",
                "James Caverlee"
            ],
            "title": "Next-item recommendation with sequential hypergraphs",
            "venue": "In SIGIR",
            "year": 2020
        },
        {
            "authors": [
                "Ziyang Wang",
                "Wei Wei",
                "Gao Cong",
                "Xiao-Li Li",
                "Xian-Ling Mao",
                "Minghui Qiu"
            ],
            "title": "Global context enhanced graph neural networks for session-based recommendation",
            "venue": "In SIGIR",
            "year": 2020
        },
        {
            "authors": [
                "Wei Wei",
                "Chao Huang",
                "Lianghao Xia",
                "Yong Xu",
                "Jiashu Zhao",
                "Dawei Yin"
            ],
            "title": "Contrastive meta learning with behavior multiplicity for recommendation",
            "year": 2022
        },
        {
            "authors": [
                "Wei Wei",
                "Chao Huang",
                "Lianghao Xia",
                "Chuxu Zhang"
            ],
            "title": "Multi-Modal Self-Supervised Learning for Recommendation",
            "year": 2023
        },
        {
            "authors": [
                "JiancanWu",
                "XiangWang",
                "Fuli Feng",
                "Xiangnan He",
                "Liang Chen",
                "Jianxun Lian",
                "Xing Xie"
            ],
            "title": "Self-supervised graph learning for recommendation",
            "venue": "In SIGIR",
            "year": 2021
        },
        {
            "authors": [
                "Shu Wu",
                "Yuyuan Tang",
                "Yanqiao Zhu",
                "Liang Wang",
                "Xing Xie"
            ],
            "title": "Session-based recommendation with graph neural networks",
            "venue": "In AAAI,",
            "year": 2019
        },
        {
            "authors": [
                "Lianghao Xia",
                "Chao Huang",
                "Yong Xu",
                "Peng Dai",
                "Xiyue Zhang",
                "Hongsheng Yang",
                "Jian Pei",
                "Liefeng Bo"
            ],
            "title": "Knowledge-Enhanced Hierarchical Graph Transformer Network for Multi-Behavior Recommendation",
            "venue": "In AAAI,",
            "year": 2021
        },
        {
            "authors": [
                "Lianghao Xia",
                "Yong Xu",
                "Chao Huang",
                "Peng Dai",
                "Liefeng Bo"
            ],
            "title": "Graph meta network for multi-behavior recommendation",
            "venue": "In SIGIR",
            "year": 2021
        },
        {
            "authors": [
                "Xin Xia",
                "Hongzhi Yin",
                "Junliang Yu",
                "Yingxia Shao",
                "Lizhen Cui"
            ],
            "title": "Self-Supervised Graph Co-Training for Session-based Recommendation",
            "venue": "In CIKM",
            "year": 2021
        },
        {
            "authors": [
                "Xin Xia",
                "Hongzhi Yin",
                "Junliang Yu",
                "Qinyong Wang",
                "Lizhen Cui",
                "Xiangliang Zhang"
            ],
            "title": "Self-supervised hypergraph convolutional networks for session-based recommendation",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Hongrui Xuan",
                "Yi Liu",
                "Bohan Li",
                "Hongzhi Yin"
            ],
            "title": "Knowledge Enhancement for Contrastive Multi-Behavior Recommendation",
            "venue": "In Proceedings of the Sixteenth ACM International Conference on Web Search and Data",
            "year": 2023
        },
        {
            "authors": [
                "Chi Zhang",
                "Rui Chen",
                "Xiangyu Zhao",
                "Qilong Han",
                "Li Li"
            ],
            "title": "Denoising and Prompt-Tuning for Multi-Behavior Recommendation",
            "venue": "In Proceedings of the ACM Web Conference",
            "year": 2023
        },
        {
            "authors": [
                "Shuai Zhang",
                "Yi Tay",
                "Lina Yao",
                "Aixin Sun"
            ],
            "title": "Next item recommendation with self-attention",
            "venue": "arXiv preprint arXiv:1808.06414",
            "year": 2018
        },
        {
            "authors": [
                "Kaixiong Zhou",
                "Xiao Huang",
                "Yuening Li",
                "Daochen Zha",
                "Rui Chen",
                "Xia Hu"
            ],
            "title": "Towards deeper graph neural networks with differentiable group normalization",
            "venue": "Advances in neural information processing systems",
            "year": 2020
        },
        {
            "authors": [
                "Yanqiao Zhu",
                "Yichen Xu",
                "Feng Yu",
                "Qiang Liu",
                "Shu Wu",
                "Liang Wang"
            ],
            "title": "Graph contrastive learning with adaptive augmentation",
            "venue": "InWWW. 2069\u20132080",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Multi-Relational Contrastive Learning for Recommendation\nWEI WEI, University of Hong Kong, China\nLIANGHAO XIA, University of Hong Kong, China CHAO HUANG\u2217, University of Hong Kong, China\nPersonalized recommender systems play a crucial role in capturing users\u2019 evolving preferences over time to provide accurate and effective recommendations on various online platforms. However, many recommendation models rely on a single type of behavior learning, which limits their ability to represent the complex relationships between users and items in real-life scenarios. In such situations, users interact with items in multiple ways, including clicking, tagging as favorite, reviewing, and purchasing. To address this issue, we propose the Relation-aware Contrastive Learning (RCL) framework, which effectively models dynamic interaction heterogeneity. The RCL model incorporates a multi-relational graph encoder that captures short-term preference heterogeneity while preserving the dedicated relation semantics for different types of user-item interactions. Moreover, we design a dynamic cross-relational memory network that enables the RCL model to capture users\u2019 long-term multi-behavior preferences and the underlying evolving cross-type behavior dependencies over time. To obtain robust and informative user representations with both commonality and diversity across multi-behavior interactions, we introduce a multi-relational contrastive learning paradigm with heterogeneous shortand long-term interest modeling. Our extensive experimental studies on several real-world datasets demonstrate the superiority of the RCL recommender system over various state-of-the-art baselines in terms of recommendation accuracy and effectiveness. We provide the implementation codes for the RCL model at https://github.com/HKUDS/RCL.\nCCS Concepts: \u2022 Information systems\u2192 Recommender systems.\nACM Reference Format: Wei Wei, Lianghao Xia, and Chao Huang. 2023. Multi-Relational Contrastive Learning for Recommendation. In Seventeenth ACM Conference on Recommender Systems (RecSys \u201923), September 18\u201322, 2023, Singapore. ACM, New York, NY, USA, 18 pages. https: //doi.org/10.1145/3604915.3608807"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "In personalized recommender systems, accurately capturing users\u2019 dynamic preferences over time is essential to provide effective recommendations. Recent advances in neural network architectures have led to the development of various models that can encode the evolving patterns of user-item interactions, leveraging deep learning techniques such as recurrent neural encoders [14], convolution-based models [31], and attention mechanisms [18]. More recently, recommender systems have employed the Transformer [24, 30] or Graph Neural Networks (GNNs) [27, 42, 46] to achieve state-of-the-art recommendation performance. Although existing recommendation methods are effective, they typically rely on a single type of user-item interaction, such as clicks or purchases, which limits their ability to capture the dynamic multi-behavior interaction patterns that commonly occur in real-world recommender systems.\nIn real-life recommendation scenarios, users frequently engage with items in diverse ways based on their evolving interests. These interactions can include various types of user behaviors, such as page views, adding items to \u2217Chao Huang is the corresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. Manuscript submitted to ACM\nar X\niv :2\n30 9.\n01 10\n3v 3\n[ cs\n.I R\n] 2\n0 O\nct 2\n02 3\nfavorites, and making purchases, which can reflect heterogeneous user intentions and relationships with items [16, 43]. However, previous user embedding functions have typically relied on a single type of behavior modeling, which is insufficient for comprehensively capturing the diverse user intents and behavior heterogeneity. To address this limitation, researchers have proposed multi-behavior representations that can capture the various latent factors underlying user-item interactions and maintain distinct embedding spaces for different types of user behaviors in recommender systems [5, 16, 47, 48]. By leveraging multi-behavior representations, recommender systems can more effectively capture the complex relationships between users and items and provide more accurate recommendations.\nAlthough it is essential to model behavior-aware user-item relationships in recommender systems, several key challenges remain to be addressed. Firstly, it is challenging to preserve the behavior-specific semantics that are pertinent to each type of user-item interaction in a dynamic manner. This is especially critical for multi-behavior recommendation, where it is necessary to distill heterogeneous item-level dependencies while jointly modeling short-term and long-term user interests. Secondly, learning informative and robust representations of multiplex user-item interactions requires a tailored modeling approach with a performant recommendation paradigm that can capture both the commonality and diversity of the different behaviors. While it is possible to embed behavior-specific semantics into individual latent vectors, it is also critical to understand the multi-behavior commonality underlying the global view of each user\u2019s dynamic preferences. By understanding this, it becomes possible to effectively model multi-behavior interactions and leverage the shared information across different types of user-item interactions.\nContributions. To overcome the challenges of modeling behavior-aware user-item relationships, we propose the Relation-aware Contrastive Learning (RCL), which effectively captures heterogeneous and dynamic user intentions from multi-behavior data in recommendation. Our framework introduces a multi-relational graph encoder equipped with temporal context embedding to model behavior-aware short-term user interests and capture the dynamic and diverse nature of user-item interactions. Additionally, we propose a dynamic cross-relational memory network that incorporates heterogeneous item-item dependencies and learns user dynamic preferences with cross-behavior dependencies. Our dynamic multi-relational modeling approach enables us to characterize diverse user intents from a long-term perspective based on the interacted item sequence in dynamic environment. Furthermore, we design a multi-relational contrastive learning paradigm that enables RCL to encode multi-behavior commonality and differentiate the behavior-aware preference of different users. Our framework learns informative and robust representations of user-item interactions across different types of behaviors and enhances the generalizability and robustness of our recommender.\nTo summarize, the key contributions of this work are presented as follows:\n\u2022 Highlighting the importance of capturing the dynamic and heterogeneous nature of user-item relationships from multi-behavior data to make accurate recommendations.\n\u2022 Introducing a novel recommendation model called RCL that combines dynamic cross-relational dependency modeling with a multi-relational contrastive learning paradigm to capture both short-term and long-term user interests. In addition, we perform a theoretical analysis of the RCL model, which is presented in the Supplementary Section.\n\u2022 Conducting experiments on three real-world datasets and demonstrating the superior performance of the RCL model. Performing ablation studies and in-depth model analysis to justify the rationale behind the model design."
        },
        {
            "heading": "2 PRELIMINARIES",
            "text": "We consider a recommendation scenario with a set of users,V\ud835\udc62 , and a set of items,V\ud835\udc56 , where \ud835\udc62 and \ud835\udc56 represent the indices of users and items, respectively. We also introduce a set of behavior types, denoted by B, with individual behavior index \ud835\udc4f. In this multi-behavior recommender system, we define target behaviors as the types of user-item\ninteractions that are of primary interest, such as purchase behavior in E-commerce platforms or like behavior in online video sites. Other types of interactions between users and items are considered auxiliary behaviors, such as page view and add-to-favorite behaviors in E-commerce platforms or watch and review behaviors in online video sites.\nMulti-Behavior Interactions. We define a behavior-aware interaction sequence, denoted by \ud835\udc46\ud835\udc62 , for each user \ud835\udc62 based on their historical interactions with items. The sequence is represented as \ud835\udc46\ud835\udc62 = (\ud835\udc561, \ud835\udc4f1), (\ud835\udc562, \ud835\udc4f2), ..., (\ud835\udc56 |\ud835\udc46\ud835\udc62 | , \ud835\udc4f |\ud835\udc46\ud835\udc62 | ), where \ud835\udc4f (\ud835\udc4f \u2208 B) represents the type of interaction between user \ud835\udc62 and item \ud835\udc56 , and |\ud835\udc46\ud835\udc62 | denotes the length of the multi-behavior sequence for user \ud835\udc62. This representation captures the dynamic and heterogeneous nature of user-item relationships.\nProblem Formulation. The goal of the recommendation model is to predict the user\u2019s next preference based on their historical interactions with items and behavior types. To this end, the model takes as input the multi-behavior interaction sequence \ud835\udc46\ud835\udc62 for each user \ud835\udc62 with the awareness of interaction behavior types. The output of the model is the probabilities of user \ud835\udc62 interacting with all candidate items in the next time step (after item \ud835\udc56 |\ud835\udc46\ud835\udc62 | )."
        },
        {
            "heading": "3 METHODOLOGY",
            "text": "This section describes the technical architecture of the RCL model, which comprises three primary components. i) Short-term multi-behavior graph encoder, which utilizes multi-relational graph neural networks (GNNs) to capture the user\u2019s short-term interests. ii) Long-term user interest modeling module, which learns time-evolving multi-behavior preferences across different time slots. iii) Multi-behavior self-supervised learning module that enhances the user representation through behavior-aware contrastive augmentation."
        },
        {
            "heading": "3.1 Short-Term Multi-Behavior Graph Encoder",
            "text": "To capture the dedicated behavior semantics for underlying user\u2019s short-term interests, we propose a multi-relational graph encoder to handle the heterogeneous item dependencies within each time slot.\n3.1.1 Short-Term Multi-Behavior Graph. We introduce the short-term multi-behavior graph G\ud835\udc4f\ud835\udc61 = (V\ud835\udc4f\ud835\udc61 , E\ud835\udc4f\ud835\udc61 ,M\ud835\udc4f\ud835\udc61 ), which represents the behavior-aware user-item interactions for behavior \ud835\udc4f within the \ud835\udc61-th time slot (e.g., day, week, or month). The graph consists of nodesV\ud835\udc4f\ud835\udc61 = V\ud835\udc61,\ud835\udc62\ud835\udc4f \u222aV\ud835\udc61, \ud835\udc56\ud835\udc4f , and edges E\ud835\udc4f\ud835\udc61 that represent the interactions between user nodesV\ud835\udc4f\ud835\udc61,\ud835\udc62 and item nodesV\ud835\udc4f\ud835\udc61,\ud835\udc56 . Furthermore, we define the user-item interaction matrix M \ud835\udc4f \ud835\udc61 based on the set of edges E\ud835\udc4f\ud835\udc61 . Each entry M\ud835\udc4f\ud835\udc61,(\ud835\udc62,\ud835\udc56 ) = 1 indicates that user \ud835\udc62 has adopted item \ud835\udc56 under behavior \ud835\udc4f within the \ud835\udc61-th time slot.\n3.1.2 Relation-aware Message Passing. We propose a relation-aware message passing schema to model relational user data using lightweight graph neural networks, which is inspired by recent research efforts [13]. This schema captures high-order dependencies among items through recursively propagating embeddings across graph layers. The relationa-aware message passing function from the (\ud835\udc59-1)-th layer to the (\ud835\udc59 )-th layer is formalized as follows:\nE\ud835\udc4f,(\ud835\udc59 ) \ud835\udc61,\ud835\udc56 = \ud835\udf0e ( \u0393(M\ud835\udc4f\ud835\udc61 \u00b7M\ud835\udc4f\ud835\udc61 \ud835\udc47 ) \u00b7 E\ud835\udc4f,(\ud835\udc59\u22121) \ud835\udc61,\ud835\udc56 \u00b7W\ud835\udc4f,(\ud835\udc59 ) \ud835\udc61,\ud835\udc56 ) \u0393(M\ud835\udc4f\ud835\udc61 \u00b7M\ud835\udc4f\ud835\udc61 \ud835\udc47 ) = (D\ud835\udc4f\ud835\udc61 )\u2212 1 2 \u00b7M\ud835\udc4f\ud835\udc61 \u00b7 (B\ud835\udc4f\ud835\udc61 ) \u22121 \u00b7M\ud835\udc4f\ud835\udc61 \ud835\udc47 \u00b7 (D\ud835\udc4f\ud835\udc61 ) \u2212 12 (1)\nwhere E\ud835\udc61, \ud835\udc56\ud835\udc4f,(\ud835\udc59 ) represents the embedding of item \ud835\udc56 at the \ud835\udc59-th graph layer during the \ud835\udc61-th time slot. The learnable transformation used during the message passing process is denoted as W\ud835\udc61, \ud835\udc56\ud835\udc4f,(\ud835\udc59 ) \u2208 R\ud835\udc51\u00d7\ud835\udc51 . The authors use the PReLU activation function [12] \ud835\udf0e (\u00b7) to introduce non-linearities during the message passing process. By stacking multiple embedding propagation layers, the authors preserve behavior-specific high-order item dependencies in the generated representations E\ud835\udc4f,(\ud835\udc3f)\n\ud835\udc61,\ud835\udc56 , where \ud835\udc3f denotes the number of propagation layers.\nTo address the issue of large value effects of embeddings during recursive propagation [41], we incorporate the graph Laplacian normalized function of eigenvectors [19] \u0393(\u00b7) into the message passing function. Specifically, we generate two diagonal degree matrices based on the interaction matrix M\ud835\udc61\ud835\udc4f . These matrices are D\ud835\udc61\ud835\udc4f \u2208 R |V\ud835\udc56 |\u00d7 |V\ud835\udc62 | and B\ud835\udc61\ud835\udc4f \u2208 R |V\ud835\udc62 |\u00d7 |V\ud835\udc56 | . The entries in these matrices are generated as follows:\n\ud835\udc37\ud835\udc4f \ud835\udc61,(\ud835\udc5b,\ud835\udc5b) =\n|V\ud835\udc4f \ud835\udc61,\ud835\udc56 |\u2211\ufe01\n\ud835\udc5b=1 M\ud835\udc4f \ud835\udc61,(\ud835\udc5b) ; \ud835\udc35 \ud835\udc4f \ud835\udc61,(\ud835\udc5a,\ud835\udc5a) = |V\ud835\udc4f\ud835\udc61,\ud835\udc62 |\u2211\ufe01 \ud835\udc5a=1 (M\ud835\udc4f \ud835\udc61,(\ud835\udc5a) ) \ud835\udc47 (2)\nwhere \ud835\udc37\ud835\udc4f \ud835\udc61,(\ud835\udc5b,\ud835\udc5b) and \ud835\udc35 \ud835\udc4f \ud835\udc61,(\ud835\udc5a,\ud835\udc5a) denote the elements of the \ud835\udc5b-th and\ud835\udc5a-th row of the diagonal matrices, respectively.\nCross-Layer Aggregation. To aggregate the embeddings encoded from each graph layer, we first concatenate all layer-specific embeddings and then feed the resulting representation into a feed-forward network. This network has a trainable projection matrix denoted as W\ud835\udc4f\ud835\udc61,\ud835\udc50\ud835\udc4e\ud835\udc61 \u2208 R(\ud835\udc59\u00d7\ud835\udc51 )\u00d7\ud835\udc51 , which generates the final aggregated item embeddings E\ud835\udc4f\ud835\udc61,\ud835\udc56 :\nE\ud835\udc4f\ud835\udc61,\ud835\udc56 = [ E\ud835\udc4f,1 \ud835\udc61,\ud835\udc56 : E\ud835\udc4f,2 \ud835\udc61,\ud835\udc56 : ... : E\ud835\udc4f,\ud835\udc59 \ud835\udc61,\ud835\udc56 ] \u00b7W\ud835\udc4f\ud835\udc61,\ud835\udc50\ud835\udc4e\ud835\udc61 ; E\ud835\udc4f\ud835\udc61,\ud835\udc56 = E\ud835\udc4f \ud835\udc61,\ud835\udc56\n| |E\ud835\udc4f \ud835\udc61,\ud835\udc56 | |\n(3)\nBy using the cross-layer aggregationmethod described above, the fused embeddingsE\ud835\udc4f \ud835\udc61,\ud835\udc56 can preserve the behavior-aware short-term user preference at the \ud835\udc61-th time slot under the behavior type of \ud835\udc4f.\n3.1.3 User Short-Term Interest Representation. After encoding the item embeddings by exploring the high-order dependencies among items, we generate user representations that maintain the behavior-specific short-term interests. To do this, we aggregate embeddings propagated from the interacted items in the short-term multi-behavior graph G\ud835\udc4f\ud835\udc61 . The embedding propagation from item \ud835\udc56 to user \ud835\udc62 is formally presented as follows:\nm\ud835\udc4f\ud835\udc62\ud835\udc61\u2190\ud835\udc56\ud835\udc61 = \ud835\udc53 (e \ud835\udc4f \ud835\udc56\ud835\udc61 , e\ud835\udc4f\ud835\udc62\ud835\udc61 ) = 1\u221a\ufe03 |B\ud835\udc4f \ud835\udc61,(\ud835\udc62 ) | |D \ud835\udc4f \ud835\udc61,(\ud835\udc56 ) | \u00b7W\ud835\udc4f\ud835\udc61,\ud835\udc62 \u00b7 e\ud835\udc4f\ud835\udc56\ud835\udc61 (4)\ne\ud835\udc56\ud835\udc61\ud835\udc4f \u2208 R\ud835\udc51\u00d71 represents the item embedding within the \ud835\udc61-th time slot under the behavior type of \ud835\udc4f, whileW\ud835\udc61,\ud835\udc62\ud835\udc4f is the transformation matrix with dimensions of R\ud835\udc51\u00d7\ud835\udc51 . To generate the short-term interest representation of all users, we use\na message passing scheme that can be presented in matrix form as follows:\nE\ud835\udc4f\ud835\udc61,\ud835\udc62 = \ud835\udf0e (\u0393(M\ud835\udc4f\ud835\udc61 \ud835\udc47 ) \u00b7 E\ud835\udc4f\ud835\udc61,\ud835\udc56 \u00b7W \ud835\udc4f \ud835\udc61,\ud835\udc62 ); E\ud835\udc4f\ud835\udc61,\ud835\udc62 = E\ud835\udc4f\ud835\udc61,\ud835\udc62 | |E\ud835\udc4f\ud835\udc61,\ud835\udc62 | | ; \u0393(M\ud835\udc4f\ud835\udc61 \ud835\udc47 ) = (B\ud835\udc4f\ud835\udc61 )\u2212 1 2 \u00b7M\ud835\udc4f\ud835\udc61 \ud835\udc47 \u00b7 (D\ud835\udc4f\ud835\udc61 )\u2212 1 2 (5)\nTo ensure the user representation E\ud835\udc4f\ud835\udc61,\ud835\udc62 corresponding to users\u2019 short-term interests at the \ud835\udc61-th time slot under the behavior type of \ud835\udc4f is properly normalized, we utilize the \u0393(\u00b7) function.\n3.1.4 Temporal Context Injection. To capture the dynamic item dependencies in the short-term multi-behavior graph G\ud835\udc4f\ud835\udc61 and model the dynamic nature of user-item interactions, we propose to inject temporal contextual signals into the user representation. To achieve this, we build a temporal context encoder over the positional encoding technique in the Transformer architecture [36]. Specifically, we use sinusoid functions to generate the relative time embedding for each user-item interaction edge. This enhances our short-term multi-behavior graph encoder with the capability of capturing behavior-aware interaction dynamics of users through temporal context injection.\n3.1.5 Priori-aware Embedding Initialization. To address the potential issue of overfitting that may arise from relying solely on time slot-specific user-item interaction data in our short-term multi-behavior graph encoder, we develop a priori-aware embedding initialization strategy. This strategy injects the representations of the previous time slot (\ud835\udc61 \u2212 1) into the embedding initialization of the current time slot \ud835\udc61 , with the aim of reducing training difficulty and deterioration [9]. Formally, the priori-aware embedding initialization is defined as follows:\nE\ud835\udc4f,0 \ud835\udc61,\ud835\udc56\n= ( \ud835\udf01 \u2217 E\ud835\udc4f,0\n\ud835\udc61,\ud835\udc56 + (1 \u2212 \ud835\udf01 ) \u2217 E\ud835\udc4f\ud835\udc61\u22121,\ud835\udc56\n) \u00b7W\ud835\udc4f\n\ud835\udf01 (6)\nwhere E\ud835\udc4f,0 \ud835\udc61,\ud835\udc56\ndenotes the original input embeddings for the short-term multi-behavior graph G\ud835\udc4f\ud835\udc61 at the \ud835\udc61-th time slot, while E\ud835\udc4f\n\ud835\udc61\u22121,\ud835\udc56 represents the representations encoded from the previous (\ud835\udc61 \u2212 1) time slot. The \ud835\udf01 andW \ud835\udc4f \ud835\udf01 variables are the\nlearnable aggregation weight and projection matrix, respectively."
        },
        {
            "heading": "3.2 Dynamic Cross-Relational Memory Network",
            "text": "The long-term multi-behavior dynamics in a multi-behavior sequential recommender system provide a holistic view of the diverse preferences of users over different time slots. To capture this global multi-behavior interest of users, we propose a dynamic cross-relational memory that learns the evolving cross-type behavior dependencies in a long-term manner.\n3.2.1 Multi-Behavior Embedding Tensor. After encoding users\u2019 behavior-aware short-term interest with user (E\ud835\udc4f\ud835\udc61,\ud835\udc62 ) and item (E \ud835\udc4f \ud835\udc61,\ud835\udc56 ) representations, we construct a three-way tensor E\u0302\ud835\udc61,\ud835\udc62 \u2208 R | B |\u00d7 |V\ud835\udc62 |\u00d7\ud835\udc51 and E\u0302\ud835\udc61,\ud835\udc56 \u2208 R | B |\u00d7 |V\ud835\udc56 |\u00d7\ud835\udc51 to represent the multi-behavior short-term interest. We stack the type-specific user and item embeddings as follows:\nE\u0302\ud835\udc61,\ud835\udc62 = \ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc50\ud835\udc58 ( E1\ud835\udc61,\ud835\udc62 ,E 2 \ud835\udc61,\ud835\udc62 , ...,E | B | \ud835\udc61,\ud835\udc62 ) ; E\u0302\ud835\udc61,\ud835\udc56 = \ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc50\ud835\udc58 ( E1\ud835\udc61,\ud835\udc56 ,E 2 \ud835\udc61,\ud835\udc56 , ...,E | B | \ud835\udc61,\ud835\udc56 ) (7)\nwhere E\ud835\udc4f\ud835\udc61,\ud835\udc62 ,E \ud835\udc4f \ud835\udc61,\ud835\udc56 denote the behavior-specific representations of users and items, respectively. As such, we can associate each time slot \ud835\udc61 with a multi-behavior embedding tensor E\u0302\ud835\udc61,\ud835\udc62 and E\u0302\ud835\udc61,\ud835\udc56 for users and items, respectively.\n3.2.2 Time-Evolving Cross-Type Behavior Dependencies. In a dynamic multi-behavior scenario, different types of user behaviors are interdependent among time slots in a long-term perspective. For example, customers may view some products on online retail sites and make their purchase decisions one day later. To capture such evolving cross-type behavior dependencies across time slots, we develop a dynamic cross-relational memory network that explicitly learns the influence weights between time slot-specific behavior-aware representations.\nTowards this end, we design a self-attention-based memory network to model the embedding correlations (e.g., E(\ud835\udc61\u22121),\ud835\udc62\u2013E\ud835\udc61,\ud835\udc62 ) between adjacent time slots (\ud835\udc61 \u2212 1) and \ud835\udc61 . In particular, we take the embedding E\ud835\udc61,\ud835\udc62 as the input for query embeddings Q\ud835\udc61 , and E(\ud835\udc61\u22121),\ud835\udc62 as the inputs corresponding to the key and value embeddings K\ud835\udc61\u22121 and V\ud835\udc61\u22121. Our dynamic cross-relational memory encoder \ud835\udefe (\u00b7) is defined with the following scaled dot-product attention function over different time slot-specific behavior representations:\nZ\ud835\udc61,\ud835\udc61\u22121 = \ud835\udefe (E\u0302\ud835\udc61 \u00b7W\ud835\udc44\ud835\udc61 , E\u0302\ud835\udc61\u22121 \u00b7W \ud835\udc3e \ud835\udc61 , E\u0302\ud835\udc61\u22121); Q\ud835\udc61 = E\u0302\ud835\udc61 \u00b7W \ud835\udc44 \ud835\udc61 ; K\ud835\udc61\u22121 = E\u0302\ud835\udc61\u22121 \u00b7W \ud835\udc3e \ud835\udc61 (8)\nwhere Z\ud835\udc61,\ud835\udc61\u22121 represents the aggregated multi-behavior embeddings of current time slot \ud835\udc61 with the incorporation of cross-type behavior dependencies from the previous (\ud835\udc61 \u2212 1)-th time slot. W\ud835\udc44\ud835\udc61 \u2208 R\ud835\udc51\u00d7\ud835\udc51 , W\ud835\udc3e\ud835\udc61 \u2208 R\ud835\udc51\u00d7\ud835\udc51 represent the linear transformation matrices corresponding to the query and key dimension, respectively. The learned cross-type behavior dependency matrix \u03a6 \u2208 R | B |\u00d7 |B | which can be derived as \u03a6 = Q\ud835\udc61 \u00b7 K\ud835\udc47\ud835\udc61\u22121. Each entry \ud835\udf19\ud835\udc4f,\ud835\udc4f\u2032 \u2208 \u03a6 indicates the estimated correlation between time slot- and behavior-specific representations E\ud835\udc4f\ud835\udc61,\ud835\udc62 and E \ud835\udc4f\u2032 \ud835\udc61\u22121,\ud835\udc62 . Therefore, our dynamic cross-relational memory network \ud835\udefe (\u00b7) can be rewritten with the following form.\n\ud835\udefe (Q\ud835\udc61 ,K\ud835\udc61\u22121,V\ud835\udc61\u22121) = \ud835\udc60\ud835\udc5c \ud835\udc53 \ud835\udc61\ud835\udc5a\ud835\udc4e\ud835\udc65 ( Q\ud835\udc61 \u00b7 K\ud835\udc47\ud835\udc61\u22121\u221a\ufe01\n\ud835\udc51/\u210e\n) \u00b7 V\ud835\udc61\u22121 (9)\nThe scale \u221a\ufe01 \ud835\udc51/\u210e is introduced to produce a softer attention distribution for avoiding gradient vanishing [36], and \u210e represents the number of head representations. With the design of our dynamic cross-relational memory network, our RCL can preserve the dedicated time-evolving behavior dependencies across different types of user interactions. In our model implementation, we utilize the Broadcast Mechanism [35] to improve the computational efficiency of tensor multiplication. With the learned evolving cross-type behavior dependencies, we refine the time slot-specific user and item embeddings as: E\u0303\ud835\udc61,\ud835\udc62 = \ud835\udf07 (E\u0302\ud835\udc61,\ud835\udc62 +Z\ud835\udc61,\ud835\udc61\u22121,\ud835\udc62 ) and E\u0303\ud835\udc61,\ud835\udc56 = \ud835\udf07 (E\u0302\ud835\udc61,\ud835\udc56 \u2295 Z\ud835\udc61,\ud835\udc61\u22121,\ud835\udc56 ), where \ud835\udf07 (\u00b7) indicates mean pooling operation."
        },
        {
            "heading": "3.3 Multi-Relational Contrastive Learning",
            "text": "After encoding the heterogeneous user interest representations corresponding to the short-term (E\u0302\ud835\udc61,\ud835\udc62 , E\u0302\ud835\udc61,\ud835\udc56 ) and longterm (E\u0303\ud835\udc61,\ud835\udc62 , E\u0303\ud835\udc61,\ud835\udc56 ) perspectives, we propose to jointly capture the diverse multi-behavior dependencies and commonality in the multi-behavior sequential recommendation scenario.\n3.3.1 Heterogeneous Behavior Aggregation. We generate the multi-behavior representation (E\ud835\udc62 , E\ud835\udc56 ) by aggregating type-specific behavior representations with a gating mechanism, which is formally presented as follows. Without loss of generality, E\ud835\udc62 denotes the aggregated user representation for both short-term and long-term interests. Item embeddings E\ud835\udc56 can be derived in an analogous way.\n\ud835\udf14\ud835\udc4f\ud835\udc62 = \ud835\udc52\ud835\udc65\ud835\udc5d (E\ud835\udc4f\ud835\udc62 W\ud835\udc53 )\u2211 | B | \ud835\udc4f=1 \ud835\udc52\ud835\udc65\ud835\udc5d (E \ud835\udc4f \ud835\udc62W\ud835\udc53 ) ; E\ud835\udc62 = | B |\u2211\ufe01 \ud835\udc4f=1 \ud835\udf14\ud835\udc4f\ud835\udc62E \ud835\udc4f \ud835\udc62 (10)\nwhere W\ud835\udc53 \u2208 R\ud835\udc51 is the transformation matrix. \ud835\udf14\ud835\udc4f\ud835\udc62 represents the learned dependency weight of \ud835\udc4f-th type of user behaviors. By aggregating the type-specific behavior representations with the gating mechanism, the joint model can effectively preserve both the short-term and long-term multi-behavior preferences of users.\n3.3.2 Cross-Relational Contrastive Self-Supervision. In our RCL model, we aim to simultaneously capture the commonality of individual users\u2019 multi-behavior patterns and the diversity of different users\u2019 multi-behavior preferences. To achieve this, we design the cross-behavior contrastive learning module, which enhances the multi-behavior\ndependency modeling with augmented self-supervision signals. Specifically, we generate contrasting views using typespecific behavior semantics and the fused multi-behavior pattern. Motivated by the property of contrastive learning, we incorporate cross-behavior contrastive self-supervision signals as auxiliary regularization in our recommendation framework, to jointly capture the commonality of individual users and the diversity of different users with respect to their multi-behavior preferences. Our RCL performs behavior-level augmentation by pulling the type-specific behavior embedding (e\ud835\udc4f\n\ud835\udc56 \u2208 R\ud835\udc51\u00d71) and multi-behavior representation (e\ud835\udc56 \u2208 R\ud835\udc51\u00d71) of the same user \ud835\udc62 closer as positive pairs, and\npushing the behavior embeddings of different users away as negative pairs. Formally, our cross-relational contrastive objective is defined as:\nL\ud835\udc4f \ud835\udc50\ud835\udc59\n= \u2212 log \ud835\udc52\ud835\udc65\ud835\udc5d (\ud835\udc60 (e \ud835\udc4f \ud835\udc62 , e\ud835\udc62 )/\ud835\udf0f) \ud835\udc52\ud835\udc65\ud835\udc5d (\ud835\udc60 (e\ud835\udc4f\ud835\udc62 , e\ud835\udc62 )/\ud835\udf0f) + \u2211 \ud835\udc62\u2260\ud835\udc62\u2032 ( \ud835\udc52\ud835\udc65\ud835\udc5d (\ud835\udc60 (e\ud835\udc4f\ud835\udc62 , e\ud835\udc62\u2032 )/\ud835\udf0f) + \ud835\udc52\ud835\udc65\ud835\udc5d (\ud835\udc60 (e\ud835\udc4f\ud835\udc62 , e\ud835\udc4f\ud835\udc62\u2032 )/\ud835\udf0f) ) (11) where The temperature parameter \ud835\udf0f is used to control the effect of mutual information estimation [7]. We define the InfoNCE-based similarity function as \ud835\udc60 (e\ud835\udc4f\ud835\udc62 , e\ud835\udc62 ) = e\ud835\udc4f\ud835\udc62 \u00b7 e\ud835\udc62/\u2225e\ud835\udc4f\ud835\udc62 \u2225\u2225e\ud835\udc62 \u2225, which is measured by the dot product between \u21132 normalized e\ud835\udc4f\ud835\udc62 and e\ud835\udc62 ."
        },
        {
            "heading": "3.4 Model Inference Phase",
            "text": "We define our optimized objective with the Bayesian Personalized Ranking (BPR) loss as follows:\nL\ud835\udc35\ud835\udc43\ud835\udc45 = \u2211\ufe01\n(\ud835\udc62,\ud835\udc56+,\ud835\udc56\u2212 ) \u2208\ud835\udc42 \u2212 log(sigmoid(\ud835\udc52\ud835\udc62 \u00b7 \ud835\udc52\ud835\udc56+ \u2212 \ud835\udc52\ud835\udc62 \u00b7 \ud835\udc52\ud835\udc56\u2212 )) + \ud835\udf06 | |\u0398| |2 (12)\nThe pairwise training samples are\ud835\udc42 = (\ud835\udc62, \ud835\udc56+, \ud835\udc56\u2212) | (\ud835\udc62, \ud835\udc56+) \u2208 E+, (\ud835\udc62, \ud835\udc56\u2212) \u2208 E\u2212 , where E+ and E\u2212 denote the corresponding observed and unobserved interactions of user \ud835\udc62. The learnable hyperparameters are denoted by \u0398. To alleviate the overfitting, we apply \ud835\udc3f2 regularization in our BPR loss. Our joint optimization objective is given below by integrating\nthe BPR loss (L\ud835\udc35\ud835\udc43\ud835\udc45) with short-term (\u2211 \ud835\udc61\u039b | B |\u2211 \ud835\udc4f L\ud835\udc50\ud835\udc59\ud835\udc60\u210e\ud835\udc5c\ud835\udc5f\ud835\udc61 ) and long-term (\u2211\ud835\udc4f | B |L\ud835\udc59\ud835\udc5c\ud835\udc5b\ud835\udc54 \ud835\udc50\ud835\udc59 ) contrastive objectives:\nL = | B |\u2211\ufe01 \ud835\udc4f L\ud835\udc35\ud835\udc43\ud835\udc45 + \ud835\udefc \u2217 | B |\u2211\ufe01 \ud835\udc4f L\ud835\udc59\ud835\udc5c\ud835\udc5b\ud835\udc54 \ud835\udc50\ud835\udc59 + \ud835\udefd \u2217 \u039b\u2211\ufe01 \ud835\udc61 | B |\u2211\ufe01 \ud835\udc4f L\ud835\udc60\u210e\ud835\udc5c\ud835\udc5f\ud835\udc61 \ud835\udc50\ud835\udc59\n(13)\nwhere \u039b represents the number of time slots. \ud835\udefc and \ud835\udefd are regularization strengths of contrastive objectives. The detailed training process of RCL is elaborated in Algorithm 1."
        },
        {
            "heading": "3.5 In-Depth Discussions on RCL",
            "text": "In this section, we present an in-depth analysis of our multi-behavior contrastive learning paradigm. Specifically, we discuss the benefits brought by the augmented behavior-aware self-supervised learning tasks from two dimensions: i) Cross-behavior mutual information maximization; ii) User interest representation discrimination. Additionally, we conduct a complexity analysis to study the efficiency of our RCL framework.\n3.5.1 Cross-Relational Mutual Information Maximization. In our multi-relational contrastive learning framework, we propose to capture the commonality of individual users\u2019 multi-behavior patterns by maximizing the mutual information between the type-specific behavior embedding (e\ud835\udc4f\n\ud835\udc56 \u2208 R\ud835\udc51\u00d71) and the multi-behavior representation\n(e\ud835\udc56 \u2208 R\ud835\udc51\u00d71). In particular, we define our information maximization function as \ud835\udc3c (z\ud835\udc56 , z\ud835\udc5d ), where z\ud835\udc56 , z\ud835\udc5d represents the anchor and positive instance in the same hypersphere, respectively. Without loss of generality, the embedding z is formally defined as: z = e/\u2225 e \u2225. In our multi-relational contrasting scenario, the mutual information estimation is performed\nAlgorithm 1: The Learning Process of RCL Framework Input: Behavior-aware interaction sequence \ud835\udc46\ud835\udc62 = {(\ud835\udc561, \ud835\udc4f1), (\ud835\udc562, \ud835\udc4f2), ..., (\ud835\udc56 |\ud835\udc46\ud835\udc62 | , \ud835\udc4f |\ud835\udc46\ud835\udc62 | )}. Short-term multi-behavior\ngraph G\ud835\udc4f\ud835\udc61 = (V\ud835\udc4f\ud835\udc61 , E\ud835\udc4f\ud835\udc61 ,M\ud835\udc4f\ud835\udc61 ). Output: Aggregated user/item representations E\ud835\udc56 , E\ud835\udc62 . The probability of the most likely next item \ud835\udc56 |\ud835\udc46\ud835\udc62 |+1.\n1 Initialize: Xavier initialized behavior-specific short term item embeddings E\ud835\udc4f,0 \ud835\udc61,\ud835\udc56 . Parameters: i) Short-term\nmulti-behavior graph encoder {W\ud835\udc4f,(\ud835\udc59 ) \ud835\udc61,\ud835\udc56 ,W\ud835\udc4f\ud835\udc61,\ud835\udc62 ,W \ud835\udc4f \ud835\udf01 ,W\ud835\udc4f\ud835\udc61,\ud835\udc50\ud835\udc4e\ud835\udc61 }. ii)Dynamic cross-relational memory network\n{W\ud835\udc44\ud835\udc61 ,W\ud835\udc3e\ud835\udc61 }. iii) Behavior fusion transformation {W\ud835\udc53 }. 2 for \ud835\udc52\ud835\udc5d\ud835\udc5c\ud835\udc50\u210e \u2190 0, 1, ... do 3 Update learning rate scheduler.\nfor \ud835\udc60\ud835\udc61\ud835\udc52\ud835\udc5d \u2190 0, 1, ... do // Short-Term Multi-Behavior Graph:\n4 for \ud835\udc61 \u2190 0, 1, ...,\u039b do 5 Get short term embeddings: E\ud835\udc4f\ud835\udc61,\ud835\udc62 ,E \ud835\udc4f \ud835\udc61,\ud835\udc56 \u2190\u2212 G\ud835\udc4f\ud835\udc61 , Eq.1, Eq.3, Eq.5, Eq.6 6 Prepare behavior aggregated embeddings for L\ud835\udc60\u210e\ud835\udc5c\ud835\udc5f\ud835\udc61 \ud835\udc50\ud835\udc59\n: E\ud835\udc61,\ud835\udc62 \u2190\u2212 Eq.10 7 end\n// Dynamic Cross-Relational Memory:\n8 for \ud835\udc61 \u2190 1, ...,\u039b do 9 Modeling time-evolving cross-type dependencies: E\u0303\ud835\udc4f\ud835\udc61,\ud835\udc62 , E\u0303 \ud835\udc4f \ud835\udc61,\ud835\udc56 \u2190\u2212 Eq.7, Eq.8, Eq.9\n10 Aggregate E\u0303\ud835\udc4f\ud835\udc61,\ud835\udc62 , E\u0303 \ud835\udc4f \ud835\udc61,\ud835\udc56 convey across \ud835\udc61 and \ud835\udc4f for L \ud835\udc59\ud835\udc5c\ud835\udc5b\ud835\udc54 \ud835\udc50\ud835\udc59 , L\ud835\udc35\ud835\udc43\ud835\udc45 : E\ud835\udc62 ,E\ud835\udc56 \u2190\u2212 Eq.10"
        },
        {
            "heading": "11 end",
            "text": "// Cross-Behavior Contrastive Task & Recommendation Task: 12 Get final multi-task objective L \u2190\u2212 L\ud835\udc4f \ud835\udc50\ud835\udc59 \u2190 Eq.11 + L\ud835\udc35\ud835\udc43\ud835\udc45 \u2190 Eq.12 13 Gradient descent backpropagation. 14 end 15 end\nbetween the fused representation E\ud835\udc62 and behavior-specific embedding in {E1\ud835\udc62 ,E2\ud835\udc62 , ...,E\ud835\udc4f\ud835\udc62 }. These contrastive-based self-supervision signals are integrated into the BPR loss function to enhance the robustness of the user representation paradigm.\nMotivated by the research in [2, 15, 32, 34], we formulate our augmented contrastive loss as a lower bound of the information maximization function \ud835\udc3c (\u00b7), which is defined as:\n\ud835\udc3c (z\ud835\udc56 , z\ud835\udc5d ) \u2265 \ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc58) \u2212 L\ud835\udc50\ud835\udc59 (14)\n\ud835\udc58 is the number of negative samples. The inequality suggests that a smaller value of L\ud835\udc50\ud835\udc59 results in a larger value of \ud835\udc3c (\u00b7). In other words, minimizing L\ud835\udc50\ud835\udc59 is equivalent to maximizing the lower bound of mutual information in \ud835\udc3c (\u00b7).\nThe above situation can be extended to the multi-behavior modeling process. In addition to the equivalence between the contrastive objective and lower bound of information maximization, the self-supervised L\ud835\udc50\ud835\udc59 is closely related to the function \ud835\udc3c (\u00b7). This provides a theoretical basis for our multi-behavior recommender system, as follows:\n\u210e\u2217 \ud835\udf03 (z\ud835\udc56 , z\ud835\udc5d ) \u221d \ud835\udc5d (z\ud835\udc56 , z\ud835\udc5d ) \ud835\udc5d (z\ud835\udc56 )\ud835\udc5d (z\ud835\udc5d ) \u221d \ud835\udc5d (z\ud835\udc56 |z\ud835\udc5d ) \ud835\udc5d (z\ud835\udc56 )\n(15)\nThe optimal point \u210e\u2217 of \u210e\ud835\udf03 = exp(\ud835\udc60 (e\ud835\udc4f\ud835\udc62 , e\ud835\udc62 )/\ud835\udf0f) is proportional to the density ratio between the joint distribution \ud835\udc5d (z\ud835\udc56 , z\ud835\udc5d ) and the product of marginals \ud835\udc5d (z\ud835\udc56 )\ud835\udc5d (z\ud835\udc5d ). This quantity is the point-wise mutual information, and the extended multi-behavior form can be implemented by optimizing the sum of a set of pairwise objectives [32].\n3.5.2 User Interest Representation Discrimination. Our developed contrastive paradigm not only captures the commonality among multiple behaviors but also enhances the diversity between individual nodes to mitigate oversmoothing [22, 54]. During backpropagation, the gradient of the loss function L\ud835\udc50\ud835\udc59 with respect to the parameters of RCL is computed and used to update the parameters, causing negative samples to move away from the anchor node e\ud835\udc62 in the parameter space. The following proportional relationship quantitatively illustrates how negative samples are pushed away from the anchor point as the similarity between samples increases:\n\ud835\udc50 (\ud835\udc65) \u221d \u221a\ufe01 1 \u2212 (\ud835\udc65)2 \u00b7 exp (\ud835\udc65/\ud835\udf0f) (16)\nwhere node similarity score \ud835\udc65 is computed using the normalized embeddings of the anchor node and negative sample. This score serves as the input to the function \ud835\udc50 (\u00b7). As the similarity \ud835\udc65 increases, negative samples will have a greater gradient \ud835\udc50 (\ud835\udc65). The temperature coefficient \ud835\udf0f of the softmax function can adjust the gradient of hard negative samples. The similarity between each node and other nodes can be adjusted by the hyperparameter \ud835\udf0f . As a result of the above analysis, we can conclude that multi-behavior contrastive learning can improve the discriminability of representations, thereby resolving the over-smoothing issue. A detailed discussion can be found in Appendix 7.1.\n3.5.3 Model Complexity Analysis. The main time consumption in our RCL framework are from several key components: i) Short-term multi-relational graph encoder: the computational cost of our graph neural architecture for item representation is \ud835\udc42 ( |B| \u00d7 \u039b \u00d7 \ud835\udc3f \u00d7 |E\ud835\udc4f\n\ud835\udc61,\ud835\udc40\ud835\udc47\ud835\udc40 | \u00d7 \ud835\udc51) for performing message passing across graph layers. Then\nfor user, it is \ud835\udc42 ( |B| \u00d7 \u039b \u00d7 |E\ud835\udc4f \ud835\udc61,\ud835\udc40 | \u00d7 \ud835\udc51). |E\ud835\udc4f \ud835\udc61,\ud835\udc40\ud835\udc47\ud835\udc40 |, |E\ud835\udc4f \ud835\udc61,\ud835\udc40 | respectively represents the number of non-zero elements in the incidence matrix \u0393(M\ud835\udc4f\ud835\udc61 \ud835\udc47 ) and \u0393(M\ud835\udc4f\ud835\udc61\n\ud835\udc47M\ud835\udc4f\ud835\udc61 ), under the behavior type of \ud835\udc4f during the time slot \ud835\udc61 . Here, \ud835\udc3f denotes the number of graph propagation layers of item. The operations of concatenation and linear transformations for layer aggregation take \ud835\udc42 ( |B| \u00d7 \u039b \u00d7 \ud835\udc3f \u00d7 |V\ud835\udc4f\n\ud835\udc56 | \u00d7 \ud835\udc51). ii) Dynamic cross-relational memory network: The most computational\ncost for the cross-relational memory component comes from the self-attention operation with the time complexity of \ud835\udc42 (\u039b \u00d7 |V\ud835\udc4f | \u00d7 |B|2 \u00d7 \ud835\udc51) quadratic with the behavior number |B|. iii) Multi-behavior contrastive learning: The cost of InfoNCE-based mutual information calculation is \ud835\udc42 (\ud835\udc51) and \ud835\udc42 (\ud835\udc4f\ud835\udc4e\ud835\udc61\ud835\udc50\u210e \u00d7 \ud835\udc51) for the numerator and denominator (in Eq.11 ), respectively. Thus, our multi-relational contrastive learning paradigm takes \ud835\udc42 (\u039b \u00d7 |B| \u00d7 |E\ud835\udc4f | \u00d7 \ud835\udc51) per epoch."
        },
        {
            "heading": "4 EVALUATION",
            "text": ""
        },
        {
            "heading": "4.1 Experimental Setup",
            "text": "Datasets. We perform model evaluations on three real-world datasets, and their statistics are shown in Table 1. i) Taobao collects four types of user behaviors from Taobao\u2019s recommender system. ii) IJCAI is an online retailing dataset released by IJCAI competition with four types of user online activities. iii) E-Commerce contains browse, review, and\npurchase behaviors of users in a real-life online retailer. Following the same settings in [17, 48], our multi-behavior sequential recommender regards purchase as the target behavior and the other types of behaviors as auxiliary behaviors. Evaluation Protocols. In our evaluation, we adopt two representative metrics, Hit Ratio (HR@N) and Normalized Discounted Cumulative Gain (NDCG@N) (\ud835\udc41 = 10 by default), to measure the recommendation accuracy. Following existing sequential recommender systems [30], we utilize the last interaction of each user as the positive sample for performance evaluation. Additionally, for each user, the last interacted item under the target behavior type is considered as the positive sample in the test set, and 99 non-interacted items are randomly sampled as negative instances. Baselines. We compare our RCL with various types of state-of-the-art recommendation methods.\n\u2022 (i) CNN/Attention-based Sequential Recommendation Approaches: Caser [31] uses the convolutional filters to encode local item dependencies of user sequences. SASRec [18], TiSASRec [20], AttRec [53] are built on selfattentionmechanism to capture correlations between temporally-ordered items.Bert4Rec [30] trains the bidirectional Transformer model with the cloze task for learning sequential patterns of user behaviors.\n\u2022 (ii) Hybrid Sequential Recommender Systems:HGN [26] is a hierarchical gating network that learns the item feature relevance for dynamic preference learning in recommendation. Chorus [39] considers both knowledge-aware item relations and temporal context in sequential recommendation.\n\u2022 (iii) GNN-based Sequential Recommendation Models: SR-GNN [46] introduces graph neural networks to model sequential behavior patterns over short item sequences.MA-GNN [27] leverages GNNs to encode both short-term and long-term item dependencies. Furthermore, HyperRec [41] proposes to capture dynamic triadic item relationships using the hypergraph structures. COTREC [49] and DHCN [50] are two state-of-the-art sequential recommender systems based on self-supervised learning paradigms.\n\u2022 (iv) Multi-Behavior Recommender Systems: NMTR [8] and DIPN [10] formalize the multi-behavior recommendation task with multi-task learning frameworks. MBGCN [16], KHGT [47] and MBGMN [48] design multi-behavior graph message passing schemes to model heterogeneous user-item interactions. EHCF [5] and CML [43] generate additional supervision signals from auxiliary behaviors to boost the recommendation performance.\nHyperparameter Settings and Implementation Details. We implement our model in PyTorch and adopted the Xavier initializer [9] for parameter initialization. The Cyclical Learning Rate strategy [29] was used during the model training phase with the AdamW [25] optimizer. For fair comparison, the number of graph layers in all GNN-based models was selected from the range 1,2,3,4 to achieve the best performance. The temperature coefficient \ud835\udf0f was tuned\nfrom 0.02, 0.035, 0.05, 0.07, 0.1, 0.3, 0.5, 0.7 in our multi-relational contrastive learning component. We further studied the influence of key hyperparameters in our model and reported the results in the Appendix."
        },
        {
            "heading": "4.2 Recommendation Performance",
            "text": "We report the performance comparison results in Table 2 and summarize the findings: (1) RCL outperforms various baselines in all cases by achieving significant performance improvements. The \u201cimprv\u201d column indicates the relative performance improvement between RCL and the best-performing baseline CML. Through the encoding of evolving dependencies across different types of behaviors, RCL is able to simultaneously capture the dynamics of users\u2019 shortterm and long-term interests by distilling the underlying heterogeneous interaction patterns. (2) RCL outperforms the compared sequential recommender systems by a large margin, which indicates that the incorporation of multi-behavior context is beneficial for disentangling the behavior heterogeneity of users. (3) Conducting dynamic contrastive learning with cross-behavior dependencies, RCL learns better multi-behavior representations compared with state-of-the-art multi-behavior recommendation approaches by preserving both the behavior commonality and diversity of users. (4) The consistent performance improvements of our method on datasets with different sparsity degrees benefit from the incorporation of effective self-supervision signals generated by our contrastive learning paradigm."
        },
        {
            "heading": "4.3 Ablation Study",
            "text": "To validate the effectiveness of our proposed methodology, we conduct an ablation study from two perspectives: i) We examine whether the proposed technical modules contribute positively to the final performance. ii) we investigate whether the auxiliary user behavior data leads to performance improvements in our model.\n4.3.1 Ablation Study on Proposed Modules. We evaluate the efficacy of key components in RCL with different variants: (1) w/o-JBL: Instead of performing joint learning with multi-typed behavior supervision labels, we directly incorporate auxiliary behavior data as contextual features for user representation. (2) w/o-CL: We further disable our multi-relational contrastive learning component to capture the behavior commonality and diversity. (3) r/w-GRU : We replace our dynamic cross-relational memory network with gated recurrent unit (GRU) to encode behavior-specific embedding sequences. (4) w/o-MBG: On the basis of w/o-CL, we remove the behavior-aware graph neural encoder, to model the high-order connectivity over the multi-behavior user-item interaction graph within a specific time slot.\nThe evaluation results shown in Table 3 demonstrate that our multi-relational learning with augmented short- and long-term contrastive objectives improves the generalization of recommender systems. Additionally, our cross-relational memory network is more effective than GRU in encoding long-term multi-behavior user interests. Furthermore, the multi-relational graph encoder has a positive effect on learning short-term heterogeneous user preferences compared with direct aggregation over ID-corresponding embeddings for collaborative modeling.\n4.3.2 Ablation Study on Relation Multiplicity. We compare the performance of our RCL model when utilizing only a portion of the multiplex behavior data, as opposed to using all user behaviors. Results of this evaluation can be found in Table 4. For each dataset, we remove each auxiliary behavior type such as views, favorites and cart behavior\nE-commerce \ud835\udc64/\ud835\udc5c-Browse \ud835\udc64/\ud835\udc5c-Review - Purchase RCL0.711 0.441 0.732 0.446 - - 0.677 0.411 0.763 0.470 from the data before training and evaluating the performance of RCL on the remaining dataset. We also remove all auxiliary behavior categories and only keep the target behavior type (Purchase). Our observations are as follows: First and foremost, auxiliary data is crucial. When utilizing only purchase data, the model performance is significantly worse than when auxiliary data is also included. This clearly highlights the benefits of including auxiliary user behavior data in recommendation models. Secondly, the importance of viewing and browsing data cannot be understated. As the auxiliary behavior with the largest amount, view and browse data are found to be the major contributors to performance improvements in our multi-behavior RCL model. This underlines how auxiliary behavior data enhances the model through increased feature data and supervision signals. Finally, we found that favorite, cart, and review behaviors also have important contributions to model performance. Although the amount of these behavior records may be similar to purchase data, it is clear that they hold valuable user preference information."
        },
        {
            "heading": "4.4 Alleviating the Data Sparsity Issue",
            "text": "Our above theoretical discussion analyzes the benefits of our multi-relational contrastive learning paradigm in capturing the multi-behavior commonality and diversity. To be specific, the mutual information maximization between positive samples is helpful to preserve the common characteristics among different types of behaviors. Additionally, contrastive learning with negative samples can push the hard negative samples away to get distinguishable user embedding, so as to encode the behavior diversity of different users and alleviate the over-smoothing problem of our graph neural model.\nTherefore, contrastive learning can improve the quality of representation and alleviate the problem caused by the scarcity of data. To this end, we select users whose interaction number on the IJCAI dataset in {<5, <15, <35, <60} for training and testing. In order to eliminate the influence of training data and simulate a real sparse data scenario, we carry out the evaluation of our model under the setting of\ud835\udc64/\ud835\udc5c-JBL, and compare it with two best-performed baselines (HyperRec and KHGT) from the lines of sequence-based models and multi-behavior recommender systems, respectively.\nAs shown in Table 5, it can be observed that under different sparsity degrees of user interaction data,\ud835\udc64/\ud835\udc5c-JBL with contrastive learning task will get better results than\ud835\udc64/\ud835\udc5c-CL. Moreover, the performance gap between our contrastive learning method and other baselines becomes larger with the higher sparsity degrees of interaction data, which again justifies the effectiveness of our RCL in addressing the data scarcity for recommender system."
        },
        {
            "heading": "4.5 Hyperparameter Sensitivity Analysis",
            "text": "Short-Term Time Granularity. To construct the short-term multi-behavior graphs, we tune the parameter of the time granularity from different time ranges due to the time span of different experimental datasets. In particular, we\nselect the time granularity of Tmall, IJCAI, and E-commerce dataset from {1, 3, 5, 9} days, {1, 3, 6, 12} months, and 1, 2, 4, 12 weeks, respectively. From the evaluation results shown in Figure 2, we observe that shorter time periods (i.e., higher time granularity) can lead to overfitting in modeling short-term behavior-aware user preferences. Hidden Representation Dimensionality. We conduct a parameter sensitivity analysis to investigate the impact of hidden dimensionality on our model\u2019s representation performance. Specifically, we vary the embedding size from a range of {8, 16, 32, 64}. Our results demonstrate that the performance on Tmall and IJCAI datasets improves significantly with an increase in the embedding size. This is due to the stronger representation power of larger embeddings. # of Graph Propagation Layers. In order to capture short-term multi-behavior user interests, we have designed a behavior-aware message-passing scheme that refines user/item embeddings by injecting multi-typed behavior context. To explore the effect of model depth, we have selected the number of GNN layers from a range of {1, 2, 3, 4}. Our observations indicate that deeper graph models may be beneficial for modeling the high-order collaborative effects on Tmall and E-commerce datasets. However, we also found that stacking more embedding propagation layers can introduce noise in representation refinement on the E-commerce dataset."
        },
        {
            "heading": "4.6 In-Depth Investigation of RCL Model",
            "text": "Our RCL model is further evaluated from three perspectives. i) In Figure 3 (a)-(d), we visualize the encoded behaviorspecific user embeddings of our RCL and compare themwith the variant w/o-CL (without the multi-relational contrastive learning). The results demonstrate that our cross-behavior data augmentation scheme is effective in preserving users\u2019 multi-behavior commonality while better differentiating diverse user preferences. ii) We observe in Figure 3 (e) that a smaller value of temperature value \ud835\udf0f can lead to larger gradients, which can help identify hard negatives and enhance the model\u2019s discrimination ability in learning personalized user interests. However, too small a temperature coefficient can result in gradient explosion, as shown in the purple part. iii) In Figure 3 (f), we visualize the learned cross-behavior dependencies between time slots using 4 \u00d7 4 weight matrices \u03a6 in Eq.8 for 400 sampled users on the Taobao dataset, and highlight six of them on the right side in Figure3 (f). We observe that most matrices have the darkest diagonal color, which is the characteristic of self-attention. The right part shows that the weight is related to the number of interactions of the behavior. For example, user 22186-[3] the super node has 111 interactions in the page view behavior. However, the interactions in other behaviors are relatively too few (i.e., {1, 5, 4}) to learn differentiated values."
        },
        {
            "heading": "5 RELATEDWORK",
            "text": "Sequential Recommendation. Recent years have witnessed numerous efforts to leverage neural networks for modeling behavior dynamics in recommendation. RNN-based methods like GRU4Rec [14] and CNN-based approaches like Caser [31] have been proposed to capture the complex temporal dynamics in user-item interactions. Moreover, several self-attention models, such as SASRec [18], BERT4Rec [30], and TiSASRec [20], have been developed to estimate item correlations and capture long-range dependencies. Inspired by the power of GNNs, recent recommendation systems have applied graph-based message passing schemes to encode multi-order dependencies. Examples include\nMA-GNN [27], SURGE [3], and GCE-GNN [42]. Furthermore, self-supervised learning has been used in recent sequential recommendation methods to augment the data, such as COTREC [49], DHCN [49]. However, most existing methods focus on modeling a single type of interaction and ignore the heterogeneous user preferences. Multi-Behavior Recommender System. Multi-behavior recommendation has been demonstrated to greatly improve recommendation performance [4]. For instance, NMTR [8] and DPT [52] differentiate behavior semantics using multitask learning schemes. To capture the diverse relationships between users and items, recent studies such as MBGCN [16], MBGMN [48], and KMCLR [51] have leveraged GNNs to encode multi-behavior patterns. Contrastive Representation Learning. Contrastive learning has emerged as a popular technique for data augmentation with auxiliary self-supervised signals [6, 23, 28, 44]. In the domain of image analysis, numerous contrastive learning methods have been proposed for modeling image data with different augmentation techniques [1, 33, 38], such as cropping, horizontal translations, and rotations. Cross-view contrastive learning has also been developed to achieve state-of-the-art graph representation performance using various augmentation operators, such as node shuffles in DGI [37], centrality-aware edge dropout in GCA [55], and subgraph sampling in MVGLR [11]."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "This work proposes a model called RCL that captures the heterogeneity of each user\u2019s interactions at both the shortterm and long-term interest levels. To better model the multi-behavior preferences of individual users and improve the distinction of behavior-aware preferences of different users, we introduce a multi-relational contrastive learning paradigm. Our experiments on three real-world datasets demonstrate that RCL significantly outperforms various baselines in terms of recommendation performance. In the future, we plan to extend RCL to adapt to cross-domain recommendation and tackle the cold-start problem by exploring LLMs for knowledge augmentation. This will enable us to leverage external knowledge sources to enhance the model\u2019s ability to make accurate recommendations."
        },
        {
            "heading": "7 APPENDIX",
            "text": ""
        },
        {
            "heading": "7.1 Detailed Discussion on User Interest Representation Discrimination",
            "text": "Contrastive loss is a hardness-aware loss function [40, 45] that can effectively push hard negative samples away from the anchor by giving them greater gradients under the contrastive training framework. This property is particularly beneficial for our multi-behavior graph neural architecture. One of the key challenges in existing GNN architectures is how to strike a balance between high-order connectivity modeling and the over-smoothing issue [21]. Stacking more graphbased information propagation layers can increase the risk of over-smoothing and undermine the ability of the model to encode collaborative effects. Therefore, enhancing the discrimination ability of the user interest representation paradigm is necessary for recommender systems. To address this challenge, our multi-behavior contrastive learning framework assigns larger gradients to hard negative samples, thereby enhancing the discrimination of user representations.\nEmbedding Normalization. To map embeddings with arbitrary value distributions into the same hyperspace, we perform embedding normalization as z\ud835\udc56 = e\ud835\udc56/\u2225 e\ud835\udc56 \u2225, where e\ud835\udc56 denotes the output prior to normalization. The gradient of the loss with respect to e\ud835\udc56 is related to that with respect to z\ud835\udc56 via the chain rule, which is presented as follows:\n\ud835\udf15L\ud835\udc56 (z\ud835\udc56 ) \ud835\udf15e\ud835\udc56 = \ud835\udf15L\ud835\udc56 (z\ud835\udc56 ) \ud835\udf15z\ud835\udc56 \ud835\udf15z\ud835\udc56 \ud835\udf15e\ud835\udc56\n(17)\n\ud835\udf15z\ud835\udc56 \ud835\udf15e\ud835\udc56 = \ud835\udf15 \ud835\udf15e\ud835\udc56 ( e\ud835\udc56 \u2225 e\ud835\udc56 \u2225 ) = 1 \u2225 e\ud835\udc56 \u2225 \ud835\udc3c \u2212 e\ud835\udc56 ( \ud835\udf15(1/\u2225 e\ud835\udc56 \u2225) \ud835\udf15e\ud835\udc56 )\ud835\udc47 =\n1 \u2225 e\ud835\udc56 \u2225\n( \ud835\udc3c \u2212\ne\ud835\udc56e\ud835\udc47\ud835\udc56 \u2225 e\ud835\udc56 \u22252\n) =\n1 \u2225 e\ud835\udc56 \u2225\n( \ud835\udc3c \u2212 z\ud835\udc56z\ud835\udc47\ud835\udc56 ) (18) Gradients of Negative Pairs.We use the loss function L\ud835\udc56 to calculate the partial derivative of the anchor point\nand analyze the influence of different samples on the gradients:\n\ud835\udf15\ud835\udc3f\ud835\udc56 \ud835\udf15z\ud835\udc56 = \ud835\udf15 \ud835\udf15z\ud835\udc56\n( \u2212\ud835\udc59\ud835\udc5c\ud835\udc54 exp (z\ud835\udc56 \u00b7 z\ud835\udc43/\ud835\udf0f)\u2211\nV\ud835\udc34 exp (z\ud835\udc56 \u00b7 z\ud835\udc34/\ud835\udf0f)\n) = \u22121\n\ud835\udf0f \u00b7 z\ud835\udc43 + 1 \ud835\udf0f \u2211 V\ud835\udc34 z\ud835\udc34 \u00b7 exp (z\ud835\udc56 \u00b7 z\ud835\udc34/\ud835\udf0f)\u2211 V\ud835\udc34 exp (z\ud835\udc56 \u00b7 z\ud835\udc34/\ud835\udf0f)\n= 1 \ud835\udf0f (\u2211 V\ud835\udc41 z\ud835\udc41 \u00b7 exp (z\ud835\udc56 \u00b7 z\ud835\udc41 /\ud835\udf0f)\u2211 V\ud835\udc34 exp (z\ud835\udc56 \u00b7 z\ud835\udc34/\ud835\udf0f) + z\ud835\udc43 \u00b7 ( exp (z\ud835\udc56 \u00b7 z\ud835\udc43/\ud835\udf0f) \u2212 \u2211 V\ud835\udc34 exp (z\ud835\udc56 \u00b7 z\ud835\udc34/\ud835\udf0f) )\u2211 V\ud835\udc34 exp (z\ud835\udc56 \u00b7 z\ud835\udc34/\ud835\udf0f) ) (19) The two terms in the formula represent the gradient contributions of positive and negative samples, respectively. Here, z\ud835\udc41 represents an instance from the set of negative samples, while z\ud835\udc43 and z\ud835\udc34 are from the positive sample set and the entire set, respectively. We will focus on the negative part, which can be expressed as:\n1 \ud835\udf0f \u00b7 \u2211 V\ud835\udc41 z\ud835\udc41 \u00b7 exp (z\ud835\udc56 \u00b7 z\ud835\udc41 /\ud835\udf0f)\u2211 V\ud835\udc34 exp (z\ud835\udc56 \u00b7 z\ud835\udc34/\ud835\udf0f) = 1 \ud835\udf0f \u00b7 \u2225 e\ud835\udc56 \u2225 \u00b7 \u2211 V\ud835\udc41 (z\ud835\udc41 \u2212 (z\ud835\udc56 \u00b7 z\ud835\udc41 ) \u00b7 z\ud835\udc56 ) \u00b7 exp (z\ud835\udc56 \u00b7 z\ud835\udc41 /\ud835\udf0f)\u2211 V\ud835\udc34 exp (z\ud835\udc56 \u00b7 z\ud835\udc34/\ud835\udf0f) (20)\nTemperature and Gradient. The proportional term of the norm of the gradient of each term in the sum formula is:\n\u2225z\ud835\udc41 \u2212 (z\ud835\udc56 \u00b7 z\ud835\udc41 ) \u00b7 z\ud835\udc56 \u2225 exp (z\ud835\udc56 \u00b7 z\ud835\udc41 /\ud835\udf0f)\u2211V\ud835\udc34 exp (z\ud835\udc56 \u00b7 z\ud835\udc34/\ud835\udf0f)\n\u221d \u221a\ufe01 1 \u2212 (z\ud835\udc56 \u00b7 z\ud835\udc41 )2 \u00b7 exp (z\ud835\udc56 \u00b7 z\ud835\udc41 /\ud835\udf0f)\n(21)\nSince both z\ud835\udc56 and z\ud835\udc41 are unit vectors, we introduce another variable \ud835\udc65 with the definition \ud835\udc65 = z\ud835\udc56 \u00b7 z\ud835\udc41 \u2208 [\u22121, 1] to simplify the expression in Eq. 21:\n\ud835\udc50 (\ud835\udc65) \u221d \u221a\ufe01 1 \u2212 (\ud835\udc65)2 \u00b7 exp (\ud835\udc65/\ud835\udf0f) (22)\n\ud835\udc50 (\ud835\udc65) is the relationship function that determines the gradient contribution of negative samples. We illustrate the function in Eq. 22 in Figure 4, where the independent variable is the similarity \ud835\udc65 and the dependent variable is proportional to the negative sample gradient. As \ud835\udc65 increases, the gradient of negative samples also increases. Decreasing the temperature coefficient \ud835\udf0f leads to a significant increase in the gradient of negative samples obtained via contrastive learning.\nIn our recommended scenario, hard negative samples z\ud835\udc41 \u2212 \u210e\ud835\udc4e\ud835\udc5f\ud835\udc51 represent users other than the anchor user. If z\ud835\udc41 \u2212 \u210e\ud835\udc4e\ud835\udc5f\ud835\udc51 is very close to the anchor point z\ud835\udc56 , the value of \ud835\udc65 for the hard negative samples approaches 1, which results in more indistinguishable user representations. The contrastive loss gives a larger gradient, and as relative negative samples, the pairs will be pushed farther away from each other. In this way, RCL enhances the user representations with multi-behavior diversity. Therefore, the experiments in Sec. 4.6 show that as the temperature \ud835\udf0f decreases, the user representations become more distinguishable and yield better performance. However, excessively small values of \ud835\udf0f can cause gradient explosion. Therefore, the temperature should be within a proper range to achieve the best performance."
        },
        {
            "heading": "7.2 Dimensional Transformation of the Memory Module",
            "text": ""
        }
    ],
    "title": "Multi-Relational Contrastive Learning for Recommendation",
    "year": 2023
}