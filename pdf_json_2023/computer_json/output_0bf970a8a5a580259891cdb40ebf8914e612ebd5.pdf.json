{
    "abstractText": "Distribution estimation has been demonstrated as one of the most effective approaches in dealing with few-shot image classification, as the low-level patterns and underlying representations can be easily transferred across different tasks in computer vision domain. However, directly applying this approach to few-shot text classification is challenging, since leveraging the statistics of known classes with sufficient samples to calibrate the distributions of novel classes may cause negative effects due to serious category difference in text domain. To alleviate this issue, we propose two simple yet effective strategies to estimate the distributions of the novel classes by utilizing unlabeled query samples, thus avoiding the potential negative transfer issue. Specifically, we first assume a class or sample follows the Gaussian distribution, and use the original support set and the nearest few query samples to estimate the corresponding mean and covariance. Then, we augment the labeled samples by sampling from the estimated distribution, which can provide sufficient supervision for training the classification model. Extensive experiments on eight few-shot text classification datasets show that the proposed method outperforms state-of-the-art baselines significantly.",
    "authors": [
        {
            "affiliations": [],
            "name": "Han Liu"
        },
        {
            "affiliations": [],
            "name": "Feng Zhang"
        },
        {
            "affiliations": [],
            "name": "Xiaotong Zhang"
        },
        {
            "affiliations": [],
            "name": "Siyang Zhao"
        },
        {
            "affiliations": [],
            "name": "Fenglong Ma"
        },
        {
            "affiliations": [],
            "name": "Xiao-Ming Wu"
        },
        {
            "affiliations": [],
            "name": "Hongyang Chen"
        },
        {
            "affiliations": [],
            "name": "Hong Yu"
        },
        {
            "affiliations": [],
            "name": "Xianchao Zhang"
        }
    ],
    "id": "SP:7cba0c4431f20df296e1b827b751fa23b3c2c9e5",
    "references": [
        {
            "authors": [
                "Y. Bao",
                "M. Wu",
                "S. Chang",
                "R. Barzilay"
            ],
            "title": "Few-shot Text Classification with Distributional Signatures",
            "venue": "ICLR.",
            "year": 2020
        },
        {
            "authors": [
                "L. Bozarth",
                "C. Budak"
            ],
            "title": "Toward a Better Performance Evaluation Framework for Fake News Classification",
            "venue": "ICWSM, 60\u201371.",
            "year": 2020
        },
        {
            "authors": [
                "I. Casanueva",
                "T. Tem\u010dinas",
                "D. Gerz",
                "M. Henderson",
                "I. Vuli\u0107"
            ],
            "title": "Efficient Intent Detection with Dual Sentence Encoders",
            "venue": "Workshop on Natural Language Processing for Conversational AI, 38\u201345.",
            "year": 2020
        },
        {
            "authors": [
                "J. Chen",
                "R. Zhang",
                "Y. Mao",
                "J. Xu"
            ],
            "title": "ContrastNet: A Contrastive Learning Framework for Few-Shot Text Classification",
            "venue": "AAAI, 10492\u201310500.",
            "year": 2022
        },
        {
            "authors": [
                "A. Coucke",
                "A. Saade",
                "A. Ball",
                "T. Bluche",
                "A. Caulier",
                "D. Leroy",
                "C. Doumouro",
                "T. Gisselbrecht",
                "F. Caltagirone",
                "T. Lavril",
                "M. Primet",
                "J. Dureau"
            ],
            "title": "Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces",
            "venue": "CoRR.",
            "year": 2018
        },
        {
            "authors": [
                "J. Deng",
                "W. Dong",
                "R. Socher",
                "L. Li",
                "K. Li",
                "L. Fei-Fei"
            ],
            "title": "ImageNet: A large-scale hierarchical image database",
            "venue": "CVPR, 248\u2013255.",
            "year": 2009
        },
        {
            "authors": [
                "J. Devlin",
                "M. Chang",
                "K. Lee",
                "K. Toutanova"
            ],
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "venue": "NAACL-HLT, 4171\u20134186.",
            "year": 2019
        },
        {
            "authors": [
                "T. Dopierre",
                "C. Gravier",
                "W. Logerais"
            ],
            "title": "ProtAugment: Intent Detection Meta-Learning through Unsupervised Diverse Paraphrasing",
            "venue": "ACL, 2454\u20132466.",
            "year": 2021
        },
        {
            "authors": [
                "C. Finn",
                "P. Abbeel",
                "S. Levine"
            ],
            "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
            "venue": "Precup, D.; and Teh, Y. W., eds., ICML, 1126\u20131135.",
            "year": 2017
        },
        {
            "authors": [
                "T. Gao",
                "A. Fisch",
                "D. Chen"
            ],
            "title": "Making Pre-trained Language Models Better Few-shot Learners",
            "venue": "ACL, 3816\u2013 3830.",
            "year": 2021
        },
        {
            "authors": [
                "T. Gao",
                "X. Han",
                "Z. Liu",
                "M. Sun"
            ],
            "title": "Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification",
            "venue": "AAAI, 6407\u20136414.",
            "year": 2019
        },
        {
            "authors": [
                "R. Geng",
                "B. Li",
                "Y. Li",
                "X. Zhu",
                "P. Jian",
                "J. Sun"
            ],
            "title": "Induction Networks for Few-Shot Text Classification",
            "venue": "EMNLP, 3902\u20133911.",
            "year": 2019
        },
        {
            "authors": [
                "C. Han",
                "Z. Fan",
                "D. Zhang",
                "M. Qiu",
                "M. Gao",
                "A. Zhou"
            ],
            "title": "Meta-Learning Adversarial Domain Adaptation",
            "year": 2021
        },
        {
            "authors": [
                "R. He",
                "J.J. McAuley"
            ],
            "title": "Ups and Downs: Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering",
            "venue": "WWW, 507\u2013517.",
            "year": 2016
        },
        {
            "authors": [
                "H. Jeremy",
                "R. Sebastian"
            ],
            "title": "Universal Language Model Fine-tuning for Text Classification",
            "venue": "ACL, 328\u2013 339.",
            "year": 2018
        },
        {
            "authors": [
                "R. Johnson",
                "T. Zhang"
            ],
            "title": "Deep Pyramid Convolutional Neural Networks for Text Categorization",
            "venue": "ACL, 562\u2013570.",
            "year": 2017
        },
        {
            "authors": [
                "J.A. Kumar",
                "S. Abirami"
            ],
            "title": "Ensemble application of bidirectional LSTM and GRU for aspect category detection with imbalanced data",
            "venue": "Neural Computing and Applications, 33(21): 14603\u201314621.",
            "year": 2021
        },
        {
            "authors": [
                "V. Kumar",
                "H. Glaude",
                "C. de Lichy",
                "W. Campbell"
            ],
            "title": "A Closer Look At Feature Space Data Augmentation For Few-Shot Intent Classification",
            "year": 2019
        },
        {
            "authors": [
                "K. Lang"
            ],
            "title": "NewsWeeder: Learning to Filter Netnews",
            "venue": "ICML, 331\u2013339.",
            "year": 1995
        },
        {
            "authors": [
                "S. Larson",
                "A. Mahendran",
                "J.J. Peper",
                "C. Clarke",
                "A. Lee",
                "P. Hill",
                "J.K. Kummerfeld",
                "K. Leach",
                "M.A. Laurenzano",
                "L. Tang",
                "J. Mars"
            ],
            "title": "An Evaluation Dataset for Intent Classification and Out-of-Scope Prediction",
            "venue": "EMNLP, 1311\u20131316.",
            "year": 2019
        },
        {
            "authors": [
                "H. Liu",
                "F. Zhang",
                "X. Zhang",
                "S. Zhao",
                "J. Sun",
                "H. Yu",
                "X. Zhang"
            ],
            "title": "Label-enhanced Prototypical Network with Contrastive Learning for Multi-label Few-shot Aspect Category Detection",
            "venue": "KDD, 1079\u20131087.",
            "year": 2022
        },
        {
            "authors": [
                "H. Liu",
                "F. Zhang",
                "X. Zhang",
                "S. Zhao",
                "X. Zhang"
            ],
            "title": "An Explicit-Joint and Supervised-Contrastive Learning Framework for Few-Shot Intent Classification and Slot Filling",
            "venue": "Findings of EMNLP, 1945\u20131955.",
            "year": 2021
        },
        {
            "authors": [
                "X. Liu",
                "A. Eshghi",
                "P. Swietojanski",
                "V. Rieser"
            ],
            "title": "Benchmarking Natural Language Understanding Services for Building Conversational Agents",
            "venue": "IWSDS, 165\u2013183.",
            "year": 2019
        },
        {
            "authors": [
                "Y. Liu",
                "J. Lee",
                "M. Park",
                "S. Kim",
                "E. Yang",
                "S.J. Hwang",
                "Y. Yang"
            ],
            "title": "Learning to Propagate Labels: Transductive Propagation Network for Few-Shot Learning",
            "venue": "ICLR.",
            "year": 2019
        },
        {
            "authors": [
                "I. Loshchilov",
                "F. Hutter"
            ],
            "title": "Decoupled Weight Decay Regularization",
            "venue": "ICLR.",
            "year": 2019
        },
        {
            "authors": [
                "S. Louvan",
                "B. Magnini"
            ],
            "title": "Recent Neural Methods on Slot Filling and Intent Classification for Task-Oriented Dialogue Systems: A Survey",
            "venue": "COLING, 480\u2013496.",
            "year": 2020
        },
        {
            "authors": [
                "T. Munkhdalai",
                "H. Yu"
            ],
            "title": "Meta Networks",
            "venue": "ICML, 2554\u20132563.",
            "year": 2017
        },
        {
            "authors": [
                "A. Nichol",
                "J. Achiam",
                "J. Schulman"
            ],
            "title": "On FirstOrder Meta-Learning Algorithms",
            "venue": "CoRR.",
            "year": 2018
        },
        {
            "authors": [
                "J. Phang",
                "T. F\u00e9vry",
                "S.R. Bowman"
            ],
            "title": "Sentence encoders on stilts: Supplementary training on intermediate labeled-data tasks",
            "venue": "CoRR.",
            "year": 2018
        },
        {
            "authors": [
                "A. Santoro",
                "S. Bartunov",
                "M.M. Botvinick",
                "D. Wierstra",
                "T.P. Lillicrap"
            ],
            "title": "One-shot Learning with MemoryAugmented Neural Networks",
            "venue": "CoRR.",
            "year": 2016
        },
        {
            "authors": [
                "J. Snell",
                "K. Swersky",
                "R. Zemel"
            ],
            "title": "Prototypical networks for few-shot learning",
            "venue": "NeurIPS, 4077\u20134087.",
            "year": 2017
        },
        {
            "authors": [
                "G. Suchin",
                "M. Ana",
                "S. Swabha",
                "L. Kyle",
                "B. Iz",
                "D. Doug",
                "S.N.A."
            ],
            "title": "Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks",
            "venue": "ACL, 8342\u20138360.",
            "year": 2020
        },
        {
            "authors": [
                "F. Sung",
                "Y. Yang",
                "L. Zhang",
                "T. Xiang",
                "P.H.S. Torr",
                "T.M. Hospedales"
            ],
            "title": "Learning to Compare: Relation Network for Few-Shot Learning",
            "venue": "CVPR, 1199\u20131208.",
            "year": 2018
        },
        {
            "authors": [
                "L. Van der Maaten",
                "G. Hinton"
            ],
            "title": "Visualizing data using t-SNE",
            "venue": "Journal of machine learning research, 9(11).",
            "year": 2008
        },
        {
            "authors": [
                "O. Vinyals",
                "C. Blundell",
                "T. Lillicrap",
                "K. Kavukcuoglu",
                "D. Wierstra"
            ],
            "title": "Matching Networks for One Shot Learning",
            "venue": "NeurIPS, 3630\u20133638.",
            "year": 2016
        },
        {
            "authors": [
                "S. Wang",
                "H. Fang",
                "M. Khabsa",
                "H. Mao",
                "H. Ma"
            ],
            "title": "Entailment as Few-Shot Learner",
            "venue": "CoRR.",
            "year": 2021
        },
        {
            "authors": [
                "J.W. Wei",
                "K. Zou"
            ],
            "title": "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks",
            "venue": "EMNLP, 6381\u20136387.",
            "year": 2019
        },
        {
            "authors": [
                "S. Yang",
                "L. Liu",
                "M. Xu"
            ],
            "title": "Free Lunch for Few-shot Learning: Distribution Calibration",
            "venue": "ICLR.",
            "year": 2021
        },
        {
            "authors": [
                "X. Zhang",
                "J. Zhao",
                "Y. LeCun"
            ],
            "title": "Character-level Convolutional Networks for Text Classification",
            "venue": "NeurIPS.",
            "year": 2015
        }
    ],
    "sections": [
        {
            "heading": "Introduction",
            "text": "Text classification plays a fundamental and crucial role in natural language processing, which has been widely applied to various real applications, such as intent detection (Louvan and Magnini 2020), sentiment analysis (Kumar and Abirami 2021), news classification (Bozarth and Budak 2020) and so on. Traditional text classification methods (Johnson and Zhang 2017; Devlin et al. 2019) have achieved impressive performance, which require a large amount of labeled instances per class for training. However, collecting and annotating sufficient data is a time-consuming and laborintensive process, sometimes even unachievable in industry, which motivates few-shot text classification.\nFew-shot learning is a paradigm for solving the data scarcity issue, which aims to detect novel categories with very limited labeled examples by using prior knowledge learned from known categories. Several kinds of methods\n*Corresponding author. Copyright \u00a9 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nhave been proposed to meet this challenge. Meta-learning based methods aim to train a generalized model which can quickly adapt to new tasks (Finn, Abbeel, and Levine 2017; Santoro et al. 2016; Snell, Swersky, and Zemel 2017; Liu et al. 2021, 2022). This type of methods has been successfully applied to solve the few-shot learning problem. Finetuning based methods usually train a model on the base set first and then transfer to novel classes via adjusting the model parameters (Jeremy and Sebastian 2018; Suchin et al. 2020), which are susceptible to the overfitting problem. Their variants like prompt-based and entailment-based methods (Gao, Fisch, and Chen 2021; Wang et al. 2021) can mitigate the above issue and have achieved promising performance. It is worth noting that most previous works focus on developing stronger models, but less attention has been paid to the property of the data itself. Intuitively, when more informative data is available for supervision, the model tends to generalize well during evaluation.\nIn order to explore the problem from the perspective of data itself, several data-augmentation based methods (Kumar et al. 2019; Dopierre, Gravier, and Logerais 2021; Chen et al. 2022) have been proposed. However, these methods require the design of a complex model and loss function to learn how to generate examples. Recently, one variant of data-augmentation based methods named distribution calibration has shown to be effective in few-shot image classification. It first estimates the distribution of the unseen classes by transferring statistics from the seen classes, and then samples an adequate number of examples to expand the size of labeled data. Nevertheless, this method cannot directly extend to text domain. The main reason is as follows. In vision domain, low-level patterns and their corresponding representations can usually be shared across classes. For example the classes white wolf and arctic fox from ImageNet (Deng et al. 2009) are very similar. The category difference, however, tends to be serious in text domain. For example, the classes get weather and play music from SNIPS (Coucke et al. 2018) are entirely different. That is to say, the unseen classes probably have no overlap with the seen classes in text domain. Simply transferring distribution statistics from seen data seems not a good solution, as some distribution statistics from seen classes may be biased or even harmful to the unseen classes. ar X iv :2 30 3.\n16 76\n4v 1\n[ cs\n.C L\n] 2\n6 M\nar 2\n02 3\nIn this paper, we propose two simple yet effective strategies (way-based and shot-based strategies) to estimate the distributions of the novel classes by exploiting unlabeled query samples instead of adequate samples from seen classes, thus circumventing the possible adverse impact caused by serious category difference. In particular, we assume a class or sample obeys the Gaussian distribution, and use the original support set and the nearest several query samples to estimate the corresponding mean and covariance. Based on the approximated distribution, we generate a sufficient amount of labeled data to augment the support set, thus boosting the model performance. Figure 1 gives a 4-way 1- shot task to illustrate the drawbacks of previous methods and the advantages of our proposed strategies. To verify the effectiveness of the proposed methods, we conduct extensive experiments on eight public datasets. The empirical results show that the proposed strategies can achieve promising results compared with other strong baselines."
        },
        {
            "heading": "Related Work",
            "text": ""
        },
        {
            "heading": "Meta-Learning Based Methods",
            "text": "Meta-learning aims to design a model which can well adapt or generalize to new tasks and new environments that have never been encountered with only a few training examples. Existing meta-learning based methods can be divided into three types. (1) Optimization-based methods, such as MAML (Finn, Abbeel, and Levine 2017) and Reptile (Nichol, Achiam, and Schulman 2018), intend to learn how to optimize the gradient descent procedure so that the model can be effective in learning with a few instances. (2) Modelbased methods, such as MANN (Santoro et al. 2016) and MetaNet (Munkhdalai and Yu 2017), rely on the modules that can update the parameters rapidly and effectively with a few steps. (3) Metric-based methods like matching network (Vinyals et al. 2016), prototypical network (Snell, Swersky, and Zemel 2017), relation network (Sung et al. 2018) and induction network (Geng et al. 2019), first learn an embedding space, and then use a metric to classify new category cases based on the proximity to labeled examples."
        },
        {
            "heading": "Fine-Tuning Based Methods",
            "text": "Traditional fine-tuning algorithms usually use a few samples belonging to the unseen classes to update the parameters of the models pre-trained on the seen classes with adequate samples, which is a straightforward way to deal with few-shot learning. However, these algorithms inevitably suffer from the over-fitting issue due to data scarcity. To mitigate this issue, Jeremy and Sebastian (2018) and Suchin et al. (2020) propose to train the models with the language model objective function on task-specific unlabeled data before fine-tuning models on the target task. Phang, Fe\u0301vry, and Bowman (2018) propose to train the model with data-rich intermediate supervised tasks before fine-tuning it on the target task. Recently, prompt-based and entailment-based methods seem potential in dealing with the few-shot learning task. LM-BFF (Gao, Fisch, and Chen 2021) introduces automatic prompt generation and incorporates the demonstrations as additional context to fine-tune smaller language models on a handful of annotated examples. EFL (Wang et al. 2021) reformulates NLP tasks as textual entailment instead of cloze questions, and provides fine-grained labelspecific descriptions instead of a single task description, thus achieving promising performance."
        },
        {
            "heading": "Data Augmentation Based Methods",
            "text": "Data augmentation is a tried and true method to solve the data sparsity problem. Conventional augmentation methods focus on word substitution (Zhang, Zhao, and LeCun 2015). EDA (Wei and Zou 2019) proposes four simple operations, synonym replacement, random insertion, random swap, and random deletion. Recently, some strong methods are specifically proposed for few-shot text classification. Kumar et al. (2019) explore six feature space data augmentation methods to improve performance in few-shot intent classification. PROTAUGMENT (Dopierre, Gravier, and Logerais 2021) introduces a short-text paraphrasing model that produces diverse paraphrases of the original text as data augmentation. ContrastNet (Chen et al. 2022) leverages data augmentation to train the supervised contrastive representation model under the regularization of a task-level unsupervised con-\ntrastive loss and an instance-level unsupervised contrastive loss. Recently, distribution estimation (Yang, Liu, and Xu 2021) has shown to be powerful in dealing with few-shot image classification, which first calibrates the distribution of the unseen classes by transferring statistics from the seen classes. Then an adequate number of examples are sampled from the calibrated distribution to expand the inputs to the classifier. Obviously, its core goal is to generate more samples based on the estimated distribution, thus providing more supervision for training the classification model. However, it heavily relies on the strong assumption that there always exist seen classes that are similar to an unseen class, which probably not holds in text domain."
        },
        {
            "heading": "The Proposed Method",
            "text": ""
        },
        {
            "heading": "Problem Formulation",
            "text": "In this paper, we use the episode learning strategy to explore few-shot text classification. Specifically, the data is divided into two parts: seen class set Cseen and unseen class set Cunseen, and Cseen \u22c2 Cunseen = \u2205. A classifier is trained with numerous samples from Cseen, and it is quickly adopted to Cunseen with only a few labeled data from Cunseen. Meta learning provides an effective solution for few-shot learning, which commonly follows the N -way K-shot setting, i.e., for each task, there are N classes and each class has K supports (labeled samples). In general, meta-learning contains two phases: training and testing.\nIn the training phase, the meta-classifier is trained on Ntrain tasks. In each training task, it consists of a support set and a query set. To construct the train task, N classes are randomly picked from Cseen. The support set is composed of randomly selecting K labeled samples from each of the N classes, i.e., S = {(xi, yi)}mi=1, where xi is a data sample, yi is the class label and m = N \u00d7K. The query set consists of a portion of the remaining samples from these N classes, i.e., Q = {(xj , yj)}nj=1, where n is the number of queries.\nIn the testing phase, the trained meta-classifier is used to predict the labels of queries in Ntest tasks. In each testing task, it also has a support set and a query set. In a similar manner, N classes are randomly sampled from the test classes Cunseen. The support set and query set are constructed in the same way as those in the meta-training phase. As the labels of queries are unknown in testing stage, the query set in test task can be represented as Q = {xj}nj=1. The goal is to predict the class labels for these queries."
        },
        {
            "heading": "Basic Few-Shot Classifier",
            "text": "We take a popular metric-based meta-learning method \u2013 prototypical network (Snell, Swersky, and Zemel 2017) \u2013 as the basic few-shot classifier. The core idea of prototypical network is to learn a mapping (metric) \u03c6 that projects support and query samples into an embedding space, and then classify the queries by learning their relations according to the Euclidean distance in that space. Specifically, for each training task, the prototypeP c of the c-th (c = 1, 2, . . . , N ) class is obtained by averaging K mapped supports \u03c6(xci ) in this class, i.e., P c = 1K \u2211K i=1 \u03c6(x c i ). For a query xq , the probability of xq belonging to the c-th class is computed by a soft-\nmax function with the Euclidean distances between \u03c6(xq) and the prototypes:\nfqc = exp(\u2212||\u03c6(xq)\u2212 P c||22)\u2211N i=1 exp(\u2212||\u03c6(xq)\u2212 P i||22) , (1)\nwhere the mapping \u03c6 is learned by minimizing the crossentropy loss. Formally,\nLbasic = min \u03c6 n\u2211 q=1 N\u2211 c=1 \u2212yqc log fqc, (2)\nwhere yqc = 1 if xq belongs to the c-th class, otherwise yqc = 0. n is the number of queries."
        },
        {
            "heading": "Distribution Estimation",
            "text": "Distribution calibration (Yang, Liu, and Xu 2021) attempts to calibrate the distributions of unseen classes with few samples by transferring statistics from seen classes with sufficient samples in vision domain. This method heavily relies on the strong assumption that there always exist seen classes which are similar with an unseen class. However, this assumption does not always hold well in text domain. To tackle this issue, we propose two simple yet effective distribution estimation strategies by utilizing unlabeled query samples.\nConsidering anN -wayK-shot task, given a novel class c, its K support samples can be represented as {x1, ...,xK}. For each xi, we can calculate the top R nearest query samples of xi according to the Euclidean distance in the embedding (mapping) space, and we denote this set as {ai1, ...,aiR}. Here R is a hyperparameter.\nWay-Based Distribution Estimation For the way-based distribution estimation strategy, we treat each way (class) as a random variable which follows the Gaussian distribution in the embedding space. In general, the mean of the Gaussian distribution can be obtained by averaging the embedding of each sample in support set:\n\u00b5s = 1\nK K\u2211 i=1 \u03c6(xi), (3)\nwhere \u03c6 is the feature extraction function. In order to better estimate the distribution of the novel class, we attempt to use the top R query samples to calibrate the estimation result. Specifically, we first calculate the mean of {a11, ...,a1R, ...,aK1, ...,aKR} with:\n\u00b5q = 1\nKR K\u2211 i=1 R\u2211 j=1 \u03c6(aij). (4)\nThen the final estimated mean \u00b5way can be represented as:\n\u00b5way = 1\n2 (\u00b5s + \u00b5q)\n= 1\n2K K\u2211 i=1 \u03c6(xi) + 1 2KR K\u2211 i=1 R\u2211 j=1 \u03c6(aij). (5)\nIn a similar manner, we can estimate the covariance matrix \u03a3way of the Gaussian distribution with:\n\u03a3way = 1\n2 (\u03a3s +\u03a3q), (6)\nwhere \u03a3s \u2208 Rd\u00d7d and \u03a3q \u2208 Rd\u00d7d can be calculated with:\n\u03a3s = 1\nK \u2212 1 K\u2211 i=1 (\u03c6(xi)\u2212 \u00b5s)(\u03c6(xi)\u2212 \u00b5s)T , (7)\n\u03a3q = 1\nKR\u2212 1 K\u2211 i=1 R\u2211 j=1 (\u03c6(aij)\u2212\u00b5q)(\u03c6(aij)\u2212\u00b5q)T . (8)\nShot-Based Distribution Estimation For the shot-based distribution estimation strategy, we follow (Yang, Liu, and Xu 2021) to treat each shot (support sample) as a random variable which obeys the Gaussian distribution. For each support sample xi, as it can represent the original mean, we only need to use the topR query samples to adjust it. Specifically, the estimated mean of the support sample xi can be obtained by:\n\u00b5i = 1\n2 (\u03c6(xi) +\n1\nR R\u2211 j=1 \u03c6(aij)), (9)\nand the estimated covariance matrix \u03a3i of the support sample xi can be calculated by:\n\u03a3i = 1\nR\u2212 1 R\u2211 j=1 (\u03c6(aij)\u2212 \u00b5i)(\u03c6(aij)\u2212 \u00b5i)T . (10)\nBy using the above distribution estimation method, for a class c with K support samples, its distribution can be represented as the set {N (\u00b51,\u03a31), ...,N (\u00b5K ,\u03a3K)}."
        },
        {
            "heading": "Distribution Sampling",
            "text": "According to the estimated distribution, we can generate more samples which can provide sufficient supervision for training the classification model.\nWay-Based Distribution Sampling Given an unseen class c, in this scenario we can generate the samples with label c by sampling from the following Gaussian distribution: Dc = {(x, c)|x \u223c N (\u00b5way,\u03a3way)}. (11) After generating a series of samples, we can combine the original support set and the generated samples together to serve as the training data for a task.\nShot-Based Distribution Sampling Given an unseen class c, we denote Sc = {(\u00b51,\u03a31), ..., (\u00b5K ,\u03a3K)} as the set of mean and covariance pairs. We can generate the samples with label c by sampling from the following Gaussian distribution:\nDc = {(x, c)|x \u223c N (\u00b5,\u03a3),\u2200(\u00b5,\u03a3) \u2208 Sc}. (12)\nAfter the sampling procedure, we can train the whole model with the original support set and the generated samples.\nRelationship between Way-Based and Shot-Based Strategies Considering the shot-based distribution sampling, if we sample uniformly from the distribution Dc = {(x, c)|x \u223c N (\u00b5,\u03a3),\u2200(\u00b5,\u03a3) \u2208 Sc}, we can get the overall mean \u00b5shot can be represented as:\n\u00b5shot = 1\nK K\u2211 i=1 \u00b5i\n= 1\nK K\u2211 i=1 ( 1 2 (\u03c6(xi) + 1 R R\u2211 j=1 \u03c6(aij)))\n= 1\n2K K\u2211 i=1 \u03c6(xi) + 1 2KR K\u2211 i=1 R\u2211 j=1 \u03c6(aij).\n(13)\nFrom Eq. (5) and Eq. (13), it is easy to observe that the way-based and shot-based distribution estimation strategies share the same mean, which indicates that these two estimated distributions probably overlap heavily. In addition, in the extreme 1-shot scenario, way-based and shot-based distribution estimation methods are equivalent."
        },
        {
            "heading": "Training and Testing Phases",
            "text": "Training During the training phase, we use the prototypical network loss and the generation loss simultaneously. For the prototypical network loss Lbasic, when calculating the prototype for each class, we combine the original support set and the generated samples as the final support set, and the remaining calculation process can refer to Eqs. (1) and (2). In terms of the generation loss, it aims to guarantee that the generated samples are close to their original center and away from other centers, thus improving the confidence of generated samples. To achieve this goal, the generation loss can be written as:\nLgen = 1 |D| \u2211\n(x\u2217,y\u2217)\u2208D\n\u2212 log p(y = y\u2217|x\u2217,S), (14)\nwhere D = \u222acDc is the overall generated data, and S is the original support set. Then the overall loss function is:\nLtotal = Lbasic + \u03bbLgen, (15) where \u03bb is a trade-off hyperparameter. By minimizingLtotal with gradient descent methods, all trainable model parameters can be learned.\nTesting In the testing phase, given an N -way K-shot task, we first estimate the distribution with way-based or shotbased approaches. Based on the estimated distribution, we generate the corresponding samples and combine them with the original support set as the final support set. Finally, we predict the class label for each query sample by the prototypical network."
        },
        {
            "heading": "Experiments",
            "text": ""
        },
        {
            "heading": "Datasets",
            "text": "We follow (Chen et al. 2022) to conduct experiments on eight text classification datasets, including four intent detection datasets: Banking77, HWU64, Clinic150, and Liu57,\nand four news or review classification datasets: HuffPost, Amazon, Reuters, and 20News. The average length of sentences in news or review classification datasets is much longer than those in intent detection datasets. Table 1 concludes the statistics of all datasets.\n(1) HuffPost (Bao et al. 2020) is a news headlines dataset with 41 classes, which are published on HuffPost from 2012 to 2018. They are shorter and less grammatical than formal sentences.\n(2) Amazon (He and McAuley 2016) consists of 142.8 million customer reviews from 24 product categories. Following (Han et al. 2021), we use a subset, having 1000 reviews per category.\n(3) Reuters (Bao et al. 2020) is collected shorter Reuters articles in 1987. Following (Bao et al. 2020), we discard multi-label articles and only use 31 classes, having at least 20 articles.\n(4) 20News (Lang 1995) covers 18828 documents from news discussion forums under 20 topics.\n(5) Banking77 (Casanueva et al. 2020) is a fine-grained single-domain dataset for intent detection. It consists of 13083 customer service queries labeled with 77 intents, in which some categories are similar and may have overlap with others.\n(6) HWU64 (Liu et al. 2019a) contains 11036 utterances covering 64 intents in 21 domains. The examples are from a real-world home robot, with multi-domain utterances, e.g., email, music, weather and so on.\n(7) Liu57 (Liu et al. 2019a) is composed of 25478 user utterances from 54 classes. The dataset is collected from Amazon Mechanical Turk.\n(8) Clinic150 (Larson et al. 2019) contains 150 intents and 23700 examples across 10 domains. It has 22500 user utterances evenly distributed in every intent and 1200 out-ofscope queries. Here we ignore these out-of-scope examples."
        },
        {
            "heading": "Baselines",
            "text": "We compare the proposed way-based distribution estimation (Way-DE) and shot-based distribution estimation (Shot-DE) with the following strong baselines.\n(1) Prototypical Network (Snell, Swersky, and Zemel 2017) is a metric-based method which calculates the prototype for each class by averaging the corresponding support samples, and utilizes the negative Euclidean distance\nbetween query samples and prototypes to do the few-shot classification task.\n(2) MAML (Finn, Abbeel, and Levine 2017) is an optimization-based method, which learns a good model initialization, and adapts to new tasks by a small number of gradient steps.\n(3) Induction Network (Geng et al. 2019) leverages the dynamic routing algorithm to learn generalized class-wise representations.\n(4) HATT (Gao et al. 2019) is a hybrid attention-based prototypical network, which improves the model robustness greatly.\n(5) DS-FSL (Bao et al. 2020) is a framework to map distributional signatures into attention scores, thus guiding the fast adaptation to new categories.\n(6) MLADA (Han et al. 2021) is a meta-learning adversarial domain adaptation network, which aims to improve the adaptive ability and generate generalized text embeddings for new classes.\n(7) ContrastNet (Chen et al. 2022) trains the supervised contrastive representation model under the regularization of a task-level unsupervised contrastive loss and an instancelevel unsupervised contrastive loss, which can prevent overfitting and generate better representations.\n(8) TPN (Liu et al. 2019b) intends to learn to propagate labels from labeled support samples to unlabeled query samples via episodic training and a specific graph construction, which is a powerful transductive few-shot learning method.\n(9) DC (Yang, Liu, and Xu 2021) calibrates novel class distribution using statistics from the seen classes with abundant samples based on similarity.\n(10) DC-DE is a variant of DC, which considers the statistics from seen classes and query data simultaneously to estimate the distribution. It is a baseline for validating whether seen classes may bring some side effects on performance.\n(11) PROTAUGMENT (Dopierre, Gravier, and Logerais 2021) is an extension of Prototypical Network (Snell, Swersky, and Zemel 2017) using diverse paraphrasing data augmentation. It conducts an instance-level unsupervised loss on the vanilla prototypical network. PROTAUGMENT (unigram) and PROTAUGMENT (bigram) are two enhanced versions using different words paraphrasing strategies.\nNote that PROTAUGMENT is a method specificallydesigned for intent detection, which is not suitable for long text classification, so we do not compare it in the news or\nreview classification task. In addition, in the intent detection task, due to space and time limitation, we just compare with the most effective methods."
        },
        {
            "heading": "Implementation Details",
            "text": "Evaluation Metric We follow (Chen et al. 2022) to use the accuracy to evaluate the performance. All reported results are from 5 different runs, and in each run the training, validation and testing classes are randomly resampled.\nParameter Settings We follow (Chen et al. 2022) to conduct experiments on 5-way 1-shot and 5-shot setting. In news and review classification task, we report the average accuracy on 1000 episodes sampled from test set, where the number of query instances per class in each episode is 25. In intent detection task, we report the average accuracy on 600 episodes sampled from test set for 4 intent detection datasets, where the number of query instances per class in each episode is 5. In terms of feature extraction, for the news or review classification task, we use the pure pre-trained bert-base-uncased model. For the intent detection task, we use the further pre-trained BERT language model provided in (Dopierre, Gravier, and Logerais 2021). We set R = 10\nfor the news or review classification task, while R = 4 for the intent detection task. For the loss function, we set \u03bb = 0.1, and optimize the model parameters using AdamW (Loshchilov and Hutter 2019) with the initial learning rate 0.00001 and dropout rate 0.1. During distribution sampling, in 1-shot and 5-shot scenarios, we generate 20 and 100 samples per class respectively. All the hyper-parameters are selected based on the performance of the validation set."
        },
        {
            "heading": "Result Analysis",
            "text": "Tables 2 and 3 report the experimental results for the news or review classification task and the intent detection task. Most baseline results are taken from (Chen et al. 2022) and the top 2 results are highlighted in bold.\nNews or Review Classification From Table 2, we can make the following observations. (1) Our proposed WayDE and Shot-DE methods perform much better than other baselines in most cases, and achieve the best performance in average. Specifically, in the 1-shot and 5-shot scenarios, from the average perspective, our proposed methods improves upon existing methods by 1.2%-32.0% and 2.1%- 36.3%. The reason is that Way-DE and Shot-DE strategies\ncan accurately estimate the distribution and generate available samples, thus providing strong supervision for training the classification model. (2) Some powerful baselines like ContrastNet and TPN also perform well in most cases. The reason is that they use a large amount of unlabeled data in target domain. While just leveraging very limited queries for each episode, our approaches still outperform them significantly, which further demonstrates the superiority of our proposed methods.\nIntent Detection From Table 3, it is easy to find that: (1) Compared with these latest methods, our proposed methods can achieve very competitive performance. Specifically, on the Liu57 dataset, the average accuracy of Way-DE and Shot-DE methods is greater than 90% and 95% in 1-shot and 5-shot scenarios, which outperforms other algorithms greatly. These improvements indicate that estimating distribution using queries and then sampling from distribution can effectively mitigate the data scarcity issue in few-shot learning. (2) Limited by the number of queries, the improvement of our proposed methods is affected, but they still perform better than other baselines, which validates the effectiveness of the proposed strategies."
        },
        {
            "heading": "Comparison of Distribution Estimation Strategies",
            "text": "In order to deeply explore the disparity of different distribution estimation methods, we conduct a series of experiments under various conditions. DC (Yang, Liu, and Xu 2021) is the distribution calibration method, which transfers the statistics from seen classes to unseen classes. DC-DE is our modified method, which considers the statistics of seen classes and query data simultaneously. Way-DE and ShotDE are our proposed distribution estimation methods by just utilizing query samples. The results are shown in Tables 2 and 3. We can observe that Way-DE and Shot-DE perform much better than DC and DC-DE, and their results are very similar. The reason is that our proposed Way-DE and ShotDE employ unlabeled query samples instead of adequate samples from seen classes, thus circumventing the possible adverse impact caused by transferring the statistics of seen classes. As Way-DE and Shot-DE have the same mean, their results tend to be consistent. In addition, DC-DE outperforms DC, but not as well as Way-DE and Shot-DE, which indicates that combining the distribution information of seen\nclasses and query data may not bring further improvement, even may be detrimental in most cases."
        },
        {
            "heading": "Visualization",
            "text": "To show what the estimated distribution looks like, we use t-SNE (Van der Maaten and Hinton 2008) to visualize the distributions. To be convenient to observe the real distributions, we use 200 unlabeled query examples and 500 generated examples per class from the Liu57 dataset under 5-way 1-shot setting. Note that in the 1-shot scenario, Way-DE and Shot-DE are equivalent in principle. Figure 2(a) shows the original support and query examples. Figure 2(b) shows the support and generated examples. Figure 2(c) shows the support, generated and query examples, which provides a comprehensive distribution representation. We have the following observations: (1) In Figure 2(a), due to the scarcity of support set, only one example in this case, the support set is more likely mismatch with the query set. (2) In Figure 2(b), by leveraging several query examples, the generated examples can better calibrate the real distribution, thus avoiding some support examples locate in the margin of the distribution. (3) In Figure 2(c), the generated examples overlap largely with the query features, which indicates our distribution estimation is accurate and reasonable. Therefore, training and testing with these examples can boost the performance effectively."
        },
        {
            "heading": "Conclusion",
            "text": "In this paper, we propose two simple and sweet distribution estimation methods to deal with the few-shot text classification task. By utilizing top nearest queries to calibrate the data distribution and generate more informative samples according to the estimated distribution, the proposed methods can avoid the potential negative impact caused by transferring from irrelevant seen classes, thus obtaining a more powerful classifier model for few-shot text classification. Extensive experimental results on four news or review classification datasets and four intent detection datasets show that our proposed Way-DE and Shot-DE outperform the state-of-theart methods by a large margin. In future work, we plan to further investigate the theoretical underpinnings of our proposed strategies, and extend the strategies to deal with the multi-label few-shot text classification task."
        },
        {
            "heading": "Acknowledgments",
            "text": "The authors are grateful to the anonymous reviewers for their valuable comments. This work was supported by National Natural Science Foundation of China (No. 62106035, 62206038, 61972065) and Fundamental Research Funds for the Central Universities (No. DUT20RC(3)040, DUT20RC(3)066), and supported in part by Key Research Project of Zhejiang Lab (No. 2022PI0AC01) and National Key Research and Development Program of China (2022YFB4500300). We also would like to thank Dalian Ascend AI Computing Center and Dalian Ascend AI Ecosystem Innovation Center for providing inclusive computing power and technical support."
        }
    ],
    "title": "Boosting Few-Shot Text Classification via Distribution Estimation",
    "year": 2023
}