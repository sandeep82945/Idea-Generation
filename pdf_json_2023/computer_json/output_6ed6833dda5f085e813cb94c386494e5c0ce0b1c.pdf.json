{
    "abstractText": "Department of Sociology and Anthropology, Ben-Gurion University of the Negev, Beer-Sheba, Israel, Uehiro Research Division for iPS Cell Ethics, Center for iPS Cell Research and Application (CiRA), Kyoto University, Kyoto, Japan, Department of Medical Ethics and History of Medicine, University Medical Center G\u00f6ttingen, G\u00f6ttingen, Germany, Department of Ethics and Political Philosophy and Interdisciplinary Hub on Digitalization and Society, Radboud University, Nijmegen, Netherlands, Institute of Biological Chemistry, and Bioethics Network Ethucation, Medical University Innsbruck, Innsbruck, Austria",
    "authors": [
        {
            "affiliations": [],
            "name": "Aviad Raz"
        },
        {
            "affiliations": [],
            "name": "Jusaku Minari"
        },
        {
            "affiliations": [],
            "name": "Silke Schicktanz"
        },
        {
            "affiliations": [],
            "name": "Tamar Sharon"
        },
        {
            "affiliations": [],
            "name": "Gabriele Werner-Felmayer"
        }
    ],
    "id": "SP:0c197648e28ff84d3da28c26704facc316d2d690",
    "references": [],
    "sections": [
        {
            "heading": "Editorial: Data-intensive medicine",
            "text": "and healthcare: ethical and social implications in the era of artificial intelligence and automated decision-making"
        },
        {
            "heading": "Aviad Raz1*, Jusaku Minari2, Silke Schicktanz3, Tamar Sharon4 and Gabriele Werner-Felmayer5",
            "text": "1Department of Sociology and Anthropology, Ben-Gurion University of the Negev, Beer-Sheba, Israel, 2Uehiro Research Division for iPS Cell Ethics, Center for iPS Cell Research and Application (CiRA), Kyoto University, Kyoto, Japan, 3Department of Medical Ethics and History of Medicine, University Medical Center G\u00f6ttingen, G\u00f6ttingen, Germany, 4Department of Ethics and Political Philosophy and Interdisciplinary Hub on Digitalization and Society, Radboud University, Nijmegen, Netherlands, 5Institute of Biological Chemistry, and Bioethics Network Ethucation, Medical University Innsbruck, Innsbruck, Austria"
        },
        {
            "heading": "KEYWORDS",
            "text": "genomic medicine, ethics, personalized medicine, automated decision-making, artificial intelligence\nEditorial on the Research Topic Data-intensive medicine and healthcare: ethical and social implications in the era of artificial intelligence and automated decision-making\nMedical \u201cbig data\u201d and artificial intelligence (AI) are a hyped duo. Promises include developing more personalised treatments, delegating medical decision-making to tireless and seemingly objective algorithms, improving preventive screening, and providing healthcare more efficiently through predictive risk scores. AI and big data, however, do not automatically transform into improved health outcomes. The practical and functional uses of AI in big data environments require integrating and interpreting a wide variety of medical data (e.g., from genomics or other omics, imaging, biomarker analyses) and other personal data. As a result, AI-driven technology bears various new challenges and risks at the societal, algorithmic, organizational, expert, and individual levels.\nScholarship on the ethical, legal, and social issues of using AI in data-intensive medicine and healthcare has highlighted numerous areas of contention, including regulation, explainability, privacy, data sharing and protection, trust, and biases, as well as how AI might affect the patient\u2013doctor relationship and support interdisciplinary expert teams in their decisions. Aiming to extend this perspective, this Research Topic focuses on AI applications in various areas of innovative data-intensive medicine, such as genomics, neuroscience, and child and elderly care. The contributions explore how ethical and social considerations can/should be part of medical AI by considering issues of diversity, the significance of datafication and automation, public and patient participation, developing deliberative or open science approaches (such as open codes), and how to ensure interoperability among developers and users while preventing misuse, hacking, or manipulation. The Research Topic comprises 10 articles dealing with various aspects of"
        },
        {
            "heading": "OPEN ACCESS",
            "text": ""
        },
        {
            "heading": "EDITED AND REVIEWED BY",
            "text": "Dov Greenbaum, Yale University, United States\n*CORRESPONDENCE Aviad Raz, aviadraz@bgu.ac.il\nRECEIVED 20 August 2023 ACCEPTED 04 September 2023 PUBLISHED 07 September 2023"
        },
        {
            "heading": "CITATION",
            "text": "Raz A, Minari J, Schicktanz S, Sharon T and Werner-Felmayer G (2023), Editorial: Data-intensive medicine and healthcare: ethical and social implications in the era of artificial intelligence and automated decision-making. Front. Genet. 14:1280344. doi: 10.3389/fgene.2023.1280344"
        },
        {
            "heading": "COPYRIGHT",
            "text": "\u00a9 2023 Raz, Minari, Schicktanz, Sharon and Werner-Felmayer. This is an openaccess article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.\nFrontiers in Genetics frontiersin.org01\nTYPE Editorial PUBLISHED 07 September 2023 DOI 10.3389/fgene.2023.1280344\nthe prospects and perils of AI in healthcare, which can be grouped into several themes representing key concerns in this emerging field\u2014especially regulation, data sharing, and explainability.\nRubeis et al. can be read as a prolegomenon to the Research Topic, as they introduce a useful typology of the various ways in which \u201cdemocratizing AI\u201d is used to hype the field of AI in healthcare. Their study highlights the ways in which the concept of \u201cdemocratizing AI\u201d tends to frame patients as consumers and focus on free-market solutions, while omitting the deliberative processes and modes of participation needed to ensure that those affected by AI in healthcare have a say on its development and use. These needs and lacunae are further highlighted in the other articles.\nThe required and/or missing regulation and ethical embedding of AI-assisted healthcare are discussed in four articles. Stake and Heinrichs examine the ethical aspects of e-health applications for child health screening. They propose to develop age-specific models that consider the vulnerability of children to balance their right to informational self-determination withmedical needs. Meszaros et al. examine more generally the future directions of AI regulation in medical care implied by the proposed EUAI Act and the EUGeneral Data Protection Regulation, analysing ways to harmonize the principles of data protection and ethical AI. Fritzsche et al. discuss the recent use of AI for polygenic risk scores (PRSs), which may enable higher prediction accuracy but also presents a range of increasingly complex ethical challenges regarding fairness, trust, and explainability, as well as regulatory uncertainties. The authors strongly advocate a proactive approach to embedding ethics in research and implementation processes for AI-driven PRSs. Raz and Minari expand this discussion by comparing AI-derived ethnicity-related PRSs and social scoring, both of which, while representing different applications, may reproduce biases. The authors argue that if AI-derived PRSs evaluate or classify the risks of natural persons based on their ethnic/racial selfdesignations, this will be akin to AI-derived social scoring based on previous social behaviours in multiple contexts or known or predicted personal or personality characteristics.\nThe challenges of data sharing are explored in two articles. Reer et al. review the requirements for useful data sharing in human neuroscience. They discuss international legal frameworks and the standardization of data and metadata organization and annotation. Bak et al. criticize the conventionally used \u201ceither/or\u201d choice of the \u201cconsent or anonymize approach\u201d and its challenge to balancing data privacy and data access. They argue that the \u201cAI revolution\u201d in healthcare can be realized only through transnational data sharing governance policies.\nTwo articles address the issue of explainability. Pierce et al. discuss the opacity problem of AI in clinical use by drawing a distinction between the function of explainability for the current patient and that for the future patient. They argue that in day-to-day clinical practice, accuracy is sufficient as an \u201cepistemic warrant\u201d for clinical decisionmaking and that themost compelling reason for requiring explainability in the sense of scientific or causal explanation is its potential to improve future care. Ott and Dabrock suggest that while transparency often follows an \u201call or nothing\u201d logic, intelligibility offers the opportunity to uncover the essential elements of anAI system:Does the system provide an adequate basis for rendering people intelligible? And does it do so not only ex ante during data collection and algorithm design but continuously during implementation and adaptation and, finally, ex post after the actual use case?\nFinally, Schicktanz et al. suggest a novel approach not only to embedding ethics into the development and use of medical AI (as all the articles discuss for their respective fields) but also to integrating AI into the development of ethical assessment. They argue for AIassisted ethical simulation that can improve context-sensitive ethical analyses, as well as for thought experiments and future-oriented technology assessments\u2014for example, applications catering for persons with dementia or cognitive impairment.\nThe diversity of the articles included in this Research Topic reminds us that under no circumstances should groups exclusively pursuing their own interest dominate the debate on medical AI. Rather, addressing the ethical challenges of medical AI requires interdisciplinary efforts involving computer scientists, ethicists, sociologists, policymakers, and domain experts (such as healthcare professionals) to address the multiple aspects of this debate which should be open to all the stakeholders involved."
        },
        {
            "heading": "Author contributions",
            "text": "AR: Writing\u2013original draft, Writing\u2013review and editing. JM: Writing\u2013review and editing. SS: Writing\u2013review and editing. TS: Writing\u2013review and editing. GW-F: Writing\u2013review and editing."
        },
        {
            "heading": "Funding",
            "text": "The author(s) declare financial support was received for the research, authorship, and/or publication of this article. AR and JM are supported by funding provided by the JSPS\u2013ISF Joint Program, Grant 62/22 (ISF), JPJSBP120228404 (JSPS), \u201cBiobanks for genomic medicine in Israel and Japan: an analysis of ethics and policy.\u201d JM is supported by the JSPS Grant-in-Aid for Scientific Research (B), No. JP21H03163. TS is supported by funding provided by the European Research Council, Grant No. 804985."
        },
        {
            "heading": "Acknowledgments",
            "text": "We thank the authors of the papers comprising this Research Topic for their valuable contributions and the referees for their rigorous review."
        },
        {
            "heading": "Conflict of interest",
            "text": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest."
        },
        {
            "heading": "Publisher\u2019s note",
            "text": "All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.\nFrontiers in Genetics frontiersin.org02\nRaz et al. 10.3389/fgene.2023.1280344"
        }
    ],
    "title": "Editorial: Data-intensive medicine and healthcare: ethical and social implications in the era of artificial intelligence and automated decision-making",
    "year": 2023
}