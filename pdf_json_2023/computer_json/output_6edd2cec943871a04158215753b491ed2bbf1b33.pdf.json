{
    "abstractText": "Generating coherent conversation is an important and challenging long text generation task, as it has various applications such as daily entertainment, education, or building conversational AI to facilitate human-computer interaction. However, current generation models often fail to effectively utilize rich linguistic and world knowledge to generate conversations just like humans. In this work, we introduce a novel conversation generation framework to effectively incorporate human knowledge and conversation structures with both controllability and interpretability for better conversation generation. Specifically, we first generate the prototype conversations from short descriptions. We then gradually and strategically incorporate different levels of conversation structures including the action triples, dialogue acts, and discourse relations via diffusion models to directly edit the prototype conversations. We demonstrate the effectiveness of our framework through experiments on two datasets by comparing our method with the state-of-the-art baseline models1.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jiaao Chen"
        },
        {
            "affiliations": [],
            "name": "Diyi Yang"
        }
    ],
    "id": "SP:d698f960c0a60588fa0d9f878880ea910ba5d941",
    "references": [
        {
            "authors": [
                "Tosin Adewumi",
                "Foteini Liwicki",
                "Marcus Liwicki"
            ],
            "title": "State-of-the-art in open-domain conversational ai: A survey",
            "year": 2022
        },
        {
            "authors": [
                "James Allen",
                "Mark Core."
            ],
            "title": "Draft of DAMSL: Dialog act markup in several layers",
            "venue": "Unpublished manuscript.",
            "year": 1997
        },
        {
            "authors": [
                "Gabor Angeli",
                "Melvin Jose Johnson Premkumar",
                "Christopher D. Manning."
            ],
            "title": "Leveraging linguistic structure for open domain information extraction",
            "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th",
            "year": 2015
        },
        {
            "authors": [
                "Nicholas Asher",
                "Julie Hunter",
                "Mathieu Morey",
                "Benamara Farah",
                "Stergos Afantenos."
            ],
            "title": "Discourse structure and dialogue acts in multiparty dialogue: the stac corpus",
            "venue": "Proceedings of the Tenth International Conference on Language Resources",
            "year": 2016
        },
        {
            "authors": [
                "Nicholas Asher",
                "Julie Hunter",
                "Mathieu Morey",
                "Benamara Farah",
                "Stergos Afantenos."
            ],
            "title": "Discourse structure and dialogue acts in multiparty dialogue: the STAC corpus",
            "venue": "Proceedings of the Tenth International Conference on Language Resources",
            "year": 2016
        },
        {
            "authors": [
                "Jacob Austin",
                "Daniel D. Johnson",
                "Jonathan Ho",
                "Daniel Tarlow",
                "Rianne van den Berg"
            ],
            "title": "Structured denoising diffusion models in discrete state-spaces",
            "year": 2021
        },
        {
            "authors": [
                "Hengyi Cai",
                "Hongshen Chen",
                "Yonghao Song",
                "Xiaofang Zhao",
                "Dawei Yin."
            ],
            "title": "Exemplar guided neural dialogue generation",
            "venue": "International Joint Conference on Artificial Intelligence.",
            "year": 2020
        },
        {
            "authors": [
                "Eugene Charniak."
            ],
            "title": "Toward a model of children\u201ds story comprehension",
            "venue": "Technical report, USA.",
            "year": 1972
        },
        {
            "authors": [
                "Jiaao Chen",
                "Diyi Yang."
            ],
            "title": "Simple conversational data augmentation for semi-supervised abstractive dialogue summarization",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6605\u20136616, Online and",
            "year": 2021
        },
        {
            "authors": [
                "Jiaao Chen",
                "Diyi Yang."
            ],
            "title": "Structure-aware abstractive conversation summarization via discourse and action graphs",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
            "year": 2021
        },
        {
            "authors": [
                "Yulong Chen",
                "Yang Liu",
                "Liang Chen",
                "Yue Zhang."
            ],
            "title": "DialogSum: A real-life scenario dialogue summarization dataset",
            "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 5062\u20135074, Online. Association for Computa-",
            "year": 2021
        },
        {
            "authors": [
                "Angela Fan",
                "Mike Lewis",
                "Yann Dauphin"
            ],
            "title": "Hierarchical neural story generation",
            "year": 2018
        },
        {
            "authors": [
                "Xiachong Feng",
                "Xiaocheng Feng",
                "Bing Qin",
                "Ting Liu."
            ],
            "title": "Incorporating commonsense knowledge into abstractive dialogue summarization via heterogeneous graph networks",
            "venue": "arXiv preprint arXiv:2010.10044.",
            "year": 2020
        },
        {
            "authors": [
                "James Paul Gee."
            ],
            "title": "An introduction to discourse analysis: Theory and method",
            "venue": "Routledge.",
            "year": 2014
        },
        {
            "authors": [
                "Bogdan Gliwa",
                "Iwona Mochol",
                "Maciej Biesek",
                "Aleksander Wawer."
            ],
            "title": "SAMSum corpus: A humanannotated dialogue dataset for abstractive summarization",
            "venue": "Proceedings of the 2nd Workshop on New Frontiers in Summarization, pages 70\u201379, Hong",
            "year": 2019
        },
        {
            "authors": [
                "Seraphina Goldfarb-Tarrant",
                "Tuhin Chakrabarty",
                "Ralph Weischedel",
                "Nanyun Peng."
            ],
            "title": "Content planning for neural story generation with aristotelian rescoring",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
            "year": 2020
        },
        {
            "authors": [
                "Shansan Gong",
                "Mukai Li",
                "Jiangtao Feng",
                "Zhiyong Wu",
                "Lingpeng Kong"
            ],
            "title": "Diffuseq: Sequence to sequence text generation with diffusion models",
            "year": 2022
        },
        {
            "authors": [
                "Jian Guan",
                "Xiaoxi Mao",
                "Changjie Fan",
                "Zitao Liu",
                "Wenbiao Ding",
                "Minlie Huang"
            ],
            "title": "Long text generation by modeling sentence-level and discourse-level coherence",
            "year": 2021
        },
        {
            "authors": [
                "Jian Guan",
                "Zhenyu Yang",
                "Rongsheng Zhang",
                "Zhipeng Hu",
                "Minlie Huang"
            ],
            "title": "Generating coherent narratives by learning dynamic and discrete entity states with a contrastive framework",
            "year": 2022
        },
        {
            "authors": [
                "Chulaka Gunasekara",
                "Guy Feigenblat",
                "Benjamin Sznajder",
                "Sachindra Joshi",
                "David Konopnicki."
            ],
            "title": "Summary grounded conversation generation",
            "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3748\u20133756, Online.",
            "year": 2021
        },
        {
            "authors": [
                "Prakhar Gupta",
                "Jeffrey Bigham",
                "Yulia Tsvetkov",
                "Amy Pavel."
            ],
            "title": "Controlling dialogue generation with semantic exemplars",
            "venue": "Proceedings of the 2021",
            "year": 2021
        },
        {
            "authors": [
                "Zhengfu He",
                "Tianxiang Sun",
                "Kuanning Wang",
                "Xuanjing Huang",
                "Xipeng Qiu"
            ],
            "title": "Diffusionbert: Improving generative masked language models with diffusion models",
            "year": 2022
        },
        {
            "authors": [
                "Jonathan Ho",
                "Ajay Jain",
                "Pieter Abbeel"
            ],
            "title": "Denoising diffusion probabilistic models",
            "year": 2020
        },
        {
            "authors": [
                "Emiel Hoogeboom",
                "Didrik Nielsen",
                "Priyank Jaini",
                "Patrick Forr\u00e9",
                "Max Welling"
            ],
            "title": "Argmax flows and multinomial diffusion: Learning categorical distributions",
            "year": 2021
        },
        {
            "authors": [
                "Changzhen Ji",
                "Yating Zhang",
                "Xiaozhong Liu",
                "Adam Jatowt",
                "Changlong Sun",
                "Conghui Zhu",
                "Tiejun Zhao."
            ],
            "title": "A neural conversation generation model via equivalent shared memory investigation",
            "venue": "Proceedings of the 30th ACM International Conference on",
            "year": 2021
        },
        {
            "authors": [
                "Paul A Kirschner",
                "Simon J Buckingham-Shum",
                "Chad S Carr."
            ],
            "title": "Visualizing argumentation: Software tools for collaborative and educational sensemaking",
            "venue": "Springer Science & Business Media.",
            "year": 2012
        },
        {
            "authors": [
                "Terry K Koo",
                "Mae Y Li."
            ],
            "title": "A guideline of selecting and reporting intraclass correlation coefficients for reliability research",
            "venue": "Journal of chiropractic medicine, 15(2):155\u2013163.",
            "year": 2016
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Veselin Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "BART: Denoising sequence-to-sequence pre-training for natural language",
            "year": 2020
        },
        {
            "authors": [
                "Jiwei Li",
                "Minh-Thang Luong",
                "Dan Jurafsky"
            ],
            "title": "A hierarchical neural autoencoder for paragraphs and documents",
            "year": 2015
        },
        {
            "authors": [
                "Qintong Li",
                "Piji Li",
                "Wei Bi",
                "Zhaochun Ren",
                "Yuxuan Lai",
                "Lingpeng Kong."
            ],
            "title": "Event transition planning for open-ended text generation",
            "venue": "Findings of the Association for Computational Linguistics: ACL 2022, pages 3412\u20133426, Dublin, Ireland. Association",
            "year": 2022
        },
        {
            "authors": [
                "Xiang Lisa Li",
                "John Thickstun",
                "Ishaan Gulrajani",
                "Percy Liang",
                "Tatsunori B. Hashimoto"
            ],
            "title": "2022b. Diffusion-lm improves controllable text generation",
            "year": 2022
        },
        {
            "authors": [
                "Chin-Yew Lin",
                "Franz Josef Och."
            ],
            "title": "Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics",
            "venue": "Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 605.",
            "year": 2004
        },
        {
            "authors": [
                "Xiaoyan Zhu"
            ],
            "title": "Long and diverse text",
            "year": 2019
        },
        {
            "authors": [
                "Jascha Sohl-Dickstein",
                "Eric Weiss",
                "Niru Maheswaranathan",
                "Surya Ganguli."
            ],
            "title": "Deep unsupervised learning using nonequilibrium thermodynamics",
            "venue": "Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Pro-",
            "year": 2015
        },
        {
            "authors": [
                "Jiaming Song",
                "Chenlin Meng",
                "Stefano Ermon."
            ],
            "title": "Denoising diffusion implicit models",
            "venue": "International Conference on Learning Representations.",
            "year": 2021
        },
        {
            "authors": [
                "Matthew Stone",
                "Una Stojnic",
                "Ernest Lepore."
            ],
            "title": "Situated utterances and discourse relations",
            "venue": "Proceedings of the 10th International Conference on Computational Semantics (IWCS 2013)\u2013Short Papers, pages 390\u2013396.",
            "year": 2013
        },
        {
            "authors": [
                "Bowen Tan",
                "Zichao Yang",
                "Maruan AI-Shedivat",
                "Eric P. Xing",
                "Zhiting Hu"
            ],
            "title": "Progressive generation of long text with pretrained language models",
            "year": 2020
        },
        {
            "authors": [
                "Thomas Wolf",
                "Victor Sanh",
                "Julien Chaumond",
                "Clement Delangue"
            ],
            "title": "Transfertransfo: A transfer learning approach for neural network based conversational agents",
            "year": 2019
        },
        {
            "authors": [
                "Peng Xu",
                "Mostofa Patwary",
                "Mohammad Shoeybi",
                "Raul Puri",
                "Pascale Fung",
                "Anima Anandkumar",
                "Bryan Catanzaro."
            ],
            "title": "MEGATRON-CNTRL: Controllable story generation with external knowledge using large-scale language models",
            "venue": "Proceedings of the",
            "year": 2020
        },
        {
            "authors": [
                "Kevin Yang",
                "Yuandong Tian",
                "Nanyun Peng",
                "Dan Klein"
            ],
            "title": "2022. Re3: Generating longer stories with recursive reprompting and revision",
            "year": 2022
        },
        {
            "authors": [
                "Yizhe Zhang",
                "Siqi Sun",
                "Michel Galley",
                "Yen-Chun Chen",
                "Chris Brockett",
                "Xiang Gao",
                "Jianfeng Gao",
                "Jingjing Liu",
                "Bill Dolan."
            ],
            "title": "DIALOGPT : Large-scale generative pre-training for conversational response generation",
            "venue": "Proceedings of the 58th Annual Meet-",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Findings of the Association for Computational Linguistics: ACL 2023, pages 7238\u20137251 July 9-14, 2023 \u00a92023 Association for Computational Linguistics"
        },
        {
            "heading": "1 Introduction",
            "text": "Generating long-form and coherent text is an important step in many natural language generation (NLG) applications (Guan et al., 2022). While recent research has shown impressive progress in generating short texts, it is still challenging for generation models to write coherent long text which requires comprehensively incorporating linguistic and world knowledge (Charniak, 1972). Our work takes a closer look at long conversation generation (Gunasekara et al., 2021), one of the most challenging long text generation tasks. The task is to generate an entire coherent conversation from a given short description, i.e., a summary, of it. Conversation generation has various applications from daily\n1The code is available at https://github.com/ SALT-NLP/Conversation_Generation_Diffusion\nentertainment, and story generation, to customer services. However, real human/human conversation logs are scarce; crowdsourcing conversational data is time-consuming, costly, and hard to ensure data quality (Gunasekara et al., 2021). Thus, better conversation generation models would allow us to generate massive natural conversational data more automatically and efficiently, which further helps build better conversational AI systems.\nEven though there are a growing number of studies that focused on long text generation such as story generation (Guan et al., 2022; Yang et al., 2022; Fan et al., 2018; Li et al., 2022a) using large pre-trained models (Fan et al., 2018; Yang et al., 2022), event planning (Guan et al., 2022; Fan et al., 2018; Li et al., 2022a) and recursive revision (Yang et al., 2022), directly applying them to generate long conversation may not work well due to the inherent different structures between stories and conversations. For instance, previous long text generation usually focused on generating stories that talk about one single topic with five sentences to one paragraph. They are shorter compared to conversations, which usually cover multiple topics between different speakers (over ten turns) (Feng et al., 2020). Furthermore, there are diverse discourse relations between different speakers (Chen and Yang, 2021b), making it even more challenging to generate long and coherent conversations.\nWhile there is a line of work about dialogue generation, they are mainly concentrated on generating the next utterance autoregressively based on the given context (Ji et al., 2021; Liu et al., 2020; Saha et al., 2022; Zhang et al., 2020; Ramakrishnan et al., 2022) with sequence-to-sequence models. Such methods usually neglect the conversation structures(Adewumi et al., 2022), and thus might easily lose focus to produce long and coherent conversations after several rounds of generation (Gunasekara et al., 2021). Moreover, the formerly generated utterances could not be further edited to\n7238\nadapt the later generated utterances. It is also unclear whether and how these sequence-to-sequence models are \u201cgradually planning\u201d to produce the long conversations. Therefore, how to design controllable methods tailored to the structures in conversations for generating long and coherent conversations becomes especially important.\nTo this end, our work introduces a Controllable Conversation Generation Framework with Diffusion Models (Diffuse-CG, shown in Figure 1) to incorporate different conversational structures in a non-autoregressive manner, inspired by recent advances in deep generative models (Li et al., 2022b; Gong et al., 2022; He et al., 2022). Specifically, we first generate a prototype conversation using pre-trained sequence-to-sequence model based on the input description. Then we leverage the diffusion models to gradually enrich the prototype conversation with conversation structures. The diffusion process allows a more flexible conversation generation by not limiting a fixed left-to-right generation order; it also allows the model to gradually incorporate different levels of conversation structures to control the granularities, including the use of action triples to add more specific topics and events (Gee, 2014; Chen and Yang, 2021b), dialogue acts to make the utterances more like human (Allen and Core, 1997; Sacks et al., 1978; Chen and Yang, 2021a), and discourse relations to generate longer conversations with better coherency (Kirschner et al., 2012; Stone et al., 2013; Asher et al., 2016a). To make the diffusion process more adapted to conversation generation and more stable, we further improve the general diffusion model (Li et al., 2022b) with linguistic-informed noise where\nwe perturb the prototype conversation in the forward process with noise including soft-masking action words, soft-masking utterances, and shuffling discourse relations, rather than pure Gaussian noise (Li et al., 2022b). Experiments on two conversation datasets, SAMSum (Gliwa et al., 2019) and DialogSum (Chen et al., 2021)by visualizing the intermediate-generated conversations, we show that Diffuse-CG achieves better interpretability for understanding how the model is structuring and generating long-form conversations."
        },
        {
            "heading": "2 Related Work",
            "text": "Long Text Generation Long-form text generation has been a longstanding challenge in natural language generation where models need to generate long, coherent and open-ended narratives (Guan et al., 2022; Yang et al., 2022; Fan et al., 2018; Li et al., 2022a; Guan et al., 2021). Recent studies have shown impressive success in generating more coherent stories through adopting hierarchical model structures (Li et al., 2015), leveraging large pre-trained models (Fan et al., 2018; Yang et al., 2022), planing first and then generating framework (Shao et al., 2019; Tan et al., 2020; Goldfarb-Tarrant et al., 2020; Li et al., 2022a) and incorporating external knowledge (Guan et al., 2022; Fan et al., 2018; Xu et al., 2020). However, previous studies mainly focus on generating singlespeaker stories and neglect one important form of long text\u2014conversations. Such methods cannot be directly applied to generate multi-speaker conversations because of the complex linguistic structures in conversations such as back-and-forth interactions (Feng et al., 2020; Chen and Yang, 2021b).\nOur work fills this gap by utilizing conversation structures to generate coherent conversations.\nDialogue Response Generation Numerous studies have been conducted on generating short responses conditioned on previous context (Ji et al., 2021; Liu et al., 2020; Saha et al., 2022; Zhang et al., 2020; Ramakrishnan et al., 2022) such as adding user\u2019s persona (Wolf et al., 2019), paraphrasing template responses (Lippe et al., 2020) and using example guidance (Gupta et al., 2021; Cai et al., 2020). While achieving state-of-the-art performances, they suffer from generating the entire conversation because they can only generate one utterance at a time and easily lose focus when generating multiple rounds of utterances or the entire conversation (Gunasekara et al., 2021). This is largely due to the fact that former errors cannot be corrected when generating utterance by utterance autoregressively, and the lack of awareness towards rich conversation structures like long-distance relations in conversations (Stone et al., 2013; Asher et al., 2016a). To this end, we design a controllable and interpretable conversation generation framework that makes use of rich structures to generate the entire conversation in a non-autoregressive way.\nDiffusion Model Diffusion models (SohlDickstein et al., 2015; Ho et al., 2020; Song et al., 2021) are recently-introduced state-of-the-art non-autoregressive generative models and have shown substantial success for visual modalities (Ramesh et al., 2022; Rombach et al., 2022). They are generally more interpretable and controllable as they gradually denoise random vectors to desired output via multiple intermediate steps (He et al., 2022; Austin et al., 2021). However, it is still difficult to apply diffusion models to textual data, because the input space in text is discrete and text is generally more complex in structures. Although there are a few exceptions to model language generation with diffusion process (Li et al., 2022b; Gong et al., 2022; He et al., 2022; Austin et al., 2021; Hoogeboom et al., 2021) where continuous and discrete space is bridged through embedding and rounding (Li et al., 2022b; Gong et al., 2022; Dieleman et al., 2022), such approaches often utilize Gaussian noise in the forward process, which usually fails to leverage the linguistic structure in text to noise the input textual data and makes the diffusion models unstable and costly (He et al., 2022). Building upon these prior works,\nwe utilize diffusion models for interpretable and controllable conversation generation and design a novel linguistic-informed noise for adapting diffusion models to generate textual conversations."
        },
        {
            "heading": "3 Background: Diffusion Models",
            "text": "Diffusion models are the recent state-of-the-art deep generative models via iterative denoising the latent variables (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2021). Basically, corruption (usually Gaussian noise) is added to the input data distribution gradually during a forward process. Then a diffusion model is trained through learning to recover the corrupted distribution to the original input data distribution step by step. A small amount of information that is perturbed during the corresponding forward process is reconstructed in every diffusion step.\nThere is usually a forward noising process and a diffusion denoising process in a diffusion model. For a given sampled input data, x0 \u223c q(x0), a Markov chain of latent variables {x1, \u00b7 \u00b7 \u00b7, xT } are generated in the forward noising process (q (xt | xt\u22121)) by progressively adding a small amount of Gaussian noise to perturb the input data:\nq (xt | xt\u22121) = N ( xt; \u221a 1\u2212 \u03b2txt\u22121, \u03b2tI )\nwhere {\u03b2t \u2208 (0, 1)}Tt=1 is a noise schedule controlling the amount of added noise in every step. Through the forward process, xT becomes an isotropic Gaussian distribution. Note that there are no trainable parameters in the forward process.\nThen a reversed diffusion process, which is learned by a parameterized model (p(xt\u22121|xt)), is learned to denoise xT to the original data x0:\np\u03b8 (xt\u22121 | xt, t) = N (xt\u22121;\u00b5\u03b8 (xt, t) ,\u03a3\u03b8 (xt, t)) ,\nwhere \u00b5\u03b8(.) and \u03a3\u03b8(.) are the learned models. The diffusion model is trained to maximize the marginal likelihood of log p\u03b8(x0). And Ho et al. expand and reweight the objectives to obtain a meansquared error (L2) loss:\nLd (x0) = T\u2211\nt=1\nE q(xt|x0) \u2225\u00b5\u03b8 (xt, t)\u2212 \u00b5\u0302 (xt, x0)\u22252\nwhere \u00b5\u0302 is the mean of the posterior q(xt\u22121|x0, xt), and \u00b5\u03b8 is the predicted mean of p\u03b8(xt\u22121|xt), which is predicted by the parameterized neural models."
        },
        {
            "heading": "4 Our Approach",
            "text": "This section introduces our controllable conversation generation model to generate natural and coherent conversations, as shown in Figure 1. Basically, we first utilize a sequence-to-sequence model to generate a prototype version of the conversation based on the given short description (Section 4.1). We then gradually incorporate the conversation structure guidance to edit the prototype conversation in order from lower levels to higher levels (action triples, dialogue acts, and discourse relations) through diffusion models (Section 4.2)."
        },
        {
            "heading": "4.1 Prototype Conversation Generation",
            "text": "We first train a sequence-to-sequence model f(F (.)) to generate the prototype conversation Cp based on the given conversation summary s, Cp = f(F (s)), where F (.) is an encoder-decoder network and f(.) is a feed-forward network to map the hidden representations to actual words. We initialize f(F (.)) with a pre-trained encoderdecoder model, i.e., BART-base (Lewis et al., 2020). f(F (.)) is learned using the ground truth summary-conversation pairs, (s, Cg) through minimizing the cross entropy L = \u2212\u2211 logP (Cg|s).\nOnce the prototype conversation generation model is learned, we utilize F (.) to generate the hidden representations X0 = {w0, ..., wl} of the prototype conversation C with l words: X0 = {w0, ..., wl} = F (s). Note that X0 \u2208 Rl\u00d7d is a matrix used as the initiate latent variable in Section 4.2, where l is the number of words in the conversation and d is the dimension of the hidden representation."
        },
        {
            "heading": "4.2 Editing with Diffusion Models",
            "text": "With the hidden representation, X0, of the prototype conversation, we then introduce our diffusion model that gradually edits the prototype conversation to form the desired long conversation. Specifically, we first add linguistic noise to X0 to get the noisy intermediate latent variables X1:T in the forward process (Section 4.2.2), and then gradually denoise XT to X\u03020 with different levels of conversation structure information in the diffusion process (Section 4.2.3). Last, we generate the long conversation Cl with the denoised X\u03020: Cl = f(X\u03020)."
        },
        {
            "heading": "4.2.1 Structures in Conversations",
            "text": "This part introduces the three types of widely-used structures with different granularity in conversa-\ntions utilized in our work2: the action triples, dialogue acts, and discourse relations. The action triples are the \u201cWHO-DOING-WHAT\u201d triplets (e.g., \u201cSam-Asking for-Betty\u2019s number\u201d) in conversations that express specific socially situated identities and activities (Chen and Yang, 2021b). The dialogue acts describe the functions and roles of every utterance in one conversation. For example, natural conversations might often have interruption utterances with dialogue acts like acknowledgment, backchannel, response acknowledgment and etc. (Allen and Core, 1997; Sacks et al., 1978). Discourse relations describe the relations between different utterances in one conversation (Asher et al., 2016b). For example, two utterances may be related to each other with the Question Answer Pair."
        },
        {
            "heading": "4.2.2 Forward Process",
            "text": "We first add noise to prototype conversation X0 = {w0, ..., wl} to generate the noisy intermediate latent variables X1:T in the forward process: Xt+1 = q(Xt). To make the diffusion process more stable and efficient, the added noise needs to corrupt the prototype conversation and gives the later diffusion process appropriate flexibility to generate conversations, while avoiding removing all the prior knowledge in X0. Thus we design and apply different types of linguistic-informed noises to perturb the structured information in conversation. Here we introduce three types of noise strategies based on the conversation structures into the forward process:\nSoft-Masking Action Words For soft-masking action words, we only add noise to the action words wi in the prototype conversation in order to perturb the action information. These action words are the words that appear in the action triples extracted from the prototype conversation using OpenIE 3 (Angeli et al., 2015; Chen and Yang, 2021b). At step t, we add a small amount of Gaussian noise to the action words wi in the prototype conversation: qa(wi,t+1|wi,t) = N(wi,t+1; \u221a (1\u2212 \u03b2t)wi,t, \u03b2tI)\n(1)\nwhere \u03b2t is the amount of noise added at step t.\nSoft-Masking Utterances For soft-masking utterances, we only add noise to all the words wi in\n2Here we choose three types of widely used structures but future work can extend this to incorporate other types of conversation structures.\n3https://github.com/philipperemy/ Stanford-OpenIE-Python\none utterance u in the prototype conversation so that the dialogue acts of the utterance are perturbed. The utterance to mask is consistent for all the steps for one prototype conversation, while we randomly reselect the utterance to mask in different epochs. At step t, we add a small amount of Gaussian noise to all the words wi in the utterance u: qu(wi,t+1|wi,t) = N(wi,t+1; \u221a (1\u2212 \u03b2t)wi,t, \u03b2tI)\n(2)\nShuffling Discourse Relations We further randomly switch the positions of two random utterances ui and uj in the conversation to perturb the discourse relations in the prototype conversation. At step t, we randomly shuffle X0:\nqr(Xt+1|Xt) = Shuffle(Xt) (3)\nIn practice, we apply these three types of noises at the same time at every diffusion step t to model q(Xt+1|Xt). Note that the forward process does not contain any trainable parameters."
        },
        {
            "heading": "4.2.3 Diffusion Process",
            "text": "After corrupting the hidden representations of the prototype conversation X0 to latent variables X1:T , we then gradually denoise XT to X\u03020 through diffusion steps, X\u0302t\u22121 = p(X\u0302t|\u03b8), where \u03b8 is the learned parameter to model the state transition. In practice, the transition is modeled by transformers. After every diffusion step t \u2208 (0, T ], we minimize the cross entropy between the predicted conversation from X\u0302t\u22121 and the ground truth conversation Cg:\nLt = CE(f(X\u0302t\u22121), Cg; \u03b8), t \u2208 (0, T ] (4)\nTo generate desired conversation in a more controlled way, we incorporate three levels of conversation-structured information introduced in Section 4.2.1 to control the generation and we describe each of them in detail below.\nAction Triples By incorporating action triples information, the conversation could include more details with diverse desired actions/events from the token-level. During training, we first extract such action triples A = {a0, ..., am} from the ground truth conversation Cg using OpenIE, where ai is a \u201c(WHO, DOING, WHAT)\u201d triple. We then represent every triple ai \u2208 A with the average of the output embeddings from the above F (.). In order to encourage the generated conversation to describe the given actions triples, after every diffusion step\nX\u0302t\u22121 = p(X\u0302t|\u03b8), t \u2208 (ta, T ], we also minimize the sum of cosine distances between the average of every token\u2019s representation in X\u0302t\u22121 and every action triple\u2019s representation:\nLat = \u2211\ni\n||avg(X\u0302t\u22121), F (ai)||cos, t \u2208 (ta, T ]\n(5)\nDialogue Acts Editing the generated conversation with the desired dialogue acts information could encourage the generated conversation to be more diverse and more like human from the utterance-level (Allen and Core, 1997; Sacks et al., 1978). During training, we first extract the dialogue acts D = {d0, ..., dm} in every ground truth conversation Cg with a learned linear dialogue acts classifier 4, where di is a one-hot vector that indicates the dialogue act for i-th utterance. We sum them up to represent the dialogue acts distribution in the ground truth conversation, d\u0302 = \u2211 i di.\nIn order to encourage the generated conversation to include utterances with the given dialogue acts, we force the generated conversation to have the same dialogue acts distribution with the ground truth conversation. Specifically, after every diffusion step, X\u0302t\u22121 = p(X\u0302t|\u03b8), t \u2208 (td, ta], we first predict the dialogue acts Dt\u22121 = {dt\u221210 , ..., dt\u22121n } for every utterance in X\u0302t\u22121 with the learned classifier, where dt\u22121i is the predicted vector that includes the probabilities of the i-th utterance is classified as different dialogue acts. We sum the predictions d\u0302t\u22121 = \u2211 i d t\u22121 i , where the j-th element in d\u0302t\u22121 denotes the total number j-type utterance in the conversation. We then minimize the L2 distance between the ground-truth distribution and the predicted distribution from the generated conversation:\nLdt = ||d\u0302, d\u0302t\u22121||2, t \u2208 (td, ta] (6)\nDiscourse Relations Controlling the generated conversation with the discourse relation information would encourage the utterances in it to be more related, leading to a more coherent conversation from a conversation level. During training, we first pre-train a discourse parsing model on a humanannotated multiparty dialogue corpus (Asher et al., 2016b) following (Shi and Huang, 2018). 5. Via\n4We use the hidden representations from the above F (.) as inputs and we achieve the accuracy with 81.6% on Switchboard corpus, which is comparable to the state-of-the-art results (Raheja and Tetreault, 2019).\n5We treat the hidden representations from F (.) as the input. We achieve 0.781 F1 score on link predictions and 0.575 F1\nthis parser, we extract the discourse relation matrix M \u2208 Rm\u00d7m\u00d7k from the ground truth conversation, where m is the number of utterances and k is the total number of different discourse relations. We sum the matrix in the first two dimensions to represent the discourse relation distribution in the ground truth conversation: r\u0302 = \u2211 i \u2211 j Mi,j,k, where the l-th element in r\u0302 means the total number of l-th discourse relation in the conversation.\nWe regularize the generated conversation to have the same discourse relation distribution with the ground truth conversation. After every diffusion step, X\u0302t\u22121 = p(X\u0302t|\u03b8), t \u2208 (0, td], we first predict the discourse relation matrix Mt\u22121 \u2208 Rn\u00d7n\u00d7k with the pre-trained parser. We also sum Mt in the first two dimensions r\u0302t\u22121 = \u2211 i \u2211 j Mi,j,k and minimize the L2 distance between it and the ground-truth distribution:\nLrt = ||r\u0302, r\u0302t\u22121||2, t \u2208 (0, td] (7)\nObjectives In practice, we sequentially use all three conversation structures, from lower levels to higher levels, i.e., action triples \u2192 dialogue acts \u2192 discourse relations. The order is selected through an ablation study (in Section 5.4). During training, we minimize the loss:\nL = T\u2211\nt=1\nLt + T\u2211\nt=ta\nLat + ta\u2211\nt=td\nLdt + td\u2211\nt=1\nLrt (8)"
        },
        {
            "heading": "5 Experiments",
            "text": ""
        },
        {
            "heading": "5.1 Datasets and Baselines",
            "text": "We perform experiments on two widely-used datasets, SAMSum (Gliwa et al., 2019) and DialogSum (Chen et al., 2021), as shown in Table 1. They are originally introduced for conversation summarization, which contains open-domain reallife daily conversations with human written summaries. In this work, we reverse the datasets where\nscore on relation classifications, which are comparable to the state-of-the-art results (Shi and Huang, 2018).\nwe utilize the summary as input and learn the generation model to generate the long conversation. During pre-processing, we add a special token (\u201c<s>\u201d) to indicate the begging of every utterance. We truncate the conversation into 800 tokens.\nWe compare our Diffuse-CG framework with several baselines:\n\u2022 BART-base (Lewis et al., 2020): We use BART-base as our backbone model. The input only contains the summary.\n\u2022 BART-Concat: We improve pure BART by directly concatenating controlling information including the action triples, dialogue acts and discourse relations to the end of the input summary.\n\u2022 Diffuse-CG-Con: We use a framework similar to our Diffuse-CG while the different levels of information are combined concurrently instead of sequentially."
        },
        {
            "heading": "5.2 Experimental Setting",
            "text": "We initialize the prototype conversation generation model with BART-base and learn the model for 20 epochs with 3e-5 learning rate, and 0.15 warm-up ratio. The batch size is 4. For the DiffuseCG, we utilize a 4-layer transformer whose hidden dimension is 512 to model p(.|\u03b8). We set the diffusion steps to be T = 500 (ta = 300 and td = 100, which means that we use 300 steps for action triples, 100 steps for dialogue acts, and 100 steps for discourse relations). We follow (Li et al., 2022b) to use an sqrt schedule in the forward process. The learning rate is set to be 3e-4 with a 0.1 warm-up ratio. The batch size is 4 and we train Diffuse-CG for 200k iterations. During inference, the beam size is set to 4. We perform all the experiments on 4 NVIDIA V100 GPUs. For diffuse-CG, the training takes around 4.8 hours, and the inference speed is 1.4second per dialogue generation."
        },
        {
            "heading": "5.3 Results",
            "text": "Automatic Evaluation We first evaluated all the models with:\n\u2022 ROUGE scores (Lin and Och, 2004) measure the n-gram overlap between the generated conversation and the ground-truth conversation.\n\u2022 Action coverage rate, Dialogue acts coverage rate, discourse Relation coverage measure the\ncoverage rate of the actions triples, dialogue acts, and discourse relations in the generated conversation compared to the ground-truth conversation.\n\u2022 LM score measure the fluency by computing the perplexity from a GPT-2 pre-trained on SAMSum and DialogSum.\n\u2022 Length measures the length of the generated conversation.\nAs shown in Table 2 and Table 3, we find that after adding the controlling structured information directly to the input, BART-Concat is generating better conversations compared to naive BART. This shows that our introduced conversation-structured\nguidance can help conversation generation by providing effective information. By applying the diffusion process, Diffuse-CG-Con and Diffuse-CG further consistently improve the performances (e.g., 8%/28%/7% improvements in ROUGE scores), which shows the effectiveness of our introduced controllable conversation generation framework. Because it makes better use of both the input summary and the controlling signals by first generating the prototype conversation and then further enriching it with the extra information using a diffusion process, which prevents the distraction from different information. Among different noise and control signals, the soft-masking action words noise and action triples diffusion worked the best, followed by shuffling discourse relations with discourse diffusion and then soft-masking utterances noise with dialogue acts diffusion. Compared to the concurrent way, our sequential Diffuse-CG works the best, indicating that editing the long conversation with a suitable order (from token levels to utterance levels and to conversation levels) is important. By gradually incorporating different levels of structure, the overall performances are improving (e.g., the ROUGE scores are increasing from 38.12/18.45/27.38 to 40.54/19.43/28.57), suggest-\ning that the sequential diffusion steps can edit the prototype conversation to higher qualities step by step, and all the introduced structures are making contributions.\nHuman Evaluation We conduct a human evaluation to evaluate the generated conversations qualitatively. We ask Amazon Mechanical Turk to rank the quality of 100 generated conversations (randomly sampled) from a given summary with 4 different models. Specifically, we ask them to rank them in terms of Coherency (the generated conversation is logical and consistent), Fluency (the generated conversation is reader-friendly) and Factualness (the generated conversation is not changing the fact from the given short descriptions). To increase annotation quality, we require turkers to have a 98% approval rate with over 10,000 approved tasks for their previous work. The pay rate was 0.5$ per hit. The rank for every summary was aggregated by majority voting. The Intra-Class Correlation (ICC1k) was 0.511, indicating moderate agreement (Koo and Li, 2016)). The average rank is shown in Table 4. Our Diffuse-CG achieves the best average rankings, indicating the effectiveness of incorporating conversation structures."
        },
        {
            "heading": "5.4 Ablation Study",
            "text": "This part describes our ablation studies on how our introduced linguistic-informed noises and the diffusion orders affect the model performances.\nNoise Strategy We first visualize the performances of Diffuse-CG with different types of noise\nstrategy in Table 5. Gaussian Noise adds Gaussian noise to all the tokens in the prototype conversation in the forward process, following previous work (Li et al., 2022b), while our introduced Linguisticinformed Noise only adds Gaussian noise to action words and random utterance as well as shuffling the conversations. Our introduced noise shows significantly better performances on SAMSum test set, indicating that our introduced noise strategy which considers the conversation structures is providing more appropriate perturbation to the prototype conversation for the diffusion process. This is because our strategy could provide flexibility to edit the prototype conversation as well as preserve the prior knowledge in the prototype conversation.\nDiffusion Orders In terms of the impact of different orders to add different structured information during the diffusion process, as shown in Table 6, we find that the best overall performance is achieved by the order: action triples \u2192 dialogue acts \u2192 discourse relations, from a lower level (token/action level) to higher level (conversationlevel). This might be because, in this structured order, more specific information can be introduced at the early stages when the conversations are more flexible to adopt a large amount of detailed information. When the conversation has enough information, it is then more effective to operate at a higher level like the relations between different utterances. This also indicates the effectiveness of structured ordering in general, especially when there are multiple levels of controlling information."
        },
        {
            "heading": "5.5 Case Study",
            "text": "We further visualize the intermediate outputs in the diffusion process of our Diffuse-CG to interpret the generation process in Figure 2. As it shows, the prototype conversation is short and coarse. When the action information is incorporated through the first diffusion stage, the conversation is enriched by more specific action information like \u201cAmanda text Larry\u201d. After the dialogue act diffusion stage, the conversation is further modified to have utterance with dialogue acts like backchannel (\u201cUrgh. All right\u201d). At last, with the discourse relation information being utilized, the conversation is more interactive and coherent with more intra-utterance relations like QA pairs. These coarse-to-fine steps show how Diffuse-CG is editing and generating better and longer conversations over time."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this work, we introduce a novel controllable conversation generation framework that utilizes different levels of conversation structures to generate long and coherent conversations based on a given short description. Specifically, we first generate the prototype conversation and then enrich it with structure information like action triples, dialogue acts, and discourse relations, together with novel linguistic-informed noises for further adapting diffusion models to generate conversations. Experiments on SAMSum and DialogSum show the effectiveness of our framework by significantly improving over the baselines. Our proposed method also\nprovides interpretability of how the model is gradually generating longer and better conversations."
        },
        {
            "heading": "7 Limitation",
            "text": "In this work, we mainly leverage control guidance such as action triples, dialogue acts, and discourse relations in structured forms that are extracted automatically from the corpus for training. We encourage future work to explore how to incorporate control information in natural language forms (for example, the natural language descriptions of the action information instead of triples). We also compose multiple modules (like the prototype generation, discourse classifier, etc.) to generate the final conversation which might lead to a larger error cascade if there is some early noise. So future work might explore how to make the pipeline learned in an end-to-end manner. What\u2019s more, we mainly focus on using three major conversation structures to help the entire conversation generation, future work might continue to explore other types of linguistic and human knowledge to further improve the conversation generation qualities."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank members of John Thickstun, the SALT Lab, and reviewers for their helpful feedback. This work was supported in part by an Amazon Faculty Research Award and an NSF grant IIS-2247357."
        },
        {
            "heading": "A For every submission:",
            "text": ""
        },
        {
            "heading": "3 A1. Did you describe the limitations of your work?",
            "text": "Section 6\nA2. Did you discuss any potential risks of your work? Not applicable. Left blank."
        },
        {
            "heading": "3 A3. Do the abstract and introduction summarize the paper\u2019s main claims?",
            "text": "Section 1\n7 A4. Have you used AI writing assistants when working on this paper? Left blank."
        },
        {
            "heading": "B Did you use or create scientific artifacts?",
            "text": "Not applicable. Left blank.\nB1. Did you cite the creators of artifacts you used? No response.\nB2. Did you discuss the license or terms for use and / or distribution of any artifacts? No response.\nB3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)? No response.\nB4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? No response.\nB5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? No response.\nB6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be. No response.\nC 3 Did you run computational experiments? Section 4"
        },
        {
            "heading": "3 C1. Did you report the number of parameters in the models used, the total computational budget",
            "text": "(e.g., GPU hours), and computing infrastructure used? Section 4\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance."
        },
        {
            "heading": "3 C2. Did you discuss the experimental setup, including hyperparameter search and best-found",
            "text": "hyperparameter values? Section 4"
        },
        {
            "heading": "3 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary",
            "text": "statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run? Section 4"
        },
        {
            "heading": "3 C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did",
            "text": "you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE, etc.)? Section 4\nD 3 Did you use human annotators (e.g., crowdworkers) or research with human participants? Section 4"
        },
        {
            "heading": "3 D1. Did you report the full text of instructions given to participants, including e.g., screenshots,",
            "text": "disclaimers of any risks to participants or annotators, etc.? Section 4"
        },
        {
            "heading": "3 D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)",
            "text": "and paid participants, and discuss if such payment is adequate given the participants\u2019 demographic (e.g., country of residence)? Section 4"
        },
        {
            "heading": "3 D3. Did you discuss whether and how consent was obtained from people whose data you\u2019re using/curating? For example, if you collected data via crowdsourcing, did your instructions to",
            "text": "crowdworkers explain how the data would be used? Section 4\nD4. Was the data collection protocol approved (or determined exempt) by an ethics review board? Not applicable. Left blank.\nD5. Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? Not applicable. Left blank."
        }
    ],
    "title": "Controllable Conversation Generation with Conversation Structures via Diffusion Models",
    "year": 2023
}