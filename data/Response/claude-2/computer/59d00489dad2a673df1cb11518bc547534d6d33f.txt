 Here are 5 possible future research ideas after reading this paper:

1. Investigate other downsampling strategies besides the commonly used factors of 2, 3, and 4. The paper currently only explores these scaling factors but other downsampling rates may provide additional benefits. 

2. Explore alternate encoder architectures besides ViT-Base. The performance gains from the scale invariance may further improve with more advanced encoders.

3. Conduct additional experiments on more diverse and challenging low-resolution image datasets. The current evaluations are limited to a few facial expression datasets. 

4. Study the effects of different pre-training durations. The paper notes the pre-training may have been inadequate on some datasets - longer pre-training may lead to better performance.

5. Apply the scale invariant representations learned by SRMAE to other downstream tasks such as object detection, segmentation, etc. The current evaluations are limited to image classification.