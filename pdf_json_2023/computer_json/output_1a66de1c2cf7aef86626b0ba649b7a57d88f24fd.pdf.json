{
    "abstractText": "Mobile edge caching (MEC) is a promising technique to improve the quality of service (QoS) for mobile users (MU) by bringing data to the network edge. However, optimizing the crucial QoS aspects of message freshness and service promptness, measured by age of information (AoI) and service delay, respectively, entails a tradeoff due to their competition for shared edge resources. This paper investigates this tradeoff by formulating their weighted sum minimization as a sequential decision-making problem, incorporating high-dimensional, discrete-valued, and linearly constrained design variables. First, to assess the feasibility of the considered problem, we characterize the corresponding achievable region by deriving its superset with the rate stability theorem and its subset with a novel stochastic policy, and develop a sufficient condition for the existence of solutions. Next, to efficiently solve this problem, we propose a mixed-order drift-plus-penalty algorithm by jointly considering the linear and quadratic Lyapunov drifts and then optimizing them with dynamic programming (DP). Finally, by leveraging the Lyapunov optimization technique, we demonstrate that the proposed algorithm achieves an O(1/V ) versus O(V ) tradeoff for the average AoI and average service delay.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ran Li"
        },
        {
            "affiliations": [],
            "name": "Chuan Huang"
        },
        {
            "affiliations": [],
            "name": "Xiaoqi Qin"
        },
        {
            "affiliations": [],
            "name": "Lei Yang"
        }
    ],
    "id": "SP:23e9d3d86ca2b524e1b9146c1817ebab95127dca",
    "references": [
        {
            "authors": [
                "Ericsson"
            ],
            "title": "Ericsson mobility report",
            "venue": "Feb. 2023. [Online]. Available: https://www.ericsson.com/491da6/assets/local/reports-papers/ mobility-report/documents/2022/ericsson-mobility-report-q4-2022.pdf.",
            "year": 2023
        },
        {
            "authors": [
                "J. Yao",
                "T. Han",
                "N. Ansari"
            ],
            "title": "On mobile edge caching",
            "venue": "IEEE Commun. Surv. Tutor., vol. 21, no. 3, pp. 2525\u20132553, thirdquarter 2019.",
            "year": 2019
        },
        {
            "authors": [
                "F. Spinelli",
                "V. Mancuso"
            ],
            "title": "Toward enabled industrial verticals in 5G: A survey on MEC-based approaches to provisioning and flexibility",
            "venue": "IEEE Commun. Surv. Tutor., vol. 23, no. 1, pp. 596\u2013630, firstquarter 2021.",
            "year": 2021
        },
        {
            "authors": [
                "J. Li",
                "F. Lin",
                "L. Yang",
                "D. Huang"
            ],
            "title": "AI service placement for multiaccess edge intelligence systems in 6G",
            "venue": "IEEE Trans. Netw. Sci. Eng., vol. 10, no. 3, pp. 1405\u20131416, May 2023.",
            "year": 2023
        },
        {
            "authors": [
                "S. Zhang",
                "H. Luo",
                "J. Li",
                "W. Shi",
                "X. Shen"
            ],
            "title": "Hierarchical soft slicing to meet multi-dimensional QoS demand in cache-enabled vehicular networks",
            "venue": "IEEE Trans. Wireless Commun., vol. 19, no. 3, pp. 2150\u2013 2162, Mar. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Zhang",
                "J. Li",
                "H. Luo",
                "J. Gao",
                "L. Zhao",
                "X. Sherman Shen"
            ],
            "title": "Lowlatency and fresh content provision in information-centric vehicular networks",
            "venue": "IEEE Trans. Mob. Comput., vol. 21, no. 5, pp. 1723\u20131738, May 2022.",
            "year": 2022
        },
        {
            "authors": [
                "B. Ji",
                "X. Zhang",
                "S. Mumtaz",
                "C. Han",
                "C. Li",
                "H. Wen",
                "D. Wang"
            ],
            "title": "Survey on the Internet of Vehicles: Network architectures and applications",
            "venue": "IEEE Commun. Stand. Mag., vol. 4, no. 1, pp. 34\u201341, Mar. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Z. Zhou",
                "Y. Guo",
                "Y. He",
                "X. Zhao",
                "W.M. Bazzi"
            ],
            "title": "Access control and resource allocation for M2M communications in industrial automation",
            "venue": "IEEE Trans. Industr. Inform., vol. 15, no. 5, pp. 3093\u20133103, May 2019.",
            "year": 2019
        },
        {
            "authors": [
                "B. Liu",
                "C. Liu",
                "M. Peng"
            ],
            "title": "Resource allocation for energy-efficient MEC in NOMA-enabled massive IoT networks",
            "venue": "IEEE J. Sel. Areas Commun., vol. 39, no. 4, pp. 1015\u20131027, Apr. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S. Kaul",
                "R. Yates",
                "M. Gruteser"
            ],
            "title": "Real-time status: how often should one update?",
            "venue": "in Proc. IEEE INFOCOM,",
            "year": 2012
        },
        {
            "authors": [
                "B. Liu",
                "X. Xu",
                "L. Qi",
                "Q. Ni",
                "W. Dou"
            ],
            "title": "Task scheduling with precedence and placement constraints for resource utilization improvement in multi-user MEC environment",
            "venue": "J. Syst. Archit., vol. 114, p. 101970, Mar. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Z. Xu",
                "W. Ren",
                "W. Liang",
                "W. Xu",
                "Q. Xia",
                "P. Zhou",
                "M. Li"
            ],
            "title": "Schedule or wait: Age-minimization for IoT big data processing in MEC via online learning",
            "venue": "Proc. IEEE INFOCOM, London, United Kingdom, 2022, pp. 1809\u20131818.",
            "year": 2022
        },
        {
            "authors": [
                "Z. Yang",
                "S. Bi",
                "Y.-J.A. Zhang"
            ],
            "title": "Dynamic offloading and trajectory control for UAV-enabled mobile edge computing system with energy harvesting devices",
            "venue": "IEEE Trans. Wirel. Commun., vol. 21, no. 12, pp. 10 515\u201310 528, Dec. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "F. Guo",
                "H. Zhang",
                "H. Ji",
                "X. Li",
                "V.C. Leung"
            ],
            "title": "Joint trajectory and computation offloading optimization for UAV-assisted MEC with NOMA",
            "venue": "Proc. IEEE INFOCOM WKSHPS, Paris, France, May 2019, pp. 1\u20136.",
            "year": 2019
        },
        {
            "authors": [
                "X. Ma",
                "H. Sun",
                "R.Q. Hu"
            ],
            "title": "Scheduling policy and power allocation for federated learning in NOMA based MEC",
            "venue": "Proc. IEEE GLOBE- COM, Taipei, Taiwan, Dec. 2020, pp. 1\u20137.",
            "year": 2020
        },
        {
            "authors": [
                "Z. Ding",
                "J. Xu",
                "O.A. Dobre",
                "H.V. Poor"
            ],
            "title": "Joint power and time allocation for NOMA\u2013MEC offloading",
            "venue": "IEEE Trans. Veh. Technol., vol. 68, no. 6, pp. 6207\u20136211, June 2019.",
            "year": 2019
        },
        {
            "authors": [
                "C. Zhao",
                "S. Xu",
                "J. Ren"
            ],
            "title": "AoI aware wireless resource allocation of energy harvesting powered MEC systems",
            "venue": "IEEE Internet Things J., vol. 14, no. 8, pp. 7835\u20137849, Dec. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "R. Talak",
                "E. Modiano"
            ],
            "title": "Age-delay tradeoffs in single server systems",
            "venue": "Proc. IEEE ISIT, Xi\u2019an, China, Oct. 2019, pp. 340\u2013344.",
            "year": 2019
        },
        {
            "authors": [
                "J. Cao",
                "X. Zhu",
                "Y. Jiang",
                "Z. Wei",
                "S. Sun"
            ],
            "title": "Information age-delay correlation and optimization with finite block length",
            "venue": "IEEE Trans. Commun., vol. 69, no. 11, pp. 7236\u20137250, Nov. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "R. Talak",
                "E.H. Modiano"
            ],
            "title": "Age-delay tradeoffs in queueing systems",
            "venue": "IEEE Trans. Inf. Theory, vol. 67, no. 3, pp. 1743\u20131758, Mar. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S. Zhang",
                "L. Wang",
                "H. Luo",
                "X. Ma",
                "S. Zhou"
            ],
            "title": "AoI-delay tradeoff in mobile edge caching with freshness-aware content refreshing",
            "venue": "IEEE Trans. Wireless Commun., vol. 20, no. 8, pp. 5329\u20135342, Aug. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "3GPP"
            ],
            "title": "LTE; evolved universal terrestrial radio access (E-UTRA); physical channels and modulation (3GPP TS 36.211 version 12.9.0 Release 12)",
            "venue": "Apr. 2017. [Online]. Available: https://www.etsi.org/deliver/ etsi ts/136200 136299/136211/12.09.00 60/ts 136211v120900p.pdf",
            "year": 2017
        },
        {
            "authors": [
                "3GPP"
            ],
            "title": "3rd generation partnership project; technical specification group radio access network; NR; overall description; stage 2 (Release 15)",
            "venue": "Dec. 2018. [Online]. Available: http://www.3gpp.org/ftp//Specs/archive/ 38 series/38.300/38300-f00.zip",
            "year": 2018
        },
        {
            "authors": [
                "F. Tang",
                "Y. Zhou",
                "N. Kato"
            ],
            "title": "Deep reinforcement learning for dynamic uplink/downlink resource allocation in high mobility 5G HetNet",
            "venue": "IEEE J. Sel. Areas Commun., vol. 38, no. 12, pp. 2773\u20132782, Dec. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "M.J. Neely"
            ],
            "title": "Stochastic network optimization with application to communication and queueing systems",
            "year": 2010
        },
        {
            "authors": [
                "L. M"
            ],
            "title": "Puterman, Markov decision processes: discrete stochastic dynamic programming",
            "year": 2014
        },
        {
            "authors": [
                "D.P. Bertsekas"
            ],
            "title": "Dynamic programming and optimal control: volume I",
            "venue": "Athena scientific Belmont,",
            "year": 2012
        },
        {
            "authors": [
                "R. Li",
                "C. Huang",
                "X. Qin",
                "S. Jiang",
                "N. Ma",
                "S. Cui"
            ],
            "title": "Coexistence between task-and data-oriented communications: A whittle\u2019s index guided multi-agent reinforcement learning approach",
            "venue": "arXiv preprint arXiv:2205.09377, May 2022.",
            "year": 2022
        },
        {
            "authors": [
                "R. Li",
                "C. Huang",
                "X. Qin",
                "S. Jiang"
            ],
            "title": "Multicast scheduling over multiple channels: A distribution-embedding deep reinforcement learning method",
            "venue": "arXiv preprint arXiv:2205.09420, May 2022.",
            "year": 2022
        },
        {
            "authors": [
                "A.J. Kleywegt",
                "J.D. Papastavrou"
            ],
            "title": "The dynamic and stochastic knapsack problem",
            "venue": "Oper. Res., vol. 46, no. 1, pp. 17\u201335, Feb. 1998.",
            "year": 1998
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Mobile edge caching (MEC), age of information (AoI), linear Lyapunov drift, quadratic Lyapunov drift, mixedorder drift-plus-penalty\nI. INTRODUCTION\nIn recent years, mobile edge caching (MEC) has emerged as a promising solution to tackle the challenges posed by the exponential growth of mobile users (MUs) and the corresponding data demands [1]. To elaborate, MEC enables the base stations (BS) at the network\u2019s edge to provide both the uplink and downlink accesses for nearby MUs, which increases the access capacity and network throughput [2]\u2013[4]. Additionally, MEC deploys caches at the BS to store frequently requested messages, thereby reducing message delivery latency and enhancing the quality of service (QoS) for MUs [5], [6]. Due to the aforementioned advantages, MEC has gained significant popularity in various applications, such as Internet of Vehicles (IoV) [7], industrial automation networks [8], and Internet of Things (IoT) [9]. For example, in IoV networks [7], MEC technique utilizes roadside units or vehicles to access all the\nThis work was submitted in part to 2023 IEEE Global Communications Conference Workshops.\nR. Li and C. Huang are with the School of Science and Engineering and the Future Network of Intelligence Institute, The Chinese University of Hong Kong, Shenzhen 518172, China (e-mails: ranli2@link.cuhk.edu.cn; huangchuan@cuhk.edu.cn).\nX. Qin is with the State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China (e-mail: xiaoqiqin@bupt.edu.cn).\nL. Yang is with the Department of Computer Science and Engineering, University of Nevada, Reno, NV 89557 USA (e-mail: leiy@unr.edu).\nsurrounding vehicles and cache real-time traffic information. This cached information is fetched by other nearby vehicles to ensure timely route planning and enhance driving safety. Moreover, since the BSs in MEC only need to serve their nearby MUs and can have modest hardware configurations [2], the deployment of MEC generally incurs low infrastructural costs, which makes MEC highly adaptable in more and more applications and positions it to play a pivotal role in shaping the future of mobile networks.\nTo ensure the efficient adoption of MEC in practical applications, the key issue is to properly schedule limited cache storages and communication resources at the BS to simultaneously meet various QoS demands from the nearby MUs. Specifically, two critical and fundamental QoS demands that need to be addressed across various applications are message freshness and service promptness [5]\u2013[9]. For instance, message freshness and service promptness are crucial in ensuring safe driving in IoV [7], where every vehicle needs to receive timely responses from roadside units regarding the up-to-date information about its surroundings. Additionally, in industrial automation networks [8], message freshness and service promptness play a vital role in detecting abnormal situations, where the sensors need to constantly monitor the status of industrial processes and promptly transmit this information to the control center to ensure timely detection and response to emergencies. Message freshness is usually quantified by age of information (AoI) [10], which measures the elapsed time since the generation of the MU\u2019s previously received message, and service promptness is measured by service delay [2], which captures the time duration from the generation of a request from one MU to the request being served by the BS. Given the significant importance of both the message freshness and service promptness, there is a desire to concurrently attain optimal AoI and service delay in MEC. Unfortunately, achieving this goal is often infeasible, since optimizing either one of these two metrics requires competitively utilization of shared communication resources at the BS [5], [6]. Hence, it becomes crucial to thoroughly investigate the relationship between AoI and service delay in MEC and develop scheduling policies that strike an proper balance between them."
        },
        {
            "heading": "A. Related Works",
            "text": "The existing works on the scheduling problem in MEC cover a wide range of applications, including IoT [11], [12], IoV [13], [14], non-orthogonal multiple access (NOMA) [15], [16], and energy harvesting networks [17]. These studies\nar X\niv :2\n30 4.\n08 78\n1v 2\n[ ee\nss .S\nY ]\n2 1\nA ug\n2 02\n3\n2 primarily addressed the problem of determining \u201cwhen to cache\u201d the messages requested by MUs, aiming to optimize AoI or other relevant metrics. In [11], the authors studied an IoT MEC network with multiple users and multiple edge servers, where the users randomly upload various tasks to the edge servers and the servers utilize shared computation resources to process the uploaded tasks. To optimize the resource utilization, the authors proposed a heuristic resource scheduling policy. In [12], the authors defined the age of data (AoD) to measure the quality of big data analytics in IoT MEC networks and proposed a Multi-armed Bandit (MAB) based online learning algorithm to minimize AoD. In [13] and [14], the authors studied an unmanned aerial vehicle (UAV)-assisted MEC scenario, and addressed the trajectory optimization and computation offloading by using perturbed Lyapunov optimization and successive convex approximation, respectively. In [15], the authors leveraged federated learning (FL) in NOMA-based MEC and used graph theory to improve the communication efficiency of FL and to accelerate the model convergence. In [16], the authors discussed the power and time allocation in NOMA-assisted MEC and derived the closed-form expression for the optimal MEC offloading policy. In [17], the authors focused on the edge resource utility maximization in an energy-harvesting powered MEC network, and proposed a Lyapunov-based algorithm to schedule the edge resources and satisfy the AoI constraints. Although the aforementioned works demonstrated notable AoI improvements for various applications, they primarily scheduled the resources for AoI minimization and neglected to consider the impact of service delay on individual MUs. This oversight may lead to a QoS degradation for MUs, especially in MEC networks with a heavy request load and limited edge resources, where some MUs may never be served. Therefore, the problem of determining \u201cwhen to serve\u201d these MUs to effectively reduce the service delay becomes a crucial problem that requires further investigations.\nRecently, there has been a surge of interests in investigating the tradeoff between AoI and service delay in MEC networks, considering both the issues of \u201cwhen to cache\u201d and \u201cwhen to serve\u201d. In [18], the authors studied a MEC system, where one source node (SN) generates time-sensitive messages and only one channel is available for transmitting these messages to the MUs, and characterized the optimal AoI-delay region theoretically. In [19], the authors also considered the single SN and single channel scenario and derived the closed-form expressions of average AoI and peak AoI (PAoI) to characterize the AoI-delay and PAoI-delay regions, respectively. In [20], the authors further considered a scenario with a single SN and multiple channels, proposing three fundamental methods, i.e., resource ordering, routing, and distribution design for resource service time, to optimize the AoI-delay tradeoff. In [21], the authors discussed the scenario with multiple SNs and one single channel, proposing a first come first serve (FCFS) method to serve the MUs, achieving a near-optimal AoIdelay tradeoff. It is important to note that while the existing literature on the AoI-delay tradeoff in MEC networks has made significant progress, the continuous-time models adopted in these works may not be suitable for practical MEC systems\nthat operate in discrete time. Additionally, there is currently no research specifically addressing the scheduling problem for the scenario with multiple SNs and multiple channels, which is a most general scenario in practical applications."
        },
        {
            "heading": "B. Main Contributions",
            "text": "This paper focuses on a general discrete-time MEC network that encompasses one BS and multiple nearby SNs and MUs. The BS is responsible for scheduling multiple (time-division) channels to fetch time-sensitive messages from the SNs via uplinks or to serve the MUs by transmitting the requested messages from its local cache via downlinks. In this context, there exists a tradeoff between the AoI and the service delay, since the uplinks and downlinks in this MEC network share the same group of channels, which creates a competitive relationship between the two performance metrics. The main objective of this paper is to investigate this intricate tradeoff and develop a scheduling policy that achieves an optimal balance between AoI and service delay. The main contributions of this paper are summarized as follows:\n\u2022 We formulate the joint AoI and delay optimization for the MEC network as a sequential decision-making problem, whose design variables are high-dimensional, discretevalued, and linearly constrained. However, to determine the achievable region or to validate the solution existence for this problem is NP-complete. To address this challenge, we characterize the superset and subset of the achievable region: First, we utilize the rate stability theorem to derive a superset of this region; then, we develop a novel stochastic policy to obtain a subset of this region, which is validated to be tight and possess the same set volume as the achievable region under specific conditions; finally, we leverage this subset to establish a sufficient condition for the solution existence of the considered problem. \u2022 We propose an innovative Lyapunov drift optimization method to efficiently solve the formulated sequential decision-making problem, which is challenging due to the non-linear property of the objective function. First, we construct one linear (first-order) and one quadratic (second-order) Lyapunov functions for the AoI and the request queues, respectively. Then, we calculate the Lyapunov drifts for these functions and use properly designed weights to combine the two drifts with a penalty term, resulting in a mixed-order drift-plus-penalty formula. Finally, we employ dynamic programming (DP) to optimize this formula and derive the schedule decisions. Furthermore, by adopting the Lyapunov optimization technique, we provide theoretical evidence that the average AoI and average service delay achieved by our algorithm exhibit an O(1/V ) versus O(V ) tradeoff.\nThe remainder of this paper is organized as follows. In Section II, we present the system model and formulate the scheduling problem. Section III analyzes the achievable region of the problem. In Section IV, we propose the mixed-order drift-plus-penalty algorithm and present theoretical evaluations of its performance. In Section V, we present simulational\n3 Local cache Downlink\ntransmitters\nUplink\ntransmissions\nDownlink\ntransmissions\nAoI\nvector\nRequest\nqueues\nRequests\nData flow Control flow\nRequest flow Uplink\nschedule\nCached\ndata\nSlot N-1\nSlot 1\nSlot N\nNo transmission\nMessage M\nUplink transmitter MSN M\nSlot N-1\nSlot 1\nSlot N\nNo transmission\nMessage 2\nUplink transmitter 2SN 2\nSlot N-1\nSlot 1\nSlot N\nNo transmission\nMessage 1\nUplink transmitter 1SN 1\nCached\nmessages\nRequest 2 Request 1 Idle Slot 1 Downlink scheduleSlot\nscheduler\nRequest 2 Request 1 Idle Slot 2\nRequest 2 Request 1 Idle Slot N\nBS\nMU 1\nMU 2\nFigure 1: System model for mobile edge caching network.\nevaluations of the proposed algorithm. Finally, Section VI concludes this paper."
        },
        {
            "heading": "II. SYSTEM MODEL AND PROBLEM FORMULATION",
            "text": "This section introduces the system model, including the transmission and information update models. Then, we define the average AoI and average service delay for the considered MEC system and formulate the corresponding scheduling problem."
        },
        {
            "heading": "A. System Model",
            "text": "Consider a MEC network, as depicted in Fig. 1, which consists of M SNs, one BS, and multiple MUs. The SNs are located at M different positions to monitor specific events and continuously pack the up-to-date monitored contents into M messages, denoted as M = {1, 2, . . . ,M}. The BS collects these messages from the SNs through wireless uplinks, stores them at its local cache, and tracks their ages. The MUs randomly send requests to the BS for downloading some of the messages in M, and the BS queues these requests and selectively serves them by transmitting the corresponding cached messages through wireless downlinks.\nAs illustrated in Fig. 2, the MEC operates on a frame-based mechanism, where the aforementioned processes of message uploading, request queueing, and message downloading occur at the beginning of each frame. Moreover, each frame is composed of N consecutive slots1. Within each frame, each slot can be allocated for either an uplink transmission from the SN to the BS or a downlink transmission from the BS to the MU. It is important to note that the allocations of slots within each frame are determined by the slot scheduler of the BS at the beginning of each frame. Additionally, a single uplink or downlink transmission may span multiple slots within a frame.\n1In LTE [22], each frame consists of 20 slots (N = 20); while in 5G NR [23], the frame structure is flexible, and N is set as 10 \u00b7 2i with i = 0, 1, 2, \u00b7 \u00b7 \u00b7.\n1) Transmission model: In this part, we present the details about the uplink and downlink transmissions in the MEC network and derive the number of slots required for the transmission of each message.\nUplink transmission: The uplink channels between the SNs and the BS are considered to be quasi-static over each frame and experience slow variations across adjacent frames [24]. Specifically, we denote the channel power gain of the uplink from the mth SN to the BS within the tth frame as gULm (t) and model it as a stationary process with the following transition probability:\nPr{gULm (t+ 1) = g\u2032|gULm (t) = g} = Prm,UL{g\u2032|g}, \u2200t \u2208 Z>0,\nwhere Z>0 is the set of all positive integers, and Prm,UL{g\u2032|g} is a constant representing the probability for gULm (t) transiting from state g to state g\u2032. Then, the maximum transmission rate over this uplink at the tth frame is given as\nB log ( 1 + PSNg UL m (t)\nNBS\n) \u2206T bits per slot, where B, log(\u00b7),\nPSN, NBS, and \u2206T represent the available bandwidth of the MEC network, the logarithm function, the maximum transmission power at the SN1, the noise power at the BS, and the duration of one slot, respectively. Let Lm denote the length (in bits) of the mth message. Then, the number of slots required to upload the mth message over this uplink within the tth frame is calculated as\n\u03baULm (t) \u225c\n\u2308 Lm\nB log ( 1 + PSNg UL m (t)\nNBS\n) \u2206T\n\u2309 , (1)\nwhere \u2308\u00b7\u2309 is the ceiling function and returns the smallest integer greater than or equal to the given number. Finally, we define the maximum value of \u03baULm (t) over m and t as K\u0302, i.e., K\u0302 \u225c maxm\u2208M,t\u2208Z>0 \u03ba UL m (t).\n1In general scenarios like LTE and 5G NR [22], [23], dynamic adjustment of transmission power among different slots or frames is possible. However, for our specific optimization objectives of maximizing message freshness and service promptness, it is evident that prioritizing the utilization of the maximum transmission power is the preferred approach.\n4                   time Assigned to uplinks to refresh the mth message Assigned to downlinks to serve the request in the (m, k)th queue\nthe tth frame\nslot\nthe (t+1)th frame\n( , )m k\nm\n(2,1) (2,3) (3,1) (4,2)2(4,1) (4,1) 1 3(2,1) (4,2)\nFigure 2: An example of frame-based MEC system. The uplink transmissions of the 1st, 2ed, and 3rd messages require 1, 1, and 2 slots, respectively. The downlink transmissions to refresh the (2,1)th, (2,3)th, (3,1)th, (4,1)th, and (4,2)th messages require 1, 3, 1, 2, and 1 slots, respectively.\nDownlink transmission: Similar to the uplink channels, the downlink channels between the BS and the MUs are also considered to be quasi-static over each frame and experience slow variations across adjacent frames. We denote the channel power gain of the downlink from the BS to the uth MU within the tth frame as gDLu (t). Then, the maximum transmission rate over this downlink at the tth frame is calculated as B log ( 1+\nPBSg DL u (t)\nNu\n) \u2206T bits per slot, where PBS and Nu represent the\nmaximum transmission power at the BS and the noise power at the uth MU, respectively. Hence, the number of slots required for sending the mth message over this downlink within the tth frame is given as\n\u03baDLm,u(t) \u225c\n\u2308 Lm\nB log ( 1 + PBSg DL u (t)\nNu\n) \u2206T\n\u2309 . (2)\nIt is important to note that the BS would serve each MU as quickly as possible. Therefore, we assume that the value of gDLu (t) remains constant during the short period (typically spanning several frames) leading up to the uth MU being served, so is \u03baDLm,u(t). Moreover, we define the maximum value of \u03baDLm,u(t) over m, u, and t as K\u0304, i.e., K\u0304 \u225c maxm\u2208M,u,t\u2208Z>0 \u03ba DL m,u(t).\n2) Information update model: We first introduce three types of information stored in the local cache of the BS, i.e., the messages uploaded from the SNs, their corresponding ages, and the requests sent from the MUs.\n\u2022 Cached messages: The BS caches M messages that are most recently uploaded from the SNs; \u2022 AoI vector: The AoI vector stores the ages of the M cached messages. Specifically, the AoI of the mth\nmessage cached in the BS at the beginning of the tth frame is denoted as xm(t) \u2208 Z>0. Then, the AoI vector is defined as x(t) \u225c [x1(t), x2(t), \u00b7 \u00b7 \u00b7 , xM (t)]T ; \u2022 Request queues: For each request from the MUs, it may demand any one of the total M messages and the corresponding downlink transmission may take a duration ranging from 1 to K\u0304 slots. Therefore, the BS employs MK\u0304 request queues to store the requests from all MUs, where the requests demanding the mth message and\nrequiring k slots for downlink transmission are stored in the (m, k)th request queue. We denote the length of the (m, k)th request queue at the tth frame as qm,k(t) and represent these MK\u0304 request queues with a matrix Q(t) \u2208 ZM\u00d7K\u0304\u22650 , where [Q(t)]m,k \u225c qm,k(t), and Z\u22650 represents the set of all non-negative integers.\nAfter the BS makes the slot allocation decision, the above three elements are updated accordingly. We denote the slot allocation decision at the tth frame as A(t) \u2208 ZM\u00d7(K\u0304+1)\u22650 with am,k(t) \u225c [A(t)]m,k: For 1 \u2264 k \u2264 K\u0304, am,k(t) represents the number of requests in the (m, k)th queue to be served over downlinks within the tth frame; for k = K\u0304 + 1, am,k(t) takes value from {0, 1}, with am,K\u0304+1(t) = 1 indicating that the up-to-date version of the mth message is to be uploaded over uplink within the tth frame and am,K\u0304+1(t) = 0 indicating that it is not to be uploaded. With this notation, the information update models for these three elements are described as follows.\n\u2022 Update of cached messages: We replace the cached messages with their most recently uploaded version; \u2022 Update of AoI vector: If the mth message is uploaded over uplink within the tth frame, i.e., am,K\u0304+1(t) = 1, the AoI of the mth message is set to 1; otherwise, it increases by one. In summary, we have\nxm(t+ 1) = xm(t) + 1\u2212 am,K\u0304+1(t)xm(t). (3)\n\u2022 Update of request queues: The update of the request queues depends on the number of arrival and departure requests. For the (m, k)th queue, the number of departure requests in the tth frame is equal to am,k(t). Additionally, the number of arrival requests, denoted as cm,k(t), is modeled as an independent and identically distributed (i.i.d.) random variable across t. We denote its mean value as \u03bbm,k and its probability mass function (pmf) as fm,k. Then, the update rule for qm,k(t) is given as\nqm,k(t+ 1)=max{qm,k(t)\u2212am,k(t), 0}+cm,k(t). (4)\nRemarkably, the slot allocation decision mentioned above are subject to the following constraints: First, the number of served requests in each request queue cannot exceed the\n5 number of its stored requests, i.e.,\nam,k(t) \u2264qm,k(t), (5)\nfor all m \u2208 M, k \u2208 K\u0304, and t \u2208 Z>0, where K\u0304 is defined as K\u0304 \u225c {1, 2, \u00b7 \u00b7 \u00b7 , K\u0304}; second, the slot allocation decision involves allocating \u2211M m=1 \u03ba UL m (t)am,K\u0304+1(t) slots for uplink\ntransmissions and \u2211M\nm=1 \u2211K\u0304 k=1 kam,k(t) slots for downlink\ntransmissions. Therefore, the total number of slots allocated in one frame should not exceed the available slots, i.e.,\nM\u2211 m=1 \u03baULm (t)am,K\u0304+1(t) + M\u2211 m=1 K\u0304\u2211 k=1 kam,k(t) \u2264 N. (6)"
        },
        {
            "heading": "B. Problem Formulation",
            "text": "This work aims to jointly optimize the average AoI and the average service delay of the randomly arrival requests, which are rigorously defined as follows.\nAverage AoI: To serve each request in the (m, k)th queue, the BS first picks the mth message in the local cache and then transmits it to the corresponding MU over downlink. Obviously, the AoI of this served request can be computed as the AoI of the mth message stored in the cache plus one more frame required for the corresponding downlink transmission1, i.e., xm(t) + 1 frames. Meanwhile, according to the slot allocation decision A(t), BS would serve am,k(t) requests in the (m, k)th request queue at the tth frame. Hence, the sum AoI of the requests stored in the (m, k)th queue and served at the tth frame is calculated as am,k(t)(xm(t) + 1). Then, considering the long-term average, the average AoI of all requests stored in MK\u0304 request queues is calculated as\nlim T\u2192\u221e\n\u2211T t=1 \u2211M m=1 \u2211K\u0304 k=1 am,k(t)(xm(t) + 1)\u2211T\nt=1 \u2211M m=1 \u2211K\u0304 k=1 cm,k(t)\n= 1\u2211M\nm=1 \u2211K\u0304 k=1\u03bbm,k lim T\u2192\u221e 1 T T\u2211 t=1 M\u2211 m=1 K\u0304\u2211 k=1 am,k(t)(xm(t) + 1),\nwhere we use the fact limT\u2192\u221e 1T cm,k(t) = \u03bbm,k,\u2211T t=1 \u2211M m=1 \u2211K\u0304 k=1 am,k(t)(xm(t)+1) represents the overall\nAoI of the arrival requests, and \u2211T\nt=1 \u2211M m=1 \u2211K\u0304 k=1 cm,k(t) is\nthe total number of the arrival requests. Average service delay: The service delay for each request is the sum of the queueing delay and the downlink transmission delay. By the queueing theorem [25], the average queueing delay for the requests stored in the (m, k)th queue is equal to the average queue length, which is given as limT\u2192\u221e 1 T \u2211T t=1 qm,k(t). Additionally, the average downlink transmission delay is fixed as one frame. Thus, the average service delay for the requests stored in the (m, k)th queue is limT\u2192\u221e 1T \u2211T t=1 qm,k(t) + 1. Considering the long-term average, the average service delay for all requests stored in\n1We assume that the minimum unit of AoI and service delay is frame, instead of slot. Therefore, the transmission time is approximately considered to be one frame.\nMK\u0304 request queues is calculated as\nlim T\u2192\u221e\n\u2211M m=1 \u2211K\u0304 k=1 \u03bbm,kT (limT\u2192\u221e 1 T \u2211T t=1 qm,k(t) + 1)\u2211T\nt=1 \u2211M m=1 \u2211K\u0304 k=1 cm,k(t)\n= 1\u2211M\nm=1 \u2211K\u0304 k=1 \u03bbm,k lim T\u2192\u221e 1 T T\u2211 t=1 M\u2211 m=1 K\u0304\u2211 k=1 \u03bbm,kqm,k(t) + 1,\nwhere \u2211M\nm=1 \u2211K\u0304 k=1 \u03bbm,kT (limT\u2192\u221e 1 T \u2211T t=1 qm,k(t) + 1)\nrepresents the overall service delay of the arrival requests.\nFrom the above analysis, we now formulate the optimization problem to jointly minimize both the average AoI and the average service delay as the following sequential decisionmaking problem:\n(P1)min A(t) lim T\u2192\u221e\n1\nT T\u2211 t=1 M\u2211 m=1 K\u0304\u2211 k=1 ( V am,k(t)(xm(t)+1)\n+\u03bbm,kqm,k(t) ) (7)\ns.t. (3), (4), (5), (6),\nwhere, V \u2208 R\u22650, with R\u22650 being the set of all non-negative real numbers, is a tradeoff parameter to balance AoI and service delay. Notably, according to [26], any solution to problem (P1) can be characterized by a slot allocation policy \u03c0, which determines the value of A(t) based on the historical information h(t) \u225c (x(1),Q(1),A(1), x(2),Q(2),A(2), \u00b7 \u00b7 \u00b7 ,x(t), Q(t)) and takes the form of \u03c0 : h(t) \u2192 A(t). Therefore, solving problem (P1) is equivalent to finding a feasible slot allocation policy that minimizes (7). Here, a slot allocation policy is considered feasible if the value of A(t) under this policy satisfies the constraints in (3), (4), (5), and (6) for all t \u2208 Zt>0.\nRemark 2.1: The linear constraints in (6) makes it difficult to determine the existence of the solution to problem (P1), which is actually an NP-complete problem [27]. Additionally, coupled with the linear constraints, the high-dimensional and discrete-valued nature of design variable A(t) makes problem (P1) challenging to be solved and the existing tools cannot efficiently address these challenges:\n\u2022 Dynamic programming suffers from the curse of dimensionality and cannot handle the problems with highdimensional and discrete-valued design variables [27]; \u2022 Deep reinforcement learning (DRL) cannot efficiently solve problem (P1) since the linear constraints in (6) strongly limit the feasible actions to only 1/(M(K\u0304+1))! of all the possible ones and make the convergence of DRL during the offline training phase extremely difficult [28], [29]; \u2022 Conventional Lyapunov drift optimization method also cannot be directly applied to solve problem (P1). Specifically, the average AoI term in the objective function (7) is the product of the design variable and a linear function of AoI, which does not fit the linear form that conventional Lyapunov methods are designed to handle [25, Theorem 4.2].\n6 0 1 2 3 4 5 0 1 2 3\n0 2 4 6 8 10 0\n2\n4\n6\n(a) (b)\nBoundary of \u02c6 ( )N Boundary of ( )N Boundary of ( )N\nBoundary of \u02c6 ( )N Boundary of ( )N Boundary of ( )N\n1,2 1,2\n1,3 1,3\nFigure 3: Boundaries of the achievable region \u00b5(N), its superset \u00b5\u0302(N), and its subset \u00b5\u0304(N) with M = 1, K\u0302 = 1, K\u0304 = 3, and \u03bb1,1 = 0. (a) MEC network with N = 10; (b) MEC network with N = 20."
        },
        {
            "heading": "III. ACHIEVABLE REGION ANALYSES",
            "text": "In this section, we first define the achievable region of problem (P1). Then, we characterize this region by studying both its superset and subset. Finally, we develop a sufficient condition to determine whether a solution to problem (P1) exists.\n1) Achievable region of problem (P1): Denote \u03bb \u2208 RM\u00d7K\u0304\u22650 as the mean arrival matrix with [\u03bb](m,k) \u225c \u03bbm,k. Next, with fixed \u03bb and N , we denote the value of problem (P1) under a general slot allocation policy \u03c0 as f\u03c0(\u03bb, N). Then, we define the achievable region of problem (P1) as follows.\nDefinition3.1: The mean arrival matrix \u03bb is achievable if there exists a feasible slot allocation policy \u03c0 such that f\u03c0(\u03bb, N) < \u221e holds. Then, the achievable region of problem (P1), denoted by \u00b5(N), is defined as the set containing all achievable \u03bb, i.e.,\n\u00b5(N) \u225c { \u03bb \u2223\u2223\u2223min\n\u03c0 f\u03c0(\u03bb, N) < \u221e,\u03bb \u2ab0 0\n} . (8)\nRemark 3.1: Based on Definition 3.1, a solution to problem (P1) exists only if the mean arrival matrix \u03bb is achievable. However, validating whether \u03bb is achievable can be extremely difficult, as it involves checking the value of f\u03c0(\u03bb, N) for all feasible slot allocation policies. An alternative approach is to first determine the achievable region of problem (P1) and then check whether \u03bb lies within this region. However, it can be validated that determining the achievable region of problem (P1) is also an NP-complete task [27], compelling us to resort to characterizing this region.\n2) Achievable region characterization: To characterize the achievable region of problem (P1), we derive its superset and subset, and then analyze their properties.\nFirst, we utilize the rate stability theorem [25, Theorem 2.4] to derive a superset of \u00b5(N). According to this theorem, we have the following results: (1) The arrival rate of the (m, k)th request queue in problem (P1) is equal to k\u03bbm,k, where k is the number of required slots to serve one request in this queue and \u03bbm,k is the arrival mean of this queue; (2) the maximum allowable departure rate of MK\u0304 request queues is equal to the number of slots in one frame, i.e., N ; and (3) if a mean arrival matrix \u03bb belongs to the achievable\nregion \u00b5(N), the total arrival rate of all MK\u0304 request queues should not exceed the maximum allowable departure rate, i.e.,\u2211M\nm=1 \u2211K\u0304 k=1 k\u03bbm,k \u2264 N . Based on these results, we define\na set \u00b5\u0302(N) as\n\u00b5\u0302(N) \u225c { \u03bb \u2223\u2223\u2223 M\u2211 m=1 K\u0304\u2211 k=1 k\u03bbm,k \u2264 N,\u03bb \u2ab0 0 } . (9)\nApparently, \u00b5\u0302(N) serves as a superset of \u00b5(N), i.e., \u00b5(N) \u2286 \u00b5\u0302(N). Note that the boundary of \u00b5\u0302(N) is a hyperplane characterized by the equality \u2211M m=1 \u2211K\u0304 k=1 k\u03bbm,k = N (see the blue curves in Fig. 3), indicating that the boundary of the achievable region \u00b5(N) lies below or on this hyperplane.\nThen, we propose the following theorem to derive a subset of \u00b5(N).\nTheorem 3.1: Define a set \u00b5\u0304(N) as\n\u00b5\u0304(N) \u225c { \u03bb \u2223\u2223\u2223K\u0302 + K\u0304\u2211\nk=1\nk\u2308\u03bbk\u2309 \u2264 N,\u03bb \u2ab0 0 } , (10)\nwith \u03bbk \u225c \u2211M\nm=1 \u03bbm,k. Then, \u00b5\u0304(N) is a subset of \u00b5(N), i.e., \u00b5\u0304(N) \u2286 \u00b5(N). Moreover, the set volumes of \u00b5\u0304(N) and \u00b5(N), denoted as Vol(\u00b5\u0304(N)) and Vol(\u00b5(N)), satisfies\nlim N\u2192\u221e Vol(\u00b5\u0304(N)) Vol(\u00b5(N)) = 1,\nwith Vol(\u00b5\u0304(N))\u225c \u222b \u03bb\u2208\u00b5\u0304(N) d\u03bb and Vol(\u00b5(N))\u225c \u222b \u03bb\u2208\u00b5(N) d\u03bb.\nSketch of proof: To prove Theorem 3.1, we first propose a stochastic slot allocation policy \u03c0s(\u03bb) : A(t) \u2192 [0, 1], which allocates the first (K\u0302 + \u2211K\u0304 k=1 k\u2308\u03bbk\u2309) slots in each frame for the uplink and downlink transmissions. Then, we prove that for any \u03bb \u2208 \u00b5\u0304(N), f\u03c0s(\u03bb)(\u03bb, N) < \u221e holds, which implies \u00b5\u0304(N) \u2286 \u00b5(N). Finally, based on the definitions of \u00b5\u0304(N) and \u00b5(N), we prove limN\u2192\u221e Vol(\u00b5\u0304(N))/Vol(\u00b5(N)) = 1. Please check Appendix A for more details.\nBased on Theorem 3.1, \u00b5\u0304(N) serves as a subset of \u00b5(N), and as N increases, the set volume of \u00b5\u0304(N) asymptotically approaches that of \u00b5(N). Moreover, the boundary of subset \u00b5\u0304(N) is characterized by the equality K\u0302 + \u2211K\u0304 k=1 k\u2308\u03bbk\u2309 = N and thus has a piecewise linear shape (see the green curves in Fig. 3), indicating that the boundary of \u00b5(N) lies above or on this piecewise linear surface.\nIn summary, the achievable region of problem (P1), i.e., \u00b5(N), can be characterized by superset \u00b5\u0302(N) and subset \u00b5\u0304(N). Additionally, Theorem 3.1 provides a sufficient condition for the solution existence of problem (P1): If the condition K\u0302 + \u2211K\u0304 k=1 k\u2308\u03bbk\u2309 \u2264 N is satisfied, then problem (P1) has at least one solution, and this solution is represented by the policy \u03c0s(\u03bb) as introduced in Appendix A."
        },
        {
            "heading": "IV. MIXED-ORDER DRIFT-PLUS-PENALTY ALGORITHM",
            "text": "In this section, we first analyze the characteristics of the two terms in the objective function (7) of problem (P1). Next, leveraging these characteristics and the Lyapunov drift optimization [25], we introduce the linear and quadratic Lyapunov functions, along with a penalty term. Then, we combine the\n7 drifts of these Lyapunov functions with the penalty term to develop a mixed-order drift-plus-penalty algorithm. Finally, we conduct the performance analysis of the proposed algorithm."
        },
        {
            "heading": "A. Lyapunov Functions and Drifts",
            "text": "The objective function (7) of problem (P1) contains an AoI term and a service delay term. Specifically, the service delay term, given by \u2211M m=1 \u2211K\u0304 k=1 \u03bbm,kqm,k(t), exhibits a linear relationship with respect to the request queues Q(t). Hence, by adopting Lyapunov drift optimization to this term, we construct a quadratic Lyapunov function with respect to Q(t) as [25, Theorem 4.1]\nL(Q(t)) \u225c 1\n2 M\u2211 m=1 K\u0304\u2211 k=1 q2m,k(t), (11)\nand define the corresponding Lyapunov drift under a general slot allocation policy \u03c0 as\n\u2206\u03c0(L(Q(t)))\n\u225cE\u03c0,cm,k(t) [L(Q(t+ 1))\u2212 L(Q(t))|x(t),Q(t)] . (12)\nHowever, the AoI term in the objective function (7) of problem (P1), given by \u2211M m=1 \u2211K\u0304 k=1 am,k(t)(xm(t) +1), is the product of the design variable am,k(t) and a linear function of the AoI xm(t), and thus cannot be handled by conventional Lyapunov methods [25, Theorem 4.2]. To address this challenge, we first propose a linear Lyapunov function of x(t) and a penalty term. Specifically, the linear Lyapunov function is defined as\nL(x(t)) \u225c M\u2211\nm=1\nxm(t), (13)\nand the corresponding Lyapunov drift under a general slot allocation policy \u03c0 is defined as\n\u2206\u03c0(L(x(t))) \u225cE\u03c0,cm,k(t) [ L(x(t+ 1))\u2212 L(x(t)) \u2223\u2223\u2223x(t),Q(t)] . (14) The proposed penalty term is defined as the conditional expectation of the AoI term under a general slot allocation policy \u03c0, i.e., \u2211M m=1 \u2211K\u0304 k=1 E\u03c0 [am,k(t)|x(t),Q(t)] (xm(t) + 1). Next, we combine the linear drift \u2206\u03c0(L(x(t))) in (14), the quadratic drift \u2206\u03c0(L(Q(t))) in (12), and the penalty term to obtain the \u201cmixed-order drift-plus-penalty\u201d, i.e.,\n\u2206\u03c0(L(Q(t))) + V ( V0\u2206\u03c0(L(x(t)))\n+ M\u2211 m=1 K\u0304\u2211 k=1 E\u03c0 [am,k(t)|x(t),Q(t)] (xm(t) + 1) ) ,\n(15)\nwhere V0 is a positive constant. Then, we find an upper bound for the mixed-order drift-plus-penalty with the following proposition.\nProposition 4.1: For any positive constant V0, the defined\nmixed-order drift-plus-penalty in (15) is upper bounded by\nC\u2212 M\u2211\nm=1 K\u0304\u2211 k=1 \u03bbm,kqm,k(t)(E\u03c0[am,k(t)|x(t),Q(t)]\u2212\u03bbm,k)\n\u2212 V V0 M\u2211\nm=1\nE\u03c0[am,K\u0304+1(t)|x(t),Q(t)]xm(t) + V V0M\n+ V M\u2211 m=1 K\u0304\u2211 k=1 E\u03c0 [am,k(t)|x(t),Q(t)] (xm(t) + 1),\n(16)\nwhere C is given as\nC\u225c 1\n2 M\u2211 m=1 K\u0304\u2211 k=1 \u03bbm,kEcm,k(t)[c 2 m,k(t)]+ 1 2 max m\u2208M,k\u2208K\u0304 \u03bbm,k \u2308N k \u23092 .\nProof: Please see Appendix B. Remarkably, the upper bound (16) proposed in Proposition 4.1 now serves as the new objective function in problem (P1), replacing the original objective function (7). We will show that by minimizing this upper bound, we can effectively control both the average AoI and the average service delay in problem (P1), thereby overcoming the non-linearity challenge posed by the AoI term in the objective function (7) of problem (P1)."
        },
        {
            "heading": "B. Algorithm",
            "text": "Our proposed mixed-order drift-plus-penalty algorithm follows the same principle as conventional Lyapunov methods [25] in making slot allocation decisions in each frame, which consists of two steps: First, it calculates the values of x(t) and Q(t) based on their update rules in (3) and (4); then, it obtains the slot allocation decision A(t) that minimizes the upper bound of the mixed-order drift-plus-penalty in (16) and simultaneously satisfies the constraints in (5) and (6). In other words, the proposed algorithm obtains the value of A(t) by solving the following problem.\n(P2) argmin A(t) (16),\ns.t. (5), (6),\nwhich can be reframed as\n(P3) argmax A(t) M\u2211 m=1 K\u0304\u2211 k=1 [\u03bbm,kqm,k(t)\u2212 V(xm(t) +1)]am,k(t)\n+V V0 M\u2211 m=1 xm(t)am,K\u0304+1(t)\ns.t. (5), (6).\nIn problem (P3), variables am,k(t), k \u2208 K\u0304, are bounded due to the constraints in (5), and am,K\u0304+1(t) takes value from set {0, 1}. Thus, problem (P3) is a mixture of the bounded knapsack problem and the 0-1 knapsack problem [30], and can be efficiently solved using DP algorithm within pseudopolynomial time. The specific algorithm can be found in [30] and is omitted in this paper.\nFinally, we summarize the mixed-order drift-plus-penalty algorithm in Algorithm I, where T0 denotes the end scheduling frame, the values of x(t) and Q(t) are derived in lines 1 and\n8 Algorithm I Proposed mixed-order drift-plus-penalty algorithm to solve problem (P1)\n1: Initialize x(1) and Q(1) as 0M\u00d71 and 0M\u00d7K\u0304 , respectively. 2: for t = 1, 2, \u00b7 \u00b7 \u00b7 , T0 3: Based on the values of x(t) and Q(t), adopt DP\nalgorithm [30] to solve problem (P3) and derive the value of A(t);\n4: Execute the slot allocation decision A(t) at the BS; 5: Observe the values of cm,k(t) for all m\u2208M and k\u2208 K\u0304 at the BS; 6: Derive the values of x(t+1) and Q(t+1) based on (3), (4), and the values of the observed cm,k(t); 7: end for\n6, and the slot allocation decisions A(t) are determined in line 3. Notably, in Algorithm I, the value of the slot allocation decision A(t) solely depends on the values of x(t) and Q(t). As a result, we can represent the corresponding slot allocation policy under Algorithm I as \u03c0m : x(t)\u00d7Q(t) \u2192 A(t), which is derived by mapping the values of x(t) and Q(t) to the corresponding solution of problem (P3)."
        },
        {
            "heading": "C. Performance Analysis",
            "text": "To evaluate the performance of the proposed Algorithm I, we first derive an upper bound on the expected value of (15) under this algorithm.\nProposition 4.2: For any \u03bb \u2208 \u00b5\u0304(N), we denote \u03f5(\u03bb) \u2208 R\u22650 as the maximum value satisfying \u03bb+ \u03f5(\u03bb) \u00b7 1M\u00d7K\u0304 \u2208 \u00b5\u0304(N)1. Then, for any \u03f5 \u2208 [0, \u03f5(\u03bb)], we have\nE\u03c0m [(15)|\u03c0=\u03c0m ]\n\u2264C + V ( V0M + M\u2211 m=1 K\u0304\u2211 k=1 (\u03bbm,k + \u03f5) )\n\u2212 \u03f5 M\u2211\nm=1 K\u0304\u2211 k=1 \u03bbm,kEQ(t)\u223c\u03c0m(Q(t))[qm,k(t)]\n\u2212 V M\u2211\nm=1 K\u0304\u2211 k=1 ( V0 MK\u0304 \u2212(\u03bbm,k+\u03f5) ) Ex(t)\u223c\u03c0m(x(t))[xm(t)].\n(17)\nHere, E\u03c0m [(15)|\u03c0=\u03c0m ] represents the expected value of (15) when the slot allocation policy \u03c0m is adopted, \u03c0m(x(t)) and \u03c0m(Q(t)) represent the distributions of x(t) and Q(t) under policy \u03c0m, respectively.\nProof: Please see Appendix C. Then, we use the derived upper bound in Proposition 4.2 to evaluate the performance of the proposed Algorithm I. The results are concluded in the following theorem.\n1Based on the definition of \u00b5\u0304(N), the value of \u03f5(\u03bb) is the solution to K\u0302+ \u2211K\u0304 k=1 k\u2308\u03bbk\u2309+ K\u0304(K\u0304+1) 2\n\u03f5(\u03bb) = N and thus can be derived by bisection search algorithm.\nTheorem 4.1: Under the proposed Algorithm I, the average AoI is upper bounded by\n1\u2211M m=1 \u2211K\u0304 k=1 \u03bbm,k\n( max\nm\u2208M,k\u2208K\u0304 (\u03bbm,k + \u03f5(\u03bb))M\n2K\u0304\n+ M\u2211 m=1 K\u0304\u2211 k=1 \u03bbm,k + C V\n) ,\n(18)\nand the average service delay is upper bounded by\n1 \u03f5(\u03bb) \u2211M\nm=1 \u2211K\u0304 k=1\u03bbm,k\n(( max\nm\u2208M,k\u2208K\u0304 (\u03bbm,k+\u03f5(\u03bb))M\n2K\u0304\n+ M\u2211 m=1 K\u0304\u2211 k=1 (\u03bbm,k + \u03f5(\u03bb)) ) V +C ) + 1.\n(19)\nProof: Please see Appendix D. Based on (18) and (19), both the average AoI and the average service delay are upper bounded, and in general scenarios where the mean arrival matrix \u03bb is fixed, the values of their upper bounds are O(1/V ) and O(V ), respectively."
        },
        {
            "heading": "V. SIMULATION RESULTS",
            "text": ""
        },
        {
            "heading": "A. Simulation Setup",
            "text": "In this section, we evaluate the performance of the proposed mixed-order drift-plus-penalty algorithm by comparing it with three widely-adopted algorithms:\n\u2022 Fixed window algorithm [21]: the state-of-the-art nearoptimal policy for the case of N = 1. It uploads messages via uplinks as soon as their ages reach certain thresholds and serves requests via downlinks using the FCFS mechanism. We extend this algorithm to cases with N > 1 by introducing a naive parallel mechanism to schedule the N slots within a frame; \u2022 DRL [28], [29]: a near-optimal policy for scenarios with small N values. However, its efficiency decreases significantly when N becomes large, due to the substantial increase in the size of neural networks used by the actor and critic of DRL; \u2022 \u03c0s(\u03bb): the benchmark algorithm proposed in Appendix A.\nWe set the simulation parameters as follows: the value of \u03baULm (t) is set to either 1 or 2 with equal probability, the pmf fm,k follows a Poisson distribution, with its mean value \u03bbm,k randomly sampled from a uniform distribution over the interval [0, 1]."
        },
        {
            "heading": "B. Performance Evaluashtion",
            "text": "In Fig. 4 (a), we evaluate the performances of various algorithms in the scenario with one SN in the MEC network and one slot in each frame, i.e., M = 1 and N = 1. We also set K\u0304 = 1 and \u03baUL1 (t) = 1 to ensure a sufficiently large achievable region for the problem. We observe that within the range of [0, 0.42] for the arrival rate \u03bb1,1, the fixed window algorithm consistently outperforms other algorithms by achieving the lowest average value of the objective function (7), and the DRL algorithm performs comparably to the fixed\n9 0 0.1 0.2 0.3 0.4 Arrival rate 0 1 2 3 4 Proposed algorithm Fixed window DRL 0 0.05 0.1 0.15 0.2 0.25 Sum arrival rate 15 Proposed algorithm Fixed window DRL A v er a g e v a lu e o f (7 )\n(a) (b)\nA v\ner a\ng e v\na lu\ne o\nf (7\n)\n10\n5\n0\nFigure 4: Arrival rate vs. average value of (7) of various algorithms. (a) The scenario with M = 1, N = 1, K\u0304 = 1; (b) The scenario with M = 10, N = 1, K\u0304 = 1.\n0 5 10 15 20 Sum arrival rate\n0\n20\n40\n60\n80\n100\n120\n140\n160 Proposed algorithm Fixed window algorithm\n0 5 10 15 20 Sum arrival rate\n0\n20\n40\n60\n80\n100\n120\n140\n160 Delay of proposed algorithm AoI of proposed algorithm\nDelay of fixed window algorithm AoI of fixed window algorithm Delay of AoI of\n0 5 10 15 20 Sum arrival rate\n0\n0.2\n0.4\n0.6\n0.8\n1\nProposed algorithm Fixed window algorithm\nA v e r a g\ne v\na lu\ne o f\n(7 )\nS lo\nt u\nti li\nty r\na te\n(a) (b) (c)\n( )s \n( )s  ( )s \n( )s \nFigure 5: Performances of various algorithms in the scenario with M = 10, N = 40, and K\u0304 = 3. (a) Sum arrival rate vs. average value of (7); (b) Sum arrival rate vs. delay/AoI; (c) Sum arrival rate vs. slot utility rate.\nwindow algorithm. However, the average value of (7) fails to converge under all of the algorithms when \u03bb1,1 exceeds 0.42, which suggests that \u03bb1,1 > 0.42 leads to an empty achievable region. Finally, the proposed algorithm has the worst performance, which is reasonable since the condition formulated in section III, i.e., K\u0302 + \u2211K\u0304 k=1 k\u2308\u03bbk\u2309 \u2264 N , is not satisfied in this scenario. In Fig. 4 (b), we investigate the scenario with 10 SNs in the MEC network and one slot in each frame and illustrate the relationship between the sum arrival rate, i.e., \u2211M m=1 \u2211K\u0304 k=1 k\u03bbm,k, and the average value of (7). It is observed that both the fixed window and DRL algorithms exhibit promising convergence performances as in the previous case, while the proposed algorithm still does not perform well since the condition K\u0302 + \u2211K\u0304 k=1 k\u2308\u03bbk\u2309 \u2264 N is not satisfied.\nIn Fig. 5 and Fig. 6, we evaluate the performances of various algorithms in the scenario with 10 SNs in the MEC network and 40 slots in each frame, i.e., M = 10 and N = 40. Additionally, we set K\u0304 = 3. In this particular scenario, both the proposed algorithm and \u03c0s(\u03bb) are applicable since the condition K\u0302 + \u2211K\u0304 k=1 k\u2308\u03bbk\u2309 \u2264 N is satisfied. However, the DRL algorithm is not applicable in this scenario due to the large action space, which has a cardinality of (41\u00d7 21\u00d7 14\u00d7 2)10. Fig. 5 (a) shows the relationship between the sum arrival rate and the average value of (7). We observe that the proposed algorithm consistently achieves significantly lower values of (7) compared to other algorithms, especially in scenarios with large sum arrival rates. This demonstrates the ability of the proposed algorithm to efficiently handle the scenarios with heavy requests. Moreover, we observe that all the algorithms achieve large average value of (7) when the sum arrival rate exceeds 23, indicating that the achievable region is empty beyond this threshold. Fig. 5 (b) illustrates the achieved average AoI and service delay under different algorithms, where the average AoI and service delay under the proposed algorithm exhibit stable growth as the sum arrival rate increases. This stability demonstrates the robustness of the proposed algorithm with respect to variations in the sum arrival rate. Fig. 5 (c) illustrates the slot utility under different algorithms. We observe that the fixed window algorithm occupies all slots within each frame all the time, whereas the proposed algorithm has an increasing slot utility rate as the sum arrival rate grows and achieves full\n10\nslot utility rate when the value of sum arrival rate is sufficiently large. This indicates that the proposed algorithm can achieve the same average value of (7) as the other algorithms while utilizing fewer slots in each frame. Moreover, we observe that the proposed algorithm achieves full slot utility rate when the sum arrival rate is around 23, which is the threshold where the achievable region is empty. This suggests that we can use the linearity of the slot utility rate with respect to the sum arrival rate in the proposed algorithm to approximate the threshold for the sum arrival rate. Finally, we consider the scenario with the sum arrival rate being 23, vary the value of V , and plot the corresponding AoI-delay tradeoff curve in Fig. 6. The results show that the proposed algorithm achieves a substantially lower tradeoff curve, indicating that it can always achieve lower average AoI or lower average service delay than the fixed window algorithm.\nIn Fig. 7 and Fig. 8, we evaluate the algorithm performances in a more complex scenario with 20 SNs in the MEC network and 80 slots in each frame. We observe that the proposed algorithm can effectively handle the cases with heavy requests, as demonstrated in Fig. 7 (a) and Fig. 7 (b), by achieving a much lower average value of (7) and stabler average AoI and average service delay than other algorithms. Furthermore, by combining the results of Fig. 7 (a) and Fig. 7 (c), we again demonstrate that the proposed algorithm can achieve the same average value of (7) as the other algorithms while utilizing fewer slots in each frame. Finally, Fig. 8 shows that the proposed algorithm can achieve a better AoI-delay tradeoff than the fixed window algorithm in complex MEC networks."
        },
        {
            "heading": "VI. CONCLUSIONS",
            "text": "This paper considers the AoI-delay tradeoff in a discretetime MEC network with multiple SNs in the network and multiple slots in one frame. We formulate the problem as a sequential decision-making problem and derive a superset and a subset of the achievable region using rate stability theorem and a novel stochastic policy. We also derive a sufficient\ncondition for checking the solution\u2019s existence by analyzing the features of the subset. To optimize the average AoI and average service delay jointly, we propose a mixed-order driftplus-penalty algorithm that uses DP to maximize the summation of a linear Lyapunov drift, a quadratic Lyapunov drift, and a penalty term. The proposed algorithm can optimize the objective function with non-linear terms. Theoretical analysis shows that the proposed algorithm achieves an O(1/V ) versus O(V ) tradeoff for average AoI and average service delay."
        },
        {
            "heading": "APPENDIX A PROOF OF THEOREM 3.1",
            "text": "To prove Theorem 3.1, we first propose a stochastic slot allocation policy \u03c0s(\u03bb) and specify its slot allocation method within each frame. Then, based on this policy, we prove that \u00b5\u0304(N) \u2286 \u00b5(N). Finally, we prove that limN\u2192\u221e Vol(\u00b5\u0304(N))/Vol(\u00b5(N)) = 1."
        },
        {
            "heading": "A. Policy \u03c0s(\u03bb)",
            "text": "We propose a stochastic policy \u03c0s(\u03bb) that allocates slots within each frame using the following two procedures. 1) : In the first procedure, the 1st to the K\u0302 th slots within each frame are simultaneously allocated to upload a random message out of the M messages and each message is selected for uploading with a probability of 1M . In other words, it follows\np1:K\u0302,m,K\u0304+1(t) = 1\nM , \u2200m \u2208 M, t \u2208 Z>0, (20)\nwhere p1:K\u0302,m,K\u0304+1(t) represents the probability of simultaneously allocating the 1st to the K\u0302 th slots to upload the mth message within the tth frame. 2) : The second procedure consists of K\u0304 steps. In the kth\nstep, we group the (K\u0302 + \u2211k\u22121\nk\u2032=1 k \u2032\u2308\u03bbk\u2032\u2309 + 1)th to the (K\u0302 +\u2211k\nk\u2032=1 k \u2032\u2308\u03bbk\u2032\u2309)th slots into \u2308\u03bbk\u2309 sets, each consisting of k slots. Within each set, we utilize all the contained slots to serve one request from either the (1, k)th, the (2, k)th, \u00b7 \u00b7 \u00b7, or the (M,k)th request queue and the probabilities of serving one request from these request queues are \u03bb1,k\u2308\u03bbk\u2309 , \u03bb2,k \u2308\u03bbk\u2309 , \u00b7 \u00b7 \u00b7 , \u03bbM,k \u2308\u03bbk\u2309 , respectively, i.e.,\npK\u0302+ \u2211k\u22121\nk\u2032=1 k \u2032\u2308\u03bbk\u2032\u2309+k(n\u22121)+1:K\u0302+ \u2211k\u22121 k\u2032=1 k \u2032\u2308\u03bbk\u2032\u2309+kn,m,k (t)\n= \u03bbm,k \u2308\u03bbk\u2309 , (21)\nfor all n \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , \u2308\u03bbk\u2309}, m \u2208 M, and k \u2208 K\u0304, where in the above equality, the notation pK\u0302+ \u2211k\u22121 k\u2032=1 k \u2032\u2308\u03bbk\u2032\u2309+k(n\u22121)+1:K\u0302+ \u2211k\u22121 k\u2032=1 k \u2032\u2308\u03bbk\u2032\u2309+kn,m,k (t) represents the probability of simultaneously allocating the (K\u0302 + \u2211k\u22121 k\u2032=1 k\n\u2032\u2308\u03bbk\u2032\u2309 + k(n \u2212 1) + 1)th to the (K\u0302 + \u2211k\u22121 k\u2032=1 k\n\u2032\u2308\u03bbk\u2032\u2309 + kn)th slots to serve one request from the (m, k)th request queue.\nIn summary, the policy \u03c0s(\u03bb) allocates K\u0302 slots for uplink transmissions in the first procedure and \u2211K\u0304 k=1 k\u2308\u03bbk\u2309 slots for downlink transmissions in the second procedure. Therefore, to ensure the proper execution of policy \u03c0s(\u03bb), the total number of the allocated slots K\u0302 + \u2211K\u0304 k=1 k\u2308\u03bbk\u2309 must not exceed the number of slots in one frame, i.e., N . In other words, \u03bb \u2208 \u00b5\u0304(N) must hold.\n11"
        },
        {
            "heading": "B. Proof of \u00b5\u0304(N) \u2286 \u00b5(N)",
            "text": "Now, we prove that \u00b5\u0304(N) is a subset of \u00b5(N). For any \u03bb \u2208 \u00b5\u0304(N), we construct policy \u03c0s(\u03bb) based on the aforementioned two procedures. Then, based on (20), we have E\u03c0s(\u03bb)[am,K\u0304+1(t)] > 0. By combining this inequality with (3), we can verify that the average AoI under the policy \u03c0s(\u03bb) is finite, i.e,\nlim T\u2192\u221e\n1\nT T\u2211 t=1 M\u2211 m=1 K\u0304\u2211 k=1 am,k(t) (xm(t) + 1) < \u221e.\nAdditionally, based on (21), it follows that am,k(t) is i.i.d. across t, and E\u03c0s(\u03bb)[am,k(t)] = \u2308\u03bbk\u2309 \u03bbm,k \u2308\u03bbk\u2309 = \u03bbm,k. By combing these results with the rate stability theorem [25, Theorem 2.4], the process {qm,k(t)}Tt=1, m \u2208 M and k \u2208 K\u0304, is guaranteed to be rate stable under policy \u03c0s(\u03bb), i.e.,\nlim t\u21920\nqm,k(t)\nt = 0 with probability 1,\nwhich ensures that the average service delay under policy \u03c0s(\u03bb) is finite, i.e,\nlim T\u2192\u221e\n1\nT T\u2211 t=1 M\u2211 m=1 K\u0304\u2211 k=1 \u03bbm,kqm,k(t) < \u221e.\nConsequently, the objective function (7) of problem (P1) under policy \u03c0s(\u03bb), which is the summation of the average AoI and the average service delay, is also finite, i.e.,\nf\u03c0s(\u03bb)(\u03bb, N) < \u221e. (22)\nFinally, by combining (22) and Definition 3.1, \u03bb \u2208 \u00b5(N) holds, which implies \u00b5\u0304(N) \u2286 \u00b5(N)."
        },
        {
            "heading": "C. Proof of limN\u2192\u221e Vol(\u00b5\u0304(N))/Vol(\u00b5(N)) = 1",
            "text": "First of all, we show that \u00b5\u0302(N\u0302) with N\u0302 \u225c N\u2212 K\u0304(K\u0304+1)2 \u2212K\u0302 is a subset of \u00b5\u0304(N). Specifically, for any \u03bb \u2208 \u00b5\u0302(N\u0302), we refer the definition in (9) and obtain\nM\u2211 m=1 K\u0304\u2211 k=1 k\u03bbm,k \u2264 N \u2212 K\u0304(K\u0304 + 1) 2 \u2212 K\u0302. (23)\nThen, by combing the fact \u2308\u03bbk\u2309 \u2264 \u03bbk+1 and inequality (23), we obtain\nK\u0302 + K\u0304\u2211 k=1 k\u2308\u03bbk\u2309 \u2264 K\u0302 + K\u0304\u2211 k=1 k(\u03bbk + 1)\n=K\u0302 + K\u0304(K\u0304 + 1)\n2 + M\u2211 m=1 K\u0304\u2211 k=1 k\u03bbm,k \u2264 N.\n(24)\nBased on inequality (24) and the definition of \u00b5\u0304(N) in (10), we have \u03bb \u2208 \u00b5\u0304(N), which implies that \u00b5\u0302(N\u0302) is a subset of \u00b5\u0304(N).\nBased on the above results and the definition of \u00b5\u0302(N) in (9), we obtain\n\u00b5\u0302(N\u0302) \u2286 \u00b5\u0304(N) \u2286 \u00b5(N) \u2286 \u00b5\u0302(N). (25)\n12\nMoreover, based on the definition in (9), we have\nlim N\u2192\u221e Vol(\u00b5\u0302(N\u0302)) Vol(\u00b5\u0302(N)) = lim N\u2192\u221e \u222b \u03bb\u2208\u00b5\u0302(N\u0302) d\u03bb\u222b \u03bb\u2208\u00b5\u0302(N) d\u03bb\n= lim N\u2192\u221e\n1 (MK\u0304)! \u03a0Mm=1\u03a0 K\u0304 k=1 N\u0302 k\n1 (MK\u0304)! \u03a0Mm=1\u03a0 K\u0304 k=1 N k\n= 1.\nBy combining this result with (25), we have\nlim N\u2192\u221e Vol(\u00b5\u0304(N)) Vol(\u00b5(N)) = 1,\nwhich completes the proof."
        },
        {
            "heading": "APPENDIX B PROOF OF PROPOSITION 4.1",
            "text": "Based on the equalities in (3) and (4) and the definitions in (13) and (11), it follows\nL(x(t+ 1))\u2212 L(x(t))\n= M\u2211 m=1 (xm(t+ 1)\u2212 xm(t))\n= M\u2211 m=1 (1\u2212 am,K\u0304+1(t)xm(t)), (26)\nL(Q(t+ 1))\u2212L(Q(t))\n= 1\n2 M\u2211 m=1 K\u0304\u2211 k=1 \u03bbm,k ( (max{qm,k(t)\u2212am,k(t),0}+cm,k(t))2\n\u2212q2m,k(t) )\n\u22641 2 M\u2211 m=1 K\u0304\u2211 k=1 \u03bbm,k ( c2m,k(t)+a 2 m,k(t)\n\u22122qm,k(t) (am,k(t)\u2212cm,k(t)) ) .\n(27)\nInequality (27) is obtained by considering the fact that for any x \u2265 0, y \u2265 0, and z \u2265 0, it follows (max{x\u2212 y, 0}+ z)2 \u2264 x2 + y2 + z2 + 2x(z \u2212 y).\nNext, by plugging the definitions in (12) and (14), equality (26), and inequality (27) into (15), we obtain\n(15)\n\u22641 2 M\u2211 m=1 K\u0304\u2211 k=1 \u03bbm,k ( Ecm,k(t)[c 2 m,k(t)]+E\u03c0 [ a2m,k(t)|x(t),Q(t) ] \u2212 2qm,k(t)(E\u03c0[am,k(t)|x(t),Q(t)]\u2212\u03bbm,k)\n) +V V0\nM\u2211 m=1 (1\u2212E\u03c0 [ am,K\u0304+1(t)|x(t),Q(t) ] xm(t))\n+ V M\u2211 m=1 K\u0304\u2211 k=1 E\u03c0 [am,k(t)|x(t),Q(t)] (xm(t)+1).\n(28)\nThen, based on inequality (6), we have\n1\n2 M\u2211 m=1 K\u0304\u2211 k=1 \u03bbm,kE\u03c0 [ a2m,k(t)|x(t),Q(t) ] \u22641 2 max m\u2208M,k\u2208K\u0304 \u03bbm,k \u2308N k \u23092 .\n(29)\nFinally, combing equality (28) and inequality (29), it yields\n(15)\n\u22641 2 M\u2211 m=1 K\u0304\u2211 k=1 \u03bbm,kEcm,k(t)[c 2 m,k(t)] + 1 2 max m\u2208M,k\u2208K\u0304 \u03bbm,k \u2308N k \u23092 \u2212\nM\u2211 m=1 K\u0304\u2211 k=1 \u03bbm,kqm,k(t) (E\u03c0 [am,k(t)|x(t),Q(t)]\u2212 \u03bbm,k)\n\u2212 V V0 M\u2211\nm=1\nE\u03c0[am,K\u0304+1(t)|x(t),Q(t)]xm(t) + V V0M\n+ V M\u2211 m=1 K\u0304\u2211 k=1 E\u03c0 [am,k(t)|x(t),Q(t)] (xm(t) + 1)\n=(16),\nwhich completes the proof."
        },
        {
            "heading": "APPENDIX C PROOF OF PROPOSITION 4.2",
            "text": "First, since policy \u03c0m is the solution to problem (P3), we have\n(16)|\u03c0=\u03c0m\u2264 (16)|\u03c0=\u03c00 , \u2200\u03c00 \u2208 \u03a0, (30)\nwhere \u03a0 is defined as the set containing all feasible slot allocation policies.\nNext, since \u03bb + \u03f5(\u03bb) \u00b7 1M\u00d7K\u0304 \u2208 \u00b5\u0304(N) holds, based on the definition of \u00b5\u0304(N) in (10), we have\n\u03c0s(\u03bb+ \u03f5 \u00b7 1M\u00d7K\u0304) \u2208 \u03a0, \u2200\u03f5 \u2208 [0, \u03f5(\u03bb)]. (31)\nBy combing Proposition 4.1, equality (30), and (31), we have\n(15)|\u03c0=\u03c0m\u2264 (16)|\u03c0=\u03c0m\u2264 (16)|\u03c0=\u03c0s(\u03bb+\u03f5\u00b71M\u00d7K\u0304). (32)\nThen, based on Appendix A, it follows\nE\u03c0s(\u03bb+\u03f5\u00b71M\u00d7K\u0304)[am,k(t)|x(t),Q(t)]=\u03bbm,k+\u03f5, (33)\nfor all m \u2208 M, k \u2208 K\u0304, t \u2208 Z>0, and \u03f5 \u2208 [0, \u03f5(\u03bb)]. By plugging (33) into (32), we have\n(15)|\u03c0=\u03c0m\u2264C + V V0M + V M\u2211\nm=1 K\u0304\u2211 k=1 (\u03bbm,k + \u03f5)\n\u2212\u03f5 M\u2211\nm=1 K\u0304\u2211 k=1 \u03bbm,kqm,k(t)\u2212 V V0 M M\u2211 m=1 xm(t)\n+ V M\u2211 m=1 K\u0304\u2211 k=1 (\u03bbm,k + \u03f5)xm(t).\n(34)\nFinally, denote the distributions of x(t) and Q(t) under policy \u03c0m as \u03c0m(x(t)) and \u03c0m(Q(t)), respectively. Taking\n13\nexpectation for (34) over policy \u03c0m, it yields\nE\u03c0m[(15)|\u03c0=\u03c0m ] = E x(t)\u223c\u03c0m(x(t)) Q(t)\u223c\u03c0m(Q(t)) [(15)|\u03c0=\u03c0m ] \u2264 (17),\nwhich completes the proof."
        },
        {
            "heading": "APPENDIX D PROOF OF THEOREM 4.1",
            "text": "First, by summing up E\u03c0m [(15)|\u03c0=\u03c0m ] over t \u2208 {1, 2 \u00b7 \u00b7 \u00b7 , T}, we have\nT\u2211 t=1 E\u03c0m [(15)|\u03c0=\u03c0m ]\n= T\u2211 t=1 Ex(t)\u223c\u03c0m(x(t)) Q(t)\u223c\u03c0m(Q(t)) E\u03c0m,cm,k(t)[L(Q(t+1))\u2212L(Q(t))|x(t),Q(t)]\n+V V0 T\u2211 t=1 E x(t)\u223c\u03c0m(x(t)) Q(t)\u223c\u03c0m(Q(t)) E\u03c0m,cm,k(t) [ L(x(t+ 1))\n\u2212 L(x(t)) \u2223\u2223\u2223x(t),Q(t)]\n+ V T\u2211 t=1 M\u2211 m=1 K\u0304\u2211 k=1 Ex(t)\u223c\u03c0m(x(t)) Q(t)\u223c\u03c0m(Q(t)) [ E\u03c0m [am,k(t)|x(t),Q(t)]\n(xm(t)+1) ]\n= T\u2211 t=1 E\u03c0m,cm,k(t) [L(Q(t+ 1))\u2212 L(Q(t))]\n+ V V0 T\u2211 t=1 E\u03c0m,cm,k(t) [L(x(t+ 1))\u2212 L(x(t))]\n+ V T\u2211 t=1 M\u2211 m=1 K\u0304\u2211 k=1 E\u03c0m,cm,k(t)[am,k(t)(xm(t) + 1)]\n(35)\n=E\u03c0m,cm,k(t) [L(Q(T + 1))\u2212 L(Q(1))] + V V0E\u03c0m,cm,k(t) [L(x(T + 1))\u2212 L(x(1))]\n+ V E\u03c0m,cm,k(t)  T\u2211 t=1 M\u2211 m=1 K\u0304\u2211 k=1 am,k(t)(xm(t)+1) , (36) where equality (35) is obtained by using the law of iterated expectation [25].\nNext, by summing up (17) over t \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , T}, we have T\u2211\nt=1\n(17)\n=T C + V (V0M + M\u2211 m=1 K\u0304\u2211 k=1 (\u03bbm,k + \u03f5) )\n\u2212 \u03f5E\u03c0m,cm,k(t)\n[ T\u2211\nt=1 M\u2211 m=1 K\u0304\u2211 k=1 \u03bbm,kqm,k(t)\n]\n\u2212VE\u03c0m,cm,k(t)  T\u2211 t=1 M\u2211 m=1 K\u0304\u2211 k=1 ( V0 MK\u0304 \u2212(\u03bbm,k + \u03f5) ) xm(t)  . (37)\nThen, based on the fact E\u03c0m[(15)|\u03c0=\u03c0m ] \u2264(17), we have\nlim T\u2192\u221e (36) T \u2264 lim T\u2192\u221e (37) T . (38)\nFinally, we fix V0 as\nV0 = MK\u0304 max m\u2208M,k\u2208K\u0304 (\u03bbm,k + \u03f5(\u03bb)) (39)\nand it follows V0 MK\u0304 \u2212 (\u03bbm,k + \u03f5) \u2265 0. (40)\nBy plugging (40) into (38), we have\nlim T\u2192\u221e\n1 T E\u03c0m,cm,k(t) [L(Q(T + 1))\u2212 L(Q(1))]\n+ lim T\u2192\u221e\n1 T V V0E\u03c0m,cm,k(t) [L(x(T + 1))\u2212 L(x(1))]\n+ lim T\u2192\u221e\n1 T V E\u03c0m,cm,k(t)  T\u2211 t=1 M\u2211 m=1 K\u0304\u2211 k=1 am,k(t)(xm(t)+1)  \u2264C+V ( max\nm\u2208M,k\u2208K\u0304 (\u03bbm,k+\u03f5(\u03bb))M\n2K\u0304+ M\u2211 m=1 K\u0304\u2211 k=1 (\u03bbm,k + \u03f5) )\n\u2212 \u03f5 lim T\u2192\u221e\n1 T E\u03c0m,cm,k(t)\n[ T\u2211\nt=1 M\u2211 m=1 K\u0304\u2211 k=1 \u03bbm,kqm,k(t)\n] ,\nwhich induces that the average AoI of the requests satisfies\n1\u2211M m=1 \u2211K\u0304 k=1\u03bbm,k lim T\u2192\u221e 1 T E\u03c0m,cm,k(t)\n[ T\u2211\nt=1 M\u2211 m=1 K\u0304\u2211 k=1\nam,k(t)(xm(t)+1)\n]\n\u2264 1\u2211M m=1 \u2211K\u0304 k=1 \u03bbm,k\n( max\nm\u2208M,k\u2208K\u0304 (\u03bbm,k + \u03f5(\u03bb))M\n2K\u0304\n+ M\u2211 m=1 K\u0304\u2211 k=1 (\u03bbm,k + \u03f5) + C V\n) ,\u2200\u03f5 \u2208 [0, \u03f5(\u03bb)],\n(41)\nand the average service delay of the requests satisfies\n1\u2211M m=1 \u2211K\u0304 k=1\u03bbm,k lim T\u2192\u221e 1 T E\u03c0m,cm,k(t)\n[ T\u2211\nt=1 M\u2211 m=1 K\u0304\u2211 k=1 \u03bbm,k\nqm,k(t)\n] + 1\n\u2264 1 \u03f5 \u2211M\nm=1 \u2211K\u0304 k=1 \u03bbm,k\n(( max\nm\u2208M,k\u2208K\u0304 (\u03bbm,k+\u03f5(\u03bb))M\n2K\u0304\n+ M\u2211 m=1 K\u0304\u2211 k=1 (\u03bbm,k + \u03f5) ) V + C ) + 1, \u2200\u03f5 \u2208 (0, \u03f5(\u03bb)].\n(42)\nSince inequality (41) holds for all \u03f5 \u2208 [0, \u03f5(\u03bb)], we set \u03f5 as 0 and derive inequality (18). Similarly, in inequality (42), we set \u03f5 as \u03f5(\u03bb) and derive inequality (19).\n14"
        }
    ],
    "title": "AoI-Delay Tradeoff in Mobile Edge Caching: A Mixed-Order Drift-Plus-Penalty Method",
    "year": 2023
}