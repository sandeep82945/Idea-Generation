{
    "abstractText": "Context: Surface electromyography (sEMG) signals contain rich information recorded from muscle movements and therefore reflect the user\u2019s intention. sEMG has seen dominant applications in rehabilitation, clinical diagnosis as well as human engineering, etc. However, current feature extraction methods for sEMG signals have been seriously limited by its stochasticity, transiency, non-stationarity. Objective: Our objective is to combat the difficulties induced by the aforementioned downsides of sEMG and thereby extract representative features for various downstream movement recognition. Method: We propose a novel 3-axis view of sEMG features composed of temporal, spatial, and channel-wise summary. We leverage the state-of-the-art architecture Transformer to enforce efficient parallel search and to get rid of limitations imposed by previous work in gesture classification. Results: We compared the proposed method against existing methods on two Ninapro datasets consisting of data from both healthy people and amputees. Experimental results show the proposed method attains the state-of-the-art (SOTA) accuracy on both datasets. We further show that the proposed method enjoys strong generalization ability: a new SOTA is achieved by pretraining the model on a different dataset followed by fine-tuning it on the target dataset.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jiaxuan Zhanga"
        },
        {
            "affiliations": [],
            "name": "Yuki Matsudaa"
        },
        {
            "affiliations": [],
            "name": "Manato Fujimotob"
        },
        {
            "affiliations": [],
            "name": "Hirohiko Suwaa"
        },
        {
            "affiliations": [],
            "name": "Keiichi Yasumotoa"
        }
    ],
    "id": "SP:9074af3387ab6bf81abbec5be82fbd3709dab384",
    "references": [
        {
            "authors": [
                "Arjan Gijsberts",
                "Manfredo Atzori",
                "Claudio Castellini",
                "Henning M\u00fcller",
                "Barbara Caputo"
            ],
            "title": "Movement error rate for evaluation of machine learning methods for semg-based hand movement classification",
            "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering,",
            "year": 2014
        },
        {
            "authors": [
                "Elisa Donati",
                "Melika Payvand",
                "Nicoletta Risi",
                "Renate Krause",
                "Giacomo Indiveri"
            ],
            "title": "Discrimination of emg signals using a neuromorphic implementation of a spiking neural network",
            "venue": "IEEE Transactions on Biomedical Circuits and Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Ludger van Dijk",
                "Corry K. van der Sluis",
                "Hylke W. van Dijk",
                "Raoul M. Bongers"
            ],
            "title": "Learning an emg controlled game: Task-specific adaptations and transfer",
            "venue": "PLOS ONE, 11(8):1\u201314,",
            "year": 2016
        },
        {
            "authors": [
                "Naveen Kumar Karnam",
                "Shiv Ram Dubey",
                "Anish Chand Turlapaty",
                "Balakrishna Gokaraju"
            ],
            "title": "Emghandnet: A hybrid cnn and bi-lstm architecture for hand activity classification using surface emg signals",
            "venue": "Biocybernetics and Biomedical Engineering,",
            "year": 2022
        },
        {
            "authors": [
                "Alexander Kenneth Clarke",
                "Seyed Farokh Atashzar",
                "Alessandro Del Vecchio",
                "Deren Barsakcioglu",
                "Silvia Muceli",
                "Paul Bentley",
                "Filip Urh",
                "Ales Holobar",
                "Dario Farina"
            ],
            "title": "Deep learning for robust decomposition of high-density surface emg signals",
            "venue": "IEEE Transactions on Biomedical Engineering,",
            "year": 2021
        },
        {
            "authors": [
                "Manfredo Atzori",
                "Arjan Gijsberts",
                "Ilja Kuzborskij",
                "Simone Elsig",
                "Anne-Gabrielle Mittaz Hager",
                "Olivier Deriaz",
                "Claudio Castellini",
                "Henning M\u00fcller",
                "Barbara Caputo"
            ],
            "title": "Characterization of a benchmark database for myoelectric movement classification",
            "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering,",
            "year": 2015
        },
        {
            "authors": [
                "Rafael Anicet Zanini",
                "Esther Luna Colombini",
                "Maria Claudia Ferrari de Castro"
            ],
            "title": "Parkinson\u2019s disease emg signal prediction using neural networks",
            "venue": "IEEE International Conference on Systems, Man and Cybernetics (SMC),",
            "year": 2019
        },
        {
            "authors": [
                "P Peckham",
                "Jayme Knutson"
            ],
            "title": "Functional electrical stimulation for neuromuscular applications",
            "venue": "Annual review of biomedical engineering, 7:327\u201360,",
            "year": 2005
        },
        {
            "authors": [
                "Maur\u00edcio C. Tosin",
                "Mariano Majolo",
                "Raissan Chedid",
                "Vin\u00edcius H. Cene",
                "Alexandre Balbinot"
            ],
            "title": "semg feature selection and classification using svm-rfe",
            "venue": "In 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),",
            "year": 2017
        },
        {
            "authors": [
                "Jason Chang",
                "Angkoon Phinyomark",
                "Erik Scheme"
            ],
            "title": "Assessment of emg benchmark data for gesture recognition using the ninapro database",
            "venue": "In 2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),",
            "year": 2020
        },
        {
            "authors": [
                "Wei dong Geng",
                "Yu Du",
                "Wenguang Jin",
                "Wentao Wei",
                "Yu Hu",
                "Jiajun Li"
            ],
            "title": "Gesture recognition by instantaneous surface emg images",
            "venue": "Scientific Reports,",
            "year": 2016
        },
        {
            "authors": [
                "Martyna Stachaczyk",
                "S. Farokh Atashzar",
                "Dario Farina"
            ],
            "title": "Adaptive spatial filtering of high-density emg for reducing the influence of noise and artefacts in myoelectric control",
            "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering,",
            "year": 2020
        },
        {
            "authors": [
                "Xin Shi",
                "Maqiang Zhai",
                "Pengjie Qin",
                "Keqi Yu",
                "Wenbo Zhou"
            ],
            "title": "A new semg signal feature extraction method based on s transform",
            "venue": "IEEE International Conference on Real-time Computing and Robotics (RCAR),",
            "year": 2021
        },
        {
            "authors": [
                "Wan-Ting Shi",
                "Zong-Jhe Lyu",
                "Shih-Tsang Tang",
                "Tsorng-Lin Chia",
                "Chia-Yen Yang"
            ],
            "title": "A bionic hand controlled by hand gesture recognition based on surface emg signals: A preliminary study",
            "venue": "Biocybernetics and Biomedical Engineering,",
            "year": 2018
        },
        {
            "authors": [
                "Chen Zheng",
                "Zhu Lingwei",
                "Yang Ziwei",
                "Matsubara Takashi"
            ],
            "title": "Automated cancer subtyping via vector quantization mutual information maximization",
            "venue": "arXiv preprint arxiv:2206.10801,",
            "year": 2022
        },
        {
            "authors": [
                "Wentao Wei",
                "Qingfeng Dai",
                "Yongkang Wong",
                "Yu Hu",
                "Mohan Kankanhalli",
                "Weidong Geng"
            ],
            "title": "Surface-electromyography-based gesture recognition by multi-view deep learning",
            "venue": "IEEE Transactions on Biomedical Engineering,",
            "year": 2019
        },
        {
            "authors": [
                "Zheng Chen",
                "Naoaki Ono",
                "Wei Chen",
                "Toshiyo Tamura",
                "MD Altaf-Ul- Amin",
                "Shigehiko Kanaya",
                "Ming Huang"
            ],
            "title": "The feasibility of predicting impending malignant ventricular arrhythmias by using nonlinear features of short heartbeat intervals",
            "venue": "Computer Methods and Programs in Biomedicine,",
            "year": 2021
        },
        {
            "authors": [
                "Fernando Quivira",
                "Toshiaki Koike-Akino",
                "Ye Wang",
                "Deniz Erdogmus"
            ],
            "title": "Translating semg signals to continuous hand poses using recurrent neural networks",
            "venue": "IEEE EMBS International Conference on Biomedical & Health Informatics (BHI),",
            "year": 2018
        },
        {
            "authors": [
                "Ziwei Yang",
                "Dong Wang",
                "Zheng Chen",
                "Ming Huang",
                "Naoaki Ono",
                "Md Altaf-Ul-Amin",
                "Shigehiko Kanaya"
            ],
            "title": "Exploring feasibility of truth-involved automatic sleep staging combined with transformer",
            "venue": "IEEE International Conference on Bioinformatics and Biomedicine (BIBM),",
            "year": 2021
        },
        {
            "authors": [
                "Zheng Chen",
                "Lingwei Zhu",
                "Ziwei Yang",
                "Renyuan Zhang"
            ],
            "title": "Multitier platform for cognizing massive electroencephalogram",
            "venue": "In Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141 ukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Alexey Dosovitskiy",
                "Lucas Beyer",
                "Alexander Kolesnikov",
                "Dirk Weissenborn",
                "Xiaohua Zhai",
                "Thomas Unterthiner",
                "Mostafa Dehghani",
                "Matthias Minderer",
                "Georg Heigold",
                "Sylvain Gelly",
                "Jakob Uszkoreit",
                "Neil Houlsby"
            ],
            "title": "An image is worth 16x16 words: Transformers for image recognition at scale",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Jiaxuan Zhang",
                "Yuki Matsuda",
                "Manato Fujimoto",
                "Hirohiko Suwa",
                "Keiichi Yasumoto"
            ],
            "title": "Feasibility analysis of semg recognition via channel-wise transformer",
            "venue": "IEEE 11th Global Conference on Consumer Electronics,",
            "year": 2022
        },
        {
            "authors": [
                "Keun-Tae Kim",
                "Cuntai Guan",
                "Seong-Whan Lee"
            ],
            "title": "A subjecttransfer framework based on single-trial emg analysis using convolutional neural networks",
            "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering,",
            "year": 2020
        },
        {
            "authors": [
                "Xiaolong Zhai",
                "Beth Jelfs",
                "Rosa H.M. Chan",
                "Chung Tin"
            ],
            "title": "Selfrecalibrating surface emg pattern recognition for neuroprosthesis control based on convolutional neural network",
            "venue": "Frontiers in Neuroscience,",
            "year": 2017
        },
        {
            "authors": [
                "Weiting Chen",
                "Zhizhong Wang",
                "Hongbo Xie",
                "Wangxin Yu"
            ],
            "title": "Characterization of surface emg signal based on fuzzy entropy",
            "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering,",
            "year": 2007
        },
        {
            "authors": [
                "Ganesh R. Naik",
                "S. Easter Selvan",
                "Hung T. Nguyen"
            ],
            "title": "Single-channel emg classification with ensemble-empirical-modedecomposition-based ica for diagnosing neuromuscular disorders",
            "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering,",
            "year": 2016
        },
        {
            "authors": [
                "Tatiana Tommasi",
                "Francesco Orabona",
                "Claudio Castellini",
                "Barbara Caputo"
            ],
            "title": "Improving control of dexterous hand prostheses using adaptive learning",
            "venue": "IEEE Transactions on Robotics,",
            "year": 2013
        },
        {
            "authors": [
                "Ali H. Al-Timemy",
                "Rami N. Khushaba",
                "Guido Bugmann",
                "Javier Escudero"
            ],
            "title": "Improving the performance against force variation of emg controlled multifunctional upper-limb prostheses for transradial amputees",
            "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering,",
            "year": 2016
        },
        {
            "authors": [
                "Naveen Kumar Karnam",
                "Anish Chand Turlapaty",
                "Shiv Ram Dubey",
                "Balakrishna Gokaraju"
            ],
            "title": "Classification of semg signals of hand gestures based on energy features",
            "venue": "Biomedical Signal Processing and Control,",
            "year": 2021
        },
        {
            "authors": [
                "Shu Shen",
                "Xuebin Wang",
                "Fan Mao",
                "Lijuan Sun",
                "Minghui Gu"
            ],
            "title": "Movements classification through semg with convolutional vision transformer and stacking ensemble learning",
            "venue": "IEEE Sensors Journal,",
            "year": 2022
        },
        {
            "authors": [
                "Kaniska Samanta",
                "Sayanjit Singha Roy",
                "Sudip Modak",
                "Soumya Chatterjee",
                "Rohit Bose"
            ],
            "title": "Neuromuscular disease detection employing deep feature extraction from cross spectrum images of electromyography signals",
            "venue": "In 2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),",
            "year": 2020
        },
        {
            "authors": [
                "Wentao Wei",
                "Yongkang Wong",
                "Yu Du",
                "Yu Hu",
                "Mohan Kankanhalli",
                "Weidong Geng"
            ],
            "title": "A multi-stream convolutional neural network for semg-based gesture recognition in muscle-computer interface",
            "venue": "Pattern Recognition Letters,",
            "year": 2019
        },
        {
            "authors": [
                "Fernando Quivira",
                "Toshiaki Koike-Akino",
                "Ye Wang",
                "Deniz Erdogmus"
            ],
            "title": "Translating semg signals to continuous hand poses using recurrent neural networks",
            "venue": "IEEE EMBS International Conference on Biomedical & Health Informatics (BHI),",
            "year": 2018
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova"
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Association for Computational Linguistics,",
            "year": 2019
        },
        {
            "authors": [
                "Ze Liu",
                "Yutong Lin",
                "Yue Cao",
                "Han Hu",
                "Yixuan Wei",
                "Zheng Zhang",
                "Stephen Lin",
                "Baining Guo"
            ],
            "title": "Swin transformer: Hierarchical vision transformer using shifted windows",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV),",
            "year": 2021
        },
        {
            "authors": [
                "Zheng Chen",
                "Ziwei Yang",
                "Lingwei Zhu",
                "Wei Chen",
                "Toshiyo Tamura",
                "Naoaki Ono",
                "MD Altaf-Ul-Amin",
                "Shigehiko Kanaya",
                "Ming Huang"
            ],
            "title": "Automated sleep staging via parallel frequency-cut attention",
            "venue": "arXiv preprint arXiv:2204.03173,",
            "year": 2022
        },
        {
            "authors": [
                "Wei Qu",
                "Zhiyong Wang",
                "Hong Hong",
                "Zheru Chi",
                "David Dagan Feng",
                "Ron Grunstein",
                "Christopher Gordon"
            ],
            "title": "A residual based attention model for eeg based sleep staging",
            "venue": "IEEE Journal of Biomedical and Health Informatics,",
            "year": 2020
        },
        {
            "authors": [
                "Ricardo V. Godoy",
                "Anany Dwivedi",
                "Minas Liarokapis"
            ],
            "title": "CC-BY-NC-ND 4.0 International license made available under a (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is The copyright holder for this preprint this version posted June 6, 2023",
            "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering,",
            "year": 2022
        },
        {
            "authors": [
                "Elahe Rahimian",
                "Soheil Zabihi",
                "Amir Asif",
                "Dario Farina",
                "Seyed Farokh Atashzar",
                "Arash Mohammadi"
            ],
            "title": "Fs-hgr: Few-shot learning for hand gesture recognition via electromyography",
            "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering,",
            "year": 2021
        },
        {
            "authors": [
                "Aarti Goyal",
                "Toshanlal Meenpal"
            ],
            "title": "Patch-based dual-tree complex wavelet transform for kinship recognition",
            "venue": "IEEE Transactions on Image Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Mohsen Ghorat",
                "G.B. Gharehpetian",
                "Hamid Latifi",
                "Maryam A. Hejazi"
            ],
            "title": "A new partial discharge signal denoising algorithm based on adaptive dual-tree complex wavelet transform",
            "venue": "IEEE Transactions on Instrumentation and Measurement,",
            "year": 2018
        },
        {
            "authors": [
                "Zheng Chen",
                "Ziwei Yang",
                "Dong Wang",
                "Ming Huang",
                "Naoaki Ono",
                "Md Altaf-Ul-Amin",
                "Shigehiko Kanaya"
            ],
            "title": "An end-to-end sleep staging simulator based on mixed deep neural networks",
            "venue": "IEEE International Conference on Bioinformatics and Biomedicine (BIBM),",
            "year": 2021
        },
        {
            "authors": [
                "Chun-Hao Chang",
                "Ladislav Rampasek",
                "Anna Goldenberg"
            ],
            "title": "Dropout feature ranking for deep learning models",
            "venue": "arXiv preprint arXiv:1712.08645,",
            "year": 2017
        },
        {
            "authors": [
                "Manfredo Atzori",
                "Matteo Cognolato",
                "Henning M\u00fcller"
            ],
            "title": "Deep learning with convolutional neural networks applied to electromyography data: A resource for the classification of movements for prosthetic hands",
            "venue": "Frontiers in neurorobotics,",
            "year": 2016
        },
        {
            "authors": [
                "Yu Hu",
                "Yongkang Wong",
                "Wentao Wei",
                "Yu Du",
                "Mohan Kankanhalli",
                "Weidong Geng"
            ],
            "title": "A novel attention-based hybrid cnn-rnn architecture for semg-based gesture recognition",
            "venue": "PloS one,",
            "year": 2018
        },
        {
            "authors": [
                "Sidharth Pancholi",
                "Amit M Joshi",
                "Deepak Joshi"
            ],
            "title": "A robust and accurate deep learning based pattern recognition framework for upper limb prosthesis using semg",
            "venue": "arXiv preprint arXiv:2106.02463,",
            "year": 2021
        },
        {
            "authors": [
                "Elahe Rahimian",
                "Soheil Zabihi",
                "Amir Asif",
                "Dario Farina",
                "S Farokh Atashzar",
                "Arash Mohammadi"
            ],
            "title": "Temgnet: Deep transformer-based decoding of upperlimb semg for hand gestures recognition",
            "venue": "arXiv preprint arXiv:2109.12379,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Movement Recognition via Channel-Activation-Wise sEMG Attention Jiaxuan Zhanga,\u2217, Yuki Matsudaa, Manato Fujimotob, Hirohiko Suwaa and Keiichi Yasumotoa aNara Institute of Science and Technology (NAIST), Ikoma, Nara 630-0192, Japan bOsaka Metropolitan University, Osaka, Osaka 558-8585, Japan\nA R T I C L E I N F O Keywords: sEMG Movement recognition Gestures classification Transformer\nA B S T R A C T Context: Surface electromyography (sEMG) signals contain rich information recorded from muscle movements and therefore reflect the user\u2019s intention. sEMG has seen dominant applications in rehabilitation, clinical diagnosis as well as human engineering, etc. However, current feature extraction methods for sEMG signals have been seriously limited by its stochasticity, transiency, non-stationarity. Objective: Our objective is to combat the difficulties induced by the aforementioned downsides of sEMG and thereby extract representative features for various downstream movement recognition. Method: We propose a novel 3-axis view of sEMG features composed of temporal, spatial, and channel-wise summary. We leverage the state-of-the-art architecture Transformer to enforce efficient parallel search and to get rid of limitations imposed by previous work in gesture classification. Results: We compared the proposed method against existing methods on two Ninapro datasets consisting of data from both healthy people and amputees. Experimental results show the proposed method attains the state-of-the-art (SOTA) accuracy on both datasets. We further show that the proposed method enjoys strong generalization ability: a new SOTA is achieved by pretraining the model on a different dataset followed by fine-tuning it on the target dataset."
        },
        {
            "heading": "1. Introduction",
            "text": "Studying neuromuscular processes in electrical stimulation is an important step toward understanding the myoelectric control mechanism in humans [1]. Surface electromyography (sEMG) is a diagnostic tool recording the activation of the muscle cells with millisecond resolution that is widely used for measuring and evaluating the electrical response associated with skeletal muscle activities [2]. Dated back to the 1960s, sEMG has been used as the capable signal to control simple prosthetic grippers with a single degree of freedom (DOF). In recent years, sEMG has also seen applications in computer games [3], virtual reality [4], humanmachine interfaces (HMI) [5], robotic control [6]. But perhaps more importantly, it has been identified as a powerful tool in physiology such as assistant diagnosis in identifying abnormal gaits, Parkinson\u2019s disease (PD) [7], and Cerebral palsy (CP) in children [8].\nSuccessful sEMG applications require high-quality and informative signal recordings. Unfortunately, there are several non-trivial obstacles in the way of obtaining clear and informative sEMG patterns. For example, sEMG signals are transient, stochastic, non-stationary, nonlinear and nonpredictable [9]. Noise contamination composes another problem and is usually unavoidable due to the nature of noninvasive signal acquisition from the surface of the skin. Depending on sEMG collecting equipment and protocol, different types of noise can be found within the signals such as motion artifacts or power line interference. The level of contamination of sEMG signals is dynamic and varies in realworld environments, introducing confounding variability to the signals and may uncorrelated the signals to the motions of interest [10]. Besides noises, muscles themselves are potential sources of confusion: a muscle is composed of many\n\u2217Corresponding author zhang.jiaxuan.ze4@is.naist.jp (J. Zhang)\ninformation domain for movement recognition by sEMG? We would give an answer here: the muscle-activation-wise sEMG channels.\nmotor units (MU), and the discharge or firing process of each MU generates a motor unit action potential which is the sum of the contributions from individual fibers that compose the MU [11]. As a result, sEMG recordings always contain massive and redundant information, reliably extracting informative representations from such massive noise-involved and redundant signals is non-trivial and has been a pending challenge to physiological research as well as to any downstream tasks.\nConventional feature extraction on sEMG recordings emphasizes expert knowledge by manually selecting features, often the output of some statistical methods from spatial or spatio-temporal spaces such as spectrum, wavelet, etc [12]. If the hand-crafted feature spaces are well-established, superior performance can be expected. Indeed, classic ma-\nPage 1 of 11\nchine learning methods such as Random Forest (RF) [13], k-Nearest Neighbor (kNN) [14], and support vector machine (SVM) [9] have recently been dominant in the community as they have shown promising performance on top of expertmade feature spaces. However, increasing evidence shows that these conventional methods can fail miserably for poorly or incompletely captured features in complicated tasks such as stochastic and transient bursts. This is because these methods represent only sensible decision-making given informative features, yet leaving how to build an informative feature space given complicated signal sources a pending question. In light of the aforementioned downsides of manual feature engineering, numerous studies have been devoted to building end-to-end pipelines; that is, methods that integrate feature extraction and decision-making into a single machine learning model for various downstream tasks.\nThe recently successful deep learning has provided a possible solution to the aforementioned problems and building superior end-to-end platforms [15]. Promising preliminary results have been shown on surface muscle signal processing problems. Theoretically, it is well-known that deep learning models with nonlinearity can approximate complicated nonlinear functions arbitrarily well, which stands as a sheer contrast to the conventional methods. Practically, variants of deep learning models have been developed for different use cases. For example, some works leveraged convolutional neural networks to capture local patterns and variations from sEMG as informative features [16]. However, though convolution can express channel connectivity of different muscle signals, the local inductive bias of CNNs inevitably leads to the loss of global information [17]. Another branch of work focused on modeling the time-series property of sEMG signals [18]. Recurrent neural networks (RNNs), such as Long Short Term Memory (LSTM), bi-LSTM, and Gated recurrent unit (GRU) can effectively summarize global information that varies with time [19]. However, the issue of variability in sEMG signals, caused by the transient and stochastic nature of the neural drive to muscles persists and can greatly perturb the performance of RNNs. While remarkable performance has been shown in language processing in which sentences have global structures, RNNs often struggle with temporal sEMG problems where local information such as the time-dependent spikes in sEMG are as important as global contexts such as the number of bursts or overall amplitude.\nThe nuances as the result of noise-contaminated muscle motor units apparently demand more sophisticated models capable of providing extra modeling power over existing architectures such as CNNs or RNNs: it is desired that both local variations and global summary of the conventional spatio-temporal domains could be extracted and displayed onto a new feature domain to serve as a better representation [20]. The state-of-the-art (SOTA) model on a variety of complicated tasks such as vision Transformer, [21, 22] comes to rescue by searching among all sEMG channels for those responsible for a specific muscle move [23]. The resultant novel time-frequency-channel representation offers a\nnew paradigm for sEMG feature extraction: since human movements typically activate only a few number of muscles, the majority of sEMG channels are not responsible for that move. Taking as input the whole channel information as CNNs or RNNs can corrupt information since noise accumulates across channels as the model proceed sequentially. By contrast, the channel-wise parallel processing of the Transformer is capable of quickly finding the channels that are responsible for a specific move, hence providing more informative and less contaminated features.\nSpecifically, we propose a novel, better feature extraction method that combines conventional feature processing with a state-of-the-art deep learning model. For each channel, we first apply wavelet transform to extract distinct frequency features. Similar to its application in word embedding, the Transformer is leveraged to embed local spatiotemporal wavelets in a channel-wise manner and to globally search for specific channels responsible for a given muscle movement. In this work, we consider sEMG classification but the time-frequency-channel representation is generally applicable and we believe it is the key contribution of the paper. To verify the proposed method, we compare it against several well-established feature engineering methods and perform feature ranking to find what constitutes important features. We summarize the main contributions of this paper as the following:\n\u2022 This work is the first approach to propose a novel 3- axis feature representation for sEMG signals realized by a new architecture built upon the state-of-the-art Transformer model.\n\u2022 We compare against conventional feature engineering methods and perform feature ranking to demonstrate the proposed pipeline enjoys strong interpretability besides superior performance.\n\u2022 We successfully achieve new state-of-the-art classification results by the novel framework in different databases.\nThe paper is organized as follows: Section II provides a brief overview of relevant literature. In Section III, we present the dataset and feature extraction. The proposed architecture is developed in Section IV. Experimental results and different evaluation scenarios are presented in Section V. Finally, Section VI concludes the paper."
        },
        {
            "heading": "2. Related Work",
            "text": "In this section, we position our work in the literature by providing a brief review of related work in chronicle order to illustrate how sEMG models have evolved from the conventional statistical learning-based methods to recent architectures focusing on sophisticated deep models."
        },
        {
            "heading": "2.1. Statistical Learning Methods",
            "text": "It is vital to recognition as well as to any downstream tasks how the sEMG features are extracted and represented.\nPage 2 of 11\nepisode is firstly converted to a time-frequency wavelet transformation. Then, different feature extraction methods are applied to this transformation and a set of feature vectors corresponding to different channels is generated. These feature vectors are embedded in a patch sequence. Each patch represents one feature vector for each sEMG channel is projected to a high dimension by using a patch-wise fully connected layer. Afterward, the augmented patch sequence is fed to the channel-wise Transformer model which can be viewed as containing a set of sub-networks. After training, a relevance calculation is conducted by the model to find the channel relevance for different sEMG recognition targets, e.g., different gestures.\nConventionally, such representation extraction is done by manually selecting from the spatial domain and/or the temporal domain [24]. Different statistical methods are used for extraction, such as spectrogram transformation [25], entropybased analysis [26], spike simulation [2], wavelet transformation [1], empirical mode decomposition [27], etc. Representative and informative features are the guarantee for the performance of subsequent learning. In the community, the current dominant trend is to have the classic statistical learning algorithms integrate the features and distill recognizable sEMG features for downstream tasks. For example, Tommasi et al. [28] proposed to utilize SVM to classify up to seven different hand movements by adaptation based on multiple pre-trained models. In [29], a classification task composed of 15 hand movements from persons with intact limbs and 12 from amputees was performed leveraging the Linear Discriminant Analysis (LDA) and SVM based on the autoregressive features. In [30], energy-based features were used with the nonparametric kNN for the classification of gestures using the sEMG recordings. In all these statistical learning methods, a key limitation is that the feature spaces could never be more expressive than the optimal spanning of the manually selected features. Manual design of relevant features is often incomplete, inaccurate, and insufficient for representing highly complicated patterns [4], say the nonlinear non-stationary variations."
        },
        {
            "heading": "2.2. Deep Learning Based Methods",
            "text": "Benefiting from deep architectures composed of nonlinear activation units, deep learning models have been shown to be capable of approximating complicated functions arbitrarily well. The community has seen an increasing number of research leveraging deep learning as an automated feature extractor to decode sEMG signals [31]. Moreover, deep learning enjoys additional benefits such as the ease of integrating decision-making module with the feature extractor into one end-to-end model. Such models can signifi-\ncantly benefit from the recent advance in computing power by deploying the model in parallel such as on the powerful graphics processing unit. Quivira et al. [32] introduced CNNs to the diagnosis of neuromuscular disorders to extract wavelet features for detecting and classifying anomalous sEMG signals. Their experiment showed promising results that real-time detection of neuromuscular disorders is possible. Wei et al. [33] proposed to utilize multi-stream CNN that takes as input and process segment of images in parallel to provide patch-wise analysis of images. Their result demonstrated state-of-the-art accuracy at the cost of 10- 20% higher computational complexity than other architectures. More recently, [34] built an accurate regression model to predict hand joint kinematics from sEMG features by using RNN with LSTM cells to account for the non-linear relationship between sEMG and hand poses. They experimented with 7 users to test the performance of the proposal and the results showed the model was capable of accurately capturing simple hand gestures such as finger flexion. It is worth noting that, the mainstream SOTA deep learning models such as variants of CNNs or RNNs have a salient shortcoming for sEMG signals: the sequential features of sEMG signals tend to be ignored. This issue is especially noticeable in the much more time-consuming and unstable RNN-based models."
        },
        {
            "heading": "2.3. The SOTA Transformer",
            "text": "As one of the most important machine learning tasks, vision and natural language processing have witnessed a breakthrough [35, 36] due to the advent of Transformer [21]. Different from previous deep learning models, it features the novel self-attention architecture that allows for efficient parallel search in the local as well as global context. Specifically, the attention mechanism attends more to contextually salient factors without considering the information transfer of time step [37]. The novel architecture proves to be superior when the modeled objects exhibit local-global structures\nPage 3 of 11\nTable 1\n18 features extracted from DTCWT used in this paper and their brief explanations.\nID Method Explanation\n\ud835\udc391 Mean Absolute Value the mean absolute value of signals \ud835\udc392 Standard Deviation standard deviation of signals \ud835\udc393 Skewness 3rd moment of signal distribution \ud835\udc394 Kurtosis 4th moment of signal distribution \ud835\udc395 Zero Crossing #the instantaneous point at which there is no voltage present \ud835\udc396 Average Energy the squared sum of the sample values in the time window \ud835\udc397 Waveform Length the cumulative length of the waveform over the sample segment \ud835\udc398 Maximum Fractal Length the maximum length of fractal dimension feature \ud835\udc399 Integrated EMG the area under the curve of the rectified signal \ud835\udc3910 Root Mean Square the square root of the arithmetic mean of the square values \ud835\udc3911 Log Detector the estimated value of contractility \ud835\udc3912 Log Difference Absolute Mean Value log difference of two independent values \ud835\udc3913 Coefficient of Variation a standardized measure of the dispersion of frequency distribution \ud835\udc3914 Difference Absolute Mean Value difference of two independent values drawn from a distribution \ud835\udc3915 Difference Absolute Standard Deviation Value 1st difference of the dispersion in a set of data \ud835\udc3916 Difference Variance Value difference variance value of wavelength \ud835\udc3917 Enhanced Mean Absolute Value the estimated value of the exerted force \ud835\udc3918 Simple Square Integral the quadratically integrable function\nsuch as sentences or images. In physiology and health care, it has very recently been utilized to provide clinical support [38].\nIn 2022, Transformer has seen extensions to sEMG recognition [31, 39]. Specifically, in work [31] a novel convolutional vision transformer (CviT) with stacking ensemble learning was proposed for the fusion of sequential and spatial features of sEMG signals with parallel training. Their experimental results demonstrated the proposed CviT obtained better performance than most current approaches. In addition, the successful application of Transformer in sEMGbased movements classification provides a significant reference for the application of Transformer in other biological signals [31]. In [39], the transformer architecture was leveraged for decoding object motions in dexterous in-hand manipulation tasks using raw EMG signals input. Their new architecture Temporal Multi-Channel Transformers and Vision Transformers were shown to outperform RF-based models and CNNs in terms of accuracy and speed of decoding the motion.\nIt is worth noting that, these work focused only on leveraging the transformer on the frequency and/or spatial-temporal features, neither considered expanding the feature space via another view as our proposed method do. As will be shown in the experimental section, our proposed new representation brings a significant improvement over their methods."
        },
        {
            "heading": "3. Methods",
            "text": "In this section, we describe the pipeline and the details of the proposed method. We first explain the signal preprocessing in Section 3.1. Then, Section 3.2 and 3.3 introduce the Spatio-temporal transformation and its feature extraction methods in different channels. Finally, the framework construction of the proposed channel-wise Transformer\nis described in Section 3.4."
        },
        {
            "heading": "3.1. Pre-processing",
            "text": "Our preprocessing pipeline consists of as the first step a signal filter. Since sEMG recordings are typically contaminated with various types of noises from sensing, device, etc, we used the 3-order Butterworth bandpass filter within a 5-500 Hz setting for each subject signal. The second step is sample generation by a 200ms moving window with half-overlapping for sample segmentation following the work [40]."
        },
        {
            "heading": "3.2. DTCWT Transformation",
            "text": "As previously mentioned, this work aims to recognize informative sEMG patterns by three-axis features (temporal-, spatial-, and channel-domain), hence, we first generally exploit sEMG temporal-spatial features. Wavelet transformation is one of the most well-known signal processing methods that can provide temporal-spatial features [41]. The determination of wavelet type, mother wavelet, and implementation techniques are the key components of the wavelet transform based temporal-spatial representations. While many wavelets and variations have been proposed, it is commonly perceived that dual-tree complex wavelet transform (DTCWT) is currently the best wavelet transform used for sEMG recognition [42]. Because DTCWT approximates the shift-invariance property and improves upon the aliasing effects. In this work, we adopt the DTCWT to first extract temporal-spatial features followed by applying coefficients to effectively represent global and local features from sEMG samples.\nIn the first step of the wavelet transform, the input signal, \ud835\udc65(\ud835\udc61) passes through two filters: high- and low-frequency. Their outputs are called detail and approximation coefficients, respectively, here, \ud835\udf13\u210e(\ud835\udc61) and \ud835\udf13\ud835\udc54(\ud835\udc61) are real-valued wavelets\nPage 4 of 11\nand the complex-valued wavelet \ud835\udf13\ud835\udc50(\ud835\udc61) is obtained as \ud835\udf13\ud835\udc36 (\ud835\udc61) = \ud835\udf13\u210e(\ud835\udc61) + \ud835\udc57\ud835\udf13\ud835\udc54(\ud835\udc61). (1)\nwhere the right items need to first calculate by the real component of wavelet coefficient \ud835\udc51\ud835\udc59(\ud835\udc45\ud835\udc52)(\ud835\udc58) and approximationcoefficient \ud835\udc4e\ud835\udc57(\ud835\udc45\ud835\udc52)(\ud835\udc58):\n\ud835\udc51\ud835\udc59(\ud835\udc45\ud835\udc52)(\ud835\udc58) = 2\ud835\udc59\u22152\u222b\n\u221e\n\u2212\u221e \ud835\udc65(\ud835\udc61)\ud835\udf13\u210e(2\ud835\udc59\ud835\udc61\u2212 \ud835\udc58)\ud835\udc51\ud835\udc61, \ud835\udc59 = 1\u22ef \ud835\udc3d (2)\n\ud835\udc4e\ud835\udc3d (\ud835\udc45\ud835\udc52)(\ud835\udc58) = 2\ud835\udc3d\u22152\u222b\n\u221e\n\u2212\u221e \ud835\udc65(\ud835\udc61)\ud835\udf19\u210e(2\ud835\udc3d \ud835\udc61 \u2212 \ud835\udc58)\ud835\udc51\ud835\udc61. (3)\nwhere \ud835\udc57 is the index of the scale factor \ud835\udc3d which controls the frequency content. Therefore, the output of DTCWT can be expressed by making a summation of the output trees.\n\ud835\udc51\ud835\udc36\ud835\udc59 (\ud835\udc58) = \ud835\udc51\ud835\udc59(\ud835\udc45\ud835\udc52)(\ud835\udc58) + \ud835\udc57\ud835\udc51\ud835\udc59(\ud835\udc3c\ud835\udc5a)(\ud835\udc58), \ud835\udc59 = 1\u22ef \ud835\udc3d (4)\n\ud835\udc4e\ud835\udc36\ud835\udc3d (\ud835\udc58) = \ud835\udc4e\ud835\udc3d (\ud835\udc45\ud835\udc52)(\ud835\udc58) + \ud835\udc57\ud835\udc4e\ud835\udc3d (\ud835\udc3c\ud835\udc40)(\ud835\udc58). (5) Consequently, the 1-D signal parts are obtained by re-\nplacing \ud835\udf13\u210e(\ud835\udc61) and \ud835\udf19\u210e(\ud835\udc61) with \ud835\udf13\ud835\udc54(\ud835\udc61) and \ud835\udf19\ud835\udc54(\ud835\udc61), respectively."
        },
        {
            "heading": "3.3. Spatio-Temporal Feature Extraction",
            "text": "Following the preprocessing of sEMG signals, the sEMG time series is changed to the time-frequency domain. This step is followed by feature extraction: a spatio-temporal vector (\ud835\udc4b\ud835\udc46\ud835\udc47 ) is generated by the following 18 feature extrac-tion methods for each channel in each sample. The details of 18 feature extraction methods can be found in Table 1. After feature extraction, we concatenate all channel-wise vectors to construct a feature matrix for each sample denoted as \ud835\udc4b\ud835\udc46\ud835\udc47 \u2208 \u211d\ud835\udc51\u00d7\ud835\udc50 , where \ud835\udc37 represents the number of extractedspatial-temporal features and \ud835\udc36 the number of channels. We consider these features have some functional overlap, such as, the \u2018Standard deviation\u2019 and \u2018Difference absolute standard deviation value\u2019, and the redundant features may lead to noise to the sEMG recognition as well as decrease the performance. Hence, a deep feature ranking method is introduced to this work to refine the feature vector construction. The details will be shown in Section 3.4.2."
        },
        {
            "heading": "3.4. Channel-wise Transformer",
            "text": "The extracted Feature matrix is fed into a deep-learning model for downstream tasks such as classification. However, the feature output should be conventionally compressed, e.g., reshaped to a vector for matching the input size of the fully connected layer. Such compression would destroy the independence between time-frequency and channel domains. Hence, a novel deep learning method, Transformer, that individually processes and summarizes the dependency is called for [22]. The transformer creates a set of sub-networks to handle different feature sub-spaces (rows or columns in the feature matrix). Relevant features among these sub-networks\nformer.\nare then found by the well-known attention mechanism [43]. Introducing the Transformer to sEMG recognition naturally suits to our proposal for processing and tracking individual contributions from the sEMG channels. Each channel index vector \ud835\udc36 of \ud835\udc4b\ud835\udc46\ud835\udc47 is taken as input to a sub-network for re-taining the feature space."
        },
        {
            "heading": "3.4.1. Channel Sequence Embedding",
            "text": "In detail, for each input \ud835\udc4b\ud835\udc46\ud835\udc47 , we first embed each col-umn to a higher dimensional space to keep channel independence. We split the channels for independent linear projection. Each linear projection operation functions to spatiotemporal feature space that projects the original feature space with \ud835\udc51 dimension to a richer space of dimension \ud835\udc51\u2032. A channelwise sequence (\ud835\udc46\ud835\udc50\u210e) is subsequently generated as the inputto Transformer. Inspired by [22], an extra class token \ud835\udc46\ud835\udc36\ud835\udc59\ud835\udc60 isinserted at the beginning of each sequence \ud835\udc46\ud835\udc50\u210e. As data passthrough the model layers, \ud835\udc46\ud835\udc36\ud835\udc59\ud835\udc60 becomes a new feature sum-marizing the global relevance of channels for downstream decision-making. The above procedure can be described mathematically as:\n\ud835\udc4b\ud835\udc50\u210e = Concat(\ud835\udc46\ud835\udc36\ud835\udc59\ud835\udc60, \ud835\udf16(\ud835\udc46\ud835\udc50\u210e)) + Pos(\ud835\udc38\ud835\udc50\u210e). (6) where \ud835\udf16(\u22c5) is the above mentioned channel-wise linear projection. Since the Transformer abandons the sequential order (positional index) of the input, a sequence of positional encoding with the same size of \ud835\udc46\ud835\udc36\ud835\udc59\ud835\udc60 is generated and usedfor learning the positional importance of each element of \ud835\udc60 during the model training. As a consequence, the sequence \ud835\udc4b\ud835\udc50\u210e is the final input fed to the Transformer model serversto make the downstream decision."
        },
        {
            "heading": "3.4.2. Feature Space Construction via Attention Mechanism",
            "text": "As shown in Figure 3, the Transformer consists of two\nlayers: an attention layer and the multi-layer perceptron (MLP). The attention layer calculates the pair-wise relevance of different patches (sEMG channels) in \ud835\udc4b\ud835\udc50\u210e and maps the rele-vance to the ground truth with three matrices: query \ud835\udc44, key\nPage 5 of 11\n\ud835\udc3e , and value \ud835\udc49 . These three matrices are the projected feature space of\ud835\udc4b\ud835\udc50\u210e, and the attention/relevance based on thesematrices is computed as:\n?\u0302?\ud835\udc36\u210e\ud835\udc4e\ud835\udc5b\ud835\udc5b\ud835\udc52\ud835\udc59\u2212\ud835\udc64\ud835\udc56\ud835\udc60\ud835\udc52 = \ud835\udf0e( \ud835\udc44\ud835\udc3e\ud835\udc47 \u221a\n\ud835\udc51 ) \u22c5 \ud835\udc49 , (7)\nwhere \ud835\udf0e(\u22c5) denotes a patch-wise softmax function. \u221a\ud835\udc51 is a normalization operation that is applied to each\ud835\udc44-\ud835\udc3e computation to control the max-min range of the attention value. The resultant matrix ?\u0302? records the attention score in different sEMG channels calculated by weighting the relevance resulting in \ud835\udf0e(\u22c5) to each row of \ud835\udc49 .\nAfterward, the normalized output of the multi-head attention layer is fed to the MLP layer. The activation function for the MLP layer is the Gaussian error linear units (GELUs) referring to [22]. When \ud835\udc60 iteratively passes through all layers of the Transformer during the training phase, \ud835\udc46\ud835\udc36\ud835\udc59\ud835\udc60 hassummarized the channel\u2019s relevancy information for different classes. This token is separated from the sequence of output and fed into a softmax layer to make the final classification decision. To achieve the feature ranking, we introduce variational dropout regularization [44] to the MLP layer. Because the MLP is the feature-wise MLP that functioned to different spatio-temporal features in each channel. The importance calculation and ranking are conducted by a max-min game of the model training: minimizing the prediction error of classification while maximizing the dropout rate for the rest of the unimportant features. Mathematically, given features , a variational mask distribution \ud835\udc5e\ud835\udf3d(\ud835\udc9b) = \u220f\ud835\udc37\n\ud835\udc57=1 \ud835\udc5e ( \ud835\udc67\ud835\udc57 \u2223 \ud835\udf03\ud835\udc57 ) = \u220f\ud835\udc37 \ud835\udc57=1 Ber ( \ud835\udc67\ud835\udc57 \u2223 \ud835\udf03\ud835\udc57 ) is estimated a fully factorized distribution [44]. Hence, the feature-wise dropout rate \ud835\udf03\ud835\udc57 corresponds to the importance of the \ud835\udc57-th feature ofspatio-temporal features."
        },
        {
            "heading": "3.4.3. Decision Making Module of Transformer",
            "text": "In practice, the attention mechanism is implemented in parallel. Specifically, similar to the multi-channel of CNNs, the attention mechanism can be extended to a set of projected attention implementations (the well-known multi-head of Transformer). The multi-head attention prevents losing the manifold expression of the features. At the beginning of each building block, \u210e (the number of the heads) sets of \ud835\udc44 and \ud835\udc3e are generated and mapped by the linear projection. Then, the attention implements \u210e times in parallel to calculate relevance representations, where each operation is called a \u2018head.\u2019 Eventually, a linear layer projects their concatenated outputs and summarizes the attention result.\n?\u0302?\u210e\ud835\udc52\ud835\udc4e\ud835\udc51\ud835\udc60\ud835\udc60 = Concat(\u210e\ud835\udc52\ud835\udc4e\ud835\udc511, \u210e\ud835\udc52\ud835\udc4e\ud835\udc512,\u22ef , \u210e\ud835\udc52\ud835\udc4e\ud835\udc51\u210e)\ud835\udc4a \ud835\udc5c, (8) where\ud835\udc4a \ud835\udc5c is the head-wise weight matrix while a linear projection is applied after the output of the multi-head attention for each round.\nAs introduced above, the output of the multi-head layer is fed to the MLP layers, with GELU being their activation function. Simultaneously, a residual connection skips each MLP and connects to the output of the building block to\navoid gradient vanishing. For downstream tasks, we solely use \ud835\udc46\ud835\udc36\ud835\udc59\ud835\udc60, which contains spatio-temporal-channel informa-tion for adaptive decision-making such as classification or other tasks. We can explicitly construct a correspondence between the input sEMG samples and different movements in the classification problem so the Transformer outputs probabilities of different classes.\n\ud835\udc66 = \ud835\udf0e(LayerNorm(\ud835\udc46\u2032\ud835\udc36\ud835\udc59\ud835\udc60)), (9) where \ud835\udc66 denotes the different targets of sEMG recognition, and \ud835\udc46\u2032\ud835\udc36\ud835\udc59\ud835\udc60 is the learned class token that is also normalizedbefore the final decision-making module."
        },
        {
            "heading": "4. Experiments",
            "text": ""
        },
        {
            "heading": "4.1. Database",
            "text": "This section briefly discusses the two publicly available benchmark datasets used in the experiments, that is, NinaPro DB2 and NinaPro DB3 from offical Ninaweb 1. In the respective measurement sessions, the sEMG sensors were placed on various muscle locations on the upper limbs. The datasets consist of hand activities broadly categorized into gestures, wrist movements, grasping objects, hand movements, etc. NinaPro DB2: In DB2, the EMG data were collected from 40 healthy subjects (12 females, 6 left-handed and average aged 30 years) who performed in total 49 movements (8 isometric and isotonic hand configurations, 9 basic wrist movements, 23 grasping and functional movements and 9 force patterns). These movements are considered relevant to daily activities of living. These 49 movements are further divided into 4 groups, and each movement was repeated 6 times with a 3-second rest period between. The sEMG signal was recorded using 12 electrodes of a Delsys Trigno Wireless system, which provides a sampling rate of 2,000 Hz [24]. NinaPro DB3: The DB3 contains 11 experimental subjects who are the trans-radial amputees, other information is exactly the same as NinaPro-DB2. According to the authors of NinaPro database, three amputated subjects performed only a part of gestures due to fatigue or pain (3 subjects), and in 2 amputated subjects, the number of electrodes was reduced to ten due to insufficient space, hence the sEMG recordings\n1http://ninaweb.hevs.ch/node/7\nPage 6 of 11\nfrom 6 six subject are used in this work following the experimental configuration used by [16]."
        },
        {
            "heading": "4.2. Experimental Setup",
            "text": "Experiments are conducted by the PyTorch deep learning framework version 1.5.0. We used the AdamW optimizer to minimize the cross entropy loss function for model training. We perform a record-wise 5-fold cross-validation for the model: in each trial, 80% (32 subjects in DB2 and 5 subjects in DB3) of the recordings of samples are used to train models with the other (8 and 1 subjects, respectively) used for the validations. We summarize all parameters in Table 2."
        },
        {
            "heading": "4.3. Ablation Study",
            "text": "Extensive ablation studies are conducted to demonstrate how the proposed method performs when removing specific components. Since we advocate for channel-wise Transformer, we compare the proposed method against:\n\u2022 Temporal-CNN with/without Transformer: CNNs with different kernels are utilized to summarize the temporal information from the raw sEMG signal.\n\u2022 Temporal-CNN + LSTM: Temporal-CNN is associated with the LSTM to model the sequential order information.\n\u2022 Wavelet + LSTM: LSTM is designed on top of DTCWT (referring to Section 3.1) to extract the sequential information in the time domain.\nNinapro DB2 and DB3.\n\u2022 Feature-vector-wise Transformer: The input of Transformer is the different feature index of spatio-temporal feature processed in Section 3.3, and each feature index summarizes all channel information.\n\u2022 Channel-wise LSTM/bi-LSTM: LSTM/bi-LSTM replace to the Transformer that aims to evaluate the effectiveness of whether the parallel attention mechanism is better to the sequential order.\nPage 7 of 11\ncuracy. The window size within 200 has the best performance."
        },
        {
            "heading": "5. Results and Discussion",
            "text": ""
        },
        {
            "heading": "5.1. Results",
            "text": "Observation 1: The proposed model enjoys fast and smooth learning. From Figure 4 it is visible that the proposed method enjoys fast learning. The accuracy lines in Figure 4 (a) quickly reached above 0.8 and 0.6 respectively within only 25 epochs. Compared to the convergence rate in the most of previous studies (normally after 50-75), the proposed method has the power in summarizing the representational features for downstream tasks. Moreover, from the right subplot in Figure 4 (b) it can be seen that the loss curves are smooth, even though the training epoch (200) is far from the 25 iterations. The convergence range in DB2 and DB3 has a consistency after the training, such results indicating sufficient training of the model without overfitting issues.\nObservation 2: The proposed model achieves SOTA and generalization ability. We compared the proposed method against existing state-of-the-art (SOTA) methods on both Ninapro DB2 and DB3 dataset and summarized the results in Table 3 and Table 4. It is visible that the proposed frame-\nand the classification performance in DB2.\nTemporal-CNN; Abla2: Temporal-CNN+LSTM; Abla3: Wavelet+LSTM; Abla4: Temporal-CNN+Transformer; Abla5: Feature-wise+Transformer; Abla6: Unidirectional LSTM; Abla7: Bi-directional LSTM; Abla8 (Proposal): Channel-wise Transformer\nwork achieved new SOTA on both datasets. As we can see, the proposal achieves 0.91 accuracy which outperforms the previous work in DB2. Although the performance of the proposed method in sole DB3 does not reach the best result, applying the pretrain-to-fine-tuning strategy based on DB2, the proposed method has the best accuracy which outperforms the 0.81 accuracy in work [47]. However, both training and testing accuracy on DB3 dataset seems to underperform that of DB2. This is because DB3 consists of a small amount of samples recorded from amputees. To improve the performance, we pretrain the model on DB2 and then transfer it to DB3 for fine-tuning. The resulting performance reached an accuracy of 0.84, which proves the superiority of the model as well as its generalization ability across datasets.\nObservation 3: Different window sizes and the num-\nPage 8 of 11\nber of features have an impact on the recognition performance of sEMG. In Table 3 and Table 4 we see the related work used different window sizes. To verify which size empirically works the best for the proposed model we swept the set [100, 150, 200, 400, 800] on both datasets. From Figure 5 it is visible that window size 200 performed the best on both DB2 and DB3. On the other hand, overly large window sizes have a negative impact on the performance since they might include more redundant noises.\nSince we introduce the MLP dropout feature ranking into this work, Figure 6 shows classification performances in the different feature vector settings with different numbers of features. With the decreasing number of features, the performance has gradually improved. Table 5 shows the details of selected features. Finally, only 8 features are the representative components embedded in sEMG channels used in this work. However, the classification performance is reduced when the F4 (Kurtosis) and F8 (Maximum Fractal Length) have dropped out of the feature vector, that is, these two features might have strong correlations to the sEMG recognition. This result proves there is some redundant and alternative information in the feature extraction or selection.\nObservation 4: The Transformer outperforms other architectures on the investigated problems. In Figure 7 we compared the performance of various ablation choices introduced in Section 4.3. The five red columns show the accuracy resulting from different feature extraction methods. However, they are all significantly lower than the two green columns representing LSTM-based channel-wise methods. Nevertheless, the green columns are also outperformed by Transformer by around 0.1, indicating the limitation brought by the temporal and Markov properties of the LSTM. As summary, it might be safe to conclude that the Transformer architecture achieves the best among the discussed candidates on the investigated problems."
        },
        {
            "heading": "5.2. Discussion and future work",
            "text": "We have to point out that this study is based on preprocessing of spatio-temporal features: DTCWT and different statistical feature extraction methods and the real input of the Transformer model is a processed feature vector, hence the proposal is a semi-automatic sEMG recognition framework. The feature vector generation inevitably derives some costs in either time or computation. This is a limitation that extends our proposal to the tiny device or IoT environment since the real-time environment requires the lower computational costs possible. One potential solution is to consider an end-to-end deep learning architecture that uses different deep learning methods to replace such conventional feature extractions and to generate the same quality features by automatic findings. Future work will make efforts in this point to explore good candidates for model designs. However, a de novo deep network sometimes has a large model size that is also limited to the tiny device. The main reason is the large-scale parameters, hence, a good model quantization is also needed to transfer the model to a real-time IoT setting.\nAlthough the performance in gesture classification tasks\nbased on public datasets is promising, the work lacks more general validation in different sEMG tasks. Considering a general-purpose model, we will find more suitable experiments for more sEMG tasks, such as robotics control or disorder environments. Meanwhile, more reliable evaluations in non-public/private datasets have been listed in our future plan."
        },
        {
            "heading": "6. Conclusion",
            "text": "In this paper, we proposed a novel 3-view sEMG feature representation enforced by conventional feature processing as well as the state-of-the-art Transformer. As proof of concept, sEMG classification was considered in this work: on two datasets consisting of both healthy people and amputees, we verified the proposed method attained state-of-the-art accuracy compared to existing methods. We also found the proposed model enjoys strong generalization ability in that the highest accuracy on the amputee dataset was achieved by pretraining the model on the healthy people data. We believe this time-frequency-channel representation is generally applicable and leveraging it to studies on gaits is one interesting future direction."
        },
        {
            "heading": "Acknowledgment",
            "text": "This research and development work was partly supported by JSPS KAKENHI JP21K19828."
        }
    ],
    "title": "Movement Recognition via Channel-Activation-Wise sEMG Attention",
    "year": 2022
}