{
    "abstractText": "Artificial neural networks (ANNs) providing sophisticated, power-efficient classification are finding their way into thin-film electronics. Thin-film technologies require robust, layout-efficient devices with facile manufacturability. Here, we show how the multimodal transistor\u2019s (MMT\u2019s) transfer characteristic, with linear dependence in saturation, replicates the rectified linear unit (ReLU) activation function of convolutional ANNs (CNNs). Using MATLAB, we evaluate CNN performance using systematically distorted ReLU functions, then substitute measured and simulated MMT transfer characteristics as proxies for ReLU. High classification accuracy is maintained, despite large variations in geometrical and electrical parameters, as CNNs use the same activation functions for training and classification.",
    "authors": [
        {
            "affiliations": [],
            "name": "Isin Surekcigil Pesch"
        },
        {
            "affiliations": [],
            "name": "Eva Bestelink"
        },
        {
            "affiliations": [],
            "name": "Olivier de Sagazan"
        },
        {
            "affiliations": [],
            "name": "Adnan Mehonic"
        },
        {
            "affiliations": [],
            "name": "Radu A. Sporea"
        }
    ],
    "id": "SP:f69cda32466f85ec120131980c08154fea20fd38",
    "references": [
        {
            "authors": [
                "M.A. Zidan",
                "J.P. Strachan",
                "W.D. Lu"
            ],
            "title": "The future of electronics based on memristive systems",
            "venue": "Nat. Electron",
            "year": 2018
        },
        {
            "authors": [
                "V.K. Sangwan",
                "M.C. Hersam"
            ],
            "title": "Neuromorphic nanoelectronic materials",
            "venue": "Nat. Nanotechnol",
            "year": 2020
        },
        {
            "authors": [
                "O. Krestinskaya",
                "A.P. James",
                "Chua",
                "L.O. Neuromemristive circuits for edge computing"
            ],
            "title": "a review",
            "venue": "IEEE Trans. Neural Netw. Learn. Syst. 31, 4\u201323",
            "year": 2020
        },
        {
            "authors": [
                "A. Mehonic",
                "A.J. Kenyon"
            ],
            "title": "Emulating the electrical activity of the neuron using a silicon oxide RRAM cell",
            "venue": "Front. Neurosci",
            "year": 2016
        },
        {
            "authors": [
                "S Oh"
            ],
            "title": "Energy-efficient Mott activation neuron for full-hardware implementation of neural networks",
            "venue": "Nat. Nanotechnol. https:// doi. org/ 10",
            "year": 2021
        },
        {
            "authors": [
                "A. Mehonic",
                "D. Joksas",
                "W.H. Ng",
                "M. Buckwell",
                "A.J. Kenyon"
            ],
            "title": "Simulation of inference accuracy using realistic rram devices",
            "venue": "Front. Neurosci",
            "year": 2019
        },
        {
            "authors": [
                "Mehonic",
                "A. et al. Memristors"
            ],
            "title": "from in-memory computing, deep learning acceleration, spiking neural networks, to the future of neuromorphic and bio-inspired computing",
            "venue": "Adv. Intell. Syst. 2, 1\u201320",
            "year": 2020
        },
        {
            "authors": [
                "E. Chicca",
                "F. Stefanini",
                "C. Bartolozzi",
                "G. Indiveri"
            ],
            "title": "Neuromorphic electronic circuits for building autonomous cognitive systems",
            "venue": "Proc. IEEE 102,",
            "year": 2014
        },
        {
            "authors": [
                "Z. Sun",
                "G. Pedretti",
                "A. Bricalli",
                "D. Ielmini"
            ],
            "title": "One-step regression and classification with cross-point resistive memory",
            "venue": "arrays. Sci. Adv",
            "year": 2020
        },
        {
            "authors": [
                "D Saito"
            ],
            "title": "IGZO-based compute cell for analog in-memory computing\u2014DTCO analysis to enable ultralow-power AI at edge",
            "venue": "IEEE Trans. Elect. Dev",
            "year": 2020
        },
        {
            "authors": [
                "A.F. Paterson",
                "T.D. Anthopoulos"
            ],
            "title": "Enabling thin-film transistor technologies and the device metrics that matter",
            "venue": "Nat. Commun",
            "year": 2018
        },
        {
            "authors": [
                "J Noh"
            ],
            "title": "Key issues with printed flexible thin film transistors and their application in disposable",
            "venue": "RF sensors. Proc. IEEE 103,",
            "year": 2015
        },
        {
            "authors": [
                "A Daus"
            ],
            "title": "Ferroelectric-like charge trapping thin-film transistors and their evaluation as memories and synaptic devices",
            "venue": "Adv. Electron. Mater",
            "year": 2017
        },
        {
            "authors": [
                "K. Datta",
                "A. Dutt",
                "A. Zaky",
                "U. Chand",
                "D. Singh",
                "Y. Li",
                "Huang",
                "J. C-.Y.",
                "A. Thean",
                "Sabry Aly",
                "M.M. Fledge"
            ],
            "title": "flexible edge platforms enabled by in-memory computing",
            "venue": "Proceedings of the 2020 Design, Automation and Test in Europe Conference and Exhibition (DATE) 1181\u20131186",
            "year": 2020
        },
        {
            "authors": [
                "Y Li"
            ],
            "title": "One transistor one electrolyte-gated transistor based spiking neural network for power-efficient neuromorphic computing system",
            "venue": "Adv. Funct. Mater",
            "year": 2021
        },
        {
            "authors": [
                "D. Ielmini",
                "Z. Wang",
                "Y. Liu"
            ],
            "title": "Brain-inspired computing via memory device physics",
            "venue": "APL Mater",
            "year": 2021
        },
        {
            "authors": [
                "E Ozer"
            ],
            "title": "A hardwired machine learning processing engine fabricated with submicron metal-oxide thin-film transistors on a flexible substrate",
            "venue": "Nat. Electron",
            "year": 2020
        },
        {
            "authors": [
                "E Bestelink"
            ],
            "title": "Versatile thin-film transistor with independent control of charge injection and transport for mixed signal and analog computation",
            "venue": "Adv. Intell. Syst",
            "year": 2000
        },
        {
            "authors": [
                "V. Sze",
                "Y.H. Chen",
                "T.J. Yang",
                "Emer",
                "J. Efficient processing of deep neural networks"
            ],
            "title": "a tutorial and survey",
            "venue": "Proc. IEEE 105, 2295\u20132329",
            "year": 2017
        },
        {
            "authors": [
                "M. Liu",
                "L. Chen",
                "X. Du",
                "L. Jin",
                "M. Shang"
            ],
            "title": "Activated gradients for deep neural networks",
            "venue": "IEEE Trans. Neural Netw. Learn. Syst. https:// doi. org/",
            "year": 2021
        },
        {
            "authors": [
                "R.A. Sporea",
                "M.J. Trainor",
                "N.D. Young",
                "J.M. Shannon",
                "S.R.P. Silva"
            ],
            "title": "Source-gated transistors for order-of-magnitude performance improvements in thin-film digital circuits",
            "venue": "Sci. Rep. 4,",
            "year": 2014
        },
        {
            "authors": [
                "R.A. Sporea",
                "K.M. Niang",
                "A.J. Flewitt",
                "S.R.P. Silva"
            ],
            "title": "Novel tunnel-contact-controlled IGZO thin-film transistors with high tolerance to geometrical variability",
            "venue": "Adv. Mater",
            "year": 1902
        },
        {
            "authors": [
                "R.A. Sporea",
                "S.R.P. Silva"
            ],
            "title": "Design considerations for the source region of Schottky-barrier source-gated transistors",
            "venue": "Proceedings of the International Semiconductor Conference,",
            "year": 2017
        },
        {
            "authors": [
                "R.A. Sporea",
                "X. Guo",
                "J.M. Shannon",
                "S.R.P. Silva"
            ],
            "title": "Effects of process variations on the current in Schottky barrier source-gated transistors",
            "venue": "Proc. Int. Semicond. Conf. CAS",
            "year": 2009
        },
        {
            "authors": [
                "E. Bestelink",
                "O. de Sagazan",
                "Sporea",
                "R.A. P-18"
            ],
            "title": "ultra-compact multi-level digital-to-analog converter based on linear multimodal thin-film transistors",
            "venue": "SID Symp. Dig. Tech. Pap. 51, 1375\u20131378",
            "year": 2020
        },
        {
            "authors": [
                "L Wang"
            ],
            "title": "Tunneling contact IGZO TFTs with reduced saturation voltages",
            "venue": "Appl. Phys. Lett. 110,",
            "year": 2017
        },
        {
            "authors": [
                "M. Hudson Beale",
                "M.T. Hagan",
                "H.B. Demuth"
            ],
            "title": "MATLAB: deep learning toolbox reference",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "1 Vol.:(0123456789) Scientific Reports | (2022) 12:670 | https://doi.org/10.1038/s41598-021-04614-9\nwww.nature.com/scientificreports"
        },
        {
            "heading": "Multimodal transistors as ReLU",
            "text": "activation functions in physical neural network classifiers"
        },
        {
            "heading": "Isin Surekcigil Pesch1, Eva Bestelink1, Olivier de Sagazan2, Adnan Mehonic3 &",
            "text": "Radu A. Sporea1*\nArtificial neural networks (ANNs) providing sophisticated, power-efficient classification are finding their way into thin-film electronics. Thin-film technologies require robust, layout-efficient devices with facile manufacturability. Here, we show how the multimodal transistor\u2019s (MMT\u2019s) transfer characteristic, with linear dependence in saturation, replicates the rectified linear unit (ReLU) activation function of convolutional ANNs (CNNs). Using MATLAB, we evaluate CNN performance using systematically distorted ReLU functions, then substitute measured and simulated MMT transfer characteristics as proxies for ReLU. High classification accuracy is maintained, despite large variations in geometrical and electrical parameters, as CNNs use the same activation functions for training and classification.\nCurrent systems using CMOS, digital technologies with von Neumann architectures, are not best suited to support a massive increase in computing power demands driven by AI development1\u20133. Unconventional and analog computation approaches have emerged as an appealing alternative to CMOS and digital systems, due to the promise of increased energy efficiency and reduced circuit complexity4\u201311.\nIn contrast with mature ULSI CMOS technologies, thin-film, large-area circuits have numerous challenges, limiting the success of complex circuits realized at reasonable cost12,13. The main challenge restricting costeffective development is the thin-film transistor (TFT), a device that comprises the backbone of many large area electronics (LAE). TFT drain current is severely prone electrode misalignments, which occur during manufacturing, resulting in a high degree of device-to-device nonuniformity. While uniformity of operation is a requirement for array-based LAE12, this has not limited the interest of exploring TFTs in edge processing alongside other thin-film architectures3,14\u201316. In this context, analog implementations of signal processing functions are particularly attractive, especially if the TFTs utilized are energy-efficient, as well as robust against variations during manufacturing and operation12. Moreover, complex circuit functions that can be performed in a compact, energy efficient footprint could further complement already attractive edge computing strategies, such as memristive neural networks3,15. Most common approaches to accelerate deep learning use novel nanoelectronic technologies to implement weights (synapses) in artificial neural networks17. Comparably much less attention has been given to efficient implementations of activation functions, which could present significant design and efficiency challenges when implemented with conventional CMOS.\u00a0Such exceptionally efficient decision and classification circuits would be of great functional, economic and social benefit when included in thin-film edge processing units as part of e.g. multi-sensor, distributed or wearable electronics18.\nThe multimodal transistor (MMT)19 (Fig.\u00a01a, b) is a TFT with superior functionality, robustness and energy efficiency, especially in analog and mixed-signal applications. Notably, it can be designed with a linear dependence between input voltage and output current even when operating in saturation19, making it highly suited to operation as a rectified linear unit (ReLU)20, as this function is immediately achievable19. The ReLU function, defined as max(0, x), where x is the input variable, is one of the most used activation functions (AFs) in artificial neural networks (ANNs).\nThe performance of ANN analog accelerators (physical NNs) depends on not only the quality of the training and the precision of physical analog weights (e.g. memristors)7, but also, to some extent, on the accuracy of the AF. Typically, AFs are implemented with operational amplifiers10, which could limit the scaling perspectives. Moreover, while AFs are an important part of the neural network structure, they can also be applied to the gradient during the training process21. Thus, implementation of a robust AF with a single micro/nano-scale device\nOPEN\n1Advanced Technology Institute, Department of Electrical and Electronic Engineering, University of Surrey, Guildford\u00a0GU2\u00a07XH,\u00a0UK.\u00a02IETR-DMM-UMR6164,\u00a0University\u00a0of\u00a0Rennes,\u00a0Rennes,\u00a0France.\u00a03Department of Electronic and\u00a0Electrical\u00a0Engineering,\u00a0University\u00a0College\u00a0London,\u00a0London\u00a0WC1E\u00a06BT,\u00a0UK. *email: r.a.sporea@surrey.ac.uk\n2 Vol:.(1234567890) Scientific Reports | (2022) 12:670 | https://doi.org/10.1038/s41598-021-04614-9\nwould be highly beneficial for further development of ANN accelerators based on non-CMOS analog devices and in-memory computing concepts.\nHere, we investigate the practicality of using the MMT\u2019s transfer characteristic as a viable ReLU AF for future thin-film ANNs with high classification accuracy, despite relatively large process variations expected in such technologies. Using MATLAB, we simulate a convolutional neural network20 (CNN, Fig.\u00a02a) operating with distortion parameters extrapolated from measured microcrystalline silicon (\u00b5-Si) and simulated amorphous silicon (a-Si) MMT transfer curves as ReLU layer AFs (Fig.\u00a02b), in comparison with the performance of MATLAB\u2019s built-in ReLU AF."
        },
        {
            "heading": "Multimodal transistor operation",
            "text": "Unlike other transistors, where a gate electrode in the channel region is responsible for controlling both charge injection and switching functions, the MMT uses the properties of a reverse-biased energy barrier at the source contact to separate these operational features19. Gate 1 (G1), which overlaps the source, solely controls the magnitude of charge injection in the source-G1 overlap region (SGO). Hence, the G1 transfer characteristic (Fig.\u00a01c) resembles that of any transistor, except the drain current dependence on G1 voltage is either exponential or linear, depending on design, rather than quadratic19. Gate 2 (G2) controls the channel switching without influencing the magnitude of drain current, once the channel is fully accumulated (Fig.\u00a01d), hence the curves flatten and resemble output characteristics. The output characteristics themselves are also flat (Fig.\u00a01e), however, this is due to the nature of the energy barrier at the source contact controlling the charge injection process19,22,23. As long as the semiconductor is thin enough to be completely depleted at the source edge by the drain bias, the device will pinch-off at the source and very low saturation voltages VDSAT can be achieved as per Eq.\u00a0(1)22,24:\nwhere Ci and Cs are the gate insulator and depleted semiconductor capacitances per unit area, and K is the drain voltage required to deplete the charges in the accumulation layer at the insulator interface.\nThe choice of layer geometry and material properties will govern the nature of drain current dependence19,25. For high gain devices with exponential drain current dependence, the capacitance divider should yield a ratio smaller than 0.1. But in this work, some of the gain and VDSAT is traded-off for constant transconductance19. This ability to produce a linear dependence of output on input can be useful for compact analog circuit design, such as digital-to-analog conversion19,26, but as the device naturally replicates the ReLU activation function, the\n(1)VDSAT = (VG1 \u2212 Vth1) ( Ci\nCi + Cs\n)\n+ K\nFigure\u00a01. The multimodal transistor (MMT). (a) Illustrative cross-section and (b) optical micrograph of a microcrystalline silicon (\u00b5-Si) multimodal transistor (MMT). Charge dynamics in the source-gate overlap (SGO) and source-drain separation (d) regions are controlled by the current control gate (Gate 1), and channel gate (Gate 2), respectively19. (c) Simulated amorphous silicon (a-Si) MMT transfer characteristics showing Gate 1 (G1) sets drain current magnitude, while Gate 2 (G2) allows or blocks its flow without influencing its magnitude. (d) Simulated transfer characteristics for G2 further demonstrating that G2 does not influence charge injection processes and thus flatten once the channel is fully accumulated. (e) Output characteristics showing low voltage saturation with high output impedance, expected from contact-controlled devices.\n3 Vol.:(0123456789) Scientific Reports | (2022) 12:670 | https://doi.org/10.1038/s41598-021-04614-9\nMMT can form a useful tool in the design kit for emerging neural network implementations19, particularly for low-cost large area electronics."
        },
        {
            "heading": "Results",
            "text": "MMT electrical measurements (Fig.\u00a03a, b) show typical contact-controlled transistor behavior19,22,23,27, with lowvoltage saturation (Fig.\u00a03b). Most devices demonstrate constant transconductance gm = dID/dVG1 over a significant range of the G1 transfer characteristics (Fig.\u00a03a), while operating in saturation. This is in contrast with the usual constant gm obtained in conventional field-effect transistors exclusively in the linear region of operation. Several of the transfer curves used as practical ReLU implementations in the subsequent analysis are displayed in Fig.\u00a03a.\nTCAD simulations (Fig.\u00a03c, d) confirm that the MMT drain current can be made directly proportional to G1 voltage19, with correct design. Should the off-current of such devices be many orders of magnitude lower than the on-current, the transfer curve would practically match the ReLU definition. Here, we consider several device geometries, source contact work functions, electron mobility values, and temperatures, which distort the MMT transfer curve away from the ideal ReLU shape (Fig.\u00a02b). We modelled the deviation by assigning suitable values to the fitting parameters in Eq.\u00a0(2).\nThe distortion was introduced by tuning the contribution of individual parameters (Fig.\u00a02b) responsible for scaling (k), vertical translation (u), reverse leakage (a, m), horizontal translation or threshold (t), and polynomial behavior (s) through multiplication with respective distortion factors \u03bb (a number between 0 and 1). The parameter values considered for training were larger than any realistic distortion expected from practical MMTs, to amplify and discriminate the effects.\nAs such, the CNN-based experiments were divided into three parts, which differ only in choice of activation function. Here, the objective was not to optimize network accuracy, but to investigate how accuracy varies with device non-idealities.\nFirstly, the accuracy of the network was benchmarked using the default MATLAB ReLU layer, after which, distortions were artificially introduced to emulate possible non-idealities of fabricated MMT transfer characteristics by replacing the default MATLAB ReLU function with a parametrized representation (Fig.\u00a02b and Eq.\u00a0(2), where RT is the total distortion introduced into the ReLU). Table\u00a01 lists the maximum value for each distortion parameter and the average accuracy over five classification runs, in which each parameter was enabled individually (respective \u03bb factor equaling 1 in Eq.\u00a0(2). The network was trained for all the combinations of the six parameters in Eq.\u00a0(2), and the results are shown in Supplementary Table\u00a0S1.\nSecondly, the parameters of Eq.\u00a0(2) were fitted to the measured MMT transfer curves of Fig.\u00a03a by selecting best-fit values for the parameters in Eq.\u00a0(2). Results are shown in Table\u00a02. Device A, which is the closest approximation of the ideal ReLU function, produces the highest accuracy. Network performance drops minutely when a negative threshold exists (Devices B and D) and deteriorates noticeably for devices with a sharper than quadratic increase (s > 1) of drain current with G1 voltage (Devices C and E). This is physically plausible, as MMT current can be designed to vary exponentially with G1 voltage, as the field-dependent reverse-bias current of a Schottky diode19.\nFinally, simulated data (Fig.\u00a03c) produced the results as per Table\u00a03, again based on best-fit values of the parameters in Eq.\u00a0(2). We observe that all simulation conditions lead to very high network accuracy. This is most likely due to the fact that the effect of changing individual parameter values, e.g. mobility or insulator thickness, largely manifests as a scaling factor rather than a significant distortion of the characteristics (see, for example, Fig.\u00a03d).\n(2)RT = uu+\n\n\n\n( mm)x \u2212 aa\n0\n( kk + 1)(x \u2212 t t) ss+1\n\n\n\nx < 0\n0 < x < t t x > t t\nFigure\u00a02. Convolutional neural network (CNN) architecture and ReLU parameter fitting. (a) Schematic representation of the CNN architecture and its input dataset (shown here as a screenshot of a subset of the MATLAB input data\u2014see \u201cMethods\u201d). The activation functions studied are included in the ReLU layer. (b) Graphical representation of the parametrized activation function, \u201ctotal distorted ReLU\u201d (RT), used in the ReLU layer. Distortion was introduced via parameters responsible for: scaling (k), vertical translation (u), reverse leakage (a, m), horizontal translation or threshold (t), and polynomial behavior (s).\n4 Vol:.(1234567890) Scientific Reports | (2022) 12:670 | https://doi.org/10.1038/s41598-021-04614-9"
        },
        {
            "heading": "Discussion",
            "text": "From Tables\u00a02, 3 and S1, it is evident that MMT-based realizations of the ReLU layer contributes to high-accuracy classification. Practical implementations will be prone to device-to-device variations, which may be mitigated by training circuits individually to account for variability. The more convenient approach of training the network at the design phase needs to take into account practical variations, which create large absolute deviations in electrical characteristics. For example, a registration error of several microns in SGO changes k, s and t minimally, whereas changes in carrier mobility or operating temperature leads to unacceptably large variations of k.\nFrom a functional standpoint, the channel gate (G2) and its independent control of current transport could bring additional benefits in unconventional intra-layer and inter-layer connectivity for compact implementation of classification functions.\nFigure\u00a03. MMT characteristics. (a) Normalized transfer characteristics of several \u00b5-Si MMTs showing deviation from the ReLU function. Device A (see the \u201cMethods\u201d section) demonstrates directly proportional dependence of drain current on G1 voltage. See Ref.19 for G2 transfer curves. (b) Measured output curves indicating low saturation voltage. For device geometries, see the \u201cMethods\u201d section. (c) Simulated transfer characteristics for a-Si MMTs with different source-G1 overlap (SGO). (d) Normalized curves to illustrate their deviation from the ReLU function.\n5 Vol.:(0123456789) Scientific Reports | (2022) 12:670 | https://doi.org/10.1038/s41598-021-04614-9"
        },
        {
            "heading": "Conclusion",
            "text": "Using measured and simulated transistor data, we have shown that well-designed multimodal transistors could operate robustly as ReLU-type activations in artificial neural networks, achieving practically identical classification accuracy as pure ReLU implementations, such as the built-in MATLAB AF. The results confirm the potential of MMT devices for thin-film decision and classification circuits integrated with distributed or disposable multiparameter sensors. Applications in wellbeing, health, environmental monitoring and smart agriculture abound.\nIn this initial analysis we have trained the neural network directly with the respective MMT transfer curves. On the way to full implementation, the study will continue with more computationally challenging situations, which consider device-to-device and operating variations in MMT electrical characteristics. It is expected that by closely matching the ReLU function, MMTs could provide a robust implementation of neural network activation functions, able to maintain high classification accuracy despite variability."
        },
        {
            "heading": "Methods",
            "text": "Device fabrication and characterization. Prototype bottom gate MMTs (Fig.\u00a01b) were fabricated at low temperature using mainly ICP-CVD techniques (Corial 210-D), performing both SiO2 and \u00b5\u2013Si layers below 180\u00a0\u00b0C. The process began with deposition of the current control gate (Gate 1 or G1) in Al (Device A) or polysilicon (Devices B-E). A 100\u00a0nm SiO2 gate insulator was deposited before the Al channel control gate (Gate 2 or G2), which was followed by a second 100\u00a0nm SiO2 insulator. 40\u00a0nm \u00b5-Si was also deposited by the same ICP-CVD reactor, followed by 20\u00a0nm SiO2 field plate oxide, which was patterned and etched to open contact windows for Cr source metal deposition to form Schottky contacts. See Ref.19 for full process details.\nMMTs were electrically characterized on a Wentworth probe station connected to a B2902A source/measure unit. The transistor\u2019s source was grounded. An additional Weir 413D power supply unit was used to provide constant 10\u00a0V on G2. MMTs with different geometries (source-G1 overlap and source-drain separation), identified as (SGO/d), were measured. Device A 54\u00a0\u00b5m/18\u00a0\u00b5m; Device B 18\u00a0\u00b5m/6\u00a0\u00b5m; Devices C and D 6\u00a0\u00b5m/6\u00a0\u00b5m; and Device E 18\u00a0\u00b5m/2\u00a0\u00b5m.\nDevice simulation. MMT simulation with Silvaco Atlas v.5.24.1.R used default material parameters for intrinsic a-Si and SiO2.\nStarting from a reference device with a source work function WF = 4.67\u00a0eV (to create the required Schottky barrier), source-G1 overlap SGO = 4\u00a0\u00b5m, semiconductor and insulator thicknesses ts = ti = 40\u00a0nm, respectively, electron mobility parameter \u00b5n = 20 cm2V-1\u00a0 s-1 and default defect distribution, at temperature T = 300\u00a0K, we changed one of the aforementioned quantities (WF, SGO, ts, ti, \u00b5n, T) in an exaggerated fashion to reveal variations in characteristics. As drain current is not modulated by the channel region, source-drain separation was kept constant at d = 4\u00a0\u00b5m. G2 was self-aligned to the drain. See Ref.19 for detailed simulation and structure parameters.\nTable 3. Fitting parameter values and network accuracy for simulated devices in which one design parameter varies; a, u and m are always zero (see complete data in Supplementary Table\u00a0S1).\nSimulation parameter and value\nDistortion parameter CNN accuracy\ns t k Avg SD\nSGO (\u00b5m)\n1 0.000 0.000 0.000 0.9868 0.0029\n4 0.000 0.025 0.030 0.9866 0.0020\n8 0.000 0.030 0.010 0.9850 0.0010\n16 0.030 0.043 0.015 0.9891 0.0013\nts (nm)\n20 0.000 0.043 0.030 0.9873 0.0031\n40 0.000 0.010 0.000 0.9859 0.0027\n80 0.000 0.010 0.000 0.9846 0.0013\nti (nm)\n20 0.000 0.000 0.000 0.9847 0.0012\n40 0.000 0.020 0.008 0.9870 0.0034\n80 0.010 0.043 0.009 0.9854 0.0024\nT (K)\n300 0.000 0.010 0.000 0.9871 0.0024\n320 0.000 0.025 0.008 0.9868 0.0027\n340 0.070 0.025 -0.008 0.9849 0.0020\n\u00b5n (cm2V-1\u00a0 s-1)\n0.2 0.000 0.000 0.000 0.9842 0.0022\n2 0.000 0.000 0.000 0.9841 0.0016\n20 0.000 0.010 0.000 0.9857 0.0024\n200 0.010 0.045 0.030 0.9851 0.0041\nWF (eV)\n4.62 0.000 0.049 0.045 0.9871 0.0024\n4.67 0.000 0.020 0.020 0.9868 0.0027\n4.72 0.000 0.008 0.010 0.9849 0.0020\n6 Vol:.(1234567890) Scientific Reports | (2022) 12:670 | https://doi.org/10.1038/s41598-021-04614-9\nArtificial neural network simulation. A CNN with fully connected layers was created using the MATLAB deep learning toolbox and trained with the standard recommended setup28 (Fig.\u00a02a). The network contained 28 \u00d7 28 \u00d7 1 image input, 24 \u00d7 24 \u00d7 20 convolution 2D, 24 \u00d7 24 \u00d7 20 batch normalization, 24 \u00d7 24 \u00d7 20 ReLU, 1 \u00d7 1 \u00d7 10 fully connected, 1 \u00d7 1 \u00d7 10 softmax, and 1 \u00d7 1 \u00d7 10 classification layers (Fig.\u00a02a). The CNN was trained to recognize handwritten numbers provided in the MATLAB Digits dataset28, containing 10,000 images from the Modified National Institute of Standards and Technology (MNIST)29 dataset.\nAs the network had to be trained numerous times, relatively simple training options were used: 0.01 initial learning rate; 232 iterations; 4 max epochs; and included the algorithm stochastic gradient descent with momentum optimizer. The CNN contained a ReLU layer, which was used by the optimizer algorithm to adjust weights during training (Fig.\u00a02a). The same activation function was used across training and classification tasks."
        },
        {
            "heading": "Data availability",
            "text": "Data and materials can be obtained via the corresponding author, on request.\nReceived: 12 August 2021; Accepted: 28 December 2021"
        },
        {
            "heading": "Acknowledgements",
            "text": "This work was supported in part by EPSRC Grants EP/R511791/1, EP/R028559/1 and EP/V002759/1. Devices were fabricated on the NanoRennes platform.\n7 Vol.:(0123456789) Scientific Reports | (2022) 12:670 | https://doi.org/10.1038/s41598-021-04614-9"
        },
        {
            "heading": "Author contributions",
            "text": "E.B., R.A.S. and A.M. conceptualized the study. E.B. and R.A.S designed the device structures. O.S. fabricated the devices. E.B. performed device characterization and simulation. I.S.P. decided on the ANN methodology and performed ANN simulations. I.S.P., E.B. and R.A.S. performed data analysis and prepared the original draft. R.A.S. supervised the project. E.B., R.A.S. and O.S. were responsible for securing funding. R.A.S and O.S. secured, maintained and administered access to resources and processes used. All authors reviewed the manuscript."
        },
        {
            "heading": "Competing interests",
            "text": "E.B. and R.A.S declare patent application PCT/GB2019/053383. I. S. P., O. S. and A. M. declare no competing interests."
        },
        {
            "heading": "Additional information",
            "text": "Supplementary Information The online version contains supplementary material available at https:// doi. org/ 10. 1038/ s41598- 021- 04614-9.\nCorrespondence and requests for materials should be addressed to R.A.S.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or\nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n\u00a9 The Author(s) 2022"
        }
    ],
    "title": "Multimodal transistors as ReLU activation functions in physical neural network classifiers",
    "year": 2022
}