{
    "abstractText": "In recent years, with the continuous progress of science and technology, the number of scientific research achievements is increasing day by day, as the exchange platform and medium of scientific research achievements, the scientific and technological academic conferences have become more and more abundant. The convening of scientific and technological academic conferences will bring large number of academic papers, researchers, research institutions and other data, and the massive data brings difficulties for researchers to obtain valuable information. Therefore, it is of great significance to use deep learning technology to mine the core information in the data of scientific and technological academic conferences, and to realize a knowledge graph and accurate portrait system of scientific and technological academic conferences, so that researchers can obtain scientific research information faster.",
    "authors": [
        {
            "affiliations": [],
            "name": "Runyu Yu"
        },
        {
            "affiliations": [],
            "name": "Zhe Xue"
        },
        {
            "affiliations": [],
            "name": "Ang Li"
        }
    ],
    "id": "SP:c087a593e5e28f8038b26b70791567e39da8980c",
    "references": [
        {
            "authors": [
                "Li Changzhou",
                "Lu Yao",
                "Wu Junfeng"
            ],
            "title": "LDA meets Word2Vec: a novel model for academic abstract clustering[C]//In",
            "venue": "Companion proceedings of the the web conference,",
            "year": 2018
        },
        {
            "authors": [
                "J Yang",
                "J Du",
                "Y. Shao"
            ],
            "title": "Construction Method of Intellectualproperty-oriented Scientific and Technological Resources Portrait[J",
            "venue": "Journal of Software",
            "year": 2021
        },
        {
            "authors": [
                "A Li",
                "J Du",
                "F Kou"
            ],
            "title": "Scientific and Technological Information Oriented Semantics-adversarial and Mediaadversarial Cross-media Retrieval[J",
            "venue": "arXiv preprint arXiv:2203.08615,",
            "year": 2022
        },
        {
            "authors": [
                "Su Xiaojuan",
                "Zhang Yingjie",
                "Bai Chen",
                "Wu Si"
            ],
            "title": "Research on the Construction and Characteristics of Chinese-English Bilingual Corpus under the Background of Big Data of Science and Technology",
            "venue": "[J]. China Science and Technology Resources Guide,",
            "year": 2019
        },
        {
            "authors": [
                "Wu Zhenxin",
                "Qian Li",
                "Xie Jing",
                "Chang Zhijun",
                "Xu Liyuan",
                "Zhao Yan"
            ],
            "title": "Construction of Big Data System of Scientific and Technological Documents for Smart Knowledge Service[J].Library and Information Work, 2020,64(24):63-72",
            "year": 2020
        },
        {
            "authors": [
                "J Pujara",
                "H Miao",
                "L Getoor"
            ],
            "title": "Knowledge graph identification[C]//International semantic web conference",
            "year": 2013
        },
        {
            "authors": [
                "X Chen",
                "S Jia",
                "Y. Xiang"
            ],
            "title": "A review: Knowledge reasoning over knowledge graph[J",
            "venue": "Expert Systems with Applications,",
            "year": 2020
        },
        {
            "authors": [
                "W Hu",
                "J Gao",
                "B Li"
            ],
            "title": "Anomaly detection using local kernel density estimation and context-based regression[J",
            "venue": "IEEE Transactions on Knowledge and Data Engineering,",
            "year": 2018
        },
        {
            "authors": [
                "Yang Fan"
            ],
            "title": "Library Big Data Practice Based on Portrait Analysis: Taking the National Library of China Big Data Project as an Example [J",
            "venue": "Library Forum,",
            "year": 2019
        },
        {
            "authors": [
                "He Yujie",
                "Du Fang",
                "Shi Yingjie",
                "Song Lijuan"
            ],
            "title": "A Review of Named Entity Recognition Based on Deep Learning [J/OL",
            "venue": "Computer Engineering and Applications:",
            "year": 2021
        },
        {
            "authors": [
                "W Liu",
                "T Xu",
                "Q Xu"
            ],
            "title": "An encoding strategy based wordcharacter LSTM for Chinese NER[C]//Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
            "year": 2019
        },
        {
            "authors": [
                "V Patil N",
                "S Patil A",
                "V. Pawar B"
            ],
            "title": "HMM based Named Entity Recognition for inflectional language[C]//2017 International Conference on Computer, Communications and Electronics (Comptelix)",
            "year": 2017
        },
        {
            "authors": [
                "Z Ju",
                "J Wang",
                "F. Zhu"
            ],
            "title": "Named entity recognition from biomedical text using SVM[C]//2011 5th international conference on bioinformatics and biomedical engineering",
            "year": 2011
        },
        {
            "authors": [
                "M Agarwal",
                "R Goutam",
                "A Jain"
            ],
            "title": "Comparative analysis of the performance of crf , hmm and maxent for part-of-speech tagging, chunking and named entity recognition for a morphologically rich language[J",
            "venue": "Proc. of Pacific Association For Computational Lingustics ,",
            "year": 2011
        },
        {
            "authors": [
                "Y Fang",
                "W Deng",
                "J Du"
            ],
            "title": "Identity-aware CycleGAN for face photo-sketch synthesis and recognition[J",
            "venue": "Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "L Xu",
                "J Du",
                "Q. Li"
            ],
            "title": "Image fusion based on nonsubsampled contourlet transform and saliency-motivated pulse coupled neural networks[J",
            "venue": "Mathematical Problems in Engineering,",
            "year": 2013
        },
        {
            "authors": [
                "J Kong",
                "L Zhang",
                "M Jiang"
            ],
            "title": "Incorporating multi-level CNN and attention mechanism for Chinese clinical named entity recognition[J",
            "venue": "Journal of Biomedical Informatics,",
            "year": 2021
        },
        {
            "authors": [
                "E Strubell",
                "P Verga",
                "D Belanger"
            ],
            "title": "Fast and Accurate Entity Recognition with Iterated Dilated Convolutions[C]//EMNLP",
            "year": 2017
        },
        {
            "authors": [
                "Yang Li",
                "Wu Yuqian",
                "Wang Junli",
                "Liu Yili"
            ],
            "title": "Review of Recurrent Neural Network Research [J",
            "venue": "Computer Applications , 2018,",
            "year": 2018
        },
        {
            "authors": [
                "W Li",
                "Y Jia",
                "J. Du"
            ],
            "title": "Recursive state estimation for complex networks with random coupling strength",
            "year": 2017
        },
        {
            "authors": [
                "S Hochreiter",
                "J. Schmidhuber"
            ],
            "title": "Long short-term memory[J",
            "venue": "Neural computation,",
            "year": 1997
        },
        {
            "authors": [
                "Z Huang",
                "W Xu",
                "K. Yu"
            ],
            "title": "Bidirectional LSTM-CRF models for sequence tagging[J",
            "venue": "arXiv preprint arXiv:1508.01991,",
            "year": 2015
        },
        {
            "authors": [
                "C Dong",
                "J Zhang",
                "C Zong"
            ],
            "title": "Character-based LSTM-CRF with radical-level features for Chinese named entity recognition[M]//Natural Language Understanding and Intelligent Applications",
            "year": 2016
        },
        {
            "authors": [
                "Y Zhang",
                "J. Yang"
            ],
            "title": "Chinese NER Using Lattice LSTM[C]//Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
            "year": 2018
        },
        {
            "authors": [
                "H Yan",
                "B Deng",
                "X Li"
            ],
            "title": "TENER: Adapting Transformer Encoder for Name Entity Recognition[J",
            "venue": "arXiv preprint arXiv:1911.04474,",
            "year": 2019
        },
        {
            "authors": [
                "Mao Mingyi",
                "Wu Chen",
                "Zhong Yixin",
                "Chen Zhicheng"
            ],
            "title": "BERT Named Entity Recognition Model with Self-Attention Mechanism [J",
            "venue": "Journal of Intelligent Systems,",
            "year": 2020
        },
        {
            "authors": [
                "A Vaswani",
                "N Shazeer",
                "N Parmar"
            ],
            "title": "Attention is all you need[J",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "W Li",
                "Y Jia",
                "J. Du"
            ],
            "title": "Variance-constrained state estimation for nonlinearly coupled complex networks[J",
            "venue": "IEEE Transactions on Cybernetics,",
            "year": 2017
        },
        {
            "authors": [
                "H Zhao",
                "Q Liu",
                "H Zhu"
            ],
            "title": "A sequential approach to market state modeling and analysis in online p2p lending[J",
            "venue": "IEEE Transactions on Systems, Man, and Cybernetics: Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Jacob Devlin",
                "C hang Mingwei",
                "Lee Kenton"
            ],
            "title": "BERT: pre-training of deep bidirectional transformers for language understanding [ EB/OL",
            "year": 2021
        },
        {
            "authors": [
                "Dai Zhenjin",
                "Wang Xutao",
                "Ni Pin"
            ],
            "title": "Named en- tity recognition using BERT BiLSTM CRF for Chinese electronic health records[C]//2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics",
            "year": 2019
        },
        {
            "authors": [
                "Li Xiangyang",
                "Zhang Huan",
                "Zhou Xiaohua"
            ],
            "title": "Chinese clinical named entity recognition with variant neural structures based on BERT methods[J",
            "venue": "Journal of bio-medical informatics,",
            "year": 2020
        },
        {
            "authors": [
                "LI Xiaonan",
                "YAN Hang",
                "QIU Xipeng"
            ],
            "title": "FLAT: Chinese NER using flat-lattice transformer[C]//Proceed- ings of the 58th Annual Meeting of the Association for Computational Linguistics",
            "venue": "Stroudsburg, USA: ACL,",
            "year": 2020
        },
        {
            "authors": [
                "W Yoon",
                "H So c",
                "J Lee"
            ],
            "title": "CollaboNet: collabora- tion of deep neural networks for biomedical named en- tity recognition[J",
            "venue": "BMC bioinformatics,",
            "year": 2019
        },
        {
            "authors": [
                "F Kou",
                "J Du",
                "Y He"
            ],
            "title": "Social network search based on semantic analysis and learning[J",
            "venue": "CAAI Transactions on Intelligence Technology,",
            "year": 2016
        },
        {
            "authors": [
                "Y Tong",
                "L. Gu"
            ],
            "title": "A news text clustering method based on similarity of text labels [C]//International",
            "venue": "Conference on Advanced Hybrid Information Processing",
            "year": 2018
        },
        {
            "authors": [
                "A Das",
                "J Mandal",
                "Z Danial"
            ],
            "title": "A novel approach for automatic Bengali question answering system using semantic similarity analysis[J",
            "venue": "International Journal of Speech Technology,",
            "year": 2020
        },
        {
            "authors": [
                "M Qian",
                "J Liu",
                "C Li"
            ],
            "title": "A comparative study of English- Chinese translations of court texts by machine and human translators and the Word2Vec based similarity measure\u2019s ability to gauge human evaluation biases[C]//Proceedings of Machine Translation Summit XVII: Translator",
            "venue": "Project and User Tracks",
            "year": 2019
        },
        {
            "authors": [
                "S Ristad E",
                "N. Yianilos P"
            ],
            "title": "Learning string-edit distance[J",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 1998
        },
        {
            "authors": [
                "S Niwattanakul",
                "J Singthongchai",
                "E Naenudorn"
            ],
            "title": "Using of Jaccard coefficient for keywords similarity[C]//Proceedings of the international multiconference of engineers and computer scientists",
            "year": 2013
        },
        {
            "authors": [
                "M Blei D",
                "Y Ng A",
                "I. Jordan M"
            ],
            "title": "Latent dirichlet allocation[J",
            "venue": "Journal of machine Learning research,",
            "year": 2003
        },
        {
            "authors": [
                "T Mikolov",
                "K Chen",
                "G Corrado"
            ],
            "title": "Efficient estimation of word representations in vector space[J",
            "venue": "arXiv preprint arXiv:1301.3781,",
            "year": 2013
        },
        {
            "authors": [
                "J Pennington",
                "R Socher",
                "D. Manning C"
            ],
            "title": "Glove: Global vectors for word representation[C]//Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)",
            "year": 2014
        },
        {
            "authors": [
                "S Huang P",
                "X HE",
                "J GAO"
            ],
            "title": "Learning deep structured semantic models for web search using clickthrough data",
            "venue": "[C]//Proceedings of the 22nd ACM international conference on Information & Knowledge Management",
            "year": 2013
        },
        {
            "authors": [
                "H Palangi",
                "L Deng",
                "Y Shen"
            ],
            "title": "Semantic modelling with long-short-term memory for information retrieval[J",
            "venue": "arXiv preprint arXiv:1412.6629,",
            "year": 2014
        },
        {
            "authors": [
                "P Neculoiu",
                "M Versteegh",
                "M. Rotaru"
            ],
            "title": "Learning text similarity with siamese recurrent networks[C]//Proceedings of the 1st Workshop on Representation Learning for NLP",
            "year": 2016
        },
        {
            "authors": [
                "L Pontes E",
                "S Huet",
                "C Linhares A"
            ],
            "title": "Predicting the Semantic Textual Similarity with Siamese CNN and LSTM[C]//Traitement Automatique des Langues Naturelles (TALN)",
            "year": 2018
        },
        {
            "authors": [
                "N Reimers",
                "I. Gurevych"
            ],
            "title": "Sentence-BERT: Sentence embeddings using siamese BERT-networks[J",
            "venue": "arXiv preprint arXiv:1908.10084,",
            "year": 2019
        },
        {
            "authors": [
                "B Li",
                "H Zhou",
                "J He"
            ],
            "title": "On the sentence embeddings from pre-trained language models[J",
            "venue": "arXiv preprint arXiv:2011.05864,",
            "year": 2020
        },
        {
            "authors": [
                "Y Gong",
                "H Luo",
                "J. Zhang"
            ],
            "title": "Natural language inference over interaction space[J",
            "venue": "arXiv preprint arXiv:1709.04348,",
            "year": 2017
        },
        {
            "authors": [
                "G Huang",
                "Z Liu",
                "L Van Der Maaten"
            ],
            "title": "Densely connected convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition",
            "year": 2017
        },
        {
            "authors": [
                "S Kim",
                "I Kang",
                "N. Kwak"
            ],
            "title": "Semantic sentence matching with densely-connected recurrent and co-attentive information[C]//Proceedings of the AAAI conference on artificial intelligence",
            "year": 2019
        },
        {
            "authors": [
                "C Li",
                "B Yang",
                "M. Li"
            ],
            "title": "Forecasting analysis of Shanghai stock Index based on ARIMA model[C]//MATEC Web of Conferences",
            "venue": "EDP Sciences,",
            "year": 2017
        },
        {
            "authors": [
                "J Hyndman R",
                "G. Athanasopoulos"
            ],
            "title": "Forecasting: principles and practice[M",
            "venue": "OTexts,",
            "year": 2018
        },
        {
            "authors": [
                "S Siami-Namini",
                "S. Namin A"
            ],
            "title": "Forecasting economics and financial time series: ARIMA vs. LSTM[J",
            "venue": "arXiv preprint arXiv:1803.06386,",
            "year": 2018
        },
        {
            "authors": [
                "S Siami-Namini",
                "N Tavakoli",
                "S. Namin A"
            ],
            "title": "The performance of LSTM and BiLSTM in forecasting time series[C]//2019",
            "venue": "IEEE International Conference on Big Data (Big Data)",
            "year": 2019
        },
        {
            "authors": [
                "X Wu",
                "B Shi",
                "Y Dong"
            ],
            "title": "Restful: Resolution-aware forecasting of behavioral time series data[C]//Proceedings of the 27th",
            "venue": "ACM International Conference on Information and Knowledge Management",
            "year": 2018
        },
        {
            "authors": [
                "T Chen",
                "H Yin",
                "H Chen"
            ],
            "title": "Tada: trend alignment with dual-attention multi-task recurrent neural networks for sales prediction[C]//2018 IEEE international conference on data mining (ICDM)",
            "year": 2018
        },
        {
            "authors": [
                "H Zhou",
                "S Zhang",
                "J Peng"
            ],
            "title": "Informer: Beyond efficient transformer for long sequence time-series forecasting[C]//Proceedings of AAAI",
            "year": 2021
        },
        {
            "authors": [
                "Zhang Yunzhong",
                "Zhu Rui"
            ],
            "title": "Knowledge Graph Construction in Graphical Academic Domain for Knowledge Question Answering System: A Multi-source Data Integration Perspective [J",
            "venue": "Information Science,",
            "year": 2021
        },
        {
            "authors": [
                "L. Dong X"
            ],
            "title": "Challenges and innovations in building a product knowledge graph[C]//Proceedings of the 24th",
            "venue": "ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
            "year": 2018
        },
        {
            "authors": [
                "K Yuan",
                "Y Deng"
            ],
            "title": "Construction Technology and Research Progress of Medical Knowledge Graph [J",
            "venue": "Computer Application Research,",
            "year": 2018
        },
        {
            "authors": [
                "S Ji",
                "S Pan",
                "E Cambria"
            ],
            "title": "A survey on knowledge graphs: Representation, acquisition, and applications[J",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems,",
            "year": 2021
        },
        {
            "authors": [
                "A Bosselut",
                "R Le Bras",
                "Y. Choi"
            ],
            "title": "Dynamic neuro-symbolic knowledge graph construction for zero-shot commonsense question answering[C]//Proceedings of the 35th",
            "venue": "AAAI Conference on Artificial Intelligence (AAAI)",
            "year": 2021
        },
        {
            "authors": [
                "Q Ai",
                "V Azizi",
                "X Chen"
            ],
            "title": "Learning heterogeneous knowledge base embeddings for explainable recommendation[J",
            "year": 2018
        },
        {
            "authors": [
                "A Sinha",
                "Z Shen",
                "Y Song"
            ],
            "title": "An overview of microsoft academic service (MAS) and applications",
            "venue": "Proceedings of the 24th International Conference on World Wide Web (WWW\u201915 Companion)",
            "year": 2015
        },
        {
            "authors": [
                "Z Xue",
                "J Du",
                "D Du"
            ],
            "title": "Deep low-rank subspace ensemble for multi-view clustering[J",
            "venue": "Information Sciences,",
            "year": 2019
        },
        {
            "authors": [
                "B Sun",
                "J Du",
                "T. Gao"
            ],
            "title": "Study on the improvement of K-nearestneighbor algorithm[C]//2009",
            "venue": "International Conference on Artificial Intelligence and Computational Intelligence,",
            "year": 2009
        },
        {
            "authors": [
                "P. Cui"
            ],
            "title": "The application of ECharts in data visualization",
            "venue": "[J]. Software",
            "year": 1964
        },
        {
            "authors": [
                "Y Yang",
                "J Du",
                "Y. Ping"
            ],
            "title": "Ontology-based intelligent information retrieval system[J",
            "venue": "Journal of Software,",
            "year": 2015
        },
        {
            "authors": [
                "N Shah",
                "D Willick",
                "V. Mago"
            ],
            "title": "A framework for social media data analytics using Elasticsearch and Kibana[J",
            "venue": "Wireless networks,",
            "year": 2018
        }
    ],
    "sections": [
        {
            "heading": "Introduction",
            "text": "In recent years, the research of big data\nhas become more and more popular. Through data mining of massive data, potentially valuable information can be obtained. Science and technology big data[1] is a branch of big data in the field of scientific research. composition. Scientific and technological resources include scholars, journals, conferences, academic papers[2], research patents[3], scientific and technological information[4], scientific and technological reports, scientific research projects, research institutions, etc.[5].\nScientific and technological academic\nconference data is a subset of scientific and technological big data. Scientific and technological academic conferences are conferences with the theme of promoting academic exchanges and promoting technological development. Generally speaking, they are authoritative and highly knowledgeable. Field researchers, scholars, teachers, students, etc. Due to the exchange and interaction of the conference, the participants will present their academic achievements and share the research content. The conference organizers organize these contents into a collection of papers. The paper collection contains the main research content and\nachievements of the conference. Therefore, the data in the conference proceedings is analyzed and mined, and the potential information contained in the conference is visually displayed in the form of maps and portraits, which can allow researchers to obtain relevant information more quickly. Valuable scientific research information[6].\nWith the advancement of artificial\nintelligence technology, knowledge graph[7] has attracted extensive attention from academia and industry for its powerful knowledge representation and reasoning capabilities. The knowledge graph can display knowledge from the perspective of the relationship between entities and entities. Compared with the traditional representation of relational data and text images, the knowledge graph has stronger semantic expression ability[8].\nWith the attention of big data, the\ndiscussion on portraits has become more and more popular. The definition of portraits is relatively broad, and it can be understood as a means of abstracting the whole picture of information, including user portraits, product portraits, resource portraits, etc. Therefore, For scientific and technological academic conference data, portraits can also be extracted. The extraction process of portraits is to extract and integrate effective information, classify conference research fields, use neural network technology[9] to predict the development trend of each classification, and then visualize it to make it more comprehensive. Accurately\ndisplay deep-level information [10]."
        },
        {
            "heading": "Named Entity Recognition for",
            "text": ""
        },
        {
            "heading": "Scientific and Technological Academic",
            "text": ""
        },
        {
            "heading": "Conferences",
            "text": "Named Entity Recognition (NER) is a\nresearch direction in the field of natural language processing and knowledge extraction classification, which can be defined as a classification problem, that is, classifying given text data, and the classification target is a predefined entity[11]. The named entity recognition of scientific and technological academic conference data belongs to the named entity recognition of the special field, which is different from the recognition of the general field. The core is that the data composition specification of the data set in the general field is relatively strict, and the classification of the division is relatively fixed, so many research results have been achieved so far. However, the technology in the scientific research field is updated and iteratively fast, and a large number of professional terms, that is, new entities, will be generated at any time. At the same time, the relationship between entities and entities is also more complex, and there may be nested entities. These factors increase the complexity of entity recognition. Difficulty[12].\nThe current mainstream research\nmethods of Chinese named entities include machine learning methods based on statistics and methods based on deep learning. The\nmachine learning method generally labels the text data, and then performs training. After training the corresponding model, it is recognized on the test set. The commonly used models here are Hidden Markov Model[13], Support Vector Machine[14], Maximum Entropy Model[15] and so on.\nResearch methods based on deep learning\nhave developed more rapidly in recent years. The core of deep learning[16] is to use neural networks to complete the learning of corpus. For the task of named entity recognition, different types of neural networks[17] can be used to complete this task. First, a convolutional neural network (CNN) can be used. Kong[18] proposed a model based on a convolutional neural network. In the model, a cascaded CNN was constructed to obtain contextual information and make full use of the GPU. Parallel computing capability, Strubell[19] proposed the concept of iterative convolutional neural network IDCNN. Compared with the LSTM model mentioned below, this model only needs linear time complexity, and can achieve nearly ten times under the condition of ensuring high accuracy. times the speed increase .\nRecurrent Neural Network (Recurrent\nneural network, RNN) is also widely used in named entity recognition tasks. Recurrent Neural Network (Recurrent neural network, RNN) [20]is a kind of neural network. The basic neural network model[21] is to process a single input, that is, it is considered that the input has\nno contextual relationship. But in the case where the input is text, it can be abstracted into a stream of interdependent data . Therefore, the specially designed recurrent neural network is very suitable for application to the field of natural language processing. The structure of RNN is composed of input layer X, hidden layer S and output layer O. The overall structure is the same as that of ordinary fully connected neural network, but one The output of the hidden layer at the moment will affect the current moment, which makes the RNN have memory. A large number of experiments show that the RNN has a good performance in the fields of entity recognition, relation extraction, and machine translation.\nLong Short-Term Memory (LSTM) [22]is\na special RNN. According to the previous introduction, it can be seen that the result of the RNN at the previous moment will affect the result of the next moment, but its weight is fixed, so the short-term The memory impact of RNN is larger, and the long-term impact will be smaller and smaller, which is the short-term memory problem of RNN. Huang et al[23]. used bidirectional long short-term memory network (BiLSTM) to label sequences for entity recognition, and achieved good results. Dong et al[24].used bidirectional LSTM-CRF neural network, using both character-level and radical-level Representing features, which solves the problem that current algorithms require artificial features and domain-specific knowledge to achieve high performance.\nZhang et al.[25]proposed the Lattice LSTM model\nMore techniques for named entity\nrecognition based on deep learning . The first is the Transformer model. Yan et al. [26]made improvements for the defects of Transformer capturing direction information , and proposed the TENER (Transformer Encoder for NER) model . Reference [27]used BERT pre-training and then fine-tuned. Combined with BiLSTM, it improved the performance. Accuracy of entity recognition on the Weibo dataset.\nAttention mechanism (Attention)[28]\ndraws on the human way of thinking. When humans observe things, they will quickly scan the whole picture, and then locate the part that needs to be focused on, and then focus their attention on this. To obtain the required detailed information, reduce the acquisition of useless information, and improve the accuracy of human visual acquisition of information. The core of the attention mechanism is to filter the input information and select the information that is more critical to the current task.\nIn 2018, the BERT model was proposed.\nIt is implemented by a two-layer Transformer model. The Transformer is only composed of a self-attention mechanism and a feedforward neural network[29]. This structure is mainly taken into account when RNN, LSTM and other models are calculated in a fixed order. Computational, that is, from left to right or from right to left, the parallel computing power\nis poor. In addition, even if LSTM is used, if the dependency information is particularly long-distance, it will still be lost. The Transformer only uses the self-attention mechanism, so even if a single input For very long sequences, the distance at any location can still be treated as a constant due to the nature of the attention mechanism[30].\nBERT is applied to various research\nfields of NLP [31]. Dai et al. [32]used the network structure of BERT + BiLISM + CRF in the application of Chinese electronic medical record recognition, which improved the accuracy of recognition. Li et al. [33]used [34]proposed FLAT for the high complexity of existing Lattice, which improved the efficiency while ensuring performance. Yoon et al. [35]proposed a model composed of multiple bidirectional LSTM networks, each network recognizes a specified entity type, and multiple tasks combine their respective learned knowledge to obtain more accurate predictions."
        },
        {
            "heading": "Similarity Calculation of Semantic",
            "text": ""
        },
        {
            "heading": "Text in Scientific and Technological",
            "text": ""
        },
        {
            "heading": "Academic Conference",
            "text": "The most obvious relationship between\nscientific and technological academic conferences is similarity[36], so the similarity between conferences is calculated by means of semantic text similarity. Semantic text similarity calculation is widely used in various branches of natural language processing\nresearch such as text classification [37], knowledge question answering [38], and machine translation [39].\nThe calculation methods of semantic text\nsimilarity are mainly based on strings, based on machine learning and based on deep learning. Among them, the string-based method is relatively simple. It directly compares the original text of two strings. Common calculation methods include edit distance [40], Jaccard similarity, etc. [41]. This kind of method is simple to implement, but can only process characters. Granular similarity cannot handle word-level problems, so it is currently used to supplement other computing methods.\nThe methods based on statistical machine\nlearning mainly include two categories: vector space model and topic model. In the vector space model, words are used as the basic unit to represent vectors. Currently, the most commonly used algorithm is TF - IDF. vectors, and then calculate the similarity between the vectors. Vector similarity calculation methods include cosine similarity, Euclidean distance, Manhattan distance, etc. If the text is regarded as a multidimensional variable, statistical correlation coefficients, such as Pearson correlation coefficient and Spearman correlation coefficient, can also be used for calculation, and these similarity calculation methods will also be involved in the calculation below. The calculation method based on the topic model is a classic method in the field of statistical machine learning. Blei et al.\n[42]proposed the latent Dirichlet distribution (LDA) model, which uses the probability model to calculate the probability distribution of the topics in the document, and finally completes each task according to its distribution. a natural language processing task.\nThe methods based on deep learning\nmainly have two architectures: twin network and interaction model in the calculation of semantic text similarity. word2vec proposed by Mikolov et al. [43] is the earliest method to generate distributed word vectors. Pennington et al. [44] proposed the Glove model, which considers the global information to a certain extent through the idea of using the probability of the co-occurrence matrix . After the word vector is obtained, the neural network model can be used for training. On the Siamese network architecture, Huang et al. [45] proposed the DSSM architecture. The algorithm model is divided into input layer, presentation layer, and matching layer. Later, it was widely applied to various semantic text similarity calculation problems; Palangi et al. [46] The LSTM network is used as the neural network of the twin architecture, which considers more contextual information , which improves the effect of the algorithm[47] proposed a similarity measure for learning variable-length character sequences , combining a bidirectional LSTM with the Siamese architecture to improve the recognition accuracy[48] proposed a method that combines convolutional and recurrent neural networks to measure the semantic similarity of\nsentences. Use CNN to consider local context and LSTM to consider global context. This combination of networks helps to preserve the relevant information of sentences and improves the calculation effect of the similarity between sentences. Reimers et al. [49] analyzed the defects of the traditional BERT network in the calculation of semantic text similarity. It needs to pass the two sentences to be compared into the model for calculation, and the calculation cost is too large, so they proposed SiameseBERT The network structure, the SBERT model is completed in only 5s, which brings a huge efficiency improvement. Li et al. [50]analyzed the results of BERT training vectors and found that the word vectors pretrained by BERT have problems of anisotropy and low-frequency vocabulary sparse, and introduced the concept of BERT - flow. In STS 12-16 and Better performance on SICK - R dataset.\nThe method based on the interaction\nmodel is an improvement on the twin network method. Because the network structure is more complex, the computational cost is relatively high. Gong et al. [51] proposed the DIIN model to vectorize the input text, and then introduce an attention mechanism to perform Finally, the corresponding matrix is obtained through the interaction layer, the features are extracted by DenseNet [52], and the final similarity comparison result is obtained through the multi-layer perceptron (MLP). Kim et al. [53]proposed the DRCN model, which also used\nthe attention mechanism and combined it with DenseNet to achieve better similarity analysis performance."
        },
        {
            "heading": "Prediction of trends in the field of",
            "text": "scientific and technological academic\nconferences\nTrend forecasting in the field of scientific\nand technological academic conferences can be abstracted into a time series forecasting problem. Time series forecasting is to predict the development trend of future data based on the laws between historical time series data. Common applications include stock forecasting, meteorological changes and so on. Time series forecasting methods are mainly divided into two categories: linear and nonlinear.\nThe structure of linear prediction method\nis relatively simple, and it is generally based on mathematical algorithms, such as autoregressive integral moving average prediction method [54], exponential smoothing method[55], etc.; such methods have low computational complexity and can achieve good results for short-term data. effect, but it will have great limitations in the face of longdistance prediction. Non-linear methods are mainly based on machine learning and deep learning. The methods based on machine learning include XGBoost , SVM, etc. The methods based on deep learning are mainly based on the variant LSTM of recurrent neural\nnetwork. Siami et al.[56] compared the performance of ARIMA prediction method and LSTM network in financial prediction, and the experiments showed that LSTM can achieve better results; Siami et al. [57]compared the performance of LSTM and BiLSTM in time series prediction in subsequent research. On the performance, experiments show. BiLSTM models provide better predictions. But it takes longer to converge. [58]proposed a multiresolution time series forecasting model RESTFul , developed a recurrent framework to encode temporal patterns at each resolution, and a convolutional fusion framework to model a combination of sequential patterns with different temporal resolutions The interdependence between them has obtained a good prediction effect. [59] divided the influencing factors into internal features and external features, which were jointly modeled by a multi - task RNN encoder. In the decoding stage, TADA utilizes two attention mechanisms to compensate for the unknown state of future influencers and adaptively aligns upcoming trends with relevant historical trends to ensure accurate sales forecasts . In addition, there are more innovative methods. Zhou et al. [60] designed an improved model based on Transformer, named Informer, which solved the problem of high time and space complexity of Transformer and achieved good prediction results."
        },
        {
            "heading": "Science and technology academic",
            "text": "conference knowledge graph and\naccurate portrait construction\nThe construction of knowledge graph\nforms a network structure through the association of different knowledge. Currently, it is widely used in search and knowledge question answering. Knowledge graph data storage needs the support of graph database [61] .\nNeo4J is currently the most\nrepresentative graph database implementation. It is implemented based on Java and Scala languages and provides enterprise and community editions. It is a high-performance non-relational graph database. Neo4J establishes relationships when creating nodes. At the same time, the bottom layer directly stores nodes and relationships in the data structure of graph, so it can be queried with constant time complexity when querying, which perfectly solves the problem of query speed. At the same time, as a graph database, it is also very good. It supports the ACID features of relational databases and provides a transaction mechanism. In terms of usage, Neo4J provides a friendly web interface and visual functions. In addition, it provides a query language Cypher, which is a declarative graph query language. Users can perform various operations on graph data without traversing the graph structure. Due to the above advantages, Neo4J is very suitable for representing a large number of networks of\nscientific and technological data.\nThe knowledge graph of scientific and\ntechnological academic conferences belongs to the domain knowledge graph, and its construction method is different from the general domain knowledge graph[62]. Generally, there are bottom-up and top-down modes, or a combination of the two [63] . For structured data, text matching, regular expressions, etc. can be used for manual sorting; for unstructured data, deep learning methods are used to extract corresponding entities and relationships [64]\nThere have been outstanding\nachievements in the construction of knowledge graphs. Reference[65] introduces the representation learning of knowledge graphs and various technologies in detail . Bosselut et al.[66] proposed a new method for generating context-related knowledge on demand using a generative neural commonsense model for zero-shot commonsense question answering tasks with improved performance . Ai et al.[67] studied how to use knowledge bases to optimize the performance of recommender systems.\nAt present, the typical knowledge graphs\nin the field of science and technology are: OAG (open academic graph) [68] ,It is a fusion of the academic knowledge graph developed by Microsoft and the Aminer platform developed by Tsinghua University, which provides researchers with functions such as academic paper search, scientific conference analysis, topic trend analysis, etc. At present, the number\nof academic documents reaches 100 million level; Acemap: an academic retrieval query system in the field of science and technology independently developed by Shanghai Jiaotong University, currently covering 100 million level papers and researchers, 10000 level journal conferences, etc., and supports dynamic network display, paper clustering[69] and other functions;\nThe task of constructing portraits of\nscientific and technological academic conferences is to show the full picture of the detailed conference information as much as possible. For the constructed knowledge graph and portrait data, use visualization components to display them. Currently, FusionCharts and ECharts [71] are commonly used , among which ECharts is a data visualization library developed based on the javaScript language. It was open sourced by the Baidu team and donated to the Apache Foundation. It provides intuitive, interactive, and personalization such as line charts, scatter charts, maps, heat maps, and relationship charts. Customized charts can provide graphics and data information for users to analyze. For the interaction of the portrait system, it can be implemented in the form of a search engine. ElasticSearch is an open source search engine developed based on Lucene, referred to as ES. Lucene is an open source fulltext retrieval toolkit. The implementation of full-text retrieval[72] is to extract all the words in the retrieved documents, build an index for them, and quickly search for the target by\nquerying the index during retrieval. An inverted index can be established through Lucene. The index established by a traditional database such as MySQL is called a forward index. In the search engine scenario, each file corresponds to an ID. The forward index is to query the document through the document ID, and then Traversing the word segmentation results of documents, getting documents containing keywords, and then scoring them back, the time complexity is very high. Lucene can reconstruct the forward index into an inverted index, that is, construct a worddocument mapping, and construct a worddocument Matrix, so that qualified documents can be quickly queried, and then scored and sorted [73].\nThe ecology of ElasticSearch is very\ncomplete. It is equipped with a visualization tool Kibana and a data collection and conversion tool Logstash. It can not only be applied to search engines, but also builds a log analysis system for another typical application. Logstash collects business system logs, stores them in ElasticSearch, and then It is displayed to operation and maintenance personnel for analysis through Kibana [74]."
        },
        {
            "heading": "Conclusion",
            "text": "From the massive scientific and\ntechnological academic conferences, the construction of knowledge maps and accurate portraits is the mining and abstraction of the deep semantic information of scientific and\ntechnological academic conferences, so that researchers can more efficiently obtain effective information from the complex scientific and technological academic conferences and paper data; The system is built on the results of related research, which can display the content to users more intuitively. This paper introduces the theoretical basis and implementation plan including named entity recognition, semantic similarity calculation, trend prediction, graph database, search engine, etc. The form of portrait, more intuitive display"
        },
        {
            "heading": "Acknowledgment",
            "text": "This work is supported by National Key R&D Program of China (2018YFB1402600), the National Natural Science Foundation of China (61772083, 61877006, 61802028, 62002027)."
        }
    ],
    "title": "Knowledge Graph and Accurate Portrait Construction of Scientific and Technological Academic Conferences",
    "year": 2022
}