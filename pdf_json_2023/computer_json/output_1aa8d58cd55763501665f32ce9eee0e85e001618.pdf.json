{
    "abstractText": "Recently, through the progress achieved in the study of computer science, automated test assemblies of parallel test forms, for which each form has equivalent measurement accuracy but with a different set of items, have emerged as a new standard tool. An important goal for automated test assembly is to assemble as many parallel test forms as possible. Although many automated test assembly methods exist, maximum clique using the integer programming method is known to be able to assemble the greatest number of assembled test forms with the highest measurement accuracy. Nevertheless, because of the high time complexity of integer programming, the method requires a month or more to assemble 300,000 tests. This study proposes a new automated test assembly using Zero-suppressed Binary Decision Diagrams (ZDD): a graphical representation for a set of item combinations. This representation is derived by reducing a binary decision tree. According to the proposed method, each node in the binary decision tree corresponds to an item of an item pool, which is a test item database. Each node has two edges, each signifying that the corresponding item is included in a test form or not. Furthermore, all equivalent nodes are shared, providing that they have equal measurement accuracy and equal test length. Numerical experiments demonstrate that the proposed method can assemble 1,500,000 test forms within 24 hr, although earlier methods have been capable of assembling only 300,000 test forms during a week or more. INDEX TERMS automated test assembly, item response theory, parallel test, zero-suppressed binary decision diagrams",
    "authors": [
        {
            "affiliations": [],
            "name": "KAZUMA FUCHIMOTO"
        },
        {
            "affiliations": [],
            "name": "SHIN-ICHI MINATO"
        },
        {
            "affiliations": [],
            "name": "MAOMI UENO"
        }
    ],
    "id": "SP:43b0eaeb8bebc3e877051974ba364de03c8d60f7",
    "references": [
        {
            "authors": [
                "Koun-Tem Sun",
                "Yu-Jen Chen",
                "Shu-Yen Tsai",
                "Chien- Fen Cheng"
            ],
            "title": "Creating irt-based parallel test forms using the genetic algorithm method",
            "venue": "Applied Measurement in Education,",
            "year": 2008
        },
        {
            "authors": [
                "Pokpong Songmuang",
                "Maomi Ueno"
            ],
            "title": "Bees algorithm for construction of multiple test forms in e-testing",
            "venue": "IEEE Transactions on Learning Technologies,",
            "year": 2011
        },
        {
            "authors": [
                "Takatoshi Ishii",
                "Pokpong Songmuang",
                "Maomi Ueno"
            ],
            "title": "Maximum clique algorithm and its approximation for uniform test form assembly",
            "venue": "IEEE Transactions on Learning Technologies,",
            "year": 2014
        },
        {
            "authors": [
                "Takatoshi Ishii",
                "Maomi Ueno"
            ],
            "title": "Clique algorithm to minimize item exposure for uniform test forms assembly",
            "venue": "In International Conference on Artificial Intelligence in Education,",
            "year": 2015
        },
        {
            "authors": [
                "Kazuma Fuchimoto",
                "Takatoshi Ishii",
                "Maomi Ueno"
            ],
            "title": "Hybrid maximum clique algorithm using parallel integer programming for uniform test assembly",
            "venue": "IEEE Transactions on Learning Technologies,",
            "year": 2022
        },
        {
            "authors": [
                "Wim J van der Linden",
                "Maomi Ueno"
            ],
            "title": "shadow-test approach to adaptive testing",
            "venue": "Behaviormetrika,",
            "year": 2022
        },
        {
            "authors": [
                "Wim J. Van der Linden"
            ],
            "title": "Linear Models for Optimal Test Design",
            "year": 2005
        },
        {
            "authors": [
                "Wim J. van der Linden",
                "Jos J. Adema"
            ],
            "title": "Simultaneous assembly of multiple test forms",
            "venue": "Journal of Educational Measurement,",
            "year": 1998
        },
        {
            "authors": [
                "Ellen Boekkooi-Timminga"
            ],
            "title": "The construction of parallel tests from irt-based item banks",
            "venue": "J. Educat. Statist. 15,",
            "year": 1990
        },
        {
            "authors": [
                "Ronald D. Armstrong",
                "Douglas H. Jones",
                "Zhaobo Wang"
            ],
            "title": "Automated parallel test construction using classical test theory",
            "venue": "Journal of Educational Statistics,",
            "year": 1994
        },
        {
            "authors": [
                "Ronald D. Armstrong",
                "Douglas H. Jones",
                "Charles S. Kunce"
            ],
            "title": "Irt test assembly using network-flow programming",
            "venue": "Applied Psychological Measurement,",
            "year": 1998
        },
        {
            "authors": [
                "Ting-Yi Chang",
                "You-Fu Shiu"
            ],
            "title": "Simultaneously construct irt-based parallel tests based on an adapted clonalg algorithm",
            "venue": "Applied Intelligence,",
            "year": 2012
        },
        {
            "authors": [
                "Jordi Pereira",
                "Mariona Vila"
            ],
            "title": "Variable neighborhood search heuristics for a test assembly design problem",
            "venue": "Expert Systems with Applications,",
            "year": 2015
        },
        {
            "authors": [
                "Dmitry I. Belov",
                "Ronald D. Armstrong"
            ],
            "title": "A constraint programming approach to extract the maximum number of non-overlapping test forms",
            "venue": "Computational Optimization and Applications,",
            "year": 2006
        },
        {
            "authors": [
                "Takatoshi Ishii",
                "Pokpong Songmuang",
                "Maomi Ueno"
            ],
            "title": "Maximum clique algorithm for uniform test forms",
            "venue": "The 16th International Conference on Artificial Intelligence in Education,",
            "year": 2013
        },
        {
            "authors": [
                "Shin-ichi Minato"
            ],
            "title": "Zero-suppressed bdds for set manipulation in combinatorial problems",
            "venue": "In Proceedings of the 30th International Design Automation Conference,",
            "year": 1993
        },
        {
            "authors": [
                "Takeru Inoue",
                "Keiji Takano",
                "Takayuki Watanabe",
                "Jun Kawahara",
                "Ryo Yoshinaka",
                "Akihiro Kishimoto",
                "Koji Tsuda",
                "Shinichi Minato",
                "Yasuhiro Hayashi"
            ],
            "title": "Distribution loss minimization with guaranteed error bound",
            "venue": "IEEE Transactions on Smart Grid,",
            "year": 2014
        },
        {
            "authors": [
                "Atsushi Takizawa",
                "Yasufumi Takechi",
                "Akio Ohta",
                "Naoki Katoh",
                "Takeru Inoue",
                "Takashi Horiyama",
                "Jun Kawahara",
                "S- I Minato"
            ],
            "title": "Enumeration of region partitioning for evacuation planning based on zdd",
            "year": 2013
        },
        {
            "authors": [
                "Atsushi Takizawa",
                "Yushi Miyata",
                "Naoki Katoh"
            ],
            "title": "Enumeration of floor plans based on a zero-suppressed binary decision diagram",
            "venue": "International Journal of Architectural Computing,",
            "year": 2015
        },
        {
            "authors": [
                "Shinsaku Sakaue",
                "Kengo Nakamura"
            ],
            "title": "Differentiable equilibrium computation with decision diagrams for stackelberg models of combinatorial congestion games",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Hiroaki Iwashita",
                "Shin-ichi Minato"
            ],
            "title": "Efficient top-down ZDD construction techniques using recursive specifications",
            "year": 2013
        },
        {
            "authors": [
                "Wim J. Van der Linden",
                "Ellen Boekkooi-Timminga"
            ],
            "title": "A maximin model for irt-based test design with practical constraints",
            "year": 1989
        },
        {
            "authors": [
                "F.M. Lord",
                "M.R. Novick"
            ],
            "title": "Statistical theories of mental test",
            "venue": "scores. Addison-Wesley Pub. Co.,",
            "year": 1968
        },
        {
            "authors": [
                "F.B. Baker",
                "S.H. Kim"
            ],
            "title": "Item Response Theory: Parameter Estimation Techniques, Second Edition. Statistics: A Series of Textbooks and Monographs",
            "year": 2004
        },
        {
            "authors": [
                "Takatoshi Ishii",
                "Maomi Ueno"
            ],
            "title": "Algorithm for uniform test assembly using a maximum clique problem and integer programming. In Artificial Intelligence in Education, pages 102\u2013112",
            "year": 2017
        },
        {
            "authors": [
                "Donald Ervin Knuth"
            ],
            "title": "The art of computer programming: Bitwise tricks & techniques",
            "venue": "Binary Decision Diagrams,",
            "year": 2009
        },
        {
            "authors": [
                "Howard Wainer"
            ],
            "title": "Rescuing computerized testing by breaking zipf\u2019s law",
            "venue": "Journal of Educational and Behavioral Statistics,",
            "year": 2000
        }
    ],
    "sections": [
        {
            "text": "INDEX TERMS automated test assembly, item response theory, parallel test, zero-suppressed binary decision diagrams\nI. INTRODUCTION\nWith the rapid development of computer science technologies, automated test assemblies [1]\u2013[5] of parallel test forms, for which each form has equivalent measurement accuracy but with a different set of items, have been put to practical use. For instance, parallel test forms are necessary when a testing organization administers tests at different times. To accomplish this mode of testing, parallel test forms are assembled in which all forms have equivalent qualities so that examinees who have used different test forms can be evaluated objectively using the same scale. Consequently, parallel test forms ensure that their scores are equivalent even if different examinees with the same ability take distinct\ntests. Automated test assemblies have resolved difficulties such as high computational costs [1], [2], maximization of the number of tests [3], [5], minimization of item exposure bias [4], and so on. Most recently, automated test assembly has been applied for computerized adaptive testing (such as [6], [7]), which selects and presents the optimal item for individual examiners.\nEarlier studies have formulated a test assembly as a combinational optimization problem. The test assembly seeks a combination of items that satisfies given test constraints, such as the test lengths and ability measurement accuracy from an item pool.\nThe most widely recognized automated test assembly\nVOLUME 10, 2022 1\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nis the Big Shadow Test method (BST), which uses Mixed-Integer Programming (MIP) [8]. This method assembles parallel test forms sequentially by minimizing the difference of measurement accuracies between a current assembled test and a set of items that remain in the item pool. Although the Big Shadow Test method can impose test constraints on parallel test forms effortlessly using MIP, the method does entail two crucially important shortcomings. First, the ability measurement accuracy of the examinee decreases as the assembled number of test forms increases. Second, this method does not guarantee maximization of the number of assembled test forms. Test organizations allocate different test forms to each examinee to secure the items from item leaks and exam cheating by the test-takers. Therefore, the second difficulty is a severe difficulty for automated test assembly. Ideally, the number of assembled test forms should exceed the number of examinees.\nTo equilibrate the ability measurement accuracies of assembled test forms, van der Linden and Ameda [9], Boekooi-Timminga [10], Armstrong et al., [11], Armstrong et al., [12], Sun et al. [1], Songmuang and Ueno [2], Chang and Shiu [13], and Pereira and Vila [14] assessed the formulated automated test assembly as a large-scale IP that directly minimizes differences of the ability measurement accuracies among tests. Unfortunately, automated test assembly entails extremely high computational costs.\nAs a method of relaxing computational costs, Sun et al. [1] proposed a method of automated test assembly using a genetic algorithm (GA), which is a heuristic algorithm. This method simultaneously assembles parallel test forms to minimize differences among the qualities of assembled test forms and to test administratordetermined values. To improve the GA method [1] performance Songmuang and Ueno [2] applied the Bees algorithm (BA) to automated test assembly [1].\nAlthough these methods demonstrated effective performance for minimizing qualitative differences among the assembled test forms, they are not guaranteed to maximize the number of assembled test forms.\nTo maximize the number of assembled test forms, Belov and Armstrong [15] proposed an automated test assembly method based on Maximum Set-Packing Problems. This method divides the item pool into the maximum number of item sets (as tests) which match given test constraints. Nevertheless, this method [15] is incapable of assembling parallel test forms with overlapping items, where overlapping items are common items among parallel test forms. Therefore, this method strongly restricts the number of assembled test forms because each item is used on only one test form with the non-overlapping condition.\nTo resolve this shortcoming, Ishii et al. [3], [16] formalized an automated test assembly with overlapping conditions as a maximum clique problem (MCP), which\nis a combinational optimization in graph theory. The automated test assembly constructs a graph in which the vertices and the edges respectively represent tests satisfying the test constraint and represent satisfaction of the overlapping constraint. Then, this method extracts the maximum clique from the graph as parallel test forms. The automated test assembly can guarantee the maximum number of assembled test forms exactly. The maximum clique method assembled 10\u20131,000 times the number of assembled test forms that the traditional methods did. However, this method limits the number of assembled test forms to a hundred thousand because the maximum clique problem has high space complexity.\nTo reduce the high space complexity of the maximum clique method, Fuchimoto et al. [5] proposed the Hybrid Maximum Clique Algorithm with Parallel Integer Programming (HMCAPIP), which is known to assemble the greatest number of assembled test forms with the highest measurement accuracy. As the first step, test forms are assembled with the overlapping constraint as a maximum clique problem with low time complexity, but with high space complexity. The second step, using integer programming (IP) with low space complexity but with high time complexity, repeats the parallel search of the tests satisfied with the overlapping constraint for all currently assembled tests. However, HMCAPIP retains the heavy time complexity of IP. For example, it requires one week or more to assemble 300,000 test forms. Moreover, the parallel search effectiveness depends on the computer specifications.\nTo improve the number of assembled test forms, this study proposes a new automated test assembly using Zero-suppressed Binary Decision Diagrams (ZDD). A ZDD is an efficient graphical representation of a set of item combinations [17]. Actually, ZDD is derived by reducing a binary decision tree using reduction rules [17]. These reduction rules are able to decrease the calculation time and computer memory limitation efficiently. Because of this benefit of ZDD, many studies have solved real-world problems such as grid power loss minimization [18], region partitioning for disaster evacuation [19], architectural floor planning [20], and Stackelberg models of combinatorial congestion games [21].\nUsing the proposed method, each node in the binary decision tree corresponds to an item of an item pool. Each node has two edges, respectively representing whether the corresponding item is included in a test form or not. The binary decision tree can enumerate all parallel test forms with the satisfied test constraints. Nevertheless, the binary decision tree has high space complexity O(2n/n), where n represents the number of items. To relax this high space complexity, the proposed method compresses the binary decision tree using ZDD in a breadth-first manner [22]: an efficient construction technique for reducing computer memory"
        },
        {
            "heading": "2 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nand calculation time. Specifically, all equivalent nodes are shared, provided that they have equivalent measurement accuracies and equivalent test lengths. Unfortunately, measurement accuracies of two nodes are rarely equivalent. Therefore, the proposed method shares those nodes when the difference in measurement accuracies between the two nodes is less than the threshold value. Then, the measurement accuracy of the shared node is approximated by the average measurement accuracies of the two nodes. Consequently, the proposed method can assemble parallel test forms without redundantly repeating calculations for measurement accuracies and test lengths.\nHowever, this ZDD has a larger measurement error than HMCAPIP has because the shared node is approximated by the average measurement accuracy. Furthermore, this ZDD is incapable of controlling overlapping items. To resolve these shortcomings, the proposed method repeats random sampling [17] from ZDD with low time complexity O(n) to enumerate parallel test forms with measurement errors that are less than a determined value and with a number of overlapping items that is less than a determined value.\nNumerical experiments demonstrate that the proposed method can assemble 1,500,000 test forms within 24 hr, although the earlier method can assemble only 300,000 test forms during a week or more.\nII. IRT Most earlier studies of automated test assembly have evaluated the measurement accuracies of parallel test forms (such as [1], [2], [8], [10]\u2013[12], [23]) using Item Response Theory (IRT) [24], [25]. It is noteworthy that IRT can measure the ability of examinees on the same scale, even when the examinees have taken different tests. In the two-parameter IRT logistic model, which is employed in most earlier studies, the probability that an examinee j (= 1, 2, . . . ,m) with ability \u03b8j \u2208 (\u2212\u221e,\u221e) answer item i(= 1, 2, . . . ,n) correctly is defined as\npi(\u03b8j ) = 1\n1 + exp(\u22121.7ai(\u03b8j \u2212 bi)) , (1)\nwhere ai \u2208 [0,\u221e) and bi \u2208 (\u2212\u221e,\u221e) respectively represent the respective discrimination power and difficulty of item i . The asymptotic variance of estimated ability based on IRT approaches the inverse of Fisher Information [24]. Therefore, IRT typically employs Fisher Information as an index of the measurement accuracy for the examinee\u2019s ability to estimate. In the two-parameter logistic model, the Fisher Information is defined when item i provides an examinee\u2019s ability \u03b8 using the following item information function.\nIIFi(\u03b8) = 1.72ai2pi(\u03b8)(1\u2212 pi(\u03b8)). (2)\nThis item information function implies that items with high Fisher Information IIFi(\u03b8) are highly discrimina-\ntory in the examinee\u2019s ability. The test information function TIFTest(\u03b8) of a test form Test is defined as\nTIFTest(\u03b8) = \u2211\ni\u2208Test IIFi(\u03b8). (3)\nThe asymptotic standard error of estimating \u03b8\u0302, which is SE(\u03b8\u0302), is the reciprocal of square root of the item and test information function at a given ability level \u03b8\u0302.\nSEi(\u03b8\u0302) = 1\u221a\nIIFi(\u03b8\u0302) , (4)\nSETest(\u03b8\u0302) = 1\u221a\nTIFTest(\u03b8\u0302) . (5)\nTherefore, using the test information function, the testing organization administrators can estimate the measurement accuracy of a test form.\nActually, the test information function is a continuous function of the examinee ability and the item characteristic parameters. Traditional methods (e.g. [1], [2], [8], [10]\u2013[12], [23]) treat values of the test information function discretely to simplify computation. For instance, these methods have been evaluated specifically for some points \u0398 = {\u03b81, . . . , \u03b8k , . . . , \u03b8K} on the ability level \u03b8. According to traditional methods, this study treats the test information function similarly."
        },
        {
            "heading": "III. TRADITIONAL METHODS OF AUTOMATED TEST ASSEMBLY",
            "text": "This section introduces two typical automated test assembly methods from earlier research."
        },
        {
            "heading": "A. BIG SHADOW TEST METHOD",
            "text": "The most widely recognized automated test assembly method, which uses mixed integer programming (MIP), is the Big Shadow Test method (BST) devised by van der Linden [8] . Actually, BST assembles parallel test forms sequentially by minimizing the difference of the test information between an assembled test form and a set of items remaining in the item pool. The set of remaining items is called the shadow test. Actually, BST optimizes the following MIP problem. variables\nxi =  1 if i -th item is selectedinto the assembling test form 0 otherwise ,\ny \u2265 0,\nzi =  1 if i -th item is selectedinto the shadow test form 0 otherwise .\nminimize\ny\nVOLUME 10, 2022 3\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nsubject to K\u2211\nk=1\n| n\u2211\ni=1\nIIFi(\u03b8k )xi \u2212 T(\u03b8k )| \u2264 My , (6)\nK\u2211 k=1 | n\u2211 i=1 IIFi(\u03b8k )zi \u2212 TST(\u03b8k )| \u2264 MSTy , (7)\nn\u2211 i=1 xi = M, (8)\nn\u2211 i=1 zi = MST, (9)\nxi + zi \u2264 1. (10) (i = 1, 2, . . . ,n)\nwhere\nTST(\u03b8k ) = MST M T(\u03b8k ), (11)\nTherein, M and MST respectively represent the numbers of items in the assembling test form and the shadow test form. Also, T(\u03b8k ) denotes a target value of the test information function at the ability level \u03b8k for the assembling test form. For the shadow test, TST(\u03b8k ) is a target value of the test information function at ability level \u03b8k . The test quality constraints without an information function (e.g., test time limits) can be included among the constraints of the MIP.\nActually, y simultaneously represents the minimum difference between the information function of the assembled test and the target value T(\u03b8k ), and the difference between information functions of the shadow test and the target value TST(\u03b8k ).\nSolving the MIP assembles a test form using items one-by-one to assemble parallel test forms. Although this greedy algorithm of BST reduces computational costs, its measurement accuracy for the examinee\u2019s ability decreases as the number of assembled test forms increases.\nB. HYBRID MAXIMUM CLIQUE ALGORITHM USING PARALLEL INTEGER PROGRAMMING METHOD Hybrid Maximum Clique Algorithm Using Parallel Integer Programming method (HMCAPIP) [5] is known to assemble the greatest number of tests with the highest measurement accuracy.\nMany automated test assemblies [1], [2], [8], [10]\u2013[12], [23] have solved a problem to minimize differences in ability measurement accuracies based on test information among tests. Nevertheless, they are not guaranteed to maximize the number of assembled test forms. Testing organizations must therefore allocate different tests to each examinee to secure the item contents.\nTo overcome this difficulty, Fuchimoto et al. [5] proposed a two-step parallel algorithm. The first step of their method assembles parallel test forms with an overlapping constraint as a maximum clique problem\nFIGURE 1. Outline of the maximum clique method.\n[3], [16] that has low time complexity but high space complexity. The clique is a graph structure, which is any two vertices with an edge. Here, the overlapping constraint (OC) restricts the number of overlapping items among tests. Figure 1 presents an outline of the maximum clique method. The method constructs a graph in which the vertices and the edges respectively represent tests satisfying the test constraint and tests satisfying the overlapping constraint. The maximum clique method extracts the maximum clique as parallel test forms from the graph.\nThe second step, using integer programming (IP) method [26] with low space complexity but high time complexity, repeats the parallel search of the tests satisfied with the overlapping constraint for all currently assembled tests. The IP for assembly of a new test is presented below. where\nxi =  1 if the i -th item is selected in the feasible test, and 0 otherwise.\nmaximize n\u2211\ni=1\n\u03bbixi , (12)\nsubject to n\u2211\ni=1\nxi = M, (13)\nLB\u03b8k \u2264 n\u2211\ni=1\nIIFi(\u03b8k )xi \u2264 UB\u03b8k , (14)\n(k = 1, 2, ...,K ) n\u2211\ni=1\nXi,rxi \u2264 OC, (15)\n(r = 1, 2, ..., |C |)\nXi,r =  1 if the i\u2013th item is selected in the r\u2013th test\nin the current clique C , and 0 otherwise."
        },
        {
            "heading": "4 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\na\nbb\ncccc\n0 1 0 1 0 1 0 0\n(a) Binary Decision Tree\na\nb\nc\n10\n(b) ZDD\n1 -\nFIGURE 2. Binary Decision Tree and Zero Suppressed Binary Decision Diagrams. Therein, 1; 2; : : : ; n respectively denote random variables distributed uniformly on [0,1], LB k and UB k denote a lower bound and an upper bound for the test information function on TIF Test ( k ). Actually, f i g(0 i n) are resampled after each problem is solved. IV. PROPOSED METHOD Currently, HMCAPIP is known to be capable of assembling the greatest number of test forms. Nevertheless, the improvement of HMCAPIP is constrained because of the high time complexity of IP in the second step. Particularly, HMCAPIP requires one week or more to assemble 300,000 tests because the IP computation time increases along with the number of assembled test forms. Moreover, the HMCAPIP parallel search performance depends on the computer speci cations. To resolve these di culties, we propose a new automated test assembly: ATA-ZDD (Automated Test Assembly using ZDD). According to the proposed method, each node in the binary decision tree corresponds to an item of an item pool. Each node has two edges, respectively representing that the corresponding item is included in a test form, or not. The binary decision tree can enumerate all parallel test forms with the satis ed test constraints. Nevertheless, the binary decision tree has high space complexityO(2n =n). To relax this high space complexity, the proposed method compresses the binary decision tree using ZDD based on a breadthrst manner [22], [27], which is known as an e cient construction technique for reducing the necessities for computer memory and calculation time. Speci cally, all equivalent nodes are shared, provided that they have the same measurement accuracies and the same test lengths. Because of this feature, the proposed method can assemble the parallel test forms without redundantly repeating calculations for the measurement accuracies and the test lengths. A. ZERO SUPPRESSED BINARY DECISION DIAGRAMS (ZDD) Actually, Zero Suppressed Binary Decision Diagrams (ZDD) [17] constitute an e cient data structure for a\nset of item combinations from a nite set. Figures 2(a) and 2(b) respectively depict examples of binary decision tree and zero-suppressed binary decision diagrams. These data structures have terminal nodes of two kinds represented as rectangles in Fig. 2: 0-terminal and 1-terminal. Paths from the root node to the 1- terminal node in these data structures correspond to a set of item combinations. Then, every non-terminal node shown as a circle in Fig. 2 is labeled by an element of a nite set with order. Moreover, each has two edges: the 0-edge and 1-edge. The 1-edge (0-edge) signi es that the parent node is included (not included) in the item combinations. Therefore, the data structures of Fig. 2 correspond to the same set of item combinations, which is ff a; cg; f b; cg; f cgg. The salient di erence between data structures of Figs. 2(a) and 2(b) is their degree of compression e ciency. In fact, ZDD can enumerate only three nodes for the set of item combinations in Fig. 2(b). To construct e cient data structures, Minato [17] applies the following two reduction rules to the binary decision tree: Share all equivalent nodes having the same item and the same pair of children. Delete all nodes for which 1-edge points directly to the 0-terminal node. By the two reduction rules, ZDD can enumerate all feasible solutions e ciently with a reasonable calculation time and memory limitation. B. AUTOMATED TEST ASSEMBLY USING ZDD (ATA-ZDD) This section presents a new automated test assembly: ATA-ZDD. For automated test assembly using ZDD, the analyses used for this study de ne a nite set I = f x1 ; x2 ; : : : ; xn g with ordered items, where n is the item pool size. Then S I is designated as an item combination. For a given test constraint function f : 2S ! f 0 ; 1g, the families of setsT for f are denoted asT = f S I j f (S) = 1g, which are called the parallel test forms. Here, the test constraints are de ned formally as presented below.\njSj = M (test lengths), (16) LB k X\nxi 2 S\nIIF xi ( k ) UB k . (17) (k = 1 ; 2; :::; K ) (test information constraints) The main idea of ATA-ZDD is to enumerate the item combinations satisfying these test constraints using ZDD. Here, we describe the use a test length variable as TL and a test information array as TI = [ti 1 ; : : : ; ti k ; : : : ; ti K ] for using the breadth- rst technique [22], [27] and branch-and-bound. The test length variable and each element of the test information array respectively correspond to jSj (eq. 16) and\nVOLUME 10, 2022 5\nThis article has been accepted for publication in IEEE Access. This is the author\u2019s version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3322720\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\n(1) root node (3) share node(2) child node\n1\n(4) connect 1-terminal node\n10\n(5) connect 0-terminal node\n1 -\nThis article has been accepted for publication in IEEE Access. This is the author\u2019s version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3322720\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nThe ATA-ZDD algorithm is presented as Algorithm 1. Algorithm 1 is unable to enumerate exactly parallel test forms to satisfy the test information constraints (eq. 17) because each element of the test information array for shared nodes is approximated by the average of the test information of two nodes in Step 3. Furthermore, this ZDD cannot control overlapping items.\nTo resolve these shortcomings, ATA-ZDD enumerates test forms that satisfy these constraints exactly using random sampling [17] with low time complexity O(n) from ZDD.\nFor this discussion, we define the families of sets with the test constraints and the overlapping constraints as parallel test forms with overlapping items TOC.\nThe algorithm consists of the following three steps. 1) Step 1 sets TOC to \u03d5. 2) Step 2 searches for a test form using random sam-\npling [17] from ZDD (T \u2208T ). Here, the random sampling has low time complexity O(n). 3) Step 3 checks that the random sampling test form T satisfies the test information constraints (eq. 17) and the overlapping constraints with all parallel test forms with overlapping items TOC (\u2200TOC \u2208 TOC | (|TOC \u2229 T | \u2264 OC)). When the random sampling test form T satisfies these constraints, it is added to the parallel test forms with overlapping items TOC (TOC \u2190 TOC \u222a T ). 4) The proposed method repeats Step 1 through Step 3 until a determined calculation time is reached.\nThis algorithm is shown in Algorithm 2 as ATA-ZDD with OC.\nThus, ATA-ZDD with OC can enumerate parallel test forms with the equivalent test information and with the number of overlapping items that is less than a\nAlgorithm 2 ATA-ZDD with OC 1: procedure ATA-ZDD with OC(OC) 2: TOC \u2190 \u2205 3: while within a time limitation do 4: for each T \u2208 T do \u25b7 random sampling 5: for each k \u2208 K do 6: TIF\u03b8k \u2190 CalculateTestInfo(T , \u03b8k ) \u25b7 eq(3) 7: if TIF\u03b8k < LB\u03b8k or UB\u03b8k < TIF\u03b8k then 8: \u25b7 Test information constraint 9: Next T 10: end if 11: end for 12: for each TOC \u2208 TOC do 13: if OC < |T \u2229 TOC| then 14: \u25b7 Overlap constraint 15: Next T 16: end if 17: end for 18: TOC \u2190 TOC \u222a T 19: end for 20: end while 21: return TOC 22: end procedure\ndetermined value via repeating random sampling [17] from ZDD with low time complexity O(n)."
        },
        {
            "heading": "V. EXPERIMENTS",
            "text": "This section presents experiments demonstrating the effectiveness of the proposed method: ATA-ZDD."
        },
        {
            "heading": "A. EFFECTIVENESS OF THE THRESHOLD PARAMETER",
            "text": "The proposed method has a tradeoff by threshold parameter Ith between the number of assembled test forms and that of nodes for ZDD construction. Therefore, we evaluate the tradeoff by changing the value of the threshold parameter to obtain the optimal value maximizing the number of assembled test forms. We compare the performances by changing the values of the threshold parameter Ith using both simulated and actual item pools. Items in the simulated item pools have discrimination parameters and difficulty parameters according to the two-parameter logistic model of IRT. We generated discrimination parameters as log2 a \u223c N (0, 12) and difficulty parameters as b \u223c N (0, 12). A detailed description of the actual item pool is presented in Table 1. This actual item pool is used for the synthetic personality inventory (SPI) examination: a popular Japanese aptitude test [28].\nFor this study, the constraints applied for the test are presented below.\n1) The test contains 100 items. 2) The test information constraints are described by\nthe lower and upper bounds of the test information function in Table 2.\nWe determined these constraints according to the actual test setting [28]. The threshold parameter of ATA-ZDD is changed from 0.01 to 0.45 in 0.01 steps. Overlapping items are not controlled for this experiment.\nTABLE 1. Details of the actual item pool\nItem Pool Parameter a Parameter b Size Range Mean SD Range Mean SD\n87 0.15 \u2212 \u22120.67 0.35 0.13 \u22122.09 \u2212 \u22124.55 0.73 1.62 93 0.19 \u2212 \u22120.69 0.43 0.12 \u22123.92 \u2212 \u22123.61 \u22120.79 1.19 104 0.13 \u2212 \u22121.10 0.59 0.21 \u22120.18 \u2212 \u22124.55 1.50 1.18 141 0.24 \u2212 \u22121.09 0.64 0.15 \u22121.41 \u2212 \u22123.91 0.60 0.85 158 0.15 \u2212 \u22123.08 0.44 0.25 \u22124.00 \u2212 \u22124.00 \u22121.12 1.43 175 0.12 \u2212 \u22120.93 0.39 0.13 \u22122.93 \u2212 \u22123.12 \u22120.25 1.11 220 0.16 \u2212 \u22120.92 0.46 0.15 \u22124.00 \u2212 \u22122.82 \u22121.28 1.09\nTotal\n978 0.12 \u2212 \u22123.08 0.46 0.19 \u22124.00 \u2212 \u22124.55 \u22120.22 1.57\nTABLE 2. Test information constraints for automated test assembly\nTIF(\u03b8)(Lower bound / Upper bound) \u03b8 = \u22122.0 \u03b8 = \u22121.0 \u03b8 = 0.0 \u03b8 = 1.0 \u03b8 = 2.0 8.0/9.6 12.8/14.4 12.8/14.4 12.8/14.4 8.0/9.6\nVOLUME 10, 2022 7\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS TA B LE 3. N um be r of te st s, nu m be r of ve rt ic es of ZD D ,a nd ca lc ul at io n ti m es by ch an gi ng th e I th pa ra m et er It em P o o l S iz e = 1 0 0 0 It em P o o l S iz e = 2 0 0 0 It em P o o l S iz e = 9 7 8 I t h N o . te st s C o m p re ss io n ra ti o T im e N o . te st s C o m p re ss io n ra ti o T im e N o . te st s C o m p re ss io n ra ti o T im e u n d er 0 .2 7 M em o ry O v er M em o ry O v er M em o ry O v er 0 .2 8 M em o ry O v er M em o ry O v er 4 .6 5 \u00d7 1 0 1 2 7 3 .7 7 \u00d7 1 0 \u2212 2 8 8 1 2 0 2 0 .2 9 M em o ry O v er M em o ry O v er 4 .2 1 \u00d7 1 0 1 2 6 2 .3 7 \u00d7 1 0 \u2212 2 8 8 2 2 0 0 .3 0 M em o ry O v er M em o ry O v er 3 .0 1 \u00d7 1 0 1 2 8 1 .5 7 \u00d7 1 0 \u2212 2 8 8 1 9 3 0 .3 1 M em o ry O v er M em o ry O v er 1 .3 4 \u00d7 1 0 1 3 0 1 .1 8 \u00d7 1 0 \u2212 2 8 8 1 4 2 0 .3 2 M em o ry O v er M em o ry O v er 9 .1 1 \u00d7 1 0 1 2 3 8 .0 4 \u00d7 1 0 \u2212 2 8 9 9 9 0 .3 3 M em o ry O v er M em o ry O v er 1 .5 6 \u00d7 1 0 1 2 3 8 .2 2 \u00d7 1 0 \u2212 2 8 9 7 8 0 .3 4 1 .6 7 \u00d7 1 0 1 3 6 1 .2 0 \u00d7 1 0 \u2212 2 9 3 1 1 2 2 M em o ry O v er 5 .2 9 \u00d7 1 0 1 2 0 5 .5 0 \u00d7 1 0 \u2212 2 8 9 6 1 0 .3 5 1 .4 3 \u00d7 1 0 1 3 6 8 .3 3 \u00d7 1 0 \u2212 2 9 4 6 5 4 M em o ry O v er 7 .8 2 \u00d7 1 0 1 2 4 3 .7 3 \u00d7 1 0 \u2212 2 8 9 4 0 0 .3 6 1 .3 8 \u00d7 1 0 1 3 6 6 .8 4 \u00d7 1 0 \u2212 2 9 4 3 3 8 M em o ry O v er 3 .1 1 \u00d7 1 0 1 1 7 2 .0 5 \u00d7 1 0 \u2212 2 8 9 3 9 0 .3 7 8 .1 2 \u00d7 1 0 1 3 5 6 .0 0 \u00d7 1 0 \u2212 2 9 4 2 5 8 M em o ry O v er 5 .3 3 \u00d7 1 0 1 2 0 3 .2 4 \u00d7 1 0 \u2212 2 8 9 2 4 0 .3 8 3 .2 0 \u00d7 1 0 1 3 6 4 .4 1 \u00d7 1 0 \u2212 2 9 4 1 3 2 2 .1 1 \u00d7 1 0 1 6 7 2 .1 6 \u00d7 1 0 \u2212 5 9 4 1 3 6 1 1 .1 7 \u00d7 1 0 1 2 9 3 .0 8 \u00d7 1 0 \u2212 2 8 9 1 1 0 .3 9 1 .0 3 \u00d7 1 0 1 3 6 3 .2 5 \u00d7 1 0 \u2212 2 9 4 7 8 6 .3 4 \u00d7 1 0 1 6 6 1 .8 5 \u00d7 1 0 \u2212 5 9 4 9 5 9 1 .0 7 \u00d7 1 0 1 2 8 2 .6 5 \u00d7 1 0 \u2212 2 8 9 5 0 .4 0 9 .1 0 \u00d7 1 0 1 3 5 2 .5 1 \u00d7 1 0 \u2212 2 9 4 4 9 3 .6 6 \u00d7 1 0 1 6 7 1 .4 4 \u00d7 1 0 \u2212 5 9 4 5 5 0 9 .8 7 \u00d7 1 0 1 2 3 1 .5 7 \u00d7 1 0 \u2212 2 8 9 5 0 .4 1 1 .5 1 \u00d7 1 0 1 3 6 1 .7 3 \u00d7 1 0 \u2212 2 9 4 2 5 2 .5 6 \u00d7 1 0 1 6 7 1 .2 1 \u00d7 1 0 \u2212 5 9 4 3 3 0 2 .7 3 \u00d7 1 0 1 1 9 1 .1 9 \u00d7 1 0 \u2212 2 8 9 5 0 .4 2 1 .9 3 \u00d7 1 0 1 3 5 1 .3 7 \u00d7 1 0 \u2212 2 9 4 1 7 2 .1 1 \u00d7 1 0 1 6 7 8 .9 5 \u00d7 1 0 \u2212 5 9 5 2 6 0 1 .7 5 \u00d7 1 0 1 2 1 9 .5 9 \u00d7 1 0 \u2212 2 9 0 3 0 .4 3 1 .5 1 \u00d7 1 0 1 3 6 1 .0 8 \u00d7 1 0 \u2212 2 9 4 1 2 1 .0 5 \u00d7 1 0 1 6 7 7 .9 9 \u00d7 1 0 \u2212 5 9 5 2 1 0 1 .3 1 \u00d7 1 0 1 2 0 8 .5 3 \u00d7 1 0 \u2212 2 9 0 3 0 .4 4 9 .5 4 \u00d7 1 0 1 3 5 8 .5 4 \u00d7 1 0 \u2212 2 9 5 8 4 .1 8 \u00d7 1 0 1 6 7 6 .1 3 \u00d7 1 0 \u2212 5 9 5 1 3 3 8 .6 2 \u00d7 1 0 1 1 6 8 .2 1 \u00d7 1 0 \u2212 2 9 0 3 0 .4 5 3 .4 8 \u00d7 1 0 1 3 5 7 .7 3 \u00d7 1 0 \u2212 2 9 5 7 1 .1 3 \u00d7 1 0 1 6 7 4 .7 7 \u00d7 1 0 \u2212 5 9 5 8 5 2 .1 9 \u00d7 1 0 1 1 9 4 .1 5 \u00d7 1 0 \u2212 2 9 0 2 TA B LE 4. N um be r of pr un in g an d nu m be r of sh ar e no de s of ZD D by ch an gi ng th e pa ra m et er I th It em P o o l S iz e = 1 0 0 0 It em P o o l S iz e = 2 0 0 0 It em P o o l S iz e = 9 7 8 I t h N o . p ru n in g R ed u ct io n ru le N o . p ru n in g R ed u ct io n ru le N o . p ru n in g R ed u ct io n ru le u n d er 0 .2 7 M em o ry O v er M em o ry O v er M em o ry O v er 0 .2 8 M em o ry O v er M em o ry O v er 5 8 9 2 8 0 1 0 .0 8 0 .2 9 M em o ry O v er M em o ry O v er 5 3 8 9 2 1 0 0 .0 1 0 .3 0 M em o ry O v er M em o ry O v er 4 8 6 8 8 1 7 0 .0 6 0 .3 1 M em o ry O v er M em o ry O v er 4 1 0 0 6 6 5 0 .0 6 0 .3 2 M em o ry O v er M em o ry O v er 3 4 1 3 2 8 7 0 .0 4 0 .3 3 M em o ry O v er M em o ry O v er 3 0 3 4 3 0 5 0 .0 5 0 .3 4 9 2 3 9 8 9 2 0 .7 9 M em o ry O v er 2 6 9 2 4 2 6 0 .0 4 0 .3 5 8 2 3 4 7 2 9 0 .7 8 M em o ry O v er 2 0 7 0 7 7 0 0 .0 3 0 .3 6 7 5 3 7 9 9 3 0 .7 9 M em o ry O v er 1 9 3 9 6 1 0 0 .0 2 0 .3 7 6 6 3 6 4 1 9 0 .7 8 M em o ry O v er 1 8 6 5 9 2 3 0 .0 4 0 .3 8 4 8 5 2 5 1 1 0 .8 0 1 7 0 2 3 8 9 0 0 .6 4 1 1 7 9 7 1 1 0 .0 6 0 .3 9 3 6 3 4 4 7 2 0 .7 9 1 5 8 9 2 0 3 9 0 .6 3 7 1 9 3 5 7 0 .0 0 0 .4 0 2 7 9 4 3 3 2 0 .7 9 1 4 5 9 1 0 9 0 0 .6 3 8 5 7 4 6 8 0 .0 4 0 .4 1 1 9 2 1 6 5 0 0 .7 9 1 4 0 2 3 9 0 0 0 .6 3 8 2 7 7 3 9 0 .0 3 0 .4 2 1 5 2 3 5 1 7 0 .7 8 1 3 7 1 6 3 4 5 0 .6 3 6 1 2 4 0 5 0 .0 3 0 .4 3 1 1 9 6 3 8 0 0 .7 8 1 2 9 6 1 6 7 5 0 .6 3 5 4 7 9 4 2 0 .0 0 0 .4 4 9 5 6 1 1 5 0 .7 8 1 0 8 8 9 6 0 4 0 .6 4 5 4 7 4 3 4 0 .0 3 0 .4 5 9 0 1 0 3 7 0 .7 7 8 3 5 9 0 9 9 0 .6 4 4 3 5 4 0 7 0 .0 2"
        },
        {
            "heading": "8 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nHere, we conduct experiments using a computer (Ryzen 9 5950X 3.40 GHz CPU; AMD Corp.) with 128 GB main memory and operating system (64bit Ubuntu; Linux).\nTable 3 presents the number of assembled test forms by changing the value of Ith . In the table, No. tests signifies the number of assembled test forms, Compression Ratio expresses the number of nodes in ZDD divided by the number of nodes in the binary decision tree, and Time denotes the calculation time (minute) for ZDD construction.\nAs described previously, the proposed method entails a tradeoff between the number of assembled test forms and that of nodes for ZDD construction. When the threshold parameter Ith is small, the proposed method tends to assemble the greatest number of assembled test forms, but it causes memory overflow.\nWhen the threshold parameter Ith becomes large, the calculation time and the number of nodes for ZDD construction decreases because the number of shared nodes is increased.\nTherefore, to decrease the calculation time and memory limitations, the threshold parameter should be increased. As described herein, the threshold is determined by the value which can assemble the greatest number of assembled test forms for each item pool.\nRegarded in greater detail, Table 4 shows the number of prunings in the Algorithm. 1 and the compression ratio obtained using the reduction rules. When the threshold parameter Ith becomes sufficiently small, the number of prunings increases because the number of shared nodes decreases and the number of branches increases. On the other hand, differences in the compression ratio with reduction rules are small, irrespective of the threshold parameter Ith .\nB. COMPARISON OF ATA-ZDD TO CONVENTIONALLY USED METHODS To demonstrate the ATA-ZDD benefits, we compare the number of assembled test forms of ATA-ZDD with those produced using the traditional methods of (Big Shadow Test Method [8] (designated for comparison as BST) and Hybrid Maximum Clique Algorithm with Parallel Integer Programming (designated for comparison as s HMCAPIP) [5]) using simulated and actual item pools described in the preceding subsection.\nWe set the test constraints as presented below. 1) The test contains 100 items. 2) The allowed maximum numbers of overlapping\nitems are changed from two to thirty by increments of two. 3) The time limitation of all methods is 24 hr. 4) The test information constraints are the same as\nthose presented in the preceding subsection. We determined the parameter values of HMCAPIP according to an explanation given in the literature by\nFuchimoto et al. (2022) [5]. For HMCAPIP and BST, we apply CPLEX [29] for the integer programming problem.\nTable 5 presents the numbers of assembled test forms produced using the proposed method and using the traditional methods, by changing item pool sizes and overlapping constraints.\nWhen OC becomes large, the proposed method can assemble a greater number of assembled test forms than the traditional methods do. It is noteworthy that the\nVOLUME 10, 2022 9\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nproposed method can assemble the 1,500,000 test forms within 24 hr, which would take one month or more if using conventional methods. These findings suggest that the proposed method has important advantages in large-scale testing, which necessitates the number of test forms.\nEven when OC becomes small, HMCAPIP can assemble a slightly greater number of tests than other methods do. The results demonstrate that the numbers converge to the maximum number of assembled test forms because, as a result of the tight OC, the exact maximum number of test forms is not large. Nevertheless, because the test information is approximated by the mean when the nodes of ZDD are shared, the proposed method does not guarantee exactly the maximum number of assembled test forms. Therefore, the performance of the proposed method is limited with a tight OC.\nWhen OC \u2265 24, because of the time complexity O(n) of random sampling, the proposed method for item pool size = 1000 can assemble a greater number of test forms than the proposed method for item pool size = 2000 does. In fact, when OC = 24, the proposed method for item pool size = 1000 samples 1,640,000,000 test forms, but the proposed method for item pool size = 2000 samples only 630,000,000 test forms.\nNevertheless, because each element of the test information array is approximated by the mean when nodes are shared, ATA-ZDD does not guarantee exactly all enumerations with satisfaction of the test constraints. To evaluate the effectiveness of this approximation, we simulate the percentage of paths which satisfy the test information constraint when using random sampling. Specifically, when the random sampling is repeated one billion times, this experiment calculates the percentage of paths which strictly satisfy the constraints of the test information.\nTable 6 shows that the percentage of paths that satisfy the constraints of the test information. The results suggest that the proposed method still has room for improvement in the threshold parameter because the number of strictly satisfied tests decreases as the amount of node-sharing increases.\nTABLE 6. Percentage of paths satisfying the test information constraint\nItem Pool Size Ith Percentage of paths\n1000 0.17 0.07\n2000 0.20 0.07\n978 0.16 0.51\nVI. CONCLUSIONS We proposed a new automated test assembly: ATAZDD. According to this proposed method, each node in the binary decision tree corresponds to an item of an item pool. Each node has two edges, respectively\nsignifying that the corresponding item is included in a test form, or not. Furthermore, all equivalent nodes are shared, providing that they have the same measurement accuracy and the same test length.\nNumerical experiments demonstrated that the proposed method assembled a greater number of test forms than the conventional methods did. It is noteworthy that the proposed method was able to assemble 1,500,000 test forms within 24 hr, whereas a currently widely used method assembled only 300,000 test forms during a week or more. Moreover, these results suggest that the drastically different quantities of assembled parallel test forms created using these methods would differ increasingly with extended calculation time.\nNevertheless, ATA-ZDD does not guarantee exactly all enumerations with the satisfaction of test constraints: each element of the test information array is approximated by the mean when nodes are shared. Therefore, the proposed method still has room for improvement of its threshold parameter optimization because the number of strictly satisfied tests is reduced as the number of node-sharing increases.\nFurthermore, this study specifically examines automated test assembly using only those constraints related to the test length and test information. In fact, actual examinations require other test constraints. For instance, the proposed method does not regulate the number of times each item has been used in the assembled test forms. Therefore, the distribution of item usage counts is not uniform, which is designated as an item exposure bias problem [30]. The exposure bias problem is known to impair the reliability of items and tests [30]. To resolve the item exposure problem, we expect to implement the proposed method using a probabilistic approach of item exposure such as probabilistic eligibility by Linden [31] in computerized adaptive testing (CAT)."
        },
        {
            "heading": "10 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nAuthor et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS\nexposure. In Artificial Intelligence in Education: 23rd International Conference, AIED 2022, Durham, UK, July 27\u201331, 2022, Proceedings, Part I, pages 626\u2013632. Springer, 2022. [8] Wim J. Van der Linden. Linear Models for Optimal Test Design. Springer, 2005. [9] Wim J. van der Linden and Jos J. Adema. Simultaneous assembly of multiple test forms. Journal of Educational Measurement, 35(3):185\u2013198, September 1998. [10] Ellen Boekkooi-Timminga. The construction of parallel tests from irt-based item banks. J. Educat. Statist. 15, 129\u2013145, 1990. [11] Ronald D. Armstrong, Douglas H. Jones, and Zhaobo Wang. Automated parallel test construction using classical test theory. Journal of Educational Statistics, 19(1):73\u201390, 1994. [12] Ronald D. Armstrong, Douglas H. Jones, and Charles S. Kunce. Irt test assembly using network-flow programming. Applied Psychological Measurement, 22(3):237\u2013247, 1998. [13] Ting-Yi Chang and You-Fu Shiu. Simultaneously construct irt-based parallel tests based on an adapted clonalg algorithm. Applied Intelligence, 36(4):979\u2013994, Jun 2012. [14] Jordi Pereira and Mariona Vila. Variable neighborhood search heuristics for a test assembly design problem. Expert Systems with Applications, 42(10):4805\u20134817, 2015. [15] Dmitry I. Belov and Ronald D. Armstrong. A constraint programming approach to extract the maximum number of non-overlapping test forms. Computational Optimization and Applications, 33:319\u2013332, 2006. [16] Takatoshi Ishii, Pokpong Songmuang, and Maomi Ueno. Maximum clique algorithm for uniform test forms. The 16th International Conference on Artificial Intelligence in Education, pages 451\u2013462, 2013. [17] Shin-ichi Minato. Zero-suppressed bdds for set manipulation in combinatorial problems. In Proceedings of the 30th International Design Automation Conference, pages 272\u2013277, 1993. [18] Takeru Inoue, Keiji Takano, Takayuki Watanabe, Jun Kawahara, Ryo Yoshinaka, Akihiro Kishimoto, Koji Tsuda, Shinichi Minato, and Yasuhiro Hayashi. Distribution loss minimization with guaranteed error bound. IEEE Transactions on Smart Grid, 5(1):102\u2013111, 2014. [19] Atsushi Takizawa, Yasufumi Takechi, Akio Ohta, Naoki Katoh, Takeru Inoue, Takashi Horiyama, Jun Kawahara, and SI Minato. Enumeration of region partitioning for evacuation planning based on zdd. 2013. [20] Atsushi Takizawa, Yushi Miyata, and Naoki Katoh. Enumeration of floor plans based on a zero-suppressed binary decision diagram. International Journal of Architectural Computing, 13(1):25\u201344, 2015. [21] Shinsaku Sakaue and Kengo Nakamura. Differentiable equilibrium computation with decision diagrams for stackelberg models of combinatorial congestion games. Advances in Neural Information Processing Systems, 34:9416\u20139428, 2021. [22] Hiroaki Iwashita and Shin-ichi Minato. Efficient top-down ZDD construction techniques using recursive specifications, 2013. [23] Wim J. Van der Linden and Ellen Boekkooi-Timminga. A maximin model for irt-based test design with practical constraints. Psychometrika, 54(2):237\u2013247, June 1989. [24] F.M. Lord and M.R. Novick. Statistical theories of mental test scores. Addison-Wesley Pub. Co., 1968. [25] F.B. Baker and S.H. Kim. Item Response Theory: Parameter Estimation Techniques, Second Edition. Statistics: A Series of Textbooks and Monographs. Taylor & Francis, 2004. [26] Takatoshi Ishii and Maomi Ueno. Algorithm for uniform test assembly using a maximum clique problem and integer programming. In Artificial Intelligence in Education, pages 102\u2013112. Springer International Publishing, 2017. [27] Donald Ervin Knuth. The art of computer programming: Bitwise tricks & techniques. Binary Decision Diagrams, 4, 2009. [28] Recruit. Synthetic Personality Inventory (SPI). [29] IBM. Ilog cplex optimization studio cplex user\u2019s manual 12.9,\n2019.\n[30] Howard Wainer. Rescuing computerized testing by breaking zipf\u2019s law. Journal of Educational and Behavioral Statistics, 25:203\u2013224, 2000. [31] Wim J Van der Linden and Seung W Choi. Improving itemexposure control in adaptive testing. Journal of Educational Measurement, 57(3):405\u2013422, 2020.\nKAZUMA FUCHIMOTO received a BEng degree from the University of ElectroCommunications in 2020, where he is currently pursuing a MEng degree. His research interests include educational technology and computer science.\nSHIN-ICHI MINATO is a Professor at Graduate School of Informatics, Kyoto University. He received B.E., M.E., and D.E. degrees respectively from Kyoto University in 1988, 1990, and 1995. He worked for NTT Laboratories from 1990 until 2004. He was a Visiting Scholar at Stanford University in 1997. He joined Hokkaido University as an Associate Professor in 2004, where he has been a Professor since October 2010. From April\n2018, he has served as a Professor at Kyoto University (present position). His research interests include efficient representations and manipulation algorithms for large-scale discrete structures, such as Boolean functions, sets of combinations, sequences, and permutations. In addition to being a senior member of IEICE, IPSJ and IEEE, he is a member of JSAI and JSCS.\nMAOMI UENO received a Ph.D. degree in computer science from the Tokyo Institute of Technology in 1994. He has served as a professor of the Graduate School of Information Systems at the University of Electro-Communications since 2013. He was conferred the Best Paper award at IEEE ICTAI2008. His interests include machine learning, data mining, Bayesian statistics, Bayesian networks, and educational tech-\nnology. He is an IEEE member.\nVOLUME 10, 2022 11\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/"
        }
    ],
    "title": "Automated Test Assembly using Zero-suppressed Binary Decision Diagrams",
    "year": 2023
}