{
    "abstractText": "In the domain of digital information dissemination, search engines act as pivotal conduits linking information seekers with providers. The advent of chat-based search engines utilizing Large Language Models (LLMs) and Retrieval Augmented Generation (RAG), exemplified by Bing Chat, marks an evolutionary leap in the search ecosystem. They demonstrate metacognitive abilities in interpreting web information and crafting responses with human-like understanding and creativity. Nonetheless, the intricate nature of LLMs renders their \u201ccognitive\u201d processes opaque, challenging even their designers\u2019 understanding. This research aims to dissect the mechanisms through which an LLM-powered chat-based search engine, specifically Bing Chat, selects information sources for its responses. To this end, an extensive dataset has been compiled through engagements with New Bing, documenting the websites it cites alongside those listed by the conventional search engine. Employing natural language processing (NLP) techniques, the research reveals that Bing Chat exhibits a preference for content that is not only readable and formally structured, but also demonstrates lower perplexity levels, indicating a unique inclination towards text that is predictable by the underlying LLM. Further enriching our analysis, we procure an additional dataset through interactions with the GPT-4 based knowledge retrieval API, unveiling a congruent text preference between the RAG API and Bing Chat. This consensus suggests that these text preferences intrinsically emerge from the underlying language models, rather than being explicitly crafted by Bing Chat\u2019s developers. Moreover, our investigation documents a greater similarity among websites cited by RAG technologies compared to those ranked highest by conventional search engines. Collectively, these findings illuminate the unique sources, preferences, and potential economic implications of chat-based search engines\u2019 content selection behavior, providing fresh perspectives for both academic research and practical applications within the search engine domain.",
    "authors": [
        {
            "affiliations": [],
            "name": "Lijia Ma"
        },
        {
            "affiliations": [],
            "name": "Michael G. Foster"
        },
        {
            "affiliations": [],
            "name": "Xingchen (Cedric) Xu"
        },
        {
            "affiliations": [],
            "name": "Yong Tan"
        }
    ],
    "id": "SP:f88f3a8173a057eae197d9d4ce91708761200b4a",
    "references": [
        {
            "authors": [
                "V Abhishek",
                "K Hosanagar"
            ],
            "title": "Optimal bidding in multi-item multislot sponsored search auctions. Operations Research 61(4):855\u2013873",
            "year": 2013
        },
        {
            "authors": [
                "S Athey",
                "G Ellison"
            ],
            "title": "Position auctions with consumer search",
            "venue": "The Quarterly Journal of Economics",
            "year": 2011
        },
        {
            "authors": [
                "L Azzopardi",
                "M Girolami",
                "K Van Risjbergen"
            ],
            "title": "Investigating the relationship between language model perplexity and ir precision-recall measures",
            "venue": "Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval,",
            "year": 2003
        },
        {
            "authors": [
                "G B\u00e9n\u00e9dict",
                "R Zhang",
                "D Metzler"
            ],
            "title": "Gen-ir@ sigir 2023: The first workshop on generative information retrieval",
            "venue": "Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,",
            "year": 2023
        },
        {
            "authors": [
                "R Berman",
                "Z Katona"
            ],
            "title": "The role of search engine optimization in search marketing. Marketing Science 32(4):644\u2013651",
            "year": 2013
        },
        {
            "authors": [
                "S Borwankar",
                "W Khern-am nuai"
            ],
            "title": "Unraveling the impact: An empirical investigation of chatgpt\u2019s exclusion from stack overflow",
            "year": 2023
        },
        {
            "authors": [
                "RL Boyd",
                "A Ashokkumar",
                "S Seraj",
                "JW Pennebaker"
            ],
            "title": "The development and psychometric properties of liwc-22",
            "venue": "Austin, TX: University of Texas",
            "year": 2022
        },
        {
            "authors": [
                "J Brand",
                "A Israeli",
                "D Ngwe"
            ],
            "title": "Using gpt for market research",
            "venue": "Available at SSRN",
            "year": 2023
        },
        {
            "authors": [
                "D Cer",
                "Y Yang",
                "Sy Kong",
                "N Hua",
                "N Limtiaco",
                "RS John",
                "N Constant",
                "M Guajardo-Cespedes",
                "S Yuan",
                "C Tar"
            ],
            "title": "Universal sentence encoder for english",
            "venue": "Proceedings of the 2018 conference on empirical methods in natural language processing: system demonstrations,",
            "year": 2018
        },
        {
            "authors": [
                "JS Chall",
                "E Dale"
            ],
            "title": "Readability revisited: The new Dale-Chall readability formula (Brookline Books)",
            "year": 1995
        },
        {
            "authors": [
                "J Chen",
                "H Lin",
                "X Han",
                "L Sun"
            ],
            "title": "Benchmarking large language models in retrieval-augmented generation",
            "year": 2023
        },
        {
            "authors": [
                "Y Chen",
                "TX Liu",
                "Y Shan",
                "S Zhong"
            ],
            "title": "2023b) The emergence of economic rationality of gpt",
            "year": 2023
        },
        {
            "authors": [
                "PJ Danaher",
                "GW Mullarkey",
                "S Essegaier"
            ],
            "title": "Factors affecting web site visit duration: A cross-domain analysis",
            "venue": "Journal of Marketing Research",
            "year": 2006
        },
        {
            "authors": [
                "T Dohmke",
                "M Iansiti",
                "G Richards"
            ],
            "title": "Sea change in software development: Economic and productivity analysis of the ai-powered developer lifecycle",
            "year": 2023
        },
        {
            "authors": [
                "X Du",
                "M Su",
                "X Zhang",
                "X Zheng"
            ],
            "title": "Bidding for multiple keywords in sponsored search advertising: Keyword categories and match types. Information Systems Research 28(4):711\u2013722",
            "year": 2017
        },
        {
            "authors": [
                "A Erdmann",
                "R Arilla",
                "JM Ponzoa"
            ],
            "title": "Search engine optimization: The long-term strategy of keyword choice",
            "venue": "Journal of Business Research",
            "year": 2022
        },
        {
            "authors": [
                "I Gabriel"
            ],
            "title": "Artificial intelligence, values, and alignment. Minds and machines 30(3):411\u2013437",
            "year": 2020
        },
        {
            "authors": [
                "D Ganguli",
                "L Lovitt",
                "J Kernion",
                "A Askell",
                "Y Bai",
                "S Kadavath",
                "B Mann",
                "E Perez",
                "N Schiefer",
                "K Ndousse"
            ],
            "title": "Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned",
            "year": 2022
        },
        {
            "authors": [
                "A Ghose",
                "PG Ipeirotis",
                "B Li"
            ],
            "title": "Examining the impact of ranking on consumer behavior and search engine revenue. Management Science 60(7):1632\u20131654",
            "year": 2014
        },
        {
            "authors": [
                "A Ghose",
                "PG Ipeirotis",
                "B Li"
            ],
            "title": "Modeling consumer footprints on search engines: An interplay with social media",
            "venue": "Management Science",
            "year": 2019
        },
        {
            "authors": [
                "A Ghose",
                "S Yang"
            ],
            "title": "An empirical analysis of search engine advertising: Sponsored search in electronic markets. Management science 55(10):1605\u20131622",
            "year": 2009
        },
        {
            "authors": [
                "LH Gilpin",
                "D Bau",
                "BZ Yuan",
                "A Bajwa",
                "M Specter",
                "L Kagal"
            ],
            "title": "Explaining explanations: An overview of interpretability of machine learning",
            "venue": "IEEE 5th International Conference on data science and advanced analytics (DSAA),",
            "year": 2018
        },
        {
            "authors": [
                "A Goldfarb",
                "C Tucker"
            ],
            "title": "Online display advertising: Targeting and obtrusiveness",
            "venue": "Marketing Science",
            "year": 2011
        },
        {
            "authors": [
                "H Gonen",
                "S Iyer",
                "T Blevins",
                "NA Smith",
                "L Zettlemoyer"
            ],
            "title": "Demystifying prompts in language models via perplexity estimation",
            "year": 2022
        },
        {
            "authors": [
                "J Gong",
                "V Abhishek",
                "B Li"
            ],
            "title": "Examining the impact of keyword ambiguity on search advertising performance. MIS Quarterly 42(3):805\u2013A14",
            "year": 2018
        },
        {
            "authors": [
                "B Guo",
                "X Zhang",
                "Z Wang",
                "M Jiang",
                "J Nie",
                "Y Ding",
                "J Yue",
                "Y Wu"
            ],
            "title": "How close is chatgpt to human experts? comparison corpus, evaluation, and detection",
            "year": 2023
        },
        {
            "authors": [
                "S Hofst\u00e4tter",
                "J Chen",
                "K Raman",
                "H Zamani"
            ],
            "title": "Fid-light: Efficient and effective retrieval-augmented text generation",
            "venue": "Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,",
            "year": 2023
        },
        {
            "authors": [
                "JJ Horton"
            ],
            "title": "Large language models as simulated economic agents: What can we learn from homo silicus",
            "venue": "Technical report, National Bureau of Economic Research",
            "year": 2023
        },
        {
            "authors": [
                "Z Hu",
                "Y Lan",
                "L Wang",
                "W Xu",
                "EP Lim",
                "RKW Lee",
                "L Bing",
                "S Poria"
            ],
            "title": "Llm-adapters: An adapter family for parameter-efficient fine-tuning of large language models",
            "year": 2023
        },
        {
            "authors": [
                "W Hua",
                "L Li",
                "S Xu",
                "L Chen",
                "Y Zhang"
            ],
            "title": "Tutorial on large language models for recommendation",
            "venue": "Proceedings of the 17th ACM Conference on Recommender Systems,",
            "year": 2023
        },
        {
            "authors": [
                "X Hui",
                "O Reshef",
                "L Zhou"
            ],
            "title": "The short-term effects of generative artificial intelligence on employment: Evidence from an online labor",
            "year": 2023
        },
        {
            "authors": [
                "BJ Jansen",
                "DL Booth",
                "A Spink"
            ],
            "title": "Determining the informational, navigational, and transactional intent of web queries. Information Processing & Management 44(3):1251\u20131266",
            "year": 2008
        },
        {
            "authors": [
                "J Ji",
                "T Qiu",
                "B Chen",
                "B Zhang",
                "H Lou",
                "K Wang",
                "Y Duan",
                "Z He",
                "J Zhou",
                "Z Zhang"
            ],
            "title": "2023) Ai alignment: A comprehensive survey",
            "year": 1985
        },
        {
            "authors": [
                "WJ Johnston",
                "S Fusi"
            ],
            "title": "Abstract representations emerge naturally in neural networks trained to perform multiple tasks",
            "venue": "Nature Communications",
            "year": 2023
        },
        {
            "authors": [
                "J Jumper",
                "R Evans",
                "A Pritzel",
                "T Green",
                "M Figurnov",
                "O Ronneberger",
                "K Tunyasuvunakool",
                "R Bates",
                "A \u017d\u00eddek",
                "A Potapenko"
            ],
            "title": "Highly accurate protein structure prediction with alphafold",
            "venue": "Nature",
            "year": 2021
        },
        {
            "authors": [
                "Z Katona",
                "M Sarvary"
            ],
            "title": "The race for sponsored links: Bidding patterns for search advertising",
            "venue": "Marketing Science",
            "year": 2010
        },
        {
            "authors": [
                "A Korinek",
                "A Balwit"
            ],
            "title": "Aligned with whom? direct and social goals for ai systems",
            "venue": "Technical report, National Bureau of Economic Research",
            "year": 2022
        },
        {
            "authors": [
                "M Kosinski"
            ],
            "title": "Theory of mind may have spontaneously emerged in large language models",
            "year": 2023
        },
        {
            "authors": [
                "P Lewis",
                "E Perez",
                "A Piktus",
                "F Petroni",
                "V Karpukhin",
                "N Goyal",
                "H K\u00fcttler",
                "M Lewis",
                "Wt Yih",
                "T Rockt\u00e4schel"
            ],
            "title": "Retrieval-augmented generation for knowledge-intensive nlp tasks",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2020
        },
        {
            "authors": [
                "D Liu",
                "J Chen",
                "AB Whinston"
            ],
            "title": "Ex ante information and the design of keyword auctions. Information Systems Research 21(1):133\u2013153",
            "year": 2010
        },
        {
            "authors": [
                "J Liu",
                "O Toubia"
            ],
            "title": "A semantic approach for estimating consumer content preferences from online search queries. Marketing Science 37(6):930\u2013952",
            "year": 2018
        },
        {
            "authors": [
                "J Liu",
                "X Xu",
                "Y Li",
                "Y Tan"
            ],
            "title": "2023a) \"generate\" the future of work through ai: Empirical evidence from online labor markets",
            "year": 2023
        },
        {
            "authors": [
                "P Liu",
                "W Yuan",
                "J Fu",
                "Z Jiang",
                "H Hayashi",
                "G Neubig"
            ],
            "title": "2023b) Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
            "year": 2023
        },
        {
            "authors": [
                "M McLuhan"
            ],
            "title": "Understanding Media: The Extensions of Man (Routledge)",
            "year": 1964
        },
        {
            "authors": [
                "Q Mei",
                "Y Xie",
                "W Yuan",
                "MO Jackson"
            ],
            "title": "A turing test of whether ai chatbots are behaviorally similar to humans",
            "venue": "Proceedings of the National Academy of Sciences 121(9):e2313925121",
            "year": 2024
        },
        {
            "authors": [
                "MR Morris",
                "J Sohl-dickstein",
                "N Fiedel",
                "T Warkentin",
                "A Dafoe",
                "A Faust",
                "C Farabet",
                "S Legg"
            ],
            "title": "Levels of agi: Operationalizing progress on the path to agi",
            "year": 2023
        },
        {
            "authors": [
                "R Nakano",
                "J Hilton",
                "S Balaji",
                "J Wu",
                "L Ouyang",
                "C Kim",
                "C Hesse",
                "S Jain",
                "Kosaraju"
            ],
            "title": "Webgpt: Browser-assisted question-answering with human feedback",
            "year": 2021
        },
        {
            "authors": [
                "L Ouyang",
                "J Wu",
                "X Jiang",
                "D Almeida",
                "C Wainwright",
                "P Mishkin",
                "C Zhang",
                "S Agarwal",
                "K Slama",
                "A Ray"
            ],
            "title": "Training language models to follow instructions with human feedback",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2022
        },
        {
            "authors": [
                "S Peng",
                "E Kalliamvakou",
                "P Cihon",
                "M Demirer"
            ],
            "title": "The impact of ai on developer productivity: Evidence from github copilot",
            "year": 2023
        },
        {
            "authors": [
                "M Reisenbichler",
                "T Reutterer",
                "DA Schweidel",
                "D Dan"
            ],
            "title": "Frontiers: Supporting content marketing",
            "year": 2022
        },
        {
            "authors": [
                "H Sch\u00fctze",
                "CD Manning",
                "P Raghavan"
            ],
            "title": "Introduction to information retrieval, volume",
            "venue": "Journal of Marketing Research",
            "year": 2008
        },
        {
            "authors": [
                "W Cambridge). Shin"
            ],
            "title": "Keyword search advertising and limited budgets. Marketing Science 34(6):882\u2013896",
            "venue": "IEEE Data Eng. Bull",
            "year": 2015
        },
        {
            "authors": [
                "W Wang",
                "S Pei",
                "T Sun"
            ],
            "title": "Unraveling generative ai from a human intelligence perspective: A battery",
            "venue": "reality. ACM Transactions on the Web (TWEB)",
            "year": 2023
        },
        {
            "authors": [
                "A Naik",
                "D Stap"
            ],
            "title": "Super-naturalinstructions: Generalization via declarative instructions on",
            "year": 2022
        },
        {
            "authors": [
                "L Xu",
                "J Chen",
                "A Whinston"
            ],
            "title": "Effects of the presence of organic listing in search advertising",
            "year": 2012
        },
        {
            "authors": [
                "R Xu",
                "Y Feng",
                "H Chen"
            ],
            "title": "Chatgpt vs. google: A comparative study of search performance and user",
            "year": 2023
        },
        {
            "authors": [
                "J Xue",
                "L Wang",
                "J Zheng",
                "Y Li",
                "Y Tan"
            ],
            "title": "Can chatgpt kill user-generated q&a platforms",
            "year": 2023
        },
        {
            "authors": [
                "WX Zhao",
                "K Zhou",
                "J Li",
                "T Tang",
                "X Wang",
                "Y Hou",
                "Y Min",
                "B Zhang",
                "J Zhang",
                "Z Dong"
            ],
            "title": "Positive, negative, or zero interdependence? Marketing science",
            "year": 2023
        },
        {
            "authors": [
                "Y Zhu",
                "H Yuan",
                "S Wang",
                "J Liu",
                "W Liu",
                "C Deng",
                "Z Dou",
                "JR Wen"
            ],
            "title": "Large language models for information",
            "year": 2023
        },
        {
            "authors": [
                "C Ziakis",
                "M Vlachopoulou",
                "T Kyrkoudis",
                "M Karagkiozidou"
            ],
            "title": "retrieval: A survey",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "Crafting Knowledge: Exploring the Creative",
            "text": ""
        },
        {
            "heading": "Mechanisms of Chat-Based Search Engines",
            "text": "Lijia Ma* Michael G. Foster School of Business, University of Washington, Seattle, WA 98195, lijiam@uw.edu\nXingchen (Cedric) Xu* Michael G. Foster School of Business, University of Washington, Seattle, WA 98195, xcxu21@uw.edu\nYong Tan\u2020 Michael G. Foster School of Business, University of Washington, Seattle, WA 98195, ytan@uw.edu\nIn the domain of digital information dissemination, search engines act as pivotal conduits linking information seekers with providers. The advent of chat-based search engines utilizing Large Language Models (LLMs) and Retrieval Augmented Generation (RAG), exemplified by Bing Chat, marks an evolutionary leap in the search ecosystem. They demonstrate metacognitive abilities in interpreting web information and crafting responses with human-like understanding and creativity. Nonetheless, the intricate nature of LLMs renders their \u201ccognitive\u201d processes opaque, challenging even their designers\u2019 understanding. This research aims to dissect the mechanisms through which an LLM-powered chat-based search engine, specifically Bing Chat, selects information sources for its responses. To this end, an extensive dataset has been compiled through engagements with New Bing, documenting the websites it cites alongside those listed by the conventional search engine. Employing natural language processing (NLP) techniques, the research reveals that Bing Chat exhibits a preference for content that is not only readable and formally structured, but also demonstrates lower perplexity levels, indicating a unique inclination towards text that is predictable by the underlying LLM. Further enriching our analysis, we procure an additional dataset through interactions with the GPT-4 based knowledge retrieval API, unveiling a congruent text preference between the RAG API and Bing Chat. This consensus suggests that these text preferences intrinsically emerge from the underlying language models, rather than being explicitly crafted by Bing Chat\u2019s developers. Moreover, our investigation documents a greater similarity among websites cited by RAG technologies compared to those ranked highest by conventional search engines. Collectively, these findings illuminate the unique sources, preferences, and potential economic implications of chat-based search engines\u2019 content selection behavior, providing fresh perspectives for both academic research and practical applications within the search engine domain.\nKey words : Generative AI, RAG, AI Creativity, AI Metacognition, AI Alignment, Search Engine, NLP\n1\nar X\niv :2\n40 2.\n19 42\n1v 1\n[ cs\n.I R\n] 2\n9 Fe\nb 20\n24"
        },
        {
            "heading": "1. Introduction",
            "text": "In the contemporary digital landscape, the volume and variety of information are expanding rapidly. To bridge the gap between information providers and seekers, search engines have become indispensable tools in everyday life. Data from Serpwatch reveals that 87% of mobile device users engage with search engines at least once daily. Google, for instance, processes an estimated 63,000 search queries per second, translating to approximately 2 trillion global searches each year1. Given the dominant role of search engines in facilitating information access, website owners aspire to gain increased visibility on these platforms, whether for the consumption of their textual content or the purchase of products offered on their websites (Berman and Katona 2013, Jansen et al. 2008).\nHowever, the search engine landscape is currently experiencing a paradigmatic shift owing to the emergence of Large Language Models (LLMs) and associated applications, especially those based on Retrieval Augmented Generation (RAG). On November 30, 2022, OpenAI introduced ChatGPT, a tool designed to address user queries in a conversational manner. Subsequently, Microsoft incorporated GPT-4 into its search engine, culminating in the debut of New Bing on February 7, 20232. This iteration of Bing integrates a chatbot, hereafter referred to as Bing Chat3, enabling online searches and the delivery of responses in comprehensive natural language. Concurrently, on March 21, 2023, Google commenced experimental trials of its chatbot-enhanced search engine, Bard, which has seen its monthly user base surpass 142 million as of early 20244. This novel category of chatbots, exemplified by Bing Chat and Bard, merges search engine capabilities with LLM-based generative artificial intelligence (AI), and are hence termed \u201cchat-based search engines\u201d. In contrast, their predecessors are hereafter denoted as \u201cconventional search engines\u201d. \u2217 These authors contributed equally to the manuscript and are listed alphabetically. \u2020 Corresponding author 1 See https://serpwatch.io/blog/search-engine-statistics/. 2 See https://techcrunch.com/2023/03/14/microsofts-new-bing-was-using-gpt-4-all-along/. 3 It is now part of Microsoft Copilot. See https://copilot.microsoft.com/ 4 See https://www.demandsage.com/google-bard-statistics/.\ninitiate their process by comprehending the query, subsequently assimilating information from pertinent websites, and ultimately delivering a coherent response that integrates references to multiple websites for substantiation, during which they demonstrate human-like metacognitive skills, including the acquisition of new knowledge and the demonstration of creativity. Nevertheless, the \u201ccognitive\u201d procedure through which the chatbot discerns pertinent information and formulates the final responses remains largely inscrutable, attributed to the complexity of its foundational model. As the parameter size of LLMs increases, elucidating the mechanism becomes increasingly unfeasible, even for the system\u2019s architects (Kosinski 2023). Delving into this machine-driven creative process is not only of scientific intrigue but also bears significant economic implications. Prior research in the realm of search engines has shed light on the considerable impact of search engine visibility on both the decision-making processes of individuals (Gong et al. 2018, Ghose et al. 2014) and the distribution of welfare among stakeholders within an economic equilibrium (Berman and Katona 2013). Within this novel search paradigm, the visibility of a website hinges on its citation by the chatbot. As chat-based search engines evolve and enhance their ability to modulate users\u2019 exposure to diverse websites5, the economic ramifications can escalate correspondingly.\nHistorically, conventional search engines also intentionally introduce opacity to their ranking algorithms, serving as a deterrent against manipulation by website proprietors. This obscurity, juxtaposed with the economically pivotal role of visibility through search engines, has given rise to the domain of Search Engine Optimization (SEO). SEO endeavors to decode the myriad factors that influence website standings within search engine results, aiming to tailor content to enhance its visibility (Reisenbichler et al. 2022, Danaher et al. 2006). Nonetheless, these insights pertaining to the ranking criteria of conventional search engines may not be directly applicable to comprehending the citation criteria of chat-based search engines, given their distinct attributes. To begin with, leading LLMs, such as those within the GPT series, are constructed using a human-in-theloop methodology, wherein human evaluators determine the optimal responses to specific queries 5 See https://www.demandsage.com/google-gemini-statistics/.\nlinguistic styles (Guo et al. 2023), potentially influencing their source preferences during information retrieval tasks. Furthermore, when referencing websites, LLMs must choose suitable textual content. However, LLMs demonstrate varied levels of understanding for different text types, typically evaluated through perplexity metrics (Gonen et al. 2022). This disparity in comprehension may also shape their preferences in the source selection process. Given such inherent uncertainties, we posit our first research question.\nRQ1: How do chat-based search engines select websites to cite in response to a query? In order to address our first research question, we procure an extensive dataset by executing queries on New Bing and harvesting responses via Bing Chat (the chat-based interface), alongside the websites referenced therein and those listed by Bing (its conventional counterpart). Following a sequence of preprocessing and text mining procedures, we conduct a comparative analysis of the linguistic characteristics of websites cited within Bing Chat\u2019s responses against those that are not cited. Our findings indicate that the chat-based search engine exhibits a preference for source content that is more readable and analytical, while demonstrating lower levels of polarity and a reduced conversational tone. Furthermore, our analysis reveals a noteworthy trend: content deemed more \u201creadable\u201d by GPT, as quantified by perplexity scores, is more likely to be cited in support of the responses. This suggests the possibility that the criteria for citation are influenced by the characteristics of the underlying LLM, rather than being exclusively determined by the New Bing engineers.\nNonetheless, it is conceivable that these criteria may be derived from the conventional search engine engine, especially considering that Bing Chat initiates its process by first identifying relevant websites prior to learning and generating responses6. Prior investigations into conventional search engines have unveiled distinct linguistic predilections within their ranking algorithms (Reisenbichler et al. 2022). Should Bing Chat predominantly extract information from websites that are highly\n6 See https://www.microsoft.com/en-us/bing/do-more-with-ai/how-bing-chat-works.\nperpetuated, thus confounding the distinct preferences attributable to the foundational LLM. To discount this alternative explanation and gain a comprehensive understanding of how chat-based search engines diverge from traditional ranking algorithms, we propose our second research question.\nRQ2: How do the selection criteria employed by chat-based search engines diverge from the ranking\ncriteria utilized by conventional search engines?\nUtilizing the same dataset, we investigate the ranking criteria employing an identical set of variables. Our findings reveal that, while there are similarities between the ranking criteria of Bing Chat\u2019s citation process (such as readability), significant differences also exist in terms of other linguistic styles (e.g., certitude) and perplexity. These outcomes again underscore the distinct nature of chat-based search engines.\nWhile our perplexity analysis hints at the influence of the foundational LLM on specific criteria, it remains uncertain whether these criteria are the product of deliberate design choices by Bing Chat\u2019s designers, akin to the dynamic anti-gaming measures employed in traditional ranking algorithms. However, compared with these traditional counterparts, the LLM used for chat-based search engines poses a greater challenge for manual design. Existing literature underscores that LLMs can manifest unforeseen behaviors once the scale of their parameters surpasses certain thresholds, with the underpinnings of these emergent phenomena eluding even the models\u2019 creators (Wei et al. 2022a, Kosinski 2023). In light of these considerations, we advance our third research question.\nRQ3: Do chat-based search engine\u2019s criteria originate through manual curation or naturally emerge\nfrom underlying language models?\nTo address this research inquiry, we delve into the information retrieval and content creation processes executed by Bing Chat\u2019s foundational model, GPT-4, with a direct examination. Should the predilection for sourcing citation texts be attributed to the intrinsic model, analogous trends are expected to manifest in scenarios utilizing GPT-4 for Retrieval Augmented Generation (RAG). In pursuit of this objective, we gather an additional dataset through the use of OpenAI\u2019s knowledge\ning our examination of the citation criteria within this RAG context, we uncover that the criteria employed by the GPT-4 based RAG are qualitatively aligned with those observed in Bing Chat. This consistency further suggests that the citation preferences of Bing Chat are derived from the LLM\u2019s inherent capabilities, rather than being artificially engineered by the search engine\u2019s developers. Furthermore, the texts cited by RAG API demonstrate greater similarities when compared with the top-ranked websites presented by conventional search engines. The disparity provides another intriguing yet justifiable distinctiveness of the LLM-based information retrieval, given its responsibility for furnishing a singular coherent response, thereby requiring an elevated level of information congruity.\nIn the subsequent sections of this paper, we integrate relevant literature and highlight our theoretical contributions in Section 2. Section 3 describes our methodology for data acquisition and the construction of variables. Section 4 presents our data analysis, addressing each research question sequentially. Finally, Section 5 concludes with a discussion on practical implications and suggests directions for future research."
        },
        {
            "heading": "2. Related Literature",
            "text": "Our research builds on and contributes to three streams of literature: i) AI Performance, AI Metacognition, and AI Alignment; ii)search engine ranking, optimization, and marketing; iii) information retrieval with generative AI."
        },
        {
            "heading": "2.1. AI Performance, AI Metacognition, and AI Alignment",
            "text": "Broadly speaking, our paper is related to the research on AI performance, AI metacognition, and AI alignment, especially for LLM-based generative AI and related applications.\nGiven the intricate architecture of LLM-based generative AI, the output and performance of such models is not entirely predictable by their designers. Particularly when the models scale up to a high number of parameters, they begin to exhibit emergent capabilities, which include unanticipated enhancements in performance on novel tasks, as discussed in the literature (Kosinski 2023, Johnston\ndevising novel metrics, tasks, and methodologies to comprehensively assess the efficacy of generative AI across various dimensions (Zhao et al. 2023). For instance, Wang et al. (2022) compiles an extensive list of over 1,600 NLP tasks to evaluate the adaptability of universal language models.\nMore interestingly, recent advancements in LLMs have notably highlighted their potential in paving the way toward Artificial General Intelligence (AGI). According to a classification proposed by Google DeepMind, AI systems can be segmented into ten diverse categories, evaluated across five performance levels (emerging, competent, expert, virtuoso, or superhuman) and categorized by their breadth of application (narrow or general) (Morris et al. 2023). Although earlier iterations of AI have evolved from rudimentary rule-based systems to highly advanced entities exemplified by AlphaFold Jumper et al. (2021), they are predominantly narrow in their focus and designed for specific tasks. In stark contrast, current generative AI models based on LLMs, like ChatGPT and Llama 2, demonstrate a broad spectrum of metacognitive capabilities, including the acquisition of new skills and creativity (Morris et al. 2023). Motivated by these developments, scholars are now endeavoring to dissect the inherent cognitive processes of AI, such as personality and rationality (Mei et al. 2024, Chen et al. 2023b, Wang et al. 2023), and to utilize AI\u2019s cognitive functions in simulating human responses (Brand et al. 2023, Horton 2023).\nAs AI systems exhibit increasingly sophisticated cognitive capabilities and the capacity for creativity that surpasses human expectations, the concept of AI alignment has garnered heightened scrutiny (Gabriel 2020). The objective of AI alignment is to ensure that AI systems act in accordance with human intentions and values, promoting robustness, interpretability, controllability, and ethicality in AI (Ji et al. 2023). Throughout the development and application of Large Language Models (LLMs), alignment principles are integrally applied. For instance, during the development phase, Reinforcement Learning from Human Feedback (RLHF) is employed to align AI with human\u2019s goals (Ouyang et al. 2022). Subsequent to model development, AI outputs and their underlying mechanisms undergo evaluation and interpretation (Gilpin et al. 2018). Moreover, Red Teaming\ndeployment of AI systems, it is imperative from a societal alignment perspective to assess the systems\u2019 impacts on the broader society (Korinek and Balwit 2022). Within this expansive framework, previous research into the economics of AI can be subsumed under AI alignment, such as studies on the effects of Generative AI on labor markets (Liu et al. 2023a, Hui et al. 2023), social communities (Borwankar and Khern-am nuai 2023, Xue et al. 2023), and software development (Peng et al. 2023, Dohmke et al. 2023).\nPursuant to this line of inquiry, our paper delves into the creative process underpinning the responses of chat-based search engines, assessing their outputs via an array of textual characteristics. Beyond identifying the distinct textual predilections of chat-based search engines, our study furnishes empirical support for the proposition that these preferences arise naturally from the foundational LLM, rather than being the product of manual curation. Furthermore, our findings elucidate potential mechanisms by which chat-based search engines may wield economic influence, specifically through their unique exposure allocation processes based on textual preferences, coupled with a reduction in information diversity. 2.2. Search Engine Ranking, Optimization, and Marketing In terms of the application context, our inquiry also contributes to the extensive academic discourse on search engine rankings, optimization, and marketing. This body of work is multifaceted, encompassing a diverse array of subtopics.\nPrimarily, certain studies concentrate on the commercial values of search engine rankings and advertisements. These investigations endeavor to decode consumer reactions to search advertisements, examining phenomena such as rank-order effects, and to evaluate the efficacy of such advertisements (Ghose et al. 2014, Goldfarb and Tucker 2011, Ghose and Yang 2009). In addition, there is scholarly effort dedicated to elucidating the dynamics between various modes of information acquisition for consumers, such as organic versus sponsored searches (Yang and Ghose 2010), generic versus branded searches (Rutz and Bucklin 2011), and the utilization of search engines in conjunction with social media platforms (Ghose et al. 2019).\nthe perspective of website proprietors (advertisers). It has been proposed that entities positioned at the pinnacle of organic search results may experience a reduction in their motivation to compete for sponsored clicks (Katona and Sarvary 2010). Furthermore, modeling such competition among websites also necessitates the consideration of the actions of consumers and search engines, such as the search engine\u2019s incentive to prioritize low-quality websites to maximize its advertising revenue (Athey and Ellison 2011, Xu et al. 2011, 2012). Berman and Katona (2013) presents a framework that examines the impact of Search Engine Optimization (SEO) on the competitive landscape among advertisers and the resulting welfare for visitors, advertisers, and the search engine.\nFinally, given the significance of search engine ranking, scholars also seek to employ techniques to comprehend and enhance website exposure. For organic search, previous research tends to investigate factors that can influence website ranking and subsequently optimize website content accordingly (Reisenbichler et al. 2022, Erdmann et al. 2022, Ziakis et al. 2019, Su et al. 2014, Danaher et al. 2006). Regarding sponsored search, scholars concentrate on optimizing websites\u2019 keyword auction strategies to maximize revenue while adhering to specific constraints in a competitive environment (Liu and Toubia 2018, Du et al. 2017, Shin 2015, Abhishek and Hosanagar 2013, Liu et al. 2010).\nOur investigation principally situates itself within the last stream of literature, as it too aims to elucidate the determinants influencing the content selection mechanism of search engines. Specifically, our study concentrates on the nascent domain of chat-based search engines, analyzing the criteria they employ to select websites for citation and how these criteria diverge from those of conventional search engines\u2019 ranking algorithms. This differentiation could engender a novel competitive environment owing to the unique traffic channel these chat-based search engines direct toward websites. Such an evolution also necessitates consideration in future SEO and platform strategies for both researchers and industry experts. 2.3. Information Retrieval with Generative AI More specifically, our research further intersects with the rapidly expanding domain concerning information retrieval facilitated by generative AI. Despite the longstanding history of information\ngenerative AI and its associated applications are revolutionizing information retrieval processes. Consequently, scholars are endeavoring to design and evaluate the information retrieval techniques in this new context.\nOn the design side, the advent of LLM-based generative AI heralds a significant shift\u2014or potentially a paradigmatic transformation\u2014in the domain of information retrieval. These generative AI systems, trained on extensive datasets, are capable of delivering substantiated responses to queries, thereby facilitating direct access to information encapsulated within the original training corpus (B\u00e9n\u00e9dict et al. 2023). Moreover, to embed domain-specific insights and contemporary information within these responses, designers may employ several strategies: (1) fine-tuning the LLMs with updated datasets (Hu et al. 2023); (2) leveraging retrieval-augmented generation that combines the original model with new data (Hofst\u00e4tter et al. 2023); or (3) utilizing straightforward prompt engineering techniques with the incorporation of new data (Liu et al. 2023b). Significantly, LLM-based generative AI can be instrumental across various stages of information retrieval, including query reformulation, content recall, content re-ranking, and the synthesis of content for the final output (Zhu et al. 2023). This multifaceted utility paves the way for the enhancement or creation of novel applications powered by generative AI, such as LLM-based recommendation engines and search agents (Hua et al. 2023, Nakano et al. 2021).\nRegarding the evaluation aspect, the intricacies inherent in both the foundational model and the unstructured information sources render the assessment of information retrieval techniques involving generative AI a formidable challenge. To address this, computer scientists devise an array of baseline tasks spanning multiple domains to gauge their efficiency (Chen et al. 2023a). Additionally, human evaluations are conducted to appraise the systems\u2019 outputs (Lewis et al. 2020). In certain instances, behavioral researchers engage human participants to undertake information-seeking tasks employing various information retrieval techniques, facilitating a comparative analysis of performance with human involvement (Xu et al. 2023).\nLLM-based information retrieval systems. Employing a variety of NLP techniques and metrics, this study elucidates the selection criteria employed by Bing Chat for citing websites and delineates the divergence of these criteria from those utilized by traditional search engines\u2019 ranking algorithms. More crucially, our research reveals that the observed disparities stem from the foundational large language models, rather than being artifacts manually introduced by the designers of Bing Chat. Specifically, we observe that: (1) Bing Chat exhibits a preference for content that is more readily interpretable (i.e., perplexity) by models within the GPT family; (2) the application of retrievalaugmented generation with GPT-4 demonstrates qualitative consistency in selection criteria akin to that of Bing Chat. Consequently, our research also advocates for future scholarly endeavors to adopt a more integrative approach towards the evaluation of LLM-based applications and the underlying large language models."
        },
        {
            "heading": "3. Data and Variables",
            "text": ""
        },
        {
            "heading": "3.1. Data Sources, Data Collection, and Preprocessing Procedures",
            "text": "3.1.1. Data Source 1: New Bing We source the first raw dataset from New Bing, an AI-driven search engine developed by Microsoft, officially released on February 7, 2023. In contrast to traditional methods of listing pertinent web content, hereafter denoted as \u201cconventional search engine,\u201d New Bing offers users an additional chatbot known as \u201cBing Chat\u201d which can provide consolidated responses by aggregating information from different websites7.\nFigure 1 offers a graphical depiction of the search output produced by the New Bing platform. To the left, conventional search outcomes are presented, each typically encompassing three elements: the website\u2019s title, its corresponding hyperlinks, and an excerpt from the site identified as most pertinent to the search query by the search algorithm. In juxtaposition, on the right-hand side, Bing Chat provides a composite response, integrating its pre-established knowledge database with 7 See https://www.microsoft.com/en-us/edge/features/the-new-bing.\ndialogue box\u2019s base. Among these hyperlinks, some are explicitly referenced within the composite answer, whereas others are simply enumerated without direct citation. It is noteworthy that a single sentence may reference none to multiple websites, while a singular website may also be cited in support of none to multiple sentences.\nTo commence our analysis, we first extract and randomize all queries from the Human ChatGPT Comparison Corpus (HC3), a dataset introduced by Guo et al. (2023), which is extensively utilized in subsequent Generative AI research for benchmarking and comparative studies (Zhao et al. 2023). Each query is individually inputted into the search engine, acting as the keyword for information retrieval. A subset of queries fails to generate search results, attributable to the inclusion of sensitive or prohibited content, such as hate speech or violent material. Additionally, instances where the Bing Chat fails to produce responses due to the aforementioned reasons, or presents responses devoid of citations to websites, albeit infrequent, are also classified as unsuccessful queries. Constrained by the\nyield results. We then collect the conventional search outcomes displayed on the initial two pages of\nsearch results, encompassing titles, excerpts, and hyperlinks of the websites listed. Afterwards, for\neach Bing Chat response, we gather the textual content, the hyperlinks cited within these responses,\nand any specific locational markers referencing these hyperlinks. Furthermore, we proceed to capture\nand archive the complete textual content of all websites listed by the conventional search engine or\ncited by Bing Chat, culminating in a repository of 13,428 distinct websites. To offer a foundational\nunderstanding of the dataset\u2019s hierarchical structure, we present summary statistics delineated by\nvarious levels of granularity within the raw dataset in Table 1.\nFor every query submitted, we show three variables that capture the scope of our data\ncollection: NumTotalWebs, denoting the aggregate number of websites gathered per query;\nNumCitedSentences, signifying the count of sentences within each query\u2019s response that reference\nat least one website; and NumCitedWebs, specifying the number of websites cited by at least one\nsentence in Bing Chat\u2019s responses. The value of NumCitedWebs naturally varies across different\nqueries, reflecting Bing Chat\u2019s selection criteria to substantiate its responses. It is pertinent to\nhighlight that the count of websites collected from the conventional search engine may also exhibit\nvariability, attributed to the exclusion of duplicate websites that are displayed in the first two pages\nof conventional search outcomes.\nDelving further, among the 700 responses generated by Bing Chat, a total of 2,586 sentences\nare identified that cite at least one website for reference. This observation is encapsulated in the\nvariable NumCitedWebsSent, representing the count of websites cited at the sentence level. Corre-\nspondingly, for each website, we ascertain the frequency with which it is referenced across different\nsentences, thereby defining the variable NumCitedSentencesWeb to quantify this metric.\nStatistic N Mean St. Dev. Min Median Max Query-level Statistics NumTotalWebs 700 19.18 1.18 12 20 20 NumCitedSentences 700 3.69 1.73 1 3 14 NumCitedWebs 700 3.37 1.31 1 3 10 Sentence-level Statistics NumCitedWebsSent 2,586 1.38 0.67 1 1 5 Website-level Statistics NumCitedSentencesWeb 13,428 0.27 0.68 0 0 8\nHowever, the dataset cannot be immediately employed for the investigation of Bing Chat\u2019s criteria, given that each website may comprise tens of thousands of words, with only a minor fraction being referenced to substantiate sentences in Bing Chat\u2019s responses. To find the most relevant texts, as delineated in the pseudocode Algorithm 1 and Figure 2, we undertake a series of preprocessing steps to compile dataset 1A: For every query, we pinpoint sentences within Bing Chat\u2019s response that cite at least one website. Subsequently, for each website sourced from this query, we identify the chunk exhibiting the highest similarity to each sentence with references and archive this chunk. This procedure involves dividing the websites into uniform chunks (128 characters each), employing the Universal Sentence Encoder to generate embeddings for both the sentences and all chunks from each website (Cer et al. 2018), and utilizing cosine distance to gauge their similarities. This methodology yields a query-sentence-website level dataset, where each entry corresponds to a website chunk most\n2 sentences that have citations, this results in 40 (20\u00d72) distinct entries within dataset 1A. Using this method, we get 49,917 observations in total.\nAlgorithm 1 Chunk Selection Process for Dataset 1A: Pseudocode Require: Bing Chat\u2019s Responses, Website Content\nInitialize Dataset 1A. for each query i: do\nRetrieve all the sentences that cite at least one website Ji. Retrieve all the related websites Ki. for each sentence j \u2208 Ji: do\nfor each website k \u2208Ki: do\nEmbed sentence j using Universal Sentence Encoder. Segment website k into Mk chunks of equal length. Embed all the chunks m\u2208Mk. Find the chunk m\u0302= argmaxm\u2208Mk cosine_similarity(m \u2032\u2019s embedding, j\u2019s embedding). Add i, j, k, and m\u0302\u2019s content to Dataset 1A.\nend for\nend for\nend for\nRegarding our second research question, which seeks to elucidate the ranking criteria and compare them with Bing Chat\u2019s criteria, we assemble Dataset 1B from the websites cataloged by the conventional search engine. Given that the search engine highlights one excerpt for each listed website it deems most pertinent to the search query, we employ this excerpt as the basis for our ranking analysis. To extract the original content of these excerpts, we identify the chunk that includes the excerpt for each website listed by the conventional search engine, thereby creating Dataset 1B following the\nthe 11,741 websites. This quantity is less than the total number of websites gathered (i.e., 13,428), attributable to the fact that some websites are exclusively cited by Bing Chat and do not appear in the conventional search engine listings, thus precluding our ability to ascertain their ranking.\nAlgorithm 2 Chunk Selection Process for Dataset 1B: Pseudocode Require: Excerpts, Website Content\nInitialize Dataset 1B. for each query i: do\nRetrieve all the related websites Ki. Retrieve all the corresponding excerpts Ek where k \u2208CKi, where CKi \u2286Ki contains websites\nthat are listed in the conventional search engine results of query i.\nfor each website k \u2208Ki: do\nSegment website k into Mk chunks of equal length. Find the chunk m\u0302 that has the longest common subsequence with the excerpt. Add i, k, and m\u0302\u2019s content to Dataset 2.\nend for\nend for\n3.1.2. Data Source 2: GPT4-based RAG To address our third research question, which endeavors to elucidate the origins of Bing Chat\u2019s preference for specific textual content \u2013 questioning whether it is attributable to the inherent capabilities of the LLM or the result of deliberate modifications by the search engine\u2019s developers \u2013 we propose a direct engagement with the foundational model, specifically GPT-4. OpenAI\u2019s Knowledge Retrieval API presents a viable means to accomplish this, offering the ability to systematically segment and access pertinent information from files provided by users, and to formulate responses that consider both the newly uploaded content and the pre-existing data repository8. By circumventing 8 See https://platform.openai.com/docs/assistants/tools/knowledge-retrieval.\nengine tasks, this API may more authentically reveal the underlying LLM\u2019s linguistic predispositions.\nTo achieve our research objectives, it is imperative to construct an additional dataset, labeled as Dataset 2, building upon the queries and websites acquired from the first data source. For each query, we aim to upload the content of all the relevant websites and ascertain which of these are referenced by the aforementioned RAG API in formulating its responses. This approach, however, introduces a challenge analogous to the one encountered during the assembly of datasets 1A and 1B, namely, the prohibitive length and resultant computational cost of processing all the websites entirely. Consequently, a methodology to distill a more concise segment from each website is necessitated. Adhering to Algorithm 3, we divide each of the 13,428 websites into segments of uniform length (128 tokens in this instance). Subsequently, for each website indexed by the conventional search engines, we leverage the search result excerpt to identify and extract the chunk encompassing this excerpt as the representative chunk for the website9. Conversely, if the website is exclusively cited by Bing Chat\u2014thus lacking a corresponding excerpt\u2014we utilize the sentence within Bing Chat\u2019s response that references the website as a focal sentence. The chunk bearing the highest similarity to this focal sentence, as quantified by cosine similarity between their embeddings, is then selected as the representative chunk for the website. Employing this methodology across the 13,428 websites, we successfully compile an equivalent number of corresponding chunks.\nSubsequently, for each query, a compilation of websites is gathered alongside the query itself, with an equivalent number of chunks (one per website) extracted from these sites. These chunks are then amalgamated into a singular text document for each query, which functions as the retrieval source document. Upon submitting both the query content and the corresponding source text document to the OpenAI Knowledge Retrieval API, a synthesized response, inclusive of citations, is generated10. Each citation delineates the original sentence along with its location within the submitted 9 If a website is both listed by the conventional search engine and cited by Bing Chat, we also use this method. 10 A detailed illustration of the prompt, query, and resultant outputs is provided in Appendix A.\nquently, Dataset 2 comprises 13,428 entries, each accompanied with an outcome variable indicating\nits citation status by the RAG algorithm.\nAlgorithm 3 Chunk Selection Process for Dataset 2: Pseudocode Require: Bing Chat\u2019s Responses, Excerpts, Website Content\nInitialize Dataset 2. for each query i: do\nRetrieve all the sentences that cite at least one website Ji. Retrieve all the related websites Ki. Retrieve all the corresponding excerpts Ek where k \u2208CKi, where CKi \u2286Ki contains websites\nthat are listed in the conventional search engine results of query i.\nfor each website k \u2208Ki: do\nSegment website k into Mk chunks of equal length. if website k \u2208CKi then\nFind the chunk m\u0302 that has the longest common subsequence with the excerpt.\nelse\nFind all the sentences from Ji that cite website k. Merge these sentences into a new sentence jall Embed the sentence jall using Universal Sentence Encoder. Embed all the chunks m\u2208Mk. Find the chunk m\u0302= argmaxm\u2208Mk cosine_similarity(m \u2032\u2019s embedding, jall\u2019s embedding).\nend if Add i, k, and m\u0302\u2019s content to Dataset 2.\nend for\nend for\nIn the process of assembling the aforementioned three datasets (Datasets 1A, 1B, and 2) sourced from two distinct data repositories (New Bing and OpenAI\u2019s Knowledge Retrieval API), we systematically acquire the textual content alongside the corresponding outcome variables. This section elaborates on the variables derived from these datasets and presents summary statistics for each dataset.\nWe initiate by elucidating the outcome variables associated with each dataset. In Dataset 1A, for each sentence with references, we define the set of relevant chunks from all websites as the citation consideration set. Consequently, we obtain 49,917 observations, calculated as the product of the number of sentences with references and the number of websites retrieved for each query, summed across all queries, denoted as \u2211\ni Number of Sentencesi \u00d7 Number of Websitesi. In this\ndataset, the variable Cited signifies whether a particular sentence cites the corresponding chunk, which, by extension, is equivalent to citing the website, given that a singular chunk from each website is considered. For Dataset 1B, we document 11,741 observations, where each encompasses the content of a website and its position as determined by a conventional search engine, encapsulated by the variable Rank. The content refers to the chunk within the website that contains the excerpt highlighted by the conventional search engine. In Dataset 2, consisting of 13,428 observations, each observation includes the content of a website and a variable Cited denoting whether it is cited by the RAG API. Here, the content corresponds to a chunk which either contains the excerpt (if listed by the conventional search engine) or bears resemblance to sentences within Bing Chat\u2019s responses (if not listed).\nIn addressing the research questions pertinent to the citation and ranking behaviors of different systems, we also extract various features from website content (i.e., chunks) to serve as independent variables. Since our research is anchored in the domain of search engine ranking literature, prompting the inclusion of the Readability metric, a widely recognized measure within this field (Reisenbichler et al. 2022). Readability evaluates the ease with which text can be understood by human readers. To quantify readability, we utilize the New Dale-Chall Readability Formula (Chall and Dale 1995),\na negative sign to the formula\u2019s output, whereby a higher score implies enhanced readability.\nAdditionally, given the relevance of our research to assessing the outputs of generative AI, which aims to replicate human-like text, we examine several linguistic features commonly employed in such evaluations. The Analytic variable quantifies the extent of analytical thought in the text, with higher values denoting greater logical consistency. The Subjectivity measures the propensity to favor objective over subjective content, with higher scores reflecting greater subjectivity. These variables primarily concern the informational content\u2019s logicality and objectivity.\nMoreover, we incorporate measures of expressive styles, such as Polarity, which gauges the emotional polarity (absolute value) of the text, with higher values indicating increased emotional polarization. The Certitude variable assesses the text\u2019s level of assertiveness, for instance, texts employing phrases like \"of course\" may be deemed to exhibit higher certitude. The Conversational measure evaluates the text\u2019s colloquialism, including the use of internet slang (e.g., \u201clmao\", \u201clol\") or discourse markers (e.g., \u201cum\", \u201coh\"). The calculation of Subjectivity and Polarity is facilitated through TextBlob (Loria et al. 2018), while the remaining metrics are derived using the Linguistic Inquiry and Word Count (LIWC) tool (Boyd et al. 2022).\nFinally, based on the research focus on LLM-based generative AI, we are particularly intrigued by the possibility that certain criteria might naturally emerge from these models. Of specific interest is the influence of \u201creadability\" from the perspective of language models on the content selection process. To explore this, we introduce the concept of Perplexity, which is formally defined as the exponentiated average negative log-likelihood of a sequence as predicted by a language model (Azzopardi et al. 2003). Intuitively, it can measure the extent to which a model anticipates the input content, wherein a sentence that aligns closely with the model\u2019s expectations exhibits lower perplexity, and conversely, a more unexpected sentence exhibits higher perplexity.\nFollowing the above steps, for every observation within the datasets, we derive a single outcome variable and seven independent variables, the summary statistics of which are presented\ninvestigating research questions 1, 2, and 3, respectively.\nIn this section, we systematically address each of our research questions. First, in Section 4.1, we scrutinize the criteria by which the chat-based search engine, specifically Bing Chat in our study, selects websites for inclusion in its responses. Following this, Section 4.2 delineates the ranking criteria employed by conventional search engines and contrasts them with those utilized by Bing Chat. Finally, Section 4.3 elucidates the source of citation criteria by utilizing the RAG model based on GPT-4 and juxtaposing them with those employed by Bing Chat."
        },
        {
            "heading": "4.1. Chat-based Search Engine\u2019s Content Selection Criteria",
            "text": "We initiate our exploration with the first research question, which investigates the criteria Bing Chat utilizes to select websites for substantiating its responses, employing Dataset 1A as elaborated in Section 3. For each query i, Bing Chat generates a response comprising at least one sentence that incorporates references. The crux of our analysis lies in discerning the textual predilections that predispose the selection of certain websites over others to underpin these referenced sentences. Given the voluminous content available on each website, we delineate a single relevant chunk from each website k to constitute the consideration set for a given sentence j. Consequently, Dataset 1A forms a query-sentence-website level dataset, encompassing 49,917 entries.\nThe variable of interest, Citedijk, indicates whether a chunk from website k has been referenced to support sentence j in Bing Chat\u2019s response to query i. To decipher the relationship between the textual features of a website\u2019s chunk and its likelihood of citation, we incorporate a suite of independent variables, as delineated on the right side of Equation 1. To strengthen the robustness of our results, we employ three distinct regression models: Ordinary Least Squares (OLS) regression (i.e., linear probability model), logistic regression, and probit regression.\nCitedijk =\u03b20 +\u03b21 \u2217Readabilityijk +\u03b22 \u2217Analyticijk +\u03b23 \u2217Certitudeijk+\n\u03b24 \u2217Subjectivityijk +\u03b25 \u2217Polarityijk +\u03b26 \u2217Conversationijk +\u03b27 \u2217Perplexityijk + \u03f5ijk\n(1)\nDependent variable:\nCited\nOLS Logistic Probit\n(1) (2) (3)\nReadability 0.0009\u2217\u2217\u2217 0.0110\u2217\u2217\u2217 0.0057\u2217\u2217\u2217 (0.0001) (0.0016) (0.0008) Analytic 0.0004\u2217\u2217\u2217 0.0073\u2217\u2217\u2217 0.0034\u2217\u2217\u2217 (0.0001) (0.0010) (0.0005) Certitude \u22120.0014 \u22120.0241 \u22120.0105 (0.0015) (0.0260) (0.0124) Subjectivity 0.0124 0.2084 0.0927 (0.0109) (0.1618) (0.0790) Polarity \u22120.0240\u2217 \u22120.3874\u2217 \u22120.1689\u2217 (0.0133) (0.2118) (0.1022) Conversation \u22120.0032\u2217\u2217 \u22120.0637\u2217\u2217 \u22120.0311\u2217\u2217 (0.0014) (0.0324) (0.0154) Perplexity \u22120.0302\u2217\u2217\u2217 \u22120.4185\u2217\u2217\u2217 \u22120.2082\u2217\u2217\u2217 (0.0036) (0.0477) (0.0240) Constant 0.2030\u2217\u2217\u2217 \u22120.9414\u2217\u2217\u2217 \u22120.6306\u2217\u2217\u2217 (0.0184) (0.2560) (0.1254)\nObservations 49,917 49,917 49,917\nNote: Robust standard errors in parentheses; *** p < 0.01, ** p < 0.05, * p < 0.1\nThe regression outcomes, as presented in Table 5, manifest consistency across the three employed models, underscoring robust findings. First, congruent with prior literature on search engines (Reisenbichler et al. 2022), chat-based search engines also exhibit a preference for content that is more readily comprehensible (\u03b21 > 0, p < 0.01). Additionally, Bing Chat demonstrate a proclivity for content characterized by higher degrees of logical reasoning and analytical thought (\u03b22 > 0, p < 0.01). Beyond these preferences more related to substantive information, Bing Chat also displays discernible inclination regarding stylistic attributes of content. Specifically, there is a tendency to reference websites manifesting reduced emotional polarity and a lower degree of conversationality (\u03b25 < 0, \u03b26 < 0), signaling a preference for more logical and formal expressions.\nnificantly lower perplexity scores (\u03b27 < 0, p < 0.01). Given that perplexity serves as a measure of text predictiveness from the perspective of the language model, this trend suggests an inclination towards sourcing content that resonates more closely with the foundational language model\u2019s training corpus. This also implies that the textual preferences exhibited by chat-based search engines may not be manually curated but rather emerge spontaneously from the underlying large language model, which is trained on extensive datasets."
        },
        {
            "heading": "4.2. Comparison with Conventional Search Engines",
            "text": "In the previous subsection, we delineate the selection criteria employed by Bing Chat for citing content in support of its responses. The objective of this subsection is to elucidate the ranking criteria utilized by conventional search engines, employing Dataset 1B for this purpose, and to undertake a comparative analysis with the criteria observed in Bing Chat. From a total collection of 13,428 websites, 11,741 are indexed by the conventional search engine and thus included in our analysis. This dataset also encompasses the websites that are both cited by Bing Chat and listed by the conventional search engine.\nFor each website k listed by the conventional search engine in response to query i, we identify the chunk containing the excerpt highlighted by the engine for our ranking analysis. The dependent variable, Rankik, signifies the rank position of website k within the conventional search engine results for query i. Notably, the ranking system commences at one, with lower values indicating superior rank positions. Following the same logic, we extract an identical set of independent variables for each website\u2019s chunk, as incorporated in the regression model delineated in Equation 2. The ordered logit and ordered probit regression models are employed to ascertain the impact of these independent variables on the websites\u2019 ranking outcomes.\nRankik =Thresholds+\u03b21 \u2217Readabilityik +\u03b22 \u2217Analyticik +\u03b23 \u2217Certitudeik+\n\u03b24 \u2217Subjectivityik +\u03b25 \u2217Polarityik +\u03b26 \u2217Conversationik +\u03b27 \u2217Perplexityik + \u03f5ik (2)\nDependent variable:\nRank\nOrdered Logit Ordered Probit\n(1) (2)\nReadability \u22120.0035\u2217\u2217 \u22120.0018\u2217\u2217 (0.0018) (0.0010) Analytic 0.0004 0.0001 (0.0008) (0.0005) Certitude \u22120.0412\u2217\u2217 \u22120.0247\u2217\u2217 (0.0208) (0.0124) Subjectivity 0.1841 0.1053 (0.1504) (0.0869) Polarity 0.1886 0.1619 (0.1823) (0.1062) Conversation 0.0690\u2217\u2217 0.0409\u2217\u2217 (0.0280) (0.0170) Perplexity \u22120.0512 \u22120.0240 (0.0457) (0.0266)\nObservations 11,741 11,741\nNote: Robust standard errors in parentheses; *** p < 0.01, ** p < 0.05, * p < 0.1\nGiven that a higher rank value corresponds to a lower priority within the ranking system, it necessitates an inverse interpretation of the coefficients. As evidenced in Table 6, there are some observed similarities in preference between the conventional and chat-based search engines. Specifically, conventional search engines also favor websites characterized by greater readability (\u03b21 < 0, p < 0.01) and those exhibiting a less conversational tone (\u03b26 > 0, p < 0.05). However, contrary to Bing Chat, there is no discernible preference for content imbued with analytical elements or content with diminished emotional polarity. Moreover, the conventional search engine demonstrates a preference for content with a higher degree of certitude (\u03b23 < 0, p < 0.05), a tendency not mirrored by the chat-based counterpart. Notably, the analysis reveals no significant correlation between perplexity and ranking, further highlighting the distinctiveness of LLM-based, chat-based search engines.\nthe imperative to revisit and reevaluate search engine research, particularly as this novel form of\ninformation retrieval continues to gain prominence."
        },
        {
            "heading": "4.3. Criteria Foundation Exploration via Retrieval-Augmented Generation",
            "text": "In the preceding two subsections, we have identified distinctive selection criteria employed by the\nchat-based search engine, which notably diverges from the criteria of conventional search engine\nrankings. Intriguingly, Bing Chat\u2019s preference for content exhibiting lower perplexity intimates that\nsuch uniqueness may originate from the foundational large language model (specifically, GPT-4 in\nthis study) rather than being deliberately programmed by New Bing\u2019s designers. Should this be the\ncase, similar text selection criteria are anticipated to be observable during direct interactions with\nGPT-4 as well.\nTo further investigate this hypothesis and address our third research question, we compile Dataset\n2 by utilizing OpenAI\u2019s knowledge retrieval API. This process entails the submission of queries\nalongside documents containing segments of content from various websites (the methodology for\nwhich is detailed in Section 3.1.2). The API\u2019s response, which includes references to specific segments\nof the document, enables us to ascertain whether the content from website k is cited in response\nto query i. The outcome variable Citeik is thus defined. Analogous to the approach outlined in the\nprevious subsections, we employ the same spectrum of textual features extracted from the website\nchunks as independent variables. The analysis also encompasses three regression models (Linear\nprobability, Logistic, and Probit regressions) with the specification summarized in Equation 3.\nCitedik =\u03b20 +\u03b21 \u2217Readabilityik +\u03b22 \u2217Analyticik +\u03b23 \u2217Certitudeik+\n\u03b24 \u2217Subjectivityik +\u03b25 \u2217Polarityik +\u03b26 \u2217Conversationik +\u03b27 \u2217Perplexityik + \u03f5ik (3)\nas isolated entities. Nonetheless, the similarity of content across websites constitutes a significant\ndimension for evaluating search engine outputs. As underscored in previous studies (Reisenbichler\net al. 2022), content similarity can offer insights into the diversity of information made available to\nusers and elucidate the exposure relationship among various websites. This metric assumes greater\nrelevance in the context of chat-based search engines, which are tasked with providing a singular\nanswer that references multiple supporting websites, thereby creating an indirect linkage among\nthese sites through the response. Hence, in addition to website-level textual disparities, chat-based\nsearch engines may also exhibit unique \u201cmarket-level\u201d content similarities.\nEmploying Dataset 2, our investigation extends to the analysis of content similarity among web-\nsites cited through the RAG process in contrast to those ranked highly by traditional search engines.\nFor each query i involving citations from Ni websites, we calculate the mean cosine similarity among the embeddings of these cited sites. In a parallel fashion, for the top Ni websites as per conventional search rankings, their average cosine similarities are computed. Out of 700 queries, 607 that feature\nat least two citations during the RAG process are selected for this similarity analysis, resulting in\ntwo sets of 607 similarity metrics\u2014one derived from RAG-cited websites and the other from websites\ntop-ranked by conventional search engines. A t-test between these datasets unveils a notable finding:\nwebsites cited by RAG display a higher degree of similarity compared to those in the top-ranked\ngroup by traditional search engines (t\u2212 stats= 5.32, p < 0.01), with the former\u2019s mean similarity\nat 0.570 (std= 0.117) and the latter\u2019s at 0.533 (std= 0.128).\nThus, in addition to distinctive criteria based on textual features at the individual website level,\napplications through RAG also manifest a reduction in information diversity among cited websites\nrelative to an equivalent number of top-ranked websites. These findings collectively underscore\nthe unique operational mechanisms and outputs of chat-based search engines, underscoring the\nimperative for revised industry practices and further research inputs.\nWith the advent of LLMs, a novel chat-based search engine paradigm has been introduced, leveraging LLMs to assimilate information from web sources and articulate responses in natural language, thereby exhibiting human-like cognitive faculties such as information assimilation and the generation of novel content. In pursuit of delineating the criteria for information selection and the foundational principles thereof, this study compiled two datasets through engagements with New Bing and the Knowledge Retrieval API powered by GPT-4. Our findings elucidate Bing Chat\u2019s inclination for content that is not only readable, formal, and logical but also exhibits lower perplexity, indicating a preference for text congruent with the anticipations of the underlying LLM. This preference is not adequately elucidated by traditional search engine ranking algorithms, underscoring the distinctive nature of chat-based search engine outputs. Additionally, through the employment of an ancillary dataset acquired via the RAG API, our research substantiates a consistent textual preference that aligns between the RAG API and Bing Chat, suggesting that these preferences are inherent to the language models rather than being explicitly configured by Bing Chat developers. Beyond the aforementioned website-level distinctions, our investigation discerns a greater similarity among websites referenced by RAG technologies vis-\u00e0-vis those prioritized by conventional search engines, signaling a broader market-level uniqueness.\nOur research intersects with and contributes to multiple domains within the scholarly literature. Predominantly, our study falls into the AI alignment framework, which emphasizes the interpretation of AI systems\u2019 behavior. We enhance this body of work by assessing the distinctive outputs generated by a LLM-based AI system and delineating the mechanisms driving these outputs. More specifically, our investigation not only reveals how chat-based search engines reference websites based on textual characteristics, but also furnishs evidence that such selection criteria are influenced by the foundational LLM. This insight extends the literature on evaluating information retrieval systems powered by generative AI. Additionally, we underscore the importance of considering both LLMbased applications and the underlying LLMs in tandem to gain a comprehensive understanding of\nthe criteria of a novel form of search engine, marking a preliminary exploration into SEO practices for chat-based search engine. We also demonstrate that the chat-based search engine\u2019s imperative to deliver coherent responses, as opposed to simply listing websites, reduces the information diversity among highly visible websites. This observation may inform future economic analyses within the search engine ecosystem.\nOur study is not merely of scientific interest but also offers substantive insights for a diverse array of stakeholders. For developers of LLM-based RAG systems, including chat-based search engines, direct interaction with the underlying model is advised. This approach allows for a nuanced understanding of behaviors potentially attributed to the foundational LLM, enhancing system testing and refinement. Similarly, this holds significance for SEO professionals and website proprietors aiming to amplify their visibility within chat-based search engine results. By engaging directly with the LLM, they can fine-tune and evaluate their content prior to website updates. Furthermore, given the chat-based search engine\u2019s response format, it could be beneficial to optimize for compatibility with frequently cited websites. Users, on the other hand, should be cognizant of the limited information diversity inherent to chat-based search engine\u2019s responses, necessitating a balance between search efficiency and the breadth of information. Furthermore, the coexistence of chat-based and traditional search engines necessitates adaptive behavior from both website owners and users, given the distinct criteria of each search modality. This dynamic introduces additional market complexities, urging market administrators and regulatory bodies to re-evaluate market designs, such as auction mechanisms, to facilitate information dissemination and balance stakeholder welfare effectively.\nAbhishek V, Hosanagar K (2013) Optimal bidding in multi-item multislot sponsored search auctions. Oper-\nations Research 61(4):855\u2013873.\nAthey S, Ellison G (2011) Position auctions with consumer search. The Quarterly Journal of Economics\n126(3):1213\u20131270.\nAzzopardi L, Girolami M, Van Risjbergen K (2003) Investigating the relationship between language model\nperplexity and ir precision-recall measures. Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval, 369\u2013370.\nB\u00e9n\u00e9dict G, Zhang R, Metzler D (2023) Gen-ir@ sigir 2023: The first workshop on generative information\nretrieval. Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, 3460\u20133463.\nBerman R, Katona Z (2013) The role of search engine optimization in search marketing. Marketing Science\n32(4):644\u2013651.\nBorwankar S, Khern-am nuai W (2023) Unraveling the impact: An empirical investigation of chatgpt\u2019s\nexclusion from stack overflow. Available at SSRN 4481959 .\nBoyd RL, Ashokkumar A, Seraj S, Pennebaker JW (2022) The development and psychometric properties of\nliwc-22. Austin, TX: University of Texas at Austin 1\u201347.\nBrand J, Israeli A, Ngwe D (2023) Using gpt for market research. Available at SSRN 4395751 .\nCer D, Yang Y, Kong Sy, Hua N, Limtiaco N, John RS, Constant N, Guajardo-Cespedes M, Yuan S, Tar C,\net al. (2018) Universal sentence encoder for english. Proceedings of the 2018 conference on empirical methods in natural language processing: system demonstrations, 169\u2013174.\nChall JS, Dale E (1995) Readability revisited: The new Dale-Chall readability formula (Brookline Books).\nChen J, Lin H, Han X, Sun L (2023a) Benchmarking large language models in retrieval-augmented generation.\narXiv preprint arXiv:2309.01431 .\nChen Y, Liu TX, Shan Y, Zhong S (2023b) The emergence of economic rationality of gpt. arXiv preprint\narXiv:2305.12763 .\nanalysis. Journal of Marketing Research 43(2):182\u2013194.\nDohmke T, Iansiti M, Richards G (2023) Sea change in software development: Economic and productivity\nanalysis of the ai-powered developer lifecycle. arXiv preprint arXiv:2306.15033 .\nDu X, Su M, Zhang X, Zheng X (2017) Bidding for multiple keywords in sponsored search advertising:\nKeyword categories and match types. Information Systems Research 28(4):711\u2013722.\nErdmann A, Arilla R, Ponzoa JM (2022) Search engine optimization: The long-term strategy of keyword\nchoice. Journal of Business Research 144:650\u2013662.\nGabriel I (2020) Artificial intelligence, values, and alignment. Minds and machines 30(3):411\u2013437.\nGanguli D, Lovitt L, Kernion J, Askell A, Bai Y, Kadavath S, Mann B, Perez E, Schiefer N, Ndousse K,\net al. (2022) Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned. arXiv preprint arXiv:2209.07858 .\nGhose A, Ipeirotis PG, Li B (2014) Examining the impact of ranking on consumer behavior and search\nengine revenue. Management Science 60(7):1632\u20131654.\nGhose A, Ipeirotis PG, Li B (2019) Modeling consumer footprints on search engines: An interplay with social\nmedia. Management Science 65(3):1363\u20131385.\nGhose A, Yang S (2009) An empirical analysis of search engine advertising: Sponsored search in electronic\nmarkets. Management science 55(10):1605\u20131622.\nGilpin LH, Bau D, Yuan BZ, Bajwa A, Specter M, Kagal L (2018) Explaining explanations: An overview\nof interpretability of machine learning. 2018 IEEE 5th International Conference on data science and advanced analytics (DSAA), 80\u201389 (IEEE).\nGoldfarb A, Tucker C (2011) Online display advertising: Targeting and obtrusiveness. Marketing Science\n30(3):389\u2013404.\nGonen H, Iyer S, Blevins T, Smith NA, Zettlemoyer L (2022) Demystifying prompts in language models via\nperplexity estimation. arXiv preprint arXiv:2212.04037 .\nGong J, Abhishek V, Li B (2018) Examining the impact of keyword ambiguity on search advertising perfor-\nmance. MIS Quarterly 42(3):805\u2013A14.\nexperts? comparison corpus, evaluation, and detection. arXiv preprint arXiv:2301.07597 .\nHofst\u00e4tter S, Chen J, Raman K, Zamani H (2023) Fid-light: Efficient and effective retrieval-augmented text\ngeneration. Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, 1437\u20131447.\nHorton JJ (2023) Large language models as simulated economic agents: What can we learn from homo\nsilicus? Technical report, National Bureau of Economic Research.\nHu Z, Lan Y, Wang L, Xu W, Lim EP, Lee RKW, Bing L, Poria S (2023) Llm-adapters: An adapter family\nfor parameter-efficient fine-tuning of large language models. arXiv preprint arXiv:2304.01933 .\nHua W, Li L, Xu S, Chen L, Zhang Y (2023) Tutorial on large language models for recommendation.\nProceedings of the 17th ACM Conference on Recommender Systems, 1281\u20131283.\nHui X, Reshef O, Zhou L (2023) The short-term effects of generative artificial intelligence on employment:\nEvidence from an online labor market. Available at SSRN 4527336 .\nJansen BJ, Booth DL, Spink A (2008) Determining the informational, navigational, and transactional intent\nof web queries. Information Processing & Management 44(3):1251\u20131266.\nJi J, Qiu T, Chen B, Zhang B, Lou H, Wang K, Duan Y, He Z, Zhou J, Zhang Z, et al. (2023) Ai alignment:\nA comprehensive survey. arXiv preprint arXiv:2310.19852 .\nJohnston WJ, Fusi S (2023) Abstract representations emerge naturally in neural networks trained to perform\nmultiple tasks. Nature Communications 14(1):1040.\nJumper J, Evans R, Pritzel A, Green T, Figurnov M, Ronneberger O, Tunyasuvunakool K, Bates R, \u017d\u00eddek\nA, Potapenko A, et al. (2021) Highly accurate protein structure prediction with alphafold. Nature 596(7873):583\u2013589.\nKatona Z, Sarvary M (2010) The race for sponsored links: Bidding patterns for search advertising. Marketing\nScience 29(2):199\u2013215.\nKorinek A, Balwit A (2022) Aligned with whom? direct and social goals for ai systems. Technical report,\nNational Bureau of Economic Research.\narXiv:2302.02083 .\nLewis P, Perez E, Piktus A, Petroni F, Karpukhin V, Goyal N, K\u00fcttler H, Lewis M, Yih Wt, Rockt\u00e4schel\nT, et al. (2020) Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems 33:9459\u20139474.\nLiu D, Chen J, Whinston AB (2010) Ex ante information and the design of keyword auctions. Information\nSystems Research 21(1):133\u2013153.\nLiu J, Toubia O (2018) A semantic approach for estimating consumer content preferences from online search\nqueries. Marketing Science 37(6):930\u2013952.\nLiu J, Xu X, Li Y, Tan Y (2023a) \"generate\" the future of work through ai: Empirical evidence from online\nlabor markets. arXiv preprint arXiv:2308.05201 .\nLiu P, Yuan W, Fu J, Jiang Z, Hayashi H, Neubig G (2023b) Pre-train, prompt, and predict: A systematic\nsurvey of prompting methods in natural language processing. ACM Computing Surveys 55(9):1\u201335.\nLoria S, et al. (2018) textblob documentation. Release 0.15 2(8):269.\nMcLuhan M (1964) Understanding Media: The Extensions of Man (Routledge).\nMei Q, Xie Y, Yuan W, Jackson MO (2024) A turing test of whether ai chatbots are behaviorally similar to\nhumans. Proceedings of the National Academy of Sciences 121(9):e2313925121.\nMorris MR, Sohl-dickstein J, Fiedel N, Warkentin T, Dafoe A, Faust A, Farabet C, Legg S (2023) Levels of\nagi: Operationalizing progress on the path to agi. arXiv preprint arXiv:2311.02462 .\nNakano R, Hilton J, Balaji S, Wu J, Ouyang L, Kim C, Hesse C, Jain S, Kosaraju, et al. (2021) Webgpt:\nBrowser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 .\nOuyang L, Wu J, Jiang X, Almeida D, Wainwright C, Mishkin P, Zhang C, Agarwal S, Slama K, Ray A,\net al. (2022) Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35:27730\u201327744.\nPeng S, Kalliamvakou E, Cihon P, Demirer M (2023) The impact of ai on developer productivity: Evidence\nfrom github copilot. arXiv preprint arXiv:2302.06590 .\nnatural language generation. Marketing Science 41(3):441\u2013452.\nRutz OJ, Bucklin RE (2011) From generic to branded: A model of spillover in paid search advertising.\nJournal of Marketing Research 48(1):87\u2013102.\nSch\u00fctze H, Manning CD, Raghavan P (2008) Introduction to information retrieval, volume 39 (Cambridge\nUniversity Press Cambridge).\nShin W (2015) Keyword search advertising and limited budgets. Marketing Science 34(6):882\u2013896.\nSinghal A, et al. (2001) Modern information retrieval: A brief overview. IEEE Data Eng. Bull. 24(4):35\u201343.\nSu AJ, Hu YC, Kuzmanovic A, Koh CK (2014) How to improve your search engine ranking: Myths and\nreality. ACM Transactions on the Web (TWEB) 8(2):1\u201325.\nWang W, Pei S, Sun T (2023) Unraveling generative ai from a human intelligence perspective: A battery of\nexperiments. Available at SSRN 4543351 .\nWang Y, Mishra S, Alipoormolabashi P, Kordi Y, Mirzaei A, Arunkumar A, Ashok A, Dhanasekaran AS,\nNaik A, Stap D, et al. (2022) Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks. arXiv preprint arXiv:2204.07705 .\nWei J, Tay Y, Bommasani R, Raffel C, Zoph B, Borgeaud S, Yogatama D, Bosma M, Zhou D, Metzler D,\net al. (2022a) Emergent abilities of large language models. arXiv preprint arXiv:2206.07682 .\nWei J, Wang X, Schuurmans D, Bosma M, Chi E, Le Q, Zhou D (2022b) Chain of thought prompting elicits\nreasoning in large language models. arXiv preprint arXiv:2201.11903 .\nXu L, Chen J, Whinston A (2011) Price competition and endogenous valuation in search advertising. Journal\nof marketing Research 48(3):566\u2013586.\nXu L, Chen J, Whinston A (2012) Effects of the presence of organic listing in search advertising. Information\nSystems Research 23(4):1284\u20131302.\nXu R, Feng Y, Chen H (2023) Chatgpt vs. google: A comparative study of search performance and user\nexperience. arXiv preprint arXiv:2307.01135 .\nXue J, Wang L, Zheng J, Li Y, Tan Y (2023) Can chatgpt kill user-generated q&a platforms? Available at\nSSRN 4448938 .\nPositive, negative, or zero interdependence? Marketing science 29(4):602\u2013623.\nZhao WX, Zhou K, Li J, Tang T, Wang X, Hou Y, Min Y, Zhang B, Zhang J, Dong Z, et al. (2023) A survey\nof large language models. arXiv preprint arXiv:2303.18223 .\nZhu Y, Yuan H, Wang S, Liu J, Liu W, Deng C, Dou Z, Wen JR (2023) Large language models for information\nretrieval: A survey. arXiv preprint arXiv:2308.07107 .\nZiakis C, Vlachopoulou M, Kyrkoudis T, Karagkiozidou M (2019) Important factors for improving google\nsearch rank. Future internet 11(2):32."
        },
        {
            "heading": "Sample Prompt",
            "text": "Please answer the question based on the content in the file attached: { query content } Please answer the question with several clear references to the original files."
        },
        {
            "heading": "Sample Query",
            "text": "Why do we wear ties? Like why as in the origins, not just to look professional. Who said it made us look professional?"
        },
        {
            "heading": "Sample Answer from GPT-4 API",
            "text": "The origins of wearing ties trace back to various historical points and represent different meanings and purposes throughout history:\n- **Ancient Roots in China**: Ties, in a form akin to scarves, were worn by ancient Chinese warriors; terracotta statues that are around 2000 years old display warriors with silk around their necks, indicating that ties were a sign of power and to establish identity even in ancient times\u30107\u2020source\u3011.\n- **Croatian Mercenaries\u2019 Influence**: The tie gained popularity during the 30-year war in the 17th century when Croatian mercenaries who fought alongside King Louis XIII of France wore pieces of cloth around their neck to tie their jackets; King Louis XIII himself took a liking to this practice, which helped to popularize the accessory\u30108\u2020source\u3011.\n- **Roman Era Representation**: Soldiers depicted on Trajan\u2019s Column, a monument commemorating Roman Emperor Trajan\u2019s victory over the Dacians, are shown wearing ties as a symbol of a warrior\u2019s courageous character, providing further historical evidence of ties being associated with military and strength\n\u30109\u2020source\u3011.\n- **Elitism and Professionalism**: In Victorian England, guidelines on how to properly wear and tie a necktie emerged, such as the advice found in the book \"Clothes And The Man,\" which could imply a sense of professionalism and elitism associated with the proper way to wear a tie\u301010\u2020source\u3011.\n- **Designer Trends in the 1920s**: The modern notion of the tie as a professional and decorative accessory might be traced to the 1920s, where French fashion designers innovated the \"designer tie\" utilizing expensive fabrics and textile patterns to create stylish and coveted pieces\u301011\u2020source\u3011.\nfication to part of military uniform, and finally into a sophisticated fashion item that carries connotations of professionalism, status, and social identity. The tradition of wearing ties has been influenced by various cultures and periods, eventually leading to the contemporary association of ties with professional attire.\nSample Annotations \u30107\u2020source\u3011 Quote: Ancient Chinese warriors are the first known wearers of scarves. A discovery of 2000-year-old terracotta statues shows the warriors wearing silk around their necks. This shows that even back then, ties were a sign of power and to show identity. \u30108\u2020source\u3011 Quote: During the 30 year war, Croatian mercenaries fought alongside the King in battle. To keep their jackets tied they used a piece of cloth which King Louis XIII took a strong liking to ... \u30109\u2020source\u3011 Quote: When Roman emperor Trajan defeated the Dacians, he erected a marble column to celebrate his victory. This column featured thousands of soldiers, many of whom were wearing ties, again as a symbol of a warrior\u2019s courageous character. \u301010\u2020source\u3011 Quote: When it came to bow ties, the major was very clear: \u201cOf course, no gentleman ever does wear a made-up tie.\u201d \u301011\u2020source\u3011 Quote: In the 1920s, French fashion designers innovated the \u201cdesigner tie,\u201d which was made from expensive fabrics and decorated with textile patterns."
        },
        {
            "heading": "Interpretation of the Results",
            "text": "In this interaction, we submit a query along with a document comprising chunks extracted from all the corresponding websites. The API subsequently furnishes a cohesive response, supported by four distinct references, each delineating the original portions (i.e., annotations) sourced from the uploaded document. Subsequently, we leverage these annotations to identify the websites containing these four annotations, designating them as cited websites, while categorizing the remaining websites as uncited."
        }
    ],
    "title": "Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines",
    "year": 2024
}