{
    "abstractText": "With the rapid development of smart manufacturing, edge computing-oriented microservice platforms are emerging as an important part of production control. In the containerized deployment of microservices, layer sharing can reduce the huge bandwidth consumption caused by image pulling, and chain sharing can reduce communication overhead caused by communication between microservices. The two sharing methods use the characteristics of each microservice to share resources during deployment. However, due to the limited resources of edge servers, it is difficult to meet the optimization goals of the two methods at the same time. Therefore, it is of critical importance to realize the improvement of service response efficiency by balancing the two sharing methods. This paper studies the optimal microservice deployment strategy that can balance layer sharing and chain sharing of microservices. We build a problem that minimizes microservice image pull delay and communication overhead and transform the problem into a linearly constrained integer quadratic programming problem through model reconstruction. A deployment strategy is obtained through the successive convex approximation (SCA) method. Experimental results show that the proposed deployment strategy can balance the two resource sharing methods. When the two sharing methods are equally considered, the average image pull delay can be reduced to 65% of the baseline, and the average communication overhead can be reduced to 30% of the baseline.",
    "authors": [
        {
            "affiliations": [],
            "name": "Yuxiang Liu"
        },
        {
            "affiliations": [],
            "name": "Bo Yang"
        },
        {
            "affiliations": [],
            "name": "Cailian Chen"
        },
        {
            "affiliations": [],
            "name": "Xinping Guan"
        }
    ],
    "id": "SP:13c4e5ce1ed321720f2965236fdbfebc87bb1bf4",
    "references": [
        {
            "authors": [
                "R. Wang",
                "L. Ji",
                "T. Ren",
                "S. He",
                "Z. Shi"
            ],
            "title": "A Low-latency and Interoperable Industrial Internet of Things Architecture for Manufacturing Systems",
            "venue": "2020 IEEE 18th International Conference on Industrial Informatics (INDIN). Warwick, United Kingdom: IEEE, Jul. 2020, pp. 859\u2013864.",
            "year": 2020
        },
        {
            "authors": [
                "L. Chen",
                "Z. Lu",
                "A. Xiao",
                "Q. Duan",
                "J. Wu",
                "P.C.K. Hung"
            ],
            "title": "A Resource Recommendation Model for Heterogeneous Workloads in Fog-Based Smart Factory Environment",
            "venue": "IEEE Transactions on Automation Science and Engineering, vol. 19, no. 3, pp. 1731\u20131743, Jul. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "N.C. Mendonca",
                "P. Jamshidi",
                "D. Garlan",
                "C. Pahl"
            ],
            "title": "Developing Self-Adaptive Microservice Systems: Challenges and Directions",
            "venue": "IEEE Software, vol. 38, no. 2, pp. 70\u201379, Mar. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Z. Nie",
                "K.-C. Chen"
            ],
            "title": "Hypergraphical Real-time Multi-Robot Task Allocation in a Smart Factory",
            "venue": "IEEE Transactions on Industrial Informatics, pp. 1\u20131, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Hazra",
                "P.K. Donta",
                "T. Amgoth",
                "S. Dustdar"
            ],
            "title": "Cooperative Transmission Scheduling and Computation Offloading with Collaboration of Fog and Cloud for Industrial IoT Applications",
            "venue": "IEEE Internet of Things Journal, pp. 1\u20131, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "K. Thramboulidis",
                "D.C. Vachtsevanou",
                "A. Solanos"
            ],
            "title": "Cyberphysical microservices: An IoT-based framework for manufacturing systems",
            "venue": "2018 IEEE Industrial Cyber-Physical Systems (ICPS), 2018, pp. 232\u2013239.",
            "year": 2018
        },
        {
            "authors": [
                "Z. Yang",
                "P. Nguyen",
                "H. Jin",
                "K. Nahrstedt"
            ],
            "title": "MIRAS: Modelbased Reinforcement Learning for Microservice Resource Allocation over Scientific Workflows",
            "venue": "2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS), Jul. 2019, pp. 122\u2013132.",
            "year": 2019
        },
        {
            "authors": [
                "H. Tian",
                "X. Xu",
                "T. Lin",
                "Y. Cheng",
                "C. Qian",
                "L. Ren",
                "M. Bilal"
            ],
            "title": "DIMA: Distributed cooperative microservice caching for internet of things in edge computing by deep reinforcement learning",
            "venue": "World Wide Web, Aug. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "L. Bao",
                "C. Wu",
                "X. Bu",
                "N. Ren",
                "M. Shen"
            ],
            "title": "Performance Modeling and Workflow Scheduling of Microservice-Based Applications in Clouds",
            "venue": "IEEE Transactions on Parallel and Distributed Systems, vol. 30, no. 9, pp. 2114\u20132129, Sep. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "C. Jian",
                "J. Ping",
                "M. Zhang"
            ],
            "title": "A cloud edge-based two-level hybrid scheduling learning model in cloud manufacturing",
            "venue": "International Journal of Production Research, vol. 59, no. 16, pp. 4836\u20134850, Aug. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "W. Shi",
                "J. Cao",
                "Q. Zhang",
                "Y. Li",
                "L. Xu"
            ],
            "title": "Edge Computing: Vision and Challenges",
            "venue": "IEEE Internet of Things Journal, vol. 3, no. 5, pp. 637\u2013646, Oct. 2016. JOURNAL OF LTEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 15",
            "year": 2016
        },
        {
            "authors": [
                "C. Zhang",
                "X. Liu",
                "X. Zheng",
                "R. Li",
                "H. Liu"
            ],
            "title": "FengHuoLun: A Federated Learning based Edge Computing Platform for Cyber- Physical Systems",
            "venue": "2020 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), Mar. 2020, pp. 1\u20134.",
            "year": 2020
        },
        {
            "authors": [
                "D. Merkel"
            ],
            "title": "Docker: Lightweight Linux containers for consistent development and deployment",
            "venue": "Linux Journal, vol. 2014, no. 239, p. 2:2, Mar. 2014.",
            "year": 2014
        },
        {
            "authors": [
                "B. Burns",
                "B. Grant",
                "D. Oppenheimer",
                "E. Brewer",
                "J. Wilkes"
            ],
            "title": "Borg, Omega, and Kubernetes",
            "venue": "Communications of the ACM, vol. 59, no. 5, pp. 50\u201357, Apr. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "L. Gu",
                "D. Zeng",
                "J. Hu",
                "H. Jin",
                "S. Guo",
                "A.Y. Zomaya"
            ],
            "title": "Exploring Layered Container Structure for Cost Efficient Microservice Deployment",
            "venue": "IEEE INFOCOM 2021 - IEEE Conference on Computer Communications. Vancouver, BC, Canada: IEEE, May 2021, pp. 1\u20139.",
            "year": 2021
        },
        {
            "authors": [
                "L. Gu",
                "Q. Tang",
                "S. Wu",
                "H. Jin",
                "Y. Zhang",
                "G. Shi",
                "T. Lin",
                "J. Rao"
            ],
            "title": "N-Docker: A NVM-HDD Hybrid Docker Storage Framework to Improve Docker Performance",
            "venue": "Network and Parallel Computing, ser. Lecture Notes in Computer Science, X. Tang, Q. Chen, P. Bose, W. Zheng, and J.-L. Gaudiot, Eds. Cham: Springer International Publishing, 2019, pp. 182\u2013194.",
            "year": 2019
        },
        {
            "authors": [
                "Y. Wang",
                "C. Zhao",
                "S. Yang",
                "X. Ren",
                "L. Wang",
                "P. Zhao",
                "X. Yang"
            ],
            "title": "MPCSM: Microservice Placement for Edge-Cloud Collaborative Smart Manufacturing",
            "venue": "IEEE Transactions on Industrial Informatics, vol. 17, no. 9, pp. 5898\u20135908, Sep. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "W. Lv",
                "Q. Wang",
                "P. Yang",
                "Y. Ding",
                "B. Yi",
                "Z. Wang",
                "C. Lin"
            ],
            "title": "Microservice Deployment in Edge Computing Based on Deep Q Learning",
            "venue": "IEEE Transactions on Parallel and Distributed Systems, pp. 1\u20131, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Y. Yu",
                "J. Yang",
                "C. Guo",
                "H. Zheng",
                "J. He"
            ],
            "title": "Joint optimization of service request routing and instance placement in the microservice system",
            "venue": "Journal of Network and Computer Applications, vol. 147, p. 102441, Dec. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J.L. Herrera",
                "J. Gal\u00e1n-Jim\u00e9nez",
                "J. Berrocal",
                "J.M. Murillo"
            ],
            "title": "Optimizing the Response Time in SDN-Fog Environments for Time- Strict IoT Applications",
            "venue": "IEEE Internet of Things Journal, vol. 8, no. 23, pp. 17 172\u201317 185, Dec. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S. Deng",
                "Z. Xiang",
                "J. Taheri",
                "M.A. Khoshkholghi",
                "J. Yin",
                "A.Y. Zomaya",
                "S. Dustdar"
            ],
            "title": "Optimal Application Deployment in Resource Constrained Distributed Edges",
            "venue": "IEEE Transactions on Mobile Computing, vol. 20, no. 5, pp. 1907\u20131923, May 2021.",
            "year": 1907
        },
        {
            "authors": [
                "X. Chen",
                "Y. Bi",
                "X. Chen",
                "H. Zhao",
                "N. Cheng",
                "F. Li",
                "W. Cheng"
            ],
            "title": "Dynamic Service Migration and Request Routing for Microservice in Multi-cell Mobile Edge Computing",
            "venue": "IEEE Internet of Things Journal, pp. 1\u20131, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "E. Fadda",
                "P. Plebani",
                "M. Vitali"
            ],
            "title": "Monitoring-Aware Optimal Deployment for Applications Based on Microservices",
            "venue": "IEEE Transactions on Services Computing, vol. 14, no. 6, pp. 1849\u20131863, 2021.",
            "year": 1849
        },
        {
            "authors": [
                "P. Zhao",
                "P. Wang",
                "X. Yang",
                "J. Lin"
            ],
            "title": "Towards Cost-Efficient Edge Intelligent Computing With Elastic Deployment of Container- Based Microservices",
            "venue": "IEEE Access, vol. 8, pp. 102 947\u2013102 957, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "F. Faticanti",
                "F. De Pellegrini",
                "D. Siracusa",
                "D. Santoro",
                "S. Cretti"
            ],
            "title": "Throughput-Aware Partitioning and Placement of Applications in Fog Computing",
            "venue": "IEEE Transactions on Network and Service Management, vol. 17, no. 4, pp. 2436\u20132450, Dec. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "C.T. Joseph",
                "K. Chandrasekaran"
            ],
            "title": "IntMA: Dynamic Interaction-aware resource allocation for containerized microservices in cloud environments",
            "venue": "Journal of Systems Architecture, vol. 111, p. 101785, Dec. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "X. Li",
                "Z. Zhou",
                "C. Zhu",
                "L. Shu",
                "J. Zhou"
            ],
            "title": "Online Reconfiguration of Latency-Aware IoT Services in Edge Networks",
            "venue": "IEEE Internet of Things Journal, pp. 1\u201312, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "V. Armani",
                "F. Faticanti",
                "S. Cretti",
                "S. Kum",
                "D. Siracusa"
            ],
            "title": "A Cost- Effective Workload Allocation Strategy for Cloud-Native Edge Services",
            "venue": "arXiv:2110.12788 [cs], Oct. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "M. Sasabe",
                "T. Hara"
            ],
            "title": "Capacitated Shortest Path Tour Problem- Based Integer Linear Programming for Service Chaining and Function Placement in NFV Networks",
            "venue": "IEEE Transactions on Network and Service Management, vol. 18, no. 1, pp. 104\u2013117, Mar. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "J. Lou",
                "H. Luo",
                "Z. Tang",
                "W. Jia",
                "W. Zhao"
            ],
            "title": "Efficient Container Assignment and Layer Sequencing in Edge Computing",
            "venue": "IEEE Transactions on Services Computing, pp. 1\u20131, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "L. Gu",
                "D. Zeng",
                "J. Hu",
                "B. Li",
                "H. Jin"
            ],
            "title": "Layer Aware Microservice Placement and Request Scheduling at the Edge",
            "venue": "IEEE INFOCOM 2021 - IEEE Conference on Computer Communications. Vancouver, BC, Canada: IEEE, May 2021, pp. 1\u20139.",
            "year": 2021
        },
        {
            "authors": [
                "L. Gu",
                "Z. Chen",
                "H. Xu",
                "D. Zeng",
                "B. Li",
                "H. Jin"
            ],
            "title": "Layeraware Collaborative Microservice Deployment toward Maximal Edge Throughput",
            "venue": "IEEE INFOCOM 2022 - IEEE Conference on Computer Communications, 2022, pp. 71\u201379.",
            "year": 2022
        },
        {
            "authors": [
                "S. Wang",
                "Y. Guo",
                "N. Zhang",
                "P. Yang",
                "A. Zhou",
                "X. Shen"
            ],
            "title": "Delay- Aware Microservice Coordination in Mobile Edge Computing: A Reinforcement Learning Approach",
            "venue": "IEEE Transactions on Mobile Computing, vol. 20, no. 3, pp. 939\u2013951, Mar. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "M. Razaviyayn"
            ],
            "title": "Successive convex approximation: Analysis and applications",
            "venue": "University of Minnesota, May 2014.",
            "year": 2014
        },
        {
            "authors": [
                "S. Fu",
                "R. Mittal",
                "L. Zhang",
                "S. Ratnasamy"
            ],
            "title": "Fast and Efficient Container Startup at the Edge via Dependency Scheduling",
            "venue": "3rd USENIX Workshop on Hot Topics in Edge Computing (HotEdge 20), p. 7, 2020.",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Industrial Internet of Things (IIoT), microservice deployment, layer sharing, chain sharing."
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "W ITH the rapid development of smart manufacturingand flexible production, the flexibility of industrial production has been greatly enhanced [1], [2]. Industrial software needs to quickly redistribute and adjust production processes according to changes of orders, which has higher requirements for flexibility and scalability of industrial software [3], [4], [5]. Traditional industrial software adopts a monolithic service architecture. The high coupling and occupancy rate within the service will increase the complexity of the whole system. Its scalability, stability, and fault tolerance are difficult to meet the requirements of smart manufacturing. Therefore, the industrial software architecture based on"
        },
        {
            "heading": "Y. Liu, B. Yang (Corresponding author), Y. Wu, C. Chen, and X. Guan are with the Department of Automation, Shanghai Jiao Tong University, Shanghai",
            "text": "200240, China; Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai 200240, China; Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai 200240, China (e-mail: liu953973860@sjtu.edu.cn; bo.yang@sjtu.edu.cn; 5wuuy5@sjtu.edu.cn; cailianchen@sjtu.edu.cn; xpguan@sjtu.edu.cn).\nmicroservices has been widely concerned [6], [7]. Through the microservice architecture, a complete service can be split into multiple loosely coupled microservices. Different microservices are logically independent and have a high degree of flexibility, scalability, and fault tolerance, which can well adapt to the requirements of smart manufacturing.\nTo meet the high requirements of computation-intensive tasks for real-time performance and service efficiency in smart manufacturing, edge computing-oriented microservice platforms are emerging [8], [9], [10], [11], [12]. At present, container technologies represented by Docker [13] and container orchestration tools represented by Kubernetes [14] are becoming mainstream solutions for microservice deployment and maintenance on edge platforms. According to different service requests and deployment strategies, each microservice which is packaged into a Docker image can be deployed to edge servers through container orchestration tools.\nIn the containerized deployment of microservices, service efficiency is an important indicator for evaluating the quality of the deployment solution. Service efficiency is mainly affected by two aspects. One is the startup time of microservices. It mainly depends on the pull delay of Docker images which are stored in the cloud through different image layers [15]. When a microservice needs to be provided locally, the edge server will pull a nonlocal container image containing all required layers from the cloud. Due to limited network bandwidth, image pulls incur a corresponding downlink delay. A comprehensive research shows that with a bandwidth of 100Mbps, the average startup time of a single image is about 20.7 seconds, while the average image pull delay is about 15.8 seconds, accounting for 76.6% of the average startup time [16]. Image pull delay has become a non-negligible factor affecting container startup time, which in turn affects the efficiency of service response. The other is the communication overhead between microservices. It depends on the amount of data communicated between microservices. An industrial application can be completed by multiple microservices deployed on one or more edge servers [17]. These microservices can be called microservice chains, and there will be frequent data exchanges between microservices in the same microservice chain [18]. A large amount of data transmission between microservices will cause high transmission delay, which will affect the service response efficiency. ar X iv :2 21 2. 14 18\n3v 1\n[ ee\nss .S\nY ]\n2 9\nD ec\n2 02\nDue to the above two aspects, it is very important to improve service efficiency through resource sharing. There are two types of resource sharing strategies for the improvement of service efficiency. One of the strategies for resource sharing is layer sharing [15]. Docker natively supports the sharing of layers. If the microservices deployed on the same edge server use the same image layer, the layer will not be pulled repeatedly when pulling images. This layer can be shared by all microservices on the server. The image pull delay can be effectively reduced by layer sharing, thereby improving the startup speed and service response efficiency of microservices. The other strategy for resource sharing is chain sharing [18], [19], which can be defined as the data sharing of microservices deployed on the same server. In the microservice chain, there is frequent data transfer between two adjacent microservices. If two microservices are deployed on the same server, the data can be directly accessed through chain sharing by the next microservice without multi-hop transmission of data. The delay and packet loss caused by data transmission can be reduced by chain sharing.\nHowever, due to the limited resources of edge servers, it is impossible for all microservices to be deployed on the same edge server. Therefore, it is necessary to find an optimal microservice deployment strategy for the trade-off between layer sharing and chain sharing. Besides service efficiency, due to the limited resources of edge servers, the microservice deployment strategy can not make full use of different resources (such as computing and storage resources) at the same time, resulting in idle computing resources. Therefore, a method is also needed to reasonably allocate resources to different microservices deployed on a server and maximize the utilization of resources.\nAiming at resource sharing and maximizing resource utilization problems among microservices, the deployment of microservices mainly faces the following difficulties. 1) How to model the layered structure of the microservice image to accurately describe the relationship between the microservice image and the container layer. 2) How to describe the chain structure of microservices and the communication between microservices. 3) How to balance layer sharing and chain sharing to establish an optimization problem to achieve the best deployment strategy. 4) How to reallocate resources to microservices deployed on edge servers to make full use of computing resources. In this paper, we study the microservice deployment problem considering microservice layer sharing and chain sharing. The problem is modeled as an integer programming problem that minimizes image pull delay and communication overhead. Based on this problem, a microservice deployment strategy and resource redistribution scheme are proposed. The main contributions of this work are as follows: 1) We describe the layered structure and chain structure\nof microservices through the same model. An integer programming problem is established to minimize the image pull delay and communication overhead. 2) Through model reconstruction, we prove that the integer programming problem can be transformed into an integer quadratic programming problem with linear constraints. The optimal solution is obtained by using the successive convex approximation (SCA) method. This\nmethod can effectively balance the image pull delay and communication overhead. 3) A resource redistribution algorithm for edge servers is proposed to make full use of idle computing resources. 4) Through experiments, the results are evaluated in multiple dimensions, such as image pull delay and interservice communication overhead. These experiments demonstrate the effectiveness of the proposed method. The remainder of this paper is organized as follows. Sec. 2 briefly reviews the related literature. In Sec. 3, the layered structure and chain structure of the system are modeled, and the problem formulation is given. Sec. 4 solves the proposed problem. Sec. 5 proposes a resource redistribution algorithm for edge servers. Sec. 6 evaluates the results of the proposed method. Sec. 7 discusses the limitations and future work. Sec. 8 concludes the paper."
        },
        {
            "heading": "2 RELATED WORKS",
            "text": "In this section, we discuss current research on the deployment of microservices.\nIn recent years, optimizing the cost and improving microservice response efficiency have received wide attention. Herrera et al. [20] designed a distributed microservice deployment framework named DADO to optimize the response time of microservices. Deng et al. [21] and Chen et al. [22] proposed algorithms to solve the cost-aware microservice deployment problem, they considered application deployment cost and service migration cost, respectively. Fadda et al. [23] provided an approach for supporting the deployment of microservices in multi-cloud environments to optimize the quality and cost. Zhao et al. [24] developed a cost-aware elastic microservice deployment algorithm to solve the container-based microservice deployment problem. The above researchers have conducted sufficient research on service response efficiency and service quality. However, these studies do not consider the characteristics of microservices, such as the chain structure of multiple microservices and the layered structure due to containerized deployment.\nFrom the perspective of the chain structure, deployment strategies become more complex due to the dependencies between microservices. In general, a microservice chain can be modeled as a directed acyclic graph [25], [26]. Wang et al. [17] and Li et al. [27] proposed algorithms to solve latencyaware microservice deployment problems. Armani et al. [28] proposed a cost-effective workload distribution strategy for microservice-based applications considering fault tolerance and load balancing of microservice chains. Sasabe et al. [29] considered the service chaining and function placement problems to optimize the total delay. Lv et al. [18] considered the containerized deployment of microservices, and a chain sharing deployment strategy is proposed to minimize the communication overhead. The above research focuses on the chain structure and chain sharing of microservices, but it does not take into account the layered structure in containerized deployments of microservices.\nFor the layered structure, researchers have focused on how to reduce the latency of image pulling by reducing image size or utilizing layer sharing of images. Lou et al. [30] considered layer sharing among images and proposed\na layer-aware scheduling algorithm. Gu et al. [31] designed a microservice deployment and request scheduling strategy based on layer sharing and used an iterative greedy algorithm to obtain the optimal strategy to improve the throughput of microservices. Gu et al. [32] also investigated the problem of how to collaboratively deploy microservices by incorporating both intra-server and inter-server layer sharing to maximize the edge throughput. The above research fully considers the layer sharing strategy in the containerized deployment of microservices, but does not consider the sharing strategy in the presence of the chain structure between microservices.\nAlthough the existing schemes have considered optimizing the efficiency and cost of microservice deployment in terms of the layered structure and chain structure, respectively, there are still some challenging problems to be solved. First, in complex intelligent manufacturing scenarios, the layered structure and chain structure usually coexist. In this case, the deployment strategies of layer sharing and chain sharing will affect each other, which further increases the difficulty of finding an effective deployment strategy. Secondly, an uneven deployment strategy will lead to idle server resources due to inconsistent server resources required by different microservices. In order to solve these problems, we propose a microservice deployment scheme that comprehensively considers layer sharing and chain sharing. It can both reduce the delay of image pulling and the communication overhead. The idle server resources can also be fully utilized. Our scheme can effectively improve the operating efficiency of microservices. To the best of our knowledge, there is no research that comprehensively considers the two sharing methods."
        },
        {
            "heading": "3 SYSTEM MODELING AND PROBLEM FORMULATION",
            "text": ""
        },
        {
            "heading": "3.1 A simple example",
            "text": "First, we show the two strategies of layer sharing and chain sharing through a simple microservice deployment model. As shown in Fig. 1, we consider two applications composed of two and three microservices, respectively. We denote the ith microservice in application k as mski. Each microservice image consists of a different number of image layers. The bandwidth between the three servers and the cloud server is 120 MB/s, and the two adjacent servers can be reached with a single hop. Under the layer sharing deployment strategy, the same image layer on the same edge server can be shared. Therefore, the size of the image layer to be pulled is 1617.48 MB, and the total download time is 13.479 seconds. However, the total communication data is 1031 KB because of communication between servers. Under the chain sharing deployment strategy, the total communication data is 0 KB since the microservices in the same chain are all deployed on the same server. The size of the image layer to be pulled is 2283 MB because there is no layer sharing, and the total pull delay is 19.025 seconds. When considering both chain sharing and layer sharing, we can get the result shown in Fig. 1(c). The size of the image layer to be pulled is 1758 MB, the total download time is 14.65 seconds, and the total communication data is 315 KB. These data can be found in Table 1. It can be seen that different deployment strategies have a significant impact on image pull delay and communication overhead. If layer sharing and chain sharing can be both considered, we will get low image pull delay and low communication overhead at the same time."
        },
        {
            "heading": "3.2 System model",
            "text": "We consider an intelligent manufacturing system, which has M production devices and N edge servers. We define device set as M = {1, 2, \u00b7 \u00b7 \u00b7 ,M} and server set as N = {1, 2, \u00b7 \u00b7 \u00b7 , N}. A cloud server is deployed at the remote end to store the microservice images. Each production device is connected to the nearest edge server. Each edge server has limited computing and storage resources, and a certain number of microservices can be deployed on it. The computing and storage resources of edge server n are denoted as CCn and C S n , and the bandwidth between cloud server and edge server n is bcloudn . Suppose there are several industrial applications, and application set is defined as K = {1, 2, \u00b7 \u00b7 \u00b7 ,K}. Each application is composed of multiple microservices. The microservice set in the kth application is Ak = {1, 2, \u00b7 \u00b7 \u00b7 , Ak}, where Ak is the amount of microservices in the kth application. Each application can handle service requests from production device. We use mski to denote the ith microservice in application k, and uki to denote the computing resources requested by microservice mski.\nAll microservice images are stored in the microservice image library of the cloud server, and are pulled by the edge server according to the deployed microservices. Every microservice image consists of some shareable layers and some non-shareable layers. We use set L = {1, 2, \u00b7 \u00b7 \u00b7 , L} to represent all layers of different size and Sl \u2208 R+ to represent the size of layer l \u2208 L. In this way, each microservice can be composed of one or more layers in L, and Ekil \u2208 {0, 1} can be used to indicate whether mski contains the lth layer.Ekil = 1 represents thatmski contains the lth layer.\nEach server will receive different service requests and data. If the expected microservice is deployed on the server at this time, the service request can be processed directly. If the expected microservice is not deployed on the server, the request and data need to be transmitted to another edge server through multi-hop transmission. Due to the different geographical locations, the hops in communication between different servers is also different. We defineDnn\u2032 as the hops of requests or data transmitted from server n to server n\u2032, which can be obtained by the shortest communication path between the two servers. It is obvious that Dnn\u2032 = Dn\u2032n, Dnn = 0. We can use a matrix D to represent the multi-hop connection between all servers. The notations and variables commonly used in this paper are summarized in Table 2.\nD =  0 D12 D13 \u00b7 \u00b7 \u00b7 D1N D21 0 D23 \u00b7 \u00b7 \u00b7 D2N D31 D32 0 \u00b7 \u00b7 \u00b7 D3N ... ... ... . . .\n... DN1 DN2 DN3 \u00b7 \u00b7 \u00b7 0\n"
        },
        {
            "heading": "3.3 Problem Formulation",
            "text": ""
        },
        {
            "heading": "3.3.1 Microservice deployment and layer sharing",
            "text": "We define xkin \u2208 {0, 1} to represent the deployment of mski, and xkin = 1 to represent that the microservice is deployed on the edge server n, otherwise not. Due to the layered structure of microservices, once a microservice is deployed on edge server n, all layers contained in the microservice image need to be pulled to server n. We use the variable dln \u2208 {0, 1} to represent whether the layer l is pulled to edge server n, and dln = 1 indicates that the lth layer needs to be downloaded to the edge server n, otherwise not.\nSince each microservice can only be deployed on a unique server, we can get the following constraints:\u2211\nn\u2208N xkin = 1,\u2200k \u2208 K,\u2200i \u2208 Ak (1)\nIf microservices deployed on the same server can share the same layer, the layer only needs to be downloaded once. Therefore, dln and x ki n satisfy the following constraints:\ndln = min { \u2211 k\u2208K \u2211 i\u2208Ak xkin E kil, 1},\u2200l \u2208 L,\u2200n \u2208 N (2)\nDue to the limited storage resources, the layer size of the deployed microservices needs to be smaller than the storage resources of edge servers. So we can get the following constraints: \u2211\nl\u2208L dlnS l \u2264 CSn ,\u2200n \u2208 N (3)\nDue to the limited computing resources, the total computing resource of all microservices deployed on a server needs to be less than the computing resource of the server. So we can get the following constraints:\u2211\nk\u2208K \u2211 i\u2208Ak xkin u ki \u2264 CCn ,\u2200n \u2208 N (4)\nFor each server, all layers deployed on the server need to be pulled from the cloud. The image pull delay of server n can be expressed as follows:\nTn =\n\u2211 l\u2208L d l nS l\nbcloudn (5)"
        },
        {
            "heading": "3.3.2 Communication overhead and chain sharing",
            "text": "We model the microservice chain as a directed weighted acyclic graph to reveal the impact of communication data on the deployment of microservices. Taking an application consisting of four microservices as an example, the modeled directed weighted graph is shown in Fig. 2. We use the interaction weightwkij to represent the size of the communication traffic between each two microservices mski and mskj .\nThe interaction graph can be written in the form of a matrix. For application k, its interaction matrix is defined as follows:\nwk =  w k 11 \u00b7 \u00b7 \u00b7 wk1Ak ... . . . ...\nwkAk1 \u00b7 \u00b7 \u00b7 w k Ak,Ak  where wkij is non-zero value only when ms k i and ms k j are connected. For example, wk of the microservice chain shown in Fig. 2 can be defined as follows:\nwk =  0 wk12 0 w k 14\n0 0 wk23 0 0 0 0 0 0 0 0 0  Based on the interaction graph, we can calculate the communication cost. Multi-hop data transmission between two adjacent microservices is not required if they are deployed on the same edge server. To calculate the total amount of data transferred between microservices in an application, we first need to find the hops between the servers where any two microservices are deployed. For the servers where any two microservices mski and mskj are deployed, we define Hop (k, i, j) = \u2211 n\u2208N \u2211 n\u2032\u2208N x ki n x kj n\u2032Dnn\u2032 to calculate the hops. For any application k, its communication overhead can be expressed as follows:\nRk = \u2211 i\u2208Ak \u2211 j\u2208Ak wkijHop (k, i, j)\n= \u2211 i\u2208Ak \u2211 j\u2208Ak ( wkij \u2211 n\u2208N \u2211 n\u2032\u2208N xkin x kj n\u2032Dnn\u2032 ) (6)"
        },
        {
            "heading": "3.3.3 The virtual microservice",
            "text": "Each application k originates from a service request on a production device. Each generated service request is transmitted via the network to the edge server closest to the production device at first. We define the number of the source device for the application k as sourcek. For each sourcek, we find its directly connected edge server Nk and define a virtual initial microservice msk0 to describe the impact of request generation location on microservice deployment. We use msk0 to denote the service requests generated on device sourcek. The microservice set in the kth application is modified as Ak = {0, 1, 2, \u00b7 \u00b7 \u00b7 , Ak}. Therefore, we should add the virtual initial microservice to the interaction diagram. Fig. 2 can be modified as follows:\nThe microservice msk0 does not actually exist, so its required computing resource is uk0 = 0 and does not contain any layers. When its deployment location is fixed, we can get the following constraints:\nxk0Nk = 1,\u2200k \u2208 K (7)"
        },
        {
            "heading": "3.3.4 Image pull delay and communication overhead minimization problem",
            "text": "The goal of microservice deployment is to minimize image pull delay and communication overhead under the constraints of device resources and service characteristics. The optimization problem can be expressed as follows:\nP1: min x,d T,R (8)\ns.t. (1), (2), (3), (4), (7)\nxkin , d l n \u2208 {0, 1} (9) where T = \u2211 n\u2208N Tn is the total image pull delay. R =\u2211\nk\u2208KR k is the total communication overhead. This problem is a multi-objective optimization problem and there is a multiplicative form of variables in Rk. Therefore, the problem is difficult to solve. In next section, we will transform the problem to a single-objective optimization problem and give a solution."
        },
        {
            "heading": "4 MICROSERVICE DEPLOYMENT SCHEME BASED",
            "text": ""
        },
        {
            "heading": "ON SCA",
            "text": ""
        },
        {
            "heading": "4.1 Problem transformation",
            "text": "We vectorize all variables through model reconstruction to make the problem clearer and easier to solve. Then we convert all constraints to linear constraints. Finally, the problem is transformed into a single-objective integer quadratic programming problem through an additive weighted model."
        },
        {
            "heading": "4.1.1 Image pull delay",
            "text": "Consider the first part of problem P1:\nT = \u2211 n\u2208N \u2211 l\u2208L d l nS l bcloudn (10)\nwhich is a linear form. We define d = [ dT1 , \u00b7 \u00b7 \u00b7 ,dTN ]T ,\nS = [ S1, \u00b7 \u00b7 \u00b7 , SL ]T , and M = [ ST\nbcloud1 , \u00b7 \u00b7 \u00b7 , S\nT\nbcloudN\n] . Then the\ncalculation of the total pull delay can be converted to\nT = Md (11)"
        },
        {
            "heading": "4.1.2 Communication overhead",
            "text": "Consider the second part of problem P1:\nR = \u2211 k\u2208K \u2211 i\u2208Ak \u2211 j\u2208Ak ( wkij \u2211 n\u2208N \u2211 n\u2032\u2208N xkin x kj n\u2032Dnn\u2032 ) (12)\nWe can also define xki = [ xki1 , x ki 2 , \u00b7 \u00b7 \u00b7 , xkiN ]T , xk =[(\nxk1 )T , \u00b7 \u00b7 \u00b7 , ( xkAk )T ]T , and x = [( x1 )T , \u00b7 \u00b7 \u00b7 , ( xK )T ]T\n. We can get \u2211\nn\u2208N \u2211 n\u2032\u2208N xkin x kj n\u2032Dnn\u2032 = ( xkj )T Dxki (13)\nLet be the Hadamard product of the matrix and define\nWk = wk D \u00b7 \u00b7 \u00b7 D... . . . ... D \u00b7 \u00b7 \u00b7 D  Ak\u00d7Ak\n(14)\nW = W 1 \u00b7 \u00b7 \u00b7 0 ... . . .\n... 0 \u00b7 \u00b7 \u00b7 WK  K\u00d7K\n(15)\nThen the calculation of the communication overhead can be converted to\nR = xTWx (16)"
        },
        {
            "heading": "4.1.3 Constraints",
            "text": "Considering equation (2), the original constraint is nonlinear. We can turn it into a linear constraint by two new constraints:\ndln \u2264 \u2211 k\u2208K \u2211 i\u2208Ak xkin E kil (17)\ndln \u2265 \u2211 k\u2208K \u2211 i\u2208Ak x ki n E kil\nZ (18)\nwhere Z is an arbitrarily large constant greater than 1. Equations (17) and (18) can be equivalent to constraint (2) because dln is a binary variable. Therefore, all constraints in problem P1 are transformed into linear constraints.\nFor linear constraints, we can also vectorize all constraints in the same way as in Sec. 4.1.1, and the transformed constraints are\nQx = b1 (19) Hx = b2 (20) d \u2264 Yx (21)\nd \u2265 Yx Z\n(22)\nSd \u2264 CS (23) Gx \u2264 CC (24)\nConstraints (19)-(24) correspond to (1), (7), (17), (18), (3), (4) respectively. Appendix A shows the detailed values of matrices Q,b1,H,b2,Y,S,CS ,G,CC . Problem P1 can be transformed into\nP2: min x,d T,R (25)\ns.t. (9), (19)\u2212 (24)\nwhere T = Md, R = xTWx."
        },
        {
            "heading": "4.1.4 Single objective optimization problem",
            "text": "The original problem has two optimization objectives. We use an additive weighting model to turn the original problem into a single-objective problem. The utility function is as follows:\nF (x,d) = \u03b8 T \u2212 Tmin Tmax \u2212 Tmin + (1\u2212 \u03b8) R\u2212Rmin\nRmax \u2212Rmin = \u03b8\nTmax \u2212 Tmin Md + 1\u2212 \u03b8 Rmax \u2212Rmin xTWx\n+ Const (26)\nwhere Const = \u2212 \u03b8TminTmax\u2212Tmin \u2212 (1\u2212\u03b8)Rmin Rmax\u2212Rmin . Tmax and Rmax represent the maximum value of image pull delay and communication overhead, respectively. Tmin and Rmin represent the minimum value of image pull delay and communication overhead. \u03b8 \u2208 [0, 1] represents the preference for image pull delay and communication overhead. Finally, the original optimization problem can be transformed into a new optimization problem as follows:\nP3: min x,d F (x,d) (27)\ns.t. (9), (19)\u2212 (24)\nThis problem is an integer quadratic programming problem. The solution of P3 is the weakly Pareto optimal solution of the original problem. If \u03b8 \u2208 (0, 1), the solution of P2 is the Pareto optimal solution. The proof can be found in [33]."
        },
        {
            "heading": "4.2 Solution based on successive convex approximation",
            "text": "Since W is not a positive semi-definite matrix, the problem is a non-convex quadratic programming, which is difficult to solve directly. First, we transform P3 into a convex optimization problem. Then the problem can be solved based on SCA [34]. Let Q = W + WT , then minimizing F (x,d) is equivalent to minimize\nU(x,d) = C1Md + 1\n2 C2x\nTQx (28)\nwhere C1 = \u03b8Tmax\u2212Tmin , C2 = 1\u2212\u03b8\nRmax\u2212Rmin . For the matrix Q, set the eigenvalues of the matrix as \u03bb1, \u03bb2, \u00b7 \u00b7 \u00b7 , \u03bbn. We can define \u03bbQ = max{|\u03bbi|}, and the matrix Q can be split as follows:\nQ = Q + \u03bbQI\u2212 \u03bbQI = P\u2212N (29)\nwhere P = Q + \u03bbQI, N = \u03bbQI. Equation (28) becomes\nU(x,d) = U1(x,d)\u2212 U2(x) (30)\nwhere U1(x,d) = C1Md + 12C2x TPx is convex, and \u2212U2(x) = \u2212 12C2x TNx is nonconvex. Next, we need to make a convex approximation to \u2212U2(x) at x\u0304, where x\u0304 is a point in the feasible set of P3. Let\nl(x) = \u2212U2(x\u0304)\u2212\u2207U2(x\u0304)T (x\u2212 x\u0304)\n= \u2212C2x\u0304TNx + 1\n2 C2x\u0304\nTNx\u0304 > \u2212U2(x) (31)\nFinally, we get the convex approximation problem\nP4: min Uqp(x,d; x\u0304, d\u0304) = U1(x,d) + l(x)\n= C1Md + 1\n2 C2x\nTPx\n\u2212 C2x\u0304TNx + 1\n2 C2x\u0304\nTNx\u0304 (32)\ns.t. (9), (19)\u2212 (24)\nP4 is a convex quadratic programming problem and can be solved directly with the commercial solver. So we can solve P3 by SCA [34] algorithm, as shown in Algorithm 1."
        },
        {
            "heading": "4.3 Convergence analysis",
            "text": "In this subsection, we show that the SCA algorithm can reach the optimal solution of P3.\nTheorem 1. If x\u0304, d\u0304 is the optimal solution to P4, then x\u0304, d\u0304 is the KKT point of P3.\nProof. Proof is provided in Appendix B.\nTheorem 2. The problem P3 can get a stationary solution by Algorithm 1.\nProof. Proof is provided in Appendix C.\nAccording to Theorem 1 and Theorem 2, we can get that Algorithm 1 can converge to a stationary point and the point is the KKT point of P3. Since the original problem is nonconvex, the global optimal solution cannot be obtained. The solution obtained by Algorithm 1 based on the SCA method [34] is the approximate optimal solution of the original problem.\nAlgorithm 1 Successive convex approximation algorithm\n1: Find a feasible point x0 and d0, choose a stepsize \u03b1 \u2208 (0, 1], and set r = 0, > 0 2: repeat 3: zr+1x , z r+1 d = arg minUqp(x,d;x\nr,dr) 4: xr+1 = xr + \u03b1(zr+1x \u2212 xr) 5: dr+1 = dr + \u03b1(zr+1d \u2212 yr) 6: r \u2190 r + 1 7: until \u2016xr \u2212 xr\u22121\u2016+ \u2016dr \u2212 dr\u22121\u2016 6"
        },
        {
            "heading": "5 RESOURCE REALLOCATION SCHEME",
            "text": "We can get a microservice deployment strategy for layer sharing and chain sharing from Sec. 4. However, the computing resources of all servers will not be fully utilized due to the constraints of computing resources and storage resources of edge servers. Edge servers may face the problem that one resource is used up while the other resource is still available. It is a waste of spare resources. In this section, we will propose a server resource redistribution method, which can fully utilize the spare resources of the server."
        },
        {
            "heading": "5.1 Problem formulation",
            "text": "After a microservice is deployed, the deployment location of the microservice remains unchanged until the end of the microservice. Assume that the computing resource of server n is CCn , and J microservices are deployed on it. These microservices can be described by a set J = {1, \u00b7 \u00b7 \u00b7 , J}. The minimum computing resource requested by microservice j is uj , and the computing resource actually allocated to microservice j is fj . The computing resources allocated to the microservice must be higher than the computing resources it requests, so there is a constraint fj > uj .\nAssuming that the amount of data that the microservice needs to process is Data. The original processing time required is told = Datauj , and the new processing time is tnew =\nData fj . The ratio of the new processing time to the original processing time is tnewtold = uj fj\n. So we define the evaluation function ej =\nuj fj\nto evaluate the impact of allocated computing resources on the processing efficiency of microservices. Then we can define the optimization problem as follows\nP5: minU = \u2211 j\u2208J ej (33)\ns.t. fj > uj ,\u2200j \u2208 J (34)\u2211 j\u2208J fj 6 C C n (35)\nConstraint (35) means that the total computing resources allocated need to be less than the total resources of the server."
        },
        {
            "heading": "5.2 Solution based on Lagrange Multiplier Method",
            "text": "The Lagrangian function of P5 is constructed as\nAlgorithm 2 Greedy deployment strategy\n1: Normalize the communication data and layer size of\neach microservice by: wkij,new = \u03b8 wkij\u2212wmin wmax\u2212wmin , S l new = (1\u2212 \u03b8) S l\u2212Smin\nSmax\u2212Smin 2: Sort wkinew and S l new. The larger the value is, the higher\nthe priority will be. Each value corresponds to two microservices with a large amount of communication data or several groups of microservices with a larger image layer. Get the sorted list List 3: for ms in List do 4: Check if these microservices in ms have been deployed 5: if all microservices have been deployed then 6: continue 7: else 8: if microservices in ms are from wkij,new then 9: Find the closest server n where the microservice\nis deployed and deploy microservice in n. 10: if server n has no enough resource then 11: find a closet server from server n to deploy. 12: end if 13: else 14: Deploy microservice in the server which has maximum bcloudn and enough resource 15: end if 16: end if 17: end for 18: Output deployment strategy\nL(fj , \u03bbi, \u00b5) = \u2211 j\u2208J ej+ \u2211 j\u2208J \u03bbi(uj\u2212fj)+\u00b5( \u2211 j\u2208J fj\u2212CCn ) (36)\nIts KKT condition is\n \u2207Lfj (fj , \u03bbi, \u00b5) = \u2212 \u2211 j\u2208J uj f2j + \u2211 j\u2208J \u03bbifj + \u00b5J = 0 \u03bbi(uj \u2212 fj) = 0,\u2200i \u2208 J \u00b5( \u2211 j\u2208J fj \u2212 CCn ) = 0\n\u03bbi > 0,\u2200i \u2208 J \u00b5 > 0\n(37)\nBy solving (37), we can get\nfj = uj\u2211 j\u2208J uj CCn (38)\nA simple explanation is that each microservice is proportionally multiplied by the ratio of the total computing resources to the initial request resources. In this way, we can redistribute the computing resources and make full use of the computing resources."
        },
        {
            "heading": "6 PERFORMANCE EVALUATION",
            "text": "In this section, we evaluate the performance to verify the effectiveness of our proposed method. We use Gurobi [35] to\nsolve the integer quadratic programming problem P4. The proposed method is compared with five methods:\n\u2022 Greedy Deployment Strategy [32] (GDS): A deployment strategy based on the greedy strategy in [32]. We modified it to fit the experiments in this paper. This algorithm works by weighting the size of the layer and chain. The steps of the algorithm are shown in Algorithm 2. \u2022 Layer-match Scheduling [36] (LS): For each microservice, select an edge server with most amount of its image layers stored locally and sequence layers according to the assignment order. \u2022 Kubernetes Deployment Strategy [37] (K8S): Kubernetes default deployment policy schedules microservices to edge servers with the required images stored locally, otherwise, to the edge server with the least total download size. \u2022 Layer-sharing Deployment Strategy (LDS): A deployment strategy that only considers layer sharing. It is a special case of the proposed method when \u03b8 = 1. \u2022 Chain-sharing Deployment Strategy (CDS): A deployment strategy that only considers chain sharing. It is a special case of the proposed method when \u03b8 = 0.\nWe use Python to conduct simulation experiments on multiple servers to evaluate the performance of the proposed method under different conditions. To accurately evaluate the effectiveness in the real world, we conduct experiments with five real edge servers. Furthermore, we carried out large-scale simulation tests on 15 servers to evaluate the adaptability of the algorithm in large-scale scenarios."
        },
        {
            "heading": "6.1 Simulation experiment",
            "text": ""
        },
        {
            "heading": "6.1.1 Experimental environment",
            "text": "The experimental platform is Python 3.9.12. The experiments are carried out on a CentOS 7 system equipped with Inter 4210R, 2.40GHz, and 64 GB RAM. We simulated a smart manufacturing production scenario with up to 9 edge servers and 36 microservices. The average storage resource of edge servers is 8 GB, the average computing resource (CPU frequency) of each server is 1.8 GHz with 4 cores, and the bandwidth between the server and the cloud server is 80-200 MB/s. The hop of adjacent servers is 1, and the element values of the D matrix vary from 0 to 5, which means the maximum hop of servers is 5. Each application consists of 2-6 microservices, and the communication data between microservices ranges from 100-2000 KB. The computing resource requirements of each microservice range from 0.002 GHz to 1.0 GHz. The number of layers of each microservice is in the range of 6-13. By dividing these layers into shareable and unshareable layers, each image can be regarded as a microservice composed of 1- 2 layers. This can reduce the difficulty of calculation. The size of each layer varies from 1-1220 MB. The above data are randomly generated in each experiment to verify the stability of the proposed method. The specific experimental parameter settings are shown in Table 3."
        },
        {
            "heading": "6.1.2 Experimental results",
            "text": "Fig. 4 shows the objective function value of different methods. Fig. 4(a) shows the objective function value in different production scale. We take the minimum amount of microservices msmin = 12 and the amount of servers nmin = 4 in this experiment as the benchmark values. Then the scale can be described as Scale = 12 ( Nms msmin\n+ Nnnmin ), whereNms is the amount of microservices, and Nn is the amount of servers. As can be seen from the figure, our proposed deployment strategy can minimize the objective function compared with the other five methods. The proposed method can also reach relatively stable results under different numbers of microservices and servers. The GDS method can also achieve a good deployment strategy by weighting the layer size\nand communication overhead. However, due to its greedy strategy, the optimal solution may not always be obtained. The LDS method and the CDS method cannot make the objective function optimal because they only consider one aspect of resource sharing. The LS and K8S methods only consider layer sharing and can not get a better result due to the high communication overhead.\nFig. 4(b) shows the objective value with different microservices and nine servers. It simulates different production loads. The higher the number of microservices is, the higher the load on one server will be. We can see that the proposed deployment strategy can achieve the optimal objective function value, and the value fluctuates within a small range under different microservice loads, which shows that the proposed method is suitable for different load conditions and has good stability. The results of other methods are worse than the proposed method.\nFig. 4(c) shows the objective value with different \u03b8 when there are 9 servers and 36 microservices on average. It simulates the effect of different weights for microservice image pull delay and communication overhead. In this figure, the function values of the LDS method, LS method, and K8S method change linearly because they only consider layer sharing of the objective function. And CDS method only considers chain sharing of the objective function. So the changes of \u03b8 can not impact the deployment strategy.\nThe proposed method can achieve optimal results no matter what value \u03b8 takes. When \u03b8 = 0, there is only the chain sharing part in the objective function, and the objective function value is the same as the CDS method. When \u03b8 = 1, there is only the layer sharing part in the objective function, and the objective function value is the same as the LDS method.\nFig. 5 shows the image pull delay and communication overhead with different \u03b8. Since the LDS, CDS, LS, and K8S methods are unaffected by \u03b8, the values of these two strategies do not change a lot in the two figures. The fluctuation of the line is more due to randomly generated microservice data. Fig. 5(a) shows the total image pull delay with different \u03b8. The higher the weight \u03b8, the lower the image pull delay of both the proposed strategy and the GDS method. When \u03b8 = 1, the proposed deployment strategy can achieve the same result as the LDS method. The image pull delay can be reduced by 140s compared to the CDS method. The proposed strategy can reduce the total image pull delay by 52s on average compared to the GDS method. Fig. 5(b) shows the total communication overhead with different \u03b8. The lower the weight \u03b8, the lower the total communication overhead of both the proposed strategy and the GDS method. When \u03b8 = 0, the proposed deployment strategy can achieve the same result as the CDS method. The total communication overhead can be reduced by 80 MB compared to the LDS method. The proposed strategy can reduce total communication overhead by 10 MB on average compared to the GDS method."
        },
        {
            "heading": "6.2 Experiment with Real Edge Servers",
            "text": ""
        },
        {
            "heading": "6.2.1 Experimental environment",
            "text": "We further conduct experiments with five edge servers in real world to evaluate the effectiveness of our method. The servers are shown in Fig. 6(a) and the topology of servers is shown in Fig. 6(b). Each server has an i5-8250U CPU, 8G RAM, and is equipped with Docker CE. Communication between servers is carried out using the TCP protocol. We select 23 microservices from Docker Hub. The image size of these microservices is in the range of 1.24-1098 MB, and the computation resource requirement is in the range of 0.2- 1.4 GHz. The number of layers of each microservice is in the range of 4-11. We simulate servers with different storage and resource constraints by limiting the resource usage of docker. The experimental results are shown in the following figures. Each data point in the figures is the average of multiple experiments."
        },
        {
            "heading": "6.2.2 Experimental results",
            "text": "Fig. 7 shows the total image pull delay and communication overhead under different storage capacities with \u03b8 = 0.5. As can be seen from Fig. 7(a), the results of the proposed method and the LDS method are very close. When storage capacity becomes more and more sufficient, the proposed method can significantly reduce the image pull delay compared with other methods. This is because when the storage resources are sufficient, more microservices with the same layer can be deployed on one edge server. It can reduce the size of the image layer to be pulled and reduce the delay. In Fig. 7(b), the CDS method can achieve the lowest communication overhead because it is optimized for the\nmicroservice chain. Compared with other methods except the CDS method, the proposed method can achieve lower communication overhead.\nFig. 8 shows the image pull delay and communication overhead under different computing capacities with \u03b8 = 0.5. The trend is the same as that in Fig. 7. From Fig. 7 and Fig. 8, we can also find that the LDS method has the best effect on image pull delay and the worst effect on communication overhead, and the CDS method is the opposite. This is the disadvantage of not considering both aspects comprehensively. Different from other methods, our proposed method can always obtain a better solution that can better balance the image pull delay and communication overhead.\nFig. 9 shows the impact of the resource reallocation strategy on the completion time of tasks. We selected two from five servers and showed the effect of resource reallocation on their task computing time. The data are shown in Table 4. We can see that resource reallocation can significantly reduce the completion time of computing tasks. In Table 4, the total task completion time of the two servers is reduced from 136.67 seconds and 111.836 seconds to 104.592 seconds and 102.456 seconds, which is a reduction of 23.7% and 8.4%, respectively. This shows that the resource reallocation strategy can effectively reduce the completion time of computing tasks and improve computing efficiency."
        },
        {
            "heading": "6.3 Large-scale Cases",
            "text": "To evaluate the performance of our proposed method in a larger scale scenario [32], we consider the topology of US NSFNET consisting of 15 edge servers as shown in Fig. 10(a). The storage resources of each edge server are\n16 GB, the computing resources are 4-core 1.6 GHz, and the bandwidth is 80-120 MB/s. We considered up to 105 microservices selected from Docker Hub and randomly combined them into applications. Other parameter settings are the same as in the previous experiments."
        },
        {
            "heading": "6.3.1 Experimental results",
            "text": "To verify the stability of the proposed method, we conducted ten experiments, and the data for each experiment are presented in Fig. 10. Fig. 10(b) shows the objective function value for ten experiments, it can be seen that the proposed method has little fluctuation and can achieve the lowest objective function value. Since the microservice composition of each experiment is random, the results vary drastically in Fig. 10(c) and Fig. 10(d). The proposed method can achieve almost the same results as the LDS method in terms of image pull delay. It can also achieve similar results to the CDS method in terms of total communication overhead. The results of the proposed method are also better than other schemes.\nFig. 11 shows the ratio of image pull delay and communication overhead to the baseline under different servers and different \u03b8. The baseline of image pull delay is defined as the total data size in the absence of layer sharing divided by the average bandwidth of servers. The lower the ratio is, the higher the layer sharing rate will be. As can be seen from the figure, our proposed method can significantly reduce the image pull delay. The image pull delay in the best case is only 56% of the baseline. When \u03b8 = 0.5, an average of 65% of the baseline ratio can be achieved in the proposed method. The baseline of communication overhead is defined as the summation of all microservice commu-\nnication data. This ratio can reflect the average number of hops between microservices. The lower the ratio is, the higher the chain sharing rate will be. As can be seen from the figure, our proposed method can significantly reduce communication overhead. The communication overhead in the best case is only 5% of the baseline. When \u03b8 = 0.5, an average of 30% of the baseline value ratio can be achieved in the proposed method. Moreover, The image pull delay and communication overhead can be reduced significantly in any server numbers, which proves the stability of our proposed method.\nFig. 12 shows the space and time consumption of the proposed method and GDS method to get the deployment strategy under different servers. With the increase in the number of servers and microservices in the network, the amount of layers and the communication between microservices is also increasing. Then the network structure becomes more and more complex. When the amount of servers is less than 10, the computing time of the proposed method is less than 20 seconds and the space occupation is less than 100 MB, which has excellent solution efficiency. In a large-scale server network, the solution time will slow down to about 450 seconds, and the space occupation will also increase to 1800 MB due to the complexity of the network. The optimal solution can still be solved in an acceptable time because the scheduling strategy of microservices does not change frequently in large-scale production. However, since the proposed method is based on solving quadratic programming problems, the time and space complexity is higher than that of Algorithm 2. It is our future work to further optimize the time complexity and space complexity of the proposed method."
        },
        {
            "heading": "7 DISCUSSION",
            "text": "In this section, we will discuss the limitations of the proposed method and the future work.\nCompared with related works, our proposed method is able to optimize the communication overhead while optimizing the image pull delay. The experiments in Section. 6 also show that the proposed method can achieve the lowest objective function value with a good trade-off between delay and overhead. However, the time and space complexity\nof this method is high in large-scale scenarios. Although the optimal solution can be obtained within an acceptable time, further optimization is required in the future.\nThe communication overhead depends not only on the amount of communication data, but also on the request frequency. If the request frequency is high, the communication overhead will be very large even if the amount of communication data at one time is small. Therefore, we believe that the calculation of communication overhead should consider the request frequency, that is, to consider the product of the communication data volume and the request frequency. However, since our method is based on microservices not requests, we cannot directly get the request frequency. Therefore, we believe that future work can consider the request frequency as an input, and then use the product of the request frequency and the amount of communication data as the calculation of communication overhead.\nDeployed microservices are not static, and the entire production process will include shutdown, migration, and startup of new microservices. In the face of the dynamic microservice deployment process, it is necessary to have corresponding deployment algorithms to adapt to dynamic scenarios. One possible future research direction is to use artificial intelligence or other methods for training after the initial deployment results such that the microservices can be dynamically adjusted."
        },
        {
            "heading": "8 CONCLUSION",
            "text": "In this paper, we study the layer sharing and chain sharing of microservices and explore a microservice deployment scheme that can balance the two ways of resource sharing. We build an image pull delay and communication overhead minimization problem. We transform the problem into a linearly constrained integer quadratic programming problem through model reconstruction and obtain the deployment strategy through a successive convex approximation (SCA) method. Further, we propose a resource reallocation algorithm to fully utilize the idle resources of the server. Experimental results show that the proposed deployment strategy can balance the two resource sharing methods of microservices. When considering the two sharing methods\nin balance, the average image pull delay can be reduced to 65% of the baseline, and the average communication overhead can be reduced to 30% of the baseline. In the future, we will expand microservice deployment from static scenarios to highly dynamic scenarios and try to obtain rapid solution algorithms in large-scale scenarios."
        },
        {
            "heading": "ACKNOWLEDGMENT",
            "text": "This work was supported by the National Key Research and Development Program of China (Grant No.2018YFB1702300), and in part by the NSF of China (Grants No. 61731012, 62025305, 61933009, and 92167205)."
        },
        {
            "heading": "APPENDIX A",
            "text": "MATRIX VALUE\n1)\nQ = Q 1 \u00b7 \u00b7 \u00b7 0 ... . . .\n... 0 \u00b7 \u00b7 \u00b7 QK  K\u00d7K\n(39)\nwhere\nQk = q \u00b7 \u00b7 \u00b7 0... . . . ... 0 \u00b7 \u00b7 \u00b7 q  Ak\u00d7Ak\nq = [1, 1, \u00b7 \u00b7 \u00b7 , 1]1\u00d7N\n2) b1 = [1, 1, \u00b7 \u00b7 \u00b7 , 1]T1\u00d7\u2211k\u2208K Ak (40) 3)\nH = H 1 \u00b7 \u00b7 \u00b7 0 ... . . .\n... 0 \u00b7 \u00b7 \u00b7 HK  K\u00d7K\n(41)\nwhere\nHk = [In\u00d7n 0 \u00b7 \u00b7 \u00b7 0]1\u00d7Ak\n4)\nb2 = [x 1,0, \u00b7 \u00b7 \u00b7 ,xK0]T (42)\nwhere xk0 = [0, \u00b7 \u00b7 \u00b7 , 1, \u00b7 \u00b7 \u00b7 , 0]T , xk0Nk = 1 5)\nY = [Y1, \u00b7 \u00b7 \u00b7 ,YN ]T (43)\nwhere\nYn =  P 1 nV 1 1E 1 \u00b7 \u00b7 \u00b7 P1nV1LE1 ... . . . ...\nPKn V K 1 E K \u00b7 \u00b7 \u00b7 PKn VKL EK  K\u00d7L\nPkn = p N n \u00b7 \u00b7 \u00b7 0 ... . . . ...\n0 \u00b7 \u00b7 \u00b7 pNn  Ak\u00d7Ak\npNn = [0, \u00b7 \u00b7 \u00b7 , 0, 1, 0, \u00b7 \u00b7 \u00b7 , 0]T1\u00d7N ,pNn (n) = 1 q = [1, 1, \u00b7 \u00b7 \u00b7 , 1]1\u00d7N\nVkl =  (p L l ) T \u00b7 \u00b7 \u00b7 0 ... . . . ...\n0 \u00b7 \u00b7 \u00b7 (pLl ) T  Ak\u00d7Ak\npLl = [0, \u00b7 \u00b7 \u00b7 , 0, 1, 0, \u00b7 \u00b7 \u00b7 , 0]T1\u00d7L,pLl (l) = 1\nEk = [( Ek1 )T , \u00b7 \u00b7 \u00b7 , ( EkAk )T ]T Eki = [ Eki1, \u00b7 \u00b7 \u00b7 , EkiL\n]T 6)\nS = S T \u00b7 \u00b7 \u00b7 0 ... . . . ...\n0 \u00b7 \u00b7 \u00b7 ST  N\u00d7N\n(44)\nwhere S = [ S1, \u00b7 \u00b7 \u00b7 , SL ]T 7)\nCS = [ CS1 , \u00b7 \u00b7 \u00b7 , CSN ]T (45)\n8) G = [G1, \u00b7 \u00b7 \u00b7 ,GN ]T (46)\nwhere\nGn = [( P1nu 1 )T , \u00b7 \u00b7 \u00b7 , ( PKn u K )T ]T\nuk = [ uk1, \u00b7 \u00b7 \u00b7 , ukAk ]T 9)\nCC = [ CC1 , \u00b7 \u00b7 \u00b7 , CCN ]T (47)"
        },
        {
            "heading": "APPENDIX B PROOF OF THEOREM 1",
            "text": "Proof. We remove the bolding of all letters in this proof to simplify the expression. We combine the same parts of the constraints in P3 and rewrite it as\nminF (x, d) = C1Md+ 1\n2 C2x\nTPx\n\u2212 C2x\u0304TNx+ 1\n2 C2x\u0304\nTNx\u0304\ns.t. aTi x = bi, i = 1, \u00b7 \u00b7 \u00b7 ,m aTi x 6 bi, i = m, \u00b7 \u00b7 \u00b7 ,m+ l cTi y 6 gi, i = 1, \u00b7 \u00b7 \u00b7 , n eix+ fiy 6 0, i = 1, \u00b7 \u00b7 \u00b7 , p\nIts KKT condition is\n C2Px\u0304\u2212 C2Nx\u0304+ \u2211m+l i=1 \u03bbiai + \u2211k i=1 \u03bdei = 0 C1M + \u2211n i=1 \u00b5ici + \u2211k i=1 \u03bdei = 0 aTi x = bi, i = 1, \u00b7 \u00b7 \u00b7 ,m aTi x 6 bi, i = m, \u00b7 \u00b7 \u00b7 ,m+ l cTi y 6 gi, i = 1, \u00b7 \u00b7 \u00b7 , n eix+ fiy 6 0, i = 1, \u00b7 \u00b7 \u00b7 , p \u03bbi > 0, i = 1, \u00b7 \u00b7 \u00b7 ,m+ l \u00b5i > 0, i = 1, \u00b7 \u00b7 \u00b7 , n \u03bdi > 0, i = 1, \u00b7 \u00b7 \u00b7 , p \u03bbi(a T i x\u2212 bi) = 0, i = m, \u00b7 \u00b7 \u00b7 ,m+ l \u00b5i(c T i y \u2212 gi) = 0, i = 1, \u00b7 \u00b7 \u00b7 , n\n\u03bdi(eix+ fiy) = 0, i = 1, \u00b7 \u00b7 \u00b7 , p\n(48)\nSince Px\u0304\u2212Nx\u0304 = Qx\u0304, so\n C2Qx\u0304+ \u2211m+l i=1 \u03bbiai + \u2211k i=1 \u03bdei = 0 C1M + \u2211n i=1 \u00b5ici + \u2211k i=1 \u03bdei = 0 aTi x = bi, i = 1, \u00b7 \u00b7 \u00b7 ,m aTi x 6 bi, i = m, \u00b7 \u00b7 \u00b7 ,m+ l cTi y 6 gi, i = 1, \u00b7 \u00b7 \u00b7 , n eix+ fiy 6 0, i = 1, \u00b7 \u00b7 \u00b7 , p \u03bbi > 0, i = 1, \u00b7 \u00b7 \u00b7 ,m+ l \u00b5i > 0, i = 1, \u00b7 \u00b7 \u00b7 , n \u03bdi > 0, i = 1, \u00b7 \u00b7 \u00b7 , p \u03bbi(a T i x\u2212 bi) = 0, i = m, \u00b7 \u00b7 \u00b7 ,m+ l \u00b5i(c T i y \u2212 gi) = 0, i = 1, \u00b7 \u00b7 \u00b7 , n\n\u03bdi(eix+ fiy) = 0, i = 1, \u00b7 \u00b7 \u00b7 , p\n(49)\nTherefore, x\u0304 is the KKT point of P3, the non-global solution of the original problem can be obtained."
        },
        {
            "heading": "APPENDIX C PROOF OF THEOREM 2",
            "text": "Proof. We remove the bolding of all letters in this proof to simplify the expression. We can find that the search direction of the algorithm is \u03bbr+1x = z r+1 x \u2212 xr, \u03bbr+1y = zr+1d \u2212 dr . According to the convexity of P4, we can get\nU(xr+1, dr+1) 6 Uqp(xr+1, dr+1;xr, dr) 6 \u03b1Uqp(xr+1, z r+1 d ;x\nr, dr) +(1\u2212 \u03b1)Uqp(xr+1, dr;xr, dr)\n6 Uqp(xr+1, dr;xr, dr) 6 \u03b1Uqp(zr+1x , d\nr;xr, dr) + (1\u2212 \u03b1)Uqp(xr, dr;xr, dr) 6 Uqp(xr, dr;xr, dr) = U(xr, dr)\n(50) where the second and the fourth inequality sign come from the convexity of Uqp(\u00b7;xr, yr). Then the value of the objective function must not be monotone increasing.\nU(xr, dr)\u2212 U(xr+1, dr+1) = U(xr, dr)\u2212 U(xr+1, dr)\n+U(xr+1, dr)\u2212 U(xr+1, dr+1) = U(xr, dr)\u2212 U(xr + \u03b1(zr+1x \u2212 xr), dr)\n+U(xr+1, dr)\u2212 U(xr+1, dr + \u03b1(zr+1d \u2212 dr)) > \u2212\u03b1U \u2032(xr, dr;\u03bbr+1x )\u2212 \u03b1U \u2032(xr+1, dr;\u03bbr+1d ) > 0\n(51)\nThen we can get\nU(x\u2217, d\u2217)\u2212 U(x0, d0) 6 U(xr, dr)\u2212 U(x0, d0) 6 \u2211r r=0 \u03b1(U \u2032(xr, dr;\u03bbr+1x ) + U \u2032(xr+1, dr;\u03bbr+1d )) (52)\nthereby\nlim r\u2192\u221e U \u2032(xr, dr;\u03bbr+1x ) = lim k\u2192\u221e U \u2032(xr, dr;\u03bbr+1y ) = 0 (53)\nSo problem P3 can get a stationary solution by SCA algorithm. We can choose \u03b1 = 1 for integer variables, and it still holds."
        }
    ],
    "title": "How to Share: Balancing Layer and Chain Sharing in Industrial Microservice Deployment",
    "year": 2023
}