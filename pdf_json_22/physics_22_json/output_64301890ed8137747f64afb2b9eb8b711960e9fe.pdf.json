{
    "abstractText": "We demonstrate high prediction accuracy of three important properties that determine the initial geometry of the heavy-ion collision (HIC) experiments by using supervised machine learning (ML) methods. These properties are the impact parameter, the eccentricity, and the participant eccentricity. Although ML techniques have been used previously to determine the impact parameter of these collisions, we study multiple ML algorithms, their error spectrum, and sampling methods using exhaustive parameter scans and ablation studies to determine a combination of efficient algorithm and tuned training set that gives multifold improvement in accuracy for all three different heavy-ion collision models. The three models chosen are a transport model, a hydrodynamic model, and a hybrid model. The motivation of using three different heavy-ion collision models was to show that even if the model is trained using a transport model, it gives accurate results for a hydrodynamic model as well as a hybrid model. We show that the accuracy of the impact-parameter prediction depends on the centrality of the collision. With the standard application of ML training methods, prediction accuracy is considerably low for central collisions. Our method increases this accuracy by multiple folds. We also show that the eccentricity prediction accuracy can be improved by inclusion of the impact parameter as a feature in all these algorithms. We discuss how the errors can be minimized and the accuracy can be improved to a great extent in all the ranges of impact-parameter and eccentricity predictions.",
    "authors": [
        {
            "affiliations": [],
            "name": "Abhisek Saha"
        },
        {
            "affiliations": [],
            "name": "Debasis Dan"
        },
        {
            "affiliations": [],
            "name": "Soma Sanyal"
        }
    ],
    "id": "SP:fe5dda0cc69e9be9c36affcf0424afd9a28f0cf1",
    "references": [
        {
            "authors": [
                "J. Adams"
            ],
            "title": "STAR Collaboration)",
            "venue": "Nucl. Phys. A 757,",
            "year": 2005
        },
        {
            "authors": [
                "B. Back"
            ],
            "title": "PHOBOS Collaboration)",
            "venue": "Nucl. Phys. A 757,",
            "year": 2005
        },
        {
            "authors": [
                "A. Arsence"
            ],
            "title": "BRAHMS Collaboration)",
            "venue": "Nucl. Phys. A 757,",
            "year": 2005
        },
        {
            "authors": [
                "K. Adcox"
            ],
            "title": "PHENIX Collaboration)",
            "venue": "Nucl. Phys. A 757,",
            "year": 2005
        },
        {
            "authors": [
                "L. Adamczyk"
            ],
            "title": "STAR Collaboration)",
            "venue": "Phys. Rev. C 96,",
            "year": 2017
        },
        {
            "authors": [
                "D. Prorok"
            ],
            "title": "Eur",
            "venue": "Phys. J. A 26, 277 ",
            "year": 2005
        },
        {
            "authors": [
                "S. Jowzaee"
            ],
            "title": "Nucl",
            "venue": "Phys. A 967, 792 ",
            "year": 2017
        },
        {
            "authors": [
                "G. Odyniec"
            ],
            "title": "J",
            "venue": "Phys.: Conf. Ser. 455, 012037 ",
            "year": 2013
        },
        {
            "authors": [
                "K. Aamodt"
            ],
            "title": "ALICE Collaboration)",
            "venue": "Phys. Rev. Lett. 106,",
            "year": 2011
        },
        {
            "authors": [
                "J. Adam"
            ],
            "title": "ALICE Collaboration)",
            "venue": "Phys. Rev. Lett. 116,",
            "year": 2016
        },
        {
            "authors": [
                "L.X. Han",
                "G.L. Ma",
                "Y.G. Ma",
                "X.Z. Cai",
                "J.H. Chen",
                "S. Zhang",
                "C. Zhong"
            ],
            "title": "Phys",
            "venue": "Rev. C 84, 064907 ",
            "year": 2011
        },
        {
            "authors": [
                "K. Adcox"
            ],
            "title": "PHENIX Collaboration)",
            "venue": "Phys. Rev. Lett. 86,",
            "year": 2001
        },
        {
            "authors": [
                "M.L. Miller",
                "K. Reygers",
                "S.J. Sanders",
                "P. Steinberg"
            ],
            "title": "Annu",
            "venue": "Rev. Nucl. Part. Sci. 57, 205 ",
            "year": 2007
        },
        {
            "authors": [
                "C. David",
                "M. Freslier",
                "J. Aichelin"
            ],
            "title": "Phys",
            "venue": "Rev. C 51, 1453 ",
            "year": 1995
        },
        {
            "authors": [
                "C. Loizides",
                "J. Kamin"
            ],
            "title": "and D",
            "venue": "d\u2019Enterria, Phys. Rev. C 97, 054910 ",
            "year": 2018
        },
        {
            "authors": [
                "F. Li",
                "Y. Wang",
                "Z. Gao",
                "P. Li",
                "H. L\u00fc",
                "Q. Li",
                "C.Y. Tsang",
                "M.B. Tsang"
            ],
            "title": "Phys",
            "venue": "Rev. C 104, 034608 ",
            "year": 2021
        },
        {
            "authors": [
                "J. De Sanctis",
                "M. Masotti"
            ],
            "title": "M",
            "venue": "Bruno et al., J. Phys. G 36, 015101 ",
            "year": 2009
        },
        {
            "authors": [
                "M. Omana Kuttan",
                "J. Steinheimer",
                "K. Zhou",
                "A. Redelbach",
                "H. Stoecker"
            ],
            "title": "Phys",
            "venue": "Lett. B 811, 135872 ",
            "year": 2020
        },
        {
            "authors": [
                "Y. Huang",
                "L.-G. Pang",
                "X. Luo",
                "X.-N. Wang"
            ],
            "title": "Phys",
            "venue": "Lett. B 827, 137001 ",
            "year": 2022
        },
        {
            "authors": [
                "S.A. Bass",
                "A. Bischoff",
                "C. Hartnack",
                "J.A. Maruhn",
                "J. Reinhardt",
                "H. Stocker",
                "W. Greiner",
                "J. Phys"
            ],
            "title": "G 20",
            "venue": "L21 ",
            "year": 1994
        },
        {
            "authors": [
                "Z.-W. Lin",
                "C.M. Ko",
                "B.-A. Li"
            ],
            "title": "Bin Zhang",
            "venue": "and S. Pal, Phys. Rev. C 72, 064901 ",
            "year": 2005
        },
        {
            "authors": [
                "Z.W. Lin",
                "S. Pal",
                "C.M. Ko",
                "B.A. Li",
                "B. Zhang"
            ],
            "title": "Phys",
            "venue": "Rev. C 64, 011902(R) ",
            "year": 2001
        },
        {
            "authors": [
                "T. Hirano",
                "Y. Nara"
            ],
            "title": "Phys",
            "venue": "Rev. C 79, 064904 ",
            "year": 2009
        },
        {
            "authors": [
                "N. Magdy",
                "J. Phys"
            ],
            "title": "G: Nucl",
            "venue": "Part. Phys. 49, 015105 ",
            "year": 2022
        },
        {
            "authors": [
                "H. Song",
                "U. Heinz"
            ],
            "title": "Phys",
            "venue": "Rev. C 77, 064901 ",
            "year": 2008
        },
        {
            "authors": [
                "X.N. Wang",
                "M. Gyulassy"
            ],
            "title": "Phys",
            "venue": "Rev. D: Part. Fields 44, 3501 ",
            "year": 1991
        },
        {
            "authors": [
                "W.-T. Deng",
                "X.-N. Wang",
                "R. Xu"
            ],
            "title": "Phys",
            "venue": "Rev. C 83, 014915 ",
            "year": 2011
        },
        {
            "authors": [
                "S. Pal",
                "M. Bleicher"
            ],
            "title": "Phys",
            "venue": "Lett. B 709, 82 ",
            "year": 2012
        },
        {
            "authors": [
                "T. Sj\u00f6strand"
            ],
            "title": "Comput",
            "venue": "Phys. Commun. 82, 74 ",
            "year": 1994
        },
        {
            "authors": [
                "B. Zhang"
            ],
            "title": "Comput",
            "venue": "Phys. Commun. 109, 193 ",
            "year": 1998
        },
        {
            "authors": [
                "B.A. Li",
                "C.M. Ko"
            ],
            "title": "Phys",
            "venue": "Rev. C 52, 2037 ",
            "year": 1995
        },
        {
            "authors": [
                "J. Xu",
                "C.M. Ko"
            ],
            "title": "Phys",
            "venue": "Rev. C 83, 034904 ",
            "year": 2011
        },
        {
            "authors": [
                "U. Heinz",
                "H. Song",
                "A.K. Chaudhuri"
            ],
            "title": "Phys",
            "venue": "Rev. C 73, 034904 ",
            "year": 2006
        },
        {
            "authors": [
                "H. Song",
                "U. Heinz"
            ],
            "title": "Phys",
            "venue": "Rev. C 78, 024902 ",
            "year": 2008
        },
        {
            "authors": [
                "C. Shen",
                "U. Heinz",
                "P. Huovinen",
                "H. Song"
            ],
            "title": "Phys",
            "venue": "Rev. C 82, 054904 ",
            "year": 2010
        },
        {
            "authors": [
                "P.F. Kolb",
                "J. Sollfrank",
                "U. Heinz"
            ],
            "title": "Phys",
            "venue": "Lett. B 459, 667 (1999); Phys. Rev. C 62, 054909 ",
            "year": 2000
        },
        {
            "authors": [
                "P. Huovinen",
                "P. Petreczky"
            ],
            "title": "Nucl",
            "venue": "Phys. A 837, 26 ",
            "year": 2010
        },
        {
            "authors": [
                "W. Israel"
            ],
            "title": "Ann",
            "venue": "Phys. (NY) 100, 310 ",
            "year": 1976
        },
        {
            "authors": [
                "W. Israel",
                "J.M. Stewart"
            ],
            "title": "Ann",
            "venue": "Phys. (NY) 118, 341 ",
            "year": 1979
        },
        {
            "authors": [
                "J.P. Boris",
                "D.L. Boon",
                "J. Comput"
            ],
            "title": "Phys",
            "venue": "11, 38 ",
            "year": 1973
        },
        {
            "authors": [
                "M. He",
                "R.J. Fries",
                "R. Rapp"
            ],
            "title": "Phys",
            "venue": "Rev. C 85, 044911 ",
            "year": 2012
        },
        {
            "authors": [
                "F. Cooper",
                "G. Frye"
            ],
            "title": "Phys",
            "venue": "Rev. D: Part. Fields 10, 186 ",
            "year": 1974
        },
        {
            "authors": [
                "G.S. Denicol",
                "C. Gale",
                "S. Jeon",
                "A. Monnai",
                "B. Schenke",
                "C. Shen"
            ],
            "title": "Phys",
            "venue": "Rev. C 98, 034916 ",
            "year": 2018
        },
        {
            "authors": [
                "I.H. Sarker",
                "SN Comput"
            ],
            "title": "Sci",
            "venue": "2, 160 ",
            "year": 2021
        },
        {
            "authors": [
                "K. Taunk",
                "S. De",
                "S. Verma"
            ],
            "title": "and A",
            "venue": "Swetapadma, in 2019 International Conference on Intelligent Computing and Control Systems (ICCS) ",
            "year": 2019
        },
        {
            "authors": [
                "L. Breiman"
            ],
            "title": "Mach",
            "venue": "Learn. 45, 5 ",
            "year": 2001
        },
        {
            "authors": [
                "P. Geurts",
                "D. Ernst",
                "L. Wehenkel"
            ],
            "title": "Mach",
            "venue": "Learn. 63, 3 ",
            "year": 2006
        },
        {
            "authors": [
                "M. Ojala",
                "G.C. Garriga",
                "J. Mach"
            ],
            "title": "Learn",
            "venue": "Research 11, 1833 ",
            "year": 2010
        },
        {
            "authors": [
                "Pedregosa"
            ],
            "title": "Scikit-Learn: Machine learning in python",
            "venue": "J. Mach. Learn. Res",
            "year": 2011
        },
        {
            "authors": [
                "I.T. Jolliffe",
                "J. Cadima"
            ],
            "title": "Philos",
            "venue": "Trans. R. Soc., A 374 20150202 (2016). 014901-13 ABHISEK SAHA, DEBASIS DAN, AND SOMA SANYAL PHYSICAL REVIEW C 106, 014901 ",
            "year": 2022
        },
        {
            "authors": [
                "K. Grebieszkow"
            ],
            "title": "Phys",
            "venue": "Rev. C 76, 064908 ",
            "year": 2007
        },
        {
            "authors": [
                "S.A. Bass",
                "A. Bischoff",
                "J.A. Maruhn",
                "H. Stocker",
                "W. Greiner"
            ],
            "title": "Phys",
            "venue": "Rev. C 53, 2358 ",
            "year": 1996
        },
        {
            "authors": [
                "F. Hu",
                "H. Li"
            ],
            "title": "Math",
            "venue": "Probl. Eng. 2013, 694809 ",
            "year": 2013
        },
        {
            "authors": [
                "H. He",
                "Y. Bai",
                "E.A. Garcia"
            ],
            "title": "and S",
            "venue": "Li, in 2008 IEEE International Joint Conference on Neural Networks ",
            "year": 2008
        },
        {
            "authors": [
                "G. Ke",
                "Q. Meng",
                "T. Finley",
                "T. Wang",
                "W. Chen",
                "W. Ma",
                "Q. Ye",
                "T. Liu"
            ],
            "title": "LightGBM: A Highly Efficient Gradient Boosting Decision Tree",
            "venue": "NIPS ",
            "year": 2017
        },
        {
            "authors": [
                "P. Parfenov",
                "D. Idrisov",
                "V.B. Luong",
                "A. Taranenko"
            ],
            "title": "Particles 4",
            "venue": "275 ",
            "year": 2021
        },
        {
            "authors": [
                "B. Abelev"
            ],
            "title": "ALICE Collaboration)",
            "venue": "Phys. Rev. C 88,",
            "year": 2013
        },
        {
            "authors": [
                "I. Arsene"
            ],
            "title": "BRAHMS Collaboration)",
            "venue": "Phys. Rev. C 72,",
            "year": 2005
        },
        {
            "authors": [
                "B.I. Abelev"
            ],
            "title": "STAR Collaboration)",
            "venue": "Phys. Rev. Lett. 97,",
            "year": 2006
        },
        {
            "authors": [
                "A. Wolterman"
            ],
            "title": "Macalester J",
            "venue": "Phys. Astron. 8, 17 ",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "PHYSICAL REVIEW C 106, 014901 (2022)\nMachine-learning model-driven prediction of the initial geometry in heavy-ion collision experiments\nAbhisek Saha ,1 Debasis Dan,2 and Soma Sanyal1 1School of Physics, University of Hyderabad, Gachibowli, Hyderabad, 500046 India\n2Microsoft India (R & D) Pvt. Ltd. Microsoft Campus, ISB Road, Gachibowli, Hyderabad, 500032 India\n(Received 30 March 2022; accepted 9 June 2022; published 5 July 2022)\nWe demonstrate high prediction accuracy of three important properties that determine the initial geometry of the heavy-ion collision (HIC) experiments by using supervised machine learning (ML) methods. These properties are the impact parameter, the eccentricity, and the participant eccentricity. Although ML techniques have been used previously to determine the impact parameter of these collisions, we study multiple ML algorithms, their error spectrum, and sampling methods using exhaustive parameter scans and ablation studies to determine a combination of efficient algorithm and tuned training set that gives multifold improvement in accuracy for all three different heavy-ion collision models. The three models chosen are a transport model, a hydrodynamic model, and a hybrid model. The motivation of using three different heavy-ion collision models was to show that even if the model is trained using a transport model, it gives accurate results for a hydrodynamic model as well as a hybrid model. We show that the accuracy of the impact-parameter prediction depends on the centrality of the collision. With the standard application of ML training methods, prediction accuracy is considerably low for central collisions. Our method increases this accuracy by multiple folds. We also show that the eccentricity prediction accuracy can be improved by inclusion of the impact parameter as a feature in all these algorithms. We discuss how the errors can be minimized and the accuracy can be improved to a great extent in all the ranges of impact-parameter and eccentricity predictions.\nDOI: 10.1103/PhysRevC.106.014901\nI. INTRODUCTION\nEver since the first run of the heavy-ion collision experiments, a lot of studies have been carried out describing and analyzing the data that we get from these experiments [1\u20133]. The beam energy scan program of the BNL Relativistic Heavy Ion Collider (RHIC) runs the collider experiments using AuAu nuclei at collision energies from 7.7 to 200 GeV [4\u20137]. One of their important aims is to search for the critical point in the QCD phase diagram [8]. The matter created in these experiments has a high baryon density. On the other hand, PbPb collisions are conducted at the LHC at collision energies of 2.76 TeV [9], 5.02 TeV [10], the aim of these experiments is to examine the high-temperature region of the QCD phase diagram. The distribution of particles in the initial stage is different for different collision systems and this affects the final stage particle spectra and the anisotropic flows [11]. The primary data we get from these experiments are the transverse momentum (pT ) spectra, the rapidity (y) spectra, the pseudorapidity (\u03b7) spectra, the particle-antiparticle ratios, and the multiplicity fluctuations. Some phenomena, e.g., the\nPublished by the American Physical Society under the terms of the Creative Commons Attribution 4.0 International license. Further distribution of this work must maintain attribution to the author(s) and the published article\u2019s title, journal citation, and DOI. Funded by SCOAP3.\nanisotropic flows, can be obtained directly from these data. But some parameters are difficult to calculate directly from the experimental data. These are the impact parameter, the initial state geometry parameters, (e.g., eccentricities) event plane angles, etc. The impact parameter is the distance between the centers of the colliding nuclei on the transverse plane of the collision. In experiments, the data are always studied with respect to the centrality of the collision because we get different spectra for different centrality collisions. The highcentrality collisions are those where the impact parameter is close to zero i.e., the head-on collisions. The peripheral collisions refer to the higher values of the impact parameter. The collision centrality plays an important role in determining the final particle spectra. The multiplicity distribution of different species is observed to depend on the centrality of the collision. In Refs. [6,12], the multiplicity fluctuations at different centralities are studied at RHIC energies, and in Refs. [9,10,13], the same has been studied at collision energies 2.76, 5.02, and 5.44 TeV, respectively. The centrality is not a property that can be attained directly from the experiments, but it can be calculated with the help of theoretical modeling by using the Glauber model [14] or some other similar model. The impact parameter as well as the initial geometry of the collision is difficult to determine experimentally. This is true especially for the more central collisions. That is why there are various proposals to determine the impact parameter. Apart from different simulations and algorithms, neural networks have also been proposed to determine the impact parameter from the experimental data [15].\n2469-9985/2022/106(1)/014901(14) 014901-1 Published by the American Physical Society\nThe determination of the impact parameter is related to the charged multiplicity produced during the heavy-ion collision. The charged particle multiplicity has a contribution from hard and soft collision processes, which in turn depend on the number of participants and also on the number of binary collisions. If x is the fraction of contribution from hard processes then the charged particle multiplicity per unit pseudorapidity can be expressed as\ndNch d\u03b7\n= npp [\n(1 \u2212 x)Npart 2\n+ xNcoll ] , (1)\nwhere npp is the multiplicity per unit rapidity in pp collisions and Ncoll is the number of binary NN collision. The number Npart of participant nuclei can be expressed as a function of the impact parameter [14,16]. If TA(s) is the thickness function of nucleus A, i.e., the probability density function of finding nucleons in A, then the number of participants in A at the transverse position s can be found by multiplying with the probability of binary nuclei-nuclei collisions with the nucleons of the nucleus B at the same position (b \u2212 s), where b is the impact parameter. So the total number of participants can be expressed as\nNpart (b) = \u222b TA(s) { 1 \u2212 exp [\u2212\u03c3 NNinel TB(b \u2212 s)]}ds\n+ \u222b TB(b \u2212 s) { 1 \u2212 exp [\u2212\u03c3 NNinel TA(b)]}ds. (2)\nHere the total number of participating nuclei is found out by summing over the contribution from nucleus A and nucleus B. Using Eqs. (1) and (2), the impact parameter, hence centrality, can be estimated by fitting the multiplicity spectra. In this method, the multiplicity fitting must be done for every event to obtain its centrality. An easier way of getting the centrality is to use machine-learning models. Machine learning has been invoked to determine the impact parameter from the experimental data in several papers [17\u201319]. Using machine learning, we can automate the whole process and the impact parameter can be calculated in an efficient way. The advantage of using machine learning (ML) is that it requires less computational power and computational time, which makes the process more agile. Most of the work in this field is related to the deep neural network algorithms. The convoluted neural network has also been used to make predictions about the impact parameter [20]. The first paper to demonstrate the importance of neural network analysis for improving the accuracy of the determination of the impact parameter is Ref. [21]. Using an artificial neural networks (ANNs) or convolutional neural networks (CNNs) they have effectively determined the impact parameter, but these networks require the tuning of hundreds of parameters. This makes the process computationally expensive. On the other hand, different non-neuronal ML models like state vector machine (SVM), random forest, kNN, etc. require fewer parameters to produce results with an accuracy similar to that of the ANN or CNN models. Thereafter, many papers explored various machine-learning algorithms to obtain more accurate results for the impact parameter.\nIn this study, we analyze various machine-learning algorithms and provide a rigorous comparison of the accuracy\nand efficiency of these algorithms by using well-defined techniques of machine learning to show a critical gap in their prediction accuracy for central collisions. We have mainly focused on three properties, impact parameter, eccentricity, and participant eccentricity. We analyze the errors in the predictions and discuss the causes that lead to these errors. We find that the accuracy is less for the low impact parameters. This is an already-known problem in the determination of the impact parameter. We provide a custom sampling method that shows significant improvement in accuracy over commonly used sampling methods in the ML community. We have also used a particular HIC model for training, while the data from two different HIC models have been used to make the predictions. This indicates that, for a well-defined training data set, the predictions for the impact parameter using the ML model are model independent.\nIn this study, the transverse momentum (pT ) spectra are taken as features and the impact parameter, eccentricity, and participant eccentricity are taken as the target variable which the model must predict. We have used a multiphase transport (AMPT) model to generate the transverse momentum spectra of Au-Au collision events at 200 GeV collision energy [22]. The charged particle multiplicity has been studied previously using the AMPT model [23]. As the target variables are known for fitting, we use supervised machine-learning algorithms. Also, the target is a continuous variable so it can have any real value, hence we use regression algorithms.\nThe focus of our study is predicting the impact parameter and the eccentricity. Eccentricity is one of the parameters which gives us the initial geometrical shape of the collision region. This also affects the elliptic flow of produced particles, which is one of the important observables used to study collective behavior in heavy-ion collisions. In Ref. [24], the effects of eccentricity fluctuation on the elliptic flow is studied at \u221a s = 200 GeV for Au-Au and Cu-Cu collisions. In a recent study [25], the flow-harmonics are studied as a function of different components of initial anisotropy using the AMPT model. In our study, the learnings and experiences gathered by the ML models from the impact-parameter prediction are passed on to predict the eccentricity of the initial stage of the heavy-ion collision system. We have also looked at how the inclusion of the impact parameter as a feature affects the prediction accuracy. We have made predictions of the initialstate anisotropy, using the impact parameter. The initial-state anisotropy is given by [16],\nn(b) = \u3008r n cos (n\u03c6 \u2212 n\u03c8 )\u3009\nrn , (3)\nwhere r = (x2 + y2)1/2, \u03c8 = tan\u22121(y/x), n = 2 gives the eccentricity, and n = 3 gives the triangularity. The above eccentricities are with respect to the reaction plane. We have also trained the model to predict participant plane eccentricity, which is given by [24]\npart = \u221a\n\u03c3 2y \u2212 \u03c3 2x + 4\u03c3 2xy \u03c3 2y + \u03c3 2x , (4)\n014901-2\nwhere the \u03c3 are the variances of the positions of the particles, \u03c3 2x = \u3008x2\u3009 \u2212 \u3008x\u30092, \u03c3 2y = \u3008y2\u3009 \u2212 \u3008y\u30092, and \u03c3xy = \u3008xy\u3009 \u2212 \u3008x\u3009\u3008y\u3009. Here \u3008 . . .\u3009 is the average over the transverse plane.\nThe AMPT is a transport model which has been used extensively to model the different stages of the heavy-ion collision from the initial collision dynamics to the final stage hadron dynamics. However, like all models, it has certain drawbacks. There are alternate simulations based on hydrodynamics which also give reliable outputs which match well with the data. In this study, we have taken the results from other models, too. This is to test if the predictions of the ML algorithms depend crucially upon the nature of the model used. Our results show that, as long as the models accurately reflect the experimental data, the ML algorithms do not distinguish between the different models. A ML algorithm trained on a specific model gives pretty accurate results when tested with the data generated by a different model.\nThe two other heavy-ion collision models used in this study are VISH2 + 1 [viscous Israel Stewart hydrodynamics in (2 + 1) dimensions] [26] and a hybrid model made of a hydro evolution model and a hadronic cascade model [27]. These two models are different from the AMPT model which is used to train the ML algorithms. So the ML models train from the pT spectra and the impact-parameter data of AMPT events and predicts impact parameters by using test data of pT spectra from the VISH2 + 1 and the hybrid models. We choose the initial conditions of different models such that they generate the pT spectra close to the one that is obtained in the actual experiments. In this way, we are examining the efficiency of the ML algorithms in a model-independent manner. However, the model-independency is limited only to those models which generate the pT spectra close to the experimental pT spectrum. The pT spectra of the hydro and the hybrid model are fit to the experimental pT spectra to measure the effectiveness of ML models to reproduce the experimental data.\nIn Sec. II, we give a brief description of the heavy-ion collision models used in this study. In Sec. III, we talk about the ML models used in this study. We also describe the parameters used to check the accuracy of different ML models. The learning process of various algorithms as well as the tuning of the hyperparameters are given in this section. We have also used rebalancing techniques to improve the accuracy of the results. These rebalancing techniques are discussed in this section. Section IV discusses the results and the predictions made by the ML models of the eccentricity and the participant eccentricity. It also discusses the ranges of eccentricity where optimum accuracy has been observed. The efficiency of predicting the impact parameter using unknown data of different HIC models and experimental data is discussed in this section. In the end, we show how the accuracy can be improved by rebalancing the dataset. We then summarize the paper in Sec. V."
        },
        {
            "heading": "II. EVENT GENERATION",
            "text": ""
        },
        {
            "heading": "A. The AMPT model",
            "text": "The AMPT model is a publicly available heavy-ion collision model which generates heavy-ion collision events. It is often\nused to understand the results obtained from experiments and it has successfully given the results which match well with the experimental observations [22]. There are two versions of AMPT. In both, the initial condition is generated by the HIJING model [28\u201330]. Here the initial configuration of nucleons is determined by the Glauber model with a Woods-Saxon nuclear distribution. Particle production from two colliding nuclei is given in terms of two processes. In hard processes, the momentum transfer is larger and they are described by pQCD and they produce minijets. The soft processes are those where the momentum transfer is lower and described by the nonperturbative process by the formation of strings. Of the two models, in the default version, the partons recombine with their parent strings after the end of interaction in the partonic state and forms hadrons using the Lund String fragmentation model [31]. In the string melting (SM) version of AMPT, the strings are converted to their valence quarks and antiquarks. The partonic stage interactions are described by Zhang\u2019s parton cascade (ZPC) where the interactions are described by the Boltzmann equations [32]. The scattering cross section of the parton interactions is calculated using pQCD. The simplified relation between total parton elastic-scattering cross-section and the medium induced screening mass is taken as\n\u03c3 \u2248 9\u03c0\u03b1 2 s\n2\u03bc2 , (5)\nwhere \u03b1s, the strong-coupling constant and \u03bc, the screening mass, taken as 0.33 and 3 fm\u22121, respectively, for a total cross section of 3 mb. When the partons stop interacting, they are hadronized by a quark coalescence model. Here the nearest quark-antiquark pair is converted into a meson and the three nearest quarks or antiquarks are converted into a baryon or an antibaryon. The hadronic dynamics are described by a relativistic transport (ART) model [33]. We have used both the versions of the AMPT model. In all the collision setup, we use Au-Au collision at 200 GeV collision energy. Different centralities are considered for different purposes. The other settings are the same as the parameters taken in Refs. [23,34]."
        },
        {
            "heading": "B. The VISH2 + 1 model",
            "text": "VISH2 + 1 is a publicly available code where the evolution of the system created in heavy-ion collisions is described by relativistic causal viscous hydrodynamics [26,35,36]. The code has been tested extensively and successfully reproduces the results from experiments [37]. The initial distribution is taken from the Glauber model in terms of energy-momentum tensor T mn. Then it solves the local energy-momentum conservation equation dmT mn = 0, where\nT mn = eumun \u2212 p mn + \u03c0mn. (6) Here mn = gmn \u2212 umun, um and un are the velocity components, and p is the pressure. \u03c0mn is the viscous shear pressure which follows the evolution equation,\nD\u03c0mn = 1 \u03c4\u03c0 (2\u03b7\u03c3 mn \u2212 \u03c0mn) \u2212 (um\u03c0nk \u2212 un\u03c0mk )Duk (7)\n014901-3\nD = umdm and the symmetric and traceless shear tensor is given by, \u03c3 mn = 12 (\u2207mun + \u2207num) \u2212 13 mndkuk . The pressure p and the energy density e are related by the equation of state (EoS), which is used to solve the hydrodynamic equations. There are three different EoSs used in this study, EoS-L, SM-EOS Q, and s95p-PCE. The EoS-L is based on lattice QCD data where a smooth crossover transition connects the QGP state to the chemically equilibrated hadron resonance gas (HRG) state [37]. SM-EOS Q is the smoothed version of the EOS Q where a first-order phase transition with a vacuum energy (bag constant) connects the noninteracting QGP state to the chemically equilibrated HRG state [38]. The s95p-PCE equation of state is obtained from fits to lattice QCD data for crossover transition at high temperatures and to a partial chemical equilibrium system of the hadrons at low temperatures [39].\nIn the Israel-Stewart [40,41] framework, the generalized hydrodynamic equation of an energy-momentum tensor T mn, together with viscous pressure contributions \u03c0mn is solved with a collision timescale \u03c4\u03c0 (relaxation time). The longitudinal boost-invariance is implemented and seven equations are solved, three for the T \u03c4\u03c4 , T \u03c4x, and T \u03c4y and four for the \u03c0mn. Here a flux-corrected transport (FCT) algorithm called a sharp and smooth transport algorithm (SHASTA) [42] is used to solve the hydrodynamic and kinetic equations. It has two stages. In the transport stage, the multidimensional calculations are simplified in terms of geometric interpretation, which is followed by an antidiffusive or corrective stage. This technique is also applied in codes like AZHYDRO [43]. The final spectra are obtained on a freeze-out hypersurface where the fluid stops interacting. The freeze-out is computed using the Cooper-Frye procedure [44] at a decoupling temperature Tdec. Here the ISPECTRA (iS) code is used, which is a fast Cooper-Frye particle momentum distribution technique that gives discrete momentum distribution of the desired hadron species [45]. We get events of emitted hadrons similar to the events generated in experiments which are then used for ML model predictions."
        },
        {
            "heading": "C. Hybrid model",
            "text": "We have used the IEBE-VISHNU code package [27], which is a hybrid model made by combining a (2 + 1)-dimensional viscous hydrodynamic model and a hadronic cascade model. Instead of using the whole package, we have used the modules separately for better handling of inputs and outputs. The output of the iS particle sampler obtained at the end of hydro evolution is used for hadronic rescatterings. Here, the UrQMD after-burner package is used to serve this purpose. After the particlization, the hadrons are produced on the hypersurface with individual production time and location. The position and momenta along with the ids are then written in a standard OSCAR1997A format which is suitable for hadronic rescattering [46]. This is done using the OSCAR to UrQMD converter routine. This also propagates all the hadrons backward in time so that all of them have a fixed initial time and the Boltzmann collision integral can be performed in the UrQMD model.\nUltrarelativistic quantum molecular dynamics (UrQMD) is a transport model where the dynamics of the hadrons are mod-\neled [47,48]. UrQMD can generate a whole collision system starting from the nuclear collision to the hadronic spectra but here we have only used it to get the hadronic evolution. The interaction among the hadrons is evaluated using the Boltzmann equation for the distribution of all hadrons. The system evolves through binary collisions or by 2-N-body decays. Fifty-three baryon species and 24 different meson species, along with their resonances, antiparticle states, and isospinprojected states are considered in the UrQMD interactions. The interaction among the hadrons and their resonances in this model are described in Ref. [48]."
        },
        {
            "heading": "III. MACHINE LEARNING METHODS",
            "text": ""
        },
        {
            "heading": "A. Machine-learning algorithms and tuning of hyperparameters",
            "text": "As mentioned in the introduction, there are various ML algorithms that we have tested for this study e.g., k-nearestneighbors, gradient boosting regression, decision trees, etc. Details of these ML algorithms are available in Ref. [49]. The accuracy of these models has been tested using standard measures such as R-squared, the root mean square error (RMSE), the mean squared error (MSE), and the mean absolute error (MAE). After running various ML algorithms, we find that although all the algorithms give very good predictions for the impact parameter, only three of them perform well for the eccentricity prediction. Hence, we concentrate only on these three algorithms. They are the k-nearest-neighbors (kNN), extra-trees regressor (ET), and the random forest regressor (RF) model. In kNN model, the target is predicted by doing a local interpolation of the target associated with the k nearest neighbors of the training dataset [50]. ET and RF are types of ensemble methods. In RF, the decision trees are made during the training and a mean of the ensemble is calculated [51]. In ET, randomized decision trees are considered that are made of subsamples of the training dataset [52]. We have used a 10-fold cross-validation (CV) to obtain a robust estimate of the parameters [53]. This also gives a bias-variance trade-off.\nSince we have used these ML algorithms for studying the data from three different HIC models, we have standardized the data before processing them. In this study, we are using the pT spectra of charged particles as features in the dataset. The pT spectra is obtained for the midrapidity region with a rapidity window of \u22120.5 to 0.5. All the pT bins have a different range of values. The difference is more significant when we compare a lower-pT bin with a higher-pT bin. Thus, it is important to make them standardized. This makes the model compatible with a new dataset coming from a different HIC model. Two types of scaling are used in this study, (i) the standard scaler or Z-score normalization and (ii) the min-max scaler [54]. To use both of these scaling techniques, we have used python sklearn.preprocessing library [55]. In most of the cases discussed in this study, we observe that the Z-score method provides an accuracy greater than the min-max scaling by 4% to 6%. So, in all the cases, we have used the Z-score standardization.\nAfter standardization, the pT spectra serve as the features in the dataset and the target variables are the impact parameter, the eccentricity, and the participant eccentricity. When the\n014901-4\nimpact parameter is used as the target variable, only the pT spectra is used as feature variables. For the other targets, the predicted impact parameter is included in the dataset as a feature variable as all the other targets have a dependency on the impact parameter. In this way, all the dependent variables\ncan be measured just by giving the pT spectra as inputs. A standard training and test set separation was done for model evaluation.\nIt is important to have enough events to achieve the best accuracy without consuming too many computing resources. The learning curve of a machine-learning model tells us how effectively a model is learning throughout its running time. We present the learning experience as a function of events. In Fig. 1, the learning curves of the kNN (green circles), ET (orange triangles), and RF (blue stars) models are shown, where the changes in the cross-validation (CV) accuracy are represented with the number of event iterations. The training score curve is shown only for the kNN model (sky color circles) which shows the accuracy while fitting the training data to the model. In the training case, the accuracy comes to a saturation very early around 3000 events, while the cases of test data accuracy shown by the other curves saturate around 6000 to 8000 events. All the learning in this study are performed over 10 000 events. The shaded area represents the standard deviations in the accuracy score.\nIn Fig. 2, the accuracy plots for impact-parameter predictions using kNN [Fig. 2(a)], ET [Fig. 2(b)], RF [Fig. 2(c)], and linear regression (LR) [Fig. 2(d)] models are shown. The ML models are trained by using the charged particle pT spectra data of the AMPT-SM model. The linear regression algorithm finds a linear relationship between a dependent and one or\n014901-5\nmore independent variables [56]. The prediction is performed by using a test dataset containing pT spectra of more than 4000 events of minimum bias Au + Au collision at 200 GeV. The red line drawn here is the optimum accuracy line and the blue points are the predictions made by the model. The accuracies achieved are 97.11%, 97.03%, 97.05%, and 96.53% for the kNN, ET, RF, and LR models, respectively. All of these accuracies are observed for a random train-test dataset split. The tenfold cross-validation scores of these models are 97.04%, 97%, 97.01%, and 96.56%, respectively. We get an accuracy of more than 95% for the kNN, ET, and RF models when the ML models are trained using the default AMPT model data. In the case of impact-parameter predictions, most of the machine-learning algorithms give a fair level of accuracy without tuning any of the hyperparameters except in certain critical impact-parameter regimes.\nIt is known that the choice of parameters can affect the accuracy of a model. Hyperparameter tuning was done to fix the parameters with minimum error validation set. In Fig. 3(a), the change in the accuracy of a kNN model is shown as a function of the number of nearest neighbors hyperparameter. For every configuration, the model is trained using 12 000 events of minimum bias Au + Au collision, and the impact parameter is taken as the target variable. The highest accuracy\nis attained by the model when the number of nearest neighbors is four or five. This is shown by the green curve which gives the tenfold cross-validation score and the shaded region is the standard deviation. The training score shown by the blue line has a score of 1.00 when the number of nearest neighbors is 1. This is a case of overfitting. For the random forest (RF) model [see Fig. 3(b)], the choice of hyperparameter is the maximum number of levels of the tree. We find that the accuracy saturates for the hyperparameter value of four or five. Like the RF model, we get the maximum CV score of the ET model when the max-depth hyperparameter is four or five. Although the above-mentioned parameters are those that most hamper the accuracy, we fix the other hyperparameters by running the RandomSearchCV function of the sklearn library and checking the accuracy for a different combination of hyperparameters.\nAs discussed earlier, in Fig. 4, we see how the inclusion of the impact parameter as a feature affects the accuracy of eccentricity prediction. As is seen in earlier studies, the eccentricity depends on the centrality of the collision. Here we found that, by the inclusion of the impact parameter as a feature, the accuracy increased in all the centrality ranges.\nThe errors in ML can be reduced by determining the highly correlated features in the data. The principal components analysis (PCA) is the most popular technique used for feature reduction of a large dataset [57]. In this work, we tried the \u201cSelectFromFeature\u201d function from the sklearn library and the PCA method to reduce the colinearity and compared the outcomes with the already-achieved accuracy using all the features. We have only shown the result of the PCA method. In Fig. 5(a), the accuracy score of a kNN model, and in Fig. 5(b), the accuracy score of an ET model are shown as a function of the number of principal components is used. Here the accuracy is observed for the impact-parameter predictions by using the pT distribution dataset of 12 000 minimum-bias\n014901-6\nAu-Au collision events at 200 GeV collision energy. The saturation in the accuracy score is achieved for the use of 7 or more principal components in both cases. Also, using seven components, a variance coverage of 95% can be achieved in the case of impact-parameter predictions. So, it is safe to use seven to eight principal components to get good accuracy without losing any major information. We used seven to eight components for the impact-parameter determination. We also found that at least ten features or ten principal components are needed to obtain an accurate result for the eccentricity and the participant eccentricity. This is expected as the data that we are using is the transverse momentum data. Since the impact parameter is known to be correlated with the transverse momentum data hence, we need a smaller number of features to obtain a high accuracy of prediction [58] for the impact parameter as compared with the eccentricity. In all the eccentricity predictions we use the PCA function to transform the features."
        },
        {
            "heading": "B. Custom resampling for unbalanced training set",
            "text": "The pT spectra we used as a feature are comprised of imbalanced datasets. As we have considered the pT spectra of minimum bias events, there are a smaller number of events for lower impact-parameter values. Thus, the event distribution of pT spectra is left-skewed. The imbalance in the data affects the prediction accuracy of the impact parameter and eccentricity\nin the lower-b region (b 1 fm). As is well known in the literature, the impact parameter is not directly accessible to the experiments. Bass et al. [59] have pointed out that, although most of the experimental observables depend on the impact parameter, the different methods of impact-parameter estimation are usually optimized for the larger impact-parameter range. This means that the experimental results for headon collisions pertaining to the lower impact-parameter range will have higher errors due to the inaccuracy of the impactparameter calculations. Currently, efforts are being made to improve the prediction of the impact parameter in the lower impact-parameter range. This is very important because there are considerable experimental results from head-on collisions which can be better analyzed with an improved prediction of the impact parameter in the lower range. So our aim is to improve the accuracy of the impact parameter in the lower range by balancing the data set appropriately.\nThere are a few sampling techniques in machine learning for rebalancing datasets, e.g., SmoteR and ADASYN [60,61]. These are python packages that increase (oversampling) or decrease (under-sampling) the minority and majority data classes, respectively, by using the neighboring data. We evaluated both techniques with all possible hyperparameter combinations. The results discussed in the next section (Sec. IV C) indicate that we do not have a sufficient increase in the accuracy of the predictions and there is a high chance of central events being predicted as noncentral ones.\nWe then adopt a method of rebalancing the data set using class weights, where different classes are the different impactparameter regimes. The various combinations of distribution region and weights were evaluated through an exhaustive grid search. Based on test set minimum error, we selected events with impact parameter 1.0 fm to be in category 1 and the rest in category 2. The weights assigned to the two classes are in the ratio 4 : 1. This technique has helped us to reduce the errors further and the results are discussed in detail in Sec. IV C."
        },
        {
            "heading": "IV. RESULTS AND DISCUSSIONS",
            "text": "A. Impact parameter and eccentricity prediction\nAs discussed earlier, the eccentricity is one of the key parameters in heavy-ion collisions. It gives information about initial-state geometry and also affects the final-state particle flows. But like the impact parameter, it is difficult to measure eccentricity directly from experiment. Here in this study, the models which are used to get the impact-parameter prediction are also used in eccentricity prediction. In fact, ET, kNN, and RF are the three best-performing algorithms in the case of eccentricity prediction.\nFigure 6 shows the prediction plot of eccentricity using the kNN [Fig. 6(a)] and ET [Fig. 6(b)] models. The accuracies obtained are 97.84% and 95.47%, respectively. This is observed for a randomly split train-test dataset of minimum-bias Au + Au events. The models are trained using 10 000 randomly selected events and the testing is performed over 2000 events, which are shown in Fig. 6. The tenfold cross-validation score is also closer to the accuracy obtained using the random\n014901-7\ntrain-test split dataset, 97.52% for the kNN model and 95.18% for the ET model. The tenfold CV score of RF model is 91.95%. We get accuracy between 87% to 93% when the ML models are trained by using the default AMPT model data.\nFigure 7 shows the prediction plot of participant eccentricity using the kNN [Fig. 7(a)] and ET [Fig. 7(b)] models. The accuracies obtained are 98.16% and 96.21%, respectively. In this case, the tenfold cross-validation scores are 97.58% and 95.25% for the kNN and ET models, respectively, and 93.78% for the RF model. In Table I, a comparison of accuracy for 3(triangularity) is shown. We have used Eq. (3) to obtain 3. Here also the kNN, ET, and RF models perform better than the other ML models. All of the three have an accuracy of over 90%. The light gradient boosting machine (LGBM) model also has an accuracy of over 88% after a tenfold cross validation. This is a tree-based machine-learning model where the tree grows vertically (leaf-wise) [62].\nIn the eccentricity prediction figures (Fig. 7), a small range of eccentricity (0.22\u20130.32) is taken for the model fitting and predictions. It is specifically the range where the maximum\nprediction accuracy is obtained for all the models. One of the reasons behind this is that the distribution of eccentricity over the events is not isotropic. In Fig. 8(a), the distribution of participant eccentricity is shown. Here the vertical axis represents the normalized number of events, and the\nTABLE I. Tenfold cross-validation accuracy of ML models for 3 predictions of minimum-bias Au-Au events at \u221a s = 200 GeV.\nModel R2 MAE RMSE\nk-nearest-neighbor regressor 0.9762 0.001 0.0013 Extra trees regressor 0.9574 0.0013 0.0017 Random forest regressor 0.9216 0.0017 0.0023 Light gradient boosting machine 0.8807 0.0022 0.0029 Decision tree regressor 0.7581 0.0024 0.0041 Gradient boosting regressor 0.6309 0.004 0.005\n014901-8\nhorizontal axis gives the eccentricity range. The peak in the distribution is observed for eccentricities between 0.15 and 0.25. The distribution is thus skewed, which means that we have an imbalanced dataset. So, the eccentricity of maximum events that are occurring fall in a particular range. Hence the model fits well in this range of eccentricity because of a larger number of fitting points. From the graph, we see that the range of eccentricity can be increased further from 0.1 to 0.5. In Fig. 8(b), a prediction plot of participant eccentricity using the kNN model is given for a larger range. Here the events are considered which have eccentricities in the range from 0.1 to 0.5. So, the range has now become three times wider than the previous cases. We observe that the points are wider from the center and away from the 45\u25e6 red line compared with the points in Fig. 7(a). We also see some points which are away and isolated from the bulk distribution. The accuracy is lowered to 78.98% from its previous value of 98.16%. The tenfold cross-validation score is 76% in this case, which is a fair amount of accuracy although it is much lower compared\nwith the maximum accuracy. This means that the range of accuracy can be fixed according to the requirement of the problem. To accommodate a wider eccentricity range, we have to compensate with accuracy. We have also applied different ML algorithms to obtain the accuracy at different collision energies from 20 to 200 GeV for the impact parameter, eccentricity, and the participant eccentricity predictions. For lower collision energies, the number of events required to train a ML model is higher compared with the number of events required for higher collision energies. This is because high multiplicity events are generated at higher collision energies. Thus, the event-by-event averages become stable.\nIn Fig. 9, we plot the error in the impact-parameter prediction as a function of the impact parameter and the eccentricity distribution. The error here is the relative error (RE) which is given by RE = |(bpred \u2212 borg)/borg|, where bpred and borg are the predicted and original value of impact parameter, respectively. We observe that, for all eccentricity and impactparameter ranges, the error is low except for the region where the impact parameter is less than 2 fm. In the majority of the distribution, the difference in the prediction and the original impact parameter is less than 0.5 (shown by the red points) and in some cases, it is less than 1. But for the lower range of impact parameters (b < 2 fm) and eccentricities, we find the difference becomes significantly larger. This is also because of imbalance in the data as discussed. There are comparably large errors for MC-Glauber model predictions of low impact parameters. Large discrepancies are also obtained for events of UrQMD and AMPT with higher charge particle when fit with MC-Glauber model data which are shown in Ref. [63]. In Ref. [64], large errors are observed for the fitting of Glauber model data to the ALICE data. Our results are similar to the recent results obtained from ML using other models like UrQMD, where it was shown that the impact parameters are determined efficiently in all the regions except the very central and the very peripheral regions [65]. This is adequately reflected in\n014901-9\nFig. 9, where a large amount of error is found in the very central region."
        },
        {
            "heading": "B. Results from the different heavy-ion collision models",
            "text": "To check the model dependency, we have used the data from other HIC models and obtained the prediction of the impact parameter. The training of a ML model has been done using the AMPT model data, but the predictions are made for other heavy-ion collision models. The other HIC models used in this study are the VISH2 + 1 model [26] which is a hydrodynamic evolution code and a hybrid model made of the VISH2 + 1 and the UrQMD models [27]. In the hybrid model, the UrQMD code is used for later-stage hadronic rescatterings. The reason for using multiple models is because we want the test set and the training set to come from different models giving the same pT spectra. This would mean that as long as the pT spectra are the same, the ML algorithms will not know which model simulated the test data. As done in the previous cases, here also we have used the transverse momentum spectra of the AMPT model as the features and impact parameters of the corresponding AMPT events as targets for the ML model training. The AMPT events considered here are the minimum-bias Au-Au events of 200 GeV collision energy. The pT spectra of VISH2 + 1 and hybrid model are obtained at the same collision energy and at specific centralities with impact parameters ranging from 0.1 to 14 fm. The parameter settings of the VISH2 + 1 model in this study is similar to the parameters considered in Ref. [37], with the Glauber initial condition, shear viscosity to entropy density ratio \u03b7/s = 0.16, and decoupling temperature Tdec = 160 MeV. The box plot is obtained for the s95p-PCE equation of state. For the hybrid model, we set the \u03b7/s to 0.08, the equation of state used is s95p-PCE, and Tdec = 165 MeV. We got 5000 events each from both of these models at all the impact-parameter ranges separately and fit the average pT spectra to the experimentally obtained pT spectra [66,67]. We considered the 0.15 to 1.4 GeV/c pT range to fit with the experimental spectra and also for ML model training. In this range, VISH2 + 1 data fit well with the experimental data. By doing this we are ensuring that the data are similar to the experiments. In an approximate manner, we are also examining the performance of ML models in case of the use of experimental data as test data for prediction. As we do not have event-by-event experimental data at specific centralities, we have used different HIC models to generate the pT spectra. In this way, we are able to obtain the error distribution of the predictions given by the ML model for a large number of events at specific centralities.\nAll the ML models considered in this study, e.g., kNN, RF, ET, and LR, perform reasonably well for impact-parameter prediction for unknown HIC model test data. In Figs. 10(a) and 10(b), we show the error plots of impact parameter predictions by the kNN model for VISH2 + 1 and hybrid UrQMD models, respectively. These are relative errors, and the box represents the distribution of errors. The middle line inside the box represents the median error, which is in the middle of the box. The top and bottom lines represent the 25th and 75th percentile of the error distribution. The green point is the mean error. In all the boxes, i.e., at all the centralities,\nthe errors are in a normal distribution. This shows a good prediction by the ML model. The end circles are the outliers which are less in number. In both the figures, we find that the error goes down for the higher-impact-parameter events. Above the impact parameter of 2 fm, the prediction errors are very close to zero. Above b = 10 fm, the errors stay low, continuing the previous trend. The three lines in Fig. 10(a) show the mean errors in impact-parameter prediction for different equations of state (EoS). The green (dashed), blue (solid), and yellow (dotted) lines represent the mean errors for s95pPCE, EOS-L, and SM-EOS Q equations of state, respectively. For all the EoS, the trend of error distribution is similar. In Fig. 10(a), we see that, for 0.1 and 0.5 fm impact-parameter events, the relative prediction errors are more than three times and in Fig. 10(b), it is more than five times compared with the real impact parameters. We have considered Au-Au collision events where the most-central collisions of 0%\u20135% centrality are comprised of events of impact parameter range 0 to 3.31 fm [16]. As has been discussed, in the case of experiments, the centrality is found by using the Glauber model. Thus, it is difficult to assign a specific impact parameter, especially in the case of the most-central events. We have seen the same nature in error prediction in Fig. 9 while working with only the AMPT events. In that case, training of the ML\n014901-10\nmodel and the testing are performed with the AMPT events. This is due to the imbalance in the dataset that we are using for the ML model training. Although we get a similar nature of error distribution in all the cases, we used the Glauber initial conditions for the hydro model input. The initial condition from the color glass condensate model can give different pT spectra. To check whether the ML models are effective in\nthis scenario, the parameters of the hydro model should be adjusted such that the pT spectra obtained match well with the experimental pT spectra."
        },
        {
            "heading": "C. Results from rebalancing the data set",
            "text": "A large error [Figs. 9 and 10] is observed in the prediction in the lower impact-parameter range due to the imbalance in the impact-parameter distribution in the training set. We overcome this through a custom sample weighing method, as mentioned in Sec. III B. As mentioned previously in Sec. III B, initially, we used standard packages to rebalance the data. The results are shown in Fig. 11(a) for one of the methods. The others give similar results. Although the error comes down in the lower impact-parameter region compared with the errors obtained in Fig. 9, still we get enough errors that would give a wrong estimate for the low-impact-parameter events. Finally, we give the results of our custom rebalancing method which has been described previously in detail in Sec. III B in Fig. 11(b). With our custom method we were able to minimize the error to less than 1, as shown in Fig. 11(b). This error is acceptable in this impact-parameter range as the prediction made in this range will always fall in the most-central collision category (0%\u20135%) for the Au-Au collisions.\nIt is also interesting to see how the AMPT trained models predict eccentricities when they are introduced to other HIC model data. In Fig. 12(a), we show the distribution of eccentricity with the centrality of 200 GeV AMPT collision events. However, the color plot suggests that there is a linear relationship between the average eccentricity and impact parameter of collision events. We see that the range of eccentricity is lower for lower-impact-parameter values. As we go for higher-impact-parameter events, the range of eccentricity becomes larger. A similar observation has been shown previously in Ref. [68]. In Fig. 12(b), we show the distribution of eccentricity predictions of VISH2 + 1 events for two centrality range. Here also the ML model is trained using minimum-bias AMPT events. The orange dots are the prediction events of 40%\u201380% centrality and the blue dots are the prediction events of 0%\u201310% centrality. In the case of 0%\u201310% centrality range, we get eccentricity distribution in 0 \u2212 0.15 range, which is also in the range of original\n014901-11\ndistribution shown in Fig. 12(a). We get a larger range in eccentricity values in the higher-impact-parameter range, the prediction also gives us the same, as represented by the orange dots. Although this shows the model independence characteristics of the ML models, it is only examined for the Glauber initial conditions of VISH2 + 1 model. We have not used the color glass condensate initial conditions as it is known that it gives a larger anisotropy but it would be interesting to see how the model would perform in that case. We plan to look at these in a later work.\nWe have shown an imbalance in the eccentricity distribution in Fig. 8(a). Due to this imbalance in the distribution, we get an accuracy of more than 95% in eccentricity prediction only when we consider a small range. For bigger range, the CV accuracy dropped down to 76%. A good amount of accuracy can also be achieved for a higher range of eccentricity distribution if the data are rebalanced in a suitable format. We have tried a similar rebalancing technique as is done for the impact-parameter prediction. We took the same number of events from each of the distribution bins and trained the model. The prediction plot is shown in Fig. 13. We observe that the event points are much closer to the optimum accuracy line (red line) compared with Fig. 8(b), which also has the same range of eccentricity. The accuracy obtained in this case is 89.49% with a cross-validation score of 91%. So, using these data-rebalancing techniques, one can improve the performance of these ML models for the prediction of the impact parameter as well as the eccentricities."
        },
        {
            "heading": "V. CONCLUSIONS",
            "text": "We have trained different machine-learning models to predict various initial stage parameters of a heavy-ion collision system using the AMPT model. We have used the pT spectra for training and testing of the ML models. We have chosen these spectra because they are one of the direct observables in heavy-ion collision experiments. We have observed their learning processes and made changes to the hyperparameters\nto get an optimum accuracy in the predictions. Out of the various models tested, we have chosen four models, kNN, RF, ET, and LR, for the prediction of the impact parameter. All the models performed well in the impact-parameter prediction. Most of the algorithms have shown an accuracy of more than 90% in the prediction of the impact parameter. In the case of the eccentricity, and the participant eccentricity prediction, three models, i.e., the kNN, ET, and RF, have performed exceptionally well and have given an accuracy of more than 90% after a tenfold cross-validation. These three models along with the decision tree and the light gradient boosting machine have a tenfold cross-validation score of more than 75% in almost all cases. There is a range of eccentricity (0.2\u20130.32) where the optimum accuracy is obtained for the eccentricity predictions. A greater range of eccentricity (0.1\u20130.5) has also been taken into consideration. We find that the choice of the range in eccentricity affects the prediction accuracy of the eccentricity due to the imbalance in the training data distribution.\nWe have also performed an analysis of how the model would possibly perform in predicting the centrality class using experimental data as test data. We have considered two heavy-ion collision models, a viscous hydrodynamic model (VISH2 + 1) and a hybrid model (HYDRO + UrQMD), which are different from the AMPT model that is used for training the machine-learning models. The ML model predictions of impact parameters are obtained for the events of the VISH2 + 1 model and the hybrid model. The hydro and hybrid model events considered for testing are taken at specific impactparameter ranges from 0.5 fm to 14 fm. The ML models (kNN results shown specifically) predicted the centrality classes of these events meticulously well. Although in both cases, we have obtained higher errors for the 0.5 fm events, the errors are very small at other impact parameters. The reason behind this is the lack of balance in the data set. When the data set is normalized, it is found that the peak of the distribution is not at the center. This indicates that the distribution of impact parameter and eccentricity over events are not isotropic.\nTo minimize these errors, we have used various sampling methods. Although there are several standard packages that help to rebalance the data, we finally see that the accuracy is improved in the lower-impact-parameter region if we assign different weights to the data at different impact parameters. For the extratrees model, rarer events are given four times the weight-age as the weight-age given to impact parameters with a large number of events. This has helped improving the accuracy in the lower-impact-parameter range. Our rebalancing technique resulted in a cross-validation accuracy of more than 90% for a higher range of eccentricity distribution. This meant an overall improvement from 75% accuracy before the rebalancing to an accuracy of 90% after the rebalancing. Our study therefore shows a rebalanced data set will be useful in making accurate prediction close to the head-on collisions.\nFinally in conclusion, we have shown that it is possible to use the pT spectra only to make accurate predictions of the initial parameters such as the impact parameter, the eccentricity, and the participant eccentricity using the ML algorithms. Even though the algorithm is trained by a single model, it can make accurate predictions from the data generated by\n014901-12\nother models as long as all the models are able to generate the experimental data accurately. This means that any of the models may be used to train the data set. We have also found that the inaccuracies in the prediction are due to the imbalance in the data set. Proper rebalancing techniques can be used to rebalance the data set and this can be used to predict more accurate results in the low-impact-parameter regime."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "For computational infrastructure, we acknowledge the Center for Modeling, Simulation and Design (CMSD) at the University of Hyderabad, where part of the simulations was carried out. A.S. is supported by INSPIRE Fellowship of the Department of Science and Technology (DST) Govt. of India, through Grant No. IF170627.\n[1] J. Adams et al. (STAR Collaboration), Nucl. Phys. A 757, 102 (2005). [2] B. Back et al. (PHOBOS Collaboration), Nucl. Phys. A 757, 28 (2005). [3] A. Arsence et al. (BRAHMS Collaboration), Nucl. Phys. A 757, 1 (2005). [4] K. Adcox et al. (PHENIX Collaboration), Nucl. Phys. A 757, 184 (2005). [5] L. Adamczyk et al. (STAR Collaboration), Phys. Rev. C 96, 044904 (2017). [6] D. Prorok, Eur. Phys. J. A 26, 277 (2005). [7] S. Jowzaee, Nucl. Phys. A 967, 792 (2017). [8] G. Odyniec, J. Phys.: Conf. Ser. 455, 012037 (2013). [9] K. Aamodt et al. (ALICE Collaboration), Phys. Rev. Lett. 106,\n032301 (2011). [10] J. Adam et al. (ALICE Collaboration), Phys. Rev. Lett. 116,\n222302 (2016). [11] L. X. Han, G. L. Ma, Y. G. Ma, X. Z. Cai, J. H. Chen, S. Zhang,\nand C. Zhong, Phys. Rev. C 84, 064907 (2011). [12] K. Adcox et al. (PHENIX Collaboration), Phys. Rev. Lett. 86,\n3500 (2001). [13] S. Acharya et al. (ALICE Collaboration), Phys. Lett. B 790, 35\n(2019); 788, 166 (2019); R. Rath, S. Tripathy, R. Sahoo, S. De, and Md. Younus, Phys. Rev. C 99, 064903 (2019). [14] M. L. Miller, K. Reygers, S. J. Sanders, and P. Steinberg, Annu. Rev. Nucl. Part. Sci. 57, 205 (2007). [15] C. David, M. Freslier, and J. Aichelin, Phys. Rev. C 51, 1453 (1995). [16] C. Loizides, J. Kamin, and D. d\u2019Enterria, Phys. Rev. C 97, 054910 (2018). [17] F. Li, Y. Wang, Z. Gao, P. Li, H. L\u00fc, Q. Li, C. Y. Tsang, and M. B. Tsang, Phys. Rev. C 104, 034608 (2021). [18] J. De Sanctis, M. Masotti, M. Bruno et al., J. Phys. G 36, 015101 (2009). [19] M. Omana Kuttan, J. Steinheimer, K. Zhou, A. Redelbach, and H. Stoecker, Phys. Lett. B 811, 135872 (2020). [20] Y. Huang, L.-G. Pang, X. Luo, X.-N. Wang, Phys. Lett. B 827, 137001 (2022). [21] S. A. Bass, A. Bischoff, C. Hartnack, J. A. Maruhn, J. Reinhardt, H. Stocker, and W. Greiner, J. Phys. G 20, L21 (1994). [22] Z.-W. Lin, C. M. Ko, B.-A. Li, Bin Zhang, and S. Pal, Phys. Rev. C 72, 064901 (2005). [23] Z. W. Lin, S. Pal, C. M. Ko, B. A. Li, and B. Zhang, Phys. Rev. C 64, 011902(R) (2001). [24] T. Hirano and Y. Nara, Phys. Rev. C 79, 064904 (2009). [25] N. Magdy, J. Phys. G: Nucl. Part. Phys. 49, 015105\n(2022). [26] H. Song and U. Heinz, Phys. Rev. C 77, 064901 (2008).\n[27] C. Shen et al., Comput. Phys. Commun. 199, 61 (2016). [28] X. N. Wang and M. Gyulassy, Phys. Rev. D: Part. Fields 44,\n3501 (1991). [29] W.-T. Deng, X.-N. Wang, and R. Xu, Phys. Rev. C 83, 014915\n(2011). [30] S. Pal and M. Bleicher, Phys. Lett. B 709, 82 (2012). [31] T. Sj\u00f6strand, Comput. Phys. Commun. 82, 74 (1994). [32] B. Zhang, Comput. Phys. Commun. 109, 193 (1998). [33] B. A. Li and C. M. Ko, Phys. Rev. C 52, 2037 (1995). [34] J. Xu and C. M. Ko, Phys. Rev. C 83, 034904 (2011). [35] U. Heinz, H. Song, and A. K. Chaudhuri, Phys. Rev. C 73,\n034904 (2006). [36] H. Song and U. Heinz, Phys. Rev. C 78, 024902 (2008). [37] C. Shen, U. Heinz, P. Huovinen, and H. Song, Phys. Rev. C 82,\n054904 (2010). [38] P. F. Kolb, J. Sollfrank, and U. Heinz, Phys. Lett. B 459, 667\n(1999); Phys. Rev. C 62, 054909 (2000). [39] P. Huovinen and P. Petreczky, Nucl. Phys. A 837, 26 (2010). [40] W. Israel, Ann. Phys. (NY) 100, 310 (1976). [41] W. Israel and J. M. Stewart, Ann. Phys. (NY) 118, 341\n(1979). [42] J. P. Boris and D. L. Boon, J. Comput. Phys. 11, 38 (1973). [43] M. He, R. J. Fries, and R. Rapp, Phys. Rev. C 85, 044911\n(2012). [44] F. Cooper and G. Frye, Phys. Rev. D: Part. Fields 10, 186\n(1974). [45] G. S. Denicol, C. Gale, S. Jeon, A. Monnai, B. Schenke, and C.\nShen, Phys. Rev. C 98, 034916 (2018). [46] https://madai.phy.duke.edu/index1ccc.html?pageid=204 [47] S. A. Bass et al., Prog. Part. Nucl. Phys. 41, 255 (1998). [48] M. Bleicher et al., J. Phys. G 25, 1859 (1999). [49] I. H. Sarker, SN Comput. Sci. 2, 160 (2021). [50] K. Taunk, S. De, S. Verma, and A. Swetapadma, in 2019 In-\nternational Conference on Intelligent Computing and Control Systems (ICCS) (IEEE, Piscataway, NJ, 2019), pp. 1255\u20131260. [51] L. Breiman, Mach. Learn. 45, 5 (2001). [52] P. Geurts, D. Ernst, and L. Wehenkel, Mach. Learn. 63, 3\n(2006). [53] M. Ojala and G. C. Garriga, J. Mach. Learn. Research 11, 1833\n(2010) [54] S. G. Patro and K. Kumar Sahu, IARJSET. Vol. 2, Issue 3,\nMarch 2015. [55] Pedregosa et al., Scikit-Learn: Machine learning in python, J.\nMach. Learn. Res. 12, 2825 (2011). [56] T. Doan and J. Kalita, in 2015 IEEE International Conference on\nData Mining Workshop (IEEE, Atlantic City, NJ, USA, 2015), pp. 1498\u20131505. [57] I. T. Jolliffe and J. Cadima, Philos. Trans. R. Soc., A 374 20150202 (2016).\n014901-13\n[58] K. Grebieszkow, Phys. Rev. C 76, 064908 (2007). [59] S. A. Bass, A. Bischoff, J. A. Maruhn, H. Stocker, and W.\nGreiner, Phys. Rev. C 53, 2358 (1996). [60] F. Hu and H. Li, Math. Probl. Eng. 2013, 694809 (2013). [61] H. He, Y. Bai, E. A. Garcia, and S. Li, in 2008 IEEE Interna-\ntional Joint Conference on Neural Networks (IEEE, Piscataway, NJ, 2008), pp. 1322\u20131328. [62] G. Ke, Q. Meng, T. Finley, T. Wang, W. Chen, W. Ma, Q. Ye, and T. Liu, LightGBM: A Highly Efficient Gradient Boosting Decision Tree, NIPS (Curran Associates, Inc., 2017).\n[63] P. Parfenov, D. Idrisov, V. B. Luong, and A. Taranenko, Particles 4, 275 (2021). [64] B. Abelev et al. (ALICE Collaboration), Phys. Rev. C 88, 044909 (2013). [65] C. Y. Tsang et al., arXiv:2107.13985. [66] I. Arsene et al. (BRAHMS Collaboration), Phys. Rev. C 72,\n014908 (2005). [67] B. I. Abelev et al. (STAR Collaboration), Phys. Rev. Lett. 97,\n152301 (2006). [68] A. Wolterman, Macalester J. Phys. Astron. 8, 17 (2020).\n014901-14"
        }
    ],
    "title": "Machine-learning model-driven prediction of the initial geometry in heavy-ion collision experiments",
    "year": 2022
}