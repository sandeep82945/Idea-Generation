{
    "abstractText": "Thiswork presents an incremental learning approach for autonomous agents to learn new tasks in a non-stationary environment. Updating a DNN model-based agent to learn new target tasks requires us to store past training data and needs a large labeled target task dataset. Few-shot task incremental learning methods overcome the limitation of labeled target datasets by adapting trained models to learn private target classes using a few labeled representatives and a large unlabeled target dataset. However, the methods assume that the source and target tasks are stationary. We propose a one-shot task incremental learning approach that can adapt to non-stationary source and target tasks. Our approach minimizes adversarial discrepancy between the model\u2019s feature space and incoming incremental data to learn an updated hypothesis. We also use distillation loss to reduce catastrophic forgetting of previously learned tasks. Finally, we use Gaussian prototypes to generate exemplar instances eliminating the need to store past training data. Unlike current work in task incremental learning, our model can learn both source and target task updates incrementally. We evaluate our method on various problem settings for incremental object detection and disease prediction model update. We evaluate our approach by measuring the performance of shared class and target private class prediction. Our results show that our approach achieved improved performance compared to existing state-of-theart task incremental learning methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "Abhinit Kumar Ambastha"
        },
        {
            "affiliations": [],
            "name": "Leong Tze Yun"
        }
    ],
    "id": "SP:8161ba35d19ba5917c84cf9b14de7ce346da0b3f",
    "references": [
        {
            "authors": [
                "John Blitzer",
                "Koby Crammer",
                "Alex Kulesza",
                "Fernando Pereira",
                "Jennifer Wortman"
            ],
            "title": "Learning bounds for domain adaptation",
            "venue": "In Advances in neural information processing systems",
            "year": 2008
        },
        {
            "authors": [
                "John Blitzer",
                "Ryan McDonald",
                "Fernando Pereira"
            ],
            "title": "Domain adaptation with structural correspondence learning",
            "venue": "In Proceedings of the 2006 conference on empirical methods in natural language processing. Association for Computational Linguistics,",
            "year": 2006
        },
        {
            "authors": [
                "Youngsang Cho",
                "Joon-Kyung Seong",
                "Yong Jeong",
                "Sung Yong Shin"
            ],
            "title": "andAlzheimer\u2019s Disease Neuroimaging Initiative",
            "venue": "NeuroImage 59,",
            "year": 2012
        },
        {
            "authors": [
                "Kathryn A Ellis",
                "Ashley I Bush",
                "David Darby",
                "Daniela De Fazio",
                "Jonathan Foster",
                "Peter Hudson",
                "Nicola T Lautenschlager",
                "Nat Lenzo",
                "Ralph N Martins",
                "Paul Maruff"
            ],
            "title": "The Australian Imaging, Biomarkers and Lifestyle (AIBL) study of aging: methodology and baseline characteristics of 1112 individuals recruited for a longitudinal study of Alzheimer\u2019s disease",
            "venue": "International psychogeriatrics 21,",
            "year": 2009
        },
        {
            "authors": [
                "Yaroslav Ganin",
                "Evgeniya Ustinova",
                "Hana Ajakan",
                "Pascal Germain",
                "Hugo Larochelle",
                "Fran\u00e7ois Laviolette",
                "Mario Marchand",
                "Victor Lempitsky"
            ],
            "title": "Domain-adversarial training of neural networks",
            "venue": "The Journal of Machine Learning Research 17,",
            "year": 2016
        },
        {
            "authors": [
                "Geoffrey Hinton",
                "Oriol Vinyals",
                "Jeff Dean"
            ],
            "title": "Distilling the knowledge in a neural network",
            "venue": "arXiv preprint arXiv:1503.02531",
            "year": 2015
        },
        {
            "authors": [
                "Judy Hoffman",
                "Trevor Darrell",
                "Kate Saenko"
            ],
            "title": "Continuous manifold based adaptation for evolving visual domains",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "year": 2014
        },
        {
            "authors": [
                "Ehsan Hosseini-Asl",
                "Robert Keynton",
                "Ayman El-Baz"
            ],
            "title": "Alzheimer\u2019s disease diagnostics by adaptation of 3D convolutional network",
            "venue": "In 2016 IEEE international conference on image processing (ICIP)",
            "year": 2016
        },
        {
            "authors": [
                "Jogendra Nath Kundu",
                "Rahul Mysore Venkatesh",
                "Naveen Venkat",
                "Ambareesh Revanur",
                "R Venkatesh Babu"
            ],
            "title": "Class-incremental domain adaptation",
            "venue": "In Computer Vision\u2013ECCV 2020: 16th European Conference,",
            "year": 2020
        },
        {
            "authors": [
                "Zhizhong Li",
                "Derek Hoiem"
            ],
            "title": "Learning without forgetting",
            "venue": "IEEE transactions on pattern analysis and machine intelligence 40,",
            "year": 2017
        },
        {
            "authors": [
                "Siqi Liu",
                "Sidong Liu",
                "Weidong Cai",
                "Hangyu Che",
                "Sonia Pujol",
                "Ron Kikinis",
                "Dagan Feng",
                "Michael J Fulham"
            ],
            "title": "Multimodal neuroimaging feature learning for multiclass diagnosis of Alzheimer\u2019s disease",
            "venue": "IEEE transactions on biomedical engineering 62,",
            "year": 2014
        },
        {
            "authors": [
                "Marc Masana",
                "Xialei Liu",
                "Bartlomiej Twardowski",
                "Mikel Menta",
                "Andrew D Bagdanov",
                "Joost van de Weijer"
            ],
            "title": "Class-incremental learning: survey and performance evaluation",
            "year": 2020
        },
        {
            "authors": [
                "Fei Mi",
                "Lingjing Kong",
                "Tao Lin",
                "Kaicheng Yu",
                "Boi Faltings"
            ],
            "title": "Generalized Class Incremental Learning",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "year": 2020
        },
        {
            "authors": [
                "Sylvestre-Alvise Rebuffi",
                "Alexander Kolesnikov",
                "Georg Sperl",
                "Christoph H Lampert"
            ],
            "title": "icarl: Incremental classifier and representation learning",
            "venue": "In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition",
            "year": 2017
        },
        {
            "authors": [
                "Kate Saenko",
                "Brian Kulis",
                "Mario Fritz",
                "Trevor Darrell"
            ],
            "title": "Adapting visual category models to new domains",
            "venue": "In European conference on computer vision",
            "year": 2010
        },
        {
            "authors": [
                "Kuniaki Saito",
                "Kohei Watanabe",
                "Yoshitaka Ushiku",
                "Tatsuya Harada"
            ],
            "title": "Maximum classifier discrepancy for unsupervised domain adaptation",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition",
            "year": 2018
        },
        {
            "authors": [
                "Tasfia Shermin",
                "Guojun Lu",
                "Shyh Wei Teng",
                "Manzur Murshed",
                "Ferdous Sohel"
            ],
            "title": "Adversarial network with multiple classifiers for open set domain adaptation",
            "venue": "IEEE Transactions on Multimedia",
            "year": 2020
        },
        {
            "authors": [
                "Eric Tzeng",
                "Judy Hoffman",
                "Kate Saenko",
                "Trevor Darrell"
            ],
            "title": "Adversarial discriminative domain adaptation",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "year": 2017
        },
        {
            "authors": [
                "Vladimir Vapnik",
                "Esther Levin",
                "Yann Le Cun"
            ],
            "title": "Measuring the VCdimension of a learning machine",
            "venue": "Neural computation 6,",
            "year": 1994
        },
        {
            "authors": [
                "Han Zhao",
                "Shanghang Zhang",
                "Guanhang Wu",
                "Jos\u00e9 MF Moura",
                "Joao P Costeira",
                "Geoffrey J Gordon"
            ],
            "title": "Adversarial multiple source domain adaptation",
            "venue": "In Advances in neural information processing systems",
            "year": 2018
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Task incremental learning problem applies to non-stationary problem settings where an agent needs to update an existing task model but does not have access to large amounts of labeled data. An example of such a setting is an autonomous agent learning an incremental object detection model. Object detection and computer vision models are helpful in various domains, such as robotics, healthcare, e-commerce, and security. A fixed label set and a stationary input data distribution limits a classification model\u2019s generalization ability in non-stationary or open-set problem settings. We can overcome these bottlenecks using unsupervised task incremental learning and update the model without access to a large replay memory.\nIn a task incremental learning problem, the agent aims to learn an optimal hypothesis for both source and target domains [10, 13, 14, 17, 18]. The source and target are assumed to have undergone a dataset shift [3]. Hence, their shared class instances have a covariate discrepancy. We assume access to a few labeled target private class instances. The current works address task incremental settings at a single time point. We extend this approach to work in nonstationary settings, where the source and target data are assumed\nto be available as a dynamic stream. To this effect we propose a new method for task incremental learning \u2013 Task Incremental Domain Adaptation (TIDo)."
        },
        {
            "heading": "1.1 BACKGROUND",
            "text": "In this section, we explore the background topics for this work and theoretical guarantees to learn a task incremental hypothesis using unlabelled data. We first provide a formal definition for task and task incremental learning.\nDefinition 1. TaskA task is defined as a two-tuple T =< D, \ud835\udc53 \u2032 >, where D is a domain and \ud835\udc53 \u2032 is an approximation of a labeling function for the domain. Learning a task is referred to as learning a close approximation of the aforementioned labeling function.\nDefinition 2. One-shot task incremental learning Given unlabelled target data \ud835\udc65 (\ud835\udc61 )\ud835\udc61 \u2208 U\ud835\udc61 and labelled source domain data \ud835\udc65 (\ud835\udc61 ) \ud835\udc60 \u2208 D\ud835\udc60 The target domain label set is given by \ud835\udc36\ud835\udc61 , the shared source and target label set is given by \ud835\udc36\ud835\udc60 , and target-private label set is given by \ud835\udc36\n\u2032 \ud835\udc61 \ud835\udc36\ud835\udc60 = \ud835\udc36\ud835\udc61\\\ud835\udc36 \u2032 \ud835\udc61 We have been given a single labelled\nsample from \ud835\udc36 \u2032 \ud835\udc61 , \ud835\udc65 (\ud835\udc61 ) \ud835\udc61 . We define task incremental learning as the problem of a target task hypothesis that can predict all labels \ud835\udc36\ud835\udc61 .\nDefinition 3. Hypothesis A hypothesis \u210e \u2208 H refers to an estimate of the labelling function \ud835\udc53 : \ud835\udc65 \u2192 \ud835\udc36 , where, \ud835\udc36 is the label set. The error of a given hypothesis w.r.t. a labelling function for a domain < D, \ud835\udc53 > is given by:\n\ud835\udf16 (\u210e, \ud835\udc53 ) := E\ud835\udc65\u223cD [I(\u210e(\ud835\udc65) \u2260 \ud835\udc53 (\ud835\udc65))], (1) where I is an indicator function.\nFor a given source domain, the true risk of a hypothesis \u210e \u2208 H is \ud835\udf16\ud835\udc46 (\u210e, \ud835\udc53 ). Since \ud835\udf16\ud835\udc60 (\u210e, \ud835\udc53 ) is intractable for most tasks, we use an empirical estimate of the risk, \ud835\udf16\ud835\udc46 (\u210e, \ud835\udc53 ). We assume similar notation for target domain as \ud835\udf16\ud835\udc47 (\u210e, \ud835\udc53 ) and \ud835\udf16\ud835\udc47 (\u210e, \ud835\udc53 ). The goal is to learn an incremental hypothesis \u210e (\ud835\udc61 ) \u2208 H at a time point (\ud835\udc61), whereH is a hypothesis class.\n\u210e (\ud835\udc61 ) = argmin \u210e\u2208H \ud835\udf16 (\ud835\udc61 )\ud835\udc47 (\u210e, \ud835\udc53 ) + \ud835\udc61\u2211\ufe01 \ud835\udc56=0 \ud835\udf16 (\ud835\udc56) \ud835\udc60 (\u210e, \ud835\udc53 )  (2) We handle the limitation of non-stationary source and target tasks using unsupervised domain adaptation. [2] show that for a classification task, empirical error and a measure of disagreement between the optimal hypothesis and the proposed hypothesis bounds the true error of a hypothesis. The authors defined the risk \ud835\udf16\ud835\udc60 (\u210e, \ud835\udc53 ) of a hypothesis \u210e \u2208 H for a given domain \ud835\udc46 , can be defined as the probability that a hypothesis disagrees with the true labeling function \ud835\udc53 of a distribution D\ud835\udc60 [2, 3]:\nar X\niv :2\n30 1.\n12 05\n5v 1\n[ cs\n.L G\n] 2\n8 Ja\nn 20\n23\n\ud835\udf16\ud835\udc60 (\u210e, \ud835\udc53 ) = E\ud835\udc65\u223cD\ud835\udc60 [|\u210e(\ud835\udc65) \u2212 \ud835\udc53 (\ud835\udc65) |] . (3) While referring to risk, we use the shorthand \ud835\udf16\ud835\udc60 (\u210e) = \ud835\udf16\ud835\udc60 (\u210e, \ud835\udc53 ). We use the notation \ud835\udf16\ud835\udc60 (\u210e) to denote the empirical risk of a hypothesis \u210e for domain \ud835\udc46 .\nBlitzer et al. [2] defined \ud835\udc51H\u0394H as the measure of maximum disagreement between any hypothesis in a hypothesis class. For a hypothesis spaceH ,H\u0394H is defined as a symmetric difference hypothesis space:\nH\u0394H = \u210e(\ud835\udc65) \u2295 \u210e \u2032 (\ud835\udc65) : \u210e,\u210e \u2032 \u2208 H , (4)\nwhere \u2295 is the XOR operator. \ud835\udc51H\u0394H was shown to satisfy the following inequality for any\nhypotheses, \u210e,\u210e \u2032 \u2208 H and domains \ud835\udc46 and \ud835\udc47 :\n|\ud835\udf16\ud835\udc60 (\u210e,\u210e\u2217) \u2212 \ud835\udf16\ud835\udc61 (\u210e,\u210e\u2217) | \u2264 1 2 \ud835\udc51H\u0394H (5)\nDefinition 4. Vapnik-Chervonenkis dimension (VC dimension)[20] The Vapnik-Chervonenkis dimension,\ud835\udc49\ud835\udc36 (H), of hypothesis spaceH defined over instance space \ud835\udc4b is the size of the largest finite subset of \ud835\udc4b shattered byH . If arbitrarily large finite sets of \ud835\udc4b can be shattered byH , then \ud835\udc49\ud835\udc36 (H) \u2261 \u221e\nLemma 1.1 shows that we can bind target task risk with source task risk.\nLemma 1.1. [2] For a given source (\ud835\udc46) and target (\ud835\udc47 ) domain, Let H be a hypothesis class and \u210e\u2217 \u2208 H be the optimal hypothesis. Let \ud835\udc51H\u0394H be a symmetric hypothesis space distance. Then for every \u210e \u2208 H we have,\n\ud835\udf16\ud835\udc47 (\u210e) \u2264 \ud835\udf16\ud835\udc47 (\u210e\u2217) + \ud835\udf16\ud835\udc47 (\u210e,\u210e\u2217) \u2264 \ud835\udf16\ud835\udc46 (\u210e) + \ud835\udf06 + 1 2 \ud835\udc51H\u0394H (D\ud835\udc46 ,D\ud835\udc47 ) (6)\nwhere,\n\ud835\udf06 = \ud835\udf16\ud835\udc47 (\u210e\u2217) + \ud835\udf16\ud835\udc60 (\u210e\u2217) (7)\nIn Theorem 1.2, we show that the risk of an incremental model update using target data will be theoretically bounded by the average risk of the source data provided in the iteration. This ensures a theoretical upper bound of model error when a target dataset is used to update an existing model.\nTheorem 1.2. Let D\u0302\ud835\udc47 be the empirically estimated target task distribution and D\u0302 (\ud835\udc61 )\ud835\udc60 be the empirical source distribution. Let \ud835\udc51H\u0394H be a symmetric hypothesis space distance, then for every \u210e \u2208 H , we can show that the true target risk is bound by the average true source risk and the domain discrepancy between D\u0302\ud835\udc47 and D\u0302 (\ud835\udc61 )\ud835\udc60 .\n\ud835\udf16\ud835\udc47 (\u210e) \u2264 1 \ud835\udc61 \ud835\udc61\u2211\ufe01 \ud835\udc56=1 ( \ud835\udf16\ud835\udc46 (\u210e (\ud835\udc56) ) + 1 2 \ud835\udc51H\u0394H (D\u0302 (\ud835\udc56) \ud835\udc46 , D\u0302\ud835\udc47 ) ) + \ud835\udf06\u2217(\ud835\udc61\u22121) (8)\nWhere,\n\ud835\udf06\u2217(\ud835\udc61\u22121) = 1 \ud835\udc61 \ud835\udc61\u2211\ufe01 \ud835\udc56=1 [\ud835\udf16\ud835\udc47 (\u210e (\ud835\udc56\u22121) ) + \ud835\udf16\ud835\udc46 (\u210e (\ud835\udc56\u22121) )] (9)\nIn Theorem 1.3, We show that the risk of an incremental model update is theoretically bounded by the average risk of the previously introduced target data and domain discrepancy between the source and target domains. This shows that the model should be able to learn incrementally using new domain data as long as it has low domain discrepancy compared to the original model source data.\nTheorem 1.3. Let D\ud835\udc47 be the true target task distribution and D (\ud835\udc61 )\ud835\udc60 be the true source distribution. Let \ud835\udc51H\u0394H be a symmetric hypothesis space distance. For every \u210e \u2208 H , we can show that the true target risk is bounded by the average true target risk of the previous increments, the domain discrepancy between D\u0302\ud835\udc47 and D\u0302 (\ud835\udc61 )\ud835\udc60 and the optimal hypothesis risk \ud835\udf06\u2217(\ud835\udc61\u22121) of the existing model.\n\ud835\udf16\ud835\udc47 (\u210e (\ud835\udc61 ) ) \u2264 1 \ud835\udc61 \u00a9\u00ab \ud835\udc61\u2211\ufe01 \ud835\udc56=1 \ud835\udf16\ud835\udc47 (\u210e (\ud835\udc56\u22121) ) + 1 2\ud835\udc61 \ud835\udc61\u2211\ufe01 \ud835\udc56=1 \ud835\udc51H\u0394H (D\ud835\udc46 ,D\ud835\udc47 ) \u00aa\u00ae\u00ac + \ud835\udf06\u2217(\ud835\udc56\u22121)\n(10) Where,\n\ud835\udf06\u2217(\ud835\udc61\u22121) = 1 \ud835\udc61 \ud835\udc61\u2211\ufe01 \ud835\udc56=1 [\ud835\udf16\ud835\udc47 (\u210e (\ud835\udc56\u22121) ) + \ud835\udf16\ud835\udc46 (\u210e (\ud835\udc56\u22121) )] (11)\nIn Theorem 1.4, we can learn an incremental model by reducing the empirical \ud835\udc3b\u2212distance (a measure of domain divergence) between unlabelled source and target domain data. The theorem is an incremental extension of the work by Blitzer et al. [2, 3].\nTheorem 1.4. Let U\u0302 (\ud835\udc61 ) \ud835\udc47 be the empirically estimated unlabelled\ntarget distribution and U\u0302 (\ud835\udc61 ) \ud835\udc60 (\ud835\udc61 )\nbe the empirical unlabelled source empirical distribution. Let \ud835\udc51H\u0394H be a symmetric hypothesis space distance. \ud835\udc5a\u2032 \ud835\udc56 is the size of the unlabelled target and source samples, and \ud835\udc51 is the Vapnik\u2013Chervonenkis dimension of the current hypothesis. Then for every \u210e \u2208 H for a probability at least 1 \u2212 \ud835\udeff ,\n\ud835\udf16\ud835\udc47 (\u210e (\ud835\udc61 ) ) \u2264 1 \ud835\udc61 \ud835\udc61\u2211\ufe01 \ud835\udc56=1 ( \ud835\udf16\ud835\udc46 (\ud835\udc56 ) (\u210e (\ud835\udc56) ) + 1 2 \ud835\udc51H\u0394H (U\u0302 (\ud835\udc61 ) \ud835\udc46 (\ud835\udc56 ) , U\u0302 (\ud835\udc61 ) \ud835\udc47 ) )\n+ 1 \ud835\udc61 \ud835\udc61\u2211\ufe01 \ud835\udc56=1 \u00a9\u00ab4 \u221a 2\ud835\udc51 log(2\ud835\udc5a\u2032 \ud835\udc56 ) + log( 4 \ud835\udeff ) \ud835\udc5a\u2032 \ud835\udc56 \u00aa\u00ae\u00ae\u00ac + \ud835\udf06\u2217(\ud835\udc61\u22121) (12) Where,\n\ud835\udf06\u2217(\ud835\udc61\u22121) = 1 \ud835\udc61 \ud835\udc61\u2211\ufe01 \ud835\udc56=1 [\ud835\udf16\ud835\udc47 (\u210e (\ud835\udc61 ) ) + \ud835\udf16\ud835\udc46 (\u210e (\ud835\udc61 ) )] (13)"
        },
        {
            "heading": "2 RELATEDWORKS",
            "text": "This section explores current works used to learn an autonomous task incremental learning agent.\nLi et al. [11] propose a neural network-based approach (Learning without forgetting) to carry out task incremental learning with minimal increase in parametric space size while satisfying low data resource conditions. The proposed method learns new target private class mappings by adding new neurons to the output layer of a classification network. The goal of the approach is to retain the\nclassification performance for the previous tasks while incrementally learning new tasks or classes. The authors use distillation loss [7] to minimize catastrophic forgetting.\nRebuffi et al. [15] propose a supervised incremental learning approach (Incremental Classifier and Representation Learning) that uses nearest mean matching and class-wise representatives from the input data. The authors update the representative instance sets (referred to as exemplars) using samples from the incremental input data batches. In our work, we address an unsupervised sourcefree approach to overcome the limitation of storing representative examples and the need to label incoming incremental data.\nHoffman et al. [8] provide a supervised approach (continual manifold adaptation) to learn a low dimensional embedding subspace for incoming target data. The work update parametric kernels to model an evolving target task distribution. Using a kernel-based approach is computationally intensive if the target dataset size is large, which limits the scalability of the approach.\nKundu et al. [10] propose a source-free class incremental learning approach that updates a model in a non-stationary environment. The authors provide a way to learn a target model with private and shared classes but assume known target classes at the time of incremental domain adaptation. Our work is an incremental extension of this work. Also, the work addresses domain shift compensation using L2 regularization, which fails to account for unknown classes. We address these challenges using distillation loss to accommodate future target private classes and an adversarial domain confusion loss to minimize domain shift for a non-stationary target domain.\nWe compared our approach to unsupervised domain adaptation methods. Ganin et al. propose the domain adversarial neural network (DANN) [6, 21]. Domain adaptation methods cannot compensate for non-stationary source distribution and do not provide the ability to add target private classes (open-set problem setting). We compare our work with DANN combined with a target private classifier. Due to the few labeled samples available for target private classes, it cannot learn an optimal hypothesis and has low predictive accuracy."
        },
        {
            "heading": "3 OUR APPROACH",
            "text": "Our approach is divided into two stages \u2013 foresighted learning and task incremental update. In the foresighted learning stage, an agent learns a generative model of the source data feature space. Foresighted learning helps the agent to generate representative samples of past data for future incremental model updates. In the task incremental learning stage, the agent updates its internal model state using unlabeled target data and a single labeled sample for target private classes."
        },
        {
            "heading": "3.1 Foresighted learning",
            "text": "This section describes the foresighted learning stage. This stage aims to identify tight class-wise clusters in feature posterior distribution using Gaussian estimation.\nWe denote the feature extractor function as \ud835\udc53\ud835\udc60 and the classifier function as \ud835\udc54\ud835\udc60 , which maps the feature extractor output to a |\ud835\udc36\ud835\udc60 +1|- class label space (where \ud835\udc36\ud835\udc60 is the source task label set size). The latent space is denoted byU. We minimize cross-entropy loss (\ud835\udc59\ud835\udc50\ud835\udc52 )\nto learn \ud835\udc54\ud835\udc60 .\n\ud835\udc59\ud835\udc50\ud835\udc52 = E (\ud835\udc65\ud835\udc60 ,\ud835\udc66\ud835\udc60 )\u223cD (\ud835\udc61 )\ud835\udc60 \ud835\udc59\ud835\udc50\ud835\udc52 (\ud835\udc54\ud835\udc60 \u00b7 \ud835\udc53\ud835\udc60 (\ud835\udc65\ud835\udc60 ), \ud835\udc66\ud835\udc60 ) (14)\nCross-entropy loss ensures discriminative decision boundaries in the latent feature space but leads to over-confident predictions. To generate representative samples for source distribution for future iterations, we minimize category bias by penalizing over-confident prediction.We achieve this by identifying out-of-distribution (OOD) samples. Re-using the trained base model to classify unknown classes leads to negative learning, i.e., and misclassification of instances belonging to unknown classes as one of the known classes. This is due to the inherent generalization bias of the source model. Kundu et al. [10] suggest detecting OOD instances to identify instances belonging to unknown classes. This is based on the understanding that instances from unknown classes lie in low-density regions of the instances of the shared classes. Kundu et al. [10] achieve this by mapping the source instances to a latent space with an underlying global prior distribution given by N(\ud835\udf07, \ud835\udf0e). Next, the instances from the target domain which lie beyond the 3\ud835\udf0e range were considered to belong to unknown classes.\nWe use a class separability objectiveL\ud835\udc601 to enforce the class-wise features to attain higher affinity to the class-wise prototypes.\nL\ud835\udc60 = L\ud835\udc601 + L\ud835\udc602 (15)\nL\ud835\udc601 : E (\ud835\udc65\ud835\udc60 ,\ud835\udc66\ud835\udc60 )\u223cD\ud835\udc60\n\u2212 log [\nexp(P\ud835\udc66\ud835\udc60\ud835\udc60 (\ud835\udc62\ud835\udc60 ))\u2211 \ud835\udc50\u2208\ud835\udc36\ud835\udc60 exp(P\ud835\udc50\ud835\udc60 (\ud835\udc62\ud835\udc60 ))\n] (16)\nL\ud835\udc602 : E (\ud835\udc65\ud835\udc60 ,\ud835\udc66\ud835\udc60 )\u223cD\ud835\udc60\n\ud835\udc59\ud835\udc50\ud835\udc52 (\ud835\udf0e (\ud835\udc54 (\ud835\udc61 )\ud835\udc60 \u00a4\ud835\udc53 (\ud835\udc61 ) \ud835\udc60 (\ud835\udc65\ud835\udc60 ), \ud835\udf0f), \ud835\udc66\ud835\udc60 )\n+ E (\ud835\udc62\ud835\udc5b,\ud835\udc66\ud835\udc5b)\u223cD\ud835\udc5b\n\ud835\udc59\ud835\udc50\ud835\udc52 (\ud835\udf0e (\ud835\udc54 (\ud835\udc61 )\ud835\udc60 (\ud835\udc62\ud835\udc5b), \ud835\udf0f), \ud835\udc66\ud835\udc5b) (17)\nWhere \ud835\udf0e denotes distillation soft loss [7],\n\ud835\udf0e (z, \ud835\udf0f) = \ud835\udc52 \ud835\udc67 \ud835\udf0f\u2211 \ud835\udc52 \ud835\udc67 \ud835\udf0f\n(18)\nD\ud835\udc5b is the distribution of the negative samples, and (\ud835\udc62\ud835\udc5b, \ud835\udc66\ud835\udc5b) represents the negative samples with \ud835\udc66\ud835\udc5b being the ( |\ud835\udc36\ud835\udc60 | + 1)\ud835\udc61\u210e class. Since we don\u2019t need distillation loss for this stage, we set \ud835\udf0f = 1."
        },
        {
            "heading": "3.2 Task incremental update",
            "text": "In this section, we describe the domain incremental update stage of the proposed method. We use the learned prototypes and the unlabeled target domain data to incrementally update the base classifier for the target task. In this stage, we use theU\u2212space guides as shared class cluster centroids and single target private samples as the target private class cluster centroids. We use an encoderdecoder approach to fine-tune theU\u2212space to accommodate target private guides. This way, we learn aU\ud835\udc61\u210e\u2212space which is used to represent previous iteration samples.\nSeveral discrepancy metrics have been proposed to match the moments of the shared class instances from source and target distributions. Adversarially trained domain discriminators are used to reducing the empirical hypothesis distance (\ud835\udc51H\u2207H ) between the source and target distributions, which has been shown to reduce the distance between the source and target distributions.\nWe learn the guides for the target domain, U (\ud835\udc61+1) using the source prototype space U. Using fixed source guides for target space reduces flexibility in accommodating target private classes. We initialize the U (\ud835\udc61+1) guides: \ud835\udc63\ud835\udc50\ud835\udc54 = \ud835\udc53\ud835\udc52 (\ud835\udf07\ud835\udc50\ud835\udc60 )\u2200\ud835\udc50 \u2208 \ud835\udc36\ud835\udc60 and \ud835\udc63\ud835\udc50\ud835\udc54 = \ud835\udc65 (\ud835\udc61 ) \ud835\udc61 \u2200\ud835\udc50 \u2208 \ud835\udc36 \u2032 \ud835\udc61 and calculate confident samples B\ud835\udc50\ud835\udc61 which are pseudolabelled using the guides (\ud835\udc58). We use a domain projection autoencoder to enable mobility of guides explicitly. The target domain contains private class instances which position themselves in the low-density regions of theU\ud835\udc61+1\u2212space. We use a reconstruction loss and L2-norm to maintain the previously learned source guide space (U\u2212space) semantics. By training the auto-encoder layers using the gradient from the classifier and domain discriminator, we adversarially trainU (\ud835\udc61+1)\u2212space.\nThe U (\ud835\udc61+1) guides are aligned using the adversarial domain confusion loss:\nL\ud835\udc51 : \u2212\ud835\udc51H\u2207H (\ud835\udc63\ud835\udc61 , \ud835\udc63\ud835\udc50\ud835\udc54) (19)\nIn order to learn an efficient domain projection \ud835\udc53\ud835\udc52 : U \u2192U (\ud835\udc61+1) and \ud835\udc53\ud835\udc51 : U (\ud835\udc61+1) \u2192 U we use reconstruction error similar to an auto-encoder. We also use distillation loss with \ud835\udf0f = 2 to ensure low catastrophic forgetting for the previously learned shared classes.\nL\ud835\udc5f = L\ud835\udc5f1 + L\ud835\udc5f2 (20)\nL\ud835\udc5f1 : E (\ud835\udc62\ud835\udc50\ud835\udc60 )\u223cP\ud835\udc50\ud835\udc60 \ud835\udc59\ud835\udc50\ud835\udc52 (\ud835\udf0e (\ud835\udc66 (\ud835\udc62\ud835\udc50\ud835\udc60 ), \ud835\udf0f), \ud835\udc50) (21)\nL\ud835\udc5f2 : E (\ud835\udc62\ud835\udc50\ud835\udc60 )\u223cP\ud835\udc50\ud835\udc60 \ud835\udc592 (\ud835\udc53\ud835\udc51 \u00b7 \ud835\udc53\ud835\udc52 (\ud835\udc62\ud835\udc50\ud835\udc60 ), \ud835\udc62\ud835\udc50\ud835\udc60 )2 (22)\nTo learn new target private classes, we apply cross-entropy loss to target confident samples:\nL\ud835\udc50 : E (\ud835\udc65\ud835\udc61 )\u223cB\ud835\udc50\ud835\udc61 \ud835\udc59\ud835\udc50\ud835\udc52 (\ud835\udc66 (\ud835\udc63\ud835\udc61 ), \ud835\udc50),\u2200\ud835\udc50 \u2208 \ud835\udc36\ud835\udc61 (23)"
        },
        {
            "heading": "4 ALGORITHM",
            "text": "Algorithm 1 outlines the task incremental update implementation. We initialize the source generative distribution using the prototypes from the previous stage (line 2). To enable the mobility of guides, we train an auto-encoder network \ud835\udc53\ud835\udc51 (\ud835\udc53\ud835\udc52 (\u00b7)) (line 3-7). We use an \ud835\udc3f2-norm loss as a reconstruction error to train the auto-encoder.\nSince we want the incremental learning agent to learn new classes from the target task, we need to update the guides to include new target class cluster guides. To this effect, we use a single labeled instance (assumed to be available) from each target task class as target class guides (line 13).\nAlgorithm 1 Task Incremental Learning algorithm\n1: Require: Target samples D\ud835\udc61 , Gaussian Prototypes P\ud835\udc50\ud835\udc60 , model parameters \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc60 , \ud835\udf03 \ud835\udc54 (\ud835\udc61 ) \ud835\udc60 , \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc61 , \ud835\udf03 \ud835\udc54 (\ud835\udc61 ) \ud835\udc61 , \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc52 , \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc51\n, \ud835\udf03\ud835\udc51 (\ud835\udc61 ) , training sample size \ud835\udc41 , percentage of confident samples \ud835\udc5b\n2: Initialize: \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc61 \u2190 \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc60 3: repeat 4: Obtain a mini-batch of proxy-source samples \ud835\udc46 = {u\ud835\udc50\ud835\udc60 \u223c P\ud835\udc50\ud835\udc60 : \ud835\udc50 \u2208 C\ud835\udc60 } 5: \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc52 \u2190 \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc52 + Adam{\ud835\udc53 (\ud835\udc61 )\ud835\udc52 } (\u2212\u2207 1 |\ud835\udc46 | \u2211 u\ud835\udc50\ud835\udc60 \u2208\ud835\udc46 \ud835\udc592 (\ud835\udc62 \ud835\udc50 \ud835\udc60 , \ud835\udc53\ud835\udc52 (\ud835\udc62\ud835\udc50\ud835\udc60 ))2) 6: \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc51 \u2190 \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc51 + Adam{\ud835\udc53 (\ud835\udc61 ) \ud835\udc51 } (\u2212\u2207 1 |\ud835\udc46 | \u2211 u\ud835\udc50\ud835\udc60 \u2208\ud835\udc46 \ud835\udc592 (\ud835\udc62 \ud835\udc50 \ud835\udc60 , \ud835\udc53\ud835\udc51 (\ud835\udc62\ud835\udc50\ud835\udc60 ))2) 7: until Convergence 8: Loss\u2190 [L\ud835\udc5f1,L\ud835\udc5f2,L\ud835\udc50 ,L\ud835\udc51 ] 9: Opt\u2190 [Adam{\ud835\udc53 (\ud835\udc61 )\ud835\udc52 ,\ud835\udc53 (\ud835\udc61 )\ud835\udc51 ,\ud835\udc54 (\ud835\udc61 ) \ud835\udc61 } ,Adam{\ud835\udc53 (\ud835\udc61 )\ud835\udc52 ,\ud835\udc53 (\ud835\udc61 )\ud835\udc51 } ,Adam{\ud835\udc53 (\ud835\udc61 )\ud835\udc61 ,\ud835\udc54 (\ud835\udc61 ) \ud835\udc61 } ,\n10: Adam{\ud835\udc53 (\ud835\udc61 )\ud835\udc61 } ,Adam{\ud835\udc53 (\ud835\udc61 )\ud835\udc52 ,\ud835\udc53 (\ud835\udc61 )\ud835\udc61 } ] 11: repeat 12: iter \u2190 iter+1, cur \u2190 iter mod 5 13: v\ud835\udc50\ud835\udc54 \u2190 \ud835\udc53\ud835\udc52 (\ud835\udf07\ud835\udc50\ud835\udc60 )\u2200\ud835\udc50 \u2208 C\ud835\udc60 , v\ud835\udc50\ud835\udc54 \u2190 \ud835\udc53\ud835\udc61 (\ud835\udc65\ud835\udc50\ud835\udc61 )\u2200\ud835\udc50 \u2208 C \u2032 \ud835\udc61 14: for \ud835\udc62\ud835\udc50\ud835\udc60 \u223c P\ud835\udc50\ud835\udc60 : \ud835\udc50 \u2208 C\ud835\udc60 do 15: \ud835\udc63\ud835\udc50\ud835\udc60 \u2190 \ud835\udc53\ud835\udc52 (u\ud835\udc50\ud835\udc60 );\ud835\udc62\ud835\udc50\ud835\udc60 \u2190 \ud835\udc53\ud835\udc51 (\ud835\udc63\ud835\udc50\ud835\udc60 ); 16: \ud835\udc66 \u2190 \ud835\udc54\ud835\udc60 (\ud835\udc62\ud835\udc50\ud835\udc60 ) |\ud835\udc50\u2208C\ud835\udc60 \u2225\ud835\udc54\ud835\udc61 (\ud835\udc63\ud835\udc50\ud835\udc60 ) 17: L\ud835\udc5f1 + \ud835\udc59\ud835\udc5a\ud835\udc60\ud835\udc52 (\ud835\udc62\ud835\udc50\ud835\udc60 , \ud835\udc62\ud835\udc50\ud835\udc60 ) 18: L\ud835\udc50 \u2190 L\ud835\udc50 + \ud835\udc59\ud835\udc50\ud835\udc52 (\ud835\udf0e (\ud835\udc66\ud835\udc60 ), \ud835\udc50) 19: end for 20: for x\ud835\udc61 \u2208 {x\ud835\udc61 \u223c D\ud835\udc61 } do 21: \ud835\udc63\ud835\udc61 \u2190 \ud835\udc53\ud835\udc61 (x\ud835\udc61 ); u\ud835\udc61 \u2190 \ud835\udc53\ud835\udc51 (\ud835\udc63\ud835\udc61 );\ud835\udc66\ud835\udc61 \u2190 \ud835\udc54\ud835\udc60 (\ud835\udc62\ud835\udc61 ) |\ud835\udc50\u2208C\ud835\udc60 \u2225\ud835\udc54\ud835\udc61 (\ud835\udc63\ud835\udc61 ) 22: \ud835\udc51 \u2190 min\ud835\udc50\u2208C\ud835\udc61 \ud835\udc592 (\ud835\udc63\ud835\udc61 , \ud835\udc63\ud835\udc50\ud835\udc54);\ud835\udc58 \u2190 arg min(\ud835\udc51) 23: L\ud835\udc5f2 \u2190 L\ud835\udc5f2 + \ud835\udc59\ud835\udc5a\ud835\udc60\ud835\udc52 (u\ud835\udc61 , \ud835\udc63\ud835\udc61 ) 24: end for 25: for \ud835\udc62\ud835\udc50\ud835\udc60 \u223c P\ud835\udc50\ud835\udc60 , x\ud835\udc61 \u2208 {x\ud835\udc61 \u223c D\ud835\udc61 } do 26: \ud835\udc63 \u2190 \ud835\udc53\ud835\udc61 (x\ud835\udc61 ); \ud835\udc66\ud835\udc51 \u2190 \ud835\udc51 ( [\ud835\udc62\ud835\udc50\ud835\udc60 , \ud835\udc63]); 27: L\ud835\udc51 \u2190 L\ud835\udc51 + \ud835\udc59\ud835\udc50\ud835\udc52 (\ud835\udc66\ud835\udc51 , [0, 1]) 28: end for 29: if reached the end of an epoch then 30: UpdateTaskIncrementalGradients(Loss,Opt) 31: Label samples in D\ud835\udc61 using guides {\ud835\udc63\ud835\udc50\ud835\udc54 : \ud835\udc50 \u2208 C\ud835\udc61 } 32: P\ud835\udc50\ud835\udc61 \u2190Gaussian Prototypes obtained using pseudo-label\ntarget samples 33: end if 34: until Convergence\nIn line 14-19, we fine-tune the feature extractor network using samples from the class-wise prototype distributions. We assume an open-set problem setting, and the target domain data is assumed to contain instances from the source domain. To learn a single classifier for source and target tasks, we pass the unlabeled target instances and source domain samples to both the source domain classifier and target domain classifier. In line 20-24, we obtain the pseudo-labels for the target domain data along with the predictions from the updated joint classifier.\nTo align the source and target domain distributions, we use a domain discriminator network, which trains the feature extractor adversarially along with the joint classifier loss (line 25-28). Finally, we update the parameters of all the components of the task incremental network and update the prototypes (line 29-33). The updated prototypes will serve as the source prototypes in the next iteration, along with the new source domain (if any) to generate the samples. The gradient update algorithm (algorithm 2) provides the gradient update step for the task incremental learning network components.\nAlgorithm 2 Gradient update algorithm\n1: Require: Model parameters, Loss, Opt 2: \ud835\udf03\n\ud835\udc53 (\ud835\udc61 ) \ud835\udc61 \u2190 \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc61 + Adam{\ud835\udc53 (\ud835\udc61 )\ud835\udc61 } (\u2212\u2207 1 \ud835\udc41 \u2211L\ud835\udc50 ) 3: \ud835\udf03\ud835\udc51 (\ud835\udc61 ) \u2190 \ud835\udf03\ud835\udc51 (\ud835\udc61 ) \u2212 Adam{\ud835\udc51 (\ud835\udc61 ) ,\ud835\udc53 (\ud835\udc61 )\ud835\udc61 } (\u2212\u2207 1 \ud835\udc41\n\u2211L\ud835\udc51 ) 4: \ud835\udf03\n\ud835\udc53 (\ud835\udc61 ) \ud835\udc61 \u2190 \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc61 \u2212 Adam{\ud835\udc51 (\ud835\udc61 ) ,\ud835\udc53 (\ud835\udc61 )\ud835\udc61 } (\u2212\u2207 1 \ud835\udc41 \u2211L\ud835\udc51 ) 5: \ud835\udf03\n\ud835\udc53 (\ud835\udc61 ) \ud835\udc61 \u2190 \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc61 \u2212 Adam{\ud835\udc53 (\ud835\udc61 )\ud835\udc61 } (\u2212\u2207 1 \ud835\udc41 \u2211L\ud835\udc5f1) 6: \ud835\udf03\n\ud835\udc53 (\ud835\udc61 ) \ud835\udc52 \u2190 \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc52 + Adam{\ud835\udc53 (\ud835\udc61 )\ud835\udc52 ,\ud835\udc53 (\ud835\udc61 )\ud835\udc51 } (\u2212\u2207 1 \ud835\udc41 \u2211L\ud835\udc5f1) 7: \ud835\udf03\n\ud835\udc53 (\ud835\udc61 ) \ud835\udc51 \u2190 \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc51 + Adam{\ud835\udc53 (\ud835\udc61 )\ud835\udc52 ,\ud835\udc53 (\ud835\udc61 )\ud835\udc51 } (\u2212\u2207 1 \ud835\udc41 \u2211L\ud835\udc5f1) 8: \ud835\udf03\n\ud835\udc53 (\ud835\udc61 ) \ud835\udc61 \u2190 \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc61 + Adam{\ud835\udc53 (\ud835\udc61 )\ud835\udc61 } (\u2212\u2207 1 \ud835\udc41 \u2211L\ud835\udc5f2) 9: \ud835\udf03\n\ud835\udc53 (\ud835\udc61 ) \ud835\udc51 \u2190 \ud835\udf03 \ud835\udc53 (\ud835\udc61 ) \ud835\udc51 + Adam{\ud835\udc53 (\ud835\udc61 ) \ud835\udc51 } (\u2212\u2207 1 \ud835\udc41 \u2211L\ud835\udc5f2)"
        },
        {
            "heading": "5 EXPERIMENTS AND RESULTS",
            "text": ""
        },
        {
            "heading": "5.1 Incremental object detection",
            "text": "We evaluated our proposed method to develop an agent to learn an incremental object detection task. Object detection in real-world images has been used as a benchmark task for several computer vision problems. In order to evaluate our approach, we created an incremental learning task that requires learning a target domain classification model given an initial source domain dataset.\nWe use an imaging dataset with multiple object classes and multiple domains. We select one of the domains as the initial labeled source domain while the rest are considered unlabelled target domains. Our goal is to learn a common model for all the domains observed by the model.\n5.1.1 Dataset. We used the office-31 object recognition dataset [16] which contains 4652 images from 3 domains and 31 classes. The domains of the dataset are web (Amazon), DSLR, and webcam. The domain details are as follows: \u2022 Amazon (A): These are images taken from Amazon [1]. They are mostly taken in a studio setting with a clear background\nand standardized lighting. We have an average of 90 images per class. \u2022 Digital single-lens reflex camera (D): This domain contains high-resolution images with a pixel resolution of (4288 \u00d7 2848). Each class contains images of 5 objects taken from 3 different angles each. In total, the domain dataset has 423 images. \u2022 Webcam (W): This domain contains low-resolution poorlighting images with a pixel resolution of (640 \u00d7 480). The dataset contains 5 objects per class with 3 angle images each. In total, we have 795 images. These images show considerable noise and color as well as white balance artifacts.\nThe 31 categories are desk lamp, computer, tile cabinet, backpack, bike, bike helmet, mouse, mug, notebook, pen, phone, printer, bookcase, bottle, calculator, desk chair, headphones, keyboard, laptop, letter tray, mobile phone, monitor, projector, puncher, ring binder, ruler, scissors, speaker, stapler, tape, and trash can.\nTo evaluate the response of our approach to both open-set differences between the source and target domains and non-stationary source and target domains, we structure the experiment as follows \u2022 The domains are introduced incrementally to the model, and the data from the domains (belonging to the same class) is assumed to be sampled from a single non-stationary distribution \u2022 In every iteration we introduce a set of shared classes\ud835\udc36\ud835\udc61\ud835\udc60 and target private classes \ud835\udc36\n\u2032 (\ud835\udc61 ) \ud835\udc61\n\u2022 The foresighted learning network learns the source guides every time a new labeled source domain is introduced. For the \ud835\udc59\ud835\udc61\u210e iteration, \ud835\udc53 (\ud835\udc61+\ud835\udc59)\ud835\udc60 is trained using data sampled from combined data from \ud835\udc62 (\ud835\udc61 )\ud835\udc60 and \ud835\udc65 (\ud835\udc61+\ud835\udc59) \ud835\udc60 \u2022 The target data in every iteration assumed to contain at least one target private class (i.e. \ud835\udc36\n\u2032 (\ud835\udc61+1) \u2260 \u2205) Like our method, iCARL and CIDA use prototype learning to enable source-free incremental learning. Although this is one of the desiderata of incremental learning, iCARL requires labeled target data. This makes it unsuitable for direct application to the unsupervised task incremental learning problem setting. Our work is motivated by CIDA, and we aim to improve upon the existing\nmethod by using an adversarial domain discrepancy estimation instead of the previously proposed alignment loss [10]. We also extend it to an incremental learning context. DANN and CMA provide a way to carry out unsupervised learning. We compare our approach to the aforementioned methods to evaluate the efficiency of end-to-end trainable adversarial methods for task incremental learning.\nWe evaluate our approach using the incremental learning task outlined in table 2.We evaluate the performance of a given approach at every time point using total accuracy and target private class accuracy. We compare our proposed approach (TIDo) to unsupervised domain adaptation methods (DANN [19]), class incremental domain adaptation methods (iCARL [15], CIDA [10]) and continual learning methods (LwF-MC [11], CMA [8]). For methods without a provision to incrementally add new classes, we trained a target private classifier (TPC). CIDA-C refers to storing and using combined target task data from past increments; this makes this a pseudo-incremental learning approach.\nFor (\ud835\udc61 +4)\ud835\udc61\u210e iteration of the experiment (refer to table.2), we have no source dataset. We do not update the source classifier for the DANN approach for this iteration as the approach requires source data to update. Also, iCARL and LwF-MC methods are supervised methods and require labeled target data. We use 5% labeled samples (available to the rest of the methods for few-shot learning) to serve as the labeled target data."
        },
        {
            "heading": "5.2 Incremental disease staging",
            "text": "We apply our proposed approach to create an incremental disease staging agent. We design an incremental learning task for learning an Alzheimer\u2019s disease prediction model.\nAlzheimer\u2019s disease staging is a non-trivial process with overlapping subjective categories. Due to the absence of a standard staging model for neurological diseases like AD, stage-wise labeled data may not be available at a single time point. We propose using task incremental learning to carry out source-free few-shot incremental updates to a base clinical model. to test our class incremental hypothesis, we aim to update a binary classification AD/HC model to predict intermediate stages of early mild cognitive impairment (EMCI) and late mild cognitive impairment (LMCI). To test our domain incremental hypothesis, we update the model using target data from a different domain (containing both shared and target private classes).\nWe evaluate the method using Alzheimer\u2019s disease data from multiple domains, different populations, and different label sets. We use Alzheimer\u2019s disease-specific datasets in this experiment\n\u2013 Alzheimer\u2019s Disease Neuroimaging Initiative (Data used in the preparation of this article were obtained from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu)) [4] and Alzheimer\u2019s Disease Neuroimaging Initiative \u2013 AIBL (Data was collected by the AIBL study group. AIBL study methodology has been reported previously [5]).\nWe create a region of interest (ROI) image dataset using MRI images from ADNI and AIBL domains. The MRI images were preprocessed using a processing pipeline. Due to the relatively low number of samples in the MRI imaging dataset, we augment the dataset using the extracted ROIs from the input images [9, 12]. For example, for the ADNI-1 dataset, we had 841 samples (200 healthy control data, 230 AD data, and 411 MCI data); after ROI augmentation, we had 3364 data instances.\nWe used ROI data from left and right Hippocampus regions and left and right temporal lobes. The extracted ROI patches had the dimension (64\u00d764\u00d764). Individual ROI patches were labeled using the sample label from which they were extracted."
        },
        {
            "heading": "5.3 Discussion",
            "text": "We proposed a source-free task incremental learning method for an agent to learn a task incrementally. We observed that our approach enabled an autonomous agent to learn a near-optimal target hypothesis with very low catastrophic forgetting for both class incremental and domain incremental applications. Since our approach is source-free, we have a very low memory complexity and can update a model incrementally using few-shot learning.\nOur results show comparable or improved performance of our approach compared to class incremental learning (CIDA-C [10]). We show that our approach can achieve similar performance without storing past target training data. This reduces the memory complexity of our approach drastically.\nWe performed a comparative analysis of the task incremental problem using unsupervised domain adaptation, continual learning, and class incremental methods. [15] propose a supervised incremental learning approach that uses representation learning and learned class-wise exemplars from the input data. The authors updated the exemplars incrementally to learn using new classes and instances. Storage of class-wise exemplar instances and the need for labeled samples from both source and target domains for model upgrades make the approach unsuitable for scalable incremental learning. We eliminate the need to store exemplar instances by generating a distribution estimation and storing class-wise guides, thereby rendering our approach source-free.\nWe compared our approach to continual manifold adaptation (CMA). CMA does not apply to open-set transfer learning settings. Hence, we learn a target private classifier (TPC) to achieve the task incremental task. Due to the few-shot configuration for target private instances, TPC risk is large. Table 3 and 4 show a high loss for target private classes, except (\ud835\udc61 + 2)\ud835\udc61\u210e iteration for Alzheimer\u2019s disease prediction (57.82\u00b14.60%) which is because the target private class (EMCI) is a sub-category of MCI, which has been observed by the classifier in the previous iterations (\ud835\udc61 + 0, \ud835\udc61 + 1) for related domains (ADNI 3 and ADNI 2)."
        },
        {
            "heading": "5.4 Ablation studies",
            "text": "We will now explore the effect of different components of our proposed approach.\nEffectiveness ofGaussian estimation andOODsample prediction: Similar to previous approaches, we analyze the sensitivity of the hyper-parameter \ud835\udc58 to observe the effects of modifying the labeling criteria for negative samples in the foresighted learning stage. To verify that our Gaussian estimates are accurate, we empirically tested the efficiency of the assumed confidence interval (3-\ud835\udf0e). Figure 2a shows that 3-\ud835\udf0e provided the maximum predictive accuracy and best captured the source distribution characteristics.\nEffect of balancing source and target unlabelled data: We used a balanced source (\ud835\udc41\ud835\udc60\ud835\udc5f\ud835\udc50 ) and target (\ud835\udc41\ud835\udc5b\ud835\udc52\ud835\udc54) domain dataset to train our baseline model. We test the robustness of our model to imbalanced data by varying the \ud835\udc41\ud835\udc60\ud835\udc5f\ud835\udc50/\ud835\udc41\ud835\udc5b\ud835\udc52\ud835\udc54 ratio by \u00b10.5. We measure the sensitivity of the source and target domain ratio in figure 2b and observe that the proposed approach is robust against data imbalance.\nChallenging one-shot learning: We observe the efficiency of our incremental learning approach by varying the ratio of samples in the target private classes to the number of shared class samples (|\ud835\udc36\u2032\ud835\udc61 |/|\ud835\udc36\ud835\udc61 ). Figure 2d shows the sensitivity of this ratio. Even though\na larger number of target private samples improves the accuracy of private guides and private class prediction, prediction accuracy reduces due to the inability of the target classifier to converge under less target shared class data.\nEffect of class separation loss:We carry out the ablation study by removing the class separation loss. We learn the post-increment accuracy of the target domain classifier without applying the class separation loss (L\ud835\udc601). We observe that the average prediction accuracy without the loss minimization was 83.45% compared to 92.12% using the class separation loss."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "In this work, we proposed an approach for an autonomous agent to learn a task incremental learning model in a non-stationary environment. We explored a one-shot learning approach to reduce the need for collecting labeled data to incrementally update a model. Using a source-free approach, we were able to learn aligned target private prototype guides and learn with very few target-labeled samples. One of the limitations of our approach is the possibility of overfitting after a given number of incremental iterations. We aim to address this limitation in our future work by exploring selective forgetting using recurrent network-based approaches. Another\npossible limitation of this work would be the use of Gaussian estimates to generate replay memory representative samples. We aim to explore adversarial methods to generate representative samples in our future work.\nREFERENCES [1] 2022. https://www.amazon.com [2] John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wort-\nman. 2008. Learning bounds for domain adaptation. In Advances in neural information processing systems. 129\u2013136. [3] John Blitzer, Ryan McDonald, and Fernando Pereira. 2006. Domain adaptation with structural correspondence learning. In Proceedings of the 2006 conference on\nempirical methods in natural language processing. Association for Computational Linguistics, 120\u2013128. [4] Youngsang Cho, Joon-Kyung Seong, Yong Jeong, Sung Yong Shin, andAlzheimer\u2019s Disease Neuroimaging Initiative. 2012. Individual subject classification for Alzheimer\u2019s disease based on incremental learning using a spatial frequency representation of cortical thickness data. NeuroImage 59, 3 (01 Feb 2012), 2217\u2013 2230. https://doi.org/10.1016/j.neuroimage.2011.09.085 22008371[pmid]. [5] Kathryn A Ellis, Ashley I Bush, David Darby, Daniela De Fazio, Jonathan Foster, Peter Hudson, Nicola T Lautenschlager, Nat Lenzo, Ralph N Martins, Paul Maruff, et al. 2009. The Australian Imaging, Biomarkers and Lifestyle (AIBL) study of aging: methodology and baseline characteristics of 1112 individuals recruited for a longitudinal study of Alzheimer\u2019s disease. International psychogeriatrics 21, 4 (2009), 672\u2013687. [6] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, Mario Marchand, and Victor Lempitsky. 2016. Domain-adversarial training of neural networks. The Journal of Machine Learning Research 17, 1 (2016), 2096\u20132030. [7] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531 (2015). [8] Judy Hoffman, Trevor Darrell, and Kate Saenko. 2014. Continuous manifold based adaptation for evolving visual domains. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 867\u2013874. [9] Ehsan Hosseini-Asl, Robert Keynton, and Ayman El-Baz. 2016. Alzheimer\u2019s disease diagnostics by adaptation of 3D convolutional network. In 2016 IEEE international conference on image processing (ICIP). IEEE, 126\u2013130. [10] Jogendra Nath Kundu, Rahul Mysore Venkatesh, Naveen Venkat, Ambareesh Revanur, and R Venkatesh Babu. 2020. Class-incremental domain adaptation. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XIII 16. Springer, 53\u201369. [11] Zhizhong Li and Derek Hoiem. 2017. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence 40, 12 (2017), 2935\u20132947.\n[12] Siqi Liu, Sidong Liu, Weidong Cai, Hangyu Che, Sonia Pujol, Ron Kikinis, Dagan Feng, Michael J Fulham, et al. 2014. Multimodal neuroimaging feature learning for multiclass diagnosis of Alzheimer\u2019s disease. IEEE transactions on biomedical engineering 62, 4 (2014), 1132\u20131140. [13] Marc Masana, Xialei Liu, Bartlomiej Twardowski, Mikel Menta, Andrew D Bagdanov, and Joost van de Weijer. 2020. Class-incremental learning: survey and performance evaluation. arXiv preprint arXiv:2010.15277 (2020). [14] Fei Mi, Lingjing Kong, Tao Lin, Kaicheng Yu, and Boi Faltings. 2020. Generalized Class Incremental Learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops. 240\u2013241. [15] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H Lampert. 2017. icarl: Incremental classifier and representation learning. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 2001\u2013 2010. [16] Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell. 2010. Adapting visual category models to new domains. In European conference on computer vision. Springer, 213\u2013226. [17] Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tatsuya Harada. 2018. Maximum classifier discrepancy for unsupervised domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition. 3723\u20133732. [18] Tasfia Shermin, Guojun Lu, Shyh Wei Teng, Manzur Murshed, and Ferdous Sohel. 2020. Adversarial network with multiple classifiers for open set domain adaptation. IEEE Transactions on Multimedia (2020). [19] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. 2017. Adversarial discriminative domain adaptation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 7167\u20137176. [20] Vladimir Vapnik, Esther Levin, and Yann Le Cun. 1994. Measuring the VCdimension of a learning machine. Neural computation 6, 5 (1994), 851\u2013876. [21] Han Zhao, Shanghang Zhang, Guanhang Wu, Jos\u00e9 MF Moura, Joao P Costeira, and Geoffrey J Gordon. 2018. Adversarial multiple source domain adaptation. In Advances in neural information processing systems. 8559\u20138570."
        }
    ],
    "title": "TIDo: Source-free Task Incremental Learning in Non-stationary Environments",
    "year": 2023
}