{
    "abstractText": "We study the formation of stable outcomes via simple dynamics in cardinal hedonic games, where the utilities of agents change over time depending on the history of the coalition formation process. Specifically, we analyze situations where members of a coalition decrease their utility for a leaving agent (resent) or increase their utility for a joining agent (appreciation). We show that in contrast to classical dynamics, for resentful or appreciative agents, dynamics are guaranteed to converge under mild conditions for various stability concepts. Thereby, we establish that both resent and appreciation are strong stability-driving forces.",
    "authors": [
        {
            "affiliations": [],
            "name": "Niclas Boehmer"
        },
        {
            "affiliations": [],
            "name": "Martin Bullinger"
        },
        {
            "affiliations": [],
            "name": "Anna Maria Kerkmann"
        }
    ],
    "id": "SP:f61968c0a24a1b8bcddc1c1de18de034fc017f82",
    "references": [
        {
            "authors": [
                "H. Aziz",
                "R. Savani"
            ],
            "title": "Hedonic games",
            "venue": "Handbook of Computational Social Choice,",
            "year": 2016
        },
        {
            "authors": [
                "H. Aziz",
                "F. Brandt",
                "H.G. Seedig"
            ],
            "title": "Computing desirable partitions in additively separable hedonic games",
            "venue": "Artificial Intelligence,",
            "year": 2013
        },
        {
            "authors": [
                "H. Aziz",
                "F. Brandl",
                "F. Brandt",
                "P. Harrenstein",
                "M. Olsen",
                "D. Peters"
            ],
            "title": "Fractional hedonic games",
            "venue": "ACM Transactions on Economics and Computation,",
            "year": 2019
        },
        {
            "authors": [
                "C. Ballester"
            ],
            "title": "NP-completeness in hedonic games",
            "venue": "Games and Economic Behavior,",
            "year": 2004
        },
        {
            "authors": [
                "S. Banerjee",
                "H. Konishi",
                "T. S\u00f6nmez"
            ],
            "title": "Core in a simple coalition formation game",
            "venue": "Social Choice and Welfare,",
            "year": 2001
        },
        {
            "authors": [
                "V. Bil\u00f2",
                "A. Fanelli",
                "M. Flammini",
                "G. Monaco",
                "L. Moscardelli"
            ],
            "title": "Nash stable outcomes in fractional hedonic games: Existence, efficiency and computation",
            "venue": "Journal of Artificial Intelligence Research,",
            "year": 2018
        },
        {
            "authors": [
                "V. Bil\u00f2",
                "G. Monaco",
                "L. Moscardelli"
            ],
            "title": "Hedonic games with fixed-size coalitions",
            "venue": "In Proceedings of the 36th AAAI Conference on Artificial Intelligence (AAAI),",
            "year": 2022
        },
        {
            "authors": [
                "A. Bogomolnaia",
                "M.O. Jackson"
            ],
            "title": "The stability of hedonic coalition structures",
            "venue": "Games and Economic Behavior,",
            "year": 2002
        },
        {
            "authors": [
                "F. Brandt",
                "M. Bullinger"
            ],
            "title": "Finding and recognizing popular coalition structures",
            "venue": "Journal of Artificial Intelligence Research,",
            "year": 2022
        },
        {
            "authors": [
                "F. Brandt",
                "M. Bullinger",
                "A. Wilczynski"
            ],
            "title": "Reaching individually stable coalition structures in hedonic games",
            "venue": "In Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI),",
            "year": 2021
        },
        {
            "authors": [
                "F. Brandt",
                "M. Bullinger",
                "L. Tappe"
            ],
            "title": "Single-agent dynamics in additively separable hedonic games",
            "venue": "In Proceedings of the 36th AAAI Conference on Artificial Intelligence (AAAI),",
            "year": 2022
        },
        {
            "authors": [
                "M. Bullinger"
            ],
            "title": "Pareto-optimality in cardinal hedonic games",
            "venue": "In Proceedings of the 19th International Conference on Autonomous Agents and Multiagent Systems (AAMAS),",
            "year": 2020
        },
        {
            "authors": [
                "M. Bullinger"
            ],
            "title": "Boundaries to single-agent stability in additively separable hedonic games",
            "venue": "In Proceedings of the 47th International Symposium on Mathematical Foundations of Computer Science (MFCS),",
            "year": 2022
        },
        {
            "authors": [
                "M. Bullinger",
                "S. Kober"
            ],
            "title": "Loyalty in cardinal hedonic games",
            "venue": "In Proceedings of the 30th International Joint Conference on Artificial Intelligence (IJCAI),",
            "year": 2021
        },
        {
            "authors": [
                "R. Carosi",
                "G. Monaco",
                "L. Moscardelli"
            ],
            "title": "Local core stability in simple symmetric fractional hedonic games",
            "venue": "In Proceedings of the 18th International Conference on Autonomous Agents and Multiagent Systems (AAMAS),",
            "year": 2019
        },
        {
            "authors": [
                "K. Cechl\u00e1rov\u00e1",
                "A. Romero-Medina"
            ],
            "title": "Stability in coalition formation",
            "venue": "games. International Journal of Game Theory,",
            "year": 2001
        },
        {
            "authors": [
                "E. Elkind",
                "M. Wooldridge"
            ],
            "title": "Hedonic coalition nets",
            "venue": "In Proceedings of the 8th International Conference on Autonomous Agents and Multiagent Systems (AAMAS),",
            "year": 2009
        },
        {
            "authors": [
                "E. Elkind",
                "A. Fanelli",
                "M. Flammini"
            ],
            "title": "Price of pareto optimality in hedonic games",
            "venue": "Artificial Intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "A. Fanelli",
                "G. Monaco",
                "L. Moscardelli"
            ],
            "title": "Relaxed core stability in fractional hedonic games",
            "venue": "In Proceedings of the 30th International Joint Conference on Artificial Intelligence (IJCAI),",
            "year": 2021
        },
        {
            "authors": [
                "M. Gairing",
                "R. Savani"
            ],
            "title": "Computing stable outcomes in symmetric additively separable hedonic games",
            "venue": "Mathematics of Operations Research,",
            "year": 2019
        },
        {
            "authors": [
                "G. Monaco",
                "L. Moscardelli",
                "Y. Velaj"
            ],
            "title": "Stable outcomes in modified fractional hedonic games",
            "venue": "hedonic games. Journal of Artificial Intelligence Research,",
            "year": 2022
        },
        {
            "authors": [
                "M. Olsen"
            ],
            "title": "On defining and computing communities",
            "venue": "Systems (AAMAS),",
            "year": 2018
        },
        {
            "authors": [
                "D. Peters",
                "E. Elkind"
            ],
            "title": "Simple causes of complexity in hedonic games",
            "year": 2017
        },
        {
            "authors": [
                "Aziz"
            ],
            "title": "Example 1), there is no CS partition for these six agents. Note that resent, which influences each player by a total utility change",
            "year": 2013
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n21 1.\n17 16\n9v 1\n[ cs\n.G T\n] 3\n0 N\nov 2"
        },
        {
            "heading": "1 Introduction",
            "text": "Coalition formation is a vibrant topic in multi-agent systems that has been continuously researched during the last decades. It concerns the question of dividing a set of agents, for example, humans or machines, into disjoint coalitions such as research teams. Agents carry preferences over these coalition structures. A common assumption is that externalities, that is, the coalition structure outside one\u2019s own coalition, play no role. This is captured in the prominent framework of hedonic games. Moreover, the desirability of a coalition structure is usually measured with respect to stability. Abstractly speaking, a coalition structure is stable if there is no agent or set of agents that can perform a beneficial deviation by joining existing coalitions or by forming new coalitions.\nThere are two specific properties of hedonic games crucially influencing past research. First, the number of possible coalitions an agent can be part of is exponentially large. Therefore, a repeatedly considered challenge is to come up with reasonable succinctly representable settings. It is very prominent in this context to aggregate utilities from cardinal valuations of other agents. Second, most established stability concepts suffer from non-existence under strong restrictions which often leads to computational boundaries such as hardness of the decision problem whether a stable state exists. Much of the research has therefore focused on identifying suitable conditions guaranteeing stable states.\nThe dominant coalition formation framework is static in two dimensions. First, stability is usually a static concept in the sense that, since a coalition structure is either stable or not, we are only interested in finding these stable structures. The underlying assumption here is that we operate in a centralized system where a (desirable) coalition structure can be created by a central authority. This paradigm has only recently been complemented by interpreting\ndeviations of agents as a dynamic process. The goal here is to reach stable coalition structures through decentralized individual decisions (Brandt et al., 2021, 2022). Second, utility functions are static. To demonstrate the implications of this assumption, we describe a run-and-chase example, which is present in many classes of hedonic games. Consider a situation where there are only the two agents Alice and Bob. Alice wants to be alone in her coalition, whereas Bob wants to be in a joint coalition with Alice. It is clear that in the two possible coalition structures, there is always an agent who wants to change their situation. From a centralized perspective, this simply means that no coalition structure has the prospect of stability. In a distributed, dynamic setting where utilities are static, the following occurs indefinitely: Whenever Alice and Bob are in a joint coalition, then Alice leaves the coalition to be alone. However, whenever Alice and Bob are in two separate coalitions, then Bob joins Alice. In practice, such an infinite situation is unreasonable: After playing run-and-chase for a while, either Alice or Bob are likely to change their behavior and therefore their preferences. On the one hand, Bob might get frustrated because he is constantly left by Alice and therefore stops his efforts to join her. On the other hand, Alice could realize the high effort that Bob makes to be in a coalition with her and feels sufficient appreciation to eventually accept Bob in her coalition. In both scenarios, we reach a state that is stable because of the history of the coalition formation process.\nIn this paper, we model situations where the history influences the agents\u2019 utilities, offering a new perspective on the reachability of stable coalition structures. We study a dynamic coalition formation process where agents perform deviations based on stability concepts. However, in contrast to previous work on dynamics, we assume that a deviation has an effect on the perception of the deviator, resulting in agents changing their utility for the deviator. We distinguish two approaches. First, an agent might act resentfully in the sense that, like Bob, she lowers her utility for an agent abandoning her. A deviator abandoning a resentful agent again and again eventually looses all of her attraction to the resentful agent. On the other hand, an agent could appreciate the effort of another agent to be part of her coalition, and therefore, like Alice, increase her utility for an agent whenever the agent joins her. After sufficient effort, the urge to leave the deviator ceases."
        },
        {
            "heading": "1.1 Contribution",
            "text": "We initiate the study of cardinal hedonic games under utility functions changing over time. In particular, we consider utility modifications based on the resentful and appreciative perception of other agents. We investigate whether decentralized dynamics based on various types of devi-\nations are guaranteed to converge. Deviations might be constrained to be individually rational (IR), that is, a deviating agent needs to prefer her new coalition to being alone. We showcase our results by considering additively separable hedonic games (ASHGs) and modified fractional hedonic games (MFHGs), where an agent\u2019s utility for a coalition is the sum or average utility for the other agents in the coalition, respectively. Table 1 provides an overview of these results. First, for resentful agents performing individually rational deviations, convergence is guaranteed in all considered cases. If deviations may also violate individual rationality, the situation becomes more complicated and elusive to a complete understanding; nevertheless, we establish several convergence guarantees while also having an involved example of a cycling dynamics in MFHGs. In contrast, appreciation is usually not sufficient to guarantee convergence. Notably, as proved in Corollary 4.3 four of our open questions concerning both resentful and appreciative agents are in some sense equivalent.\nIn fact, most of our results do not only apply to ASHGs and/or MFHGs but to larger classes of hedonic games. For this, we develop an axiomatic framework for utility aggregation based on the perception of friends and enemies, that is, agents yielding positive and negative utility, respectively.\nIn our simulations, we observe that our model of dynamic utilities leads to the (quick) convergence of Nash dynamics. Moreover, we analyze the structure and expressiveness of the produced outcomes. Finally, we outline results for other perception models and for computational questions concerned with finding shortest converging sequences."
        },
        {
            "heading": "1.2 Related Work",
            "text": "Hedonic games originate from economic theory (Dre\u0300ze and Greenberg, 1980), but their constant and broad consideration only started with key publications by Banerjee et al. (2001), Cechla\u0301rova\u0301 and Romero-Medina (2001), and Bogomolnaia and Jackson (2002). An overview of hedonic games is provided in the survey by Aziz and Savani (2016). The search for suitable representations of reasonable classes of hedonic games has led to various proposals (see, e.g., Cechla\u0301rova\u0301 and Romero-Medina, 2001; Bogomolnaia and Jackson, 2002; Ballester, 2004; Elkind and Wooldridge, 2009; Olsen, 2012; Aziz et al., 2019).\nVarious stability concepts and their computational boundaries have been previously studied. We focus on results concerning ASHGs (Bogomolnaia and Jackson, 2002) and MFHGs (Olsen, 2012). Sung and Dimitrov (2010) show prototype NP-hardness reductions for single-agent stability concepts in ASHGs, paving the way for many similar results for single-agent and group stability (see, e.g., Aziz et al., 2013; Brandt et al., 2022; Bullinger, 2022). Gairing and Savani (2019) consider ASHGs under symmetric utilities and show PLS-completeness of computing stable states, while Woeginger (2013) and Peters (2017) show \u03a3P2 -completeness of the (strict) core in ASHGs. Peters and Elkind (2015) provide a meta view on computational hardness. For MFHGs, there seem to be less computational boundaries. Indeed, for symmetric and binary utilities, stable states exist and can be efficiently computed. Core stability is even tractable for symmetric and arbitrarily weighted utilities (Monaco et al., 2018). Apart from the consideration of stability, other desirable notions of efficiency or fairness such as Pareto optimality, envy-freeness, or popularity have been studied for ASHGs and MFHGs (Aziz et al., 2013; Elkind et al., 2020; Bullinger, 2020; Brandt and Bullinger, 2022). These papers provide more evidence that MFHGs seem to be less complex than ASHGs.\nThe dynamical, distributed approach to coalition formation received increased attention very recently (Hoefer et al., 2018; Bilo\u0300 et al., 2018; Carosi et al., 2019; Brandt et al., 2021; Fanelli et al., 2021; Brandt et al., 2022; Bilo\u0300 et al., 2022). There, Bilo\u0300 et al. (2018); Brandt et al. (2021, 2022) consider stability based on single-agent deviations, whereas\nCarosi et al. (2019); Fanelli et al. (2021) consider group stability. Finally, another recent approach to achieve a guarantee to stability in hedonic games is the consideration of loyalty (Bullinger and Kober, 2021) which is based on altruism in hedonic games (Kerkmann et al., 2022)."
        },
        {
            "heading": "2 Preliminaries and Model",
            "text": "In this section, we define the basic coalition formation setting, our specific model, and provide some first observations. For an integer i \u2208 N, we define [i] = {1, . . . , i}."
        },
        {
            "heading": "2.1 Cardinal Hedonic Games",
            "text": "Let N = [n] be a finite set of agents. A coalition is any subset of N . We denote the set of all possible coalitions containing agent i \u2208 N by Ni = {C \u2286 N : i \u2208 C}. Any partition of the agents N is also called coalition structure and we denote the set of all partitions of N by \u03a0N . Given an agent i \u2208 N and a partition \u03c0 \u2208 \u03a0N , let \u03c0(i) denote the coalition of i, i.e., the unique coalition C \u2208 \u03c0 with i \u2208 C. A (cardinal) hedonic game is a pair (N,u) consisting of a set N of agents and a utility profile u = (ui)i\u2208N where ui : N \u2192 Q is the utility function of agent i. Thus, for i, j \u2208 N , ui(j) is i\u2019s utility for agent j. We sometimes equivalently view a utility function as a vector ui \u2208 Q\nn. An agent j \u2208 N is a friend (or enemy) of an agent i \u2208 N if ui(j) > 0 (or ui(j) < 0).\nTo move from utilities for single agents to utilities over coalitions, we use cardinal aggregation functions (CAFs). For every agent i \u2208 N , the CAF Ai : Ni \u00d7 Qn \u2192 Q specifies i\u2019s utility for a given coalition for her given utility vector. Then, the utility of an agent for a partition \u03c0 with respect to aggregation function Ai is u Ai i (\u03c0) = Ai(\u03c0(i), ui). To keep notation concise, we sometimes omit the CAF as a superscript when it is clear from the context. For an agent i \u2208 N with utility function ui, a coalition C \u2208 Ni is individually rational (IR) if Ai(C, ui) \u2265 Ai({i}, ui). Further, a partition \u03c0 is individually rational (IR) for agent i if \u03c0(i) is an individually rational coalition.\nCommon classes of cardinal hedonic games such as the two specific classes studied in this paper have a straightforward representation with respect to CAFs. For each agent i \u2208 N with utility function ui,\n\u2022 additively separable hedonic games (ASHGs) (Bogomolnaia and Jackson, 2002) use the aggregation function AS defined by AS i(C, ui) = \u2211 j\u2208C\\{i} ui(j) and\n\u2022 modified fractional hedonic games (MFHGs) (Olsen, 2012) use the aggregation function\nMF defined by MF i(C, ui) = \u2211 j\u2208C\\{i} ui(j)\n|C|\u22121 if |C| \u2265 2 and MF i(C, ui) = 0, otherwise."
        },
        {
            "heading": "2.2 Deviations and Stability",
            "text": "As indicated in the introduction, we distinguish different stability notions based on single-agent deviations and group deviations. Given a partition \u03c0 \u2208 \u03a0N , agent i \u2208 N might perform a single-agent deviation from \u03c0(i) to any coalition C \u2208 \u03c0 \u222a {\u2205}, resulting in the partition \u03c0\u2032 = (\u03c0 \\ {\u03c0(i), C})\u222a {\u03c0(i) \\ {i}, C \u222a {i}}; and a group of agents C \u2286 N might perform a group deviation, leading to the partition \u03c0\u2032 = (\u03c0 \\ {\u03c0(j) | j \u2208 C}) \u222a {\u03c0(j) \\ C | j \u2208 C} \u222a {C}.\nDepending on which agents improve as a result of a deviation, we distinguish the following types of deviations. Agent i\u2019s single-agent deviation from \u03c0(i) to C \u2208 \u03c0 \u222a {\u2205}, resulting in partition \u03c0\u2032, is a Nash (NS) deviation if ui(\u03c0 \u2032) > ui(\u03c0). An NS deviation of i from \u03c0 to \u03c0 \u2032 is called\n\u2022 an individual (IS) deviation if uj(\u03c0 \u2032) \u2265 uj(\u03c0) for all j \u2208 C, where C is the coalition to\nwhich i deviated; and\n\u2022 a contractual Nash (CNS) deviation if uj(\u03c0 \u2032) \u2265 uj(\u03c0) for all j \u2208 \u03c0(i) \\ {i}.\nA group deviation of coalition C from \u03c0 to \u03c0\u2032 is\n\u2022 a core (CS) deviation if ui(\u03c0 \u2032) > ui(\u03c0) for all i \u2208 C; and\n\u2022 a strict core (SCS) deviation if ui(\u03c0 \u2032) \u2265 ui(\u03c0) for all i \u2208 C and uj(\u03c0 \u2032) > uj(\u03c0) for some j \u2208 C.\nFinally, for all types of deviations introduced above, we define the respective stability notion of a partition by the absence of a corresponding deviation. For example, a partition \u03c0 is said to be Nash-stable (NS) if there is no NS deviation from \u03c0 to another partition. The logical relations among the resulting stability concepts are illustrated in Figure 1 (see also Aziz and Savani, 2016).\nFor a given partition, several single-agent or group deviations might be possible. Yet, some deviations seem to be more reasonable than others. We say that a deviation is IR if the resulting partition is IR for all deviating agents. For all our considered stability concepts it holds that if an agent has a deviation (that is potentially not IR), then she also has an IR deviation where she forms a singleton coalition."
        },
        {
            "heading": "2.3 Dynamic Coalition Formation",
            "text": "We now introduce our model of dynamic coalition formation over time, and the concepts of resent and appreciation. Throughout the paper, we consider sequences of partitions (\u03c0t)t\u22650, where for every t \u2265 1, \u03c0t evolves from \u03c0t\u22121 by means of some single-agent or group deviation. We assume that both the initial coalition structure \u03c00 and the initial utility vectors u0i for each agent i \u2208 N are given. However, utilities change over time as follows. Under resent, agents decrease their utilities for all deviators that leave them (by one), while under appreciation, agents increase their utilities for all deviators that join them (by one).1 More formally, if for some t \u2265 1, \u03c0t evolves from \u03c0t\u22121 via a single-agent deviation of agent k \u2208 N , then, for i, j \u2208 N ,\n\u2022 for resentful agents, uti(j) arises from u t\u22121 i (j) as\nuti(j) =\n{\nut\u22121i (j) \u2212 1 i 6= k, j = k, j \u2208 \u03c0 t\u22121(i), ut\u22121i (j) else.\n\u2022 for appreciative agents, uti(j) arises from u t\u22121 i (j) as\nuti(j) =\n{\nut\u22121i (j) + 1 i 6= k, j = k, j \u2208 \u03c0 t(i),\nut\u22121i (j) else. 1Note that our choice of decreasing, resp., increasing the utilities by one is somewhat arbitrary, as our theoretical results hold for any fixed increase or decrease of utilities. However, note that in case the utility change in each round is not constant, our convergence guarantees are no longer applicable, as, for instance, run-and-chase situations can occur.\nIf for t \u2265 1, \u03c0t evolves from \u03c0t\u22121 via a group deviation of C \u2286 N , then, for i, j \u2208 N ,\n\u2022 for resentful agents, uti(j) arises from u t\u22121 i (j) as\nuti(j) =\n{\nut\u22121i (j) \u2212 1 i /\u2208 C, j \u2208 C, j \u2208 \u03c0 t\u22121(i), ut\u22121i (j) else.\n\u2022 for appreciative agents, uti(j) arises from u t\u22121 i (j) as\nuti(j) =\n{\nut\u22121i (j) + 1 i 6= j, i \u2208 C, j \u2208 C, ut\u22121i (j) else.\nWe are concerned about sequences of partitions that evolve by deviations with respect to the current utilities of the agents. For any stability concept \u03b1 \u2208 {NS , IS ,CNS ,CS ,SCS}, a sequence of partitions (\u03c0t)t\u22650 is called an execution of an \u03b1 dynamics if \u03c0 t evolves from \u03c0t\u22121 through an \u03b1 deviation with respect to the utility functions (ut\u22121i )i\u2208N . If all deviations are individually rational, we call the dynamics individually rational, e.g., individually rational NS dynamics in the case of Nash stability.\nAn execution of an \u03b1 dynamics converges if it terminates after a finite number of T steps in a partition \u03c0T that is stable with respect to (uTi )i\u2208N under the stability notion \u03b1. We say that the \u03b1 dynamics converges if every execution of the \u03b1 dynamics converges for every initial utility profile and partition. By contrast, the dynamics cycles if there exists an infinite execution of the dynamics (for some initial utilities and partition). The central question of this paper is when dynamics converge for resentful or appreciative agents.\nIt is convenient to use a compact notation for utilities. We write ut,Aii (\u03c0) = Ai(\u03c0(i), u t i) and ut,Aii (C) = Ai(C, u t i) for the utility of agent i at time t for a partition \u03c0 \u2208 \u03a0N or for coalition C \u2208 Ni, respectively. If the CAF Ai is clear from context, we usually omit it as superscript. Before our main analysis, we present a useful lemma that holds for arbitrary dynamics. The lemma can be applied to show that, from a certain point onwards, every deviation occurs infinitely often in an infinite execution of a dynamic. The proof is straightforward and is included in the appendix.\nLemma 2.1. Let (\u03c0t)t\u22650 be an infinite sequence of partitions induced by single-agent (or group) deviations. Then, there exists a t0 \u2265 0 such that every single-agent (or group) deviation performed at some time t \u2265 t0 occurs infinitely often.\nLastly, we call an infinite sequence of partitions \u03c0 = (\u03c0t)t\u22650 periodic if there exist t0 \u2208 N and p \u2208 N such that, for all k \u2208 N0 and l \u2208 {0, . . . , p \u2212 1}, it holds that \u03c0 t0+kp+l = \u03c0t0+l."
        },
        {
            "heading": "2.4 Properties of Aggregation Functions",
            "text": "We now introduce some useful properties of CAFs. For any i \u2208 N , a CAF Ai satisfies\n\u2022 aversion to enemies (ATE) if, for all coalitions C \u2208 Ni, agents j \u2208 C \\ {i}, and utility vectors ui \u2208 Q\nn with ui(j) < 0, it holds that Ai(C, ui) \u2264 Ai(C \\ {j}, ui). In other words, the aggregated utility is weakly better whenever an enemy leaves i\u2019s coalition.\n\u2022 individually rational aversion to enemies (IR ATE) if, for all coalitions C \u2208 Ni, agents j \u2208 C \\{i}, and utility vectors ui \u2208 Q\nn with ui(j) < 0, it holds that Ai(C, ui) \u2264 Ai(C \\{j}, ui) if Ai(C, ui) \u2265 Ai({i}, ui). In other words, the aggregated utility is weakly better when an enemy leaves one of i\u2019s individually rational coalitions.\n\u2022 enemy monotonicity (EM) if, for all coalitions C \u2208 Ni, agents j \u2208 N , and utility vectors ui, u \u2032 i \u2208 Q n with ui(k) = u \u2032 i(k) for all k 6= j and u \u2032 i(j) < ui(j) < 0, it holds that\nAi(C, ui) \u2265 Ai(C, u \u2032 i). In other words, decreasing the utility for an enemy cannot improve a coalition value.\n\u2022 enemy domination (ED) if, for all utility vectors ui \u2208 Q n and agents j \u2208 N \\ {i}, there\nexists a constant c(ui, j) such that for all utility vectors u \u2032 i \u2208 Q n with u\u2032i(k) \u2264 ui(k) for all k \u2208 N and u\u2032i(j) \u2264 c(ui, j), it holds for every C \u2208 Ni with j \u2208 C that Ai(C, u \u2032 i) < Ai({i}, u \u2032 i). In other words, an CAF satisfies ED if in case i\u2019s utility for some agent j is sufficiently negative and i\u2019s utility for every other agent is bounded, then no coalition containing j is individually rational for i.\nAll of these axioms capture the treatment of enemies. The first two axioms deal with situations where an enemy leaves the agent\u2019s coalition, where ATE is stronger than IR ATE. On the other hand, EM and ED are variable utility conditions describing situations where the utility for an enemy decreases or some agent turns into a very bad enemy, respectively. Apart from the implication between ATE and IR ATE, there are no other logical relationships between any pair of axioms.\nExample 2.2. In this example, we consider a game (N,u) for which the CAF MF violates ATE. Let N = {a, b, c} and let the single-agent utilities be ua(b) = \u22121, ua(c) = \u22123, ub(a) = 1, and ub(c) = \u22121. (The utilities uc(a) and uc(b) are irrelevant.)\nThen, removing an enemy can make an agent worse. Indeed, MF a(N,ua) = \u22122 > \u22123 = MF a({a, c}, ua). Hence, MF violates ATE. On the other hand, as we will see in Proposition 2.3, removing an enemy from an individually rational coalition cannot decrease the utility in an MFHG. For instance, MF b(N,ub) = 0 < 1 = MF b({a, b}, ub). \u22b3\nStill, classical aggregation functions usually satisfy (most of) our introduced axioms.\nProposition 2.3. The additively separable CAF AS i satisfies ATE, IR ATE, EM, and ED. The modified fractional CAF MF i satisfies IR ATE, EM, and ED but violates ATE.\nProof. We first consider additively separable aggregation and each axiom separately.\n\u2022 ATE holds because a sum gets smaller when removing a negative summand.\n\u2022 IR ATE follows from ATE.\n\u2022 EM holds because a sum can only get smaller when decreasing every summand (and decreasing one of them strictly).\n\u2022 ED holds because \u2211\nk\u2208C\\{i} ui(k) gets negative if all summands only diminish and, for j \u2208 C \\ {i}, u(j) \u2264 \u22121 \u2212 \u2211\nk\u2208C\\{j} ui(k). Hence, we can choose the constant c(ui, j) = minC\u2208Ni : j\u2208C \u22121\u2212 \u2211 k\u2208C\\{j} ui(k).\nNext, we consider modified fractional aggregation. The violation of ATE is considered in Example 2.2.\n\u2022 IR ATE: Let C \u2286 Ni, j \u2208 C \\ {i}, and ui \u2208 Q n with ui(j) < 0. Moreover, suppose that\nMF i(C, ui) \u2265 0. Then, |C| \u2265 3 because otherwise MF i(C, ui) = ui(j) < 0. Consequently,\nMF i(C \\ {j}, ui) \u2265 MF i(C, ui)\n\u21d4\n\u2211\nk\u2208C\\{i,j} ui(k)\n|C| \u2212 2 \u2265\n\u2211\nk\u2208C\\{i} ui(k)\n|C| \u2212 1\n\u21d4(|C| \u2212 1) \u2211\nk\u2208C\\{i,j}\nui(k) \u2265 (|C| \u2212 2) \u2211\nk\u2208C\\{i}\nui(k)\n\u21d4 \u2211\nk\u2208C\\{i,j}\nui(k) \u2265 (|C| \u2212 2)ui(j)\n\u21d4\n\u2211\nk\u2208C\\{i} ui(k)\n|C| \u2212 1 \u2265 ui(j).\nHence, whenever ui(j) < 0 and MF i(C, ui) \u2265 0, the utility increases in the coalition where j has left.\n\u2022 EM and ED hold for the same reasons as for ASHGs because the division by a positive number does not change the respective arguments."
        },
        {
            "heading": "3 Dynamics for Resentful Agents",
            "text": "In this section, we study the convergence of different types of dynamics for resentful agents. We start by considering (S)CS and IS dynamics, before turning to CNS and NS dynamics."
        },
        {
            "heading": "3.1 Core Stability and Individual Stability",
            "text": "If deviating agents need consensus from their new coalition, it turns out that resent is a strong force to establish convergence. The intuitive reason for this is that an agent a can only leave an agent b for a limited number of times until resent prevents that they form a joint coalition again. In fact, otherwise b\u2019s utility for a becomes arbitrarily negative and b no longer gives a her consent to join. We will prove that SCS dynamics, and thereby also CS and IS dynamics, always converge for a wide class of CAFs.\nTheorem 3.1. The SCS, CS, and IS dynamics converge for resentful agents whose CAFs satisfy aversion to enemies and enemy monotonicity.\nProof. It suffices to consider SCS dynamics because every CS dynamics and every IS dynamics is also an SCS dynamics.\nLet a hedonic game (N,u0) with resentful agents be given where every agent i \u2208 N has a CAF Ai that satisfies aversion to enemies and enemy monotonicity. The key insight to show convergence of the SCS dynamics is to prove that in every infinite sequence of SCS deviations, it happens infinitely often that the non-negative single-agent valuation of some agent for another agent is decreased (due to resent). This is a contradiction, as the number of such deviations is bounded by \u2211\ni,j\u2208N : u0i (j)\u22650 (\u230au0i (j)\u230b + 1).\nConsider an infinite execution (\u03c0t)t\u22650 of the SCS dynamics. For the sake of contradiction, assume that there is a step t0 \u2265 0 in this execution such that, starting with t0, it never happens again that the non-negative valuation of some agent for another agent is decreased. The first step towards a contradiction is to show that every SCS deviation is a Pareto improvement in this situation.2 Indeed, every deviation is weakly improving for every agent in the coalitions that are abandoned: As no agent decreases her non-negative utility for another agent, each abandoned agent is solely abandoned by agents for which she momentarily has a negative utility. We can then iteratively apply aversion to enemies to conclude that the deviation (weakly) increases the utility of each abandoned agent. Further, since by the definition of an SCS deviation, every agent of the newly formed coalition is weakly improving, and some of them are strictly improving, each SCS deviation is a Pareto improvement.\nStill, it is not clear, why the changes of the utility functions due to resent cannot cause sequences of Pareto improvements of infinite length, and we need enemy monotonicity to prove that this can never be the case. To this end, we will show that every agent i can deviate at most once to each coalition C \u2208 Ni while improving her utility by doing so. This provides an upper bound for the length of any sequence of Pareto improving deviations.\nConsider a time t \u2265 t0 and define for some agent i \u2208 N the set C t i = {C \u2208 Ni : u t i(C) > uti(\u03c0 t)}, i.e., the set of coalitions that would lead to an improvement of agent i at time t. Consider the potential function V t = \u2211\ni\u2208N |C t i |. Note that V t0 \u2264 \u2211\ni\u2208N |Ni| is initially bounded and that the potential attains only non-negative integer values. We will show that the potential decreases in every time step after t0.\nTo this end, let i \u2208 N be some fixed agent and t \u2265 t0 some fixed time. If \u03c0 t+1(i) = \u03c0t(i),\nthen agent i does not change her utilities, and Ct+1i = C t i . Further, if \u03c0 t+1(i) 6= \u03c0t(i) but agent i was not part of the deviating coalition, then, by our above assumption that no non-negative utility gets decreased, uti(j) < 0 for all agents j \u2208 \u03c0\nt(i)\\\u03c0t+1(i). Hence, we can repeatedly apply aversion to enemies for all agents in \u03c0t(i) \\ \u03c0t+1(i) to conclude that ut+1i (\u03c0 t+1) = uti(\u03c0 t+1) \u2265 uti(\u03c0 t). Further, as only i\u2019s valuations of agents from \u03c0t(i) \\ \u03c0t+1(i) got modified (decreased), the only coalitions C \u2208 Ni that might have changed their value for agent i contain some agent in \u03c0t(i) \\ \u03c0t+1(i). Hence, we can (repeatedly) apply enemy monotonicity to conclude that ut+1i (C) \u2264 u t i(C) for all such coalitions. Hence, C t+1 i \u2286 C t i .\nFinally, if agent i is part of the deviating coalition at step t, then she does not change her utilities for any agent and weakly improves the valuation of her coalition. Hence, Ct+1i \u2286 C t i and we can conclude that V t+1 \u2264 V t. Further, if i strictly improves her utility, then ut+1i (\u03c0 t+1) > ut+1i (\u03c0 t) and it follows that \u03c0t+1(i) \u2208 Cti \\ C t+1 i . Hence, C t+1 i ( C t i . Since this has to be the case for at least one agent in every time step, we conclude that V t+1 < V t.\nAs the cardinal aggregation function AS satisfies aversion to enemies and enemy monotonicity (cf. Proposition 2.3), Theorem 3.1 in particular implies that the SCS, CS, and IS dynamics always converge in ASHGs for resentful agents.\nNotably, Theorem 3.1 breaks down if we consider a CAF violating aversion to enemies, even if enemy monotonicity is still satisfied. Indeed, we can then \u201cignore\u201d individual utilities. For instance, anonymous hedonic games where agents only care about the size of their coalitions satisfy enemy monotonicity. In such games, resent is clearly irrelevant and there exist anonymous hedonic games where IS dynamics cycle (Brandt et al., 2021). Consequently, a result similar to Theorem 3.1 for aggregation functions that only satisfy enemy monotonicity cannot be obtained. On the other hand, it remains an open question whether enemy monotonicity is necessary for Theorem 3.1.\n2An outcome is a Pareto improvement over another outcome if it is weakly better for all agents and strictly better for some agents.\nUnfortunately, MF violates aversion to enemies (Proposition 2.3), implying that Theorem 3.1 cannot be directly applied to MFHGs for resentful agents. Nevertheless, if we require the performed SCS deviations to be individually rational, then we can achieve convergence for a class of games containing MFHGs (cf. Proposition 2.3).\nTheorem 3.2. The individually rational SCS, CS, and IS dynamics converge for resentful agents whose CAFs satisfy individually rational aversion to enemies and enemy monotonicity.\nProof. Again, it suffices to consider SCS dynamics. Let a hedonic game (N,u0) with resentful agents be given where every agent i \u2208 N has a CAF Ai that satisfies individually rational aversion to enemies and enemy monotonicity. Assume that agents perform only individually rational deviations. Assume for contradiction that there exists an infinite execution of the individually rational SCS dynamics. Since the single-agent utilities for other agents can only decrease and are bounded by the initial partition of the sequence, there exists a time t0 \u2265 0 in the infinite dynamics after which no agent can be left by an agent for which she has non-negative utility. By Lemma 2.1, there exists a time t1 \u2265 t0 such that every SCS deviation performed after time t1 is performed infinitely often.\nNow, consider the first group deviation performed after time t1, where a coalition C is formed and let i \u2208 C be an arbitrary agent in this coalition. Note that the formation of C was an individually rational deviation, and therefore C is individually rational for agent i at time t1. We claim that i\u2019s utility cannot decrease until the next time when the same deviation is performed, and that all coalitions that i is part of until then are IR. Until the next repetition of the same deviation, there are two potential cases when i\u2019s utility is affected. First, it can happen that i is part of a deviating coalition. Clearly, this cannot decrease her utility, and therefore not affect her individual rationality. Second, it can happen that i\u2019s coalition is left by a set of agents D. Since i is resentful and decreases her utility for all agents in D, it must be the case that her utility is negative for every agent in D at the point in time where the deviation involving D occurs.\nMoreover, i\u2019s coalition is IR when D leaves. Indeed, assume for contradiction that i\u2019s coalition is not IR, and consider the first time after the formation of C when i is in a coalition that is not IR. By our analysis before, this can only happen after i performed a group deviation, but since this deviation originated from an IR coalition, the resulting coalition must also be IR, a contradiction.\nNow, by applying individually rational aversion to enemies for each agent in D one after another, we can conclude that i cannot have decreased her utility at the point in time where she is left by D.\nHence, at the next time, when coalition C is formed, by the same deviation as our initial deviation, none of the agents in C has decreased her utility. Moreover, enemy monotonicity implies that the utility of C of any agent for C can only have decreased since the last time when C was formed. Hence, no agent can strictly improve her utility when forming C again, a contradiction. We conclude that the dynamics cannot run infinitely.\nIt remains open whether general SCS, CS, or IS dynamics for resentful agents may cycle in an MFHG."
        },
        {
            "heading": "3.2 Contractual Nash Stability and Nash Stability",
            "text": "For individually rational NS dynamics, resent helps to establish convergence for a wide class of games.\nTheorem 3.3. The individually rational NS dynamics converges for resentful agents whose CAFs satisfy enemy domination.\nProof. Let a hedonic game (N,u0) with resentful agents be given where every agent i \u2208 N has a CAF Ai that satisfies enemy domination. Assume for contradiction that there is an infinite execution of the individually rational NS dynamics (\u03c0t)t\u22650. Suppose that, for every t \u2265 1, \u03c0 t evolves from \u03c0t\u22121 by an individually rational NS deviation of agent dt. By Lemma 2.1, there exists t0 \u2265 0 such that every deviation performed after t0 is performed infinitely often. We will reach a contradiction in two steps. First, we use enemy domination to show that no agent can ever be abandoned by an agent that she joined after t0. Then, as a second step, we use this insight to show the existence of a non-negative potential function decreasing in every time step after t0.\nFor the first step, let i \u2208 N be an agent and let C \u2208 Ni be a coalition such that agent i performs a deviation at time t1 \u2265 t0 to form coalition C. Then, no agent from C \\ {i} can abandon agent i in any of their deviations after time t0. Assume for contradiction that there exists an agent j \u2208 C \\ {i} who abandons agent i after time t0. Since the aggregation function satisfies enemy domination, there is a constant c(ui, j) such that for all utility vectors u \u2032 i with u\u2032i(k) \u2264 u t1 i (k) for all k \u2208 N and u \u2032 i(j) \u2264 c(ui, j), it holds that u \u2032 i(C) < u \u2032 i({i}).\nSince every deviation occurs infinitely often, there exists a time t2 \u2265 t1 such that agent j has abandoned agent i for at least ut1i (j) \u2212 c(ui, j) times between time t1 and time t2. Since agent i is resentful, this implies that ut2i (j) \u2264 u t1 i (j)\u2212 (u t1 i (j)\u2212 c(ui, j)) = c(ui, j). Additionally, resentful agents can only decrease utilities for other agents. Therefore, it holds for all t \u2265 t2 and k \u2208 N that uti(k) \u2264 u t1 i (k) and u t i(j) \u2264 c(ui, j). Consequently, it follows from enemy domination for all times t \u2265 t2 that agent i cannot deviate to form coalition C again because this deviation would not be individually rational. However, this contradicts the fact that every deviation after time t1 has to be performed infinitely often. This establishes the second step, i.e., that an agent can never be left by an agent that is part of a coalition which she joins after time t0.\nFor the second step, we will now define a potential function that is bounded from below by 0, integer-valued, and strictly decreasing in every step t \u2265 t1. Therefore, fix an agent i \u2208 N and define Ai = {j \u2208 N : j abandons i after time t0}. Given t \u2265 t0, we have to distinguish two cases. If i already performed a deviation after time t0, then let di(t) = max{t0 \u2264 t \u2032 \u2264 t : dt \u2032 = i} be the last time that i performed a deviation between t0 and t. In this case, define Pi(t) = {C \u2286 N \\ Ai : i \u2208 C, u t i(C) > u t i(\u03c0 di(t))}. Otherwise, set Pi(t) = 2 N\\Ai . Note that Pi(t) contains all coalitions which i could potentially form through a deviation after time t. Define the potential \u039b(t) = \u2211\nj\u2208N |Pj(t)|.\nWe observe that Pi(t + 1) = Pi(t) if i 6= d t+1. Assume now that i = dt+1. If the first deviation of i occurs at time t, then Pi(t + 1) \u2286 Pi(t) \\ {\u03c0 t(i)}. Otherwise, it must hold that \u03c0t(i) = \u03c0di(t)(i), i.e., i is part of the same coalition in step t to which it deviated in step di(t), which is the last deviation performed by i. Indeed, due to the second step, no agent that was present when i joined \u03c0di(t)(i) \\ {i} can have left and i is not allowed to leave if any agent from N \\ \u03c0di(t)(i) is still present. Also, agent i\u2019s utilities for agents in N \\Ai have not changed since her last deviation and therefore uti(j) = u\ndi(t)(j) for all j \u2208 N \\ Ai. Thus, i derives the same utility from \u03c0t(i) and \u03c0di(t)(i). It follows that Pi(t+1) \u2286 Pi(t) \\ {\u03c0\nt(i)}. Consequently, in each case, \u039b(t+ 1) < \u039b(t). As \u039b(t) \u2265 0 for all t \u2265 t1, the dynamics can run for at most \u039b(t1) steps after time t1. This completes the proof.\nAs AS and MF satisfy enemy domination (Proposition 2.3), Theorem 3.3 implies that the individually rational NS dynamics converges in ASHGs and MFHGs for resentful agents. However, we do not know under which conditions resent is sufficient to guarantee convergence for arbitrary (not necessarily individually rational) NS dynamics. In this case, our proof for Theorem 3.3 no longer works because it is possible that agents join coalitions for which they have an arbitrarily low utility (if the utility for their abandoned coalition was even worse). In\nfact, slightly counterintuitive, there is a non-trivial example of a cycling NS dynamics in an MFHG for resentful agents.\nTheorem 3.4. The NS dynamics may cycle in MFHGs for resentful agents.\nProof. We now describe an involved example of an MFHG together with an infinite periodic sequence of NS deviations for resentful agents. We construct this example in a way such that each agent leaves every other agent exactly once in each cycle. This establishes that the agents\u2019 preference between relevant coalitions is maintained : if a deviating agent prefers a joined coalition C1 to an abandoned coalition C2 before (and during) the first execution of the cycle, then it still prefers C1 to C2 before (and during) each execution of the cycle.\nConsider the game with agent set N = {a, a\u2032, b, b\u2032, c, c\u2032} and utilities as depicted in Table 2. The initial utilities result from setting x = 0 in Table 2. Note that the utility values are not chosen to be minimal but simply in a way that it can easily be verified that deviations are indeed NS deviations. We now present an infinite sequence (\u03c0t)t\u22650 of partitions, always consisting of three coalitions. For each partition, we refer to the first listed coalition as C1, to the second as C2, and the third as C3. For the sake of clarity, for each partition, we also specify which agent deviates to which coalition in the next step. Specifically, for n \u2265 0, we have\n\u2022 \u03c018n+1 = {{b\u2032, a\u2032}, {a}, {c\u2032 , c, b}} with agent b deviating to C1,\n\u2022 \u03c018n+2 = {{b\u2032, a\u2032, b}, {a}, {c\u2032 , c}} with agent c deviating to C1,\n\u2022 \u03c018n+3 = {{b\u2032, a\u2032, b, c}, {a}, {c\u2032}} with agent a\u2032 deviating to C3,\n\u2022 \u03c018n+4 = {{b\u2032, b, c}, {a}, {c\u2032 , a\u2032}} with agent a\u2032 deviating to C2,\n\u2022 \u03c018n+5 = {{b\u2032, b, c}, {a, a\u2032}, {c\u2032}} with agent c deviating to C2,\n\u2022 \u03c018n+6 = {{b\u2032, b}, {a, a\u2032, c}, {c\u2032}} with agent b\u2032 deviating to C3,\n\u2022 \u03c018n+7 = {{b}, {a, a\u2032, c}, {c\u2032, b\u2032}} with agent c deviating to C3,\n\u2022 \u03c018n+8 = {{b}, {a, a\u2032}, {c\u2032, b\u2032, c}} with agent a deviating to C3,\n\u2022 \u03c018n+9 = {{b}, {a\u2032}, {c\u2032, b\u2032, c, a}} with agent b\u2032 deviating to C2,\n\u2022 \u03c018n+10 = {{b}, {a\u2032, b\u2032}, {c\u2032, c, a}} with agent b\u2032 deviating to C1,\n\u2022 \u03c018n+11 = {{b, b\u2032}, {a\u2032}, {c\u2032, c, a}} with agent a deviating to C1,\n\u2022 \u03c018n+12 = {{b, b\u2032, a}, {a\u2032}, {c\u2032, c}} with agent c\u2032 deviating to C2,\n\u2022 \u03c018n+13 = {{b, b\u2032, a}, {a\u2032, c\u2032}, {c}} with agent a deviating to C2,\n\u2022 \u03c018n+14 = {{b, b\u2032}, {a\u2032, c\u2032, a}, {c}} with agent b deviating to C2,\n\u2022 \u03c018n+15 = {{b\u2032}, {a\u2032, c\u2032, a, b}, {c}} with agent c\u2032 deviating to C1,\n\u2022 \u03c018n+16 = {{b\u2032, c\u2032}, {a\u2032, a, b}, {c}} with agent c\u2032 deviating to C3,\n\u2022 \u03c018n+17 = {{b\u2032}, {a\u2032, a, b}, {c, c\u2032}} with agent b deviating to C3, and\n\u2022 \u03c018n+18 = {{b\u2032}, {a\u2032, a}, {c, c\u2032 , b}} with agent a\u2032 deviating to C1.\nThen, it is possible to verify that for k \u2265 1, \u03c0k\u22121 leads to \u03c0k by means of an NS deviation. Hence, we have presented an MFHG with an infinite sequence of NS deviations for resentful agents.\nThis result indicates that some condition like aversion to enemies is probably needed for establishing a convergence guarantee for general NS dynamics; however, it remains open whether such a result is possible (even for ASHGs). Notably, this question for CAFs satisfying aversion to enemies is the same as asking whether a CNS dynamics may cycle: For resentful agents in case of a cycling NS dynamics, there is also a cycling CNS dynamics.\nProposition 3.5. For resentful agents with CAFs satisfying aversion to enemies, every sequence of NS deviations contains only finitely many deviations that are not CNS deviations.\nProof. Let a hedonic game (N,u0) with resentful agents be given where every agent i \u2208 N has a CAF Ai that satisfies aversion to enemies. Furthermore, assume that there exists an infinite sequence (\u03c0t)t\u22650 of partitions resulting from NS deviations of resentful agents. By Lemma 2.1, there exists a time t0 \u2265 0 such that every deviation performed after t0 must occur infinitely often.\nDefine L = {(i, j) \u2208 N2 : i left by j after time t0}, i.e., the set of pairs of such agents. Let (i, j) \u2208 L. Then, there exists a time t(i, j) \u2265 t0 such that i was left by j for at least \u230au t0 i (j)\u230b+1 times after time t0 and before time t(i, j). Consider the time t1 = max{t(i, j) : (i, j) \u2208 L}. We claim that all deviations after time t1 are CNS deviations. Indeed, assume that agent i is left by agent j at time t \u2265 t1. By construction, as t(i, j) \u2264 t1, it holds that u t i(j) < 0. Consequently, enemy monotonicity implies that Ai(\u03c0 t, uti) \u2264 Ai(\u03c0\nt+1, uti). Hence, every deviation after time t1 is a CNS deviation. Thus, there are only finitely many deviations (at most t1 many) that are not CNS deviations."
        },
        {
            "heading": "4 Dynamics for Appreciative Agents",
            "text": "We now turn to analyzing the effects of appreciation on the convergence of different types of dynamics. Here, as statements for general CAFs would require the introduction of (even) further axioms, we focus on AS and MF instead. We start by establishing a close connection between cycling dynamics for resentful and appreciative agents in ASHGs, highlighting a close connection between the two studied models. Subsequently, we analyze CS and (C)NS dynamics."
        },
        {
            "heading": "4.1 From Resent to Appreciation",
            "text": "We describe how we can transform certain types of infinite sequences of deviations for resentful agents to sequences for appreciative agents and vice versa. We focus on ASHGs, yet believe that similar statements can hold for other classes of hedonic games. We start with Nash stability.\nTheorem 4.1. The following statements are equivalent:\n1. There exists an ASHG admitting an infinite and periodic sequence of NS deviations for resentful agents.\n2. There exists an ASHG admitting an infinite and periodic sequence of NS deviations for appreciative agents.\nThe idea to prove Theorem 4.1 is to reverse a periodic fragment of an infinite sequence and to appropriately adjust the initial utilities. This essentially reverses the roles of resent and appreciation, as the agents that an agent a leaves in the sequence for resentful agents correspond to the agents a joins in the sequence for appreciative agents. The formal proof is quite technical and we defer it to the appendix.\nBy Proposition 3.5, Theorem 4.1 can be extended to also include infinite and periodic sequences of CNS deviations for resentful agents. In fact, the equivalence can be extended even further, as we show that in ASHGs with appreciative agents, the question whether there is a cycling NS dynamics is equivalent to asking for a cycling IS dynamics. The proof idea for the next statement is that in every infinite sequence of NS deviations, there exists a certain time step from which on agent a has a positive utility for each agent b that joins a (because b has already joined a sufficiently often).\nProposition 4.2. For appreciative agents in ASHGs every sequence of NS deviations contains only finitely many deviations that are not IS deviations.\nProof. Let an ASHG (N,u0) with appreciative agents be given. Furthermore, assume that there exists an infinite sequence (\u03c0t)t\u22650 of partitions resulting from NS deviations. By Lemma 2.1, there exists a time t0 such that every deviation performed after t0 occurs infinitely often.\nDefine L = {(i, j) \u2208 N2 : i is joined by j after time t0}. Let (i, j) \u2208 L. Then, there exists a time t(i, j) \u2265 t0 such that i was joined by j for at least \u2308|u t0 i (j)|\u2309 + 1 times after time t0 and before time t(i, j). Consider the time t1 = max{t(i, j) : (i, j) \u2208 L}. We claim that all deviations after time t1 are IS deviations. Indeed, assume that agent i is joined by agent j at time t \u2265 t1. By construction, as t(i, j) \u2264 t1, it holds that u t i(j) > 0. Consequently, agent i prefers \u03c0\nt+1 to \u03c0t. Hence, every deviation after time t1 is an IS deviation. Thus, there are only finitely many deviations (at most t1 many) that are not IS deviations.\nTo sum up, combining Theorem 4.1 and Propositions 4.2 and 3.5, we get the following equivalences.\nCorollary 4.3. The following statements are equivalent:\n1. There exists an ASHG admitting an infinite and periodic sequence of CNS deviations for resentful agents.\n2. There exists an ASHG admitting an infinite and periodic sequence of NS deviations for resentful agents.\n3. There exists an ASHG admitting an infinite and periodic sequence of NS deviations for appreciative agents.\n4. There exists an ASHG admitting an infinite and periodic sequence of IS deviations for appreciative agents."
        },
        {
            "heading": "4.2 Convergence for Appreciative Agents",
            "text": "We now give an overview under which circumstances appreciation is (not) sufficient to guarantee convergence in MFHGs and ASHGs. In contrast to resent, appreciation is not sufficient to guarantee convergence of CS dynamics.3\nTheorem 4.4. The individually rational CS dynamics may cycle in ASHGs and MFHGs for appreciative agents.\nProof. Let N = {a, b, c} be the set of agents and let the agents\u2019 initial utilities be as follows:\nu0a(b) = u 0 b(c) = u 0 c(a) = 4, u 0 a(c) = u 0 b(a) = u 0 c(b) = 1.\nLet \u03c00 = {{a}, {b}, {c}} and for t > 0, let\n\u03c0t =\n\n \n \n{{a, c}, {b}}, if t mod 3 = 0\n{{a, b}, {c}}, if t mod 3 = 1\n{{a}, {b, c}}, if t mod 3 = 2.\nWe claim that (\u03c0t)t\u22650 is an infinite sequence, where for every t \u2265 1, \u03c0 t evolves from \u03c0t\u22121 by a core deviation of coalition Ct. Specifically, we have\nCt =\n\n \n \n{a, c}, if t mod 3 = 0\n{a, b}, if t mod 3 = 1\n{b, c}, if t mod 3 = 2.\nThus in each cycle of length three, each agent performs exactly one core deviation with any other agent. Thus, for t \u2265 0 with t mod 3 = 0 it holds that\nuta(b) = u t b(c) = u t c(a) =\n2 3 t+ 4\nand\nuta(c) = u t b(a) = u t c(b) =\n2 3 t+ 1.\nThus, for each t > 0, it holds that uta(b) > u t a(c), u t b(c) > u t b(a), and u t c(a) > u t c(b), implying that each of the deviations Ct for t > 0 is a core deviation if each agent i \u2208 N aggregates utilities according to AS i or MF i.\nHowever, in the games considered in Theorem 4.4, there exists an execution of the CS dynamics that converges. This raises the (open) question whether a converging execution of the CS dynamics exists for every initial state in ASHGs and MFHGs for appreciative agents.\nLastly, we consider IS and (C)NS dynamics. In ASHGs for appreciative agents, it remains open whether IS and NS dynamics may cycle. In fact, we have seen in Proposition 4.2 that these two questions are equivalent and in Corollary 4.3 that they are very closely related to our open questions concerning resentful agents. On the other hand, for CNS, appreciation is sufficient to guarantee convergence.\nTheorem 4.5. The CNS dynamics converges in ASHGs for appreciative agents.\n3For ASHGs, the next statement can be extended to an ASHG where initial valuations are symmetric by slightly modifying the game presented by Aziz et al. (2013, Figure 2).\nProof. Let an ASHG (N,u0) be given and consider an execution (\u03c0t)t\u22650 of the CNS dynamics. Assume for contradiction that the dynamics is infinite. By Lemma 2.1, there exists t0 \u2265 0 such that every deviation performed at time t \u2265 t0 is performed infinitely often.\nNow, consider an agent i that joins a coalition C containing agent j at some time t \u2265 t0. We claim that it is impossible that j ever joins a coalition containing agent i after time t0. For the contrary, assume that this happens, and therefore happens infinitely often. Then, since agent i and agent j join each other infinitely often, there exists a time t\u2032 \u2265 t0 such that u t j(i) > 0 and uti(j) > 0 for all t \u2265 t \u2032. Some time after t\u2032, the agents i and j will be in a joint coalition, again. Then, to perform the deviation again where i joins C, the two agents have to be dissolved, i.e., one of them has to leave the other. However, since they by now have positive utility for each other, each of them would block the other agent from leaving according to the additively separable CAF. Hence, this cannot happen, a contradiction. Consequently, agent j cannot join a coalition containing i after time t0.\nThus, the utilities of an agent i for agents in coalitions which she joins by a deviation are not affected after time t0 by appreciation. Therefore, there exists a global constant U such that the maximum utility of any agent obtained after any deviation is U . We derive a contradiction by showing that some agent has to abandon a coalition of unbounded utility.\nTo this end, we prove the following claim.\nClaim 4.6. There exists an agent i that abandons a coalition C containing an agent j that joins i at some point during the dynamics.\nProof. Assume for contradiction that no such agent exists. To derive a contradiction, we will construct an infinite sequence of coalitions increasing in utility with respect to the utility at time t0. This cannot happen, because the number of coalitions an agent can be part of (and therefore the number of different utility values that an agent can achieve at a fixed time) is bounded.\nWe claim that there exists an agent d \u2208 N and a sequence of coalitions (Ck)k\u22650 such that for every k \u2265 1, the following two conditions hold:\n1. d\u2019s utility with respect to time t0 is strictly increasing, i.e., u t0 d (Ck) > u t0 d (Ck\u22121).\n2. The coalition Ck is formed by a deviation of agent d.\nConsider the first agent d performing a deviation after time t0, where d abandons coalition C0 to form coalition C1. Then, u t0 d (C1) > u t0 d (C0). Hence, we have found the first step of the sequence. Now, assume that we have constructed a sequence (Ck) m k=0 which satisfies the two conditions. We know that Cm is formed by a deviation of agent d. Consider the next time t\u0302 where some agent e \u2208 Cm leaves the coalition C containing Cm (which must happen, because the dynamics is infinite). If e 6= d, then we derive a contradiction to our initial assumption because e then leaves a coalition containing an agent, namely agent d, that joined her by a deviation. Hence, e = d. If there exists an agent f \u2208 C \\ Cm, then we again derive a contradiction because f must have joined d at some point. This implies that C = Cm. Set Cm+1 to the coalition joined by agent d. Then, Cm+1 clearly fulfills the second condition. Also, ut0d (Cm+1) = u t\u0302 d(Cm+1) > u t\u0302 d(C) = u t\u0302 d(Cm) = u t0 d (Cm). In the first and last equality, we use that appreciation does not affect the utilities for agents joined by agent d after time t0. Hence, also the first condition is fulfilled. As such a sequence of coalitions cannot exist, we derive a contradiction, and the claim must hold. \u22b3\nNow, consider an agent i that abandons a coalition C containing an agent j that joins i at some point during the dynamics. Since the deviation where agent j joins i happens infinitely\noften, there exists a time T \u2265 t0 such that u t i(j) \u2265 U \u2212\n\u2211\nl\u2208C\\{j} u t0 i (l) for all t \u2265 T . Consider\nthe next time T \u2032 \u2265 T where i abandons C to form some coalition D. Then, uT \u2032\ni (D) \u2264 U \u2264 uT \u2032\ni (j) + \u2211 l\u2208C\\{j} u t0 i (l) \u2264 u T \u2032\ni (C). In the last inequality, we use that the utility of i for other agents can only have increased since time t0 (because of appreciation). Hence, this deviation was not beneficial for i. This is a final contradiction showing that an infinite dynamics cannot exist.\nWe proved in Theorem 3.4 that NS dynamics may cycle in MFHGs for resentful agents. \u201cReversing\u201d this sequence and appropriately adjusting the initial utilities leads to a cycling NS dynamics for appreciative agents. We defer the details to the appendix.\nTheorem 4.7. The individually rational NS dynamics may cycle in MFHGs for appreciative agents.\nIt remains open whether IS dynamics may cycle in MFHGs for appreciative agents. Note that the arguments from Proposition 4.2 for showing the \u201cequivalence\u201d for IS and NS dynamics under appreciation do not work for MFHGs."
        },
        {
            "heading": "5 Dynamics with Resentful Deviatiors",
            "text": "Previously, we have assumed that a deviation of an agent a changes the utility other agents have for a. In contrast, one could also consider what happens if a deviation of a changes a\u2019s utility for other agents. Under deviator-resent, we assume that an agent decreases her utility for all agents she abandons.\nFormally, if for some t \u2265 1, \u03c0t evolves from \u03c0t\u22121 via a single-agent deviation of agent k \u2208 N , then for deviator-resentful agents, for i, j \u2208 N , uti(j) arises from u t\u22121 i (j) as\nuti(j) =\n{\nut\u22121i (j) \u2212 1 i = k, j \u2208 \u03c0 t\u22121(i) \\ {i}, ut\u22121i (j) else.\nSimilarly, for deviator-resentful agents, if for t \u2265 1, \u03c0t evolves from \u03c0t\u22121 via a group deviation of C \u2286 N , then, for i, j \u2208 N , uti(j) arises from u t\u22121 i (j) as\nuti(j) =\n{\nut\u22121i (j)\u2212 1 i \u2208 C, j \u2208 \u03c0 t\u22121(i) \\ C, ut\u22121i (j) else.\nIn addition to the axioms introduced in Section 2, we also define two more axioms that are only relevant for the results in this section. These are weak conditions about friends.\n\u2022 friend necessity (FN) if, for all coalitions C \u2208 Ni and utility vectors ui \u2208 Q n, Ai(C, ui) > 0\nimplies that there exists j \u2208 C \\ {i} with ui(j) > 0. In other words, an agent can only have a positive utility for a coalition if it contains a friend.\n\u2022 single friend desire (SFD) if, for all coalitions C \u2208 Ni, agents j \u2208 C \\ {i}, and utility vectors ui \u2208 Q\nn such ui(j) > 0 and ui(k) \u2264 0 for all k \u2208 C \\ {j}, it holds that Ai(C, ui) > Ai(C \\ {j}, ui). In other words, a coalition to which exactly one friend belongs is strictly preferred to the same coalition without this friend.\nWe show that additively separable and modified fractional utility aggregation satisfies these axioms.\nProposition 5.1. The additively separable CAF AS i and the modified fractional CAF MF i satisfy FN and SFD.\nProof. FN holds because a sum (or a sum divided by a positive number) can only be positive if some summand is positive. SFD holds for the additively separable aggregation because a sum gets larger when adding a positive number. SFD holds for the modified fractional aggregation because a negative fraction gets larger when adding a positive number to the numerator while the denominator increases."
        },
        {
            "heading": "5.1 Contractual Nash Stability and Nash Stability",
            "text": "An intuitive reason why deviator-resent can contribute to the convergence of dynamics is that, after agent a abandons a coalition C, a\u2019s utility for C decreases and thus a is less likely to join C again. However, deviator-resent does not resolve the run-and-chase example, implying that NS dynamics may cycle for a wide variety of hedonic games with deviator-resentful agents. Indeed, consider the dynamics between two agents a and b where initially a has utility 1 for b and b initially has utility \u22121 for a. Then, a will still always join b in one step, while b leaves a in the next step (thereby decreasing b\u2019s utility for a even further).\nObservation 5.2. The NS dynamics may cycle for deviator-resentful agents whose CAFs satisfy friend necessity and single friend desire.\nBy Proposition 5.1 this implies that the NS dynamics may cycle in ASHGs and MFHGs. Moreover, somewhat surprisingly, also CNS dynamics may still cycle in ASHGs and MFHGs with deviator-resentful agents, even if deviations are restricted to be individually rational. Notably, this is in a clear contrast to our previous results for resentful agents where individual rationality was for all types of dynamics sufficient to guarantee convergence.\nProposition 5.3. The individually rational CNS dynamics may cycle in MFHGs and ASHGs for deviator-resentful agents.\nProof. Consider a cardinal hedonic game with N = {a, b, c} where the initial single-agent utilities are given as ua(b) = ub(c) = uc(a) = 0 and ub(a) = uc(b) = ua(c) = \u22121. For k \u2265 0, let \u03c03k = {{a, b}, {c}}, \u03c03k+1 = {{a}, {b, c}}, and \u03c03k+2 = {{a, c}, {b}}.\nThen, (\u03c0k)k\u22650 represents an individually rational CNS dynamics with respect to additively separable and modified fractional utility aggregation.\nIt is possible to modify the previous examples to start a dynamics from the singleton partition.\nIn contrast to this, as soon as we enforce that agents only deviate to a non-singleton coalition if they strictly prefer it to being in a singleton coalition, convergence can be guaranteed.\nProposition 5.4. The CNS dynamics converges for deviator-resentful agents whose CAFs satisfy friend necessity and single friend desire if agents only deviate to non-singleton coalitions if they strictly prefer them to being in a singleton.\nProof. Let a hedonic game (N,u0) with deviator-resentful agents be given where every agent i \u2208 N has a CAF Ai that satisfies friend necessity and single friend desire. Assume for the sake of contradiction that there exists an infinite sequence (\u03c0t)t\u22650 of partitions resulting from CNS deviations of deviator-resentful agents where agents only deviate to non-singleton coalitions if they strictly prefer them to being in a singleton. By Lemma 2.1, there exists a time t0 \u2265 0 such that every deviation performed after t0 must occur infinitely often. This implies in particular\nthat there is a step t\u20320 \u2265 t0 such that an agent i has a negative utility for all agents that i leaves at some point after t\u20320.\nNow, let us fix a time step t\u2032 \u2265 t\u20320 where some agent d deviates into a non-singleton coalition. As every deviation is repeated (infinitely often) after t0 \u2264 t\n\u2032, there has to be some time step where d deviates again. In particular, let t\u2032\u2032 be the smallest t with t > t\u2032 where d deviates again after time t\u2032. For some time step t, let Ct := \u03c0\nt(d) be the coalition of d after step t. We now examine the coalitions Ct\u2032 , . . . , Ct\u2032\u2032\u22121, i.e., the coalitions d is part of between her two deviations.\nAs we assume that an agent only deviates into a non-singleton coalition if she strictly prefers it to being in a singleton coalition, d prefers Ct\u2032 to being in a singleton. Hence, by friend necessity, there is an agent a \u2208 Ct\u2032 for which d has positive utility at time t\n\u2032\u22121. By single friend desire, it follows that there is an agent a \u2208 Ct\u2032\u2032\u22121 for which d has a positive utility. Indeed, otherwise, there is some t \u2208 [t\u2032, t\u2032\u2032 \u2212 2] such that there is a friend of d in Ct but not in Ct+1. However, this cannot happen because, due to single friend desire, d strictly prefers Ct to Ct+1, implying that d would have vetoed the deviation taking place in time step t+ 1. This implies that there is at least one agent for which d has positive utility in Ct\u2032\u2032\u22121. However, d leaves this agent in time step t\u2032\u2032. This contradicts our initial assumption that each agent has a negative utility for all agents they leave in some step after t\u20320 \u2264 t \u2032 \u2264 t\u2032\u2032.\nAs the CAFs AS i and MF i satisfy friend necessity and single friend desire (cf. Proposition 5.1), Proposition 5.4 implies that, for every ASHG and MFHG with deviator-resentful agents, some execution of the CNS dynamics converges."
        },
        {
            "heading": "5.2 Core Stability and Individual Stability",
            "text": "We now turn to the consent-based stability concepts individual stability and (strict) core stability. Here, the influence of deviator-resent is more profound.\nIndividual Rationality\nWe start by considering individually rational SCS dynamics. Here, like for resentful agents, convergence is guaranteed for a wide class of CAFs.\nProposition 5.5. The individually rational SCS, CS, and IS dynamics converge for deviatorresentful agents whose CAFs satisfy enemy domination.\nProof. We show the statement for SCS deviations, which implies convergence of CS and IS dynamics. Let a hedonic game (N,u0) with deviator-resentful agents be given where every agent i \u2208 N has a CAF Ai that satisfies enemy domination. Assume for the sake of contradiction that there exists an infinite sequence (\u03c0t)t\u22650 of partitions resulting from SCS deviations of deviatorresentful agents. By Lemma 2.1, there exists a time t0 \u2265 0 such that every deviation performed after t0 must occur infinitely often.\nWe first show that if two agent i and j perform a core deviation together at some point after t0, then i cannot leave j nor can j leave i after t0. We prove that i cannot leave j (the other case is symmetric). By enemy domination, there exists a constant c(ut0i , j) such that for all utility vectors u\u2032i \u2208 Q n with u\u2032i(k) \u2264 u t0 i (k) for all k \u2208 N and u \u2032 i(j) \u2264 c(u t0 i , j), it holds for every C \u2208 Ni with j \u2208 C that Ai(C, u \u2032 i) < Ai({i}, u \u2032 i).\nAs each deviation after t0 occurs infinitely often, the fact that i leaves j after t0 infinitely often implies that there exists a time t1 \u2265 t0 such that agent i leaves agent j for u t0 i (j)\u2212c(u t0 i , j) times between time t0 and time t1. Since agent i is deviator-resentful, this implies that u t1 i (j) \u2264 c(ut0i , j). Additionally, deviator-resentful agents can only decrease utilities for other agents. Therefore, it holds for all t \u2265 t0 and k \u2208 N that u t i(k) \u2264 u t0 i (k). Consequently, from the\ndefinition of c(ut0i , j) it follows that agent i cannot deviate to form a coalition together with j after t1, because this deviation would not be individually rational. However, such a deviation takes place because we have assumed that i and j deviate together at some point after t0 and such a deviation is performed infinitely often. This establishes that i and j cannot leave each other after t0.\nFinally, consider some time t \u2265 t0 in which a coalition Ct performs a group deviation. Then, from our above observation we get that no agent that is part of Ct can ever leave another agent that is part of Ct after this, implying that \u03c0 t\u2032(j) \u2286 Ct for all j \u2208 Ct and t \u2032 \u2265 t. This implies that the size of Ct needs to monotonically increase over time. Notably, this holds for all coalitions that ever performed a deviation after time t0. Yet the overall number of agents is bounded, resulting in a contradiction.\nAs AS i and MF i satisfy enemy domination (Proposition 5.1), Proposition 5.5 implies that the individually rational SCS, IS, and CS dynamics converge in ASHGs and MFHGs for deviator-resentful agents.\nAbsence of Individual Rationality\nIf we drop the requirement that deviations are individual rational, the picture changes. For MFHGs, IS, CS, and SCS dynamics may cycle.\nProposition 5.6. The IS, CS, and SCS dynamics may cycle in MFHG for deviator-resentful agents, even when starting from the singleton partition.\nProof. Consider the MFHG with agent set N = {a, b, c, d, e, f} and utilities as depicted in Figure 3, where the number of an arc from agents i to j describes the utility that i has for j. The initial utilities result from setting x to 0 in Figure 3. Consider the following infinite sequence of partitions. For n \u2265 0,\n\u2022 \u03c03n = {{\u03b1, a, b}, {\u03b2}, {\u03b3, c}},\n\u2022 \u03c03n+1 = {{\u03b1, a}, {\u03b2, b, c}, {\u03b3}}, and\n\u2022 \u03c03n+2 = {{\u03b1}, {\u03b2, b}, {\u03b3, a, c}}.\nNote that the utilities of agents after x executions of this cycle of three deviations are shown in Figure 3. Observing that for k \u2265 1, \u03c0k\u22121 leads to \u03c0k by means of a (S)CS deviation completes the counterexample. Note that we can also modify the dynamics to start in the singleton partition, by inserting the two partitions {{\u03b1}, {\u03b2}, {\u03b3}, {a}, {b}, {c}} and {{\u03b1, a, b}, {\u03b2}, {\u03b3}, {c}} in the beginning of the dynamics.\nUsing the same initial utilities, for IS deviations we have the following cycling sequence of partitions. For n \u2265 0,\n\u2022 \u03c06n = {{\u03b1, a, b}, {\u03b2}, {\u03b3, c}},\n\u2022 \u03c06n+1 = {{\u03b1, a, b}, {\u03b2, c}, {\u03b3}},\n\u2022 \u03c06n+2 = {{\u03b1, a}, {\u03b2, b, c}, {\u03b3}},\n\u2022 \u03c06n+3 = {{\u03b1}, {\u03b2, b, c}, {\u03b3, a}},\n\u2022 \u03c06n+4 = {{\u03b1}, {\u03b2, b}, {\u03b3, a, c}}, and\n\u2022 \u03c06n+5 = {{\u03b1, b}, {\u03b2}, {\u03b3, a, c}}.\nAgain the utilities of agents after x executions of this cycle of six partitions are shown in Figure 3. We again observe that for k \u2265 1, \u03c0k\u22121 leads to \u03c0k by means of a IS deviation, which completes the counterexample. Again we can also modify the example to start in a singleton partition by adding the three partitions {{\u03b1}, {\u03b2}, {\u03b3}, {a}, {b}, {c}}, {{\u03b1, a}, {\u03b2}, {\u03b3}, {b}, {c}}, {{\u03b1, a, b}, {\u03b2}, {\u03b3}, {c}} in the beginning of the dynamics.\nBy contrast, IS dynamics are still always guaranteed to converge in ASHG. Note that this is the only contrast between ASHGs and MFHGs proven in this paper (in all other cases we either have the same result for both classes, or a result for one and an open question for the other).\nTheorem 5.7. In ASHGs, the IS dynamics converges for deviator-resentful agents.\nProof. Let an ASHG (N,u0) be given. For the sake of contradiction assume that there exists an infinite sequence (\u03c0t)t\u22650 of partitions resulting from IS deviations of deviator-resentful agents. For each t \u2265 0, let dt be the agent deviating in step t from \u03c0t\u22121(dt) to \u03c0t(dt). By Lemma 2.1, there exists t0 \u2265 0 such that every deviation performed after t0 is performed infinitely often.\nNote that for each t \u2265 t0 it holds that d t cannot be left by an agent j \u2208 \u03c0t(dt) after t0, as otherwise j will leave dt infinitely often and thus, as utilities are only decreasing, at some point will no longer approve the join of dt, as she derives negative utility from dt. We refer to this as the first observation.\nFix some t \u2265 t0 and let d := dt and C := \u03c0 t(dt) (note that d joins C \\ {dt} at step t ). As\nour second observation we now show that there is some t\u2032 > t with dt \u2032 = d and \u03c0t \u2032\u22121(dt) = C. From our choice of t0 it follows that there is some t\n\u2032 \u2265 t where d performs a deviation for the next time. Assume now, for the sake of contradiction that there is some t\u2032\u2032 with t\u2032 > t\u2032\u2032 > t where \u03c0t \u2032\u2032 (d) 6= \u03c0t \u2032\u2032\u22121(d) and select the smallest such t\u2032\u2032. If \u03c0t \u2032\u2032 (d) is changed because an agent j left it, then, by our choice of t\u2032\u2032, it follows that j \u2208 C, which contradicts our first observation. If \u03c0t \u2032\u2032 (d) is changed because an agent j joined it, then it needs to hold that j leaves the coalition of d again before t\u2032: Otherwise, d leaves j which again contradicts the first observation as d needs to approve the join of j. Thus, the second observation follows.\nHowever, the second observation implies that for d it holds that utd(\u03c0 t(d)) = ut \u2032\u22121 d (\u03c0 t\u2032\u22121(d)).\nIn the next step, d performs an IS deviation and thus increases her utility, i.e., ut \u2032 d (\u03c0 t\u2032(d)) > ut \u2032\u22121 d (\u03c0 t\u2032\u22121(d)). Afterwards, the second observation can be applied again until d performs the\nnext deviation. Thus, d\u2019s utility is strictly increasing, however, as utilities are initially bounded and resent can only cause their decay, this leads to a contradiction. Hence, IS dynamics have to converge.\nWe have seen that deviator-resent can be powerful force for stability, as CS dynamics with individual rational deviations in MFHGs and ASHGs and IS dynamics in ASHGs always converge. However, deviator-resent is not sufficient to guarantee convergence of IS and general CS dynamics in MFHGs, yielding a different behavior of ASHGs and MFHGs for IS dynamics. Notably, we did not prove any such contrasts in our analysis of resent and appreciation. Overall, our results indicate that deviator-resent has clear ramifications on convergence guarantees, yet the general picture seems to be slightly more nuanced than for resent or appreciation. In particular, we were not able to settle whether SCS or CS dynamics are guaranteed to converge in ASHG for deviator-resentful agents without the individual rationality assumption, leaving this as an open question."
        },
        {
            "heading": "6 Simulations",
            "text": "In this section, we analyze by means of simulations how resent and appreciation influence dynamics in ASHGs. We focus on NS dynamics, as in randomly sampled ASHGs the IS dynamics typically converge quickly even without resent or appreciation (implying that they have only a small effect). Moreover, executing core dynamics is computationally too costly, as already checking whether an outcome is core stable is computationally intractable."
        },
        {
            "heading": "6.1 Setup",
            "text": "We mostly focus on ASHGs with an agent set N containing n = 50 agents,4 and sample their utilities using one of the following two models:\nUniform For two agents a, b \u2208 N with a 6= b, we sample ua(b), i.e., a\u2019s value for b, by drawing a random integer between \u2212100 and 100.\nGaussian For each agent a \u2208 N , we sample her base qualification \u00b5a by drawing a random integer between \u2212100 and 100. For two agents a, b \u2208 N with a 6= b, we sample ua(b) by drawing an integer from the Gaussian distribution with mean \u00b5b and standard deviation 10.5\nOur dynamics start with the singleton partition. Subsequently, in each step, we compute all possible NS deviations. If there are no NS deviations, we stop; otherwise, we sample one NS deviation uniformly at random and execute it. To be able to vary the \u201cintensity\u201d of the resentful/appreciative perception, we introduce a change coefficient c, which we typically set to 1: For resentful agents, if an agent a deviates from a coalition C \u2032 to a coalition C, then we reduce the utility that agents from C \u2032 have for a by c; for appreciative agents, we increase the utility that agents from C have for a by c. We also examine what happens if agents are both resentful and appreciative and both of the above described effects are present. In this case we speak of resentful-appreciative agents. For all our simulations, we set a time-out of 100 000, i.e., after 100 000 steps we report that the dynamics did not converge.6\n4We analyze the influence of the number of agents in Section 6.5. 5We analyze the influence of the chosen standard deviation in Section 6.4. 6We want to remark that this does not necessarily imply that no NS stable outcome exists in such a game or that there is no path to stability for the dynamics, but rather that selecting NS deviations randomly was not sufficient to ensure convergence (in a reasonable time)."
        },
        {
            "heading": "6.2 Convergence Time",
            "text": "We start by analyzing the influence of resent and of appreciation on how fast NS dynamics converge. For this, we sampled 100 games with 50 agents and for each recorded the number of steps until convergence.\nUniform Utilities In Figure 4a, we visualize the results for uniform utilities. The NS dynamics for agents that are neither resentful nor appreciative did not converge in any of our sampled games (within the limit of 100 000 steps). By contrast, even for a change coefficient c = 1, NS dynamics converged in all games for resentful or appreciative agents. However, there is a clear difference between these two: For resentful agents, the average number of steps until convergence is 59 910 for c = 1, whereas for appreciative agents the NS dynamics converges much faster (for c = 1 the average convergence time is 4243). Increasing c to 4, for resentful agents and for appreciative agents, the average convergence time roughly quarters, while increasing c to 10 only decreases the time by an additional factor of two. In sum, appreciation seems more helpful to establish fast convergence than resent in case of uniform utilities. Nevertheless, for both concepts, the number of steps until convergence is quite large (compared to the number of agents). While increasing the change coefficient leads to faster convergence the decrease in convergence time is particularly strong for smaller values of the coefficient, indicating that NS dynamics need some time to find the \u201cright\u201d deviations somewhat independent of the value of the change coefficient.\nIn contrast to our theoretical analysis, we also consider the case of resentful-appreciative agents. Compared to appreciative agents, adding resent leads to a substantial increase of the convergence time by a factor of around 2.5 (while for resentful agents, adding appreciation still leads to faster convergence). While this slower convergence for resentful-appreciative agents compared to appreciative agents may be surprising at first glance, recall the intuitive justifications why resent and appreciation contribute to a faster convergence. For appreciative agents, utilities only increase over time, whereas for resentful agents utilities only decrease over time. Thus, if we combine the two, it is in principle possible that some valuations that increase for appreciative agents stay constant for resentful-appreciative agents, and the two effects can cancel out each other. For uniform utilities, this effect seems to be stronger than the additional \u201cstability force\u201d established by resent.\nGaussian Utilities In Figure 4b, we visualize the result of our first set of simulations for Gaussian utilities. In this case, the NS dynamics for agents that are neither resentful nor appreciative converged in 3 of the 100 games. In contrast, for resentful or for appreciative agents, the NS dynamics converged in all games. In particular, convergence was much quicker (in at most 2000 steps) than under uniform utilities, indicating that ASHGs under Gaussian utilities seems to facilitate reaching stable states compared to uniform utilities. Examining the results in more detail, the difference between resentful and appreciative agents is less profound here than for uniform utilities. While resent leads to faster convergence for c < 3, appreciation is more powerful for c \u2265 3. Considering the influence of the change coefficient, for resentful agents, we again see the trend that increasing the change coefficient has a strong effect for smaller c but that this effect becomes less strong for larger c. On the other hand, for appreciative agents, the relation between c and the convergence time is rather linear. Moreover, in contrast to uniform utilities, resent and appreciation seem to not \u201ccancel out\u201d each other. For resentful-appreciative agents, NS dynamics converge faster than for either of the two separately."
        },
        {
            "heading": "6.3 Structure of Outcomes and Comparison to Base Game",
            "text": "We now take a closer look at the outcomes and utility functions produced by NS dynamics for resentful and/or appreciative agents. Again, we generated 100 games with n = 50 agents each for uniform and Gaussian utilities. In addition, we generated 100 games with n = 25 agents and Gaussian utilities (as the original NS dynamics converge more often in such games). In all games, we set the change coefficient c to 1. Table 3 summarizes the results of our simulations. All values in the table are averaged from the respective 100 games. In the last part of the table, we only consider the 13 games with n = 25 and Gaussian utilities in which an NS dynamics in the original game converged within 100 000 steps. For reference, we depict the number of steps the dynamics needed to converge in the first column. We analyze the structure of the produced NS outcomes as follows. Columns three to six consider the produced coalitions, that is, the number of coalitions and their average and maximum size. The next two columns concern the outcome\u2019s degree of stability with respect to the original utilities, where we record the number of agents violating individual rationality and possessing an NS deviation, respectively. The\nlast three columns concern the change of the utility profile, that is, the average utility in the outcome partition with respect to the final utilities, the average change of each entry of the utility function comparing the initial and final utilities, and the fraction of pairs of friends with respect to the final utilities, that is tuples (a, b) \u2208 N2 for which ua(b) > 0. 7\nUniform Utilities We first focus on uniform utilities. Recall that our dynamics need many steps until reaching convergence. Therefore, it is not surprising that the produced outcomes are quite \u201cdegenerated\u201d for both resentful agents and appreciative agents. For resentful agents, the produced outcomes consist only of singleton coalitions in all games, which means that agents have left each other sufficiently often to ensure that all pairwise utilities are non-positive. This is also reflected by the facts that all agents have NS deviations with respect to their original utilities, and that on average the valuations of agents changed by 51.25. Overall, the produced outcomes have little connection to the original game and simply exploit that all utilities become negative at some point for resentful agents.\nBy contrast, for appreciative agents, there is typically one large coalition containing 40 or more agents together with one or two small coalitions. Indeed, this is also reflected by the observations that the average number of coalitions is 2.74 and the average maximum size is 42.57. The typical run of an NS dynamics for appreciative agents here can be described in two phases. First, agents increase their utility for each other by deviating between smaller coalitions (where some agents, which are negatively valued by many others, are not joined, which often leads to them being part of small coalitions in the final outcome). Subsequently, in a second phase, agents already possess a generally high utility level, and thus tend to favor large coalitions (even when having a negative utility for some of the agents in the coalition). Notably, it does not happen that eventually all utilities between pairs of agents are positive, and in this sense, the behavior of appreciative agents is not the contrary of the behavior of resentful agents. In fact, slightly counterintuitively, only 56% of agent pairs have a positive evaluation after convergence of the dynamics. Consequently, agents (from the large coalition) often dislike other coalition members: On average, an agent only values 59% of her coalition members positively. Nevertheless, the relationship of the produced outcome and the agent\u2019s original utilities is still quite low with 18.7 agents for which individual rationality is violated and 22.21 agents having an NS deviation.\nFor resentful-appreciative agents, the produced outcomes are in some sense between the two extremes for resentful agents and for appreciative agents: Typically, several medium-size coalitions form (the average number of coalitions is 5.26 and the maximum size is on average 18.43). Further, the average change of the utility values is \u22120.13 and only 51% of agent pairs have a positive evaluation, implying that the utility changes caused by resent and by appreciation cancel out each other from an aggregated perspective. However, on an individual level, utilities still change quite drastically, as the absolute difference between the initial utilities values and the values at the end of the dynamic is on average 12.15. Notably, the outcome produced by resentful-appreciative agents is also in some sense less \u201cdegenerated\u201d as for the the two separately: It consists of medium-size coalitions, utilities are structurally more similar to the initial utilities, and most importantly, the outcome is closer to stability in the original game (with only 2.33 agents for which individual rationality is violated and only 10.15 agents having an NS deviation).\nGaussian Utilities We now turn to Gaussian utilities, where the dynamics converge much quicker than for uniform utilities. Moreover, the outcomes produced by our three dynamics\n7Note that, in both utility models, this value is on average 0.5 for the initial utilities.\nare quite similar, which follows the intuition that the final utility profiles remain quite similar after the execution of \u201cfew\u201d steps. In general, NS outcomes produced by our dynamics typically consist of one large coalition containing roughly half of the agents (these are usually the agents with positive ground qualification), while other agents are placed into coalitions of size one or two.\nLet us first focus on the second and third part of Table 3 presenting the results of 100 games with n = 50 and n = 25 agents, respectively. First, the outcomes for appreciative agents typically contain fewer coalitions than for resentful agents. Interestingly, this is not achieved because of the size of the \u201clarge\u201d coalition but due to a larger average size of the many small coalitions. For resentful-appreciative agents, the produced outcomes are structurally similar to the ones for resentful agents with a slightly smaller number of coalitions (achieved by an increase of the size of the \u201clarge\u201d coalition). Second, for all three types of dynamics the produced outcomes are much closer to being stable in the original game than for uniform utilities (only around 10% of the agents have an NS deviation). In particular, for resentful-appreciative agents, the produced outcomes are closest to stability in the original game. Lastly, considering the average utility of agents in the produced outcome, the three perception types produce quite similar results: Naturally, for appreciative agents, the average utility of agents in the produced outcome is highest. However, in both other dynamics, agents are only slightly less happy.\nIn the fourth part of the table, we depict statistics concerning the 13 of our 100 games with n = 25 agents having Gaussian utilities for which an original NS dynamic converged (in the time limit). In the first line, we show properties of the outcomes produced by the original dynamics. The NS outcomes produced by the original NS dynamics are structurally quite similar to the ones shown in the third part of the table, indicating that the outcomes produced by our three dynamics on games with 25 or 50 agents having Gaussian utilities are quite \u201cnatural\u201d and not degenerated. The similarities become even more profound when comparing the outcomes produced by the original dynamics on the selected 13 games to the outcomes produced by our three types of dynamics on the same 13 games: For resentful and resentful-appreciative agents, the produced outcomes are very similar or even identical to the outcome produced by the original NS dynamics in all 13 games (and are in particular always stable in the original games). For appreciative agents, the \u201clarge\u201d coalition in the outcome is typically quite similar or identical to the \u201clarge\u201d coalition produced by the original dynamics; however, sometimes fewer small coalitions are produced (in particular, some of the produced outcomes are not stable in the original game). Concerning the average utility in the final partition, resentful agents are only marginally less happy than in the original dynamics, indicating that only very few agents end up in a coalition with an agent they left at some point, whereas the average utility is slightly higher for appreciative agents and resentful-appreciative agents."
        },
        {
            "heading": "6.4 Influence of Standard Deviation for Gaussian Utilities",
            "text": "In this section, we focus on Gaussian utilities and analyze the influence of the standard deviation \u03c3 on convergence times. Recalling the drastic differences in the behavior of the dynamics between Gaussian utilities (with \u03c3 = 10) and uniform utilities observed in the previous subsections, it is to be expected that the convergence time increases with increasing \u03c3 (as we are in some sense getting closer to uniform utilities for larger \u03c3). To analyze this effect in more detail, for \u03c3 \u2208 {0, 5, 10, . . . , 95, 100}, we sampled 100 games with n = 50 agents having Gaussian utilities with standard deviation \u03c3, and measured the average convergence times of our three types of NS dynamics for a change coefficient c = 1. The results are shown in Figure 5, where we only show the average convergence time of all dynamics that converged in the time bound of 100 000 steps. For resentful agents, the NS dynamics did not converge in 7/23/48/63/75\ngames for a standard deviation of 60/70/80/90/100, respectively (for appreciative agents and resentful-appreciative agents the dynamics always converged). Overall, our hypothesis that increasing the standard deviation leads to an increased convergence time is confirmed clearly. Slightly unexpected, for \u03c3 \u2265 80, Gaussian utilities seem to be even \u201charder\u201d than uniform utilities: For resentful agents, the dynamics did not even converge for roughly half of the games and for appreciative agents the average convergence time is about twice as large. The reason for this is that for large \u03c3 utilities often fall out of the range [\u2212100, 100] (from which we sample the agent\u2019s base qualification for Gaussian utilities and the utilities for uniform utilities). In games which are \u201cfar away\u201d from stability and for which resentful agents or appreciative agents produce degenerated outcomes (as described in the previous section) an increased range of the utility values clearly contributes to a higher convergence time: For instance, for resentful agents, we have observed that the dynamics typically runs until all utility values are negative, which takes more time if some utility values are initially larger."
        },
        {
            "heading": "6.5 Influence of the Number of Agents",
            "text": "We now briefly analyze the influence of the number of agents on the convergence time of NS dynamics with resentful and/or appreciative agents. For this, for different numbers of agents, we generated 100 games and executed NS dynamics with resentful and/or appreciative agents and a change coefficient of c = 1. We show the results for uniform utilities in Figure 6a and the results for Gaussian utilities in Figure 6b. Overall, unsurprisingly, the higher the number of agents, the higher is the convergence time of our dynamics.\nFor uniform utilities, the relation of the different types of dynamics is independent of the number of agents. For appreciative agents, the average convergence time is the lowest, while convergence is still faster for resentful agents than for resentful-appreciative agents. The increase in the convergence time between n = 10 and n = 60 is almost linear for all three types. However, the slope substantially depends on the considered type: For resentful agents, comparing n = 10 and n = 60, the convergence time increases by a factor of 47, for appreciative agents the factor is 11, and for resentful-appreciative agents the factor is 38. Thereby, the difference between the three becomes larger with a growing number of agents. This again highlights the different\nnature of the three types of NS dynamics for uniform utilities that we have observed above: For resentful agents, for uniform utilities, all utility values need to become negative, which requires substantially, but linearly, more deviations the higher the number of agents. In contrast, for appreciative agents, agents typically only join each other until almost everyone has a positive valuation for a very large coalition. Naturally also this requires more deviations the higher the number of agents, yet with slower scaling.\nFor Gaussian utilities, we also see an almost linear increase of the average convergence time. Moreover, for most considered agent numbers, dynamics for resentful-appreciative agents converge faster than the ones for resentful agents which in turn converge faster than the ones for appreciative agents. However, in contrast to uniform utilities, here the difference between the three types of NS dynamics changes only slightly for different numbers of agents. Furthermore, comparing n = 10 and n = 60, the convergence time of all three types of NS dynamics only increases by a factor of around 12. Lastly, for resentful agents, we can observe a slightly unexpected phenomenon, as for a smaller number of agents the convergence time does not steadily increase, e.g., for n = 10 the average converge time is 425 steps and for n = 15 it is 204 steps."
        },
        {
            "heading": "7 Shortest Converge Sequences",
            "text": "In our simulations in Section 6, we have analyzed how fast random executions of NS dynamics converge for resentful and/or appreciative agents. An interesting related direction to shed further light on the power of resent and appreciation is to analyze the length of the shortest converging execution of dynamics. The corresponding computational problem is to decide whether in a given game (where a stable outcome is guaranteed to be reachable), there is a converging deviation sequence of a given length from some given starting partition.\nNotably, this problem has not been addressed in the literature for classical dynamics, yet is of no less relevance in the general case. While existing hardness results for deciding whether a game admits a stable outcome suggest the hardness of the shortest converge sequence problem for the general case, they do not directly imply hardness, as stable states might not be reachable from some initial partition via the allowed deviations. Moreover, convergence might require exponential time from some initial partition (Brandt et al., 2022).\nWe present three reductions showing that for ASHGs deciding whether we can converge in a given number of steps is NP-hard for CS, IS, CNS, and NS dynamics for resentful, for appreciative, and for classical agents (that is, agents with constant utility functions over time).\nMore formally, for \u03b1 \u2208 {NS, IS,CNS,CS}, we define the following decision problem:\nresentful-ashg-\u03b1-sequence\nGiven: An additively separable hedonic game with resentful agents and some integer k. Question: Is there an execution (\u03c0t)t\u22650 of the \u03b1 dynamics that starts from the singleton partition \u03c00 and converges in at most k steps?\nDefining appreciative-ashg-\u03b1-sequence analogously for appreciative agents, we can show that these problems are NP-hard for NS, IS, CNS, and CS.\nTheorem 7.1. For \u03b1 \u2208 {NS, IS,CNS,CS}, resentful- and appreciative-ashg-\u03b1sequence are NP-hard.\nBefore turning to the proof of Theorem 7.1, we want to make a few remarks. First, note that all our constructions in the following proofs also work for normal agents with constant utilities over time. Hence, our constructions also imply the hardness of the respective decision problem for (time-independent) ASHGs.\nSecond, we want to discuss membership in NP. Note that the sequence of partitions leading to a stable partition is a certificate for a Yes-instance of size O(nk). Hence, if k is given in unary encoding, then this is a certificate of polynomial size. Moreover, for the reduced instance in our proofs, it holds that k \u2208 O(n), and therefore the hardness holds on a class of instances for which membership in NP is satisfied. Still, it is not clear whether resentful- and appreciativeashg-\u03b1-sequence are in NP for a general k in binary encoding.\nThe proof of Theorem 7.1 consists of three individual constructions. We showcase the technique by proving the statement for NS and IS in Lemma 7.2. The proofs for CNS and CS are similar, and are deferred to Lemmas C.1 and C.2 in the appendix.\nLemma 7.2. For \u03b1 \u2208 {NS, IS}, resentful- and appreciative-ashg-\u03b1-Sequence are NPhard.\nProof. We first show the statement for IS and resentful agents. We reduce from Restricted Exact Cover by 3-Sets (RX3C) where we are given a finite universe U = {x1, . . . , x3t} and a family S = {S1, . . . , S3t} of 3-subsets of U where each element from U appears in exactly three sets from S. The question is whether there is a family S \u2032 \u2286 S which is an exact cover of U .\nConstruction. Given an instance (U,S) of RX3C, we set k = 10t and create the following additively separable hedonic game. We add one element agent x for each element x \u2208 U and one set agent S for each set S \u2208 S. Moreover, we add 2t filling agents F = {f1, . . . , f2t}. Lastly, we add a penalizing gadget consisting of 10t+ 1 penalizing agents {p} \u222aQ with Q = {pi,j | i \u2208 [5t], j \u2208 [2]}. The resulting set of agents is N = U \u222aS \u222aF \u222a {p} \u222aQ. The initial utilities of the players are illustrated in Figure 7:\n\u2022 Each element agent has utility zero for each other element agent and utility 1 for each set agent.\n\u2022 Each filling agent has utility 1 for each set agent.\n\u2022 Each set agent S \u2208 S has utility 20t for the three element agents x \u2208 S, utility 60t for each filling agent, utility 60t for p, and utility zero for each penalizing agent in Q.\n\u2022 p has utility 10t for each set agent and utility zero for each penalizing agent in Q.\n\u2022 Each penalizing agent pi,j \u2208 Q has utility 30t for each set agent, utility 30t for p, utility 40t for her corresponding penalizing agent pi,k with k \u2208 [2], k 6= j, and utility zero for all remaining penalizing agents in Q.\n\u2022 All not explicitly mentioned utilities are \u22121000t.\nWe now show that there is an exact cover of U if and only if there is a sequence starting with the singleton partition and reaching an IS partition after at most k IS deviations, where agents are resentful.\n(\u21d2) Given an exact cover S \u2032 \u2286 S, we let the agents deviate as follows. For each S \u2208 S \\ S \u2032, one filling agent deviates to S (there are 2t of these sets and 2t filling agents). For each S \u2208 S \u2032, the three element agents x with x \u2208 S deviate to S. As S \u2032 is an exact cover, each filling and each element agent deviate exactly once, leading to 5t deviations so far. Furthermore, for i \u2208 [5t], pi,2 deviates to pi,1. Thus, we have 10t deviations in total. If we order these deviations arbitrarily, then all deviations are NS deviations, as each agent deviates from the singleton coalition to a coalition for which she has positive utility. Furthermore, these NS deviations are IS deviations as the agents in the joined coalitions have non-negative utilities for the deviators. It remains to show that the resulting partition is NS (and thus also IS): Observe that there is at most one set agent per coalition. As element and filling agents only derive a positive utility from set agents and are in a coalition with a set agent, no element or filling agent has an NS deviation. Agent p only has a positive utility for the set agents but all set agents are accompanied by either element or filling agents for which p has a large negative utility. Hence, p has no NS deviation. Agents pi,1 and pi,2 with i \u2208 [5t] do not want to deviate as they have utility 40t for coalition {pi,1, pi,2} and value no other available coalition with more than 30t. Lastly, each set agent S \u2208 S is in a coalition from which she derives utility 60t. All other coalitions are either the coalition just containing p (for which S has utility 60t as well), coalitions containing other penalizing agents (for which S has utility zero), or contain a different set agent (for which S has large negative utility). Thus, S has no NS deviation either and the created partition is NS.\n(\u21d0) Assume that we have a sequence of \u2113 \u2264 k = 10t IS deviations leading from the singleton partition \u03c00 to an IS partition \u03c0\u2113. As a first observation, note that in this sequence no two agents who have utility \u22121000t for each other can ever be in the same coalition because they would never join each other. Second, as we start from the singleton partition, the resent an agent has build up for the other agents after \u2113 deviations sums up to at most \u21132 \u2264 5t.\nNext, we show that, in \u03c0\u2113, no set agent is in a joint coalition with p. For the sake of a contradiction, assume that p \u2208 \u03c0\u2113(S) for some S \u2208 S. By the first observation, this means that there is no other set agent, no element agent, and no filling agent in \u03c0\u2113(S). Hence \u03c0\u2113(S) \u2286\n{p, S} \u222aQ. Let pi,j \u2208 Q be a penalizing agent who has not performed any deviation, yet. This agent has to exist because, otherwise, we would have needed at least 10t+1 deviations to reach \u03c0\u2113. Then, pi,j has a utility of at least u 0 pi,j (S) + u0pi,j (p) \u2212 5t = 55t for \u03c0 \u2113(S) and thus has a possible NS deviation to \u03c0\u2113(S). (As pi,j has not deviated yet, she can have a utility of at most 40t for \u03c0\u2113(pi,j) if pi,k with k \u2208 [2], k 6= j has joined her.) This NS deviation is also an IS deviation as, initially, no agent from \u03c0\u2113(S) has a negative utility for pi,j. This is a contradiction to \u03c0\u2113 being IS. So, \u03c0\u2113(p) \u2286 {p} \u222aQ.\nAs \u03c0\u2113 is IS, no set agent S has any possible IS deviation from \u03c0\u2113(S) to \u03c0\u2113(p). As p and all other penalizing agents would always allow S to join her (note that they cannot have decreased their utility by more than 5t for S until step \u2113), S has no NS deviation to join \u03c0\u2113(p). Since (a) the resent that S has build up for any agent sums up to at most \u22125t, (b) S initially has utilities zero for all penalizing agents pi,j \u2208 \u03c0\n\u2113(p), (c) S initially has utility 60t for p, and (d) S does not want to move to p, it follows that u\u2113S(\u03c0\n\u2113(S)) \u2265 60t\u2212 5t = 55t. Therefore, \u03c0\u2113(S) contains at least one filling agent or three element agents x with x \u2208 S. Since this holds for all set agents and no two set agents are in one coalition, the existence of an exact cover (namely S \u2032 = {S \u2208 S | S is together with three element agents}) is implied.\nBy the same proof as above, there is an exact cover of U exactly if there is a sequence of at most k NS deviations leading to an NS partition for resentful agents.\nFor appreciative agents, we can use the same construction. The proof of correctness is very similar."
        },
        {
            "heading": "8 Conclusion and Future Directions",
            "text": "We have initiated the study of hedonic games with time-dependent utility functions, which are influenced by deviations in the past. In this course, we have studied a dynamic model of hedonic games by considering sequences of partitions evolving through sequences of deviations. Whenever a deviation is performed, some of the agents influenced by this deviation modify their utility. In particular, we have considered resentful agents, which decrease their utility for agents who abandon them, and appreciative agents, which increase their utility for agents who join them.\nIn our theoretical analysis, we have investigated whether the resentful or appreciative perception of other agents is sufficient to guarantee convergence for dynamics based on various deviation types. To state our results in broad generality, we have proposed axioms for utility aggregation. These consider the treatment of friends and enemies. All of our axioms are satisfied for additively separable aggregation of utilities, while modified fractional utility aggregation satisfies all axioms except aversion to enemies.\nFor resentful agents, we have shown the convergence of dynamics based on all types of group and single-agent deviations under fairly general conditions. However, some of these results also need the individual rationality of deviations. By contrast, for appreciative agents, we can only guarantee convergence of the CNS dynamics in ASHGs, while we have found several possibilities for cycling for the other types of dynamics. Resent and appreciation do not need to be expressed by the agents affected by a deviation, but they may also affect the deviator herself. We have seen that deviator-resent can be a strong force for stability over time.\nApart from our theoretical analysis, we have also studied the effects of resent and appreciation by means of simulations. This gives insight in the actual running time of the dynamics as well as in the structure of the partitions obtained after the convergence of the dynamics. We have considered two utility models, namely utilities selected uniformly at random and according to Gaussian distributions. It turned out that the produced outcomes are fairly degenerate under uniformly random utilities. For resentful agents, the outcome is usually the singleton\npartition, while the outcome consists of one large hub coalition and a few smaller coalitions for appreciative agents. A compromise and a seemingly more realistic result is obtained if agents are affected by both resent and appreciation. Then, the outcomes consist of several medium-size coalitions, and seem to be more related to the original base game. By contrast, under Gaussian utilities, the differences of the outcomes for different agent types are much less profound, which suggests that results by simulations may highly depend on the creation of the random games.\nWe complement the simulation results on the running time by a theoretical consideration of the problem of convergence within a given time limit. There, we obtain hardness results for dynamics in ASHGs based on any stability concept considered in this paper. Notably, these hardness results not only hold for resentful and appreciative agents but also for for normal agents (with time-independent utilities).\nBased on our work, one research direction is to consider other effects that could affect agents\u2019 valuations over time and potentially contribute to additional convergence results. Apart from this, we have also posed several specific open questions throughout the paper (even showing the equivalence of some of them in Corollary 4.3). In particular, it remains open, whether we can extend our convergence results for resentful agents to the modified fractional aggregation without the restriction to individually rational deviations. There, we only know that we may cycle for general NS dynamics. Moreover, complementing our simulations, it would be interesting to theoretically analyze the effects of combining resent and appreciation. A concrete open question here is whether CS dynamics are guaranteed to converge, which is the case for resentful agents but not for appreciative agents. Finally, another path for future research is to consider fastest convergence in other classes of hedonic games apart from ASHGs."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was partially supported by the Deutsche Forschungsgemeinschaft under grants NI 369/22, BR 2312/11-2, and BR 2312/12-1, and the NRW project Online Participation. We would like to thank the participants of the Dagstuhl seminar 21331 on Coalition Formation Games, and especially Florian Brandl, Gre\u0301gory Bonnet, Edith Elkind, Bettina Klaus, Seckin O\u0308zbilen, and Sanjukta Roy, for fruitful discussions."
        },
        {
            "heading": "Appendix: Missing Proofs",
            "text": "In the appendix, we provide all missing proofs."
        },
        {
            "heading": "A Additional Material for Section 2",
            "text": "In this section, we provide the proof for our lemma considering infinite sequences of partitions.\nLemma 2.1. Let (\u03c0t)t\u22650 be an infinite sequence of partitions induced by single-agent (or group) deviations. Then, there exists a t0 \u2265 0 such that every single-agent (or group) deviation performed at some time t \u2265 t0 occurs infinitely often.\nProof. We simultaneously prove the part of the lemma about single-agent deviations and group deviations by showing a stronger lemma that implies both. To this end, we consider labeled transitions. A labeled sequence with respect to \u00b5 is a sequence a = (at)t\u22650 together with a (labeling) function \u00b5 : N\u22650 \u2192 L. Given a labeled sequence a = (a\nt)t\u22650 with respect to \u00b5, a labeled transition of a with respect to L is a tuple (l, a1, a2) such that there exists t \u2265 0 with at = a1, a\nt+1 = a2, and \u00b5(t) = l. Then, Lemma 2.1 follows from the next claim by interpreting the deviating single agent or group of agents as labels of a transition between partitions.\nClaim A.1. Let N be a non-empty and finite ground set and L be a non-empty and finite set of labels. Let a = (at)t\u22650 be an infinite labeled sequence over A with respect to \u00b5 where a\nt \u2208 N for all t \u2265 0. Then, there exists a t0 \u2265 0 such that every labeled transition of a with respect to L performed at some time t \u2265 t0 occurs infinitely often.\nProof. Let a = (at)t\u22650 be an infinite labeled sequence with respect to \u00b5 over finite and nonempty ground sets and label sets. Given a1, a2 \u2208 N and l \u2208 L, define t(l, a1, a2) = sup{t \u2265 0: at = a1, a\nt+1 = a2, \u00b5(t) = l}, where we set sup \u2205 = 0. In other words, t(l, a1, a2) defines the last time step where the labeled transition (l, a1, a2) occurs. We define t0 = max{t(l, a1, a2) : l \u2208 L, a1, a2 \u2208 N, t(l, a1, a2) < \u221e}. By construction, every labeled transition performed after t0 must occur infinitely often. \u22b3\nThis completes the proof of the lemma."
        },
        {
            "heading": "B Additional Material for Section 4",
            "text": "Theorem 4.1. The following statements are equivalent:\n1. There exists an ASHG admitting an infinite and periodic sequence of NS deviations for resentful agents.\n2. There exists an ASHG admitting an infinite and periodic sequence of NS deviations for appreciative agents.\nProof. We only show how the first statement implies the second statement. The reverse implication is completely analogous.\nAssume that every agent i \u2208 N is resentful and uses the CAF AS i. Assume that there exists an infinite and periodic sequence (\u03c0t)t\u22650 of NS deviations. Assume that \u03c0\nt evolves from \u03c0t\u22121 through an NS deviation of agent dt for all t \u2265 1. By periodicity, there exist t0 \u2208 N and p \u2208 N such that, for all k \u2208 N0 and l \u2208 {0, . . . , p\u2212 1}, it holds that \u03c0\nt0+kp+l = \u03c0t0+l. We define an infinite and periodic sequence for appreciative agents. Essentially, this sequence reverts the order of one (periodic) segment of (\u03c0t)t\u22650 and appends it indefinitely.\nGiven k \u2208 N0 and l \u2208 {0, . . . , p\u2212 1}, define \u03c3 kp+l = \u03c0t0+p\u2212l. Clearly, this defines an infinite and periodic sequence of partitions (\u03c3t)t\u22650 induced by single-agent deviations. In particular, partition \u03c3kp+l+1 evolves from partition \u03c3kp+l by a single-agent deviation of agent dt0+p\u2212l. Moreover, define initial utilities by u\u03040i (j) = \u2212u t0 i (j). We assume that these utilities are updated in (\u03c3t)t\u22650 according to appreciation. Given a pair of agents i, j, let ri(j) = |{l \u2208 {1, . . . , p} : d\nt0+l = j, i \u2208 \u03c0t0+l(j)}|, i.e., the resent that i builds for j during one period. Also, given a pair of agents i, j and s \u2208 {1, . . . , p}, let rsi (j) = |{l \u2208 {1, . . . , s} : d\nt0+l = j, i \u2208 \u03c0t0+l(j)}|, i.e., the resent that i builds for j until step s of a period.\nWe have to show that the single-agent deviations are even NS deviations. Therefore, fix k \u2208 N0, l \u2208 {0, . . . , p \u2212 1}, and define \u03c3 = \u03c3\nkp+l, \u03c3\u2032 = \u03c3kp+l+1, and d = dt0+p\u2212l. We first claim that\n\u2211\nj\u2208\u03c3\u2032(d)\nrd(j) \u2265 \u2211\nj\u2208\u03c3(d)\nrd(j), (1)\ni.e., the appreciation of a deviator build during one period for an abandoned coalition is bounded by the appreciation build for the joined coalition.\nSuppose the contrary. Clearly, the resent that agents aggregate in one iteration of the cycle (\u03c0t0 , . . . , \u03c0t0+p) is the same as the appreciation that agents aggregate in a cycle (\u03c30, . . . , \u03c3p).\nThen, it holds for all m \u2208 N0 that\n0 < ut0+mp\u2212l\u22121d (\u03c0 t0+p\u2212l)\u2212 ut0+mp\u2212l\u22121d (\u03c0 t0+p\u2212l\u22121)\n= ut0+p\u2212l\u22121d (\u03c0 t0+p\u2212l)\u2212 ut0+p\u2212l\u22121d (\u03c0 t0+p\u2212l\u22121)\n\u2212 (m\u2212 1)\n\n\n\u2211\nj\u2208\u03c0t0+p\u2212l(d)\nrd(j)\u2212 \u2211\nj\u2208\u03c0t0+p\u2212l\u22121(d)\nrd(j)\n\n\n= ut0+p\u2212l\u22121d (\u03c0 t0+p\u2212l)\u2212 ut0+p\u2212l\u22121d (\u03c0 t0+p\u2212l\u22121)\n\u2212 (m\u2212 1)\n\n\n\u2211\nj\u2208\u03c3(d)\nrd(j)\u2212 \u2211\nj\u2208\u03c3\u2032(d)\nrd(j)\n\n .\nTherefore,\n(m\u2212 1)\n\n\n\u2211\nj\u2208\u03c3(d)\nrd(j) \u2212 \u2211\nj\u2208\u03c3\u2032(d)\nrd(j)\n\n\n< ut0+p\u2212l\u22121d (\u03c0 t0+p\u2212l)\u2212 ut0+p\u2212l\u22121d (\u03c0 t0+p\u2212l\u22121).\nHowever, the left hand side of this equation is unbounded while the right hand side is fixed. Hence, this cannot be true for all m \u2208 N0, a contradiction. We have thus established Equation (1).\nWe can compute that the deviation is indeed a NS deviation in every period:\nu\u0304kp+ld (\u03c3 \u2032)\u2212 u\u0304kp+ld (\u03c3)\n= u\u0304ld(\u03c3 \u2032)\u2212 u\u0304ld(\u03c3)\n+ k\n\n\n\u2211\nj\u2208\u03c3\u2032(d)\nrd(j)\u2212 \u2211\nj\u2208\u03c3(d)\nrd(j)\n\n\n(1) \u2265 u\u0304ld(\u03c3 \u2032)\u2212 u\u0304ld(\u03c3) = u\u03040d(\u03c3 \u2032) + \u2211\nj\u2208\u03c3\u2032(d)\n(rd(j) \u2212 r p\u2212l d (j))\n\u2212 u\u03040d(\u03c3)\u2212 \u2211\nj\u2208\u03c3(d)\n(rd(j) \u2212 r p\u2212l d (j))\n= \u2212ut0d (\u03c0 t0+p\u2212l\u22121) +\n\u2211\nj\u2208\u03c0t0+p\u2212l\u22121(d)\n(rd(j) \u2212 r p\u2212l d (j))\n+ ut0d (\u03c0 t0+p\u2212l)\u2212\n\u2211\nj\u2208\u03c0t0+p\u2212l(d)\n(rd(j)\u2212 r p\u2212l d (j))\n= \u2212ut0+p\u2212ld (\u03c0 t0+p\u2212l\u22121) +\n\u2211\nj\u2208\u03c0t0+p\u2212l\u22121(d)\nrd(j)\n+ ut0+p\u2212ld (\u03c0 t0+p\u2212l)\u2212\n\u2211\nj\u2208\u03c0t0+p\u2212l(d)\nrd(j)\n(1) \u2265 ut0+p\u2212ld (\u03c0 t0+p\u2212l)\u2212 ut0+p\u2212ld (\u03c0 t0+p\u2212l\u22121) > 0.\nThe strict inequality in the end holds because the deviation performed by d in the sequence (\u03c0t)t\u22650 is a NS deviation. Hence, the sequence (\u03c3 t)t\u22650 evolves through NS deviations.\nTheorem 4.7. The individually rational NS dynamics may cycle in MFHGs for appreciative agents.\nProof. We now describe an involved example of an MFHG together with an infinite periodic sequence of NS deviations for appreciative agents. Our example is very similar to the one presented for resentful agents in Theorem 3.4. In fact, following the general idea of Theorem 4.1, we reverse the deviation sequence and appropriately adjust the initial utilities. As in Theorem 3.4, each agent joins each other agent exactly once in each cycle. This establishes the same invariant: if a deviating agent prefers a joined coalition C1 to an abandoned coalition C2 before (and during) the first execution of the cycle, then it still prefers C1 to C2 before (and during) each execution of the cycle.\nConsider the game with agent set N = {a, a\u2032, b, b\u2032, c, c\u2032} and utilities as depicted in Table 4. The initial utilities result from setting x = 0 in Table 4. We now present an infinite sequence (\u03c0t)t\u22650 of partitions, always consisting of three coalitions. For each partition, we refer to the first listed coalition as C1, to the second as C2, and the third as C3. For the sake of clarity, for each partition, we also specify which agent deviates to which coalition in the next step. Specifically, for n \u2265 0, we have\n\u2022 \u03c018n+1 = {{b\u2032}, {a, a\u2032}, {b, c, c\u2032}} with agent b deviating to C2,\n\u2022 \u03c018n+2 = {{b\u2032}, {b, a, a\u2032}, {c, c\u2032}} with agent c\u2032 deviating to C1,\n\u2022 \u03c018n+3 = {{b\u2032, c\u2032}, {b, a, a\u2032}, {c}} with agent c\u2032 deviating to C2,\n\u2022 \u03c018n+4 = {{b\u2032}, {b, a, a\u2032, c\u2032}, {c}} with agent b deviating to C1,\n\u2022 \u03c018n+5 = {{b\u2032, b}, {a, a\u2032, c\u2032}, {c}} with agent a deviating to C1,\n\u2022 \u03c018n+6 = {{b\u2032, b, a}, {a\u2032, c\u2032}, {c}} with agent c\u2032 deviating to C3,\n\u2022 \u03c018n+7 = {{b\u2032, b, a}, {a\u2032}, {c, c\u2032}} with agent a deviating to C3,\n\u2022 \u03c018n+8 = {{b\u2032, b}, {a\u2032}, {c, c\u2032, a}} with agent b\u2032 deviating to C2,\n\u2022 \u03c018n+9 = {{b}, {a\u2032, b\u2032}, {c, c\u2032, a}} with agent b\u2032 deviating to C3,\n\u2022 \u03c018n+10 = {{b}, {a\u2032}, {c, c\u2032, a, b\u2032}} with agent a deviating to C2,\n\u2022 \u03c018n+11 = {{b}, {a\u2032, a}, {c, c\u2032, b\u2032}} with agent c deviating to C2,\n\u2022 \u03c018n+12 = {{b}, {a\u2032, a, c}, {c\u2032, b\u2032}} with agent b\u2032 deviating to C1,\n\u2022 \u03c018n+13 = {{b, b\u2032}, {a\u2032, a, c}, {c\u2032}} with agent c deviating to C1,\n\u2022 \u03c018n+14 = {{b, b\u2032, c}, {a\u2032, a}, {c\u2032}} with agent a\u2032 deviating to C3,\n\u2022 \u03c018n+15 = {{b, b\u2032, c}, {a}, {c\u2032 , a\u2032}} with agent a\u2032 deviating to C1,\n\u2022 \u03c018n+16 = {{b, b\u2032, c, a\u2032}, {a}, {c\u2032}} with agent c deviating to C3,\n\u2022 \u03c018n+17 = {{b, b\u2032, a\u2032}, {a}, {c\u2032, c}} with agent b deviating to C3,\n\u2022 \u03c018n+18 = {{b\u2032, a\u2032}, {a}, {c\u2032, c, b}} with agent a\u2032 deviating to C2.\nThen, it is possible to verify that for k \u2265 1, \u03c0k\u22121 leads to \u03c0k by means of an NS deviation. Hence, we have presented an MFHG with an infinite sequence of NS deviations for appreciative agents."
        },
        {
            "heading": "C Additional Material for Section 7",
            "text": "The goal of this section is to complete the proof of Theorem 7.1. Since we have already considered NS and IS in Lemma 7.2, it remains to consider CNS and CS. We split the remaining proof into two more lemmas.\nLemma C.1. resentful- and appreciative-ashg-CNS-Sequence are NP-hard.\nProof. We first show the statement for resentful agents. We again reduce from RX3C. Construction. From an instance of RX3C, given by a universe U = {x1, . . . , x3t} and a family S = {S1, . . . , S3t} of 3-subsets of U , we create an additively separable hedonic game as follows. We create the set of agents N = U \u222a S \u222a F \u222aQ with element agents U , set agents S, filling agents F = {f1, . . . , f2t}, and penalizing agents Q = {p0, . . . , p4}. The initial utilities of the agents are illustrated in Figure 8:\n\u2022 Each element agent has utility 1 for each other element agent.\n\u2022 Each set agent S \u2208 S has utility 20t for the three element agents x \u2208 S, utility 60t for each filling agent, utility 60t for p0, and utility zero for p1.\n\u2022 p0 has utility 10t for each set agent and utility zero for p1.\n\u2022 p1 has utility 1 for p0.\n\u2022 p2, p3, and p4 have utility 200t for p1.\n\u2022 p2 has utility \u2212100t for p3 and utility \u2212400t for p4.\n\u2022 p3 has utility \u2212100t for p4 and utility \u2212400t for p2.\n\u2022 p4 has utility \u2212100t for p2 and utility \u2212400t for p3.\n\u2022 All not explicitly mentioned utilities are \u22121000t.\nThe penalizing gadget consisting of agents p1, . . . , p4 is a variant of an ASHG by Sung and Dimitrov (2007, Example 2) for which no CNS partition exists (in normal ASHGs).\nWe set k to 5t+1 and show that there is an exact cover of U if and only if there is a sequence starting from the singleton partition of at most k CNS deviations leading to an CNS partition, where agents are resentful. (\u21d2) Given an exact cover S \u2032 \u2286 S, consider the following sequence of k = 5t + 1 deviations. First, for each set S \u2208 S \u2032 with S = {xi, xj , xl}, xi and xj join xl and afterwards the set agent S joins {xi, xj , xl} (3t deviations). Second, all set agents S with S /\u2208 S \u2032 join a filling agent each (2t deviations). Last, p1 joins p0. All these deviations are NS deviations as each of these deviations is performed from a singleton to a coalition with positive utility for the deviator. Moreover, all these NS deviations are CNS deviations because they are performed from singletons; so there are no other agents who could veto the deviation.\nNext, we show that the resulting partition \u03c0 is CNS. First, each set agent has utility 60t for \u03c0(S). Since every other coalition either contains an agent for which she has utility \u22121000t or is the coalition {p0, p1}, for which she has utility 60t, she does not want to deviate. Second, each element and filling agent do not have any CNS deviation because they have a set agent in their coalition who would veto their deviation. Third, p1 would veto a deviation of p0, so p0 has no CNS deviation. Fourth, p1 does not want to deviate to another coalition as she has utility 1 for \u03c0(p1) = {p0, p1} and every other coalition in \u03c0 contains an agent for which she has utility \u22121000t. Last, p2, p3, and p4 do not want to deviate as they only have a positive utility (of 200t) for agent p1 but p1 is together with p0 for which they have utility \u22121000t.\n(\u21d0) Assume that we have a sequence of \u2113 \u2264 k = 5t + 1 CNS deviations leading from the singleton partition \u03c00 to a CNS partition \u03c0\u2113. In this sequence, no two agents who mutually have utility \u22121000t for each other can ever be in the same coalition because they would never join each other. Furthermore, as we start from the singleton partition, the resent an agent has accumulated for the other agents after \u2113 deviations sums up to at most \u21132 \u2264 3t.\nWe will now show that no set agent is together with p0 in \u03c0 \u2113. For the sake of a contradiction, assume that S \u2208 \u03c0\u2113(p0) for some S \u2208 S. By the first observation, this implies that \u03c0 \u2113(p0) \u2286 {S, p0, p1}. It further holds that p1 /\u2208 \u03c0 \u2113(p0) because, otherwise, p1 would have a CNS deviation to a singleton coalition. Hence, \u03c0\u2113(p0) = {S, p0}. Next, consider coalition \u03c0 \u2113(p1). By the first observation, we have \u03c0\u2113(p1) \u2286 S \u222a Q. Furthermore, there is no set agent in \u03c0 \u2113(p1): Indeed, assume for contradiction that there is some set agent S\u2032 in \u03c0\u2113(p1). Then, by the first observation,\nneither p2, p3, nor p4 are in \u03c0 \u2113(p1). Furthermore, we already now that p0 is not in \u03c0 \u2113(p1). It follows that \u03c0\u2113(p1) = {S\n\u2032, p1} which means that p1 has a CNS deviation to a singleton coalition, a contradiction. Hence, \u03c0\u2113(p1) \u2286 {p1, . . . , p4}. For i \u2208 {2, 3, 4}, it also holds by the first observation that \u03c0\u2113(pi) \u2286 {p1, . . . , p4}. We will now show that {p1, . . . , p4} can not be divided into a CNS partition (cf. Sung and Dimitrov, 2007, Example 2). Note that the arguments also hold when lowering any utilities among this agents by at most 3t and therefore \u03c0\u2113 is no CNS partition, which is a contradiction.\nFirst, none of p2, p3, and p4 can be in the same coalition because the agent with a initial utility of \u2212400t for another agent in her coalition would have a CNS deviation to a singleton. Hence, the remaining possible partitions of {p1, . . . , p4} are \u03c0 \u2032 = {{p1}, {p2}, {p3}, {p4}}, \u03c0 \u2032\u2032 = {{p1, p2}, {p3}, {p4}}, \u03c0 \u2032\u2032\u2032 = {{p2}, {p1, p3}, {p4}}, and \u03c0\n\u2032\u2032\u2032\u2032 = {{p2}, {p3}, {p1, p4}}. But all these partitions are not CNS: \u03c0\u2032 is not stable because p2 has a CNS deviation to {p1}; \u03c0\n\u2032\u2032 is not stable because p4 has a CNS deviation to {p1, p2}; \u03c0\n\u2032\u2032\u2032 is not stable because p2 has a CNS deviation to {p1, p3}; \u03c0\n\u2032\u2032\u2032\u2032 is not stable because p3 has a CNS deviation to {p1, p4}. Thus, we have shown that \u03c0\u2113 is not CNS. This is a contradiction and therefore the initial assumption was wrong, i.e., no set agent is together with p0 in \u03c0\n\u2113. Since \u03c0\u2113 is CNS, no set agent has a CNS deviation to p0. Note that p0 is the only agent who has positive utilities for the set agents. So, for any set agent S \u2208 S, there is no agent in \u03c0\u2113(S) who would veto a deviation of S. Therefore, no set agent has an NS deviation to p0. Furthermore, we know that \u03c0\u2113(p0) \u2286 {p0, p1} because of the first observation and because no set agent is with p0. So, for every set agent S \u2208 S, we have u \u2113 S(\u03c0 \u2113) \u2265 u\u2113S(\u03c0 \u2113(p0) \u222a {S}) \u2265 60t\u2212 3t = 57t (where 60t is S\u2019s initial utility for p0 and \u22123t is a bound for the resent that S might have build for p0 or p1). Therefore, \u03c0\n\u2113(S) contains at least one filling agent or three element agents x with x \u2208 S. Since no two set agents are in the same coalition, this implies the existence of an exact cover for U .\nFor appreciative agents, we can use almost the same construction. We just set p0\u2019s initial utility for p1 to \u22121 while all other utilities stay the same. Then, the proof of correctness is very similar to the proof for resentful agents.\nLemma C.2. resentful- and appreciative-ashg-CS-Sequence are NP-hard.\nProof. We first show the statement for resentful agents and reduce from RX3C. Construction. Let an instance of RX3C (U,S) with a universe U = {x1, . . . , x3t} and a family S = {S1, . . . , S3t} of 3-subsets of U be given. We set k = 3t+2 and create the following additively separable hedonic game. The set of agents is N = U \u222aS \u222aF \u222aQ with element agents U , set agents S, filling agents F = {f1, . . . , f2t}, and penalizing agents Q = {p0, . . . , p6}. The initial utilities of the agents are illustrated in Figure 9:\n\u2022 Each set agent S has utility 60t for each filling agent, utility 20t for element agents x with x \u2208 S, and utility 60t for the penalizing agent p0.\n\u2022 Each element agent has utility 1 for each set agent and utility 0 for all other element agents.\n\u2022 Each filling agent has utility 1 for each set agent.\n\u2022 p0 has utility 20t for all set agents and utility 10t for p1.\n\u2022 Agents p1, p3, and p5 have utility 40t for each other.\n\u2022 For i \u2208 {1, 3, 5}, agent pi has utility 60t for agent pi+1 and vice versa.\n\u2022 For i \u2208 {2, 4, 6}, agent pi has utility 50t for agent pi+1 and vice versa (where p7 = p1).\n\u2022 All not explicitly mentioned utilities are \u22121000t.\nNote that the penalizing gadget consisting of agents p1, . . . , p6 is a variant of an ASHG by Aziz et al. (2013, Example 1) for which no CS partition exists (for normal ASHGs).\n(\u21d2) Given an exact cover S \u2032 \u2286 S, consider the following sequence of group deviations. For each S \u2208 S \u2032, S and the three x \u2208 S deviate together (t deviations). For each S \u2208 S \\ S \u2032, S deviates with one filling agent that is still in a singleton (2t deviations). Now, p0 deviates with p1. Lastly, p3, p4, and p5 deviate together. Hence, we have 3t+ 2 deviations in total.\nAll these deviations are CS deviations as all these deviations are performed from singletons to coalitions with positive utilities for all deviators.\nNext, we show that the resulting partition \u03c0 is CS. First note that no two agents who have utility \u22121000t for each other want to deviate together. Each element agent x only has a positive utility of 1 for all set agents and is in a coalition with one set agent. As no two set agents will ever deviate together, there is no coalition that x could deviate with to improve her utility. The same holds for all filling agents. Each set agent S has utility 60t for \u03c0(S). As no element or filling agent wants to deviate, the only remaining agent for which S has positive utility is p0. Yet, S only has utility 60t for p0 which is no improvement compared to \u03c0(S). So no set agent has a CS deviation. Therefore, also p0 has no CS deviation as she would only like to deviate with some set agents. p1 has utility 300t for \u03c0(p1) = {p0, p1} and would thus not deviate without p0. Similarly, the remaining agents p2, . . . , p6 have no CS deviation without p1. Thus, the whole partition \u03c0 is CS.\n(\u21d0) Assume that we have a sequence of \u2113 \u2264 k = 3t + 2 CS deviations leading from the singleton partition \u03c00 to a CS partition \u03c0\u2113. In this sequence, no agent is ever in a coalition with an agent for which she has utility \u22121000t because she would never deviate with this agent. Therefore, the largest coalitions in this sequence have size at most four (containing one set agent and three element agents). It follows that the sum of the resent that a single agent accumulates for the other agents during \u2113 \u2264 3t+2 deviations is bounded by \u21132 \u00b7 3 \u2264 3t+2 2 \u00b7 3 = 9 2t+3 because she can be left by at most three agents every second deviation. We will now show that no set agent is in a joint coalition with p0 in \u03c0\n\u2113. For the sake of a contradiction, assume that S \u2208 \u03c0\u2113(p0) for some S \u2208 S. By the first observation, this implies that \u03c0\u2113(p0) = {S, p0}. This means that p1, . . . , p6 have formed coalitions among each other.\nYet, as argued by Aziz et al. (2013, Example 1), there is no CS partition for these six agents. Note that resent, which influences each player by a total utility change of at most 92t+ 3, does not facilitate stability because the differences between the utilities in this group are at least 10t. It follows that \u03c0\u2113 is not CS which is a contradiction. So no set agent is together with p0 in \u03c0\n\u2113. Next, since \u03c0\u2113 is CS, no coalition {S, p0} with S \u2208 S has a CS deviation. Since p0 is together with no set agent in \u03c0\u2113, p0 can have a utility of at most 10t for \u03c0 \u2113 and wants to deviate to {S, p0}. So, S does not want to deviate to {S, p0}. Therefore, u \u2113 S(\u03c0 \u2113) \u2265 u\u2113S({S, p0}) \u2265 60t\u2212 ( 9 2t+ 3) = 111 2 t\u2212 3. Hence, \u03c0\n\u2113(S) contains at least one filling agent or three element agents x with x \u2208 S. Since no two set agents are in the same coalition, this implies the existence of an exact cover for U .\nFor appreciative agents, we can use the same construction and the proof is very similar."
        }
    ],
    "title": "Causes of Stability in Dynamic Coalition Formation",
    "year": 2022
}