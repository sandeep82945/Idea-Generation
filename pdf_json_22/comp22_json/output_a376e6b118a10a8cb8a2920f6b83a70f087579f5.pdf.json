{
    "abstractText": "Solving math word problems requires deductive reasoning over the quantities in the text. Various recent research efforts mostly relied on sequence-to-sequence or sequence-to-tree models to generate mathematical expressions without explicitly performing relational reasoning between quantities in the given context. While empirically effective, such approaches typically do not provide explanations for the generated expressions. In this work, we view the task as a complex relation extraction problem, proposing a novel approach that presents explainable deductive reasoning steps to iteratively construct target expressions, where each step involves a primitive operation over two quantities defining their relation. Through extensive experiments on four benchmark datasets, we show that the proposed model significantly outperforms existing strong baselines. We further demonstrate that the deductive procedure not only presents more explainable steps but also enables us to make more accurate predictions on questions that require more complex reasoning.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zhanming Jie"
        },
        {
            "affiliations": [],
            "name": "Jierui Li"
        },
        {
            "affiliations": [],
            "name": "Wei Lu"
        }
    ],
    "id": "SP:bb93f67171493466a9c9f0920a124c31b05663a9",
    "references": [
        {
            "authors": [
                "Aida Amini",
                "Saadia Gabriel",
                "Shanchuan Lin",
                "Rik Koncel-Kedziorski",
                "Yejin Choi",
                "Hannaneh Hajishirzi."
            ],
            "title": "Mathqa: Towards interpretable math word problem solving with operation-based formalisms",
            "venue": "Proceedings of NAACL.",
            "year": 2019
        },
        {
            "authors": [
                "Jacob Andreas",
                "Marcus Rohrbach",
                "Trevor Darrell",
                "Dan Klein."
            ],
            "title": "Neural module networks",
            "venue": "Proceedings of CVPR.",
            "year": 2016
        },
        {
            "authors": [
                "Yoshua Bengio",
                "Yann Lecun",
                "Geoffrey Hinton."
            ],
            "title": "Deep learning for ai",
            "venue": "Communications of the ACM, 64(7):58\u201365.",
            "year": 2021
        },
        {
            "authors": [
                "Tarek R Besold",
                "Artur d\u2019Avila Garcez",
                "Sebastian Bader",
                "Howard Bowman",
                "Pedro Domingos",
                "Pascal Hitzler",
                "Kai-Uwe K\u00fchnberger",
                "Luis C Lamb",
                "Daniel Lowd",
                "Priscila Machado Vieira Lima"
            ],
            "title": "Neuralsymbolic learning and reasoning: A survey",
            "year": 2017
        },
        {
            "authors": [
                "Daniel G Bobrow"
            ],
            "title": "Natural language input for a computer problem solving system",
            "year": 1964
        },
        {
            "authors": [
                "Yixuan Cao",
                "Feng Hong",
                "Hongwei Li",
                "Ping Luo."
            ],
            "title": "A bottom-up dag structure extraction model for math word problems",
            "venue": "Proceedings of AAAI.",
            "year": 2021
        },
        {
            "authors": [
                "Ting-Rui Chiang",
                "Yun-Nung Chen."
            ],
            "title": "Semantically-aligned equation generation for solving and reasoning math word problems",
            "venue": "Proceedings of NAACL.",
            "year": 2019
        },
        {
            "authors": [
                "Kyunghyun Cho",
                "Bart van Merri\u00ebnboer",
                "Dzmitry Bahdanau",
                "Yoshua Bengio."
            ],
            "title": "On the properties of neural machine translation: Encoder\u2013decoder approaches",
            "venue": "Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statisti-",
            "year": 2014
        },
        {
            "authors": [
                "Eldan Cohen",
                "Christopher Beck."
            ],
            "title": "Empirical analysis of beam search performance degradation in neural sequence models",
            "venue": "Proceedings of ICML.",
            "year": 2019
        },
        {
            "authors": [
                "Michael Collins."
            ],
            "title": "Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms",
            "venue": "Proceedings of EMNLP.",
            "year": 2002
        },
        {
            "authors": [
                "Alexis Conneau",
                "Kartikay Khandelwal",
                "Naman Goyal Vishrav Chaudhary Guillaume Wenzek",
                "Francisco Guzm\u00e1n",
                "Edouard Grave Myle Ott Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Unsupervised cross-lingual representation learning at scale",
            "venue": "In",
            "year": 2020
        },
        {
            "authors": [
                "Yiming Cui",
                "Wanxiang Che",
                "Ting Liu",
                "Bing Qin",
                "Ziqing Yang",
                "Shijin Wang",
                "Guoping Hu."
            ],
            "title": "Pre-training with whole word masking for chinese bert",
            "venue": "arXiv preprint arXiv:1906.08101.",
            "year": 2019
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of NAACL.",
            "year": 2019
        },
        {
            "authors": [
                "Ian Goodfellow",
                "Yoshua Bengio",
                "Aaron Courville."
            ],
            "title": "Deep learning",
            "venue": "MIT press.",
            "year": 2016
        },
        {
            "authors": [
                "Nitish Gupta",
                "Kevin Lin",
                "Dan Roth",
                "Sameer Singh",
                "Matt Gardner."
            ],
            "title": "Neural module networks for reasoning over text",
            "venue": "Proceedings of ICLR.",
            "year": 2020
        },
        {
            "authors": [
                "Chris Hokamp",
                "Qun Liu."
            ],
            "title": "Lexically constrained decoding for sequence generation using grid beam search",
            "venue": "Proceedings of ACL.",
            "year": 2017
        },
        {
            "authors": [
                "Danqing Huang",
                "Jing Liu",
                "Chin-Yew Lin",
                "Jian Yin."
            ],
            "title": "Neural math word problem solver with reinforcement learning",
            "venue": "Proceedings of COLING.",
            "year": 2018
        },
        {
            "authors": [
                "Daniel Kahneman."
            ],
            "title": "Thinking, fast and slow",
            "venue": "Macmillan.",
            "year": 2011
        },
        {
            "authors": [
                "Angelos Katharopoulos",
                "Apoorv Vyas",
                "Nikolaos Pappas",
                "Fran\u00e7ois Fleuret."
            ],
            "title": "Transformers are rnns: Fast autoregressive transformers with linear attention",
            "venue": "Proceedings of ICML.",
            "year": 2020
        },
        {
            "authors": [
                "Diederik P Kingma",
                "Jimmy Ba."
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv preprint arXiv:1412.6980.",
            "year": 2014
        },
        {
            "authors": [
                "Thomas N Kipf",
                "Max Welling."
            ],
            "title": "Semisupervised classification with graph convolutional networks",
            "venue": "Proceedings of ICLR.",
            "year": 2017
        },
        {
            "authors": [
                "Philipp Koehn",
                "Rebecca Knowles."
            ],
            "title": "Six challenges for neural machine translation",
            "venue": "Proceedings of the First Workshop on Neural Machine Translation, ACL.",
            "year": 2017
        },
        {
            "authors": [
                "Rik Koncel-Kedziorski",
                "Subhro Roy",
                "Aida Amini",
                "Nate Kushman",
                "Hannaneh Hajishirzi."
            ],
            "title": "Mawps: A math word problem repository",
            "venue": "Proceedings of NAACL.",
            "year": 2016
        },
        {
            "authors": [
                "Nate Kushman",
                "Yoav Artzi",
                "Luke Zettlemoyer",
                "Regina Barzilay."
            ],
            "title": "Learning to automatically solve algebra word problems",
            "venue": "Proceedings of ACL.",
            "year": 2014
        },
        {
            "authors": [
                "Yihuai Lan",
                "Lei Wang",
                "Qiyuan Zhang",
                "Yunshi Lan",
                "Bing Tian Dai",
                "Yan Wang",
                "Dongxiang Zhang",
                "Ee-Peng Lim."
            ],
            "title": "Mwptoolkit: An open-source framework for deep learning-based math word problem solvers",
            "venue": "arXiv preprint arXiv:2109.00799.",
            "year": 2021
        },
        {
            "authors": [
                "Kenton Lee",
                "Luheng He",
                "Mike Lewis",
                "Luke Zettlemoyer."
            ],
            "title": "End-to-end neural coreference resolution",
            "venue": "Proceedings of EMNLP.",
            "year": 2017
        },
        {
            "authors": [
                "Kenton Lee",
                "Luheng He",
                "Luke Zettlemoyer."
            ],
            "title": "Higher-order coreference resolution with coarse-tofine inference",
            "venue": "Proceedings of NAACL.",
            "year": 2018
        },
        {
            "authors": [
                "Tao Lei",
                "Regina Barzilay",
                "Tommi Jaakkola."
            ],
            "title": "Rationalizing neural predictions",
            "venue": "Proceedings of EMNLP.",
            "year": 2016
        },
        {
            "authors": [
                "Jierui Li",
                "Lei Wang",
                "Jipeng Zhang",
                "Yan Wang",
                "Bing Tian Dai",
                "Dongxiang Zhang."
            ],
            "title": "Modeling intra-relation in math word problems with different functional multi-head attentions",
            "venue": "Proceedings of the ACL.",
            "year": 2019
        },
        {
            "authors": [
                "Shucheng Li",
                "Lingfei Wu",
                "Shiwei Feng",
                "Fangli Xu",
                "Fengyuan Xu",
                "Sheng Zhong."
            ],
            "title": "Graph-totree neural networks for learning structured inputoutput translation with applications to semantic parsing and math word problem",
            "venue": "Proceedings of Find-",
            "year": 2020
        },
        {
            "authors": [
                "Zhongli Li",
                "Wenxuan Zhang",
                "Chao Yan",
                "Qingyu Zhou",
                "Chao Li",
                "Hongzhi Liu",
                "Yunbo Cao."
            ],
            "title": "Seeking patterns, not just memorizing procedures: Contrastive learning for solving math word problems",
            "venue": "arXiv preprint arXiv:2110.08464.",
            "year": 2021
        },
        {
            "authors": [
                "Chao-Chun Liang",
                "Yu-Shiang Wong",
                "Yi-Chung Lin",
                "Keh-Yih Su."
            ],
            "title": "A meaning-based statistical english math word problem solver",
            "venue": "Proceedings of NAACL.",
            "year": 2018
        },
        {
            "authors": [
                "Zhenwen Liang",
                "Jipeng Zhang",
                "Jie Shao",
                "Xiangliang Zhang."
            ],
            "title": "Mwp-bert: A strong baseline for math word problems",
            "venue": "arXiv preprint arXiv:2107.13435.",
            "year": 2021
        },
        {
            "authors": [
                "Christian Liguda",
                "Thies Pfeiffer."
            ],
            "title": "Modeling math word problems with augmented semantic networks",
            "venue": "International Conference on Application of Natural Language to Information Systems.",
            "year": 2012
        },
        {
            "authors": [
                "Xin Lin",
                "Zhenya Huang",
                "Hongke Zhao",
                "Enhong Chen",
                "Qi Liu",
                "Hao Wang",
                "Shijin Wang."
            ],
            "title": "Hms: A hierarchical solver with dependency-enhanced understanding for math word problem",
            "venue": "Proceedings of AAAI.",
            "year": 2021
        },
        {
            "authors": [
                "Wang Ling",
                "Dani Yogatama",
                "Chris Dyer",
                "Phil Blunsom."
            ],
            "title": "Program induction by rationale generation: Learning to solve and explain algebraic word problems",
            "venue": "Proceedings of ACL.",
            "year": 2017
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Ilya Loshchilov",
                "Frank Hutter."
            ],
            "title": "Decoupled weight decay regularization",
            "venue": "Proceedings of ICLR.",
            "year": 2019
        },
        {
            "authors": [
                "Minh-Thang Luong",
                "Hieu Pham",
                "Christopher D Manning."
            ],
            "title": "Effective approaches to attentionbased neural machine translation",
            "venue": "Proceedings of EMNLP.",
            "year": 2015
        },
        {
            "authors": [
                "Anirban Mukherjee",
                "Utpal Garain."
            ],
            "title": "A review of methods for automatic understanding of natural language mathematical problems",
            "venue": "Artificial Intelligence Review, 29(2):93\u2013122.",
            "year": 2008
        },
        {
            "authors": [
                "Mark-Jan Nederhof."
            ],
            "title": "Weighted deductive parsing and knuth\u2019s algorithm",
            "venue": "Computational Linguistics, 29(1):135\u2013143.",
            "year": 2003
        },
        {
            "authors": [
                "Arkil Patel",
                "Satwik Bhattamishra",
                "Navin Goyal"
            ],
            "title": "Are NLP models really able to solve simple math word problems",
            "venue": "In Proceedings of NAACL",
            "year": 2021
        },
        {
            "authors": [
                "Jean Piaget."
            ],
            "title": "Child\u2019s Conception of Number",
            "venue": "Routledge.",
            "year": 1952
        },
        {
            "authors": [
                "Jinghui Qin",
                "Xiaodan Liang",
                "Yining Hong",
                "Jianheng Tang",
                "Liang Lin."
            ],
            "title": "Neural-symbolic solver for math word problems with auxiliary tasks",
            "venue": "Proceedings of ACL-IJCNLP.",
            "year": 2021
        },
        {
            "authors": [
                "Cassandra A Richards",
                "Jennifer A Sanderson."
            ],
            "title": "The role of imagination in facilitating deductive reasoning in 2-, 3-and 4-year-olds",
            "venue": "Cognition, 72(2):B1\u2013B9.",
            "year": 1999
        },
        {
            "authors": [
                "Subhro Roy",
                "Dan Roth."
            ],
            "title": "Solving general arithmetic word problems",
            "venue": "Proceedings of EMNLP.",
            "year": 2015
        },
        {
            "authors": [
                "Subhro Roy",
                "Dan Roth."
            ],
            "title": "Mapping to declarative knowledge for word problem solving",
            "venue": "Transactions of the Association for Computational Linguistics, 6:159\u2013172.",
            "year": 2018
        },
        {
            "authors": [
                "Jianhao Shen",
                "Yichun Yin",
                "Lin Li",
                "Lifeng Shang",
                "Xin Jiang",
                "Ming Zhang",
                "Qun Liu."
            ],
            "title": "Generate & rank: A multi-task framework for math word problems",
            "venue": "Proceedings of Findings of EMNLP.",
            "year": 2021
        },
        {
            "authors": [
                "Yibin Shen",
                "Cheqing Jin."
            ],
            "title": "Solving math word problems with multi-encoders and multi-decoders",
            "venue": "Proceedings of COLING.",
            "year": 2020
        },
        {
            "authors": [
                "Stuart M Shieber",
                "Yves Schabes",
                "Fernando CN Pereira."
            ],
            "title": "Principles and implementation of deductive parsing",
            "venue": "The Journal of logic programming, 24(1-2):3\u201336.",
            "year": 1995
        },
        {
            "authors": [
                "Minghuan Tan",
                "Lei Wang",
                "Lingxiao Jiang",
                "Jing Jiang."
            ],
            "title": "Investigating math word problems using pretrained multilingual language models",
            "venue": "arXiv preprint arXiv:2105.08928.",
            "year": 2021
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Proceedings of NeurIPS.",
            "year": 2017
        },
        {
            "authors": [
                "Piia Maria Vilenius-Tuohimaa",
                "Kaisa Aunola",
                "JariErik Nurmi."
            ],
            "title": "The association between mathematical word problems and reading comprehension",
            "venue": "Educational Psychology, 28(4):409\u2013426.",
            "year": 2008
        },
        {
            "authors": [
                "Lei Wang",
                "Dongxiang Zhang",
                "Jipeng Zhang",
                "Xing Xu",
                "Lianli Gao",
                "Bing Tian Dai",
                "Heng Tao Shen."
            ],
            "title": "Template-based math word problem solvers with recursive neural networks",
            "venue": "Proceedings of AAAI.",
            "year": 2019
        },
        {
            "authors": [
                "Yan Wang",
                "Xiaojiang Liu",
                "Shuming Shi."
            ],
            "title": "Deep neural solver for math word problems",
            "venue": "Proceedings of EMNLP.",
            "year": 2017
        },
        {
            "authors": [
                "Ronald J Williams",
                "David Zipser."
            ],
            "title": "A learning algorithm for continually running fully recurrent neural networks",
            "venue": "Neural computation, 1(2):270\u2013 280.",
            "year": 1989
        },
        {
            "authors": [
                "Thomas Wolf",
                "Julien Chaumond",
                "Lysandre Debut",
                "Victor Sanh",
                "Clement Delangue",
                "Anthony Moi",
                "Pierric Cistac",
                "Morgan Funtowicz",
                "Joe Davison",
                "Sam Shleifer"
            ],
            "title": "Transformers: State-of-theart natural language processing",
            "year": 2020
        },
        {
            "authors": [
                "Qinzhuo Wu",
                "Qi Zhang",
                "Jinlan Fu",
                "Xuan-Jing Huang."
            ],
            "title": "A knowledge-aware sequence-to-tree network for math word problem solving",
            "venue": "Proceedings of EMNLP.",
            "year": 2020
        },
        {
            "authors": [
                "Qinzhuo Wu",
                "Qi Zhang",
                "Zhongyu Wei",
                "Xuan-Jing Huang."
            ],
            "title": "Math word problem solving with explicit numerical values",
            "venue": "Proceedings of ACLIJCNLP.",
            "year": 2021
        },
        {
            "authors": [
                "Zhipeng Xie",
                "Shichao Sun."
            ],
            "title": "A goal-driven tree-structured neural model for math word problems",
            "venue": "Proceedings of IJCAI.",
            "year": 2019
        },
        {
            "authors": [
                "Dmitry Zelenko",
                "Chinatsu Aone",
                "Anthony Richardella."
            ],
            "title": "Kernel methods for relation extraction",
            "venue": "Journal of machine learning research, 3(Feb).",
            "year": 2003
        },
        {
            "authors": [
                "Jipeng Zhang",
                "Lei Wang",
                "Roy Ka-Wei Lee",
                "Yi Bin",
                "Yan Wang",
                "Jie Shao",
                "Ee-Peng Lim."
            ],
            "title": "Graph-totree learning for solving math word problems",
            "venue": "Proceedings of ACL.",
            "year": 2020
        },
        {
            "authors": [
                "Zexuan Zhong",
                "Danqi Chen."
            ],
            "title": "A frustratingly easy approach for entity and relation extraction",
            "venue": "Proceedings of NAACL.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Math word problem (MWP) solving (Bobrow, 1964) is a task of answering a mathematical question that is described in natural language. Solving MWP requires logical reasoning over the quantities presented in the context (Mukherjee and Garain, 2008) to compute the numerical answer. Various recent research efforts regarded the problem as a generation problem \u2013 typically, such models focus on generating the complete target mathematical expression, often represented in the form of a linear sequence or a tree structure (Xie and Sun, 2019).\nFigure 1 (top) depicts a typical approach that attempts to generate the target expression in the\n1Our code and data are released at https://github. com/allanj/Deductive-MWP.\nQuestion: In a division sum , the remainder is 8 and the divisor is 6 times the quotient and is obt-ained by adding 3 to the thrice of the remainder. What is the dividend? Answer: 129.5 Expr: ((8 \u00d7 3 + 3)\u00d7(8 \u00d7 3 + 3)\u00f76)+8\nform of a tree structure, which is adopted in recent research efforts (Xie and Sun, 2019; Zhang et al., 2020; Patel et al., 2021; Wu et al., 2021). Specifically, the output is an expression that can be obtained from such a generated structure. We note that, however, there are several limitations with such a structure generation approach. First, such a process typically involves a particular order when generating the structure. In the example, given the complexity of the problem, the decision of generating the addition (\u201c+\u201d) operation as the very first step could be counter-intuitive and does not provide adequate explanations that show the reasoning process when being presented to a human learner. Furthermore, the resulting tree contains identical sub-trees (\u201c8 \u00d7 3 + 3\u201d) as highlighted in blue dashed boxes. Unless a certain specifically designed mechanism is introduced for reusing the already generated intermediate expression, the approach would need to repeat the same effort in its process for generating the same sub-expression. ar X iv :2 20 3.\n10 31\n6v 4\n[ cs\n.C L\n] 1\n5 Se\np 20\n22\nSolving math problems generally requires deductive reasoning, which is also regarded as one of the important abilities in children\u2019s cognitive development (Piaget, 1952). In this work, we propose a novel approach that explicitly presents deductive reasoning steps. We make a key observation that MWP solving fundamentally can be viewed as a complex relation extraction problem \u2013 the task of identifying the complex relations among the quantities that appear in the given problem text. Each primitive arithmetic operation (such as addition, subtraction) essentially defines a different type of relation. Drawing on the success of some recent models for relation extraction in the literature (Zhong and Chen, 2021), our proposed approach involves a process that repeatedly performs relation extraction between two chosen quantities (including newly generated quantities).\nAs shown in Figure 1, our approach directly extracts the relation (\u201cmultiplication\u201d, or \u201c\u00d7\u201d) between 8 and 3, which come from the contexts \u201cremainder is 8\u201d and \u201cthrice of the remainder\u201d. In addition, it allows us to reuse the results from the intermediate expression in the fourth step. This process naturally yields a deductive reasoning procedure that iteratively derives new knowledge from existing ones. Designing such a complex relation extraction system presents several practical challenges. For example, some quantities may be irrelevant to the question while some others may need to be used multiple times. The model also needs to learn how to properly handle the new quantities that emerge from the intermediate expressions. Learning how to effectively search for the optimal sequence of operations (relations) and when to stop the deductive process is also important.\nIn this work, we tackle the above challenges and make the following major contributions:\n\u2022 We formulate MWP solving as a complex relation extraction task, where we aim to repeatedly identify the basic relations between different quantities. To the best of our knowledge, this is the first effort that successfully tackles MWP solving from such a new perspective.\n\u2022 Our model is able to automatically produce explainable steps that lead to the final answer, presenting a deductive reasoning process.\n\u2022 Our experimental results on four standard datasets across two languages show that our model significantly outperforms existing strong baselines. We further show that the model per-\nforms better on problems with more complex equations than previous approaches."
        },
        {
            "heading": "2 Related Work",
            "text": "Early efforts focused on solving MWP using probabilistic models with handcrafted features (Liguda and Pfeiffer, 2012). Kushman et al. (2014) and Roy and Roth (2018) designed templates to find the alignments between the declarative language and equations. Most recent works solve the problem by using sequence or tree generation models. Wang et al. (2017) proposed the Math23k dataset and presented a sequence-to-sequence (seq2seq) approach to generate the mathematical expression (Chiang and Chen, 2019). Other approaches improve the seq2seq model with reinforcement learning (Huang et al., 2018), template-based methods (Wang et al., 2019), and group attention mechanism (Li et al., 2019). Xie and Sun (2019) proposed a goal-driven tree-structured (GTS) model to generate the expression tree. This sequence-to-tree approach significantly improved the performance over the traditional seq2seq approaches. Some follow-up works incorporated external knowledge such as syntactic dependency (Shen and Jin, 2020; Lin et al., 2021) or commonsense knowledge (Wu et al., 2020). Cao et al. (2021) modeled the equations as a directed acyclic graph to obtain the expression. Zhang et al. (2020) and Li et al. (2020) adopted a graph-to-tree approach to model the quantity relations using the graph convolutional networks (GCN) (Kipf and Welling, 2017). Applying pre-trained language models such as BERT (Devlin et al., 2019) was shown to significantly benefit the tree expression generation (Lan et al., 2021; Tan et al., 2021; Liang et al., 2021; Li et al., 2021; Shen et al., 2021).\nDifferent from the tree-based generation models, our work is related to deductive systems (Shieber et al., 1995; Nederhof, 2003) where we aim to obtain step-by-step expressions. Recent efforts have also been working towards this direction. Ling et al. (2017) constructed a dataset to provide explanations for expressions at each step. Amini et al. (2019) created the MathQA dataset annotated with step-by-step operations. The annotations present the expression at each intermediate step during problem-solving. Our deductive process (Figure 1) attempts to automatically obtain the expression in an incremental, step-by-step manner.\nOur approach is also related to relation extraction (RE) (Zelenko et al., 2003), a fundamental task in\nthe field of information extraction that is focused on identifying the relationships between a pair of entities. Recently, Zhong and Chen (2021) designed a simple and effective approach to directly model the relations on the span pair representations. In this work, we treat the operation between a pair of quantities as the relation at each step in our deductive reasoning process. Traditional methods (Liang et al., 2018) applied rule-based approaches to extract the mathematical relations.\nMWP solving is typically regarded as one of the system 2 tasks (Kahneman, 2011; Bengio et al., 2021), and our current approach to this problem is related to neural symbolic reasoning (Besold et al., 2017). We design differentiable modules (Andreas et al., 2016; Gupta et al., 2020) in our model (\u00a73.2) to perform reasoning among the quantities."
        },
        {
            "heading": "3 Approach",
            "text": "The math word problem solving task can be defined as follows. Given a problem description S = {w1, w2,\u22ef, wn} that consists of a list of n words and QS = {q1, q2,\u22ef, qm}, a list of m quantities that appear in S , our task is to solve the problem and return the numerical answer. Ideally, the answer shall be computed through a mathematical reasoning process over a series of primitive mathematical operations (Amini et al., 2019) as shown in Figure 1. Such operations may include \u201c+\u201d (addition), \u201c\u2212\u201d (subtraction), \u201c\u00d7\u201d (multiplication), \u201c\u00f7\u201d (division), and \u201c\u2217\u2217\u201d (exponentiation).2\nIn our view, each of the primitive mathematical operations above can essentially be used for describing a specific relation between quantities. Fundamentally, solving a math word problem is a problem of complex relation extraction, which requires us to repeatedly identify the relations between quantities (including those appearing in the text and those intermediate ones created by relations). The overall solving procedure requires in-\n2While we consider binary operators, extending our approach to support unary or ternary operators is possible (\u00a74.3).\nvoking a relation classification module at each step, yielding a deductive reasoning process.\nIn practice, some questions cannot be answered without relying on certain predefined constants (such as \u03c0 and 1) that may not have appeared in the given problem description. We therefore also consider a set of constants C = {c1, c2,\u22ef, c\u2223C\u2223}. Such constants are also regarded as quantities (i.e., they would be regarded as {qm+1, qm+2, . . . , qm+\u2223C\u2223}) which may play useful roles when forming the final answer expression."
        },
        {
            "heading": "3.1 A Deductive System",
            "text": "As shown in Figure 1, applying the mathematical relation (e.g., \u201c+\u201d) between two quantities yields an intermediate expression e. In general, at step t, the resulting expression e(t) (after evaluation) becomes a newly created quantity that is added to the list of candidate quantities and is ready for participating in the remaining deductive reasoning process from step t + 1 onward. This process can be mathematically denoted as follows:\n\u2022 Initialization:\nQ(0) = QS \u222a C\n\u2022 At step t:\ne (t) i,j,op = qi op \u2212\u2192 qj qi, qj \u2208 Q (t\u22121)\nQ(t) = Q(t\u22121) \u222a {e(t)i,j,op}\nq\u2223Q(t)\u2223 \u2236= e (t) i,j,op\nwhere e(t)i,j,op represents the expression after applying the relation op to the ordered pair (qi, qj). Following the standard deduction systems (Shieber et al., 1995; Nederhof, 2003), the reasoning process can be formulated in Figure 2. We start with an axiom with the list of quantities in Q(0). The inference rule is qi op \u2212\u2192 qj as described above to obtain the expression as a new quantity at step t."
        },
        {
            "heading": "3.2 Model Components",
            "text": "Reasoner Figure 3 shows the deductive reasoning procedure in our model for an example that involves 3 quantities. We first convert the quantities (e.g., 2, 088) into a general quantity token \u201c<quant>\u201d. We next adopt a pre-trained language model such as BERT (Devlin et al., 2019) or Roberta (Cui et al., 2019; Liu et al., 2019) to obtain the quantity representation q for each quantity q.\nGiven the quantity representations, we consider all the possible quantity pairs, (qi, qj). Similar to Lee et al. (2017), we can obtain the representation of each pair by concatenating the two quantity representations and the element-wise product between them. As shown in Figure 3, we apply a non-linear feed-forward network (FFN) on top of the pair representation to get the representation of the newly created expression. The above procedure can be mathematically written as:\nei,j,op = FFNop([qi, qj , qi \u25e6 qj]), i \u2264 j (1)\nwhere ei,j,op is the representation of the intermediate expression e and op is the operation (e.g., \u201c+\u201d, \u201c\u2212\u201d) applied to the ordered pair (qi, qj). FFNop is an operation-specific network that gives the expression representation under the particular operation op. Note that we have the constraint i \u2264 j. As a result we also consider the \u201creverse operation\u201d for division and subtraction (Roy and Roth, 2015).\nAs shown in Figure 3, the expression e1,2,\u00f7 will be regarded as a new quantity with representation q4 at t = 1. In general, we can assign a score to a single reasoning step that yields the expression e(t)i,j,op from qi and qj with operation op. Such a score can be calculated by summing over the scores defined over the representations of the two quantities and the score defined over the expression:\ns(e(t)i,j,op) = sq(qi) + sq(qj) + se(ei,j,op) (2)\nwhere we have:\nsq(qi) = wq \u22c5 FFN(qi) se(ei,j,op) = we \u22c5 ei,j,op\n(3)\nwhere sq(\u22c5) and se(\u22c5) are the scores assigned to the quantity and the expression, respectively, and wq and we are the corresponding learnable parameters. Our goal is to find the optimal expression sequence [e(1), e(2),\u22ef, e(T )] that enables us to compute the final numerical answer, where T is the total number of steps required for this deductive process.\nTerminator Our model also has a mechanism that decides whether the deductive procedure is ready to terminate at any given time. We introduce a binary label \u03c4 , where 1 means the procedure stops here, and 0 otherwise. The final score of the expression e at time step t can be calculated as:\nS(e(t)i,j,op, \u03c4) = s(e (t) i,j,op)+w\u03c4 \u22c5FFN(ei,j,op) (4)\nwhere w\u03c4 is the parameter vector for scoring the \u03c4 .\nRationalizer Once we obtain a new intermediate expression at step t, it is crucial to update the representations for the existing quantities. We call this step rationalization because it could potentially give us the rationale that explains an outcome (Lei et al., 2016). As shown in Figure 4, the intermediate expression e serves as the rationale that explains how the quantity changes from q to q\u2032. Without this step, there is a potential shortcoming for the model. That is, because if the quantity representations do not get updated as we continue the deductive reasoning process, those expressions that were initially highly ranked (say, at the first step) would always be preferred over those lowly ranked ones throughout the process.3 We rationalize the quantity representation using the current intermediate expression e(t), so that the quantity is aware of the generated expressions when its representation gets updated. This procedure can be mathematically formulated as follows:\nq \u2032 i = Rationalizer(qi, e (t)) \u2200 1 \u2264 i \u2264 \u2223Q\u2223 (5) 3See the supplementary material for more details on this.\nTwo well-known techniques we can adopt as rationalizers are multi-head self-attention (Vaswani et al., 2017) and a gated recurrent unit (GRU) (Cho et al., 2014) cell, which allow us to update the quantity representation, given the intermediate expression representation. Table 1 shows the mechanism in two different rationalizers. For the first approach, we essentially construct a sentence with two token representations \u2013 quantity qi and the previous expression e \u2013 to perform self-attention. In the second approach, we use qi as the input state and e as the previous hidden state in a GRU cell."
        },
        {
            "heading": "3.3 Training and Inference",
            "text": "Similar to training sequence-to-sequence models (Luong et al., 2015), we adopt the teacherforcing strategy (Williams and Zipser, 1989) to guide the model with gold expressions during training. The loss4 can be written as:\nL(\u03b8) = T\n\u2211 t=1 ( max (i,j,op)\u2208H(t),\u03c4 [S\u03b8(e (t) i,j,op, \u03c4)] \u2212 S\u03b8(e (t) i\u2217,j\u2217,op\u2217 , \u03c4 \u2217)) + \u03bb\u2223\u2223\u03b8\u2223\u22232 (6)\nwhere \u03b8 includes all parameters in the deductive reasoner and H(t) contains all the possible choices of quantity pairs and relations available at time step t. \u03bb is the hyperparameter for the L2 regularization term. The set H(t) grows as new expressions are constructed and become new quantities during the deductive reasoning process. The overall loss is computed by summing over the loss at each time step (assuming totally T steps).\nDuring inference, we set a maximum time step Tmax and find the best expression e\n\u2217 that has the highest score at each time step. Once we see \u03c4 = 1 is chosen, we stop constructing new expressions\n4Actually, one might have noticed that this loss comes with a trivial solution at \u03b8 = 0. In practice, however, our model and training process would prevent us from reaching such a degenerate solution with proper initialization (Goodfellow et al., 2016). This is similar to the training of a structured perceptron (Collins, 2002), where a similar situation is also involved.\nand terminate the process. The overall expression (formed by the resulting expression sequence) will be used for computing the final numerical answer.\nDeclarative Constraints Our model repeatedly relies on existing quantities to construct new quantities, which results in a structure showing the deductive reasoning process. One advantage of such an approach is that it allows certain declarative knowledge to be conveniently incorporated. For example, as we can see in Equation 6, the default approach considers all the possible combinations among the quantities during the maximization step. We can easily impose constraints to avoid considering certain combinations. In practice, we found in certain datasets such as SVAMP, there does not exist any expression that involve operations applied to the same quantity (such as 9 + 9 or 9 \u00d7 9, where 9 is from the same quantity in the text). Besides, we also observe that the intermediate results would not be negative. We can simply exclude such cases in the maximization process, effectively reducing the search space during both training and inference. We show that adding such declarative constraints can help improve the performance."
        },
        {
            "heading": "4 Experiments",
            "text": "Datasets We conduct experiments on four datasets across two different languages: MAWPS (Koncel-Kedziorski et al., 2016), Math23k (Wang et al., 2017), MathQA (Amini et al., 2019), and SVAMP (Patel et al., 2021). The dataset statistics can be found in Table 2. For MathQA5, we follow Tan et al. (2021)6 to\n5The original MathQA (Amini et al., 2019) dataset contains a certain number of instances that have annotated equations which cannot lead to the correct numerical answer.\n6Our dataset size is not exactly the same as Tan et al. (2021) as they included some instances that are wrongly annotated. We only kept the part that has correct annotations. We con-\nadapt the dataset to filter out some questions that are unsolvable. We consider the operations \u201caddition\u201d, \u201csubtraction\u201d, \u201cmultiplication\u201d, and \u201cdivision\u201d for MAWPS and SVAMP, and an extra \u201cexponentiation\u201d for MathQA and Math23k.\nThe number of operations involved in each question can be one of the indicators to help us gauge the difficulty of a dataset. Figure 5 shows the percentage distribution of the number of operations involved in each question. The MathQA dataset generally contains larger portions of questions that involve more operations, while 97% of the questions in MAWPS can be answered with only one or two operations. More than 60% of the instances in MathQA have three or more operations, which likely makes their problems harder to solve. Furthermore, MathQA (Amini et al., 2019) contains GRE questions in many domains including physics, geometry, probability, etc., while Math23k questions are from primary school. Different from other datasets, SVAMP (Patel et al., 2021)7 is a challenging set that is manually created to evaluate a model\u2019s robustness. They applied variations over the instances sampled from MAWPS. Such variations could be: adding extra quantities, swapping the positions between noun phrases, etc.\nBaselines The baseline approaches can be broadly categorized into sequence-to-sequence (S2S), sequence-to-tree (S2T) and graph-to-tree (G2T) models. GroupAttn (Li et al., 2019) designed several types of attention mechanisms such as question or quantity related attentions in the seq2seq model. Tan et al. (2021) uses multilingual\nfirmed such information with the authors of Tan et al. (2021), and make our version of this dataset publicly available.\n7There is no test split for this dataset. We strictly follow the experiment setting in Patel et al. (2021).\nBERT with an LSTM decoder (mBERT-LSTM). Lan et al. (2021) presented two seq2seq models that use BERT/Roberta as both encoder and decoder, namely, BERT-BERT and Roberta-Roberta. Sequence-to-tree models mainly use a tree-based decoder with GRU (GTS) (Xie and Sun, 2019) or BERT as the encoder (BERT-Tree) (Liang et al., 2021; Li et al., 2021). NUMS2T (Wu et al., 2020) and NeuralSymbolic (Qin et al., 2021) solver incorporate external knowledge in the S2T architectures. Graph2Tree (Zhang et al., 2020) models the quantity relations using GCN.\nTraining Details We adopt BERT (Devlin et al., 2019) and Roberta (Liu et al., 2019) for the English datasets. Chinese BERT and Chinese Roberta (Cui et al., 2019) are used for Math23k. We use the GRU cell as the rationalizer. We also conduct experiments with multilingual BERT and XLMRoberta (Conneau et al., 2020). The pre-trained models are initialized from HuggingFace\u2019s Transformers (Wolf et al., 2020). We optimize the loss with the Adam optimizer (Kingma and Ba, 2014; Loshchilov and Hutter, 2019). We use a learning rate of 2e-5 and a batch size of 30. The regularization coefficient \u03bb is set to 0.01. We run our models with 5 random seeds and report the average results (with standard deviation). Following most previous works, we mainly report the value accuracy (percentage) in our experiments. In other words, a prediction is considered correct if the predicted expression leads to the same value as the gold expression. Following previous practice (Zhang et al., 2020; Tan et al., 2021; Patel et al., 2021), we report\n5-fold cross-validation results on both MAWPS8 and Math23k, and also report the test set performance for Math23k, MathQA and SVAMP."
        },
        {
            "heading": "4.1 Results",
            "text": "MAWPS and Math23k We first discuss the results on MAWPS and Math23k, two datasets that are commonly used in previous research. Table 3 and 4 show the main results of the proposed models with different pre-trained language models. We compare with previous works that have reported results on these datasets. Among all the encoders for our model DEDUCTREASONER, the Roberta encoder achieves the best performance. In addition, DEDUCTREASONER significantly outperforms all the baselines regardless of the choice of encoder. The performance on the best S2S model (Roberta-Roberta) is on par with the best S2T model (Roberta-Graph2Tree) on MAWPS. Overall, the accuracy of Roberta-based DEDUCTREASONER is more than 3 points higher than RobertaGraph2Tree (p < 0.001)9 on MAWPS, and more than 2 points higher than BERT-Tree (p < 0.005) on Math23k. The comparisons show that our deductive reasoner is robust across different languages and datasets of different sizes. We noted that different approaches compare against each other though the experiments are conducted in different settings on the Math23k dataset. We present the detailed comparsion in Appendix C.\nMathQA and SVAMP As mentioned before, MathQA and SVAMP are more challenging \u2013 the former consists of more complex questions and the latter consists of specifically designed challenging questions. Table 5 and 6 show the performance comparisons. We are able to outperform the best baseline mBERT-LSTM10 by 1.5 points in accuracy\n8All previous efforts combine training/dev/test sets and perform 5-fold cross validation, which we follow.\n9We conduct bootstrapping t-test to compare the results. 10We ran the their code on our adapted MathQA dataset.\non MathQA. Different from other three datasets, the performance between different language models shows larger gaps on SVAMP. As we can see from baselines and our models, the choice of encoder appear to be important for solving questions in SVAMP \u2013 the results on using Roberta as the encoder are particularly striking. Our best variant ROBERTA-DEDUCTREASONER achieves an accuracy score of 47.3 and is able to outperfrom the best baseline (Roberta-Graph2Tree) by 3.5 points (p < 0.01). By incorporating the constraints from our prior knowledge (as discussed in \u00a73.3), we observe significant improvements for all variants \u2013 up to 7.0 points for our BERT-DEDUCTREASONER.\nOverall, these results show that our model is more robust as compared to previous approaches on such challenging datasets.\nFine-grained Analysis We further perform finegrained performance analysis based on questions with different numbers of operations. Table 7 shows the accuracy scores for questions that involve different numbers of operations. It also shows the equation accuracy on all datasets11. We compared our ROBERTA-\n11Equ Acc: we regard an equation as correct if and only if it matches with the reference equation (up to reordering of sub-expressions due to commutative operations, namley \u201c+\u201d and \u201c\u00d7\u201d).\nDEDUCTREASONER with the best performing baselines in Table 3 (Roberta-Graph2Tree), 4 (BERT-Tree), 5 (mBERT+LSTM) and 6 (RobertaGraph2Tree). On MAWPS and Math23k, our ROBERTA-DEDUCTREASONER model consistently yields higher results than baselines. On MathQA, our model also performs better on questions that involve 2, 3, and 4 operations. For the other more challenging dataset SVAMP, our model has comparable performance with the baseline on 1-step questions, but achieves significantly better results (+14.3 points) on questions that involve 2 steps. Such comparisons on MathQA and SVAMP show that our model has a robust reasoning capability on more complex questions.\nWe observe that all models (including ours and existing models) are achieving much lower accuracy scores on SVAMP, as compared to other datasets. We further investigate the reason for this. Patel et al. (2021) added irrelevant information such as extra quantities in the question to confuse the models. We quantify the effect by counting the percentage of instances which have quantities unused in the equations. As we can see in Table 8, SVAMP has the largest proportion (i.e., 44.5%) of instances whose gold equations do not fully utilize all the quantities in the problem text. The performance also significantly drops on those questions with more than one unused quantity on all datasets. The analysis suggests that our model still suffer from extra irrelevant information in the question and the performance is severely affected when such irrelevant information appears more frequently.\nEffect of Rationalizer Table 9 shows the performance comparison with different rationalizers. As described in \u00a73.2, the rationalizer is used to update the quantity representations at each step, so as to better \u201cprepare them\u201d for the subsequent reasoning process given the new context. We believe this step is crucial for achieving good performance, especially for complex MWP solving. As shown in Table 9, the performance drops by 7.3 points in value accuracy for Math23k without rationalization, confirming the importance of rationalization in solving more complex problems that involve more steps. As most of the questions in MAWPS involve only 1-step questions, the significance of using rationalizer is not fully revealed on this dataset.\nIt can be seen that using self-attention achieves worse performance than the GRU unit. We believe the lower performance by using multi-head attention as rationalizer may be attributed to two reasons. First, GRU comes with sophisticated internal gating mechanisms, which may allow richer representations for the quantities. Second, attention, often interpreted as a mechanism for measuring similarities (Katharopoulos et al., 2020), may be inherently biased when being used for updating quantity representations. This is because when measuring the similarity between quantities and a specific expression (Figure 4), those quantities that have just participated in the construction of the expression may receive a higher degree of similarity."
        },
        {
            "heading": "4.2 Case Studies",
            "text": "Explainability of Output Figure 6 presents an example prediction from Math23k. In this question, the gold deductive process first obtains the speed difference by \u201c5 \u00f7 (5 + 3) \u2212 3 \u00f7 (5 + 3)\u201d and the final answer is 1400 divided by this difference. On the other hand, the predicted deductive process offers a slightly different understanding in speed difference. Assuming speed can be measured by some abstract \u201cunits\u201d, the predicted deductive process first performs subtraction between 5 and 3, which gives us \u201c2 units\u201d of speed difference. Next, we can obtain the number of words associated with each speed unit (1400\u00f72). Finally, we can arrive at the total number of words by multiplying the number of words per unit (700) and the total number of units (8).12 Through such an example we can see that our deductive reasoner is able to produce explainable steps to understand the answers.\nQuestion Perturbation The model predictions also give us guidance to understand the errors. Figure 7 shows how we can perturb a question given the error prediction (taken from Math23k). As we can see, the first step is incorrectly predicted with the \u201c+\u201d relation between 255 and 35. Because the first step involves the two quantities in the first two sentences, where we can locate the possible cause for the error. The gold step has a probability of 0.062 which is somewhat lower than the incorrect prediction. We believe that the second sentence (marked in red) may convey semantics that can be challenging for the model to digest, resulting in the incorrect prediction. Thus, we perturb the second sentence to make it semantically more straightforward (marked below in blue). The probability for the sub-expression 225 \u2212 35 becomes higher after the purtubation, leading to a correct prediction (the\n12Interestingly, when we presented this question to 3 human solvers, 2 of them used the first approach and 1 of them arrived at the second approach.\n\u201c\u2212\u201d relation). Such an analysis demonstrates the strong interpretability of our deductive reasoner, and highlights the important connection between math word problem solving and reading comprehension, a topic that has been studied in educational psychology (Vilenius-Tuohimaa et al., 2008)."
        },
        {
            "heading": "4.3 Practical Issues",
            "text": "We discuss some practical issues with the current model in this section. Similar to most previous research efforts (Li et al., 2019; Xie and Sun, 2019), our work needs to maintain a list of constants (e.g., 1 and \u03c0) as additional candidate quantities. However, a large number of quantities could lead to a large search space of expressions (i.e., H). In practice, we could select some top-scoring quantities and build expressions on top of them (Lee et al., 2018). Another assumption of our model, as shown in Figure 3, is that only binary operators are considered. Actually, extending it to support unary or ternary operators can be straightforward. Handling unary operators would require the introduction of some unary rules, and a ternary operator can be defined as a composition of two binary operators.\nOur current model performs the greedy search in the training and inference process, which could be improved with a beam search process. One challenge with designing the beam search algorithm is that the search space H(t) is expanding at each step t (Equation 6). We empirically found the model tends to favor outputs that involve fewer reasoning steps. In fact, better understanding the behavior and effect of beam search in seq2seq models remains an active research topic (Cohen and Beck, 2019; Koehn and Knowles, 2017; Hokamp and Liu, 2017), and we believe how to perform effective beam search in our setup could be an interesting research question that is worth exploring further."
        },
        {
            "heading": "5 Conclusion and Future Work",
            "text": "We provide a new perspective to the task of MWP solving and argue that it can be fundamentally regarded as a complex relation extraction problem. Based on this observation, and motivated by the deductive reasoning process, we propose an end-toend deductive reasoner to obtain the answer expression in a step-by-step manner. At each step, our model performs iterative mathematical relation extraction between quantities. Thorough experiments on four standard datasets demonstrate that our deductive reasoner is robust and able to yield new\nstate-of-the-art performance. The model achieves particularly better performance for complex questions that involve a larger number of operations. It offers us the flexibility in interpreting the results, thanks to the deductive nature of our model.\nFuture directions that we would like to explore include how to effectively incorporate commonsense knowledge into the deductive reasoning process, and how to facilitate counterfactual reasoning (Richards and Sanderson, 1999)."
        },
        {
            "heading": "Acknowledgements",
            "text": "We would like to thank the anonymous reviewers and our ARR action editor for their constructive comments, and Hang Li for helpful discussions and comments on this work. This work was done when Jierui Li was working as a research assistant at SUTD, and when Wei Lu was serving as a consultant at ByteDance AI Lab."
        },
        {
            "heading": "B Additional Implementation Details",
            "text": "We implement our model with PyTorch and run all experiments using Tesla V100 GPU. The feedforward network in our model is simply linear transformation followed by the ReLU activation. We also apply layer normalization and dropout in the feed-forward network. The hidden size in the feedforward network is 768, which the is same as the hidden size used in BERT/Roberta."
        },
        {
            "heading": "C Detailed Comparison on Math23k Dataset",
            "text": "We try to find the experiment details of previous work on the Math23k dataset. Table 10 shows their\nperformance with respect to different data splits, different beam sizes, etc.\n\u2022 Group Attention (Li et al., 2019): According to their paper in Table 2, they use the train/test split.\n\u2022 GTS (Xie and Sun, 2019): They only report the five-fold cross-validation performance.\n\u2022 KA-S2T (Wu et al., 2020): According to \u00a73.1 in their paper, they use their customized split though they still directly compared with the GTS approach.\n\u2022 MultiE&D (Shen and Jin, 2020): They did not mention that if they have validation set. But they mentioned that the results are evaluated on the test set. Thus, we marked it \u201cunknown\u201d.\n\u2022 Graph2Tree (Zhang et al., 2020): They also mentioned that the results are evaluated on test set. But the validation set could be used in their implementation based on the observation in their codebase.\n\u2022 NeuralSymbolic (Qin et al., 2021): They used greedy search (\u00a74.2.2) for generation and experimented with 5-fold cross validation in the experiments (\u00a74.3).\n\u2022 NUM2ST (Wu et al., 2021): They used customized splits according to \u00a73.1 in their paper.\n\u2022 HMS (Lin et al., 2021): The beam size is not mentioned in the paper. But we found the default value in the open-source codebase is 1. They did not mentioned the exact split either but simply mentioning \u201cfollow previous work\u201d. We assume they are using the train/validation/test split as we found that the codebase contains the validation set.\n\u2022 BERT-Tree (Li et al., 2021): They use\ntrain/validation/test split as described in the paper.\n\u2022 mBART-Large (Shen et al., 2021): They did not mentioned the split either but mentioning that the results are evaluated on the test set.\nWe present our performance for all the settings in Table 10. To compare with the recent work using mBart-Large (Shen et al., 2021), we also report the performance with a Roberta-Large encoder for our DEDUCTREASONER on the test set."
        }
    ],
    "title": "Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction",
    "year": 2022
}