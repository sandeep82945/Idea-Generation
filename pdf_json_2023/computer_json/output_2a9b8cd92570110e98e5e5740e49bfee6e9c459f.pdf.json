{
    "abstractText": "Label distribution learning (LDL) is a new machine learning paradigm for solving label ambiguity. Since it is difficult to directly obtain label distributions, many studies are focusing on how to recover label distributions from logical labels, dubbed label enhancement (LE). Existing LE methods estimate label distributions by simply building a mapping relationship between features and label distributions under the supervision of logical labels. They typically overlook the fact that both features and logical labels are descriptions of the instance from different views. Therefore, we propose a novel method called Contrastive Label Enhancement (ConLE) which integrates features and logical labels into the unified projection space to generate high-level features by contrastive learning strategy. In this approach, features and logical labels belonging to the same sample are pulled closer, while those of different samples are projected farther away from each other in the projection space. Subsequently, we leverage the obtained high-level features to gain label distributions through a welldesigned training strategy that considers the consistency of label attributes. Extensive experiments on LDL benchmark datasets demonstrate the effectiveness and superiority of our method.",
    "authors": [
        {
            "affiliations": [],
            "name": "Yifei Wang"
        },
        {
            "affiliations": [],
            "name": "Yiyang Zhou"
        },
        {
            "affiliations": [],
            "name": "Jihua Zhu"
        },
        {
            "affiliations": [],
            "name": "Xinyuan Liu"
        },
        {
            "affiliations": [],
            "name": "Wenbiao Yan"
        },
        {
            "affiliations": [],
            "name": "Zhiqiang Tian"
        }
    ],
    "id": "SP:a8b16c0e5f9ccf6c15a407ba2701dec2a7a06ffd",
    "references": [
        {
            "authors": [
                "Junwen Bai",
                "Shufeng Kong",
                "Carla P Gomes. Gaussian mixture variational autoencoder with contrastive learning for multi-label classification. In International Conference on Machine Learning"
            ],
            "title": "pages 1383\u2013 1398",
            "venue": "PMLR,",
            "year": 2022
        },
        {
            "authors": [
                "Bo Dai",
                "Dahua Lin. Contrastive learning for image captioning"
            ],
            "title": "Advances in Neural Information Processing Systems",
            "venue": "30,",
            "year": 2017
        },
        {
            "authors": [
                "Michael B Eisen",
                "Paul T Spellman",
                "Patrick O Brown",
                "David Botstein. Cluster analysis",
                "display of genome-wide expression patterns"
            ],
            "title": "Proceedings of the National Academy of Sciences",
            "venue": "95(25):14863\u2013 14868,",
            "year": 1998
        },
        {
            "authors": [
                "Yongbiao Gao",
                "Yu Zhang",
                "Xin Geng. Label enhancement for label distribution learning via prior knowledge"
            ],
            "title": "In Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence",
            "venue": "pages 3223\u20133229,",
            "year": 2021
        },
        {
            "authors": [
                "Yongbiao Gao",
                "Ke Wang",
                "Xin Geng"
            ],
            "title": "Sequential label enhancement",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Neamat El Gayar",
                "Friedhelm Schwenker",
                "G\u00fcnther Palm. A study of the robustness of knn classifiers trained using soft labels. In IAPR Workshop on Artificial Neural Networks in Pattern Recognition"
            ],
            "title": "pages 67\u201380",
            "venue": "Springer,",
            "year": 2006
        },
        {
            "authors": [
                "Xin Geng",
                "Chao Yin",
                "Zhi-Hua Zhou. Facial age estimation by learning from label distributions"
            ],
            "title": "IEEE transactions on pattern analysis and machine intelligence",
            "venue": "35(10):2401\u20132412,",
            "year": 2013
        },
        {
            "authors": [
                "Xin Geng. Label distribution learning"
            ],
            "title": "IEEE Transactions on Knowledge and Data Engineering",
            "venue": "28(7):1734\u20131748,",
            "year": 2016
        },
        {
            "authors": [
                "Eva Gibaja",
                "Sebasti\u00e1n Ventura"
            ],
            "title": "Multi-label learning: a review of the state of the art and ongoing research",
            "venue": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 4(6):411\u2013444,",
            "year": 2014
        },
        {
            "authors": [
                "Grill et al",
                "2020] Jean-Bastien Grill",
                "Florian Strub",
                "Florent Altch\u00e9",
                "Corentin Tallec",
                "Pierre Richemond",
                "Elena Buchatskaya",
                "Carl Doersch",
                "Bernardo Avila Pires",
                "Zhaohan Guo",
                "Mohammad Gheshlaghi Azar"
            ],
            "title": "Bootstrap your own latent-a new approach to self-supervised",
            "year": 2020
        },
        {
            "authors": [
                "Xiufeng Jiang",
                "Zhang Yi",
                "Jian Cheng Lv. Fuzzy svm with a new fuzzy membership function"
            ],
            "title": "Neural Computing & Applications",
            "venue": "15(3):268\u2013276,",
            "year": 2006
        },
        {
            "authors": [
                "Atsushi Kanehira",
                "Tatsuya Harada. Multi-label ranking from positive",
                "unlabeled data"
            ],
            "title": "In Proceedings of the IEEE conference on computer vision and pattern recognition",
            "venue": "pages 5138\u20135146,",
            "year": 2016
        },
        {
            "authors": [
                "Yu-Kun Li",
                "Min-Ling Zhang",
                "Xin Geng. Leveraging implicit relative labeling-importance information for effective multi-label learning"
            ],
            "title": "In 2015 IEEE International Conference on Data Mining",
            "venue": "pages 251\u2013260. IEEE,",
            "year": 2015
        },
        {
            "authors": [
                "Junnan Li",
                "Pan Zhou",
                "Caiming Xiong",
                "Steven CH Hoi"
            ],
            "title": "Prototypical contrastive learning of unsupervised representations",
            "venue": "arXiv preprint arXiv:2005.04966,",
            "year": 2020
        },
        {
            "authors": [
                "Yunfan Li",
                "Peng Hu",
                "Zitao Liu",
                "Dezhong Peng",
                "Joey Tianyi Zhou",
                "Xi Peng. Contrastive clustering. In Proceedings of the AAAI Conference on Artificial Intelligence"
            ],
            "title": "volume 35",
            "venue": "pages 8547\u20138555,",
            "year": 2021
        },
        {
            "authors": [
                "Michael Lyons",
                "Shigeru Akamatsu",
                "Miyuki Kamachi",
                "Jiro Gyoba. Coding facial expressions with gabor wavelets. In Proceedings Third IEEE international conference on automatic face",
                "gesture recognition"
            ],
            "title": "pages 200\u2013205",
            "venue": "IEEE,",
            "year": 1998
        },
        {
            "authors": [
                "Andrew L Maas",
                "Awni Y Hannun",
                "Andrew Y Ng"
            ],
            "title": "et al",
            "venue": "Rectifier nonlinearities improve neural network acoustic models. In Proc. icml, volume 30, page 3. Atlanta, Georgia, USA,",
            "year": 2013
        },
        {
            "authors": [
                "Jose M Moyano",
                "Eva L Gibaja",
                "Krzysztof J Cios",
                "Sebasti\u00e1n Ventura. An evolutionary approach to build ensembles of multi-label classifiers"
            ],
            "title": "Information Fusion",
            "venue": "50:168\u2013180,",
            "year": 2019
        },
        {
            "authors": [
                "Paszke et al",
                "2019] Adam Paszke",
                "Sam Gross",
                "Francisco Massa",
                "Adam Lerer",
                "James Bradbury",
                "Gregory Chanan",
                "Trevor Killeen",
                "Zeming Lin",
                "Natalia Gimelshein",
                "Luca Antiga"
            ],
            "title": "Pytorch: An imperative style, highperformance deep learning",
            "year": 2019
        },
        {
            "authors": [
                "Lei Qi",
                "Jiaying Shen",
                "Jiaqi Liu",
                "Yinghuan Shi",
                "Xin Geng"
            ],
            "title": "Label distribution learning for generalizable multi-source person re-identification",
            "venue": "arXiv preprint arXiv:2204.05903,",
            "year": 2022
        },
        {
            "authors": [
                "Qian et al",
                "2022] Shengsheng Qian",
                "Dizhan Xue",
                "Quan Fang",
                "Changsheng Xu"
            ],
            "title": "Integrating multi-label contrastive learning with dual adversarial graph neural networks for cross-modal retrieval",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Sebastian Ruder"
            ],
            "title": "An overview of gradient descent optimization algorithms",
            "venue": "arXiv preprint arXiv:1609.04747,",
            "year": 2016
        },
        {
            "authors": [
                "Haoyu Tang",
                "Jihua Zhu",
                "Qinghai Zheng",
                "Jun Wang",
                "Shanmin Pang",
                "Zhongyu Li. Label enhancement with sample correlations via low-rank representation. In Proceedings of the AAAI Conference on Artificial Intelligence"
            ],
            "title": "volume 34",
            "venue": "pages 5932\u20135939,",
            "year": 2020
        },
        {
            "authors": [
                "Ran Wang",
                "Xinyu Dai"
            ],
            "title": "et al",
            "venue": "Contrastive learning-enhanced nearest neighbor mechanism for multilabel text classification. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 672\u2013679,",
            "year": 2022
        },
        {
            "authors": [
                "Ning Xu",
                "Yun-Peng Liu",
                "Xin Geng. Label enhancement for label distribution learning"
            ],
            "title": "IEEE Transactions on Knowledge and Data Engineering",
            "venue": "33(4):1632\u20131643,",
            "year": 2019
        },
        {
            "authors": [
                "N. Xu, Y. Liu,",
                "X. Geng. Label enhancement for label distribution learning. IEEE Transactions on Knowledge",
                "Data Engineering"
            ],
            "title": "33(04):1632\u20131643",
            "venue": "apr",
            "year": 2021
        },
        {
            "authors": [
                "Ning Xu",
                "Jun Shu",
                "Renyi Zheng",
                "Xin Geng",
                "Deyu Meng",
                "Min-Ling Zhang. Variational label enhancement"
            ],
            "title": "IEEE Transactions on Pattern Analysis & Machine Intelligence",
            "venue": "(01):1\u201315,",
            "year": 2022
        },
        {
            "authors": [
                "Yan Yan",
                "Xu-Cheng Yin",
                "Chun Yang",
                "BoWen Zhang",
                "Hong-Wei Hao"
            ],
            "title": "Multi-label ranking with lstm2 for document classification",
            "venue": "Chinese Conference on Pattern Recognition, pages 349\u2013363. Springer,",
            "year": 2016
        },
        {
            "authors": [
                "Lijun Yin",
                "Xiaozhou Wei",
                "Yi Sun",
                "Jun Wang",
                "Matthew J Rosato"
            ],
            "title": "A 3d facial expression database for facial behavior research",
            "venue": "7th international conference on automatic face and gesture recognition (FGR06), pages 211\u2013216. IEEE,",
            "year": 2006
        },
        {
            "authors": [
                "Zhaoxiang Zhang",
                "Mo Wang",
                "Xin Geng. Crowd counting in public video surveillance by label distribution learning"
            ],
            "title": "Neurocomputing",
            "venue": "166:151\u2013163,",
            "year": 2015
        },
        {
            "authors": [
                "Shu Zhang",
                "Ran Xu",
                "Caiming Xiong",
                "Chetan Ramaiah"
            ],
            "title": "Use all the labels: A hierarchical multi-label contrastive learning framework",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16660\u201316669,",
            "year": 2022
        },
        {
            "authors": [
                "Zhao et al",
                "2022] Xingyu Zhao",
                "Yuexuan An",
                "Ning Xu",
                "Xin Geng"
            ],
            "title": "Fusion label enhancement for multi-label learning",
            "venue": "Lud De Raedt, editor, Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Qinghai Zheng",
                "Jihua Zhu",
                "Haoyu Tang",
                "Xinyuan Liu",
                "Zhongyu Li",
                "Huimin Lu"
            ],
            "title": "Generalized label enhancement with sample correlations",
            "venue": "IEEE Transactions on Knowledge and Data Engineering,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "In recent years, Label Distribution Learning (LDL) [Geng, 2016] has drawn much attention in machine learning, with its effectiveness demonstrated in various applications [Geng et al., 2013; Zhang et al., 2015; Qi et al., 2022]. Unlike single-label learning (SLL) and multi-label learning (MLL) [Gibaja and Ventura, 2014; Moyano et al., 2019; Zhao et al., 2022], LDL can provide information on how much each label describes a sample, which helps to deal with the problem of label ambiguity [Geng, 2016]. However, Obtaining label distributions is more challenging than logical labels, as it requires many annotators to manually indicate the degree to\n\u2217Corresponding author\nwhich each label describes an instance and accurately quantifying this degree remains difficult. Thus, [Xu et al., 2019] proposed Label Enhancement (LE), leveraging the topological information in the feature space and the correlation among the labels to recover label distributions from logical labels.\nMore specifically, LE can be seen as a preprocessing of LDL [Zheng et al., 2021], which takes the logically labeled datasets as inputs and outputs label distributions. As shown in Figure 1, this image reflects the complete information of the sample including some details. Meanwhile, its corresponding logical labels only highlight the most salient features, such as the sky, lake, mountain, and forest. Features contain comprehensive information about samples with many redundancies, while logical labels hold arresting information but are not allsided. Therefore, it is reasonable to assume that features and logical labels can be regarded as two descriptions of instances from different views, possessing complete and salient information of samples. The purpose of LE tasks can be simplified as enhancing the significant knowledge in logical labels by utilizing detailed features. Subsequently, each label is allocated a descriptive degree according to its importance.\nMost existing LE methods concentrate on establishing the mapping relationship between features and label distributions under the guidance of logical labels. Although these previous works have achieved good performance for LE problem, they neglect that features and labels are descriptions of two dif-\nar X\niv :2\n30 5.\n09 50\n0v 1\n[ cs\n.L G\n] 1\n6 M\nay 2\n02 3\nferent dimensions related to the same samples. Furthermore, logical labels can only indicate the conspicuous information of each sample without obtaining the label description ranking. The label distributions may appear to be quite different even if the logical labels present the same results.\nTo address these issues, we propose the ConLE method which fuses features and logic labels to generate the highlevel features of samples by contrastive learning strategy. More specifically, we elaborately train a representation learning model, which forces the features and logical labels of the same instance to be close in projection space, while those of different instances are farther away. By concatenating the representations of features and logical labels in projection space, we get high-level features including knowledge of logic labels and features. Accordingly, label distributions can be recovered from high-level features by the feature mapping network. Since it is expected that the properties of labels in the recovered label distributions should be consistent with those in the logical labels, we design a training strategy with label-level consistency to guide the learning of the feature mapping network.\nOur contributions can be delivered as follows:\n\u2022 Based on our analysis of label enhancement, we recognize that features and logical labels offer distinct perspectives on instances, with features providing comprehensive information and logical labels highlighting salient information. In order to leverage the intrinsic relevance between these two views, we propose the Contrastive Label Enhancement (ConLE) method, which unifies features and logical labels in a projection space to generate high-level features for label enhancement.\n\u2022 Since all possible labels should have similar properties in logical labels and label distributions, we design a training strategy to keep the consistency of label properties for the generation of label distributions. This strategy not only maintains the attributes of relevant and irrelevant labels but also minimizes the distance between logical labels and label distributions.\n\u2022 Extensive experiments are conducted on 13 benchmark datasets, experimental results validate the effectiveness and superiority of our ConLE compared with several state-of-the-art LE methods."
        },
        {
            "heading": "2 Related Work",
            "text": "In this section, we mainly introduce the related work of this paper from two research directions: label enhancement and contrastive learning.\nLabel Enhancement. Label enhancement is proposed to recover label distributions from logical labels and provide data preparation for LDL. For example, the Graph Laplacian LE (GLLE) method proposed by [Xu et al., 2021] makes the learned label distributions close to logical labels while accounting for learning label correlations, making similar samples have similar label distributions. The method LESC proposed by [Tang et al., 2020] uses low-rank representations to excavate the underlying information contained in the feature\nspace. [Xu et al., 2022] proposed LEVI to infer label distributions from logical labels via variational inference. The method RLLE formulates label enhancement as a dynamic decision process and uses prior knowledge to define the target for LE [Gao et al., 2021]. The kernel-based label enhancement (KM) algorithm maps each instance to a highdimensional space and uses a kernel function to calculate the distance between samples and the center of the group, in order to obtain the label description. [Jiang et al., 2006]. The LE algorithm based on label propagation (LP) recovers label distributions from logical labels by using the iterative label propagation technique [Li et al., 2015]. Sequential label enhancement (Seq LE) formulates the LE task as a sequential decision procedure, which is more consistent with the process of annotating the label distributions in human brains [Gao et al., 2022]. However, these works neglect the essential connection between features and logical labels. In this paper, we regard features and logical labels as sample descriptions from different views, where we can create faithful high-level features for label enhancement by integrating them into the unified projection space.\nContrastive Learning. The basic idea of contrastive learning, an excellent representation learning method, is to map the original data to a feature space. Within this space, the objective is to maximize the similarities among positive pairs while minimizing those among negative pairs. [Grill et al., 2020; Li et al., 2020]. Currently, contrastive learning has achieved good results in many machine learning domains [Li et al., 2021; Dai and Lin, 2017]. Here we primarily introduce several contrastive learning methods applied to multi-label learning. [Wang et al., 2022] designed a multi-label contrastive learning objective in the multi-label text classification task, which improves the retrieval process of their KNN-based method. [Zhang et al., 2022] present a hierarchical multilabel representation learning framework that can leverage all available labels and preserve the hierarchical relationship between classes. [Qian et al., 2022] propose two novel models to learn discriminative and modality-invariant representations for cross-modal retrieval. [Bai et al., 2022] propose a novel contrastive learning boosted multi-label prediction model based on a Gaussian mixture variational autoencoder (C-GMVAE), which learns a multimodal prior space and employs a contrastive loss. For ConLE, the descriptions of one identical sample are regarded as positive pairs and those of different samples are negative pairs. We pull positive pairs close and negative pairs farther away in projection space by contrastive learning to obtain good highlevel features, which is really beneficial for the LE process."
        },
        {
            "heading": "3 The ConLE Approach",
            "text": "In this paper, we use the following notations. The set of instances is denoted by X = {x1, x2, ..., xn} \u2208 Rdim1\u00d7n, where dim1 is the dimensionality of each instance and n is the number of instances. Y = {y1, y2, ..., yc} denotes the complete set of labels, where c is the number of classes. For an instance xi, its logical label is represented by Li = (ly1xi , l y2 xi , . . . , l yc xi )\nT, where lyjxi can only take values of 0 or 1. The label distribution for xi is denoted by\nDi = (d y1 xi , d y2 xi , . . . , d yc xi) T, where dyjxi depicts the degree to which xi belongs to label yj . It is worth noting that the sum of all label description degrees for xi is equal to 1. The purpose of LE tasks is to recover the label distribution Di of xi from the logical label Li and transform the logically labeled dataset S = {(xi, Li)|1 \u2264 i \u2264 n} into the LDL training set E = {(xi, Di)|1 \u2264 i \u2264 n}. The proposed Contrastive Label Enhancement (ConLE) in this paper contains two important components: the generation of high-level features by contrastive learning and the training strategy with label-level consistency for LE. Overall, the loss function of ConLE can be formulated as follows:\nLConLE = lcon + latt. (1)\nwhere lcon denotes the contrastive loss for high-level features, latt indicates the loss of training strategy with label-level consistency. The framework of ConLE and the detailed procedure of these two parts is shown in Figure 2."
        },
        {
            "heading": "3.1 The Generation of High-Level Features by Contrastive Learning",
            "text": "The first section provides a detailed analysis of the essence of LE tasks. We regard features and logic labels as two descriptions of samples. Features contain complete information, while logic labels capture prominent details. Label distributions show the description degree of each label. We can\u2019t simply focus on the salient information in logical labels, but\nmake good use of salient information and supplement the detailed information according to the original features. To effectively excavate the knowledge of features and logical labels, we adopt the contrastive learning of sample-level consistency.\nTo reduce the information loss induced by contrastive loss, we do not directly conduct contrastive learning on the feature matrix [Li et al., 2021]. Instead, we project the features (X) and logical labels (L) of all samples into a unified projection space via two mapping networks (F1(\u00b7; \u03b8),F2(\u00b7;\u03c6)), and then get the representations Z and Q. Specifically, the representations of features and logic labels in the projection space can be obtained by the following formula:\nZm = F1(xm; \u03b8), (2)\nQm = F2(Lm;\u03c6), (3)\nwhere xm and Lm represent the features and logical labels of the m-th sample, Zm and Qm denote their embedded representations in the dim2-dimensional space. \u03b8 and \u03c6 refer to the corresponding network parameters.\nContrastive learning aims to maximize the similarities of positive pairs while minimizing those of negative ones. In this paper, we construct positive and negative pairs at the instance level with Z and Q where {Zm, Qm} is positive pair and leave other (n \u2212 1) pairs to be negative. The cosine similarity is\nutilized to measure the closeness degree between pairs:\nh(Zm, Qm) = (Zm)(Qm)\nT\n||Zm|| ||Qm|| . (4)\nTo optimize pairwise similarities without losing their generality, the form of instance-level contrastive loss between Zm and Qm is defined as:\nlm = lZm + lQm , (5)\nwhere lZm denotes the contrastive loss for Zm and lQm indicates loss of Qm. Specifically, the item lZm is defined as:\nlZm = \u2212log e(h(Zm,Qm)/\u03c4I)\u2211n\ns=1,s6=m[e (h(Zm,Zs)/\u03c4I) + e(h(Zm,Qs)/\u03c4I)]\n,\n(6) and the item lQm is formulated as:\nlQm = \u2212log e(h(Qm,Zm)/\u03c4I)\u2211n\ns=1,s6=m[e (h(Qm,Qs)/\u03c4I) + e(h(Qm,Zs)/\u03c4I)]\n,\n(7) where \u03c4I is the instance-level temperature parameter to control the softness. Further, the instance-level contrastive loss is computed across all samples as:\nlcon = 1\nn\n\u2211n m=1lm. (8)\nThe expressions Z and Q updated by contrastive learning strategy will be concatenated as high-level features H , which are taken as inputs of the feature mapping network to learn the label distributions:\nH = concat(Z,Q). (9)"
        },
        {
            "heading": "3.2 The Training Strategy With Label-Level Consistency for LE",
            "text": "Based on the obtained high-level features, we introduce a feature mapping network F3 to generate label distributions. In other words, we have the following formula:\nDm = F3(Hm;\u03d5), (10)\nwhereDm is the recovered label distribution of the m-th sample andHm is the high-level feature, and \u03d5 denote the parameter of feature mapping network F3 .\nIn ConLE, we consider the consistency of label attributes in logical labels and label distributions. Firstly, because of recovered label distributions should be close to existing logical labels, we expect to minimize the distance between logical labels and the recovered label distributions, which is normalized by the softmax normalization form. This criterion can be defined as:\nldis = n\u2211 m=1 ||F3(Hm;\u03d5)\u2212 Lm||2, (11)\nwhereDm and Lm represents the recovered label distribution and logic label of the m-th sample. Moreover, logical labels divide all possible labels into relevant labels marked 1 and irrelevant labels marked 0 for each sample. We hope to ensure\nAlgorithm 1 The optimization of ConLE Input: Training instances X = {x1, x2, ..., xn}; Logical labels L = {L1, L2, ..., Ln}; Temperature parameter \u03c4I Output: label distributions D = {D1, D2, ..., Dn} 1: Random Initialize \u03b8, \u03c6 and \u03d5; 2: while not converged do 3: Obtain {Zm, Qm}nm=1 by Eq. (2) and Eq. (3); 4: Obtain the high-level features H by Eq. (9); 5: Obtain label distributions D by Eq. (10); 6: Optimize \u03b8, \u03c6, \u03d5 through Eq. (1); 7: end while 8: return D\nthat the attributes of relevant and irrelevant labels are consistent in label distributions and logical labels. This idea is considered in many multi-label learning methods [Kanehira and Harada, 2016; Yan et al., 2016]. Under their inspiration, we apply a threshold strategy to ensure that the description degree of relevant labels should be greater than that of irrelevant labels in the recovered label distributions. This strategy can be written as follows:\ndy + xm \u2212 d y\u2212 xm > 0 s.t. y+ \u2208 Pm, y\u2212 \u2208 Nm (12)\nwhere Pm is used to indicate the set of relevant labels in xm, Nm represents the set of irrelevant labels in xm, dy + xm and d y\u2212\nxm are the prediction results of LE process.\nIn this way, we can get the loss function of threshold strategy:\nlthr = 1\nn n\u2211 m=1 \u2211 y+\u2208Pm \u2211 y\u2212\u2208Nm [max(dy \u2212 xm\u2212d y+ xm + , 0)], (13)\nwhere is a hyperparameter that determines the threshold. The formula can be simplified to:\nlthr = 1\nn\n\u2211n m=1[max(max d y\u2212 xm \u2212min d y+ xm + , 0)], (14)\nFinally, the loss function of training strategy for label-level consistency can be formulated as follows:\nlatt = \u03bb1ldis + \u03bb2lthr, (15)\nwhere \u03bb1 and \u03bb1 are two trade-off parameters. This designed training strategy can guarantee that label attributes are the same in the logical labels and label distributions, thus obtaining a better feature mapping network to recover label distributions. The full optimization process of ConLE is summarized in Algorithm 1."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Datasets",
            "text": "We conduct comprehensive experiments on 13 real-world datasets to verify the effectiveness of our method. To be specific, SJAFFE dataset [Lyons et al., 1998] and SBU-3DFE dataset [Yin et al., 2006] are obtained from the two facial expression databases, JAFFE and BU-3DFE. Each image in\ndatasets is rated for six different emotions (i.e., happiness, sadness, surprise, fear, anger, and disgust) using 5-level scale. The Natural Scene dataset is collected from 2000 natural scene images. Dataset Movie is about the user rating for 7755 movies. Yeast datasets are derived from biological experiments on gene expression levels of budding yeast at different time points [Eisen et al., 1998]. The basic statistics of these datasets are shown in Table 1."
        },
        {
            "heading": "4.2 Evaluation Measures",
            "text": "The performance of the LE algorithm is usually calculated by distance or similarity between the recovered label distributions and the real label distributions. According to [Geng, 2016], we select six measures to evaluate the recovery performance, i.e., Kullback-Leibler divergence (K-L)\u2193, Chebyshev distance (Cheb)\u2193, Clark distance (Clark)\u2193, Canberra metric (Canber)\u2193, Cosine coefficient (Cosine)\u2191 and Intersection similarity (Intersec)\u2191. The first four are distance measures and the last two are similarity measures. The formulae for these six measures are summarized in Table 2."
        },
        {
            "heading": "4.3 Comparison Methods",
            "text": "We compare ConLE with six advanced LE methods, including FCM [Gayar et al., 2006], KM [Jiang et al., 2006], LP [Li et al., 2015], GLLE [Xu et al., 2021], LEVI-MLP [Xu et al., 2022] and LESC [Tang et al., 2020]. The following are the datails of comparison algorithms used in our experiments:\n1) FCM: This method makes use of membership degree to determine which cluster each instance belongs to according to fuzzy C-means clustering.\n2) KM: It is a kernel-based algorithm that uses the fuzzy SVM to get the radius and center, obtaining the membership degree as the final label distribution.\n3) LP: This approach applies label propagation (LP) in semi-supervised learning to label enhancement, employing graph models to construct a label propagation matrix and generate label distributions.\n4) GLLE: The algorithm recovers label distributions in the feature space guided by the topological information.\n5) LEVI-MLP: It regards label distributions as potential vectors and infers them from the logical labels in the training datasets by using variational inference.\n6) LESC: This method utilizes the low-rank representation to capture the global relationship of samples and predict implicit label correlation to achieve label enhancement."
        },
        {
            "heading": "4.4 Experimental Results",
            "text": "Implementation Details. In ConLE, we adopt the SGD optimizer [Ruder, 2016] for optimization and utilize the LeakyReLU activation function [Maas et al., 2013] to implement the networks. The code of this method is implemented by PyTorch [Paszke et al., 2019] on one NVIDIA Geforce GTX 2080ti GPU with 11GB memory. All experiments for our selected comparison algorithms follow the optimal settings mentioned in their papers and we run the programs using the code provided by their relevant authors. All algorithms are evaluated by ten times ten-fold cross-validation for fairness. When comparing with other algorithms, the hyperparameters of ConLE are set as follows: \u03bb1 is set to 0.5, \u03bb2 is set to 1 and the temperature parameter \u03c4I is 0.5.\nRecovery Performance. The detailed comparison results are presented in Table 3, with the best performance on each dataset highlighted in bold. For each evaluation metric, \u2193 shows the smaller the better while \u2191 shows the larger the better. The average rankings of each algorithm across all the datasets are shown in the last row of each table.\nThe experimental results clearly indicate that our ConLE method exhibits superior recovery performance compared to the other six advanced LE algorithms. Specifically, ConLE can achieve the ranking of 1.00, 1.23, 1.00, 1.07, 1.15 and 1.00 respectively for the six evaluation metrics. ConLE obtains excellent performance both on large-scale datasets such as movie and small-scale datasets such as SJAFFE. ConLE can attain significant improvements both in comparison with algorithm adaption and specialized algorithms by exploring the description consistency of features and logical labels in the same sample. We integrate features and logical labels into the unified projection space to generate high-level features\nand keep the consistency of label attributes in the process of label enhancement.\nAblation Studies. Our ConLE method consists of two main components: generating high-level features by contrastive learning and a training strategy with label-level consistency for LE. Ablation studies are conducted to verify the effectiveness of the two modules in our method.\nTherefore, we first remove the part of ConLE that generates high-level features and get a comparison algorithm ConLEh, whose loss function can be written as:\nLConLEh = \u03bb1ldis + \u03bb2lthr, (16)\nIn ConLEh, we only explore the consistency information of label attributes without considering the description consistency of features and labels.\nSecondly, we need to remove the strategy that ensures the consistency of label attributes. To ensure the normal training process, we still keep the strategy of minimizing the distance between label distributions and logical labels. The loss func-\ntion of the comparison function ConLEl: LConLEl = \u03bb1ldis + lcon. (17)\nTable 4 provides the recovery results of ConLEh, ConLEl and ConLE. Due to the limitation of space, only the representative results measured on Kullback-Leibler, Clark, Canberra and Intersection are shown in the table. From the experimental results, we can observe that ConLE is superior to ConLEh and ConLEl in all cases. Compared with ConLEh, ConLE considers the inherent relationship between features and logical labels. It grasps the description consistency of samples and constructs high-level features for training. Compared with ConLEl, ConLE considers label-level consistency of logical labels and label distributions. It makes that each relevant label in the logical labels has a greater description degree in the label distributions. Therefore, our experimental results have verified that both modules of ConLE play essential roles in achieving excellent recovery performance. The integration of these modules in the complete ConLE method has been demonstrated to be highly effective.\nParameters Sensitivity. To investigate the sensitivity of ConLE to hyperparameters, we performed experiments on SBU-3DFE with different values of the two trade-off hyperparameters \u03bb1 and \u03bb2. In this experiment, we fix one hyperparameter and choose another hyperparameter from {0.1, 0.3,\n0.5, 0.8 ,1, 5, 10}. As shown in Figure 3, we can observe that the ConLE method can obtain satisfactory recovery results and our model is insensitive to \u03bb1 and \u03bb2.\nConvergence Analysis. To illustrate the convergence of ConLE, we present an experiment conducted on Movie dataset by Canberra\u2193 as an example, with the corresponding convergence curve depicted in Figure 4. The value of the objective function decreases and the performance increases with more iterations. Finally, they tend to be stable. The properties remain the same for all datasets."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this work, we propose Contrastive Label Enhancement (ConLE), a novel method to cope with the (Label Enhancement) LE problem. ConLE regards features and logic labels as descriptions from different views, and then elegantly integrates them to generate high-level features by contrastive learning. Additionally, ConLE employs a training strategy that considers the consistency of label attributes to estimate the label distributions from high-level features. Experimental results on 13 datasets demonstrate its superior performance\nover other state-of-the-art methods."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was supported by the National Key R&D Program of China under Grant 2020AAA0109602."
        }
    ],
    "title": "Contrastive Label Enhancement",
    "year": 2023
}