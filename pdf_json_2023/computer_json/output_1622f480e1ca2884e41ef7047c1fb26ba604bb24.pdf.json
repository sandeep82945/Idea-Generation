{
    "abstractText": "Obesity and laziness are some of the common issues in the majority of the youth today. This has led to the development of a proposed exergaming solution where users can play first-person physical games. This research study not only proposes a solution for physical fitness in the form of a game using wearable sensors but also proposes a multi-purpose system that provides different applications when trained for the domain-specific dataset. Critical tasks of gesture recognition and depiction in virtual reality can be applied to many applications in the domains of crime detection, fitness, healthcare, online learning, and sports. In particular, the proposed system enables a user to perform, detect, and depict different gestures in the virtual reality game. First, the system pre-processes input data by applying a median filter to overcome the anomalies. Then, features are extracted through a convolutional neural network, power spectral density, skewness, and kurtosis methods. Further, the system optimizes different features by using the grey wolf optimization. Lastly, the feature set which is optimized is fed to a recurrent neural network for classification. When Compared to the traditional methods, the suggested system gives better results while being easier to use. The IMSporting behaviors (IMSB) dataset includes badminton and other physical activities, the WISDM dataset includes common locomotor motions, and the ERICA dataset which includes a variety of exercises, were used in the experimentation. According to experimental findings, the suggested approach outperformed current methods, which showed detection accuracies of 85.01%, 88.46%, and 93.18% over the IMSB, WISDM, and ERICA datasets, respectively. INDEX TERMS Convolution neural network, exergaming, grey wolf optimization, recurrent neural network, virtual reality, wearable sensors.",
    "authors": [
        {
            "affiliations": [],
            "name": "MIR MUSHHOOD AFSAR"
        },
        {
            "affiliations": [],
            "name": "SHIZZA SAQIB"
        },
        {
            "affiliations": [],
            "name": "MOHAMMAD ALADFAJ"
        },
        {
            "affiliations": [],
            "name": "MOHAMMED HAMAD ALATIYYAH"
        },
        {
            "affiliations": [],
            "name": "KHALED ALNOWAISER"
        },
        {
            "affiliations": [],
            "name": "HANAN ALJUAID"
        },
        {
            "affiliations": [],
            "name": "JEONGMIN PARK"
        }
    ],
    "id": "SP:6cad324e1b218ac77d2f61387c30973631d0df5e",
    "references": [
        {
            "authors": [
                "Z. Belyaeva",
                "A. Petrosyan",
                "S.M.R. Shams"
            ],
            "title": "Stakeholder data analysis in the video gaming industry: Implications for regional development",
            "venue": "EuroMed J. Bus., vol. 17, no. 3, pp. 333\u2013349, Aug. 2022, doi: 10.1108/EMJB-10-2021-0150.",
            "year": 2022
        },
        {
            "authors": [
                "E. Zamani"
            ],
            "title": "Effect of addiction to computer games on physical and mental health of female and male students of guidance school in city of Isfahan",
            "venue": "Addiction Health, vol. 1, no. 2, pp. 98\u2013104, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "S.A. Bowman"
            ],
            "title": "Television-viewing characteristics of adults: Correlations to eating practices and overweight and health status",
            "venue": "Preventing Chronic Disease, vol. 3, pp. 1\u201311, Jan. 2006.",
            "year": 2006
        },
        {
            "authors": [
                "B. Poetker"
            ],
            "title": "The very real history of virtual reality (+A look ahead)",
            "venue": "Vis. Coupled Airborne Syst., USA, Tech. Rep. re:2019, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "O. Ouyed",
                "M.A. Said"
            ],
            "title": "Group-of-features relevance in multinomial kernel logistic regression and application to human interaction recognition",
            "venue": "Exp. Syst. Appl., vol. 148, Jun. 2020, Art. no. 113247.",
            "year": 2020
        },
        {
            "authors": [
                "G. Tao",
                "B. Garrett",
                "T. Taverner",
                "E. Cordingley",
                "C. Sun"
            ],
            "title": "Immersive virtual reality health games: A narrative review of game design",
            "venue": "J. NeuroEng. Rehabil., vol. 18, no. 1, pp. 1\u201321, Dec. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "L. Jones"
            ],
            "title": "VR and. . . better healthcare",
            "venue": "Eng. Technol., vol. 11, no. 3, pp. 36\u201339, Apr. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "P. Zikas",
                "S. Kateros",
                "P. Margarita"
            ],
            "title": "Mixed reality serious games and gamification for smart education",
            "venue": "Proc. Eur. Conf. Games Based Learn., 2016, pp. 805\u2013812.",
            "year": 2016
        },
        {
            "authors": [
                "M. Yates",
                "A. Kelemen",
                "C.S. Lanyi"
            ],
            "title": "Virtual reality gaming in the rehabilitation of the upper extremities post-stroke",
            "venue": "Brain Injury, vol. 30, no. 7, pp. 855\u2013863, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "I. Paraskevopoulos",
                "E. Tsekleves"
            ],
            "title": "Use of gaming sensors and customised exergames for parkinson\u2019s disease rehabilitation: A proposed virtual reality framework",
            "venue": "Proc. 5th Int. Conf. Games Virtual Worlds Serious Appl. (VS-GAMES), Sep. 2013, pp. 1\u20135.",
            "year": 2013
        },
        {
            "authors": [
                "D. Fitzgerald",
                "J. Foody",
                "D. Kelly",
                "T. Ward",
                "C. Markham",
                "J. McDonald",
                "B. Caulfield"
            ],
            "title": "Development of a wearable motion capture suit and virtual reality biofeedback system for the instruction and analysis of sports rehabilitation exercises",
            "venue": "Proc. 29th Annu. Int. Conf. IEEE Eng. Med. Biol. Soc., Aug. 2007, pp. 4870\u20134874.",
            "year": 2007
        },
        {
            "authors": [
                "I.F. Mondrag\u00f3n Bernal",
                "N.E. Lozano-Ram\u00edrez",
                "J.M. Puerto Cort\u00e9s",
                "S. Valdivia",
                "R. Mu\u00f1oz",
                "J. Arag\u00f3n",
                "R. Garc\u00eda",
                "G. Hern\u00e1ndez"
            ],
            "title": "An immersive virtual reality training game for power substations evaluated in terms of usability and engagement",
            "venue": "Appl. Sci., vol. 12, no. 2, p. 711, Jan. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "M. Ma",
                "L. Jain",
                "P. Anderson"
            ],
            "title": "Healthcare training enhancement through virtual reality and serious games",
            "venue": "Virtual, Augmented Reality Serious Games Healthcare, vol. 68, pp. 9\u201327, Jan. 2014.",
            "year": 2014
        },
        {
            "authors": [
                "M.H. Abidi",
                "A. Ahmad",
                "S. Darmoul",
                "A.M. Al-Ahmari"
            ],
            "title": "Haptics assisted virtual assembly",
            "venue": "IFAC-PapersOnLine, vol. 48, no. 3, pp. 100\u2013105, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "K. Gerling",
                "P. Dickinson",
                "K. Hicks",
                "L. Mason",
                "A.L. Simeone",
                "K. Spiel"
            ],
            "title": "Virtual reality games for people using wheelchairs",
            "venue": "Proc. CHI Conf. Hum. Factors Comput. Syst., New York, NY, USA, Apr. 2020, pp. 1\u201311.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Xu",
                "M. Tong",
                "W.-K. Ming",
                "Y. Lin",
                "W. Mai",
                "W. Huang",
                "Z. Chen"
            ],
            "title": "A depth camera\u2013based, task-specific virtual reality rehabilitation game for patients with stroke: Pilot usability study",
            "venue": "JMIR Serious Games, vol. 9, no. 1, Mar. 2021, Art. no. e20916.",
            "year": 2021
        },
        {
            "authors": [
                "S. Park",
                "H. Aan",
                "J. Jo",
                "H. Kim",
                "S. Han",
                "J. Kim",
                "P. Yoon",
                "K. Kim"
            ],
            "title": "A-visor and A-camera: Arduino-based cardboard head-mounted controllers for VR games",
            "venue": "Proc. IEEE Conf. Virtual Reality 3D User Int. Abstr. Workshops (VRW), Atlanta, GA, USA, Mar. 2021, pp. 434\u2013435.",
            "year": 2021
        },
        {
            "authors": [
                "M.H. Abidi",
                "A. Al-Ahmari",
                "A. Ahmad",
                "W. Ameen",
                "H. Alkhalefah"
            ],
            "title": "Assessment of virtual reality-based manufacturing assembly training system",
            "venue": "Int. J. Adv. Manuf. Technol., vol. 105, no. 9, pp. 3743\u20133759, Dec. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M.H. Abidi",
                "A.M.E. Tamimi",
                "A.M.A. Ahmari",
                "E.S.A. Nasr"
            ],
            "title": "Assessment and comparison of immersive virtual assembly training system",
            "venue": "Int. J. Rapid Manuf., vol. 3, no. 4, p. 266, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "A. Al-Ahmari",
                "M. Abidi",
                "A. Ahmad",
                "S. Darmoul"
            ],
            "title": "Development of a virtual manufacturing assembly simulation system",
            "venue": "Adv. Mech. Eng., vol. 8, no. 3, pp. 1\u201317, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "S. Tang",
                "S. Yuan",
                "Y. Zhu"
            ],
            "title": "Data preprocessing techniques in convolutional neural network based on fault diagnosis towards rotating machinery",
            "venue": "IEEE Access, vol. 8, pp. 149487\u2013149496, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A. Famili",
                "W.-M. Shen",
                "R. Weber",
                "E. Simoudis"
            ],
            "title": "Data preprocessing and intelligent data analysis",
            "venue": "Intell. Data Anal., vol. 1, no. 1, pp. 3\u201323, 1997.",
            "year": 1997
        },
        {
            "authors": [
                "S. Tripathy",
                "T. Swarnkar"
            ],
            "title": "Performance observation of mammograms using an improved dynamic window based adaptive median filter",
            "venue": "J. Discrete Math. Sci. Cryptogr., vol. 23, no. 1, pp. 167\u2013175, Jan. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "D. Varshni",
                "K. Thakral",
                "L. Agarwal",
                "R. Nijhawan",
                "A. Mittal"
            ],
            "title": "Pneumonia detection using CNN based feature extraction",
            "venue": "Proc. IEEE Int. Conf. Electr., Comput. Commun. Technol. (ICECCT), Feb. 2019, pp. 1\u20137.",
            "year": 2019
        },
        {
            "authors": [
                "X. Shao",
                "C.-S. Kim",
                "P. Sontakke"
            ],
            "title": "Accurate deep model for electricity consumption forecasting using multi-channel and multi-scale feature fusion CNN\u2013LSTM",
            "venue": "Energies, vol. 13, no. 8, p. 1881, Apr. 2020.",
            "year": 1881
        },
        {
            "authors": [
                "H. Nassuna",
                "O.S. Eyobu",
                "J.-H. Kim",
                "D. Lee"
            ],
            "title": "Feature selection based on variance distribution of power spectral density for driving behavior recognition",
            "venue": "Proc. 14th IEEE Conf. Ind. Electron. Appl. (ICIEA), Jun. 2019, pp. 335\u2013338. VOLUME 11, 2023 12471 M. M. Afsar et al.: Body-Worn Sensors for Recognizing Physical Sports Activities in Exergaming via Deep Learning Model",
            "year": 2019
        },
        {
            "authors": [
                "J. Chen",
                "J. Wang",
                "J.M.W. Brownjohn"
            ],
            "title": "Power spectral-density model for pedestrian walking load",
            "venue": "J. Structural Eng., vol. 145, no. 2, Feb. 2019, Art. no. 04018239.",
            "year": 2019
        },
        {
            "authors": [
                "A. Koduru",
                "H.B. Valiveti",
                "andA.K. Budati"
            ],
            "title": "Feature extraction algorithms to improve the speech emotion recognition rate",
            "venue": "Int. J. Speech Technol., vol. 23, no. 1, pp. 45\u201355, Mar. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "D. Trafimow",
                "T. Wang",
                "C. Wang"
            ],
            "title": "From a sampling precision perspective, skewness is a friend and not an enemy!\u2019",
            "venue": "Educ. Psychol. Meas., vol. 79,",
            "year": 2019
        },
        {
            "authors": [
                "A.K. Alanazi"
            ],
            "title": "Application of neural network and time-domain feature extraction techniques for determining, volumetric percentages and the type of two phase flow regimes independent of scale layer thickness,\u2019\u2019Appl",
            "venue": "Sci., vol. 12,",
            "year": 2022
        },
        {
            "authors": [
                "M. Altaf",
                "T. Akram",
                "M.A. Khan",
                "M. Iqbal",
                "M.M.I. Ch",
                "C.-H. Hsu"
            ],
            "title": "A new statistical features based approach for bearing fault diagnosis using vibration signals",
            "venue": "Sensors, vol. 22, no. 5, p. 2012, Mar. 2022.",
            "year": 2012
        },
        {
            "authors": [
                "T.M. Ghazal",
                "N. Taleb"
            ],
            "title": "Feature optimization and identification of ovarian cancer using internet of medical things",
            "venue": "Exp. Syst., vol. 39, no. 9, p. e12987, Nov. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "K. Asghari",
                "M. Masdari",
                "F.S. Gharehchopogh",
                "R. Saneifard"
            ],
            "title": "A chaotic and hybrid gray wolf-whale algorithm for solving continuous optimization problems",
            "venue": "Prog. Artif. Intell., vol. 10, no. 3, pp. 349\u2013374, Sep. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "E. Krishna",
                "V. Institute of Technology",
                "T. Arunkumar",
                "V. Institute of Technology"
            ],
            "title": "Hybrid particle swarm and gray wolf optimization algorithm for IoT intrusion detection system",
            "venue": "Int. J. Intell. Eng. Syst., vol. 14, no. 4, pp. 66\u201376, Aug. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "H. Singh Gill",
                "O.I. Khalaf",
                "Y. Alotaibi",
                "S. Alghamdi",
                "F. Alassery"
            ],
            "title": "Multi-model CNN-RNN-LSTM based fruit recognition and classification",
            "venue": "Intell. Autom. Soft Comput., vol. 33, no. 1, pp. 637\u2013650, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "J.A. Nasir",
                "O.S. Khan",
                "I. Varlamis"
            ],
            "title": "Fake news detection: A hybrid CNN-RNN based deep learning approach",
            "venue": "Int. J. Inf. Manag. Data Insights, vol. 1, no. 1, Apr. 2021, Art. no. 100007.",
            "year": 2021
        },
        {
            "authors": [
                "J. Yan",
                "L. Jin",
                "Z. Yuan",
                "Z. Liu"
            ],
            "title": "RNN for receding horizon control of redundant robot manipulators",
            "venue": "IEEE Trans. Ind. Electron., vol. 69, no. 2, pp. 1608\u20131619, Feb. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "A. Jalal",
                "M.A.K. Quaid",
                "A.S. Hasan"
            ],
            "title": "Wearable sensor-based human behavior understanding and recognition in daily life for smart environments",
            "venue": "Proc. Int. Conf. Frontiers Inf. Technol. (FIT), Dec. 2018, pp. 105\u2013110, doi: 10.1109/FIT.2018.00026.",
            "year": 2018
        },
        {
            "authors": [
                "A. Jalal",
                "M.A.K. Quaid",
                "andM.A. Sidduqi"
            ],
            "title": "A triaxial acceleration-based human motion detection for ambient smart home system",
            "venue": "Proc. 16th Int. Bhurban Conf. Appl. Sci. Technol. (IBCAST), Jan. 2019, pp. 353\u2013358.",
            "year": 2019
        },
        {
            "authors": [
                "S.K. Challa",
                "A. Kumar",
                "V.B. Semwal"
            ],
            "title": "Amultibranch CNN-BILSTM model for human activity recognition using wearable sensor data",
            "venue": "Vis. Comput., vol. 38, pp. 4095\u20134109, Aug. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "M. Radhakrishnan",
                "D. Rathnayake",
                "O.K. Han",
                "I. Hwang",
                "A. Misra"
            ],
            "title": "ERICA: Enabling real-time mistake detection & corrective feedback for free-weights exercises",
            "venue": "Proc. 18th Conf. Embedded Networked Sensor Syst. New York, NY, USA: Association for Computing Machinery, 2020, pp. 558\u2013571.",
            "year": 2020
        },
        {
            "authors": [
                "F.N. Nezami",
                "M.A.W\u00e4chter",
                "N.Maleki",
                "P. Spaniol",
                "L.M. Kuhne",
                "A. Haas",
                "J.M. Pingel",
                "L. Tiemann",
                "F. Nienhaus",
                "L. Keller",
                "S.U. K\u00f6nig",
                "P. K\u00f6nig",
                "G. Pipa"
            ],
            "title": "Westdrive X LoopAR: An open-access virtual reality project in unity for evaluating user interaction methods during takeover requests",
            "venue": "Sensors, vol. 21, no. 5, p. 1879, Mar. 2021.",
            "year": 1879
        },
        {
            "authors": [
                "Y. Peng",
                "J. Chung",
                "Q. Cao",
                "Y. Cai"
            ],
            "title": "Design of a virtual home for special needs children to learn life skills",
            "venue": "inWhen VR Serious GamesMeet Special Needs Education. Berlin, Germany: Springer, 2021, pp. 31\u201361.",
            "year": 2021
        },
        {
            "authors": [
                "A. Luque",
                "A. Carrasco",
                "A. Martin",
                "A. De Las Heras"
            ],
            "title": "The impact of class imbalance in classification performance metrics based on the binary confusion matrix",
            "venue": "Pattern Recognit., vol. 91, pp. 216\u2013231, Oct. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "N. Tatbul",
                "T.J. Lee",
                "S. Zdonik",
                "M. Alam",
                "J. Gottschlich"
            ],
            "title": "Precision and recall for time series",
            "venue": "Proc. Adv. Neural Inf. Process. Syst., 2018, pp. 1\u201311.",
            "year": 2018
        },
        {
            "authors": [
                "S.B. Tahir",
                "A. Jalal",
                "K. Kim"
            ],
            "title": "Wearable inertial sensors for daily activity analysis based on Adam optimization and the maximum entropy Markov model",
            "venue": "Entropy, vol. 22, no. 5, p. 579, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S.B.U.D. Tahir",
                "A. Jalal",
                "M. Batool"
            ],
            "title": "Wearable sensors for activity analysis using SMO-based random forest over smart home and sports datasets",
            "venue": "Proc. 3rd Int. Conf. Advancements Comput. Sci. (ICACS), Feb. 2020, pp. 1\u20136.",
            "year": 2020
        },
        {
            "authors": [
                "S.B.U.D. Tahir",
                "A. Jalal",
                "K. Kim"
            ],
            "title": "Daily life log recognition based on automatic features for health care physical exercise via IMU sensors",
            "venue": "Proc. Int. Bhurban Conf. Appl. Sci. Technol. (IBCAST), Jan. 2021, pp. 494\u2013499.",
            "year": 2021
        },
        {
            "authors": [
                "S.F. Idowu",
                "A. Selamat",
                "R. Ibrahim"
            ],
            "title": "Performance evaluation of classifiers on activity recognition for disasters mitigation using smartphone sensing",
            "venue": "Jurnal Teknologi, vol. 77, no. 13, Nov. 2015.",
            "year": 2015
        },
        {
            "authors": [
                "K. Takahashi",
                "K. Yamamoto",
                "A. Kuchiba",
                "T. Koyama"
            ],
            "title": "Confidence interval for micro-averaged F1 and macro-averaged F1 scores",
            "venue": "Int. J. Speech Technol., vol. 52, no. 5, pp. 4961\u20134972, Mar. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "M. Batool",
                "A. Jalal",
                "K. Kim"
            ],
            "title": "Telemonitoring of daily activity using accelerometer and gyroscope in smart home environments",
            "venue": "J. Electr. Eng. Technol., vol. 15, no. 6, pp. 2801\u20132809, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "W. Ahmad",
                "B.M. Kazmi",
                "H. Ali"
            ],
            "title": "Human activity recognition using multi-head CNN followed by LSTM",
            "venue": "Proc. 15th Int. Conf. Emerg. Technol. (ICET), Dec. 2019, pp. 1\u20136.",
            "year": 2019
        },
        {
            "authors": [
                "K.H.Walse",
                "R.V. Dharaskar",
                "V.M. Thakare"
            ],
            "title": "Performance evaluation of classifiers on WISDM dataset for human activity recognition",
            "venue": "Proc. 2nd Int. Conf. Inf. Commun. Technol. Competitive Strategies, Mar. 2016, pp. 1\u20137.",
            "year": 2016
        },
        {
            "authors": [
                "B. Zhou",
                "M. Sundholm",
                "J. Cheng",
                "H. Cruz",
                "P. Lukowicz"
            ],
            "title": "Never skip leg day: A novel wearable approach to monitoring gym leg exercises",
            "venue": "Proc. IEEE Int. Conf. Pervasive Comput. Commun. (PerCom), Mar. 2016, pp. 1\u20139.",
            "year": 2016
        }
    ],
    "sections": [
        {
            "text": "INDEX TERMS Convolution neural network, exergaming, grey wolf optimization, recurrent neural network, virtual reality, wearable sensors.\nI. INTRODUCTION According to global statistics, the gaming sector is now the one that is expanding the quickest globally. The gaming\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Alberto Cano .\nindustry, which was estimated to be worth \u2018\u2018$179.7 billion\u2019\u2019 in 2021, is predicted to increase at a \u2018\u2018CAGR of 8.94%\u2019\u2019 from 2022 to 2027 and reach a value of $339.95 billion. [1]. Playing games using a mouse and keyboard is old-fashioned, and the need for a new methodology for playing games is essential to further expand this billion-dollar industry.\n12460 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 11, 2023\nApart from that, studies have revealed that people with more screen time are prone to become obese, lazy, sleepless, and tired [2]. Generally, sleeplessness can cause anxiety, mental disorders, and anger issues in adults. Most of these adults have no physical activities, and they are addicted to gaming, which causes a lot of rash effects on their behavior and their bodies [3]. Researchers have been trying to find new ways to make games less harmful andmore useful in areas like health, education, sports, and the military. This is because games are used by a lot of people and can have negative effects on them.\nMorton Heilig created the first virtual system in 1957 and gave rise to the concept of virtual reality (VR). The proposed gadget was known as sensorama, but later, in 1987, researcher Jaron Lanier came up with the phrase \u2018\u2018virtual reality\u2019\u2019 [4]. VR headsets are now too expensive for the general public to use. Oculus Go, for instance, has the highest pricing at $545. The Oculus headgear may be purchased for as low as $249 [5]. There are some systems similar to Meta Quest 2, HTCVive Pro 2, Sony PlayStation VR, andWii Nintendo that provides similar and amazing experiences to their users, but they are quite costly. Apart from that these VR devices have long wires attached to computers which restrict users from moving freely in the space around them. There is no gesture recognition system inside these systems. They can only be used for a single purpose at a time. Powerful computing machines are required for generating VR views, and VR illusions and the controllers for playing games only work after buttons on the controllers are pressed. Some VR headsets have cameras that continuously detect the controller movements, and, in this way, they performed an action. In such a system it is common to witness action delay, speed issues, and gesture accuracy issues. Apart from these issues, there is also a configuration issue that is common in almost all VR headsets i.e., login, signup, and connectivity-related issues. Hence, a novel, more efficient, wireless, cost-effective, and the sensors-based wearable system is suggested in order to make a difference. It will help youngsters having obesity and other related issues by encouraging the use of physical exercise in them.\n1) The proposed approach is multi-purpose and not only limited to gaming, but it can also be used in other domains such as fitness, robotics, drones, sports, and e-learning. 2) It connects VR and human physical health through playing games in an indoor environment. 3) The systemwill also enhance the trend of old-fashioned games by introducing a sensors-based wearable device that can control gaming objects precisely through accelerometer data generated from human body gestures. 4) The system makes a unique virtual reality experience by using inertial sensors, and it is both affordable and user-friendly. 5) The system removes the wires and the need for powerful computers. Instead, the wireless approach is\ndesigned for playing exergames in a virtual reality headset using wearable sensors. 6) To anticipate the values, an accurate recurrent neural network (RNN) classifier is utilized.\nThe proposed approach uses 6 DOF (degrees of freedom) inertial sensors to measure acceleration. This data will be transferred via a transmitter to the computer, where a pretrained deep-learning model will test via an RNN classifier. Finally, the gaming behavior will be predicted, and the appropriate interface will be loaded into the game. The sensor data controls the avatar gestures and sends the realtime gesture data to a pre-trained model. The motions and activity recognition may be shown over the personal computer (PC) at the same time as the user watches in their VR headset.\nNumerous head-mounted displays for VR (HMD-VR) exergames are being utilized widely for rehabilitation and to aid the recovery of patients [6]. In addition, VR games have several uses in the medical field, such as preventative health and well-being along with medical evaluations in clinical treatments [7]. VR gaming has a wide range of educational uses as well. The use of games in a classroom increases students\u2019 engagement and motivation, whereas first-person VR game usage will keep students active and healthy while having fun [8]. There has been a resurgence in the research related to delivering therapy using VR gaming systems. VR games offer potential in the treatment of numerous ailments, including post-stroke, Parkinson\u2019s disease, and others [9].\nThe following are our system\u2019s significant contributions:\n\u2022 Our suggested system provides a cost-effective solution to very serious issues like childhood obesity and other health-related problems. \u2022 Similar systems exist in the realm of VR, but they are exceedingly expensive and out of the reach of the common man. As a result, the suggested method creates a product that allows individuals to keep in shape while playing games in an indoor environment. \u2022 Our hardware-based system is being developed and tested. Therefore, it is a reliable solution for physical health and other applications. \u2022 To make our system efficient and affordable, we are incorporating a straightforward and inexpensive VR device. \u2022 The system outperformed other alreadymade approaches in terms of accuracy rates.\nThe remaining article is structured as follows: Section II looks at similar research in the area of VR sports action detection using sensors and cameras. The suggested technique is thoroughly explained in Section III. The many datasets that were utilized to verify the effectiveness of the suggested strategy and the outcomes of those tests are described in Section IV. The paper\u2019s concluding part and goals for the future are included in Section V.\nVOLUME 11, 2023 12461\nII. RELATED WORKs For deep learning and machine learning-based systems employing a range of sensors, including inertial measurement units (IMU), cameras, and other fused sensors, several methodologies have been proposed by numerous academics. This section reviews the research on camera-based and wearable sensors-based systems.\nA. VIRTUAL REALITY EXERGAMING WITH WEARABLE SENSORS Virtual reality games and sensors have been utilized in several applications in recent years. I. Paraskevopoulos and E. Tsekleves suggested a system in [10] that incorporated motion capture technology that was more affordable, flexible, and off-the-shelf with video games that were specially designed to meet the needs of Parkinson\u2019s Disease (PD) rehabilitation. However, they used larger controllers for the game, and D. Fitzgerald et al. developed a computer game for VR in order to lead an athlete through several advised rehabilitation activities [11].\nIn an effort to enhance physical performance while avoiding or treating musculoskeletal disorders, certified professionals have prescribed training programs to athletes. With the use of serious games and virtual environments, Mondrag\u00f3n Bernal et al. developed and assessed a system for teaching power distribution operation. Building information modelling from a \u2018\u2018115 kV\u2019\u2019 substation was utilised to create a scenario with high technical details suited for professional training in the VR simulator. [12].\nImmersive 3D virtual worlds and serious games, or video games meant to be educational, are both growing in popularity. Serious games have just lately been tested for healthcare education. Following a review of educational philosophies highlighting the importance of serious games and virtual simulations as teaching aids, Ma et al. examined various instances of early teaching models and evaluated procedures in their study [13]. They further made recommendations for how to assess their worth in a learning environment.\nVR technologies are gaining popularity as a way to model, evaluate, and improve the assembly process. Abidi et al. discussed the development of a \u2018\u2018haptic virtual reality platform\u2019\u2019 for virtual assembly planning, execution, and evaluation. The technology enables real-time handling and interaction with virtual components. To examine the advantages and disadvantages of combining haptics with physical-basedmodeling, the system consists of several software programs including Open Haptics, PhysX, and OpenGL/GLUT libraries [14].\nB. VIRTUAL REALITY EXERGAMING WITH CAMERA Researchers have used a variety of approaches while employing camera-orientedVR systems. To put handicapped persons at ease, Gerling et al. [15] devised a system that employed the \u2018\u2018Kinect v2 depth camera\u2019\u2019 to evaluate the movement of wheelchair and created two Unity VR games. The study\u2019s findings were highly encouraging since an immersive\nVR experience for persons with disabilities proved to be a wonderful experience for them.\nStomp Joy was a camera based VR game which was specific to one task which was rehabilitation after lower limbs stroke developed by Xu et al. [16]. Sangmin et al. [17] created a VR game in Unity for the A-Camera and A-Visor. They displayed cutting-edge head-mounted virtual reality controllers that enthusiasts could easily construct for themselves using corrugated cardboard, an Arduino, and sensors.\nAnother study expands the use of VR in manufacturing by incorporating ideas and research from training simulations into the evaluation of assembly training efficacy and training transfer [18]. A research was carried out by Abidi et al. to evaluate and contrast the virtual assembly training method used for the first Saudi Arabian vehicle prototype. Three learning contexts were examined in this study: conventional engineering, computer-aided design environments, and immersive VR. Random assignments were made to the various training contexts for 15 university students [19].\nIndustrial design, planning, and prototyping are more successful and economical when done in VR. The study conducted by Abdulrahman M. Al-Ahmari and colleagues and reported in this paper was primarily concerned with creating a \u2018\u2018virtual manufacturing assembly simulation system\u2019\u2019 that tackles the limitations of VR settings. Using a virtual environment, the proposed system builds an interactive workbench for looking at different assembly options and teaching how to put them together [20].\nDissimilar from the above systems in literature, our framework proposed wireless body-worn sensors for controlling 3D game objects, a deep learning-based approach for recognizing sports behaviors, and activity recognition for an indoor gaming activity that is used to predict the label of the considered game activity.\nIII. OUR APPROACH This section elaborates on the proposed architecture for active monitoring of the sports-related activities of humans and their conversion into IMU data for its recognition in gaming activity. Such recognition can be very helpful for demonstrating complex sports behaviors in VR. It is also helpful for artificial intelligence-based gaming objects to recognize a set of sports behavior.\nFig. 1 shows a description of the overall system. According to the figure, wearable sensors generate accelerometer data for particular gaming activity, which is performed by humans using the body-worn sensors-based device. The publicly available benchmarked datasets were used to evaluate the proposed system. The data was pre-processed, and the corresponding features were extracted. A well-known approach of grey wolf optimization (GWO) was efficiently used for feature optimization over the extracted features. RNN classifier is further applied for the classification of these optimized features to recognize the gestures performed by humans. Lastly, the predicted gesture was depicted in the\n12462 VOLUME 11, 2023\nVR game and the user can play the game as first person in the VR world.\nA. DATA PRE-PROCESSING The ERICA dataset contained 3-axes accelerometer data, which is obtained by integrating mpu6050 device with Arduino. Each value in the data portrayed a certain position of a body part where the body-worn device is attached in 3D space. Hence, each value of the dataset is equally important in the proposed approach, but the data may contain irrelevancy, irregularity, inconsistencies, and repetition that can affect the proposed model and generate false predictions [21]. It is called the noise in data that needs to be calibrated before it is fed to the classifier. To reduce this noise, the data was divided into frames, which improve the quality of data and ensure the employment of signal enhancement for data filtering to identify undesired features. It also helps in avoiding irrelevancy, irregularity, inconsistencies, and repetition issues [22]. Then, a 3rd order median filter has been used to cancel the significant noise artifact. However, the median filter is a \u2018\u2018nonlinear filter\u2019\u2019, which removes \u2018\u2018speckle noise\u2019\u2019 from a given signal. It provides the median of the signal in a required size and outperformed the \u2018\u2018low pass filter\u2019\u2019 because of reducing noise with keeping the original signal. The median filter is calculated as:\nMed(X ) =  x [n 2 ] if n is even\nX [n\u2212 12] + X [n+ 12] 2\nif n is odd (1)\nwhere n is the count of values and X is the \u2018\u2018ordered set of values\u2019\u2019 in the dataset [23]. ERICA is a lightweight dataset containing sensor data from three different gym exercises. Every data value is important, and a small proportion of data\nrequires pre-processing. For this purpose, median filter was applied. Fig. 2 shows the result of the median filter applied over ERICA dataset in the form of filtered and unfiltered signals. The dotted line displays the filtered wave, and the solid line shows the unfiltered data.\nB. FEATURES EXTRACTION After pre-processing, the data is further subjected to features extraction methods to collect unique features from the data. These features were then passed to the features optimization module for further processing. We have utilized four different feature extraction methods including power spectral density (PSD), skewness, kurtosis, and convolutional neural network (CNN)."
        },
        {
            "heading": "1) POWER SPECTRAL DENSITY (PSD)",
            "text": "PSD determines the \u2018\u2018power of a signal as a function of frequency\u2019\u2019 by using the signal\u2019s per unit frequency [26]. Watts per hertz (W/Hz) is a typical unit of measurement for PSD. Fast Fourier Transform (FFT) has it\u2019s function to\nVOLUME 11, 2023 12463\nproduce the Discrete Fourier Transform X (wi) of a signal, where wi gives the frequency point. Following is the equation to calculate PSD:\nP (wi) = 1 N |X (wi) |2 (2)\nThe average power Px can be explained as S (f ) df , where the function S (f ) is used to express the power of each minimal limit unit\u2019s frequency component, it will be referred to as the PSD [27].\nP\u0304x = lim t0\u2192\u221e 1 2t0\n\u222b \u221e\n\u2212\u221e\nE [\u2223\u2223Xt0 (f )\u2223\u2223] df (3)\n=\n\u222b \u221e\n\u2212\u221e\nlim t0\u2192\u221e E [\u2223\u2223Xt0 (f )\u2223\u2223] 2t0 df\nS (f ) = lim t0\u2192\u221e E [\u2223\u2223Xt0 (f )\u2223\u2223] 2t0\n(4)\nPSD shows the energy of fluctuations relative to frequency. In other words, it demonstrates the frequencies whose certain variants are strong and those frequencies that are weak. PSD is applied over three columns of the dataset, which contains accelerometer data in the x, y, and z-axis. This data is collected concerning time domain. When PSD is applied over the ERICA dataset, unique features are extracted from the frequency domain. Fig. 3 elucidates the results, which show the signals\u2019 power vs frequency. This helped in explaining the distribution of data between multiple frequency domains."
        },
        {
            "heading": "2) SKEWNESS",
            "text": "Skewness can be defined as a slight deviation from the \u2018\u2018normal distribution or symmetrical bell curve\u2019\u2019 in a collection of data. There are various conditions. If the curve is seen inclined towards right or left, data has skewness. Skewness can have zero, negative, positive, or undefined values [28]. Skewness can be calculated as:\nSkewness =\n\u2211N 1 (Xi \u2212 X ) 3\n(N \u2212 1) \u2217 \u03c3 3 (5)\nwhereN is the total sample count in data, Xi is the value of the samples, X gives the mean, and \u03c3 shows the standard deviation. Skewness scores are calculated between \u22123 and +3.\nIf a value of skewness in a distribution is more than 1 or lesser than -1, it is said to be strongly skewed, if it is between 0.5 and 1 or -0.5 and -1, it is said to be mildly skewed. Additionally, the distribution is said to be very symmetrical if the value of skewness is between -0.5 and 0.5 [29]. The skewness of the \u2018\u2018ERICA dataset\u2019\u2019 is shown in Fig. 4."
        },
        {
            "heading": "3) KURTOSIS",
            "text": "The final feature extraction method used in our proposed system was kurtosis. It can be termed as the cumulative weight of a distribution\u2019s tails in relation to its middle point. A set of essentially normal data may be visualized using a histogram to reveal a bell-shaped peak with the majority of data falling within three standard deviations (plus or minus) of the average [30]. The equation below is a mathematical formula for kurtosis:\nKurtosis =\n\u2211N i=1 (Xi\u2212X ) N\n\u03c3 4 (6)\nwhere N is the total sample count in data, Xi is the value of the samples, X denotes mean and \u03c3 denotes standard deviation. A metric in the statistics field is called kurtosis, which expresses the measure of divergence of a distribution\u2019s tail from those of a normal distribution. Kurtosis, thus, tells if a particular distribution\u2019s tails include greater values. [31]. Fig. 5 displays the features selected from ERICA dataset via the kurtosis-based features extraction method.\n12464 VOLUME 11, 2023"
        },
        {
            "heading": "4) CONVOLUTIONAL NEURAL NETWORK",
            "text": "To extract features, we applied CNN over the filtered data that collected the features, while a dissimilar neural network classified the features. The feature extraction network uses input data. Three layers make up a neural network; input, output, and hidden layer. The neurons in CNN are similar to the neurons of human body. The way they take the input, analyze it and send the response to the body is similar. Data arrays are accepted as input by the input layer. CNN\u2019s may have several hidden layers that employmathematics to extract characteristics from the provided data. Several instances of this include convolution, pooling, corrected linear units, and fully connected layers. Formally, the following formulas were used to extract key features map via one-dimensional convolution operation:\na(l+1)j (\u03c4 ) = \u03c3 (b l j + \u2211F l f=1 K ljf (\u03c4 ) \u2217 a l f (\u03c4 ))\n= \u03c3 (blj + \u2211F l f=1 [ \u2211pl p=1 K ljf (p) \u2217 a l f (\u03c4 \u2212 p))]\n(7)\nwhere alj (\u03c4 ) denotes the \u2018\u2018feature map j in layer l\u2019\u2019, \u03c3 is a \u2018\u2018non-linear function\u2019\u2019, F l gives the \u2018\u2018number of feature maps in layer l\u2019\u2019, K ljf displays the \u2018\u2018kernel convolved over feature map f in layer l\u2019\u2019 to form the \u2018\u2018feature map j in layer (l+1)\u2019\u2019, pl is the \u2018\u2018length of kernels in layer l\u2019\u2019 and blj provides a \u2018\u2018bias vector\u2019\u2019 [25]. The datasets have some activities and when we pass the dataset columns to CNN based feature extraction method, we will get a unique feature. The features extracted of CNN on the ERICA dataset are demonstrated by three different colors in Fig. 6.\nThe algorithm for data preprocessing and features extraction methods described above is shown in Algorithm 1:\nC. FEATURE OPTIMIZATION The dimensionality reduction method was employed next over multiple datasets to divide and reduce the vector size to make them more manageable groups. A necessary step in the \u2018\u2018feature selection process\u2019\u2019 of a predictive model is to make the feature array smaller and use only the features that are important in certain cases. Fewer input variables\nAlgorithm 1 \u2018\u2018Data Preprocessing and Feature Extraction\u2019\u2019 Input: Dataset Output: Filtered dataset and extracted features For i from 0 to length of dataset For j from 0 to length of dataset[i] Set dataset[i][j] to median(dataset[j])\nFor i from 0 to length of dataset For j from 0 to length of dataset[i] Apply 1 by 1 convolutional layer Extract and add result feature map to extracted features For i from 0 to length of data For j from 0 to length of data[i] Compute Skewness of data Extract and add result feature map to extracted features For i from 0 to length of dataset For j from 0 to length of data[i] Compute Kurtosis of data Extract and add result feature map to extracted features For i from 0 to length of dataset For j from 0 to length of data[i] Compute Power Spectral Density of data Extract and add result feature map to extracted features\nmight improve the model\u2019s performance while simultaneously minimizing the computational expense of modeling. Modern advanced feature selection techniques choose a subset of essential features utilizing the strength of optimization algorithms to improve classification outcomes [32].\nNumerous controlling factors were used by the majority of optimization algorithms including the genetic algorithm. Theymust be tuned for improved performance. The optimization step of the proposed system uses the GWO technique, which is a novel meta-heuristic optimization technique. Its guiding premise is to model cooperative hunting behavior similar to that of grey wolves in the wild. Compared to other techniques, GWO has a unique model structure. The goal of the GWO is to use population interaction to locate the best areas of the complicated search space [33]. The pack finds its prey by changing the positions of the individual agents with respect to the prey location as follows:\nX (t + 1) = Xp (t) + A.D (8)\nwhere Xp is the prey position, X is the grey wolf position t is the iteration, the dot operator shows vector entry-wise multiplication, and D is defined as:\nD = |C .Xp (t) \u2212 X (t)| (9)\nwhere coefficient vectors (A and C) are computed as follows:\nA = 2a.r1 \u2212 a (10)\nC = 2r2 (11)\nwhere \u2018\u2018r1 and r2\u2019\u2019are random vectors with ranges [0, 1] and a is a linear function of the number of exploration and\nVOLUME 11, 2023 12465\nexploitation repetitions. All wolves have the same value for a. According to these calculations, a wolf can modify its location in the search area around its prey at any random time. The entire pack engages in hunting based on information provided by the beta, alpha, and delta wolves, who are aware of the whereabouts of the prey, as stated in the following:\nX (t + 1) = X1 + X2 + X3\n3 (12)\nwhere X1,X2,X3 are calculated as follows:\nX1 = |X\u03b1 \u2212 A1.D\u03b1| (13)\nX2 = |X\u03b2 \u2212 A2.D\u03b2 | (14)\nX3 = |X\u03b3 \u2212 A3.D\u03b3 | (15)\nwhere X1,X2,X3 are best results and D\u03b1,D\u03b2 , D\u03b3 are calculated as [34]:\nD\u03b1 = |C1.X\u03b1 \u2212 X | (16)\nD\u03b2 = |C2.X\u03b2 \u2212 X | (17)\nD\u03b3 = |C3.X\u03b3 \u2212 X | (18)\nFig. 7, Fig. 8, and Fig. 9 display the visualization of the fitness value or best solution with the number of iterations by applying GWO over the ERICA, IMSporting Behaviors (IMSB), and WISDM datasets, respectively.\nD. RECURRENT NEURAL NETWORK The classification of interactions has been carried out by a classifier named RNN and it is the last phase of the proposed system. The RNN is a fast, robust, and one of the most reliable neural networks currently available due to its unique feature called internal memory [35]. Fig. 10 shows a visual representation of the RNN for the ERICA dataset, which has a 5 hidden layers of LSTM, one input layer of LSTM and an output-dense layer.\nx(t) is used as input at any time step t in RNN. Onehot vector x1, for instance, may correspond to a word in a text. H(t) serves as the network\u2019s \u2018\u2019memory\u2019\u2019 and represents a\n12466 VOLUME 11, 2023\nconcealed state at time t. The hidden state of the previous time step and the current input is used to determine h (t). The RNN has connections for hidden input, hidden-to-hidden recurrent connections, and hidden-to-output connections, all of which were parameterized by a \u2018\u2019weight matrix U,\u2019\u2019 \u2018\u2019weight matrix W,\u2019\u2019 and \u2018\u2019weight matrix V,\u2019\u2019 respectively. Over time, all of these \u2018\u2019weights (U, V, W)\u2019\u2019 were shared. By o(t), the network output is shown. [36]. The following set of equations can be used to model the RNN forward pass:\na(t) = b+Wh(t\u22121) + Ux(t) (19) o(t) = c+ Vh(t) (20)\nh(t) = tanh ( a(t) ) (21)\ny\u0302(t) = softmax(o(t)) (22)\nThe equations shown above are an illustration of a recurrent network that converts an \u2018\u2018input sequence\u2019\u2019 into an identically lengthened \u2018\u2018output sequence\u2019\u2019. The sum of the losses across all the time steps would thus be the overall loss for a particular series of x and y values. We suppose that the vector of probabilities over the output was obtained by using the \u2018\u2018outputs o(t)\u2019\u2019 in the softmax function [37]. We also suppose that, given the current input, the loss L is the \u2018\u2018negative loglikelihood\u2019\u2019 of the genuine goal y(t). The algorithm for feature optimization and classification by RNN is shown below in Algorithm 2:\nAlgorithm 2 Grey Wolf Optimization and Classification by RNN Input: Dataset with extracted features Output: Optimized features and classification result Initialize the grey wolf population Xi, i = \u00af1, n Initialize a, A and C Find each search agent fitness X\u221d = \u2018\u2018Best Search Agent\u2019\u2019 X\u03b2 =\u2018\u2018Second Best Search Agent\u2019\u2019 X\u03b3 =\u2018\u2018Third Best Search Agent\u2019\u2019 while t < iterations maximum number do for each search agent do Randomly initialize r1and r2 Update current search agent position\nUpdate a, A and C Find all search agent fitness Update X\u221d,X\u03b2 and X\u03b3 t = t + 1\nReturn X\u221d Initialize X to dataset[features] Initialize Y to dataset[classes] Split X and Y to train and test data by 80% and 20% ratio Set RNN to sequential mode Add an \u2018\u2018LSTM\u2019\u2019 layer with 128 units, and return_sequence = True Add an \u2018\u2018LSTM\u2019\u2019 layer with 128 units, and return_sequence = True For each i which is [True, True, False]\nAdd LSTM layer with return_sequence = i Add Dense layer with softmax activation function and units = outputclasses.length Compile RNN with adam optimizer and categorical_crossentropy loss function Run RNN with 100 epochs and batch size = 8\nIV. EXPERIMENTAL SETUP AND RESULTS The experimental results part discusses about the benchmark datasets which we have used in our study, and experimental setup for the proposed system, statistical evaluation, results by implementing the proposed architecture, and comparison of this work with other body-worn systems.\nA. DATASET DESCRIPTION AND METRICS High-intensity interval training (HIIT) can be delivered through exergaming in virtual reality, which combines exercise and enjoyment. We have used three different datasets in this study i.e., IMSB [38], [39], WISDM [40], and ERICA [41].\nThe first dataset used is IMSB created by Intelligent Media Centre, Air University, Islamabad. There are six different sports-related interactions in the IMSB dataset including table tennis, football, cycling, badminton, basketball, skipping. Three tri-axial accelerometers were attached to the knee, wrist, and lower neck regions of the subjects. The dataset contained motion data from participants performing six different sports as mentioned above. The dataset also contained 120 data sequences with varying exercise time period from the 40s to 60s. A total of 20 subjects were engaged in repetitive behaviors. Fig. 11 shows the plots of raw data from three accelerometers in x, y, and z coordinates for basketball and badminton behavior.\nThe WISDM is the next dataset that was used. The activities included in the dataset are running, sitting, standing, going up and down stairs, and so on. There are 1,098,207 total samples in this dataset, including 424,400 walking samples, 342,177 jogging samples, 122,869 upstairs samples, 100,427 downstairs samples, 59,939 sitting samples, and 48,395 standing samples. Fig. 12 represents the walking and jogging behavior over the WISDM dataset.\nVOLUME 11, 2023 12467\nThe third dataset utilized was ERICA, which was created for the automated tracking and analysis of exercise activities at the individual level. This dataset was acquired as part of the development of a low-cost, pervasive digital personal training system that combines affordable IoT sensors linked to dumbbells with personal wireless ear-worn devices (earables) to enable fine-grained tracking of a person\u2019s free-weight exercise training. Total of 324 samples from three separate free-weight workouts carried out by 27 subjects are included in this dataset. The activities performed in a dataset are biceps curls, lateral raises, and triceps extensions. Fig. 13 shows\nthe biceps curls and lateral raises behavior of the ERICA dataset.\nB. EXPERIMENTAL SETUP This section gives a brief description of the implementation of our proposed system. A 3D VR game will be made in Unity3d which when playing is visible to the person by a screen attached to the VR headset and on the PC as well through screen casting method [42].\nA 6 DOF sensor MPU6050 is utilized for capturing the motion data of the human body during exergaming. Arduino nano read the sensor data and send it via nrf24l01 to the receiving point, which is computer, using serial communication. Further, the User Datagram Protocol (UDP) communication was used to establish a secure connection using specific IP based path to convey data from host to destination and in our system, it helps in establishing a secure channel connection between computer and VR game to convey the predicted results from the proposed model to the game [43]. The results are presented in the form of confusion matrices and a precision-recall table. On a Windows 10 computer running the Unity3D and Python programming languages, with 16 GB of RAM, and a Core i7-7500U CPU running at 2.70 GHz, all processing and experimentation were carried out. nRF24L01 and MPU6050 on an Arduino Nano were utilized to create body-worn. Finally, using the IMSB, WISDM, and ERICA datasets, the suggested system\u2019s performance is compared to the precision of other already made systems.\nC. SATISTICAL EVALUATION We will go over the experimental findings of the suggested model using the publically accessible IMSB, WISDM, and ERICA datasets in this part. We will also be comparing the results with other state-of-the-art methods."
        },
        {
            "heading": "1) IMSporting BEHAVIORS DATASET",
            "text": "Regarding the IMSB dataset, confusion matrices are used to demonstrate interaction recognition for different dataset types. A \u2018\u2018confusion matrix\u2019\u2019 measures the effectiveness of a classifier on the basis of \u2018\u2018true positives, false positives, true negatives, and false negatives\u2019\u2019. [44]. The amount of true positives reveals the correctly detected classes represented on the matrix diagonal. Table 1 demonstrates the confusion matrix over the IMSB dataset.\nTABLE 1. Confusion matrix over imsporting behaviors dataset.\n12468 VOLUME 11, 2023\nThe confusion matrix in Table 1 shows that a few interaction classes having related activity types are confused with each other. The mean accuracy achieved by applying the classifier is 85.01%. The recall, precision, and F1-score for different classes over the IMSB dataset are shown in Table 2.\nHence, an accurate system was developed, which was able to recognize each game with high precision [45]. The results of the gaming interface using the IMSB dataset are presented in Fig. 14.\nTable 3 represents a comparison of classifier results when compared to the other state-of-the-art methods. Many systems were developed that are similar to the proposed method. A comparison of the systems developed over the IMSB dataset has been displayed in Table 3. The results from other\nsystems using different classifiers over the IMSB dataset are compared with the proposed method. Authors have used artificial neural networks algorithm along with features extraction methods and got an accuracy of 82.83% [46]. Another system utilized a random forest algorithm and achieved an accuracy of 83.42% [47]. One of the other proposed systems used for classification through LSTM with multi-fused features extraction achieved an accuracy of 80% [48]. Lastly, a system using the multi-layer perceptron (MLP) achieved an accuracy of 75.90% [49]. The system proposed in this paper has achieved an accuracy of 85.01% that outperformed all the previously proposed systems."
        },
        {
            "heading": "2) WISDM DATASET",
            "text": "For WISDM dataset, the results from RNN classifier over the optimized features produced the confusion matrix that is shown in table 4. It is clear that the result of interaction classes was efficient and acceptable. A small amount of data from some interaction classes was confused i.e., achieving a mean accuracy of 88.46%.\nThe ratio of \u2018\u2018correct positive predictions\u2019\u2019 to the \u2018\u2018total positives\u2019\u2019 is precision while the recall is the \u2018\u2018true positive rate\u2019\u2019, and it is the ratio of \u2018\u2018correct positive\u2019\u2019 to the \u2018\u2018total predicted positives\u2019\u2019. The average of precision and recall is the F1 score [50]. The precision, recall, and F1-score for classes of the dataset are given in Table 5.\nTABLE 5. Classification results over WISDM dataset.\nAn accurate system was developed that can recognize each game with high precision. The results of the gaming interface using the WISDM dataset are shown in Fig. 15.\nTable 6 represents a comparison of RNN results over the WISDM dataset with other state-of-the-art models. The results were compared with the conventional system and compared with the proposed method. Authors in [51] have used a reweighted genetic algorithm and achieved an accuracy of 87.75%. Another proposed system in [52] utilized MLP and achieved a 75.09% accuracy rate. Another system applied classification through CNN and achieved 75.90% accuracy [53]. The Hoeffding tree algorithm has achieved an accuracy rate of 75.54% in another proposed method [53]. Lastly, a system utilized support vector machines and achieved 82.77% accuracy [38]. The proposed system in this paper has outperformed these systems by achieving an accuracy rate of 88.46%."
        },
        {
            "heading": "3) ERICA DATASET",
            "text": "Due to its light nature, many classifiers generate efficient results over the ERICA dataset. The accuracy acquired by the proposed system via RNN and optimized features from ERICA dataset is 93.18%. The confusion matrix over ERICA dataset is shown in Table 7. It is shown that the results of interaction classes have achieved a mean accuracy rate of 93.18%. Despite the complications in activities, the results show that few activities are confused with other activities.\nThe precision, recall, and F1-score for activities recognized are given in Table 8. The outcomes from the gaming interface over ERICA dataset are shown in Fig. 16. The interface also illustrates the gaming object\u2019s gesture position that will give the information regarding gaming label prediction.\nTable 9 represents a comparison of RNN results over the ERICA dataset with other state-of-the-art methodologies. According to the table, Radhakrishnan et al. used the ERICA dataset for their experiment and achieved 70.0% accuracy using a random forest classifier [41]. An accuracy rate of 81.7%was attained for identifying gymworkouts while monitoring the leg muscles using a pressure-sensing system [54].\n12470 VOLUME 11, 2023\nThe accuracy of the Kalman filter is 84.0% in a filter-based sensor fusion activity recognition system [55].\nV. CONCLUSION The proposed system effectively implemented a VR firstperson game with an accurate deep learning-based gesture recognition system. Recently, it solved a major problem of obesity caused by a lack of physical activity particularly in the young generation. Three datasets were utilized for experimenting with the proposed approach, which are IMSB, WISDM, and ERICA datasets. First, the dataset used is pre-processed by applying a third-order median filter. Next, features were extracted by four well-known techniques called power spectral density, CNN-based features extraction, skewness, and kurtosis. Then, the datasets were further reduced through grey wolf optimization to get the optimized features. Further, the gestures were classified by applying the RNN classifier. After gesture prediction, the hardware is implemented using Arduino and motion sensors. Furthermore, the hardware and software components are created and combined by serial communication. Extensive experiments have been performed over the three datasets and demonstrated the effectiveness and efficiency of the system by achieving remarkable results and superior performance. It also outperformed the recognition accuracy of conventional state-of-theart systems.\nAs for limitations, the sensor must be calibrated otherwise, it will generate wrong results. The sensor must be placed in the right place to get the desired gesture result. The dataset was generated by taking data on exercises from healthy and young persons, and if you try Bodyworns on disabled persons, you may get the wrong result. Activity labels might appear after a few seconds of delay if you performed multiple activities together in less than 2 seconds. A battery power of 5V is required for the sensor to work normally.\nBy including new features and playable games, we want to increase the effectiveness of the suggested system in the future. Additionally, we want to create a jacket with bodyworn sensors. In the future, we also hope to increase the system\u2019s precision and provide consumers a better user interface so they may play and take pleasure in a virtual gaming experience.\nREFERENCES [1] Z. Belyaeva, A. Petrosyan, and S. M. R. Shams, \u2018\u2018Stakeholder data anal-\nysis in the video gaming industry: Implications for regional development,\u2019\u2019 EuroMed J. Bus., vol. 17, no. 3, pp. 333\u2013349, Aug. 2022, doi: 10.1108/EMJB-10-2021-0150. [2] E. Zamani, \u2018\u2018Effect of addiction to computer games on physical and mental health of female and male students of guidance school in city of Isfahan,\u2019\u2019 Addiction Health, vol. 1, no. 2, pp. 98\u2013104, 2009. [3] S. A. Bowman, \u2018\u2018Television-viewing characteristics of adults: Correlations to eating practices and overweight and health status,\u2019\u2019 Preventing Chronic Disease, vol. 3, pp. 1\u201311, Jan. 2006. [4] B. Poetker, \u2018\u2018The very real history of virtual reality (+A look ahead),\u2019\u2019 Vis. Coupled Airborne Syst., USA, Tech. Rep. re:2019, 2019. [5] O. Ouyed and M. A. Said, \u2018\u2018Group-of-features relevance in multinomial kernel logistic regression and application to human interaction recognition,\u2019\u2019 Exp. Syst. Appl., vol. 148, Jun. 2020, Art. no. 113247.\n[6] G. Tao, B. Garrett, T. Taverner, E. Cordingley, and C. Sun, \u2018\u2018Immersive virtual reality health games: A narrative review of game design,\u2019\u2019 J. NeuroEng. Rehabil., vol. 18, no. 1, pp. 1\u201321, Dec. 2021. [7] L. Jones, \u2018\u2018VR and. . . better healthcare,\u2019\u2019 Eng. Technol., vol. 11, no. 3, pp. 36\u201339, Apr. 2016. [8] P. Zikas, S. Kateros, and P. Margarita, \u2018\u2018Mixed reality serious games and gamification for smart education,\u2019\u2019 in Proc. Eur. Conf. Games Based Learn., 2016, pp. 805\u2013812. [9] M. Yates, A. Kelemen, and C. S. Lanyi, \u2018\u2018Virtual reality gaming in the rehabilitation of the upper extremities post-stroke,\u2019\u2019 Brain Injury, vol. 30, no. 7, pp. 855\u2013863, 2016. [10] I. Paraskevopoulos and E. Tsekleves, \u2018\u2018Use of gaming sensors and customised exergames for parkinson\u2019s disease rehabilitation: A proposed virtual reality framework,\u2019\u2019 in Proc. 5th Int. Conf. Games Virtual Worlds Serious Appl. (VS-GAMES), Sep. 2013, pp. 1\u20135. [11] D. Fitzgerald, J. Foody, D. Kelly, T. Ward, C. Markham, J. McDonald, and B. Caulfield, \u2018\u2018Development of a wearable motion capture suit and virtual reality biofeedback system for the instruction and analysis of sports rehabilitation exercises,\u2019\u2019 in Proc. 29th Annu. Int. Conf. IEEE Eng. Med. Biol. Soc., Aug. 2007, pp. 4870\u20134874. [12] I. F. Mondrag\u00f3n Bernal, N. E. Lozano-Ram\u00edrez, J. M. Puerto Cort\u00e9s, S. Valdivia, R. Mu\u00f1oz, J. Arag\u00f3n, R. Garc\u00eda, and G. Hern\u00e1ndez, \u2018\u2018An immersive virtual reality training game for power substations evaluated in terms of usability and engagement,\u2019\u2019 Appl. Sci., vol. 12, no. 2, p. 711, Jan. 2022. [13] M. Ma, L. Jain, and P. Anderson, \u2018\u2018Healthcare training enhancement through virtual reality and serious games,\u2019\u2019 Virtual, Augmented Reality Serious Games Healthcare, vol. 68, pp. 9\u201327, Jan. 2014. [14] M. H. Abidi, A. Ahmad, S. Darmoul, and A. M. Al-Ahmari, \u2018\u2018Haptics assisted virtual assembly,\u2019\u2019 IFAC-PapersOnLine, vol. 48, no. 3, pp. 100\u2013105, 2015. [15] K. Gerling, P. Dickinson, K. Hicks, L. Mason, A. L. Simeone, and K. Spiel, \u2018\u2018Virtual reality games for people using wheelchairs,\u2019\u2019 in Proc. CHI Conf. Hum. Factors Comput. Syst., New York, NY, USA, Apr. 2020, pp. 1\u201311. [16] Y. Xu, M. Tong, W.-K. Ming, Y. Lin, W. Mai, W. Huang, and Z. Chen, \u2018\u2018A depth camera\u2013based, task-specific virtual reality rehabilitation game for patients with stroke: Pilot usability study,\u2019\u2019 JMIR Serious Games, vol. 9, no. 1, Mar. 2021, Art. no. e20916. [17] S. Park, H. Aan, J. Jo, H. Kim, S. Han, J. Kim, P. Yoon, and K. Kim, \u2018\u2018A-visor and A-camera: Arduino-based cardboard head-mounted controllers for VR games,\u2019\u2019 in Proc. IEEE Conf. Virtual Reality 3D User Int. Abstr. Workshops (VRW), Atlanta, GA, USA, Mar. 2021, pp. 434\u2013435. [18] M. H. Abidi, A. Al-Ahmari, A. Ahmad, W. Ameen, and H. Alkhalefah, \u2018\u2018Assessment of virtual reality-based manufacturing assembly training system,\u2019\u2019 Int. J. Adv. Manuf. Technol., vol. 105, no. 9, pp. 3743\u20133759, Dec. 2019. [19] M. H. Abidi, A. M. E. Tamimi, A. M. A. Ahmari, and E. S. A. Nasr, \u2018\u2018Assessment and comparison of immersive virtual assembly training system,\u2019\u2019 Int. J. Rapid Manuf., vol. 3, no. 4, p. 266, 2013. [20] A. Al-Ahmari, M. Abidi, A. Ahmad, and S. Darmoul, \u2018\u2018Development of a virtual manufacturing assembly simulation system,\u2019\u2019 Adv. Mech. Eng., vol. 8, no. 3, pp. 1\u201317, 2016. [21] S. Tang, S. Yuan, and Y. Zhu, \u2018\u2018Data preprocessing techniques in convolutional neural network based on fault diagnosis towards rotating machinery,\u2019\u2019 IEEE Access, vol. 8, pp. 149487\u2013149496, 2020. [22] A. Famili, W.-M. Shen, R. Weber, and E. Simoudis, \u2018\u2018Data preprocessing and intelligent data analysis,\u2019\u2019 Intell. Data Anal., vol. 1, no. 1, pp. 3\u201323, 1997. [23] S. Tripathy and T. Swarnkar, \u2018\u2018Performance observation of mammograms using an improved dynamic window based adaptive median filter,\u2019\u2019 J. Discrete Math. Sci. Cryptogr., vol. 23, no. 1, pp. 167\u2013175, Jan. 2020. [24] D. Varshni, K. Thakral, L. Agarwal, R. Nijhawan, and A. Mittal, \u2018\u2018Pneumonia detection using CNN based feature extraction,\u2019\u2019 in Proc. IEEE Int. Conf. Electr., Comput. Commun. Technol. (ICECCT), Feb. 2019, pp. 1\u20137. [25] X. Shao, C.-S. Kim, and P. Sontakke, \u2018\u2018Accurate deep model for electricity consumption forecasting using multi-channel and multi-scale feature fusion CNN\u2013LSTM,\u2019\u2019 Energies, vol. 13, no. 8, p. 1881, Apr. 2020. [26] H. Nassuna, O. S. Eyobu, J.-H. Kim, and D. Lee, \u2018\u2018Feature selection based on variance distribution of power spectral density for driving behavior recognition,\u2019\u2019 in Proc. 14th IEEE Conf. Ind. Electron. Appl. (ICIEA), Jun. 2019, pp. 335\u2013338.\nVOLUME 11, 2023 12471\n[27] J. Chen, J. Wang, and J. M. W. Brownjohn, \u2018\u2018Power spectral-density model for pedestrian walking load,\u2019\u2019 J. Structural Eng., vol. 145, no. 2, Feb. 2019, Art. no. 04018239. [28] A. Koduru, H. B. Valiveti, andA.K. Budati, \u2018\u2018Feature extraction algorithms to improve the speech emotion recognition rate,\u2019\u2019 Int. J. Speech Technol., vol. 23, no. 1, pp. 45\u201355, Mar. 2020. [29] D. Trafimow, T. Wang, and C. Wang, \u2018\u2018From a sampling precision perspective, skewness is a friend and not an enemy!\u2019\u2019 Educ. Psychol. Meas., vol. 79, no. 1, pp. 129\u2013150, Feb. 2019. [30] A. K. Alanazi, \u2018\u2018Application of neural network and time-domain feature extraction techniques for determining, volumetric percentages and the type of two phase flow regimes independent of scale layer thickness,\u2019\u2019Appl. Sci., vol. 12, no. 3, p. 1336, 2022. [31] M. Altaf, T. Akram, M. A. Khan, M. Iqbal, M. M. I. Ch, and C.-H. Hsu, \u2018\u2018A new statistical features based approach for bearing fault diagnosis using vibration signals,\u2019\u2019 Sensors, vol. 22, no. 5, p. 2012, Mar. 2022. [32] T. M. Ghazal and N. Taleb, \u2018\u2018Feature optimization and identification of ovarian cancer using internet of medical things,\u2019\u2019 Exp. Syst., vol. 39, no. 9, p. e12987, Nov. 2022. [33] K. Asghari, M. Masdari, F. S. Gharehchopogh, and R. Saneifard, \u2018\u2018A chaotic and hybrid gray wolf-whale algorithm for solving continuous optimization problems,\u2019\u2019 Prog. Artif. Intell., vol. 10, no. 3, pp. 349\u2013374, Sep. 2021. [34] E. Krishna, V. Institute of Technology, T. Arunkumar, and V. Institute of Technology, \u2018\u2018Hybrid particle swarm and gray wolf optimization algorithm for IoT intrusion detection system,\u2019\u2019 Int. J. Intell. Eng. Syst., vol. 14, no. 4, pp. 66\u201376, Aug. 2021. [35] H. Singh Gill, O. I. Khalaf, Y. Alotaibi, S. Alghamdi, and F. Alassery, \u2018\u2018Multi-model CNN-RNN-LSTM based fruit recognition and classification,\u2019\u2019 Intell. Autom. Soft Comput., vol. 33, no. 1, pp. 637\u2013650, 2022. [36] J. A. Nasir, O. S. Khan, and I. Varlamis, \u2018\u2018Fake news detection: A hybrid CNN-RNN based deep learning approach,\u2019\u2019 Int. J. Inf. Manag. Data Insights, vol. 1, no. 1, Apr. 2021, Art. no. 100007. [37] J. Yan, L. Jin, Z. Yuan, and Z. Liu, \u2018\u2018RNN for receding horizon control of redundant robot manipulators,\u2019\u2019 IEEE Trans. Ind. Electron., vol. 69, no. 2, pp. 1608\u20131619, Feb. 2022. [38] A. Jalal, M. A. K. Quaid, and A. S. Hasan, \u2018\u2018Wearable sensor-based human behavior understanding and recognition in daily life for smart environments,\u2019\u2019 in Proc. Int. Conf. Frontiers Inf. Technol. (FIT), Dec. 2018, pp. 105\u2013110, doi: 10.1109/FIT.2018.00026. [39] A. Jalal, M. A. K. Quaid, andM. A. Sidduqi, \u2018\u2018A triaxial acceleration-based human motion detection for ambient smart home system,\u2019\u2019 in Proc. 16th Int. Bhurban Conf. Appl. Sci. Technol. (IBCAST), Jan. 2019, pp. 353\u2013358. [40] S. K. Challa, A. Kumar, and V. B. Semwal, \u2018\u2018Amultibranch CNN-BILSTM model for human activity recognition using wearable sensor data,\u2019\u2019 Vis. Comput., vol. 38, pp. 4095\u20134109, Aug. 2021. [41] M. Radhakrishnan, D. Rathnayake, O. K. Han, I. Hwang, and A. Misra, \u2018\u2018ERICA: Enabling real-time mistake detection & corrective feedback for free-weights exercises,\u2019\u2019 in Proc. 18th Conf. Embedded Networked Sensor Syst. New York, NY, USA: Association for Computing Machinery, 2020, pp. 558\u2013571. [42] F. N. Nezami, M. A.W\u00e4chter, N.Maleki, P. Spaniol, L.M. Kuhne, A. Haas, J. M. Pingel, L. Tiemann, F. Nienhaus, L. Keller, S. U. K\u00f6nig, P. K\u00f6nig, and G. Pipa, \u2018\u2018Westdrive X LoopAR: An open-access virtual reality project in unity for evaluating user interaction methods during takeover requests,\u2019\u2019 Sensors, vol. 21, no. 5, p. 1879, Mar. 2021. [43] Y. Peng, J. Chung, Q. Cao, and Y. Cai, \u2018\u2018Design of a virtual home for special needs children to learn life skills,\u2019\u2019 inWhen VR Serious GamesMeet Special Needs Education. Berlin, Germany: Springer, 2021, pp. 31\u201361. [44] A. Luque, A. Carrasco, A. Martin, and A. De Las Heras, \u2018\u2018The impact of class imbalance in classification performance metrics based on the binary confusion matrix,\u2019\u2019 Pattern Recognit., vol. 91, pp. 216\u2013231, Oct. 2019. [45] N. Tatbul, T. J. Lee, S. Zdonik, M. Alam, and J. Gottschlich, \u2018\u2018Precision and recall for time series,\u2019\u2019 in Proc. Adv. Neural Inf. Process. Syst., 2018, pp. 1\u201311. [46] S. B. Tahir, A. Jalal, and K. Kim, \u2018\u2018Wearable inertial sensors for daily activity analysis based on Adam optimization and the maximum entropy Markov model,\u2019\u2019 Entropy, vol. 22, no. 5, p. 579, 2020. [47] S. B. U. D. Tahir, A. Jalal, and M. Batool, \u2018\u2018Wearable sensors for activity analysis using SMO-based random forest over smart home and sports datasets,\u2019\u2019 in Proc. 3rd Int. Conf. Advancements Comput. Sci. (ICACS), Feb. 2020, pp. 1\u20136.\n[48] S. B. U. D. Tahir, A. Jalal, and K. Kim, \u2018\u2018Daily life log recognition based on automatic features for health care physical exercise via IMU sensors,\u2019\u2019 in Proc. Int. Bhurban Conf. Appl. Sci. Technol. (IBCAST), Jan. 2021, pp. 494\u2013499. [49] S. F. Idowu, A. Selamat, and R. Ibrahim, \u2018\u2018Performance evaluation of classifiers on activity recognition for disasters mitigation using smartphone sensing,\u2019\u2019 Jurnal Teknologi, vol. 77, no. 13, Nov. 2015. [50] K. Takahashi, K. Yamamoto, A. Kuchiba, and T. Koyama, \u2018\u2018Confidence interval for micro-averaged F1 and macro-averaged F1 scores,\u2019\u2019 Int. J. Speech Technol., vol. 52, no. 5, pp. 4961\u20134972, Mar. 2022. [51] M. Batool, A. Jalal, and K. Kim, \u2018\u2018Telemonitoring of daily activity using accelerometer and gyroscope in smart home environments,\u2019\u2019 J. Electr. Eng. Technol., vol. 15, no. 6, pp. 2801\u20132809, 2020. [52] W. Ahmad, B. M. Kazmi, and H. Ali, \u2018\u2018Human activity recognition using multi-head CNN followed by LSTM,\u2019\u2019 in Proc. 15th Int. Conf. Emerg. Technol. (ICET), Dec. 2019, pp. 1\u20136. [53] K. H.Walse, R. V. Dharaskar, and V.M. Thakare, \u2018\u2018Performance evaluation of classifiers on WISDM dataset for human activity recognition,\u2019\u2019 in Proc. 2nd Int. Conf. Inf. Commun. Technol. Competitive Strategies, Mar. 2016, pp. 1\u20137. [54] B. Zhou, M. Sundholm, J. Cheng, H. Cruz, and P. Lukowicz, \u2018\u2018Never skip leg day: A novel wearable approach to monitoring gym leg exercises,\u2019\u2019 in Proc. IEEE Int. Conf. Pervasive Comput. Commun. (PerCom), Mar. 2016, pp. 1\u20139. [55] T. A. Shloul, M. Javeed, M. Gochoo, S. A. Alsuhibany, Y. Y. Ghadi, A. Jalal, and J. Park, \u2018\u2018Student\u2019s health exercise recognition tool for E-learning education,\u2019\u2019 Intell. Autom. Soft Comput., vol. 35, no. 1, pp. 149\u2013161, 2023.\nMIR MUSHHOOD AFSAR received the B.S. degree in computer science from Air University, Islamabad. He is currently a Research Assistant with the Intelligent Media Centre. His research interests include machine learning, deep learning, camera and sensor-based gesture recognition, and virtual reality.\nSHIZZA SAQIB received the bachelor\u2019s degree in computer science from Air University, Islamabad. She is currently a Research Assistant with the Intelligent Media Center. Her research interests include machine learning, deep learning, image processing, and virtual reality.\nMOHAMMAD ALADFAJ is currently with the Department of Natural Engineering, College of Science, King Saud University, Saudi Arabia.\nMOHAMMED HAMAD ALATIYYAH is an Assistant Professor of computer science with the Computer Science Department, Prince Sattam Bin Abdulaziz University, Saudi Arabia. His research interests include the recommender systems and computer vision, such as group recommender systems, travel recommender systems, and drone vision.\n12472 VOLUME 11, 2023\nKHALED ALNOWAISER received the Ph.D. degree in computer science from Glasgow University, Scotland. He is an Assistant Professor with the Computer Engineering Department, Prince Sattam Bin Abdulaziz University, Saudi Arabia. His research interests include computer vision, optimization techniques, and performance enhancement.\nHANAN ALJUAID received the B.S. degree from KAU University and the M.S. and Ph.D. degrees in computer science from UTM University, in 2014. She is currently with the Computer Sciences Department, College of Computer and Information Sciences, Princess Nourah Bint Abdul Rahman University (PNU), Saudi Arabia. Much of her work has been on improving the understanding, design, and performance of pattern recognition, mainly through the application of data mining and machine learning. She has given numerous invited talks and tutorials. She has published numerous articles in pattern recognition, the IoT, and data science. Her research interests include computer vision and NLP.\nAHMAD JALAL received the Ph.D. degree from the Department of Biomedical Engineering, Kyung Hee University, South Korea. He is currently an Associate Professor with the Department of Computer Science and Engineering, Air University, Pakistan. Currently, he is a Postdoctoral Research Fellowship with POSTECH. His research interests include multimedia contents and artificial intelligence.\nJEONGMIN PARK received the Ph.D. degree from the College of Information and Communication Engineering, Sungkyunkwan University, in 2009. He was a Senior Researcher at the Electronics and Telecommunications Research Institute (ETRI) and a Research Professor at Sungkyunkwan University, South Korea. In 2014, he joined with the Tech University of Korea, South Korea, where he is an Associate Professor with the Department of Computer Engineering.\nHis research interests include high-reliable autonomic computing mechanism and human-oriented interaction systems.\nVOLUME 11, 2023 12473"
        }
    ],
    "title": "Body-Worn Sensors for Recognizing Physical Sports Activities in Exergaming via Deep Learning Model",
    "year": 2023
}