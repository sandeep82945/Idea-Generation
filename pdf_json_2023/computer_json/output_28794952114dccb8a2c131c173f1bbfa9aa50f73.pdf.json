{
    "abstractText": "Weakly supervised instance segmentation (WSIS) using only image-level labels is a challenging task due to the difficulty of aligning coarse annotations with the finer task. However, with the advancement of deep neural networks (DNNs), WSIS has garnered significant attention. Following a proposalbased paradigm, we encounter a redundant segmentation problem resulting from a single instance being represented by multiple proposals. For example, we feed a picture of a dog and proposals into the network and expect to output only one proposal containing a dog, but the network outputs multiple proposals. To address this problem, we propose a novel approach for WSIS that focuses on the online refinement of complete instances through the use of MaskIoU heads to predict the integrity scores of proposals and a Complete Instances Mining (CIM) strategy to explicitly model the redundant segmentation problem and generate refined pseudo labels. Our approach allows the network to become aware of multiple instances and complete instances, and we further improve its robustness through the incorporation of an Anti-noise strategy. Empirical evaluations on the PASCAL VOC 2012 and MS COCO datasets demonstrate that our method achieves state-of-the-art performance with a notable margin. Our implementation will be made available at https://github.com/ZechengLi19/CIM.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zecheng Li"
        },
        {
            "affiliations": [],
            "name": "Zening Zeng"
        },
        {
            "affiliations": [],
            "name": "Yuqi Liang"
        },
        {
            "affiliations": [],
            "name": "Jin-Gang Yu"
        }
    ],
    "id": "SP:f4d4806d340f41263bb8f0dfc3350f6c1f55ca38",
    "references": [
        {
            "authors": [
                "Jiwoon Ahn",
                "Sunghyun Cho",
                "Suha Kwak. Weakly supervised learning of instance segmentation with inter-pixel relations"
            ],
            "title": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "venue": "pages 2204\u20132213,",
            "year": 2019
        },
        {
            "authors": [
                "Aditya Arun",
                "C.V. Jawahar",
                "M. Pawan Kumar. Weakly supervised instance segmentation by learning annotation consistent instances"
            ],
            "title": "In Proceedings of the European Conference on Computer Vision",
            "venue": "pages 254\u2013270,",
            "year": 2020
        },
        {
            "authors": [
                "Hakan Bilen",
                "Andrea Vedaldi. Weakly supervised deep detection networks"
            ],
            "title": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "venue": "pages 2846\u20132854,",
            "year": 2016
        },
        {
            "authors": [
                "Zhaowei Cai",
                "Nuno Vasconcelos"
            ],
            "title": "Cascade r-cnn: Delving into high quality object detection",
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 6154\u20136162,",
            "year": 2018
        },
        {
            "authors": [
                "Mark Everingham",
                "Luc Van Gool",
                "Christopher KI Williams",
                "John Winn",
                "Andrew Zisserman"
            ],
            "title": "The pascal visual object classes (voc) challenge",
            "venue": "International Journal of Computer Vision, 88(2):303\u2013338,",
            "year": 2010
        },
        {
            "authors": [
                "Ruochen Fan",
                "Qibin Hou",
                "Ming-Ming Cheng",
                "Gang Yu",
                "Ralph R Martin",
                "Shi-Min Hu. Associating inter-image salient instances for weakly supervised semantic segmentation"
            ],
            "title": "In Proceedings of the European Conference on Computer Vision",
            "venue": "pages 367\u2013383,",
            "year": 2018
        },
        {
            "authors": [
                "Ge et al",
                "2019] Weifeng Ge",
                "Weilin Huang",
                "Sheng Guo",
                "Matthew Scott"
            ],
            "title": "Label-penet: Sequential label propagation and enhancement networks for weakly supervised instance segmentation",
            "venue": "In Proceedings of the IEEE International Conference on Computer Vision,",
            "year": 2019
        },
        {
            "authors": [
                "Ross Girshick. Fast r-cnn"
            ],
            "title": "In Proceedings of the IEEE International Conference on Computer Vision",
            "venue": "pages 1440\u20131448,",
            "year": 2015
        },
        {
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun. Deep residual learning for image recognition"
            ],
            "title": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "venue": "pages 770\u2013778,",
            "year": 2016
        },
        {
            "authors": [
                "Kaiming He",
                "Georgia Gkioxari",
                "Piotr Doll\u00e1r",
                "Ross Girshick. Mask r-cnn"
            ],
            "title": "In Proceedings of the IEEE International Conference on Computer Vision",
            "venue": "pages 2980\u20132988,",
            "year": 2017
        },
        {
            "authors": [
                "Vadim Kantorov",
                "Maxime Oquab",
                "Minsu Cho",
                "Ivan Laptev"
            ],
            "title": "Contextlocnet: Contextaware deep network models for weakly supervised localization",
            "venue": "Proceedings of the European Conference on Computer Vision, pages 350\u2013365,",
            "year": 2016
        },
        {
            "authors": [
                "Kim et al",
                "2022] Beomyoung Kim",
                "Youngjoon Yoo",
                "Chae Eun Rhee",
                "Junmo Kim"
            ],
            "title": "Beyond semantic to instance segmentation: Weakly-supervised instance segmentation via semantic knowledge transfer and selfrefinement",
            "venue": "In Proceedings of the IEEE Conference",
            "year": 2022
        },
        {
            "authors": [
                "Issam H Laradji",
                "David Vazquez",
                "Mark Schmidt"
            ],
            "title": "Where are the masks: Instance segmentation with image-level supervision",
            "venue": "Proceedings of the British Machine Vision Conference,",
            "year": 2019
        },
        {
            "authors": [
                "Tsung-Yi Lin",
                "Michael Maire",
                "Serge Belongie",
                "James Hays",
                "Pietro Perona",
                "Deva Ramanan",
                "Piotr Doll\u00e1r",
                "C Lawrence Zitnick"
            ],
            "title": "Microsoft coco: Common objects in context",
            "venue": "Proceedings of the European Conference on Computer Vision, pages 740\u2013755,",
            "year": 2014
        },
        {
            "authors": [
                "Liu et al",
                "2020] Yun Liu",
                "Yu-Huan Wu",
                "Peisong Wen",
                "Yujun Shi",
                "Yu Qiu",
                "Ming-Ming Cheng"
            ],
            "title": "Leveraging instance-, image- and dataset-level information for weakly supervised instance segmentation",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Kevis-Kokitsi Maninis",
                "Jordi PontTuset",
                "Pablo Arbel\u00e1ez",
                "Luc Van Gool"
            ],
            "title": "Convolutional oriented boundaries: From image segmentation to highlevel tasks",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 40(4):819\u2013833,",
            "year": 2018
        },
        {
            "authors": [
                "Jia-Rong Ou",
                "Shu-Le Deng",
                "Jin-Gang Yu"
            ],
            "title": "Ws-rcnn: Learning to score proposals for weakly supervised instance segmentation",
            "venue": "Sensors, 21(10):3475,",
            "year": 2021
        },
        {
            "authors": [
                "Pont-Tuset et al",
                "2017] Jordi Pont-Tuset",
                "Pablo Arbel\u00e1ez",
                "Jonathan T. Barron",
                "Ferran Marques",
                "Jitendra Malik"
            ],
            "title": "Multiscale combinatorial grouping for image segmentation and object proposal generation",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2017
        },
        {
            "authors": [
                "Ren et al",
                "2020a] Zhongzheng Ren",
                "Zhiding Yu",
                "Xiaodong Yang",
                "Ming-Yu Liu",
                "Yong Jae Lee",
                "Alexander G. Schwing",
                "Jan Kautz"
            ],
            "title": "Instance-aware, context-focused, and memory-efficient weakly supervised object detection",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision",
            "year": 2020
        },
        {
            "authors": [
                "Ren et al",
                "2020b] Zhongzheng Ren",
                "Zhiding Yu",
                "Xiaodong Yang",
                "Ming-Yu Liu",
                "Alexander G. Schwing",
                "Jan Kautz"
            ],
            "title": "Ufo2: A unified framework towards omnisupervised object detection",
            "year": 2020
        },
        {
            "authors": [
                "Jinhwan Seo",
                "Wonho Bae",
                "Danica J Sutherland",
                "Junhyug Noh",
                "Daijin Kim. Object discovery via contrastive learning for weakly supervised object detection"
            ],
            "title": "In Proceedings of the European Conference on Computer Vision",
            "venue": "pages 312\u2013329,",
            "year": 2022
        },
        {
            "authors": [
                "Yunhang Shen",
                "Rongrong Ji",
                "Yan Wang",
                "Yongjian Wu",
                "Liujuan Cao. Cyclic guidance for weakly supervised joint detection",
                "segmentation"
            ],
            "title": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "venue": "pages 697\u2013707,",
            "year": 2019
        },
        {
            "authors": [
                "Shen et al",
                "2021] Yunhang Shen",
                "Liujuan Cao",
                "Zhiwei Chen",
                "Baochang Zhang",
                "Chi Su",
                "Yongjian Wu",
                "Feiyue Huang",
                "Rongrong Ji"
            ],
            "title": "Parallel detection-andsegmentation learning for weakly supervised instance segmentation",
            "venue": "In Proceedings of the IEEE International Con-",
            "year": 2021
        },
        {
            "authors": [
                "Karen Simonyan",
                "Andrew Zisserman. Very deep convolutional networks for large-scale image recognition"
            ],
            "title": "In Proceedings of the International Conference on Learning Representations",
            "venue": "pages 1\u201314,",
            "year": 2015
        },
        {
            "authors": [
                "Lin Sui",
                "Chen-Lin Zhang",
                "Jianxin Wu. Salvage of supervision in weakly supervised object detection"
            ],
            "title": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "venue": "pages 14207\u201314216,",
            "year": 2021
        },
        {
            "authors": [
                "Peng Tang",
                "Xinggang Wang",
                "Xiang Bai",
                "Wenyu Liu. Multiple instance detection network with online instance classifier refinement"
            ],
            "title": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "venue": "pages 3059\u20133067,",
            "year": 2017
        },
        {
            "authors": [
                "Peng Tang",
                "Xinggang Wang",
                "Song Bai",
                "Wei Shen",
                "Xiang Bai",
                "Wenyu Liu",
                "Alan Yuille"
            ],
            "title": "Pcl: Proposal cluster learning for weakly supervised object detection",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 42(1):176\u2013191,",
            "year": 2020
        },
        {
            "authors": [
                "Zhi Tian",
                "Chunhua Shen",
                "Hao Chen",
                "Tong He"
            ],
            "title": "Fcos: Fully convolutional one-stage object detection",
            "venue": "Proceedings of the IEEE International Conference on Computer Vision, pages 9627\u20139636,",
            "year": 2019
        },
        {
            "authors": [
                "Jasper RR Uijlings",
                "Koen EA Van De Sande",
                "Theo Gevers",
                "Arnold WM Smeulders. Selective search for object recognition"
            ],
            "title": "International Journal of Computer Vision",
            "venue": "104(2):154\u2013171,",
            "year": 2013
        },
        {
            "authors": [
                "Wan et al",
                "2019] Fang Wan",
                "Chang Liu",
                "Wei Ke",
                "Xiangyang Ji",
                "Jianbin Jiao",
                "Qixiang Ye"
            ],
            "title": "C-mil: Continuation multiple instance learning for weakly supervised object detection",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Wang et al",
                "2021] Jingdong Wang",
                "Ke Sun",
                "Tianheng Cheng",
                "Borui Jiang",
                "Chaorui Deng",
                "Yang Zhao",
                "Dong Liu",
                "Yadong Mu",
                "Mingkui Tan",
                "Xinggang Wang",
                "Wenyu Liu",
                "Bin Xiao"
            ],
            "title": "Deep high-resolution representation",
            "year": 2021
        },
        {
            "authors": [
                "Wang et al",
                "2022] Guanchun Wang",
                "Xiangrong Zhang",
                "Zelin Peng",
                "Xu Tang",
                "Huiyu Zhou",
                "Licheng Jiao"
            ],
            "title": "Absolute wrong makes better: Boosting weakly supervised object detection via negative deterministic information",
            "venue": "In Proceedings of the International Joint Conference on Ar-",
            "year": 2022
        },
        {
            "authors": [
                "Zeng et al",
                "2019] Zhaoyang Zeng",
                "Bei Liu",
                "Jianlong Fu",
                "Hongyang Chao",
                "Lei Zhang"
            ],
            "title": "Wsod2: Learning bottom-up and top-down objectness distillation for weakly-supervised object detection",
            "venue": "In Proceedings of the IEEE International Conference on Computer Vision,",
            "year": 2019
        },
        {
            "authors": [
                "Bolei Zhou",
                "Aditya Khosla",
                "Agata Lapedriza",
                "Aude Oliva",
                "Antonio Torralba. Learning deep features for discriminative localization"
            ],
            "title": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "venue": "pages 2921\u20132929,",
            "year": 2016
        },
        {
            "authors": [
                "Yanzhao Zhou",
                "Yi Zhu",
                "Qixiang Ye",
                "Qiang Qiu",
                "Jianbin Jiao. Weakly supervised instance segmentation using class peak response"
            ],
            "title": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "venue": "pages 3791\u20133800,",
            "year": 2018
        },
        {
            "authors": [
                "Zhu et al",
                "2019] Yi Zhu",
                "Yanzhao Zhou",
                "Huijuan Xu",
                "Qixiang Ye",
                "David Doermann",
                "Jianbin Jiao"
            ],
            "title": "Learning instance activation maps for weakly supervised instance segmentation",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Instance segmentation involves the simultaneous estimation of object location and masking segmentation, and it has made significant progress with the assistance of large datasets and instance-level annotations. However, process of obtaining instance-level annotations can be costly and time-consuming. As a solution, weak annotations such as box-level and imagelevel annotations have been utilized in instance segmentation. Among these weak annotations, the use of image-level annotations is the most cost-effective, but also the most challenging due to the difficulty of aligning coarse annotations with\n\u2217Corresponding Author\nthe finer task. Weakly supervised instance segmentation (WSIS), which involves using only image-level annotations, has experienced widespread growth in recent years. There are two main paradigms for addressing WSIS: proposal-based paradigm and proposal-free paradigm. The proposal-based paradigm [Zhou et al., 2018; Liu et al., 2020; Shen et al., 2021; Ou et al., 2021] assumes that an instance can be represented by a proposal, thus simplifying WSIS as a classification task. However, these approaches will result in impaired segmentation performance due to redundant segmentation , as illustrated in Figure 1. Typically, if we simply select a few results as output, the segmentation results will be the most discriminative parts of instances. In contrast, the proposal-free paradigm [Ahn et al., 2019; Kim et al., 2022] generates segmentation results online without proposals. During training, this paradigm relies on confident precomputed pseudo labels to achieve better performance. To leverage these pre-computed pseudo labels, IRNet [Ahn et al., 2019] utilizes Class Attention Maps (CAM) [Zhou et al., 2016] while BESTIE [Kim et al., 2022] uses weakly supervised semantic segmentation (WSSS) maps. The proposalfree paradigm is heavily dependent on pre-computed pseudo labels, which can limit its potential for further improvement.\nTo address the limitations mentioned above, we propose a novel proposal-based method that operates in an online refinement manner and consists of three key components: MaskIoU heads, a Complete Instances Mining (CIM) strat-\negy, and an Anti-noise strategy. Our method also utilizes pre-computed pseudo labels to warm up the model. Instead of using techniques such as random walk (RW) [Ahn et al., 2019] or conditional random fields (CRF) [Ge et al., 2019; Shen et al., 2019; Zhu et al., 2019] to mine complete instances, which can significantly slow down training process, our method employs MaskIoU heads to predict the integrity scores of proposals and the CIM strategy to mine complete instances. We then generate refined pseudo labels based on spatial relationships using the mined complete instances. Finally, the Anti-noise strategy ensures that our method does not suffer from significant performance degradation when pre-computed/refined pseudo labels are noisy.\nThe main contributions of our work are as follows:\n\u2022 We introduce the MaskIoU head to WSIS for the first time and propose an Anti-noise strategy to filter out noise caused by pre-computed pseudo labels and refined pseudo labels, improving the robustness of our method.\n\u2022 We explicitly address the problem called redundant segmentation and present an effective Complete Instances Mining (CIM) strategy to guide the network to pay more attention to complete instances.\n\u2022 Despite its simplicity, our method achieves state-of-theart performance on the PASCAL VOC 2012 and MS COCO datasets with a notable margin."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Weakly Supervised Object Detection",
            "text": "Multiple Instance Learning (MIL) is a popular paradigm for addressing weakly supervised object detection (WSOD), as it utilizes proposals generated by selective search [Uijlings et al., 2013] as a bag of instances.\nWSDDN [Bilen and Vedaldi, 2016] proposed a classification branch and a detection branch to output confident proposals as results, but this approach tends to predict the most discriminative parts of objects. To handle this issue, contextlocnet [Kantorov et al., 2016] introduced contextual information to a contrastive model. OICR [Tang et al., 2017] proposed an online instance classifier refinement strategy, which utilizes the proposals of the highest confidence as a pseudo label to supervise the next branch for improved performance. MIST [Ren et al., 2020a] considered the presence of multiple instances and employed Concrete DropBlock to mine complete instances. C-MIL [Wan et al., 2019] designed a novel MIL loss to avoid getting stuck into local minima, while PCL [Tang et al., 2020] transformed the single MIL problem into multiple MIL subproblems through clustering proposals. WSOD2 [Zeng et al., 2019] combined bottom-up and topdown objectness knowledge as evidence to discover complete instances in the candidates. NDI-WSOD [Wang et al., 2022] and OD-WSCL [Seo et al., 2022] approached WSOD through contrastive learning.\nAlthough WSIS is distinct from WSOD, it is worth noting that our approach was inspired by WSOD approaches and WSOD approaches can be easily transferred to WSIS."
        },
        {
            "heading": "2.2 Weakly Supervised Instance Segmentation",
            "text": "WSIS with only image-level annotations can be divided into two paradigms: proposal-based paradigm and proposal-free paradigm.\nFollowing the proposal-based paradigm, PRM [Zhou et al., 2018] used peaks in Peak Response Maps (PRM) as instance cues and combined them with CAM to predict instances. IAM [Zhu et al., 2019] generated Instance Activation Maps (IAM) through an extent filling module to identify complete instances. Label-PEnet [Ge et al., 2019] employed a cascaded pipeline in a coarse-to-fine manner to simultaneously perform classification, object detection, and instance segmentation. Arun et al. [Arun et al., 2020] used a conditional distribution to explicitly model the uncertainty, which enables pseudo labels to become more reliable. Fan et al. [Fan et al., 2018] and LIID [Liu et al., 2020] used instance saliency labels to support the generation of pseudo labels and considered the relationships in the training set. WS-RCNN [Ou et al., 2021] proposed an Attention-Guided Pseudo Labeling (AGPL) strategy and an Entropic OpenSet Loss to improve WSIS. PDSL [Shen et al., 2021] treated proposals as segmentation cues and proposed a framework for learning detection and segmentation in parallel. Our proposed method is similar to PDSL, but does not require additional segmentation branches due to the ability of proposals to effectively segment instances.\nFollowing the proposal-free paradigm, IRNet [Ahn et al., 2019] used displacement field to indicate instances and generate complete instances via Class Boundary Maps and random walk. BESTIE [Kim et al., 2022] transferred the knowledge of WSSS to WSIS by a strengthening constraint. While our method also leverages pre-computed pseudo labels, we design our approach in an online refinement manner and propose an Anti-noise strategy to reduce the dependence on these pre-computed labels.\nThorough comparisons of representative proposal-based and proposal-free methods show that outputs from these two paradigms focus on different aspects. Proposal-based methods tend to have higher recall and lower precision, while proposal-free methods exhibit the opposite. Despite these differences, there is not a significant gap in performance between the two paradigms. Previous proposal-based methods have effectively utilized the power of proposals, which not only consider bottom-up information of the image but also simplify the task. However, a convolutional neural network (CNN) trained for image classification typically results in redundant segmentation. To alleviate this problem, some researchers [Zhu et al., 2019; Arun et al., 2020; Ou et al., 2021] have made some attempts. In contrast, our method explicitly models this problem and addresses it through the Complete Instances Mining (CIM) strategy."
        },
        {
            "heading": "3 Proposed Method",
            "text": ""
        },
        {
            "heading": "3.1 Preliminary and Overview",
            "text": "Given an image I sized by HI\u00d7WI , and its image-level label Y \u2208 RC , where C is the number of categories and Yc = 1 indicates that image I contains the cth category, and otherwise, Yc = 0. To simplify the task, proposals R \u2208 RN\u00d7HI\u00d7WI are obtained using off-the-shelf proposal techniques [Pont-Tuset\net al., 2017; Maninis et al., 2018], where Rn is a binary segmentation mask and N indicates the number of proposals. In this work, we modify the image-level label Y \u2208 RC+1 to include the background category, denoted as Y0 = 1.\nOur method follows the proposal-based paradigm and consists of an Anti-noise branch and several Refinement branches, as illustrated in Figure 2. To begin, we obtain pre-computed pseudo labels using the AGPL strategy proposed by WS-RCNN [Ou et al., 2021]. Then, we use MaskFuse to extract proposal features and feed them into multiple branches. Finally, the CIM strategy explicitly models the redundant segmentation problem and generates refined pseudo labels. To further enhance the robustness of our network, we apply an Anti-noise strategy."
        },
        {
            "heading": "3.2 Reviewing AGPL",
            "text": "The AGPL strategy is a method for generating pseudo labels for a set of proposals in the WS-RCNN model. The method starts by training a classifier and producing CAM. For each target category c, confident peaks from CAM are selected as instance cues, denoted as pc = {pc1, pc2, \u00b7 \u00b7 \u00b7 , pci}, where pci means the ith peak in the cth category. For each peak, AGPL averages and thresholds proposals containing it to leverage support mask Sci , denoted the number of proposals as n c i .\nSci =  1 nci \u2211 pci\u2208Rn Rn  > 0.7, (1)\nThe AGPL strategy sorts the support mask set in descending order according to scores of peaks and assigns labels to proposals based on the IoU between the proposal and the support mask. The pre-computed pseudo labels of proposals are represented as y\u03020 \u2208 RN\u00d7{C+1}.\ny\u03020i,c = 1 if IoU(Ri, S c k) > 0.5 (2)\nDuring the labeling process, each proposal is assigned to only one category. Proposals that overlap with support masks but are not assigned to any categories are assigned as background. Finally, proposal clusters are generated based on whether proposals are assigned by the same support mask, with each background proposal being assigned as a single cluster. The proposal clusters set is denoted as H = {(C1,M1, s1), (C2,M2, s2), \u00b7 \u00b7 \u00b7 , (CN0 ,MN0 , sN0)}, where Cn, Mn, and sn represent the set of proposals, the number of proposals, and the label of the nth proposal cluster, respectively."
        },
        {
            "heading": "3.3 MaskFuse",
            "text": "In contrast to WSOD, WSIS utilizes binary masks as proposals rather than bounding boxes. As a result, RoIPool [Girshick, 2015] and RoIAlign [He et al., 2017] operations are not available for WSIS.\nTo address the lack of feature extraction operation in WSIS, we propose a lightweight operation called MaskFuse. The MaskFuse leverages the bounding box feature B \u2208 Rh\u00d7w\u00d7D obtained through the RoIAlign operation and\nAlgorithm 1 Complete Instances Mining (CIM) strategy Input: Image label Y , proposals R, classification scores yk\u22121, integrity scores tk\u22121 Parameter: NMS threshold \u03c4nms, containment threshold \u03c4con, percentage of seeds pseed Output: Pseudo ground truth P k\n1: P k = \u2205 2: for c = 1 to C do 3: if Yc = 1 then 4: // Step 1: selecting seeds 5: Rcls \u2190 Sort(yk\u22121\u2217,c ) 6: Rkeep \u2190 keep top pseed percent of Rcls 7: indseed = NMS(Rkeep, \u03c4nms) 8: // Step 2: mining pseudo ground truth 9: Calculate matrix M \u2208 RN\u00d7N ,Mi,j = Ri\u2229RjRj\n10: Mcon = M [:, indseed] > \u03c4con 11: indgt = argmax(Mcontk\u22121\u2217,c , dim = 0) 12: P kc .append(R[indgt]) 13: end if 14: end for\nextracts the corresponding proposal Rcrop \u2208 Rh\u00d7w using the RoICrop operation. Then, we concatenate Rcrop \u2299 B with B and utilize a convolutional layer and two fully connected layers to fuse features from mask-level and box-level. The MaskFuse allows each proposal to be represented by a feature with contextual information, enabling WSOD methods to be transferred to WSIS."
        },
        {
            "heading": "3.4 Refinement Branch",
            "text": "The MaskIoU head, proposed by MS R-CNN [Huang et al., 2019], and the center-ness head, proposed by FCOS [Tian et al., 2019], are designed to learn the quality of predicted results (i.e., masks and bounding boxes) in their respective methods. However, this powerful head is missing in WSIS. To fill this gap, we implement the MaskIoU head into our framework.\nGiven proposal features, the kth Refinement branch produces two matrixes yk, tk \u2208 RN\u00d7{C+1} from classification and MaskIoU heads, which represent the classification and integrity scores, respectively. Furthermore, we employ the CIM strategy to produce refined pseudo labels from preceding branch, denoted as y\u0302k, t\u0302k. Following OICR [Tang et al., 2017], we also propose loss weights wk \u2208 RN to mitigate the degradation caused by noisy refined pseudo labels.\nLkref =\u2212 1\nNfg +Nbg N\u2211 n=1 C\u2211 c=0 wkn y\u0302 k n,c log y k n,c\n+ 1\nNfg N\u2211 n=1 C\u2211 c=1 wkn y\u0302 k n,cLSmooth\u2212L1(t\u0302kn,c \u2212 tkn,c)\n(3)\nwhere Nfg and Nbg represent number of foreground and background. LSmooth\u2212L1 indicates smooth-L1 loss [Girshick, 2015]."
        },
        {
            "heading": "3.5 Complete Instances Mining (CIM)",
            "text": "Motivated by redundant segmentation, we propose a novel Complete Instances Mining (CIM) strategy. CIM can be divided into two steps: selecting seeds and mining pseudo ground truth. The first step is similar to the operation of MIST [Ren et al., 2020a] strategy.\nLet\u2019s start with a simple modeling of redundant segmentation. As we expected, partial segmentations typically have high classification scores and low integrity scores, while complete segmentations have the opposite. Additionally, partial segmentations are often spatially contained within complete segmentations. Hence, we utilize classification and integrity scores as metrics for CIM, illustrated in Algorithm 1. CIM awares multiple instances through selecting seeds, which maintains a high recall of pseudo ground truth. For each seed, the proposal that contains it and has the highest integrity score is considered as its corresponding pseudo ground truth. Mining pseudo ground truth enables our method to identify complete instances by aggregating multiple seeds.\nTo collect more pseudo labels, we assign refined pseudo labels to all proposals. For each proposal, if it highly overlaps with pseudo ground truth, we consider its classification target to be the category of pseudo ground truth. \u03c4cls is a hyperparameter.\ny\u0302ki,c = { 1 if max(IoU(Ri, P kc )) > \u03c4cls 0 otherwise (4)\nThe integrity target is determined in the same way. \u03c4iou is also a hyper-parameter.\nt\u0302ki,c = { 1 if max(IoU(Ri, P kc )) > \u03c4iou 0 otherwise (5)\nIn which, \u03c4iou is typically greater than \u03c4cls. The loss weight for each proposal can be calculated using Equation 6, where c and j indicate the category and index of pseudo ground truth that has the largest overlap with the Ri, respectively.\nwki = y k\u22121 j,c t k\u22121 j,c (6)\nWe follow the rule mentioned in Section 3.2 to assign background labels. To further improve performance, we implement a cascaded threshold \u03c4cas into our framework inspired by Cascade R-CNN [Cai and Vasconcelos, 2018]. This involves modifying \u03c4cls and \u03c4iou in the kth Refinement branch to \u03c4cls + (k \u2212 1) \u03c4cas and \u03c4iou + (k \u2212 1) \u03c4cas, respectively."
        },
        {
            "heading": "3.6 Anti-Noise Strategy",
            "text": "High-quality pre-computed pseudo labels facilitate the network in achieving faster convergence and better performance. However, noise in these labels can confuse the network and lead to overfitting. Similarly, noisy refined pseudo labels also degrade segmentation performance. To address these issues, we propose an Anti-noise strategy comprising an Anti-noise branch and an Anti-noise sampling strategy.\nAnti-noise branch. We adopt the WSDDN branch [Bilen and Vedaldi, 2016] as the Anti-noise branch. Similar to the Refinement branches, it also produces two matrixes y0, t0 \u2208 RN\u00d7{C+1} from classification head and Anti-noise head. Then, image-level score can be obtained by yI =\nLanti =\u2212 1\nC + 1 C\u2211 c=0 {Yc log yIc + (1\u2212 Yc) log(1\u2212 yIc )}\n\u2212 \u03b1 Nfg +Nbg N0\u2211 i=1 C\u2211 c=0 Mi si,c log \u2211 n\u2208Ci y0n,c Mi\n(7)\nHere, the hyper-parameter \u03b1 is set to 12 by default. Espe-\ncially, the Anti-noise head is not directly guided, which en-\nables it to filter out noise in pre-computed pseudo labels.\nAnti-noise sampling. Refined pseudo labels also contain noise, as constraints of the CIM strategy are relaxed. Our observations suggest that noisy labels tend to have lower loss weights. Based on this insight, we adopt an Anti-noise sampling strategy that treats loss weights as sampling probabilities to sample pseudo ground truth P k. Specifically, we im-\nplement sampling with replacement to filter out noise in refined pseudo labels.\nIn summary, the objective function can be written as:\nLtotal = Lanti + K\u2211\nk=1\nLkref (8)\nwhere K is set to 3 by default."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Datasets and Evaluation Metrics",
            "text": "Following previous methods, we also evaluate our method on PASCAL VOC 2012 [Everingham et al., 2010] and MS COCO [Lin et al., 2014] datasets. The VOC 2012 dataset includes 10,582 images for training and 1,449 images for validation, comprising 20 object categories. The COCO dataset comprises 115K training, 5K validation, and 20K testing images across 80 object categories. Following previous methods, we report the mean average precision (mAP ) with IoU thresholds of 0.25, 0.5, 0.7, and 0.75 for VOC 2012 and report mAP with IoU thresholds from 0.5 to 0.95 for COCO."
        },
        {
            "heading": "4.2 Implementation Details",
            "text": "Our method is implemented in PyTorch and experiments are conducted on an Nvidia RTX 3090. We use COB [Maninis et al., 2018] method to generate proposals for all experiments and utilize ResNet50 [He et al., 2016] as the backbone. As we using mAP25 and mAP50 as evaluation metrics, we set classification \u03c4cls and integrity \u03c4iou thresholds to 0.25 and 0.5, respectively. The cascaded threshold \u03c4cas is set to 0.1. \u03c4nms, and pseed in Algorithm 1 are set to \u03c4cls, and 0.1, respectively. Containment threshold \u03c4con is set to 0.85 following SoS [Sui et al., 2021]. Although there are many hyper-parameters, we only tune values of \u03c4cas and pseed.\nDuring training, we use the SGD optimization algorithm with an initial learning rate of 2.5 \u00d7 10\u22124 and a weight decay of 5\u00d7 10\u22124. We adopt a step learning rate decay schema with a decay weight of 0.1 and set the mini-batch size to 4.\nThe total number of training iterations is 4.5 \u00d7 104 for the VOC 2012 dataset and 24 \u00d7 104 iterations for the COCO dataset. For data augmentation, we apply five image scales {480, 576, 688, 864, 1200} with random horizontal flips for both training and testing. During testing, we employ the product of classification and integrity scores as the output of each Refinement branch and average these outputs as the final scores. Following previous methods, we also generate pseudo labels from our method for training Mask R-CNN."
        },
        {
            "heading": "4.3 Comparison With State-of-the-Art",
            "text": "We compare the performance of our method with previous state-of-the-art WSIS methods, as shown in Table 1 and Table 2. For a fair comparison, we also report the results obtained with different backbones, i.e., VGG-16 [Simonyan and Zisserman, 2015] and HRNet-W48 [Wang et al., 2021]. Note that MIST is originally an object detection method, and we adapt it to the WSIS task for comparison.\nOur proposed method outperforms all previous methods on both datasets, achieving higher performance than LIID [Liu et al., 2020] even without the use of instance saliency labels, demonstrating that such labels are not necessary for further advancement in WSIS. Additionally, our method demonstrates a 4.9% and 1.7% improvement in terms of mAP50 on the VOC 2012 and COCO, respectively, when compared with BESTIE [Kim et al., 2022]. Thanks to impressive semantic segmentation maps produced by WSSS, BESTIE achieves excellent performance on simple images, i.e., single instance, multiple non-adjacent instances, and multiple instances of different categories. However, BESTIE tends to produce grouping instances results caused by its strengthening constraints, illustrated in the second row of Figure 3. In contrast, we follow the proposal-based paradigm which always results in redundant segmentation rather than grouping instances. Hence, we propose CIM to mine complete instances, illustrated in the third row of Figure 3.\nAlthough my approach may appear overly complex, it is implemented using only one linear layer per head, and its training can be completed in a few hours, as shown in Table 3.\nMeanwhile, the code implementation of CIM is simple."
        },
        {
            "heading": "4.4 Ablation Study",
            "text": "We conduct several ablation studies on the VOC 2012 dataset to evaluate the effectiveness of each component. In these studies, we use ResNet-50 as the backbone and do not apply Mask R-CNN to save time. When the CIM strategy is unavailable, we adopt MIST [Ren et al., 2020a] strategy to replace it and adapt \u03c4cls and \u03c4nms to 0.5.\nImpact of AGPL As shown in Table 4, the use of AGPL results in an improvement in segmentation performance, with an increase of 49.2% and 20.6% in terms of mAP50 and mAP75, respectively. Although AGPL produces reliable pre-computed pseudo labels, it only provides coarse complete instance cues, leading to a significant improvement in mAP50 but little gain in mAP75.\nImpact of MaskIoU and CIM As shown in Table 4, the performance is slightly improved when the MaskIoU heads are applied alone because the distri-\nbution of refined pseudo labels does not change. By employing the CIM strategy, our method achieves a 1.3% and 2.4% improvement in terms of mAP50 and mAP75, respectively. This demonstrates that our method can effectively mine complete instances, resulting in improved performance for stricter metrics, i.e., mAP75.\nImpact of Cascaded Threshold Furthermore, the cascaded threshold design allows our method to operate in a coarse-to-fine manner. As shown in the last row of Table 4, the cascaded threshold results in a 1.0% and 2.3% improvement in terms of mAP50 and mAP75, respectively, as it guides deeper Refinement branches to focus on more complete instances.\nWe also evaluate the seeds and pseudo ground truth generated by CIM, as shown in Figure 4. It is obvious that pseudo ground truth outperforms seeds and deeper Refinement branch performs better. As reported in the Table 5, the effect of different cascade thresholds is small.\nImpact of Anti-Noise Strategy Following UFO2[Ren et al., 2020b], we treat the precomputed pseudo labels as ground truth and apply a KLdivergence loss on the Anti-noise head, which reduces its performance to 50.4% in terms of mAP50. This result suggests that redundant parameters in the Anti-noise head effectively filter out noise in pre-computed pseudo labels.\nTo further evaluate the impact of Anti-noise sampling, we introduce noise by increasing the number of seeds in the CIM process. As shown in Table 6, the use of Anti-noise sampling increases the robustness of our method."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this paper, we propose a proposal-based approach in an online refinement manner to address the redundant segmentation problem. Our method incorporates the MaskIoU head and utilizes the CIM strategy to mine complete instances without resorting to RW or CRF. Additionally, we propose the Anti-noise strategy to filter out noise in pseudo labels. Our approach demonstrates state-of-the-art performance on the VOC 2012 and COCO datasets. Moving forward, we expect to investigate methods to enhance the robustness of the model without resorting to Anti-noise sampling strategy that may complicate the analysis."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was funded by Natural Science Foundation of China under Grants No. 62076099 and No. 61703166."
        }
    ],
    "title": "Complete Instances Mining for Weakly Supervised Instance Segmentation",
    "year": 2023
}