{
    "abstractText": "A new bound on the error probability of coding with limited code length over additive white Gaussian noise (AWGN) channels is proposed. The developed bound is proved to be universal for two connected encoding ways. On the one hand, we conceive folding the conventional codes, such as Hadamard and binary random ones, in order to adapt shorter code length. On the other hand, we further extend the above folded structure to Gaussian random coding and hence to bound its error probability. Finally, we demonstrate that the bound of the above two constructions can be unified as \u221a log2e 2\u03c0nC2 \u2212n(C/2\u2212R) where C represents the capacity of the AWGN channel, n and R stand for the code length and rate, respectively. This theoretical contribution confirms that, in the context of short code length and low rate, the developed two constructions exhibit excellent performance even close to the Shannon bound on AWGN channels. INDEX TERMS AWGN, Hadamard code, binary random code, capacity.",
    "authors": [
        {
            "affiliations": [],
            "name": "DENGSHENG LIN"
        },
        {
            "affiliations": [],
            "name": "YUE XIAO"
        }
    ],
    "id": "SP:2a99fced44e5cbbd6774f41c0ae80f5d2cd0a952",
    "references": [
        {
            "authors": [
                "C. Berrou",
                "A. Glavieux",
                "P. Thitimajshima"
            ],
            "title": "Near Shannon limit error correcting coding and decoding: Turbo-codes. 1",
            "venue": "Proc. IEEE Int. Conf. Commun., May 1993, pp. 1064\u20131070.",
            "year": 1993
        },
        {
            "authors": [
                "R.G. Gallager"
            ],
            "title": "Low-density parity-check codes",
            "venue": "IRE Trans. Inf. Theory, vol. IT-8, no. 1, pp. 21\u201328, Jan. 1962.",
            "year": 1962
        },
        {
            "authors": [
                "D.J.C. MacKay",
                "R.M. Neal"
            ],
            "title": "Near Shannon limit performance of low density parity check codes",
            "venue": "IEE Electron. Lett., vol. 33, pp. 457\u2013458, Mar. 1997.",
            "year": 1997
        },
        {
            "authors": [
                "S.Y. Chung",
                "G.D. Forney",
                "Jr.",
                "T.J. Richardson",
                "R. Urbanke"
            ],
            "title": "On the design of low-density parity-check codes within 0.0045 dB of the Shannon limit",
            "venue": "IEEE Commun. Lett., vol. 5, no. 2, pp. 58\u201360, Feb. 2001.",
            "year": 2001
        },
        {
            "authors": [
                "E. Arikan"
            ],
            "title": "Channel polarization: A method for constructing capacityachieving codes for symmetric binary-input memoryless channels",
            "venue": "IEEE Trans. Inf. Theory, vol. 55, no. 7, pp. 3051\u20133073, Jul. 2009.",
            "year": 2009
        },
        {
            "authors": [
                "C.E. Shannon"
            ],
            "title": "A mathematical theory of communication",
            "venue": "Bell Syst. Tech. J., vol. 27, no. 3, pp. 379\u2013423, Jul. 1948.",
            "year": 1948
        },
        {
            "authors": [
                "R.G. Gallager"
            ],
            "title": "A simple derivation of the coding theorem and some applications",
            "venue": "IEEE Trans. Inf. Theory, vol. 11, no. 1, pp. 3\u201318, Jan. 1965.",
            "year": 1965
        },
        {
            "authors": [
                "M. Shirvanimoghaddam"
            ],
            "title": "Short block-length codes for ultrareliable low latency communications",
            "venue": "IEEE Commun. Mag., vol. 57, no. 2, pp. 130\u2013137, Feb. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "E. Arikan"
            ],
            "title": "Serially concatenated polar codes",
            "venue": "IEEE Access, vol. 6, pp. 64549\u201364555, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "D. Baron",
                "M.A. Khojastepour",
                "R.G. Baraniuk"
            ],
            "title": "How quickly can we approach channel capacity?",
            "venue": "in Proc. 38th Asilomar Conf. Signals Syst. Comput.,",
            "year": 2004
        },
        {
            "authors": [
                "Y. Polyanskiy",
                "H.V. Poor",
                "S. Verdu"
            ],
            "title": "Channel coding rate in the finite blocklength regime",
            "venue": "IEEE Trans. Inf. Theory, vol. 56, no. 5, pp. 2307\u20132359, May 2010. 460 VOLUME 3, 2022",
            "year": 2010
        },
        {
            "authors": [
                "C.E. Shannon"
            ],
            "title": "Certain results in coding theory for noisy channels",
            "venue": "Inf. Control, vol. 1, pp. 6\u201325, Sep. 1957.",
            "year": 1957
        },
        {
            "authors": [
                "C.E. Shannon",
                "R.G. Gallager",
                "E.R. Berlekamp"
            ],
            "title": "Lower bounds to error probability for coding on discrete memoryless channels I",
            "venue": "Inf. Control, vol. 10, no. 1, pp. 65\u2013103, 1967.",
            "year": 1967
        },
        {
            "authors": [
                "G. Poltyrev"
            ],
            "title": "Bounds on the decoding error probability of binary linear codes via their spectra",
            "venue": "IEEE Trans. Inf. Theory, vol. 40, no. 4, pp. 1284\u20131292, Jul. 1994.",
            "year": 1994
        },
        {
            "authors": [
                "H.V. Poor",
                "S. Verdu"
            ],
            "title": "A lower bound on the error probability in multihypothesis testing",
            "venue": "IEEE Trans. Inf. Theory, vol. 41, no. 6, pp. 1992\u20131993, Nov. 1995.",
            "year": 1992
        },
        {
            "authors": [
                "D.E. Lazic",
                "T. Beth",
                "S. Egner"
            ],
            "title": "Constrained capacity of the AWGN channel",
            "venue": "Proc. IEEE Int. Symp. Inf. Theory (ISIT), Cambridge, MA, USA, 1998, p. 237.",
            "year": 1998
        },
        {
            "authors": [
                "C.E. Shannon"
            ],
            "title": "Probability of error for optimal codes in a Gaussian channel",
            "venue": "Bell Syst. Tech. J., vol. 38, no. 3, pp. 611\u2013656, May 1959.",
            "year": 1959
        },
        {
            "authors": [
                "A. Valembois",
                "M.P.C. Fossorier"
            ],
            "title": "Sphere-packing bounds revisited for moderate block lengths",
            "venue": "IEEE Trans. Inf. Theory, vol. 50, no. 12, pp. 2998\u20133014, Dec. 2004.",
            "year": 2004
        },
        {
            "authors": [
                "G. Wiechman",
                "I. Sason"
            ],
            "title": "An improved sphere-packing bound for finite-length codes over symmetric memoryless channels",
            "venue": "IEEE Trans. Inf. Theory, vol. 54, no. 5, pp. 1962\u20131990, May 2008.",
            "year": 1962
        },
        {
            "authors": [
                "R.G. Gallager"
            ],
            "title": "Information Theory and Reliable Communication",
            "venue": "New York, NY, USA: Wiley,",
            "year": 1968
        },
        {
            "authors": [
                "Y. Polyanskiy"
            ],
            "title": "A perspective on massive random-access",
            "venue": "Proc. IEEE Int. Symp. Inf. Theory (ISIT), Aug. 2017, pp. 2523\u20132527.",
            "year": 2017
        },
        {
            "authors": [
                "W.K.R. Leung",
                "G. Yue",
                "L. Ping",
                "X. Wang"
            ],
            "title": "Concatenated zigzag hadamard codes",
            "venue": "IEEE Trans. Inf. Theory, vol. 52, no. 4, pp. 1711\u20131723, Apr. 2006.",
            "year": 2006
        },
        {
            "authors": [
                "R. Yarlagadda",
                "J. Hershey"
            ],
            "title": "Hadamard Matrix Analysis and Synthesis: With Applications to Communications and Signal/Image Processing",
            "year": 1997
        },
        {
            "authors": [
                "S. Lin",
                "D. Costello"
            ],
            "title": "Error Control Coding",
            "venue": "Upper Saddle River, NJ, USA: Prentice-Hall,",
            "year": 2004
        },
        {
            "authors": [
                "J.M. Wozencraft",
                "I.M. Jacobs"
            ],
            "title": "Principles of Communication Engineering",
            "year": 1965
        },
        {
            "authors": [
                "W. Feller"
            ],
            "title": "An Introduction to Probability Theory and Its Applications",
            "venue": "DENGSHENG LIN (Member,",
            "year": 1971
        }
    ],
    "sections": [
        {
            "text": "demonstrate that the bound of the above two constructions can be unified as \u221a\nlog2e 2\u03c0nC2 \u2212n(C/2\u2212R) where C represents the capacity of the AWGN channel, n and R stand for the code length and rate, respectively. This theoretical contribution confirms that, in the context of short code length and low rate, the developed two constructions exhibit excellent performance even close to the Shannon bound on AWGN channels.\nINDEX TERMS AWGN, Hadamard code, binary random code, capacity.\nI. INTRODUCTION THEGREAT progress on channel coding has been madein the recent three decades [1]\u2013[5], toward achieving the capacity with affordable implementation complexity. More explicitly, three kinds of milestone coding techniques, as Turbo code [1], low-density parity-check(LDPC) code [2]\u2013[4] and polar code [5], nowadays have been at the center of attention of the coding community, by offering powerful forward error control (FEC) capability for modern cellular mobile communication systems [6], [7]. Despite the outstanding performance in practical use, current theoretical analysis works such as [5] have proven that the Shannon capacity can be ultimately reached on discrete memoryless channels. According to the classical coding theorem, the capacityachieving FEC depends on the increase of the code length [8], due to the fact that in the asymptotic regime, the block error ratio (BLER) can decrease exponentially with the code length. This phenomenon can be described as [8]\nPe < 2 \u2212n(C\u2212R),\nwhere n means code length, C and R stand for the capacity and the rate, respectively. The above theoretical proof is based on the so-called asymptotic equipartition property (AEP) [9]. Meanwhile, Gallager also developed another theoretical proof in [10] resulting in\nPe < exp(\u2212nE(R)), where\nE(R) = max \u03c1,pk (\u2212\u03c1R+ E0(\u03c1, pk))\nis termed as error exponent while \u03c1 is a real number between (0, 1]. And\nEo(\u03c1, pk) = \u2212log \u239b \u239d\nJ\u2211 i=1 ( K\u2211 k=1 pkP 1/(1+\u03c1) i,k )1+\u03c1\u239e \u23a0,\nin which pk represents the probability of input alphabet of K symbols while Pi,k denotes the channel transition probability with J output symbols. Therefore, the optimal rate R (0 \u2264 R < C) can be achieved by maximizing Eo(\u03c1, pk) over \u03c1 and input probabilities pk [10].\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nVOLUME 3, 2022 453\nLIN AND XIAO: NEW BOUND TO ERROR PROBABILITY ON AWGN CHANNELS\nThe above-mentioned theoretical results are attained based on the assumption that the code length is enough large. However, for some recently emerging scenarios such as ultrareliable low latency communications (URLLC) [11], [12], the code length will be limited to a finite extent in order to shorten the time delay, while the reliability is still expected to remain an ultra high level, such as an error probability of 10\u22125 within 1 millisecond described in [11]. As a result, this scenario will bring double challenges for channel coding. Unfortunately, most of the existing coding techniques [13]\u2013[16] only work well in the middle-reliability region instead of the highreliability one, which motivates us to focus on this region in the context of limited code length. Meanwhile, it has become crucial to evaluate the coding performance in the non-asymptotic regime [17]. Although for finite length, there is no exact expression to bridge the coding parameters and the error probability [18], most researches tended to utilize attainable inequalities and approximations to bound the performance of various families of short codes [19]\u2013[23]. Specifically, C. E. Shannon firstly proposed a tight lower bound of error probability over additive white Gaussian noise (AWGN) channels based on packing spherical cones [24]. More sphere-packing bounds for moderate code length were derived in [25] and [26]. Gallager further developed another new bound based on Gaussian random coding [27]. In [18], Polyanskiy et al. introduced a series of new lower and upper bounds for finite-length codes on various channels including the binary symmetric channel, binary erasure channel and AWGN channel. Especially, an exact normal approximation was also proposed as a uniform expression for classic channels, written as\nPe \u2248 Q (\u221a n\nv (C \u2212 R)\n)\nwhere Q(\u00b7) represents the complementary Gaussian cumulative distribution function and v is channel dispersion defined as the variance of information density under the capacity achieving distribution of codewords. In the context of AWGN channel, for example, channel dispersion is given as\nv = P(P+ 2) 2(P+ 1)2 log 2 2(e),\nwhere P denotes the transmit power [18]. Following the above-mentioned current theoretical works, a new upper bound of error probability is developed in this\ncontribution for coding in AWGN channels, in order to theoretically disclose the high-reliability region under limited code length. Specifically, the bound is obtained by folding the conventional codes such as Hadamard and binary random ones. Furthermore, we extend this structure to Gaussian random coding. Through theoretical derivation, we demonstrate that all the above coding structures considered exhibit a uniform bound of error probability on AWGN channels, which can be briefly expressed in advance as\nPe <\n\u221a log2e\n2\u03c0nC 2\u2212n(C/2\u2212R).\nThe above theoretical result achieved in this work has the potential to be a new guidance for coding design. On the one hand, the bound indicates that this way of coding can only achieve a half of the capacity of the AWGN channel when the code length n approaches infinity. On the other hand, we can also exhibit that under limited code length and low code rate, this coding mechanism performs excellently owing to its outstanding error exponent, even close to the Shannon\u2019s bound [24]. In general, this coding technique is demonstrated to have the potential to adapt URLLC in the context of high interference, such as massive random-access [28]. The remainder of this manuscript is organized as follows. Section II firstly introduces the concept of code folding, while quantifying its capacity on the AWGN channel. According to the disclosed properties of the folding channel, an upper bound of block error probability on AWGN channel is proposed based on folding the Hadamard code. Furthermore, by extending the code folding structure into a general configuration as the binary random code, the theoretical bound is quantified as an identical form in Section III. Furthermore, Section IV extends the above coding way into Gaussian random coding with theoretical analysis. The numerical results are then presented in Section V, while our concluding remarks are provided in Section VI."
        },
        {
            "heading": "II. FOLDING THE HADAMARD CODE",
            "text": ""
        },
        {
            "heading": "A. THE WAY OF CODE FOLDING AND ITS CAPACITY",
            "text": "In order to reduce the code length while maintaining the amount of information bits, we firstly consider folding a conventional code as described in Fig. 1. In general, the original code is described as [x0,0, x0,1, . . . , x0,n\u22121; x1,0, x1,1, . . . , x1,n\u22121; xnf\u22121,0, xnf\u22121,1, . . . , xnf\u22121,n\u22121] with length\n454 VOLUME 3, 2022\nns, whose symbols xi,j, i = 0, 1, . . . , nf \u2212 1, j = 0, 1, . . . , n\u2212 1, are real numbers while obeying standard normal distribution. Then the original code is folded into nf dimensions where the ith dimension with length n is described as xi,j, j = 0, 1, . . . , n \u2212 1. Apparently, the code length is reduced from ns to n = ns/nf by folding the original code into the ultimate super-symbols as\nx\u2032j = nf\u22121\u2211 i=0 \u221a aixi,j, (1)\nwhere ai stands for the power scaler of each dimension. Then the folded super-symbols are transmitted through the AWGN channel as\nyj = x\u2032j + zj, (2) where zj is the noise term with standard normal distribution. We substitute Eq. (1) into Eq. (2) and let\nx\u2032i\u22121,j = i\u22121\u2211 t=0 \u221a atxt,j, (3) x\u2032\u2032i+1,j = nf\u22121\u2211 t=i+1 \u221a atxt,j (4)\nand\nyi,j = yj \u2212 x\u2032i\u22121,j (5) for i > 0. Then Eq. (2) can be rewritten as yi,j = \u221aaixi,j + x\u2032\u2032i+1,j + zj. (6) Suppose that the decoder can perfectly recover x\u2032i\u22121,j step by step, so yi,j can be correctly achieved. In this case, the interference to xi,j is determined by x\u2032\u2032i+1,j. We further define the ith sub-channel as yi,j = \u221aaixi,j + zi,j, (7) where\nzi,j = x\u2032\u2032i+1,j + zj. (8) Clearly, the ith sub-channel is also an AWGN channel with mean 0 and variance\n\u03c3 2i = \u23a7 \u23aa\u23a8 \u23aa\u23a9 nf\u22121\u2211 t=i+1\nat + 1, i < nf \u2212 1 1, i = nf \u2212 1.\n(9)\nSo the SNR of the ith sub-channel is expressed as\nSi = ai \u03c3 2i . (10)\nTo keep the SNR of each sub-channel as a constant Sf , combining Eq. (9) and Eq. (10), we arrive at\nai = Sf ( Sf + 1 )i . (11)\nWe demonstrate that there exists a power scaler ai for each sub-channel to keep a constant SNR. Thus, the transmit super-symbol x\u2032j is with power\na = nf\u22121\u2211 i=0 ai\n= (Sf + 1 )nf \u2212 1. (12)\nThe capacity of the AWGN channel with SNR S = a is then expressed as\nC = 1 2 log2(1 + S). (13)\nOn the other hand, following (12), we have\nlog2(1 + S) = nf log2 ( 1 + Sf ) , (14)\ni.e.,\nC = nf Cf , (15) where\nCf = 1 2 log2\n( 1 + Sf ) (16)\nis the capacity of the sub-channel. The above result shows that the way of code folding will not reduce the capacity of the AWGN channel."
        },
        {
            "heading": "B. FOLDING THE HADAMARD CODE",
            "text": "Following the above-mentioned structure, we tend to fold conventional Hadamard code as an example. At the beginning, an ns \u00d7 ns Hadamard matrix can be recursively constructed as [29]\nHns = [ Hns/2 Hns/2 Hns/2 \u2212Hns/2 ] . (17)\nLet H1 = 1, while considering all of the row vectors in Hns as the codewords, then the matrix can carry k = log2ns information bits. Based on the properties of Hadamard code, the inner product of any pair of row vectors will be zero [30]. In other words, their Euclidean distance d is equal to \u221a 2ns. Note that, since Hadamard code is a kind of binary code, it doesn\u2019t strictly satisfy the condition of Gaussian folded noise introduced in Section II-A. However, in the following Section IV-A, we will theoretically demonstrate that the folded Hadamard code can approach Gaussian distribution when nf goes to infinity. Based on the union bound, the block error rate of the code in the AWGN channel with SNR Sf can be described as [31]\nPe \u2264 2kQ (\u221a\nns 2 Sf\n) , (18)\nwhere\nQ(x) = \u222b +\u221e x 1\u221a 2\u03c0 exp (\u2212t2 2 ) dt. (19)\nVOLUME 3, 2022 455\nLIN AND XIAO: NEW BOUND TO ERROR PROBABILITY ON AWGN CHANNELS\nNote that, the Hadamard code is now expected to be now transmitted in the folded Gaussian channel, according to the process of Fig. 1. Then the symbols from different dimensions nf are overlapped to generate the transmit symbol x\u2032j, j = 0, 1, . . . , n \u2212 1. Consequently, the folded code is with length n and rate R = k/n. Following the definition of the folded channel, there are nf AWGN sub-channels with constant SNR Sf . So Eq. (18) holds for the folded channel. By substituting Eq. (14) into Eq. (18), we have\nPe \u2264 2kQ (\u221a 1\n2 nnf ( (S+ 1)1/nf \u2212 1)\n) . (20)\nThen, the following limit holds as\nlim nf\u2192\u221e\nnf ( (S+ 1)1/nf \u2212 1 )\n= log(S+ 1) = 2C log2e . (21)\nTherefore, when nf \u2192 \u221e, substituting Eq. (21) into Eq. (20), we have\nPe \u2264 2kQ (\u221a nC\nlog2e\n) . (22)\nFurthermore, considering [32]\nQ(x) < 1\u221a 2\u03c0x exp\n( \u2212x 2\n2\n) , (23)\nwe finally arrive at\nPe <\n\u221a log2e\n2\u03c0nC 2\u2212n(C/2\u2212R). (24)\nThe above result exhibits that the block error probability of the folded Hadamard code is exponentially descending with the code length only if the rate is less than C/2. Clearly, the bound cannot achieve the Shannon capacity which requires R asymptotically close to C along with the code length. However, in the context of low code rate and short code length, the bound exhibits excellent good performance owing to its excellent error exponent. At the receiver, to achieve the bound, a successive interference cancellation algorithm is assumed to perfectly recover the symbols from the sub-channels step by step. Otherwise, the performance will decrease. Moreover, the complexity of decoding is a function of ns, which is normally much larger than the code length n. In Section IV, we will demonstrate that the proposed code is actually equivalent to Gaussian random code. In this case, the complexity of decoding will decrease to be a function of n."
        },
        {
            "heading": "III. FOLDING THE BINARY RANDOM CODE",
            "text": "For the Hadamard code, ns is always equal to 2k. It implies that the information length k will go to infinity along with nf \u2192 \u221e. So the bound shown in Eq. (24) only holds for infinite information length. In the following, we will demonstrate that Eq. (24) still holds even if we break through the\noriginal limitation of the equivalent distance property of the Hadamard code, so as to develop a general way of folding the binary random code. Since there is no fixed relation between k and ns for the binary random code, it allows the existence of finite k with infinite ns and nf . As a result, the bound will be extended to the configuration of arbitrary code rate and code length. By uniformly selecting 2k binary sequences with length ns, the Hamming distance between any two sequences will obey binomial distribution with mean ns/2 and variance ns/4. Meanwhile, it will converge to normal distribution with ns going to infinity based on De Moivre-Laplace theorem [33]. In other words, the squared Euclidean distance between any two sequences obeys normal distribution with mean ns/2 and variance ns/4. Then the probability density function (PDF) of the Euclidean distance can be written as\nPd(x) = \u23a7 \u23a8 \u23a9 \u221a 2x\u221a \u03c0\u03c3 2S exp ( \u2212 ( x2\u2212\u03bcs )2 2\u03c3 2s ) , x \u2265 0\n0, x < 0, (25)\nwhere \u03bcs = ns/2, \u03c3 2s = ns/4. Therefore, the BLER can be further expressed as\nPe = 2kPe1, (26) where\nPe1 = \u222b \u221e\n0 Pd(x)Q\n(\u221a Sf x ) dx. (27)\nThe integral in Eq. (27) cannot be obtained directly. Therefore, we define \u03bb \u2208 (0, 1) and split the above integral into two terms as\nPe1 = \u222b \u03bb\u221ans/2\n0 Pd(x)Q\n(\u221a Sf x ) dx\n+ \u222b \u221e\n\u03bb \u221a ns/2\nPd(x)Q (\u221a Sf x ) dx, (28)\nwhere Q(x) is a monotonous decreasing function with Q(x) \u2264 1/2, and\n\u222b \u221e 0 Pd(x)dx = 1. (29)\nThen, we arrive at\nPe1 \u2264 1\n2 \u222b \u03bb\u221ans/2 0 Pd(x)dx+ Q ( \u03bb \u221a 1 2 Sf ns )\u222b \u221e \u03bb \u221a ns/2 Pd(x)dx\n\u2264 \u03b8 2\n+ Q ( \u03bb \u221a 1\n2 Sf ns\n) , (30)\nwhere\n\u03b8 = \u222b \u03bb\u221ans/2\n0 Pd(x)dx. (31)\nBased on Chebyshev inequality [33], i.e.,\nPd(|x\u2212 E| > ) < V 2 , (32)\n456 VOLUME 3, 2022\nwhere E and V denote the mean and variance of Pd(x), respectively, in the context of\n= E \u2212 \u03bb \u221a n\n2 , (33)\nwe have\n\u03b8 = Pd ( x < \u03bb \u221a ns 2 )\n< V\n( E \u2212 \u03bb \u221a ns 2 )2 . (34)\nSince Pd(x) cannot be directly achieved, we tend to derive its upper and lower bound in order to further simplify Eq. (30). Considering that Pd(x2) obeys normal distribution with mean E(x2) = ns/2, in the following, we aim at achieving a lower bound of E. According to the former definition, we have\nE = \u222b +\u221e\n0 xPd(x)dx\n= \u222b +\u221e\n0 x\n\u221a 2x\u221a\n\u03c0ns/4 exp\n( \u2212 ( x2 \u2212 ns/2 )2 ns/2 ) dx. (35)\nThen Eq. (35) can be rewritten as\nE = \u222b +\u221e\n0\n(ns/2)1/4 \u221a x\u221a\n\u03c0 exp\n( \u2212 ( x\u2212 \u221a ns 2 )2) dx. (36)\nLet \u03b1 = (ns/2)1/2 and \u03b2 = (ns/2)1/4 with \u03b1 \u2212 \u03b2 > 0, then we have\nE > \u222b \u03b1+\u03b2 \u03b1\u2212\u03b2 \u03b2 \u221a x\u221a \u03c0 exp ( \u2212(x\u2212 \u03b1)2 ) dx\n> \u222b \u03b1+\u03b2 \u03b1\u2212\u03b2 \u03b2 \u221a \u03b1 \u2212 \u03b2\u221a \u03c0 exp ( \u2212(x\u2212 \u03b1)2 ) dx = \u221a ns/2 \u2212 (ns/2)3/4\u221a\n\u03c0\n\u222b \u03b2 \u2212\u03b2 exp ( \u2212x2 ) dx. (37)\nSince\nlim \u03b2\u2192\u221e \u222b \u03b2 \u2212\u03b2 exp ( \u2212x2 ) dx = \u221a\u03c0, (38)\nwe finally arrive at\nE > \u221a ns/2 \u2212 (ns/2)3/4. (39)\nTherefore, an upper bound of the variance can be ultimately obtained as\nV = E ( x2 ) \u2212 E(x)2\n< ns 2 \u2212 ( ns 2 \u2212 (ns 2 )3/4) = (ns\n2\n)3/4 . (40)\nSubstituting the bounds of E and V into Eq. (34), we have\n\u03b8 <\n( ns 2 )3/4 (\u221a\nns 2 \u2212 ( ns 2 )3/4 \u2212 \u03bb \u221a ns 2 ))2\n= 1 \u03b2 (\u221a\n1 \u2212 1 \u03b2\n\u2212 \u03bb )2 . (41)\nTherefore, there always exists \u03bb infinitely close to 1 when \u03b2 \u2192 \u221e and \u03b8 \u2192 0. Consequently, Eq. (30) is reduced to\nPe1 \u2264 Q (\u221a 1\n2 Sf ns\n) . (42)\nSubstituting Eq. (42) into Eq. (26) while combining Eq. (18) and Eq. (26), we finally conclude that the BLER bound of the folded binary random coding is identical to that of the folded Hadamard coding as attained in Eq. (24). Different from the Hadamard code with fixed ns = 2k, the binary random code is capable of adapting arbitrary code length and rate. So the bound of Eq. (24) holds for a general configuration of finite code length and rate."
        },
        {
            "heading": "IV. FROM BINARY RANDOM CODING TO GAUSSIAN RANDOM CODING",
            "text": "A limitation of the above theoretical work lies in that, binary codes including the Hadamard code and binary random one don\u2019t strictly satisfy the condition of Gaussian folded noise introduced in Section II-A. Therefore, we will theoretically demonstrate that the folded binary code can approach Gaussian distribution for each sub-channel defined in Section II-A when nf goes to infinity.\nOn the other hand, in order to achieve the bound, the folding number nf will go to infinity even for finite information length k so that it is unacceptable for practical implementation. In this section, we will further exhibit that the proposed way of folding the codes is actually equivalent to the format of Gaussian random codes. Then, we will also disclose that the bound shown in Eq. (24) still holds when the coded super-symbol x\u2032j is replaced directly by a Gaussian variable with mean 0 and variance a. Without the folding operation in Eq. (1), the complexity of the encoding and the decoding is only related to k and n rather than ns and nf ."
        },
        {
            "heading": "A. GAUSSIAN APPROACHING FOR BINARY CODES",
            "text": "Note that the binary sequence obeys binomial distribution with equal probability. Since the original Hadamard code cannot be considered as random sequences, we introduce a perfect permutation to eliminate its regular structure in order to approach the binomial distribution. Then the folded supersymbol x\u2032j is generated following Eq. (1). Note that here we have xi,j \u2208 {\u22121, 1} for binary code. Considering each folded symbol is with constant power coefficients ai, there are only nf values for ai. By substituting Eq. (14) and Eq. (21) into Eq. (11), we arrive at\nai = 2C nf log2e (1 + S) i nf . (43)\nVOLUME 3, 2022 457\nLIN AND XIAO: NEW BOUND TO ERROR PROBABILITY ON AWGN CHANNELS\nAn example of the values of ai with nf = 10000, a = 1 is portrayed in Fig. 2. Note that ai is monotonously increasing with i. We divide the curve of ai into \u221a nf segments, each\nwith length \u221a nf . For convenience, without loss of generality,\u221a\nnf is assumed to be an integer. So the beginning and the end of the \u03c4 th segment have the values of\na\u03c4,1 = 2C nf log2e\n(1 + S) \u221a nf \u03c4 nf , 0 \u2264 \u03c4 < \u221anf , (44)\nand\na\u03c4,2 = 2C nf log2e\n(1 + S) \u221a nf (\u03c4+1)\u22121 nf . (45)\nTheir ratio is then expressed as\n\u03b7\u03c4 = a\u03c4,2 a\u03c4,1\n= (1 + S) \u221a nf\u22121 nf . (46)\nWhen nf \u2192 \u221e, we have \u03b7\u03c4 \u2192 1, i.e., a\u03c4,2 \u2192 a\u03c4,1. Consequently, Eq. (1) is rewritten as\nx\u2032j = \u221a nf\u22121\u2211 \u03c4=0 \u221a a\u03c4,1\u03c9\u03c4,j, (47)\nwhere\n\u03c9\u03c4,j = \u221a nf\u22121\u2211 t=0 x\u221anf \u03c4+t,j. (48)\nTherefore, when \u221a nf goes to infinity, \u03c9\u03c4,j, as the summary of the random variables with binomial distribution, obeys normal distribution with mean zero and variance\u221a nf . Furthermore, since the linear combination of variables with normal distribution also obeys normal distribution, x\u2032j stands for a Gaussian variable, too. Moreover, although the interference within the same segment doesn\u2019t strictly obey Gaussian distribution, the fraction term will gradually approach 0 with the infinite increase of \u221a nf . Considering\n\u221a nf as the number of sub-channel defined in Section II-A and the original code as \u03c9\u03c4,j, the result in Section II-A is still available for the way of binary coding."
        },
        {
            "heading": "B. FROM BINARY RANDOM CODING TO GAUSSIAN RANDOM CODING",
            "text": "In the previous subsection, we have proven that the coded super-symbols x\u2032j obey i.i.d. Gaussian distributions with nf approaching to infinity when they are constructed by folding the binary random code. In the following, we will show that, for any given Gaussian coded super-symbol x\u2032j, there always exists a binary random sequence with length nf satisfying Eq. (1), while obeying binomial distribution along with the length nf going to infinity. Based on the result in the previous subsection, calculation of Eq. (1) can be divided into two steps by following Eq. (47) and Eq. (48), respectively. For the first step, Eq. (47) can be rewritten as\n\u03c9\u03020,j = 1\u221a a0,1\n\u239b \u239dx\u2032j \u2212 \u221a nf\u22121\u2211 \u03c4=1 \u221a a\u03c4,1\u03c9\u0302\u03c4,j \u239e \u23a0. (49)\nFollowing Eq. (49), we firstly randomly generate \u03c9\u0302\u03c4,j, \u03c4 = 1, 2, . . . , \u221a nf \u22121 with standard normal distribution. Then the variable \u03c9\u03020,j can be determined based on Eq. (49). Clearly, \u03c9\u03020,j obeys standard normal distribution, too. Note that \u03c9\u0302\u03c4,j, which are considered as real Gaussian variables, are slightly different from \u03c9\u03c4,j defined in Eq. (48). But this difference can be negligible according to De Moivre-Laplace theorem [33]. For the second step, Eq. (48) can be written as\n\u03c9\u03c4,j = \u03c9\u2032\u03c4,j \u2212 \u03c9\u2032\u2032\u03c4,j, (50) where\n\u03c9\u2032\u03c4,j = \u2211\nx\u221anf \u03c4+t,j=1 1, (51)\n458 VOLUME 3, 2022\nFIGURE 4. The performance of the proposed bound in AWGN channels with extremely high reliability.\nand\n\u03c9\u2032\u2032\u03c4,j = \u2211\nx\u221anf \u03c4+t,j=\u22121 1\n= \u221anf \u2212 \u03c9\u2032\u03c4,j. (52) Replacing \u03c9\u0302\u03c4,j by \u03c9\u03c4,j, we have\n\u03c9\u2032\u03c4,j = [ \u03c9\u0302\u03c4,j + \u221anf\n2\n] , (53)\nwhere [ \u00b7 ] means rounding to the nearest integer. Although \u03c9\u2032\u03c4,j from Eq. (53) may be larger than \u221a nf , its probability\nwill approach zero when \u221a nf \u2192 \u221e. Following Eq. (48), we construct a binary sequence with \u03c9\u2032\u03c4,j \u201c1\u201ds and \u03c9\u2032\u2032\u03c4,j \u201c\u22121\u201ds. Moreover, \u201c1\u201ds and \u201c\u22121\u201ds are randomly generated in the sequence. In other words, the probability of every position being \u201c1\u201d and \u201c\u22121\u201d in the sequence is equal and independent. Consequently, this binary random sequence obeys binomial distribution. Combining the analyses in the previous two subsections, we summarize that the transmit super-symbols x\u2032j can be generated directly by Gaussian random variables or by overlapping binary random sequences with amplified power coefficient aj given in Eq. (1). Compared with the latter way, the way of Gaussian random coding is with lower encoding and decoding complexity only relative to n."
        },
        {
            "heading": "V. RESULTS",
            "text": "In this section, we firstly simulate three codes constructed by the proposed methods to evaluate their BLER performances. These coding ways are based on the Hadamard coding, binary random coding and Gaussian random coding, respectively. The three codes are all with a code length of 128 and a code rate of 0.125, while the maximum likelihood decoding is used at the receiver. As results, their BLER curves are shown in Fig. 3. From the results, we demonstrate that all these coding ways exhibit similar error performances, as concluded through above-mentioned theoretical analysis. Fig. 4 presents the numerical results for the proposed bound of BLERs in AWGN channels. Note that the derived theoretical result in Eq. (24) is tight in the region of short code length and low code rate, therefore, we focus on the length of information bits k as 16, while the code length n is selected as 128, 512, 1024 and 2048, respectively. For comparison, we also list the Shannon\u2019s bound [24], and the normal approximation presented by Polyanskis et al. [18]. Note that, our developed bound is capable of approaching Shannon bound gradually by increasing the code length, in the context of extremely low error floor. This phenomenon supports that the ways of folding the codes and Gaussian random coding could both be theoretically demonstrated to approach the Shannon bound toward extremely high reliability, in the context of low code rate and limited code length. Therefore, our developed coding ways, from code folding to Gaussian random coding, has the potential to apply the scenario with high reliability and sever interference [28]. Furthermore, in Fig. 5, we simulate the BLER performance of Gaussian random coding as an example with maximum likelihood decoding. As expected, the performance of practical coding is between the derived bound and Shannon bound. Specifically, at a BLER of 10\u22125, when the code length is 128, the performance of Gaussian random coding is only\nVOLUME 3, 2022 459\nLIN AND XIAO: NEW BOUND TO ERROR PROBABILITY ON AWGN CHANNELS\n0.2dB away from the developed bound. As expected, when the code length goes higher, the performance will approach both the derived bound and Shannon bound."
        },
        {
            "heading": "VI. CONCLUSION",
            "text": "Aiming at constructing powerful codes in the context of short code length and low code rate, two connected coding ways as code folding and Gaussian random coding were investigated, by bounding their block error probability performances in the AWGN channel. Through theoretical analysis, we demonstrate that the aforementioned coding ways have\na uniform performance bound as \u221a\nlog2e 2\u03c0nC2 \u2212n(C/2\u2212R), which firstly describes a tradeoff among code length, rate and reliability for code design while demonstrating its advantage in short code length and low rate. Finally, numerical results were also performed to exhibit the excellent performance even close to Shannon bound in the above-mentioned configuration. The above contribution demonstrated that these coding ways have the potential to adapt the scenario of ultra reliability and low latency in the context of massive interference, which will be the focus of our future works."
        }
    ],
    "title": "A New Bound to Error Probability on AWGN Channels: From Folded Coding to Gaussian Random Coding",
    "year": 2022
}