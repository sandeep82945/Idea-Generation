{
    "abstractText": "Electroencephalogram (EEG) signals are effective tools towards seizure analysis where one of the most important challenges is accurate detection of seizure events and brain regions in which seizure happens or initiates. However, all existing machine learning-based algorithms for seizure analysis require access to the labeled seizure data while acquiring labeled data is very labor intensive, expensive, as well as clinicians dependent given the subjective nature of the visual qualitative interpretation of EEG signals. In this paper, we propose to detect seizure channels and clips in a self-supervised manner where no access to the seizure data is needed. The proposed method considers local structural and contextual information embedded in EEG graphs by employing positive and negative sub-graphs. We train our method through minimizing contrastive and generative losses. The employ of local EEG sub-graphs makes the algorithm an appropriate choice when accessing to all EEG channels is impossible due to complications such as skull fractures. We conduct an extensive set of experiments on the largest seizure dataset and demonstrate that our proposed framework outperforms the state-of-the-art methods in the EEG-based seizure study. The proposed method is the only study that requires no access to the seizure data in its training phase, yet establishes a new state-of-the-art to the field, and outperforms all related supervised methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "Thi Kieu"
        },
        {
            "affiliations": [],
            "name": "Khanh Ho"
        },
        {
            "affiliations": [],
            "name": "Narges Armanfard"
        }
    ],
    "id": "SP:736d92bd6c2888a284d71d1deca42dbc3b581e92",
    "references": [
        {
            "authors": [
                "A. Abdelhameed",
                "M. Bayoumi"
            ],
            "title": "A deep learning approach for automatic seizure detection in children with epilepsy",
            "venue": "Frontiers in Computational Neuroscience, 15: 650050.",
            "year": 2021
        },
        {
            "authors": [
                "N. Armanfard",
                "M. Komeili",
                "J.P. Reilly",
                "J.F. Connolly"
            ],
            "title": "A machine learning framework for automatic and continuous MMN detection with preliminary results for coma outcome prediction",
            "venue": "IEEE journal of biomedical and health informatics, 23(4): 1794\u20131804.",
            "year": 2018
        },
        {
            "authors": [
                "E. Beghi",
                "G. Giussani"
            ],
            "title": "Aging and the epidemiology of epilepsy",
            "venue": "Neuroepidemiology, 51(3-4): 216\u2013223.",
            "year": 2018
        },
        {
            "authors": [
                "E. Bisong"
            ],
            "title": "Introduction to Scikit-learn",
            "venue": "Building machine learning and deep learning models on Google cloud platform, 215\u2013229. Springer.",
            "year": 2019
        },
        {
            "authors": [
                "K.J. Blinowska"
            ],
            "title": "Review of the methods of determination of directed connectivity from multichannel data",
            "venue": "Medical & biological engineering & computing, 49(5): 521\u2013529.",
            "year": 2011
        },
        {
            "authors": [
                "B. Gao",
                "J. Zhou",
                "Y. Yang",
                "J. Chi",
                "Q. Yuan"
            ],
            "title": "Generative adversarial network and convolutional neural network-based EEG imbalanced classification model for seizure detection",
            "venue": "Biocybernetics and Biomedical Engineering, 42(1): 1\u201315.",
            "year": 2022
        },
        {
            "authors": [
                "H. Hojjati",
                "T.K.K. Ho",
                "N. Armanfard"
            ],
            "title": "SelfSupervised Anomaly Detection: A Survey and Outlook",
            "venue": "arXiv preprint arXiv:2205.05173.",
            "year": 2022
        },
        {
            "authors": [
                "E.L. Johnson"
            ],
            "title": "Seizures and epilepsy",
            "venue": "Medical Clinics, 103(2): 309\u2013324.",
            "year": 2019
        },
        {
            "authors": [
                "V. Khalkhali",
                "N. Shawki",
                "V. Shah",
                "M. Golmohammadi",
                "I. Obeid",
                "J. Picone"
            ],
            "title": "Low Latency Real-Time Seizure Detection Using Transfer Deep Learning",
            "venue": "2021 IEEE Signal Processing in Medicine and Biology Symposium (SPMB), 1\u20137. IEEE.",
            "year": 2021
        },
        {
            "authors": [
                "L. Kuhlmann",
                "K. Lehnertz",
                "M.P. Richardson",
                "B. Schelter",
                "H.P. Zaveri"
            ],
            "title": "Seizure prediction\u2014ready for a new era",
            "venue": "Nature Reviews Neurology, 14(10): 618\u2013630.",
            "year": 2018
        },
        {
            "authors": [
                "V.J. Lawhern",
                "A.J. Solon",
                "N.R. Waytowich",
                "S.M. Gordon",
                "C.P. Hung",
                "B.J. Lance"
            ],
            "title": "EEGNet: a compact convolutional neural network for EEG-based brain\u2013 computer interfaces",
            "venue": "Journal of neural engineering, 15(5): 056013.",
            "year": 2018
        },
        {
            "authors": [
                "C.-L. Li",
                "K. Sohn",
                "J. Yoon",
                "T. Pfister"
            ],
            "title": "Cutpaste: Self-supervised learning for anomaly detection and localization",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 9664\u20139674.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Liu",
                "Z. Li",
                "S. Pan",
                "C. Gong",
                "C. Zhou",
                "G. Karypis"
            ],
            "title": "Anomaly detection on attributed networks via contrastive self-supervised learning",
            "venue": "IEEE transactions on neural networks and learning systems, 33(6): 2378\u20132392.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Liu",
                "S. Pan",
                "Y.G. Wang",
                "F. Xiong",
                "L. Wang",
                "Q. Chen",
                "V.C. Lee"
            ],
            "title": "Anomaly detection in dynamic graphs via transformer",
            "venue": "IEEE Transactions on Knowledge and Data Engineering.",
            "year": 2021
        },
        {
            "authors": [
                "A. Mahajan",
                "K. Somaraj",
                "M. Sameer"
            ],
            "title": "Adopting artificial intelligence powered ConvNet to detect epileptic seizures",
            "venue": "2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES), 427\u2013432. IEEE.",
            "year": 2021
        },
        {
            "authors": [
                "P. Mathur",
                "V.K. Chakka"
            ],
            "title": "Graph Signal Processing Based Cross-Subject Mental Task Classification Using Multi-Channel EEG Signals",
            "venue": "IEEE Sensors Journal, 22(8): 7971\u20137978.",
            "year": 2022
        },
        {
            "authors": [
                "M. Rashed-Al-Mahfuz",
                "M.A. Moni",
                "S. Uddin",
                "S.A. Alyami",
                "M.A. Summers",
                "V. Eapen"
            ],
            "title": "A deep convolutional neural network method to detect seizures and characteristic frequencies using epileptic electroencephalogram (EEG) data",
            "venue": "IEEE Journal of Translational Engineering in",
            "year": 2021
        },
        {
            "authors": [
                "K. Saab",
                "J. Dunnmon",
                "C. R\u00e9",
                "D. Rubin",
                "C. Lee-Messer"
            ],
            "title": "Weak supervision as an efficient approach for automated seizure detection in electroencephalography",
            "venue": "NPJ digital medicine, 3(1): 1\u201312.",
            "year": 2020
        },
        {
            "authors": [
                "S.S. Saboksayr",
                "G. Mateos",
                "M. Cetin"
            ],
            "title": "EEGbased emotion classification using graph signal processing",
            "venue": "ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 1065\u2013 1069. IEEE.",
            "year": 2021
        },
        {
            "authors": [
                "Saichand",
                "N. V"
            ],
            "title": "Epileptic seizure detection using novel Multilayer LSTM Discriminant Network and dynamic mode Koopman decomposition",
            "venue": "Biomedical Signal Processing and Control,",
            "year": 2021
        },
        {
            "authors": [
                "V. Shah",
                "E. Von Weltin",
                "S. Lopez",
                "J.R. McHugh",
                "L. Veloso",
                "M. Golmohammadi",
                "I. Obeid",
                "J. Picone"
            ],
            "title": "The temple university hospital seizure detection corpus",
            "venue": "Frontiers in neuroinformatics, 12: 83.",
            "year": 2018
        },
        {
            "authors": [
                "A. Sharma",
                "J. Rai",
                "R. Tewari"
            ],
            "title": "Epileptic seizure anticipation and localisation of epileptogenic region using EEG signals",
            "venue": "Journal of Medical Engineering & Technology, 42(3): 203\u2013216.",
            "year": 2018
        },
        {
            "authors": [
                "M. Shen",
                "P. Wen",
                "B. Song",
                "Y. Li"
            ],
            "title": "An EEG based real-time epilepsy seizure detection approach using discrete wavelet transform and machine learning methods",
            "venue": "Biomedical Signal Processing and Control, 77: 103820.",
            "year": 2022
        },
        {
            "authors": [
                "A. Shoeibi",
                "M. Khodatars",
                "N. Ghassemi",
                "M. Jafari",
                "P. Moridian",
                "R. Alizadehsani",
                "M. Panahiazar",
                "F. Khozeimeh",
                "A. Zare",
                "H Hosseini-Nejad"
            ],
            "title": "Epileptic seizures detection using deep learning techniques: a review",
            "year": 2021
        },
        {
            "authors": [
                "R. Surges",
                "S. Shmuely",
                "C. Dietze",
                "P. Ryvlin",
                "R.D. Thijs"
            ],
            "title": "Identifying patients with epilepsy at high risk of cardiac death: signs, risk factors and initial management of high risk of cardiac death",
            "venue": "Epileptic Disorders, 23(1): 17\u201339.",
            "year": 2021
        },
        {
            "authors": [
                "S. Tang",
                "J. Dunnmon",
                "K.K. Saab",
                "X. Zhang",
                "Q. Huang",
                "F. Dubost",
                "D. Rubin",
                "C. Lee-Messer"
            ],
            "title": "SelfSupervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis",
            "venue": "International Conference on Learning Representations.",
            "year": 2021
        },
        {
            "authors": [
                "P. Thuwajit",
                "P. Rangpong",
                "P. Sawangjai",
                "P. Autthasan",
                "R. Chaisaen",
                "N. Banluesombatkul",
                "P. Boonchit",
                "N. Tatsaringkansakul",
                "T. Sudhawiyangkul",
                "T. Wilaiprasitporn"
            ],
            "title": "EEGWaveNet: Multiscale CNN-Based Spatiotemporal Feature Extraction for EEG Seizure Detection",
            "venue": "IEEE",
            "year": 2021
        },
        {
            "authors": [
                "H. Tong",
                "C. Faloutsos",
                "J.-Y. Pan"
            ],
            "title": "Fast random walk with restart and its applications",
            "venue": "Sixth international conference on data mining (ICDM\u201906), 613\u2013622. IEEE.",
            "year": 2006
        },
        {
            "authors": [
                "N. Wagh",
                "Y. Varatharajah"
            ],
            "title": "Eeg-gcnn: Augmenting electroencephalogram-based neurological disease diagnosis using a domain-guided graph convolutional neural network",
            "venue": "Machine Learning for Health, 367\u2013378. PMLR.",
            "year": 2020
        },
        {
            "authors": [
                "J. Wang",
                "S. Liang",
                "Y. Wang",
                "Y. Zhang",
                "D. He",
                "J. Ma",
                "C. Ruan",
                "Y. Wu",
                "X. Hong",
                "J. Shen"
            ],
            "title": "A weighted overlook graph representation of eeg data for absence epilepsy detection",
            "venue": "2020 IEEE International Conference on Data Mining (ICDM), 581\u2013590. IEEE.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Xie",
                "Z. Xu",
                "J. Zhang",
                "Z. Wang",
                "S. Ji"
            ],
            "title": "Selfsupervised learning of graph neural networks: A unified review",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence.",
            "year": 2022
        },
        {
            "authors": [
                "T. Yan",
                "X. Dong",
                "N. Mu",
                "T. Liu",
                "D. Chen",
                "L. Deng",
                "C. Wang",
                "L. Zhao"
            ],
            "title": "Positive classification advantage: tracing the time course based on brain oscillation",
            "venue": "Frontiers in human neuroscience, 11: 659.",
            "year": 2018
        },
        {
            "authors": [
                "J. Zeng",
                "P. Xie"
            ],
            "title": "Contrastive self-supervised learning for graph classification",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, 10824\u201310832.",
            "year": 2021
        },
        {
            "authors": [
                "H. Zhang",
                "G. Lu",
                "M. Zhan",
                "B. Zhang"
            ],
            "title": "Semisupervised classification of graph convolutional networks with Laplacian rank constraints",
            "venue": "Neural Processing Letters, 1\u201312.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Zheng",
                "M. Jin",
                "Y. Liu",
                "L. Chi",
                "K.T. Phan",
                "Y.-P.P. Chen"
            ],
            "title": "Generative and contrastive self-supervised learning for graph anomaly detection",
            "venue": "IEEE Transactions on Knowledge and Data Engineering.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "Introduction",
            "text": "Epilepsy is one of the most prevalent neurological disorders affecting 65 million people (Johnson 2019). Patients with epilepsy suffer from sudden and unforeseen seizures, during which they are vulnerable to injury, suffocation and death (Surges et al. 2021). Epileptic seizure detection makes it possible to identify more accurately the epileptogenic zone (EZ), which is the brain area responsible for initiating seizures (Sharma, Rai, and Tewari 2018), and the surgical resection of EZ renders epilepsy patients seizure-free. As epilepsy can start at any age, early detection is crucial to prevent further damage during physiological development and to increase life expectancy (Beghi and Giussani 2018).\nScalp electroencephalogram (EEG) has been considered as the most common tool to detect seizures (Kuhlmann et al.\n*Corresponding Author (Email: thi.k.ho@mcgill.ca). Copyright \u00a9 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\n2018). EEG measures the voltage changes between electrodes by the ionic currents flowing within the brain neurons and provides spatial-temporal information of the brain. However, detecting seizures in EEGs requires a direct examination by experienced EEG readers that requires a huge amount of time and effort. Moreover, different opinions of experts can cause discrepant diagnostic results (Yan et al. 2018). Therefore, the development of automated and objective methods for epileptic seizure detection is needed.\nAlthough many studies have proposed deep learning (DL) based models for automated seizure detection (Saab et al. 2020; Shoeibi et al. 2021; Abdelhameed and Bayoumi 2021; Thuwajit et al. 2021; Khalkhali et al. 2021; RashedAl-Mahfuz et al. 2021; Mahajan, Somaraj, and Sameer 2021; Saichand et al. 2021; Shen et al. 2022; Gao et al. 2022), several challenges still remain unsolved. First, these studies train their proposed model in a supervised approach \u2013 i.e. availability of labeled seizure data during training is required. This does not address the challenge from a clinical perspective as seizure labels obtaining is difficult and labour expensive during the process of manually seizure marking, hence very scarce in real-world applications.\nSecond, these studies apply deep convolutional neural networks (CNNs) directly to the time-series signals or spectrograms hence ignore the critically important information physical distance-based connectivity and functionalbased connectivity between different brain regions. Several studies have recently proposed graph learning techniques to capture the relationships between EEG electrodes (aka EEG nodes) (Wang et al. 2020; Wagh and Varatharajah 2020; Saboksayr, Mateos, and Cetin 2021; Tang et al. 2021; Saboksayr, Mateos, and Cetin 2021; Mathur and Chakka 2022). However, they all fail to take into consideration the local patterns (e.g. local sub-graphs and sub-structures) when learning EEG graphs. Such local information could be effective when detecting anomalies in EEG graphs. The effectiveness of such local information has been recently demonstrated in applications such as analyzing social, traffic, citation, and financial transaction networks (Liu et al. 2021a,b; Zheng et al. 2021). However, its effectiveness in analyzing EEG signals, that are inherently non-stationary and dynamic, has remained unexplored to date.\nThird, as is discussed before, in real-world applications, there is not enough training data from seizure class; while\nar X\niv :2\n20 8.\n07 44\n8v 4\n[ cs\n.L G\n] 1\n5 Ja\nn 20\nthe existence of adequate data from both normal and seizure classes is essential when training supervised algorithms. To handle the imbalance-data issue, some graph-based methods employ graph augmentation (Wagh and Varatharajah 2020; Tang et al. 2021). However, in EEG graphs, not every augmentation technique is effective as some may corrupt the underlying brain region connectivities. Hence, pinpointing appropriate augmentation strategies in EEG graphs that preserve the underlying semantic information is necessary towards proving accurate seizure detection and localization.\nBased on the above observations, we propose a novel approach for the detection of abnormal brain regions and EEG channels, called Contrastive and Generative Selfsupervised Learning for EEG Graphs (EEG-CGS). Although the effectiveness of contrastive learning methods, as a self-supervised learning technique, has been demonstrated for anomaly detection (Li et al. 2021; Hojjati, Ho, and Armanfard 2022) and graph analysis in general (Zeng and Xie 2021; Xie et al. 2022), its ability on analysing the EEG graphs has remained unexplored.\nThe main contributions of this paper are as follows:\n\u2022 We propose a self-supervised method for identifying abnormal brain regions and EEG channels without having access to the abnormal class data during the training phase. To the best of our knowledge, this is the first study for unsupervised identification of abnormal EEG channels and regions.\n\u2022 We propose to model brain regions and their connectivities using attributed graphs where each EEG channel is considered as a graph node. Each node is associated with a feature vector constructed from the corresponding EEG signal. Nodes are connected based on four different metrics including nodes Euclidean distance, randomly connection of nodes, node features correlations, and directed transfer function; the first two are meant to capture the geometry of EEG channels and the last two are for capturing connectivity of brain regions.\n\u2022 We propose an effective augmentation approach to create the positive and negative pairs. Augmentations are based on sub-graphs hence allowing to capture the local structural and contextual information.\n\u2022 The proposed self-supervised method is realized through employing contrastive and generative learning techniques. We define a channel-based anomaly score function which is a linear combination of the contrastive and reconstruction losses.\n\u2022 Performance of the proposed abnormal EEG node and region detection is demonstrated on the largest and most comprehensive EEG seizure dataset TUSZ. We show that the proposed EEG-CGS establishes a new state-ofthe-art on this dataset. EEG-CGS significantly outperforms all existing (supervised) seizure detection techniques.\n\u2022 The proposed technique can be considered as a general approach for the detection and localization in other brain disorders. The sub-graph based nature of EEGCGS makes it a suitable choice for applications where\nnot all EEG channels are available or reliable during training. E.g. in coma outcome prediction application, the scalp of comatose patients is usually uneven with fractions so that recording of all EEG channels is rarely possible (Armanfard et al. 2018)."
        },
        {
            "heading": "Proposed Method",
            "text": "The block diagram of the proposed method is shown in Figure 1. The proposed EEG-CGS for node anomaly detection consists of four components namely EEG graph construction, positive and negative pair sampling, contrastive and generative learning based on graph neural networks (GNN), and anomaly score computation. The following sections discuss these components in detail."
        },
        {
            "heading": "EEG Graph Construction",
            "text": "An EEG graph is denoted as G = (A,X ) where A = (V, E). A \u2208 Rn\u00d7n is the adjacency matrix which its element on the ith row and jth column, i.e. aij , is greater than zero if a connectivity exists between EEG electrodes vi and vj . V = {v1, ..., vn} is the set of n electrodes (aka nodes), E is the set of m edges, X \u2208 Rn\u00d7d is the feature matrix, d denotes the number of attributes (aka features) representing an EEG signal. The ith row of X , denoted by xi, is the feature vector representing the ith EEG channel. For a given EEG clip, we build four types of EEG graphs:\n\u2022 Dist-EEG-Graph endeavors to embed the structure of electrode locations in the graph\u2019s adjacency matrix, using Euclidean distance between electrodes. As the electrode locations are fixed in an EEG recording cap, the same adjacency matrix is obtained for all EEG clips. More specifically, aij of Dist-EEG-Graph is obtained as follows:\naij =\n{ exp(\u2212\u2016vi\u2212vj\u2016 2\n\u03b62 ) if \u2016vi \u2212 vj\u2016 \u2264 k 0 if O.W. , (1)\nwhere \u2016\u00b7\u2016 denotes `2-norm and \u03b6 is a scaling constant. The closer the two electrodes vi and vj are, the closer aij is to 1. In all our experiments k is set to 0.9 for all EEG clips. Setting aij = 0 for far away electrodes imposes sparsity to the graph.\n\u2022 Rand-EEG-Graph is built based on the assumption that all electrodes are connected and equally contribute in brain activities. This graph is realized through forming an adjacency matrix as follows:\naij = { 0.5 if i 6= j 1 if O.W. . (2)\nIn this way, every edge has the chance of being present in the graph.\n\u2022 Corr-EEG-Graph is meant to capture the functional connectivity between electrodes. It is encoded in the adjacency matrix elements defined as below:\naij =\n{ xcorr(xi,xj) \u2016xi\u2016\u2016xj\u2016 if vj \u2208 N (vi)\n0 if O.W. , (3)\nwhere xcorr(\u00b7,\u00b7) denotes cross correlation function, N (vi) presents the top-3 neighborhood nodes of vi that have the highest normalized correlation. N (vi) is set to the top-3 neighborhood nodes to avoid overly connected graphs. We only keep the top three edges (i.e., m = 3) for each node to avoid overly connected graphs.\n\u2022 DTF-EEG-Graph is Directed Transfer Function Graph (Blinowska 2011) that is meant to capture the mutual influence between EEG channels, hence it models functional connectivity of the brain regions. The adjacency matrix for this graph is as follows:\naij =\n{ xcorr(xi,xj)\u221a\u2211n\nm=1,m 6=i,j \u2016xcorr(xi,xm)\u20162 if vj \u2208 N (vi)\n0 if O.W. ,\n(4) aij takes a value from 0 to 1, and denotes a ratio between the correlation of the attributes of vi and vj to the correlations of the features of all the remaining nodes and xi. As similar to Corr-EEG-Graph, we set N (vi) to the top-3 neighbors of vi."
        },
        {
            "heading": "Positive and Negative Pair Sampling",
            "text": "For every EEG clip in an input mini-batch B, we first construct the four graphs discussed in the EEG Graph Construction section (see the EEG Graph Construction block in Figure 1). Then, we create positive and negative sub-graphs\nfor each clip to be used in its following step where the algorithm\u2019s networks are trained using reconstruction and contrastive losses.\nWe create two positive and one negative sub-graphs for every node in every constructed EEG graph. To this end, we first select an electrode as target node vt and then select the two positive sub-graphs G+s1 and G + s2 , and one negative sub-graph G\u2212s1 . Each target node is assigned to its own sub-graphs. To form G+s1 and G + s2 , we leverage a random walk with restart (RWR) technique (Tong, Faloutsos, and Pan 2006) by which sub-graphs are centered at the target node with the fixed size \u03b1 which controls the radius of the surrounding contexts. In the other words, \u03b1 determines the number of nodes within the sub-graphs. To impose generalization to the system, we anonymize the target node in the positive sub-graphs by replacing its feature vector with an all-zero vector. To form the negative sub-graph G\u2212s1 , we first find the farthest electrode from the target node and then apply the RWR to the farthest node with a same \u03b1 value as of the one used for the positive sub-graphs. In Figure 1, \u03b1 is set to 4 indicating 4 nodes are considered in the positive and negative sub-graphs where the farthest node to the target node (i.e. C3) is T4."
        },
        {
            "heading": "Contrastive and Generative Learning",
            "text": "As is shown in Figure 1, we employ GNN autoencoder to realize the unsupervised contrastive and generative learning objectives. The autoencoder consists of two networks: encoder and decoder, respectively denoted as GNNe(\u00b7, \u00b7) and GNNd(\u00b7, \u00b7). Encoder takes a graph as input and embed it to a lower dimensional space while decoder takes the encoder\u2019s output as input and endeavors to reconstruct the encoder\u2019s input.\nAssume a sub-graph Gs = (As,Xs), where As \u2208 R\u03b1\u00d7\u03b1 and Xs \u2208 R\u03b1\u00d7d respectively denote the sub-graph adjacency matrix and the node attributes. The encoder takes Gs as input and embed it to a lower dimensional space as below:\nEs = GNNe(Xs,As) , ReLu(A\u0302sXsWe), (5)\nwhere Es \u2208 R\u03b1\u00d7d \u2032 , d\u2032 d, We denotes the encoder trainable parameters, and ReLu is the Rectified Linear Unit. A\u0302s = D\u0303 \u2212 12 s A\u0303sD\u0303 \u2212 12 s , A\u0303s = As + I is the adjacency matrix with self-loop, D\u0303s is the diagonal node degree matrix of the sub-graph where its ith diagonal element is equal to \u2211 j a\u0303sij . I is the identity matrix. For more details, see (Zhang et al. 2021). We also embed the target node to the lower dimensional space defined by the encoder. Since a single node vi has no adjacency matrix, we define its embedding as below:\nei = ReLu(xiWe). (6)\nIn summary, for each constructed graph, we feed three sub-graphs and one target node to the GNNe to create their embeddings in the lower dimensional space, as is illustrated in the output of GNNe in Figure 1 where d\u2032 is set to 3.\nContrastive Learning Module: To learn the local topological structure of the graphs, we propose to employ contrastive learning module. In order to create positive and negative pairs to be used for the purpose of contrastive learning, we first take an average over all the \u03b1 rows of Es to map it to a d\u2032 dimensional vector, called rs \u2208 R1\u00d7d \u2032 .\nSince we have formed two positive and one negative subgraphs for each target node, we define two positive and one negative pairs. The positive pairs are P+1 = (et, r+s1 ) and P+2 = (et, r+s2 ), and the negative pair is P \u2212 1 = (et, r \u2212 s1 ). Embedding of the target node vt is denoted by et, r+s{1,2} indicates the d\u2032 dimensional vector obtained by taking an average of the E+s{1,2} = GNNe(G + s{1,2}\n), and r\u2212s1 indicates the d\u2032 dimensional vector obtained by taking average of the E\u2212s1 = GNNe(G \u2212 s1).\nWe introduce a trainable scoring matrix Ws \u2208 Rd \u2032\u00d7d\u2032\nwhere the similarity of et to r+s1 is obtained as below:\nSim+t,1 = \u03c3(etWsr +> s1 ), (7)\nwhere \u03c3(.) is the logistic function that outputs a value between 0 and 1 and (\u00b7)> denotes the transpose operator. Similarly, Sim+t,2 and Sim \u2212 t,1 can be obtained by replacing r + s1 in (7) with r+s2 and r \u2212 s1 , respectively.\nFinally, inspired by (Zheng et al. 2021), we define the contrastive loss function, Lcon as below:\nLcon = \u2212 1\n2n|B| 2\u2211 q=1 n\u2211 t=1 ( log(Sim+t,q) + log(1\u2212Sim\u2212t,1) ) ,\n(8) where |B| indicates the number of EEG clips in the minibatch B, and n denotes the number of all existing EEG electrodes (e.g., n is 19 in a 10-20 EEG cap recording system).\nGenerative Learning Module: This module is to learn the contextual information hidden in the graph through reconstructing the target node anonymized in the positive subgraphs G+1 and G + 2 , using the other node features and edges of the sub-graph. More specifically, we reconstruct the input sub-graph G+s{1,2} using its embedded version E + s{1,2} , i.e. G\u0302+s{1,2} = GNNd(E + s{1,2}\n) while minimizing the below reconstruction loss:\nLrec = 1\n2n|B| 2\u2211 q=1 n\u2211 t=1 \u2016x\u0302t,q \u2212 xt\u20162 , (9)\nwhere x\u0302t,q is the reconstructed vector of the target node xt, taken from the reconstructed graph G\u0302+sq = GNNd(E + sq ). We denote the parameters of the decoder as Wd. Finally, we define the total loss L through weighted sum of the reconstruction and contrastive losses, as below:\nL = \u03bbLcon + (1\u2212 \u03bb)Lrec, (10)\nwhere \u03bb is the balancing hyperparameter."
        },
        {
            "heading": "Anomaly Score",
            "text": "From the contrastive and generative modules, for a node vi \u2208 V , we define the anomaly scoring function as below: f(vi) = \u03bbfcon(vi) + (1\u2212 \u03bb)frec(vi), (11) where fcon(vi) = 12 \u22112 q=1 \u03b4(Sim \u2212 i,1 \u2212 Sim + i,q) is the con-\ntrastive anomaly score, and frec(vi) = 12 \u22112 q=1 \u03b4(||x\u0302i,q \u2212 xi||2) is the reconstruction anomaly score, and \u03b4 is the MinMaxScaler function (Bisong 2019) that scales the scores to the range [0, 1].\nThe anomaly score for all nodes is calculated. If vi is an anomaly node from structural point of view, both Sim+i,q , q \u2208 {1, 2} and Sim\u2212i,1 would be close to 0.5 as there exists a mismatch between vi and the corresponding node in subgraphs G+sq ,G \u2212 s1 used for training the algorithm networks, because we only use normal clips and nodes in the training phase. Here, the scaling function \u03b4 maps 0 to 1, hence fcon(vi) would be equal to 1. If vi is an anomaly node from contextual point of view, frec(vi) would be close to 1 as the decoder cannot reconstruct an anomaly since the networks are trained on only normal nodes and clips. If vi is a normal node, both of fcon(vi) and frec(vi) would be close to 0. In other words, an anomaly (normal) node would result into a high (low) anomaly score.\nIn the inference phase, a node is considered as an anomaly if its corresponding anomaly score is higher than\na threshold \u03c41. An EEG clip is considered as seizure-free (i.e. normal) if there are less than \u03c42 abnormal nodes within its corresponding EEG graph, otherwise it is detected as a seizure clip. The inference phase for a seizure clip is illustrated in Figure 1 at block (4)."
        },
        {
            "heading": "Experiments",
            "text": "We use the public benchmark dataset, Temple University Hospital EEG Seizure Corpus (TUSZ) v1.5.2 (Shah et al. 2018), which contains the largest number of seizure categories and patient samples. TUSZ is recorded over years, and recorded by different equipment generations from subjects of all ages. Thus, the variance is much more than other available EEG datasets in the seizure study, hence it is the most challenging dataset for seizure detection. The number of existing channels is 19 recorded in the standard EEG 10-20 system, as is shown in Figure 1. Table 1 summarizes the TUSZ dataset used in our experiments. As is shown in the table, in the training phase, we use the same number of normal clips as is used in other supervised methods, and do not use any seizure clips. In the test phase, the same number of test clips, including seizure and normal clips, is used in our comparison supervised methods and our method. To evaluate the model\u2019s ability in seizure location detection, we use the available annotations on focal and generalized seizure types from 23 distinct patients. Note that compared with other types of seizures, focal and generalized types are most present in epilepsy patients.\nPerformance of the proposed method for anomaly detection is quantified using five criteria including Receiver Operating Characteristics - Area Under the Curve (ROCAUC), Precision (Pre.), F1 score (F1), Sensitivity (Sen.) and Specificity (Spec.).\nWe compare our proposed EEG-CGS with two streams of DL-based methods 1: (1) DL models in the EEG time-series and/or spectrograms domain, including EEGNet (Lawhern et al. 2018), EEG-TL (Khalkhali et al. 2021), Dense-CNN, LSTM and CNN-LSTM (Tang et al. 2021); and (2) DL models in the EEG graph domain (Tang et al. 2021). Unlike our method, these DL models make use of the seizure data and their corresponding labels in the training phase. For a fair comparison, we test the methods on the same test data, whilst our method is trained on a much smaller number of\n1To provide a fair comparison, we do not include algorithms that require training their model on an extra EEG dataset (using transfer learning), in addition to the given TUSZ data."
        },
        {
            "heading": "Graph Type Pre F1 Sen Spec",
            "text": "training sample because we do not include any seizure data in the training phase.\nWe introduce four variations of our EEG-CGS method based on the type of constructed graph used as the input. In the following, we refer to these variations as EEGd-CGS, EEGr-CGS, EEGc-CGS, EEGf -CGS and EEGt-CGS, respectively corresponding to the cases where the employed input graph is Dist-EEG-Graph, Rand-EEG-Graph, CorrEEG-Graph, DTF-EEG-Graph and the case where all the four graph types are concatenated and fed to the system as the input representing the given input EEG clip. In our experiments, following (Tang et al. 2021), we simply use the Fast Fourier Transform coefficients as attributes of EEG channels , although adding other attributes such as Wavelet coefficients might also be useful, which is out of the scope of this paper.\nThe hyperparameters d, k, m, d \u2032 , \u03b1, \u03bb, \u03c41, \u03c42 of the proposed method are respectively set to 6000, 0.9, 3, 256, 4, 0.6, 0.4, 1. To have a fair comparison, all hyperparameters of the proposed method are fixed over all experiments. Regarding the EEGt-CGS case, we also set the hyperparameters to be the same as the values mentioned above; where at the inference phase, we take an average of anomaly scores computed for all nodes of the four graph types \u2013 a node is predicted as an anomaly if the average score is greater than \u03c41. Based on the average anomaly scores for all nodes, an EEG clip is predicted as seizure if the number of predicted anomalous nodes (over all clips) is greater than \u03c42. Hyperparameters of our comparison methods are set to the values suggested by their authors.\nThe performance of our proposed method is demonstrated for anomalous channel detection, seizure clip detection and seizure channel detection."
        },
        {
            "heading": "Detection of Synthetic Anomalous Channels",
            "text": "This section is to verify the performance of the proposed method for reliable anomalous channel detection. To this end, we create a synthetic test set using the normal clips used in the training phase. More specifically, we first average every 35 normal clips (with no overlap). We then, with probability of 3%, inject an anomaly node to the average clip. A node of the selected average clip will be corrupted with a probability of 0.03%, and no more than one node is corrupted per average clip. A node is corrupted both contextually and structurally. To this end, we perform two types of corruptions to make vi abnormal: (1) we connect vi to all other nodes in the average clip \u2013 i.e. we set aij = 1 for j = 1, . . . , n; (2) we corrupt the attribute vector of vi by"
        },
        {
            "heading": "Graph Type Pre F1 Sen Spec",
            "text": "replacing its feature vector with the feature vector of the node in the average clip that has the largest Euclidean distance to vi. We then feed the average clips (that some have injected anomalies) to the EEG-CGS networks trained on the pure normal clips and let the trained system compute the anomaly score for all channels. If the anomaly score is greater than the pre-defined threshold \u03c41, then the corresponding channels are marked as anomalies.\n(Liu et al. 2021a) demonstrated that, for node anomaly detection in the test phase, it would be more effective to create multiple contrastive pairs to capture more neighbors of the target node. (Note that in the training phase, we created only two contrastive pairs.) As such, following (Liu et al. 2021a), we compute the anomaly score for 80 randomly selected sub-graphs that include both close and far nodes around the target node. The final anomaly score of a target node is then the average of the 80 calculated ones. This strategy makes the final anomaly score more reliable. Our experiments show high detection performance can be obtained for a wide range of contrastive pair numbers.\nNode anomaly detection results for the four variations of our EEG-CGS method are reported in Table 2. The results demonstrate the effectiveness of our unsupervised method for anomalous EEG channel detection. Note that this is the only existing study for anomalous EEG channel detection with access to no abnormal data. The reported results, confirm the effectiveness of the reconstructed graphs and that including all graphs for detection results in a more consistent performance across all metrics."
        },
        {
            "heading": "Detection of Seizure Clips and Channels",
            "text": "The performance of the proposed method along with our comparison methods, for seizure clip detection, are shown in Table 3. Note that the proposed method is a selfsupervised 1-class classification technique while all the comparison methods are supervised 2-class classification methods. The compared methods are the current state-ofthe-art in the seizure detection research field. Our method significantly outperforms all the comparison methods in all metrics and set a new SOTA in the field though it is trained with only normal data compared to the other methods that are trained with much more data including both normal and abnormal.\nTo show the effectiveness of our proposed method for anomalous channel detection, in a seizure test clip, we mark the channel with an anomaly score greater than \u03c41 as an anomaly and compare them with the ground-truth of seizure channels provided in the TUSZ dataset. The performance is reported in Table 4. As it can be seen, the proposed technique can effectively identify the anomalous node in a realworld dataset, as well.\nFigure 3 visualizes the anomaly score of the EEG channels for a typical focal seizure clip and a typical generalized seizure clip. Subfigure (a) shows that, as is expected, the channels with high anomaly scores (e.g., FP2 to C4 and F8 to T6) are focused on specific brain regions that also match the ground-truth. For the generalized seizure case shown in subfigure (b), as is expected, the EEG-CGS method correctly tells us that anomalous channels are spread across the brain, not focused on a specific region as opposed to the focal seizure case shown in (a)."
        },
        {
            "heading": "Visualization of Graph\u2019s Nodes Connectivity",
            "text": "This section is to visualize the EEG graph level of nodes connectivity (i.e. adjacency matrix) changes when a seizure happens. At each graph, the intensity of an edge between nodes vi and vj depends on the value of aij in the graph\u2019s adjacency matrix. This figure also visualizes the level of node strength, where the level of strength at node vi is defined as \u03a3nj=1,j 6=iaij , i.e. the summation of all connectivities per node \u2013 if a node is connected to channels with high\nadjacency values, a high level of strength is assigned to the node.\nAs is discussed in the EEG Graph Construction section, the adjacency matrix of Dist-EEG and Rand-EEG graphs do not change when a seizure happens since they are defined based on the Euclidean distance of node locations and independent from the node attributes. However, the connectivities (i.e. adjacency matrices) vary in the Corr-EEG and DTF-EEG graphs when a seizure happens. These changes are noticeable when one compares the node connectivities and level of strengths before, at the onset, and during a seizure incident. As is shown in Figure 2, before a seizure incident (i.e. in normal brain activity), in the Corr-EEGGraph, all nodes have almost similar level of strengths and every node is connected to almost similar number of other nodes. This uniform structure changes when the seizure starts and deepen during a seizure episode. The changes happen to the DTF-EEG graph are also visualized in the figure. As it can be seen, this graph also carries important information and its variations help in distinguishing a seizure activity from normal. This figure demonstrates the effectiveness of the proposed constructed graphs in identifying seizure channels and clips in the self-supervised way."
        },
        {
            "heading": "Hyperparameters Sensitivity",
            "text": "In this section, we investigate the effect of hyperparameters \u03bb, \u03b1, and d\u2032 on the performance of the proposed method.\nIn Figure 4a, we explore the importance of the con-\ntrastive and generative components through changing the hyperparameter \u03bb in the loss function L defined in (10), where \u03bb \u2208 {0, 0.6, 1}. \u03bb = 0 (1) is equivalent to removing the contrastive (generative) component of the proposed method, while setting \u03bb to a moderate value such as 0.6 allows the method to include both components when training its networks. We explored the performance of EEG{d,r,c,f}CGS for these three values. The results show that for all method variations, \u03bb = 0.6 provides a better AUC compared to the extreme cases \u03bb = 0 and \u03bb = 1.\nIn Figure 4b, we explore the impact of subgraph size, i.e. \u03b1 by selecting \u03b1 from the set {1, 2, 4, 6, 8}. We observe that more reliable performance (with high AUC value) can be obtained for \u03b1 = 4, i.e. 4 nodes are included in a subgraph.\nTo investigate the effect of the embedding space dimension d\u2032 on the proposed method, we run our method variations using different d\u2032 values from set {16, 32, 64, 128, 256, 512}. The results shown in Figure 4c demonstrate that the method is not too sensitive to this hyperparameter and a reliable and accurate performance can be obtained for a wide range of d\u2032."
        },
        {
            "heading": "Conclusion",
            "text": "This paper is the first attempt on providing a self-supervised method for anomalous EEG channel detection. The proposed EEG-CGS method, consisting of contrastive and generative components, is trained only on normal EEG data\nwith no-access to the abnormal samples. We propose to construct EEG attributed sub-graphs to capture the local structural and contextual information. The performance of the proposed method is demonstrated on both synthetic and real-world anomalies. The proposed method sets a new state-of-the-art for seizure detection on the largest and most difficult publicly available seizure dataset. EEG-CGS can be considered as an anomalous channel detection technique that can be employed for the detection of other brain disorders. The employ of sub-graphs rather than the whole EEG graph also makes the algorithm appropriate in applications, such as coma outcome prognosis, where access to all EEG channels is not possible, e.g. due to skull fractures."
        },
        {
            "heading": "Acknowledgments",
            "text": "The authors would like to acknowledge the financial support of the Natural Sciences, Engineering Research Council of Canada (NSERC), Fonds de recherche du Quebec, and the Department of Electrical and Computer Engineering at McGill University. The authors also wish to thank Calcul Quebec and Compute Canada for providing the necessary computational resources to conduct our experiments."
        },
        {
            "heading": "Ethics Statement",
            "text": "The Temple University Hospital EEG Seizure Corpus is publicly available with full Institutional Review Board (IRB) approval (Shah et al. 2018) at https://isip.piconepress. com/projects/tuh eeg/html/downloads.shtml. The authors have no conflicts of interest to declare. No harmful insights are observed by our proposed method described in this paper. Source code is publicly available at https://github.com/ Armanfard-Lab/EEG-CGS."
        }
    ],
    "title": "Self-Supervised Learning for Anomalous Channel Detection in EEG Graphs: Application to Seizure Analysis",
    "year": 2023
}