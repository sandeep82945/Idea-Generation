{
    "abstractText": "Breast cancer is a common but serious and even lethal disease. Fortunately, compared with other cancers, breast cancer treatments currently are relatively well developed. The use of specific drugs is typically essential in the majority of breast cancer treatment strategies. Given the aforementioned factors, it is important to continue researching effective antibreast cancer drug design. Machine learning-based computer-aided drug design is currently a common practice in both drug industries and academic institutes. According to the characteristics of breast cancer, we selected multiple candidate compounds; based on the corresponding molecular descriptors, biological activities, and pharmacokinetic properties, a dataset of inhibition potency and pharmacokinetic properties paired with multiple features of compounds was constructed. On this basis, the random forest method was utilized to choose greater-influenced feature embeddings; thus, 224 main operating variables were selected for further analysis; we then employed the efficient MobileNetV3 deep neural network as the backbone to establish the prediction models for the inhibition potency and pharmacokinetic properties of the compounds. After data preprocessing, the weights are obtained by training on the refined dataset. Finally, we define an optimization problem to discover compounds with the best properties. The problem is solved using the genetic algorithm with the acquired prediction model, and the solution value for the corresponding operating variables with the best clinical properties in theory is then obtained. Analysis demonstrates that our approach could be used to aid the screening process of antibreast cancer drug candidates.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zhibai Huang"
        },
        {
            "affiliations": [],
            "name": "Shengji Jiang"
        },
        {
            "affiliations": [],
            "name": "Weiqiang Xiao"
        },
        {
            "affiliations": [],
            "name": "Jincheng Wang"
        }
    ],
    "id": "SP:8a7b1b1786d0239c78962d648cfa66fb7cf573ce",
    "references": [
        {
            "authors": [
                "A.G.Waks",
                "E.P. Winer"
            ],
            "title": "Breast cancer treatment",
            "venue": "JAMA, vol. 321, no. 3, pp. 288\u2013300, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M.J. Duffy"
            ],
            "title": "Estrogen receptors: role in breast cancer",
            "venue": "Critical Reviews in Clinical Laboratory Sciences, vol. 43, no. 4, pp. 325\u2013 347, 2006.",
            "year": 2006
        },
        {
            "authors": [
                "S. Ali",
                "R.C. Coombes"
            ],
            "title": "Estrogen receptor alpha in human breast cancer: occurrence and significance",
            "venue": "Journal of Mammary Gland Biology and Neoplasia, vol. 5, no. 3, pp. 271\u2013281, 2000.",
            "year": 2000
        },
        {
            "authors": [
                "M. Sarhadi",
                "L. Aryan",
                "M. Zarei"
            ],
            "title": "The estrogen receptor and breast cancer: a complete review",
            "venue": "CRPASE Transactions of Applied Sciences, vol. 6, pp. 309\u2013314, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "W.P. Bocchinfuso",
                "K.S. Korach"
            ],
            "title": "Mammary gland development and tumorigenesis in estrogen receptor knockout mice",
            "venue": "Journal of Mammary Gland Biology and Neoplasia, vol. 2, no. 4, pp. 323\u2013334, 1997.",
            "year": 1997
        },
        {
            "authors": [
                "V.C. Jordan"
            ],
            "title": "Tamoxifen: a most unlikely pioneering medicine",
            "venue": "Nature Reviews Drug Discovery, vol. 2, no. 3, pp. 205\u2013 213, 2003.",
            "year": 2003
        },
        {
            "authors": [
                "C.K. Osborne"
            ],
            "title": "Tamoxifen in the treatment of breast cancer",
            "venue": "New England Journal of Medicine, vol. 339, no. 22, pp. 1609\u2013 1618, 1998.",
            "year": 1998
        },
        {
            "authors": [
                "B. Furr",
                "V. Jordan"
            ],
            "title": "The pharmacology and clinical uses of tamoxifen",
            "venue": "Pharmacology & Therapeutics, vol. 25, no. 2, pp. 127\u2013205, 1984.",
            "year": 1984
        },
        {
            "authors": [
                "X. Fang",
                "J. Cao",
                "A. Shen"
            ],
            "title": "Advances in anti-breast cancer drugs and the application of nano-drug delivery systems in breast cancer therapy",
            "venue": "Journal of Drug Delivery Science and Technology, vol. 57, article 101662, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A. Emadi",
                "R.J. Jones",
                "R.A. Brodsky"
            ],
            "title": "Cyclophosphamide and cancer: golden anniversary",
            "venue": "Nature Reviews Clinical Oncology, vol. 6, no. 11, pp. 638\u2013647, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "L. Gianni",
                "T. Pienkowski",
                "Y.H. Im"
            ],
            "title": "Efficacy and safety of neoadjuvant pertuzumab and trastuzumab in women with locally advanced, inflammatory, or early HER2-positive breast cancer (NeoSphere): a randomised multicentre, open-label, phase 2 trial",
            "venue": "The Lancet Oncology, vol. 13, no. 1, pp. 25\u201332, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "M. Capelan",
                "L. Pugliano",
                "E. de Azambuja"
            ],
            "title": "Pertuzumab: new hope for patients with HER2-positive breast cancer",
            "venue": "Annals of Oncology, vol. 24, no. 2, pp. 273\u2013282, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "S.M. Swain",
                "J. Baselga",
                "S.B. Kim"
            ],
            "title": "Pertuzumab, trastuzumab, and docetaxel in HER2-positive metastatic breast cancer",
            "venue": "New England Journal of Medicine, vol. 372, no. 8, pp. 724\u2013734, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "R. Gozalbes",
                "J. Doucet",
                "F. Derouin"
            ],
            "title": "Application of topological descriptors in QSAR and drug design: history and new trends",
            "venue": "Current Drug Targets-Infectious Disorders, vol. 2, no. 1, pp. 93\u2013102, 2002.",
            "year": 2002
        },
        {
            "authors": [
                "J. Verma",
                "V.M. Khedkar",
                "E.C. Coutinho"
            ],
            "title": "3D-QSAR in drug design - a review",
            "venue": "Current Topics in Medicinal Chemistry, vol. 10, no. 1, pp. 95\u2013115, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "Y. Wang",
                "J. Xing",
                "Y. Xu"
            ],
            "title": "In silicoADME/T modelling for rational drug design",
            "venue": "Quarterly Reviews of Biophysics, vol. 48, no. 4, pp. 488\u2013515, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "F. Ghasemi",
                "A. Mehridehnavi",
                "A. Perez-Garrido",
                "H. Perez- Sanchez"
            ],
            "title": "Neural network and deep-learning algorithms used in QSAR studies: merits and drawbacks",
            "venue": "Drug Discovery Today, vol. 23, no. 10, pp. 1784\u20131790, 2018. 12 Computational and Mathematical Methods in Medicine",
            "year": 2018
        },
        {
            "authors": [
                "S.P. Niculescu"
            ],
            "title": "Artificial neural networks and genetic algorithms in QSAR",
            "venue": "Journal of Molecular Structure: THEO- CHEM, vol. 622, no. 1\u20132, pp. 71\u201383, 2003.",
            "year": 2003
        },
        {
            "authors": [
                "W. Cui",
                "A. Aouidate",
                "S. Wang",
                "Q. Yu",
                "Y. Li",
                "S. Yuan"
            ],
            "title": "Discovering anti-cancer drugs via computational methods",
            "venue": "Frontiers in Pharmacology, vol. 11, p. 733, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "G.R. Marshall"
            ],
            "title": "Computer-aided drug design,\u201dAnnual",
            "venue": "Review of Pharmacology and Toxicology,",
            "year": 1987
        },
        {
            "authors": [
                "J. Xiong",
                "Z. Xiong",
                "K. Chen",
                "H. Jiang",
                "M. Zheng"
            ],
            "title": "Graph neural networks for automated _de novo_ drug design",
            "venue": "Drug Discovery Today, vol. 26, no. 6, pp. 1382\u20131393, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "C.H. Liu",
                "M. Korablyov",
                "S. Jastrz\u0119bski",
                "P. W\u0142odarczyk- Pruszy\u0144ski",
                "Y. Bengio",
                "M.H. Segler"
            ],
            "title": "RetroGNN: approximating retrosynthesis by graph neural networks for de novo drug design",
            "venue": "2020, http://arxiv.org/abs/2011.13042.",
            "year": 2020
        },
        {
            "authors": [
                "A. Howard",
                "M. Sandler",
                "G. Chu"
            ],
            "title": "Searching for mobilenetv3",
            "venue": "Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 1314\u20131324, Seoul, Korea, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "X. Lu",
                "H. Wu",
                "Y. Zeng"
            ],
            "title": "Classification of Alzheimer\u2019s disease in MobileNet",
            "venue": "Journal of Physics: Conference Series, vol. 1345, no. 4, article 042012, 2019.",
            "year": 2012
        },
        {
            "authors": [
                "W. Sae-Lim",
                "W. Wettayaprasit",
                "P. Aiyarak"
            ],
            "title": "Convolutional neural networks using MobileNet for skin lesion classification",
            "venue": "2019 16th International Joint Conference on Computer Science and Software Engineering (JCSSE), pp. 242\u2013247, Chonburi, Thailand, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "D.-S. Cao",
                "Q.-S. Xu",
                "Q.-N. Hu",
                "Y.-Z. Liang"
            ],
            "title": "ChemoPy: freely available python package for computational biology and chemoinformatics",
            "venue": "Bioinformatics, vol. 29, no. 8, pp. 1092\u20131094, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "S. Patro",
                "K.K. Sahu"
            ],
            "title": "Normalization: A preprocessing stage",
            "venue": "2015, http://arxiv.org/abs/1503.06462.",
            "year": 2015
        },
        {
            "authors": [
                "L. Breiman"
            ],
            "title": "Random forests",
            "venue": "Machine Learning, vol. 45, no. 1, pp. 5\u201332, 2001.",
            "year": 2001
        },
        {
            "authors": [
                "K. Simonyan",
                "A. Zisserman"
            ],
            "title": "Very deep convolutional networks for large-scale image recognition",
            "venue": "2014, http://arxiv .org/abs/1409.1556.",
            "year": 2014
        },
        {
            "authors": [
                "L. Bottou"
            ],
            "title": "Large-scale machine learning with stochastic gradient descent",
            "venue": "Proceedings of COMPSTAT\u20192010, , pp. 177\u2013186, Springer, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: a method for stochastic optimization",
            "venue": "2014, http://arxiv.org/abs/1412.6980.",
            "year": 2014
        },
        {
            "authors": [
                "I. Loshchilov",
                "F. Hutter"
            ],
            "title": "Decoupled weight decay regularization",
            "venue": "2017, http://arxiv.org/abs/1711.05101.",
            "year": 2017
        },
        {
            "authors": [
                "D. Whitley"
            ],
            "title": "A genetic algorithm tutorial",
            "venue": "Statistics and Computing, vol. 4, no. 2, pp. 65\u201385, 1994.",
            "year": 1994
        },
        {
            "authors": [
                "M. Dorigo",
                "M. Birattari",
                "T. Stutzle"
            ],
            "title": "Ant colony optimization",
            "venue": "IEEE Computational Intelligence Magazine, vol. 1, no. 4, pp. 28\u201339, 2006.",
            "year": 2006
        },
        {
            "authors": [
                "J. Kennedy",
                "R. Eberhart"
            ],
            "title": "Particle swarm optimization",
            "venue": "Proceedings of ICNN\u201995-international conference on neural networks, pp. 1942\u20131948, Perth, WA, Australia, 1995. 13 Computational and Mathematical Methods in Medicine",
            "year": 1942
        }
    ],
    "sections": [
        {
            "text": "Research Article Optimization Method of an Antibreast Cancer Drug Candidate Based on Machine Learning\nZhibai Huang , Shengji Jiang , and Weiqiang Xiao\nEast China Institute of Computing Technology, Shanghai, China\nCorrespondence should be addressed to Zhibai Huang; huangzhibainudt4@nudt.edu.cn\nReceived 19 July 2022; Revised 17 August 2022; Accepted 22 August 2022; Published 5 September 2022\nAcademic Editor: Jincheng Wang\nCopyright \u00a9 2022 Zhibai Huang et al. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\nBreast cancer is a common but serious and even lethal disease. Fortunately, compared with other cancers, breast cancer treatments currently are relatively well developed. The use of specific drugs is typically essential in the majority of breast cancer treatment strategies. Given the aforementioned factors, it is important to continue researching effective antibreast cancer drug design. Machine learning-based computer-aided drug design is currently a common practice in both drug industries and academic institutes. According to the characteristics of breast cancer, we selected multiple candidate compounds; based on the corresponding molecular descriptors, biological activities, and pharmacokinetic properties, a dataset of inhibition potency and pharmacokinetic properties paired with multiple features of compounds was constructed. On this basis, the random forest method was utilized to choose greater-influenced feature embeddings; thus, 224 main operating variables were selected for further analysis; we then employed the efficient MobileNetV3 deep neural network as the backbone to establish the prediction models for the inhibition potency and pharmacokinetic properties of the compounds. After data preprocessing, the weights are obtained by training on the refined dataset. Finally, we define an optimization problem to discover compounds with the best properties. The problem is solved using the genetic algorithm with the acquired prediction model, and the solution value for the corresponding operating variables with the best clinical properties in theory is then obtained. Analysis demonstrates that our approach could be used to aid the screening process of antibreast cancer drug candidates."
        },
        {
            "heading": "1. Introduction",
            "text": "Breast cancer currently ranks among the most prevalent cancers worldwide [1] and has a high fatality rate. Estrogen receptors are connected with the development of breast cancer [2, 3]. Given that the estrogen receptor \u03b1 subtype (estrogen receptor alpha (ER\u03b1)) is present in roughly 70% of breast cancer cells [4], it has been widely considered in the diagnosis of breast cancer [2]. Studies on mice with ER\u03b1 gene modifications have demonstrated that ER\u03b1 does, in fact, play a crucial role in the development of the uterus and mammary glands [4, 5]. Consequently, as ER\u03b1 is considered a key target for the treatment of breast cancer, substances that can suppress ER\u03b1 activity might be proper candidates for use as therapeutics [2].\nFor a long time, the gold standard for the endocrine treatment of several breast cancer types was tamoxifen [6], a common drug with estrogen-like actions. Since tamoxifen\nwas found to be effective in treating breast cancer, numerous studies have been conducted to highlight the significance of hormone therapy for the disease [7, 8]. In addition to hormone therapy, other medicines for breast cancer include chemotherapy and immunological therapy [9]. As the leading drugs for the aforementioned therapies, cyclophosphamide, docetaxel, pertuzumab, and trastuzumab are currently commonly used to treat breast cancer [10\u201313].\nBuilding an inhibitory potency prediction model can be used to screen candidate compounds during the conventional drug design process to save time and money [14]. The precise procedure is as follows: first, for a biological target associated with a disease, gather data on a number of compounds that affect the target and their biological activity. Next, build a quantitative structure-activity relationship (QSAR) model of candidates using a number of molecular descriptors as independent variables and the biological activity value of the compound as the dependent variable. Finally,\nHindawi Computational and Mathematical Methods in Medicine Volume 2022, Article ID 4133663, 13 pages https://doi.org/10.1155/2022/4133663\nthe model is employed to forecast how a molecule might seem when having sufficient biological activity or to direct the structural improvement of already existing compounds [15].\nIn addition to having significant biological activity, a chemical should also have appropriate pharmacokinetic and safety qualities in the human body to be employed as a new medicine. Similar to that, it can be evaluated using an established QSAR model [16]. There are numerous ways to create prediction models at the time, whereas methods based on artificial neural networks have received more attention from academic communities than other alternatives [15, 17, 18]. Computer-aided drug design techniques have been applied extensively in many aspects of drug design after years of development [19, 20]. Deep neural networks have been extensively used since the dawn of the big data age, and numerous research in drug design have been conducted [21, 22]. A few researchers have attempted to use the effective convolutional neural network MobileNetV3 [23] in the field of medicine [24, 25].\nIn this research, based on the current knowledge, we created a dataset of potential antibreast cancer drug candidates, and then, we refined the dataset by applying the random forest algorithm. We explore adopting MobileNetV3 to create a QSAR model on the refined dataset to construct the qualitative model of pharmacokinetic performance and the quantitative prediction model of inhibitory potency. Finally, a problem for optimizing the attributes of the chemical is created based on the model that was obtained and the genetic algorithm is utilized to solve the problem."
        },
        {
            "heading": "2. Dataset Construction and Preprocessing",
            "text": "2.1. Dataset Construction. According to prior knowledge and experience, we selected a total of 1974 compounds, calculated the corresponding 2-dimensional and 3-dimensional molecular descriptors by computing software [26], and subsequently marked their biological activity values and ADMET properties to complete the construction of the dataset. We choose IC50, pIC50 as the index for biological activity, Caco-2 for A (absorption), CYP3A4 for D (distribution), hERG for M (metabolism), HOB for E (excretion), and MN for T (toxicity). Specifically, Caco-2 is the permeability of small intestinal epithelial cells, which can measure the ability of the compound to be absorbed by the human body. CYP3A4 is the cytochrome P450 enzyme 3A4 isoform, which is the main metabolic enzyme in the human body, which can measure the compound. hERG is the cardiac safety evaluation of the compound, which can measure the cardiotoxicity of the compound. HOB is the oral bioavailability of the human body, which can measure the proportion of the drug absorbed into the human blood circulation after entering the human body. MN is the micronucleus test and is a method to detect whether a compound is genotoxic.\nBased on the dataset (including 1974 compound samples, each with 1361 molecular descriptor variables, e.g., electrotopological state atom type descriptor, ring count descriptor, WHIM descriptor etc., 2 biological activity data, and 5 ADMET property data), we then built a quantitative\nprediction model for compound biological activity and a categorical prediction model for ADMET properties."
        },
        {
            "heading": "2.2. Data Preprocessing",
            "text": "2.2.1. Data Cleaning. Due to some problems in the collected raw data, to ensure the data analysis quality, the raw data should be cleaned in a certain level. The overall data processing method is as follows:\n(1) There is dimensionless normalization of molecular descriptor data in all samples\n(2) For data columns with most of the data being 0, delete them directly\n(3) Only the pIC50 array was selected as the biological activity label\nConsidering the large difference in raw values between different molecular descriptors, to improve the model accuracy, we first use the min-max normalization method [27] to perform dimensionless normalization on the molecular descriptor data.\nOn this basis, we double check the normalized samples and delete most of the data columns with 0 values (dimensionless normalized molecular descriptors) to reduce data redundancy. Make datasets more compact and efficient without losing too much information. By excluding some factors with low impact on biological activity in advance, the convergence speed of subsequent selection of main features should be accelerated.\nFinally, we chose pIC50 as the only numerical annotation for biological activity. Since the pIC50 value is distributed in the \u00bd0, 10 interval, it is more friendly to the deep network model. Considering that the IC50 and pIC50 can be equivalently transformed through numerical calculation, dropping the IC50 label should not ignore valuable information. Only pIC50 is selected as the biological activity numerical labeling instead of the IC50 and pIC50 binary label group; we believe that the sole existence of pIC50 should make the dataset more \u201ccompact,\u201d thus leading to a more efficient and accurate prediction model.\n2.2.2. Selecting Main Features. Considering the large number of data columns in the dataset, it is necessary to further compress the number of data columns; we chose to use the random forest algorithm [28] to select features to further compress the dataset. The importance of each feature can be obtained by performing certain operations on the result of the sample classification. The smaller the result is, the smaller impact that this feature affects the prediction result. According to the variable contribution ranking obtained by random forest algorithm, we select a total of 224 data columns (which are processed molecular descriptors) in order of contribution, as shown in Figure 1.\nAmong them, XlogP is the lipid-water partition coefficient, which reflects the absorption effect of molecules through the cell membrane. TopoPSA is the topological polar surface area, reflecting factors such as molecular size and solubility. From the statistical results of the categories\nto which each variable belongs, it can be seen that the extracted variables include a certain level of comprehensive types of compound fingerprints. The variance is relatively minimal, which suggests that the extracted variables place a balanced emphasis on each category, according to the distribution of the number of variables contained in each category. The final selected normalized molecular descriptors are shown in Table 1. After the compressing process, we have done all data preprocessing for the deep neural network."
        },
        {
            "heading": "3. Compound Property Prediction Model",
            "text": ""
        },
        {
            "heading": "3.1. Quantitative Prediction Model for Biological Activity",
            "text": "3.1.1. Model Design. Artificial neural networks are currently employed and widely applied in the field of computer-aided drug design. The most often used neural network is the BP (back propagation) neural network, a multivariate feedforward neural network trained via error back propagation. Deep neural networks, a version of BP neural networks, have drawn considerable attention in many fields of academia and industry. Convolutional neural networks among them have significant advantages in performance and are especially well liked in the field of computer vision. However, it is important to keep in mind that the majority of the current popular convolutional neural networks have complex structures, thus containing a lot of parameters, combined with the neural network\u2019s data-hungry nature making model training very challenging. Special consideration should be given when training these networks on relatively small-amount biological activity datasets.\nOn the other hand, it is crucial to properly design the number of neurons in the hidden layer during the whole network construction process. The workload required to make the network function will significantly arise if the hidden layer contains too many neurons, which can quickly result in an undesired overfitting issue. Conversely, if the hidden layer contains too few neurons, which will also negatively\naffect the network\u2019s quality, thus resulting in poor prediction accuracy. The total number of neurons in a neural network\u2019s hidden layer is directly correlated with the difficulty of the task, the number of neurons in the input and output layers, and the expected bias settings of those neurons.\nConsidering the mentioned problems, we chose the MobileNetV3 deep convolutional neural network as the backbone to construct a quantitative prediction model for the biological activity of compounds. As one of the representatives of lightweight models, compared to the classic convolutional network VGG16 [29], MobileNetV3 greatly reduces the number of parameters but is more efficient and easier to train while ensuring similar performance. The schematic diagram of the network structure that we use is shown in Figure 2.\n3.1.2. Model Training.We first divide the 1974 group of data in the dataset into training set data (around 80% in amount), test set data (around 15% in amount), and validation set (around 5% in amount) according to the proportions of 80%, 15%, and 5%, respectively. After the division is completed, 224 main variables in the dataset and pIC50 annotations were constructed as a pair; then, randomly sample 10 data pairs as a batch for model input.\nAs an important part of model optimization, the loss function needs to be carefully considered. Considering that the quantitative prediction problem can be summarized as a regression problem, we choose MSELoss (mean square error loss), the most commonly used one in the regression task, as the loss function.\nDeep learning tasks will produce varying results depending on the optimizers used. We first identified the SGD (stochastic gradient descent) [30] and Adam optimizer (adaptive moment estimation optimizer) [31] as alternatives based on the properties of the MobileNetV3 network itself and the properties of the dataset; we then compared the performance in the experimental training, and Adam was ultimately selected as the optimizer.\nTable 1: The contribution of the top 224 important molecular descriptors (from low to high).\nDescriptor Importance\nSmax11 0.00065\nMATSp7 0.00065\nCIC4 0.000652\nMDEC-14 0.000656\nS17 0.000659\nminHCsats 0.00066\nSmin34 0.000661\nSHaaCH 0.000664\nSIC3 0.000664\nSHCsats 0.000681\nSmin 0.000681\nCrippenLogP 0.000682\nmaxsOH 0.000684\nATSc1 0.000684\nbcutm13 0.000684\nphi 0.000686\nMATSm3 0.000688\nCIC3 0.000688\nVSAEstate7 0.000691\nSPC-4 0.000695\nEstateVSA7 0.000702\nSmin8 0.000704\nWTPT-5 0.000706\nTPSA1 0.000708\nnaccr 0.00071\nMATSm7 0.000712\nmaxdsN 0.000712\nCIC1 0.000713\nSmin35 0.000714\nATSe5 0.000716\nminHCsatu 0.000725\nGATSp3 0.000726\nGATSm5 0.000727\nALogp2 0.000729\nGATSp7 0.00073\nEstateVSA1 0.000737\nIDE 0.000741\nmindO 0.000744\nmChi1 0.000745\nSaasC 0.00076\nbcute9 0.000761\nnAtomLAC 0.000762\nmaxdssC 0.000771\nGATSe7 0.000775\nSmax 0.000781\nETA_Epsilon_1 0.000787\nMATSv5 0.000789\nbcutp5 0.000793\nTable 1: Continued.\nDescriptor Importance\nIC1 0.000796\nmaxHBint7 0.000797\nQCss 0.000823\nCIC6 0.000823\nALogP 0.000826\nbcutm3 0.00083\nSsOH 0.000847\nBertzCT 0.000851\nEstateVSA4 0.000851\nSdssC 0.000855\nbcutm2 0.000866\nMAXDN 0.000868\nPC6 0.000872\nMATSm6 0.000891\nSHBint5 0.000897\nSaaCH 0.0009\nMATSp5 0.000901\nMRVSA6 0.000904\nslogPVSA1 0.000904\nMATSm5 0.000922\nbcute12 0.000926\nJ 0.000927\nGATSm4 0.000927\nMRVSA5 0.000933\nMATSm1 0.000934\nGATSm8 0.000939\nSmin12 0.000946\nhmin 0.00095\nVC-4 0.000962\nMATSe5 0.000963\nMATSp4 0.000964\nPEOEVSA5 0.000967\nminHBd 0.000971\nGATSv3 0.000974\nbcutm9 0.000979\nPEOEVSA8 0.00098\nECCEN 0.000987\nMATSm8 0.000988\nIC2 0.000995\nBCUTp-1l 0.001004\nminssCH2 0.001017\nQHss 0.001019\nSmax16 0.00102\nbcutm12 0.001026\nETA_EtaP_F 0.001026\nETA_dEpsilon_D 0.001038\nbcute4 0.001038\nWTPT-3 0.001042\nMAXDP2 0.001042\nTable 1: Continued.\nDescriptor Importance\nknotpv 0.001043\nMDEO-11 0.001043\nmaxHCsats 0.00105\nChiv5ch 0.001063\nGATSe5 0.001072\nVPC-5 0.001081\nMATSv8 0.00109\nmaxsF 0.001096\nQNmin 0.001109\nETA_BetaP_s 0.001109\nChiv6ch 0.00111\nIC3 0.001117\nVPC-6 0.001119\nVSAEstate2 0.001121\nMATSp3 0.001137\nslogPVSA2 0.00114\nWTPT-4 0.001162\ngmin 0.001163\nminHBint6 0.001176\nminHBint7 0.001195\nSmax24 0.001225\nMATSp6 0.001229\nPEOEVSA1 0.001234\nSIC2 0.001237\nS34 0.001257\nbcute1 0.001278\nMATSv3 0.001281\nSC-5 0.001283\ndchi0 0.00129\nSIC1 0.001291\nmaxHBd 0.001307\nPEOEVSA7 0.001342\nMDEC-24 0.001345\nSCH-7 0.001347\nSHBd 0.001349\nMATSe8 0.001375\nMATSv1 0.001375\nSHCsatu 0.001386\nSmin15 0.001398\nBCUTp-1h 0.00141\nGATSm3 0.001461\nbcutp12 0.001465\nMLFER_BH 0.001485\nGATSv1 0.001559\nQOmax 0.001589\nslogPVSA0 0.001592\nbcute10 0.001605\nSmin24 0.001609\nMATSp1 0.001616\nTable 1: Continued.\nDescriptor Importance\nChiv3 0.001662\nQNmax 0.001663\nbcutv4 0.00168\nVCH-5 0.001717\nVSAEstate4 0.001785\nATSc5 0.001813\nC3SP2 0.001831\nmindssC 0.001846\nATSc2 0.001859\nminHBint10 0.001866\nATSc3 0.001892\nMDEC-22 0.001909\nMAXDP 0.001935\nknotp 0.001942\nGATSm1 0.002\nGATSp4 0.002026\nmaxsssCH 0.002031\nS25 0.002032\nbcutp1 0.002049\nETA_Shape_Y 0.002124\nbcutp9 0.002186\nXLogP 0.002237\nATSc4 0.002298\nmaxHBint5 0.002321\nmaxHBint8 0.002379\nminsOH 0.002424\nGATSm2 0.002443\nSPC-6 0.00248\nMATSe3 0.002549\nMLFER_S 0.002597\nSHBint6 0.002733\nndssC 0.002743\nbcutv1 0.002787\nVCH-7 0.002879\nBCUTc-1l 0.002923\nQCmax 0.00298\nScar 0.003191\nminssO 0.003312\nBCUTc-1h 0.003494\nMLFER_A 0.003711\nTopoPSA 0.003768\nMDEO-12 0.003868\nminHBa 0.004054\nSmin33 0.004253\nSHsOH 0.004402\nGATSe8 0.004485\nPEOEVSA6 0.00461\nMnc 0.004826\nMATSe1 0.004978\nFinally, considering the nature of the Adam optimizer itself, we adopt the cosine annealing strategy [32] to update the learning rate to optimize the performance of the model as much as possible. In selecting the most suitable upper limit of the hyperparameter learning rate and the number of epochs, we also performed experimental training on the actual training set. Ultimately, we came to the conclusion that the upper limit of the learning rate is 0.0001 and the number of epochs is 100."
        },
        {
            "heading": "3.2. Qualitative Prediction Model for ADMET Properties. To",
            "text": "simplify the problem, we trained the models separately for the five properties in ADMET. To further simplify the problem, we believe that each property has only two possibilities of \u201cyes\u201d or \u201cno,\u201d which can be expressed by the values 0 and 1. In this way, the problem can be classified as a binary classification problem; then, we can reuse the divided dataset given in Section 3.1.2 and merely change the data label to pharmacokinetic properties.\nSince the input data share a certain level of similarity, we still employ the MobileNetV3 structure as the backbone; therefore the desired model structure is essentially identical\nto the structure described in Figure 2. The only needed minor change is to adjust the output neuron of the bottom fully connected layer and add an extra sigmoid activation function; other designs shall not be repeated here.\nTo adapt to the binary classification problem, the model training method also needs to be adjusted. We changed the loss function to BCELoss (binary cross entropy loss), while the optimizer, learning rate adjustment strategy, and hyperparameter setup remain unchanged. The prediction accuracy is obtained based on the comparison between the predicted outputs and the real labels.\nDuring the training process based on experiments on real datasets, the issue of data imbalance has been found. To prevent the trained model from being biased due to data imbalance, we redundantly expand the data, that is, expanding the samples of a relatively small number to be roughly equivalent to the other categories."
        },
        {
            "heading": "3.3. Optimization Model for Clinical Properties Based on",
            "text": "Specific Features\n3.3.1. Definition of Optimization Problem. We now define an optimization problem using these six prediction models that were trained in earlier sections, looking for the ideal circumstances for the 224 variable values that were chosen. Note that we assume that any \u201cacceptable\u201d compound must perform \u201cwell\u201d at least three of the given ADMET properties; then, the problem could be defined as follows:\nDefinition 1. Given the selected molecular descriptor, what value of the molecular descriptor satisfied can make the compound have better biological activity for inhibiting ER\u03b1, meanwhile having better ADMET properties (at least three or better).\n3.3.2. Optimization Problem Modeling. First, determine the decision variables; we follow the selected results in the previous section; consider the selected 224 molecular descriptors as decision variables, denoted as follows:\nX = x1, x2, x3,\u22ef, x224f g: \u00f01\u00de\nNow, determine the objective function. After analyzing the problem, we can find that the problem essentially is as follows: based on the given prediction models, under the premise that at least three properties of the given five ADMET properties are \u201cgood,\u201d by changing the value of selected features, the clinical properties (both inhibition potency and pharmacokinetic performance) are optimized to guide the production process. The biological activity of the compound is altered by the chosen feature\u2019s value; it is worth noting that this process will also alter the compounds\u2019 ADMET properties. Therefore, the relations between each model should not be ignored. By applying the prediction models to the input samples, the predicted value of ADMET properties of each sample can be obtained. Following the idea in Section 3.2, we take all the values representing good properties as 1 and the values of bad properties as 0; then, we get an optimization limit that the pharmacokinetic point\nTable 1: Continued.\nDescriptor Importance\nLDI 0.005205\nMDEC-33 0.005471\nGATSe1 0.005843\nbcute2 0.005866\nVC-5 0.006197\nnC 0.0064\nnHBAcc 0.006408\nLogP2 0.006781\nSHBint10 0.006873\nHy 0.007517\nkappam3 0.007695\nVSAEstate1 0.007799\nQNss 0.009891\nminsssN 0.01014\nLogP 0.011371\nmaxssO 0.011647\nATSp4.1 0.013044\nQHmax 0.014923\nC1SP2 0.01631\nminHBint5 0.017225\nATSv5 0.017404\nSmax35 0.018515\nminHsOH 0.025883\nmaxHsOH 0.028849\nLipoaffinityIndex 0.031403\nQOmin 0.041317\nQmin 0.043254\nMDEC-23 0.049635\nATSp5.1 0.143226\n(the sum of ADMET property marks) has a maximum value of 5. According to Definition 1, the ADMET marks of an \u201cacceptable\u201d compound should not be less than 3; then, the modified output function of the qualitative prediction model is derived, denoted original output as \u03d5\u00f0X\u00de; then, denote our desired function as \u03a6\u00f0X\u00de, defined as follows:\n\u03a6 X\u00f0 \u00de = 0, 0 \u2264 \u3020 ADMETproperties \u03d5 X\u00f0 \u00de < 3,\n\u3020 ADMETproperties \u03d5 X\u00f0 \u00de, 3 \u2264 \u3020 ADMETproperties \u03d5 X\u00f0 \u00de \u2264 5:\n8>>< >>:\n\u00f02\u00de\nIn addition to the ADMET properties, we need to consider the pIC50 value of the compound as well. The goal of this output function is to obtain the highest activity value under the premise of satisfying \u201cacceptable\u201d ADMET properties; combined with the definition of pIC50, the modified quantitative prediction model output function is given. We denoted it as \u03a8\u00f0X\u00de and the original one as \u03c8\u00f0X\u00de, define as follows:\n\u03a8 X\u00f0 \u00de = 0, 10 < \u03c8 X\u00f0 \u00de, 0, \u03c8 X\u00f0 \u00de < 0, \u03c8 X\u00f0 \u00de, 0 \u2264 \u03c8 X\u00f0 \u00de \u2264 10: 8>< >: \u00f03\u00de\nIntuitively, the optimization problem should be a multiobjective nonlinear programming problem. To simplify the solution process, we transform it into a single-objective nonlinear programming problem to solve. Considering the optimization problem, it is desired that the compound\u2019s ADMET properties are as good as possible and the biological activity is as high as possible, that is, to find a set of selected feature values X0 to maximize the sum of \u03a6\u00f0X0\u00de and \u03a8\u00f0X0\u00de. In this way, we are able to extract the objective function of the optimization problem, which is defined as follows:\nF X\u00f0 \u00de =\u03a8 X\u00f0 \u00de +\u03a6 X\u00f0 \u00de: \u00f04\u00de\nFinally, determine the constraints: for this optimization problem, since the proposed 224 decision variables (dimensionless normalized molecular descriptors) have a certain range of actual values, there is constraint 1 as follows:\n0 \u2264 xi \u2264 1, i = 1, 2, 3,\u22ef, 224: \u00f05\u00de\nNow, take into account the biological activity limitation. Considering the predicted pIC50 value, according to the definition of pIC50, it can be seen that there is a constraint on the value of \u03c8\u00f0X\u00de and we hope that the optimized biological activity value is not lower than the maximum value in the dataset for building the prediction model, so there is a constraint 2 as follows:\n10 \u2265 pIC50t arg et \u2265 pIC50source \u2265 0: \u00f06\u00de\nCombine constraints with the target function; in summary, the problem can be defined as follows:\nMax F X\u00f0 \u00de\ns:t: 0 \u2264 xi \u2264 1, i = 1, 2, 3,\u22ef, 224,\n10 \u2265 pIC50target \u2265 pIC50source \u2265 0:\n( \u00f07\u00de\n3.3.3. Optimization Problem Solving. We now address the optimization problem raised in Section 3.3.2. It can be said that the optimization problem is a single-objective nonlinear optimization problem given the complicated link between molecular descriptors and biological activity. Intelligent optimization algorithms, such the genetic algorithm [33], ant colony algorithm [34], and particle swarm optimization [35], can be used to solve this type of problem\u2019s model to acquire the optimal set of variables. We employ the genetic algorithm to address the optimization problem since it can frequently produce better optimization results more quickly than some traditional optimization methods when solving complex combinatorial optimization problems. Figure 3 depicts a typical genetic algorithm optimization procedure.\nThe primary chromosomes of some members of the population are first constructed by performing binary coding on the sample operating variable\u2019s initial value, and the chromosomes of the remaining individuals are randomly generated within the value range of the operating variable. To determine the fitness of each chromosome in the population and to calculate the corresponding selection probability matrix, the binary-coded chromosomes are first decoded to the actual values of the altered variables before being input into the ADMET property prediction model and the biological activity prediction model. Chromosomes with higher fitness are more likely to be selected during evolution. Roulette selection is used in the selection strategy. Chromosomes interact with one another and mutate to create new chromosomes. Finally, if a combination of operational variables satisfies all requirements for biological activity and pharmacokinetic features, record the combination and optimize the following sample; if not, keep iterating until the ideal operating circumstances are discovered.\nWe built the solver in Python language to lessen the implementation\u2019s complexity. When using a genetic algorithm, simulating more complex \u201cpopulations\u201d takes longer and takes more effort. After simulation training and testing, we find the proper parameters for the solver. We randomly created the initial population and fixed the number to 2000, taking into account the difficulty of solving and the accuracy requirements. The number of iterations is limited\nTable 4: The predicted values for best-performance candidate\u2019s operating variables.\nDescriptor Normalized Real\nALogP 0.796372 22.52675\nALogp2 0.565526 301.9008\nnC 0.911078 80.17483\nATSc1 0.49451 2.244443\nATSc2 0.939863 2.221841\nATSc3 0.15546 0.141572\nATSc4 0.452555 1.233483\nATSc5 0.454323 1.587603\nBCUTc-1l 0.086871 0.020243\nBCUTc-1h 0.197627 0.09002\nBCUTp-1l 0.348526 1.416559\nBCUTp-1h 0.30613 2.687486\nC1SP2 0.842156 16.84312\nC3SP2 0.44475 5.337003\nSCH-7 0.570198 1.226224\nVCH-5 0.136673 0.066583\nVCH-7 0.284164 0.471843\nSC-5 0.90026 2.358201\nVC-4 0.678221 0.33911\nVC-5 0.476908 0.706329\nSPC-4 0.223485 4.435693\nSPC-6 0.734395 25.70635\nVPC-5 0.126582 1.515056\nVPC-6 0.017549 0.319702\nCrippenLogP 0.908239 23.01173\nECCEN 0.868879 13130.5\nndssC 0.095972 2.687217\nSHBd 0.814323 14.78969\nSHBint5 0.536753 51.89493\nSHBint6 0.493409 88.24471\nSHBint10 0.622465 71.61779\nSHsOH 0.680758 1.868451\nSHaaCH 0.943556 9.03814\nSHCsats 0.361675 16.73021\nSHCsatu 0.005772 0.112306\nSaaCH 0.522805 20.98883\nSdssC 0.131028 4.567775\nSaasC 0.472381 10.71859\nSsOH 0.945776 62.06689\nminHBd 0.004693 0.004157\nminHBa 0.381193 6.144505\nminHBint5 0.414706 5.288915\nminHBint6 0.647892 5.650089\nminHBint7 0.123079 1.481101\nminHBint10 0.785248 9.487377\nminHsOH 0.825143 0.730969\nminHCsats 0.59855 0.663469\nminHCsatu 0.105526 0.118007\nTable 4: Continued.\nDescriptor Normalized Real\nminssCH2 0.889895 2.358533\nmindssC 0.268325 1.054303\nminsssN 0.735504 2.011435\nminsOH 0.967622 11.35247\nmindO 0.231127 3.32619\nminssO 0.222965 1.499747\nmaxHBd 0.573001 0.488639\nmaxHBint5 0.502949 5.811736\nmaxHBint7 0.117421 1.2678\nmaxHBint8 0.185541 1.72333\nmaxHsOH 0.609498 0.519763\nmaxHCsats 0.973025 1.252399\nmaxsssCH 0.255134 0.249398\nmaxdssC 0.322333 0.754448\nmaxdsN 0.148611 0.763495\nmaxsOH 0.982069 12.24723\nmaxssO 0.754777 5.077492\nmaxsF 0.375781 5.816332\nhmin 0.202651 0.19802\ngmin 0.196719 1.518661\nLipoaffinityIndex 0.351299 9.693234\nMAXDN 0.916639 5.952869\nMAXDP 0.688238 4.738658\nMAXDP2 0.41876 2.882345\nETA_Epsilon_1 0.744645 0.275913\nETA_dEpsilon_D 0.389612 0.062396\nETA_Shape_Y 0.912192 0.399887\nETA_BetaP_s 0.60827 0.118229\nETA_EtaP_F 0.156509 0.243636\nnHBAcc 0.763162 50.36871\nnAtomLAC 0.886048 15.94887\nMDEC-14 0.861766 4.024826\nMDEC-22 0.385049 13.60019\nMDEC-23 0.253417 13.6896\nMDEC-24 0.187219 2.285725\nMDEC-33 0.722608 35.96141\nMDEO-11 0.339665 1.592459\nMDEO-12 0.690197 2.438236\nMLFER_A 0.884812 7.618233\nMLFER_BH 0.682306 15.75445\nMLFER_S 0.983677 20.57753\nTopoPSA 0.810281 968.5693\nWTPT-3 0.939527 169.2643\nWTPT-4 0.836226 42.47587\nWTPT-5 0.580833 73.03263\nXLogP 0.921274 16.46778\nkappam3 0.591715 38.51945\nphi 0.069879 4.911113\nLDI 0.839175 0.266858\nTable 4: Continued.\nDescriptor Normalized Real\nMnc 0.401081 0.122731\nQNss 0.717554 3.800167\nQCss 0.401335 0.675045\nQHss 0.816212 1.412047\nQmin 0.458487 0.197608\nQOmin 0.902885 0.557983\nQNmin 0.399317 0.186082\nQOmax 0.2189 0.111201\nQNmax 0.733215 0.462658\nQCmax 0.219663 0.114005\nQHmax 0.309301 0.08877\nmChi1 0.70787 0.059461\nknotp 0.463493 3.682452\nChiv3 0.504351 12.68139\ndchi0 0.531787 14.54385\nChiv5ch 0.373625 0.159538\nChiv6ch 0.813352 0.252139\nknotpv 0.332321 1.601785\nnaccr 0.252895 8.092637\nPC6 0.68057 207.574"
        },
        {
            "heading": "S17 0.617016 13.29916",
            "text": ""
        },
        {
            "heading": "S25 0.41233 3.873014",
            "text": ""
        },
        {
            "heading": "S34 0.471534 30.94445",
            "text": "Smax11 0.012002 0.028529\nSmax16 0.270107 0.819234\nSmax24 0.166683 0.618393\nSmax35 0.118755 0.798862\nSmin8 0.95032 2.519298\nSmin12 0.345704 1.386271\nSmin15 0.094406 0.351002\nSmin24 0.795928 2.952893\nSmin33 0.561019 6.58187\nSmin34 0.555043 7.947103\nSmin35 0.727286 4.891723\nScar 0.881448 89.12223\nSmax 0.089706 1.067416\nSmin 0.953752 6.591381\nGATSm1 0.812402 1.001692\nGATSm2 0.634299 0.793508\nGATSm3 0.120694 0.223285\nGATSm4 0.510951 0.973362\nGATSm5 0.049626 0.135925\nGATSm8 0.100571 0.559475\nGATSv1 0.961747 0.951168\nGATSv3 0.282006 0.472642\nGATSe1 0.927808 0.905541\nGATSe5 0.599223 1.181668\nGATSe7 0.23859 1.199867\nGATSe8 0.078374 0.43999\nTable 4: Continued.\nDescriptor Normalized Real\nGATSp3 0.437899 0.708521\nGATSp4 0.924518 1.591095\nGATSp7 0.980757 4.932225\nTPSA1 0.606654 694.4674\nslogPVSA0 0.062831 13.0085\nslogPVSA1 0.216952 76.48269\nslogPVSA2 0.700064 67.12981\nMRVSA5 0.64033 57.65721\nMRVSA6 0.374169 51.50251\nPEOEVSA1 0.302775 42.13574\nPEOEVSA5 0.643223 105.9755\nPEOEVSA6 0.965518 159.7043\nPEOEVSA7 0.010657 0.809047\nPEOEVSA8 0.929568 51.26194\nEstateVSA1 0.420173 90.7544\nEstateVSA4 0.150524 17.979\nEstateVSA7 0.617028 85.38316\nVSAEstate1 0.916056 260.2258\nVSAEstate2 0.469295 61.3763\nVSAEstate4 0.182115 5.816037\nVSAEstate7 0.434015 9.820449\nMATSm1 0.259205 0.199588\nMATSm3 0.55142 0.600496\nMATSm5 0.41914 0.43381\nMATSm6 0.11384 0.224834\nMATSm7 0.309463 0.536608\nMATSm8 0.835615 8.049475\nMATSv1 0.691362 0.486719\nMATSv3 0.421519 0.464936\nMATSv5 0.803173 1.224839\nMATSv8 0.974739 10.77086\nMATSe1 0.044383 0.029914\nMATSe3 0.858027 0.967855\nMATSe5 0.820808 0.897964\nMATSe8 0.84285 8.119175\nMATSp1 0.618676 0.638474\nMATSp3 0.031658 0.035141\nMATSp4 0.995234 1.393328\nMATSp5 0.310054 0.464771\nMATSp6 0.950285 1.76563\nMATSp7 0.401141 0.920218\nATSv5 0.422807 1.369895\nATSe5 0.526873 1.836152\nATSp4.1 0.970895 2.954435\nATSp5.1 0.441556 1.408123"
        },
        {
            "heading": "J 0.517201 2.905116",
            "text": "BertzCT 0.331505 0.429631\nIDE 0.017944 0.054297\nLogP 0.809566 20.63664\nto 500. As for the chromosomes, the number is set to 224, the length of each chromosome is set to 20 bits, the crossover rate is set to 0.6, and the mutation rate is set to 0.1. Record the value of the operand variable that maximizes the objective function, and return it."
        },
        {
            "heading": "4. Experimental Results and Discussions",
            "text": ""
        },
        {
            "heading": "4.1. Analysis of the Biological Activity Prediction Model.",
            "text": "Once the network has been trained, the prediction can be made by simply feeding the network the values of the main variables. The validation set was imported into the model after establishing the quantitative neural network-based prediction model of biological activity. The predicted outcomes were compared with their real labels, which are displayed in Table 2.\nThe change curve of the predicted value and its corresponding actual value are similar in Figure 4, which shows that the model has a decent prediction result and is able to accurately reflect the biological activity in theory. The mean square error of the model is 1.572, which is within the\nacceptable range when choosing MSE to measure the prediction accuracy."
        },
        {
            "heading": "4.2. Analysis of the ADMET Property Prediction Model.",
            "text": "Compare the predicted results with the actual results by importing the validation set into the trained ADMET property prediction model. The following table display the findings (Table 3).\nThe verification results for all five attributes are acceptable as considering the aforementioned tables, while the results for HOB are a little inferior. Nevertheless, the accuracy rate is still quite good. The prediction accuracy of HOB is the lowest result in terms of these five attributes, and this fact might be caused by data imbalance, since the neural network-based models tend to develop a preference on biased data. However, our model\u2019s average prediction accuracy is close to 85%, which is quite a satisfactory performance."
        },
        {
            "heading": "4.3. Analysis of the Clinical Property Optimizing Model. By",
            "text": "resolving the optimization problem, the optimal fitness value of 13 is discovered and the relevant actual values for the molecular descriptors are resolved. Table 4 shows the values of the first 224 molecular descriptors in detail.\nIt can be found that due to the inconsistency of the definitions among the descriptors, the value difference is relatively large but it seems to not affect the results at last. Consider Figure 5, since the dataset that we created has a maximum fitness value of 12.86 while an optimal fitness value of 13 that could be attained by solving the problem; this fact proves that, by applying our method to existing chemical data, it might be possible to find a candidate which has better properties."
        },
        {
            "heading": "5. Conclusion",
            "text": "Breast cancer, as a common and influential disease, requires the development of new drugs to continuously improve the treatment methods. How to efficiently select possible drug\nTable 4: Continued.\nDescriptor Normalized Real\nLogP2 0.935064 170.3864\nHy 0.258499 0.832883\nCIC1 0.531694 2.274054\nCIC3 0.195279 0.597359\nCIC4 0.947302 2.624027\nCIC6 0.315254 0.833533\nSIC1 0.534191 0.238783\nSIC2 0.548336 0.223173\nSIC3 0.93592 0.379048\nIC1 0.62343 1.283018\nIC2 0.961285 2.260943\nIC3 0.605757 1.788194\nbcutm13 0.686797 0.80836\nbcutm12 0.096662 0.106618\nbcutm9 0.662882 0.380495\nbcutm3 0.045307 0.169084\nbcutm2 0.449717 3.285183\nbcutv4 0.772798 0.863988\nbcutv1 0.57612 0.338759\nbcute12 0.330634 0.366674\nbcute10 0.721806 0.510317\nbcute9 0.529904 0.349736\nbcute4 0.370874 0.411299\nbcute2 0.741989 0.470421\nbcute1 0.128208 0.061027\nbcutp12 0.873497 0.828075\nbcutp9 0.541204 0.357195\nbcutp5 0.669777 0.953092\nbcutp1 0.884249 0.579183\ncandidates to reduce the cost of drug development has a certain research value. In our work, we consider the use of machine learning methods to assist in the selection of compounds. We first used the known knowledge and computer compound molecular descriptor calculation software to construct a dataset and then used the random forest algorithm to screen the features and simplify the dataset; then, based on the MobileNetV3 structural deep convolutional network, the biological activity and pharmacokinetics were constructed.\nThe invention of novel medications is necessary for the ongoing development of effective treatments for breast cancer, a common and notable disease. There may be some research value in how to effectively choose potential medication candidates to lower the cost of drug development. In our study, we take into account the application of machine learning techniques to aid in compound selection. First, a dataset was created by combining already known inhibition potency knowledge and the compound molecular descriptors generated by modern calculation software. Next, features were screened out and the dataset was made simpler using the random forest algorithm. Finally, the MobileNetV3 structural deep convolutional network was introduced to construct the biological activity and pharmacokinetics. A genetic algorithm solver is utilized to solve an optimization problem based on the obtained prediction model to predict the best value for the chosen molecular descriptors. The analysis from the perspective of the entire drug design process, rather than constructing or modifying each child model, reflects the proposed model\u2019s innovation and applicability the most. The internal connection and progressive relationship of each model are emphasized in many places throughout this paper. We believe that our four-step method of influencing variable screening, biological activity prediction modeling, pharmacokinetic properties modeling, and clinical property optimization can successfully model and optimize the properties of drugs through various machine learning technologies and serve as a useful guide for drug manufacturers. According to the aforementioned analysis, our method not only offers a significant practical industrial application value but also some academic innovation and research value.\nIn the future, our research direction will mainly focus on giving weight to the properties of ADMET. For example, for the properties of hERG, we do not want the drug to be highly toxic to the human body, so for toxic compounds, we will appropriately reduce its evaluation, that is, the calculated adaptation value. Other properties are the same, and we expect to obtain antibreast cancer drugs with better efficacy and less harm to the human body through this method.\nData Availability\nThe datasets used during the current study are available from the corresponding author upon reasonable request.\nConflicts of Interest\nThe authors declare that they have no conflicts of interest."
        }
    ],
    "title": "Optimization Method of an Antibreast Cancer Drug Candidate Based on Machine Learning",
    "year": 2022
}