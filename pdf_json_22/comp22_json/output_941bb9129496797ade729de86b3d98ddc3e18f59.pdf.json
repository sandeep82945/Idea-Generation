{
    "abstractText": "By combining related objects, unsupervised machine learning techniques aim to reveal the underlying patterns in a data set. Non-negative Matrix Factorization (NMF) is a data mining technique that splits data matrices by imposing restrictions on the elements\u2019 non-negativity into two matrices: one representing the data partitions and the other to represent the cluster prototypes of the data set. This method has attracted a lot of attention and is used in a wide range of applications, including text mining, clustering, language modeling, music transcription, and neuroscience (gene separation). The interpretation of the generated matrices is made simpler by the absence of negative values. In this article, we propose a study on multi-modal clustering algorithms and present a novel method called multi-modal multi-view non-negative matrix factorization, in which we analyze the collaboration of several local NMF models. The experimental results show the value of the proposed approach, which was evaluated using a variety of data sets, and the obtained results are very promising compared to state of art methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "Yasser KHALAFAOUI"
        },
        {
            "affiliations": [],
            "name": "Nistor GROZAVU"
        },
        {
            "affiliations": [],
            "name": "Basarab MATEI"
        }
    ],
    "id": "SP:b874790d8ae3f038ecc8c018f32aa89dc4fe7344",
    "references": [
        {
            "authors": [
                "A. Yan",
                "W. Wang",
                "Y. Ren",
                "H. Geng"
            ],
            "title": "A Clustering Algorithm for Multi-Modal Heterogeneous Big Data With Abnormal Data",
            "venue": "Frontiers in Neurorobotics,",
            "year": 2021
        },
        {
            "authors": [
                "N. Grozavu",
                "B. Matei",
                "Y. Bennani",
                "K. Benlamine"
            ],
            "title": "Multiview Clustering Based on Non-negative Matrix Factorization",
            "year": 2022
        },
        {
            "authors": [
                "A. Cichocki",
                "R. Zdunek",
                "A.H. Phan",
                "S.I. Amari"
            ],
            "title": "Nonnegative matrix and Tensor Factorizations: Applications to Exploratory Multi-way Data Analysis and Blind Source Separation",
            "year": 2009
        },
        {
            "authors": [
                "J. Kim",
                "H. Park"
            ],
            "title": "Sparse Nonnegative Matrix Factorization for Clustering",
            "venue": "Georgia Institute of Technology",
            "year": 2008
        },
        {
            "authors": [
                "P. Paatero",
                "U. Tapper"
            ],
            "title": "Positive Matrix Factorization: A Nonnegative Factor Model with Optimal Utilization of Error Estimates of Data Values. Environmetrics",
            "year": 1994
        },
        {
            "authors": [
                "A. Kaur",
                "S.K. Pal",
                "A.P. Singh"
            ],
            "title": "Hybridization of Chaos and Flower Pollination Algorithm over K-Means for Data Clustering",
            "venue": "Applied Soft Computing,",
            "year": 2020
        },
        {
            "authors": [
                "S. Bickel",
                "T. Scheffer"
            ],
            "title": "November. Multi-view Clustering",
            "venue": "In Proceedings of ICDM (Vol",
            "year": 2004
        },
        {
            "authors": [
                "V.R. De Sa",
                "August"
            ],
            "title": "Spectral Clustering with two Views. In ICML workshop on learning with multiple views",
            "year": 2005
        },
        {
            "authors": [
                "Y. Yang",
                "H. Wang"
            ],
            "title": "Multi-view Clustering: A survey",
            "venue": "Big Data Mining and Analytics,",
            "year": 2018
        },
        {
            "authors": [
                "B. Zhao",
                "J.T. Kwok",
                "C. Zhang",
                "April"
            ],
            "title": "Multiple Kernel Clustering",
            "venue": "In Proceedings of the 2009 SIAM Intern. Conf. on Data Mining (pp. 638-649)",
            "year": 2009
        },
        {
            "authors": [
                "L. Du",
                "P. Zhou",
                "L. Shi",
                "H. Wang",
                "M. Fan",
                "W. Wang",
                "Y.D. Shen",
                "June"
            ],
            "title": "Robust Multiple Kernel K-means using L21-norm",
            "venue": "In Proc. of the 24th international joint conference on artificial intelligence",
            "year": 2015
        },
        {
            "authors": [
                "S. Wang",
                "Y. Ye",
                "R.Y. Lau",
                "August"
            ],
            "title": "A Generative Model with Ensemble Manifold Regularization for Multi-view Clustering",
            "venue": "In International Conf. on Intelligent Computing (pp",
            "year": 2015
        },
        {
            "authors": [
                "Z. Zhang",
                "J. Mao"
            ],
            "title": "Jointly Sparse Neighborhood Graph for Multi-view Manifold Clustering",
            "venue": "Neurocomputing, 216,",
            "year": 2016
        },
        {
            "authors": [
                "S. Xie",
                "H. Lu",
                "Y. He"
            ],
            "title": "November. Multi-task Co-clustering via Nonnegative Matrix Factorization",
            "venue": "In Proceedings of the 21st International Conf. on Pattern Recognition",
            "year": 2012
        },
        {
            "authors": [
                "Q. Gu",
                "J. Zhou"
            ],
            "title": "December. Learning the Shared Subspace for Multi-task Clustering and Transductive Transfer Classification",
            "venue": "In Proc. of 2009 9th IEEE International Conf. on Data Mining (pp. 159-168)",
            "year": 2009
        },
        {
            "authors": [
                "J. Ma",
                "Y. Zhang",
                "L. Zhang"
            ],
            "title": "Discriminative Subspace Matrix Factorization for Multiview Data Clustering",
            "venue": "Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "C. Ding",
                "X. He",
                "H.D. Simon",
                "April"
            ],
            "title": "On the Equivalence of Nonnegative Matrix Factorization and Spectral Clustering",
            "venue": "In Proc. of the 2005 SIAM international conference on data mining (pp. 606-610)",
            "year": 2005
        },
        {
            "authors": [
                "W. Pedrycz"
            ],
            "title": "Collaborative Fuzzy Clustering",
            "venue": "Pattern Recognition Letters,",
            "year": 2002
        },
        {
            "authors": [
                "W. Pedrycz",
                "K. Hirota"
            ],
            "title": "A Consensus-driven Fuzzy Clustering",
            "venue": "Pattern Recognition Letters,",
            "year": 2008
        },
        {
            "authors": [
                "L. Wang",
                "Y. Zhang",
                "J. Feng"
            ],
            "title": "On the Euclidean Distance of Images",
            "venue": "IEEE transactions on pattern analysis and machine intelligence,",
            "year": 2005
        },
        {
            "authors": [
                "D. Hu",
                "F. Nie",
                "X. Li"
            ],
            "title": "Deep Multimodal Clustering for Unsupervised Audiovisual Learning",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "year": 2019
        },
        {
            "authors": [
                "D. Seung",
                "L. Lee"
            ],
            "title": "Algorithms for Non-negative Matrix Factorization",
            "venue": "Advances in neural information processing systems,",
            "year": 2001
        },
        {
            "authors": [
                "H.W. Kuhn",
                "A.W. Tucker"
            ],
            "title": "Nonlinear Programming. In Berkeley University of California Press, editor,Proceedings of 2nd Berkeley Symposium, pages 481\u2013492,1951",
            "year": 1951
        },
        {
            "authors": [
                "A. Zadeh",
                "R. Zellers",
                "E. Pincus",
                "L.P. Morency"
            ],
            "title": "Multimodal Sentiment Intensity Analysis in Videos: Facial Gestures and Verbal Messages",
            "venue": "IEEE Intelligent Systems,",
            "year": 2016
        },
        {
            "authors": [
                "Tat-Seng Chua",
                "Jinhui Tang",
                "Richang Hong",
                "Haojie Li",
                "Zhiping Luo",
                "Yan-Tao Zheng"
            ],
            "title": "NUS-WIDE: A Real-World Web Image Database from National University of Singapore",
            "venue": "In Proceedings of ACM International Conference on Image and Video Retrieval. Greece. Jul. 8-10,",
            "year": 2009
        },
        {
            "authors": [
                "H. Phan",
                "H. Le Nguyen",
                "O.Y. Ch\u00e9n",
                "L. Pham",
                "P. Koch",
                "I. McLoughlin",
                "A. Mertins",
                "June"
            ],
            "title": "Multi-view Audio and Music Classification",
            "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 611-615)",
            "year": 2021
        },
        {
            "authors": [
                "J. Devlin",
                "M.W. Chang",
                "K. Lee",
                "K. Toutanova"
            ],
            "title": "Bert: Pretraining of Deep Bidirectional Transformers for Language Understanding",
            "venue": "arXiv preprint arXiv:1810.04805",
            "year": 2018
        },
        {
            "authors": [
                "T. Mikolov",
                "I. Sutskever",
                "K. Chen",
                "G.S. Corrado",
                "J. Dean"
            ],
            "title": "Distributed Representations of Words and Phrases and their Compositionality",
            "venue": "Adv. in neural information processing systems,",
            "year": 2013
        }
    ],
    "sections": [
        {
            "text": "Non-negative Matrix Factorization (NMF) is a data mining technique that splits data matrices by imposing restrictions on the elements\u2019 non-negativity into two matrices: one representing the data partitions and the other to represent the cluster prototypes of the data set. This method has attracted a lot of attention and is used in a wide range of applications, including text mining, clustering, language modeling, music transcription, and neuroscience (gene separation). The interpretation of the generated matrices is made simpler by the absence of negative values. In this article, we propose a study on multi-modal clustering algorithms and present a novel method called multi-modal multi-view non-negative matrix factorization, in which we analyze the collaboration of several local NMF models. The experimental results show the value of the proposed approach, which was evaluated using a variety of data sets, and the obtained results are very promising compared to state of art methods.\nIndex Terms\u2014multi-modal multi-view clustering, collaborative clustering, non-negative matrix factorization\nI. INTRODUCTION\nThe development and everyday use of social media has led people to share their lives and express their opinions online. As a result, data (text, images, audio/speech, video, etc.) generated by social networks users is changing rapidly. As data collections become highly diversified [1] due to the emergence of multi-modal data sets, multi-view data sets (i.e. the same data sample described in various ways) and dispersed data, it is now critical to effectively extract inherent information from these multi-source data sets. Data Clustering is an approach to discover the intrinsic structures of a collection of items by grouping objects with similar features [2].\nDue to the increasing variety and volume of data sets, clustering algorithms struggle to achieve competitive results with high certainty. However, similar issues can be addressed more easily by combining several approaches to improve both the quality and reliability of the outputs.\nNMF has received a lot of attention in recent years [3] [4] and has been used in a variety of domains including feature selection, dimensionality reduction, text mining and clustering\n* Corresponding author\n[2]. Paatero (1994) [5] established the NMF method, an unsupervised clustering methodology in which a data matrix is factored into (usually) two matrices: a matrix of cluster prototypes and a matrix of data partitions, such that none of the matrices has any negative component. The exclusion of negative values makes it easier to interpret the constructed matrices. Self-Organizing Map (SOM) is another clustering algorithm that involves artificial neural networks [16]. To achieve clustering, this method processes all of the data samples one at a time and maps the cluster centers to a twodimensional space. De Sa (2005) [8] presented a simple and effective spectral clustering approach and used it to analyse web page data with two views. The similarity matrix is used first to combine the features extracted of both views, and then the standard spectral clustering technique is used to perform clustering and produce the final clustering result.\nIn a multi-view setting, a data sample can describe the same item from different angles and in different ways [6]. Having different views complementing each other, multiview clustering algorithms become important for information extraction. In the literature, we distinguish four categories:\n\u2022 Multi-view graph clustering. These methods find a fusion graph (or network) across all views and then applies semiautomatic segmentation algorithms or other techniques (e.g., spectral clustering) to the fusion graph to produce the clustering result. Wang et al. (2017) [12] introduced a generative model that uses ensemble manifold regularization. In particular, they built a nearest neighbor graph for each view to encode the corresponding manifold information, and a multiple graph ensemble regularization framework was designed to learn the optimal intrinsic manifold. The PLSA-based multi-view topic model was then modified to include the manifold regularization term, producing a unified objective function. Zhang and Mao (2016) [13] used sparse weights for similarity graph generation with unreliable neighbors filter in order to identify accurate neighbors for multi-view clustering efficiently, by presenting every object as a weighted sum of its neighbors for each view. \u2022 Multi-kernel learning. This class of methods employs predefined kernels associated to different views, which ar X iv :2\n30 8.\n04 77\n8v 1\n[ cs\n.A I]\n9 A\nug 2\n02 3\nare then combined either linearly or non-linearly to improve clustering performance [9]. Zhao et al. (2009) [10] introduced a multi-kernel clustering algorithm based on maximum margin clustering, which finds the best clusterings, the optimal kernels as well as the maximum margin hyperplane together at the same time. Du et al. (2015) [11] proposed a robust K-means (with l2,1norm) on kernel space and applied a multiple kernel Kmeans algorithm that can find simultaneously the optimal combination of multiple kernels, the best clustering labels and cluster membership. \u2022 Multi-task multi-view clustering. These methods assign one or more tasks to each view, transfer inter-task knowledge to one another, and exploit multi-task and multiview relationships to improve clustering performance.Gu and Zhou (2009) [15] presented a cross-domain based multi-task clustering solution in which each view is assigned a task. This method aims to learn a subspace that allows knowledge transfer from one task to another. Xie et al. (2012) [14] presented a 3-factor NMF-based multitask collaborative clustering method. The cost function was made of two parts: task-specific co-clustering and cross-task feature space regularization. \u2022 Collaborative clustering algorithms. This approach deals with multi-view data by adopting a co-training strategy. It bootstraps the clustering of different views by using the information extracted from one another. By applying this method iteratively, the clustering results of all views tend to converge, leading to the broadest consensus across all views. Bickel and Scheffer (2004) [7] introduced a k-means-based multi-view clustering algorithm and applied it to text clustering data with two conditionally independent views. Furthermore, Grozavu et al. (2022) [2] proposed a NMF based multi-view clustering. First, NMF is applied to each view independently, then a collaboration phase is added in order to find hidden structures and patterns, and allow the interaction between these different views.\nHowever, these approaches are not adapted for the multi-view multi-modal aspect of the data sets (i.e. multi-source data sets where each source can have multiple views or representations). Taking into account the augmenting complexity and volume of data sets nowadays and the need for efficient information extraction algorithms, it is important to develop a solution that tackles this subject.\nOur research sets out to propose a new method for multimodal multi-view clustering by extending some multi-view solutions proposed in the literature. The algorithm first applies a NMF on each view locally; then a collaboration phase between different views within the same modality allows for the exchange of information and finally a second collaboration phase is introduced, where each of the other modalities contributes to the co-clustering.\nThe remainder of the paper is organized as follows: Section II discusses the preliminary setting of the proposed approach and the formal definition of our solution. Section III proposes\noptimizations of the solution under different conditions. Finally, we assess the performances of the proposed algorithm through experimental results in Section Experiment. The paper ends with a conclusion and several future works."
        },
        {
            "heading": "II. PROBLEM FORMALIZATION",
            "text": ""
        },
        {
            "heading": "A. NMF Algorithm",
            "text": "The traditional Nonnegative Matrix Factorization algorithm is proven to be equivalent to relaxed K-means clustering method [17]. Given a non-negative data matrix of M features and N objects, denoted as X = (x1, x2, \u00b7 \u00b7 \u00b7 , xN ) \u2208 RM\u00d7N+ , such that xn \u2208 RM\u00d71+ represents the nth object of X , the NMF algorithm gives a low rank approximation of X using two non-negative matrices product FG, such that F is the matrix of cluster prototypes and G is the matrix of data partitions defined respectively as F = (f1, f2, \u00b7 \u00b7 \u00b7 , fk) \u2208 RM\u00d7K+ , and G = (g1, g2, \u00b7 \u00b7 \u00b7 , gN ) \u2208 RK\u00d7N+ , with K a parameter representing the number of components. Under a constrained optimization, the NMF cost function to minimize can be written as:\nL(X,F,G) = \u2225X \u2212 FG\u22252 (1)\nwith L representing the Frobenius norm of the matrix X\u2212FG."
        },
        {
            "heading": "B. Multi-modal Multi-view Setting",
            "text": "In this section, we investigate the exchange of information between finite clustering results obtained using an NMF model and those obtained in a multi-modal multi-view context. NMF clustering algorithm is applied on each data set. We are interested in the multi-view clustering technique introduced by Grozavu et al. (2022) [2] because it allows for the comparison of data that are equivalent but defined by distinct factors, and we have revised it in order to apply it to the multimodal context. All of the distributed views in this case share the same units but are described differently. Here, all NMF factorizations will share the same number of centroid vectors.\nAs stated earlier, let X = (x1, x2, \u00b7 \u00b7 \u00b7 , xN ) \u2208 RM\u00d7N+ be a data set of M features and N objects containing non-negative values. In the case of multi-modal multi-view framework, we assume that we have a finite number of modalities p \u2208 N, and each modality has a finite number of views v \u2208 N. Locally, we apply a traditional NMF to each modality views. The local NMF expression can be rewritten as follows:\nL(vp)(X (vp), F (vp), G(vp)) = \u2225X(vp) \u2212 F (vp)G(vp)\u22252 (2)\nwhere, the subscript vp denotes both the modality and view dependency. F (vp) = (f (vp)1 , f (vp) 2 , \u00b7 \u00b7 \u00b7 , f (vp) k ) \u2208 RM\u00d7K+ is the cluster centroids matrix and G(vp) = (g\n(vp) 1 , g (vp) 2 , \u00b7 \u00b7 \u00b7 , g (vp) N ) \u2208 R K\u00d7N(vp) + indicates the data par-\ntition matrix."
        },
        {
            "heading": "C. Multi-view collaboration term",
            "text": "Adding extracted information from different views v\u2032 \u0338= v to a view v is a popular collaborative approach [18] [19]. In their work [2], Grozavu et al. presented a multi-view collaboration technique that minimizes the distance between a data point\nand its corresponding prototypes of local NMF views v\u2032 \u0338= v to incorporate the information from view v\u2032. In order to achieve this information transfer, they introduced the euclidean distances matrix D(v) of each data point of X(v) and the set of centroids F (v), such that D(v)kn = \u2225x (v) n \u2212 k(v)\u2225.\nHowever, this setting can\u2019t be applied in our multi-modal context, since the euclidean distance is not suited for image similarities. As described in [20], the euclidean distance is highly sensitive to even small image deformations. Since the traditional euclidean distance is a summation of the pixel-wise intensity differences, even minor deformations may produce large euclidean distances. Instead, when dealing with multimodalities Hu et al. (2019) [21] suggest to use the inner product between each data point and the set of centroids. Taking this into account, we modify the distance matrix D(v) presented earlier by using the inner product instead of the euclidean distance, such that dvpkn = \u27e8x (vp) n , k(vp)\u27e9.\nAs a result, the pairwise collaborative term C(vp, v\u2032p) between the vth and v\u2032th NMFs is defined as follows:\nCvp,v\u2032p(F (vp), G(vp)) = \u2225(G(vp) \u2212G(v \u2032 p)) \u25e6D(vp)\u22252F (3)\nNotice that v\u2032p denotes another view of the same modality. The collaborative term C(vp, v\u2032p) is equivalent to the weighted sum of the inner product between the data point x(vp)n and all the centroids in F (vp), with G(vp)\u2212G(v \u2032 p) representing the weight.\nIn (3), when G(vp) and G(v \u2032 p) agree, the collaborative term\nequals zero and we consider only the vth local NMF"
        },
        {
            "heading": "D. Multi-modal collaboration term",
            "text": "In our multi-modal multi-view context, we also want to include the information extracted from the views of the other modalities p\u2032 \u0338= p. With this additional knowledge transfer, the NMF algorithm not only include the information from local views v\u2032p \u0338= vp but also the information from distant views vp\u2032 (i.e. views of other modalities).\nWe define the multi-modal collaborative term as follows:\nOvp,vp\u2032 (F (vp), G(vp)) = \u2225F (vp)(G(vp) \u2212G(vp\u2032 ))\u22252F (4)\nHaving two data partition matrices of different modalities G(vp) and G(vp\u2032 ), our objective is to minimize the multi-modal collaborative term. Notice that O(vp, vp\u2032) is equal to zero if G(vp)=G(vp\u2032 ).\nHence, the set of matrix partitions G(vp) and the set of centroids F (vp) are estimated iteratively and alternatively by minimizing the following objective function: J (F,G) = \u2211P\np=1 (\u2211V vp=1 (Lv(F (vp), G(vp)) + G(vp, v\u2032p) ) +H(vp, vp\u2032)\n(5) where G(vp, v\u2032p) = \u2211\nv\u2032p \u0338=vp\n\u03b2vp,v\u2032p \u00b7 C(vp, v \u2032 p) (6)\nand H(vp, vp\u2032) = \u2211 vp \u0338=vp\u2032 \u03b3vp,vp\u2032O(vp, vp\u2032) (7)\nHere, Lv is the vth local NMF expression introduced in (2). \u03b2vp,v\u2032p and \u03b3vp,vp\u2032 are the degrees of the multi-view and multi-modal collaborations respectively, with respect to the constraints \u2211 v\u2032p \u0338=vp \u03b2vp,v\u2032p = 1 and \u2211 vp\u2032 \u0338=vp \u03b3vp,vp\u2032 = 1"
        },
        {
            "heading": "III. OPTIMIZATION",
            "text": ""
        },
        {
            "heading": "A. Algorithm Derivation",
            "text": "Recall that the described cost function in (5) is differentiable and its derivative exists at each point in its domain. As a result, there is always a minimum, which can be found using nonlinear programming.\nTo minimize the aforementioned cost function (5), we use the gradient descent technique. For \u0398 \u2208 {F (vp), G(vp)} st. \u0398 \u2265 0, the update formula of the cost function (5) is:\n\u0398 = \u0398\u2212 \u03b7\u0398 \u25e6 \u2207\u0398(J (F,G)) (8)\nDue to the presence of the subtraction operator in (8), the non-negativity condition is violated. To adress this issue, we consider Lee and Seung\u2019s strategy (2001) [22] by using an adaptive learning rate for the cost function J and the parameter \u0398 \u2208 {F (vp), G(vp)}:\n\u03b7\u0398 = \u0398\n[\u2207\u0398J ]+ (9)\nThe update rule of the partition matrix and centroid matrix is written as follows:\n\u0398 = \u0398 \u25e6 [\u2207\u0398J ]\u2212 [\u2207\u0398J ]+\n(10)\nSuch that \u25e6 and the fraction line represent the element-wise multiplication and division respectively. Notice that in (10), the negative terms of the gradient are in the numerator, while the denominator contains the positive terms."
        },
        {
            "heading": "B. Optimized Weights for the Collaborative terms",
            "text": "Here, we examine how optimizing the degrees of collaboration \u03b2vp,v\u2032p and \u03b3vp,vp\u2032 , introduced in (6) and (7), can produce the optimal solution for the cost function and reduce the risk of negative collaboration.\nSince \u03b2vp,v\u2032p \u2265 0, we consider the collaboration weight \u03b2vp,v\u2032p = \u03c4 2 vp,v\u2032p\n. Our objective is to find the positive weights \u03c42vp,v\u2032p that will determine the collaborative term\u2019s strength.\nUsing the condition \u2200vp, \u2211V\nv\u2032p \u0338=vp \u03c42vp,v\u2032p = 1 along with the\nKarush-Kuhn-Tucker (KKT) conditions [23], the results of the optimization are presented in (11):\n\u03b2vp,v\u2032p = |Cvp,v\u2032p | 2(\u2211 v\u2032p \u0338=vp |Cvp,v\u2032p |2 ) (11)\nSimilarly, the optimized multi-modal collaborative term is written as:\n\u03b3vp,vp\u2032 = |Ovp,vp\u2032 | 2(\u2211 vp\u2032 \u0338=vp |Ovp,vp\u2032 |2 ) (12)\nWe propose an interpretation to these results: in the context of multi-modal multi-view collaboration, overall results should\nimprove if individual algorithms give more weight to algorithms with the same results as local solutions(higher weight \u03c4 value for a specific NMF model).\nAlgorithm 1 Multi-modal Multi-view NMF Convex-initialization: Randomly set the cluster prototypes, v number of views and p number of modalities. For all realizations Local phase: forall views v of a modality p do\nOptimize the NMF cost function (2). end Multi-modal Multi-view Collaboration phase: Compute the optimized \u03b2vp,v\u2032p with (11) Compute the optimized \u03b3vp,vp\u2032 with (12) forall views v of all modalities p do\nEstimate the partitions matrix of all views (10). Estimate the centroids matrix of all views (10).\nend"
        },
        {
            "heading": "IV. EXPERIMENTS",
            "text": "In this section, we assess the performances of our proposed collaborative strategy on two multi-modal data sets: Multimodal Corpus of Sentiment Intensity (MOSI) [24] and NUSWIDE [25]. Further details on the data sets are given in order to illustrate the premise of the presented approach. Since we have access to these data set labels, the performance of the multi-modal multi-view NMF clustering is evaluated using two standard metrics: the silhouette index and purity."
        },
        {
            "heading": "A. Purity Evaluation Procedure",
            "text": "Purity is a metric that measures the extent to which clusters contain a single class. Let L = {l1, l2, \u00b7 \u00b7 \u00b7 ln}, n \u2208 N and K = {k1, k2, \u00b7 \u00b7 \u00b7 km},m \u2208 N be the known data labels and centroids respectively. The purity score of a clustering is defined as:\npurity = |K|\u2211 m=1 max |L| i=1 |kim| |km|\n(13)\nwhere |km| denotes the total number of observations associated with the cluster km, and |kim| denotes the amount of data of class li related to the cluster km.\nThe purity of the clustering result is equal to the expected purity of all clusters. A High purity score indicates a good clustering process."
        },
        {
            "heading": "B. Silhouette Evaluation Procedure",
            "text": "The silhouette index is the average silhouette coefficient over each data sample. It is computed using the following formula:\nsilhouette = (b\u2212 a)\nmax(a, b) (14)\nwhere a is the mean distance between instances of the same cluster (i.e. the mean intra-cluster distance), and b is the mean\ndistance to the instances of the successive closest cluster (i.e. mean nearest-cluster distance).\nThe silhouette coefficient is defined in the interval [\u22121, 1]; a value close to 1 indicates that the instance is inside its own cluster and distant from other clusters, a value close to 0 indicates that it is near a cluster boundary, and a value close to \u22121 indicates that the instance may have been mistakenly assigned to a different cluster."
        },
        {
            "heading": "C. Data Set Descriptions",
            "text": "\u2022 NUS-WIDE - contains 269,648 images and their associated 5,018 unique tags from Flickr. A ground truth of 81 classes is provided, consisting of events, programs, animals, objects, people. A semi-automatic process is used to create the ground truth and human labelers assess the relevance of the image classes. Six low-level image features are given: color histogram, color correlogram, edge direction histogram, wavelet texture, block-wise color moments and a bag of visual words on SIFT descriptions. We extracted two subsets (NUS-2B, NUS-CDF) that we used for our experimentation (see Tab. I). Experiments are performed using both modalities (i.e. image and text). For the image modality, we used the edge direction histogram and the wavelet texture. \u2022 MOSI - contains 2199 opinion video clips. Each clip has a sentiment annotation in the interval [\u22123, 3].For each opinion video clip, the audio file and transcriptions are provided. The data set is meticulously annotated with labels for sentiment intensity and subjectivity. In our experimentation, we only used the text and audio modalities. We extracted two views (low-level features) from the audio modality: the raw audio signal (Raw) and the Mel-scale spectrogram (MEL), as suggested in [26]. As for the text modality, we used the BERT [27] and Word2Vec (W2V) [28] views. To illustrate the process of multi-modal multi-view collaboration, we introduce a Gaussian noise with a mean of zero and a standard deviation of one to the Word2Vec view. Finally, in order to compute the purity score, we transformed the data set into binary classification by assigning the label \u201dpositive\u201d to the sentiments in the interval (0, 3] and the label \u201dnegative\u201d to the sentiments in the interval [\u22123, 0]\nD. Illustration of the proposed solution on the NUS-2B subset\nAs stated previously, we will use the case of a collaboration between two views of the same modality (image) and a view of the other modality (text) to simplify the interpretation of the collaboration principle.\nTo allow collaboration between different views and modalities, the structures of all local clustering results must be similar (i.e. same dimensions). To ensure this condition, we applied PCA (Principal Component Analysis) on all modalities views.\nFig. 1 represents a projection of the wavelet texture view in a two-dimensional space using T-SNE (T-Distributed Stochastic Neighbor Embedding), using the ground truth provided. The associated cluster for each set of data is displayed with a specific color.\nUsing NMF prior to the multi-modal multi-view collaboration, the purity scores achieved on the image views (wavelet texture and edge direction histogram) and the text view are 52.7%, 71.6% and 85.6% respectively.\nWe then applied the second phase of the proposed method (the multi-modal multi-view collaboration) to share the clustering information throughout all NMF clustering results.\nFollowing the collaboration of the edge direction histogram and text views with the wavelet texture view, the purity score of the latter rose to 66.4%. Fig. 2 shows the result of the muti-modal multi-view collaboration on the wavelet texture image view. Furthermore, we computed the Silhouette index to evaluate the resulting clustering structure after the collaboration. The Silhouette index increased from 0.32 to 0.38. Tab. II summarizes these experiments.\nIn another experiment, we analyzed the impact of the horizontal collaboration of views with lower purity score on a view with a higher score. To do so, we introduced a Gaussian noise to the text view to reduce its clustering quality, which became 61.85%. Next, by collaborating the noisy text and the wavelet texture views with the edge histogram texture view, the purity score of the latter decreased from 71.6% to 63.08%.\nWe notice that the collaboration between a view with a low purity score and views and modalities with higher purity\nscores enhances the quality of the initial view. Whereas, a collaboration between a view with a higher purity score and views and modalities with lower purity score diminishes the quality of the initial view.\nThese findings indicate that while the multi-modal multiview collaboration increases or decreases the purity score based on the clustering quality of distant collaborators, it has a little impact on the Silhouette index, as the collaboration only takes in consideration the distant partitions without altering the local structure of the view."
        },
        {
            "heading": "E. Comparison with other technique",
            "text": "To illustrate the usefulness of the multi-modal multi-view collaboration approach presented, we compare it with the multi-view clustering technique proposed in [2]. The comparison is conducted on the NUS-CDF subset.\nTab. III gives the purity score and Silhouette index of each local NMF clustering and horizontal collaboration algorithm. Regarding the Multi-view NMF clustering technique, the clustering quality of the edge direction histogram view decreased from 39.3% to 38.32%, after the collaboration, due to the local knowledge transfer of the wavelet texture view (lower purity of 37.98%). Whereas, using our method, the edge direction histogram view\u2019s clustering quality increased, after the collaboration, from 39.3% to 57.04% as a result of the local knowledge transfer of both the text modality and the intra-modality view (wavelet texture).\nThis comparison shows the importance of including the information from other modalities during the collaboration.\nF. Validation using additional data sets\nIn this part, we applied our solution to the MOSI data set and computed the clustering purity score before and after the collaboration.\nIn Tab. IV, notice that the purity score increases when the majority of distant collaborators have a strong segmentation. Similarly, we can see that the collaboration has little impact on the Silhouette index since the data set structure remains unchanged."
        },
        {
            "heading": "V. CONCLUSION",
            "text": "In this study, we presented a novel method for multi-modal multi-view horizontal collaboration by transferring knowledge between various local Non-negative Matrix Factorizations. Through this collaboration, various NMFs can interact and reveal the inherent patterns and structures in data sets.\nWe presented our proposed technique, which is well-suited for collaboration between views of various modalities that represent the same objects but with different attributes.\nThe experimental findings show that the proposed method, which has been validated against a variety of data sets, produces better results than the multi-view NMF clustering.\nAs part of our future work, we plan to implement an ensemble technique to find a single consensus partition among all the local NMFs after the collaboration. We also plan to analyze the impact of different modalities on the results of the collaboration by introducing a weight factor for each modality."
        }
    ],
    "title": "Multi-modal Multi-view Clustering based on Non-negative Matrix Factorization",
    "year": 2023
}