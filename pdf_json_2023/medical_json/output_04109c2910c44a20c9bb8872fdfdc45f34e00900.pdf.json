{
    "abstractText": "Diabetic retinopathy (DR) and diabetic macular edema (DME) are forms of eye illness caused by diabetes that affects the blood vessels in the eyes, with the ground occupied by lesions of varied extent determining the disease burden. This is among the most common cause of visual impairment in the working population. Various factors have been discovered to play an important role in a person\u2019s growth of this condition. Among the essential elements at the top of the list are anxiety and long-term diabetes. If not detected early, this illness might result in permanent eyesight loss. The damage can be reduced or avoided if it is recognized ahead of time. Unfortunately, due to the time and arduous nature of the diagnosing process, it is harder to identify the prevalence of this condition. Skilled doctors manually review digital color images to look for damage produced by vascular anomalies, the most common complication of diabetic retinopathy. Even though this procedure is reasonably accurate, it is quite pricey. The delays highlight the necessity for diagnosis to be automated, which will have a considerable positive significant impact on the health sector. The use of AI in diagnosing the disease has yielded promising and dependable findings in recent years, which is the impetus for this publication. This article used ensemble convolutional neural network (ECNN) to diagnose DR and DME automatically, with accurate results of 99 percent. This result was achieved using preprocessing, blood vessel segmentation, feature extraction, and classification. For contrast enhancement, the Harris hawks optimization (HHO) technique is presented. Finally, the experiments were conducted for two kinds of datasets: IDRiR and Messidor for accuracy, precision, recall, F-score, computational time, and error rate.",
    "authors": [
        {
            "affiliations": [],
            "name": "Swaminathan Sundaram"
        },
        {
            "affiliations": [],
            "name": "Meganathan Selvamani"
        },
        {
            "affiliations": [],
            "name": "Sekar Kidambi Raju"
        },
        {
            "affiliations": [],
            "name": "Seethalakshmi Ramaswamy"
        },
        {
            "affiliations": [],
            "name": "Saiful Islam"
        },
        {
            "affiliations": [],
            "name": "Jae-Hyuk Cha"
        },
        {
            "affiliations": [],
            "name": "Nouf Abdullah Almujally"
        },
        {
            "affiliations": [],
            "name": "Ahmed Elaraby"
        }
    ],
    "id": "SP:2f85d0c6544f20b224c00d32dcfc421c54a90f0e",
    "references": [
        {
            "authors": [
                "A.S. Thiagarajan",
                "J. Adikesavan",
                "S. Balachandran",
                "B.G. Ramamoorthy"
            ],
            "title": "Diabetic Retinopathy Detection using Deep Learning Techniques",
            "venue": "J. Comput. Sci",
            "year": 2020
        },
        {
            "authors": [
                "S.M. Skariah",
                "K.S. Arun"
            ],
            "title": "A Deep Learning Based Approach for Automated Diabetic Retinopathy Detection and Grading",
            "venue": "In Proceedings of the 2021 4th Biennial International Conference on Nascent Technologies in Engineering (ICNTE), Navi Mumbai, India,",
            "year": 2021
        },
        {
            "authors": [
                "P. Chowdhury",
                "M.R. Islam",
                "M.A. Based"
            ],
            "title": "Transfer Learning Approach for Diabetic Retinopathy Detection using Efficient Network with 2 Phase Training",
            "venue": "In Proceedings of the 2021 6th International Conference for Convergence in Technology (I2CT),",
            "year": 2021
        },
        {
            "authors": [
                "L. Feng",
                "Y. Wang",
                "T. Xu",
                "L. Dong",
                "L. Yan",
                "M. Jiang",
                "X. Zhang",
                "H. Jiang",
                "Z. Wu",
                "H. Zou"
            ],
            "title": "Deep learning-based automated detection for diabetic retinopathy and diabetic macular oedema in retinal fundus photographs",
            "venue": "Eye 2022,",
            "year": 2022
        },
        {
            "authors": [
                "C. Bhardwaj",
                "S. Jain",
                "M. Sood"
            ],
            "title": "Deep Learning\u2013Based Diabetic Retinopathy Severity Grading System",
            "venue": "Employing Quadrant Ensemble Model. J. Digit. Imaging",
            "year": 2021
        },
        {
            "authors": [
                "K. Snehil"
            ],
            "title": "Diabetic Retinopathy Diagnosis with Ensemble Deep-Learning",
            "venue": "In Proceedings of the 3rd International Conference on Vision, Image and Signal Processing, Vancouver, BC, Canada,",
            "year": 2019
        },
        {
            "authors": [
                "J.I. Orlando",
                "E. Prokofyeva",
                "M.D. Fresno",
                "M.B. Blaschko"
            ],
            "title": "Learning to Detect Red Lesions in Fundus Photographs: An Ensemble Approach based on",
            "venue": "Deep Learning",
            "year": 2017
        },
        {
            "authors": [
                "Y. Yan",
                "J. Gong",
                "Y. Liu"
            ],
            "title": "A Novel Deep Learning Method for Red Lesions Detection Using Hybrid Feature",
            "venue": "In Proceedings of the 2019 Chinese Control And Decision Conference (CCDC), Nanchang, China,",
            "year": 2019
        },
        {
            "authors": [
                "M. Safwan",
                "S.S. Chennamsetty",
                "A. Kori",
                "V. Alex",
                "G. Krishnamurthi"
            ],
            "title": "Classification of Breast Cancer and Grading of Diabetic Retinopathy & Macular Edema using Ensemble of Pre-Trained Convolutional Neural Networks",
            "year": 2018
        },
        {
            "authors": [
                "B. Harangi",
                "J. T\u00f3th",
                "A. Hajdu"
            ],
            "title": "Fusion of Deep Convolutional Neural Networks for Microaneurysm Detection in Color Fundus Images",
            "venue": "In Proceedings of the 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),",
            "year": 2018
        },
        {
            "authors": [
                "S. Ramchandre",
                "B. Patil",
                "S. Pharande",
                "K. Javali",
                "H. Pande"
            ],
            "title": "A Deep Learning Approach for Diabetic Retinopathy detection using Transfer Learning",
            "venue": "In Proceedings of the 2020 IEEE International Conference for Innovation in Technology (INOCON),",
            "year": 2020
        },
        {
            "authors": [
                "M. Shorfuzzaman",
                "M.S. Hossain",
                "A. El Saddik"
            ],
            "title": "An Explainable Deep Learning Ensemble Model for Robust Diagnosis of Diabetic Retinopathy Grading",
            "venue": "ACM Trans. Multimed. Comput. Commun. Appl",
            "year": 2021
        },
        {
            "authors": [
                "R.S. Rajkumar",
                "T. Jagathishkumar",
                "D. Ragul",
                "A.G. Selvarani"
            ],
            "title": "Transfer Learning Approach for Diabetic Retinopathy Detection using Residual Network",
            "venue": "In Proceedings of the 2021 6th International Conference on Inventive Computation Technologies (ICICT), Coimbatore, India,",
            "year": 2021
        },
        {
            "authors": [
                "M. Al-Smadi",
                "M.M. Hammad",
                "Q.B. Baker",
                "S.A. Al-Zboon"
            ],
            "title": "A transfer learning with deep neural network approach for diabetic retinopathy classification",
            "venue": "Int. J. Electr. Comput. Eng",
            "year": 2021
        },
        {
            "authors": [
                "M. Dela Pava",
                "H. R\u2019ios",
                "F.J. Rodr\u2019iguez",
                "O.J. Perdomo",
                "F.A. Gonz\u2019alez"
            ],
            "title": "A deep learning model for classification of diabetic Retinopathy in eye fundus images based on retinal lesion detection",
            "venue": "In Proceedings of the Symposium on Medical Information Processing and Analysis, Mexico City, Mexico,",
            "year": 2021
        },
        {
            "authors": [
                "M. Chetoui",
                "M.A. Akhloufi"
            ],
            "title": "Explainable end-to-end deep Learning for diabetic retinopathy detection across multiple datasets",
            "venue": "J. Med. Imaging 2020,",
            "year": 2023
        },
        {
            "authors": [
                "E. Mohamed",
                "M.N. Elmohsen",
                "T.A. Basha"
            ],
            "title": "Improved Automatic Grading of Diabetic Retinopathy Using Deep Learning and Principal Component Analysis",
            "venue": "In Proceedings of the 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),",
            "year": 2021
        },
        {
            "authors": [
                "A.A. Khan",
                "N. Kulkarni",
                "A. Kumar",
                "A. Kamat"
            ],
            "title": "D-CNN and Image Processing Based Approach for Diabetic Retinopathy Classification",
            "venue": "In Advances in Intelligent Systems and Computing; Springer: Berlin/Heidelberg,",
            "year": 2021
        },
        {
            "authors": [
                "Y. Han",
                "M. Tao",
                "X. Zheng"
            ],
            "title": "Ensembling Learning for Automated Detection of Diabetic Retinopathy",
            "venue": "In Proceedings of 2021 International Conference on Medical Imaging and Computer-Aided Diagnosis (MICAD",
            "year": 2021
        },
        {
            "authors": [
                "R. Afrin",
                "P.C. Shill"
            ],
            "title": "Automatic Lesions Detection and Classification of Diabetic Retinopathy Using Fuzzy Logic",
            "venue": "In Proceedings of the 2019 International Conference on Robotics, Electrical and Input Image Processing Techniques (ICREST), Dhaka, Bangladesh,",
            "year": 2019
        },
        {
            "authors": [
                "S. Chaudhary",
                "H.R. Ramya"
            ],
            "title": "Detection of Diabetic Retinopathy using Machine Learning Algorithm",
            "venue": "In Proceedings of the 2020 IEEE International Conference for Innovation in Technology (INOCON), Bangaluru, India,",
            "year": 2020
        },
        {
            "authors": [
                "A. Ali",
                "S. Qadri",
                "W.K. Mashwani",
                "W. Kumam",
                "P. Kumam",
                "S. Naeem",
                "A. G\u00f6ktas",
                "F. Jamal",
                "C. Chesneau",
                "S Anam"
            ],
            "title": "Machine Learning Based Automated Segmentation and Hybrid Feature Analysis for Diabetic Retinopathy Classification Using Fundus Image",
            "year": 2020
        },
        {
            "authors": [
                "K. Kumar",
                "P. Megha",
                "K. Meenakshy"
            ],
            "title": "Diabetic Retinopathy Detection & Classification Techniques: A Review",
            "venue": "Int. J. Sci. Technol. Res. 2020,",
            "year": 2020
        },
        {
            "authors": [
                "M. Ammal",
                "D. Gladis"
            ],
            "title": "Perception of hard exudates using Fuzzy Optimization and Discrete Wavelet Transformation in Fundus Image",
            "venue": "In Proceedings of the 2021 Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV), Tirunelveli, India,",
            "year": 2021
        },
        {
            "authors": [
                "E.B. Tala",
                "B. Thabet"
            ],
            "title": "Diabetic Retinopathy Recognition System based on GLDM Features and Feed Forward Neural Network Classifier",
            "venue": "Al-Qadisiyah J. Pure Sci. 2022,",
            "year": 2022
        },
        {
            "authors": [
                "S. Patil",
                "P. Kulkarni"
            ],
            "title": "Diabetic Retinopathy Detection: Methods and Challenges",
            "venue": "In Proceedings of the 2019 IEEE Pune Section International Conference (PuneCon), Pune, India,",
            "year": 2019
        },
        {
            "authors": [
                "L. Qiao",
                "Y. Zhu",
                "H. Zhou"
            ],
            "title": "Diabetic Retinopathy Detection Using Prognosis of Microaneurysm and Early Diagnosis System for Nonproliferative Diabetic Retinopathy Based on Deep Learning Algorithms",
            "venue": "IEEE Access 2020,",
            "year": 2020
        },
        {
            "authors": [
                "T. Ara\u00fajo",
                "G. Aresta",
                "L. Mendon\u00e7a",
                "S. Penas",
                "C. Maia",
                "\u00c2. Carneiro",
                "A.M. Mendon\u00e7a",
                "A. Campilho"
            ],
            "title": "Data Augmentation for Improving Proliferative Diabetic Retinopathy Detection in Eye Fundus Images",
            "venue": "IEEE Access 2020,",
            "year": 2020
        },
        {
            "authors": [
                "T. Nazir",
                "A. Irtaza",
                "A. Javed",
                "H. Malik",
                "D. Hussain",
                "R.A. Naqvi"
            ],
            "title": "Retinal Image Analysis for Diabetes-Based Eye Disease Detection Using Deep Learning",
            "venue": "Appl. Sci",
            "year": 2020
        },
        {
            "authors": [
                "R.J. Chalakkal",
                "F.M. Hafiz",
                "W. Abdulla",
                "A. Swain"
            ],
            "title": "An Efficient Framework for Automated Screening of Clinically Significant Macular Edema",
            "venue": "Comput. Biol. Med",
            "year": 2021
        },
        {
            "authors": [
                "N. Sikder",
                "M. Masud",
                "A. Bairagi",
                "A.S. Arif",
                "A. Nahid",
                "H. Alhumyani"
            ],
            "title": "Severity Classification of Diabetic Retinopathy Using an Ensemble Learning Algorithm through Analyzing Retinal Images",
            "venue": "Symmetry",
            "year": 2021
        },
        {
            "authors": [
                "E. AbdelMaksoud",
                "S. Barakat",
                "M.M. Elmogy"
            ],
            "title": "A comprehensive diagnosis system for early signs and different diabetic retinopathy grades using fundus retinal images based on pathological changes detection",
            "venue": "Comput. Biol. Med",
            "year": 2020
        },
        {
            "authors": [
                "N. Singh",
                "L. Kaur",
                "K. Singh"
            ],
            "title": "Histogram equalization techniques for enhancement of low radiance retinal images for early detection of diabetic Retinopathy",
            "venue": "Eng. Sci. Technol. Int. J. 2019,",
            "year": 2019
        },
        {
            "authors": [
                "X. Li",
                "X. Hu",
                "L. Yu",
                "L. Zhu",
                "C. Fu",
                "P. Heng"
            ],
            "title": "CANet: Cross-Disease Attention Network for Joint Diabetic Retinopathy and Diabetic Macular Edema Grading",
            "venue": "IEEE Trans. Med. Imaging",
            "year": 2020
        },
        {
            "authors": [
                "J. Wang",
                "Y. Bai",
                "B. Xia"
            ],
            "title": "Simultaneous Diagnosis of Severity and Features of Diabetic Retinopathy in Fundus Photography Using Deep Learning",
            "venue": "IEEE J. Biomed. Health Inform",
            "year": 2020
        },
        {
            "authors": [
                "K. Aurangzeb",
                "S. Aslam",
                "M.A. Alhussein",
                "R.A. Naqvi",
                "M. Arsalan",
                "S.I. Haider"
            ],
            "title": "Contrast Enhancement of Fundus Images by Employing Modified PSO for Improving the Performance of Deep Learning Models",
            "venue": "IEEE Access 2021,",
            "year": 2021
        },
        {
            "authors": [
                "G.G. Rajput",
                "B. Reshmi",
                "I. Rajesh"
            ],
            "title": "Automatic detection and grading of diabetic maculopathy using fundus images",
            "venue": "Procedia Comput. Sci",
            "year": 2020
        },
        {
            "authors": [
                "S. Ahn",
                "Q.T. Pham",
                "J. Shin",
                "S.J. Song"
            ],
            "title": "Future Image Synthesis for Diabetic Retinopathy Based on the Lesion Occurrence Probability",
            "year": 2021
        },
        {
            "authors": [
                "S. Qummar",
                "F.G. Khan",
                "S. Shah",
                "A. Khan",
                "S. Shamshirband",
                "Z.U. Rehman",
                "I. Ahmed Khan",
                "W. Jadoon"
            ],
            "title": "A Deep Learning Ensemble Approach for Diabetic Retinopathy Detection",
            "venue": "IEEE Access 2019,",
            "year": 2019
        },
        {
            "authors": [
                "T. Nazir",
                "M. Nawaz",
                "J. Rashid",
                "R. Mahum",
                "M.F. Masood",
                "A. Mehmood",
                "F. Ali",
                "J. Kim",
                "H. Kwon",
                "A. Hussain"
            ],
            "title": "Detection of Diabetic Eye Disease from Retinal Images Using a Deep Learning based CenterNet Model. Sensors",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Citation: Sundaram, S.; Selvamani,\nM.; Raju, S.K.; Ramaswamy, S.; Islam,\nS.; Cha, J.-H.; Almujally, N.A.;\nElaraby, A. Diabetic Retinopathy and\nDiabetic Macular Edema Detection\nUsing Ensemble Based Convolutional\nNeural Networks. Diagnostics 2023,\n13, 1001. https://doi.org/10.3390/\ndiagnostics13051001\nAcademic Editor: Jae-Ho Han\nReceived: 28 January 2023\nRevised: 23 February 2023\nAccepted: 2 March 2023\nPublished: 6 March 2023\nCopyright: \u00a9 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: diabetic retinopathy; ensemble convolutional neural network; diabetic macular edema; Harris hawks optimization and artificial intelligence\n1. Introduction\nComputer-assisted health care, health care technology consulting, and health monitoring equipment are just a few of the current buzz words. Thanks to the connection and computing architecture that has drawn attention to the electronic era we live in, ordinary people now have the luxury of receiving diagnosis and treatment from the comforts of home with a single tap [1\u20133]. While routine illnesses and minor illnesses can usually be treated without visiting a doctor, some more severe illnesses still necessitate a great deal\nDiagnostics 2023, 13, 1001. https://doi.org/10.3390/diagnostics13051001 https://www.mdpi.com/journal/diagnostics\nDiagnostics 2023, 13, 1001 2 of 25\nof effort from the medical establishment. Technology can help, but not replace human intervention. With the advancement in AI technology, technologies can now autonomously analyze a patient\u2019s condition and identify a condition in a matter of seconds using the patient\u2019s significant history and associated data [4\u20136]. By 2025, the amount of DR individuals suffering is predicted to rise from 382 million to 592 million. According to a study conducted in the Pakistani province of Khyber Pakhtunkhwa (KPK), 30 percent of diabetic individuals suffer from DR, with 5.6 percent going blind [7\u20139]. If mild NPDR is not treated in the beginning phases, it might progress to PDR. In another study, 130 people with DR symptoms were found in Sindh, Pakistan [10,11]. According to the findings, DR patients made up 23.85% of the overall examined patients, with PDR patients accounting for 25.8% [12,13]. Patients with DR are symptomatic in the beginning phases; however, as the disease progresses, it causes blobs, vision problems, distortions, and gradual visual acuity loss. Diabetic retinopathy is one of the issues previously mentioned in the article. Diabetic retinopathy is caused by diabetes destroying the blood flow on the retina\u2019s inner, resulting in blood and other body fluids leaking into the tissues surrounding it. Soft, damaged tissue (also known as cotton wool patches) [14], hard exudates, microaneurysms, and hemorrhages form as little more than a result of the leaking [15]. It is the most common cause of visual loss in the working-age population [16]. Diabetic retinopathy (DR) is caused due to diabetes mellitus, which can damage the retina and even lead to the loss of vision. The DR has several stages of severity such as mild, moderate, and severe [17]. The severe stage of DR is termed as proliferative diabetic retinopathy (PDR), in which the formation of new vessels in the retina is observed [18]. However, the early detection of DR and proper diagnosis will reverse or reduce the growth of the effects caused by the disease. Diabetic macular edema (DME) is a condition in which the lesions caused by DR are observed in the middle portion of the retina called the macula. The DME is considered as a serious condition as the damage caused by it is irreversible. The identification of features such as micro-aneurysms, hard exudates, hemorrhages, etc., can be used to carry out the detection of these diseases. These micro-aneurysms refer to the red spots in the retina\u2019s blood vessels with sharp margins formed in the early stages of the disease. The exudates are caused due to abnormality in the blood vessels, which are formed as yellowish-white spots in the outer layer of the retina. Hemorrhages also occur such as micro-aneurysms but have irregular margins caused due to the leakage of capillaries. The blockage of arteries also contributes to cotton wool spots, which occur as a white region in the retinal nerve. Several methods have been developed for the detection of DR and DME to provide diagnosis, but these traditional methods were inefficient in accurately detecting diseases. Deep learning techniques have been deployed for disease detection in which the retinal image (fundus image) is used as the input in which the features are extracted for detection. These approaches have been found to be more effective in identifying features than the traditional methods; however, these approaches also suffer from inaccuracy due to the presence of noises and artifacts in the input images. Figure 1 describes the retina images for disease DR and DME. As a result, it is hard but critical to recognize DR to prevent the worst effects of later stages. Fundus imaging is utilized to diagnose DR, as mentioned in the preceding section. Manual analysis can only be performed by highly qualified subject matter experts and is thus cost and time intensive. As a result, it is critical to apply machine vision technologies to assess the retina image features and aid physicians and radiologists. Hands-on development and end-to-end learning are two types of computer vision-based methodologies. Traditional algorithms such as HoG, SIFT, LBP, Gaussian filters, and others are used to extract the features; however, they failed to preserve the scale, rotation, and brightness fluctuations [19].\nDiagnostics 2023, 13, 1001 3 of 25i ti , , x FOR PEER REVIEW 3 of 7\n(a) (b) (c) (d) (e)\nFigure 1. Retina images. (a) No DR and DME, (b) mild DR and DME, (c) moderate DR and DME, (d) severe DR and DME, and (e) non-PDR.\nSeveral existing approaches have integrated the preprocessing of input images and the deep learning-based detection of diseases in which the accuracy in the detection of diseases was observed to be improved. The common processes involved in these approaches are the preprocessing of input images, enhancement in contrast, and the extraction of features for the detection of diseases. The machine learning models such as support vector machine (SVM) and K-nearest neighbor (KNN) classifiers were found to be appropriate for detecting DR and DME. The severity of the disease was determined by the number of features identified by the model; however, the imbalance in the distribution of datasets resulted in the inefficient determination of severity. In particular, an effective mechanism in the detection of DR and DME, along with the determination of severity, is still in demand. The major aim of this research work was to provide the effective detection of DR and DME and to determine the disease\u2019s severity to define the disease\u2019s damage level on the patient. The accuracy of detection was achieved by performing the proper processing of the input retinal image. End-to-end learning understands the underlying rich traits dynamically, allowing for greater identification. Inside the retina imaging databases, many hand-on engineering and end-to-end learning-based algorithms have been used to identify the DR. Still, none of them can identify the mild stage. Accurate diagnosis of the weak stage is critical for controlling this devastating disease. Utilizing end-to-end deep ensembles models, this study attempted to discover all stages of DR (including the moderate stage). The findings revealed that the proposed strategy beats the current methods. The major objective of this research is to provide precise classification between the DR and DME and to compute the severity of the diseases accurately. This objective can be achieved by fulfilling the sub-objectives, which are listed as follows, \u2022 To minimize the noise level in the input image by performing effective preprocessing of the image; \u2022 To maximize the precise identification of features from the preprocessed image by enhancing the contrast level; \u2022 To maximize the accuracy of detection by incorporating the segmentation of lesions in the blood vessels; \u2022 Effectively classify the images into three classes based on the extraction of significant features; \u2022 To determine the severity of the disease based on the variation in the intensity of the\nfeatures for diagnosis. The major contributions of this paper are as follows:\n\u2022 In our work, we performed preprocessing that included three processes such as noise removal using iterative expectation maximization, artifact removal using nonlinear filtering, and contrast enhancement using Harris hawks optimization; the preprocessed image was used to enhance the quality of the images, which led to high segmentation and detection accuracy. Preprocessing was performed to reduce noise and artifacts and improve the contrast, which increased the efficiency of feature extraction and reduced the false detection rate.\nFigure 1. Retina i ages. (a) No DR and D E, (b) ild DR and D E, (c) oderate DR and D E, (d) severe DR and DME, and (e) non-PDR.\nisti g approaches have integrated the preprocessing of input images and the deep learning-based d tection of diseases in which the accuracy in the detection of diseases was observed to b improved. The c mmon pro esses i volved in these approaches are the\neprocessing of input images, enhancement in contrast, and the extraction of features for he detection of di eases. The machine learning models such as support vector ma ine (SVM) and K-nearest neighbor (KNN) classifiers were f und to be appropriate for detecting DR and DME. The severity of the isease was det mined by th number of features identified by the model; however, the imbalance in the distribution of datasets resulted in the inefficient determination of severity. In particular, an eff ctive mechanism in the detection of DR and DME, along with the determination of severity, is still in demand. The major aim of this research work was to provide the effective detection of DR and DME and to determine the disease\u2019s severity to define the disease\u2019s damage level on the patient. The accuracy of detection was achieved by performing the proper processing of the input retinal image. End-to-end learning understands the underlying rich traits dynamically, allowing for greater identification. Inside the retina imaging databases, many hand-on engineering and end-to-end learning-based algorithms have been used to identify the DR. Still, none of them can identify the mild stage. Accurate diagnosis of the weak stage is critical for controlling this devastating disease. Utilizing end-to-end deep ensembles models, this study attempted to discover all stages of DR (including the moderate stage). The findings revealed that the proposed strategy beats the current methods. The major objective of this research is to provide precise classification between the DR and DME and to compute the severity of the diseases accurately. This objective can be achieved by fulfilling the sub-objectives, which are listed as follows,\n\u2022 To minimize the noise level in the input image by performing effective preprocessing of the image; \u2022 To maximize the precise identification of features from the preprocessed image by enhancing the contrast level; \u2022 To maximize the accuracy of detection by incorporating the segmentation of lesions in the blood vessels; \u2022 Effectively classify the images into three classes based on the extraction of significant features; \u2022 To determine the severity of the disease based on the variation in the intensity of the features for diagnosis.\nThe major contributions of this paper are as follows:\n\u2022 In our work, we performed preprocessing that included three processes such as noise removal using iterative expectation maximization, artifact removal using nonlinear filtering, and contrast enhancement using Harris hawks optimization; the preprocessed image was used to enhance the quality of the images, which led to high segmentation and detection accuracy. Preprocessing was performed to reduce noise and artifacts and improve the contrast, which increased the efficiency of feature extraction and reduced the false detection rate. \u2022 Segmentation was performed before feature extraction and classification, which increased the detection accuracy. For segmentation, we proposed improved OPTICS\nDiagnostics 2023, 13, 1001 4 of 25\nclustering, which considers particular regions of interest and takes less time for segmentation, thus reducing latency and increasing the disease detection accuracy.\n\u2022 Improved OPTICS clustering overcomes misalignment problems due to considering the particular region of interest, thus increasing the segmentation and detection accuracy. \u2022 The extraction of features was carried out in the segmented images obtained from the previous process. Features such as micro-aneurysms, hemorrhages, and hard exudates, collectively termed as structural features, are considered the essential features; along with this, the shape features, orientation features, and color features are also considered for the classification of DR and DME. The ensemble CNN architecture was implemented for this purpose, which outperformed the ensemble CNN class prediction. From this, the classification of images was carried out in several classes, namely, normal, DR, and DME. Furthermore, the severity of the disease was computed by using conditional entropy in which the number of lesions is considered for the threshold generation. Based on the threshold, the severity level of the disease was classified into three classes: mid, moderate, and severe. \u2022 The proposed research work is evaluated in terms of performance metrics such as accuracy, precision, recall, F-score, computation time, and error rate.\nThe rest of the paper is organized as follows: Section 2 illustrates the state-of-the-art in diabetic retinopathy and diabetic macular edema detection using specific approaches. Section 3 discusses the major problems that exist in this field. Section 4 describes the system model with the proposed algorithms and techniques in detail. Section 5 describes the experimental results of the proposed as well as previous methods. Section 6 concludes the paper by providing future enhancements.\n2. Related Work\nIn the literature, the diagnosis of DR has received much interest. In [20], researchers offered a robust system that automatically recognized and classified retinal lesions (blood vessels, microaneurysms, and exudates) from retinal imaging. Blood vessels, microaneurysms, and exudates were first discovered using image processing methods. Following this, the retina properties of the vascular system, microaneurysm count, exudate area, contrast, and homogenization were evaluated from the images obtained. These characteristics were then fed into a fuzzy classifier that uses the information to classify healthy, mild NPDR, moderate NPDR, severe NPDR, and PDR stages. A sample of 40 color fundus images was obtained from the DIARETDB0, DIARETDB1, and STARE datasets using a fuzzy classifier, correctly classifying the images with an efficiency of up to 95.63 percent. A reliable automated approach for detecting and classifying the various stages of DR has been suggested The optic disc and retina neurons are separated, and characteristics are retrieved using the gray level co-occurrence matrix (GLCM) approach. To identify various stages of DR, a fuzzy classifier and a convolutional neural network were used to classify them. DIARETDB0, STARE, and DIARETDB1 were the datasets used [21]. The unique clustering-based automatic region growth methodology was introduced in this study. Several types of features\u2014waveform (W), co-occurrence matrix (COM), histogram (H), and run-length matrix (RLM)\u2014were retrieved for the texture features, and several ML algorithms were used to achieve a classification performance of 77.67 percent, 80 percent, 89.87 percent, and 96.33 percent, respectively. The information fusion approach was utilized to create a fused hybrid-feature database to improve the accuracy of the classification. Two hundred and forty-five elements of the hybrids\u2019 feature data (H, W, COM, and RLM) were extracted from each image, and 13 optimum characteristics were chosen using four methodologies: Fischer, mutual information feature selection, information gain, and the possibility of the dependent variable average correlation [22]. The number of DR patients outnumbered the number of practitioners by a large margin. As a result, manual clinical diagnosis or screening takes a long time. To avoid this problem, follow-up scanning is performed regularly, and automated DR identification and intensity\nDiagnostics 2023, 13, 1001 5 of 25\nclassification are required. Several strategies for detecting retinopathy and classifying its severity and likelihood are presented here [23]. Exudates are the diagnostic indications of diabetic retinopathy, a retina condition caused by long-term diabetes that can lead to eyesight problems if not detected early. The procedure of recognizing and categorizing exudates from a retinal image has been made easier thanks to a medical screening program. The exudates are first segregated using the FCM technique and then transformed into discrete mother wavelets. The classifier is fed the texture textural properties retrieved by the grey-level co-occurrence matrix. The suggested program\u2019s efficiency was evaluated by comparing it to the data from the publicly available dataset IDRID. MATLAB was used to formulate and construct a GUI [24]. This research has the proposed texture feature extraction characteristics of the GLDM method (contrast, angular second moments, density, median, and inverse difference moment) feature and feed-forward neural net classifier as a machine learning-based approach for DR detection and evaluation. According to the results of the trials and performance assessment, the suggested methodology had a detection performance of 95% [25]. Diabetes is responsible for 50 deaths per 1000 live births amongst individuals over the age of 70. The identification of diabetes at a preliminary phase and the implementation of a suitable therapy may minimize the visual loss among the sufferers. Once symptoms of DR have been identified, the severity of the disease must be defined to recommend the appropriate treatment. Mild nonproliferative diabetic retinopathy (NPDR), moderate NPDR, severe NPDR, proliferative diabetic retinopathy (PDR), and no DR are the five phases of diabetic retinopathy severity. The techniques and issues associated with DR identification are summarized in this publication [26]. In [27], the authors proposed diabetic retinopathy classification using retinal images through an ensemble learning algorithm. The proposed work includes the following processes: retinal image collection, preprocessing, feature extraction, and feature selection and classification. In preprocessing, the noisy images, duplicate images, and black borders are removed from the images. Tone mapping is used to increase the contrast and luminance in the images. Two sets of features are extracted from images such as the histogram-based feature and GLCM feature extraction. Then, the features are concatenated to select the relevant features. Here, the GA algorithm is used for feature selection. Finally, classification was undertaken by the XGBoost algorithm using the selected features. Here, genetic algorithm (GA) was used for feature selection; it takes a lot of time to select the features, thus increasing feature selection and classification latency. Early detection of diabetic retinopathy using retinal images for diabetes is presented in [28]. The proposed method includes four processes: preprocessing, segmentation, feature extraction, and classification. The preprocessing includes noise removal and contrast enhancement using histogram equalization (HE). The segmentation is performed by Gaussian derivative and Coye filter, which segments the EX, MA, and HM. The features are extracted from the segmented image and extract features such as EX, MA, and HM values. Finally, SVM is used to classify the images using the extracted features. Here, SVM was used for classification, which takes a lot of time for training when considering larger datasets, thus leading to classification latency. A histogram equalization method for the early detection of diabetic retinopathy was presented in [29]. The proposed algorithm included three methods: histogram clipping, RIHE-RVE, and RIHE-RRVE, which addressed the issues of the illumination of the retinal images. To avoid enhancement, the histogram clipping algorithm was proposed. The simulation result showed that the proposed method achieved a high performance compared to the other state-of-the-art methods. Here, the histogram equalization method was proposed, however, it is an unselective process that may increase the background noise contrast while decreasing the functional input image. The authors in [30] proposed CANet to detect diabetic retinopathy and macular edema for diabetes. The proposed work used ResNet50 to produce a feature map with various resolutions including a cross-disease attention network, disease-specific attention module, and disease-dependent attention module. The disease-specific attention module was used\nDiagnostics 2023, 13, 1001 6 of 25\nto learn the features of the two diseases. In this stage, the inter special relationship was evaluated to detect the diseases. A disease dependent attention module was used to evaluate the internal relationship between the DR and DME diseases. Here, raw images were considered for training and testing, thus increasing the high false positive rate due to the presence of noise and low contrast, also reducing the detection accuracy. The authors in [31] proposed a deep learning algorithm to detect diabetic retinopathy disease in diabetic patients. The proposed method included two processes: diagnosing DR severity and the feature extraction of DR. The proposed system hierarchical multitask learning architecture aims to detect both the DR severity and DR feature extraction. Finally, the fully connected layer provides the output, and it considers the hybrid loss, crossentropy loss, and kappa loss for reducing the errors in the levels of DR severity. The simulation results showed that the proposed model achieved a higher performance using traditional deep learning methods. Here, the traditional deep learning method was used to detect the DR severity levels and feature extraction of DR; however, it generated multiple convolutional layers, thus increasing the complexity and latency. In [32], the authors proposed a modified contrast enhancement approach from the effective identification of features in detecting diabetic retinopathy and diabetic macular edema. The limitations of conventional contrast limited the adaptive histogram equalization (CLAHE) technique such as the fixed clip limit and region of context, resulting in the inefficient identification of minute features, but can be overcome by implementing modified particle swarm optimization (MPSO) to determine the optimal clip limit and region of context, thereby resulting in the precise identification of features that further help in the accurate detection of diseases. The global best solution of all the operating particles was computed by comparing the output provided by all the particles in the iteration, which resulted in enhanced image contrast. The optimization of the clip limit and region of context was performed by the MPSO algorithm for the purpose of enhancing the contrast of the input image, but the proposed algorithm possessed slow convergence and is stuck in the optimal local solution. In [33], the authors proposed an approach for the detection of diabetic macular edema in an automatic manner. The macular edema was identified, and the severity of the disease was determined by implementing mathematical morphology. The retinal image was used as the input from the detection process that was carried out. Initially, the preprocessing of the input image was performed from the removal of noise and enhancement of the contrast. Furthermore, the localization of the macula was executed by removing the optic disc and locating the center of the fovea. Then, the exudates in the region of the macula were identified in order to determine the severity of the disease. The removal of artifacts such as reflection due to lighting was removed as a post-processing step to achieve an accurate determination of severity. The detection of the macula in the input retinal image was carried out by using mathematical morphology, but this approach resulted in less accuracy in the detection of the macula region. In [34], the authors proposed a probability-based construction of the future retinal image in detecting diabetic retinopathy. The difficulty in identifying the future instances of lesions in the retinal image was addressed. Initially, the segmentation of lesions and vessels was carried out to identify the severity of the disease from the input retinal image. Then, the probability of future lesion location was computed by the construction of a probability map. Furthermore, the generated probability map, along with the structure of vessels, was considered for the systemization of future lesions in the retina. This method was found to be effective in predicting future lesions based on the progression of the severity of diseases. The future severity of diabetic retinopathy was determined by using the probability map and the features of the current vessels, but the lack of noise removal in the input image reduced the efficiency of this approach.\nDiagnostics 2023, 13, 1001 7 of 25\n3. Problem Statement\nAn input fundus image is used to perform the identification of diabetic retinopathy and diabetic macular edema; however, the accuracy of the system is decreased by the increased false detection rate of the existing techniques. In addition, the following issues are encountered in the best detection of DR and DME, which are listed as:\n\u2022 Difficulty in feature differentiation: The detection of DR and DME is based on various features such as hard exudates, hemorrhages, and micro-aneurysms, but the differentiation of these minute features from each other is a hard task, which degrades the computation of the accurate severity of diseases. \u2022 Class Overlapping: Current techniques also consider illness severity; however, the sparse training data for each severity leads to class imbalance issues that degrade the classification accuracy. \u2022 Inadequate preprocessing: Using the current methods for effective contrast enhancement with traditional preprocessing leads to difficulties distinguishing features from the background.\nIn [35], the authors proposed diabetic retinopathy detection using a deep convolution neural network (DCNN) for nonproliferative diabetic retinopathy. The proposed work includes three phases: preprocessing, candidate lesion detection, and candidate extraction. In preprocessing, the image contrast is enhanced using curve transformation. Then, the images are smoothened by a bandpass filter. In the lesion, the detection process includes four stages: optical disc removal, candidate lesion detection, vessel extraction, and preprocessing. In candidate extraction, the micro-aneurysms are detected to measure the coefficient between every pixel using Gaussian kernels. For this, a PCA algorithm was proposed to reduce the dimensionality. Finally, classification was undertaken by DCNN. In this way, the proposed work achieved high accuracy of nonproliferated diabetic retinopathy. The major issues determined in this paper are as follows:\n\u2022 Here, preprocessing was performed to enhance the quality of the retinal images; however, the retina image still has noise due to the implementation of traditional contrast enhancement techniques, thus reducing the image quality, which leads to a high false detection and reduced detection accuracy. \u2022 DCNN is used for feature extraction and the detection of nonproliferated diabetic retinopathy. Still, DCNN focuses on the whole image for the extraction of features without any particular region of interest, thus increasing the high latency for feature detection. \u2022 The PCA algorithm was used to reduce the dimensionality, but the number of principal components must be selected otherwise it may cause information loss, thus reducing the detection accuracy.\nThe authors in [36] proposed a data augmentation method to improve the detection rate of proliferative diabetic retinopathy. The NVs were inserted onto pixels located on vessels. Vessel segmentation was performed by Otsu thresholding and the U-Net deep learning algorithm, and then optic disc segmentation was performed. The count of NVs was determined by selecting random values using a threshold. The next process is semi-random blood vessel generation, which is based on the tree structure. This process considers the shape and orientation of the NVs. For the vessel color assignment color, a matrix was proposed that calculates the weighted average of the RGB values of the images. Finally, DR grading and data augmentation was proposed to improve the NVs. Some of the significant problems in this research are as follows:\n\u2022 Here, the Otsu thresholding method was used for vessel segmentation, which performed well; however, it did not provide an optimal result for noisy images. First, the noise is removed from the images, and then the thresholding is applied; otherwise, this method will fail, thus reducing the performance of vessel segmentation. \u2022 The detection of diabetic retinopathy was carried out by performing the segmentation of neovessels in the retina. However, performing detection based on a single feature results in a high false detection rate.\nDiagnostics 2023, 13, 1001 8 of 25\n\u2022 Here, the U-Net algorithm was also used for vessel segmentation, which takes a lot of time to learn the vessels from the retinal images at the middle layers, thus leading to high latency.\nThe authors in [37] proposed the analysis of retinal images to detect eye diseases for diabetes using the deep learning method. The proposed method considered two processes: detection and localization, and the segmentation of localized regions. For localization, the author proposed the FRCNN method, which extracts the features from the images that evaluate the affected portions. For the segmentation process, the author proposed the FKM clustering algorithm. The ground truth was generated for detecting the affected regions during training. Finally, the DME is classified into two classes such as DME and background. The serious issues in this paper are as follows:\n\u2022 Here, raw images were considered for the localization and segmentation process, thus reducing segmentation and detection accuracy due to low contrast and the presence of noise in the retinal images. \u2022 Faster RCNN was implemented for the extraction of features but the lack of pixelto-pixel alignment in the region of interest caused misalignment, resulting in the degradation of the detection accuracy. \u2022 The proposed approach was used for diabetic-based disease detection in the eye, but the detection of various diseases from the limited number of trained images resulted in class imbalances.\nThe authors in [38] presented an efficient framework for the detection of macular edema disease for diabetes. The proposed work used the combination of a deep convolution neural network (DCNN) and a meta-heuristic algorithm for feature extraction and feature selection, respectively. At the stage of feature extraction, the proposed work reduced the feature extraction complexity by reducing the prior knowledge. The SMOTE algorithm was used to perform class imbalance. The generic algorithm and binary particle swarm optimization algorithm were used to select the relevant features. The drawbacks in this paper are as follows:\n\u2022 Here, the features were extracted from the noisy images, thus reducing the quality of the images and leading to poor feature extraction, thus increasing the macular edema\u2019s false detection rate. \u2022 The integration of the genetic algorithm and binary particle swarm optimization was used to determine the subset size. However, implementing these two algorithms increases the complexity and time consumption, thereby increasing the latency. \u2022 DCNN was used for feature extraction and the detection of nonproliferated diabetic retinopathy, however, DCNN focuses on the whole image for the extraction of features without any particular region of interest, thus increasing the high latency for feature detection.\n4. Proposed Model\nIn this research work, we concentrated on accurately detecting the DR and DME from the input fundus images. The severity of the disease is also determined based on the features extracted from the images. Figure 2 shows the architectural view of the proposed work. The description of the dataset is provided below: The properties of the blood vessels in the retinal image enable the ophthalmologist to assess retinal disease. The presence of lesions on the fundus image is the first sign of diabetic retinopathy. The preprocessing technique is mainly used to remove unwanted noise and enhance some image features. The fundamental idea underlying OPTICS is to find the points associated by density to extract the cluster structure of a dataset. The approach generates a density-based representation of the data by constructing a reachability graph, an ordered collection of points. Each location in the list has a reachability distance associated with it, which\nDiagnostics 2023, 13, 1001 9 of 25\nmeasures how simple it is to get to that site from other points in the collection. Points with comparable accessibility distances are most likely in the same category.\nDiagnostics 2023, 13, x FOR PEER REVIEW 9 of 27\nThe properties of the blood vessels in the retinal image enable the ophthalmologist to assess retinal disease. The presence of lesions on the fundus image is the first sign of diabetic retinopathy. The preprocessing technique is mainly used to remove unwanted noise and enhance some image features. The fundamental idea underlying OPTICS is to find the points associated by density to extract the cluster structure of a dataset. The approach generates a density-based\nFigure 2. System model.\nBefore sharing our preprocessed image with CNN, we converted the image to an array and mapped that array\u2019s values in the range of 0 to 1 as the epoch was set at 235 to reach a deep network. The initial learning rate was kept at 1 \u00d7 103, which is the default value for the\nDiagnostics 2023, 13, 1001 10 of 25\nAdam\u2019s optimizer, and the die stack size was 32. We trained our model with more pictures, obtained only a few hundred of images for training, and generated more images from the existing dataset by passing parameters such as the rotating range, width changing range, height changing range, scissors range, zoom range, and pan on image data generator. The classification of diabetic retinopathy is classified into two types: nonproliferative and proliferative. The term \u201cproliferative\u201d refers to whether the retina has neovascularization (abnormal blood vessel growth). Nonproliferative diabetic retinopathy refers to early illness without neovascularization (NPDR). Dataset Collection: For accurate prediction of diabetic retinopathy and diabetic macular edema, we applied two kinds of retina fundus images: IDRiD and MESSIDOR. The description of these two datasets is as follows:\n\u2022 IDRiD: Based on the presence of DR and DME disease, 516 images were loaded in the dataset. In addition, images were acquired through the field of view and stored in JPG format, and the size of each image was 800 KB. This dataset contained 81 color fundus images with the sign of DR. With this dataset, hard exudates (EX), microaneurysms (MA), soft exudates (SE), and hemorrhage (HE) based images are stored. \u2022 MESSIDOR: This dataset was used, whose scope is to develop the DR and DME detection of images. In total, 1200 eye fundus images were used with the multiple pixel rates of 1440 \u00d7 960, 2240 \u00d7 1488, and 2304 \u00d7 1536. The following steps implement a prediction of DR and DME.\n4.1. Preprocessing\nThis is an initial step for DR and DME detection. To enhance the information for the disease diagnosis system, it is necessary to use some of the preprocessing steps as follows: (a) Noise Filtering: Fundus images are cropped by salt and pepper noises, which are removed from the input images using the iterative expectation maximization (IEM) approach. In this approach, uncertainty is overwhelmed by using IEM variables. Noise is removed in the zig-zag trajectory and edge, and the corner position of the image is denoised using IEM variables. A dynamic threshold was computed and adjusted accordingly for noise removal since the acquisition of each image was different with their resolution. The proposed inverse dual tree initial ranging (IDTIR) procedure uses the iterative expectation maximization (IEM) algorithm. The IEM algorithm is an iterative method that effectively estimates the parameters of the statistical model. In the IEM algorithm, two major steps are executed to estimate the parameters accurately. These steps can be explained as follows:\n\u2022 E-step\u2014This step determines the current estimate of parameters by creating a function for the expectation of log-likelihood. The expectation step is the base of the proposed IEM algorithm. \u2022 M-step\u2014This step is the final step that computes the parameters in such a way that the expected log-likelihood function can be maximized (i.e., the likelihood function determined in the E-step is maximized to calculate the parameters.\nThe above two steps were iteratively executed to determine the final parameters. Let \u03c9V,L be the parameter vector, and it can be represented as \u03c9V,L = [hV,L, TV,L] \u2208 \u00b5 for the Lth active channel path of the given ranging code. The set of parameters is represented as \u00b5. The latest estimated parameter set is denoted as \u00b5\u0302 and can be formulated as follows,\n\u03c9\u0302V,L = [ h\u0302V,L, T\u0302V,L ] \u2208 \u00b5\u0302 (1)\nE-Step Computation In this step, the expected value is calculated as\nG(\u03c9V,L|\u00b5\u0302) , lnP ( Y|\u03c9V,L, \u00b5\u0302 ) \u03b1\u2212 \u2016 ( Y\u2212 K\u0302V,L ) \u2212 hV,L\u0393(TV,L){V\u20162 (2)\nDiagnostics 2023, 13, 1001 11 of 25\nHere,\nK\u0302V, , N\n\u2211 \u2135=1\nNB \u2211 s=1\nh\u0302\u2135,s\u0393(T\u0302\u2135,s){\u2135 \u2212 h\u0302V,L\u0393 ( T\u0302V,L ) {V (3)\nM-Step Computation In this step, the expected value is maximized as follows:\n\u03c9\u0302V,L = argmax{G(\u03c9V,L|\u00b5\u0302)} (4)\nAfter parameter estimation, the estimated parameters are updated in the parameter vector. These two steps are executed until the terminating condition is met. The channel coefficient is derived from the parameter vector by letting the derivative equal zero with the fixed timing offset. (b) Artifact Removal: Blurriness, poor edges, and illumination are called artifacts, which are removed using the nonlinear diffusion filtering algorithm, which eliminates all kinds of artifacts and ensures the image quality in terms of illumination correction and edge preservation. (c) Contrast Enhancement: Low contrast is one of the important issues of image classification. In this work, we considered contrast enhancement as an optimization problem with the intention of optimizing the pixel values based on the contrast level of the input image. To enhance the contrast level of the input image, we proposed the Harris hawks optimization algorithm, which improves the performance of the image brightness. H2O is a recently developed meta-heuristic algorithm that performs better in solving optimization problems. The H2O algorithm mimics the cooperative strategy and chasing style of the Harris hawks in nature. Since it has an intelligent searching strategy and fast convergence rate, it works better than the conventional genetic algorithm, particle swarm optimization algorithm, etc. Due to the benefits of the H2O algorithm, it was adapted for contrast enhancement using the pixel intensity rate in the proposed system. The proposed H2ORSS algorithm detects the optimum threshold value for replacing the pixel intensity values with normal ones. The proposed H2ORSS algorithm involves three major processes: initialization, fitness value estimation, and update of hawks. Initially, the image matrix is initialized as hawks with the population size of PS. For each hawk (Xi) in the population, the fitness function is estimated. The fitness function is determined in terms of the pixel intensity, neighbor intensity, and resolution. The fitness function of the ith hawk is expressed as follows, Once the fitness is computed for all hawks, then three sequential phases are executed to select the optimal solution.\nPhase 1: Exploration Phase This phase relies on waiting, searching, and detecting prey. In every step, each Harris\nhawk is considered as the alternative solution. Based on the fittest solution, the position for each Harris hawk is updated as follows:\nX(iter + 1) = { Xrand(iter)\u2212\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f (iter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next iteration is denoted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the present location vectors of the hawks. Furthermore, \u2134 is the random\nnumber selected in the range of 0 and 1, and u , l are the upper bound and lower bound, respectively. The average location of hawks (\ud835\udd4f (iter) can be estimated from the following expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Exploration to Exploitation Next, the algorithm transforms the state from exploration to exploitation. In this\ntransformation, the energy of the prey is dissipated due to evading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initial state energy of the prey and t is the maximum iteration. By varying the tendency of E , the state of the prey can be judged.\nPhase 3: Exploitation After judging the state of the prey, the Harris hawks attack the selected prey. In\npractice, the prey changes the evading behavior, frequently changing the attacking behavior. Four strategies are constructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besiege and hard besiege are the basic strategies to attack the prey, which is decided as follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of the prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) represents the difference in the location vector of prey in each iteration. This difference is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selected to attack the prey.\nIn general, these probability values show that the prey\u2019s energy is dissipated and has low evading energy. In this case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next position of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\n1|Xrand(iter)\u2212 2\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f (iter) \u2212 \ud835\udd4f iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) T e location of the hawks i the next iteration is denoted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the present location vectors of the hawks. Furthermore, \u2134 is the random\nnumbe sel cted in the range of 0 and 1, and u , l are the upper bound and lower bound, respectively. The average locat on of hawks (\ud835\udd4f (iter) can be stimated from the f llowing expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transform from Exploration to Exploitation Next, the algorithm transforms the s ate from exploration to exploitation. In this\ntra sformation, th energy of he prey is dissipated due to evading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initial stat energy of the prey and t is the maximum iteration. By varying the tendency of E , the state of th prey can be judged.\nPhase 3: Exploitation After judging the state of the prey, the Harris hawks attack the selected prey. In\npractic , t prey changes the evading behavior, frequ ntly hanging the attacking behavior. Four strategies are constructed in the H2ORSS lgorithm for attacking prey based on evading behav or. Here, soft nd ard besiege are the basic strategies to attack th prey, which is decided as follows: If E \u2265 0.5, then a oft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besi e attacking str tegy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 s the jum intensity of the prey during the evading process, and it is giv-\nen s \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(it r) represents the difference in the location vector of prey in each iteration. This difference s estimated by using the f llowing expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besi ge strategy is sel cted to attack the prey.\nIn general, these probability values show that the prey\u2019s nergy is dissipated and has low evading nergy. In his case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next po ition of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs thi st ategy nvolves progressive dives, the hawk\u2019s ive is formulated as follows:\n2X(it r)|\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\nThis phase relies aiti , searc i , a etecti rey. In every step, each Har-\nris hawk is considered as the alternative solution. Based on the fittest solution, the posi-\ntion for each Harris hawk is updated as follows:\n\ud835\udd4f(iter + 1) = { \ud835\udd4frand(iter) \u2212 \ud835\udcc71 rand 2 \ud835\udd4fp(iter) \ud835\udd4fa(iter) \ud835\udcc73(lb \ud835\udcc74(ub lb)) if \u2134 0.5\n(5)\nThe location of the ha ks in the ext iteratio is e o e as \ud835\udd4f(iter 1) and \ud835\udcc71, \ud835\udcc72,\n\ud835\udcc73, \ud835\udcc74 are the present location vectors of the ha ks. Further ore, \u2134 is the ando nu ber selecte in the range of 0 an 1, an ub, lb are the upper bound and lo er bound, respectively. The average location of ha ks (\ud835\udd4fa(iter) can be esti ated fro the fo lo ing expression:\n\ud835\udd4fa(iter) 1\nPS \u2211 \ud835\udd4fi(iter)\nPS\ni=1\n(6)\nPhase 2: Transfor ation fro Exploration to Exploitation\next, the algorith transfor s the state fr exploration t ex loitatio . I this\ntransfor ation, the energy of the rey is issi ate e to evading behavi r. The energy\nlevel of the prey is (Ep), ich is expressed as fo lo s:\nEp 2Eo(1 iter\nTm ) (7)\nere, E0 is the initial state energy of the prey and tm is the axi u iteration. By\nvarying the tendency of E0, the state of the prey can be judge .\nPhase 3: Exploitation\nfter judging the s ate of the prey, he arris ha ks a tack the selected prey. In\npractice, the prey changes the evading behavior, frequently changing the attacki be-\nhavior. Four strategies are constr cte in the 2 SS algorith for attacking re\nbased on evading behavior. ere, soft besiege an har besiege are the basic strategies\nto a tack the prey, hich is decided as fo lo s: If |Ep| 0.5, then a soft besiege occurs, and if |Ep| 0.5, then a hard besiege occurs.\nSoft Besiege\nThis attacking strategy is selected hen Ep 0.5 and \ud835\udcc7 0.5 by arris ha ks.\nThis soft besiege attacking strategy is o ele as follo s:\n\ud835\udd4f(iter 1) \u2206\ud835\udd4f(iter) Ep|\ud835\udd09\ud835\udd4fp(iter \ud835\udd4f(iter))| (8)\nere, \ud835\udd09 is the ju p intensity of the prey during the evading rocess, a it is gi -\nen as \ud835\udd09 2(1 \ud835\udcc75) and \u2206\ud835\udd4f iter) represents the difference in the location vector of prey in each iteration. his difference is esti ate by sing e follo i g ex ressio :\n\u2206\ud835\udd4f(iter) \ud835\udd4fp(iter) \ud835\udd4f(iter) (9)\nard Besiege\nIf |Ep| 0.5 and \ud835\udcc7 0.5, the har besiege strategy is selected to attack the rey.\nIn general, these probability values sho that the prey\u2019s energy is dissipated and has\nlo evading energy. In this case, the position of arris ha ks is ate by the fo lo -\ning equation:\n\ud835\udd4f(iter 1) \ud835\udd4fp(iter) Ep|\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege ith Progr siv apid ives\nThis strategy is selected hen the prey has suffici nt nergy to eva e for the at-\ntack. This situation is explaine as |Ep| 0.5 and \ud835\udcc7 0.5. Based on this behavior, the next position of the ha ks is updated as fo lo s:\n\ud835\udd1c \ud835\udd4fp(iter) Ep|\ud835\udd09\ud835\udd4fp(iter \ud835\udd4f(iter))| (11)\nXp(iter)\u2212Xa(iter)\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f (iter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the n xt iteration is d noted as \ud835\udd4f(i er + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the pre nt l catio vectors of the hawks. Furthermore, \u2134 is th random\nnumber selecte in the range f 0 and 1, and u , l re th upper bou d and low r bound, respectively. The average location of hawks (\ud835\udd4f (iter) can be estimated from the following expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Ph se 2: Transformation fro Explo ation to Expl ita ion Next, the al ori hm ansform the state fr m ex loration t xploitation. In this ransformation the nergy of the prey is dissipated due t evading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHer , E is the initi l state energ of he prey and t is the maximum iteration. By varying the endency of E , the state of the prey can be judged.\nPhase 3: Exploitation Aft r judging state of th prey, th Harris hawks attack the selected prey. In\npractice, t prey changes the vading behavior, frequently changing the attacking behavior. Four strategies are construct d in the H2ORSS algorithm for acking prey bas d on evad ng behavior. Here, s ft besiege and hard besiege ar th basic trategies to attack the prey, which is d ided as follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, hen a hard besiege occurs.\nSoft Besiege This a tacking strategy is sel cted when E \u2265 0.5 nd \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 i the jump int nsity of the p ey during he eva ng process, and it is giv-\nn as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(it r) represe ts th differ nce in the location vector of prey in each iteration. This difference is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 nd \ud835\udcc7 \u2265 0.5, the rd b siege trat selected to ttack the prey.\nIn eneral, these probability values show t at t e prey\u2019s ene gy is di s pate and has low evading energy. In this case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Be ieg with Progre sive Rapid Dives This strat gy is s lected when the prey has sufficient e ergy to ev d f rm the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next position of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\n3(lb\nDiagnostics 2023, 13, x FOR P ER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f (iter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The l ca ion of he hawks in th next iteration is denoted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are th prese t locati n vec ors of the hawks. Fu thermore, \u2134 is the rand m\nnumber sel cted i the rang of 0 and 1, and u , l are h upper bound and l wer bou d, r sp ctiv ly. The average l cation of hawks (\ud835\udd4f (iter) can be estimated from the following expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) P se 2: Tr nsf mation fr m Expl ration to Exploitati n N xt, the algo ithm transforms the stat fr m xploration to xploitation. In this\ntr nsformat on, the energy of t e prey is dissipa ed due to evading behavior. The energy level of the prey is (E ), which i expressed a follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E i th ini ial state energy of the prey d t is the aximum iteration. By varying the tendency of E , the state of the pr y can be judged.\nPhas 3: Exploitation After judging the state of the prey, he H r is haw s a tack the sel cted prey. In\npract ce, th prey changes the vading behavior, freque tly ha ing the behavior. F ur st t gi s a e constructe in the H2ORSS lgori hm for att cking prey based on evading behavi r. Her , soft besiege and hard are the basic strategies to attack the pr y, whi h is decided a follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSof Besiege Th s at ackin trat gy is lected wh n E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThi soft besiege attacking strategy is mode ed a follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of th pr y during the evading p ocess, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f( t r) represents the differ ce in he locati n vect r of prey in each iteration. This difference is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, hard b si ge strat gy i selec e to attack the prey.\nIn gen r l, the prob b l ty v lues show that the prey\u2019s energy is dissipated and has low evading e ergy. In this case, he position of Harris hawks is updat d by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft B iege wi Progr ssive Rapid Dives This strat gy is selected when t e prey h sufficient en rgy to evade form the at-\nack. Th s s t ation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this be avior, the next position of the hawks is updated a follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs his strategy inv lves progressive dives, the hawk\u2019s dive is formulated as follows:\n4 b lb ) if\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\nThis phase relies on waiti g, searching, and detecting prey. In every s ep, each Har\nris hawk is considered as the alternative solution. Based on the fittest solution, the posi-\ntion for each Harris hawk is updated as follows:\n\ud835\udd4f(iter + 1) = { \ud835\udd4frand(iter) \u2212 \ud835\udcc71|\ud835\udd4frand(iter) \u2212 2\ud835\udcc72\ud835\udd4f(iter)| \u2265 .\n\ud835\udd4fp(iter) \u2212 \ud835\udd4fa(iter) \u2212 \ud835\udcc73(lb + \ud835\udcc74(ub \u2212 lb)) if \u2134 < 0.5 (5)\nThe location of he hawks in the nex iteration is deno d as \ud835\udd4f(iter + 1) nd \ud835\udcc71, \ud835\udcc72,\n\ud835\udcc73, \ud835\udcc74 ar the present location vectors of the hawks. Furthermore, \u2134 is random numbe el ed in ang of 0 nd 1, ub, lb ar the upp r bound and low r bound, respectively. Th average loc tion of hawks (\ud835\udd4fa(iter) can be est mat d from the following expressi n:\n\ud835\udd4fa(iter) = 1\nPS \u2211 \ud835\udd4fi(iter)\nPS\ni=1\n(6)\nPhase 2: Transfor a io f m Explora ion t Exploit\nNext, the algorithm t ansforms the state f om xploratio to itati . I this\ntransformation, th e ergy of th prey i is ipated du to evading behavior. The en rgy\nlevel of th prey is (Ep), which is expre s d as follows:\nEp = 2Eo(1 \u2212 iter\nTm ) (7)\nHere, E0 is the initial state en rgy of th prey and m is the maxim m i eration. By\nvarying the tendency of E0, the state of he pr y can be judged.\nPhase 3: Exploitation\nAfter judging the sta e of h prey, the Harris hawk tt ck t e s lec d prey. In\npractice, the prey hanges the ev ding behavi r, f equently c anging the ttacking be-\nh vior. Four str tegies a e cons ru ed in he H2ORSS algorithm fo tta king pr y\nbased on evadi g be vior. He , soft besieg an hard b sieg are the a c str tegi s\nto attack the prey, whic is decided as follows: If |Ep| \u2265 0.5, then a soft besieg occurs, and if |Ep| < 0.5, then a hard besiege occu s.\nSoft Besiege\nThis attacking trategy is s lec ed wh n Ep \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawk .\nThis soft besiege attacking trate y is modeled as follows:\n\ud835\udd4f(iter + 1) = \u2206\ud835\udd4f it ) \u2212 Ep|\ud835\udd09\ud835\udd4fp \u2212 \ud835\udd4f(iter))| (8)\nHere, \ud835\udd09 is the jump intensity of th pr y during th evading process, d t is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc75) a d \u2206\ud835\udd4f(it r) represents th diff r c in th location vect r f prey in each iter tion. Th s difference is timat d by using the following expressi n:\n\u2206\ud835\udd4f(iter) = \ud835\udd4fp(iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege\nIf |Ep| < 0.5 and \ud835\udcc7 \u2265 0.5, th hard besiege strat gy i selected to att ck the prey.\nIn g neral, th se probabili y values show that the prey\u2019 en rgy is d ipat d and h\nlow ev d ng energy. In this case, the position f Harris hawk is updated by the follow-\ning equation:\n\ud835\udd4f(iter + 1) = \ud835\udd4fp(iter) \u2212 Ep|\u2206 (iter)| (10)\nSoft Besi e with Progressiv Rapid Dives\ntrategy is s lected when the pr y h s sufficient energy t evad fo m the at-\ntack. Th s situa ion is explain s |Ep| \u2265 0.5 and \ud835\udcc7 < 0.5 B sed on this behavior, the next position f he hawks is updated as follows:\n\ud835\udd1c = \ud835\udd4fp(iter) \u2212 Ep|\ud835\udd09 p \u2212 \ud835\udd4f(iter))| (11)\n< 0 5 (5)\nThe location of the hawks i the n xt iteration is d not d as X(iter + 1) and\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (it r) \u2212 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f ( r) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next iteration is denoted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the present location vectors of the hawks. Furthermore, \u2134 is the random\nnumber selected in the range of 0 and 1, and u , l are the upper bound and lower bound, respectively. The average location of hawks (\ud835\udd4f (iter) can be estimated from the following expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Exploration to Exploitation Next, the algorithm transforms the state from exploration to exploitation. In this\ntransformation, the energy of the prey is dissipated due to evading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initial state energy of the prey and t is the maximum iteration. By varying the tendency of E , the state of the prey can be judged.\nPhase 3: Exploitation After judging the state of the prey, the Harris hawks attack the selected prey. In\npractice, the prey changes the evading behavior, frequently changing the attacking behavior. Four strategies are constructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besiege and hard besiege are the basic strategies to attack the prey, which is decided as follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of the prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) represents the difference in the location vector of prey in each iteration. This difference is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selected to attack the prey.\nIn general, these probability values show that the prey\u2019s energy is dissipated and has low evading energy. In this case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next position of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\n1,\nDiagnostics 2023, 13, x FOR PE R REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f (i r) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next i erat on is denoted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 ar the present location vect rs of t e hawks. Fu the more, \u2134 is the random\nnumb r selected in the range of 0 and 1, and u , l ar the upper bound and lower bound, respectively. Th average location of hawks (\ud835\udd4f (iter) can be estimated from the following expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Explorati n to Exploitation Next, the algorithm transforms the state from explorati n to exploitatio . In this\ntransformation, th energy of th prey i dissipated due to evading behavior. Th energy level of th prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initi l stat energy of th prey and t is the maxi um i eration. By varying he t dency of E , the state of th prey can be ju ged.\nPhase 3: Exploitation After judging the state of the prey, the Harris hawks attack the selected prey. In\npractice, th prey changes the evading behavior, fr quently changing the attacking behavior. Fou strategies are cons ructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besiege and hard besieg ar the basic strategies o attack th prey, wh ch is cided as follows: If E \u2265 0.5, then a soft besiege occurs,\nand if E < 0.5, then a hard besiege occurs. Soft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks. This soft besiege attacking strategy is mo eled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of th prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) repre ents the difference in the location vector of prey in each i eration. This differenc is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selec ed o attack th prey.\nIn general, these probability values show that th prey\u2019s energy dissipated and has low evadi g energy. In thi case, the p sition of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when th prey has suffici t energy to evade form the at-\ntack. This situat on is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next p sition of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s d ve is formulated as follows:\n2,\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 \ud835\udcc7 |\ud835\udd4f (it r) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f (iter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next iteration is denoted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the present location vectors of the hawks. Furthermore, \u2134 is the random\nnumber selected in the range of 0 and 1, and u , l are the upper bound and lower bound, respectively. The average location of hawks (\ud835\udd4f (iter) can be estimated from the following expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Exploration to Exploitation Next, the algorithm transforms the state from exploration to exploitation. In this\ntransformation, the energy of the prey is dissipated due to evading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initial state energy of the prey and t is the maximum iteration. By varying the tendency of E , the state of the prey can be judged.\nPhase 3: Exploitation After judging the state of the prey, the Harris hawks attack the selected prey. In\npractice, the prey changes the evading behavior, frequently changing the attacking behavior. Four strategies are constructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besiege and hard besiege are the basic strategies to attack the prey, which is decided as follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of the prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) represents the difference in the location vector of prey in each iteration. This difference is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selected to attack the pr y.\nIn general, these probability values show that the prey\u2019s energy is dissipated and has low evading energy. In this case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, he next position of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as f llows:\n3,\nDiagnostics 2023, 13, x FOR PE R REVIEW 1 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(it r)| if \u2134 \u2265 0.5\ud835\udd4f (iter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next iteration is d noted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 ar th present location vect rs of the hawks. Fu the more, \u2134 is the random\nnumb r selected in the range of 0 and 1, and u , l ar the upper bound and low r bound, respectively. Th v rage location of hawks (\ud835\udd4f (iter) can be estimated from th following xpression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Explorati n to Exploitation Next, the algorithm transforms the state from explorati n to exploitation. In this\ntransformation, th energy of th prey is dissipated du to evading behavior. Th en rgy evel of th prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initi l stat energy of th prey and t is the maximum iteration. By varying the te dency of E , the state of th prey can be ju ged.\nPhase 3: Exploitation After judging the state of th prey, the Harris hawks attack the selected prey. In\npractic , th prey changes the evading behavior, frequently changing the attack ng behavior. Four strategies are cons ructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besiege and hard besieg ar the basic strategies to attack th prey, which is cided as follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is mo eled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of th prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) repre ents the difference in the location vector of prey in each iteration. This differenc is estimated by using the following xpression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selec ed o attack th pr y.\nI general, these probability values show that th prey\u2019s energy i dissipated and has low evadi g energy. In this cas , the p sition of Harris hawks is up ated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rap d Dives This strategy is selected when th prey has suffici t energy to evade form the at-\ntack. This situat on is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next p sition of the hawks is up ated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\n4 are the p esent l i v ctors f the awks. Fu t rmor ,\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\nThis phase relies on waiti g, searching, d tecting prey. In every step, each Har-\nris hawk is considered as the alternative solution. Based on the fittest solution, the posi-\ntion for each Harris hawk is updated as follows:\n\ud835\udd4f(iter + 1) = { \ud835\udd4fra d(it r) \u2212 \ud835\udcc71|\ud835\udd4fra d(it r) \u2212 2\ud835\udcc72\ud835\udd4f(iter)| if \u2134 \u2265 0.5\n\ud835\udd4fp(it r) \u2212 \ud835\udd4fa(iter) \u2212 \ud835\udcc73(l + \ud835\udcc74(ub \u2212 lb)) if \u2134 < 0.5 (5)\nTh locatio of the hawks in the next iteration is d not d as \ud835\udd4f(iter + 1) and \ud835\udcc71, \ud835\udcc72,\n\ud835\udcc73, \ud835\udcc74 are the present location vec ors of the hawks. Furthermor , \u2134 is the random number selected in the range f 0 and 1, a ub, lb ar the upper bound and lower bound, respectively. The av rage location hawks (\ud835\udd4fa(ite ) can be estimated from the following expression:\n\ud835\udd4fa(iter) = 1\nPS \u2211 \ud835\udd4fi(iter)\nPS\ni=1\n(6)\nPhase 2: Transformation from Exploration to Exploit ti n\nNex , th algorithm transforms the st e from exploration to expl itation. In this\ntran formation, he energy of the prey is dissipat d due to evading behavior. The nergy\nlevel of the prey is (Ep), which is expressed as follows:\nEp = 2Eo 1 \u2212 iter\nTm ) (7)\nHere, E0 is the initial state energy of the prey and tm is the maximum itera i n. B\nvarying the t dency of E0, the state of the prey c n be judged.\nPhase 3: Exploitation\nAft judging the state of t pr y, the H rr s hawks attack the select d pr y. In\npractice, the pr y changes the evading behavior, f equently changing the attacking be-\nhavior. Four strategies are constructed in the H2ORSS algorithm for attacking pr y\nbas d on vading behavio . Here, soft besi e and ard besiege are th basic strategie\nt attack the prey, which is decided as follows: If |Ep| \u2265 0.5, then soft besi ge occurs, and if |Ep| < 0.5, then a hard besiege occurs.\nSoft Besiege\nThis attacking strategy is selected w en Ep \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is odeled as follows:\n\ud835\udd4f(iter + 1 = \u2206\ud835\udd4f(iter) \u2212 Ep|\ud835\udd09\ud835\udd4fp(iter \u2212 \ud835\udd4f(iter))| (8)\nHere, \ud835\udd09 is th jump intensity of the prey during the evading process, and it i giv-\nn as \ud835\udd09 = 2(1 \u2212 \ud835\udcc75) and \u2206\ud835\udd4f(it r) repr sents th difference in the location vector of\nprey in each iteration. This differe ce is estimated by using the following expression:\n\u2206\ud835\udd4f(iter) = \ud835\udd4fp(iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege\nIf |Ep| < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besi g stra egy is selected to ttack the prey.\nIn general, t ese probability value show that t prey\u2019s energy is dis ipat d and has\nlow evading ene gy. In this c s , th posi ion f Harris hawks is updated by the follow-\ning equation:\n\ud835\udd4f(iter + 1) = \ud835\udd4fp(iter) \u2212 Ep|\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives\nThis strategy is s l cted when the prey h s suff cient energy to ev de form the at-\ntack This situation is expl i ed as |Ep| \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this b h vior, the next position of the hawks is updated as follows:\n\ud835\udd1c = \ud835\udd4fp(iter) \u2212 Ep|\ud835\udd09\ud835\udd4fp(iter \u2212 \ud835\udd4f(iter))| (11)\nis the random number selected i t e range of 0 nd 1, and ub, lb are the pp r bound and lower b und, respectively. The average locati n of awks (X (it r) n be es imated fr m followi g expressi :\nXa(iter) = 1\nPS\nPS \u2211 i=1 Xi(iter) (6)\nPhase 2: Transformation from Exploration to Exploitation\nDiagnostics 2023, 13, 1001 12 of 25\nNext, the algorithm transforms the state from exploration to exploitation. In this transformation, the energy of the prey is dissipated due to evading behavior. The energy level of the prey is (Ep), which is expressed as follows:\nEp = 2Eo ( 1\u2212 iter\nTm\n) (7)\nHere, E0 is the initial state energy of the prey and tm is the maximum iteration. By varying the tendency of E0, the state of the prey can be judged.\nPhase 3: Exploitation After judging the state of the prey, the Harris hawks attack the selected prey. In\npractice, the prey changes the evading behavior, frequently changing the attacking behavior. Four strategies are constructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besiege and hard besiege are the basic strategies to attack the prey, which is decided as follows: If\n\u2223\u2223Ep\u2223\u2223 \u2265 0.5, then a soft besiege occurs, and if \u2223\u2223Ep\u2223\u2223 < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when Ep \u2265 0.5 and\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f (iter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next iteration is denoted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the present location vectors of the hawks. Furthermore, \u2134 is the random\nnumber selected in the range of 0 and 1, and u , l are the upper bound and lower bound, respectively. The average location of hawks (\ud835\udd4f (iter) can be estimated from the following expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Exploration to Exploitation Next, the algorithm transforms the state from exploration to exploitation. In this\ntransformation, the energy of the prey is dissipated due to evading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initial state energy of the prey and t is the maximum iteration. By varying the tendency of E , the state of the prey can be judged.\nPhase 3: Exploitation After judging the state of the prey, the Harris hawks attack the selected prey. In\npractice, the prey changes the evading behavior, frequently changing the attacking behavior. Four strategies are constructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besiege and hard besiege are the basic strategies to attack the prey, which is decided as follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of the prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) represents the difference in the location vector of prey in each iteration. This difference is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selected to attack the prey.\nIn general, these probability values show that the prey\u2019s energy is dissipated and has low evading energy. In this case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next position of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\n\u2265 0.5 by Harris hawks. This soft besiege attacking strategy is modeled as follows:\nX(iter + 1) = \u2206X(iter)\u2212 Ep \u2223\u2223FXp(iter\u2212X(iter))\u2223\u2223 (8)\nHere, F is the jump intensity of the prey during the evading process, and it is given as F = 2(1\u2212\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f (iter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next iteration is denoted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the present location vectors of the hawks. Furthermore, \u2134 is the random\nnumber selected in the range of 0 and 1, and u , l are the upper bound and lower bound, respectively. The average location of hawks (\ud835\udd4f (iter) c be estimated from the following expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Exploration to Exploitation Next, the algorithm transforms the state from exploration to exploitation. In this\ntransformation, the energy of the prey is dissipated due to evading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initial state energy of the prey and t is the maximum iteration. By varying the tendency of E , the state of the prey can be judged.\nPhase 3: Exploitation After judging the state of the prey, the Harris hawks attack the selected prey. In\npractice, the prey changes the evading behavior, frequently changing the attacking behavior. Four strategies are constructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besiege and hard besiege are the basic strategies to attack the prey, which is decided as follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of the prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) represents the difference in the location vector of prey in each iteration. This difference is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(i er) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selected to attack the prey.\nIn general, these probability values show that the prey\u2019s energy is dissipated and has low evading energy. In this case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next position of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\n5) and \u2206X(iter) represents the difference in the location vector of prey in each iteration. This difference is estimated by using the following expression:\n\u2206X(iter) = Xp(iter)\u2212X(iter) (9)\nHard Besiege If \u2223\u2223Ep\u2223\u2223 < 0.5 and\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f (iter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next iteration is denoted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the present location vectors of the hawks. Furthermore, \u2134 is the random\nnumber selected in the range of 0 and 1, and u , l are the upper bound and lower bound, respectively. The ave ge location f hawks (\ud835\udd4f (iter) can be estimated from the following expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Exploration to Exploitation Next, the algorithm transforms the state from exploration to exploitation. In this\ntransformation, the energy of the prey is dissipated due to evading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initial state energy of the prey and t is the maximu it ration. By varying the tendency of E , the state of the prey can be judged.\nPhase 3: Exploitation After judging the state of the prey, the Harris hawks attack the selected prey. I\npractice, the prey changes the evadi g behavior, frequently changing the attacking behavior. Four strategies are construct d in the H2ORSS algorithm for attacking pre based on evading behavior. Here, soft besiege and hard besiege are the basic strategies to attack the prey, which is decided as follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of the prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) represents the difference in the location ctor of prey in each iteration. This difference is estima ed by using the followi g ex ssion: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selected to attack the prey.\nIn general, these probability values show that the pre \u2019s energy is dissipat d and has low evading energy. In this case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next position of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\n\u2265 0.5, the hard besiege strategy is selected to attack the prey. In general, these probability values show that the prey\u2019s energy is dissipated and has low evading energy. In this case, the position of Harris hawks is updated by the following equation:\nX(iter + 1) = Xp(it r)\u2212 Ep|\u2206X(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the attack.\nThis situation is explained as \u2223\u2223Ep\u2223\u2223 \u2265 0.5 and\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f (iter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next iteration is denoted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the present l cation vectors of the hawks. Furthermore, \u2134 is the random\nnumber selected in he rang of 0 and 1, and u , l are the upper bound and lower bound, resp ct vely. The average locatio of hawks (\ud835\udd4f (it r) can be estimated from the following expre sion:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Exploration to Exploitation Next, the algorithm transforms the state from exploration to exploitation. In this\ntransformation, the energy of the prey is dissipated due to evading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 i rT ) (7)\nHere, E is the initial state energy of the prey and t is the maximum iteration. By varying the tendency of E , the state of the prey can be judged.\nPhase 3: Exploitation After ju ging the state of the prey, the Harris hawks attack the selected prey. In\npractice, the prey changes the evading behavior, frequently changing the attacking behavior. Four strategies are constructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besi ge and hard b siege are the basic strategies to attack the prey, which is deci ed s follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a ha d be iege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) H re, \ud835\udd09 is the jump intensity of the prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) represents the difference in the location vector of prey in each iteration. This difference is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besieg If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selected to attack the prey.\nIn general, these probability values show that the prey\u2019s energy is dissipated and has low evading energy. In this case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next position of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\n< 0.5. Based on this behav or, the next position of the hawks is updated as follows:\nY = Xp( ter)\u2212 Ep \u2223\u2223FXp(iter\u2212X(iter))\u2223\u2223 (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\nZ = Y+ B\u2217lf(d) (12)\nwhere B represents the random vector; lf(d) represents the levy flight with the dimension d. Thus, the next position is updated as follows:\n(iter + 1) = { Y if f(Y) < f(X(iter)) Z if f(Z) < f(X(iter)) (13)\nHard Besiege with Progressive Rapid Dives\nDiagnostics 2023, 13, 1001 13 of 25\nThis situation is defined as the prey has not sufficient energy to escape. This situation is formulated as \u2223\u2223Ep\u2223\u2223 < 0.5 and\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f (iter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next iteration is denoted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the present location vectors of the hawks. Furthermore, \u2134 is the random\nnumber selected in the range of 0 and 1, and u , l are the upper bound and lower bound, respectively. The average location of hawks (\ud835\udd4f (iter) can be estimated from the following expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Exploration to Exploitation Next, the algorithm transforms the state from exploration to exploitation. In this\ntransformation, the energy of the prey is dissipated due to evading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initial state energy of the prey and t is the maximum iteration. By varying the tendency of E , the state of the prey can be judged.\nPhase 3: Exploitation After judging the state of the prey, the Harris hawks attack the selected prey. In\npractice, the prey changes the evading behavior, frequently changing the attacking behavior. Four strategies are constructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besiege and hard besiege are the basic strategies to attack the prey, which is decided as follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of the prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) represents the difference in the location vector of prey in each iteration. This difference is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selected to attack the prey.\nIn general, these probability values show that the prey\u2019s energy is dissipated and has low evading energy. In this case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next position of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\n< 0.5. Th ule for this situation is formulated as follows:\nX(iter + 1) = { Y if f(Y) < f(X(iter)) Z if f(Z) < f(X(iter)) (14)\nHere, Y is estimated using the upcoming Equation,\nY = Xp(iter)\u2212 Ep \u2223\u2223FXp(iter\u2212Xa(iter)) (15)\nBased on the above rules, the position of each hawk is updated, and the optimal solution is derived over itera ion. Finally, the optimum threshold value was computed for the prediction of contrast values throughout the images. Algorithm 1 deals with Generalized Linear Model (GLM), which is used for regression and classification tasks, is one of the key algorithms in H2O. GLM is a versatile and effective modeling approach that can deal with different data kinds and distributions.\nAlgorithm 1 Pseudocode for H2O\nInput : PS, Maxite Output: Optimal Threshold\nBegin Initialize \u2192 hawks population Xi (C.U.i ); While (Stopping Condition Not Met) do Compute\u2192 fitness function For (Xi \u2208 XPS )do Update \u2192 Eo and F; Update \u2192 Ep using Equation (8); End For If ( Ep \u2265 1 )Then Update position using Equation (9); End If If ( Ep < 1 )Then If ( Diagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f (iter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next iteration is denoted as \ud835\udd4f(iter + 1) a d \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the present location vectors of the hawks. Furthermore, \u2134 is the random\nnumber selected in the range of 0 and 1, and u , l are the upper bound and lower bound, respectively. The average location of hawks (\ud835\udd4f (iter) can be estimated from the following expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Exploration to Exploitation Next, the algorithm transforms the state from exploration to exploitation. In this\ntransformation, the energy of the prey is dissipated due to vading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initial state energy of the prey and t is the maximum iteration. By varying the tendency of E , the state of the prey can be judged.\nPhase 3: Exploitation After judging the state of the prey, the Harris hawks attack the selected prey. In\npractice, the prey changes the evading behavior, frequently changing the attacking behavior. Four strategies are constructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besiege and hard besiege are the basic strategies to attack the prey, which is decided as follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of the prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) represents the difference in the location vector of prey in each iteration. This difference is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selected to attack the prey.\nIn general, these probability values show that the prey\u2019s energy is dissipated and has low evading energy. In this case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next position of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\n\u2265 0.5 && \u2223\u2223Ep\u2223\u2223\u2265 0.5 )\nUpdate\u2192 position using Equation (10); Else If (\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f (iter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next iteration is denoted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the present location vectors of the hawks. Furthermore, \u2134 is the random\nnumber selected in the range of 0 and 1, and u , l are the upper bound and lower bound, respectively. The average location of hawks (\ud835\udd4f (iter) can be estimated from the following expression:\n\ud835\udd4f (it ) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Exploration to Exploitation Next, the algorithm transforms the state from exploration to exploitation. In this\ntransformation, the energy of the prey is dissipated due to evading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initial state energy of the prey and t is the maximum iteration. By varying the tendency of E , the state of the prey can be judg d.\nPhase 3: Exploitati n After judging the state of the prey, the Harris hawks attack the selected prey. In\npractice, the prey changes the evading behavior, frequently changing the attacking behavior. Four strategies are constructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besiege and hard besiege are the basic strategies to attack the prey, which is decided as follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of the prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) represents the difference in the location vector of prey in each iteration. This difference is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selected to attack the prey.\nIn general, these probability values show that the prey\u2019s energy is dissipated and has low evading energy. In this case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next position of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\n\u2265 0.5 && \u2223\u2223Ep\u2223\u2223< 0.5 )Then\nUpdate\u2192 position using Equation (11); Else If (\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f ( ter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next iteration is denoted as (iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the present location vectors of the hawks. Furthermore, \u2134 is the random\nnumber selected in the range of 0 and 1, and u , l are the upper bound and lower bound, respectively. The average location of hawks (\ud835\udd4f (iter) can be estimated from the following expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Exploration to Exploitation Next, the algorithm transforms the tate from exploration to exploitatio . In this\ntransformation, the energy of the prey s dissipated due to evading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initial state energy of the prey and t is the maximum iteration. By varying the tendency of E , the state of the prey can be judged.\nPhase 3: Exploitation After judging the state of the prey, the Harris hawks attack the selected prey. In\npractice, the prey changes the evading behavior, frequently changing the attacking behavior. Four strategies are constructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besiege and hard besiege are the basic strategies to attack the prey, which is decided as follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of the prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) represents the difference in the location vector of prey in each iteration. This difference is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(it ) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selected to attack the prey.\nIn general, these probability values show that the prey\u2019s energy is dissipated and has low evading energy. In this case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(it r)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next position of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\n< 0.5 && \u2223\u2223Ep\u2223\u2223\u2265 0.5 )Then\nUpdate\u2192 position using Equation (12); Else If (\nDiagnostics 2023, 13, x FOR PEER REVIEW 12 of 27\n\ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 \ud835\udcc7 |\ud835\udd4f (iter) \u2212 2\ud835\udcc7 \ud835\udd4f(iter)| if \u2134 \u2265 0.5\ud835\udd4f ( ter) \u2212 \ud835\udd4f (iter) \u2212 \ud835\udcc7 l + \ud835\udcc7 (u \u2212 l ) if \u2134 < 0.5 (5) The location of the hawks in the next iteration is denoted as \ud835\udd4f(iter + 1) and \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 , \ud835\udcc7 are the present location v ctors of the hawks. Furthermore, \u2134 is the random\nnumber selected in the range of 0 and 1, and u , l are the upper bound and lower bound, respectively. The average location of hawks (\ud835\udd4f (iter) can be estimated from the following expression:\n\ud835\udd4f (iter) = 1PS \ud835\udd4f (iter) (6) Phase 2: Transformation from Exploration to Exploitation Next, the algorithm transforms the state from exploration to exploitation. In this\ntransformation, the energy of the prey is dissipated due to evading behavior. The energy level of the prey is (E ), which is expressed as follows: E = 2E (1 \u2212 iterT ) (7)\nHere, E is the initial state energy of the prey and t is the maximum iteration. By varying the tendency of E , the state of the prey can be judged.\nPhase 3: Exploitation After judging the state of the prey, the Harris hawks attack the selected prey. In\npractice, the prey changes the evading behavior, frequently changing the attacking behavior. Four strategies are constructed in the H2ORSS algorithm for attacking prey based on evading behavior. Here, soft besiege and hard besiege are the basic strategies to attack the prey, which is decided as follows: If E \u2265 0.5, then a soft besiege occurs, and if E < 0.5, then a hard besiege occurs.\nSoft Besiege This attacking strategy is selected when E \u2265 0.5 and \ud835\udcc7 \u2265 0.5 by Harris hawks.\nThis soft besiege attacking strategy is modeled as follows: \ud835\udd4f(iter + 1) = \u2206\ud835\udd4f(iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (8) Here, \ud835\udd09 is the jump intensity of the prey during the evading process, and it is giv-\nen as \ud835\udd09 = 2(1 \u2212 \ud835\udcc7 ) and \u2206\ud835\udd4f(iter) represents the difference in the location vector of prey in each iteration. This difference is estimated by using the following expression: \u2206\ud835\udd4f(iter) = \ud835\udd4f (iter) \u2212 \ud835\udd4f(iter) (9)\nHard Besiege If E < 0.5 and \ud835\udcc7 \u2265 0.5, the hard besiege strategy is selected to attack the prey.\nIn general, these probability values show that the prey\u2019s energy is dissipated and has low evading energy. In this case, the position of Harris hawks is updated by the following equation: \ud835\udd4f(iter + 1) = \ud835\udd4f (iter) \u2212 E |\u2206\ud835\udd4f(iter)| (10)\nSoft Besiege with Progressive Rapid Dives This strategy is selected when the prey has sufficient energy to evade form the at-\ntack. This situation is explained as E \u2265 0.5 and \ud835\udcc7 < 0.5. Based on this behavior, the next position of the hawks is updated as follows: \ud835\udd1c = \ud835\udd4f (iter) \u2212 E |\ud835\udd09\ud835\udd4f (iter \u2212 \ud835\udd4f(iter))| (11)\nAs this strategy involves progressive dives, the hawk\u2019s dive is formulated as follows:\n< 0.5 && \u2223\u2223Ep\u2223\u2223< 0.5 )Then\nUpdate\u2192 position using Equation (13); End If End If End While End\n4.2. Blood Vessel Segmentation\nBlo d vessels are important in computing the image intensity, edges, texture, and other analyses of image features. Analyzing the diagnosis over the segmented area increases the accuracy and precision rate of any disease. Hence, the optic disk is removed from the contrast-enhanced image, and th n t e blood vess ls are extracted using improved mask RCNN, i which ROI alignment is the first step that predicts the region of interest from the input image. In this work, pixel-wise oftmax was applied for accurate segmentation of blood vessels, which was better than the CNN, RNN, RCNN, and DCNN algorithms [39,40]. OPTICS clustering stands for ordering points to identify clustering structure. It is more similar to DBSCAN clustering. OPTICS algorithm includes two measurements, which are defined as follows,\nDiagnostics 2023, 13, 1001 14 of 25\n\u2022 Core distance: This represents the minimum values of the radius essential to classify the given point as a core point. If the considered point is not a core point, then its core distance is indeterminate. \u2022 Reachability distance: This is represented with respect to another cluster data point. The reachability distance between two points (x,y) is the highest of the core distance and then the Euclidean distance between the two points (x, y). The reachability distance is not defined if the y point is not a core point. Figure 3 represents the calculation of the reachability distance. The general procedure of M-OPTICS is defined as follows:\nDiagnostics 2023, 13, x FOR PEER REVIEW 14 of 27 4.2. Blood Vessel Segmentation Blood vessels are important in computing the image intensity, edges, texture, and\nother analyses of image features. Analyzing the diagnosis over the segmented area increases the accuracy and precision rate of any disease. Hence, the optic disk is removed from the contrast-enhanced image, and then the blood vessels are extracted using improved mask RCNN, in which ROI alignment is the first step that predicts the region of interest from the input image. In this work, pixel-wise softmax was applied for accurate segmentation of blood vessels, which was better than the CNN, RNN, RCNN, and DCNN algorithms [39,40]. OPTICS clustering stands for ordering points to identify clustering structure. It is more similar to DBSCAN clustering. OPTICS algorithm includes two measurements, which are defined as follows, \u2022 Core distance: This represents the minimum values of the radius essential to classify\nthe given point as a core point. If the considered p int is not a core point, then its core distance is indeterminate.\n\u2022 Reachability distance: This is represented with respect to another cluster data point. The reachability distance between two points (x,y) is the highest of the core distance and then the Euclidean distance between the two points (x, y). The reachability distance is not defined if the y point is not a core point. Figure 3 represents the calculation of the reachability distance. The general procedure of M-OPTICS is defined as follows:\nNext, the proposed M-OPTICS explanation is defined as follows: M-OPTICS considers three important conditions: maximum radius, distance, and number of cluster points including the core distance, core points, and reachability distance. In the M-OPTICS algorithm, the point P is known as the core point when the point is on MinPts. The reachability distance and core distance calculations are given as follows: CD(o) = \u221e , |o, \u03b5| < \ud835\udc40\ud835\udc56\ud835\udc5b\ud835\udc43\ud835\udc61\ud835\udc60MinPts \u2212 D(o), otherwise (16)\nFig re 3. (a) P I S clustering algorith . ( ) eachability istance.\nt e proposed M-OPTICS explan tion is defined as follows: M-OPTICS considers thr e important conditions: maximum radius, distance, and number of cluster points including the core distance, core points, and reach bility dist nce. In the M-OPTICS algorithm, the point P is known as the core point whe the point is o MinPts. The reachability distance and core distance calcul tions are giv n as follows:\nCD(o) = {\n\u221e , |o, \u03b5| < MinPts MinPts\u2212D(o), otherwise (16)\nR.D.(p, o) = max(CD(o), D(p, o)) (17)\nwhere p represents the object and o represents the center point. The core distance represents the lowest value, which is the radius. From the radius, the core point is different. RD represents the reachability distance, which is estimated as the highest core distance, and \u03b5 represents the radius of the data. The reachability distance data are clustered separately. The data similarities were measured by Jaccard similarity, which calculates the similarity between a finite set of samples. The calculation of the Jaccard similarity is defined as follows:\nJD = 1\u2212 J\u00b5(A, B) (18)\nJ\u00b5(A, B) = \u00b5(A\u2229 B) \u00b5(A\u222a B) (19)\nDiagnostics 2023, 13, 1001 15 of 25\nwhere A and B represent the two points obtained from the blood vessels. The CNN-based ensemble learning model was incorporated due to two major unique features: shared weights and local connections. The extraction of features from the input data using convolutional layers and determining the relationship between the obtained features using the pooling layers was implemented, which can be formulated as:\nalq = V\n\u2211 p=1\nal\u22121p \u2217Jlpq + ylq (20)\nwhere Jlpq, ylq denote the trainable parameters, and V denotes the input features. The output provided by the nonlinear layer is computed as:\nxd = f ( vd )\n(21)\nwhere function f ( vd )\ndenotes the output of the rectified linear unit. The performance of the model can be further improved by executing batch normalization. The dataset comprising of fused images of R dimensions comprised of a T number of training samples can be denoted as H = {(hi, cli)|1 \u2264 i \u2264 T}, where the classes are cli \u2208 Cl = {1, 2, . . . , M} and the maximum count of classes is denoted as M. In the ensemble model, each model\u2019s training is performed randomly. The input of each CNN will be H\u0303 = {( h\u0303i, cli\n)\u2223\u2223\u22231 \u2264 i \u2264 T}, which comprises r \u201cR feature subspaces that are randomly selected.\nFor instance, i and j are two identical features with dimension d, and for that similarity\nfunction sim(i,j)pd , which is computed by:\nsim(i,j)pd = vectori \u00d7 vectorj\n\u2016vectori\u2016 \u00d7 \u2016vectorj\u2016 (22)\nFor a different number of CNN layers and the operations involved in this study, computational complexity was evaluated, which is described as follows:\nPvs(i) = (1\u2212 \u00b5)\u00d7O(N) + \u00b5\u00d7O(N) = O(N) (23)\nwhere O(N) represents the sum of iterations for performing the feature extraction and classification \u00b5 \u2208 [0, 1] and then S.S.upd with respect to the fx as follows:\nS.S.upd = arg ( maxip\u03b5idxi ( fx ( PVsn ))) = O(N) (24)\nwhere O(N) represents the sum of iterations for S.S.upd, which provides the near optimum feature matches from the trained set. Once the features are extracted, they are then updated by the presented method.\nThe output obtained from each CNN is denoted as x = CNN ( H\u0303 )\n; the collective outputs obtained from the individual CNN are denoted as X = {x1, x2, . . . , xL}, where L denotes the ensemble\u2019s size, and the global output of the ensemble model is obtained by using weighted averaging of the output of the individual CNN. The weighted average of the output of the individual CNN is formulated as:\nG = \u2211Tj=1 wjsj\nT with wj \u2265 0\nT\n\u2211 j=1 wj = 1 (25)\nwhere sj denotes the score and wj denotes the weight of the j\u2212 th(j = 1, 2, 3) model.\nDiagnostics 2023, 13, 1001 16 of 25\nThe classifier diversity between any two CNN models is computed as:\nCD(i, j) = Tw NT\n(26)\nwhere NT and Tw denote the total number of test samples and the difference of results caused by the samples. The diversity of the ensemble model is computed as the average of the classifier diversities, which can be formulated as:\nED = \u2211Mi=1 \u2211 M j=1 CD(i, j)\nL , i 6= j (27)\nwhere ED denotes the diversity of the ensemble model, and CD denotes the classifier diversity. The classification output achieved from the weighted averaging of the individual CNN models possessed increased accuracy than the individual CNN models. Figure 4 presented the SMDTR-CNN-based land cover classification for identifying normal, DR and DME. Diagnostics 2023, 13, x FOR PEER REVIEW 17 of 27\nFigure 4. SMDTR-CNN-based land cover classification.\nTable 1 addresses the ensemble deep learning model below with their filters, filter size, stride, padding, and output image size. A CNN\u2019s fundamental building block is a convolutional layer and includes a series of filters, the parameters of which must be learned throughout the training process. The filters are often smaller in size than the real image. The pooling layer\u2019s function is to lower the spatial size of the representation in order to reduce the number of parameters and calculations in the network; it operates independently on each feature map (channels). Maximum pooling and average pooling are the two types of pooling layers. Max pooling is a procedure commonly used for the individual CNN convolution layers listed below when they are added to a model. Maxpooling minimizes the picture dimensionality by lowering the number of pixels in the preceding convolution layer\u2019s output. The rectified linear activation unit (ReLU) is one of the few milestones in the deep learning revolution. It is basic, but it is superior to the activation features of its predecessors such as sigmoid or tanh.\nFigure 4. S DTR-C -based land cover classification.\nTable 1 addresses the ensemble deep learning model below with their filters, filter size, stride, padding, and output image size. A CNN\u2019s fundamental building block is a convolutional layer and includes a series of filters, the parameters of which must be learned throughout the training process. The filters are often smaller in size than the real image. The pooling layer\u2019s function is to lower the spatial size of the representation in order to reduce the number of parameters and calculations in the network; it operates independently on each feature map (channels). Maximum pooling and average pooling are the two types\nDiagnostics 2023, 13, 1001 17 of 25\nof pooling layers. Max pooling is a procedure commonly used for the individual CNN convolution layers listed below when they are added to a model. Maxpooling minimizes the picture dimensionality by lowering the number of pixels in the preceding convolution layer\u2019s output. The rectified linear activation unit (ReLU) is one of the few milestones in the deep learning revolution. It is basic, but it is superior to the activation features of its predecessors such as sigmoid or tanh.\nThe E-CNN performance was estimated with the accuracy, precision, recall, F-score, error rate, and computational time.\n5.1. Accuracy\nAccuracy is defined as the ratio of the received input image inventive classification scheme by the assessed classification scheme, which can be formulated as:\nA = T1 + T2\nT1 + T2 +F1 +F2 (28)\nFrom the above equation, F1,F2 denote the false positive and false negative values, respectively; and T1, T2 denote the true positive and true negative values, respectively. Accuracy is the significant metric for calculating the performance of the system.\n5.2. Precision\nPrecision is computed by the ratio of excluding the significant classification result from the overall classification outcome. The meticulousness of the system can be measured using precision, which can be formulated as:\nP = T2T1 +F1 (29)\nDiagnostics 2023, 13, 1001 18 of 25\n5.3. Recall\nThe recall is defined as the ratio of excluding the same classification result to the recovered results. The recall is used for measuring the comprehensiveness of the system, which can be formulated as:\nR = T1T1 +F2 (30)\n5.4. F-Score\nThe F-score is computed by using the parameters of recall and precision by jointly assessing them. The results accuracy can be computed using F-score, which can be formulated as:\nFS = 2 \u2217 P \u2217 R P +R (31)\n5.5. Computation Time\nComputation time is the amount of time needed to complete a computational operation. Computation time is calculated by calculating the time elapsed between the classification completion and computation. The system\u2019s efficacy is assessed in terms of computation time. It is appreciated whether the study obtained a greater accuracy with better precision of outcome in a shorter computing period.\n5.6. Error Rate\nIn Table 2, the results analysis of all models is furnished in the numerical form for better understanding. The error rate is defined as the ratio of errors in the sample to the overall samples. The error rate is used to determine the system\u2019s performance. A good system has a much lower error rate, which can be formulated as:\nError Rate = No of Errors\nNo of Samples (32)\nAs can be seen in Figures 5\u201310, we evaluated the proposed E-CNN to various stateof-the-art approaches such as SVM, KNN, enhanced CNN, and deep learning (DL). When analyzing performance, the optic disk (OD) is eliminated because it is a non-lesion area. The numerical findings suggest that our proposed E-CNN was superior. E-CNN had a mean\nDiagnostics 2023, 13, 1001 19 of 25\naccuracy of 99.84 percent, which was 4.38 percent greater than the benchmark. Although its effectiveness was equivalent to that of the Messidor database, it performed poorly in blood vessel segments. Diagnostics 2023, 13, x FOR PEER REVIEW 20 of 27\n(a)\n(b)\nFigure 5. Detection accuracy (a). IDRiR and (b). Messidor.\n(a)\n50 60 70 80 90\n100\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00D\net ec\ntio n\nA cc\nur ac\ny (%\n)\nNumber of Samples\nSVM KNN Improved CNN DL Ensemble CNN\n50 60 70 80 90\n100\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00D\net ec\ntio n\nA cc\nur ac\ny (%\n)\nNumber of Samples\nSVM KNN Improved CNN DL Ensemble CNN\n50\n60\n70\n80\n90\n100\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00\nPr ec\nisi on\n(% )\nNo of samples\nSVM KNN Improved CNN DL Ensemble CNN\nFigure 5. Detection accuracy (a). IDRiR and (b). Messidor.\nDiagnostics 2023, 13, x FOR PEER REVIEW 20 of 27\n(a)\n(b)\nFigure 5. Detection accuracy (a). IDRiR and (b). Messidor.\n(a)\n50 60 70 80 90\n100\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00D\net ec\ntio n\nA cc\nur ac\ny (%\n)\nNumber of Samples\nSVM KNN Improved CNN DL Ensemble CNN\n50 60 70 80 90\n100\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00D\net ec\ntio n\nA cc\nur ac\ny (%\n)\nNumber of Samples\nSVM KNN Improved CNN DL Ensemble CNN\n50\n60\n70\n80\n90\n100\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00\nPr ec\nisi on\n(% )\nNo of samples\nSVM KNN Improved CNN DL Ensemble CNN\nFigure 6. Cont.\nDiagnostics 2023, 13, 1001 20 of 25Diagnostics 2023, 13, x FOR PEER REVIEW 21 of 27\n(b)\nFigure 6. Precision. (a) IDRiR and (b) Messidor.\n(a)\n(b)\nFigure 7. Recall. (a) IDRiR and (b) Messidor.\n50\n60\n70\n80\n90\n100\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00\nPr ec\nisi on\n(% )\nNo of samples\nSVM KNN Improved CNN DL Ensemble CNN\n50\n70\n90\n110\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00\nRe ca\nll (%\n)\nNo of Samples\nSVM KNN Improved CNN DL Ensemble CNN\n50\n70\n90\n110\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00\nRe ca\nll (%\n)\nNo of Samples\nSVM KNN Improved CNN DL Ensemble CNN\nFigure 6. Precision. (a) IDRiR and (b) Messidor.\nDiagnostics 2023, 13, x FOR PEER REVIEW 21 of 27\n(b)\nFigure 6. Precision. (a) IDRiR and (b) Messidor.\n(a)\n(b)\nFigure 7. Recall. (a) IDRiR and (b) Messidor.\n50\n60\n70\n80\n90\n100\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00\nPr ec\nisi on\n(% )\nNo of samples\nSVM KNN Improved CNN DL Ensemble CNN\n50\n70\n90\n110\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00\nRe ca\nll (%\n)\nNo of Samples\nSVM KNN Improved CNN DL Ensemble CNN\n50\n70\n90\n110\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00\nRe ca\nll (%\n)\nNo of Samples\nSVM KNN Improved CNN DL Ensemble CNN\nFigure 7. Recall. (a) IDRiR and (b) Messidor.\nDiagnostics 2023, 13, 1001 21 of 25Diagnostics 2023, 13, x FOR PEER REVIEW 22 of 27\n(a)\n(b)\nFigure 8. F-Score. (a) IDRiR and (b) Messidor.\n(a)\n50\n70\n90\n110\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00\nFsc\nor e\n(% )\nNo of Samples\nSVM KNN Improved CNN DL Ensemble CNN\n50\n70\n90\n110\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00\nFsc\nor e\n(% )\nNo of Samples\nSVM KNN Improved CNN DL Ensemble CNN\n0\n5\n10\n15\n20\n10 200 300 400 500 600 700 800 900 1000\nCo m\npu ta\ntio n\nTi m\ne (s\n)\nNo of Samples SVM KNN Improved CNN DL Ensemble CNN\nFigure 8. F-Score. (a) IDRiR and (b) Messidor.\nDiagnostics 2023, 13, x FOR PEER REVIEW 22 of 27\n(a)\n(b)\nFigure 8. F-Score. (a) IDRiR and (b) Messidor.\n(a)\n50\n70\n90\n110\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00\nFsc\nor e\n(% )\nNo of Samples\nSVM KNN Improved CNN DL Ensemble CNN\n50\n70\n90\n110\n10 20 0 30 0 40 0 50 0 60 0 70 0 80 0 90 0 10 00\nFsc\nor e\n(% )\nNo of Samples\nSVM KNN Improved CNN DL Ensemble CNN\n0\n5\n10\n15\n20\n10 200 300 400 500 600 700 800 900 1000\nCo m\npu ta\ntio n\nTi m\ne (s\n)\nNo of Samples SVM KNN Improv d C N DL Ensemble CNN\nFigure 9. Cont.\nDiagnostics 2023, 13, 1001 22 of 25Diagnostics 2023, 13, x FOR PEER REVIEW 23 of 27\n(b)\nFigure 9. Computation time. (a). IDRiR and (b) Messidor.\n(a)\n(b)\nFigure 10. Error Rate. (a) IDRiR and (b) Messidor.\nFurthermore, as shown in Figures 5\u201310, the accuracy, precision, recall, f-score, computational time, and error rate produced by E-CNN were much better than those acquired by other approaches. The difficulty of misclassification was exacerbated in the\n0\n5\n10\n15\n20\n10 200 300 400 500 600 700 800 900 1000Co m\npu ta\ntio n\nTi m\ne (s\n)\nNo of Samples SVM KNN Improved CNN DL\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n1\n10 200 300 400 500 600 700 800 900 1000\nEr ro\nr R at\ne\nNo of Samples SVM KNN Improved CNN DL Ensemble CNN\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n1\n10 200 300 400 500 600 700 800 900 1000\nEr ro\nr R at\ne\nNo of Samples SVM KNN Improved CNN DL Ensemble CNN\nFigure 9. Co putation ti e. (a). I RiR and (b) essidor.\nDiagnostics 2023, 13, x FOR PEER REVIEW 23 of 27\n(b)\nFigure 9. Computation time. (a). IDRiR and (b) Messidor.\n(a)\n(b)\nFigure 10. Error Rate. (a) IDRiR and (b) Messidor.\nFurthermore, as shown in Figures 5\u201310, the accuracy, precision, recall, f-score, computational time, and error rate produced by E-CNN were much better than those acquired by other approaches. The difficulty of misclassification was exacerbated in the\n0\n5\n10\n15\n20\n10 200 300 400 500 600 700 800 900 1000Co m\npu ta\ntio n\nTi m\ne (s\n)\nNo of Samples SVM KNN Improved CNN DL\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n1\n10 200 300 400 500 600 700 800 900 1000\nEr ro\nr R at\ne\nNo of Samples SVM KNN Improved CNN DL Ensemble CNN\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n1\n10 200 300 400 500 600 700 800 900 1000\nEr ro\nr R at\ne\nNo of Samples SVM KNN Improved CNN DL Ensemble CNN\nFigure 10. Error Rate. (a) IDRiR and (b) Messidor.\nFurthermore, as in Figures 5\u201310, the accuracy, precision, recall, f-score, computational time, and rror rate p oduced by E-CNN were much b tter than those acquired by\nDiagnostics 2023, 13, 1001 23 of 25\nother approaches. The difficulty of misclassification was exacerbated in the lesions DR and DME due to fewer samples; however, our proposed technique could still meet this obstacle. The quantitative class labels are also shown in Figure 5 to further illustrate the suggested strategy\u2019s efficiency. In the DR lesion segmentation challenge, one can see that the E-CNN was much more accurate and robust. We also performed an ablation experiment to prove the accuracy of the proposed E-CNN. The SVM is referred to as the baseline approach for convenience. The suggested strategy has been demonstrated to generate significant improvements over the baseline regarding four targets, as shown in Figures 5\u201310. The addition of preprocessing also improved the performance. The mean precision improved by 3.83 percent in comparison to the benchmark. Our proposed technology, in particular, can be simply integrated into other encoder\u2013decoder networks, which we wish to conduct soon. Additionally, the proposed E-CNN achieved the greatest accuracy values in DR and DME diagnosis, demonstrating the efficacy of our proposed method. In this work, ensemble convolutional neural networks (ECNNs) were used to classify images of diabetic retinopathy. A recently developed meta-heuristic method, the Harris hawks optimization (HHO) algorithm, was used to optimize the ECNN hyperparameters. Then, the Harris hawks optimization technique was used to improve the feature extraction and classification processes to obtain the most significant features. Compared to previous systems, the deep learning model provides extremely satisfactory results regarding the specificity, precision, accuracy, and recall.\n6. Conclusions\nAll of the studies on the DR classification issue can be divided into two groups. The first is a binary DR diagnosis in which the individual possesses or does not. The problem with this technique is that after we realize a person has DR, we cannot tell how serious the disease is. Multi-class identification is the answer to this challenge. As previously mentioned, we classified DR into five classes or phases using multi-class classification. However, almost all of the associated studies, particularly in the early stages of DR, have been unable to appropriately define every one of the stages of DR. It is critical to identify the DR at a very early stage to treat the disease, as treating the disease at a much later date is challenging and can result in death. To our understanding, no other study has employed the IDRiR and Messidor databases to identify the milder phases of DR that we used in our study. Our approach outperformed the present advancements in detecting the mild stage. Furthermore, no one else has demonstrated the impact of a balanced dataset in previous research. The unbalanced dataset may have caused the classification accuracy to be skewed. The network can be trained on features correctly when samples in the classes are evenly distributed such as in a balanced dataset; however, in the case of asymmetrical distributions, the network performs for heavily tested classes. Furthermore, the present CNN architectures for DR identification do not consider the impact of varied hyperparameter tweaking (meta-learning) as well as its consequences. In the future, we plan to use some other deep-learning techniques for DR and DME disease classification. Recently, CNN-based methodology has been considered to learn features for classification. However, tuning non-trainable hyperparameters for such networks is manual, intuitive, and non-trivial. In the future, a technique based on DR and DME will be proposed to adjust the CNN architecture parameters. The convolution and pooling layer number, the kernel number, and the kernel size of the convolution layer are determined by the upcoming proposed technique. Therefore, the number of untrainable hyperparameters can be reduced. There are some challenges in adapting DR and DME to a CNN. Based on the dimension of the input image, the maximum and minimum sizes of the kernel must be specified for clear classification.\nAuthor Contributions: Software, S.S.; Validation, M.S.; Formal analysis, S.R.; Investigation, S.I.; Writing\u2014review & editing, J.-H.C.; Data curation, N.A.A.; Resources, A.E.; Writing\u2014original draft, S.K.R. All authors have read and agreed to the published version of the manuscript.\nDiagnostics 2023, 13, 1001 24 of 25\nFunding: This work was supported by \u201cHuman Resources Program in Energy Technology\u201d of the Korea Institute of Energy Technology Evaluation and Planning (KETEP), granted financial resources from the Ministry of Trade, Industry & Energy, Republic of Korea. (No. 20204010600090). The funding of this work was provided by Princess Nourah bint Abdulrahman University Researchers Supporting Project number (PNURSP2023R410), Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia.\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability Statement: For this research work, datasets were taken from the kaggle repository site, available online at kaggle.com/datasets/mariaherrerot/idrid-dataset and https://www.kaggle. com/datasets/google-brain/messidor2-dr-grades (19 October 2022).\nAcknowledgments: The authors are thankful to Princess Nourah bint Abdulrahman University Researchers Supporting Project number (PNURSP2023R410), Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia.\nConflicts of Interest: The authors declare no conflict of interest.\nReferences 1. Thiagarajan, A.S.; Adikesavan, J.; Balachandran, S.; Ramamoorthy, B.G. Diabetic Retinopathy Detection using Deep Learning Techniques. J. Comput. Sci. 2020, 16, 305\u2013313. [CrossRef] 2. Skariah, S.M.; Arun, K.S. A Deep Learning Based Approach for Automated Diabetic Retinopathy Detection and Grading. In\nProceedings of the 2021 4th Biennial International Conference on Nascent Technologies in Engineering (ICNTE), Navi Mumbai, India, 15\u201316 January 2021; pp. 1\u20136.\n3. Chowdhury, P.; Islam, M.R.; Based, M.A.; Chowdhury, P. Transfer Learning Approach for Diabetic Retinopathy Detection using Efficient Network with 2 Phase Training. In Proceedings of the 2021 6th International Conference for Convergence in Technology (I2CT), Maharashtra, India, 2\u20134 April 2021; pp. 1\u20136. 4. Feng, L.; Wang, Y.; Xu, T.; Dong, L.; Yan, L.; Jiang, M.; Zhang, X.; Jiang, H.; Wu, Z.; Zou, H. Deep learning-based automated detection for diabetic retinopathy and diabetic macular oedema in retinal fundus photographs. Eye 2022, 36, 1433\u20131441. 5. Bhardwaj, C.; Jain, S.; Sood, M. Deep Learning\u2013Based Diabetic Retinopathy Severity Grading System Employing Quadrant Ensemble Model. J. Digit. Imaging 2021, 34, 440\u2013457. [CrossRef] [PubMed] 6. Snehil, K. Diabetic Retinopathy Diagnosis with Ensemble Deep-Learning. In Proceedings of the 3rd International Conference on Vision, Image and Signal Processing, Vancouver, BC, Canada, 26\u201328 August 2019; pp. 1\u20135. 7. Orlando, J.I.; Prokofyeva, E.; Fresno, M.D.; Blaschko, M.B. Learning to Detect Red Lesions in Fundus Photographs: An Ensemble Approach based on Deep Learning. arXiv 2017, arXiv:abs/1706.03008. 8. Yan, Y.; Gong, J.; Liu, Y. A Novel Deep Learning Method for Red Lesions Detection Using Hybrid Feature. In Proceedings of the 2019 Chinese Control And Decision Conference (CCDC), Nanchang, China, 3\u20135 June 2019; pp. 2287\u20132292. 9. Safwan, M.; Chennamsetty, S.S.; Kori, A.; Alex, V.; Krishnamurthi, G. Classification of Breast Cancer and Grading of Diabetic Retinopathy & Macular Edema using Ensemble of Pre-Trained Convolutional Neural Networks. In Lecture Notes in Computer Science Book Series; Spring: Berlin/Heidelberg, Germany, 2018; Volume 10882. 10. Harangi, B.; T\u00f3th, J.; Hajdu, A. Fusion of Deep Convolutional Neural Networks for Microaneurysm Detection in Color Fundus Images. In Proceedings of the 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Honolulu, HI, USA, 18\u201321 July 2018; pp. 3705\u20133708. 11. Ramchandre, S.; Patil, B.; Pharande, S.; Javali, K.; Pande, H. A Deep Learning Approach for Diabetic Retinopathy detection using Transfer Learning. In Proceedings of the 2020 IEEE International Conference for Innovation in Technology (INOCON), Bangalore, India, 6\u20138 November 2020; pp. 1\u20135. 12. Shorfuzzaman, M.; Hossain, M.S.; El Saddik, A. An Explainable Deep Learning Ensemble Model for Robust Diagnosis of Diabetic Retinopathy Grading. ACM Trans. Multimed. Comput. Commun. Appl. 2021, 17, 1\u201324. [CrossRef] 13. Rajkumar, R.S.; Jagathishkumar, T.; Ragul, D.; Selvarani, A.G. Transfer Learning Approach for Diabetic Retinopathy Detection using Residual Network. In Proceedings of the 2021 6th International Conference on Inventive Computation Technologies (ICICT), Coimbatore, India, 20\u201322 January 2021; pp. 1189\u20131193. 14. Al-Smadi, M.; Hammad, M.M.; Baker, Q.B.; Al-Zboon, S.A. A transfer learning with deep neural network approach for diabetic retinopathy classification. Int. J. Electr. Comput. Eng. 2021, 11, 3492\u20133501. [CrossRef] 15. Dela Pava, M.; R\u2019ios, H.; Rodr\u2019iguez, F.J.; Perdomo, O.J.; Gonz\u2019alez, F.A. A deep learning model for classification of diabetic Retinopathy in eye fundus images based on retinal lesion detection. In Proceedings of the Symposium on Medical Information Processing and Analysis, Mexico City, Mexico, 17\u201319 November 2021. 16. Chetoui, M.; Akhloufi, M.A. Explainable end-to-end deep Learning for diabetic retinopathy detection across multiple datasets. J. Med. Imaging 2020, 7, 044503. [CrossRef]\nDiagnostics 2023, 13, 1001 25 of 25\n17. Mohamed, E.; Elmohsen, M.N.; Basha, T.A. Improved Automatic Grading of Diabetic Retinopathy Using Deep Learning and Principal Component Analysis. In Proceedings of the 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), Scotland, UK, 1\u20135 November 2021; pp. 3898\u20133901. 18. Khan, A.A.; Kulkarni, N.; Kumar, A.; Kamat, A. D-CNN and Image Processing Based Approach for Diabetic Retinopathy Classification. In Advances in Intelligent Systems and Computing; Springer: Berlin/Heidelberg, Germany, 2021. 19. Han, Y.; Tao, M.; Zheng, X. Ensembling Learning for Automated Detection of Diabetic Retinopathy. In Proceedings of 2021 International Conference on Medical Imaging and Computer-Aided Diagnosis (MICAD 2021) Medical Imaging and Computer-Aided Diagnosis; Springer: Singapore, 2022. 20. Afrin, R.; Shill, P.C. Automatic Lesions Detection and Classification of Diabetic Retinopathy Using Fuzzy Logic. In Proceedings of the 2019 International Conference on Robotics, Electrical and Input Image Processing Techniques (ICREST), Dhaka, Bangladesh, 10\u201312 January 2019; pp. 527\u2013532. 21. Chaudhary, S.; Ramya, H.R. Detection of Diabetic Retinopathy using Machine Learning Algorithm. In Proceedings of the 2020 IEEE International Conference for Innovation in Technology (INOCON), Bangaluru, India, 6\u20138 November 2020; pp. 1\u20135. 22. Ali, A.; Qadri, S.; Mashwani, W.K.; Kumam, W.; Kumam, P.; Naeem, S.; G\u00f6ktas, A.; Jamal, F.; Chesneau, C.; Anam, S.; et al. Machine Learning Based Automated Segmentation and Hybrid Feature Analysis for Diabetic Retinopathy Classification Using Fundus Image. Entropy 2020, 22, 567. [CrossRef] 23. Kumar, K.; Megha, P.; Meenakshy, K. Diabetic Retinopathy Detection & Classification Techniques: A Review. Int. J. Sci. Technol. Res. 2020, 9, 1621\u20131628. 24. Ammal, M.; Gladis, D. Perception of hard exudates using Fuzzy Optimization and Discrete Wavelet Transformation in Fundus Image. In Proceedings of the 2021 Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV), Tirunelveli, India, 4\u20136 February 2021; pp. 1034\u20131039. 25. Tala, E.B.; Thabet, B. Diabetic Retinopathy Recognition System based on GLDM Features and Feed Forward Neural Network Classifier. Al-Qadisiyah J. Pure Sci. 2022, 27, comp1-16. [CrossRef] 26. Patil, S.; Kulkarni, P. Diabetic Retinopathy Detection: Methods and Challenges. In Proceedings of the 2019 IEEE Pune Section International Conference (PuneCon), Pune, India, 18\u201320 December 2019; Volume 2022, pp. 1\u20133. 27. Qiao, L.; Zhu, Y.; Zhou, H. Diabetic Retinopathy Detection Using Prognosis of Microaneurysm and Early Diagnosis System for Nonproliferative Diabetic Retinopathy Based on Deep Learning Algorithms. IEEE Access 2020, 8, 104292\u2013104302. [CrossRef] 28. Ara\u00fajo, T.; Aresta, G.; Mendon\u00e7a, L.; Penas, S.; Maia, C.; Carneiro, \u00c2.; Mendon\u00e7a, A.M.; Campilho, A. Data Augmentation for Improving Proliferative Diabetic Retinopathy Detection in Eye Fundus Images. IEEE Access 2020, 8, 182462\u2013182474. [CrossRef] 29. Nazir, T.; Irtaza, A.; Javed, A.; Malik, H.; Hussain, D.; Naqvi, R.A. Retinal Image Analysis for Diabetes-Based Eye Disease Detection Using Deep Learning. Appl. Sci. 2020, 10, 6185. [CrossRef] 30. Chalakkal, R.J.; Hafiz, F.M.; Abdulla, W.; Swain, A. An Efficient Framework for Automated Screening of Clinically Significant Macular Edema. Comput. Biol. Med. 2021, 130, 104128. [CrossRef] [PubMed] 31. Sikder, N.; Masud, M.; Bairagi, A.; Arif, A.S.; Nahid, A.; Alhumyani, H. Severity Classification of Diabetic Retinopathy Using an Ensemble Learning Algorithm through Analyzing Retinal Images. Symmetry 2021, 13, 670. [CrossRef] 32. AbdelMaksoud, E.; Barakat, S.; Elmogy, M.M. A comprehensive diagnosis system for early signs and different diabetic retinopathy grades using fundus retinal images based on pathological changes detection. Comput. Biol. Med. 2020, 126, 104039. [CrossRef] 33. Singh, N.; Kaur, L.; Singh, K. Histogram equalization techniques for enhancement of low radiance retinal images for early detection of diabetic Retinopathy. Eng. Sci. Technol. Int. J. 2019, 22, 736\u2013745. [CrossRef] 34. Li, X.; Hu, X.; Yu, L.; Zhu, L.; Fu, C.; Heng, P. CANet: Cross-Disease Attention Network for Joint Diabetic Retinopathy and Diabetic Macular Edema Grading. IEEE Trans. Med. Imaging 2020, 39, 1483\u20131493. [CrossRef] 35. Wang, J.; Bai, Y.; Xia, B. Simultaneous Diagnosis of Severity and Features of Diabetic Retinopathy in Fundus Photography Using Deep Learning. IEEE J. Biomed. Health Inform. 2020, 24, 3397\u20133407. [CrossRef] 36. Aurangzeb, K.; Aslam, S.; Alhussein, M.A.; Naqvi, R.A.; Arsalan, M.; Haider, S.I. Contrast Enhancement of Fundus Images by Employing Modified PSO for Improving the Performance of Deep Learning Models. IEEE Access 2021, 9, 47930\u201347945. [CrossRef] 37. Rajput, G.G.; Reshmi, B.; Rajesh, I. Automatic detection and grading of diabetic maculopathy using fundus images. Procedia Comput. Sci. 2020, 167, 57\u201366. [CrossRef] 38. Ahn, S.; Pham, Q.T.; Shin, J.; Song, S.J. Future Image Synthesis for Diabetic Retinopathy Based on the Lesion Occurrence Probability. Electronics 2021, 10, 726. [CrossRef] 39. Qummar, S.; Khan, F.G.; Shah, S.; Khan, A.; Shamshirband, S.; Rehman, Z.U.; Ahmed Khan, I.; Jadoon, W. A Deep Learning Ensemble Approach for Diabetic Retinopathy Detection. IEEE Access 2019, 7, 150530\u2013150539. [CrossRef] 40. Nazir, T.; Nawaz, M.; Rashid, J.; Mahum, R.; Masood, M.F.; Mehmood, A.; Ali, F.; Kim, J.; Kwon, H.; Hussain, A. Detection of Diabetic Eye Disease from Retinal Images Using a Deep Learning based CenterNet Model. Sensors 2021, 21, 5283. [CrossRef] [PubMed]\nDisclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."
        }
    ],
    "title": "Diabetic Retinopathy and Diabetic Macular Edema Detection Using Ensemble Based Convolutional Neural Networks",
    "year": 2023
}