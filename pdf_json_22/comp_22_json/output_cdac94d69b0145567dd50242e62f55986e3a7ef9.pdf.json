{
    "abstractText": "The non-uniform photoelectric response of infrared imaging systems results in fixed-pattern stripe noise being superimposed on infrared images, which severely reduces image quality. As the applications of degraded infrared images are limited, it is crucial to effectively preserve original details. Existing image destriping methods struggle to concurrently remove all stripe noise artifacts, preserve image details and structures, and balance real-time performance. In this paper we propose a novel algorithm for destriping degraded images, which takes advantage of neighbouring column signal correlation to remove independent column stripe noise. This is achieved through an iterative deep unfolding algorithm where the estimated noise of one network iteration is used as input to the next iteration. This progression substantially reduces the search space of possible function approximations, allowing for efficient training on larger datasets. The proposed method allows for a more precise estimation of stripe noise to preserve scene details more accurately. Extensive experimental results demonstrate that the proposed model outperforms existing destriping methods on artificially corrupted images on both quantitative and qualitative assessments.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zeshan Fayyaz"
        },
        {
            "affiliations": [],
            "name": "Daniel Platnick"
        },
        {
            "affiliations": [],
            "name": "Hannan Fayyaz"
        },
        {
            "affiliations": [],
            "name": "Nariman Farsad"
        }
    ],
    "id": "SP:33e3ee6d2cb33995caeb6a0e02d03e13e785eb20",
    "references": [
        {
            "authors": [
                "X. Kuang",
                "X. Sui",
                "Y. Liu",
                "Q. Chen",
                "G. Guohua"
            ],
            "title": "Single infrared image optical noise removal using a deep convolutional neural network",
            "venue": "IEEE Photonics Journal, vol. 10, no. 2, pp. 1\u201315, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "S.-P. Wang"
            ],
            "title": "Stripe noise removal for infrared image by minimizing difference between columns",
            "venue": "Infrared Physics & Technology, vol. 77, pp. 58\u201364, 2016. [Online]. Available: https://www.sciencedirect.com/ science/article/pii/S1350449515300293",
            "year": 2016
        },
        {
            "authors": [
                "R. Lai",
                "G. Yue",
                "G. Zhang"
            ],
            "title": "Total variation based neural network regression for nonuniformity correction of infrared images",
            "venue": "Symmetry, vol. 10, no. 5, 2018. [Online]. Available: https://www.mdpi.com/ 2073-8994/10/5/157",
            "year": 2018
        },
        {
            "authors": [
                "Y. Chang",
                "L. Yan",
                "T. Wu",
                "S. Zhong"
            ],
            "title": "Remote sensing image stripe noise removal: From image decomposition perspective",
            "venue": "IEEE Transactions on Geoscience and Remote Sensing, vol. 54, no. 12, pp. 7018\u20137031, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "H. Li",
                "C.Y. Suen"
            ],
            "title": "A novel non-local means image denoising method based on grey theory",
            "venue": "Pattern Recognition, vol. 49, pp. 237\u2013248, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "K. He",
                "J. Sun",
                "X. Tang"
            ],
            "title": "Guided image filtering",
            "venue": "IEEE transactions on pattern analysis and machine intelligence, vol. 35, no. 6, pp. 1397\u2013 1409, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "Y. Tendero",
                "S. Landeau",
                "J. Gilles"
            ],
            "title": "Non-uniformity correction of infrared images by midway equalization",
            "venue": "Image Processing On Line, vol. 2, pp. 134\u2013, 07 2012.",
            "year": 2012
        },
        {
            "authors": [
                "J. Guan",
                "R. Lai",
                "A. Xiong"
            ],
            "title": "Wavelet deep neural network for stripe noise removal",
            "venue": "IEEE Access, vol. 7, pp. 44 544\u201344 554, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "\u2014\u2014"
            ],
            "title": "Learning spatiotemporal features for single image stripe noise removal",
            "venue": "IEEE Access, vol. 7, pp. 144 489\u2013144 499, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "X. Song",
                "H.-C. Li",
                "L. Pan",
                "Y.-J. Deng",
                "P. Zhang",
                "L. You",
                "Q. Du"
            ],
            "title": "Unsupervised robust projection learning by low-rank and sparse decomposition for hyperspectral feature extraction",
            "venue": "IEEE Geoscience and Remote Sensing Letters, vol. 19, pp. 1\u20135, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Wan",
                "A. Ma",
                "W. He",
                "Y. Zhong"
            ],
            "title": "Accurate multi-objective lowrank and sparse model for hyperspectral image denoising method",
            "venue": "IEEE Transactions on Evolutionary Computation, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "J.R. Hershey",
                "J.L. Roux",
                "F. Weninger"
            ],
            "title": "Deep unfolding: Model-based inspiration of novel deep architectures",
            "venue": "arXiv preprint arXiv:1409.2574, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "V. Monga",
                "Y. Li",
                "Y.C. Eldar"
            ],
            "title": "Algorithm unrolling: Interpretable, efficient deep learning for signal and image processing",
            "venue": "IEEE Signal Processing Magazine, vol. 38, no. 2, pp. 18\u201344, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "\u2014\u2014"
            ],
            "title": "Algorithm unrolling: Interpretable, efficient deep learning for signal and image processing",
            "venue": "IEEE Signal Processing Magazine, vol. 38, no. 2, pp. 18\u201344, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "B.N. Chiche",
                "J. Frontera-Pons",
                "A. Woiselle",
                "J.-L. Starck"
            ],
            "title": "Deep unrolled network for video super-resolution",
            "venue": "2020 Tenth International Conference on Image Processing Theory, Tools and Applications (IPTA). IEEE, 2020, pp. 1\u20136.",
            "year": 2020
        },
        {
            "authors": [
                "Z. He",
                "Y. Cao",
                "Y. Dong",
                "J. Yang",
                "Y. Cao",
                "C.-L. Tisse"
            ],
            "title": "Singleimage-based nonuniformity correction of uncooled long-wave infrared detectors: A deep-learning approach",
            "venue": "Applied optics, vol. 57, no. 18, pp. D155\u2013D164, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "P. Xiao",
                "Y. Guo",
                "P. Zhuang"
            ],
            "title": "Removing stripe noise from infrared cloud images via deep convolutional networks",
            "venue": "IEEE Photonics Journal, vol. 10, no. 4, pp. 1\u201314, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "X. Yin",
                "C. Liu",
                "X. Fang"
            ],
            "title": "Sentiment analysis based on bigru information enhancement",
            "venue": "Journal of Physics: Conference Series, vol. 1748, p. 032054, 01 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Hor\u00e9",
                "D. Ziou"
            ],
            "title": "Image quality metrics: Psnr vs. ssim",
            "venue": "2010 20th International Conference on Pattern Recognition, 2010, pp. 2366\u2013 2369.",
            "year": 2010
        },
        {
            "authors": [
                "Z. Wang",
                "A.C. Bovik",
                "H.R. Sheikh",
                "E.P. Simoncelli"
            ],
            "title": "Image quality assessment: from error visibility to structural similarity",
            "venue": "IEEE transactions on image processing, vol. 13, no. 4, pp. 600\u2013612, 2004.",
            "year": 2004
        },
        {
            "authors": [
                "A. Hore",
                "D. Ziou"
            ],
            "title": "Image quality metrics: Psnr vs. ssim",
            "venue": "2010 20th international conference on pattern recognition. IEEE, 2010, pp. 2366\u20132369.",
            "year": 2010
        },
        {
            "authors": [
                "W. Luo",
                "J. Li",
                "W. Xu",
                "J. Yang"
            ],
            "title": "Learning sparse features in convolutional neural networks for image classification",
            "venue": "International Conference on Intelligent Science and Big Data Engineering. Springer, 2015, pp. 29\u201338.",
            "year": 2015
        },
        {
            "authors": [
                "G. Chaladze",
                "L. Kalatozishvili"
            ],
            "title": "Linnaeus 5 dataset for machine learning",
            "venue": "2017.",
            "year": 2017
        },
        {
            "authors": [
                "K. Zhang",
                "W. Zuo",
                "Y. Chen",
                "D. Meng",
                "L. Zhang"
            ],
            "title": "Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising",
            "venue": "IEEE transactions on image processing, vol. 26, no. 7, pp. 3142\u20133155, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "D. Martin",
                "C. Fowlkes",
                "D. Tal",
                "J. Malik"
            ],
            "title": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics",
            "venue": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, vol. 2. IEEE, 2001, pp. 416\u2013423.",
            "year": 2001
        },
        {
            "authors": [
                "J.-B. Huang",
                "A. Singh",
                "N. Ahuja"
            ],
            "title": "Single image super-resolution from transformed self-exemplars",
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 5197\u20135206.",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Image denoising, fixed-pattern noise, infrared image sensors, deep unfolding, neural networks, image restoration\nI. INTRODUCTION Infrared imaging systems are an important tool used across many field domains, including medical imaging, transport navigation, and remote sensing [1]. Infrared images are typically corrupted by stripe noise due to the non-uniform sensing of light in the system\u2019s photo-receptive sensors [2]. This corruption results in significant fixed-pattern noise (FPN) embedded in the image, which decreases the quality of infrared imaging systems. To produce a more accurate image, it is imperative to remove the superimposed vertical stripe noise artifacts and preserve the original structures of the image.\nPrevious destriping methods can be placed into three categories: optimization-based methods, statistics-based methods, and deep learning-based methods. Optimization-based stripe noise correction methods are contextualized as an ill-posed inverse problem, where several priors are inputted into the regularizer model [3]. Low-rank regularization (LRR) [4], nonlocal means (NLM) [5] and guided-filter (GF) [6] are methods that use prior knowledge of the ground truth to remove stripe noise. Prior-based strategies remove stripe noise indiscriminately, resulting in blurred image artifacts. Standard statisticsbased methods include the midway histogram equalization (MHE) [7] approach. This algorithm evenly distributes pixel intensity values throughout the image, typically increasing contrast and image clarity. One drawback to the MHE algorithm is that due to its indiscriminate nature, it may increase\nthe contrast of noise artifacts and hinder the image signal quality.\nDeep learning-based methods eventually show vast improvement in the performance of stripe-noise removal algorithms. J. Guan et al.\u2019s [8] stripe noise removal wavelet deep neural network (SNRWDNN) consists of a convolutional neural network (CNN) which predicts the wavelet transform coefficients of an image, and then the inverse transformation is applied to achieve the destriped image. Additionally, J. Guan et al.\u2019s [9] spatiotemporal stripe noise removal (ST-SNR) approach uses bidirectional gated convolutional recurrent units (BiGCRU) to take advantage of the strong dependency between the continuous stripe component along the columns and the rows. These methods are effective at removing low to medium levels of stripe noise but still leave minor stripe artifacts, especially when corrupted with higher levels of noise.\nAs the applications of degraded infrared images are limited, it is crucial to remove the column-wise noise while preserving complex details. Previous traditional destriping methods, such as low-rank and sparse matrix decomposition often lead to inaccurate sparse modeling and unstable results. Deep learning-based denoising methods originate from unsupervised low-rank sparse decomposition for feature extraction [10]. Y. Wan et al. [11] present a deep-learning based destriping approach based on an accurate multi-objective low-rank sparse denoising framework, and the problem is converted into a multi-objective optimization problem.\nInspired by deep-unfolding techniques [12], [13], to overcome this challenge, in this work, we propose the deepunfolding for iterative noise removal (DINR) algorithm. In the proposed method, recurrent neural network (RNN)s are used to iteratively remove column noise from the image. In particular, during each iteration, the noise over each column is estimated using the current as well as the adjacent columns. The high correlation between adjacent columns in the clean image can be used by the algorithm to better differentiate the noise from the original signal. The estimated noise at the end of each iteration is then used to progressively clean the image. Thus, our method continuously feeds the output of the network, which is a partially destriped image, as input back into the network. This iterative noise estimation and removal destripes an image until all stripe noise artifacts are removed. In certain instances, DINR outperforms the current state-of-theart (SOTA) for stripe noise removal by 22.99% on quantitative assessments, as well as qualitatively more accurately preserves complex scene details and original shadowing in high-intensity noise regions.\nar X\niv :2\n20 9.\n14 97\n3v 1\n[ ee\nss .I\nV ]\n2 7\nSe p\n20 22\nDeep learning approaches attempt to discover model information by optimizing network parameters learned from training. Although highly efficient, deep learning typically suffers the drawbacks of requiring large training sets, lack of interpretability, and overfitting. In general, RNNs generate predictions over many time steps, which can be simplified and further improved by unfolding, or unrolling the algorithm over the input sequence. Unfolded networks inherit prior domain and structure knowledge, rather than learnt through extensive training and are capable of more accurately approximating the target function due to its universal approximation capability [14]. Deep unrolled networks have previously been deployed for video super-resolution tasks, as explored in the working of B. N. Chiche et al. [15] and results find that unrolled networks allow for flexibility in learning a single model to nonblindly deal with multiple degradations while learning spatial patterns and details.\nThe rest of this paper is organized as follows. The problem statement is discussed in Section II. Then, in Section III, we present DINR. Section IV presents the evaluation results and comparison to prior work, and the paper ends with concluding remarks in Section V."
        },
        {
            "heading": "II. STRIPE NOISE REMOVAL PROBLEM AND MOTIVATION",
            "text": "To model the stripe noise in infrared imaging, we follow the models proposed in prior work [8], [9]. Let X , S, and Y , respectively, denote the n \u00d7 m matrices of the original clean image, the stripe noise, and the degraded image. Then the noise added to i-th column is given by:\nyi = xi + si, (1)\nwhere yi, xi, and si are the i-th column of Y , X , and S, respectively, and the elements of si are equal in value (i.e., s (1) i = s (2) i \u00b7 \u00b7 \u00b7 = s (n) i and distributed as\nsi \u223c N(0, \u03c32). (2)\nWhile the noise variance remains the same across the columns of the same image, the variance can change from image to image. Specifically, for the stripe matrix S, the standard deviation is distributed as\n\u03c3 \u223c U(0, \u03b2), (3)\nwhere U is the uniform distribution, and \u03b2 controls the noise power. Fig. 1 shows a clean sample image, stripe noise, and the noisy image.\nThe goal of denoising is to estimate the clean image X\u0302 from the noisy observation Y . Specifically, inspired by deepunfolding techniques [12], [13], our proposed algorithm aims to iteratively estimate the residual noise and progressively clean the image."
        },
        {
            "heading": "III. DEEP UNFOLDING FOR ITERATIVE NOISE REMOVAL",
            "text": "In this section, we will introduce the overall network architecture and outline our approach to stripe noise removal.\nGiven a noisy image Y , our proposed algorithm DINR aims to estimate the noise and the clean image iteratively. Specifically, let X\u0302(k) be the estimated clean image at the end of the k-th iteration with X\u0302(0) = Y , and let S\u0302(k) be the estimated noise at the end of the k-th iteration. Instead of our algorithm estimating the clean image directly during each iteration, it estimates the noise. Therefore, the estimated noise after the k-th iteration is given by\nS\u0302(k) = X\u0302(0) \u2212 X\u0302(k). (4)\nDuring the iteration, the noise is re-estimated from the previous iteration using a function S\u0302(k) = fk(X\u0302(k\u22121)). Therefore, the output of the k-th iteration is given by:\nX\u0302(k) = X\u0302(0) \u2212 fk(X\u0302(k\u22121)). (5)\nTo design the function fk that estimates the residual noise from the previous step, we use the following facts about stripe noise. 1) The same noise is added to every pixel in a given column of the image. 2) To distinguish the noise from ground truth pixel values of the clean image for the i-th column, pixel values from adjacent columns can be exploited as they will be highly correlated with the i-th column.\nUsing these two facts, we use RNNs, specifically bidirectional gated recurrent units (BiGRU), to represent the function fk. That is fk is represented by the k-th layer of a multi-layer BiGRU, where the BiGRU inputs are m vectors of length n. Therefore, the function fk in (5), for the i-th column is given by:\nfk(x\u0302 (k\u22121) i ) = BiGRUk ( x\u0302 (k\u22121) i , gk(x\u0302 (k\u22121) 0:i\u22121 ), hk(x\u0302 (k\u22121) i+1:m) ) ,\n(6)\nwhere gk(.) and hk(.) are the GRU states from the forward and backward GRUs, respectively. These state vectors summarize relevant information from the columns before and the columns after the i-th column. Using this technique, the network can denoise an image column-wise using spatial information from neighbouring columns. A GRU is a modified type of RNN. As opposed to RNNs, GRUs merge the input gate and the forget gate into a single update gate and merge the cell state into the hidden state [18]. A BiGRU extensively gathers redundant information from past and future inputs to better estimate the stripe component. The bidirectional strategy allows us to compare columns with both of its neighbours, strengthening\nits long-time correlation and allowing for learning of temporal and spatial contextual information simultaneously.\nUnlike the BiGCRU proposed in J. Guan et. al [9], a BiGRU better preserves complex scene details by not over-smoothing an image with a convolutional layer. A comprehensive ablation study performed with BiGRU layers stacked with convolutional layers can be found in our source code repository. Our overall algorithm is shown in Fig. 2. Assuming we unfold the algorithm for T iterations, the deep-unfolded layers can then be trained end-to-end using a mean squared error loss between X\u0302(T ) and X ."
        },
        {
            "heading": "IV. EVALUATION RESULTS",
            "text": "In this section, we illustrate the quantitative and qualitative performance evaluation of the DINR method1. We utilize the\n1The code for running the experiments is available at https://github.com/ ZeshanFayyaz/StripeNoise\nperformance metrics of peak signal-to-noise ratio (PSNR) [19] and structural similarity index (SSIM) [20] [21] to assess the destriping capabilities of DINR in comparison to eight prior methods, some of which are currently state-of-the-art to the best of our knowledge. We begin this section by describing the quantitative evaluation indexes. Further, we describe the datasets used and an ablation study. We then compare DINR to prior work.\nA. Image Quality Metrics\nIn all further experiments, we verify and compare the effectiveness of the proposed DINR model using quantitative evaluation metrics such as PSNR and SSIM [21]. Given a ground-truth image f and a degraded test image g, with dimensions of M \u00d7N , the PSNR between f and g is defined by:\nPSNR(f, g) = 10 log10(255 2/MSE(f, g)) (7)\nwhere,\nMSE(f, g) = 1\nMN M\u2211 i=1 N\u2211 j=1 (fij \u2212 gij)2 (8)\nThe PSNR value approaches infinity as MSE approaches zero. This indicates that a higher PSNR provides higher image quality. SSIM was developed by Wang et al. [20] and is used to measure the similarity between two images. SSIM models image distortion as a combination of three factors that are loss of correlation, luminance distortion, and contrast distortion\n[21]. Unlike PSNR, SSIM is based on visible structures in the image."
        },
        {
            "heading": "B. Datasets and Ablation Study",
            "text": "The publicly available datasets BSDS500 [22] and Linnaeus 5 [23] are used to train the DINR model. They total 6,300 images, which are split 85% and 15% for training and validation, respectively. These images are corrupted using stripe noise with noise intensity (\u03b2) from 0 to 0.25 according to (1) and (3) and tested against images with the same stripe noise intensity. The maximum number of training epochs is set at\n100, with a batch size of 50. The training phase only takes about 1.5 hours on a single NVidia Quadro RTX 8000 GPU.\nFor evaluation we used several different datasets including: Set12 [24], BSDS100 [25], INFRARED100, Linnaeus 5, and Urban100 [26]. We also evaluate the algorithm over a variety of noise intensities (\u03b2 = 0.05, 0.15, and 0.25).\nWe begin this section by presenting an ablation study to find the best number of iterations (i.e., unfolding layers) for our DINR algorithm. The number of BiGRU layers examined was from 6 to 20. An excerpt of the results is summarized in Table I based on the PSNR and SSIM evaluation on all five datasets using \u03b2 = 0.05 (low noise), 0.15 (moderate noise), and 0.25 (high noise). As the number of BiGRU layers increases above 15, the performance decreases on images with highlevel intensity noise. On average, across all datasets and \u03b2 values, 15 BiGRU layers perform the best."
        },
        {
            "heading": "C. Performance Comparison to Prior Work",
            "text": "We start by evaluating the performance of DINR compared to prior work over the Set12 test dataset. This dataset was used in prior work for performance evaluation and contains only 12 images. Table II depicts the mean PSNR and SSIM values for the degraded images, as well as the predicted images for each destriping method for various levels of noise intensity. We test our method on light noise (\u03b2 = 0.06) up to distinct high intensity noise (\u03b2 = 0.22). The model with the bestperformance is depicted in bold. As can be seen from Table II, our proposed DINR method outperforms all prior methods in terms of PSNR and SSIM. Moreover, as noise intensity increases, the performance gap between DINR and the next best algorithm widens (about 16% higher PSNR at \u03b2 = 0.22).\nSince Set12 has only 12 images, we compare the performance of DINR with the prior SOTA SNRWDNN over all 5 test datasets. These results are summarized in Table III, where the best performing method is outlined in bold. For all test datasets, our DINR model achieves significantly higher\nPSNR and SSIM compared to SNRWDNN. Moreover, we observe that this gap widens for higher intensity noise. This implies that the proposed method effectively distinguishes the noise component and preserves details during testing. As the proposed model produces significantly higher SSIM values, we conclude that the destriped result is more close to the original image in human perception.\nFor a qualitative performance evaluation, we examine the destriping capabilities of the proposed DINR algorithm against the previous SOTA, SNRWDNN. Fig. 3 depicts a sample image randomly selected from each of the five datasets, with \u03b2 = 0.15 noise intensity superimposed. As can be noted for all examples, DINR achieves a higher PSNR and SSIM value, indicating a closer resemblance to the ground truth. Qualitatively, DINR can be seen to preserve original intensities and details. Other algorithms tend to lose effectiveness at higher levels of noise, but DINR removes high-intensity regions of noise just as well as low noise. For all instances, DINR outperforms SNRWDNN extensively in PSNR and SSIM. The proposed method preserves complex details and does not oversmooth the predicted image, as can be seen in Fig. 3(b) and Fig. 3(c). An example can be seen by the destriping results of SNRWDNN in Fig. 4(c), which displays gray bands in the destriped image, where the high-intensity noise was.\nA sample image found in Urban100 and Linnaeus 5 is shown in Fig. 4. Demonstrably, there are differences in the destriping results of DINR and SNRWDNN. Specifically, there are visible residual noise artifacts in the image cleaned by SNRWDNN, while DINR has very few artifacts. Fig. 4(e) illustrates the column-by-column mean pixel value. A predicted image may be considered denoised based on how closely it follows the original curve. It can be seen from columns 80- 125 that the SNRWDNN model fails to track the original curve. This can be observed in Fig. 4(c), and we highlight the columns where SNRWDNN demonstrates a lack of detail preservation.\nSimilarly, the column-by-column mean pixel value of the Linnaeus 5 test image can be found in Fig. 4(j). The destriped result of DINR closely tracks the ground truth image, depicting that the algorithm preserves intensities and details. It is useful to note the gray bands in Fig. 4(h), which coincide with the high-intensity stripe noise regions in Fig. 4(g). These inconsistent intensity changes can be found in Fig. 4(j) between columns 40 and 100 as well as 140 to 215."
        },
        {
            "heading": "V. CONCLUSION",
            "text": "We propose DINR, a novel stripe noise removal algorithm. Unlike existing destriping methods, DINR utilizes deepunfolding to iteratively destripe the noisy image column by column. During each iteration, BiGRUs are used to estimate the column noise, using information from adjacent columns to help distinguish between noise and actual pixel values. The noise estimate is improved with each iteration (i.e., layer) of the BiGRU up until the 15th layer. Experimental results indicate that our model performs exceptionally well at high noise intensity and outperforms classical methods as well as\nSOTA deep learning-based methods. These outstanding results may be seen qualitatively in the preservation of complex background details, or quantitatively, as evaluated by PSNR and SSIM.\nFuture work consists of making improvements to the computational complexity, as well as utilizing our iterative BiGRU deep-unfolding approach to perform excellently in other degraded image restoration tasks consisting of vertical-patterned noise and artifacts, such as rain-removal."
        }
    ],
    "title": "Deep Unfolding for Iterative Stripe Noise Removal",
    "year": 2022
}