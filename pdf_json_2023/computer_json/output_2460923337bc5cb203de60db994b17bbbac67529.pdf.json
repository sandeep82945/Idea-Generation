{
    "abstractText": "The negative impact of label noise is well studied in classical supervised learning yet remains an open research question in meta-learning. Meta-learners aim to adapt to unseen learning tasks by learning a good initial model in meta-training and consecutively fine-tuning it according to new tasks during meta-testing. In this paper, we present the first extensive analysis of the impact of varying levels of label noise on the performance of state-of-the-art meta-learners, specifically gradient-based N -way K-shot learners. We show that the accuracy of Reptile, iMAML, and foMAML drops by up to 42% on the Omniglot and CifarFS datasets when meta-training is affected by label noise. To strengthen the resilience against label noise, we propose two sampling techniques, namely manifold (Man) and batch manifold (BatMan), which transform the noisy supervised learners into semi-supervised ones to increase the utility of noisy labels. We first construct manifold samples of N -way 2-contrastive-shot tasks through augmentation, learning the embedding via a contrastive loss in meta-training, and then perform classification through zeroing on the embedding in meta-testing. We show that our approach can effectively mitigate the impact of meta-training label noise. Even with 60% wrong labels BatMan and Man can limit the meta-testing accuracy drop to 2.5, 9.4, 1.1 percent points, respectively, with existing meta-learners across the Omniglot, CifarFS, and MiniImagenet datasets.",
    "authors": [
        {
            "affiliations": [],
            "name": "A PREPRINT"
        },
        {
            "affiliations": [],
            "name": "Jeroen M"
        },
        {
            "affiliations": [],
            "name": "Galjaard"
        },
        {
            "affiliations": [],
            "name": "Robert"
        },
        {
            "affiliations": [],
            "name": "Birke"
        }
    ],
    "id": "SP:e728588907568d46d080ade9e51f5b7a2c305145",
    "references": [
        {
            "authors": [
                "P. Bachman",
                "R.D. Hjelm",
                "W. Buchwalter"
            ],
            "title": "Learning Representations by Maximizing Mutual Information Across Views",
            "venue": "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems",
            "year": 2019
        },
        {
            "authors": [
                "L. Bertinetto",
                "P.H. Torr",
                "J. Henriques",
                "A. Vedaldi"
            ],
            "title": "Meta-learning with differentiable closed-form solvers",
            "venue": "In: 7th International Conference on Learning Representations,",
            "year": 2019
        },
        {
            "authors": [
                "V. Boutin",
                "L. Singhal",
                "X. Thomas",
                "T. Serre"
            ],
            "title": "Diversity vs. Recognizability: Human-like generalization in one-shot generative models",
            "year": 2022
        },
        {
            "authors": [
                "D. Chen",
                "L. Wu",
                "S. Tang",
                "X. Yun",
                "B. Long",
                "Y. Zhuang"
            ],
            "title": "Robust Meta-learning with Sampling Noise and Label Noise via Eigen-Reptile",
            "venue": "Proceedings of the 39th International Conference on Machine Learning. Proceedings of Machine Learning Research,",
            "year": 2022
        },
        {
            "authors": [
                "C. Finn",
                "P. Abbeel",
                "S. Levine"
            ],
            "title": "Model-agnostic meta-learning for fast adaptation of deep networks",
            "venue": "34th International Conference on Machine Learning,",
            "year": 2017
        },
        {
            "authors": [
                "K. Hsu",
                "S. Levine",
                "C. Finn"
            ],
            "title": "Unsupervised Learning via Meta-Learning",
            "venue": "International Conference on Learning Representations,",
            "year": 2019
        },
        {
            "authors": [
                "C.H. Kao",
                "W.C. Chiu",
                "P.Y. Chen"
            ],
            "title": "MAML is a Noisy Contrastive Learner in Classification",
            "venue": "The Tenth International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "S. Khodadadeh",
                "L. B\u00f6l\u00f6ni",
                "M. Shah"
            ],
            "title": "Unsupervised Meta-Learning for Few-Shot Image Classification",
            "venue": "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems",
            "year": 2019
        },
        {
            "authors": [
                "K. Killamsetty",
                "C. Li",
                "C. Zhao",
                "F. Chen",
                "R. Iyer"
            ],
            "title": "A Nested Bi-level Optimization Framework for Robust Few Shot Learning",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
            "year": 2022
        },
        {
            "authors": [
                "B.M. Lake",
                "R. Salakhutdinov",
                "J. Gross",
                "J.B. Tenenbaum"
            ],
            "title": "One shot learning of simple visual concepts",
            "venue": "Proceedings of the Annual Meeting of the Cognitive Science Society",
            "year": 2011
        },
        {
            "authors": [
                "M. Li",
                "M. Soltanolkotabi",
                "S. Oymak"
            ],
            "title": "Gradient Descent with Early Stopping is Provably Robust to Label Noise for Overparameterized Neural Networks",
            "venue": "Conference on Artificial Intelligence and Statistics,",
            "year": 2020
        },
        {
            "authors": [
                "K.J. Liang",
                "S.B. Rangrej",
                "V. Petrovic",
                "T. Hassner"
            ],
            "title": "Few-shot Learning with Noisy Labels",
            "year": 2022
        },
        {
            "authors": [
                "J. Lu",
                "S. Jin",
                "J. Liang",
                "C. Zhang"
            ],
            "title": "Robust few-shot learning for user-provided data",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "year": 2020
        },
        {
            "authors": [
                "P. Mazumder",
                "P. Singh",
                "V.P. Namboodiri"
            ],
            "title": "RNNP: A Robust Few-Shot Learning Approach",
            "venue": "IEEE Winter Conference on Applications of Computer Vision, WACV 2021,",
            "year": 2021
        },
        {
            "authors": [
                "C. Medina",
                "A. Devos",
                "M. Grossglauser"
            ],
            "title": "Self-Supervised Prototypical Transfer Learning for Few-Shot Classification",
            "venue": "CoRR (2020),",
            "year": 2006
        },
        {
            "authors": [
                "Muhammad Abdullah Jamal",
                "L. Wang",
                "B. Gong"
            ],
            "title": "A Lazy Approach to Long-Horizon Gradient- Based Meta-Learning",
            "venue": "International Conference on Computer Vision pp",
            "year": 2021
        },
        {
            "authors": [
                "A. Nichol",
                "J. Achiam",
                "J. Schulman"
            ],
            "title": "On First-Order Meta-Learning Algorithms",
            "venue": "CoRR pp",
            "year": 2018
        },
        {
            "authors": [
                "A. Rajeswaran",
                "C. Finn",
                "S.M. Kakade",
                "S. Levine"
            ],
            "title": "Meta-Learning with Implicit Gradients",
            "venue": "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems",
            "year": 2019
        },
        {
            "authors": [
                "J. Schmidhuber"
            ],
            "title": "Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-.",
            "venue": "hook. Diploma thesis, Inst. f. Inf., Tech. Univ. Munich",
            "year": 1987
        },
        {
            "authors": [
                "O.K. Shirekar",
                "A. Singh",
                "H.J. Rad"
            ],
            "title": "Self-Attention Message Passing for Contrastive Few-Shot Learning",
            "venue": "{IEEE/CVF} Winter Conference on Applications of Computer Vision, {WACV} 2023,",
            "year": 2023
        },
        {
            "authors": [
                "H. Song",
                "M. Kim",
                "D. Park",
                "Y. Shin",
                "J.G. Lee"
            ],
            "title": "Learning from noisy labels with deep neural networks: A survey",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems pp",
            "year": 2022
        },
        {
            "authors": [
                "Z. Wang",
                "G. Hu",
                "Q. Hu"
            ],
            "title": "Training Noise-Robust Deep Neural Networks via Meta-Learning",
            "venue": "{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "H. Yao",
                "Y. Wang",
                "Y. Wei",
                "P. Zhao",
                "M. Mahdavi",
                "D. Lian",
                "C. Finn"
            ],
            "title": "Meta-learning with an Adaptive Task Scheduler",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2021
        },
        {
            "authors": [
                "C.H. Yeh",
                "C.Y. Hong",
                "Y.C. Hsu",
                "T.L. Liu",
                "Y. Chen",
                "Y. LeCun"
            ],
            "title": "Decoupled Contrastive Learning",
            "venue": "European Conference,",
            "year": 2022
        },
        {
            "authors": [
                "X. Yu",
                "T. Liu",
                "M. Gong",
                "K. Zhang",
                "K. Batmanghelich",
                "D. Tao"
            ],
            "title": "Label-Noise Robust Domain Adaptation",
            "venue": "Proceedings of the 37th International Conference on Machine Learning,",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Few-Shot Learning (FSL) poses the problem where learners need to quickly adapt to new unseen tasks by using a low number of samples. Meta-learning [19, 5] emerged as a promising solution to this problem. Like humans, meta-learners learn the information at a higher abstraction or meta-level, providing the inductive bias to adapt to new tasks quickly. Among existing meta-learners, gradient-based few-shot learners, e.g., iMAML [18] and foMAML(+ZO) [5, 7], have been shown effective to solve N -way K-shot (N,K) problems, that need to learn N classes given only K samples each. Such few-shot learners are composed of two stages, meta-training and meta-testing, each with their own labeled support and query data sets. Meta-training learns a meta-model using two sequential optimization loops. The inner-loop adapts the model to a specific task via supervised learning on the support set. The outer-loop updates the meta-model based on the adapted task-specific model and query set. Using a similar structure, meta-testing verifies how well the meta-model performs on new tasks. First, it uses supervised learning to adapt the meta-model to an unseen task given by a test support set. Then it computes the learner\u2019s accuracy on the testing query set comparing predicted and given labels. Class labels are thus crucial in both meta-training and meta-testing.\nLabel noise is more the norm than a rarity and can significantly degrade the performance of supervised learners [21]. Prior studies address label noise mainly in classical supervised learners. In this context, samples hold labels different from the underlying ground truth. In the context of FSL, label noise means that a shot (example) may not correspond\nar X\niv :2\n30 9.\n06 04\n6v 1\n[ cs\n.L G\nto the way (class) it was provided with. This yields a degenerate N -way K-shot problem where ways become indistinguishable since they contain shots of the same ground truth. Such noise may appear in the meta-training and meta-testing support and meta-training query set.\nGiven the importance of labels in meta-training and meta-testing, only a few studies [14, 12, 13] address the challenge of noisy labels in FSL and only at the level of the meta-testing support set. As the number of samples per class is very limited, e.g., five to ten shots, the task adaptation step can be over-parameterized by label noise and lead to significant degradation. Unfortunately, label noise can appear at all the support and query sets of meta-testing and meta-training, and little is known on its impact and resolution. Moreover, the existing meta-learners that account for label noise still require clean data to learn a meta-objective. [9] distills the impact of label noise by adding an additional meta-objective on clean validation data. [23] proposes an adaptive task-aware scheduling (ATS) to learn to filter out noisy tasks but assumes a static set of tasks, of which only a fraction has corrupted support sets.\nIn this paper, we first answer whether state-of-the-art FSL methods are resilient to label noise. We consider label noise present in the query and support sets during meta-training. We empirically show that Reptile [17], Eigen-Reptile [4], iMAML [18], and foMAML+ZO [7] are significantly affected by label noise in meta-training, overfitting to noise and degrading the efficacy of any randomly initialized models. To address the noisy labels in meta-training, we propose BatMan, which turns any supervised few-shot learner into a semi-supervised one by a novel batch manifold sampling and contrastive learning. We learn the embedding in meta-training and then apply a zeroing strategy in meta-testing. Specifically, we turn a noisy N -way K-shot problem into a self-cleansed N -way 2-contrastive shot problem. We first augment the original shots and construct contrastive pairs, ensuring the shots are from the same class. We then sample such pairs from the N ways, termed manifold (Man) samples. To lower the probability of getting noisy N -ways, i.e., overlapping classes, we draw a batch of such Man samples, termed BatMan sampling. Combining this approach with the Decoupled Contrastive Loss (DCL) [24], we can effectively learn the embedding of the initial model, which can then be adapted in meta-testing to a new N -way K-shot task.\nThe specific contributions of this paper are:\n1. A first-of-its-kind study on the impact of label noise in meta-training for gradient-based meta-learners. 2. A generic and self-cleansing framework, BatMan-CLR, that turns meta-learners into semi-supervised ones by\n(batched) manifold sampling N -way 2-contrastive shots. 3. Extensive evaluation on four meta-learners, Reptile, EigenReptile, iMAML, and foMAML, shows nearly no\nperformance degradation under the presence of up to 60% label noise."
        },
        {
            "heading": "2 Preliminary and Related work",
            "text": "Preliminary on FSL. FSL considers the setting where a learned model must adapt to new settings leveraging only a few samples. In this setting, meta-learning has emerged as a promising research direction. Gradient-based meta-learners\naim to find a meta-model with parameters \u03b8 capable of quickly adapting into a task-specific parameterization \u03d5. We consider the N -way K-shot classification problem, which consists of a family of tasks, made up of N classes, each with K samples, termed (N,K)-FSL tasks. We focus on gradient-based meta-learners which aim to find \u03b8 iteratively using a two-step meta-training algorithm (see Figure 1a). At the beginning of each meta-epoch, the learner selects a task T and samples two task-specific sets, support Dsupport and query Dquery, from the training data Dtrain. More formally a task T is a tuple of support and query data (Dsupport,Dquery) = T , defined as sets of inputs X and targets (labels) Y :\nDsupport = N\u22c3 i=1 {(Xij , Y ij )}Kj=1, Dquery = N\u22c3 i=1 {(Xij , Y ij )} Q j=1.\nNext, step one transforms \u03b8t using the features and labels (Xs, Ys) \u2208 Dsupport and a supervised loss function Lsup in task-specific parameters \u03d5. Then, step two uses \u03d5, the data (Xq, Yq) \u2208 Dquery, and Lsup to obtain \u03b8t+1 for the next iteration. Note that while the support set Dsupport is used during an inner-loop to train for a specific task, the query set Dquery is used in an outer-loop to learn the meta-model. During meta-training, the support set for a single task is built by randomly selecting N classes from the training set Dtrain, each with K samples. For the query set, we select Q additional samples for the same N selected classes.\nMeta-testing aims to evaluate the ability of the trained meta-model \u03b8\u2217 to adapt to new tasks (see Figure 1b) Analogous to meta-training, first we select a testing task and sample Dsupport and Dquery from the test data Dtest. Next, an adaptation step uses Dsupport to transform the generic meta-model with parameters \u03b8\u2217 into the task-specific model with parameters \u03d5\u2217. Finally, \u03d5\u2217 is tested on the query set (Xq, Yq) \u2208 Dquery by comparing its predictions Y\u0302q against known labels Yq . Examples of gradient-based meta-learners include MAML [5], iMAML [18], foMAML(+ZO) [7], Reptile [17] and Eigen-Reptile [4]. MAML updates the meta-model via gradient descent through gradient descent [5]. As this operation is both compute and memory intensive [5, 18, 16] many works proposed approximations. iMAML [18] and foMAML (with the zero-ing trick from [7]) approximate the meta-gradient w.r.t. \u03b8t by leveraging the first-order gradient on Dquery w.r.t. \u03d5u. This drops the need for gradient descent through gradient descent.\nfoMAML assumes that the higher-order components of the meta-gradient can be ignored altogether, whereas iMAML enforces that it can calculate the meta-gradient using more adaptation steps and weight regularization. Reptile [17] drops Dquery during meta-training by estimating the meta-gradient by stepping towards \u03d5u to find \u03b8t+1. Eigen-Reptile [4] builds on this by decomposing the inner-optimization path [\u03b8t, \u03d51, . . . , \u03d5u] and stepping towards the direction with the largest variance.\nLabel noise in FSL. Label noise poses a major challenge to meta-learners, especially in the absence of clean data that can be used as ground truth during the training phase. Although a large collection of work exists on robust supervised learning [22, 11, 25], these are not directly applicable to meta-learners due to the limited number of samples available during each adaptation process. Recognizing the presence of label noise, related studies [23, 13, 9, 12, 14, 12] mainly focus on distilling the label noise appearing in meta-testing by explicitly studying the noise patterns [23, 12, 13], using soft-relabeling [14] through clustering or re-weighting suspicious samples [9] based on additional clean data. To our best knowledge, Eigen-Reptile [4] is the only study that addresses noisy training data in FSL by updating the inner-loop only along the direction of the highest variance. However, such an approach lacks generalization to other state-of-the-art meta-learners.\nThe impact of label noise. Here we motivate the need of noise resilience in few shot learning via an empirical study. We investigate the effect of label noise on two representative datasets, CifarFS [2] and Omniglot [10], in a (5, 5)-FSL setting with a query set of 15 samples per class. The details of the datasets and experiments can be found in Section 4.1. We re-implement four different meta-learners: Eigen-Reptile (ER) [4], Reptile [17], first order MAML with Zero Out\n(foMAML+ZO) [7], and implicit MAML (iMAML) [18]. We train each learner using hyper-parameters comparable to the ones in the corresponding paper. We consider a symmetric label noise setting, where each label of class i has \u03f5 probability to be corrupted with a random label j \u0338= i with uniform probability across all other classes. Table 1 shows the meta-test accuracy obtained by the different meta-learners under varying degrees of corrupted training labels, \u03f5 = [0.0, 0.3, 0.6]. Note that \u03f5 = 0.0 means no noise, i.e., all clean labels. Reported results are the average across three runs with 95% confidence intervals. Both datasets and all meta-learners clearly show a significant performance degradation as the noise ratio increases. With the CifarFS dataset, accuracy drops across all meta-learners on average by 10.1% and 27.4% under 30% and 60% corrupted labels, respectively. The Omniglot dataset shows similar trends but more limited in amplitude, with 8.1% and 17.0% average degradation. This is due to the fact that the Omniglot dataset is easier to learn. Indeed, all meta-learners obtain an accuracy score above 90% under zero noise. Interestingly, although ER is the sole meta-learner that explicitly aims to counter noise, it is not always the most robust one. Under moderate noise, i.e. 30%, foMAML+ZO is the least affected with accuracy drops of 6.2% and 1.6% for CifarFS and Omniglot, respectively. Only under heavy noise, i.e. 60%, on the CifarFS dataset ER is the least affected learner (accuracy drop of 19.3%) and able to beat the others by a small 0.9 percentage points higher accuracy margin. More in general, Reptile, ER and iMAML show a higher but almost linear impact of noise, while foMAML+ZO degrades less with 30% noise but gets much worse under 60% noise. Overall, the results underline the need for better noise resilience across all meta-learners."
        },
        {
            "heading": "3 Proposed method",
            "text": "The core challenge of dealing with noise in meta-(or few shot) learning is that labels lose meaning misguiding standard supervised approaches with wrongly labeled samples. This challenge is amplified in the FSL setting as the limited number of samples (shots) in each class (way) makes it harder to isolate the noise from the signal in each class. In other words, the few clean samples\u2014those corresponding to the original not-corrupted class\u2014may not be enough to appropriately guide the gradient descent algorithm in the correct direction of the class label. Thus, our approach aims at building clean ways and shots\u2014such that each \u2018way\u2019 becomes more likely to have samples all with the same ground truth. Specifically, the proposed Man sampling uses data augmentation to create clean shots, which guarantees that the underlying ground truth label is the same, rather than leveraging other shots of the same \u2018way\u2019. We further introduce batches, with BatMan sampling, to increase the likelihood of observing all N classes in a single inner-loop step. In this section, we go over the three main steps of our proposed method, namely, i) re-sampling, either with Man or BatMan, ii) \u2018semi\u2019-supervised meta-training with a contrastive loss, and iii) classification of new tasks (meta-testing) leveraging a zeroing trick. Together these steps can be incorporated into existing meta-learning algorithms to achieve label noise robustness. Section 4 provides results for both Man and BatMan re-sampling. Figure 2 provides a graphical depiction of our proposed method applied on a noisy (3, 2)-FSL task.\nAlgorithm 1 Pseudocode for Man Sampling. BatMan is achieved through multiple Man samples. Require: Augment feature augment function.\n1: function MANSAMPLING(D, N ) 2: M = {} 3: for j \u2208 [1, . . . , N ] do 4: X \u2190 rand ((X, y) \u2208 D : y = j) 5: A1 \u2190 Augment(X) 6: A2 \u2190 Augment(X) 7: M \u2190M \u222a {(A1, j), (A2, j)} 8: end for 9: return M\n10: end function\nAlgorithm 2 General structure with BatMan-CLR for MAML style learners.\n1: function BatMan-CLR(\u03d5, Dsupport, Dquery, \u03b1, N , u) 2: for Bi \u2208 [BatMan(Dsupport, N)]ui=1 do 3: \u03d5\u2190 \u03d5\u2212 \u03b1v\u2207\u03d5 \u2211 Mj\u2208Bi Lcon(\u03d5(Mj))) 4: end for 5: Bquery \u2190 BatMan(Dquery, N) 6: Louter \u2190\n\u2211 Mj\u2208Bquery Lcon(\u03d5(Mj)))\n7: return \u03d5,Louter 8: end function\nManifold and BatMan re-sampling. We start with an (N,K)-FSL problem with noisy labels and observe that we can re-frame it as an (N, 2)-FSL problem by sampling 1 data point from each way and creating one more sample for each class employing augmentations. Thus we end up with two samples with the same label for each way. Since we sample N observations from all N \u00d7K in Dquery, we end up with up to N actual classes, as some classes may end up contributing more than one observation to a sub-sampled task. In this manner, many potential (N, 2) sub-tasks can be created, each corresponding to a different task \u2018manifold\u2019 [17] due to noisy labels. We coin this sampling approach Manifold (Man) sampling, described as pseudo-code in Algorithm 1. Note that to avoid introducing a bias towards\nthe original sample, for each shot we use Augment to draw two random augmentations. As a simple extension of Man sampling, we propose a Batched Manifold (BatMan) sampling, where several Man samples are batched together to employ more samples in a single step. By grouping a batch of Man samples, we can jointly optimize multiple \u201csub-problems\u201d. Additionally, this increases the likelihood of considering all query classes together in the calculation of meta-gradients.\nThis process is illustrated in Figure 2, with a 3-way 2-shot FSL setting, where each row index represents a way and each column index a shot. The classes are illustrated with different colors, where initially there are 2 shots of each of the green, purple, and yellow classes. Noise has caused the class of the first shot in the green class to have a red class label, and the second shot of the yellow class to have a purple class label. A pool of Man samples is generated by sampling 1 shot from each of the 3 classes and augmenting it twice to have an (N, 2) FSL task. A batch of such tasks is generated to perform a meta-training step through gradient descent.\nIn the presence of noise, the process of cleaning up the classes is necessary as samples from two apparently different classes may actually come from the same class. In the simplest case with 2 classes and a probability p = 1\u2212 \u03f5 that a sample has a ground truth label, the classes resulting from the Man sampling process belong to different classes with probability p2 + (1 \u2212 p)2, as either both lack noise or both are noisy. On the contrary, the 2 samples selected actually belong to the same class with probability 2p(1\u2212 p). In general, with N classes there are N ! combinations in which the Man samples actually correspond to the N different classes while there are NN combinations to select the N samples, with replacement. Let us consider the case of symmetric noise where a sample has a ground truth label i with probability p and that the sample is mislabeled as a different class j \u0338= i with probability (1\u2212 p)/(K \u2212 1). The probability of obtaining a clean selection of classes can then be posed as the probability of obtaining one of the N ! combinations in which this occurs. To represent each possible selection we employ permutation matrices. Let P iN be the N \u00d7N ith permutation matrix out of the N ! such matrices. For instance, in the N = 3 case, we have 6 different permutation matrices, i.e.,[\n1 0 0 0 1 0 0 0 1\n] , [ 1 0 0 0 0 1 0 1 0 ] , [ 0 1 0 1 0 0 0 0 1 ] , [ 0 1 0 0 0 1 1 0 0 ] , [ 0 0 1 1 0 0 0 1 0 ] , [ 0 0 1 0 1 0 1 0 0 ] .\nLet us also define the N \u00d7N matrix Q with entries qij such that qii = p and qij = (1\u2212 p)/(N \u2212 1) for i \u0338= j. The probability of obtaining one of these valid permutations under Man sampling can thus be obtained as the trace of the matrix P iNQ. As a result, the probability of obtaining a clean selection of ways can be expressed as\nN !\u2211 i=1 trace(P iNQ),\nconsidering all possible valid selections of samples that lead to a set with N different classes. As this probability becomes smaller with increasing label noise, BatMan sampling helps by introducing additional samples that increase the likelihood of observing all N classes in a single meta-epoch.\nSemi-supervised meta-training with contrastive loss. Although re-sampling allows for likely valid (N, 2) sub-tasks, which classes they contain remains unknown. As such these sub-tasks can be considered as semi-supervised, as there are now at most N classes. To aid this, we incorporate a contrastive loss to allow for joint optimization of semantically misaligned sub-tasks. Note that from the sampled augmentations obtained in step 1 of Figure 2, we artificially build positive and negative pairs. These positive and negative pairs can be optimized under a contrastive learning strategy. We use the Decoupled Contrastive Loss (DCL) [24], which is particularly well-suited for small data sets, although alternative contrastive losses can easily replace it. Once samples are augmented and BatMan sampling applied, the batches are used in the meta-training step where the embeddings z are computed and contrasted using a contrastive loss.\nClassification of new tasks. The meta-model \u03b8\u2217 trained using the contrastive loss produces embeddings instead of classes as output. To solve this, we append the meta-model with a fully connected layer C0 = (W,b) with W = 0 and b = 0. This approach decouples the embedding learning from the classification task. Similar to [7], this allows us to treat the model as a semi-supervised meta-learned backbone. The resulting meta-model \u03b8\u2217\u2032 = C0 \u25e6 \u03b8\u2217 can then be treated as a supervised learner utilizing the cross entropy (CE) classification loss. We found that applying the Zeroing Out trick on the classification layer significantly impacts the learner\u2019s performance because it allows leveraging the optimized embedding from the pre-trained meta-model \u03b8\u2217. This is because the stochastic gradient descent will directly use the embeddings as activations without the noise introduced by randomly initialized weights."
        },
        {
            "heading": "4 Evaluation Results",
            "text": "In this section, we present the effectiveness of BatMan-CLR in enhancing the noise resilience for state-of-the-art meta-learners, namely Reptile, iMAML, and foMAML+ZO, under the presence of different noise levels. We further include Eigen-Reptile, a noise-aware FSL as an additional baseline."
        },
        {
            "heading": "4.1 Setup",
            "text": "We consider three data sets in a (5, 5)-FSL setting: Omniglot, Cifar Few-Shot (CifarFS), and miniImagenet. To emulate training label noise, for each dataset, we add symmetric random noise to Dtrain with 30% and 60% corrupted labels. For instance, for experiments with 60% noise, we randomly select 60% samples of each class in Dtrain, and assign them to a different class within the same split. Reported meta-test results are on clean data, to evaluate the learners under a base-case scenario. The support set is of size 5 (15), and query set 15 (Reptile learners), following [5, 17]. All experiments ran on machines with 128 GB RAM, 2x AMD EPYC 7282 16-Core CPUs, and a 16 GB Nvidia A4000 GPU. We used cross-entropy loss for supervised meta-training and meta-testing.\nWe incorporate Man and BatMan sampling into Reptile, Eigen-Reptile, iMAML and foMAML with Zeroing-trick. Each learner uses a ConvNet-4 architecture with 64 filters and a linear layer with output dimension R128. On Omniglot, the number of filters was increased to 128. We use weight decay centered around \u03b8t [18] on iMAML and foMAML+ZO resets its final layer to zero at the beginning of each inner-loop. The learners were trained with the original papers\u2019 hyper-parameters, except for the following changes. Eigen-Reptile and Reptile run with 7 inner-loop steps, iMAML with 12 (16 for Omniglot), and foMAML with 5. iMAML\u2019s proximal decay was set to 0.5 (2.0 for Omniglot). Each learner was meta-tested after 5K, 15K (10K), 15K (10K), training outer-loop steps (iMAML) respectively for Omniglot, CifarFS and MiniImagenet. On CifarFS and MiniImagenet we use the augmentations proposed in [1]. For Omniglot, we follow the normal augmentation scheme in [3], applying one of random crop, affine transform, or perspective transform. During meta-testing the task-specific model is fine-tuned for 10 steps on Omniglot and CifarFS, and 20 steps on MiniImagenet.\nWhen applying BatMan-CLR on the meta-learners, we keep the same model sizes with the addition of a larger decision head: R128 rather than R5. The batch size of BatMan is set to 5 for all inner-loop adaptations, thereby resulting in mini batching for (Eigen) Reptile, and 15 for the meta-gradient calculation of iMAML and foMAML. For each support sample, 5 augmentations are created, whereas each query sample is augmented twice, allowing the inner-loop to sample more diverse tasks. The final reported testing accuracy is averaged over 3 test runs, using 2048 tasks sampled from Dtest."
        },
        {
            "heading": "4.2 Testing accuracy",
            "text": "The results of BatMan-CLR on noisy CifarFS and Omniglot are summarized in Table 2, and on MiniImagenet in Table 3. We report testing accuracy with both Man and BatMan for CifarFS and Omniglot. Prior to analyzing the results, we underline how all learners face significant degradation under label noise, as shown in Section 2.\nOmniglot and CifarFS. BatMan-CLR clearly strengthens the resilience of all learners on all three datasets, with only a marginal decrease in testing accuracy under label noise. On Omniglot (see Table 2, when encountering the label noise in meta-training, all learners can still learn effective initial models for task adaptation, reaching an accuracy of around 96%. In fact, all learners are able to display a performance under label noise similar to that without noise. On CifarFS, we observe similar results. Most learners reach a test accuracy between 62-64%, except when applying Man sampling on Eigen-Reptile. These results strongly validate the effectiveness of BatMan, which self-cleanses the \u2018shots\u2019 by creating contrastive pairs and \u2018ways\u2019 in batched Man samples.\nIn terms of comparison between BatMan and Man, there is a visible advantage in using BatMan, especially on the more difficult CifarFS. This suggests that taking steps with more information, as in BatMan, provides greater benefits than taking a larger number of simpler steps, as in Man. Zooming into the performance of different learners on CifarFS, the difference in testing accuracy between Man and BatMan on CifarFS is smaller with foMAML and iMAML, compared to Reptile and Eigen-Reptile. This can be explained by the fact that in our experiments, the MAML style learners use BatMan to calculate the meta-gradient, resulting in more informative meta-updates. Reptile learners do not calculate their meta-gradients using query data but directly using the inner-optimization direction.\nAn observation worth mentioning is that Eigen-Reptile paired with Man, deteriorates under noise on CifarFS. We speculate that this is due to the fact that in Eigen-Reptile the meta-gradient approximation is performed by selecting the optimization direction with the highest variance. However, a high level of noise introduces a high variance into the optimization directions, making it harder to select an appropriate direction even with the use of Man. By employing the less noisy BatMan estimation strategy, the learner is able to better select an optimization direction and achieves a performance comparable to Reptile.\nMiniImagenet. We further evaluate BatMan-CLR on MiniImagenet, a more difficult dataset consisting of more diverse classes and larger inputs. Table 3 summarizes the results. Under BatMan-CLR, the testing accuracy of most meta-learners has only limited drops, i.e., ranging between 0.5 and 1%."
        },
        {
            "heading": "4.3 Ablations",
            "text": "First, we consider the impact of supervised task generation by training meta-learners in a self-supervised learning (SSL) setting. Similar to UMTRA [8] and CACTUS [6], we construct (5, 5/15)-FSL tasks (MAML/Reptile) by drawing 5 random images from Dtrain. To construct the required shots, K +Q augmentations are created and split in a support and query set, such that |Dsupport| = K and |Dquery| = Q. Table 4 provides the results on Omniglot and CifarFS in the rows indicated with SSL. We use the same hyper-parameters and loss function as for BatMan-CLR, with the meta-batch size increased to 25 (from 5), so that learners see a comparable number of unique classes per meta-epoch.\nAlthough this approach shows similar performance to BatMan-CLR on Omniglot, on CifarFS there is a considerable gap of 11-13.8 percent points compared to BatMan-CLR (gray columns). This indicates that BatMan-CLR profits from seeing more unique classes and samples during each inner-loop.\nSecond, we replace BatMan with a random manifold sampler (Rand) to investigate the impact of the BatMan sampling strategy. Table 4 shows the results. We pair Rand with BatMan in different configurations for the inner and outer-loop, again evaluated on Omniglot and CifarFS. Reptile and Eigen-Reptile only use a support set during meta-training, so we only replace their inner-sampling strategy. We keep the same hyper-parameters as used in the corresponding BatMan-CLR setting.\nIn general, the learners trained with random sampling in the outer-loop show an increased accuracy as the noise level increases. Learners show an increase in accuracy of around 2-8% and 2-3% on Omniglot and CifarFS, comparing noise-less with \u03f5 = 0.6, whereas BatMan-CLR sees a slight drop while staying ahead of Rand across the board. This shows that BatMan has the capability to self-clean. An interesting exception is Omniglot combined with Eigen-Reptile when increasing the noise level to 0.3 from 0 (Table 4b). This is expected as higher noise levels increase the expected number of unique ground-truth classes in a task, thereby yielding fewer false negatives in each Rand manifold during contrastive learning. Replacing only the inner or outer-loop sampler for iMAML and foMAML with Rand, we see that the contribution of the inner-loop is less significant than the outer-loop. This shows that BatMan-CLR is also an effective strategy when replacing only the outer-loop (R/B)."
        },
        {
            "heading": "5 Conclusion",
            "text": "Motivated by the ubiquitous presence of label noise, we empirically unveil the impact of label noise on existing few-shot meta-learners, with a particular focus on noise in meta-training. As the number of shots per class is low, the label noise can be exceedingly detrimental to meta-learners and highly challenging to address. To enhance the resilience against label noise for few-shots learners, we propose BatMan\u2014a generic approach that turns supervised few-shot tasks into semi-supervised ones. BatMan is capable of self-cleansing noisy N -way K shots instances by (i) batch manifold sampling that re-constructs N -way 2-contrastive-shots via augmentation and (ii) introducing the DCL [24] contrastive loss. Our results on three datasets, Omniglot, CifarFS, and MiniImagenet, show that BatMan can maintain the effectiveness of few-shot learners independent of label noise levels, i.e., reserving almost 30% accuracy degradation.\nAs future work, we aim to explore further (label noisy) meta-testing paired with BatMan-CLR and adding class awareness [8, 20]. Further exploring the utility under the meta-testing setting of BatMan-CLR would be valuable to this work. Other loss functions can be explored, such as ProtoCLR [15]. Lastly, we consider limited types of label noise during meta-training, leaving for future work the extension to noise such as out-of-domain noise, asymmetric noise, or task-level corruption [23], as well as taking classes\u2019 semantics into account during noise generation."
        }
    ],
    "title": "BATMAN-CLR: MAKING FEW-SHOTS META-LEARNERS RESILIENT AGAINST LABEL NOISE",
    "year": 2023
}