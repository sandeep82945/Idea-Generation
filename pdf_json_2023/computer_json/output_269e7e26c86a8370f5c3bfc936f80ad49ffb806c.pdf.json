{
    "abstractText": "We introduce a new optimization algorithm, termed contrastive adjustment, for learning Markov transition kernels whose stationary distribution matches the data distribution. Contrastive adjustment is not restricted to a particular family of transition distributions and can be used to model data in both continuous and discrete state spaces. Inspired by recent work on noise-annealed sampling, we propose a particular transition operator, the noise kernel, that can trade mixing speed for sample fidelity. We show that contrastive adjustment is highly valuable in humancomputer design processes, as the stationarity of the learned Markov chain enables local exploration of the data manifold and makes it possible to iteratively refine outputs by human feedback. We compare the performance of noise kernels trained with contrastive adjustment to current state-of-the-art generative models and demonstrate promising results on a variety of image synthesis tasks.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ludvig Bergenstr\u030aahle"
        },
        {
            "affiliations": [],
            "name": "Jens Lagergren"
        },
        {
            "affiliations": [],
            "name": "Joakim Lundeberg"
        }
    ],
    "id": "SP:90f7e09531054b42c989fc03694660b25b7725d8",
    "references": [
        {
            "authors": [
                "Guillaume Alain"
            ],
            "title": "GSNs: Generative Stochastic Networks",
            "venue": "CoRR",
            "year": 2015
        },
        {
            "authors": [
                "Jacob Austin"
            ],
            "title": "Structured denoising diffusion models in discrete state-spaces",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2021
        },
        {
            "authors": [
                "Thomas Bachlechner"
            ],
            "title": "Rezero is all you need: Fast convergence at large depth",
            "venue": "Uncertainty in Artificial Intelligence. PMLR",
            "year": 2021
        },
        {
            "authors": [
                "Yilun Du",
                "Igor Mordatch"
            ],
            "title": "Implicit Generation and Modeling with Energy Based Models",
            "venue": "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems",
            "year": 2019
        },
        {
            "authors": [
                "Ian J. Goodfellow"
            ],
            "title": "Generative Adversarial Nets",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2014
        },
        {
            "authors": [
                "Anirudh Goyal"
            ],
            "title": "Variational Walkback: Learning a Transition Operator as a Stochastic Recurrent Net",
            "venue": "Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017,",
            "year": 2017
        },
        {
            "authors": [
                "Matej Grci\u0107",
                "Ivan Grub\u01d0si\u0107",
                "Sin\u01d0sa \u0160egvi\u0107"
            ],
            "title": "Densely connected normalizing flows",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2021
        },
        {
            "authors": [
                "Martin Heusel"
            ],
            "title": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium",
            "venue": "Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017,",
            "year": 2017
        },
        {
            "authors": [
                "Geoffrey E Hinton"
            ],
            "title": "Training products of experts by minimizing contrastive divergence",
            "venue": "Neural computation",
            "year": 2002
        },
        {
            "authors": [
                "Jonathan Ho",
                "Ajay Jain",
                "Pieter Abbeel"
            ],
            "title": "Denoising Diffusion Probabilistic Models",
            "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems",
            "year": 2020
        },
        {
            "authors": [
                "Emiel Hoogeboom"
            ],
            "title": "Argmax flows and multinomial diffusion: Learning categorical distributions",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2021
        },
        {
            "authors": [
                "Tero Karras"
            ],
            "title": "Progressive Growing of GANs for Improved Quality, Stability, and Variation",
            "venue": "International Conference on Learning Representations,",
            "year": 2018
        },
        {
            "authors": [
                "Tero Karras"
            ],
            "title": "Training Generative Adversarial Networks with Limited Data",
            "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems",
            "year": 2020
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A Method for Stochastic Optimization",
            "venue": "International Conference on Learning Representations,",
            "year": 2015
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Max Welling"
            ],
            "title": "Auto- Encoding Variational Bayes",
            "venue": "International Conference on Learning Representations,",
            "year": 2014
        },
        {
            "authors": [
                "Alex Krizhevsky",
                "Geoffrey Hinton"
            ],
            "title": "Learning multiple layers of features from tiny images",
            "year": 2009
        },
        {
            "authors": [
                "Chenlin Meng"
            ],
            "title": "Concrete Score Matching: Generalized Score Matching for Discrete Data",
            "venue": "CoRR abs/2211.00802",
            "year": 2022
        },
        {
            "authors": [
                "Nicki Skafte Detlefsen"
            ],
            "title": "TorchMetrics - Measuring Reproducibility in PyTorch. 2022",
            "venue": "doi: 10.21105/joss.04101",
            "year": 2022
        },
        {
            "authors": [
                "A\u00e4ron van den Oord"
            ],
            "title": "Conditional Image Generation with PixelCNN Decoders",
            "venue": "Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016,",
            "year": 2016
        },
        {
            "authors": [
                "Georg Ostrovski",
                "Will Dabney",
                "R\u00e9mi Munos"
            ],
            "title": "Autoregressive Quantile Networks for Generative Modeling",
            "venue": "Proceedings of the 35th International Conference on Machine Learning,",
            "year": 2018
        },
        {
            "authors": [
                "Danilo Jimenez Rezende",
                "Shakir Mohamed"
            ],
            "title": "Variational Inference with Normalizing Flows",
            "venue": "Proceedings of the 32nd International Conference on Machine Learning,",
            "year": 2015
        },
        {
            "authors": [
                "Olaf Ronneberger",
                "Philipp Fischer",
                "Thomas Brox"
            ],
            "title": "U-Net: Convolutional networks for biomedical image segmentation",
            "venue": "18th International Conference,",
            "year": 2015
        },
        {
            "authors": [
                "Jascha Sohl-Dickstein"
            ],
            "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics",
            "venue": "Proceedings of the 32nd International Conference on Machine Learning,",
            "year": 2015
        },
        {
            "authors": [
                "Jiaming Song",
                "Chenlin Meng",
                "Stefano Ermon"
            ],
            "title": "Denoising Diffusion Implicit Models",
            "venue": "International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Yang Song",
                "Stefano Ermon"
            ],
            "title": "Generative Modeling by Estimating Gradients of the Data Distribution",
            "venue": "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems",
            "year": 2019
        },
        {
            "authors": [
                "Yang Song"
            ],
            "title": "Score-Based Generative Modeling through Stochastic Differential Equations",
            "venue": "International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Ashish Vaswani"
            ],
            "title": "Attention is All you Need",
            "venue": "Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017,",
            "year": 2017
        },
        {
            "authors": [
                "Yinhuai Wang",
                "Jiwen Yu",
                "Jian Zhang"
            ],
            "title": "Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model",
            "venue": "ArXiv preprint abs/2212.00490",
            "year": 2022
        },
        {
            "authors": [
                "Fisher Yu"
            ],
            "title": "LSUN: Construction of a Large-Scale Image Dataset Using Deep Learning With Humans in the Loop",
            "venue": "ArXiv preprint abs/1506.03365",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "We introduce a new optimization algorithm, termed contrastive adjustment, for learning Markov transition kernels whose stationary distribution matches the data distribution. Contrastive adjustment is not restricted to a particular family of transition distributions and can be used to model data in both continuous and discrete state spaces. Inspired by recent work on noise-annealed sampling, we propose a particular transition operator, the noise kernel, that can trade mixing speed for sample fidelity. We show that contrastive adjustment is highly valuable in humancomputer design processes, as the stationarity of the learned Markov chain enables local exploration of the data manifold and makes it possible to iteratively refine outputs by human feedback. We compare the performance of noise kernels trained with contrastive adjustment to current state-of-the-art generative models and demonstrate promising results on a variety of image synthesis tasks."
        },
        {
            "heading": "1 Introduction",
            "text": "Generative models have emerged as a powerful tool with applications spanning a wide range of subject areas, from image, text, and audio synthesis in the creative arts to data analysis and molecule design in the sciences. The literature on generative models encompasses many different methods, including those based on variational autoencoders [15], autoregression [19], normalizing flows [21], adversarial optimization [5], and Markov chain Monte Carlo (MCMC) [25]. While often very general and applicable to many domains, different methods have distinct strengths and limitations. For example, adversarial methods can typically generate high-quality samples but are difficult to train on diverse datasets, while autoregressive models are easier to train but slow to sample from as they require sequential generation.\n\u2217Correspondence to: joakim.lundeberg@scilifelab.se\nIn this paper, we introduce contrastive adjustment, an optimization algorithm for learning arbitrary Markov transition operators whose stationary distribution matches an unknown data distribution. The learned transition operators obey detailed balance and can be used to quickly generate variants of existing data, making them exceptionally suited for human-in-the-loop design processes. Additionally, inspired by recent work [10, 25] on noise-annealed sampling, we propose noise kernels, a specific transition model that can be learned with contrastive adjustment and allows for efficient de novo synthesis by modeling the data distribution over multiple noise levels. We find that noise kernels trained with contrastive adjustment produce diverse, high-quality samples on image datasets of different resolutions (Figure 1). To further demonstrate their flexibility,\nar X\niv :2\n30 3.\n05 49\n7v 2\n[ cs\n.L G\n] 1\n7 M\nar 2\n02 3\nwe allow noise kernels to be conditioned on partial data and illustrate how they can be used to inpaint missing image regions without retraining. We find that contrastive adjustment and noise kernel transition models are straightforward to implement, can be applied to both discrete and continuous data domains, and show promising performance on a variety of image synthesis tasks."
        },
        {
            "heading": "2 Method",
            "text": "The goal of contrastive adjustment is to learn a reversible Markov transition kernel p(y | x) = p(Xt+1 = y | Xt = x) whose stationary distribution matches an unknown data distribution p(x). At optimality, the transition distribution adheres to the detailed balance criterion,\np(x)p(y | x) = p(y)p(x | y). (1)\nContrastive adjustment learns the transition distribution by iterative adjustments; when Bxy = p(x)p(y | x)\u2212p(y)p(x | y) > 0 for some values x, y, we decrease p(y | x) and increase p(x | y). Note that since the data distribution p(x) is unknown, we cannot evaluate Bxy directly. The central idea of contrastive adjustment is that directionally accurate updates to the transition distribution can still be estimated by Monte Carlo sampling. Specifically, we take a sample from the one-step process (x, y) \u223c p(x)p(y | x) and decrease the probability of the forward transition p(y | x) while increasing the probability of the backward transition p(x | y) (Algorithm 1). Assuming symmetric updates and disregarding normalization constraints, the expected adjustment of p(y | x) is negative when Bxy > 0 and positive when Bxy < 0. Incremental updates proceed until p(x)p(y | x) = p(y)p(x | y) for\nAlgorithm 1 High-level description\nInput: data distribution p(x), transition distribution p(y | x) repeat\nSample x \u223c p(x) Sample y \u223c p(y | x) Decrease p(y | x) Increase p(x | y)\nuntil convergence\nAlgorithm 2 Gradient-based adjustments\nInput: data distribution p(x), transition model p\u03b8(y | x), weights \u03b8, learning rate \u03b7 repeat\nSample x \u223c p(x) Sample y \u223c p\u03b8(y | x) g \u2190 \u2207\u03b8 log p\u03b8(x | y) \u03b8 \u2190 \u03b8 + \u03b7g\nuntil convergence\nall x, y, whereby downward and upward adjustments cancel out in expectation (Figure 2).\nIn most practical applications, p\u03b8(y | x) will be parameterized by a neural network with weights \u03b8. While several different adjustment functions are possible, a natural choice is updating \u03b8 in the direction or anti-direction of the gradient of the log transition probabilities. Noting that the expected update to \u03b8 from downward adjustments then is\nEp(x)p(y|x) [\u2212\u2207\u03b8 log p\u03b8(y | x)] = \u2212 \u222b\u222b p(x)p\u03b8(y | x)\u2207\u03b8 log p\u03b8(y | x) dxdy (2)\n= \u2212 \u222b\u222b p(x)\u2207\u03b8p\u03b8(y | x) dxdy (3)\n= \u2212\u2207\u03b8 \u222b\u222b p(x)p\u03b8(y | x) dxdy = \u2212\u2207\u03b81 = 0, (4)\nwe can implement gradient-based contrastive adjustment without performing the downward adjustment step, as described in Algorithm 2."
        },
        {
            "heading": "2.1 Noise kernel transition models",
            "text": "The transition model determines the dynamics of the learned Markov chain and is thus a crucial component of contrastive adjustment. It should be able to capture the modes of the data but also allow for efficient sampling. One of the key insights of Song and Ermon [25] is that it is possible to trade off between these two objectives by modeling the data over different noise levels. Specifically, at higher noise levels, the data\ndistribution is flatter, allowing the transition kernel to take larger steps without falling off the data manifold. At lower noise levels, the mixing speed is slower but sample fidelity higher. Consequently, one can attain both efficient mixing and high sample fidelity by switching between high and low noise regimes.\nMotivated by this idea, we propose to learn a specific class of transition distributions, which we will refer to as noise kernels, for modeling noisy representations of the data. To define a noise kernel, let p(z) be the data distribution and p(x | z) a distribution that adds noise to a non-noisy example z. Suppose the marginal density for a transition from x to y at some step in the chain can be modeled by the joint distribution\np(z, x, y) = p(z)p(x | z)p(y | z, x), (5)\nwhere the last term is the conditional transition probability from x to y, defined so that\np(x | z)p(y | z, x) = p(y | z)p(x | z, y). (6)\nUnder this framework, the transition distribution is given by the marginal\np(y | x) = \u222b p(z | x)p(y | z, x) dz, (7)\nwhere p(z | x) is a denoising distribution. Note that the transition distribution (7) adheres to the detailed balance criterion, since\np(x)p(y | x) = \u222b p(z)p(x | z)p(y | z, x) dz (8)\n= \u222b p(z)p(y | z)p(x | z, y) dz (9)\n= p(y)p(x | y), (10)\nwhere the second equality follows from Equation (6).\nIn general, we cannot solve Equation (7) for the denoising distribution p(z | x) analytically, but we can replace it with a learnable distribution r\u03b8(z | x) parameterized by weights \u03b8, giving us the approximate transition model\np\u03b8(y | x) = \u222b r\u03b8(z | x)p(y | z, x) dz. (11)\nBy selecting r\u03b8 appropriately, we can ensure the integral in Equation (11) is tractable and that p\u03b8 is identifiable by the distribution parameters of r\u03b8 (cf. Sections 2.3 and 2.4). The distribution r\u03b8 can then be used as a denoiser to reconstruct samples in observation space.\nSince noise kernels are equilibrium models according to Equation (10), they are learnable by contrastive\nadjustment. In this case, the data distribution in Algorithm 2 is the noisy distribution p(x) = \u222b p(z)p(x | z) dz. While it should be noted that there could be multiple transition models p\u03b8 consistent with detailed balance, we did not find this to be a problem in practice. As an alternative to contrastive adjustment, noise kernels can also be learned by optimizing r\u03b8 with a reconstruction loss or by minimizing the KullbackLeibler divergence between Equation (7) and Equation (11). However, we generally found contrastive adjustment to produce better results."
        },
        {
            "heading": "2.2 Non-equilibrium transitions",
            "text": "As discussed in Section 2.1, efficient mixing and high sample fidelity can be achieved by switching between high and low noise regimes. While contrastive adjustment learns a reversible Markov chain, it is straightforward to extend Equation (11) to allow for nonequilibrium transitions over different noise levels at inference time. Specifically, instead of requiring the conditional transition distribution to obey the detailed balance criterion (6), we now let it depend on the step t of the chain and require only that\u222b\npt(x | z)pt(y | z, x) dz = pt+1(y | z), (12)\nwhere pt(\u00b7 | z) is a time-dependent noise distribution. The transition model is then defined as\npt\u03b8(y | x) = \u222b rt\u03b8(z | x)pt(y | z, x) dz, (13)\nwhere we let the denoising model rt\u03b8(z | x) = r\u03b8(z | x, \u03b2t) depend on the noise level \u03b2t at step t.\nTraining is the same as in Section 2.1, except that a separate transition model is learned for each noise level. In practice, we share the weights \u03b8 of the denoising model r\u03b8 over an infinite number of noise levels \u03b2 \u2208 (0, 1) and, similar to [10], condition r\u03b8 on a sinusoidal position embedding of \u03b2. During training, we sample \u03b2 uniformly from the range (0, 1) for each example."
        },
        {
            "heading": "2.3 Continuous noise kernels",
            "text": "We are now ready to define concrete examples of noise kernels for continuous and categorical data. In the continuous case, we will use an isotropic Gaussian noise distribution:\npt(x | z) = N (x | \u03b1tz, \u03b2tI) , (14)\nwhere \u03b2t and \u03b1t determine the noise level at step t. To improve the stability of the kernel, we introduce a\ndependency on the previous state in the conditional transition distribution:\npt(y | z, x) = N (y | wx+ at+1z, bt+1I), (15)\nwhere w is a scalar hyperparameter and we have used I to denote the identity matrix. The scalars at+1 and bt+1 can be derived from the conditions (6) and (12) for equilibrium and non-equilibrium transitions, respectively. In the non-equilibrium case, we can make use of the following proposition:\nProposition 1. Consider the joint distribution p(X,Y ) = p(X)p(Y | X), where p(X) = N(X | \u00b5, \u03c32) and p(Y | X) = N(Y | aX + b, c2). Then the marginal distribution of Y is given by p(Y ) = N(Y | a\u00b5+ b, c2 + a2\u03c32).\nSince (14) and (15) are diagonal Gaussians, we can apply Proposition 1 dimension-wise with X = x, Y = y, \u00b5 = \u03b1tz, \u03c3 2 = \u03b2t, a = w, b = at+1z, and c 2 = bt+1 to obtain\nw\u03b1tz + at+1z = \u03b1t+1z \u21d2 at+1 = \u03b1t+1 \u2212 w\u03b1t (16) bt+1 + w 2\u03b2t = \u03b2t+1 \u21d2 bt+1 = \u03b2t+1 \u2212 w2\u03b2t. (17)\nAs stated by the following proposition, we do not need to treat the equilibrium case separately:\nProposition 2. If the noise level is constant over time, so that \u03b2t = \u03b2 and \u03b1t = \u03b1 for all t, then the continuous noise kernel defined by Equations (14) to (17) satisfies the detailed balance criterion (6).\nProofs of Propositions 1 and 2 are provided in Appendix B.\nTo derive the transition model pt\u03b8, we define\nrt\u03b8(z | x) = N ( z | \u00b5\u03b8(x, \u03b2t), \u03c32\u03b8(x, \u03b2t)I ) , (18)\nwhere \u00b5\u03b8 and \u03c3 2 \u03b8 are deep neural networks parameterized by weights \u03b8. We can now use Proposition 1 again but with X = z, Y = y, \u00b5 = \u00b5\u03b8(x, \u03b1t), \u03c32 = \u03c32\u03b8(x, \u03b1t), a = at+1, b = wx, and c\n2 = bt+1 to compute Equation (11), giving us the transition model\npt\u03b8(y | x) = N (y | mt+1, s2t+1I), (19)\nwhere\nmt+1 = wx+ (\u03b1t+1 \u2212 w\u03b1t)\u00b5\u03b8(x, \u03b1t) (20) s2t+1 = \u03b2t+1 \u2212 w2\u03b2t + (\u03b1t+1 \u2212 w\u03b1t)2\u03c32\u03b8(x, \u03b1t).\n(21)"
        },
        {
            "heading": "2.4 Categorical noise kernels",
            "text": "For categorical data, we follow [2] and use an absorbing state noise process. We assume the data is Ddimensional and that each dimension can take on one of K values. Then, the noisy data has K + 1 categories, where the last category is an absorbing state, indicating that the underlying value has been masked. For every element i of the data, the noise distribution replaces its value zi by the absorbing state K+1 with probability \u03b2t:\npt(xi | z) = Cat (xi | (1\u2212 \u03b2t)1zi + \u03b2t1K+1) , (22)\nwhere 1a denotes the one-hot encoding of a value a in K + 1 categories. As in Section 2.3, we let the conditional transition distribution depend on the previous state to improve the stability of the chain:\npt(yi | z, x) = Cat ( yi | (1\u2212 bt+1)w1xi+\n+ (1\u2212 bt+1)(1\u2212 w)1zi + bt+11K+1 ) , (23)\nwhere w is a scalar hyperparameter controlling the mixing speed of the kernel. We select bt+1 to ensure the discrete analogs of conditions (6) and (12). For the non-equilibrium case, note that Equations (22) and (23) mean that yi either takes on the value zi or K + 1, and that the latter happens with probability\npt(yi = K + 1 | z) = (1\u2212 bt+1)w\u03b2t + bt+1. (24)\nWe therefore must have\n(1\u2212 bt+1)w\u03b2t + bt+1 = \u03b2t+1 \u21d2 bt+1 = (\u03b2t+1 \u2212 w\u03b2t)/(1\u2212 w\u03b2t). (25)\nSimilar to the noise kernel described in Section 2.3, we do not need to treat the equilibrium case separately:\nProposition 3. If the noise level is constant over time, so that \u03b2t = \u03b2 for all t, then the categorical noise kernel defined by Equations (22), (23) and (25) satisfies the detailed balance criterion (6).\nA proof of Proposition 3 is provided in Appendix B.\nWe model the denoising distribution as rt\u03b8(zi | x) = Cat ( zi | f i\u03b8(x, \u03b1t) ) , (26)\nwhere f i\u03b8 is a deep neural network parameterized by weights \u03b8 with output indexed by i. Inserting Equations (23) and (26) into the discrete version of Equation (11), we get the transition model\npt\u03b8(yi | x) = Cat ( yi | (1\u2212 bt+1)w1xi+\n+ (1\u2212 bt+1)(1\u2212 w)f i\u03b8(x, \u03b1t) + bt+11K+1 ) . (27)"
        },
        {
            "heading": "3 Experiments",
            "text": "We evaluate the performance of noise kernels optimized by contrastive adjustment on a number of image synthesis tasks. The transition models are defined as in Sections 2.3 and 2.4, and we parameterize r\u03b8 by a U-Net [22] architecture similar to the one used by Hoogeboom et al. [11]. For continuous noise kernels, we use w = 0.5 and set \u03b1t = 1 \u2212 \u03b2t. For categorical noise kernels, we use w = 0.95. The models are trained as in Algorithm 2 but with minibatch gradient descent using the Adam optimizer [14]. Implementation details are provided in Appendix A."
        },
        {
            "heading": "3.1 Image synthesis: continuous data",
            "text": "To generate images, we sample x0 \u223c N (0, I) and run the Markov chain forward while linearly annealing the noise level from \u03b20 = 1.0 to \u03b2T = 0.01 over T = 100 steps. The generated images are denoised by taking the mean of r\u03b8(z | xT ).\nWe compare the image synthesis performance of noise kernels trained with contrastive adjustment to other state-of-the-art generative models on CIFAR-10 (Table 1). Contrastive adjustment attains an average FID score of 18.27 over five independent runs, which is lower than the top performing normalizing flow, autoregressive, and energy-based models, but higher than the best score-based, diffusion, and adversarial models. Uncurated samples are presented in Appendix E.\nTo investigate the performance of contrastive adjustment on higher-resolution images, we additionally train noise kernels on the LSUN Church (cropped and resized to 128 \u00d7 128) and CelebA-HQ (resized to 256 \u00d7 256) datasets. Figure 3 shows traces of the sampling process and representative samples from our models. Overall, we find generated images to be diverse and well-composed. On LSUN Church, our model attains a competitive FID score of 9.40. Uncurated samples are presented in Appendices C and D."
        },
        {
            "heading": "3.2 Image synthesis: categorical data",
            "text": "Categorical data is non-ordinal and therefore typically more challenging to model than continuous or ordered discrete data, as the relationships between categories is not self-evident. To keep consistency\nwith our evaluations on continuous data, we again evaluate the performance of contrastive adjustment on CIFAR-10 but note that categorical data models are not ideal for image datasets, since pixel intensity values are ordered. While it would be possible to adapt noise kernel models for ordered discrete data, for example by restricting the transition distribution to only allow transitions between adjacent categories, we leave these adaptations for future work.\nTo make it easier for the model to learn how categories are related, we discretize pixel intensities into 10 categories. Samples are generated by setting all elements of x0 to 1K+1 and running the Markov chain for T = 500 steps while linearly annealing \u03b2t from 1.0 to 0.5. Comparing generated samples to the discretized dataset, our model attains a FID score of 14.76. Uncurated samples are presented in Appendix F."
        },
        {
            "heading": "3.3 Variant generation",
            "text": "Variant generation allows human input to guide the sampling process by iteratively refining synthesized outputs. Such design processes could be highly valuable in many different fields, including not only the production of art and music but also, for example, the discovery of new molecules for drug development. As an MCMC-based generative model, contrastive adjustment is especially suited for this task, as it allows for local exploration of the data manifold by sequential sampling. Variants are generated by starting from an example x0 and running the Markov chain forward a desired number of steps. The noise scale \u03b2t can be adjusted to control the amount of variation added in each step.\nWe exemplify variant generation using contrastive adjustment in Figure 4, where we start with an image from the LSUN Church dataset and run the Markov chain for T = 100 steps at a constant noise level \u03b2 = 0.2 in order to generate variants of the original image. After each generation, we select one of the outputs to create new samples from and repeat the process. To illustrate the diversity of variants that can be produced in this way, we generate two distinct trajectories that select for different visual attributes in the images. Additional variant generation traces are provided in Appendix G."
        },
        {
            "heading": "3.4 Inpainting",
            "text": "Inpainting is the task of filling in missing regions of an image and is an important tool in image editing and restoration. Noise kernels can be conditioned on existing data without retraining by fixing the denois-\ning distribution r\u03b8 to be a point mass at the observed image pixels. Concretely, let z\u0304 be the original image and M a binary mask, where Mij = 1 if pixel (i, j) is to be inpainted and Mij = 0 otherwise. Where Mij = 0, we modify the denoising model r\u03b8 to be a delta distribution centered at z\u0304. In the case of continuous data, we then have instead of Equations (20) and (21):\nmt+1 = wx+ (\u03b1t+1 \u2212 \u03b1tw)( M\u00b5\u03b8(x, \u03b1t) + (1\u2212M)z\u0304) (28)\ns2t+1 = (\u03b2t+1 \u2212 w2\u03b2t)+ (\u03b1t+1 \u2212 \u03b1tw)2M\u03c32\u03b8(x, \u03b1t). (29)\nFigure 5 shows inpainting results on CelebA-HQ where we have masked out randomly selected 16\u00d7 16 tiles of the original images. We find that the model is able to generate coherent and realistic inpaintings even when large parts of the original image has been masked out. Additional inpainting results for different mask types are provided in Appendix H."
        },
        {
            "heading": "4 Related work",
            "text": "Walkback and variational walkback Contrastive adjustment is closely related to the walkback algorithm in Generative Stochastic Networks (GSNs) [1]. GSNs form a Markov chain by alternating sampling from a corruption process and a denoising distribution. The walkback algorithm runs the chain forward a variable number of steps starting with an example from the dataset and then updates the denoising distribution to increase the backward log-likelihood of the original example. In contrast to contrastive adjustment, GSNs use different forward and backward models and do not contrast the transition probabilities of time-adjacent states. Instead, GSNs are trained so that the denoising model can undo, or \u201cwalk back\u201d from, the noise generated by the forward process in one step.\nThe variational walkback algorithm [6] introduces a finite Markov chain that transitions from low- to hightemperature sampling. Similar to contrastive adjustment, variational walkback uses the same forward and backward models. However, variational walkback does not attempt to learn an equilibrium process, where the transition operator obeys detailed balance. Instead, the algorithm is derived from a variational objective that maximizes a lower bound on the evidence of the initial state of the chain.\nContrastive divergence The idea of contrasting examples from the data distribution with one-step\nMCMC perturbations induced by the model being learned is similar in spirit to contrastive divergence [9], which is used to estimate the gradient of the log-likelihood in energy-based models. While the learned energy model can be used for MCMC-based sampling, contrastive divergence does not explicitly learn a transition kernel.\nDiffusion models Sampling data by noise annealing has been studied extensively in recent works. Denoising diffusion probabilistic models and their derivatives [10, 23] have gained wide-spread popularity and achieved state-of-the-art results on many data synthesis tasks. Notably, the continuous and categorical noise kernels studied in this work are similar to the non-Markovian inference models proposed by Song, Meng, and Ermon [24] but can also be used for stationary chains. Additionally, score-based generative models, such as noise conditional score networks (NCSNs) [25], can, similar to contrastive adjustment, learn stationary sampling distributions. However, they are limited to Langevin sampling and do not allow arbitrary transition operators. As a consequence, NCSNs cannot, for example, be used to model categorical data without extensive modifications [17]."
        },
        {
            "heading": "5 Limitations and future work",
            "text": "We have presented a first exposition of contrastive adjustment and its applications to generative modeling. As such, there are several promising avenues for future research.\nFirst, we have left a formal treatment of the convergence properties of contrastive adjustment to future work. While we have empirically found contrastive adjustment to be well-behaved, it is not clear under which conditions it is guaranteed to converge and what the convergence rate is.\nSecond, we have studied the performance of contrastive adjustment only on image datasets. Nevertheless, the flexibility of contrastive adjustment and its ability to model both continuous and discrete data domains make it highly promising also for other modalities, including text and audio.\nFinally, similarities between noise kernels and denoising diffusion probabilistic models open up for several potential cross-breeding opportunities. For example, recent progress on conditional diffusion models [28, 30] could be incorporated into our models to improve their generative capabilities. We hope future work will explore these and other research directions."
        },
        {
            "heading": "20% 40% 60%",
            "text": ""
        },
        {
            "heading": "6 Conclusion",
            "text": "We have proposed contrastive adjustment for learning Markov chains whose stationary distribution matches the data distribution. Contrastive adjustment is easy to implement and can be applied to both continuous and discrete data domains. A notable strength of our models is their ability to efficiently generate variants of provided data, making it possible to locally explore the data manifold and to bring in human competence and guidance in iterative human-computer design loops. We have found their performance to be close to current state-of-the-art generative models for image synthesis and expect results could be improved by future adaptations and tuning.\nBroader impact\nOur research adds to a growing body of work on neural generative models. Powerful generative models are likely to have a large impact on society in the near future. On the one hand, they have the potential to improve productivity and creative output in a wide range of professions. On the other hand,\nthey may also cause considerable harm in a number of ways. In the short term, productivity gains from generative models may cause significant worker displacement. In the longer term, several ethical issues may arise. For example, given their ability to generate realistic representations of real-world objects and persons, generative models may be used to create misleading content that can be used to deceive the public or for other malicious purposes. Furthermore, when used in decision-making systems, it is important to consider potential biases in the training data, as these may be propagated by the model and thus affect the fairness of the system. Data verifiability and model explainability will likely be key topics in mitigating these downsides. Overall, given the disruptive potential of generative models, it is crucial that they are deployed with care and that the research community continues to engage in an open dialogue with the public about their capabilities and limitations in order to minimize potential risks while enabling the large potential benefits they stand to give to society.\nSoftware and data availability\nCode for the experiments in this paper is available at https://github.com/ludvb/nkca. The CIFAR10 [16], CelebA-HQ [12], and LSUN Church [29] datasets are available from their respective official sources."
        },
        {
            "heading": "Acknowledgments",
            "text": "This project has received funding from the European Research Council (ERC) under the European Union\u2019s Horizon 2020 research and innovation programme (grant agreement no. 101021019). This work was also supported by the Knut and Alice Wallenberg foundation, the Erling-Persson family foundation, the Swedish Cancer Society, and the Swedish Research Council."
        },
        {
            "heading": "A Experimental details",
            "text": "The denoising model r\u03b8 largely follows the architecture used in Hoogeboom et al. [11], which is a U-Net [22] with two residual blocks and a residual linear self-attention layer at each resolution. We make some minor modifications by adding ReZero [3] to every residual connection, removing the dropout layers, and moving the self-attention layers to between the residual blocks. Following [10], the noise level is encoded using a sinusoidal position embedding [27] that is added to the data volume in each residual block.\nOur CIFAR-10 and LSUN Church models use a channel size of 128 and a 4-level deep U-Net with channel multipliers (1, 2, 4, 8) and consist of 118 million parameters. Our CelebA-HQ model uses a channel size of 256 and a 6-level deep U-Net with channel multipliers (1, 1, 2, 2, 4, 4) and consists of 272 million parameters.\nHyperparameter selection for w and the final noise level \u03b2T were performed on CIFAR-10 with line search using FID as the evaluation metric. Selected values were reused for the other datasets.\nThe CelebA-HQ model was trained for 437 500 iterations (500 epochs) with a batch size of 32 on four NVIDIA A100 GPUs with no data augmentation. The LSUN Church model was trained for 1 972 500 iterations (500 epochs) with a batch size of 32 on a single NVIDIA A100 GPU with no data augmentation. The continuous CIFAR-10 model was trained for 273 700 iterations (700 epochs) with a batch size of 128 on a single NVIDIA A100 GPU with random horizontal flips. The categorical CIFAR-10 model was trained for 49 000 iterations (500 epochs) with a batch size of 512 on a single NVIDIA A100 GPU with random horizontal flips. We used the Adam optimizer [14] with a learning rate of 1\u00d7 10\u22124 in all experiments except for the CelebA-HQ model, where we used a learning rate of 2\u00d7 10\u22125. Evaluation weights were computed as exponential moving averages of training weights with a decay rate of 0.999.\nFID and Inception scores were computed using Torchmetrics [18]. All evaluations were made against the training set of the respective dataset. The generated dataset sizes were the same as the training set sizes, i.e., 50 000 for CIFAR-10, 126 227 for LSUN Church, and 28 000 for CelebA-HQ."
        },
        {
            "heading": "B Proofs",
            "text": "Proposition 1. Consider the joint distribution p(X,Y ) = p(X)p(Y | X), where p(X) = N(X | \u00b5, \u03c32) and p(Y | X) = N(Y | aX+b, c2). Then the marginal distribution of Y is given by p(Y ) = N(Y | a\u00b5+b, c2+a2\u03c32).\nProof. The density of the joint distribution can be written as p(X,Y ) \u221d exp ( \u2212 (X \u2212 \u00b5) 2\n2\u03c32 \u2212 (Y \u2212 (aX + b)) 2 2c2\n) (30)\n\u221d exp ( \u2212 ( 1\n2\u03c32 +\na2\n2c2\n) X2 \u2212 1\n2c2 Y 2 +\na c2 XY +\n( \u00b5\n\u03c32 \u2212 ab c2\n) X + b\nc2 Y\n) . (31)\nWe therefore have\np(Y ) = \u222b p(X,Y ) dX (32)\n\u221d \u222b exp ( \u2212 ( 1\n2\u03c32 +\na2\n2c2\n) X2 \u2212 1\n2c2 Y 2 +\n( \u00b5\n\u03c32 + a(Y \u2212 b) c2\n) X + b\nc2 Y\n) dX (33)\n= exp ( \u2212 1\n2c2 Y 2 +\nb\nc2 Y\n)\u222b exp ( \u2212 ( 1\n2\u03c32 +\na2\n2c2 ) ( X2 \u2212 2 ( \u00b5\n2\u03c32 + a(Y \u2212 b) 2c2\n)/( 1\n2\u03c32 +\na2\n2c2\n) X )) dX (34)\n= exp ( \u2212 1\n2c2 Y 2 +\nb\nc2 Y\n) exp (( \u00b5\n2\u03c32 + a(Y \u2212 b) 2c2\n)2/( 1\n2\u03c32 +\na2\n2c2\n))\n\u222b exp ( \u2212 ( 1\n2\u03c32 +\na2\n2c2\n)( X \u2212 ( \u00b5\n2\u03c32 + a(Y \u2212 b) 2c2\n)/( 1\n2\u03c32 +\na2\n2c2\n))2) dX (35)\n\u221d exp ( \u2212 1\n2c2 Y 2 +\nb\nc2 Y +\n( \u00b5\n2\u03c32 + a(Y \u2212 b) 2c2\n)2/( 1\n2\u03c32 +\na2\n2c2\n)) (36)\n\u221d exp ( \u2212 ( 1\n2c2 \u2212 a\n2\n4c4\n/( 1\n2\u03c32 +\na2\n2c2\n)) Y 2 + ( b\nc2 + a c2\n( \u00b5\n\u03c32 \u2212 ab c2\n)/( 1\n\u03c32 + a2 c2\n)) Y ) (37)\n= exp ( \u2212 1\n2(c2 + a2\u03c32) Y 2 + 2\na\u00b5+ b\n2(c2 + a2\u03c32) Y\n) (38)\n\u221d exp ( \u2212 (Y \u2212 (a\u00b5+ b)) 2\n2(c2 + a2\u03c32)\n) , (39)\nwhere the proportionality (36) follows from the fact that the integrand is proportional to a Gaussian density and the integral of a density over its support is equal to one. Equation (39) means p(Y ) = CN(Y | a\u00b5 + b, c2 + a2\u03c32) for some constant C. Since p(Y ) is a density function, we must have C = 1, completing the proof.\nProposition 2. If the noise level is constant over time, so that \u03b2t = \u03b2 and \u03b1t = \u03b1 for all t, then the continuous noise kernel defined by Equations (14) to (17) satisfies the detailed balance criterion (6).\nProof. Consider an element i of the data. From Equations (15) to (17), we have\np(yi | z, xi) = N(yi | wxi + (1\u2212 w)\u03b1zi, (1\u2212 w2)\u03b2). (40)\nUsing (31) with X = xi, Y = yi, \u00b5 = \u03b1zi, \u03c3 2 = \u03b2, a = w, b = (1\u2212 w)\u03b1zi, and c2 = (1\u2212 w2)\u03b2, p(xi | z)p(yi | z, xi) \u221d exp ( \u2212 ( 1\n2\u03b2 +\nw2\n2(1\u2212 w2)\u03b2\n) x2i \u2212\n1\n2(1\u2212 w2)\u03b2 y2i +\nw\n(1\u2212 w2)\u03b2 xiyi\n+ ( \u03b1zi \u03b2 \u2212 w(1\u2212 w)\u03b1zi (1\u2212 w2)\u03b2 ) xi + (1\u2212 w)\u03b1zi (1\u2212 w2)\u03b2 yi ) (41)\n= exp ( \u2212 1 2(1\u2212 w2)\u03b2 ( x2i + y 2 i ) +\nw\n(1\u2212 w2)\u03b2 xiyi + \u03b1zi (1 + w)\u03b2 (xi + yi)\n) . (42)\nWe can see that (42) is symmetric in xi and yi, whereby p(xi | z)p(yi | z, xi) = p(yi | z)p(xi | z, yi) for all xi, yi. It follows that\np(x | z)p(y | z, x) = \u220f i p(xi | z)p(yi | z, xi) = \u220f i p(yi | z)p(xi | z, yi) = p(x | z)p(y | z, x), (43)\nas required.\nProposition 3. If the noise level is constant over time, so that \u03b2t = \u03b2 for all t, then the categorical noise kernel defined by Equations (22), (23) and (25) satisfies the detailed balance criterion (6).\nProof. Consider an element i of the data. Sampling Xit and X i t+1 by Equations (22) and (23), there are four possible outcomes: (Xit , X i t+1) = (zi, zi), (X i t , X i t+1) = (K + 1,K + 1), (X i t , X i t+1) = (zi,K + 1), and (Xit , X i t+1) = (K + 1, zi). The first two outcomes are symmetric in X i t and X i t+1 and therefore trivially balanced. It remains to show that the last two outcomes have equal probability. Using (25) and the fact that \u03b2t = \u03b2 for all t, we have b = \u03b2(1\u2212 w)/(1\u2212 w\u03b2) and hence\np(Xit = zi | z)p(Xit+1 = K + 1 | z,Xit = zi) = (1\u2212 \u03b2)b (44) = \u03b2(1\u2212 w)(1\u2212 \u03b2)/(1\u2212 w\u03b2) (45)\np(Xit = K + 1 | z)p(Xit+1 = zi | z,Xit = K + 1) = \u03b2(1\u2212 b)(1\u2212 w) (46) = \u03b2(1\u2212 w)(1\u2212 (1\u2212 w)\u03b2/(1\u2212 w\u03b2)) (47) = \u03b2(1\u2212 w)(1\u2212 \u03b2)/(1\u2212 w\u03b2). (48)\nTherefore, p(xi | z)p(yi | z, xi) = p(yi | z)p(xi | z, yi) for all xi, yi. Since p(x | z) and p(y | z, x) are element-wise factorized, this also means that\np(x | z)p(y | z, x) = \u220f i p(xi | z)p(yi | z, xi) = \u220f i p(yi | z)p(xi | z, yi) = p(y | z)p(x | z, y), (49)\nas required."
        },
        {
            "heading": "C Extended image synthesis results: LSUN Church",
            "text": ""
        },
        {
            "heading": "D Extended image synthesis results: CelebA-HQ",
            "text": "E Image synthesis results: CIFAR-10\nF Image synthesis results: CIFAR-10 (categorical)"
        },
        {
            "heading": "G Extended variant generation results",
            "text": ""
        },
        {
            "heading": "H Extended inpainting results",
            "text": ""
        }
    ],
    "title": "Learning Stationary Markov Processes with Contrastive Adjustment",
    "year": 2023
}