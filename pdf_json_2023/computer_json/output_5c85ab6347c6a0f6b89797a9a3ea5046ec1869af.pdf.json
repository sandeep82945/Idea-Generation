{
    "abstractText": "Accurately localizing objects in three dimensions (3D) is crucial for various computer vision applications, such as robotics, autonomous driving, and augmented reality. This task finds another important application in sports analytics and, in this work, we present a novel method for 3D basketball localization from a single calibrated image. Our approach predicts the object\u2019s height in pixels in image space by estimating its projection onto the ground plane within the image, leveraging the image itself and the object\u2019s location as inputs. The 3D coordinates of the ball are then reconstructed by exploiting the known projection matrix. Extensive experiments on the public DeepSport dataset, which provides ground truth annotations for 3D ball location alongside camera calibration information for each image, demonstrate the effectiveness of our method, offering substantial accuracy improvements compared to recent work. Our work opens up new possibilities for enhanced ball tracking and understanding, advancing computer vision in diverse domains. The source code of this work is made publicly available at https://github.com/ gabriel-vanzandycke/deepsport.",
    "authors": [
        {
            "affiliations": [],
            "name": "Marcello Davide Caio"
        },
        {
            "affiliations": [],
            "name": "Gabriel Van Zandycke"
        },
        {
            "affiliations": [],
            "name": "Christophe De Vleeschouwer"
        }
    ],
    "id": "SP:e70636643eb24a4739d2027f93220c45b4cb7565",
    "references": [
        {
            "authors": [
                "Baljinder Bal",
                "Gaurav Dureja"
            ],
            "title": "Hawk Eye: A Logical Innovative Technology Use in Sports for Effective Decision Making",
            "venue": "Sport Science Review,",
            "year": 2012
        },
        {
            "authors": [
                "Hua Tsung Chen",
                "Ming Chun Tien",
                "Yi Wen Chen",
                "Wen Jiin Tsai",
                "Suh Yin Lee"
            ],
            "title": "Physics-based ball tracking and 3D trajectory reconstruction with applications to shooting location estimation in basketball video",
            "venue": "Journal of Visual Communication and Image Representation,",
            "year": 2009
        },
        {
            "authors": [
                "Hua Tsung Chen",
                "Wen Jiin Tsai",
                "Suh Yin Lee",
                "Jen Yu Yu"
            ],
            "title": "Ball tracking and 3D trajectory approximation with applications to tactics analysis from single-camera volleyball sequences",
            "venue": "Multimedia Tools and Applications,",
            "year": 2012
        },
        {
            "authors": [
                "Xina Cheng",
                "Norikazu Ikoma",
                "Masaaki Honda",
                "Takeshi Ikenaga"
            ],
            "title": "Simultaneous physical and conceptual ball state estimation in volleyball game analysis",
            "venue": "IEEE Visual Communications and Image Processing,",
            "year": 2017
        },
        {
            "authors": [
                "Varuna De Silva",
                "Mike Caine",
                "James Skinner",
                "Safak Dogan",
                "Ahmet Kondoz",
                "Tilson Peter",
                "Elliott Axtell",
                "Matt Birnie",
                "Ben Smith"
            ],
            "title": "Player tracking data analytics as a tool for physical performance management in football: A case study from chelsea football club",
            "venue": "academy. Sports,",
            "year": 2018
        },
        {
            "authors": [
                "Jia Deng",
                "Wei Dong",
                "Richard Socher",
                "Li-Jia Li",
                "Kai Li",
                "Li Fei-Fei"
            ],
            "title": "ImageNet: A large-scale hierarchical image database",
            "venue": "Institute of Electrical and Electronics Engineers (IEEE),",
            "year": 2010
        },
        {
            "authors": [
                "T. D\u2019Orazio",
                "M. Leo",
                "N. Mosca",
                "P. Spagnolo",
                "P.L. Mazzeo"
            ],
            "title": "A semi-automatic system for ground truth generation of soccer video sequences",
            "venue": "In 6th IEEE International Conference on Advanced Video and Signal Based Surveillance,",
            "year": 2009
        },
        {
            "authors": [
                "Seyed Abolfazl Ghasemzadeh",
                "Gabriel Van Zandycke",
                "Maxime Istasse",
                "Niels Sayez",
                "Amirafshar Moshtaghpour",
                "Christophe De Vleeschouwer"
            ],
            "title": "Deepsportlab: a unified framework for ball detection, player instance segmentation and pose estimation in team sports scenes",
            "venue": "British Machine Vision Conference",
            "year": 2021
        },
        {
            "authors": [
                "Xavier Glorot",
                "Yoshua Bengio"
            ],
            "title": "Understanding the difficulty of training deep feedforward neural networks",
            "venue": "In Journal of Machine Learning Research,",
            "year": 2010
        },
        {
            "authors": [
                "Peter J. Huber"
            ],
            "title": "Robust Estimation of a Location Parameter",
            "venue": "The Annals of Mathematical Statistics,",
            "year": 1964
        },
        {
            "authors": [
                "Paresh R. Kamble",
                "Avinash G. Keskar",
                "Kishor M"
            ],
            "title": "Bhurchandi. Ball tracking in sports: a survey",
            "venue": "Artificial Intelligence Review,",
            "year": 2019
        },
        {
            "authors": [
                "Taeone Kim",
                "Yongduek Seo",
                "Ki Sang Hong"
            ],
            "title": "Physics-based 3D position analysis of a soccer ball from monocular image sequences",
            "venue": "Proceedings of the IEEE International Conference on Computer Vision,",
            "year": 1998
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations,",
            "year": 2015
        },
        {
            "authors": [
                "K.C. Amit Kumar",
                "Pascaline Parisot",
                "Christophe De Vleeschouwer"
            ],
            "title": "Demo: Spatiotemporal template matching for ball detection",
            "venue": "In 2011 5th ACM/IEEE International Conference on Distributed Smart Cameras,",
            "year": 2011
        },
        {
            "authors": [
                "Mikel Labayen",
                "Igor G. Olaizola",
                "Naiara Aginako",
                "Julian Florez"
            ],
            "title": "Accurate ball trajectory tracking and 3D visualization for computer-assisted sports broadcast",
            "venue": "Multimedia Tools and Applications,",
            "year": 2014
        },
        {
            "authors": [
                "Christoph H. Lampert",
                "Jan Peters"
            ],
            "title": "Real-time detection of colored objects in multiple camera streams with off-the-shelf hardware components",
            "venue": "Journal of Real-Time Image Processing,",
            "year": 2012
        },
        {
            "authors": [
                "Adrien Maglo",
                "Astrid Orcesi",
                "Quoc-Cuong Pham"
            ],
            "title": "A resnet-18 network to estimate the ball diameter in basketball images, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Andrii Maksai",
                "Xinchao Wang",
                "Pascal Fua"
            ],
            "title": "What players do with the ball: A physically constrained interaction modeling",
            "venue": "In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,",
            "year": 2016
        },
        {
            "authors": [
                "Lucas Ant\u00f4nio Monezi",
                "Anderson Calderani Junior",
                "Luciano Allegretti Mercadante",
                "Leonardo Tomazeli Duarte",
                "Milton S"
            ],
            "title": "Misuta. A video-based framework for automatic 3d localization of multiple basketball players: A combinatorial optimization approach",
            "venue": "Frontiers in Bioengineering and Biotechnology,",
            "year": 2020
        },
        {
            "authors": [
                "Pascaline Parisot",
                "Christophe De Vleeschouwer"
            ],
            "title": "Graph-based filtering of ballistic trajectory",
            "venue": "In Proceedings - IEEE International Conference on Multimedia and Expo,",
            "year": 2011
        },
        {
            "authors": [
                "Pascaline Parisot",
                "Christophe De Vleeschouwer"
            ],
            "title": "Consensus-based trajectory estimation for ball detection in calibrated cameras systems",
            "venue": "Journal of Real-Time Image Processing,",
            "year": 2019
        },
        {
            "authors": [
                "Gopal Pingali",
                "Agata Opalach",
                "Yves Jean"
            ],
            "title": "Ball tracking and virtual replays for innovative tennis broadcasts",
            "venue": "Proceedings-International Conf. on Pattern Recognition,",
            "year": 2000
        },
        {
            "authors": [
                "Jinchang Ren",
                "James Orwell",
                "Graeme A. Jones",
                "Ming Xu"
            ],
            "title": "Real-time modeling of 3-D soccer ball trajectories from multiple fixed cameras",
            "venue": "IEEE Transactions on Circuits and Systems for Video Technology,",
            "year": 2008
        },
        {
            "authors": [
                "Hubert Shum",
                "Taku Komura"
            ],
            "title": "A spatiotemporal 6 approach to extract the 3D trajectory of the baseball from a single view video sequence",
            "venue": "IEEE International Conference on Multimedia and Expo (ICME),",
            "year": 2004
        },
        {
            "authors": [
                "Hugo Silva",
                "Andr\u00e9 Dias",
                "Jos\u00e9 Almeida",
                "Alfredo Martins",
                "Eduardo Silva"
            ],
            "title": "Real-Time 3D Ball Trajectory Estimation for RoboCup Middle Size League Using a Single Camera",
            "venue": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),",
            "year": 2011
        },
        {
            "authors": [
                "Brian Skinner",
                "Stephen J. Guy"
            ],
            "title": "A method for using player tracking data in basketball to learn player skills and predict team performance",
            "venue": "PLOS ONE, 10(9):1\u201315,",
            "year": 2015
        },
        {
            "authors": [
                "Jonas Sk\u00f6ld"
            ],
            "title": "Estimating 3D-trajectories from Monocular Video Sequences Estimating 3Dtrajectories from Monocular Video Sequences",
            "venue": "KTH Royal Institute of Technology,",
            "year": 2015
        },
        {
            "authors": [
                "Gabriel Van Zandycke"
            ],
            "title": "Image and Signal Processing Group (UCL) \u2014 Softwares: https://sites.uclouvain.be/ ispgroup/Softwares/DeepSport",
            "year": 2020
        },
        {
            "authors": [
                "Gabriel Van Zandycke"
            ],
            "title": "DeepSport dataset: https://www.kaggle",
            "venue": "com/gabrielvanzandycke/ deepsport-dataset,",
            "year": 2021
        },
        {
            "authors": [
                "Gabriel Van Zandycke",
                "Christophe De Vleeschouwer"
            ],
            "title": "Real-time CNN-based segmentation architecture for ball detection in a single view setup",
            "venue": "MMSports",
            "year": 2019
        },
        {
            "authors": [
                "Gabriel Van Zandycke",
                "Christophe De Vleeschouwer"
            ],
            "title": "3D Ball Localization From A Single Calibrated Image, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Gabriel Van Zandycke",
                "Vladimir Somers",
                "Maxime Istasse",
                "Carlo Del Don",
                "Davide Zambrano"
            ],
            "title": "Deepsportradar-v1: Computer vision dataset for sports understanding with high quality annotations",
            "venue": "In Proceedings of the 5th International ACM Workshop on Multimedia Content Analysis in Sports, MMSports",
            "year": 2022
        },
        {
            "authors": [
                "Christophe De Vleeschouwer",
                "Fan Chen",
                "Damien Delannay"
            ],
            "title": "Distributed video acquisition and annotation for sport-event summarization",
            "venue": "NEM summit,",
            "year": 2008
        },
        {
            "authors": [
                "Yukun Yang",
                "Min Xu",
                "Wanneng Wu",
                "Ruiheng Zhang",
                "Yu Peng"
            ],
            "title": "3d multiview basketball players detection and localization based on probabilistic occupancy",
            "year": 2018
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Three-dimensional (3D) localization plays a crucial role in computer vision, enabling a wide range of applications across various domains. While 3D localization is relatively straightforward when certain assumptions can be made, such as objects being located on the ground plane, or when triangulation is possible, the task becomes significantly more challenging when objects are positioned off the ground and only a single image is available. Under these circumstances, this challenge extends to human perception, emphasizing the importance of developing robust computational methods for 3D localization.\nIn sports analytics, understanding the precise 3D localization of objects, such as balls [11] and players [35, 19], can offer valuable insights for player performance analysis [26, 5], referee assistance [1], and audience engagement. While existing commercial solutions in sports analytics often rely on multi-camera setups [14, 22, 23, 16,\n4, 20, 21, 18], these often come with logistical and financial constraints. In scenarios where access to premium multi-camera setups is limited, the ability to leverage single calibrated camera systems for accurate ball localization becomes invaluable. In this work, we focus on the open problem of estimating the 3D location of balls in basketball games from single calibrated images.\nWhile 3D ball localization has been extensively studied for parabolic trajectories in calibrated videos [3, 24, 2, 12, 27, 21, 15, 25], little attention has been given to the general challenge of 3D ball localization from a single calibrated image, leaving a significant gap in research. Recent works addressing this task involved the estimation of the ball\u2019s diameter in pixels and the reconstruction of its 3D location based on this estimation[32, 17]. How-\nar X\niv :2\n30 9.\n03 64\n0v 1\n[ cs\n.C V\n] 7\nS ep\n2 02\n3\never, this approach suffers from various limitations, including sensitivity to variations in the ball\u2019s size within the image, issues with motion blur and image resolution, and the requirement for prior knowledge of the ball\u2019s realworld size.\nThe observation that motivates this work is that in basketball, much like in other sports, human observers rely on contextual cues such as the position, occlusion, and size of nearby players, crowd, and court objects like basketball boards to accurately locate the ball during a game. If tasked with estimating the 3D position of the ball in a paused video, a person would use the position of the players\u2019 feet on the court as a reference for X and Y coordinates, while making an informed guess about the height at which the ball is held. During passes or shots, the task becomes even more challenging and cues like players gaze orientation are required to improve the height perception. The idea is to give enough context to the model to guess the ball height in image space, and use geometry to retrieve the 3D ball coordinates.\nThis paper introduces a novel approach to 3D ball localization in basketball from single calibrated images. Building upon previous work [31, 8], we assume that the ball has already been detected in the image, allowing us to crop the image region around the ball. By providing sufficient context within the crop, our model predicts the height of the ball in image space, measured in pixels. Furthermore, by placing the ball at the center of the crop, we implicitly convey its location to the model.\nBesides lifting the limitations of the previous method, this approach is more versatile and easily transferable to other sports such as soccer, volleyball, handball, and potentially extensible to domains beyond sports."
        },
        {
            "heading": "2 Method",
            "text": "We propose to estimate the 3D location of a ball by training a neural network model to predict the distance in pixels between the ball and its ground projection in image space. Retrieving the 3D ball coordinates is then easily achieved by leveraging the projection matrix from the camera calibration data."
        },
        {
            "heading": "2.1 Ball height estimation in pixels",
            "text": "Our model has a Convolutional Neural Network (CNN) backbone to extract image features, which are subsequently processed by a regression head supervised to predict the distance in pixels between the ball and its ground projection in the image space. The model operates on square image crops centered on the ball, ensuring sufficient contextual information is provided."
        },
        {
            "heading": "2.2 Pixels height to world coordinates",
            "text": "Let us define a 3D coordinates system (X,Y, Z) with the horizontal ground plane defined by Z = 0, for the real world, and a 2D coordinate system (x, y), for image space. Details of the camera calibration allow us to project 3D points from the real world to the image space, and to convert 2D points in image space into light rays in 3D. To transform the estimated height of the ball in image space into its corresponding 3D coordinates in the real world, we apply the following procedure; see Fig. 2.\nFirst, the input image is undistorted, ensuring that straight lines in the real world correspond to straight lines in image space. Then, the image is rotated, aligning the Z-axis in the real world with the vertical direction y in the image space. After rotation, the predicted height of the ball in pixels h\u0302 effectively represents the vertical displacement between the ball\u2019s position in the image (x\u0303, y\u0303), located at the center of the crop, and its projection onto the ground in image space (x\u0303, y\u0303 + h\u0302). As the camera is calibrated, we can project (x\u0303, y\u0303 + h\u0302) into 3D space on the Z = 0 ground plane, determining the position of the ball\u2019s projection on the ground (X\u0303, Y\u0303 , 0). Finally, to obtain the 3D world coordinates of the ball, we perform a reprojection process. We trace the path of the light ray passing through the ball in the image space, determining the two 3D points at which it intersects the Y = Y\u0303 and X = X\u0303 vertical planes. By taking the average of these two points, we retrieve the 3D ball coordinates."
        },
        {
            "heading": "3 Datasets",
            "text": "In this study, we aim to evaluate the effectiveness of our proposed method for ball 3D localization in basketball.\nTo accomplish this, we require a suitable dataset that provides high-resolution images with accurate ball annotations. While datasets such as Basket-APIDIS [34] and Soccer-ISSIA [7] have been previously utilized for related tasks, we exclude them from consideration as the concerns raised in reference [32] also apply to this work.\nDeepSport dataset Following Ref. [33], we utilize for training of our models the public DeepSport dataset [30, 29], introduced in Ref. [31] and expanded in Ref. [33], which offers 364 high-resolution panoramic images captured during professional basketball matches across 15 different arenas. The images in the dataset vary in resolution, typically reaching approximately 4500\u00d71500 pixels. The ball\u2019s 3D annotation is provided through the annotation of its center and vertical projection on the court within the image space.\nBallistic dataset Beside evaluation of our model on the DeepSport dataset, in Section 4.6, we benchmark it also on the evaluation dataset introduced in Ref. [32] that features highly reliable 3D ball annotations from ballistic trajectories. This dataset is composed of 233 images of 2336 \u00d7 1756 pixels resolution, coming from 2 different basketball arenas."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Experiment configurations",
            "text": "Implementation details and metrics used to conduct this research are presented hereafter.\nDataset As mentioned in Section 3, we use the DeepSport dataset for training, and have adopted the split defined in [30], where each fold contains images from basketball arenas exclusive to that fold. The fold A remained unseen and was used for testing.\nBaseline As a baseline for our approach, we use a model introduced in Ref. [32] whereby the ball 3D position is obtained by estimating its diameter in the image space\nand combining knowledge of real ball size with calibration data.\nArchitecture We study the impact of the feature extractor by experimenting with several popular architectures, including VGG, ResNet, MobileNet and EfficientNet; all pre-trained on ImageNet [6] from the TensorFlow library [28]. The regression head, borrowed from Ref. [32], contains 3 layers, and outputs a scalar supervised to predict the ball height in pixels.\nContext size We thoroughly investigate the impact of the square crop size on our model\u2019s performance. It is evident that a small crop around the basketball would lack sufficient context for the model to accurately estimate its projection onto the ground. By enlarging the crop size and incorporating elements from the surrounding scene, we anticipate a significant enhancement in model performance. However, it is important to note that as the crop size increases, the improvements in performance may eventually plateau, leading to diminishing returns.\nImage scale In our research, we investigate the influence of the input image scale on our model\u2019s performance, as it directly affects the representation of the basketball and all relevant objects and people within the scene. Moreover, the combined effect of image scale and context size also influences the inference speed of the model, a critical consideration for real-time analysis in production systems.\nTraining procedure The backbone is pre-trained on ImageNet [6] from the TensorFlow library [28], and we initialize the regression head with the Glorot initializer [9]. The neural network is then trained on image patches centered around the oracle ball positions for 100 epochs using Adam optimizer [13] with a learning rate of 10\u22124. The final height prediction is supervised with a Huber loss [10] with \u03b4 = 1.0. Each experiment is repeated with 8 different initialization of the regression head and every reported metric is composed of mean and standard deviation computed over the 8 repetitions.\nMetrics We evaluate the performance of our 3D ball localization method using the following metrics:\n\u2022 Mean Absolute Error (MAE [px]): This metric measures the average error in pixels for the predicted height of the ball in image space.\n\u2022 Mean and Median Absolute Projection Error (MAPE [m] and MdnAPE [m]): These metrics quantify the average and median error in meters for the predicted projection of the ball on the court floor, with respect to the ground truth basketball projection.\n\u2022 Mean and Median Absolute 3D Error (MA3DE [m] and MdnA3DE [m]): These metrics assess the average and median error in meters for the reconstructed 3D ball position, relative to the ground truth 3D ball position.\nBy utilizing these metrics, we can comprehensively assess the accuracy and performance of our proposed 3D ball localization method. As the metrics are computed on oracle ball positions in image space, they reveal the true errors from our proposed approach, decorrelated from any error that a detector upstream could introduce."
        },
        {
            "heading": "4.2 Evaluation against the baseline",
            "text": "As a first experiment, we validate our proposed method for 3D ball localization against the model presented in Ref. [32], which relied on ball size estimation. For our model, we select a reasonable set of hyperparameters: the crop size is fixed to 512 pixels (about 1/3rd of the average dataset image height), the backbone is VGG16, and the image resolution is the one of the dataset. These choice of hyperparameters will be taken as default in the following sections. To ensure a fair comparison, we retrained the baseline model using the same hyperparameters as described in the previous paper and ran the experiments under similar conditions.\nThe results in Table 1 demonstrate the superiority of our proposed method over the baseline model. The significant improvement in MAPE and MA3DE validates the effectiveness of our approach for accurate 3D ball localization, setting a solid foundation for further experimentation and analysis.\nThe notable discrepancy between median and mean values observed across all experiments, including both our proposed method and the baseline, indicates that current solutions for ball 3D localization are significantly affected by outliers. Consequently, the performance of these models in production may be better than what is suggested by mean value of metrics."
        },
        {
            "heading": "4.3 Impact of backbone",
            "text": "We considered several popular backbone architectures including VGG, ResNet, MobileNet and EfficientNet. Our findings show that they all have similar performance when trained on the DeepSport dataset. We anticipate that when exposed to a larger dataset, larger models would perform better, at the cost of longer inference time."
        },
        {
            "heading": "4.4 Impact of context size",
            "text": "Here, we investigate the influence of context size on the predictive power of our model for 3D ball localization; see Fig. 3. Smaller crop sizes provide faster inference and require fewer resources, but may lack sufficient context for accurate height estimation. Conversely, larger crop sizes offer more contextual information, potentially improving model performance. Our goal is to identify the ideal crop size for a production environment where both performance and speed are important. We explore a range of crop sizes: 64, 96, 128, 256, 320, 480, 512, 640, and 800 pixels. For each crop size, we report in Table 2 the resulting MAPE.\nAs expected, a small crop size such as 64 \u00d7 64 yields a higher MAPE, indicating limited context for accurate height estimation. As the crop size increases, MAPE decreases, indicating improved performance. However, MAPE already plateaus beyond a crop size of 256 pixels. We thus identify the crop size of 256 pixels as the optimal choice, striking a balance between model performance and efficient inference, with promising implications for real-time applications."
        },
        {
            "heading": "4.5 Impact of image scale",
            "text": "In this section, we present a comprehensive study to assess the robustness of our model with respect to input image scale. The dataset comprises panoramic images of the basketball court. To evaluate the impact of image scale, effectively we shrink the images at various ratios (1, 1/2, 1/4, and 1/8). The square crop used as input to the model is also scaled accordingly, such that the model has access to the same contextual information independently of the scale.\nFrom the results in Table 3, we observe that our proposed method exhibits remarkable robustness concerning image resolution. Despite shrinking the images up to 1/8th of the original size, the model\u2019s performance re-\nScale Ratio MAPE [m]\nmains consistent. This robustness stands in stark contrast to the approach presented in Ref. [32], where highresolution images were a prerequisite for achieving accurate ball localization."
        },
        {
            "heading": "4.6 Benchmark on ballistic dataset",
            "text": "We evaluate our method on a benchmark dataset of balls moving on ballistic trajectories, as introduced in Ref.[32]. The obtained Mean Absolute Projection Error (MAPE) on this dataset is 2.68 \u00b1 0.12 m, significantly higher than the results obtained on the DeepSport test set; see Table1. The poor performance on the ballistic dataset is promptly explained by observing the distinct distribution of ball heights in the two datasets; see Fig. 4. The ballistic dataset shows a skew towards higher ball heights, with nearly half of the samples (102/233) having balls above 3 m, while the DeepSport dataset primarily comprises balls below this mark, with only 60 of 801 training samples reaching 3 meters.\nTo mitigate this limitation, we attempted to balance the number of balls above and below 2 meters in the training set. This approach resulted in an improved performance on the ballistic dataset, reducing the MAPE to 2.21\u00b10.27 m. Nonetheless, the limited number of high-ball samples in the training dataset remains a problem: feeding the same few high-ball samples to the neural network many times during training can not help much the model to generalise to those situations. We anticipate that a larger dataset, featuring more samples with high-ball instances, could narrow the gap between the performance on the ballistic dataset and the DeepSport test set."
        },
        {
            "heading": "5 Discussion",
            "text": "In this paper, we introduced a novel method for 3D ball localization, achieving impressive results with MAPE as low as 1.1 meters. Notably, our proposed approach exhibits remarkable robustness with respect to image resolution, allowing the use of low-resolution images with the same crop size, thereby providing more context while maintaining good performance and inference speed.\nAlthough our method demonstrates significant improvements in various scenarios, it underperforms on the ballistic dataset [32]. However, this outcome is not surprising given its skewed distribution of ball heights, which significantly differs from the one on which our models were trained.\nWhile our method is based on single images, there is potential for even better performance when applied to videos, by means of temporal smoothing or tracking. However, this goes beyond the scopes of this paper and would require an ad-hoc dataset, at least for evaluation.\nLastly, the performance of our approach could be further optimized with a more extensive and diverse training dataset. With additional data, our approach has the potential to achieve even better results, and the use of larger backbones may yield higher accuracy."
        },
        {
            "heading": "6 Conclusion",
            "text": "In conclusion, we have presented a novel method for 3D ball localization that offers a significant improvement over existing approaches in terms of accuracy and robustness. Importantly, this approach can be readily extended to other sports, given the creation of similar datasets tailored to each sport.\nMoreover, our method\u2019s underlying concept of height detection in the image space and subsequent 3D position reconstruction holds promise for general 3D object localization. While each application may adapt the idea to suit specific tasks, the fundamental framework remains applicable."
        },
        {
            "heading": "Acknowledgements",
            "text": "Part of this work has been funded by the Walloon Region project DeepSport and by Sportradar AG. C. De Vleeschouwer is a Research Director of the Fonds de la Recherche Scientifique - FNRS. Computational resources have been provided by the supercomputing facilities of the Universite\u0301 catholique de Louvain (CISM/UCL) and the Consortium des E\u0301quipements de Calcul Intensif en Fe\u0301de\u0301ration Wallonie Bruxelles (CE\u0301CI) funded by the Fond de la Recherche Scientifique de Belgique (F.R.S.FNRS) under convention 2.5020.11 and by the Walloon Region. M. D. Caio and G. Van Zandycke thank Sportradar AG for enabling and sponsoring this work, and for its commitment to scientific research, which made it possible for us to make significant contributions to the sports technology field. We also thank Davide Zambrano and the rest of the Computer Vision and Deep Learning team at Sportradar AG for their overall support of this work and for the fruitful conversations that led to the findings presented in this paper."
        }
    ],
    "title": "Context-Aware 3D Object Localization from Single Calibrated Images: A Study of Basketballs",
    "year": 2023
}