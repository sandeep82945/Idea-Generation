{
    "abstractText": "The quantitative characterization of the evolution of the error distribution (as the step-size tends to zero) is a fundamental problem in the analysis of stochastic numerical method. In this paper, we answer this problem by proving that the error of numerical method for linear stochastic differential equation satisfies the limit theorems and large deviation principle. To the best of our knowledge, this is the first result on the quantitative characterization of the evolution of the error distribution of stochastic numerical method. As an application, we provide a new perspective to explain the superiority of symplectic methods for stochastic Hamiltonian systems in the long-time computation. To be specific, by taking the linear stochastic oscillator as the test equation, we show that in the long-time computation, the probability that the error deviates from the typical value is smaller for the symplectic methods than that for the non-symplectic methods, which reveals that the stochastic symplectic methods are more stable than non-symplectic methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "JIALIN HONG"
        }
    ],
    "id": "SP:e17c5d4a7b82556b09fdf3e8cef42971b8ddd9bb",
    "references": [
        {
            "authors": [
                "C. Chen",
                "J. Hong",
                "D. Jin",
                "L. Sun"
            ],
            "title": "Asymptotically-preserving large deviations principles by stochastic symplectic methods for a linear stochastic oscillator",
            "venue": "SIAM J. Numer. Anal.,",
            "year": 2021
        },
        {
            "authors": [
                "C. Chen",
                "J. Hong",
                "D. Jin",
                "L. Sun"
            ],
            "title": "Large deviations principles for symplectic discretizations of stochastic linear Schr\u00f6dinger equation",
            "venue": "Potential Anal.,",
            "year": 2022
        },
        {
            "authors": [
                "J. Cui",
                "J. Hong",
                "Z. Liu",
                "W. Zhou"
            ],
            "title": "Stochastic symplectic and multi-symplectic methods for nonlinear Schr\u00f6dinger equation with white noise dispersion",
            "venue": "J. Comput. Phys.,",
            "year": 2017
        },
        {
            "authors": [
                "A. Dembo",
                "O. Zeitouni"
            ],
            "title": "Large Deviations Techniques and Applications, volume 38",
            "venue": "Springer Science & Business Media,",
            "year": 2009
        },
        {
            "authors": [
                "Lawrence C. Evans"
            ],
            "title": "An introduction to stochastic differential equations",
            "venue": "American Mathematical Society,",
            "year": 2013
        },
        {
            "authors": [
                "J. Hong",
                "L. Sun"
            ],
            "title": "Symplectic Integration of Stochastic Hamiltonian Systems, volume 2314 of Lecture Notes in Mathematics",
            "year": 2022
        },
        {
            "authors": [
                "J. Hong",
                "X. Wang"
            ],
            "title": "Invariant Measures for Stochastic Nonlinear Schr\u00f6dinger Equations. Numerical Approximations and Symplectic Structures, volume 2251 of Lecture Notes in Mathematics",
            "year": 2019
        },
        {
            "authors": [
                "Jean Jacod",
                "Philip Protter"
            ],
            "title": "Asymptotic error distributions for the Euler method for stochastic differential equations",
            "venue": "Ann. Probab.,",
            "year": 1998
        },
        {
            "authors": [
                "A. Klenke"
            ],
            "title": "Probability Theory. Universitext",
            "year": 2008
        },
        {
            "authors": [
                "A.H.S. Melb\u00f8and D.J. Higham"
            ],
            "title": "Numerical simulation of a linear stochastic oscillator with additive noise",
            "venue": "Appl. Numer. Math.,",
            "year": 2004
        },
        {
            "authors": [
                "G.N. Milstein",
                "M.V. Tretyakov"
            ],
            "title": "Stochastic Numerics for Mathematical Physics",
            "venue": "Scientific Computation. Springer-Verlag,",
            "year": 2004
        },
        {
            "authors": [
                "Philip Protter",
                "Lisha Qiu",
                "Jaime San Martin"
            ],
            "title": "Asymptotic error distribution for the Euler scheme with locally Lipschitz coefficients",
            "venue": "Stochastic Process. Appl.,",
            "year": 2020
        },
        {
            "authors": [
                "C.M. Rohwer",
                "F. Angeletti",
                "H. Touchette"
            ],
            "title": "Convergence of large-deviation estimators",
            "venue": "Phys. Rev. E,",
            "year": 2015
        },
        {
            "authors": [
                "M.J. Senosiain",
                "A. Tocino"
            ],
            "title": "A review on numerical schemes for solving a linear stochastic oscillator",
            "venue": "BIT, 55(2):515\u2013529,",
            "year": 2015
        },
        {
            "authors": [
                "L. Wang",
                "J. Hong",
                "L. Sun"
            ],
            "title": "Modified equations for weakly convergent stochastic symplectic schemes via their generating functions",
            "year": 2016
        },
        {
            "authors": [
                "Z. Wang",
                "J. Xin",
                "Z. Zhang"
            ],
            "title": "Computing effective diffusivity of chaotic and stochastic flows using structure-preserving schemes",
            "venue": "SIAM J. Numer. Anal.,",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "1. Introduction\nOne core of numerical analysis of stochastic differential equations is the error analysis of numerical method, since the error, the difference between the exact solution and numerical solution, is a fundamental quantity to measure the computational accuracy of the numerical method. There have been extensive results on the upper bound estimate of statistical moments of the error (as the step-size tends to zero), which is also known as the strong convergence analysis of numerical methods (see e.g., [11] and references therein). Since the error of a numerical method is a random variable in essence, a more ambitious target is to study the error distribution. The distribution of the normalized error process of the Euler\u2013Maruyama method has been investigated in for instance [8, 12], where the limits of normalized error distributions are provided precisely. However, to the best of our knowledge, the quantitative characterization of the evolution of the error distribution (for instance, the large deviation principle of the error) as the step-size tends to zero is still an open problem.\nIn order to answer this problem, we consider the following linear stochastic differential equation {\ndu(t) = A(t)u(t)dt+ b(t)dW(t), u(0) = u0 (1.1)\nto obtain precise results about the probabilistic evolution of the errors of general numerical methods. Here, u(t) = (u(1)(t), \u00b7 \u00b7 \u00b7 , u(d)(t))\u22a4, A : [0, T ] \u2192 Rd\u00d7d, b : [0, T ] \u2192 Rd\u00d7d\u0303, u0 \u2208 Rd and W = {W(t), t \u2265 0} is a d\u0303-dimensional Brownian motion defined on (\u2126,F , {Ft}t\u22650,P). We aim to characterize the probabilistic evolution of the error of general numerical method for\n2010 Mathematics Subject Classification. Primary 60F10, 60H35, 65C30, 65P10. Key words and phrases. Error of numerical method, central limit theorem, large deviation principle, stochastic symplectic method . The research of this work is supported by National key R&D Program of China (No.2020YFA0713701), and by the National Natural Science Foundation of China (Nos. 11971470, 12031020, 12171047).\n1\nar X\niv :2\n30 4.\n01 60\n2v 2\n[ m\nat h.\nN A\n] 1\n1 A\nug 2\n02 3\n2 JIALIN HONG, GE LIANG, AND DERUI SHENG\n(1.1) in the small step-size limit quantitatively by studying the limit theorems (including the strong law of large numbers and the central limit theorem) and the large deviation principle for the error.\nThe strong law of large numbers and the central limit theorem concern the limit of the error in sense of almost surely and the weak limit of the distribution of the normalized error, respectively; the large deviation principle concerns the exponential-type estimates of the probability that the error deviates from the origin. All of them describe the asymptotical behavior of the error as the step-size vanishes. For fixed step-size h > 0, we consider a general convergent numerical method for (1.1) of the form\nun+1 = A\u0303nun + b\u0303n\u2206Wn, (1.2)\nwhere un = (u (1) n , \u00b7 \u00b7 \u00b7 , u(d)n )\u22a4, A\u0303n \u2208 Rd\u00d7d, b\u0303n \u2208 Rd\u00d7d\u0303, \u2206Wn := Wtn+1\u2212Wtn , n = 0, 1, \u00b7 \u00b7 \u00b7 , N\u2212 1 and N = T/h. By the Borel\u2013Cantelli lemma, we obtain the strong law of large numbers of the error {e(i)N := u (i) N \u2212u(i)(T )}N\u2208N+ , i = 1, \u00b7 \u00b7 \u00b7 , d. We also establish the central limit theorem of the error {e(i)N }N\u2208N+ , i.e.,\nNe (i) N \u2212 E[Ne (i) N ] \u2192 N (0, T 2K (i) T ) in distribution,\nwhere K (i) T = limN\u2192\u221eVar(e (i) N )/h 2 is called the error constant in this paper. Further, by the Ga\u0308rtner\u2013Ellis theorem, we prove that the error {e(i)N }N\u2208N+ satisfies the large deviation principle with the deviation scale {N2}N\u2208N+ and the good rate function I(i)(x) = 12K(i)T T 2\nx2, x \u2208 R. The above central limit theorem and large deviation principle of the error can be used to estimate the probability of the error\u2019s deviation from its typical value. This provides a new perspective of understanding the superiority of stochastic symplectic methods over nonsymplectic methods in the long-time computation.\nExtensive numerical simulations (see e.g., [3, 6, 7, 15]) show that for the stochastic Hamiltonian systems, the symplectic methods are capable of providing the long-time energy preservation and stability, compared to the non-symplectic methods. For the mechanism of the superiority of the stochastic symplectic methods, it is partially solved in [15, 16] by deriving the modified equations associated with some symmetric methods, and in [1, 2] by investigating the ability of symplectic methods to asymptotically preserve the large deviation principles of some observables associated with the original system. Concerning that the linear stochastic oscillator is one of the typical stochastic Hamiltonian systems, we take it as the test equation to study the difference between the probabilistic evolution of the errors of symplectic methods and that of non-symplectic methods. To this end, we derive the error constant KT for several concrete symplectic and non-symplectic methods, and find that the growth of KT is almost proportional to T and T 3 for the considered symplectic and non-symplectic methods, respectively. On this basis, we are able to compare the error\u2019s deviation from the typical value for the considered symplectic and non-symplectic methods of the linear stochastic oscillator. More precisely, at the scale \u03f5/N , the probability that the error deviates from the mean is strictly smaller for the symplectic methods than that for the non-symplectic methods. Besides, at the scale \u03f5, the probability of the error\u2019s deviation from the origin decays exponentially faster for the symplectic methods than that for the non-symplectic methods. These two comparisons reveal the superiority of symplectic methods to non-symplectic methods in the long-time computation from the perspective of the probabilistic evolution of the error.\nThe rest of this paper is organized as follows. In section 2, we present the limit theorems and the large deviation principle of the error of the general numerical method (1.2). Then\nPROBABILISTIC EVOLUTION OF THE ERROR 3\nwe derive the error constant for several concrete symplectic and non-symplectic methods for the linear stochastic oscillator in subsections 3.1\u20133.2. The superiority of stochastic symplectic methods is illustrated in subsection 3.3. In section 4, numerical experiments are performed to verify the theoretical results. Finally, conclusions and several open problems are given in section 5.\n2. Probabilistic evolution of the error\nIn order to study the probabilistic evolution of the error, we estabilish the limit theorems and the large deviation principle of the error of a general numerical method for (1.1). We refer to [4, 9] for more details about the concepts of the limit theorems and the large deviation principle. In the sequel, let R = O(hp), p \u2265 0, stand for |R| \u2264 Chp for all sufficiently small h > 0, where C is independent of h. Let K \u223c T p, p \u2265 0, stand for limT\u2192\u221eK/T p = C, where C is independent of T . We denote the one-dimensional normal random variable with mean m \u2208 R and variance \u03c32 \u2265 0 by N (m,\u03c32). Especially, if \u03c32 = 0, N (m, 0) = \u03b4m is the Dirac measure concentrated on m.\nThe exact solution of (1.1) is given by (see e.g., [5])\nu(t) = \u03a6(t)u0 + \u222b t 0 \u03a6(t)\u03a6(s)\u22121b(s)dW(s), (2.1)\nwhere \u03a6(\u00b7) is the fundamental matrix of the nonautonomous system{ \u03a6\u0307(t) = A(t)\u03a6(t),\n\u03a6(0) = I. (2.2)\nIn terms of the numerical method (1.2), it follows that\nun+1 = \u03a0 n k=0A\u0303n\u2212ku0 + n\u2211 k=0 ( \u03a0n\u2212k\u22121i=0 A\u0303n\u2212i ) b\u0303k\u2206Wk, n = 0, \u00b7 \u00b7 \u00b7 , N \u2212 1, (2.3)\nwhere we use the convention \u03a0\u22121i=0A\u0303n\u2212i = 1. Utilizing (2.1) and (2.3), it yields that\nen : = un \u2212 u(tn) = ( \u03a0nk=0A\u0303n\u2212k \u2212\u03a6(tn) ) u0 (2.4)\n+ n\u22121\u2211 k=0 \u222b tk+1 tk (( \u03a0n\u2212k\u22122i=0 A\u0303n\u2212i\u22121 ) b\u0303k \u2212\u03a6(tn)\u03a6(s)\u22121b(s) ) dW(s).\nCombined with (2.4), the independent increment property of the Brownian motion shows that the distribution of the error eN = (e (1) N , \u00b7 \u00b7 \u00b7 , e (d) N )\n\u22a4 is Gaussian, which is uniquely determined by its mean and covariance matrix. Since the diffusion coefficient in (1.1) is independent of the solution, it is known that the mean-square convergence order of general numerical methods (such as stochastic Runge\u2013Kutta methods) for (1.1) is no less than 1. Hence, we propose the following assumption, which ensures that (1.2) possesses at least first order accuracy in the mean square sense.\nAssumption 2.1. For each i = 1, \u00b7 \u00b7 \u00b7 , d, E[e(i)N ] = O(h) and Var(e (i) N ) = K (i) T h 2+O(h3) with some error constant K\n(i) T \u2265 0.\n4 JIALIN HONG, GE LIANG, AND DERUI SHENG\nRemark 2.2. Let A\u0303EMn = I+A(tn)h and b\u0303 EM n = b(tn) be the associated coefficient matrices of the Euler\u2013Maruyama method. If the numerical method (1.2) satisfies\n\u2225A\u0303n \u2212 A\u0303EMn \u2225F = O(h2) and \u2225b\u0303n \u2212 b\u0303EMn \u2225F = O(h), (2.5)\nthen Assumption 2.1 holds in view of the fundamental convergence theorem (see [11]).\nIn the following, we give the strong law of large numbers, the central limit theorem and the large deviation principle of the error {e(i)N }N\u2208N+ , i = 1, \u00b7 \u00b7 \u00b7 , d. They characterize the asymptotical behavior of the error as the step-size tends to zero, and help us better understand the probabilistic evolution of the error.\nTheorem 2.3. For the general numerical method (1.2) satisfying Assumption 2.1, the following properties hold for {e(i)N }N\u2208N+ , i = 1, \u00b7 \u00b7 \u00b7 , d. (i) Strong law of large numbers:\nlim N\u2192\u221e\ne (i) N = 0 a.s.\n(ii) Central limit theorem:\nNe (i) N \u2212 E[Ne (i) N ] \u2192 N (0, T 2K (i) T ) in distribution.\n(iii) The large deviation principle holds for the error {e(i)N }N\u2208N+ with the deviation scale {N2}N\u2208N+, i.e.,\nlim sup N\u2192\u221e\n1\nN2 logP(e(i)N \u2208 F ) \u2264 \u2212 infx\u2208F I (i)(x), \u2200 closed F \u2282 R, (2.6)\nlim inf N\u2192\u221e\n1\nN2 logP(e(i)N \u2208 G) \u2265 \u2212 infx\u2208G I (i)(x), \u2200 open G \u2282 R, (2.7)\nwhere the rate function I(i)(\u00b7) is\nI(i)(x) =  x2 2K (i) T T 2 , if K (i) T > 0,\n+\u221e \u00b7 1{y \u0338=0}(x), if K (i) T = 0.\nHere 1{y \u0338=0} is the indicator function on the set {y \u2208 R : y \u0338= 0}.\nProof. (i) According to Assumption 2.1, there exists C1(T ) > 0 such that E [ |e(i)N | 2 ] \u2264 2Var(e(i)N ) + 2|E[e (i) N ]| 2 \u2264 C1(T )h2.\nFor fixed \u00b5 \u2208 (12 , 1), the Markov inequality indicates that for any \u03b4 > 0,\nP(N1\u2212\u00b5|e(i)N | > \u03b4) \u2264 \u03b4 \u22122N2\u22122\u00b5E [ |e(i)N | 2 ] \u2264 \u03b4\u22122N\u22122\u00b5C1(T )T 2.\nHence for any \u03b4 > 0, \u2211\u221e\nN=1 P(N1\u2212\u00b5|e (i) N | > \u03b4) < \u221e, which together with the Borel\u2013Cantelli\nlemma leads to the strong law of large numbers of the error {e(i)N }N\u2208N+ . (ii) Since limN\u2192\u221eVar(Ne (i) N ) = T 2K (i) T , we have the central limit theorem of the error {e(i)N }N\u2208N+ due to the fact that the L2(\u2126)-limit of Gaussian random variables is still a Gaussian random variable.\n(iii) Notice that\n\u039b(i)(\u03bb) = lim N\u2192\u221e\n1\nN2 logE\n[ exp(\u03bbN2e (i) N ) ]\nPROBABILISTIC EVOLUTION OF THE ERROR 5\n= lim N\u2192\u221e\n1\nN2 log exp\n( \u03bbN2E[e(i)N ] + 1\n2 \u03bb2N4Var(e\n(i) N ) )\n= lim N\u2192\u221e\n( \u03bbE[e(i)N ] + 1\n2 \u03bb2N2Var(e\n(i) N ) ) = 1\n2 \u03bb2T 2K (i) T .\nWe divide the proof into two cases K (i) T > 0 and K (i) T = 0.\nCase (a): K (i) T > 0. It is easy to show that \u039b (i)(\u00b7) is essentially smooth and lower semicontinuous. Besides, the origin 0 belongs to D\u25e6\n\u039b(i) . Hence, based on Ga\u0308rtner\u2013Ellis theorem\n(see [4, Theorem 2.3.6]), the large deviation principle holds for the error {e(i)N }N\u2208N+ with the good rate function\nI(i)(x) = sup \u03bb\u2208R {\u03bbx\u2212 1 2 \u03bb2T 2K (i) T } =\nx2\n2K (i) T T\n2 , x \u2208 R.\nCase (b): K (i) T = 0. We divide the proof into three steps for this case. Step 1. For a fixed x0 > 0, it follows from E[e (i) N ] = O(h) that there exists an N0 \u2208 N+\nsuch that\nE[e(i)N ] < x0, \u2200N > N0.\nSince the distribution of e (i) N is Gaussian, [9, Lemma 22.2] yields that\nP(e(i)N \u2265 x0) \u2264 1\u221a 2\u03c0\n\u221a Var(e\n(i) N )\nx0 \u2212 E[e(i)N ] exp\n( \u2212 (x0 \u2212 E[e(i)N ])2\n2Var(e (i) N )\n) ,\nwhich combined with Var(e (i) N ) = O(h3) leads to\nlim N\u2192\u221e\n1\nN2 logP(e(i)N \u2265 x0) = \u2212\u221e, \u2200x0 > 0. (2.8)\nSimilarly, one gets\nlim N\u2192\u221e\n1\nN2 logP(e(i)N \u2264 x0) = \u2212\u221e, \u2200x0 < 0. (2.9)\nStep 2. If 0 \u2208 F , (2.6) holds naturally since infx\u2208F I(i)(x) = 0 and P(e(i)N \u2208 F ) \u2264 1. If 0 /\u2208 F , it is obvious that infx\u2208F I(i)(x) = +\u221e. By defining x+ := inf(F \u2229 (0,\u221e)) and x\u2212 := sup(F \u2229 (\u2212\u221e, 0)), we use (2.8), (2.9) and [9, Lemma 23.9] to obtain that if 0 /\u2208 F ,\nlim sup N\u2192\u221e\n1\nN2 logP(e(i)N \u2208 F )\n\u2264 lim sup N\u2192\u221e\n1 N2 log ( P(e(i)N \u2265 x+) + P(e (i) N \u2264 x\u2212) ) \u2264 max\n{ lim sup N\u2192\u221e 1 N2 logP(e(i)N \u2265 x+), lim sup N\u2192\u221e 1 N2 logP(e(i)N \u2264 x\u2212) } = \u2212\u221e.\nStep 3. If 0 /\u2208 G, (2.7) holds immediately since infx\u2208G I(i)(x) = +\u221e. If 0 \u2208 G, there exists some \u03b4 > 0 such that (\u2212\u03b4, \u03b4) \u2282 G. Besides, by (2.8), for any M < 0, there exists an N1 \u2208 N+ such that\n1\nN2 logP(e(i)N \u2265 \u03b4) < M, \u2200N > N1,\nwhich implies that limN\u2192\u221e P(e (i) N \u2265 \u03b4) = 0.\n6 JIALIN HONG, GE LIANG, AND DERUI SHENG\nBy a similar argument, we have limN\u2192\u221e P(e (i) N \u2264 \u2212\u03b4) = 0. Hence\nlim N\u2192\u221e\n1\nN2 logP(|e(i)N | < \u03b4) = limN\u2192\u221e\n1\nN2 log(1\u2212 P(|e(i)N | \u2265 \u03b4)) = 0,\nwhich implies that if 0 \u2208 G,\nlim inf N\u2192\u221e\n1\nN2 logP(e(i)N \u2208 G) \u2265 lim infN\u2192\u221e\n1\nN2 logP(|e(i)N | < \u03b4) = 0.\nThe proof is completed. \u25a1\nRemark 2.4. If the covariance matrix Cov(eN ) = HTh 2 + O(h3), where the error matrix HT \u2208 Rd\u00d7d is positive definite, we can also obtain the strong law of large numbers, the central limit theorem and the large deviation principle of the error {eN}N\u2208N+ with the good rate function I(x) = 1\n2T 2 x\u22a4H\u22121T x,x \u2208 Rd.\n3. Comparison of symplectic and non-symplectic methods\nIn this section, by taking the linear stochastic oscillator as the test equation, we study the limit theorems and the large deviation principle of the errors of several symplectic methods and non-symplectic methods. And we try to explain the superiority of stochastic symplectic methods from the perspective of the probabilistic evolution of error.\nBy introducing Yt := X\u0307t, the linear stochastic oscillator X\u0308t +Xt = \u03b1W\u0307t can be written as\nd ( Xt Yt ) = ( 0 1 \u22121 0 )( Xt Yt ) dt+ \u03b1 ( 0 1 ) dWt, t \u2208 [0, T ] (3.1)\nwith initial data (X0, Y0) \u22a4 = (x0, y0) \u22a4. Here \u03b1 > 0, T > 0, and W = {Wt}t\u2208[0,T ] denotes a one-dimensional standard Brownian motion defined on (\u2126,F , {Ft}t\u22650,P).\nThe exact solution of (3.1) is given by (see e.g., [10]) Xt = x0 cos t+ y0 sin t+ \u03b1 \u222b t 0 sin(t\u2212 s)dWs,\nYt = \u2212x0 sin t+ y0 cos t+ \u03b1 \u222b t 0 cos(t\u2212 s)dWs.\n(3.2)\nMoreover, the symplectic structure of its phase flow is preserved (see e.g., [14]), i.e.,\ndXt \u2227 dYt = dx0 \u2227 dy0, \u2200 t \u2265 0. For fixed step-size h > 0, we consider a general convergent numerical method for (3.1) of\nthe form ( xn+1 yn+1 ) = A ( xn yn ) + \u03b1b\u2206Wn := ( a11 a12 a21 a22 )( xn yn ) + \u03b1 ( b1 b2 ) \u2206Wn, (3.3)\nwhere \u2206Wn := Wtn+1 \u2212Wtn , n = 0, 1, \u00b7 \u00b7 \u00b7 , N \u2212 1 and N = T/h. Remark 3.1. For the numerical method (3.3), the condition (2.5) is equivalent to (see [1, Theorem 4.1])\n|a11 \u2212 1|+ |a22 \u2212 1|+ |a12 \u2212 h|+ |a21 + h| = O(h2), |b1|+ |b2 \u2212 1| = O(h). (3.4)\nA numerical method {(xn, yn)}Nn=0 for (3.1) is called symplectic if dxn+1 \u2227 dyn+1 = dxn \u2227 dyn, \u2200n = 0, . . . , N \u2212 1.\nIn view of the fact that {Yt}t\u2208[0,T ] is the derivative of {Xt}t\u2208[0,T ] and many physical observations (e.g., the mean position 1T \u222b T 0 Xtdt and the mean velocity XT T ) of (3.1) depends on\nPROBABILISTIC EVOLUTION OF THE ERROR 7\n{Xt}t\u2208[0,T ], we mainly consider the error eN := xN \u2212XT . In terms of the numerical method (3.3), it follows from [14] that\nxn = (a11\u03b1\u0302n\u22121 + \u03b2\u0302n\u22121)x0 + a12\u03b1\u0302n\u22121y0\n+ \u03b1 n\u22121\u2211 k=0 (b1\u03b1\u0302n\u22121\u2212k + (a12b2 \u2212 a22b1) \u03b1\u0302n\u22122\u2212k)\u2206Wk, (3.5)\nwhere\n\u03b1\u0302k = (det(A)) k 2 sin((k + 1)\u03be)\nsin(\u03be) , \u03b2\u0302k = \u2212 (det(A))\nk+1 2\nsin (k\u03be)\nsin(\u03be) (3.6)\nfor any integer k, with \u03be \u2208 (0, \u03c0) satisfying\ncos(\u03be) = tr(A) 2 \u221a det(A) , sin(\u03be) =\n\u221a 4 det(A)\u2212 (tr(A))2\n2 \u221a det(A)\n. (3.7)\nUtilizing (3.2) and (3.5), it yields that\neN = [a11\u03b1\u0302N\u22121 + \u03b2\u0302N\u22121 \u2212 cos(T )]x0 + [a12\u03b1\u0302N\u22121 \u2212 sin(T )]y0\n+ \u03b1 N\u22121\u2211 j=0 \u222b tj+1 tj (b1\u03b1\u0302N\u22121\u2212j + (a12b2 \u2212 a22b1)\u03b1\u0302N\u22122\u2212j \u2212 sin(T \u2212 s)) dW (s). (3.8)\nAccording to Theorem 2.3, the error constant is an important quantity in characterizing the limit distribution of NeN and the large deviation rate function of {eN}N\u2208N+ . In order to determine the associated error constants, we begin with giving the explicit expressions of the variances of the errors of general symplectic and non-symplectic methods. By (3.8) and Ito\u0302 isometry, one gets\nVar(eN ) = \u03b1 2E [\u2223\u2223\u2223\u2223N\u22121\u2211 j=0 \u222b tj+1 tj [b1\u03b1\u0302N\u22121\u2212j + (a12b2 \u2212 a22b1) \u03b1\u0302N\u22122\u2212j \u2212 sin (T \u2212 s)] dW (s) \u2223\u2223\u2223\u22232 ]\n= \u03b12 N\u22121\u2211 j=0 \u222b tj+1 tj (b1\u03b1\u0302N\u22121\u2212j + (a12b2 \u2212 a22b1) \u03b1\u0302N\u22122\u2212j \u2212 sin (T \u2212 s))2 ds = \u03b12 N\u22121\u2211 j=0 (b1\u03b1\u0302N\u22121\u2212j + (a12b2 \u2212 a22b1) \u03b1\u0302N\u22122\u2212j)2 h\n+ \u03b12 N\u22121\u2211 j=0 [ h 2 + 1 4 sin (2T \u2212 2tj+1)\u2212 1 4 sin (2T \u2212 2tj) ] \u2212 2\u03b12 N\u22121\u2211 j=0 (b1\u03b1\u0302N\u22121\u2212j + (a12b2 \u2212 a22b1) \u03b1\u0302N\u22122\u2212j) [cos (T \u2212 tj+1)\u2212 cos (T \u2212 tj)]\n= 4\u2211 k=1 Sk,\nwhere\nS1 := \u03b12hb21 N\u22121\u2211 j=0 \u03b1\u03022N\u22121\u2212j + \u03b1 2h (a12b2 \u2212 a22b1)2 N\u22121\u2211 j=0 \u03b1\u03022N\u22122\u2212j ,\n8 JIALIN HONG, GE LIANG, AND DERUI SHENG\nS2 := 2\u03b12hb1 (a12b2 \u2212 a22b1) N\u22121\u2211 j=0 \u03b1\u0302N\u22121\u2212j\u03b1\u0302N\u22122\u2212j , S3 := \u22122\u03b12b1 N\u22121\u2211 j=0 \u03b1\u0302N\u22121\u2212j (cos (T \u2212 tj+1)\u2212 cos (T \u2212 tj)) , S4 := \u22122\u03b12 (a12b2 \u2212 a22b1) N\u22121\u2211 j=0 \u03b1\u0302N\u22122\u2212j (cos (T \u2212 tj+1)\u2212 cos (T \u2212 tj)) + \u03b12 2 T \u2212 \u03b1 2 sin(2T ) 4 .\nFor the term S1, we substitute (3.6) into S1 to get\nS1 = \u03b12hb21 sin2 (\u03be) N\u22121\u2211 k=0 (det (A)) k sin2 ((k + 1) \u03be)\n+ \u03b12h(a12b2 \u2212 a22b1)2\nsin2(\u03be)\nN\u22122\u2211 k=0 (det(A)) k sin2((k + 1)\u03be)\n= \u03b12hb21\n2 sin2 (\u03be) N\u22121\u2211 k=0 (det (A)) k \u2212 \u03b1 2hb21 2 sin2 (\u03be) det(A) N\u2211 k=1 (det (A)) k cos (2k\u03be)\n+ \u03b12h(a12b2 \u2212 a22b1)2\n2 sin2(\u03be)\nN\u22122\u2211 k=0 (det(A)) k \u2212 \u03b1 2h(a12b2 \u2212 a22b1)2 2 sin2(\u03be) det(A) N\u22121\u2211 k=1 (det(A)) k cos(2k\u03be).\nSimilarly, we obtain\nS2 = \u03b12hb1(a12b2 \u2212 a22b1) sin(\u03be) tan(\u03be) \u221a det(A) N\u22121\u2211 k=0 (det(A)) k \u2212 \u03b1 2hb1(a12b2 \u2212 a22b1) sin(\u03be) tan(\u03be) (det(A)) 3 2 N\u2211 k=1 (det(A)) k cos(2k\u03be)\n\u2212 \u03b1 2hb1(a12b2 \u2212 a22b1) sin(\u03be) (det(A)) 3 2 N\u2211 k=1 (det(A)) k sin(2k\u03be),\nS3 = \u2212 \u03b12b1 tan(\u03be) N\u22121\u2211 k=1 (\u221a det(A) )k sin(k(\u03be + h))\u2212 \u03b1 2b1 tan(\u03be) N\u22121\u2211 k=1 (\u221a det(A) )k sin(k(\u03be \u2212 h))\n\u2212 2\u03b12b1 \u2212 \u03b12b1 N\u22121\u2211 k=1 (\u221a det(A) )k cos(k(\u03be + h))\u2212 \u03b12b1 N\u22121\u2211 k=1 (\u221a det(A) )k cos(k(\u03be \u2212 h))\n+ \u03b12b1 sin(\u03be) \u221a det(A) N\u2211 k=1 (\u221a det(A) )k sin(k(\u03be + h))\n+ \u03b12b1 sin(\u03be) \u221a det(A) N\u2211 k=1 (\u221a det(A) )k sin(k(\u03be \u2212 h)),\nS4 = \u03b12(a12b2 \u2212 a22b1)(cos(h)\u2212 1) sin(\u03be) \u221a det(A) N\u22121\u2211 k=1 (\u221a det(A) )k sin(k(\u03be + h))\n+ \u03b12(a12b2 \u2212 a22b1)(cos(h)\u2212 1) sin(\u03be) \u221a det(A) N\u22121\u2211 k=1 (\u221a det(A) )k sin(k(\u03be \u2212 h))\n+ \u03b12(a12b2 \u2212 a22b1) sin(h) sin(\u03be) \u221a det(A) N\u22121\u2211 k=1 (\u221a det(A) )k cos(k(\u03be + h))\nPROBABILISTIC EVOLUTION OF THE ERROR 9\n\u2212 \u03b1 2(a12b2 \u2212 a22b1) sin(h) sin(\u03be) \u221a det(A) N\u22121\u2211 k=1 (\u221a det(A) )k cos(k(\u03be \u2212 h)) + \u03b1 2 2 T \u2212 \u03b1 2 sin(2T ) 4 .\nFurther, we sum up S1-S4 to get\nVar(eN ) = {\u03b12(a12b2 \u2212 a22b1)(cos(h)\u2212 1)\nsin(\u03be) \u221a det(A) \u2212 \u03b1 2b1 tan(\u03be) }N\u22121\u2211 k=1 (\u221a det(A) )k sin(k(\u03be + h))\n+ {\u03b12(a12b2 \u2212 a22b1)(cos(h)\u2212 1)\nsin(\u03be) \u221a det(A) \u2212 \u03b1 2b1 tan(\u03be) }N\u22121\u2211 k=1 (\u221a det(A) )k sin(k(\u03be \u2212 h))\n+ {\u03b12(a12b2 \u2212 a22b1) sin(h)\nsin(\u03be) \u221a det(A) \u2212 \u03b12b1 }N\u22121\u2211 k=1 (\u221a det(A) )k cos(k(\u03be + h))\n\u2212 {\u03b12(a12b2 \u2212 a22b1) sin(h)\nsin(\u03be) \u221a det(A) + \u03b12b1 }N\u22121\u2211 k=1 (\u221a det(A) )k cos(k(\u03be \u2212 h))\n+ \u03b12b1 sin(\u03be) \u221a det(A) N\u2211 k=1 (\u221a det(A) )k ( sin(k(\u03be + h)) + sin(k(\u03be \u2212 h)) ) (3.9)\n+ { \u03b12hb21 2 sin2 (\u03be) + \u03b12hb1(a12b2 \u2212 a22b1) sin(\u03be) tan(\u03be) \u221a det(A) }N\u22121\u2211 k=0 (det(A)) k\n\u2212 { \u03b12hb1(a12b2 \u2212 a22b1) sin(\u03be) tan(\u03be) (det(A)) 3 2 + \u03b12hb21 2 sin2 (\u03be) det(A) } N\u2211 k=1 (det(A)) k cos(2k\u03be)\n+ \u03b12h(a12b2 \u2212 a22b1)2\n2 sin2(\u03be)\n{N\u22122\u2211 k=0 (det(A)) k \u2212 N\u22121\u2211 k=1 (det(A)) k\u22121 cos(2k\u03be) }\n\u2212 \u03b1 2hb1(a12b2 \u2212 a22b1) sin(\u03be) (det(A)) 3 2 N\u2211 k=1 (det(A)) k sin(2k\u03be)\u2212 2\u03b12b1 + \u03b12 2 T \u2212 \u03b1 2 sin(2T ) 4 .\nTo proceed, we need the following fundamental lemma.\nLemma 3.2. For arbitrary \u03be \u2208 (0, 2\u03c0), n \u2208 N+, and a \u2208 R, we have the followings. (1)\nn\u2211 k=1 sin(k\u03be)ak = a sin(\u03be)\u2212 an+1 sin((n+ 1)\u03be) + an+2 sin(n\u03be) 1\u2212 2a cos(\u03be) + a2 .\nIn particular, if a = 1, then\nn\u2211 k=1 sin(k\u03be) = cos( \u03be2)\u2212 cos((n+ 1 2)\u03be) 2 sin( \u03be2) .\n(2)\nn\u2211 k=1 cos (k\u03be) ak = a cos (\u03be)\u2212 a2 \u2212 an+1 cos ((n+ 1) \u03be) + an+2 cos (n\u03be) 1\u2212 2a cos (\u03be) + a2 .\nIn particular, if a = 1, then n\u2211\nk=1\ncos(k\u03be) = sin((n+ 12)\u03be)\n2 sin( \u03be2) \u2212 1 2 .\n10 JIALIN HONG, GE LIANG, AND DERUI SHENG\nProof. (1) See [1, Lemma 3.1]. (2) Since cos(k\u03be) = ( e\u2212ik\u03be + eik\u03be ) /2, we have\nn\u2211 k=1 cos (k\u03be) ak = n\u2211 k=1 akeik\u03be + ake\u2212ik\u03be 2 = 1 2 n\u2211 k=1 ( aei\u03be )k + 1 2 n\u2211 k=1 ( ae\u2212i\u03be )k = 1\n2\naei\u03be ( 1\u2212 ( aei\u03be )n) 1\u2212 aei\u03be + 1 2 ae\u2212i\u03be ( 1\u2212 ( ae\u2212i\u03be )n) 1\u2212 ae\u2212i\u03be\n= a ( ei\u03be + e\u2212i\u03be ) \u2212 2a2 \u2212 an+1 ( ei(n+1)\u03be + e\u2212i(n+1)\u03be ) + an+2(ein\u03be + e\u2212in\u03be)\n2 (1\u2212 a (e\u2212i\u03be + ei\u03be) + a2)\n= a cos(\u03be)\u2212 a2 \u2212 an+1 cos((n+ 1)\u03be) + an+2 cos(n\u03be)\n1\u2212 2a cos(\u03be) + a2 .\nIf a = 1, it yields that\nn\u2211 k=1 cos(k\u03be) = cos(\u03be)\u2212 1\u2212 cos((n+ 1)\u03be) + cos(n\u03be) 2\u2212 2 cos (\u03be)\n= cos (n\u03be)\u2212 cos ((n+ 1) \u03be) 4 sin2 ( \u03be 2 ) \u2212 1 2 =\nsin (( n+ 12 ) \u03be )\n2 sin ( \u03be 2 ) \u2212 1 2 .\n\u25a1\nThe expression (3.9) of the variance Var(eN ) depends heavily on det(A). Recall that (3.3) is a symplectic method if and only if det(A) = 1 (see e.g., [14]). Hence we are in the position to simplify the expressions of the variances of the errors for symplectic and non-symplectic methods, separately. By means of Lemma 3.2, we simplify Var(eN ) further to get the following statements.\nProposition 3.3. For the symplectic method with \u03be \u0338= h, the variance of the error eN is given by\nVar(eN ) = \u03b12b21 (2T + h) 4 sin2 (\u03be) \u2212 \u03b1 2hb21 sin ((2N + 1) \u03be) 4 sin3 (\u03be) + \u03b12 (a12b2 \u2212 a22b1)2 (2T \u2212 h) 4 sin2 (\u03be)\n+ \u03b12b1 sin (\u03be) ( Z+3 + Z \u2212 3 ) \u2212 \u03b1 2h (a12b2 \u2212 a22b1)2 sin ((2N \u2212 1) \u03be) 4 sin3 (\u03be)\n\u2212 \u03b1 2b1h (a12b2 \u2212 a22b1) sin (2N\u03be)\n2 sin3 (\u03be) +\n\u03b12\n2 T + \u03b12b1 (a12b2 \u2212 a22b1)T sin (\u03be) tan (\u03be)\n(3.10)\n+ \u03b12 (a12b2 \u2212 a22b1) sin (h)\nsin (\u03be) (Z+2 \u2212 Z \u2212 2 )\u2212 \u03b1 2b1(Z + 2 + Z \u2212 2 )\u2212\n\u03b12 sin (2T )\n4\n\u2212\n( 2\u03b12 (a12b2 \u2212 a22b1) sin2 ( h 2 ) sin (\u03be) + \u03b12b1 tan(\u03be) ) (Z+1 + Z \u2212 1 )\u2212 \u03b1 2b1,\nwhere\nZ\u00b11 = cos ( \u03be\u00b1h 2 ) \u2212 cos (( N \u2212 12 ) (\u03be \u00b1 h) ) 2 sin ( \u03be\u00b1h 2 ) , Z\u00b12 = sin ((N \u2212 12) (\u03be \u00b1 h)) 2 sin ( \u03be\u00b1h 2 ) ,\nPROBABILISTIC EVOLUTION OF THE ERROR 11 Z\u00b13 = cos ( \u03be\u00b1h 2 ) \u2212 cos (( N + 12 ) (\u03be \u00b1 h) ) 2 sin ( \u03be\u00b1h 2\n) . For the symplectic method with \u03be = h,\nVar(eN ) = \u03b12b21\n2 sin2 (h)\n( T + 1\n2 h\n) + \u03b12 (a12b2 \u2212 a22b1) ( sin (2T \u2212 h) 2 sin (h) \u2212N + 1 2 ) + \u03b12 (a12b2 \u2212 a22b1)2\n2 sin2 (h)\n( T \u2212 1\n2 h\n) \u2212 \u03b1\n2h (a12b2 \u2212 a22b1)2 sin (2T \u2212 h) 4 sin3 (h)\n+ \u03b12b1 (a12b2 \u2212 a22b1)T sin (h) tan (h) \u2212 \u03b1 2b1h (a12b2 \u2212 a22b1) sin (2T ) 2 sin3 (h) \u2212 \u03b1 2 sin (2T ) 4 (3.11)\n\u2212 \u03b1 2b1 (cos (h)\u2212 cos (2T \u2212 h)) 2 tan (h) sin (h) \u2212 \u03b1 2hb21 sin (2T + h) 4 sin3 (h) + \u03b12T 2\n+ \u03b12b1 (cos (h)\u2212 cos (2T + h))\n2 sin2 (h) \u2212 \u03b12b1N \u2212 \u03b12b1 sin (2T \u2212 h) 2 sin (h)\n\u2212 \u03b12 (a12b2 \u2212 a22b1) sin2\n( h 2 ) (cos (h)\u2212 cos (2T \u2212 h))\nsin2 (h) \u2212 \u03b1 2b1 2 .\nProposition 3.4. For the non-symplectic method, the variance of the error eN is given by\nVar(eN ) = \u03b12hb21\n( 1\u2212 (det (A))N ) (2\u2212 2 det (A)) sin2 (\u03be) + \u03b12h (a12b2 \u2212 a22b1)2 ( 1\u2212 (det (A))N\u22121 ) 2 (1\u2212 det (A)) sin2 (\u03be)\n\u2212\n( \u03b12b1 \u221a det(A)\ntan (\u03be) +\n2\u03b12 (a12b2 \u2212 a22b1) sin2 ( h 2 ) sin (\u03be) ) (H+1 +H \u2212 1 )\n\u2212 \u03b12b1 \u221a det(A)(H+2 +H \u2212 2 ) + \u03b12(a12b2 \u2212 a22b1) sin(h) sin(\u03be) (H+2 \u2212H \u2212 2 )\n+ \u03b12hb1(a12b2 \u2212 a22b1)(1\u2212 (det(A))N ) (1\u2212 det(A)) sin(\u03be) tan(\u03be) \u221a det(A) \u2212 2\u03b12b1 \u2212 \u03b12 sin(2T ) 4\n\u2212 \u03b1 2h(a12b2 \u2212 a22b1)2\n2 sin2 (\u03be) H5 \u2212 \u03b12hb1(a12b2 \u2212 a22b1) sin(\u03be) \u221a det(A) H6 + \u03b12 2 T\n+ \u03b12b1 sin(\u03be) (H+3 +H \u2212 3 )\u2212\n( \u03b12hb21\n2 sin2(\u03be) + \u03b12hb1(a12b2 \u2212 a22b1) sin(\u03be) tan(\u03be) \u221a det(A)\n) H4,\nwhere\nH\u00b11 = sin (\u03be \u00b1 h)\u2212 (det (A))\nN\u22121 2 sin (N\u03be \u00b1 T ) + (det (A)) N 2 sin ((N \u2212 1) \u03be \u00b1 T \u2213 h) 1\u2212 2 \u221a det (A) cos (\u03be \u00b1 h) + det (A) ,\nH\u00b12 = cos(\u03be \u00b1 h)\u2212\n\u221a det(A)\u2212 (det(A)) N\u22121 2 cos(N\u03be \u00b1 T ) + (det(A)) N 2 cos((N \u2212 1)\u03be \u00b1 T \u2213 h)\n1\u2212 2 \u221a det(A) cos(\u03be \u00b1 h) + det(A)\n,\nH\u00b13 = sin(\u03be \u00b1 h)\u2212 (det(A))\nN 2 sin((N + 1)\u03be \u00b1 T \u00b1 h) + (det(A)) N+1 2 sin(N\u03be \u00b1 T ) 1\u2212 2 \u221a det(A) cos(\u03be \u00b1 h) + det(A) ,\n12 JIALIN HONG, GE LIANG, AND DERUI SHENG\nH4 = cos(2\u03be)\u2212 det(A)\u2212 (det(A))N cos(2N\u03be + 2\u03be) + (det(A))N+1 cos(2N\u03be)\n1\u2212 2 det(A) cos(2\u03be) + (det(A))2 ,\nH5 = cos(2\u03be)\u2212 det(A)\u2212 (det (A))N\u22121 cos (2N\u03be) + (det (A))N cos (2N\u03be \u2212 2\u03be)\n1\u2212 2 det (A) cos (2\u03be) + (det (A))2 ,\nH6 = sin(2\u03be)\u2212 (det(A))N sin(2N\u03be + 2\u03be) + (det(A))N+1 sin(2N\u03be)\n1\u2212 2 det(A) cos(2\u03be) + (det(A))2 .\n3.1. Probabilistic evolution of errors for symplectic methods. In this part, we focus on the limit theorems and the large deviation principle of the errors {eN}N\u2208N+ for several symplectic methods, including stochastic \u03b2 methods (see e.g., [11, equation (2.7)]) and general symplectic methods with \u03be = h.\n3.1.1. Symplectic \u03b2 methods (\u03b2 \u2208 [0, 1]). Applying the symplectic \u03b2 method to (3.1), the coefficients A\u03b2 and b\u03b2 are given by\nA\u03b2 = 1\n1 + \u03b2(1\u2212 \u03b2)h2\n( 1\u2212 (1\u2212 \u03b2)2h2 h \u2212h 1\u2212 \u03b22h2 ) ,\nb\u03b2 = 1\n1 + \u03b2(1\u2212 \u03b2)h2\n( (1\u2212 \u03b2)h\n1\n) .\nThe symplectic \u03b2 method reduces to the midpoint method when \u03b2 = 12 . Notice that the components of A\u03b2 and b\u03b2 satisfy (3.4), which implies that Assumption 2.1 holds.\nIt is clear that\ndet(A\u03b2) = 1, tr(A\u03b2) = 2\u2212\n( 2\u03b22 \u2212 2\u03b2 + 1 ) h2\n1 + \u03b2 (1\u2212 \u03b2)h2 , a12b2 \u2212 a22b1 =\n\u03b2h\n1 + \u03b2(1\u2212 \u03b2)h2 , sin(\u03be) = h \u221a 4\u2212 (1\u2212 2\u03b2)2h2\n2 + 2\u03b2(1\u2212 \u03b2)h2 , cos(\u03be) =\n2\u2212 (2\u03b22 \u2212 2\u03b2 + 1)h2\n2 + 2\u03b2(1\u2212 \u03b2)h2 .\nBy substituting the above expressions into (3.10), we obtain\nVar(eN ) = 2\u03b12(1\u2212 \u03b2)2(T + 12h) 4\u2212 (1\u2212 2\u03b2)2h2 \u2212 2\u03b1 2(1\u2212 \u03b2)2(1 + \u03b2(1\u2212 \u03b2)h2) sin(2N\u03be + \u03be) (4\u2212 (1\u2212 2\u03b2)2h2) 32\n\u2212 2\u03b1 2\u03b22(1 + (1\u2212 \u03b2)\u03b2h2) sin((2N \u2212 1)\u03be)\n(4\u2212 (1\u2212 2\u03b2)2h2) 32 + 2\u03b12(1\u2212 \u03b2)\u03b2T (2\u2212 (2\u03b22 \u2212 2\u03b2 + 1)h2) (1 + \u03b2(1\u2212 \u03b2)h2)(4\u2212 (1\u2212 2\u03b2)2h2)\n\u2212 4\u03b1 2(1\u2212 \u03b2)\u03b2(1 + \u03b2(1\u2212 \u03b2)h2) sin(2N\u03be) (4\u2212 (1\u2212 2\u03b2)2h2) 32 \u2212 \u03b1 2(1\u2212 \u03b2)h 1 + \u03b2(1\u2212 \u03b2)h2 + \u03b12 2 T \u2212 \u03b1 2 sin(2T ) 4 (3.12)\n\u2212 ( \u03b12(1\u2212 \u03b2)(2\u2212 (2\u03b22 \u2212 2\u03b2 + 1)h2) (1 + \u03b2(1\u2212 \u03b2)h2) \u221a 4\u2212 (1\u2212 2\u03b2)2h2 + 4\u03b12\u03b2 sin2(h2 )\u221a 4\u2212 (1\u2212 2\u03b2)2h2 ) (Z+1 + Z \u2212 1 )\n\u2212 \u03b1 2(1\u2212 \u03b2)h\n2(1 + \u03b2(1\u2212 \u03b2)h2) (Z+2 + Z \u2212 2 ) + 2\u03b12\u03b2 sin(h)\u221a 4\u2212 (1\u2212 2\u03b2)2h2 (Z+2 \u2212 Z \u2212 2 )\n+ 2\u03b12(1\u2212 \u03b2)\u221a\n4\u2212 (1\u2212 2\u03b2)2h2 (Z+3 + Z \u2212 3 ) + 2\u03b12\u03b22(T \u2212 12h) 4\u2212 (2\u03b2 \u2212 1)2h2 .\nCase 1 : \u03b2 \u2208 [0, 12 \u2212 \u221a 6 6 ) \u222a ( 1 2 \u2212 \u221a 6 6 , 1 2 + \u221a 6 6 ) \u222a ( 1 2 + \u221a 6 6 , 1]. By the Taylor expansion arcsin(h) = h+ 16h 3 + 340h 5 +O(h7), we have\n\u03be = h+\n( \u03b22\n2 \u2212 \u03b2 2 + 1 24\n) h3 + ( 3\u03b24\n8 \u2212 3\u03b2\n3\n4 +\n7\u03b22\n16 \u2212 \u03b2 16 + 3 640\n) h5 +O(h7),\nPROBABILISTIC EVOLUTION OF THE ERROR 13\nwhich implies that\nsin ( \u03be \u2212 h 2 ) = ( \u03b22 4 \u2212 \u03b2 4 + 1 48 ) h3 + ( 3\u03b24 16 \u2212 3\u03b2 3 8 + 7\u03b22 32 \u2212 \u03b2 32 + 3 1280 ) h5 +O(h7).\nAs other terms in (3.12) can be similarly expanded, one gets\nVar(eN ) = ( 3\u03b22 \u2212 3\u03b2 + 1 )(\u03b12 6 T + \u03b12 12 sin (2T ) ) h2 +O(h3).\nIn view of Theorem 2.3, we obtain the central limit theorem of the error of the stochastic \u03b2 method\nNeN \u2212 E[NeN ] \u2192 N ( 0, (3\u03b22 \u2212 3\u03b2 + 1) (\u03b12 6 T 3 + \u03b12 12 T 2 sin(2T ) )) in distribution,\nand the large deviation rate function of the error of the stochastic \u03b2 method\nI(x) = 6x2\n\u03b12(3\u03b22 \u2212 3\u03b2 + 1)(2T 3 + T 2 sin(2T )) , x \u2208 R.\nCase 2 : \u03b2 \u2208 {12 \u2212 \u221a 6 6 , 1 2 + \u221a 6 6 }. Since \u03b2 2\n4 \u2212 \u03b2 4 + 1 48 = 0, it yields that sin( \u03be\u2212h 2 ) = h5 960 + h7 24192 + O(h 9). By expanding\ncos( \u03be\u2212h2 ), cos((N \u2212 1 2)(\u03be \u2212 h)), sin((N \u2212 1 2)(\u03be \u2212 h)) and cos((N + 1 2)(\u03be \u2212 h)) to O(h 7), we can similarly use Proposition 3.3 to obtain\nVar(eN ) =\n( 7\u03b12\n36 T +\n\u03b12 16 sin(2T )\n) h2 +O(h3).\nCombined with Theorem 2.3, the following central limit theorem of the error holds NeN \u2212 E[NeN ] \u2192 N ( 0, ( 7\u03b12\n36 T 3 +\n\u03b12 16 T 2 sin(2T )\n)) in distribution.\nIn addition, the large deviation rate function of the error of the stochastic \u03b2 method is given by I(x) = 72x 2\n28\u03b12T 3+9\u03b12T 2 sin(2T ) for x \u2208 R.\nRemark 3.5. For any fixed T > 0, the error constant of the midpoint method (\u03b2 = 12) is minimal among symplectic \u03b2 methods.\n3.1.2. General symplectic methods with \u03be = h. By (3.7), for the symplectic method, the condition \u03be = h is equivalent to tr(A) = 2 cos(h). By assuming further that the coefficients aij(\u00b7), bi(\u00b7), i, j = 1, 2, are smooth functions satisfying (3.4), we have\na11 = 1 + a (1) 11 h 2 + a (2) 11 h 3 + a (3) 11 h 4 +O(h5),\na22 = 1\u2212 (1 + a(1)11 )h 2 \u2212 a(2)11 h\n3 + ( 1\n12 \u2212 a(3)11 )h 4 +O(h5),\na12 = h+ a (1) 12 h 2 + a (2) 12 h 3 + a (3) 12 h 4 +O(h5), a21 = \u2212h+ a(1)21 h 2 + a (2) 21 h 3 + a (3) 21 h 4 +O(h5),\nb1 = b (1) 1 h+ b (2) 1 h 2 + b (3) 1 h 3 + b (4) 1 h 4 +O(h5), b2 = 1 + b (1) 2 h+ b (2) 2 h 2 + b (3) 2 h 3 + b (4) 2 h 4 +O(h5).\n(3.13)\n14 JIALIN HONG, GE LIANG, AND DERUI SHENG\nIn view of (3.11) and (3.13), it yields that Var(eN ) = K e Th 2+O(h3), where the error constant KeT is given by\nKeT = \u03b1 2\n( 1 + 3b\n(1) 1 (b (1) 1 \u2212 1) + 3(a (1) 12 + b (1) 2 ) 2\n6 T +\n(1\u2212 2b(1)1 )(a (1) 12 + b (1) 2 )\n2 (cos(2T )\u2212 1)\n+ 1 + 3b\n(1) 1 (b (1) 1 \u2212 1)\u2212 3(a (1) 12 + b (1) 2 ) 2\n12 sin (2T )\n) . (3.14)\nFurthermore, Theorem 2.3 yields the corresponding central limit theorem NeN \u2212 E[NeN ] \u2192 N ( 0, T 2KeT ) in distribution,\nand the corresponding large deviation rate function I(x) = x 2\n2KeTT 2 , x \u2208 R.\nWe present three existing symplectic methods satisfying \u03be = h in Table 1.\nRemark 3.6. When T \u226b 1, among the symplectic methods satisfying \u03be = h, the numerical method satisfying\nb (1) 1 =\n1 2 and a (1) 12 + b (1) 2 = 0 (3.15)\nhas the minimal error constant. Obviously the optimal method satisfies (3.15). Besides, we construct a symplectic method satisfying (3.15):\nA = ( cos(h) sin(h) \u2212 sin(h) cos(h) ) , b = ( h 2 1 ) . (3.16)\n3.2. Probabilistic evolution of errors for non-symplectic methods. This part is devoted to studying the limit theorems and the large deviation principle of the errors {eN}N\u2208N+ for several non-symplectic methods, including stochastic \u03b8-methods (\u03b8 \u0338= 12) and the PC(EMBEM) method (see e.g., [14]).\n3.2.1. Stochastic \u03b8-methods (\u03b8 \u2208 [0, 12) \u222a ( 1 2 , 1]). For \u03b8 \u2208 [0, 1 2) \u222a ( 1 2 , 1], the coefficients of the stochastic \u03b8-method for (3.1) is given by\nA\u03b8 = 1\n1 + \u03b82h2\n( 1\u2212 (1\u2212 \u03b8)\u03b8h2 h \u2212h 1\u2212 (1\u2212 \u03b8)\u03b8h2 ) , b\u03b8 =\n1\n1 + \u03b82h2 ( \u03b8h 1 ) ,\nfor which (3.4) is satisfied, and so is Assumption 2.1. It is readily to show that\ncos(\u03be) = 1\u2212 (1\u2212 \u03b8)\u03b8h2\u221a\n1 + (1\u2212 \u03b8)2h2 \u221a 1 + \u03b82h2 ,\nPROBABILISTIC EVOLUTION OF THE ERROR 15\nsin(\u03be) = h\u221a\n1 + (1\u2212 \u03b8)2h2 \u221a 1 + \u03b82h2 ,\ndet(A\u03b8) = 1 + (1\u2212 \u03b8)2h2\n1 + \u03b82h2 , a12b2 \u2212 a22b1 = (1\u2212 \u03b8)h 1 + \u03b82h2 .\nOn this basis, we can further formulate \u03be in terms of h as follows\n\u03be = h+ ( \u03b8 \u2212 \u03b82 \u2212 1\n3\n) h3 + ( \u03b84 \u2212 2\u03b83 + 2\u03b82 \u2212 \u03b8 + 1\n5\n) h5\n+ ( 3\u03b85 \u2212 \u03b86 \u2212 5\u03b84 + 5\u03b83 \u2212 3\u03b82 + \u03b8 \u2212 1\n7\n) h7 +O(h9).\nPlugging the above relations into Proposition 3.4, we can obtain\nVar(eN ) = K \u03b8 Th 2 +O(h3), (3.17)\nwhere the error constant K\u03b8T is given by\nK\u03b8T = \u03b12(2\u03b8 \u2212 1)2 24 T 3 \u2212 \u03b1 2 sin(2T )(2\u03b8 \u2212 1)2 16 T 2\n+ \u03b12 ( (1\u2212 \u03b8)3 \u2212 5\u03b83\n6 + (2\u03b8 \u2212 1)2 cos(2T ) 16\n) T + \u03b12 ( 1\n48 +\n(2\u03b8 \u2212 1)2\n32\n) sin(2T ).\nThus, by Theorem 2.3, the error {eN}N\u2208N+ of the stochastic \u03b8-method with \u03b8 \u2208 [0, 12)\u222a ( 1 2 , 1] satisfies the central limit theorem\nNeN \u2212 E[NeN ] \u2192 N (0, T 2K\u03b8T ) in distribution,\nand the large deviation principle with the good rate function I(x) = x 2\n2K\u03b8TT 2 , x \u2208 R.\n3.2.2. PC(EM-BEM) method. The PC(EM-BEM) method is a predictor-corrector method using the Euler\u2013Maruyama method as predictor and the backward Euler\u2013Maruyama method as corrector, whose coefficients are given by\nA = ( 1\u2212 h2 h \u2212h 1\u2212 h2 ) , b = ( h 1 ) .\nBy a straightforward calculation, we have\ndet(A) = 1\u2212 h2 + h4, tr(A) = 2\u2212 2h2, a12b2 \u2212 a22b1 = h3,\nsin(\u03be) = h\u221a\n1\u2212 h2 + h4 , cos(\u03be) = 1\u2212 h2\u221a 1\u2212 h2 + h4 ,\nwhich leads to\n\u03be = h+ 2h3\n3 +\nh5\n5 +\nh7\n7 +O(h9). (3.18)\nBased on (3.18), we can simplify the Taylor series in Proposition 3.4 into\nVar(eN ) =\n( \u03b12\n24 T 3 \u2212 \u03b1\n2 sin(2T )\n16 T 2 +\n( \u03b12 cos(T ) 2\n8 +\n5\u03b12\n48\n) T + 5\u03b12 sin(2T )\n96\n) h2 +O(h3). (3.19)\nThen it follows from Theorem 2.3 that for the PC(EM-BEM) method, NeN \u2212 E[NeN ] converges to\nN ( 0, (\u03b12 24 T 5 \u2212 \u03b1 2 sin(2T ) 16 T 4 + (\u03b12 cos(T )2 8 + 5\u03b12 48 ) T 3 + 5\u03b12T 2 sin(2T ) 96 ))\n16 JIALIN HONG, GE LIANG, AND DERUI SHENG\nin distribution, and the large deviation rate function I is given by\nI(x) = 48x2\n4\u03b12T 5 \u2212 6\u03b12 sin(2T )T 4 + (12\u03b12 cos2(T ) + 10\u03b12)T 3 + 5\u03b12T 2 sin(2T ) . (3.20)\n3.3. Superiority of stochastic symplectic methods. Let e (s) N and e (ns) N be the errors of the considered symplectic method and non-symplectic method for (3.1), respectively. It has been shown in subsection 3.1 and subsection 3.2 that the error constants K (s) T := KT \u223c T for symplectic methods and K (ns) T := KT \u223c T 3 for non-symplectic methods, respectively. Since K (s) T /K (ns) T \u2192 0 as T \u2192 \u221e, one can choose a sufficiently large constant T0 > 0 so that K (s) T < K (ns) T for all T \u2265 T0. Based on Theorem 2.3, we try to make a comparison between the considered symplectic methods and non-symplectic methods.\nProposition 3.7. Let T \u2265 T0 and \u03f5 > 0 be arbitrarily fixed. Then there exists some sufficiently large N0 \u2208 N+ such that for any N \u2265 N0,\nP ( |e(s)N \u2212 E[e (s) N ]| > \u03f5\nN\n) < P ( |e(ns)N \u2212 E[e (ns) N ]| > \u03f5\nN\n) , (3.21)\nP(|e(s)N | > \u03f5) P(|e(ns)N | > \u03f5)\n\u2264 exp ( \u2212 1\n2 N2R\u03f5(T )\n) , (3.22)\nwhere R\u03f5(T ) := \u03f5 2\n2T 2\n( 1\nK (s) T\n\u2212 1 K\n(ns) T\n) > 0.\nProof. Given \u03f5 > 0, it follows from Theorem 2.3(ii) that\nlim N\u2192\u221e\nP ( |Ne(s)N \u2212 E[Ne (s) N ]| > \u03f5 ) = N (0, T 2K(s)T )({|x| > \u03f5})\n= N (0, T 2K(ns)T ) ({ |x| > \u03f5 \u221a K (ns) T /K (s) T }) < N (0, T 2K(ns)T ) ({ |x| > \u03f5 }) = lim N\u2192\u221e P ( |Ne(ns)N \u2212 E[Ne (ns) N ]| > \u03f5 ) .\nTherefore there exists N1 \u2208 N+ such that (3.21) holds for any N \u2265 N1. From the large deviation principles of {e(s)N }N\u2208N+ and {e (ns) N }N\u2208N+ in Theorem 2.3(iii), we know that\nlim N\u2192\u221e\n1 N2 log ( P(|e(s)N | > \u03f5) P(|e(ns)N | > \u03f5) ) = \u2212R\u03f5(T ).\nHence there exists some N2 \u2208 N+ such that\n1 N2 log ( P(|e(s)N | > \u03f5) P(|e(ns)N | > \u03f5) ) \u2264 \u22121 2 R\u03f5(T ), \u2200N > N2,\ni.e., (3.22) holds for any N \u2265 N2. By taking N0 = max{N1, N2}, we finish the proof. \u25a1\nThe above proposition compares the error\u2019s deviation of symplectic and non-symplectic methods. On one hand, the relation (3.21) indicates that at the scale \u03f5/N , the probability that the error deviates from the mean is smaller for the symplectic method than that for the non-symplectic method. On the other hand, the relation (3.22) reveals that at the scale \u03f5, the probability of the error\u2019s deviation from the origin decays exponentially faster for the symplectic method than that for the non-symplecic method. In summary, symplectic methods\nPROBABILISTIC EVOLUTION OF THE ERROR 17\nare superior to non-symplectic methods from the perspective of the probabilistic evolution of the error, although they may have the same mean square convergence order.\n4. Numerical experiments\nThis section provides numerical experiments to illustrate the theoretical results by numerically simulating the exponential method, integral method, optimal method, method (3.16), stochastic \u03b8-method (\u03b8 = 14) and PC(EM-BEM) method. In the following experiments, we set the initial data (x0, y0) = (1, 0) and \u03b1 = 1.\nFirst, we show the relation between Var(eN )/h 2 and T evaluated with times (20, 40, 60, 80) and 2000 sample paths. For the exponential method, integral method, optimal method and method (3.16), we choose N = 27 with the corresponding time step-sizes ( 5\n25 , 5 24 , 15 25 , 5 23 ). As\nis displayed in Fig. 1, Var(eN )/h 2 for these symplectic methods grows linearly with respect to time T , which is consistent with the reference line g(T ) = KeT \u223c T , where KeT is given by (3.14). For the stochastic \u03b8-method and PC(EM-BEM) method, we consider the time step-sizes ( 5\n213 , 5 212 , 15 213 , 5 211 ) by taking N = 215. Fig. 2 shows that Var(eN )/h 2 \u223c T 3, which\ncoincides with the theoretical results (3.17) and (3.19). Next, we follow the algorithm in [13] to numerically simulate the large deviation rate function of {eN}N\u2208N+ . More precisely, for a fixed time T > 0 and sufficiently large N0, we take 1\nN20 logE[e\u03bbN20 eN0 ] as the approximation of the logarithmic moment generating function\n\u039b(\u03bb). Based on the Monte\u2013Carlo method, we obtain M0 sampling paths of eN0 and use 1 M0 \u2211M0 i=1 exp(\u03bbN 2 0 e (i) N0 ) to approximate the expectation E[e\u03bbN20 eN0 ]. Hence we simulate \u039b(\u03bb)\n18 JIALIN HONG, GE LIANG, AND DERUI SHENG\nby computing\n\u039bM0,N0(\u03bb) := 1 N0 log ( 1 M0 M0\u2211 i=1 exp ( \u03bbN20 e (i) N0 )) .\nFurther, we approximate the value of the rate function I(y) = sup\u03bb\u2208R{\u03bby \u2212\u039b(\u03bb)} at y(\u03bb) := (\u039bM0,N0)\n\u2032(\u03bb) by IM0,N0(y(\u03bb)) := \u03bby(\u03bb)\u2212\u039bM0,N0(\u03bb). In the following, set \u03bb(j) = \u22122+0.0001(j\u2212 1), j = 1, 2, \u00b7 \u00b7 \u00b7 , 40001, N0 = 100, M0 = 2000. The large deviation rate functions of {eN}N\u2208N+ are showed in Fig. 3 and Fig. 4, which validates our theoretical results.\n5. Conclusions and future aspects\nBy focusing on the linear stochastic differential equation, we present the probabilistic evolution of the error of general numerical method via establishing the strong law of large numbers,\nPROBABILISTIC EVOLUTION OF THE ERROR 19\nthe central limit theorem and the large deviation principle. For general stochastic differential equations, there have been fruitful results on the strong and weak error analysis of numerical methods. Based on the strong convergence result, the strong law of large numbers of the error of common stochastic numerical method can still be derived by using the Borel\u2013Cantelli lemma. However, it is still unclear that whether the central limit theorem and large deviation principle hold for the errors of numerical methods for general stochastic differential equations. This problem is meaningful but also challenging since it is hard to obtain the distributions of the errors of numerical methods for general stochastic differential equations.\nOn the other hand, we provide a new perspective of explaining the superiority of the symplectic methods in the long-time computation by taking the linear stochastic oscillator as the test equation and comparing the probabilistic evolutions of the errors of several concrete symplectic and non-symplectic methods. For general stochastic Hamiltonian systems, we also expect to explain the mechanism of the superiority of symplectic methods via studying the probabilistic evolution of the error. We will study these problems in our future research.\nReferences\n[1] C. Chen, J. Hong, D. Jin, and L. Sun. Asymptotically-preserving large deviations principles by stochastic symplectic methods for a linear stochastic oscillator. SIAM J. Numer. Anal., 59(1):32\u201359, 2021. [2] C. Chen, J. Hong, D. Jin, and L. Sun. Large deviations principles for symplectic discretizations of stochastic linear Schro\u0308dinger equation. Potential Anal., https://doi.org/10.1007/s11118-022-09990-z, 2022. [3] J. Cui, J. Hong, Z. Liu, and W. Zhou. Stochastic symplectic and multi-symplectic methods for nonlinear Schro\u0308dinger equation with white noise dispersion. J. Comput. Phys., 342:267\u2013285, 2017. [4] A. Dembo and O. Zeitouni. Large Deviations Techniques and Applications, volume 38. Springer Science & Business Media, 2009. [5] Lawrence C. Evans. An introduction to stochastic differential equations. American Mathematical Society, Providence, RI, 2013. [6] J. Hong and L. Sun. Symplectic Integration of Stochastic Hamiltonian Systems, volume 2314 of Lecture Notes in Mathematics. Springer Nature, 2022. [7] J. Hong and X. Wang. Invariant Measures for Stochastic Nonlinear Schro\u0308dinger Equations. Numerical Approximations and Symplectic Structures, volume 2251 of Lecture Notes in Mathematics. Springer, Singapore, 2019. [8] Jean Jacod and Philip Protter. Asymptotic error distributions for the Euler method for stochastic differential equations. Ann. Probab., 26(1):267\u2013307, 1998. [9] A. Klenke. Probability Theory. Universitext. Springer-Verlag London, Ltd., London, 2008. A comprehensive course, Translated from the 2006 German original. [10] A. H. S. Melb\u00f8and D. J. Higham. Numerical simulation of a linear stochastic oscillator with additive noise. Appl. Numer. Math., 51(1):89\u201399, 2004.\n20 JIALIN HONG, GE LIANG, AND DERUI SHENG\n[11] G. N. Milstein and M. V. Tretyakov. Stochastic Numerics for Mathematical Physics. Scientific Computation. Springer-Verlag, Berlin, 2004. [12] Philip Protter, Lisha Qiu, and Jaime San Martin. Asymptotic error distribution for the Euler scheme with locally Lipschitz coefficients. Stochastic Process. Appl., 130(4):2296\u20132311, 2020. [13] C. M. Rohwer, F. Angeletti, and H. Touchette. Convergence of large-deviation estimators. Phys. Rev. E, 92:052104, Nov 2015. [14] M. J. Senosiain and A. Tocino. A review on numerical schemes for solving a linear stochastic oscillator. BIT, 55(2):515\u2013529, 2015. [15] L. Wang, J. Hong, and L. Sun. Modified equations for weakly convergent stochastic symplectic schemes via their generating functions. BIT, 56(3):1131\u20131162, 2016. [16] Z. Wang, J. Xin, and Z. Zhang. Computing effective diffusivity of chaotic and stochastic flows using structure-preserving schemes. SIAM J. Numer. Anal., 56(4):2322\u20132344, 2018.\nAcademy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing 100190, China; School of Mathematical Sciences, University of Chinese Academy of Sciences, Beijing 100049, China\nEmail address: hjl@lsec.cc.ac.cn\nAcademy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing 100190, China; School of Mathematical Sciences, University of Chinese Academy of Sciences, Beijing 100049, China\nEmail address: liangge2020@lsec.cc.ac.cn (Corresponding author)\nDepartment of Applied Mathematics, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong\nEmail address: derui.sheng@polyu.edu.hk"
        }
    ],
    "title": "PROBABILISTIC EVOLUTION OF THE ERROR OF NUMERICAL METHOD FOR LINEAR STOCHASTIC DIFFERENTIAL EQUATION",
    "year": 2023
}