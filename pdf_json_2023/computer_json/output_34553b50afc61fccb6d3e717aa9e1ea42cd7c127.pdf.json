{
    "abstractText": "Las redes adversarias generativas (GANs) son un m\u00e9todo basado en el entrenamiento de dos redes neuronales, una denominada generadora y otra discriminadora, compitiendo entre s\u00ed para generar nuevas instancias que se asemejen a las de la distribuci\u00f3n de probabilidad de los datos de entrenamiento. Las GANs tienen una amplia gama de aplicaciones en campos como la visi\u00f3n por computadora, la segmentaci\u00f3n sem\u00e1ntica, la s\u00edntesis de series temporales, la edici\u00f3n de imagen, el procesamiento del lenguaje natural y la generaci\u00f3n de imagen a partir de texto, entre otros. Los modelos generativos modelizan la distribuci\u00f3n de probabilidad de un conjunto de datos, pero en lugar de proporcionar un valor de probabilidad, generan nuevas instancias cercanas a la distribuci\u00f3n original. Las GANs utilizan un esquema de aprendizaje que permite codi\ue000car los atributos de\ue000nitorios de la distribuci\u00f3n de probabilidad en una red neuronal, lo que permite generar instancias que se asemejen a la distribuci\u00f3n de probabilidad original. En este art\u00edculo se presentan los fundamentos te\u00f3ricos de este tipo de redes as\u00ed como los esquemas b\u00e1sicos de la arquitectura y algunas de sus aplicaciones. Este art\u00edculo est\u00e1 en espa\u00f1ol para facilitar la llegada de este conocimiento cient\u00ed\ue000co a la comunidad hispanohablante. ABSTRACT Generative adversarial networks (GANs) are a method based on the training of two neural networks, one called generator and the other discriminator, competing with each other to generate new instances that resemble those of the probability distribution of the training data. GANs have a wide range of applications in \ue000elds such as computer vision, semantic segmentation, time series synthesis, image editing, natural language processing, and image generation from text, among others. Generative models model the probability distribution of a data set, but instead of providing a probability value, they generate new instances that are close to the original distribution. GANs use a learning scheme that allows the de\ue000ning attributes of the probability distribution to be encoded in a neural network, allowing instances to be generated that resemble the original probability distribution. This article presents the theoretical foundations of this type of network as well as the basic architecture schemes and some of its applications. This article is in Spanish to facilitate the arrival of this scienti\ue000c knowledge to the Spanish-speaking community.",
    "authors": [
        {
            "affiliations": [],
            "name": "FUNDAMENTOS TE\u00d3RICOS"
        },
        {
            "affiliations": [],
            "name": "Y APLICACIONES"
        },
        {
            "affiliations": [],
            "name": "Jordi de la Torre"
        }
    ],
    "id": "SP:f1a13baaebf65a37e963927cf13d5f57537b6538",
    "references": [
        {
            "authors": [
                "Antonia Creswell",
                "Tom White",
                "Vincent Dumoulin",
                "Kai Arulkumaran",
                "Biswa Sengupta",
                "Anil A Bharath"
            ],
            "title": "Generative adversarial networks: An overview",
            "venue": "IEEE signal processing magazine,",
            "year": 2018
        },
        {
            "authors": [
                "Gilad Cohen",
                "Raja Giryes"
            ],
            "title": "Generative adversarial networks",
            "venue": "arXiv preprint arXiv:2203.00667,",
            "year": 2022
        },
        {
            "authors": [
                "Gintare Karolina Dziugaite",
                "Daniel M Roy",
                "Zoubin Ghahramani"
            ],
            "title": "Training generative neural networks via maximum mean discrepancy optimization",
            "venue": "arXiv preprint arXiv:1505.03906,",
            "year": 2015
        },
        {
            "authors": [
                "Tero Karras",
                "Timo Aila",
                "Samuli Laine",
                "Jaakko Lehtinen"
            ],
            "title": "Progressive growing of gans for improved quality, stability, and variation",
            "venue": "arXiv preprint arXiv:1710.10196,",
            "year": 2017
        },
        {
            "authors": [
                "Christian Ledig",
                "Lucas Theis",
                "Ferenc Husz\u00e1r",
                "Jose Caballero",
                "Andrew Cunningham",
                "Alejandro Acosta",
                "Andrew Aitken",
                "Alykhan Tejani",
                "Johannes Totz",
                "Zehan Wang"
            ],
            "title": "Photo-realistic single image super-resolution using a generative adversarial network",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Pauline Luc",
                "Camille Couprie",
                "Soumith Chintala",
                "Jakob Verbeek"
            ],
            "title": "Semantic segmentation using adversarial networks",
            "venue": "arXiv preprint arXiv:1611.08408,",
            "year": 2016
        },
        {
            "authors": [
                "Phillip Isola",
                "Jun-Yan Zhu",
                "Tinghui Zhou",
                "Alexei A Efros"
            ],
            "title": "Image-to-image translation with conditional adversarial networks",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Ting-Chun Wang",
                "Ming-Yu Liu",
                "Jun-Yan Zhu",
                "Andrew Tao",
                "Jan Kautz",
                "Bryan Catanzaro"
            ],
            "title": "High-resolution image synthesis and semantic manipulation with conditional gans",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2018
        },
        {
            "authors": [
                "Judy Hoffman",
                "Eric Tzeng",
                "Taesung Park",
                "Jun-Yan Zhu",
                "Phillip Isola",
                "Kate Saenko",
                "Alexei Efros",
                "Trevor Darrell"
            ],
            "title": "Cycada: Cycle-consistent adversarial domain adaptation",
            "venue": "In International conference on machine learning,",
            "year": 2018
        },
        {
            "authors": [
                "Kay Gregor Hartmann",
                "Robin Tibor Schirrmeister",
                "Tonio Ball"
            ],
            "title": "Eeg-gan: Generative adversarial networks for electroencephalograhic (eeg) brain signals",
            "venue": "arXiv preprint arXiv:1806.01875,",
            "year": 2018
        },
        {
            "authors": [
                "Tamar Rott Shaham",
                "Tali Dekel",
                "Tomer Michaeli"
            ],
            "title": "Singan: Learning a generative model from a single natural image",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2019
        },
        {
            "authors": [
                "Guillaume Lample",
                "Neil Zeghidour",
                "Nicolas Usunier",
                "Antoine Bordes",
                "Ludovic Denoyer",
                "Marc\u2019Aurelio Ranzato"
            ],
            "title": "Fader networks: Manipulating images by sliding attributes",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Rameen Abdal",
                "Peihao Zhu",
                "Niloy J Mitra",
                "Peter Wonka"
            ],
            "title": "Style\ue001ow: Attribute-conditioned exploration of stylegan-generated images using conditional continuous normalizing \ue001ows",
            "venue": "ACM Transactions on Graphics (ToG),",
            "year": 2021
        },
        {
            "authors": [
                "Weihao Xia",
                "Yulun Zhang",
                "Yujiu Yang",
                "Jing-Hao Xue",
                "Bolei Zhou",
                "Ming-Hsuan Yang"
            ],
            "title": "Gan inversion: A survey",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "William Fedus",
                "Ian Goodfellow",
                "Andrew M Dai"
            ],
            "title": "Maskgan: better text generation via \ue000lling in the",
            "venue": "arXiv preprint arXiv:1801.07736,",
            "year": 2018
        },
        {
            "authors": [
                "Nikolay Jetchev",
                "Urs Bergmann",
                "Roland Vollgraf"
            ],
            "title": "Texture synthesis with spatial generative adversarial networks",
            "venue": "arXiv preprint arXiv:1611.08207,",
            "year": 2016
        },
        {
            "authors": [
                "Jiaxian Guo",
                "Sidi Lu",
                "Han Cai",
                "Weinan Zhang",
                "Yong Yu",
                "Jun Wang"
            ],
            "title": "Long text generation via adversarial training with leaked information",
            "venue": "In Proceedings of the AAAI conference on arti\ue000cial intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Aditya Ramesh",
                "Mikhail Pavlov",
                "Gabriel Goh",
                "Scott Gray",
                "Chelsea Voss",
                "Alec Radford",
                "Mark Chen",
                "Ilya Sutskever"
            ],
            "title": "Zero-shot text-to-image generation",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Alec Radford",
                "Jong Wook Kim",
                "Chris Hallacy",
                "Aditya Ramesh",
                "Gabriel Goh",
                "Sandhini Agarwal",
                "Girish Sastry",
                "Amanda Askell",
                "Pamela Mishkin",
                "Jack Clark"
            ],
            "title": "Learning transferable visual models from natural language supervision",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Or Patashnik",
                "Zongze Wu",
                "Eli Shechtman",
                "Daniel Cohen-Or",
                "Dani Lischinski"
            ],
            "title": "Styleclip: Text-driven manipulation of stylegan imagery",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Monireh Mohebbi Moghadam",
                "Bahar Boroomand",
                "Mohammad Jalali",
                "Arman Zareian",
                "Alireza DaeiJavad",
                "Mohammad Hossein Manshaei"
            ],
            "title": "Game of gans: Game theoretical models for generative adversarial networks",
            "venue": "arXiv preprint arXiv:2106.06976,",
            "year": 2021
        },
        {
            "authors": [
                "Diederik P Kingma",
                "Max Welling"
            ],
            "title": "Auto-encoding variational bayes",
            "venue": "arXiv preprint arXiv:1312.6114,",
            "year": 2013
        },
        {
            "authors": [
                "Augustus Odena"
            ],
            "title": "Semi-supervised learning with generative adversarial networks",
            "venue": "arXiv preprint arXiv:1606.01583,",
            "year": 2016
        },
        {
            "authors": [
                "Mehdi Mirza",
                "Simon Osindero"
            ],
            "title": "Conditional generative adversarial nets",
            "venue": "arXiv preprint arXiv:1411.1784,",
            "year": 2014
        },
        {
            "authors": [
                "Alec Radford",
                "Luke Metz",
                "Soumith Chintala"
            ],
            "title": "Unsupervised representation learning with deep convolutional generative adversarial networks",
            "venue": "arXiv preprint arXiv:1511.06434,",
            "year": 2015
        },
        {
            "authors": [
                "Vincent Dumoulin",
                "Francesco Visin"
            ],
            "title": "A guide to convolution arithmetic for deep learning",
            "venue": "arXiv preprint arXiv:1603.07285,",
            "year": 2016
        },
        {
            "authors": [
                "Andrew L Maas",
                "Awni Y Hannun",
                "Andrew Y Ng"
            ],
            "title": "Recti\ue000er nonlinearities improve neural network acoustic models",
            "venue": "In Proc. icml,",
            "year": 2013
        },
        {
            "authors": [
                "Han Zhang",
                "Ian Goodfellow",
                "Dimitris Metaxas",
                "Augustus Odena"
            ],
            "title": "Self-attention generative adversarial networks",
            "venue": "In International conference on machine learning,",
            "year": 2019
        },
        {
            "authors": [
                "Koby Crammer",
                "Yoram Singer"
            ],
            "title": "On the algorithmic implementation of multiclass kernel-based vector machines",
            "venue": "Journal of machine learning research,",
            "year": 2001
        },
        {
            "authors": [
                "Andrew Brock",
                "Jeff Donahue",
                "Karen Simonyan"
            ],
            "title": "Large scale gan training for high \ue000delity natural image synthesis",
            "venue": "arXiv preprint arXiv:1809.11096,",
            "year": 2018
        },
        {
            "authors": [
                "Takeru Miyato",
                "Toshiki Kataoka",
                "Masanori Koyama",
                "Yuichi Yoshida"
            ],
            "title": "Spectral normalization for generative adversarial networks",
            "venue": "arXiv preprint arXiv:1802.05957,",
            "year": 2018
        },
        {
            "authors": [
                "Martin Heusel",
                "Hubert Ramsauer",
                "Thomas Unterthiner",
                "Bernhard Nessler",
                "Sepp Hochreiter"
            ],
            "title": "Gans trained by a two time-scale update rule converge to a local nash equilibrium",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Harm De Vries",
                "Florian Strub",
                "J\u00e9r\u00e9mie Mary",
                "Hugo Larochelle",
                "Olivier Pietquin",
                "Aaron C Courville"
            ],
            "title": "Modulating early visual processing by language",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Takeru Miyato",
                "Masanori Koyama"
            ],
            "title": "cgans with projection discriminator",
            "venue": "arXiv preprint arXiv:1802.05637,",
            "year": 2018
        },
        {
            "authors": [
                "Andrew Brock",
                "Theodore Lim",
                "James M Ritchie",
                "Nick Weston"
            ],
            "title": "Neural photo editing with introspective adversarial networks",
            "venue": "arXiv preprint arXiv:1609.07093,",
            "year": 2016
        },
        {
            "authors": [
                "Tero Karras",
                "Samuli Laine",
                "Timo Aila"
            ],
            "title": "A style-based generator architecture for generative adversarial networks",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Xun Huang",
                "Serge Belongie"
            ],
            "title": "Arbitrary style transfer in real-time with adaptive instance normalization",
            "venue": "In Proceedings of the IEEE international conference on computer vision,",
            "year": 2017
        },
        {
            "authors": [
                "Sebastian Nowozin",
                "Botond Cseke",
                "Ryota Tomioka"
            ],
            "title": "f-gan: Training generative neural samplers using variational divergence minimization",
            "venue": "Advances in neural information processing systems,",
            "year": 2016
        },
        {
            "authors": [
                "Bharath K Sriperumbudur",
                "Arthur Gretton",
                "Kenji Fukumizu",
                "Bernhard Sch\u00f6lkopf",
                "Gert RG Lanckriet"
            ],
            "title": "Hilbert space embeddings and metrics on probability measures",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2010
        },
        {
            "authors": [
                "Martin Arjovsky",
                "Soumith Chintala",
                "L\u00e9on Bottou"
            ],
            "title": "Wasserstein generative adversarial networks",
            "venue": "In International conference on machine learning,",
            "year": 2017
        },
        {
            "authors": [
                "Tilmann Gneiting",
                "Adrian E Raftery"
            ],
            "title": "Strictly proper scoring rules, prediction, and estimation",
            "venue": "Journal of the American statistical Association,",
            "year": 2007
        },
        {
            "authors": [
                "Syed Mumtaz Ali",
                "Samuel D Silvey"
            ],
            "title": "A general class of coef\ue000cients of divergence of one distribution from another",
            "venue": "Journal of the Royal Statistical Society: Series B (Methodological),",
            "year": 1966
        },
        {
            "authors": [
                "Solomon Kullback",
                "Richard A Leibler"
            ],
            "title": "On information and suf\ue000ciency",
            "venue": "The annals of mathematical statistics,",
            "year": 1951
        },
        {
            "authors": [
                "XuanLong Nguyen",
                "Martin J Wainwright",
                "Michael I Jordan"
            ],
            "title": "Estimating divergence functionals and the likelihood ratio by convex risk minimization",
            "venue": "IEEE Transactions on Information Theory,",
            "year": 2010
        },
        {
            "authors": [
                "Mark Reid",
                "Robert Williamson"
            ],
            "title": "Information, divergence and risk for binary experiments",
            "year": 2011
        },
        {
            "authors": [
                "Frank L Hitchcock"
            ],
            "title": "The distribution of a product from several sources to numerous localities",
            "venue": "Journal of mathematics and physics,",
            "year": 1941
        },
        {
            "authors": [
                "Ting Chen",
                "Xiaohua Zhai",
                "Marvin Ritter",
                "Mario Lucic",
                "Neil Houlsby"
            ],
            "title": "Self-supervised gans via auxiliary rotation loss",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Huikai Wu",
                "Shuai Zheng",
                "Junge Zhang",
                "Kaiqi Huang"
            ],
            "title": "Gp-gan: Towards realistic high-resolution image blending",
            "venue": "In Proceedings of the 27th ACM international conference on multimedia,",
            "year": 2019
        },
        {
            "authors": [
                "Lars Mescheder",
                "Andreas Geiger",
                "Sebastian Nowozin"
            ],
            "title": "Which training methods for gans do actually converge",
            "venue": "In International conference on machine learning,",
            "year": 2018
        },
        {
            "authors": [
                "Sergey Ioffe",
                "Christian Szegedy"
            ],
            "title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
            "venue": "In International conference on machine learning,",
            "year": 2015
        },
        {
            "authors": [
                "Tim Salimans",
                "Durk P Kingma"
            ],
            "title": "Weight normalization: A simple reparameterization to accelerate training of deep neural networks",
            "venue": "Advances in neural information processing systems,",
            "year": 2016
        },
        {
            "authors": [
                "Sung Woo Park",
                "Junseok Kwon"
            ],
            "title": "Spheregan: Sphere generative adversarial network based on geometric moment matching and its applications",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "REDES GENERATIVAS ADVERSARIAS (GAN) FUNDAMENTOS TE\u00d3RICOS Y APLICACIONES\nSURVEY\nJordi de la Torre\u2217\nPh.D. in Computer Science (ML/AI) Universitat Oberta de Catalunya\nBarcelona, ES jordi.delatorre@gmail.com\nFebruary 18, 2023\nABSTRACT\nLas redes adversarias generativas (GANs) son un m\u00e9todo basado en el entrenamiento de dos redes neuronales, una denominada generadora y otra discriminadora, compitiendo entre s\u00ed para generar nuevas instancias que se asemejen a las de la distribuci\u00f3n de probabilidad de los datos de entrenamiento. Las GANs tienen una amplia gama de aplicaciones en campos como la visi\u00f3n por computadora, la segmentaci\u00f3n sem\u00e1ntica, la s\u00edntesis de series temporales, la edici\u00f3n de imagen, el procesamiento del lenguaje natural y la generaci\u00f3n de imagen a partir de texto, entre otros. Los modelos generativos modelizan la distribuci\u00f3n de probabilidad de un conjunto de datos, pero en lugar de proporcionar un valor de probabilidad, generan nuevas instancias cercanas a la distribuci\u00f3n original. Las GANs utilizan un esquema de aprendizaje que permite codicar los atributos denitorios de la distribuci\u00f3n de probabilidad en una red neuronal, lo que permite generar instancias que se asemejen a la distribuci\u00f3n de probabilidad original. En este art\u00edculo se presentan los fundamentos te\u00f3ricos de este tipo de redes as\u00ed como los esquemas b\u00e1sicos de la arquitectura y algunas de sus aplicaciones. Este art\u00edculo est\u00e1 en espa\u00f1ol para facilitar la llegada de este conocimiento cient\u00edco a la comunidad hispanohablante.\nABSTRACT\nGenerative adversarial networks (GANs) are a method based on the training of two neural networks, one called generator and the other discriminator, competing with each other to generate new instances that resemble those of the probability distribution of the training data. GANs have a wide range of applications in elds such as computer vision, semantic segmentation, time series synthesis, image editing, natural language processing, and image generation from text, among others. Generative models model the probability distribution of a data set, but instead of providing a probability value, they generate new instances that are close to the original distribution. GANs use a learning scheme that allows the dening attributes of the probability distribution to be encoded in a neural network, allowing instances to be generated that resemble the original probability distribution. This article presents the theoretical foundations of this type of network as well as the basic architecture schemes and some of its applications. This article is in Spanish to facilitate the arrival of this scientic knowledge to the Spanish-speaking community.\nKeywords redes generativas \u00b7 GAN \u00b7 entrenamiento adversario \u00b7 inteligencia articial \u00b7 machine learning\n\u2217mailto:jordi.delatorre@gmail.com web:jorditg.github.io\n1 Introducci\u00f3n\nLas redes antag\u00f3nicas generativas o redes adversarias generativas (GANs) ([1], [2], [3]) son un m\u00e9todo para la optimizaci\u00f3n competitivo entre dos redes neuronales, una llamada generadora y otra discriminadora, con el objetivo de conseguir generar nuevas instancias idealmente indistinguibles a las pertenecientes a la distribuci\u00f3n de probabilidad de la que derivan los datos de entrenamiento.\nEl fundamento te\u00f3rico general del que derivan, permite su utilizaci\u00f3n para la generaci\u00f3n de cualquier tipo de datos, habi\u00e9ndose demostrado efectiva en campos diversos como son la visi\u00f3n por computador ([4], [5], [6]), la segmentaci\u00f3n sem\u00e1ntica ([7], [8], [9], [10]), la s\u00edntesis de series temporales ([11]), la edici\u00f3n de imagen ([12], [13], [14], [15]), el procesamiento del lenguaje natural ([16], [17], [18]), la generaci\u00f3n de imagen a partir de texto ([19], [20], [21]) entre otros.\nPara cualquier conjunto de datos, podemos hipotetizar que es posible denir una distribuci\u00f3n de probabilidad pdata representativa de la poblaci\u00f3n representada por la muestra formada por el conjunto de datos. De ser esto posible, para cualquier valor de x ser\u00e1 posible establecer un valor Pdata(x) que determine la probabilidad de que x pertenezca a la poblaci\u00f3n. De existir una funci\u00f3n de este tipo, ser\u00eda una funci\u00f3n discriminativa que dada una instancia permitir\u00eda conocer la probabilidad de pertenencia a la poblaci\u00f3n. Los modelos generativos modelizan la distribuci\u00f3n de probabilidad mencionada pero no proporcionan un valor de probabilidad, sino que generan instancias nuevas que pertenecen a distribuciones de probabilidad pr\u00f3ximas a la que pretenden asemejar. Las GANs denen un esquema de aprendizaje que facilita la codicaci\u00f3n de los atributos denitorios de la distribuci\u00f3n de probabilidad en una red neuronal de manera que la red incorpore la informaci\u00f3n esencial que le permite generar instancias pertenecientes a distribuciones de probabilidad pr\u00f3ximas a la que el conjunto de datos que pretende representar.\nEn la siguiente secci\u00f3n se presenta el esquema b\u00e1sico de la arquitectura GAN y su aspecto distintivo, la naturaleza de la funci\u00f3n objetivo utilizada para su optimizaci\u00f3n. Posteriormente, se presentan las arquitecturas y funciones de objetivo derivadas, as\u00ed como sus aplicaciones."
        },
        {
            "heading": "2 El concepto de redes antag\u00f3nicas",
            "text": "La arquitectura GAN est\u00e1 formada por dos redes neuronales constituyentes: una denominada discriminadora (D) y otra generadora G. La red G se encarga de generar nuevas instancias del mismo dominio que el del conjunto de datos de origen. La red D se encarga de discriminar si los datos de entrada son reales, esto es pertenecientes al conjunto de datos de entrada o bien son cticios, esto es generados articialmente. Ambas redes se entrenan de manera conjunta de manera que G maximice sus posibilidades de no ser detectada por D y D de forma que haga cada vez m\u00e1s sosticados sus m\u00e9todos de detecci\u00f3n de los datos generados articialmente por G. Estas dos redes adversarias compiten en un juego de suma cero en el que se hipotetiza que eventualmente llegan a un equilibrio de Nash [22].\nzin xfake G(z)\ngenerador z \u223c pz ruido latente\nxreal x \u223c pdata\nx real? D(x)\ndiscriminador\nFigura 1: Diagrama representativo del proceso de entrenamiento de las redes adversarias generativas (GANs)\nEn la gura 2 se muestra un diagrama representativo del proceso de optimizaci\u00f3n de las GAN. Un vector z es muestreo de una distribuci\u00f3n de probabilidad aleatoria pz , z \u223c pz y alimentado como entrada a G. El prop\u00f3sito de la optimizaci\u00f3n es conseguir que G(z) \u223c pg acabe siendo una estimaci\u00f3n de la distribuci\u00f3n de probabilidad Pdata. Las GAN se optimizan la funci\u00f3n min-max de un juego de suma cero expresado por la ecuaci\u00f3n 1.\nm\u0131\u0301n G ma\u0301x D Ex\u223cpr log[D(x)] + Ez\u223cpz log[1\u2212D(G(z))] (1)\nEquivalentemente, sean p\u03b8, D\u03c9 las redes neuronales generadora y discriminadora de una GAN, siendo \u03b8 los par\u00e1metros de G y \u03c9 los de D. Ambas redes se optimizan en conjunto con la funci\u00f3n objetivo denida por la ecuaci\u00f3n 2.\nm\u0131\u0301n \u03b8 ma\u0301x \u03c9 Ex\u223cQ log[D\u03c9(x)] + Ex\u223cp\u03b8 log[1\u2212D\u03c9(x))] (2)\nDurante el proceso de optimizaci\u00f3n la redD recibir\u00e1 como entrada de manera aleatoria datos pertenecientes al conjunto de datos y otros procedentes de la red G. Se optimizar\u00e1 su funcionamiento para que su discriminaci\u00f3n sea efectiva (ecuaci\u00f3n 3).\n\u2207\u03b8D 1\nm\nm X\ni=1\n[logD(x(i)) + log(1\u2212D(G(z(i))))] (3)\nAl mismo tiempo, cuando D reciba una entrada procedente de G, \u00e9ste se optimizar\u00e1 para mejorar sus predicciones y hacer cada vez m\u00e1s dif\u00edcil el papel de D. Esto \u00fanicamente se puede conseguir mejorando la calidad de los datos generados y haci\u00e9ndolos m\u00e1s parecidos al conjunto de datos original (ecuaci\u00f3n 4).\n\u2207\u03b8G 1\nm\nm X\ni=1\nlog(1\u2212D(G(z(i)))) (4)\nSe establece as\u00ed una competici\u00f3n entre las dos redes (de ah\u00ed el nombre de adversarias) de forma que idealmente en el progreso de este proceso ambas mejoran su funcionamiento al punto que idealmente el generador acaba produciendo datos cada vez m\u00e1s parecidos a los del conjunto de datos original."
        },
        {
            "heading": "3 Ventajas e inconvenientes de las GAN",
            "text": "Desde su introducci\u00f3n en 2014, las GANs han despertado un gran inter\u00e9s sobre todo en el campo de la generaci\u00f3n de imagen. Esto ha sido debido a que presentan una serie de ventajas sobre el otro paradigma dominante hasta el momento en lo que a modelos generativos se reere, los VAEs [23]. Dichas ventajas son las siguientes:\n\u2022 Im\u00e1genes m\u00e1s n\u00edtidas: Las GANs producen im\u00e1genes m\u00e1s n\u00edtidas que otros modelos generativos disponibles hasta el momento. Los modelos de difusi\u00f3n que veremos m\u00e1s adelante son una excepci\u00f3n posterior en este aspecto.\n\u2022 Tama\u00f1no congurable: El tama\u00f1o de la variable aleatoria no est\u00e1 restringido pudi\u00e9ndose enriquecer en caso de ser necesario.\n\u2022 Generador vers\u00e1til: El paradigma de dise\u00f1o basado en GANs soporta distintos tipos de funciones generadoras, a diferencia de otros modelos generativos que pueden tener restricciones debido a su arquitectura. Los VAEs, por ejemplo, obligan a utilizar una funci\u00f3n Gaussiana en la primera capa del Generador.\nLa arquitectura tambi\u00e9n tiene sus desventajas entre las que est\u00e1n las siguientes:\n\u2022 Colapso de modo: Durante el entrenamiento sincronizado de generador y discriminador, el generador puede tener tendencia a reproducir \u00fanicamente un modo espec\u00edco que es capaz de burlar al discriminador. A pesar de que este patr\u00f3n puede estar minimizando la funci\u00f3n objetivo, lo hace sin cubrir todo el dominio del conjunto de datos.\n\u2022 Desvanecimiento de gradientes: A veces el discriminador se optimiza demasiado r\u00e1pido en su funci\u00f3n. En estos casos, los gradientes que propaga pueden ser demasiado bajos para asegurar la optimizaci\u00f3n del generador.\n\u2022 Inestabilidad: A menudo durante el entrenamiento los par\u00e1metros de ambas redes uct\u00faan sin encontrar un punto de equilibrio. En estas circunstancias el generador tiene dicultades en encontrar un punto que genere im\u00e1genes de alta calidad."
        },
        {
            "heading": "4 Arquitecturas derivadas",
            "text": "En esta secci\u00f3n se presentan aquellas arquitecturas derivadas de la original que mejoran su rendimiento en alguna de las desventajas mencionadas."
        },
        {
            "heading": "4.1 GAN semi-supervisada (SGAN)",
            "text": "SGAN [24] incluye una variaci\u00f3n en el discriminador que le permite aprovechar las ventajas de contar con datos supervisados. Consiste en a\u00f1adir un cabezal adicional para la predicci\u00f3n de la clase de pertenencia. En aquellos casos reales que se conoce dicha clase, se utiliza el cabezal softmax de predicci\u00f3n para optimizar al discriminador. En aquellos que no se conozca, se utiliza la optimizaci\u00f3n v\u00eda clasicaci\u00f3n binaria t\u00edpica de la GAN convencional. Los resultados demuestran que este tipo de entrenamiento mejora las capacidades de SGAN respecto a la GAN original."
        },
        {
            "heading": "4.2 Conditional GAN (CGAN)",
            "text": "CGAN [25] modica el m\u00e9todo original introduciendo una entrada adicional tanto en el generador como en el discriminador. Esta entrada adicional sirve como condicionante para ambas funciones. Esta nueva informaci\u00f3n y se fusiona en el generador con el muestreo de la variable aleatoria z para posteriormente generar la nuevas instancias. Lo mismo ocurre en el discriminador donde y se integra con los datos x a analizar. La nueva funci\u00f3n de optimizaci\u00f3n queda como indica la ecuaci\u00f3n 5.\nm\u0131\u0301n G ma\u0301x D Ex\u223cpr log[D(x|y)] + Ez\u223cpz log[1\u2212D(G(z|y))] (5)"
        },
        {
            "heading": "4.3 Red antag\u00f3nica generativa convolucional profunda (DCGAN)",
            "text": "Las redes antag\u00f3nicas generativas convolucionales profundas (DCGAN) fueron introducidas por primera vez en [26] como m\u00e9todo para la generaci\u00f3n de im\u00e1genes. Utilizan convoluciones en el discriminador y convoluciones traspuestas [27] en el generador. Adem\u00e1s de mejoras en la resoluci\u00f3n de las im\u00e1genes generadas, consiguen mejoras en la estabilidad del entrenamiento que en su estudio atribuyen a la introducci\u00f3n de las siguientes modicaciones:\n\u2022 Sustituci\u00f3n de todas las capas de pooling de las dos redes. En el discriminador se utilizan n\u00facleos con stride mayor que 1 y en el generador convoluciones traspuestas para aumentar el tama\u00f1o de la imagen.\n\u2022 Uso de la normalizaci\u00f3n por lotes en las dos redes.\n\u2022 En el discriminador se cambia la funci\u00f3n de activaci\u00f3n de ReLU a LeakyReLU [28]. En el generador se utilizan ReLU en todas las capas excepto en la \u00faltima donde se usa la funci\u00f3n de activaci\u00f3n tangente hiperb\u00f3lica (tanh)."
        },
        {
            "heading": "4.4 Progressive GAN (PROGAN)",
            "text": "En [5] se introduce un m\u00e9todo progresivo de entrenamiento y aumento de la resoluci\u00f3n de las im\u00e1genes generadas que da muy buenos resultados. Muchas de las arquitecturas GAN m\u00e1s exitosas usan este m\u00e9todo. En el trabajo citado se empieza entrenando una red generativa de 4x4 para ir a\u00f1adiendo capas en el generador y discriminador conforme va avanzando el entrenamiento hasta conseguir resoluciones de salida de 1024x1024. Conforme se van a\u00f1adiendo capas, todas las capas anteriores siguen estando sometidas a los cambios inherentes a la optimizaci\u00f3n de las redes."
        },
        {
            "heading": "4.5 Self-attention GAN (SAGAN)",
            "text": "Muchas de las implementaciones existentes hasta el momento fallan en la captura de patrones geom\u00e9tricos y estructurales de largo alcance. Se hipotetiza que la causa de esto es debida a la naturaleza convolucional de las arquitecturas generativas. Debido a ella, las dependencias son de corto alcance y requieren del paso a trav\u00e9s de varias capas para ser resueltas. Existen diversas soluciones que se pueden aplicar para solucionar este aspecto. La primera ser\u00eda aumentar el tama\u00f1o de las convoluciones con el aumento asociado de los requerimientos computacionales. Otra ser\u00eda el incremento de la profundidad de las redes. Una tercera posibilidad, que es la propuesta por SAGAN [29] es la utilizaci\u00f3n de mecanismos de auto-atenci\u00f3n en alguna de las capas de la red convolucional.\nLos atributos de salida x \u2208 RC\u00d7N de una capa de la red neuronal se transforman en dos espacios f(x) = W fx y g(x) = W gx para posteriormente calcular la atenci\u00f3n como indica la ecuaci\u00f3n 6.\n\u03b2j,i = exp(si,j)\nN P\ni=1\nexp(si,j)\ndonde si,j = f(xi) Tg(xj) (6)\n\u03b2j,i indica la atenci\u00f3n que est\u00e1 prestando a la regi\u00f3n i cuando est\u00e1 generando la j. C es el n\u00famero de canales y N el n\u00famero de atributos de la anterior capa. La salida de la capa de atenci\u00f3n o = (o1,o2, ...oN ) \u2208 RC\u00d7N se puede expresar como indica la ecuaci\u00f3n 7.\noj = v\nN X\ni=1\n\u03b2j,ih(xi) , h(xi) = W hxi , v(xi) = W vxi (7)\nDonde W g \u2208 RC\u0304\u00d7C , W f \u2208 RC\u0304\u00d7C , W h \u2208 RC\u0304\u00d7C y W v \u2208 RC\u00d7C\u0304 son matrices optimizadas en tiempo de entrenamiento, implementadas como convoluciones 1x1. En el art\u00edculo se ja C\u0304 = C/8 por ser m\u00e1s eciente de cara a la computaci\u00f3n y, seg\u00fan se indica, no afectar signicativamente a los resultados.\nEl valor de auto-atenci\u00f3n considerado se escala y se suma al valor del atributo de entrada, yi = \u03b3oi + xi siendo \u03b3 un par\u00e1metro optimizable que se inicializa a cero. Esto tiene su l\u00f3gica pues al inicio del entrenamiento se puede esperar resolver las dependencias locales para que una vez avanzada la optimizaci\u00f3n se ane resolviendo las dependencias de mayor alcance. Este mecanismo de atenci\u00f3n se aplica tanto al generador como al discriminador. Ambos son optimizados minimizando una versi\u00f3n modicada de la funci\u00f3n de optimizaci\u00f3n original, que toma la forma de la ecuaci\u00f3n 8. Esta ecuaci\u00f3n es la versi\u00f3n de m\u00e1ximo-margen (Hinge Loss) t\u00edpica para la optimizaci\u00f3n de SVMs [30].\nLD = \u2212E(x,y)\u223cPdata [m\u0131\u0301n(0,\u22121 +D(x, y))]\u2212 Ez\u223cpz,y\u223cPdata [m\u0131\u0301n(0,\u22121\u2212D(G(z), y))] LG = \u2212Ez\u223cpz,y\u223cPdataG(G(z), y)\n(8)\nJunto con su propuesta presentan tambi\u00e9n una metodolog\u00eda de entrenamiento para estabilizar el inherentemente inestable proceso de optimizaci\u00f3n de las GANs."
        },
        {
            "heading": "4.6 BigGAN",
            "text": "BigGAN [31] es un tipo de GAN dise\u00f1ada para la generaci\u00f3n, mediante escalado, de im\u00e1genes de alta resoluci\u00f3n. Incluye una serie de cambios incrementales respecto a las redes anteriormente mencionadas as\u00ed como tambi\u00e9n algunas innovaciones.\nEntre las mejoras incrementales de relevancia encontramos las siguientes:\n1. Propuesta de arquitectura basada en SAGAN utilizando normalizaci\u00f3n espectral [32] tanto para D como para G y utilizando TTUR [33].\n2. Al igual que SAGAN utiliza la funci\u00f3n de p\u00e9rdida Hinge como objetivo de optimizaci\u00f3n\n3. Utiliza normalizaci\u00f3n por lotes condicionada a la clase (CBN) [34] (mediante proyecci\u00f3n lineal) para proveer de informaci\u00f3n de la clase a G.\n4. Utiliza un discriminador por proyecci\u00f3n [35] para incorporar la informaci\u00f3n de la clase.\nEn cuanto a las innovaciones resaltar:\n1. Incremento del tama\u00f1o de los lotes.\n2. Incremento del tama\u00f1o de capa.\n3. Adici\u00f3n de conexiones directas entre la variable latente z y las capas intermedias de la red.\n4. Uso de una variante de regularizaci\u00f3n ortogonal [36].\nBigGAN consigue una mejora sustancial de la calidad de las im\u00e1genes generadas para tama\u00f1os de 128x128, 256x256 y 512x512, aumentando el n\u00famero de par\u00e1metros (x4) y incrementando el tama\u00f1o del batch de entrenamiento (x8) respecto a SAGAN. Adem\u00e1s de las modicaciones indicadas, introducen algunos cambios sobre las variables latentes, durante el proceso de inferencia consistentes en truncar los valores fuera de un rango determinado."
        },
        {
            "heading": "4.7 StyleGAN",
            "text": "StyleGAN [37] propone una nueva arquitectura para el generador, manteniendo el mismo dise\u00f1o para el discriminador. En la gura 4.7 se muestra un esquema de la arquitectura propuesta para la red generadora.\nStyleGAN tiene tres componentes caracter\u00edsticos:\nFigura 2: Diagrama de la arquitectura StyleGAN. Fuente: https://github.com/christianversloot/ machine-learning-articles/blob/main/stylegan-a-step-by-step-introduction.md\n1. Crecimiento progresivo del tama\u00f1o de la imagen generada al estilo de PROGAN (bloques en amarillo) (4\u00d74 \u2192 8\u00d78 \u2192 16\u00d716 \u2192 32\u00d732 \u2192 64\u00d764 \u2192 128\u00d7128 \u2192 256\u00d7256 \u2192 512\u00d7512 \u2192 1024\u00d71024)\n2. En los bloques de Upsample utiliza muestreo bilinear en vez de la copia del valor de los vecinos cercanos.\n3. Sustituci\u00f3n del vector de entrada z \u223c Pz por una matriz de entrada constante de 4\u00d7 4\u00d7 512 y se introduce una red de ruido gaussiano, que alimenta independientemente a cada una de las capas intermedias.\n4. Introducci\u00f3n de la denominada Red de mapeo del ruido, que al paso por varias capas completamente conectadas, transforma una entrada aleatoria en una representaci\u00f3n interna de los estilos. La salida de esta red act\u00faa como entrada en los bloques AdaIN de cada capa jando los par\u00e1metros de sesgo y escalado del bloque con la nalidad de actuar como estilos adaptativos.\n5. AdaIN. Normalizaci\u00f3n adaptativa de las instancias: Introducida inicialmente en [38]. StyleGAN la utiliza tanto como capa de normalizaci\u00f3n como para establecer el estilo a trav\u00e9s de los par\u00e1metros de escalado y sesgo que son derivados de las representaciones internas aprendidas por la red de mapeo de ruido."
        },
        {
            "heading": "5 f-GAN una generalizaci\u00f3n de las GANs",
            "text": "En las secciones previas, hemos presentado a las GANs como una herramienta para generar datos, que se optimiza para producir resultados que se parezcan a los datos de entrenamiento. Se ha explicado c\u00f3mo este proceso se lleva a cabo a trav\u00e9s de la optimizaci\u00f3n de un modelo parametrizable en forma de red neuronal, midiendo la diferencia entre la distribuci\u00f3n del modelo y la real durante el proceso de entrenamiento.\nEn este apartado, exploraremos c\u00f3mo distintas formas de medir esta distancia pueden dar lugar a diferentes funciones objetivo y, por lo tanto, a distintas redes resultantes. Este concepto se ha formalizado en el art\u00edculo [39], que proporciona una generalizaci\u00f3n del concepto de distancia en GANs para diferentes formas de medir la distancia entre distribuciones de probabilidad."
        },
        {
            "heading": "5.1 Introducci\u00f3n",
            "text": "Un modelo probabil\u00edstico es una representaci\u00f3n formal que describe un evento o fen\u00f3meno en t\u00e9rminos de una distribuci\u00f3n de probabilidad, en lugar de proporcionar una respuesta \u00fanica como lo hacen los modelos deterministas.\nEstos modelos se utilizan para modelar procesos estoc\u00e1sticos, donde los resultados no est\u00e1n determinados de antemano y pueden variar con el tiempo o en funci\u00f3n de las condiciones.\nCuando los principios que rigen un fen\u00f3meno son desconocidos o es demasiado complejo describirlos de manera computacionalmente eciente, una forma de aproximar la soluci\u00f3n es modelar su distribuci\u00f3n de probabilidad a partir de muestras recopiladas del entorno. De esta manera, se pueden hacer predicciones y tomar decisiones basadas en una comprensi\u00f3n probabil\u00edstica del fen\u00f3meno en cuesti\u00f3n."
        },
        {
            "heading": "5.2 Estimaci\u00f3n de modelos probabil\u00edsticos",
            "text": "Suponiendo que existe una distribuci\u00f3n de probabilidad real Q, se puede utilizar un modelo param\u00e9trico P para aproximar a Q. Para evaluar la validez de nuestro modelo debemos tener un medio de evaluar las diferencias entre ambas distribuciones. Sabemos que ambas variables son estoc\u00e1sticas, esto es, no est\u00e1n denidas por un \u00fanico valor comparable sino que son distribuciones (funciones). Debemos disponer, por tanto, de una medida que nos permita comparar funciones. Una forma de hacer esto es realizar una abstracci\u00f3n del concepto de distancia para generalizarlo, no \u00fanicamente para medir distancias entre puntos, sino tambi\u00e9n para identicar distancias entre distribuciones de probabilidad. Para facilitar el proceso, puede ser necesario hacer alg\u00fan tipo de suposici\u00f3n sobre P , como que su muestreo sea manejable, de cara a asegurar que las muestras del modelo sean comparables con las muestras reales; que P tenga un gradiente manejable con respecto al muestreo de cara a poder utilizar t\u00e9cnicas de optimizaci\u00f3n y, nalmente, que tenga una funci\u00f3n de probabilidad manejable de forma que pueda calcularse la probabilidad punto a punto."
        },
        {
            "heading": "5.3 GANs como modelos probabil\u00edsticos",
            "text": "Como ya sabemos, las GANs usan una combinaci\u00f3n de dos redes neuronales para crear un modelo generativo con el objetivo de aprender a imitar una distribuci\u00f3n real. El generador, como su nombre indica, genera una muestra modelo a partir de un vector aleatorio mediante el uso de una transformaci\u00f3n determinista. El discriminador recibe muestras pertenecientes a la distribuci\u00f3n real escogidas al azar y del modelo de generaci\u00f3n y se entrena para diferenciarlas. Ambas redes est\u00e1n entrenadas de manera adversaria, una para generar im\u00e1genes lo m\u00e1s cercanas posible a la distribuci\u00f3n real y la otra para detectar las muestras procedentes del generador. Aunque las GAN no proporcionan un valor de probabilidad de la imagen generada, es de esperar que este valor, aunque no sea conocido, exista."
        },
        {
            "heading": "5.4 Distancia entre distribuciones de probabilidad",
            "text": "Existen diferentes enfoques para denir la distancia entre las distribuciones de probabilidad. Podemos diferenciar principalmente entre tres enfoques diferentes:\n1. M\u00e9tricas de probabilidad integral\n2. Reglas para puntuaci\u00f3n\n3. f-divergencias"
        },
        {
            "heading": "5.4.1 M\u00e9tricas de probabilidad integral",
            "text": "Abordado por primera vez en las publicaci\u00f3n [40], el punto clave de este m\u00e9todo es que ambas distribuciones aparecen en forma de expectativa, lo que permite aproximarse a dicho valor mediante muestreo. La distancia de Wasserstein se deriva de estos m\u00e9todos, y luego se us\u00f3 con \u00e9xito como una distancia en Wasserstein-GAN [41]."
        },
        {
            "heading": "5.4.2 Reglas para puntuaci\u00f3n",
            "text": "En [42] se propuso el enfoque de utilizar una puntuaci\u00f3n para evaluar la adecuaci\u00f3n de una distribuci\u00f3n a otra. El punto es la optimizaci\u00f3n de la puntuaci\u00f3n. La puntuaci\u00f3n m\u00e1xima se logra cuando ambas distribuciones son iguales."
        },
        {
            "heading": "5.4.3 f-divergencias",
            "text": "Abordado por primera vez en [43], las distribuciones P y Q se requieren en forma de funci\u00f3n de densidad. Las f-divergencias son una generalizaci\u00f3n de la divergencia Kullback-Leiber [44]. La expectativa de la distribuci\u00f3n Q se multiplica por una funci\u00f3n convexa de la relaci\u00f3n de verosimilitud entre P yQ. Por lo general, no se aplica directamente porque normalmente no se dispone de la distribuci\u00f3n de los datos de forma expl\u00edcita.\nEn [45], [46] y en [1] se desarrollaron m\u00e9todos para usar f-divergencias en problemas donde P tiene forma de distribuci\u00f3n y Q tiene forma de expectativa y tambi\u00e9n donde ambas distribuciones tienen forma de expectativa. Esto permiti\u00f3 el uso de tales m\u00e9tricas en problemas donde solo se encuentran disponibles muestras de ambas distribuciones.\nMatem\u00e1ticamente, podemos denir la f-divergencia, denotada como Df (P || Q), como la distancia entre dos distribuciones de probabilidad P y Q que se puede calcular mediante la ecuaci\u00f3n 9.\nDf (Q || P ) =\nZ\nX\np(x)f\nq(x)\np(x)\ndx (9)\ndonde f es una funci\u00f3n convexa, denominada funci\u00f3n generador (nada que ver con el generador de las GANs), que cumple la propiedad f(1) = 0, esto es, que en aquellos puntos donde las dos funciones son iguales la distancia es cero.\nLa distancia siempre es ser mayor que 0 y es \u00fanicamente igual a cero cuando las dos distribuciones coinciden en todo el dominioX .\nNombre Df (P || Q) Generador f(u) Total variation 12 R\n| p(x)\u2212 q(x) | dx 12 | u\u2212 1 | Kullback-Leibler R\np(x) log p(x) q(x) dx u log u\nReverse Kulback-Leibler R q(x) log q(x) p(x)dx \u2212 log u Pearson \u03c72 R (q(x)\u2212p(x))2\np(x) dx (u\u2212 1) 2\nNeyman \u03c72 R (p(x)\u2212q(x))2 q(x) dx (1\u2212u)2 u Squared Hellinger R ( p p(x)\u2212 p q(x))2dx ( \u221a u\u2212 1)2 Jeffrey R (p(x)\u2212 q(x)) log\np(x) q(x) dx) (u\u2212 1) log u Jensen-Shannon 12 R p(x) log 2p(x) p(x)+q(x) + q(x) log 2q(x) p(x)+q(x)dx \u2212(u+ 1) log 1+u 2 + u log u Jensen-Shannon weighted R\np(x)\u03c0 log p(x) \u03c0p(x)+(1\u2212\u03c0)q(x) + (1\u2212 \u03c0)q(x) log q(x) \u03c0p(x)+(1\u2212\u03c0)q(x)dx \u03c0u log u+ (1\u2212 \u03c0 + \u03c0u) log(1\u2212 \u03c0 + \u03c0u)\nGAN R p(x) log 2p(x) p(x)+q(x) + q(x) log 2q(x) p(x)+q(x)dx\u2212 log 4 u log u\u2212 (u+ 1) log(u+ 1) \u03b1-divergence 1 \u03b1(\u03b1\u22121) R p(x) h q(x) p(x) \u03b1 \u2212 1 i \u2212 \u03b1(q(x)\u2212 p(x)) dx 1 \u03b1(\u03b1\u22121) (u \u03b1 \u2212 1\u2212 \u03b1(u\u2212 1))\nCuadro 1: f-divergencias y generador asociado. Formas distintas de medir la distancia entre dos distribuciones de probabilidad P y Q"
        },
        {
            "heading": "5.4.4 Estimaci\u00f3n de las f-divergencias mediante muestreo",
            "text": "En [45] se deriva un m\u00e9todo variacional general para estimar las f-divergencias a partir del muestreo de las distribuciones P y Q.\nDel an\u00e1lisis de funciones convexas sabemos que toda funci\u00f3n convexa f tiene un conjugado de Fenchel f\u2217 para el que se cumple que f(u) = sup\nt\u2208domf\u2217\n{tu\u2212 f\u2217(t)}, esto es, que cualquier funci\u00f3n convexa puede ser representada como un\nconjunto de m\u00e1ximos puntuales de funciones lineales. Siendo f\u2217(t) el punto de intercepci\u00f3n con el eje de y para cada punto t.\nDf (Q || P ) =\nZ\nX\np(x)f( q(x)\np(x) )dx \u2265\n\u2265 sup T\u2208T (\nZ q(x)T (x)dx\u2212 Z\nX\np(x)f\u2217(T (x))dx) =\n= sup T\u2208T\n(Ex\u223cQ[T (x)]\u2212 Ex\u223cP [f\u2217(T (x))]) (10)\nLas expresiones pueden ser convertidas a expectativas y utilizadas en un algoritmo de muestreo. Un punto a tener en cuenta es que para algunas divergencias, f\u2217 \u00fanicamente est\u00e1 denido para un dominio restringido. En esos casos, antes de utilizar la funci\u00f3n objetivo, debe ser mapeada al dominio donde est\u00e1 denida."
        },
        {
            "heading": "5.4.5 Funci\u00f3n variacional asociada al discriminador",
            "text": "En el art\u00edculo introductorio de las GAN [1] se demuestra que la optimizaci\u00f3n propuesta para la funci\u00f3n de p\u00e9rdida (eq. 2) es equivalente a minimizar la divergencia de Jensen-Shanon.\nComparando la expresi\u00f3n de la ecuaci\u00f3n 10 con la funci\u00f3n objetivo de GAN vemos que T (x) = log(D\u03c9(x)). Conrmamos pues que la GAN original minimiza la divergencia Jensen-Shanon, una caso particular de la f-GAN."
        },
        {
            "heading": "5.5 Conclusi\u00f3n",
            "text": "En esta secci\u00f3n se ha generalizado el concepto de medida de la distancia entre distribuciones de probabilidad, utilizado en la funci\u00f3n de p\u00e9rdida de las GAN, para poderlo usar en un contexto m\u00e1s general con cualquier f-divergencia para la medida de la distancia entre la distribuci\u00f3n de probabilidad del modelo y la original. En este contexto m\u00e1s general, se ha demostrado que la GAN original es un caso particular de optimizaci\u00f3n que utiliza la f-divergencia de Jensen-Shanon para la medida de la distancia entre distribuciones. Cualquiera de las medidas alternativas presentadas da lugar a optimizaciones equivalentes, a pesar de ser distintas, desde un punto de vista representativo."
        },
        {
            "heading": "5.6 Funciones de optimizaci\u00f3n mejoradas",
            "text": "En la anterior secci\u00f3n hemos introducido el concepto de f-divergencia para generalizar el concepto de distancia entre distribuciones y hemos nombrado otros m\u00e9todos alternativos como las m\u00e9tricas de probabilidad integral. En esta secci\u00f3n presentaremos las opciones de optimizaci\u00f3n que en la pr\u00e1ctica han demostrado ser m\u00e1s efectivas para mejorar los problemas relacionados con la optimizaci\u00f3n min-max original, esto es, el colapso de modo y el desvanecimiento de gradientes. Los objetivos presentados a parte de remediar estos aspectos tambi\u00e9n mejora la calidad de las im\u00e1genes generadas."
        },
        {
            "heading": "5.6.1 Wasserstein GAN (WGAN)",
            "text": "WGAN [41] resuelve el problema del desvanecimiento de gradientes y colapso de modo reemplazando la optimizaci\u00f3n de la f-divergencia de Jensen Shanon mediante el uso de la m\u00e9trica de probabilidad integral EM (Earth mover distance [47]) tambi\u00e9n llamada distancia de Wasserstein. La ecuaci\u00f3n 11 muestra la ecuaci\u00f3n que la dene.\nW (pr, pg) = \u0131\u0301nf \u03b3\u2208 Q (pr,pg)\nE(x,y)\u223c\u03b3 [||x\u2212 y||] (11)\ndonde Q\n(pr, pg) representa en conjunto de todas las distribuciones conjuntas \u03b3(x, y) cuyos marginales son pr y pg . La distancia EM representa el m\u00ednimo coste necesario para transportar la \"masa\"de pr a pg para conseguir hacerlas iguales.\nLas f-divergencias como KL y JS muestran problemas de inestabilidad cuando pr y pg est\u00e1n muy alejadas una de otra. EM es estable tambi\u00e9n en estos casos, adem\u00e1s de ser continua, hecho que facilita la derivaci\u00f3n de gradientes \u00fatiles para llevar a cabo la optimizaci\u00f3n. Un inconveniente es que el \u00ednmo de la ecuaci\u00f3n 11 es intratable. Por esa raz\u00f3n los autores de WGAN estiman el coste de EM con la ecuaci\u00f3n 12.\nW (pr, pg) \u2248 ma\u0301x w\u223cW Ex\u223cpr [fw(x)]\u2212 Ez\u223cpz [fw(G(z))] (12)\ndonde fww\u2208W es una familia de funciones param\u00e9tricas que son K-Lipschitz para alg\u00fanK(||f ||L) \u2264 K). Los autores proponen encontrar la mejor funci\u00f3n fw que maximiza la eq. 12 propagando el gradiente Ez\u223cpz [fw(G(z))], donde g\u03b8 es el generador g con par\u00e1metros \u03b8. fw puede ser representada por D pero condicionada a ser K-Lipschitz. w en fw representa a los par\u00e1metros de D y el objetivo de D es maximizar 12, que aproxima la distancia EM. Cuando D es \u00f3ptimo, 12 se aproxima a la distancia EM real y G se optimiza para minimizar la ecuaci\u00f3n 13.\n\u2212m\u0131\u0301n G Ez\u223cpz [fw(G(z))] (13)\nWGAN suele tener unos gradientes m\u00e1s suaves y medibles en todo el dominio que otras f-divergencias y aprende mejor incluso cuando no est\u00e1 produciendo a\u00fan buenas im\u00e1genes."
        },
        {
            "heading": "5.6.2 GAN auto-supervisada (SSGAN)",
            "text": "SSGAN [48] utiliza un sistema similar a la CGAN [25] pero sin la necesidad de contar con etiquetado expl\u00edcito. Adem\u00e1s introduce un nuevo elemento en la funci\u00f3n de p\u00e9rdida, el objetivo del cual es prever el valor de una clase que se deriva directamente de la naturaleza de la imagen analizada. Concretamente, los autores predicen la rotaci\u00f3n de la imagen de 4 posibles valores. Este valor es conocido y calculable sin necesidad de etiquetar las im\u00e1genes y se demuestra \u00fatil para mejorar las capacidades predictivas del discriminador, as\u00ed como para aprender representaciones \u00fatiles para la generaci\u00f3n. La nueva funci\u00f3n de p\u00e9rdida tiene la forma indicada en la ecuaci\u00f3n 14.\nLG = \u2212V (G,D)\u2212 \u03b1Ex\u223cpGEr\u223cR[logQD(R = r | xr)] LD = \u2212V (G,D)\u2212 \u03b2Ex\u223cpdataEr\u223cR[logQD(R = r | xr)]\n(14)\ndonde V(G,D) es el objetivo general de la GAN original (ecuaci\u00f3n 1), Pdata y PG son las distribuciones real y del generador respectivamente, r \u2208 R es la rotaci\u00f3n seleccionada entre los \u00e1ngulos permitidos (R = {0, 90, 180, 270}). Una imagen rotada r grados se denota como xr y Q(R | xr) es la distribuci\u00f3n predicha sobre los \u00e1ngulos de rotaci\u00f3n de la muestra. Esta funci\u00f3n de p\u00e9rdida fuerza a aprender representaciones internas de la rotaci\u00f3n de forma supervisada hipotetizando que dichas representaciones ser\u00e1n \u00fatiles tambi\u00e9n para la generalizaci\u00f3n de las capacidades generativas de la GAN. SSGAN obtiene resultados comparables a los de CGAN sin la necesidad de etiquetado externo."
        },
        {
            "heading": "5.6.3 Normalizaci\u00f3n espectral (SNGAN)",
            "text": "En SNGAN [32] se propone el uso de normalizaci\u00f3n de los par\u00e1metros como medio de estabilizaci\u00f3n del entrenamiento del discriminador. Es una t\u00e9cnica que es computacionalmente eciente y que puede ser aplicada de manera sencilla. Sabemos que si D es una funci\u00f3n k-Lipshitz , esto es, intuitivamente, que es una funci\u00f3n continua sin variaciones abruptas, esto puede servir para estabilizar el entrenamiento de las GAN. SNGAN controla el valor de la constante de Lipschitz limitando la norma espectral de cada capa, normalizando la matriz de pesos de cada capa W para satisfacer la restricci\u00f3n \u03c3(W ) = 1 (esto es, que el mayor valor singular de la matriz de pesos sea 1). Esto se consigue simplemente normalizando cada capa mediante la ecuaci\u00f3n 15.\nW\u0304 SN (W ) = W\n\u03c3(W ) (15)\ndonde W representa a la matriz de pesos de cada capa. En el art\u00edculo citado se demuestra que esta operaci\u00f3n hace que la constante de Lipschitz en el discriminador quede limitada a un m\u00e1ximo de 1, hecho que facilita la optimizaci\u00f3n.\nSNGAN consigue mejoras importantes de los resultados comparado con las t\u00e9cnicas previas de estabilizaci\u00f3n del entrenamiento publicadas, entre las que se incluyen el recorte del valor de los pesos [41], la penalizaci\u00f3n de gradientes [49], [50], normalizaci\u00f3n batch [51], normalizaci\u00f3n de pesos [52], normalizaci\u00f3n de capas [53] y regularizaci\u00f3n ortonormal [36]."
        },
        {
            "heading": "5.6.4 SphereGAN",
            "text": "SphereGAN [54] es una GAN que utiliza m\u00e9trica de probabilidad integral (IPM) que usa una hiperesfera para ligar la IPM a la funci\u00f3n objetivo y de esta forma mejorar la estabilidad del entrenamiento. La funci\u00f3n objetivo utilizada es la indicada en la ecuaci\u00f3n 16.\nm\u0131\u0301n G ma\u0301x D\nX\nr\nEx[d r s(N , D(x))]\u2212\nX\nr\nEz[d r s(N , D(G(z)))] (16)\npara r = 1, ..., R donde drs mide la distancia con momento r entre cada muestra y el polo norte de la hiperesfera,N . El sub\u00edndice s indica que drs est\u00e1 denido en S n.\nEsta propuesta mejora a las anteriores funciones objetivo basadas en la distancia Wasserstein gracias a la denici\u00f3n de los IPM en la hiperesfera. Esto le permite prescindir de muchas de las restricciones que deben ser impuestas a D para asegurar un entrenamiento estable en las anteriores propuestas, como las restricciones sobre la naturaleza Lischitz de las funciones requeridas por la distancia Wasserstein.\nEl funcionamiento de SphereGAN se podr\u00eda describir de la forma siguiente: la red G genera datos a partir de un vector aleatorio z. Im\u00e1genes reales y otras las procedentes de G se alimentan a la red discriminadoraD que, a diferencia de las propuestas anteriores, da como resultado un vector de dimensi\u00f3n n. SphereGAN re-mapea este vector en una hiperesfera de n dimensiones utilizando transformaciones geom\u00e9tricas. Los puntos mapeados se utilizan para calcular los\nmomentos geom\u00e9tricos centrados en el polo norte (N ) de dicha hiper-esfera. La red discriminadora intenta maximizar las diferencias de momento entre las im\u00e1genes reales y las falsas, mientras que la generadora intenta conseguir lo contrario."
        },
        {
            "heading": "6 Una aplicaci\u00f3n de las GAN: aumento de datos",
            "text": "El aumento de datos es una t\u00e9cnica habitual para mejorar el entrenamiento de los modelos en aquellas circunstancias donde se dispone de pocos datos. Podr\u00edamos decir que las circunstancias m\u00e1s habituales que requieren aumento de datos ser\u00edan las siguientes:\n\u2022 Etiquetado limitado: Disponer de pocos datos etiquetados.\n\u2022 Diversidad limitada: Cuando el conjunto de entrenamiento falta variedad en los datos.\n\u2022 Datos restringidos: Alguna de la informaci\u00f3n es sensible y no puede utilizarse directamente.\nLos dos primeros casos se pueden resolver manualmente, poniendo recursos para etiquetar m\u00e1s datos, pero puede suponer un coste elevado. Una alternativa para el primer caso consiste en utilizar GANs para aumentar la cantidad de datos. SGAN, por ejemplo, permite generar nuevos datos anotados. El segundo caso es m\u00e1s habitual, pues suele ser habitual disponer de conjuntos de datos con clases desbalanceadas pobres en las clases raras."
        },
        {
            "heading": "7 Conclusiones",
            "text": "En este cap\u00edtulo hemos introducido a las GAN como m\u00e9todo para la generaci\u00f3n de datos. Es un tipo de arquitectura especialmente estudiada en el campo de generaci\u00f3n de imagen. Es un tipo de arquitectura con mucho potencial que tiene algunos problemas sobre todo relacionados con la estabilidad en el entrenamiento. En este cap\u00edtulo hemos estudiado el dise\u00f1o original, sus ventajas e inconvenientes as\u00ed como algunas modicaciones destinadas a solventar los problemas de la propuesta original. Si bien hemos intentado describir los puntos que consideramos clave, el campo en cuesti\u00f3n es muy amplio, tanto en arquitecturas, como en aplicaciones. Este cap\u00edtulo debe servir como punto de partida para complementarlo con la bibliograf\u00eda citada as\u00ed como con las futuras aportaciones.\nReferencias\n[1] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. Communications of the ACM, 63(11):139\u2013144, 2020.\n[2] Antonia Creswell, Tom White, Vincent Dumoulin, Kai Arulkumaran, Biswa Sengupta, and Anil A Bharath. Generative adversarial networks: An overview. IEEE signal processing magazine, 35(1):53\u201365, 2018.\n[3] Gilad Cohen and Raja Giryes. Generative adversarial networks. arXiv preprint arXiv:2203.00667, 2022.\n[4] Gintare Karolina Dziugaite, Daniel M Roy, and Zoubin Ghahramani. Training generative neural networks via maximum mean discrepancy optimization. arXiv preprint arXiv:1505.03906, 2015.\n[5] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017.\n[6] Christian Ledig, Lucas Theis, Ferenc Husz\u00e1r, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, et al. Photo-realistic single image super-resolution using a generative adversarial network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4681\u20134690, 2017.\n[7] Pauline Luc, Camille Couprie, Soumith Chintala, and Jakob Verbeek. Semantic segmentation using adversarial networks. arXiv preprint arXiv:1611.08408, 2016.\n[8] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1125\u20131134, 2017.\n[9] Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, and Bryan Catanzaro. High-resolution image synthesis and semantic manipulation with conditional gans. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 8798\u20138807, 2018.\n[10] Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate Saenko, Alexei Efros, and Trevor Darrell. Cycada: Cycle-consistent adversarial domain adaptation. In International conference on machine learning, pages 1989\u20131998. Pmlr, 2018.\n[11] Kay Gregor Hartmann, Robin Tibor Schirrmeister, and Tonio Ball. Eeg-gan: Generative adversarial networks for electroencephalograhic (eeg) brain signals. arXiv preprint arXiv:1806.01875, 2018.\n[12] Tamar Rott Shaham, Tali Dekel, and Tomer Michaeli. Singan: Learning a generative model from a single natural image. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 4570\u20134580, 2019.\n[13] Guillaume Lample, Neil Zeghidour, Nicolas Usunier, Antoine Bordes, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato. Fader networks: Manipulating images by sliding attributes. Advances in neural information processing systems, 30, 2017.\n[14] Rameen Abdal, Peihao Zhu, Niloy J Mitra, and Peter Wonka. Styleow: Attribute-conditioned exploration of stylegan-generated images using conditional continuous normalizing ows. ACM Transactions on Graphics (ToG), 40(3):1\u201321, 2021.\n[15] Weihao Xia, Yulun Zhang, Yujiu Yang, Jing-Hao Xue, Bolei Zhou, and Ming-Hsuan Yang. Gan inversion: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022.\n[16] William Fedus, Ian Goodfellow, and Andrew M Dai. Maskgan: better text generation via lling in the_. arXiv preprint arXiv:1801.07736, 2018.\n[17] Nikolay Jetchev, Urs Bergmann, and Roland Vollgraf. Texture synthesis with spatial generative adversarial networks. arXiv preprint arXiv:1611.08207, 2016.\n[18] Jiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, and Jun Wang. Long text generation via adversarial training with leaked information. In Proceedings of the AAAI conference on articial intelligence, volume 32, 2018.\n[19] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In International Conference on Machine Learning, pages 8821\u2013 8831. PMLR, 2021.\n[20] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning, pages 8748\u20138763. PMLR, 2021.\n[21] Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, and Dani Lischinski. Styleclip: Text-driven manipulation of stylegan imagery. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 2085\u20132094, 2021.\n[22] Monireh Mohebbi Moghadam, Bahar Boroomand, Mohammad Jalali, Arman Zareian, Alireza DaeiJavad, and Mohammad Hossein Manshaei. Game of gans: Game theoretical models for generative adversarial networks. arXiv preprint arXiv:2106.06976, 2021.\n[23] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.\n[24] Augustus Odena. Semi-supervised learning with generative adversarial networks. arXiv preprint arXiv:1606.01583, 2016.\n[25] Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784, 2014.\n[26] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.\n[27] Vincent Dumoulin and Francesco Visin. A guide to convolution arithmetic for deep learning. arXiv preprint arXiv:1603.07285, 2016.\n[28] Andrew L Maas, Awni Y Hannun, Andrew Y Ng, et al. Rectier nonlinearities improve neural network acoustic models. In Proc. icml, volume 30, page 3. Citeseer, 2013.\n[29] Han Zhang, Ian Goodfellow, Dimitris Metaxas, and Augustus Odena. Self-attention generative adversarial networks. In International conference on machine learning, pages 7354\u20137363. PMLR, 2019.\n[30] Koby Crammer and Yoram Singer. On the algorithmic implementation of multiclass kernel-based vector machines. Journal of machine learning research, 2(Dec):265\u2013292, 2001.\n[31] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high delity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018.\n[32] Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for generative adversarial networks. arXiv preprint arXiv:1802.05957, 2018.\n[33] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems, 30, 2017.\n[34] Harm De Vries, Florian Strub, J\u00e9r\u00e9mie Mary, Hugo Larochelle, Olivier Pietquin, and Aaron C Courville. Modulating early visual processing by language. Advances in Neural Information Processing Systems, 30, 2017.\n[35] Takeru Miyato and Masanori Koyama. cgans with projection discriminator. arXiv preprint arXiv:1802.05637, 2018.\n[36] Andrew Brock, Theodore Lim, James M Ritchie, and Nick Weston. Neural photo editing with introspective adversarial networks. arXiv preprint arXiv:1609.07093, 2016.\n[37] Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarial networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4401\u20134410, 2019.\n[38] Xun Huang and Serge Belongie. Arbitrary style transfer in real-time with adaptive instance normalization. In Proceedings of the IEEE international conference on computer vision, pages 1501\u20131510, 2017.\n[39] Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers using variational divergence minimization. Advances in neural information processing systems, 29, 2016.\n[40] Bharath K Sriperumbudur, Arthur Gretton, Kenji Fukumizu, Bernhard Sch\u00f6lkopf, and Gert RG Lanckriet. Hilbert space embeddings and metrics on probability measures. The Journal of Machine Learning Research, 11:1517\u2013 1561, 2010.\n[41] Martin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. Wasserstein generative adversarial networks. In International conference on machine learning, pages 214\u2013223. PMLR, 2017.\n[42] Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the American statistical Association, 102(477):359\u2013378, 2007.\n[43] Syed Mumtaz Ali and Samuel D Silvey. A general class of coefcients of divergence of one distribution from another. Journal of the Royal Statistical Society: Series B (Methodological), 28(1):131\u2013142, 1966.\n[44] Solomon Kullback and Richard A Leibler. On information and sufciency. The annals of mathematical statistics, 22(1):79\u201386, 1951.\n[45] XuanLong Nguyen, Martin J Wainwright, and Michael I Jordan. Estimating divergence functionals and the likelihood ratio by convex risk minimization. IEEE Transactions on Information Theory, 56(11):5847\u20135861, 2010.\n[46] Mark Reid, Robert Williamson, et al. Information, divergence and risk for binary experiments. 2011.\n[47] Frank L Hitchcock. The distribution of a product from several sources to numerous localities. Journal of mathematics and physics, 20(1-4):224\u2013230, 1941.\n[48] Ting Chen, Xiaohua Zhai, Marvin Ritter, Mario Lucic, and Neil Houlsby. Self-supervised gans via auxiliary rotation loss. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 12154\u201312163, 2019.\n[49] Huikai Wu, Shuai Zheng, Junge Zhang, and Kaiqi Huang. Gp-gan: Towards realistic high-resolution image blending. In Proceedings of the 27th ACM international conference on multimedia, pages 2487\u20132495, 2019.\n[50] Lars Mescheder, Andreas Geiger, and Sebastian Nowozin. Which training methods for gans do actually converge? In International conference on machine learning, pages 3481\u20133490. PMLR, 2018.\n[51] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International conference on machine learning, pages 448\u2013456. PMLR, 2015.\n[52] Tim Salimans and Durk P Kingma. Weight normalization: A simple reparameterization to accelerate training of deep neural networks. Advances in neural information processing systems, 29, 2016.\n[53] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. ArXiv e-prints, pages arXiv\u20131607, 2016.\n[54] Sung Woo Park and Junseok Kwon. Spheregan: Sphere generative adversarial network based on geometric moment matching and its applications. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020."
        }
    ],
    "title": "REDES GENERATIVAS ADVERSARIAS (GAN)",
    "year": 2023
}