{
    "abstractText": "20 Rib fracture is a common disease that requires prompt treatment. This study 21 focuses on developing a rib fracture diagnosis deep learning method using contralateral, 22 contextual, and edge enhanced modules and evaluating its detection performance. A 23 novel rib fracture diagnosis method was designed, named CCE-Net. To evaluate the 24 performance of this method, 1639 digital radiography (DR) images were enrolled. 25 Fracture features were extracted for three modules: contralateral, contextual, and edge 26 enhanced modules. These modules can be used to identify fracture features in rib DR 27 images, imitating the experience of broad-certificated radiologists. The contralateral 28 module assists in diagnosing rib fractures by comparing the difference between the 29 detected target region and the contralateral region. The contextual module helps to aid 30 rib fracture detection by extracting contextual features. The edge enhanced module 31 improves the accuracy of fracture detection by enhancing the edge information of the 32 rib bone. The head of this two-stage detection network uses the multi-path fusion 33 mechanism as the main architecture to integrate and utilize the above modules. The 34 qualitative results show that with the ground truth of rib fracture as the evaluation 35 standard, CCE-Net can achieve a better visual effect of fracture detection than other 36 methods. The quantitative results show that CCE-Net can achieve the best performance 37 in various detection indicators include AP50 0.911, AP75 0.794, AP25 0.913, and 38 Recall 0.934. Experimental results show that CCE-Net can acquire the excellent ability 39 of rib fracture diagnosis. We invasion that this approach will be applied to clinical study. 40",
    "authors": [
        {
            "affiliations": [],
            "name": "Y. Gao"
        },
        {
            "affiliations": [],
            "name": "H. Liu"
        },
        {
            "affiliations": [],
            "name": "L. Jiang"
        },
        {
            "affiliations": [],
            "name": "C. Yang"
        },
        {
            "affiliations": [],
            "name": "X. Yin"
        },
        {
            "affiliations": [],
            "name": "Jean-Louis Coatrieux"
        },
        {
            "affiliations": [],
            "name": "Y. Chen"
        },
        {
            "affiliations": [],
            "name": "Yuan Gao"
        },
        {
            "affiliations": [],
            "name": "Hongzhi Liu"
        },
        {
            "affiliations": [],
            "name": "Liang Jiang"
        },
        {
            "affiliations": [],
            "name": "Chunfeng Yang"
        },
        {
            "affiliations": [],
            "name": "Xindao Yin"
        },
        {
            "affiliations": [],
            "name": "Yang Chen"
        }
    ],
    "id": "SP:9e8a7bcd61cd09e48da77c2b435152b9928485be",
    "references": [
        {
            "authors": [
                "S.H. Cho",
                "Y.M. Sung",
                "M.S. Kim",
                "Missed rib fractures on evaluation of initial 532 chest CT for trauma patients"
            ],
            "title": "Pattern analysis and diagnostic value of coronal 533 multiplanar reconstruction images with multidetector row CT, Br J Radiol",
            "venue": "85 534",
            "year": 2012
        },
        {
            "authors": [
                "M.P. Fredric",
                "M. Sarah",
                "A.O. Francis",
                "A. Darwin",
                "D. Andrew",
                "G.E. John",
                "F. 536 Bruce",
                "G. Mario",
                "M. Silvana",
                "M. Christian",
                "S. Babak",
                "T. William",
                "H.V. Don",
                "537 W.W. Thomas",
                "Consensus statement"
            ],
            "title": "surgical stabilization of rib fractures rib 538 fracture colloquium clinical practice guidelines, Injury",
            "venue": "48",
            "year": 2017
        },
        {
            "authors": [
                "D.D.J.C. Mayberry"
            ],
            "title": "Trunkey, The fractured rib in chest wall trauma, Chest Surg 540 ACCEPTED MANUSCRIPT - CLEAN",
            "venue": "COPY 18 Clin N Am",
            "year": 1997
        },
        {
            "authors": [
                "B.S. Talbot",
                "C.P. Gange",
                "A. Chaturvedi",
                "N. Klionsky",
                "S.K. Hobbs",
                "A. Chaturvedi",
                "542 Traumatic rib injury"
            ],
            "title": "Patterns, imaging pitfalls, complications, and treatment, 543 Radiographics",
            "venue": "37",
            "year": 2017
        },
        {
            "authors": [
                "F.C. Lin",
                "R. Li",
                "Y. Tung",
                "K. Jeng",
                "S.C. Tsai"
            ],
            "title": "Morbidity, mortality, associated 545 injuries, and management of traumatic rib fractures",
            "venue": "J Chinese Med Assoc",
            "year": 2016
        },
        {
            "authors": [
                "B. Eric",
                "L. Andre",
                "C. David",
                "M. Lynne",
                "R. Sebastien",
                "T. Stephane",
                "L. Jacques",
                "548 M. Marcel"
            ],
            "title": "Elderly trauma patients with rib fractures are at greater risk of death 549 and pneumonia",
            "venue": "Journal of Trauma and Acute Care Surgery",
            "year": 2003
        },
        {
            "authors": [
                "R.M. Shorr",
                "A. Rodriguez",
                "M.C. Indeck",
                "M.D. Crittenden",
                "R.A.S. Hartunian"
            ],
            "title": "556 Cowley, Blunt chest trauma in the elderly",
            "venue": "The Journal of Trauma",
            "year": 1989
        },
        {
            "authors": [
                "F. Birse",
                "H. Williams",
                "D. Shipway",
                "E. Carlton",
                "Blunt chest trauma in the elderly"
            ],
            "title": "559 an expert practice review, Emergency Medicine Journal",
            "venue": "37",
            "year": 2020
        },
        {
            "authors": [
                "D. Stephanie",
                "A. Affatato",
                "Blunt chest trauma"
            ],
            "title": "utility of radiological evaluation 561 and effect on treatment patterns, The American journal of emergency medicine",
            "venue": "562 26",
            "year": 2006
        },
        {
            "authors": [
                "L. Fabricant",
                "B. Ham",
                "R. Mullins",
                "J. Mayberry"
            ],
            "title": "Prolonged pain and disability are 564 common after rib fractures",
            "venue": "The American Journal of Surgery",
            "year": 2013
        },
        {
            "authors": [
                "J.B. Holcomb",
                "N.R. McMullin",
                "R.A. Kozar",
                "M.H. Lygas",
                "F.A. Moore"
            ],
            "title": "Morbidity 567 from rib fractures increases after age",
            "venue": "Journal of the American College of 568 Surgeons",
            "year": 2003
        },
        {
            "authors": [
                "B.T. Flagel",
                "F.A. Luchette",
                "R.L. Reed",
                "T.J. Esposito",
                "K.A. Davis",
                "J.M. 570 Santaniello",
                "R.L. Gamelli",
                "Half-a-dozen ribs"
            ],
            "title": "The breakpoint for mortality, 571 Surgery",
            "venue": "138",
            "year": 2005
        },
        {
            "authors": [
                "R. Kent",
                "W. Woods",
                "O. Bostrom"
            ],
            "title": "Fatality risk and the presence of rib fractures",
            "venue": "Annals of Advances in Automotive Medicine/Annual Scientific Conference,",
            "year": 2008
        },
        {
            "authors": [
                "W.M. Wu",
                "Y. Yang",
                "Z.L. Gao",
                "T.C. Zhao",
                "W.W. He"
            ],
            "title": "Which is better to multiple 576 rib fractures, surgical treatment or conservative treatment?, International journal 577 of clinical and experimental medicine",
            "year": 2015
        },
        {
            "authors": [
                "M. Sirmali",
                "H. T\u00fcr\u00fct",
                "S. Top\u00e7u",
                "E. G\u00fclhan",
                "\u00dc. Yazici",
                "S. Kaya",
                "I. Ta\u015ftepe",
                "A 579 comprehensive analysis of traumatic rib fractures"
            ],
            "title": "morbidity, mortality and 580 management, European Journal of Cardio-Thoracic Surgery",
            "venue": "24",
            "year": 2003
        },
        {
            "authors": [
                "S.W. Ho",
                "Y.H. Teng",
                "S.F. Yang",
                "H.W. Yeh",
                "Y.H. Wang",
                "M.C. Chou",
                "C.B. Yeh",
                "582 Risk of pneumonia in patients with isolated minor rib fractures"
            ],
            "title": "a nationwide 583 cohort study, BMJ open",
            "venue": "7",
            "year": 2017
        },
        {
            "authors": [
                "H. Tanaka",
                "T. Yukioka",
                "Y. Yamaguti",
                "S. Shimizu",
                "H. Goto",
                "H. Matsuda",
                "S. 585 Shimazaki"
            ],
            "title": "Surgical stabilization of internal pneumatic stabilization? a 586 prospective randomized study of management of severe flail chest patients",
            "venue": "J 587 Trauma",
            "year": 2002
        },
        {
            "authors": [
                "M.S. Lu",
                "Y.K. Huang",
                "Y.H. Liu",
                "H.P. Liu",
                "C.L. Kao"
            ],
            "title": "Delayed pneumothorax 589 complicating minor rib fracture after chest trauma",
            "venue": "Am J Emerg Med",
            "year": 2008
        },
        {
            "authors": [
                "M. Bemelman",
                "M.W. de Kruijf",
                "B.M. van",
                "L. Leenen",
                "Rib fractures"
            ],
            "title": "To fix or 592 not to fix? An evidence-based algorithm, Korean J Thorac Cardiovasc Surg",
            "venue": "50 593",
            "year": 2017
        },
        {
            "authors": [
                "M.B. de Jong",
                "M.C. Kokke",
                "F. Hietbrink",
                "L.P.H. Leenen",
                "Surgical management 595 of rib fractures"
            ],
            "title": "Strategies and literature review, Scand J Surg",
            "venue": "103",
            "year": 2014
        },
        {
            "authors": [
                "E.G. Hwang",
                "Y. Lee",
                "Simple X-ray versus ultrasonography examination in blunt 598 chest trauma"
            ],
            "title": "effective tools of accurate diagnosis and considerations for rib 599 fractures, J Exerc Rehabil",
            "venue": "12",
            "year": 2016
        },
        {
            "authors": [
                "J. Malghem",
                "B.C. Vande Berg",
                "B.E.F.E. Lecouvet"
            ],
            "title": "Maldague, Costal cartilage 601 fractures as revealed on CT and sonography",
            "venue": "Am J Roentgenol,",
            "year": 2001
        },
        {
            "authors": [
                "M. Kara",
                "E. Dikmen",
                "H.H. Erdal",
                "I. Simsir",
                "S.A. Kara"
            ],
            "title": "Disclosure of unnoticed 604 rib fractures with the use of ultrasonography in minor blunt chest trauma",
            "venue": "Eur J 605 Cardio-thoracic Surg",
            "year": 2003
        },
        {
            "authors": [
                "L.I.G. Worthley"
            ],
            "title": "Thoracic epidural in the management of chest trauma",
            "venue": "Intensive 607 Care Med",
            "year": 1985
        },
        {
            "authors": [
                "Y. Barnea",
                "H. Kashtan",
                "Y. Skornick",
                "N. Werbin",
                "Isolated rib fractures in elderly 609 patients"
            ],
            "title": "Mortality and morbidity, Can J Surg",
            "venue": "45",
            "year": 2002
        },
        {
            "authors": [
                "T.J. Ellis"
            ],
            "title": "Hip fractures in the elderly",
            "venue": "Curr Womens Health Rep",
            "year": 2003
        },
        {
            "authors": [
                "T. Weikert",
                "L.A. Noordtzij",
                "J. Bremerich",
                "S. Bram",
                "P. Victor",
                "C. Joshy",
                "S. Gregor",
                "613 W.S. Alexander"
            ],
            "title": "Assessment of a deep learning algorithm for the detection of 614 rib fractures on whole-body trauma computed tomography",
            "venue": "Korean J Radiol",
            "year": 2020
        },
        {
            "authors": [
                "Q.Q. Zhou",
                "W. Tang",
                "J. Wang",
                "Z.C. Hu",
                "Z.Y. Xia",
                "Z. Rongguo",
                "X. Fan",
                "W. Yong"
            ],
            "title": "Automatic detection and classification of rib 618 fractures based on patients\u2019 CT images and clinical information via 619 convolutional neural network",
            "venue": "Eur Radiol",
            "year": 2021
        },
        {
            "authors": [
                "A. Urbaneja",
                "J. De Verbizier",
                "A.S. Formery",
                "C. Tobon-Gomez",
                "L. Nace",
                "A. Blum",
                "621 P.A.G. Teixeira",
                "Automatic rib cage unfolding with CT cylindrical projection 622 reformat in polytraumatized patients for rib fracture detection",
                "623 characterization"
            ],
            "title": "Feasibility and clinical application, Eur J Radiol",
            "venue": "110",
            "year": 2019
        },
        {
            "authors": [
                "L. Jin",
                "J. Yang",
                "K. Kuang",
                "B. Ni",
                "Y. Gao",
                "Y. Sun",
                "P. Gao",
                "W. Ma",
                "M. Tan",
                "H. 626 Kang",
                "J. Chen",
                "M. Li",
                "Deep-learning-assisted detection",
                "segmentation of rib 627 fractures from CT scans"
            ],
            "title": "Development and validation of FracNet, EBioMedicine",
            "venue": "628 ACCEPTED MANUSCRIPT - CLEAN COPY 20 62",
            "year": 2020
        },
        {
            "authors": [
                "X.H. Meng",
                "D.J. Wu",
                "Z. Wang",
                "X.L. Ma",
                "X.M. Dong",
                "A.E. Liu",
                "L. Chen"
            ],
            "title": "A fully 630 automated rib fracture detection system on chest CT images and its impact on 631 radiologist performance, Skeletal Radiol",
            "year": 2021
        },
        {
            "authors": [
                "R. Lindsey",
                "A. Daluiski",
                "S. Chopra",
                "A. Lachapelle",
                "M. Mozer",
                "S. Sicular",
                "D. 633 Hanel",
                "M. Gardner",
                "A. Gupta",
                "R. Hotchkiss",
                "H. Potter"
            ],
            "title": "Deep neural network 634 improves fracture detection by clinicians",
            "venue": "Proc Natl Acad Sci U S A",
            "year": 2018
        },
        {
            "authors": [
                "E. Yahalomi",
                "M. Chernofsky",
                "M. Werman"
            ],
            "title": "Detection of Distal Radius Fractures 637 Trained by a Small Set of X-Ray Images and Faster R-CNN, Intelligent 638 Computing-Proceedings of the Computing",
            "year": 2019
        },
        {
            "authors": [
                "Y.L. Thian",
                "Y. Li",
                "P. Jagmohan",
                "D. Sia",
                "V.E.Y. Chan",
                "R.T. Tan"
            ],
            "title": "Convolutional 640 Neural Networks for Automated Fracture Detection and Localization on Wrist 641 Radiographs",
            "venue": "Radiol Artif Intell",
            "year": 2019
        },
        {
            "authors": [
                "D.H. Kim",
                "T. MacKinnon",
                "Artificial intelligence in fracture detection"
            ],
            "title": "transfer 643 learning from deep convolutional neural networks, Clin Radiol",
            "venue": "73",
            "year": 2018
        },
        {
            "authors": [
                "G. Kitamura",
                "C.Y. Chung",
                "B.E. Moore"
            ],
            "title": "Ankle Fracture Detection Utilizing a 646 Convolutional Neural Network Ensemble Implemented with a Small Sample, De 647 Novo Training, and Multiview Incorporation",
            "venue": "J Digit Imaging",
            "year": 2019
        },
        {
            "authors": [
                "O. Ronneberger",
                "P. Fischer",
                "T. Brox"
            ],
            "title": "U-net: Convolutional networks for 650 biomedical image segmentation, International Conference on Medical image 651 computing and computer-assisted",
            "year": 2015
        },
        {
            "authors": [
                "J. Liu",
                "G. Zhao",
                "Y. Fei",
                "M. Zhang",
                "Y. Wang",
                "Y. Yu"
            ],
            "title": "Align, attend and locate: 653 Chest x-ray diagnosis via contrast induced attention network with limited 654 supervision",
            "year": 2019
        },
        {
            "authors": [
                "M. Everingham",
                "L.V. Gool",
                "C.K.I. Williams",
                "J. Winn",
                "A. Zisserman"
            ],
            "title": "The pascal 659 visual object classes (VOC) challenge",
            "venue": "Int J Comput Vis",
            "year": 2010
        },
        {
            "authors": [
                "J. Lian",
                "J. Liu",
                "S. Zhang",
                "K. Gao",
                "X. Liu",
                "D. Zhang",
                "Y. Yu"
            ],
            "title": "A Structure-Aware 661 Relation Network for Thoracic Diseases Detection and Segmentation",
            "venue": "IEEE 662 transactions on medical imaging",
            "year": 2021
        },
        {
            "authors": [
                "R. Padilla",
                "S. Netto",
                "E. Silva"
            ],
            "title": "A Survey on Performance Metrics for Object664 Detection Algorithms, international conference on systems, signals and image 665 processing (IWSSIP)",
            "year": 2020
        },
        {
            "authors": [
                "S. Ren",
                "K. He",
                "R. Girshick",
                "J. Sun",
                "Faster R-CNN"
            ],
            "title": "towards real-time object 667 detection with region proposal networks, IEEE transactions on pattern analysis 668 and machine intelligence",
            "venue": "39",
            "year": 2016
        },
        {
            "authors": [
                "J. Pang",
                "K. Chen",
                "J. Shi",
                "H. Feng",
                "W. Ouyang",
                "D. Lin",
                "Libra"
            ],
            "title": "R-CNN: Towards 670 balanced learning for object detection",
            "venue": "Proc IEEE Comput Soc Conf Comput Vis 671 Pattern Recognit",
            "year": 2019
        },
        {
            "authors": [
                "H. Zhang",
                "H. Chang",
                "B. Ma",
                "N. Wang",
                "X. Chen"
            ],
            "title": "Dynamic R-CNN: Towards 673 High Quality Object Detection via Dynamic Training",
            "venue": "European Conference on 674 Computer Vision",
            "year": 2020
        },
        {
            "authors": [
                "Z. Cai",
                "N. Vasconcelos"
            ],
            "title": "Cascade R-CNN: Delving into High Quality Object 676 Detection",
            "venue": "Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit",
            "year": 2018
        },
        {
            "authors": [
                "A. Bochkovskiy",
                "C.Y. Wang",
                "H.Y.M. Liao"
            ],
            "title": "YOLOv4: Optimal Speed and 679 Accuracy of Object Detection, 2020",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "ACCEPTED MANUSCRIPT - CLEAN COPY\nfocuses on developing a rib fracture diagnosis deep learning method using contralateral, 22 contextual, and edge enhanced modules and evaluating its detection performance. A 23 novel rib fracture diagnosis method was designed, named CCE-Net. To evaluate the 24 performance of this method, 1639 digital radiography (DR) images were enrolled. 25 Fracture features were extracted for three modules: contralateral, contextual, and edge 26 enhanced modules. These modules can be used to identify fracture features in rib DR 27 images, imitating the experience of broad-certificated radiologists. The contralateral 28 module assists in diagnosing rib fractures by comparing the difference between the 29 detected target region and the contralateral region. The contextual module helps to aid 30 rib fracture detection by extracting contextual features. The edge enhanced module 31 improves the accuracy of fracture detection by enhancing the edge information of the 32 rib bone. The head of this two-stage detection network uses the multi-path fusion 33 mechanism as the main architecture to integrate and utilize the above modules. The 34 qualitative results show that with the ground truth of rib fracture as the evaluation 35 standard, CCE-Net can achieve a better visual effect of fracture detection than other 36 methods. The quantitative results show that CCE-Net can achieve the best performance 37 in various detection indicators include AP50 0.911, AP75 0.794, AP25 0.913, and 38 Recall 0.934. Experimental results show that CCE-Net can acquire the excellent ability 39 of rib fracture diagnosis. We invasion that this approach will be applied to clinical study. 40\n41\nACCEPTED MANUSCRIPT - CLEAN COPY\nKeywords: rib fracture, deep learning, contralateral module, contextual module, edge 42 enhanced module 43 44"
        },
        {
            "heading": "1. Introduction 45",
            "text": "Rib fractures are the most common injury in blunt chest trauma [1\u20134]. It can cause 46 chest pain and restrict physical mobility [5-11]. People over 45 years old with more 47 than four rib fractures are considered dangerous [12,13]. Rib fractures need to be 48 diagnosed and treated as soon as possible [14,15,16]. There are many reasons why it is 49 necessary to diagnosis rib fractures: it will easily cause respiratory complications such 50 as posttraumatic pneumonia if the diagnosis of rib fractures is not timely [4,17,18]; they 51 are indicators of trauma-related diseases that require immediate treatment, such as 52 pneumothorax and their onset can be delayed for several days [19]; the diagnosis of rib 53 fractures can be used as the basis for further comprehensive treatment strategies [20,21]. 54 DR is usually the preferred method of rib fracture detection [22]. Due to the different 55 shapes of rib fractures, the rate of missed diagnosis and misdiagnosis is relatively high 56 [23,24]. Rib fractures can become a life-threatening disease unless detected and treated 57 appropriately, especially in elderly patients [25,26,27]. With the rapid development of 58 artificial intelligence, it is worth introducing deep learning technology to improve rib 59 fracture diagnosis and recognition accuracy as much as possible. 60 Previous work mainly focused on rib fracture detection in CT images. Weikert et 61 al. [28] proposed a deep learning-based prototype algorithm detecting rib fractures on 62 trauma CT on a pre-examination level. Zhou et al. [29] built a CNN model combining 63 CT images and clinical information to detect and classify rib fractures automatically. 64 Urbaneja et al. [30] proposed that CT with unfolded cylindrical projection can be used 65 for rib fracture detection and characterization. Jin et al. [31] used a 3D-UNet model to 66 solve the segmentation problem of rib fractures. Meng et al. [32] helped radiologists 67 achieve high performance in diagnosing and classifying rib fractures on CT images with 68 the assistance of deep learning algorithms. Although the above-mentioned CT-based 69 methods have achieved good performance, there are few excellent methods based on 70 DR. Compared with CT, DR has a faster imaging speed and a smaller radiation dose. 71 DR is the first choice for the radiologist to diagnose rib fractures. Lindsey et al. [33] 72 train a deep learning model to detect fractures on radiographs with a diagnostic 73 accuracy similar to senior subspecialized orthopedic surgeons. Yahalomi et al. [34] train 74 a Faster R-CNN, a machine vision neural network for object detection, to identify and 75 locate distal radius fractures in anteroposterior X-ray images. Thian et al. [35] 76 demonstrate the ability of an object detection CNN to detect and localize radius and 77 ulna fractures on wrist radiographs with high sensitivity and specificity. Kim et al. [36] 78 identify the extent to which transfer learning from deep convolutional neural networks 79 (CNNs), pre-trained on non-medical images, can be used for automated fracture 80 detection on plain radiographs. Kitamura et al. [37] use a convolutional neural network 81 ensemble implemented with a small sample, de novo training, and multiview 82 incorporation to detect ankle fracture. Although there are many deep learning-based 83 fracture detection studies on DR, there are scant clinically reliable rib fracture detection 84\nACCEPTED MANUSCRIPT - CLEAN COPY\nalgorithms. Due to low texture contrast, large differences in patient anatomy, and 85 overlapping organs, it is very challenging to detect and locate rib fractures in DR images 86 automatically. 87\nThis paper proposes a contralateral, contextual, and edge enhanced network (CCE-88 Net) address the above challenges of detecting rib fractures. CCE-Net mainly adopts a 89 region-based two-stage detector. It combines three novel feature extraction streams: the 90 contralateral module, contextual module, and edge enhancement module, so that 91 accurate feature extraction. Since the left and right parts of the human chest ribs have 92 many similar skeleton structures, radiologists often use the left-right comparison 93 method to help them diagnose rib fractures. To extract the similarity information of the 94 contralateral ribs, the spine line is used as the axis of symmetry to obtain a symmetrical 95 rib patch. The contralateral patch is used as one of the neural network inputs. A fusion 96 module is designed to integrate the features of the disease proposal and its contralateral 97 reference patch. The above experience also applies to the upper and lower ribs, which 98 have structural similarities. The contextual module is integrated into the pipeline. The 99 flatness and smoothness of the bone edges are an important basis for fracture judgment 100 when radiologists diagnose rib fractures. To capture bone edge information, the edges 101 containing the key texture structure of the ribs are extracted. Specifically, the edge 102 information reflecting the bone texture structure is integrated as one of the neural 103 network inputs. Therefore, the above methods can help CCE-Net obtain rich 104 characteristic information and excellent performance. The contributions of the study 105 can be listed as follows. 106 1. This study aimed to develop a novel deep learning-based model for rib fractures 107 automatically detection. The performance of our model is compared with other models 108 in rib fractures detection. 109 2. A two-stage detection method is creatively proposed that can effectively 110 integrate multiple feature extraction modules of the contralateral, contextual, edge 111 enhanced, which makes full use of the unique feature information of the rib image. 112 These modules are similar to the experience of radiologists in diagnosing rib fractures. 113 3. A weight distribution fusion method aims to fuse different image detail features 114 and texture structure features of rib fractures at the decision level. It helps obtain a 115 complete feature representation and enables the model to be trained end-to-end. 116 117\n2. Material and Methods 118 2.1. Network architecture overview 119 This paper aims to detect rib fractures in DR images automatically. The flow chart 120 for these steps is shown in Fig.1. The radiologists often focus on the differences in 121 different regions and the smoothness of the bone edge as the diagnosis basis of rib 122 fractures. Based on these essentials, the CCE-Net is proposed to exploit contralateral, 123 contextual, and edge texture information to enhance the feature representations of rib 124 fractures. The network architecture of CCE-Net is depicted in Fig.2. The contralateral 125 and contextual patches are extracted according to the spine line segmentation algorithm. 126 The edge images are acquired based on the edge extraction algorithm. These three 127\nACCEPTED MANUSCRIPT - CLEAN COPY\nmodules will be used as the neural network inputs to help the two-stage detector achieve 128 better feature representation. The details are illustrated below. 129 130\n131 Fig.1 The workflow of this study. Image preprocessing can extract image patches and 132 the spine line from original images. Three novel modules (contralateral, contextual, 133 and edge enhanced) can obtain more features of rib fractures. The feature fusion of the 134 three modules can assist the basic detection network in achieving performance 135 improvement. It should be noted that the DR image with the red outline on the left is 136 used as the input of this method, and the fusion result of the green outline on the right 137 is used as the output of this method. 138 139\nACCEPTED MANUSCRIPT - CLEAN COPY\n140 Fig.2. The network architecture of CCE-Net. Our proposed method is based on the 141 two-stage network. It extracts valid information on rib fractures, integrating four 142 branches marked in orange, green, yellow and blue: target, contralateral, contextual, 143 and edge. Four branches perform the same feature extraction on the backbone 144 network. The results of four branches can be effectively fused in the neck stage to 145 provide more reliable feature information in the subsequent stages. 146\n147 2.2. Contralateral module 148 The contrast of the contralateral patch is useful for radiologists to reference. 149 Especially when fractures are contained in images, the contralateral information helps 150 differentiate the abnormal and the normal ribs and better highlights the difference of 151 fracture regions. Considering that the ribs of the human body are symmetrical, and the 152 spine is situated in the relatively middle position of the chest. The symmetrical central 153 axis of the ribs on both sides is the same as the line of the human spine. We first roughly 154 segment the spine line and extract the contralateral patch based on the left-right 155 symmetry of the ribs. 156 157 2.2.1 Spine line roughly extraction 158 Examining symmetrical regions on both sides of the spine can help radiologists 159 determine rib fractures. The human spine is a skeletal organ usually located in the center 160 and has a regular shape in the DR image. Therefore, the spine line is only needed to 161 roughly segment to examine the contralateral patch of the rib. 162 Specifically, the spine line can be roughly segmented by a CNN model. The UNet 163 [38] is selected as the spine line segmentation model. We label the spine region on the 164\nACCEPTED MANUSCRIPT - CLEAN COPY\nDR data set and use this data set to train the model. Because the symmetrical central 165 axis of the ribs on both sides is not a precise line, there is no need for high segmentation 166 accuracy requirements for the spine segmentation model. 167 The minimum circumscribed quadrilateral enclosing the spine mask can be obtained. 168 The spine line bridged by the centers of two short edges is regarded as the symmetric 169 axis. The spine line can be expressed as \ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34 + \ud835\udc35\ud835\udc35\ud835\udc35\ud835\udc35 + \ud835\udc36\ud835\udc36 = 0. The target patch is denoted 170 as \ud835\udc43\ud835\udc43\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61(\ud835\udc34\ud835\udc34\ud835\udc61\ud835\udc61,\ud835\udc35\ud835\udc35\ud835\udc61\ud835\udc61), and the contralateral patch can be denoted as \ud835\udc43\ud835\udc43\ud835\udc50\ud835\udc50\ud835\udc50\ud835\udc50\ud835\udc50\ud835\udc50\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61(\ud835\udc34\ud835\udc34\ud835\udc4f\ud835\udc4f,\ud835\udc35\ud835\udc35\ud835\udc4f\ud835\udc4f). T The 171 following formula can express the contralateral patch: 172\n\ud835\udc34\ud835\udc34\ud835\udc4f\ud835\udc4f = \ud835\udc34\ud835\udc34\ud835\udc61\ud835\udc61 \u2212 (2\ud835\udc34\ud835\udc34 \u2217 (\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc61\ud835\udc61 + \ud835\udc35\ud835\udc35\ud835\udc35\ud835\udc35\ud835\udc61\ud835\udc61 + \ud835\udc36\ud835\udc36))\n\ud835\udc34\ud835\udc342 + \ud835\udc35\ud835\udc352\n\ud835\udc35\ud835\udc35\ud835\udc4f\ud835\udc4f = \ud835\udc35\ud835\udc35\ud835\udc61\ud835\udc61 \u2212 (2\ud835\udc35\ud835\udc35 \u2217 (\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc61\ud835\udc61 + \ud835\udc35\ud835\udc35\ud835\udc35\ud835\udc35\ud835\udc61\ud835\udc61 + \ud835\udc36\ud835\udc36))\n\ud835\udc34\ud835\udc342 + \ud835\udc35\ud835\udc352\nEq (1)\nAfter the central axis of symmetry is determined, the region symmetrical with the 173 target region according to the spine symmetry axis can be determined as the 174 contralateral patch. 175\n176 2.2.2. Contralateral images fusion 177 After obtaining the contralateral patch, the characteristics of the highly similar 178 structure on both sides of the human ribs are used to pair each target patch with its 179 contralateral patch. An attention mechanism uses the difference between the target and 180 contralateral patch in high-level semantic features to guide the potential location of the 181 fracture. The contrast-induced attention [39] is used to fuse features of each target patch 182 and its contralateral patch. 183 The feature fusion process of the target area and the opposite patch feature is shown 184 in Fig.3. We define the target patch as \ud835\udc42\ud835\udc42, and the contralateral patch obtained as \ud835\udc42\ud835\udc42\u2032. 185 They perform the same convolution operation as \ud835\udc39\ud835\udc39 in the backbone network. The 186 feature maps are effectively fused to realize the contralateral information extraction. 187 The fusion operation adopts a pixel-by-pixel method. The subtraction operation 188 between \ud835\udc39\ud835\udc39(\ud835\udc42\ud835\udc42) and \ud835\udc39\ud835\udc39(\ud835\udc42\ud835\udc42\u2032) helps provide contrast information and suppress the response 189 of attributes unrelated to fracture recognition and location. On the other hand, adding 190 the above subtraction results from the target patch is helpful to identify the same 191 structural information of the ribs with larger responses in the patches on both sides. The 192 attention module \ud835\udc40\ud835\udc40 encodes \ud835\udc39\ud835\udc39(\ud835\udc42\ud835\udc42) and \ud835\udc39\ud835\udc39(\ud835\udc42\ud835\udc42\u2032) into the attention maps. The attention 193 maps are multiplied pixel by pixel to weight the original target feature map to obtain \ud835\udc53\ud835\udc53. 194 The operation is shown below. 195\n\ud835\udc53\ud835\udc53 = \ud835\udc40\ud835\udc40\ufffd\ud835\udc39\ud835\udc39(\ud835\udc42\ud835\udc42) + \ud835\udf06\ud835\udf06\ufffd\ud835\udc39\ud835\udc39(\ud835\udc42\ud835\udc42) \u2212 \ud835\udc39\ud835\udc39(\ud835\udc42\ud835\udc42\u2032)\ufffd\ufffd \u2217 \ud835\udc39\ud835\udc39(\ud835\udc42\ud835\udc42) Eq (2)\nACCEPTED MANUSCRIPT - CLEAN COPY\n196 Fig.3. An overview of the fusion flow. It aims to fuse the effective information of 197 each part to extract the results. The addition and subtraction of the contralateral patch 198 and the target patch are effectively fused with the target patch by using the attention 199 module. 200 201 2.3. Contextual module 202 Focusing on multiple adjacent ribs can make the detection more accurate. The 203 normal rib is similar in shape and signal intensity to its adjacent normal rib. By checking 204 on the contextual information of the diagnosed region, the radiologists can intuitively 205 obtain the changes in the appearance of bones due to fractures. A contextual module 206 that takes adjacent contextual ribs as input is designed to imitate a radiologist. 207 208 2.3.1. Contextual images extraction 209 The longitudinal position of each diagnosed rib region needs to be judged 210 according to the rough segmentation result of the spine. Since there are no more than 211 12 human ribs on each side [40], one of the adjacent upper and lower rib regions should 212 be selected as the input of the context module. If the longitudinal position belongs to 213 the upper region of the spine, the adjacent rib region on the lower side is taken as the 214 input of the context module; otherwise, the adjacent rib region on the upper side is taken 215 as the input of the context module. After the patch direction selection decision is 216 determined, the diagnosed rib patch can be moved along the extension direction of the 217 spine's central axis by half of the boundary length to obtain the context patch. It should 218 be noted that the boundary length refers to the width of the patch, and this study uses 219 640 pixels as the patch width. Due to the short distance between the adjacent ribs of the 220 human body, half the distance of the moving patch boundary can sufficiently cover the 221 adjacent ribs. 222 223 2.3.2. Contextual images fusion 224 The contextual module is designed to take two adjacent ribs as input patches, 225 including the current diagnosis rib and its adjacent rib. A two-branch structure is used 226 to compare adjacent ribs to identify fractures. This structure uses the same fusion 227 method as in Equation 2 in the previous section. We denote the two patches of the 228 current diagnosis rib and its adjacent rib as \ud835\udc45\ud835\udc45\ud835\udc50\ud835\udc50 and \ud835\udc45\ud835\udc45\ud835\udc61\ud835\udc61, respectively. These two branches 229 have the same feature extraction network as \ud835\udc39\ud835\udc39 . The resulting feature map uses the 230 attention mechanism for feature layer fusion and then is input to the rest of the 231\nACCEPTED MANUSCRIPT - CLEAN COPY\nconvolution of the overall network. The final fusion feature maps \ud835\udc40\ud835\udc40\ud835\udc53\ud835\udc53 can be expressed 232 as: 233 \ud835\udc40\ud835\udc40\ud835\udc53\ud835\udc53 = \ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34\ud835\udc34(\ud835\udc39\ud835\udc39(\ud835\udc45\ud835\udc45\ud835\udc50\ud835\udc50) + \ud835\udf06\ud835\udf06(\ud835\udc39\ud835\udc39(\ud835\udc45\ud835\udc45\ud835\udc50\ud835\udc50) \u2212 \ud835\udc39\ud835\udc39(\ud835\udc45\ud835\udc45\ud835\udc61\ud835\udc61))) Eq (3) 234 2.4. Edge enhanced module 235 To capture the edge information of the ribs in the image, we extract the edges 236 containing key texture information for visual recognition and integrate the edge map 237 with the neural network model to improve fracture detection. Rib fractures are highly 238 correlated with the appearance of the bone edges of the ribs. For example, a fractured 239 rib will show abnormal curvature of the skeletal cortex. Based on the above experience, 240 we believe that purely enforcing the widening of the receptive field is not sufficient for 241 rib fracture detection, and the introduction of more comprehensive edge information 242 can improve the detection effect. Since the edges reflect local intensity changes and 243 display the boundary information of ribs in the image, maintaining the edges can 244 preserve the structure of the image content and the texture details. 245\n246 2.4.1. Edge enhanced images extraction 247 The edge information is added to the neural network to enforce the feature map's 248 integration with the original image's edge information. The Sobel operator can calculate 249 the edge map due to its simplicity. Sobel filters \ud835\udc46\ud835\udc46 are used to convolve the original 250 image \ud835\udc3c\ud835\udc3c\ud835\udc50\ud835\udc50 to generate the edge map. Then, the edge information map is integrated into 251 the input image \ud835\udc3c\ud835\udc3c by addition pixel by pixel as the following equation: 252 \ud835\udc3c\ud835\udc3c\ud835\udc61\ud835\udc61 = \ud835\udf06\ud835\udf06\ud835\udc61\ud835\udc61\ud835\udc46\ud835\udc46(\ud835\udc3c\ud835\udc3c\ud835\udc50\ud835\udc50)\u2a01\ud835\udc3c\ud835\udc3c Eq (4) Where \ud835\udf06\ud835\udf06\ud835\udc61\ud835\udc61 means the scale factor of edge information, and \u2a01 means the operation of 253 addition pixel by pixel. 254 By adding the scale factor calculated by the Sobel operator to the input image, the 255 neural network can integrate the information of texture structure and edge intensity to 256 pay more attention to the rib edge information and reduce the sensitivity to noise. The 257 Sobel filter assigns higher weights to the edge region of the original image and lower 258 weights to other regions, which directly enhances the use of image edges by the neural 259 network. 260 261 2.5. Fusion architecture 262 As shown in Fig.2, all three parts are integrated into the whole framework. Our 263 work aims to integrate each region proposal feature \ud835\udc53\ud835\udc53 of contralateral, contextual and 264 edge enhanced modules into the final output \ud835\udc42\ud835\udc42 . Integrate by simply connecting 265 operation to make the contribution of each stream equal, which may ignore the high-266 value features from a module. Feature fusion methods may enhance some feature 267 modules and suppress some feature modules. If we simply combine each feature 268 extraction module mechanically, it is easy to lose the features that should be enhanced. 269 Therefore, we need to design a fusion method that conforms to the characteristics of 270 deep learning. This study needs to select appropriate scale features for different feature 271 extraction modules. The effective fusion of features is achieved by introducing self-272 learning to select appropriate scales. We link the results of the three modules by 273\nACCEPTED MANUSCRIPT - CLEAN COPY\nassigning different weight factors to the feature extraction module through the weight 274 distribution module. A weight distribution module is introduced as \ud835\udc4a\ud835\udc4a that can perform 275 backward propagation and adaptively determine the weights of different modules. The 276 weight distribution module is inspired by the attention mechanism and consists of 277 multiple convolutional and pooling layers. The specific process can be expressed as the 278 following Equation 5: 279 \ud835\udc4a\ud835\udc4a = \ud835\udc64\ud835\udc641\ud835\udc53\ud835\udc531 + \ud835\udc64\ud835\udc642\ud835\udc53\ud835\udc532 + \ud835\udc64\ud835\udc643\ud835\udc53\ud835\udc533 Eq (5) Where \ud835\udc53\ud835\udc531, \ud835\udc53\ud835\udc532 and \ud835\udc53\ud835\udc533 mean the feature maps result of contralateral, contextual and edge 280 enhanced modules, \ud835\udc64\ud835\udc641, \ud835\udc64\ud835\udc642 and \ud835\udc64\ud835\udc643 mean the attention mechanism operation. 281 The final output feature maps of CCE-Net can be expressed as O: 282 \ud835\udc42\ud835\udc42 = \ud835\udf06\ud835\udf06\ud835\udc4a\ud835\udc4a + (1 \u2212 \ud835\udf06\ud835\udf06)\ud835\udc53\ud835\udc53\ud835\udc50\ud835\udc50\ud835\udc61\ud835\udc61\ud835\udc5c\ud835\udc5c Eq (6) Where \ud835\udc53\ud835\udc53\ud835\udc50\ud835\udc50\ud835\udc61\ud835\udc61\ud835\udc5c\ud835\udc5c means the feature maps of original rib patch, \ud835\udf06\ud835\udf06 means the parameter 283 weighting the importance of these three modules. 284 285 2.6. Loss function 286 The detection network architecture that combines the above three modules has been 287 established. The loss function can calculate the error between actual values and 288 predicted values. Cross entropy loss is chosen as the objection function and is given by 289 Eq (7): 290\n\ud835\udc59\ud835\udc59\ud835\udc34\ud835\udc34\ud835\udc59\ud835\udc59\ud835\udc59\ud835\udc59 = \u2212 1 \ud835\udc41\ud835\udc41 \ufffd(\ud835\udc35\ud835\udc35 \u00d7 log(\ud835\udc35\ud835\udc35\ufffd\ud835\udc5a\ud835\udc5a) + (1 \u2212 \ud835\udc35\ud835\udc35) \u00d7 log(1 \u2212 \ud835\udc35\ud835\udc35\ufffd\ud835\udc5a\ud835\udc5a)) Eq (7)\nwhere y is the label and \ud835\udc35\ud835\udc35\ud835\udc5a\ud835\udc5a is the predicted output vector. 291 292\n3. Experimentals and Results 293 3.1. Dataset 294 A private dataset named Rib-NJFH is collected to train and validate our proposed 295 method. Due to the protection of patient privacy, please forgive us that the dataset used 296 in this study cannot be publicly available. The dataset contains 1639 DR images from 297 Nanjing First Hospital, among which there are 2703 rib fractures. We use 1311 images 298 for training, 164 images for validating, and 164 images for testing. All images are 299 annotated and examined by experienced radiologists. 300 301 3.2. Evaluation metrics 302 The bounding box AP [41] and recall are calculated to evaluate the performance of 303 the model. Considering rib fractures as a general target, AP50 is used as the main 304 evaluation index. AP25 and AP75 are used as references. We believe that AP75 better 305 reflects the accurate positioning performance of the fracture region due to its strict 306 evaluation criteria, AP25 has relatively loose evaluation criteria to determine whether 307 the test results are misjudged and thus better reflects the recognition performance of rib 308 abnormalities, AP50 is a comprehensive performance index for fracture recognition and 309 regional positioning [42, 43]. 310\n\ud835\udc34\ud835\udc34\ud835\udc43\ud835\udc43 = \ufffd \ud835\udc43\ud835\udc43(\ud835\udc5f\ud835\udc5f)\ud835\udc51\ud835\udc51\ud835\udc5f\ud835\udc5f 1\n0 Eq (9)\n311\nACCEPTED MANUSCRIPT - CLEAN COPY\nThe PR curve with the corresponding AUCs was calculated for validation datasets 312 to evaluate the performance of the model. The Recall is defined by Eq (10): 313\n\ud835\udc45\ud835\udc45\ud835\udc34\ud835\udc34\ud835\udc45\ud835\udc45\ud835\udc45\ud835\udc45\ud835\udc59\ud835\udc59\ud835\udc59\ud835\udc59 = \ud835\udc47\ud835\udc47\ud835\udc43\ud835\udc43\n\ud835\udc47\ud835\udc47\ud835\udc43\ud835\udc43 + \ud835\udc39\ud835\udc39\ud835\udc41\ud835\udc41 Eq (10)\nWhere TP and FN are the numbers of positive samples correctly classified and 314 incorrectly classified, TN and FP are the numbers of negative simples correctly 315 classified and incorrectly classified. 316 317 3.3. Implementation details 318 The segmentation of the spine's central axis is needed to use in the contralateral 319 module and the contextual module for our experiment. Specifically, the spine regions 320 of the training set are labeled. An example of spine labeling is shown in Fig.4. The 321 segmentation algorithm is used to complete the segmentation of the spine region in the 322 image preprocessing part. After the segmentation results are obtained, image 323 morphology is used to extract the central axis from the spine mask to obtain the 324 contralateral patch. 325 326\n327 Fig.4. The spine line obtention. A red box marks the spine segmentation result. The 328 spine line is used as the position basis of the image extraction of the contralateral 329 module and the contextual module. 330 331 The data set is divided into the training set, the validation set and the test set at 332 8:1:1. The image patches randomly cropped from DR images are resized to 640\u00d7640 333 pixels. Rotation, horizontal and vertical flipping are used for data augmentation. All 334 experiments are implemented using Pytorch on 2 NVIDIA 1080Ti GPUs. ResNet-50 is 335 used as the backbone of the proposed method. We train our model for 50 epochs and 336 test it every five times. For all training, the optimizer is stochastic gradient descent 337 (SGD) with a weight decay of 0.001 and momentum of 0.9 to optimize all models and 338 the batch-size is 2 on each GPU. The learning rate starts at 0.01 and reduces by a factor 339 of 10 after 30 and 40 epochs. 340 341 3.4. Models comparison 342 According to the characteristics of our dataset and detection task, we compare with 343 methods that include Faster RCNN [44], Libra RCNN [45], Dynamic RCNN [46], 344 Cascade RCNN [47] and YOLO v4 [48]. 345 346 3.4.1. Quantitative Results 347\nACCEPTED MANUSCRIPT - CLEAN COPY\nTo validate the performance of CCE-Net, five mainstream algorithms are selected 348 to implement the comparison experiments. For rib DR images, the performance metrics 349 in the training sets can be achieved with the accuracy of 99.648 and the loss of 0.027. 350 The validation set can achieve AP50 and Recall of 0.910 and 0.938. In the test sets, the 351 model's detection performance yielded the AP50 of 0.911, and the Recall is 0.934, as 352 shown in Table 1. 353 354\nTable 1 The quantitative comparisons performance of our method. 355 Method AP50 AP75 AP25 Recall AUC\nFaster RCNN 0.787 0.349 0.878 0.875 0.816 Libra RCNN 0.825 0.326 0.862 0.886 0.847 Dynamic RCNN 0.887 0.516 0.904 0.903 0.901 Cascade RCNN 0.910 0.781 0.911 0.929 0.933\nYOLO v4 0.813 0.689 0.816 0.881 0.840 CCE-Net 0.911 0.794 0.913 0.934 0.941\n356 The five comparison models, including \u2018Faster RCNN with ResNet-50\u2019, \u2018Libra 357 RCNN\u2019, \u2018Dynamic RCNN\u2019, \u2018Cascade RCNN with ResNeXt-101\u2019 and \u2018YOLO v4\u2019, are 358 re-implemented using our dataset. We are committed to merging our proposed module 359 into a two-stage network of Faster RCNN with ResNet-50 as introduced in Section 360 3. The performance of our method compared with different methods is presented in 361\nTable 1. The experimental results in Table 1 show that our method achieves the best 362 performance in all evaluation metrics. Our method equipped with \u2018Faster RCNN\u2019 363 achieves 15.76% AP50, 127.5% AP75 and 3.99% AP75 higher than the results of the 364 original \u2018Faster RCNN\u2019 respectively, the Recall increase by 6.74%, which shows the 365 advantages of the network in the rib fracture detection ability. In addition, due to the 366 ResNet-50 backbone network, our method can achieve fast detection speed while 367 ensuring detection accuracy. 368 For all indicators, our method can achieve better results than other methods. The 369 improvement of AP50 brought by our method is 10.42% (from 0.825 to 0.911), 2.71% 370 (from 0.887 to 0.911) and 1.1% (from 0.91 to 0.911) when using \u2018Libra RCNN\u2019, 371 \u2018Dynamic RCNN\u2019 and \u2018Cascade RCNN with ResNeXt-101\u2019 to produce rib fracture 372 proposals. Compared with \u2018YOLO v4\u2019, which is the one-stage model and achieved 373 outstanding detection performance, the one-stage model with \u2018YOLO v4\u2019 achieves 374 0.813 AP50 and 0.881 Recall. Our method is 0.098 and 0.053 higher than the 'YOLO 375 v4' results, respectively. 376\n377 3.4.2. Qualitative Results 378 Visualization images are used to show the difference between the proposed method 379 and other methods. The results of CCE-Net and other methods are shown in Fig.5. The 380 second column is the result of the proposed method. CCE-Net can effectively detect 381 fracture targets. The third to seventh columns are the results of comparison methods. 382 There are missed detections and false detections in the results of comparison methods. 383 To illustrate the effectiveness of information extraction, feature maps of three 384 different layers are visualized. The visualization includes the result and the feature maps 385\nACCEPTED MANUSCRIPT - CLEAN COPY\nwith sizes of 64, 32, 16 pixels. The feature maps of different sizes are enlarged to the 386 same size and displayed by superimposing the original image. As shown in Fig.6, the 387 proposed method can focus on more reasonable regions. Overall, the correctness of the 388 proposed method is the best because it focuses on more reasonable image features. 389 The PR curves of different methods on the validation data can be shown in Fig.7. 390 For the results of CCE-Net with rib fractures detection, the method obtains good 391 performance. 392\n393 Origin image CCE-Net\nFaster RCNN\nLibra RCNN\nDynamic RCNN\nCascade RCNN YOLO v4\n(a) (b) (c) (d) (e) (f) (g)\nFig.5. The results demonstrate that the CCE-Net with three modules has better 394 detection Precision and Recall performance. Blue, green, and red boxes stand for the 395 patch position, ground truth, and results, respectively. (a) represent origin images. (b), 396 (c), (d), (e), (f), and (g) represent results obtained via CCE-Net, Faster RCNN, Libra 397 RCNN, Dynamic RCNN, Cascade RCNN, and YOLO v4, respectively. 398 399\n(a) (b)\n(c) (d)\nACCEPTED MANUSCRIPT - CLEAN COPY\nFig.6. The visualization images show that the CCE-Net can pay more attention to the 400 rib fracture region as the decline in feature maps size. Feature maps are superimposed 401 displayed on the original image through uniform scaling. (a) represent the result. (b), 402 (c), and (d) represent the feature map of different sizes of 64*64, 32*32, and 16*16, 403 respectively. 404 405\n406 Fig.7. The PR curves show that the CCE-Net has the best performance compared 407 with other methods. 408 409 3.5. Ablation study 410 To validate the effectiveness of each module, an ablation study is conducted on the 411 proposed model. We use the same training, validation, and test sets in all experiments. 412 The \u2018Faster RCNN with ResNet-50\u2019 is used as the baseline model. The contralateral, 413 contextual, and edge enhanced modules are removed from CCE-Net. The results of 414 ablation are shown in Table 2 and Fig.8. The PR curves of the ablation experiment can 415 be seen in Fig.9, which demonstrates the enhancement of our method. 416\n417 3.5.1. The effect of contralateral module 418 Compared with CCE-Net, if we remove the contralateral module, the performance 419 is decreased by 1.9% and 0.76% on AP50 and Recall, respectively. The decline on AP50 420 validates the effectiveness of the contralateral module on overlapping positions. 421 422 3.5.2. The effect of contextual module 423 Removing the contextual module decreases performance by 1.67% and 2.52% on 424 AP50 and Recall, respectively, compared with CCE-Net. It indicates that the contextual 425 module enhances feature representation more for regions of structure repetition. When 426\nACCEPTED MANUSCRIPT - CLEAN COPY\nadding the contextual module, partial fracture judgment is corrected based on the upper 427 and lower adjacent ribs. 428 429 3.5.3. The effect of edge enhanced image module 430 Compared with the contralateral module and contextual module, adding the edge 431 enhanced module can boost the performance by 7.05% and 7.6% on AP50 and Recall, 432 respectively. The edge enhanced module is encoded by edge information and texture 433 information. This encoding mechanism affects the rib fracture localization, making the 434 proposed method obtain more edge information gains. 435 436\nFig.8. These comparison cases show that the contralateral, contextual, and edge 439\nACCEPTED MANUSCRIPT - CLEAN COPY\nenhanced module can improve detection capabilities at overlapping positions, 440 structure repetition regions, and complex edge locations, respectively. (a), (b), and (c) 441 represent different origin images. (d), (e), and (f) represent CCE-Net. (g), (h), and (i) 442 represent the results of removing the contralateral module, contextual module, and 443 edge enhanced module, respectively. 444 445\n446 Fig.9. The PR curves show the comparison of the ablation study. 447\n448\n4. Discussion 449 This study proposes a novel network architecture for image detection of rib 450 fractures. Three modules are integrated into the Faster RCNN [44] framework. The 451 contralateral module is used to obtain contralateral information of the same structure 452 on both sides of the spine. The contextual module is added to extract image features of 453 the upper and lower positions of the ribs. The edge enhanced module can stress rib 454 image edges and obtain the target details more effectively. Experimental results show 455 that combining these three modules improves the rib fracture detection performance in 456 evaluation indicators. Compared to the performance of the Faster RCNN, AP50 is 457 observed to increase by 15.76% from 0.787 to 0.911 and Recall increases by 6.74% 458 from 0.875 to 0.934. Even compared with many mainstream detection algorithms, 459 including Faster RCNN [44], Libra RCNN [45], Dynamic RCNN [46], Cascade RCNN 460 [47] and YOLO v4 [48] in our experiment, the proposed method exhibits a certain 461 performance improvement in detection effect and fewer training parameters. The 462 ablation experiments are also conducted on CCE-Net by removing different modules. 463 The methods after removing different modules have a certain degree attenuation of the 464 detection effect in different scenarios. It is verified that the proposed method can detect 465\nACCEPTED MANUSCRIPT - CLEAN COPY\nvarious rib fracture features more effectively and comprehensively. 466 Rib image data are more conducive to detecting fractures when combined with the 467 visual features of contralateral, contextual and edge images. One elaborate fusion way 468 to accomplish the features fusion process is to fuse image features from three modules 469 at different network stages. The feature fusion process at the neck of basic two-stage 470 network architecture is designed for the contralateral and contextual modules. They 471 have different original images requiring feature extraction at the backbone stage. The 472 edge image is added to the rib image straightforwardly before feature extraction for the 473 edge enhanced module. In the feature fusion process details, we innovatively used a 474 mixture of numerical operations and attention mechanisms to achieve a better feature 475 fusion strategy. Besides, the different information contained in the three modules is 476 needed to combine to make the final decision. The reasonable weight control of each 477 feature channel is designed at the neck stage of the network, expecting that the proposed 478 method can simulate the clinical diagnosis ideas of radiologists. 479 Although the proposed network architecture has good detection capabilities in rib 480 fracture images, the detection results still have several limitations due to the complexity 481 of medical data. Some failure cases are shown in Fig.10. The limitations of our method 482 are as follows: (1) For some DR images, due to the curvature of the spine, the accurate 483 extraction of curved spine lines still needs to solve; (2) Whether the texture and 484 structural similarity of rib images can be better integrated is also an interesting research 485 topic. To settle these issues, it deserves further study to design a more efficient module 486 to explore the contralateral contextual information and enhance the extraction of 487 information. 488 489\n(a) (b)\nFig.10. These failure cases demonstrate that our proposed method is still worth 490 improving. (a) The origin image, (b) CCE-Net. 491\n492\n5. Conclusion 493 This study proposed a CCE-Net based on contralateral, contextual, and edge 494 enhanced modules to detect rib fracture. A rib fracture is a kind of small target object, 495 which is difficult to detect integrally. Following the valuable experience of radiologists 496 in diagnosis, new modules were added to the design of the detection network. CCE-Net 497 unified contralateral, contextual and edge information together. Compared with the 498 traditional detection network, CCE-Net can capture more effective information. We 499 established the rib fracture database with 1639 DR rib images to train the CCE-Net 500\nACCEPTED MANUSCRIPT - CLEAN COPY\nmodel. A total of 2703 rib fractures were in our database labeled by experienced 501 radiologists. Based on experiments, compared with other methods, its performance can 502 improve the medical image detection ability of rib fracture targets. The detection 503 performance of the CCE-Net was significantly improved than the current methods. 504 CCE-Net attained AP50 0.911, AP75 0.794, AP25 0.913, and Recall 0.934. It can 505 reduce workload for radiologists and assist radiologists in rib fracture diagnosis. 506 507\nAcknowledgments 508 This work was supported in part by the Postgraduate Research & Practice 509 Innovation Program of Jiangsu Province under Grants SJCX21_0635; in part by the 510 Xinghuo Talent Program of Nanjing First Hospital; in part by the State\u2019s Key Project 511 of Research and Development Plan under Grants 2017YFA0104302, 512 2017YFC0109202, and 2017YFC0107900, in part by National Natural Science 513 Foundation under Grants 81530060 and 61871117, in part by the Science and 514 Technology Program of Guangdong under Grant 2018B030333001. 515 516\nCRediT authorship contribution statement 517 Yuan Gao: Conceptualization, Methodology, Formal analysis, Data curation, Validation, 518 Writing. Hongzhi Liu: Conceptualization, Methodology, Writing, Validation, 519 Investigation. Yang Chen: Funding acquisition, Writing, Validation, Investigation. 520 Liang Jiang: Funding acquisition, Conceptualization, Methodology, Supervision, 521 Writing. Chunfeng Yang: Data curation, Writing. Xindao Yin: Formal analysis, Data 522 curation, Funding acquisition, Supervision. Jean-Louis Coatrieux: Data curation, 523 Writing. 524 525\nConflict of Interest 526 The authors declare that they have no known competing financial interests or 527 personal relationships that could have appeared to influence the work reported in this 528 paper. 529 530\nReference 531 1. S.H. Cho, Y.M. Sung, M.S. Kim, Missed rib fractures on evaluation of initial 532 chest CT for trauma patients: Pattern analysis and diagnostic value of coronal 533 multiplanar reconstruction images with multidetector row CT, Br J Radiol. 85 534 (2012) 845-850. 535 2. M.P. Fredric, M. Sarah, A.O. Francis, A. Darwin, D. Andrew, G.E. John, F. 536 Bruce, G. Mario, M. Silvana, M. Christian, S. Babak, T. William, H. V. Don, 537 W.W. Thomas, Consensus statement: surgical stabilization of rib fractures rib 538 fracture colloquium clinical practice guidelines, Injury. 48 (2017) 307-321. 539 3. J.C. Mayberry, D.D. Trunkey, The fractured rib in chest wall trauma, Chest Surg 540\nACCEPTED MANUSCRIPT - CLEAN COPY\nClin N Am. 7 (1997) 239-261. 541 4. B.S. Talbot, C.P. Gange, A. Chaturvedi, N. Klionsky, S.K. Hobbs, A. Chaturvedi, 542 Traumatic rib injury: Patterns, imaging pitfalls, complications, and treatment, 543 Radiographics. 37 (2017) 628-651. 544 5. F.C. Lin, R. Li, Y. Tung, K. Jeng, S.C. Tsai, Morbidity, mortality, associated 545 injuries, and management of traumatic rib fractures, J Chinese Med Assoc. (2016) 546 6-11. 547 6. B. Eric, L. Andre, C. David, M. Lynne, R. Sebastien, T. Stephane, L. Jacques, 548 M. Marcel, Elderly trauma patients with rib fractures are at greater risk of death 549 and pneumonia, Journal of Trauma and Acute Care Surgery. 54 (2003) 478-485. 550 7. S. RobTodd, M.M. McNally, J.B. Holcomb, R. A. Kozar, L.S. Kao, E.A. 551 Gonzalez, C.S. Cocanour, G.A.Vercruysse, M.H. Lygas, B. K. Brasseaux, F.A. 552 Moore, A multidisciplinary clinical pathway decreases rib fracture\u2013associated 553 infectious morbidity and mortality in high-risk trauma patients, The American 554 Journal of Surgery. 192 (2006) 806-811. 555 8. R.M. Shorr, A. Rodriguez, M.C. Indeck, M.D. Crittenden, S. Hartunian, R.A. 556 Cowley, Blunt chest trauma in the elderly, The Journal of Trauma. 29 (1989) 557 234-237. 558 9. F. Birse, H. Williams, D. Shipway, E. Carlton, Blunt chest trauma in the elderly: 559 an expert practice review, Emergency Medicine Journal. 37 (2020) 73-78. 560 10. D. Stephanie, A. Affatato, Blunt chest trauma: utility of radiological evaluation 561 and effect on treatment patterns, The American journal of emergency medicine. 562 26 (2006) 482-486. 563 11. L. Fabricant, B. Ham, R. Mullins, J. Mayberry, Prolonged pain and disability are 564 common after rib fractures, The American Journal of Surgery. 205 (2013) 511-565 516. 566 12. J.B. Holcomb, N.R. McMullin, R.A. Kozar, M.H. Lygas, F.A. Moore, Morbidity 567 from rib fractures increases after age 45, Journal of the American College of 568 Surgeons. 196 (2003) 549-555. 569 13. B.T. Flagel, F.A. Luchette, R.L. Reed, T.J. Esposito, K.A. Davis, J.M. 570 Santaniello, R.L. Gamelli, Half-a-dozen ribs: The breakpoint for mortality, 571 Surgery. 138 (2005) 717-725. 572 14. R. Kent, W. Woods, O. Bostrom, Fatality risk and the presence of rib fractures, 573 Annals of Advances in Automotive Medicine/Annual Scientific Conference, 574 Association for the Advancement of Automotive Medicine. 52 (2008). 575 15. W.M. Wu, Y. Yang, Z.L. Gao, T.C. Zhao, W.W. He, Which is better to multiple 576 rib fractures, surgical treatment or conservative treatment?, International journal 577 of clinical and experimental medicine. 8 (2015) 7930. 578 16. M. Sirmali, H. T\u00fcr\u00fct, S. Top\u00e7u, E. G\u00fclhan, \u00dc. Yazici, S. Kaya, I. Ta\u015ftepe, A 579 comprehensive analysis of traumatic rib fractures: morbidity, mortality and 580 management, European Journal of Cardio-Thoracic Surgery. 24 (2003) 133-138. 581 17. S.W. Ho, Y.H. Teng, S.F. Yang, H.W. Yeh, Y.H. Wang, M.C. Chou, C.B. Yeh, 582 Risk of pneumonia in patients with isolated minor rib fractures: a nationwide 583 cohort study, BMJ open. 7 (2017) e013029. 584\nACCEPTED MANUSCRIPT - CLEAN COPY\n18. H. Tanaka, T. Yukioka, Y. Yamaguti, S. Shimizu, H. Goto, H. Matsuda, S. 585 Shimazaki, Surgical stabilization of internal pneumatic stabilization? a 586 prospective randomized study of management of severe flail chest patients, J 587 Trauma. 52 (2002) 727-732. 588 19. M.S. Lu, Y.K. Huang, Y.H. Liu, H.P. Liu, C.L. Kao, Delayed pneumothorax 589 complicating minor rib fracture after chest trauma, Am J Emerg Med. 26 (2008) 590 551-554. 591 20. M. Bemelman, M.W. de Kruijf, B.M. van, L. Leenen, Rib fractures: To fix or 592 not to fix? An evidence-based algorithm, Korean J Thorac Cardiovasc Surg. 50 593 (2017) 229-234. 594 21. M.B. de Jong, M.C. Kokke, F. Hietbrink, L.P.H. Leenen, Surgical management 595 of rib fractures: Strategies and literature review, Scand J Surg. 103 (2014) 120-596 125. 597 22. E.G. Hwang, Y. Lee, Simple X-ray versus ultrasonography examination in blunt 598 chest trauma: effective tools of accurate diagnosis and considerations for rib 599 fractures, J Exerc Rehabil. 12 (2016) 637-641. 600 23. J. Malghem, B.C. Vande Berg, F.E. Lecouvet, B.E. Maldague, Costal cartilage 601 fractures as revealed on CT and sonography. Am J Roentgenol, 176 (2001) 429-602 432. 603 24. M. Kara, E. Dikmen, H.H. Erdal, I. Simsir, S.A. Kara, Disclosure of unnoticed 604 rib fractures with the use of ultrasonography in minor blunt chest trauma, Eur J 605 Cardio-thoracic Surg. 24 (2003) 608-613. 606 25. L.I.G. Worthley, Thoracic epidural in the management of chest trauma, Intensive 607 Care Med. 11 (1985) 312-315. 608 26. Y. Barnea, H. Kashtan, Y. Skornick, N. Werbin, Isolated rib fractures in elderly 609 patients: Mortality and morbidity, Can J Surg. 45 (2002) 43-46. 610 27. T.J. Ellis, Hip fractures in the elderly, Curr Womens Health Rep. 3 (2003) 75-611 80. 612 28. T. Weikert, L.A. Noordtzij, J. Bremerich, S. Bram, P. Victor, C. Joshy, S. Gregor, 613 W.S. Alexander, Assessment of a deep learning algorithm for the detection of 614 rib fractures on whole-body trauma computed tomography, Korean J Radiol. 21 615 (2020) 891-899. 616 29. Q.Q. Zhou, W. Tang, J. Wang, Z.C. Hu, Z.Y. Xia, Z. Rongguo, X. Fan, W. Yong, 617 X. Yin, B. Zhang, H. Zhang, Automatic detection and classification of rib 618 fractures based on patients\u2019 CT images and clinical information via 619 convolutional neural network, Eur Radiol. 31 (2021) 3815-3825. 620 30. A. Urbaneja, J. De Verbizier, A.S. Formery, C. Tobon-Gomez, L. Nace, A. Blum, 621 P. A. G. Teixeira, Automatic rib cage unfolding with CT cylindrical projection 622 reformat in polytraumatized patients for rib fracture detection and 623 characterization: Feasibility and clinical application, Eur J Radiol. 110 (2019) 624 121-127. 625 31. L. Jin, J. Yang, K. Kuang, B. Ni, Y. Gao, Y. Sun, P. Gao, W. Ma, M. Tan, H. 626 Kang, J. Chen, M. Li, Deep-learning-assisted detection and segmentation of rib 627 fractures from CT scans: Development and validation of FracNet, EBioMedicine. 628\nACCEPTED MANUSCRIPT - CLEAN COPY\n62 (2020) 103106. 629 32. X.H. Meng, D.J. Wu, Z. Wang, X.L. Ma, X.M. Dong, A.E. Liu, L. Chen, A fully 630 automated rib fracture detection system on chest CT images and its impact on 631 radiologist performance, Skeletal Radiol. (2021) 1821-1828. 632 33. R. Lindsey, A. Daluiski, S. Chopra, A. Lachapelle, M. Mozer, S. Sicular, D. 633 Hanel, M. Gardner, A. Gupta, R. Hotchkiss, H. Potter, Deep neural network 634 improves fracture detection by clinicians. Proc Natl Acad Sci U S A. 115 (2018) 635 11591-11596. 636 34. E. Yahalomi, M. Chernofsky, M. Werman, Detection of Distal Radius Fractures 637 Trained by a Small Set of X-Ray Images and Faster R-CNN, Intelligent 638 Computing-Proceedings of the Computing Conference. (2019) 971-981. 639 35. Y.L. Thian, Y. Li, P. Jagmohan, D. Sia, V.E.Y. Chan, R.T. Tan, Convolutional 640 Neural Networks for Automated Fracture Detection and Localization on Wrist 641 Radiographs, Radiol Artif Intell. 1 (2019) e180001. 642 36. D.H. Kim, T. MacKinnon, Artificial intelligence in fracture detection: transfer 643 learning from deep convolutional neural networks, Clin Radiol. 73 (2018) 439-644 445. 645 37. G. Kitamura, C.Y. Chung, B.E. Moore, Ankle Fracture Detection Utilizing a 646 Convolutional Neural Network Ensemble Implemented with a Small Sample, De 647 Novo Training, and Multiview Incorporation, J Digit Imaging. 32 (2019) 672-648 677. 649 38. O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional networks for 650 biomedical image segmentation, International Conference on Medical image 651 computing and computer-assisted intervention, Springer (2015) 234\u2013241. 652 39. J. Liu, G. Zhao, Y. Fei, M. Zhang, Y. Wang, Y. Yu, Align, attend and locate: 653 Chest x-ray diagnosis via contrast induced attention network with limited 654 supervision, Proc IEEE Int Conf Comput Vis. (2019) 10631-10640. 655 40. A.F. Tredgold, Variations of ribs in the primates, with especial reference to the 656 number of sternal ribs in man, Journal of anatomy and physiology. 31 (1897) 657 288. 658 41. M. Everingham, L.V. Gool, C.K.I. Williams, J. Winn, A. Zisserman, The pascal 659 visual object classes (VOC) challenge, Int J Comput Vis. 88 (2010) 303-338. 660 42. J. Lian, J. Liu, S. Zhang, K. Gao, X. Liu, D. Zhang, Y. Yu, A Structure-Aware 661 Relation Network for Thoracic Diseases Detection and Segmentation, IEEE 662 transactions on medical imaging. 2021. 663 43. R. Padilla, S. Netto, E. Silva, A Survey on Performance Metrics for Object-664 Detection Algorithms, international conference on systems, signals and image 665 processing (IWSSIP), IEEE. (2020) 237-242. 666 44. S. Ren, K. He, R. Girshick, J. Sun, Faster R-CNN: towards real-time object 667 detection with region proposal networks, IEEE transactions on pattern analysis 668 and machine intelligence. 39 (2016) 1137-1149. 669 45. J. Pang, K. Chen, J. Shi, H. Feng, W. Ouyang, D. Lin, Libra R-CNN: Towards 670 balanced learning for object detection, Proc IEEE Comput Soc Conf Comput Vis 671 Pattern Recognit. (2019) 821-830. 672\nACCEPTED MANUSCRIPT - CLEAN COPY\n46. H. Zhang, H. Chang, B. Ma, N. Wang, X. Chen, Dynamic R-CNN: Towards 673 High Quality Object Detection via Dynamic Training, European Conference on 674 Computer Vision. 2020. 675 47. Z. Cai, N. Vasconcelos, Cascade R-CNN: Delving into High Quality Object 676 Detection, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit. (2018) 677 6154-6162. 678 48. A. Bochkovskiy, C.Y. Wang, H.Y.M. Liao, YOLOv4: Optimal Speed and 679 Accuracy of Object Detection, 2020. 680\n681"
        }
    ],
    "title": "CCE-Net: A rib fracture diagnosis network based on contralateral, contextual, and edge enhanced modules",
    "year": 2024
}