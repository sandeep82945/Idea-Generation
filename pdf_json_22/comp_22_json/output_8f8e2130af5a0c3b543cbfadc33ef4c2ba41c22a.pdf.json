{
    "abstractText": "In this work, we propose a control scheme for linear systems subject to pointwise in time state and input constraints that aims to minimize time-varying and a priori unknown cost functions. The proposed controller is based on online convex optimization and a reference governor. In particular, we apply online gradient descent to track the time-varying and a priori unknown optimal steady state of the system. Moreover, we use a \u03bb-contractive set to enforce constraint satisfaction and a sufficient convergence rate of the closed-loop system to the optimal steady state. We prove that the proposed scheme is recursively feasible, ensures that the state and input constraints are satisfied at all times, and achieves a dynamic regret that is linearly bounded by the variation of the cost functions. The algorithm\u2019s performance and constraint satisfaction is illustrated by means of a simulation example.",
    "authors": [
        {
            "affiliations": [],
            "name": "Marko Nonhoff"
        },
        {
            "affiliations": [],
            "name": "Johannes K\u00f6hler"
        },
        {
            "affiliations": [],
            "name": "Matthias A. M\u00fcller"
        }
    ],
    "id": "SP:103bbdd109af34e6368251f77122f537d491c9c6",
    "references": [
        {
            "authors": [
                "N. Agarwal",
                "B. Bullins",
                "E. Hazan",
                "S. Kakade",
                "K. Singh"
            ],
            "title": "Online control with adversarial disturbances",
            "venue": "In Proc. of the 36th International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "G. Bianchin",
                "M. Vaquero",
                "J. Cortes",
                "E. Dall\u2019Anese"
            ],
            "title": "Online stochastic optimization for unknown linear systems: Datadriven synthesis and controller analysis",
            "year": 2021
        },
        {
            "authors": [
                "M. Colombino",
                "E. Dall\u2019Anese",
                "A. Bernstein"
            ],
            "title": "Online optimization as a feedback controller: Stability and tracking",
            "year": 2020
        },
        {
            "authors": [
                "A. Didier",
                "J. Sieber",
                "M.N. Zeilinger"
            ],
            "title": "A system level approach to regret optimal control",
            "venue": "IEEE Control Systems Letters,",
            "year": 2022
        },
        {
            "authors": [
                "I. Dogan",
                "Z.J.M. Shen",
                "A. Aswani"
            ],
            "title": "Regret analysis of learning-based MPC with partially-unknown cost function. Available online at arXiv:2108.02307",
            "year": 2021
        },
        {
            "authors": [
                "E. Garone",
                "S. Di Cairano",
                "I. Kolmanovsky"
            ],
            "title": "Reference and command governors for systems with constraints",
            "venue": "A survey on theory and applications. Automatica,",
            "year": 2017
        },
        {
            "authors": [
                "E. Gilbert",
                "K. Tan"
            ],
            "title": "Linear systems with state and control constraints: the theory and application of maximal output admissible sets",
            "venue": "IEEE Transactions on Automatic Control,",
            "year": 1991
        },
        {
            "authors": [
                "A. Hauswirth",
                "S. Bolognani",
                "G. Hug",
                "F. D\u00f6rfler"
            ],
            "title": "Timescale separation in autonomous optimization",
            "venue": "IEEE Transactions on Automatic Control,",
            "year": 2021
        },
        {
            "authors": [
                "E. Hazan"
            ],
            "title": "Introduction to online convex optimization",
            "venue": "Foundations and Trends\u00ae in Optimization,",
            "year": 2016
        },
        {
            "authors": [
                "M. Herceg",
                "M. Kvasnica",
                "C. Jones",
                "M. Morari"
            ],
            "title": "Multi-Parametric Toolbox 3.0",
            "venue": "In Proc. of the European Control Conference,",
            "year": 2013
        },
        {
            "authors": [
                "U. Kalabi\u0107",
                "I. Kolmanovsky"
            ],
            "title": "Reference and command governors for systems with slowly time-varying references and time-dependent constraints",
            "venue": "In Proc. of the 53rd IEEE Conference on Decision and Control,",
            "year": 2014
        },
        {
            "authors": [
                "L.S.P. Lawrence",
                "Z.E. Nelson",
                "E. Mallada",
                "J.W. Simpson-Porco"
            ],
            "title": "Optimal steady-state control for linear time-invariant systems",
            "venue": "In Proc. of the 2018 IEEE Conference on Decision and Control (CDC),",
            "year": 2018
        },
        {
            "authors": [
                "Y. Li",
                "X. Chen",
                "N. Li"
            ],
            "title": "Online optimal control with linear dynamics and predictions: Algorithms and regret analysis",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Y. Li",
                "S. Das",
                "N. Li"
            ],
            "title": "Online optimal control with affine constraints",
            "venue": "In Proc. of the AAAI Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "S. Menta",
                "A. Hauswirth",
                "S. Bolognani",
                "G. Hug",
                "F. D\u00f6rfler"
            ],
            "title": "Stability of dynamic feedback optimization with applications to power systems",
            "venue": "In Proc. of the 2018 56th Annual Allerton Conference on Communication,",
            "year": 2018
        },
        {
            "authors": [
                "Y. Nesterov"
            ],
            "title": "Lectures on Convex Optimization, volume 137 of Springer Optimization and Its Applications. Springer, 2 edition",
            "year": 2018
        },
        {
            "authors": [
                "M. Nonhoff",
                "M.A. M\u00fcller"
            ],
            "title": "Online gradient descent for linear dynamical systems",
            "venue": "IFAC-PapersOnLine,",
            "year": 2020
        },
        {
            "authors": [
                "M. Nonhoff",
                "M.A. M\u00fcller"
            ],
            "title": "An online convex optimization algorithm for controlling linear systems with state and input constraints",
            "venue": "In Proc. of the 2021 American Control Conference,",
            "year": 2021
        },
        {
            "authors": [
                "M. Nonhoff",
                "M.A. M\u00fcller"
            ],
            "title": "On the relation between dynamic regret and closed-loop stability. Available online at arXiv:2209.05964",
            "year": 2022
        },
        {
            "authors": [
                "M. Nonhoff",
                "M.A. M\u00fcller"
            ],
            "title": "Online convex optimization for data-driven control of dynamical systems",
            "venue": "IEEE Open Journal of Control Systems,",
            "year": 2022
        },
        {
            "authors": [
                "S. Shalev-Shwartz"
            ],
            "title": "Online learning and online convex optimization",
            "venue": "Foundations and Trends\u00ae in Machine Learning,",
            "year": 2012
        },
        {
            "authors": [
                "Y. Tang",
                "K. Dvijotham",
                "S. Low"
            ],
            "title": "Real-time optimal power flow",
            "venue": "IEEE Transactions on Smart Grid,",
            "year": 2017
        },
        {
            "authors": [
                "T. Zheng",
                "J. Simpson-Porco",
                "E. Mallada"
            ],
            "title": "Implicit trajectory planning for feedback linearizable systems: A timevarying optimization approach",
            "venue": "In Proc. of the 2020 American Control Conference,",
            "year": 2020
        },
        {
            "authors": [
                "M. Zinkevich"
            ],
            "title": "Online convex programming and generalized infinitesimal gradient ascent",
            "venue": "In Proc. of the Twentieth International Conference on Machine Learning,",
            "year": 2003
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n21 1.\n09 08\n8v 2\n[ ee\nss .S\nY ]\n1 5\nJu n\n20 23\nKeywords: Optimal control, control of constrained systems, dynamic regret, online convex optimization, reference governor"
        },
        {
            "heading": "1. INTRODUCTION",
            "text": "Application of online convex optimization (OCO) to the problem of controlling linear dynamical systems subject to time-varying cost functions has recently gained significant interest. In contrast to classical numerical optimization, in the OCO framework the cost functions are allowed to be time-varying and a priori unknown, compare, e.g., ShalevShwartz (2012); Hazan (2016) and the references therein for an overview. More specifically, an OCO algorithm has to choose an action ut at every time instant t. Only after the action is chosen, the current cost function Lt(u) is revealed to the algorithm, which leads to a cost Lt(ut) depending on the algorithm\u2019s chosen action.\nIn the context of controller synthesis, the OCO framework is of interest due to its low computational complexity and ability to handle time-varying and a priori unknown cost functions. These kind of cost functions commonly have to be considered in practice, e.g., due to unknown renewable energy generation or a priori unknown energy prices, compare, e.g., Tang et al. (2017). Therefore, OCObased controllers have been proposed for linear dynamical systems (Li et al., 2019; Nonhoff and Mu\u0308ller, 2020) subject to disturbances (Agarwal et al., 2019) and in a purely data-driven setting with noisy output feedback (Nonhoff and Mu\u0308ller, 2022b). Such OCO-based control algorithms are typically analyzed theoretically in terms of dynamic regret, a performance measure adopted from the OCO framework. Dynamic regret is able to capture transient performance of the closed loop system and is defined as the\n\u22c6 This work was supported by Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - 505182457.\ndifference between the accumulated closed-loop cost of the controller and some benchmark, which is typically defined in hindsight, i.e., with knowledge of all cost functions. Studying the dynamic regret of controllers for dynamical systems has recently gained increasing attention, compare, e.g., Dogan et al. (2021); Didier et al. (2022). However, in the literature on OCO-based control, pointwise in time state and input constraints are only considered in Nonhoff and Mu\u0308ller (2021); Li et al. (2021), and restrictive assumptions or a limited setting are necessary in these works to guarantee constraint satisfaction at all times. In particular, Nonhoff and Mu\u0308ller (2021) invoke controllability arguments with a deadbeat controller which can deteriorate the practical performance, whereas Li et al. (2021) consider constraint satisfaction under disturbances, but limit the setting to disturbance rejection, and, thus, only compare to controllers that drive the system to the origin. Therefore, we propose an OCO-based controller for constrained linear systems and time-varying, a priori unknown cost functions in this work, that does not rely on additional restrictive assumptions.\nAnother closely related line of research is so-called feedback optimization, where the goal is to control a dynamical system to the solution of a (possibly time-varying) optimization problem. Again, the main focus of research is on linear dynamical systems subject to disturbances (Menta et al., 2018; Lawrence et al., 2018; Colombino et al., 2020), in the data-driven setting (Bianchin et al., 2021), and for nonlinear systems (Hauswirth et al., 2021; Zheng et al., 2020). In contrast to the OCO-based approaches, typically only asymptotic guarantees in the form of stability of the closed-loop system are given. Moreover, in the feedback optimization setting constraints are only considered for\nthe asymptotic steady state, while point-wise in time constraints on the state trajectory are generally not satisfied.\nMotivated by the fact that constraints are ubiquitous in practice due to, e.g., actuator limitations or mechanical restrictions, and violation of these constraints can often be safety-critical, we aim to design an algorithm that can handle both time-varying and a priori unknown cost functions as well as pointwise in time state and input constraints. In order to address the shortcomings discussed above, we combine the OCO-framework with a reference governor (RG) that ensures satisfaction of constraints on both the inputs and states of the system at all times. Reference governors modify the reference command to a welldesigned closed-loop system whenever application of the unmodified reference would lead to constraint violation, compare, e.g., Garone et al. (2017) for a recent survey on the topic. More specifically, we use online projected gradient descent (Zinkevich, 2003), a well-studied method from OCO, to track the time-varying optimal steady state of the system under control. Then, comparable to the approach taken in Kalabic\u0301 and Kolmanovsky (2014), we design a reference governor based on a \u03bb-contractive set to enforce constraint satisfaction. Additionally, our approach using a \u03bb-contractive set ensures a minimal rate of progress at each time step, which finally guarantees a linearly bounded dynamic regret. To the authors\u2019 best knowledge, this is the first work that proves bounded dynamic regret for a reference governor scheme.\nThis paper is organized as follows. Section 2 presents the setting considered in this paper. In Section 3, we introduce and explain the proposed control scheme, and in Section 4 we prove theoretical guarantees for the emerging closed loop, in particular recursive feasibility, constraint satisfaction at all times, and a bound on the dynamic regret. A numerical simulation example is given in Section 5. Section 6 concludes the paper.\nNotation: We denote the set of integer numbers greater than or equal to zero by N\u22650. For a vector x \u2208 R\nn, \u2016x\u2016 is the Euclidean norm. For a matrix A \u2208 Rn\u00d7m, the corresponding induced matrix 2-norm is \u2016A\u2016 and \u03c1(A) denotes its spectral radius. The identity matrix of size n \u00d7 n is given by In and 0m\u00d7n \u2208 R\nm\u00d7n is the matrix of all zeros. The gradient of a function f : Rn \u2192 R evaluated at x \u2208 Rn is denoted by \u2207f(x). For two sets S, T \u2286 Rn, S \u2295 T := {x + y : x \u2208 S, y \u2208 T } is the Minkowski set sum, the interior of S is int S, and for a compact set S \u2286 Rn, \u03a0S(x) := argmins\u2208S \u2016x\u2212 s\u2016 denotes projection of the point x \u2208 Rn onto the set S."
        },
        {
            "heading": "2. SETTING",
            "text": "We consider linear time-invariant systems of the form\nxt+1 = Axt +But, (1)\nwith some initial state x0 \u2208 R n, where x \u2208 Rn is the system state, u \u2208 Rm the system input, and t \u2208 N\u22650. System (1) is subject to constraints\nyt = C0xt +D0ut \u2208 Y \u2286 R m, (2)\nwhich have to be satisfied at all times t \u2208 N\u22650.\nAssumption 1. The pair (A,B) is stabilizable.\nAssumption 2. Y is compact, convex, and 0 \u2208 int Y.\nThe goal is to optimize performance measured in terms of time-varying, a priori unknown, convex cost functions Lt(ut, xt). More specifically, at each time t, only the previous cost functions L0, . . . , Lt\u22121 are known and we want to solve the optimization problem\nmin u\nT \u2211\nt=0\nLt(ut, xt) s.t. (1) - (2).\nBy Assumption 1, we can design a linear state feedback K \u2208 Rm\u00d7n such that AK := A+BK is Schur stable, i.e., \u03c1(AK) is strictly smaller than one. Then, we can define ut = vt + Kxt and rewrite the system dynamics (1) and constraints (2) as\nxt+1 = AKxt +Bvt (3a)\nyt = Cxt +Dvt \u2208 Y, (3b)\nwhere C = (C0 + D0K) and D = D0. Similarly, the time-varying optimization problem can be equivalently reformulated as\nmin v\nT \u2211\nt=0\nLt(vt +Kxt, xt) s.t. (3). (4)\nLet SK = (In \u2212 AK) \u22121B be the map 1 from an input to the corresponding steady state of the stabilized system (3) and define the set of all feasible steady-state inputs as Sv := {v : (CSK +D)v \u2208 Y}.\nAssumption 3. The cost functions Lt(ut, xt) are Lipschitz continuous with Lipschitz constant lL for all t \u2208 N\u22650, i.e., Lt(ut, xt)\u2212Lt(u\u0303t, x\u0303t) \u2264 lL \u2016(ut, xt)\u2212 (u\u0303t, x\u0303t)\u2016 holds for all (ut, xt), (u\u0303t, x\u0303t) \u2208 Z := {(u, x) \u2208 R\nm \u00d7Rn : C0x+D0u \u2208 Y}, and the steady-state cost functions Lst (v) = Lt(v + KSKv, SKv) are \u03b1v-strongly convex and lv-smooth\n2 for all t \u2208 N\u22650 and v \u2208 Sv.\nAssumption 3 is a common assumption in the literature on OCO-based control, compare, e.g., Li et al. (2019); Nonhoff and Mu\u0308ller (2022b).\nSince the cost functions Lt are a priori unknown, we can in general not compute the minimizing input of (4) online. Instead, similar to Nonhoff and Mu\u0308ller (2022b), we adopt the strategy of tracking the a priori unknown and timevarying optimal steady-state reference given by\n\u03b7t := argmin r\nLst (r) s.t. r \u2208 S\u0304v. (5)\nwhere S\u0304v is a compact, convex subset of Sv such that S\u0304v \u2286 int Sv. The optimal steady state can be recovered by \u03b8t := SK\u03b7t. Then, we define dynamic regret R as the difference between the accumulated closed-loop cost and the optimal steady-state cost as\nR := T \u2211\nt=0\nLt(vt +Kxt, xt)\u2212 L s t (\u03b7t). (6)\nThe goal is to achieve a bound for the dynamic regret R that is linear in the path length given by \u2211T\nt=1 \u2016\u03b7t \u2212 \u03b7t\u22121\u2016, because Li et al. (2019) show for a similar, unconstrained setting that the best achievable bound is linear in the path length. Additionally, Nonhoff and Mu\u0308ller (2022a) prove that such a linear bound implies asymptotic stability under mild assumptions in the unconstrained case.\n1 Since AK is Schur stable, the inverse exists and the map is unique. 2 Compare (Nesterov, 2018, Definition 2.1.3 and (2.1.9))."
        },
        {
            "heading": "3. OCO-BASED CONTROL USING A REFERENCE GOVERNOR",
            "text": ""
        },
        {
            "heading": "3.1 Design of the reference governor",
            "text": "In order to ensure satisfaction of the pointwise in time state and input constraints in (2), we design a reference governor in this section. Reference governors compute a feasible reference command vt at each time t such that, if vt is applied constantly to the system (3), then the constraints yt \u2208 Y are satisfied for all future time steps. This can be achieved using the maximal output admissible set (MAS) (Gilbert and Tan, 1991).\nDefinition 4. The maximal output admissible set of a system xt+1 = Axt with constraints Cxt \u2208 Y is defined as O\u221e = {x \u2208 R n : CAtx \u2208 Y \u2200t \u2208 N\u22650}.\nNote that any MAS O\u221e is positively invariant by definition, i.e., AO\u221e \u2286 O\u221e. Moreover, the MAS (or a close inner approximation thereof) can be calculated efficiently if Y is polytopic, A is at least Lyapunov stable, and the pair (A,C) is observable (Gilbert and Tan, 1991).\nSimilar to the approach presented in Kalabic\u0301 and Kolmanovsky (2014), we employ a \u03bb-contractive set in our reference governor in order to ensure a sufficient rate of convergence and prove bounded dynamic regret.\nDefinition 5. For a system xt+1 = Axt, a set X \u2286 R n is \u03bb-contractive with some \u03bb \u2208 (0, 1) if it is compact, convex, 0 \u2208 int X , and AX \u2286 \u03bbX .\nWe denote by et := xt \u2212 SKvt the error between the state xt and the steady state corresponding to the reference vt. Consider a constant reference vt = v for all t \u2208 N\u22650. Then, the error dynamics of the system (3a) and the constraints (3b) written in the error coordinates are\net+1 = xt+1 \u2212 SKv = AKxt \u2212AKSKv = AKet, (7a)\nyt = C(et + SKv) +Dv = Cet + (CSK +D)v \u2208 Y. (7b)\nHence, we choose a \u03bb satisfying \u03c1(AK) < \u03bb < 1 and define O\u03bb\u221e as the MAS of\n\u03bdt+1 = \u03bdt, (8a) \u03c7t+1 = 1\n\u03bb AK\u03c7t, (8b)\n\u03c8t = C\u03c7t + (CSK +D)\u03bdt \u2208 Y. (8c)\nSince Y is compact, convex, and 0 \u2208 int Y by Assumption 2, O\u03bb\u221e is closed, convex, and 0 \u2208 int O \u03bb \u221e (Gilbert and Tan, 1991). Moreover, O\u03bb\u221e has the following properties. Lemma 6. Let Assumptions 1 and 2 be satisfied and let E\u03bb\u221e(v) := {e \u2208 R\nn : (v, e) \u2208 O\u03bb\u221e}. For any constant input vt = v \u2208 Sv for all t \u2208 N\u22650, (i) E \u03bb \u221e(v) is \u03bbcontractive for (7a), and (ii) yt \u2208 Y for all t \u2208 N\u22650 if x0 \u2208 E \u03bb \u221e(v) \u2295 {SKv}.\nProof. (i) Since the MAS is positively invariant, we have by definition of O\u03bb\u221e that\net \u2208 E \u03bb \u221e(v) \u21d4 (v, et) \u2208 O \u03bb \u221e \u21d2\n(\nv, 1\n\u03bb AKet\n)\n\u2208 O\u03bb\u221e\n\u21d4 et+1 = AKet \u2208 \u03bbE \u03bb \u221e(v). (9) (ii) For any v \u2208 Sv, we have v \u2208 Sv \u21d4 (CSK +D)v \u2208 Y \u21d4 (v, 0) \u2208 O\u03bb\u221e \u21d4 0 \u2208 E \u03bb \u221e(v), i.e., 0 \u2208 E \u03bb \u221e(v) for any v \u2208 Sv. By convexity of O\u03bb\u221e, this implies \u03bbE \u03bb \u221e(v) \u2286 E \u03bb \u221e(v). By (9),\nwe get for any v \u2208 Sv and et \u2208 E \u03bb \u221e(v), et \u2208 E \u03bb \u221e(v) \u21d2 et+1 \u2208 \u03bbE \u03bb \u221e(v) \u2286 E \u03bb \u221e(v), i.e., the set E \u03bb \u221e(v) is positive invariant for the system (7a). Since x0 \u2208 E \u03bb \u221e(v) \u2295 {SKv} implies e0 = x0 \u2212 SKv \u2208 E \u03bb \u221e(v), we have et \u2208 E \u03bb \u221e(v) for all t \u2208 N\u22650. Moreover, et \u2208 E \u03bb \u221e(v) and the fact that O\u03bb\u221e is the MAS of system (8) with output (8c), imply et \u2208 E \u03bb \u221e(v) \u21d2 yt = Cet + (CSK +D)v \u2208 Y.\nLemma 6 shows that, if the reference input vt is kept constant and the error et = xt \u2212 SKvt together with the reference vt is contained in O \u03bb \u221e, then we can ensure contraction of the error and satisfaction of the constraints (2)."
        },
        {
            "heading": "3.2 OCO-RG scheme",
            "text": "In this section, we introduce the proposed combination of OCO and a reference governor. A block diagram of the proposed approach is shown in Figure 1 and our OCORG scheme is given in Algorithm 1. At each time t \u2208 N\u22651, given access to the previous cost function Lt\u22121, we measure the system state xt and\n(1) apply one projected gradient descent step with a suitable step size \u03b3 > 0 in (10) to the optimization problem {minr L s t\u22121(r) s.t. r \u2208 S\u0304v} in order to com-\npute an estimate rt of the previous optimal reference \u03b7t\u22121, compare (5). Hence, rt tracks the optimal steady state reference \u03b7t\u22121. (2) Next, we apply a reference governor that enforces constraint satisfaction by computing a feasible reference command vt based on the estimate rt and the measured state xt in (11). The constraint in (11a) ensures that the error et = xt\u2212SKvt between xt and the steady state corresponding to vt lies in the set O\u03bb\u221e, which ensures that the error is contractive and constraint satisfaction by Lemma 6. (3) Finally, we apply ut = vt + Kxt as given in (12) to the system (1), receive the current cost function Lt, and move to time step t+ 1.\nSince we do not have access to any cost function at time t = 0, we apply an initial reference v0 = r0 and set \u03b10 = 1. In order to ensure safe operation, i.e., satisfaction of the state and input constraints at all times, we assume that the initial reference r0 is feasible.\nAssumption 7. The initial reference r0 \u2208 Sv satisfies (r0, x0 \u2212 SKr0) \u2208 O \u03bb \u221e.\nThe proposed algorithm is illustrated in Figure 2. Note that rt \u2208 S\u0304v for all t \u2208 N\u22650 due to the projection in (10) and Assumption 7. Hence, (rt, SKrt) is a feasible steady state of system (3) at all times.\nAt each time t, we have to compute one gradient step and a projection in (10), and solve one scalar optimization prob-\nlem in (11). The projection can be done efficiently if the set of all feasible steady states S\u0304v, which is typically lowdimensional, has a simple structure. Thus, Algorithm 1 has a particularly low computational complexity if the projection onto the set S\u0304v can be solved efficiently."
        },
        {
            "heading": "4. THEORETICAL ANALYSIS",
            "text": "First, we show that the proposed OCO-RG scheme is recursively feasible, i.e., the optimization problem in (11) has a solution at all times t \u2208 N\u22651 and the algorithm is well-defined. Moreover, we show that the constraints (2) are satisfied at all times t \u2208 N\u22650.\nLemma 8. Let Assumptions 1, 2, and 7 hold. Algorithm 1 is recursively feasible and yt \u2208 Y for all t \u2208 N\u22650.\nProof. Note that vt \u2208 S\u0304v \u2286 Sv for all t \u2265 N\u22650, because v0 \u2208 S\u0304v and rt \u2208 S\u0304v for all t \u2208 N\u22650 by (10) and Assumption 7. Then, Lemma 6(i) implies that, if there exists a feasible reference input vt satisfying the constraint (11a) at time t, then vt+1 = vt and, hence, \u03b1t+1 = 0 is a feasible solution of (11) at time t+ 1. Thus, Algorithm 1 is recursively feasible. Moreover, constraint satisfaction is guaranteed by Lemma 6(ii) for all t \u2208 N\u22650 because Algorithm 1 is recursively feasible.\nHaving established that the proposed OCO-RG scheme is well-defined at all times, we analyze the closed-loop performance of Algorithm 1. In order to establish a bound on the dynamic regret, we first prove that the modified reference vt is moved towards rt at all times.\nLemma 9. Suppose Assumptions 1, 2, and 7 are satisfied. There exists \u01eb \u2208 (0, 1] such that \u03b1t \u2265 \u01eb for all t \u2208 N\u22650.\nProof. Fix any t \u2208 N\u22651. Assumption 7 and Lemma 8 imply (vt\u22121, xt\u22121 \u2212 SKvt\u22121) \u2208 O \u03bb \u221e and, thus,\n(vt\u22121, xt\u22121 \u2212 SKvt\u22121) \u2208 O \u03bb \u221e\n\u21d4 et\u22121 \u2208 E \u03bb \u221e(vt\u22121) (9) \u21d2 AKet\u22121 \u2208 \u03bbE \u03bb \u221e(vt\u22121)\n\u21d4\n(\nvt\u22121, 1\n\u03bb AK(xt\u22121 \u2212 SKvt\u22121)\n)\n\u2208 O\u03bb\u221e\n\u21d4\n(\nvt\u22121, 1\n\u03bb (xt \u2212 SKvt\u22121)\n)\n\u2208 O\u03bb\u221e, (13)\nbecauseAKSKvt\u22121 = SKvt\u22121\u2212Bvt\u22121. Let Y\u0304 be a compact subset of int Y such that (CSK +D)S\u0304v \u2286 Y\u0304 , and let O\u0304 \u03bb \u221e be the MAS of (8) with Y replaced by Y\u0304 in (8c). Then, O\u0304\u03bb\u221e \u2286 int O \u03bb \u221e by definition, and (r, 0) \u2208 O\u0304 \u03bb \u221e for all r \u2208 S\u0304v because r \u2208 S\u0304v \u21d4 C \u00b7 0+ (CSK +D)r \u2208 Y\u0304 \u21d4 (r, 0) \u2208 O\u0304 \u03bb \u221e. Hence, there exists \u03b4 > 0 such that ( r + r\u03b4,\u2212SKr \u03b4 )\n\u2208 O\u03bb\u221e for all r \u2208 S\u0304v and r\n\u03b4 \u2208 \u03b4B, where B \u2286 Rm is the unit ball. We proceed by a case distinction.\nCase 1: \u2016rt \u2212 vt\u22121\u2016 \u2265 (1\u2212 \u03bb)\u03b4. Let r \u03b4 t := \u03b4 rt\u2212vt\u22121 \u2016rt\u2212vt\u22121\u2016 \u2208 \u03b4B and \u03b1ct := (1\u2212\u03bb)\u03b4\n\u2016rt\u2212vt\u22121\u2016 \u2208 (0, 1]. Since vt\u22121 \u2208 S\u0304v, we have\n(vt\u22121 + r \u03b4 t ,\u2212SKr \u03b4 t ) \u2208 O \u03bb \u221e as shown above. Applying a convex combination with (13) yields\n\u03bb\n(\nvt\u22121, 1\n\u03bb (xt \u2212 SKvt\u22121)\n)\n+ (1\u2212 \u03bb) ( vt\u22121 + r \u03b4 t ,\u2212SKr \u03b4 t ) \u2208 O\u03bb\u221e \u21d4 (vt\u22121 + \u03b1 c t(rt \u2212 vt\u22121),\nxt \u2212 SK (vt\u22121 + \u03b1 c t(rt \u2212 vt\u22121))) \u2208 O \u03bb \u221e.\nComparing the above inclusion to the constraints in (11), we get that vct = vt\u22121 + \u03b1 c t(rt \u2212 vt\u22121) is a feasible candidate solution at time t because 0 < \u03b1ct \u2264 1. Since \u03b1t is maximized in (11), we get\n1 \u2265 \u03b1t \u2265 \u03b1 c t =\n(1 \u2212 \u03bb)\u03b4\n\u2016rt \u2212 vt\u22121\u2016 \u2265 (1\u2212 \u03bb)\n\u03b4 \u2206 =: \u01eb > 0,\nwhere \u2206 > 0 is a finite constant satisfying \u2206 \u2265 max\u03bd1,\u03bd2\u2208S\u0304v \u2016\u03bd1 \u2212 \u03bd2\u2016, which exists by compactness of S\u0304v.\nCase 2: \u2016rt \u2212 vt\u22121\u2016 < (1 \u2212 \u03bb)\u03b4. Let r \u03b4 t := rt\u2212vt\u22121 1\u2212\u03bb \u2208 \u03b4B, which again implies (vt\u22121 + r \u03b4 t ,\u2212SKr \u03b4 t ) \u2208 O \u03bb \u221e. Applying the same convex combination as before, we get (rt, xt \u2212 SKrt) \u2208 O \u03bb \u221e, i.e., vt = rt and \u03b1t = 1 \u2265 \u01eb is a feasible solution to (11a) at time t.\nCombining the results above, we have \u03b1t \u2265 \u01eb for all t \u2208 N\u22651. Therefore, \u03b10 = 1 concludes the proof.\nFinally, we are ready to analyze closed-loop performance.\nTheorem 10. Let Assumptions 1-3, and 7 be satisfied. The closed loop achieves\nR \u2264 K0 +K\u03b7\nT \u2211\nt=1\n\u2016\u03b7t \u2212 \u03b7t\u22121\u2016 , (14)\nwhere K0 = K0,\u03b8 \u2016x0 \u2212 \u03b80\u2016 + K0,\u03b7 \u2016v0 \u2212 \u03b70\u2016 and K0,\u03b8,K0,\u03b7,K\u03b7 > 0 are constants independent of T .\nProof. Lipschitz continuity from Assumption 3 together with \u03b8t = SK\u03b7t yields\nR (6) =\nT \u2211\nt=0\nLt(vt +Kxt, xt)\u2212 Lt(\u03b7t +K\u03b8t, \u03b8t)\n\u2264 lL\nT \u2211\nt=0\n\u2225 \u2225 \u2225 \u2225 [ vt +Kxt xt ] \u2212 [ \u03b7t +K\u03b8t \u03b8t ] \u2225 \u2225 \u2225 \u2225\n= lL\nT \u2211\nt=0\n\u2225 \u2225 \u2225 \u2225 [ K(xt \u2212 SKvt) xt \u2212 SKvt ] + [ (KSK + Im)(vt \u2212 \u03b7t) SK(vt \u2212 \u03b7t) ] \u2225 \u2225 \u2225 \u2225\n\u2264 kx\nT \u2211\nt=0\n\u2016xt \u2212 SKvt\u2016+ kv\nT \u2211\nt=0\n\u2016vt \u2212 \u03b7t\u2016 , (15)\nwhere we defined kv := lL \u2225 \u2225[(KSK + Im) \u22a4, S\u22a4K ] \u22a4 \u2225 \u2225 and kx := lL \u2225 \u2225[K\u22a4, In] \u22a4 \u2225\n\u2225. In the following, we proceed to bound the sums in (15) separately. First, note that the optimal steady-state input \u03b7t, its estimate rt, and the modified reference input vt are only defined for t \u2208 N\u22650. Thus, we set without loss of generality \u03b7\u22121 = v\u22121 = r\u22121 = r0 = v0. Moreover, we make use of the following standard result from convex optimization.\nLemma 11. (Nesterov, 2018, Theorem 2.2.14) Suppose Assumption 2 and 3 are satisfied and let \u03b3 \u2208 (0, 2\n\u03b1v+lv ]. Then,\n\u2225 \u2225\u03a0S\u0304v (r \u2212 \u03b3\u2207L s t (r)) \u2212 \u03b7t \u2225 \u2225 \u2264 \u03ba \u2016r \u2212 \u03b7t\u2016 (16)\nholds for any r \u2208 S\u0304v, where \u03ba = 1\u2212 \u03b3\u03b1v \u2208 [0, 1).\nUsing (16), the triangle inequality, and r\u22121 = \u03b7\u22121, we get T \u2211\nt=0\n\u2016rt \u2212 \u03b7t\u22121\u2016 (16) \u2264 \u03ba\nT \u2211\nt=0\n\u2016rt \u2212 \u03b7t\u22121\u2016+ \u03ba\nT \u2211\nt=0\n\u2016\u03b7t \u2212 \u03b7t\u22121\u2016 .\nRearranging yields T \u2211\nt=0\n\u2016rt \u2212 \u03b7t\u22121\u2016 \u2264 \u03ba\n1\u2212 \u03ba\nT\u22121 \u2211\nt=0\n\u2016\u03b7t \u2212 \u03b7t\u22121\u2016 . (17)\nNext, using the triangle inequality we get T \u2211\nt=0\n\u2016vt \u2212 \u03b7t\u2016 (11b) \u2264\nT \u2211\nt=0\n(1\u2212 \u03b1t) \u2016vt\u22121 \u2212 \u03b7t\u22121\u2016\n+\nT \u2211\nt=0\n\u03b1t \u2016rt \u2212 \u03b7t\u22121\u2016+\nT \u2211\nt=0\n\u2016\u03b7t \u2212 \u03b7t\u22121\u2016\n(17)\n\u2264 (1 \u2212 \u01eb)\nT \u2211\nt=0\n\u2016vt \u2212 \u03b7t\u2016+ 1\n1\u2212 \u03ba\nT \u2211\nt=0\n\u2016\u03b7t \u2212 \u03b7t\u22121\u2016 ,\nwhere we used 1 \u2265 \u03b1t \u2265 \u01eb > 0 and v\u22121 = \u03b7\u22121. Again, rearranging yields\nT \u2211\nt=0\n\u2016vt \u2212 \u03b7t\u2016 \u2264 1\n\u01eb\u03ba\nT \u2211\nt=0\n\u2016\u03b7t \u2212 \u03b7t\u22121\u2016 , (18)\nwhere \u01eb\u03ba := \u01eb(1\u2212\u03ba). Moreover, v\u22121 = \u03b7\u22121 and (18) imply T \u2211\nt=0\n\u2016vt \u2212 vt\u22121\u2016 \u2264 2\nT \u2211\nt=0\n\u2016vt \u2212 \u03b7t\u2016+\nT \u2211\nt=0\n\u2016\u03b7t \u2212 \u03b7t\u22121\u2016\n(18)\n\u2264 2 + \u01eb\u03ba \u01eb\u03ba\nT \u2211\nt=0\n\u2016\u03b7t \u2212 \u03b7t\u22121\u2016 . (19)\nIt remains to bound the first sum in (15). First, consider the error dynamics et = xt\u2212SKvt given by et = AKet\u22121+ SK(vt\u22121 \u2212 vt). Applying this equation repeatedly yields\net = A t Ke0 +\nt\u22121 \u2211\ni=0\nAiKSK(vt\u2212i\u22121 \u2212 vt\u2212i). (20)\nSince AK is Schur stable, there exist constants c \u2265 1, \u03c3 \u2208 (0, 1) such that \u2016AtK\u2016 \u2264 c\u03c3\nt. Hence, applying the closed-loop error dynamics dynamics (20) yields\nT \u2211\nt=0\n\u2016xt \u2212 SKvt\u2016 (20) \u2264\nT \u2211\nt=0\n\u2225 \u2225AtK \u2225 \u2225 \u2016e0\u2016\n+ \u2016SK\u2016\nT \u2211\nt=0\nt\u22121 \u2211\ni=0\n\u2225 \u2225AiK \u2225 \u2225 \u2016vt\u2212i\u22121 \u2212 vt\u2212i\u2016\n\u2264 c\n1\u2212 \u03c3 \u2016e0\u2016+ \u2016SK\u2016\nT \u2211\nt=0\n(\n\u2016vt \u2212 vt\u22121\u2016\nT\u22121 \u2211\ni=0\n\u2225 \u2225AiK \u2225 \u2225\n)\n(19)\n\u2264 c\n1\u2212 \u03c3 \u2016x0 \u2212 \u03b80\u2016+\nc\n1\u2212 \u03c3 \u2016SK\u2016 \u2016v0 \u2212 \u03b70\u2016\n+ c\n1\u2212 \u03c3 \u2016SK\u2016 2 + \u01eb\u03ba \u01eb\u03ba\nT \u2211\nt=0\n\u2016\u03b7t \u2212 \u03b7t\u22121\u2016 . (21)\nInserting (18) and (21) into (15), and using \u03b7\u22121 = v0 proves the result (14)."
        },
        {
            "heading": "5. NUMERICAL EXAMPLE",
            "text": "In this section, we illustrate the performance of the proposed OCO-RG scheme by numerical simulation. We consider the problem of tracking a time-varying and a priori unknown reference while minimizing control effort. In particular, the linear system (1) is generated randomly by sampling each entry of A \u2208 R5\u00d75 from a uniform distribution over the interval [\u22121, 1]. We obtained an unstable system with \u03c1(A) \u2248 1.62 and set B = [0 . . . 0 1] \u22a4 . We consider box constraints of the form |xi| \u2264 1, i \u2208 {1, . . . , 5}, and |u| \u2264 1. The stabilizing controller K is chosen such that the eigenvalues of AK are given by eig(A) = {0.1, 0.15, . . . , 0.3}. Finally, we let \u03bb = 0.95, S\u0304v = 0.95Sv \u2286 int Sv, and compute O \u03bb \u221e using the multi-parametric toolbox (Herceg et al., 2013). The cost functions are given by Lt(u, x) = 1 2 \u2016x\u2212 x\u0304t\u2016 2 + qt2 \u2016ut\u2016 2 , where x\u0304t = z\u0304t + 0.2 sin( \u03c0 100 t), and both z\u0304t \u2208 [\u22121, 1] and qt \u2208 [0, 2] are a priori unknown. More specifically, at each time t, we change qt with a probability of 1% by uniformly sampling it from the interval [0, 2] and keep it constant otherwise. We apply the same procedure to z\u0304t \u2208 [\u22121, 1]. Finally, we set \u03b3 = 0.1 and initialize the system and the algorithm with x0 = 0n, and r0 = 0. The results are illustrated in Figure 3. The top plot of Figure 3 shows the first state of the closed-loop system x1 together with the optimal steady state \u03b81 and the corresponding constraints. It can be seen that the closed loop follows the optimal steady state closely, for sudden changes as well as for slow, continuous changes induced by the sine term in the definition of x\u0304t. Moreover, the middle plot of Figure 3 illustrates the optimal steady-state input \u03b7t+K\u03b8t, the estimate rt + Kxt, the applied input ut = vt + Kxt, and the input constraints. Since the reference command rt together with the stabilizing feedback Kxt would violate the input constraints, the reference governor modifies the reference such that ut satisfies the constraints at all times. The bottom plot of Figure 3 shows the parameter \u03b1t. As proven in Lemma 9, \u03b1t > 0 at all times t. More specifically, in this simulation the lowest value of \u03b1t is approximately 6 \u00b7 10\u22123. The maximum computation time of the proposed\nOCO-RG scheme 3 averaged over 100 trials and different realizations of the cost function is approximately 66\u00b5s per time step."
        },
        {
            "heading": "6. CONCLUSION",
            "text": "In this paper, we propose an algorithm for controlling dynamical systems subject to time-varying and a priori unknown cost functions as well as pointwise in time state and input constraints by combining the online convex optimization framework with a reference governor. In particular, we make use of a \u03bb-contractive set to ensure constraint satisfaction at all times as well as a sufficient convergence rate for proving that the closed loop\u2019s dynamic regret is bounded linearly in the variation of the cost functions. Future works includes obtaining theoretical guarantees for the practically important case of disturbances."
        }
    ],
    "year": 2023
}