{
    "abstractText": "Training deep neural networks (DNNs) with noisy labels often leads to poorly generalized models as DNNs tend to memorize the noisy labels in training. Various strategies have been developed for improving sample selection precision and mitigating the noisy label memorization issue. However, most existing works adopt a class-dependent softmax classifier that is vulnerable to noisy labels by entangling the classification of multi-class features. This paper presents a class-independent regularization (CIR) method that can effectively alleviate the negative impact of noisy labels in DNN training. CIR regularizes the class-dependent softmax classifier by introducing multi-binary classifiers each of which takes care of one class only. Thanks to its class-independent nature, CIR is tolerant to noisy labels as misclassification by one binary classifier does not affect others. For effective training of CIR, we design a heterogeneous adaptive co-teaching strategy that forces the class-independent and class-dependent classifiers to focus on sample selection and image classification, respectively, in a cooperative manner. Extensive experiments show that CIR achieves superior performance consistently across multiple benchmarks with both synthetic and real images. Code is available at https://github.com/RumengYi/CIR.",
    "authors": [
        {
            "affiliations": [],
            "name": "Rumeng Yi"
        },
        {
            "affiliations": [],
            "name": "Dayan Guan"
        },
        {
            "affiliations": [],
            "name": "Yaping Huang"
        },
        {
            "affiliations": [],
            "name": "Shijian Lu"
        }
    ],
    "id": "SP:1087d97c6a5871b7062dd7ee826d847e280d96f5",
    "references": [
        {
            "authors": [
                "E. Arazo",
                "D. Ortego",
                "P. Albert",
                "N. O\u2019Connor",
                "K. McGuinness"
            ],
            "title": "Unsupervised label noise modeling and loss correction",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2019
        },
        {
            "authors": [
                "Y. Bai",
                "E. Yang",
                "B. Han",
                "Y. Yang",
                "J. Li",
                "Y. Mao",
                "G. Niu",
                "T. Liu"
            ],
            "title": "Understanding and improving early stopping for learning with noisy labels",
            "venue": "Advances in Neural Information Processing Systems (NeurIPS), 24392\u201324403.",
            "year": 2021
        },
        {
            "authors": [
                "D. Berthelot",
                "N. Carlini",
                "I. Goodfellow",
                "N. Papernot",
                "A. Oliver",
                "C.A. Raffel"
            ],
            "title": "Mixmatch: A holistic approach to semi-supervised learning",
            "venue": "Advances in neural information processing systems, 32.",
            "year": 2019
        },
        {
            "authors": [
                "S. Bucci",
                "M.R. Loghmani",
                "T. Tommasi"
            ],
            "title": "On the effectiveness of image rotation for open set domain adaptation",
            "venue": "European Conference on Computer Vision (ECCV), 422\u2013438. Springer.",
            "year": 2020
        },
        {
            "authors": [
                "C. Chen",
                "O. Li",
                "D. Tao",
                "A. Barnett",
                "C. Rudin",
                "J.K. Su"
            ],
            "title": "This looks like that: deep learning for interpretable image recognition",
            "venue": "Advances in Neural Information Processing Systems (NeurIPS), 1\u201312.",
            "year": 2019
        },
        {
            "authors": [
                "L.-C. Chen",
                "Y. Zhu",
                "G. Papandreou",
                "F. Schroff",
                "H. Adam"
            ],
            "title": "Encoder-decoder with atrous separable convolution for semantic image segmentation",
            "venue": "European Conference on Computer Vision (ECCV), 801\u2013818.",
            "year": 2018
        },
        {
            "authors": [
                "T. Chen",
                "S. Kornblith",
                "M. Norouzi",
                "G. Hinton"
            ],
            "title": "A simple framework for contrastive learning of visual representations",
            "venue": "International Conference on Machine Learning (ICML), 1597\u20131607.",
            "year": 2020
        },
        {
            "authors": [
                "Z. Chen",
                "T. Wang",
                "X. Wu",
                "X.-S. Hua",
                "H. Zhang",
                "Q. Sun"
            ],
            "title": "Class re-activation maps for weakly-supervised semantic segmentation",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 969\u2013978.",
            "year": 2022
        },
        {
            "authors": [
                "E. Englesson",
                "H. Azizpour"
            ],
            "title": "Generalized jensen-shannon divergence loss for learning with noisy labels",
            "venue": "Advances in Neural Information Processing Systems (NeurIPS), 34: 30284\u201330297.",
            "year": 2021
        },
        {
            "authors": [
                "R. Girshick"
            ],
            "title": "Fast r-cnn",
            "venue": "Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 1440\u20131448.",
            "year": 2015
        },
        {
            "authors": [
                "B. Han",
                "Q. Yao",
                "X. Yu",
                "G. Niu",
                "M. Xu",
                "W. Hu",
                "I. Tsang",
                "M. Sugiyama"
            ],
            "title": "Co-teaching: Robust training of deep neural networks with extremely noisy labels",
            "venue": "Advances in Neural Information Processing Systems (NeurIPS), 8536\u20138546.",
            "year": 2018
        },
        {
            "authors": [
                "J. Han",
                "P. Luo",
                "X. Wang"
            ],
            "title": "Deep self-learning from noisy labels",
            "venue": "Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 5138\u20135147.",
            "year": 2019
        },
        {
            "authors": [
                "K. He",
                "X. Zhang",
                "S. Ren",
                "J. Sun"
            ],
            "title": "Identity mappings in deep residual networks",
            "venue": "European conference on computer vision (ECCV), 630\u2013645.",
            "year": 2016
        },
        {
            "authors": [
                "J. Huang",
                "L. Qu",
                "R. Jia",
                "B. Zhao"
            ],
            "title": "O2U-Net: A simple noisy label detection approach for deep neural networks",
            "venue": "Proceedings of IEEE/CVF International Conference on Computer Vision (ICCV), 3326\u20133334.",
            "year": 2019
        },
        {
            "authors": [
                "T. Kim",
                "J. Ko",
                "J. Choi",
                "S.-Y Yun"
            ],
            "title": "FINE samples for learning with noisy labels",
            "venue": "In Advances in Neural Information Processing Systems (NeurIPS),",
            "year": 2021
        },
        {
            "authors": [
                "Y. Kim",
                "J. Yun",
                "H. Shon",
                "J. Kim"
            ],
            "title": "Joint negative and positive learning for noisy labels",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 9442\u20139451.",
            "year": 2021
        },
        {
            "authors": [
                "N. Komodakis",
                "S. Gidaris"
            ],
            "title": "Unsupervised representation learning by predicting image rotations",
            "venue": "International Conference on Learning Representations (ICLR), 1\u201316.",
            "year": 2018
        },
        {
            "authors": [
                "A. Krizhevsky",
                "G Hinton"
            ],
            "title": "Learning multiple layers of features from tiny images. Master\u2019s thesis University of Toronto",
            "year": 2009
        },
        {
            "authors": [
                "K.-H. Lee",
                "X. He",
                "L. Zhang",
                "L. Yang"
            ],
            "title": "Cleannet: Transfer learning for scalable image classifier training with label noise",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 5447\u2013 5456.",
            "year": 2018
        },
        {
            "authors": [
                "J. Li",
                "R. Socher",
                "S.C. Hoi"
            ],
            "title": "DivideMix: Learning with noisy labels as semi-supervised learning",
            "venue": "International Conference on Learning Representations (ICLR), 1\u201314.",
            "year": 2020
        },
        {
            "authors": [
                "J. Li",
                "Y. Wong",
                "Q. Zhao",
                "M.S. Kankanhalli"
            ],
            "title": "Learning to learn from noisy labeled data",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 5051\u20135059.",
            "year": 2019
        },
        {
            "authors": [
                "S. Li",
                "X. Xia",
                "S. Ge",
                "T. Liu"
            ],
            "title": "Selectivesupervised contrastive learning with noisy labels",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 316\u2013325.",
            "year": 2022
        },
        {
            "authors": [
                "X. Liang",
                "L. Yao",
                "X. Liu",
                "Y. Zhou"
            ],
            "title": "Tripartite: Tackle noisy labels by a more precise partition",
            "venue": "arXiv preprint arXiv:2202.09579, 1\u201316.",
            "year": 2022
        },
        {
            "authors": [
                "H. Liu",
                "Z. Cao",
                "M. Long",
                "J. Wang",
                "Q. Yang"
            ],
            "title": "Separate to adapt: Open set domain adaptation via progressive separation",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2927\u20132936.",
            "year": 2019
        },
        {
            "authors": [
                "S. Liu",
                "J. Niles-Weed",
                "N. Razavian",
                "C. FernandezGranda"
            ],
            "title": "Early-learning regularization prevents memorization of noisy labels",
            "venue": "Advances in Neural Information Processing Systems (NeurIPS), 20331\u201320342.",
            "year": 2020
        },
        {
            "authors": [
                "E. Malach",
                "S. Shalev-Shwartz"
            ],
            "title": "Decoupling\u201d when to update\u201d from\u201d how to update",
            "venue": "Advances in Neural Information Processing Systems (NeurIPS), 960\u2013970.",
            "year": 2017
        },
        {
            "authors": [
                "D. Ortego",
                "E. Arazo",
                "P. Albert",
                "N.E. O\u2019Connor",
                "K. McGuinness"
            ],
            "title": "Multi-objective interpolation training for robustness to label noise",
            "year": 2021
        },
        {
            "authors": [
                "G. Patrini",
                "A. Rozza",
                "A. Krishna Menon",
                "R. Nock",
                "L. Qu"
            ],
            "title": "Making deep neural networks robust to label noise: A loss correction approach",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 1944\u20131952.",
            "year": 2017
        },
        {
            "authors": [
                "X. Peng",
                "K. Wang",
                "Z. Zeng",
                "Q. Li",
                "J. Yang",
                "Y. Qiao"
            ],
            "title": "Suppressing mislabeled data via grouping and selfattention",
            "venue": "Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XVI 16, 786\u2013802. Springer.",
            "year": 2020
        },
        {
            "authors": [
                "M. Ren",
                "W. Zeng",
                "B. Yang",
                "R. Urtasun"
            ],
            "title": "Learning to reweight examples for robust deep learning",
            "venue": "International Conference on Machine Learning (ICML), 4334\u2013 4343.",
            "year": 2018
        },
        {
            "authors": [
                "K. Saito",
                "D. Kim",
                "K. Saenko"
            ],
            "title": "OpenMatch: Openset consistency regularization for semi-supervised learning with outliers",
            "venue": "Advances in Neural Information Processing Systems (NeurIPS), 25956\u201325967.",
            "year": 2021
        },
        {
            "authors": [
                "K. Saito",
                "K. Saenko"
            ],
            "title": "Ovanet: One-vs-all network for universal domain adaptation",
            "venue": "Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 9000\u20139009.",
            "year": 2021
        },
        {
            "authors": [
                "Z. Sun",
                "F. Shen",
                "D. Huang",
                "Q. Wang",
                "X. Shu",
                "Y. Yao",
                "J. Tang"
            ],
            "title": "PNP: Robust learning from noisy labels by probabilistic noise prediction",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 5311\u20135320.",
            "year": 2022
        },
        {
            "authors": [
                "K. Wang",
                "X. Peng",
                "J. Yang",
                "S. Lu",
                "Y. Qiao"
            ],
            "title": "Suppressing uncertainties for large-scale facial expression recognition",
            "venue": "Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 6897\u20136906.",
            "year": 2020
        },
        {
            "authors": [
                "Q. Wang",
                "B. Han",
                "T. Liu",
                "G. Niu",
                "J. Yang",
                "C. Gong"
            ],
            "title": "Tackling instance-dependent label noise via a universal probabilistic model",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), volume 35, 10183\u2013 10191.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Wang",
                "X. Ma",
                "Z. Chen",
                "Y. Luo",
                "J. Yi",
                "J. Bailey"
            ],
            "title": "Symmetric cross entropy for robust learning with noisy labels",
            "venue": "Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 322\u2013330.",
            "year": 2019
        },
        {
            "authors": [
                "H. Wei",
                "L. Feng",
                "X. Chen",
                "B. An"
            ],
            "title": "Combating noisy labels by agreement: A joint training method with co-regularization",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 13726\u201313735.",
            "year": 2020
        },
        {
            "authors": [
                "T. Xiao",
                "T. Xia",
                "Y. Yang",
                "C. Huang",
                "X. Wang"
            ],
            "title": "Learning from massive noisy labeled data for image classification",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2691\u2013 2699.",
            "year": 2015
        },
        {
            "authors": [
                "Y. Yao",
                "Z. Sun",
                "C. Zhang",
                "F. Shen",
                "Q. Wu",
                "J. Zhang",
                "Z. Tang"
            ],
            "title": "Jo-src: A contrastive approach for combating noisy labels",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 5192\u20135201.",
            "year": 2021
        },
        {
            "authors": [
                "K. Yi",
                "J. Wu"
            ],
            "title": "Probabilistic end-to-end noise correction for learning with noisy labels",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 7017\u20137025.",
            "year": 2019
        },
        {
            "authors": [
                "R. Yi",
                "Y. Huang"
            ],
            "title": "TC-Net: Detecting noisy labels via transform consistency",
            "venue": "IEEE Transactions on Multimedia, 1\u201314.",
            "year": 2021
        },
        {
            "authors": [
                "X. Yu",
                "B. Han",
                "J. Yao",
                "G. Niu",
                "I. Tsang",
                "M. Sugiyama"
            ],
            "title": "How does disagreement help generalization against label corruption",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2019
        },
        {
            "authors": [
                "C. Zhang",
                "S. Bengio",
                "M. Hardt",
                "B. Recht",
                "O. Vinyals"
            ],
            "title": "Understanding deep learning requires rethinking generalization",
            "venue": "International Conference on Learning Representations (ICLR), 1\u201315.",
            "year": 2017
        },
        {
            "authors": [
                "H. Zhang",
                "M. Cisse",
                "Y.N. Dauphin",
                "D. Lopez-Paz"
            ],
            "title": "Mixup: Beyond empirical risk minimization",
            "venue": "International Conference on Learning Representations (ICLR), 1\u201313.",
            "year": 2018
        },
        {
            "authors": [
                "W. Zhang",
                "Y. Wang",
                "Y. Qiao"
            ],
            "title": "Metacleaner: Learning to hallucinate clean representations for noisylabeled visual recognition",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 7373\u20137382.",
            "year": 2019
        },
        {
            "authors": [
                "Z. Zhang",
                "M. Sabuncu"
            ],
            "title": "Generalized cross entropy loss for training deep neural networks with noisy labels",
            "venue": "Advances in Neural Information Processing Systems (NeurIPS), 1\u201311.",
            "year": 2018
        },
        {
            "authors": [
                "Z. Zhang",
                "H. Zhang",
                "S.O. Arik",
                "H. Lee",
                "T. Pfister"
            ],
            "title": "Distilling effective supervision from severe label noise",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 9294\u20139303.",
            "year": 2020
        },
        {
            "authors": [
                "R. Zhu",
                "S. Li"
            ],
            "title": "CrossMatch: Cross-classifier consistency regularization for open-set single domain generalization",
            "venue": "International Conference on Learning Representations (ICLR), 1\u201317.",
            "year": 2021
        },
        {
            "authors": [
                "Z. Zhu",
                "T. Liu",
                "Y. Liu"
            ],
            "title": "A second-order approach to learning with instance-dependent label noise",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 10113\u201310123.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "Introduction",
            "text": "Deep Neural Networks (DNNs) have achieved remarkable success in the computer vision community thanks to the large-scale datasets with precisely human-annotated labels (Chen et al. 2018) (Girshick 2015). However, collecting such high-quality annotations is extremely expensive and time-consuming, which may not be feasible in practice. Two alternative solutions are crowd-sourcing from nonexperts and online queries by search engines. Unfortunately, these low-cost approaches inevitably introduce noisy labels. Recent studies have shown that DNNs can easily overfit to noisy labels and result in poor generalization performance (Zhang et al. 2017). Therefore, attention has been concentrated on how to learn with noisy labels.\nRecent studies have reached a consensus for learning from noisy labels by jointly minimizing the negative impact of noisy samples and maximizing the exploitation of clean\n*Corresponding Author Copyright \u00a9 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nsamples. An active research direction is training DNNs with selected or reweighted training, where the challenge is to design a proper criterion for identifying clean samples. Existing criteria are mainly divided into two types: loss-based criterion (i.e., small-loss (Han et al. 2018) (Yu et al. 2019) and Gaussian Mixture Model (GMM) (Li, Socher, and Hoi 2020)) and consistency-based criterion (i.e., prediction consistency between two networks (Wei et al. 2020) (Liang et al. 2022) or two views (Yi and Huang 2021)). Although promising performance gains have been witnessed by employing these sample selection strategies, they heavily rely on the predictions from DNNs commonly trained with softmax cross-entropy loss. However, the standard softmax classifier is sensitive to noisy labels due to its class-dependent property, i.e., the misclassification of one class penalizes the activation on others (Chen et al. 2022) (Chen et al. 2019), which not only outputs misleadingly high confidences on noisy data, but also affects the training of other classes, and eventually degrades the purity of the selected clean samples.\nGiven this insight, we propose a novel Class-Independent\nRegularization (CIR) by introducing multi-binary classifier for sample selection, which reformulates the K-way multiclass classification into K binary classification. Specifically, each binary classifier learns to distinguish each individual class versus all the rest of classes together. Due to the nonexclusive activation across different classes, multi-binary classifier are class-independent and more robust for noisy labels. To validate this claim, we design a toy experiment by training DNNs with the standard softmax classifier (SSC) and the multi-binary classifier (MBC), respectively, on CIFAR datasets with different noise rates. The experimental results are shown in Fig. 1. When the training labels are clean, SSC outperforms MBC slightly as illustrated in Fig. 1 (a) and (c), demonstrating that SSC should be retained when classifying samples with clean labels after the sample selection procedure. When the training labels are noisy, MBC surpasses SSC with large margins under the higher noise rates as illustrated in Fig. 1 (b) and (d), demonstrating the superiority of MBC in learning with noisy labels during the sample selection procedure (more results are shown in the section of experiments). Based on these two empirical demonstrations, we further develop a heterogeneous adaptive coteaching strategy by coupling MBC in the sample selection procedure and SSC in the image classification procedure. In summary, our contribution is three-fold:\n\u2022 We propose a class-independent regularization (CIR) method that addresses the negative impact of the standard class-dependent softmax classifier in noisy label learning during sample selection.\n\u2022 We specially design a heterogeneous adaptive coteaching strategy to cooperate the class-independent multi-binary classifier with the standard class-dependent softmax classification, which can mutually promote the sample selection and image classification in a cooperative manner.\n\u2022 We conduct comprehensive experiments on the synthetic and real-world noise benchmarks and the experimental results demonstrate that our method achieves the stateof-the-art performance."
        },
        {
            "heading": "Related Works",
            "text": ""
        },
        {
            "heading": "Learning from Noisy Labels",
            "text": "Learning from noisy labels can be divided into two categories (Huang et al. 2019): (1) directly training noise-robust models and (2) detecting noisy labels and then reducing their impacts. The former typically focuses on designing noiserobust objective functions (Zhang and Sabuncu 2018) (Wang et al. 2019) or regularizations (Zhang et al. 2020) to reduce the effect of the overfitting on noisy labels, but these methods do not perform well under high noise ratios (Bai et al. 2021). In the solution of the latter, potential noisy labels are first detected, and then removed them from the training set or fed to the model after corrected them. However, the challenge is to find a proper criterion for identifying clean samples. Existing methods roughly fall on two types: loss-based criterion and consistency-based criterion. The representative approaches of the former are small-loss criterion (Han et al.\n2018) (Yu et al. 2019), which selects a human-defined proportion of small-loss samples as clean ones, and Gaussian Mixture Model (GMM) criterion (Li, Socher, and Hoi 2020), which fits GMM to the sample losses to model the distribution of clean and noisy samples. The representative approaches of the latter are prediction consistency, which partitions the training data into clean and noisy subsets based on the consistent predictions of two networks (Wei et al. 2020) (Liang et al. 2022) or two views (Yi and Huang 2021).\nHowever, the above methods rely heavily on the predictions from DNNs. We argue that the standard softmax classifier in DNNs is vulnerable to noisy labels due to its classdependent nature, i.e., the misclassified score of one class suppresses the activation of others, which affects the performance of sample selection. To alleviate the negative impact of noisy labels, we introduce a class-independent multibinary classifier to regularize the class-dependent standard softmax classifier."
        },
        {
            "heading": "Multi-binary Classifier Training",
            "text": "Multi-binary classifier (MBC) is widely used in open-set recognition (Saito, Kim, and Saenko 2021) and open-set domain adaptation (Zhu and Li 2021) (Saito and Saenko 2021) (Liu et al. 2019) tasks to identify unknown classes samples. In open-set scenario, there exists outliers that do not belong to the known classes in the training dataset, so the above methods adopt MBC to learn a boundary between inliers and outliers for each class. If all of the binary classifiers regard the input as negative, this sample has a high probability of belonging to an unknown class. In this way, they leverage the MBC to capture the notion of \u201cnone of the above\u201d, which avoids the closed-world assumption of the standard softmax classifier (SSC).\nDifferent from the above methods, we leverage the classindependent property of MBC to regularize the SSC. Specifically, the SSC encourages to improve the output of ground truth and penalizes all others simultaneously, when the supervision is noisy, the classification scores of all classes will be affected due to the class-dependent property in SSC, resulting in overfitting to noisy labels. However, the MBC can alleviate this problem. The binary cross-entropy used in MBC is a nonexclusive activation function, which is dedicated to recognizing one class only and misclassification from one class will not affect others, improving the ability of identifying the noisy labels during sample selection."
        },
        {
            "heading": "Class-Independent Regularization",
            "text": ""
        },
        {
            "heading": "Problem Definition",
            "text": "We consider a classification problem with a training set D = {(x1, y1), ..., (xN , yN )}, where xi is an image and yi \u2208 {0, 1}C is a one-hot label over C classes which may contains noise. Let G and Fs denote the feature extractor and standard softmax classifier (SSC) of DNNs, respectively. Therefore, the model\u2019s output softmax probability of xi is ps(xi) = Fs(G(xi)). In general, the objective function is\nempirical risk of cross-entropy loss, which is formulated by:\nLc = \u2212 1\nN N\u2211 i=1 yi \u00b7 log ps(xi), (1)\nwhere N is the total number of samples and \u00b7 denotes dot product. Since yi contains noise, the model will overfit the noisy labels and result a poor classification performance.\nExisting methods try to divide training data into clean and noisy subsets by designing a criterion for identifying clean samples, but they rely heavily on the predictions from SSC. We argue that the class-dependent nature of SSC might enlarge the effects of noisy labels. Therefore, we propose a class-independent regularization equipped with a heterogeneous adaptive co-teaching strategy to mitigate the negative impact of class-dependent property in SSC."
        },
        {
            "heading": "Heterogeneous Adaptive Co-teaching",
            "text": "The illustration of the proposed CIR is given in Fig. 2 (a). Different from the traditional co-teaching strategy that de-\nploys two networks with the same architecture to find possibly clean samples for each other (Han et al. 2018) (Yu et al. 2019), the proposed CIR employs a heterogeneous adaptive co-teaching strategy to learn with noisy labels. Specifically, for the training of MBC, the clean samples are collected according to the prediction confidence of the SSC by an adaptive thresholding strategy (Fig. 2 (c)). To make MBC learn an effective boundary among the positive and the nearest negative classes, a negative class masking strategy (Fig. 2 (b)) is applied to keep an appropriate number of negative classes for training. Subsequently, the clean samples are identified according to whether the predictions of the binary classifier with maximum confidence are consistent with their given labels. Finally, the SSC utilizes the clean subset as labeled data and the noisy subset as unlabeled data to perform semi-supervised learning. In this cooperative manner, MBC and SSC share the same feature extractor, the network therefore can learn better feature representations by using SSC to perform semi-supervised learning, which in turn promotes the discriminative ability of MBC to distinguish clean\nsamples from noisy ones.\nMulti-binary Classifier Training To alleviate the negative effect of class-dependent SSC during sample selection, we introduce MBC to regularize the SSC. Let Fm represent MBC with C classes as Fm = {F 1m, ..., FCm}, where F km is the k-th binary classifier with output pkm(xi) = F k m(G(xi)). pkm(z = 0|xi) and pkm(z = 1|xi) denote the output probability that the instance xi belongs to the k-th class or not, respectively, where pkm(z = 0|xi) + pkm(z = 1|xi) = 1.\nThe clean subset used to train MBC is selected by SSC. A naive way is to set a pre-defined threshold for all classes to cut off high-confidence samples according to the SSC\u2019s prediction. However, this strategy can only make sure that highquality clean data contribute to the model training, while it ignores a considerable amount of other clean data with lowconfidence, especially at the early stage of the training process, where only a few clean data have their prediction confidence above the threshold. To address this issue, we design an adaptive thresholding strategy to dynamically determine the threshold for each class according to their learning status. As shown in Fig. 2 (c), the learning status of each class can be reflected by counting the number of samples whose predictions of SSC fall into this class, and meanwhile their confidences are above a fixed pre-defined threshold \u03c4 : \u03c3t(c) =\nN\u2211 i=1 1(argmax(ps,t(xi)) = c) \u00b7 1(max(ps,t(xi)) \u2265 \u03c4),\n(2) where \u03c3t(c) represents the learning status of class c at training epoch t, and ps,t(xi) is the prediction of SSC for sample xi at training epoch t. The larger \u03c3t(c) means the better learning status of class c. Then we normalize the \u03c3t(c) to [0, 1] and use the normalized \u03c3t(c) to scale the fixed predefined threshold \u03c4 , which is formulated by:\nTt(c) = \u03c3t(c)\nmax c\n\u03c3t \u00b7 \u03c4, (3)\nwhere Tt(c) is a threshold of class c at training epoch t, and can be adaptively adjusted during the training process according to the learning status. A smaller \u03c3t(c) means the class is hard to learn, therefore we set a lower threshold Tt(c) to select clean samples for this class. As the number of training epochs increases, all classes are well trained and their thresholds will all approach the fixed threshold \u03c4 . At training epoch t, given the image xi and its label li \u2208 {1, ..., C}, we can obtain the clean subset as follow:\nDsc ={(xsci , ysci )| argmax(ps,t(xi)) = li and max(ps,t(xi)) \u2265 Tt(argmax(ps,t(xi)))}.\n(4)\nGiven clean subset Dsc = {(xsc1 , ysc1 ), ..., (xscNsc , y sc Nsc )}, where Nsc is the total number of selected clean samples, we apply a negative class masking strategy for MBC to learn an effective boundary among positive and the nearest negative classes. As shown in Fig. 2 (b), for each training sample, the corresponding negative classes are remained in two manners: (1) The class l\u0304ssci that the SSC is most difficult to distinguish, i.e., the class is different from the ground-truth but\nhaving the largest prediction score in SSC. (2) The class l\u0304randi that is randomly selected from the category set excluding the ground-truth label lsci and l\u0304 ssc i . Therefore, the loss function used for training the MBC can be formulated as:\nLm = 1\nNsc [ Nsc\u2211 i=1 \u2212 log(pl sc i m(z = 0|xsci ))\n\u2212 \u2211 k\u2208l\u0304sci log(pkm(z = 1|xsci )) ] ,\n(5)\nwhere l\u0304sci = {l\u0304ssci , l\u0304randi }.\nStandard Softmax Classifier Training After each training of MBC, clean samples are selected according to whether the predictions of the binary classifier with maximum confidence are consistent with their given labels. Given the image xi and its label li \u2208 {1, ..., C}, we can obtain the clean subset as follow:\nDmc = {(xmci , ymci )| argmax (pkm(z = 0|xi)) = li}, (6)\nand the noisy subset is Dmn = D\\Dmc . Then SSC utilizes the clean subset Dmc as labeled dataset and the noisy subset Dmn as unlabeled dataset to perform semi-supervised learning.\nSimilar to DivideMix (Li, Socher, and Hoi 2020), we improve MixMatch (Berthelot et al. 2019) by label refinement and label guessing on clean and noisy samples to perform semi-supervised learning. Specifically, we first generate two copies of each sample in Dmc and Dmn with weak augmentation: D\u0302mc,d = {(x\u0302mc1,d, ymc1 ), ..., (x\u0302mcNmc,d, y mc Nmc\n); d \u2208 (1, 2)} and D\u0302mn,d = {x\u0302mn1,d , ..., x\u0302mnNmn,d; d \u2208 (1, 2)}.\nSecond, we perform label refinement for the labeled sample xmci by linearly combining the ground-truth label y mc i with the soft label pssoft generated by SSC\u2019s prediction ps(x\u0302 mc i,d ) (averaged across two weak augmentations of x mc i ), which is guided by \u03c9i (the prediction confidence of the binary classifier corresponding to its ground-truth label lmci ):\ny\u0303mci = \u03c9iy mc i + (1\u2212 \u03c9i)pssoft , (7)\nwhere\npssoft = 1\n2 2\u2211 d=1 ps(x\u0302 mc i,d ), (8)\n\u03c9i = 1\n2 2\u2211 d=1 p lmci m (z = 0|x\u0302mci,d ). (9)\nThird, we perform label guessing for the unlabeled sample xmni by averaging the SSC\u2019s predictions of two weak augmentations to produce more reliable guessed label:\ny\u0303mni = 1\n2 2\u2211 d=1 ps(x\u0302 mn i,d ). (10)\nBesides, we also apply temperature sharpening on y\u0303mci and y\u0303mni to get y\u0302 mc i and y\u0302 mn i .\nThen we aggregate the labeled and unlabeled images with their refined and guessed labels respectively to form X\u0302 and\nU\u0302 , and use MixMatch to generate X \u2032 and U \u2032 . The semisupervised losses are formulated as:\nLsup = 1 |X \u2032 | \u2211\nx,y\u2208X \u2032 y \u00b7 log ps(x), (11)\nLunsup = 1 |U \u2032 | \u2211\nx,y\u2208U \u2032 \u2225y \u2212 ps(x)\u222522. (12)\nIn summary, the total loss for training SSC can be computed as follows:\nLs = Lsup + Lunsup + Lreg, (13)\nwhere Lreg is a regularization term to regularize the network\u2019s output across all samples similar to DivideMix.\nTraining and Inference In summary, combining the training of MBC and SSC together, our final objective loss function is: L = Lm + Ls. (14) In the test stage, we utilize the ensemble of SSC and MBC for getting the final classification score."
        },
        {
            "heading": "Experiments",
            "text": ""
        },
        {
            "heading": "Datasets and Implementation Details",
            "text": "Datasets and Noise Setting We extensively evaluate our approach on CIFAR-10, CIFAR-100 (Krizhevsky, Hinton et al. 2009), Clothing1M (Xiao et al. 2015) and Food101N (Lee et al. 2018) datasets. Both CIFAR-10 and CIFAR-100 contain 50K training images and 10K test images of size 32 \u00d7 32, which involve 10 classes and 100 classes, respectively. Clothing1M contains 1 million images of clothes with 14 categories. Food101N contains 310k images of food with 101 categories. For CIFAR-10 and\nCIFAR-100 datasets, following previous works (Li, Socher, and Hoi 2020) (Liu et al. 2020) (Bai et al. 2021), we inject two types of label noise: symmetric and asymmetric into the dataset in a specified noise rate. The symmetric label noise is generated by using a random one-hot vector to replace the ground-truth label of one sample. The asymmetric label noise is designed to mimic the structure of real-world label noise, such as CAT\u2194DOG, BIRD\u2194AIRPLANE. For realworld noisy datasets Clothing1M and Food101N, the overall label accuracy are 61.54% and 80%, respectively.\nImplementation Details For experiments on CIFAR datasets, following previous work (Li, Socher, and Hoi 2020), we use an 18-layer PreAct ResNet architecture (He et al. 2016) and train it using SGD with a momentum of 0.9, a weight decay of 0.0005, and a batch size of 128. The network is trained for 300 epochs. We set the initial learning rate as 0.02, and reduce it by a factor of 100 after 150 epoch. The warm-up epochs are set to 10 for CIFAR-10 and 30 for CIFAR-100. For real-world datasets, following previous works (Li, Socher, and Hoi 2020) (Yao et al. 2021), we use ResNet-50 with ImageNet pretrained weight and train the network for 80 epochs. We set the initial learning rate as 0.002 and reduce it by a factor of 10 after 30 epochs. The warm-up epochs are set to 5, and other experiment settings are the same as CIFAR datasets. The hyperparameter \u03c4 used in CIFAR is selected from {0.5, ..., 0.9}, and used in Clothing1M and Food101N are 0.4 and 0.2, respectively."
        },
        {
            "heading": "Comparison with State-of-the-art Methods",
            "text": "Results on CIFAR-10 and CIFAR-100 Datasets We use the conventional training with the softmax crossentropy loss (SSC) and binary cross-entropy loss (MBC) on noisy datasets as our baselines, and compare the proposed CIR with recent state-of-the-art methods, includ-\ning MixUp (Zhang et al. 2018), Forward (Patrini et al. 2017), GCE (Zhang and Sabuncu 2018), P-correct (Yi and Wu 2019), M-correct (Arazo et al. 2019), DivideMix (Li, Socher, and Hoi 2020), ELR (Liu et al. 2020), GCE + (Zhang and Sabuncu 2018), ELR+ (Liu et al. 2020), MOIT+ (Ortego et al. 2021) and Sel-CL+ (Li et al. 2022). Since the last four approaches apply contrastive learning (Chen et al. 2020) to reduce the risk of noise memorization, we incorporate the similar techniques to further facilitate our CIR, which called CIR+. In CIR+, we empirically find that the contrastive learning performs worse than the rotation recognition (Komodakis and Gidaris 2018), so in this paper, we introduce the rotation recognition as an auxiliary task for feature learning enhancement. For fair comparisons, the reported results are all obtained with one single model. We report the average test accuracy over the last 10 epochs. As shown in Table 1, we first observe that the test accuracy of MBC outperforms SSC in most cases. The margin is clearer, especially on symmetric 80% and asymmetric 40%, demonstrating that MBC is more robust to noisy labels.\nFor CIFAR-10, from moderate to severe label noise, CIR performs better than the compared methods in most cases, which exceeds the second-best method DivideMix by 2.1% on average accuracy. And the performance can be further boosted by CIR+, which exceeds the second-best method Sel-CL+ by 2.3% on average accuracy. For the more difficult CIFAR-100, CIR achieves a significant improvement over the second-best method ELR by 5.7% on average accuracy. Moreover, CIR+ exceeds the second-best method Sel-CL+ by 2.3% on average accuracy. In addition, we also evaluate the performance of sample selection during training on CIFAR-100 with all noise rates, and the results are shown in Fig. 3. We show the Area Under a Curve (AUC) for clean/noisy classification from MBC during training (the first row), and those curves prove that CIR can distinguish\nclean and noisy samples accurately and comprehensively as training proceeds, even for high noise ratio, and the corresponding test accuracy curve (the second row) also verifies the effectiveness of CIR.\nResults on Real-world Datasets We compare CIR with two baselines (SSC and MBC) and the state-of-the-art methods, including MetaL (Li et al. 2019), P-correct (Yi and Wu 2019), DivideMix (Li, Socher, and Hoi 2020), ELR (Liu et al. 2020), FINE (Kim et al. 2021a), UPM (Wang et al. 2021), JNPL (Kim et al. 2021b), CAL (Zhu, Liu, and Liu 2021) CNet (Lee et al. 2018), DeepSelf (Han, Luo, and Wang 2019), MCleaner (Zhang, Wang, and Qiao 2019), AFM (Peng et al. 2020), GJS (Englesson and Azizpour 2021) and PNP (Sun et al. 2022) on Clothing1M and Food101N datasets. For fair comparisons, the reported results are all obtained with one single model. The results are shown in Table 2. Similar to CIFAR, the test accuracy of MBC also outperforms SSC, especially on the more challenge dataset Clothing1M, the performance of MBC exceeds the SSC by 2.34%. Meanwhile, CIR consistently outperforms competing methods across all datasets and exceeds the second-best methods by 0.16% and 0.21% on Clothing1M and Food101N, respectively."
        },
        {
            "heading": "Further Analysis",
            "text": "Ablation Study To verify the effectiveness of the CIR, the ablation studies are conducted on CIFAR-10 with symmetric 20% (Sym-20%) and 50% (Sym-50%), asymmetric 20% (Asym-20%) and 30% (Asym-30%) noise rates, respectively. The results are shown in Table 3.\nAs the baseline of CIR, we use the clean samples selected by MBC to train SSC, where the samples used to train MBC are selected by a pre-defined threshold, and the MBC are trained only using l\u0304rand as negative class. As shown in (1) of Table 3, the test accuracies are 93.5% (Sym-20%), 90.2% (Sym-50%), 93.2% (Asym-20%) and 91.8% (Asym30%), respectively, which exceed several approaches in Table 1, demonstrating that MBC can select clean samples\nCIR Small-loss Prediction consistency GMM\naccurately. Since the MBC provides accurate supervision for SSC training, after applying semi-supervised learning (SSL), the performance can be further boosted (the results are shown in (2)). Especially on symmetric noise, the network regards more noisy samples as unlabeled data for training and the performance is improved by 1.9% (Sym-20%) and 4.0% (Sym-50%), respectively.\nTo study the effect of adaptive thresholding (AT) strategy, we select clean samples according to the adaptive threshold instead of a pre-defined threshold on the basis of (2), and the results are shown in (3). Compared with (2), the performance is further improved, especially on asymmetric noise. A possible reason is that the network is more difficult to identify clean samples from the asymmetric noisy dataset because this noise type is designed to mimic the structure of real-world label noise, resulting a large number of clean samples have low-confidence. In this case, the proposed AT strategy provides more effective supervision at the early stage, and lays a solid foundation for the subsequent training.\nTo study the effect of negative class masking (NCM) strategy, we treat l\u0304ssc as negative class to train the MBC on the basis of (3), and the results are shown in (4). Compared with (3), the performance is further improved by 0.1%-0.7%, demonstrating that the proposed NCM can enforce the binary classifiers learn an effective boundary among the positive and negative classes.\nRobustness Analysis of Different Criteria To evaluate the performance of sample selection, we compare the proposed CIR with class-dependent based methods, i.e., smallloss criterion (Han et al. 2018), GMM criterion (Li, Socher, and Hoi 2020) and prediction consistency criterion (Yi and Huang 2021) using one single model on four cases, i.e., symmetric 20%, 50%, 80% and asymmetric 40% noise rates on CIFAR-100 dataset. We only use the selected clean samples\nto train the network, and report the F1 score (the first row) and the corresponding test accuracy (the second row) during training. The results are shown in Fig. 4. It can be seen from the first row that CIR can select clean samples from noisy ones accurately irrespective of the noise level. It is worth noting that in asymmetric noise case, the F1 score of the class-dependent based methods are all below 65%, but CIR exceeds them by a large margin, which demonstrates that CIR is tolerant to noisy labels. Meanwhile, the accurate separation also provides the accurate supervisions for the subsequent training process. The corresponding test accuracy curve also verifies the effectiveness of CIR."
        },
        {
            "heading": "Conclusion",
            "text": "In this paper, we propose the Class-Independent Regularization (CIR) to alleviate the negative impact of noisy label learning. Specifically, CIR regularizes the standard class-dependent softmax classifier by introducing a classindependent multi-binary classifier, where each binary classifier is dedicated to recognizing one class only. For training CIR effectively, we design a heterogeneous adaptive coteaching strategy that forces the class-independent and classdependent classifiers to focus on sample selection and image classification, respectively, in a cooperative manner. Experiments on synthetic and real-world noise benchmarks demonstrate the effectiveness of CIR."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work is supported by National Natural Science Foundation of China (62271042, 62106017, 61906013), Beijing Natural Science Foundation (M22022, L211015), Hebei Natural Science Foundation (F2022105018), Fundamental Research Funds for the Central Universities (2019JBZ104)."
        },
        {
            "heading": "IEEE/CVF Conference on Computer Vision and Pattern",
            "text": "Recognition (CVPR), 6606\u20136615. Patrini, G.; Rozza, A.; Krishna Menon, A.; Nock, R.; and Qu, L. 2017. Making deep neural networks robust to label noise: A loss correction approach. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 1944\u20131952. Peng, X.; Wang, K.; Zeng, Z.; Li, Q.; Yang, J.; and Qiao, Y. 2020. Suppressing mislabeled data via grouping and selfattention. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XVI 16, 786\u2013802. Springer. Ren, M.; Zeng, W.; Yang, B.; and Urtasun, R. 2018. Learning to reweight examples for robust deep learning. In International Conference on Machine Learning (ICML), 4334\u2013 4343. Saito, K.; Kim, D.; and Saenko, K. 2021. OpenMatch: Openset consistency regularization for semi-supervised learning with outliers. In Advances in Neural Information Processing Systems (NeurIPS), 25956\u201325967. Saito, K.; and Saenko, K. 2021. Ovanet: One-vs-all network for universal domain adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 9000\u20139009. Sun, Z.; Shen, F.; Huang, D.; Wang, Q.; Shu, X.; Yao, Y.; and Tang, J. 2022. PNP: Robust learning from noisy labels by probabilistic noise prediction. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 5311\u20135320. Wang, K.; Peng, X.; Yang, J.; Lu, S.; and Qiao, Y. 2020. Suppressing uncertainties for large-scale facial expression recognition. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 6897\u20136906. Wang, Q.; Han, B.; Liu, T.; Niu, G.; Yang, J.; and Gong, C. 2021. Tackling instance-dependent label noise via a universal probabilistic model. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), volume 35, 10183\u2013 10191. Wang, Y.; Ma, X.; Chen, Z.; Luo, Y.; Yi, J.; and Bailey, J. 2019. Symmetric cross entropy for robust learning with noisy labels. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 322\u2013330. Wei, H.; Feng, L.; Chen, X.; and An, B. 2020. Combating noisy labels by agreement: A joint training method with co-regularization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 13726\u201313735. Xiao, T.; Xia, T.; Yang, Y.; Huang, C.; and Wang, X. 2015. Learning from massive noisy labeled data for image classification. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2691\u2013 2699. Yao, Y.; Sun, Z.; Zhang, C.; Shen, F.; Wu, Q.; Zhang, J.; and Tang, Z. 2021. Jo-src: A contrastive approach for combating noisy labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 5192\u20135201.\nYi, K.; and Wu, J. 2019. Probabilistic end-to-end noise correction for learning with noisy labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 7017\u20137025. Yi, R.; and Huang, Y. 2021. TC-Net: Detecting noisy labels via transform consistency. IEEE Transactions on Multimedia, 1\u201314. Yu, X.; Han, B.; Yao, J.; Niu, G.; Tsang, I.; and Sugiyama, M. 2019. How does disagreement help generalization against label corruption? In International Conference on Machine Learning (ICML), 7164\u20137173. Zhang, C.; Bengio, S.; Hardt, M.; Recht, B.; and Vinyals, O. 2017. Understanding deep learning requires rethinking generalization. In International Conference on Learning Representations (ICLR), 1\u201315. Zhang, H.; Cisse, M.; Dauphin, Y. N.; and Lopez-Paz, D. 2018. Mixup: Beyond empirical risk minimization. In International Conference on Learning Representations (ICLR), 1\u201313. Zhang, W.; Wang, Y.; and Qiao, Y. 2019. Metacleaner: Learning to hallucinate clean representations for noisylabeled visual recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 7373\u20137382. Zhang, Z.; and Sabuncu, M. 2018. Generalized cross entropy loss for training deep neural networks with noisy labels. In Advances in Neural Information Processing Systems (NeurIPS), 1\u201311. Zhang, Z.; Zhang, H.; Arik, S. O.; Lee, H.; and Pfister, T. 2020. Distilling effective supervision from severe label noise. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 9294\u20139303. Zhu, R.; and Li, S. 2021. CrossMatch: Cross-classifier consistency regularization for open-set single domain generalization. In International Conference on Learning Representations (ICLR), 1\u201317. Zhu, Z.; Liu, T.; and Liu, Y. 2021. A second-order approach to learning with instance-dependent label noise. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 10113\u201310123."
        }
    ],
    "title": "Class-Independent Regularization for Learning with Noisy Labels",
    "year": 2023
}