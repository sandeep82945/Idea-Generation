{
    "abstractText": "Deep Neural Networks (DNNs) are being adopted as components in software systems. Creating and specializing DNNs from scratch has grown increasingly difficult as stateof-the-art architectures grow more complex. Following the path of traditional software engineering, machine learning engineers have begun to reuse large-scale pre-trained models (PTMs) and fine-tune these models for downstream tasks. Prior works have studied reuse practices for traditional software packages to guide software engineers towards better package maintenance and dependency management. We lack a similar foundation of knowledge to guide behaviors in pre-trained model ecosystems. In this work, we present the first empirical investigation of PTM reuse. We interviewed 12 practitioners from the most popular PTM ecosystem, Hugging Face, to learn the practices and challenges of PTM reuse. From this data, we model the decision-making process for PTM reuse. Based on the identified practices, we describe useful attributes for model reuse, including provenance, reproducibility, and portability. Three challenges for PTM reuse are missing attributes, discrepancies between claimed and actual performance, and model risks. We substantiate these identified challenges with systematic measurements in the Hugging Face ecosystem. Our work informs future directions on optimizing deep learning ecosystems by automated measuring useful attributes and potential attacks, and envision future research on infrastructure and standardization for model registries.",
    "authors": [
        {
            "affiliations": [],
            "name": "Wenxin Jiang"
        },
        {
            "affiliations": [],
            "name": "Nicholas Synovic"
        },
        {
            "affiliations": [],
            "name": "Matt Hyatt"
        },
        {
            "affiliations": [],
            "name": "Taylor R. Schorlemmer"
        },
        {
            "affiliations": [],
            "name": "Rohan Sethi"
        },
        {
            "affiliations": [],
            "name": "Yung-Hsiang Lu"
        },
        {
            "affiliations": [],
            "name": "George K. Thiruvathukal"
        },
        {
            "affiliations": [],
            "name": "James C. Davis"
        },
        {
            "affiliations": [],
            "name": "NPM PyPi HuggingFace"
        }
    ],
    "id": "SP:868e5290ef7b91c6fa1fc429dbf8f7798a98b674",
    "references": [
        {
            "authors": [
                "E. Raymond"
            ],
            "title": "The cathedral and the bazaar",
            "venue": "Knowledge, Technology & Policy, vol. 12, no. 3, pp. 23\u201349, 1999.",
            "year": 1999
        },
        {
            "authors": [
                "R. Abdalkareem",
                "O. Nourry",
                "S. Wehaibi",
                "S. Mujahid",
                "E. Shihab"
            ],
            "title": "Why do developers use trivial packages? an empirical case study on npm",
            "venue": "European Software Engineering Conference/Foundations of Software Engineering (ESEC/FSE), 2017.",
            "year": 2017
        },
        {
            "authors": [
                "N.K. Gopalakrishna",
                "D. Anandayuvaraj",
                "A. Detti",
                "F.L. Bland",
                "S. Rahaman",
                "J.C. Davis"
            ],
            "title": "If security is required\u201d: Engineering and Security Practices for Machine Learning-based IoT Devices",
            "venue": "International Workshop on Software Engineering Research & Practices for the Internet of Things (SERP4IoT), 2022.",
            "year": 2022
        },
        {
            "authors": [
                "J. Garcia",
                "Y. Feng",
                "J. Shen",
                "S. Almanee",
                "Y. Xia",
                "a. Q.A. Chen"
            ],
            "title": "A comprehensive study of autonomous vehicle bugs",
            "venue": "International Conference on Software Engineering (ICSE), 2020.",
            "year": 2020
        },
        {
            "authors": [
                "D. Patterson",
                "J. Gonzalez",
                "Q. Le",
                "C. Liang",
                "L.-M. Munguia",
                "D. Rothchild",
                "D. So",
                "M. Texier",
                "J. Dean"
            ],
            "title": "Carbon Emissions and Large Neural Network Training",
            "venue": "2021. [Online]. Available: https://arxiv.org/abs/2104.10350",
            "year": 2021
        },
        {
            "authors": [
                "H.V. Pham",
                "S. Qian",
                "J. Wang",
                "T. Lutellier",
                "J. Rosenthal",
                "L. Tan",
                "Y. Yu",
                "N. Nagappan"
            ],
            "title": "Problems and Opportunities in Training Deep Learning Software Systems: An Analysis of Variance",
            "venue": "International Conference on Automated Software Engineering (ASE), 2020.",
            "year": 2020
        },
        {
            "authors": [
                "X. Han",
                "Z. Zhang",
                "N. Ding",
                "Y. Gu",
                "X. Liu",
                "Y. Huo",
                "J. Qiu",
                "Y. Yao",
                "A. Zhang",
                "L. Zhang",
                "W. Han",
                "M. Huang",
                "Q. Jin",
                "Y. Lan",
                "Y. Liu",
                "Z. Liu",
                "Z. Lu",
                "X. Qiu",
                "R. Song",
                "J. Tang",
                "J.-R. Wen",
                "J. Yuan",
                "W.X. Zhao",
                "J. Zhu"
            ],
            "title": "Pre-trained models: Past, present and future",
            "venue": "AI Open, vol. 2, pp. 225\u2013250, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "J. Gordon"
            ],
            "title": "Introducing TensorFlow Hub: A Library for Reusable Machine Learning Modules in TensorFlow",
            "venue": "https://blog.tensorflow.org/ 2018/03/introducing-tensorflow-hub-library.html, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "T. Wolf",
                "L. Debut",
                "V. Sanh",
                "J. Chaumond",
                "C. Delangue",
                "A. Moi",
                "P. Cistac",
                "T. Rault",
                "R. Louf",
                "M. Funtowicz",
                "J. Davison",
                "S. Shleifer",
                "P. von Platen",
                "C. Ma",
                "Y. Jernite",
                "J. Plu",
                "C. Xu",
                "T. Le Scao",
                "S. Gugger",
                "M. Drame",
                "Q. Lhoest",
                "A. Rush"
            ],
            "title": "Transformers: State-of-the-Art Natural Language Processing",
            "venue": "Conference on Empirical Methods in Natural Language Processing: System Demonstrations, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "M. Zimmermann",
                "C.-A. Staicu",
                "M. Pradel"
            ],
            "title": "Small World with High Risks: A Study of Security Threats in the npm Ecosystem",
            "venue": "USENIX Security Symposium, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "N. Zahan",
                "T. Zimmermann",
                "P. Godefroid",
                "B. Murphy",
                "C. Maddila",
                "L. Williams"
            ],
            "title": "What are Weak Links in the npm Supply Chain?",
            "venue": "in International Conference on Software Engineering (ICSE),",
            "year": 2022
        },
        {
            "authors": [
                "A. Zerouali",
                "T. Mens",
                "A. Decan",
                "C. De Roover"
            ],
            "title": "On the impact of security vulnerabilities in the npm and RubyGems dependency networks",
            "venue": "Empirical Software Engineering (EMSE), 2022.",
            "year": 2022
        },
        {
            "authors": [
                "A.S. Jadhav",
                "R.M. Sonar"
            ],
            "title": "Evaluating and selecting software packages: A review",
            "venue": "Information and Software Technology, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "A. Decan",
                "T. Mens",
                "P. Grosjean"
            ],
            "title": "An empirical comparison of dependency network evolution in seven software packaging ecosystems",
            "venue": "Empirical Software Engineering (EMSE), 2019.",
            "year": 2019
        },
        {
            "authors": [
                "C. Okafor",
                "T.R. Schorlemmer",
                "S. Torres-Arias",
                "J.C. Davis"
            ],
            "title": "Sok: Analysis of software supply chain security by establishing secure design properties",
            "venue": "ACM Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses (SCORED\u201922), 2022.",
            "year": 2022
        },
        {
            "authors": [
                "S. Schelter",
                "F. Biessmann",
                "T. Januschowski",
                "D. Salinas",
                "S. Seufert",
                "G. Szarvas"
            ],
            "title": "On Challenges in Machine Learning Model Management",
            "venue": "Bulletin of the IEEE Computer Society Technical Committee on Data Engineering, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "S. Amershi",
                "A. Begel",
                "C. Bird",
                "R. DeLine",
                "H. Gall"
            ],
            "title": "Software Engineering for Machine Learning: A Case Study",
            "venue": "International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP), 2019.",
            "year": 2019
        },
        {
            "authors": [
                "R.B. Johnson",
                "A.J. Onwuegbuzie"
            ],
            "title": "Mixed Methods Research: A Research Paradigm Whose Time Has Come",
            "venue": "Educational Researcher, 2004.",
            "year": 2004
        },
        {
            "authors": [
                "W. Jiang",
                "N. Synovic",
                "R. Sethi",
                "A. Indarapu",
                "M. Hyatt",
                "T.R. Schorlemmer",
                "G.K. Thiruvathukal",
                "J.C. Davis"
            ],
            "title": "An empirical study of artifacts and security risks in the pre-trained model supply chain",
            "venue": "ACM Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses, 2022, pp. 105\u2013114.",
            "year": 2022
        },
        {
            "authors": [
                "A. e. a. Monteil"
            ],
            "title": "Nine Best Practices for Research Software Registries and Repositories: A Concise Guide",
            "venue": "Dec. 2020, arXiv:2012.13117 [cs]. [Online]. Available: http://arxiv.org/abs/2012.13117",
            "year": 2020
        },
        {
            "authors": [
                "S. Oladele"
            ],
            "title": "Ml model registry: What it is, why it matters, how to implement it",
            "venue": "2022. [Online]. Available: https://neptune.ai/blog/ ml-model-registry",
            "year": 2022
        },
        {
            "authors": [
                "M.J. Smith",
                "C. Sala",
                "J.M. Kanter",
                "K. Veeramachaneni"
            ],
            "title": "The Machine Learning Bazaar: Harnessing the ML Ecosystem for Effective System Development",
            "venue": "Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data, Jun. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A.S. Jadhav",
                "R.M. Sonar"
            ],
            "title": "Framework for evaluation and selection of the software packages: A hybrid knowledge based system approach",
            "venue": "Journal of Systems and Software (JSS), 2011.",
            "year": 2011
        },
        {
            "authors": [
                "V. del Bianco",
                "L. Lavazza",
                "S. Morasca",
                "D. Taibi"
            ],
            "title": "A Survey on Open Source Software Trustworthiness",
            "venue": "IEEE Software, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "A. Zerouali",
                "T. Mens",
                "G. Robles",
                "J.M. Gonzalez-Barahona"
            ],
            "title": "On the Diversity of Software Package Popularity Metrics: An Empirical Study of npm",
            "venue": "International Conference on Software Analysis, Evolution and Reengineering (SANER), 2019.",
            "year": 2019
        },
        {
            "authors": [
                "D. Mitropoulos",
                "V. Karakoidas",
                "P. Louridas",
                "G. Gousios",
                "D. Spinellis"
            ],
            "title": "The bug catalog of the maven ecosystem",
            "venue": "Working Conference on Mining Software Repositories (MSR), 2014.",
            "year": 2014
        },
        {
            "authors": [
                "C. Soto-Valero",
                "A. Benelallam",
                "N. Harrand",
                "O. Barais",
                "B. Baudry"
            ],
            "title": "The Emergence of Software Diversity in Maven Central",
            "venue": "International Conference on Mining Software Repositories (MSR), 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J. Pineau",
                "P. Vincent-Lamarre",
                "K. Sinha",
                "V. Lariviere",
                "A. Beygelzimer"
            ],
            "title": "Improving Reproducibility in Machine Learning Research",
            "venue": "Journal of Machine Learning Research, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "P. Goswami",
                "S. Gupta",
                "Z. Li",
                "N. Meng",
                "D. Yao"
            ],
            "title": "Investigating The Reproducibility of NPM Packages",
            "venue": "International Conference on Software Maintenance and Evolution (ICSME), 2020.",
            "year": 2020
        },
        {
            "authors": [
                "D.-L. Vu",
                "F. Massacci",
                "I. Pashchenko",
                "H. Plate",
                "A. Sabetta"
            ],
            "title": "Last- PyMile: identifying the discrepancy between sources and packages",
            "venue": "European Software Eng. Conf. and Symp. on the Foundations of Software Eng. (ESEC/FSE), 2021.",
            "year": 2021
        },
        {
            "authors": [
                "M. Hutson"
            ],
            "title": "Artificial intelligence faces reproducibility crisis",
            "venue": "American Association for the Advancement of Science, vol. 359, no. 6377, pp. 725\u2013726, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "W. Jiang",
                "N. Synovic",
                "R. Sethi"
            ],
            "title": "An Empirical Study of Artifacts and Security Risks in the Pre-trained Model Supply Chain",
            "venue": "Los Angeles, p. 10, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "S.J. Pan",
                "Q. Yang"
            ],
            "title": "A Survey on Transfer Learning",
            "venue": "Transactions on Knowledge and Data Engineering, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "T. Liang",
                "J. Glossner",
                "L. Wang",
                "S. Shi",
                "X. Zhang"
            ],
            "title": "Pruning and quantization for deep neural network acceleration: A survey",
            "venue": "Neurocomputing, pp. 370\u2013403, 2021. [Online]. Available: https: //www.sciencedirect.com/science/article/pii/S0925231221010894",
            "year": 2021
        },
        {
            "authors": [
                "G. Hinton",
                "O. Vinyals",
                "J. Dean"
            ],
            "title": "Distilling the Knowledge in a Neural Network",
            "venue": "Mar. 2015, arXiv:1503.02531 [cs, stat]. [Online]. Available: http://arxiv.org/abs/1503.02531",
            "year": 2015
        },
        {
            "authors": [
                "P. Dube",
                "B. Bhattacharjee",
                "S. Huo",
                "P. Watson",
                "B. Belgodere"
            ],
            "title": "Automatic Labeling of Data for Transfer Learning",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2019, pp. 122\u2013129.",
            "year": 2019
        },
        {
            "authors": [
                "F. Zhuang",
                "Z. Qi",
                "K. Duan",
                "D. Xi",
                "Y. Zhu",
                "H. Zhu",
                "H. Xiong",
                "Q. He"
            ],
            "title": "A Comprehensive Survey on Transfer Learning",
            "venue": "Jun. 2020. [Online]. Available: http://arxiv.org/abs/1911.02685",
            "year": 2020
        },
        {
            "authors": [
                "S. Rahman",
                "E. River",
                "F. Khomh",
                "Y.G. Guhneuc",
                "B. Lehnert"
            ],
            "title": "Machine learning software engineering in practice: An industrial case study",
            "venue": "International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP), 2019.",
            "year": 2019
        },
        {
            "authors": [
                "Databricks"
            ],
            "title": "Mlflow model registry",
            "venue": "2022. [Online]. Available: https://databricks.com/product/mlflow-model-registry",
            "year": 2022
        },
        {
            "authors": [
                "NPM"
            ],
            "title": "npm",
            "venue": "2022. [Online]. Available: httnps://www.npmjs.com/",
            "year": 2022
        },
        {
            "authors": [
                "PyPI"
            ],
            "title": "Python package index",
            "venue": "2022. [Online]. Available: https: //pypi.org",
            "year": 2022
        },
        {
            "authors": [
                "TensorFlow team"
            ],
            "title": "Tensorflow hub",
            "venue": "2022. [Online]. Available: https://www.tensorflow.org/hub",
            "year": 2022
        },
        {
            "authors": [
                "Pytorch"
            ],
            "title": "Pytorch hub",
            "venue": "2021. [Online]. Available: https://pytorch.org/ hub/",
            "year": 2021
        },
        {
            "authors": [
                "ONNX"
            ],
            "title": "Onnx model zoo",
            "venue": "2022. [Online]. Available: https: //github.com/onnx/models",
            "year": 2022
        },
        {
            "authors": [
                "Y.K. Jing"
            ],
            "title": "Model Zoo - Deep learning code and pretrained models",
            "venue": "2021. [Online]. Available: https://modelzoo.co/",
            "year": 2021
        },
        {
            "authors": [
                "NVIDIA"
            ],
            "title": "NVIDIA NGC: AI Development Catalog",
            "venue": "2022. [Online]. Available: https://catalog.ngc.nvidia.com/",
            "year": 2022
        },
        {
            "authors": [
                "Computational Imaging",
                "Bioinformatics Lab"
            ],
            "title": "Modelhub",
            "venue": "2022. [Online]. Available: http://modelhub.ai/",
            "year": 2022
        },
        {
            "authors": [
                "M. Injadat",
                "A. Moubayed",
                "A.B. Nassif",
                "A. Shami"
            ],
            "title": "Machine learning towards intelligent systems: applications, challenges, and opportunities",
            "venue": "Artificial Intelligence Review, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "D. Marijan",
                "A. Gotlieb"
            ],
            "title": "Software Testing for Machine Learning",
            "venue": "AAAI Conference on Artificial Intelligence, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "K. Rasheed",
                "A. Qayyum",
                "M. Ghaly",
                "A. Al-Fuqaha",
                "A. Razi",
                "J. Qadir"
            ],
            "title": "Explainable, trustworthy, and ethical machine learning for healthcare: A survey",
            "venue": "Computers in Biology and Medicine, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "J.M. Wing"
            ],
            "title": "Trustworthy AI",
            "venue": "Communications of the ACM, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "M. Mora-Cantallops",
                "S. S\u00e1nchez-Alonso",
                "E. Garc\u0131\u0301a-Barriocanal",
                "M.- A. Sicilia"
            ],
            "title": "Traceability for Trustworthy AI: A Review of Models and Tools",
            "venue": "Big Data and Cognitive Computing, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "L. Floridi"
            ],
            "title": "Establishing the rules for building trustworthy AI",
            "venue": "Nature Machine Intelligence, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "S. Shams",
                "R. Platania",
                "K. Lee",
                "S.-J. Park"
            ],
            "title": "Evaluation of deep learning frameworks over different hpc architectures",
            "venue": "International Conference on Distributed Computing Systems (ICDCS), 2017.",
            "year": 2017
        },
        {
            "authors": [
                "L. Liu",
                "Y. Wu",
                "W. Wei",
                "W. Cao",
                "S. Sahin",
                "Q. Zhang"
            ],
            "title": "Benchmarking deep learning frameworks: Design considerations, metrics and beyond",
            "venue": "International Conference on Distributed Computing Systems, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "N. Akhtar",
                "A. Mian"
            ],
            "title": "Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey",
            "venue": "IEEE Access, vol. 6, pp. 14 410\u201314 430, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Y. Liu",
                "S. Ma",
                "Y. Aafer",
                "W.-C. Lee",
                "J. Zhai",
                "W. Wang",
                "X. Zhang"
            ],
            "title": "Trojaning Attack on Neural Networks",
            "venue": "Network and Distributed Systems Security (NDSS) Symposium, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "T. Gu",
                "B. Dolan-Gavitt",
                "S. Garg"
            ],
            "title": "BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain",
            "venue": "2019. [Online]. Available: http://arxiv.org/abs/1708.06733",
            "year": 2019
        },
        {
            "authors": [
                "K. Kurita",
                "P. Michel",
                "G. Neubig"
            ],
            "title": "Weight Poisoning Attacks on Pre-trained Models",
            "venue": "arXiv, Tech. Rep., 2020. [Online]. Available: http://arxiv.org/abs/2004.06660",
            "year": 2020
        },
        {
            "authors": [
                "M. Goldblum",
                "D. Tsipras",
                "C. Xie",
                "X. Chen",
                "A. Schwarzschild",
                "D. Song",
                "A. Madry",
                "B. Li",
                "T. Goldstein"
            ],
            "title": "Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Z. Wang",
                "C. Liu",
                "X. Cui"
            ],
            "title": "EvilModel: Hiding Malware Inside of Neural Network Models",
            "venue": "IEEE Symposium on Computers and Communications (ISCC), 2021.",
            "year": 2021
        },
        {
            "authors": [
                "\u00f6. Aslan",
                "R. Samet"
            ],
            "title": "A Comprehensive Review on Malware Detection Approaches",
            "venue": "IEEE Access, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "J. Ritchie",
                "L. Spencer"
            ],
            "title": "Qualitative data analysis for applied policy research",
            "venue": "Analyzing qualitative data. Routledge, 2002, pp. 187\u2013208.",
            "year": 2002
        },
        {
            "authors": [
                "A. Srivastava",
                "S. Thomson"
            ],
            "title": "Framework analysis: A qualitative methodology for applied policy research",
            "venue": "Journal of Administration and Governance (JOAAG), vol. 4, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "L.G. Michael",
                "J. Donohue",
                "J.C. Davis",
                "D. Lee",
                "F. Servant"
            ],
            "title": "Regexes are Hard: Decision-Making, Difficulties, and Risks in Programming Regular Expressions",
            "venue": "International Conference on Automated Software Engineering (ASE), 2019.",
            "year": 2019
        },
        {
            "authors": [
                "A. Cruz",
                "A. Duarte"
            ],
            "title": "npms",
            "venue": "2022. [Online]. Available: https: //npms.io/about",
            "year": 2022
        },
        {
            "authors": [
                "A. Abdellatif",
                "Y. Zeng",
                "M. Elshafei",
                "E. Shihab",
                "W. Shang"
            ],
            "title": "Simplifying the Search of npm Packages",
            "venue": "Information and Software Technology, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Hugging Face"
            ],
            "title": "Hugging face users",
            "venue": "2022. [Online]. Available: https://huggingface.co/users",
            "year": 2022
        },
        {
            "authors": [
                "J. Saldana"
            ],
            "title": "Fundamentals of qualitative research",
            "year": 2011
        },
        {
            "authors": [
                "G. Guest",
                "A. Bunce",
                "L. Johnson"
            ],
            "title": "How Many Interviews Are Enough?: An Experiment with Data Saturation and Variability",
            "venue": "Field Methods, 2006. [Online]. Available: http://journals.sagepub.com/doi/10. 1177/1525822X05279903",
            "year": 2006
        },
        {
            "authors": [
                "Microsoft"
            ],
            "title": "The STRIDE Threat Model",
            "venue": "2021. [Online]. Available: https://learn.microsoft.com/en-us/previous-versions/ commerce-server/ee823878(v=cs.20)",
            "year": 2021
        },
        {
            "authors": [
                "D. Boyd"
            ],
            "title": "How to approach threat modeling",
            "venue": "2021. [Online]. Available: https://aws.amazon.com/blogs/security/ how-to-approach-threat-modeling/",
            "year": 2021
        },
        {
            "authors": [
                "L. Conklin"
            ],
            "title": "Threat Modeling Process",
            "venue": "2023. [Online]. Available: https://owasp.org/www-community/Threat Modeling Process",
            "year": 2023
        },
        {
            "authors": [
                "A. Shostack"
            ],
            "title": "Experiences threat modeling at microsoft",
            "venue": "the Workshop on Modeling Security, vol. 413, 2008.",
            "year": 2008
        },
        {
            "authors": [
                "R.S. Pressman"
            ],
            "title": "Software engineering: a practitioner\u2019s approach",
            "venue": "Palgrave macmillan,",
            "year": 2005
        },
        {
            "authors": [
                "J. Fingas"
            ],
            "title": "AI trained on 4chan\u2019s most hateful board is just as toxic as you\u2019d expect",
            "venue": "2022. [Online]. Available: https://www.engadget.com/ ai-bot-4chan-hate-machine-162550734.html",
            "year": 2022
        },
        {
            "authors": [
                "N.P. Tschacher"
            ],
            "title": "Typosquatting in programming language package managers",
            "venue": "Ph.D. dissertation, Universit\u00e4t Hamburg, Fachbereich Informatik, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "J. Nivre",
                "M.-C. De Marneffe",
                "F. Ginter",
                "Y. Goldberg",
                "J. Hajic",
                "C.D. Manning",
                "R. McDonald",
                "S. Petrov",
                "S. Pyysalo",
                "N. Silveira"
            ],
            "title": "Universal dependencies v1: A multilingual treebank collection",
            "venue": "International Conference on Language Resources and Evaluation (LREC), 2016, pp. 1659\u20131666.",
            "year": 2016
        },
        {
            "authors": [
                "J. Devlin",
                "M.-W. Chang",
                "K. Lee",
                "K. Toutanova"
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv, 2018. [Online]. Available: https://arxiv.org/abs/1810.04805",
            "year": 2018
        },
        {
            "authors": [
                "J. Saltzer",
                "M. Schroeder"
            ],
            "title": "The protection of information in computer systems",
            "venue": "Proceedings of the IEEE, vol. 63, no. 9, pp. 1278\u20131308, 1975. [Online]. Available: http://ieeexplore.ieee.org/document/1451869/",
            "year": 1975
        },
        {
            "authors": [
                "W. Jiang",
                "N. Synovic",
                "P. Jajal",
                "T.R. Schorlemmer",
                "A. Tewari",
                "B. Pareek",
                "G.K. Thiruvathukal",
                "J.C. Davis"
            ],
            "title": "PTMTorrent: A Dataset for Mining Open-source Pre-trained Model Packages",
            "venue": "2023. [Online]. Available: https://doi.org/10.6084/m9.figshare.22009880",
            "year": 2023
        },
        {
            "authors": [
                "G. Gousios",
                "D. Spinellis"
            ],
            "title": "GHTorrent: Github\u2019s data from a firehose",
            "venue": "International Working Conference on Mining Software Repositories (MSR), 2012.",
            "year": 2012
        },
        {
            "authors": [
                "S. Baltes"
            ],
            "title": "SOTorrent: Reconstructing and Analyzing the Evolution of Stack Overflow Posts",
            "venue": "International Conference on Mining Software Repositories (MSR), 2018.",
            "year": 2018
        },
        {
            "authors": [
                "R. Abdalkareem",
                "O. Nourry",
                "S. Wehaibi",
                "S. Mujahid",
                "E. Shihab"
            ],
            "title": "Why do developers use trivial packages? an empirical case study on npm",
            "venue": "European Software Engineering Conference/Foundations of Software Engineering (ESEC/FSE), 2017.",
            "year": 2017
        },
        {
            "authors": [
                "C. Bogart",
                "C. K\u00e4stner",
                "J. Herbsleb"
            ],
            "title": "When It Breaks, It Breaks: How Ecosystem Developers Reason about the Stability of Dependencies",
            "venue": "International Conference on Automated Software Engineering Workshop (ASEW), 2015.",
            "year": 2015
        },
        {
            "authors": [
                "M. Anasuodei",
                "Ojekudo",
                "N. Akpofure"
            ],
            "title": "Software Reusability: Approaches and Challenges",
            "venue": "International Journal of Research and Innovation in Applied Science, vol. 06, no. 05, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Wang",
                "B. Chen",
                "K. Huang",
                "B. Shi",
                "C. Xu",
                "X. Peng",
                "Y. Wu",
                "Y. Liu"
            ],
            "title": "An Empirical Study of Usages, Updates and Risks of Third-Party Libraries in Java Projects",
            "venue": "International Conference on Software Maintenance and Evolution (ICSME), 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Mujahid",
                "R. Abdalkareem",
                "E. Shihab"
            ],
            "title": "What are the Characteristics of Highly-Selected Packages? A Case Study on the NPM Ecosystem",
            "venue": "SSRN Electronic Journal, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "R. Hamon",
                "H. Junklewitz",
                "J.I. Sanchez Martin"
            ],
            "title": "Robustness and explainability of artificial intelligence",
            "venue": "Publications Office of the European Union, vol. 207, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "GitHub"
            ],
            "title": "Adding a workflow status badge",
            "venue": "2022. [Online]. Available: https://docs.github. com/en/actions/monitoring-and-troubleshooting-workflows/ adding-a-workflow-status-badge",
            "year": 2022
        },
        {
            "authors": [
                "X. He",
                "K. Zhao",
                "X. Chu"
            ],
            "title": "AutoML: A survey of the state-of-the-art",
            "venue": "Knowledge-Based Systems, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Liu",
                "C. Chen",
                "R. Zhang",
                "T. Qin",
                "X. Ji",
                "H. Lin",
                "M. Yang"
            ],
            "title": "Enhancing the interoperability between deep learning frameworks by model conversion",
            "venue": "European Software Engineering Conference/Foundations of Software Engineering (ESEC/FSE), 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Cisco"
            ],
            "title": "ClamAV",
            "venue": "2022. [Online]. Available: https://www.clamav.net/",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "In this work, we present the first empirical investigation of PTM reuse. We interviewed 12 practitioners from the most popular PTM ecosystem, Hugging Face, to learn the practices and challenges of PTM reuse. From this data, we model the decision-making process for PTM reuse. Based on the identified practices, we describe useful attributes for model reuse, including provenance, reproducibility, and portability. Three challenges for PTM reuse are missing attributes, discrepancies between claimed and actual performance, and model risks. We substantiate these identified challenges with systematic measurements in the Hugging Face ecosystem. Our work informs future directions on optimizing deep learning ecosystems by automated measuring useful attributes and potential attacks, and envision future research on infrastructure and standardization for model registries.\nIndex Terms\u2014Software reuse, Empirical software engineering, Machine learning, Deep learning, Software supply chain, Engineering decision making, Cybersecurity, Trust\nI. INTRODUCTION\nPackage reuse has transformed software engineering in programming languages such as JavaScript and Python [1, 2], and is transforming deep learning model engineering [3]. Deep Neural Networks (DNNs) are widely used in modern software systems, such as image recognition in autonomous vehicles [4]. Engineering a DNN is challenging due to the capital and operating expenses of training models [5] and variation in deep learning libraries [6]. These problems can be addressed by reusing pre-trained DNN models (PTMs) to amortize DNN development costs across multiple projects and organizations [7]. PTMs are shared via Deep Learning (DL) model registries, which are modeled on traditional software package registries such as NPM and provide packages with model architectures, weights, licenses, and other metadata. DL model registries enable reuse-driven DNN engineering [8, 9] As Figure 1 shows, PTM reuse is now appreciable [7].\nReusability and trustworthiness problems in software package registries impact the relevant ecosystems [10\u201312]. Much is\nknown about the practices and challenges of reusing traditional software packages [13\u201315], but how this knowledge transfers to the reuse of PTM packages has not been investigated. Existing software engineering knowledge describes how large companies manage private models [16, 17]. However, we do not know how small-to-large engineering teams reuse models in DL model registries nor what challenges they experience.\nIn this work, we present the first empirical study of pretrained model reuse. We took a mixed-methods approach to identify diverse phenomena for future investigation [18]. We focused our study on the Hugging Face DL model registry, which is the largest PTM registry at present [19]. First, we interviewed 12 Hugging Face practitioners to understand the practices and challenges of PTM reuse. Second, we complemented this qualitative data with measurements of the Hugging Face registry. We built a dataflow model of the creation and distribution process for PTMs in Hugging Face and collected and analyzed a dataset of 63,182 PTM packages.\nOur findings indicate that PTM reuse workflows are similar to those for traditional software package reuse, but that engineers follow practices and experience challenges specific to deep learning. Based on our interview data, we: present the first decision-making workflow for PTM reuse, identify useful PTM attributes and three common challenges, and discuss the extent to which existing techniques meet these challenges (\u00a7V\u2014\u00a7VII). Our dataflow model of PTM distribution found several vectors for software supply chain attacks (\u00a7VIII). Our analysis shows unique properties of the PTM package ecosystem relative to traditional software package ecosystems,\nar X\niv :2\n30 3.\n02 55\n2v 1\n[ cs\n.S E\n] 5\nM ar\n2 02\n3\nnotably that the attributes and decision-making workflow are more complex (\u00a7X). We share the HFTorrent dataset of 63,182 PTM package histories for further analysis (\u00a7IX). We conclude by discussing four new research problems for further study (\u00a7X). Our contributions are:\n\u2022 We depict a decision-making workflow for PTM reuse, and identify three challenges for PTM reuse (\u00a7V\u2014\u00a7VII). \u2022 We measure the risks of collaboration in Hugging Face. We identify several potential software supply chain concerns facing PTM reusers (\u00a7VIII). \u2022 We publish the HFTorrent dataset of 63,182 PTM packages for future analysis (\u00a7IX). \u2022 We identified unique properties of PTM package reuse to guide future research on model audit, infrastructure, standardization, and attack detection (\u00a7X).\nSignificance: PTM reuse reduces the engineering costs of employing DNNs in industry. This paper describes the first investigation of PTM reuse from a software engineering perspective. We are the first to (1) capture the decisionmaking workflow and challenges for PTM reuse; (2) determine attributes of PTMs that facilitate reuse; and (3) measure risks of PTM reuse in the Hugging Face DL model registry. Our findings can help PTM maintainers and registries improve the quality of their offerings, and show opportunities for software engineering tools to support PTM reusers in this process."
        },
        {
            "heading": "II. BACKGROUND AND RELATED WORK",
            "text": "A. Software Package Reuse\nSoftware package registries store versioned packaged software, associated metadata, documentation, and configurations [20]. Similarly, deep learning (DL) model registries distribute PTMs with metadata, a model card (i.e., documentation), relevant configurations, and versions of pre-trained weights [21]. DL model registries are an important component of the DL ecosystem [22]. As shown in Figure 2, PTM packages may contain more component than traditional packages, including weights, datasets, and performance metrics.\nEvaluating and selecting software packages is a difficult, but essential, activity for package reuse [13]. Prior work shows that engineers may improve their software selection with insights into the decision-making process and an understanding of relevant factors [13, 23, 24]. Existing literature focuses on practices in traditional software package registries, such as NPM [25] and Maven [26, 27]. The extent to which reuse practices for traditional software will transfer to the reuse of PTM packages is unclear.\nReproducibility is another important aspect of software package reuse [28]. In traditional software packages, Goswami et al. found that 38% of explored NPM package versions are non-reproducible [29]. Similarly, Vu et al. highlighted existing discrepancies at different levels of granularity in PyPi [30]. Following the machine learning scientific research community [31], the software engineering community has just begun to study concerns in DL model registries [32]. We offer an early software engineering view on this topic.\nB. Pre-Trained Model Reuse\nPTM reuse is necessitated by the emergence of largescale models, and is enabled by learning and compression techniques, including transfer learning [33], quantization and pruning [34], knowledge distillation [35], and data labeling [36]. Through transfer learning, DNNs can be pre-trained on large datasets and fine-tuned to solve specialized tasks, leveraging a PTM\u2019s knowledge of one task to better teach it a similar task [33, 37]. Using quantization and pruning methods, PTMs can be optimized for latency- or energy-sensitive contexts, such as on edge devices, without compromising accuracy [34]. Via knowledge distillation, PTMs can be used to teach a smaller model, yielding good performance and reduced computational costs [35]. Engineers can also use PTMs to automatically label datasets [36].\nPractitioners from major technology companies report challenges in model management and model reliability [16, 17]. Schelter et al. summarized model validation challenges, including decisions on model retraining, metadata querying, and adversarial settings [16]. Rahman et al. highlighted that the behavior of ML models can be easily affected because of their data-driven nature [38]. To better reuse the PTMs, it is important to monitor the performance of deployed models, track changes in data characteristics, and to retrain and revalidate them frequently.\nOne way to address the management problems is to use a DL model registry, which is defined as: a collaborative model hub where teams can share DL models [21, 39]. The DL model registry concept imitates traditional software package registries such as NPM [40] and PyPi [41]. Through web searches, we identified several prominent DL model registries, including Hugging Face [42], TensorFlow Hub [43], PyTorch Hub [44], and ONNX Model Zoo [45]. Among all registries we examined [42\u201348], Hugging Face offers the largest and most diverse set of PTMs \u2014 it hosts over 60,000 PTMs, fifty times as many as the next largest DL model registry, as well as many types of models and datasets.\nC. Deep Learning Trustworthiness\nThe trustworthiness (e.g., reproducibility, explainability) of DL software grows in importance as DL techniques\nare deployed in sensitive contexts such as autonomous vehicles [49, 50]. For example, DL traceability is hampered because authors often omit training logs and documentation [38, 51]. Wing urges the DL community to explore a combination of approaches to achieve trustworthy DL [52]. To improve the trustworthiness of ML systems, prior work recommends considering aspects including provenance, reproducibility, and portability [38, 52\u201354], as defined in Table I. Some researchers have investigated the performance variances tied to DL frameworks [55, 56], which threatens DL reliability.\nAdversarial attacks and defences are also important to DL trustworthiness [57, 58]. Gu et al. proposed the general term BadNet for models that perform well on benchmark datasets but poorly on attacker-defined inputs [59]. Kurita et al. showed that it is possible to construct BadNets from weight poisoning attacks by injecting PTM with vulnerabilities that expose backdoors after fine-tuning [60]. Additionally, Goldblum et al. discussed that it is also possible to attack a model indirectly via malicious labels in its training dataset (data poisoning) [61]. Wang et al. described an EvilModel where a PTM has malware bytes hidden inside its neurons\u2019 parameters to be extracted and assembled into malware at run-time [62]. These attacks are not all covered by existing malware detection techniques and raise potential risks to DL model registries [63]."
        },
        {
            "heading": "III. RESEARCH QUESTIONS",
            "text": "Summarizing the literature: Much is known about software engineers\u2019 practices and challenges in reusing traditional software packages, but little about DL software packages (PTMs). Reuse and trust are unexamined in DL model registries.\nWe studied the reusability of PTM packages in DL model registries, examining qualitative and quantitative aspects. We focused on one DL model registry, Hugging Face, as it is by far the largest registry at present [19]. For PTM reuse in the Hugging Face ecosystem, we ask: RQ1 How do engineers select PTMs? RQ2 What PTM attributes facilitate PTM reuse? RQ3 What are the challenges of PTM reuse? RQ4 To what extent are the risks of reusing PTMs mitigated\nby Hugging Face defenses? RQ1-2 are focused on current software engineering practice, priming the participants to describe their challenges in RQ3. RQ4 complements this data with quantitative measurements."
        },
        {
            "heading": "IV. METHODOLOGY",
            "text": "To answer our research questions, we used a mixed approach that combined two perspectives [18]. We first explore qualitative insights by interviewing practitioners, then we substantiate our findings with systematic measurements in Hugging Face ecosystem. The relationship between our questions and methods is shown in Figure 3.\nA. Qualitative Study: Interviews with PTM Reusers\nOur interview study follows a four-step process modeled on the framework analysis methodology [64, 65]:\n(1) Data Familiarization and Framework Identification Our initial thematic framework is based on three themes from our literature review (\u00a7II): model selection, PTM attributes, and PTM trustworthiness. For model selection, the identified considerations were the PTM reuse issues and factors affecting the decision-making process [19, 66]. For attributes, we saw both traditional attributes (i.e., popularity, quality, maintenance) [67, 68], and DL-specific attributes, viz. provenance, reproducibility, and portability [52\u201354], shown in the first three columns in Table I. For trustworthiness, we considered the aspects assumed trustworthy plus possible discrepancies [19]. (2) Interview Design We designed a semi-structured interview protocol with questions that explore the three identified themes of PTM reuse and trust. We conducted three pilot interviews. We then revised our framework and interview protocol, adding some PTM attributes and factors and clarifying definitions.\nThe final interview protocol took 30\u201345 minutes. We compensated interview participants with a $20 gift card. The protocol is available in our artifact (\u00a7XII). (3) Recruitment We recruited users from the Hugging Face ecosystem [42], who presumably have experience in developing and reusing PTMs. According to the Hugging Face website [69] there are 18,348 Hugging Face users, 690 of whom have PRO accounts and 17,658 of whom have regular accounts. We sorted the lists of PRO and regular users by the number of models they have contributed to Hugging Face, and contacted the first 50 users of each type. We interviewed the 12 respondents described in Table II. This was a (response rate of 24%, of whom 9 had PRO accounts. Our participants contributed between 4 and 2500 models to Hugging Face. (4) Analysis We transcribed the interview recordings. Two researchers performed memoing [70], mapping the transcripts to the pre-defined themes. Each memo had a quote for one of the themes. Multiple researchers analyzed 4 transcripts and had high agreement on the memos extracted for each theme. Agreement was because the pre-defined themes had clear definitions, but we did not measure the agreement precisely. A single researcher memoed the remaining 8 transcripts.\nThen we organized the memos in a matrix by theme. Two researchers used the matrix to develop a thorough understanding of the larger picture. Then we answered each RQ by our understanding and reference to the matrix.\nAs part of our analysis, we measured saturation from our interview transcripts by analyzing the number of cumulative unique codes by participant [71]. Saturation was achieved after\n7 participants so we did not continue to recruit participants.\nB. Quantitative Study: Risk Mitigation Measurement\nOur qualitative findings identified a variety of challenges and risks in PTM reuse. We measured these risks and mitigations in the Hugging Face ecosystem with the STRIDE methodology for threat modeling and risk assessment [72].1 STRIDE was proposed by Microsoft as a security analysis technique and is widely used [72\u201375]. STRIDE focuses on trust assumptions related to data, making it suitable for PTMs.\nSTRIDE is a two-step process. First, the system under consideration is modeled using a dataflow diagram, and trust boundaries and the actors involved are identified. Second, each boundary is analyzed for the threats of the STRIDE acronym.\nFollowing the STRIDE methodology, we started by developing a dataflow diagram for PTMs on Hugging Face. Two researchers analyzed Hugging Face\u2019s public documentation. After internal iteration, we settled on one primary trust boundary: user control vs. Hugging Face internal control. We identified threats and six risk-mitigating features across this boundary. Owing to the nature of the available data source\n1STRIDE is a mnemonic for Spoofing identity, data Tampering, Repudiation, Information Disclosure, Denial of Service, and Elevation of privilege.\n(public documentation), we limited our analysis to a subset of the STRIDE threats: Spoofing, Tampering, Repudiation, and Elevation of Privilege. The completeness of our dataflow diagram was ensured by having two researchers review the documentation. These same researchers checked the soundness of the model by creating and using models on Hugging Face both as individual accounts and organization contributors."
        },
        {
            "heading": "V. RQ1: HOW DO ENGINEERS SELECT PTMS?",
            "text": "Finding 1: The participants share a similar decision-making process (Figure 4). Among the four PTM reuse scenarios in the research literature, our participants reported using only two: transfer learning and quantization techniques. When reusing, participants find PTMs from DL model registries easier to adopt than PTMs from GitHub projects.\nA. Reuse scenarios\nMost interview participants take PTMs from model registries and apply transfer learning techniques to the model. They either \u201cfine-tune an existing PTM\u201d by (optionally) extending architecture and training on a task-specific dataset, or \u201cbuild a new model on top of the pre-trained one\u201d. Commonly, they select PTMs from leading technology companies (e.g., Google, Meta) because \u201cthe datasets are carefully cleaned and [the models] are straightforward to fine-tune\u201d.\nThe other three reuse scenarios discussed in the research literature (\u00a7II-B) were far less common in our interviews. P5 described using quantized models. No participants described using PTMs for knowledge distillation or for data labeling.\nB. Decision-making process\nTo understand how engineers select PTMs, we asked participants to summarize their decision-making processes. We found similarities between participant responses. We followed Michael et al. [66] in adapting a general software engineering reuse process [76] to integrate our findings into a unified model (Figure 4). Our model contains 4 stages: (1) Reusability assessment, (2) Model selection, (3) Downstream evaluation, and (4) Model deployment. We discuss each in turn. Reusability Assessment Engineers begin the decision-making process with a reusability assessment. Before selecting a\nmodel, engineers must identify an ML task and determine if model reuse is appropriate. An ML task is composed of requirements including model input and output, latency, size, and licensing. Engineers must then decide if they should reuse a PTM or create a solution from scratch since \u201cPTMs do not work for every use case.\u201d Task parameters influence this decision. For example, three participants (P8, P9, P11) reuse PTMs because they \u201cdo not have enough computational resources\u201d. In a similar manner, participants (P2, P5, P8, P9, P11) note that DL model registries provide inference APIs to simplify reuse \u2014 PTMs are \u201ceasy to use and test\u201d.\nModel Selection Once engineers decide to reuse a model, they must select an existing architecture and an associated PTM. Engineers search for candidate architectures \u201cbuilt for the problem that [they are] trying to solve\u201d, browsing model registries or relevant papers. Most study participants prefer to search through model registries. For example, participants (P1, P4, P6) said they can \u201ceasily find a model\u201d in model registries due to classification at the domain (e.g., computer vision, natural language processing) and task (e.g., text generation, image classification) levels. P10 noted that standardizing PTM reuse increases model registries\u2019 popularity.\nOnce engineers select a candidate architecture, they must find a particular PTM to use. All study participants, including those who select architectures from papers, prefer PTMs from model registries. \u201cEase of use is very important\u201d to engineers that do not think it is worth \u201cspend[ing] much time on trying to understand the script[s] from the GitHub models\u201d. P8 noted models from Hugging Face are \u201cplug and play.\u201d Since multiple PTMs might implement the same architecture, engineers select from among candidates based on PTM attributes (\u00a7VII). For example, most participants use popularity as a factor to select a PTM because it indicates \u201c[community] trust in the model\u201d. As another example, multiple participants (P2, P3, P8, P11) choose NLP PTMs trained on appropriate datasets (e.g., models trained on datasets with the correct language).\nDownstream Evaluation After selecting a PTM, engineers conduct a downstream evaluation for their specific task. Engineers have the option of assessing more than one candidate PTM in this stage. They download \u201ca few models,\u201d \u201cfinetune them,\u201d \u201ctest them,\u201d then \u201ccompare them.\u201d When engineers select a candidate PTM, they first apply reuse techniques\nto fit the model to their specific application (cf. \u00a7II-B and \u00a7V-A). This procedure is not necessarily straightforward because some models \u201cdon\u2019t really work too well directly, even with their own datasets\u201d. Furthermore, 11 out of 12 of the participants observed a lack of adequate documentation or discrepancies within existing documentation.\nAfter applying reuse techniques, engineers evaluate the model to see if it is ready for model deployment. When evaluating the trade-off between performance and architecture, P1, P8 and P10 state that these two factors are \u201ctightly relevant to each other\u201d and should be considered in a \u201cfifty-fifty split\u201d. Some participants prioritize one of these factors over the other. For example, P3 and P6 compare multiple models to maximize task performance. On the other hand, P7 will not use a \u201cweird architecture\u201d even if its documented performance is higher. Model Deployment Finally, engineers deploy their models. Deployment may depend on model characteristics and deployment environments. All participants mention that certain characteristics such as PTM size, robustness, and documentation significantly impact the deployment of models to other environments (i.e., different hardware or software configurations than what is used in development). Participant (P8) describes that the rapid increase in model size makes it \u201cimpossible for most [low-resourced teams] to actually run these models on their systems.\u201d Participant (P5) states that most \u201cmodels are on PyTorch or TF\u201d and are therefore more difficult to deploy on mobile devices. Participant (P4) notes that documentation \u201cfor running a model on multiple GPUs\u201d is \u201cnot clear.\u201d"
        },
        {
            "heading": "VI. RQ2: WHAT PTM ATTRIBUTES FACILITATE PTM REUSE?",
            "text": "Finding 2: For Traditional attributes, Popularity is most helpful. Provenance, Reproducibility, and Portability are the three DL-specific attributes we should consider.\nHere we would like to learn about what sort of information is useful to engineers who reuse PTMs. We asked about two types of attributes here: traditional and DL-specific attributes.\nA. Traditional Attributes\nIn the interview, we asked about whether the traditional attributes as offered by traditional package registries, such as NPM [68], are helpful in DL model registries.\nAlmost all participants highlighted the importance of popularity in DL model registries. For example, P12 stated that a PTM with \u201clots of downloads\u201d means that \u201cit could be a good start point to try\u201d. P5 mentioned that \u201cpopularity usually goes side by side with maintenance and can indicate the quality\u201d.\nSome participants thought that quality and maintenance are also very useful. P2 said it is important to \u201cknow that it is constantly maintained and does not have many open issues\u201d, and pointed out that good maintenance means \u201cif the code is being updated or if you raise a bug, then someone will help you out\u201d. This is highly important because \u201cyou are relying on someone else\u201d and \u201cyou want to build that trust factor\u201d.\nHowever, some participants think that maintenance and quality are less useful. Recall from \u00a7V that most reuse scenarios are fine-tuning on new datasets or tasks. Provided that the model is fine-tunable, some participants mentioned that maintenance and quality metrics are \u201cless useful in downstream tasks\u201d. P12 suggested that maintenance may be less relevant because of the cost of making changes \u2014 \u201cit is really hard to modify the PTM...there were some issues during pretraining\u201d in a large language model, but the model has not been retrained \u201cbecause it is too large\u201d.\nB. DL-specific Attributes We added three DL-specific attributes: provenance, reproducibility, and portability. The participants provided the relevant factors for each attribute. Table I also indicates the factors for each attribute which were mentioned by multiple participants. Most participants mentioned that these three attributes can cover all the aspects they would consider. Provenance Some Hugging Face PTMs provide many provenance metrics, such as information about original paper, dataset, and architecture. However, these are not detailed enough to fully address model reuse challenges. P3 and P9 would like to see \u201cvisualization of model architecture\u201d and the \u201cexplanation of changes\u201d compared to the paper. P2, P4, P6, P8 mentioned the importance of more details of datasets because \u201cdifferent authors process data differently, so it cannot be easily compared\u201d. P10 and P12 highlighted the importance of training logs because they would like to see \u201chow the PTM was generated\u201d based on the training checkpoints and scripts. Reproducibility Reproducibility is the most problematic aspect of PTMs. The reproducibility issues mainly come from two aspects: (1) the configuration of training (2) the understanding of model. For the training configuration, the participants tend to care more about the hardware specification (e.g., types, memory), training configuration (e.g., training scripts, hyperparameters). As a result, they think environment image would be helpful to help them easily configure the settings and make the model more reproducible. In terms of understanding of the models, different kinds of demos (e.g., Notebook demo, Fine-tune demo) and better documentation would be helpful. Portability Different models have different deployment constraints, which makes understanding the portability of PTMs helpful for engineers. Similar to reproducibility, the portability factors include hardware specification and environment.\nMoreover, for deployment, latency and framework support aspects are essential. For example, the inference time and cost of computational resources could be different in different platforms, as mentioned by P2 and P6. This information can help engineers understand the portability of PTMs. P3 mentioned that \u201cautomate[d] creation of other formats of the model for different hardware\u201d could also be very helpful for the deployment. The quantized model is also \u201chelpful for continuous deployment and fine-tuning\u201d, as mentioned by P5. As a result, he also suggested the development of automated quantization. Some participants also mentioned the fine-tuning instructions, which help them determine whether a model can be used in specific tasks. For example, P12 would like to adapt language models to handle programming languages to improve their software testing, and the fine-tuning instructions can help him on deciding which model they should consider. P6 also mentioned that if the model registries can provide a \u201ccost estimation for different servers\u201d (e.g., different machine classes on a Cloud service provider). Moreover, P1 and P3 both said that \u201clicensing should be explicit to industry users\u201d."
        },
        {
            "heading": "VII. RQ3: WHAT ARE THE CHALLENGES OF PTM REUSE?",
            "text": "Finding 3: Three common challenges for PTM reuse are missing attributes, discrepancies between claims and actual performances, and model risks (e.g., privacy issues and unethical models) (Table III).\nMissing Attributes Missing attributes are identiifed as the most challenging problem. Almost every participant mentioned that there are missing details in the model registries, including datasets, licensing, model details, robustness, and interpretability. The attributes are missing for multiple reasons: Insufficient documentation is one reason. P5 and P7 observed \u201cmissing details of models\u201d in model registries. For example, P1 and P11 found the \u201cperformances of the published models are unclear\u201d in the model registries. P8 suggested that the reason for under-documentation in Hugging Face is that PTM authors can upload any model; Hugging Face does not enforce any form of documentation. Another reason is that the PTM authors occasionally do not measure the robustness and explainability of the models\u2014and model registries do not provide an automated approach to measure such attributes. Discrepancies Existing discrepancies are another key challenge mentioned by most participants. P7 pointed out that \u201csome of the models are over-promising\u201d. P2 indicated another reproducibility issue: the \u201cmodel names are not named correctly and sometimes the provided scripts are broken\u201d. These discrepancies could result in a waste of time and efforts. P5 pointed that another reason for this kind of problem is that training configuration details (i.e., hyper-parameters) are hard to find. P6 also mentioned that some authors only provide a script instead of providing the actual fine-tuned model and corresponding performances in Hugging Face due to the sensitivity of these results. P8 and P9 indicated that they sometimes follow the provided steps, including the models and\ndatasets\u2014even the hardware configurations\u2014and still could not reproduce the results claimed by the PTM authors. Model Risks There exist potential risks for PTMs in the model registries, including privacy and ethics aspects. We discussed in \u00a7II that prior studies have identified many risks of PTMs. The participants mentioned both internal and external problems in DL model registries. Internal risks often involve privacy problems of models and data. P2 mentioned that when using the models from model registries, \u201cthe model deployment and data transmission are not in their control\u201d. They could not directly deploy the model provided by Hugging Face because it is \u201cunreliable to send\u201d their sensitive dataset by Hugging Face inference APIs. P8 mentioned that if a model \u201cis trained with malicious intents. It could have a lot of consequences in the real world\u201d. This indicates the potential risks of a malicious model being uploaded to model registries.\nA PTM can be used for unethical or nefarious purposes. P8 gave an example of a chatbot created by training on a racist discussion forum. This model \u201ccreated a huge mayhem\u201d because it was publicly released [77]. P10 observed that it is hard to know \u201cwhat exactly generated the model because most training logs are missing\u201d \u2014 the internal biases are concerning and could potentially make the model a BadNet [59]."
        },
        {
            "heading": "VIII. RQ4: TO WHAT EXTENT ARE THE RISKS OF REUSING PTMS MITIGATED BY HUGGING FACE DEFENSES?",
            "text": "Finding 4: Although Hugging Face offers mitigations for many risks, these mitigations are incomplete or not widely adopted (Table IV). Model information can be missing or inaccurate due to the self-reporting nature of model metrics (Figure 7). These risks make the existence of malicious models possible in the model registries.\nOur interview data identified a range of challenges (\u00a7VII). Incomplete or inaccurate data about PTMs was most common. Engineers also expressed concern about malicious or unethical models, e.g., \u201cBadNets\u201d [59]. These findings led us to examine the Hugging Face defenses that mitigate these risks. We adapted the STRIDE methodology [72] to systematically measure the potential risks in Hugging Face, beginning with an analysis of the dataflow involved in collaborating on Hugging Face. The identified risks are shown in Table IV.\nA. Hugging Face PTM Dataflow Model\nBased on our analysis of Hugging Face\u2019s Hub and client libraries documentation, we made a dataflow diagram as\nshown in Figure 5, to represent the how models are created and shared. This allows us to visualize the dataflow from model contributors to users, which involves the developing, releasing, and accessing of PTMs on Hugging Face.\nThe common unit of reuse on Hugging Face is the repository, classified into datasets (input/output data for supervised or unsupervised learning) and models (PTM architecture, weights, and configuration, cf. Figure 2).\nAll Hugging Face repositories have automated and manual risk mitigations to limit the spread of malware or malicious models. These include organization verification, user permission models, commit hash checkout, and model cards (Figure 5). Additionally, some PTMs depend on other datasets or PTMs which can expose themselves to outside risks.\nB. Risk Analysis\nHugging Face implements six risk mitigations. These are organization verification, PTM documentation, GPG commit signing, a user permission model, automatic malware scanning (ClamAV), and utilizing a commit hash to checkout a model. While commit hash checkouts are not easily measured (performed by users on their own machines), we measured the use and scope of the others within the Hugging Face ecosystem. We detail our results on organization verification, PTM documentation, user permission model, and GPG commit signing. Following the risk analysis of traditional package registries [10], we also examine the potential impact of dependencies. The result for ClamAV was uninteresting as no (zero) PTM packages were flagged by ClamAV. Organization Verification Hugging Face allows an organization to increase trust by verifying its identity, demonstrating to Hugging Face that an organization controls an associated web domain. We counted the number of verified organizations via web scraping. Out of 6,243 organizations, only 199 (3.19%) were verified. With such a small percentage of verified organizations, users cannot determine the legitimacy of unverified organizations. The low adoption rate raises the risk of Spoofing: malicious users may masquerade as real organizations, similar to typosquatting [10, 78].\nThis lack of adoption is concerning because organizational reputation was cited as a factor under the Provenance attribute (Table I). The risk of such squatting attacks can be greater for PTM packages than for traditional ones, because new niches in the ecosystem accompany every new state-of-the-art model. A malicious actor could identify missing PTMs in the cross\nproduct of (architecture, dataset) and provide EvilModels [62] in that niche, pretending to be a legitimate organization.\nDependencies The dependencies of PTMs pose potential risks. Malicious models can be injected directly via data manipulation [61], or indirectly via weight poisoning [60]. Models released through Hugging Face may be vulnerable through their dependencies on model architectures, the associated weights for those architectures, and datasets. P5, P8, P10 stated that they fine-tune PTMs on a daily basis, implying that an attack could have a rapid impact.\nFigure 6 shows that the Universal Dependencies dataset [79] is the most popular dataset on Hugging Face, with 6,834 models depending upon it. The distribution of models that depend on a particular architecture is similar to Figure 6.\nWe found that the BERT [80] architecture is the most popular architecture on Hugging Face presently, with 10,247 models depending upon it. Hugging Face models have the potential to be trained off of multiple datasets as well. Our analysis of the existing Hugging Face models shows that many models depend on the works of others that can be maliciously tampered with. In tampering with these dependencies, BadNets [59] and unethical models [77] can be created, which could affect downstream PTMs.\nPTM Documentation Figure 7 shows the distribution of missing documentation in Hugging Face. The highest proportion of models that make performance claims in machine-parseable documentation (YAML) was from the token-classification task, with 17% of models meeting the criteria. We found that 26,192 models belong to various tasks (represented by other) where only 12 (0.05%) PTMs provide machine-parseable claims about the PTM. Due to the sparse usage of performance claim reporting, there can be potential risks of Repudiation: model performance can be obscured, misreported, or misleading.\nSome models report their performance in plain texts or tables, and are hard to identify by the users. It is also common for documentation to omit any performance claims or to refer the user to read an associated research paper for more information about performance, without assurance that this is the same model tested in the research paper. Some popular PTMs are poorly documented as well. The language model SpanBERT/spanbert-large-cased is the 9th most downloaded PTM on Hugging Face and receives 6.9 million monthly downloads, yet has no model card. Figure 7 supports that missing attributes is a real challenge existing in the\nHugging Face DL model registries. The lack of transparency reduces the trustworthiness of the models and increase the potential risks of malicious models.\nGPG Commit Signing Hugging Face provides a verification tag for commits that have been signed with a GPG key. By signing with a GPG key, users are providing verification that they have signed their commits, and not as someone masquerading as them. This feature allows users to accurately trace back the changes to the PTM packages. Using the HFTorrent dataset (\u00a7IX), we analyzed the usage of commit signing within Hugging Face model repositories. Out of 63,182 model repositories, we found 132 (0.21%) repositories within the dataset implemented signed commits. Additionally, only 2 verified organizations have at least one repository with signed commits. This indicates that potential attackers can be contributing malicious code, implementing a BadNet [59] or EvilModel [62] under a pseudonym, or manipulating the git commit history to hide malicious activity.\nThe limited usage of GPG commit signing exposes models hosted on Hugging Face to Spoofing, Tampering, and Repudiation risks. First, unsigned Hugging Face models are vulnerable to Spoofing since attackers could make commits under the alias of a legitimate maintainer. Second, these models face the risk of Tampering because attackers could contribute malicious code or edit commit history. Finally, unsigned models could also risk repudiation since a lack of verified commit history allows an individual to deny actions within a repository.\nUser Permission Model Hugging Face has a standard approach of users and organizations (Figure 5). One shortcoming of the permission model is that Hugging Face organizations violate the principle of least privilege [81]: an organization member with Write privilege can modify any PTM owned by the organization. Therefore, an attacker could contribute malicious code, thereby raising the risk of Elevation of Privileges."
        },
        {
            "heading": "IX. THE HFTORRENT DATASET",
            "text": "Our analysis in \u00a7VIII relied in part on measurements of the PTM packages in Hugging Face. To reduce the impact on the Hugging Face service during our measurements, we took a snapshot of 63,182 PTM packages in the Hugging Face registry. This snapshot, the HFTorrent Dataset, is included in the artifact accompanying this paper. An improved version of this dataset is now available [82]. We hope these data facilitate further research on PTM packages, similar to the impact of the GHTorrent [83] and SOTorrent [84] datasets. Creation process We initiated a copy of all PTM packages in the Hugging Face registry. Copies were taken between August 15th and 16th, with rate limiting to avoid abuse of the Hugging Face registry. 186 (0.3%) of the copies failed, caused, we believe, by concurrent changes in package names. Dataset contents The HFTorrent dataset contains the repository histories of 63,182 of the PTM packages available on Hugging Face as of August 2022. They are provided as bare git clones to reduce space, resulting in a compressed footprint of \u223c20 GB. Each PTM package can be reconstructed to its most recent version, including the model card, architecture, weights, and other elements provided by the maintainers (cf. Figure 2). Further information is available in our artifact."
        },
        {
            "heading": "X. DISCUSSION AND IMPLICATIONS",
            "text": "A. Integrating the findings\nOur qualitative and quantitative studies provide a deeper understanding of the practices and challenges for DL model registries. In \u00a7V we obtained a general reuse process (Figure 4) which is complemented by the specific details for Hugging Face (Figure 5). In \u00a7VI we studied how the theoretical attributes of reproducibility and provenance can affect the decision-making process of PTM reuse (Figure 4). These attributes are partially operationalized in Hugging Face by aspects measured in \u00a7VIII: organizations and verification, PTM documentation, GPG commit signing, and dependencies. For example, our results in \u00a7VIII imply that although PTM\nreusers value the provenance of models, this provenance is actually untrustworthy in Hugging Face due to the low adoption of verified organizations and commit signing. In \u00a7VIII we measured risks based on the identified challenges from \u00a7VII. For example, in \u00a7VII we qualitatively learned that documentation may be missing or have discrepancies. In \u00a7VIII we quantitatively measured that model documentation is missing or inadequate for 80% of PTMs.\nB. Comparison to traditional package registries\nOur qualitative analysis in \u00a7V\u2014\u00a7VIII sheds light on the differences between model registries and traditional registries, in terms of decision-making, attributes, and potential risks. Decision-making Our results indicate that the decision-making process of PTMs (Figure 4) is more complex than traditional packages [23, 85, 86], both in terms of the assessment and evaluation. Traditional software package reuse is integrated throughout the software development process [87] to improve productivity [85]. Our result shows that DL engineers behave similarly with PTMs. However, PTM reusers have to perform more complicated assessment and evaluation during decisionmaking process. PTMs are hard to evaluate and compare with others, as indicated by P3, P6, P8, P10. Moreover, Figure 4 involves three back edges (loops between selection and assessment), while the decision-making process for the traditional software reuse reportedly involves fewer iterations [13, 23]. Moreover, we can see in the selection stage of Figure 4, different factors are considered, including the dataset availability and cost. Traditional software reuser tend to consider more about the ease of use, and such detailed information are less needed by PTM reusers. Wang et al. suggest that developers should use the usage statistics to guide the evolution [88]. Similarly, PTM providers should consider the practices and challenges based on our qualitative data, and utilize it as a guidance to improve the PTMs in DL model registries. Attributes Our interview data indicated the significance of traditional attributes (i.e., popularity, quality, and maintenance) and the requirements for DL-specific attributes. For Traditional attributes, Popularity is most helpful for PTM reuse, while Quality and Maintenance are less useful compared to traditional packages (\u00a7VI). This differs from traditional software reusers, who consider quality and maintenance of packages as important as popularity when selecting and reusing the packages [25, 68, 89]. This difference comes from the expensive\ncost and data-driven nature in PTMs. It is hard for PTM users to directly obtain and employ an existing model. In contrast with taking a package from NPM or PyPI and directly reuse it in the codes, PTM reuse requires a deeper understanding and knowledge of how a model works. However, \u201cthere are not quite reliable methods to measure the explainability of PTMs yet\u201d, as indicated by P10. Therefore, to better reuse the PTMs, the engineers need more information from the model registries, which result in the requirements for DL-specific attributes. Potential risks The dependencies, maintainers, and reported issues can help analyze the security risks in software registries [10]. Prior work indicates that developers should manage the upstream dependencies and minimize the impact on downstream tasks [86]. Recently, Jiang et al. empirically studied the maintainers\u2019 reach of model registries [19]. However, the results here suggest that there are different risks within model registries, such as Spoofing, Tampering, Repudiation, and Elevation of privileges (Table IV). These risks can have varying degrees of impacts on the reusability of PTMs: The unaware discrepancies \u201cdo play a huge role\u201d (P8, P11, P12). They may not only \u201chinder developer progress\u201d, but also change the accuracy and robustness of downstream PTMs [61]. Moreover, our STRIDE analysis (\u00a7VIII) indicates multiple risks and the potential to introduce vulnerabilities [59, 60].\nC. Implications\nCompared to well-studied traditional package registries (e.g., NPM, PyPi), the use and study of DL model registries is still in its infancy. Our empirical study of Hugging Face model registry informs future directions on model audit, infrastructure, PTM standardization, and adversarial attack detection. Model audit Our results in \u00a7VI and \u00a7VII shows that one major challenge of PTM reuse is the missing attributes in model registries. The most important attribute is the performance of PTMs which would significantly affect the reusability of models. Though recently Hugging Face released their automated validation tool [90], it is still not able to satisfy the requirement of engineers. P8 stated that \u201cRobustness and Explainabiltiy are very key factors to consider when you are deploying ML models in the real world.\u201d which are important for the eventual goal of model transparency [91].\nThe proposed DL-specific attributes should also be measured and provided. Our study indicates the importance of these attributes (\u00a7VI) and identify the corresponding factors. We inform researchers on developing formulas and automated tools to automatically calculate the score of each attribute and integrate them into the model registries, similar to the pqm scores (i.e., popularity, quality, and maintenance) in [40].\nWe envision that future directions should consist of largescale measurements of PTMs or of encouraging model registries to change their PTM release requirements so that it would be easier for users to audit models by themselves. Infrastructure The infrastructure of model registries can be improved from different aspects. P2 mentioned that the badge mechanism would be helpful for communicating the missing\nattributes (e.g., reproducibility), similar to continuous integration badges provided by GitHub [92]. P6 mentioned a unified fine-tuning process could also assist engineers. Moreover, multiple participants highlighted the importance of tools for automatically creating quantized models or converting models into different formats. These tools could improve PTM portability and thus support model deployment.\nSome interview participants (P6, P9) mentioned that they select PTMs first based on their experience, and then based on evaluation metrics. P10 mentioned that he reuses PTMs to understand the \u201cthe generalizing behavior of fine-tuned models\u201d. This envisions development of PTM recommendation systems, which can sort the models by scores calculated by model performance in downstream tasks, or predicted by another ML model. A similar system can help to reduce the work for ML engineers and could be integrated as part of the AutoML pipeline for PTM reuse [93]. PTM Standardization Our results on \u00a7VI shows that, the model registries should include the training logs and corresponding checkpoints. This information can help reusers better understand the PTM and improve the provenance and reproducibility. As associated research opportunities, such artifacts can be costly to create and store, and it is unclear how engineers can best apply them.\nBeyond model provenance, another opportunity for standardization is in the model format itself. P5 said that \u201cmany PTMs are on PyTorch or TensorFlow\u201d but they would like to use ONNX format models which could make the deployment easier for them. However, due to the rapid appearance of new operators [94], ONNX could not support all of them, especially for state-of-the-art models [95]. Knowing the compatibility of PTMs in model registries with standardized formats such as ONNX would also engineers make better decisions and save their time. We suggest future work examining development challenges in the ONNX framework. Adversarial attack detection One of the major challenges for PTM reuse are adversarial attacks, as shown in \u00a7V. Attacks can be harmful to both the PTM reusers and the downstream application users. Although Hugging Face employs ClamAV [96] for malware scanning, this only detects traditional attacks, not new attacks such as BadNets [59]. As a result, we suggest future studies working on automated detection of toxic models and poisoned datasets. Integrating these detectors into model registries can largely improve their trustworthiness."
        },
        {
            "heading": "XI. THREATS TO VALIDITY",
            "text": "Internal Threats Our choice of research methods potentially threatens the validity of our investigation of PTM reuse practices and challenges (RQ1-3). Our results here are derived solely from interview data but not generalized via a survey instrument. As a mitigation, our measurements of the Hugging Face ecosystem (RQ4) substantiate many of the interview participants\u2019 concerns. In addition, we note that the participants of greatest interest are those who also make the greatest use of PTMs, i.e., presumably those with PRO accounts on Hugging\nFace. 9 of our 12 participants have PRO accounts, representing 1% of the PRO user population.\nAnother internal threat is the reliability of our framework analysis on the interview data. Our framework analysis might be biased by our understanding and transfer of concepts from traditional software to PTMs. This conceptual framework helps us tease out similarities and differences in the PTM context, although we recognize that our interviews might reflect our biases and perspectives and therefore bias participants to a certain way of thinking. To mitigate bias, we asked if the participant had anything to add in terms of each theme in our framework throughout the interview, and some did so. External Threats Our study examines only one DL model registry, Hugging Face. We note, however, that examining a single package registry, e.g., NPM, is fairly common in the literature. For PTMs, focusing on Hugging Face is sensible, since it is the only open DL model registry and has an order of magnitude more models than other registries. Our results may not generalize to other DL model registries, but given the relative importance and growing influence of Hugging Face it is unclear whether this is a concern.\nAnother external threat is the saturation of our interview study because of the interview study\u2019s sampling approach (one PTM registry) and size (12 participants). Within our sample, we saw a high degree of agreement. The saturation of our interview study was achieved after 7 participants (\u00a7IV-A)\nML researchers identified many uses of PTMs (\u00a7II-B), but our participants only employed a subset related to fine-tuning: transfer learning, quantization and pruning. This may pose a threat to external validity. Our random sampling approach may bias us towards high-probability use cases. One interpretation of our data is that fine-tuning is a popular approach in practice, which would motivate greater study of PTM finetuning relative to more theoretical applications."
        },
        {
            "heading": "XII. CONCLUSION",
            "text": "We conducted the first empirical study of PTM reuse in the Hugging Face DL model registries. Based on interviews with 12 practitioners, we defined the decision-making workflow for PTM reuse, and identified three challenges, including missing attributes, discrepancies, and model risks. To substantiate our qualitative data, we further investigated into useful attributes and potential risks in the Hugging Face ecosystem. We unveiled risky engineering practices in the Hugging Face ecosystem, particularly a lack of signatures in the PTM supply chain. Our empirical data motivates future research on PTM audit, automated PTM attribute measurements, improved infrastructure for PTM reuse, and PTM standardization.\nREPRODUCIBILITY AND RESEARCH ETHICS\nOur artifact is available at https://doi.org/10.5281/zenodo. 7555469. Within it, we provide the anonymized interview data used to answer RQ1-3, the HFTorrent dataset used to answer RQ4, and software for the measurements described in RQ4. Human subjects work was approved by institutional IRB."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "The authors thank the reviewers; and A. Grigorescu, D. Montes, A. Indarapu, and A. Tewari for their input. This work was supported by Google and Cisco and by NSF awards #2107230, #2229703, #2107020, and #2104319."
        }
    ],
    "title": "An Empirical Study of Pre-Trained Model Reuse in the Hugging Face Deep Learning Model Registry",
    "year": 2023
}