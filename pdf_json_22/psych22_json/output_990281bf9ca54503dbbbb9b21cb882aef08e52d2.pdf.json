{
    "abstractText": "Studies on facial affect recognition have been instrumental in gaining insights into cognition and emotion, and in influencing the design of computational models and perceptual interfaces. Such studies have been conducted for several decades.1-3 Historically, many studies have employed six facial expressions, namely happiness, sadness, anger, disgust, fear, and surprise, when testing human emotional perception.4,5 Other studies used more or fewer facial expressions in their studies.6,7 Of these, the expression of happiness was recognized more easily than were other emotions.8 In a meta-analysis of emotional expressions, McKasy9 reported that anger did not Print ISSN 1738-3684 / On-line ISSN 1976-3026 OPEN ACCESS",
    "authors": [
        {
            "affiliations": [],
            "name": "Sujin Bae"
        },
        {
            "affiliations": [],
            "name": "Eunhee Rhee"
        },
        {
            "affiliations": [],
            "name": "Beom Seuk Hwang"
        },
        {
            "affiliations": [],
            "name": "Young Don Son"
        },
        {
            "affiliations": [],
            "name": "Ji Hyun Bae"
        },
        {
            "affiliations": [],
            "name": "Doug Hyun Han"
        }
    ],
    "id": "SP:346e4b814b5aacc6857a01121d2f3dab2d431797",
    "references": [
        {
            "authors": [
                "SAH Alharbi",
                "K Button",
                "L Zhang",
                "KJ O\u2019Shea",
                "V Fasolt",
                "AJ Lee"
            ],
            "title": "Are affective factors related to individual differences in facial expression recognition",
            "venue": "R Soc Open Sci 2020;7:190699",
            "year": 1906
        },
        {
            "authors": [
                "SL Bistricky",
                "RE Ingram",
                "RA. Atchley"
            ],
            "title": "Facial affect processing and depression susceptibility: cognitive biases and cognitive neuroscience",
            "year": 2011
        },
        {
            "authors": [
                "AM Passarotti",
                "JA Sweeney",
                "MN. Pavuluri"
            ],
            "title": "Emotion processing influences working memory circuits in pediatric bipolar disorder and attention-deficit/hyperactivity disorder",
            "venue": "J Am Acad Child Adolesc Psychiatry",
            "year": 2010
        },
        {
            "authors": [
                "C. Darwin"
            ],
            "title": "The expression of the emotions in man and animals",
            "year": 1965
        },
        {
            "authors": [
                "Izard CE"
            ],
            "title": "Emotion theory and research: highlights, unanswered questions, and emerging issues",
            "venue": "Annu Rev Psychol",
            "year": 2009
        },
        {
            "authors": [
                "N Hedger",
                "WJ Adams",
                "M. Garner"
            ],
            "title": "Fearful faces have a sensory advantage in the competition for awareness",
            "venue": "J Exp Psychol Hum Percept Perform",
            "year": 2015
        },
        {
            "authors": [
                "J Lange",
                "MW Heerdink",
                "GA. van Kleef"
            ],
            "title": "Reading emotions, reading people: emotion perception and inferences drawn from perceived emotions",
            "venue": "Curr Opin Psychol",
            "year": 2022
        },
        {
            "authors": [
                "MG Calvo",
                "P Avero",
                "A Fern\u00e1ndez-Mart\u00edn",
                "G. Recio"
            ],
            "title": "Recognition thresholds for static and dynamic emotional faces. Emotion 2016;16:1186-1200",
            "year": 2016
        },
        {
            "authors": [
                "M. McKasy"
            ],
            "title": "A discrete emotion with discrete effects: effects of anger on depth of information processing",
            "venue": "Cogn Process 2020;21:555-573",
            "year": 2020
        },
        {
            "authors": [
                "R K\u00fchne",
                "C. Schemer"
            ],
            "title": "The emotional effects of news frames on information processing and opinion formation",
            "venue": "Commun Res",
            "year": 2015
        },
        {
            "authors": [
                "Nabi RL"
            ],
            "title": "A cognitive\u2010functional model for the effects of discrete negative emotions on information processing, attitude change, and recall",
            "venue": "Commun Theory 1999;9:292-320",
            "year": 1999
        },
        {
            "authors": [
                "Lazarus RS"
            ],
            "title": "Progress on a cognitive-motivational-relational theory of emotion",
            "venue": "Am Psychol",
            "year": 1991
        },
        {
            "authors": [
                "L Pessoa",
                "S Japee",
                "LG. Ungerleider"
            ],
            "title": "Visual awareness and the detection of fearful faces. Emotion 2005;5:243-247",
            "year": 2005
        },
        {
            "authors": [
                "LR Demenescu",
                "R Kortekaas",
                "JA den Boer",
                "A. Aleman"
            ],
            "title": "Impaired attribution of emotion to facial expressions in anxiety and major depression",
            "venue": "PLoS One 2010;5:e15058",
            "year": 2010
        },
        {
            "authors": [
                "EL Acland",
                "M Jambon",
                "T. Malti"
            ],
            "title": "Children\u2019s emotion recognition and aggression: a multi-cohort longitudinal study",
            "venue": "Aggress Behav",
            "year": 2021
        },
        {
            "authors": [
                "O. Dan"
            ],
            "title": "Recognition of emotional facial expressions in adolescents with attention deficit/hyperactivity disorder",
            "venue": "J Adolesc",
            "year": 2020
        },
        {
            "authors": [
                "J L\u00f6yt\u00f6m\u00e4ki",
                "P Ohtonen",
                "ML Laakso",
                "K. Huttunen"
            ],
            "title": "The role of linguistic and cognitive factors in emotion recognition difficulties in children with ASD, ADHD or DLD",
            "venue": "Int J Lang Commun Disord 2020;55:231242",
            "year": 2020
        },
        {
            "authors": [
                "C Mancini",
                "L Falciati",
                "C Maioli",
                "G. Mirabella"
            ],
            "title": "Happy facial expressions impair inhibitory control with respect to fearful facial expressions but only when task-relevant",
            "venue": "Emotion",
            "year": 2022
        },
        {
            "authors": [
                "J Xu",
                "L Hao",
                "M Chen",
                "Y He",
                "M Jiang",
                "T Tian"
            ],
            "title": "Developmental sex differences in negative emotion decision-making dynamics: computational evidence and amygdala-prefrontal pathways",
            "venue": "Cereb Cortex",
            "year": 2021
        },
        {
            "authors": [
                "M Buades-Rotger",
                "AK Solbakk",
                "M Liebrand",
                "T Endestad",
                "I Funderud",
                "P Siegwardt"
            ],
            "title": "Patients with ventromedial prefrontal lesions show an implicit approach bias to angry faces",
            "venue": "J Cogn Neurosci",
            "year": 2021
        },
        {
            "authors": [
                "O Pascalis",
                "X de Martin de Vivi\u00e9s",
                "G Anzures",
                "PC Quinn",
                "AM Slater",
                "JW Tanaka"
            ],
            "title": "Development of face processing",
            "venue": "Wiley Interdiscip Rev Cogn Sci 2011;2:666-675",
            "year": 2011
        },
        {
            "authors": [
                "J. Cohen"
            ],
            "title": "A power primer",
            "year": 1992
        },
        {
            "authors": [
                "DV Sheehan",
                "Y Lecrubier",
                "KH Sheehan",
                "P Amorim",
                "J Janavs",
                "E Weiller"
            ],
            "title": "The mini-international neuropsychiatric interview (M.I.N.I.): the development and validation of a structured diagnostic psychiatric interview for DSM-IV and ICD-10",
            "venue": "J Clin Psychiatry",
            "year": 1998
        },
        {
            "authors": [
                "SW Yoo",
                "YS Kim",
                "JS Noh",
                "KS Oh",
                "CH Kim",
                "K NamKoong"
            ],
            "title": "Validity of Korean version of the mini-international neuropsychiatric interview. Anxiety Mood 2006;2:50-55",
            "year": 2006
        },
        {
            "authors": [
                "X Wang",
                "Y Wang",
                "T. Xin"
            ],
            "title": "The psychometric properties of the Chinese version of the Beck Depression Inventory-II with middle school",
            "year": 2020
        },
        {
            "authors": [
                "EH Lee",
                "SJ Lee",
                "ST Hwang",
                "SH Hong",
                "JH. Kim"
            ],
            "title": "Reliability and validity of the Beck Depression Inventory-II among Korean adolescents. Psychiatry Investig 2017;14:30-36",
            "year": 2017
        },
        {
            "authors": [
                "HK Lee",
                "EH Lee",
                "ST Hwang",
                "SH Hong",
                "JH. Kim"
            ],
            "title": "Psychometric properties of the Beck Anxiety Inventory in the community-dwelling sample of Korean adults",
            "venue": "Kor J Clin Psychol",
            "year": 2016
        },
        {
            "authors": [
                "JH Patton",
                "MS Stanford",
                "ES. Barratt"
            ],
            "title": "Factor structure of the Barratt impulsiveness scale",
            "venue": "J Clin Psychol",
            "year": 1995
        },
        {
            "authors": [
                "SR Lee",
                "WH Lee",
                "JS Park",
                "SM Kim",
                "JW Kim",
                "JH. Shim"
            ],
            "title": "The study on reliability and validity of Korean version of the Barratt impulsiveness scale11-revised in nonclinical adult subjects",
            "venue": "J Korean Neuropsychiatr Assoc 2012;51:378-386",
            "year": 2012
        },
        {
            "authors": [
                "RC Kessler",
                "L Adler",
                "M Ames",
                "O Demler",
                "S Faraone",
                "E Hiripi"
            ],
            "title": "The World Health Organization adult ADHD self-report scale (ASRS): a short screening scale for use in the general population",
            "venue": "Psychol Med",
            "year": 2005
        },
        {
            "authors": [
                "JH Kim",
                "EH Lee",
                "YS. Joung"
            ],
            "title": "The WHO adult ADHD self-report scale: reliability and validity of the Korean version",
            "venue": "Psychiatry Investig",
            "year": 2013
        },
        {
            "authors": [
                "AH Buss",
                "M. Perry"
            ],
            "title": "The aggression questionnaire",
            "venue": "J Pers Soc Psychol",
            "year": 1992
        },
        {
            "authors": [
                "E Kim",
                "HW Yim",
                "H Jeong",
                "SJ Jo",
                "HK Lee",
                "HJ Son"
            ],
            "title": "The association between aggression and risk of Internet gaming disorder in Korean adolescents: the mediation effect of father-adolescent communication style. Epidemiol Health 2018;40:e2018039",
            "year": 2018
        },
        {
            "authors": [
                "SB Lee",
                "SJ Koo",
                "YY Song",
                "MK Lee",
                "YJ Jeong",
                "C Kwon"
            ],
            "title": "Theory of mind as a mediator of reasoning and facial emotion recognition: findings from 200 healthy people. Psychiatry Investig 2014;11:105-111",
            "year": 2014
        },
        {
            "authors": [
                "KU Lee",
                "J Kim",
                "B Yeon",
                "SH Kim",
                "JH. Chae"
            ],
            "title": "Development and standardization of extended ChaeLee Korean facial expressions of emotions. Psychiatry Investig 2013;10:155-163",
            "year": 2013
        },
        {
            "authors": [
                "G Mei",
                "Y Li",
                "S Chen",
                "M Cen",
                "M. Bao"
            ],
            "title": "Lower recognition thresholds for sad facial expressions in subthreshold depression: a longitudinal study",
            "venue": "Psychiatry Res",
            "year": 2020
        },
        {
            "authors": [
                "Marsh PJ",
                "Williams LM"
            ],
            "title": "ADHD and schizophrenia phenomenology: visual scanpaths to emotional faces as a potential psychophysiological marker",
            "venue": "Neurosci Biobehav Rev 2006;30:651-665",
            "year": 2006
        },
        {
            "authors": [
                "K Pelc",
                "C Kornreich",
                "ML Foisy",
                "B. Dan"
            ],
            "title": "Recognition of emotional facial expressions in attention-deficit hyperactivity disorder",
            "venue": "Pediatr Neurol 2006;35:93-97",
            "year": 2006
        },
        {
            "authors": [
                "P Liu",
                "S Han",
                "Z Meng",
                "Y. Tong"
            ],
            "title": "Facial expression recognition via a boosted deep belief network",
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition;",
            "year": 2014
        },
        {
            "authors": [
                "P. Vuilleumier"
            ],
            "title": "How brains beware: neural mechanisms of emotional attention",
            "venue": "Trends Cogn Sci 2005;9:585-594",
            "year": 2022
        },
        {
            "authors": [
                "Stein T",
                "Verosky SC"
            ],
            "title": "No effect of value learning on awareness and attention for faces: evidence from continuous flash suppression and the attentional blink",
            "venue": "J Exp Psychol Hum Percept Perform",
            "year": 2021
        },
        {
            "authors": [
                "Johnson MH"
            ],
            "title": "Face processing as a brain adaptation at multiple timescales",
            "venue": "Q J Exp Psychol",
            "year": 2011
        },
        {
            "authors": [
                "C Bertini",
                "E. L\u00e0davas"
            ],
            "title": "Fear-related signals are prioritised in visual, somatosensory and spatial systems",
            "year": 2021
        },
        {
            "authors": [
                "K Borhani",
                "V. Nejati"
            ],
            "title": "Emotional face recognition in individuals withattention-deficit/hyperactivity disorder: a review article",
            "venue": "Dev Neuropsychol",
            "year": 2018
        },
        {
            "authors": [
                "J Sinzig",
                "D Morsch",
                "G. Lehmkuhl"
            ],
            "title": "Do hyperactivity, impulsivity and inattention have an impact on the ability of facial affect recognition in children with autism and ADHD",
            "venue": "Eur Child Adolesc Psychiatry",
            "year": 2008
        },
        {
            "authors": [
                "J. van Stralen"
            ],
            "title": "Emotional dysregulation in children with attention-deficit/hyperactivity disorder",
            "venue": "Atten Defic Hyperact Disord",
            "year": 2016
        },
        {
            "authors": [
                "J Bisch",
                "B Kreifelts",
                "J Bretscher",
                "D Wildgruber",
                "A Fallgatter",
                "T. Ethofer"
            ],
            "title": "Emotion perception in adult attention-deficit hyperactivity disorder",
            "venue": "J Neural Transm (Vienna)",
            "year": 2016
        },
        {
            "authors": [
                "A Petroni",
                "A Canales-Johnson",
                "H Urquina",
                "R Guex",
                "E Hurtado",
                "A Blenkmann"
            ],
            "title": "The cortical processing of facial emotional expression is associated with social cognition skills and executive functioning: a preliminary study",
            "year": 2011
        },
        {
            "authors": [
                "T Shioiri",
                "T Someya",
                "D Helmeste",
                "SW. Tang"
            ],
            "title": "Misinterpretation of facial expression: a cross-cultural study",
            "venue": "Psychiatry Clin Neurosci",
            "year": 1999
        }
    ],
    "sections": [
        {
            "text": "Copyright \u00a9 2022 Korean Neuropsychiatric Association 435"
        },
        {
            "heading": "INTRODUCTION",
            "text": "Studies on facial affect recognition have been instrumental in gaining insights into cognition and emotion, and in influencing the design of computational models and perceptual interfaces. Such studies have been conducted for several decades.1-3\nHistorically, many studies have employed six facial expressions, namely happiness, sadness, anger, disgust, fear, and surprise, when testing human emotional perception.4,5 Other studies used more or fewer facial expressions in their studies.6,7 Of these, the expression of happiness was recognized more easily than were other emotions.8 In a meta-analysis of emotional expressions, McKasy9 reported that anger did not\nPrint ISSN 1738-3684 / On-line ISSN 1976-3026 OPEN ACCESS\nhave a significant effect on depth of information processing when compared to other emotions, including neutrality, sadness, happiness, and fear. Anger is defined as a strong unpleasant emotion due to interfering obstacles or disparaging offenses against oneself or another.10,11 Compared to sadness, anger has a more obvious target of blame and accountability.12 A fearful facial expression was the most salient for humans to visualize, compared to other facial expressions.13 Based on the results of these studies, we hypothesized that the differentiation between Anger, Fear, and Sad facial expressions could provide insight into human cognition and emotions.\nA facial affect recognition deficit is thought to be due to the individual emotional statuses of depression, anxiety, and aggression,1,14,15 as well as to cognitive factors of attention and impulsivity. Demenescu et al.14 reported that adults with anxiety disorders or major depressive disorders found it difficult to recognize facial expressions. Alharbi et al.1 suggested that affective factors, including depression and anxiety, could predict individual differences in emotional recognition. In a multicohort longitudinal study, Acland et al.15 reported that nega-"
        },
        {
            "heading": "ORIGINAL ARTICLE",
            "text": ""
        },
        {
            "heading": "Correlations Between Psychological Status and",
            "text": ""
        },
        {
            "heading": "Perception of Facial Expression",
            "text": ""
        },
        {
            "heading": "Sujin Bae1, Eunhee Rhee2, Beom Seuk Hwang2, Young Don Son3, Ji Hyun Bae4, and Doug Hyun Han1 ",
            "text": "1Department of Psychiatry, Chung-Ang University Hospital, Seoul, Republic of Korea 2Department of Applied Statistics, Chung-Ang University, Seoul, Republic of Korea 3Department of Health Sciences & Technology, Gachon University, Incheon, Republic of Korea 4Department of Biomedical Engineering, Gachon University, Incheon, Republic of Korea\nObjective Facial affect recognition is associated with neuropsychological status and psychiatric diseases. We hypothesized that facial affect recognition is associated with psychological status and perception of other affects. Methods A total of 80 images depicting facial affect, including 20 Neutral, 20 Angry, 20 Fear, and 20 Sad, were screened for use in our research. A total of 100 healthy individuals were asked to rate these images using a 10-point Likert scale and complete psychological scales assessing the emotional statuses and cognitive functions. Results The participants\u2019 emotional state of aggression, attention, and impulsivity may have been associated with their interpretation of the Angry facial expressions. The participants often rated the Angry facial expressions as Fear. The participants rated Fear images as Angry or Sad. In response to a Sad facial expression, the participants reported psychological statuses of attention and impulsivity which were associated with the facial expression rating. The participants rated the Sad expression as Angry or Fear. Conclusion The psychological statuses of the participants were significantly correlated with their interpretation of facial affects. In particular, a psychological state of attention was often correlated with incorrect affect ratings. Attention and impulsivity could affect the rating of the sad facial expressions. Psychiatry Investig 2022;19(6):435-442\nKeywords Facial expression; Angry; Fear; Neutral; Psychological status.\nReceived: January 19, 2022 Revised: March 29, 2022 Accepted: April 19, 2022  Correspondence: Doug Hyun Han, MD, PhD Department of Psychiatry, Chung-Ang University Hospital, 102 Heukseok-ro, Dongjack-gu, Seoul 06973, Republic of Korea Tel: +82-2-6299-3132, Fax: +82-2-813-5387, E-mail: hduk70@gmail.com cc This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (https://creativecommons.org/licenses/bync/4.0) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.\nhttps://doi.org/10.30773/pi.2022.0025\n436 Psychiatry Investig 2022;19(6):435-442\ntive emotion recognition was associated with higher concurrent aggression.\nIn addition to emotional factors, difficulties in facial affect recognition are associated with cognitive impairments, including attention and impulsivity.16-20 In a review of facial emotional recognition in adolescents with attention deficit hyperactivity disorder (ADHD), Dan16 reported that adolescents with ADHD found the recognition of facial expressions difficult due to differences in their brain activity. L\u00f6yt\u00f6m\u00e4ki et al.17 stated that a delay in emotional recognition in patients with ADHD is associated with the linguistic and cognitive skills required for selective intervention procedures. Faces can provide multidimensional visual stimuli and a broad range of information, including identity, gender, age, race, mood, and intentions.21 Several studies have suggested that impulsivity could affect the response to emotional face stimuli, including happy, angry, and sad.15 However, few studies have reported a correlation between cognitive function and emotional perception in healthy individuals. This makes our study one of the first to attempt this.\nWe hypothesized that facial affect recognition would be affected by participants\u2019 emotional status, including depression, anxiety, and aggression, as well as cognitive functions, including attention and impulsivity. Additionally, one facial affect can be perceived as another facial affect influenced by individual emotional and cognitive factors."
        },
        {
            "heading": "METHODS",
            "text": ""
        },
        {
            "heading": "Participants and study procedure",
            "text": "Effect size was determined using Cohen\u2019s d.22 The effect size\nand power values were 0.20 and 0.95, respectively. We planned to recruit 100 participants for the analyses of this study using flyers and the web bulletin board service of Chung-Ang University. This study was approved by the Institutional Review Board of Chung-Ang University (IRB number: 1041078- 202008-HRBM-231-01). All the participants provided written informed consent.\nA total of 103 participants were recruited based on the following criteria: 1) the participants must be at least 18 years of age and 2) must not have a history of psychiatric diseases such as schizophrenia, other psychotic disorders, intellectual disability, mental disorders, or neurological disease. Through screening using the Mini International Neuropsychiatric Interview (MINI), and after meeting with a psychiatric doctor (DHH), three participants were excluded from the study. Two participants were excluded because of a major depressive disorder. The other participant was excluded because of substance dependence. Therefore, we used data from a total of 100 participants in the analyses (Figure 1).\nAfter screening for psychiatric comorbidities and completing surveys for psychological status, all participants were asked to rate facial affects in response to images depicting facial expressions, including Neutral, Angry, Fear, and Sad.\nPsychiatry comorbidity screening and psychological status assessment\nPsychiatric comorbidities were screened using the Korean version of the MINI. The MINI is a semi-structured diagnostic interview that is generally used to assess the presence of co-occurring mental disorders.23,24\nBefore rating the facial expression images, all participants\nwww.psychiatryinvestigation.org 437\nwere asked to complete psychological surveys in order to assess the emotional status of depression, anxiety, and aggression, as well as cognitive functions of attention and impulsivity (Figure 1).\nDepression was assessed using the Beck Depression Inventory II (BDI-II).25 The BDI-II is a 21-item self-report inventory used to assess the severity of depression. Each item is rated on a 4-point Likert-type scale ranging from 0 to 3. The total score ranged from 0 to 63. The Korean version of the BDI-II has good internal consistency (Cronbach\u2019s alpha=0.89).26 Anxiety symptoms were assessed using the Beck Anxiety Inventory (BAI). The BAI is a 21-item self-report inventory used to assess anxiety severity. Each item is rated on a 4-point Likerttype scale ranging from 0 to 3, with a total score ranging from 0 to 63. The Korean version of the BAI has good internal consistency (Cronbach\u2019s alpha=0.95).27 Impulsivity was assessed using the Barratt Impulsiveness Scale\u201311 (BIS-11), which consists of 30 items rated on a 4-point scale ranging from 1 to 4.28 The Korean version of the BIS-11 has good internal consistency (Cronbach\u2019s alpha=0.78).29\nAttention problems were assessed using the Korean version of the Adult Attention Deficit/Hyperactivity Disorder SelfReport Scale (K-ASRS). The total K-ASRS score ranges from 0 (best) to 72 (worst; 34). The questions in the K-ASRS were divided into two sections: A (six questions) and B (12 questions). Four or more positive answers in Section A can indicate K-ASRS.30,31 Aggression was measured using the Buss\u2013 Perry Aggression Questionnaire (AQ).32 The AQ consisted of 29 items assessing overall aggression and four sub-components assessing aggression, including physical aggression, verbal aggression, anger, and hostility. The AQ-Korean version also has good internal consistency (Cronbach\u2019s alpha=0.87).33\nRating facial images of emotion Eighty images depicting facial expressions were screened in our study. These included 20 Neutral (N), 20 Angry (A), 20 Fear (F), and 20 Sad (S) facial images. All facial affect images were randomly selected from the following four categories: neutral, angry, fear, and sad out of 176 Korean facial expressions34 and 259 extended ChaeLee Korean facial expressions.35 Using a 10-point Likert scale, 100 healthy individuals were asked to identify three emotions in each image depicting a facial expression. For example, participants identified anger, fear, and sadness in response to an \u201cangry\u201d facial affect image.\nThe presentation of the facial expression images consisted of 20 blocks. Each block contained four facial expressions (N, A, F, and S) with various distributions. One of the 20 facial expression images in each category was distributed into 20 blocks. The presentation order of the facial expression images in each category was distributed as follows: N-A-F-S, N-A-S-"
        },
        {
            "heading": "F, N-F-A-S, N-S-A-F, N-F-S-A, N-S-F-A, A-F-S-N, A-S-F-N,",
            "text": "A-N-S-F, A-N-F-S, A-S-N-F, A-F-N-S, F-N-A-S, F-N-S-A, FA-N-S, F-A-S-N, F-S-A-N, and S-A-F-N, A-F-S-N, S-F-A-N. Each image (5\u00d77 cm2) was shown to the participant for three seconds. The participants rated the images for three seconds. A total of 480 seconds was required to rate all 80 images in the four categories.\nIf participants could not respond within three seconds they were timed out, these trials were discarded from the analyses. Participants underwent response training for 10 minutes to reduce the percentage of discarded trials. Of the 8,000 trials (80 trials in 100 participants), 38 (0.48%) were discarded as timed out in the analyses."
        },
        {
            "heading": "Data control and statistics",
            "text": "Linear mixed-effects models were used to estimate the effect of participants\u2019 psychological status on the rating scores and the 95% confidence interval after adjusting for the effect of participants\u2019 sex on the results. Subsequently, the affect of each facial expression image was compared with that of a neutral face. This served as the reference image. In addition, the rating scores for each image were fitted using the estimated coefficients of the linear mixed-effects models. All tests were two-sided and differences were considered statistically significant at a significance level of 0.05. All statistical analyses were performed using the lmer function of the lem4 package in the R software (version 3.6.3; R Foundation for Statistical Computing, Vienna, Austria)."
        },
        {
            "heading": "RESULTS",
            "text": "Demographic and psychological characteristics of the participants\nThe clinical characteristics and psychological state of the participants are presented in Table 1. The sex ratios of the participants were 78.0% male and 22.0% female. The mean age of participants was 22.9\u00b12.6 years and educational duration was 14.5\u00b11.7 years.\nEffects of psychological status on the rating of facial emotional expressions\nIn response to fearful facial expressions, the emotional status of aggression and cognitive function of attention were associated with participants\u2019 ratings (Table 2). Controlling for psychological status, fearful facial expressions could be responded to as anger or sadness in the current results. The participants may interpret the images depicting Fear as Angry and Sad.\nIn response to the Sad facial expression, the cognitive functions of attention and impulsivity were associated with the\n438 Psychiatry Investig 2022;19(6):435-442\nparticipants\u2019 facial affect ratings (Table 2). Controlling for psychological status, the Sad facial expression could be responded to as anger or fear emotions in the current results. The participants could interpret the images depicting Sad as Angry and Fear. Conclusively, controlling for psychological status, fearful and sad facial expressions could be interpreted as other emotions.\nFitted rating scores of facial emotion expression images\nAmong the neutral facial expression images, those depicting Neutral 11 had the lowest fitted rating scores, while Neutral 1 had the highest fitted rating scores in the Angry, Fear, and Sad ratings. Among the facial expression images depicting anger, the image depicting Angry 13 had the highest fitted rating score, and Angry 6 had the lowest fitted rating score in the Angry group. Among the images depicting fear, that of Fear 18 had the highest fitted rating score, and Fear 7 had the lowest fitted rating score in the Fear group. Among the images depicting sad facial expressions, Sad 2 had the highest fitted rating score, and Sad 11 had the lowest fitted rating score in the Sad group (Table 3)."
        },
        {
            "heading": "DISCUSSION",
            "text": "In the present study, participants\u2019 emotional mood and anxiety were not linked to the rating of facial emotional expressions. This differs from the results of previous studies.1,2,14 Many studies have suggested that patients with depression and anxiety tend to gravitate toward depressive or anxious facial emotional expressions.1,2,14 In a longitudinal study on recognition thresholds, Mei et al.36 reported that individuals with subthreshold depression exhibited increased perceptual sensitiv-\nTa bl\ne 2.\nE ffe\nct s\nof p\nsy ch\nol og\nic al\ns ta\ntu s\non th\ne ra\ntin g\nof fa\nci al\ne m\not io\nns\nPr ed\nic to\nr A\nng ry\nfa ce\nFe ar\nfa ce\nSa d\nfa ce\nEs tim\nat io\nn CI\npva\nlu e\nEs tim\nat io\nn CI\npva\nlu e\nEs tim\nat io\nn CI\npva\nlu e\nIn te\nrc ep\nt -2\n.6 5\n-5 .5\n6\u2013 -0\n.2 7\n0. 07\n5 -3\n.8 6\n-7 .5\n6\u2013 -0\n.1 5\n0. 04\n1 -2\n.6 5\n-5 .7\n5\u2013 0.\n46 0.\n03 2\nSe x\n0. 30\n-0 .4\n5\u2013 1.\n04 0.\n43 4\n0. 32\n-0 .6\n4\u2013 1.\n27 0.\n51 6\n0. 56\n-0 .2\n3\u2013 1.\n36 0.\n16 5\nK -A\nSR S\n-0 .0\n5 -0\n.1 0\u2013\n0. 01\n0. 07\n9 -0\n.1 0\n-0 .1\n7\u2013 0.\n03 0.\n00 6 *\n-0 .0\n7 -0\n.1 3\u2013\n-0 .0\n1 0.\n02 3 *\nBI S-\n11 0.\n04 -0\n.0 0\u2013\n0. 09\n0. 06\n0 0.\n04 -0\n.0 0\u2013\n0. 11\n0. 05\n1 0.\n05 0.\n00 \u20130\n.0 9\n0. 04\n5 *\nAQ 0.\n02 -0\n.0 0\u2013\n0. 05\n0. 07\n1 0.\n02 0.\n00 \u20130\n.0 7\n0. 02\n4 * 0.\n02 -0\n.0 0\u2013\n0. 05\n0. 06\n5\nBD I-\nII 0.\n01 -0\n.0 4\u2013\n0. 06\n0. 60\n2 0.\n01 -0\n.0 6\u2013\n0. 07\n0. 78\n7 0.\n04 -0\n.0 2\u2013\n0. 09\n0. 20\n2\nBA I\n-0 .0\n0 -0\n.0 6\u2013\n0. 05\n0. 92\n7 -0\n.0 0\n-0 .0\n4\u2013 0.\n10 0.\n39 1\n0. 02\n-0 .0\n4\u2013 0.\n08 0.\n60 4\nA ng\nry em\not io\nn 6.\n78 6.\n22 \u20137\n.3 4\n<0 .0\n01 *\n1. 25\n0. 66\n\u20131 .8\n4 <0\n.0 01\n* -0\n.7 4\n-1 .3\n6\u2013 -0\n.4 5\n0. 00\n5 *\nFe ar\nem ot\nio n\n1. 95\n1. 39\n\u20132 .5\n0 <0\n.0 01\n* 4.\n37 3.\n78 \u20134\n.9 7\n<0 .0\n01 *\n0. 15\n-0 .4\n7\u2013 0.\n77 0.\n01 9 *\nSa d\nem ot\nio n\n0. 37\n-0 .1\n9\u2013 0.\n93 0.\n19 3\n3. 01\n2. 41\n\u20133 .6\n0 <0\n.0 01\n* 4.\n90 4.\n28 \u20135\n.5 2\n<0 .0\n01 *\nLi ne\nar m\nix ed\n-e ffe\nct s m\nod el\nad ju\nste d\nfo r s\nex . *\nsta tis\ntic al\nly si\ngn ifi\nca nt\n. K -A\nSR S,\nth e K\nor ea\nn ve\nrs io\nn of\nth e A\ndu lt\nAt te\nnt io\nn D\nefi cit\n/H yp\ner ac\ntiv ity\nD iso\nrd er\nS elf\n-R ep\nor t S\nca le;\nB IS\n-1 1,\nB ar\nra tt\nIm -\npu lsi\nve ne\nss S\nca le\u2013\n11 ; A\nQ , B\nus s\u2013\nPe rr\ny A gg\nre ss\nio n\nQ ue\nsti on\nna ire\n; B D\nIII,\nB ec\nk D\nep re\nss io\nn In\nve nt\nor y I\nI; BA\nI, Be\nck A\nnx ie\nty In\nve nt\nor y;\nC I,\nco nfi\nde nc\ne i nt\ner va\nl\nwww.psychiatryinvestigation.org 439\nTa bl\ne 3.\nF itt\ned ra\ntin g\nsc or\nes o\nf t he\nfa ci\nal e\nm ot\nio n\nex pr\nes si\non p\nic tu\nre s\nN eu\ntra l\npi ct\nur es\nPe rc\neiv ed\nem ot\nio n\nA ng\nry\npi ct\nur es\nPe rc\neiv ed\nem ot\nio n\nFe ar\nfu l\npi ct\nur es\nPe rc\neiv ed\nem ot\nio n\nSa d\npi ct\nur es\nPe rc\neiv ed\nem ot\nio n\nA ng\nry Fe\nar Sa\nd A\nng ry\nFe ar\nSa d\nA ng\nry Fe\nar Sa\nd A\nng ry\nFe ar\nSa d\nN eu\ntra l 1\n1 0.\n51 0.\n66 1.\n08 A\nng ry\n1 3\n8. 74\n2. 33\n1. 33\nFe ar\n1 8\n1. 70\n6. 20\n2. 58\nSa d\n2 0.\n78 4.\n22 7.\n49\nN eu\ntra l 9\n0.\n61 1.\n23 2.\n52 A\nng ry\n1 4\n8. 59\n2. 65\n1. 23\nFe ar\n2 0\n2. 00\n6. 86\n3. 03\nSa d\n4 0.\n94 4.\n38 6.\n38\nN eu\ntra l 1\n8 0.\n64 1.\n56 2.\n68 A\nng ry\n1 8.\n59 2.\n96 1.\n62 Fe\nar 1\n7 2.\n00 6.\n20 2.\n38 Sa\nd 7\n1. 00\n2. 99\n5. 47\nN eu\ntra l 3\n0.\n79 0.\n91 1.\n72 A\nng ry\n1 1\n8. 56\n2. 51\n1. 07\nFe ar\n1 9\n2. 06\n6. 38\n2. 22\nSa d\n10 1.\n01 3.\n59 5.\n77\nN eu\ntra l 4\n0.\n83 0.\n69 0.\n76 A\nng ry\n3 8.\n36 2.\n38 1.\n00 Fe\nar 1\n2 2.\n08 6.\n77 1.\n95 Sa\nd 5\n1. 04\n4. 16\n6. 98\nN eu\ntra l 1\n6 0.\n94 2.\n36 2.\n81 A\nng ry\n1 7\n8. 30\n2. 64\n1. 64\nFe ar\n1 5\n2. 32\n6. 72\n2. 19\nSa d\n9 1.\n06 3.\n96 6.\n27\nN eu\ntra l 1\n7 1.\n01 1.\n18 1.\n91 A\nng ry\n1 5\n8. 11\n2. 79\n1. 15\nFe ar\n1 6\n2. 43\n6. 46\n1. 96\nSa d\n6 1.\n08 4.\n51 6.\n98\nN eu\ntra l 1\n3 1.\n05 0.\n99 1.\n86 A\nng ry\n1 8\n8. 08\n2. 67\n1. 87\nFe ar\n1 0\n2. 54\n5. 58\n2. 65\nSa d\n3 1.\n11 3.\n84 6.\n34\nN eu\ntra l 7\n1. 07\n1. 11\n2. 04\nA ng\nry 8\n8. 06\n2. 50\n1. 37\nFe ar\n1 3\n2. 54\n6. 24\n1. 77\nSa d\n1 1.\n11 4.\n25 8.\n29\nN eu\ntra l 2\n1. 17\n2. 36\n3. 83\nA ng\nry 1\n9 8.\n04 2.\n41 1.\n18 Fe\nar 1\n1 2.\n72 5.\n98 1.\n85 Sa\nd 8\n1. 11\n3. 89\n7. 00\nN eu\ntra l 1\n4 1.\n18 1.\n18 1.\n51 A\nng ry\n7 7.\n96 2.\n65 1.\n34 Fe\nar 3\n3. 24\n4. 34\n2. 02\nSa d\n18 1.\n47 4.\n37 7.\n67\nN eu\ntra l 1\n9 1.\n21 0.\n75 1.\n36 A\nng ry\n2 0\n7. 94\n2. 98\n1. 43\nFe ar\n1 3.\n41 4.\n04 1.\n29 Sa\nd 13\n1. 52\n3. 98\n7. 40\nN eu\ntra l 2\n0 1.\n23 0.\n88 1.\n50 A\nng ry\n4 7.\n92 2.\n64 1.\n09 Fe\nar 1\n4 3.\n50 6.\n30 1.\n68 Sa\nd 14\n1. 77\n4. 69\n7. 95\nN eu\ntra l 1\n0 1.\n25 1.\n76 2.\n82 A\nng ry\n9 7.\n80 2.\n37 1.\n14 Fe\nar 8\n3. 73\n5. 64\n1. 95\nSa d\n12 1.\n95 4.\n49 7.\n56\nN eu\ntra l 1\n5 1.\n34 1.\n41 2.\n69 A\nng ry\n1 6\n7. 78\n2. 64\n1. 20\nFe ar\n2 3.\n76 5.\n39 2.\n32 Sa\nd 19\n2. 01\n4. 36\n7. 77\nN eu\ntra l 6\n1. 46\n1. 43\n1. 69\nA ng\nry 1\n2 7.\n76 2.\n66 1.\n21 Fe\nar 4\n4. 03\n5. 24\n2. 30\nSa d\n16 2.\n05 4.\n11 7.\n47\nN eu\ntra l 1\n2 1.\n65 0.\n98 1.\n53 A\nng ry\n5 7.\n73 2.\n51 1.\n05 Fe\nar 6\n4. 12\n4. 09\n2. 09\nSa d\n17 2.\n07 4.\n63 7.\n77\nN eu\ntra l 8\n1.\n65 1.\n89 2.\n49 A\nng ry\n2 7.\n45 2.\n23 1.\n41 Fe\nar 9\n4. 39\n4. 64\n2. 47\nSa d\n20 2.\n25 6.\n77 2.\n74\nN eu\ntra l 5\n1. 90\n1. 09\n1. 26\nA ng\nry 1\n0 7.\n23 2.\n31 1.\n21 Fe\nar 5\n4. 80\n4. 91\n2. 19\nSa d\n15 2.\n70 4.\n64 7.\n52\nN eu\ntra l 1\n2. 23\n1. 84\n3. 01\nA ng\nry 6\n6. 38\n2. 38\n1. 68\nFe ar\n7\n5. 32\n5. 70\n3. 21\nSa d\n11 3.\n08 4.\n57 8.\n20\nC oe\nffi cie\nnt s o\nf t he\nli ne\nar m\nix ed\n-e ffe\nct s m\nod els\n440 Psychiatry Investig 2022;19(6):435-442\nity toward sad expressions and was associated with participants\u2019 current depressive states. Our study differs from previous studies in that we recruited healthy subjects after screening for psychiatric diseases. Previous studies recruited patients with depression, anxiety disorders, and ADHD. The emotional status of aggression could have affected the participants\u2019 ratings of fearful expressions in the current study and was consistent with that of a previous study. Acland et al.15 declared that negative emotions, including sadness and fear, were concurrent with an aggressive emotional status in healthy children.\nThe cognitive function of the participants was significantly correlated with their interpretation of the facial affects. Attention, in particular, was correlated with affect ratings. Attention and aggression levels may have affected the ratings of fearful facial expressions in the present study. Attention and impulsivity may have affected ratings of sad facial expressions.\nThese results are in line with those of previous studies on the correlation between facial expression and attention.37,38 The attention mechanism is thought to play a crucial role in human emotion perception, including feature extraction and artifact removal.39 The saliency and meaning of facial emotional expressions can facilitate conscious perception in healthy subjects.40\nAdditionally, the emotional and motivational value of social signals derived from facial expressions may be associated with the attention system.41 Faces were thought to be regarded as special objects containing social significance, such as innate salience.42 In the competition of several facial emotional expressions, fearful expressions with a sensory advantage were most salient to human vision.6 Bertini and L\u00e0davas43 suggested that fear-related signals should be prioritized in the visual system. In a previous systematic review, fear was the facial expression that patients with ADHD were least likely to recognize.44 Pessoa et al.13 stated that fear facial expressions would be more salient to human vision than are other facial expressions.\nThe core deficits of facial expression recognition in ADHD might be caused by a failure to correctly interpret affects due to inattention or impulsivity.37 Deficits in sustained attention and inhibition in ADHD are thought to dysregulate emotional facial perception processing.45 In fact, aggression and impulsivity were associated with Fear and Sad facial expressions in the present study. In a review of emotional dysregulation in ADHD, van Stralen46 stated that executive function deficits may be associated with inappropriate internalized (sadness) or externalized (aggression) emotional responses.\nHowever, whether abnormal executive function in subjects with ADHD can cause deficits in emotional recognition remains controversial.47 Petroni et al.48 suggested that these two capabilities may be separate from each other at the clinical lev-\nel; however, they are linked at the neural level. In the present study, participants were more likely to interpret facial expressions as emotions that they had previously felt. However, images depicting Fear could be rated as Angry or Sad while pictures depicting a Sad facial expression could be rated as Angry or Fear. By controlling emotional status and cognitive function, healthy individuals can misinterpret facial expressions as other emotions. Shioiro et al.49 reported the misinterpretation of emotional facial recognition: sad and anger were misinterpreted as disgust, and fear was misinterpreted as surprise. Usually, misinterpretation of facial expressions has been reported to be associated with cultural background and emotional intensity.17 However, the present study suggests that significant misinterpretation of facial expressions could occur in the condition of the same cultural background and intensity. Based on these results, we suggest that researchers consider the participants\u2019 psychological status, including emotional status and cognitive functions, as well as their misinterpretation of facial expressions.\nThe present study has several limitations. First, the small number of participants and unbalanced sex distribution are insufficient to generalize the results, although we considered them in the statistical analyses. Second, in the present study, we did not perform thorough standardized cognitive function tests to assess attention and intelligence. Future studies should include a larger number of participants, a more balanced sex distribution, and cognitive function tests.\nIn conclusion, our findings suggest that interpretation of facial expressions can be affected by psychological status and misinterpretation of other affects. Researchers should consider these factors when planning facial expressions studies."
        },
        {
            "heading": "Availability of Data and Material",
            "text": "The datasets generated or analyzed during the study are available from the corresponding author upon reasonable request."
        },
        {
            "heading": "Conflicts of Interest",
            "text": "The authors have no potential conflicts of interest to disclose."
        },
        {
            "heading": "Author Contributions",
            "text": "Conceptualization: Doug Hyun Han, Young Don Son. Data curation: Sujin Bae. Formal analysis: Beom Seuk Hwang, Eunhee Rhee. Funding acquisition: Doug Hyun Han, Young Don Son. Investigation: Doug Hyun Han. Methodology: Doug Hyun Han, Sujin Bae. Project administration: Eunhee Rhee. Validation: Sujin Bae, Ji Hyun Bae. Writing\u2014original draft: Doug Hyun Han, Young Don Son. Writing\u2014review & editing: Doug Hyun Han, Sujin Bae."
        },
        {
            "heading": "ORCID iDs",
            "text": "Sujin Bae https://orcid.org/0000-0002-9671-4627 Eunhee Rhee https://orcid.org/0000-0002-8366-9855 Beom Seuk Hwang https://orcid.org/0000-0001-7224-1127 Young Don Son https://orcid.org/0000-0001-7029-2422 Ji Hyun Bae https://orcid.org/0000-0002-1260-1642 Doug Hyun Han https://orcid.org/0000-0002-8314-0767\nwww.psychiatryinvestigation.org 441"
        },
        {
            "heading": "Funding Statement",
            "text": "This work was supported by a National Research Foundation of Korea (NRF) grant funded by the Korean government (MSIT) (NRF2020R1A4A1019623)."
        },
        {
            "heading": "Acknowledgments",
            "text": "We acknowledge the contributions of colleagues, institutions, and agencies that aided the efforts of the authors."
        }
    ],
    "title": "Correlations Between Psychological Status and Perception of Facial Expression",
    "year": 2022
}