{
    "abstractText": "Gradient-push algorithm has been widely used for decentralized optimization problems when the connectivity network is a direct graph. This paper shows that the gradient-push algorithm with stepsize \u03b1 > 0 converges exponentially fast to an O(\u03b1)-neighborhood of the optimizer under the assumption that each cost is smooth and the total cost is strongly convex. Numerical experiments are provided to support the theoretical convergence results.",
    "authors": [
        {
            "affiliations": [],
            "name": "WOOCHEOL CHOI"
        },
        {
            "affiliations": [],
            "name": "DOHEON KIM"
        }
    ],
    "id": "SP:db79057fb38fc7917f6670f8edb9b246eb334d4c",
    "references": [
        {
            "authors": [
                "P.A. Forero",
                "A. Cano",
                "G.B. Giannakis"
            ],
            "title": "Consensus-based distributed support vector machines",
            "venue": "Journal of Machine Learning Research, vol. 11, pp. 1663\u20141707, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "H. Raja",
                "W.U. Bajwa"
            ],
            "title": "Cloud K-SVD: A collaborative dictionary learning algorithm for big, distributed data",
            "venue": "IEEE Transactions on Signal Processing, vol. 64, no. 1, pp. 173\u2014188, Jan. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "T. Yang",
                "X. Yi",
                "J. Wu",
                "Y. Yuan",
                "D. Wu",
                "Z. Meng",
                "Y. Hong",
                "H. Wang",
                "Z. Lin",
                "K.H. Johansson"
            ],
            "title": "A survey of distributed optimization",
            "venue": "Annual Reviews in Control, vol. 47, pp. 278 \u2014 305, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "L. Bottou",
                "F.E. Curtis",
                "J. Nocedal"
            ],
            "title": "Optimization methods for large-scale machine learning",
            "venue": "SIAM Review, vol. 60, no. 2, pp. 223\u2014311, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "F. Bullo",
                "J. Cortes",
                "S. Martinez"
            ],
            "title": "Distributed Control of Robotic Networks: A Mathematical Approach to Motion",
            "venue": "Coordination Algorithms,",
            "year": 2009
        },
        {
            "authors": [
                "W. Ren"
            ],
            "title": "Consensus Based Formation Control Strategies for Multi-Vehicle Systems, in Proceedings of the Amer-ican",
            "venue": "Control Conference,",
            "year": 2006
        },
        {
            "authors": [
                "Y. Cao",
                "W. Yu",
                "W. Ren",
                "G. Chen"
            ],
            "title": "An overview of recent progress in the study of distributed multi-agent coordination",
            "venue": "IEEE Trans Ind. Informat.,",
            "year": 2013
        },
        {
            "authors": [
                "W. Choi",
                "D. Kim",
                "S. Yun"
            ],
            "title": "Convergence results of a nested decentralized gradient method for nonstrongly convex problems",
            "venue": "J. Optim. Theory Appl",
            "year": 2022
        },
        {
            "authors": [
                "G.B. Giannakis",
                "V. Kekatos",
                "N. Gatsis",
                "S.-J. Kim",
                "H. Zhu",
                "B. Wollenberg"
            ],
            "title": "Mon-itoring and optimization for power grids: A signal processing perspective",
            "venue": "IEEE Signal Processing Mag.,",
            "year": 2013
        },
        {
            "authors": [
                "V. Kekatos",
                "G.B. Giannakis"
            ],
            "title": "Distributed robust power system state estimation",
            "venue": "IEEE Trans. Power Syst.,",
            "year": 2013
        },
        {
            "authors": [
                "K.I. Tsianos",
                "S. Lawlor",
                "M.G. Rabbat"
            ],
            "title": "Consensus-based distributed optimization: Practical issues and applications in large-scale machine learning",
            "venue": "Proceedings of the IEEE Allerton Conference on Communication,",
            "year": 2012
        },
        {
            "authors": [
                "M. Akbari",
                "B. Gharesifard",
                "T. Linder"
            ],
            "title": "Distributed online convex optimization on time-varying directed graphs",
            "venue": "IEEE Trans. Control Netw. Syst., vol. 4, no. 3, pp. 417\u2013428, Sep. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "M. Assran",
                "N. Loizou",
                "N. Ballas",
                "M. Rabbat"
            ],
            "title": "Stochastic gradient push for distributed deep learning",
            "venue": "36th International Conference on Machine Learning. Jun. 2019, vol. 97, pp. 344\u2013353, PMLR. 19",
            "year": 2019
        },
        {
            "authors": [
                "J.A. Bazerque",
                "G.B. Giannakis"
            ],
            "title": "Distributed spectrum sensing for cognitive radio networks by exploiting sparsity",
            "venue": "IEEE Trans. Signal Process",
            "year": 2010
        },
        {
            "authors": [
                "A.S. Berahas",
                "R. Bollapragada",
                "N.S. Keskar",
                "E. Wei"
            ],
            "title": "Balancing communication and computation in distributed optimization",
            "venue": "IEEE Trans. Autom. Control",
            "year": 2018
        },
        {
            "authors": [
                "S. Bubeck"
            ],
            "title": "Convex optimization: Algorithms and complexity",
            "venue": "Foundations and Trends in Machine Learning,",
            "year": 2015
        },
        {
            "authors": [
                "A.I. Chen",
                "A. Ozdaglar"
            ],
            "title": "A fast distributed proximal-gradient method",
            "venue": "Communication, Control, and Computing (Allerton), 2012 50th Annual Allerton Conference on. IEEE, 2012, pp. 601\u2013608.",
            "year": 2012
        },
        {
            "authors": [
                "D. Jakovetic",
                "J. Xavier",
                "J.M.F. Moura"
            ],
            "title": "Fast Distributed Gradient Methods",
            "venue": "IEEE Transactions on Automatic Control, vol. 59, no. 5, pp. 1131\u20131146, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "J. Kim",
                "W. Choi"
            ],
            "title": "Gradient-push algorithm for distributed optimization with event-triggered communications",
            "venue": "IEEE Access,",
            "year": 2023
        },
        {
            "authors": [
                "J. Li",
                "C. Gu",
                "Z. Wu"
            ],
            "title": "Online distributed stochastic learning algorithm for convex optimization in timevarying directed networks",
            "venue": "Neurocomputing",
            "year": 2020
        },
        {
            "authors": [
                "A. Nedi\u0107",
                "A. Ozdaglar"
            ],
            "title": "Distributed subgradient methods for multi-agent optimization",
            "venue": "IEEE Transactions on Automatic Control, vol. 54, no. 1, pp. 48, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "A. Nedi\u0107",
                "A. Olshevsky"
            ],
            "title": "Stochastic gradient-push for strongly convex functions on time-varying directed graphs",
            "venue": "IEEE Transactions on Automatic Control, vol. 61, no. 12, pp. 3936\u20133947, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "A. Nedi\u0107",
                "A. Olshevsky"
            ],
            "title": "Distributed optimization over time-varying directed graphs",
            "venue": "IEEE Transactions on Automatic Control, vol. 60, no. 3, pp. 601\u2013615, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "A. Nedi\u0107",
                "A. Olshevsky",
                "W. Shi"
            ],
            "title": "Achieving geometric convergence for distributed optimization over time-varying graphs",
            "venue": "SIAM Journal on Optimization, vol. 27, no. 4, pp. 2597\u20132633, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "G. Qu",
                "N. Li"
            ],
            "title": "Harnessing smoothness to accelerate distributed optimization",
            "venue": "IEEE Transactions on Control of Network Systems, vol. 5, no. 3, pp. 1245\u20131260, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "A.H. Sayed"
            ],
            "title": "Diffusion adaptation over networks",
            "venue": "Academic Press Library in Signal Processing,",
            "year": 2013
        },
        {
            "authors": [
                "I.D. Schizas",
                "G.B. Giannakis",
                "S.I. Roumeliotis",
                "A. Ribeiro"
            ],
            "title": "Consensus in ad hoc WSNs with noisy links\u2014part II: distributed estimation and smoothing of random signals",
            "venue": "IEEE Trans. Signal Process",
            "year": 2008
        },
        {
            "authors": [
                "E. Seneta"
            ],
            "title": "Non-negative matrices and Markov chains, 2nd Ed",
            "year": 1981
        },
        {
            "authors": [
                "W. Shi",
                "Q. Ling",
                "G. Wu",
                "W. Yin"
            ],
            "title": "Extra: an exact first-order algorithm for decentralized consensus optimization",
            "venue": "SIAM J. Optim",
            "year": 2015
        },
        {
            "authors": [
                "W. Shi",
                "Q. Ling",
                "K. Yuan",
                "G. Wu",
                "W. Yin"
            ],
            "title": "On the linear convergence of theADMMin decentralized consensus optimization",
            "venue": "IEEE Trans. Signal Process",
            "year": 2014
        },
        {
            "authors": [
                "T. Tatarenko",
                "B. Touri"
            ],
            "title": "Non-convex distributed optimization",
            "venue": "IEEE Trans. Automat. Control",
            "year": 2017
        },
        {
            "authors": [
                "K. Tsianos",
                "S. Lawlor",
                "M.G. Rabbat"
            ],
            "title": "Communication/computation tradeoffs in consensus-based distributed optimization,",
            "venue": "in Proc. Adv. Neural Inf. Process. Syst.,",
            "year": 2012
        },
        {
            "authors": [
                "K.I. Tsianos",
                "S. Lawlor",
                "M.G. Rabbat"
            ],
            "title": "Push-sum distributed dual averaging for convex optimization",
            "venue": "Proc. IEEE Conf. Dec. Control, Maui, HI, USA, 2012, pp. 5453\u20145458.",
            "year": 2012
        },
        {
            "authors": [
                "C. Xi",
                "U.A. Khan"
            ],
            "title": "DEXTRA: A fast algorithm for optimization over directed graphs",
            "venue": "IEEE Transactions on Automatic Control, vol. 62, no. 10, pp. 4980\u20134993, Oct. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "R. Xin",
                "A.K. Sahu",
                "U.A. Khan",
                "S. Kar"
            ],
            "title": "Distributed stochastic optimization with gradient tracking over strongly-connected networks",
            "venue": "58th IEEE Conference on Decision and Control, Dec. 2019, pp. 8353\u20138358.",
            "year": 2019
        },
        {
            "authors": [
                "R. Xin",
                "U.A. Khan"
            ],
            "title": "A linear algorithm for optimization over directed graphs with geometric convergence",
            "venue": "IEEE Control Systems Letters, vol. 2, no. 3, pp. 315\u2013320, 2018. 20 WOOCHEOL CHOI, DOHEON KIM, AND SEOK-BAE YUN",
            "year": 2018
        },
        {
            "authors": [
                "K. Yuan",
                "Q. Ling",
                "W. Yin"
            ],
            "title": "On the convergence of decentralized gradient descent",
            "venue": "SIAM Journal on Optimization, vol. 26, no. 3, pp. 1835\u20131854, Sep. 2016.",
            "year": 1835
        },
        {
            "authors": [
                "D. Yuan",
                "S. Xu",
                "J. Lu"
            ],
            "title": "Gradient-free method for distributed multi-agent optimization via push-sum algorithms, Internat",
            "venue": "J. Robust Nonlinear Control",
            "year": 2015
        },
        {
            "authors": [
                "J. Li",
                "C. Gu",
                "Z. Wu"
            ],
            "title": "Online distributed stochastic learning algorithm for convex optimization in time-varying directed networks, Neurocomputing (2019)",
            "year": 2019
        },
        {
            "authors": [
                "T. Yang"
            ],
            "title": "A Distributed Algorithm for Economic Dispatch Over Time-Varying Directed Networks With Delays,",
            "venue": "IEEE Transactions on Industrial Electronics,",
            "year": 2017
        },
        {
            "authors": [
                "M.S. Assran",
                "M.G. Rabbat"
            ],
            "title": "Asynchronous Gradient Push,",
            "venue": "IEEE Transactions on Automatic Control,",
            "year": 2021
        },
        {
            "authors": [
                "W. Yu",
                "H. Liu",
                "W. Zheng",
                "Y. Zhu"
            ],
            "title": "Distributed discrete-time convex optimization with nonidentical local constraints over time-varying unbalanced directed graphs",
            "venue": "Automatica J. IFAC",
            "year": 2021
        },
        {
            "authors": [
                "M. Akbari",
                "B. Gharesifard",
                "T. Linder"
            ],
            "title": "Distributed Online Convex Optimization on Time-Varying Directed Graphs,",
            "venue": "IEEE Transactions on Control of Network Systems,",
            "year": 2017
        },
        {
            "authors": [
                "C. Wang",
                "S. Xu",
                "D. Yuan",
                "B. Zhang",
                "Z. Zhang"
            ],
            "title": "Push-Sum Distributed Online Optimization With Bandit Feedback,",
            "venue": "IEEE Transactions on Cybernetics,",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "tion problems when the connectivity network is a direct graph. This paper shows that the gradient-push algorithm with stepsize \u03b1 > 0 converges exponentially fast to an O(\u03b1)-neighborhood of the optimizer under the assumption that each cost is smooth and the total cost is strongly convex. Numerical experiments are provided to support the theoretical convergence results.\nContents\n1. Introduction 1 2. Gradient-push algorithm and related basic results 4 3. The intuition behind the gradient-push algorithm 7 4. Main convergence result 8 5. Weighted Consensus 10 6. Estimates on the distance between the average and the optimizer 12 7. Uniform boundedness of the sequence 14 8. Convergence estimates 15 9. Numerical experiments 16 9.1. Convex local cost case 17 9.2. Nonconvex local cost case 17 Acknowledgments 17 References 18\n1. Introduction\nIn this paper we are concerned with the distributed optimization\nmin x\u2208Rd f(x) = n\u2211 i=1 fi(x), (1.1)\nwhere n denotes the number of the agents in the network, and fi : Rd \u2192 R is the local objective function available only to the agent i for each 1 \u2264 i \u2264 n. We can reformulate\n2010 Mathematics Subject Classification. Primary 90C25, 68Q25. Key words and phrases. Gradient-push algorithm, Push-sum algorithm, Convex optimization.\n1\nar X\niv :2\n30 2.\n08 77\n9v 1\n[ m\nat h.\nO C\n] 1\n7 Fe\nb 20\n2 WOOCHEOL CHOI, DOHEON KIM, AND SEOK-BAE YUN\nthis problem as\nmin xi\u2208Rd n\u2211 i=1 fi(xi)\ns.t. xi = xj , \u2200 j \u2208 Ni,\nwhere Ni is the set of in-neighbors of agent i in the directed network.\nDistributed optimization has been studied extensively in the last years, since it appears in various applications, including wireless sensor networks [15, 29], multi-agent control [5, 6, 7], smart grids [10, 11], and machine learning [1, 2, 3, 4, 12].\nTo solve the distributed optimization on networks, there have been a numerous research in the context of the distributed optimization. We refer to [23, 26, 31, 32], and references therin. Among the algorithms, one fundamental algorithm is the distributed gradient descent algorithm (DGD) introduced in [23]. Although this algorithm has led to great progress in distributed optimization, it is known that the exact convergence is achieved only using a diminishing stepsize, which is contrast to the centralized gradient descent method. This fact motivated the development of various distributed optimization algorithms such as EXTRA [31], decentralized gradient trakcing (DGD) [26, 27, 38]. Recently there has been an interest in designing the communication efficient algorithm for the distributed optimization [28, 18, 19, 16].\nWe are interested in the distributed optimization posed on directed graphs, which has gained increasing attention in recent years. Nedic-Olshevsky [23, 25] developed the gradient-push algorithm, which is based on the push-sum algorithm for consensus [20, 35] on directed graphs. The gradient-push algorithm has been widely used by numerous researchers. The algorithm has been studied for online distributed optimization [13, 22, 46, 42, 47]. The work [?] studied the gradient-push algorithm involving the quantized communications and the paper [21] designed the gradient-push algorithm with the event-triggred communication. In addition, the gradient-push algorithm has been used for constrained distributed optimization [45] and zeroth-order distributed optimization [40]. See also [44] for the asynchronous gradient-push algorithm. We also refer to the works [26, 36, 38] for the variants of gradient-push algorithm involving the communication of gradient informations.\nDespite its wide applications, the convergence analysis of the gradient-push algorithm has not been fully exploited in the literature. In the original work [23], Nedic-Olshevsky established the convergence result for convex cost functions when the stepsize \u03b1(t) is given as \u03b1(t) = 1/ \u221a t or satisfies the condition \u2211\u221e t=1 \u03b1(t) = \u221e and \u2211\u221e t=1 \u03b1(t)\n2 < \u221e. In the work [25], the convergence result was obtained when the cost function is strongly convex and \u03b1(t) = c/t for some c > 0. Recently, the work [33] established a convergence result for non-convex cost functions. The results are summarized in Table 1. We remark that the convergence results in the previous works [23, 25, 33] assumed that the gradient of the cost functions are uniformly bounded.\n3 In this paper, we will obtain a convergence result of the gradient-push algorithm without assuming the uniform boundedness of the gradients of the cost functions. We will only assume that each cost function is L-smooth and the total cost is strongly convex. Under these assumptions, we will show that the gradient-push algorithm with a constant stepsize \u03b1(t) \u2261 \u03b1 > 0 converges exponentially fast to an O(\u03b1)-neighborhood of the optimizer x\u2217. This result can be seen as an extension of the works [39, 9] where the authors obtained the exponential convergence results of the decentralized gradient descent on undirected graph.\nThis paper is organized as follows: In Section 2, we review the push-sum algorithm and related properties. In Section 3, we provide the intuition behind the push-sum algorithm for reader\u2019s understanding. In Section 4, we state the main convergence results of this paper. In Section 5, the estimate measuring the effect of the weighted consensus process is obtained. In Section 6, we derive a sequential estimate on the distance between the average and the optimizer. Combining the estimates from Section 5 and 6, we prove the uniform boundedness of the sequence in Section 7, and establish the main convergence result in Section 8. In the final Section 9, we provide numerical results supporting our theoretical results."
        },
        {
            "heading": "4 WOOCHEOL CHOI, DOHEON KIM, AND SEOK-BAE YUN",
            "text": "2. Gradient-push algorithm and related basic results\nIn this section, we review the gradient-push algorithm and some preliminary results for\nobtaining the convergence estimates of the gradient-push algorithm.\nWe consider a directed graph G = (V,E) with the vertex set V = {1, 2, \u00b7 \u00b7 \u00b7 , n} and the edge set E \u2282 V \u00d7 V , where the communication between agents are performed. Here (i, j) \u2208 E means that there is a directed edge from agent i to j. We define the set of in-neighbors of agent i by\nN ini = {j \u2208 V | (j, i) \u2208 E},\nand the set of out-neighbors of agent i is defined by\nNouti = {j \u2208 V | (i, j) \u2208 E}.\nThroughout this paper, we assume that G satisfies the following two assumptions:\n\u2022 (G1) Every vertex of G has a self-loop, i.e.,\n(i, i) \u2208 E (\u21d4 i \u2208 N ini \u21d4 i \u2208 Nouti ), \u2200 i \u2208 V.\n\u2022 (G2) G is strongly connected, i.e., G contains a directed path from i to j for every (i, j) \u2208 V \u00d7 V .\nWe set dj = |Noutj | and\nWij =\n{ 1 dj\nif j \u2208 N ini (or, equivalently, i \u2208 Noutj ) 0 if j /\u2208 N ini .\n(2.1)\nThe gradient-push algorithm [23] is described as follows: Given inital data xi(0) \u2208 Rd, yi(0) = 1, for each 1 \u2264 i \u2264 n, and t \u2208 N \u222a {0}, we update\nwi(t+ 1) = n\u2211 j=1 Wijxj(t)\nyi(t+ 1) = n\u2211 j=1 Wijyj(t) zi(t+ 1) = wi(t+ 1)\nyi(t+ 1)\nxi(t+ 1) = wi(t+ 1)\u2212 \u03b1\u2207fi(zi(t+ 1)).\n(2.2)\nLet us denote by w(t) = col(w1(t), \u00b7 \u00b7 \u00b7 , wn(t)) \u2208 Rnd the column vector obtained by stacking w1(t), . . . , wn(t), and similarly for x(t) \u2208 Rnd, y(t) \u2208 Rd, and z(t) \u2208 Rnd. Then we may write the above algorithm as\nw(t+ 1) = (W \u2297 Id)x(t)\ny(t+ 1) = Wy(t)\nzi(t+ 1) = wi(t+ 1)\nyi(t+ 1) , 1 \u2264 i \u2264 n,\nx(t+ 1) = w(t+ 1)\u2212 \u03b1\u2207F (z(t+ 1)),\n(2.3)\n5 where we define \u2207F (x) := col(\u2207f1(x1), \u00b7 \u00b7 \u00b7 ,\u2207fn(xn)) for any x = col(x1, . . . , xn), Id is the d \u00d7 d identity matrix, and \u2297 is the Kronecker product. We assume that yi(0) = 1, i = 1, . . . , n. Note that the positivity of y(t) is ensured by the following inductive argument:\nyi(t+ 1) = n\u2211 j=1 Wijyj(t) \u2265Wiiyi(t) = yi(t) di > 0.\nWe notice that W is column stochastic, by the following relation:\nn\u2211 i=1 Wij = n\u2211 i=1 1N ini (j) dj = n\u2211 i=1 1Noutj (i) |Noutj | = 1, j = 1, . . . , n.\nNote that column stochasticity of W is equivalent to 1>nW = 1 > n . Also note that by (2.1), Wij > 0 if and only if (j, i) \u2208 E. By (G2), W is an irreducible matrix, so we can apply the Perron-Frobenius theorem to deduce that W has a right eigenvector \u03c0 = (\u03c01, \u00b7 \u00b7 \u00b7 , \u03c0n)> associated with the eigenvalue 1, of which all entries are positive and satisfy\nn\u2211 j=1 \u03c0j = 1. (2.4)\nMoreover, by (G1), G is aperiodic. Since G is both strongly connected and aperiodic, W is primitive, and it is known that\nW\u221e := lim k\u2192\u221e W k = \u03c01>n (2.5)\nwith convergence speed geometrically fast [30]. We denote the Euclidean norm by \u2016 \u00b7 \u2016 and for a matrix A \u2208 Rn\u00d7n, and set the matrix norm |||A||| by\n|||A||| = sup x\u2208Rn\\{0} \u2016Ax\u2016 \u2016x\u2016 .\nNow we define a weighted inner product as \u3008x, y\u3009\u03c0 = x>diag(\u03c0)\u22121y and its induced norm \u2016x\u2016\u03c0 = \u2016diag( \u221a \u03c0)\u22121x\u2016. We also set |||A|||\u03c0 as the matrix norm induced by \u2016 \u00b7 \u2016\u03c0 for A \u2208 Rn\u00d7n, i.e.,\n|||A|||\u03c0 = sup x\u2208Rn\\{0} \u2016Ax\u2016\u03c0 \u2016x\u2016\u03c0 .\nIt is easy to check that |||A|||\u03c0 = \u2223\u2223\u2223\u2223\u2223\u2223diag(\u221a\u03c0)\u22121Adiag(\u221a\u03c0)\u2223\u2223\u2223\u2223\u2223\u2223. Also we have\n\u2016 \u00b7 \u2016\u03c0 \u2264 1 \u221a \u03c0a \u2016 \u00b7 \u2016 and \u2016 \u00b7 \u2016 \u2264 \u221a \u03c0b\u2016 \u00b7 \u2016\u03c0,\nwhere \u03c0a and \u03c0b denote the minimum and maximum values of \u03c0. We state a basic lemma for W .\nLemma 2.1. We have\n|||W |||\u03c0 = |||W\u221e|||\u03c0 = 1."
        },
        {
            "heading": "6 WOOCHEOL CHOI, DOHEON KIM, AND SEOK-BAE YUN",
            "text": "Proof. We give a proof of this lemma for reader\u2019s convenience. Using Cauchy-Schwartz inequality, we deduce the following inequality\n\u2016Wx\u20162\u03c0 = n\u2211 i=1 ( n\u2211 j=1 wij \u221a \u03c0j xj\u221a \u03c0j )2 \u03c0\u22121i\n\u2264 n\u2211 i=1 ( n\u2211 j=1 wij\u03c0j )( n\u2211 j=1 wij x2j \u03c0j \u03c0\u22121i ) =\nn\u2211 i=1 n\u2211 j=1 wij x2j \u03c0j = n\u2211 j=1 x2j \u03c0j = \u2016x\u20162\u03c0,\nwhich proves |||W |||\u03c0 \u2264 1. Also this directly implies that |||W\u221e|||\u03c0 \u2264 1. Combining these inequalities with the fact W\u03c0 = \u03c0 yields that\n|||W |||\u03c0 = |||W\u221e|||\u03c0 = 1.\nThis finishes the proof.\nWe recall the following result from [37, Lemma 1]:\nLemma 2.2 ([37]). Under assumptions (G1) and (G2), we have the estimate \u03c3W := |||W \u2212W\u221e|||\u03c0 < 1.\nUsing this lemma, one may derive the following convergence estimate of y(t) \u2208 Rn\ntowards n\u03c0 \u2208 Rn:\n\u2016y(t)\u2212 n\u03c0\u2016\u03c0 = \u2225\u2225(W \u2212W\u221e)t(1n \u2212 n\u03c0)\u2225\u2225\u03c0 \u2264 \u03c3tW \u20161n \u2212 n\u03c0\u2016\u03c0 (2.6)\nWe can similarly define a weighted inner product on Rnd by\n\u3008x, y\u3009\u03c0\u22971d := x >diag(\u03c0 \u2297 1d)\u22121y = x>(diag(\u03c0)\u22121 \u2297 Id)y,\nand its induced norm and matrix norm can be defined analogously.\nLemma 2.3. For any n\u00d7 n matrix A, we have\n|||A\u2297 Id|||\u03c0\u22971d = |||A|||\u03c0.\nProof. We proceed in the following way: |||A\u2297 Id|||\u03c0\u22971d = \u2223\u2223\u2223\u2223\u2223\u2223diag(\u221a\u03c0 \u2297 1d)\u22121(A\u2297 Id)diag(\u221a\u03c0 \u2297 1d)\u2223\u2223\u2223\u2223\u2223\u2223\n= \u2223\u2223\u2223\u2223\u2223\u2223(diag(\u221a\u03c0)\u22121 \u2297 Id)(A\u2297 Id)(diag(\u221a\u03c0)\u2297 Id)\u2223\u2223\u2223\u2223\u2223\u2223\n= \u2223\u2223\u2223\u2223\u2223\u2223[diag(\u221a\u03c0)\u22121Adiag(\u221a\u03c0)]\u2297 Id\u2223\u2223\u2223\u2223\u2223\u2223\n= \u2223\u2223\u2223\u2223\u2223\u2223diag(\u221a\u03c0)\u22121Adiag(\u221a\u03c0)\u2223\u2223\u2223\u2223\u2223\u2223\n= |||A|||\u03c0.\nIn the fourth inequality, we have used that the matrix norm |||\u00b7||| is equal to the largest singular value of the matrix.\n7 3. The intuition behind the gradient-push algorithm\nIn this section, we give an intuition behind the gradient-push algorithm (2.3). We may\nwrite the algorithm (2.3) in terms of w(t) as\nw(t+ 1) = (W \u2297 Id)(w(t)\u2212 \u03b1\u2207F (z(t)). (3.1)\nIn order to understand the algorithm (2.3) in the above form, one needs to find why we define z(t) as zi(t) = wi(t)/yi(t). First, we prove that regardless of the value of the variable z(t), the variable w(t) in (3.1) achieves a weighted consensus up to an O(\u03b1) error under a mild boundedness assumption. Precisely, we have the following lemma.\nLemma 3.1. Assume that sups\u22650 \u2016\u2207F (z(s))\u2016 < \u221e. Then there exist constants D > 0 and \u03b6 \u2208 (0, 1) determined by the graph such that\n\u2016w(t)\u2212 n\u03c0 \u2297 w\u0304(t)\u2016 \u2264 D\u03b6t\u2016w(0)\u2016 \u2212 (\u03b1D)\u03b6 1\u2212 \u03b6 sup s\u22650 \u2016\u2207F (z(s))\u2016\nfor all t \u2265 0.\nProof. Using (3.1) iteratively, we have\nw(t) = W t \u2297 Id(w(0))\u2212 \u03b1 t\u22121\u2211 k=1 ( W t\u2212k \u2297 Id ) \u2207F (z(k)). (3.2)\nMultiplying \u03c01Tn in front of the both sides and using the property that \u03c01 T nW = \u03c01 T n , we get the following equation\n\u03c0 \u2297 w\u0304(t) = \u03c01Tn \u2297 Id(w(0))\u2212 \u03b1 t\u22121\u2211 k=1 \u03c01Tn \u2297 Id\u2207F (z(k)). (3.3)\nCombining (3.2) and (3.3) gives the following identity\nw(t)\u2212n\u03c0\u2297 w\u0304(t) = ( W t\u2212 \u03c01Tn ) \u2297 Id(w(0))\u2212\u03b1 t\u22121\u2211 k=1 [ (W t\u2212k \u2212 \u03c01Tn )\u2297 Id ] \u2207F (z(k)). (3.4)\nBy the property (2.6), there exist constants D > 0 and \u03b6 > 0 such that\u2223\u2223\u2223\u2223\u2223\u2223W t \u2212 \u03c01Tn \u2223\u2223\u2223\u2223\u2223\u2223 \u2264 D\u03b6t for all t \u2265 0. Inserting this estimate in (3.4) we deduce\n\u2016w(t)\u2212 n\u03c0 \u2297 w\u0304(t)\u2016\n\u2264 D\u03b6t\u2016w(0)\u2016 \u2212D\u03b1 t\u22121\u2211 k=1 \u03b6t\u2212k\u2016\u2207F (z(k))\u2016\n\u2264 D\u03b6t\u2016w(0)\u2016 \u2212 \u03b1D sup s\u22650 \u2016\u2207F (z(s))\u2016 t\u22121\u2211 k=1 \u03b6t\u2212k = D\u03b6t\u2016w(0)\u2016 \u2212 (\u03b1D)\u03b6 1\u2212 \u03b6 sup s\u22650 \u2016\u2207F (z(s))\u2016.\nThe proof is done."
        },
        {
            "heading": "8 WOOCHEOL CHOI, DOHEON KIM, AND SEOK-BAE YUN",
            "text": "The above lemma shows that w(t)/n\u03c0 gets close to the consensus w\u0304(t) as t\u2192\u221e up to an error O(\u03b1). Now, we multiply \u03c01Tn in front of both sides of (3.1), we find\nw\u0304(t+ 1) = w\u0304(t)\u2212 \u03b1 n n\u2211 i=1 \u2207fi(zi(t))\n= w\u0304(t)\u2212 \u03b1\u2207f(w\u0304(t)) + \u03b1 n n\u2211 i=1 ( \u2207fi(w\u0304(t))\u2212\u2207fi(zi(t)) ) .\nFrom this expression, we see that {w\u0304(t)}t\u22650 follows approximately the gradient descent method of the global cost function f provided that zi(t) is close enough to w\u0304(t) for each 1 \u2264 i \u2264 n. On the other hand, the above lemm yields that wi(t)n\u03c0i gets close to w\u0304(t) up to an O(\u03b1)-error.\nTherefore, if we want the solution w\u0304(t) to converge to the minimizer w\u2217 of f , the natural choice of zi(t) would be wi(t)/n\u03c0i if we konw \u03c0i in advance. However, it is often the case that the value \u03c0i should be calculated in a distributed manner when a graph of network is given. Having said this, a natural choice of zi(t) is given by zi(t) = wi(t)/yi(t) with the balancing constants y(t) of (2.2) in view of the exponential convergence of y(t) to n\u03c0 (see (2.6)).\n4. Main convergence result\nThroughout this paper, we assume that the cost functions satisfy the following two\nassumptions.\n\u2022 (F1) The gradient of each function fi is Lipschitz continuous with constant Li > 0 for all 1 \u2264 i \u2264 d, i.e., fi is Li-smooth:\n\u2016\u2207fi(x)\u2212\u2207fi(y)\u2016 \u2264 Li\u2016x\u2212 y\u2016 \u2200 x, y \u2208 Rd. (4.1)\n\u2022 (F2) The total cost f is \u03b2-strongly convex with a value \u03b2 > 0.\nUnder the above assumptions, there exists a unique minimizer w\u2217 of the cost f . In order to analyze the convergence property of the algorithm (2.2), we consider the following two quantities\nAt := \u2016w\u0304(t)\u2212 w\u2217\u2016 and Bt := \u2016w(t)\u2212 (W\u221e \u2297 Id)w(t)\u2016\u03c0.\nHere At measures the distance between the average of states w\u0304(t) and the optimal point w\u2217. Also we note that\n(W\u221e \u2297 Id)w(t) = (\u03c01Tn \u2297 Id)w(t) = n\u03c0 \u2297 w\u0304(t). (4.2)\nTherefore Bt measures how the static w(t) to the weighted consensus states n\u03c0 \u2297 w\u0304(t). Obtaining convergence properties of At and Bt will give a convergence estimate of the sequence w(t) to n\u03c0 \u2297 w\u2217 as seen in the following lemma.\nLemma 4.1. We have\n\u2016w(t)\u2212 n\u03c0 \u2297 w\u2217\u2016\u03c0\u22971d \u2264 \u2016w(t)\u2212 n\u03c0 \u2297 w\u0304(t)\u2016\u03c0\u22971d + n\u2016w\u0304(t)\u2212 w\u2217\u2016.\n9 Proof. We apply the triangle inequality to find\n\u2016w(t)\u2212 n\u03c0 \u2297 w\u2217\u2016\u03c0\u22971d \u2264 \u2016w(t)\u2212 n\u03c0 \u2297 w\u0304(t)\u2016\u03c0\u22971d + \u2016n\u03c0 \u2297 (w\u0304(t)\u2212 w\u2217)\u2016\u03c0\u22971d . (4.3)\nBy (2.4),\n\u2016n\u03c0 \u2297 (w\u0304(t)\u2212 w\u2217)\u20162\u03c0\u22971d = n 2 n\u2211 j=1 \u03c0j\u2016w\u0304(t)\u2212 w\u2217\u20162 = n2\u2016w\u0304(t)\u2212 w\u2217\u20162.\nCombining this with (4.3) gives\n\u2016w(t)\u2212 n\u03c0 \u2297 w\u2217\u2016\u03c0\u22971d \u2264 \u2016w(t)\u2212 n\u03c0 \u2297 w\u0304(t)\u2016\u03c0\u22971d + n\u2016w\u0304(t)\u2212 w\u2217\u2016.\nThe proof is done.\nIn order to state the main convergence results, we set the following values:\n\u03b4 = max t\u2208N0 max 1\u2264i\u2264n\n1\nyi(t) and \u03c1 = \u03c3W (1 + \u03b1L\u03b4). (4.4)\nWe also set \u03b3 = \u03b2L\u03b2+L and\nD1 = \u03b4\u20161n \u2212 n\u03c0\u2016\u03c0 + \u221a\u221a\u221a\u221a n\u2211 j=1 1 \u03c0j\nD2 = L\u03b4\u20161n \u2212 n\u03c0\u2016\u03c0\u2016w\u2217\u2016+ \u2016\u2207F (1n \u2297 w\u2217)\u2016\u03c0\u22971d .\nIn the following result, we establish that the sequence {(At, Bt)}t\u22650 is bounded under a condition on the stepsize \u03b1 > 0.\nTheorem 4.2. Let b = n\u03b34L\u03b4 . Assume that (F1) and (F2) hold, and that \u03b1 > 0 satisfies\n\u03b1 \u2264 2 L+ \u03b2 and \u03b1 < b(1\u2212 \u03c3W ) L\u03c3W (\u03b4b+ \u03b4\u20161n \u2212 n\u03c0\u2016\u03c0 + \u221a\u2211n\nj=1 1 \u03c0j\n) (4.5)\nfor all t \u2265 0. Then the sequence {(At, Bt)}t\u2208N0 is uniformly bounded in time, i.e.,\nsup t\u22650 At <\u221e, sup t\u22650 Bt <\u221e.\nMore precisely, take a value t0 \u2208 N such that (L\u03b4/n)\u20161n \u2212 n\u03c0\u2016\u03c0\u03c3t0W \u2264 \u03b3/2 and define R > 0 as\nR = max { At0 ,\nBt0 b , 2\u2016w\u2217\u2016,\n\u03c3W\u03b1D2 b(1\u2212 \u03c3W )\u2212 \u03b1L\u03c3W (\u03b4b+ \u03b4\u20161n \u2212 n\u03c0\u2016\u03c0 + \u221a\u2211n\nj=1 1 \u03c0j )\n} .\nThen we have\nAt \u2264 R and Bt \u2264 bR\nfor all t \u2265 t0.\nWe mention that the above boundedness result may hold for a larger range of \u03b1 > 0 than that guaranteed by Theorem 4.2. We refer to [39, 9] for the discussion of this issue for the decentralized gradient method on undirected graph.\nNow we state the main convergence result for the gradient-push algorithm."
        },
        {
            "heading": "10 WOOCHEOL CHOI, DOHEON KIM, AND SEOK-BAE YUN",
            "text": "Theorem 4.3. Assume that (F1) and (F2) hold, and that \u03b1 > 0 satisfies \u03b1 \u2264 2L+\u03b2 and the sequence {At} is bounded, i.e., there exists R > 0 such that At \u2264 R for all t \u2265 0. Set R\u0304 = LD1R+ D2 > 0. Then for all t \u2265 0 we have\n\u2016w(t)\u2212 n\u03c0 \u2297 w\u0304(t)\u2016\u03c0\u22971d \u2264 \u03c1 t\u2016w(0)\u2212 n\u03c0 \u2297 w\u0304(0)\u2016\u03c0\u22971d +\n\u03b1\u03c3W R\u0304\n1\u2212 \u03c1 (4.6)\nand \u2016w\u0304(t)\u2212 w\u2217\u2016 \u2264 (1\u2212 \u03b3\u03b1)t\u2016w\u0304(0)\u2212 w\u2217\u2016+ \u03b1L\u03b4\nn \u2016w(0)\u2212 n\u03c0 \u2297 w\u0304(0)\u2016\u03c0\u22971dt\n[ max{1\u2212 \u03b3\u03b1, \u03c1} ]t\u22121 + \u03b1L\u03b4\nn \u20161n \u2212 n\u03c0\u2016\u03c0(\u2016w\u2217\u2016+R)t\n[ max{1\u2212 \u03b3\u03b1, e\u2212c} ]t\u22121 + \u03b1L\u03b4\nn\u03b3\n\u03c3W R\u0304 1\u2212 \u03c1 .\nThe above result establishes that w(t) converges exponentially fast to an O (\n\u03b1 1\u2212\u03c1\n) neigh-\nborhood of n\u03c0\u2297 w\u0304\u2217. In order to prove the above two results, we will derive two sequential inequalities of At and Bt in the next two sections. Based on those inequalities, we prove Theorem 4.2 in Section 7, and then establish the proof of Theorem 4.3 in Section 8.\n5. Weighted Consensus\nIn this section, we give an estimate of \u2016w(t+ 1)\u2212 (W\u221e \u2297 Id)w(t+ 1)\u2016\u03c0\u22971d in terms of \u2016w(t)\u2212 (W\u221e\u2297Id)w(t)\u2016\u03c0\u22971d and \u2016w\u0304(t)\u2212w\u2217\u2016. As a preliminary step, we bound a measure of the consensus for the variable z(t) in terms of w(t) in the following lemma.\nLemma 5.1. We have the following estimate\n\u2016z(t)\u22121n\u2297 w\u0304(t)\u2016\u03c0\u22971d \u2264 \u03b4\u2016w(t)\u2212n\u03c0\u2297 w\u0304(t)\u2016\u03c0\u22971d +\u03b4\u20161n \u2212 n\u03c0\u2016\u03c0\u03c3 t W ( \u2016w\u0304(t)\u2212w\u2217\u2016+\u2016w\u2217\u2016 ) .\nfor all t \u2208 N \u222a {0} and 1 \u2264 i \u2264 n.\nProof. Using the definition of z(t) in (2.2) and \u03b4 > 0 from (4.4), we find\n\u2016z(t)\u2212 1n \u2297 w\u0304(t)\u2016\u03c0\u22971d = [ n\u2211 j=1 1 \u03c0j (wj(t) yj(t) \u2212 w\u0304(t) )2]1/2\n\u2264 \u03b4 [ n\u2211 j=1 1 \u03c0j (wj(t)\u2212 yj(t)w\u0304(t))2 ]1/2 = \u03b4\u2016w(t)\u2212 y(t)\u2297 w\u0304(t)\u2016\u03c0\u22971d .\nBy applying the triangle inequality here, we get \u2016z(t)\u2212 1n \u2297 w\u0304(t)\u2016\u03c0\u22971d \u2264 \u03b4 ( \u2016w(t)\u2212 n\u03c0 \u2297 w\u0304(t)\u2016\u03c0\u22971d + \u2016(n\u03c0 \u2212 y(t))\u2297 w\u0304(t)\u2016\u03c0\u22971d ) . (5.1)\nHere we use (2.6) to estimate\n\u2016(n\u03c0 \u2212 y(t))\u2297 w\u0304(t)\u20162\u03c0\u22971d = n\u2211 j=1 1 \u03c0j ( n\u03c0j \u2212 yj(t) )2 \u2016w\u0304(t)\u20162\n= \u2016n\u03c0 \u2212 y(t)\u20162\u03c0\u2016w\u0304(t)\u20162 \u2264 \u20161n \u2212 n\u03c0\u20162\u03c0\u03c32tW \u2016w\u0304(t)\u20162.\n(5.2)\n11\nPutting this in (5.1) yields the following estimate\n\u2016z(t)\u22121n \u2297 w\u0304(t)\u2016\u03c0\u22971d \u2264 \u03b4\u2016w(t)\u2212 n\u03c0 \u2297 w\u0304(t)\u2016\u03c0\u22971d + \u03b4\u20161n \u2212 n\u03c0\u2016\u03c0\u03c3 t W \u2016w\u0304(t)\u2016\n\u2264 \u03b4\u2016w(t)\u2212 n\u03c0 \u2297 w\u0304(t)\u2016\u03c0\u22971d + \u03b4\u20161n \u2212 n\u03c0\u2016\u03c0\u03c3 t W ( \u2016w\u0304(t)\u2212 w\u2217\u2016+ \u2016w\u2217\u2016 ) .\nThe proof is done.\nWe are ready to establish the main estimate of this seciton.\nProposition 5.2. Assume that (F1) and (F2) hold, and that \u03ba(t) \u2265 1 for all t \u2265 0. Then we have\n\u2016w(t+ 1)\u2212 n\u03c0 \u2297 w\u0304(t+ 1)\u2016\u03c0\u22971d \u2264 \u03c3W (1 + \u03b1L\u03b4)\u2016w(t)\u2212 n\u03c0 \u2297 w\u0304(t)\u2016\u03c0\u22971d + \u03b1L\u03c3WD1[t]\u2016w\u0304(t)\u2212 w\u2217\u2016+ \u03b1\u03c3WD2[t], (5.3)\nwhere\nD1[t] = \u03b4\u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW + \u221a\u221a\u221a\u221a n\u2211 j=1 1 \u03c0j D2[t] = L\u03b4\u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW \u2016w\u2217\u2016+ \u2016\u2207F (1n \u2297 w\u2217)\u2016\u03c0\u22971d .\nProof. First we prove (5.3). Using the definition (2.3) and the relation (4.2), we proceed as follows.\n\u2016w(t+ 1)\u2212 (W\u221e \u2297 Id)w(t+ 1)\u2016\u03c0\u22971d = \u2016((In \u2212W\u221e)\u2297 Id)w(t+ 1)\u2016\u03c0\u22971d = \u2016[((In \u2212W\u221e)W )\u2297 Id]x(t)\u2016\u03c0\u22971d = \u2016[((In \u2212W\u221e)W )\u2297 Id](w(t)\u2212 \u03b1\u2207F (z(t)))\u2016\u03c0\u22971d\n(5.4)\nWe further manipulate this identity to have\n\u2016w(t+ 1)\u2212 (W\u221e \u2297 Id)w(t+ 1)\u2016\u03c0\u22971d = \u2016[(W \u2212W\u221e)\u2297 Id](w(t)\u2212 \u03b1\u2207F (z(t)))\u2016\u03c0\u22971d = \u2016[(W \u2212W\u221e)\u2297 Id][((In \u2212W\u221e)\u2297 Id)w(t)\u2212 \u03b1\u2207F (z(t))]\u2016\u03c0\u22971d ,\nwhere we have used W\u221eW = WW\u221e = (W\u221e)2 = W\u221e in the first and the second equalities. By the triangle inequality and Lemma 2.3, we estimate (5.4) as follows:\n\u2016w(t+ 1)\u2212 (W\u221e \u2297 Id)w(t+ 1)\u2016\u03c0\u22971d \u2264 |||(W \u2212W\u221e)\u2297 Id|||\u03c0\u22971d [\u2016((In \u2212W \u221e)\u2297 Id)w(t)\u2016\u03c0\u22971d + \u03b1\u2016\u2207F (z(t))\u2016\u03c0\u22971d ]\n= |||W \u2212W\u221e|||\u03c0 [\u2016w(t)\u2212 (W \u221e \u2297 Id)w(t)\u2016\u03c0\u22971d + \u03b1\u2016\u2207F (z(t))\u2016\u03c0\u22971d ] .\n(5.5)\nThis together with Lemma 2.2 gives\n\u2016w(t+ 1)\u2212 (W\u221e \u2297 Id)w(t+ 1)\u2016\u03c0\u22971d \u2264 \u03c3W \u2016w(t)\u2212 (W\u221e \u2297 Id)w(t)\u2016\u03c0\u22971d + \u03b1\u03c3W \u2016\u2207F (z(t))\u2016\u03c0\u22971d .\n(5.6)"
        },
        {
            "heading": "12 WOOCHEOL CHOI, DOHEON KIM, AND SEOK-BAE YUN",
            "text": "To estimate \u2016\u2207F (z(t))\u2016\u03c0\u22971d further, we write\n\u2207F (z(t)) = (\u2207F (z(t))\u2212\u2207F (1n \u2297 w\u0304(t)))\n+ (\u2207F (1n \u2297 w\u0304(t))\u2212\u2207F (1n \u2297 w\u2217)) +\u2207F (1n \u2297 w\u2217). (5.7)\nUsing Lemma 5.1 we have\n\u2016z(t)\u2212 1n \u2297 w\u0304(t)\u2016\u03c0\u22971d\n\u2264 \u03b4\u2016w(t)\u2212 n\u03c0 \u2297 w\u0304(t)\u2016\u03c0\u22971d + \u03b4\u20161n \u2212 n\u03c0\u2016\u03c0\u03c3 t W ( \u2016w\u0304(t)\u2212 w\u2217\u2016+ \u2016w\u2217\u2016 ) .\nCombining this with (5.7) yields\n\u2016\u2207F (z(t))\u2016\u03c0\u22971d \u2264 L\u2016z(t)\u2212 1n \u2297 w\u0304(t)\u2016\u03c0\u22971d + L\u20161n \u2297 w\u0304(t)\u2212 1n \u2297 w\u2217\u2016\u03c0\u22971d + \u2016\u2207F (1n \u2297 w\u2217)\u2016\u03c0\u22971d\n\u2264 L\u03b4\u2016w(t)\u2212 n\u03c0 \u2297 w\u0304(t)\u2016\u03c0\u22971d + L ( \u03b4\u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW + \u221a\u221a\u221a\u221a n\u2211 j=1 1 \u03c0j ) \u2016w\u0304(t)\u2212 w\u2217\u2016\n+ \u2016\u2207F (1n \u2297 w\u2217)\u2016\u03c0\u22971d + L\u03b4\u20161n \u2212 n\u03c0\u2016\u03c0\u03c3 t W \u2016w\u2217\u2016.\nPutting this estimate in (5.6) gives the following estimate\n\u2016w(t+ 1)\u2212 (W\u221e \u2297 Id)w(t+ 1)\u2016\u03c0\u22971d \u2264 \u03c3W (1 + \u03b1L\u03b4)\u2016(W\u221e \u2297 Id)w(t)\u2212 w(t)\u2016\u03c0\u22971d\n+ \u03b1L\u03c3W ( \u03b4\u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW + \u221a\u221a\u221a\u221a n\u2211 j=1 1 \u03c0j ) \u2016w\u0304(t)\u2212 w\u2217\u2016\n+ \u03b1\u03c3W ( L\u03b4\u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW \u2016w\u2217\u2016+ \u2016\u2207F (1n \u2297 w\u2217)\u2016\u03c0\u22971d ) .\nThe proof is done.\n6. Estimates on the distance between the average and the optimizer\nIn this section, we find an estimate of \u2016w\u0304(t + 1) \u2212 w\u2217\u2016 in terms of \u2016w\u0304(t) \u2212 w\u2217\u2016 and \u2016w(t) \u2212 (W\u221e \u2297 Id)w(t)\u2016\u03c0\u22971d . We begin with recalling a classical result in the following lemma (see e.g. [17]).\nLemma 6.1. Assume that f is \u03b2-strongly convex and L-smooth. Then\n\u3008\u2207f(x)\u2212\u2207f(y), x\u2212 y\u3009 \u2265 L\u03b2 L+ \u03b2 \u2016x\u2212 y\u20162 + 1 L+ \u03b2 \u2016\u2207f(x)\u2212\u2207f(y)\u20162\nholds for all x, y \u2208 Rd.\nNow we state the main result of this section.\nProposition 6.2. Assume that (F1) and (F2) hold, and f is \u03b2-strongly convex, and that \u03ba(t) \u2265 1 for all t \u2265 0. Let \u03b3 = \u03b2LL+\u03b2 \u2208 (0, 1). Then, for \u03b1 \u2208 ( 0, 2L+\u03b2 ] , we have the\n13\nfollowing estimates \u2016w\u0304(t+ 1)\u2212 w\u2217\u2016 \u2264 (\n1\u2212 \u03b3\u03b1+ \u03b1L\u03b4 n \u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW\n) \u2016w\u0304(t)\u2212 w\u2217\u2016\n+ \u03b1L\u03b4\nn \u2016(W\u221e \u2297 Id)w(t)\u2212 w(t)\u2016\u03c0\u22971d +\n\u03b1L\u03b4\nn \u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW \u2016w\u2217\u2016.\n(6.1)\nwhere w\u2217 is the minimizer of the problem (1.1).\nProof. From (2.3) we find\nw\u0304(t+ 1) = 1\nn (1>n \u2297 Id)w(t+ 1) =\n1 n (1>n \u2297 Id)(W \u2297 Id)x(t) = 1 n (1>n \u2297 Id)x(t)\n= 1\nn (1>n \u2297 Id)(w(t)\u2212 \u03b1\u2207F (z(t)))\n= w\u0304(t)\u2212 \u03b1 n n\u2211 i=1 \u2207fi(zi(t))\n= w\u0304(t)\u2212 \u03b1 n n\u2211 i=1 \u2207fi ( wi(t) yi(t) ) .\nLet us write the above term as\nw\u0304(t+ 1)\u2212 w\u2217 = w\u0304(t)\u2212 w\u2217 \u2212 \u03b1\nn n\u2211 i=1 \u2207fi(w\u0304(t)) + \u03b1 n n\u2211 i=1 ( \u2207fi(w\u0304(t))\u2212\u2207fi ( wi(t) yi(t) )) .\n(6.2)\nUsing Lemma 6.1, we have\n\u2016w\u0304(t)\u2212 w\u2217 \u2212 \u03b1\u2207f(w\u0304(t))\u20162\n= \u2016w\u0304(t)\u2212 w\u2217\u20162 \u2212 2\u03b1\u3008w\u0304(t)\u2212 w\u2217, \u2207f(w\u0304(t))\u3009+ \u03b12\u2016\u2207f(w\u0304(t))\u20162 \u2264 \u2016w\u0304(t)\u2212 w\u2217\u20162 \u2212 2\u03b1\u03b2L\nL+ \u03b2 \u2016w\u0304(t)\u2212 w\u2217\u20162 \u2212\n2\u03b1\nL+ \u03b2 \u2016\u2207f(w\u0304(t))\u20162 + \u03b12\u2016\u2207f(w\u0304(t))\u20162.\nSince \u03b1 \u2264 2L+\u03b2 , the above inequality gives\n\u2016w\u0304(t)\u2212 w\u2217 \u2212 \u03b1\u2207f(w\u0304(t))\u20162 \u2264 (\n1\u2212 2\u03b1\u03b2L L+ \u03b2\n) \u2016w\u0304(t)\u2212 w\u2217\u20162\n\u2264 (\n1\u2212 \u03b1\u03b2L L+ \u03b2\n)2 \u2016w\u0304(t)\u2212 w\u2217\u20162.\nHence we have \u2225\u2225\u2225\u2225\u2225w\u0304(t)\u2212 w\u2217 \u2212 \u03b1n n\u2211 i=1 \u2207fi(w\u0304(t)) \u2225\u2225\u2225\u2225\u2225 \u2264 (1\u2212 \u03b3\u03b1)\u2016w\u0304(t)\u2212 w\u2217\u2016, (6.3) where \u03b3 = \u03b2LL+\u03b2 \u2208 (0, 1). In order to esimate the right-most term of (6.2), we use (4.1) to have \u2225\u2225\u2225\u2225\u2225\u03b1n n\u2211 i=1 ( \u2207fi(w\u0304(t))\u2212\u2207fi ( wi(t) yi(t) ))\u2225\u2225\u2225\u2225\u2225 \u2264 \u03b1Ln n\u2211 i=1 \u2225\u2225\u2225\u2225w\u0304(t)\u2212 wi(t)yi(t) \u2225\u2225\u2225\u2225 , (6.4)"
        },
        {
            "heading": "14 WOOCHEOL CHOI, DOHEON KIM, AND SEOK-BAE YUN",
            "text": "whose right hand side is estimated as\nn\u2211 i=1 \u2225\u2225\u2225w\u0304(t)\u2212 wi(t) yi(t) \u2225\u2225\u2225 \u2264 ( n\u2211 i=1 \u03c0i )1/2( n\u2211 i=1 1 \u03c0i \u2225\u2225\u2225w\u0304(t)\u2212 wi(t) yi(t) \u2225\u2225\u22252)1/2 = \u20161n \u2297 w\u0304(t)\u2212 z(t)\u2016\u03c0\u22971d .\nGathering the estimates (6.3) and (6.4) in (6.2) we find\n\u2016w\u0304(t+ 1)\u2212 w\u2217\u2016 \u2264 (1\u2212 \u03b3\u03b1)\u2016w\u0304(t)\u2212 w\u2217\u2016+ \u03b1L\nn \u20161n \u2297 w\u0304(t)\u2212 z(t)\u2016\u03c0\u22971d .\nCombining this with Lemma 5.1 gives the following estimate \u2016w\u0304(t+ 1)\u2212 w\u2217\u2016 \u2264 (\n1\u2212 \u03b3\u03b1+ \u03b1L\u03b4 n \u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW\n) \u2016w\u0304(t)\u2212 w\u2217\u2016\n+ \u03b1L\u03b4\nn \u2016(W\u221e \u2297 Id)w(t)\u2212 w(t)\u2016\u03c0\u22971d +\n\u03b1L\u03b4\nn \u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW \u2016w\u2217\u2016.\nThe proof is done.\n7. Uniform boundedness of the sequence\nNow we shall use the recursive estimates of the previous sections to establish the uniform boundedness property of the sequence {wk(t)}. For the proof, we recall the estimates of the sequences At = \u2016w\u0304(t)\u2212w\u2217\u2016 and Bt = \u2016(W\u221e\u2297 Id)w(t)\u2212w(t)\u2016\u03c0\u22971d given by Propositions 5.2 and 6.2:\nAt+1 \u2264 (1\u2212 \u03b3\u03b1+ \u03b1L\u03b4\nn \u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW )At +\n\u03b1L\u03b4\nn Bt +\n\u03b1L\u03b4\nn \u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW \u2016w\u2217\u2016 (7.1)\nand\nBt+1 \u2264 \u03c3W (1 + \u03b1L\u03b4)Bt + \u03c3W (\u03b1L)D1At + \u03b1\u03c3WD2, (7.2)\nwhere D1 = D1[0] and D2 = D2[0]. Now we establish the uniform boundedness result of the sequence {(At, Bt)}t\u2208N0 .\nProof of Theorem 4.2. Take a value t0 \u2208 N such that for t \u2265 t0 we have (L\u03b4/n)\u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW \u2264 \u03b3/2. Choose R > 0 as\nR = max { At0 ,\nBt0 b , 2\u2016w\u2217\u2016,\n\u03c3W\u03b1D2 b(1\u2212 \u03c3W )\u2212 \u03b1L\u03c3W (\u03b4b+ \u03b4\u20161n \u2212 n\u03c0\u2016\u03c0 + \u221a\u2211n\nj=1 1 \u03c0j )\n} .\nBy an inductive argument, we will show that\nAt \u2264 R and Bt \u2264 bR (7.3)\nfor all t \u2265 t0. Assume that At \u2264 R and Bt \u2264 bR for some t \u2265 t0. Then we use (7.1) to deduce\nAt+1 \u2264 (1\u2212 \u03b3\u03b1/2)R+ \u03b1L\u03b4\nn bR+\n\u03b1L\u03b4\nn \u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW \u2016w\u2217\u2016\n= ( 1\u2212 ( \u03b3/2\u2212 (L\u03b4/n)b ) \u03b1 ) R+ \u03b3\u03b1\n2 \u00b7 R 2\n= R.\n15\nNext we estimate Bt+1 using (7.2) as\nBt+1 \u2264 \u03c3W (1 + \u03b1L\u03b4)bR+ \u03c3W\u03b1LD1R+ \u03c3W\u03b1D2\n\u2264 \u03c3W (1 + \u03b1L\u03b4)bR+ \u03c3W\u03b1L ( \u03b4\u20161n \u2212 n\u03c0\u2016\u03c0 + \u221a\u221a\u221a\u221a n\u2211 j=1 1 \u03c0j ) R+ \u03c3W\u03b1D2\n\u2264 bR.\nThe proof is done.\n8. Convergence estimates\nIn this section, we prove the main convergence result of the gradient-push algorithm stated in Theorem 4.3. For this aim, we prepare the following two basic lemmas to analyze further the sequential estimates (7.1) and (7.2) of At and Bt.\nLemma 8.1. Assume that a sequence {Yt}t\u22650 \u2282 R satisfies\nYt+1 \u2264 (1\u2212 \u03b1)Yt + C \u2200t \u2265 0 (8.1)\nfor some C > 0 and \u03b1 \u2208 (0, 1). Then we have\nYt \u2264 (1\u2212 \u03b1)tY0 + C\n\u03b1 .\nProof. Using (8.1) iteratively, we have\nYt \u2264 (1\u2212 \u03b1)tY0 + C t\u22121\u2211 k=0 (1\u2212 \u03b1)k.\n\u2264 (1\u2212 \u03b1)tY0 + C\n\u03b1 ,\nwhich proves the lemma.\nLemma 8.2. Assume that a sequence {Yt}t\u22650 \u2282 R satisfies\nYt+1 \u2264 (1\u2212 \u03b1)Yt + C\u03c1t \u2200t \u2265 0 (8.2)\nfor some C > 0, \u03b1 \u2208 (0, 1) and \u03c1 \u2208 (0, 1). Then we have\nYt \u2264 (1\u2212 \u03b1)tY0 + Ct (max{1\u2212 \u03b1, \u03c1})t\u22121 .\nProof. Making use of (8.2) recursively, we find\nYt \u2264 (1\u2212 \u03b1)tY0 + C t\u22121\u2211 k=0 (1\u2212 \u03b1)k\u03c1t\u22121\u2212k\n\u2264 (1\u2212 \u03b1)tY0 + C t\u22121\u2211 k=0 (max{1\u2212 \u03b1, \u03c1})t\u22121 = (1\u2212 \u03b1)tY0 + Ct (max{1\u2212 \u03b1, \u03c1})t\u22121 .\nThe proof is done.\nNow we are ready to establish the main convergence result."
        },
        {
            "heading": "16 WOOCHEOL CHOI, DOHEON KIM, AND SEOK-BAE YUN",
            "text": "Proof of Theorem 4.3. Let R := supt\u22650At. By (7.2), we get\nBt+1 \u2264 \u03c3W (1 + \u03b1L)Bt + \u03c3W (\u03b1L)D1R+ \u03b1\u03c3WD2 \u2264 \u03c1Bt + \u03b1\u03c3W R\u0304 for all t \u2265 0,\nwhere we have let \u03c1 = \u03c3W (1 + \u03b1L) and R\u0304 = LD1R+ D2. Using this we obtain Bt \u2264 \u03c1tB0 + ( \u03c1t\u22121 + \u03c1t\u22122 + \u00b7 \u00b7 \u00b7+ 1 ) \u03b1\u03c3W R\u0304\n\u2264 \u03c1tB0 + \u03b1\u03c3W R\u0304\n1\u2212 \u03c1 ,\nwhich proves (4.6). Using this inequality in (7.1) we have\nAt+1 \u2264 (1\u2212 \u03b3\u03b1)At + \u03b1L\u03b4\nn \u03c1tB0 + \u03b1\n2L\u03b4\nn\n\u03c3W R\u0304 1\u2212 \u03c1 + \u03b1L\u03b4 n \u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW (\u2016w\u2217\u2016+R).\nTo analyze this inequality, we consider three sequences A1t , A 2 t , A 3 t such that for t \u2265 0,\nA1t+1 = (1\u2212 \u03b3\u03b1)A1t + \u03b12 L\u03b4\nn\n\u03c3W R\u0304 1\u2212 \u03c1\nA2t+1 = (1\u2212 \u03b3\u03b1)A2t + \u03b1L\u03b4\nn \u03c1tB0\nA3t+1 = (1\u2212 \u03b3\u03b1)A3t + \u03b1L\u03b4\nn \u20161n \u2212 n\u03c0\u2016\u03c0\u03c3tW (\u2016w\u2217\u2016+R),\nwith initial values A10 = A0, A 2 0 = 0, and A 3 0 = 0. We use Lemma 8.1 and Lemma 8.2 to analyze these sequences to find\nA1t \u2264 (1\u2212 \u03b3\u03b1)tA0 + \u03b1L\u03b4\nn\u03b3\n\u03c3W R\u0304 1\u2212 \u03c1\nA2t \u2264 \u03b1L\u03b4 n B0t [ max{1\u2212 \u03b3\u03b1, \u03c1} ]t\u22121 A3t \u2264 \u03b1L\u03b4\nn \u20161n \u2212 n\u03c0\u2016\u03c0(\u2016w\u2217\u2016+R)t\n[ max{1\u2212 \u03b3\u03b1, e\u2212c} ]t\u22121 .\nCollecting the above estimates, we get\nAt \u2264 (1\u2212 \u03b3\u03b1)tA0 + \u03b1L\u03b4 n B0t [ max{1\u2212 \u03b3\u03b1, \u03c1} ]t\u22121\n+ \u03b1L\u03b4\nn \u20161n \u2212 n\u03c0\u2016\u03c0(\u2016w\u2217\u2016+R)t\n[ max{1\u2212 \u03b3\u03b1, e\u2212c} ]t\u22121 + \u03b1L\u03b4\nn\u03b3\n\u03c3W R\u0304 1\u2212 \u03c1 .\nThe proof is done.\n9. Numerical experiments\nHere we provide numerical results for the gradient-push algorithm (2.2) that support our theoretical convergence result. For all experiments, we set xi(0) = 1d (i = 1, . . . , n), d = 5, n = 10, and generated a random directed graph G with n vertices by letting each possible arc to occur independently with probability p = 0.7, except for the self-loops, which must exist with probability 1. Then the matrix W would be naturally determined by (2.1). In the first example, we consider the least square parameter estimation problem\n17\nwhere each cost is convex. In the second example, we consider local cost of the form fj(x) = 1 2x TAjx+B T j x where Aj may not be a positive semidefinite matrix.\n9.1. Convex local cost case. We consider the least square parameter estimation problem\nf(x) = 1\n2n n\u2211 j=1 \u2016Ajx\u2212 bj\u20162.\nHere Aj and bj are 3 \u00d7 d, 3 \u00d7 1 matrices respectively, with i.i.d. entries drawn from the standard normal distribution. It is well known that the minimizer of f is given by\nx\u2217 = ( n\u2211 j=1 A>j Aj )\u22121 n\u2211 j=1 A>j bj . Figure 1 shows the graph of n\u2211 i=1 \u2016zi(t)\u2212 x\u2217\u20162 with respect to the iteration t, for \u03b1 = 10\u22121, 10\u22122, 10\u22123, 10\u22124. As expected, the limiting error seems to be proportional to the value of \u03b1.\n9.2. Nonconvex local cost case. Here we consider the following problem\nf(x) = 1\nn n\u2211 j=1 fj(x),\nwhere fj(x) = 1 2x T (I + Cj)x + d T j x. Here Cj is a symmetric d \u00d7 d matrix and dj \u2208 Rd for each 1 \u2264 j \u2264 n, with i.i.d. entries(excluding the pairs that must be equal because of the symmetry condition) drawn from the standard normal distribution. If the resulting f is not convex, then all random entries are sampled again. The minimizer of f is given\nby x\u2217 = \u2212 (\u2211N j=1(I + Cj) )\u22121\u2211N j=1 dj . Figure 2 shows the graph of n\u2211 i=1 \u2016zi(t)\u2212 x\u2217\u20162 with respect to the iteration t, for \u03b1 = 10\u22121, 10\u22122, 10\u22123, 10\u22124. Although our analysis does not treat the case where some fj may not be convex, the limiting error seems to be proportional to the value of \u03b1.\nAcknowledgments\nThe work of Woocheol Choi was supported by the National Research Foundation of Korea NRF- 2016R1A5A1008055 and Grant NRF-2021R1F1A1059671. The work of Doheon Kim was supported by the National Research Foundation of Korea(NRF) grant funded by the Korea government(MSIT) (No. RS-2022-00166699). Doheon Kim is grateful for"
        },
        {
            "heading": "18 WOOCHEOL CHOI, DOHEON KIM, AND SEOK-BAE YUN",
            "text": "support by the Open KIAS Center at Korea Institute for Advanced Study. The work of Seok-Bae Yun was supported by Samsung Science and Technology Foundation under Project Number SSTF-BA1801-02.\nReferences\n[1] P. A. Forero, A. Cano, and G. B. Giannakis, \u201c\u201dConsensus-based distributed support vector ma-\nchines,\u201d\u201d Journal of Machine Learning Research, vol. 11, pp. 1663\u20141707, 2010.\n[2] H. Raja and W. U. Bajwa, \u201c\u201dCloud K-SVD: A collaborative dictionary learning algorithm for big,\ndistributed data,\u201d\u201d IEEE Transactions on Signal Processing, vol. 64, no. 1, pp. 173\u2014188, Jan. 2016. [3] T. Yang, X. Yi, J. Wu, Y. Yuan, D. Wu, Z. Meng, Y. Hong, H. Wang, Z. Lin, and K. H. Johansson,\n\u201c\u201dA survey of distributed optimization,\u201d\u201d Annual Reviews in Control, vol. 47, pp. 278 \u2014 305, 2019.\n[4] L. Bottou, F. E. Curtis, and J. Nocedal, \u201c\u201dOptimization methods for large-scale machine learning,\u201d\u201d\nSIAM Review, vol. 60, no. 2, pp. 223\u2014311, 2018.\n[5] Bullo, F., Cortes, J., Martinez, S.: Distributed Control of Robotic Networks: A Mathematical Ap-\nproach to Motion Coordination Algorithms, vol. 27. Princeton University Press, Princeton (2009)\n[6] W. Ren, Consensus Based Formation Control Strategies for Multi-Vehicle Systems, in Proceedings of\nthe Amer-ican Control Conference, 2006, pp. 4237\u20144242.\n[7] Y. Cao, W. Yu, W. Ren, and G. Chen, An overview of recent progress in the study of distributed\nmulti-agent coordination, IEEE Trans Ind. Informat., 9 (2013), pp. 427\u2013438\n[8] W. Choi, D. Kim, S. Yun, Convergence results of a nested decentralized gradient method for non-\nstrongly convex problems. J. Optim. Theory Appl. 195 (2022), no. 1, 172\u2013204.\n[9] W. Choi, J. Kim, On the convergence of decentralized gradient descent with diminishing stepsize,\nrevisited, arXiv:2203.09079.\n[10] G. B. Giannakis, V. Kekatos, N. Gatsis, S.-J. Kim, H. Zhu, and B. Wollenberg, Mon-itoring and\noptimization for power grids: A signal processing perspective, IEEE Signal Processing Mag., 30 (2013), pp. 107\u2013128, [11] V. Kekatos and G. B. Giannakis, Distributed robust power system state estimation, IEEE Trans.\nPower Syst., 28 (2013), pp. 1617\u20131626,\n[12] K. I. Tsianos, S. Lawlor, and M. G. Rabbat, Consensus-based distributed optimization: Practical\nissues and applications in large-scale machine learning, in Proceedings of the IEEE Allerton Conference on Communication, Control, and Computing, IEEE, New York, 2012, pp. 1543\u20131550, [13] M. Akbari, B. Gharesifard, and T. Linder, \u201cDistributed online convex optimization on time-varying\ndirected graphs,\u201d IEEE Trans. Control Netw. Syst., vol. 4, no. 3, pp. 417\u2013428, Sep. 2017.\n[14] M. Assran, N. Loizou, N. Ballas, and M. Rabbat, \u201cStochastic gradient push for distributed deep\nlearning,\u201d in 36th International Conference on Machine Learning. Jun. 2019, vol. 97, pp. 344\u2013353, PMLR.\n19\n[15] Bazerque, J.A., Giannakis, G.B.: Distributed spectrum sensing for cognitive radio networks by ex-\nploiting sparsity. IEEE Trans. Signal Process. 58(3), 1847\u20131862 (2010)\n[16] Berahas, A.S., Bollapragada, R., Keskar, N.S., Wei, E.: Balancing communication and computation\nin distributed optimization. IEEE Trans. Autom. Control 64(8), 3141\u20133155 (2018)\n[17] S. Bubeck. Convex optimization: Algorithms and complexity. Foundations and Trends in Machine\nLearning, 8(3\u20134):231\u2013357, 2015.\n[18] A. I. Chen and A. Ozdaglar, \u201cA fast distributed proximal-gradient method,\u201d in Communication, Con-\ntrol, and Computing (Allerton), 2012 50th Annual Allerton Conference on. IEEE, 2012, pp. 601\u2013608. [19] D. Jakovetic, J. Xavier, and J. M. F. Moura, \u201cFast Distributed Gradient Methods,\u201d IEEE Transactions\non Automatic Control, vol. 59, no. 5, pp. 1131\u20131146, 2014.\n[20] D. Kempe, A. Dobra, and J. Gehrke, \u201c\u201dGossip-based computation [21] J. Kim, W. Choi, Gradient-push algorithm for distributed optimization with event-triggered commu-\nnications, IEEE Access, vol. 11, pp. 517-534, 2023\n[22] J. Li, C. Gu, Z. Wu Online distributed stochastic learning algorithm for convex optimization in time-\nvarying directed networks , Neurocomputing 416 (2020) 85\u201394\n[23] A. Nedic\u0301 and A. Ozdaglar, \u201cDistributed subgradient methods for multi-agent optimization,\u201d IEEE\nTransactions on Automatic Control, vol. 54, no. 1, pp. 48, 2009.\n[24] A. Nedic\u0301 and A. Olshevsky, \u201cStochastic gradient-push for strongly convex functions on time-varying\ndirected graphs,\u201d IEEE Transactions on Automatic Control, vol. 61, no. 12, pp. 3936\u20133947, 2016.\n[25] A. Nedic\u0301 and A. Olshevsky, \u201cDistributed optimization over time-varying directed graphs,\u201d IEEE\nTransactions on Automatic Control, vol. 60, no. 3, pp. 601\u2013615, 2014.\n[26] A. Nedic\u0301, A. Olshevsky, and W. Shi, \u201cAchieving geometric convergence for distributed optimization\nover time-varying graphs,\u201d SIAM Journal on Optimization, vol. 27, no. 4, pp. 2597\u20132633, 2017.\n[27] G. Qu and N. Li, \u201cHarnessing smoothness to accelerate distributed optimization,\u201d IEEE Transactions\non Control of Network Systems, vol. 5, no. 3, pp. 1245\u20131260, 2018.\n[28] A. H. Sayed, Diffusion adaptation over networks. Academic Press Library in Signal Processing, 2013,\nvol. 3.\n[29] Schizas, I.D., Giannakis, G.B., Roumeliotis, S.I., Ribeiro, A.: Consensus in ad hoc WSNs with noisy\nlinks\u2014part II: distributed estimation and smoothing of random signals. IEEE Trans. Signal Process. 56(4), 1650\u20131666 (2008)\n[30] E. Seneta. Non-negative matrices and Markov chains, 2nd Ed. Springer-Verlag New York (1981). [31] W. Shi, Q. Ling, G. Wu, W. Yin, Extra: an exact first-order algorithm for decentralized consensus\noptimization. SIAM J. Optim. 25(2), 944\u2013966 (2015)\n[32] W. Shi, Q. Ling, K. Yuan, G. Wu, W. Yin, On the linear convergence of theADMMin decentralized\nconsensus optimization. IEEE Trans. Signal Process. 62(7), 1750\u20131761 (2014)\n[33] T. Tatarenko, B. Touri, Non-convex distributed optimization. IEEE Trans. Automat. Control 62\n(2017), no. 8, 3744\u20133757.\n[34] K. Tsianos, S. Lawlor, and M. G. Rabbat, \u201dCommunication/computation tradeoffs in consensus-based\ndistributed optimization,\u201d in Proc. Adv. Neural Inf. Process. Syst., 2012, pp. 1943\u20131951\n[35] K. I. Tsianos, S. Lawlor, and M. G. Rabbat, \u201c\u201dPush-sum distributed dual averaging for convex\noptimization,\u201d\u201d in Proc. IEEE Conf. Dec. Control, Maui, HI, USA, 2012, pp. 5453\u20145458.\n[36] C. Xi and U. A. Khan, \u201cDEXTRA: A fast algorithm for optimization over directed graphs,\u201d IEEE\nTransactions on Automatic Control, vol. 62, no. 10, pp. 4980\u20134993, Oct. 2017.\n[37] R. Xin, A. K. Sahu, U. A. Khan, and S. Kar, \u201cDistributed stochastic optimization with gradient\ntracking over strongly-connected networks,\u201d in 58th IEEE Conference on Decision and Control, Dec. 2019, pp. 8353\u20138358. [38] R. Xin and U. A. Khan, \u201cA linear algorithm for optimization over directed graphs with geometric\nconvergence,\u201d IEEE Control Systems Letters, vol. 2, no. 3, pp. 315\u2013320, 2018."
        },
        {
            "heading": "20 WOOCHEOL CHOI, DOHEON KIM, AND SEOK-BAE YUN",
            "text": "[39] K. Yuan, Q. Ling, and W. Yin, \u201cOn the convergence of decentralized gradient descent,\u201d SIAM Journal\non Optimization, vol. 26, no. 3, pp. 1835\u20131854, Sep. 2016.\n[40] D. Yuan, S. Xu, J. Lu, Gradient-free method for distributed multi-agent optimization via push-sum\nalgorithms, Internat. J. Robust Nonlinear Control 25 (2015), no. 10, 1569\u20131580.\n[41] H. Taheri, A. Mokhtari, H. Hassani, and R. Pedarsani, Quantized decentralized stochastic learning\nover directed graphs. In International Conference on Machine Learning, 2020.\n[42] J. Li, C. Gu, Z. Wu, Online distributed stochastic learning algorithm for convex optimization in\ntime-varying directed networks, Neurocomputing (2019).\n[43] T. Yang et al., \u201dA Distributed Algorithm for Economic Dispatch Over Time-Varying Directed Net-\nworks With Delays,\u201d in IEEE Transactions on Industrial Electronics, vol. 64, no. 6, pp. 5095-5106, June 2017. [44] M. S. Assran and M. G. Rabbat, \u201dAsynchronous Gradient Push,\u201d in IEEE Transactions on Automatic\nControl, vol. 66, no. 1, pp. 168-183, Jan. 2021.\n[45] W. Yu, H. Liu, W. Zheng, Y. Zhu, Distributed discrete-time convex optimization with nonidentical\nlocal constraints over time-varying unbalanced directed graphs. Automatica J. IFAC 134 (2021).\n[46] M. Akbari, B. Gharesifard and T. Linder, \u201dDistributed Online Convex Optimization on Time-Varying\nDirected Graphs,\u201d in IEEE Transactions on Control of Network Systems, vol. 4, no. 3, pp. 417-428, Sept. 2017. [47] C. Wang, S. Xu, D. Yuan, B. Zhang and Z. Zhang, \u201dPush-Sum Distributed Online Optimization With\nBandit Feedback,\u201d in IEEE Transactions on Cybernetics, vol. 52, no. 4, pp. 2263-2273, April 2022.\nDepartment of Mathematics, Sungkyunkwan University, Suwon 440-746, Republic of Ko-\nrea\nEmail address: choiwc@skku.edu\nDepartment of Applied Mathematics, Hanyang University, Hanyangdaehak-ro 55, Sangnok-\ngu, Ansan, Gyeonggi-do 15588, Republic of Korea\nEmail address: doheonkim@hanyang.ac.kr\nDepartment of Mathematics, Sungkyunkwan University, Suwon 440-746, Republic of Ko-\nrea\nEmail address: sbyun01@skku.edu"
        }
    ],
    "title": "ON THE CONVERGENCE RESULT OF THE GRADIENT-PUSH ALGORITHM ON DIRECTED GRAPHS WITH CONSTANT STEPSIZE",
    "year": 2023
}