{
    "abstractText": "ASMR (Autonomous Sensory Meridian Response) has grown to immense popularity on YouTube and drawn HCI designers\u2019 attention to its effects and applications in design. YouTube ASMR creators incorporate visual elements, sounds, motifs of touching and tasting, and other scenarios in multisensory video interactions to deliver enjoyable and relaxing experiences to their viewers. ASMRtists engage viewers by social, physical, and task attractions. Research has identified the benefits of ASMR in mental wellbeing. However, ASMR remains an understudied phenomenon in the HCI community, constraining designers\u2019 ability to incorporate ASMR in video-based designs. This work annotates and analyzes the interaction modalities and parasocial attractions of 2663 videos to identify unique experiences. YouTube comment sections are also analyzed to compare viewers\u2019 responses to different ASMR interactions. We find that ASMR videos are experiences of multimodal social connection, relaxing physical intimacy, and sensory-rich activity observation. Design implications are discussed to foster future ASMR-augmented video interactions.",
    "authors": [
        {
            "affiliations": [],
            "name": "Shuo Niu"
        },
        {
            "affiliations": [],
            "name": "Hugh S. Manon"
        },
        {
            "affiliations": [],
            "name": "Ava Bartolome"
        },
        {
            "affiliations": [],
            "name": "Nguyen B. Ha"
        },
        {
            "affiliations": [],
            "name": "Keegan Veazey"
        }
    ],
    "id": "SP:9eeb1c5c8daf211060c62664a80c1dede3c4f621",
    "references": [
        {
            "authors": [
                "Nitin K Ahuja"
            ],
            "title": "It feels good to be measured\": clinical role-play, Walker Percy, and the tingles",
            "venue": "Perspectives in biology and medicine 56,",
            "year": 2013
        },
        {
            "authors": [
                "Muhammad Abubakar Alhassan",
                "Diane Pennington"
            ],
            "title": "Detecting Critical Responses from Deliberate Self-Harm Videos on YouTube. In Proceedings of the 2020 Conference on Human Information Interaction and Retrieval (CHIIR \u201920)",
            "venue": "Association for Computing Machinery,",
            "year": 2020
        },
        {
            "authors": [
                "Joceline Andersen"
            ],
            "title": "Now You\u2019ve Got the Shiveries: Affect, Intimacy, and the ASMR Whisper Community",
            "venue": "Television & New Media 16,",
            "year": 2014
        },
        {
            "authors": [
                "Laurensia Anjani",
                "Terrance Mok",
                "Anthony Tang",
                "Lora Oehlberg",
                "Wooi Boon Goh"
            ],
            "title": "Why Do People Watch Others Eat Food? An Empirical Study on the Motivations and Practices of Mukbang Viewers",
            "venue": "In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI \u201920)",
            "year": 2020
        },
        {
            "authors": [
                "Emma L Barratt",
                "Nick J Davis"
            ],
            "title": "Autonomous Sensory Meridian Response (ASMR): a flow-like mental state",
            "venue": "PeerJ",
            "year": 2015
        },
        {
            "authors": [
                "Emma L Barratt",
                "Charles Spence",
                "Nick J Davis"
            ],
            "title": "Sensory determinants of the autonomous sensory meridian response (ASMR): understanding the triggers",
            "venue": "PeerJ 5 (2017),",
            "year": 2017
        },
        {
            "authors": [
                "Ava Bartolome",
                "Nguyen Binh Ha",
                "Shuo Niu"
            ],
            "title": "Investigating Multimodal Interactions and Parasocial Attractiveness in YouTube ASMR Videos",
            "venue": "In Companion Publication of the 2021 Conference on Computer Supported Cooperative Work and Social Computing (CSCW \u201921)",
            "year": 2021
        },
        {
            "authors": [
                "Gerlof Bouma"
            ],
            "title": "Normalized (pointwise) mutual information in collocation extraction",
            "venue": "Proceedings of GSCL",
            "year": 2009
        },
        {
            "authors": [
                "Jean Burgess"
            ],
            "title": "YouTube and the formalisation of amateur media",
            "venue": "In Amateur Media",
            "year": 2012
        },
        {
            "authors": [
                "Jean Burgess",
                "Joshua Green"
            ],
            "title": "YouTube: Online video and participatory culture",
            "year": 2018
        },
        {
            "authors": [
                "Sean. Cannell",
                "Benji. Travis"
            ],
            "title": "YouTube secrets : the ultimate guide to growing your following and making money as a video influencer",
            "venue": "Lioncrest Publishing",
            "year": 2018
        },
        {
            "authors": [
                "Harry Cheadle"
            ],
            "title": "ASMR, the Good Feeling no one can Explain",
            "venue": "VICE. http://www. vice. com/read/asmr-the-good-feeling-no-one-can-explain (accessed October",
            "year": 2012
        },
        {
            "authors": [
                "Munmun De Choudhury",
                "Michael Gamon",
                "Scott Counts",
                "Eric Horvitz"
            ],
            "title": "Predicting depression via social media",
            "venue": "Icwsm",
            "year": 2013
        },
        {
            "authors": [
                "Jialin Deng",
                "Yan Wang",
                "Carlos Velasco",
                "Rob Comber",
                "Marianna Obrist",
                "Katherine Isbister",
                "Charles Spence",
                "Florian \u2019Floyd\u2019 Mueller"
            ],
            "title": "The Future of Human-Food Interaction",
            "venue": "In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. Association for Computing Machinery,",
            "year": 2021
        },
        {
            "authors": [
                "Yvonne D Eaves"
            ],
            "title": "A synthesis technique for grounded theory data analysis",
            "venue": "Journal of Advanced Nursing 35,",
            "year": 2001
        },
        {
            "authors": [
                "Ethan Fast",
                "Binbin Chen",
                "Michael S Bernstein"
            ],
            "title": "Empath: Understanding Topic Signals in Large-Scale Text",
            "venue": "In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI \u201916)",
            "year": 2016
        },
        {
            "authors": [
                "Beverley Fredborg",
                "Jim Clark",
                "Stephen D Smith"
            ],
            "title": "An Examination of Personality Traits Associated with Autonomous Sensory Meridian Response (ASMR)",
            "venue": "Frontiers in Psychology",
            "year": 2017
        },
        {
            "authors": [
                "Beverley K Fredborg",
                "James M Clark",
                "Stephen D Smith"
            ],
            "title": "Mindfulness and autonomous sensory meridian response (ASMR)",
            "venue": "PeerJ",
            "year": 2018
        },
        {
            "authors": [
                "Rob Gallagher"
            ],
            "title": "Eliciting Euphoria Online: The Aesthetics of \u201cASMR",
            "venue": "Video Culture. FILM CRITICISM 40,",
            "year": 2016
        },
        {
            "authors": [
                "Yumei Gan"
            ],
            "title": "Capturing love at a distance: Multisensoriality in intimate video calls between migrant parents and their left-behind children",
            "venue": "Social Interaction. Video-Based Studies of Human Sociality 4,",
            "year": 2021
        },
        {
            "authors": [
                "David C Giles"
            ],
            "title": "Parasocial Interaction: A Review of the Literature and a Model for Future Research",
            "venue": "Media Psychology 4,",
            "year": 2002
        },
        {
            "authors": [
                "Paula Clare Harper"
            ],
            "title": "ASMR: bodily pleasure, online performance, digital modality",
            "venue": "Sound Studies 6,",
            "year": 2020
        },
        {
            "authors": [
                "Tilo Hartmann"
            ],
            "title": "Parasocial interaction, parasocial relationships, and wellbeing. In The Routledge handbook of media use and well-being: International perspectives on theory and research on positive media effects",
            "year": 2017
        },
        {
            "authors": [
                "Marc Hassenzahl"
            ],
            "title": "Experience Design: Technology for All the Right Reasons",
            "venue": "Synthesis Lectures on Human-Centered Informatics",
            "year": 2010
        },
        {
            "authors": [
                "Donald Horton",
                "R Richard Wohl"
            ],
            "title": "Mass Communication and Para-Social Interaction",
            "venue": "Psychiatry 19,",
            "year": 1956
        },
        {
            "authors": [
                "Mu Hu",
                "Mingli Zhang",
                "Nuan Luo"
            ],
            "title": "Understanding participation on video sharing communities: The role of self-construal and community interactivity",
            "venue": "Computers in Human Behavior",
            "year": 2016
        },
        {
            "authors": [
                "Agnieszka B Janik McErlean",
                "Michael J Banissy"
            ],
            "title": "Assessing Individual Variation in Personality and Empathy Traits in Self-Reported Autonomous Sensory Meridian Response",
            "venue": "Multisensory Research 30,",
            "year": 2017
        },
        {
            "authors": [
                "Isabel L Kampmann",
                "Paul M G Emmelkamp",
                "Nexhmedin Morina"
            ],
            "title": "Metaanalysis of technology-assisted interventions for social anxiety disorder",
            "venue": "Journal of Anxiety Disorders",
            "year": 2016
        },
        {
            "authors": [
                "Ryan M Kelly",
                "Yueyang Cheng",
                "Dana McKay",
                "GregWadley",
                "George Buchanan"
            ],
            "title": "It\u2019s About MissingMuchMore Than the People\u201d: How Students Use Digital Technologies to Alleviate Homesickness",
            "venue": "In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI \u201921)",
            "year": 2021
        },
        {
            "authors": [
                "Helle Breth Klausen"
            ],
            "title": "Safe and sound\u2019: What technologically-mediated ASMR is capable of through sound",
            "venue": "SoundEffects - An Interdisciplinary Journal of Sound and Sound Experience",
            "year": 2019
        },
        {
            "authors": [
                "Josephine Klefeker",
                "Libi Striegl",
                "Laura Devendorf"
            ],
            "title": "What HCI Can Learn from ASMR: Becoming Enchanted with the Mundane",
            "venue": "In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI \u201920)",
            "year": 2020
        },
        {
            "authors": [
                "Alexsandra Kovacevich",
                "David Huron"
            ],
            "title": "Two studies of autonomous sensory meridian response (ASMR): The relationship between ASMR and musicinduced frisson. Empirical musicology review",
            "year": 2019
        },
        {
            "authors": [
                "Kate Szer Kurtin",
                "NinaO\u2019Brien",
                "Deya Roy",
                "LindaDam"
            ],
            "title": "TheDevelopment of Parasocial Interaction Relationships on YouTube",
            "venue": "The Journal of Social Media in Society;",
            "year": 2018
        },
        {
            "authors": [
                "Joanna \u0141api\u0144ska"
            ],
            "title": "CREATIVITY OF HUMANANDNON-HUMANMATTER INTERWOVEN: AUTONOMOUS SENSORY MERIDIAN RESPONSE VIDEOS IN A POSTHUMAN PERSPECTIVE",
            "venue": "Creativity Studies 13,",
            "year": 2020
        },
        {
            "authors": [
                "Yoonjoo Lee",
                "John Joon Young Chung",
                "Jean Y Song",
                "Minsuk Chang",
                "Juho Kim"
            ],
            "title": "Personalizing Ambience and Illusionary Presence: How People Use \u201cStudywithMe\u201d Videos to Create Effective Studying Environments",
            "venue": "In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI \u201921)",
            "year": 2021
        },
        {
            "authors": [
                "Mengjie Liu",
                "Qiang Zhou"
            ],
            "title": "A Preliminary Compilation of a Digital Video Library on Triggering Autonomous Sensory Meridian Response (ASMR): A Trial Among 807 Chinese College Students",
            "venue": "Frontiers in Psychology",
            "year": 2019
        },
        {
            "authors": [
                "Anna M Lomanowska",
                "Matthieu J Guitton"
            ],
            "title": "Online intimacy and wellbeing in the digital age",
            "venue": "Internet Interventions",
            "year": 2016
        },
        {
            "authors": [
                "Jessica Maddox"
            ],
            "title": "What do creators and viewers owe each other? Microcelebrity, reciprocity, and transactional tingles in the ASMR YouTube community. First Monday 26, 1 SE - Articles",
            "year": 2020
        },
        {
            "authors": [
                "Hugh S Manon"
            ],
            "title": "ASMR Mania, Trigger-Chasing, and the Anxiety of Digital Repletion",
            "year": 2018
        },
        {
            "authors": [
                "Allison Mooney",
                "Jason Klein"
            ],
            "title": "Consumer Goods, and Consumer Trends",
            "year": 2016
        },
        {
            "authors": [
                "Ricardo Morales",
                "Daniela Ram\u00edrez-Benavides",
                "Mario Villena-Gonzalez"
            ],
            "title": "Autonomous Sensory Meridian Response self-reporters showed higher scores for cognitive reappraisal as an emotion regulation strategy",
            "venue": "PeerJ 9 (2021),",
            "year": 2021
        },
        {
            "authors": [
                "Robby Nadler"
            ],
            "title": "Understanding \u201cZoom fatigue\u201d: Theorizing spatial dynamics as third skins in computer-mediated communication",
            "venue": "Computers and Composition",
            "year": 2020
        },
        {
            "authors": [
                "Iida Nissinen"
            ],
            "title": "Tingles, tea boxes and sticky sounds\u2013ASMR read diffractively with agential realism",
            "year": 2018
        },
        {
            "authors": [
                "Shuo Niu",
                "Ava Bartolome",
                "Cat Mai",
                "Ha B Nguyen"
            ],
            "title": "Stayhome #Withme: How do youtubers help with covid-19 loneliness",
            "venue": "In Conference on Human Factors in Computing Systems - Proceedings",
            "year": 2021
        },
        {
            "authors": [
                "Shuo Niu",
                "Cat Mai",
                "Katherine G McKim",
                "D Scott McCrickard"
            ],
            "title": "TeamTrees: Investigating How YouTubers Participate in a Social Media Campaign",
            "venue": "Proc. ACM Hum.-Comput. Interact",
            "year": 2021
        },
        {
            "authors": [
                "Theodore Oing",
                "Julie Prescott"
            ],
            "title": "Implementations of Virtual Reality for Anxiety-Related Disorders: Systematic Review",
            "venue": "JMIR Serious Games 6,",
            "year": 2018
        },
        {
            "authors": [
                "Sharon Oviatt"
            ],
            "title": "Ten Myths of Multimodal Interaction",
            "venue": "Commun. ACM 42,",
            "year": 1999
        },
        {
            "authors": [
                "Emmi Parviainen",
                "Marie Louise Juul S\\ondergaard"
            ],
            "title": "Experiential Qualities ofWhispering with Voice Assistants",
            "venue": "In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI \u201920)",
            "year": 2020
        },
        {
            "authors": [
                "James W Pennebaker",
                "Ryan L Boyd",
                "Kayla Jordan",
                "Kate Blackburn"
            ],
            "title": "The development and psychometric properties of LIWC2015",
            "year": 2015
        },
        {
            "authors": [
                "Giulia Poerio"
            ],
            "title": "Could Insomnia Be Relieved with a YouTube Video? The Relaxation and Calm of ASMR",
            "venue": "In The Restless Compendium : Interdisciplinary Investigations of Rest and Its Opposites,",
            "year": 2016
        },
        {
            "authors": [
                "Giulia Lara Poerio",
                "Emma Blakey",
                "Thomas J Hostler",
                "Theresa Veltri"
            ],
            "title": "More than a feeling: Autonomous sensory meridian response (ASMR) is characterized by reliable changes in affect and physiology",
            "venue": "PLOS ONE 13,",
            "year": 2018
        },
        {
            "authors": [
                "Eugenia Ha Rim Rho",
                "Melissa Mazmanian"
            ],
            "title": "Political Hashtags & the Lost Art of Democratic Discourse",
            "venue": "In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI \u201920)",
            "year": 2020
        },
        {
            "authors": [
                "Craig Richard"
            ],
            "title": "Brain tingles: The secret to triggering autonomous sensory meridian response for improved sleep, stress relief, and head-to-toe euphoria",
            "year": 2018
        },
        {
            "authors": [
                "Dana Rotman",
                "Jennifer Golbeck",
                "Jennifer Preece"
            ],
            "title": "The Community is Where the Rapport is \u2013 on Sense and Structure in the Youtube Community",
            "venue": "In Proceedings of the Fourth International Conference on Communities and Technologies (C&T \u201909)",
            "year": 2009
        },
        {
            "authors": [
                "Rebecca B Rubin",
                "Michael P McHugh"
            ],
            "title": "Development of parasocial interaction relationships",
            "venue": "Journal of Broadcasting & Electronic Media 31,",
            "year": 1987
        },
        {
            "authors": [
                "Kristen M Scott",
                "Simone Ashby",
                "Julian Hanna"
            ],
            "title": "Human, All Too Human\": NOAAWeather Radio and the Emotional Impact of Synthetic Voices",
            "venue": "In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. Association for Computing Machinery,",
            "year": 2020
        },
        {
            "authors": [
                "RAJEEV SHARMA",
                "VLADIMIR I PAVLOVI\u0106",
                "THOMAS S HUANG"
            ],
            "title": "Toward Multimodal Human-Computer Interface",
            "venue": "In Advances in Image Processing and Understanding. Series in Machine Perception and Artificial Intelligence, Vol. Volume 52. WORLD SCIENTIFIC,",
            "year": 2002
        },
        {
            "authors": [
                "Stefan Siersdorfer",
                "Sergiu Chelaru",
                "Wolfgang Nejdl",
                "Jose San Pedro"
            ],
            "title": "How Useful Are Your Comments? Analyzing and Predicting Youtube Comments and Comment Ratings",
            "venue": "In Proceedings of the 19th International Conference on World Wide Web (WWW \u201910)",
            "year": 2010
        },
        {
            "authors": [
                "Naomi Smith",
                "Anne-Marie Snider"
            ],
            "title": "ASMR, affect and digitally-mediated intimacy",
            "venue": "Emotion, Space and Society",
            "year": 2019
        },
        {
            "authors": [
                "Stephen D Smith",
                "Beverley Katherine Fredborg",
                "Jennifer Kornelsen"
            ],
            "title": "Functional connectivity associated with five different categories of Autonomous Sensory Meridian Response (ASMR) triggers",
            "venue": "Consciousness and Cognition",
            "year": 2020
        },
        {
            "authors": [
                "Stephen D Smith",
                "Beverley Katherine Fredborg",
                "Jennifer Kornelsen"
            ],
            "title": "An examination of the default mode network in individuals with autonomous sensory meridian response (ASMR)",
            "venue": "Social Neuroscience 12,",
            "year": 2017
        },
        {
            "authors": [
                "Rebecca Lurie Starr",
                "Tianxiao Wang",
                "Christian Go"
            ],
            "title": "Sexuality vs. sensuality: The multimodal construction of affective stance in Chinese ASMR performances",
            "venue": "Journal of Sociolinguistics 24,",
            "year": 2020
        },
        {
            "authors": [
                "Amanda Stears"
            ],
            "title": "Three Things You Need to Know About ASMR Videos",
            "year": 2021
        },
        {
            "authors": [
                "Jayne Wallace",
                "Anja Thieme",
                "Gavin Wood",
                "Guy Schofield",
                "Patrick Olivier"
            ],
            "title": "Enabling Self, Intimacy and a Sense of Home in Dementia: An Enquiry into Design in a Hospital Setting",
            "venue": "In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI \u201912)",
            "year": 2012
        },
        {
            "authors": [
                "Philip Weber",
                "Thomas Ludwig",
                "Sabrina Brodesser",
                "Laura Gr\u00f6newald"
            ],
            "title": "It\u2019s a Kind of Art!\u201d: Understanding Food Influencers as Influential Content Creators",
            "venue": "In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI \u201921)",
            "year": 2021
        },
        {
            "authors": [
                "Donghee Yvette Wohn",
                "Guo Freeman",
                "Caitlin McLaughlin"
            ],
            "title": "Explaining Viewers\u2019 Emotional, Instrumental, and Financial Support Provision for Live Streamers",
            "venue": "In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI \u201918)",
            "year": 2018
        },
        {
            "authors": [
                "Zhenhui Yuan",
                "Gheorghita Ghinea",
                "Gabriel-Miro Muntean"
            ],
            "title": "Beyond Multimedia Adaptation: Quality of Experience-Aware Multi-Sensorial Media Delivery",
            "venue": "IEEE Transactions on Multimedia 17,",
            "year": 2015
        },
        {
            "authors": [
                "Michele Zappavigna"
            ],
            "title": "Digital intimacy and ambient embodied copresence in YouTube videos: construing visual and aural perspective in ASMR role play videos",
            "venue": "Visual Communication",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "CCS CONCEPTS \u2022 Human-centered computing \u2192 Empirical studies in collaborative and social computing.\nKEYWORDS ASMR; YouTube; video; multimodal; parasocial; experience\nACM Reference Format: Shuo Niu, Hugh S. Manon, Ava Bartolome, Nguyen B. Ha, and Keegan Veazey. 2022. Close-up and Whispering: An Understanding of Multimodal and Parasocial Interactions in YouTube ASMR videos. In CHI Conference on Human Factors in Computing Systems (CHI \u201922), April 29-May 5, 2022, New Orleans, LA, USA. ACM, New York, NY, USA, 17 pages. https://doi.org/10. 1145/3491102.3517563\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI \u201922, April 29-May 5, 2022, New Orleans, LA, USA \u00a9 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-9157-3/22/04. . . $15.00 https://doi.org/10.1145/3491102.3517563"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Autonomous Sensory Meridian Response (ASMR) is a phenomenon usually experienced as tingling sensations in the crown of the head in response to a range of audio-visual triggers such as whispering, tapping, and hand movements [53]. ASMR videos incorporate audio, touch, taste, observation, and roleplay effects to deliver enjoyable and relaxing feelings. Over the past decade, the creation culture on YouTube has attracted numerous ASMR creators (known colloquially by users as \u201cASMRtists\u201d) to design a wide array of tingle-inducing sounds and actions to intentionally induce ASMR feelings [3, 41]. ASMRtists have also leveraged ASMR videos to connect to the viewers and build online ASMR communities [3, 61]. A typical YouTube ASMR video may feature an ASMRtist whispering to the viewer, roleplaying personal attention such as massages or haircuts, making crisp sounds, or engaging in various slow and repetitive movements [5]. YouTube hosted more than 5.2 million ASMR videos in 2016 and 13 million in 2019, and the searches for ASMR grew over 200% in 2015 and are consistently increasing [42, 65]. Remarkably \u201cASMR\u201d is among the top five YouTube search queries globally and in the US, with a search volume of more than 14 million1.\nIn Human-Computer Interaction (HCI), experience-centered design requires researchers to capture and analyze the experiences generated from interaction and adopt the understanding of these experiences in design practices [25]. ASMR is a unique experience insofar as only some users experience the \u201ctingles\u201d as a response to particular triggers, and the same trigger may have different effects on different people [18, 28, 41, 53]. Over the years, ASMRtists developed highly stylized and conventionally patterned ASMR videos to engage their viewers, and as a way to enhance affect and intimacy [3, 70]. Prior research on ASMR has focused on characterizing ASMR triggers [5, 19] or understanding ASMR interactions through qualitative video analysis [3, 61, 70], user surveys [38, 53], and brain imaging [63]. Most studies described YouTube ASMR videos primarily as roleplays [1, 64, 70] or as a single video type with a mixture of ASMR triggers [53, 61]. However, little data-driven research has been conducted to categorize the wide variety of ASMR experiences developed by YouTube ASMRtists. YouTubers create ASMR videos with or without elements of social interaction, using roleplays or simply manipulating objects, and position themselves up-close or distant from the viewer. A macro understanding of the delivery\n1https://ahrefs.com/blog/top-youtube-searches/\nar X\niv :2\n20 2.\n06 83\n9v 3\n[ cs\n.H C\n] 2\n3 O\nct 2\n02 3\nmechanism and experience patterns in YouTube ASMR videos will help technology and service designers explore ways to integrate ASMR and assess its effects on the user experience. Since experience seekers need different triggers to acquire ASMR sensations, a quantitative overview of common ASMR interaction modalities will indicate what ASMR interactions may work for more users.\nIn this study, we collect a large number of ASMR videos and perform a mixed-method analysis to obtain an overview of ASMR interactions and experiences. This work analyzes 2663 ASMR videos collected from YouTube to examine the multimodal interactions and the ways ASMR performers para-socially attract the viewers. We focus on intentional ASMR videos \u2013 videos with \u201cASMR\u201d labels in which a variety of triggers are purposefully displayed by the performer \u2013 to understand ASMRtists\u2019 common approaches to trigger ASMR experiences. Prior work identified visual, audio, touch, taste, and scenario-based ASMR triggers [18, 55, 62, 70]. By interacting with ASMR videos, viewers are able to experience a simulation of intimacy with the video performer through \u201cparasocial interactions\u201d [68] \u2013 a one-sided intimacy experienced by a viewer through repeated encounters with a figure on screen. In parasocial relationships, video performers develop and manage three types of attractiveness \u2013 social attraction, physical attraction, and task attraction [57]. We quantify the manners in which the ASMRtists socialize with the viewer (social attraction), the camera proximity of the ASMRtists in the videos (as an alternative for physical attraction), and purposeful activities performed by the ASMRtists (task attraction). This work addresses three main research questions:\n\u2022 RQ1: How are various interaction modalities employed in YouTube ASMR videos? \u2022 RQ2: How do YouTube ASMRtists design parasocial attractiveness through multimodal interactions? \u2022 RQ3: How do different multimodal interactions and parasocial attractions affect the expression of viewers\u2019 feelings in the comments?\nFigure 1 illustrates the structure of the research questions. RQ1 provides an overview of multimodal interactions in YouTube ASMR videos to inform designs with common ASMR performing methods. RQ2 focuses on understanding the patterns of parasocial attractiveness through multimodal interactions. We summarize the experiences delivered by YouTube ASMR videos and identify the associated interaction modalities. RQ3 utilizes viewers\u2019 comments to infer how different multimodal interactions and parasocial attractions affect viewers\u2019 social, perceptual, and relaxation feelings. We first use grounded-theory approaches to identify subcategories of interaction modalities and parasocial attractions. Then the codebook is translated into a questionnaire task. The annotation tasks\nwere completed by participants recruited from Amazon Mechanical Turk (MTurk). We perform statistical analysis to address the research questions.\nThe development of multimodal interactions depends on the natural integration patterns that typify the combined use of different input modes [49]. Understanding diverse interaction modalities through analyzing extensive video data inform different ways to incorporate ASMR in technology design. Our results indicate social attractions are enhanced by combining multiple ASMR interaction modalities. Most ASMRtists use the closeup camera proximity as a means of building physical attractiveness. ASMRtists emulate physical closeness through microphonically-amplified whispering, manipulating objects, virtually \u201ctouching\u201d the viewer, and making mouth noises and microphone-jostling sounds near the camera or the microphone. Many ASMR videos do not involve purposeful tasks and are not roleplays. Tasks used in non-roleplay videos include soft and routine activities such as performing medical or cosmetic treatments, eating and drinking, and demonstrating mundane daily activities. The ASMR experiences delivered by YouTube ASMRtists can be described as three experience patterns: multimodal social connection, relaxing physical intimacy, and observation of sensory-rich activities. This work aims to inspire future technologies and services to incorporate ASMR triggers to design ASMR-augmented relaxing or intimate experiences."
        },
        {
            "heading": "2 BACKGROUND",
            "text": ""
        },
        {
            "heading": "2.1 ASMR Videos on YouTube",
            "text": "The now widely-adopted term \u201cAutonomous Sensory Meridian Response\u201d (ASMR) was coined in 2010 to describe a sensory phenomenon that usually involves the sensation of tingling as a response to certain audio-visual stimuli [6]. Common ASMR videos show intentional or unintentional gentle interactions such as speaking softly, playing or brushing hair, moving hands, and tapping or scratching surfaces [18, 53], which may trigger a low-grade euphoria response and tingling sensations on the viewer\u2019s head and spine [1]. The ASMR trend on social media began with a Yahoo group sharing personal experiences of head tingles when watching specific kinds of videos [3, 13]. Those original videos were dubbed \u201cunintentional\u201d ASMR, and involved real-world scenarios such as doctor\u2019s office examinations and suit fittings, captured for some non-ASMR purpose and uploaded, but subsequently re-contextualized for their ASMR tingle-triggering properties [20, 41]. Afterward, creators made numerous \u201cintentional\u201d ASMR videos on YouTube in which ASMRtists purposefully use visual and sound stimuli and scripted roleplays to induce ASMR experiences [1, 40]. In 2019, there were 13 million ASMR videos on YouTube [65]. Popular ASMRtists such as GentleWhispering ASMR, SAS-ASMR, and Gibi ASMR, have millions of subscribers, and their videos attracted millions of views and generate considerable revenue for the creators [65, 70].\nDespite the popularity of this emerging video genre on YouTube, studies found ASMR triggers do not work for everyone, and some individuals only experience the tingles with very precise, idiosyncratic triggers [5, 53]. ASMR was found to be associated with specific personality traits of individual viewers and to vary from person to person [18, 28]. Users\u2019 diverse needs triggering effects drive ASMR consumers to constantly search for videos with the keyword\n\u201cASMR.\u201d [3] In turn, the YouTube culture of creativity and participation [10] encourages ASMRtists to make numerous ASMR videos to satisfy ASMR experience-seekers\u2019 diverse needs. The growing trend of ASMR creation and consumption drew researchers\u2019 attention. Prior studies focused on understanding the sensational effects through interviewing ASMR viewers (e.g., [5, 38, 53]) or scanning brain images (e.g., [63]). Some studies examined the creator-viewer interactions and the digital intimacy through qualitative analyses of a few viral videos (e.g., [40, 61, 70]).\nAlthough the diversity of ASMR triggers is widely noted, there is little analysis of large video data sets to explain the creation practices employed by ASMRtists. ASMR can be induced with virtual face-to-face interactions [5, 64] or simply by manipulating objects without showing performers\u2019 faces [45]. Some ASMR videos consist of constant soft speaking while others involve object manipulation without talking [36]. Some ASMR videos pretend to touch the viewers in roleplays while others perform massages on a second person who is also visible in the video [70]. ASMR sensations can emerge both in response to food consumption videos [4] and to videos showing a person studying quietly [37]. A quantitative analysis of extensive videos will help HCI designers discern the significance of different ASMR interactions and experiences. First, since an ASMR trigger may or may not induce ASMR experiences, an overview of common ASMR interaction modalities and experiential patterns will help technology designers to incorporate ASMR triggers that are effective for a broader range of users. Second, recent research noted ASMR is not just a sensory experience; it is also a kind of mediated intimacy offered by ASMRtists to deliver a sense of social connection [3, 61, 70]. However, there is limited understanding of how such social experiences are commonly constructed and their relationships with trigger interactions and social settings. Last, understanding viewers\u2019 social, perceptual, and relaxation feelings will help technology designers understand the possible effects of different ASMR experiences."
        },
        {
            "heading": "2.2 Multimodal Interactions in ASMR videos",
            "text": "Researchers have examined various triggers in ASMR videos to understand this emerging media form and its physiological effects. Richard summarizes ASMR stimuli as audio, touch, visual, and scenario triggers [55]. Smith et al. examined people\u2019s responses to five trigger types, including watching, touching, repetitive sounds, simulations, and mouth sounds [62]. Zappavigna explored ASMR roleplays and found linguistic, visual, and aural resources are used to create a sense of co-presence with the performer [70]. This study explores common interactions performed by YouTube ASMRtists. HCI researchers have identified vision, hearing, touch, smell, and taste as five sensing modalities to embody interactions [59, 69]. Grounded in multimodal interaction theories [59, 69] and trigger modalities identified in the literature [55], RQ1 explores visual, sound, touch, taste, and scenario as five interaction modalities in YouTube ASMR videos. Visual interactions describe how the performers present themselves and the trigger objects. We look into visual settings such as ASMRtists showing themselves in front of the camera, performing slow activities, or simply showing hands manipulating ASMR trigger objects. Sound interactions refer to what types of hearing triggers are made by the ASMRtists. This modality\nseeks to capture sounds like human speaking, tapping or scratching objects, or various sound effects produced by interacting with the microphone. Touch interactions examine how ASMRtists stimulate haptic feelings. For this modality, we observe how ASMRtists use their hands to interact with themselves, physical objects, the camera, or another person in the video. Taste interactions investigate whether or not the ASMRtists eat food in the video. And finally, scenario triggers describe the simulated situation and environment in roleplay videos, such as haircuts, eye exams, or other dramatized forms of assistance from the figure on screen [55]."
        },
        {
            "heading": "2.3 Parasocial Attractions in ASMR Videos",
            "text": "A large community of YouTube creators designate themselves as \u201cASMRtists\u201d by regularly creating and uploading ASMR videos [3]. The pseudo-interactive nature of the videos engenders a sort of intimacy with the video creator [11, 27, 46]. The essentially onesided intimacy with the video performers, generated by a \u201cconversational give-and-take,\u201d is defined as a parasocial relationship, and the interactions users have with videos that generate parasocial relationships are called \u201cparasocial interactions.\u201d [24, 26] Parasocial relationships and interactions have beenwidely found in the interactive reponses of viewers to a TV or social media figure, which affect viewers socially and emotionally. Video-watching may lead some viewers to imagine themselves interacting with the performer [22]. Studies found parasocial relationships can provide social support and shield against the effects of exclusion and loneliness [24, 46]. YouTube users mostly focus their investments (of time, of energy) in parasocial interactions with the video creator, rather than building a friend and community network like other social media [47, 56]. ASMR videos can be seen as a unique form of parasocial interactions offered by ASMRtists [10]. Klausen described ASMR as a \u201cpara-haptic interactional\u201d relation with the ASMRtists while obtaining a form of presence and intimacy [31]. Zappavigna also considered ASMR videos as a construction of the interactive context in which viewers feel co-presence with the performer [70]. Smith argued that in ASMR videos, affective experiences are intentionally construed and strategically heightened [61]. However, due to a dearth of quantitative analysis of parasocial interactions in ASMR videos, it is unknown how prevalent the social experience is, or what general approaches are best used to deliver such one-sided intimacy.\nThis work analyzes the associations between parasocial interactions and interaction modalities to explore the patterns of social and intimate experiences designed by ASMRtists. The parasocial interaction theory suggests that video performers develop social, physical, and task attractions to engage viewers and establish parasocial relationships [34, 57]. Social attraction refers to the degree to which one feels they would like to befriend the television or media persona [34]. In ASMR, performers may simulate conversational scenarios and socialize with the viewers through their soft vocal and bodily interactions [31, 70]. Creators use ASMR videos to attract patrons and build network of fans [40]. Physical attraction refers to how video performers appeal to the viewer physically [34]. In this study, we measure camera spatial proximity as a vector of physical attraction since it is difficult to quantify the attractiveness of performers\u2019 physical appearance. ASMRtists tend to perform body\nand hand movements very near the camera [64, 70]. ASMRtists may themselves appear in the video either in close up to show intimacy [3, 23, 61], or they may exclusively show trigger objects on screen without showing their faces [55]. Task attraction describes how ably, credibly, or reliably a performer can complete a task [34]. ASMRtists perform different tasks such as professional treatments [1, 35, 70], mundane activities like putting on makeups or sorting cards [18, 32, 37], or less meaningful activities like cutting soap or tapping their fingernails on objects [20]. RQ2 uses the parasocial attraction framework identified in [57] to examine the patterns of social, proximity, or task-observing experiences."
        },
        {
            "heading": "2.4 ASMR Experiences and Benefits",
            "text": "ASMR experiences are touted by many as promoting calm and relaxed feelings [33, 43, 52] and are associated with positive affect and a sense of interpersonal connection [31, 53, 61]. Barratt and Davis found that ASMR combines positive feelings, relaxation, and tingling sensation of the skin and provides temporary relief from depression [5]. Smith et al. analyzed neuroimages during ASMR tingles and found ASMR was associated with a blending of multiple resting-state networks [63]. Kovacevich examined comments to ASMR videos and found positive comments appreciated the calming or relaxing effects [33]. For social and intimate experiences, Klausen argued that ASMRtists leverage binaural sounds and haptic interactions to create a form of embodied presence and distant intimacy with the viewers [31]. Smith and Snider also suggested ASMR performers intentionally express feelings of intimacy and affection to the viewers [61]. Recent HCI research explored the use of ASMR effects in wearable technologies for enchantment and slow experiences [32]. Studies on food-eating videos (colloquially known as \u201cMukbang\u201d) found ASMR a key motivator for video watching [4, 67]. YouTube study-with-me videos also use ASMR effects [37].\nRQ3 seeks to obtain an initial understanding of viewers\u2019 responses to different ASMR experiences through comment analysis. Prior work found that people can have different feelings with the same ASMR trigger [19? ] and don\u2019t publicly share ASMR experiences with others [4, 5]. Comments represent immediate and direct user reactions to a video and analyzing comments is a more straightforward way to capture viewers\u2019 feelings than rating by external participants [33]. Word analysis of YouTube comments is a common approach to infer the influence of videos on viewers [2, 58, 60]. In RQ3, we measure how ASMR viewers comment on three common feelings of ASMR identified in prior research: social connection and intimacy, sensory perception, and relaxation and sleepiness. Considering the difficulties of manually annotating a large number of comments and subjectively rating viewers\u2019 feelings, a mixed-method of Linguistic Inquiry andWord Count (LIWC) software [51] and pointwise mutual information (PMI) [8] is used. LIWC has been scientifically validated to analyze people\u2019s social and emotional expression on social media [14, 17]. PMI is also a lexicon-based method to identify topically important keywords [14, 54]. Both methods are widely used in prior HCI research to imply psychological processes from social media data (e.g., [14, 17, 54]). Then we compare the word frequencies in comments of videos with different interaction modalities and parasocial attractions."
        },
        {
            "heading": "3 ASMR VIDEO DATA",
            "text": "We collected recent ASMR videos from active video creators to analyze ASMR videos on YouTube. The ASMR videos were crawled using the YouTube Data API2 with the search seed \u201cASMR.\u201d In the first step, we searched ASMR videos on Jun 11, 2020, and Oct 20, 2020, to collect a list of videos posted in the prior three months, respective to each search date. This step lets us identify active channels that were recently posting ASMR videos. Then the crawler collected all available videos belonging to those active channels to form a raw dataset. 227,133 videos were returned from YouTube. For each video, we requested the YouTube API to return 300 top-level comments3. Since comments belonging to a video are analyzed together, and popular videos may have numerous comments, collecting up to 300 per video ensures all videos have a similar amount of comments.\nTitles and tags are processed to filter out non-English videos. We exclude non-English videos due to difficulties in the data tagging and categorization. Videoswithout \u201cASMR\u201d in the titles are removed since this work focuses on intentional ASMR videos with a clear ASMR theme and is designed for this experience (an ASMRtist may post non-ASMR videos). We exclude videos shorter than 5 minutes (\ud835\udc41 = 9676, 4.26%) due to many of them being previews of full videos and compilations of short video clips from multiple ASMR videos. We also only keep videos posted between Jan 1, 2020, and Jun 01, 2020, to ensure the videos reflect the latest creation styles and have enough time to receive comments. We remove videos with fewer than 50 comments (31.39% of videos) to ensure videos had enough comments for word analysis.\nAfter filtering, 85,734 videos are kept for data sampling. These videos come from 697 different channels. Then we randomly sample 200 videos for grounded theory analysis. We sample up to 10 videos per channel for the final data analysis. There are many channels with less than ten videos in our dataset \u2013 the eventual sampling results in 2830 videos for data annotation. The data collection overlaps with the emergence of COVID-19, but through a rough examination, we didn\u2019t notice a significant mention of COVID-19 in the videos. The IRB (Institutional Review Board) office at the authors\u2019 institute has reviewed the entire research process and exempted this research from ethics board review (see Appendix A for more information)."
        },
        {
            "heading": "4 METHODS",
            "text": ""
        },
        {
            "heading": "4.1 Grounded Analysis",
            "text": "Analysis in prior studies identified triggers from a small video sample or a few popular ASMR roleplays. Therefore, we choose to conduct a grounded theory analysis to extract common interaction modalities and parasocial attraction techniques. Grounded theory data analysis has been widely used to inductively derive models of social processes [12, 16]. This work follows open, axial, and selective coding procedures to generate and verify modality and attractiveness subcategories. We randomly sample 200 videos from 166 ASMRtists for the grounded analysis [7].\n2https://developers.google.com/youtube/v3 3YouTube Data API does not specify how the returned comments are selected and ordered. https://developers.google.com/youtube/v3/docs/comments/list\nIn the open coding phase, two of the authors of this research watched 50 videos each and take notes on the visual, sound, touch, taste, and scenario triggers described in [55]. The example multimodal interactions can be found in Figure 2. For parasocial attractiveness, the authors annotated how the ASMRtists simulate communication with their viewers (social attraction), where the ASMRtist is situated in proximity to the camera (spatial proximity), and the tasks the ASMRtists perform (task attraction).\nFor axial coding, the two authors used the affinity diagramming approach to summarize these notes and develop subcategories of interaction modalities and parasocial attractions (see Table 1 and Table 2 for the codebook). The categorization of social attraction identifies that ASMRtists may communicate with the viewer in the form of a one-sided talk, or may chat with the viewers as in a back-and-forth conversation by pausing and waiting for the viewer to reply. Some other ASMRtists make ASMR videos without any human voice on the audio track, instead using gestures and text to communicate. For spatial proximity, we focus on categorizing the proximity with which ASMRtists positioned themselves in relation to the camera. We adopt the shot scales used in film and TV4 (Figure 3) to annotate how the ASMRtist is displayed within the video frame (including extreme closeup, closeup, and medium closeup), medium distance (including medium shot and medium-full shot), or showing the whole body from head to toe (full shot). The annotation of the tasks performed by the ASMRtists finds three main categories of activities with clear goals. Treatment and service tasks seek to perform actions such as massage or haircut on the viewer. Some videos perform everyday tasks such as painting, writing, or applying makeup. Other videos demonstrate eating or drinking a large quantity of food (called Mukbang videos on YouTube [4]).\nIn selective coding, two authors annotated the remaining 100 videos using the codebook to validate the subcategories and obtain the inter-rater agreements between experts. Audio and touch were annotated as multi-categorical values. Visual, taste, scenario, social, physical, and task were annotated as single-categorical values. After annotation, 12 of 100 videos were removed due to unavailability (e.g., deleted, private, age-restricted, or non-English). Fleiss Kappa with Jaccard distance was used to calculate between expert agreement. For the 88 videos, all multimodal and parasocial categories reach substantial agreements with kappa scores between 0.62 and 0.88 (Table 3). Social and task have relatively lower agreement due to the differences in deciding if the ASMRtist talks to or talks with the viewer (e.g., a video is tagged differently because the ASMRtist mostly whispers by herself but also greets the viewer) and whether an activity is considered common and daily (e.g., one rater feels mixing makeup slime is a common activity while the other rater annotate it as a non-task video). Sound and touch have a lower agreement because they are multi-choice categories. Then the third author annotated disagreed answers independently to solve discrepancies and generate 88 expert annotations. The expert annotations were used to assess the accuracy of annotations completed on Amazon Mechanical Turk.\n4https://www.studiobinder.com/blog/types-of-camera-shots-sizes-in-film/"
        },
        {
            "heading": "4.2 Video Data Annotation",
            "text": "This work uses Amazon Mechanical Turk (MTurk) to annotate the ASMR videos. Each task consists of two steps. Each participant was asked to watch each video for three minutes in the beginning, one minute in the middle, and one minute in the end. Then the participant was asked to annotate the five multimodal interactions and three parasocial attractions by answering multi-choice questions. Example pictures were provided to explain each visual and proximity subcategory. Example video clips were provided to explain each sound and touch subcategory. A qualification test was performed to pre-screen qualified participants. To be qualified, the MTurkers must indicate that they have watched at least 10 ASMR videos before, do not feel ASMR videos disturbing or unsatisfying, and experience a tingling sensation and relaxation after watching ASMR videos. To test participants\u2019 ASMR knowledge, a pre-screen question asked them to pick two typical ASMR videos from the other four non-ASMR videos. To ensure annotation quality, we only invited MTurkers who have completed more than 5000 tasks on MTurk with an approval rate greater than 97%. A simple math question and a question asking participants to choose two ASMR\nvideos from four video descriptions were deployed in each task as attention tests. MTurkers must answer both attention tests correctly to get the work accepted. Otherwise, the task is rejected and re-released to other participants.\nBefore annotating all the data, we first test the agreement between MTurk workers and the expert annotations. MTurkers also completed the 88 videos that the experts have annotated. The annotations of all subcategories between experts and MTurkers reached a substantial agreement, with kappa scores ranging from 0.67 to 0.80 (Table 3). At the end, the annotation was completed by 47 MTurk participants with an average completion time of 8.9 minutes. Each accepted task was paid at the rate of USD $1.50. MTurkers report 167 videos with problems (99 unavailable, 28 age-restricted, and 40 non-English). After removing the 167 videos, 2663 videos are used for final data analysis. These videos have an average of 225,143.69 views (\ud835\udc46\ud835\udc37 = 654717.5) and 5180.89 likes (\ud835\udc46\ud835\udc37 = 9554.74)."
        },
        {
            "heading": "4.3 Comment Data Processing",
            "text": "483,583 comments of the 2663 videos were collected for analysis, with each video having 181.59 comments on average (\ud835\udc46\ud835\udc37 = 87.81). Among 2663 videos, 687 videos have 300 comments. The comment analysis uses two different text processing methods, LIWC [51] and PMI [8], to obtain words related to social connection and intimacy, sensory perception, and relaxation and sleepiness. For each video, we merge all the collected comments into one corpus and use LIWC to calculate the percentages of words related to social processes and sensory perception. Social processes include words like \u201cmate,\u201d \u201ctalk,\u201d and \u201cthey\u201d and all non-first-person-singular personal pronouns, as well as verbs that suggest human interaction (talking, sharing) [51]. Sensory perception includes bodily and perceptual words. The body category under biological processes contains words such as \u201ccheek,\u201d \u201chands,\u201d and \u201cspit.\u201d Perceptual processes recognize words related to perception, including \u201clook,\u201d \u201cheard,\u201d and \u201cfeeling.\u201d We also generate a text document with all comments combined and obtained the emotional tone and social-, body-, and perception-word percentages in the entire comment corpus. This step allows us to examine the overall sentiment in ASMR video comments and compare ASMR comments with the base rates of expressive writing, natural speech, and Twitter data [51].\nLIWC does not provide words related to intimacy, relaxation, and sleep processes. Therefore, we use the pointwise mutual information (PMI) technique [8] to recognize words and phrases associated with those processes. Similar approaches have been widely applied in social media analysis (e.g., [14, 54]). The PMI measures the likelihood that two terms occur together in a corpus. The PMIs are calculated based on the 8,914,289 comments from the filtered 85,734 videos. Comments are pre-processed to remove stop words and punctuation to retain only meaningful words (including regular words and emojis). Words are then processed to find bigrams of common phrases. The keywords to generate associated word lists are \u201cintimate,\u201d \u201crelax,\u201d and \u201csleep.\u201d To filter out too-rare and toocommon words, identified associated words must appear in at least 1000 comments and no more than 1/10 of all comments. We choose the top 3% of the qualified terms with the highest PMIs as the word lists for each keyword. Table 4 lists example words associated with each keyword. Then we apply a similar approach as in LIWC to count the percentages of words from each list in each video\u2019s comments."
        },
        {
            "heading": "4.4 Statistical Method",
            "text": "The visual, taste, scenario annotations, and the three parasocial subcategories are stored as multi-categorical nominal variables. Sound and touch, the two subcategories with multiple possible choices, are saved as dummy variables (1 is containing the interaction, otherwise 0). For RQ2, Pearson\u2019s Chi-squared test (contingency table) is used to identify significant associations between multimodal interaction and parasocial attraction subcategories. For comment analysis in RQ3, we first perform regression analysis to identify multimodal and parasocial subcategories that significantly predict each feeling word percentage. For each feeling word, two least-squared regression (LSR) models are built, with one using multimodal interactions as independent variables and the other using parasocial attraction variables. The two models are multivariate regressions with all modality factors (or all attraction factors) serving as independent variables simultaneously. We perform posthoc analysis with the Steel-Dwass method for each significant factor to identify differences between subcategory pairs. Nonparametric comparisons are performed due to the word frequencies being not normally distributed. In all statistical testings, the significant threshold (\ud835\udc4e\ud835\udc59\ud835\udc5d\u210e\ud835\udc4e = 0.05) is adjusted with the Bonferroni method."
        },
        {
            "heading": "5 RESULTS",
            "text": ""
        },
        {
            "heading": "5.1 RQ1: Multimodal Interactions in ASMR Videos",
            "text": "RQ1 seeks to overview the interaction modalities used in ASMR videos and suggest how prevalent triggers are (see Figure 4 left). Visual. Face-to-face is the most common visual setting. Around 2/3 of videos present ASMRtists themselves in front of the camera. The ASMRtists also perform triggers in other modalities like making whispering and object sounds, manipulating objects, or reaching to the camera at the same time (see Figure 4 right). Mukbang, object only, and images are also common visual settings. Only a small proportion of ASMR videos use video games, animals, or other visual interactions. Sound. We notice ASMRtists tend to mix multiple sound effects in ASMR videos. Only 896 (33.65%) videos contain only one type of sound. 1081 (40.59%) of videos use two audio triggers. 687 (25.80%) videos use three or more different types of sound effects. The most common sound in ASMR videos is whispering and soft speaking. Other common sound effects include object sounds, mouth effects, body and cloth sounds, mic effects, and ambient sounds. Touch. More than half (\ud835\udc41 = 1573, 59.07%) of ASMR videos use at least one touch trigger in the video. The most common touch interaction is touching objects in the video to generate tingling sounds. 29.1% of videos have ASMRtists reaching toward the camera and pretended to touch the viewers\u2019 face or body. Less than 10% of videos contain touching ASMRtists\u2019 own body parts or a person in the video. Taste. Tasting is not a commonly used interaction modality in ASMR videos. Only 12.35% of videos use tasting triggers, mostly in Mukbang videos (Figure 4 right). Scenario. 71.65% of videos do not use any roleplays in the videos. The most common roleplay is in service scenarios in which ASMRtists perform services or treatment processes. Less than 10% of videos are fantasy or romance roleplays.\nThe analysis of the distribution of multimodal interactions in ASMR videos suggests most ASMRtists choose to look at the camera to mimic face-to-face interactions with the viewer. ASMR videos are sound-diverse and rich. The most common sound interactions are whispering to the viewers and sounds made by manipulating trigger objects. Around 1/3 of ASMR videos use touch interaction by touching objects and/or touching the viewers. Taste interaction is used to perform Mukbang videos. The majority of the ASMR videos do not have roleplays and plotted scenarios. The most common ASMR scenario is service or treatment roleplays."
        },
        {
            "heading": "5.2 RQ2: Parasocial Attractions and ASMR Experience Patterns",
            "text": "RQ2 examines parasocial attractions in ASMR videos and their associated interaction modalities to evoke ASMR experiences. Figure 5 left illustrates their distribution, and Figure 5 right shows all the positive and negative associations.\n5.2.1 ASMR for Social Experiences. The analysis of social attraction shows that 1843 (69.21%) of the videos have the ASMRtists talking to or talking with the viewer (Figure 5 left). Pearson\u2019s chi-squared test suggests the face-to-face presentation (\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 .\ud835\udc53 \ud835\udc4e\ud835\udc50\ud835\udc52_\ud835\udc61\ud835\udc5c_\ud835\udc53 \ud835\udc4e\ud835\udc50\ud835\udc52), whispering sounds (\ud835\udc60\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51.\ud835\udc64\u210e\ud835\udc56\ud835\udc60\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc56\ud835\udc5b\ud835\udc54), and virtually touching the viewer through camera-reaching (\ud835\udc61\ud835\udc5c\ud835\udc62\ud835\udc50\u210e.\ud835\udc63\ud835\udc56\ud835\udc52\ud835\udc64\ud835\udc52\ud835\udc5f ) are significantly\nassociated with talk-to or and talk-with videos (\ud835\udc60\ud835\udc5c\ud835\udc50\ud835\udc56\ud835\udc4e\ud835\udc59 .\ud835\udc61\ud835\udc4e\ud835\udc59\ud835\udc58_\ud835\udc61\ud835\udc5c and \ud835\udc60\ud835\udc5c\ud835\udc50\ud835\udc56\ud835\udc4e\ud835\udc59 .\ud835\udc61\ud835\udc4e\ud835\udc59\ud835\udc58_\ud835\udc64\ud835\udc56\ud835\udc61\u210e). Videos that talk to the viewers are also significantly associated with touching objects (\ud835\udc61\ud835\udc5c\ud835\udc62\ud835\udc50\u210e.\ud835\udc5c\ud835\udc4f \ud835\udc57\ud835\udc52\ud835\udc50\ud835\udc61\ud835\udc60). Talking with the viewers is also associated with all three types of roleplays (Figure 5 right). Among all 1843 talk-to and talk-with videos, 1366 have the ASMRtists interacting with the viewers in \u201cfaceto-face\u201d settings and making whispering sounds (e.g., Figure 6- a). 645 videos also pretend to touch the viewers through camera reaching (e.g., Figure 6-b). 504 videos talk to the viewers while the ASMRtists touch objects to make tingling sounds (e.g., Figure 6-c). Talk-with videos use scenarios in which the ASMRtist roleplays a service provider (\ud835\udc41 = 273, Figure 6-d), a fantasy character (\ud835\udc41 = 108, Figure 6-e), or an intimate partner (\ud835\udc41 = 81, Figure 6-f). Although most talk-with videos show the performer looking at the viewer face-to-face, 116 out of 639 talk-with videos are videos with static or no images (\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 .\ud835\udc56\ud835\udc5a\ud835\udc4e\ud835\udc54\ud835\udc52\ud835\udc60 , e.g., Figure 6-f). Non-socializing videos are associated with Mukbang (\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 .\ud835\udc5a\ud835\udc62\ud835\udc58\ud835\udc4f\ud835\udc4e\ud835\udc5b\ud835\udc54), object-only (\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 .\ud835\udc5c\ud835\udc4f \ud835\udc57\ud835\udc52\ud835\udc50\ud835\udc61_\ud835\udc5c\ud835\udc5b\ud835\udc59\ud835\udc66), serving other people (\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 .\ud835\udc60\ud835\udc52\ud835\udc5f\ud835\udc63\ud835\udc52_\ud835\udc5d\ud835\udc52\ud835\udc5c\ud835\udc5d\ud835\udc59\ud835\udc52), touching another person in the video (\ud835\udc61\ud835\udc5c\ud835\udc62\ud835\udc50\u210e.\ud835\udc5f\ud835\udc52\ud835\udc4e\ud835\udc59_\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc60\ud835\udc5c\ud835\udc5b), tasting (\ud835\udc61\ud835\udc4e\ud835\udc60\ud835\udc61\ud835\udc52), and non-roleplays (\ud835\udc60\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc5c.\ud835\udc5b\ud835\udc5c\ud835\udc5b\ud835\udc52).\nThe high percentage of videos with conversational content suggests that social connection is a common experience incorporated by ASMRtists. ASMR performers deliver social connection experiences with multimodal interactions such as face-to-face whispering,\nhand-reaching, and one-sided or back-and-forth conversation. The ASMRtists tend to touch objects to generate tingling sounds while talking to the viewers. ASMRtists also perform service, fantasy, and romantic roleplays to engage the viewer in an emulated conversation, in which many ASMRtists pretend that they can hear the viewer\u2019s responses. Videos without socialization are videos of food eating, serving another person, or merely manipulating objects.\n5.2.2 ASMR for Intimate Interaction. The result of spatial proximity suggests that the majority (1868, 70.15%) of the ASMR videos have the ASMRtists presenting their full faces in closeup, medium, and full shot camera distances (Figure 5 left). Only 550 (20.65%) videos do not have human appearances, and 245 (9.2%) videos show partial faces. Closeup is the most used shot scale used in ASMR videos, suggesting most ASMRtists seek to simulate nearness with the viewer by positioning themselves in close camera proximity. The association analysis suggests that face-to-face (\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 .\ud835\udc53 \ud835\udc4e\ud835\udc50\ud835\udc52_\ud835\udc61\ud835\udc5c_\ud835\udc53 \ud835\udc4e\ud835\udc50\ud835\udc52), whispering sounds (\ud835\udc60\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51.\ud835\udc64\u210e\ud835\udc56\ud835\udc60\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc56\ud835\udc5b\ud835\udc54), object sounds (\ud835\udc60\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51.\ud835\udc5c\ud835\udc4f \ud835\udc57\ud835\udc52\ud835\udc50\ud835\udc61 ), mouth sounds (\ud835\udc60\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51.\ud835\udc5a\ud835\udc5c\ud835\udc62\ud835\udc61\u210e), mic effects (\ud835\udc60\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51.\ud835\udc5a\ud835\udc56\ud835\udc50), and the touching of objects (\ud835\udc61\ud835\udc5c\ud835\udc62\ud835\udc50\u210e.\ud835\udc5c\ud835\udc4f \ud835\udc57\ud835\udc52\ud835\udc50\ud835\udc61\ud835\udc60) and viewers (\ud835\udc61\ud835\udc5c\ud835\udc62\ud835\udc50\u210e.\ud835\udc63\ud835\udc56\ud835\udc52\ud835\udc64\ud835\udc52\ud835\udc5f ) significantly associate with closeup camera proximity (\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc65\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc61\ud835\udc66.\ud835\udc50\ud835\udc59\ud835\udc5c\ud835\udc60\ud835\udc52\ud835\udc62\ud835\udc5d , Figure 5 right). In all 1653 closeup videos, 1490 videos whispers to the viewer near the camera (e.g., Figure 7-a). 809 videos have ASMRtists making various trigger sounds (e.g., Figure 7-b). 591 and 245 closeup videos contain mouth effects (e.g., Figure 7-c) and mic\neffects (e.g., Figure 7-d). For touch interactions, closeup videos also consist of manipulating objects (e.g., Figure 7-b) and pretending to touch the viewers (e.g., Figure 7-e). In these videos, ASMRtists make mouth sounds near the mic or interact with the mic to engender the sound of physical closeness. Although some videos do not show the ASMRtist on screen, 59 of them simulate intimate and romantic roleplays in their conversations with the viewers (Figure 7-f).\nThese results suggest that ASMRtists seek to use cameras and microphones to emulate intimate interactions with the viewers. Common approaches include positioning near the camera, near-mic whispering, manipulating objects, reaching hands to the camera, and making mouth and mic sounds. Even in videos without the performer\u2019s physical presence, ASMRtists can emulate intimate roleplays and conversations to express intimacy.\n5.2.3 ASMR for Activity Observation. The analysis of task attraction shows most of the videos do not contain a clear task. More than half of the videos (\ud835\udc41 = 1549, 58.17%) are \ud835\udc61\ud835\udc4e\ud835\udc60\ud835\udc58.\ud835\udc5b\ud835\udc5c\ud835\udc5b\ud835\udc52 . The associations suggest three main types of videos that do not have specific tasks. The first type is ASMRtists using the face-to-face camera setting (\ud835\udc41 = 1085) and chatting with the viewer and/or making random sounds (e.g., Figure 8-a). The second main type is chatting in fantasy or romance roleplays (\ud835\udc41 = 210, e.g., Figure 6-f and 7-f). The third type is object-only videos (\ud835\udc41 = 191), in which\nASMRtists manipulate trigger objects without meaningful purposes (e.g., Figure 8-b and c). More than 40% of videos contain treatment, eating and drinking, and common daily tasks. Among 578 treatment videos, ASMRtists whisper to the viewer (\ud835\udc41 = 507), make object (\ud835\udc41 = 317) and body/cloth sounds (\ud835\udc41 = 164), and emulate service scenarios (\ud835\udc41 = 381). Treatment videos (\ud835\udc61\ud835\udc4e\ud835\udc60\ud835\udc58.\ud835\udc61\ud835\udc5f\ud835\udc52\ud835\udc4e\ud835\udc61\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61 ) are significantly associated with face-to-face (\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 .\ud835\udc53 \ud835\udc4e\ud835\udc50\ud835\udc52_\ud835\udc61\ud835\udc5c_\ud835\udc53 \ud835\udc4e\ud835\udc50\ud835\udc52 , \ud835\udc41 = 456) and touching the viewer (\ud835\udc61\ud835\udc5c\ud835\udc62\ud835\udc50\u210e.\ud835\udc63\ud835\udc56\ud835\udc52\ud835\udc64\ud835\udc52\ud835\udc5f ,\ud835\udc41 = 304), as those treatment videos pretend to perform the service on the viewer (e.g., Figure 6-b and d and Figure 7-e). Treatment videos (\ud835\udc61\ud835\udc4e\ud835\udc60\ud835\udc58.\ud835\udc61\ud835\udc5f\ud835\udc52\ud835\udc4e\ud835\udc61\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61 ) are also significantly associated with performing service on another person (\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 .\ud835\udc60\ud835\udc52\ud835\udc5f\ud835\udc63\ud835\udc52_\ud835\udc5d\ud835\udc52\ud835\udc5c\ud835\udc5d\ud835\udc59\ud835\udc52 , \ud835\udc41 = 85) and touching them (\ud835\udc61\ud835\udc5c\ud835\udc62\ud835\udc50\u210e.\ud835\udc5f\ud835\udc52\ud835\udc4e\ud835\udc59_\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc60\ud835\udc5c\ud835\udc5b, \ud835\udc41 = 83, e.g., Figure 8-d). 337 videos consist of tasks of eating and drinking (e.g., Figure 8-e and f), most of which present a large quantity of food in the video (\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 .\ud835\udc5a\ud835\udc62\ud835\udc58\ud835\udc4f\ud835\udc4e\ud835\udc5b\ud835\udc54, \ud835\udc41 = 259) and make mouth sounds (\ud835\udc60\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51.\ud835\udc5a\ud835\udc5c\ud835\udc62\ud835\udc61\u210e, \ud835\udc41 = 301). Mukbang task is significantly associated with non-social (\ud835\udc60\ud835\udc5c\ud835\udc50\ud835\udc56\ud835\udc4e\ud835\udc59 .\ud835\udc5b\ud835\udc5c\ud835\udc5b\ud835\udc52) and partial face presentations (\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc65\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc61\ud835\udc66.\ud835\udc5d\ud835\udc4e\ud835\udc5f\ud835\udc61\ud835\udc56\ud835\udc4e\ud835\udc59_\ud835\udc53 \ud835\udc4e\ud835\udc50\ud835\udc52). The third major task is common daily activities (e.g., Figure 8-g and h). 216 (8.11%) videos show daily tasks in which ASMRtists perform everyday activities. Common daily tasks (\ud835\udc47\ud835\udc4e\ud835\udc60\ud835\udc58.\ud835\udc50\ud835\udc5c\ud835\udc5a\ud835\udc5a\ud835\udc5c\ud835\udc5b) are significantly associated with object-only presentations (\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 .\ud835\udc5c\ud835\udc4f \ud835\udc57\ud835\udc52\ud835\udc50\ud835\udc61_\ud835\udc5c\ud835\udc5b\ud835\udc59\ud835\udc66, \ud835\udc41 = 43), whispering sounds (\ud835\udc60\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51.\ud835\udc64\u210e\ud835\udc56\ud835\udc60\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc56\ud835\udc5b\ud835\udc54, \ud835\udc41 = 184), and object\nsounds (\ud835\udc60\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51.\ud835\udc5c\ud835\udc4f \ud835\udc57\ud835\udc52\ud835\udc50\ud835\udc61 , \ud835\udc41 = 122). Daily tasks (\ud835\udc61\ud835\udc4e\ud835\udc60\ud835\udc58.\ud835\udc50\ud835\udc5c\ud835\udc5a\ud835\udc5a\ud835\udc5c\ud835\udc5b) are also significantly associated with touching own body (\ud835\udc61\ud835\udc5c\ud835\udc62\ud835\udc50\u210e.\ud835\udc5c\ud835\udc64\ud835\udc5b_\ud835\udc4f\ud835\udc5c\ud835\udc51\ud835\udc66, \ud835\udc41 = 38) because these videos contain activities such as applying makeup (e.g., Figure 8-h).\nThese results indicate that ASMRtists tend to present activities without a clear, purposeful task. The taskless videos include mundane, repetitive, and unintentional actions, facing the viewers or only showing the trigger objects. Videos with particular tasks involve treating the viewer or another person, eating a large quantity of food, or other common everyday activities. Those activities are also considered soft, clicking, slow, or repetitive, which are likely to induce ASMR experiences [5]."
        },
        {
            "heading": "5.3 RQ3: Viewers\u2019 Comments about the Feelings of ASMR Experience",
            "text": "RQ3 explores viewers\u2019 feelings about different ASMR interactions by calculating the percentages of the LIWC and PMI identified keywords. We first compare the linguistic attributes of all ASMR video comments with the base rates of expressive writing, natural speech, and Twitter data [51]. Figure 9 shows the results. The emotion tone score of all ASMR comments is 99 (50 is neutral), higher than the other three types of textual data, indicating viewers\u2019 overall positive reaction to the ASMR videos. ASMR comments have comparable social word frequencies, suggesting viewers have similar social expression as in other texts. The body words (7.68%) and perception words (7.63%) in ASMR comments are higher than the other three texts. This shows that viewers write more in the comments about things associated with body and perception processes. The overall positive emotion and high frequency of body and perception words imply that viewers obtained sensational pleasure from watching the ASMR videos.\n5.3.1 Social and Intimacy. The LSR model that predicts social word frequencies by the parasocial attraction subcategories suggests that parasocial attraction factors are significant predictors (Table 5). The model that predicts social word frequencies by interaction modalities shows that visual and sound are significant predictors. The posthoc analysis shows that ASMR videos that leverage social attraction techniques lead to higher use of social words in the comments (Figure 10 top). The social word frequencies in talkto and talk-with (\ud835\udc60\ud835\udc5c\ud835\udc50\ud835\udc56\ud835\udc4e\ud835\udc59 .\ud835\udc61\ud835\udc4e\ud835\udc59\ud835\udc58_\ud835\udc61\ud835\udc5c and \ud835\udc60\ud835\udc5c\ud835\udc50\ud835\udc56\ud835\udc4e\ud835\udc59 .\ud835\udc61\ud835\udc4e\ud835\udc59\ud835\udc58_\ud835\udc64\ud835\udc56\ud835\udc61\u210e) videos are significantly higher than gesture/text videos (\ud835\udc60\ud835\udc5c\ud835\udc50\ud835\udc56\ud835\udc4e\ud835\udc59 .\ud835\udc54\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc62\ud835\udc5f\ud835\udc52&\ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 ) and non-social videos (\ud835\udc60\ud835\udc5c\ud835\udc50\ud835\udc56\ud835\udc4e\ud835\udc59 .\ud835\udc5b\ud835\udc5c\ud835\udc5b\ud835\udc52). Similarly, videos with ASMRtists whispering sounds have more social comments than videos without communication. For spatial proximity, videos with the ASMRtists being closeup (\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc65\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc61\ud835\udc66.\ud835\udc50\ud835\udc59\ud835\udc5c\ud835\udc60\ud835\udc52\ud835\udc62\ud835\udc5d), and medium distance (\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc65\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc61\ud835\udc66.\ud835\udc5a\ud835\udc52\ud835\udc51\ud835\udc56\ud835\udc62\ud835\udc5a) have higher social word frequencies than videos without ASMRtists\u2019 appearances. With regard to visual modalities, videos that use visual settings of static images (mostly audio-only roleplays), face-to-face interaction, and serving people have higher social word frequencies than Mukbang and object manipulation videos. These results indicate that the social attraction techniques used in ASMR videos, such as talking to/with the viewers, showing themselves face-to-face, and whispering led viewers to express more social processes in the comments than non-social ASMR videos.\nTable 5: Results of multivariate LSR models that predict the percentages of feeling words in comments. Only the p-values of significant predictors are presented. Adjusted \ud835\udefc = 0.0083. *Multi-choice factors, \ud835\udc5d is from the dummy variable with the smallest p-value.\nDependent variable LSR of Parasocial Attractions LSR of Multimodal Interactions \ud835\udc39 \ud835\udc5d \ud835\udc5f2 \ud835\udc5d\ud835\udc60\ud835\udc5c\ud835\udc50\ud835\udc56\ud835\udc4e\ud835\udc59 \ud835\udc5d\ud835\udc5d\u210e\ud835\udc66\ud835\udc60\ud835\udc56\ud835\udc50\ud835\udc4e\ud835\udc59 \ud835\udc5d\ud835\udc61\ud835\udc4e\ud835\udc60\ud835\udc58 \ud835\udc39 \ud835\udc5d \ud835\udc5f\n2 \ud835\udc5d\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 \ud835\udc5d\ud835\udc60\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51 * \ud835\udc5d\ud835\udc61\ud835\udc5c\ud835\udc62\ud835\udc50\u210e* \ud835\udc5d\ud835\udc61\ud835\udc4e\ud835\udc60\ud835\udc61\ud835\udc52 \ud835\udc5d\ud835\udc60\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc5c Social words 32.35 <0.0001 0.11 <0.0001 <0.0001 - 18.44 <0.0001 0.13 <0.0001 <0.0001 - - -\nIntimacy words 24.03 <0.0001 0.08 <0.0001 0.0012 <0.0001 16.92 <0.0001 0.12 0.0016 <0.0001 - - 0.0001 Body words 49.36 <0.0001 0.16 <0.0001 <0.0001 <0.0001 39.03 <0.0001 0.25 <0.0001 <0.0001 0.0002 0.0060 0.0003\nPerception words 29.55 <0.0001 0.10 <0.0001 <0.0001 0.0006 27.21 <0.0001 0.18 <0.0001 <0.0001 <0.0001 - <0.0001 Relax words 43.28 <0.0001 0.14 0.0003 <0.0001 <0.0001 30.42 <0.0001 0.20 <0.0001 <0.0001 <0.0001 0.00035 <0.0001 Sleep words 36.73 <0.0001 0.12 0.0065 0.0004 <0.0001 23.03 <0.0001 0.16 - <0.0001 <0.0001 <0.0001 <0.0001\nFigure 10: Social and intimate word frequencies between subcategories of significant multimodal and parasocial predictors. Ordered by the average percentage in descending order. Horizontal bars show significant differences (\ud835\udc5d* < 0.05, \ud835\udc5d** < 0.01, \ud835\udc5d*** < 0.001).\nThe LSR models which predict the intimate word frequency show that social, proximity, and task, are significant parasocial predictors (Table 5). Visual, sound, and scenario are the significant multimodal interaction predictors. The posthoc analysis shows that talking with or to viewers leads to more comments related to intimacy. Figure 10 bottom shows the results. Videos with whispering sounds also have significantly more intimate words in the comments than videos without whispering. Mukbang videos have significantly lower intimate words in comments. The comparison of intimate words shows that comments to roleplay videos have more viewers\u2019 intimate expressions than videos without roleplays. Since many fantasy and romance roleplays are voice-only, videos without performers\u2019 faces (\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc65\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc61\ud835\udc66.\ud835\udc5b\ud835\udc5c_\ud835\udc53 \ud835\udc4e\ud835\udc50\ud835\udc52), with static images (\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 .\ud835\udc56\ud835\udc5a\ud835\udc4e\ud835\udc54\ud835\udc52\ud835\udc60), and with ambient sounds (\ud835\udc60\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51.\ud835\udc4e\ud835\udc5a\ud835\udc4f\ud835\udc56\ud835\udc52\ud835\udc5b\ud835\udc50\ud835\udc52) have significantly higher numbers of intimate words in the comments.\nThe comparison of social and intimate words suggests that the ASMR videos with social interactions \u2013 such as presenting the ASMRtist in the videos and whispering to the viewers \u2013 are more likely to receive viewers\u2019 social responses than ASMR videos without socialization. Roleplays lead to more intimate reactions in the comments than non-roleplay videos. In contrast, Mukbang and object-only videos have lower social and intimate expressions.\n5.3.2 Body and Perception. Viewers share their body and perceptual feelings or comment on ASMRtists\u2019 body or actions. The LSR model suggests social, spatial, and task attractions can significantly predict the use of body and perception words (Table 5). All multimodal interaction subcategories are significant predictors of body words. Visual, sound, touch, and scenario are significant predictors of perception words. Posthoc shows that Mukbang videos\nlead to the highest sensory words in comments (Figure 11). Eating or drinking videos (\ud835\udc61\ud835\udc4e\ud835\udc60\ud835\udc58.\ud835\udc52\ud835\udc4e\ud835\udc61&\ud835\udc51\ud835\udc5f\ud835\udc56\ud835\udc5b\ud835\udc58) have significantly more sensory responses than other task-oriented and taskless videos. Comments to videos that contain mouth sounds have significantly more body and perception words. Taste interactions lead to significantly more body words. Since Mukbang videos tend to show partial faces and only use gestures and text to communicate (e.g., Figure 8-e and f), the gesture/text (\ud835\udc60\ud835\udc5c\ud835\udc50\ud835\udc56\ud835\udc4e\ud835\udc59 .\ud835\udc54\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc62\ud835\udc5f\ud835\udc52&\ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61 ) and the partial face (\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc65\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc61\ud835\udc66.\ud835\udc5d\ud835\udc4e\ud835\udc5f\ud835\udc61\ud835\udc56\ud835\udc4e\ud835\udc59_\ud835\udc53 \ud835\udc4e\ud835\udc50\ud835\udc52) videos have the highest sensory word use in the comments. We also noticed that videos without tasks (\ud835\udc61\ud835\udc4e\ud835\udc60\ud835\udc58.\ud835\udc5b\ud835\udc5c\ud835\udc5b\ud835\udc52) have higher body words. Non-roleplay videos (\ud835\udc60\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc5c.\ud835\udc5b\ud835\udc5c\ud835\udc5b\ud835\udc52) have the highest usages of body and perception words. Object-only videos (\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 .\ud835\udc5c\ud835\udc4f \ud835\udc57\ud835\udc52\ud835\udc50\ud835\udc61_\ud835\udc5c\ud835\udc5b\ud835\udc59\ud835\udc66, e.g., Figure 8-b and c) also have a higher mentioning of the body and perception words. Videos with object sounds (\ud835\udc60\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51.\ud835\udc5c\ud835\udc4f \ud835\udc57\ud835\udc52\ud835\udc50\ud835\udc61 , e.g., Figure 6-c and Figure 7-b) and mic sounds (\ud835\udc60\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51.\ud835\udc5a\ud835\udc56\ud835\udc50 , e.g., Figure 7-d and 8-a) have significantly more comments with body and perception words. These results imply that presenting and consuming a large quantity of food in ASMR videos, as well as videos without tasks or roleplays are more likely to induce viewers\u2019 feelings related to sensory perception.\n5.3.3 Relaxation and Sleepiness. The LSR model that predicts relaxation words shows that all parasocial and multimodal subcategories are significant predictors (Table 5). The model that predicts sleep words suggests that all parasocial and multimodal subcategories except for visual interaction are significant predictors. Posthoc analysis between different categories shows that videos related to treatment and intimate interactions have the highest percentage of relax and sleep words in comments (Figure 12). Videos with treatment performance (\ud835\udc61\ud835\udc4e\ud835\udc60\ud835\udc58.\ud835\udc61\ud835\udc5f\ud835\udc52\ud835\udc4e\ud835\udc61\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61 and \ud835\udc60\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc5c.\ud835\udc60\ud835\udc52\ud835\udc5f\ud835\udc63\ud835\udc56\ud835\udc50\ud835\udc52) have the highest percentages for both measurements. Videos that involve performing services on another person (\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc62\ud835\udc4e\ud835\udc59 .\ud835\udc60\ud835\udc52\ud835\udc5f\ud835\udc63\ud835\udc52_\ud835\udc5d\ud835\udc52\ud835\udc5c\ud835\udc5d\ud835\udc59\ud835\udc52 and \ud835\udc61\ud835\udc5c\ud835\udc62\ud835\udc50\u210e.\ud835\udc5f\ud835\udc52\ud835\udc4e\ud835\udc59_\ud835\udc5d\ud835\udc52\ud835\udc5c\ud835\udc5d\ud835\udc59\ud835\udc52) also lead to more relaxation expression. Videos that pretend to touch the viewer by reaching toward the camera (\ud835\udc61\ud835\udc5c\ud835\udc62\ud835\udc50\u210e.\ud835\udc63\ud835\udc56\ud835\udc52\ud835\udc64\ud835\udc52\ud835\udc5f ) have significantly more sleep words than videos without this interaction. ASMR videos with mic sounds (\ud835\udc60\ud835\udc5c\ud835\udc62\ud835\udc5b\ud835\udc51.\ud835\udc5a\ud835\udc56\ud835\udc50), in which ASMRtists get close up to the camera and make near-ear mic sound effects (e.g., Figure 7-d and Figure 8-a), lead viewers to comment more about relaxation and sleepiness.\nThese results imply that videos showing treatment processes and physical intimacy induce feelings of relaxation and sleepiness for viewers more often. Videos with near-ear microphone effects also incite feelings of relaxation and sleepiness. It should be noted that although the visual and touch settings of treatment ASMRs seek to simulate physical intimacy with the viewers, viewers do not express more intimacy in the comments. Instead, the emulation of close proximity interactions in treatments lets viewers express more relaxation and sleepiness."
        },
        {
            "heading": "6 DISCUSSION",
            "text": "The analysis of multimodal interactions and parasocial attractions describes the common patterns used to induce ASMR experiences through audio-visual media. Our work depicts commonASMR interactions but does not contrast their effects with other online content. This section summarizes that the ASMRtists deliver ASMR effects\nthrough three experience patterns: multimodal social connection, relaxing physical intimacy, and sensory-rich activity observation."
        },
        {
            "heading": "6.1 ASMR as an Experience of Multimodal Social Connection",
            "text": "Prior research primarily examine ASMR triggers\u2019 characteristics, and their different physiological effects on the viewers [6, 53, 55]. Although ASMR videos are considered as a new pathway to connect creators and their viewers [40], there is little knowledge regarding what specific interactions ASMRtists perform to best establish social connections. We find the social experience in YouTube ASMR videos is commonly offered and multi-modeled. Around 65% of videos in our data contain the performer looking at the camera, which gives the illusion of a \u201cface-to-face\u201d interaction between the actor and the viewer, and 78% of videos involve whispering. 70% of ASMR videos have ASMRtists communicating verbally to the viewer, with 24% of videos pretending that the performer can hear viewers\u2019 reply (talk-with videos). 59.07% of videos used at least one type of touch interaction. The pervasive use of conversational content reveals that sound effects are not the only drivers of ASMR; ASMRtists engage viewers and induce ASMR through experiences of one-sided social connection. These results are consistent with the significance of face-to-face interactions noted in prior research [64]. In a multimodal conversation, the performer faces the viewer, communicates in whispers, touches the viewers through camera reaching, introduces and manipulates triggers, and emulates imagined scenarios. Since ASMR needs to be triggered with appropriate stimuli [5], and because not all triggers \u201cwork\u201d for all viewers, the diverse modalities allow viewers to try out and encounter triggers that can bring ASMR sensations. The social interactions could also foster the feeling of co-presence with the ASMR performer [70]. Interaction modalities such as whispering with/to the viewers and being spatially close up to the camera lead viewers to write more about the social processes in the comments. Even in audio-only videos without visual presentations, ASMRtists play fantasy and romantic roles and chat with the viewers in stories. The analysis of viewer comments suggests that viewers tend to leave more intimate comments to videos with those ASMR components.\nThese findings imply new pathways to design parasocial experiences with ASMR effects. ASMR interaction techniques can provide social exposure that increases closeness in asynchronous video communication. Video-based technologies incorporating ASMR effects and multimodal ASMR interactions may augment parasocial connection experiences. Since ASMR may offer positive affect, as well as intimate and relaxing experiences for viewers [3? ], face-to-face video communications can leverage ASMR interactions to transfer the process of speaking-listening to a richer experience with tingling sensations. The social experience pattern captured from ASMRtists\u2019 videos implies that technologies can incorporate ASMR interactions in multiple modalities such as whispering, camerareaching, emulated back-and-forth conversation, and trigger manipulation in order to induce viewers\u2019 ASMR sensations. Users need both time and variety in order to see if tingles develop, and the multi-modalities allow for that temporal unfolding and variety. For example, applications such as video conferencing tools, podcasts, and social audio apps can potentially introduce multimodal\nASMR to reduce the exhaustion and fatigue from long-time use [44]. Voice-based virtual assistants [50] may also include ASMR effects to reduce the robotic sound."
        },
        {
            "heading": "6.2 ASMR as an Experience of Relaxing",
            "text": "Physical Intimacy\nLeveraging attraction and interaction techniques to demonstrate intimacy is also a typical pattern in ASMRtists\u2019 videos. Prior research has explored ASMR as an experience of digital intimacy [3, 31] as well as the ways ASMRtists create roleplay videos to foster intimate feelings with the viewers [70]. This paper overviews ASMRtists\u2019 techniques to design intimate experiences and how these techniques relax viewers and help with sleeping. We find that the most common camera shot type in ASMR videos is closeup \u2013 framing the performer\u2019s face at a near distance while excluding most of their body. Around 30% of videos have the ASMRtists pretending to touch the viewers through camera reaching. About 30% of videos also make close-mic mouth sounds, and 12% manipulate the microphone itself to simulate physical intimacy through sound interactions. These interactions are commonly performed in service-oriented videos such those involving massage, haircuts, makeup applications, etc. However, our comment analysis suggests\nthat viewers do not express more intimacy to videos with intimate interactions than other videos. On the other hand, videos with close interactions have more comments regarding relaxation and sleepiness-related words. Our results imply that although ASMRtists virtually approach the viewers, viewers expressed relaxing and calming experiences more than intimacy to such videos.\nOur findings suggest new opportunities to design ASMR-based applications to present intimacy and deliver soothing experiences. For example, ASMR interactions allow service providers such as masseurs and Reiki masters to offer virtual treatments through ASMR videos. This virtual therapy could provide a possible solution when in-person service is unavailable, or for users who cannot afford in-person treatment. People separated from loving relationships [21] or patients living in stressful hospital settings [66] need intimate interactions. ASMR effects with close-mic whispers and near-camera touching could potentially engender a feeling of intimacy to induce relaxing experiences. Virtual social encounters with ASMR performers could also provide alternatives for people with social difficulties (e.g., due to autism or social anxiety) to enjoy safe, calm, regularized social experiences on demand [29]. To augment such experiences, designers can create new ASMR video\ninteractions. For example, ASMRtists use the talk-with and camerareaching techniques to mimic physical proximity. Novel interaction techniques such as VR, AR, and other telepresence technologies can be integrated to augment the social and virtual presence during ASMR videos. However, we want to remind the HCI community of the existance of sexual ASMR videos (S-ASMR) that are intentionally made for sexuality and sexual arousal [64]. The design for intimacy needs to differentiate ASMR videos from S-ASMR videos, especially to avoid young kids accessing an S-ASMR video without parental guidance."
        },
        {
            "heading": "6.3 ASMR as an Experience of Sensory-rich Activity Observation",
            "text": "Prior research have studied roleplay ASMRs as a primary type [35, 41, 64, 67, 70]. However, our findings suggest that more than 70% of videos in our data do not have roleplay scenarios. Also, in contrast to the wide use of social attraction and spatial proximity, most ASMRtists\u2019 videos do not use task attractions to elicit ASMR experiences. Only around 40% of videos in our dataset have identifiable tasks and goals. These numbers indicate that intentional ASMR videos are not limited to roleplays; future work should include the diverse non-roleplays and taskless videos when examining ASMR performance and effects. Videos with tasks include the performance\nof various physical treatments, eating a large quantities of food, and displaying mundane activities such as playing cards or putting on makeup. Taskless videos can involve casual chatting or object or mic manipulation without showing the performer. The infrequent appearance in videos of purposeful tasks implies that ASMR effects do not require attention or real acts of care to take place. Therefore, many ASMRtists choose not to demonstrate abilities by completing tasks or making clear storylines, but instead remain focused exclusively on the production of triggering effects. The analysis of viewer comments further reveals that eating/drinking videos and videos without tasks or roleplays are associated with viewers\u2019 comments about the body and perceptual processes, indicating that these videos are prone to trigger bodily and perceptual experiences.\nAlthough personal attention, care, and intimacy are common elicitors of ASMR [3], our findings suggest many ASMRtists also adopt the \u201ctaskless\u201d activities in ASMR videos. Those videos don\u2019t particularly care about addressing viewers, adopting a stance of calculated indifference, and this disinvested attitude is designed to induce ASMR feelings. Therefore, videos that does not require close attention except for observing peaceful and repetitive activities \u2013 videos such as crafting process demonstrations, instructions for applying makeups or skincare, and tutorials on organizing everyday objects \u2013 may consider employing ASMR effects. Prior research\nsuggested that ASMR is an ambient sensory effect in YouTube study-with-me videos [37]. Videos like these can potentially reduce the human presence and intentionally make tingling sounds in the background to trigger ASMR feelings. However, videos that include slow and dull tasks may evoke ASMR feelings unintentionally and could make viewers lose focus and feel sleepy. In those cases, ASMR may need to be avoided if the video is geared toward learning and requires attention. Designers may also consider conveying sensoryrich experiences through Mukbang ASMR or sound-focused ASMR. Watching food-eating videos has shown benefits to mitigate homesickness [30]. People watch Mukbang videos to gain multi-sensory immersion and \u201ccommensality.\u201d [4] ASMR can be a sensory experience incorporated in human-food interaction [15, 67]. Interaction designers can induce ASMR experiences by mouth and mic sounds to augment sensory pleasure. Technologies for sensory reality and relaxation (e.g., virtual reality for anxiety-related problems [48]) can incorporate ASMR techniques such as eating/drinking sounds or sound-focused scenes to induce sense of presence and relaxing experiences."
        },
        {
            "heading": "7 CONCLUSION AND FUTUREWORK",
            "text": "This work analyzed the multimodal interactions and parasocial experiences in 2663 YouTube ASMR videos. We annotated how ASMRtists use visual, sound, touch, taste, and roleplay triggers to deliver social, physical, and task attractiveness. We obtained the distribution of ASMR interaction modalities and parasocial attractions. The associations between interaction modalities and parasocial attractions reveal patterns of ASMR experiences. Feelingoriented words were recognized from viewer comments in order to probe whether different ASMR interactions lead to different viewer feelings. Face-to-face orientation, whispering sounds, and touching objects are the most interaction modalities. Social interactions are common and multi-modeled. ASMRtists implement social attractions and virtually proximate the viewers, but most ASMR videos do not involve roleplays or contain purposeful tasks. Our results summarize that YouTube ASMR videos provide three experiences: multimodal social connection, relaxing physical intimacy, and sensory-rich activity observation. These experiential descriptions seek to foster future media productions on a wide array of platforms that include ASMR interactions and effects.\nMoving forward, we hope this work serves as a seminal study to inspire more ASMR-augmented designs. There are also many open-ended questions to be addressed by HCI researchers and practitioners. First, one limitation of this work is that we only consider intentional ASMR created and shared by YouTube ASMRtists to induce ASMR experiences specifically. Prior studies noticed viewers also experience ASMR with videos such as Bob Ross\u2019 The Joy of Painting and a recording of Lectures on Quantum Field Theory [20, 41], which are not made for ASMR but contains ASMR properties. We did not include unintentional videos without \u201cASMR\u201d labels due to difficulties recognizing and collecting them from YouTube. We also consider intentional ASMR interactions to be purposefully designed and performed; therefore, easier to be adopted in design. Future research may compare and contrast the effects of the two ASMR video types. Second, this work does not interview actual\nviewers to obtain their in-situ feelings of ASMR interactions; viewers\u2019 reactions to different ASMR interactions were obtained from video comments. It is possible that viewers do not externalize all of their feelings of intimacy or relaxation in comments. However, we believe this work provides an overview of ASMR interaction techniques that can guide future studies to examine ASMR-based intimacy and well-being in various use cases [39]. Future research needs to assess the actual effects of ASMR interactions of different people and in different contexts, especially when ASMR interactions are designed for people with social anxiety or disabilities. Third, YouTube creators contribute vernacular creativity [9] to build parasocial relationships. HCI researchers should consider interviewing ASMRtists or involving them in participatory design to understand their preferences and difficulties in managing parasocial interactions. Last, the growing ASMR communities across different cultures [4, 37] encourages HCI studies to examine how ASMR videos affect the creator-viewer communications and relationships. It is valuable to expand ASMR research to non-English videos to have a cross-cultural understanding of ASMR."
        },
        {
            "heading": "A DATA PROTECTION IMPACT ASSESSMENT (DPIA)",
            "text": "All videos are publicly shared when gathered, and the researchers did not directly interact with any ASRMtists to collect any information about the video creators. We acknowledge this work uses automated data processing tools (LIWC and PMI) to recognize behavioral information from YouTube comments. To protect YouTube users\u2019 privacy, we de-linked the YouTube account information from the collected comments after the data was collected. To our best knowledge, YouTube does not support searching comments. LIWC and PMI are lexicon-based techniques that count the appearance of words related to the measured dimensions. Only words related to common feelings such as social process, intimacy, perception, and relaxation are quantified. We did not intentionally recognize or process any identity information.\nThe data annotation on Amazon Mechanical Turk only involves identifying objective information from the video (e.g., how the\nASMRtist interacts with trigger objects or the camera). All questions are multi-choice questions with pre-defined categories. We do not ask participants to provide personal information or subjectively describe any video content. To protect the participants who are uncomfortable with ASMR videos, all participants must pass a qualification test before the study. The participant must indicate that they had watched ASMR videos before and did not feel them disturbing. At the beginning of the annotation, we also informed that if the video content makes the participant uncomfortable, they should close the survey immediately. With the careful research steps, the IRB office at the authors\u2019 institute granted an exemption to the protocol of this study."
        }
    ],
    "title": "Close-up and Whispering: An Understanding of Multimodal and Parasocial Interactions in YouTube ASMR videos",
    "year": 2023
}