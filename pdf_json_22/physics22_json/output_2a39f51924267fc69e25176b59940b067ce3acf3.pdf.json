{
    "abstractText": "Carnegie Mellon University, Pittsburgh, PA, United States, Astronomical Observatory of Jagiellonian University, Krak\u00f3w, Poland, National Astronomical Observatory of Japan, Mitaka, Japan, Space Science Institute, Boulder, CO, United States, Department of Mathematics, University of Wroclaw, Wroc\u0142aw, Poland, Department of Statistics, Lund University, Lund, Sweden, Astronomical Observatory of Jagiellonian University, Krakow, Poland, National Centre for Nuclear Research, Warsaw, Poland, Physics Department, University of Michigan, Ann Arbor, MI, United States, Theoretical Quantum Physics Laboratory, RIKEN, Wako, Japan, Interdisciplinary Theoretical and Mathematical Science Program, RIKEN (iTHEMS), Wako, Japan, Finnish Centre for Astronomy with ESO (FINCA), University of Turku, Turku, Finland",
    "authors": [
        {
            "affiliations": [],
            "name": "Spencer James Gibson"
        },
        {
            "affiliations": [],
            "name": "Aditya Narendra"
        },
        {
            "affiliations": [],
            "name": "Maria Giovanna Dainotti"
        },
        {
            "affiliations": [],
            "name": "Malgorzata Bogdan"
        },
        {
            "affiliations": [],
            "name": "Agnieszka Pollo"
        },
        {
            "affiliations": [],
            "name": "Artem Poliszczuk"
        },
        {
            "affiliations": [],
            "name": "Enrico Rinaldi"
        },
        {
            "affiliations": [],
            "name": "Ioannis Liodakis"
        }
    ],
    "id": "SP:f21aa89b8d30242d4842a7f17138ce1868173e78",
    "references": [
        {
            "authors": [
                "M. Ackermann",
                "M. Ajello",
                "A. Albert",
                "W.B. Atwood",
                "L. Baldini",
                "J Ballet"
            ],
            "title": "Multiwavelength Evidence for Quasi-Periodic Modulation in the Gamma-Ray Blazar PG 1553+113",
            "venue": "Astrophysical J. Lett. 813,",
            "year": 2015
        },
        {
            "authors": [
                "M. Ackermann",
                "M. Ajello",
                "A. Allafort",
                "L. Baldini",
                "J. Ballet",
                "D Bastieri"
            ],
            "title": "GeV Observations of Star-forming Galaxies with the Fermi Large Area Telescope",
            "venue": "Astrophysical J. 755,",
            "year": 2012
        },
        {
            "authors": [
                "H. Aihara",
                "C.A. Prieto",
                "D. An",
                "S.F. Anderson",
                "\u00c9. Aubourg",
                "E Balbinot"
            ],
            "title": "Erratum: The Eighth Data Release of the sloan Digital Sky Survey: First Data from SDSS-III.Astrophysical",
            "venue": "J. Suppl. Ser. 193,",
            "year": 2011
        },
        {
            "authors": [
                "M. Ajello",
                "R. Angioni",
                "M. Axelsson",
                "J. Ballet",
                "G. Barbiellini",
                "D Bastieri"
            ],
            "title": "The Fourth Catalog of Active Galactic Nuclei Detected by the Fermi Large Area Telescope",
            "venue": "ApJ 892,",
            "year": 2020
        },
        {
            "authors": [
                "A. Birnbaum"
            ],
            "title": "On the Foundations of Statistical Inference",
            "venue": "J. Am. Stat. Assoc. 57, 269\u2013306. doi:10.1080/01621459.1962.10480660",
            "year": 1962
        },
        {
            "authors": [
                "L. Breiman"
            ],
            "title": "Random Forests",
            "venue": "Machine Learn. 45, 5\u201332. doi:10.1023/a: 1010933404324",
            "year": 2001
        },
        {
            "authors": [
                "M. Brescia",
                "S. Cavuoti",
                "R. D\u2019Abrusco",
                "G. Longo",
                "A. Mercurio"
            ],
            "title": "Photometric Redshifts for Quasars in Multi-Band Surveys",
            "venue": "ApJ 772,",
            "year": 2013
        },
        {
            "authors": [
                "M. Brescia",
                "M. Salvato",
                "S. Cavuoti",
                "T.T. Ananna",
                "G. Riccio",
                "LaMassa",
                "S. M"
            ],
            "title": "Photometric Redshifts for X-ray-selected Active Galactic Nuclei in the eROSITA Era.Monthly Notices R",
            "year": 2019
        },
        {
            "authors": [
                "S. Cavuoti",
                "M. Brescia",
                "R. D\u2019Abrusco",
                "G. Longo",
                "M. Paolillo"
            ],
            "title": "Photometric Classification of Emission Line Galaxies with MachineLearning Methods",
            "venue": "Monthly Notices R. Astronomical Soc. 437,",
            "year": 2014
        },
        {
            "authors": [
                "J. Chiang",
                "C.E. Fichtel",
                "C. Von Montigny",
                "P.L. Nolan",
                "V. Petrosian"
            ],
            "title": "The Evolution of Gamma-Ray\u2013loud Active Galactic Nuclei",
            "venue": "ApJ 452, 156. doi:10.1086/176287",
            "year": 1995
        },
        {
            "authors": [
                "C. Cortes",
                "V. Vapnik"
            ],
            "title": "Support-vector networks",
            "venue": "Machine Learn. 20, 273\u2013297. doi:10.1023/a:1022627411411",
            "year": 1995
        },
        {
            "authors": [
                "S.J. Curran"
            ],
            "title": "QSO Photometric Redshifts from SDSS, WISE, and GALEX Colours.Monthly Notices R",
            "venue": "Astronomical Soc. Lett. 493,",
            "year": 2020
        },
        {
            "authors": [
                "M.G. Dainotti",
                "M. Bogdan",
                "A. Narendra",
                "S.J. Gibson",
                "B. Miasojedow",
                "I Liodakis"
            ],
            "title": "Predicting the Redshift of \u03b3-Ray-loud AGNs Using Supervised Machine Learning",
            "venue": "ApJ 920,",
            "year": 2021
        },
        {
            "authors": [
                "A. D\u2019Isanto",
                "K.L. Polsterer"
            ],
            "title": "Photometric Redshift Estimation via Deep Learning. Generalized and Pre-Classification-Less, Image Based, Fully Probabilistic Redshifts",
            "venue": "aap 609,",
            "year": 2018
        },
        {
            "authors": [
                "A. Dom\u00ednguez",
                "R. Wojtak",
                "J. Finke",
                "M. Ajello",
                "K. Helgason",
                "F Prada"
            ],
            "title": "A NewMeasurement of the Hubble Constant andMatter Content of the Universe",
            "year": 2019
        },
        {
            "authors": [
                "S. Fotopoulou",
                "S. Paltani"
            ],
            "title": "CPz: Classification-Aided PhotometricRedshift Estimation",
            "venue": "A&A 619, A14. doi:10.1051/0004-6361/201730763",
            "year": 2018
        },
        {
            "authors": [
                "J. Friedman",
                "T. Hastie",
                "R. Tibshirani"
            ],
            "title": "Regularization Paths for Generalized Linear Models via Coordinate Descent",
            "venue": "J. Stat. Softw. 33, 1. doi:10.18637/jss.v033.i01",
            "year": 2010
        },
        {
            "authors": [
                "J.H. Friedman",
                "C.B. Roosen"
            ],
            "title": "An Introduction to Multivariate Adaptive Regression Splines",
            "venue": "Stat. Methods Med. Res. 4, 197\u2013217. doi:10. 1177/096228029500400303",
            "year": 1995
        },
        {
            "authors": [
                "P. Geurts",
                "D. Ernst",
                "L. Wehenkel"
            ],
            "title": "Extremely Randomized Trees",
            "venue": "Machine Learn. 63, 42\u201363. doi:10.1007/s10994-006-6226-1",
            "year": 2006
        },
        {
            "authors": [
                "T.J. Hastie",
                "R.J. Tibshirani"
            ],
            "title": "Generalized Additive Models, 43",
            "venue": "Boca Raton: CRC Press.",
            "year": 1990
        },
        {
            "authors": [
                "T. Hastie",
                "R. Tibshirani"
            ],
            "title": "Generalized Additive Models: Some Applications",
            "venue": "J. Am. Stat. Assoc. 82, 371\u2013386. doi:10.1080/01621459.1987. 10478440",
            "year": 1987
        },
        {
            "authors": [
                "H. Hildebrandt",
                "S. Arnouts",
                "P. Capak",
                "L.A. Moustakas",
                "C. Wolf",
                "Abdalla",
                "F. B"
            ],
            "title": "PHAT: PHoto-zAccuracy Testing",
            "venue": "A&A 523,",
            "year": 2010
        },
        {
            "authors": [
                "T.K. Ho"
            ],
            "title": "Random Decision Forests,",
            "venue": "Proceedings of the Third International Conference on Document Analysis and Recognition",
            "year": 1995
        },
        {
            "authors": [
                "T. Hothorn",
                "K. Hornik",
                "A. Zeileis"
            ],
            "title": "Unbiased Recursive Partitioning: A Conditional Inference Framework",
            "venue": "J. Comput. Graphical Stat. 15, 651\u2013674. doi:10.1198/106186006x133933",
            "year": 2006
        },
        {
            "authors": [
                "O. Ilbert",
                "P. Capak",
                "M. Salvato",
                "H. Aussel",
                "H. McCracken",
                "Sanders",
                "D. B"
            ],
            "title": "Cosmos Photometric Redshifts with 30-Bands",
            "year": 2008
        },
        {
            "authors": [
                "E. Jones",
                "J. Singal"
            ],
            "title": "Analysis of a Custom Support Vector Machine for Photometric Redshift Estimation and the Inclusion of Galaxy Shape Information",
            "venue": "A&A 600, A113. doi:10.1051/0004-6361/201629558",
            "year": 2017
        },
        {
            "authors": [
                "I. Liodakis",
                "T. Hovatta",
                "D. Huppenkothen",
                "S. Kiehlmann",
                "W. Max-Moerbeck",
                "A.C.S. Readhead"
            ],
            "title": "Constraining the Limiting Brightness Temperature and Doppler Factors for the Largest Sample of Radio-Bright Blazars",
            "venue": "ApJ 866, 137. doi:10.3847/1538-4357/aae2b7",
            "year": 2018
        },
        {
            "authors": [
                "I. Liodakis",
                "V. Pavlidou",
                "T. Hovatta",
                "W. Max-Moerbeck",
                "T.J. Pearson",
                "Richards",
                "J. L"
            ],
            "title": "Bimodal Radio Variability in OVRO-40 M-Monitored Blazars",
            "venue": "MNRAS 467,",
            "year": 2017
        },
        {
            "authors": [
                "R.J. Little",
                "D.B. Rubin"
            ],
            "title": "Statistical Analysis with Missing Data, 793",
            "venue": "Hoboken: John Wiley & Sons.",
            "year": 2019
        },
        {
            "authors": [
                "C.H.A. Logan",
                "S. Fotopoulou"
            ],
            "title": "Unsupervised star, Galaxy, QSO Classification",
            "venue": "A&A 633, A154. doi:10.1051/0004-6361/201936648",
            "year": 2020
        },
        {
            "authors": [
                "K.J. Luken",
                "R. Padhy",
                "X.R. Wang"
            ],
            "title": "Missing Data Imputation for Galaxy Redshift Estimation",
            "venue": "arXiv:2111.13806.",
            "year": 2021
        },
        {
            "authors": [
                "L. Marcotulli",
                "M. Ajello",
                "M. Di Mauro"
            ],
            "title": "The Density of Blazars above 100 MeV and the Origin of the Extragalactic Gamma-ray Background,",
            "venue": "American Astronomical Society Meeting Abstracts (American Astronomical Society Meeting Abstracts),",
            "year": 2020
        },
        {
            "authors": [
                "A. Narendra",
                "S.J. Gibson",
                "M.G. Dainotti",
                "M. Bogdan",
                "A. Pollo",
                "I Liodakis"
            ],
            "title": "Predicting the Redshift of Gamma-ray Loud AGNs Using Supervised Machine Learning: Part 2. arXiv:2201.05374",
            "year": 2022
        },
        {
            "authors": [
                "J. Pasquet-Itam",
                "J. Pasquet"
            ],
            "title": "Deep Learning Approach for Classifying, Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82",
            "venue": "A&AAstronomy & Astrophysics 611, A97. doi:10.1051/ 0004-6361/201731106",
            "year": 2018
        },
        {
            "authors": [
                "V. Petrosian"
            ],
            "title": "Surface Brightness and Evolution of Galaxies",
            "venue": "ApJ 209, L1. doi:10.1086/182253",
            "year": 1976
        },
        {
            "authors": [
                "E.C. Polley",
                "M.J. Van der Laan"
            ],
            "title": "Super Learner in Prediction",
            "venue": "U.C. Berkeley Division of Biostatistics Working Paper Series. Bepress. Available at: https://biostats.bepress.com/ucbbiostat/paper266",
            "year": 2010
        },
        {
            "authors": [
                "D.B. Rubin"
            ],
            "title": "Inference and Missing Data",
            "venue": "Biometrika 63, 581\u2013592. doi:10. 1093/biomet/63.3.581",
            "year": 1976
        },
        {
            "authors": [
                "M. Salvato",
                "O. Ilbert",
                "B. Hoyle"
            ],
            "title": "The many Flavours of Photometric Redshifts",
            "venue": "Nat. Astron. 3, 212\u2013222. doi:10.1038/s41550-018-0478-0",
            "year": 2019
        },
        {
            "authors": [
                "J.L. Schafer",
                "J.W. Graham"
            ],
            "title": "Missing Data: Our View of the State of the Art",
            "venue": "Psychol. Methods 7, 147\u2013177. doi:10.1037/1082-989x.7.2.147",
            "year": 2002
        },
        {
            "authors": [
                "J. Singal"
            ],
            "title": "A Determination of the Gamma-ray Flux and Photon Spectral index Distributions of Blazars from theFermi-LAT 3LAC.Mon",
            "venue": "Not. R. Astron. Soc. 454,",
            "year": 2015
        },
        {
            "authors": [
                "J. Singal",
                "A. Ko",
                "V. Petrosian"
            ],
            "title": "Gamma-Ray Luminosity and Photon Index Evolution of FSRQ Blazars and Contribution to the Gamma-Ray Background",
            "venue": "Astrophysical J. 786, 109.",
            "year": 2014
        },
        {
            "authors": [
                "J. Singal",
                "A. Ko",
                "V. Petrosian"
            ],
            "title": "Flat Spectrum Radio Quasar Evolution and the Gamma-ray Background",
            "venue": "Proc. IAU 9, 149\u2013152. doi:10.1017/ s1743921314003597 Frontiers in Astronomy and Space Sciences | www.frontiersin.org",
            "year": 2013
        },
        {
            "authors": [
                "J. Singal",
                "V. Petrosian",
                "M. Ajello"
            ],
            "title": "Flux and Photon Spectral Index Distributions Offermi-Lat Blazars and Contribution to the Extragalactic Gamma-ray Background",
            "venue": "ApJ 753, 45. doi:10.1088/0004-637x/753/1/45",
            "year": 2012
        },
        {
            "authors": [
                "J. Singal",
                "V. Petrosian",
                "A. Ko"
            ],
            "title": "Cosmological Evolution of the FSRQ Gamma-ray Luminosity Function and Spectra and the Contribution to the Background Based on Fermi-LAT Observations",
            "venue": "AAS/High Energy Astrophysics Division# 13, 300\u2013307.",
            "year": 2013
        },
        {
            "authors": [
                "R. Tibshirani"
            ],
            "title": "Regression Shrinkage and Selection via the Lasso",
            "venue": "J. R. Stat. Soc. Ser. B (Methodological) 58, 267\u2013288. doi:10.1111/j.2517-6161.1996.tb02080.x",
            "year": 1996
        },
        {
            "authors": [
                "S. Van Buuren",
                "K. Groothuis-Oudshoorn"
            ],
            "title": "mice: Multivariate Imputation by Chained Equations in R",
            "venue": "J. Stat. Softw. 45, 1\u201367. doi:10.18637/jss.v045.i03",
            "year": 2011
        },
        {
            "authors": [
                "T.M. Venters",
                "V. Pavlidou"
            ],
            "title": "Probing the Intergalactic Magnetic Field with the Anisotropy of the Extragalactic Gamma-ray Background.MNRAS",
            "year": 2013
        },
        {
            "authors": [
                "S.P. Wakely",
                "D. andHoran"
            ],
            "title": "TeVCat: An online catalog for VeryHigh Energy Gamma-Ray Astronomy,",
            "venue": "in International Cosmic Ray Conference,",
            "year": 2008
        },
        {
            "authors": [
                "E.L. Wright",
                "P.R.M. Eisenhardt",
                "A.K. Mainzer",
                "M.E. Ressler",
                "R.M. Cutri",
                "T Jarrett"
            ],
            "title": "The Wide-field Infrared Survey Explorer (WISE): Mission Description and Initial On-orbit Performance",
            "venue": "Astronomical J. 140,",
            "year": 2010
        },
        {
            "authors": [
                "Q. Yang",
                "Wu",
                "X.-B",
                "X. Fan",
                "L. Jiang",
                "I. McGreer",
                "R Green"
            ],
            "title": "Quasar Photometric Redshifts and Candidate Selection: A New Algorithm Based on",
            "year": 2017
        },
        {
            "authors": [
                "Mata",
                "J. A"
            ],
            "title": "Machine-learning Classifiers for",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "Using Multivariate Imputation by Chained Equations to Predict Redshifts of Active Galactic Nuclei Spencer James Gibson1, Aditya Narendra2, Maria Giovanna Dainotti 3,4*, Malgorzata Bogdan5,6, Agnieszka Pollo7,8, Artem Poliszczuk8, Enrico Rinaldi 9,10,11 and Ioannis Liodakis12\n1Carnegie Mellon University, Pittsburgh, PA, United States, 2Astronomical Observatory of Jagiellonian University, Krak\u00f3w, Poland, 3National Astronomical Observatory of Japan, Mitaka, Japan, 4Space Science Institute, Boulder, CO, United States, 5Department of Mathematics, University of Wroclaw, Wroc\u0142aw, Poland, 6Department of Statistics, Lund University, Lund, Sweden, 7Astronomical Observatory of Jagiellonian University, Krakow, Poland, 8National Centre for Nuclear Research, Warsaw, Poland, 9Physics Department, University of Michigan, Ann Arbor, MI, United States, 10Theoretical Quantum Physics Laboratory, RIKEN, Wako, Japan, 11Interdisciplinary Theoretical and Mathematical Science Program, RIKEN (iTHEMS), Wako, Japan, 12Finnish Centre for Astronomy with ESO (FINCA), University of Turku, Turku, Finland\nRedshift measurement of active galactic nuclei (AGNs) remains a time-consuming and challenging task, as it requires follow up spectroscopic observations and detailed analysis. Hence, there exists an urgent requirement for alternative redshift estimation techniques. The use of machine learning (ML) for this purpose has been growing over the last few years, primarily due to the availability of large-scale galactic surveys. However, due to observational errors, a significant fraction of these data sets often have missing entries, rendering that fraction unusable for ML regression applications. In this study, we demonstrate the performance of an imputation technique called Multivariate Imputation by Chained Equations (MICE), which rectifies the issue of missing data entries by imputing them using the available information in the catalog. We use the Fermi-LAT Fourth Data Release Catalog (4LAC) and impute 24% of the catalog. Subsequently, we follow the methodology described in Dainotti et al. (ApJ, 2021, 920, 118) and create an MLmodel for estimating the redshift of 4LAC AGNs. We present results which highlight positive impact of MICE imputation technique on the machine learning models performance and obtained redshift estimation accuracy.\nKeywords: redshift, AGNs, BLLs, FSRQs, FERMI 4LAC, machine learning regressors, imputation, MICE\n1 INTRODUCTION\nSpectroscopic redshift measurement of Active Galactic Nuclei (AGNs) is a highly time-consuming operation and is a strong limiting factor for a large-scale extragalactic surveys. Hence, there is a pressing requirement for alternative redshift estimation techniques that provide reasonably good results Salvato et al. (2019). In current cosmological studies, such alternative redshift estimates, referred to as photometric redshifts, play a key role in our understanding of the Extragalactic Background Light (EBL) origins Wakely and Horan (2008)1, magnetic field structure in the intergalactic medium Marcotulli et al. (2020); Venters and Pavlidou (2013); Fermi-LAT Collaboration et al. (2018) and help in determining the bounds on various cosmological parameters Dom\u00ednguez et al. (2019); Petrosian (1976); Singal et al. (2013b), Singal et al. (2012),\nEdited by: Olga Verkhoglyadova,\nNASA Jet Propulsion Laboratory (JPL), United States\nReviewed by: Ali Luo,\nNational Astronomical Observatories (CAS), China Jaime Perea,\nInstitute of Astrophysics of Andalusia, Spain\n*Correspondence: Maria Giovanna Dainotti\nmariagiovannadainotti@yahoo.it\nSpecialty section: This article was submitted to\nAstrostatistics, a section of the journal\nFrontiers in Astronomy and Space Sciences\nReceived: 15 December 2021 Accepted: 24 January 2022 Published: 04 March 2022\nCitation: Gibson SJ, Narendra A, Dainotti MG,\nBogdan M, Pollo A, Poliszczuk A, Rinaldi E and Liodakis I (2022) Using Multivariate Imputation by Chained Equations to Predict Redshifts of Active Galactic Nuclei. Front. Astron. Space Sci. 9:836215.\ndoi: 10.3389/fspas.2022.836215\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 8362151\nORIGINAL RESEARCH published: 04 March 2022 doi: 10.3389/fspas.2022.836215\nSingal et al. (2014); Singal (2015); Singal et al. (2013a); Chiang et al. (1995); Ackermann et al. (2015); Singal et al. (2013b); Ackermann et al. (2012).\nOne technique that has gained significant momentum is the use of machine learning (ML) to determine the photometric redshift of AGNs Brescia et al. (2013), Brescia et al. (2019); Dainotti et al. (2021); Nakoneczny et al. (2019); Jones and Singal (2017); Cavuoti et al. (2014); Fotopoulou and Paltani (2018); Logan and Fotopoulou (2020); Yang et al. (2017); Zhang et al. (2019); Curran (2020); Nakoneczny et al. (2019); Pasquet-Itam and Pasquet (2018); Jones and Singal (2017). Large AGN data sets derived from all-sky surveys like the Wide-field Infrared Survey Explorer (WISE) Brescia et al. (2019); Ilbert et al. (2008); Hildebrandt et al. (2010); Brescia et al. (2013); Wright et al. (2010); D\u2019Isanto and Polsterer (2018) and Sloan Digital Sky Survey (SDSS) Aihara et al. (2011) have played a significant role in the proliferation of ML approaches. However, the quality of the results from an ML approach depends significantly on the size and quality of the training data: the data on which the MLmodels learn the underlying relationship to predict the redshift. Unfortunately, almost all of these large data sets suffer from the issue of missing entries, which can lead to a considerable portion of the data being discarded.\nThis is especially problematic in catalogs of smaller size, such as in the case of gamma-ray loud AGNs.\nUsing the Fermi Fourth Data Release Catalog\u2019s (4LAC) gamma-ray loud AGNs Ajello et al. (2020); Abdollahi et al. (2020), Dainotti et al. (2021) demonstrated that ML methods lead to promising results, with a 71% correlation between the predicted and observed redshifts. However, in that study, the training set consists of only 730 AGNs, and a majority of the data (50%) are discarded due to missing entries. More specifically, we have several reasons why the sources are missing also in relation to the variables we consider. Regarding the missing values of the Gaia magnitudes: this could be either because the sources are too faint and thus they undergo the so called Malmquist bias effect (only the brightest sources are visible at high-z) or the coordinates are not accurate enough and the cross-matching is failing to produce a counterpart (the latter is not that likely, the former is much more likely).\nRegarding the variables observed in \u03b3-rays: here the source is detected, but it is faint in gamma-rays and again we have the Malmquist bias effect in relation to the detector threshold of Fermi-LAT and/or it does not appear variable and/or the spectral fitting fails to produce values, hence the missing values.\nRegarding the multi-wavelength estimates (], ]f]): these depend on the availability of multi-wavelength data from radio to X-rays. If sufficient data exists then a value can be estimated, so the missing values are most likely sources that have not been observed by telescopes. In other words, this does not mean that the sources are necessarily faint, they could be bright, but just no telescope performed follow-up observations.\nThere is also the possibility to explain the missing values because of the relativistic effects that dominate blazar emission. The relativistic effects, quantified by a parameter called the Doppler factor, boost the observed flux across all frequencies, but also shorten the timescales making sources appear more\nvariable. It has been shown that sources detected in \u03b3-rays have higher Doppler factors and are more variable Liodakis et al. (2017), Liodakis et al. (2018). This would suggest that sources observed more off-axis, i.e., lower Doppler factor, would have a lower \u03b3-ray flux and appear less variable. Therefore introduce more missing values as we have discussed above.\nIn this study, we address this issue of missing entries using an imputation technique called Multivariate Imputation by Chained Equations (MICE) Van Buuren and Groothuis-Oudshoorn (2011). This technique was also recently used by Luken et al. (2021) for redshift estimation of Radio-loud AGNs.\nLuken et al. (2021) test multiple imputation techniques, MICE included, to determine the best tool for reliably imputing missing values. Their study considers the redshift estimation of radio-loud galaxies present in the Australia Telescope Large Area Survey (ATLAS). However, in contrast to our approach where we impute actual missing information in the catalog, they manually set specific percentages of their data as missing and test how effective various imputation techniques are. Their results demonstrate distinctly that MICE is the best imputation technique, leading to the least root mean square error (RMSE) and outlier percentages for the regression algorithms they have tested.\nIn our study, we are using the updated 4LAC catalog, and using MICE imputations to fill in missing entries, we achieve a training data set which is 98% larger than the one used in Dainotti et al. (2021). We achieve results on this more extensive training set that are comparable to Dainotti et al. (2021) while attaining higher correlations. Furthermore, we are using additional ML algorithms in the SuperLearner ensemble technique, as compared to Dainotti et al. (2021).\nSection 2 discusses the specifics of the extended 4LAC data set: how we create the training set, which predictors are used and which outliers are removed. In Section 3 we discuss the MICE imputation technique, the SuperLearner ensemble with a brief description of the six algorithms used in this analysis, followed by the different feature engineering techniques implemented. Finally, we present the results in Section 4, followed by the discussion and conclusions in Section 5."
        },
        {
            "heading": "2 SAMPLE",
            "text": "This study uses the Fermi Fourth Data Release Catalog (4LAC), containing 3,511 gamma-ray loud AGNs, 1764 of which have a measured spectroscopic redshift. Two categories of AGNs dominate the 4LAC catalog, BL Lacertae (BLL) objects and Flat Spectrum Radio Quasars (FSRQ). To keep the analysis consistent with Dainotti et al. (2021), we remove all the nonBLL and non-FSRQ AGNs.\nThese AGNs have 13 measured properties in the 4LAC catalog; however, we only use 11 and a categorical variable that distinguishes BLLs and FSRQs. The two omitted properties in the analysis are Highest_Energy and Fractional_Variability because 42.5% of the entries are missing, and there is insufficient information to impute them reliably. We consider imputation of predictors which have\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 8362152\nmissing entries in less than 18% of the data. The remaining 11 properties and the categorical variables are Gaia_G_Magnitude, Variability_Index, Flux, Energy_Flux, PL_Index, ]f], LP_Index, Significance, Pivot_Energy, ], and LP_\u03b2 and LabelNo, serve as the predictors for the redshift in the machine learning models and are defined in Dainotti et al. (2021) and Ajello et al. (2020). However, some of these properties are not used as they appear in the 4LAC, since they span several orders of magnitude. The properties Flux, Energy_Flux, Significance, Variability_Index, ], ]f], and Pivot_Energy are used in their base-10 logarithmic form. In the categorical variable LabelNo we assign the values 2 and 3 to BLLs and FSRQs, respectively. We are not training the ML models to predict the redshift directly. Instead, we train the models to predict 1/(z + 1), where z is the redshift. Such a transformation of the target variable is crucial as it helps improve the model\u2019s performance. In addition, 1/(z + 1) is known as the scale factor and has a more substantial cosmological significance than redshift itself. We remove AGNs with an LP_\u03b2 < 0.7, LP_Index > 1, and LogFlux > -10.5, as they are outliers of their respective distributions. These steps lead us to a final data sample of 1897 AGNs, out of which 1,444 AGNs have a measured redshift (see Figure 1). These AGNs form the training sample, while the remaining 453 AGNs, which do not have a measured redshift, form the generalization sample."
        },
        {
            "heading": "3 METHODOLOGY",
            "text": "Here we present the various techniques implemented in the study, definitions of the statistical metrics used, and a comprehensive step-by-step description of our procedure to obtain the results. We use the following metrics to measure the performance of our ML model:\n\u2022 Bias: Mean of the difference between the observed and predicted values. \u2022 \u03c3NMAD: Normalized median absolute deviation between the predicted and observed measurements. \u2022 r: Pearson correlation coefficient between the predicted and observed measurements. \u2022 Root Mean Square Error (RMSE) between the predicted and observed redshift \u2022 Standard Deviation \u03c3 between the predicted and observed redshift\nWe present these metrics for both \u0394znorm and \u0394z, which are defined as:\n\u0394z zobserved \u2212 zpredicted (1) \u0394znorm \u0394z1 + zobserved (2)\nWe also quote the catastrophic outlier percentage, defined as the percentage of predictions that lies beyond the 2\u03c3 error. The metrics presented in this study are the same as in Dainotti et al. (2021), allowing for easy comparison."
        },
        {
            "heading": "3.1 Procedure",
            "text": "Here we provide a walk-through of how the final results are obtained. First, we remove all the non-BLL and non-FSRQ AGNs from the 4LAC data set, in addition to outliers, and end up with 1897 AGNs for the total set. Then, we impute the missing entries using MICE (see Section 3.2). Having obtained a complete data set, we split it into the training and the generalization sets, depending on whether the AGNs have or do not have a measured redshift value. We aim to train an ensemble model that is the least complex and best suited to the data at hand. For this purpose, we need to test many different algorithms with ten-\nFIGURE 1 | Redshift distribution of the training set.\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 8362153\nFIGURE 3 | The pattern of the missing data. The blue cells represent complete values, while the pink ones indicate where we havemissing data. The first row shows that there are 1,432 AGNs without missing values. Second row shows that there are 228 data points with Gaia_G_Magnitude missing. Third row shows that there are 122 data points with Log] and Log]f]missing. And finally, the last row shows that there are 115 data points with missing values inGaia_G_Magnitude, Log] and Log]f]. The columns indicate that there are 237 missing values in Log] and Log]f], and 343 missing values in Gaia_G_Magnitude. The remaining predictors have no missing entries.\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 8362154\nfold cross-validation (10fCV). Cross-validation is a resampling procedure that uses different portions of the data, in this case 10, to train and test a model, and find out which algorithm performs the best in terms of the previously defined metrics. However, since there is inherent randomness in how the folds are created during 10fCV, we perform 10fCV one hundred times and average the results to derandomize and stabilize them. This repeated\nk-fold cross-validation technique is standard in evaluating ML models. In each of the one hundred iterations of 10fCV, we train a SuperLearner model (see Section 3.3) on the training set using the twelve algorithms shown in Figure 2. Finally, averaging over the one hundred iterations, we obtained the coefficients and risk measurements associated with each SuperLearner ensemble model, as well as the individual algorithms. Following the previous step, we pick six algorithms that have coefficients greater than 0.05 (see Section 3.4 for information about these algorithms).\nWith the six best ML algorithms, we create an ensemble with SuperLearner and perform the 10fCV one hundred times once more. The final cross-validated results are again an average of these one hundred iterations.\nNext, we proceed to show the results obtained without the repeated cross-validation procedure. For this, we simply select a fixed validation set by choosing the last 111 AGNs from the 1,444 AGNs of the previously used training data. Now, with the new training set of 1,333 AGNs, we train a SuperLearner model, with the algorithms being the same as in the crossvalidation step, and we predict the redshift of the validation set. We then calculate the same statistical metrics for these results as we did for the cross-validated results. The results on this fixed validation set provide a representative of the performance of the SuperLearner model, which we have explored in more details (and in a more computationally expensive way) during the repeated cross-validation procedure."
        },
        {
            "heading": "3.2 Multivariate Imputation by Chained Equations",
            "text": "Multivariate Imputation by Chained Equations (MICE) is a method for imputing missing values for multivariate data Van Buuren and Groothuis-Oudshoorn (2011); Luken et al. (2021). The multivariate in MICE highlights its use of multiple variables to impute missing values. The MICE algorithm works under the assumption that the data are missing at random (MAR). MAR was first detailed in the paper Rubin (1976). It implies that errors in the system or with users cause the missing entries and not intrinsic features of the object being measured. Furthermore, MAR implies the possibility that the missing entries can be inferred by the other variables present in the data Schafer and Graham (2002). Indeed, this is a strong assumption, and it is our first step to deal with missing data. However, we know that selection biases play an important role for the flux detection. Although this problem is mitigated for the gamma-ray sources, for the G-band magnitude, one can argue that, e.g., BL Lacs are systematically fainter than FSRQs and below the Gaia limiting magnitude. A more in-depth analysis to take this problem into account is worthwhile, but this is beyond the scope of the current paper.\nWith this assumption, MICE attempts to fill in the absent entries using the complete variables in the data set iteratively. We impute the missing variables 20 times with each iteration of MICE consisting of multiple steps. General practice is to perform the imputation ten times as in Luken et al. (2021) and Van\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 8362155\nBuuren and Groothuis-Oudshoorn (2011), but we perform it twenty times to stabilize the imputation.\nHere, we use the method \u201cmidastouch\u201d\u2014a predictive mean matching (PMM) method Little and Rubin (2019). It works by initializing a feature\u2019s missing entries with its mean and then estimating them by training a model using the rest of the complete data. For each prediction, a probability is assigned based on its distance from the value imputed for the desired entry. The missing entry is imputed by randomly drawing from the observed values of the respective predictor, weighted according to the probability defined previously.\nThe process is repeated for each missing entry until all have been refitted. This new complete table is used as a basis for the next iteration of MICE, where the same process is repeated until the sequence of table converges or a set number of iterations is achieved."
        },
        {
            "heading": "3.3 SuperLearner",
            "text": "SuperLearner Van der Laan et al. (2007) is an algorithm that constructs an ensemble of ML models predictions using a crossvalidated metric and a set of normalized coefficients. By default Superlearner uses a ten-fold cross-validation procedure. It outputs a combination of user-provided ML models such that the RMSE of the final prediction is minimized by default Polley and Van der Laan (2010) (or any other user-defined metric defining the expected risk of the task at hand). In our setup, SuperLearner achieves this using 10fCV, where the training data is divided into ten equal portions or folds, the models are trained on nine folds, and the 10th fold is used as a test set. The models predict the target variable of the test set, and based on the RMSE of their predictions, SuperLearner assigns a coefficient. If an algorithm has a lower RMSE in 10fCV, it will be assigned a higher coefficient. Finally, it creates the ensemble as a linear combination of the constituent models multiplied by their respective coefficients. Note that this 10fCV is an internal procedure of model selection to build the SuperLearner ensemble model, and it is separate from the repeated crossvalidation procedure which we described in Section 3.1 and which is used to evaluate the performance and final results."
        },
        {
            "heading": "3.4 The Machine Learning Algorithms Used in Our Analysis",
            "text": "Following Dainotti et al. (2021) we analyze the coefficients assigned by SuperLearner to 12 ML algorithms, and pick those with a value greater than 0.05. In Figure 2, we show all the ML algorithms tested, and their coefficients. We pick the six algorithms above the 0.05 cutoff, which are: Enhanced\nAdaptive Regression Through Hinge (EARTH), KSVM, Cforest, Ranger, Random Forest, and Linear Model. We provide brief explanations for each of them below.\nEnhanced Adaptive Regression Through Hinges (EARTH) is an algorithm that allows for better modeling of predictor interaction and non-linearity in the data compared to the linear model. It is based on the Multivariate Adaptive Regression Splines method (MARS) Friedman and Roosen (1995). EARTH works by fitting a sum or product of hinges. Hinges are part-wise linear fits of the data that are joined such that the sum-of-squares residual error is minimized with each added term.\nKSVM is an R implementation of the Support Vector Regression method (SVR). Similar to Support Vector Machine (SVM) Cortes and Vapnik (1995), SVR uses a kernel function to send its inputs to a higher-dimensional space where the data is linearly separable by a hyper-plane. SVR aims to fit this hyperplane such that the prediction error is within a pre-specified threshold. For our purposes, KSVMuses the Gaussian kernel with the default parameters.\nThe Random Forest algorithm Breiman (2001); Ho (1995) seeks to extend decision trees capabilities by simultaneously generating multiple, independent decision trees. For regression tasks, Random Forest will return the average of the outputs of each of the generated decision trees. An advantage of Random Forest over decision trees is the reduction in the variance. However, Random Forest often suffers from low interpretability.\nThe Ranger algorithm is similar to Random Forest with the difference of extremely randomized trees (ERTs) Geurts et al. (2006) and quicker implementation.\nSimilar to Random Forest, the Cforest algorithm Hothorn et al. (2006) builds conditional inference trees that perform splits on significance tests instead of information gain.\nWe use the ordinary least squares (OLS) linear model found in the SuperLearner package. This model aims to minimize the mean squared error.\nNote that we are using the default hyperparameter settings for all the algorithms."
        },
        {
            "heading": "3.5 Feature Engineering",
            "text": "Feature engineering is a broad term that incorporates two techniques: feature selection and feature creation. Feature selection is a method where the best predictors of a response variable are chosen from a larger pool of predictors. There exist multiple methods to perform feature selection. We are using the Least Absolute Selection and Shrinkage Operator (LASSO) method. Feature selection is an essential part of any ML study as it reduces the dimensionality of the data andminimizes the risk\nTABLE 1 | Composition of the training and generalization sets, and Redshift properties on the training set.\nType Training set Generalization set Redshift median Redshift minimum Redshift maximum\nBLLs 721 450 0.336 3.7 \u00d7 10\u20135 2.82 FSRQ 723 3 1.12 0.097 4.313\nTotal 1,444 453 0.628 3.7 \u00d7 10\u20135 4.313\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 8362156\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 8362157\nof overfitting. Feature creation is a technique where additional features are created from various combinations of existing properties. These combinations can be cross-multiplications, higher-order terms, or ratios. Feature creation can reveal hidden patterns in the data that ML algorithms might not be able to discern and consequently boost the performance.\nIn machine learning, some of the methods used by SuperLearner are linear by nature (BayesGLM, Lasso, elasticnet). Adding quadratic and multiplicative terms allows us to model some types of non-linear relationships. Interactions among variables are very important and can boost the prediction when used. The phrase \u201cinteraction among the variables\u201d means the influence of one variable on the other;\nhowever, not in an additive way, but rather in a multiplicative way. In our feature engineering procedure, we build these interactions by cross-products and squares of the initial variables. It is common that adding O2 predictors aids results since they may contain information not available in the O1 predictors.\nIn this study, we create 66 new features, which, as mentioned, are the cross-products and squares of the existing features of the 4LAC catalog. We denote the existing predictors of the 4LAC catalog as Order-1 (O1) predictors and the new predictors as Order-2 (O2). Thus, we expand the set of predictors from the initial eleven O1 predictors to a combined seventy-eight O1 and O2 predictors.\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 8362158\nFor features selection, LASSO Tibshirani (1996) is used. It works by constraining the \u21131 norm of the coefficient vector to be less than or equal to a tuning parameter \u03bb while fitting a linear model to the data. The predictors that LASSO chooses have a non-zero coefficient for the largest \u03bb value with the property that the corresponding prediction error is within one standard deviation of the minimum prediction error Friedman et al. (2010); Birnbaum (1962); Hastie and Tibshirani. (1987), Hastie and Tibshirani. (1990); Friedman et al. (2010). This study performs LASSO feature selection on a fold-by-fold basis during external 10fCV. Optimal features are picked using LASSO for nine of the ten folds, and the predictions on the 10th fold are performed using these selected features. This step is iterated such that for every combination of nine folds, an independent set of features is picked. This usage of LASSO is in contrast to Dainotti et al. (2021), where the best features are picked for the entire training set. Our updated technique ensures that during the 10fCV, LASSO only picks the best predictors based on the training data, and the test set does not affect the models. This feature selection method is applied to both the O1 and O2 predictor sets."
        },
        {
            "heading": "4 RESULTS",
            "text": "The quality of theMICE imputations depends on the information density of the entire data set. Hence, to ensure the best possible imputations we use all 1897 AGNs which remain after the removal of outliers and non-BLL and non-FSRQ AGNs. The pattern of the missing entries in our data set is shown in Figure 3, and they are present in only three predictors, namely, Log], Log] f], and Gaia_G_Magnitude (see Sec. 2). There are 237 AGNs which have missing values in both Log] and Log]f], and 343 AGNs have a missing value in Gaia_G_Magnitude. MICE is used to fill the missing values of these AGNs. In Figure 4 we show the distributions of Log], Log]f], and Gaia_G_Magnitude with and without MICE. The quality of the MICE imputations can be\nevaluated in part by comparing the original distribution of a variable and its distribution with imputations. If the imputations alter the distribution, the results cannot be trusted and would require additional precautions or measures to deal with the missing values. However, as can be discerned from the plots (Figure 4), the MICE imputations are indeed following the underlying distribution for the three predictors, and hence we confidently incorporate them into our analysis. We impute 465 data points, 24% of our data set, resulting in a training sample of 1,444 AGNs and a generalization sample of 453 AGNs. The two sets are detailed in Table. 1."
        },
        {
            "heading": "4.1 Multivariate Imputation by Chained Equations Reliability Analysis",
            "text": "In the work by Luken et al. (2021), they present an extensive analysis of the reliability of MICE imputations. However, since they use a different dataset than ours, a similar investigation regarding the performance of MICE is essential. Thus, we take 1,432 AGNs from our catalog with no missing entries and randomly dropped 20% of the entries from each of the three predictors which have missing entries, namely: Log], Log]f], and Gaia_G_Magnitude. We then impute these dropped entries using MICE, as described in Section 3.2. This process is repeated fifteen times, and each time a different set of random entries are dropped. Furthermore, as we can see in Figure 5, the observed vs predicted values for Log], Log]f] and Gaia_G_Magnitude are concentrated about the y = x line, with little variance. The mean squared error (MSE), defined as the, of the observed values vs the MICE imputed values for Log], Log]f], and Gaia_G_Magnitude were 1.05, 0.196, and 1.43, respectively. Thus, the MSEs are all small, which provides evidence that the MICE imputed effectively. Note that if MICE imputes effectively, then the imputed values and observed values should come from the same distribution for each of the three variables. To check this, we performed a Kolmogorov-Smirnov (KS) test on the observed vs MICE imputed values for each of the three\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 8362159\nvariables with missing entries. The p-values of the KS test for Log], Log]f], and Gaia_G_Magnitude were 0.744, 0.5815, and 0.6539, respectively. Since each of these p-values is above 0.05, we cannot reject the null-hypothesis; namely, we conclude that the observed values and the MICE imputed values come from same distributions for any of the three variables. As shown in Figure 5, the overlapped histogram of the observed vs MICE imputed values for Log], Log]f] and Gaia_G_Magnitude are each very similar, which reinforces the findings of the KS test - namely, that they are from the same distribution. This provides additional proof for the accuracy, and reliability of the MICE imputations."
        },
        {
            "heading": "4.2 With O1 Variables",
            "text": "The O1 variable set consists of 12 predictors, including the categorical variable LabelNo, which distinguishes between BLLs and FSRQs. LASSO chooses the best predictors from within this set for each fold in the 10fCV as explained in Section 3.5.\nUsing this feature set with the six algorithms mentioned, we obtain a correlation in the 1/(z + 1) scale of 75.8%, a \u03c3 of 0.123, an RMSE of 0.123, and a \u03c3NMAD of 0.118. In the linear redshift scale (z scale), we obtain a correlation of 73%, an RMSE of 0.466, a \u03c3 of 0.458, a bias of 0.092, and a \u03c3NMAD of 0.318. In the normalized\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 83621510\nscale (\u0394znorm), the RMSE obtained is 0.209, bias is 6 \u00d7 10\u20133, and \u03c3NMAD is equal to 0.195. The correlation plots are shown in Figure 6, with the left panel showing the correlation in the 1/(z + 1) scale and the right panel showing the correlation in the z scale. We obtain a low 5% catastrophic outlier percentage in this scenario. The lines in blue depict the 2\u03c3 curves for each plot, where the \u03c3 is calculated in the 1/(z + 1) scale.\nIn Figure 7, we present the distributions of \u03c3NMAD and RMSE across the one hundred iterations. Note that \u03c3NMAD is written as NMAD in the plots for brevity.\nIn Figure 8, we present the distributions of various parameters and the normalized relative influence plot of the 11 predictors - LabelNo is excluded, as its a categorical variable. The top left panel shows the variation in the linear correlation obtained from the one hundred iterations. The top right panel shows the distribution of \u0394z along with the \u03c3 (blue vertical line) and bias (red vertical line) values. The bottom left panel shows the distribution of the \u0394znorm along with the bias and \u03c3 presented similarly. Finally, the barplot in the bottom right panel shows the relative influence of the 11 predictors used. LP_\u03b2 has the highest\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 83621511\ninfluence, followed by Log], LogPivot_Energy, and LogSignificance. Surprisingly, Gaia_G_Magnitude has the least influence at \u2248 1%, in contrast to Dainotti et al. (2021), where we found it to be quite significant at \u2248 11% influence. The difference we obtain from this analysis and the previous one of Dainotti et al. (2021) lies in the data set and that MICE had not been used."
        },
        {
            "heading": "4.3 With O2 Variables",
            "text": "The O2 variables, 78 in total, are made from cross-products of the O1 variables. As in the O1 case, LASSO feature selection is performed on a fold-by-fold basis, after which the SuperLearner ensemble with the six algorithms previously mentioned is trained and makes predictions. The crossvalidation and validation correlation plots are presented in Figure 9.\nAs shown in the previous section, we have correlation plots in the 1/(z + 1) scale and the z scale. In the 1/(z + 1) scale, we get a correlation of 75.6%, RMSE of 0.124, and \u03c3NMAD of 0.116. In the z scale, we obtain a correlation of 73%, RMSE of 0.467, and \u03c3NMAD of 0.308. We obtain the statistical parameters for \u0394z: an RMSE of 0.467, a \u03c3 of 0.458, a bias of 0.093, and a \u03c3NMAD of 0.308. For \u0394znorm, we obtain an RMSE of 0.21, a bias of 7 \u00d7 10\u20134, and a \u03c3NMAD of 0.193. We have a similar catastrophic outlier percentage (5%) as the O1 variable case, although the number of AGNs predicted outside the 2\u03c3 cone is seven AGNs more. This discrepancy can be attributed to the randomness inherent in our calculations and additional noise introduced by the O2 predictors.\nIn Figure 10, we show the distributions of \u03c3NMAD and RMSE. Note that there is an outlier during the analysis, which leads to the unusually high RMSE value seen in the distribution.\nFigure 11 shows the distribution plots for various parameters. The top left panel shows the distribution of the correlations across the one hundred iterations. There is an outlier in the distribution\nof the correlation plot, corresponding to the distributions of RMSE in Figure 10. This scenario only happens with the O2 variable set and with MICE imputations. Apart from this fluctuation, most of the correlations lie around 73%. The histogram distribution plots for \u0394z (top right) and \u0394znorm (bottom left) show a similar spread as in the case of the O1 variable set. We only present predictors with influence greater than 0.5% in the relative influence plot. In this case, PL_Index turns out to have the highest influence, over 20%, followed by LogSignificance, LogPivot_Energy, and LogEnergy_Flux100.\nWe note that out of the 11 O1 predictors with relative influences, only 3 have less than 5% influence, and out of the 78 O2 predictors, only 4 have greater than 5% influence. Thus, the majority of the O2 predictors do not seem to provide much additional information about the redshift.\nIn Tables 2 and 3 we provide a comparision between the results obtained in the two experiments we have here with MICE, and one without MICE imputations. The latter results have been taken from Narendra et al. (2022)."
        },
        {
            "heading": "5 DISCUSSIONS AND CONCLUSION",
            "text": "In Dainotti et al. (2021), the correlation between the observed and predicted redshift achieved with a training set of 730 AGNs was 71%, with RMSE of 0.434, \u03c3NMAD (\u0394znorm) of 0.192, and a catastrophic outlier of 5%. Here, with the use of an updated 4LAC catalog, O1 predictors, and the MICE imputation technique, along with additional ML algorithms in the SuperLearner ensemble, we achieve a correlation of 73% between the observed and predicted redshift, an RMSE of 0.466, \u03c3NMAD (\u0394znorm) of 0.195 and a catastrophic outlier of 5%. Although the RMSE and \u03c3NMAD (\u0394znorm) are increasing by 7 and 1.5%, respectively, we are able to maintain the\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 83621512\ncatastrophic outliers at 5%, while increasing the correlation by 3%. These results are achieved with a data sample 98% larger than the one used by Dainotti et al. (2021). Note that this achievement is not trivial, as a larger data set does not guarantee favourable results.\nWith the O2 predictor set, we obtain a similar correlation of 73% between the predicted and observed redshifts. However, compared to the O1 case, the RMSE goes up by 0.2%\u20130.467 and the \u03c3NMAD (\u0394znorm) goes down by 1% to 0.193. The catastrophic outlier percentage is maintained at 5% in both cases.\nThe most influential O1 predictors in this study were LP_\u03b2, Log], LogPivot_Energy, LogSignificance, LP_Index, PL_Index,\nand LogEnergy_Flux, each of which has a relative influence greater than 5%. LP_\u03b2 was also the most influential predictor in Dainotti et al. (2021), followed by LogPivot_Energy, LogSignificance, LogEnergy_Flux, and Log]. The main difference in the relative influences of the predictors in these studies is that in the O1 case with MICE, LP_Index and PL_Index are the 5th and 7th most influential predictors, respectively, while in Dainotti et al. (2021), they were not influential.\nAmong the O2 predictors, PL_Index is the most influential, followed by LogSignificance, LogPivot_Energy, and LogEnergy_Flux, each of which has a relative influence\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 83621513\ngreater than 5%. Note that the only O2 predictors with influence greater than 5% are those we have just listed and they are also O1 predictors. When additional variables are added it is not guaranteed that the most influential variables will be kept the same. This is true for both parametric and nonparametric models. The influence is a measure of how much your improvement in the prediction changes when you remove one variable in relation to the presence of the other variables. Thus, these measures depend on the other variables in the model and are different when O2 variables are added. We can conclude from these results that the O1 predictors contain most of the predictive information for redshift, in the case of the 4LAC catalog. Furthermore, we note that obtaining results with the O2 set takes more time than with the O1 set due to the larger list of predictors. However, in other catalogs, such O2 predictors might perform better and be an avenue worth exploring in the future.\nHere, we use MICE on the O1 variables, because this allows MICE to act on three variables which present missing entries. In this way, we can control the effectiveness of MICE and the results. We agree with the referee that imputing the MICE in the cross products would imply an imputation on variables that are currently not defined and most importantly would allow more uncertainty when the cross products would involve for example two variables with missing entries. If we had used MICE in the O2 parameters we would have had a large number of imputation which would be less controllable. From these results, we can discern that the MICE imputation technique is a robust method to mitigate the issue of missing entries in a catalog while maintaining the predictive power of the data.\nDATA AVAILABILITY STATEMENT\nPublicly available datasets were analyzed in this study. This data can be found here: https://fermi.gsfc.nasa.gov/ssc/data/access/lat/ 10yr_catalog/.\nAUTHOR CONTRIBUTIONS\nSG and AN were responsible for improving parts of the initial code, the generation of the final results, and the writing of the manuscript. This project was initiated by MD. The original code was developed by her and MB. It was later modified to suit the specific needs of this project. MD also participated in all the discussions regarding the project was instrumental in shaping the outcome, and determining the structure of the manuscript. MB helped with the statistical results of the work. Dr. Agniezska Pollo participated in crucial discussions regarding the direction of the research. AP helped in editing the manuscript along with discussions about the results. ER helped in editing the structure of the manuscript along with discussions about the procedures that were adopted along with the idea of using LASSO feature selection inside the cross-validation. IL helped us in acquiring and explaining the data and its features, along with corresponding labels of BLL and FSRQ. He also helped in making the manuscript clearer.\nFUNDING\nFunding for the DPAC is provided by national institutions, in particular the institutions participating in the Gaia MultiLateral Agreement (MLA). The Gaia mission website is https://www. cosmos.esa.int/gaia. The Gaia archive website is https://archives. esac.esa.int/gaia. This research was supported by the Polish National Science Centre grant UMO-2018/30/M/ST9/00 757 and by Polish Ministry of Science and Higher Education grant DIR/WK/2018/12. This research was also supported by the MNS2021 grant N17/MNS/000057 by the Faculty of Physics, Astronomy and Applied Computer Science, Jagiellonian University."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "This work presents results from the European Space Agency (ESA) space mission, Gaia. Gaia data are being processed by the Gaia Data Processing and Analysis Consortium (DPAC). MD thanks Trevor Hastie for the interesting discussion on overfitting problems. We also thank Raymond Wayne for the initial computation and discussions about balanced sampling techniques which will be implemented in subsequent papers. We also thank Shubbham Bharadwaj for helping create four of the plots with correct fonts and symbols.\nFrontiers in Astronomy and Space Sciences | www.frontiersin.org March 2022 | Volume 9 | Article 83621514"
        }
    ],
    "title": "Using Multivariate Imputation by Chained Equations to Predict Redshifts of Active Galactic Nuclei",
    "year": 2022
}