Recent studies have shown that recommendation systems commonly suffer from popularity bias. Popularity bias refers to the problem that popular items (i.e., frequently rated items) are recommended frequently while less popular items are recommended rarely or not at all. Researchers adopted two approaches to examining popularity bias: (i) from the users’ perspective, by analyzing how far a recommendation system deviates from user’s expectations in receiving popular items, and (ii) by analyzing the amount of exposure that long-tail items receive, measured by overall catalog coverage and novelty. In this paper, we examine the first point of view in the book domain, although the findings may be applied to other domains as well. To this end, we analyze the well-known Book-Crossing dataset and define three user groups based on their tendency towards popular items (i.e., Niche, Diverse, Bestsellerfocused). Further, we evaluate the performance of nine state-of-the-art recommendation algorithms and two baselines (i.e., Random, MostPop) from both the accuracy (e.g., NDCG, Precision, Recall) and popularity bias perspectives. Our results indicate that most state-of-the-art recommendation algorithms suffer from popularity bias in the book domain, and fail to meet users’ expectations with Niche and Diverse tastes despite having a larger profile size. Conversely, Bestseller-focused users are more likely to receive high-quality recommendations, both in terms of fairness and personalization. Furthermore, our study shows a tradeoff between personalization and unfairness of popularity bias in recommendation algorithms for users belonging to the Diverse and Bestseller groups, that is, algorithms with high capability of personalization suffer from the unfairness of popularity bias. Finally, across the models, our results show that WMF and VAECF can provide a higher quality recommendation when considering both accuracy and fairness perspectives. 1 introduction Recommender systems have been utilized in various information spaces such as entertainment, education, and online dating. They aim to support users in finding desired information that is typically hard and time-consuming to find without such systems. Recommendation algorithms proposed in the literature can be categorized into multiple groups according to the context of recommendation and how they learn user preference. Collaborative Filtering (CF) is one of the most widely-investigated classes of algorithms used for recommendation. These algorithms generate recommendations based on explicit or implicit interactions between users and items in the system [24,19] without benefiting from the content information, as opposed to content-based recommendation techniques. Hence, one limitation of CF algorithms is the problem of popularity bias which causes the popular (i.e., shorthead) items to be over-emphasized in the recommendation list. In contrast, the majority of less popular (i.e., long-tail) items do not get enough visibility in the recommendation lists. Tackling popularity bias can make the recommender system more applicable in the real world for various reasons [7,8]. A recommender system suffering from popularity bias would result in the market being dominated by a few well-known brands and deprive the discovery of new and unpopular items, which could ignore the interest of users with niche tastes. Popularity bias has been largely investigated from the item-centered perspective, that is, how frequently popular items appear in recommendation lists. The item-centered perspective study ignores users’ interest in popular or less popular items, which causes a limitation as the popularity bias does not affect users equally [3]. Recently, Abdollahpouri et al. [2] have conducted a research study to look at the popularity bias from a different perspective: the users’. To shed light on this topic, suppose a user rated 40 long-tail (less-popular) items and 60 popular items. Therefore, we expect the recommendation algorithm to end up with the same ratio of popular items in the recommended list presented to this user. Despite our expectations, most recommendation algorithms generate a recommendation list including close to 100 popular items. Furthermore, Abdollahpouri et al. [2] evaluate how popularity bias leads to unfair treatment of different user groups according to their interests in popular movies. Their experiments demonstrate that the state-of-the-art recommendation algorithms can not comprehensively understand users who tend to be interested in unpopular items [1]. Popularity biases are known to arise from the underlying characteristics of the data, such as the number of interactions per item or user, sparsity, and an unbalanced distribution of interactions among items. As a result, in this work, we aim to reproduce the research study of Abdollahpouri et al. [2] and conduct it in a different domain and dataset. In particular, we select the book domain and Book-Crossing dataset due to a variety of reasons. First, the Book-Crossing data characteristic differs significantly from the previous study on the MovieLens 1M dataset in that it reports (256.46, 165.59) interactions per item and users respectively, as opposed to (12.79, 13.92) in Book-Crossing dataset. Table 1 summarizes
the main data characteristic of Book-Crossing dataset. Additionally, there are several aspects of book recommendations that make them different, challenging, and somehow more important than recommendations entertainment industry, such as movie and music recommendations [5,9]. For instance, although bookreading must become more prevalent in society, the investigation proves the opposite i.e., the practice of reading for pleasure or education is declining, particularly among the young [5]. Also, since a reader spends much time reading books, it is crucial that the content matches their known preferences and expectations. The experience of finding a match that is suitable can be rewarding for readers, but an inappropriate recommendation could result in losing interest, further contributing to the downward trend. It is, therefore, crucial to examine the existence of popularity bias from a user-centered perspective in book recommendations and, for reasons of comparability, we would like to answer the same two research questions as in the study of Abdollahpouri et al. [2]:
– RQ1: How much are different individuals or groups of users interested in popular books? – RQ2: How does the popularity bias in recommendation algorithms impact users with different tendencies toward popular books? In the following, we explore the Book-Crossing dataset characteristics and investigate RQ1 in Section 2. Then, we examine RQ2 in Section 3. We discuss the findings of our study and conclude the paper in Sections 4 and 5, respectively. Finally, to enable reproducibility of the experiment, we have made our codes open source.4
4 https://github.com/rahmanidashti/FairBook 6,358 6,921 88,552 13.92 12.79 99.80%  2 popularity bias in data In this paper, we utilize the well-known Book-Crossing5 dataset that contains 1, 149, 780 anonymous explicit and implicit ratings of approximately 340, 556 books made by 105, 283 users in a 4-week crawl (August - September 2004) [25]. From the dataset, we first removed all the implicit ratings, then we removed users who had fewer than 5 ratings so that the retained users were those who were likely to have rated enough long-tail items.The limit of 5 ratings was also used to remove distant long-tail items. Once short-profile users and distant long-tail items are removed, the Book-Crossing dataset consists of 6, 358 users who rated 6, 921 books, totaling 88, 552 in ratings. In the following, we will address the first research question. Table 1 shows the characteristics of the Book-Crossing datasets. 2.1 reading distribution of books Fig. 1 illustrates the distribution of readings in Book-Crossing dataset. Figure 1a indicates that reading counts of books follow a long-tail distribution as expected. That means a small proportion of books are read by many users, whereas a significant proportion (i.e., the long-tail) is read by only a small number of readers. Additionally, we illustrate in Fig 1b the ratio of popular books to all books read by users. Same as [2], we sort books based on the number of readers and consider them as popular if they are within the top-20% of the sorted list. By this definition, we observe that around 5, 256 out of 6, 358 users (i.e., around 83% of users) have read at least 20% of unpopular books in their profile. 2.2 user profile size and popularity bias in book data In Fig. 2 we investigate whether a correlation exists between the size of the user profile and the presence of popular books in the profile. Specifically, in Fig. 2a, we depict the number of popular books in a user’s profile over the size of the profile. As could be expected, there is a positive correlation since the more items in a user profile, the greater probability there are popular items in the profile. On the other hand, when plotting the average popularity of books in a user profile over the profile size in Fig. 2b, we observe a negative correlation, which indicates that users having a smaller profile size tend to read books with higher average popularity. Same as [2], we define the popularity of a book as the ratio of users who have read that book. 5 http://www2.informatik.uni-freiburg.de/~cziegler/BX/
As stated before, in this work, we investigate the popularity bias from the users’ perspective, same as [2]. To this end, we categorized all users into three groups according to their profile’s ratio of popular items (i.e., book). This ratio indicates how interested they are in popular items. – Niche users: After sorting users based on the ratio of popular items in their profiles, we refer to the bottom 20% of the sorted list as Niche users. – Bestseller-focused users: We consider the top 20% users of the sorted list as Bestseller-focused users interested in popular books. – Diverse users: The rest of the users fall within this category. Users in this category have varied interests in popular and unpopular books. Fig. 3 indicates the average profile size of different user groups. As expected, Diverse users have the largest profile size, followed by Niche users. The Bestsellerfocused group has the smallest average profile size. Based on our analysis in section 2.2, diverse users have larger average profile size; therefore, we can expect them to read more popular books than niche users. Furthermore, the small profile size of Bestseller-focused users implies that they are focused on reading solely popular books.Finally, we expect that recommendation algorithms influenced by popularity bias will provide Bestseller-focused users with the best recommendation quality (i.e., accuracy), followed by Diverse users. Furthermore, Niche users are likely to receive the lowest recommendation quality, as they have the lowest ratio of popular items in their profile. We will explore these expectations in the next section. Hence, in this section, we find that majority of users (i.e., around five-seventh) have read at least 20% of unpopular books. Furthermore, we find that users with a small profile size tend to read more popular books than users having a larger profile size. To sum up, we investigated RQ1 in this section and our findings are in agreement with what Abdollahpouri et al. have reported in [2]. 3 popularity bias in book recommendation In this section, we study popularity bias in state-of-the-art book recommendation algorithms. In order to foster the reproducibility of this study, we implement and evaluate all recommendation algorithms using Cornac6, which is a Python-based open source recommendation framework [21,22]. Therefore, we formulate the book recommendation using Cornac as a rating prediction problem, where we predict the preference of a target user u for a target book b. Then, we recommend the top-10 books with the highest predicted preferences. For ease of comparison, we use the same evaluation setup used in [2] to evaluate the performance of the recommendation algorithms. To this end, we set aside 80% of the Book-Crossing dataset as training set and the remaining 20% as the test set. We further extended the prior study of [2] by incorporating a more comprehensive range of state-of-the-art algorithms, including (i) baseline approaches, (ii) K-Nearest Neighbour (KNN) approaches, (iii) Matrix Factorization (MF) approaches, and (iv) Neural Network (NN) approaches. Specifically, we evaluate two baselines approaches, i.e., Random and MostPop. We include the UserKNN [6], which is a KNN-based method. We also evaluate five MF-based approaches, including MF [13], PMF [18], NMF [15], WMF [12], and PF [10]. We also consider BPR [20] as one of the well-know ranking-based algorithms. Eventually, we include two state-of-the-art NN-based approaches, i.e., NeuMF [11] and VAECF [16]. We adopt the recommendation algorithm with the default hyperparameter settings suggested in their original paper. 3.1 recommendation of popular books As shown in our analysis in Section 2, there is an imbalanced distribution in the book rating data, i.e., certain books are rated very frequently while the majority of items are rated by only a few users. In this section, we investigate to what extent different recommendation algorithms propagate this bias
6 https://cornac.preferred.ai/
into their recommendations. First, we examine algorithms’ overall performance without taking into account how they perform for different users or groups of users based on their tendency towards popular items. In Fig. 4, we illustrate the correlation of book popularity and how often the eight algorithms recommend these books. Among baseline algorithms, we are seeing a strong positive correlation on MostPop showing algorithm tendency to recommend popular items frequently not giving chance to long-tail items and no meaningful correlation on Random as expected. Interestingly, we observe a strong correlation between the popularity of items and their recommendation frequency on NeuMF and BPR with very similar behavior to MostPop. A majority of books were not exposed to users by these algorithms, while popular ones are more frequently highlighted. Furthermore, our experiment shows a moderate positive correlation in WMF and PF among the Matrix Factorization-based approaches. In contrast to Abdollahpouri et al. [2] and Kowald et al. [14] study in the Movie and Music domain, no positive correlation exists in PMF, MF, and NMF, indicating that the latter algorithms in Matrix Factorization-based approaches are not prone to popularity bias in Book-Crossing dataset. Additionally, this suggests that the characteristics of underlying data and the domain could play a key role in determining how recommendation algorithms behave in propagating popularity bias in various domains. Finally, among NN-based state-of-the-art approaches investigated in this study, the VAECF model has a moderately positive correlation and a better performance than the NeuMF model. 3.2 popularity bias for different user groups In this section, we investigate the effect of popularity bias on different user groups (i.e., Niche, Diverse, and Bestseller-focused) in book recommendations. To this end, we use delta Group Average Popularity (∆GAP) metric proposed
M ostPop BPR M F PFM NM F W M F PF NeuM F VAECF
Niche
Diverse
BestSeller
* * * * *
** ** 2
4
6
(a) MAE
M ostPop BPR M F PFM NM F W M F PF NeuM F VAECF
Niche
Diverse
BestSeller
* * * * * * ** ** ** ** ** ** 0.005 0.010
0.015
0.020
(b) Precision
M ostPop BPR M F PFM NM F W M F PF NeuM F VAECF
Niche
Diverse
BestSeller
* * * * * ** ** ** ** ** ** 0.025
0.050
0.075
(c) Recall
M ostPop BPR M F PFM NM F W M F PF NeuM F VAECF
Niche
Diverse
BestSeller
* * * * * ** ** ** ** ** ** 0.02
0.04
(d) NDCG
Fig. 6: The performance of models for the three user groups in terms of MAE (the lower, the better) and Precision, Recall, and NDCG (the higher, the better). The best results are always given for the Bestseller-focused user group (statistically significant according to a t-test with p < 0.005 as indicated by **). Across the algorithms, the best results are provided by VAECF (indicated by dark blue colour). by Abdollahpouri et al. [2] to evaluate the unfairness of popularity bias. We further use MAE, Precision, Recall, and NDCG to evaluate the performance of recommender algorithms. For each recommendation algorithm and user group, ∆GAP measures the difference between the average popularity of the recommended books and the average expected popularity shown in the user’s profiles history as follows:
∆GAP = GAP (g)r −GAP (g)p
GAP (g)p (1)
where g is a certain user group (i.e., Niche, Diverse, or Bestseller-focused), GAP (g)r and GAP (g)p represent the GAP value for recommendation lists and user profiles, respectively, and it is defined as follows:
GAP (g) =
∑ u∈g ∑ i∈pu φ(i)
|pu|
|g| (2)
where φ(i) is the popularity of item i, which is the number of times it is rated divided by the total number of users, and pu is the list of items in the profile of user u. The value of ∆GAP = 0 indicates a fair recommendation meaning that the average popularity of recommended books matches the average popularity of the user profile. Fig. 5 shows ∆GAP values for recommendation algorithms among the three user groups. As can be seen, Niches users receive significantly higher average ∆GAP values followed by Diverse and Bestseller-focused users, respectively. This finding confirms the results of the Abdollahpouri et al. [2] study and suggests that the popularity bias affects Niche users the most, that is, despite being interested in unpopular items, they receive recommendations of popular items. Interestingly, although the Bestseller-focused group receives the most favorable recommendations, the average ∆GAP is 126.55, revealing how algorithms can propagate the popularity bias even further than the Bestseller-focused user groups’ interest in popular items. Fig. 5 further illustrates that algorithms investigated in this study show similar behavior in terms of popularity bias among different user groups. Moreover, in line with our analysis in section 3.1, Random, MF, and NMF models provide the fairest recommendations, while MostPop, BPR, and NeuMF suffer from the propagation of popularity bias across all user groups. Then, to address RQ2, we analyze the results of MAE (the lower, the better), Precision, Recall, and NDCG (the higher, the better) of the recommendation algorithms on three users groups. Moreover, we determine the statistically significant differences using the two-tailed paired t-test at a 95% confidence interval (p < 0.05). As we see in Fig. 6, the Niche group receives significantly worse recommendations than two other groups (i.e., Diverse and Bestseller-focused), while the Bestseller-focused group gets the best performance. According to this result, algorithms are not capable of detecting the difference in taste between users, even though the average size of user profiles for Niche users is larger than that of the Bestseller-focused group (i.e., more training data), further emphasizing the unfairness of popularity bias. Across the algorithms, we see that WMF and VAECF algorithms provide the highest accuracy in all user groups. Notably, the WMF algorithm displayed the best performance in Niche group when considering both accuracy and fairness. 3.3 unfairness of popularity bias vs. personalization The main objective of this part is to explore the potential correlation or trade-off between unfairness of popularity bias and personalization measured by NDCG,
between groups of users who have differing preferences for popular items. To this purpose, Fig. 7 shows the correlation plot between NDCG@10 and ∆GAP for three user groups defined in Section 2.2 where each point represents the performance of a state-of-the-art recommendation algorithm. Interestingly, we observe an uphill (positive) correlation between NDCG and ∆GAP in the Bestsellerfocused and Diverse user groups with the p-value and Pearson’s coefficient of (0.01, 0.79) and (0.05, 0.66), respectively. In contrast, we find no meaningful correlation (i.e., p-value of 0.69) between accuracy and unfairness of popularity bias among users with Niche tastes. These results indicate that algorithms with a high accuracy score fall short on popularity bias fairness from the perspective of users with Diverse and Bestseller-focused tastes, prompting further studies on how to incorporate users’ taste and expectations in recommendation without sacrificing the overall accuracy. 4 discussion In this section, we present a summary of the answers we found to the research questions in Section 1. – Answer to RQ1: In line with the previous study of Abdollahpouri et al. [2], our experiments demonstrate that different users have a considerably different tendency towards popular items. Moreover, we discovered that around 83% of users have read at least 20% of unpopular books in their profile and expect to receive some of these items in recommendations. Our result further reveals that users with larger profile sizes who contribute most to the system have diverse tastes and interact with a substantial amount of unpopular items. – Answer to RQ2: Our results for various state-of-the-art recommendation algorithms demonstrate that most algorithms are unfair to users who have a niche or diverse taste in books in terms of popularity, i.e., these users receive recommendations that have lower accuracy and mainly consist of popular books. In addition, the study shows popularity bias negatively affects all user groups, even those focusing on bestsellers, but the magnitude of this effect varies greatly depending on the user group. 5 conclusion and future work In this paper, we reproduced the study of Abdollahpouri et al. [2] on the unfairness of popularity bias from the user’s perspective in the Movie domain, which we have applied to the book domain. Similar to the original paper, we divided all users into three groups (i.e., Niche, Diverse and Bestseller-focused) based on their level of interest in popular items. Our results on various state-of-theart recommendation algorithms reveal that the most widely adopted algorithms fail to capture users’ interest in unpopular items and recommend mostly popular items. Notably, the quality of recommendations received by users with a
Diverse or Niche taste is significantly lower than that of users with Bestsellers taste, despite having a large profile size. Moreover, our experiments led to new observations and possible directions for future research. First, we noticed that algorithms could differ significantly in their ability to capture users’ tastes based on the domain. For instance, the NMF algorithm suffers from the unfairness of popularity bias in the music domain [14] while offering an entirely fair recommendation in Book-Crossing dataset. A future research direction that would be interesting is identifying the underlying reason for the variance, in particular, which feature of the data (e.g., sparsity, average user interaction) plays the primary role in propagating the popularity bias. Additionally, our results suggest that an underlying tradeoff exists between personalization and fairness of popularity bias in Diverse and Bestseller-focused groups, that is, algorithms with high personalization abilities tend to experience fairness issues. Reproducibility. To enable reproducibility of the results, we provide our dataset, source codes with all used parameter settings, and more experimental results and analysis on our webpage: https://rahmanidashti.github.io/FairBook/