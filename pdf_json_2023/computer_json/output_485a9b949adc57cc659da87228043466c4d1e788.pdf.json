{
    "abstractText": "Binary memristor crossbars have great potential for use in brain-inspired neuromorphic computing. The complementary crossbar array has been proposed to perform the Exclusive-NOR function for neuromorphic pattern recognition. The single crossbar obtained by shortening the Exclusive-NOR function has more advantages in terms of power consumption, area occupancy, and fault tolerance. In this paper, we present the impact of data density on the single memristor crossbar architecture for neuromorphic image recognition. The impact of data density on the single memristor architecture is mathematically derived from the reduced formula of the Exclusive-NOR function, and then verified via circuit simulation. The complementary and single crossbar architectures are tested by using ten 32 \u00d7 32 images with different data densities of 0.25, 0.5, and 0.75. The simulation results showed that the data density of images has a negative effect on the single memristor crossbar architecture while not affecting the complementary memristor crossbar architecture. The maximum output column current produced by the single memristor crossbar array decreases as data density decreases while the complementary memristor crossbar array architecture provides stable maximum output column currents. When recognizing images with data density as low as 0.25, the maximum output column currents of the single memristor crossbar architecture is reduced four-fold compared with the maximum currents from the complementary memristor crossbar architecture. This reduction causes the Winner-take-all circuit to work incorrectly and will reduce the recognition rate of the single memristor crossbar architecture. These simulation results show that the single memristor crossbar architecture has more advantages compared with the complementary crossbar architecture when the images do have not many different densities, and none of the images have very low densities. This work also indicates that the single crossbar architecture must be improved by adding a constant term to deal with images that have low data densities. These are valuable case studies for archiving the advantages of single memristor crossbar architecture in neuromorphic computing applications.",
    "authors": [
        {
            "affiliations": [],
            "name": "Aiqun Liu"
        },
        {
            "affiliations": [],
            "name": "Zhongrui Wang"
        },
        {
            "affiliations": [],
            "name": "Arman Roohi"
        }
    ],
    "id": "SP:86d8dc61d036bacc4cc89d071d9980f831c33e8b",
    "references": [
        {
            "authors": [
                "L. Chua"
            ],
            "title": "Memristor-The missing circuit element",
            "venue": "IEEE Trans. Circuit Theory",
            "year": 1971
        },
        {
            "authors": [
                "D.B. Strukov",
                "G.S. Snider",
                "D.R. Stewart",
                "R.S. Williams"
            ],
            "title": "The missing memristor found",
            "venue": "Nature",
            "year": 2008
        },
        {
            "authors": [
                "S. Jo",
                "T. Chang",
                "I. Ebong",
                "B. Bhadviya",
                "P. Mazumder",
                "W. Lu"
            ],
            "title": "Nanoscale Memristor Device as Synapse in Neuromorphic Systems",
            "venue": "Nano Lett. 2010,",
            "year": 2010
        },
        {
            "authors": [
                "H. Kim",
                "M.P. Sah",
                "C. Yang",
                "T. Roska",
                "L.O. Chua"
            ],
            "title": "Neural Synaptic Weighting With a Pulse-Based Memristor Circuit",
            "venue": "IEEE Trans. Circuits Syst. I Regul. Pap",
            "year": 2012
        },
        {
            "authors": [
                "R.S. Williams"
            ],
            "title": "How We Found The Missing Memristor",
            "venue": "IEEE Spectr",
            "year": 2008
        },
        {
            "authors": [
                "S. Pi",
                "C. Li",
                "H. Jiang",
                "W. Xia",
                "H. Xin",
                "J.J. Yang",
                "Q. Xia"
            ],
            "title": "Memristor crossbar arrays with 6-nm half-pitch and 2-nm critical dimension",
            "venue": "Nat. Nanotechnol",
            "year": 2019
        },
        {
            "authors": [
                "C. K\u00fcgeler",
                "M. Meier",
                "R. Rosezin",
                "S. Gilles",
                "R. Waser"
            ],
            "title": "High density 3D memory architecture based on the resistive switching effect",
            "venue": "Solid-State Electron",
            "year": 2009
        },
        {
            "authors": [
                "C. Li",
                "L. Han",
                "H. Jiang",
                "M.-H. Jang",
                "P. Lin",
                "Q. Wu",
                "M. Barnell",
                "J.J. Yang",
                "H.L. Xin",
                "Q. Xia"
            ],
            "title": "Three-dimensional crossbar arrays of self-rectifying Si/SiO2/Si memristors",
            "venue": "Nat. Commun. 2017,",
            "year": 2017
        },
        {
            "authors": [
                "G.C. Adam",
                "B.D. Hoskins",
                "M. Prezioso",
                "F. Merrikh-Bayat",
                "B. Chakrabarti",
                "D.B. Strukov"
            ],
            "title": "3-D Memristor Crossbars for Analog and Neuromorphic Computing Applications",
            "venue": "IEEE Trans. Electron Devices",
            "year": 2017
        },
        {
            "authors": [
                "Y. Taur"
            ],
            "title": "CMOS design near the limit of scaling",
            "venue": "IBM J. Res. Dev",
            "year": 2002
        },
        {
            "authors": [
                "T. Pesic-Brdanin",
                "B. Doki\u0107"
            ],
            "title": "Strained silicon layer in CMOS technology",
            "year": 2014
        },
        {
            "authors": [
                "S. Wen",
                "S. Xiao",
                "Y. Yang",
                "Z. Yan",
                "Z. Zeng",
                "T. Huang"
            ],
            "title": "Adjusting Learning Rate of Memristor-Based Multilayer Neural Networks via Fuzzy Method",
            "venue": "IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst",
            "year": 2019
        },
        {
            "authors": [
                "O. Krestinskaya",
                "K.N. Salama",
                "A.P. James"
            ],
            "title": "Learning in Memristive Neural Network Architectures Using Analog Backpropagation Circuits",
            "venue": "IEEE Trans. Circuits Syst. I Regul. Pap",
            "year": 2019
        },
        {
            "authors": [
                "S. Wen",
                "H. Wei",
                "Z. Yan",
                "Z. Guo",
                "Y. Yang",
                "T. Huang",
                "Y. Chen"
            ],
            "title": "Memristor-Based Design of Sparse Compact Convolutional Neural Network",
            "venue": "IEEE Trans. Netw. Sci. Eng. 2020,",
            "year": 1990
        },
        {
            "authors": [
                "J. Fu",
                "Z. Liao",
                "J. Wang"
            ],
            "title": "Memristor-Based Neuromorphic Hardware Improvement for Privacy-Preserving ANN",
            "venue": "IEEE Trans. Very Large Scale Integr. Syst",
            "year": 2019
        },
        {
            "authors": [
                "Y. Zhang",
                "M. Cui",
                "L. Shen",
                "Z. Zeng"
            ],
            "title": "Memristive Quantized Neural Networks: A Novel Approach to Accelerate Deep Learning On-Chip",
            "venue": "IEEE Trans. Cybern",
            "year": 2021
        },
        {
            "authors": [
                "X. Liu",
                "Z. Zeng"
            ],
            "title": "Memristor crossbar architectures for implementing deep neural networks",
            "venue": "Complex Intell. Syst. 2022,",
            "year": 2022
        },
        {
            "authors": [
                "R. Wang",
                "W. Zhang",
                "S. Wang",
                "T. Zeng",
                "X. Ma",
                "H. Wang",
                "Y. Hao"
            ],
            "title": "Memristor-Based Signal Processing for Compressed Sensing",
            "venue": "Nanomaterials",
            "year": 2023
        },
        {
            "authors": [
                "G.C. Adam",
                "A. Khiat",
                "T. Prodromakis"
            ],
            "title": "Challenges hindering memristive neuromorphic hardware from going mainstream",
            "venue": "Nat. Commun. 2018,",
            "year": 2018
        },
        {
            "authors": [
                "W. Xu",
                "J. Wang",
                "X. Yan"
            ],
            "title": "Advances in Memristor-Based",
            "venue": "Neural Networks. Front. Nanotechnol. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "K.V. Pham",
                "S.B. Tran",
                "T.V. Nguyen",
                "K.-S. Min"
            ],
            "title": "Asymmetrical Training Scheme of Binary-Memristor-Crossbar-Based Neural Networks for Energy-Efficient Edge-Computing Nanoscale Systems",
            "venue": "Micromachines",
            "year": 2019
        },
        {
            "authors": [
                "H. Yu",
                "L. Ni",
                "H. Huang"
            ],
            "title": "Distributed In-Memory Computing on Binary Memristor-Crossbar for Machine Learning. In Advances in Memristors, Memristive Devices and Systems",
            "year": 2017
        },
        {
            "authors": [
                "M.W. Eysenck",
                "M.T. Keane"
            ],
            "title": "Cognitive Psychology: A Student\u2019s Handbook, 4th ed.; Psychology",
            "year": 2000
        },
        {
            "authors": [
                "S.N. Truong",
                "S.-J. Ham",
                "K.-S. Min"
            ],
            "title": "Neuromorphic crossbar circuit with nanoscale filamentary-switching binary memristors for speech recognition",
            "venue": "Nanoscale Res. Lett. 2014,",
            "year": 2014
        },
        {
            "authors": [
                "X. Wu",
                "B. Dang",
                "H. Wang",
                "Y. Yang"
            ],
            "title": "Spike-Enabled Audio Learning in Multilevel Synaptic Memristor Array-Based Spiking Neural Network",
            "venue": "Adv. Intell. Syst. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "S.N. Truong",
                "S. Shin",
                "S. Byeon",
                "J. Song",
                "K. Min"
            ],
            "title": "New Twin Crossbar Architecture of Binary Memristors for Low-Power Image Recognition With Discrete Cosine Transform",
            "venue": "IEEE Trans. Nanotechnol",
            "year": 2015
        },
        {
            "authors": [
                "S.N. Truong"
            ],
            "title": "Single Crossbar Array of Memristors With Bipolar Inputs for Neuromorphic Image Recognition",
            "venue": "IEEE Access 2020,",
            "year": 2020
        },
        {
            "authors": [
                "S.N. Truong",
                "K.V. Pham",
                "W. Yang",
                "S. Shin",
                "K. Pedrotti",
                "K.-S. Min"
            ],
            "title": "New pulse amplitude modulation for fine tuning of memristor synapses. Microelectron",
            "venue": "J. 2016,",
            "year": 2016
        },
        {
            "authors": [
                "C. Yakopcic",
                "T.M. Taha",
                "G. Subramanyam",
                "R.E. Pino",
                "S. Rogers"
            ],
            "title": "A Memristor Device Model",
            "venue": "IEEE Electron Device Lett",
            "year": 2011
        }
    ],
    "sections": [
        {
            "text": "Citation: Le, M.; Truong, S.N.\nResearch on the Impact of Data\nDensity on Memristor Crossbar\nArchitectures in Neuromorphic\nPattern Recognition. Micromachines\n2023, 14, 1990. https://doi.org/\n10.3390/mi14111990\nAcademic Editors: Aiqun Liu,\nZhongrui Wang, Arman Roohi,\nHaider Abbas and Andrey Sokolov\nReceived: 21 August 2023\nRevised: 22 September 2023\nAccepted: 25 October 2023\nPublished: 27 October 2023\nCopyright: \u00a9 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: pattern recognition; memristor crossbar circuit; neuromorphic computing"
        },
        {
            "heading": "1. Introduction",
            "text": "Memristor was mathematically proposed in 1971 by Prof. L. O. Chua as basic as the three circuit elements, namely the resistor, inductor, and capacitor [1]. The first practical memristor device was introduced by R. S. William and several colleagues at HewlettPackard Laboratories in 2008 [2]. The conductance of a memristor, also known as memristance, can be modified by programming pulses and has the ability to be maintained, making the memristor an ideal device for modelling the synaptic plasticity of biological neuronal systems [3,4]. Furthermore, with 2D array and 3D array structures [5\u20139], memristor crossbar arrays have become an emerging technology for high-density neuromorphic computing systems, as an alternative to CMOS technology that is unquestionably approaching the physical scaling limits [10,11]. Hardware implementations of neural computing using memristor crossbars have achieved much success in the last decade [12\u201317]. Since the multiplication and accumula-\nMicromachines 2023, 14, 1990. https://doi.org/10.3390/mi14111990 https://www.mdpi.com/journal/micromachines\nMicromachines 2023, 14, 1990 2 of 13\ntion operations can be performed using Kirchoff\u2019s law and Ohm\u2019s law at the circuit level, the results can be obtained in a single step, leading to a significant improvement in computational speed, energy consumption, and area occupancy [18]. Although the memristor crossbar has many advantages, the implementation of neural computing using memristor crossbar faces many challenges, caused by non-ideal device parameters, for example, programming variation, state-stuck devices, conductance drift, and device variability [19,20]. The binary memristor crossbar, in which memristor has only two states: low resistance and high resistance states, becomes more feasible for neuromorphic computing [13,16,21,22]. The binary memristor crossbar can perform the cognitive task of pattern recognition, which is the process that matches information from a stimulus with information retrieved from the memory [23]. Several brain-inspired neuromorphic computing circuits employing binary memristor crossbar arrays for neuromorphic pattern recognitions such as speech recognition [24,25] and image recognition [26,27] have been recently proposed. With the high ratio of high resistance state to low resistance state, binary memristor arrays are more efficient for implementing brain-inspired neuromorphic computing for pattern recognition applications in terms of power consumption, and noise and device variation tolerance, compared with analog memristor crossbar arrays. The first interesting architecture of binary memristor crossbar for brain-inspired neuromorphic computing is the complementary crossbar that performs the logical function of Exclusive-NOR for speech and image recognition [24]. The twin crossbar architecture is a modified version of the complementary crossbar for low-power neuromorphic image recognition [26]. The single crossbar architecture is then an optimized version of the complementary crossbar and the twin crossbar by shortening the Exclusive-NOR function [27]. The single memristor crossbar architecture has more advantages in terms of area occupancy, power consumption, and fault tolerance. The single memristor crossbar is a potential piece of architecture for neuromorphic image recognition because it can save area occupancy and power consumption, compared to the complementary and twin crossbar architectures. In previous work, to obtain the single crossbar architecture, a constant term in the expanded function of the Exclusive-NOR is omitted. Because all constant terms of all columns are omitted, so it does not affect the identification of the winner. The single memristor crossbar circuit was tested with 10 binary images. The tested images have a high number of 1 bits. Single crossbar architecture has not been tested with images with the low number of 1 bits. Bit 1 of binary image data is represented by a low resistance state memristor, which mainly produces the output column current in single memristor crossbar architecture. If the number of 1 bits is low, the output currents are all very small, which can impact the accuracy of output decision circuit. In this work, we find out the impact of data density on the operation of the single memristor crossbar architecture, in which a constant term of the expanded function of the Exclusive-NOR is omitted. This research shows an interesting result that the single memristor crossbar architecture has the advantage for images with high density, but does not work well with low-density images."
        },
        {
            "heading": "2. The Complementary Memristor Crossbar Architecture and the Single Memristor Crossbar Architecture for Neuromorphic Pattern Recognition",
            "text": "A complementary memristor crossbar architecture has been proposed for the cognitive task of pattern recognition based on the Exclusive NOR operation to measure the similarity between the input pattern and the stored patterns. Complementary memristor crossbar architecture is composed of two complementary crossbar arrays, as conceptually shown in Figure 1. The column outputs are obtained by the Exclusive NOR operation between the input vector and the column vectors [24]:\nY = A\u2295M = AM + A\u2032M\u2032 = A \u00b7 (M+) + A\u2032 \u00b7 (M\u2212) (1)\nMicromachines 2023, 14, 1990 3 of 13\nMicromachines 2023, 14, x FOR PEER REVIEW 3 of 13\n\ud835\udc4c = \ud835\udc34 \u2295 \ud835\udc40 = \ud835\udc34\ud835\udc40 + \ud835\udc34\u2032\ud835\udc40\u2032 = \ud835\udc34 \u2219 (\ud835\udc40 +) + \ud835\udc34\u2032 \u2219 (\ud835\udc40 \u2212) (1)\nIn Equation (1), \ud835\udc34 is the input vector, \ud835\udc40 + and \ud835\udc40 \u2212 represent the memristor\ncrossbar and its inversion, which consists of inverted elements of \ud835\udc40 +, respectively. The\nblock diagram and schematic of the complementary memristor crossbar architecture are\nshown in Figure 1.\nFigure 1a conceptually shows a block diagram of the complementary crossbar ar-\nchitecture for recognizing m patterns. In Figure 1a, the input vector \ud835\udc34 has the size of 1 \u00d7\nn, the \ud835\udc40 + and \ud835\udc40 \u2212 are the two complementary memristor arrays with the size of n \u00d7 m\nin which \ud835\udc5a patterns are pre-stored for later recognition. Each pattern is saved in one\ncolumn of the arrays, in the format of binary data. A memristor in one column of the \ud835\udc40 +\narray may be set at either a high resistance state (HRS) or a low resistance state (LRS)\nwhen storing a bit 0 or a bit 1, respectively. The \ud835\udc40\u2212 array contains memristors that have\ninverted values with corresponding memristors in \ud835\udc40 + . For example, if the \ud835\udc400,0 memristor in the \ud835\udc40 + array has the value of HRS, the \ud835\udc40\u20320,0 memristor in the \ud835\udc40 \u2212 array will have the value of LRS. The \ud835\udc40 + array and \ud835\udc40 \u2212 array can be described in matrices\nas follows:\n\ud835\udc40+ =\n[\n\ud835\udc400,0 \ud835\udc400,1 \u2026 \ud835\udc400,(\ud835\udc5a\u22121) \ud835\udc401,0 \ud835\udc401,1 \u2026 \ud835\udc401,(\ud835\udc5a\u22121)\n\u22ee \u22ee \u22ee \u22ee \ud835\udc40(\ud835\udc5b\u22121),0 \ud835\udc40(\ud835\udc5b\u22121),1 \u2026 \ud835\udc40(\ud835\udc5b\u22121),(\ud835\udc5a\u22121)]\n(2)\nFig re 1. ( ) l i ristor cr ssbar architecture for neuro orphic pattern recognition.\nIn Equation (1), A is the input vector, M+ and M\u2212 represent the memristor crossbar and its inversion, which consists of inverted lements of M+, respectively. Th block diagram and schematic of the complementary me ristor crossb r architecture are shown i Figure 1. Figure 1a conceptually shows a block diagram of the compleme tary crossbar architecture for recognizing m patterns. In Figure 1a, the input vector A has the size of 1 \u00d7 n, the M+ and M\u2212 are the two complementary memristor ar ays with the size of n \u00d7 m in which m pat rns re pre-stored for later recognition. Each pattern is saved in one column of the arrays, in the format of binary data. A m mristor in one colu n of the M+ array may be set at either a high resistance state (HRS) or a low resistance state (LRS) wh n storing a bit 0 or a bit 1, respectively. The M\u2212 array contains memristors that have inverted values with corresponding memristors in M+. For example, if the M0,0 memristor in the M+ array has the value of HRS, the M\u20320,0 memristor in the M\u2212 array will have the value of LRS. The M+ array and M\u2212 array can be described in matrices as follows:\nM+ =  M0,0 M0,1 . . . M0,(m\u22121) M1,0 M1,1 . . . M1,(m\u22121)\n... ...\n... ...\nM(n\u22121),0 M(n\u22121),1 . . . M(n\u22121),(m\u22121)\n\nM\u2212 =  M\u20320,0 M\u20320,1 . . . M\u20320,(m\u22121) M\u20321,0 M\u20321,1 . . . M\u20321,(m\u22121)\n... ...\n... ...\nM\u2032(n\u22121),0 M\u2032(n\u22121),1 . . . M\u2032(n\u22121),(m\u22121)\n (2)\nMicromachines 2023, 14, 1990 4 of 13\nThe input vector A is applied to the M+ array, and its inversion vector, A\u2032, is applied to the M\u2212 array to implement the Exclusive-NOR function between A and M as discussed in Equation (1) in order to obtain the following results:\nY = [ a0 a1 . . . a(n\u22121) ] \u00b7  M0,0 M0,1 . . . M0,(m\u22121) M1,0 M1,1 . . . M1,(m\u22121)\n... ...\n... ...\nM(n\u22121),0 M(n\u22121),1 . . . M(n\u22121),(m\u22121)\n\n+ [ a\u20320 a\u20321 . . . a\u2032(n\u22121) ] \u00b7  M\u20320,0 M\u20320,1 . . . M\u20320,(m\u22121) M\u20321,0 M\u20321,1 . . . M\u20321,(m\u22121)\n... ...\n... ...\nM\u2032(n\u22121),0 M\u2032(n\u22121),1 . . . M\u2032(n\u22121),(m\u22121)  = [ i0 i1 \u00b7 \u00b7 \u00b7 im\u22121 ]\n(3)\nwhere Y = [ i0 i1 \u00b7 \u00b7 \u00b7 im\u22121 ] is the output vector that contains m output column currents. The output current is then fed into a Winner-take-all circuit, which determines the maximum output current. If the Winner-take-all circuit shows that ik is the maximum output current, it means that the input vector A best matches the pattern stored in column kth of the arrays. Figure 1b represents the schematic of a complementary memristor crossbar circuit for recognizing ten black and white images with the size of 32 \u00d7 32. Each image is converted into a vector of size 1024 \u00d7 1 and stored in one column of the M+ array while its inverted vector is stored in the corresponding column of the M\u2212 array. The input image represented by vector A = [ a0 a1 . . . a1023 ] and its inversion vector A\u2032, are applied to the M+ array and the M\u2212 array as presented in Equation (3). The output column current ik is then copied by a current mirror circuit, and makes the pre-charged capacitor Ck discharge. When the capacitor Ck discharges, the voltage VCk decreases either fast or slowly depending on the value of the current ik. If the current ik is large, the capacitor Ck discharges fast and the voltage VCk decreases fast. Ten discharging voltages, VC0 to VC9, are then compared to each other using the Winner-take-all circuit to find the fastest one. The schematic of the Winner-take-all circuit is shown in Figure 2 [24]. Micromachines 2023, 14, x FOR PEER REVIEW 5 of 13\nFigure 2. The schematic of the Winner-take-all circuit.\nThe single memristor crossbar architecture was proposed by utilizing the Exclu-\nsive-NOR function with only one memristor array [27]. The Exclusive-NOR function can\nbe expanded as follows:\n\ud835\udc4c = \ud835\udc34 \u2295 \ud835\udc40 = \ud835\udc34\ud835\udc40 + \ud835\udc34\u2032\ud835\udc40\u2032\n= \ud835\udc34\ud835\udc40 + \ud835\udc34\u2032(1 \u2212 \ud835\udc40)\n= (\ud835\udc34 \u2212 \ud835\udc34\u2032)\ud835\udc40 + \ud835\udc34\u2032\n(4)\nIn Equation (4), \ud835\udc34\u2032 is a constant term for all columns and can be ignored because\nthis term does not affect the determination of the maximum output current. The opti-\nmized Exclusive-NOR function for the single memristor crossbar architecture is ex-\npressed as:\n\ud835\udc4c = \ud835\udc34 \u2295 \ud835\udc40 = \ud835\udc35 \u2219 \ud835\udc40 \ud835\udc64\u210e\ud835\udc52\ud835\udc5f\ud835\udc52 \ud835\udc35 = (\ud835\udc34 \u2212 \ud835\udc34\u2032) (5)\nor:\n\ud835\udc4c = [\ud835\udc4f0 \ud835\udc4f1 \u2026 \ud835\udc4f(\ud835\udc5b\u22121)] \u2219\n[\n\ud835\udc400,0 \ud835\udc400,1 \u2026 \ud835\udc400,(\ud835\udc5a\u22121) \ud835\udc401,0 \ud835\udc401,1 \u2026 \ud835\udc401,(\ud835\udc5a\u22121)\n\u22ee \u22ee \u22ee \u22ee \ud835\udc40(\ud835\udc5b\u22121),0 \ud835\udc40(\ud835\udc5b\u22121),1 \u2026 \ud835\udc40(\ud835\udc5b\u22121),(\ud835\udc5a\u22121)]\n= [\ud835\udc560 \ud835\udc561 \u22ef \ud835\udc56\ud835\udc5a\u22121]\n(6)\nIn Equation (5), \ud835\udc35 = [\ud835\udc4f0 \ud835\udc4f1 \u22ef \ud835\udc4f(\ud835\udc5b\u22121)] is the bipolar input vector generated\nfrom subtraction (\ud835\udc34 \u2212 \ud835\udc34\u2032) and contains the values 1 and \u22121. For example, if the input\nvector \ud835\udc34 is \ud835\udc34 = [ 0 1 0], \ud835\udc34\u2032 will be \ud835\udc34\u2032 = [ 1 0 1] and (\ud835\udc34 \u2212 \ud835\udc34\u2032) will result \ud835\udc35 =\n[ \u22121 1 \u22121] . Therefore, single memristor crossbar architecture employs only one\nmemristor array along with a unipolar-to-bipolar Convertor, as shown in Figure 3.\nFigure 3a shows the block diagram of the single memristor crossbar architecture for\nrecognizing \ud835\udc5a patterns and Figure 3b represents the schematic of the single memristor\ncrossbar architecture for recognizing ten 32 \u00d7 32 binary images. The input vector \ud835\udc34 is\nfirst turned into the bipolar input vector \ud835\udc35 by the Unipolar to bipolar Convertor. The\nbipolar input vector \ud835\udc35 is next applied to the single memristor array where ten patterns\nare stored to obtain the output column currents, the \ud835\udc560 to \ud835\udc569, as expressed in Equations (5) and (6). The output column currents are finally compared to each other by the Win-\nner-take-all circuit to find the maximum output column current \ud835\udc56\ud835\udc58. Here, the input vector \ud835\udc34 best matches the pattern pre-stored in \ud835\udc58th column of the single memristor array.\nQD\nR\nQD\nR\nQD\nR\nLocking\npulse\nFF1\nD0\nPulse\nGenerator\nVC2\nVC1\nOutput0\nOutput1\nOutput9 VC9\nVC0\nQD\nR Output2\nCLK\nCLK\nCLK\nCLK\nFF2\nFF3\nFF10\nVREF\nI9\nI2\nI1\nI0\nI11 I12\nD1\nD2\nD9\nD0\nD1\nD2\nD9\nDelay\nI10 M1\nM2 M12\nFigure 2. The schematic of the Win er-take-all circuit.\nIn the Winner-take-all circuit, ten comparators receive ten discharging voltages, from VC0 to VC9, and compare these voltages with the reference voltage VREF. When a voltage VCk decreases to belo the VREF, the output Dk changes to high while the other outputs remaining low. This means that if VCk is the fastest discharging voltage, the comparators set only Dk to high. The Pulse Generator then produces a locking pulse after a delaying\nMicromachines 2023, 14, 1990 5 of 13\ntime to set the Outputk to high by the flip-flop FFk. The Outputk becomes high, while the other outputs remaining low indicates that the input vector A matches the pattern in the column kth of the memristor arrays. The single memristor crossbar architecture was proposed by utilizing the ExclusiveNOR function with only one memristor array [27]. The Exclusive-NOR function can be expanded as follows:\nY = A\u2295M = AM + A\u2032M\u2032 = AM + A\u2032(1\u2212M) = (A\u2212 A\u2032)M + A\u2032\n(4)\nIn Equation (4), A\u2032 is a constant term for all columns and can be ignored because this term does not affect the determination of the maximum output current. The optimized Exclusive-NOR function for the single memristor crossbar architecture is expressed as:\nY = A\u2295M = B\u00b7M where B = (A\u2212 A\u2032) (5)\nor:\nY = [ b0 b1 . . . b(n\u22121) ] \u00b7  M0,0 M0,1 . . . M0,(m\u22121) M1,0 M1,1 . . . M1,(m\u22121)\n... ...\n... ...\nM(n\u22121),0 M(n\u22121),1 . . . M(n\u22121),(m\u22121)  = [ i0 i1 \u00b7 \u00b7 \u00b7 im\u22121 ] (6)\nIn Equation (5), B = [ b0 b1 \u00b7 \u00b7 \u00b7 b(n\u22121) ] is the bipolar input vector generated from\nsubtraction (A\u2212 A\u2032) and contains the values 1 and \u22121. For example, if the input vector A is A = [ 0 1 0 ] , A\u2032 will be A\u2032 = [ 1 0 1 ] and (A\u2212 A\u2032) will result B = [ \u22121 1 \u22121 ] . Therefore, single memristor crossbar architecture employs only one memristor array along with a unipolar-to-bipolar Convertor, as shown in Figure 3. Micromachines 2023, 14, x FOR PEER REVIEW 6 of 13\nFigure 3. (a) The block diagram and (b) the schematic of the single memristor crossbar architecture for neuromorphic pattern recognition.\nSo far, we can see that the single memristor crossbar array with bipolar input has the\nsame functionality as the complementary memristor crossbar architecture for pattern\nrecognition based on Exclusive-NOR operation. In Equation (4), \ud835\udc34 is the input vector, \ud835\udc40\nis the memristor array in which images are stored in columns. We apply the input vector\nto the array and obtain the output column currents. The winning column is identified as\nthe maximum column current by using a digital Winner-take-all circuit [24]. For a par-\nticular input, all columns in Equation (4) are added a term of \ud835\udc34\u2032; thus, the existence of \ud835\udc34\u2032\ndoes not affect the determination of the maximum column current. Based on this infer-\nence, it is possible to omit the constant term of \ud835\udc34\u2032 to obtain Equation (5). However, in\nEquation (5), if the input vector \ud835\udc34 has a large number of 1 bits (defined as high density),\nmeaning \ud835\udc34\u2032 has small number of 1 bits (defined as low density), the column currents are\nall high. If the input vector \ud835\udc34 has low density, meaning \ud835\udc34\u2032 has high density, omitting \ud835\udc34\u2032\nleads to all column currents are very low. In the CMOS circuit, it is difficult to determine\nthe maximum current when all currents are very low or all currents are very high because\nCMOS transistors have threshold and saturation voltages. Therefore, the single memris-\ntor crossbar architecture becomes a problem when the input images have fewer 1 bits.\n3. Simulation and Results\nThe circuit simulations were performed to test the impact of data density on the\nperformance of single memristor crossbar and the complementary memristor crossbar\narchitectures. The simulations were performed using the SPECTRE circuit simulation\nprovided by Cadence Design Systems Inc, San Jose, CA, USA [28]. Memristors were\nmodeled using Verilog-A [29,30]. Memristor model and parameters are chosen to fit the\npractical memristor device presented in Figure 4 [29,30]. Figure 4 shows a hysteresis be-\nhavior of a real memristor based on the film structure of Pt/LaAlO3/Nb-doped SrTiO3\nstacked layer and a memristor model that can be used to describe various memristive\nbehaviors [29,30].\nVC0\nCLK\nM0\nM1\nC0\nVDD\nM2\nWinner-take-all circuit\nOutput0 Output9\nImage #0\ni0\na1022\na1023\na0\na2\na1\nUnipolar to bipolar\nconverter\nM0,0\nM1,0\nM1023,0\nVC1\nCLK\nM3\nM4\nC1\nVDD\nM5 i1\nM0,1\nM1,1\nM1023,1\nVC9\nCLK C9\nVDD\nM29 i9\nM0,9\nM1,9\nM1023,9\nImage #1 Image #9\ni0 i1 i9\nM27\nM28\n#0\na0\nan \u2212 1\nWinner-take-all circuit\nOutput0 Outputm \u2212 1\nLRS\nHRS Pattern\n#1 #2 #m \u2212 1\n\u2212\ni0 i1 i2 im \u2212 1\nM\n(A \u2212 A')\nNegative input\nPositive input\nUnipolar to bipolar\nconverter\n(a) (b)\nb0\nb1\nb2\nbn \u2212 1\nM\nV+\nV\u2212Vr V+ V\u2212Vr V+ V\u2212Vr\nV+ V\u2212Vr V+ V\u2212Vr\nFigure 3. (a) The block diagram and (b) the schematic of the single memristor crossbar architecture for neuromorphic pattern recognition.\nFigure 3a shows the block diagram of the single memristor crossbar architecture for recognizing m patterns and Figure 3b represents the schematic of the single memristor crossbar architecture for recognizing ten 32 \u00d7 32 binary images. The input vector A is first turned into the bipolar input vector B by the Unipolar to bipolar Convertor. The bipolar\nMicromachines 2023, 14, 1990 6 of 13\ninput vector B is next applied to the single memristor array where ten patterns are stored to obtain the output column currents, the i0 to i9, as expressed in Equations (5) and (6). The output column currents are finally compared to each other by the Winner-take-all circuit to find the maximum output column current ik. Here, the input vector A best matches the pattern pre-stored in kth column of the single memristor array. So far, we can see that the single memristor crossbar array with bipolar input has the same functionality as the complementary memristor crossbar architecture for pattern recognition based on Exclusive-NOR operation. In Equation (4), A is the input vector, M is the memristor array in which images are stored in columns. We apply the input vector to the array and obtain the output column currents. The winning column is identified as the maximum column current by using a digital Winner-take-all circuit [24]. For a particular input, all columns in Equation (4) are added a term of A\u2032; thus, the existence of A\u2032 does not affect the determination of the maximum column current. Based on this inference, it is possible to omit the constant term of A\u2032 to obtain Equation (5). However, in Equation (5), if the input vector A has a large number of 1 bits (defined as high density), meaning A\u2032 has small number of 1 bits (defined as low density), the column currents are all high. If the input vector A has low density, meaning A\u2032 has high density, omitting A\u2032 leads to all column currents are very low. In the CMOS circuit, it is difficult to determine the maximum current when all currents are very low or all currents are very high because CMOS transistors have threshold and saturation voltages. Therefore, the single memristor crossbar architecture becomes a problem when the input images have fewer 1 bits."
        },
        {
            "heading": "3. Simulation and Results",
            "text": "The circuit simulations were performed to test the impact of data density on the performance of single memristor crossbar and the complementary memristor crossbar architectures. The simulations were performed using the SPECTRE circuit simulation provided by Cadence Design Systems Inc, San Jose, CA, USA [28]. Memristors were modeled using Verilog-A [29,30]. Memristor model and parameters are chosen to fit the practical memristor device presented in Figure 4 [29,30]. Figure 4 shows a hysteresis behavior of a real memristor based on the film structure of Pt/LaAlO3/Nb-doped SrTiO3 stacked layer and a memristor model that can be used to describe various memristive behaviors [29,30]. Micromachines 2023, 14, x FOR PEER REVIEW 7 of 13\n-3 -2 -1 0 1 2 3\n-100\n0\n100\n200\n300\nC u rr\ne n t\n(m A\n)\nVoltage (V)\nSimulation\nExperiment\nFigure 4. The memristor\u2019s current\u2013voltage characteristic measured from the real device and the memristor\u2019s behavior model [29].\nAs discussed in the previous section, it is essential to analyze the impact of data\ndensity of patterns on the complementary and the single memristor crossbar architec-\nThe original images are grayscale images with the size of 32 \u00d7 32. Binary images are\nproduced by thresholding grayscale images. By varying the threshold, we obtain images\nwith different data densities. The first three images (#0, #1, and #2) have a low data den-\nsity of 0.25, the next three images (#3, #4, #5) have a moderate data density of 0.5, and the\nlast four images (#6, #7, #8, and #9) have a high density of 0.75. These different data den-\nsity images are then vectorized to the size of 1024 \u00d7 1 and stored in the memristor arrays\nof the complementary crossbar architecture and the single crossbar architecture. Each\nFigure 4. The memristor\u2019s current\u2013voltage characteristic measured from the real device and the memristor\u2019s behavior model [29].\nAs discussed in the previous section, it is essential to analyze the impact of data density of patterns on the complementary and the single memristor crossbar architectures. The data density of a binary image is defined as the percentage of bit 1 s in the image data.\nIn particular, images with high data density will have a higher number of 1 bits, whereas images with low data density will have fewer 1 bits. In this paper, ten images are used to analyze the impact of data density on the performance of memristor crossbar architectures. The original images are presented in Figure 5.\nMicromachines 2023, 14, x FOR PEER REVIEW 7 of 13 -3 -2 -1 0 1 2 3 -100 0 100 200 300 C u rr e n t (m A )\nVoltage (V)\nSimulation Experiment\nimage dat . In particular, images with high data density will have a higher number of 1\nbits, whereas images with low data density will have fewer 1 bits. I this paper, ten im-\nages are used to analyze the impact of data density on the performance of memristor\ncrossbar architectures. The original images are presented in Figure 5.\nFigure 5. Ten original grayscale images, numbered from image number 0 (#0) to image number 9 (#9).\nThe original images are grayscale images with the size of 32 \u00d7 32. Binary images are\nproduced by thresholding grayscale images. By varying the threshold, we obtain images\nwith different data densities. The first three images (#0, #1, and #2) have a low data den-\nsity of 0.25, the next three images (#3, #4, #5) have a moderate data density of 0.5, and the\nlast four images (#6, #7, #8, and #9) have a high density of 0.75. These different data den-\nsity images are then vectorized to the size of 1024 \u00d7 1 and stored in the memristor arrays\nof the complementary crossbar architecture and the single crossbar architecture. Each\n#0 #1 #2 #3 #4\n#5 #6 #7 #8 #9\nFigure 5. Ten original grayscale images, numbered from image number 0 (#0) to image number 9 (#9).\nThe original images are grayscale images with the size of 32 \u00d7 32. Binary images are produced by thresholding grayscale images. By varying the threshold, we obtain images with different data densities. The first three images (#0, #1, and #2) have a low data density of 0.25, the next three images (#3, #4, #5) have a moderate data density of 0.5, and the last four images (#6, #7, #8, and #9) have a high density of 0.75. These different data density images are then vectorized to the size of 1024 \u00d7 1 and stored in the memristor arrays of the complementary crossbar architecture and the single crossbar architecture. Each image is stored in a column of the array. Binary images with different data density produced by thresholding grayscale images are shown in Figure 6. In Figure 6a, a low data density of 0.25 means that the number of bits 1 accounts for 25% of the total number of pixels in the image. In Figure 6b, the images have equal numbers of white pixels and black pixels, and images in Figure 6c have a greater number of white pixels than black pixels. Binary images are represented by vectors of binary values. Each image is stored in one column of the memristor array for single crossbar architecture. For complementary crossbar architecture, each image is stored in two columns, one column in the memristor array and the other in the inverted memristor array, as mentioned before. Binary value 0 is represented by the high resistance state (HRS) memristor and binary 1 is represented by the low resistance state (LRS) memristor in the crossbar array. The HRS and LRS are 1 M\u2126 and 10 K\u2126, respectively. The binary values 0 and 1 in the input vector are mapped to input voltages of 0 V and 1 V, respectively. The input image represented by the vector of input voltage is applied to the crossbar circuit. The output currents are produced at the bottom of columns according to the Ohm\u2019s law and the Kirchoff\u2019s current law. These output column currents are then compared to each other using a Winner-take-all circuit to determine the maximum column current, corresponding to the column containing the pre-stored image that best matches the input image. The Winner-take-all circuit is based on the discharge speeds of pre-charged capacitors, which are controlled by the output column currents, to find the fastest discharging capacitor. Therefore, the values of output column currents play an important role in the recognition accuracy of the memristor crossbar array architectures. The output column currents when recognizing ten input images with different data densities are shown in Figure 7.\nMicromachines 2023, 14, 1990 8 of 13\nMicromachines 2023, 14, x FOR PEER REVIEW 8 of 13\nimage is stored in a column of the array. Binary images with different data density pro-\nduced by thresholding grayscale images are shown in Figure 6.\nFigure 6. Ten black and white images, numbered from image number 0 (#0) to image number 9 (#9), with different data densities: (a) with data density of 0.25, (b) with data density of 0.5, (c) with data density of 0.75.\nIn Figure 6a, a low data density of 0.25 means that the number of bits 1 accounts for\n25% of the total number of pixels in the image. In Figure 6b, the images have equal\nnumbers of white pixels and black pixels, and images in Figure 6c have a greater number\nof white pixels than black pixels.\nBinary images are represented by vectors of binary values. Each image is stored in\none column of the memristor array for single crossbar architecture. For complementary\ncrossbar architecture, each image is stored in two columns, one column in the memristor\narray and the other in the inverted memristor array, as mentioned before. Binary value 0\nis represented by the high resistance state (HRS) memristor and binary 1 is represented\nby the low resistance state (LRS) memristor in the crossbar array. The HRS and LRS are 1\nM\u2126 and 10 K\u2126, respectively. The binary values 0 and 1 in the input vector are mapped to\ninput voltages of 0 V and 1 V, respectively. The input image represented by the vector of\ninput voltage is applied to the crossbar circuit. The output currents are produced at the\nbottom of columns according to the Ohm\u2019s law and the Kirchoff\u2019s current law. These\noutput column currents are then compared to each other using a Winner-take-all circuit\nto determine the maximum column current, corresponding to the column containing the\npre-stored image that best matches the input image. The Winner-take-all circuit is based\non the discharge speeds of pre-charged capacitors, which are controlled by the output\ncolumn currents, to find the fastest discharging capacitor. Therefore, the values of output\ncolumn currents play an important role in the recognition accuracy of the memristor\ncrossbar array architectures. The output column currents when recognizing ten input\nimages with different data densities are shown in Figure 7.\nFigure 6. Ten black and white images, numbered from image number 0 (#0) to image number 9 (#9), with different data densities: (a) with data density of 0.25, (b) with data density of 0.5, (c) with data density of 0.75.\nFigure 7a reveals that the complementary crossbar architecture produces the same amount of maximum column currents when recognizing 10 images (from #0 to #9) which have different data densities. In other words, the maximum output column current of the complementary crossbar architecture does not depend on the data density of the input images and the stored images. In particular, although the data densities of input images are varied from 0.25 to 0.75, th maximum output column currents e stab e at above 100 mA. The reason for these stable aximum output column currents is that the complementary crossbar architecture employs two complementary memristor arrays: the M+ memristor array and the M\u2212memristor array which contains memristors with inverted values of the corresponding memristors in the M+ array. When a low data density image is stored in the M+ memristor array, its inverted image or the complementary high data density image would als be stored i the M\u2212memristor array and vice versa. An output column current is the sum of corresponding output currents from the M+ and M\u2212 arrays; therefore, the maximum output column current remain unchanged regardless of the input images with different data densities.\nMicromachines 2023, 14, 1990 9 of 13\nMicromachines 2023, 14, x FOR PEER REVIEW 9 of 13 Figure 7a reveals that the complementary crossbar architecture produces the same amount of maximum column currents when recognizing 10 images (from #0 to #9) which have different data densities. In other words, the maximum output column current of the complementary crossbar architecture does not depend on the data density of the input images and the stored images. In particular, although the data densities of input images are varied from 0.25 to 0.75, the maximum output column currents are stable at above 100 mA. The reason for these stable maximum output column currents is that the complementary crossbar architecture employs two complementary memristor arrays: the \ud835\udc40 + memristor array and the \ud835\udc40 \u2212 memristor array which contains memristors with inverted\nvalues of the corresponding memristors in the \ud835\udc40 + array. When a low data density im-\nage is stored in the \ud835\udc40 + memristor array, its inverted image or the complementary high\ndata density image would also be stored in the \ud835\udc40 \u2212 memristor array and vice versa. An\noutput column current is the sum of corresponding output currents from the \ud835\udc40 + and\n\ud835\udc40 \u2212 arrays; therefore, the maximum output column current remain unchanged regard-\nless of the input images with different data densities.\nIn contrast, with the single memristor crossbar architecture, the output column currents reduce when the data densities of input images are decreased, as shown in Figure 7b. In particular, when the data density of input images is as low as 0.25 (images #0, #1, #2), the maximum output column currents decreased as much as four times in comparison with the complementary crossbar architecture and the other column currents are 0. The reason for this result is described by Equation (5). In Equation (5), the parameter A\u2032 is omitted because it is a constant. Although this dismissing is mathematically true for implementing the Exclusive-NOR function with the single memristor crossbar array, it\nMicromachines 2023, 14, 1990 10 of 13\ncauses a reduction by an amount of A\u2032 at every output column current. In addition, the subtraction in Equation (5) can yield negative values when the input image has few white pixels or low data density, and these negative values do not generate any current to output column currents. Therefore, when recognizing input images with a low data density of 0.25 by the single crossbar architecture, the maximum column current reduces about 4 times in comparison with by the complementary crossbar architecture, and the rest column currents are 0. When the data density is 0.5 (images #3, #4, #5) and 0.75 (images #6, #7, #8, #9), the maximum output column currents produced by the single crossbar architecture are also decreased, equal to around 0.5 and 0.75; the largest one is generated by the complementary crossbar architecture. Because the Winner-take-all circuit is based on the output column currents, this reduction in the maximum output column current of the single memristor crossbar architecture should be considered. As represented in previous section, the output column currents from memristor crossbars cause the pre-charged capacitors, the C0 to C9, to discharge at different speeds. When an output column current is high, it makes the corresponding capacitor discharge fast, and a capacitor will discharge slowly when the corresponding column current is low. The discharging voltages, the VC0 to VC9, from the pre-charged capacitors is fed into the winner-take-all circuit to determine the maximum output current, corresponding to fastest discharging voltage. When the fastest discharging voltage degrades to below the reference voltage of 0.5 V, it makes the Pulse Generator create a pulse to lock the wining output among all outputs, from Output0 to Output9. If the Outputk becomes 1 while the others are 0, it indicates that VCk is the fastest discharging voltage or the input image best matches the pattern pre-stored in the kth column. We next analyze the discharging voltages, from VC0 to VC9, which are produced by the single memristor crossbar array corresponding to different data density input images. The discharging voltages when recognizing the image #6 (with data density of 0.75) and the image #0 (with data density of 0.25) with the single crossbar architecture are shown in Figure 8. As shown in Figure 8a, when recognizing image #6, which has high data density of 0.75, using the single memristor crossbar array, the pre-charged capacitor C6 discharges fastest. The discharging voltage VC6 decreases fastest to 0.5 V after around 0.3 ns while the others discharging voltages keep as high as above 0.7 V. In the Winner-take-all circuit, the reference voltage of comparators is set at VREF = 0.5V. Therefore, the comparator i6, which received the VC6 voltage, would set the output D6 to high and the Pulse Generator could finally create a locking pulse to lock the Output6 = 1 to indicate that the output column current i6 is the maximum. In Figure 8b, when recognizing image #0 (data density is 0.25) using the single memristor crossbar array, after the same period time of 0.3 ns, there is no discharging voltage which decreases below the reference voltage of VREF = 0.5V. This means that the Pulse Generator could not create a locking pulse and the Winner-take-all circuit could not determine which column current is the maximum after the same period of time as when recognizing image #6 with a high data density of 0.75. These results prove that low data density input images can cause the single memristor crossbar architecture to recognize incorrectly and, therefore, degrade the recognition rate.\nMicromachines 2023, 14, 1990 11 of 13\nMicromachines 2023, 14, x FOR PEER REVIEW 11 of 13\ndensity input images can cause the single memristor crossbar architecture to recognize\nincorrectly and, therefore, degrade the recognition rate."
        },
        {
            "heading": "4. Discussion",
            "text": "The single memristor crossbar is an optimized crossbar architecture for\nbrain-inspired neuromorphic computing. The single memristor crossbar architecture\nconsumes less power and occupies smaller area than the complementary memristor\ncrossbar architecture. In addition, using only one memristor crossbar array can improve\nthe fault tolerance of the memristor crossbar circuit. Here, the cross-point fault is one of\nthe main causes that significantly reduces the accuracy of the memristor crossbar-base\nneuromorphic circuits [27]. In this paper, we figured out that the single crossbar works\nwell if images have larger number of 1 bits. By contrast, if images have fewer 1 bits, the\ncomplementary crossbar architecture performs the image recognition better than the\nsingle crossbar architecture. When the input images have data density as low as 0.25, the\nmaximum output column currents obtained by the single memristor crossbar architec-\nture reduce about four times in comparison with the complementary crossbar architec-\nture. The Winner-take-all circuit could not determine the maximum current, leading to\nthe degradation of the recognition rate of the single memristor crossbar architecture. The\nsingle me ristor crossbar is n optimized crossbar architectu e fo brain-inspired neuromorphic computing. The single memristor crossbar architecture c n umes less power and occupies maller area than the co p ementary memristor crossbar architectu e. In addition, using only o e memristor crossbar array can improve the fault tolerance of\nmemristor crossbar circuit. He e, the cross-po nt fault is one of the main cau es that significa tly reduces he accur cy of the m mristor rossbar-base neuromorphic circuits [27]. In this pa er, we figured out that the singl crossbar works well if images have larger number of 1 bits. By contrast, if images have fewer 1 bits, the complem nta y cro sbar architecture performs the image recognition better than the single cr ssbar architectur . When the input images have data density as low as 0.25, the maximum output column currents obtained by the single memristor crossbar architecture reduce about four times in comparison with the complementary crossbar architecture. The Winner-take-all circuit could not determine the maximum current, leading to the degradation of the recognition rate of the single memristor crossbar architecture. The discoveries from this study are twofold: First, the single memristor crossbar is effective in neuromorphic image recognition provided all images must have high data density. Second, to accommodate images with a low data density, the architecture of the single memristor crossbar must be improved to\nMicromachines 2023, 14, 1990 12 of 13\ncontain the constant term in the expression of Exclusive-NOR function. These are valuable case studies for archiving the advantages of single memristor crossbar architecture in neuromorphic computing applications."
        },
        {
            "heading": "5. Conclusions",
            "text": "In this work, we present the impact of data density on the performance of the single memristor crossbar architecture and the complementary memristor crossbar architecture. The impact of data density on the performance of single crossbar architecture is mathematically figured out by analyzing the effect of the omitted constant term in the Exclusive-NOR operation. The observation is then verified by the circuit simulation for the recognition of images with different levels of density. The complementary crossbar architecture consumes more power and occupies a larger area compared with the single crossbar architecture; however, the complementary crossbar architecture does not depend on data density. Otherwise, single crossbar consumes less power and occupies smaller area than complementary crossbar but single crossbar degrades the performance with low data density images. This work recommends that to ensure the single crossbar architecture works correctly for binary image recognition application, binary images must have high number of 1 bits. Finally, this work also indicates that the single crossbar architecture must be improved by adding a constant term to deal with images that have low data densities. These are valuable case studies for archiving the advantages of single memristor crossbar architecture in neuromorphic computing applications.\nAuthor Contributions: The manuscript was written through the contributions of all authors. Conceptualization, M.L. and S.N.T.; methodology, M.L. and S.N.T.; validation, S.N.T. and M.L.; writing\u2014 original draft preparation, M.L.; writing\u2014review and editing, S.N.T. All authors have read and agreed to the published version of the manuscript.\nFunding: This research received no external funding.\nData Availability Statement: The data presented in this study are available on request from the corresponding author. The data are not publicly available due to the privacy.\nConflicts of Interest: The authors declare no conflict of interest.\nReferences 1. Chua, L. Memristor-The missing circuit element. IEEE Trans. Circuit Theory 1971, 18, 507\u2013519. [CrossRef] 2. Strukov, D.B.; Snider, G.S.; Stewart, D.R.; Williams, R.S. The missing memristor found. Nature 2008, 453, 80\u201383. [CrossRef] 3. Jo, S.; Chang, T.; Ebong, I.; Bhadviya, B.; Mazumder, P.; Lu, W. Nanoscale Memristor Device as Synapse in Neuromorphic Systems. Nano Lett. 2010, 10, 1297\u20131301. [CrossRef] [PubMed] 4. Kim, H.; Sah, M.P.; Yang, C.; Roska, T.; Chua, L.O. Neural Synaptic Weighting With a Pulse-Based Memristor Circuit. IEEE Trans. Circuits Syst. I Regul. Pap. 2012, 59, 148\u2013158. [CrossRef] 5. Williams, R.S. How We Found The Missing Memristor. IEEE Spectr. 2008, 45, 28\u201335. [CrossRef] 6. Pi, S.; Li, C.; Jiang, H.; Xia, W.; Xin, H.; Yang, J.J.; Xia, Q. Memristor crossbar arrays with 6-nm half-pitch and 2-nm critical dimension. Nat. Nanotechnol. 2019, 14, 35\u201339. [CrossRef] 7. K\u00fcgeler, C.; Meier, M.; Rosezin, R.; Gilles, S.; Waser, R. High density 3D memory architecture based on the resistive switching effect. Solid-State Electron. 2009, 53, 1287\u20131292. [CrossRef] 8. Li, C.; Han, L.; Jiang, H.; Jang, M.-H.; Lin, P.; Wu, Q.; Barnell, M.; Yang, J.J.; Xin, H.L.; Xia, Q. Three-dimensional crossbar arrays of self-rectifying Si/SiO2/Si memristors. Nat. Commun. 2017, 8, 15666. [CrossRef] 9. Adam, G.C.; Hoskins, B.D.; Prezioso, M.; Merrikh-Bayat, F.; Chakrabarti, B.; Strukov, D.B. 3-D Memristor Crossbars for Analog and Neuromorphic Computing Applications. IEEE Trans. Electron Devices 2017, 64, 312\u2013318. [CrossRef] 10. Taur, Y. CMOS design near the limit of scaling. IBM J. Res. Dev. 2002, 46, 213\u2013222. [CrossRef] 11. Pesic-Brdanin, T.; Dokic\u0301, B. Strained silicon layer in CMOS technology. Electronics 2014, 18, 63\u201369. [CrossRef] 12. Wen, S.; Xiao, S.; Yang, Y.; Yan, Z.; Zeng, Z.; Huang, T. Adjusting Learning Rate of Memristor-Based Multilayer Neural Networks via Fuzzy Method. IEEE Trans. Comput.-Aided Des. Integr. Circuits Syst. 2019, 38, 1084\u20131094. [CrossRef] 13. Krestinskaya, O.; Salama, K.N.; James, A.P. Learning in Memristive Neural Network Architectures Using Analog Backpropagation Circuits. IEEE Trans. Circuits Syst. I Regul. Pap. 2019, 66, 719\u2013732. [CrossRef] 14. Wen, S.; Wei, H.; Yan, Z.; Guo, Z.; Yang, Y.; Huang, T.; Chen, Y. Memristor-Based Design of Sparse Compact Convolutional Neural\nNetwork. IEEE Trans. Netw. Sci. Eng. 2020, 7, 1431\u20131440. [CrossRef]\nMicromachines 2023, 14, 1990 13 of 13\n15. Fu, J.; Liao, Z.; Wang, J. Memristor-Based Neuromorphic Hardware Improvement for Privacy-Preserving ANN. IEEE Trans. Very Large Scale Integr. Syst. 2019, 27, 2745\u20132754. [CrossRef] 16. Zhang, Y.; Cui, M.; Shen, L.; Zeng, Z. Memristive Quantized Neural Networks: A Novel Approach to Accelerate Deep Learning On-Chip. IEEE Trans. Cybern. 2021, 51, 1875\u20131887. [CrossRef] 17. Liu, X.; Zeng, Z. Memristor crossbar architectures for implementing deep neural networks. Complex Intell. Syst. 2022, 8, 787\u2013802. [CrossRef] 18. Wang, R.; Zhang, W.; Wang, S.; Zeng, T.; Ma, X.; Wang, H.; Hao, Y. Memristor-Based Signal Processing for Compressed Sensing. Nanomaterials 2023, 13, 1354. [CrossRef] 19. Adam, G.C.; Khiat, A.; Prodromakis, T. Challenges hindering memristive neuromorphic hardware from going mainstream. Nat. Commun. 2018, 9, 5267. [CrossRef] 20. Xu, W.; Wang, J.; Yan, X. Advances in Memristor-Based Neural Networks. Front. Nanotechnol. 2021, 3, 645995. [CrossRef] 21. Pham, K.V.; Tran, S.B.; Nguyen, T.V.; Min, K.-S. Asymmetrical Training Scheme of Binary-Memristor-Crossbar-Based Neural Networks for Energy-Efficient Edge-Computing Nanoscale Systems. Micromachines 2019, 10, 141. [CrossRef] [PubMed] 22. Yu, H.; Ni, L.; Huang, H. Distributed In-Memory Computing on Binary Memristor-Crossbar for Machine Learning. In Advances\nin Memristors, Memristive Devices and Systems; Vaidyanathan, S., Volos, C., Eds.; Springer International Publishing: Cham, Switzerland, 2017; pp. 275\u2013304.\n23. Eysenck, M.W.; Keane, M.T. Cognitive Psychology: A Student\u2019s Handbook, 4th ed.; Psychology Press: New York, NY, USA, 2000; p. 631. 24. Truong, S.N.; Ham, S.-J.; Min, K.-S. Neuromorphic crossbar circuit with nanoscale filamentary-switching binary memristors for speech recognition. Nanoscale Res. Lett. 2014, 9, 629. [CrossRef] [PubMed] 25. Wu, X.; Dang, B.; Wang, H.; Wu, X.; Yang, Y. Spike-Enabled Audio Learning in Multilevel Synaptic Memristor Array-Based Spiking Neural Network. Adv. Intell. Syst. 2021, 4, 2100151. [CrossRef] 26. Truong, S.N.; Shin, S.; Byeon, S.; Song, J.; Min, K. New Twin Crossbar Architecture of Binary Memristors for Low-Power Image Recognition With Discrete Cosine Transform. IEEE Trans. Nanotechnol. 2015, 14, 1104\u20131111. [CrossRef] 27. Truong, S.N. Single Crossbar Array of Memristors With Bipolar Inputs for Neuromorphic Image Recognition. IEEE Access 2020, 8, 69327\u201369332. [CrossRef] 28. Spectre\u00ae Circuit Simulator Reference; Cadence Design Systems: San Jose, CA, USA, 2003; p. 912. 29. Truong, S.N.; Pham, K.V.; Yang, W.; Shin, S.; Pedrotti, K.; Min, K.-S. New pulse amplitude modulation for fine tuning of memristor synapses. Microelectron. J. 2016, 55, 162\u2013168. [CrossRef] 30. Yakopcic, C.; Taha, T.M.; Subramanyam, G.; Pino, R.E.; Rogers, S. A Memristor Device Model. IEEE Electron Device Lett. 2011, 32,\n1436\u20131438. [CrossRef]\nDisclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."
        }
    ],
    "title": "Research on the Impact of Data Density on Memristor Crossbar Architectures in Neuromorphic Pattern Recognition",
    "year": 2023
}