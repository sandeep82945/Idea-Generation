{
    "abstractText": "Te presence of these indicators undermines our confdence in the integrity of the article\u2019s content and we cannot, therefore, vouch for its reliability. Please note that this notice is intended solely to alert readers that the content of this article is unreliable. We have not investigated whether authors were aware of or involved in the systematic manipulation of the publication process. Wiley and Hindawi regrets that the usual quality checks did not identify these issues before publication and have since put additional measures in place to safeguard research integrity. We wish to credit our own Research Integrity and Research Publishing teams and anonymous and named external researchers and research integrity experts for contributing to this investigation. Te corresponding author, as the representative of all authors, has been given the opportunity to register their agreement or disagreement to this retraction. We have kept a record of any response received.",
    "authors": [
        {
            "affiliations": [],
            "name": "Maryam Alruwaythi"
        }
    ],
    "id": "SP:90e5a8e31d2ba2c0a04685758a0c507cf9fa1dc1",
    "references": [
        {
            "authors": [
                "O. Mohamed",
                "S.A. Aly"
            ],
            "title": "Arabic speech emotion recognition employing wav2vec2. 0 and hubert based on baved dataset",
            "venue": "2021, https://arxiv.org/abs/2110.04425.",
            "year": 2021
        },
        {
            "authors": [
                "B. Li",
                "J. Zhu",
                "C. Wang"
            ],
            "title": "Depression severity prediction by multi-model fusion",
            "venue": "Proceedings of the HEALTHINFO 2018: <e <ird International Conference on Informatics and Assistive Technologies for HealthCare, pp. 19\u201324, Medical Support and Wellbeing, Nice, France, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "O.W. H"
            ],
            "title": "Depression, Other Common Mental Disorders",
            "venue": "Global Health Estimates,",
            "year": 2017
        },
        {
            "authors": [
                "T. Saba",
                "A Rehman",
                "M. N Shahzad"
            ],
            "title": "Machine learning for post-traumatic stress disorder identification utilizing resting-state functional magnetic resonance imaging",
            "venue": "Microscopy Research and Technique, vol. 2021, no. 80, 2022.",
            "year": 2021
        },
        {
            "authors": [
                "M.N. Shahzad",
                "H. Ali",
                "T. Saba",
                "A. Rehman",
                "H. Kolivand",
                "S.A. Bahaj"
            ],
            "title": "Identifying patients with PTSD utilizing restingstate fMRI data and neural network approach",
            "venue": "IEEE Access, vol. 9, pp. 107941\u2013107954, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "P. Fusar-Poli",
                "B. Nelson",
                "L. Valmaggia",
                "A.R. Yung",
                "P.K. McGuire"
            ],
            "title": "Comorbid depressive and anxiety disorders in 509 individuals with an at-risk mental state: impact on psychopathology and transition to psychosis",
            "venue": "Schizophrenia Bulletin, vol. 40, no. 1, pp. 120\u2013131, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "A. V\u00e1zquez-Romero",
                "A. Gallardo-Anto\u013a\u0131n"
            ],
            "title": "Automatic detection of depression in speech using ensemble convolutional neural networks",
            "venue": "Entropy, vol. 22, no. 6, p. 688, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "M.A. Khan",
                "S. Kadry",
                "Y.-D. Zhang"
            ],
            "title": "Prediction of COVID-19 - pneumonia based on selected deep features and one class kernel extreme learning machine",
            "venue": "Computers & Electrical Engineering, vol. 90, Article ID 106960, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "H. Wang",
                "Y. Liu",
                "X. Zhen",
                "X. Tu"
            ],
            "title": "Depression speech recognition with a three-dimensional convolutional network",
            "venue": "Frontiers in Human Neuroscience, vol. 15, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Saidi",
                "S.B. Othman",
                "S.B. Saoud"
            ],
            "title": "Hybrid CNN-SVM classifier for efficient depression detection system",
            "venue": "Proceedings of the 2020 4th International Conference on Advanced Systems and Emergent Technologies (IC_ASET), pp. 229\u2013234, IEEE, Manhattan, New York, December 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Yun",
                "C.D. Yoo"
            ],
            "title": "Loss-scaled large-margin Gaussian mixture models for speech emotion classification",
            "venue": "IEEE Transactions on Audio Speech and Language Processing, vol. 20, no. 2, pp. 585\u2013598, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "J.R.Williamson",
                "T.F. Quatieri",
                "B.S. Helfer",
                "R. Horwitz",
                "B. Yu",
                "D.D. Mehta"
            ],
            "title": "Vocal biomarkers of depression based on motor incoordination",
            "venue": "Proceedings of the 3rd ACM International Workshop on Audio/visual Emotion challenge, pp. 41\u201348, Barcelona Spain, October 2013.",
            "year": 2013
        },
        {
            "authors": [
                "D. Le",
                "E.M. Provost"
            ],
            "title": "Emotion recognition from spontaneous speech using hidden Markov models with deep belief networks",
            "venue": "Proceedings of the 2013 IEEE Workshop on Automatic Speech Recognition and Understanding, pp. 216\u2013 221, IEEE, Manhattan, New York, December 2013.",
            "year": 2013
        },
        {
            "authors": [
                "Y.H. Kao",
                "L.S. Lee"
            ],
            "title": "Feature analysis for emotion recognition from Mandarin speech considering the special characteristics of Chinese language",
            "venue": "Proceedings of the InterSpeech, Pittsburgh, PA, USA, September 2006.",
            "year": 2006
        },
        {
            "authors": [
                "M. Yousuf",
                "Z. Mehmood",
                "H.A. Habib"
            ],
            "title": "A novel technique based on visual words fusion analysis of sparse features for effective content-based image retrieval",
            "venue": "Mathematical Problems in Engineering, vol. 2018, Article ID 2134395, 13 pages, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "K. Han",
                "D. Yu",
                "I. Tashev"
            ],
            "title": "Speech emotion recognition using deep neural network and extreme learning machine",
            "venue": "Proceedings of the Interspeech 2014, Singapore, Malaysia, September 2014.",
            "year": 2014
        },
        {
            "authors": [
                "D. Bertero",
                "P. Fung"
            ],
            "title": "A first look into a convolutional neural network for speech emotion detection",
            "venue": "Proceedings of the 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 5115\u20135119, IEEE, New Orleans, LA, USA, 2017, March.",
            "year": 2017
        },
        {
            "authors": [
                "K. Cho",
                "B. Van Merri\u00ebnboer",
                "C. Gulcehre"
            ],
            "title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation",
            "venue": "2014, https://arxiv.org/abs/1406. 1078.",
            "year": 2014
        },
        {
            "authors": [
                "J. Bradbury",
                "S. Merity",
                "C. Xiong",
                "R. Socher"
            ],
            "title": "Quasi-recurrent neural networks",
            "venue": "2016, https://arxiv.org/abs/1611. 01576.",
            "year": 2016
        },
        {
            "authors": [
                "S. Basu",
                "J. Chakraborty",
                "M. Aftabuddin"
            ],
            "title": "Emotion recognition from speech using convolutional neural network with recurrent neural network architecture",
            "venue": "Proceedings of the 2017 2nd International Conference on Communication and Electronics Systems (ICCES), pp. 333\u2013336, IEEE, Coimbatore, India, October 2017.",
            "year": 2017
        },
        {
            "authors": [
                "S. Indolia",
                "A.K. Goswami",
                "S.P. Mishra",
                "P. Asopa"
            ],
            "title": "Conceptual understanding of convolutional neural network- A deep learning approach",
            "venue": "Procedia Computer Science, vol. 132, pp. 679\u2013688, 2018. 8 Computational Intelligence and Neuroscience RE TR AC TE D",
            "year": 2018
        },
        {
            "authors": [
                "K.B. Lee",
                "S. Cheon",
                "C.O. Kim"
            ],
            "title": "A convolutional neural network for fault classification and diagnosis in semiconductor manufacturing processes",
            "venue": "IEEE Transactions on Semiconductor Manufacturing, vol. 30, no. 2, pp. 135\u2013142, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "J. Koushik"
            ],
            "title": "Understanding convolutional neural networks",
            "venue": "vol. 3, pp. 1\u20136, 2016, http://arxiv.org/abs/1605.09081.",
            "year": 2016
        },
        {
            "authors": [
                "S.-H.Wang",
                "P. Phillips",
                "Y. Sui",
                "B. Liu",
                "M. Yang",
                "H. Cheng"
            ],
            "title": "Classification of alzheimer\u2019s disease based on eight-layer convolutional neural network with leaky rectified linear unit and max pooling",
            "venue": "Journal of Medical Systems, vol. 42, no. 5, pp. 85\u201311, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "L. Wang"
            ],
            "title": "Support Vector Machines: <eory and Applications - Google Knihy, Springler",
            "venue": "Salmon Tower Building New York City,",
            "year": 2005
        },
        {
            "authors": [
                "A. Sarwar",
                "Z. Mehmood",
                "T. Saba",
                "K.A. Qazi",
                "A. Adnan",
                "H. Jamal"
            ],
            "title": "A novel method for content-based image retrieval to improve the effectiveness of the bag-of-words model using a support vector machine",
            "venue": "Journal of Information Science, vol. 45, no. 1, pp. 117\u2013135, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "K.M. Sullivan",
                "S. Luke"
            ],
            "title": "Evolving kernels for support vector machine classification",
            "venue": "Proceedings of the 9th Annual conference on Genetic and Evolutionary Computation - GECCO \u201807, pp. 1702\u20131707, London, England, July 2007.",
            "year": 2007
        },
        {
            "authors": [
                "Y. Ming",
                "S. Cao",
                "R. Zhang"
            ],
            "title": "Understanding hidden memories of recurrent neural networks",
            "venue": "Proceedings of the 2017 IEEE Conference on Visual Analytics Science and Technology (VAST), pp. 13\u201324, IEEE, NewOrleans, LA, USA, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "G. Mesnil",
                "X. He",
                "L. Deng",
                "Y. Bengio"
            ],
            "title": "Investigation of recurrent - neural - network architectures and learning methods for spoken language understanding",
            "venue": "Interspeech, vol. 2, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "X. Yang",
                "J. Liu"
            ],
            "title": "Using word confusion networks for slot filling in spoken language understanding",
            "venue": "Interspeech 2015, vol. 2015, no. 3, pp. 1353\u20131357, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "K. Hajian-Tilaki"
            ],
            "title": "Receiver operating characteristic (ROC) curve analysis for medical diagnostic test evaluation",
            "venue": "Caspian journal of internal medicine, vol. 4, no. 2, pp. 627\u2013635, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "H. Lu",
                "Z. Ge",
                "Y. Song",
                "D. Jiang",
                "T. Zhou",
                "J. Qin"
            ],
            "title": "A temporal-aware lstm enhanced by loss-switch mechanism for traffic flow forecasting",
            "venue": "Neurocomputing, vol. 427, pp. 169\u2013 178, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "K. Yousaf",
                "Z. Mehmood",
                "T. Saba"
            ],
            "title": "Mobile-health applications for the efficient delivery of health care facility to people with dementia (pwd) and support to their carers: a survey",
            "venue": "BioMed Research International, vol. 2019, Article ID 7151475, 26 pages, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "K.B. DeSalvo",
                "V.S. Fan",
                "M.B. McDonell",
                "S.D. Fihn"
            ],
            "title": "Predicting mortality and healthcare utilization with a single question",
            "venue": "Health Services Research, vol. 40, no. 4, pp. 1234\u20131246, 2005.",
            "year": 2005
        },
        {
            "authors": [
                "H. Dyoniputri"
            ],
            "title": "A hybrid convolutional neural network and support vector machine for dysarthria speech classification",
            "venue": "International Journal of Innovative Computing, Information and Control, vol. 17, no. 1, pp. 111\u2013123, 2021. Computational Intelligence and Neuroscience 9",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "Retraction",
            "text": ""
        },
        {
            "heading": "Retracted: Arabic Speech Analysis for Classification and",
            "text": ""
        },
        {
            "heading": "Prediction of Mental Illness due to Depression Using",
            "text": ""
        },
        {
            "heading": "Deep Learning",
            "text": "Computational Intelligence and Neuroscience\nReceived 10 October 2023; Accepted 10 October 2023; Published 11 October 2023\nCopyright \u00a9 2023 Computational Intelligence and Neuroscience. Tis is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\nTis article has been retracted by Hindawi following an investigation undertaken by the publisher [1]. Tis investigation has uncovered evidence of one or more of the following indicators of systematic manipulation of the publication process:\n(1) Discrepancies in scope (2) Discrepancies in the description of the research\nreported (3) Discrepancies between the availability of data and\nthe research described (4) Inappropriate citations (5) Incoherent, meaningless and/or irrelevant content\nincluded in the article (6) Peer-review manipulation\nTe presence of these indicators undermines our confdence in the integrity of the article\u2019s content and we cannot, therefore, vouch for its reliability. Please note that this notice is intended solely to alert readers that the content of this article is unreliable. We have not investigated whether authors were aware of or involved in the systematic manipulation of the publication process.\nWiley and Hindawi regrets that the usual quality checks did not identify these issues before publication and have since put additional measures in place to safeguard research integrity.\nWe wish to credit our own Research Integrity and Research Publishing teams and anonymous and named external researchers and research integrity experts for contributing to this investigation.\nTe corresponding author, as the representative of all authors, has been given the opportunity to register their agreement or disagreement to this retraction. We have kept a record of any response received."
        },
        {
            "heading": "1. Introduction",
            "text": "Depression is known as a mental disorder or mental illness, and according to WHO, currently more than 300 million (4.4%) people are affected by depression [1], and its rate is continually increasing [2]. From 2005 to 2015, almost 18% of the occurrence of depression has increased worldwide. Depression leads to somatic problems, mental disorders, sleep disorders, and gastrointestinal problems. -e selfconfidence and rumination symptoms show in depressionrelated patients [3, 4]. It affects the functioning or performance of patients at school, family, and work. It may also severely impact people causing self-harm and sometimes suicide. Mood disorder and mental illness in adult life are also associated with depressive disorder [5, 6]. From depression, people may also experience a bad mood, low selfesteem, loss of interest, low energy, and body pain without a clear cause [7]. Automatic speech recognition (ASR) is well known as speech recognition. It provides the facility of understanding the users\u2019 speech by converting the word speech into series using the computer [8]. A speech emotion recognition system is helpful in medical practice for detecting changes in mental state and emotions. For example, when a patient has mood swings, the system will react rapidly and examine their current psychological state [9]. As a result, the depression prediction methods might help\nHindawi Computational Intelligence and Neuroscience Volume 2022, Article ID 8622022, 9 pages https://doi.org/10.1155/2022/8622022\nRE TR AC TE D\ndesign better mental health care software and technologies such as intelligent robots.\n1.1.Background. Depression rates are continually increasing in people where many issues occur from this mental disorder in daily life. Unfortunately, it is difficult to predict depression from people while neutral speaking. Machine learning can be considered one of the most common ways to look at data from different sources and figure out how people feel and speak under depression.\nEarly recognition of depressed symptoms, followed by evaluation and therapy, may greatly enhance the odds of controlling symptoms and the underlying illness and attenuate harmful consequences for health and social life. However, detecting depression disorder is difficult and timeconsuming. Current methods primarily rely on clinical discussion and surveys conducted by a psychologist for mental disorder predictions. -is method is largely based on one-on-one surveys and may generally identify depression as a mental disorder condition. Since machine learning models are increasingly being used to make essential predictions in critical situations daily, the demand for transparency from all the people in the AI industry grows in these situations. Many research projects attempt to develop an automated depression detection system [10]. -e GMMs (Gaussian mixtures models) [11, 12], HMMs (hidden Markov models) [13], and SVM (support vector machine) [14, 15] were used to recognize the depressed emotions using the speech data.\nDeep neural networks have lately made significant contributions to a wide range of disciplines of study, including pattern recognition, and proved a better option than traditional machine learning techniques such as SVM, ANN, HMM, and so on. Han et al. [16] proposed a DNN-ELM (extreme learning machine) based voice emotion classification system. Bertero and Fung [17] used the convolutional neural network (CNN), which has a lot of applications in this field to recognize voice-related emotions, and reported good results. In the subsequent research, RNN and LSTM (long short-term memory) were also enhanced, and GRU [18], QRNN [19], and other models were also proposed for speech data. Simultaneously, different work attempted to integrate the CNN and RNN into a CRNN model for speech emotion recognition [20]. -e 1D-CNN architecture improves the individual systems\u2019 performance since it was recently developed to deal with text or one-dimension data such as human speech. However, ensemble CNN models exhibited better performance for emotions classification using speech analysis [7].\nTo help address these issues, we built an automated method for identifying depressive symptoms from Arabic speech analysis. -e proposed automated mental illness identification technique, which describes users\u2019 concerns in Arabic, might significantly contribute to this research area. -is study proposed a hybridmodel (CNN+SVM) to classify depression from Arabic speech analysis and predict mental disorders. Additionally, results are compared with RNN and 1-D CNN for the same problem on the same data set.\n1.2. Main Contributions. -is research has the following main contributions:\n(i) -e first time, CNN+ SVM-based hybrid model is proposed for Arabic speech analysis to predict mental illness due to depression and attained approximately 92% accuracy\n(ii) A large Arabic speech benchmark data set is employed for experiments\n(iii) Experts from both themedical and psychology fields are consulted to derive possible symptoms of depression for best features identification\n(iv) RNN and CNN are individually applied to the same data set for analysis and comparisons of the results of the proposed hybrid model\n(v) Using our model researcher will detect depression while speaking the Arabic language with an approximately 92% accuracy rate\nFurthermore, this research is divided into four main sections. Section 2 presents the proposed methodology. Section 3 details experimental results with analysis. Section 4 compares the results of the proposed hybrid model with individual RNN and CNN on the same benchmark data set. Finally, Section 5 summarizes the research."
        },
        {
            "heading": "2. Proposed Methodology",
            "text": "-is study is designed to predict depression using recorded Arabic speech analysis or while speaking in the Arabic language with the proposed hybrid approach exhibited in Figure 1 and compare with deep learning (DL) models such as RNN and CNN.\nFirst, we extracted the features from the speeches of both depression and nondepression groups. -e Mcc, chroma_stft, chroma_cqt, tonnetz, melspectrogram, spectral_centroid, and spectral_contrast features were extracted for speeches using the Python coding.\nCNN is a deep learning model used for pattern classification and is composed of an input layer, hidden layers, and output layer F \ufffd (Y, W) \ufffd X, where Y is the input,W is the weight vector, F is any function, and X is the output. -e hidden layer contains four components: the convolution layer, pooling layer, fully connected layer, and activation function [21].\n(i) Convolution layer: a kernel is selected that goes over the input vector that produces a feature map xi,j \ufffd \u03c3((W\u2217Y)i,j + b), where xi,j is the output of the convolution operator, W is the kernel with goes over, Y is the input, \u03c3 denotes the nonlinearity in the network, and b is the bias [21\u201323].\n(ii) Pooling layer: the dominant features are extracted by selecting a window that passes through the pooling function, average pooling, max-pooling, or stochastic pooling [24].\n(iii) Fully connected layer: the convolution and pooling outputs are included here, and the final dot product of input and weight vector is computed in this layer\nRE TR AC\nTE\n(iv) Activation function: sigmoid (it takes values between [0, 1]) also called logistic function; in CNN, its use may cause vanishing or gradient f(x) \ufffd (1/1 + e\u2212 x)) and [14] softmax (it takes a vector argument and transforms to a vector whose elements fall in the range [0, 1]). When all our dependent variables are categorical, then softmax function is appropriate f(x) \ufffd (ezi/nj e zj ), and ReLU does not allow the gradient to vanish f(x) \ufffd max(0, x) for values greater than zero; it is linear [24]. (v) Support vector machine (SVM): it is a nonparametric supervised machine learning technique employed to classify data by fitting a hyperplane to the data [25, 26]. -ere are different types of SVM learning mechanisms to classify the data; for this purpose, a kernel (kernel selected to make nonlinear data linearly separable) is fitted to the data; the most commonly used kernels are Gaussian K(xi, xj) \ufffd e \u2212 c\u2217xi\u2212 x2j and sigmoid K(xi, xj) \ufffd tanh(c(xi, xj) + r) [27]. -e dense layer of the CNNmodel is used to make the hybrid approach for depression prediction. -e architecture of the proposed model is explained in Table 1.\n2.1. RecurrentNeuralNetwork (RNN). RNN is normally used to analyze sequential data (e.g., speech, text); just like other neural networks, it contains input, hidden and, output layers [28]. -e hidden layer, called the recurrent layer, keeps the same parameters in the following layers that keep on updating in its memory, h(t) \ufffd f(Wx(t) + Uh(t \u2212 1)), where W and U are weight matrices, x(t). -e input vector is h(t \u2212 1), and the correlated hidden layer and f represent the nonlinear activation function [28\u201330]. In the hidden layer, different activation functions are used. -e most commonly used are sigmoid and tanh: sigmoid function f(x) \ufffd 1/1 + e\u2212 x [29] and tanh function h(t) with range (\u20131, 1) [28]. In the output layer, the softmax function is used y(t) \ufffd g(Vh(t)), where f(x) \ufffd eVih(t)/nj e\nVjh(t) for the final output [28, 29]. -e architecture of RNN is explained in Figure 2.\n-e proposed hybrid approach and individual CNN and RNN are applied to diagnose depression while speaking\nArabic. -e training-testing criteria are adopted in the analysis for 200 speeches. A total of 70% (140 speeches) of data are used as a training part, and 30% (60 speeches) of data are used as a testing part. -e train data is used to train the CNN+SVM, RNN, and CNN, and test data is used to check the validity of all models and the prediction rate of the trained sample. -e accuracy, area under curve (AUC), sensitivity, specificity, false-positive rate (FPR), and falsenegative rate (FNR) are calculated to observe the model\u2019s performance in depth using the following equations.\nAccuracy \ufffd TP + TN\nTP + FP + FN + TN ,\nAUC \ufffd TPRate d(FPRate),\nSensitivity \ufffd TP\nTP + FN ,\nSpecificity \ufffd TN\nTN + FP ,\nFNR \ufffd FN\nTPe + FN ,\nFPR \ufffd FP\nFP + TN .\n(1)\nTable 1: Architecture of proposed hybrid model."
        },
        {
            "heading": "CNN+ SVM",
            "text": "Layers Results Parameters Conv1D1 (Nil, 202, 32) 128 Max pool 1 (Nil, 101, 32) 0 Conv1D2 (Nil, 101, 64) 6,208 Max pool 2 (Nil, 50, 64) 0 Conv1D3 (Nil, 50, 64) 12,352 Max pool 3 (Nil, 25, 64) 0 Dropout (Nil, 25, 64) 0 Flatten (Nil, 1,600) 0 Dense 1 (Nil, 128) 204,928 Used for SVM Dense 2 (Nil, 1) 129 Total params: 223,745 Trainable params: 223,745\nRE TR AC\nTE\nDwhere FP stands for false positive, TN for true negative, TPfor true positive, and TN for true negative.-e Receiver Operating Characteristic (ROC) curve is also drawn to check the model accuracy by plotting the sensitivity and specificity [31]."
        },
        {
            "heading": "3. Experimental Results and Performance Analysis",
            "text": "Using Arabic speech analysis, the study predicts depression disorder and compares it with DL models such as RNN and CNN. Out of 100% of the data, 70% of data are used for training and 30% for testing stages. 3.1.DataDescription. In this study, we used the Basic Arabic Vocal Emotions Dataset (BAVED), composed of Arabic words spelt in different levels of emotions recorded in an audio format https://www.kaggle.com/a13x10/basic-arabicvocal-emotions-dataset. In experiments, we included seven words, 0 for \u201clike,\u201d 1 for \u201cunlike,\u201d 2 for \u201cthis,\u201d 3 for \u201cfile,\u201d 4 for \u201cgood,\u201d 5 for \u201cneutral\u201d and 6 for \u201cbad.\u201d -e seven words are further classified according to their emotional intensity: 0 denotes low emotion including tired or weary, 1 denotes neutral emotion, and 2 denotes strong emotion of happiness, joy, sadness, and anger.-e categories labelled as 0 and 1 are for low and neutral emotions that represent nondepression (sadness) and negative emotions (anger). 3.2. Hybrid Model Performance. First, we applied the proposed hybrid model to the data. As a result, we attained a 90% accuracy rate to classify the depression while speaking in the training part and a 91.60% accuracy rate to predict the depression from the testing part. -e graphical representation of the accuracy of the CNN+SVM model with a bar chart on train and test data is presented in Figure 3. -e red color presents the accuracy of the training data and the blue color presents the accuracy of testing data.\nCorrectly classifying the depression speeches present in diagonal and off-diagonal values shows incorrect speech prediction.-e hybrid model has accurately predicted a total of 126 (depression\ufffd 68, nondepression\ufffd 58) speeches and 14 speeches incorrectly predicted for the training data set. Similarly, the RNN model has accurately predicted 55 (depression\ufffd 31, nondepression\ufffd 24) speeches and 5 speeches not correctly predicted for the test data set. Figure 4 presents confusion matrix results of the hybrid model on train and test data.\n3.3. Individual RNN and CNN Models Performance. RNN and CNN individually applied the data where the RNN achieved an 80.70% accuracy rate to predict the depression while speaking in the training part and got an 81.60% accuracy rate for the testing part. Similarly, CNN attained an 88.5% accuracy rate to predict the depression while speaking in the training part and attained an 86.60% accuracy rate for the testing part. -e accuracies attained in the training and testing stages of RNN and CNNmodels are exhibited in Figure 5.-e red color presents the accuracy of the training data and the blue color presents the accuracy of testing data.\n-e training and testing loss and accuracy are measured for RNN and CNN models are plotted against the 25 epochs shown in Figure 6 -e blue and red solid lines represent the accuracies of the RNN and CNN model for train and test data. -e dotted blue and red solid lines present the losses of the RNN and CNN model with respect to training and testing data. It is observed that initially, network loss is higher but as epochs increase, the loss shows a decreasing trend in all models [32].\n-e results of RNN and CNNmodels with respect to the confusion matrix on train and test data are presented in Figure 7. -e correctly classified depressed speeches are presented in diagonal and off-diagonal values presented as the incorrect classified prediction speech. -e RNN model has accurately predicted a total of 113 (depression\ufffd 69, nondepression\ufffd 44) speeches and 27 speeches incorrectly predicted for the training data set. Likewise, the RNN model has predicted a total of 49 (depression\ufffd 31, nondepression\ufffd 18) speeches accurately and 11 speeches incorrectly predicted for the testing data set. On the other hand, the CNN model has predicted a total of 124 (depression\ufffd 66, nondepression\ufffd 58) speeches accurately and 16 speeches incorrectly on the train data set. Correspondingly, the CNN model has predicted a total of 52 (depression\ufffd 29, nondepression\ufffd 23) speeches accurately and 8 speeches incorrectly on the test data set.\nTRAINING DATA\nTESTING DATA\n80.70%\n81.60%\nPROPOSED HYBRID MODEL ACCURACY\nFigure 3: Hybrid model accuracy on training and testing data.\nRE TR\nAC TE"
        },
        {
            "heading": "4. Comparisons of ProposedHybridModel with RNN and CNN",
            "text": "4.1. Sensitivity Analysis. -e assessment of the models is checked with sensitivity, specificity, FPR, and FNR for both train and test data given in Table 2 Sensitivity and specificity represent a model that correctly identifies depression and nondepression speech if it belongs to depression and nondepression speeches. -e FPR and FNR are probabilities showing that a model predicts depression but it belongs to nondepression and predicts nondepression while it belongs to depression [33]. For the training data set, the RNNmodel achieved the 100%, 61.9%, 0.0, and 0.380 of sensitivity, specificity, FPR, and FNR, respectively. Similarly, for the testing data set, 100%, 62%, 0.0, and 0.379 of sensitivity, specificity, FPR, and FNR, respectively. -e CNN model achieved the 95.6%, 81.6%, 0.043, and 0.183 of sensitivity, specificity, FPR, and FNR, respectively, for the training data set. Similarly, 93.5%, 79.3%, 0.064, and 0.206 of sensitivity, specificity, FPR, and FNR, respectively, were attained for the testing data set. -e proposed hybrid model achieved the 98.5%, 81.6%, 0.014, and 0.181 of sensitivity, specificity, FPR, and FNR, respectively, for the training data set. Similarly, for testing the data set, 100%, 82.7%, 0.0, and 0.172 of sensitivity, specificity, FPR, and FNR, respectively, were attained. -e performance also measured by calculating precision, recall, and F1-score. -e hybrid model achieved high precision, recall, and F1-score than individually RNN and CNN. -e\nprecision, recall, and F1-score values of the proposed hybrid model were 0.983, 0.816, and 0.892 for training data, respectively. Similarly, 1, 0.827, and 0.905 values were achieved for precision, recall, and F1-score, respectively, for testing data for the proposed hybrid model as presented in Table 3.\n4.2. ROC Curve Analysis. -e ROC curve is used to plot the sensitivity and specificity of training and testing data. -e ROC curve values 0.70\u20130.80, >0.80 and >0.90 are acceptable, excellent and rarely observed [34]. -e ROC with AUC of the RNN, CNN, and CNN+SVM model based on speech analysis is shown in Figure 8.\n-e hybrid approach provided the minimum FPR, FNR, and a higher sensitivity and specificity rate than the RNN and CNN model to predict the depression in the Arabic language.\n4.3. Discussion and Comparisons. -e study is designed to predict depression using speech or while speaking in the Arabic language with the proposed hybrid approach and compare it with deep learning (DL)models such as RNN and CNN. All approaches are used to diagnose depression while speaking in the Arabic language. -e training-testing approach is adopted in our analysis. A total of 70% of data are used as the training part, and 30% of data are used as the testing part. -e CNN+SVM is 90.0% and 91.60% that correctly predict the depression while speaking in the training and testing. Overall, the hybrid approach (CNN+ SVM) provided better results than RNN and CNN in the same data set. -e CNN+SVM provides better results or accuracy than the individual approach in speech data [35]. -e RNN has 80.70% and 81.60% that correctly predict depression while speaking in training and testing. Comparably, the CNN has 88.50% and 86.60% that correctly predict depression while speaking in training and testing stages. While the proposed hybrid model predicted 126 speeches correctly and 14 speeches incorrectly for the training data set. Also, it has predicted 55 speeches correctly and 5 speeches not correctly for the testing data set. -e RNN model mispredicted 113 speeches correctly and 27 for the training data set. Similarly, the testing data set has predicted 49 speeches correctly and 11 incorrectly.-e CNN model mispredicted 124 speeches correctly and 16 for the\nRE\nTR AC TE\nD\ntraining data set. -e testing data set has predicted 52 speeches correctly and 8 incorrectly.-e CNN+SVMmodel achieved the 98.5%, 81.6%, 0.014, and 0.181 of sensitivity, specificity, FPR, and FNR, respectively, for the training data set. Similarly, for testing the data set, it achieved the 100%, 82.7%, 0.0, and 0.172 of sensitivity, specificity, FPR, and FNR, respectively. For the training data set, the RNN model achieved the 100%, 61.9%, 0.0, and 0.380 of sensitivity, specificity, FPR, and FNR, respectively. Correspondingly, for the testing data set, it achieved the 100%, 62%, 0.0, and 0.379 of sensitivity, specificity, FPR, and FNR, respectively. -e CNN model achieved the 95.6%, 81.6%, 0.043, and 0.183 of sensitivity, specificity, FPR, and FNR, respectively, for the training data set, while 93.5%, 79.3%, 0.064, and 0.206 of sensitivity, specificity, FPR, and FNR, respectively, for\ntesting data set. Sometimes, testing accuracy is found high than training data, but themodel will consider as generalized fine. -e precision, recall, and F1-score values of the proposed hybrid model were 0.983, 0.816, and 0.892 for training data, respectively. Similarly, 1, 0.827, and 0.905 values were got for precision, recall, and F1-score, respectively, for testing data for the proposed hybrid model.\n-e AUC value of the RNN model is found 0.81 on train and test data. Additionally, the AUC value of the CNN model is found 0.89 and 0.86 on train and test data. Comparably, the AUC value of the hybrid model is found 0.90 and 0.91 on train and test data. Based on all criteria, the hybrid model correctly identifies the depression while speaking than RNN and CNN model individually. In addition, the hybrid approach provided the minimum FPR, FNR, and higher sensitivity specificity rate than the RNN and CNN model to predict depression in the Arabic speech."
        },
        {
            "heading": "5. Conclusion",
            "text": "-is paper has presented a hybrid model to classify depression for mental illness prediction from Arabic speech analysis. Additionally, for the same task, two deep learning models RNN and CNN are also applied individually on the same benchmark database to analyze and compare the results using standard training-testing criteria. -e proposed hybrid model attained 90.0% and 91.60% correctly predicted depression while speaking on train and test data.-e RNN is 80.70% and 81.60% correctly predicted depression while speaking in training and testing, respectively. -e CNN has 88.50% and 86.60% that correctly predict depression while speaking in training and testing. Overall, the hybrid approach provided better results than RNN and CNN on the same benchmark database.\nMoreover, the hybrid approach came out with minimum FPR and FNR. It provided a higher sensitivity and specificity rate than the RNN and CNN model to predict depression in the Arabic language. -ese research findings will be helpful to detect depression while speaking or in Arabic speech. -erefore, doctors, psychiatrists, or psychologists can use our approaches in healthcare applications to see depression while speaking. -e doctors could also utilize the proposed approach to identify or separate the depression from neutral or normal speaking. Using our model researcher will detect depression while speaking the Arabic language with an approximately 92% accuracy rate. -e proposed model could be used as a tool in the voice recognition field to detect depression while speaking the Arabic language. Depressed\nTable 2: Performance comparisons of hybrid model with RNN and CNN.\nAccuracy (%) AUC Sensitivity (%) Specificity (%) FPR FNR\nTraining RNN 80.70 0.81 100 61.9 0.0 0.380 CNN 88.50 0.89 95.6 816 0.043 0.183\nCNN+ SVM 90 0.90 98.5 81.6 0.014 0.183\nTesting RNN 81.60 0.81 100 62 0.0 0.379 CNN 86.60 0.86 93.5 79.3 0.064 0.206\nCNN+ SVM 91.60 0.91 100 82.7 0.0 0.172\nTable 3: Performance measured with precision, recall, and f1score.\nPrecision Recall F1-score\nTraining RNN 1 0.619718 0.765217 CNN 0.95082 0.816901 0.878788\nCNN+SVM 0.983051 0.816901 0.892308\nTesting RNN 1 0.62069 0.765957 CNN 0.92 0.793103 0.851852\nCNN+SVM 1 0.827586 0.90566\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nse ns\niti vi\nty\n0.80.4 0.60.2 1.00.0 1 - specificity\nRNN AUC of Training data = 0.81 RNN AUC of Testing data = 0.81 CNN AUC of Training data = 0.89 CNN AUC of Testing data = 0.86 CNN+SVM AUC of Training data = 0.90 CNN+SVM AUC of Testing data = 0.91\nFigure 8:-e ROCwith AUC of the RNN, CNN, and hybridmodel based on Arabic speech analysis.\nRE TR AC TE D\npersons will refer to psychiatrist for their therapies and their treatments."
        },
        {
            "heading": "Data Availability",
            "text": "-e open-access data set employed for experiments is detailed below Basic Arabic Vocal Emotions Dataset (BAVED), composed of Arabic words spelt in different levels of emotions recorded in an audio format https://www. kaggle.com/a13x10/basic-arabic-vocal-emotions-dataset. -e data were selected from the data source available online. However, its size was not significant enough. In the future, we will use a huge data size taken from different races (depression speeches and nondepression speeches) for the classification/identification of depression while speaking in different languages using the proposed method."
        },
        {
            "heading": "Conflicts of Interest",
            "text": "-e authors declare that there are no conflicts of interest for this research."
        },
        {
            "heading": "Authors\u2019 Contributions",
            "text": "All authors contributed equally scientifically."
        },
        {
            "heading": "Acknowledgments",
            "text": "-is research was supported by Artificial Intelligence and Data Analytics Lab (AIDA), CCIS, Prince Sultan University, Riyadh, Saudi Arabia. -e authors also would like to acknowledge the support of Prince Sultan University for paying the APC of this publication."
        }
    ],
    "title": "Retraction Retracted: Arabic Speech Analysis for Classification and Prediction of Mental Illness due to Depression Using Deep Learning",
    "year": 2023
}