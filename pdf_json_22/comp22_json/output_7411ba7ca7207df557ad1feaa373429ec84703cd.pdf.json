{
    "abstractText": "Unbounded SubsetSum is a classical textbook problem: given integers w1, w2, \u00b7 \u00b7 \u00b7 , wn \u2208 [1, u], c, u, we need to find if there exists m1,m2, \u00b7 \u00b7 \u00b7 ,mn \u2208 N satisfying c = \u2211 n i=1 wimi. In its all-target version, t \u2208 Z+ is given and answer for all integers c \u2208 [0, t] is required. In this paper, we study three generalizations of this simple problem: All-Target Unbounded Knapsack, All-Target CoinChange and Residue Table. By new combinatorial insights into the structures of solutions, we present a novel two-phase approach for such problems. As a result, we present the first near-linear algorithms for CoinChange and Residue Table, which runs in \u00d5(u+ t) and \u00d5(u) time deterministically. We also show if we can compute (min,+) convolution for n-length arrays in T (n) time, then All-Target Unbounded Knapsack can be solved in \u00d5(T (u) + t) time, thus establishing sub-quadratic equivalence between All-Target Unbounded Knapsack and (min,+) convolution.",
    "authors": [
        {
            "affiliations": [],
            "name": "Mingyang Deng"
        }
    ],
    "id": "SP:ea60e06904e3fb3e71248f4a1e87f2ab2d4c589c",
    "references": [
        {
            "authors": [
                "D. Aingworth",
                "C. Chekuri",
                "R. Motwani"
            ],
            "title": "Fast estimation of diameter and shortest paths (without matrix multiplication)",
            "venue": "In Proceedings of the Seventh Annual ACMSIAM Symposium on Discrete Algorithms (Atlanta, GA,",
            "year": 1996
        },
        {
            "authors": [
                "Yonatan Aumann",
                "Moshe Lewenstein",
                "Noa Lewenstein",
                "Dekel Tsur"
            ],
            "title": "Finding witnesses by peeling",
            "venue": "ACM Trans. Algorithms,",
            "year": 2011
        },
        {
            "authors": [
                "N. Alon",
                "M. Naor"
            ],
            "title": "Derandomization, witnesses for Boolean matrix multiplication and construction of perfect hash functions",
            "year": 1996
        },
        {
            "authors": [
                "Kyriakos Axiotis",
                "Christos Tzamos"
            ],
            "title": "Capacitated dynamic programming: faster knapsack and graph algorithms. In 46th International Colloquium on Automata, Languages, and Programming, volume 132 of LIPIcs",
            "venue": "Leibniz Int. Proc. Inform., pages Art. No. 19,",
            "year": 2019
        },
        {
            "authors": [
                "Alfred Brauer",
                "James E. Shockley"
            ],
            "title": "On a problem of Frobenius",
            "venue": "J. Reine Angew. Math.,",
            "year": 1962
        },
        {
            "authors": [
                "Timothy M Chan",
                "Qizheng He"
            ],
            "title": "On the change-making problem",
            "venue": "In Symposium on Simplicity in Algorithms,",
            "year": 2020
        },
        {
            "authors": [
                "Timothy M. Chan",
                "Qizheng He"
            ],
            "title": "More on change-making and related problems",
            "venue": "J. Comput. System Sci.,",
            "year": 2021
        },
        {
            "authors": [
                "Marek Cygan",
                "Marcin Mucha",
                "Karol W\u0119grzycki",
                "Micha\u0142 W\u0142odarczyk"
            ],
            "title": "On problems equivalent to (min,+)-convolution",
            "venue": "ACM Trans. Algorithms,",
            "year": 2019
        },
        {
            "authors": [
                "Martin F\u00fcrer"
            ],
            "title": "How fast can we multiply large integers on an actual computer? In LATIN 2014: theoretical informatics, volume 8392 of Lecture Notes in Comput",
            "year": 2014
        },
        {
            "authors": [
                "Kim-Manuel Klein"
            ],
            "title": "On the fine-grained complexity of the unbounded subsetsum and the frobenius problem",
            "venue": "arXiv preprint arXiv:2108.05581,",
            "year": 2021
        },
        {
            "authors": [
                "Andrea Lincoln",
                "Adam Polak",
                "Virginia Vassilevska Williams"
            ],
            "title": "Monochromatic triangles, intermediate matrix products, and convolutions",
            "venue": "arXiv preprint arXiv:2009.14479,",
            "year": 2020
        },
        {
            "authors": [
                "Ryan Williams"
            ],
            "title": "Faster all-pairs shortest paths via circuit complexity",
            "venue": "Proceedings of the 2014 ACM Symposium on Theory of Computing,",
            "year": 2014
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n20 2.\n13 48\n4v 1\n[ cs\n.D S]\n\u2211 n\ni=1 wimi. In\nits all-target version, t \u2208 Z+ is given and answer for all integers c \u2208 [0, t] is required. In this paper, we study three generalizations of this simple problem: All-Target Unbounded Knapsack, All-Target CoinChange and Residue Table. By new combinatorial insights into the structures of solutions, we present a novel two-phase approach for such problems. As a result, we present the first near-linear algorithms for CoinChange and Residue Table, which runs in O\u0303(u+ t) and O\u0303(u) time deterministically. We also show if we can compute (min,+) convolution for n-length arrays in T (n) time, then All-Target Unbounded Knapsack can be solved in O\u0303(T (u) + t) time, thus establishing sub-quadratic equivalence between All-Target Unbounded Knapsack and (min,+) convolution."
        },
        {
            "heading": "1 Introduction",
            "text": ""
        },
        {
            "heading": "1.1 Background",
            "text": "Consider the following problem, All-Target Unbounded SubsetSum. Given w1, w2, \u00b7 \u00b7 \u00b7 , wn, t \u2208 Z+, for each c \u2208 [0, t] we want to find if there are some w\u2019s with sum t, where every w could be used multiple times. More formally, we want to find if there exists m1,m2, \u00b7 \u00b7 \u00b7 ,mn \u2208 N satisfying c = \u2211n i=1wimi, for each c \u2208 [0, t]. We call a c for which such a m exists feasible and non-feasible otherwise. While this problem is relatively simple and could be easily solved in O\u0303(n+ t)1 time by repeated convolutions, many of its generalizations are not well-understood. In this paper, we address three related problems that have been studied separately, All-Target Unbounded Knapsack, All-Target CoinChange and Residue Table.\nIn All-Target CoinChange, for each c one needs to find the minimum possible \u2211n\ni=1mi while satisfying c = \u2211n i=1 wimi. Intuitively, w\u2019s are the possible values of the coins and the cashier needs\n1 O\u0303 hides polylogarithmic factors.\nto find the minimum number of coins with values summing up to c. In All-Target Unbounded Knapsack, each wi is associated with an integer pi, and one needs to find the maximum possible\u2211n\ni=1 pimi while satisfying c = \u2211n\ni=1 wimi. Considering (wi, pi) as a type of item with weight wi and profit pi, we are trying to find the maximum profit for items with total weight c. In their corresponding Single-Target version, only answer for one target c = t is required.\nCoinChange and Unbounded Knapsack are two textbook problems for dynamic programming. While Single-Target CoinChange can be solved in O\u0303(t) time with convolution and repeated squaring [CH20], the best known algorithm for All-Target CoinChange has long been a O\u0303(t3/2)-time algorithm [LPW20], until the recent improvement to O\u0303(t4/3) by Chan and He [CH22]. They also presented a O(u2 log(u) + t) time algorithm, which is more efficient when u\u226a t.\nOn Unbounded Knapsack, Cygan et al. [CMWW19] showed a sub-quadratic algorithm (O(t2\u2212\u03b5) for some \u03b5 > 0) for Single-Target Unbounded Knapsack would imply a sub-quadratic algorithm for (min,+) convolution. Axiotis and Tzamos [AT19] showed if n-length (min,+) convolution can be solved in T (n) time, then Single-Target Unbounded Knapsack can be solved in O(T (u) poly log(t)) time, thereby establishing a sub-quadratic equivalence between Single-Target Unbounded Knapsack and (min,+) convolution. However, their method does not apply for the All-Target version. Chan and He [CH22] recently presented a O(u2 log u+ t)-time algorithm for All-Target Unbounded Knapsack.\nIn Residue Table, for each t \u2208 [0, w1), we need to find the smallest \u2211n\ni=1wici among all c1, c2, \u00b7 \u00b7 \u00b7 , cn \u2208 N satisfying t \u2261 \u2211n i=1wici (mod w1). That is, we need to compute the smallest feasible sum with remainder t modulo w1. Residue Table is first introduced by Brauer and Shockley [BS62] to tackle the Frobenius problem. This table would allow one to check in O(1) time if a sum is feasible for Unbounded SubsetSum, by comparing it with the minimum feasible sum with the same remainder modulo w1, since we can always add more w1\u2019s to a feasible sum to get another feasible sum. Klein [Kle21] presented an algorithm computing the table in O\u0303(u3/2) time."
        },
        {
            "heading": "1.2 Main results",
            "text": "In this paper, we present new insights on structures of solutions to these two problems. Crucial to our observations is focusing only on optimal-valued solutions with minimal lexical order and the optimal substructure property of these solutions. The optimal substructure property of the solutions enables us to \u201cpeel\u201d solutions, removing duplicated items to arrive at solutions without duplicated items, which we call kernels. From kernels, we can \u201cpropagate\u201d backwards, adding duplicated items for item types in kernels, to get optimal solutions. Therefore, we can tackle these problems with a two-phase approach: compute the solutions for the kernels and propagate.\nWith this approach, we arrive at new results for the three problems:\nAll-Target Unbounded Knapsack (Theorem 5.2) Let T (n) be the time required for n-length (min,+) convolution, All-Target Unbounded Knapsack can be solved in O\u0303(T (u) + t) time.\nAll-Target CoinChange (Theorem 5.9) All-Target CoinChange can be solved in O\u0303(u+t) time.\nResidue Table (Theorem 5.10) Residue Table can be computed in O\u0303(u) time.\nOur algorithms are relatively simple and practical. Notice that if we can solve All-Target Unbounded Knapsack in T (u + t) time, we can compute (min,+) convolution for n-length arrays in\nO(T (n)) time: to compute (min,+) convolution of a1, a2, \u00b7 \u00b7 \u00b7 , an and b1, b2, \u00b7 \u00b7 \u00b7 , bn, let x be a sufficiently large integer, create items (4n + i, ai + x) and (2n + i, bi) for every i and run All-Target Unbounded Knapsack. The optimal value for 6n + s will be value at position s in the convolution result plus x. Therefore our purposed results are all optimal, up to log factors."
        },
        {
            "heading": "1.3 Technical overview",
            "text": "Structural property under lexical Order Our algorithm sprouts from the recent observation made by Klein [Kle21] which implies that for unbounded knapsack, it suffices to not use too many types of items. Specifically, if we fix an arbitrarily chosen lexical order, then the lexicographically smallest optimal solution sol(j) for each feasible target sum j \u2208 [1, t] has a support of logarithmic size (i.e. |supp(sol(j))| = O(log t)). Since CoinChange can be viewed as a special case of unbounded knapsack, this structural property also applies.\nWitness propagation using the optimal substructure property The most essential technique in our paper is \u201cwitness propagation.\u201d It exploits the following optimal substructure property for lexicographically smallest optimal solutions: for any target j, and for any \u201cwitness\u201d x \u2208 supp(sol(\u03c4)), sol(j\u2212wx) is equal to sol(j) with the multiplicity of x decreased by 1. Suppose that we can somehow compute sol(j) for every feasible target j \u2208 [1, t] whose optimal solution is of logarithmic size (i.e. |sol(j)| = O(log u)), defined as a \u201ckernel,\u201d then since the total number of \u201cwitnesses\u201d is logarithmic, we can propagate the solutions forward by enumerating witnesses and finds the optimal solution for all other feasible targets in [1, t]. This witness propagation runs in O\u0303(t) time.\nMin-witness with arbitrary lexical order For unbounded knapsack, since the kernels are in [1, O(u log u)], the optimal solutions for kernels can be computed in O(T (O(u log u)) log u) = O(u2/2\u2126( \u221a log u)) time by repeating (min,+) convolution on this interval for O(log u) times. For CoinChange, although it is easy to compute the size of the optimal solutions for kernels in O\u0303(u) time using FFT, it is not easy to find the lexicographically smallest optimal solutions as they seem to require finding \u201cminimum witnesses\u201d for convolution, for which currently the best algorithm only runs in O\u0303(u1.5) time (e.g. [LP18]). However, since the lexical order can be arbitrary, we can overcome this barrier by picking certain orders. We purpose two different approaches of independent interest. First, we first show minimum witness is easy to compute under a random order. Also, we provide a deterministic construction which computes \u03c3 and minimum witnesses alongside in similar spirit."
        },
        {
            "heading": "2 Preliminaries",
            "text": "We first formally define the three problems. For a set of integers w1, w2, \u00b7 \u00b7 \u00b7 , wn, we call a sum c feasible if c = \u2211n i=1 wimi where mi \u2208 N. We call such (m1,m2, \u00b7 \u00b7 \u00b7 ,mn) a solution to sum c. The support of m is defined to be supp(m) = {j | mj > 0}. The size of m is defined to be |m| = \u2211n i=1mi.\nAll-Target Unbounded Knapsack Input: n, u \u2208 Z+, w1, w2, \u00b7 \u00b7 \u00b7 , wn \u2208 [1, u] \u2229 Z, p1, p2, \u00b7 \u00b7 \u00b7 , pn \u2208 Z Task: Define value of solution val(m) = \u2211n i=1 pimi. For each integer c \u2208 [1, t], output maximum possible value of a solution to sum c, or \u2212\u221e if not feasible.\nNotice that in our definition we require sum of weights to be exactly c instead of not exceeding c in some other definitions.\nAll-Target CoinChange Input: n, u \u2208 Z+, w1, w2, \u00b7 \u00b7 \u00b7 , wn \u2208 [1, u] \u2229 Z Task: Define value of solution val(m) = \u2212\u2211ni=1mi. For each integer c \u2208 [1, t], output maximum possible value of a solution to sum c, or \u2212\u221e if not feasible.\nWith this set of notation, it\u2019s clear that All-Target CoinChange is a special case of All-Target Unbounded Knapsack.\nResidue Table Input: u \u2208 Z+, w1, w2, \u00b7 \u00b7 \u00b7 , wn \u2208 [1, u] \u2229 Z Task: For each integer c \u2208 [0, w1 \u2212 1], output minimum feasible s \u2265 0 where s \u2261 c (mod w1).\nWe call a solution for All-Target Unbounded Knapsack and All-Target CoinChange optimal iff it is of maximal possible value for the same sum. We consider any solution of Residue Table optimal.\nA lexical order \u03c3 = (\u03c31, \u03c32, \u00b7 \u00b7 \u00b7 , \u03c3n) is a permutation of [1, n] denoting an order between the items. Items that appear earlier in \u03c3 are lexicographically smaller. Solution A = (a1, a2, \u00b7 \u00b7 \u00b7 an) is lexicalgraphically smaller than B = (b1, b2, \u00b7 \u00b7 \u00b7 , bn) if there exists a j \u2208 [1, n] such that for all k < j, a\u03c3k = b\u03c3k and a\u03c3j > b\u03c3j . We denote this by A < B.\nThe lexicographicall smallest optimal solution for sum j under \u03c3 is denoted by sol(j, \u03c3), and sol(j, \u03c3) = \u2205 for unfeasible j\u2019s. A feasible target j \u2208 [0, u] is called an x-kernel under \u03c3 if |sol(j, \u03c3)| \u2264 x. Let solm(u, \u03c3) be sol(j, \u03c3) for the minimum feasible j with remainder u modulo w1, or \u2205 if such j does not exist.\nDue to the additive nature, our problem is closely related to convolutions. We define boolean convolutions and (min,+) convolutions.\nDefinition 2.1 (boolean convolution). Define arrays of {0, 1} boolean arrays. Given two boolean arrays a[0 \u00b7 \u00b7 \u00b7 n] and b[0 \u00b7 \u00b7 \u00b7m], define their boolean convolution as c[0 \u00b7 \u00b7 \u00b7 n + m] where c[i] = \u2228j+k=i(a[j] \u2227 b[k]).\nBoolean convolution can be computed in O((n+m) log(n+m)) time by regular convolution via Fast Fourier Transform (e.g. [F1\u03084]).\nDefinition 2.2 ((min,+) convolution). Given two arrays, a[0 \u00b7 \u00b7 \u00b7 n] and b[0 \u00b7 \u00b7 \u00b7m], define their convolution as c[0 \u00b7 \u00b7 \u00b7 n+m] where c[i] = minj+k=i(a[j] + b[k]). Lemma 2.3 ([Wil14]). (min,+) convolution be computed in O((n +m)2/2\u2126( \u221a log(n+m))) time."
        },
        {
            "heading": "3 Combinatorial Properties",
            "text": "We start by introducing Lemma 1 in [Kle21], which implies solutions have logarithmic sized-support in Unbounded SubsetSum.\nLemma 3.1 (Lemma 1 in [Kle21]). For Unbounded SubsetSum, for any lexical order \u03c3 and any feasible target j, let x = sol(j, \u03c3) be the lexicographically smallest solution for j under \u03c3, then\u220f\ni 6=\u03c31 (xi + 1) \u2264 w\u03c31 \u2264 u.\nCorollary 3.2. For Unbounded SubsetSum, for any lexical order \u03c3 and any feasible target j, |supp(sol(j, \u03c3))| \u2264 log2 u + 1. Thus for residue table, the support sizes of the solutions are also \u2264 log2 u+ 1. Proof. Let x = sol(j, \u03c3), by Lemma 3.1 2|supp(x)|\u22121 \u2264 \u220fi 6=\u03c31 (xi + 1) \u2264 j + 1, so |supp(x)| \u2264 log2 u+ 1.\nWe can extend the lemma to the valued version with a similar adjusting argument.\nLemma 3.3. For Unbounded Knapsack, for any lexical order \u03c3 and any feasible target j, let x = sol(j, \u03c3), then \u220fn i=1 (xi + 1) \u2264 u+ 1.\nProof. Suppose otherwise, consider all integer sequences (y1, y2, \u00b7 \u00b7 \u00b7 , yn) so that yi \u2208 [0, xi]. Notice 0 \u2264 \u2211ni=1 yiwi \u2264 \u2211n i=1 xiwi = j and the number of y\u2019s is \u220fn i=1 (xi + 1) > j + 1, by pigeonhole\nprinciple there is y 6= y\u2032 so that \u2211ni=1 yiwi = \u2211n i=1 y \u2032 iwi. j = \u2211n i=1(xi\u2212 yi+ y\u2032i)wi = \u2211n i=1(xi+ yi\u2212\ny\u2032i)wi. If \u2211n i=1 yipi 6= \u2211n i=1 y \u2032 ipi, one of {xi\u2212yi+y\u2032i}i and {xi+yi\u2212y\u2032i}i is a solution for j with larger value. Otherwise, both of them have value equal to x\u2019s, and one of them will be lexicographically smaller than x. In both cases we get a contradiction with optimality of x.\nCorollary 3.4. For Unbounded Knapsack and CoinChange, for any lexical order \u03c3 and any feasible target j, |supp(sol(j, \u03c3))| \u2264 log2(j + 1). Proof. Let x = sol(j, \u03c3), by Lemma 3.3 2|supp(x)| \u2264 \u220fni=1 (xi + 1) \u2264 j + 1, so |supp(x)| \u2264 log2(j + 1).\nCorollary 3.4 only implies O(log(t))-size supports instead of O(log(u)) as in Corollary 3.2, but we can use the following lemma.\nLemma 3.5 (Lemma 4.1 in [CH22]2). Let s be any type with maximum value/weight ratio, for any feasible target j > u2, j\u2212 s must also be feasible, and an optimal solution for j might be found by adding an item of type s to any optimal solution for j \u2212 s. Thus if t > u2, we can first compute optimal solutions for [0, u2], and then for each j \u2208 (u2, t], simply add item s to a solution for j \u2212 s to get a solution for j.\nBy investigating further into these lexicographically minimal solutions, we can find the following structural property between solutions, optimal substructure property.\nLemma 3.6 (optimal substructure property). For any lexical order \u03c3, a feasible target j \u2208 [1, t] and a \u201cwitness\u201d x \u2208 supp(sol(j, \u03c3)), let sol(j, \u03c3) = (u1, u2, \u00b7 \u00b7 \u00b7 , un). Define (v1, v2, \u00b7 \u00b7 \u00b7 , vn) as follows:\nvk = { uk if k 6= w uk \u2212 1 if k = w .\nwe have sol(j \u2212 wx, \u03c3) = v. 2The original proof is for unweighted case, but it can be easily modified to prove the weighted case.\nProof. Firstly, we prove val(sol(j \u2212 wx, \u03c3)) = val(v) by showing that neither val(sol(j \u2212 wx, \u03c3)) < val(v) nor val(v) < val(sol(j \u2212 wx, \u03c3)) can hold. If val(sol(j \u2212 wx, \u03c3)) < val(v), then adding item x to sol(j \u2212 wx, \u03c3) gives a better solution for j, which is impossible. If val(v) < val(sol(j \u2212 wx, \u03c3), then removing x from sol(j, \u03c3) gives a better solution for j \u2212 wx, which is impossible.\nWe then argue that neither sol(j\u2212wx, \u03c3) < v nor v < sol(j\u2212wx, \u03c3) can hold. If sol(j\u2212wx, \u03c3) < v, then adding item x to sol(j \u2212 wx, \u03c3) gives a lexicographically smaller solution for j with the same value, which is impossible. If v < sol(j \u2212 wx, \u03c3), then removing x from sol(j, \u03c3) gives a lexicographically smaller solution for j \u2212 wx with the same value, which is impossible.\nWe also have the following modular analog, which can be proved similarly.\nLemma 3.7 (optimal substructure property, modular). For any lexical order \u03c3, . For any j and a \u201cwitness\u201d x \u2208 supp(solm(j, \u03c3)), let solm(j, \u03c3) = (u1, u2, \u00b7 \u00b7 \u00b7 , un). Define (v1, v2, \u00b7 \u00b7 \u00b7 , vn) as follows:\nvk = { uk if k 6= w uk \u2212 1 if k = w .\nwe have solm((j \u2212 wx) mod w1, \u03c3) = v."
        },
        {
            "heading": "4 Witness Propagation",
            "text": "With the help of optimal substructure property, we introduce the idea of witness propagation. By Corollary 3.2 or 3.4, we have support of the solutions are logarithmic-sized. Let k be an upper bound of the size of supports. Suppose we have an array of solutions sol[0, \u00b7 \u00b7 \u00b7 , t] where sol[j] = sol(j, \u03c3) for all k-kernel j and sol[j] is a valid solution or \u2205 for other j\u2019s. The idea is to gradually propagate from existing solutions, each time adding one more item in some existing solution. By the optimal substructure property, every optimal solution can be thus found from kernel formed by its support. We give the following algorithm 1.\nAlgorithm 1 Witness propogation\n1: procedure Propagation 2: for j \u2208 [1, t] do 3: if sol[j] 6= \u2205 then 4: for x \u2208 supp(sol[j]) do 5: s\u2190 sol[j] 6: sx \u2190 sx + 1 7: if (sol[j + x] = \u2205) OR (val(s) > val(sol[j + x])) OR ((val(s) = val(sol[j + x])) AND (s < sol[j + x])) then 8: sol[j + x]\u2190 s 9: end if\n10: end for 11: end if 12: end for 13: end procedure\nLemma 4.1. Given sol[j] = sol(j, \u03c3) for all k-kernels j where k is an upper bound of support sizes, algorithm 1 decides whether each j \u2208 [1, t] is feasible, and correctly computes an optimal solution for every feasible j.\nProof. It suffices to show that for each feasible j\u2032, sol[j\u2032] = sol(j\u2032, \u03c3) is once examined on line 8. We prove by induction on |sol(j\u2032, \u03c3)|. Firstly, we have assumed that sol[j\u2032] = sol(j\u2032, \u03c3) for all j\u2032 where |sol(j\u2032, \u03c3)| \u2264 2 log2(u) + 1, which are the (2 log2(u) + 1)-kernels. Suppose |sol(j\u2032, \u03c3)| > 2 log2(u) + 1. From Lemma 3.3 we know supp(sol(j\u2032, \u03c3)) \u2264 log2(j + 1) \u2264 2 log2(u)+1, so there exists an x \u2032 \u2208 supp(sol(j\u2032, \u03c3)) with multiplicity at least 2, then from Lemma 3.6 we know that x\u2032 \u2208 supp(sol(j\u2032\u2212wx, \u03c3)). By induction hypothesis sol[j\u2032\u2212wx] = supp(sol(j\u2032\u2212wx, \u03c3)), therefore sol(j\u2032, \u03c3) will be examined on line 8 when j = j\u2032 \u2212 wx and x = x\u2032.\nLemma 4.2. For any lexical order \u03c3, given sol(j, \u03c3) for every (2 log2 u + 1)-kernel j, All-Target Knapsack can be solved in O(t log2(u)) time.\nProof. We can compute answers for u2 + 1, u2 + 2, \u00b7 \u00b7 \u00b7 , t by Lemma 3.5, so we may assume t \u2264 u2. k = 2 log2 u+ 1 \u2265 log2(t+ 1) would be an upper bound on support sizes by Corollary 3.4.\nWe implement algorithm 1 by storing each sol as an array which size equals to its support, recording non-zero positions and corresponding values in lexical order. Comparisons can then be done in time linear to array sizes.\nSize of supports of the internal sol\u2019s should be no larger than k+1 \u2264 2 log2(u)+2 by the nature of this algorithm. For every feasible j, there are O(log(u)) witnesses x on line 2 and updating for each witness takes time O(log(u)). Therefore the total time complexity for propagation should be O(t log2(u)).\nBy modifying Algorithm 1 in a modular fashion, we can prove a similar result for Residue Table.\nLemma 4.3. For any lexical order \u03c3, given sol(j, \u03c3) for every log2(u + 1)-kernel j, residue table can be computed in O(u log2(u)) time.\nProof. We update solm[j mod w1] with all sol(j, \u03c3)\u2019s and propagate on solm similar to Algorithm 1, in a Dijkstra-like fashion. Instead of looping through j in increasing order, we iterate through j\u2019s in the order of solution sizes. We maintain a priority queue with Fibonacci heap, each time popping the entry with minimum solution size and propagating with it. When we propagate, we decrease key in the Fibonacci heap in O(1) time. The correctness can be proved by an induction on solution size."
        },
        {
            "heading": "5 Kernel Computation",
            "text": "With Lemma 4.2 and 4.3, we only need to consider the computation of O(log u)-kernels. Intuitively, we could set up an array of values for each weight and convolve it with itself O(log u) times, but while we can get an optimal-valued solution in this way, it\u2019s not necessarily of minimal lexical order. However, if we can for the convolutions, find the minimum witness with respect to the lexical order, we can compute the solutions we want. We illustrate the idea in algorithm 2 for Unbounded Knapsack. For Coinchange and Residue Table, simply modify v, f to be booleans and change (max,+) convolution to boolean convolution.\nAlgorithm 2 Kernel Computation with Minimum Witness\n1: procedure Kernel Computation(\u03c3) 2: k \u2190 \u230a2 log2(u) + 1\u230b 3: Initialize v[0, \u00b7 \u00b7 \u00b7 , ku] and f [0, \u00b7 \u00b7 \u00b7 , u] to be \u2212\u221e, sol[0, \u00b7 \u00b7 \u00b7 , ku] to be \u2205 4: v[0]\u2190 0 5: sol[0]\u2190 {} 6: for i \u2208 [1, n] do 7: f [w\u03c3i ]\u2190 p\u03c3i 8: end for 9: for j \u2208 [1, k] do\n10: Compute (max,+) convolution of v and f and store in v\u2032 11: For each v\u2032[i], find the minimum t[i] (\u201cwitness\u201d) so that f [w\u03c3t[i] ] contributed to v \u2032[i] 12: for i \u2208 [1, ku] do 13: if v\u2032[i] 6= \u2212\u221e then 14: v[i]\u2190 v\u2032[i] 15: c\u2190 \u03c3t[i] 16: s\u2190 sol[i\u2212 wc] 17: sc \u2190 sc + 1 18: sol[i]\u2190 s 19: end if 20: end for 21: end for 22: end procedure\nLemma 5.1. Algorithm 2 correctly computes sol with respect to \u03c3 for all (2 log2(u) + 1)-kernels.\nProof. Let k = \u230a2 log2(u) + 1\u230b. Clearly the k kernels are in [0, ku] since they are sum of at most k w\u2019s. We perform induction on j in the code: after running the inner loop for j times, correct sol has been computed for all j-kernels. Except 0, all j-kernel can be resulted from adding one element to a j \u2212 1-kernel, and the optimal value is computed by the convolution. To minimize the lexical order, we find the smallest possible witness, which is the smallest possible starting element (smallest j so that \u03c3j position could be non-empty). The remaining part is also minimal possible by induction hypothesis.\n5.1 Minimum Witness for (max,+) Convolution\nFor (max,+) convolution, we can find the minimum witness during the convolution by letting vw = (n+ 1)v, fw[w\u03c3i ] = (n+ 1)f [w\u03c3i ]\u2212 i, and we can tell the minimum witness by the remainder modulo n+ 1.\nTheorem 5.2. Let T (n) be the time required for n-length (min,+) convolution in T (n) time. All-Target Unbounded Knapsack can be solved in O(T (u) log3(u) + t log2(u)) time.\nProof. From Lemma 4.2 it suffices to compute sol(j, \u03c3) for all (2 log2 u + 1)-kernels. We modify algorithm 2 to compute minimum witness: let vw[i] = (n+ 1)v[i] and fw[\u03c3i] = (n+ 1)f [\u03c3i]\u2212 i and compute (max,+) convolution on vw and fw in the inner loop. v\n\u2032 and t can both be computed from the convolution result.\nThe algorithm calculates (max,+) convolution on length-O(u log(u)) arrays O(log(u)) times, taking O(T (u) log3(u)) time. Combining with Lemma 4.2, the final time complexity would be O(T (u) log3(u) + t log2(u))."
        },
        {
            "heading": "5.2 Minimum Witness for Boolean Convolution under Random Order",
            "text": "While computing minimum witness for boolean convolution is hard and the current best algorithm runs in O\u0303(u1.5) time (e.g. [LP18]), we can overcome this barrier by carefully picking \u03c3. In this subsection, we show minimum witness is likely easier for a randomly chosen \u03c3.\nTheorem 5.3 (Minimum witness finding for random permutations). Given boolean arrays a[0 \u00b7 \u00b7 \u00b7 n\u2212 1] and b[0 \u00b7 \u00b7 \u00b7m\u2212 1], and their convolution c[0 \u00b7 \u00b7 \u00b7 n +m\u2212 2]. For every index i where c[i] > 0, let x[i] = {k | a[k] = b[i\u2212 k] = 1}.\nFor a uniformly randomly chosen lexical order \u03c3 over all n! possible permutations, in expected O\u0303(n+m) time we can compute an array d[0 \u00b7 \u00b7 \u00b7 n+m\u2212 1] where for each index where c[i] > 0, d[i] is equal to the element in x[i] that is smallest under \u03c3.\nWe purpose Algorithm 3, which computes d[0 \u00b7 \u00b7 \u00b7 n+m\u2212 2] given \u03c3, a[0 \u00b7 \u00b7 \u00b7 n\u2212 1], b[0 \u00b7 \u00b7 \u00b7m\u2212 1] and c[0 \u00b7 \u00b7 \u00b7 n+m\u2212 2]. Without loss of generality we assume that n is a power of two.\nAlgorithm 3 Minimum witness finding under random order\n1: procedure MinimumWitnessFinding 2: x\u2190 [\u2205]n 3: d\u2190 [\u22121]n 4: for l = [1, 2, 4, \u00b7 \u00b7 \u00b7 n/2, n] do 5: a\u2032 \u2190 [0]n 6: for i \u2208 [0, l \u2212 1] do 7: a\u2032[\u03c3i] = a[\u03c3i] 8: end for 9: Compute the boolean convolution c\u2032 of a\u2032 and b.\n10: while there exists some j \u2208 [0, n +m\u2212 2] that c\u2032[j] > 0 and d[j] = \u22121 do 11: Uniformly sample an array of witnesses d\u2032 from a\u2032, b and c\u2032. \u22b2 Lemma 5.4 12: for j \u2208 [0, n+m\u2212 2] do 13: if c\u2032[j] > 0 AND d[j] = \u22121 then 14: x[j]\u2190 x[j] \u222a {d\u2032[j]} 15: if |x[j]| = c\u2032[j] then 16: d[j] = min\u03c3{x[j]} \u22b2 Minimum with respect to order \u03c3 17: end if 18: end if 19: end for 20: end while 21: end for 22: end procedure\nIn algorithm 3, we sample an array of witnesses with the following lemma.\nLemma 5.4 (Witness sampling for boolean convolution (e.g. [LP18])). Given two boolean arrays a[0 \u00b7 \u00b7 \u00b7 n \u2212 1] and b[0 \u00b7 \u00b7 \u00b7m \u2212 1], and their convolution c[0 \u00b7 \u00b7 \u00b7 n + m \u2212 2]. For each index i where c[i] > 0, let x[i] = {j | a[j] = b[i\u2212 j] = 1}.\nIn O((n+m) poly log (n+m)) expected time, we can compute an array d[0 \u00b7 \u00b7 \u00b7 n+m\u2212 2] such that for each i where c[i] > 0, d[i] is equal to a uniformly random element from x[i].\nTo prove the correctness of Algorithm 3, we first show the following lemma:\nLemma 5.5. For each j where c[j] > 0, with at least 1 \u2212 1/(n + m)5 probability, there exists a power of two l such that in algorithm 3, corresponding c\u2032[j] \u2208 (0, 5 log2(n+m)). Proof. Consider another way to uniformly sample \u03c3: we first partition indexes into first n/2 and the last n/2, then partition first n/2 further into two parts of n/4, and so on. After log2 n such partitions, finally we permute the indexes within each part. It\u2019s clear that each intermediate part in this process corresponds to a prefix of \u03c3 with a power of two length.\nWith this process in mind, consider the smallest intermediate part with witness, we\u2019ll have c\u2032[j] > 0 for the corresponding l and c\u2032[j] = 0 for l/2. These c\u2032[j] witnesses must all have been partitioned to indexes [l/2, l) instead of [0, l/2), and the probability that this happens is( l/2 c\u2032[j] ) / ( l c\u2032[j] ) = \u220fc\u2032[j]\u22121 i=0 l/2\u2212i l\u2212i \u2264 2\u2212c \u2032[j]. If c\u2032[j] > 5 log2(n+m), the probability is < 1/(n +m) 5.\nProof of Theorem 5.3. We show algorithm 3 suffice. For each power of two l, the algorithm samples a witness for each j, until all c\u2032[j] witnesses have been found for every j. The minimum witnesses are then computed from these witnesses and these j\u2019s are no longer considered.\nFor each l, let u = maxj{c\u2032[j]} for j\u2019s we\u2019re considering (d[j] = \u22121 in the algorithm). Clearly u \u2264 n, and by Lemma 5.5 and union bound over all j\u2019s Pr[u > 5 log2(n + m)] < 1/(n + m)4, therefore E[u] = O(log(n+m)).\nConsider some j, for every 10 log(n+m)c\u2032[j] samplings, the probability that one witness is not found is (1 \u2212 1/c\u2032[j])10 log(n+m)c\u2032[j] \u2264 e\u221210 log(n+m) = (n +m)\u221210. Therefore by union bound, after 10 log(n +m)u samplings, the probability that any of the c\u2032[j] witnesses is not found from some j is \u2264 (n+m)\u22128 < 1/2, so each 10 log(n+m)u samplings give \u2265 1/2 success rate and the expected number of samplings is \u2264 20 log(n+m)E[u] = O(log2(n +m)).\nEach of the sampling takes O\u0303(n + m) expected time by Lemma 5.4 and we need to consider log2 n l\u2019s, so the algorithm takes O\u0303(n+m) expected time.\nThis algorithm is of individual interest, and immediately gives near-optimal randomized algorithms solving All-Target Coinchange and Residue Table."
        },
        {
            "heading": "5.3 Minimum Witness for Boolean Convolution with Adaptive Ordering",
            "text": "Under a deterministic setting, we can no longer sample a random \u03c3. However, we can pick \u03c3 and compute minimum witness together, in an adaptive fashion.\nLemma 5.6. Given a[0 \u00b7 \u00b7 \u00b7 n \u2212 1] and b[0 \u00b7 \u00b7 \u00b7m \u2212 1], and their convolution c[0 \u00b7 \u00b7 \u00b7 n +m \u2212 2]. For every index i where c[i] > 0, let x[i] = {k | a[k] = b[i\u2212 k] = 1}.\nFor integer k, in deterministic O(k(n+m) poly log (n+m)) time, we can compute min(|x[i]|, k) distinct members of x[i], for each i where c[i] > 0.\nThe lemma may be proved in a similar fashion as in [AN96]. Alternatively, we can convert it into a instance of k-reconstruction problem defined in [ALLT11] and use that algorithm.\nLemma 5.7 (Deterministic hitting sets). Given sets S1, S2, \u00b7 \u00b7 \u00b7Su where for every i, Si \u2286 {1, 2, \u00b7 \u00b7 \u00b7 , n}, |Si| \u2265 R. We can compute a \u201chitting set\u201d S of size \u2264 (n/R) log(u) deterministically so that S\u2229Si 6= \u2205 for all i, in O\u0303((n+ u)R) time.\nThe lemma is a natural extension of Theorem 1 in [ACM96] (which addresses the n = u case) and can be proved in the same way.\nTheorem 5.8. Given O\u0303(1) n-length boolean convolutions, in O\u0303(n) time deterministically, we can compute a permutation \u03c3, and the minimum witness of the convolutions with respect to \u03c3.\nProof. Assuming n = 2\u03b1, we determine \u03c3 and compute minimum witnesses in the following fashion: for i from \u03b1 down to 1, determine first 2i\u22121 elements of \u03c3 out of its first 2i elements, and compute minimum witness for the results with no witness lying in the first 2i\u22121 elements.\nTo find first 2i\u22121 elements out of first 2i elements, suppose there are t result elements (elements of the convolutions results), we consider only first 2i elements and set k = 2 log(t) = O\u0303(1) in Lemma 5.6 to find at most k witnesses out of the first 2i elements for every result element.\nConsider all result elements with at least k witnesses, we have found k of these witnesses and with Lemma 5.7 we can compute a hitting set of size \u2264 2i log(t)/k = 2i\u22121. We then set the first 2i\u22121 elements to be this hitting set, then these results will all have witness in this first half. We pick any permutation for the remaining 2i\u22121 elements in \u03c3. All results with < k witnesses have all their witnesses computed, and we can compute minimum witness naively for those with no witnesses in the first half.\nAs a result, we get algorithm 4.\nAlgorithm 4 Adaptive Minimum Witness\n1: procedure AdaptiveMinimumWitness 2: Suppose we have p convolutions of length n: ci = ai \u2297 bi for i \u2208 [1, p] 3: Let l = {(i, j) | i \u2208 [1, p], j \u2208 [0, 2n \u2212 2]} 4: for m \u2208 [n, n/2, n/4, \u00b7 \u00b7 \u00b7 , 1] do 5: k = 2\u2308log(|l|)\u2309+ 5 6: For each (p, q) in l, compute a set of k different witnesses w[p][q] \u2286 \u03c3[0, \u00b7 \u00b7 \u00b7 ,m/2\u2212 1] for\nc[p][q] if possible \u22b2 Lemma 5.6 7: Find a hitting set S \u2286 \u03c3[0, \u00b7 \u00b7 \u00b7 ,m\u2212 1] of size m/2 for all w[p][q] of size \u2265 k\u22b2 Lemma 5.7 8: Permute \u03c3[0, \u00b7 \u00b7 \u00b7 ,m\u2212 1] so \u03c3[0, \u00b7 \u00b7 \u00b7 ,m/2 \u2212 1] forms S 9: for (p, q) \u2208 l do 10: if |w[p, q]| < k AND w[p, q] \u2286 \u03c3[m/2, \u00b7 \u00b7 \u00b7 ,m\u2212 1] then 11: c[p, q]\u2190 min\u03c3 w[p, q] \u22b2 Minimum with respect to order \u03c3 12: Remove (p, q) from l 13: end if 14: end for 15: end for 16: end procedure\nCombining Theorem 5.8, Lemma 5.1, 4.2 and 4.3, we arrive at near-linear solutions for All-Target CoinChange and Residue Table.\nTheorem 5.9. All-Target CoinChange can be solved in O((u+t) poly log(u)) time deterministically.\nProof. Replace witness finding in Algorithm 2 with Algorithm 4, we can compute lexicographically minimal solutions for all (2 log2 u+ 1)-kernels. We then propagate with Lemma 4.2.\nTheorem 5.10. Residue Table can be computed in O(upoly log(u)) time deterministically.\nProof. Replace witness finding in Algorithm 2 with Algorithm 4 and propagate with Lemma 4.3."
        },
        {
            "heading": "6 Conclusion",
            "text": "We presented new combinatorial insights and near-optimal algorithms to three generalizations of Unbounded SubsetSum. Our insights and techniques are of independent interest and can also apply to other generalizations for Unbounded SubsetSum."
        },
        {
            "heading": "Acknowledgment",
            "text": ""
        }
    ],
    "title": "On Problems Related to Unbounded SubsetSum: A Unified Combinatorial Approach",
    "year": 2022
}