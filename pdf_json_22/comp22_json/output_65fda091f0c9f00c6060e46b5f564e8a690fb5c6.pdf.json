{
    "abstractText": "Recent studies have shown that recommendation systems commonly suffer from popularity bias. Popularity bias refers to the problem that popular items (i.e., frequently rated items) are recommended frequently while less popular items are recommended rarely or not at all. Researchers adopted two approaches to examining popularity bias: (i) from the users\u2019 perspective, by analyzing how far a recommendation system deviates from user\u2019s expectations in receiving popular items, and (ii) by analyzing the amount of exposure that long-tail items receive, measured by overall catalog coverage and novelty. In this paper, we examine the first point of view in the book domain, although the findings may be applied to other domains as well. To this end, we analyze the well-known Book-Crossing dataset and define three user groups based on their tendency towards popular items (i.e., Niche, Diverse, Bestsellerfocused). Further, we evaluate the performance of nine state-of-the-art recommendation algorithms and two baselines (i.e., Random, MostPop) from both the accuracy (e.g., NDCG, Precision, Recall) and popularity bias perspectives. Our results indicate that most state-of-the-art recommendation algorithms suffer from popularity bias in the book domain, and fail to meet users\u2019 expectations with Niche and Diverse tastes despite having a larger profile size. Conversely, Bestseller-focused users are more likely to receive high-quality recommendations, both in terms of fairness and personalization. Furthermore, our study shows a tradeoff between personalization and unfairness of popularity bias in recommendation algorithms for users belonging to the Diverse and Bestseller groups, that is, algorithms with high capability of personalization suffer from the unfairness of popularity bias. Finally, across the models, our results show that WMF and VAECF can provide a higher quality recommendation when considering both accuracy and fairness perspectives.",
    "authors": [
        {
            "affiliations": [],
            "name": "Mohammadmehdi Naghiaei"
        },
        {
            "affiliations": [],
            "name": "Hossein A. Rahmani"
        },
        {
            "affiliations": [],
            "name": "Mahdi Dehghan"
        },
        {
            "affiliations": [],
            "name": "H. A. Rahmani"
        },
        {
            "affiliations": [],
            "name": "M. Dehghan"
        }
    ],
    "id": "SP:0a48792b2b1f2aa601902bd26cd14fcb9d0e9117",
    "references": [
        {
            "authors": [
                "H. Abdollahpouri",
                "R. Burke",
                "B. Mobasher"
            ],
            "title": "Managing popularity bias in recommender systems with personalized re-ranking",
            "venue": "The thirty-second international flairs conference",
            "year": 2019
        },
        {
            "authors": [
                "H. Abdollahpouri",
                "M. Mansoury",
                "R. Burke",
                "B. Mobasher"
            ],
            "title": "The unfairness of popularity bias in recommendation",
            "venue": "arXiv preprint arXiv:1907.13286",
            "year": 2019
        },
        {
            "authors": [
                "H. Abdollahpouri",
                "M. Mansoury",
                "R. Burke",
                "B. Mobasher",
                "E. Malthouse"
            ],
            "title": "Usercentered evaluation of popularity bias in recommender systems",
            "venue": "Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization. pp. 119\u2013129",
            "year": 2021
        },
        {
            "authors": [
                "M.M. Afsar",
                "T. Crump",
                "B. Far"
            ],
            "title": "Reinforcement learning based recommender systems: A survey",
            "venue": "arXiv preprint arXiv:2101.06286",
            "year": 2021
        },
        {
            "authors": [
                "H. Alharthi",
                "D. Inkpen",
                "S. Szpakowicz"
            ],
            "title": "A survey of book recommender systems",
            "venue": "Journal of Intelligent Information Systems 51(1), 139\u2013160",
            "year": 2018
        },
        {
            "authors": [
                "J.S. Breese",
                "D. Heckerman",
                "C. Kadie"
            ],
            "title": "Empirical analysis of predictive algorithms for collaborative filtering",
            "venue": "arXiv preprint arXiv:1301.7363",
            "year": 2013
        },
        {
            "authors": [
                "\u00d2. Celma",
                "P. Cano"
            ],
            "title": "From hits to niches? or how popular artists can bias music recommendation and discovery",
            "venue": "Proceedings of the 2nd KDD Workshop on Large-Scale Recommender Systems and the Netflix Prize Competition. pp. 1\u20138",
            "year": 2008
        },
        {
            "authors": [
                "G.L. Ciampaglia",
                "A. Nematzadeh",
                "F. Menczer",
                "A. Flammini"
            ],
            "title": "How algorithmic popularity bias hinders or promotes quality",
            "venue": "Scientific reports 8(1), 1\u20137",
            "year": 2018
        },
        {
            "authors": [
                "Y. Deldjoo",
                "A. Bellogin",
                "T. Di Noia"
            ],
            "title": "Explaining recommender systems fairness and accuracy through the lens of data characteristics",
            "venue": "Information Processing & Management 58(5), 102662",
            "year": 2021
        },
        {
            "authors": [
                "P. Gopalan",
                "J.M. Hofman",
                "D.M. Blei"
            ],
            "title": "Scalable recommendation with hierarchical poisson factorization",
            "venue": "Proceedings of the Thirty-First Conference on Uncertainty in Artificial Intelligence. pp. 326\u2013335",
            "year": 2015
        },
        {
            "authors": [
                "X. He",
                "L. Liao",
                "H. Zhang",
                "L. Nie",
                "X. Hu",
                "T.S. Chua"
            ],
            "title": "Neural collaborative filtering",
            "venue": "Proceedings of the 26th international conference on world wide web. pp. 173\u2013182. ACM, Perth, Australia",
            "year": 2017
        },
        {
            "authors": [
                "Y. Hu",
                "Y. Koren",
                "C. Volinsky"
            ],
            "title": "Collaborative filtering for implicit feedback datasets",
            "venue": "2008 Eighth IEEE International Conference on Data Mining. pp. 263\u2013272. Ieee",
            "year": 2008
        },
        {
            "authors": [
                "Y. Koren",
                "R. Bell",
                "C. Volinsky"
            ],
            "title": "Matrix factorization techniques for recommender systems",
            "venue": "Computer 42(8), 30\u201337",
            "year": 2009
        },
        {
            "authors": [
                "D. Kowald",
                "M. Schedl",
                "E. Lex"
            ],
            "title": "The unfairness of popularity bias in music recommendation: a reproducibility study",
            "venue": "Advances in Information Retrieval 12036, 35",
            "year": 2020
        },
        {
            "authors": [
                "D.D. Lee",
                "H.S. Seung"
            ],
            "title": "Algorithms for non-negative matrix factorization",
            "venue": "Proceedings of the 13th International Conference on Neural Information Processing Systems. p. 535\u2013541. NIPS\u201900, MIT Press, Cambridge, MA, USA",
            "year": 2000
        },
        {
            "authors": [
                "D. Liang",
                "R.G. Krishnan",
                "M.D. Hoffman",
                "T. Jebara"
            ],
            "title": "Variational autoencoders for collaborative filtering",
            "venue": "Proceedings of the 2018 world wide web conference. pp. 689\u2013698",
            "year": 2018
        },
        {
            "authors": [
                "P. Lops",
                "Gemmis",
                "M.d.",
                "G. Semeraro"
            ],
            "title": "Content-based recommender systems: State of the art and trends",
            "venue": "Recommender systems handbook pp. 73\u2013105",
            "year": 2011
        },
        {
            "authors": [
                "A. Mnih",
                "R.R. Salakhutdinov"
            ],
            "title": "Probabilistic matrix factorization",
            "venue": "Advances in neural information processing systems. pp. 1257\u20131264",
            "year": 2008
        },
        {
            "authors": [
                "H.A. Rahmani",
                "M. Aliannejadi",
                "M. Baratchi",
                "F. Crestani"
            ],
            "title": "Joint geographical and temporal modeling based on matrix factorization for point-of-interest recommendation",
            "venue": "European Conference on Information Retrieval. pp. 205\u2013219. Springer, Lisboa, Portugal (Online)",
            "year": 2020
        },
        {
            "authors": [
                "S. Rendle",
                "C. Freudenthaler",
                "Z. Gantner",
                "L. Schmidt-Thieme"
            ],
            "title": "Bpr: Bayesian personalized ranking from implicit feedback",
            "venue": "Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. pp. 452\u2013461",
            "year": 2009
        },
        {
            "authors": [
                "A. Salah",
                "Q.T. Truong",
                "H.W. Lauw"
            ],
            "title": "Cornac: A comparative framework for multimodal recommender systems",
            "venue": "Journal of Machine Learning Research 21(95), 1\u20135",
            "year": 2020
        },
        {
            "authors": [
                "Q.T. Truong",
                "A. Salah",
                "T.B. Tran",
                "J. Guo",
                "H.W. Lauw"
            ],
            "title": "Exploring crossmodality utilization in recommender systems",
            "venue": "IEEE Internet Computing",
            "year": 2021
        },
        {
            "authors": [
                "S. Wang",
                "L. Cao",
                "Y. Wang",
                "Q.Z. Sheng",
                "M.A. Orgun",
                "D. Lian"
            ],
            "title": "A survey on session-based recommender systems",
            "venue": "ACM Computing Surveys (CSUR) 54(7), 1\u2013 38",
            "year": 2021
        },
        {
            "authors": [
                "S. Zhang",
                "L. Yao",
                "A. Sun",
                "Y. Tay"
            ],
            "title": "Deep learning based recommender system: A survey and new perspectives",
            "venue": "ACM Computing Surveys (CSUR) 52(1), 1\u201338",
            "year": 2019
        },
        {
            "authors": [
                "C.N. Ziegler",
                "S.M. McNee",
                "J.A. Konstan",
                "G. Lausen"
            ],
            "title": "Improving recommendation lists through topic diversification",
            "venue": "Proceedings of the 14th international conference on World Wide Web. pp. 22\u201332",
            "year": 2005
        }
    ],
    "sections": [
        {
            "text": "Keywords: Algorithmic fairness \u00b7 Recommender systems \u00b7 Popularity bias \u00b7 Item popularity \u00b7 Book recommendation \u00b7 Reproducibility\n? Corresponding author.\nar X\niv :2\n20 2.\n13 44\n6v 1\n[ cs\n.I R\n] 2\n7 Fe"
        },
        {
            "heading": "1 Introduction",
            "text": "Recommender systems have been utilized in various information spaces such as entertainment, education, and online dating. They aim to support users in finding desired information that is typically hard and time-consuming to find without such systems. Recommendation algorithms proposed in the literature can be categorized into multiple groups according to the context of recommendation and how they learn user preference.\nCollaborative Filtering (CF) is one of the most widely-investigated classes of algorithms used for recommendation. These algorithms generate recommendations based on explicit or implicit interactions between users and items in the system [24,19] without benefiting from the content information, as opposed to content-based recommendation techniques. Hence, one limitation of CF algorithms is the problem of popularity bias which causes the popular (i.e., shorthead) items to be over-emphasized in the recommendation list. In contrast, the majority of less popular (i.e., long-tail) items do not get enough visibility in the recommendation lists. Tackling popularity bias can make the recommender system more applicable in the real world for various reasons [7,8]. A recommender system suffering from popularity bias would result in the market being dominated by a few well-known brands and deprive the discovery of new and unpopular items, which could ignore the interest of users with niche tastes.\nPopularity bias has been largely investigated from the item-centered perspective, that is, how frequently popular items appear in recommendation lists. The item-centered perspective study ignores users\u2019 interest in popular or less popular items, which causes a limitation as the popularity bias does not affect users equally [3]. Recently, Abdollahpouri et al. [2] have conducted a research study to look at the popularity bias from a different perspective: the users\u2019. To shed light on this topic, suppose a user rated 40 long-tail (less-popular) items and 60 popular items. Therefore, we expect the recommendation algorithm to end up with the same ratio of popular items in the recommended list presented to this user. Despite our expectations, most recommendation algorithms generate a recommendation list including close to 100 popular items. Furthermore, Abdollahpouri et al. [2] evaluate how popularity bias leads to unfair treatment of different user groups according to their interests in popular movies. Their experiments demonstrate that the state-of-the-art recommendation algorithms can not comprehensively understand users who tend to be interested in unpopular items [1].\nPopularity biases are known to arise from the underlying characteristics of the data, such as the number of interactions per item or user, sparsity, and an unbalanced distribution of interactions among items. As a result, in this work, we aim to reproduce the research study of Abdollahpouri et al. [2] and conduct it in a different domain and dataset. In particular, we select the book domain and Book-Crossing dataset due to a variety of reasons. First, the Book-Crossing data characteristic differs significantly from the previous study on the MovieLens 1M dataset in that it reports (256.46, 165.59) interactions per item and users respectively, as opposed to (12.79, 13.92) in Book-Crossing dataset. Table 1 summarizes\nthe main data characteristic of Book-Crossing dataset. Additionally, there are several aspects of book recommendations that make them different, challenging, and somehow more important than recommendations entertainment industry, such as movie and music recommendations [5,9]. For instance, although bookreading must become more prevalent in society, the investigation proves the opposite i.e., the practice of reading for pleasure or education is declining, particularly among the young [5]. Also, since a reader spends much time reading books, it is crucial that the content matches their known preferences and expectations. The experience of finding a match that is suitable can be rewarding for readers, but an inappropriate recommendation could result in losing interest, further contributing to the downward trend. It is, therefore, crucial to examine the existence of popularity bias from a user-centered perspective in book recommendations and, for reasons of comparability, we would like to answer the same two research questions as in the study of Abdollahpouri et al. [2]:\n\u2013 RQ1: How much are different individuals or groups of users interested in popular books?\n\u2013 RQ2: How does the popularity bias in recommendation algorithms impact users with different tendencies toward popular books?\nIn the following, we explore the Book-Crossing dataset characteristics and investigate RQ1 in Section 2. Then, we examine RQ2 in Section 3. We discuss the findings of our study and conclude the paper in Sections 4 and 5, respectively. Finally, to enable reproducibility of the experiment, we have made our codes open source.4\n4 https://github.com/rahmanidashti/FairBook"
        },
        {
            "heading": "6,358 6,921 88,552 13.92 12.79 99.80%",
            "text": ""
        },
        {
            "heading": "2 Popularity Bias in Data",
            "text": "In this paper, we utilize the well-known Book-Crossing5 dataset that contains 1, 149, 780 anonymous explicit and implicit ratings of approximately 340, 556 books made by 105, 283 users in a 4-week crawl (August - September 2004) [25]. From the dataset, we first removed all the implicit ratings, then we removed users who had fewer than 5 ratings so that the retained users were those who were likely to have rated enough long-tail items.The limit of 5 ratings was also used to remove distant long-tail items. Once short-profile users and distant long-tail items are removed, the Book-Crossing dataset consists of 6, 358 users who rated 6, 921 books, totaling 88, 552 in ratings. In the following, we will address the first research question. Table 1 shows the characteristics of the Book-Crossing datasets."
        },
        {
            "heading": "2.1 Reading Distribution of Books",
            "text": "Fig. 1 illustrates the distribution of readings in Book-Crossing dataset. Figure 1a indicates that reading counts of books follow a long-tail distribution as expected. That means a small proportion of books are read by many users, whereas a significant proportion (i.e., the long-tail) is read by only a small number of readers. Additionally, we illustrate in Fig 1b the ratio of popular books to all books read by users. Same as [2], we sort books based on the number of readers and consider them as popular if they are within the top-20% of the sorted list. By this definition, we observe that around 5, 256 out of 6, 358 users (i.e., around 83% of users) have read at least 20% of unpopular books in their profile."
        },
        {
            "heading": "2.2 User Profile Size and Popularity Bias in Book Data",
            "text": "In Fig. 2 we investigate whether a correlation exists between the size of the user profile and the presence of popular books in the profile. Specifically, in Fig. 2a, we depict the number of popular books in a user\u2019s profile over the size of the profile. As could be expected, there is a positive correlation since the more items in a user profile, the greater probability there are popular items in the profile. On the other hand, when plotting the average popularity of books in a user profile over the profile size in Fig. 2b, we observe a negative correlation, which indicates that users having a smaller profile size tend to read books with higher average popularity. Same as [2], we define the popularity of a book as the ratio of users who have read that book.\n5 http://www2.informatik.uni-freiburg.de/~cziegler/BX/\nAs stated before, in this work, we investigate the popularity bias from the users\u2019 perspective, same as [2]. To this end, we categorized all users into three groups according to their profile\u2019s ratio of popular items (i.e., book). This ratio indicates how interested they are in popular items.\n\u2013 Niche users: After sorting users based on the ratio of popular items in their profiles, we refer to the bottom 20% of the sorted list as Niche users. \u2013 Bestseller-focused users: We consider the top 20% users of the sorted list as Bestseller-focused users interested in popular books. \u2013 Diverse users: The rest of the users fall within this category. Users in this category have varied interests in popular and unpopular books.\nFig. 3 indicates the average profile size of different user groups. As expected, Diverse users have the largest profile size, followed by Niche users. The Bestsellerfocused group has the smallest average profile size. Based on our analysis in section 2.2, diverse users have larger average profile size; therefore, we can expect them to read more popular books than niche users. Furthermore, the small profile size of Bestseller-focused users implies that they are focused on reading solely popular books.Finally, we expect that recommendation algorithms influenced by popularity bias will provide Bestseller-focused users with the best recommendation quality (i.e., accuracy), followed by Diverse users. Furthermore, Niche users are likely to receive the lowest recommendation quality, as they have the lowest ratio of popular items in their profile. We will explore these expectations in the next section.\nHence, in this section, we find that majority of users (i.e., around five-seventh) have read at least 20% of unpopular books. Furthermore, we find that users with a small profile size tend to read more popular books than users having a larger profile size. To sum up, we investigated RQ1 in this section and our findings are in agreement with what Abdollahpouri et al. have reported in [2]."
        },
        {
            "heading": "3 Popularity Bias in Book Recommendation",
            "text": "In this section, we study popularity bias in state-of-the-art book recommendation algorithms. In order to foster the reproducibility of this study, we implement and evaluate all recommendation algorithms using Cornac6, which is a Python-based open source recommendation framework [21,22]. Therefore, we formulate the book recommendation using Cornac as a rating prediction problem, where we predict the preference of a target user u for a target book b. Then, we recommend the top-10 books with the highest predicted preferences.\nFor ease of comparison, we use the same evaluation setup used in [2] to evaluate the performance of the recommendation algorithms. To this end, we set aside 80% of the Book-Crossing dataset as training set and the remaining 20% as the test set. We further extended the prior study of [2] by incorporating a more comprehensive range of state-of-the-art algorithms, including (i) baseline approaches, (ii) K-Nearest Neighbour (KNN) approaches, (iii) Matrix Factorization (MF) approaches, and (iv) Neural Network (NN) approaches. Specifically, we evaluate two baselines approaches, i.e., Random and MostPop. We include the UserKNN [6], which is a KNN-based method. We also evaluate five MF-based approaches, including MF [13], PMF [18], NMF [15], WMF [12], and PF [10]. We also consider BPR [20] as one of the well-know ranking-based algorithms. Eventually, we include two state-of-the-art NN-based approaches, i.e., NeuMF [11] and VAECF [16]. We adopt the recommendation algorithm with the default hyperparameter settings suggested in their original paper."
        },
        {
            "heading": "3.1 Recommendation of Popular Books",
            "text": "As shown in our analysis in Section 2, there is an imbalanced distribution in the book rating data, i.e., certain books are rated very frequently while the majority of items are rated by only a few users. In this section, we investigate to what extent different recommendation algorithms propagate this bias\n6 https://cornac.preferred.ai/\ninto their recommendations. First, we examine algorithms\u2019 overall performance without taking into account how they perform for different users or groups of users based on their tendency towards popular items. In Fig. 4, we illustrate the correlation of book popularity and how often the eight algorithms recommend these books. Among baseline algorithms, we are seeing a strong positive correlation on MostPop showing algorithm tendency to recommend popular items frequently not giving chance to long-tail items and no meaningful correlation on Random as expected. Interestingly, we observe a strong correlation between the popularity of items and their recommendation frequency on NeuMF and BPR with very similar behavior to MostPop. A majority of books were not exposed to users by these algorithms, while popular ones are more frequently highlighted. Furthermore, our experiment shows a moderate positive correlation in WMF and PF among the Matrix Factorization-based approaches. In contrast to Abdollahpouri et al. [2] and Kowald et al. [14] study in the Movie and Music domain, no positive correlation exists in PMF, MF, and NMF, indicating that the latter algorithms in Matrix Factorization-based approaches are not prone to popularity bias in Book-Crossing dataset. Additionally, this suggests that the characteristics of underlying data and the domain could play a key role in determining how recommendation algorithms behave in propagating popularity bias in various domains. Finally, among NN-based state-of-the-art approaches investigated in this study, the VAECF model has a moderately positive correlation and a better performance than the NeuMF model."
        },
        {
            "heading": "3.2 Popularity Bias for Different User Groups",
            "text": "In this section, we investigate the effect of popularity bias on different user groups (i.e., Niche, Diverse, and Bestseller-focused) in book recommendations. To this end, we use delta Group Average Popularity (\u2206GAP) metric proposed\nM ostPop BPR M F PFM NM F W M F PF NeuM F VAECF\nNiche\nDiverse\nBestSeller\n* * * * *\n** ** 2\n4\n6\n(a) MAE\nM ostPop BPR M F PFM NM F W M F PF NeuM F VAECF\nNiche\nDiverse\nBestSeller\n* * * * * * ** ** ** ** ** ** 0.005 0.010\n0.015\n0.020\n(b) Precision\nM ostPop BPR M F PFM NM F W M F PF NeuM F VAECF\nNiche\nDiverse\nBestSeller\n* * * * * ** ** ** ** ** ** 0.025\n0.050\n0.075\n(c) Recall\nM ostPop BPR M F PFM NM F W M F PF NeuM F VAECF\nNiche\nDiverse\nBestSeller\n* * * * * ** ** ** ** ** ** 0.02\n0.04\n(d) NDCG\nFig. 6: The performance of models for the three user groups in terms of MAE (the lower, the better) and Precision, Recall, and NDCG (the higher, the better). The best results are always given for the Bestseller-focused user group (statistically significant according to a t-test with p < 0.005 as indicated by **). Across the algorithms, the best results are provided by VAECF (indicated by dark blue colour).\nby Abdollahpouri et al. [2] to evaluate the unfairness of popularity bias. We further use MAE, Precision, Recall, and NDCG to evaluate the performance of recommender algorithms. For each recommendation algorithm and user group, \u2206GAP measures the difference between the average popularity of the recommended books and the average expected popularity shown in the user\u2019s profiles history as follows:\n\u2206GAP = GAP (g)r \u2212GAP (g)p\nGAP (g)p (1)\nwhere g is a certain user group (i.e., Niche, Diverse, or Bestseller-focused), GAP (g)r and GAP (g)p represent the GAP value for recommendation lists and user profiles, respectively, and it is defined as follows:\nGAP (g) =\n\u2211 u\u2208g \u2211 i\u2208pu \u03c6(i)\n|pu|\n|g| (2)\nwhere \u03c6(i) is the popularity of item i, which is the number of times it is rated divided by the total number of users, and pu is the list of items in the profile of user u. The value of \u2206GAP = 0 indicates a fair recommendation meaning that the average popularity of recommended books matches the average popularity of the user profile.\nFig. 5 shows \u2206GAP values for recommendation algorithms among the three user groups. As can be seen, Niches users receive significantly higher average \u2206GAP values followed by Diverse and Bestseller-focused users, respectively. This finding confirms the results of the Abdollahpouri et al. [2] study and suggests that the popularity bias affects Niche users the most, that is, despite being interested in unpopular items, they receive recommendations of popular items. Interestingly, although the Bestseller-focused group receives the most favorable recommendations, the average \u2206GAP is 126.55, revealing how algorithms can propagate the popularity bias even further than the Bestseller-focused user groups\u2019 interest in popular items. Fig. 5 further illustrates that algorithms investigated in this study show similar behavior in terms of popularity bias among different user groups. Moreover, in line with our analysis in section 3.1, Random, MF, and NMF models provide the fairest recommendations, while MostPop, BPR, and NeuMF suffer from the propagation of popularity bias across all user groups.\nThen, to address RQ2, we analyze the results of MAE (the lower, the better), Precision, Recall, and NDCG (the higher, the better) of the recommendation algorithms on three users groups. Moreover, we determine the statistically significant differences using the two-tailed paired t-test at a 95% confidence interval (p < 0.05). As we see in Fig. 6, the Niche group receives significantly worse recommendations than two other groups (i.e., Diverse and Bestseller-focused), while the Bestseller-focused group gets the best performance. According to this result, algorithms are not capable of detecting the difference in taste between users, even though the average size of user profiles for Niche users is larger than that of the Bestseller-focused group (i.e., more training data), further emphasizing the unfairness of popularity bias. Across the algorithms, we see that WMF and VAECF algorithms provide the highest accuracy in all user groups. Notably, the WMF algorithm displayed the best performance in Niche group when considering both accuracy and fairness."
        },
        {
            "heading": "3.3 Unfairness of Popularity Bias vs. Personalization",
            "text": "The main objective of this part is to explore the potential correlation or trade-off between unfairness of popularity bias and personalization measured by NDCG,\nbetween groups of users who have differing preferences for popular items. To this purpose, Fig. 7 shows the correlation plot between NDCG@10 and \u2206GAP for three user groups defined in Section 2.2 where each point represents the performance of a state-of-the-art recommendation algorithm. Interestingly, we observe an uphill (positive) correlation between NDCG and \u2206GAP in the Bestsellerfocused and Diverse user groups with the p-value and Pearson\u2019s coefficient of (0.01, 0.79) and (0.05, 0.66), respectively. In contrast, we find no meaningful correlation (i.e., p-value of 0.69) between accuracy and unfairness of popularity bias among users with Niche tastes. These results indicate that algorithms with a high accuracy score fall short on popularity bias fairness from the perspective of users with Diverse and Bestseller-focused tastes, prompting further studies on how to incorporate users\u2019 taste and expectations in recommendation without sacrificing the overall accuracy."
        },
        {
            "heading": "4 Discussion",
            "text": "In this section, we present a summary of the answers we found to the research questions in Section 1.\n\u2013 Answer to RQ1: In line with the previous study of Abdollahpouri et al. [2], our experiments demonstrate that different users have a considerably different tendency towards popular items. Moreover, we discovered that around 83% of users have read at least 20% of unpopular books in their profile and expect to receive some of these items in recommendations. Our result further reveals that users with larger profile sizes who contribute most to the system have diverse tastes and interact with a substantial amount of unpopular items. \u2013 Answer to RQ2: Our results for various state-of-the-art recommendation algorithms demonstrate that most algorithms are unfair to users who have a niche or diverse taste in books in terms of popularity, i.e., these users receive recommendations that have lower accuracy and mainly consist of popular books. In addition, the study shows popularity bias negatively affects all user groups, even those focusing on bestsellers, but the magnitude of this effect varies greatly depending on the user group."
        },
        {
            "heading": "5 Conclusion and Future Work",
            "text": "In this paper, we reproduced the study of Abdollahpouri et al. [2] on the unfairness of popularity bias from the user\u2019s perspective in the Movie domain, which we have applied to the book domain. Similar to the original paper, we divided all users into three groups (i.e., Niche, Diverse and Bestseller-focused) based on their level of interest in popular items. Our results on various state-of-theart recommendation algorithms reveal that the most widely adopted algorithms fail to capture users\u2019 interest in unpopular items and recommend mostly popular items. Notably, the quality of recommendations received by users with a\nDiverse or Niche taste is significantly lower than that of users with Bestsellers taste, despite having a large profile size. Moreover, our experiments led to new observations and possible directions for future research. First, we noticed that algorithms could differ significantly in their ability to capture users\u2019 tastes based on the domain. For instance, the NMF algorithm suffers from the unfairness of popularity bias in the music domain [14] while offering an entirely fair recommendation in Book-Crossing dataset. A future research direction that would be interesting is identifying the underlying reason for the variance, in particular, which feature of the data (e.g., sparsity, average user interaction) plays the primary role in propagating the popularity bias. Additionally, our results suggest that an underlying tradeoff exists between personalization and fairness of popularity bias in Diverse and Bestseller-focused groups, that is, algorithms with high personalization abilities tend to experience fairness issues. Thus, further research could be worthwhile into implementing a recommendation algorithm that can find the optimal tradeoff between personalization and the unfairness of popularity biases to enhance the system\u2019s overall effectiveness. Finally, it would be interesting to investigate popularity bias on other domains and algorithms such as session-based [23], content-based [17], or reinforcement learning-based recommendation [4] methods, as well as incorporating further evaluation metrics such as novelty and coverage.\nReproducibility. To enable reproducibility of the results, we provide our dataset, source codes with all used parameter settings, and more experimental results and analysis on our webpage: https://rahmanidashti.github.io/FairBook/"
        }
    ],
    "title": "The Unfairness of Popularity Bias in Book Recommendation",
    "year": 2022
}