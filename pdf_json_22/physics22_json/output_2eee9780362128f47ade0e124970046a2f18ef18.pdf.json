{
    "abstractText": "In a special run of the LHC with \u03b2 = 2.5 km, proton\u2013proton elastic-scattering events were recorded at \u221a s = 13 TeV with an integrated luminosity of 340 \u03bcb\u22121 using the ALFA subdetector of ATLAS in 2016. The elastic cross section was measured differentially in the Mandelstam t variable in the range from \u2212t = 2.5 \u00b7 10\u22124 GeV2 to \u2212t = 0.46 GeV2 using 6.9 million elastic-scattering candidates. This paper presents measurements of the total cross section \u03c3tot, parameters of the nuclear slope, and the \u03c1parameter defined as the ratio of the real part to the imaginary part of the elastic-scattering amplitude in the limit t \u2192 0. These parameters are determined from a fit to the differential elastic cross section using the optical theorem and different parameterizations of the t-dependence. The results for \u03c3tot and \u03c1 are \u03c3tot(pp \u2192 X) = 104.7 \u00b1 1.1 mb, \u03c1 = 0.098 \u00b1 0.011. The uncertainty in \u03c3tot is dominated by the luminosity measurement, and in \u03c1 by imperfect knowledge of the detector alignment and by modelling of the nuclear amplitude.",
    "authors": [],
    "id": "SP:77e7d4192361a35a89df8c02d28b523dac9b971c",
    "references": [
        {
            "authors": [
                "TOTEM Collaboration",
                "First determination of the \u03c1 parameter at \u221a s = 13 TeV"
            ],
            "title": "probing the existence of a colourless C-odd threegluon compound state",
            "venue": "Eur. Phys. J. C 79, 785",
            "year": 2019
        },
        {
            "authors": [
                "J.R. COMPETE Collaboration"
            ],
            "title": "Cudell et al., Benchmarks for the forward observables at RHIC, the Tevatron-Run II, and the LHC",
            "venue": "Phys. Rev. Lett. 89,",
            "year": 2002
        },
        {
            "authors": [
                "S. Abdel Khalek"
            ],
            "title": "The ALFA Roman Pot detectors of ATLAS",
            "venue": "JINST 11,",
            "year": 2016
        },
        {
            "authors": [
                "A. Garc\u00eda-Tabar\u00e9s Valdivieso"
            ],
            "title": "Optics measurements and corrections at \u03b2 = 2.5 km. CERN-ACC-Note-2018-0052 (2018)",
            "year": 2018
        },
        {
            "authors": [
                "E. Todesco",
                "J. Wenninger"
            ],
            "title": "Large hadron collider momentum calibration and accuracy",
            "venue": "Phys. Rev. Accel. Beams",
            "year": 2017
        },
        {
            "authors": [
                "C. Zamantzas"
            ],
            "title": "The LHC beam loss monitoring system\u2019s data contribution to other systems, in 2007",
            "venue": "IEEE Nuclear Science Symposium Conference Record, vol",
            "year": 2007
        },
        {
            "authors": [
                "H.A. Bethe"
            ],
            "title": "Scattering and polarization of protons by nuclei",
            "venue": "Ann. Phys. 3,",
            "year": 1958
        },
        {
            "authors": [
                "D.R.G.B. West"
            ],
            "title": "Yennie, Coulomb interference in high-energy scattering",
            "venue": "Phys. Rev. 172,",
            "year": 1968
        },
        {
            "authors": [
                "TOTEM Collaboration",
                "Measurement of elastic pp scattering at \u221a s = 8 TeV in the Coulomb\u2013nuclear interference region"
            ],
            "title": "determination of the \u03c1-parameter and the total cross-section",
            "venue": "Eur. Phys. J. C 76, 661",
            "year": 2016
        },
        {
            "authors": [
                "M.G.P. Grafstrom"
            ],
            "title": "Ryskin, Bethe phase variation due to a nonexponential nuclear amplitude and the possibility of using a tdependent phase to determine the \u03c1-parameter from elastic scattering data (2020)",
            "year": 2010
        },
        {
            "authors": [
                "R. Cahn"
            ],
            "title": "Coulombic-hadronic interference in an eikonal model",
            "venue": "Z. Phys. C 15,",
            "year": 1982
        },
        {
            "authors": [
                "G.G. Simon",
                "C. Schmitt",
                "F. Borkowski",
                "V.H. Walther"
            ],
            "title": "Absolute electron-proton cross sections at low momentum transfer measured with a high pressure gas target system",
            "venue": "Nucl. Phys. A 333,",
            "year": 1980
        },
        {
            "authors": [
                "Collaboration",
                "J.C. Bernauer"
            ],
            "title": "Electric and magnetic form factors of the proton",
            "venue": "Phys. Rev. C 90,",
            "year": 2014
        },
        {
            "authors": [
                "C. Bourrely",
                "J. Soffer",
                "T.T. Wu"
            ],
            "title": "Determination of the forward slope in pp and P\u0304 P elastic scattering up to LHC energy",
            "venue": "Eur. Phys. J. C 71,",
            "year": 2011
        },
        {
            "authors": [
                "Collaboration",
                "S. Agostinelli"
            ],
            "title": "GEANT4\u2014a simulation toolkit",
            "venue": "Nucl. Instrum. Methods A 506,",
            "year": 2003
        },
        {
            "authors": [
                "R. Ciesielski"
            ],
            "title": "MBR Monte Carlo simulation in PYTHIA8",
            "venue": "PoS ICHEP2012,",
            "year": 2013
        },
        {
            "authors": [
                "T. Sj\u00f6strand"
            ],
            "title": "An introduction to PYTHIA 8.2",
            "venue": "Comput. Phys. Commun. 191,",
            "year": 2015
        },
        {
            "authors": [
                "B. Malaescu"
            ],
            "title": "An iterative, dynamically stabilized(IDS) method of data unfolding, in PHYSTAT",
            "venue": "https://doi.org/",
            "year": 2011
        },
        {
            "authors": [
                "V.G.A. H\u00f6cker"
            ],
            "title": "Kartvelishvili, SVD approach to data unfolding",
            "venue": "Nucl. Instrum. Methods A 372,",
            "year": 1996
        },
        {
            "authors": [
                "G. Avoni"
            ],
            "title": "The new LUCID-2 detector for luminosity measurement and monitoring in ATLAS",
            "venue": "JINST 13,",
            "year": 2018
        },
        {
            "authors": [
                "V. Cindro"
            ],
            "title": "The ATLAS beam conditions monitor",
            "venue": "JINST 3,",
            "year": 2008
        },
        {
            "authors": [
                "S. van der Meer"
            ],
            "title": "Calibration of the effective beam height in the ISR",
            "venue": "http://cds.cern.ch/record/296752. Accessed",
            "year": 1968
        },
        {
            "authors": [
                "V. Blobel"
            ],
            "title": "Some comments on \u03c72 minimization applications, in Proceedings of the conference on statistical problems in particle physics, astrophysics and cosmology, PHYSTAT 2003, ed",
            "venue": "p. MOET002. https://www.slac.stanford.edu/ econf/C030908/papers/MOET002.pdf. Accessed",
            "year": 2003
        },
        {
            "authors": [
                "G. Bohm",
                "G. Zech"
            ],
            "title": "Introduction to statistics and data analysis for physicists (DESY",
            "year": 2014
        },
        {
            "authors": [
                "C. Bourrely",
                "J. Soffer",
                "D. Wray"
            ],
            "title": "Spin effects in proton-proton elastic scattering near the forward direction",
            "venue": "Nucl. Phys. B 77,",
            "year": 1974
        },
        {
            "authors": [
                "V.D.R.J.N. Phillips"
            ],
            "title": "Barger, Model independent analysis of the structure in p p scattering",
            "venue": "Phys. Lett. B 46,",
            "year": 1973
        },
        {
            "authors": [
                "V.M. TOTEM Collaborations"
            ],
            "title": "Abazov et al., Odderon exchange from elastic scattering differences between pp and p p\u0304 data at 1.96 TeV and from pp forward scattering measurements",
            "venue": "Phys. Rev. Lett. 127,",
            "year": 2021
        },
        {
            "authors": [
                "M.M. Block",
                "R.N. Cahn",
                "Forward hadronic pp",
                "p\u0304 p elastic scattering amplitudes"
            ],
            "title": "analysis of existing data and extrapolations to collider energies",
            "venue": "Phys. Lett. B 120, 224",
            "year": 1983
        },
        {
            "authors": [
                "C. Bourrely",
                "A. Martin"
            ],
            "title": "Theoretical predictions for pp and p antip elastic scattering in the TeV energy domain, in CERN-ECFA Workshop on Feasibility of Hadron Colliders in the LEP Tunnel",
            "venue": "https://cds.cern.ch/record/153114. https://doi.org/10",
            "year": 1984
        },
        {
            "authors": [
                "E. Gotsman",
                "E. Levin",
                "I. Potashnikova",
                "CGC/saturation approach"
            ],
            "title": "secondary Reggeons and \u03c1 = Re/Im dependence on energy",
            "venue": "Phys. Lett. B 786, 472",
            "year": 2018
        },
        {
            "authors": [
                "L. Lukaszuk",
                "B. Nicolescu"
            ],
            "title": "A possible interpretation of pp rising total cross-sections",
            "venue": "Lett. Nuovo Cim. 8,",
            "year": 1973
        },
        {
            "authors": [
                "E. Martynov",
                "B. Nicolescu"
            ],
            "title": "Did TOTEM experiment discover the Odderon",
            "venue": "Phys. Lett. B 778,",
            "year": 2018
        },
        {
            "authors": [
                "M.G. Ryskin"
            ],
            "title": "Odderon and polarization phenomena in QCD",
            "venue": "Sov. J. Nucl. Phys. 46,",
            "year": 1987
        },
        {
            "authors": [
                "V.A. Khoze",
                "M.G.A.D. Martin"
            ],
            "title": "Ryskin, Elastic and diffractive scattering at the LHC",
            "venue": "Phys. Lett. B 784,",
            "year": 2018
        },
        {
            "authors": [
                "O.V. Selyugin"
            ],
            "title": "Nucleon structure and the high energy interactions",
            "venue": "Phys. Rev. D",
            "year": 2015
        },
        {
            "authors": [
                "J.R.O.V. Selyugin"
            ],
            "title": "Cudell, Odderon, HEGS model and LHC data",
            "venue": "Acta Phys. Pol. Supp. 12,",
            "year": 2019
        },
        {
            "authors": [
                "F.M.M. Block"
            ],
            "title": "Halzen, New experimental evidence that the proton develops asymptotically into a black disk",
            "venue": "Phys. Rev. D",
            "year": 2012
        },
        {
            "authors": [
                "Pierre Auger"
            ],
            "title": "Collaboration, Measurement of the proton-air crosssection at \u221a s = 57 TeV with the Pierre Auger Observatory",
            "venue": "Phys. Rev. Lett. 109,",
            "year": 2012
        },
        {
            "authors": [
                "S. Ostapchenko",
                "QGSJET-II"
            ],
            "title": "towards reliable description of very high energy hadronic interactions",
            "venue": "Nucl. Phys. B Proc. Suppl. 151, 143",
            "year": 2006
        },
        {
            "authors": [
                "T. Sj\u00f6strand",
                "S. Mrenna",
                "P. Skands"
            ],
            "title": "A brief introduction to PYTHIA 8.1",
            "venue": "Comput. Phys. Commun. 178,",
            "year": 2008
        },
        {
            "authors": [
                "T. Pierog",
                "I. Karpenko",
                "J.M. Katzy",
                "E. Yatsenko",
                "K. Werner",
                "EPOS LHC"
            ],
            "title": "test of collective hadronization with data measured at the CERN Large Hadron Collider",
            "venue": "Phys. Rev. C 92, 034906",
            "year": 2015
        },
        {
            "authors": [
                "M.G.V.A. Schegelsky"
            ],
            "title": "Ryskin, Diffraction cone shrinkage speed up with the collision energy",
            "venue": "Phys. Rev. D",
            "year": 2012
        }
    ],
    "sections": [
        {
            "text": "using the ALFA subdetector of ATLAS in 2016. The elastic cross section was measured differentially in the Mandelstam t variable in the range from \u2212t = 2.5 \u00b7 10\u22124 GeV2 to \u2212t = 0.46 GeV2 using 6.9 million elastic-scattering candidates. This paper presents measurements of the total cross section \u03c3tot, parameters of the nuclear slope, and the \u03c1parameter defined as the ratio of the real part to the imaginary part of the elastic-scattering amplitude in the limit t \u2192 0. These parameters are determined from a fit to the differential elastic cross section using the optical theorem and different parameterizations of the t-dependence. The results for \u03c3tot and \u03c1 are \u03c3tot(pp \u2192 X) = 104.7 \u00b1 1.1 mb, \u03c1 = 0.098 \u00b1 0.011. The uncertainty in \u03c3tot is dominated by the luminosity measurement, and in \u03c1 by imperfect knowledge of the detector alignment and by modelling of the nuclear amplitude.\nContents\n1 Introduction . . . . . . . . . . . . . . . . . . . . . 1 2 Experimental set-up . . . . . . . . . . . . . . . . . 3 3 Experimental method . . . . . . . . . . . . . . . . 3\n3.1 Measurement principle . . . . . . . . . . . . . 3 3.2 Data taking . . . . . . . . . . . . . . . . . . . 5 3.3 Track reconstruction and alignment . . . . . . . 6\n4 Simulation model for elastic scattering . . . . . . . 7 4.1 Theoretical predictions . . . . . . . . . . . . . 7 4.2 Simulation model . . . . . . . . . . . . . . . . 8\n5 Data analysis . . . . . . . . . . . . . . . . . . . . . 9 5.1 Event selection . . . . . . . . . . . . . . . . . 9 5.2 Background determination . . . . . . . . . . . 10 5.3 Reconstruction efficiency . . . . . . . . . . . . 11\ne-mail: atlas.publications@cern.ch\n5.4 Acceptance and unfolding . . . . . . . . . . . . 14 5.5 Beam optics . . . . . . . . . . . . . . . . . . . 16 5.6 Luminosity . . . . . . . . . . . . . . . . . . . 18\n6 Results . . . . . . . . . . . . . . . . . . . . . . . . 20 6.1 The differential elastic cross section . . . . . . 20\nExperimental systematic uncertainties . . . . . 20 6.2 Fitting procedure . . . . . . . . . . . . . . . . 22 6.3 Theoretical uncertainties . . . . . . . . . . . . 22 6.4 Stability checks . . . . . . . . . . . . . . . . . 23 6.5 Elastic and inelastic cross sections, and \u03c3el/\u03c3tot 24 6.6 Absolute luminosity calibration . . . . . . . . . 26\n7 Interpretation . . . . . . . . . . . . . . . . . . . . . 26 7.1 Energy evolution of \u03c3tot and \u03c1 . . . . . . . . . 26 7.2 Evolution of the ratio \u03c3el/\u03c3tot . . . . . . . . . . 29 7.3 Inelastic cross section . . . . . . . . . . . . . . 29 7.4 Nuclear slope B . . . . . . . . . . . . . . . . . 29\n8 Conclusion . . . . . . . . . . . . . . . . . . . . . . 30 Appendix . . . . . . . . . . . . . . . . . . . . . . . . 31 A HepData material . . . . . . . . . . . . . . . . . . . 34 References . . . . . . . . . . . . . . . . . . . . . . . . 34"
        },
        {
            "heading": "1 Introduction",
            "text": "Measurements of elastic scattering at hadron colliders give unique experimental access to non-perturbative dynamics, which cannot be calculated from first principles. Of particular importance are the total hadronic cross section, \u03c3tot, and the ratio of the real part to the imaginary part of the elasticscattering amplitude (\u03c1-parameter), which probes Coulomb\u2013 nuclear interference (CNI). These observables are related by dispersion relations derived from foundational unitarity and analyticity arguments for scattering amplitudes. Dispersion relations connect the \u03c1-parameter at a certain energy to the energy evolution of \u03c3tot both below and above this energy. The \u03c1-parameter at the LHC energy has recently received significant interest because of a measurement at \u221a s = 13 TeV\nby the TOTEM experiment [1] which measured a lower value\nof the \u03c1-parameter than would be expected assuming a ln2 s rise of the total cross section, s being the centre-of-mass energy squared.\nThe \u03c1-parameter is sensitive not only to the high-energy evolution of the total hadronic cross section but also to the fundamental structure of the elastic-scattering amplitude. Traditionally, the elastic-scattering amplitude at energies well above 100 GeV has been thought to be dominated by an exchange of Pomerons in the t-channel (see e.g. Ref. [2]). In QCD the Pomeron is represented by a two-gluon colourless state with spin\u2013parity\u2013charge quantum numbers JPC = 0++. The additional possible presence of a three-gluon colourless state with JPC = 1\u2212\u2212, the so-called Odderon, can also influence the value of the \u03c1-parameter. Thus, measurements of the \u03c1-parameter at the highest energy of the LHC are essential.\nThe \u03c1-parameter is defined as the ratio of the real part to the imaginary part of the elastic-scattering amplitude in the limit t \u2192 0, i.e. \u03c1 = Re[ fel(t)]\nIm[ fel(t)] \u2223 \u2223 \u2223 \u2223 t\u21920 ,\nwhere fel(t) is the elastic-scattering amplitude and where t stands for the four-momentum transfer in the reaction.\nNormally, the \u03c1-parameter is determined by measuring the differential elastic cross section at such small values of |t | that the amplitude is sensitive both to the Coulomb amplitude and the strong amplitude, and thus also to the interference between the two. The phase of the Coulomb amplitude is known, and therefore the value of \u03c1 can be extracted from the measured size of the interference term.\nThe ATLAS experiment has previously measured elastic scattering at 7 and 8 TeV [3,4] using the ATLAS Roman Pot system ALFA [5]. However, those measurements did not extend to the region of very small |t |-values where the differential cross section is sensitive to the \u03c1-parameter. Such small |t |-values require measurements of angles in the microradian range, which in turn need even smaller divergence of the beam at the interaction point (IP). Moreover, they require that the vertically movable Roman Pot detectors approach to within millimetres of the beam.\nThis paper presents a new measurement using pp collision data at \u221a s = 13 TeV, corresponding to an integrated luminosity of 340 \u00b5b\u22121. For the first time, the ATLAS measurement is extended, by an order of magnitude lower in \u2212t , to such small scattering angles that the Coulomb interaction starts to play a role. Here, the differential elastic cross section is measured down to \u2212t = 2.5 \u00b7 10\u22124 GeV2. The acceptance for elastic events is very small for such low values of |t | and if an acceptance greater than 10% is required, the lower limit is \u2212t = 4.5 \u00d7 10\u22124 GeV2. The needed small divergence of\nthe beam at the IP is achieved by using very high-\u03b2 optics1 (\u03b2 = 2.5 km), producing a large beam spot size but very small beam divergence.\nThe measurements rely upon the very accurate luminosity determination that ATLAS provides for all cross-section measurements [6]. The TOTEM experiment has a different approach, using the so-called luminosity-independent method for the normalization of the differential cross section. The main uncertainty in using this method comes from the Monte Carlo estimate of the non-measurable forward diffractive cross section. In addition, ATLAS has introduced data-driven methods to constrain the parameters of the detector alignment. The alignment uncertainty and the luminosity uncertainty together constitute the dominant uncertainty in the measurement of the differential elastic cross section.\nThe optical theorem connects the hadronic component of the total cross section \u03c3tot to the imaginary part of the scattering amplitude in the forward direction,\n\u03c3tot = 4\u03c0 Im [ fel (t)]|t\u21920 . (1) In the same manner as in the ATLAS measurements at\n7 TeV and 8 TeV, the optical theorem is also used in the present analysis to determine \u03c3tot by extrapolating the differential cross section to t \u2192 0. The total hadronic elastic cross section, in turn, is obtained from an integration of the measured differential elastic cross section. Using the trivial relation, \u03c3inel = \u03c3tot \u2212 \u03c3el, the total inelastic cross section can also be calculated.\nAnother aspect of interest is whether the differential elastic cross section can be described by a simple exponent in the region where the strong interaction dominates or if higherorder corrections are needed (for an overview of the experimental situation, see the introduction of Ref. [7]). Such tendencies were already observed at the Intersecting Storage Rings (ISR) but the sample size was insufficient to draw a definite conclusion. With the large sample available here at 13 TeV, ATLAS has an opportunity to establish such a nonexponential behaviour. TOTEM has reported observations of non-exponential behaviour at both 8 TeV [7] and 13 TeV [8].\nThe paper is organized in the following way. Section 2 presents the experimental set-up and includes a brief description of the ALFA subdetector. The data sets and the datataking conditions are discussed in Sect. 3, where the measurement method and detector alignment are also explained. The theoretical framework and simulation tools for the description of elastic scattering are presented in Sect. 4. The main points of the data analysis are discussed in Sect. 5. Section 6 is devoted to the determination of the differential elastic cross\n1 The \u03b2-function determines the variation of the beam envelope around the LHC ring and depends on the focusing properties of the magnetic lattice. \u03b2 is the value of the \u03b2-function at the IP. The beam divergence at the IP is about 0.3 \u00b5rad for \u03b2 = 2.5 km.\nsection and the physics parameters. The interpretation of the results is discussed in Sect. 7. The conclusions are given in Sect. 8."
        },
        {
            "heading": "2 Experimental set-up",
            "text": "The ALFA detector is a specific part of the ATLAS experiment [9] designed to measure the elastic scattering of protons. Because the protons are elastically scattered at very small angles the tracking detectors need to be placed close to the beam and far from the IP. For this purpose two stations with tracking detectors are located on both sides of the central ATLAS detector.\nThe conceptual layout of the detectors in the two stations on one side of the ATLAS detector is shown in Fig. 1. In each station, two main tracking detectors (MDs) measure the trajectory of scattered protons in the upper or lower half of the station. Overlap detectors (ODs) are placed on the right and left sides of each MD. They are used to measure the vertical distance between the upper and lower MDs by recording halo protons passing through the left-side or right-side ODs on the two MDs. The MDs and ODs are supplemented by trigger counters made of 3 mm scintillator tiles. The detectors are housed in so-called Roman Pots (RPs), an upper one and a lower one, which are movable and can approach the circulating beam in the vertical direction to within 1 mm. Due to the layout of the LHC accelerator, with two parallel beam pipes close to each other in the horizontal plane, a choice of vertically moving RPs was natural.\nEach MD consists of 10 modules with 64 scintillating fibres of 0.5 mm size glued on both the front and back sides of a titanium support plate. The fibres on both sides are arranged orthogonally in a uv-geometry at \u00b145\u25e6 to the y-axis. The module layers are staggered in steps of a tenth of the fibre size. The spatial resolution of the MDs is measured to be about 32\u00b5m. The ODs consists of only three layers of 0.5 mm fibres. A detailed description of the ALFA detector can be found in Ref. [5].\nThe schematic layout of the ALFA stations in the LHC is shown in Fig. 2. Two stations at distances of 237 m and 245 m on each side of the interaction point ensure the reconstruction of the scattered proton\u2019s trajectory. The stations on the right side of ATLAS measure the scattered protons along the outgoing LHC beam 1 line (C-side), while stations on the left side cover the outgoing LHC beam 2 line (A-side). The eight MDs form two independent spectrometer arms. Arm 1 consists of the upper detectors in the two stations on the left side combined with the lower detectors in the two stations on the right side of the IP. Arm 2 consists of the two lower detectors on the left side combined with the two upper detectors on the right side. The preselection of elastic-scattering\nevents requires triggers to have fired in at least one MD on either side of a spectrometer arm.\nIn the LHC Long Shutdown period from 2013 to 2014 (known as LS1) some major technical investments were made to ensure data taking with ALFA in Run 2. Dangerous heating of the fiber detectors up to damage level was observed at higher beam intensities in Run 1. To protect the detectors, all stations were equipped with an active air cooling system and additional passive cooling components. Another modification was necessary to reach the high-\u03b2\u2217 value of 2.5 km: two additional water-cooled power cables were installed to allow more flexible quadrupole operation.\nFor physics analysis the most relevant modification was the relocation of the outer stations B7L1 and B7R1. The new positions increased the distance between inner and outer stations from 4 m to about 8 m. As a consequence the track angular resolution improved significantly.\n3 Experimental method\n3.1 Measurement principle\nThe data were recorded with special beam optics characterized by a \u03b2 of 2.5 km [10] at the IP resulting in small beam divergence and providing parallel-to-point focusing in the vertical plane. In parallel-to-point beam optics the betatron oscillation has a phase advance of 90\u25e6 between the IP and the RPs, such that all particles scattered at the same angle are focused to the same position in the detector, independent of their production vertex position. This focusing is only achieved in the vertical plane.\nThe beam optics parameters are needed for the reconstruction of the scattering angle \u03b8 at the IP. In elastic scattering at high energies the four-momentum transfer t is calculated\nFig. 2 A sketch of the experimental set-up, not to scale, showing the positions of the ALFA Roman Pot stations in the outgoing LHC beams, and the quadrupole (Q1\u2013Q6) and dipole (D1\u2013D2) magnets situated between the IP and ALFA. The ALFA detectors are numbered A1\u2013 A8, and are combined into inner stations A7R1 and A7L1, which are\ncloser to the IP, and outer stations B7R1 and B7L1. The arrows in the top panel indicate the beam directions and in the bottom panel the scattered proton directions. The stations A7R1 and B7R1 measure the scattered protons along the outgoing LHC beam 1 line (C-side) while stations A7L1 and B7L1 cover the outgoing LHC beam 2 line (A-side)\nfrom \u03b8 by:\n\u2212 t = (\u03b8 \u00d7 p)2 , (2) where p is the nominal LHC beam momentum of 6.5 TeV [11] and \u03b8 is reconstructed from the proton trajectories in ALFA. The trajectories are measured in the beam coordinate system, where the transverse positions x and y are determined relative to the nominal orbit. A formalism based on transport matrices relates the positions and angles of particles at two different points of the magnetic lattice.\nThe trajectory (w(\u03be), \u03b8w(\u03be)), where w \u2208 {x, y} is the transverse position at a distance \u03be from the IP and \u03b8w is the angle in the w direction between the particle trajectory and the nominal orbit, is given by the transport matrix M and the coordinates at the IP (w , \u03b8 w): (\nw(\u03be)\n\u03b8w(\u03be)\n) = M ( w\n\u03b8 w\n) = (\nM11 M12 M21 M22\n)(\nw\n\u03b8 w\n)\n. (3)\nHere the elements of the transport matrix can be calculated from the optical function \u03b2 and its derivative with respect to \u03be and . The transport matrix M must be calculated separately in x and y and depends on the longitudinal position \u03be ; the corresponding indices have been dropped for clarity. The focusing properties of the beam optics in the vertical plane enable a reconstruction of the scattering angle with good precision using only M12, but in the horizontal plane the phase advance is close to 180\u25e6 and different reconstruction methods are investigated.\nThe ALFA detector was designed to use the \u2018subtraction\u2019 method, exploiting the fact that for elastic scattering the par-\nticles are back-to-back, so that the scattering angles on the A-side and C-side are the same in magnitude and opposite in sign, and that the protons originate from the same vertex. The beam optics was optimized to maximize the lever arm M12 in the vertical plane to access the smallest possible scattering angle. The positions measured with ALFA on the A-side and C-side of ATLAS have the same magnitude to within 50\u2013100 \u00b5m but opposite signs, and in the subtraction method the scattering angle is calculated according to:\n\u03b8 w = wA \u2212 wC\nM12,A + M12,C . (4)\nThe measurements from inner and outer stations are averaged in y to obtain the final value of \u03b8 . The subtraction method is the nominal method in both planes and yields the best t-resolution. In contrast to previous analyses using 90 m optics [3,4], the lever arm M12 in the horizontal plane at the inner stations is so small that its contribution to the scattering angle determination introduces an unacceptable degradation of the resolution. Therefore, a method named \u2018subtraction light\u2019 is used instead, which uses y everywhere in the \u03b8 - reconstruction but ignores the x-measurement at the inner stations and only uses x at the outer stations. However, the x measurement is used for event selection purposes and for the local track angle used in the method described below.\nAn alternative method for the reconstruction of the horizontal scattering angle uses the \u2018local angle\u2019 \u03b8w of the tracks measured between the inner and outer stations on the same side: \u03b8 w = \u03b8w,A \u2212 \u03b8w,C\nM22,A + M22,C . (5)\nAnother method performs a \u2018local subtraction\u2019 of measurements at the inner station at 237 m and the outer station at 245 m, separately on the A-side and C-side, before combining the two sides:\n\u03b8 w,S = M24511,S \u00d7 w237,S \u2212 M23711,S \u00d7 w245,S M24511,S \u00d7 M23712,S \u2212 M23711,S \u00d7 M24512,S , S = A, C.\nFinally, the \u2018lattice\u2019 method uses both the measured positions and the local angle to reconstruct the scattering angle by the inversion of the transport matrix (\nw\n\u03b8 w\n) = M\u22121 ( w\n\u03b8w\n)\n,\nand from the second row of the inverted matrix the scattering angle is determined to be\n\u03b8 w = M\u2212121 \u00d7 w + M\u2212122 \u00d7 \u03b8w. The lattice method yields a scattering angle measurement at each station, and the average value is taken for the treconstruction. All methods using the local angle suffer from limited resolution due to a moderate angular resolution of about 5 \u00b5rad. These alternative methods are nevertheless used to cross-check the subtraction method and determine beam optics parameters.\nFor all methods, t is calculated from the scattering angles as follows:\n\u2212 t = (\n(\u03b8 x ) 2 + (\u03b8 y )2\n)\np2, (6)\nwhere \u03b8 y is always reconstructed with the subtraction method, because of the parallel-to-point focusing in the vertical plane, while the four methods are used for \u03b8 x .\n3.2 Data taking\nSince the high-\u03b2 runs are very different from the standard LHC runs, a few test fills were performed to find acceptable beam parameter settings. The minimum accessible value tmin is influenced by three parameters: the\u03b2-function, the distance of the detectors from the beam trajectory, and the beam emittance. It is expressed in the following formula:\n|tmin| = p 2 \u00b7 n2 \u00b7 N\n\u03b2 ,\nwith the beam momentum p, the detector transverse position as a multiple n of the beam width \u03c3 = \u221a \u00b7 \u03b2, the (normalized) emittance ( N and the value of the \u03b2-function at the IP, \u03b2 .\nTo achieve a |tmin| value of a few times 10\u22124 GeV2 for the given beam momentum of 6.5 TeV and \u03b2 = 2.5 km, the detectors need to be placed at a distance of 3\u03c3 from the beam trajectory. The target value for the emittance was about 1 \u00b5m.\nTo achieve acceptable conditions for recording physics data, several collimator settings were tested. The tight collimator positions induced shower particles by interactions with halo particles. The main challenge in the data taking was the handling of the rapid increase of background for elastic triggers.\nThe final procedure was to scrape the beam with the primary vertical collimators to 2\u03c3 of the beam width and position the RPs at 3\u03c3 . The collimators were then retracted to 2.5\u03c3 to reduce the impact of shower particles from their edges. In addition the secondary vertical and horizontal collimators were used to optimize the background conditions.\nDue to LHC machine protection requirements, the total beam intensity in the high-\u03b2 runs is limited to 3\u00b71011 protons per beam. A filling scheme of five bunches with 6 \u00b7 1010 protons each was used in all fills. For background studies in the first fill, one pair of non-colliding bunches was used.\nAfter the LHC was filled, the energy was ramped up to 6.5 TeV and \u03b2 was de-squeezed to 2.5 km. The next step was the beam-based alignment (BBA). In this procedure, the RP windows scrape the beam edge and the resulting signals in the beam loss monitors [12] are used to determine the beam trajectory. All RP and collimator positions are given in terms of the beam width \u03c3 relative to the measured beam trajectory.\nWhen the BBA procedure was finished, the collimators were moved to their final positions and the RPs were set at the 3\u03c3 positions, corresponding to a distance between the RP window facing the beam and the beam orbit of about 0.5 mm. The detectors themselves were about 0.3\u20130.4 mm further away from the beam orbit due to the RP window thickness and the gap towards the detector edge.\nThe evolution of the background fraction was monitored by the ratio of background to elastic trigger rates. If the background rate reached the level of the elastic rate the RPs were retracted slightly and a re-scraping to a beam width of 2\u03c3 was performed. Depending on the beam intensity, this procedure was repeated after 30\u201390 min. The fill was dumped when the elastic rate fell below 1 Hz.\nIn four fills (5313, 5315, 5317, 5321), which each lasted between 10 and 24 h, a total integrated luminosity of about 340 \u00b5b\u22121 was collected. The luminosity and the recorded number of elastic-scattering candidates for the individual fills and runs are given in Sect. 5.1.\nThe emittance was regularly measured by wire scans and a dedicated synchrotron light monitor. After injection, typical values of the horizontal and vertical emittances were below 1 \u00b5m. After ramp-up and de-squeezing, these values grew to about 1.1 \u00b5m for the vertical emittance and about 2.5 \u00b5m for the horizontal emittance. The measured emittance and its time evolution are taken into account in the event simulation model described in Sect. 4.2.\nA dedicated trigger menu was used to record the sample of elastic interactions, and also the various diffractive and back-\nground samples needed for systematic studies. The collection of elastic events is based on conditions which require in each spectrometer arm a trigger signal in at least one detector in the stations at opposite sides of the central ATLAS detector. For background studies, a similar trigger pattern was used but it combined all upper or lower detectors of all stations, which excludes elastic events by construction. The trigger efficiency was derived from a minimum-bias sample, which is based on a single trigger signal from any ALFA detector. For the selected data sample, the data acquisition dead time was below 0.3% and the trigger efficiency was above 99.97%. An extensive software suite [13] is used in the reconstruction of data, in detector operations, and in the trigger and data acquisition systems of the experiment.\n3.3 Track reconstruction and alignment\nThe tracks of the elastically scattered protons are reconstructed in the ALFA main detectors. The tracks are reconstructed individually in each ALFA detector. The reconstruction method takes advantage of the fact that the tracks left by the elastically scattered protons are almost parallel to the beam. Then, one can neglect the slope of the trajectory and focus on the determination of its position only. Because the layers are staggered, the position is constrained by the geometrical overlap of the fired fibres projected separately on the u and v directions. A track is required to consist of hits in at least three overlapping fibres in each direction (an elastically scattered proton typically fires 18\u201319 fibres in a detector).\nReconstruction of the event kinematics requires knowledge of the transverse position of the tracks relative to the beam. A transformation from the detector-related u and v coordinates to the x and y coordinates relative to the beam requires a good understanding of the detector position: the rotation of the detector around the beam axis,2 the horizontal offset between the centre of the detector and the centre of the beam, and the vertical distance between the detector and the beam.\nInformation about the horizontal offset and the rotation angle is obtained from the analysis of distributions of elastically scattered protons (see Sect. 5.1 for details of the event selection). The (x, y) distribution of the positions of these protons at a given RP station has an elliptical shape centred around the beam and is elongated in the y direction. The two detectors of the station, upper and lower, measure fragments of this ellipse. For a correctly calculated horizontal offset, the average value of the x position, \u3008x\u3009, should be zero. For a correctly determined rotation of the detector, no correlation should be observed between x and y. The alignment procedures are based on measurements of \u3008x\u3009 and how \u3008x\u3009 depends\n2 Other possible rotations only affect track positions at the level of rotation angle squared and are neglected.\non y. The resulting alignment corrections are applied iteratively until the detectors are fully aligned.\nThe information about the vertical distance between each detector and the centre of the beam is obtained from several sources. First, the distance between the upper and lower detectors is measured using data collected by the ALFA overlap detectors, which are placed on the sides of the main detectors and extend below the beam for the upper RP and above the beam for the lower RP [5]. A simultaneous measurement of traversing particles by the upper and lower detectors allows the determination of their relative position in the vertical direction.\nThe measurement using the overlap detectors provides the vertical distance between the upper and lower detectors, i.e. the sum of their distances to the beam centre. The determination of the position of the beam between the detectors is again based on a basic property of the (x, y) distribution of elastically scattered protons, namely that it has an up\u2013down mirror symmetry. Part of the alignment procedure is to search for a vertical beam offset that equalizes the y distributions (corrected for the reconstruction efficiency, see Sect. 5.3) in the upper and lower detectors.\nThe alignment analysis presented above was performed separately for different detectors and data-taking periods, resulting in a range of values and corresponding uncertainties for each parameter. Table 1 summarizes the obtained results.\nThe dominant systematic uncertainty for the rotation angle originates from ignoring the underlying fibre structure of the detectors. This structure can induce a bias in the reconstructed hit pattern at a scale comparable to the spatial resolution. The magnitude of this effect is estimated by varying the fiducial volume in which the alignment analysis is performed. The statistical uncertainty is at a similar level. The total uncertainty of the horizontal offset is dominated by the systematic component, evaluated by changing the method of extracting the centre of the distribution.\nThe uncertainty for the vertical distance is dominated by the systematic component originating from our imperfect knowledge of how the overlap detectors are positioned relative to the main detectors, from the choice of statistical method used to extract the distance value, and from the event selection. The dominant source of systematic uncertainty for the vertical offset is related to the choice of method for testing the compatibility of the distributions, and this uncertainty is similar in size to the statistical uncertainty.\nThe next step of the alignment analysis exploits the fact that the kinematics of an elastic-scattering event are fully described by only two parameters, meaning that a measurement of the proton position in one detector fully constrains the kinematics. This measurement can then be extrapolated to all other detectors of the same elastic arm. The properties of the LHC optics used for these measurements, especially its parallel-to-point focusing in the vertical plane, make this\nextrapolation very precise in the y coordinate. Comparing the extrapolated position with the measured one provides further constraints on the vertical alignment. The analysis showed a need for distance corrections at different stations of up to 55 \u00b5m, which is larger than the estimated distance uncertainties, suggesting that they are underestimated. One possible explanation is a non-zero average angle of the particles traversing the overlap detectors, which would lead to a bias in the distance measurement.\nThe above steps of the alignment analysis are based on the same principles and techniques as used in the previous ALFA measurements [3,4]. However, the final analysis presented in this paper is very sensitive to the distance uncertainties. Therefore, additional steps for vertical alignment were introduced to ensure sufficient precision. Once the relative positions of all detectors within each elastic arm are fixed using the precise extrapolations discussed above, the two remaining parameters are the global vertical distance between the two arms and the global vertical position of the beam between them.\nThe global vertical distance is found by performing the complete analysis presented in this paper (see Sect. 5) assuming different values of the global vertical distance. A fit to the differential elastic cross section is performed using only statistical uncertainties. The \u03c72 of the fit, considered as a function of the global vertical distance, has a clear minimum whose position determines the final vertical distance used in the analysis. This correction is found to be 86 \u00b5m. It is added to the distance determined by averaging the distance measurements from individual stations. The uncertainty is evaluated to be 22 \u00b5m, with the largest contribution originating from the variation of the luminosity within its uncertainty (see Sect. 5.6).\nIt is worth noting that the sensitivity of the \u03c72 value to distance originates from the very good acceptance of the ALFA detectors down to the region dominated by the Coulomb interaction, which is well understood. Performing the analysis with misaligned detectors affects the measured distribution, making it incompatible with our knowledge of the physics that governs the behaviour of the t-spectrum in this range, thus increasing the \u03c72.\nAs the final step of the alignment, the vertical position of the beam between the elastic arms is fine-tuned by equalizing the t-spectra measured in the two arms. The principle is similar to that for the measurement per station discussed above,\nbut when performed at the arms level the resulting uncertainty is improved to 4\u201315 \u00b5m, with corrections of the order of 12\u201327 \u00b5m (depending on the data-taking period). The uncertainty is dominated by two systematic components of similar size related to the details of testing the compatibility of the distributions and to the uncertainty of the reconstruction efficiency in the two arms.\n4 Simulation model for elastic scattering\n4.1 Theoretical predictions\nElastic scattering is related to the total cross section through the optical theorem (Eq. (1)) and the differential elastic cross section is obtained from the scattering amplitudes of the contributing diagrams:\nd\u03c3 dt = 1 16\u03c0 \u2223 \u2223 \u2223 fN(t) + fC(t)ei\u03b1\u03c6(t) \u2223 \u2223 \u2223 2 . (7)\nHere, fN is the purely strong-interaction amplitude, fC is the Coulomb amplitude, \u03b1 is the fine-structure constant, and a phase \u03c6 is induced by long-range Coulomb interactions [14,15]. In the simplest model elaborated in Ref. [15] the individual amplitudes are given by\nfC(t) = \u22128\u03c0\u03b1h\u0304cG 2(t)\n|t | , (8)\nfN(t) = (\u03c1 + i) \u03c3tot h\u0304c e \u2212B|t | 2 ,\nwhere G is the electric form factor of the proton and B is the nuclear slope. The value of fN(0) follows from the optical theorem, while the t-dependence is the simplest parameterization, which is valid only at small |t |. A possible generalization of Eq. (8) that incorporates a t-dependent slope consists of the introduction of additional terms C proportional to t2 and D proportional to |t |3\nfN(t) = (\u03c1 + i) \u03c3tot h\u0304c e \u2212B|t |\u2212Ct2\u2212D|t |3 2 , (9)\nparameterizing the curvature of the t-spectrum at large |t |. Their effect is most visible in between \u2212t = 0.05 GeV2 and \u2212t = 0.2 GeV2. At smaller |t |, the slope of the tspectrum is essentially constant and well parameterized by exp (\u2212B|t |/2), and at very large |t | beyond 0.2 GeV2 the\nform of the spectrum changes when approaching the diffractive dip, which is a local minimum in the t-spectrum generated by the interference of diffractive amplitudes. It is located around 0.5 GeV2 in 13 TeV pp collisions and followed by a local maximum, called the bump. At yet larger |t |-values the spectrum continues to fall steeply.\nDepending on the number of terms included in the exponential function, three different models are considered for parameterization of the nuclear amplitude; they are referred to as the B-model with validity up to \u2212t = 0.04 GeV2, the BC-model with validity up to \u2212t = 0.1 GeV2 and the full BCD-model with validity up to \u2212t = 0.2 GeV2. The validity ranges are approximate and were empirically determined by studying the quality of a fit to the data.\nThe theoretical form of the t-dependence of the cross section is obtained by evaluating the square of the complex amplitudes, following Eqs. (7), (8), and (9):\nd\u03c3 dt = 4\u03c0\u03b1\n2(h\u0304c)2\n|t |2 \u00d7 G 4(t)\n\u2212\u03c3tot \u00d7 \u03b1G 2(t)\n|t | [sin (\u03b1\u03c6(t)) + \u03c1 cos (\u03b1\u03c6(t))]\n\u00d7e \u2212B|t |\u2212Ct 2\u2212D|t |3 2 + \u03c3 2tot 1 + \u03c12\n16\u03c0(h\u0304c)2 \u00d7 e\n(\u2212B|t |\u2212Ct2\u2212D|t |3), (10)\nwhere the first term corresponds to the Coulomb interaction, the second to the Coulomb\u2013nuclear interference (CNI), and the last to the hadronic interaction. This parameterization is used to fit the differential elastic cross section to extract the physics parameters \u03c3tot and \u03c1, and the terms B, C and D relevant to the nuclear slope, depending on the model. This simple parameterization of the differential elastic cross section has been criticized by the authors of Ref. [16]. The criticism is based upon the fact that the formula has only been derived for a constant B-slope and is thus in principle not valid when the curvature terms C and D are introduced. However, in Ref. [17] it is shown that the formula is still valid at a level of 10\u22123 in \u03c1 given this kind of t-dependence of the slope.\nThe theoretical prediction given by Eq. (10) also depends on the Coulomb phase \u03c6 and the form factor G. This analysis uses a conventional dipole parameterization of the proton electric form factor from Ref. [18]\nG(t) = ( + |t | )2 ,\nwhere = 0.71 GeV2. The uncertainty in the electric form factor is derived by comparing the simple dipole parameterization with more sophisticated forms [19], which better describe the high-precision low-energy electron\u2013proton elastic-scattering data [20]. An expression for the Coulomb\nphase was initially derived in Ref. [15]\n\u03c6(t) = \u2212 ln B|t | 2 \u2212 \u03c6C, (11)\nwhere the model-dependent Coulomb phase shift \u03c6C was taken to be \u03b3E = 0.577. Further corrections, primarily from the form factor, were calculated in Ref. [18] and the expression nominally used in this analysis is\n\u03c6(t) = \u2212 ( \u03b3E + ln B|t | 2 + ln ( 1 + 8 B ))\n+4|t |\n\u00b7 ln 4|t | \u2212\n2|t |\n. (12)\nUncertainties in the Coulomb phase are estimated by replacing the parameterization in Eq. (12) by the simple form in Eq. (11). This change has only a minor impact on the crosssection prediction. Replacing the dipole by other forms also has a negligible impact on the determination of the physics parameters.\nIn the present theoretical framework, a constant nuclear phase is assumed between the real and imaginary parts of the nuclear amplitude. In Ref. [17], various alternative tdependent nuclear phase models are discussed which would entail a t-dependence of the \u03c1 parameter. The models suggested in Ref. [17] are considered for systematic uncertainty purposes, excluding an extreme model featuring a peripheral phase. The model with the largest impact is a simple model in which the \u03c1-value vanishes at \u2212t = 0.1 GeV2\narg fN(t) = \u03c0 2\n\u2212 arctan ( \u03c1(0) (\n1 + t 0.1\n))\n. (13)\n4.2 Simulation model\nMonte Carlo (MC) simulated events are used to calculate acceptance and unfolding corrections. A fast simulation is used in which the detector resolution is parameterized and tuned to data and the elastically scattered protons are passed through the LHC lattice by means of the beam transport 2 \u00d7 2 matrix according to Eq. (3). The detector geometry is described by a set of simple requirements. The fast simulation offers convenient methods to tune the relevant detector and beam parameters, in terms of resolution and beam divergence, to measured control observables. The generation of elastic-scattering events is performed with a simple \u2018toy\u2019 MC simulation. For each event, a t-value is randomly drawn from a probability density function representing the theoretical model. The nominal model, named BCD, includes the small-|t | parameterization in Eq. (10) with three slope parameters B, C and D. The parameters of the event generation model are summarized in Table 2. The values of the slope parameters, and also \u03c3tot and \u03c1, were iteratively adjusted in the analysis and are close to the final results. The\nvalidity of this model is limited to relatively small \u2212t values, |t | < 0.2 GeV2, which is of relevance for the physics parameter determination in this analysis. The acceptance of the present data set does not cover the dip, but a parameterization based on the model introduced by Ref. [21] to describe this region is used for |t | > 0.2 GeV2.\nThe simulation model also includes the relevant LHC beam parameters that describe the width of the production vertex distribution, the intrinsic beam energy spread, and the beam divergence at the IP. The last is of particular importance, as the angular divergence contributes to the scattering angle resolution. The divergence is inferred from a combination of measurements of the beam emittance from wire scans performed by the LHC beam instrumentation, from the beam width measured by the ATLAS inner detector, and in the vertical plane directly from ALFA angular measurements. The resulting beam divergence is implemented per plane, per beam, and per run and, in addition, the time-dependent emittance growth during the runs is incorporated.\nA fast parameterization of the detector response is used for the detector simulation, with the spatial resolution tuned to the measured resolution. The resolution is measured by extrapolating tracks reconstructed in the inner stations to the outer stations using beam optics matrix-element ratios and comparing predicted positions with measured positions. Thus, it is a convolution of the resolutions in the inner and outer stations. The fast simulation is tuned to reproduce this convolved resolution. A full Geant4 [22] simulation is used to set the resolution scale between detectors at the inner and outer stations, which cannot be determined from the data.\n5 Data analysis\n5.1 Event selection\nAll data used in this analysis were recorded in September 2016 with a beam optics of \u03b2 = 2.5 km in four fills of the LHC resulting in seven ATLAS runs. An event preselection consisting of data quality, trigger and recon-\nstruction requirements was applied, resulting in a sample of elastic-scattering candidates. Data quality requirements were applied to ensure that the ALFA detector was fully operational. Only data recorded outside of the scraping periods are taken into account. Furthermore, only periods of the data taking where the dead-time fraction was below 5% are used. The luminosity-weighted average dead-time fraction is below 0.3%. These requirements eliminate less than 5% of the data.\nEvents are required to pass the trigger conditions for elastic-scattering events, and have a reconstructed track in all four detectors of the arm which fired the trigger. Events with additional tracks in detectors of the other arm arise from the temporal overlap of halo protons with elastic-scattering protons and are retained. If halo and elastic-scattering protons overlap in the same detectors, which happens typically only on one side, a track-matching procedure [3] between the detectors on each side is applied to identify the elastic track.\nFiducial cuts to ensure good containment inside the detection area are applied to the vertical coordinate. Tracks must be at least 60 \u00b5m away from the edge of the detector nearer the beam, where the full detection efficiency is reached. The cut at the detector edge determines the smallest accessible value of |t |. At large vertical distance, the vertical coordinate must be at least 1 mm away from the shadow of the beam screen, a protection element of the quadrupoles, in order to minimize the impact from showers generated in the beam screen.\nFurther geometrical cuts on the left\u2013right acollinearity are applied, exploiting the back-to-back topology of elasticscattering events. Figure 3 shows the correlation between left-side (A-side) and right-side (C-side) positions measured in the vertical plane.\nThe elastic-scattering candidates are observed in a narrow region along the diagonal, and events are selected in a band of 2 mm width, as indicated by the red lines in Fig. 3. In the horizontal plane the position difference between the left and right sides must be within 3.5\u03c3 of its resolution determined from simulation. An efficient cut against non-elastic background is obtained from the correlation of the local angle between two stations and the position in the horizontal plane, as shown in Fig. 4, where elastic-scattering events appear inside a broad ellipse with positive slope, whereas background is concentrated in a narrow ellipse with negative slope or in the band in the top-right quadrant. A similar selection is also applied in the vertical plane, where elastic events are selected in a band in the local angle of 40 \u00b5rad width. The selection requirements are summarized in Table 3, alongside the number of events that meet the requirements at each step of the event selection for the longest run. A total of 6.9 million events were selected. The selection efficiency relative to the preselection is about 94%. The fraction of elastic pile-up events, where two elastic events from the same bunch crossing are\nobserved in two different arms, is about 0.20/00. The numbers of selected elastic-scattering candidates per run are summarized in Table 4.\n5.2 Background determination\nA small fraction of the background is expected to be inside the fiducial volume defined by the event selection cuts. The background contributions can be clearly observed e.g. in Fig. 4, where the elastic core populates the interior of the elliptical contour, whereas distinct patterns seen as narrow or wide bands constitute background from different sources. A fraction of the background extends into the selected area and thus constitutes an irreducible component that needs to be subtracted from the reconstructed t-spectrum. The fraction of background events is very small and its subtraction has little impact on the results.\nTwo types of background are considered: non-elastic physics background processes from central diffraction, also known as double-Pomeron exchange (DPE) pp \u2192 pp + X , and accidental coincidences of either halo protons on both sides or a halo proton on one side and a proton from single diffraction (SD) on the other side. Other combinations involving double diffraction or protons from non-diffractive processes in conjunction with a halo proton are not considered, given the overall small level of background. The strategy for the determination of the background is to use a data-driven template method for the halo+halo and halo+SD estimation and a MC simulation for DPE. The DPE simulation is based on the MBR model [23], which predicts a total DPE cross section of 0.82 mb at 13 TeV. The event generation for DPE is done with nominal MBR settings as implemented in Pythia"
        },
        {
            "heading": "8.303 [24].",
            "text": "In the data-driven method used to calculate the contribution from accidental coincidences, events with tracks only"
        },
        {
            "heading": "5313 308979 21.38 423 862 84.82 \u00b1 0.56 83.11 \u00b1 0.87",
            "text": ""
        },
        {
            "heading": "5313 308982 6.81 136 499 85.84 \u00b1 0.54 84.44 \u00b1 0.55",
            "text": ""
        },
        {
            "heading": "5314 309010 41.27 846 581 87.11 \u00b1 0.51 85.00 \u00b1 0.64",
            "text": ""
        },
        {
            "heading": "5317 309039 120.08 2 409 968 85.45 \u00b1 0.49 83.23 \u00b1 0.52",
            "text": ""
        },
        {
            "heading": "5317 309074 44.31 887 373 85.55 \u00b1 0.39 83.48 \u00b1 0.48",
            "text": ""
        },
        {
            "heading": "5321 309165 55.87 1 149 499 87.08 \u00b1 0.40 85.41 \u00b1 0.44",
            "text": ""
        },
        {
            "heading": "5321 309166 50.17 1 043 576 88.28 \u00b1 0.38 86.43 \u00b1 0.45",
            "text": "on one side of the experiment are selected, and those with activity on the opposite side are vetoed. The veto suppresses contributions from elastic events and the sample composition is thus dominated by halo and SD events. Then a background template is constructed by randomly mixing uncorrelated single-sided events from the left side and right side, corresponding to the background from accidental coincidences. The absolute normalization of the templates is obtained by comparing the number of events in the data and the template in control regions, before applying the event selection cuts. The procedure is illustrated in Fig. 5, where the correlation between the horizontal track position and the local angle is shown in data, in DPE simulation and in the templates. The normalization region is depicted in Fig. 5a showing the correlation in data between the horizontal position and local angle in the horizontal plane. The events are counted outside of the shaded area in the upper right corner and the elliptical elastic signal region. The non-shaded normalization region is dominated by background from accidental coincidences of halo protons and free of elastic events. Simulated DPE events shown in Fig. 5b contribute very little to this area, but a large fraction of accidental coincidences from the eventmixing templates shown in Fig. 5c lie in the normalization region. The templates are scaled such that the number of events in this region equals the number of events in the data. The irreducible background for selected events is then calculated by applying the nominal event-selection cuts to the properly scaled template events.\nAlso, the normalization for simulated DPE events is determined from the data by counting events in a region of the correlation between the vertical coordinate on the A-side and Cside (not shown). The selected normalization region is mostly populated by DPE events. About 10% of the data events in the normalization area originate from accidental coincidences, which are subtracted before calculating the DPE scaling factor.\nThe resulting background estimate is illustrated in Fig. 6 for Arm 1, which shows that the overall level of background is very small and dominated by DPE, except at small |t | where the accidental coincidences prevail. In previous analyses at \u03b2 = 90 m [3,4] a procedure called the \u2018anti-golden\u2019 method was applied, in which events collected in all upper or all lower detectors were used to estimate the irreducible background in the sample of elastic-scattering candidates. This method is not used in the present analysis because the detectors are much closer to the beam and even small vertical beam offsets (up to 80\u00b5m, see Sect. 3.3) introduce an asymmetry between the arms that is not reproduced by the anti-golden method.\nThe resulting background level is 0.750/00 on average with very small differences between the different runs. Systematic uncertainties are estimated by changing the normalization regions, the template composition, and the parameters of the DPE simulation. The nominal normalization region for accidental coincidences shown in Fig. 5 in the plane of x and \u03b8x is changed to a region in the plane of x on the A-side and C-side, which exhibits a different type of correlation. The template composition is varied by imposing a veto on minimum-bias triggers from the central ATLAS detector, thereby depleting the SD content of the templates. The normalization regions for the DPE background are varied in a similar way. In addition, the DPE background shape is changed by varying the value of the Pomeron intercept in the simulation from 0.02 to 0.15. Varying this MBR parameter was found to have the largest impact on the DPE shape. The total background uncertainties are dominated by systematic uncertainties and range from 10.4 to 14.8%.\n5.3 Reconstruction efficiency\nThe reconstruction efficiency accounts for the elastic events which cannot be fully reconstructed because of the following effects and which therefore need to be excluded from the analysis. The development of a hadronic shower in the\nRoman Pot may lead to configurations where the proton track cannot be reconstructed in one or more of the four detectors. Also, an overlap with a halo proton or SD proton can lead to reconstruction failures, particularly if these background protons have initiated a shower either in the Roman Pot material or upstream as a result of a collimator scattering or beam\u2013 gas interaction. The large majority of failed reconstructions are thus related to events with a hit multiplicity that is too large, in which no meaningful tracks can be determined. The probability of reconstruction failing because of too few hits is in contrast very low, since for the regular reconstruction\nonly three good layers out of ten in u and v are required and the single-layer efficiency is about 90% [5].\nThe number of elastically scattered protons that are lost is estimated by a data-driven tag-and-probe method. This method exploits the back-to-back topology of elastic events, allowing a proton to be tagged on one side of the spectrometer and probe the reconstruction on the other side. The probability that an elastic event is fully reconstructed is given by the reconstruction efficiency:\n\u03b5rec = Nreco/(Nreco + Nfail),\nwhere Nreco is the number of fully reconstructed elasticscattering events, which have at least one reconstructed track in each of the four detectors of a spectrometer arm, and Nfail is the number of not fully reconstructed elastic-scattering events that have reconstructed tracks in fewer than four detectors. Events are grouped into several reconstruction cases, for which different selection criteria and corrections are applied, to determine if an event is from elastically scattered protons, but was not fully reconstructed because of inefficiencies.\nBoth the fully reconstructed and failed events need to have an elastic trigger signal present and need to be inside the acceptance region. The efficiency is determined separately for the two spectrometer arms. Based on the number of detectors with at least one reconstructed track, the events are grouped into six reconstruction cases called topologies named 4/4, 3/4, 2/4, (1 + 1)/4, 1/4 and 0/4. The first number in this notation indicates the number of detectors with at least one reconstructed track. In the 2/4 case, both detectors with tracks are on one side of the IP and in the (1 + 1)/4 case they are on different sides.\nElastic events for all cases are selected with the event selection described in Sect. 5.1, using the subset of cuts available to each particular topology. The tag-and-probe method relies on the very high efficiency of the trigger scintillator (\u03b5trig > 99.9%) to tag the activity of events in the four detectors of an arm. The activity is quantified by the number of hits, which must be more than five. Then selection cuts are applied to detectors with reconstructed tracks to accept events as elastic or reject them as background. Not all cuts can be applied\nto every case because limitations may make them impossible to apply, e.g. left\u2013right correlation cuts in the 2/4 case. This results in an overestimation of the elastic event yield and a reduced background rejection efficiency, which is accounted for by a phase-space correction derived from simulation. Because of the reduced set of cuts available for topologies with failed reconstructions, the background rejection is less efficient and more background is present, particularly in the 2/4 topology.\nThe background strategy follows the method applied to \u2018golden\u2019 4/4 events and described in Sect. 5.2: two background contributions from DPE events and accidental halo+SD events are considered, where both are normalized in control regions specific to the topology. The single-side templates for the accidental coincidences are extended to also include events where only one detector has a reconstructed track. For the cases where only two or fewer detectors have reconstructed tracks, particularly the 2/4 case, the background from accidental coincidences becomes important, with a similar contribution from the DPE background. For the cases with only one or no detector with reconstructed tracks, the tracking information is not sufficient for event classification, and the expected yields are calculated with a probabilistic method [3] based on cases with reconstructed tracks in two or more detectors. Taking into account background subtraction and phase-space corrections, the final reconstruction efficiency calculation can be cast in the following equation:\n\u03b5rec = N4/4 \u2212 B4/4( N4/4 \u2212 B4/4 ) + N3/4\u2212B3/4PS(3/4) + N2/4\u2212B2/4PS(2/4) + N(1+1)/4\u2212B(1+1)/4 PS((1+1)/4) + Nlower , (14)\nwhere Bj/4 denotes the background, PS the phase-space correction and Nlower merges the background-subtracted topologies calculated by the probabilistic method. The t-spectra after background subtraction and with phase-space corrections are shown for different topology classes in Fig. 7. The shape of the spectra for topologies with failed reconstruction is in good agreement with the shape of 4/4 cases, except for the 2/4 case where at large |t | values the background, mostly from DPE, is slightly overestimated. This leads to a bias, which is taken into account in the systematic uncertainty (see Fig. 10). The final reconstruction efficiency calculated per run and per arm according to Eq. (14) is shown in Fig. 8. The values are around 85%, and are typically about 2% higher for Arm 1 than for Arm 2 because of a slightly different material distribution [3]. The results are summarized in Table 4 for both arms. The systematic uncertainties range between 0.4% and 0.9% and are dominated by the composition of the templates for accidental coincidences and uncertainties in the background subtraction. The former are evaluated by applying different\nveto conditions and by increasing and decreasing the SD fraction in the template; the latter are calculated by varying the background normalization regions; and in both cases the procedure described in Sect. 5.2 is followed.\nThe reconstruction efficiency has a time dependence, both within a run and between runs. This time dependence is correlated with the number of halo protons overlapping in time with protons from elastic scattering. Every proton, be it from elastic scattering, an SD event or the beam halo, has a certain probability to develop a hadronic shower; thus in events with\noverlapping protons the shower probability is approximately twice as high as in events with only one proton per detector. The correlation between the reconstruction efficiency and the number of overlapping halo events is illustrated in Fig. 9, where \u03b5rec is plotted as a function of the fraction of multi-track events. Each point in Fig. 9 corresponds to a datataking period between beam scrapings. Multi-track events are defined as events with a selected elastically scattered proton in each detector and an additional reconstructed track in any of the four detectors. Different sources can create additional tracks, such as cross-talk, but these are time-independent, whereas additional tracks from the halo exhibit a strong time dependence. Therefore, the time-variation of the multi-track fraction is dominated by the halo overlap, which induces the clear correlation with \u03b5rec, shown in Fig. 9. The reconstruction efficiency is nominally assumed to be independent of the t-value because of the uniform material distribution across the detection surface. However, a possible t-dependent bias could be introduced, through deficiencies in the background subtraction method for the 2/4 topology. A model of this possible t-dependence, shown in Fig. 10, is used to assess an additional systematic uncertainty.\n5.4 Acceptance and unfolding\nThe acceptance is defined as the ratio of events at particle level passing all geometrical and fiducial acceptance cuts defined in Sect. 5.1 to the total number of generated events, and is calculated as a function of t . The differential elastic cross section is corrected for acceptance losses. The calcu-\nlation is carried out with the simulation model described in Sect. 4.2. The acceptance is shown in Fig. 11 for each arm. The shape of the acceptance curve can be understood from the contributions of the vertical and horizontal scattering angles to t (see Eq. (6)). The smallest accessible value of |t | is obtained at the detector edge and set by the vertical distance of the detector from the beam. Close to the edge, the acceptance is small because a fraction of the events are lost due to the beam divergence, i.e. events inside the acceptance on one side but outside on the other side. At small |t |, up to\n\u2212t \u223c 0.15 GeV2, vertical and horizontal scattering angles contribute about equally to a given value of t . Larger |t |- values imply larger vertical scattering angles and larger values of |y|, and with increasing |y| the fraction of events lost in the gap between the main detectors decreases. The maximum acceptance is reached for events occurring at the largest possible values of |y| within the beam-screen cut. Beyond that point the acceptance decreases steadily because the events are required to have larger values of |x |, since these t-values are dominated by the horizontal scattering angle component. The difference between the two arms is mainly related to the vertical beam offset, which brings the detectors of Arm 2 closer to the beam, thereby increasing the acceptance. Meanwhile, events at large |y| are shadowed by the beam screen, decreasing the acceptance for Arm 2 at large |t |.\nThe measured t-spectrum is distorted by detector resolution and beam smearing effects, including angular divergence, vertex smearing and energy smearing. These effects change the shape of the reconstructed t-spectrum, particularly at small |t | as shown in Fig. 12, which also shows how detector resolution effects depend strongly on the reconstruction method. The magnitude of the matrix elements used in the t-reconstruction relative to the detector spatial and angular resolutions determines the performance of a method. While the subtraction method receives only small contributions from the detector resolution, which is good for the space coordinate measurement, all other methods suffer from\na sizeable degradation once detector resolution is included. The degradation arises from the local angle being poorly measured, given that the 8 m distance between the two stations is too small to obtain good precision.\nAfter background subtraction, the measured t-spectrum in each arm is corrected for migration effects using an iterative, dynamically stabilized unfolding method [25]. MC simulation is used to obtain the migration matrix shown in Fig. 13 that is used in the unfolding. The superior resolution of the subtraction method means the migration almost ends only one or two bins away from the diagonal, whereas a few more non-diagonal elements are populated for the local angle method. For the subtraction method the impact on the t-spectrum is very small and confined to the first few bins, whereas for the local angle method the corrections are slightly larger and flat for \u2212t > 10\u22123 GeV2. Overall, the impact of the resolution on the reconstructed t-spectrum is negligible, except for very small |t | at the detector edge, where the beam divergence is important. The very first bin at smallest |t | is dominated by divergence effects. The events that contribute to this bin have a small vertical scattering angle and would, in the absence of divergence, be outside of the acceptance defined by the vertical cut close to the detector edge. The divergence-induced angular smearing folded with the steeply falling scattering angle distribution causes many more events to migrate into that bin than out of it.\nThe results are cross-checked using an unfolding method based on the singular value decomposition method [26]. The unfolding procedure is applied to the distribution obtained using all selected events, after background subtraction in each elastic arm. A data-driven closure test is used to evaluate any bias in the unfolded data spectrum shape due to mis-modelling of the reconstruction-level spectrum shape in the simulation. The simulation is reweighted, according to a polynomial function parameterizing the data/MC difference, at particle level such that the reconstruction-level spectrum in simulation matches the data. The modified reconstructionlevel simulation is unfolded using the original migration matrix, and the result is compared with the modified particlelevel spectrum. The resulting bias is considered as systematic uncertainty; it is very small.\nThe unfolding procedure introduces a statistical correlation between the bins of the t-spectrum, which is incorporated in a covariance matrix included when fitting the data.\n5.5 Beam optics\nThe reconstruction of the t-value requires knowledge of the elements of the transport matrix. The transport matrix can be calculated from the design of the 2.5 km beam optics, which consists of a sequence of the beam elements including the alignment parameters of the magnets, the magnet currents and the field calibrations. This initial set of matrix\nelements is referred to as the \u2018design optics\u2019. Small corrections, allowed within the range of the systematic uncertainties, need to be applied to the design optics for the measurement of the physics parameters, following a procedure developed in Refs. [3,4]. Constraints on beam optics parameters are derived from the ALFA data, exploiting the fact that the reconstructed scattering angle must be the same for different reconstruction methods using different transport matrix elements. The beam optics parameters are determined from a global fit, using these constraints, with the design optics as a starting value. The tuned parameters are the field strengths of the quadrupoles, quantified by the k-values, located between the IP and ALFA, and named Q1\u2013Q6 (see Fig. 2), in beam 1 and beam 2. For the 2.5 km beam optics, the following kvalues are tuned to fulfil the ALFA constraints: a single kvalue correction for Q1 and Q3, because they are connected to a common power line, and independent k-values for Q5 and Q6. In the fit, the k-values for beam 1 and beam 2 are treated as independent parameters, resulting in a total of six fitted parameters.\nReconstructed tracks from elastic-scattering events are used to derive two classes of data-driven constraints on the beam optics:\n\u2022 Correlations between A-side and C-side measurements of positions or angles, and between positions or angles measured in the inner and outer stations of ALFA on the same side. These are used to infer the ratio of matrix elements in the beam transport matrix. The resulting constraints are independent of any optics input. \u2022 Correlations between the reconstructed scattering angles. These are calculated using different methods to derive further constraints on matrix elements as scaling factors. These factors indicate the amount of scaling needed for a given matrix element ratio to equalize the measurements of the scattering angle. These constraints depend on the given optics model. The design beam optics with quadrupole currents measured during the run is used as a reference to calculate the constraints.\nFor each constraint, the bias induced by the measurement method because of resolution or acceptance effects is estimated by evaluating the constraint in simulation and comparing the value with that from the design optics. An additive correction is then applied to the constraint values obtained from data before comparison with beam optics calculations. These corrections are generally small and at the level of a few per mille.\nA stringent constraint from the second class is illustrated in Fig. 14. This example shows the comparison of the scattering angle in the horizontal plane reconstructed with the subtraction method, Eq. (4), which is based on the position and M12,x , and the local angle method Eq. (5), which is based on\nthe local angle and M22,x . Figure 14 shows the difference in scattering angle between the two methods as a function of the scattering angle determined with the subtraction method. The slope is extracted using a linear fit in the central region (red line). This slope is used as the scaling factor for the matrix element ratio M12/M22. Its value of about 1% indicates that the design optics ratio M12,x/M22,x needs to be increased\nby 1% to obtain the same scattering angle, on average, from both methods using data.\nA total of 21 constraints were determined from the ALFA data. A sub-set of 17 constraints with the best precision are normally included in the \u03c72 calculation of the fit, four constraints with larger experimental uncertainties and less constraining power are not included but kept for control. All ALFA constraints are treated as uncorrelated in the fit, but coherent changes in the constraints observed under experimental variations of the analysis are taken into account in the systematic uncertainty. In the minimization procedure, the beam optics calculation program MadX [27] is used to extract the optics parameters and to calculate the matrix element ratios for a given set of magnet strengths. The ALFA system provides precise constraints on the matrix element ratios, but cannot probe the deviations of single magnets. There are, therefore, several sets of optics parameters which minimize the \u03c72, arising from different combinations of magnet strengths. The chosen configuration, called the effective optics, is one solution among many. Different sets of quadrupoles are included in the fit, and a variation of the choice of set represents the main contribution to the systematic uncertainty. Figure 15 shows the pull of the ALFA constraints after the minimization, which resulted in magnet strength corrections ranging from 0.1 to 0.6%, with rather large differences between beam 1 and beam 2, most notably for Q6 with a negative correction of \u22120.62% in beam 1 and a positive correction of 0.13% in beam 2. The \u03c72 of the fit includes the systematic uncertainties of the constraints and is of good quality with \u03c72/Ndof = 0.45. The resulting change in the transport matrix elements most important for t-reconstruction is up to 1%.\nSystematic uncertainties for the k-values and matrix elements include the coherent change of constraints under experimental variations. A total of 13 variations, including the nominal constraints obtained from the average of the arms and the constraints from individual arms, are taken into account and the standard deviation of the resulting distribution is assigned as an uncertainty. The dominant systematic uncertainty with the largest impact on the t-reconstruction is obtained when treating only the k-values of Q5 and Q6 as free parameters in the fit, which still results in an acceptable fit quality.\n5.6 Luminosity\nThe general methods for luminosity determination in ATLAS are described in Ref. [6]. However, a dedicated measurement is required due to the special \u03b2 = 2.5 km optics resulting in different conditions shown in Table 5. The ATLAS general strategy to provide a reliable luminosity determination and to properly assess the systematic uncertainties is to compare the measurements of different detectors and algorithms. This section describes the luminosity determination for this run and its systematic uncertainty using LUCID (LUminosity measurement with a Cherenkov Integrating Detector) [28] as the baseline alongside approaches using the Beam Conditions Monitor (BCM) [29] and the Inner Detector (ID) [9] of ATLAS. Each detector and each algorithm is calibrated in special van der Meer (vdM) scans [30], except the track counting algorithm, which is cross-calibrated to LUCID in parts of the vdM scan run with head-on collisions. Table 5 summarizes the differences between high-\u03b2\nruns, high-luminosity runs and vdM scans. Such differences\nare due to the number of colliding bunches and the average numbers of interactions per bunch crossing (pile-up parameter \u03bc), leading to an instantaneous luminosity in the high \u03b2\nregime which is up to seven orders of magnitude lower than in high-luminosity running, and three orders of magnitude lower than in the vdM scans.\nThe algorithms listed in Table 6 were used in the final analysis. They were chosen as having the sensitivity needed for high-\u03b2 runs and at the same time exhibiting the most favourable background conditions. Both LUCID and the BCM have detectors on both the A-side and C-side of the ATLAS IP. The A-side detectors were not used in OR-mode due to high background on the A-side. The track-counting algorithm using ID data is independent of LUCID and the BCM. The track-counting algorithm obtains the per-bunch visible interaction value \u03bcvis from the mean number of reconstructed tracks per bunch crossing averaged over a luminosity block, which corresponds to a period of about one minute with approximately constant luminosity. The track measurements used in this analysis are based on the TightModLumi3\nworking point [6]; they are available for only two of the ALFA runs (308979 and 309165).\nLUCID_EventORC_BI, being the most stable algorithm with favourable background conditions, was chosen as the reference algorithm and the other algorithms are used to evaluate the systematic uncertainties. The percentage differences with respect to the reference algorithm are shown in Fig. 16 for all runs as a function of the run number. This is a key plot in the context of evaluating the systematic uncertainties. The main sources of systematic uncertainty are the vdM calibra-\n3 The TightModLumi working point is named 2017 selection in Ref. [6].\nTable 5 Main parameters for high-\u03b2 runs, vdM scans and high-luminosity runs [6]\nAlgorithm Definition L int [\u00b5b\u22121] Deviation [%] LUCID_EventORC_BI Activity on the C-side in LUCID 339.9 \u00b1 0.1 \u2013 LUCID_EventAND_BI Activity on both sides in LUCID \u2013 \u2013 LUCID_EventORC_BI2 Activity on the C-side in LUCID 341.1 \u00b1 0.1 +0.4 LUCID_EventAND_BI2 Activity both sides in LUCID 341.2 \u00b1 0.2 +0.4 BCM_T_EventAND Activity on both sides in the BCM 337.2 \u00b1 0.2 \u22121.8 TightModLumi Track counting using the Inner Detector \u2013 \u2013\ntion uncertainty, calibration transfer uncertainty, long-term stability uncertainty and background uncertainty.\nvdM calibration uncertainty: This source of uncertainty is the same as for the standard luminosity analysis, and in 2016 it was evaluated to be 1.1% [6], while the central value of the calibration was updated for this analysis, applying the techniques described in Ref. [6].\nCalibration transfer uncertainty: This arises because the vdM scans are performed at a luminosity 103 times higher than the luminosity during the ALFA data taking (see Table 5). Any non-linearity between the vdM-scan and\nALFA-run luminosity regimes would appear as systematic deviation between algorithms in the stability plot shown in Fig. 16. It is therefore included in the deviations of the various independent algorithms from the reference one.\nLong-term stability uncertainty: Unlike the standard data taking, the period with high-\u03b2 runs was very short, lasting only a few days. Nevertheless, these runs were acquired four months after the vdM-scan session and about one month before a vdM-like scan, the so-called MD1814 scan. The stability of the detectors and algorithms from the time of the vdM-scan session was evaluated through the comparison between these two scans, and it is reflected in the stability plot of Fig. 16. Thus, no additional uncertainty is needed to account for the long-term stability.\nBackground uncertainty: The single-beam background to the luminosity signal, as estimated from unpaired bunches, appears negligible for all LUCID and BCM algorithms used in this analysis. There is no sign of collision background for the chosen algorithms. A more quantitative constraint on collision background can be inferred from the internal consistency, over the entire ALFA running period, of measurements reported by five independent luminosity algorithms with very different intrinsic background sensitivity. Therefore, the internal consistency of the measurements displayed in Fig. 16 implicitly sets an upper limit on the possible impact of collision backgrounds on the reported integrated luminosity.\nThe total systematic uncertainty of the luminosity measurement can be obtained from the absolute calibration uncertainty of the vdM scan and from the stability and consistency\namong the various algorithms. Figure 16 shows the deviation of the luminosity from the value given by the reference algorithm run by run. However, the run-integrated luminosity is most relevant for the determination of \u03c3tot. The runintegrated luminosity measured by the various algorithms is compared with the reference LUCID_EventORC_BI value. This provides the uncertainty related to all listed effects: calibration transfer, long-term stability and background. The biggest deviation in the run-integrated luminosity is found to be \u22121.8% for the BCM_T_EventAND algorithm. Unfortunately, the TightModLumi track-counting algorithm was only available in two runs. The TightModLumi runintegrated luminosity in these two runs deviates from the value given by reference LUCID algorithm by 1.85%. This number is therefore taken as the stability and consistency uncertainty.\nAdding in quadrature the uncertainty in the absolute calibration (1.1%) and that associated with the stability and consistency of the available independent luminosity measurements (1.85%), a total systematic uncertainty of 2.15% is obtained for the integrated luminosity delivered during the seven high-\u03b2 runs.\nThe final value of the integrated luminosity is therefore:\nL int = 339.9 \u00b1 0.1 (stat.) \u00b1 7.3 (syst.) \u00b5b\u22121."
        },
        {
            "heading": "6 Results",
            "text": "6.1 The differential elastic cross section\nSeveral corrections are applied to calculate the differential elastic cross section. The corrections are made individually per run and per arm before combining all runs and the two arms in the final differential elastic cross section. In a given bin ti , the cross section is calculated according to the following formula:\nd\u03c3 dti = 1 ti \u00d7 M \u22121[Ni \u2212 Bi ] Ai \u00d7 rec \u00d7 trig \u00d7 DAQ \u00d7 L int ,\nwhere ti is the bin width, M\u22121 represents the unfolding procedure applied to the background-subtracted number of events Ni \u2212 Bi , Ai is the acceptance, rec is the event reconstruction efficiency, trig is the trigger efficiency, DAQ is the dead-time correction and L int is the integrated luminosity used for this analysis. The binning in t is chosen to be appropriate for the experimental resolution and statistical uncertainty. At small |t | the selected bin width is two times the resolution. At larger |t | the bin width is increased to compensate for the lower number of events from the exponentially falling distribution. The resulting differential elastic cross section obtained using the subtraction method is shown in Fig. 19\nand numerical values with uncertainties are summarized in Tables 12 and 13 in the Appendix.\nExperimental systematic uncertainties\nSeveral variations of the analysis are performed under different experimental conditions in order to assess the systematic uncertainties. For certain sources, several variations potentially probing the same effect are considered. From these variations, the largest deviation from the nominal cross section is retained as the systematic uncertainty. A total of 20 sources of uncertainty are propagated to the differential elastic cross section as follows:\n\u2022 For the alignment, separate uncertainties are calculated for different components of the alignment procedure. The dominant uncertainty is related to the global correction to the distance parameter determined by the procedure described in Sect. 3.3, and the correction is varied by its total uncertainty. For the vertical beam offset, the uncertainties are assumed to be fully correlated between inner and outer stations but anti-correlated between the left and right sides, and thus systematic shifts preserve the internal consistency of the data. Uncertainties related to the horizontal offset and to the rotation are propagated directly to the differential cross section, where both the full-correlation and anti-correlation assumptions were tested. The resulting uncertainties are rather small and similar for the two correlation assumptions, and the larger one is retained as the nominal uncertainty. \u2022 The nominal effective optics model with corrections to the strength of Q1, Q3, Q5 and Q6 is replaced by a simplified model in which only Q5 and Q6 are tuned (see Sect. 5.5). This alternative optics model yields by far the largest cross-section difference with respect to the nominal beam optics. Several other uncertainties related to the input optics constraints, to the inclusion of Q2 and Q4 in the fit and a variation of their strength by its uncertainty, to the quadrupole alignment and to the propagation of the intrinsic effective optics fit are considered as a stability test. These gave rise to very small changes in the cross section which were not included in the systematic uncertainty. \u2022 The beam transport in the simulation nominally achieved with the transport matrix is replaced by the symplectic PTC transport module in MadX [27], where the quadrupole strengths of the effective optics were fed into a MadX strength file. The difference between PTCtracking and matrix transport also accounts for the simplification in the effective optics fit where a beamline set-up was used, as opposed to the multi-turn ring set-up nominally used in MadX for LHC simulations.\n\u2022 The nominal crossing angle for the 2.5 km campaign was zero, but the measurement of the crossing angle by the beam position monitors around IP1 has a limited precision estimated to be 10 \u00b5rad. A residual noncompensated crossing angle in the vertical plane with parallel-to-point focusing beam optics would cause a shift of the beam position at ALFA. Such a shift would trivially be corrected by the alignment procedure. In the horizontal plane, a crossing angle would also shift the beam centre and, in addition, broaden the beam distribution. The latter effect is assessed by applying a crossing angle in the MadX beam transport simulation and then used for acceptance and unfolding corrections in the analysis. \u2022 The nominal beam energy value of p = 6500 GeV is varied by its uncertainty of 0.1% [11] simultaneously in the data for t-reconstruction according to Eq. (2), and in the simulation both at the generator level and again in the t-reconstruction. \u2022 The emittance model used to calculate the angular divergence in the simulation is varied by its uncertainty of the order of 10%, and the time dependence of the emittance is replaced by a luminosity-weighted average. \u2022 In the simulation the nominal model for the t-spectrum with three slope parameters B, C , D (see Sect. 4.1) is replaced by a model with a constant exponential slope B. \u2022 The value of the \u03c1-parameter in simulation is varied by \u00b10.01, corresponding to its uncertainty (see Sect. 6.2). \u2022 The detector resolution in the simulation is varied, replacing the resolution determined from the collision data with values 3\u20134 \u00b5m smaller, as predicted from the Geant4 simulation, and 4\u20135 \u00b5m larger, as measured using test-\nbeam data. Additionally, a small y-dependence (10%) of the resolution observed in the data is parameterized and used instead of the nominal constant value. \u2022 The uncertainty in the background from accidental coincidences is calculated from a variation of the normalization regions and template composition. For DPE the normalization region is also varied and the shape is changed in the simulation, as explained in Sect. 5.2. \u2022 The intrinsic unfolding uncertainty is determined from the data-driven closure test explained in Sect. 5.4. \u2022 The event reconstruction efficiency is varied by its uncertainty discussed in Sect. 5.3. Furthermore, a possible tdependence of the reconstruction efficiency is taken into account. \u2022 The luminosity uncertainty of 2.15% is propagated to the cross section (see Sect. 5.6). \u2022 For the tracking efficiency, the minimum number of fibre layers in both u and v required to reconstruct a track is varied between three and four (see Sect. 3.3).\nThe systematic uncertainties related to the sources above are calculated using the offset method. In this method, the nominal value of a certain parameter in the analysis chain is varied according to the assigned uncertainty. The shift in bin ti for systematic uncertainty source k, \u03b4k(ti ) = d\u03c3k(ti )/dt \u2212 d\u03c3nominal(ti )/dt is recorded, keeping track of the sign and thereby accounting for correlations across the t-spectrum. Systematic shifts are included in the fit used to determine the physics parameters, as outlined in Sect. 6.2. The systematic t-dependent shifts for the differential elastic cross section are shown in Figs. 17a, b and 18a, b for the entire range of the tspectrum. The dominant systematic uncertainties at small |t | are related to the vertical alignment, detector resolution and\npossible t-dependent reconstruction efficiency; the second and third effects are also important at large |t |.\n6.2 Fitting procedure\nThe physics parameters, total cross section, \u03c1-parameter and the slope parameters are obtained from a fit of the theoretical spectrum (Eq. (10)), including the CNI term, to the measured differential cross section. Both the statistical and systematic uncertainties as well as their correlations are taken into account in the fit. The statistical correlations are included in the covariance matrix calculated in the unfolding procedure. The correlations of systematic uncertainties are taken into account by using a profile minimization procedure [31], where nuisance parameters corresponding to all 20 systematic shifts are included, and the \u03c72 is given by:\n\u03c72 = \u2211\ni, j\n[( D(i) \u2212 ( 1 + 2 \u2211\nl=1 \u03b1l\n)\n\u00d7 T (i) \u2212 18 \u2211\nk=1 \u03b2k \u00d7 \u03b4k(i)\n)\n\u00d7V\u22121(i, j) \u00d7 ( D( j) \u2212 ( 1 + 2 \u2211\nl=1 \u03b1l\n)\n\u00d7 T ( j) \u2212 18 \u2211\nk=1 \u03b2k \u00d7 \u03b4k( j)\n)]\n+ 18 \u2211\nk=1 \u03b22k +\n2 \u2211\nl=1\n\u03b12l\n2l ,\nwhere D(i) is the measured value of the elastic cross section in bin i , T (i) the theoretical prediction and V (i, j) the statistical covariance matrix. For each systematic uncertainty that changes the shape of the t-spectrum, a nuisance parameter \u03b2k multiplying the corresponding shift \u03b4k is fitted as a free parameter, and a penalty term \u2211\nk \u03b2 2 k is added to the\n\u03c72. Two scale parameters, \u03b1l , are used to describe the rescal-\ning of the normalization of the theoretical prediction due to the t-independent uncertainties in the luminosity and the reconstruction efficiency l . The sum in quadrature of these two scale factors divided by their uncertainties results in a second penalty term,\n\u22112 l=1 \u03b12l / 2l . The uncertainties in the\nphysics parameter values returned by the profile fit account for both the experimental systematic and statistical uncertainties. In the case of the time-dependent emittance model and the t-dependent reconstruction efficiency, the fit could somewhat constrain the nuisance parameters, resulting in slightly reduced systematic uncertainties. The differential cross section and the fitted theoretical prediction are shown in Fig. 19. The fit range is chosen from t = \u22124.5 \u00b7 10\u22124 GeV2 to t = \u22120.205 GeV2. The lower |t | value is chosen to be as close as possible to t = 0 to maximize the coverage of the CNI region while having an acceptance above 10%. The value chosen for the upper limit is motivated by theoretical considerations not to extend the fit into the region where the shape of the differential cross section is influenced by the approach of the dip. The main fit results are \u03c3tot = 104.7 \u00b1 1.1 mb and \u03c1 = 0.098 \u00b1 0.011; further details are summarized in Table 7.\nHere, the experimental uncertainty is obtained from the profile fit, the statistical component is calculated from a bootstrap method [32], and the theoretical uncertainties are discussed below.\n6.3 Theoretical uncertainties\nThe theoretical systematic uncertainty is calculated by changing the assumptions of the model used in the profile fit (see Sect. 4.1). The parameterization of the nuclear amplitude, nominally using three slope parameters B, C and D\nin the exponential term, is reduced to two parameters B and C and to a single constant slope B. In each case the upper end of the fit range is progressively reduced in order to obtain a good description of the data. Further variations include changes in the parameterization of the electric form factor of the proton and of the Coulomb phase, as well as the inclusion of a term related to the magnetic moment of the proton, which induces a spin dependence in the Coulomb amplitude [33]. For the nuclear phase, several assumptions about the possible t-dependence were investigated. The systematic uncertainty is calculated with a simple model of a t-dependence according to Eq. (13). Other nuclear phase models suggested in Ref. [17] were also evaluated, but were not taken into account in the uncertainty calculation. Among\nthese, the largest change is observed when using a peripheral phase, but according to Ref. [17] this phase model represents an extreme case with a large change increasing with |t |. The resulting theoretical uncertainties are summarized in Table 8.\nThe presence of a t-dependent slope in the data requiring an extension of the simple exponential model \u223c exp (\u2212B|t |) used in previous analyses [3,4] with less constraining data is illustrated in Fig. 20. The plot shows the differential crosssection data normalized to a reference exponential fit in the range from \u2212t = 0.04 GeV2 to \u2212t = 0.2 GeV2 where the effect is most visible. Other models fitted in the same range but with a t-dependent slope are normalized to the same reference and found to describe the data better, with one additional parameter C giving a satisfactory description up to \u2212t = 0.1 GeV2 and the full BCD-model up to \u2212t = 0.2 GeV2. The regime beyond \u2212t = 0.2 GeV2 is characterized by the onset of diffractive interference phenomena leading to the dip, which requires a different type of parameterization [21,34].\n6.4 Stability checks\nSeveral cross-checks of the analysis are performed in order to verify the stability of the results. A test for possible time dependence is performed by repeating the analysis separately for each run in the campaign. The results shown in Fig. 21 demonstrate that the physics parameters determined per run are compatible with one another and with results from the time-integrated combined data set. A very basic test probing the sensitivity to different fitting options consists of a simple fit that uses only the statistical covariance matrix in the definition of \u03c72. The result given in Table 9 shows good agreement with the profile fit. There are small shifts of the central values which originate from different weights of the bins inside the fit range when systematic uncertainties are omitted, the latter having a different t-shape than statistical uncertainties.\nIndependent measurements are performed in each arm of ALFA, and are combined before fitting the physics parameters. The fits can, however, also be done per arm for the subsample collected in that arm, in which case the acceptance is reduced roughly by a factor of two. In order to test\nTable 8 Systematic uncertainties originating from the choice of model fitted to the data. Details of the models for the nuclear phase can be found in Ref. [17]. The simple phase model is included in the systematic uncertainty calculation, and the other nuclear phase model results are given for reference\nVariation \u03c3tot [mb] \u03c1 B [GeV\u22122] C [GeV\u22124] D [GeV\u22126]\nBC 0.04 0.0018 \u2013 \u2013 \u2013\nB 0.09 0.0047 \u2013 \u2013 \u2013\nForm factor 0.01 0.0022 0.01 < 0.1 0.1\nSpin dependence < 0.01 0.0013 < 0.01 < 0.1 < 0.1\nCoulomb phase 0.02 0.0030 < 0.01 < 0.1 < 0.1\nSimple phase 0.05 < 0.0001 0.01 < 0.1 0.1\nTotal theoretical 0.12 0.0064 0.01 0.04 0.15 Peripheral phase 0.21 \u2212 0.0060 0.80 7.3 12.2 Durand-Ha phase 0.02 < 0.0001 0.01 < 0.1 0.2\nStandard phase 0.02 < 0.0001 < 0.01 < 0.1 0.1\nBailly phase 0.01 < 0.0001 < 0.01 < 0.1 < 0.1\nFig. 20 The data normalized to a reference exponential function compared to models of the nuclear amplitude with a t-dependent exponential slope. The error bars include the statistical uncertainty only\nthe consistency of the measurements in the two arms, the same standard fit range used in the nominal combined analysis is applied, although the acceptance per arm is below 10% in the first bin. This test is carried out with a fit including only statistical uncertainties. The difference between the arms is found to be consistent with the arm-dependent vertical offset and reconstruction efficiency uncertainties.\nAs outlined in Sect. 3.1, the t-value can be reconstructed with four different methods, with the subtraction method being the nominal method. Different methods use different combinations of the transport matrix in the reconstruction. Table 10 reveals good consistency among the methods, with the small differences being within the beam optics uncertainty.\nFinally the dependence of the fit results on the choice of fit range was investigated. Both the upper and lower ends of the fit range were varied. The largest change was found when the lower end of the fit range was moved to \u2212tmin = 1.26 \u00b7 10\u22123 GeV2 where a resulting shift of 0.2 mb for \u03c3tot and of 0.0017 for \u03c1 was observed with negligible changes in the slope parameters. Moving the upper end of the fit range to \u2212tmax = 0.15 GeV2 had little impact on \u03c3tot and \u03c1, but changed the slope parameter C by 1.2 GeV\u22124 and the slope parameter D by 4.7 GeV\u22126. These changes are significantly smaller than the quoted experimental uncertainties.\n6.5 Elastic and inelastic cross sections, and \u03c3el/\u03c3tot\nThe total elastic cross section measured inside the fiducial volume is obtained by integrating the observed differential elastic cross section in the available t range from \u2212t = 2.5\u00d7 10\u22124 GeV2 to \u2212t = 0.46 GeV2. The result is \u03c3 obsel = 27.80 \u00b1 0.09 (stat.) \u00b1 0.64 (syst.) mb. This measurement accounts for both the strong interaction and electromagnetic interaction in the CNI region. For the extrapolation to the full phase space, a common approach is to use only the nuclear part of the fit, which in the past typically consisted of only a single exponential term \u223c exp(\u2212B|t |), and to integrate from zero to infinity. The Coulomb interaction needs to be disregarded in this approach because only the hadronic part of elastic scattering is to be integrated. In this analysis, the nuclear amplitude parameterization is extended to include the curvature parameters C and D and the integration is carried out numerically from zero to 1000 GeV2, neglecting the part of the cross section at higher |t |. The result is\n\u03c3 extrel = 27.27 \u00b1 1.10 (exp.) \u00b1 0.30 (th.) mb,\nwhere the first uncertainty is propagated from the profile fit and thus includes experimental systematic and statistical uncertainties and the second uncertainty accounts for the model dependence. The same integration can also be restricted to the measurement range and reveals that a contribution of about 0.75 mb can be attributed to electromagnetic interactions inside the fiducial volume. The fact that the observed cross section in the fiducial volume is larger than the cross section extrapolated to full phase space is related to the large contribution from Coulomb scattering in the small-|t | region of the fiducial volume.\nThe total integrated (hadronic) inelastic cross section is obtained by subtracting the extrapolated elastic cross section from the total cross section. The result is\n\u03c3inel = 77.41 \u00b1 1.07 (exp.) \u00b1 0.18 (th.) mb,\nwhere again the uncertainty, taking into account correlations, is propagated from the profile fit to the total and extrapolated elastic cross sections in the first error, and the second error represents the theoretical uncertainties. This result from ALFA can be compared with the ATLAS measurement of the inelastic cross section using the MBTS [35], which is \u03c3inel = 78.1 \u00b1 2.8 mb, where the uncertainty is dominated by the extrapolation to full phase space covering the diffractive region with protons of momentum loss p/p < 5\u00b710\u22126. The two measurements are compatible within the uncertainties.\nAnother derived quantity is the ratio of the elastic cross section to the total cross section,\n\u03c3el \u03c3tot = 0.257 \u00b1 0.008 (exp.) \u00b1 0.009 (th.).\nThe normalization uncertainty between \u03c3el and \u03c3tot is correlated and partly cancels out in the ratio. The value of this\nratio should asymptotically approach 1/2 in the black-disk limit (see Sect. 7.2), a value that the present measurement is far below. A study of the ratio\u2019s energy evolution may reveal additional aspects of strong interactions in low-momentum transfer reactions.\n6.6 Absolute luminosity calibration\nThe initial goal for ALFA was to provide an absolute calibration of the luminosity [36]. The method requires covering the CNI region of the t-spectrum to gain sensitivity to the Coulomb interaction, which is independent of \u03c3tot. In the nuclear regime the normalization is fully correlated with the total cross section and an independent measurement of luminosity and \u03c3tot is impossible. The good CNI-coverage of the present data set allows an evaluation of this method, as demonstrated recently in Ref. [1]. Because the differential elastic cross section normalized by the luminosity from LUCID was used to constrain the alignment, this absolute calibration test can only be used to assess the achievable precision.\nDifferent fitting strategies were considered for luminosity calibration. In the actual implementation, one more parameter xL is introduced as a multiplicative factor to the nominal luminosity and is fitted together with the five physics parameters over the nominal fit range. For this study a fit including only statistical uncertainties is used and the result for xL is\nxL = 1.008 \u00b1 0.020 (stat.) \u00b1 0.059 (syst.), where the first uncertainty is purely statistical and the second accounts for the experimental systematic uncertainties. For the other physics parameters, values compatible with the nominal values are found. The experimental systematic uncertainties are obtained by repeating the fit under the same variations of the analysis that were taken into account for the nominal profile fit, except for the luminosity uncertainty. The systematic uncertainty of xL is dominated by the distance uncertainty (0.038) and the possible t-dependence of the reconstruction efficiency (0.039), whereas all other uncertainties are much smaller and when added in quadrature amount to 0.027. The dependence on the fit range was also investigated and a variation of its lower end induces a change of 0.035 in xL and the upper-end variation induces a change of 0.014. These changes are well covered by the quoted uncertainty.\nAnother fit option consists of a separation of the fits in two steps. In the first step, the slope parameters are fitted at large |t | between \u2212t = 0.01 GeV2 and \u2212t = 0.2 GeV2 with nominal luminosity in a region where the data have a negligible sensitivity to \u03c1. The actual value of \u03c1 used in the fit was verified to have no impact on the slope parameters B, C and D. In the second step, the values of the parameters B, C and D determined in the first step are fixed and a fit is\nperformed in the complementary small-|t | region from \u2212t = 4.5 \u00b7 10\u22124 GeV2 to \u2212t = 0.01 GeV2 with \u03c3tot, \u03c1 and xL as free parameters. The result from this fit set-up is\nxL = 1.017 \u00b1 0.021 (stat.) \u00b1 0.061 (syst.). The results are thus rather similar to those from the sixparameter simultaneous fit, with marginally larger uncertainties. Also, the dependence on the fit range is similar, with the exception of the variation of the lower end of the fit range, which induces a slightly larger change in xL . The alternative absolute luminosity calibration with ALFA revealed the expected consistency with the nominal luminosity, presented in Sect. 5.6, based on the LUCID detector with vdM calibration, but the 2.15% precision of the latter is far better."
        },
        {
            "heading": "7 Interpretation",
            "text": "7.1 Energy evolution of \u03c3tot and \u03c1\nElastic scattering is a low-pT process, and a perturbative expansion cannot be applied. Therefore, \u03c3tot and the \u03c1parameter cannot be calculated from first principles in QCD. Nonetheless, the fundamental principles of analyticity of the elastic-scattering amplitude, crossing symmetry, and unitarity must be respected, which are captured by dispersion relations. Dispersion relations connect the energy evolution of the \u03c1-parameter with the energy evolution of \u03c3tot.\nThe COMPETE Collaboration [2] provides global fits to elastic-scattering measurements in pp, p p\u0304 and other beamparticle collisions from low energies of around 5 GeV to LHC energies and above. The pp case at high energies is of interest here. At high energy, they use a crossing-even amplitude (C+), which implies that the p p\u0304 and pp cross sections converge asymptotically. This amplitude is based upon the Pomeron concept and a double and triple pole is assumed, leading to an energy evolution of \u03c3tot combining ln s and ln2 s terms. COMPETE does not use a crossingodd amplitude (C\u2212) corresponding to the so-called Odderon. Recently, the t-spectrum measured in pp collisions at the LHC by TOTEM was extrapolated to the Tevatron energy and compared with the direct measurement of the p p\u0304 spectrum by D0 to claim evidence for the Odderon [37].\nFigures 22 and 23 show the world data for \u03c3tot and \u03c1 together with the new result from ALFA. Also shown in these figures are the predictions of the COMPETE model (black lines), taken from the PDG [38], and of other models discussed below. The COMPETE prediction corresponds to their latest global fit for \u03c3tot and \u03c1, which includes all data available up to 7 TeV and also the TOTEM point at 8 TeV.\nThe new ALFA measurement of \u03c1 is compatible within uncertainties with the recent TOTEM measurement [1], but the TOTEM value of the total cross section is about 5.8 mb\nhigher than the ALFA measurement. The difference between ALFA and TOTEM corresponds to a discrepancy of about 2.2\u03c3 assuming uncorrelated uncertainties. This trend was already observed at 7 and 8 TeV and is confirmed at 13 TeV. The difference between the ALFA and TOTEM measurements of the differential elastic cross section is essentially confined to the normalization, whereas the shapes are mostly in good agreement.\nATLAS and TOTEM use quite different methods to obtain the absolute normalization. ATLAS uses the method outlined in Sect. 5.6 for a precise luminosity measurement, while TOTEM uses the so-called luminosity-independent method. The luminosity-independent method requires a simultaneous measurement of the total inelastic rate including a MC estimation of the non-measurable contribution from low-mass diffraction, which for TOTEM covers masses below 4.6 GeV.\nThe COMPETE prediction of \u03c3tot is in good agreement with the ALFA data at 13 TeV but it exceeds the \u03c1 measurements of ALFA and TOTEM by more than 3\u03c3 . One possible explanation for a lower \u03c1-value could be that \u03c3tot asymptotically grows slightly slower than the ln2 s evolution assumed by COMPETE. In the 1980s, Block and Cahn [39] and Bourrely and Martin (BCBM) [40] suggested the possibility of a damped ln2 s amplitude which gives an energy dependence of the form ln2 s/(1+\u03b1 ln2 s), where \u03b1 is the damping factor. The proposed amplitude modifies the high-energy behaviour of\u03c1 and\u03c3tot and the latter will asymptotically approach a constant value. Our global fit to the latest ALFA and TOTEM data together with lower-energy pp data using this amplitude and applying dispersion relations is shown by the blue dashed lines in Figs. 22 and 23. A fair description of the ALFA data is found for a damping factor \u03b1 = 0.0014. The damped-amplitude model was suggested in the context of\nputting limits on predictions of \u03c3tot at energies beyond the ISR and the amplitude was not derived from an underlying physics model. The damping factor was thus regarded as a measure of the energy scale where a possible deviation from ln2 s evolution might set in. Later, there were attempts to explain a slower rise of \u03c3tot in relation to Color Glass Condensate models [41].\nAn alternative way to generate a low \u03c1-value is to assume the existence of a crossing-odd amplitude. This would imply that differences between anti-particles and particles would prevail asymptotically. Such an amplitude generates a lower \u03c1-value for pp scattering and a higher value for p p\u0304 scattering relative to the crossing-even amplitude. This type of amplitude was first proposed in 1973, e.g. in Ref. [42]. Much later, the C\u2212 amplitude was associated with a three-gluon state in QCD, in contrast to the two-gluon state of the Pomeron.\nThe original proposal from 1973 was extreme in the sense that the strong interaction was assumed to be as strong as allowed by axiomatic field theory. This implies that not only the imaginary part of the scattering amplitude increases as ln2 s but also the real part. The corresponding model was named FMO [43] (the Froissaron Maximal Odderon) and is displayed in Figs. 22 and 23 (red lines). This model was tuned to the TOTEM data, which are well described, whereas the ALFA cross-section data at 7 and 8 TeV were discarded from the model tuning and are thus not well described. The FMO model generates a shift \u03c1 \u22120.04 at 13 TeV, whereas in Ref. [44] the Odderon contribution was estimated to be O(1 mb) and thus \u03c1 \u22120.01.\nFigures 22 and 23 show the result of the model constructed by the KMR group [45] (green dashed lines). This is a twochannel eikonal model with few parameters and it uses all available high-energy data for \u03c1 and \u03c3tot, as well as the cor-\nresponding differential elastic cross sections, and also all available measurements of low-mass diffraction. The latest TOTEM data at 13 TeV are also included as a constraint. For the calculation shown, they have only used a C+ amplitude and yet they get a reasonable description of \u03c1. They also estimate the contribution of the Odderon (not included in the figure) and find its contribution is only \u03c1 \u22120.005.\nFigures 22 and 23 also show the results of two other models. The HEGS (High Energy General Structure) model [46] (purple dotted lines) is based on reggenized gluon exchange and generalized parton distributions. Their estimate of the Odderon contribution is small [47]. The description of \u03c1 overshoots the experimental values of TOTEM and ALFA, but not as much as the COMPETE prediction. In their fit to the data, they have included all data up to 7 TeV and the point at 8 TeV from TOTEM.\nThe BJAS model (from the initials of the authors of Ref. [48] and shown by the light blue dotted-dashed lines) uses both a C+ amplitude and a C\u2212 amplitude. The\nC\u2212 amplitude resembles the Maximal Odderon and thus describes the \u03c1 data points very well at 13 TeV. This model has a distinct feature that the inelastic profile as a function of the impact parameter b has a small dip at b = 0, which can be interpreted as hollowness. All data available up to 13 TeV were used to determine the parameters of this model.\nTo better quantify the level of agreement between the models and the data, a \u03c72-comparison is presented in Table 11, using either all available data from pp collisions or the partial contributions from ALFA and TOTEM. COMPETE provides a good description of the data up to 8 TeV, but it fails to describe the 13 TeV \u03c1 data. The FMO model is overall in poorest agreement with the pp data and disagrees with the ALFA data, but it yields the best description of the TOTEM data, to which it was tuned. The BCBM model achieves the best overall description and is also in good agreement with the ALFA data but, given the discrepancy in the total crosssection data, is not in good agreement with TOTEM. For the\nother models, only discrete values are provided, and thus the comparison is restricted to the LHC range.\nThe conclusion drawn from these model comparisons is that it is difficult to separate possible effects from a flatter energy dependence of \u03c3tot and contributions from a possible C\u2212 contribution in the form of an Odderon. The fact that the size of the Odderon contribution is subject to large uncertainties complicates the matter further.\n7.2 Evolution of the ratio \u03c3el/\u03c3tot\nAt the highest energies hadron\u2013hadron scattering cross sections may asymptotically approach the geometrical size of the hadrons, a configuration which is referred to as the blackdisc limit. In this case, the elastic and inelastic cross sections become equal, and thus the ratio \u03c3el/\u03c3tot is 1/2. At present energies, this ratio is closer to 1/4 but an increase from the ISR to LHC energies is clearly observed. The energy evolution of \u03c3el/\u03c3tot is investigated in Fig. 24, where the new measurement at 13 TeV is compared with the values from TOTEM and lower energies. In order to guide the eye, the data are compared with a simple parameterization of \u03c3el [3,4] normalized to the COMPETE prediction of \u03c3tot. A set of consistent calculations of the ratio using \u03c3el and \u03c3tot calculated in the same framework are also shown in Fig. 24. The prediction from Block and Halzen [49] was derived before the LHC data was available and clearly overshoots the data as well as the BJAS prediction. The Block and Halzen model is only valid for data above 100 GeV. This is also true for the KMR model [45]. However, this model is in good agreement with the ATLAS data and also lower-energy data in the range of applicability.\n7.3 Inelastic cross section\nThe measurement of the inelastic cross section determined here is compared with the ALFA measurements in Run 1, direct measurements from ATLAS [35,50] and other experiments [38,51\u201356], together with generator predictions [57\u2013 59] and model calculations by KMR and BJAS in Fig. 25. The most precise measurement in the LHC energy range are the ALFA measurement followed by the TOTEM measurements. The other measurements, not using Roman Pots, have limited precision due to the fact that the full inelastic phase space is not covered and they have to rely upon theoretical models to extrapolate beyond the fiducial volume.\n7.4 Nuclear slope B\nIn the context of Regge field theory, the energy evolution of the nuclear slope at small |t | is related to the slope of the Pomeron Regge trajectory \u03b1\u2032. Taking B as the leading slope term at small |t |, its evolution with s is expected to be\nB = B0 + 2 \u00b7 \u03b1\u2032 ln ( s\ns0\n)\n.\nThe increase of the B slope corresponds to a reduction of the emission cone of elastically scattered particles, a phenomenon known as the shrinkage of the forward cone. It was verified that this linear relation is quite accurate at lower energy, where the scattering process is dominated by a single Pomeron exchange but the energy is still high enough for secondary Regge trajectories to be unimportant. However, at higher energies, in a situation with multi-Pomeron exchange, the increase of B is expected to be faster than linear and an additional term in ln2 (s/s0) may be needed to describe the evolution. This may be the case at the LHC, as pointed out in Ref. [60].\nIn the present analysis the t-dependence of the nuclear slope is taken into account, but in order to compare it with previous measurements at lower energy the leading slope parameter B is determined in a dedicated fit at small |t |, where the slope is approximately constant, without the curvature parameters C and D.\nIn Fig. 26 the LHC data are compared with lower-energy data and with the model in Ref. [60] (red line), which included only TOTEM data at 7 TeV for the LHC and a restricted selection of lower-energy data, particularly ISR data. Also shown in Fig. 26 is an attempt to repeat the fit with the same parameterization as in Ref. [60], but including all data (blue solid line). For comparison, a simple fit is also shown using only the linear term in ln (s/s0) (dashed blue line).\nWhile a quadratic energy evolution appears to be favoured by the data, it must also be concluded that the selection of lower-energy data has a significant impact on the shape of the evolution, and the fit including all data does not give a perfect description of the LHC data. A good description of the 7 and 8 TeV data is obtained with the selection in Ref. [60], but the prediction at 13 TeV is higher than the measurements.\nThe prediction of the BJAS model (light blue dasheddotted line) does not provide a good description of the nuclear slope\u2019s energy evolution, as can be seen in Fig. 26."
        },
        {
            "heading": "8 Conclusion",
            "text": "This paper presents measurements of the total cross section, \u03c1-parameter and nuclear slope parameters using elastic pp scattering data at \u221a s = 13 TeV recorded by the\nALFA subdetector of ATLAS in 2016 in a special LHC run with \u03b2 = 2.5 km optics, corresponding to an integrated luminosity of 340 \u00b5b\u22121. The analysis introduces dedicated data-driven methods to determine the relevant beam optics\nparameters, event reconstruction efficiency, simulation tuning and vertical Roman Pot alignment. The alignment precision achieved, about 22 \u00b5m, is required to determine the \u03c1-parameter, because the main sensitivity is at small |t | in the CNI region where the alignment has the largest impact.\nFrom a fit to the differential elastic cross section in the range from \u2212t = 4.5 \u00b7 10\u22124 GeV2 to \u2212t = 0.2 GeV2, the total cross section and \u03c1-parameter are determined to be:\n\u03c3tot(pp \u2192 X) = 104.68 \u00b1 1.08 (exp.) \u00b1 0.12 (th.) mb, \u03c1 = 0.0978 \u00b1 0.0085 (exp.) \u00b1 0.0064 (th.),\nwhere the first error accounts for all experimental systematic uncertainties and includes the statistical component, and the second is related to the model uncertainties. The experimental systematic uncertainty is dominated by the uncertainty in the luminosity and the alignment. This analysis included a dedicated luminosity determination for the \u03b2 = 2.5 km run, which is directly used to normalize the cross-section measurements. This new value of the total cross section is about 5.8 mb lower than the measurement from the TOTEM Collaboration, corresponding approximately to a 2.2\u03c3 tension, assuming uncorrelated uncertainties. A similar difference was already observed at 7 and 8 TeV. The main difference is traced back to the normalization of the differential elastic cross section measured by ATLAS and TOTEM.\nA study of the form of the t-spectrum revealed the need to introduce a t-dependent parameterization of the exponential nuclear slope (see Eq. (9)), assumed to be constant at 7 and 8 TeV. It is found in this analysis that with two more parametersC and D in addition to B used in previous measurements a satisfactory description is achieved; they are measured to be:\nB = 21.14 \u00b1 0.13 GeV\u22122, C = \u22126.7 \u00b1 2.2 GeV\u22124, D = 17.4 \u00b1 7.8 GeV\u22126.\nThe new data for \u03c3tot and \u03c1 are compared with lowerenergy data, and the energy evolution of these data is analysed in the context of model studies of the evolution. The widely used COMPETE model yields a good description of the ATLAS and lower-energy total cross-section data, but fails to describe the \u03c1 measurements at 13 TeV. The FMO model, tuned to the TOTEM data, featuring a maximal Odderon contribution in the nuclear amplitude, was also investigated and found to be in good agreement with the \u03c1 measurements but it exceeds the ATLAS total cross-section measurement. A simultaneous fit exploiting dispersion relations was performed to \u03c3tot and \u03c1 data, using the BCBM parameterization of a purely even but damped amplitude, and was found to give a good description of both \u03c3tot and \u03c1. This study shows that the commonly accepted energy evolution as implemented in the COMPETE model is in tension with the\n13 TeV elastic-scattering data. Nonetheless, further research is needed to understand whether the low value of \u03c1 can be attributed to the Odderon or other effects in strong interactions.\nThis analysis also measures the inelastic cross section, and its value is the most precise of the five available LHC measurements.\nThe ratio \u03c3el/\u03c3tot, a measure of the opaqueness of the proton, continues to grow slowly with energy, and its evolution is well described by the KMR model. The measurement remains far from probing the black-disc limit, i.e. a totally opaque proton.\nThe study of the evolution of the leading nuclear slope B confirms the tendency already found at 7 and 8 TeV: in the energy range of the LHC, the shrinkage of the forward cone starts to accelerate relative to the linear dependence found previously at energies below the LHC range, as expected from the onset of multi-Pomeron exchange.\nAcknowledgements We thank CERN for the very successful operation of the LHC, as well as the support staff from our institutions without whom ATLAS could not be operated efficiently. We are indebted to the beam optics development team, led by H. Burkhardt, for the design, commissioning and thorough operation of the high-\u03b2 optics in dedicated LHC fills. We acknowledge the support of ANPCyT, Argentina; YerPhI, Armenia; ARC, Australia; BMWFW and FWF, Austria; ANAS, Azerbaijan; CNPq and FAPESP, Brazil; NSERC, NRC and CFI, Canada; CERN; ANID, Chile; CAS, MOST and NSFC, China; Minciencias, Colombia; MEYS CR, Czech Republic; DNRF and DNSRC, Denmark; IN2P3-CNRS and CEA-DRF/IRFU, France; SRNSFG, Georgia; BMBF, HGF and MPG, Germany; GSRI, Greece; RGC and Hong Kong SAR, China; ISF and Benoziyo Center, Israel; INFN, Italy; MEXT and JSPS, Japan; CNRST, Morocco; NWO, Netherlands; RCN, Norway; MEiN, Poland; FCT, Portugal; MNE/IFA, Romania; MESTD, Serbia; MSSR, Slovakia; ARRS and MIZ\u0160, Slovenia; DSI/NRF, South Africa; MICINN, Spain; SRC and Wallenberg Foundation, Sweden; SERI, SNSF and Cantons of Bern and Geneva, Switzerland; MOST, Taiwan; TENMAK, T\u00fcrkiye; STFC, United Kingdom; DOE and NSF, United States of America. In addition, individual groups and members have received support from BCKDF, CANARIE, Compute Canada and CRC, Canada; PRIMUS 21/SCI/017 and UNCE SCI/013, Czech Republic; COST, ERC, ERDF, Horizon 2020 and Marie Sk\u0142odowska-Curie Actions, European Union; Investissements d\u2019Avenir Labex, Investissements d\u2019Avenir Idex and ANR, France; DFG and AvH Foundation, Germany; Herakleitos, Thales and Aristeia programmes co-financed by EU-ESF and the Greek NSRF, Greece; BSF-NSF and MINERVA, Israel; Norwegian Financial Mechanism 2014\u20132021, Norway; NCN and NAWA, Poland; La Caixa Banking Foundation, CERCA Programme Generalitat de Catalunya and PROMETEO and GenT Programmes Generalitat Valenciana, Spain; G\u00f6ran Gustafssons Stiftelse, Sweden; The Royal Society and Leverhulme Trust, United Kingdom.\nThe crucial computing support from all WLCG partners is acknowledged gratefully, in particular from CERN, the ATLAS Tier-1 facilities at TRIUMF (Canada), NDGF (Denmark, Norway, Sweden), CCIN2P3 (France), KIT/GridKA (Germany), INFN-CNAF (Italy), NLT1 (Netherlands), PIC (Spain), ASGC (Taiwan), RAL (UK) and BNL (USA), the Tier-2 facilities worldwide and large non-WLCG resource providers. Major contributors of computing resources are listed in Ref. [61].\nData Availability Statement This manuscript has no associated data or the data will not be deposited. [Authors\u2019 comment: All ATLAS scientific output is published in journals, and preliminary results are made available in Conference Notes. All are openly available, without restriction on use by external parties beyond copyright law and the standard conditions agreed by CERN. Data associated with journal publications are also made available: tables and data from plots (e.g. cross section values, likelihood profiles, selection efficiencies, cross section limits, ...) are stored in appropriate repositories such as HEPDATA (http:// hepdata.cedar.ac.uk/). ATLAS also strives to make additional material related to the paper available that allows a reinterpretation of the data in the context of new theoretical models. For example, an extended encapsulation of the analysis is often provided for measurements in the framework of RIVET (http://rivet.hepforge.org/).\u201d This information is taken from the ATLAS Data Access Policy, which is a public document that can be downloaded from http://opendata.cern.ch/record/413 [opendata.cern.ch].]\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecomm ons.org/licenses/by/4.0/. Funded by SCOAP3. SCOAP3 supports the goals of the International Year of Basic Sciences for Sustainable Development.\nAppendix\nNumerical values of the differential elastic cross section are given in the range from \u2212t = 2.5 \u00b7 10\u22124 GeV2 to \u2212t = 0.05785 GeV2 in Table 12 and from \u2212t = 0.05785 GeV2 to \u2212t = 0.46 GeV2 in Table 13."
        },
        {
            "heading": "A HepData material",
            "text": "The HEPData record 128017 contains the following tables:\n1. The total cross section 2. The \u03c1-parameter 3. The nuclear slope parameter B 4. The nuclear slope parameter C 5. The nuclear slope parameter D 6. The measured total elastic cross section inside the fiducial\nvolume 7. The nuclear part of the total elastic cross section extrap-\nolated to full phase space 8. The total inelastic cross section 9. The ratio of the elastic to total cross section\n10. The differential elastic cross section with statistical uncertainties and 20 experimental systematic signed relative uncertainties associated to nuisance parameters used in the profile fit\n11. The statistical covariance matrix for the differential elastic cross section."
        }
    ],
    "year": 2023
}