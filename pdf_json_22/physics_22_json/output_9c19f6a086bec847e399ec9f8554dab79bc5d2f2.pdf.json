{
    "abstractText": "The recent advances in machine learning algorithms have boosted the application of these techniques to the field of condensed matter physics, in order e.g. to classify the phases of matter at equilibrium or to predict the real-time dynamics of a large class of physical models. Typically in these works, a machine learning algorithm is trained and tested on data coming from the same physical model. Here we demonstrate that unsupervised and supervised machine learning techniques are able to predict phases of a non-exactly solvable model when trained on data of a solvable model. In particular, we employ a training set made by single-particle correlation functions of a noninteracting quantum wire and by using principal component analysis, k-means clustering, t-distributed stochastic neighbor embedding and convolutional neural networks we reconstruct the phase diagram of an interacting superconductor. We show that both the principal component analysis and the convolutional neural networks trained on the data of the non-interacting model can identify the topological phases of the interacting model. Our findings indicate that non-trivial phases of matter emerging from the presence of interactions can be identified by means of unsupervised and supervised techniques applied to data of non-interacting systems. Copyright S. Tibaldi et al. This work is licensed under the Creative Commons Attribution 4.0 International License. Published by the SciPost Foundation. Received 24-02-2022 Accepted 01-12-2022 Published 19-01-2023 Check for updates doi:10.21468/SciPostPhys.14.1.005",
    "authors": [
        {
            "affiliations": [],
            "name": "Simone Tibaldi"
        },
        {
            "affiliations": [],
            "name": "Giuseppe Magnifico"
        },
        {
            "affiliations": [],
            "name": "Davide Vodola"
        },
        {
            "affiliations": [],
            "name": "Elisa Ercolessi"
        }
    ],
    "id": "SP:738bb3144369256725edc2e1d13c9fb1793efa68",
    "references": [
        {
            "authors": [
                "P. Mehta",
                "M. Bukov",
                "C.-H. Wang",
                "A.G.R. Day",
                "C. Richardson",
                "C.K. Fisher",
                "D.J. Schwab"
            ],
            "title": "A high-bias",
            "venue": "low-variance introduction to Machine Learning for physicists, Phys. Rep. 810, 1 ",
            "year": 2019
        },
        {
            "authors": [
                "G. Carleo",
                "I. Cirac",
                "K. Cranmer",
                "L. Daudet",
                "M. Schuld",
                "N. Tishby",
                "L. Vogt-Maranto",
                "L. Zdeborov\u00e1"
            ],
            "title": "Machine learning and the physical sciences",
            "venue": "Rev. Mod. Phys. 91, 045002 ",
            "year": 2019
        },
        {
            "authors": [
                "G. Carleo",
                "M. Troyer"
            ],
            "title": "Solving the quantum many-body problem with artificial neural networks",
            "venue": "Science 355, 602 ",
            "year": 2017
        },
        {
            "authors": [
                "S. Czischek",
                "M. G\u00e4rttner",
                "T. Gasenzer"
            ],
            "title": "Quenches near Ising quantum criticality as a challenge for artificial neural networks",
            "venue": "Phys. Rev. B 98, 024311 ",
            "year": 2018
        },
        {
            "authors": [
                "G. Torlai",
                "G. Mazzola",
                "J. Carrasquilla",
                "M. Troyer",
                "R. Melko",
                "G. Carleo"
            ],
            "title": "Neural-network quantum state tomography",
            "venue": "Nat. Phys. 14, 447 ",
            "year": 2018
        },
        {
            "authors": [
                "L. Wang"
            ],
            "title": "Discovering phase transitions with unsupervised learning",
            "venue": "Phys. Rev. B 94, 195105 ",
            "year": 2016
        },
        {
            "authors": [
                "E.P.L. van Nieuwenburg",
                "Y.-H. Liu",
                "S.D. Huber"
            ],
            "title": "Learning phase transitions by confusion, Nat",
            "venue": "Phys. 13,",
            "year": 2017
        },
        {
            "authors": [
                "P. Broecker",
                "J. Carrasquilla",
                "R.G. Melko",
                "S. Trebst"
            ],
            "title": "Machine learning quantum phases of matter beyond the fermion sign problem",
            "venue": "Sci. Rep. 7, 8823 ",
            "year": 2017
        },
        {
            "authors": [
                "W. Hu",
                "R.R.P. Singh",
                "R.T. Scalettar"
            ],
            "title": "Discovering phases",
            "venue": "phase transitions, and crossovers through unsupervised machine learning: A critical examination, Phys. Rev. E 95, 062122 ",
            "year": 2017
        },
        {
            "authors": [
                "M.S. Scheurer",
                "R.-J. Slager"
            ],
            "title": "Unsupervised machine learning and band topology",
            "venue": "Phys. Rev. Lett. 124, 226401 ",
            "year": 2020
        },
        {
            "authors": [
                "J.F. Rodriguez-Nieva",
                "M.S. Scheurer"
            ],
            "title": "Identifying topological order through unsupervised machine learning",
            "venue": "Nat. Phys. 15, 790 (2019), doi:10.1038/s41567-019-0512-x. 15 SciPost Phys. 14, 005 ",
            "year": 2023
        },
        {
            "authors": [
                "N. K\u00e4ming",
                "A. Dawid",
                "K. Kottmann",
                "M. Lewenstein",
                "K. Sengstock",
                "A. Dauphin",
                "C. Weitenberg"
            ],
            "title": "Unsupervised machine learning of topological phase transitions from experimental data",
            "venue": "Mach. Learn.: Sci. Technol. 2, 035037 ",
            "year": 2021
        },
        {
            "authors": [
                "S. Sachdev"
            ],
            "title": "Quantum phase transitions",
            "venue": "Cambridge University Press, Cambridge, UK, ISBN 9780521514682 ",
            "year": 2011
        },
        {
            "authors": [
                "B.A. Bernevig",
                "T.L. Hughes"
            ],
            "title": "Topological insulators and topological superconductors",
            "venue": "Princeton University Press, New Jersey, US, ISBN 9781400846733 ",
            "year": 2013
        },
        {
            "authors": [
                "B. Zeng",
                "X. Chen",
                "D.-L. Zhou",
                "X.-G. Wen"
            ],
            "title": "Quantum information meets quantum matter",
            "venue": "Springer, New York, US, ISBN 9781493990825 ",
            "year": 2019
        },
        {
            "authors": [
                "P. Zhang",
                "H. Shen",
                "H. Zhai"
            ],
            "title": "Machine learning topological invariants with neural networks",
            "venue": "Phys. Rev. Lett. 120, 066401 ",
            "year": 2018
        },
        {
            "authors": [
                "N. Sun",
                "J. Yi",
                "P. Zhang",
                "H. Shen",
                "H. Zhai"
            ],
            "title": "Deep learning topological invariants of band insulators",
            "venue": "Phys. Rev. B 98, 085402 ",
            "year": 2018
        },
        {
            "authors": [
                "P. Huembeli",
                "A. Dauphin",
                "P. Wittek"
            ],
            "title": "Identifying quantum phase transitions with adversarial neural networks",
            "venue": "Phys. Rev. B 97, 134109 ",
            "year": 2018
        },
        {
            "authors": [
                "P. Molignini",
                "A. Zegarra"
            ],
            "title": "E",
            "venue": "van Nieuwenburg, R. Chitra and W. Chen, A supervised learning algorithm for interacting topological insulators based on local curvature, SciPost Phys. 11, 073 ",
            "year": 2021
        },
        {
            "authors": [
                "Y. Che",
                "C. Gneiting",
                "T. Liu",
                "F. Nori"
            ],
            "title": "Topological quantum phase transitions retrieved through unsupervised machine learning",
            "venue": "Phys. Rev. B 102, 134213 ",
            "year": 2020
        },
        {
            "authors": [
                "C. Lobo",
                "S.D. Gensemer"
            ],
            "title": "Technique for measuring correlation functions in interacting gases",
            "venue": "Phys. Rev. A 78, 023618 ",
            "year": 2008
        },
        {
            "authors": [
                "M.F. Parsons",
                "A. Mazurenko",
                "C.S. Chiu",
                "G. Ji",
                "D. Greif",
                "M. Greiner"
            ],
            "title": "Site-resolved measurement of the spin-correlation function in the Fermi-Hubbard model",
            "venue": "Science 353, 1253 ",
            "year": 2016
        },
        {
            "authors": [
                "L.W. Cheuk"
            ],
            "title": "Observation of spatial charge and spin correlations in the 2D Fermi",
            "venue": "Hubbard model, Science 353,",
            "year": 2016
        },
        {
            "authors": [
                "M. Gluza",
                "J. Eisert"
            ],
            "title": "Recovering quantum correlations in optical lattices from interaction quenches",
            "venue": "Phys. Rev. Lett. 127, 090503 ",
            "year": 2021
        },
        {
            "authors": [
                "A.Y. Kitaev"
            ],
            "title": "Unpaired Majorana fermions in quantum wires",
            "venue": "Phys.-Uspekhi 44, 131 ",
            "year": 2001
        },
        {
            "authors": [
                "E.M. Stoudenmire",
                "J. Alicea",
                "O.A. Starykh",
                "M.P.A. Fisher"
            ],
            "title": "Interaction effects in topological superconducting wires supporting Majorana fermions",
            "venue": "Phys. Rev. B 84, 014503 (2011), doi:10.1103/PhysRevB.84.014503. 16 SciPost Phys. 14, 005 ",
            "year": 2023
        },
        {
            "authors": [
                "F. Hassler",
                "D. Schuricht"
            ],
            "title": "Strongly interacting Majorana modes in an array of Josephson junctions",
            "venue": "New J. Phys. 14, 125018 ",
            "year": 2012
        },
        {
            "authors": [
                "R. Thomale",
                "S. Rachel",
                "P. Schmitteckert"
            ],
            "title": "Tunneling spectra simulation of interacting Majorana wires",
            "venue": "Phys. Rev. B 88, 161103 ",
            "year": 2013
        },
        {
            "authors": [
                "H. Katsura",
                "D. Schuricht",
                "M. Takahashi"
            ],
            "title": "Exact ground states and topological order in interacting Kitaev/Majorana chains",
            "venue": "Phys. Rev. B 92, 115137 ",
            "year": 2015
        },
        {
            "authors": [
                "J.-J. Miao",
                "H.-K. Jin",
                "F.-C. Zhang",
                "Y. Zhou"
            ],
            "title": "Exact solution for the interacting Kitaev chain at the symmetric point",
            "venue": "Phys. Rev. Lett. 118, 267701 ",
            "year": 2017
        },
        {
            "authors": [
                "P. Fromholz",
                "G. Magnifico",
                "V. Vitale",
                "T. Mendes-Santos",
                "M. Dalmonte"
            ],
            "title": "Entanglement topological invariants for one-dimensional topological superconductors",
            "venue": "Phys. Rev. B 101, 085136 ",
            "year": 2020
        },
        {
            "authors": [
                "U. Schollw\u00f6ck"
            ],
            "title": "The density-matrix renormalization group",
            "venue": "Rev. Mod. Phys. 77, 259 ",
            "year": 2005
        },
        {
            "authors": [
                "I. Goodfellow",
                "Y. Bengio",
                "A. Courville"
            ],
            "title": "Deep learning",
            "venue": "MIT Press, Massachusetts, US, ISBN 9780262035613 ",
            "year": 2016
        },
        {
            "authors": [
                "D.J.C. MacKay"
            ],
            "title": "Information theory",
            "venue": "inference, and learning algorithms, Cambridge University Press, Cambridge, UK, ISBN 9780521642989 ",
            "year": 2003
        },
        {
            "authors": [
                "L. van der Maaten",
                "G. Hinton"
            ],
            "title": "Viualizing data using t-sne",
            "venue": "J. Mach. Learn. Res",
            "year": 2008
        },
        {
            "authors": [
                "A.P. Schnyder",
                "S. Ryu",
                "A. Furusaki",
                "A.W.W. Ludwig"
            ],
            "title": "Classification of topological insulators and superconductors in three spatial dimensions",
            "venue": "Phys. Rev. B 78, 195125 ",
            "year": 2008
        },
        {
            "authors": [
                "C.-K. Chiu",
                "J.C.Y. Teo",
                "A.P. Schnyder",
                "S. Ryu"
            ],
            "title": "Classification of topological quantum matter with symmetries",
            "venue": "Rev. Mod. Phys. 88, 035005 ",
            "year": 2016
        },
        {
            "authors": [
                "J. Kruthoff"
            ],
            "title": "J",
            "venue": "de Boer, J. van Wezel, C. L. Kane and R.-J. Slager, Topological classification of crystalline insulators through band structure combinatorics, Phys. Rev. X 7, 041069 ",
            "year": 2017
        },
        {
            "authors": [
                "R.-J. Slager",
                "A. Mesaros",
                "V. Juri\u010di\u0107",
                "J. Zaanen"
            ],
            "title": "The space group classification of topological band-insulators",
            "venue": "Nat. Phys. 9, 98 ",
            "year": 2012
        },
        {
            "authors": [
                "J.K. Asb\u00f3th",
                "L. Oroszl\u00e1ny",
                "A. P\u00e1lyi"
            ],
            "title": "A short course on topological insulators",
            "venue": "Springer International Publishing, Cham, ISBN 9783319256054 ",
            "year": 2016
        },
        {
            "authors": [
                "M. Fishman",
                "S.R. White",
                "E.M. Stoudenmire"
            ],
            "title": "The ITensor Software Library for Tensor Network Calculations",
            "venue": "SciPost Phys. Codebases, 4 ",
            "year": 2022
        },
        {
            "authors": [
                "A. Valenti"
            ],
            "title": "E",
            "venue": "van Nieuwenburg, S. Huber and E. Greplova, Hamiltonian learning for quantum error correction, Phys. Rev. Res. 1, 033092 (2019), doi:10.1103/PhysRevResearch.1.033092. 17 SciPost Phys. 14, 005 ",
            "year": 2023
        },
        {
            "authors": [
                "A. Krizhevsky",
                "I. Sutskever",
                "G.E. Hinton"
            ],
            "title": "Imagenet classification with deep convolutional neural networks",
            "venue": "Advances in neural information processing systems 25, Curran Associates, Inc. ",
            "year": 2012
        },
        {
            "authors": [
                "J. Carrasquilla",
                "R.G. Melko"
            ],
            "title": "Machine learning phases of matter",
            "venue": "Nat. Phys. 13, 431 ",
            "year": 2017
        },
        {
            "authors": [
                "Y. Ming",
                "C.-T. Lin",
                "S.D. Bartlett",
                "W.-W. Zhang"
            ],
            "title": "Quantum topology identification with deep neural networks and quantum walks",
            "venue": "npj Comput. Mater. 5, 88 ",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "The recent advances in machine learning algorithms have boosted the application of these techniques to the field of condensed matter physics, in order e.g. to classify the phases of matter at equilibrium or to predict the real-time dynamics of a large class of physical models. Typically in these works, a machine learning algorithm is trained and tested on data coming from the same physical model. Here we demonstrate that unsupervised and supervised machine learning techniques are able to predict phases of a non-exactly solvable model when trained on data of a solvable model. In particular, we employ a training set made by single-particle correlation functions of a noninteracting quantum wire and by using principal component analysis, k-means clustering, t-distributed stochastic neighbor embedding and convolutional neural networks we reconstruct the phase diagram of an interacting superconductor. We show that both the principal component analysis and the convolutional neural networks trained on the data of the non-interacting model can identify the topological phases of the interacting model. Our findings indicate that non-trivial phases of matter emerging from the presence of interactions can be identified by means of unsupervised and supervised techniques applied to data of non-interacting systems.\nCopyright S. Tibaldi et al. This work is licensed under the Creative Commons Attribution 4.0 International License. Published by the SciPost Foundation.\nReceived 24-02-2022 Accepted 01-12-2022 Published 19-01-2023\nCheck for updates\ndoi:10.21468/SciPostPhys.14.1.005\nContents"
        },
        {
            "heading": "1 Introduction 2",
            "text": ""
        },
        {
            "heading": "2 Models 4",
            "text": "2.1 Non-interacting topological superconductor 4 2.2 Interacting topological superconductor 5\n3 Unsupervised training 5\n3.1 Principal Components Analysis 6 3.2 K-means clustering 8 3.3 t-distributed stochastic neighbor embedding 10"
        },
        {
            "heading": "4 Supervised Training 12",
            "text": ""
        },
        {
            "heading": "5 Conclusions 14",
            "text": "References 15"
        },
        {
            "heading": "1 Introduction",
            "text": "In the last few years research in physics has seen a new series of methods and practices inspired by and exploiting machine learning [1]. These new instruments have proved to be useful in applications in many-body quantum physics [2], in particular for finding a representation of a wavefunction [3] and describing its dynamics [4], for reconstructing the wavefunction from experimental data [5], for speeding-up numerical simulations [4], and for classifying quantum phases of matter of both synthetic [6\u201311] and experimental data [12]. A particular type of the latter is given by symmetry protected and topologically ordered phases, whose classification escapes from the standard Landau theory of spontaneous symmetry breaking [13]. Indeed the combination of symmetries and topology can lead to new kinds of quantum phases that are characterized by a set of unusual features, such as non-local order parameters, the appearance of zero energy states at the boundary of the system, topological invariants, and long-range entanglement (for reviews see, for example: [14, 15]). From an experimental point of view, topological materials have attracted much attention also because they represent a promising solution for physical implementation of qubits, more resilient to decoherence processes that affect devices based on superconducting or atomic physics technologies.\nDue to their intrinsically non-local features and the lack of local order parameters, the classification of topological phases is considered a very challenging task to tackle [2]. However, machine learning methods have been successfully applied to both non-interacting models where the topological invariant (winding number) representing each phase was known a priori [16, 17], and to interacting models where the topological invariant cannot be obtained easily [18].\nDespite their success, in order to perform well, machine learning models require data sets with a very large number of training data, in the order of the thousands or millions. However, especially when handling interacting systems, it is not always easy to build such big data sets from both numerical simulations or experimental measurements. This led us to study a machine learning model trained on a data set obtained from a solvable system to be then applied to an interacting model which is obtained as an interacting generalization of the former, as in Ref. [19]. In this way, insights about the features of a simple dataset can be exploited to characterize the phases of a more complicated one, saving simulation resources. Differently from what has been done in previous works [16, 20], our dataset will be constructed out of twopoint single-particle correlation functions. These encode the properties of the different phases of the model and can be obtained numerically and measured experimentally [21\u201323], e.g. by using atom gas microscope with quenches to non-interacting models [24] or with randomized measurements [25].\nIn this work we show that supervised and unsupervised machine learning models can clas-\nsify topological phases of an interacting system by being trained on data computed from simpler topological models. More specifically, our goal is to use machine learning techniques to predict the topological and non-topological quantum phases of two paradigmatic models: the one dimensional Kitaev chain in its non-interacting [26] and interacting scenario [27\u201332], with the idea that one can exploit the knowledge of the easily solvable non-interacting model in order to extract information also on the interacting case. We construct the correlator dataset from the analytical solution of the non-interacting model and by means of numerical simulations implemented with the Density Matrix Renormalization Group (DMRG) algorithm for the interacting system [33]. Firstly, we probe the data with three unsupervised methods: the principal components analysis (PCA), k-means clustering and tdistributed stochastic neighbor embedding (t-SNE) [34\u201336]. With PCA we investigate to what extent the knowledge about principal component vectors of the data of the non-interacting case can be used to learn also the underline pattern that distinguishes the different phases in the interacting case. We use k-means\u2019 ability to find clusters and centroids to correctly predict the number of phases as well the location of the phase transition lines for both the non-interacting and interacting case. Then, we check that also t-SNE is able to form clusters of data.\nFinally we devise an ensemble of convolutional neural networks (CNN) which is trained on the non-interacting data and then tested to predict the phases of the interacting model.\nThe paper is organized as follows: in Sec. 2, we introduce the models and the datasets that will be used for the training and testing of the machine learning methods. In Sec. 3,\nwe apply unsupervised methods (PCA, k-means clustering and t-SNE) to analyze the internal structure of the datasets. In Section 4, we apply a supervised model trained on the data of the non interacting model and test it on the interacting data. Finally, we draw our conclusions in Sec. 5."
        },
        {
            "heading": "2 Models",
            "text": "In this section we describe the two models, the non-interacting and the interacting Kitaev chain, whose quantum phases we want to classify, and we define the standard and anomalous correlation functions that will be used as indicator of the topological phases, thus providing the training and test sets."
        },
        {
            "heading": "2.1 Non-interacting topological superconductor",
            "text": "We consider the one-dimensional Kitaev model [26] defined on a lattice with L sites described by the following non-interacting (NI) Hamiltonian\nHNI = \u2211\ni\n(Ja\u2020i ai+1 +\u2206 aiai+1 + h.c.) +\u00b5 \u2211\ni\na\u2020i ai . (1)\nHere the operators ai (a \u2020 i ) annihilate (create) a spinless fermion on the lattice site i. The Hamiltonian HNI describes a topological superconductor with nearest neighbour hopping of strength J , p-wave superconducting pairing of strength \u2206 and chemical potential \u00b5. When considering periodic boundary conditions, we can diagonalize HNI by going to momentum space by means of standard Fourier transform, so that it is reduced to a sum over the Brillouin zone (BZ), HNI = \u2211\nk\u2208BZ H(k), of a two-band Hamiltonian H(k) = hz(k)\u03c3 z + hy(k)\u03c3 y , where\nk is the lattice quasi momentum and\nhz(k) = J cos k+\u00b5/2 , hy(k) =\u2206 sin k , (2)\nand \u03c3x ,\u03c3 y are Pauli matrices. A Bogoliubov transformation casts HNI in diagonal form HNI = \u2211\nk E(k)\u03b7 \u2020 k\u03b7k , where \u03b7k are Bogoliubov operators and the single-particle energy E(k)\nis given by E(k) = q\nhz(k)2 + hy(k)2 . (3)\nThis model describes a one-dimensional topological superconductor belonging to the BDI symmetry class [37\u201340]. Its different phases are classified by the winding number \u03bd of the normalized Hamiltonian vector h\u0302(k) = h\u20d7(k)/\u2225h\u20d7(k)\u2225 with h\u20d7(k) = (hy(k), hz(k)), which is a continuous map from the 1D BZ to the circle S1. The winding number \u03bd is an integer that counts how many times the Hamiltonian vector h\u0302(k) turns around the origin when the quasimomentum k moves from 0 to 2\u03c0 in the 1D BZ. Panel (a) of Fig. 1 shows the phase diagram of the model in Eq. (1) in the (\u00b5,\u2206) plane, having set the energy scale J = 1. Notice that the phase diagram is symmetric for \u00b5\u2194\u2212\u00b5. Three different phases appear: a trivial phase with winding number \u03bd= 0 (green) and two non trivial phases with winding number \u03bd= \u00b11 (orange/red). The winding number corresponds to the number of zero energy states that the model hosts at the boundaries of the chain, when considering open boundary conditions, a fact that is known in literature [14,41] as bulk-edge correspondence. For \u03bd= 0 no edge states will be present, while for \u03bd= \u00b11 an edge state on each boundary appears.\nThe information on the different phases can also be extracted from the Fourier transform\nof the single-particle standard (c(k)) and anomalous ( f (k)) correlation functions:\nc(k) = \u2211\ni, j\neik(i\u2212 j) \u2329a\u2020i a j\u232a , (4)\nf (k) = \u2211\ni, j\neik(i\u2212 j) \u2329aia j\u232a , (5)\nwhere the expectation values are taken on the ground state. We note that c(k) is real, while f (k) is purely imaginary, due to the antisymmetry of the expectation value \u2329aia j\u232a for the exchange i\u2194 j. So we will redefine the latter by taking its imaginary part. For the Kitaev model of Eq. (1), c(k) and f (k) can be computed analytically and they take the form\nc(k) = 1 2 + \u00b5/2+ J cos k 2E(k) , (6)\nf (k) = \u2206 sin k 2E(k) . (7)\nNotice that they have a similar form to the components of the Hamiltonian vector h\u0302(k) from which the winding number is calculated. Their behaviour in the different phases is shown in panel (b) of Fig. 1.\nThe correlation functions c(k) and f (k)will be used for building a non-interacting training set S where each data point is labelled with the winding number of its corresponding phase."
        },
        {
            "heading": "2.2 Interacting topological superconductor",
            "text": "We now add a nearest neighbor interaction term to the Hamiltonian (1) to obtain:\nH I = \u2211\ni\n(Ja\u2020i ai+1 +\u2206 aiai+1 + h.c.) +\u00b5 \u2211\ni\nni + V \u2211\ni\nnini+1 , (8)\nwhere ni = a \u2020 i ai is the occupation number at site i. This model cannot be solved exactly due to the interacting potential. By means of the DMRG algorithm [42], we have reproduced the phase diagram, after setting J = \u2206 = 1, which is shown in panel (c) of Fig. 1, for \u00b5 > 0 only since the model is symmetric for \u00b5\u2194\u2212\u00b5. The model in Eq. (8) is characterized by only one topological superconducting phase (TOP, yellow) and three trivial phases: Topological trivial (TRI, green), Charge Density Wave (CDW, light-blue) and a Schr\u00f6dinger-cat-like phase (CAT, light green dashed line) which shows up at the symmetric point \u00b5 = 0 as a superposition of two trivial superconducting states with different occupation numbers [28\u201331]. At V = 0 we recover the non-interacting case with a critical point at \u00b5= 2. The different phases in Fig. 1(c) are detected from the number of edge states that appear in the chain: in the TRI, CDW and CAT phases the number of edge states is zero, while it is one in the TOP phase.\nIn the interacting case, it is not possible to evaluate exactly the correlation functions c(k) (Eq. (4)) and f (k) (Eq. (5)) on the ground state of the Hamiltonian of Eq. (8). Therefore we calculate them by means of the DMRG algorithm for a lattice of size L = 100. Some examples of the correlation functions for the different regions of the phase diagram are shown in panel (d) of Fig. 1."
        },
        {
            "heading": "3 Unsupervised training",
            "text": "Having obtained the datasets of the correlation functions for both the non-interacting and and interacting model, we use three unsupervised methods, namely PCA, k-means clustering and t-SNE, to extract the relevant information in both datasets and predict the phases of both models."
        },
        {
            "heading": "3.1 Principal Components Analysis",
            "text": "Principal components analysis is a standard technique used in statistics and machine learning for dimensionality reduction.\nIn order to apply PCA we start by creating a design matrix\nX =\n\n c1(k0) . . . c1(kL\u22121) f1(k0) . . . f1(kL\u22121) ...\ncN (k0) . . . cN (kL\u22121) fN (k0) . . . fN (kL\u22121)\n\n , (9)\nwhere each of its N rows is given by the correlation functions c(k) and f (k) from Eqs. (4) and (5) for one point (\u00b5\u03b1,\u2206\u03b1), \u03b1 = 1, . . . , N , of the phase diagram. Each column represents the Fourier components of the correlation functions with quasi-momentum kn = 2\u03c0n/L (n = 0, . . . , L \u2212 1) that are interpreted as the features of the data from which the PCA extracts the principal components. We rescale the columns of X such that they have zero mean and unit standard deviation and we compute the eigenvalues {\u03bbi}, the explained variances \u03b5i = \u03bbi/ \u2211 j \u03bb j , and the eigenvectors {wi} of the correlation matrix S = X T X . The principal components of the data X , which are the eigenvectors of S corresponding to the largest eigenvalues, are the directions in a 2L dimensional space along which the original data show the largest variance. A common measure of the projection along the principal components is the quantified leading component (QLC) [6, 9]. For both the non-interacting and the interacting case, we compute the QLC by dividing the set of the two parameters in 40 sections, creating a grid of 40\u00d7 40 subsets, each made of M datapoints, as better specified below. Then, for each of the subsets we calculate the quantity\npi = \u2211\ns\n|Xs \u00b7wi| M , (10)\nwhere s runs on the elements of each subset, Xs is the s-th row of the matrix X corresponding to the s-th point of the subset, and wi is the i-th eigenvector of S. The value of the QLC for a datapoint shows how much that point is represented by that specific principal component.\nNon-interacting Hamiltonian \u2013 For the Hamiltonian of Eq. (1), we create the desing matrix X (NI) from data points generated in the range \u00b5 \u2208 [\u22128,8[ and \u2206 \u2208 [\u22122, 2[ with a step of 0.1 for \u00b5 and 0.05 for \u2206, for a system with L = 100 sites. This subdivision of the ranges of \u2206 and \u00b5 corresponds to have a total of N = 12800 data points. The sum\n\u22114 i=1 \u03b5i of the explained\nvariances of the first four eigenvalues results in 96.6% meaning that most of the information of the data X is contained in the first four eigenvectors. For this reason, in Fig. 2, we show the first four QLCs. These are calculated as in Eq. (10) by grouping the N = 12800 datapoints in 40\u00d7 40 subsets corresponding to M = 8 datapoints per subset. The explained variances \u03b5i of each eigenvector are reported for each of the first four components. In panel (a) we see that p1 is large for the points with |\u00b5| > 2, this means that the first principal component allows us to find the points of the phase diagram with winding number \u03bd = 0 (that belong to the trivial phases TRI\u2212 and TRI+). This is due to the shape of the first principal component w1 (depicted in the inset of Fig. 2(a)) that resembles the shape of the correlation functions c(k) and f (k) shown in Fig. 1(b) (TOP+1 phase). In Fig. 2(b), we see that, instead, p2 allows us to extract the points of the phase diagram with winding number \u03bd = \u00b11 as the shape of the second principal component w2 (depicted in the inset of Fig. 2(b)) is similar to the correlation functions c(k) and f (k) shown in Fig. 1(b) (TOP\u00b11 phases). This analysis shows that the first two principal components are sensitive to the trivial and non-trivial phases. All the other 198 QLCs have a total explained variance of the order of 13%, in particular the third QLC (Fig. 2(c)) has explained variance \u03b53 = 5.2% and recognizes the phase transition lines, while\nthe fourth (Fig. 2(d)) has explained variance \u03b54 = 4.2% and has a larger projection on the phase with winding \u03bd= \u22121.\nInteracting Hamiltonian \u2013 We are interested in understanding if the principal components of the non-interacting model computed before can be used to distinguish among the phases of the interacting Hamiltonian. To this end, we construct a design matrix X (I) with data obtained from the interacting Hamiltonian in the range \u00b5 \u2208 [0, 5[, V \u2208 [\u22124,4[ with a step of 0.1. Then, we calculate the QLC by projecting these data along the principal components wi of the noninteracting Hamiltonian. The first four QLC are shown in Fig. 3. The first (panel (a)) and the fourth (panel (d)) principal components w1 and w4 of the non-interacting data show higher projections on the interacting data and are thus able to discriminate between the trivial and topological phases, respectively. We will comment in Sec. 4 about the appearance of a ligther colored region in the CDW phase, just on the right of the phase transition line for large values of \u00b5. The third principal components w3 (panel (c)) recovers only the transition line between the trivial and the non-trivial superconducting phases while the second one seems to highlight only the region for low \u00b5 and V \u2208 [\u22121,0]. We note that, even though the CAT phase is present only on the single line \u00b5 = 0, three out of four principal components are able to recognize it (Fig. 3(a), (c), (d)).\nWe can say with fairness that the PCA is able to learn the underlying pattern which distinguishes a trivial phase from a topological one. This is a good indication that even a supervised method can exploit the representation it learns of the non-interacting data to classify the interacting ones."
        },
        {
            "heading": "3.2 K-means clustering",
            "text": "K-means clustering is a machine learning method for finding clusters and cluster centers in a set of unlabelled data [35]. The algorithm starts by choosing a number of cluster centers called centroids and then it iteratively moves the centers to minimize the total variance within\ncluster. The centroids are the central point of every cluster that are calculated by the algorithm autonomously, so we interpret them as the most representative point of the cluster.\nIn order to settle on a value of K without any a priori knowledge of our data we choose to calculate the silhouette score eS which is a value representing the average quality of the clusterization for each K . Calling a the distance of a sample point to its centroid and b its distance to the second closest centroid we can calculate the silhouette of a data point as S = (b \u2212 a)/max(a, b). The values for S lie in the range [\u22121,1] where negative numbers correspond to a wrongly assigned point. Positive values indicate the right classification and the quality increases reaching 1.\nWe run k-means algorithm with different K values and select the K with the largest silhouette score. Due to the sensitivity of the algorithm to initial conditions we run k-means 10 times for each K and then collect the average silhouette value eS of every point over the 10 runs, whereas the centroids and projections correspond to the largest silhouette only.\nNon-interacting Hamiltonian \u2013 The analysis of the silhouette for the non-interacting data turns out to be very informative. Firstly, after multiple iterations as explained above, we find the maximum value of the silhouette score at K = 4 as shown in Fig. 4(a). This suggests that the most reasonable way to divide the data points is in 4 classes, which might correspond to 4 different phases. Secondly, we see that the silhouette of a point can be used for identifying the phase transition lines. In fact, the points lying near a phase transition might be reasonably associable to the two different phases of the transition, that is they might show properties of both phases. So we expect their silhouette value to be close to 0, indicating that their classification might be non ideal. This is indeed the case, as it is seen from Fig. 4(b) which shows the average silhouette of every point calculated over 10 iterations of k-means algorithm applied with K = 4, as suggested by the previous analysis. We can see that points that are inside the phases have a larger silhouette than points lying at the phase transition.\nLet us now move to the analysis of the centroids obtained by applying k-means algorithm with K = 4. In Fig. 4(c) and (d) we plot the 4 centroids and the distance of the points to each centroid, respectively. Each centroid seems to exactly represent the features of the datapoints,\ni.e. the correlation functions, of the four different regions of the phase diagram. Also, all the points of a phase have a distance very close to zero to their centroid, showing that we can separate the phases of the diagram with ease.\nInteracting Hamiltonian \u2013 The same analysis can be repeated on the interacting dataset, obtaining similar results which are collected in Fig. 5. In particular the silhouette reaches its peak at K = 4 corresponding to the four phases of the interacting model shown in Fig. 1(c).\nIn Fig. 6, for completeness, we show the scatter plots of the labels assigned by k-means ran with k = 4 for both datasets. The reconstruction of the phase diagrams is neat and in accordance with the results of Figs. 4 and 5.\nWe can summarize the results of this section saying that, in both the non-interacting and the interacting models, the k-means clustering algorithm, by trying to separate points, is able to learn the characteristic shape of the correlation functions of each phase and to identify the boundaries where the phase transitions occur."
        },
        {
            "heading": "3.3 t-distributed stochastic neighbor embedding",
            "text": "t-SNE [36] is a popular dimensionality reduction technique that creates a low-dimensional distribution of data which is faithful to the original one and thus helps visualizing clusters of data in 2 or 3 space. It starts by creating a probability distribution from the Euclidean distances between data points in their original space. In particular given two points x i , x j \u2208D where D is the dataset, we interpret the conditional probability pi| j as a measure of similarity between the two points under a Gaussian centered at x i:\np j|i = exp(||x i \u2212 x j||2/2\u03c32) \u2211\nk \u0338=i exp(||x i \u2212 xk||2/2\u03c32) , (11)\nwhere\u03c3 is a parameter that we will discuss later. t-SNE creates a symmetric joint probability P from 11 by taking pi j = (pi| j + p j|i)/2. Then, it gives to each point x i a new set of coordinates in a lower-dimensional space yi \u2208 Rd for d = 2 or 3, where the similarity between points is\ngiven by a t-Student distribution Q in the form:\nqi j = ||yi \u2212 y j||2 \u2211\nk \u0338=l ||yk \u2212 yl ||2 . (12)\nIn order to make qi j a faithful low-dimensional representation of the distribution pi j , t-SNE minimizes the Kullback-Leibler divergence\nC = K L(P||Q) = \u2211\ni\n\u2211\nj\npi j log pi j qi j . (13)\nTypically this is done updating the position of points yi by gradient descent:\nyi = yi \u2212\u03b7 \u2202 C \u2202 yi , (14)\nwith \u03b7 the learning rate. The parameter \u03c3 appearing in 11 is related to another hyperparameter called perplexity which is the one that needs to be set when running the t-SNE. Perplexity can be seen as the average number of neighbors we expect the points to have in the original space and typical values range from 5 to 50 [36].\nWe ran t-SNE on our datasets varying both perplexity and learning rate \u03b7 without seeing major changes to the final result. Also, no relevant distinction was found in either reducing the dimensions to 3 or 2, so we stick to 2D.\nIn Figure 7 we plot the results of t-SNE on the non-interacting/interacting dataset. For both models we plot the dimensional reduction to 2 dimensions. In the non-interacting case we see four well-separated clusters and each one corresponds to one of the phases of the model. In\nparticular t-SNE separates the two trivial phases (TRI+, TRI-) of the non interacting model in the same way as K-means does. For the interacting case the clusters are not as well-separated except for the CAT phase. Although the shape of the of the low-dimensional representation is not meaningful in t-SNE cluster, we are interested in finding the position of the points close to the phase transition lines. For this reason we adjust the brightness of each data point according to its silhouette value that was calculated in section 3.B (compare with Figs. 4 and 5). In this way we are able to see that the points closer to a phase transition are close to the margin of the cluster."
        },
        {
            "heading": "4 Supervised Training",
            "text": "In this section we exploit the information gained from the unsupervised analysis of the data to use a supervised model for predicting the different (trivial or topological) phases via the analysis of correlation functions. Our aim is to train the network on the data of the noninteracting Hamiltonian and test it on the interacting data. This is an approach that has been recently exploited in the context of machine learning applied to systems without analytical solution, e.g. [43].\nFor this reasons we decided to employ an ensemble method which is favourable even when tackling difficult classification problems [2]. The base element of the ensemble we use is a convolutional neural network (CNN), a type of machine learning model that has found many\nsuccessful applications in image recognition problems [44] and vastly employed in applications to quantum many body problems [16,17,45,46]. This network uses small matrices of weights, called features, which perform a series of discrete convolutions and are able to extract local properties of the data, for details see [34].\nCNN ensemble \u2013 The ensemble of classifiers is made of C = 180 CNNs, as schematically shown in Fig. 8. Each CNN has an initial hidden layer \u21131 (in green) of m1 = 100 filters (weights) of size 2\u00d72 (yellow in the picture) and stride 1, which produce m1 = 100 arrays of size N1 = L\u22121= 99. Each network can have three different internal structures whose schemes are reported in Fig. 8. The number of additional hidden layers \u2113\u03b1 (in red) can vary from 1 to 3 while each of the hidden layers in a network has the same number of weights per layer which can be m = 25, 50,100. Finally, the networks have been trained with different batch sizes (512, 1024) and different random initial training configuration of the weights centered at zero (10 different starting seeds for each network). Each network accepts as input the 2\u00d7 L matrix made by stacking c(k) and f (k) from Eqs. (6)-(7) and produces a single real number \u03c9\u03b1 in output which is the estimate for the topological indicator of the input. All layers neurons have ReLU activation ( f (x) = max{0, x}) except for the last one which is linear ( f (x) = x). The loss function is given by the mean squared error. The output of each network is then averaged to produce:\ne\u03c9= 1 C\nC \u2211\n\u03b1=1\n\u03c9\u03b1 . (15)\nIn the following we will show that this quantity can be used as a topological indicator in order to reconstruct the phase diagram of the interacting model.\nTraining \u2013 The networks are trained separately. The dataset of the non-interacting model is\nmade of 2\u00d7 105 points covering the whole phase diagram of the non interacting Hamiltonian of Fig. 1(a). Each network is trained with Adam gradient descent method by using an early stopping technique until convergence is achieved. This typically requires around 100 steps.\nTesting \u2013 For the test dataset we considered 4 \u00d7 103 evenly spaced samples in the grid [\u22124, 4] \u00d7 [0, 5] for V and \u00b5 in order to fully reconstruct the interacting phase diagram of Fig. 1(c). The ensemble, trained on the non-interacting data, efficiently evaluates the topological classification of the test set resulting in the predicted phase diagram shown in Fig. 9(a). We note that the predictions \u03c9\u03b1 of the 180 CNNs are very consistent: they are constrained in the range [0, 1] and their standard deviation is \u223c 9%.\nAll the points of the SC and CAT phases are correctly classified as non topological and the predicted values of \u03c9\u0303 show a sharp transition between the TRI and TOP phases, meaning that the ensemble was able to learn how to identify the two different phases of the superconductor. On the other hand, there is a less marked transition between the TOP and CDW phases. In Fig. 9(b) we show two horizontal cuts of the phase diagram taken for \u00b5 = 0.5 and \u00b5 = 4. Interestingly, in the CDW phase for \u00b5 \u2273 1, the values of e\u03c9 present discontinuities as a function of the potential V (indicated by the dashed vertical lines for \u00b5 = 4 in Fig. 9(b)) that correspond to the boundaries of an incommensurate CDW that has been found e.g. in [29]. The appearence of this additional phases is also caught by the PCA (Fig. 3(a, d)) and k-means (Fig. 5(b)) results."
        },
        {
            "heading": "5 Conclusions",
            "text": "In this work we have shown how one can use machine learning techniques to predict the topological and non-topological quantum phases of a paradigmatic model, namely the interacting Kitaev chain, by exploiting the knowledge of the easily solvable non-interacting model. More specifically, we have constructed the non-interacting dataset from the analytical solutions of the standard and anomalous correlation functions of the model, while we have used the DMRG algorithm to calculate the correlation functions in the interacting case.\nAt first, we have probed our data with PCA, k-means clustering and t-SNE. With the former, we have confirmed that the non-interacting data contain enough information to predict the main features of the interacting dataset as well. With k-means, we were able to identify the right number of phases as well as correctly locate the phase transition lines. Also, we have seen that the correlation functions of the four centroids reproduce the pattern of the correlation functions of the different phases. With t-SNE, we were able to see clusters of data corresponding to the phases of the models and, thanks to the silhouette values obtained from k-means, the localization of the phase transition points at the borders of the various clusters.\nThen we have used an ensemble of CNN, which was trained on the non-interacting dataset and then tested to calculate and predict the phases of the interacting model. The ensemble does efficiently evaluate the topological class of this model, with only the data points of the topological superconducting phase producing a topological indicator equal to one on average. This means that the ensemble network is able to reconstruct the phase diagram indifferently of the shapes and phases of the input data.\nThese findings clearly indicate that non-trivial phases of matter that emerge in presence of interactions can be identified by means of unsupervised and supervised techniques applied to data of non-interacting systems. These results offer a number of advantages since the data of non-interacting or solvable quantum many-body systems can be easily generated by means of analytical computation, numerical simulations, or directly measured in state-of-the-art experiments. Furthermore, all the protocols developed in this work could be easily generalized to higher-dimensional systems or finite-temperature regimes."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank E. Tignone, F. Dell\u2019Anna, S. Pradhan for useful discussions. This research is funded by Istituto Nazionale di Fisica Nucleare (INFN) through the project \u201cQUANTUM\u201d, the International Foundation Big Data and Artificial Intelligence for Human Development (IFAB) through the project \u201cQuantum Computing for Applications\u201d and the QuantERA 2020 Project \u201cQuantHEP\u201d. G. M. is partially supported by the Italian PRIN2017 and the Horizon 2020 research and innovation programme under grant agreement No 817482 (Quantum Flagship - PASQuanS). We acknowledge the use of computational resources from the parallel computing cluster of the Open Physics Hub (https://site.unibo.it/openphysicshub/en) at the Physics and Astronomy Department in Bologna."
        }
    ],
    "title": "Unsupervised and supervised learning of interacting topological phases from single-particle correlation functions",
    "year": 2023
}