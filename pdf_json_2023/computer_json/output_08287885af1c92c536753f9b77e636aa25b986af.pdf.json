{
    "abstractText": "As an important component of the railway system, the surface damage that occurs on the rails due to daily operations can pose significant safety hazards. This paper proposes a simple yet effective rail surface defect detection model, FS-RSDD, for rail surface condition monitoring, which also aims to address the issue of insufficient defect samples faced by previous detection models. The model utilizes a pre-trained model to extract deep features of both normal rail samples and defect samples. Subsequently, an unsupervised learning method is employed to learn feature distributions and obtain a feature prototype memory bank. Using prototype learning techniques, FS-RSDD estimates the probability of a test sample belonging to a defect at each pixel based on the prototype memory bank. This approach overcomes the limitations of deep learning algorithms based on supervised learning techniques, which often suffer from insufficient training samples and low credibility in validation. FS-RSDD achieves high accuracy in defect detection and localization with only a small number of defect samples used for training. Surpassing benchmarked few-shot industrial defect detection algorithms, FS-RSDD achieves an ROC of 95.2% and 99.1% on RSDDS Type-I and Type-II rail defect data, respectively, and is on par with state-of-the-art unsupervised anomaly detection algorithms.",
    "authors": [
        {
            "affiliations": [],
            "name": "Yongzhi Min"
        },
        {
            "affiliations": [],
            "name": "Ziwei Wang"
        },
        {
            "affiliations": [],
            "name": "Yang Liu"
        },
        {
            "affiliations": [],
            "name": "Zheng Wang"
        }
    ],
    "id": "SP:78030f66a93e80524b8ded6e8f54d15b4f12cec8",
    "references": [
        {
            "authors": [
                "Y. Li",
                "H. Trinh",
                "N. Haas",
                "C. Otto",
                "S. Pankanti"
            ],
            "title": "Rail Component Detection, Optimization, and Assessment for Automatic Rail Track Inspection",
            "venue": "IEEE Trans. Intell. Transp. Syst",
            "year": 2014
        },
        {
            "authors": [
                "B. Gao",
                "L. Bai",
                "W.L. Woo",
                "G.Y. Tian",
                "Y. Cheng"
            ],
            "title": "Automatic Defect Identification of Eddy Current Pulsed Thermography Using Single Channel Blind Source Separation",
            "venue": "IEEE Trans. Instrum. Meas",
            "year": 2014
        },
        {
            "authors": [
                "T.A. Alvarenga",
                "A.L. Carvalho",
                "L.M. Honorio",
                "A.S. Cerqueira",
                "L.M.A. Filho",
                "R.A. Nobrega"
            ],
            "title": "Detection and Classification System for Rail Surface Defects",
            "venue": "Based on Eddy Current. Sensors",
            "year": 2021
        },
        {
            "authors": [
                "H. Wang",
                "M. Li",
                "Z. Wan"
            ],
            "title": "Rail Surface Defect Detection Based on Improved Mask R-CNN",
            "venue": "Comput. Electr. Eng",
            "year": 2022
        },
        {
            "authors": [
                "C.-C. Hsieh",
                "T.-Y. Hsu",
                "W.-H. Huang"
            ],
            "title": "An Online Rail Track Fastener Classification System",
            "venue": "Based on YOLO Models. Sensors",
            "year": 2022
        },
        {
            "authors": [
                "H. Luo",
                "L. Cai",
                "C. Li"
            ],
            "title": "Rail Surface Defect Detection Based on An Improved YOLOv5s",
            "venue": "Appl. Sci. 2023,",
            "year": 2023
        },
        {
            "authors": [
                "C. Zhang",
                "D. Xu",
                "L. Zhang",
                "W. Deng"
            ],
            "title": "Rail Surface Defect Detection Based on Image Enhancement and Improved YOLOX",
            "venue": "Electronics 2023,",
            "year": 2023
        },
        {
            "authors": [
                "J. Hu",
                "P. Qiao",
                "H. Lv",
                "L. Yang",
                "A. Ouyang",
                "Y. He",
                "Y. Liu"
            ],
            "title": "High Speed Railway Fastener Defect Detection by Using Improved YoLoX-Nano",
            "venue": "Model. Sensors",
            "year": 2022
        },
        {
            "authors": [
                "D. Gudovskiy",
                "S. Ishizaka",
                "K. Kozuka"
            ],
            "title": "CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via Conditional Normalizing Flows",
            "venue": "In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV),",
            "year": 2021
        },
        {
            "authors": [
                "M. Yang",
                "P. Wu",
                "J. Liu",
                "H. Feng"
            ],
            "title": "MemSeg: A Semi-Supervised Method for Image Surface Defect Detection Using Differences and Commonalities",
            "venue": "Eng. Appl. Artif. Intell",
            "year": 2022
        },
        {
            "authors": [
                "G. Pang",
                "C. Shen",
                "L. Cao",
                "A.V.D. Hengel"
            ],
            "title": "Deep Learning for Anomaly Detection: A Review",
            "venue": "ACM Comput. Surv",
            "year": 2022
        },
        {
            "authors": [
                "H. Yu",
                "Q. Li",
                "Y. Tan",
                "J. Gan",
                "J. Wang",
                "Y. Geng",
                "L. Jia"
            ],
            "title": "A Coarse-to-Fine Model for Rail Surface Defect Detection",
            "venue": "IEEE Trans. Instrum. Meas",
            "year": 2019
        },
        {
            "authors": [
                "S. Ghorai",
                "A. Mukherjee",
                "M. Gangadaran",
                "P.K. Dutta"
            ],
            "title": "Automatic Defect Detection on Hot-Rolled Flat Steel Products",
            "venue": "IEEE Trans. Instrum. Meas",
            "year": 2013
        },
        {
            "authors": [
                "H. Zhang",
                "X. Jin",
                "Q.M.J. Wu",
                "Y. Wang",
                "Z. He",
                "Y. Yang"
            ],
            "title": "Automatic Visual Detection System of Railway Surface Defects with Curvature Filter and Improved Gaussian Mixture Model",
            "venue": "IEEE Trans. Instrum. Meas",
            "year": 2018
        },
        {
            "authors": [
                "Z. Liu",
                "W. Wang",
                "X. Zhang",
                "W. Jia"
            ],
            "title": "Inspection of Rail Surface Defects Based on Image Processing",
            "venue": "In Proceedings of the 2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics (CAR 2010), Wuhan, China,",
            "year": 2010
        },
        {
            "authors": [
                "S. Meng",
                "S. Kuang",
                "Z. Ma",
                "Y. Wu"
            ],
            "title": "MtlrNet: An Effective Deep Multitask Learning Architecture for Rail Crack Detection",
            "venue": "IEEE Trans. Instrum. Meas",
            "year": 2022
        },
        {
            "authors": [
                "H. Zhang",
                "Y. Song",
                "Y. Chen",
                "H. Zhong",
                "L. Liu",
                "Y. Wang",
                "T. Akilan",
                "Q.M.J. Wu"
            ],
            "title": "MRSDI-CNN: Multi-Model Rail Surface Defect Inspection System Based on Convolutional Neural Networks",
            "venue": "IEEE Trans. Intell. Transp. Syst",
            "year": 2022
        },
        {
            "authors": [
                "D. Zhang",
                "K. Song",
                "Q. Wang",
                "Y. He",
                "X. Wen",
                "Y. Yan"
            ],
            "title": "Two Deep Learning Networks for Rail Surface Defect Inspection of Limited Samples With Line-Level Label",
            "venue": "IEEE Trans. Ind. Inform",
            "year": 2021
        },
        {
            "authors": [
                "Q. Zhang",
                "B. Wu",
                "Y. Shao",
                "Z. Ye"
            ],
            "title": "Surface Defect Detection of Rails Based on Convolutional Neural Network Multi-Scale-Cross FastFlow",
            "venue": "In Proceedings of the 2022 5th International Conference on Pattern Recognition and Artificial Intelligence (PRAI), Chengdu, China,",
            "year": 2022
        },
        {
            "authors": [
                "M. Niu",
                "K. Song",
                "L. Huang",
                "Q. Wang",
                "Y. Yan",
                "Q. Meng"
            ],
            "title": "Unsupervised Saliency Detection of Rail Surface Defects Using Stereoscopic Images",
            "venue": "IEEE Trans. Ind. Inform",
            "year": 2021
        },
        {
            "authors": [
                "C. Ding",
                "G. Pang",
                "C. Shen"
            ],
            "title": "Catching Both Gray and Black Swans: Open-Set Supervised Anomaly Detection",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2022
        },
        {
            "authors": [
                "G. Pang",
                "C. Ding",
                "C. Shen",
                "A.V.D. Hengel"
            ],
            "title": "Explainable Deep Few-Shot Anomaly Detection with Deviation Networks",
            "venue": "arXiv 2021,",
            "year": 2021
        },
        {
            "authors": [
                "B. Liu",
                "F. Gao",
                "Y. Li"
            ],
            "title": "Cost-Sensitive YOLOv5 for Detecting Surface Defects of Industrial Products",
            "venue": "Sensors 2023,",
            "year": 2023
        },
        {
            "authors": [
                "B. Li",
                "Q. Gao"
            ],
            "title": "Defect Detection for Metal Shaft Surfaces Based on an Improved YOLOv5 Algorithm and Transfer Learning",
            "venue": "Sensors 2023,",
            "year": 2023
        },
        {
            "authors": [
                "G. Han",
                "T. Li",
                "Q. Li",
                "F. Zhao",
                "M. Zhang",
                "R. Wang",
                "Q. Yuan",
                "K. Liu",
                "L. Qin"
            ],
            "title": "Improved Algorithm for Insulator and Its Defect Detection",
            "venue": "Based on YOLOX. Sensors",
            "year": 2022
        },
        {
            "authors": [
                "J. Zheng",
                "H. Wu",
                "H. Zhang",
                "Z. Wang",
                "W. Xu"
            ],
            "title": "Insulator-Defect Detection Algorithm Based on Improved YOLOv7",
            "venue": "Sensors 2022,",
            "year": 2022
        },
        {
            "authors": [
                "L. Kou",
                "M. Sysyn",
                "S. Fischer",
                "J. Liu",
                "O. Nabochenko"
            ],
            "title": "Optical Rail Surface Crack Detection Method Based on Semantic Segmentation Replacement for Magnetic Particle Inspection",
            "venue": "Sensors 2022,",
            "year": 2022
        },
        {
            "authors": [
                "T. Defard",
                "A. Setkov",
                "A. Loesch",
                "R. Audigier"
            ],
            "title": "PaDiM: A Patch Distribution Modeling Framework for Anomaly Detection and Localization",
            "venue": "In Pattern Recognition. ICPR International Workshops and Challenges. ICPR 2021;",
            "year": 2020
        },
        {
            "authors": [
                "G. Wang",
                "S. Han",
                "E. Ding",
                "D. Huang"
            ],
            "title": "Student-Teacher Feature Pyramid Matching for Anomaly Detection",
            "venue": "arXiv 2021,",
            "year": 2021
        },
        {
            "authors": [
                "K. Roth",
                "L. Pemula",
                "J. Zepeda",
                "B. Scholkopf",
                "T. Brox",
                "P. Gehler"
            ],
            "title": "Towards Total Recall in Industrial Anomaly Detection",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), New Orleans, LA, USA,",
            "year": 2022
        },
        {
            "authors": [
                "K. He",
                "X. Zhang",
                "S. Ren",
                "J. Sun"
            ],
            "title": "Deep Residual Learning for Image Recognition",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2016
        },
        {
            "authors": [
                "C.-L. Li",
                "K. Sohn",
                "J. Yoon",
                "T. Pfister"
            ],
            "title": "CutPaste: Self-Supervised Learning for Anomaly Detection and Localization",
            "venue": "arXiv 2021,",
            "year": 2021
        },
        {
            "authors": [
                "T. Reiss",
                "N. Cohen",
                "L. Bergman",
                "Y. Hoshen"
            ],
            "title": "PANDA: Adapting Pretrained Features for Anomaly Detection and Segmentation",
            "venue": "In Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, TN, USA,",
            "year": 2021
        },
        {
            "authors": [
                "M. Rudolph",
                "B. Wandt",
                "B. Rosenhahn"
            ],
            "title": "Same Same But DifferNet: Semi-Supervised Defect Detection with Normalizing Flows",
            "venue": "In Proceedings of the 2021 IEEE Winter Conference on Applications of Computer Vision (WACV), Waikoloa, HI, USA,",
            "year": 2021
        },
        {
            "authors": [
                "Z. Chen",
                "Y. Fu",
                "Y. Zhang",
                "Y.-G. Jiang",
                "X. Xue",
                "L. Sigal"
            ],
            "title": "Multi-Level Semantic Feature Augmentation for One-Shot Learning",
            "venue": "IEEE Trans. Image Process",
            "year": 2019
        },
        {
            "authors": [
                "C. Xu",
                "C. Liu",
                "X. Sun",
                "S. Yang",
                "Y. Wang",
                "C. Wang",
                "Y. Fu"
            ],
            "title": "PatchMix Augmentation to Identify Causal Features in Few-Shot Learning 2022",
            "venue": "arXiv 2022,",
            "year": 2022
        },
        {
            "authors": [
                "C. Finn",
                "P. Abbeel",
                "S. Levine"
            ],
            "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
            "venue": "In Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia, PMLR",
            "year": 2017
        },
        {
            "authors": [
                "G.R. Koch"
            ],
            "title": "Siamese Neural Networks for One-Shot Image Recognition",
            "venue": "Master\u2019s Thesis,",
            "year": 2015
        },
        {
            "authors": [
                "O. Vinyals",
                "C. Blundell",
                "T. Lillicrap",
                "D. Wierstra"
            ],
            "title": "Matching Networks for One Shot Learning",
            "venue": "In Advances in Neural Information Processing Systems; Curran Associates,",
            "year": 2016
        },
        {
            "authors": [
                "J. Snell",
                "K. Swersky",
                "R.S. Zemel"
            ],
            "title": "Prototypical Networks for Few-Shot Learning 2017",
            "venue": "arXiv 2017,",
            "year": 2017
        },
        {
            "authors": [
                "B. Yang",
                "C. Liu",
                "B. Li",
                "J. Jiao",
                "Q. Ye"
            ],
            "title": "Prototype Mixture Models for Few-Shot Semantic Segmentation",
            "venue": "arXiv 2020,",
            "year": 2020
        },
        {
            "authors": [
                "N. Dong",
                "E.P. Xing"
            ],
            "title": "Few-Shot Semantic Segmentation with Prototype Learning",
            "venue": "BMVC 2018,",
            "year": 2023
        },
        {
            "authors": [
                "J. Gan",
                "Q. Li",
                "J. Wang",
                "H. Yu"
            ],
            "title": "A Hierarchical Extractor-Based Visual Rail Surface Inspection System",
            "venue": "IEEE Sens. J. 2017,",
            "year": 2017
        },
        {
            "authors": [
                "S. Akcay",
                "D. Ameln",
                "A. Vaidya",
                "B. Lakshmanan",
                "N. Ahuja",
                "U. Genc"
            ],
            "title": "Anomalib: A Deep Learning Library for Anomaly Detection",
            "venue": "In Proceedings of the 2022 IEEE International Conference on Image Processing (ICIP),",
            "year": 2022
        },
        {
            "authors": [
                "S. Zagoruyko",
                "N. Komodakis"
            ],
            "title": "Wide Residual Networks 2017",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "Citation: Min, Y.; Wang, Z.; Liu, Y.;\nWang, Z. FS-RSDD: Few-Shot Rail\nSurface Defect Detection with\nPrototype Learning. Sensors 2023, 23,\n7894. https://doi.org/10.3390/\ns23187894\nAcademic Editor: Yi Qin\nReceived: 4 August 2023\nRevised: 29 August 2023\nAccepted: 5 September 2023\nPublished: 15 September 2023\nCopyright: \u00a9 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: rail surface defect detection; few-shot learning; prototype learning; transfer learning; unsupervised anomaly detection"
        },
        {
            "heading": "1. Introduction",
            "text": "The rapid growth of railway operation mileage in recent years, due to the construction of numerous new railway lines in many countries, has significantly increased the pressure on maintenance. During the daily operation of railway systems, the interaction between wheels and rails inevitably leads to surface defects such as spalling, corrugation, and grinding, which pose serious hidden dangers to safe operation. Unlike internal defects in rails that can be detected using techniques such as ultrasound [1] and eddy current [2,3], traditional rail surface defect detection is mainly conducted through manual visual inspection, which is inefficient and heavily relies on human workers\u2019 experience [4]. In recent years, many researchers have focused on developing machine vision-based rail surface defect detection technologies that offer higher efficiency and accuracy to address the aforementioned issues. With the rapid development of artificial intelligence technology, deep-learning-based algorithms, specifically supervised learning-based defect detection algorithms, are being widely applied in rail surface defect detection [5\u20138]. However, defect samples are difficult to obtain in practical work; thus, defect detection methods based on supervised learning face two important challenges due to insufficient defect samples. One of them is the risk of overfitting caused by the limited training data, which may not adequately represent the distribution of defect; additionally, supervised learning methods typically require the use of a portion of the defect data for training,\nSensors 2023, 23, 7894. https://doi.org/10.3390/s23187894 https://www.mdpi.com/journal/sensors\nSensors 2023, 23, 7894 2 of 19\nleading to a reduction in the number of testing samples available for validation, which affects the credibility of the validation results. Inspired by the concept of anomaly detection (AD), some researchers have turned their attention to utilizing unsupervised learning techniques to address the aforementioned issues in the field of defect detection [9\u201311]. However, these unsupervised learning-based methods rely completely on modeling the distribution of normal samples, lacking an understanding of defect data, which may lead to poor classification performance and a potentially high false-positive/negative rate [12]. To tackle the aforementioned shortcomings of supervised learning-based defect detection methods, this paper proposes a few-shot rail surface defect detection model called FS-RSDD (few-shot rail surface defect detection). Inspired by the prototype learning and feature-embedding-based unsupervised AD (anomaly detection algorithms), FS-RSDD uses a pre-trained neural network as a feature extractor for both normal and defective rail images. Global average pooling and mask average pooling are used to embed features for normal and defective samples, respectively, which aim to compress the feature maps into feature vectors to obtain a compact feature memory bank. Subsequently, an unsupervised learning algorithm is used to obtain the feature prototypes of normal samples. Finally, the detection of rail defects is accomplished through the similarity computation between input features and prototypes. In summary, our main contributions are as follows:\n1. To overcome the challenges associated with using supervised learning-based defect detection algorithms when there is insufficient defect data available, we have introduced a simple yet effective few-shot rail surface defect detection method called FS-RSDD, which combines unsupervised anomaly detection with prototype learning. By effectively integrating the feature prototypes of normal rail images and defect rail images, we have achieved high accuracy in detecting rail surface defects with very little defect samples used for training. 2. By avoiding the partitioning of normal rail backgrounds into small image patches and individually modeling the feature distribution of each image patch, FS-RSDD achieves a compact feature memory bank for normal rail samples, alleviating the issue of memory bank redundancy in feature-embedding-based unsupervised anomaly detection algorithms. 3. FS-RSDD extensively leverages the fusion of multi-scale features to improve prediction accuracy. Furthermore, due to the integration of both normal background feature prototypes and defect feature prototypes for defect detection, the performance of the FS-RSDD model remains stable and robust compared to other few-shot industrial defect detection algorithms, even when the quality of the defect samples used for training is relatively low. 4. Through extensive experiments, our method outperformed most existing few-shot supervised defect detection algorithms under the same number of defect samples used for training and achieved comparable performance to existing unsupervised anomaly detection algorithms which assume the availability of normal training samples only."
        },
        {
            "heading": "2. Related Works",
            "text": ""
        },
        {
            "heading": "2.1. Rail Surface Defect Detection",
            "text": "Previous research on rail surface defect detection often utilizes traditional image processing techniques to extract features from defect images and trains detection models using corresponding machine learning methods [13\u201316]. However, the performance of these methods is limited by the design of feature extraction, and the detection results can easily be affected by factors such as lighting, noise, and other factors. With the rapid development of deep learning technology, an increasing number of researchers have started studying rail surface defect detection methods based on deep learning, especially supervised learning methods. Wang Hao et al. integrated the improved pyramid feature fusion and modified loss function into the Mask-RCNN algorithm for the purpose of detecting rail surface defects [4]. Meng Si et al. proposed a multi-task architecture for rail surface defect detection, which includes two branch models for rail detection and defect segmentation [17]. Zhang\nSensors 2023, 23, 7894 3 of 19\nHui et al. cascaded the one-stage object detection algorithms SSD and YOLOv3, integrating the detection results from both networks to improve the accuracy of rail surface defect detection [18]. However, these approaches neglected the fact that defect samples are scarce and difficult to obtain in practical work. Due to the limited number of defect samples in the field of defect detection, supervised algorithms-based defect detection models often face issues of overfitting and low validation credibility. To address these problems, many researchers have proposed corresponding solutions. D. Zhang et al. partitioned the rail image data into multiple segments and trained the defect detection model. However, this approach did not fundamentally solve the problem [19], and more researchers have recently started studying steel rail surface defect algorithms based on unsupervised anomaly detection algorithms. Q. Zhang et al. implemented the detection of rail surface defects using the multi-scale cross FastFlow model [20], while Menghui Niu et al. proposed an unsupervised stereoscopic saliency detection method for detecting rail surface defects and achieved good detection results [21]. However, some studies have pointed out that unsupervised anomaly defect detection algorithms often lead to a higher false detection rate [22,23] due to the lack of knowledge about defect samples during the training process. In this paper, we propose a simple yet effective few-shot rail surface defect detection algorithm that fully utilizes the feature information of normal steel rail samples and defect sample information to achieve defect detection."
        },
        {
            "heading": "2.2. Unsupervised Anomaly Detection for Industrial Images",
            "text": "Deep-learning-based algorithms are being widely used in industrial defect detection research in recent years due to their high efficiency and accuracy. Many researchers have devoted themselves to researching industrial defect detection algorithms based on supervised learning algorithms, which significantly depends on labeled defect data [24\u201329]. However, due to the hardship of collecting defective samples, it is extremely hard to obtain enough defect data for a deep model to learn its distribution. Furthermore, supervised learning-based methods require defect data for training, which further restricts the quantity of test datasets and affects the credibility of validation performance. In recent years, unsupervised-based anomaly detection (AD) algorithms have become the mainstream paradigm for industrial defect detection, which can be categorized as reconstruction-based and feature-embedding-based [30\u201332]. Reconstruction-based methods aim to train a deep network such as an adversarial generative network (GAN) or auto encoder (AE) to reconstruct normal images. When defective images are fed into the network, the defective parts cannot be reconstructed well, allowing for the detection of defects. However, sometimes the model can also yield a good reconstruction for the defective parts due to the powerful ability of the deep model [30]. Feature-embedding-based methods became the prevalent architecture in recent years, which typically consisted of a feature extractor and a feature estimator. A feature extractor is a deep network, typically a ResNet [33], that is pre-trained on ImageNet datasets. It is used to extract features from normal images, which are then stored into a memory bank. A feature estimator is used to estimate the distribution for normal features, which can be a multidimensional Gaussian distribution [34], clustering methods [35], or flowbased methods [36]. To avoid the deviation caused by different data distribution between industrial images and ImageNet datasets, only features from shallow layers are used. After distribution estimation, a distance metric is typically used to detect defects, since defects should be far from the center of the estimated distribution. One major drawback of embedding-based anomaly detection algorithms is that they estimate the distribution separately for each patch of the feature map, resulting in a massive and redundant feature memory bank to restore features from each patch. Many researchers have tried different methods to alleviate the problem: Padim experimentally studied the possibility to reduce redundancy of the memory bank and eventually chose to randomly discard a portion of the extracted features [30]; Patchcore utilized a coreset subsampling method to select representative features [32], thereby compressing the size of the feature memory bank.\nSensors 2023, 23, 7894 4 of 19\nThis paper introduces a feature representation method widely used in few-shot learning, which obtains a representative and compact feature memory bank and alleviates the aforementioned redundancy problem of the memory bank for rail surface defect detection."
        },
        {
            "heading": "2.3. Few-Shot Learning",
            "text": "In recent years, deep learning algorithms based on supervised learning have garnered significant attention from researchers due to the remarkable ability of deep models and large-scale datasets with high-quality labels. However, it is well known that supervised algorithms fail to acquire strong generalization ability when trained on a dataset with a small amount of data. Moreover, in many fields such as industrial defect detection, collecting a large-scale dataset with high-quality annotations proves to be challenging. This realization has prompted many researchers to shift their focus to the field of few-shot learning, with the aim of enabling the model to obtain strong generalization ability with only a few samples, akin to human beings. Within the domain of few-shot learning in computer vision, image classification tasks are a prominent focal point. These tasks can be broadly categorized into three distinct classes: data-augmentation-based methods, parameter-optimization-based methods, and metric-learning-based methods. Data-augmentation-based methods aim to address the challenge of limited samples in few-shot learning indirectly by enhancing the intricacy of the dataset through data augmentation. Trinet [37] employs autoencoders to map the features to the semantic space, followed by mapping the augmented features back to the sample space via semantic nearest neighbor search. Moreover, Patchmix [38] resolves the issue of distribution shift by substituting a specific region of the query image with random gallery images from diverse categories. Parameter-optimization-based methods generally first train a meta-learner to learn common features (prior knowledge) of different tasks and then apply the obtained metaknowledge to fine-tune the base learner on the query set. The model-agnostic metalearning (MAML) [39], which first trains the model on a large number of task sets to obtain an adaptable weight and then fine-tunes the model on the target task to obtain the final classifier. Metric-learning-based methods leverage pre-trained neural networks to extract features from training data. These extracted features are then utilized to measure similarity between the training data and test data using a metric. Representative methods include Siamese networks [40] and matching networks [41]. The former inputs two samples into the neural network and compares the similarity of the output feature vectors, while the latter uses attention mechanisms to obtain information about the correlation between feature vectors. A typical embedding-based approach to few-shot image classification is the prototypical network [42], which utilizes a pre-trained model to extract features from a limited amount of labeled data and learns corresponding feature prototypes from them. The network then produces a distribution over classes for an input feature based on a softmax function over distances to the prototypes in the embedding space. The prototypical network approach, combined with the utilization of mask average pooling, has been widely adopted in few-shot semantic segmentation methods. In addition, the idea of prototype features in prototypical networks has also been widely applied in many unsupervised anomaly detection algorithms [43,44]."
        },
        {
            "heading": "3. Methods",
            "text": "This paper proposes an approach for rail surface defect detection called FS-RSDD. It aims to tackle the challenge of detecting surface defects with a limited number of defect samples. The proposed model combines defect feature prototypes and background feature prototypes to enable few-shot learning in this task. The architecture of the model is depicted in Figure 1, illustrating the integration of the proposed approach.\nSensors 2023, 23, 7894 5 of 19\nSensors 2023, 23, x FOR PEER REVIEW 5 of 20\n3. Methods\nThis paper proposes an approach for rail surface defect detection called FS-RSDD. It\naims to tackle the challenge of detecting surface defects with a limited number of defect\nsamples. The proposed model combines defect feature prototypes and background fea-\nture prototypes to enable few-shot learning in this task. The architecture of the model is\ndepicted in Figure 1, illustrating the integration of the proposed approach.\nFigure 1. The architecture of proposed model.\nFigure 1 depicts the proposed method, which consists of two parts: embedding ex-\ntraction and prediction. In the embedding extraction phase, the approach is inspired by\nfeature-embedding-based anomaly detection techniques. A pre-trained model is em-\nployed for extracting multi-scale features from the training set images. These extracted\nfeatures are then processed to generate a compact memory bank.\nDuring the prediction phase, the feature prototypes obtained from the embedding\nextraction phase are utilized to calculate the multi-scale similarity feature maps with the\nfeature map of test images. These similarity feature maps of normal and defect samples\nare then synthesized at each scale to generate a segmentation probability map. Finally, the\nprobability map is smoothed to obtain the final prediction result. This process enables the\ndetection of rail surface defects with high accuracy with limited defect samples.\n3.1. Embedding Extraction\nIn this paper, a ResNet \ud835\udc54(\u2219) pre-trained on the public dataset ImageNet is em-\nployed as a feature extractor, and k is defined as a layer index of ResNet. In order to avoid\nthe deviation caused by different data distribution between industrial images and\nImageNet datasets, only features from first three layers are used; thus, \ud835\udc58 \u2208 {1,2,3}. First, the pre-trained model weights are fixed, and then the training set images are\npassed through the feature extractor. Next, the feature maps are extracted from the shal-\nlow layer of the network. Specifically, we are presented with {\ud835\udc41\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b, \ud835\udc37\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b}, in which subset\ud835\udc41\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b = {\ud835\udc651, \ud835\udc652,\u2219\u2219\u2219, \ud835\udc65\ud835\udc41} only contains normal samples and subset \ud835\udc37\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b = {\ud835\udc65\ud835\udc41+1, \ud835\udc65\ud835\udc41+2,\u2219\u2219\u2219 , \ud835\udc65\ud835\udc41+\ud835\udc40} only contains defect samples with \ud835\udc41 \u226b \ud835\udc40. As shown in Equations (1) and (2), \ud835\udc39\ud835\udc37 \ud835\udc58 and \ud835\udc39\ud835\udc41 \ud835\udc58 refer to the defect feature maps and normal feature maps, respectively. They are obtained from the k-th layer of the feature extractor, which is denoted as \ud835\udc54\ud835\udc58(\u2219). \ud835\udc40 and \ud835\udc41 refer to number of defect samples and normal samples respectively. \ud835\udc36\ud835\udc58, \ud835\udc3b\ud835\udc58, \ud835\udc4a\ud835\udc58 refer to channels, height, and width of feature map from layer k.\n\ud835\udc39\ud835\udc41 \ud835\udc58 = \ud835\udc54\ud835\udc58(\ud835\udc41\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b), \ud835\udc39\ud835\udc41 \ud835\udc58 \u2208 \ud835\udc45\ud835\udc41\u00d7\ud835\udc36\ud835\udc58\u00d7\ud835\udc3b\ud835\udc58\u00d7\ud835\udc4a\ud835\udc58 (1)\n\ud835\udc39\ud835\udc37 \ud835\udc58 = \ud835\udc54\ud835\udc58(\ud835\udc41\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b), \ud835\udc39\ud835\udc37 \ud835\udc58 \u2208 \ud835\udc45\ud835\udc40\u00d7\ud835\udc36\ud835\udc58\u00d7\ud835\udc3b\ud835\udc58\u00d7\ud835\udc4a\ud835\udc58 (2)\nFigure 1. The architecture of proposed model.\nFigure 1 depicts the proposed method, which consists of two parts: embedding extraction and prediction. In the embedding extraction phase, the approach is inspired by feature-embedding-based anomaly detection techniques. A pre-trained model is employed for extracting multi-scale features from the training set images. These extracted features are then processed to generate a compact memory bank. During the prediction phase, the feature prototypes obtained from the embedding extraction phase are utilized to calculate the multi-scale similarity feature maps with the feature map of test images. These similarity feature maps of normal and defect samples are then synthesized at each scale to generate a segmentation probability map. Finally, the probability map is smoothed to obtain the final prediction result. This process enables the detection of rail surface defects with high accuracy with limited defect samples."
        },
        {
            "heading": "3.1. Embedding Extraction",
            "text": "In this paper, a ResNet g(\u00b7) pre-trained on the public dataset ImageNet is employed as a feature extractor, and k is defined as a layer i dex of ResNet. In order to avoid the deviation c used by different data di tribution betwe n i ustrial images and ImageNet datasets, only feat res from first three layers are used; thus, k \u2208 {1, 2, 3}. First, the pre-trained model weight are fixed, and then the training set images are passed t rough the feature extractor. Next, the feature maps are extracted from the shallow layer of the n twork. Specifically, we are pre ented with {Ntrain, Dtrain}, in hich subs t Ntrain = {x1, x2, \u00b7 \u00b7 \u00b7 , xN} only contains normal samples and subset Dtrain = {xN+1, xN+2, \u00b7 \u00b7 \u00b7 , xN+M} only contains defect sample with N M. As shown in Equations (1) and (2), FkD and F k N refer to the defect feature maps and normal feature maps, respectively. They are obtain d from the k-th layer of the feature extractor, which s denoted as gk(\u00b7). M and N refer to number f defect samples nd normal samples r spectively. Ck, Hk, Wk ref r to channels, height, and width of featu e map from layer k.\nFkN = gk(Ntrain), F k N \u2208 RN\u00d7Ck\u00d7Hk\u00d7Wk (1)\nFkD = gk(Ntrain), F k D \u2208 RM\u00d7Ck\u00d7Hk\u00d7Wk (2)\nAfter obtaining the feature representations from defective and normal rail images, the corresponding feature memory bank can be created by the proposed process."
        },
        {
            "heading": "3.2. Compact Multi-Scale Memory Bank",
            "text": "After obtaining the corresponding feature maps, the global average pooling (GAP) operation is applied to the feature maps of normal rail images. This operation fuses the global information of normal samples into a feature vector. On the other hand, for defective rail images, since the defective parts only occupy a small portion of the entire image, the\nSensors 2023, 23, 7894 6 of 19\nmask average pooling (MAP) operation is used. This operation, as shown in Figure 2, is widely employed in few-shot semantic segmentation. It eliminates the features of normal parts in the feature map and only preserves the defect-specific features by element-wise production between feature map and mask, and then global average pooling is applied to obtain the prototype of defects.\nSensors 2023, 23, x FOR PEER REVIEW 6 of 20 After obtaining the feature representations from defective and normal rail images, the corresponding feature memory bank can be created by the proposed process.\n3.2. Compact Multi-Scale Memory Bank\nAfter obtaining the corresponding feature maps, the global average pooling (GAP)\noperation is applied to the feature maps of normal rail images. This operation fuses the\nglobal information of normal samples into a feature vector. On the other hand, for defec-\ntive rail images, since the defective parts only occupy a small portion of the entire image,\nthe mask average pooling (MAP) operation is used. This operation, as shown in Figure 2,\nis widely empl yed in few-shot semantic segmentation. It eliminates the features of nor-\nmal parts in the feature map and only preserves the defect-specific features by element-\nwise production between feature map and mask, and then global average pooling is ap-\nplied to obtain the prototype of defects.\nFigure 2. Mask average pooling.\nIn Equations (3) and (4), GAP represents the global average pooling operation,\n\ud835\udc5a\ud835\udc4e\ud835\udc60\ud835\udc58\ud835\udc37\ud835\udc57 \ud835\udc58 represents the ground truth mask, \ud835\udc5d\ud835\udc37 \ud835\udc58(\ud835\udc65\ud835\udc57) represents the feature prototype, both \ud835\udc5a\ud835\udc4e\ud835\udc60\ud835\udc58\ud835\udc37\ud835\udc57 \ud835\udc58 and \ud835\udc5d\ud835\udc37 \ud835\udc58(\ud835\udc65\ud835\udc57) correspond to a certain defective sample \ud835\udc65\ud835\udc57, and \ud835\udc5d\ud835\udc5b \ud835\udc58(\ud835\udc65\ud835\udc56) represents the feature prototype of the normal sample \ud835\udc65\ud835\udc56. Additionally, \ud835\udc53\ud835\udc37 \ud835\udc58(\ud835\udc65\ud835\udc57) indicates a feature map corresponding to a certain image \ud835\udc65\ud835\udc57, and \ud835\udc53\ud835\udc41 \ud835\udc58(\ud835\udc65\ud835\udc56) indicates a feature map corresponding to \ud835\udc65\ud835\udc56. \u2299 indicates the Hadamard product.\n\ud835\udc5d\ud835\udc37 \ud835\udc58(\ud835\udc65\ud835\udc57) = \ud835\udc3a\ud835\udc34\ud835\udc43(\ud835\udc53\ud835\udc37 \ud835\udc58(\ud835\udc65\ud835\udc57) \u2299 \ud835\udc5a\ud835\udc4e\ud835\udc60\ud835\udc58\ud835\udc37\ud835\udc57 \ud835\udc58 ), \ud835\udc5d\ud835\udc37 \ud835\udc58 \u2208 \ud835\udc45\ud835\udc36\ud835\udc58 , \ud835\udc65\ud835\udc57 \u2208 \ud835\udc37\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b (3)\n\ud835\udc5d\ud835\udc41 \ud835\udc58 (\ud835\udc65\ud835\udc56) = \ud835\udc3a\ud835\udc34\ud835\udc43 (\ud835\udc53\ud835\udc41 \ud835\udc58(\ud835\udc65\ud835\udc56)), \ud835\udc5d\ud835\udc41 \ud835\udc58 \u2208 \ud835\udc45\ud835\udc36\ud835\udc58 , \ud835\udc65\ud835\udc56 \u2208 \ud835\udc37\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b (4)\nThe global average pooling operation is shown in Equation (5), where \ud835\udc5d\ud835\udc41 \ud835\udc58 (\ud835\udc65\ud835\udc56) repre-\nsents the normal feature prototype obtained by applying global average pooling to a certain normal feature in the layer k, and \ud835\udc53\ud835\udc41 \ud835\udc58(\ud835\udc65\ud835\udc56)(\u210e, \ud835\udc64) represents the value of feature map \ud835\udc53\ud835\udc41 \ud835\udc58(\ud835\udc65\ud835\udc56) at position (h,w).\n\ud835\udc5d\ud835\udc41 \ud835\udc58 (\ud835\udc65\ud835\udc56) =\n1\n\ud835\udc3b\ud835\udc58 \u2219 \ud835\udc4a\ud835\udc58 \u2211 \u2211 \ud835\udc53\ud835\udc41\n\ud835\udc58(\ud835\udc65\ud835\udc56)(\u210e, \ud835\udc64), \ud835\udc5d\ud835\udc41 \ud835\udc58 \u2208 \ud835\udc45\ud835\udc36\ud835\udc58\n\ud835\udc4a\ud835\udc58\n\ud835\udc64=1\n\ud835\udc3b\ud835\udc58\n\u210e=1\n(5)\nAs the number of normal samples used is significantly higher than the number of\ndefect samples, which is distinct from the few-shot learning scenario, unsupervised algo-\nrithms can be used to obtain the distribution of normal sample features. Instead of esti-\nmating the feature prototype using the mean of sample features, as carried out in the pro-\ntotypical network, this study adopts a widely used clustering algorithm, K-Means, to clus-\nter the normal sample features. The cluster centers are then used as the final feature pro-\ntotypes of the normal samples.\nFigur . average po ling.\nIn Equations (3) and (4), GAP represents the global average pooling operation, maskkDj represents the ground truth mask, pkD ( xj )\nrepresents the feature prototype, both maskkDj and pkD ( xj )\ncorrespond to a certain defective sample xj, and pkn(xi) represents the feature prototype of the normal sample xi. Additionally, f kD ( xj )\nindicates a feature map corresponding to a certain image xj, and f kN(xi) indicates a feature map corresponding to xi. indicates the Hadamard product.\npkD ( xj ) = GAP ( f kD ( xj ) maskkDj ) , pkD \u2208 RCk , xj \u2208 Dtrain (3)\npkN(xi) = GAP ( f kN(xi) ) , pkN \u2208 RCk , xi \u2208 Dtrain (4)\nThe global average pooling operation is shown in Equation (5), where pkN(xi) represents the normal feature prototype obtained by applying global average pooling to a certain normal feature in the layer k, and f kN(xi)(h, w) represents the value of feature map f k N(xi) at position (h,w).\npkN(xi) = 1\nHk\u00b7Wk\nHk\n\u2211 h=1\nWk\n\u2211 w=1\nf kN(xi)(h, w), p k N \u2208 RCk (5)\nAs the number of normal samples used is significantly higher than the number of defect samples, which is distinct from the few-shot learning scenario, unsupervised algorithms can be used to obtain the distribution of nor al sample features. Instead of estimating the feature pr otype using the mean of l features, as carried out in the prototypical network, this study adopts a widely used cl algorithm, K-Means, to cluster the normal sample features. The cluster centers are then used as the final feature prototypes of the normal samples. For the normal sample feature prototype, which consists of a set of feature vectors, clustering is performed with a predetermined number of clusters denoted as n. In this study, a cluster center number of 30 is chosen to cluster the normal samples, and the resulting cluster centers are utilized as the final feature prototypes. Since the number of\nSensors 2023, 23, 7894 7 of 19\ndefect sample features is relatively small, no clustering is conducted, and they are directly used as feature prototypes. All prototypes will be stored as a memory bank."
        },
        {
            "heading": "3.3. Pixel-Level Defect Detection",
            "text": "After completing the construction of memory bank, the detection process involves several steps as illustrated in Figure 3. First, the test image is fed into the corresponding feature extractor, which is then used to extract multi-scale intermediate features of the image. Next, the obtained intermediate features are then compared to the feature prototypes obtained during the model construction stage, and based on their similarity, corresponding similarity feature maps are calculated.\nSensors 2023, 23, x FOR PEER REVIEW 7 of 20\nFor the normal sample feature prototype, which consists of a set of feature vectors,\nclustering is performed with a predetermined number of clusters denoted as n. In this\nstudy, a cluster center number of 30 is chosen to cluster the normal samples, and the re-\nsulting cluster centers are utilized as the final feature prototypes. Since the number of\ndefect sample features is relatively small, no clustering is conducted, and they are directly\nused as feature prototypes. All prototypes will be stored as a memory bank.\n3.3. Pixel-Level Defect Detection\nAfter completing the construction of memory bank, the detection process involves\nseveral steps as illustrated in Figure 3. First, the test image is fed in o the c rre ponding\nfeatu e extractor, which is then used to extract mult -scal nt rmediate features of the\nim ge. Next, the obtained intermediate features are then compared to th f t proto-\ntypes obtained during the model construction stage, a d based on their similarity, corre-\nsponding similarity feature maps are calculated.\nFigure 3. Detection procedure of FS-RSDD.\nThe features obtained from the test images are compared to the corresponding multi-\nscale normal and defect prototypes at each position using a similarity calculation \ud835\udc60(\u2219). The\nsimilarity calculation between input and prototypes is shown in Equations (6) and (7). \ud835\udc46\ud835\udc37 \ud835\udc58(\ud835\udc65)(\u210e, \ud835\udc64) refers to the similarity between defect feature prototypes and input image feature map at position (h,w), similarly \ud835\udc46\ud835\udc41 \ud835\udc58(\ud835\udc65)(\u210e, \ud835\udc64) refers to the similarity between normal feature prototypes and input image feature map. Specifically, \ud835\udc53\ud835\udc56\ud835\udc5a\ud835\udc54 \ud835\udc58 denotes feature map of a input image.\n\ud835\udc46\ud835\udc37 \ud835\udc58(\ud835\udc65)(\u210e, \ud835\udc64) =\n1 \ud835\udc5b \u2211 \ud835\udc60 (\ud835\udc5d\ud835\udc37 \ud835\udc58(\ud835\udc65\ud835\udc56), \ud835\udc53\ud835\udc56\ud835\udc5a\ud835\udc54 \ud835\udc58 (\u210e, \ud835\udc64)) ,\n\ud835\udc5b\n\ud835\udc56=1\n\ud835\udc46\ud835\udc37 \ud835\udc58(\ud835\udc65)(\u210e, \ud835\udc64) \u2208 \ud835\udc45 (6)\n\ud835\udc46\ud835\udc41 \ud835\udc58(\ud835\udc65)(\u210e, \ud835\udc64) =\n1 \ud835\udc5b \u2211 \ud835\udc60 (\ud835\udc5d\ud835\udc41 \ud835\udc58 (\ud835\udc65\ud835\udc56), \ud835\udc53\ud835\udc56\ud835\udc5a\ud835\udc54 \ud835\udc58 (\u210e, \ud835\udc64)) , \ud835\udc46\ud835\udc41 \ud835\udc58(\ud835\udc65)(\u210e, \ud835\udc64) \u2208 \ud835\udc45\n\ud835\udc5b\n\ud835\udc56=1\n(7)\nIn this study, cosine similarity was chosen for similarity calculation. The calculation\nprocess for the similarity feature map is demonstrated in Equation (8), where the defect prototype \ud835\udc5d\ud835\udc37 \ud835\udc58(\ud835\udc65\ud835\udc57) and input image feature map \ud835\udc53\ud835\udc56\ud835\udc5a\ud835\udc54 \ud835\udc58 (\u210e, \ud835\udc64) are both vectors of length \ud835\udc36\ud835\udc58.\n\ud835\udc60 (\ud835\udc5d\ud835\udc37 \ud835\udc58(\ud835\udc65\ud835\udc57), \ud835\udc53\ud835\udc56\ud835\udc5a\ud835\udc54\n\ud835\udc58 (\u210e, \ud835\udc64)) = \ud835\udc5d\ud835\udc37\n\ud835\udc58(\ud835\udc65\ud835\udc57) \u2219 \ud835\udc53\ud835\udc56\ud835\udc5a\ud835\udc54 \ud835\udc58 (\u210e, \ud835\udc64)\n\u2016\ud835\udc5d\ud835\udc37 \ud835\udc58(\ud835\udc65\ud835\udc57)\u20162 \u00d7 \u2016\ud835\udc53\ud835\udc56\ud835\udc5a\ud835\udc54 \ud835\udc58 (\u210e, \ud835\udc64)\u2016 2\n(8)\nAfter performing similarity calculations between all feature prototypes and the input\nimage features, a probability distribution over defects for each position in the image is\nestablished using softmax. This allows us to obtain the probability of each position being\nThe features obtained from the test images are compared to the corresponding multiscale normal and defect prototypes at each position using a similarity calculation s(\u00b7). The similarity calculation between input and prototypes is shown in Equations (6) and (7). SkD(x)(h, w) refers to the similarity between defect feature prototypes and input image feature map at position (h,w), similarly SkN(x)(h, w) refers to the similarity between normal feature prototypes and input image feature map. Specifically, f kimg denotes feature map of a input image.\nSkD(x)(h, w) = 1 n\nn\n\u2211 i=1\ns (\npkD(xi), f k img(h, w) ) ,SkD(x)(h, w) \u2208 R (6)\nSkN(x)(h, w) = 1 n\nn\n\u2211 i=1\ns (\npkN(xi), f k img(h, w) ) , SkN(x)(h, w) \u2208 R (7)\nIn this study, cosine similarity was chosen for similarity calculation. The calculation process for the similarity feature map is demonstrated in Equation (8), where the defect prototype pkD ( xj ) and input image feature map f kimg(h, w) are both vectors of length Ck.\ns ( pkD ( xj ) , f kimg(h, w) ) = pkD ( xj ) \u00b7 f kimg(h, w)\u2225\u2225pkD(xj)\u2225\u22252 \u00d7 \u2225\u2225\u2225 f kimg(h, w)\u2225\u2225\u22252 (8)\nAfter p rforming sim larity calc lations betwe n all feature rototypes and the input image f at res, a probability distribution ver def cts for each position in the image is established using softmax. This allows us to obtain the probability of each position\nSensors 2023, 23, 7894 8 of 19\nbeing a defect, as shown in Equation (9), where q(y = de f ect|x ) represents the conditional probability that y belongs to defect under the premise of given input x:\nq(y = de f ect| x) = 1 3\n3\n\u2211 k=1\nexp (\nSkD(x)(h, w) exp ( SkD(x)(h, w) + exp ( SkN(x)(h, w) ) (9) By combining Equation (9), we can observe that the essence of FS-RSDD is to evaluate\nthe similarity between input samples and defect prototypes, as well as the dissimilarity between input samples and normal prototypes in three feature spaces (obtained from three layers of the feature extractor), as illustrated in Figure 4. Finally, defect detection is performed by integrating the prediction results from the three feature spaces, as shown in Equation (9).\nSensors 2023, 23, x FOR PEER REVIEW 8 of 20\na defect, as shown in Equation (9), where \ud835\udc5e(\ud835\udc66 = \ud835\udc51\ud835\udc52\ud835\udc53\ud835\udc52\ud835\udc50\ud835\udc61|\ud835\udc65) represents the conditional\nprobability that y belongs to defect under the premise of given input x:\n\ud835\udc5e(\ud835\udc66 = \ud835\udc51\ud835\udc52\ud835\udc53\ud835\udc52\ud835\udc50\ud835\udc61|\ud835\udc65) = 1\n3 \u2211\n\ud835\udc52\ud835\udc65\ud835\udc5d(\ud835\udc46\ud835\udc37 \ud835\udc58(\ud835\udc65)(\u210e, \ud835\udc64)\n\ud835\udc52\ud835\udc65\ud835\udc5d(\ud835\udc46\ud835\udc37 \ud835\udc58(\ud835\udc65)(\u210e, \ud835\udc64) + \ud835\udc52\ud835\udc65\ud835\udc5d(\ud835\udc46\ud835\udc41 \ud835\udc58(\ud835\udc65)(\u210e, \ud835\udc64))\n3\n\ud835\udc58=1\n(9)\nBy combining Equation (9), we can observe that the essence of FS-RSDD is to evaluate\nthe similarity between input samples and defect prototypes, as well as the dissimilarity\nbetween input samples and norm l prototy es in three feature spaces (obta ned from\nthree layers of the feature ext actor), as illu trated in Fig 4. Finally, defect detection is\nperformed by integrating the prediction results from the three feature spaces, as shown in\nEquation (9)."
        },
        {
            "heading": "3.4. Image-Level Defect Detection",
            "text": "Image-level defect detection aims to perform image-level binary classification be-\ntween normal rail images and rail images containing defects. By processing the predicted\nresults in Section 3.3 accordingly, we can obtain the corresponding image-level prediction\nresults.\nOur approach is based on a simple idea. If we define \ud835\udc5e(\ud835\udc66 = \ud835\udc51\ud835\udc52\ud835\udc53\ud835\udc52\ud835\udc50\ud835\udc61|\ud835\udc65) in Section 3.3\nas the defect score of a certain pixel, we can represent the probability of an image contain-\ning defects by considering the defect score of the pixel with the highest defect score in the\npredicted image. However, this approach leads to poor performance, as it only considers\nindividual pixels and lacks consideration for the local neighborhood pixels. In order to\nfurther improve the detection accuracy, we decided to use a simple Gaussian blur to fuse\ninformation from the local neighborhood of pixels. The process of Gaussian blur on an\nimage is the convolution of the image with a two-dimensional Gaussian distribution that\nhas been discretely sampled, as shown in Figure 5. Subsequently, we performed image-\nlevel defect detection. This approach significantly improved the performance of our\nmodel, as demonstrated in Section 4.3."
        },
        {
            "heading": "3.4. Image-Level Defect Detection",
            "text": "Image-level defect detection aims to perform image-level binary classification between normal rail images and rail images containing defects. By processing the predicted results in Section 3.3 accordingly, we can obtain the corresponding image-level prediction results. Our approach is based on a simple idea. If we define q(y = de f ect| x) in Section 3.3 as the defect score f a certain pixel, we can represent the probability of a image containing defects by considering the defect score of the pixel with the highest defect score in the predicted image. However, this approach leads to poor performance, as it only considers individual pixels and lacks consideration for the local neighborhood pixels. In order to further improve the detection accuracy, we decided to use a simple Gaussian blur to fuse information from the local neighborhood of pixels. The process of Gaussian blur on an image is the convolution of the image with a two-dimensional Gaussian distribution that has been discretely sampled, as shown in Figure 5. Subsequently, we performed image-level defect detecti n. T is approach significantly improved the performance of our model, as demonstrated in Section 4.3.\nSensors 2023, 23, 7894 9 of 19Sensor 2023, 23, x FOR PEER REVIEW 9 of 20\n4.1. Evaluation Metrics\nThis article focuses on the detection and localization of rail surface defects, which\ninvolves binary classification tasks at both image and pixel levels for defect rail images\nand normal rail images. The receiver operating characteristic (ROC) and precision recall\n(PR) are used as the evaluation metrics for the model.\nThese two performance metrics have different emphases, which enable this study to\ncomprehensively evaluate the performance of the model during the experimental process.\nAdditionally, we assessed the classification performance at both the image level and the\npixel level. These two metrics, respectively, represent the algorithm\u2019s ability to classify\ndefects and accurately locate them. By evaluating performance at both levels, a more com-\nprehensive analysis of the algorithm\u2019s effectiveness can be obtained.\nAs defined in Equations (10) and (11), the x-axis of the ROC curve represents the\nfalse-positive rate (FPR), and the y-axis represents the true-positive rate (TPR), in which\nFP denotes false positives (negative samples falsely predicted as positive), TN denotes\ntrue negatives (negative samples correctly predicted as negative), TP denotes true posi-\ntives (positive samples correctly predicted as positive), and FN denotes false negatives\n(positive samples falsely predicted as negative). A larger area under the ROC curve indi-\ncates better performance of the classifier. In this article, the model evaluation metrics are\ndivided into image-level ROCs and pixel-level ROCs, which correspond to evaluation\nmetrics for images and individual pixels, respectively.\n\ud835\udc39\ud835\udc43\ud835\udc45 = \ud835\udc39\ud835\udc43\n\ud835\udc39\ud835\udc43 + \ud835\udc47\ud835\udc41 (10)\n\ud835\udc47\ud835\udc43\ud835\udc45 = \ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc41 (11)\nThe recall rate is represented on the x-axis of the PR curve, while the accuracy preci-\nsion is depicted on the vertical axis. The definitions of recall and precision are provided in\nEquations (12) and (13), respectively. The area under the PR curve corresponds to the av-\nerage accuracy (AP). A larger area under the PR curve indicates better performance of the\nclassifier.\n\ud835\udc45\ud835\udc52\ud835\udc50\ud835\udc4e\ud835\udc59\ud835\udc59 = \ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc41 (12)\n\ud835\udc43\ud835\udc5f\ud835\udc52\ud835\udc50\ud835\udc56\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b = \ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc43 (13)\n4.2. Experiment Setup"
        },
        {
            "heading": "4. Experiments and Results",
            "text": ""
        },
        {
            "heading": "4.1. Evaluation Metrics",
            "text": "This article focuses on the detection and localization of rail surface defects, which involves binary classification tasks at both image and pixel levels for defect rail images and normal rail images. The receiver operating characteristic (ROC) and precision recall (PR) are used as the evaluation metrics for the model. These two performance etrics have different emphases, which enable this study to comprehensively evaluate the performance of the odel during t e experimental process. Additio ally, we ssessed th classificati n p rformance at both the image level and the pixel level. These two metrics, respectively, represent the algorith \u2019s ability to classify defects and accurately lo ate them. By evaluating performance at both levels, a more comprehensive analysis of t e algorithm\u2019s effectiveness can be obtained. As defined in Equ tions (10) and (11), the x-axis of the ROC curve represents the false-positive rate (FPR), and the y-axis repres nts the true-positive rate (TPR), in whic FP d notes false positives ( egative samples falsely predicted as positive), TN denotes true negatives (negative sampl s correctly r dicted as n gative), TP denotes true positives (positive samples correctly r dicted as positive), and FN denotes false egatives (positive sam les falsely predicted as negative). A l rger area under the ROC curve indicates b tter perform nce of the classifier. In this article, the model evaluation metrics are di ided into image-level ROCs a d pixel-level ROCs, which correspond to evaluation metrics for images and individual pixels, respectively.\nFPR = FP\nFP + TN (10)\nTPR TP\nTP + FN (11)\nThe recall rate is represented on the x-axis of the PR curve, while the accuracy precision is depicted on the vertical axis. The definitions of recall and precision are provided in Equations (12) and (13), respectively. The area under the PR curve corresponds to the average accuracy ( P). A larger area under the PR curve indicates better performance of the classifier.\nRecall = TP\nTP + FN (12)\nPrecision TP\nTP FP (13)\nSensors 2023, 23, 7894 10 of 19\n4.2. Experiment Setup 4.2.1. Dataset Setup\nThis article uses a dataset from the open-source Rail Surface Defect Detection dataset (RSDDS) [45]. RSDDS consists of two types of rail defect data: Type-I and Type-II. TypeI defects were obtained from 67 defect images collected from high-speed train tracks. Type-II defects, on the other hand, were collected from 128 defect images obtained from regular/heavy-duty transportation tracks. In this article, the two types of defect images are first divided into normal samples and defect samples through fixed ratio image cropping. During the cropping process, images that have a too small defect area are discarded. The image processing process is shown in Figure 6.\nSensors 2023, 23, x FOR PEER REVIEW 10 of 20\n4.2.1. Dataset Setup\nThis article uses a dataset from the open-source Rail Surface Defect Detection dataset\n(RSDDS) [45]. RSDDS consists of two types of rail defect data: Type-I and Type-II. Type-I\ndefects were obtained from 67 defect images collected from high-speed train tracks. Type-\nII defects, on the other hand, were collected from 128 defect images obtained from regu-\nlar/heavy-duty transportation tracks. In this article, the two types of defect images are first\ndivided into normal samples and defect samples through fixed ratio image cropping. Dur-\ning the cropping process, i ages that have a too small defect area are discarded. The im-\nage proc ssing process is hown in Figure 6.\nFigure 6. The process of dataset creation.\nAfter the aforementioned process, there are 113 defect samples in Type-I dataset and\n230 defect samples in Type-II dataset. To ensure a balanced representation of positive and\nnegative samples in the test set and to provide a more accurate evaluation of the perfor-\nmance of the proposed method, we randomly selected normal rail samples for the test set,\nensuring that the quantity was consistent with the number of defect samples.\nFinally, the Type-I dataset consisted of 302 normal samples for the training set, 113\ndefect samples, and 113 normal samples for the testing set. Meanwhile, the Type-II dataset\ncomprised 2071 normal samples for the training set, 230 defect samples, and 230 normal\nsamples for the testing set. Additionally, the model necessitates a limited number of defect\nsamples during the training phase, which will be randomly selected from the test set. After\nbeing partitioned and resized, the resolution of Type-I rail images is 160 \u00d7 160, while Type-\nII rail images have a resolution of 64 \u00d7 64.\n4.2.2. Comparison Experiment Setup\nThe proposed method in this article is compared with mainstream unsupervised in-\ndustrial defect detection algorithms and existing few-shot supervised industrial defect de-\ntection algorithms in terms of classification evaluation metrics on the RSDDS dataset.\nAs there may be variations in the defect samples extracted during each training pro-\ncess, a random selection of a small subset of defect samples is employed for training dur-\ning the experimental process. To ensure robustness, multiple experiments are conducted,\nand the average value is considered as the validation result of the model.\nIn the comparison experiments with unsupervised methods, since the defect samples\nfor training are randomly selected in each experiment, the test set may not include the\nexact same defect samples in each experiment. Therefore, to maintain consistency, multi-\nple tests are also conducted on the unsupervised industrial defect detection algorithms,\nand the defect samples utilized for our method are excluded from the test set to ensure a\nFigure 6. The process of dataset creation.\nAfter the aforementioned process, there are 113 defect samples in Type-I dataset and 230 defect samples in Type-II dataset. To ensure a balanced representation of positive and negative samples in the test set and to provide a more accurate evaluation of the performance of the proposed method, we randomly selected normal rail samples for the test set, ensuring that the quantity was consistent with the number of defect samples. Finally, the Type-I dataset consisted of 302 normal samples for the training set, 113 defect samples, and 113 normal samples for the testing set. Meanwhile, the TypeII dataset comprised 2071 normal samples for the training set, 230 defect samples, and 230 normal samples for the testing set. Additionally, the model necessitates a limited number of defect samples during the training phase, which will be randomly selected from the test set. After being partitioned and resized, the resolution of Type-I rail images is 160 \u00d7 160, while Type-II rail images have a resolution of 64 \u00d7 64.\n4.2.2. Comparison Experiment Setup\nThe proposed method in this article is compared with mainstream unsupervised industrial defect detection algorithms and existing f w-shot supervised industrial d fect detec ion algorithms in terms of classification evaluation metrics on the RSDDS datase . As there may be variations in the defect samples extract d duri g each training process, a random selection of a small subset of defect samples is employe for training dur the experimental process. To ensure robustness, multiple experiments are conducted, a d the average valu is considered a the validation result of the model. In the comparison experiments with unsupervised methods, since the defect samples for trai ing are randomly selected in each experiment, the test set may not include the exact same defect samples in each experiment. Therefore, to maintain consistency, multiple tests are also conducted on the unsupervised industrial defect detection algorithms, and the defect samples utilized for our method are excluded from the test set to ensure a fair evaluation of both methods on the same test set, ensuring that the test set used aligns\nSensors 2023, 23, 7894 11 of 19\nconsistently with the test set employed in each experiment of the proposed method in this article. Similarly, when comparing the performance with few-shot supervised industrial defect detection algorithms, multiple experiments are conducted, and the average test results are used as the final performance metric. Additionally, in each experiment, the defect samples utilized for training the few-shot supervised industrial defect detection algorithm are consistent with the defect samples randomly selected for training in the proposed method in this article. Furthermore, the default values were maintained for all other settings of the comparative models in the code. All the comparative models that were involved with the gradient decent process are trained to convergence to guarantee the impartiality of performance comparisons."
        },
        {
            "heading": "4.3. Comparison with Unsupervised-Based Algorithm",
            "text": "The performance comparison results with unsupervised methods are presented in Tables 1\u20133. Table 1 displays the average image-level ROC, Table 2 shows the average image-level AP, and Table 3 presents the average pixel-level ROC. All of these metrics were obtained from 20 random sampling validations. In the training process, \u201cm\u201d refers to the defect sample used. It is worth mentioning that the unsupervised algorithms were implemented using the open-source industrial defect detection library anomalib [46].\nCombining the data from Tables 1 and 2, it can be observed that our proposed method outperforms other unsupervised industrial defect detection algorithms in terms of imagelevel classification ROC, except for PatchCore. However, it does not show significant advantage over other unsupervised algorithms in terms of image-level AP. The reason behind this result lies in the fact that AP is more inclined towards the detection of positive instances, i.e., defect samples, while ROC is a relatively balanced evaluation metric. The better performance of our method in ROC compared to AP may be\nSensors 2023, 23, 7894 12 of 19\nattributed to the fact that, while maintaining a high precision, our method has a lower falsepositive rate for defect detection. However, it has a higher false-negative rate compared to some algorithms, while under the same conditions, some unsupervised defect detection algorithms have a lower false-negative rate but a higher false-positive rate. We further analyzed the defects that were not successfully detected by our method. Figure 7 shows the heatmap of the undetected defect samples and the successfully classified normal samples by our method, under the given defect detection threshold.\nSensors 2023, 23, x FOR PEER REVIEW 12 of 20 Table 3. Pixel-level ROC of our proposed FS-RSDD and other unsupervised anomaly detection models. Model Dataset FS-RSDD Padim PatchCore stfpm cflow fastclow RSDDS Type-I m = 5 0.987 0.976 0.974 0.980 0.970 0.953\nRSDDS Type-I m = 10 0.991 0.977 0.975 0.981 0.971 0.954\nRSDDS Type-II m = 5 0.961 0.920 0.919 0.948 0.852 0.919\nRSDDS Type-II m = 10 0.962 0.920 0.920 0.948 0.855 0.919\nThe reason behind this result lies in the fact that AP is more inclined towards the\ndetection of positive instances, i.e., defect samples, while ROC is a relatively balanced\nevaluation metric. The better performance of our method in ROC compared to AP may be\nattributed to the fact that, while maintaining a high precision, our method has a lower\nf lse-positive rate for defect d tection. However, it has a highe false-negative rat com-\npared to some algorithms, while under the same conditions, some unsupervised defect\ndetection algorithms have a lower false-negative rate but a higher false-positive rate.\nWe furt er analyz d the defects that were not successfully detected by our method.\nFigure 7 shows the heatmap of the undetected defect samples and th successf lly classi-\nfied normal samples by our met od, under the given defect detection threshold.\n(a) (b)\nFigure 7. The heatmap visualization of false negatives and true negatives in the prediction results: (a) heatmap of false negatives, showing high defect scores in the actual defective regions; (b) heatmap of true negatives, showing high anomaly scores for noise or stains that are similar to defects.\nBy observing the heatmap of false-negative samples, we can visually see that the de-\nfective parts in the rail images are actually represented by darker colors. This means that\nour proposed method can accurately distinguish the defect foreground from the normal\nrail background. The reason why these defects were not detected can be further observed\nfrom the predicted results of true-negative samples. We can see that the reason for the\nlower AP in our method is that for those stains or noises that are difficult to distinguish\nfrom defects in the images, our method also considers them as potential defects. Although\nthe probability of these noises belonging to defects may not be significantly higher than\ntrue defects, this ambiguous discrimination leads to our method\u2019s inability to provide\nclear judgments for some challenging cases. In other words, the trade-off of our method\nrarely misclassifying normal samples as defect samples is that some defect samples are\nFigure 7. The heatmap visualization of false negatives and true negatives in the prediction results: (a) heatmap of false negatives, showing high defect scores in the actual defective regions; (b) heatmap of true negatives, showing high anomaly scores for noise or stains that are similar to defects.\nBy observing the heatmap of false-negative samples, we can visually see that the defective parts in the rail i ages are actually represented by darker colors. This means that our proposed method can accurately distinguish the defect foreground from the normal rail background. The reason why these defects were not detected can be further observed from the predicted results of true-negative samples. We can see that the reason for the l wer AP in our method is that for those stains or noises that are difficult to distinguish from defects in the images, our method also considers them s potential defects. Although the probability of these noises b longing to defects may not be significantly higher than true defects, this ambiguous discrimination lead to our method\u2019s in bi ity to p ovide clear judgment for some challenging cases. In other words, e trade-off of our method rarely misclassifying normal samples as d fect samples is that some defect samples are also considered normal samples. As a result, w have a higher ROC but a r latively lower AP. Another thing we can observe from Tables 1 and 2 is that, regardless of the algorithm used, there is a significantly better performance on Type-II data compared to Type-I data. The reason behind this phenomenon is consistent with our previous analysis on the difference in performance between the two metrics, which is the presence of noise and interference in the images. As shown in Figure 8, it can be seen that, perhaps due to better image acquisition conditions, the Type-II rail images contain much less noise compared to Type-I data. In Figure 8, the red curve indicates the defective area, while the green curve indicates the noise that is similar to the defect. It can be clearly seen that Type-I data contain much more noise that interferes with defect detection compared to Type-II data. Furthermore, according to the data in Table 3, we can also observe that our method outperforms most unsupervised AD methods except Patchcore in terms of pixel-level ROC, indicating that our algorithm achieves more precise segmentation for the same defect.\nSensors 2023, 23, 7894 13 of 19\nSensors 2023, 23, x FOR PEER REVIEW 13 of 20 also considered as normal samples. As a result, we have a higher ROC but a relatively lower AP. Another thing we can observe from Tables 1 and 2 is that, regardless of the algorithm used, there is a significantly better performance on Type-II data compared to Type-I data. The reason behind this phenomenon is consistent with our previous analysis on the dif-\nference in performance between the two metrics, which is the presence of noise and inter-\nference in the images. As shown in Figure 8, it can be seen that, perhaps due to better\nimage acquisition conditions, the Type-II rail images contain much less noise compared\nto Type-I data.\nIn Figure 8, the red curve indicates the defective area, while the green curve indicates\nthe noise that is similar to the defect. It can be clearly seen that Type-I data contain much\nmore noise that interferes with defect detection compared to Type-II data.\nFigure 9. Comparison of FS-RSDD with other unsupervised AD models in terms of prediction results.\n4.4. Comparison with Few-Shot Supervised-Based AD Algorithms\nWe also conducted comparative experiments with few-shot industrial defect detec-\ntion algorithms. The experimental setting was similar to the unsupervised algorithm com-\nparison experiment. We conducted 20 experiments, each time randomly selecting m defect\nsamples for model training. The defect samples used for training in the comparative meth-\nods remained consistent with our proposed method. The average ROC and average AP\nwere then calculated for performance comparison, as shown in Table 4. According to the\nresults in the table, considering both the ROC and AP metrics, our method demonstrates\nadvantages compared to DevNet [23] and DRA [22].\nTable 4. Comparison between FS-RSDD and other few-shot industrial defect detection models.\nROC AP\nDataset FS-RSDD DevNet DRA FS-RSDD DevNet DRA\nType-I m = 5 0.941 0.905 0.888 0.943 0.967 0.958\nType-I m = 10 0.952 0.930 0.927 0.953 0.976 0.973\nType-II m = 5 0.989 0.858 0.955 0.986 0.901 0.963\nType-II m = 10 0.991 0.911 0.974 0.986 0.939 0.978\nWe not only compared the average performance but also recorded the performance\nof the model for each experiment in order to observe the impact of different training sam-\nples on the model\u2019s performance.\nFigure 10 shows the changes in the model\u2019s ROC after training with randomly sam-\npled defect data from Type-I and Type-II datasets, respectively."
        },
        {
            "heading": "4.4. Comparison with Few-Shot Supervised-Based AD Algorithms",
            "text": "We also conducted comparative experiments with few-shot industrial defect detection algorithms. The experimental setting was similar to the unsupervised algorithm comparison experiment. We conducted 20 experiments, each time randomly selecting m defect samples for odel training. The defect samples used for training in the comparative methods remained consistent with our proposed method. The average ROC and average AP were then calculated for performance co parison, as shown in Table 4. According to the results in the table, considering both the ROC and AP metrics, our method demonstrates advantages compared to DevNet [23] and DRA [22]. We not only compared the average performance but also recorded the performance of the model for each xperiment in order to observe the impact of different training samples on the model\u2019s performance.\nFigure 10 shows the changes in the model\u2019s ROC after training with randomly sampled\ndefect data from Type-I and Type-II datasets, respectively.\nSensors 2023, 23, 7894 14 of 19\nTable 4. Comparison between FS-RSDD and other few-shot industrial defect detection models.\nROC AP\nDataset FS-RSDD DevNet DRA FS-RSDD DevNet DRA Type-I m = 5 0.941 0.905 0.888 0.943 0.967 0.958 Type-I m = 10 0.952 0.930 0.927 0.953 0.976 0.973 Type-II m = 5 0.989 0.858 0.955 0.986 0.901 0.963 Type-II m = 10 0.991 0.911 0.974 0.986 0.939 0.978 Sensors 2023, 23, x FOR PEER REVIEW 15 of 20\n(a) (b) (c) (d)\nFigure 10. Performance fluctuations of FS-RSDD compared to the benchmarked few-shot supervised-based AD algorithms with different defect data for training: (a) Type-I, m = 5; (b) Type-II, m = 5; (c) Type-I, m = 10; (d) Type-II, m = 10.\nFrom the observation of Figure 10, it can be noticed that FS-RSDD exhibits more sta-\nble and robust performance compared to other models when different defect data are used\nfor training. Furthermore, although FS-RSDD shows more fluctuations on Type-I data\ncompared to Type-II data, it shows better performance compared to the rest of the few-\nshot supervised-based AD models. This is mainly attributed to the fact that FS-RSDD not\nonly utilizes defect features but also fully utilizes the features of a normal rail for defect\ndetection. On the other hand, other algorithms tend to focus more on extracting infor-\nmation from defect samples, which can lead to lower accuracy when the quality of defect\nsamples is poor."
        },
        {
            "heading": "4.5. Ablative Studies",
            "text": "In this section, we conducted ablation experiments to explore the impact of different\nsettings on the performance of FS-RSDD. These experiments included comparative exper-\niments on the model\u2019s performance using features from different semantic levels of the\nfeature extractor, whether using Gaussian blur or not, and extracting features using dif-\nferent feature extractors. The experiments were conducted by extracting defect samples\nand training the model 20 times and then comparing the average performance of the\nmodel. The number of samples extracted was m = 10, and the defect samples used for\ntraining were consistent with those used in the experiments in Sections 4.1 and 4.2.\nWe first conducted comparative experiments on the performance of the FS-RSDD\nmodel using different feature extractors, both with and without Gaussian blur. Table 5\npresents the performance of FS-RSDD on Type-I and Type-II rail surface defect datasets\nwhen using ResNet18, ResNet50, and WideResNet50 [47] as feature extractors.\nTable 5. The impact of different feature extractors and the use of Gaussian blur on the performance of FS-RSDD.\nFeature Extractor Image-Level ROC Image-Level AP Pixel-Level ROC FPS\nType-I\nm = 10\nResNet18 0.896 0.889 0.964 130.890\nResNet50 0.906 0.901 0.976 70.403\nWideResNet50 0.930 0.927 0.985 64.664\nResNet18 + Gaussian blur 0.934 0.935 0.980 130.052\nResNet50 + Gaussian blur 0.937 0.935 0.986 70.837\nWideResNet50 + Gaussian blur 0.952 0.953 0.991 63.519\nType-II\nm = 10\nResNet18 0.968 0.959 0.939 299.114\nResNet50 0.984 0.978 0.948 231.154\nFigure 10. Performance fluctuations of FS-RSDD compared to the benchmarked few-shot supervisedbased AD algorithms with different defect data for training: (a) Type-I, m = 5; (b) Type-II, m = 5; (c) Type-I, m = 10; (d) Type-II, m = 10.\nFrom the observation of Figure 10, it can be noticed that FS-RSDD exhibits more stable and robust performance compared to other models when different defect data are used for training. Furthermore, although FS-RSDD shows more fluctuations on Type-I data compared to Type-II data, it shows better performance compared to the rest of the few-shot supervisedbased AD models. This is mainly attributed to the fact that FS-RSDD not only utilizes defect features but also fully utilizes the features of a normal rail for defect detection. On the other hand, other algorithms tend to focus more on extracting information from defect samples, which can lead to lower accuracy when the quality of defect samples is poor."
        },
        {
            "heading": "4.5. Ablative Studies",
            "text": "In this section, we conducted ablation experiments to explore the impact of different settings on the performanc of FS-RSDD. Thes experiments included comparative experime ts on the model\u2019s performance using features from different sem ntic l vels of the feature extractor, wh ther using Gaussian blur or not, and extracting features using different feature extractors. The experime ts were conducted by extracting defect samples and training th model 20 times and then comparing the average performance of the od l. The number of sa pl s extract d was m = 10, and the defect samples used for training were consistent with those used in the experiments in Sections 4.1 and 4.2. We first conducted comparative experiments on the performa ce of the FS-RSDD model using different feature extractors, both with and without Gaussian blur. Table 5 presents the performance of FS-RSDD on Type-I and Type-II rail surface defect datasets when using ResNet18, ResNet50, and WideResNet50 [47] as feature extractors. From the experiment data in Table 5, we can clearly observe the significant impact of different feature extractors and the use of Gaussian blur on the detection performance of\nthe model. From this, we can observe that when using ResNet18 as the feature extractor,\nthe model has lower accuracy but faster speed. This is evident due to ResNet18 having\nfewer model parameters and faster inference speed but correspondingly poorer feature extraction capability. On the other hand, unlike ResNet18, WideResNet50, with its wider\nSensors 2023, 23, 7894 15 of 19\nfeature channels, can achieve better performance when used as a feature extractor, albeit with relatively slower detection speed.\nAdditionally, by comparing the performance of each feature extractor with and without Gaussian blur, we can easily observe the extent of improvement that Gaussian blur brings to the model\u2019s performance. This demonstrates the enhancement of predictive performance through the fusion of pixel neighborhood features. Comparative experiments were also conducted on the performance of the FS-RSDD model by utilizing features from different semantic levels to construct the memory bank, as presented in Table 6. In the experiment, the WideResNet50 is employed as the feature extractor, and Gaussian blur is applied to improve the performance. It can be clearly seen that the use of different combinations of semantic level features has an impact on the performance of FS-RSDD. When only using single- or two-level features for model construction, the performance of the model is suboptimal. However, when using multi-level features from a shallow layer, FS-RSDD exhibits the best performance. Furthermore, we conducted experiments with the utilization of features from deeper semantic levels. However, we observed no significant enhancement in the performance of FS-RSDD but a decrease in frames per second (FPS) due to the increased number of feature similarity calculations.\nSensors 2023, 23, 7894 16 of 19"
        },
        {
            "heading": "4.6. Time Complexity and the Size of Memory Bank",
            "text": "In this section, we conducted a comparative analysis of the computational complexity and size of memory banks among different models. The Type-I image data have a resolution of 160 \u00d7 160, while the Type-II data have a resolution of 64 \u00d7 64. All models employed the same network, WideResNet50, as the feature extractor. It is evident from Table 7 that FSRSDD, benefiting from its compact feature memory bank that models the entire normal rail background, outperforms unsupervised anomaly detection and few-shot defect detection algorithms in terms of time complexity. Moreover, this advantage is more significant on the low-resolution Type-II dataset.\nWe also conducted experiments regarding the size of the memory bank. We extracted the memory bank of our model and other methods and compared them to demonstrate the compactness of the memory bank obtained by our approach. We contrasted our method with memory-bank-based approaches [30,32]. The results are as shown in Table 8. In the experiment, each model utilizes the WideResNet50 feature extractor, with an input image resolution of 160."
        },
        {
            "heading": "5. Discussion",
            "text": "The method proposed in this article mainly combines the idea of feature-embeddingbased industrial defect detection algorithms and the prototypical network. By embedding features of defects and normal rails, corresponding feature memory banks are obtained. FS-RSDD estimates the similarity of the input samples to the defect prototype and the normal prototype in the feature space for defect detection. This simple and direct method can achieve quite good results on the rail surface defect dataset using only a few samples. However, there are still some shortcomings. After studying the experimental results in Section 4.3, it can be concluded that although this method can effectively distinguish the rail background and defect foreground, it cannot effectively discriminate between defects and noise. To explore the possibility of improving the model\u2019s detection performance using traditional image-processing techniques, we conducted additional experiments. We performed another experiment on both the RSDDS Type-I dataset without processing and the dataset processed with image processing. The experiment was conducted only once, and the random seed was fixed. Following the method described in reference [45], we used gamma transform to improve the uneven lighting in the images and combined it with Gaussian blur for image denoising. In the end, we achieved a pixel-level ROC of 99.3% and an image-level ROC of 96.5% on the original dataset, while on the denoised dataset we achieved a pixel-level ROC of 99.3% and an image-level ROC of 96.2%. It can be seen that after image processing, the model\u2019s performance did not improve as expected. We believe this may be due to the fact that deep-learning-based feature extractors have strong feature extraction capabilities, and the noise and uneven lighting that traditional\nSensors 2023, 23, 7894 17 of 19\nimage processing techniques can handle can also be distinguished by the feature extractor. However, noise and interference that are difficult for the feature extractor to distinguish are equally challenging for traditional image processing techniques. Therefore, instead of traditional image processing methods, we will focus on enhancing our work through novel image processing techniques in the future. Additionally, our research will prioritize exploring deep learning methods in defect detection."
        },
        {
            "heading": "6. Conclusions",
            "text": "This paper proposes a few-shot rail surface defect detection model, FS-RSDD, to address the issue of insufficient defect samples in the field of rail surface defect detection. FSRSDD combines the idea of feature-embedding-based industrial defect detection algorithms with the prototypical network. The method utilizes a pre-trained convolutional neural network to embed features of both defective and normal samples. It then uses clustering algorithms to learn the distribution of features of normal samples. Finally, through the prototype learning approach, softmax is used to estimate the probability of a test sample\u2019s feature belonging to a defect in the feature space. The proposed method surpasses all comparative algorithms in terms of speed by achieving a compact feature memory bank, which models the overall feature distribution of normal rail backgrounds. Additionally, the proposed method outperforms comparative few-shot defect detection algorithms in terms of accuracy on the RSDDS public dataset and is on par with the current state-of-the-art unsupervised anomaly detection algorithms.\nAuthor Contributions: Conceptualization, Y.M. and Z.W. (Ziwei Wang); data curation, Z.W. (Ziwei Wang); methodology, Z.W. (Ziwei Wang), Y.L. and Z.W. (Zheng Wang); writing\u2014original draft, Z.W. (Ziwei Wang) and Y.L.; writing\u2014review and editing, Y.M. and Z.W. (Zheng Wang). All authors have read and agreed to the published version of the manuscript.\nFunding: This research was funded by the National Natural Science Foundation of China (Grant No. 62066024) and the National Natural Science Foundation of China (Grant No.12162019).\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability Statement: Not applicable.\nConflicts of Interest: The authors declare no conflict of interest.\nReferences 1. Li, Y.; Trinh, H.; Haas, N.; Otto, C.; Pankanti, S. Rail Component Detection, Optimization, and Assessment for Automatic Rail Track Inspection. IEEE Trans. Intell. Transp. Syst. 2014, 15, 760\u2013770. [CrossRef] 2. Gao, B.; Bai, L.; Woo, W.L.; Tian, G.Y.; Cheng, Y. Automatic Defect Identification of Eddy Current Pulsed Thermography Using Single Channel Blind Source Separation. IEEE Trans. Instrum. Meas. 2014, 63, 913\u2013922. [CrossRef] 3. Alvarenga, T.A.; Carvalho, A.L.; Honorio, L.M.; Cerqueira, A.S.; Filho, L.M.A.; Nobrega, R.A. Detection and Classification System for Rail Surface Defects Based on Eddy Current. Sensors 2021, 21, 7937. [CrossRef] [PubMed] 4. Wang, H.; Li, M.; Wan, Z. Rail Surface Defect Detection Based on Improved Mask R-CNN. Comput. Electr. Eng. 2022, 102, 108269. [CrossRef] 5. Hsieh, C.-C.; Hsu, T.-Y.; Huang, W.-H. An Online Rail Track Fastener Classification System Based on YOLO Models. Sensors 2022, 22, 9970. [CrossRef] 6. Luo, H.; Cai, L.; Li, C. Rail Surface Defect Detection Based on An Improved YOLOv5s. Appl. Sci. 2023, 13, 7330. [CrossRef] 7. Zhang, C.; Xu, D.; Zhang, L.; Deng, W. Rail Surface Defect Detection Based on Image Enhancement and Improved YOLOX. Electronics 2023, 12, 2672. [CrossRef] 8. Hu, J.; Qiao, P.; Lv, H.; Yang, L.; Ouyang, A.; He, Y.; Liu, Y. High Speed Railway Fastener Defect Detection by Using Improved YoLoX-Nano Model. Sensors 2022, 22, 8399. [CrossRef] 9. Gudovskiy, D.; Ishizaka, S.; Kozuka, K. CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via\nConditional Normalizing Flows. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Waikoloa, HI, USA, 3\u20138 January 2021.\n10. Yu, J.; Zheng, Y.; Wang, X.; Li, W.; Wu, Y.; Zhao, R.; Wu, L. FastFlow: Unsupervised Anomaly Detection and Localization via 2D Normalizing Flows. arXiv 2021, arXiv:2111.07677.\nSensors 2023, 23, 7894 18 of 19\n11. Yang, M.; Wu, P.; Liu, J.; Feng, H. MemSeg: A Semi-Supervised Method for Image Surface Defect Detection Using Differences and Commonalities. Eng. Appl. Artif. Intell. 2022, 119, 105835. [CrossRef] 12. Pang, G.; Shen, C.; Cao, L.; Hengel, A.V.D. Deep Learning for Anomaly Detection: A Review. ACM Comput. Surv. 2022, 54, 1\u201338. [CrossRef] 13. Yu, H.; Li, Q.; Tan, Y.; Gan, J.; Wang, J.; Geng, Y.; Jia, L. A Coarse-to-Fine Model for Rail Surface Defect Detection. IEEE Trans. Instrum. Meas. 2019, 68, 656\u2013666. [CrossRef] 14. Ghorai, S.; Mukherjee, A.; Gangadaran, M.; Dutta, P.K. Automatic Defect Detection on Hot-Rolled Flat Steel Products. IEEE Trans. Instrum. Meas. 2013, 62, 612\u2013621. [CrossRef] 15. Zhang, H.; Jin, X.; Wu, Q.M.J.; Wang, Y.; He, Z.; Yang, Y. Automatic Visual Detection System of Railway Surface Defects with Curvature Filter and Improved Gaussian Mixture Model. IEEE Trans. Instrum. Meas. 2018, 67, 1593\u20131608. [CrossRef] 16. Liu, Z.; Wang, W.; Zhang, X.; Jia, W. Inspection of Rail Surface Defects Based on Image Processing. In Proceedings of the 2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics (CAR 2010), Wuhan, China, 3\u20137 March 2010; Volume 1, pp. 472\u2013475. 17. Meng, S.; Kuang, S.; Ma, Z.; Wu, Y. MtlrNet: An Effective Deep Multitask Learning Architecture for Rail Crack Detection. IEEE Trans. Instrum. Meas. 2022, 71, 1\u201310. [CrossRef] 18. Zhang, H.; Song, Y.; Chen, Y.; Zhong, H.; Liu, L.; Wang, Y.; Akilan, T.; Wu, Q.M.J. MRSDI-CNN: Multi-Model Rail Surface Defect Inspection System Based on Convolutional Neural Networks. IEEE Trans. Intell. Transp. Syst. 2022, 23, 11162\u201311177. [CrossRef] 19. Zhang, D.; Song, K.; Wang, Q.; He, Y.; Wen, X.; Yan, Y. Two Deep Learning Networks for Rail Surface Defect Inspection of Limited Samples With Line-Level Label. IEEE Trans. Ind. Inform. 2021, 17, 6731\u20136741. [CrossRef] 20. Zhang, Q.; Wu, B.; Shao, Y.; Ye, Z. Surface Defect Detection of Rails Based on Convolutional Neural Network Multi-Scale-Cross FastFlow. In Proceedings of the 2022 5th International Conference on Pattern Recognition and Artificial Intelligence (PRAI), Chengdu, China, 19\u201321 August 2022; pp. 405\u2013411. 21. Niu, M.; Song, K.; Huang, L.; Wang, Q.; Yan, Y.; Meng, Q. Unsupervised Saliency Detection of Rail Surface Defects Using Stereoscopic Images. IEEE Trans. Ind. Inform. 2021, 17, 2271\u20132281. [CrossRef] 22. Ding, C.; Pang, G.; Shen, C. Catching Both Gray and Black Swans: Open-Set Supervised Anomaly Detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), New Orleans, LA, USA, 18\u201324 June 2022. 23. Pang, G.; Ding, C.; Shen, C.; Hengel, A.V.D. Explainable Deep Few-Shot Anomaly Detection with Deviation Networks. arXiv 2021, arXiv:2108.00462. 24. Liu, B.; Gao, F.; Li, Y. Cost-Sensitive YOLOv5 for Detecting Surface Defects of Industrial Products. Sensors 2023, 23, 2610. [CrossRef] 25. Li, B.; Gao, Q. Defect Detection for Metal Shaft Surfaces Based on an Improved YOLOv5 Algorithm and Transfer Learning. Sensors 2023, 23, 3761. [CrossRef] [PubMed] 26. Ahmed, K.R. DSTEELNet: A Real-Time Parallel Dilated CNN with Atrous Spatial Pyramid Pooling for Detecting and Classifying Defects in Surface Steel Strips. Sensors 2023, 23, 544. [CrossRef] 27. Han, G.; Li, T.; Li, Q.; Zhao, F.; Zhang, M.; Wang, R.; Yuan, Q.; Liu, K.; Qin, L. Improved Algorithm for Insulator and Its Defect Detection Based on YOLOX. Sensors 2022, 22, 6186. [CrossRef] 28. Zheng, J.; Wu, H.; Zhang, H.; Wang, Z.; Xu, W. Insulator-Defect Detection Algorithm Based on Improved YOLOv7. Sensors 2022, 22, 8801. [CrossRef] [PubMed] 29. Kou, L.; Sysyn, M.; Fischer, S.; Liu, J.; Nabochenko, O. Optical Rail Surface Crack Detection Method Based on Semantic Segmentation Replacement for Magnetic Particle Inspection. Sensors 2022, 22, 8214. [CrossRef] [PubMed] 30. Defard, T.; Setkov, A.; Loesch, A.; Audigier, R. PaDiM: A Patch Distribution Modeling Framework for Anomaly Detection and Localization. In Pattern Recognition. ICPR International Workshops and Challenges. ICPR 2021; Lecture Notes in Computer Science; Springer: Cham, Switzerland, 2020. 31. Wang, G.; Han, S.; Ding, E.; Huang, D. Student-Teacher Feature Pyramid Matching for Anomaly Detection. arXiv 2021, arXiv:2103.04257. 32. Roth, K.; Pemula, L.; Zepeda, J.; Scholkopf, B.; Brox, T.; Gehler, P. Towards Total Recall in Industrial Anomaly Detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), New Orleans, LA, USA, 18\u201324 June 2022; IEEE: Piscataway, NJ, USA, 2022; pp. 14298\u201314308. 33. He, K.; Zhang, X.; Ren, S.; Sun, J. Deep Residual Learning for Image Recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, USA, 27\u201330 June 2016. 34. Li, C.-L.; Sohn, K.; Yoon, J.; Pfister, T. CutPaste: Self-Supervised Learning for Anomaly Detection and Localization. arXiv 2021, arXiv:2104.04015. 35. Reiss, T.; Cohen, N.; Bergman, L.; Hoshen, Y. PANDA: Adapting Pretrained Features for Anomaly Detection and Segmentation. In Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, TN, USA, 20\u201325 June 2021; pp. 2805\u20132813. 36. Rudolph, M.; Wandt, B.; Rosenhahn, B. Same Same But DifferNet: Semi-Supervised Defect Detection with Normalizing Flows. In Proceedings of the 2021 IEEE Winter Conference on Applications of Computer Vision (WACV), Waikoloa, HI, USA, 3\u20138 January 2021; pp. 1906\u20131915.\nSensors 2023, 23, 7894 19 of 19\n37. Chen, Z.; Fu, Y.; Zhang, Y.; Jiang, Y.-G.; Xue, X.; Sigal, L. Multi-Level Semantic Feature Augmentation for One-Shot Learning. IEEE Trans. Image Process. 2019, 28, 4594\u20134605. [CrossRef] 38. Xu, C.; Liu, C.; Sun, X.; Yang, S.; Wang, Y.; Wang, C.; Fu, Y. PatchMix Augmentation to Identify Causal Features in Few-Shot Learning 2022. arXiv 2022, arXiv:2211.16019. 39. Finn, C.; Abbeel, P.; Levine, S. Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks. In Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia, PMLR. 17 July 2017; pp. 1126\u20131135. 40. Koch, G.R. Siamese Neural Networks for One-Shot Image Recognition. Master\u2019s Thesis, University of Toronto, Toronto, ON, Canada, 2015. 41. Vinyals, O.; Blundell, C.; Lillicrap, T.; Wierstra, D. Matching Networks for One Shot Learning. In Advances in Neural Information Processing Systems; Curran Associates, Inc.: New York, NY, USA, 2016; Volume 29. 42. Snell, J.; Swersky, K.; Zemel, R.S. Prototypical Networks for Few-Shot Learning 2017. arXiv 2017, arXiv:1703.05175v2. 43. Yang, B.; Liu, C.; Li, B.; Jiao, J.; Ye, Q. Prototype Mixture Models for Few-Shot Semantic Segmentation. arXiv 2020, arXiv:2008.03898. 44. Dong, N.; Xing, E.P. Few-Shot Semantic Segmentation with Prototype Learning. BMVC 2018, 3. Available online: http://bmvc2018.org/contents/papers/0255.pdf (accessed on 29 August 2023). 45. Gan, J.; Li, Q.; Wang, J.; Yu, H. A Hierarchical Extractor-Based Visual Rail Surface Inspection System. IEEE Sens. J. 2017, 17, 7935\u20137944. [CrossRef] 46. Akcay, S.; Ameln, D.; Vaidya, A.; Lakshmanan, B.; Ahuja, N.; Genc, U. Anomalib: A Deep Learning Library for Anomaly\nDetection. In Proceedings of the 2022 IEEE International Conference on Image Processing (ICIP), Bordeaux, France, 16\u201319 October 2022; pp. 1706\u20131710.\n47. Zagoruyko, S.; Komodakis, N. Wide Residual Networks 2017. arXiv 2017, arXiv:1605.07146v4.\nDisclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."
        }
    ],
    "title": "FS-RSDD: Few-Shot Rail Surface Defect Detection with Prototype Learning",
    "year": 2023
}