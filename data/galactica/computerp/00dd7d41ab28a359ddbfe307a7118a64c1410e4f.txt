 Lung cancer has been the leading cause of cancer death for many decades. With the advent of artifcial intelligence, various machine learning models have been proposed for lung cancer detection (LCD). Typically, challenges in building an accurate LCD model are the small-scale datasets, the poor generalizability to detect unseen data, and the selection of useful source domains and prioritization of multiple source domains for transfer learning. In this paper, a multiround transfer learning and modifed generative adversarial network (MTL-MGAN) algorithm is proposed for LCD. Te MTL transfers the knowledge between the prioritized source domains and target domain to get rid of exhaust search of datasets prioritization among multiple datasets, maximizing the transferability with a multiround transfer learning process, and avoiding negative transfer via customization of loss functions in the aspects of domain, instance, and feature. In regard to the MGAN, it not only generates additional training data but also creates intermediate domains to bridge the gap between the source domains and target domains. 10 benchmark datasets are chosen for the performance evaluation and analysis of the MTL-MGAN. Te proposed algorithm has signifcantly improved the accuracy compared with related works. To examine the contributions of the individual components of the MTLMGAN, ablation studies are conducted to confrm the efectiveness of the prioritization algorithm, the MTL, the negative transfer avoidance via loss functions, and the MGAN. Te research implications are to confrm the feasibility of multiround transfer learning to enhance the optimal solution of the target model and to provide a generic approach to bridge the gap between the source domain and target domain using MGAN. Hindawi International Journal of Intelligent Systems Volume 2023, Article ID 6376275, 14 pages https://doi.org/10.1155/2023/6376275 1. 
(i) Domains: the improvements of the sensitivity, specifcity, precision, F-measure, and accuracy are ranged 2.09–2.40%, 1.97–2.47%, 2.07–2.40%, 2.07–2.52%, and 2.18–2.30%. Te average improvements of the fve target models are 2.23%, 2.26%, 2.27%, 2.31%, and 2.24% in sensitivity, specifcity, precision, F-measure, and accuracy, respectively. (ii) Instances: the improvements of the sensitivity, specifcity, precision, F-measure, and accuracy are ranged 1.67–2.06%, 1.84–2.40%, 1.55–2.41%, 1.75–2.29%, and 1.85–2.17%. Te average improvements of the fve target models are 1.97%, 2.05%, 2.06%, 2.01%, and 1.99% in sensitivity, specifcity, precision, F-measure, and accuracy, respectively. (iii) Features: the improvements of the sensitivity, specifcity, precision, F-measure, and accuracy are ranged 1.33–1.76%, 1.23–1.57%, 1.43–1.55%, 1.14–2.28%, and 1.34–1.66%. Te average improvements of the fve target models are 1.57%, 1.42%, 1.47%, 1.53%, and 1.53% in sensitivity, specifcity, precision, F-measure, and accuracy, respectively. 4.4. Contribution of the MGAN. MGAN is applied to create two intermediate domains based on the source domain and target domain. Table 5 verifes the contributions of MGAN. Te improvements of the sensitivity, specifcity, precision, F-measure, and accuracy are ranged 3.07–4.61%, 2.92–4.33%, 3.06–4.81%, 2.18–4.24%, and 3.15–4.47%, respectively. Te average improvements in sensitivity, specifcity, precision, F-measure, and accuracy using with the inclusion of MGAN are 3.61%, 3.56%, 3.70%, 3.32%, and 3.58%, respectively. 4.5. Complexity of the Algorithms. It can be seen from the results that the prioritization algorithm is important to signifcantly reduced the trials of the MTL-MGAN with diferent orders of multiple source datasets. Tis also refects a signifcant reduction in the complexity of the model that avoids unnecessary computing power on exhaustive search. Regarding MTL, which is the strategy to perform multiple times of the transfer learning process. To avoid negative transfer, the loss functions are designed based on the aspects of domains, instances, and features. Although this increases the complexity of the optimization algorithm, the ablation study (Section 4.3) confrms the efectiveness of loss functions. Creating two intermediate domains using MGAN increases the time and computing power of the transfer learning process, however, they contribute to the avoidance of negative transfer. 5. conclusion Te technological advancement of the machine learning algorithms has received attention in recent years to enhance the medical diagnosis of lung cancers. Responding to the research limitations of existing lung cancer detection models in multiround transfer learning, negative transfer, and lack of bridge between source and target domains, we have proposed a multiround transfer learning and modifed generative adversarial network algorithm with a prioritization algorithm and modifed loss functions in domains, instances, and features perspectives. 10 benchmark datasets are selected to evaluate the performance of the proposed
algorithm. It signifcantly enhances the performance of the lung cancer detection model, compared with related works. Ablation studies also provide convincing results to reveal the contributions of the components of the proposed algorithm in the aspects of prioritization algorithm, multiple transfer learning, customized loss functions in domains, instances, features, and modifed generative adversarial network. Te implication of the proposed algorithm releases the constraints in the selection of source domains and target domains. Terefore, it can contribute to various research areas, such as sustainable development goals [37], green applications [38], cyber-physical systems [39, 40], smart homes [41], and medical diagnosis [6, 7, 42]. To enhance the efciency of the optimization algorithm, future investigations could be conducted with various types of optimization approaches, which details can be referred to in review articles [46, 47]. List 1 Summary of the acronyms and symbols. acronyms 2DW: 2D dynamic warping MTL: Multiround transfer learning c: Conditional variable MTL-MGAN: Multiround transfer learning and modifed generative adversarial network CT: Computed tomography n: Noise vector d: Distance between two encodings NG: Number of encodings labeled for label G dmoment(DS, DT): Moment distance NH: Number of encodings labeled for label H dmodi fied(DS, DT)
: Modifed moment distance NL: Number of encodings labeled for label L D: Discriminator PDs1 , . . . ,PDsN N: Prioritized source datasets with N≤M DS: Source domains p: Number of penalized singular values Ds1 , . . . ,DsM: M source datasets smn: Similarity score between the m th sequence in Di and the nth sequence in Dj Dt: Trained target model SCi: Silhouette coefcient for a single encoding vector DT: Single target domain SC: Average Silhouette coefcient F   [f1, · · · , fN]
: Feature matrix with size N SSij: Total similarity score for dataset Di with Ni sequences and dataset Dj with Nj sequences F(Xsi) 1: Average operation of the 1st order features with the si source domain SVD: Singular value decomposition F(Xsi)
2: Average operation of the 2nd order features with the si source domain
SWDacross: Sum of the weighted diferences across classes F(Xt) 1: Average operation of the 1st order features with the target domain Xt SWDwithin: Sum of the weighted diferences within classes F(Xt)
2: Average operation of the 2nd order features with the target domain Xt
TD: Target dataset G: Generator U: Left singular vector GAN: Generative adversarial network V: Right singular vector H: Some labels of i X: Data distribution ID-MGANs: Intermediate domain based on the source domain using MGAN z: Latent variable ID-MGANt: Intermediate domain based on the target
domain using MGAN
αi: Normalized weight (iαi   1) of the source domain si L: Label for the fnal model βi: Hyperparameter to control the generalization error of Mi LCD: Lung cancer detection ci: Hyperparameter to control the
regularization of the samples in component Ci
M2DW: Modifed 2D dynamic warping δTi: Loss function to predict a sample in DT Mi: Mahalanobis distance of component Ci ρ: Hyperparameter to control the strength of penalization MGAN: Modifed generative adversarial network Σ: Singular value matrix of F. data availability Te data used to support the study are included in the paper. conflicts of interest Te authors declare that there are no conficts of interest.