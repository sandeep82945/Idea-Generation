{
    "abstractText": "We report on a novel model linking deep convolutional neural networks (CNN) to biological vision and fundamental particle physics. Information propagation in a CNN is modeled via an analogy to an optical system, where information is concentrated near a bottleneck where the 2D spatial resolution collapses about a focal point 1\u00d7 1 = 1. A 3D space (x, y, t) is defined by (x, y) coordinates in the image plane and CNN layer t, where a principal ray (0, 0, t) runs in the direction of information propagation through both the optical axis and the image center pixel located at (x, y) = (0, 0), about which the sharpest possible spatial focus is limited to a circle of confusion in the image plane. Our novel insight is to model the principal optical ray (0, 0, t) as geometrically equivalent to the medial vector in the positive orthant I(x, y) \u2208 R of a N -channel activation space, e.g. along the greyscale (or luminance) vector (t, t, t) in RGB colour space. Information is thus concentrated into an energy potential E(x, y, t) = \u2016I(x, y, t)\u2016, which, particularly for bottleneck layers t of generic CNNs, is highly concentrated and symmetric about the spatial origin (0, 0, t) and exhibits the well-known \"Sombrero\" potential of the boson particle. This symmetry is broken in classification, where bottleneck layers of generic pre-trained CNN models exhibit a consistent classspecific bias towards an angle \u03b8 \u2208 U(1) defined simultaneously in the image plane and in activation feature space. Initial observations validate our hypothesis from generic pre-trained CNN activation maps and a bare-bones memory-based classification scheme, with no training or tuning. Training from scratch using combined one-hot +U(1) loss improves classification for all tasks tested including ImageNet.",
    "authors": [
        {
            "affiliations": [],
            "name": "Louis-Fran\u00e7ois Bouchard"
        },
        {
            "affiliations": [],
            "name": "Mohsen Ben Lazreg"
        },
        {
            "affiliations": [],
            "name": "Matthew Toews"
        }
    ],
    "id": "SP:6f0983566a02791b97495dd5c9a54261ab35b683",
    "references": [
        {
            "authors": [
                "Georges Aad",
                "Tatevik Abajyan",
                "B Abbott",
                "J Abdallah",
                "S Abdel Khalek",
                "Ahmed Ali Abdelalim",
                "R Aben",
                "B Abi",
                "M Abolins",
                "OS AbouZeid"
            ],
            "title": "Observation of a new particle in the search for the standard model higgs boson with the atlas detector at the lhc",
            "venue": "Physics Letters B,",
            "year": 2012
        },
        {
            "authors": [
                "Relja Arandjelovi\u0107",
                "Petr Gronat",
                "Akihiko Torii",
                "Tomas Pajdla",
                "Josef Sivic"
            ],
            "title": "Netvlad: Cnn architecture for weakly supervised place recognition, 2016",
            "year": 2016
        },
        {
            "authors": [
                "Hossein Azizpour",
                "Ali Sharif Razavian",
                "Josephine Sullivan",
                "Atsuto Maki",
                "Stefan Carlsson"
            ],
            "title": "Factors of transferability for a generic convnet",
            "year": 2015
        },
        {
            "authors": [
                "Hugo Bartolomei",
                "Manohar Kumar",
                "R\u00e9mi Bisognin",
                "Arthur Marguerite",
                "J-M Berroir",
                "Erwann Bocquillon",
                "Bernard Placais",
                "Antonella Cavanna",
                "Q Dong",
                "Ulf Gennser"
            ],
            "title": "Fractional statistics in anyon collisions",
            "year": 2020
        },
        {
            "authors": [
                "Rani Ben-Yishai",
                "R Lev Bar-Or",
                "Haim Sompolinsky"
            ],
            "title": "Theory of orientation tuning in visual cortex",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 1995
        },
        {
            "authors": [
                "Maxim Berman",
                "Herv\u00e9 J\u00e9gou",
                "Andrea Vedaldi",
                "Iasonas Kokkinos",
                "Matthijs Douze"
            ],
            "title": "Multigrain: a unified image embedding for classes and instances",
            "year": 1902
        },
        {
            "authors": [
                "E. Bernhardsson"
            ],
            "title": "Annoy on github",
            "venue": "https://github.com/spotify/annoy",
            "year": 2015
        },
        {
            "authors": [
                "Guido Boffetta",
                "R Monasson",
                "R Zecchina"
            ],
            "title": "Symmetry breaking in nonmonotonic neural networks",
            "venue": "Journal of Physics A: Mathematical and General,",
            "year": 1993
        },
        {
            "authors": [
                "Nicolas Carion",
                "Francisco Massa",
                "Gabriel Synnaeve",
                "Nicolas Usunier",
                "Alexander Kirillov",
                "Sergey Zagoruyko"
            ],
            "title": "End-to-end object detection with transformers",
            "venue": "In European Conference on Computer Vision,",
            "year": 2020
        },
        {
            "authors": [
                "Laurent Chauvin",
                "Kuldeep Kumar",
                "Christian Desrosiers",
                "William Wells III",
                "Matthew Toews"
            ],
            "title": "Efficient pairwise neuroimage analysis using the soft jaccard index and 3d keypoint sets",
            "venue": "arXiv preprint arXiv:2103.06966,",
            "year": 2021
        },
        {
            "authors": [
                "Ricky TQ Chen",
                "Yulia Rubanova",
                "Jesse Bettencourt",
                "David K Duvenaud"
            ],
            "title": "Neural ordinary differential equations",
            "venue": "Advances in neural information processing systems,",
            "year": 2018
        },
        {
            "authors": [
                "Wei-Yu Chen",
                "Yen-Cheng Liu",
                "Zsolt Kira",
                "Yu-Chiang Frank Wang",
                "Jia-Bin Huang"
            ],
            "title": "A closer look at few-shot classification",
            "year": 1904
        },
        {
            "authors": [
                "M. Cimpoi",
                "S. Maji",
                "I. Kokkinos"
            ],
            "title": "S",
            "venue": "Mohamed, , and A. Vedaldi. Describing textures in the wild. In Proceedings of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)",
            "year": 2014
        },
        {
            "authors": [
                "Mircea Cimpoi",
                "Subhransu Maji",
                "Iasonas Kokkinos",
                "Andrea Vedaldi"
            ],
            "title": "Deep filter banks for texture recognition, description, and segmentation",
            "venue": "International Journal of Computer Vision,",
            "year": 2016
        },
        {
            "authors": [
                "Taco Cohen",
                "Maurice Weiler",
                "Berkay Kicanaoglu",
                "Max Welling"
            ],
            "title": "Gauge equivariant convolutional networks and the icosahedral cnn",
            "venue": "In International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "Thomas Cover",
                "Peter Hart"
            ],
            "title": "Nearest neighbor pattern classification",
            "venue": "IEEE transactions on information theory,",
            "year": 1967
        },
        {
            "authors": [
                "J. Deng",
                "W. Dong",
                "R. Socher",
                "L. Li"
            ],
            "title": "Kai Li",
            "venue": "and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE Conference on Computer Vision and Pattern Recognition, pages 248\u2013255",
            "year": 2009
        },
        {
            "authors": [
                "MWMG Dissanayake",
                "Nhan Phan-Thien"
            ],
            "title": "Neural-network-based approximations for solving partial differential equations. communications",
            "venue": "Numerical Methods in Engineering,",
            "year": 1994
        },
        {
            "authors": [
                "Li Fei-Fei",
                "Rob Fergus",
                "Pietro Perona"
            ],
            "title": "One-shot learning of object categories",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,",
            "year": 2006
        },
        {
            "authors": [
                "F.R.S. Karl Pearson"
            ],
            "title": "Liii. on lines and planes of closest fit to systems of points in space",
            "venue": "The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science,",
            "year": 1901
        },
        {
            "authors": [
                "Jeffrey Goldstone"
            ],
            "title": "Field theories with \u00absuperconductor",
            "venue": "solutions. Il Nuovo Cimento (1955-1965),",
            "year": 1961
        },
        {
            "authors": [
                "Albert Gordo",
                "Jon Almaz\u00e1n",
                "Jerome Revaud",
                "Diane Larlus"
            ],
            "title": "Deep image retrieval: Learning global representations for image search",
            "venue": "In European conference on computer vision,",
            "year": 2016
        },
        {
            "authors": [
                "Yunhui Guo",
                "Noel C Codella",
                "Leonid Karlinsky",
                "James V Codella",
                "John R Smith",
                "Kate Saenko",
                "Tajana Rosing",
                "Rogerio Feris"
            ],
            "title": "A broader study of cross-domain few-shot learning",
            "venue": "In European Conference on Computer Vision,",
            "year": 2020
        },
        {
            "authors": [
                "Daniel Haase",
                "Manuel Amthor"
            ],
            "title": "Rethinking depthwise separable convolutions: How intra-kernel correlations lead to improved mobilenets",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2016
        },
        {
            "authors": [
                "Mikael Henaff",
                "Joan Bruna",
                "Yann LeCun"
            ],
            "title": "Deep convolutional networks on graph-structured data",
            "venue": "arXiv preprint arXiv:1506.05163,",
            "year": 2015
        },
        {
            "authors": [
                "Peter Ware Higgs"
            ],
            "title": "Broken symmetries, massless particles and gauge fields",
            "venue": "Phys. Lett.,",
            "year": 1964
        },
        {
            "authors": [
                "Jie Hu",
                "Li Shen",
                "Gang Sun"
            ],
            "title": "Squeeze-and-excitation networks",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2018
        },
        {
            "authors": [
                "Zilong Huang",
                "Xinggang Wang",
                "Lichao Huang",
                "Chang Huang",
                "Yunchao Wei",
                "Wenyu Liu"
            ],
            "title": "Ccnet: Criss-cross attention for semantic segmentation",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2019
        },
        {
            "authors": [
                "Wei Jiang",
                "Eduard Trulls",
                "Jan Hosang",
                "Andrea Tagliasacchi",
                "Kwang Moo Yi"
            ],
            "title": "Cotr: Correspondence transformer for matching across images",
            "venue": "arXiv preprint arXiv:2103.14167,",
            "year": 2021
        },
        {
            "authors": [
                "Aditya Khosla",
                "Nityananda Jayadevaprakash",
                "Bangpeng Yao",
                "Li Fei-Fei"
            ],
            "title": "Novel dataset for fine-grained image categorization",
            "venue": "In First Workshop on Fine-Grained Visual Categorization, IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2011
        },
        {
            "authors": [
                "Bobak Kiani",
                "Randall Balestriero",
                "Yann Lecun",
                "Seth Lloyd"
            ],
            "title": "projunn: efficient method for training deep networks with unitary matrices",
            "venue": "arXiv preprint arXiv:2203.05483,",
            "year": 2022
        },
        {
            "authors": [
                "Sung Soo Kim",
                "Herv\u00e9 Rouault",
                "Shaul Druckmann",
                "Vivek Jayaraman"
            ],
            "title": "Ring attractor dynamics in the drosophila central brain",
            "year": 2017
        },
        {
            "authors": [
                "Diederik Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "International Conference on Learning Representations,",
            "year": 2014
        },
        {
            "authors": [
                "Thomas N Kipf",
                "Max Welling"
            ],
            "title": "Semi-supervised classification with graph convolutional networks",
            "venue": "arXiv preprint arXiv:1609.02907,",
            "year": 2016
        },
        {
            "authors": [
                "Simon Kornblith",
                "Jonathon Shlens",
                "Quoc V. Le"
            ],
            "title": "Do better imagenet models transfer",
            "year": 2019
        },
        {
            "authors": [
                "Jonathan Krause",
                "Michael Stark",
                "Jia Deng",
                "Li Fei-Fei"
            ],
            "title": "3d object representations for fine-grained categorization",
            "venue": "In 4th International IEEE Workshop on 3D Representation and Recognition (3dRR-13), Sydney, Australia,",
            "year": 2013
        },
        {
            "authors": [
                "Alex Krizhevsky",
                "Ilya Sutskever",
                "Geoffrey E Hinton"
            ],
            "title": "Imagenet classification with deep convolutional neural networks",
            "venue": "Advances in neural information processing systems,",
            "year": 2012
        },
        {
            "authors": [
                "Y. LeCun",
                "B. Boser",
                "J.S. Denker",
                "D. Henderson",
                "R.E. Howard",
                "W. Hubbard",
                "L.D. Jackel"
            ],
            "title": "Backpropagation applied to handwritten zip code recognition",
            "venue": "Neural Computation, 1(4):541\u2013551",
            "year": 1989
        },
        {
            "authors": [
                "Karel Lenc",
                "Andrea Vedaldi"
            ],
            "title": "Understanding image representations by measuring their equivariance and equivalence",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2015
        },
        {
            "authors": [
                "Ze Liu",
                "Yutong Lin",
                "Yue Cao",
                "Han Hu",
                "Yixuan Wei",
                "Zheng Zhang",
                "Stephen Lin",
                "Baining Guo"
            ],
            "title": "Swin transformer: Hierarchical vision transformer using shifted windows",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Jonathan Long",
                "Evan Shelhamer",
                "Trevor Darrell"
            ],
            "title": "Fully convolutional networks for semantic segmentation",
            "venue": "CoRR, abs/1411.4038,",
            "year": 2014
        },
        {
            "authors": [
                "Ilya Loshchilov",
                "Frank Hutter"
            ],
            "title": "SGDR: stochastic gradient descent with restarts",
            "year": 2016
        },
        {
            "authors": [
                "Subhransu Maji",
                "Esa Rahtu",
                "Juho Kannala",
                "Matthew B. Blaschko",
                "Andrea Vedaldi"
            ],
            "title": "Fine-grained visual classification of aircraft",
            "venue": "CoRR, abs/1306.5151,",
            "year": 2013
        },
        {
            "authors": [
                "Pascal Mettes",
                "Elise van der Pol",
                "Cees Snoek"
            ],
            "title": "Hyperspherical prototype networks",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "R\u00e9mi Monasson",
                "Dominic O\u2019Kane"
            ],
            "title": "Domains of solutions and replica symmetry breaking in multilayer neural networks",
            "venue": "EPL (Europhysics Letters),",
            "year": 1994
        },
        {
            "authors": [
                "Vinod Nair",
                "Geoffrey E. Hinton"
            ],
            "title": "Rectified linear units improve restricted boltzmann machines",
            "venue": "In Proceedings of the 27th International Conference on International Conference on Machine Learning,",
            "year": 2010
        },
        {
            "authors": [
                "Van Nhan Nguyen",
                "Sigurd L\u00f8kse",
                "Kristoffer Wickstr\u00f8m",
                "Michael Kampffmeyer",
                "Davide Roverso",
                "Robert Jenssen"
            ],
            "title": "Sen: A novel feature normalization dissimilarity measure for prototypical few-shot learning networks",
            "venue": "In European Conference on Computer Vision,",
            "year": 2020
        },
        {
            "authors": [
                "Maria-Elena Nilsback",
                "Andrew Zisserman"
            ],
            "title": "Automated flower classification over a large number of classes",
            "venue": "In Indian Conference on Computer Vision, Graphics and Image Processing,",
            "year": 2008
        },
        {
            "authors": [
                "Hyeonwoo Noh",
                "Andre Araujo",
                "Jack Sim",
                "Tobias Weyand",
                "Bohyung Han"
            ],
            "title": "Large-scale image retrieval with attentive deep local features",
            "venue": "In Proceedings of the IEEE international conference on computer vision,",
            "year": 2017
        },
        {
            "authors": [
                "Nicolas Papernot",
                "Patrick McDaniel"
            ],
            "title": "Deep k-nearest neighbors: Towards confident, interpretable and robust deep learning",
            "venue": "arXiv preprint arXiv:1803.04765,",
            "year": 2018
        },
        {
            "authors": [
                "Omkar M. Parkhi",
                "Andrea Vedaldi",
                "Andrew Zisserman",
                "C.V. Jawahar"
            ],
            "title": "Cats and dogs",
            "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2012
        },
        {
            "authors": [
                "Adam Paszke",
                "Sam Gross",
                "Francisco Massa",
                "Adam Lerer",
                "James Bradbury",
                "Gregory Chanan",
                "Trevor Killeen",
                "Zeming Lin",
                "Natalia Gimelshein",
                "Luca Antiga",
                "Alban Desmaison",
                "Andreas Kopf",
                "Edward Yang",
                "Zachary DeVito",
                "Martin Raison",
                "Alykhan Tejani",
                "Sasank Chilamkurthy",
                "Benoit Steiner",
                "Lu Fang",
                "Junjie Bai",
                "Soumith Chintala"
            ],
            "title": "Pytorch: An imperative style, high-performance deep learning library",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2019
        },
        {
            "authors": [
                "Ariadna Quattoni",
                "Antonio Torralba"
            ],
            "title": "Recognizing indoor scenes",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2009
        },
        {
            "authors": [
                "Filip Radenovi\u0107",
                "Giorgos Tolias",
                "Ond\u0159ej Chum"
            ],
            "title": "Fine-tuning cnn image retrieval with no human annotation",
            "venue": "IEEE transactions on pattern analysis and machine intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Maziar Raissi",
                "Paris Perdikaris",
                "George E Karniadakis"
            ],
            "title": "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations",
            "venue": "Journal of Computational Physics,",
            "year": 2019
        },
        {
            "authors": [
                "Ali Sharif Razavian",
                "Josephine Sullivan",
                "Stefan Carlsson",
                "Atsuto Maki"
            ],
            "title": "Visual instance retrieval with deep convolutional networks, 2016",
            "year": 2016
        },
        {
            "authors": [
                "Pau Rodr\u00edguez",
                "Miguel A Bautista",
                "Jordi Gonz\u00e0lez",
                "Sergio Escalera"
            ],
            "title": "Beyond one-hot encoding: Lower dimensional target embedding",
            "venue": "Image and Vision Computing,",
            "year": 2018
        },
        {
            "authors": [
                "F. Rosenblatt"
            ],
            "title": "The perceptron: A probabilistic model for information storage and organization in the brain",
            "venue": "Psychological Review, pages 65\u2013386",
            "year": 1958
        },
        {
            "authors": [
                "Tam\u00e1s Roska",
                "Leon O Chua",
                "Dietrich Wolf",
                "Tibor Kozek",
                "Ronald Tetzlaff",
                "Frank Puffer"
            ],
            "title": "Simulating nonlinear waves and partial differential equations via cnn",
            "venue": "i. basic techniques. IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications,",
            "year": 1995
        },
        {
            "authors": [
                "Mark Sandler",
                "Andrew Howard",
                "Menglong Zhu",
                "Andrey Zhmoginov",
                "Liang-Chieh Chen"
            ],
            "title": "Mobilenetv2: Inverted residuals and linear bottlenecks",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2018
        },
        {
            "authors": [
                "Johannes Seelig",
                "Vivek Jayaraman"
            ],
            "title": "Neural dynamics for landmark orientation and angular path integration",
            "venue": "Nature, 521:186\u201391,",
            "year": 2015
        },
        {
            "authors": [
                "Ali Sharif Razavian",
                "Hossein Azizpour",
                "Josephine Sullivan",
                "Stefan Carlsson"
            ],
            "title": "Cnn features off-the-shelf: an astounding baseline for recognition",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition workshops,",
            "year": 2014
        },
        {
            "authors": [
                "Jiayi Shen",
                "Zehao Xiao",
                "Xiantong Zhen",
                "Lei Zhang"
            ],
            "title": "Spherical zero-shot learning",
            "venue": "IEEE Transactions on Circuits and Systems for Video Technology,",
            "year": 2021
        },
        {
            "authors": [
                "Karen Simonyan",
                "Andrew Zisserman"
            ],
            "title": "Very deep convolutional networks for large-scale image recognition",
            "year": 2015
        },
        {
            "authors": [
                "Tess E Smidt",
                "Mario Geiger",
                "Benjamin Kurt Miller"
            ],
            "title": "Finding symmetry breaking order parameters with euclidean neural networks",
            "venue": "Physical Review Research,",
            "year": 2021
        },
        {
            "authors": [
                "Jake Snell",
                "Kevin Swersky",
                "Richard Zemel"
            ],
            "title": "Prototypical networks for few-shot learning",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Xiubao Sui",
                "Qiuhao Wu",
                "Jia Liu",
                "Qian Chen",
                "Guohua Gu"
            ],
            "title": "A review of optical neural networks",
            "venue": "IEEE Access,",
            "year": 2020
        },
        {
            "authors": [
                "Jiaming Sun",
                "Zehong Shen",
                "Yuang Wang",
                "Hujun Bao",
                "Xiaowei Zhou"
            ],
            "title": "Loftr: Detector-free local feature matching with transformers",
            "venue": "arXiv preprint arXiv:2104.00680,",
            "year": 2021
        },
        {
            "authors": [
                "Shiliang Sun",
                "Zehui Cao",
                "Han Zhu",
                "Jing Zhao"
            ],
            "title": "A survey of optimization methods from a machine learning perspective",
            "year": 1906
        },
        {
            "authors": [
                "Christian Szegedy",
                "Vincent Vanhoucke",
                "Sergey Ioffe",
                "Jon Shlens",
                "Zbigniew Wojna"
            ],
            "title": "Rethinking the inception architecture for computer vision",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2016
        },
        {
            "authors": [
                "Mingxing Tan",
                "Quoc V. Le"
            ],
            "title": "Efficientnet: Rethinking model scaling for convolutional neural networks",
            "year": 1905
        },
        {
            "authors": [
                "Hidenori Tanaka",
                "Daniel Kunin"
            ],
            "title": "Noether\u2019s learning dynamics: Role of symmetry breaking in neural networks",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Yehui Tang",
                "Kai Han",
                "Jianyuan Guo",
                "Chang Xu",
                "Yanxi Li",
                "Chao Xu",
                "Yunhe Wang"
            ],
            "title": "An image patch is a wave: Phase-aware vision mlp",
            "venue": "arXiv preprint arXiv:2111.12294,",
            "year": 2021
        },
        {
            "authors": [
                "Giorgos Tolias",
                "Ronan Sicre",
                "Herv\u00e9 J\u00e9gou"
            ],
            "title": "Particular object retrieval with integral max-pooling of cnn activations, 2016",
            "year": 2016
        },
        {
            "authors": [
                "David C. Van Essen",
                "Stephen M. Smith",
                "Deanna M. Barch",
                "Timothy E.J. Behrens",
                "Essa Yacoub",
                "Kamil Ugurbil"
            ],
            "title": "The wu-minn human connectome project: An overview",
            "year": 2013
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "Lukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "arXiv preprint arXiv:1706.03762,",
            "year": 2017
        },
        {
            "authors": [
                "Jian Wang",
                "Feng Zhou",
                "Shilei Wen",
                "Xiao Liu",
                "Yuanqing Lin"
            ],
            "title": "Deep metric learning with angular loss",
            "venue": "In Proceedings of the IEEE international conference on computer vision,",
            "year": 2017
        },
        {
            "authors": [
                "Xiaolong Wang",
                "Ross Girshick",
                "Abhinav Gupta",
                "Kaiming He"
            ],
            "title": "Non-local neural networks",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2018
        },
        {
            "authors": [
                "Yan Wang",
                "Wei-Lun Chao",
                "Kilian Q. Weinberger",
                "Laurens van der Maaten"
            ],
            "title": "Simpleshot: Revisiting nearest-neighbor classification for few-shot learning",
            "year": 1911
        },
        {
            "authors": [
                "Peter Welinder",
                "Steve Branson",
                "Takeshi Mita",
                "Catherine Wah",
                "Florian Schroff",
                "Serge Belongie",
                "Pietro Perona"
            ],
            "title": "Caltech-ucsd birds 200",
            "venue": "Technical Report CNS-TR-201,",
            "year": 2010
        },
        {
            "authors": [
                "Yandong Wen",
                "Kaipeng Zhang",
                "Zhifeng Li",
                "Yu Qiao"
            ],
            "title": "A discriminative feature learning approach for deep face recognition",
            "venue": "In European conference on computer vision,",
            "year": 2016
        },
        {
            "authors": [
                "Frank Wilczek"
            ],
            "title": "Quantum mechanics of fractional-spin particles",
            "venue": "Physical review letters,",
            "year": 1982
        },
        {
            "authors": [
                "Sanghyun Woo",
                "Jongchan Park",
                "Joon-Young Lee",
                "In So Kweon"
            ],
            "title": "Cbam: Convolutional block attention module",
            "venue": "In Proceedings of the European conference on computer vision (ECCV),",
            "year": 2018
        },
        {
            "authors": [
                "Matthew D Zeiler",
                "Rob Fergus"
            ],
            "title": "Visualizing and understanding convolutional networks",
            "venue": "In European conference on computer vision,",
            "year": 2014
        },
        {
            "authors": [
                "Zhifei Zhang",
                "Yang Song",
                "Hairong Qi"
            ],
            "title": "Age progression/regression by conditional adversarial autoencoder",
            "year": 2017
        },
        {
            "authors": [
                "Yutong Zheng",
                "Dipan K Pal",
                "Marios Savvides"
            ],
            "title": "Ring loss: Convex feature normalization for face recognition",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2018
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "A modern computer vision system involves image acquisition, computational processing and memory indexing. Research in the last decade has focused intensely on optimizing computational processing, i.e. deep neural network classification of labelled image data [42, 74], and more rarely considers aspects of acquisition. Nevertheless, both optical capture systems and deep neural networks propagate visual information across time, and operate by concentrating visual information in spatial bottlenecks. Might there be unexplored analogies between the two systems leading to new insights and improved architectures?\nTo answer this question, we propose to analyse information propagation through an optical system equipped with a lens and followed by a deep neural network encoder-decoder, as shown in Figure 1, noting several novel and remarkable analogies between both systems. First, multi-spectral information\nPreprint. Under review.\nar X\niv :2\n20 6.\n02 22\n0v 2\n[ cs\n.C V\n] 3\n1 A\nug 2\nin the (x, y) plane may be viewed as collapsing to a point 1\u00d7 1 = 1 resolution at both a) an optical focal point and b) a neural network bottleneck. These points are located on a ray t perpendicular to the (x, y) plane of both a) the propagating optical wavefront and b) network image layer. Information present in both (x, y) spatial coordinates and activation channels I(x, y) may thus be treated within a unified geometrical framework, centered about the principal ray. We pay special attention to the circle of confusion, which represents a minimum spatial radius within which information may be focused in an optical system, given lens imperfections including diffraction, lens aberrations, chromatic aberration of the input spectrum. Analogously, we hypothesize a circle of confusion limiting the maximum classification accuracy may be achieved in the spatial bottleneck of a deep neural network filtering process. Both observations and training experiments support a model whereby bottleneck activations for different classes are optimally distributed along a unit circle angle \u03b8 \u2208 U(1) defined simultaneous in the image plane and in the activation feature space.\nOur paper begins by presenting novel observations regarding the common structure of activation maps in bottleneck layers [89, 44], shared across diverse pre-trained architectures (ResNet [28], DenseNet [32], Inception [75], VGG [69]) and datasets (textures, objects, fine-grained objects). In all cases, the activation energy E(x, y) = \u2016I(x, y)\u20162 is highly symmetric and concentrated near the image center (x, y), highly reminiscent of the so-called \"sombrero\" potential associated with boson particles [23]. This symmetry is broken in classification trials via transfer learning from generic pretrained networks, via classic nearest-neighbor lookup [18] of pre-trained bottleneck activation information stored in memory. Lookup of individual pixel-wise activations rather than typical representations such pooled vectors or entire flattened layers both leads to superior classification accuracy and allows symmetry-breaking to be observed. Most notably, while matches between images of the same class are concentrated near the image center or origin (x, y) = (0, 0), they exhibit a consistent class-specific bias towards an angular direction \u03b8 \u2208 U(1) in both the image plane and feature space.\nThese observations lead us to investigate the hypothesis of a unitary class label \u03b8 \u2208 U(1) parameter in network training from scratch. Training networks with a single random angular class label leads to improved classification across a wide variety of tasks including generic objects, textures, animals, and highly specific categories including bird species or aircrafts. We propose a combined one\u2212hot+U(1) loss function, introducing an antisymmetric training signal via an angular class label (x, y) \u2208 U(1) constrained to the unit circle x2 + y2 = 1, which leads to consistently higher accuracy across a variety of CNN architextures and classification tasks of varying specificity including ImageNet."
        },
        {
            "heading": "2 Related Work",
            "text": "Our work adopts an analogy between the propagation of light in an optical system and layer-wise CNN processing, where layers are evaluated in discrete time steps t. Deep neural networks may be used to simulate ordinary and partial differential equations [20, 13], including solving forward and inverse problems and simulating wave propagation via graphics processing unit (GPU)-based CNN implementations [64, 60]. This is unsurprising given that GPUs were designed initially for graphics algorithms such as ray tracing that approximate Maxwell\u2019s electromagnetic (EM) field\nequations for wavelengths much smaller than objects imaged (e.g. the [380, 750]nm range of the visible RGB spectrum vs. human-sized objects). Neural networks may be computed via physical optical filters, where the difficulty is in achieving non-linear activations [72]. The key insight is that information may be modeled as propagating through space as a field evolving in discrete time steps, in a sequential, feed-forward manner with transitions defined by linear dot product operators It,x\u0304 = It\u22121,x\u0304 \u00b7Wt,x\u0304 in addition to non-linear activation, sub-sampling, pooling, etc. Our results derive from basic geometrical notions, the x\u0304 = (x, y) \u2208 R2 image space centered on (x, y) = (0, 0), a 3D spacetime (t, x\u0304) \u2208 R+ \u00d7 R2, and a vector-valued activation image I(t, x\u0304) \u2208 RN . Our novel approach considers a single unitary U(1) variable, i.e. (x, y) coordinates constrained to the unit circle x2 + y2 = 1 or equivalently an angle \u03b8 = atan2(y, x). U(1) may be also understood by considering that any function f(x\u0304) may be expressed as the sum f(x\u0304) = fs(x\u0304) + fa(x\u0304) of symmetric fs(x\u0304) and anti-symmetric fa(x\u0304) components, i.e. the cos(x\u0304) and sin(x\u0304) components of Euler\u2019s equation ei\u03b8 = cos(\u03b8) + i sin(\u03b8). Unitary variables are well known in mathematical analysis and increasingly used in machine learning formulations [36, 78]. In the standard model of 3D particle physics, fundamental particles are defined as fields or wave functions \u03c8(x\u0304) referred to as bosons \u03c8s(x\u0304) if the wave function is symmetric (eg. notably the photon and the Higgs boson) and as fermions \u03c8a(x\u0304) if it is anti-symmetric (e.g. quarks and leptons, notably the electron).\nSymmetry-breaking is a process by which an energy potential transitions from a symmetric to an asymmetric state. In deep neural networks, early investigations included replica symmetry breaking [50] and non-monotonic neural networks [9], more recently Euclidean neural networks [70] and Noether\u2019s notions of continuous symmetry from Lagrangian energy formulations [77]. In biological networks it has been notably investigated as an orientation selection mechanism within the cortex [6], ring attractor dynamics projecting individual photons into the fruit fly brain and measuring the angular response [37]. In particle physics, the Higgs mechanism lending mass to other standard particles is based on symmetry breaking, first proposed in 1962 [30] and experimentally confirmed in 2012 [1] (Nobel prize 2013), the same year AlexNet ushered in the wave of GPU-trained deep neural networks [42]. Most recently, 2D quasi-particles called anyons were theorized in 1982 [87] and observed experimentally in 2020 as electrons constrained to 2D sheets of gallium arsenide [5]. Anyon wavefunctions are not constrained to be exclusively symmetric or anti-symmetric, as are standard 3D particles (e.g. photons or electrons), and offer a potential mechanism for quantum computing and memory formation via a braiding-like particle exchange process in the 2D plane.\nOur initial observations of U(1) symmetry-breaking are based on nearest neighbor indexing and classification [18], specifically using spatially-localized activation vectors in pre-trained networks. This follows the transfer learning approach, where networks pre-trained on large generic datasets such as ImageNet [19] are used as general feature extractors for new tasks [40, 4, 16]. Deep bottleneck activations tend to outperform specialized shallower networks and meta-learning methods [14], particularly in the case of few training data and a large domain shift between training and testing data [25]. Various approaches seek to adapt ImageNet models to fine-grained tasks by encoding activations at bottleneck layers, e.g. via descriptor information (e.g. extracted off-the-shelf features [67], VLAD [3]), global average or max pooling [61], generalized mean (GeM) [59], regional max pooling (R-MAC) [79] in intermediate layers, modulated by attention operators [54]. Additional training may consider joint loss between classification and instance retrieval terms [7]. The mechanism of spatially localized activations (as opposed to global descriptors) is closely linked to the attention mechanisms [33], including non-local networks [83], squeeze-and-excitation networks [31], transformer architectures [81, 11, 27] including hierarchically shifted windows [45], thin bottleneck layers [65], self-attention mechanisms considering locations and channels [88], intra-kernel correlations [26], multi-layer perceptrons incorporating Euler\u2019s angle [78], correspondence-based transformers [34] and detectors [73], and geometrical embedding of spatial information via graphs [39, 29]. Whereas these works typically seek end-to-end learning solutions fitting within GPU memory constraints [24], we seek to demonstrate the U(1) theory via basic memory lookup.\nOur final results training from scratch using U(1) labels is similar in spirit to work seeking to regularize the label and/or the activation feature space, including using real-valued rather than one-hot training labels [62], learning-based classifiers [84, 86], prototypical networks for few-shot learning [52, 71], deep k-nearest neighbors [55], geometrical regularization based on hyperspheres [49, 68], enforcing constant radial distance from the feature space origin [91] or angular loss between prototypes [82]. We seek to present our theory in the broadest, most general context. We consider a basic classification and deliberately eschew architectural modifications that might limit the generality\nof our analysis. We demonstrate our general theory with results using a wide variety of pre-trained architectures including DenseNet [32], Inception [75], ResNet [28], VGG [69] directly imported from TensorFlow [2]. We consider a variety of testing datasets not used in ImageNet [19] training, with including general categories (e.g. Caltech 101 [21]), and specific instances (e.g. human brain MRIs of family members [80], faces [90]).\n3 Information Propagation and U(1) Symmetry-breaking\nWe propose modeling information propagation through a generic visual information processing system, including both the optical capture apparatus and discrete layer-wise processing in a deep convolutional neural network, as shown in Figure 1. We develop an analogy between both, in order to develop the notion of an information spectrum, unit circle of confusion and generic classification as a U(1) symmetry-breaking process.\nThe flow of information through spacetime in a computer vision system may be viewed as the propagation of information quanta through spacetime. In an optical system as in Figure 1 a), information is carried by photons radiating from a 3D scene, where photons travel along rays in 3D space at a constant speed in a vacuum. Light rays concentrated at a focus via a lens or a pinhole may be accumulated into a spatially coherent 2D image at an image plane, e.g. a RGB photosensor array. In a feedforward neural network system as in Figure 1 b), information is carried by activation vectors and propagating layer-wise operations including linear dot product, non-linear activation functions such as ReLu [51], pooling and subsampling. Information concentrated at a focus may be used for prediction or propagated further to achieve a spatially coherent 2D image segmentation [46].\nSeveral aspects common to both systems may be noted. Information is distributed across a 2D spatial plane (x, y), i.e. a propagating light wavefront or a deep network layer, and across a spectrum I(x, y), i.e. the tri-chromatic RGB spectrum of visible light or the activation channels of a network layer. We define the principal ray as perpendicular to the (x, y) image plane, and central to both the 2D image space and information channel space. In both systems, information is routed towards a focal point along the principal ray, where the finest achievable focus is limited to a circle of confusion, shown as a black ring in Figure 1. The circle of confusion is a well-known optical phenomenon arising from diffraction or lens imperfections, and compounded by dispersion, channel-specific refraction and chromatic aberration. We hypothesize a similar phenomenon in deep neural networks, due to the point spread function of filtering operations, and this motivates our investigation into bottleneck disentanglement.\nIn an optical system, the electromagnetic (EM) spectrum encodes information as photon particles, which may be modeled as propagating through 3D space via Dirac delta operators \u03b4(dx\u0304) (i.e. translation filters) defined in 3D space by the geometry of the optical apparatus. Photons are so-called boson particles defined by a symmetric wave function \u03c8(x) = \u03c8s(x) = \u03c8s(\u2212x), and may accumulate at a spatial focus according to Bose-Einstein statistics [10] 1. In a deep neural network, information is entangled in a limited number of activation channels I(x, y) \u2208 RN+, and propagated via multi-channel filtering operations. An important difference between the two systems is that in the case of deep CNNs [43], the channel spectrum or gauge [17] is transformed at each layer in order to encode and compress increasing amounts of visual information at reduced spatial resolutions up to the network bottleneck, trading equivalent representations for class-specific information the deeper we get into the network [89, 44], whereas the EM gauge is preserved during light propagation.\nThe propagation of information in both systems may be modeled as a vector field propagating through (x, y, t) spacetime via local dot product operators as follows. Let It,x\u0304 be a vector of multi-channel information at layer t and spatial location x\u0304 = (x, y), for example a 3-channel RGB image or a N-channel activation layer. Information may be propagated from time t to t+ 1 by the dot product operation It+1,x\u0304 = I\u0304t,x\u0304 \u00b7Wt,x\u0304, where I\u0304t,x\u0304 is a neighborhood tensor defined in the spatial window surrounding (t, x\u0304), and Wt,x\u0304 are the weights of a linear filter of the same size and shape as I\u0304t,x\u0304. Note that in a convolutional neural network (CNN) [43], filters are translation invariant and constant across a layer Wt,x\u0304 = Wt [89, 44], however they may generally vary with spatial location as in multi-layer perceptrons [63] or transformer networks [81] (hence transformers \u2019doing away with convolution\u2019).\n1As opposed to so-called fermion particles such as electrons defined by an anti-symmetric wave function \u03c8(x) = \u03c8a(x) = \u2212\u03c8a(\u2212x) which may only accumulate in (spin-up, spin-down) pairs due to the Pauli exclusion principle.\nOur model is illustrated in Figure 2, where multi-channel activation information is non-negative (e.g. following rectification (ReLu) [51]), located in the positive orthant of activation space It,x\u0304 \u2208 RN+, and may be expressed in polar coordinates (r, \u03b8, t) centered about the spatial origin (x, y) = (0, 0) and along the principal ray (0, 0, t). For example, RGB color pixels may be represented by hue, saturation, intensity (HSV) coordinates, where color perception is closely linked to a hue angle \u03b8 \u2208 U(1). We propose an analogy whereby multi-channel CNN activations are also represented via a class angle \u03b8 \u2208 U(1) according to dominant intensity channels. We hypothesize that this is a primary mechanism by which class information is encoded in image space, and that it may be identified and used as a training signal in the (x, y) image plane of arbitrary CNN layers, most notably bottleneck layers with minimal spatial extent. We observe the scalar energy Et,x\u0304 = \u2016It,x\u0304\u20162 \u2208 R+ of activation layers It,x\u0304 from a variety of generic architectures pretrained on the ImageNet dataset [19] in response to input images not used in training (e.g. Caltech 101 [21]). As shown in Figure 2, the average activation energy of pre-trained bottleneck layers is generally distributed symmetrically about the origin in a \"sombrero\" shape reminiscent of a bosonic wave function. This symmetry is broken in classification as shown in Figure 2 b), class-specific activation information exhibits a consistent asymmetric bias towards an angle \u03b8 \u2208 U(1) shared across individuals of a class."
        },
        {
            "heading": "4 Experiments",
            "text": "Our experiments validate our U(1) theory in two sections. We first demonstrate symmetry-breaking in basic nearest neighbor classification experiments, for a variety generic ImageNet pre-trained CNNs. We then perform training with U(1) class labels, using a novel one-hot + U(1) loss function modeling symmetric + antisymmetric components."
        },
        {
            "heading": "4.1 Observing Symmetry-breaking in CNN Bottleneck Layers",
            "text": "We hypothesize that class information in trained networks is generally concentrated into an angular argument \u03b8 \u2208 U(1) both in the (x, y) image plane and in activation feature space. We begin with observations supporting this hypothesis, where classification via basic nearest-neighbor indexing of pre-trained network activations is achieved via a symmetry-breaking process in the image plane. Figure 3 illustrates our proposed experimental retrieval architecture, where individual vectors It,x\u0304 may translate across image space in order to match with similar vectors in memory extracted from similar classes. As noted, the general mechanism is closely linked to spatial attention approaches, and our implementation is designed to maximize baseline classification performance. Note also that minimizing the distance between vectors is equivalent to maximizing their dot product.\nClassification is achieved by maximising the likelihood function p(I|C, {I \u2032}) of class C associated with input image I from set of image examples {I \u2032} stored in memory:\nC\u2217 = argmax C p(I|C, {I \u2032}), (1)\nwhere C\u2217 is a maximum likelihood (ML) estimate of the image class. The likelihood function is defined as follows. Let i and j be indices applying respectively to query and memory images. Let xi, xj \u2208 R2 be discrete spatial point locations, xi \u2208 \u2126I in the query image and xj \u2208 \u2126I\u2032 in memory images. Indices j \u2208 NNi belong to a set of K nearest neighbors of associated with i defined as NNi : {j : \u2016Ixi \u2212 I \u2032xj\u2016 \u2264 \u2016Ixi \u2212 I \u2032xk\u2016} identified via activation vector memory indexing, where I \u2032xk is the kth nearest neighbor of Ixi in memory. The likelihood may be expressed as a kernel density\np(I|C, {I \u2032}) \u221d \u2211 i \u2211 j\u2208Ni f(Ixi \u2212 I \u2032 xj )[C = C \u2032 j ]\u2211\nxj [C = C \u2032j ]\n, (2)\nwhere [C = C \u2032j ] is the Iverson bracket evaluating to 1 upon equality and 0 otherwise, and the denominator normalizes for class frequency across the entire memory set \u2211 j [C = C \u2032 j ]. The kernel function in Equation (2) is based on activation vector (dis)similarity f(Ixi , I \u2032 xj ) and is defined as:\nf(Ixi , I \u2032 xj ) = exp\u2212\n{ \u2016Ixi \u2212 I \u2032xj\u2016 2\n\u03b12i +\n} , (3)\nwhere in Equation (3), \u03b1i = min xj\u2208\u2126I\u2032\n\u2016Ixi \u2212 I \u2032xj\u2016 is an adaptive kernel bandwidth parameter defined\nas the distance to nearest activation vector Ixi in memory I \u2032 xj \u2208 {I \u2032}, and is a small positive constant ensuring a non-zero denominator. Note that the Euclidean and cosine distances are equivalent argmin \u2016Ixi\u2212I \u2032xj\u2016 = argmin{1\u2212Ixi \u00b7I \u2032 xj} for magnitude-normalized descriptors \u2016Ixi\u2016 = \u2016I \u2032 xj\u2016 = 1, and may be used interchangeably according to the computational architecture at hand.\nExperiments are based on a variety of generic CNN architectures trained on the ImageNet dataset [19], and tested in basic memory-based retrieval experiments using various datasets specifically not used in training, including general objects (Caltech 101 [21]), textures (DTD) [15] and specific objects [80, 90]. Figure 4 establishes baseline classification results across CNN architectures and descriptors, showing that localized pixel vector matching lead to the highest accuracy amongst alternatives, particularly for Densenet [32]. Note that high accuracy for pixel vector matching is due to the trade-off between memory and computation (e.g. 7x7=49 pixels vs. 1 global descriptor). As our goal here is to observe symmetry-breaking via the most accurate spatially localized information available, however, efficiency is not an immediate concern and is beyond the focus of our work here. We achieve efficient retrieval using the Approximate Nearest Neighbor library (Annoy) method [8] indexing method, a rapid tree-based algorithm with O(log N) query complexity for N elements in memory. Further efficiency could be achieved via compression (e.g PCA [22]) or specialized architectures [73, 34].\nExamples of consistent U(1) symmetry-breaking are shown in Figure 5. Note how distributions of nearest neighbor pixel vector matches between images of same class are consistently biased towards a similar angle \u03b8, validating class-specific asymmetry as predicted by our model in Figure 2. Visualizations in Figure 5 make use of the 7 \u00d7 7 = 49 pixel DenseNet201 [32] architecture with It,x\u0304 \u2208 R1920 channel vectors, which led to the highest accuracy in memory-based classification trials.\n4.2 Training with One-hot + U(1) Loss\nGiven the pattern of regular angular symmetry-breaking observed in the case of pre-trained network indexing, we hypothesize that orientation may be learned from arbitrary U(1) class labels in order to improve classification. Training combines a standard one-hot loss function with an additional angular U(1) loss, and applies to generic networks and training from scratch with no bells or whistles. U(1) loss uses a single angular training label, selected randomly for each class on a unit circle \u03b8 \u2208 U(1) in the (x, y) plane. U(1) labels are parameterized as (x, y) coordinates constrained to x2 + y2 = 1, and estimated via fully-connected layers immediately following the bottleneck. The L2 distance between\nU(1) labels and predicted (x, y) parameters is used as a loss function, and mixed in equal weighting with one-hot difference to generate a combined cross-entropy loss for the backward step. We train over a fixed 100 epochs, with original train, validation, and test sets and 5-fold cross-validation on a single Titan RTX GPU. We use the Adam optimizer [38] and CosineAnnealingLR scheduler [47] with default parameters from PyTorch [57] in all experiments and basic data augmentation in the form of horizontal flips and random crops. Training and classification are evaluated in diverse few-shot learning tasks of varying degrees of granularity, including the Describable Textures Dataset (DTD) [15], Caltech-UCSD Birds [85], Stanford Dogs [35], Flowers [53], Pets [56], Indoor67 [58], FGVC-Aircraft [48], Cars [41], and Imagenet [19].\nTraining with one-hot + U(1) loss improved classification for all tested networks compared to one-hot alone. Table 1 reports results for the network architectures leading to the highest overall accuracy (EfficientNet-B0) [76] and the most improved (Resnet) [28]. As an additional experiment, we tested (x, y) labels generated from various 2-parameter distributions other than the unit circle U(1), including centered (one-hot alone), discrete binary combinations [\u00b11,\u00b11] and uniformly distribution over space. Figure 6 shows preliminary results for a single dataset, where U(1) labels lead to the highest accuracy amongst alternatives."
        },
        {
            "heading": "5 Discussion",
            "text": "We present a novel model of information propagation in deep CNN layers with an analogy to light propagation in an optical system, including a focal point and an inherent circle of confusion in both cases. We assume the equivalence of the principal optical axis (0, 0, t) and the medial vector of positive activation feature space. These are both central to the (x, y) image plane allow class to be characterized by a hue-like angle \u03b8 \u2208 U(1), defined both in the image plane and activation feature space. Our model provides an \u2019end-to-end\u2019 view including also the optical capture system and memory storage. Our most significant finding pertains to information regarding (x, y) image space, which in its most concentrated form in low-resolution network layers just prior to spatial collapse 1\u00d7 1 = 1, is well-represented by a single unitary variable \u03b8 \u2208 U(1). Furthermore, the process by which classification occurs involves U(1) symmetry breaking of the deep CNN bottleneck energy E(x, y) = \u2016It,x\u0304\u20162, consistent with the \"sombrero\" bosonic potential. Our observations of a regular angular asymmetry consistent with image class are the first in the literature, to our knowledge, and indicate that symmetry-breaking occurs naturally in generic pre-trained CNNs, linking deep learning more closely to biological networks and recent results in particle physics. Our angular observations are consistent with biological models: specifically \u03b8 deviations in Figure 5 induced from image inputs, and \u03b8 deviations in orientation/heading selection in the fruit fly visual system induced by individual photon inputs, see [37] Figure 3. They are also reminiscent recently discovered anyon quasiparticles [5], and may provide mechanism for memory formation whereby an input sequence is woven into a \"braid\" of memory via the particle exchange process in the 2D plane.\nOur work brings together a broad range of fundamental concepts and state-of-the-art research in optics, particle physics, biological and artificial neural networks, which we attempt to present in the broadest and most understandable description, avoiding as much as possible domain-specific jargon. Our experiments make use of the most widely-known, generic neural network architectures, data sets and NN classification [18] in order to best demonstrate our U(1) theory. One exception is the HCP brain MRI dataset [80], a publicly available set of 1010 subject images acquired with ethics review board approval and patient consent, designed to reflect the demographic diversity of the USA population, including family members and siblings. Family classification from brain MRI is a highly challenging few-shot learning task not yet addressed via deep learning. Handcrafted descriptors have been used to identify images of the same individuals or family members [12], note subjects are labeled according to random codes with no personal identifiable information. Our experimental pixel vector matching method is effective for classification and demonstrating our theory with general pre-trained CNN architectures, particularly lo-res bottleneck layers, however would require optimisation for larger layers or applications with tight memory or timing constraints. The classification accuracy for models training from scratch is improved by incorporating an antisymmetric U(1) loss function, a result complementary to recent unitary optimization research [78, 36]."
        },
        {
            "heading": "6 Appendices",
            "text": ""
        },
        {
            "heading": "6.1 U(1)-like Symmetry Breaking in the Drosophila Melanogaster Cortex",
            "text": "We noted that the U(1) symmetry breaking structure in deep CNN bottleneck layers shown in Figure 5 (due to input image class) is similar to examples of angular neural firing patterns observed in deep layers of biological neural networks. Specifically, activations in deep/central brain layers of the drosophila melanogaster cortex linked to the fly\u2019s compass network determining heading [37, 66], in response to dual-photon input stimuli. As central brain regions are typically dominated by recurrent networks which often produce complex patterns of neural activity, it is remarkable to observe a high-level, abstract internal representation in the form of a topological ring representing the heading direction in response to input light stimulus patterns."
        },
        {
            "heading": "6.2 Pixel Vector Matching Distributions",
            "text": "Our experimental observations regarding symmetry are derived from a rudimentary nearest neighbor (NN) classification algorithm (Section 4.1), where activation vectors Ix from individual pixel locations x are matched between query image locations xi to NN locations xnn of vectors stored in memory. We justify the use of pixel vector indexing by the observation that it generally leads to superior classification performance in comparison to other representations including max pooling or flattening, see Figure 3 and Figure 4, for a number of different networks and classification tasks. Figure 5 shows distributions of nearest neighbor matching locations xnn, here Figure 8 shows distributions p(xnn|xi) conditioned query pixel location xi. Matching locations xnn are tightly distributed around the query pixel locations xi, indicating that in CNN bottleneck layers, activation information Ix is highly specific to location x, and that unrelated class match distributions exhibit noticeably higher variability in nearest neighbor location xnn."
        }
    ],
    "title": "U(1) Symmetry-breaking Observed in Generic CNN Bottleneck Layers",
    "year": 2022
}