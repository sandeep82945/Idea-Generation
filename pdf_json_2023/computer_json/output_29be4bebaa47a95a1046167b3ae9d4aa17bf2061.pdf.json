{
    "abstractText": "COPYRIGHT \u00a9 2023 Verma, Jin, Zhou, Huang, Tan, Choong, Tan, Gao, Xu, Ting and Liu. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms. Privacy-preserving continual learning methods for medical image classification: a comparative analysis",
    "authors": [
        {
            "affiliations": [],
            "name": "Yi-Ting Hsieh"
        },
        {
            "affiliations": [],
            "name": "Chia-Ying Tsai"
        },
        {
            "affiliations": [],
            "name": "Tanvi Verma"
        },
        {
            "affiliations": [],
            "name": "Liyuan Jin"
        },
        {
            "affiliations": [],
            "name": "Jun Zhou"
        },
        {
            "affiliations": [],
            "name": "Jia Huang"
        },
        {
            "affiliations": [],
            "name": "Mingrui Tan"
        },
        {
            "affiliations": [],
            "name": "Benjamin Chen"
        },
        {
            "affiliations": [],
            "name": "Ming Choong"
        },
        {
            "affiliations": [],
            "name": "Ting Fang Tan"
        },
        {
            "affiliations": [],
            "name": "Fei Gao"
        },
        {
            "affiliations": [],
            "name": "Xinxing Xu"
        },
        {
            "affiliations": [],
            "name": "Daniel S. Ting"
        },
        {
            "affiliations": [],
            "name": "Yong Liu"
        }
    ],
    "id": "SP:3a60de7bc6a36390112e82fe7e543254f42744cd",
    "references": [
        {
            "authors": [
                "IJ Goodfellow",
                "M Mirza",
                "D Xiao",
                "A Courville",
                "Y. Bengio"
            ],
            "title": "An empirical investigation of catastrophic forgetting in gradient-based neural networks",
            "venue": "arXiv preprint arXiv:13126211",
            "year": 2013
        },
        {
            "authors": [
                "D Kermany",
                "K Zhang",
                "M. Goldbaum"
            ],
            "title": "Large dataset of labeled optical coherence tomography (OCT) and chest x-ray images.Mendeley Data",
            "year": 2018
        },
        {
            "authors": [
                "J Yang",
                "R Shi",
                "decathlon Ni B. \u201cMedmnist classification"
            ],
            "title": "a lightweight autoML benchmark for medical image analysis,\u201d in: 2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)",
            "venue": "IEEE",
            "year": 2021
        },
        {
            "authors": [
                "A Krizhevsky",
                "G Hinton"
            ],
            "title": "Learning multiple layers of features from tiny images",
            "year": 2009
        },
        {
            "authors": [
                "Van de Ven GM",
                "Tolias AS"
            ],
            "title": "Three scenarios for continual learning",
            "venue": "arXiv preprint arXiv:190407734",
            "year": 2019
        },
        {
            "authors": [
                "SJ Pan",
                "IW Tsang",
                "JT Kwok",
                "Q. Yang"
            ],
            "title": "Domain adaptation via transfer component analysis",
            "venue": "IEEE Trans Neural Netw",
            "year": 2010
        },
        {
            "authors": [
                "J Kirkpatrick",
                "R Pascanu",
                "N Rabinowitz",
                "J Veness",
                "G Desjardins",
                "AA Rusu"
            ],
            "title": "Overcoming catastrophic forgetting in neural networks",
            "venue": "Proc Natl Acad Sci USA",
            "year": 2017
        },
        {
            "authors": [
                "J Lee",
                "HG Hong",
                "D Joo",
                "J. Kim"
            ],
            "title": "Continual learning with extended kroneckerfactored approximate curvature",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "year": 2020
        },
        {
            "authors": [
                "F Zenke",
                "B Poole",
                "In Ganguli S. Continual learning through synaptic intelligence."
            ],
            "title": "International Conference on Machine Learning",
            "venue": "PMLR",
            "year": 2017
        },
        {
            "authors": [
                "R Aljundi",
                "F Babiloni",
                "M Elhoseiny",
                "M Rohrbach",
                "synapses Tuytelaars T. Memory aware"
            ],
            "title": "learning what (not) to forget",
            "venue": "Proceedings of the European Conference on Computer Vision (ECCV).",
            "year": 2018
        },
        {
            "authors": [
                "A Chaudhry",
                "PK Dokania",
                "T Ajanthan",
                "learning Torr PH. Riemannian walk for incremental"
            ],
            "title": "Understanding forgetting and intransigence",
            "venue": "Proceedings of the European Conference on Computer Vision (ECCV).",
            "year": 2018
        },
        {
            "authors": [
                "H Ahn",
                "S Cha",
                "D Lee",
                "T. Moon"
            ],
            "title": "Uncertainty-based continual learning with adaptive regularization.Advances in Neural Information",
            "venue": "Processing Systems",
            "year": 2019
        },
        {
            "authors": [
                "S Jung",
                "H Ahn",
                "S Cha",
                "In Moon T. Continual learning with node-importance based adaptive group sparse regularization."
            ],
            "title": "Advances in Neural Information Processing Systems 33",
            "venue": "Curran Associates",
            "year": 2020
        },
        {
            "authors": [
                "G Zeng",
                "Y Chen",
                "B Cui",
                "S. Yu"
            ],
            "title": "Continual learning of contextdependent processing in neural networks",
            "venue": "Nat Mach Intell",
            "year": 2019
        },
        {
            "authors": [
                "G Saha",
                "I Garg",
                "K. Roy"
            ],
            "title": "Gradient projectionmemory for continual learning",
            "venue": "arXiv preprint arXiv:210309762",
            "year": 2021
        },
        {
            "authors": [
                "X He",
                "H. Jaeger"
            ],
            "title": "Overcoming catastrophic interference using conceptor-aided backpropagation",
            "venue": "In: International Conference on Learning Representations",
            "year": 2018
        },
        {
            "authors": [
                "G Hinton",
                "O Vinyals",
                "J. Dean"
            ],
            "title": "Distilling the knowledge in a neural network",
            "venue": "arXiv preprint arXiv:150302531",
            "year": 2015
        },
        {
            "authors": [
                "Z Li",
                "D. Hoiem"
            ],
            "title": "Learning without forgetting",
            "venue": "IEEE Trans Pattern Anal Mach Intell",
            "year": 2017
        },
        {
            "authors": [
                "P Dhar",
                "RV Singh",
                "KC Peng",
                "Z Wu",
                "R. Chellappa"
            ],
            "title": "Learning without memorizing",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "year": 2019
        },
        {
            "authors": [
                "A Douillard",
                "M Cord",
                "C Ollion",
                "T Robert",
                "PODNet Valle E."
            ],
            "title": "pooled outputs distillation for small-tasks incremental learning",
            "venue": "European Conference on Computer Vision. Springer",
            "year": 2020
        },
        {
            "authors": [
                "VK Kurmi",
                "BN Patro",
                "VK Subramanian",
                "VP. Namboodiri"
            ],
            "title": "Do not forget to attend to uncertainty while mitigating catastrophic forgetting",
            "venue": "Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision",
            "year": 2021
        },
        {
            "authors": [
                "C Simon",
                "P Koniusz",
                "M. Harandi"
            ],
            "title": "On learning the geodesic path for incremental learning",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "year": 2021
        },
        {
            "authors": [
                "J Yoon",
                "E Yang",
                "J Lee",
                "SJ. Hwang"
            ],
            "title": "Lifelong learning with dynamically expandable networks. arXiv preprint arXiv:170801547 (2017)",
            "year": 2017
        },
        {
            "authors": [
                "J Xu",
                "Z. Zhu"
            ],
            "title": "Reinforced continual learning",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2018
        },
        {
            "authors": [
                "CY Hung",
                "CH Tu",
                "CE Wu",
                "CH Chen",
                "YM Chan",
                "CS. Chen"
            ],
            "title": "Compacting, picking and growing for unforgetting continual learning",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2019
        },
        {
            "authors": [
                "AA Rusu",
                "NC Rabinowitz",
                "G Desjardins",
                "H Soyer",
                "J Kirkpatrick",
                "K Kavukcuoglu"
            ],
            "title": "Progressive neural networks",
            "venue": "arXiv preprint arXiv:160604671",
            "year": 2016
        },
        {
            "authors": [
                "J Yoon",
                "S Kim",
                "E Yang",
                "SJ. Hwang"
            ],
            "title": "Scalable and order-robust continual learning with additive parameter decomposition",
            "venue": "arXiv preprint arXiv:190209432",
            "year": 2019
        },
        {
            "authors": [
                "VK Verma",
                "KJ Liang",
                "N Mehta",
                "P Rai",
                "L. Carin"
            ],
            "title": "Efficient feature transformations for discriminative and generative continual learning",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "year": 2021
        },
        {
            "authors": [
                "R Aljundi",
                "P Chakravarty",
                "gate Tuytelaars T. Expert"
            ],
            "title": "lifelong learning with a network of experts",
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "year": 2017
        },
        {
            "authors": [
                "H Shin",
                "JK Lee",
                "J Kim",
                "J. Kim"
            ],
            "title": "Continual learning with deep generative replay",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2017
        },
        {
            "authors": [
                "van de Ven GM",
                "Tolias AS"
            ],
            "title": "Generative replay with feedback connections as a general strategy for continual learning",
            "venue": "arXiv preprint arXiv:180910635",
            "year": 2018
        },
        {
            "authors": [
                "GM van de Ven",
                "HT Siegelmann",
                "AS. Tolias"
            ],
            "title": "Brain-inspired replay for continual learning with artificial neural networks",
            "venue": "Nat Commun",
            "year": 2020
        },
        {
            "authors": [
                "T Lesort",
                "H Caselles-Dupr\u00e9",
                "M Garcia-Ortiz",
                "A Stoian",
                "In Filliat D. Generative models from the perspective of continual learning."
            ],
            "title": "2019 International Joint Conference on Neural Networks (IJCNN)",
            "venue": "IEEE",
            "year": 2019
        },
        {
            "authors": [
                "Y Liu",
                "S Parisot",
                "G Slabaugh",
                "X Jia",
                "A Leonardis",
                "classifiers Tuytelaars T. More",
                "forgetting less"
            ],
            "title": "a generic multi-classifier paradigm for incremental learning",
            "venue": "Vedaldi A, Bischof H, Brox T, Frahm JM, editors. Computer Vision \u2013 ECCV 2020. Cham: Springer International Publishing",
            "year": 2020
        },
        {
            "authors": [
                "JN Kather",
                "J Krisam",
                "P Charoentong",
                "T Luedde",
                "E Herpel",
                "CA Weis",
                "learning et al. Predicting survival from colorectal cancer histology slides using deep"
            ],
            "title": "a retrospective multicenter study",
            "venue": "PLoS Med.",
            "year": 2019
        },
        {
            "authors": [
                "SI Mirzadeh",
                "M Farajtabar",
                "R Pascanu",
                "H. Ghasemzadeh"
            ],
            "title": "Understanding the role of training regimes in continual learning",
            "venue": "In:Advances in Neural Information Processing Systems 33. Curran Associates",
            "year": 2020
        },
        {
            "authors": [
                "DSW Ting",
                "CYL Cheung",
                "G Lim",
                "GSW Tan",
                "ND Quang",
                "A Gan"
            ],
            "title": "Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes",
            "year": 2017
        },
        {
            "authors": [
                "B McMahan",
                "E Moore",
                "D Ramage",
                "S Hampson",
                "In y Arcas BA. Communicationefficient learning of deep networks from decentralized data."
            ],
            "title": "Artificial Intelligence and Statistics",
            "venue": "PMLR",
            "year": 2017
        },
        {
            "authors": [
                "Q Dou",
                "TY So",
                "M Jiang",
                "Q Liu",
                "V Vardhanabhuti",
                "G Kaissis",
                "CT et al. Federated deep learning for detecting COVID-19 lung abnormalities in"
            ],
            "title": "a privacy-preserving multinational validation study",
            "venue": "NPJ Digit Med.",
            "year": 2021
        },
        {
            "authors": [
                "GI Parisi",
                "R Kemker",
                "JL Part",
                "C Kanan",
                "networks Wermter S. Continual lifelong learning with neural"
            ],
            "title": "a review",
            "venue": "Neural Netw.",
            "year": 2019
        },
        {
            "authors": [
                "DelangeM",
                "R Aljundi",
                "MasanaM",
                "S Parisot",
                "X Jia",
                "A Leonardis",
                "survey et al. A continual learning"
            ],
            "title": "defying forgetting in classification tasks",
            "venue": "IEEE Trans Pattern Anal Mach Intell.",
            "year": 2021
        },
        {
            "authors": [
                "S Farquhar",
                "Y. Gal"
            ],
            "title": "Towards robust evaluations of continual learning",
            "venue": "arXiv preprint arXiv:180509733",
            "year": 2018
        },
        {
            "authors": [
                "H Qu",
                "H Rahmani",
                "L Xu",
                "B Williams",
                "vision Liu J. Recent advances of continual learning in computer"
            ],
            "title": "an overview",
            "venue": "arXiv preprint arXiv:210911369",
            "year": 2021
        },
        {
            "authors": [
                "TL Hayes",
                "GP Krishnan",
                "M Bazhenov",
                "HT Siegelmann",
                "TJ Sejnowski",
                "learning Kanan C. Replay in deep"
            ],
            "title": "current approaches and missing biological elements",
            "venue": "Neural Comput.",
            "year": 2021
        },
        {
            "authors": [
                "M Masana",
                "X Liu",
                "B Twardowski",
                "M Menta",
                "AD Bagdanov",
                "learning van de Weijer J. Class-incremental"
            ],
            "title": "survey and performance evaluation on image classification",
            "venue": "IEEE Trans Pattern Anal Mach Intell.",
            "year": 2022
        },
        {
            "authors": [
                "E Belouadah",
                "A Popescu",
                "I. Kanellos"
            ],
            "title": "A comprehensive study of class incremental learning algorithms for visual tasks",
            "venue": "Neural Netw",
            "year": 2020
        },
        {
            "authors": [
                "Z Mai",
                "R Li",
                "J Jeong",
                "D Quispe",
                "H Kim",
                "classification Sanner S. Online continual learning in image"
            ],
            "title": "an empirical survey",
            "venue": "Neurocomputing.",
            "year": 2022
        },
        {
            "authors": [
                "MM Derakhshani",
                "I Najdenkoska",
                "T van Sonsbeek",
                "X Zhen",
                "D Mahapatra",
                "M Worring",
                "LifeLonger et al."
            ],
            "title": "a benchmark for continual disease classification",
            "venue": "International Conference on Medical Image Computing and Computer Assisted Intervention.",
            "year": 2022
        },
        {
            "authors": [
                "SA Rebuffi",
                "A Kolesnikov",
                "G Sperl",
                "ICARL Lampert CH."
            ],
            "title": "incremental classifier and representation learning",
            "venue": "Proceedings of the IEEE conference on Computer Vision and Pattern Recognition.",
            "year": 2017
        },
        {
            "authors": [
                "FM Castro",
                "MJ Mar\u00edn-Jim\u00e9nez",
                "N Guil",
                "C Schmid",
                "K. Alahari"
            ],
            "title": "End-to-end incremental learning",
            "venue": "Proceedings of the European Conference on Computer Vision (ECCV)",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "TYPE Original Research PUBLISHED 14 August 2023 DOI 10.3389/fmed.2023.1227515"
        },
        {
            "heading": "OPEN ACCESS",
            "text": ""
        },
        {
            "heading": "EDITED BY",
            "text": "Yi-Ting Hsieh, National Taiwan University Hospital, Taiwan"
        },
        {
            "heading": "REVIEWED BY",
            "text": "Chia-Ying Tsai, Fu Jen Catholic University Hospital, Taiwan Jo-Hsuan Wu, University of California, San Diego, United States\n*CORRESPONDENCE Tanvi Verma\nTanvi_Verma@ihpc.a-star.edu.sg\n\u2020These authors have contributed equally to this work and share first authorship\nRECEIVED 23 May 2023 ACCEPTED 28 July 2023 PUBLISHED 14 August 2023"
        },
        {
            "heading": "CITATION",
            "text": "Verma T, Jin L, Zhou J, Huang J, Tan M, Choong BCM, Tan TF, Gao F, Xu X, Ting DS and Liu Y (2023) Privacy-preserving continual learning methods for medical image classification: a comparative analysis. Front. Med. 10:1227515. doi: 10.3389/fmed.2023.1227515"
        },
        {
            "heading": "COPYRIGHT",
            "text": "\u00a9 2023 Verma, Jin, Zhou, Huang, Tan, Choong, Tan, Gao, Xu, Ting and Liu. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.\nPrivacy-preserving continual learning methods for medical image classification: a comparative analysis\nTanvi Verma1*\u2020, Liyuan Jin2,3\u2020, Jun Zhou1, Jia Huang1, Mingrui Tan1, Benjamin Chen Ming Choong1, Ting Fang Tan2,4, Fei Gao1, Xinxing Xu1, Daniel S. Ting2,3,4 and Yong Liu1\n1Institute of High Performance Computing, Agency for Science, Technology and Research (A\u2217STAR), Singapore, Singapore, 2Artificial Intelligence and Digital Innovation Research Group, Singapore Eye Research Institute, Singapore, Singapore, 3Duke-NUS Medical School, Singapore, Singapore, 4Singapore National Eye Centre, Singapore, Singapore\nBackground: The implementation of deep learning models for medical image classification poses significant challenges, including gradual performance degradation and limited adaptability to new diseases. However, frequent retraining of models is unfeasible and raises concerns about healthcare privacy due to the retention of prior patient data. To address these issues, this study investigated privacy-preserving continual learning methods as an alternative solution.\nMethods: Weevaluated twelve privacy-preserving non-storage continual learning algorithms based deep learning models for classifying retinal diseases from public optical coherence tomography (OCT) images, in a class-incremental learning scenario. The OCT dataset comprises 108,309 OCT images. Its classes include normal (47.21%), drusen (7.96%), choroidal neovascularization (CNV) (34.35%), and diabetic macular edema (DME) (10.48%). Each class consisted of 250 testing images. For continuous training, the first task involved CNV and normal classes, the second task focused on DME class, and the third task included drusen class. All selected algorithms were further experimented with di erent training sequence combinations. The final model\u2019s average class accuracy was measured. The performance of the joint model obtained through retraining and the original finetunemodel without continual learning algorithmswere compared. Additionally, a publicly available medical dataset for colon cancer detection based on histology slides was selected as a proof of concept, while the CIFAR10 dataset was included as the continual learning benchmark.\nResults: Among the continual learning algorithms, Brain-inspired-replay (BIR) outperformed the others in the continual learning-based classification of retinal diseases from OCT images, achieving an accuracy of 62.00% (95% confidence interval: 59.36-64.64%), with consistent top performance observed in di erent training sequences. For colon cancer histology classification, E cient Feature Transformations (EFT) attained the highest accuracy of 66.82% (95% confidence interval: 64.23-69.42%). In comparison, the joint model achieved accuracies of 90.76% and 89.28%, respectively. The finetune model demonstrated catastrophic forgetting in both datasets.\nConclusion: Although the joint retraining model exhibited superior performance, continual learning holds promise in mitigating catastrophic forgetting and facilitating continual model updates while preserving privacy in healthcare deep\nFrontiers inMedicine 01 frontiersin.org\nlearning models. Thus, it presents a highly promising solution for the long-term clinical deployment of such models.\nKEYWORDS\ncontinual learning, medical image classification, model deployment, optical coherence tomography, comparative analysis"
        },
        {
            "heading": "1. Introduction",
            "text": "Continual learning refers to the process of continually training and updating a deep learningmodel over time, as new data becomes available. This approach is particularly pertinent for medical image classification model deployment because any potentially deployed deep learning model could suffer from a gradual decline in performance from underlying distribution shifts over time. By continuously retraining the model with new data, the model could maintain high classification performance and adapt to changes in the data distribution. However, in continual learning scenarios, the conventional deep learning approach often leads to catastrophic forgetting, where the model experiences memory loss or a significant decline in performance on previous classes after being trained on new tasks or datasets (1). This is a commonly reported phenomenon in deep learning because the model prioritizes its weights and biases optimization for the new task, leading it to forget or overwrite previously learned information. Alternatively, to mitigate catastrophic forgetting in medical image classification, one potential solution is to retrain the model with cumulative data whenever a new dataset becomes available. However, retraining from scratch frequently in the model\u2019s deployment phase is not practical. Furthermore, data privacy is of utmost importance in the medical domain, and due to strict regulatory requirements, it may not always be possible to access old data (2). Additionally, medical data is often stored in dedicated servers, making it difficult to shuffle multiple datasets. Researchers have proposed a number of continual learning approaches to overcome catastrophic forgetting. However, there have been few studies on medical imaging using continual learning. Furthermore, achieving a trade-off between stability and plasticity remains another challenge in the continual learning scenario. Stability refers to retaining previously acquired knowledge, while plasticity pertains to the model\u2019s ability to learn new knowledge from the new data.\nIn the context of continual learning, \u201cnon-storage\u201d refers to the absence of storing or retaining old data from previous tasks or classes. Continual learning approaches can be categorized into two broad groups: exemplar-based and exemplar-free approaches. Exemplar-based approaches store a small number of data or exemplars and reintroduce them with the new data during training to prevent the model from forgetting the old knowledge. Conversely, exemplar-free approaches (non-storage) rely on regularization, expansion, and generative replay to achieve similar goals without storing exemplar data. Given concerns about privacy and accessibility with medical data, the storage of\nprevious exemplar data from old studies is not feasible. Therefore, exemplar-free continual learning approaches are preferable for medical image classification models and preserve healthcare privacy.\nThe training process for continual learning happens sequentially in a series of tasks, and during each training session, the model only has access to the data for the current task. Task incremental, domain incremental and class incremental are three common scenarios of continual learning. In task incremental learning, the model has access to the task identifier during inference, which obviates the need for the model to differentiate between images from different tasks. Domain incremental learning, on the other hand, does not require task identification at inference time, since the output space of each task is the same. Class incremental learning, the most clinically relevant yet challenging scenario, involves the model\u2019s inability to access the task identifier at inference time, and the model must therefore be capable of distinguishing between images from all tasks. The class incremental learning is more closely aligned with real-life scenarios and more suitable for real-world medical image classification.\nHence, in this research, privacy-preserving exemplar-free continual learning approaches were explored in class learning scenarios for medical imaging classification targeting significant and prevalent diseases using publically available datasets, namely optical coherence tomography (OCT) (3) and PathMNIST (4). As a benchmark for continual learning performance, CIFAR10 dataset (5) was included."
        },
        {
            "heading": "2. Background",
            "text": "Continual learning involves training machine learning models on data from a series of tasks D = {D1,D2, \u00b7 \u00b7 \u00b7 ,DT}. Task Dt = {(xti , y t i )} nt i=1 is the t th task where xti \u2208 Xt is an input, y t i \u2208 Yt is the corresponding label and nt is number of classes in the task. During training the tth task, only training data Dt is available while the training data of previous tasks are no longer accessible. The tasks are generally assumed to be distinct from one another. The goal of continual learning is to train a parameterized model f\u03b8 :X \u2192 Y that can predict the correct label for an unseen test sample from any task. Here X = \u222aTt=1Xt is the input space and Y = \u222a T t=1Yt is the output space. In continual learning, the marginal probability distribution of inputs varies across tasks, i.e., P(X1) 6= P(X2). Based on probability distribution of output space and whether the task identity is provided at the inference time, there are three different continual learning scenarios (6).\nFrontiers inMedicine 02 frontiersin.org"
        },
        {
            "heading": "2.1. Task incremental scenario",
            "text": "The probability distribution of output space varies between tasks (P(Y1) 6= P(Y2)) and task identifier is provided at the time of inference for task incremental scenario. Hence, it is possible to train models with task-specific components in this scenario. \u201cMulti-headed\u201d network architecture is commonly used for this scenario where each task has its own output units, but the rest of the network is shared among tasks."
        },
        {
            "heading": "2.2. Domain incremental scenario",
            "text": "The output space (and hence the corresponding probability distribution) remains same across the tasks for domain incremental scenario, i.e., {Y1} = {Y2} and P(Y1) = P(Y2). The problem setting looks similar to domain adaptation (7). However unlike domain adaptation, which focuses on achieving good performance on new task, the goal of continual learning is to maintain good performance on previously learned tasks while also achieving reasonable performance on new tasks."
        },
        {
            "heading": "2.3. Class incremental scenario",
            "text": "Similar to task incremental scenario, the probability distribution of output space varies between tasks in class incremental scenario. However, the model does not have access to task identifier at the time of inference which make it the most complex scenario of continual learning. The network architecture for class incremental scenario is generally \u201csingle-headed\u201d where a single output layer is used to make predictions for all tasks. Sometimes \u201cmulti-headed\u201d architectures are used for this scenario, but it needs prediction of task identifier before predicting the class label of the image at the time of inference. Figure 1 shows an example of a \u201csingle-headed\u201d model which is being trained in class incremental scenario to classify OCT images into different retinal pathologies. In many real-world applications, it is not practical to assume that the task identifier will be available at the time of inference, especially in the medical domain where the model is often used to classify diseases. Therefore, an exclusive focus was placed on this scenario in this research."
        },
        {
            "heading": "3. Exemplar-free continual learning approaches",
            "text": "In this section, threemain categories of exemplar-free continual\nlearning approaches and associated algorithms were summarized."
        },
        {
            "heading": "3.1. Regularization-based methods",
            "text": "Regularization-based continual learning methods add a regularization term to the training loss function that encourages it to retain the knowledge it has learned from previous tasks\nwhile also allowing it to adapt to new tasks. Regularization-based methods can be further divided into weight-based and data-based regularization methods.\nThe first group of regularization-based approaches aims to prevent weight drift, which is considered to be crucial for previous tasks. This is achieved by estimating the importance of each parameter in the network after learning each task. When training new tasks, the importance of each parameter is taken into account and used to discourage its changes. For example, Elastic Weight Consolidation (EWC) (8) uses a quadratic penalty term to restrict modification of important weights. (9) proposed a quadratic penalty method for continual learning of neural networks that contain batch normalization layers. Synaptic Intelligence (SI) method (10) uses synapse to measure the weights\u2019 importance. Memory Aware Synapses (MAS) (11) determines the importance of weights using a Hebbian learning model, which is based on the sensitivity of the output function. Riemanian Walk (RWalk) (12) method uses Fisher Information Matrix approximation and online path integral to calculate the importance for each parameter. (13) defined a notion of uncertainty and made the variance of the incoming weights of each node trainable. To maintain stabilityplasticity trade-off, they also included two regularization terms for stability and plasticity respectively. Similarly, (14) added a drifting regularization for stability and a Lasso regularization for plasticity. There are a few methods which regularize gradients of weights. For instance, Orthogonal Weights Modification (OWM) (15) maps the weights modification (gradients) onto a subspace generated by all the previous tasks in order to maintain the performance of previous tasks. Gradient Projection Memory (GPM) (16) regularizes the gradients by restricting the direction of gradient descent steps. Likewise, (17) proposed conceptor-aided backpropagation (CAB), in which gradients are shielded by conceptors (characterizes the linear subspace formed by activation in a layer) against degradation of previously learned tasks.\nOn the other hand, data-based regularization methods use knowledge distillation (18) to prevent the model from forgetting. Knowledge distillation refers to the technique of transferring the knowledge of a model trained on previous tasks to a new model that will learn new tasks. The basic idea is to use the output of the model trained on previous tasks as a \u201csoft target\u201d for the new model. The new model is trained to mimic the output of the old model on the previous tasks, as well as learn new tasks. Learning without Forgetting (LwF) (19) is one of the earliest methods to use knowledge distillation for continual learning. Extending on LwF, (20) proposed Learning without Memorizing (LwM), which adds attention distillation loss by Gradient-weighted Class Activation Mapping (Grad-CAM) along with knowledge distillation loss to mitigate catastrophic forgetting. There are a few methods such as PODNet (21), Attention Uncertainty (AU) (22) and GeoDL (23) which incorporate exemplar memory in addition to knowledge distillation techniques to address the challenge of continual learning.\nA major drawback of regularization-based approaches is that they are highly sensitive to the selection of hyperparameters, making it challenging to achieve a suitable balance between stability and plasticity.\nFrontiers inMedicine 03 frontiersin.org\nFIGURE 1 An example for class incremental scenario in medical imaging classification: Continual learning based deep learning algorithm sequentially learns a series of retinal pathologies in OCT such as CNV, DME, Drusen, and normal finding."
        },
        {
            "heading": "3.2. Expansion-based methods",
            "text": "In contrast to regularization-based methods, expansion-based continual learning approaches focus on expanding the capacity of the model to handle new tasks. This can be achieved by adding new parameters or neurons to the model, or by creating multiple versions of the model, each specialized for a specific task.\nOne popular approach of expansion-based continual learning is called dynamic expansion, where the model\u2019s capacity is expanded by adding new neurons or parameters to the model as new tasks are encountered. This approach allows the model to adapt to new tasks by creating new representations or features that are specific to the new task. Dynamically Expandable Network (DEN) (24), Reinforced Continual Learning (RCL) (25) and Compacting Picking Growing (CPG) (26) are some methods which fall under this category.\nAnother approach is called task-specific expansion, where either multiple versions of the model (each specialized for a specific task) are created, or task specific classifier is added to the model. This allows the overall system to handle multiple tasks\nsimultaneously. Progressive Network (27), Additive Parameter Decomposition (APD) (28), Efficient Feature Transformation (EFT) (29) and Expert Gate (30) are some of the methods that utilize task-specific expansion to continuously learn new tasks without forgetting previous tasks.\nMost of the existing expansion-based methods are suitable for the task-incremental scenario, i.e., they assume availability of task\nidentity at the time of inference. However, certain methods such\nas Expert Gate, iTAML and EFT predict the task identifier prior to predicting the correct class. Expansion-based methods typically\nexhibit superior performance compared to regularization-based methods. However, the requirement for two levels of inferences, first determining the task identity and then the actual class label, may decrease the overall performance of the model."
        },
        {
            "heading": "3.3. Generative replay-based methods",
            "text": "The idea of generative replay-based methods in continual learning is to generate synthetic data that resembles the distribution of old tasks, and use them to train the model along with the data in new tasks. This allows the model to learn new tasks while maintaining knowledge of previously learned tasks, without the need to keep any exemplars from those tasks. Some popular generative methods used in continual learning include generative replay (GR) (31), Replay-through-Feedback (RtF) (32) and Brain Inspired Replay (BIR) (33). GR utilizes a generative adversarial network to generate previous data whereas RtF and BIR use a variational autoencoder as generator.\nThe main disadvantage of generative method is that it takes a long time to train the generative model. Furthermore, it has been shown that generative models may struggle when dealing with complex datasets (34)."
        },
        {
            "heading": "4. Compared methods",
            "text": "In this study, pertinent algorithms from each category of exemplar-free continual learning methods were selected. Within the weight-based regularization methods category, EWC (8), SI\nFrontiers inMedicine 04 frontiersin.org\n(10), MAS (11), MUC-MAS (35), RWalk (12), OWM (15), and GPM (16) were included. For data-based regularization, LwF (19) and LwM (20) were selected. EFT (29) was chosen as the expansionbased method, while GR (31) and BIR (33) were selected from the generative-replay methods. The lower baseline (finetune) and the upper baseline (joint) approaches were included for comparison. Finetuning involves adapting a pre-trained model to new data or tasks without starting from scratch, while joint training relies on retraining the model on cumulative data from all tasks. A comprehensive description of these selected algorithms is provided in the Supplementary material."
        },
        {
            "heading": "5. Methodology",
            "text": "The model underwent incremental training on three tasks. By definition, Model 1 was initially trained on the first task, followed by expanding Model 1 into Model 2 through sequential training on task 2 data. Similarly, Model 2 was further expanded into Model 3 after being trained on task 3 data. The detailed network architecture and hyperparameter values are provided in the Supplementary material."
        },
        {
            "heading": "5.1. Datasets",
            "text": "Two medical datasets: optical coherence tomography (OCT) (3) and PathMNIST (36) and one non-medical dataset: CIFAR10 (5) were selected. All images are in RGB color, normalized using the mean and standard deviation of ImageNet. All three datasets were split into three tasks and the set of classes in each task was fixed across all experiments. The specific class description for each dataset is specified below.\n\u2022 OCT: This dataset contains over 108,309 publicly available\nOCT training images, including four classes regarding the condition of the retina: Normal (47.21%), Drusen (7.96%), Choroidal Neovascularization (CNV) (34.35%), Diabetic Macular Edema (DME) (10.48%). There are 250 testing images for each class. The first task contains two classes: Normal and CNV, the second task contains only DME and the last task contains only Drusen. It was selected for its highly imbalanced classes simulating a more realistic continual learning scenario, particularly when the model has already been trained on a large number of data in earlier tasks and the new task only contains a small number of training images. Furthermore, additional investigations on continuous learning sequences were explored for the significance of unbalanced data distribution, as reported in the Supplementary material. Those scenarios include task 1 containing a large amount of data while task 3 containing the least amount of data, and vice versa. \u2022 PathMNIST: As part of MedMNIST dataset, PathMNIST\ndataset is selected due to its distinguishing feature of encompassing a greater number of disease classes. It consists of histology slides with 9 different colon pathology classes. It contains 89,996 training and 7,180 testing images. The number of training images in a class varies from 7,886 to 12,885, with\nan average of 10,000. The 9 classes are divided into three tasks containing three classes each. \u2022 CIFAR10: As a traditional continual learning benchmark,\nCIFAR10 dataset was selected to compare the adaptability and robustness of different algorithms. It consists of 60,000 natural images in 10 classes, such as cat and truck. There are 5,000 training images and 1,000 testing images per class. The first task contains four classes while the two subsequent tasks contain three classes each."
        },
        {
            "heading": "5.2. Statistical analysis",
            "text": "Experiments were conducted using three different seed values. Following common practices in the field of continual learning (12, 37), average accuracy and average forgetting were selected as the evaluation metrics. Average accuracy measures the overall performance of the model after training on task t is complete. It is computed as At = 1 t \u2211t i=1 a i t , where a i t is the accuracy of the model on task i after training on task t. On the other hand, task-wise accuracy was also introduced to highlight model adaptation and the balance between stability and plasticity during sequential training, measured by the intermediate and final accuracies of each task on the intermediate (Model 1 and Model 2) and final model (Model 3). The forgetting metric was included by measuring the decline in accuracy for each task by comparing the highest accuracy achieved during training with the final accuracy after training is completed. This provides an estimate of the extent model has been forgotten based on its current state. The forgetting on task i after the model has been trained on task t is given by f it = max j\u2208{1,\u00b7\u00b7\u00b7 ,t\u22121} (aij \u2212 a i t). The average forgetting of the final model is computed as F = 1 T\u22121 \u2211T\u22121 i=1 f i T ."
        },
        {
            "heading": "6. Results",
            "text": "The average accuracy and forgetting of the final model (Model 3) after it has been trained on the three tasks sequentially are calculated. The task-wise accuracy on each model is also measured for a better insight into the balance between stability and plasticity."
        },
        {
            "heading": "6.1. Average accuracy and forgetting",
            "text": "The average accuracy and forgetting ofModel 3 are presented in Table 1, and the effect of sequential training on the average accuracy of the model is shown in Figure 2. For average accuracy, joint training obtains best performance of 90.76%, 89.28% and 88.01% respectively and it serves as the upper bound. Among all validated algorithms, BIR shows the best retinal disease classification on OCT and CIFAR10 performance with average accuracy of 62.00% (95% CI 59.36-64.64%) and 64.68% (95% confidence interval (CI) 63.76-65.59%) respectively. EFT obtains the best colorectal cancer histology classification on PathMNIST with average accuracy of 66.82% (95% CI 64.23-69.42%). Additionally, EFT demonstrates consistent better accuracy and lower forgetting across different datasets with average accuracy of 43.20% (95% CI 41.24-45.16%)\nFrontiers inMedicine 05 frontiersin.org\non OCT and 60.65% (95% CI 58.57-62.73%) on CIFAR10. RWalk\u2019s performance is poor and is comparable to the performance of Finetune with catastrophic forgetting. Other algorithms such as LwF, EWC, MAS, MUC-MAS and GR appear to have comparable performance to Finetune in terms of average accuracy. However, they are still able to retain some knowledge of previous tasks (evident from their lower forgetting), in contrast to Finetune, which almost completely forgets previous tasks, as can be observed in Table 2. GR performs poorly on all datasets in contrast to similar generative replay method BIR.\nIn terms of forgetting, although the accuracy of SI is not high, it demonstrates the least forgetting (21.27% on OCT). For PathMNIST and CIFAR10 datasets, OWM and EFT show the least forgetting, measured by 16.34% and 31.31% respectively. We also note that the performance of exemplar-free continual learning methods is greatly influenced by the structure of the dataset. For instance, OWM, which performs relatively well on PathMNIST (52.42% accuracy, 16.34% forgetting) and CIFAR10 (48.30% accuracy, 42.18% forgetting), does poorly on the unbalanced data of OCT (38.93% accuracy, 83.10% forgetting). In contrast, SI performs better on OCT (43.6% accuracy, 21.27% forgetting) and performs relatively worse on PathMNIST (32.40% accuracy, 28.94% forgetting) and CIFAR10 (28.51% accuracy, 40.62% forgetting).\nIn summary, EFT and BIR exhibit better overall accuracy compared to the other selected exemplar-free continual learning methods."
        },
        {
            "heading": "6.2. Task-wise accuracy",
            "text": "Based on Figures 3\u20135, the accuracy of each task is affected after the model is trained on each task for OCT, PathMNIST and CIFAR10 datasets respectively. Plots in Figures 3A, 4A, 5A show the decline in accuracy of task 1 data after sequential training\non the three tasks. The X-axis represents the three models. It is observed that although the initial accuracy on task 1 is almost similar for all methods, it drastically declines (except for a few wellperforming methods such as EFT, BIR, etc.) after training on task 2. However, the accuracies of task 2 data vary widely (Figures 3B, 4B, 5B) depending on the stability-plasticity trade-off used by each method. The initial accuracy of task 2 for methods such as SI, LwM, and GPM is relatively low as, to maintain stability, the model is not flexible enough to incorporate new knowledge. The same behavior is observed for the task 3 data (Figures 3C, 4C, 5C), and the initial accuracy of task 3 data varies with the algorithm.\nResults reported in Table 2 provides a better picture of the stability-plasticity trade-off employed by each algorithm where the accuracy of each task on Model 3 was reported. Algorithms such as LwF, EWC,MAS, RWalk andGR almost completely forget previous tasks and their average accuracy reported in Table 1 is mainly due to the high accuracy of task 3. Based on the relatively better performance of EFT across three different datasets, it supports the\nassertion that expansion-based methods, which add task-specific\nnodes to the model, are better able to retain the knowledge of previous tasks compared to regularization-based methods. As EFT maintains a task-specific classifier, it is able to maintain relatively better accuracies on each task.\nIt is noteworthy that for some algorithms such as LwM, SI, and\nGPM, the final accuracy of task 1 is higher than the final accuracy\nof task 2, which appears counterintuitive. However, as seen in Figures 3B, 4B, 5B, to maintain stability, the initial accuracies\nof task 2 are low to begin with. Therefore, when the model is\nsubsequently trained on task 3, the accuracy of task 2 further declines and is lower than the final accuracy of task 1 (which was\nhigh to begin with). This explains the behavior of having task 2\u2019s\nfinal accuracy lower than task 1\u2019s final accuracy.\nThe majority of methods, except for EFT and OWM to some extent, exhibit poor performance on the PathMNIST dataset. This\nFrontiers inMedicine 06 frontiersin.org\ncould be attributed to the presence of overlapping features among classes across different tasks. The limited success of OWM on this dataset highlights the existence of feature overlap, as even with an extensive training regime of 500 epochs and a learning rate of 1e7, OWM struggled to identify a suitable subspace in the feature space for the third task, despite its attempt to project the gradients of the new task orthogonally to the subspace of previous tasks.\nAnother notable observation is that while methods like LwF and BIR excel at retaining knowledge of the most recent task, they tend to exhibit a higher degree of forgetting as the number of tasks increases. For instance, although BIR demonstrates the highest average accuracy in both OCT and CIFAR10, it still experiences significant forgetting (51.31% on OCT and 42.30% on CIFAR10). This indicates that although these models achieve high accuracy on current tasks, they struggle to retain information about earlier tasks. Additionally, regularization-based methods are highly sensitive to hyperparameters, and even small changes to the regularization loss coefficient can lead to vastly different results.\nIn the context where the later tasks have more training data compared to the earlier tasks, BIR consistently maintains its performance on the OCT dataset, even when the class sequence is altered. This is demonstrated in the Supplementary material. However, while EFT maintains its overall accuracy, its taskwise accuracy exhibits variations for different sequences. GR\u2019s performance remains unaffected by data imbalance; however, its overall accuracy remains low, and forgetting remains high. Other regularization-based methods, including LwF, EWC, MAS and MUC-MAS demonstrate similar patterns. For the remaining regularization-based methods, such as LWM, SI, GPM, OWM and RWalk changes in the task sequence impact their task-wise accuracy. Despite this, their overall accuracy remains low.\nIn conclusion, striking a balance between stability and plasticity poses a significant challenge, especially for regularizationbased algorithms. However, generative-based and expansionbased methods show promise in enhancing classification accuracy for tasks in the context of continual learning. Furthermore, generative-based methods are well-suited for scenarios where data is imbalanced across tasks. These approaches hold the potential for addressing the complexities of retaining previously learned knowledge while accommodating new information."
        },
        {
            "heading": "7. Discussion",
            "text": "In the field of medical imaging, deep learning models have been widely used for classification tasks across various medical imaging modalities. These models have been incorporated into real-world practice for decision-making in diagnosis and treatment, as evidenced by recent examples such as referable diabetic retinopathy screening in ophthalmology using color fundus photography (38). While deep learning models have provided a balance between healthcare burden and disease management, emerging imaging devices and new disease pathologies require further improvement of existing models. Continual learning has the potential to mitigate catastrophic forgetting and enable continual model updates,\nFrontiers inMedicine 07 frontiersin.org\nmaking it a promising solution for medical image classification models. In our study, we focused on comparing exemplar-free continual learning methods for medical image classification. We observed that regularization-based methods generally struggled in addressing catastrophic forgetting, while expansion-based methods and generative replay-based methods showed potential in retaining knowledge of earlier tasks. Although the AI field frequently reports on objective metrics like forgetting, it lacks clinical reliability and applicability. This is primarily due to its limited intermodel variability and weak correlation with model performance as demonstrated. Additionally, as the concept of continual learning is still in its early stages within the medical field, determining the average accuracy threshold for clinical deployment remains an unexplored area that necessitates careful consideration of balancing healthcare privacy concerns.\nOur results show a considerable gap between best-performing continual learning algorithms with traditional joint training model which involves storing previous data and retraining themodel from scratch. However, this conventional joint training model would not exist in the real world due to its storage for retraining strongly violating healthcare patient privacy. Despite challenges for current continual learning-based methods to achieve optimal classification performance, continual learning based deep learning model would likely be the next paradigm for medical image classification models with the aforementioned advantages. Another interesting topic is the balance between loss in the deep learning model\u2019s performance and breakage in individual patient privacy. As the next paradigm for deep learning in medical imaging, continual learning could potentially offer cross-institutional training for expanding model generalizability, learning about new diseases, and even enhancing limited data on rare diseases. Federated Learning (FL) (39) offers an alternative to deep learning when dealing with imbalanced\nhealthcare data and healthcare privacy issues, relying on distributed localized model training and subsequent updating centralized models without exchanging raw input data. This approach has shown practical applicability in real-world scenarios, particularly in multi-center collaborations focused on COVID-19 detection during the recent pandemic (40) during the last pandemic. While continual learning may appear similar to FL, its distinct strength lies in the fact that knowledge is \u201cmemorized\u201d within the model parameters, eliminating the need for complex adjunct security measures like differential privacy or blockchain integration in FL. Moreover, in FL, all the training data is assumed to be available simultaneously, albeit on different local clients. On the other hand, continual learning deals with the temporal factor, where training data arrives with time, and older training data may become unavailable due to privacy concerns.\nAs for continual learning techniques, although many original continual learning approaches achieve their best performance in task incremental scenarios, class incremental scenarios are more realistic in healthcare settings and continual learning deployment in medical image classification due to intrinsic input data complexity and uncertainty to task information. However, not all existing continual learning algorithms perform well in the class incremental learning scenario, due to their unique design and inconsistent performance in different seeds. Additionally, certain algorithms demonstrated robustness in handling data imbalance across tasks. The strength of our research lies in being the first comparative study that extensively analyzed all existing privacy-preserving continual learning algorithms on two medical imaging modalities. Such significant datasets were selected based on their application in diseases with high prevalence, morbidity and mortality. However, we acknowledge the limitation of not including many other forms ofmedical imaging. In future work, it is pertinent\nFrontiers inMedicine 08 frontiersin.org\nto explore the influence of different input data types, for example, chest X-ray, color fundus photography, computed tomography, and magnetic resonance imaging."
        },
        {
            "heading": "8. Related work",
            "text": "With a growing interest in have been many approaches proposed in the literature. This has been followed by several surveys\nFrontiers inMedicine 09 frontiersin.org\nand empirical papers that aim to provide an overview of the field and evaluate the performance of these methods. To enable a structured comparison between continual learning methods, Van\nde Ven and Tolias (6) described the three scenarios of learning. Parisi et al. (41) discussed continual learning from the perspective of biological lifelong learning such as structural plasticity, memory replay, curriculum and transfer learning etc. Delange et al. (42) offered a comprehensive experimental comparison of 11 different continual learning methods, however, they focused on easier task incremental setting and assume that the task identifier is known at the time of inference. In their interesting work Farquhar and Gal (43) examined standard evaluation practices and observed that based on the selection of experimental design, some continual learning approaches look better than they are. Qu et al. (44) grouped continual learning methods by their representative techniques, including regularization, knowledge distillation, memory, generative replay, parameter isolation etc. The study conducted by Hayes et al. (45) presents a thorough comparison between replay in the mammalian brain and replay in artificial neural networks and identified the gaps between replay in these two fields. Most of the empirical surveys (46\u201348) cover all three scenarios of continual learning and select only a handful of approaches suitable for each scenario for comparing performances. Hence, these works do not deep dive into a more focused use case of exemplar-free class-incremental setting which is particularly relevant to the medical domain. Furthermore, they do not compare these state-of-the-art algorithms on medical datasets. Research conducted by Derakhshani et al. (49) is closest to our work, where the authors have established a benchmark for classifying diseases using the MedMNIST dataset. However, they have considered a limited selection of five continual learning methods across all three scenarios of continual learning. As exemplar-free methods, they chose EWC (8), MAS (11), and LwF (19), while iCarL (50) and EEIL (51) were selected as exemplar-based methods. They reported iCarL achieving the highest performance on the PathMNIST dataset with an accuracy of 58.46%. In contrast, EFT (29), an expansion-based exemplar-free method, performed the best (66.82%) on the PathMNIST dataset based on the current study."
        },
        {
            "heading": "9. Conclusion",
            "text": "Three major continual learning methods namely regularization-based, expansion-based, and generative replaybased methods, and relevant algorithms were explained and summarized in this research. Furthermore, twelve state-of-the-art privacy-preserving continual learning algorithms were investigated for medical imaging classification using deep learning models. BIR algorithm achieved the best average accuracy on OCT for retinal disease classification among all continual learning algorithms, and EFT is the best-performing algorithm on PathMNIST for colorectal cancer histology classification. It was suggested both expansion-based and generative replay-based methods, specifically EFT and BIR, show the greatest potential in continual learning for medical applications. Given the frequent model updates and the need for the integration of new medical knowledge, continual learning has become an increasingly important topic in healthcare model deployment. Nevertheless, the trade-off between performance loss and patient privacy remains a crucial consideration. Continual learning offers a promising avenue for\nFrontiers inMedicine 10 frontiersin.org\nimproving model performance while preserving patient privacy, and could potentially be the next paradigm for next-generation deep learning-based medical image classification."
        },
        {
            "heading": "Data availability statement",
            "text": "Publicly available datasets were analyzed in this study. OCT data can be found at: https://data.mendeley.com/datasets/ rscbjbr9sj/3, PathMNIST data can be found at: https://zenodo.org/ record/6496656#.ZGMJ--xByys and CIFAR10 data can be found at: https://www.cs.toronto.edu/~kriz/cifar.html."
        },
        {
            "heading": "Author contributions",
            "text": "TV and LJ: conceptualization. TV, LJ, JZ, JH, MT, and BC: methodology, implementation, and experiments. TV, LJ, JZ, JH, MT, and TT: draft preparation and visualization. TV, LJ, FG, and XX: review and editing. DT and YL: supervision. All authors have read and agreed to the published version of the manuscript."
        },
        {
            "heading": "Funding",
            "text": "This work was supported by the Agency for Science, Technology and Research (A*STAR) AME Programmatic Funds (Grant Number: A20H4b0141), National Medical Research\nCouncil, Singapore (Grant Number: NMRC/HSRG/0087/2018, MOH-000655-00, and MOH-001014-00), and Duke-NUS Medical School (Grant Number: Duke-NUS/RSF/2021/0018 and 05/FY2020/EX/15-A58)."
        },
        {
            "heading": "Conflict of interest",
            "text": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest."
        },
        {
            "heading": "Publisher\u2019s note",
            "text": "All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher."
        },
        {
            "heading": "Supplementary material",
            "text": "The Supplementary Material for this article can be found online at: https://www.frontiersin.org/articles/10.3389/fmed.2023. 1227515/full#supplementary-material"
        }
    ],
    "title": "Privacy-preserving continual learning methods for medical image classification: a comparative analysis",
    "year": 2023
}