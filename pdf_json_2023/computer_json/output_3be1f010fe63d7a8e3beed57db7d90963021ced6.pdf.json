{
    "abstractText": "This survey presents recent research on determining control-theoretic properties and designing controllers with rigorous guarantees using semidefinite programming and for nonlinear systems for which no mathematical models but measured trajectories are available. Data-driven control techniques have been developed to circumvent a time-consuming modelling by first principles and because of the increasing availability of data. Recently, this research field has gained increased attention by the application of Willems\u2019 fundamental lemma, which provides a fertile ground for the development of data-driven control schemes with guarantees for linear time-invariant systems. While the fundamental lemma can be generalized to further system classes, there does not exist a comparable data-based system representation for nonlinear systems. At the same time, nonlinear systems constitute the majority of practical systems. Moreover, they include additional challenges such as data-based surrogate models that prevent system analysis and controller design by convex optimization. Therefore, a variety of data-driven control approaches has been developed with different required prior insights into the system to ensure a guaranteed inference. In this survey, we will discuss developments in the context of data-driven control for nonlinear systems. In particular, we will focus on methods based on system representations providing guarantees from finite data, while the analysis and the controller design boil down to convex optimization problems given as semidefinite programming. Thus, these approaches achieve reasonable advances compared to the state-of-the-art system analysis and controller design by models from system identification. Specifically, the paper covers system representations based on extensions of Willems\u2019 fundamental lemma, set membership, kernel techniques, the Koopman operator, and feedback linearization.",
    "authors": [
        {
            "affiliations": [],
            "name": "Tim Martina"
        },
        {
            "affiliations": [],
            "name": "Thomas B. Sch\u00f6nb"
        },
        {
            "affiliations": [],
            "name": "Frank Allg\u00f6wera"
        }
    ],
    "id": "SP:8fafc938abe53108d520735bf7ef43e2224ebc9c",
    "references": [
        {
            "authors": [
                "M. Abudia",
                "J.A. Rosenfeld",
                "R. Kamalapurkar"
            ],
            "title": "Carleman Lifting",
            "year": 2022
        },
        {
            "authors": [
                "tomat. Control",
                "V.G. Lopez",
                "M.A. M\u00fcller"
            ],
            "title": "On the design",
            "year": 2023
        },
        {
            "authors": [
                "A. Amini",
                "Q. Sun",
                "N. Motee"
            ],
            "title": "Error Bounds for Carleman",
            "venue": "In Proc. 22nd IFAC World Congress, arXiv preprint,",
            "year": 2021
        },
        {
            "authors": [
                "Boston",
                "pp"
            ],
            "title": "Nonlinear Adaptive Control. Encyclopedia of Systems",
            "year": 2014
        },
        {
            "authors": [
                "Control. Springer",
                "K.J. London. \u00c5str\u00f6m",
                "B. Wittenmark"
            ],
            "title": "Adaptive Control (2nd ed.)",
            "year": 1989
        },
        {
            "authors": [
                "A.A. Wesley. Bachnas",
                "R. T\u00f3th",
                "A. Mesbah",
                "J.H.A. Ludlage"
            ],
            "title": "A review on",
            "year": 2014
        },
        {
            "authors": [
                "J. Berberich",
                "F. Allg\u00f6wer"
            ],
            "title": "distillation column case study",
            "venue": "Journal of Process Control,",
            "year": 2020
        },
        {
            "authors": [
                "C.M. Bishop"
            ],
            "title": "Pattern Recognition and Machine Learning",
            "year": 2006
        },
        {
            "authors": [
                "A. New York. Bisoffi",
                "C. De Persis",
                "P. Tesi"
            ],
            "title": "Data-based stabilization",
            "year": 2020
        },
        {
            "authors": [
                "A. Bisoffi",
                "C. De Persis",
                "P. Tesi"
            ],
            "title": "Data-driven control via Petersen\u2019s",
            "venue": "trol Letters,",
            "year": 2022
        },
        {
            "authors": [
                "D. Bruder",
                "C.D. Remy",
                "R. Vasudevan"
            ],
            "title": "Nonlinear system identification of soft robot dynamics using Koopman operator theory",
            "venue": "Proc. Int. Conf. on Robotics and Automation (ICRA), pp. 6244\u20136250.",
            "year": 2019
        },
        {
            "authors": [
                "S.L. Brunton",
                "B.W. Brunton",
                "J.L. Proctor",
                "J.N. Kutz"
            ],
            "title": "Koopman Invariant Subspaces and Finite Linear Representations of Nonlinear Dynamical Systems for Control",
            "venue": "PloS one, 11(2): e0150171.",
            "year": 2016
        },
        {
            "authors": [
                "J.P. Calliess"
            ],
            "title": "Conservative decision-making and inference in uncertain dynamical systems",
            "venue": "PhD thesis, University of Oxford.",
            "year": 2014
        },
        {
            "authors": [
                "M.C. Campi",
                "A. Lecchini",
                "S.M. Savaresi"
            ],
            "title": "Virtual reference feedback tuning: a direct method for the design of feedback controllers",
            "venue": "Automatica, 38(8):1337-1346.",
            "year": 2002
        },
        {
            "authors": [
                "M.C. Campi",
                "S. Garatti",
                "M. Prandini"
            ],
            "title": "The scenario approach for systems and control design",
            "venue": "Annual Reviews in Control, 33(2):149\u2013157.",
            "year": 2009
        },
        {
            "authors": [
                "A. Capone",
                "A. Lederer",
                "S. Hirche"
            ],
            "title": "Gaussian Process Uniform Error Bounds with Unknown Hyperparameters for Safety-Critical Applications",
            "venue": "Proc. Conf. Machine Learning.",
            "year": 2022
        },
        {
            "authors": [
                "T. Carleman"
            ],
            "title": "Application de la th\u00e9orie des \u00e9quations int\u00e9grales lin\u00e9aires aux syst\u00e9mes d\u2019\u00e9quations diff\u00e9rentielles non lin\u00e9aires",
            "venue": "Acta Mathematica, vol. 59, pp. 63\u201387.",
            "year": 1932
        },
        {
            "authors": [
                "R.J. Caverly",
                "J.R. Forbes"
            ],
            "title": "LMI Properties and Applications in Systems, Stability, and Control Theory",
            "venue": "arXiv preprint arXiv:1903.08599.",
            "year": 2019
        },
        {
            "authors": [
                "A. Cetinkaya",
                "M. Kishida"
            ],
            "title": "Nonlinear Data-Driven Control for Stabilizing Periodic Orbits",
            "venue": "Proc. 60th Conf. Decision and Control (CDC), pp. 4326-4331.",
            "year": 2021
        },
        {
            "authors": [
                "S.K. Cheah",
                "D. Bhattacharjee",
                "M.S. Hemati",
                "R.J. Caverly"
            ],
            "title": "Robust Local Stabilization of Nonlinear Systems With Controller-Dependent Norm Bounds: A Convex Approach With Input-Output Sampling",
            "venue": "IEEE Control Systems Lett., vol. 7, pp. 931-936.",
            "year": 2023
        },
        {
            "authors": [
                "Y. Cheng",
                "M. Sznaier",
                "C. Lagoa"
            ],
            "title": "Robust Superstabilizing Controller Design from Open-Loop Experimental",
            "venue": "Proc. IFAC Symposium on Sys. Id., 48(28):1337\u20131342.",
            "year": 2015
        },
        {
            "authors": [
                "S.I. Chernyshenko",
                "P. Goulart",
                "D. Huang",
                "A. Papachristodoulou"
            ],
            "title": "Polynomial sum of squares in fluid dynamics: a review with a look ahead",
            "venue": "Phil. Trans. R. Soc. A., 372:20130350.",
            "year": 2014
        },
        {
            "authors": [
                "G. Chesi",
                "A. Garulli",
                "A. Tesi",
                "A. Vicino"
            ],
            "title": "Homogeneous Polynomial Forms for Robustness Analysis of Uncertain Systems",
            "venue": "Springer, London.",
            "year": 2009
        },
        {
            "authors": [
                "S.R. Chowdhury",
                "A. Gopalan"
            ],
            "title": "On Kernelized Multi-armed Bandits",
            "venue": "Proc. Conf. Machine Learning.",
            "year": 2017
        },
        {
            "authors": [
                "T. \u00c7imen"
            ],
            "title": "Systematic and effective design of nonlinear feedback controllers via the state-dependent Riccati equation (SDRE) method",
            "venue": "Annual Reviews in Control, 34(1):32\u201351.",
            "year": 2010
        },
        {
            "authors": [
                "J. Coulson",
                "J. Lygeros",
                "F. D\u00f6rfler"
            ],
            "title": "Data-enabled predictive control: In the shallows of the DeePC",
            "venue": "Proc. European Control Conf. (ECC), pp. 307\u2013312.",
            "year": 2019
        },
        {
            "authors": [
                "T. Dai",
                "M. Sznaier"
            ],
            "title": "Nonlinear Data-Driven Control via StateDependent Representations",
            "venue": "Proc. 60th Conf. Decision and Control (CDC), pp. 5765\u20135770.",
            "year": 2021
        },
        {
            "authors": [
                "T. Dai",
                "M. Sznaier"
            ],
            "title": "A Semi-Algebraic Optimization Approach to Data-Driven Control of Continuous-Time Nonlinear Systems",
            "venue": "IEEE Control Systems Lett., 5(2):487-492.",
            "year": 2021
        },
        {
            "authors": [
                "C. De Persis",
                "P. Tesi"
            ],
            "title": "Formulas for Data-Driven Control: Stabilization, Optimality and Robustness",
            "venue": "IEEE Trans. Automat. Control, 65(3):909\u2013924.",
            "year": 2020
        },
        {
            "authors": [
                "C. De Persis",
                "P. Tesi"
            ],
            "title": "Designing Experiments for Data-Driven Control of Nonlinear Systems",
            "venue": "Proc. Symposium on Mathematical Theory of Networks and Systems, 54(9):285\u2013290.",
            "year": 2021
        },
        {
            "authors": [
                "C. De Persis",
                "M. Rotulo",
                "P. Tesi"
            ],
            "title": "Learning Controllers from Data via Approximate Nonlinearity Cancellation",
            "venue": "IEEE Trans. Automat. Control, 68(10):6082-6097.",
            "year": 2022
        },
        {
            "authors": [
                "C. De Persis",
                "D. Gadginmath",
                "F. Pasqualetti",
                "P. Tesi"
            ],
            "title": "DataDriven Feedback Linearization with Complete Dictionaries",
            "venue": "arXiv preprint arXiv:2308.11229.",
            "year": 2023
        },
        {
            "authors": [
                "A. Devonport",
                "H. Yin",
                "M. Arcak"
            ],
            "title": "Bayesian Safe Learning and Control with Sum-of-Squares Analysis and Polynomial Kernels",
            "venue": "Proc. 59th Conf. Decision and Control (CDC), pp. 3159-3165.",
            "year": 2020
        },
        {
            "authors": [
                "J. Diwold",
                "B. Kolar",
                "M. Sch\u00f6berl"
            ],
            "title": "A Trajectory-Based Approach to Discrete-Time Flatness",
            "venue": "IEEE Control Systems Lett., vol. 6, pp. 289-294.",
            "year": 2022
        },
        {
            "authors": [
                "F. D\u00f6rfler",
                "P. Tesi",
                "C. De Persis"
            ],
            "title": "On the Role of Regularization",
            "year": 2022
        },
        {
            "authors": [
                "W. Favoreel",
                "B. De Moor",
                "P. Van Overschee",
                "M. Gevers"
            ],
            "title": "Modelfree subspace-based LQG-design",
            "venue": "Proc. American Control Conf. (ACC), pp. 3372\u20133376.",
            "year": 1999
        },
        {
            "authors": [
                "C. Fiedler",
                "C.W. Scherer",
                "S. Trimpe"
            ],
            "title": "Practical and Rigorous Uncertainty Bounds for Gaussian Process Regression",
            "venue": "Proc. AAAI Conf. Artificial Intelligence, 35(8):7439-7447.",
            "year": 2021
        },
        {
            "authors": [
                "C. Fiedler",
                "C.W. Scherer",
                "S. Trimpe"
            ],
            "title": "Learning-enhanced robust controller synthesis with rigorous statistical and control-theoretic guarantees",
            "venue": "Proc. 60th Conf. Decision and Control (CDC), pp. 5122-5129.",
            "year": 2021
        },
        {
            "authors": [
                "E. Fogel"
            ],
            "title": "System Identification via Membership Set Constraints with Energy Constrained Noise",
            "venue": "IEEE Trans. Automat. Control, 24(5):752-758.",
            "year": 1979
        },
        {
            "authors": [
                "S. Formentin",
                "S.M. Savaresi"
            ],
            "title": "Virtual reference feedback tuning for linear parameter-varying systems",
            "venue": "Proc. 18th IFAC World Congress, pp. 10219\u201310224.",
            "year": 2011
        },
        {
            "authors": [
                "F. Forni",
                "R. Sepulchre",
                "A.J. van der Schaft"
            ],
            "title": "On differential passivity of physical systems",
            "venue": "In Proc. 52nd Conf. Decision and Control (CDC),",
            "year": 2013
        },
        {
            "authors": [
                "R.A. Freeman",
                "P. Kokotovi\u0107"
            ],
            "title": "Robust Nonlinear Control Design",
            "venue": "Birkh\u00e4user, Boston.",
            "year": 1996
        },
        {
            "authors": [
                "H. Garnier",
                "P.C. Young"
            ],
            "title": "The advantages of directly identifying continuous-time transfer function models in practical applications",
            "venue": "International Journal of Control, 87(7):1319\u20131338.",
            "year": 2014
        },
        {
            "authors": [
                "M. Guo",
                "C. De Persis",
                "P. Tesi"
            ],
            "title": "Data-Driven Stabilization of Nonlinear Polynomial Systems With Noisy Data",
            "venue": "IEEE Trans. Automat. Control, 67(8):4210-4217.",
            "year": 2022
        },
        {
            "authors": [
                "M. Guo",
                "C. De Persis",
                "P. Tesi"
            ],
            "title": "Data-driven stabilizer design and closed-loop analysis of general nonlinear systems via Taylor\u2019s expansion",
            "venue": "arXiv preprint arXiv:2209.01071.",
            "year": 2022
        },
        {
            "authors": [
                "N. Hashemian",
                "A. Armaou"
            ],
            "title": "Feedback control design using model predictive control formulation and Carleman approximation method",
            "venue": "AIChE J. 65(9): e16666.",
            "year": 2019
        },
        {
            "authors": [
                "M.K. Helwa",
                "A. Heins",
                "A.P. Schoellig"
            ],
            "title": "Provably Robust LearningBased Approach for High-Accuracy Tracking Control of Lagrangian Systems",
            "venue": "IEEE Robotics and Automation Letters, 4(2):1587-1594.",
            "year": 2019
        },
        {
            "authors": [
                "L. Hewing",
                "K.P. Wabersich",
                "M. Menner",
                "M.N. Zeilinger"
            ],
            "title": "Learning-Based Model Predictive Control: Toward Safe Learning in Control",
            "venue": "Annual Review of Control, Robotics, and Autonomous Systems, vol. 3, pp. 269-296.",
            "year": 2020
        },
        {
            "authors": [
                "G. Hilhorst",
                "E. Lambrechts",
                "G. Pipeleers"
            ],
            "title": "Control of linear parameter-varying systems using B-splines",
            "venue": "Proc. 55th Conf. Decision and Control (CDC), pp. 3246-3251.",
            "year": 2016
        },
        {
            "authors": [
                "H. Hjalmarsson",
                "M. Gevers",
                "S. Gunnarsson",
                "O. Lequin"
            ],
            "title": "Iterative feedback tuning: theory and applications",
            "venue": "IEEE Control Systems Magazine, 18(4):26-41.",
            "year": 1998
        },
        {
            "authors": [
                "Z.S. Hou",
                "Z. Wang"
            ],
            "title": "From model-based control to data-driven control: Survey, classification and perspective",
            "venue": "Information Sciences, vol. 235, pp. 3-35.",
            "year": 2013
        },
        {
            "authors": [
                "Z. Hu",
                "C. De Persis",
                "P. Tesi"
            ],
            "title": "Learning controllers from data via kernel-based interpolation",
            "venue": "arXiv preprint arXiv:2304.09577.",
            "year": 2023
        },
        {
            "authors": [
                "A. Isidori"
            ],
            "title": "Nonlinear Control Systems (3rd ed.)",
            "year": 1995
        },
        {
            "authors": [
                "C. Jidling",
                "N. Wahlstr\u00f6m",
                "A. Wills",
                "T.B. Sch\u00f6n"
            ],
            "title": "Linearly constrained gaussian processes",
            "venue": "Proc. Advances in Neural Information Processing Systems, vol. 30.",
            "year": 2017
        },
        {
            "authors": [
                "E. Kaiser",
                "J.N. Kutz",
                "S.L. Brunton"
            ],
            "title": "Data-driven discovery of Koopman eigenfunctions for control",
            "venue": "Mach. Learn.: Sci. Technol., 2(3): 035023.",
            "year": 2021
        },
        {
            "authors": [
                "M. Kamb",
                "E. Kaiser",
                "S.L. Brunton",
                "L.N. Kutz"
            ],
            "title": "Time-Delay Observables for Koopman: Theory and Applications",
            "venue": "SIAM Journal on Applied Dynamical Systems, 19(2):886-917.",
            "year": 2020
        },
        {
            "authors": [
                "M. Kanagawa",
                "P. Hennig",
                "D. Sejdinovic",
                "B.K. Sriperumbudur"
            ],
            "title": "Gaussian Processes and Kernel Methods: A Review on Connections and Equivalences",
            "venue": "arXiv preprint arXiv:1807.02582.",
            "year": 2018
        },
        {
            "authors": [
                "Khalil",
                "H.K"
            ],
            "title": "Nonlinear Systems (3rd ed.)",
            "year": 2002
        },
        {
            "authors": [
                "A. Koch",
                "J. Berberich",
                "J. K\u00f6hler",
                "F. Allg\u00f6wer"
            ],
            "title": "Determining optimal input-output properties: A data-driven approach",
            "venue": "Automatica, vol. 134, pp. 109906.",
            "year": 2021
        },
        {
            "authors": [
                "A. Koch",
                "J. Berberich",
                "F. Allg\u00f6wer"
            ],
            "title": "Provably Robust Verification of Dissipativity Properties from Data",
            "venue": "IEEE Trans. Automat. Control, 67(8):4248\u20134255.",
            "year": 2022
        },
        {
            "authors": [
                "M. Korda",
                "I. Mezi\u0107"
            ],
            "title": "Linear predictors for nonlinear dynamical",
            "venue": "Proc. National Academy of Sciences,",
            "year": 2018
        },
        {
            "authors": [
                "A. Hall PTR. Luppi",
                "A. Bisoffi",
                "C. De Persis",
                "P. Tesi"
            ],
            "title": "Hall information and system sciences series",
            "year": 2021
        },
        {
            "authors": [
                "A. Luppi",
                "C. De Persis",
                "P. Tesi"
            ],
            "title": "On data-driven stabilization",
            "year": 2022
        },
        {
            "authors": [
                "B. Lusch",
                "J.N. Kutz",
                "S.L. Brunton"
            ],
            "title": "Deep learning for univer",
            "venue": "trol Lett.,",
            "year": 2018
        },
        {
            "authors": [
                "A. Mauroy",
                "I. Mezi\u0107",
                "Y. Susuki"
            ],
            "title": "The Koopman operator in systems",
            "year": 2020
        },
        {
            "authors": [
                "Springer",
                "I. Switzerland. Markovsky",
                "P. Rapisarda"
            ],
            "title": "Data-driven simulation and control",
            "year": 2008
        },
        {
            "authors": [
                "T. Martin",
                "F. Allg\u00f6wer"
            ],
            "title": "Iterative data-driven inference of nonlin",
            "year": 2020
        },
        {
            "authors": [
                "F. Allg\u00f6wer"
            ],
            "title": "Dissipativity Verification with Guarantees",
            "venue": "Decision and Control. (CDC),",
            "year": 2021
        },
        {
            "authors": [
                "T. Martin",
                "F. Allg\u00f6wer"
            ],
            "title": "Data-driven system analysis",
            "year": 2023
        },
        {
            "authors": [
                "F. Allg\u00f6wer"
            ],
            "title": "Determining dissipativity for nonlinear",
            "venue": "(Early Access),",
            "year": 2023
        },
        {
            "authors": [
                "F. Allg\u00f6wer"
            ],
            "title": "Data-driven inference on optimal input",
            "venue": "American Control Conf. (ACC),",
            "year": 2022
        },
        {
            "authors": [
                "D.Q. Mayne",
                "M.M. Seron",
                "S.V. Rakovi\u0107"
            ],
            "title": "Robust model predictive control of constrained linear systems with bounded disturbances",
            "venue": "Automatica, 41(2):219\u2013224.",
            "year": 2005
        },
        {
            "authors": [
                "Mejari",
                "A. Gupta",
                "D. Piga"
            ],
            "title": "Data-Driven Computation of Robust Invariant Sets and Gain-Scheduled Controllers for Linear ParameterVarying Systems. arXiv preprint arXiv:2309.0181",
            "year": 2023
        },
        {
            "authors": [
                "I. Mezi\u0107"
            ],
            "title": "Spectral properties of dynamical systems, model reduction and decompositions",
            "venue": "Nonlinear Dynamics, vol. 41, pp. 309\u2013325.",
            "year": 2005
        },
        {
            "authors": [
                "M. Milanese",
                "C. Novara"
            ],
            "title": "Set Membership identification of nonlinear systems",
            "venue": "Automatica, 40(6):957-975.",
            "year": 2004
        },
        {
            "authors": [
                "J. Miller",
                "T. Dai",
                "M. Sznaier"
            ],
            "title": "Data-Driven Stabilizing and Robust Control of Discrete-Time Linear Systems with Error in Variables",
            "venue": "arXiv preprint arXiv:2210.13430.",
            "year": 2022
        },
        {
            "authors": [
                "J. Miller",
                "M. Sznaier"
            ],
            "title": "Data-Driven Gain Scheduling Control of Linear Parameter-Varying Systems Using Quadratic Matrix Inequalities",
            "venue": "IEEE Control Systems Lett., vol. 7, pp. 835-840.",
            "year": 2023
        },
        {
            "authors": [
                "Y. Min",
                "S.M. Richards",
                "N. Azizan"
            ],
            "title": "Data-Driven Control with Inherent Lyapunov Stability",
            "venue": "arXiv preprint arXiv:2303.03157.",
            "year": 2023
        },
        {
            "authors": [
                "S. Monaco",
                "D. Normand-Cyrot"
            ],
            "title": "Minimum-phase nonlinear discrete-time systems and feedback stabilization",
            "venue": "Proc. 26th Conf. Decision and Control (CDC), pp. 979\u2013986.",
            "year": 1987
        },
        {
            "authors": [
                "J.M. Montenbruck",
                "F. Allg\u00f6wer"
            ],
            "title": "Some Problems Arising in Controller Design from Big Data via Input-Output Methods",
            "venue": "Proc. 55th Conf. Decision and Control (CDC), pp. 6525-6530.",
            "year": 2016
        },
        {
            "authors": [
                "K. Narendra",
                "A. Annaswamy"
            ],
            "title": "Robust adaptive control in the presence of bounded disturbances",
            "venue": "IEEE Trans. Automat. Control, 31(4):306315.",
            "year": 1986
        },
        {
            "authors": [
                "O. Nelles"
            ],
            "title": "Nonlinear System Identification: From Classical Approaches to Neural Networks Fuzzy Models, and Gaussian Processes (2nd ed.)",
            "year": 2021
        },
        {
            "authors": [
                "H.H. Nguyen",
                "M. Friedel",
                "R. Findeisen"
            ],
            "title": "LMI-based Data-Driven Robust Model Predictive Control",
            "venue": "arXiv preprint arXiv:2303.04777.",
            "year": 2023
        },
        {
            "authors": [
                "B. Nortmann",
                "T. Mylvaganam"
            ],
            "title": "Data-Driven Control of Linear Time-Varying Systems",
            "venue": "Proc. 59th Conf. Decision and Control (CDC), pp. 3939\u20133944.",
            "year": 2020
        },
        {
            "authors": [
                "C. Novara",
                "L. Fagiano",
                "M. Milanese"
            ],
            "title": "Direct feedback control design for nonlinear systems",
            "venue": "Automatica, 49(4):849\u2013860.",
            "year": 2013
        },
        {
            "authors": [
                "F. N\u00fcske",
                "S. Peitz",
                "F. Philipp",
                "M. Schaller",
                "K. Worthmann"
            ],
            "title": "Finitedata error bounds for Koopman-based prediction and control",
            "venue": "Journal of Nonlinear Science, 33:14.",
            "year": 2023
        },
        {
            "authors": [
                "S. Oymak",
                "N. Ozay"
            ],
            "title": "Non-asymptotic Identification of LTI Systems from a Single Trajectory",
            "venue": "Proc. American Control Conf. (ACC), 5655\u20135661.",
            "year": 2019
        },
        {
            "authors": [
                "M. Putinar"
            ],
            "title": "Positive polynomials on compact semi-algebraic sets",
            "venue": "Indiana Univ. Math. J. 42, pp. 969\u2013984.",
            "year": 1993
        },
        {
            "authors": [
                "A. Rantzer"
            ],
            "title": "A dual to Lyapunov\u2019s stability theorem",
            "venue": "Systems & Control Lett., 42(3):161\u2013168.",
            "year": 2001
        },
        {
            "authors": [
                "C.E. Rasmussen",
                "C.K.I. Williams"
            ],
            "title": "Gaussian Processes for Machine Learning",
            "venue": "The MIT Press.",
            "year": 2006
        },
        {
            "authors": [
                "A. Romer",
                "S. Trimpe",
                "F. Allg\u00f6wer"
            ],
            "title": "Data-driven inference of passivity properties via Gaussian process optimization",
            "venue": "Proc. European Control Conf. (ECC), pp. 29\u201335.",
            "year": 2019
        },
        {
            "authors": [
                "A. Romer",
                "J. Berberich",
                "J. K\u00f6hler",
                "F. Allg\u00f6wer"
            ],
            "title": "One-shot verification of dissipativity properties from input-output data",
            "venue": "IEEE Control Systems Lett., 3(3):709\u2013714.",
            "year": 2019
        },
        {
            "authors": [
                "D. Rotondo",
                "G. Luta",
                "J.H.U. Aarv\u00e5g"
            ],
            "title": "Towards a Taylor-Carleman bilinearization approach for the design of nonlinear state-feedback controllers",
            "venue": "European Journal of Control, vol. 68, pp. 100670.",
            "year": 2022
        },
        {
            "authors": [
                "M.G. Safonov",
                "T.C. Tsao"
            ],
            "title": "The unfalsified control concept and learning",
            "venue": "IEEE Trans. Automat. Control, 42(6):843-847.",
            "year": 1997
        },
        {
            "authors": [
                "T. Sauer",
                "Y. Xu"
            ],
            "title": "On multivariate Hermite interpolation",
            "venue": "Advances in Computational Mathematics, vol. 4, pp. 207\u2013259.",
            "year": 1995
        },
        {
            "authors": [
                "P. Scharnhorst",
                "E.T. Maddalena",
                "Y. Jiang",
                "C.N. Jones"
            ],
            "title": "Robust uncertainty bounds in reproducing kernel hilbert spaces: A convex optimization approach",
            "venue": "IEEE Trans. Automat. Control, 68(5):2848-2861.",
            "year": 2023
        },
        {
            "authors": [
                "C.W. Scherer",
                "S. Weiland"
            ],
            "title": "Linear matrix inequalities in control, Lecture Notes (Compilation: 2015)",
            "venue": "Available: https://www.imng.unistuttgart.de/mst/files/LectureNotes.pdf .",
            "year": 2000
        },
        {
            "authors": [
                "C.W. Scherer"
            ],
            "title": "LPV control and full block multipliers",
            "venue": "Automatica, 37(3):361\u2013375.",
            "year": 2001
        },
        {
            "authors": [
                "C.W. Scherer",
                "C. Hol"
            ],
            "title": "Matrix Sum-of-Squares Relaxations for Robust Semi-Definite Programs",
            "venue": "Math. Programming, 107, pp. 189\u2013211.",
            "year": 2006
        },
        {
            "authors": [
                "S. Sinha",
                "S.P. Nandanoori",
                "J. Drgona",
                "D. Vrabie"
            ],
            "title": "Data-driven stabilization of discrete-time control-affine nonlinear systems: A Koopman operator approach",
            "venue": "Proc. European Control Conf. (ECC), pp. 552-559.",
            "year": 2022
        },
        {
            "authors": [
                "I. Steinwart",
                "A. Christmann"
            ],
            "title": "Support Vector Machines",
            "venue": "Springer, New York.",
            "year": 2008
        },
        {
            "authors": [
                "R. Str\u00e4sser",
                "J. Berberich",
                "F. Allg\u00f6wer"
            ],
            "title": "Data-Driven Control of Nonlinear Systems: Beyond Polynomial Dynamics",
            "venue": "Proc. 60th Conf. Decision and Control (CDC), pp. 4344-4351.",
            "year": 2021
        },
        {
            "authors": [
                "R. Str\u00e4sser",
                "J. Berberich",
                "F. Allg\u00f6wer"
            ],
            "title": "Robust data-driven control for nonlinear systems using the Koopman operator",
            "venue": "Proc. 22nd IFAC World Congress, arXiv preprint arXiv:2304.03519.",
            "year": 2023
        },
        {
            "authors": [
                "R. Str\u00e4sser",
                "J. Berberich",
                "F. Allg\u00f6wer"
            ],
            "title": "Control of bilinear systems using gain-scheduling: Stability and performance guarantees",
            "venue": "arXiv preprint arXiv:2304.04486.",
            "year": 2023
        },
        {
            "authors": [
                "S.H. Strogatz"
            ],
            "title": "Nonlinear dynamics and chaos: With applications to physics, biology, chemistry, and engineering (2nd ed.)",
            "year": 2014
        },
        {
            "authors": [
                "M. Sznaier"
            ],
            "title": "A Data Driven, Convex Optimization Approach to Learning Koopman Operators",
            "venue": "Proc. Machine Learning Research, vol. 144, pp. 1\u201311.",
            "year": 2021
        },
        {
            "authors": [
                "M. Tanaskovic",
                "L. Fagiano",
                "C. Novara",
                "M. Morari"
            ],
            "title": "Data-driven control of nonlinear systems: An on-line direct approach",
            "venue": "Automatica, vol. 75, pp. 1\u201310.",
            "year": 2017
        },
        {
            "authors": [
                "A.J. Taylor",
                "V.D. Dorobantu",
                "S. Dean",
                "B. Recht",
                "Y Yue",
                "A.D. Ames"
            ],
            "title": "Towards Robust Data-Driven Control Synthesis for Nonlinear Systems with Actuation Uncertainty",
            "venue": "In Proc. 60th Conf. Decision and Control (CDC),",
            "year": 2021
        },
        {
            "authors": [
                "M. Tiwari",
                "G. Nehma",
                "B. Lusch"
            ],
            "title": "Computationally Efficient DataDriven Discovery and Linear Representation of Nonlinear Systems For Control",
            "venue": "arXiv preprint arXiv:2309.04074.",
            "year": 2023
        },
        {
            "authors": [
                "R. T\u00f3th"
            ],
            "title": "Modeling and Identification of Linear Parameter-Varying Systems",
            "venue": "Springer Berlin, Heidelberg.",
            "year": 2010
        },
        {
            "authors": [
                "J. Umenberger",
                "M. Ferizbegovic",
                "T.B. Sch\u00f6n",
                "H. Hjalmarsson"
            ],
            "title": "Robust exploration in linear quadratic reinforcement learning",
            "venue": "Proc. Advances in Neural Information Processing Systems, vol. 32.",
            "year": 2019
        },
        {
            "authors": [
                "J. Umlauft",
                "L. P\u00f6hler",
                "S. Hirche"
            ],
            "title": "An Uncertainty-Based Control Lyapunov Approach for Control-Affine Systems Modeled by Gaussian Process",
            "venue": "IEEE Control Systems Lett., 2(3):483-488.",
            "year": 2018
        },
        {
            "authors": [
                "L. Vandenberghe",
                "S. Boyd"
            ],
            "title": "Semidefinite Programming",
            "venue": "SIAM Review, 38(1):49-95.",
            "year": 1996
        },
        {
            "authors": [
                "H.J. van Waarde",
                "J. Eising",
                "H.L. Trentelman",
                "M.K. Camlibel"
            ],
            "title": "Data Informativity: A new perspective on Data-Driven Analysis and Control",
            "venue": "IEEE Trans. Automat. Control,",
            "year": 2020
        },
        {
            "authors": [
                "H.J. van Waarde",
                "M.K. Camlibel",
                "M. Mesbahi"
            ],
            "title": "From Noisy Data to Feedback Controllers: Nonconservative Design via a Matrix S-Lemma",
            "venue": "IEEE Trans. Automat. Control,",
            "year": 2022
        },
        {
            "authors": [
                "H.J. van Waarde",
                "J. Eising",
                "M.K. Camlibel",
                "H.L. Trentelman"
            ],
            "title": "The informativity approach : To Data-driven Analysis and Control. arXiv preprint arXiv:2302.10488",
            "year": 2023
        },
        {
            "authors": [
                "C. Verhoek",
                "R. T\u00f3th",
                "S. Haesaert",
                "A. Koch"
            ],
            "title": "Fundamental Lemma for Data-Driven Analysis of Linear Parameter-Varying Systems",
            "venue": "Proc. 60th Conf. Decision and Control (CDC), pp. 5040-5046.",
            "year": 2021
        },
        {
            "authors": [
                "C. Verhoek",
                "H.S. Abbas",
                "R. T\u00f3th",
                "S. Haesaert"
            ],
            "title": "Data-Driven Predictive Control for Linear Parameter-Varying Systems",
            "venue": "Proc. 4th IFAC Workshop on LPV Systems, 54(8):101-108.",
            "year": 2021
        },
        {
            "authors": [
                "C. Verhoek",
                "R. T\u00f3th",
                "H.S. Abbas"
            ],
            "title": "Direct Data-Driven StateFeedback Control of Linear Parameter-Varying Systems",
            "venue": "arXiv preprint arXiv:2211.17182.",
            "year": 2022
        },
        {
            "authors": [
                "C. Verhoek",
                "H.S. Abbas",
                "R. T\u00f3th"
            ],
            "title": "Direct data-driven LPV control of nonlinear systems: An experimental result",
            "venue": "arXiv preprint arXiv:2211.17191.",
            "year": 2022
        },
        {
            "authors": [
                "C. Verhoek",
                "P.J.W. Koelewijn",
                "S. Haesaert",
                "R. T\u00f3th"
            ],
            "title": "Direct datadriven state-feedback control of general nonlinear systems",
            "venue": "arXiv preprint arXiv:2303.10648.",
            "year": 2023
        },
        {
            "authors": [
                "C. Verhoek",
                "J. Berberich",
                "S. Haesaert",
                "F. Allg\u00f6wer",
                "R. T\u00f3th"
            ],
            "title": "Data-driven Dissipativity Analysis of Linear Parameter-Varying Systems",
            "venue": "arXiv preprint arXiv:2303.10648.",
            "year": 2023
        },
        {
            "authors": [
                "J.C. Willems"
            ],
            "title": "Dissipative dynamical systems part I: General theory",
            "venue": "Arch. Rational Mech. Anal., vol. 45, pp. 321\u2013351.",
            "year": 1972
        },
        {
            "authors": [
                "B. Yi",
                "I.R. Manchester"
            ],
            "title": "On the Equivalence of Contraction and Koopman Approaches for Nonlinear Stability and Control",
            "venue": "Proc. 60th Conf. Decision and Control (CDC), pp. 4609-4614.",
            "year": 2021
        },
        {
            "authors": [
                "M. Yin",
                "A. Iannelli",
                "R.S. Smith"
            ],
            "title": "Maximum Likelihood Estimation in Data-Driven Modeling and Control",
            "venue": "IEEE Trans. Automat. Control, 68(1):317-328.",
            "year": 2021
        },
        {
            "authors": [
                "Z. Yuan",
                "J. Cort\u00e9s"
            ],
            "title": "Data-Driven Optimal Control of Bilinear Systems",
            "venue": "IEEE Control Systems Lett., vol. 6, pp. 2479\u20132484.",
            "year": 2022
        },
        {
            "authors": [
                "A. Xue",
                "N. Matni"
            ],
            "title": "Data-Driven System Level Synthesis",
            "venue": "Proc. Machine Learning Research, vol. 144, pp. 1\u201312.",
            "year": 2021
        },
        {
            "authors": [
                "X. Zhang",
                "W. Pan",
                "R. Scattolini",
                "S. Yu",
                "X. Xu"
            ],
            "title": "Robust tubebased model predictive control with Koopman operators",
            "venue": "Automatica, vol. 137, pp. 110114.",
            "year": 2022
        },
        {
            "authors": [
                "Y. Zheng"
            ],
            "title": "Chordal Sparsity in Control and Optimization of Large-scale Systems",
            "venue": "PhD thesis, University of Oxford.",
            "year": 2019
        },
        {
            "authors": [
                "J. Zheng",
                "T. Dai",
                "J. Miller",
                "M. Sznaier"
            ],
            "title": "Robust Data-Driven Safe Control using Density Functions",
            "venue": "arXiv preprint arXiv:2303.09004.",
            "year": 2023
        },
        {
            "authors": [
                "J.G. Ziegler",
                "N.B. Nichols"
            ],
            "title": "Optimum settings for automatic controllers",
            "venue": "Trans. ASME, vol. 64, pp. 759\u2013768.",
            "year": 1942
        }
    ],
    "sections": [
        {
            "text": "This survey presents recent research on determining control-theoretic properties and designing controllers with rigorous guarantees using semidefinite programming and for nonlinear systems for which no mathematical models but measured trajectories are available. Data-driven control techniques have been developed to circumvent a time-consuming modelling by first principles and because of the increasing availability of data. Recently, this research field has gained increased attention by the application of Willems\u2019 fundamental lemma, which provides a fertile ground for the development of data-driven control schemes with guarantees for linear time-invariant systems. While the fundamental lemma can be generalized to further system classes, there does not exist a comparable data-based system representation for nonlinear systems. At the same time, nonlinear systems constitute the majority of practical systems. Moreover, they include additional challenges such as data-based surrogate models that prevent system analysis and controller design by convex optimization. Therefore, a variety of data-driven control approaches has been developed with different required prior insights into the system to ensure a guaranteed inference. In this survey, we will discuss developments in the context of data-driven control for nonlinear systems. In particular, we will focus on methods based on system representations providing guarantees from finite data, while the analysis and the controller design boil down to convex optimization problems given as semidefinite programming. Thus, these approaches achieve reasonable advances compared to the state-of-the-art system analysis and controller design by models from system identification. Specifically, the paper covers system representations based on extensions of Willems\u2019 fundamental lemma, set membership, kernel techniques, the Koopman operator, and feedback linearization.\nKeywords: Data-driven control, Data-driven system analysis, Nonlinear systems, Semidefinite programming"
        },
        {
            "heading": "1. Introduction",
            "text": "Model-based control techniques suppose the access to a mathematical model that describes the behavior of a system over time. The description of the dynamics can be given as difference equations in discrete time or as differential equations in continuous time of the system\u2019s inputs and states or outputs. Besides the synthesis of a controller to influence the behavior of the system, system analysis aims to provide valuable insights into the system by the verification of control-theoretic properties such as dissipativity (Willems, 1972). Subsequently, these properties can be used for a controller design using feedback\n\u22c6Frank Allgo\u0308wer thanks the funding by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany\u2019s Excellence Strategy - EXC 2075 - 390740016 and under grant 468094890. The work of Thomas B. Scho\u0308n is funded by Kjell och Ma\u0308rta Beijer Foundation and by the project NewLEADS - New Directions in Learning Dynamical Systems (contract number: 621-2016-06079), funded by the Swedish Research Council. Tim Martin and Frank Allgo\u0308wer also acknowledge the support by the Stuttgart Center for Simulation Science (SimTech). \u00a92023. This manuscript has been accepted to Annual Reviews in Control (https://doi.org/10.1016/j.arcontrol.2023.100911) and is made available under a Creative Commons Licence CC-BY-NC-ND. \u2217Corresponding author Email addresses: tim.martin@ist.uni-stuttgart.de (Tim Martin), thomas.schon@it.uu.se (Thomas B. Scho\u0308n), frank.allgower@ist.uni-stuttgart.de (Frank Allgo\u0308wer)\nlaws (Khalil, 2002), e.g., the small-gain theorem or the interconnection of passive systems.\nOne possible derivation of models is based on first principles, for instance, Newton\u2019s laws of motion, Kirchhoff\u2019s circuit laws, and the first and second law of thermodynamics. However, their application often requires expert knowledge, calls for a priori simplifications to obtain suitable models for control, or is more time consuming than the controller design itself. At the same time, the goal intrinsically is the controller instead of a model.\nFor these reasons, data-driven approaches (Hou and Wang, 2013) have gained in popularity. There system properties are verified and controllers designed from measured trajectories of the underlying system. System identification (Ljung, 1999; Nelles, 2021) represents a so-called indirect data-driven method because first a model is identified from data and then analyzed or a controller is derived by model-based techniques. However, here the mismatch between the identified model and the underlying system is often obscure. Indeed, the investigation of the model mismatch is even for the identification of linear time-invariant (LTI) systems an active research field (Oymak and Ozay, 2019). At the same time, if this mismatch is unknown, then the design of a controller with closed-loop stability and performance guarantees is jeopardized though inherent guarantees of the control design procedure.\nInvestigations of direct data-driven techniques for LTI sys-\nPreprint submitted to Annual Reviews in Control November 6, 2023\nar X\niv :2\n30 6.\n16 04\n2v 2\n[ m\nat h.\nO C\n] 3\nN ov\n2 02\n3\ntems without an intermediate modelling step include PID control (Ziegler and Nichols, 1942), adaptive control (\u00c5stro\u0308m and Wittenmark, 1989), iterative feedback tuning (Hjalmarsson et al., 1998), virtual reference feedback tuning (Campi et al., 2002), reinforcement learning (Bradtke, 1992), unfalsified control (Safonov and Tsao, 1997), and subspace-based LQG-control (Favoreel et al., 1999).\nMoreover, the renewed interest in the behavioral approach and the fundamental lemma from Willems et al. (2005) in the context of data-driven control has led to a framework (Markovsky and Do\u0308rfler, 2021) for data-driven system analysis and various control schemes. Furthermore, inspired by Willems\u2019 fundamental lemma, De Persis and Tesi (2020) presents a parametrization of the closed loop of an LTI system and a state feedback based on data matrices. This result also has led to further data-driven control synthesis approaches (Markovsky and Do\u0308rfler, 2021).\nWhile the data for Willems\u2019 fundamental lemma would allow the exact identification of the LTI system, the data-informativity framework of van Waarde et al. (2020, 2023) examines the question, when data are informative enough to draw conclusions concerning controllability, stabilizability, etc. Therefore, the amount of data that is needed to identify a system is in general larger than what is needed to control the system. The framework is based on the set of all LTI systems explaining the data. This resembles a set-membership approach (Fogel, 1979), which is, e.g., exploited in Cheng et al. (2015) to design a controller for superstability from noisy input-output data by linear programming.\nThese recent developments have established for LTI systems a comprising framework for data-driven system analysis and control including, e.g., verification of various system properties, optimal control, robust control, and predictive control. However, analogous results are missing for nonlinear systems due to the manifold of additional challenges. Indeed, the identification of a nonlinear system only from a finite set of samples is not possible. Instead, additional a priori insights into the system are required. Moreover, although many controller design techniques have inherent closed-loop stability guarantees, they are jeopardized due to the not exactly known nonlinearities. Thus, no end-to-end guarantees for the closed loop can be recovered. Additionally, estimating a bound between the nonlinearity and its estimation from finite data is nontrivial. Lastly, a direct analysis of nonlinear systems leads in general to nonconvex optimization problems, for example, the estimation of the region of attraction.\nData-driven approaches for nonlinear systems with guarantees include nonlinear adaptive control (Astolfi, 2014), learning-based model predictive control (MPC) (Hewing et al., 2020), reinforcement learning with safety guarantees (Berkenkamp et al., 2017), and stability verification (Lavaei et al., 2022) using scenario optimization (Campi et al., 2009). Furthermore, neural networks are exemplarily applied in Min et al. (2023) to simultaneously learn the dynamics, controller, and a Lyapunov function to provide stability guarantees under a known approximation error of the neural network. Under a known upper bound on the Lipschitz constant of the system\u2019s\ndynamics, set membership (Novara et al., 2013) and Kinky inference (Calliess, 2014) provide a framework for nonlinear systems to design a controller, for instance, by online prediction (Tanaskovic et al., 2017) or online certificate function control (Taylor et al., 2021). Related to this framework, Montenbruck and Allgo\u0308wer (2016) presents a data-driven system analysis via the input-output mapping of a nonlinear system and Martin and Allgo\u0308wer (2020) examines an extension by an iterative sampling scheme.\nThis article focuses on data-driven methods based on system representations providing rigorous guarantees and enabling verification of control-theoretic properties and the design of controllers via semidefinite programming (SDP). To circumvent nonconvex optimization though nonlinear system dynamics, convex relaxations and various linearization and polynomialization methods are employed. Due to noisy measurements or the approximation of the system dynamics, the underlying dynamics can not exactly be identified. Nevertheless, the presented approaches provide guarantees by first obtaining a set of systems consistent with the data and a bound on the approximation error. Combined with robust control techniques and a convex optimization via SDPs, rigorous end-to-end guarantees for the determined system properties and closed loop are ensured from finite data. The motivation for the development of these methods is explained in the following points (i)-(vi).\n(i) The presented methods derive system representations suitable for data-driven system analysis and the design of various controller schemes from data. Therefore, these methods strive to establish a framework for nonlinear data-driven system analysis and control, analogously to the frameworks for LTI systems by the fundamental lemma (Willems et al., 2005) and data informativity (van Waarde et al., 2020).\n(ii) System identification, e.g., based on neural networks or Gaussian processes, can result in precise but strong nonlinear, models. Whereas a system analysis or a state feedback design based on these models would be a nonconvex optimization problem, the presented system representations are tailored for solving many control-related problems by SDPs.\n(iii) As shown in Section 3, SDPs can be solved in practice often in a tractable way by relying on well-established algorithms and solvers.\n(iv) While system identification aims to approximate the dynamics as precise as possible, the system representations presented here are motivated to verify system properties or design a controller. As in the LTI case (van Waarde et al., 2020), one expect that the identification requires more data than the verification or controller synthesis problem.\n(v) System identification techniques for nonlinear systems not always provide error bounds to ensure guarantees.\n(vi) The presented system representations leverage, among others, a set of systems feasible with the observed data, similar to a set-membership approach (Novara et al., 2013). While the existing literature considers Lipschitz approximations for specific control structures and data-inefficient system analysis (Montenbruck and Allgo\u0308wer, 2016), the presented methods exploits more general robust control techniques to, e.g., include performance criteria for more general closed-loop structures.\nIn contrast to set-membership identification (Milanese and Novara, 2004), where the feasible system set is leveraged to obtain a model and its mismatch, the methods here exploits the system set directly for control.\nThe survey is organized as follows. We begin with the introduction of some notation and a motivation of SDPs in control in Section 3. Afterwards, we will briefly report the presented data-driven approaches in Section 4 and then provide a more detailed discussion of their key ideas. Therefore, we will focus on the data-based representation of the nonlinear system rather than their application to specific control problems. Section 10 shows further discussion of the presented methods and Section 11 concludes the article."
        },
        {
            "heading": "2. Notation",
            "text": "Throughout the article, we denote the set of natural numbers by N, the natural numbers including zero by N0, and the set of real numbers by R. The Euclidean norm of a vector v \u2208 Rn is denoted by ||v||2. Furthermore, I and 0 corresponds to the identity and the zero matrix of suitable dimensions, respectively. The Frobenius norm of a matrix M \u2208 Rn\u00d7m is denoted by ||M||Fr. The right inverse of a full-row-rank matrix R \u2208 Rn\u00d7m is denoted by R\u2020 \u2208 Rm\u00d7n. For a symmetric matrix A = AT , A \u227b 0 or A \u2ab0 0 denote that A is positive definite or positive semidefinite, respectively. Analogously, A \u227a 0 or A \u2aaf 0 if A is negative definite or negative semidefinite, respectively."
        },
        {
            "heading": "3. Semidefinite programming in control",
            "text": "This section motivates the application of SDPs in system analysis and control. To this end, we first provide a brief introduction of SDPs following Vandenberghe and Boyd (1996). Second, we comment on the usefulness of SDPs in control.\nWhile SDPs are introduced in different forms, we remain on a control perspective. There an SDP minimizes a linear function subject to a constraint given by the definiteness of an affine function of symmetric matrices. More precisely,\nmin x\u2208Rn\ncT x\nsubject to F(x) = F0 + n\u2211\ni=1\nxiFi \u2ab0 0, (1)\nwith c \u2208 Rn and symmetric matrices Fi \u2208 Rm\u00d7m, i = 0, . . . , n. Since the objective function as well as F(x) are linear in the optimization variable x, optimization problem (1) is convex. In this case, all local optima are globally optimal such that convex optimization problems are theoretically tractable.\nThe optimization problem of SDP (1) can be illustrated as in Figure 1. To find its optimal solution, we need to push the dotted line as far as possible into the direction of \u2212c while not intersecting the feasible set F(x) \u2ab0 0. As illustrated, the feasible set is convex and the optimal solution xopt lies in general on its boundary, i.e., the matrix F(xopt) is singular.\nBesides the theoretical tractability due to convexity, SDPs are attractive as many problems from combinatorial optimization and control theory can be recast as an SDP. Indeed, SDPs can handle constraints given by linear matrix inequalities (LMI) F(x) \u2ab0 0, convex quadratic inequalities, lower bounds on matrix norms, lower bounds on determinants of positive semidefinite matrices, and polynomial inequalities via sum-of-squares (SOS) hierarchies (see Section 3.1).\nFurthermore, SDPs generalize linear programming with matrix inequalities instead of componentwise inequalities between vectors. By this connection, many results and algorithms from linear programming extend to SDPs even though the latter is more general. For instance, most interior-point methods for linear programming can be generalized to SDPs. To this end, barrier functions are introduced which tend to infinity as points approach the boundary of the feasible set. Thereby, the constraint optimization (1) can be reformulated into an unconstrained one, which can be solved efficiently by Newton iteration techniques. Similar to linear programming, these iterations have polynomial worst-case complexity and perform very well in practice. For instance, Vandenberghe and Boyd (1996) provides the ruleof-thumb that interior-point methods solve SDPs in 5\u221250 iterations, where each iteration corresponds to a least-squares problem of the same size as the original problem.\nWe conclude this section by a simple application of SDPs in a control context. For that purpose, we want to check whether an LTI system x\u0307(t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t) with state x(t) \u2208 Rnx , input u(t) \u2208 Rm, and output y(t) \u2208 Rm, is passive. According to Willems (1972), we need to search for a positive definite function S (x) such that S\u0307 (x(t)) \u2264 y(t)T u(t) for all x(t) \u2208 Rnx and u(t) \u2208 Rm. For the quadratic ansatz S (x) = xT Px, P \u2ab0 0, we obtain the condition[\nx u ]T [\u2212PA \u2212 AT P \u2212PB + 12C \u2212BT P + 12C D ] \ufe38 \ufe37\ufe37 \ufe38\n=L(P)\n[ x u ] \u2265 0, (2)\nwhich is implied by L(P) \u2ab0 0. By introducing each element of\nP = p11 \u00b7 \u00b7 \u00b7... . . . , one can see that L(P) \u2ab0 0 is an LMI with the optimization variables pi j, i = 1, . . . , nx, j = 1, . . . , nx. Hence, we can check for passivity of an LTI system by the SDP\nmin P\u2208Rnx\u00d7nx 0 subject to [ P 0 0 L(P) ] \u2ab0 0.\nWhen replacing the LTI dynamics by a nonlinear x\u0307(t) = f (x(t), u(t)), y(t) = h(x(t), u(t)), then condition (2) results into a nonlinear matrix inequality. The resulting optimization problem is therefore not an SDP in general. To rely on the wellestablished solvers for SDPs, the methods presented here not only need to infer on the dynamics of the system but also derive a system description suitable for a system analysis and a controller design by SDPs."
        },
        {
            "heading": "3.1. Sum-of-squares optimization",
            "text": "Many control-related problems, e.g., the verification of Lyapunov stability of a polynomial system, include polynomial inequality constraints. To solve these NP-hard problems, polynomial inequalities can be relaxed by SOS decomposition leading to an SDP with LMI constraints. We will briefly introduce SOS optimization here as various presented methods rely on this relaxation.\nConsider a real polynomial in x = [ x1 \u00b7 \u00b7 \u00b7 xn ]T \u2208 Rn of degree d\np(x) = \u2211\n\u03b1\u2208Nn0,|\u03b1|\u2264d a\u03b1x\u03b1,\nwith vectorial indices \u03b1T = [ \u03b11 \u00b7 \u00b7 \u00b7 \u03b1n ]T \u2208 Nn0, |\u03b1| = \u03b11 + \u00b7 \u00b7 \u00b7 + \u03b1n, real coefficients a\u03b1 \u2208 R, and monomials x\u03b1 = x\u03b111 \u00b7 \u00b7 \u00b7 x \u03b1n n . Let R[x], R[x]m, and R[x]m\u00d7n denote the set of all real polynomials, all m-dimensional polynomial vectors,\nand all m \u00d7 n polynomial matrices, respectively. Then a matrix P \u2208 R[x]n\u00d7n is an SOS matrix if there exists a matrix Q \u2208 R[x]m\u00d7n such that P(x) = Q(x)T Q(x). According to the square matricial representation (Chesi et al., 2009), the search for Q boils down to checking the feasibility of an LMI.\nBy the SOS decomposition P(x) = Q(x)T Q(x), all SOS matrices are positive semidefinite for all x \u2208 Rn. However, not all polynomial positive semidefinite matrices are SOS. Thus, an SOS condition corresponds to a relaxation of a positive semidefiniteness condition of a polynomial matrix. Nevertheless, SOS optimization is widely used in control for the following two reasons. The Positivstellensatz from Putinar (1993) allows to check for non-negativity of a polynomial on a compact semialgebraic set. Together with a matrix-version of this result (Scherer and Hol, 2006), a regional analysis of control systems is possible. Moreover, the moment-SOS hierarchy (Lasserre, 2000) shows that the relaxation converges with increasing degree of polynomials.\nOne drawback of SOS optimization is scalability. Indeed, for a polynomial p(x) with degree 2d, the SOS relaxation of p(x) \u2264 0 leads to p(x) = z(x)Qz(x) and Q \u2ab0 0 with Q of dimensions ( n + d\nd\n) \u00d7 ( n + d\nd\n) \u2248 nd \u00d7 nd. If the scalability of stan-\ndard SOS relaxation prevents the application to large problems, chordal sparsity (Zheng, 2019) for the obtained SOS problem might improve scalability issues. Furthermore, SOS relaxation could be replaced by B-spline relaxations, which shows less conservatism and less computational demand for, e.g., LPV controller design with polynomial parameter dependence (Hilhorst et al., 2016)."
        },
        {
            "heading": "4. Preview",
            "text": "The purpose of this section is to provide a preview of the data-driven methods covered in this survey. They are organized\nby the derivation technique for their data-based system representation as given in Table 1."
        },
        {
            "heading": "4.1. Data-based polynomial approximation",
            "text": "In Section 5, we will take a closer look at characterizations of the unknown nonlinear dynamics by data-based polynomial approximation. Polynomial approximation has been widely used to deal with nonlinear systems in control theory (Abudia et al., 2022) and in application, e.g., by Taylor linearization of the system dynamics. Thus, this data-based system representation is intuitive from a control perspective. Furthermore, a polynomial representation allows for the verification of system properties and for the design of controllers by SOS optimization. Moreover, a polynomial approximation does not require knowledge of a function basis containing the system dynamics. At the same time, the literature on polynomial interpolation (Sauer and Xu, 1995) provides well-investigated approximation errors. These are essential to infer a tight set membership for the nonlinear system from data and to provide guarantees.\nFor Taylor polynomials (TP), Martin and Allgo\u0308wer (2022a) verifies dissipativity properties, Martin and Allgo\u0308wer (2023b) determines incremental dissipativity, Guo et al. (2022b) derives locally asymptotically stabilizing controllers, and Martin et al. (2023a) obtains state-feedback laws to render an equilibrium globally asymptotically stable while satisfying closed-loop performance criteria. Since TPs commonly provide local approximations, Martin and Allgo\u0308wer (2023b) combines multiple TPs to refine the data-driven inference.\nIf the error of the polynomial approximation vanishes, then the special case of polynomial systems is obtained. Datadriven control for unknown polynomial systems using SOS relaxation include the verification of dissipativity (Martin and Allgo\u0308wer, 2021) and integral quadratic constraints (IQC) (Martin and Allgo\u0308wer, 2022b) and the controller synthesis (Guo et al., 2022a; Bisoffi et al., 2022; Dai and Sznaier, 2021b; Luppi et al., 2021; Zheng et al., 2023). Related to the polynomial case, Stra\u0308sser et al. (2021) considers the controller synthesis for rational systems. Related to the polynomial approximation by TPs, Berberich et al. (2022a); Nguyen et al. (2023); Cheah et al. (2023) investigate Lur\u2019e-type systems (Khalil, 2002) (Chapter 10.1) with a data-driven inference of the LTI part of the dynamics while assuming measurements and a known sector bound on the nonlinear part. Note that all these results excessively exploit techniques from robust control as linear fractional representation (LFR), Petersen\u2019s lemma, a matrix S-lemma (van Waarde et al., 2022), or Farkas\u2019 lemma to provide guarantees though the system dynamics is not precisely known.\nIn contrast to the previous set-membership approaches, De Persis and Tesi (2020) uses Taylor linearization to provide a data-driven representation of the linear part of the closed loop. Thereby, an equilibrium point can be rendered locally asymptotically stable by solving an optimization problem with LMI\n1Martin and Allgo\u0308wer (2021), Martin and Allgo\u0308wer (2022b), Guo et al. (2022a), Bisoffi et al. (2022), Dai and Sznaier (2021b), Luppi et al. (2021), Zheng et al. (2023), Stra\u0308sser et al. (2021), Berberich et al. (2022a), Nguyen et al. (2023), Cheah et al. (2023)\nconstraints. Moreover, the closed-loop characterization is extended to polynomial systems (Guo et al., 2022a), periodic orbits (Cetinkaya and Kishida, 2021), and Lur\u2019e-type systems (Luppi et al., 2022)."
        },
        {
            "heading": "4.2. Gaussian processes and kernel ridge regression",
            "text": "Gaussian processes (GP) and kernel ridge regression constitute a flexible framework to approximate nonlinear functions in machine learning and nonlinear dynamics in system identification. Both regression methods provide the possibility to include prior knowledge and inherent uncertainty measures to derive guarantees for data-driven control. However, the obtained system representation is often strongly nonlinear due to nonlinear kernel functions. To deal with this nonlinearity, Umlauft et al. (2018) presents a controller design by feedback linearization and Capone et al. (2022) by backstepping. Nonetheless, both require a certain structure of the system dynamics. Therefore, we will study in Section 6 the following three approaches to achieve a controller synthesis by SDPs.\nFiedler et al. (2021b) learns a linear sector for the nonlinear parts of the dynamics from a GP to apply linear robust control afterwards. To this end, Fiedler et al. (2021a) establishes a statistical bound between the underlying nonlinear dynamics and the mean function of the GP.\nInstead of bounding the mismatch of the kernel regression by a sector, Berkenkamp and Schoellig (2015) directly computes the Taylor linearization of the nonlinear GP-model around an equilibrium point for a linear robust controller design. Alternatively, Hu et al. (2023) suggests to stabilize the linear part of a kernel regression, while approximately cancelling its nonlinearity as in De Persis et al. (2022).\nDevonport et al. (2020) proposes to use polynomial kernels yielding a polynomial regression model and a polynomial sector for the approximation error. Thus, a system analysis and a controller design by SOS techniques are possible. Moreover, we will observe connections to the polynomial approximation approach shown in Section 5.1."
        },
        {
            "heading": "4.3. Embedding into linear parameter-varying systems",
            "text": "In Section 7, we will report data-driven system analysis and controller design for a nonlinear system by combining datadriven methods for linear parameter-varying (LPV) systems and embedding nonlinear systems into LPV systems. Thereby, this paradigm provides a data-driven system analysis and controller design by SDPs for nonlinear systems. In contrast to the local approximations by polynomials, LPV systems provide a global linearization of the nonlinear system. However, for the embedding, a known function basis of the scheduling map or the velocity-form of the underlying nonlinear system is required. The LPV representation of the nonlinear system is not tight as the scheduling parameter can change independently of the state and input.\nFor LPV systems, Verhoek et al. (2021a) introduces a fundamental lemma for verifying dissipativity properties (Verhoek et al., 2023b) and predictive control (Verhoek et al., 2021b). Moreover, Verhoek et al. (2022a) provides a representation of\nopen-loop and closed-loop LPV systems from noise-free trajectories. Miller and Sznaier (2023) and Mejari, et al. (2023) introduce a set-membership description for LPV systems from noisy data for the controller design with stability and performance guarantees based on SDPs.\nUnder the assumption that a function basis of the scheduling map is known, the unknown nonlinear dynamics can be written as an LPV system. Since the nonlinear dynamics is contained within the solution of the LPV system, Verhoek et al. (2022b) obtains a data-driven LPV controller that stabilizes the underlying nonlinear system. Alternatively, if the function basis of the velocity-form of a nonlinear system is known, then the velocityform can be embedded into the data-driven framework of LPV systems (Verhoek et al., 2023a).\nRelated to exploiting the extended linearization of a nonlinear system as in Verhoek et al. (2022b), the authors Dai and Sznaier (2021a) suggest to compute in each time instance a control policy for the frozen system matrices of the nonlinear extended linearization. Together with enforcing a decrease of the Lyapunov function along the closed-loop trajectory, the iterative scheme guarantees closed-loop stability by solving a finite set of LMIs in each time step. The inference on the extended linearization is obtained under a known function basis of the nonlinear dynamics and from data subject to noise."
        },
        {
            "heading": "4.4. Koopman lifting",
            "text": "The Koopman operator (Bevanda et al., 2021) provides an exact description of the nonlinear dynamics by a single, but infinite-dimensional, (bi-)linear system. To this end, the timeevolution of the states is observed through the lens of observables. By a finite dictionary of observables, a finite dimensional system representation is obtained from finite data using extended dynamics mode decomposition (EDMD). While the emerging estimation error is neglected in many existing results, we will focus in Section 8 on works incorporating this error. Thereby, a controller design with guarantees is achieved.\nCombined with the data-based validation of the estimation error, Zhang et al. (2022) provides a linear robust predictive control scheme with closed-loop guarantees. Stra\u0308sser et al. (2023a) considers a bilinear lifted system and determines a linear feedback of the lifted states that asymptotically stabilizes the nonlinear system. Moreover, a region of attraction w.r.t. the lifted state is guaranteed.\nMotivated by the bilinear model deduced from the lifting, we will shortly report the data-driven control approaches Bisoffi et al. (2020), Yuan and Corte\u0301s (2022), and Stra\u0308sser et al. (2023b) for bilinear systems with unknown system matrices."
        },
        {
            "heading": "4.5. Approximate nonlinearity cancellation and feedback linearization",
            "text": "Whereas the previous approaches derive a suitable representation of the system dynamics itself, nonlinearity cancellation and feedback linearization modify the dynamics by a state feedback to obtain an approximately linear system description. Since the feedback linearization includes an input transformation, the dynamics of the original and the transformed linear\nsystem differs. Hence, a data-driven system analysis by feedback linearization or nonlinearity cancellation is intrinsically not possible. For more details, we refer to Section 9.\nDe Persis et al. (2022) locally asymptotically stabilizes an equilibrium by approximately cancelling the nonlinearity of the closed-loop dynamics. To this end, the data-based closed-loop parametrization for LTI systems (De Persis and Tesi, 2020) is obtained for the linear part of the closed loop of a nonlinear system with known function basis. Subsequently, a controller that stabilizes the linear part of the closed-loop dynamics and minimizes the influence of the nonlinearity can be determined by an SDP.\nThe global feedback linearization of a flat system serves as the basis for an extension of Willems\u2019 fundamental lemma (Alsalti et al., 2021) under a known function basis for the input transformation. Alsalti et al. (2023a) relaxes this assumption by incorporating the error for an arbitrary choice of basis functions into data-driven simulation and output-matching control. Further, Alsalti et al. (2022) proposes a robust predictive control scheme for full-state feedback-linearizable nonlinear systems. However, all these results require nonlinear optimization."
        },
        {
            "heading": "5. Data-driven control by polynomial approximation",
            "text": "A polynomial system representation allows for a system analysis and controller design by SDPs via SOS techniques. Moreover, the well-elaborated error bounds for polynomial interpolation (Sauer and Xu, 1995) can be leveraged by robust control methods to ensure rigorous guarantees despite approximation of the nonlinear dynamics.\nAfter an elaboration of data-driven control based on polynomial interpolation techniques, works on polynomial, rational, and Lur\u2019e-type systems will be reported. Lastly, we will review a data-based closed-loop representation, which will also be leveraged in some of the later presented frameworks."
        },
        {
            "heading": "5.1. Data-driven control by polynomial interpolation",
            "text": "In the sequel, we present the data-driven set-membership approach for system analysis and controller design from Martin and Allgo\u0308wer (2023b), Martin and Allgo\u0308wer (2022a), and Martin et al. (2023a). There the feasible system set for nonlinear systems is derived by combining noisy data and error bounds for polynomial interpolation. Since the feasible system set is characterized by polynomial inequalities, the subsequent system analysis and state-feedback design boil down to SOS optimization problems.\nWe begin with some background on polynomial interpolation. By Taylor\u2019s theorem (Apostol, 1974), a k + 1 times continuously differentiable function f : Rnx \u2192 R can be written as f (x) = Tk(\u03c9)[ f (x)] + Rk(\u03c9)[ f (x)] with the TP of order k at \u03c9 \u2208 Rnx\nTk(\u03c9)[ f (x)] = k\u2211 |\u03b1|=0 1 \u03b1! \u2202|\u03b1| f (\u03c9) \u2202x\u03b1 (x \u2212 \u03c9)\u03b1 ,\nwith \u03b1! = \u03b11! \u00b7 \u00b7 \u00b7\u03b1nx !. Moreover, for all x \u2208 Rnx there exists a \u03bd \u2208 [0, 1] such that\nRk(\u03c9)[ f (x)] = \u2211 |\u03b1|=k+1 1 \u03b1! \u2202k+1 f (\u03c9 + \u03bd(x \u2212 \u03c9)) \u2202x\u03b1 (x \u2212 \u03c9)\u03b1 .\nSince \u03bd intrinsically depends on x, it summarizes the nonpolynomial nonlinearity of f . Furthermore, its value is typically unknown. Hence, Martin and Allgo\u0308wer (2022a) assumes an upper bound on the magnitude of the (k + 1)-th partial derivatives to avoid the computation of \u03bd.\nAssumption 1 (Martin and Allgo\u0308wer (2022a)). Upper bounds M\u03b1 \u2265 0, \u03b1 \u2208 Nnx0 , |\u03b1| = k + 1, on the magnitude of each (k + 1)-th order partial derivative of f are known, i.e.,\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2202k+1 f (x)\u2202x\u03b1 \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 2 \u2264 M\u03b1, \u2200x \u2208 Rnx .\nUnder Assumption 1, the Lagrange remainder Rk(\u03c9)[ f (x)] can be bounded by\n(Rk(\u03c9)[ f (x)])2 \u2264 \u2211 |\u03b1|=k+1 \u03ba M2\u03b1 \u03b1!2 (x \u2212 \u03c9)2\u03b1 , (3)\nwhere \u03ba \u2208 N0 is equal to the number of M\u03b1 , 0. Since the right-hand side of (3) does not depend on \u03bd, we conclude that f is contained in the polynomial characterized sector\nf (x) \u2208 Tk(\u03c9)[ f (x)] + R(x) : R2(x) \u2264 \u2211|\u03b1|=k+1 \u03ba M2\u03b1 \u03b1!2 (x \u2212 \u03c9)2\u03b1  . (4)\nWhile the investigation of the approximation error for polynomial interpolation is well-studied, Martin and Allgo\u0308wer (2022a) proposes their application to infer on the interpolation polynomial from noisy data. For that purpose, let noisy samples {yi, xi}Si=1 with yi = f (xi) + di be available. The unknown noise realizations di satisfy d2i \u2264 \u03f52. Furthermore, let the TP be written as z(x)T a\u2217, where a\u2217 \u2208 Rnz summarizes the unknown coefficients of the interpolation polynomial and z(x) \u2208 R[x]nz is a vector of linear independent polynomials building a basis for all polynomials with degree less than or equal to k. For instance, z could contain all monomials up to degree k. Following a set-membership procedure (Milanese and Novara, 2004), we characterize all coefficients a \u2208 Rnz admissible with the data\n{a : \u2203di \u2208 R, i = 1, . . . , S , satisfying d2i \u2264 \u03f52 and yi = z(xi)T a + Rk(\u03c9)[ f (xi)] + di}. (5)\nNote that (5) includes the coefficients of the true interpolation polynomial a\u2217. Furthermore, since the remainder evaluated at the data are unknown, Martin and Allgo\u0308wer (2022a) (Lemma 2) calculates a superset of (5) based on the error bounds for TPs (3) , denoted by R\u0304poly[ f (xi)],\n\u03a3a = { a : (yi \u2212 z(xi)T a)2 \u2264 q(yi, xi), i = 1, . . . , S }\nwith q(yi, xi) = R\u0304poly[ f (xi)]+\u03f52+2\u03f5 \u221a\nR\u0304poly[ f (xi)]. Finally, combining the polynomial sector bound for TPs (4) with \u03a3a leads to a set membership for the unknown nonlinear function\nf (x) \u2208 { z(x)T a + R(x) : a \u2208 \u03a3a,R(x)2 \u2264 R\u0304poly[ f (x)] } . (6)\nBy the latter, we obtain for the nonlinear function f a representation that is based on noisy data, is polynomial, and does not require a function basis of f .\nBefore we continue with the application of the feasible system set (6) for data-driven system analysis and control, some comments are appropriate. By Assumption 1, the rate of variation of the nonlinear function f is bounded. Therefore, we can infer the behavior of f in the neighbourhood of a sample. A similar causality of the behavior of f and samples is, e.g., also considered in set-membership identification (Milanese and Novara, 2004) by a known Lipschitz constant. Since the bounds M\u03b1 are usually not known, we refer to Martin and Allgo\u0308wer (2023b) for their estimation by a validation procedure and the applicability for data from a real experiment.\nMoreover, Martin and Allgo\u0308wer (2023b) discusses the choice of \u03c9 and a combining of multiple local polynomial interpolations, i.e., a piecewise polynomial approximation, to reduce the approximation error. To reduce the computation burden, Martin and Allgo\u0308wer (2022a) (Proposition 1) suggests to compute the ellipsoidal outer approximationa : [ I aT ]T Q [ I aT ] \u2aaf 0\n (7) of \u03a3a. Furthermore, Martin et al. (2023a) investigates a Frequentist and Bayesian treatment for Gaussian distributed di, following the lines of Umenberger et al. (2019).\nNext, we show how to verify system properties for a general nonlinear system by the derived set membership (6). For that purpose, Martin and Allgo\u0308wer (2022a) analyzes an unknown nonlinear continuous-time system\nx\u0307(t) = f (x(t), u(t))\nwith k + 1 times continuously differentiable function f =[ f1 \u00b7 \u00b7 \u00b7 fnx ] : Rnx+nu \u2192 Rnx and noisy data {x\u0307i, xi, ui}Si=1 with x\u0307i = f (xi, ui) + di. Note that di might include estimation errors of the time-derivatives of the states. Applying a polynomial interpolation for each element of f yields\nf (x, u) =  z1(x, u)T a\u22171 + R[ f1(x, u)]\n... znx (x, u) T a\u2217nx + R[ fnx (x, u)]  =  z1(x, u)T S 1\n... znx (x, u) T S nx \ufe38 \ufe37\ufe37 \ufe38 =:Z(x,u) a\u2217 +  R[ f1(x, u)] ... R[ fnx (x, u)] \ufe38 \ufe37\ufe37 \ufe38 =:R[ f (x,u)] ,\nwith a\u2217i = S ia \u2217, and R[ f (x, u)]T R[ f (x, u)] \u2264 \u2211nxi=1 R\u0304poly[ fi(x, u)]. As shown in Martin and Allgo\u0308wer (2023b) (Remark 2) and\nMartin et al. (2023a), summarizing all unknown coefficients of the polynomial interpolations into a\u2217 and considering zi for each row of f can be leveraged to include interpolation polynomials of different orders and prior knowledge on the structure of f .\nFor the available data {x\u0307i, xi, ui}Si=1, we pursue the described derivation of \u03a3a to conclude that f (x, u) is contained in the feasible system setZ(x, u)T a + R(x, u) : a \u2208 \u03a3a,\nR(x, u)T R(x, u) \u2264 nx\u2211 i=1 R\u0304poly[ fi(x, u)]  . (8)\nGiven the quadratic description (7) for \u03a3a, the feasible system set can also be written as an LFR (Scherer and Weiland, 2000)\n[ x\u0307(t) q(t) ] =  0 0 I I[I0 ] [ 0 I ] 0 0   x(t) u(t)\nw1(t) w2(t)  , w1(t) = Z(q(t))T a,w2(t) = R(q(t)),\nwith w2(t)T w2(t) \u2264 \u2211nx\ni=1 R\u0304 poly[ fi(q(t))] and[\nS Ti zi(q(t)) w1,i(t)\n]T Q [ S Ti zi(q(t))\nw1,i(t)\n] \u2264 0,\nfor w1 = [ w1,1 \u00b7 \u00b7 \u00b7 w1,nx ]T .\nAlthough the uncertainty descriptions of w1 and w2 are polynomial in q, we can apply the LMI-based robust control framework of Scherer and Weiland (2000) to verify system properties for all systems within the set membership (8). If all systems satisfy a certain property, then also the ground-truth system fulfils the property as it is contained within (8). Due to the polynomial bounds on the uncertainties w1 and w2, the verification boils down to an SOS condition. By an additional S-procedure, Martin and Allgo\u0308wer (2022a) and Martin and Allgo\u0308wer (2023b) verify dissipativity and incremental dissipativity properties, respectively, for all trajectories of the unknown nonlinear system staying within a compact set. A regional analysis is meaningful due to the non-global inferences on the dynamics from data. Moreover, the results from Martin and Allgo\u0308wer (2022b) (arXiv:2103.10306v3, Section 5.B) can be applied here to determine optimal IQCs to gather tighter system properties than by simple dissipativity properties.\nMartin et al. (2023a) elaborates the set membership (8) with a TP at \u03c9 = 0 for each row of an input-affine nonlinear system. Following the robust control framework of Scherer and Weiland (2000), Theorem 8 of Martin et al. (2023a) formulates the conditions for data-driven dissipativity verification in the dual space. Thereby, a state-feedback design by SOS optimization with quadratic performance guarantees is possible. In contrast to the TP approach from Guo et al. (2022b), the authors Martin et al. (2023a) incorporate the remainder of polynomial interpolation into the controller synthesis to obtain globally asymptotically stabilizing controllers.\nFigure 2 summarizes the data-driven system analysis and control by polynomial interpolation. While this framework seems to be flexible, we also identify some open questions and problems. Among others, the impact of the chosen polynomial basis for z1, . . . , znx should be analysed. Here, the basis should be optimized for the controller design. Hence, the basis is ideally optimized during the controller synthesis. Since the the presented procedure can also be applied for more general polynomial interpolations, e.g., Hermite polynomials (Sauer and Xu, 1995), this investigation might reduce the conservatism by means of more regional polynomial approximations."
        },
        {
            "heading": "5.2. Polynomial, rational, and Lur\u2019e-type systems",
            "text": "We summarize in the following the data-driven setmembership approaches for polynomial, rational, and Lur\u2019etype systems. These classes of nonlinear systems are strongly related to the system representation by polynomial interpolation as shown in Figure 3. Polynomial systems comprises, for example, fluid dynamics (Chernyshenko et al., 2014) and robotics (Majumdar, 2013), whereas rational dynamics, e.g., biochemical reactors (Strogatz, 2014). Lur\u2019e systems (Khalil, 2002) (Chapter 10.1) are LTI systems including a sector bounded nonlinearity, and thus can comprise exemplarily Lipschitz bounded nonlinearities and recurrent neural networks (Luppi et al., 2022).\nThe literature on data-driven system analysis and control for polynomial systems mostly studies a continuous-time system with polynomial dynamics x\u0307(t) = Az(x(t), u(t)) or input-affine polynomial dynamics x\u0307(t) = Az\u0304(x(t)) + BW(x(t))u(t), respectively. While the coefficient matrices A \u2208 Rnx\u00d7nz and B \u2208 Rnx\u00d7nB\nare unknown, a set of data {x\u0307i, xi, ui}Si=1 is available and a vector z \u2208 R[x, u]nz or a vector z\u0304 \u2208 R[x]nz and a polynomial matrix W \u2208 R[x]nB\u00d7nu , respectively, are known. The latter can be satisfied from knowledge of an upper bound on the degree of the polynomial dynamics.\nClearly, considering polynomial systems generalizes the results for LTI systems (van Waarde et al., 2022; Koch et al., 2022). On the other hand, the polynomial problem setup is included in the data-driven framework of polynomial interpolation in Section 5.1: For vanishing approximation error R\u0304poly[ f (x, u)] = 0, we can proceed as in Section 5.1 to derive a set membership for the unidentified coefficients and, subsequently, to verify system properties and to design a state feedback. Hence, we directly report the examined data-driven control problems for polynomial systems.\nBased on SOS optimization, Martin and Allgo\u0308wer (2021) and Martin and Allgo\u0308wer (2022b) investigate the verification of dissipativity and more general time domain hard IQCs with optimized linear filter, respectively. Whereas most model-based and data-driven results, which are based on SOS optimization, consider continuous-time systems, Martin and Allgo\u0308wer (2021) and Martin and Allgo\u0308wer (2022b) investigate discrete-time polynomial systems. Thereby, the data of the time-derivative of the states are avoided. This advantage comes at the cost of being restricted to quadratic storage functions (Martin and Allgo\u0308wer, 2022b) or polynomials of higher degree due to the function decomposition V( f (x, u)) with a polynomial storage function V(x). Moreover, polynomial discrete-time systems often require a regional analysis because a time discretization of a globally asymptotically stable system can lead to a locally asymptotically stable discrete-time system. For instance, the Euler time discretization with time step T > 0 of x\u0307 = \u2212x3 yields x(t+1) = x(t)\u2212T x(t)3. However, the state of the discretized system tends to infinity for any initial condition ||x(0)||2 > \u221a 2/T .\nFurthermore, data-driven controller design for global stabilization for continuous-time polynomial systems is examined: Guo et al. (2022a) derives a polynomial state feedback from data solving a single SOS condition. To this end, an energybounded noise of the data immediately leads to a set membership for the unknown coefficient matrices, which can be exploited by means of the non-conservative S-lemma from van Waarde et al. (2022). The same control problem for pointwisein-time-bounded noise is solved in Bisoffi et al. (2022) by the non-conservative Petersen\u2019s lemma and an ellipsoidal outer approximation of the set of coefficients consistent with the data. However, the controller design requires alternating SOS optimization due to the bilinearity of optimization variables. Dai and Sznaier (2021b) proposes a rational state feedback by relating the feasible system set with the set of systems with converging trajectories via Farkas\u2019 lemma. Therefore, the weaker stability of Rantzer\u2019s dual Lyapunov theory (Rantzer, 2001) is considered. Farkas\u2019 lemma leads to a condition that can be relaxed to an SDP by SOS relaxation and the nuclear norm relaxation for rank conditions. Summarized, the literature on data-driven state-feedback design considers a variety of robust control techniques to stabilize all systems consistent with the data. However, we assess the robust control framework by\nLFRs (Scherer and Weiland, 2000) to constitute one of the most appealing ones. In particular, it can also be applied for polynomial problems and leads to SDPs despite multiple uncertainty channels and performance criteria.\nIn contrast to global stabilization, Luppi et al. (2021) and Zheng et al. (2023) investigate the control of unknown polynomial systems including safety conditions rather than stability conditions. To this end, Luppi et al. (2021) optimizes over a polynomial state-feedback law to enlarge the size of an invariant set. The feasible system set is incorporated into the invariance condition by Young\u2019s relation (Caverly and Forbes, 2019). But in fact, as in the model-based case, the derived invariance conditions are bilinear, and thus have to be solved by alternating SOS optimization. To circumvent the nonconvexity, Zheng et al. (2023) proposes a density function formulation based on the dual Lyapunov method (Rantzer, 2001) and to proceed along the lines of Dai and Sznaier (2021b). The obtained rational state feedback keeps the closed-loop trajectories of all polynomial systems admissible with the data outside of an unsafe set.\nInstead of polynomial systems, Stra\u0308sser et al. (2021) presents a data-driven feedback design for continuous-time rational systems. Multiplication of the rational dynamics by all denominators of the dynamics yields a problem formulation akin to that in the polynomial case. However, the problem emerges that the additive noise does not affect the data through the original rational dynamics but the polynomial reformulation. The remaining procedure follows a set-membership approach combined with robust control techniques from Scherer and Weiland (2000). Thereby, a state feedback is designed with stability and performance guarantees by solving an SOS problem.\nRelated to a linear TP with bounded Lagrange remainder, the Lur\u2019e problem considers an LTI system with a sector bounded nonlinearity. In a data-driven context, Berberich et al. (2022a) proposes a flexible multiplier LMI-framework to combine data, prior information on the LTI system, and bounded and measurable nonlinearities. To obtain a feasible system set for the LTI system with sector bounded and measurable nonlinearity, Nguyen et al. (2023) solves an optimal control problem from MPC with state and input constraints by application of the Slemma from van Waarde et al. (2022). Cheah et al. (2023) solves a similar problem by Young\u2019s relation."
        },
        {
            "heading": "5.3. A data-driven closed-loop characterization",
            "text": "De Persis and Tesi (2020) examines besides the data-driven stabilization of LTI systems also the nonlinear case. In contrast to the set-membership approaches of Section 5.1 and 5.2, De Persis and Tesi (2020) proposes to directly characterize the closed loop by data matrices. This result has also inspired further works reported, among others, in this section.\nDe Persis and Tesi (2020) (Section 5.2) considers the stabilization of an unknown nonlinear discrete-time system x(t+1) = f (x(t), u(t)). To apply their results from LTI systems, the authors propose a Taylor linearization around the known equilib-\nrium point (xe, ue) = (0, 0). This leads to the linearized system dynamics\nx(t + 1) = Ax(t) + Bu(t) + d(t), (9)\nwith A = \u2202 f (0,0) \u2202x , B = \u2202 f (0,0) \u2202u , and remainder d. Clearly, (9) corresponds to the TP approximation from Section 5.1 for k = 1 and\u03c9 = 0. For data {xi, ui}Si=1 satisfying xi+1 = Axi+Bui+di, De Persis and Tesi (2020) defines the data-dependent matrices X =[ x1 \u00b7 \u00b7 \u00b7 xS\u22121 ] , U = [ u1 \u00b7 \u00b7 \u00b7 uS\u22121 ] , X+ = [ x2 \u00b7 \u00b7 \u00b7 xS ] ,\nand D = [ d1 \u00b7 \u00b7 \u00b7 dS\u22121 ] .\nAssumption 2 (De Persis and Tesi (2020) (Assumption 5)). Let a constant M > 0 with DDT \u2aaf MX+X+T be known.\nAssumption 2 cumulatively bounds the whole sequence of the remainder d1, . . . , dS\u22121 by a single constraint, rather than for each realization di separately as in Section 5.1. Furthermore, in contrast to the quadratically increasing bound of the Lagrange remainder (3), Assumption 2 supposes a bound on the remainder that increases linearly. Nevertheless, M of Assumption 2 corresponds to similar insights as M\u03b1 in Assumption 1.\nFor deriving a stabilizing linear state feedback u = Kx, observe that the data matrices satisfy X+ = AX + BU + D. Hence, the linear part of the closed-loop dynamics can be characterized based on the data matrices\nA + BK = [ A B ] [ I K ] = [ A B ] [X U ] G = (X+ \u2212 D)G, (10)\nwith G satisfying [ I K ] = [ X U ] G. (11)\nThe persistence of excitation (PE) condition that [ X U ] has full row rank (De Persis and Tesi, 2020) (Assumption 4) guarantees that G always exists. Note that a data-based description of the closed-loop dynamics can also be retrieved by the relationship[ A B ] = (X+ \u2212 D) [ X U ]\u2020 , which corresponds to G = [ X U ]\u2020 [ I K ] . Instead of one specific G, the closed-loop description (10) with consistency condition (11) provides for a fixed K a whole subspace in terms of G. Hence, optimizing over G typically results in non-unique solutions. As shown in Do\u0308rfler et al. (2022), it is advantageous to regularize G to single out solutions that are robust regarding noise.\nAlong Theorem 6 of De Persis and Tesi (2020), the origin of the nonlinear system is asymptotically stable if the linear part of the closed loop (10) is asymptotically stable, i.e., if there exists a Lyapunov matrix P \u227b 0 and matrix G such that\n(A+BK)P(A+BK)T \u2212P = ((X+\u2212D)G)P((X+\u2212D)G)T \u2212P \u227a 0.\nSince the remainder matrix D is unknown, Theorem 5 of De Persis and Tesi (2020) uses Young\u2019s relation (Caverly and Forbes, 2019) to ensure by an SDP that this stability condition holds for all D satisfying Assumption 2. By optimizing over P and G, the state-feedback matrix K can be recovered from (11).\nDe Persis and Tesi (2020) describes the uncertainty from the unknown remainder directly by the matrix D. Thereby, De Persis and Tesi (2020) obtains a parametrization G of the to-be-optimized controller that increases with the number of data. In contrast, the set-membership approach in Section 5.1 translates the uncertain remainder into an uncertainty of the coefficients of the TP. This leads to a controller design that does not scale with the number of samples. Moreover, incorporating the remainder of the TP approximation into the controller synthesis (Martin et al., 2023a) enables a global stabilization. Throughout this article, we will see further results based on a set-membership procedure or the closed-loop characterization from De Persis and Tesi (2020) exhibiting similar properties.\nSome of the data-based results for nonlinear systems inspired by De Persis and Tesi (2020) are mentioned next. Guo et al. (2022a) includes an extension for polynomial systems. De Persis and Tesi (2021) proposes an experiment design by scaled input sequences to ensure Assumption 2 and the PE condition for the data from a nonlinear system. Furthermore, Cetinkaya and Kishida (2021) stabilizes a periodic orbit using a Pyragastype control law and a system representation for the periodic time-evolution of the states. While the to-be-stabilized orbit becomes an equilibrium of the periodic system description, Cetinkaya and Kishida (2021) also solves the problem when the orbit is not precisely known. Luppi et al. (2022) stabilizes Lur\u2019e-type systems x(t + 1) = Ax(t) + B(u(t)) + f (t, x(t)) using SDPs with LMI constraints. To this end, a quadratic constraint and samples of the nonlinearity f need to be known, analogously to the approaches for Lur\u2019e systems mentioned in Section 5.2.\nAlthough not directly related to the presented closed-loop representation of De Persis and Tesi (2020), we would also like to mention Berberich et al. (2022b). The authors also use a data-based inference on the behavior of the affine Taylor linearization, but in the context of predictive control. To this end, online updated data is combined with the fundamental lemma of Willems et al. (2005) to obtain a data-driven system parametrization of the nonlinear system in the neighbourhood of the current state. Thereby, the MPC scheme boils down to solving a convex quadratic program in each time instance."
        },
        {
            "heading": "6. GP and kernel ridge regression for data-driven control",
            "text": "GP and kernel ridge regression constitute well-established techniques in machine learning to approximate a nonlinear function from data and to predict its outputs for unseen inputs (Rasmussen and Williams, 2006) and (Bishop, 2006) (Section 6). Both regression methods are equipped with an uncertainty measure given by an upper bound for their approximation error. However, the regression solution and its error bound are usually nonlinear due to the nonlinear kernel functions. For that reason, the research direction, reported in this section, tackles the challenge to identify a representation of the regression that is suitable for system analysis and controller synthesis using SDPs. Thereby, these data-based methods can be leveraged for\na wide range of control problems compared to the specific control schemes, e.g., using GP models with feedback linearization (Helwa et al., 2019) and (Lederer et al., 2019)."
        },
        {
            "heading": "6.1. Kernel ridge regression",
            "text": "For kernel ridge regression, we first introduce the notion of kernel functions and their reproducing kernel Hilbert space (RKHS) to efficiently solve the following infinite-dimensional regression problem: For an unknown nonlinear function f : X \u2286 Rnx \u2192 R, let the data points {yi, xi}Si=1 with yi = f (xi) be available. Then, we want to find the solution of\nmin \u00b5\u2208H S\u2211 i=1 (yi \u2212 \u00b5(xi))2 + \u03bb ||\u00b5||2H , (12)\nwhere \u03bb > 0 is a regularization parameter, H a real Hilbert space of functions \u00b5 : X\u2192 R, and || \u00b7 ||H the associated function norm, i.e., ||\u00b5||H = \u221a \u27e8\u00b5, \u00b5\u27e9H .\nTo solve this least-squares-error (LSE) problem, let a function k : X \u00d7 X \u2192 R be a kernel if it is symmetric k(x, x\u2032) = k(x\u2032, x) for all x, x\u2032 \u2208 X and positive definite, i.e.,\u2211n\ni, j=1 \u03b1i\u03b1 jk(xi, x j) \u2265 0 for all n \u2208 N, x1, . . . , xn \u2208 X, and \u03b11, . . . , \u03b1n \u2208 R (Steinwart and Christmann, 2008) (Theorem 4.16). Kernels naturally emerge in finite dimensional linear regression problems and allow a computationally efficient evaluation. Indeed, the solution of a linear regression includes the evaluation of the scalar product of the feature mapping Z(x) : X \u2192 Rn f , with often large n f . At the same time, there exists for many Z(x) a kernel k such that k(x, x\u2032) = Z(x)T Z(x\u2032) (Steinwart and Christmann, 2008) (Definition 4.1).\nThe special class of reproducing kernels and their associated RKHS will be crucial to solve (12). According to Steinwart and Christmann (2008) (Def. 4.18), a kernel k : X \u00d7 X \u2192 R is a reproducing kernel of a real Hilbert space H of functions f : X \u2192 R if k(x, \u00b7) \u2208 H and f (x) = \u27e8 f , k(x, \u00b7)\u27e9H for all x \u2208 X and f \u2208 H . The Hilbert spaceH is called RKHS of kernel k.\nIn the sequel, let a kernel k and its RKHSH be given and the following assumption be satisfied.\nAssumption 3 (Maddalena et al. (2021)). Let f \u2208 H and let an upper bound M on || f ||H be known. Under Assumption 3, the regression problem (12) is called kernel ridge regression and the representer theorem (Kanagawa et al., 2018) (Theorem 3.4) provides its explicit solution\n\u00b5(x) = yX(\u03bbI + KX)\u22121K(x) \u2208 H , (13) with yX = [ y1 \u00b7 \u00b7 \u00b7 yS ] , K(x) = [ k(x, x1) \u00b7 \u00b7 \u00b7 k(x, xS ) ]T , and Gram matrix KX , i.e., its (i, j)-th element corresponds to k(xi, x j). Furthermore, Hu et al. (2023) derives the following approximation error\n|| f (x) \u2212 \u00b5(x)||2 \u2264 M \u221a k(x, x) \u2212 K(x)T K\u0302\u22121X K(x),\nfor all x \u2208 X and with K\u0302X = (\u03bbI + KX)(2\u03bbI + KX)\u22121(\u03bbI + KX). Thus, we obtain the set membership\nf (x) \u2208 \u03a3ker = { \u00b5(x) + R(x) : \u00b5(x) = yX(\u03bbI + KX)\u22121K(x)\nand R(x)2 \u2264 M2(k(x, x) \u2212 K(x)T K\u0302\u22121X K(x)) } . (14)\nBy (14), we can conclude that the unknown function f is contained within a sector with centre \u00b5(x) and width\nM \u221a\nk(x, x) \u2212 K(x)T K\u0302\u22121X K(x). In contrast to the set membership (6) from polynomial approximation, the description of \u03a3ker is usually nonlinear as the kernel k is typically nonlinear, for example, compare the list of kernels in Section 2.1 of Kanagawa et al. (2018). Hence, a direct application of \u03a3ker for a system analysis or a controller design by SDPs is not possible. Furthermore, Assumption 3 requires a bound on the norm associated to the kernel of the nonlinear function, while Assumption 1 a bound on high order partial derivatives. Both insights enable one to bound the difference between the nonlinear function and the approximation by the kernel regression or the polynomial interpolation. With the approximation error for f < H from Fiedler et al. (2021a), both approaches do not require knowledge of a function basis of the underlying nonlinear function. A data-driven inference on Assumption 3 is examined in Scharnhorst et al. (2023). Moreover, an approximation error for noisy data is investigated in Maddalena et al. (2021). Finally, since the kernel and the functions of its RKHS can share desired properties (Jidling et al., 2017), prior knowledge on f can be included to reduce conservatism and improve the data efficiency."
        },
        {
            "heading": "6.2. GP regression",
            "text": "GP regression is another non-parametric regression method to infer an unknown nonlinear function by refining a prior belief by a set of noisy data. Hence, GP regression is a Bayesian method, where the underlying data generation is not drawn from a fixed function (Frequentist statistics) but from a stochastic process F , i.e., a distribution over functions.\nIn the sequel, let a random vector X that is Gaussian distributed with mean \u00b5 and covariance matrix \u039e \u227b 0 be denoted by X \u223c N(\u00b5,\u039e). A GP is a collection of random variables such that any finite subset is Gaussian distributed (Rasmussen and Williams, 2006). This specific stochastic process is uniquely defined by its mean function m : X\u2192 R and its covariance kernel k(x, x\u2032). If the prior distribution F is a GP with zero mean and covariance k and the data {yi, xi}Si=1 with yi = F (xi) + di and independently identically distributed (iid) di \u223c N(0, \u03c32) is available, then the posterior Fpost is again a GP with mean\n\u00b5post(x) = yX(\u03c32I + KX)\u22121K(x) (15)\nand covariance\nkpost(x, x\u2032) = k(x, x\u2032) \u2212 yX(\u03c32I + KX)\u22121K(x) (16)\n(Rasmussen and Williams, 2006). Here yX ,KX , and K(x) are defined as for the kernel ridge regression. Thus, the kernel ridge regression solution (13) is the same as the posterior mean. Intuitively, for large regularization parameters \u03bb or large noise variance \u03c32, the regression loosely fits the samples or does not trust the data, respectively. For more details on the connections between GP and kernel ridge regression, we refer to Kanagawa et al. (2018). Moreover, the posterior variance kpost(x, x) measures the uncertainty of the inference on the data-generating distribution F .\nIn the context of robust control, the ground truth dynamics might not be a stochastic process F but a function f : X \u2192 R. Since the posterior mean and covariance are obtained from Bayesian methods, a Frequentist bound on f can not be derived directly from the previous Bayesian treatment. To infer a Frequentist bound, let data {yi, xi}Si=1 with yi = f (xi)+ di and iid di \u223c N(0, \u03c32) be given. Then we can rely on Assumption 3 to compute a bound on the approximation error of the form\nPr ( || f (x) \u2212 \u00b5post(x)||2 \u2264 \u03b2 \u221a kpost(x, x),\u2200x \u2208 X ) \u2265 1 \u2212 \u03b4, (17)\nwith confidence \u03b4 \u2208 (0, 1), posterior mean \u00b5post (15), posterior variance kpost (16), and where Pr(E) denotes the probability of an event E. For the scalar \u03b2, Fiedler et al. (2021a) (Theorem 1) proposes \u03b2 = M + R \u221a log(det(\u03c32I + KX)) \u2212 2log(\u03b4) and Chowdhury and Gopalan (2017) (Theorem 2) \u03b2 = M + R \u221a 2(\u03b3 + 1 + ln(1/\u03b4)). However, the latter requires the rather difficult calculation of the maximum information gain \u03b3, and thus often calls for heuristic upper bounds. The error bound in (17) yields the following stochastic set membership\nf (x) \u2208 \u03a3GP = {\u00b5(x) + R(x) : \u00b5(x) = \u00b5post(x) and R(x)2 \u2264 \u03b22kpost(x, x)},\n(18)\nwith probability 1 \u2212 \u03b4. Due to the nonlinear kernel function k, the set membership \u03a3GP includes nonlinear functions as in \u03a3ker. For that reason, Umlauft et al. (2018) proposes a feedback linearization to stabilize the input-affine system x\u0307 = f (x)+G(x)u with a GP model for f (x). The controller design requires a perfectly known and invertible input matrix G(x). Moreover, a control Lyapunov function musts be calculated to establish stability guarantees, which requires the computationally complex solution of a dynamic program. Similarly, Capone et al. (2022) calls for perfect knowledge of G(x) and specific structure of the nonlinear dynamics f (x) as common for backstepping control (Khalil, 2002) (Section 13.2). Following a robust backstepping procedure, stability of the closed loop can be guaranteed from the GP inference on f (x). Furthermore, Berkenkamp et al. (2016) proposes to directly study the time-derivative of a Lyapunov function for analysing the region of attraction of a stable closed loop. Indeed, the time-derivative of a Lyapunov function for a GP model of the dynamics is again a GP. Due to the impossible evaluation of the confidence intervals of this GP, a discretization of the state space and an over-estimation by Lipschitz continuity are required, which prevent an extension to a controller synthesis. Lastly, Romer et al. (2019) verifies a bound on the L2-gain and passivity properties via optimizing over a confidence region inferred from a GP.\nSince all these approaches require nonlinear optimization or a specific system dynamics, we present three approaches to tackle the nonlinearity of the kernel such that a system analysis and controller design by SDPs are possible."
        },
        {
            "heading": "6.3. Learning linear sectors from GPs",
            "text": "Fiedler et al. (2021b) suggests to linearly bound the Frequentist approximation error (17). Thereby, the nonlinear dynamics\nis represented by a linear system with linearly bounded uncertainty as common for system analysis and controller design by linear robust control techniques.\nFor a nonlinear unknown part \u03d5 : [a, b] \u2192 R of a dynamics, Fiedler et al. (2021b) considers the sector\n\u03ba1x2 \u2264 x\u03d5(x) \u2264 \u03ba2x2, (19)\nas common, for instance, for Lure\u2019s problem. According to the set membership \u03a3GP for \u03d5(x) and Fiedler et al. (2021b) (Lemma 2), \u03d5(x) belongs with probability at least 1\u2212 \u03b4 to the sector (19) with\n\u03ba1 = min x\u2208[a,b]\\0\n\u03be x2 , \u03ba2 = max x\u2208[a,b]\\0 \u03be x2 , (20)\n\u03be = min { x(\u00b5post(x) + \u03b2 \u221a kpost(x, x)), x(\u00b5post(x) \u2212 \u03b2 \u221a kpost(x, x)) } . Intuitively, Lemma 2 of Fiedler et al. (2021b) determines two linear functions \u03ba1x and \u03ba2x that under and over approximate the nonlinear boundaries \u00b5post(x) \u2212 \u03b2 \u221a kpost(x, x) and\n\u00b5post(x)+\u03b2 \u221a\nkpost(x, x), respectively. Thereby, \u03d5(x) is contained within the set {\u03bax : \u03ba1 \u2264 \u03ba \u2264 \u03ba2}. Note that this result requires \u03d5 to satisfy Assumption 3, i.e., \u03d5 is an element of the RKHS of the kernel of the GP and an upper bound of the norm of \u03d5 associated to the RKHS is known. Moreover, the computation of \u03ba1, \u03ba2 includes a nonlinear optimization problem, which might be complex for multivariate \u03d5 : Rn \u2192 R.\nWe refer to Fiedler et al. (2021b) for the application of the linear sector (19) for a linear state-feedback design with quadratic performance using LFRs and SDPs. Note that also other control problems can be solved based on this LFR description.\nThe presented concept is comparable with the polynomial representation from Section 5.1 because both determine a suitable sector around the nonlinearity. However, Martin and Allgo\u0308wer (2022a) directly determines a polynomial sector of the dynamics instead of the inference of a learning method. Therefore, depending on the nonlinearity of the learning method, the linear sector (19) might be more conservative than actually necessary for the nonlinear dynamics. For instance, the shape of \u00b5post(x)\u00b1\u03b2 \u221a kpost(x, x) strongly depends on the chosen kernel function and its hyperparameters. Moreover, whereas Martin and Allgo\u0308wer (2023b) computes the sector by an SDP, (20) requires to solve a nonlinear optimization problem."
        },
        {
            "heading": "6.4. Data-driven control by linearized kernels",
            "text": "Berkenkamp and Schoellig (2015) linearizes the posterior mean (15) and covariance (16) around an equilibrium for a linear robust controller design. Therefore, Berkenkamp and Schoellig (2015) considers a Bayesian rather than a Frequentist treatment as in Fiedler et al. (2021b). Furthermore, we analyze the stabilization of an unknown nonlinear system by nonlinearity cancellation as proposed by Hu et al. (2023).\nSimilar to Section 6.3, Berkenkamp and Schoellig (2015) presents a robust controller design by an LFR, but of the linearized nonlinear dynamics of x(t + 1) = f (x(t), u(t)), deduced from a GP. Since the derivative of a GP is again a GP, Berkenkamp and Schoellig (2015) infers the Jacobian matrix\nof f (x, u) = [ f1(x, u) \u00b7 \u00b7 \u00b7 fnx (x, u) ]T around an equilibrium\npoint \u03bee = [ xTe u T e ]T by\n\u2202 fi \u2202\u03be \u2223\u2223\u2223\u2223\u2223\u2223 \u03bee \u223c N (\u00b5\u2032i(\u03bee),\u039e\u2032i(\u03bee)) . (21) The posterior mean function \u00b5\u2032i(\u03bee) and the covariance matrix \u039e\u2032i(\u03bee) can be found in Berkenkamp and Schoellig (2015) (equation (10) and (11)). Thus, Berkenkamp and Schoellig (2015) can conclude on a probabilistic set membership for the Jacobian matrix \u2202 f\n\u2202\u03be \u2223\u2223\u2223\u2223 \u03bee . We refer to equations (17)-(21) in Berkenkamp\nand Schoellig (2015) for an LFR for the linearized dynamics and to Theorem 1 in Berkenkamp and Schoellig (2015) for a robust linear state-feedback synthesis with H2 performance by solving an SDP with LMI constraints. Moreover, Berkenkamp and Schoellig (2015) suggests possible extensions by learning the operating point \u03bee from the learned GP of \u03a6, updating the GP by additional data to improve the control performance, not full state measurements, and tracking control.\nWe emphasize that Berkenkamp and Schoellig (2015) elaborates a Bayesian inference on the system dynamics, and therefore the data-generating f (x, u) is a sample from a GP. Since the controller from Berkenkamp and Schoellig (2015) (Theorem 1) robustly asymptotically stabilizes the set membership of the Jacobian matrix, the controller asymptotically stabilizes the nonlinear system if its Jacobian matrix sampled from (21) is contained within this set. But in fact, no guarantees regarding the region of attraction and the performance of the closed loop can be deduced because the high order nonlinearities are neglected for the synthesis. Contrary, Fiedler et al. (2021b) incorporates the nonlinearity within the synthesis, and thereby can, e.g., guarantee closed-loop performance and a region of attraction. For that reason, the procedure of Berkenkamp and Schoellig (2015) is not suitable for determining dissipativity properties. Furthermore, instead of deriving an inference on the Jacobian linearization by first learning a GP, one could also directly receive the Jacobian from data following the polynomial approximation in Section 5.1 for a TP with \u03c9 = \u03bee and k = 1.\nHu et al. (2023) presents a second approach to stabilize a nonlinear system by mainly focusing on the linear part of a kernel ridge regression. More specifically, Hu et al. (2023) considers the nonlinear dynamics\nx(t + 1) = f (x(t)) + Bu(t),\nwith unknown nonlinear drift f (x) and unknown input matrix B. To infer on the drift, data {yi, xi}Si=1 with yi = f (xi) of the system without exciting input u = 0 have to be measured. Applying (14) for each row implies under Assumption 3 the uncertain system representation\nx(t + 1) = AK(x(t)) + Bu(t) + R(x(t)), with data-dependent matrix A = [ y1 \u00b7 \u00b7 \u00b7 yS ] (\u03bbI +KX)\u22121 and ||R(x)||22 \u2264 nxM2(k(x, x) \u2212 K(x)T K\u0302\u22121X K(x)).\nTo conclude on the unknown input matrix B, additional data {y\u0303i, x\u0303i, u\u0303i}S\u0303i=1 with y\u0303i = f (x\u0303i) + Bu\u0303i is measured. Alternatively to the cumulative uncertainty bound (Hu et al., 2023) (equation (31) and (32)), we suggest to compute a tighter ellipsoidal outer approximation \u03a3B for ||y\u0303i \u2212 AK(x\u0303i) \u2212 Bu\u0303i||22 \u2264 nxM2(k(x\u0303i, x\u0303i)\u2212K(x\u0303i)T K\u0302\u22121X K(x\u0303i)), i = 1, . . . , S\u0303 , as in Martin and Allgo\u0308wer (2022a).\nTo stabilize the nonlinear closed loop, Hu et al. (2023) separates the known kernel approximation AK(x(t)) into its linear and nonlinear components and uses the control structure u = F\u0304x + F\u0303K\u0303(x). Then, Hu et al. (2023) follows the nonlinearity cancellation approach of De Persis et al. (2022). Hence, the linear feedback F\u0304x aims to stabilize the linear closed-loop dynamics, whereas the nonlinear feedback F\u0303K\u0303(x) tries to minimize the influence of the nonlinearity of the closed loop. Both can be formulated as an SDP (Hu et al., 2023).\nFollowing the discussion of Berkenkamp and Schoellig (2015), the approach of Hu et al. (2023) can only guarantee asymptotic stability if the choice of kernels satisfies\nlim||x||2\u21920 \u221a\nk(x, x) \u2212 K(x)T K\u0302\u22121X K(x)/||x||2 = 0. Since R(x) is neglected for stabilization, weaker closed-loop guarantees are achieved compared to Fiedler et al. (2021b). Moreover, since the system representation and the closed-loop representation include the nonlinear term R(x), the verification of dissipativity or a region of attraction would require nonlinear optimization (Hu et al., 2023) (Theorem 2)."
        },
        {
            "heading": "6.5. Polynomial kernel for data-driven control",
            "text": "In contrast to Section 6.3 and Section 6.4, Devonport et al. (2020) does not reduce the nonlinear kernel to a linear representation but to a polynomial. To this end, the nonlinearity of kernels is handled by polynomial kernels together with an uniform bound for the approximation error of the nonlinear dynamics by polynomials. Due to the polynomial system representation, SOS optimization can be applied for verifying system properties and controller synthesis.\nAs in Section 5.2, the application of SOS relaxation motivates the investigation of continuous-time systems\nx\u0307(t) = f (x(t)) +G(x(t))u(t) + \u03a6(x(t)),\nwhere f : X \u2192 Rnx and G : X \u2192 Rnx\u00d7nu correspond to polynomial prior knowledge on the dynamics and \u03a6 : X \u2192 Rnx to an unknown and potentially nonlinear term. Furthermore, let f (0) = \u03a6(0) = 0. To infer the unknown nonlinear function \u03a6, let data {yi, xi, ui}Si=1 with yi = f (xi) + G(xi)ui + \u03a6(xi) + di and uniformly bounded noise ||di||\u221e \u2264 \u03c3 be given. Then Devonport et al. (2020) suggests to approximate each element of \u03a6 = [ \u03a61(x) \u00b7 \u00b7 \u00b7 \u03a6nx (x) ]T by polynomial kernels\nk(x, x\u2032) = \u2113\u2211\ni=1\n\u03b12i (x T x\u2032)i,\nwith scaling factors \u03b1i \u2208 R. Since the corresponding RKHS Hpoly is the set of all polynomials of degree less than or equal to \u2113 and zero at zero, \u03a6 < Hpoly. Thus, Assumption 3 is violated.\nTo this end, Devonport et al. (2020) supposes the following assumption.\nAssumption 4 (Devonport et al. (2020) (Assumption 3)). For a known \u03f5 > 0, there exists a polynomial vector q(x) of degree less or equal to \u2113 such that ||\u03a6(x) \u2212 q(x)||\u221e \u2264 \u03f5 for all x \u2208 X.\nBy Assumption 4, the data satisfy\nyi = f (xi) +G(xi)ui + q(xi) + d\u0303i, (22)\nwith ||d\u0303i||\u221e \u2264 \u03c3 + \u03f5. Since each element of q(x) =[ q1(x) \u00b7 \u00b7 \u00b7 qnx (x) ]T is an element ofHpoly, we can derive for each qi(x) the set membership (18) from data (22) and known ||qi||Hpoly according to Assumption 3. This in turn results in a set membership\n{\u00b5(x) + R(x) : \u00b5(x) = \u00b5post(x) and R(x)2 \u2264 \u03b22kpost(x, x) + \u03f52}. (23) for each \u03a6i(x). Devonport et al. (2020) shows that the posterior mean \u00b5post(x) and variance kpost(x, x) are polynomial for a polynomial kernel. Hence, the set membership (23) is characterized by polynomials analogously to the set membership from TPs (6). Thus, the system analysis and controller synthesis from Section 5.1 by solving an SOS optimization problem is also possible for the set membership from polynomial kernels (23). Indeed, the uncertain TP in (6) reduces to the known \u00b5post(x) in (23), while the square of the remainder in (6) and (23) is upper bounded by a polynomial. Furthermore, Section 5.1 considers a row-wise inference on the dynamics by TPs compatible to the kernel inference for each \u03a6i by (23). Nevertheless, Devonport et al. (2020) shows an alternating optimization over the state feedback and Lyapunov function.\nOriginally, Devonport et al. (2020) (Proposition 3 and Section 4) does not explicitly account for the uncertainty \u03f5 in (23) and in the subsequent controller synthesis. If we include this uniform bounded uncertainty, then (23) is non-zero for x = 0. Thus, an inference on stability of the origin is prevented. To circumvent this issue, we suggest to derive a polynomial bound \u03f5(x) \u2265 0 with \u03f5(0) = 0. For instance, a suitable \u03f5(x) can be calculated from the remainder formula for TPs (3) or Hermite polynomials (Sauer and Xu, 1995) under Assumption 1.\nFollowing the idea of computing \u03f5(x) from the remainder formula for TPs, then qi(x) corresponds to the TP of \u03a6i(x) in Assumption 4. In this case, the set membership from TPs (6) and from polynomial kernels (23) include the bound for the remainder (3). Further, (6) computes the smallest ellipse containing the set of polynomials consistent with (22). The centre of the ellipse can be interpret as an LSE estimation. On the other hand, the posterior mean \u00b5post(x) corresponds to the LSE estimation for the TP qi from data (22)."
        },
        {
            "heading": "7. Data-driven control by LPV embedding",
            "text": "An LPV system is a linear system with system matrices that depend on a time-varying independent variable. This variable\nis called scheduling variable and can describe nonlinearities, time-varying system parameters, or exogenous effects. In contrast to linear time-varying systems, the scheduling variable is unknown a priori but measurable. Hence, gain scheduling control is possible where the control law depends on the state and the scheduling variable. While LPV systems establish an interesting extension of LTI systems in itself, To\u0301th (2010) shows their potential of capturing the behavior of nonlinear systems.\nFor that reason, we review the data-driven treatment of a nonlinear system by combining data-driven control of LPV systems and the embedding of the nonlinear system into an LPV system. To this end, we first provide an overview on the extension of data-driven results for LTI systems to LPV systems. Afterwards, the embedding of nonlinear systems into LPV systems is discussed from a data-based perspective."
        },
        {
            "heading": "7.1. Data-driven control for LPV systems",
            "text": "This section introduces three data-driven representations for unknown LPV systems: (i) an extension of Willems\u2019 fundamental lemma, (ii) an extension of De Persis and Tesi (2020), and (iii) a set-membership approach. All three data-driven system representations ensure rigorous guarantees and system analysis and control based on SDPs. Notice that specific data-driven control schemes for LPV systems has been already investigated previously, for instance, by virtual reference feedback tuning (Formentin and Savaresi, 2011). See also the survey by Bachnas et al. (2014).\n(i) In the behavioral framework, the dynamics of a system is characterized by its behavior that spans all possible inputoutput trajectories that can be observed from the system. Since the framework is trajectory-based, it is appealing for representations of dynamical systems from measured trajectories. One particular result is the fundamental lemma by Willems et al. (2005) that characterizes any trajectory of an LTI system based on a single measured trajectory. Therefore, this non-parametric parametrization can directly be exploited for data-driven simulation and output matching control (Markovsky and Rapisarda, 2008), predictive control (Coulson et al., 2019; Berberich et al., 2021; Yin et al., 2021), system level synthesis (Xue and Matni, 2021), and the verification of dissipativity (Maupong et. al., 2017; Romer et al., 2019) and more general inputoutput properties (Koch et al., 2021) over a data-dependent time horizon. Moreover, various extensions of the fundamental lemma, among others, linear time-varying systems (Nortmann and Mylvaganam, 2020) and Wiener or Hammerstein systems (Berberich and Allgo\u0308wer, 2020) are investigated.\nBased on a behavioral formulation, Verhoek et al. (2021a) (Theorem 2) presents a fundamental lemma for general LPV systems. For the sake of simplicity, we only present the fundamental lemma for LPV systems with IO-representation\ny(t) = na\u2211 i=1 ai(p(t \u2212 i))y(k \u2212 i) + nb\u2211 i=1 bi(p(t \u2212 i))u(t \u2212 i), (24)\nwith output y(t) \u2208 Rny , input u(t) \u2208 Rnu , scheduling parameter p(t) = [ p1(t) \u00b7 \u00b7 \u00b7 pnp (t) ]T \u2208 P, and na \u2265 1, nb \u2265 0. The\nfunctions ai and bi depend affine on the time-shifted scheduling parameter, i.e.,\nai(p(t \u2212 i)) = np\u2211 j=0 ai, j p j(t \u2212 i),\nbi(p(k \u2212 i)) = np\u2211 j=0 bi, j p j(t \u2212 i),\nwith unknown coefficients ai, j \u2208 Rny\u00d7ny and bi, j \u2208 Rny\u00d7nu . Now let a trajectory (y, p, u) from (24) of length N be given, i.e., y = [ y(1) \u00b7 \u00b7 \u00b7 y(N) ] , p = [ p(1) \u00b7 \u00b7 \u00b7 p(N) ] , and u =[\nu(1) \u00b7 \u00b7 \u00b7 u(N) ]\nsatisfying (24). Furthermore, let (u, p) be PE of a sufficiently large degree (Verhoek et al., 2021a). Then the fundamental lemma for LTI systems implies that for any trajectory (y\u0304, p\u0304, u\u0304) from (24) of length L, there exists a g \u2208 RN\u2212L+1 such that  HL(u) HL(p \u2297 u) \u2212 P\u0304nuHL(u)\nHL(y) HL(p \u2297 y) \u2212 P\u0304nyHL(y)\n g =  vec(u\u0304) 0 vec(y\u0304)\n0  , (25) where \u2297 is the Kronecker product of two matrices, P\u0304n is a block-diagonal matrix with diagonal blocks p\u0304(t) \u2297 In, vec(u\u0304) =[ u\u0304(1)T \u00b7 \u00b7 \u00b7 u\u0304(L)T ]T , and HL the Hankel matrix of depth L (Verhoek et al., 2021a). By the simple algebraic relation (25), a single trajectory (y, p, u) is sufficient to generate any trajectory (y\u0304, p\u0304, u\u0304) of an LPV system. Thus, it can be leveraged to predict the behavior of an LPV system for a data-driven predictive control scheme (Verhoek et al., 2021b). Following the ideas for LTI systems (Romer et al., 2019), Verhoek et al. (2023b) determines finitehorizon dissipativity properties from one recorded noisefree trajectory.\n(ii) While the fundamental lemma (25) allows for an easy treatment of input-output data under rather mild controllability assumptions on the system, it only allows for system properties to be inferred over finite horizon. For arbitrary time horizons, Verhoek et al. (2022a) extends De Persis and Tesi (2020) to a representation of open- and closed-loop LPV systems from input-scheduling-parameter-state data. For that purpose, let the system matrices A : P \u2192 Rnx\u00d7nx and B : P \u2192 Rnx\u00d7nu be affine w.r.t. the scheduling parameter p, i.e.,\nA(p) = A0 + np\u2211 i=1 piAi, B(p) = B0 + np\u2211 i=1 piBi, (26)\nwith unknown matrices Ai, Bi, i = 1, . . . , np. Then Verhoek et al. (2022a) studies an LPV system in SS-representation\nx(t + 1) = A(p(t))x(t) + B(p(t))u(t) = A [\nx(t) p(t) \u2297 x(t)\n] + B [ u(t)\np(t) \u2297 u(t)\n] ,\n(27)\nwith state x(t) \u2208 Rnx , input u(t) \u2208 Rnu , and unknown matrices A = [ A0 A1 \u00b7 \u00b7 \u00b7 Anp ] and B = [ B0 B1 \u00b7 \u00b7 \u00b7 Bnp ] .\nTo find A and B, let the noise-free data {xi, pi, ui}Si=1 from (27) be available and let the data-depended matrix\nG =  x1 \u00b7 \u00b7 \u00b7 xS\u22121 p1 \u2297 x1 \u00b7 \u00b7 \u00b7 pS\u22121 \u2297 xS\u22121 u1 \u00b7 \u00b7 \u00b7 uS\u22121\np1 \u2297 u1 \u00b7 \u00b7 \u00b7 pS\u22121 \u2297 uS\u22121  have full row rank. The latter condition corresponds to a PE condition that generalizes the corresponding condition for LTI systems (De Persis and Tesi, 2020). Since\nX+ = [ x2 \u00b7 \u00b7 \u00b7 xS ] = [ A B ] G\nand G has full row rank, we obtain the unknown matrices A and B by [ A B ] = X+G\u2020 and the following data-based representation of (27)\nx(t + 1) = X+G\u2020  x(t) p(t) \u2297 x(t) u(t)\np(t) \u2297 u(t)  . By this data-based representation and the model-based conditions for stability and quadratic performance for LPV systems (Verhoek et al., 2022a) (Lemma 1-4), we can analyze an LPV system directly from data.\nFor the data-driven controller synthesis for (27), Verhoek et al. (2022a) extends the data-based closed-loop representation of LTI systems (De Persis and Tesi, 2020) (Theorem 2), as shown in Section 5.3, for a state feedback u(t) = K(p(t))x(t). For a polytopic and convex P, the design of a stabilizing feedback boils down to a finite number of LMI constraints by the full-block S-procedure (Scherer, 2001). Verhoek et al. (2022a) (Theorem 4-6) presents further statements for a data-driven controller synthesis with performance guarantees. Thereby, it is possible to design a controller for LPV systems with stability and performance guarantees from data by solving an SDP with a finite number of LMIs constraints.\n(iii) Miller and Sznaier (2023) considers a set-membership approach for LPV systems, and thus ensures rigorous guarantees despite noise-corrupted data. Moreover, the controller synthesis does not scale with the number of data as in Verhoek et al. (2022a). To this end, noisy samples {xi, pi, ui}Si=1 from the LPV systems in SS-representation (27) with B(p) = B are drawn, i.e.,\nxi+1 = A [\nxi pi \u2297 xi\n] + Bui + di.\nThe actual noise realizations di, i = 1, . . . , S , are unknown. Collecting the data into matrices X = [ x1 \u00b7 \u00b7 \u00b7 xS\u22121 ] ,U = [ u1 \u00b7 \u00b7 \u00b7 uS\u22121 ] , X+ =[\nx2 \u00b7 \u00b7 \u00b7 xS ] , PX = [ p1 \u2297 x1 \u00b7 \u00b7 \u00b7 pS\u22121 \u2297 xS\u22121 ] , and\nD = [ d1 \u00b7 \u00b7 \u00b7 dS\u22121 ] amounts to the relation\nX+ = [ A B ]  XPXU  + D. (28)\nFor simplicity and analogously to the LTI result (van Waarde et al., 2022), let the noise be cumulatively bounded[\nI DT\n]T [ \u22061 \u2206 T 2\n\u22062 \u22063\n] [ I\nDT\n] \u2ab0 0,\nwith \u22063 \u2aaf 0. See Martin and Allgo\u0308wer (2022b) for a comparison of this cumulative and pointwise-in-time noise bound. Substituting the unknown noise matrix D from (28) immediately yields the set membership for the unknown coefficient matrices A and B\n\u03a3A,B= {[ A\u0303 B\u0303 ] :\n\u22c6T [ \u22061 \u2206 T 2\n\u22062 \u22063\n] \u00b7  I 0 X+ T \u2212  XPXU  T   I[A\u0303 B\u0303]T  \u2ab0 0  . (29)\nBy \u201c\u22c6\u201d, the matrices on the right-hand side of \u201c\u00b7\u201d are abbreviated.\nSince \u03a3A,B characterizes the set of all LPV systems consistent with the noisy data, the ground-truth LPV system (27) is contained within the set. Therefore, finding a control policy, that stabilizes all LPV systems within \u03a3A,B, also stabilizes the ground-truth system. In contrast to the previous LPV approaches, here the data is corrupted by noise, and thereby the true system can not be exactly identified from data. This uncertainty adds conservatism to the controller design but can be handled by robust control techniques.\nBy Lemma 1 from Miller and Sznaier (2023), the controller synthesis for LPV systems with convex polytopic scheduling space P boils down to the robust stabilization of the LTI systems with system matrices contained in the set membership (29) and scheduling parameters at the vertices P. This can be solved by a non-conservative S-Lemma (van Waarde et al., 2022). Thereby, also a controller design with performance guarantees is conceivable. In contrast to Verhoek et al. (2022a), the setmembership approach has the advantage that the number of optimization variables does not increase with the number of samples.\nFollowing a similar procedure, Mejari, et al. (2023) presents a set-membership approach for LPV systems using pointwisein-time bounded noise. Moreover, the synthesis of a gainscheduling feedback controller that ensures a robust invariant set w.r.t. bounded disturbance is investigated."
        },
        {
            "heading": "7.2. Data-driven LPV embedding of nonlinear systems",
            "text": "While the data-driven LPV methods from the previous section are also of independent interest, we clarify next their applicability for checking system properties and controller design for nonlinear systems. To this end, we consider the two conversions of a nonlinear system into an LPV system as proposed by Verhoek et al. (2022b) and Verhoek et al. (2023a) in a datadriven control context.\nVerhoek et al. (2022b) studies a general nonlinear discretetime system\nx(t + 1) = f (x(t), u(t)), (30)\nwith continuously differentiable function f : X \u00d7 U \u2192 X and f (0, 0) = 0. As shown in C\u0327imen (2010) (Proposition 1) and the references therein, the nonlinear system can be embedded into the LPV system (27) with scheduling parameter p(t) = \u03c8(x(t), u(t)) \u2208 P. Thus, f (x, u) \u2208 {A(p)x+B(p)u : p \u2208 P}.\nAssumption 5 (Verhoek et al. (2022b)). Let the scheduling map \u03c8(x, u) be known and chosen such that the matrices A(p) and B(p) of (27) are affine in p as in (26).\nUnder Assumption 5, input-scheduling-parameter-state data can be obtained from recorded input-state trajectories of the nonlinear system (30) as required for the three data-driven representations for LPV from Section 7.1. Thus, a set membership for the nonlinear system (30) is given by the set of all LPV systems consistent with the data, i.e.,\n\u03a3LPV =\n{ A [ x\np \u2297 x\n] + B [ u\np \u2297 u\n] : p \u2208 P, [ A B ] = X+G\u2020 } (31)\nor\n\u03a3\u0303LPV =\n{ A\u0303 [ x\np \u2297 x\n] + B\u0303 [ u\np \u2297 u\n] : p \u2208 P, [ A\u0303 B\u0303 ] \u2208 \u03a3A,B } .\n(32) Moreover, Assumption 5 allows the scheduling parameter to be constructed from input-state measurements of the nonlinear system to realize the feedback law u(t) = K(p(t))x(t). Hence, we can conclude that all three data-driven LPV approaches from Section 7.1 are conceivable for a data-driven system analysis or controller design for nonlinear systems under Assumption 5. Note that Verhoek et al. (2022b) focuses on the LPV representation (ii) from Verhoek et al. (2022a).\nAs shown in Koelewijn et al. (2020), the previous direct LPV embedding comes with the shortcoming that stability from the LPV system (27) implies stability for the nonlinear system (30) only at the origin but not for potential non-zero equilibria. This phenomenon emerges as the LPV stability analysis supposes that the scheduling parameter is an exogenous variable independent of state and input. Therefore, Verhoek et al. (2023a) considers an LPV embedding of the so-called velocity-form of a nonlinear system. Thereby, global stability and performance guarantees are possible.\nThe velocity-form of a nonlinear system describes the dynamics of \u2206x(t) = x(t) \u2212 x(t \u2212 1) and naturally exhibits a state-depended form. Similar to Assumption 5, Verhoek et al. (2023a) requires additional insights into the nonlinearities of its dynamics to infer a suitable scheduling variable. As for the direct LPV embedding, the data-driven control methods for LPV systems (i)-(iii) from the previous section are applicable for analysing and designing controllers for the embedded velocity-form LPV system using SDPs with a finite number of LMI constraints. Also note the similarities of the analysis of the velocity-form and incremental system analysis of nonlinear system (30) (Forni et al., 2013).\nAs summarized in Figure 4, combining an embedding of an unknown nonlinear dynamics into an LPV system and datadriven control techniques for LPV systems enables a data-based system analysis and control of nonlinear systems. The key idea to analyze systems and design controllers by SDPs despite nonlinear dynamics is the linearization by embedding the nonlinear system into an LPV system. Thereby, the nonlinearity is relaxed as the free scheduling variable. The LPV embedding comes at the cost of additional conservatism due to the independence of the scheduling variable regarding states and inputs. Thus, the LPV representation allows for more possible trajectories than the ground-truth nonlinear system. Nevertheless, To\u0301th (2010) indicates the successful application of an LPV embedding for a large subset of nonlinear systems. We also refer to Markovsky (2023) for an embedding of a nonlinear system into an LTI system by introducing additional inputs and for its application for data-driven simulation.\nIn contrast to the previously presented approaches by polynomial approximation (Section 5) and kernel regression (Section 6), the LPV approach requires knowledge of a function basis containing the nonlinearity of the dynamics (Assumption 5) or of its velocity-form. This insight might be reasonable for mechanical or electrical systems, however, is often not known. The latter scenario is tackled in the polynomial approximation and kernel regression approach. We assess the latter problem more difficult as the data only provide local insights into the nonlinear dynamics. Hence, the number of required data samples, e.g., in Verhoek et al. (2022b), can be significantly smaller. Further advantages of the LPV approach are the design of a potentially more flexible nonlinear feedback law and it does not rely on the scalability of an SOS relaxation.\nWe conclude with some possible extensions and open questions. As commented in Verhoek et al. (2023a) (Remark 1), Assumption 5 could be relaxed by using a monomial basis instead of a true function basis. This motivates the question whether an upper bound on the remainder for TPs and the insight from Assumption 1 can be incorporated into the data-based LPV representations and the subsequent analysis. For a monomial basis, a second question is whether a direct SOS treatment of the polynomial approximation is beneficial compared to an LPV relaxation by embedding the polynomial dynamics into an LPV\nsystem. Furthermore, we point out that an LPV embedding under Assumption 5 might be non-unique. For instance, given p1 = x1x2 and p2 = x22, then[\nx+1 x+2\n] = [ x1x22\nx21x2 + x 3 2\n] = [ \u03b1p2 (1 \u2212 \u03b1)p1 p1 p2 ] [ x1 x2 ] \u2200\u03b1 \u2208 R.\nHence, the problem arises that the set of matrices A1 and A2 from (26) compatible with the data is always a linear subspace, and thus unbounded. At the same time, many robust control techniques require a bounded uncertainty set."
        },
        {
            "heading": "7.3. Iterative control scheme by extended linearization",
            "text": "Related to the problem setup in Verhoek et al. (2022b), we briefly report the data-driven iterative control scheme of Dai and Sznaier (2021a). There the controller design for an unknown nonlinear system x(t+1) = f (x(t))+g(x(t))u(t) is solved by the extended linearization (C\u0327imen, 2010) and under a known function basis that spans the dynamics.\nAssumption 6 (Dai and Sznaier (2021a) (Assumption 1)). Let basis functions F : Rnx \u2192 Rn f and G : Rnx \u2192 Rng\u00d7nu be known such that there exist matrices A \u2208 Rnx\u00d7n f , B \u2208 Rnx\u00d7ng with f (x) = AF(x) and g(x) = BG(x).\nAssumption 6 calls for a dictionary of basis functions for the nonlinear system dynamics. This insight might by accessible from first principles, e.g., for mechanical or electrical systems.\nProceeding as in Miller and Sznaier (2023) or Mejari, et al. (2023) yields a set membership \u03a3A,B for the unknown matrices A and B from noisy data {xi, ui}Si=1. Thus, Dai and Sznaier (2021a) concludes on the nonlinear data-based system representation\nf (x) + g(x)u \u2208 { A\u0303Z(x)x + B\u0303G(x)u : [ A\u0303 B\u0303 ] \u2208 \u03a3A,B } , (33)\nwith extended linearization F(x) = Z(x)x. Instead of exploiting an LPV embedding to linearize the nonlinearity of (33) as in Verhoek et al. (2022b), Dai and Sznaier (2021a) suggests an online scheme. There the optimization problem\nmin u(t),u(t+1),... \u221e\u2211 i=t x(i)T Qx(i) + u(i)T Ru(i)\ns.t. x(i + 1) = A\u0303Z(x(t))x(i) + B\u0303G(x(t))u(i)\n(34)\nis solved in each time instant t and the first part of the optimal control policy u(t) is applied to the system. Hence, the key idea to circumvent the nonlinearity of (33) is to freeze Z(x) and G(x) at time t and to treat the nonlinear dynamics as an LTI system. Hence, the optimal control problem (34) can be solved for all[ A\u0303 B\u0303 ] \u2208 \u03a3A,B by an SDP with LMI constraints using datadriven control for LTI systems (van Waarde et al., 2022). To guarantee that the equilibrium at the origin is globally asymptotically stable, the optimal control problem is extended by a decrease of a control Lyapunov function along the closed-loop trajectory.\nOn the one hand, this procedure constitutes an alternative to an LPV embedding as similar assumptions on prior insights and data are required. On the other hand, the optimal control problem (34) has to be solved iteratively online and the closed loop does not necessarily satisfy a specified control performance. An open question is whether the non-unique extended linearization might lead to performance or feasibility issues although not observed in the numerical example of Dai and Sznaier (2021a). Moreover, the feasibility of the optimal control problem is not guaranteed during runtime, which is typically ensured in MPC. We highlight the connection to the datadriven predictive control approach for nonlinear systems from Berberich et al. (2022b). There also an online updated local linear approximation of the nonlinear system is exploited but by using the fundamental lemma by Willems et al. (2005) rather than a set-membership representation."
        },
        {
            "heading": "8. Data-driven control by state lifting",
            "text": "The nonlinearity of a dynamical system usually prevents a system analysis and controller design by convex optimization. The literature on the Koopman operator presents a solution by lifting the states to higher, potentially infinite, dimensions. Thereby, the nonlinear dynamics is exactly described by a (bi-)linear system, and thus can be handled by control techniques for (bi-)linear systems. Due to its success in application, we review the Koopman operator with a focus on results providing rigorous guarantees."
        },
        {
            "heading": "8.1. Koopman operator paradigm",
            "text": "The Koopman operator paradigm was first introduced by Koopman (1931) and it has been increasingly used over the last decades because it provides a global (bi-)linear system description in contrast to a local Jacobian linearization. Its applications cover prediction (Mezic\u0301, 2005), global stability analysis (Mauroy et al., 2020), MPC (Korda and Mezic\u0301, 2018a), linear-quadratic regulation (Brunton et al., 2016), and robotics (Bruder et al., 2019). Further control-oriented applications can be found in Section 5.2 of Bevanda et al. (2021).\nThe notion of the Koopman operator is originally introduced for an autonomous system x(t + 1) = f (x(t)) with state x(t) \u2208 X \u2286 Rn. Instead of observing the time evolution of the states, the Koopman operator considers the system dynamics through the lens of scalar functions \u03c8 : X \u2192 C from a function space H . Thereby, the Koopman operator K : H \u2192 H is given by K\u03c8 = \u03c8 \u25e6 f , with function composition \u25e6. Thus, the operator characterizes the propagation of a whole hypersurface over one time-step rather than of a single state. Due to the linearity of the function composition, K is linear, although the underlying dynamics is nonlinear. Moreover, K operates globally for all x \u2208 X with K\u03c8(x) = \u03c8 \u25e6 f (x) = \u03c8(x(t + 1)).\nBesides providing a global linearization, the Koopman theory can be useful in system analysis: The particular choice of observables by the eigenfunctions \u03d5 of K , with K\u03d5 = \u03bb\u03d5 and eigenvalue \u03bb, enables a spectral analysis of nonlinear systems. Furthermore, Yi and Manchester (2021) investigates the equivalence of Koopman theory and contraction theory and Mauroy\net al. (2013) shows the connection of Koopman and Lyapunov theory by interpreting Lyapunov functions as special case of observable. We refer to the survey by Bevanda et al. (2021) and the references therein for more details including data-based inferences on eigenfunctions (Section 3.4).\nThe linearity of the system representation comes at the cost that the Koopman operator is infinite-dimensional. Therefore, a finite dimensional truncation is necessary for an efficient analysis and controller design. For that purpose, a dictionary of finitely many observables {\u03c8i}nDi=1 is chosen, which leads to the lifted finite-dimensional dynamics z(t + 1) = Az(t) with z = [ \u03c81(x) \u00b7 \u00b7 \u00b7 \u03c8nD (x) ]T = \u03a8(x). However, since the dictionary generally does not span an invariant space w.r.t. the Koopman operator, the lifted dynamics involves a truncation error. Since this error depends on the system dynamics and the chosen observables, its structure and size is in general unclear. The literature examines, besides specific choices of observables as time-delay coordinates (Kamb et al., 2020), learning of suitable observables from data, e.g., learning the eigenfunctions (Kaiser et al., 2021), deep learning (Lusch et al., 2018), and by SDPs (Sznaier, 2021). While the observables are mostly chosen to achieve a small prediction error, optimizing the dictionary together with a controller is interesting to find observables achieving good control performance.\nWhile the Koopman operator is linear for autonomous systems, the Koopman paradigm leads for input-affine systems and state-dependent lifting functions to a bilinear system description in continuous-time and to an LPV description in discretetime (Bevanda et al., 2021) (Corollary 5.1.1). Nevertheless, most works restrict the finite-dimensional truncation model to an LTI system (Korda and Mezic\u0301, 2018a; Zhang et al., 2022) z(t + 1) = Az(t) + Bu(t) or a bilinear system (Sinha et al., 2022; Stra\u0308sser et al., 2023a) z(t + 1) = Az(t) + u(t)(B0 + B1z(t)) (here u(t) \u2208 R).\nExtended dynamic mode decomposition (EDMD) constitutes a common estimation of the finite-dimensional system matrices of the truncation models from data: For a given set of statedependent observables {\u03c8i}nDi=1, input-state samples {xi, ui}Si=1 are collected from the underlying nonlinear system x(t + 1) = f (x(t))+ g(x(t))u(t). Then, for a bilinear system representation, the LSE problem\nmin A,B0,B1 \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223Z+ \u2212 [A B0 B1] Y \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 Fr\n(35)\nis solved with data-dependent matrices Z+ =[ \u03a8(x2) \u00b7 \u00b7 \u00b7 \u03a8(xS ) ] and\nY =  \u03a8(x1) \u00b7 \u00b7 \u00b7 \u03a8(xS\u22121)u1 \u00b7 \u00b7 \u00b7 uS\u22121 \u03a8(x1)u1 \u00b7 \u00b7 \u00b7 \u03a8(xS\u22121)uS\u22121  . As shown in Korda and Mezic\u0301 (2018b), EDMD is asymptotically consistent, i.e., converges to the Koopman operator for nD \u2192 \u221e and S \u2192 \u221e under some additional assumptions. In the non-asymptotic case, Nu\u0308ske et al. (2023) provides statistical bounds on the estimation error due to finite data."
        },
        {
            "heading": "8.2. Data-driven control by state lifting with guarantees",
            "text": "In the following, we take a closer look at two articles because they incorporate an estimation error into the controller design by a Koopman-lifted system representation. Thereby, guarantees for the closed loop of the original nonlinear system can be recovered if the estimation error satisfies the assumed error characterization.\nZhang et al. (2022) proposes to lift the nonlinear system x(t + 1) = f (x(t), u(t)), x \u2208 X, u \u2208 U, for a suitable choice of observables to the LTI system\nz(t + 1) = Az(t) + Bu(t) + w(t), x(t) = Cz(t) + v(t).\n(36)\nThe matrices A and B are calculated from EDMD, analogously to (35) with an additional regularization, and the output matrix C from\nmin C S\u2211 i=1 ||C\u03a8(xi) \u2212 xi||22 + \u03b2 ||C||2Fr,\nwith regularization parameter \u03b2 > 0. Thereby, the transformation from z to the predicted state x is also linearized for general observables. To account for the truncation error, EDMD for finite data, and the simplified LTI representation of the infinite dimensional Koopman model, Zhang et al. (2022) extends the lifted system by bounded uncertainties w and v.\nAssumption 7 (Zhang et al. (2022)). For (36), w \u2208 W and v \u2208 V with known bounded setsW andV.\nUnder reasonable assumptions on the observables, Zhang et al. (2022) (Proposition 2) proves that the uncertainty setsW and V are bounded. Further, since the knowledge ofW and V is non-trivial, Zhang et al. (2022) suggests to validate a choice of W andV using statistical learning theory.\nUnder Assumption 7, the nonlinear dynamics is captured by\nf (x, u) \u2208 {C(A\u03a8(x) + Bu + w) + v : w \u2208 W, v \u2208 V},\nwith A, B, and C from EDMD. The nonlinearity of this set membership by \u03a8(x) can be circumvented by analysing the lifted system (36) with lifted state vector z = \u03a8(x).\nSince the error characterization of Assumption 7 does not vanish at the origin, this uncertainty description is not suitable for verifying dissipativity or a state-feedback design. Instead, Zhang et al. (2022) follows a robust tube-based MPC approach (Mayne et al., 2005). Thereby, Zhang et al. (2022) proves closed-loop robustness w.r.t. the estimation error and point-wise convergence (Theorem 3). Furthermore, an MPC scheme with nonconvex optimization is circumvented by the linear Koopman prediction model.\nIn contrast to a linear MPC, Stra\u0308sser et al. (2023a) designs a state feedback from a lifted state model including a finitegain bounded estimation error. Since a lifting of an input-affine nonlinear system does not lead to an LTI system (Bevanda et al., 2021), Sinha et al. (2022) and Stra\u0308sser et al. (2023a) consider a discrete-time bilinear representation\nz(t + 1) = Az(t) + u(t)(B0 + B1z(t))\nof a finite-dimensional lifted system with scalar input u(t) \u2208 R. Thus, a higher accuracy and better control performance can be achieved. Sinha et al. (2022) does not account for the error by estimating the Koopman operator. Contrary, Stra\u0308sser et al. (2023a) supposes a finite-gain bound for an additive estimation error during closed-loop operation with u(t) = kT z(t).\nAssumption 8 (Stra\u0308sser et al. (2023a) (Assumption 2)). An additive estimation error \u03f5(z) \u2208 RnD satisfies a finite-gain bound ||\u03f5(z)||2 \u2264 L||z||2 with known L \u2265 0.\nStra\u0308sser et al. (2023a) proposes to estimate L by first approximating the Lipschitz constant of the nonlinear dynamics from data. Together with the matrices A, B0, B1 from EDMD, this results in a Lipschitz constant of \u03f5(z) satisfying the finite-gain bound in Assumption 8. Alternatively, a validation procedure by Hoeffding\u2019s inequality or learning a kernel approximation for \u03f5(z) to obtain a linear sector by Fiedler et al. (2021b) are conceivable. However, since the gain L is required for the closed loop and the controller gain k is undetermined at first, closed-loop data is not available. Therefore, the estimation of L is non-trivial and might require an iteration between controller synthesis and estimation of L.\nUnder Assumption 8, the nonlinear dynamics of the closed loop f (x) + g(x)kT\u03a8(x) is contained in\n{\u03a8\u22121(A\u03a8(x) + kT\u03a8(x)(B0 + B1\u03a8(x)) + \u03f5(\u03a8(x))) : ||\u03f5(\u03a8(x))||2 \u2264 L||\u03a8(x)||2}.\nFor the lifted state z = \u03a8(x), the nonlinearity of the set membership boils down to a bilinear system with finite-gain bounded uncertainty. Moreover, the inverse mapping x = \u03a8\u22121(z) might be a simple matrix multiplication for certain lifting, e.g., delay or monomial coordinates (Stra\u0308sser et al., 2023a). Thereby, a stabilizing linear feedback of the lifted states can be received by LMI robust control techniques for bilinear systems that also stabilizes the nonlinear system.\nMotivated by the bilinear model deduced from lifting techniques, we summarize in the following remark three data-driven control techniques for bilinear systems.\nRemark 1 (Data-driven control of bilinear systems). For bilinear systems with unknown system matrices, Yuan and Corte\u0301s (2022) presents an extension of Willems\u2019 fundamental lemma by interpreting the bilinearity as an independent input. Similar to De Persis and Tesi (2020), Bisoffi et al. (2020) presents a data-based closed-loop parametrization in order to design a state feedback by LMIs. Since the bilinearity is actually known and available for feedback, Stra\u0308sser et al. (2023b) presents a gain-scheduling controller to achieve a better control performance than Stra\u0308sser et al. (2023a).\nZhang et al. (2022) and Stra\u0308sser et al. (2023a) consider a closed-loop analysis in the lifted states without ensuring that the lifted states actually have a preimage in the original state space. By incorporating a projection of the lifted states back on the original space together with the error bounds from Nu\u0308ske et al. (2023), Bold et al. (2023) presents a nonlinear predictive\ncontroller with practical asymptotic stability guarantees. For that purpose, a similar error bound as in Assumption 8 is deduced from Nu\u0308ske et al. (2023) but in the original state space under the assumption of a finite and invariant dictionary of observables.\nIn contrast to the Koopman operator, Carleman lifting (Carleman, 1932) provides by monomial observables a systematic approach to bound its estimation error from finite data. For instance, Amini et al. (2021) and Abudia et al. (2022) derive a guaranteed, but potentially conservative, error bound between trajectories of an autonomous nonlinear system and the data-driven inference of a truncated lifted linear system. Hence, further examinations on these error bounds are necessary for the application, e.g., for a linear MPC design (Hashemian and Armaou, 2019). Furthermore, Rotondo et al. (2022) investigates the connection of Carleman lifting and TP approximation but neglects the error regarding the vector field of the truncated Carleman lifting. Similarly, Bramburger et al. (2023) exploits a combination of Koopman lifting with polynomial observables and SOS optimization but also neglects the error due to finite data and truncation. However, due to the polynomial dictionary, an investigation of the estimation error might be possible.\nRelated to the state lifting by the Koopman operator, a nonlinear system x\u0307 = f (x) + g(x)u can be polynomialized if the dynamics contain only certain nonlinearities. More specifically, the time derivatives of the nonlinear functions in f and g have to be written as terms of the same functions. See Table 2 in Stra\u0308sser et al. (2021) for a collection of such functions. In this case, the nonlinear dynamics can be formulated as a finitedimensional polynomial system z\u0307(t) = AZ(z(t)) + BH(z(t))u(t) by introducing a lifted state z together with some conservatism (Stra\u0308sser et al., 2021) (Remark 9). In a data-driven context, Stra\u0308sser et al. (2021) examines polynomialization of nonlinear systems with known function basis of f and g. Hence, the data-driven system analysis and controller design boils to the problem of polynomial systems with unknown coefficient matrices A and B as in Section 5.2.\nThe Koopman operator constitutes a powerful tool to analyze general nonlinear system by methods from linear or bilinear control theory. While the operator is infinite-dimensional, the literature asks for finite-dimensional estimations retrieved from a finite set of data. Recent works take the error by truncation and simplified lifted model into account and handle it by robust control techniques. Thus, a system analysis and a controller design with rigorous guarantees and using SDPs are possible. But in fact, the characterization of this error is so far rather vague, and therefore potentially conservative. Concurrent, deriving insights into the error for arbitrary observables is non-trivial and still an open problem. Moreover, while the controller performance is optimized regarding the lifted states, the resulting performance of the underlying system might be unclear."
        },
        {
            "heading": "9. Data-driven control by approximate nonlinearity cancellation and feedback linearization",
            "text": "Approximate nonlinearity cancellation aims to find a feedback law that stabilizes the systems while reducing the influence of the nonlinearity of the closed-loop dynamics. Whereas the presented nonlinearity cancellation technique works in the original states, feedback linearization transforms a nonlinear system via a certain change of coordinates and a feedback law (Isidori, 1995). For flat systems, the transformed system dynamics becomes linear as the nonlinear internal dynamics vanishes. Systems of that kind emerges in practice, e.g., in robotics and in automatic flight control (Levine, 2009). Due to the feedback law in both paradigms, the dynamics is changed in order to obtain a closed-loop description suitable for linear control design techniques. In contrast, the previously presented approaches aim to obtain a suitable characterisation of the openloop dynamics itself instead of modifying it.\nWe report the data-driven control literature exploiting SDPs within these control frameworks. We begin with the data-driven nonlinearity cancellation because this result will be required to obtain a linear system description via feedback linearization."
        },
        {
            "heading": "9.1. Data-driven approximate nonlinearity cancellation",
            "text": "In this section, we review exact and approximate nonlinearity cancellation for a data-driven controller design of nonlinear systems by SDPs. More specifically, De Persis et al. (2022) aims to stabilize and cancel the nonlinearity of the discrete-time nonlinear system\nx(t + 1) = f (x) + Bu, (37)\nwith unknown drift f : Rnx \u2192 Rnx and unknown input matrix B \u2208 Rnx\u00d7nu . To infer on the nonlinear function f from data, the knowledge of a function basis is supposed.\nAssumption 9 (De Persis et al. (2022) (Assumption 1)). Let a continuous function z : Rnx \u2192 Rnz be known such that f (x) = Az(x) for some matrix A \u2208 Rnx\u00d7nz .\nA similar assumption is already introduced and clarified in Section 7.2 and Section 7.3. For that reason, a suitable basis z might be available from first principles, while only the system parameters A are unknown. Since one key idea will be to separate the linear and nonlinear dynamics, De Persis et al. (2022) writes z without loss of generality as\nz(x) = [\nx q(x)\n] ,\nwhere q only contains nonlinear functions. After the stage is set, De Persis et al. (2022) extends De Persis and Tesi (2020) by determining a data-driven representation of the closed loop with system (37) and the nonlinear state feedback u(t) = Kz(t). To this end, the data {xi, ui}Si=1 from system (37) is collected into the matrices U = [ u1 \u00b7 \u00b7 \u00b7 uS\u22121\n] , X+ =[\nx2 \u00b7 \u00b7 \u00b7 xS ] ,Z = [ x1 \u00b7 \u00b7 \u00b7 xS\u22121\nq(x1) \u00b7 \u00b7 \u00b7 q(xS\u22121)\n] . Then, the closed\nloop can be characterized by the following data-dependent matrices\nx(t + 1) = [ A B ] [ I K ] z(x)\n= [ A B ] [Z U ] Gz(x) = X+Gz(x),\nwhere the last equality follows from X+ = AZ+BU. The second equality holds for a matrix G satisfying[\nI K\n] = [ Z U ] G, (38)\nas already shown in De Persis and Tesi (2020) and Section 5.3. Proceeding the idea of separating the linear and nonlinear terms, De Persis et al. (2022) (Lemma 1) derives the data-based closed-loop description x(t + 1) = Lx + Nq(x) with L = X+G1, N = X+G2, G = [ G1 G2 ] .\nGiven this description of the closed loop, it is globally asymptotically stabilized for a G satisfying X+G2 = 0 and that renders L = X+G1 to be Schur. Indeed, by cancelling the input matrix X+G2 of the nonlinearity, only the linear system matrix X+G1 needs to become stable. De Persis et al. (2022) (Theorem 1 and Theorem 3) formulates this problem as an SDP. Furthermore, De Persis et al. (2022) (Theorem 4) investigates the case when the nonlinearity X+G2 can not be cancelled out exactly. Instead, its influence ||X+G2||Fr is minimized. Therefore, the nonlinearity is only approximately cancelled and the origin is only asymptotically stable, if the linear part dominates the nonlinear, i.e.,\nlim ||x||2\u21920 ||q(x)||2 ||x||2 = 0.\nThis procedure can also be adapted for noisy data and bounded neglected nonlinearities (De Persis et al., 2022)(Theorem 6 and 8). To this end, the controller again musts render the linear closed-loop dynamics stable. However, since the dynamics can not exactly be identified from data, a set of systems matrices has to be stabilized.\nWhile De Persis and Tesi (2020) neglects the nonlinearity and elaborates a linear feedback design, De Persis et al. (2022) achieves a more flexible nonlinear feedback law. Moreover, the effect of the nonlinearity is minimized to increase the region of attraction. However, since the stabilization criterion in De Persis and Tesi (2020) and De Persis et al. (2022) contains only the linear part of the dynamics, only an asymptotically stable equilibrium can be ensured without guarantees for the size of the region of attraction. Moreover, the refinement of the latter is unclear because the nonlinearity might actually be useful for stabilization. Thus, a cancellation might even decrease the region of attraction or might render the system non-robust regarding small disturbances (Freeman and Kokotovic\u0301, 1996). Instead of cancelling the nonlinearity, it is bounded and incorporated into the controller synthesis in Martin et al. (2023a) to achieve performance criteria and global stability.\nTo impose further guarantees, De Persis et al. (2022) proposes to analyze the region of attraction (Proposition 1) or robust invariant sets (Theorem 7) for the obtained closed loop.\nNonetheless, here the problem arises that the closed-loop dynamics contains nonlinear terms, and thus estimating these sets calls for solving a nonconvex optimization problem. Furthermore, the complexity of the closed-loop parametrization (38) increases with the number of samples as in De Persis and Tesi (2020). Thus, a set membership for the uncertain system matrices A and B might be preferable. Finally, note that nonlinearity cancellation conceptually does not allow for analyzing the underlying system regarding, e.g., dissipativity."
        },
        {
            "heading": "9.2. Data-driven feedback linearization",
            "text": "Before studying the data-based case, we begin with a general recap of feedback linearization of flat single-input single-output discrete-time systems and refer to Monaco and Normand-Cyrot (1987) for the multiple-input multiple-output case. Consider the nonlinear system\nx(t + 1) = f (x(t), u(t)), y(t) = h(x(t)),\n(39)\nwith smooth functions f : Rnx \u00d7 R \u2192 Rnx and h : Rnx \u2192 R. Further, we assume that system (39) satisfies\n\u2202\n\u2202u (h \u25e6 f i0 \u25e6 f (x, u)) = 0, \u2200(x, u) \u2208 Rnx \u00d7 R, 0 \u2264 i \u2264 nx \u2212 2,\n\u2202\n\u2202u (h \u25e6 f nx\u221210 \u25e6 f (x, u)) , 0, \u2200(x, u) \u2208 R nx \u00d7 R,\nwith f i0 denoting the i times composition of f (x, 0). Therefore, system (39) has a well-defined relative degree nx, and hence is called flat. Following Diwold et al. (2022), one can define the state transformation\nz(t) = \u03a8(x(t)) =  h(x(t)) h \u25e6 f0(x(t)) ...\nh \u25e6 f nx\u221210 (x(t))\n =  y(t) y(t + 1)\n... y(t + nx \u2212 1)  , which yields the transformed system dynamics of (39)\nz(t + 1) =  z2(t) ...\nznx (t) h \u25e6 f nx\u221210 \u25e6 f (x(t), u(t))  , y(t) = z1(t).\n(40)\nThus, a flat system can be fully linearized by the state transformation z = \u03a8(x), containing only forward time-shifted outputs, and the input transformation v(t) = h \u25e6 f nx\u221210 \u25e6 f (x(t), u(t)) = \u03a8v(x(t), u(t)) = \u03a8v(\u03a8\u22121(z(t)), u(t)) = \u03a8v(Y(t), u(t)) with Y(t) =[ y(t) \u00b7 \u00b7 \u00b7 y(t + nx \u2212 1) ] .\nAfter this introduction to feedback linearization, we can proceed to the data-driven control of flat systems. To this end, let the flat system (39) be unknown, and thus the input transformation\u03a8v as well. Note that the unknown system can be perturbed to check for flatness (Alsalti et al., 2023a). Then Alsalti et al. (2021) suggests to assume that \u03a8v admits a linear combination of known functions.\nAssumption 10 (Alsalti et al. (2021)). Suppose that the input transformation takes the form \u03a8v(Y(t), u(t)) = aT \u03a8\u0303v(Y(t), u(t)) with known vector of functions \u03a8\u0303v : Rnx \u00d7 R \u2192 Rn\u03a8\u0303 and unknown coefficient vector a \u2208 Rn\u03a8\u0303 .\nIn general, finding a suitable choice of \u03a8\u0303v can be challenging, in particular for discrete-time systems. Indeed, the function composition \u03a8v = h \u25e6 f nx\u221210 \u25e6 f (x, u) prevents the derivation of \u03a8\u0303v from a function basis of the system dynamics f , which might be available from first principles. In contrast, this is possible for continuous-time systems as the function composition is replaced by Lie derivatives. For instance, consider the flat discrete-/continuous-time system\nx1(t + 1)|x\u03071(t) = \u03b11 sin(x2(t)), x2(t + 1)|x\u03072(t) = \u03b12 cos(x1(t)) + u(t),\ny(t) = x1(t),\nwith unknown coefficients \u03b11 and \u03b12 and basis functions sin(x2), cos(x1), and u. For the discrete-time case, the input transformation corresponds to\u03a8v(x, u) = \u03b11 sin(\u03b12 cos(x1)+u). Hence, \u03a8\u0303v(x, u) = sin(\u03b12 cos(x1) + u) which is however unknown due to the unknown coefficient \u03b12. Contrary, in continuous time, v(t) = y\u0308(t) = \u03b11\u03b12 cos(x1) cos(x2)+\u03b11 cos(x2)u with known basis functions cos(x1) cos(x2) and cos(x2)u.\nIn case a function basis \u03a8\u0303v is not available and only the scalar product of \u03a8\u0303v is required, then Alsalti et al. (2021) proposes to consider an infinite number of basis functions and to compute the scalar product by kernel methods. However, this comes with the drawback that an infinitely long PE input sequence is required to span the whole input-output trajectories of the system. Alternatively, Alsalti et al. (2023a) (Assumption 5) relaxes Assumption 10 by incorporating an uniformly bounded uncertainty \u03f5\n\u03a8v(Y(t), u(t)) = aT \u03a8\u0303v(Y(t), u(t)) + \u03f5(Y(t), u(t)). (41)\nThereby, \u03a8\u0303v does not necessarily have to span a function basis for \u03a8v.\nUnder Assumption 10, the feedback linearization (40) of nonlinear system (39) yields\nz(t + 1) =  0 1 \u00b7 \u00b7 \u00b7 0 ... . . . . . . ... ...\n. . . 1 0 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 0 \ufe38 \ufe37\ufe37 \ufe38 =:D z(t) +  0 ... 0 aT  \u03a8\u0303v(Y(t), u(t)),\ny(t) = [ 1 0 \u00b7 \u00b7 \u00b7 0 ] z(t).\n(42)\nTherefore, the behavior \u03a8\u0303v \u2192 y is linear with unknown input matrix [ 0 \u00b7 \u00b7 \u00b7 0 a ]T . Thus, Alsalti et al. (2021) (Proposition 1) can apply Willems\u2019 fundamental lemma for LTI systems here. Note that the PE condition is more difficult to be fulfilled for a larger function basis. Moreover, the PE condition includes input and output data instead of only input data as in the LTI case. Therefore, the PE condition can only be checked after\nan experiment is carried out. We refer to Alsalti et al. (2023b) (Theorem 5) for the design of inputs to guarantee PE of a sequence of monomial basis functions.\nBy means of the extension of Willems\u2019 fundamental lemma for flat systems, Alsalti et al. (2021) solves the data-driven simulation and output-matching control problem for feedback linearizable systems. Alsalti et al. (2023a) generalises these results for the relaxed version (41) of Assumption 10. Specifically, the effect of uniformly bounded uncertainty \u03f5 and output measurement noise on the data-driven simulation and outputmatching control problem is analyzed by providing output error bounds. Bounding this error together with the extended fundamental lemma can be leveraged for robust data-driven predictive control with rigorous stability guarantees (Alsalti et al., 2022, 2023c).\nWhile the feedback linearization leads to a linear behavior from the new input v to y, the system dynamics u \u2192 y in (42) is nonetheless nonlinear. Therefore, the extended fundamental lemma results in nonlinear optimization problems for the data-driven simulation, output-matching control, and predictive control. Thus, solving these optimization problems might be difficult or computationally expensive, in particular, if a large prediction horizon or number of basis functions are considered. Furthermore, for data {xi, ui}Si=1 satisfying xi+1 = f (xi, ui) and error (41), we can determine a set membership containing f (x, u){ \u03a8\u22121(D\u03a8(x) + [ 0 1\n] (a\u0303T \u03a8\u0303v(x, u) + \u03f5(x, u))) : ||\u03f5(x, u)||2 \u2264 \u03f5\u2217,\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u03a8(xi+1) \u2212 D\u03a8(xi) \u2212 [01 ] a\u0303T \u03a8\u0303v(xi, ui) \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 2 \u2264 \u03f5\u2217, i = 1, . . . , S \u2212 1 } .\nNote that \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223\u03a8(xi+1) \u2212 D\u03a8(xi) \u2212 [01 ] a\u0303T \u03a8\u0303v(xi, ui) \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 2 \u2264 \u03f5\u2217, i = 1, . . . , S \u2212 1, imply the set of all coefficients a\u0303 feasible with that data, and thus contains the true unknown coefficients a. While the nonlinearity from \u03a8 and \u03a8\u22121 can be circumvented by considering the set membership w.r.t. z, the nonlinearity from \u03a8\u0303v(x, u) remains.\nTo circumvent a controller design by a nonlinear optimization problem, De Persis et al. (2022) (Assumption 6) restricts Assumption 10 to a linear input transformation concerning the input\n\u03a8v(Y(t), u(t)) = aT \u03a8\u0303v(Y(t)) + bu(t). (43)\nWhile this condition might only be possible for special cases, e.g., the polynomial system in De Persis et al. (2022) (Example 10), it is always satisfied for an input-affine continuous-time system with linear input matrix. For a purely linear system description, De Persis et al. (2022) (Corollary 2) requires in addition to (43) that the nonlinearity aT \u03a8\u0303v(Y(t)) can be exactly cancelled. The remaining data-driven inference of the unknowns a and b and the nonlinearity cancellation using SDPs corresponds to the procedure described in Section 9.1.\nThe main advantage of a feedback linearization is that a flat system can exactly be linearized in some coordinates. Thereby,\nfor instance, global asymptotic stability can be ensured. On the other hand, the approximate nonlinearity cancellation from Section 9.1 stays in the original coordinates. Thus, it allows a controller design and closed-loop analysis in the original coordinates. Moreover, the latter does not require flatness of the system.\nUnder the more restrictive assumption that complete dictionaries for the state transformation \u03a8 and the input transformation \u03a8v are available, De Persis et al. (2023) learns both transformations from data. To this end, the null space of a data-dependent matrix has to be computed, which is even for large matrices possible. Based on the obtained state and input transformation, an explicit control law to locally stabilize the nonlinear system around an equilibrium can be deduced.\nIn summary, data-driven feedback linearization requires knowledge of a function basis for the input transformation and leads to a nonlinear system description. Hence, it does not allow for a system analysis or state-feedback design by SDPs. A linear description of the system dynamics can only be obtained together with a nonlinearity cancellation. Contrary, Koopman linearization does not require an input transformation. Thus, a (bi-)linear characterization of the system itself is deduced, which is suitable for a system analysis by SDPs. We refer to Kaiser et al. (2021) for a more thorough discussion of advantages of the Koopman paradigm compared to feedback linearization. Moreover, the question rises whether the overhead of SDPs is necessary as practicable and rigorous learning-based approaches based on feedback linearization already exist, e.g., see Helwa et al. (2019) and Lederer et al. (2019)."
        },
        {
            "heading": "10. Discussion",
            "text": "After the presentation of the various data-based system representations, we consider in this section a more general and embraced discussion. Specifically, we discuss the derivation of the system representations and the required prior model knowledge. Moreover, we compare the implementability of the presented approaches with similar data-driven methods from the literature. We review how the different methods incorporate noisy data. Finally, we give some general comments on the advantages of data-based discrete- and continuous-time system representations. Table 2 partially summarizes the discussion."
        },
        {
            "heading": "10.1. Derivation of data-driven system representations",
            "text": "We can identify a common procedure for the derivation of the presented data-driven system representations. Using techniques from model-based control theory, the nonlinear dynamics f (x, u) is first embedded into a set of surrogate systems \u03a3sur, which are suitable for a system analysis or a controller synthesis via SDP. However, for unknown nonlinear systems, these surrogate systems include unknown coefficients. Therefore, \u03a3sur is embedded into the set of systems \u03a3sur-dd with data-driven inference on the unknown coefficients. For the polynomial interpolation approach, \u03a3sur corresponds to the polynomial sector (4)\nfrom TPs and \u03a3sur-dd corresponds to (6) with the inference on the TP from data. Analogously, for data-driven LPV embedding, \u03a3sur is the standard LPV embedding {A(p)x + B(p)u : p \u2208 P} such that \u03a3sur-dd corresponds to (32). Indeed, we can proceed this for all set membership introduced here except for the ones obtained by GP and kernel ridge regression. There first a datadriven set membership \u03a3dd including nonlinear functions is obtained, e.g., (18). Then a set of linear surrogate systems \u03a3dd-sur, e.g., from (20) is obtained. We illustrate both procedures in Figure 5."
        },
        {
            "heading": "10.2. Data-driven system analysis, predictive control, and state-feedback design",
            "text": "The presented system representations can be applied for data-driven system analysis and control. We provide a brief summary in Table 2. Note that the extension of the state feedback with input-state measurements to output feedback with input-output data is possible for a discrete-time setup by considering the extended state of past outputs (De Persis and Tesi, 2020; Berberich et al., 2022a; Koch et al., 2022). However, the extended state might lead to conservative requirements on the system and data."
        },
        {
            "heading": "10.3. Prior system knowledge",
            "text": "All presented system representations require some prior system knowledge to infer guarantees on the dynamics from data. We divide these into two categories.\nThe first type of assumption asks for an upper bound on a Lipschitz constant, higher order partial derivatives, or the complexity of the dynamics. While these assumptions are easier to satisfy than the second type, they only allow an accurate inference on the dynamics in the neighbourhood of samples. Indeed, this information typically implies only a correlation of the nonlinear behaviour at a data point and its neighbourhood. Due to the multitude of local models from polynomial approximation or the non-parametric model from kernel regression, these approaches are computational more demanding. This drawback\nmight be circumvented in an online control scheme, where only the local behaviour of the system is relevant at one time step.\nThe second type of assumptions calls for a function basis that captures the nonlinearity of the dynamics, the scheduling parameter, a state transformation, etc. Thereby, these assumptions reduce the problem to unknown coefficients. We saw inferences on these coefficients by a set-membership procedure or Willem\u2019s fundamental lemma. Due to the prior information on the actual nonlinearity, we will observe in Section 10.4 that the number of samples are lower than for the approaches based on the first type of assumption and some machine learning approximation methods, e.g., using neural networks."
        },
        {
            "heading": "10.4. Implementability",
            "text": "For the discussion of implementability of the presented approaches, we rely on the examples provided in the reported works. We first observe that numerical examples of a nonlinear system with two states are mostly considered. This is in line with the system complexity of examples of other datadriven control approaches with comparable focus on theoretical guarantees, e.g., backstepping for GPs (Capone et al., 2022), estimation of the region of attraction from GPs (Berkenkamp et al., 2016), control certificate functions based on Lipschitz estimation (Taylor et al., 2021), safe reinforcement learning (Berkenkamp et al., 2017), neural Lyapunov function (Min et al., 2023), and learning deep neural networks for Koopman models (Tiwari et al., 2023). These works study the same inverted pendulum example as in Martin et al. (2023a), Verhoek et al. (2022b), Devonport et al. (2020), De Persis et al. (2022), and Zhang et al. (2022).\nFor the inference on a Koopman model, Zhang et al. (2022) and Stra\u0308sser et al. (2023a) require 5 \u00b7 104 samples for the inverted pendulum with 5 lifted states and 2000 for a Van der Pol oscillator with 32 lifted states, respectively. For learning a neural Lyapunov function or a deep neural network for a Koopman model, Min et al. (2023) and Tiwari et al. (2023) call for even 105 and 1.6 \u00b7 106 samples, respectively. Contrary, Martin et al. (2023a), Verhoek et al. (2022b), Devonport et al. (2020),\nDe Persis et al. (2022), and Zhang et al. (2022) require only between 10 and 100 samples from the inverted pendulum. As expected, approaches with a priori known nonlinear dictionary call for less data. The computation time to solve the resulting SDPs are reported in Martin et al. (2023a) with 8 s, Devonport et al. (2020) with 5 minutes, and Stra\u0308sser et al. (2023a) with less than one second.\nThis brief comparison shows that the presented data-driven control methods perform in numerical examples comparable with the existing literature, while providing additional advantages as discussed in the introduction. While Martin and Allgo\u0308wer (2023b), Verhoek et al. (2022b), and Berberich et al. (2022b) present initial applications on experimental examples, a broader application of the presented system representations for real data and a more detailed comparison using benchmark examples should be part of future research."
        },
        {
            "heading": "10.5. Noisy data",
            "text": "As summarized in Table 2, except for the fundamental lemma, most presented system representations provide guarantees though noise-corrupted data. The noise is mostly characterized by deterministic bounds as commonly supposed in datadriven control (van Waarde et al., 2022), data-driven system analysis (Koch et al., 2022), set-membership identification (Novara et al., 2013), adaptive control (Narendra and Annaswamy, 1986), and robust model predictive control (Mayne et al., 2005). However, such a noise description might be conservative if the noise is, e.g., Gaussian distributed as often assumed in system identification. Nevertheless, one can obtain for the presented set memberships, which are linear in the unknown parameters, analogous results with probabilistic guarantees for Gaussian distributed noise following Umenberger et al. (2019) and Martin et al. (2023a).\nFurthermore, an additive measurement noise dmeas on the true states xtrue, i.e., xmeas = xtrue + dmeas, yields a more challenging errors-in-variables problem than the presented simplified noise models. To refine these models, one could\nextend the SOS approach for LTI systems from Miller et al. (2022)."
        },
        {
            "heading": "10.6. Discrete- and continuous-time models from data",
            "text": "Throughout the presentation of the different data-based methods, we have seen continuous-time as well as discrete-time setups. While the approaches from Section 5, 6, 7.1 (ii) and (iii), 8, and Section 9.1 can be considered for both setups, the question rises what are the advantages compared to each other?\nThe main advantage of a discrete-time system representation is that only measurements of state or output trajectories are required instead of their time derivatives in addition. The latter can usually only be obtained under weak noise and fast sampling, which allows for signal smoothing with subsequent approximation of the time derivatives by finite differences.\nAdvantages of continuous-time system representations are that the learned parameters have a physical meaning as they do not depend on the sampling interval. Moreover, non-uniformly sampled data can be handled. Furthermore, the choice of the sampling interval is less critical than in discrete time. Indeed, if the sampling interval is too low compared to the system dynamics, then the eigenvalues of the discrete-time model are close to the unit circle leading to inaccurate stability inferences. We refer for more details to Garnier and Young (2014). Lastly, we mention that, e.g., the condition for Lyapunov stability is always linear w.r.t. the dynamics in continuous time while quadratic only for quadratic Lyapunov functions in discrete time. At the same time, transferring these conditions into an SDP by LMI robust control techniques is easier if these conditions are linear or quadratic regarding the nonlinear dynamics."
        },
        {
            "heading": "10.7. A new paradigm of data-driven control methods?",
            "text": "According to Definition 4 for data-driven control in the survey of Hou and Wang (2013), the approaches presented here would not be classified as data-driven. Indeed, the definition requires the controller design to be based on input-output data and does not allow for exploiting any model information. Moreover, instead of a direct method from data to control input, here first a data-based representation of the system is obtained, which is then explicitly included in the controller synthesis by SDPs. Furthermore, in view of Hou and Wang (2013), data-driven control methods are applicable independent of the class of systems. Thereby, the paradigm of data-driven control has changed over the last decade to a much broader collection of control techniques."
        },
        {
            "heading": "11. Conclusion",
            "text": "In this survey, we provided an overview on data-driven control approaches for nonlinear systems. In particular, the focus lay on data-based system representations, which are tailored for verifying system properties and designing controllers by SDPs.\nThereby, these methods strive to establish a framework for nonlinear data-driven system analysis and control rather than providing specific control schemes. More specifically, we discussed data-driven control by polynomial approximation, GP and kernel regression, LPV embedding, state lifting, and nonlinearity cancellation and feedback linearization.\nExcept for GP and kernel regression, these data-driven system representations are inspired by the model-based control literature. There the same techniques are leveraged to derive a verification of system properties and a controller synthesis by SDPs despite nonlinear system dynamics. Since the goal of these control methods is to derive a linear-like representation, data-driven techniques for LTI, bilinear, LPV, and polynomial systems are still relevant in the nonlinear case. Moreover, most of the data-based system characterizations for nonlinear systems that we have presented are combined with LMIbased robust techniques to achieve rigorous guarantees. In contrast, many system representations from system identification and machine learning are tailored to provide a precise surrogate model of the underlying system, and thus aim to approximate its dynamics as precise as possible. However, this typically leads to complex surrogate models preventing a convex system analysis and controller synthesis.\nGuarantees for data-driven inference on nonlinear system regardless of the framework require a priori insights into the dynamics. Hence, the performance of the data-driven approaches not only rely on the informativity of the data but also on the accuracy of the prior information. This is an additional challenge compared to the LTI case, where this kind of assumptions is not required.\nTo conclude this survey, we provide further open challenges and questions beside the ones mentioned in the individual sections: (i) While the characterization of errors for a polynomial approximation is well-established, the proposed error characterizations, e.g., for the estimation of the Koopman operator, are tailored for control, and thus might be conservative. (ii) How to justify assumptions with prior insights in a data-based setup? (iii) Input-output data are investigated mainly using the extended state (Berberich et al., 2022a) resulting in restrictive assumptions on the data. Moreover, Montenbruck and Allgo\u0308wer (2016) and Martin and Allgo\u0308wer (2020) consider the inputoutput system behaviour directly by its input-output mapping. However, this requires a large number of measured trajectories. (iv) Closing the gap between representations from a control and a data perspective. While the former is tailored for system analysis and control, the latter for explaining the data and providing a precise surrogate model. However, we search rather for a data-motivated representation suitable for controller design. (v) For a comprising comparison of data-driven control schemes, benchmark systems and data would be required. (vi) The extension of the data-informativity framework (van Waarde et al., 2023) to nonlinear systems is missing, i.e., when is the data informative to infer observability, controllability, stabilizability, etc., for a nonlinear system."
        }
    ],
    "title": "Guarantees for data-driven control of nonlinear systems using semidefinite programming: A survey ",
    "year": 2023
}