{
    "abstractText": "Empathy, which is widely used in psychological counselling, is a key trait of everyday human conversations. Equipped with commonsense knowledge, current approaches to empathetic response generation focus on capturing implicit emotion within dialogue context, where the emotions are treated as a static variable throughout the conversations. However, emotions change dynamically between utterances, which makes previous works difficult to perceive the emotion flow and predict the correct emotion of the target response, leading to inappropriate response. Furthermore, simply importing commonsense knowledge without harmonization may trigger the conflicts between knowledge and emotion, which confuse the model to choose incorrect information to guide the generation process. To address the above problems, we propose a Serial Encoding and Emotion-Knowledge interaction (SEEK) method for empathetic dialogue generation. We use a fine-grained encoding strategy which is more sensitive to the emotion dynamics (emotion flow) in the conversations to predict the emotion-intent characteristic of response. Besides, we design a novel framework to model the interaction between knowledge and emotion to generate more sensible response. Extensive experiments on EMPATHETICDIALOGUES demonstrate that SEEK outperforms the strong baselines in both automatic and manual evaluations.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Lanrui Wang"
        },
        {
            "affiliations": [],
            "name": "Jiangnan Li"
        },
        {
            "affiliations": [],
            "name": "Zheng Lin"
        },
        {
            "affiliations": [],
            "name": "Fandong Meng"
        },
        {
            "affiliations": [],
            "name": "Chenxu Yang"
        },
        {
            "affiliations": [],
            "name": "Weiping Wang"
        },
        {
            "affiliations": [],
            "name": "Jie Zhou"
        }
    ],
    "id": "SP:6ec04183cfb4b646e58f4a5bbb92b7121252b166",
    "references": [
        {
            "authors": [
                "Antoine Bosselut",
                "Hannah Rashkin",
                "Maarten Sap",
                "Chaitanya Malaviya",
                "Asli Celikyilmaz",
                "Yejin Choi"
            ],
            "title": "COMET: commonsense transformers",
            "year": 2019
        },
        {
            "authors": [
                "Shaojie Jiang",
                "Pengjie Ren",
                "Christof Monz",
                "Maarten de Rijke."
            ],
            "title": "Improving neural response diversity with frequency-aware cross-entropy loss",
            "venue": "The World Wide Web Conference, WWW 2019, San Francisco, CA, USA, May 13-17, 2019, pages",
            "year": 2019
        },
        {
            "authors": [
                "Hyunwoo Kim",
                "Byeongchang Kim",
                "Gunhee Kim."
            ],
            "title": "Perspective-taking and pragmatics for generating empathetic responses focused on emotion causes",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Wongyu Kim",
                "Youbin Ahn",
                "Donghyun Kim",
                "Kyong-Ho Lee."
            ],
            "title": "Emp-rft: Empathetic response generation via recognizing feature transitions between utterances",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the",
            "year": 2022
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba."
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.",
            "year": 2015
        },
        {
            "authors": [
                "Jiwei Li",
                "Michel Galley",
                "Chris Brockett",
                "Jianfeng Gao",
                "Bill Dolan."
            ],
            "title": "A diversity-promoting objective function for neural conversation models",
            "venue": "NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Com-",
            "year": 2016
        },
        {
            "authors": [
                "Qintong Li",
                "Hongshen Chen",
                "Zhaochun Ren",
                "Zhumin Chen",
                "Zhaopeng Tu",
                "Jun Ma."
            ],
            "title": "Empgan: Multi-resolution interactive empathetic dialogue generation",
            "venue": "CoRR, abs/1911.08698.",
            "year": 2019
        },
        {
            "authors": [
                "Qintong Li",
                "Piji Li",
                "Zhumin Chen",
                "Zhaochun Ren."
            ],
            "title": "Empathetic dialogue generation via knowledge enhancing and emotion dependency modeling",
            "venue": "CoRR, abs/2009.09708.",
            "year": 2020
        },
        {
            "authors": [
                "Yunlong Liang",
                "Fandong Meng",
                "Ying Zhang",
                "Yufeng Chen",
                "Jinan Xu",
                "Jie Zhou."
            ],
            "title": "Infusing multisource knowledge with heterogeneous graph neural network for emotional conversation generation",
            "venue": "Thirty-Fifth AAAI Conference on Artificial Intelli-",
            "year": 2021
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "Rouge: A package for automatic evaluation of summaries",
            "venue": "Text summarization branches out, pages 74\u201381.",
            "year": 2004
        },
        {
            "authors": [
                "Zhaojiang Lin",
                "Andrea Madotto",
                "Jamin Shin",
                "Peng Xu",
                "Pascale Fung."
            ],
            "title": "MoEL: Mixture of empathetic listeners",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Confer-",
            "year": 2019
        },
        {
            "authors": [
                "Chia-Wei Liu",
                "Ryan Lowe",
                "Iulian Serban",
                "Michael Noseworthy",
                "Laurent Charlin",
                "Joelle Pineau."
            ],
            "title": "How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation",
            "venue": "Pro-",
            "year": 2016
        },
        {
            "authors": [
                "Siyang Liu",
                "Chujie Zheng",
                "Orianna Demasi",
                "Sahand Sabour",
                "Yu Li",
                "Zhou Yu",
                "Yong Jiang",
                "Minlie Huang."
            ],
            "title": "Towards emotional support dialog systems",
            "venue": "CoRR, abs/2106.01144.",
            "year": 2021
        },
        {
            "authors": [
                "Navonil Majumder",
                "Pengfei Hong",
                "Shanshan Peng",
                "Jiankun Lu",
                "Deepanway Ghosal",
                "Alexander Gelbukh",
                "Rada Mihalcea",
                "Soujanya Poria."
            ],
            "title": "MIME: MIMicking emotions for empathetic response generation",
            "venue": "Proceedings of the 2020 Con-",
            "year": 2020
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, July 6-12, 2002, Philadelphia,",
            "year": 2002
        },
        {
            "authors": [
                "Sasank Chilamkurthy",
                "Benoit Steiner",
                "Lu Fang",
                "Junjie Bai",
                "Soumith Chintala."
            ],
            "title": "Pytorch: An imperative style, high-performance deep learning library",
            "venue": "CoRR, abs/1912.01703.",
            "year": 2019
        },
        {
            "authors": [
                "Jeffrey Pennington",
                "Richard Socher",
                "Christopher D. Manning."
            ],
            "title": "Glove: Global vectors for word representation",
            "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014,",
            "year": 2014
        },
        {
            "authors": [
                "Alec Radford",
                "Karthik Narasimhan",
                "Tim Salimans",
                "Ilya Sutskever"
            ],
            "title": "Improving language understanding by generative pre-training",
            "year": 2018
        },
        {
            "authors": [
                "Hannah Rashkin",
                "Eric Michael Smith",
                "Margaret Li",
                "Y-Lan Boureau."
            ],
            "title": "Towards empathetic opendomain conversation models: A new benchmark and dataset",
            "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL",
            "year": 2019
        },
        {
            "authors": [
                "Sahand Sabour",
                "Chujie Zheng",
                "Minlie Huang."
            ],
            "title": "CEM: commonsense-aware empathetic response generation",
            "venue": "CoRR, abs/2109.05739.",
            "year": 2021
        },
        {
            "authors": [
                "Maarten Sap",
                "Ronan Le Bras",
                "Emily Allaway",
                "Chandra Bhagavatula",
                "Nicholas Lourie",
                "Hannah Rashkin",
                "Brendan Roof",
                "Noah A. Smith",
                "Yejin Choi."
            ],
            "title": "ATOMIC: an atlas of machine commonsense for if-then reasoning",
            "venue": "The Thirty-Third AAAI Con-",
            "year": 2019
        },
        {
            "authors": [
                "Ashish Sharma",
                "Inna W. Lin",
                "Adam S. Miner",
                "David C. Atkins",
                "Tim Althoff."
            ],
            "title": "Towards facilitating empathic conversations in online mental health support: A reinforcement learning approach",
            "venue": "CoRR, abs/2101.07714.",
            "year": 2021
        },
        {
            "authors": [
                "Ashish Sharma",
                "Adam S. Miner",
                "David C. Atkins",
                "Tim Althoff."
            ],
            "title": "A computational approach to understanding empathy expressed in text-based mental health support",
            "venue": "CoRR, abs/2009.08441.",
            "year": 2020
        },
        {
            "authors": [
                "Lei Shen",
                "Yang Feng."
            ],
            "title": "CDL: curriculum dual learning for emotion-controllable response generation",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020, pages 556\u2013566. As-",
            "year": 2020
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N. Gomez",
                "Lukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in Neural Information Processing Systems 30: Annual Conference on Neural",
            "year": 2017
        },
        {
            "authors": [
                "Anuradha Welivita",
                "Pearl Pu."
            ],
            "title": "A taxonomy of empathetic response intents in human social conversations",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020, Barcelona, Spain (Online), December 8-13,",
            "year": 2020
        },
        {
            "authors": [
                "Anuradha Welivita",
                "Yubo Xie",
                "Pearl Pu."
            ],
            "title": "A large-scale dataset for empathetic response generation",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Domini-",
            "year": 2021
        },
        {
            "authors": [
                "Chujie Zheng",
                "Yong Liu",
                "Wei Chen",
                "Yongcai Leng",
                "Minlie Huang."
            ],
            "title": "Comae: A multi-factor hierarchical framework for empathetic response generation",
            "venue": "Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, Online",
            "year": 2021
        },
        {
            "authors": [
                "Peixiang Zhong",
                "Di Wang",
                "Pengfei Li",
                "Chen Zhang",
                "Hao Wang",
                "Chunyan Miao."
            ],
            "title": "CARE: commonsense-aware emotional response generation with latent concepts",
            "venue": "Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-",
            "year": 2021
        },
        {
            "authors": [
                "Peixiang Zhong",
                "Di Wang",
                "Pengfei Li",
                "Chen Zhang",
                "Hao Wang",
                "Chunyan Miao."
            ],
            "title": "CARE: commonsense-aware emotional response generation with latent concepts",
            "venue": "Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-",
            "year": 2021
        },
        {
            "authors": [
                "Peixiang Zhong",
                "Di Wang",
                "Chunyan Miao."
            ],
            "title": "An affect-rich neural conversational model with biased attention and weighted cross-entropy loss",
            "venue": "The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative",
            "year": 2019
        },
        {
            "authors": [
                "Hao Zhou",
                "Minlie Huang",
                "Tianyang Zhang",
                "Xiaoyan Zhu",
                "Bing Liu."
            ],
            "title": "Emotional chatting machine: Emotional conversation generation with internal and external memory",
            "venue": "Proceedings of the Thirty-Second AAAI Conference on Artificial Intelli-",
            "year": 2018
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Enriching dialogue systems with human characteristics and capabilities is a hotspot in the humanlike dialogue system research area. Empathy, which is used extensively in psychological counselling (Sharma et al., 2021; Liu et al., 2021; Sharma et al., 2020), is a key trait of everyday human conversations. In contrast to generating responses with\n\u2217 Zheng Lin is the corresponding author. 1The code is available at https://github.com/\nwlr737/EMNLP2022-SEEK\ncontrolled emotions (Zhou et al., 2018; Zheng et al., 2021), the key to the empathetic dialogue system is to understand the user\u2019s emotions and generate appropriate responses. Several works concentrate on improving the empathetic models\u2019 ability to capture contextual emotions by emotion mimicry (Majumder et al., 2020), feedback-based adversarial generating (Li et al., 2019), or the mixture of experts (Lin et al., 2019). On the other hand, Sabour et al. (2021); Li et al. (2020) introduce commonsense knowledge into empathetic models so as to better perceive implicit semantic information and generate more informative and empathetic response.\nHowever, the existing works are all about the dialogue-level emotional perception (Lin et al.,\nar X\niv :2\n21 0.\n11 71\n5v 3\n[ cs\n.C L\n] 1\n3 N\nov 2\n02 2\n2019; Majumder et al., 2020; Li et al., 2019; Sabour et al., 2021; Li et al., 2020). Since emotions change dynamically throughout conversations, the coarse modeling method at the dialogue level (recognizing the emotion of the whole conversation context) cannot capture the process of emotional dynamics and makes it difficult to predict response emotions. Welivita and Pu (2020) have studied the shifting pattern of the utterances and drawn two graphs to show the most common emotion-intent flow patterns (with a frequency \u2265 5) throughout the first four dialogue turns and the global exchanging trends of emotion-intent between speakers and listeners in the EMPATHETICDIALOGUES dataset. For instance, in the first case illustrated in Fig. 1, the speaker\u2019s emotion shifts from afraid at the beginning of the conversation to an embarrassed selfdeprecation about previous experience of fearing heights (sharing such a funny story). Accordingly, it is much better that the dialogue agent should express the same self-deprecating sentiment like the gold response. Nevertheless, the baseline models have difficulty capturing subtle changes in the speaker\u2019s emotions and can only provide response according to the fear detected. Moreover, merely introducing knowledge without making emotionally logical choices may lead to logical conflicts between knowledge and emotion in the generated responses. As illustrated in the second case illustrated in Fig. 1, the CEM (Sabour et al., 2021) model chooses the wrong knowledge and is unable to correctly give empathetic responses with nostalgic overtones, which makes knowledge and emotion come into conflict.\nTo this end, we propose a Serial Encoding and Emotion-Knowledge interaction (SEEK) method for empathetic dialogue generation. To achieve a more fine-grained perception of emotional dynamics, we use an utterance-level encoding strategy which is more sensitive to the emotion flow in the conversations and able to predict the emotion characteristic of the response. We further introduce two new emotion-intent identification tasks to understand contextual emotion and predict the emotional and intentional trait of responses. For the problem of conflicts between knowledge and emotions, we also design a framework modeling the process of bi-directional interaction between them. Extensive experimental results on the utterance-level annotated EMPATHETICDIALOGUES (ED) dataset (Welivita and Pu, 2020) demonstrate that SEEK outper-\nforms the strong baseline with both automatic and manual evaluation metrics. Our contributions are summarized as follows:\n\u2022 To the best of our knowledge, our work is the first to model the emotion flow that involves the process of emotional dynamics in the task of empathetic dialogue generation. In addition to the coarse emotion at the dialogue level, we introduce fine-grained emotions at the utterance level.\n\u2022 By modelling the bi-directional interactive selection process between commonsense knowledge and emotions, we have improved not only the ability to recognize contextual emotions, but also the ability to filter out unreasonable external knowledge, allowing the model to generate more sensible empathetic responses.\n\u2022 The automatic and manual evaluation on annotated-ED dataset shows that our proposed model is superior to the strong baselines and capable of generating more diverse and sensible empathetic responses."
        },
        {
            "heading": "2 Related Work",
            "text": "In order to control the emotion of the generated response, which is one of the fundamental characteristics of daily conversation, plenty of approaches (Zhou et al., 2018; Zheng et al., 2021; Zhong et al., 2019; Shen and Feng, 2020; Liang et al., 2021) view the target emotion as a guiding information of the models\u2019 generator.\nContrary to controlling the emotion of the target response, the task of empathetic dialogue generation requires that the models learn a proper emotion to express empathy. Numerous researchers have attempted to improve the dialogue models\u2019 ability to respond empathetically. Rashkin et al. (2019) proposed a benchmark and dataset to build and evaluate empathetic dialogue generation models. Lin et al. (2019) learned a precise emotion distribution of the response based on mixture of experts. Majumder et al. (2020) split the emotions into two classes and designed a framework to mimic the target emotion in a certain class. Li et al. (2019) utilized user feedback to build a multi-resolution adversarial training framework. In addition, Kim et al. (2021) and Kim et al. (2022) focused on the keywords and emotion cause of dialogue history\nto better understand the context-level emotion and recognize feature transitions between utterances. As well, several datasets (Liu et al., 2021; Welivita et al., 2021) of empathetic dialogue generation have been published for further research. However, most of the current approaches do not pay enough attention to the emotion flow of the conversations.\nCommonsense knowledge is widely used to build dialogue systems. Zhong et al. (2021a) utilize Commonsense knowledge graph to gain candidate words for generation. Sabour et al. (2021) adopt COMET (Bosselut et al., 2019), a pre-trained language model to generate commonsense inference for retrieving implicit information of dialogue context. In addition, Li et al. (2020) construct a graphbased framework to encode the context-knowledge graph retrieved on commonsense knowledge base. The knowledge introduced into these models might become a trigger of logical conflicts due to the absence of harmony selection."
        },
        {
            "heading": "3 Methodology",
            "text": ""
        },
        {
            "heading": "3.1 Task Formulation",
            "text": "The task of empathetic dialogue generation is to generate empathetic responses based on the historical context. Given a dialogue D, where the context and the target response are denoted as C = [C1, ..., CN\u22121] and Y respectively, with a emotion label of the whole context ec. Additionally, a given sequence of emotion-intent labels EI = [ei1, ..., eiN\u22121, eiY ] of the corresponding utterances in D, which includes the 32 emotion categories, and 9 common intent classes. Our goal is to generate the next utterance Y , which is fluent and coherent to the context, and express empathy to the speaker\u2019s situation and feelings."
        },
        {
            "heading": "3.2 Utterance and Knowledge Encoder",
            "text": "Utterance Encoding: To get a precise representation of each utterance, we firstly encode the context at the utterance level to extract the contextual information. We employ Transformer (Vaswani et al., 2017) to encode the utterance. The embedding of the input is the sum of the word embedding, positional embedding, and dialogue state embedding. Following previous work, we prepend the utterance ui with [CLS] token to obtain the utterance input Ci = [wCLS , w1, w2, ..., wLi ]. The embedding is then fed into the Transformer, and we obtain the representation:\nHUi = TRSEnc(EMBCi), (1)\nwhere HUi \u2208 RLn\u00d7d, Ln is the length of the utterance, and d is the hidden size of the encoder. We take the representation of [CLS] to represent the utterance:\nU i = HUi [0]. (2)\nKnowledge Encoding: In order to generate high-quality commonsense inferences for the corresponding context, we utilize COMET (Bosselut et al., 2019), which is a pre-trained GPT (Radford et al., 2018) language model and fine-tuned on ATOMIC (Sap et al., 2019), to generate five types of commonsense knowledge: the effect of the person (xEffect), the reaction of the person speaking the corresponding sentence (xReact), the intent before the person speaking (xIntent), what the person needs (xNeed), and what the person wants after speaking the sentence (xWant). Appending these five special relation tokens after the utterance and feeding them into COMET, we get 5 commonsense inferences texts for each relation of input utterance and then concatenate them to Ki. Similarly, we encode the knowledge text using the same Transformer Encoder, and average the encoded hidden state via mean pooling (Zhong et al., 2021b):\nHKi = TRSEnc(Ki) Ki = Mean(HKi)\n(3)"
        },
        {
            "heading": "3.3 Emotion Flow Perceiver",
            "text": "Regarding the task of emotional understanding of each utterance as a tagging task, we use a Bi-LSTM to model the emotion dynamics and the interactions between different utterances for the contextual understanding process.\nThe input of Bi-LSTM is the concatenation of the encoded utterances and knowledge:\nai = [U i;Ki], U\u0302 i = BiLSTM(W aai), (4)\nwhere W a \u2208 R2d\u00d7d is a trainable weight, and U\u0302 i \u2208 R2d represents the processed utterance representation."
        },
        {
            "heading": "3.3.1 Fine-grained Emotion Recognition",
            "text": "For better understanding of the conversation, we pass U\u0302 i through a tagging classifier to produce a fine-grained emotion-intent tagging distribution Ptag \u2208 Rt:\nPtag(eii) = Softmax(WeU\u0302 i) (5)\nwhere t is the number of emotion-intent categories. We train the tagging module with the crossentropy loss between the predicted distribution and the ground truth label for a conversation context:\nLemo = \u2212 N\u22121\u2211 i=1 log(Ptag(eii)). (6)"
        },
        {
            "heading": "3.3.2 Response Emotion-Intent Prediction",
            "text": "The shift in emotion and intent in empathetic dialogue conforms to an intuitive pattern. We use the attention mechanism to learn the shift pattern of emotion and intent between utterances.\nh\u0302pre = attention([U\u03021, U\u03022, ..., U\u0302N\u22121]), Ppre = Softmax(Wph\u0302pre), (7)\nwhere h\u0302pre \u2208 R2d is the representation of the predicted emotion-intent characteristic of response, and W p \u2208 R2d\u00d7t is the weight vector for the linear layer. Ppre denotes the predicted distribution of the emotion-intent of the target response, t is the number of emotion and intent categories.\nDuring training, we then minimize the crossentropy loss between the emotion-intent distribution of the predicted response Ppre and the ground truth label eiN of the target response :\nLpre = \u2212log(Ppre(eiN )). (8)"
        },
        {
            "heading": "3.3.3 Dialogue Emotion Recognition",
            "text": "The sequence of utterances representation not only has the contextual information of utterances themselves but also indicates the emotional trait of the\nwhole dialogue. Similarly, we employ the attention mechanism to summarize the holistic emotion label, based on the sequence [U\u03021, U\u03022, ..., U\u0302N\u22121]:\nh\u0302dia = attention([U\u03021, U\u03022, ..., U\u0302N\u22121]), Pdia = Softmax(Wdh\u0302dia), (9)\nwhere hdia \u2208 R2d, and W d \u2208 R2d\u00d7q is the weight vector for the linear layer. The Pdia is the distribution of the dialogue emotion, q is the number of available emotion categories.\nThe ground truth label of the dialogue emotion is denoted as e\u2217. The cross-entropy loss utilized to optimize the process of summarizing the conversational emotion is calculated by:\nLdia = \u2212log(Pdia(e\u2217)). (10)"
        },
        {
            "heading": "3.4 Knowledge Selecting Decoder",
            "text": "Merely introducing commonsense knowledge into empathetic models without making an emotionally logical selection to is not ideal. Sabour et al. (2021) select commonsense inferences with an implicit procedure. On the contrary, our method models the process of bi-directional interactions between emotion and knowledge of the corresponding utterance in the conversations.\nWe adopt s layers of Cross-Attention Transformer to perform the harmony of emotion and knowledge. Since the utterance representation sequence [U\u03021, U\u03022, ..., U\u0302N\u22121] passed through the three tasks of emotion, it contains emotional characteristics of the corresponding utterances. The\ninputs of Cross-Attention Knowledge Selector are composed of the utterance representation sequence acting as the query vector, the key and value vector which are both the knowledge text generated from the COMET model K = [K1, ...KN\u22121]. The hidden representation of selected knowledge is as follows:\nS = Cross-Attention(U\u0302 ,K,K), (11)\nwhere S \u2208 RLs\u00d7d, Ls is the maximum length of the knowledge text, and d is the hidden size of the model.\nAfterward,we average the harmonized knowledge via mean pooling (Zhong et al., 2021b):\nS = pooling(S). (12)\nWe take the Transformer Decoder as the backbone of the Decoder. We perform a concatenation operation between the averaged harmonized knowledge S and the prediction of response representation h\u0302pre to get a mixture of these two types of information to represent the [SOS] token:\n[SOS] = W k([S; h\u0302pre]) (13)\nwhere W k \u2208 R2d\u00d7d is the weight vector for the linear layer.\nAt the training stage, we prepend the target response uN = [y1, ..., yT ] with the [SOS] token and get the final input of the Decoder Y = [[SOS], y1, ..., yT ].The training loss is the standard negative log-likelihood (NLL) loss on the target response uN :\nLnll = \u2212 T\u2211 t=1 log(P (yt|C, y<t). (14)"
        },
        {
            "heading": "3.5 Training Objectives",
            "text": "During the training process, we need to minimize three classification losses and a response generation loss. The classification losses are weighted equally:\nLcls = Ltag + Lpre + Ldia. (15) In order to improve the diversity of the generated response, we adopt Frequency-Aware CrossEntropy (FACE) (Jiang et al., 2019) as an additional loss to penalize high-frequency tokens, similar to Sabour et al. (2021):\nLdiv = \u2212 T\u2211 t=1 V\u2211 i=1 wi\u03b4t(ci)log(P (yt|C, y<t),\n(16)\nwhere wi is a frequency weight value of the i-th token in the vocabulary V , ci represents a candidate token in the vocabulary and \u03b4t(ci) is a function indicate whether ci equals to the ground truth token yt.\nLastly, all the parameters for our proposed model are jointly trained and optimized by minimizing the weighted sum of the three mentioned losses:\nL = \u03b1Lnll + \u03b2Lcls + \u03b3Ldiv, (17)\nwhere \u03b1, \u03b2, and \u03b3 are hyper-parameters used to balance three losses. In our experiments, we set \u03b1= 1, \u03b2= 1, and \u03b3= 1.5."
        },
        {
            "heading": "4 Experimental Setup",
            "text": ""
        },
        {
            "heading": "4.1 Dataset",
            "text": "Our experiments are conducted on the utterancelevel annotated EMPATHETICDIALOGUES (ED) (Rashkin et al., 2019; Welivita and Pu, 2020). ED is a large-scale multi-turn dialogue dataset that contains 25k empathetic conversations between a speaker and a listener. ED provides 32 evenly distributed emotion labels which are common in daily chats. However, the emotion labels of ED dataset are on the context level, there are no explicit signals for utterance-level emotions. Welivita and Pu (2020) annotated ED dataset with 41 new categories of utterance-level emotional and intentional labels, which provide fine-grained information about the empathetic dialogues in ED dataset."
        },
        {
            "heading": "4.2 Baselines",
            "text": "We select several strong baseline models for comparison, including: MIME: Majumder et al. (2020) proposed a Transformer-based model employing mimicry strategy to sample the emotion of target responses based on the detected user emotion. The emotions are separated into two classes (positive and negative). The model utilizes a VAE to get the representations of the mimicking and non-mimicking emotions. EmpDG (Li et al., 2019): An adversarial training framework is composed of an empathetic generator and a semantic-emotional discriminator. The discriminator ensures that the responses generated by the generator are relevant to the context and also empathetic. The converged generator trained on the adversarial framework can generate empathetic responses with high diversity. KEMP: Li et al. (2020) employed a graph encoder to extract the contextual and concept information\nof the context graph constructed on external knowledge. The knowledge-enriched context graph contains emotional dependencies which helps to understand the emotion characteristic of conversations. CEM: Sabour et al. (2021) use COMET to generate commonsense knowledge based on the last utterance said by the speaker in dialogue. The authors use five specific prefixes (xIntent, xEffect, xWant, xNeed, xReact) to obtain five types of knowledge corresponding to the last utterance. The model can generate more informative empathetic responses."
        },
        {
            "heading": "4.3 Implementation Details",
            "text": "We implement our model using Pytorch (Paszke et al., 2019), and utilize Adam (Kingma and Ba, 2015) optimizer to optimize the model. We use 300-dimensional pre-trained GloVE vectors (Pennington et al., 2014) to initialize the word embeddings, which are shared between the encoder and the decoder. During the training stage, the learning rate is initialed as 0.0001 and we vary the learning rate following Vaswani et al. (2017). Our model is trained on one NVIDIA Geforce RTX 3090 GPU using a batch size of 32 and the early stopping strategy. For other settings, such as dropout rate, maximum decoding steps, and so forth, we keep the same as Sabour et al. (2021). The training time of SEEK is about 3 hours for around 27000 iterations."
        },
        {
            "heading": "4.4 Automatic Evaluation",
            "text": "Since Liu et al. (2016) had proved that some automatic metrics based on word overlapping might be improper to evaluate the dialogue systems, such as BLEU (Papineni et al., 2002) and ROUGE (Lin, 2004), we adopt Perplexity (PPL) and Distinct-n (Dist-n) (Li et al., 2016) as the main automatic metrics of generation quality. For the conversational emotion recognition and our newly introduced two tasks including fine-grained emotion-intent tagging and response emotion-intent prediction, we employ dialogue emotion accuracy (DE Acc.), utterance emotion-intent accuracy (UEI Acc.) and response emotion-intent accuracy (REI Acc.).\nTo examine whether SEEK can generate more sensible response with fine-grained emotion recognition, we compare the performance of our model with the strong baselines. As shown in Table 1, the diversity scores (Dist-1 and Dist-2) of SEEK outperform all of the baselines, which indicates our models can generate more informative response based on the external knowledge. We attribute this improvement to the knowledge selector and the predicted emotion of the target responses, with which the cross-attention mechanism helps to select the related knowledge based on the contextual information of utterances, and the predicted vector provides\nadditional information of the generating process.\nTo prove if SEEK has better understanding of the dialogue emotion, we list the accuracy of the baselines and our proposed model. Remarkably, SEEK surpasses all of the baselines by a large margin, we attribute the increase of performance to the two fine-grained tasks we introduced. The better comprehension of the utterances in dialogue, the more accuracy it takes. In terms of the two new accuracy scores, UEI Accuracy and REI Accuracy, SEEK reaches satisfying performances, as the number of the categories of these two tasks are 41."
        },
        {
            "heading": "4.5 Human Evaluation",
            "text": "Following previous works, we conduct a human evaluation based on three aspects: coherence (Coh.): How much does the response relevant to the context? empathy (Emp.): How much does the model know about the speaker\u2019s situation and emotion characteristic? Does the model respond empathetically enough or give suggestions? fluency (Flu.): How much the generated response obey the grammar? We randomly choose 100 dialogues and assign the responses generated by the models to three crowd-sourced workers for the evaluation. Each aspect is on a scale of 1 to 5. Moreover, considering the variation between different individuals, we conduct another human A/B test to directly compare our method with other baselines. Three professional annotators score the questionnaire of the response pairs to choose one of the responses in random order or select \"Tie\" when the quality of provided sentence is difficult to distinguish. As the results of the human rating and A/B test are shown in Table 3 and table 4, SEEK outperforms the baselines in all the three aspects."
        },
        {
            "heading": "4.6 Ablation Studies",
            "text": "To study the effect of tasks and modules employed in our model, we remove the newly introduced tasks and the interaction process between emotion and knowledge. Additionally, we replace the knowledge type and encoding strategy respectively. The results are demonstrated in Table 2.\nRemoving the task of fine-grained Utterance Emotion-Intent tagging and Response EmotionIntent prediction (w/o Utter, w/o Res, and w/o Utter & Res) causes the drop of accuracy of dialogue emotion recognition and generative quality, as these variants lose the fine-grained understanding of the dialogue and the ability to predict the emotion-intent characteristics of the target response.\nThe margin between the variant (w/o Emo) without emotional harmonization of the knowledge and SEEK proves the importance of the interaction between knowledge and emotion-intent from the Knowledge Selection module of our model. The variant without knowledge (w/o Know) indicates the importance of external knowledge for the diversity of responses the model generated.\nMoreover, the decreased performance by replacing the type of knowledge + Others Know and the encoding strategy + Context Enc shows the superiority of our method. Using Others type of knowledge in our model rather than PersonX results in a considerable decrease in all performance, which indicates that the PersonX type of commonsense helps the model to understand the utterances more effectively. The encoding strategy employed\nby baselines (as the variant + Context Enc used) emphasizes on overall understanding of the whole conversation, ignoring an accurate grasp of utterances, which leads to a decline of performance.\nRemarkably, the UEI Accuracy of w/o Utter and REI Accuracy of w/o Res are higher than SEEK. This is possibly due to the noise of the utterance label of annotated ED dataset and the subtle differences between intent categories (e.g. agreeing and acknowledging, counselling and questioning), which means the classification supervision signal of utterances or the response will make the input vector of attention module harder and lose some information of other classes. The loss of information about the hidden states may confuse another classifier and leads to a decrease in accuracy. In any case, although there exists a trade-off between these two tasks, they can simultaneously improve the ability of the model to generate more sensible empathetic responses by modeling the emotion flow."
        },
        {
            "heading": "4.7 Case Study",
            "text": "The first case of figure 1 illustrates how emotion shifts during a multi-turn conversation. For better\ncompares generated responses of our model and the baselines, we show two of the generated result of our model and baselines in Table 5. In the first case, the baselines failed to give responses with nostalgic overtones, similar to the commonsense knowledge demonstrated in figure 1, where CEM choose the wrong knowledge to generate response with a happy emotion and the intent to have fun. On the contrary, SEEK successfully gives a response with more sensitive and accurate emotional perception. Similarly, in the second case, all of the baselines generate responses based on the explicit emotion guilty, without fine-grained understanding which is more accurate. Unlike the baselines, SEEK respond sensitively with sympathizing intent.\nWe further draw a heat map to illustrate the crossattention weights of commonsense knowledge in a certain case. The detailed information of that case and analysis will be shown in Appendix A."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this paper, we study the task of empathetic dialogue generation. The strong baselines ignore emo-\ntion flow of the conversations. We therefore proposed a Serial Encoding and Emotion-Knowledge interaction (SEEK) method for empathetic dialogue generation, to predict the correct emotion of the target response by perceiving the emotion flow of the context and harmonizing commonsense knowledge with fine-grained emotions to avoid conflicts. Experiments on the utterance-level annotated EMPATHETICDIALOGUES show that our model outperforms the baselines, and the ablation studies indicate that all the components of our model, the encoding strategy, and the commonsense knowledge work.\nIn the future, we will focus on further usage (e.g. providing online-emotion aid) of empathetic systems and try to improve normalization capabilities of our model on other datasets.\nLimitations\nThe limitation of our work mainly comes from the shortage of datasets in the task of empathetic dialogue generation. Although there are several newly released large-scale datasets (Liu et al., 2021; Welivita et al., 2021), most of the research can only be carried out on the English corpus EMPATHETICDIALOGUES. Another limitation is the problem of evaluation metrics. As mentioned in Liu et al. (2016), the scores of standard automatic evaluation metrics are not consistent with human evaluation results. The lack of task-specifically automatic metrics makes it troublesome for evaluating empathetic dialogue generation.\nEthical Considerations\nThe data (Rashkin et al., 2019; Welivita and Pu, 2020) used in our work is all drawn from opensource datasets. The conversations of the dataset are around given emotions and carried out by employed crowd-sourced workers, with no personal privacy issues involved."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was supported by National Natural Science Foundation of China (No. 61976207, No. 61906187)."
        },
        {
            "heading": "A More Cases",
            "text": "To show the process of knowledge selection of our proposed model, we clearly show the attention weights on the commonsense knowledge in Table 6. We firstly get the weights matrix from Cross-Attention outputs and search the words in the knowledge text by the index of high-value elements. To directly show the selecting process, we mark the knowledge words based on the color in the heat map we drew: the higher weight the knowledge words have the darker blue marks them in the table.\nIn this case, the context of the case is mainly about a couple of parents asking for the gender of the baby in a hospital and the COMET totally model generates 25 commonsense inferences based on it. The speaker reacts excitedly to knowing the gender of their baby which infers something to celebrate, and SEEK chooses the correct knowledge and expresses congratulation."
        }
    ],
    "title": "Empathetic Dialogue Generation via Sensitive Emotion Recognition and Sensible Knowledge Selection",
    "year": 2022
}