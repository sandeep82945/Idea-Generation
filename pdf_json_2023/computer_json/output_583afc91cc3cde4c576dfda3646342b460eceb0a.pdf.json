{
    "abstractText": "Robotic navigation in unknown, cluttered environments with limited sensing capabilities poses significant challenges in robotics. Local trajectory optimization methods, such as Model Predictive Path Intergal (MPPI), are a promising solution to this challenge. However, global guidance is required to ensure effective navigation, especially when encountering challenging environmental conditions or navigating beyond the planning horizon. This study presents the GP-MPPI, an online learning-based control strategy that integrates MPPI with a local perception model based on Sparse Gaussian Process (SGP). The key idea is to leverage the learning capability of SGP to construct a variance (uncertainty) surface, which enables the robot to learn about the navigable space surrounding it, identify a set of suggested subgoals, and ultimately recommend the optimal subgoal that minimizes a predefined cost function to the local MPPI planner. Afterward, MPPI computes the optimal control sequence that satisfies the robot and collision avoidance constraints. Such an approach eliminates the necessity of a global map of the environment or an offline training process. We validate the efficiency and robustness of our proposed control strategy through both simulated and real-world experiments of 2D autonomous navigation tasks in complex unknown environments, demonstrating its superiority in guiding the robot safely towards its desired goal while avoiding obstacles and escaping entrapment in local minima. The GPU implementation of GP-MPPI, including the supplementary video, is available at https://github.com/IhabMohamed/GP-MPPI.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ihab S. Mohamed"
        },
        {
            "affiliations": [],
            "name": "Mahmoud Ali"
        },
        {
            "affiliations": [],
            "name": "Lantao Liu"
        }
    ],
    "id": "SP:98cf2d30b26f5f7110b632e783120663b4a77145",
    "references": [
        {
            "authors": [
                "S. Koenig",
                "M. Likhachev"
            ],
            "title": "Fast replanning for navigation in unknown terrain",
            "venue": "IEEE Trans. on Robotics, vol. 21, no. 3, pp. 354\u2013363, 2005.",
            "year": 2005
        },
        {
            "authors": [
                "M. Otte",
                "E. Frazzoli"
            ],
            "title": "RRTX: Asymptotically optimal single-query sampling-based motion planning with quick replanning",
            "venue": "The International Journal of Robotics Research, vol. 35, no. 7, pp. 797\u2013822, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "L. Hewing",
                "K.P. Wabersich",
                "M. Menner",
                "M.N. Zeilinger"
            ],
            "title": "Learningbased model predictive control: Toward safe learning in control",
            "venue": "Annual Review of Control, Robot, and Auto. Syst., vol. 3, pp. 269\u2013296, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "B. Brito",
                "M. Everett",
                "J.P. How",
                "J. Alonso-Mora"
            ],
            "title": "Where to go next: Learning a subgoal recommendation policy for navigation in dynamic environments",
            "venue": "IEEE Robot. and Automat. Lett., vol. 6, no. 3, pp. 4616\u2013 4623, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "M. Lodel",
                "B. Brito",
                "A. Serra-G\u00f3mez",
                "L. Ferranti",
                "R. Babu\u0161ka",
                "J. Alonso-Mora"
            ],
            "title": "Where to look next: Learning viewpoint recommendations for informative trajectory planning",
            "venue": "Int. Conf. on Robot. and Automat. (ICRA). IEEE, 2022, pp. 4466\u20134472.",
            "year": 2022
        },
        {
            "authors": [
                "C. Greatwood",
                "A.G. Richards"
            ],
            "title": "Reinforcement learning and model predictive control for robust embedded quadrotor guidance and control",
            "venue": "Autonomous Robots, vol. 43, pp. 1681\u20131693, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "K. Lowrey",
                "A. Rajeswaran",
                "S. Kakade",
                "E. Todorov",
                "I. Mordatch"
            ],
            "title": "Plan online, learn offline: Efficient learning and exploration via modelbased control",
            "venue": "Int. Conf. on Learning Representations, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J. Wang",
                "M.T. Fader",
                "J.A. Marshall"
            ],
            "title": "Learning-based model predictive control for improved mobile robot path following using gaussian processes and feedback linearization",
            "venue": "Journal of Field Robotics, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "J. Minguez",
                "L. Montano"
            ],
            "title": "Nearness diagram (ND) navigation: collision avoidance in troublesome scenarios",
            "venue": "IEEE Trans. on Robot. and Automat., vol. 20, no. 1, pp. 45\u201359, 2004.",
            "year": 2004
        },
        {
            "authors": [
                "V. Sezer",
                "M. Gokasan"
            ],
            "title": "A novel obstacle avoidance algorithm: Follow the gap method",
            "venue": "Robotics and Autonomous Systems, vol. 60, no. 9, pp. 1123\u20131134, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "C. Ye",
                "P. Webb"
            ],
            "title": "A sub goal seeking approach for reactive navigation in complex unknown environments",
            "venue": "Robotics and Autonomous Systems, vol. 57, no. 9, pp. 877\u2013888, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "M. Mujahed",
                "D. Fischer",
                "B. Mertsching"
            ],
            "title": "Admissible gap navigation: A new collision avoidance approach",
            "venue": "Robotics and autonomous systems, vol. 103, pp. 93\u2013110, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "G. Williams",
                "A. Aldrich",
                "E.A. Theodorou"
            ],
            "title": "Model predictive path integral control: From theory to parallel computation",
            "venue": "Journal of Guidance, Control, and Dynamics, vol. 40, no. 2, pp. 344\u2013357, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "I.S. Mohamed",
                "K. Yin",
                "L. Liu"
            ],
            "title": "Autonomous navigation of AGVs in unknown cluttered environments: log-MPPI control strategy",
            "venue": "IEEE Robot. and Automat. Lett., vol. 7, no. 4, pp. 10 240\u201310 247, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "A. Savitzky",
                "M.J. Golay"
            ],
            "title": "Smoothing and differentiation of data by simplified least squares procedures.",
            "venue": "Analytical chemistry,",
            "year": 1964
        },
        {
            "authors": [
                "C.E. Rasmussen",
                "C.K. Williams"
            ],
            "title": "Gaussian processes for machine learning",
            "venue": "MIT press,",
            "year": 2005
        },
        {
            "authors": [
                "N. Lawrence",
                "M. Seeger",
                "R. Herbrich"
            ],
            "title": "Fast sparse Gaussian process methods: The informative vector machine",
            "venue": "Proc. of the 16th annual conf. on neural information processing syst., 2003, pp. 609\u2013616.",
            "year": 2003
        },
        {
            "authors": [
                "E. Snelson",
                "Z. Ghahramani"
            ],
            "title": "Sparse gaussian processes using pseudo-inputs",
            "venue": "Advances in neural information processing systems, vol. 18, p. 1257, 2006.",
            "year": 2006
        },
        {
            "authors": [
                "M. Titsias"
            ],
            "title": "Variational learning of inducing variables in sparse gaussian processes",
            "venue": "Artificial intell. and statist. PMLR, 2009, pp. 567\u2013574.",
            "year": 2009
        },
        {
            "authors": [
                "I.S. Mohamed",
                "G. Allibert",
                "P. Martinet"
            ],
            "title": "Sampling-based MPC for constrained vision based control",
            "venue": "IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS), 2021, pp. 3753\u20133758.",
            "year": 2021
        },
        {
            "authors": [
                "J. Yin",
                "Z. Zhang",
                "E. Theodorou",
                "P. Tsiotras"
            ],
            "title": "Trajectory distribution control for model predictive path integral control using covariance steering",
            "venue": "Int. Conf. on Robot. and Automat. (ICRA), 2022, pp. 1478\u2013 1484.",
            "year": 2022
        },
        {
            "authors": [
                "C. Tao",
                "H. Kim",
                "N. Hovakimyan"
            ],
            "title": "RRT guided model predictive path integral method",
            "venue": "arXiv preprint arXiv:2301.13143, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "M. Ali",
                "L. Liu"
            ],
            "title": "Light-weight pointcloud representation with sparse gaussian process",
            "venue": "Int. Conf. on Robot. and Automat. (ICRA), 2023, pp. 4931\u20134937.",
            "year": 2023
        },
        {
            "authors": [
                "M. Ali",
                "L. Liu"
            ],
            "title": "GP-Frontier for local mapless navigation",
            "venue": "Int. Conf. on Robot. and Automat. (ICRA), 2023, pp. 10 047\u201310 053.",
            "year": 2023
        },
        {
            "authors": [
                "B. Yamauchi"
            ],
            "title": "Frontier-based exploration using multiple robots",
            "venue": "Proc. of the second int. conf. on Autonomous agents, 1998, pp. 47\u201353.",
            "year": 1998
        },
        {
            "authors": [
                "K. Yan",
                "B. Ma"
            ],
            "title": "Mapless navigation based on 2D LIDAR in complex unknown environments",
            "venue": "Sensors, vol. 20, no. 20, p. 5802, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "I.S. Mohamed",
                "G. Allibert",
                "P. Martinet"
            ],
            "title": "Model predictive path integral control framework for partially observable navigation: A quadrotor case study",
            "venue": "16th Int. Conf. on Control, Automation, Robotics and Vision (ICARCV), Shenzhen, China, Dec. 2020, pp. 196\u2013203.",
            "year": 2020
        },
        {
            "authors": [
                "A.G. d. G. Matthews",
                "M. Van Der Wilk",
                "T. Nickson",
                "K. Fujii",
                "A. Boukouvalas",
                "P. Le\u00f3n-Villagr\u00e1",
                "Z. Ghahramani",
                "J. Hensman"
            ],
            "title": "GPflow: A Gaussian process library using TensorFlow",
            "venue": "J. Mach. Learn. Res., vol. 18, no. 40, pp. 1\u20136, 2017.",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Autonomous vehicle navigation, MPPI, sparse Gaussian process (SGP), occupancy grid map path planning.\nI. INTRODUCTION AND RELATED WORK\nAutonomous navigation of mobile robots in unknown, cluttered, and unpredictable environments with limited sensor capabilities is a challenging task owing to the inherent uncertainty and complexity of such environments. To tackle this challenge, a receding-horizon strategy such as Model Predictive Control (MPC) is commonly employed. The MPC control framework allows the robot to simultaneously plan a short trajectory (sequence of actions), following which the robot executes the immediate action while planning a subsequent trajectory. To successfully achieve receding-horizon planning, the robot must consider both safety and persistent feasibility, where safety is achieved by avoiding collisions with any obstacles while executing a planned trajectory, and persistent feasibility is maintained by always generating a safe trajectory that does not result in dead-ends or local minima while progressing towards the desired goal.\nOne of the significant challenges in robot motion planning is that the desired goal is often situated beyond the planning\nAuthors are with the Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN 47408 USA (e-mail: {mohamedi, alimaa, lantao}@iu.edu) \u2217Ihab S. Mohamed and Mahmoud Ali equally contributed to this work. This work is supported by National Science Foundation with grant numbers 2006886 and 2047169.\nhorizon, which requires the use of local subgoals or cost-togo heuristics for motion safety and persistent feasibility. A common strategy is to rely on single-query motion planning algorithms, such as A\u2217 and RRTX, to identify feasible paths that direct the local planner towards its desired goal [1], [2]. For instance, the RRTX algorithm, introduced in [2], incorporates replanning techniques from Dynamic Rapidly-exploring Random Trees (DRRT) and Rapid-exploring Random Trees (RRT\u2217) algorithms to adjust the path during exploration based on environmental changes. However, due to its high computational demands, implementing this algorithm in real-time on a robot can be challenging.\nOne alternative method to achieve efficient solutions for motion planning problems is the integration of MPC with datadriven methods, also known as learning-based MPC [3]. To name a few, a subgoal planning policy using Deep Reinforcement Learning (DRL) is recently proposed to guide the local MPC planner to navigate in crowded surroundings [4], [5]. Similarly, RL was utilized to choose the next subgoal from a set of predefined possibilities [6], which guides the robot through challenging environments with dead-end corridors while also prevents the MPC planner from getting trapped in local minima. Another related work that combines learning with MPC is POLO which aims to enhance MPC performance by learning a global value function [7]. Most of these approaches typically rely on either offline training or having access to the global map of the environment. In addition, many recent studies have suggested combining Gaussian Process (GP) with MPC to learn system dynamics, leading to better control performance and robustness to uncertainty [8].\nAnother research avenue employed gap-based techniques\nar X\niv :2\n30 7.\n04 01\n9v 3\n[ cs\n.R O\n] 2\n8 Ju\nl 2 02\n3\nthat identify gaps as free spaces between obstacles, enabling a robot to move through them while avoiding local minima and obstacles. The first developed method was the Nearness Diagram (ND) [9], but many of its variants exhibited undesired oscillatory motion. To overcome these limitations, robotics researchers have developed techniques that rely on the geometry of the gap. One such technique is the Follow-the-Gap Method (FGM), which selects a gap based on its area and computes the robot\u2019s heading using the gap center\u2019s direction relative to both the robot and the final goal [10]. Another approach is the sub-goal seeking method, which assigns a cost to each sub-goal based on the goal heading error with respect to the robot and the gap heading, and then selects the sub-goal with the lowest cost (error) [11]. The Admissible Gap (AG) method [12], an iterative algorithm that takes into account the exact shape and kinematic constraints of the robot, identifies possible admissible gaps, and selects the nearest gap as the goal.\nDifferent from all these strategies, our proposed framework leverages a Sparse variant of Gaussian Process (SGP) which is a new perception model by \u201cabstracting\u201d local perception data so that the local sub-goal for navigation can be naturally extracted. Specifically, we introduce the GP-MPPI control strategy, which enhances the state-of-the-art sampling-based MPC, Model Predictive Path Integral (MPPI) [13], by incorporating the GP-subgoal recommender policy. Such a policy takes advantage of the SGP occupancy model to learn about the navigable space surrounding the robot, identifies a set of suggested subgoals, and ultimately recommends the optimal subgoal that minimizes a predefined cost function to the MPPI local planner, as demonstrated in Fig. 1. Subsequently, MPPI computes the optimal control sequence that satisfies the robot and collision avoidance constraints while moving towards the recommended subgoal, followed by executing the first optimal control u0 to the robot. In summary, the contributions of this work can be summarized as follows:\n1) We propose an online learning-based control strategy that recommends subgoals solely based on local sensory information, ensuring safety and persistent feasibility; such an approach eliminates the need for a global map of the environment or an offline training process as in RL techniques, resulting in a more flexible and agile control framework that can be easily deployed in different unexplored environments, as revealed in Section III. 2) To the best of the authors\u2019 knowledge, this is the first attempt to utilize the SGP occupancy model in conjunction with sampling-based trajectory optimization methods, specifically MPPI, to efficiently explore the navigable space surrounding the robot. 3) In Sections IV and V, we validate our GP-MPPI control strategy for collision-free navigation in complex and unknown cluttered environments, using both simulation and experimental demonstrations; by comparing it with two baseline sampling-based approaches (namely, MPPI [13], and log-MPPI [14]), we show its effectiveness in overcoming local minima that may arise when the sampled trajectories of MPPI are concentrated in high-cost regions or due to challenging environmental conditions."
        },
        {
            "heading": "II. PRELIMINARIES",
            "text": "To provide the necessary background for our proposed work, in this section, we formulate the optimal control problem and present a concise overview of the MPPI control strategy that can be utilized to address this problem, along with a brief introduction to the Sparse Gaussian Process (SGP) which is the backbone of our GP-subgoal recommender policy."
        },
        {
            "heading": "A. Problem Formulation",
            "text": "Consider a nonlinear discrete-time stochastic dynamical system\nxk+1 = f (xk,uk + \u03b4uk) , (1)\nwith xk \u2208 Rnx and uk \u2208 Rnu representing the state of the system and its control input, respectively. The disturbance introduced into the control input, \u03b4uk, is modeled as a zeromean Gaussian noise with co-variance \u03a3u. Given a finite time-horizon N , we define the control sequence U as U = [u0,u1, . . . ,uN\u22121]\n\u22a4 \u2208 RnuN and the resulting state trajectory of the system being controlled as X = [x0,x1, . . . ,xN ]\n\u22a4 \u2208 Rnx(N+1). Furthermore, X d is used to represent the ddimensional space with Xrob (xk) \u2282 X d and Xobs \u2282 X d representing the robot\u2019s occupied area and obstacles\u2019 area, respectively. Let xs and xf denote the initial and desired (goal) state of the robot, respectively. Given Xrob (xk) ,Xobs,xs, and xf , we aim to find the optimal control sequence, U, that allows the robot to safely and efficiently navigate from its initial state, xs, to the desired state, xf , by avoiding both getting stuck in local minima and collisions with obstacles, while minimizing a cost function J . The optimization problem at hand can be approached utilizing the classical MPPI control strategy described in [13]. This optimization can be mathematically expressed as in (2), with the objective of minimizing the cost function, J , which is comprised of the expectation of a combination of state terminal cost \u03d5(xN ), running cost q(xk), and control inputs uk, weighted by the positive-definite matrix R \u2208 Rnu\u00d7nu , taking into consideration the system dynamics outlined in (2b) and constraints such as collision avoidance and control constraints as stated in (2c).\nmin U\nJ = E [ \u03d5 (xN ) +\nN\u22121\u2211 k=0 ( q (xk) + 1 2 u\u22a4k Ruk )] , (2a)\ns.t. xk+1 = f (xk,uk + \u03b4uk) , \u03b4uk \u223c N (0,\u03a3u), (2b) Xrob (xk) \u2229 Xobs = \u2205, h(xk,uk) \u2264 0, (2c) x0 = xs, uk \u2208 U, xk \u2208 X. (2d)"
        },
        {
            "heading": "B. Overview of MPPI Control Strategy",
            "text": "In order to solve the optimization control problem defined in (2), MPPI leverages Monte Carlo simulation to generate a significant number of real-time simulated trajectories by propagating them from the underlying system dynamics. It then evaluates the cost-to-go of each trajectory based on a predefined cost function and updates the optimal control sequence by considering a weighted average cost from all of the simulated trajectories. More details are given in [13], [14]. Subsequently, each trajectory \u03c4i in the time-horizon N can have its cost-to-go evaluated as given in (3), where the costto-go S\u0303(\u03c4i) is calculated as the sum of the terminal state cost\n\u03d5(xN ) and the instantaneous running cost q\u0303(xk,uk, \u03b4uk,i) over all time steps. The instantaneous running cost, q\u0303, expressed in (4), is comprised of the state-dependent running cost q(xk) and the quadratic control cost q(uk, \u03b4uk), where \u03b3u = \u03bd\u22121 2\u03bd and the aggressiveness in exploring the state-space is determined by the parameter \u03bd \u2208 R+. Specifically,\nS\u0303 (\u03c4i) = \u03d5 (xN)+ N\u22121\u2211 k=0 q\u0303 (xk,uk, \u03b4uk,i)\u2200i\u2208{0,\u00b7 \u00b7 \u00b7,M\u22121}, (3)\nq\u0303= q (xk)\ufe38 \ufe37\ufe37 \ufe38 State-dep. + \u03b3u\u03b4u \u22a4 k,iR\u03b4uk,i+ u \u22a4 k R\u03b4uk,i+\n1\n2 u\u22a4k Ruk\ufe38 \ufe37\ufe37 \ufe38\nq (uk, \u03b4uk): Quadratic Control Cost\n. (4)\nAs outlined in (5) from [13], the optimal control sequence {uk}N\u22121k=0 in the vanilla MPPI algorithm is iteratively updated by taking a weighted average cost from all simulated trajectories, where S\u0303 (\u03c4m) represents the cost-to-go of the mth trajectory, and \u03bb \u2208 R+ denotes the \u201cinverse temperature\u201d, which regulates the selectiveness of the weighted average of the trajectories. After smoothing the resulting control sequence with a Savitzky-Galoy filter [15], the first control u0 is executed in the system, with the remaining sequence utilized as a warm-start for the next optimization step. Formally,\nuk \u2190 uk + \u2211M\u22121 m=0 exp ( \u22121 \u03bb S\u0303 (\u03c4m) ) \u03b4uk,m\u2211M\u22121\nm=0 exp ( \u22121 \u03bb S\u0303 (\u03c4m) ) . (5)"
        },
        {
            "heading": "C. Sparse Gaussian Process",
            "text": "Gaussian Process (GP) is a well-established non-parametric model described by a mean function m(z) and a co-variance function k(z, z\u2032) (also referred to as kernel function), where z \u2208 Rng is the input to the GP [16]; it can be mathematically expressed as f(z) \u223c GP (m(z), k (z, z\u2032)) . (6) Let D = {(zi, yi)}ni=1 denote a dataset consisting of n input-output pairs, where each output yi \u2208 R is assumed to be the sum of an unknown underlying function f(zi) and Gaussian noise \u03f5i with a zero-mean and variance \u03c32, i.e., \u03f5i \u223c N ( 0, \u03c32 ) . In the context of GP regression, to estimate the output y\u2217 for a given new input z\u2217, the following GP prediction equation is employed\np(y\u2217|y) = N (y\u2217|my(z\u2217), ky(z\u2217, z\u2217) + \u03c32), my(z) = Kzn ( \u03c32I +Knn )\u22121 y,\nky (z, z \u2032) = k (z, z\u2032)\u2212Kzn ( \u03c32I +Knn )\u22121 Knz\u2032 ,\n(7)\nwhere my(z) and ky(z, z\u2032) are the GP posterior mean and co-variance functions, respectively, while Knn \u2208 Rn\u00d7n refers to the n \u00d7 n co-variance matrix of the training inputs and Kzn \u2208 Rn is n-dimensional row vector of kernel function values between z and the training inputs, with Knz = K\u22a4zn. Achieving a more accurate GP prediction requires the optimization of hyper-parameters, such as kernel parameters \u0398 and noise variance \u03c32, by maximizing the log marginal likelihood\nlog p(y) = log [ N ( y | 0, \u03c32I +Knn )] . (8)\nThe standard GP can be computationally intensive due to its complexity of O(n3), where n represents the number of training instances. To mitigate this issue, various approximation methods, collectively known as Sparse Gaussian Process\n(SGP), have been developed as an alternative approach. Instead of using the complete training data, SGP employs a smaller set of ms training points, called inducing points Zms , resulting in a more efficient process and a lower computation complexity of O(nm2s) [17]\u2013[19]. Our present work leverages the variational SGP method, proposed in [19], to approximate the true posterior of a GP p(f |y) using an approximated variational posterior distribution q(f, fms), where fms are the values of the underlying function f at the inducing points Zms . This approximation is done by augmenting the true posterior with the variable fms such as p(f, fms |y) = p(f |fms)p(fms |y). Then, the approximated variational distribution q(f, fms) can be factorized in the same manner as the augmented true posterior, as follows q(f, fms) = p(f |fms)\u03d5(fms), (9) where \u03d5(fms) is an unconstrained variational distribution over fms and p(f |fms) is the conditional GP prior. By minimizing the Kullback-Leibler (KL) divergence between the approximated and true posteriors, KL[q(f, fms)||p(f |y)], the variational SGP obtains estimates of the inducing inputs Zms and hyperparameters (\u0398, \u03c32)."
        },
        {
            "heading": "III. GP-MPPI CONTROL STRATEGY",
            "text": "The goal of our present research, as outlined in (2), is to determine the optimal control sequence U = {uk}N\u22121k=0 that enables safe and efficient navigation of the mobile robots through complex and unknown cluttered environments, while avoiding collisions with obstacles and getting trapped in local minima. Although the MPPI control framework, as summarized in [20], has many positive attributes, it is prone to generating infeasible control sequences or trajectories, particularly when the distribution of all sampled trajectories are concentrated within high-cost regions. To mitigate this issue, new sampling strategies proposed in [14], [21] have enabled more efficient exploration of the state-space, allowing the algorithm to find better solutions and potentially reduce the risk of trapping in local minima. Nevertheless, for specific tasks such as the one depicted in Fig. 3(b), eliminating the local minima remains a potential challenge that needs to be tackled.\nOne solution could be incorporating MPPI with a global planner, such as the solution presented in [22], which utilizes the RRT algorithm to guide MPPI. Instead, we introduce the GP-MPPI control strategy, a new online navigation technique that leverages the SGP occupancy model to learn about the navigable space surrounding the robot. Specifically, we introduce the GP-subgoal recommender policy, which identifies a set of recommended subgoals and subsequently suggests the optimal subgoal that minimizes a predefined cost function to the MPPI local planner, as depicted in Fig. 1 and explained in detail in Section III-B. Unlike conventional methods, a distinctive aspect of the proposed control strategy is that it does not require either a global map for long-term planning or an offline training process."
        },
        {
            "heading": "A. SGP Occupancy Surface Representation",
            "text": "Our proposed GP-subgoal recommendation policy relies on our earlier work presented in [23], [24], where we transformed pointcloud data into an occupancy surface and modeled it\nusing a Sparse Gaussian Process (SGP). Within this approach, the occupancy surface takes the form of a 2D circular surface centered around the sensor origin and has a predefined radius of roc. This surface serves as the projection space for all observed points, which are represented in spherical coordinates (\u03b8i, \u03b1i, ri), where (\u03b8i, \u03b1i, ri) correspond to the azimuth, elevation, and radius values of each observed point, respectively. Each point zi on the occupancy surface is defined by two attributes: the azimuth and elevation angles zi = (\u03b8i, \u03b1i), and assigned an occupancy value f(zi) that is a function of the point radius ri, such as f(zi) = roc \u2212 ri. Afterward, the probability of occupancy f(z) over the occupancy surface is modeled by an SGP occupancy model, as follows\nf(z) \u223c SGP (m(z), k (z, z\u2032)) ,\nk (z, z\u2032) = \u03c32f\n( 1 +\n(z\u2212 z\u2032)2 2\u03b1\u21132\n)\u2212\u03b1 ,\n(10)\nwhere \u03c32f is the signal variance, l is the length-scale, and \u03b1 is the relative weighting factor that manipulates large and small scale variations. In our SGP model, the point\u2019s occupancy to radius relation is encoded as a zero-mean function, m(z) = 0, where the occupancy value of the non-observed points is set to zero. The Rational Quadratic (RQ) kernel, k (z, z\u2032), is selected as the SGP kernel due to its ability to model functions that vary across different length-scale [16]. This characteristic makes the RQ kernel well-suited for modeling the occupancy surface.\nIn Fig. 2, we present a concrete example of the SGP occupancy model applied to our Jackal robot, which is equipped with a Velodyne VLP-16 LiDAR and located in an unknown cluttered environment, as depicted in Fig 2(a). The figure also illustrates the raw pointcloud generated by the onboard sensor (Fig 2(b)), as well as the original occupancy surface, which represents the projection of the point clouds onto the 2D circular surface with radius roc, where warmer colors indicate areas of lower occupancy (Fig 2(c)). Furthermore, Fig 2(d) exhibits the SGP occupancy surface reconstructed by the SGP occupancy model, as previously expressed in (10). The precision of the SGP occupancy model is intensively evaluated in our previous work [23], where the results showed that an SGP occupancy model comprising of 400 inducing points generates a reconstructed point cloud with an average error of approximately 12 cm."
        },
        {
            "heading": "B. GP-Subgoal Recommender Policy",
            "text": "The primary advantage of GP and its variants, compared to other modeling techniques, is their ability to provide a measure\nof variance, which indicates the level of uncertainty, along with a function estimate (i.e., mean). More precisely, in the context of the occupancy surface, the SGP occupancy model prediction, as defined in (7), provides both mean \u00b5oci and variance \u03c3oci values for each point on the surface, where the mean represents the expected occupancy while the variance reflects the uncertainty associated with the predicted occupancy. Consequently, constructing the SGP occupancy surface is accompanied by an SGP variance surface that captures the uncertainty in the occupancy estimate, as depicted in Fig. 2(e).\nWithin this research, we have opened up a new avenue for effectively utilizing the SGP variance surface as a reliable indicator for distinguishing between occupied and free spaces around the robot, where regions with variances higher than a certain threshold Vth correspond to free space, while lowvariance regions indicate occupied space. In fact, the variance surface changes across observations due to variations in the number and distribution of observed points employed in the training of the SGP model. As a result, the variance threshold Vth is considered to be a variable that relies on the distribution of the variance across the surface and can be calculated as Vth = Kmvm, where Km \u2208 R+ is a tuning parameter and vm represents the mean of the variance distribution. To identify free navigable spaces, we define a Gaussian Process frontier (namely, GP frontier) as the centroid point (\u03b8i, \u03b1i) of each high variance region. These GP frontiers {fi}Fi=1 serve as local recommended subgoals (see colored circles in Fig. 2(e)). Unlike the well-known frontier concept introduced in [25], it is worth noting that our GP frontier does not rely on a global occupancy map; instead, it is extracted from the uncertainty of the current observation.\nFollowing the identification of the GP frontiers by the SGP model, a cost function Jgp is utilized to determine the optimal GP frontier f\u2217 that guides the local planner (in our case, MPPI) towards the desired state xf . Our cost function Jgp, given in (11), has been established with two distinct terms. The first term, as introduced in [26], calculates the distance dfs between a GP frontier fi and the desired state xf . This distance criterion is used to identify the GP frontier closest to xf . The second term, inspired by the direction criterion proposed in [11], evaluates the direction \u03b8fi of a GP frontier with respect to the robot heading. This criterion prioritizes a GP frontier that aligns better with the robot heading.\nJgp (fi) = kdstdfs + kdir\u03b8 2 fi,\nf\u2217 = arg min fi\u2208F (Jgp (fi)) , (11)\nwhere kdst, kdir are weighting factors. The GP frontier direction \u03b8fi is squared to indicate the absolute direction. Finally, the local planner receives the optimal subgoal g\u2217, obtained by acquiring the Cartesian coordinate of the optimal GP frontier f\u2217, which leads the robot to its desired state xf ."
        },
        {
            "heading": "C. Real-Time GP-MPPI Control Algorithm",
            "text": "Algorithm 1 summarizes the real-time control cycle of the GP-MPPI algorithm, which includes two primary components: the local MPPI motion planner (described earlier in Section IIB) and the GP-subgoal recommender (explained in Section IIIB). Each time-step \u2206t, the GP policy recommends the optimal subgoal g\u2217, the current state is estimated, and a M \u00d7 N random control variations \u03b4u are generated (lines 2 : 4). Then, M trajectories are simulated in parallel, propagated from the system dynamics defined in (1), and evaluated using (3) (lines 5 : 13). It is noteworthy that the minimum sampled cost trajectory, denoted as S\u0303min, among all simulated trajectories prevents numerical overflow or underflow without affecting the optimality of the algorithm [27]. After that, the optimal control sequence {uk}N\u22121k=0 is updated, smoothed with a SavitzkyGaloy filter, and the first control u0 is applied to the system (lines 14 : 18), while the remaining sequence of length N \u2212 1 is slid down to be utilized at next time-step (lines 19 : 22). In lines 25 to 38, the function known as GPSubgoalRecommender is described, which takes a pointcloud input (PCL) and returns the optimal subgoal g\u2217 for the local planner. To optimize the hyper-parameters \u0398 and inducing points Zms of the SGP occupancy model, the pointcloud data is transformed into training data D (lines 26 : 29). The mean occupancy \u00b5oc and variance \u03c3oc are then estimated over the surface Z\u2217, and the GP frontiers are defined as those with \u03c3oc > Vth, where the centroids of these frontiers are converted to Cartesian coordinates (lines 30 : 34). Finally, the cost function Jgp in (11) is used to select the optimal subgoal g\u2217 (lines 35 : 37).\nIn this study, we introduce two operating modes for the GPMPPI algorithm: the simple mode (SM) and the recovery mode (RM). Under the simple mode, MPPI consistently leverages the optimal subgoal g\u2217 suggested by the GP policy. In contrast, in the recovery mode, MPPI generates the optimal control sequence that steers the robot towards its desired state xf , adhering to the recommended subgoal only when the robot is at risk of encountering local minima. Such local minima occur when the robot\u2019s linear velocity is zero (v = 0) and its current state xk does not match xf (i.e., xk \u0338= xf ). Thanks to the optimal control sequence {uk}N\u22121k=0 obtained by MPPI, we can efficiently anticipate the occurrence of local minima by imposing a condition on the mean of the predicted linear velocities over the time-horizon N , expressed as follows:\n\u00b5u = 1\nN N\u22121\u2211 i=0 |vi| < uth, (12)\nwhere uth \u2208 R+ represents a control switching threshold set based on N . If this condition is fulfilled, then MPPI will follow the subgoal recommended by the GP rather than navigating directly towards its desired state xf .\nAlgorithm 1 Real-Time GP-MPPI Control Algorithm Given:\nM,N : Number of rollouts (samples) & timesteps (u0,u1, . . . ,uN\u22121) \u2261 U: Initial control sequence f,\u2206t: Dynamics & time-step size \u03d5, q, \u03bb, \u03bd,\u03a3u, Q,R: Cost & control hyper-parameters SGF: Savitzky-Galoy (SG) convolutional filter PCL,Z\u2217: Pointcloud & 2D variance surface (Grid) \u0398,ms, kdst, kdir, km: GP policy hyper-parameters\n1: while task not completed do 2: g\u2217 \u2190 GP-SubgoalRecommender(PCL), 3: x0 \u2190 StateEstimator(), x0 \u2208 Rnx 4: \u03b4u\u2190 GaussianNoiseGenerator(), \u03b4u \u2208 RM\u00d7N 5: for m\u2190 0 to M \u2212 1 in parallel do 6: x\u2190 x0, S\u0303 (\u03c4m)\u2190 0, S\u0303 (\u03c4m) \u2208 R+ 7: for k \u2190 0 to N \u2212 1 do 8: xk+1 \u2190 xk + f (xk,uk + \u03b4uk,m)\u2206t, 9: S\u0303 (\u03c4m)\u2190 S\u0303 (\u03c4m) + q\u0303, 10: end for 11: S\u0303 (\u03c4m)\u2190 S\u0303 (\u03c4m) + \u03d5 (xN ), 12: end for 13: S\u0303min \u2190 minm[S\u0303 (\u03c4m)], \u2200m = {0, . . . ,M \u2212 1} 14: for k \u2190 0 to N \u2212 1 do 15: uk \u2190 uk + \u2211M\u22121 m=0 exp ( \u22121 \u03bb [S\u0303(\u03c4m)\u2212S\u0303min] ) \u03b4uk,m\u2211M\u22121 m=0 exp ( \u22121 \u03bb [S\u0303(\u03c4m)\u2212S\u0303min]\n) , 16: end for 17: u\u2190 SGF(u), 18: u0 \u2190 SendToActuators(u), 19: for k \u2190 1 to N \u2212 1 do 20: uk\u22121 \u2190 uk, 21: end for 22: uN\u22121 \u2190 ControlSequenceInitializer(uN\u22121), 23: Check for task completion 24: end while 25: function GP-SubgoalRecommender(PCL), 26: (\u03b8i, \u03b1i, ri) \u2190 Cartesian2Spherical(PCL(xi, yi, zi)), 27: oci = roc \u2212 ri, D = {(zi, oci)}ni=1, 28: f(z) \u223c SGP (m(z), k (z, z\u2032)), k \u2190 RQ, 29: Optimize (\u0398, Zms ) \u2190 D, 30: (\u00b5oc, \u03c3oc)\u2190 SGP-Predict(Z\u2217), 31: vm \u2190 Mean(\u03c3oc), Vth \u2190 Kmvm, 32: GP-Frontiers\u2190 (\u03c3oc > Vth), 33: (\u03b8fi , \u03b1fi)\u2190 CentroidOfGP-Frontiers, 34: (xfi , yfi , 0)\u2190 Spherical2Cartesian(\u03b8fi , \u03b1fi , roc), 35: dfs \u2190 EuclideanDistance((xfi , yfi),xf ), 36: f\u2217 = argminfi\u2208F (Jgp (fi)), 37: g\u2217 \u2190 (xf\u2217 , yf\u2217 , \u03b8f\u2217), 38: return g\u2217 39: end function"
        },
        {
            "heading": "IV. SIMULATION-BASED EVALUATION",
            "text": "In this section, the effectiveness of our proposed control strategy is assessed and compared with both vanilla MPPI and logMPPI control strategies in a goal-oriented autonomous ground vehicle (AGV) navigation task conducted in 2D cluttered environments of unknown nature."
        },
        {
            "heading": "A. Simulation Setup:",
            "text": "In this study, we consider the kinematics model of a differential wheeled robot presented in [14], specifically the fully autonomous ClearPath Jackal robot, where the robot\u2019s position and orientation in the world frame are given by x = [x, y, \u03b8]\u22a4 \u2208 R3, and the control input u = [v, \u03c9]\u22a4 \u2208 R2 denotes the robot\u2019s linear and angular velocities. Our autonomous AGV platform is equipped with a 16-beam Velodyne LiDAR sensor utilized for two key functions: (i) constructing the SGP variance surface, and (ii) generating the local costmap.\nThe simulations for all proposed control schemes were conducted with the following parameters: a prediction time of 6 s, a control frequency of 30Hz (i.e., N = 180), sampling 2528 rollouts per time-step \u2206t, and an exploration variance \u03bd of 1200. Additionally, a control weighting matrix R, expressed as \u03bb\u03a3\u2212 1 2\nn , is utilized. In the case of MPPI and GPMPPI, the inverse temperature \u03bb and the control noise covariance \u03a3u = \u03a3n = Diag ( \u03c32v , \u03c3 2 w ) are both set to 0.572 and Diag (0.023, 0.028), respectively. However, for log-MPPI, different values of 0.169 and Diag (0.017, 0.019) are used for these parameters, along with a normal distribution that has a co-variance of \u03a3n = Diag (0.002, 0.0022) (For more details, refer to [14]). The Savitzky-Galoy (SG) convolutional filter is utilized with a quadratic polynomial function, i.e., nsg = 2, and a window length lsg of 51. The occupancy surface was constructed with an occupancy radius roc of 5 meters, a full azimuth range of \u2212180o to 180o, and elevation height of 0o to 15o. The SGP occupancy model was designed with 400 inducing points (Zm = 400), where the GP frontiers were identified based on a variance threshold of Vth = Kmvm, where Km was set to 0.4. For the distance and direction factors Kdst and Kdir of the cost function Jgp, we assigned weighting factors of 5 and 4, respectively. To enable the recovery mode of the GP-MPPI, we have set the control threshold, uth, to 0.55 [m/sec]. All the proposed control schemes, which are written in Python and integrated with the Robot Operating System (ROS) framework, are executed in real-time on an NVIDIA GeForce GTX 1660 Ti laptop GPU, with the GPsubgoal recommender built on GPflow [28].\nTo accomplish the 2D navigation task, we adopt a statedependent cost function described in (13), which comprises two terms. The first term, with Q = Diag(2.5, 2.5, 5), aims to steer the robot towards its desired state, whereas the second term incorporates a Boolean variable Icrash to heavily penalizes collisions with obstacles. q(xk) = (xk \u2212 xf )\u22a4Q(xk \u2212 xf ) + 103Icrash. (13) Since the robot is operating in unknown environments, it relies on a 2D costmap to maintain a record of obstacles in its vicinity. This costmap is generated by analyzing sensor data from the environment and constructing a 2D occupancy grid, with each cell typically categorized as occupied, free, or unknown [29]. The generated occupancy grid is subsequently employed as a 2D local costmap, feeding directly into the sampling-based MPC algorithm, enabling safe and collisionfree navigation. The robot-centered 2D local costmap, which is built by the on-board Velodyne VLP-16 LiDAR sensor, has a size of 200 cell \u00d7 200 cell and a grid resolution of\n0.05m/cell. Finally, throughout the simulations, the maximum linear velocity vmax of the robot is set to 1.5m/s."
        },
        {
            "heading": "B. Simulation Scenarios and Performance Metrics:",
            "text": "The benchmark evaluation utilizes two types of Gazebo simulation environments, as depicted in Fig. 3. The first type, referred to as Forest #1, is a 50m \u00d7 50m forest-like environment characterized by tree-shaped obstacles with a density of 0.2 trees/m2; The other type, named Maze #1, is a 20m \u00d7 20m maze-like environment with three U-shaped rooms (i.e., U1, U2, and U3), as well as various other obstacles (highlighted in red in Fig. 3(b))1. In the first scenario, denoted as Forest #1, the robot is directed to navigate from an initial pose xs = [\u22125,\u22128, 0]\u22a4 to a desired pose xf = [20, 20, 45]\u22a4 in ([m], [m], [deg]). Meanwhile, in Maze #1, we conducted two separate control missions to (i) evaluate the robustness of our proposed control strategy, and (ii) examine its performance under the two different operating modes, previously described in Section III-C. The first mission, MU1, requires the robot to navigate from xs = [\u22125,\u22128, 60]\u22a4 to a desired pose xf = [4, 4, 45]\n\u22a4 located inside U1; while, in the second mission, named MU2, the robot starts at xs = [\u22126, 8, 0]\u22a4, crosses U2, and reaches a desired pose of xf = [8,\u22128, 170]\u22a4.\nTo ensure a fair and comprehensive comparison of the three control schemes, we have established a set of performance metrics, including the task completion percentage Tc, the average distance traveled by the robot dav to reach xf from xs, the average linear velocity vav of the robot within the cluttered environment, and the percentage of assistanceAgp provided by the GP-subgoal recommender policy to MPPI when the recovery mode is utilized. The successful task completion entails the robot reaching the target position without encountering obstacles or getting trapped in local minima Rlm."
        },
        {
            "heading": "C. Simulation Results:",
            "text": "We evaluated the effectiveness of the proposed control strategies in Forest #1 and Maze #1 (i.e., MU1 & MU2) through 10 trials each, and the resulting performance statistics are summarized in Table I. The performance results demonstrate that, as expected, the proposed GP-MPPI control\n1To evaluate the local planner\u2019s obstacle avoidance capability, the red obstacles are intentionally made undetectable as occupied space by the GPsubgoal recommender, as occupancy elevation height is set to a higher value.\nstrategy outperforms both the vanilla MPPI and log-MPPI as the autonomous vehicle successfully accomplished all control missions (with Tc = 100%) without getting stuck in local minima or colliding with obstacles (i.e., Rlm = 0), despite having limited perception range and incomplete knowledge of the environment. In contrast, in Forest #1, log-MPPI achieved a task completion rate Tc of 95.72% over 10 trials, compared to 86.87% when MPPI was utilized. Additionally, log-MPPI encountered local minima only twice, while MPPI was trapped six times. Nevertheless, both control methods were unable to complete any of the trials in MU1 and MU2 due to the challenging environmental conditions (refer to the robot trajectories generated by log-MPPI in Fig. 3(b)). Additionally, our proposed approach in Forest #1 provided a shorter route towards the desired state xf , especially when the recovery mode (RM) is activated, similar to the optimal trajectory of the baselines, with an average linear velocity vav of 1.30m/s, which approaches the maximum specified velocity of 1.5m/s.\nConcerning the two modes of GP-MPPI, it is observed that activating the recovery mode (RM) during Forest #1 and MU1 missions improves the average distance traveled dav by the robot. For instance, in MU1, dav was approximately 32.74m with RM, whereas with the simple mode (SM), which consistently relies on the subgoal recommended by GP, dav was roughly 34.48m. On the other hand, during the MU2 mission, the RM produced a slightly longer robot trajectory than the SM since operating our proposed GP-MPPI in the RM strikes a balance between the state-dependent cost function that directs the robot to follow a direct route towards the desired state and the optimal subgoal recommended by the GP policy that forces the robot to avoid the dead-ends associated with rooms U2 and U3 on its way to xf , as illustrated in Fig. 4(b). We can also see that, due to the presence of U-shaped rooms in Maze #1, the GP provides more assistance, represented by Agp, than in Forest #1. In Fig. 4, we illustrate through an example from the conducted trials the robot trajectories generated by GP-MPPI under the two operating modes in Maze #1. We can clearly observe that our proposed control strategy successfully achieves collision-free navigation in both modes, without getting stuck in local minima. As an example,\nFig. 5(a) displays the velocity profile of the robot during the MU1 mission shown in Fig. 4(a), while using GP-MPPI with RM, along with its corresponding mean of the predicted linear velocities \u00b5u over the given time-horizon N (see Fig. 5(b)). The mean values that fall below the switching threshold uth, set at 0.55 [m/sec], denote the intervals where the RM is active, and are visually emphasized in yellow in Fig. 4(a)."
        },
        {
            "heading": "V. REAL-WORLD DEMONSTRATION",
            "text": "In this section, we experimentally demonstrate the applicability of our proposed control strategy in achieving a safe 2D grid-based collision-free navigation in a complex and unknown indoor cluttered environment.\n1) Experimental Setup and Validation Environment: To conduct our experimental validation, we used the simulation setup previously outlined in Section IV-A, except for (i) setting the maximum speed vmax to 1.0m/s to avoid the robot localization error associated with using the RealSense camera as a source of localization, (ii) setting the occupancy radius roc to 3.0m, and (iii) decreasing the size of the 2D grid map to 120 cell \u00d7 120 cell.\nWe also decreased the recovery mode switching threshold uth to 0.3m/s to be compatible with the updated vmax. Additionally, to ensure real-time execution of the GP-subgoal recommender policy, we decrease the resolution of the SGP\nvariance surface to one-third of its original value along the azimuth axis while keeping the original resolution along the elevation axis. We employed an L-shaped indoor corridor\nenvironment measuring 9m \u00d7 14m for experimental validation. The environment has a varying width between 1.8m and 2.8m and contains randomly placed boxes-like obstacles, as depicted in Fig. 6. The assigned control mission of the robot is to navigate from xs = [0, 0, 0]\u22a4 and arrive at xf = [7.5, 13, 90]\n\u22a4. 2) Experimental Results: The performance statistics of our proposed GP-MPPI control scheme, gathered from four trials conducted in our indoor environment, are summarized in Table II for the two operating modes. From all trials, we can conclude that both operating modes provide collision-free navigation in the cluttered environment with an average linear velocity of 0.80m/sec, without the risk of being trapped in local minima (as Rlm = 0) while moving towards its desired state. This ensures the safety and consistent feasibility of the receding-horizon planning. In contrast, it is observed that the vanilla MPPI and log-MPPI consistently failed to complete any of the trials due to being trapped in the first edge of the L-shaped environment. However, MPPI managed to avoid such traps with the aid of the GP-subgoal recommender policy in the recovery mode (RM), which provides an average assistance percentage Agp of roughly 31.36%. More details about the simulation and experimental results, including the behavior of the baselines, are provided in the supplementary video: https://youtu.be/et9t8X1wHKI."
        },
        {
            "heading": "VI. CONCLUSION",
            "text": "In this work, we proposed the GP-MPPI control strategy, which comprises two primary components: the GP-subgoal recommender policy and the local planner, the MPPI. First, the GP-subgoal recommender utilized the learning capacity of SGP to create a reliable SGP variance surface, which served as an indicator for differentiating between occupied and free spaces around the robot. Consequently, a set of suggested subgoals was identified, and the optimal subgoal that minimizes a predefined cost function was recommended to the local MPPI planner. Based on the recommended subgoal, MPPI computes the optimal control input that enables the robot to navigate towards the goal efficiently and safely while accounting for its dynamics and avoiding collisions. By conducting a combination of simulated and real-world experiments, we have shown that our proposed control strategy is superior to the vanilla MPPI and log-MPPI methods in achieving efficient and safe navigation in unknown and complex environments, thereby avoiding the risk of getting stuck in local minima."
        }
    ],
    "title": "GP-guided MPPI for Efficient Navigation in Complex Unknown Cluttered Environments",
    "year": 2023
}