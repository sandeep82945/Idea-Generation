{
    "abstractText": "Open space grassland is being increasingly farmed or built upon, leading to a ramping up of conservation efforts targeting roadside verges. Approximately half of all UK grassland species can be found along the country\u2019s 500,000 km of roads, with some 91 species either threatened or near threatened. Careful management of these \u201cwildlife corridors\u201d is therefore essential to preventing species extinction and maintaining biodiversity with grassland habitats. Wildlife trusts have often enlisted the support of volunteers to survey roadside verges and identify new \u201cLocal Wildlife Sites\u201d as areas of high conservation potential. Using volunteer survey data from 3,900 km of roadside verges alongside publicly available street-view imagery, we present DeepVerge; a deep learning-based method that can automatically survey sections of roadside verge by detecting the presence of positive indicator species. Using images and ground truth survey data from the rural county of Lincolnshire, DeepVerge achieved a mean accuracy of 88%. Such a method may be used by local authorities to identify new local wildlife sites, and aid management and environmental planning in line with legal and government policy obligations, saving thousands of hours of manual labour.",
    "authors": [
        {
            "affiliations": [],
            "name": "Andrew Perrett"
        },
        {
            "affiliations": [],
            "name": "Charlie Barnes"
        },
        {
            "affiliations": [],
            "name": "Mark Schofield"
        },
        {
            "affiliations": [],
            "name": "Lan Qie"
        },
        {
            "affiliations": [],
            "name": "Petra Bosilj"
        },
        {
            "affiliations": [],
            "name": "James M. Brown"
        }
    ],
    "id": "SP:9eedd17668b85ee4e5f52ef9c2fdea901d08074c",
    "references": [
        {
            "authors": [
                "A.F. Agarap"
            ],
            "title": "Deep Learning using Rectified Linear Units (ReLU)",
            "year": 2019
        },
        {
            "authors": [
                "D. Anguelov",
                "C. Dulong",
                "D. Filip",
                "C. Frueh",
                "S. Lafon",
                "R. Lyon",
                "A. Ogale",
                "L. Vincent",
                "J. Weaver"
            ],
            "title": "Google street view: Capturing the world at street level",
            "venue": "IEEE Computer",
            "year": 2010
        },
        {
            "authors": [
                "T.A. August",
                "O.L. Pescott",
                "A. Joly",
                "P. Bonnet"
            ],
            "title": "Ai naturalists might hold the key to unlocking biodiversity data in social media",
            "venue": "imagery. Patterns",
            "year": 2020
        },
        {
            "authors": [
                "J. Biesmeijer",
                "S. Roberts",
                "M. Reemer",
                "R. Ohlem\u00fcller",
                "M. Edwards",
                "T. Peeters",
                "A. Schaffers",
                "S. Potts",
                "R. Kleukers",
                "C Thomas"
            ],
            "title": "Parallel declines in pollinators and insect-pollinated plants in britain and the netherlands",
            "venue": "Microbiol. Immunol 282,",
            "year": 2004
        },
        {
            "authors": [
                "F. Biljecki",
                "K. Ito"
            ],
            "title": "Street view imagery in urban analytics and gis: A review",
            "venue": "Landscape and Urban Planning",
            "year": 2021
        },
        {
            "authors": [
                "E. Biott"
            ],
            "title": "Life on the verge: Wolds - hlf evaluation report",
            "year": 2013
        },
        {
            "authors": [
                "A. Campbell",
                "A. Both",
                "Q.C. Sun"
            ],
            "title": "Detecting and mapping traffic signs from Google Street View images using deep learning and GIS",
            "venue": "Computers, Environment and Urban Systems",
            "year": 2019
        },
        {
            "authors": [
                "P. Carey",
                "S. Wallis",
                "B. Emmett",
                "L. Maskell",
                "J. Murphy",
                "L. Norton",
                "I. Simpson",
                "S. Smart"
            ],
            "title": "Countryside survey: Uk headline messages",
            "year": 2008
        },
        {
            "authors": [
                "N.V. Chawla",
                "K.W. Bowyer",
                "L.O. Hall",
                "W.P. Kegelmeyer"
            ],
            "title": "SMOTE: Synthetic Minority Over-sampling Technique",
            "venue": "Journal of Artificial Intelligence Research",
            "year": 2002
        },
        {
            "authors": [
                "L. Depauw",
                "H. Blondeel",
                "E. De Lombaerde",
                "K. De Pauw",
                "D. Landuyt",
                "E. Lorer",
                "P. Vangansbeke",
                "T. Vanneste",
                "K. Verheyen",
                "P. De Frenne"
            ],
            "title": "The use of photos to investigate ecological change",
            "venue": "Journal of Ecology n/a",
            "year": 2022
        },
        {
            "authors": [
                "E. Deus",
                "J.S. Silva",
                "F.X. Catry",
                "M. Rocha",
                "F. Moreira"
            ],
            "title": "Google Street View as an alternative method to car surveys in large-scale vegetation assessments",
            "venue": "Environmental Monitoring and Assessment",
            "year": 2016
        },
        {
            "authors": [
                "K. He",
                "X. Zhang",
                "S. Ren",
                "J. Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "in: Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2016
        },
        {
            "authors": [
                "S. Ioffe",
                "C. Szegedy"
            ],
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
            "venue": "in: Proceedings of the 32nd International Conference on Machine Learning, PMLR. pp. 448\u2013456",
            "year": 2015
        },
        {
            "authors": [
                "R.G. Jefferson",
                "T.H. Blackstock",
                "R.J. Pakeman",
                "B.A. Emmett",
                "R.J. Pywell",
                "J.P. Grime",
                "J. Silvertown"
            ],
            "title": "Technical report: The uk national ecosystem assessment : Semi-natural grasslands",
            "year": 2011
        },
        {
            "authors": [
                "J.H. Kim",
                "S. Lee",
                "J.R. Hipp",
                "D. Ki"
            ],
            "title": "Decoding urban landscapes: Google street view and measurement sensitivity",
            "venue": "Computers, Environment and Urban Systems",
            "year": 2021
        },
        {
            "authors": [
                "D. Kotowska",
                "T. P\u00e4rt",
                "M. \u017bmihorski"
            ],
            "title": "Evaluating Google Street View for tracking invasive alien plants along roads",
            "venue": "Ecological Indicators",
            "year": 2021
        },
        {
            "authors": [
                "J. Li",
                "Cheng",
                "J.h",
                "Shi",
                "J.y",
                "F. Huang"
            ],
            "title": "Brief Introduction of Back Propagation (BP) Neural Network Algorithm and Its Improvement",
            "venue": "Advances in Computer Science and Information Engineering,",
            "year": 2012
        },
        {
            "authors": [
                "P. Li",
                "D. Li",
                "W. Li",
                "S. Gong",
                "Y. Fu",
                "T.M. Hospedales"
            ],
            "title": "A Simple Feature Augmentation for Domain Generalization",
            "year": 2021
        },
        {
            "authors": [
                "J.L. Long",
                "N. Zhang",
                "T. Darrell"
            ],
            "title": "Do convnets learn correspondence",
            "venue": "org.uk/ [accessed",
            "year": 2022
        },
        {
            "authors": [
                "Associates",
                "D. Inc. Mazerolle",
                "S. Blaney"
            ],
            "title": "Google street view: a new online tool",
            "year": 2011
        },
        {
            "authors": [
                "PLANT INVASIONS",
                "P. 77\u201383. Neil"
            ],
            "title": "Local Wildlife Site Guidelines for Greater Lincolnshire",
            "year": 2013
        },
        {
            "authors": [],
            "title": "Using 164 Million Google Street View Images to Derive Built",
            "year": 2020
        },
        {
            "authors": [
                "J.M. Bullock",
                "L.V. Dicks",
                "J.L. Osborne"
            ],
            "title": "Enhancing road verges",
            "year": 2020
        },
        {
            "authors": [
                "L. Sun",
                "Z. Chen",
                "Q.M.J. Wu",
                "H. Zhao",
                "W. He",
                "X. Yan"
            ],
            "title": "AMPNet: Average- and Max-Pool Networks for Salient Object Detection",
            "venue": "IEEE Transactions on Circuits and Systems for Video Technology",
            "year": 2021
        },
        {
            "authors": [
                "M. Tan",
                "Le"
            ],
            "title": "Efficientnet: Rethinking model scaling for convolutional neural networks",
            "venue": "Q.V.,",
            "year": 2019
        },
        {
            "authors": [
                "D. Warzecha",
                "T. Diek\u00f6tter",
                "V. Wolters",
                "F. Jauker"
            ],
            "title": "Attractiveness of wildflower mixtures for wild bees and hoverflies depends on some key plant species",
            "venue": "Insect Conservation and Diversity",
            "year": 2018
        },
        {
            "authors": [
                "D. Wei",
                "B. Zhou",
                "A. Torrabla",
                "W. Freeman"
            ],
            "title": "Understanding IntraClass Knowledge Inside CNN",
            "year": 2015
        },
        {
            "authors": [
                "S. Xie",
                "R. Girshick",
                "P. Doll\u00e1r",
                "Z. Tu",
                "K. He"
            ],
            "title": "Aggregated Residual Transformations for Deep Neural Networks",
            "venue": "Technical Report arXiv:1611.05431. arXiv. doi:10.48550/arXiv.1611.05431",
            "year": 2017
        },
        {
            "authors": [
                "Y. Zhao",
                "Z. Sun",
                "E. Tian",
                "C. Hu",
                "H. Zong",
                "F. Yang"
            ],
            "title": "A CNN Model for Herb Identification Based on Part Priority Attention Mechanism",
            "venue": "IEEE International Conference on Systems, Man, and Cybernetics (SMC),",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Open space grassland is being increasingly farmed or built upon, leading to a ramping up of conservation efforts targeting roadside verges. Approximately half of all UK grassland species can be found along the country\u2019s 500,000 km of roads, with some 91 species either threatened or near threatened. Careful management of these \u201cwildlife corridors\u201d is therefore essential to preventing species extinction and maintaining biodiversity with grassland habitats. Wildlife trusts have often enlisted the support of volunteers to survey roadside verges and identify new \u201cLocal Wildlife Sites\u201d as areas of high conservation potential. Using volunteer survey data from 3,900 km of roadside verges alongside publicly available street-view imagery, we present DeepVerge; a deep learning-based method that can automatically survey sections of roadside verge by detecting the presence of positive indicator species. Using images and ground truth survey data from the rural county of Lincolnshire, DeepVerge achieved a mean accuracy of 88%. Such a method may be used by local authorities to identify new local wildlife sites, and aid management and environmental planning in line with legal and government policy obligations, saving thousands of hours of manual labour.\nKeywords: Google Street View, Convolutional Neural Network, Machine Learning, Life on the Verge, Local Wildlife Sites, Remote Surveying, CNN, Lincolnshire Wildlife Trust\nPreprint submitted to Computers Environment and Urban Systems June 10, 2022\nar X\niv :2\n20 6.\n04 27\n1v 1\n[ cs\n.C V"
        },
        {
            "heading": "1. Introduction and Motivation",
            "text": "Over the past century, open space grassland and wildflower meadows have been increasingly farmed or built upon. At the same time, the number of roads (and therefore roadside verges) has increased, making the proportion of grassland within roadside verges much greater. The 2011 UK National Ecosystem Assessment (Jefferson et al., 2011) found that semi-natural grassland has greatly declined in area since 1945, with losses of around 90% in the UK\u2019s lowlands. By 2011 only 2% of this grassland area was classed as high diversity with two studies showing that a loss of 97% of enclosed seminatural grassland was seen between 1930 and 1984 (Lincolnshire Wildlife Trust, 2016; Jefferson et al., 2011), mainly due to agriculture improvement (Warzecha et al., 2018). The Countryside Survey 2007 (Carey et al., 2008) showed that the decline had slowed between 1998 and 2007 allowing the focus to be shifted toward increasing the amount of grassland and the diversity within. 50% of all grassland plant species can be identified on road verges, including 91 species which are either threatened or near threatened (Plantlife, 2017).\nSurveying and classifying verges is not only a time consuming activity that requires experts and volunteers alike, but often a legal requirement. Local Wildlife Sites (LWSs) are designated areas identified as having local conservation value, and serve to protect local diversity while complementing a more general environmental stewardship. Local authorities are required to identify LWSs based on indicators of local biodiversity, and as a way of assessing the effectiveness of their planning systems (Neil, 2013). Diversity within grassland also requires management as part of the response to the climate emergency. Species rich grassland stores more carbon than species poor grassland with important interactions between, and within, species (Gov.Wales, 2022). Management of verges is critical for these interactions, but also for authorities and businesses who will be required to demonstrate biodiversity net gain due to UK government policies aimed at mitigating climate change.\nAn important factor within verge management is the role of pollinators, specifically within roadside verges, but also within agriculture in general. Pollinators and wildflowers can be functionally linked, with a decline in one seeing a decline in the other (Biesmeijer et al., 2004) which contributes to the importance placed upon diversity. Diversity and its management was addressed with a review of 140 relevant studies, providing recommendations for verges and entire road networks. Pollination and diversity must go to-\ngether when considering grassland management due to a lack of holistic and large-scale understanding of the net effects that roadside verges have upon pollinators (Phillips et al., 2020). Species rich verges, and more generally green space, also contribute on a psychological, and general well-being level to the public (Stubbings et al., 2019; O\u2019Sullivan et al., 2017).\nNew and efficient ways of managing verges, taking advantage of technological improvements, are necessary if conservation efforts are to succeed over such a large area of grassland. The use of imagery within ecology studies is an often overlooked source of data (Depauw et al., 2022), due to the lack of quantitative methods to estimate the presence and extent of different species of flora and fauna. Computer vision, and more recently artificial intelligence (AI), can be used to extract meaning from unstructured images in a way that is not possible for a human. AI can efficiently automate the identification of scene content within imagery (e.g., wildflower species) and provide a new way to help naturalists manage verges, producing what has been termed an \u201cAI Naturalist\u201d (August et al., 2020). Such an approach brings together the latest state-of-the-art machine learning technologies, such as artificial neural networks (ANN), and large publicly available image datasets, such as Google Street View (GSV) (Anguelov et al., 2010), to provide a monitoring and surveying technique that ecologists could take advantage of.\nIn this work, we propose an AI-based approach to automated surveying of road verge habitat quality using convolutional neural networks (CNNs) and publicly-available street-view imagery of roadside verges. Utilising a supervised learning approach, a state-of-the-art CNN was trained on thousands of images with corresponding ground truth labels obtained from one of the UK\u2019s largest road verge surveys, \u201cLife on the Verge\u201d. Our approach, entitled DeepVerge is, to our knowledge, the first application of AI to ecological conservation based on street-view imagery."
        },
        {
            "heading": "2. Related Work",
            "text": ""
        },
        {
            "heading": "2.1. Convolutional neural networks",
            "text": "Convolutional Neural Networks (CNNs) (O\u2019Shea and Nash, 2015) are continually pushing boundaries in terms of image classification. Examples of recent state of-the-art (SOTA) CNNs include ResNet (He et al., 2016), EfficientNet (Tan and Le, 2019) and ResNeXt (Xie et al., 2017), to name just a few. A CNN has two main parts: a convolutional backbone for representation learning, and a fully connected neural network (NN) that serves\nas a classifier. CNNs can be greatly enhanced through pre-training on a larger dataset (possibly from a different domain altogether) and harnessing the learned representations in a process called transfer learning (Perez and Wang, 2017). Massive labelled image datasets (Long et al., 2014) are routinely used to train CNNs, allowing them to learn information that is commonly found within many image domains. Applications to domains with limited data thereby benefit from reduced training times and/or increased performance in not having to learn these common traits from scratch. There is mounting evidence that these algorithms can just be taken off the shelf (Razavian et al., 2014) and then fine-tuned to specific datasets."
        },
        {
            "heading": "2.2. Street-view imagery",
            "text": "A review of street view imagery for urban analytics found over 600 papers using this imagery and that GSV is an entrenched component of urban analytics and GIScience (Biljecki and Ito, 2021). One of the earliest examples of GSV use, for remote surveying, (Friedland, 2009) used street level imagery to compare building damage before and after a hurricanes Katrina and Ike. Possibly the first remote ecological study to make use of GSV (Rousselet et al., 2013) looked at the species distribution of the Pine Processionary Moth. GSV images were used to infer the presence of the moth and derive an occurrence metric. The results showed that their derived metric correlated highly with the field study achieving an accuracy of 96%.\nEvaluation of GSV roadside verges were used for tracking invasive alien plants along roads (Kotowska et al., 2021) and its use was found to have a great potential to support ecological research in documenting species distribution. While both Rousselet et al. (2013) and Kotowska et al. (2021) used humans in the loop to visually detect occurrence within the GSV imagery, Ringland et al. (2019) used a CNN to detect crop types within the imagery and even automated the collection of GSV images. Humans were still used in their pipeline however, within the selection of suitable images, and they achieved an overall accuracy of 83% classifying crop types. Deus et al. (2016) compared the more common method of using car surveys (CS) with what they termed as Remote Sensing using GSV as a possible cost effective alternative. They, like others, used GSV to determine occurrence of a single plant species (Eucalyptus globulus Labill) using human observers, and while finding lower occurrence using GSV they were able to improve the results using other variables. They went on to conclude that GSV use was a cost-effective alternative to CS.\nWhile the combination of GSV and CNNs has been used in contexts such as herb identification (Zhao et al., 2020) and street sign detection (Campbell et al., 2019), the combination typically focuses on specific object detection or classification within the scene, rather than classifying the scene itself. Scenery classification has been made within the urban environment (Nguyen et al., 2020), where the presence of crosswalks, building types, utility wires, single lane road and a percentage of greenery were used to classify COVID-19 risk of neighbourhoods. The Nguyen et al. (2020) study still used human in the loop for annotation of ground truth and also directed the CNN toward object indicators. Our study, by comparison, automates annotation without directing the CNN toward any specific object."
        },
        {
            "heading": "3. Data Preparation and Curation",
            "text": ""
        },
        {
            "heading": "3.1. Ground truth",
            "text": "Lincolnshire Wildlife Trust (LWT) has conducted thorough surveys of Lincolnshire\u2019s roadside verges under a project entitled \u201cLife on the Verge (LotV)\u201d. The project included three citizen science sub-projects that correspond to 3,500 road sections/specific localities of Lincolnshire Wolds (LotVW), Lincolnshire Northern Edge, and Limestone Grassland (Fig. 1). The results of these surveys provide ground truth (GT) for this study.\nEach section has the roadside verges within scored by a value corresponding to the number of positive indicator species identified (Neil, 2013). These scores were later quantized into a LotVW ordinal scoring system with five levels, as detailed in Table. 1, describing to the verge\u2019s biodiversity status and conservation potential. The 5th category is special, in that it includes the most important areas having already been designated as Roadside Nature Reserves (RNRs) (Biott, 2013) (LWT Internal Document).\nSurveying started in 2009 with the first LotVW sub-project (Lincolnshire Wildlife Trust, 2013) involving 1,100 hours from over 100 people to cover 1,115 km of roads. Between 2009 and 2016, surveying was expanded to 3,900 km of roadside verges and found 159 new LWS of wildflower-rich habitat (Lincolnshire Wildlife Trust, 2016). The mean road length, for each section, was approximately 1 km with the number of GPS-derived GT locations in each varying from 3 to 30+. Overall the survey results provided approximately 50,000 GPS locations that require mapping or snapping to their associated GSV panorama locations to create a usable GT.\nAny road has features such as junctions, bends and straights, which themselves have features such as the start, middle and end. A road section therefore can be described with a series of GPS locations placed at each of these features. These road feature locations, along with 8-way compass directions identifying the number of wildflower species of each verges section are provided within the LWT survey results."
        },
        {
            "heading": "3.2. Raw data",
            "text": "With the aim of developing a remote means of surveying roadside verges, the ability to identify new LWSs was identified as a core objective. In order to train a model with this capability however, it was first necessary to transform the raw data into a useable dataset. The survey data was provided by LWT in Keyhole Mark-up Language (KML) (Open Geospatial Consortium, 2020), which required processing in order to produce a usable GT annotated image dataset. Additionally, imagery required extraction via an Application Programming Interface (API) from within 360\u00b0 GSV panoramic images taken by Google over the last decade or more. The pipeline (Fig. 2) was almost entirely automated and began by parsing the KML file and translating the GT GPS coordinates that describe the road approximately, into GSV panorama GPS locations, which describe the road accurately. The panorama locations are an accurate representation of the road since they were generated along the path of the Google car.\nGSV panoramas were investigated to find their spacing and coverage, which varied from 10 to 20 metres (Mazerolle and Blaney, 2011). The angle between sequential panorama locations gave the bearing of the road, which in turn revealed the perpendicular angle to the verge, allowing score label(s) to be assigned to each location. Providing that the location\u2019s verge direction had a corresponding score within the survey data, images were extracted from the panorama. The collection of these images became the annotated dataset, which was later used to train the CNN. This process also highlighted several issues. In particular, survey GPS locations often failed to line up with GSV panorama GPS locations, and could easily snap to a panorama within a different road, especially around junctions, with a naive approach. In addition to this, if there were not enough GT locations describing the road, or their accuracy was poor, it would lead to incorrectly calculated angles and cause extracted images to be mislabeled (Fig. 13)."
        },
        {
            "heading": "3.3. Road features and panorama locations",
            "text": "A small change in the number of GPS locations describing a road section can have a large effect on how these locations are labelled using the GT. As an example, adding a location C in Fig. 13 results in a more faithful orientation being assigned to the road section between locations A and B.\nWhen annotating CNN training images, accidental mislabelling introduces noise within the GT dataset. Such noise can originate from duplication (Fig. 4), incorrect verge angles (Fig. 13), snapping to the wrong panorama,\nor from the natural species variability of roadside verges. Interpolation of panorama locations between two points, (such as Point A and C, Fig. 13) may reveal a further set of GSV panoramas in which to extract verges images from.\nNot all of the images extracted from panoramas will be good examples of the score associated with the compass octant direction. The natural variability along any single verge section may see patches of high species rich grassland and, very likely, also areas with poor conservation potential, yet all images from this section will be labelled with the same score.\nVarious researchers (Stubbings et al., 2019; Kim et al., 2021; Nguyen et al., 2020) discuss using a grid, or intervals, to choose where to take images from. However, with the panorama locations having variable spacing this can lead to duplicate images being captured due to the nature of the GSV snap to grid translation of GPS points to panorama points.\nWhile requesting images from the expected GPS locations (Fig. 4) the requested image from D2 will return the same panorama as for C2. The Fig. 4 example will lead to an 11% image duplication which can cause the CNN to favour features within these duplicated images."
        },
        {
            "heading": "3.4. GT GPS Translation to GSV",
            "text": "Having investigated GPS locations that describe road features and their correlation to GSV panorama locations, a translation from one to the other was performed (Fig. 5a). Translation allows matching GT 8-way compass scores to the perpendicular verge at these translated panorama locations (Fig. 5b). Any panorama location that correlates to a GT score can have images extracted (Fig. 5c) to build the GT dataset."
        },
        {
            "heading": "3.5. Image Extraction and Dataset Building",
            "text": "A decision needed to be made in regards to how much and exactly what part of the panorama will be used. Fig. 5b shows two matching scoring directions of North and West with 3 other locations failing to be matched as their verge angle falls outside of a scoring octant. Extracting an image with a Field Of View (FOV) of 180\u00b0 perpendicular to the road would capture the entire verge, however this wide angle would also capture a lot of sky and road. Instead, three images of 45\u00b0 are taken. The FOV equates to zooming. Zoom in and the image can become pixelated, zoom out and details are lost.\nA FOV of 45\u00b0 was chosen as a good compromise that also correlates with an 8-way compass (Fig. 6). A pitch of 20\u00b0 was applied (moving the camera up within the panorama) to reduce the amount of road in the images.\nWhen building the dataset additional criteria was used to allow finer control over which images were chosen in order to reduce noise. Firstly, images were extracted from the 2009 summer months (June,July and August) from within the Lincolnshire Wolds area, to match the LovW survey data.\nThis produced 3396 images, with scores ranging from 0 to 19 but a 3rd of these fell into the lowest category. To increase the number of images the criteria was modified to also include the Northern Lincolnshire Edge area as well as the year 2021. This produced 6882 images with more images falling within other categories. GSV added images for both these areas in 2009 and 2021, with the later year also providing better quality images. All images were downloaded using the GSV API and have a size of 640 by 640 pixels, many of which have the Google logo embedded within.\nA manual annotation of these images was carried out to mark and remove bad images, which we classed as images that included cars, houses, verges that had been completely cut or where the verge was not in view. This removed 889 images. Due to road sections having start and end points, some sections shared the same panorama locations and produced duplicate images. 44 Duplicate images were removed leaving 5949 images within the dataset. There will still be noise present within the dataset, represented by poor quality imagery and images that mainly contain hedges or fields.\nImages were not taken from the 3rd area of Limestone Grassland so that there are images from an area that the model has never seen before, which will allow future model performance to be tested within a different locality."
        },
        {
            "heading": "4. Methodology",
            "text": ""
        },
        {
            "heading": "4.1. Baseline model",
            "text": "The key role for the use of a CNN is to find and extract objects within images, 1st stage, that belong to individual classes so that classification, 2ndstage, can be made. A baseline CNN model (Fig. 7) was built that could be used for experimentation, and to compare the effectiveness of employing a SOTA CNN model to improve performance.\nThe baseline model comprises of 6 convolution blocks (Fig. 7b-f, with d repeated), with each block followed by batch normalised (Ioffe and Szegedy, 2015), rectified with ReLu non-linearly (Agarap, 2019) and max pooling (Sun et al., 2021). Each block progressively increases the number of feature maps while reducing their dimensions. The Convolutions take the original 3 channel RGB image of 384 x 384 pixels down to 256 channels of 5 x 5 pixels, known as down sampling (Shorten and Khoshgoftaar (2019)). The resulting feature map array has a depth of 256 which is then flattened before being fed into the FCNN. The flattening allows connection of the 256 x 52 feature maps to 6400 artificial neuron inputs of the FCNN. Three layers or neurons are batch normalised followed by ReLu non-linearity before outputting the 4 classes (Fig. 7g-i).\nThe difference between the known class, the GT, and the learned probable class produces an error metric. A proportion of the error is back propagated (Li et al., 2012) through the model to update the filter parameters so as to reduce the error on the next training run (epoch). After multiple epochs this error is minimised and thereby classifying each image.\nThe process learns the best filter parameters that describe features within the image that are spatially independent from both the images themselves and other features found.\nAny parameter, a variable, that is set before the model is run to control its behaviour is called a hyper-parameter, as opposed to parameters that get changed as a result of the running. Hyper-parameters were tuned during training (Sect. 4.3)."
        },
        {
            "heading": "4.2. Augmentation and Image Transformations",
            "text": "Augmentation is used to both artificially increase the number of images and to make random image transformations of each image, since the model needs to learn generalised features and not precise features (Shorten and Khoshgoftaar, 2019; Li et al., 2021). Since the Google Car (in most cases) drives on one side of the road and not in the middle, extracted images take on perspective, rotation, brightness and scale variations. Fig. 8 shows images from 3 panoramas highlighting these variations and can be used to inform an augmentation policy. The variations show perspective, brightness and contrast and scaling differences, leading to an augmentation policy that can include images being randomly horizontally flipped, normalised, scaled and with perspective distortion. Additionally, it can be assumed that the car will go over bumps, effectively causing possible camera rotation.\nAny given image will be fed into a CNN model multiple times (once per epoch / training run) but transformed randomly each time, so the model sees multiple variations of the same image. Features within the images that remain invariant to the random transformations will be learnt. With each image having a classification label (a score group) situations arise whereby some classes (groups) have many more image examples in than others (class imbalance). The imbalance between classes can be evened out by over-sampling\nminority classes to match the majority class. Over-sampling involves duplicating images but applying one or more random transformations (Table 2) to each image to form a different image."
        },
        {
            "heading": "4.3. Training and Experiments",
            "text": "Training the model involved splitting the dataset up into training, validation and test (held-out) sub-sets (70%, 10% and 20%). The validation set was augmented and balanced and was used for hyper-parameter tuning during training runs and the held-out set used for measuring the model\u2019s performance on images not seen by the model, to simulate a more real world test.\nEach training run consisted of 50 or 100 epochs with each epoch presenting the training set to the model using a different image shuffle, along with a different random augmentation applied. The shuffling and random augmentations require controlling via the use of Python\u2019s, Pytorch\u2019s and Numpy\u2019s Random Number Generator (RNG) (Pytorch, 2019) seed in order for experiments to be reproducible. A seed of 0 was used throughout.\nA software tool was developed so that the entire pipeline from parsing the LWT KML file to the choice of CNN hyper-parameters, approximately 75 variables, could be configured and controlled. With such a large number of variables a full grid search seeking the absolute best parameters could not be employed, however a manual grid search was employed concentrating upon the main hyper-parameters of the CNN and covered approximately 500 training runs.\nExperiments were conducted using Ubuntu 21 OS with 32GB main memory, Intel i9 12th Gen. processor and a Nvidia RTX 3080 Ti GPU.\nOnce the most important tuning parameters were found, various experiments were carried out by iteratively adding different augmentations and other components (Table. 3), changing the model each time, and looking at the effect each had upon the model\u2019s performance, as measured by accuracy in predicting the class of each image.\nEach iteration, 0 to 6, was trained over 50 epochs with iterations 7 to 9 fine tuned with a further 50 epochs from iteration 6. As components are added some early iterations produced worse results, such as adding the component bad image purge, which turned out to be caused by duplicate images being left within the dataset. This was rectified in the last iteration. The benefit of over-sampling to balance the classes was not seen until further augmentation transforms were applied in later iterations.\nGradually a model and pipeline was arrived at that gave a result of 82.27%, tested against the held-out image set. The result suggested that the augmentation policy and hyper-parameters were ready to be tested using SOTA models to achieve a performance increase.\nThe baseline model was substituted for SOTA CNN models of increasing depth. The training results (Table 4), showed that pre-trained SOTA models gave upto a 6.72% test accuracy improvement, with no other alterations to the pipeline. The models have been pre-trained using ImageNet challenge (Russakovsky et al., 2015) and therefore give the model a lot of prior knowledge as a starting point, with our pipeline fine tuning the model for our specific need. The image batch size was set to maximise available memory, nearest power of 2, with the final layer of the FCNN, which has 1000 classification outputs, reduced to 4.\nThe deeper the model the harder it will be to train (He et al., 2016), although this has not been experienced. The first ResNet-18 model had no\nprevious knowledge before training but still had a similar number of learnable parameters, compared to the baseline, but did not perform as well, possibly being caused by the model being too complex to train with limited epochs.\nTraining performance plots, (Figs. 9 and 10), clearly show the end of training using a learning rate of 1e-04 for the first 50 epochs. The learned knowledge is then passed back into the model for the second stage of training at the smaller learning rate of 1e\u22125.\nThe performance metrics are all calculated using multi-class versions of standard binary class metrics. The large performance swings from one epoch to the next reflects the random nature of augmentation differences between epochs. The variations would be less with a larger dataset or with a smaller learning rate."
        },
        {
            "heading": "5. Results",
            "text": "Uniform Manifold Approximation and Projection (UMAP) is a dimension reduction technique that is used for visualising general non-linear dimension reduction. The visualised results, (Figs. 11 and 12), show a UMAP clustering plot and a confusion matrix plot, detailing how the best performing ResNeXt model has classified each image (88.99% accuracy) from within the heldout test dataset, for one shuffle, using a seed of 0 for reproducibility. Class imbalance shows up within each class\u2019 performance and sees the highest class (12+) being most effected between dataset shuffles due to having the least\n0 2 4 6 8 10 12 1\n2\n3\n4\n5\n6\n7\n8\n9\n0-3\n4-7\n8-11\n12+\nCl as s\nFigure 11: UMAP Projection of ResNeXt-50 model for fold-1\n0-3 4-7 8-11 12+ Predicted label\n0-3\n4-7\n8-11\n12+\nTr ue\nla be\nl\n651 (94.35%) 29 (4.20%) 5 (0.72%) 5 (0.72%)\n32 (9.82%) 283 (86.81%) 10 (3.07%) 1 (0.31%)\n16 (14.68%) 9 (8.26%) 82 (75.23%) 2 (1.83%)\n8 (12.50%) 4 (6.25%) 5 (7.81%) 47 (73.44%)\n0%\n20%\n40%\n60%\n80%\n100%\nFigure 12: ResNeXt-50 held out test set confusion matrix for fold-1\nsamples. Overall metrics are reported for 5-fold cross validation with the best fold shown within Table 5. The 5-Fold summary (Table. 6) has a mean accuracy of 88% with precision, recall and F1-score metrics calculated using macro averaging, PAvg = (Pclass1 + Pclass2 + Pclass3 + Pclass4)/Nclasses."
        },
        {
            "heading": "6. Discussion",
            "text": "While work continues on this project, it is not currently known how many classes can be distinguished from. The results show a 4 class system performs well, although less classes have shown better accuracy (well into the 90% bracket) and a 5 class output also produces accuracy above 80%. Class imbalance of verge samples provide a big challenge since over sampling minority classes, using augmentation, is not a good substitute for original images of verges with a higher number of positive indicator species. A larger dataset with more samples from the minority classes, rectifying class imbalance with real data, could possibly increase performance of all classes to 90%+ accuracy. On going work will interpolate between road features, Fig. 13, giving more panorama locations to extract more higher scoring samples to alleviate class this imbalance. Different techniques addressing class imbalance such as a combination of under-sampling majority and over-sampling minority classes (Chawla et al., 2002) could also be employed. Understanding interclass knowledge inside the CNN may also be a direction to explore (Wei et al., 2015; Long et al., 2014) as would be the effect that the overall image scene, sky and road, has upon classifying verges.\nExperiments (Sect. 4.3) would seem to backup comments (Razavian et al., 2014) suggesting SOTA models can be taken off the shelf and fine\ntuned, rather than hand crafting specific models for many applications, although perhaps with an added caveat of several models should be tried before choosing."
        },
        {
            "heading": "7. Conclusion",
            "text": "GSV imagery can be an effective data source for the remote surveying of roadside verges to a high probability that could identify verges that have little to no conservation potential. An automated pipeline enabling a SOTA CNN to learn both the fine differences between inter-class and broad differences within intra-class features is a possible remote replacement for large scale physical surveys that would normally take many hours spread over, potentially, years. Remote surveying or monitoring could be accomplished within hours for a fairly large area. With GPU / Computer technology constantly improving the situation year on year would afford either bigger areas to be surveyed within a usable time frame or surveys to be carried and results obtained within the same day. The implications of this study lie within the importance placed upon identification of LWSs for use within conservation management and environmental planning that local authorities are required to carry out. We Demonstrate that remote surveying using GSV as a data source for classification by a CNN is possible and would give authorities a cost effective way to manage and monitor their legal responsibilities whilst simultaneously aiding conservation efforts."
        },
        {
            "heading": "8. Acknowledgements",
            "text": "This project would not have been possible without the Lincolnshire Wildlife Trust\u2019s (Lincolnshire Wildlife Trust, 2021) invaluable survey results from their Life on the Verge projects (Lincolnshire Wildlife Trust, 2016). The thousands of hours work put in by 250 volunteers years ago are still being appreciated."
        }
    ],
    "title": "DeepVerge: Classification of Roadside Verge Biodiversity and Conservation Potential",
    "year": 2022
}