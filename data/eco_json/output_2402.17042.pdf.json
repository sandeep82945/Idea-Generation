{
    "abstractText": "Randomized Controlled Trials (RCTs) are pivotal in generating internally valid estimates with minimal assumptions, serving as a cornerstone for researchers dedicated to advancing causal inference methods. However, extending these findings beyond the experimental cohort to achieve externally valid estimates is crucial for broader scientific inquiry. This paper delves into the forefront of addressing these external validity challenges, encapsulating the essence of a multidisciplinary workshop held at the Institute for Computational and Experimental Research in Mathematics (ICERM), Brown University, in Fall 2023. The workshop congregated experts from diverse fields including social science, medicine, public health, statistics, computer science, and education, to tackle the unique obstacles each discipline faces in extrapolating experimental findings. Our study presents three key contributions: we integrate ongoing efforts, highlighting methodological synergies across fields; provide an exhaustive review of generalizability and transportability based on the workshop\u2019s discourse; and identify persistent hurdles while suggesting avenues for future research. By doing so, this paper aims to enhance the collective understanding of the generalizability and transportability of causal effects, fostering cross-disciplinary collaboration and offering valuable insights for researchers working on refining and applying causal inference methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "Melody Y. Huang"
        },
        {
            "affiliations": [],
            "name": "Sarah E. Robertson"
        }
    ],
    "id": "SP:3ce3e2441c696230a420f64d1e87fb945bd659a4",
    "references": [
        {
            "authors": [
                "M. Bennett",
                "J.P. Vielma",
                "J.R. Zubizarreta"
            ],
            "title": "Building representative matched samples with multi-valued treatments in large observational studies",
            "year": 2020
        },
        {
            "authors": [
                "C.L. Brantner",
                "Chang",
                "T.-H",
                "T.Q. Nguyen",
                "H. Hong",
                "L. Di Stefano",
                "E.A. Stuart"
            ],
            "title": "Methods for integrating trials and non-experimental data to examine treatment effect heterogeneity",
            "venue": "arXiv preprint arXiv:2302.13428",
            "year": 2023
        },
        {
            "authors": [
                "A.L. Buchanan",
                "M.G. Hudgens",
                "S.R. Cole",
                "K.R. Mollan",
                "P.E. Sax",
                "E.S. Daar",
                "A.A. Adimora",
                "J.J. Eron",
                "M.J. Mugavero"
            ],
            "title": "Generalizing evidence from randomized trials using inverse probability of sampling weights",
            "venue": "Journal of the Royal Statistical Society Series A: Statistics in Society,",
            "year": 2018
        },
        {
            "authors": [
                "Y. Cheng",
                "L. Wu",
                "S. Yang"
            ],
            "title": "Enhancing treatment effect estimation: A model robust approach integrating randomized experiments and external controls using the double penalty integration estimator",
            "venue": "In Uncertainty in Artificial Intelligence,",
            "year": 2023
        },
        {
            "authors": [
                "V. Chernozhukov",
                "D. Chetverikov",
                "M. Demirer",
                "E. Duflo",
                "C. Hansen",
                "W. Newey",
                "J. Robins"
            ],
            "title": "Double/debiased machine learning for treatment and structural parameters",
            "year": 2018
        },
        {
            "authors": [
                "H.A. Chipman",
                "E.I. George",
                "R. McCulloch"
            ],
            "title": "Bayesian ensemble learning",
            "venue": "In Advances in Neural Information Processing Systems",
            "year": 2007
        },
        {
            "authors": [
                "S.R. Cole",
                "E.A. Stuart"
            ],
            "title": "Generalizing evidence from randomized clinical trials to target populations: The actg 320 trial",
            "venue": "American Journal of Epidemiology,",
            "year": 2010
        },
        {
            "authors": [
                "B. Colnet",
                "I. Mayer",
                "G. Chen",
                "A. Dieng",
                "R. Li",
                "G. Varoquaux",
                "Vert",
                "J.-P",
                "J. Josse",
                "S. Yang"
            ],
            "title": "Causal inference methods for combining randomized trials and observational studies: a review",
            "venue": "arXiv preprint arXiv:2011.08047",
            "year": 2020
        },
        {
            "authors": [
                "I.J. Dahabreh",
                "M.A. Hern\u00e1n"
            ],
            "title": "Extending inferences from a randomized trial to a target population",
            "venue": "European journal of epidemiology,",
            "year": 2019
        },
        {
            "authors": [
                "I.J. Dahabreh",
                "S.E. Robertson",
                "M.A. Hern\u00e1n"
            ],
            "title": "Generalizing and transporting inferences about the effects of treatment assignment subject to non-adherence",
            "venue": "arXiv preprint arXiv:2211.04876",
            "year": 2022
        },
        {
            "authors": [
                "I.J. Dahabreh",
                "S.E. Robertson",
                "L.C. Petito",
                "M.A. Hern\u00e1n",
                "J.A. Steingrimsson"
            ],
            "title": "Efficient and robust methods for causally interpretable meta-analysis: Transporting inferences frommultiple randomized trials to a target population",
            "year": 2023
        },
        {
            "authors": [
                "I.J. Dahabreh",
                "S.E. Robertson",
                "E.J. Tchetgen",
                "E.A. Stuart",
                "M.A. Hern\u00e1n"
            ],
            "title": "Generalizing causal inferences from individuals in randomized trials to all trial-eligible individuals",
            "year": 2019
        },
        {
            "authors": [
                "I. Degtiar",
                "S. Rose"
            ],
            "title": "A review of generalizability and transportability",
            "venue": "Annual Review of Statistics and Its Application,",
            "year": 2023
        },
        {
            "authors": [
                "J. Duchi",
                "H. Namkoong"
            ],
            "title": "Learning models with uniform performance via distributionally robust optimization. arXiv preprint arXiv:1810.08750",
            "year": 2018
        },
        {
            "authors": [
                "N. Egami",
                "E. Hartman"
            ],
            "title": "Elements of external validity: Framework, design, and analysis",
            "venue": "American Political Science Review,",
            "year": 2022
        },
        {
            "authors": [
                "M.R. Elliott",
                "O. Carroll",
                "R. Grieve",
                "J. Carpenter"
            ],
            "title": "Improving transportability of randomized controlled trial inference using robust predictionmethods",
            "venue": "Statistical Methods in Medical Research,",
            "year": 2023
        },
        {
            "authors": [
                "M. Gechter",
                "C. Samii",
                "R. Dehejia",
                "C. Pop-Eleches"
            ],
            "title": "Evaluating ex ante counterfactual predictions using ex post causal inference. arXiv preprint arXiv:1806.07016",
            "year": 2018
        },
        {
            "authors": [
                "M. Huang"
            ],
            "title": "Sensitivity analysis in the generalization of experimental results",
            "venue": "arXiv preprint arXiv:2202.03408",
            "year": 2022
        },
        {
            "authors": [
                "M. Huang",
                "N. Egami",
                "E. Hartman",
                "L. Miratrix"
            ],
            "title": "Leveraging population outcomes to improve the generalization of experimental results: Application to the jtpa study",
            "year": 2023
        },
        {
            "authors": [
                "J.H. Huling"
            ],
            "title": "Transportability of prinicipal causal effects. ICERM",
            "year": 2023
        },
        {
            "authors": [
                "K. Imai",
                "G. King",
                "E.A. Stuart"
            ],
            "title": "Misunderstandings between experimentalists and observationalists about causal inference",
            "venue": "Journal of the Royal Statistical Society: Series A (Statistics in Society),",
            "year": 2008
        },
        {
            "authors": [
                "H.L. Kern",
                "E.A. Stuart",
                "J. Hill",
                "D.P. Green"
            ],
            "title": "Assessing methods for generalizing experimental impact estimates to target populations",
            "venue": "Journal of Research on Educational Effectiveness,",
            "year": 2016
        },
        {
            "authors": [
                "M.P. Kim",
                "C. Kern",
                "S. Goldwasser",
                "F. Kreuter",
                "O. Reingold"
            ],
            "title": "Universal adaptability: Targetindependent inference that competes with propensity scoring",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2022
        },
        {
            "authors": [
                "W.M. Kouw",
                "M. Loog"
            ],
            "title": "An introduction to domain adaptation and transfer learning",
            "venue": "arXiv preprint arXiv:1812.11806",
            "year": 2018
        },
        {
            "authors": [
                "F. Li",
                "A.L. Buchanan",
                "S.R. Cole"
            ],
            "title": "Generalizing trial evidence to target populations in nonnested designs: Applications to aids clinical trials",
            "venue": "Journal of the Royal Statistical Society Series C: Applied Statistics,",
            "year": 2022
        },
        {
            "authors": [
                "L.W. Miratrix",
                "J.S. Sekhon",
                "A.G. Theodoridis",
                "L.F. Campos"
            ],
            "title": "Worth weighting? how to think about and use weights in survey experiments",
            "venue": "Political Analysis,",
            "year": 2018
        },
        {
            "authors": [
                "M. Morucci",
                "V. Orlandi",
                "H. Parikh",
                "S. Roy",
                "C. Rudin",
                "A. Volfovsky"
            ],
            "title": "A double machine learning approach to combining experimental and observational data",
            "venue": "arXiv preprint arXiv:2307.01449",
            "year": 2023
        },
        {
            "authors": [
                "T.Q. Nguyen",
                "C. Ebnesajjad",
                "S.R. Cole",
                "Stuart",
                "E. A"
            ],
            "title": "Sensitivity analysis for an unobserved moderator in rct-to-target-population generalization of treatment effects",
            "year": 2017
        },
        {
            "authors": [
                "R.B. Olsen",
                "L.L. Orr",
                "S.H. Bell",
                "E.A. Stuart"
            ],
            "title": "External validity in policy evaluations that choose sites purposively",
            "venue": "Journal of Policy Analysis and Management,",
            "year": 2013
        },
        {
            "authors": [
                "S.J. Pan",
                "Q. Yang"
            ],
            "title": "A survey on transfer learning",
            "venue": "IEEE Transactions on knowledge and data engineering,",
            "year": 2009
        },
        {
            "authors": [
                "H. Parikh",
                "R. Ross",
                "E. Stuart",
                "K. Rudolph"
            ],
            "title": "Who are we missing? a principled approach to characterizing the underrepresented population",
            "venue": "arXiv preprint arXiv:2401.14512",
            "year": 2024
        },
        {
            "authors": [
                "H. Rahimian",
                "S. Mehrotra"
            ],
            "title": "Distributionally robust optimization: A review",
            "venue": "arXiv preprint arXiv:1908.05659",
            "year": 2019
        },
        {
            "authors": [
                "I. Redko",
                "E. Morvant",
                "A. Habrard",
                "M. Sebban",
                "Y. Bennani"
            ],
            "title": "Advances in domain adaptation theory",
            "year": 2019
        },
        {
            "authors": [
                "S.E. Robertson",
                "J.A. Steingrimsson",
                "I.J. Dahabreh"
            ],
            "title": "Regression-based estimation of heterogeneous treatment effects when extending inferences from a randomized trial to a target population",
            "venue": "European Journal of Epidemiology,",
            "year": 2023
        },
        {
            "authors": [
                "Rudolph",
                "van der Laan"
            ],
            "title": "Robust estimation of encouragement design intervention effects transported across sites",
            "venue": "Journal of the Royal Statistical Society Series B: Statistical Methodology,",
            "year": 2017
        },
        {
            "authors": [
                "Rudolph",
                "N.T. Williams",
                "E.A. Stuart",
                "I. Diaz"
            ],
            "title": "Efficiently transporting average treatment effects using a sufficient subset of effect modifiers",
            "venue": "arXiv preprint arXiv:2304.00117",
            "year": 2023
        },
        {
            "authors": [
                "K. Rudolph",
                "M. van Der Laan"
            ],
            "title": "Robust estimation of encouragement design intervention effects transported across sites",
            "venue": "Journal Of The Royal Statistical Society Series B-Statistical Methodology,",
            "year": 2017
        },
        {
            "authors": [
                "H. Schmidli",
                "D.A. H\u00e4ring",
                "M. Thomas",
                "A. Cassidy",
                "S. Weber",
                "F. Bretz"
            ],
            "title": "Beyond randomized clinical trials: use of external controls",
            "venue": "Clinical Pharmacology & Therapeutics,",
            "year": 2020
        },
        {
            "authors": [
                "N. Schnitzler",
                "E. Kaizar"
            ],
            "title": "A two-stage method for extending inferences from a collection of trials",
            "venue": "arXiv preprint arXiv:2309.03693",
            "year": 2023
        },
        {
            "authors": [
                "M. Staib",
                "S. Jegelka"
            ],
            "title": "Distributionally robust optimization and generalization in kernel methods",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "E.A. Stuart",
                "C.P. Bradshaw",
                "P.J. Leaf"
            ],
            "title": "Assessing the generalizability of randomized trial results to target populations",
            "venue": "Prevention Science,",
            "year": 2015
        },
        {
            "authors": [
                "E.A. Stuart",
                "S.R. Cole",
                "C.P. Bradshaw",
                "P.J. Leaf"
            ],
            "title": "The use of propensity scores to assess the generalizability of results from randomized trials: Use of propensity scores to assess generalizability",
            "venue": "Journal of the Royal Statistical Society: Series A (Statistics in Society),",
            "year": 2011
        },
        {
            "authors": [
                "E. Tipton",
                "M. Mamakos"
            ],
            "title": "Designing randomized experiments to predict unit-specific treatment effects",
            "venue": "arXiv preprint arXiv:2310.18500",
            "year": 2023
        },
        {
            "authors": [
                "Vo",
                "T.-T",
                "K.E. Rudolph",
                "I. Diaz"
            ],
            "title": "Heterogeneity assessment in causal data fusion problems",
            "venue": "arXiv preprint arXiv:2208.05543",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n40 2.\n17 04\n2v 1\n[ st\nat .M\nE ]\n2 6\nFe b\nKeywords: Causal Inference, Generalizability, External validity, Machine Learning\n\u2217Co-first authors; All authors contributed equally to the paper.\nThe authors would like to thank Elizabeth Stuart, Kara Rudolph, Quinn Lanners for their comments and feedback on the paper. Also, the authors would like to thank the ICERM workshop organizers Elizabeth Stuart, Jon Steingrimsson, and Issa Dahabreh as well as the participants for engaging in the discourse and discussion. \u2020HDSI Postdoctoral Fellow, Harvard University, Dept. of Statistics & IQSS, Email: melodyhuang@fas.harvard.edu \u2021Postdoctoral Fellow, Harvard T.H. Chan School of Public Health, Email: srobertson@hsph.harvard.edu \u00a7Postdoctoral Fellow, Johns Hopkins University, Dept. of Biostatistics, Email: hparikh4@jh.edu"
        },
        {
            "heading": "1 Introduction",
            "text": "Randomized controlled trials (RCTs) are often considered the gold standard for estimating causal effects. From field experiments to medical clinical trials, RCTs form the bedrock of decision-making in social sciences, public health, medicine, and other fields. However, a major challenge is assessing the external validity of the estimated causal effects from the trial. Researchers generally care not only about the estimated effect within their experimental sample, but also about the impact of a specific intervention beyond the experiment, within a larger, or different target population. Due to feasibility or ethical constraints, RCTs rarely comprise a representative sample from the target population, limiting the external validity of the estimated results.\nLimitations to external validity arise from differences between the trial and target populations. These differences can be a result of (i) observed or unobserved pretreatment characteristics, (ii) settings such as geography, the timing of treatment, dosage, or staff training, and (iii) outcomes, such as the length and timings of measurements (Degtiar and Rose, 2023). Challenges to the generalizability of trials prompt careful consideration of necessary and realistic assumptions for the identification and estimation of causal effects for the target population (Stuart et al., 2015). A variety of posthoc adjustment methods have been proposed to account for differences in the trial and target populations, allowing researchers to estimate externally valid causal effects under certain assumptions (e.g., Chipman et al., 2007; Stuart et al., 2011; Kern et al., 2016; Rudolph and van Der Laan, 2017; Bennett et al., 2020; Rudolph et al., 2023; Dahabreh et al., 2019).\nIn this paper, we discuss recent advancements in the generalizability and transportability literature. We refer to generalizability analyses as interest in learning about a restricted target population that meets all trial eligibility criteria and transportability analyses as interest in learning about a target population broader than the trial eligibility criteria Dahabreh and Herna\u0301n (2019). In particular, we focus on the setting in which the trial population is a non-representative subset of the target population. This paper provides a comprehensive overview of recent work discussed at a workshop hosted by the Institute for Computational and Experimental Research in Mathematics (ICERM) at Brown University in Fall 2023 on \u201cExtending Inferences from Trials to Target Population\u201d.\nThe workshop brought together researchers from diverse interdisciplinary backgrounds, spanning social science, medicine, public health, statistics, computer science, and education. The unique substantive settings and challenges of researchers in each discipline introduce distinct challenges when generalizing experimental results. For instance, within the context of trials, ethical concerns around potential comorbidities from treatment and preventing negative treatment outcomes are paramount in medicine and public health. As such, many experimental studies in medicine impose selective criteria in trial participation. As a result, it can\nthen be difficult to assess the effectiveness of a medical intervention on individuals systematically excluded from participating in the trial. As another example, education researchers often grapple with challenges arising from small sample sizes and the intricacies of clustered randomized controlled trial settings. As such, being able to understand treatment effect variation with limited units is crucial to designing an externally valid study.\nThe overarching goal of this article is to synthesize ongoing work in the generalizability (and transportability) literature, providing a summary that unifies methodological themes across diverse fields. It seeks to highlight challenges encountered in the pursuit of generalizability and transportability and to pinpoint methodological gaps in the current landscape. We identify three major themes that encompass the current work: (i) assessment of the external validity of trials (Section 2), (ii) considering external validity beyond intention-to-treat effects (Section 3), and (iii) leveraging advancements in machine learning approaches to improve estimation in external validity (Section 4). We conclude the paper with a brief discussion of existing challenges and potential future directions in Section 5."
        },
        {
            "heading": "2 Validity of Identifying Assumptions under Covariate Shifts",
            "text": "One primary source of bias when aiming to estimate externally valid causal effects arises from differences in the underlying distribution of treatment effect moderators between the experimental sample and the target population (e.g., Imai et al., 2008; Cole and Stuart, 2010; Olsen et al., 2013; Egami and Hartman, 2022). Informally, moderators are covariates that describe how the treatment will differentially affect individuals. Thus, to estimate a valid causal effect across a target population of interest, researchers must adjust for the covariate shift in the underlying moderators between the experimental sample and the target population. Two common identifying assumptions leveraged in practice are (1) selection on observables (also referred to as conditional exchangeability) and (2) positivity of trial participation.\nThe first assumption, selection on observables, assumes that researchers can control for all distributional differences in moderators between the experimental sample and the target population. The selection on observables assumption is also referred to as conditional ignorability of treatment effect heterogeneity and selection, or conditional mean exchangeability (e.g., Dahabreh et al., 2019; Cole and Stuart, 2010; Olsen et al., 2013). In general, the selection on observables assumption is often challenging to justify in practice. First, while researchers have more control over which covariates are measured across the experimental sample, there is often less availability of covariates measured across the target population. Researchers generally rely\non electronic health records, census data, or large-scale surveys for covariate information across the target population. As such, there are often moderators that researchers know to be important, but cannot control for, as there is no population-level measure (e.g., Nguyen et al., 2017). Second, even if target population covariates are available, how the target population data is measured may differ, which can challenge estimation. Finally, even in the trial measuring the full set of moderators that account for treatment effect heterogeneity requires strong substantive knowledge.\nThe second assumption, the positivity of trial participation, requires that all units in the target population have a non-zero chance of being in the experimental sample. This assumption may be violated due to logistical, financial, and ethical constraints. From a logistical standpoint, researchers\u2019 priority tends to be maximizing power within their experimental study or efficient recruitment of study subjects \u2014 not external validity. As a result, recruiting as many units as possible into the experiment as easily as possible is generally a priority, as this can improve the precision of the within-sample treatment effect. Financially, recruiting a truly representative experimental sample can be infeasible, as the target population often consists of hard-to-reach individuals, many of whom will be costly to reach and recruit for the experiment. Finally, exclusion criteria in experiments can result in subsets of the target population being omitted from studies, thus violating positivity. For example, pregnant individuals are often excluded from early-stage medical trials due to ethical considerations but may be considered part of a target population of interest.\nWhile the combination of these assumptions allows researchers to theoretically identify the target population\u2019s average treatment effect, in practice, they can be difficult to justify. Several recent advancements focus on methods to help researchers consider the validity of the underlying identifying assumptions. We summarize key themes below:\nUnderstanding Treatment Effect Heterogeneity. Both selection on observables and positivity of trial participation rely on researchers knowing which covariates moderate the treatment effect of the intervention of interest. This is important for both the design stage of an experiment\u2013i.e., understanding which individuals to recruit into the experimental sample\u2013and for post-hoc adjustments\u2013i.e., knowing which covariates to collect across both the experimental sample and the target population. Tipton and Mamakos (2023) provides a new view on the importance of understanding the underlying moderators by formulating the challenge of generalizing experimental results as a prediction problem. In particular, the authors highlight that in the absence of a sufficiently heterogeneous experimental sample, the target populations that the experimental results can be generalized (or transported) to will be limited. Furthermore, not only will\nstandard estimated effects be biased for population quantities, but the associated uncertainty will also be incorrect, making inference challenging as well. In the absence of knowledge about heterogeneity, it can be challenging to effectively recruit a representative experimental sample, and it will be infeasible to perform posthoc adjustment.\nDeveloping Methods for Researchers to Incorporate Substantive Knowledge. Incorporating substantive knowledge into research methodologies is crucial for formulating effective policy recommendations, especially when utilizing existing experimental data in new domains. Gechter et al. (2018) introduce a structured approach to integrating expert knowledge with ex-post experimental evidence for assessing modeling choices for policy recommendation. This process aids in selecting the appropriate method for generating preliminary recommendations in contexts lacking experimental data. Similarly, addressing the challenge of positivity violations\u2014where certain subgroups are absent from the sample\u2014requires reliance on substantive knowledge or mechanistic models. Zivich et al. (2023) introduces a novel approach that employs deterministic mathematical models to calculate treatment effects for segments of the target population not included in the experimental sample. This method then integrates these calculations with traditional statistical models for areas where data overlap exists, providing a comprehensive estimation of the average treatment effect for the entire target population.\nAssessing Validity of Identifying Assumptions. Sensitivity analyses allow researchers to consider the robustness of results to violations of the underlying assumptions. In the context of evaluating selection on observables assumptions, sensitivity analyses often take the form of parameterizing the bias that arises from omitting a moderator, either from the estimated weights (e.g., Cole and Stuart, 2010; Stuart et al., 2011; Buchanan et al., 2018), or the underlying treatment effect heterogeneity model (e.g., Kern et al., 2016). If researchers find that even for a relatively weak moderator, the resulting bias is very large, then this implies that there is a relatively large degree of sensitivity to an omitted moderator. In contrast, if researchers find that the bias is small even for relatively strong moderators, then this implies a greater degree of robustness. A recent paper by Huang (2022) decomposes the bias from omitting a moderator (i.e., a violation in the underlying selection on observables assumption) into two sensitivity parameters: an R2 value that represents how imbalanced an omitted moderator is across the trial sample and target population and a correlation term that represents how correlated the omitted moderator is to the individual-level treatment effect. The paper also introduces a suite of sensitivity tools that allow researchers to summarize the robustness of their\ngeneralized estimates transparently and systematically. These tools include numerical summary measures, like the robustness value, visual summary measures in the form of bias contour plots, and a benchmarking approach that allows researchers to incorporate the observed covariates into the sensitivity analysis and calibrate what might be plausible sensitivity parameters."
        },
        {
            "heading": "3 Beyond Transporting intention-to-treat Effects",
            "text": "Most transportability methods primarily focus on estimating the effects of assignment (e.g., intention-to-treat effect analogs) in the target population. However, recent work discussed at ICERM (Dahabreh et al., 2022) highlights that the effect of assignment may be unidentifiable, especially when non-adherence is present. When non-adherence is present, other causal effects may be of interest instead (Huling, 2023). We start by reviewing assumptions often implicitly assumed, in addition to the more explicitly stated assumptions of no selection on the observables and positivity of trial participation discussed in the previous section, that are needed to identify the effect of assignment in the target population.\nVariation Irrelevance for Treatment Assignment. Variation irrelevance for treatment assignment holds when there is no direct effect of assignment on the outcome. In other words, the outcome is not affected by how treatment is assigned. However, the assignment may include double-blinding in the trial, which will not occur in clinical practice and may directly affect the outcome. Therefore, pragmatic trials, with open-label assignment, may be more transportable and more likely to have the assignment variation irrelevance hold.\nPerfect Adherence to Treatment Assignment. Perfect adherence occurs when the assigned treatment is always equal to the received treatment, both within and outside the trial. However, adherence is generally higher in trials than in target populations of interest.\nNo Trial Engagement Effects. Trial engagement effects (Dahabreh and Herna\u0301n, 2019) are any effects participation has on the outcome, either directly on the outcome or indirectly on the outcome (e.g., participation increasing adherence) (Rudolph and van der Laan, 2017; Morucci et al., 2023).\nMost work on transportability (Dahabreh et al., 2019) require these assumptions of assignment variation\nirrelevance, perfect adherence, and no trial-engagement effects when identifying the effect of assignment in the target population. Yet these are strong assumptions and need to be closely examined. Considering possible causal structures by drawing causal directed acyclic graphs over the trial and target population is one way to help examine these assumptions. One example of a causal structure shows that even if there are no trial-engagement effects when participation in the trial has unmeasured common causes with treatment receipt (i.e., there is non-adherence), then it is not possible to identify the effect of assignment in the target population (Dahabreh et al., 2022). However, assuming an absence of unmeasured common causes with treatment receipt, even in the presence of trial-engagement effects, it may instead be possible to learn about the joint intervention interventions to scale up trial activities that affect adherence and assign treatment.\nThus, there is a need to move beyond just identifying the effect of assignment alone in the target population, especially since in many cases these assumptions will not hold, making the effect unidentifiable. For many transportability analyses, it may be more realistic to focus on other causal estimands. At ICERM, principal stratification (Huling, 2023) was discussed as one strategy to estimate alternative causal effects in the target population."
        },
        {
            "heading": "4 Machine Learning and Generalizability",
            "text": "Recent work in machine learning (ML) has enabled researchers to flexibly estimate causal relationships between variables in complex data settings (Chernozhukov et al., 2018; Rudolph and van der Laan, 2017). ML methods offer several advantages over traditional approaches, particularly in their ability to flexibly handle high-dimensional data with nonlinear dependencies (Morucci et al., 2023). In the following section, we discuss recent advances in ML and how they can be utilized to help improve estimation in the context of generalizability.\nOne of the key strengths of ML in causal inference lies in its flexibility to model nuisance parameters, which are factors that influence the outcome but are not of primary interest. By effectively modeling these nuisance parameters, ML algorithms can provide more precise estimates of heterogeneous causal effects, which is crucial to understanding generalizability (Huang et al., 2023). In addition to its modeling flexibility, ML exhibits remarkable efficiency, particularly in high-dimensional scenarios. ML algorithms can extract meaningful patterns from large and complex datasets, leading to more accurate and efficient causal inference. This efficiency translates into the ability to derive reliable insights from smaller, less expensive datasets, particularly valuable in settings where data collection is costly or time-consuming.\nCurrent ML-aided approaches for generalizing causal inferences from randomized controlled trials (RCTs)\nto target populations focus on three main areas:\nEstimating heterogeneous effects. Identifying effect moderators is a key part of understanding the potential generalizability or transportability of study results. With their ability to capture complex nonlinear relationships and handle high-dimensional data, ML methods are well-suited to estimate heterogeneous treatment effects (Brantner et al., 2023; Colnet et al., 2020; Robertson et al., 2023). Recent advancements have focused on efficient estimation in high-dimensional scenarios (Rudolph et al., 2023; Vo et al., 2022), multi-calibration for transportability to an (unknown) target population (Kim et al., 2022), predicting individualized causal effects (Tipton and Mamakos, 2023), and using flexible ML approaches for robust estimation (Elliott et al., 2023).\nLeveraging Multiple Data Sources. Machine learning approaches for leveraging multiple data sources (i.e., data fusion) present a cost-effective and time-efficient alternative to conducting extensive cohort RCTs. This approach enhances the capability to generalize or transport estimated treatment effects across different populations (Cheng et al., 2023; Schmidli et al., 2020; Morucci et al., 2023; Schnitzler and Kaizar, 2023). For instance, Schnitzler and Kaizar (2023) introduces a two-stage method to extend inferences from multiple RCTs to a target population. Similarly, ML methods can be employed to borrow information from external control datasets, even if these datasets are not perfectly representative of the RCT population. This enables researchers to draw reliable conclusions from smaller, less expensive RCTs (Morucci et al., 2023; Schmidli et al., 2020). Generalizing or transporting experimental results can result in large efficiency loss, as a result in variance inflation from weighting (e.g., Miratrix et al., 2018). Recent work has shown that researchers can leverage machine learning and external controls to effectively residualize their experimental data, allowing for more efficient generalizations to different target populations (e.g., Huang et al., 2023). However, combining multiple sources of data (e.g., as in a meta-analysis of individual patient data to an external target population) requires alternative assumptions, than the one trial case (Dahabreh et al., 2023).\nInterpretable characterization of underrepresented subgroups. A significant challenge in generalizing RCT findings is ensuring that the benefits of evidence-based interventions reach all segments of society, including underrepresented groups (Li et al., 2022; Buchanan et al., 2018). RCTs often struggle to recruit and retain participants from diverse backgrounds, leading to a lack of data on how interventions may affect\nthese populations. ML methods can play a critical role in addressing this challenge by providing interpretable characterizations of underrepresented groups in the trial population (Parikh et al., 2024). By identifying patterns in the data that differentiate these groups, ML algorithms can help researchers understand the factors that contribute to their underrepresentation and develop strategies to improve recruitment and retention.\nConnection to Recent Advancements in Machine Learning: A separate but related field of research in machine learning literature, with significant overlap with causal inference, encompasses domain adaptation (Kouw and Loog, 2018), distributionally robust optimization (Rahimian and Mehrotra, 2019), and transfer learning (Pan and Yang, 2009). In these areas, the training data used for fitting the model differs from the target dataset of interest, often unknown beforehand. These methods seek to bridge the gap between training and target datasets, enabling the model to generalize effectively to new situations and populations. In domain adaptation, the goal is to adapt a model trained on one domain to perform well on a different domain (Redko et al., 2019). This is often relevant in causal inference settings where the trial cohort may not perfectly represent the target population. Distributionally robust optimization aims to develop models that are robust to changes in the distribution of the data, ensuring that their performance remains consistent across different target populations (Duchi and Namkoong, 2018; Rahimian and Mehrotra, 2019; Staib and Jegelka, 2019). Transfer learning focuses on transferring knowledge from a source task to a target task, even with different input or output spaces (Pan and Yang, 2009; Zhuang et al., 2020). This approach is beneficial in scenarios where the target dataset is small or limited, allowing researchers to leverage insights from a related task to improve performance on the target task."
        },
        {
            "heading": "5 Discussion and Conclusion",
            "text": "Our paper delves into the latest advancement in causal methods for generalizability and transportability, encapsulated by discussions at the ICERM workshop. It identifies three key areas of focus: (i) evaluating the robustness of foundational assumptions, (ii) extending the scope of causal analysis beyond traditional intention-to-treat effects, and (iii) incorporating machine learning to enhance the applicability of findings across various contexts.\nThe workshop also highlighted several challenges in bridging the research-to-practice gap. We provide\nexamples of key areas requiring particular focus in the coming years:\n1. Addressing Data Harmonization Challenges Most methods in the literature, including nearly\nall the work presented here, require data that is harmonized across trial and population. In other words, the data in the experiment and the target population must be measured in the same way and be encoded in the same way. Furthermore, the treatment administered in the experiment must also be administered in the same way in the target population. Constructing harmonized data poses a significant challenge and is not straightforward, especially given the current lack of coordination of measurement tools across trials and population data. A concerted effort is needed to design approaches for data harmonization, along with remedial strategies when harmonization is not feasible.\n2. Addressing the Underrepresentation in Trials While many approaches discussed here focus on\nassessing violations of positivity and lack of representation, these approaches generally rely on posthoc adjustments and require strong assumptions. More work must be done to consider how to design future studies to provide information on target populations holistically, especially when the target population comprises of underrepresented groups.\n3. Understanding the Underlying Causal Mechanism Inferring causal effects is not merely a sta-\ntistical challenge; it heavily relies on underlying domain knowledge for the careful consideration of necessary assumptions. There is a need for a strong partnership between domain experts and methodologists to deepen the understanding of the underlying causal mechanisms and the plausibility of assumptions. This collaborative effort will contribute to developing robust and reliable approaches that align with real-world complexities.\nThese directions are pivotal for designing approaches that are not only well-grounded and accurate but also practical in addressing real-world, high-stakes issues in generalizability and transportability. By bringing together the expertise of domain specialists and methodological rigor, these collaborations ensure the reliability and applicability of the developed approaches."
        }
    ],
    "title": "Towards Generalizing Inferences from Trials to Target Populations\u2217",
    "year": 2024
}