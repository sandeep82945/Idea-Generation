{
    "abstractText": "Although deep federated learning has received much attention in recent years, progress has been made mainly in the context of natural images and barely for computational pathology. However, deep federated learning is an opportunity to create datasets that reflect the data diversity of many laboratories. Further, the effort of dataset construction can be divided among many. Unfortunately, existing algorithms cannot be easily applied to computational pathology since previous work presupposes that data distributions of laboratories must be similar. This is an unlikely assumption, mainly since different laboratories have different staining styles. As a solution, we propose BottleGAN, a generative model that can computationally align the staining styles of many laboratories and can be trained in a privacy-preserving manner to foster federated learning in computational pathology. We construct a heterogenic multi-institutional dataset based on the PESO segmentation dataset and improve the IOU by 42% compared to existing federated learning algorithms. An implementation of BottleGAN is available at https://github.com/MECLabTUDA/BottleGAN.",
    "authors": [
        {
            "affiliations": [],
            "name": "Nicolas Wagner"
        },
        {
            "affiliations": [],
            "name": "Moritz Fuchs"
        },
        {
            "affiliations": [],
            "name": "Anirban Mukhopadhyay"
        }
    ],
    "id": "SP:3e97446cce74aa6db230a3a239feeba5c0da2add",
    "references": [
        {
            "authors": [
                "M. Andreux",
                "J.O. du Terrail",
                "C. Beguier",
                "E.W. Tramel"
            ],
            "title": "Siloed federated learning for multi-centric histopathology datasets",
            "venue": "Domain Adaptation and Representation Transfer, and Distributed and Collaborative Learning, pp. 129\u2013139. Springer",
            "year": 2020
        },
        {
            "authors": [
                "W. Bulten",
                "P. B\u00e1ndi",
                "J. Hoven",
                "R. van de Loo",
                "J. Lotz",
                "N. Weiss",
                "J. van der Laak",
                "B. van Ginneken",
                "C. Hulsbergen-van de Kaa",
                "G. Litjens"
            ],
            "title": "Epithelium segmentation using deep learning in h&e-stained prostate specimens with immunohistochemistry as reference standard",
            "venue": "Scientific reports 9(1), 1\u201310",
            "year": 2019
        },
        {
            "authors": [
                "G. Campanella",
                "M.G. Hanna",
                "L. Geneslaw",
                "A. Miraflor",
                "V.W.K. Silva",
                "K.J. Busam",
                "E. Brogi",
                "V.E. Reuter",
                "D.S. Klimstra",
                "T.J. Fuchs"
            ],
            "title": "Clinical-grade computational pathology using weakly supervised deep learning on whole slide images",
            "venue": "Nature medicine 25(8), 1301\u20131309",
            "year": 2019
        },
        {
            "authors": [
                "H. Chang",
                "V. Shejwalkar",
                "R. Shokri",
                "A. Houmansadr"
            ],
            "title": "Cronus: Robust and heterogeneous collaborative learning with black-box knowledge transfer",
            "venue": "arXiv preprint arXiv:1912.11279",
            "year": 2019
        },
        {
            "authors": [
                "H.Y. Chen",
                "W.L. Chao"
            ],
            "title": "Fedbe: Making bayesian model ensemble applicable to federated learning",
            "venue": "arXiv preprint arXiv:2009.01974",
            "year": 2020
        },
        {
            "authors": [
                "Y. Choi",
                "M. Choi",
                "M. Kim",
                "J.W. Ha",
                "S. Kim",
                "J. Choo"
            ],
            "title": "Stargan: Unified generative adversarial networks for multi-domain image-to-image translation",
            "venue": "CVPR. pp. 8789\u20138797",
            "year": 2018
        },
        {
            "authors": [
                "Y. Choi",
                "Y. Uh",
                "J. Yoo",
                "J.W. Ha"
            ],
            "title": "Stargan v2: Diverse image synthesis for multiple domains",
            "venue": "CVPR. pp. 8188\u20138197",
            "year": 2020
        },
        {
            "authors": [
                "E. Diao",
                "J. Ding",
                "V. Tarokh"
            ],
            "title": "Heterofl: Computation and communication efficient federated learning for heterogeneous clients",
            "venue": "arXiv preprint arXiv:2010.01264",
            "year": 2020
        },
        {
            "authors": [
                "M. Heusel",
                "H. Ramsauer",
                "T. Unterthiner",
                "B. Nessler",
                "S. Hochreiter"
            ],
            "title": "Gans trained by a two time-scale update rule converge to a local nash equilibrium",
            "venue": "Advances in neural information processing systems 30",
            "year": 2017
        },
        {
            "authors": [
                "G. Hinton",
                "O. Vinyals",
                "J. Dean"
            ],
            "title": "Distilling the knowledge in a neural network",
            "venue": "arXiv preprint arXiv:1503.02531",
            "year": 2015
        },
        {
            "authors": [
                "T.M.H. Hsu",
                "H. Qi",
                "M. Brown"
            ],
            "title": "Measuring the effects of non-identical data distribution for federated visual classification",
            "venue": "arXiv preprint arXiv:1909.06335",
            "year": 2019
        },
        {
            "authors": [
                "T.M.H. Hsu",
                "H. Qi",
                "M. Brown"
            ],
            "title": "Federated visual classification with real-world data distribution",
            "venue": "Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part X 16. pp. 76\u201392. Springer",
            "year": 2020
        },
        {
            "authors": [
                "X. Huang",
                "S. Belongie"
            ],
            "title": "Arbitrary style transfer in real-time with adaptive instance normalization",
            "venue": "ICCV. pp. 1501\u20131510",
            "year": 2017
        },
        {
            "authors": [
                "W. Jeong",
                "J. Yoon",
                "E. Yang",
                "S.J. Hwang"
            ],
            "title": "Federated semi-supervised learning with inter-client consistency & disjoint learning",
            "venue": "arXiv preprint arXiv:2006.12097",
            "year": 2020
        },
        {
            "authors": [
                "S.P. Karimireddy",
                "S. Kale",
                "M. Mohri",
                "S. Reddi",
                "S. Stich",
                "A.T. Suresh"
            ],
            "title": "Scaffold: Stochastic controlled averaging for federated learning",
            "venue": "International Conference on Machine Learning. pp. 5132\u20135143. PMLR",
            "year": 2020
        },
        {
            "authors": [
                "T. Karras",
                "S. Laine",
                "T. Aila"
            ],
            "title": "A style-based generator architecture for generative adversarial networks",
            "venue": "CVPR. pp. 4401\u20134410",
            "year": 2019
        },
        {
            "authors": [
                "C. Li",
                "M. Wand"
            ],
            "title": "Precomputed real-time texture synthesis with markovian generative adversarial networks",
            "venue": "ECCV. pp. 702\u2013716. Springer",
            "year": 2016
        },
        {
            "authors": [
                "T. Li",
                "A.K. Sahu",
                "M. Zaheer",
                "M. Sanjabi",
                "A. Talwalkar",
                "V. Smith"
            ],
            "title": "Federated optimization in heterogeneous networks",
            "venue": "arXiv preprint arXiv:1812.06127",
            "year": 2018
        },
        {
            "authors": [
                "T. Lin",
                "L. Kong",
                "S.U. Stich",
                "M. Jaggi"
            ],
            "title": "Ensemble distillation for robust model fusion in federated learning",
            "venue": "arXiv preprint arXiv:2006.07242",
            "year": 2020
        },
        {
            "authors": [
                "M.Y. Lu",
                "D. Kong",
                "J. Lipkova",
                "R.J. Chen",
                "R. Singh",
                "D.F. Williamson",
                "T.Y. Chen",
                "F. Mahmood"
            ],
            "title": "Federated learning for computational pathology on gigapixel whole slide images",
            "venue": "arXiv preprint arXiv:2009.10190",
            "year": 2020
        },
        {
            "authors": [
                "B.R. Lutnick",
                "D. Manthey",
                "J.U. Becker",
                "J.E. Zuckerman",
                "L. Rodrigues",
                "K.Y. Jen",
                "P. Sarder"
            ],
            "title": "A tool for federated training of segmentation models on whole slide images",
            "venue": "bioRxiv",
            "year": 2021
        },
        {
            "authors": [
                "B. McMahan",
                "E. Moore",
                "D. Ramage",
                "S. Hampson",
                "B.A. y Arcas"
            ],
            "title": "Communication-efficient learning of deep networks from decentralized data",
            "venue": "Artificial intelligence and statistics. pp. 1273\u20131282. PMLR",
            "year": 2017
        },
        {
            "authors": [
                "S. Reddi",
                "Z. Charles",
                "M. Zaheer",
                "Z. Garrett",
                "K. Rush",
                "J. Kone\u010dn\u1ef3",
                "S. Kumar",
                "H.B. McMahan"
            ],
            "title": "Adaptive federated optimization",
            "venue": "arXiv preprint arXiv:2003.00295",
            "year": 2020
        },
        {
            "authors": [
                "O. Ronneberger",
                "P. Fischer",
                "T. Brox"
            ],
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "venue": "MICCAI. pp. 234\u2013241. Springer",
            "year": 2015
        },
        {
            "authors": [
                "F. Sattler",
                "T. Korjakow",
                "R. Rischke",
                "W. Samek"
            ],
            "title": "Fedaux: Leveraging unlabeled auxiliary data in federated learning",
            "venue": "arXiv preprint arXiv:2102.02514",
            "year": 2021
        },
        {
            "authors": [
                "B. Sch\u00f6mig-Markiefka",
                "A. Pryalukhin",
                "W. Hulla",
                "A. Bychkov",
                "J. Fukuoka",
                "A. Madabhushi",
                "V. Achter",
                "L. Nieroda",
                "R. B\u00fcttner",
                "A Quaas"
            ],
            "title": "Quality control stress test for deep learning-based diagnostic model in digital pathology",
            "venue": "Modern Pathology pp. 1\u201311",
            "year": 2021
        },
        {
            "authors": [
                "M.T. Shaban",
                "C. Baur",
                "N. Navab",
                "S. Albarqouni"
            ],
            "title": "Staingan: Stain style transfer for digital histological images",
            "venue": "2019 Ieee 16th international symposium on biomedical imaging (Isbi 2019). pp. 953\u2013956. IEEE",
            "year": 2019
        },
        {
            "authors": [
                "K. Sohn",
                "D. Berthelot",
                "C.L. Li",
                "Z. Zhang",
                "N. Carlini",
                "E.D. Cubuk",
                "A. Kurakin",
                "H. Zhang",
                "C. Raffel"
            ],
            "title": "Fixmatch: Simplifying semi-supervised learning with consistency and confidence",
            "venue": "arXiv preprint arXiv:2001.07685",
            "year": 2020
        },
        {
            "authors": [
                "J.Y. Zhu",
                "T. Park",
                "P. Isola",
                "A.A. Efros"
            ],
            "title": "Unpaired image-to-image translation using cycle-consistent adversarial networks",
            "venue": "ICCV. pp. 2223\u20132232",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "Keywords: Federated Learning \u00b7 Computational Pathology \u00b7 Deep Learning."
        },
        {
            "heading": "1 Introduction",
            "text": "Automatic processing of histological images has the potential to become an essential prerequisite for computer-assisted diagnosis, prognostication, and assessments in computational pathology (CP). If neural networks are to be used for this purpose, the standard deep learning methods need to be trained on a vast amount of labeled data. In reality, such data is hardly available in the public domain. For instance, filtered by segmentation and histology, grand-challenge.org solely offers 15 datasets. Many of these are only of limited use. Considering the number of different dyes used in histopathology and different anatomies as well as tissue structures that are examined, many more labeled datasets are necessary. This problem is exacerbated because the style of staining can differ significantly between laboratories but also within a laboratory for a variety of reasons [26].\n? Equal contribution.\nar X\niv :2\n20 9.\n14 84\n9v 1\n[ ee\nss .I\nV ]\n2 9\nSe p\nFor instance, protocols, storage conditions, or reagents may vary. A neural network, however, should be reliable regardless of the staining style. To this end, a solution is to collect representative training data from many laboratories [3]. Unfortunately, creating large-scale datasets is only possible with an enormous effort, both in time and money.\nThe concept of federated learning (FL) appears to be a solution to this as it allows distributing the dataset creation work among many and captures the data diversity of multiple laboratories. Unfortunately, existing FL algorithms either expect a publicly available representative unlabeled dataset [4, 19, 25] or only work if participating clients are closely aligned in their data distribution [11]. It is fair to assume that neither requirement is fulfilled for computational pathology. Further, previous work does not integrate unlabeled clients out of the box [11,22], leading to high participation barriers.\nIn this study, we propose BottleGAN, a novel generative adversarial network architecture that makes FL applicable to CP by aligning the local data distributions of laboratories through stain normalization. We pair BottleGAN with an unsupervised federated learning procedure that makes no further demands on participating clients apart from minimal hardware requirements. We demonstrate how BottleGAN can seamlessly be integrated into federated learning algorithms based on weight aggregation (WA) [11, 18, 22] for solving downstream tasks. WA algorithms train a local neural network model per client and simply average the local model weights at a server to form a global model. After WA with BottleGAN, trained models are valid for the staining styles of all laboratories that participated in the unsupervised training of BottleGAN but did not necessarily contribute annotations to WA. We demonstrate on a heterogenic multi-institutional version of the PESO [2] dataset significant improvement through BottleGAN compared to existing work on federated learning."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Weight Aggregation",
            "text": "Most WA algorithms are derived from the underlying idea of FedAvg [22]. FedAvg assumes that each client dataset is sampled i.i.d from a common data distribution. Many improvements have been developed to handle situations in which this assumption is not entirely fulfilled (i.e. client drift) [5, 11, 12, 15, 23]. The literature on federated learning in CP is very limited. Although evaluated on WSIs, Andreux et al. [1] use a more general adaptation of federated learning in that they learn different normalization statistics per client. Changing normalization layers has also been studied by others [8]. Lu et al. [20] are mainly concerned about the size of WSIs and use a pretrained model for embedding WSI patches. However, neither approach addresses the heterogeneity of participants in federated learning and goes significantly beyond standard weight aggregation algorithms. Recently, [21] have shown in a minimal setting with only three clients that FL can create robustness of deep learning in CP to multi-institutional heterogeneity."
        },
        {
            "heading": "2.2 Stain Normalization",
            "text": "Lately, various versions of StainGAN [27] have become the dominant idea for stain normalization. StainGAN is an adaption of CycleGAN [29] and is able to learn the stain normalization task from small exemplary WSI crops while incorporating spatial variations. Unfortunately, CycleGANs, and hence StainGANs, are only able to handle one-to-one style mappings. In the FL setting under consideration in this work, the staining styles of all clients must be aligned. We are not aware of any work that is particularly intended to normalize various staining styles with only one or two neural networks. The most notable works for such many-to-many style transfers in the natural image domain, StarGAN [6] and StarGANv2 [7], use a framework akin to CycleGANs but deploys a single conditional generator for all transferred styles. BottleGAN can be used as an orthogonal mechanism to improve existing WA-based FL algorithms with federated stain normalization."
        },
        {
            "heading": "3 Method",
            "text": "In the following, we first give a problem statement of FL in CP and derive the necessity of BottleGAN. Afterward, we show how BottleGAN is constructed and how it can be trained with FL."
        },
        {
            "heading": "3.1 Problem Statement",
            "text": "In a standard deep learning setting for CP we have access to a dataset D = {(xi, yi)}Ni=1 of N WSI-Label pairs. In the FL setting, however, we assume that\nthere are clients K each owning a portion Dk = {(xki , yki )}N k i=1 of D = \u2294K k=1 D k that can not be shared with others. For a simplified notation, we omit unlabeled clients which trivially can be integrated in the following derivations. As mentioned in the introduction, the success of WA-based FL is commonly dependent on the local distributions, from which the client datasets Dk were drawn, not diverging too much [11]. For CP, we can further decompose a WSI x into a destained content image c and staining style function s such that s(c) = x.3\nGiven the staining style functions S = \u22c3K k=1{ski }N k\ni=1 of all clients, we define the decomposed dataset of a client as\nDk = \u22c3 s\u2208S {(s(cki ), yki )}N k i=1. (1)\nIn words, Dk contains the content images of a client in the staining styles of all clients. If we can create the decomposed set for each client in a privacy-preserving manner, we can also align the client data distributions much more closely."
        },
        {
            "heading": "3.2 Network Architecture",
            "text": "For creating the decomposed datasets, we introduce BottleGAN, a neural network architecture that is able to map between the staining styles of all clients. The BottleGAN architecture follows a Many-One-Many paradigm that differs conceptually from previous work as depicted in Figure 1. BottleGAN consists of two generators that perform staining style transfers and two discriminators needed for training purposes. Generator Gs is responsible for approximating all staining style functions s \u2208 S whereas Gs\u22121 is trained to approximate all inverse staining style functions s\u22121. Hence, in contrast to a naive implementation of a Many One-One paradigm (Figure 1 (b)), i.e. one StainGAN [27] per staining style transfer, we are significantly more computationally efficient as the number of neural networks to train remains constant. Additionally, compared to a StarGAN-based [6, 7] Many-Many approach (Figure 1 (c)), we avoid that the number of staining style transfers one network has to learn grows quadratic with the number of staining styles. Our architecture results in linear growth and, thereby, simplifies the training task considerably.\nGenerators Both generators follow the same three major design choices that are novel in contrast to previous deep stain normalization networks [27]. First, we only use convolutions of size 1x1, no downsampling or upsampling techniques, and no skip connections that are usually used in common neural style transfer architectures like U-Net [24] or SB-Generators [16]. Contrary to changing the style of a pixel in a natural image, changing the staining style of a pixel in a WSI should only depend on the pixel\u2019s content and the globally prevalent staining style. Obviously, image capturing noise and other influences weaken this\n3 Without loss of generality we can assume that the content image is stained in a reference staining scheme rather than destained.\nassumption. Nonetheless, in the federated setting, it is desirable to keep the communication and training costs of neural networks as small as possible for clients. For CP, both can be improved if parameter-efficient networks are used that avoid modeling long-distance correlations between pixels. Another advantage is that our architecture is entirely independent of the size of the input image. Phrased differently, as most WSIs can not be processed at once by neural networks due to their size, the standard solution is moving the networks across a WSI and processing one crop after the other. In this case, architectures like U-Net probably process a pixel differently depending on its position within a crop.\nSecond, we follow the current success of adaptive instance normalization (AdaIN) [7,13,16] to condition the BottleGAN generators on a particular staining style function. Although we implement all staining style functions with one BottleGAN and all inverse functions with another, we only use one trainable style code per staining style. Gaussian noise is added to style codes to represent ambiguities in staining style functions and make BottleGAN more robust.\nFinally, both generators work directly in the optical density (OD) space, which is the negated logarithm of the image intensities. This is plausible since the staining matrix, which can describe all linear effects of staining, also acts in the OD space.\nDiscriminators Looking at the discriminators now, both differ in their structure. The discriminator Dc decides whether an image is destained (or reference stained). Hence, we can make use of a standard PatchGAN [17] discriminator for this binary decision. The discriminator Ds, however, is ought to decide for all staining styles if an image is stained in a particular style or not. For this, we condition a PatchGAN discriminator by concatenating the respective style code to the output of the last downsampling convolutional layer."
        },
        {
            "heading": "3.3 Federated Learning",
            "text": "We train BottleGAN with FL based on knowledge distillation [10]. Given a dataset X = \u2294K k=1 X\nk of WSIs as the union of non-shareable local datasets Xk of clients K and a shareable dataset C of destained or reference stained WSIs owned by a server. We start by asking all clients to train their own local BottleGAN solely between their staining style and the reference staining style defined by C. This requires a non-federated training similar to CycleGAN [29]. Afterward, the clients send their local models to the server. The server, in turn, applies the collected client generators to its own dataset C to create a novel dataset X\u0302 that contains C in the staining styles of all clients. The server then proceeds by training a global BottleGAN on X\u0302 and C as a distillation of all local BottleGANs. Finally, each client receives the global BottleGAN and is able to create the decomposed dataset. The only assumption we make is that the reference dataset C is public, and this assumption seems to be mostly fulfilled based on public teaching examples alone.\nAn algorithmic description of the federated and the non-federated learning of BottleGAN is given in the supplementary material. Due to the enormous size of WSIs, an offline construction of the decomposed datasets might not be handy. Therefore, we state an online integration of BottleGAN into WA-based FL in the supplementary material, too."
        },
        {
            "heading": "4 Evaluation",
            "text": ""
        },
        {
            "heading": "4.1 Dataset",
            "text": "Most available CP segmentation datasets are either too small or lack a sufficient labeling quality for the evaluation of FL algorithms. Additionally, the computational costs of simulating FL systems are massive. Hence, we limit ourselves to the PESO [2] dataset of prostate specimens. PESO comprises 102 hematoxylin and eosin stained whole slide images (WSI) and corresponding segmentation masks."
        },
        {
            "heading": "4.2 Experimental Setup",
            "text": "Method IOU ECE NLL\nFedAvgM 0.470 0.061 0.339 + FixMatch 0.613 0.016 0.193\nBottleGAN 0.671 0.011 0.177 + FixMatch 0.671 0.013 0.180\nTable 1: The IOU (\u2191), ECE (\u2193), and NLL (\u2193) results on the test set for all evaluated methods. The homogenization of the clients through BottleGAN significantly improves all metrics.\nOur experiments simulate a FL setup with 20 clients for 100 training rounds. Each client owns a training and a testing WSI, respectively. Both WSIs follow the same staining style, which we establish with the Macenko algorithm. The staining styles are unique per client and are random linear combinations of the styles defined in Scho\u0308mig-Markiefka et al. [26]. To increase realism, we assume that not every client offers labels at all, and if they do, then the number of labels varies. For this purpose, we allow 60 labeled 300\u00d7 300 px patches at a 10\u00d7 magnification among the clients, whereby half of the clients can have between 1 and 11 patches. The other half does not have ground truth annotations at all and only contributes its staining styles. We always process random image crops of size 224\u00d7 224 px.\nSince BottleGAN can be paired with any WA-based FL algorithm, and in line with other recent work [5,14,19], we choose FedAvgM [11] as a baseline comparison. Further, as BottleGAN should be considered a federated semi-supervised learning (FSSL) algorithm due to its capability to include unlabeled clients, we also compare against the naive combination of FedAvgM and the state-of-theart semi-supervised learning algorithm FixMatch [28]. At this, we follow the implementation of Jeong et al. [14] but stick to the naive combination as other mechanisms are orthogonal to BottleGAN. The performance of all algorithms is compared with the help of the intersection over union (IOU), the expected calibration error (ECE), and the negative-log likelihood (NLL). Results are an average over two seeds and three folds. For each fold, the labeled patches are distributed differently among the clients. We will make the implementation publicly available."
        },
        {
            "heading": "4.3 Results",
            "text": "The test results after 100 simulated communication rounds of FedAvgM can be read in Table 1. Further, we plot the development throughout training in Figure 3. The findings are unambiguous. The worst result is achieved in all metrics when\nonly FedAvgM is applied, whereas the homogenization of client staining styles through BottleGAN seems to be a way to success for FL in CP. The addition of BottleGAN leads to significant improvements in all evaluated metrics. The IOU is increased by 0.21, the ECE is lowered by 0.50, and the NLL is reduced by 0.16. The addition of FixMatch can only improve plain FedAvgM without BottleGAN and even leads to slightly worse performance in terms of NLL and ECE if combined with BottleGAN. Presumably, the consistency learning of FixMatch also results in some sort of client homogenization but not to the extent BottleGAN can achieve."
        },
        {
            "heading": "4.4 BottleGAN Architecture",
            "text": "We validate major design choices of BottleGAN by training it in a non-federated setting to capture staining style transfer between 240 artificial staining styles. The staining styles are created as random linear combinations of the styles defined in Scho\u0308mig-Markiefka et al. [26]. Additionally, the entries of the corresponding stain matrices and the pixelwise optical densities are augmented with independent Gaussian noise. Exemplary artificial staining styles are displayed in Figure 2 (a), the normalization of BottleGAN in Figure 2 (b), and the restaining in Figure 2 (c). Even for so many challenging style transfers, both the normalization and the restaining visually appear to be successfully achieved. Further experiments are evaluated by the mean squared reconstruction error (MSE), and the Fre\u0301chet inception distance (FID) [9]. The results can be found in Table 2. First, we validate the novel generator design. BottleGAN achieves a MSE on par with the usually used U-Net [24, 27] generator and even improves the FID while being translation invariant, using only half of the parameters, and avoiding upsampling artifacts. We also compare the novel Many-One-Many paradigm implemented by BottleGAN to the Many-Many paradigm of StarGAN [6] and a Many-One paradigm that implements BottleGAN with only one generator for both normalization and restaining. Considering the same training budget, BottleGAN greatly outperforms all other paradigms. Please note that we did not compare against the Many-One-One paradigm, which would train many StainGANs (see Figure 1 (b)) due to the intractable computational costs."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this work, we introduced BottleGAN, a novel generative model to unify heterogeneous histological slides from different pathology labs in their staining style. BottleGAN is built of a new architecture tailored explicitly to staining style transfer and paired with an unsupervised FL algorithm. Further, we integrated BottleGAN into WA-based FL and demonstrated the superiority of our approach in contrast to existing FL algorithms developed for natural images. As BottleGAN allows for incorporating clients with unlabeled datasets, it becomes easier for laboratories to enter federated learning and share knowledge. In future work, we aim to incorporate uncertainty estimation into BottleGAN for building a bridge between FL and continual learning."
        }
    ],
    "title": "Federated Stain Normalization for Computational Pathology",
    "year": 2022
}