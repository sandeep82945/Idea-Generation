{
    "abstractText": "Identifying market abuse activity from data on investors\u2019 trading activity is very challenging both for the data volume and for the low signal to noise ratio. Here we propose two complementary unsupervised machine learning methods to support market surveillance aimed at identifying potential insider trading activities. The first one uses clustering to identify, in the vicinity of a price sensitive event such as a takeover bid, discontinuities in the trading activity of an investor with respect to his/her own past trading history and on the present trading activity of his/her peers. The second unsupervised approach aims at identifying (small) groups of investors that act coherently around price sensitive events, pointing to potential insider rings, i.e. a group of synchronised traders displaying strong directional trading in rewarding position in a period before the price sensitive event. As a case study, we apply our methods to investor resolved data of Italian stocks around takeover bids.",
    "authors": [
        {
            "affiliations": [],
            "name": "Piero Mazzarisi"
        },
        {
            "affiliations": [],
            "name": "Adele Ravagnani"
        },
        {
            "affiliations": [],
            "name": "Paola Deriu"
        },
        {
            "affiliations": [],
            "name": "Fabrizio Lillo"
        },
        {
            "affiliations": [],
            "name": "Francesca Medda"
        },
        {
            "affiliations": [],
            "name": "Antonio Russo"
        }
    ],
    "id": "SP:beb273e90c33fa1f1a94d063c818d12b48a9d9e3",
    "references": [
        {
            "authors": [
                "CC Aggarwal"
            ],
            "title": "Outlier Analysis",
            "venue": "Springer-Verlag New York;",
            "year": 2013
        },
        {
            "authors": [
                "Akoglu"
            ],
            "title": "Graph based anomaly detection and description: a survey",
            "venue": "Data Min Knowl Disc",
            "year": 2015
        },
        {
            "authors": [
                "Barth\u00e9lemy"
            ],
            "title": "Human centered processes and decision support systems",
            "venue": "European Journal of Operational Research,",
            "year": 2002
        },
        {
            "authors": [
                "Bhattacharya",
                "U. Daouk (2002)] Bhattacharya",
                "H. Daouk"
            ],
            "title": "The world price of insider trading",
            "venue": "The journal of Finance,",
            "year": 2002
        },
        {
            "authors": [
                "Baltakiene"
            ],
            "title": "Clusters of investors around initial public offering",
            "venue": "Palgrave Communications,",
            "year": 2019
        },
        {
            "authors": [
                "Bohlin"
            ],
            "title": "Community detection and visualization of networks with the map equation framework. In Measuring scholarly impact (pp. 3-34)",
            "year": 2014
        },
        {
            "authors": [
                "Chandola"
            ],
            "title": "Anomaly detection: A survey",
            "venue": "ACM computing surveys (CSUR),",
            "year": 2009
        },
        {
            "authors": [
                "De Jong"
            ],
            "title": "Tackling financial market abuse in the EU",
            "venue": "Library of the European Parliament",
            "year": 2013
        },
        {
            "authors": [
                "Donoho",
                "August"
            ],
            "title": "Early detection of insider trading in option markets",
            "venue": "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 420-429)",
            "year": 2004
        },
        {
            "authors": [
                "Goldstein",
                "M. Uchida (2016)] Goldstein",
                "S. Uchida"
            ],
            "title": "A comparative evaluation of unsupervised anomaly detection algorithms for multivariate data",
            "venue": "PloS one,",
            "year": 2016
        },
        {
            "authors": [
                "Hastie"
            ],
            "title": "The elements of statistical learning: data mining, inference, and prediction (Vol",
            "year": 2009
        },
        {
            "authors": [
                "Y. Hong"
            ],
            "title": "On computing the distribution function for the Poisson binomial distribution",
            "venue": "Computational Statistics & Data Analysis,",
            "year": 2013
        },
        {
            "authors": [
                "La Morgia"
            ],
            "title": "The doge of wall street: Analysis and detection of pump and dump cryptocurrency manipulations",
            "venue": "ACM Transactions on Internet Technology (TOIT)",
            "year": 2021
        },
        {
            "authors": [
                "Li"
            ],
            "title": "Market manipulation detection based on classification methods",
            "venue": "Procedia Computer Science,",
            "year": 2017
        },
        {
            "authors": [
                "S. Lloyd"
            ],
            "title": "Least squares quantization in PCM",
            "venue": "IEEE transactions on information theory,",
            "year": 1982
        },
        {
            "authors": [
                "F. Musciotto",
                "J. Piilo",
                "R.N. Mantegna"
            ],
            "title": "High-frequency trading and networked markets",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2021
        },
        {
            "authors": [
                "Saracco"
            ],
            "title": "Inferring monopartite projections of bipartite networks: an entropy-based approach",
            "venue": "New Journal of Physics,",
            "year": 2017
        },
        {
            "authors": [
                "Song"
            ],
            "title": "Conditional anomaly detection",
            "venue": "IEEE Transactions on knowledge and Data Engineering,",
            "year": 2007
        },
        {
            "authors": [
                "Tumminello"
            ],
            "title": "Statistically validated networks in bipartite complex systems",
            "venue": "PloS one,",
            "year": 2011
        },
        {
            "authors": [
                "Tumminello"
            ],
            "title": "Identification of clusters of investors from their real trading activity in a financial market",
            "venue": "New Journal of Physics,",
            "year": 2012
        },
        {
            "authors": [
                "West",
                "J. Bhattacharya (2016)] West",
                "M. Bhattacharya"
            ],
            "title": "Intelligent financial fraud detection: a comprehensive review",
            "venue": "Computers & security,",
            "year": 2016
        },
        {
            "authors": [
                "Wu"
            ],
            "title": "A survey of human-in-the-loop for machine learning",
            "year": 2022
        },
        {
            "authors": [],
            "title": "Robustness analysis of SVN: comparison with maximum entropy methods In order to check the robustness of the SVN method for market abuse detection, the clustering is performed also with another method introduced in [Saracco et al. (2017)",
            "year": 2017
        },
        {
            "authors": [
                "In [Saracco"
            ],
            "title": "ERG models are considered; here, we choose to focus on the Bipartite Configuration Model (BiCM). The BiCM Hamiltonian imposes constraints on the degree sequences of both layers indeed, H(\u03b8",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "Identifying market abuse activity from data on investors\u2019 trading activity is very challenging both for the data volume and for the low signal to noise ratio. Here we propose two complementary unsupervised machine learning methods to support market surveillance aimed at identifying potential insider trading activities. The first one uses clustering to identify, in the vicinity of a price sensitive event such as a takeover bid, discontinuities in the trading activity of an investor with respect to his/her own past trading history and on the present trading activity of his/her peers. The second unsupervised approach aims at identifying (small) groups of investors that act coherently around price sensitive events, pointing to potential insider rings, i.e. a group of synchronised traders displaying strong directional trading in rewarding position in a period before the price sensitive event. As a case study, we apply our methods to investor resolved data of Italian stocks around takeover bids.\nKeywords: Insider trading, Market abuse, Unsupervised learning, Statistically validated networks\n1This paper represents the personal opinions of the authors and do not bind the membership organization in any way. \u2217These authors contributed equally to the work. 2Scuola Normale Superiore, Pisa 3Dipartimento di Economia Politica e Statistica, Universita\u0300 di Siena, Italy. 4Consob, Italy. 5Dipartimento di Matematica, Universita\u0300 di Bologna, Italy. 6University College London, Institute of Finance and Technology\nar X\niv :2\n21 2.\n05 91\n2v 1\n[ q-\nfi n.\nST ]\n6 D\nec 2"
        },
        {
            "heading": "1 Introduction",
            "text": "In financial markets the concept of market abuse consists in an intentional conduct that violates market integrity and natural demand-supply dynamics through misuse of privileged information, unlawful disclosure of inside information, unfair trading practices, price manipulation, creation of unfair market conditions, and deception of market players, to name but a few examples.\nIn literature, the area of market abuse covers a number of different conducts that nonetheless could be grouped into two main categories: 1) insider dealing: the act of utilizing inside information in order to make, change, or cancel deals, or to encourage a third-party to deal using this knowledge and unlawful disclosure of inside information, by releasing information without correct permissions; 2) market manipulation, subdivided in trade base manipulation, action trade manipulation, or information based manipulation: in other terms an umbrella for a series of actions which distort market performance.\nThe European legislator defines market abuse as any unlawful conduct on the financial markets involving the commission or attempted commission of insider dealing, i.e. the unlawful disclosure of inside information or the recommendation to others to engage in insider dealing, as well as market manipulation. Such conducts, preventing full and effective market integrity and compromising public confidence, are expressly prohibited and administratively sanctioned, leaving Member States the possibility of also imposing criminal sanctions.\nIn Europe the current legal framework of reference is represented by Directive 2014/57/EU (so-called MAD II), European Regulation 596/2014 (so-called MAR) as well as a bunch of Delegated Regulations supplementing the MAR Regulation with regard to regulatory technical standards on several aspects. The European legislator envisaged equipping the competent authorities of each Member State with adequate tools, powers and resources to ensure the effectiveness of supervision. In addition, the European provisions concerning market abuse require criminalisation of the most serious misconduct leaving to national legislators the power to criminalise certain misbehaviours. The Italian case is noteworthy because yet the implementation of the first Market Abuse Directive (MAD), in 2005, was a hook to introduce severe administrative sanctions in addition to the pre-existing criminal penalties. Therefore, since long ago, in Italy Consob\u2019s supervisory activities in this area may give rise to both administrative and criminal sanctioning proceedings, the latter by reporting the detected conducts to the Judicial Authority.\nIn this paper the focus is on insider trading, which is maybe the simplest market abuse conduct to conceive, but also one of the most widespread and difficult to enforce, since it is recognized as an illicit a probatio diabolica for the difficulties inherent in the search for a smoking gun. Knowing in advance how the price will likely move in response to the release of the information to the market (a.k.a. price sensitive event (PSE), such as, for example, the announcement of a takeover bid), can be easily exploited to make a profit. Such a type of practice is prohibited or criminalized in most jurisdictions around the world [Bhattacharya and Daouk (2002)]. However, rules are specific of each country and efforts in persecuting insider trading vary considerably.\nThe \u201cproof\u201d and the subsequent imposition of a sanction (either administrative or criminal) to a trader that have operated as an insider is however a complex process, involving many steps: (i) the detection of alerts pointing to anomalies that appear\nattributable to abusive behaviors , (ii) the concrete assessment of the allegedly suspicious conduct with respect to possible rationale that may have supported the strategy under analysis, (iii) the investigation phase aimed at gathering evidence and clues of the abusive conduct, and (iv) the subsequent legal trial to confirm the fact that the unlawful conduct was committed.\nThe scope of this work concerns the first step, i.e. the analysis of the trading behavior of investors in the presence of a price sensitive event, and, in part, the second one. The goal is providing a methodology based on unsupervised machine learning techniques that is able to provide and indication on whether the trading behavior of an investor or a group of investors is anomalous or not, thus supporting the monitoring and surveillance processes by the competent Authority and the assessment of the conduct.\nIn fact, the assessment of the trading behavior of an investor, alleged to be suspicious in terms of fault of abnormality remains a crucial point. In other words, focusing on a single trader, the smoking gun of the crime1 in the context of insider trading is a clue not easy to unearth; in addition also serious, precise and concordant evidences could not be sufficient to build case strong enough. Nonetheless, once the alert is triggered, the more discontinuous an investor\u2019s strategy is with respect to its trading history, the more suspicious its behavior can be considered. For example, the trading of only one stock could be suspicious when it happens: (i) for a specific time frame proximate to (and preceding) the dissemination of a price-sensitive news item, (ii) by assuming a rewarding position in relation to the price movement, and (iii) in the absence of other similar investments (i.e. in the same security over a longer timeframe or in securities similar in terms of capitalization, sector, risk, asset class, and for countervalues at least comparable in size to the investment under analysis).\nRather than splitting all investors into two classes, i.e. anomalous or not, it seems therefore more reasonable to assign a score to each trader as a measure of how much his/her behavior differs from the most suspicious one. Three considerations guided the design of our methodology:\n\u2022 First, anomalies need to be studied in a dynamical framework, in which any deviation from ordinary trading of an investor immediately before a price sensitive event must be characterized with respect to his/her activity in a past reference period when no anomalies are assumed. Such a comparison should include not only the trading in the asset under investigation but in whole market.\n\u2022 Second, the deviations from ordinary trading of an investor should be compared with the trading behavior of his/her peers, defined as the investors which, in the past reference period, trade similarly to the investor under investigation. In other words, a modification in the trading behavior before a price sensitive event might require subtle interpretation and assessment if the (large) group of peers also modfiified their behavior in a similar way. For example, such cases might be due to some public leakage of information or some market dynamics which lead the investor and his/her peers to modify the trading.\n\u2022 Third, when we look at small groups of traders, the coordination of a group in buying or selling a stock may be the signal of the spreading of confidential information within the group (insider ring). The study of such coordinated behaviors\n1As in a murder, finding the killer with the gun immediately after the fire shoot is a proof of guilt rarely available to investigators.\nmay further reveal when the confidential information started to spread before the price sensitive event. For instance, the appearance of coordinated buyers at some date before the announcement of a takeover bid could permit to infer from market data when the confidential information has been formed, then exploited by some insiders.\nThe inference of such dynamic patterns can help the competent authority by providing a better understanding of the market dynamics and and can help in the identification of individual and collective suspects of insider trading activity.\nLiterature Review. Market abuse detection naturally fits into the framework of anomaly detection, which basically amounts at identifying data instances that cannot be associated with a normal behavior and that are rare in the data set. The goal is to define a region of the features\u2019 space whose belong normal observations; observations that do not lie in this region are defined as anomalies [Chandola et al. (2009)]. Identifying this normality region is not straightforward: the boundary between normal and anomalous behavior is not always sharp, behaviors that are actually anomalous could be disguised in order not to be identified, the definition of normal behavior could be time varying and it is strongly dependent on the application domain, it is difficult to distinguish noise from anomalous behavior [Chandola et al. (2009)]. From a practical point of view, there are three main aspects which determine the formulation of the anomaly detection method: the nature of the input data, the type of anomaly, availability of data labels, the desired output of the technique. Data instances can be of various type (binary/categorical/continuous, univariate/multivariate) and independent among them or related to each other, as it is the case of time series and sequences, spatial data and graph data, for which ad hoc methodologies have to be employed [Akoglu et al. (2015), Aggarwal (2013)]. Concerning the type of anomalies, the standard case is represented by point anomalies, which are single elements identified as anomalous; they could be global or local depending on whether the entire features\u2019 space or a specific region of it is considered [Goldstein and Uchida (2016)]. Interestingly, there are cases when an element can be seen as normal, but when a given context is taken into account, it turns out to be an anomaly. We refer to this type as contextual anomalies [Chandola et al. (2009)], also referred to as conditional anomalies [Song et al. (2007)]. It may happen, for instance, that an investor has operated on a stock and, without a context, such an operation looks similar to other operations in the market. However, when compared to the own past behavior of the investor or to the operations of other investors, some discontinuity or synchronization patterns may be revealed and the operation could turn out to be identified as anomalous. Contextual anomalies problems can be tackled by algorithms for point anomaly detection once the context is included as a new feature. Finally, we could have data instances that are normal if considered individually, while they are anomalous together: they are the so-called collective anomalies [Chandola et al. (2009)] and they can occur in data set where data instances are dependent. Another important issue is the availability of data labels which causes the employment of a different type of anomaly detection approach: supervised when each observation is labeled as normal or anomalous, semi-supervised when training data do not contain any anomalies and unsupervised when no labels are provided as in our interest case. Typically, outputs of anomaly detection algorithms associate to each observation a score, which quantifies the magnitude of its anomalous character. Setting a suited threshold, the ranked list of anomalies can provide labels\nfor each data instance. It is evident anomaly detection problems are challenging and indeed, a variety of different approaches have been developed to tackle them. In particular, for the unsupervised approach, algorithms can be classified in four main categories: nearest-neighbor based, clustering-based, statistical and subspace techniques [Chandola et al. (2009), Goldstein and Uchida (2016)]. Among them, the methods are multiple and their formulations are case-by-case dependent.\nAnomaly detection has been widely explored in the literature, especially in the last years when its developments have been going at the same pace as machine learning\u2019s. The applications in the field of financial frauds detection are numerous [West and Bhattacharya (2016)] and among them, some works are related to market abuse detection such as [Minenna (2003), Donoho (2004), Li et al. (2017), La Morgia et al. (2022)]. However, insider trading detection in stock markets is a quite unexplored topic.\nOur contribution2 In this paper, we propose a machine learning approach to the problem of insider trading detection, that leverages on the availability of a rich dataset including all daily transactions of all (anonymized) investors in the Italian stocks, from the beginning of 2019 to the third quarter of 2021. The methodology is based on two standard and well-known techniques, i.e. the k-means clustering algorithm [Hartigan (1975)] and the statistically validated co-occurrence networks [Tumminello et al. (2011)], that are generalized in a dynamic framework for the study of contextual anomalies in the stock market. The anomaly detection approach proposed here is suited for the specific application to insider trading analysis The methodology has been built following the analysis and reasoning adopted by the Italian competent Authority (Consob) in the first steps of the investigation for insider trading, also taking into account the expertise acquired by the analysis of the output cases already discussed in court.\nIn a first instance, we propose a dynamic clustering approach based on the kmeans algorithm [Hartigan (1975)]. The main idea is representing market data in an Euclidean space in which the trading activity on one stock by an investor in a given time period is described by a point whose coordinates are some trading features, namely the total bought or sold turnover, the trading concentration (also called magnitude), and the financial exposure on the stock. The clustering of investors in such feature space at successive times within a given reference period allows to achieve a stable description of the usual trading behavior, described by clusters persistent in time. Such a characterization of the market provides the ideal context in which we can assess the discontinuity of the investors\u2019 behavior, if any, both with respect to his/her past trading behavior and with respect to the trading behavior before the PSE of his/her peers. For example, when a price sensitive event for the stock is within the reference period, some operations that places an investor in a rewarding position never assumed before, i.e. the switching towards the cluster he/she never belonged to, can be classified as anomalous. The goal is then revealing all discontinuities towards rewarding position with respect to the price sensitive event and ranking them according to some anomaly\n2The methodology presented in the paper was conceived during 2022 for the purposes of developing a proof of concept. It is, in no way, a tool used in the analysis and investigations carried out by Consob. The methodology may possibly constitute in the future one of the tools to help and support the preliminary analysis and detection activities more efficiently. Any subsequent enforcement activity will, in any case, be based on the broader set of information that is gathered in the course of investigations and other possible types of analysis.\nscore, thus providing the competent authority with a list of suspicious behaviors to be further analyzed.\nThe second clustering approach we employ is based on the so-called Statistically Validated Networks (hereinafter SVN). This is an unsupervised learning method which was introduced in [Tumminello et al. (2011)] and further employed in other works such as [Tumminello et al. (2012)]. This method aims at detecting unexpected structures in the projection of a bipartite network which represent a complex system. Similarly to [Tumminello et al. (2012)], we start from a bipartite network investors-trading days, which represents the trading activity for a specific asset in the Italian Stock Exchange. This network is projected in a traders\u2019 graph where links are statistically validated, thus capturing agents\u2019 trading co-occurrences. Then, on this validated projected network, clusters are identified and they represent groups of traders who are synchronized in the kind and time of trading actions. Given these clusters, our analysis focuses on a time window before the PSE under investigation and our goal is to detect group of traders who are likely to be suspicious for market abuse. If for instance, we are studying a takeover bid, investors who belong to a group with suspicious behavior, trade in a rewarding manner in the reference period before the price sensitive event. Since a positive reaction from the market follows a takeover bid, their trading is extremely polarized towards buying transactions.\nAs it is illustrated in the following, the SVN-based clustering approach turns out to be a powerful tool to detect group of investors with suspicious trading before a PSE. Moreover, capturing synchronized trading activity could be of help for the competent authority in establishing when information becomes spread among the market operators and so, how the reference period to focus on market abuse investigations should be framed.\nIt is worth noticing that given the different nature and goals of the k-means and SVN clustering approaches, these two methods lead to different and complementary results, potentially revealing the presence of single insiders and/or insider rings. Finally, the coupled use of the two methods needs to be intended as a support tool to the competent authority in the first steps of insider trading analysis. As such, the proposed methodology contributes to the field of human-centered decision support systems [Barthe\u0301lemy et al. (2002)]. In fact, the SVN-based approach can also be used in a human-in-the-loop manner [Wu et al. (2022)]: a trader z who is considered as suspicious can be used as seed in the statistically validated network of investors to find other possible suspects (neighbors of z in the SVN displaying coordinated trading behavior) or even potential insider rings (clique of connected nodes in the SVN displaying high synchronization).\nPaper organization. The paper is organized as it follows. Section 2 describes the two proposed methods for the identification of individual and collective potential insider trading activities. Section 3 presents the dataset we use in our empirical analysis and Section 4 presents the results obtained with our method, with a special focus on one PSE. Results for other PSEs are presented in the Appendix. Finally, Section 5 draw some conclusions and present some suggestions for further work."
        },
        {
            "heading": "2 Methods",
            "text": "In this Section, we present two different clustering methods, which allow to find groups of investors with similar behavior in trading a given stock, and generalize them to devise a methodology of contextual anomaly detection for insider trading. In the first method, groups are identified by partitioning investors depending on some trading features (turnover, magnitudo, and exposure). In the second method, investors are identified as similar when they trade in a coordinated way (e.g. they buy or sell in the same days), displaying some significant correlation in the trading activity. Finally, contextual anomalies refer to either the discontinuity and the coordination of the trading behavior of investors in the presence of a price sensitive event. This is shown for a particular case study in the next section."
        },
        {
            "heading": "2.1 Method based on k-means clustering",
            "text": "The k-means clustering algorithm [Hartigan (1975)] is an unsupervised learning method for finding clusters of points in a set of unlabeled data that lie in a Euclidean space. Each data point x is a n-tuple of real numbers characterizing the trading features of each investor. The method aims to partition N data points into K clusters, each point belonging to the cluster with the nearest mean, which is named the centroid of the cluster. Such a particular point in the feature space summarizes the average characteristics of all points in the cluster. The output of the clustering algorithm is a partition of the feature space into Voronoi cells. More specifically, given a set of data points {xi}i=1,...,N with xi \u2208 Rn and the number K of clusters in which we aim to partition the feature space, the k \u2212means algorithm finds K sets S = {Sk}k=1,...,K of points corresponding to K centroids, in such a way the squared distance (variance) of points from the centroid within each cluster is minimized, i.e.\nargminS K\u2211 k=1 \u2211 i\u2208Sk ||xi \u2212 ck||2 = argminS K\u2211 k=1 |Sk|Var(Sk) (1)\nwhere ck = 1 |Sk| \u2211 i\u2208Sk xi is the mean of points belonging to Sk, whose cardinality is |Sk|. The vector ck defines the position of the centroid in the feature space. The problem (1) is in general computationally difficult (NP-hard), however there exist several heuristic methods converging quickly to a local minimum. Here, we use a two-phase iterative algorithm, see e.g. [Lloyd (1982)], that minimizes the withincluster variances by alternating batch updates (reassigning points to their nearest cluster centroid, all at once, followed by recalculation of cluster centroids) and online updates (reassigning points one by one only if it reduces the within-cluster variances)."
        },
        {
            "heading": "Trading features",
            "text": "Let N be the number of investors, M the number of stocks, and S the number of trading days. For a given stock j \u2208 {1, . . . ,M} and a given time window \u2206 = (t, t+ |\u2206|] with |\u2206| > 0, e.g. a week (|\u2206| = 5) or a month (|\u2206| = 20), each investor i is associated with a triple of features (i.e. K = 3), summarizing his/her trading activity during that period:\n1. the signed turnover, namely the aggregated Euro turnover of operations within the period, with positive (negative) sign for a net buying (selling) volume,\nA (j) i = \u2211 t\u2208\u2206 Ab(i, j, t)\u2212 \u2211 t\u2208\u2206 As(i, j, t),\nwhere Ab(i, j, t) and As(i, j, t) are the total Euro turnover bought and sold by investor i for stock j in day t;\n2. the magnitudo (or portfolio concentration), namely the relative Euro turnover (without sign) traded in the stock with respect to the total amount traded in any stock,\na (j) i = A\u0303 (j) i\u2211M\nj=1 A\u0303 (j) i\n, with A\u0303 (j) i = \u2211 t\u2208\u2206 Ab(i, j, t) + \u2211 t\u2208\u2206 As(i, j, t);\n3. the maximum exposure (in Euro) to the stock in the time window,\nE (j) i = ( max t\u2208\u2206 |\u03b1t| ) sign(\u03b1t\u0303)\nwhere \u03b1t is the position 3 (in Euro turnover) of investor i in stock j at day t and\nt\u0303 = argmaxt\u2208\u2206|\u03b1t|. For a stock j, a data point having the three features as coordinates in an Euclidean space R3 describes the trading behavior of an investor i, aggregated over a time window \u2206.\nWhile the magnitudo (i.e. relative turnover) a (j) i is by definition between 0 and 1, both the aggregated turnover and the exposure depend strongly on the size of the trader\u2019s portfolio. In absence of any normalization, the clustering algorithm would tend to group together investors of similar sizes, independently from their idiosyncratic trading behavior. Hence, in order to avoid such a spurious effect, it is convenient to rescale each value within the interval [\u22121, 1], as follows. First, let us consider the whole period [t1, tS ], containing m > 1 time windows of length |\u2206|, possibly overlapping.4 Then we compute the three features for each investor i within each time window, i.e. xi \u2261 {A(j)i,s , a (j) i,s , E (j) i,s }s=1,...,m. Finally, we define the re-scaled signed turnover and the re-scaled maximum exposure as\nA (j) i,s \u2190[\nA (j) i,s\nmaxs |A(j)i,s | ,\nand\nE (j) i,s \u2190[\nE (j) i,s\nmaxs |E(j)i,s | .\n3In general, information on the precise composition of the portfolio of each investor is not available, but only the daily aggregated information on his/her operations. As a proxy of asset positions we assume that they are zero on Jan. 1, 2019, then each position at day t is obtained by aggregating bought and sold turnovers from Jan. 1, 2019 up to t.\n4An example is a reference period of one year, with twenty days long windows (i.e. one business month), which are rolled week by week starting from January.\nIn this way, we are able to map the trading activity of an investor i on a stock j in a given time window to three normalized features defined in the space [\u22121, 1] \u00d7 [0, 1] \u00d7 [\u22121,\u22121]. A pictorial example is shown in Figure 1, where a generic investor, i.e. the black dot, belonging to some cluster is identified by three coordinates in the feature space, namely the signed turnover, the magnitudo, and the maximum exposure as defined above.\nSuch an approach is particularly useful when we aim to characterize the trading behavior of an investor within a given time window, with respect to the typical operations done in the whole reference period. In particular, when tS is the date of a price sensitive event for a stock, it is possible to compare the trading behavior of an investor in the previous |\u2206| days with the past. From the point of view of the regulator, this serves to verify whether the current behavior of an investor is coherent or not with its own past.\nFinally, notice that the clustering analysis for the time window \u2206 includes only those investors that are active at least one day in \u2206."
        },
        {
            "heading": "Number of clusters",
            "text": "The number of clusters K in which we partition the feature space is the only input we give to the clustering algorithm. In absence of any prior information on the number of clusters, this represents an hyperparameter one needs to optimize. This is usually done by following some heuristics [Hastie et al. (2009)]. Here, we use a standard approach in clustering analysis known as the elbow method. It is based on the computation of the mean variance of features {xi}i=1,...,N with respect to the centroids\u2019 position\n{ck}k=1,...,K as a function of the number of clusters K, namely\nEK = 1\nK K\u2211 k=1 \u2211 i\u2208Sk ||xi \u2212 ck||2. (2)\nIn fact, EK is a non-increasing function in K, since a larger number of clusters will naturally improve the fit, thus reducing the variance. However, this leads to overfitting at some point. The idea is finding a cutoff point at which the diminishing of the variance (2) becomes negligible. This is obtained by finding the number of clusters K such that the relative (negative) increments of Ek are smaller than 5% when more than K clusters are used. The procedure is in general repeated within each time window of length |\u2206|, by covering the whole period [1, T ]. We select the optimal number of clusters K as the (rounded) mean value over the m time windows."
        },
        {
            "heading": "Dynamic clustering",
            "text": "The k-means clustering algorithm is applied to the set of features computed within each time period \u2206, by rolling the window over the whole period [1, T ]. For each window, the output of the method is the positions of centroids, together with the vector of labels, indicating which investors belong to each cluster. Unfortunately, the convergence to a global minimum is not ensured, possibly resulting in very different centroids\u2019 positions moving from one time period to the next one. Moreover, any permutation of labels does not change the loss function in Eq. (1). However, when we roll the time window over the whole period, it is convenient to associate two clusters in a row with the same label when both of them are formed in large part by the same investors.\nIn order to recover a pattern of stability for clusters, the centroids\u2019 positions that solve the minimization problem at a given time are then used as starting point of the clustering method when the time window is shifted one step forward5. Once the new centroids\u2019 positions are found in the new time window, we consider all possible permutations of labels over the set {1, . . . ,K} and compute the Jaccard similarity coefficient [Hastie et al. (2009)] between the current clusters and the previous ones. This is a metric measuring the overlap between the two sets of elements, which is equal to one when each element is also in the other set and vice versa, zero if not. Any other value between zero and one suggests a partial overlapping between the two clusters, such that the larger is the overlapping, the larger is the coefficient. The final assigned labels are the ones maximizing the Jaccard similarity. In this way, cluster stability tends to be preserved over time.\nIdentification and classification of potential insiders.\nOnce the dynamic clusters have been obtained, the method identifies the potential insider investors. To a PSE one can associate rewarding position (buy or sell) which tells us which is the trading direction that would have produced a profit. Let us assume that in the PSE under investigation the rewarding position is buy. An insider i that aims at maximizing the profit by exploiting the sensitive information on the takeover bid would purchase during the reference period the largest possible volume (Ai \u2192 1),\n5At initial time, random positions are used. The algorithm is then repeated many times for different input seeds, in order to find the global minimum over the number of initializations.\nin particular concentrating his/her investment on the stock (ai \u2192 1), thus reaching his/her maximal historical exposure (Ei \u2192 1). It is clear that the best rewarding position in the feature space is represented by the unit vector 1 \u2261 (1, 1, 1).6 This allows us to identify the cluster with rewarding position (w.r.t. PSE).\nFollowing the principles exposed in the Introduction, an investor that is suspect for insider trading has a discontinuous behavior with respect to his/her own past trading and with respect to the trading behavior of her peers. The proposed clustering method permits to identify the set of suspects with discontinuous trading behavior in a datadriven manner. In fact, an investor is defined as discontinuous if he/she has never belonged to the cluster in the past (non-overlapping) time windows.7 If this is the case, there are two mutually exclusive possibilities: (i) the investor has never traded the stock in the considered period; (ii) the investor has traded the stock in the past, but taking a different position, e.g. lower exposure (Ei 1) and larger portfolio diversification (ai 1). We name the first type of investors as hard discontinuous traders, while the second one as soft discontinuous.\nFinally, given the identified set of discontinuous traders, it is of interest to obtain a ranking of the suspects depending on some score function measuring how much anomalous is their trading behavior. To this end, we can consider any decreasing function of the Euclidean distance d(xi,1) \u2261 \u221a ||xi \u2212 1||2 of the vector of features xi characterizing the investor i from the best rewarding position 1. In the empirical analyses below, the score is defined as si = exp(\u2212d(xi,1)), but other functions can be used."
        },
        {
            "heading": "2.2 Method based on Statistically validated Networks",
            "text": "The second clustering approach we employ is based on the so-called Statistically Validated Networks, which is an unsupervised learning method introduced in [Tumminello et al. (2011)] and further employed in other works such as [Tumminello et al. (2012), Baltakiene et al. (2019), Musciotto (2022)].\nThis method aims at detecting structures in the projection of bipartite networks which represent complex systems. Analogously to [Tumminello et al. (2012)], the complex system under our investigation is the activity of traders in the Italian Stock Exchange. Our goal is to identify clusters of investors who are synchronized in the kind and time of trading actions. This clustering is the starting point for a subsequent analysis which allows us to detect group of traders who are likely to be suspicious for market abuse in correspondence of price sensitive events."
        },
        {
            "heading": "The SVN",
            "text": "Given the stock under investigation, the first step of the method consists in constructing a bipartite network, where the two sets of nodes are made up of traders and trading days respectively. Only links between a trader and a trading day can occur and they\n6Notice here that such considerations are independent from the size of the investor. Two investors with different capital, but trading similarly in a given period, are considered similar in the feature space. This is coherent with the current regulation about insider trading, which persecutes the illegal behavior, independently from the volume of the investment or the profit, if any.\n7Before such an analysis, we need to ensure the stability in time of the cluster under investigation. This is done by verifying that the position of the centroid is almost constant for all time windows.\nrepresent trading activity states. Figure 2 provides an example of this bipartite network. Each edge colors stands for a different trading state.\nMore formally, let us consider i = 1 . . . , N traders and t = 1, . . . , T trading days. In order to characterize investors\u2019 trading activity, the following metric, which we denominate directionality, is associated to investor i in day t:\nr(i, t) = Vb(i, t)\u2212 Vs(i, t) Vb(i, t) + Vs(i, t)\n(3)\nwhere Vb(i, t) and Vs(i, t) are the total volumes (in shares) bought and sold by trader i in day t. The metric r(i, t) is normalized in the sense that it can assume values between \u22121 and 1. This overcomes the difficulty of comparing heterogeneous investors who trade volumes with different orders of magnitude and the activity of a single investor which can be heterogeneous over time.\nDepending on the value of this variable r(i, t) compared to a fixed threshold \u03b8, three different states are defined:\n\u2022 r(i, t) > \u03b8, buying state i.e. s(i, t) = b;\n\u2022 r(i, t) < \u2212\u03b8, selling state i.e. s(i, t) = s; \u2022 \u2212\u03b8 \u2264 r(i, t) \u2264 \u03b8, buying-selling state i.e. s(i, t) = bs. Concerning the threshold \u03b8, in the following we set \u03b8 = 0.01 but, as also observed in [Tumminello et al. (2012)], we verified that results are not affected by the choice of this parameter.\nGiven the states {s(i, t) i = 1, . . . , N, t = 1, . . . , T}, we build a bipartite network where\n\u2022 one layer is made up of traders: A = {1, . . . , N}; \u2022 the other layer is made up of trading days: B = {1, . . . , T}; \u2022 only links of the type (i, t) i \u2208 A, t \u2208 B are admitted; \u2022 each link can be b, s, bs, depending on s(i, t).\nThe goal of our analysis is to perform a clustering of traders therefore, starting from our bipartite system, we focus on the projected network of traders, which is a new network with N nodes, each representing a trader. A link between node i and node j exists if in the bipartite network, the traders i and j share at least one trading day of activity. This means that being E and EP the sets of edges in the bipartite and in the projected network respectively,\n(i, j) \u2208 EP \u21d0\u21d2 for i, j \u2208 A \u2203t \u2208 B s.t. (i, t) \u2208 E and (j, t) \u2208 E .\nSince edges in the bipartite system can be of three types according with the states b, s and bs, in the projected network of traders we can have 9 types of links: bb, ss, bsbs, bs, sb, bbs, bsb, sbs, bss. For instance, if between i and j there exists a link of the type bbs, this means that there is at least one trading day in which i is in state b and j is in state bs. If we consider the network in Figure 2, this situation corresponds to traders i = 1 and j = 2 since in day t = 1, i is in state b and j is in state bs.\nThe projected network of traders is a weighted network where weights are given by the number of days for which a given co-occurrence of states between two traders occurs. Let us consider the example above i.e. in the projected network there exists an edge (i, j) of the type bbs. The weight of this link is given by the number of days for which trader i is in state b and j is in state bs i.e.\nwij = |H| where H \u2282 B s.t. s(i, t) = b and s(j, t) = bs \u2200t \u2208 H.\nIf two traders (i, j) do not share trading days, wij = 0. Thus, we obtain a multilink weighted graph with 9 types of link which can be formalized as GP = (VP , EP , L) where VP = A, L = {bb, ss, bsbs, bs, sb, bbs, bsb, sbs, bss},\nEP = {(wij , lij) i, j \u2208 VP , lij \u2208 L}\nand wij as defined above. This graph is almost complete and so, before performing the clustering, we identify links which are statistically validated against a null hypothesis. These links should highlight the structure and the organization of the system since their presence cannot be explained by a random assignation of co-occurrences. In doing so, the Statistically Validated Networks (SVN) method [Tumminello et al. (2011), Tumminello et al. (2012)] is employed.\nLet us consider the link (i, j) \u2208 EP . First, we define as NQi the number of days in which trader i is in state Q (b, s or bs). Analogously, NRj is the number of days in which trader j is in state R (b, s or bs). Then, NQRij is the number of days in which i is in state Q and j is in state R.\nThe null hypothesis is the random co-occurrence of state Q for investor i and state R for investor j. Thus, the probability of observing X days out of T in which the two traders are in the given states, is described by the hypergeometric distribution H(X|T,NQi , NRj ) and its p-value is defined as\np(NQRij ) = P(X \u2265 N QR ij ) = 1\u2212 NQRij \u22121\u2211 X=0 H(X|T,NQi , N R j ) .\nIf p(NQRij ) is lower than a threshold p, the link is validated.\nConcerning the choice of the statistical threshold, it is fundamental to observe that multiple hypothesis tests are being performed. Thus, suited corrections should be employed. According to the Bonferroni correction, the threshold is the usual singletest significance level divided by the number of performed tests i.e. p = \u03b1/Ntest = 2\u03b1/(9N(N \u2212 1)) and we choose \u03b1 = 0.01. Another approach is the so-called False Discovery Rate (FDR), which is less stringent than Bonferroni. On the one hand, FDR is more prone to validate false positives, on the other hand its statistical power is greater thus resulting in the validation of less false negatives. All the p-values are sorted in increasing order i.e. p1 \u2264 p2 \u2264 . . . \u2264 pNtest ; then, the FDR threshold is pk\u0304 where k\u0304 = arg maxk=1,...,Ntest k such that pk\u0304 \u2264 k\u0304\u03b1/Ntest.\nOnce all tests are performed, the validated projected network of traders is obtained and clustering of traders can be carried out. We adopt the minimalist approach which was proposed in [Tumminello et al. (2012)]: communities of traders are detected on the network which only considers diagonal links i.e. bb, ss, bsbs. As in the previously cited papers, in the empirical analysis described below we find that the number of diagonal links is predominant compared to that of non-diagonal links. Moreover, our goal is to find clusters of investors with similar trading activity around PSEs that are best captured by diagonal links.\nIdentifying clusters with Infomap\nAnalogously to [Tumminello et al. (2011)], in order to obtain clusters, the Infomap method for community detection in networks is employed on the validated networks. Infomap is a community detection method. It is an algorithm which minimizes the map equation over possible network partitions [Bohlin et al. (2014)]. It is part of the flow models for community detection indeed, the map equation for a given network partition represents the information cost of a random walker which moves on the partition. Infomap amounts at finding the network partition for which the information cost is minimum. The map equation allows to obtain a result which is less likely to be affected by resolution limit in community detection and for this reason it is considered one of the best methods. From a practical point of view, we relied on its implementation in the Python package infomap."
        },
        {
            "heading": "Characterising clusters",
            "text": "Given traders\u2019 clusters, their composition can be characterized by relying on the method introduced in [Tumminello et al. (2011)], analogously to what is done in [Tumminello et al. (2012), Baltakiene et al. (2019)]. In particular, we investigate the over-expression and underexpression of the investors\u2019 categories and co-occurrences of states.\nThe method is again based on the hypergeometric distribution as a benchmark for randomness. We have a total of NV elements divided in NC clusters. In order to test whether the attribute Q is over-expressed in the cluster C, we compute the p-value\npo(NCQ) = 1\u2212 NCQ\u22121\u2211 X=0 H(X|NV , NC , NQ)\nwhere NQ is the total number of elements in the system with attribute Q. If po(NCQ) is lower than a statistical threshold corrected with Bonferroni or FDR, then the null\nhypothesis is rejected and we can conclude the attribute Q is over-expressed in cluster C.\nIn a similar way, we test whether an attribute Q is under-expressed in cluster C by comparing the p-value\npu(NCQ) = NCQ\u2211 X=0 H(X|NV , NC , NQ)\nwith a given statistical threshold.\nIdentification and classification of potential insider rings.\nAfter the identification of the groups of investors, the method is used to identify potential insider rings, i.e. small groups of investors which trade in a synchronized way and in a rewarding position before the PSE. If, for example, the rewarding position is to buy, looking for coordinated suspicious clusters consists in finding groups of investors who are in the b state in the proximity of the PSE.\nIn order to characterize more quantitatively clusters\u2019 suspicious behavior, some aggregated metrics are considered. The focus is on a time window \u2206\u0304 before the PSE; this could be considered as an average reference period observed by the competent Authorities while investigating insider trading related to the kind of PSE here considered. Then, metrics are computed on \u2206\u0304 as averages over each cluster. They are the mean directionality RC and the mean expected profit \u03c0C . RC is the average over the cluster C of the metric r(i, t) (Equation 3). The mean expected profit \u03c0C is defined as the average expected profit of the traders in cluster C computed with respect to the takeover bid share price pTB announced at the time of the PSE:\n\u03c0C = 1\nNC \u2211 i\u2208C \u03c0i where\n\u03c0i = pTB (\u2211 t\u2208\u2206\u0304 [Vb(i, t)\u2212 Vs(i, t)] ) \u2212 \u2211 t\u2208\u2206\u0304 [Ab(i, t)\u2212As(i, t)] (4)\nwhere NC is the number of traders in cluster C, Vb/s(i, t) are the volumes (in shares) bought/sold by trader i in day t, Ab/s(i, t) are the amounts (in Euro) bought/sold by trader i in day t."
        },
        {
            "heading": "3 Data",
            "text": ""
        },
        {
            "heading": "3.1 Transaction reporting database",
            "text": "The analysis is based on transaction reports collected by Consob for the Italian stocks, according to the directive 2014/65 by European Union, also called MiFID II8 The\n8In a nutshell, the MiFIDII/MiFIR regime has introduced new regulations for European financial markets and, among them, the transaction reporting obligation that requires investment firms or intermediaries executing transactions in financial instruments to communicate \u201ccomplete and accurate details of such transactions to the competent authority as quickly as possible, and no later than the close of the following working day\u201d.\nrelevant dataset was built aggregating the daily transactions of all investors operating in any of the Italian stocks, in the period from January 1, 2019 to September 30, 2021. In details, the dataset was built according to the following rules: i) all the information related to the identity of individual investors have been anonymized; ii) with reference to each stock (identified by its ISIN code), each data point keeps a record of:\n1. anonymous identifier of the investor;\n2. type of investors (household: H, investment firm: IF, legal entity: L);\n3. trading venue of the operation (Borsa Italiana - MTA, London Stock Exchange - LSE, off-exchange, etc.) for a total of . . . ;\n4. day of the operation;\n5. buy and sell volumes (in shares);\n6. buy and sell Euro volumes;\n7. number of buy and sell contracts;\n8. price of both the first and the last contracts (if there are more than one contract, otherwise they coincide);\n9. minimum and max prices of contracts (if there are more than one contract, otherwise they coincide);\n10. average price of buy (sell) contracts.\nIn the period covered by the dataset, 2,253,707 investors were observed, operating in 286 Italian stocks. This dataset was recently used in the investigation of the trading behavior of Italian investors during the Covid pandemic ([Deriu et al. (2022)])."
        },
        {
            "heading": "3.2 Price sensitive events database",
            "text": "In addition to the transaction reporting database, a data set containing several price sensitive events (PSEs) was built; such events, obviously public, had all been analysed by the competent Authority with the aim of market abuse detection, by the way of standard analytics methodologies. PSEs are events or a set of circumstances relating to listed companies which, when made public, had a significant impact on the price of the company\u2019s shares.\nOur focus is on insider dealing in the Italian Stock Exchange. Investors who know in advance when a PSE will occur, can trade in a rewarding manner before the information spreads, thus closing their position after the PSE and making a profit. For instance, if a trader knows a few days before its public announcement that a takeover bid is going to occur for a given stock, they could exploit such information by buying shares of the stock considered. When the takeover bid occurs, the shares\u2019 price goes up aligning with the offer price and thus, the informed trader can sell by making a no-risk profit.\nPSEs dataset contains a list of takeover bids for a number of stocks. As known, a takeover bid is a public offer made by a physical person or a legal entity who is willing to buy other shareholders\u2019 shares at a price higher than the stock market value. As we saw, takeover bids can be exploited by an informed trader by buying before the event. It is worth mentioning that takeover bids have prolonged effects on the market, thus an insider can make a profit even without closing the position immediately after the announcement.\nOur data report for each PSE the stock, the type of the event, its date, and the time window for insider trading analysis. This reference period for investigation varies depending on the type of PSE, which leads to different definitions of the time at which an information starts to be considered price sensitive. In Table 1, the PSEs database is displayed."
        },
        {
            "heading": "4 Results",
            "text": "We tested our methods on a set of specific PSEs, namely takeover bids, which are listed in Table 1 together with the considered reference period. For space reason, in the following we present in detail a case study related to the the takeover bid for the Italian stock \u201cIndustria Macchine Automatiche\u201d (IMA) announced on July 28, 2020. In the Tables and in the Appendix we present also results obtained by investigating the other PSEs.\nThe data set related to IMA covers the period January 2, 2019 - February 15, 2021 i.e. T = 541 trading days. The starting number of active investors9 is 26, 911 and the total number of records is 214, 122. Summary statistics of the data set is reported in the top panel of Table 2 by referring to the investors\u2019 grouping of our database, as explained in Section 3.1. We observe 95.5% of investors are represented by households and their corresponding exchanged volume amounts at 6.7% of the total. On the other hand, investment firms which are the 0.5% of total investors, trade 59.0% of the total volume.\nBy looking at the number of days with trading activity for each trader in the investigated period, we observe that this number is small for a wide range of investors. This is shown in Figure 3 where the probability density function of investors\u2019 trading activity days is displayed.\nIn the SVN analysis below, we will consider a threshold on the number of days in which an investor has traded, then obtaining the restricted set of the most active investors in the market. Summary statistics of this restricted data set are reported also in the top panel of Table 2. Finally, in the bottom panel of Table 2, the same statistics, but aggregated over all types of investors, are shown for the other assets involved in a takeover bid analysis.\n9An investor is active if he/she executed at least one transaction in the observed time frame. In the text the words investor and trader are used indifferently."
        },
        {
            "heading": "4.1 K-means results",
            "text": "The k-means clustering method described in Section 2.1 is applied by defining: (i) tS as the date of the PSE, namely July 28, 2020, (ii) the length of the time window |\u2206| as the duration of the reference period shown in Table 1, i.e. one business month of 20 days, and (iii) January 2, 2020 as initial time t1. We consider a rolling window \u2206 starting from January 2020, then shifted week by week until the date of the PSE, for a total of 27 time windows. Within each time window, the features characterizing the trading behavior of an investor are computed as described above.\nBefore running the algorithm we find the optimal number of clusters K in each time window. The distribution of optimal Ks is shown in the left panel of Figure 4. We select a single hyperparameter K for each time window as the rounded mean of the distribution, obtaining K = 7. We finally consider the dynamic clustering approach, achieving a stable description of the clusters in which we partition the feature space. This is confirmed by the high value of the Jaccard similarity coefficient, as shown in the middle panel of Figure 4. In fact, the positions of the centroids in the feature space is almost stable in the whole period, see the right panel of Figure 4.\nA pictorial representation of the clusters in the Euclidean space at three different months (May, June, July) is shown in Figure 5, where each cluster is identified by a\ndifferent color. We can notice that almost all clusters are stable from one month to the next one, with the exception of the blue and the purple ones. Moving from May to June and then from June to July, the optimal partition shows some switching behavior depending on the distribution of blue and purple features at different months.\nFollowing the discussion in Section 2.1, the cluster more likely to be involved in insider activity is the red one, since it is the one whose centroid is closest to 1. However, being in the red cluster is not necessarily an indication of insider activity, since it is necessary to investigate whether an investor belonged to it also in the reference period or displayed a discontinuous behavior.\nFor IMA there are 66 soft discontinuous and 237 hard discontinuous traders in the red cluster, summing to 303 discontinuous traders over a total of 379 investors in the red cluster, see Table 3. The question is now whether the fraction of discontinuous traders is statistically significant when compared with other clusters or not. In other words, the crucial point is to know if the cluster with rewarding position is somehow anomalous when looking at the discontinuity of trading behavior of investors. A pairwise comparison can be performed in a statistical fashion by using the \u03c72-test. Given two clusters, whose investors are labeled as continuous or discontinuous traders, we can test the null hypothesis that the labels have equal probability in the two clusters (e.g. if the fraction of discontinuous traders in the red cluster is consistent with the fraction\nof discontinuous traders in another cluster) by considering the following statistic\n\u03c72 = \u2211\n`\u2208{C,D}\n(n (1) ` \u2212 n (2) ` ) 2\nn (1) ` + n (2) `\nwhere ` indicates the label, i.e. continuous C or discontinuous D, and n (1) ` (n (2) ` ) is the number of investors with label ` in the first (second) cluster. Under the null hypothesis, the test statistic (4.1) is \u03c72-distributed with one degree of freedom. When the p-value associated with the test statistic is below a given confidence level, e.g. 5% or 1%, the null hypothesis is rejected and it is possible to conclude that two clusters are statistically different. In the case under investigation, the comparison between the red cluster and any other one is done by performing K \u2212 1 \u03c72-test, i.e. red vs. any other color. The results lead to the conclusion that the red cluster is statistically different from the others if the null hypothesis is always rejected. For IMA and PANARIAGROUP this is true at 5% confidence level while for the others at 1% level. In particular, the fraction of discontinuous traders in the red cluster is always larger than others. This result is summarized in Table 3, where the percentage of discontinuous traders in the red cluster and the average percentage in other clusters is displayed.\nOnce the set of discontinuous investors has been obtained, we can sort them according to the score si defined in Section 2.1, which is inversely related to the distance from the 1 point in the cube. The ranking for IMA is shown in Table 4. Notice that there are 224 discontinuous traders in the highest rewarding position (score equal to one) over a total of 303 investors. This subset is then ranked according to the number of shares bought within the reference period. The directionality of the operations, as defined in Eq. (3), and the expected profit, as defined in Eq. (4) and with respect to the takeover bid share price pTB = 68.0 \u20ac, are also shown.\nThis kind of ranking is the final output of the methodology introduced here and needs to be interpreted as support to the investigation for insider trading by the regulator."
        },
        {
            "heading": "4.2 SVN results",
            "text": "We now describe the application of the SVN method to the IMA takeover bid to identify small groups of potential insiders. Since the method is based on a statistical set, analogously to what is done in [Tumminello et al. (2011)], we restrict the analysis to the investors who traded at least 8 days in the investigated time period. Setting this threshold allows us to reduce the statistical uncertainty which is typical of rare events. The number of traders under investigation drops to N = 4, 844 as shown in Table 2 together with a summary of this restricted data set. From this table, it is evident that the investors in the restricted data set i.e. the ones who are active in at least 8 days, trade 93.6% of the total exchanged volume.\nGiven this data restriction, we proceed as explained in subsection 2.2: states and the projected network of traders are obtained, then links are statistically validated with both Bonferroni and FDR corrections and finally, clustering is performed via Infomap.\nThe Bonferroni threshold turns out to be equal to about 9.47 \u00b710\u221211 while the FDR threshold is about 3.39\u00b710\u22124. Table 5 shows the number of validated edges we obtained with the two corrections. With both corrections, the majority of validated links belong\nto the bb and ss types and are about 3 millions. This represents a consistent reduction in the number of possible edges in the projected network of traders which amounts at N(N \u2212 1)/2 \u2217 9 ' 108. However, as we will see in the following, this number is larger than the one obtained for assets with similar number of investigated records and this could be due to the fact than in the IMA case there are stronger signals of synchronization.\nFocusing on the diagonal links i.e. bb, ss and bsbs, and on the resulting network, the clustering is performed. With the Bonferroni correction, the SVN is made up of 2, 434 non-isolated nodes and 3, 127, 424 edges. With FDR instead, the SVN is made up of 4, 673 non-isolated nodes and 3, 511, 267 edges. See Appendix B for further details about SVN traders\u2019 type. When Infomap is run for both the Bonferroni and FDR SVN we obtain 69 and 13 clusters, respectively. In Appendix B, tables with summary statistics about the most populated clusters are reported together with an analysis of the relation between the FDR and the Bonferroni network.\nOnce the clusters have been obtained, we display the activity of the investors which do not correspond to isolated nodes as suggested in [Tumminello et al. (2011)], providing an extremely useful representation of coordinated behaviors of investors around the PSE. Figures 6 and 7 show the trading activity of non-isolated nodes in the Bonferroni10 SVN. The x-axis represents investors and the y-axis trading days. Black points correspond to no-activity, red to b state, green to s state and white to bs state. Therefore, each vertical sequence of points represents the activity over time of a given trader. Vertical light blue lines separate the clusters obtained via Infomap and the dotted orange horizontal line marks the date of the PSE i.e. the takeover bid of July 28, 2020.\nFigure 6 shows that the largest identified cluster is composed by more than 2000 investors, most of them being households, and displays an extremely synchronized behavior. This coordinated behavior is likely explained by investors with portfolios managed by the same entity. In Figure 7 we observe all the other clusters and it is clear that the degree of trading synchronization inside each of them is very high, displaying, also for this database, the amazing capability of SVN to identify small synchronized clusters.\n10In Appendix B, the corresponding activity plots for the FDR SVN are reported.\nWe now turn to the use of SVN for the identification of potential insider rings. For the IMA case, the reference period \u2206\u0304 corresponds to the period from June 29, 2020 to the PSE and the takeover bid share price, used to compute the mean expected profit \u03c0C , is pTB = 68.0 \u20ac. To identify suspect clusters, we compute he mean directionality RC and \u03c0C for the clusters of both the Bonferroni and the FDR SVN. Table 6, reports the results for the Bonferroni clusters with mean directionality greater than 0.5. Most of these clusters are made up of a couple of traders and in three cases, only one of them is active in the reference period \u2206\u0304. Notice that also the large cluster of Fig. 6 is present in the table. Figure 8 shows the activity of the small clusters of Table 6. The buying coordinated behavior of these traders in the time window \u2206\u0304 is evident. Several clusters in the figure were essentially inactive in the months preceding the PSE and started trading in very coordinated way with a rewarding position (buy in the IMA case) in the vicinity of the PSE and then closed the position after it. This suggests a suspicious behavior that requires further investigations by the competent Authority.\nWhen we use FDR instead of Bonferroni correction, we find that the obtained clusters have typically a lower directionality and this might be related to the larger number of false positives detected by FDR. As Figure 15 of the Appendix shoes, the FDR cluster number 1 contains the majority of non-isolated nodes in the Bonferroni SVN. This issue concerning the FDR correction is also present for other the other investigated PSEs. Table 7 shows the number of traders in clusters with mean directionality greater than or equal to 0.9 for the 5 takeover bids. It is observed that employing the FDR correction in the IMA case leads to a catastrophic reduction in the number of traders in clusters with high directionality. This reduction is about the 27 % for UBI. Also for MOLMED the FDR captures less traders in clusters with high directionality, even if the difference is just of a couple of units. On the other hand, results are unchanged for CARRARO while, for PANARIAGROUP, the FDR correction is more effective at detecting traders in suspicious clusters but, similarly to MOLMED, the difference is just of one unit.\nThe richer nature of the FDR SVN can however be determinant when we would like to use the SVN method in a kind of human-in-the-loop manner. Let us suppose that another method for market abuse detection determines that an investor has a suspicious behavior. Then, it is possible to identify investors who are coordinated with the suspicious one in their trading actions, by focusing on the first neighbors in the validated projected network of investors. As an example, we will consider the suspicious investors identified according to the k-means-based methodology in the IMA case. These are isolated nodes in the Bonferroni SVN, while they are not in the FDR SVN. In Figure 9, each sub figure shows the trading activity of a suspected trader according to k-means (the one most on the left) and of its first neighbors in the FDR SVN. It is clear that several first neighbors exhibit suspicious trading behavior around the takeover bid, but they were not identified by the k-means method. A more precise analysis is out of the scope of the paper and it is left for future research.\nAs seen above, the choice of the correction used for multiple hypothesis tests is fundamental and can lead to different conclusions about candidate traders as insiders. Then, an option would be treating the statistical threshold for edge validation in our projected network of traders, as a parameter to be optimized. The optimal value of this threshold corresponds to the maximum number of traders in clusters with mean directionality greater than or equal to 0.9. In Figure 10, this analysis is carried out for\nIMA, UBI, PANARIAGROUP and MOLMED. The trend observed for IMA and UBI is similar and the maximum is achieved for a statistical threshold equal to 10\u22125 and 10\u22127 respectively. This choice would amount at obtaining for IMA, 27 more traders in suspected clusters than the Bonferroni correction and 36 for UBI. For PANARIAGROUP, 10\u22126 leads to the maximum value 4. MOLMED instead, has an optimal threshold equal to 10\u22125, which leads to 7 traders in suspected clusters. It is worth noting that MOLMED and PANARIAGROUP are asset with less records than IMA and UBI, as shown by Table 2, and so, this could also explain their fluctuating behavior observed in Figure 10. These results confirm how the choice of an optimal statistical threshold for validation should be carried out case-by-case.\nNotice that, in order to check the robustness of the SVN method for market abuse detection, the clustering is performed also with an entropy-based approach introduced in [Saracco et al. (2017)]. The Jaccard similarity [Hastie et al. (2009)] between couples of clusters obtained with the two procedures is computed and good agreement is found, as it is shown in the results reported in Appendix C."
        },
        {
            "heading": "4.3 Discussion on methods",
            "text": "The k-means and the SVN based approaches for market abuse detection are two methods with different purposes: the former aims at capturing discontinuities in the trading operations of single investors (although taking into account the trading behavior of\nhis/her peers). Instead the latter focuses on the identification of coordinated suspicious behavior of groups of investors. Consequently, they detect different anomalies.\nLet us focus on IMA again and compare the traders identified as suspicious by the two methods. The k-means identified a total of 303 discontinuous investors, divided in 237 hard and 66 soft. On the other hand, the SVN Bonferroni approach detected 1, 662 traders in clusters with mean directionality greater than or equal to 0.9. The overlap is very small, resulting in 4 traders, 2 households and 2 legal entities. The two households are soft discontinuous traders and they are part of the cluster number 1 in the SVN Bonferroni. They are both characterized by a strong directionality (1 and 0.99) but different levels of expected profit (1380 \u20ac and 95, 619 \u20ac). The two legal entities are instead hard discontinuous traders with very high expected profits (277, 625 \u20ac and 241, 132 \u20ac) and directionality (1 and 0.81); they are traders number 3 and 4 in Table 4. Interestingly, they form a micro cluster of 2 highly synchronized traders, that is the cluster number 29 in the SVN Bonferroni.\nThis comparison highlights how the two methods provide different but complementary results. Given the complexity of the problem, it has to be tackled with an approach that captures several aspects at the same time. Therefore, the lacking of overlapping between the results of the two methods needs to be considered as strength of the proposed approach."
        },
        {
            "heading": "5 Conclusions",
            "text": "This paper proposes the use of two unsupervised clustering methods for the identification of potential suspects of insider trading in the vicinity of a PSE, such as a takeover bid. The first method clusters the investors in a space of three features and identifies as potential suspects those investors who display a discontinuous trading behavior with respect to their past activity and in a rewarding direction with respect to the PSE. The second method aims at detecting small groups of investors which trade in a synchronized and rewarding way in the vicinity of a PSE, pointing at possible insider rings and collusion in the insider trading activity. The two methods are complementary and indeed the overlap between the potential suspects found by them is small. In our opinion this is an advantage, since they focus on two different aspects of insider trading activity. Moreover, as shown at the end of Section 4.2, they can be used jointly to identify investors which are not identified by each method individually. This approach based on the identification of neighbors of suspect investors in the FDR network can also be used by considering suspects obtained with other methods (for example with the traditional supervising approach) rather than with the suspects from k-means.\nThere are several extensions of this work which we can foresee. First, it would be interesting to extend our analysis to other PSE, such as, for example, Accelerated Bookbuilds or corporate news releases. Second, in the k-means approach we have considered three specific features, which have been chosen both because they are financially relevant for the problem under investigation (insider trading) and because they allow to represent the investors in a three dimensional space. However, it is clear that other features could be added to the clustering analyses obtaining a richer characterization of the investors\u2019 population and thus a more precise identification of discontinuous behavior. Third, concerning the SVN approach, we used a trading day to define synchronous trading and for this reason we defined the trading state on a daily level. However,\nsynchronous behavior can occur on longer (or shorter) time scales and one can easily extend our methodology in this direction. Finally the SVN method could shed light on the reference time to monitor suspicious trading activity around a PSE.\nIdentification of insider trading is a complicated activity which requires the analysis of large and complex datasets, especially if one wants to consider the activity of potential insiders, not on an individual basis, but through a comparison with the behavior of the whole population of investors. Our proposed methodologies provide two contributions in this direction and we believe they might be very useful in the monitoring activity of supervising authorities. As clearly reported, such methodologies do not constitute any official process of the Consob but represent an in-depth analysis tool to be used when certain investigative conditions are met."
        },
        {
            "heading": "Acknowledgments",
            "text": "We wish to thank Sandro Leocata, Francesco Gigante, Carlo Martinoli, Stefania La Civita, Alessio Sanfilippo, Vincenzo Vicari, Giancarlo Carotenuto and Mario Formato - working at the Consob, Market Division, Cash and Derivatives Department - for their useful comments."
        },
        {
            "heading": "APPENDIX",
            "text": ""
        },
        {
            "heading": "A Robustness analysis of k-means: outputs for",
            "text": "other PSEs\nThe analysis of cluster stability, similarly to the one presented in Section 4.1, is performed also for other takeover bid events involving other stocks. The obtained results are in line with the IMA case presented above. They are summarized in Figures 11 and 12."
        },
        {
            "heading": "B SVN: more details about the IMA case",
            "text": "In table 8, the number of different types of non-isolated traders in the Bonferroni and FDR SVN bb-ss-bsbs is reported.\nIn tables 9 - 10, summary statistics about the most populated clusters obtained via Infomap are reported. In particular, the method illustrated in the last paragraph of subsection 2.2 is employed to obtain the over/under-expression of traders\u2019 attributes in clusters.\nIn figures 13 - 14, plots which represent trading activity of non-isolated nodes in the FDR SVN bb-ss-bsbs are displayed.\nBeing the FDR correction less restrictive than Bonferroni, the SVN obtained with\nthe latter is contained in the SVN achieved with the former. Figure 15 shows an heat map representing how the clusters obtained via Infomap from the Bonferroni SVN are contained in the clusters coming from the analogous FDR network. The element (i, j) in the plot is the fraction of nodes of Bonferroni cluster j that is contained in FDR cluster i. This means each column sums up to 1 and represents how the nodes in the corresponding Bonferroni cluster are rearranged in the FDR clusters. The FDR cluster number 1 is made up of 4, 417 elements and it turns out to contain most of the non-isolated nodes detected by the Bonferroni SVN."
        },
        {
            "heading": "C Robustness analysis of SVN: comparison with",
            "text": "maximum entropy methods\nIn order to check the robustness of the SVN method for market abuse detection, the clustering is performed also with another method introduced in [Saracco et al. (2017)]. It is an entropy-based approach which employs the Bipartite Configuration Model (BiCM) as statistical benchmark."
        },
        {
            "heading": "C.1 Method",
            "text": "As for the SVN method, the starting point is to compute the states {s(i, t) i = 1, . . . , N, t = 1, . . . , T} and then, to organize our data in a bipartite network where\n\u2022 one layer is made up of traders: A = {1, . . . , N}; \u2022 the other layer is made up of trading days: B = {1, . . . , T}; \u2022 only links of the type (i, t) i \u2208 A, t \u2208 B are admitted; \u2022 each link can be b, s, bs, depending on s(i, t).\nGiven the bipartite network, traders similarity is computed and its statistical significance is measured by performing multiple hypothesis tests with the BiCM as benchmark.\nFor simplicity, let us consider our network as it just had a single type of diagonal link e.g. bb and thus, let us focus on the states of type b. Traders similarity is defined as the number of trading days in which i is in state b and so does j:\nNij = T\u2211 t=1 \u03c3it\u03c3jt = T\u2211 t=1 N tij\nwhere \u03c3it = I[(i, t) \u2208 E] and E is the edge set of the bipartite graph. This measure of similarity represents the number of the so-called V-motifs.\nIn order to quantify the statistical significance of traders\u2019 similarity, the Exponential Random Graph (ERG) class of null-models is considered. These models assign to a bipartite graph M a probability\nP (M) = e\u2212H(\u03b8,C(M))\nZ(\u03b8)\nwhere \u03b8 is a vector of unknown parameters, C(M) is a vector of constraints, H(\u03b8, C(M)) is the system\u2019s Hamiltonian and Z(\u03b8) is the partition function.\nIn [Saracco et al. (2017)], several ERG models are considered; here, we choose to focus on the Bipartite Configuration Model (BiCM). The BiCM Hamiltonian imposes constraints on the degree sequences of both layers indeed,\nH(\u03b8, C(M)) = N\u2211 i=1 \u03b1iki + T\u2211 t=1 \u03b2tht\nwhere ki, i = 1, . . . , N and ht, i = t, . . . , T are the degrees of traders and trading days respectively. More precisely, we have\nki = T\u2211 t=1 \u03c3it\nht = N\u2211 i=1 \u03c3it .\nThe parameters \u03b1i, i = 1, . . . , N and \u03b2t, t = 1, . . . , T are Lagrange multipliers which are determined by Maximum Likelihood Estimation (MLE) starting from the biadjacency matrix M\u2217 of an observed network.\nThe linear constraints of the system allow us to rewrite P (M) in a factorized form:\nP (M) = N\u220f i=1 T\u220f t=1 p\u03c3itit (1\u2212 pit) 1\u2212\u03c3it\nwhere\npit = e\u2212(\u03b1i+\u03b2t)\n1 + e\u2212(\u03b1i+\u03b2t) .\nThe presence of linear constraints in the Hamiltonian amounts at treating links as independent random variables. This means Nij is the sum of T independent Bernoulli random variables with\nP(N tij = 1) = pitpjt P(N tij = 0) = 1\u2212 pitpjt .\nThus, Nij is a Poisson-Binomial random variable and\nP(Nij = n) = \u2211 C\u2282Cn [\u220f t\u2208C pitpjt \u220f t\u2032 /\u2208C (1\u2212 pit\u2032pjt\u2032) ]\nwhere Cn is the set of all subsets made up of n integers that can be selected from {1, 2, . . . , T}.\nGiven this distribution, the computation of the p-value follows:\np(N\u2217ij) = P(Nij \u2265 N\u2217ij)\nwhere N\u2217ij is the value of the V-motifs in the observed network. As for the SVN method, the link (i, j) is validated whether p(N\u2217ij) is lower than a statistical threshold which is corrected with the FDR procedure. In order to implement this method, we used the Python package bicm, which relies on the algorithm introduced in [Hong (2013)] to compute the Poisson-Binomial distribution. Once the validated projected network of traders is obtained, we performed the clustering with Infomap."
        },
        {
            "heading": "C.2 Results",
            "text": "As for the SVN method, first we obtain activity states and the bipartite network of traders and trading days. Given this network, V-motifs are validated as it is described in the previous paragraph. Our ultimate goal is to perform clustering on the validated projected network of traders with only diagonal links therefore, the maximum entropy method can be run on a reorganized version of the bipartite network: it is made up of three disjoint bipartite graphs, each one characterized by a different edge type (b, s and bs).\nSo, the maximum number of edges in the projected network of traders we obtain with this approach, is 3N(3N \u2212 1)/2. This number is greater than the corresponding one we have in the SVN method i.e. 9N(N \u2212 1)/2 ; indeed, in that case the validated network was obtained allowing for all links and not-diagonal edges were removed secondly. However, we observe 3N(3N \u2212 1)/2 and 9N(N \u2212 1)/2 share their dominating terms and given N = 4, 844, the corrections in multiple tests for the two methods have a difference which is negligible.\nThe validated projected network of traders that is obtained with the maximum entropy method has 3, 279, 920 edges and 2, 751 non-isolated nodes. After running Infomap, the clusters are 93 and analyses similar to the ones carried out in the SVN method can be done. However, we would like to focus on a comparison of the clusters obtained by the Bonferroni SVN and the maximum entropy method. In figure 16, an heat map representing the Jaccard similarity [Hastie et al. (2009)] between couples of clusters obtained with the two procedures is reported. The line which can be identified, shows that basically, 41 clusters have a one-to-one correspondence and among them, 31 have values of Jaccard similarity greater than 0.8."
        }
    ],
    "title": "A machine learning approach to support decision in insider trading detection",
    "year": 2022
}