{
    "abstractText": "While the PICO framework is widely used by clinicians for clinical question formulation when querying the medical literature, it does not have the expressiveness to explicitly capture medical findings based on any standard. In addition, findings extracted from the literature are represented as freetext, which is not amenable to computation. This research extends the PICO framework with Observation elements, which capture the observed effect that an Intervention has on an Outcome, forming Intervention-Observation-Outcome triplets. In addition, we present a framework to normalize Observation elements with respect to their significance and the direction of the effect, as well as a rule-based approach to perform the normalization of these attributes. Our method achieves macroaveraged F1 scores of 0.82 and 0.73 for identifying the significance and direction attributes, respectively.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ali Turfaha"
        },
        {
            "affiliations": [],
            "name": "Hao Liua"
        },
        {
            "affiliations": [],
            "name": "Latoya A Stewartb"
        },
        {
            "affiliations": [],
            "name": "Tian Kanga"
        },
        {
            "affiliations": [],
            "name": "Chunhua Wenga"
        }
    ],
    "id": "SP:f248311fbfc93e0eda021b7fb6c60446d3e19ae2",
    "references": [
        {
            "authors": [
                "D.L. Sackett",
                "W.M. Rosenberg",
                "J.M. Gray",
                "R.B. Haynes",
                "W.S. Richardson"
            ],
            "title": "Evidence based medicine: what it is and what it isn't",
            "venue": "in, British Medical Journal Publishing Group,",
            "year": 1996
        },
        {
            "authors": [
                "H. Bastian",
                "P. Glasziou",
                "I. Chalmers"
            ],
            "title": "Seventy-five trials and eleven systematic reviews a day: how will we ever keep up",
            "venue": "PLoS med",
            "year": 2010
        },
        {
            "authors": [
                "J.W. Ely",
                "J.A. Osheroff",
                "M.H. Ebell",
                "G.R. Bergus",
                "B.T. Levy",
                "M.L. Chambliss",
                "E.R. Evans"
            ],
            "title": "Analysis of questions asked by family doctors regarding patient",
            "venue": "care, Bmj",
            "year": 1999
        },
        {
            "authors": [
                "S.A. Miller",
                "J.L. Forrest"
            ],
            "title": "Enhancing your practice through evidence-based decision making: PICO, learning how to ask good questions",
            "venue": "Journal of Evidence Based Dental Practice",
            "year": 2001
        },
        {
            "authors": [
                "D. Demner-Fushman",
                "J. Lin"
            ],
            "title": "Answering clinical questions with knowledge-based and statistical techniques",
            "venue": "Computational Linguistics",
            "year": 2007
        },
        {
            "authors": [
                "E. Znaidi",
                "L. Tamine",
                "C. Latiri"
            ],
            "title": "Answering PICO clinical questions: A semantic graph-based approach",
            "venue": "in: Conference on Artificial Intelligence in Medicine in Europe,",
            "year": 2015
        },
        {
            "authors": [
                "F. Boudin",
                "J.-Y. Nie",
                "M. Dawes"
            ],
            "title": "Clinical information retrieval using document and PICO structure, in: Human Language Technologies: The 2010",
            "venue": "Annual Conference of the North American Chapter of the Association for Computational Linguistics,",
            "year": 2010
        },
        {
            "authors": [
                "B.C. Wallace",
                "J. Kuiper",
                "A. Sharma",
                "M. Zhu",
                "I.J. Marshall"
            ],
            "title": "Extracting PICO sentences from clinical trial reports using supervised distant supervision",
            "venue": "The Journal of Machine Learning Research",
            "year": 2016
        },
        {
            "authors": [
                "T. Kang",
                "S. Zou",
                "C. Weng"
            ],
            "title": "Pretraining to recognize PICO elements from randomized controlled trial literature, Studies in health technology and informatics",
            "year": 2019
        },
        {
            "authors": [
                "O. Bodenreider"
            ],
            "title": "The unified medical language system (UMLS): integrating biomedical terminology, Nucleic acids research",
            "year": 2004
        },
        {
            "authors": [
                "J.M. Overhage",
                "P.B. Ryan",
                "C.G. Reich",
                "A.G. Hartzema",
                "P.E. Stang"
            ],
            "title": "Validation of a common data model for active safety surveillance research",
            "venue": "Journal of the American Medical Informatics Association",
            "year": 2012
        },
        {
            "authors": [
                "J.L. Warner",
                "D. Dymshyts",
                "C.G. Reich",
                "M.J. Gurley",
                "H. Hochheiser",
                "Z.H. Moldwin",
                "R. Belenkaya",
                "A.E. Williams",
                "P.C. Yang"
            ],
            "title": "HemOnc: A new standard vocabulary for chemotherapy regimen representation in the OMOP common data model, Journal of biomedical informatics",
            "year": 2019
        },
        {
            "authors": [
                "H. Xu",
                "S.P. Stenner",
                "S. Doan",
                "K.B. Johnson",
                "L.R. Waitman",
                "J.C. Denny"
            ],
            "title": "MedEx: a medication information extraction system for clinical narratives",
            "venue": "Journal of the American Medical Informatics Association",
            "year": 2010
        },
        {
            "authors": [
                "S. Sohn",
                "C. Clark",
                "S.R. Halgrim",
                "S.P. Murphy",
                "C.G. Chute",
                "H. Liu"
            ],
            "title": "MedXN: an open source medication extraction and normalization tool for clinical text",
            "venue": "Journal of the American Medical Informatics Association",
            "year": 2014
        },
        {
            "authors": [
                "T.W. Post"
            ],
            "title": "UpToDate: Evidence-based Clinical",
            "venue": "Decision Support,",
            "year": 2021
        },
        {
            "authors": [
                "I. Chalmers"
            ],
            "title": "The Cochrane collaboration: preparing, maintaining, and disseminating systematic reviews of the effects of health care",
            "venue": "Annals of the New York Academy of Sciences",
            "year": 1993
        },
        {
            "authors": [
                "X. Zhang",
                "P. Geng",
                "T. Zhang",
                "Q. Lu",
                "P. Gao",
                "J. Mei"
            ],
            "title": "Aceso: PICO-guided Evidence Summarization on Medical Literature, IEEE journal of biomedical and health informatics",
            "year": 2020
        },
        {
            "authors": [
                "M. Fiszman",
                "D. Demner-Fushman",
                "H. Kilicoglu",
                "T.C. Rindflesch"
            ],
            "title": "Automatic summarization of MEDLINE citations for evidence-based medical treatment: a topic-oriented evaluation, Journal of biomedical informatics",
            "year": 2009
        },
        {
            "authors": [
                "S. Bird",
                "E. Loper",
                "E. Klein"
            ],
            "title": "Natural Language Processing with Python, O'Reilly Media",
            "year": 2009
        },
        {
            "authors": [
                "P. Stenetorp",
                "S. Pyysalo",
                "G. Topi\u0107",
                "T. Ohta",
                "S. Ananiadou",
                "J.i. Tsujii"
            ],
            "title": "BRAT: a web-based tool for NLP-assisted text annotation",
            "venue": "in: Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics,",
            "year": 2012
        },
        {
            "authors": [
                "I. Boutron",
                "P. Ravaud"
            ],
            "title": "Misrepresentation and distortion of research in biomedical literature",
            "venue": "Proceedings of the National Academy of Sciences",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "While the PICO framework is widely used by clinicians for clinical question formulation when querying the medical literature, it does not have the expressiveness to explicitly capture medical findings based on any standard. In addition, findings extracted from the literature are represented as freetext, which is not amenable to computation. This research extends the PICO framework with Observation elements, which capture the observed effect that an Intervention has on an Outcome, forming Intervention-Observation-Outcome triplets. In addition, we present a framework to normalize Observation elements with respect to their significance and the direction of the effect, as well as a rule-based approach to perform the normalization of these attributes. Our method achieves macroaveraged F1 scores of 0.82 and 0.73 for identifying the significance and direction attributes, respectively."
        },
        {
            "heading": "Keywords",
            "text": "Natural Language Processing, Evidence-based Medicine, Text Mining"
        },
        {
            "heading": "Introduction",
            "text": "Evidence-Based Medicine (EBM) is the practice of using the best evidence to make decisions about the care of patients [1]. Unfortunately the large and ever-increasing amount of information available in the medical literature, the time required to read and synthesize the findings presented, and the hectic nature of clinical schedules are barriers to implementing EBM [2; 3]. Thus, it is imperative to improve the efficiency of the EBMdriven decision-making process, especially the processes of searching for and identifying the findings in medical literature.\nThe PICO framework has been widely adopted to explicitly formulate clinical questions and facilitate EBM [4]. PICO is an acronym for the components of the framework, which identifies the Population, Intervention, Comparator, and Outcome of interest.\nMuch of the prior work using PICO has focused on incorporating PICO into document retrieval [5-7] and automatic annotation of PICO elements in medical literature [8; 9]. PICO elements are further mapped to medical concepts using standardized vocabularies such as UMLS [10] and OMOP [11]. Recent work has been made to normalize composite treatments, such as HemOnc [12] to capture chemotherapy regimen information, as well as efforts to capture more general medication information such as dosage and frequency [13; 14]. The normalization of these more nuanced medical details is necessary to enhance the expressiveness and completeness of medical literature mining, as well as to enhance the capacities of the computational systems that rely on this information. While these combined efforts greatly improve the process of identifying relevant\nmedical evidence to a clinician\u2019s queries, they do not address the time-consuming process of reading and understanding the literature.\nThere have been both manual efforts\u2014such as UptoDate [15] and the Cochrane Collaboration [16]\u2014as well as automated efforts [17; 18] to capture and summarize the findings in medical literature; however they do not go beyond presenting the findings as free text. While this presentation is conducive to a human reader trying to make sense of a single article, it is not as useful for automated evidence synthesis and summarization of larger bodies of literature\u2014as there is no standard representation of the findings these articles present.\nThis research seeks to leverage the widespread use of PICO in order to represent and normalize the findings in the medical literature for use in medical evidence computation and synthesis. By adding Observation elements to the PICO framework\u2014 which capture the relationship between the treatments and the Outcome measure\u2014we enable it to represent medical findings as well as questions. As we have identified no prior work addressing this issue in this fashion, we also propose a normalization scheme to extract and normalize two attributes from the Observations: significance and the direction of the observed effect. Our contributions are two-fold: (1) we extend the PICO framework to include Observation elements to facilitate evidence computing tasks and (2) we implement and evaluate a framework to normalize Observation elements with respect to significance and the direction of the observed effect."
        },
        {
            "heading": "Methods",
            "text": ""
        },
        {
            "heading": "Observation Elements and Attributes",
            "text": "For the purposes of this study, we combine Intervention and Comparator classes, and will refer to them simply as Interventions. As described above, Observation elements represent the observed relationship between Interventions and the Outcome measure. For example, Figure 1 presents related Intervention, Observation, and Outcome elements from a snippet of text which form a medical finding. In this case, the treatment significantly increased the prevalence of \u201cgood results.\u201d We formulate \u201cfindings\u201d as the combination of related Intervention, Observation, and Outcome elements in the text.\nFor the Observation elements in these findings, we seek to categorize them with respect to two attributes: Significance and Clinical / Measurement Direction."
        },
        {
            "heading": "Significance",
            "text": "The Significance attribute of an Observation, as the name would suggest, captures if the finding in question was statistically significant. It takes one of three possible values: TRUE, FALSE, and N/A. TRUE/FALSE values for significance are used for significant/not significant findings respectively, while N/A is used for cases where no indication of significance is made. Examples from these three classes are included below, with the relevant context to determine the class label underlined.\nTRUE: \u201cBone-specific alkaline phosphatase decreased ( p < 0.05 ) \u2026\u201d [PID: 10993031]\nFALSE: \u201cNo significant difference was observed after 6 and 12 months of treatment in PEF variability\u201d [PID: 10741095]\nN/A: \u201cPEF variability improved in BDP and BDP + S groups\u201d [PID: 10741095]"
        },
        {
            "heading": "Clinical/Measurement Direction",
            "text": "The Clinical/Measurement Direction (referred to henceforth simply as Direction) captures the effect of the Intervention on the Outcome as presented in the text. It takes one of four possible values: UP, DOWN, CHANGE, UNKNOWN. Explanations of these categories as well as some examples are included below, with the relevant context to determine the class label underlined.\nUP: The UP category captures effects that are presented in terms of a positive numeric (e.g. an increase in some value) or clinical (e.g. an improvement in the patient\u2019s condition) effect\n\u201cgood results were significantly higher in the ketorolac-treated group\u201d [PID: 9001833]\n\u201cPEF variability improved in BDP and BDP + S groups\u201d [PID: 10741095]\nDOWN: The DOWN category captures the effects that are presented in terms of a negative numeric (e.g. a decrease in some value) or clinical (e.g. a worsening of the patient\u2019s condition) effect\n\u201cBone-specific alkaline phosphatase decreased ( p < 0.05 ) \u2026\u201d [PID: 10993031]\n\u201cstatistically significant , but clinically small , impairment of memory\u201d [PID: 11205419]\nCHANGE: The CHANGE category captures effects that are presented as differences between the groups in question, without specifying the nature of that difference\n\u201cThe difference in the median annual change between the two groups was significant (P=0.013)\u201d [PID: 10385063]\nUNKNOWN: The UNKNOWN category captures effects where the direction of the effect is not apparent from the text\n\u201cin a Cox model of overall survival , but the effect of cisplatin was not significant\u201d [PID: 8918486]"
        },
        {
            "heading": "Normalization Process",
            "text": "With the framework above, we present and evaluate the following rule-based method to determine the values for the different attributes. There are separate processes for the categorization of an Observation with respect to these attributes, the details of which can be found below."
        },
        {
            "heading": "Significance Normalization",
            "text": "In order to determine the value for the Significance attribute, we first employ regular expressions to scan the Observation and its immediate surrounding context, for indicators of significance such as explicit wording or p-values. If no indication of significance is detected, then the Observation is assigned to the N/A category.\nIf an indication of significance is present, then the Observation is checked for negations (e.g., \u201cno significant difference\u201d) if significance was indicated via explicit wording, and the TRUE/FALSE value is assigned accordingly. Alternatively, if significance was indicated with a p-value, then the process to determine significance is as follows. If the computed p-value is provided in the text (e.g., p = 0.0013), then we compare its value against the threshold of 0.05 to determine significance. If the p-value is given as greater than some value (e.g., p > 0.05), then the Observation is marked as non-significant and assigned the value FALSE for significance. Alternatively, if the p-value is presented as less than some value (e.g., p < 0.01) then the Observation is assigned the value TRUE."
        },
        {
            "heading": "Direction Normalization",
            "text": "We employ a string-matching approach to determine the Direction of a given Observation, using synonyms to improve coverage without having to specify every possible term. First, the Observation and its immediate context is scanned for negations (e.g. no significant difference), and if one is found the Observation is labelled UNKNOWN. Next, given a set of trigger words for the TRUE, FALSE, and CHANGE classes, we scan the Observation for matches to these terms and assign the observation to the corresponding category. For example, the UP class set of trigger words may include terms such as \u201cincrease\u201d or \u201cimprove,\u201d whereas the DOWN class trigger words would include \u201cdecrease\u201d or \u201cdeteriorate.\u201d\nIf no exact match is found, we then repeat the exact match search using synonyms of the terms in the trigger word sets. Word synonyms are determined using WordNet [19], and terms in the text are transformed to the form present in the WordNet database when possible. We use the WordNet implementation from the python NLTK package [20]."
        },
        {
            "heading": "Experiment Design and Evaluation",
            "text": "For the training set, 211 abstracts were pulled from PubMed and manually annotated for their PICO elements using the BRAT annotation tool [21]. We then generated \u201cfindings\u201d specified by Intervention-Observation-Outcome triplets as defined above; we took a sample of 150 of such triplets and manually labeled them for their Significance and Direction according to the class definitions provided above. For the testing set, we pulled an additional 50 abstracts and followed the same process to generate the \u201cfindings\u201d presented in them. We randomly selected 150 of these triplets and once again manually labeled them with respect to their Significance and Direction for use as a testing set. Two annotators determined the Significance and Direction; a sample of 20 \u201cfindings\u201d were used to establish inter-annotator agreement between two annotators. After this step, one annotator determined the labels for the training set while the other labeled the testing set. A\nbreakdown of the class distributions for the two attributes across the datasets can be found in Table 1. The training set was used to determine the Significance trigger phrases, as well as the candidate set of words for the Direction classes. We then evaluated the model using the testing set.\nWe formulate the task of determining the value for each attribute as a multi-class classification problem, and present the class-specific precision, recall, and F1 scores in Tables 2 and 3. In order to have an idea of the overall quality of the normalization performance, we also present the micro and macro-averaged values for each measure of interest, as the attributes have varying degrees of class imbalance across the datasets."
        },
        {
            "heading": "Results",
            "text": ""
        },
        {
            "heading": "Significance",
            "text": "The performance of the Significance attribute normalization process outlined above can be found in Table 2. Our approach achieves a macro-averaged F1 score of 0.82 on the testing set for this task. The F1 scores for the TRUE, FALSE, and N/A classes are 0.81, 0.78, and 0.85 respectively. While the performance metrics tend to be similar across the training and test sets, there is an observed degradation (-0.12) in the FALSE category\u2019s Recall as well as the N/A category\u2019s Precision (-0.11)."
        },
        {
            "heading": "Clinical/Measurement Direction",
            "text": "The performance of the Direction normalization process outlined in the earlier section can be found in Table 3. Our approach achieves an overall macro-averaged F1 score of 0.73 on this task. The macro-averaged F1 scores for the UP, DOWN, CHANGE, and UNKNOWN Direction classes were 0.83, 0.81, 0.62, and 0.65 respectively. Between the training and testing dataset we see drops in the recall of the UP class (-0.16), as well as improvements in the CHANGE class\u2019s precision (+0.22)."
        },
        {
            "heading": "Discussion",
            "text": ""
        },
        {
            "heading": "Error Analysis",
            "text": "Errors in determining the Significance come predominantly from limitations in the annotation of Observations rather than\nlimitations of the logic employed, and originate from disconnected spans of text comprising the \u2018full\u2019 Observation. Consider the examples below (the Intervention is italicized, the Outcome is underlined, and the annotated Observation is in bold)\nSignificant Doppler flow improvement was obtained in the L-arginine supplemented group [PID: 10402369]\nIn the CG, soccer training caused an improvement of smaller magnitude in 10m and shooting speed (p < 0.05). [PID: 30431535]\nIn both cases, the Direction component of the Observation is separate from the Significance component, but the annotation can only capture one of them. In the first example, due to the wording of the sentence the indicator of significance is separated from the Observation by the Outcome. In the second example the significance indicator is a p-value, but it is presented at the end of the sentence. For cases like the latter one it may be possible to have an additional step to assign un-marked p-values to the closest observation, but further analysis would be necessary to determine how this affects performance.\nWith respect to the observed drop in performance in the proposed rule-based method\u2019s on the FALSE category, we attribute this decrease in performance to an increase in the prevalence of cases similar to the ones mentioned above in the testing dataset. A performance shift can be expected as the training set only contains 15 FALSE Observations whereas the testing set contains 40 of them, bringing the performance more in line with the TRUE category.\nErrors in determining the Direction attribute arise both from the aforementioned limitation in the annotation as well as the lack of coverage in the class-specific trigger words. For example, the testing set has terms such as \u201calleviate\u201d and \u201cprolong,\u201d which are out of the scope of the synonyms generated from the training set. As mentioned in the results section, we observe an increase in the performance on the CHANGE class\u2019s precision. Our proposed method appears to have had difficulty differentiating CHANGE and UNKNOWN Observations; in the testing set 6/18 predicted CHANGE Observations were in fact UNKNOWN, and 8/21 of the CHANGE Observations were predicted to be UNKNOWN. The magnitude of the change in performance may also be due to the limited number of CHANGE examples in the original training set."
        },
        {
            "heading": "Limitations and Extensions",
            "text": "We recognize the limitations of our simple framework. Primarily, there is no distinction made between clinical findings and numerical ones. This is particularly relevant in cases where a clinical increase corresponds to a numeric decrease (e.g., blood pressure in hypertension patients). An improvement (UP) in such a patient\u2019s blood pressure corresponds to a decrease (DOWN) in the numeric value; assigning it to any of the UP/DOWN Direction categories results in a dissonance with the other type of finding. This issue also arises in the example provided earlier which describes improvements in PEF variability; an improvement actually corresponds to a decrease in some numeric value.\nThere is some ambiguity in this framework when it comes to representing negative findings\u2014findings that report the absence of an effect. Consider an intervention that is reported to operate \u201cwithout increasing the rate of complications.\u201d This finding would fall into the UNKNOWN category defined above because the actual effect on the outcome, if any, is not specified. However, it may be meaningful to capture the fact that this finding is presented in terms of an \u201cincrease in complications,\u201d even if it presents the absence of an increase. In the case of a noninferiority trial, this type of negative finding would be one of the main conclusions to draw from the text. For cases like this it may be better\u2014for interpretation\u2014to split up the Direction attribute into sub-components that capture the direction presented in the finding along with a negation.\nWe recommend further work on synthesizing propositions that operate on the same Intervention and Outcome to have a more complete understanding of the effect presented in the text. In the example below, the presented finding is a significant increase in the levels of peripheral leukocytes and lymphocytes.\n\u201cOver a 24-month observation period the immunized group always had higher levels of peripheral leukocytes and peripheral lymphocytes ; this difference was significant for the first 21 months.\u201d [PID: 8908288]\nIt is clear to a human reader that the \u201cdifference\u201d specified is in fact an increase, however with our current approach there would be two extracted findings (the observations for which are bolded): an increase of unspecified significance, and a significant change in the levels of the leukocytes and lymphocytes.\nWith respect to the normalization process, we recommend future work explore more robust statistical or computational approaches, such as neural networks, to determine the Direction attribute. While we do offset some of the brittleness of using a manually specified list of words by enriching it with synonyms, such an approach is not scalable to deal with the many possible ways to describe findings in medical literature."
        },
        {
            "heading": "Use Cases for Normalization",
            "text": "Suppose that a clinician is looking to compare the effectiveness of different interventions with respect to some outcome measure. With a PICO-based search, at best this provides them a list of potentially relevant studies that they would need to review manually. While available summaries of the relevant documents would help speed up this process, they do not address the issue of needing to sift through a potentially large volume of relevant articles. Making use of our approach to normalize findings, it would be possible to generate summary views of the literature as a whole, indicating for example that of the 15 relevant documents retrieved, 12 of them indicate a significant positive effect of the intervention on the outcome while the remaining three do not have significant findings. While the simplicity of the current framework somewhat limits its expressivity, it can assist in streamlining the evidence review portion of EBM.\nThis framework has uses beyond simply summarizing the literature. With a standard representation of \u201cfindings,\u201d it is possible to detect when there is a contradiction in the results of different studies. In addition, it has been noted that abstracts may report findings in a more positive light than in the main text of the article [22]; our approach can be extended to full-text articles to automatically identify such instances where the findings of a study are \u201cspun\u201d differently in the Abstract."
        },
        {
            "heading": "Conclusions",
            "text": "In this study, we propose a novel extension to the PICO framework: Observation elements which capture the effect of the Intervention on the Outcome, in order to extend the framework to more explicitly represent findings in the literature. In addition, we propose and evaluate a rule-based method to normalize these elements by capturing information about significance and the direction of the reported effect. We are able to achieve F1 scores of 0.82 and 0.73 for determining the Significance and Direction of medical findings respectively."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was supported by 5R01LM009886-11 (Bridging the semantic gap between research eligibility criteria and clinical data; PI: Weng). We thank Mathew Spotnitz, Konstantin Stojanovic, and Anna Ostropolets for helpful discussions."
        },
        {
            "heading": "Address for correspondence",
            "text": "Chunhua Weng, chunhua@columbia.edu. Department of Biomedical Informatics, Columbia University. PH-20, 622 W 168 ST, PH-20, New York, NY 10032, USA"
        }
    ],
    "title": "Extending PICO with Observation Normalization for Evidence Computing",
    "year": 2022
}