{
    "abstractText": "Background: N6, 2\u2019-O-dimethyladenosine (mAm) is an abundant RNA methylation modification on vertebrate mRNAs and is present in the transcription initiation region of mRNAs. It has recently been experimentally shown to be associated with several human disorders, including obesity genes, and stomach cancer, among others. As a result, N6,2\u2032-O-dimethyladenosine (mAm) site will play a crucial part in the regulation of RNA if it can be correctly identified. Results: This study proposes a novel deep learning-based mAm prediction model, EMDL_m6Am, which employs one-hot encoding to expressthe feature map of the RNA sequence and recognizes mAm sites by integrating different CNN models via stacking. Including DenseNet, Inflated Convolutional Network (DCNN) and Deep Multiscale Residual Network (MSRN), the sensitivity (Sn), specificity (Sp), accuracy (ACC), Mathews correlation coefficient (MCC) and area under the curve (AUC) of our model on the training data set reach 86.62%, 88.94%, 87.78%, 0.7590 and 0.8778, respectively, and the prediction results on the independent test set are as high as 82.25%, 79.72%, 80.98%, 0.6199, and 0.8211. Conclusions: In conclusion, the experimental results demonstrated that EMDL_ m6Am greatly improved the predictive performance of the mAm sites and could provide a valuable reference for the next part of the study. The source code and experimental data are available at: https:// github. com/ 13133 989982/ EMDLm6Am.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jianhua Jia"
        },
        {
            "affiliations": [],
            "name": "Zhangying Wei"
        },
        {
            "affiliations": [],
            "name": "Mingwei Sun"
        }
    ],
    "id": "SP:e22ba9a969058ea80442a1bee1080cde6e6b02a5",
    "references": [
        {
            "authors": [
                "P Boccaletto",
                "MA Machnicka",
                "E Purta",
                "P Pi\u0105tkowski",
                "B Bagi\u0144ski",
                "TK Wirecki"
            ],
            "title": "MODOMICS: a database of RNA modification pathways",
            "venue": "update. Nucl Acids Res",
            "year": 2017
        },
        {
            "authors": [
                "N Jonkhout",
                "J Tran",
                "MA Smith",
                "N Schonrock",
                "JS Mattick",
                "EM. Novoa"
            ],
            "title": "The RNA modification landscape in human disease",
            "venue": "RNA. 2017;23:1754\u201369. Page 19 of 20 Jia et al. BMC Bioinformatics",
            "year": 2017
        },
        {
            "authors": [
                "R Desrosiers",
                "K Friderici",
                "F. Rottman"
            ],
            "title": "Identification of methylated nucleosides in messenger RNA from Novikoff hepatoma cells",
            "venue": "Proc Natl Acad Sci USA",
            "year": 1974
        },
        {
            "authors": [
                "C Wei",
                "A Gershowitz",
                "N6 Moss B"
            ],
            "title": "O2\u2019-dimethyladenosine a novel methylated ribonucleoside next to the 5\u2019 terminal of animal cell and virus mRNAs",
            "year": 1975
        },
        {
            "authors": [
                "MS Ben-Haim",
                "Y Pinto",
                "S Moshitch-Moshkovitz",
                "V Hershkovitz",
                "N Kol",
                "T Diamant-Levi"
            ],
            "title": "Dynamic regulation of N6,2\u2032-Odimethyladenosine (m6Am) in obesity",
            "year": 2021
        },
        {
            "authors": [
                "S Schwartz",
                "MR Mumbach",
                "M Jovanovic",
                "T Wang",
                "K Maciag",
                "GG Bushkin"
            ],
            "title": "Perturbation of m6A writers reveals two distinct classes of mRNA methylation at internal and 5",
            "year": 2014
        },
        {
            "authors": [
                "D Benak",
                "F Kolar",
                "L Zhang",
                "Y Devaux",
                "M. Hlavackova"
            ],
            "title": "RNA modification m6Am: the role in cardiac biology",
            "year": 2023
        },
        {
            "authors": [
                "B Cesaro",
                "M Tarullo",
                "A. Fatica"
            ],
            "title": "Regulation of Gene Expression by m6Am RNA Modification",
            "venue": "Int J Mol Sci",
            "year": 2023
        },
        {
            "authors": [
                "G Fernandez Rodriguez",
                "B Cesaro",
                "A. Fatica"
            ],
            "title": "Multiple Roles of m6A RNA Modification in Translational Regulation in Cancer",
            "venue": "Int J Mol Sci",
            "year": 2022
        },
        {
            "authors": [
                "W Zhuo",
                "M Sun",
                "K Wang",
                "L Zhang",
                "K Li",
                "D Yi"
            ],
            "title": "m6Am methyltransferase PCIF1 is essential for aggressiveness of gastric cancer cells by inhibiting TM9SF1 mRNA translation",
            "venue": "Cell Discov. 2022;8:48",
            "year": 2022
        },
        {
            "authors": [
                "J Mauer",
                "X Luo",
                "A Blanjoie",
                "X Jiao",
                "AV Grozhik",
                "DP Patil"
            ],
            "title": "Reversible methylation of m6Am in the 5\u2032 cap controls mRNA",
            "year": 2017
        },
        {
            "authors": [
                "RR Pandey",
                "E Delfino",
                "D Homolka",
                "A Roithova",
                "K-M Chen",
                "L Li"
            ],
            "title": "The mammalian cap-specific m6Am RNA methyltransferase PCIF1 regulates transcript levels in mouse tissues",
            "year": 2020
        },
        {
            "authors": [
                "K Boulias",
                "D Toczyd\u0142owska-Socha",
                "BR Hawley",
                "N Liberman",
                "K Takashima",
                "S Zaccara"
            ],
            "title": "Identification of the m6Am methyltransferase PCIF1 reveals the location and functions of m6Am in the transcriptome",
            "venue": "Mol Cell. 2019;75:631-643.e8",
            "year": 2019
        },
        {
            "authors": [
                "S Akichika",
                "S Hirano",
                "Y Shichino",
                "T Suzuki",
                "H Nishimasu",
                "R Ishitani"
            ],
            "title": "Cap-specific terminal N 6-methylation of RNA by an RNA polymerase II-associated methyltransferase",
            "year": 2019
        },
        {
            "authors": [
                "Hawley BR",
                "Jaffrey SR"
            ],
            "title": "Transcriptome-wide mapping of m6 A and m6 Am at single-nucleotide resolution using miCLIP",
            "venue": "Curr Protoc Mol Biol",
            "year": 2019
        },
        {
            "authors": [
                "CWQ Koh",
                "YT Goh",
                "WSS. Goh"
            ],
            "title": "Atlas of quantitative single-base-resolution N6-methyl-adenine methylomes",
            "venue": "Nat Commun",
            "year": 2019
        },
        {
            "authors": [
                "H Sun",
                "K Li",
                "X Zhang",
                "J Liu",
                "M Zhang",
                "H Meng"
            ],
            "title": "m6Am-seq reveals the dynamic m6Am methylation in the human transcriptome",
            "year": 2021
        },
        {
            "authors": [
                "J Jiang",
                "B Song",
                "K Chen",
                "Z Lu",
                "R Rong",
                "Y Zhong"
            ],
            "title": "m6AmPred: Identifying RNA N6, 2\u2032-O-dimethyladenosine (m6Am) sites based on sequence-derived information",
            "year": 2022
        },
        {
            "authors": [
                "Z Song",
                "D Huang",
                "B Song",
                "K Chen",
                "Y Song",
                "G Liu"
            ],
            "title": "Attention-based multi-label neural networks for integrated prediction and interpretation of twelve widely occurring RNA",
            "year": 2021
        },
        {
            "authors": [
                "Z Luo",
                "W Su",
                "L Lou",
                "W Qiu",
                "X Xiao",
                "Z. Xu"
            ],
            "title": "DLm6Am: a deep-learning-based tool for identifying N6,2\u2032-O-dimethyladenosine sites in RNA",
            "year": 2022
        },
        {
            "authors": [
                "H Wang",
                "H Zhao",
                "Z Yan",
                "J Zhao",
                "J. Han"
            ],
            "title": "MDCAN-Lys: a model for predicting succinylation sites based on multilane dense convolutional attention Network",
            "year": 2021
        },
        {
            "authors": [
                "H Wang",
                "Z Yan",
                "D Liu",
                "H Zhao",
                "J. Zhao"
            ],
            "title": "MDC-Kace: a model for predicting lysine acetylation sites based on modular densely connected convolutional networks",
            "venue": "IEEE Access",
            "year": 2020
        },
        {
            "authors": [
                "M Niu",
                "Q Zou",
                "C. Lin"
            ],
            "title": "CRBPDL: Identification of circRNA-RBP interaction sites using an ensemble neural network approach",
            "venue": "PLoS Comput Biol",
            "year": 2022
        },
        {
            "authors": [
                "J Jia",
                "G Wu",
                "W. Qiu"
            ],
            "title": "pSuc-FFSEA: predicting lysine succinylation sites in proteins based on feature fusion and stacking ensemble algorithm",
            "venue": "Front Cell Dev Biol",
            "year": 2022
        },
        {
            "authors": [
                "W Li",
                "A. Godzik"
            ],
            "title": "Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences. Bioinformatics",
            "venue": "https:// doi. org/",
            "year": 2006
        },
        {
            "authors": [
                "W Chen",
                "H Tran",
                "Z Liang",
                "H Lin",
                "L. Zhang"
            ],
            "title": "Identification and analysis of the N6-methyladenosine in the Saccharomyces cerevisiae transcriptome",
            "year": 2015
        },
        {
            "authors": [
                "MU Rehman",
                "H Tayara",
                "KT. Chong"
            ],
            "title": "DL-M6A: identification of N6-methyladenosine sites in mammals using deep learning based on different encoding schemes",
            "year": 2022
        },
        {
            "authors": [
                "Bari ATMG",
                "Reaz MR",
                "Choi H-J",
                "Jeong B-S"
            ],
            "title": "DNA encoding for splice site prediction in large DNA sequence",
            "year": 2013
        },
        {
            "authors": [
                "H Yang",
                "H Lv",
                "H Ding",
                "W Chen",
                "H. Lin"
            ],
            "title": "iRNA-2OM: a sequence-based predictor for Identifying 2\u2019-O-Methylation sites in homo sapiens",
            "venue": "J Comput Biol",
            "year": 2018
        },
        {
            "authors": [
                "W Chen",
                "P Feng",
                "H Tang",
                "H Ding",
                "H. Lin"
            ],
            "title": "RAMPred: identifying the N1-methyladenosine sites in eukaryotic transcriptomes",
            "year": 2016
        },
        {
            "authors": [
                "W Chen",
                "H Tang",
                "H. Lin"
            ],
            "title": "MethyRNA: a web server for identification of N6-methyladenosine sites",
            "venue": "J Biomol Struct Dyn",
            "year": 2017
        },
        {
            "authors": [
                "G Huang",
                "Z Liu",
                "L van der Maaten",
                "KQ. Weinberger"
            ],
            "title": "Densely connected convolutional networks",
            "year": 2017
        },
        {
            "authors": [
                "J Jia",
                "G Wu",
                "M Li",
                "W. Qiu"
            ],
            "title": "pSuc-EDBAM: predicting lysine succinylation sites in proteins based on ensemble dense blocks and an attention",
            "year": 2022
        },
        {
            "authors": [
                "J Jia",
                "M Sun",
                "G Wu",
                "W Qiu"
            ],
            "title": "DeepDN_iGlu: prediction of lysine glutarylation sites based on attention residual learning method and DenseNet",
            "venue": "MBE",
            "year": 2023
        },
        {
            "authors": [
                "M Holschneider",
                "R Kronland-Martinet",
                "J Morlet",
                "Ph. Tchamitchian"
            ],
            "title": "A real-time algorithm for signal analysis with the help of the wavelet transform",
            "year": 1990
        },
        {
            "authors": [
                "T Ku",
                "Q Yang",
                "H. Zhang"
            ],
            "title": "Multilevel feature fusion dilated convolutional network for semantic segmentation",
            "venue": "Int J Adv Rob Syst. 2021. https:// doi",
            "year": 2021
        },
        {
            "authors": [
                "C Liu",
                "J Song",
                "H Ogata",
                "MSNet-4mC Akutsu T."
            ],
            "title": "learning effective multi-scale representations for identifying DNA N4-methylcytosine sites",
            "venue": "Bioinformatics. 2022:btac671. Page 20 of 20 Jia et al. BMC Bioinformatics",
            "year": 2023
        },
        {
            "authors": [
                "M Chaabane",
                "R Williams",
                "A Stephens",
                "J. Park"
            ],
            "title": "circDeep: deep learning approach for circular RNA classification from other long non-coding RNA",
            "venue": "Bioinformatics (Oxford,",
            "year": 2019
        },
        {
            "authors": [
                "Kha Q-H",
                "Ho Q-T",
                "Le NQK"
            ],
            "title": "Identifying SNARE proteins using an alignment-free method based on multiscan convolutional neural network and PSSM profiles",
            "venue": "J Chem Inf",
            "year": 2022
        },
        {
            "authors": [
                "Le NQK",
                "Ho Q-T",
                "Nguyen V-N",
                "Chang J-S"
            ],
            "title": "BERT-promoter: an improved sequence-based predictor of DNA promoter using BERT pre-trained model and SHAP feature selection",
            "year": 2022
        },
        {
            "authors": [
                "Wang C-Y",
                "Liao H-YM",
                "Wu Y-H",
                "Chen P-Y",
                "Hsieh J-W",
                "Yeh I-H"
            ],
            "title": "CSPNet: a new backbone that can enhance learning capability of CNN",
            "year": 2020
        },
        {
            "authors": [
                "Q Guan",
                "Y Wang",
                "B Ping",
                "D Li",
                "J Du",
                "Y Qin"
            ],
            "title": "Deep convolutional neural network VGG-16 model for differential diagnosing of papillary thyroid carcinomas in cytological images: a pilot study",
            "venue": "J Cancer",
            "year": 2019
        },
        {
            "authors": [
                "K He",
                "X Zhang",
                "S Ren",
                "J. Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "year": 2016
        },
        {
            "authors": [
                "J Xiao",
                "J Wang",
                "S Cao",
                "B. Li"
            ],
            "title": "Application of a novel and improved VGG-19 network in the detection of workers wearing masks",
            "venue": "J Phys Conf Ser. 2020;1518:012041",
            "year": 2041
        },
        {
            "authors": [
                "V Vacic",
                "LM Iakoucheva",
                "P. Radivojac"
            ],
            "title": "Two sample logo: a graphical representation of the differences between two sets of sequence",
            "venue": "alignments. Bioinformatics",
            "year": 2006
        }
    ],
    "sections": [
        {
            "text": "\u00a9 The Author(s) 2023. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\nResults: This study proposes a novel deep learning-based m6Am prediction model, EMDL_m6Am, which employs one-hot encoding to expressthe feature map of the RNA sequence and recognizes m6Am sites by integrating different CNN models via stacking. Including DenseNet, Inflated Convolutional Network (DCNN) and Deep Multiscale Residual Network (MSRN), the sensitivity (Sn), specificity (Sp), accuracy (ACC), Mathews correlation coefficient (MCC) and area under the curve (AUC) of our model on the training data set reach 86.62%, 88.94%, 87.78%, 0.7590 and 0.8778, respectively, and the prediction results on the independent test set are as high as 82.25%, 79.72%, 80.98%, 0.6199, and 0.8211.\nConclusions: In conclusion, the experimental results demonstrated that EMDL_ m6Am greatly improved the predictive performance of the m6Am sites and could provide a valuable reference for the next part of the study. The source code and experimental data are available at: https:// github. com/ 13133 989982/ EMDL- m6Am. Keywords: m6Am site identification, Stacking, Deep learning, DenseNet, DCNN, MSRN\nIntroduction In recent years, dynamic epigenetic changes of RNA have drawn considerable attention in biological study. There are already more than 160 different forms of RNA modifications known [1]. According to reports, the majority of RNA modification enzyme mutations have an important role in the emergence of human disorders [2]. In rat messenger RNA (mRNA), the N6-methyladenosine (m6A) modifications were discovered [3], while N6-2\u2032-O-methyladenosine (m6Am) alterations were discovered shortly [4]. One of the most prevalent post-transcriptional modifications of mRNA is N6,2\u2032-O-methyladenosine\n*Correspondence: jjh163yx@163.com; weizy5003@163.com\n1 School of Information Engineering, Jingdezhen Ceramic University, Jingdezhen 333403, China\n(m6Am), which was found on the second base of the modification close to the m7G cap [4]. In the meantime, m6Am, a terminal alteration generally 2\u2032-O-methylated at the second base close to the 50 cap in mRNA, together with further methylation at the N6 position, has just recently been Identified as a promising target for FTO removal from the human obesity gene [5], associated with obesity [6].\nThrough the experimental studies, researchers have been able to uncover more and more hidden characteristics of m6Am. Recent research has gradually revealed the importance of m6Am in biological functions, including in the field of cardiac biology [7] research, gene expression regulation [8], tumor development, and more [9]. For example, PCIF1 and m6Am were experimentally proven to be essential in the development of gastric cancer by Zhuo et\u00a0al. [10]. The progression of gastric cancer is accelerated by increased methyltransferases driven by m6Am methylation changes (PCIF1). By providing resistance to DCP2-mediated mRNA capping, M6Am confers mRNA [11]. Furthermore,\u00a0 m6Am may also control other processes involving the metabolism of RNA. The experimental findings of Jan Mauer et\u00a0 al. [11] demonstrated that m6Am plays a significant role in the stability [11\u201313] and translation [14] function of mRNA. Overall, research on m6Am\u2019s biological effects is still in its early stages, and its primary functions are yet unknown. There are numerous wet-lab experimentation techniques available. As an illustration, Hawley et\u00a0al. [15] developed miCLIP, a mapping of m6A and m6Am at single nucleotide precision, to find the m6Am sites. Additionally, m6ACE-seq was introduced by Koh et\u00a0al. [16] to statistically map m6A and m6Am across the transcriptome. There is also the MeRIP-seq (m6A-seq), which has limited resolution, antibody cross-reactivity, and inability to differentiate between cap-m6Am and m6A in 50 RNA fragments.\nMany other researchers are still striving to find m6Am sites\u00a0 using wet experimental approaches nowadays, including\u00a0Sun et\u00a0al. [17], they used antibodies to m6Am to recognize m6Am, but there was a limitation that they cannot precisely distinguish between m6Am and 5\u2032-UTR m6A.\u00a0Because the existing wet experimental techniques are expensive and time-consuming, it is vital to develop new computational methods for the exact identification of m6Am sites.\nDespite the fact that prediction of m6Am sites have not been studied for a long time, a number of prediction techniques have been developed. The first one bases its prediction identification on conventional machine learning model. Based on RNA sequence and employing electron\u2013ion interaction and pseudo-EIIP (PseEIIP) coding to predict sites, Jiang et\u00a0al. [18] developed a predictor called m6AmPred, and the team continued to identify m6Am sites computationally using deep learning algorithms with proposing a new predictor called MultiRM [19]. As deep learning framework, based on the LSTMattention mechanism combined with Word2vec embedding module, can perform multitag prediction, including prediction of m6A, m6Am, and other 12 RNA modification sites with powerful features.\nRecently, Luo et\u00a0al. [20] used a different coding approach and model than Jiang to predict m6Am. They used three coding approaches\u2014one-hot coding, nucleotide chemical properties, and nucleotide density\u2014as well as three base classifiers\u2014multi-headed attention, two parallel embedding modules, CNN and BiLSTM, and a prediction module for m6Am sites. As a whole, the computational identification of m6Am sites has made\nsome strides, that the algorithms now in use can predict m6Am sites with a high level of performance and accuracy. However, there is still a lot that can be done to increase the precision of these predictors for m6Am sites identification.\nBased on the above-mentioned consideration, we propose EMDL_m6Am, a stacking ensemble deep learning model, in response to the current mission of identifying m6Am sites. It ismotivated by those m6Am data and the certain sites prediction models. The whole flowchart is displayed in Fig.\u00a0 1. The model consists of an encoding module for features and a feature extraction module. The raw data is initially encoded in one step. Then, three deep learning models\u2014A, B, and C\u2014are divided up into the feature extraction module, and stacking integration is added later. Conv1D is for a one-dimensional convolutional layer. Avepooling1D stands for an average pooling layer, a fully connected layer is denoted Dense for, and BN for batch normalization.\nAs shown in Fig.\u00a01, first, we attempted to use a number of popular RNA sequence coding techniques, such as one-hot, nucleotide chemical property (NCP), and nucleotide density (ND), both singly and in combination. Through the prediction performance obtained from the experiment, we finally selected the most straightforward, effective coding technique, one-hot, for RNA sequence coding. Second, we examined the performance of different deep learning predictors, including: DenseNet [21, 22], Inflated Convolutional Network and Deep Multiscale Residual Network(MSRN) [23] and Bidirectional gating recurrent unit (BiGRU), and got some inspirations from them. Through carefully testing, we discovered that the DenseNet network based on one-hot encoding performs well. DenseNet still has drawbacks when compared with the currently state-of-the-art predictor DLm6Am, though.\nHence, giving that the performance gaps amongst the three deep learning classifiers are not very large, we built a stacking ensemble deep learning model and used a straightforward logistic regression model for prediction in the second layer of stacking. Three deep learning models are employed in the first layer of stacking to forecast the original data to obtain the prediction results, and the second layer filters the first layer\u2019s prediction outcomes. Notably, we optimized the input of the second layer of the stacking model in this work, i.e., the output values of the first layer were stitched with the original dataset to serve as the input of the second layer, in order to avoid losing the original feature map information, which was inspired by the stacking prediction model from Jia et\u00a0al. [24]. Finally, the code is obtainable in the Github repository (https:// github. com/ 13133 989982/ EMDL- m6Am)."
        },
        {
            "heading": "Materials and\u00a0methods",
            "text": ""
        },
        {
            "heading": "Benchmark dataset",
            "text": "Lately, Sun et\u00a0al. [17] proposed a new sequencing approach, m6Am-seq, which can effectively distinguish m6Am from m6A using RNA immunoprecipitation and selective external demethylation. From this, they used this sequencing approach to provide 2166 m6Am sites in the entire human transcriptome at mononuclear resolution with a high confidence level for these sites. Subsequently, luo et\u00a0al. [20] did a three-step process on the sites information provided by m6Am-seq: first, a sample sequence was extracted using a sliding window of (2\u03b4 + 1)\u2212 nt, as shown in Eq.\u00a0(1), and a sequence can be displayed as:\nwhereas in BCA (B = C, G, or U) motifs, K stands for the nucleotide adenosine and A for the nucleotide next to K. The distance between each nucleotide and the central site K is indicated by the subscript, with A_(\u2212\u03b4) standing for the \u03b4-th upriver nucleotide from the middle, A_(+\u03b4) denoting the \u03b4-th downriver nucleotide from the center, and so on. In this study, the \u03b4 value was configured for 20. The sequence fragment is regarded as a positive sample if the m6Am site is in the middle of it; otherwise, it is a negative sample. Secondly, sequences with more than 80% similarity were removed using the redundancy removal tool CD-HIT [25], Finally, negative samples were chosen at random in a 1:1 ratio to create the ultimate benchmark dataset, from which 80% of the samples were chosen as the training set and the residual 20% as the independent test set. The dataset used in our work is from the dataset created in three steps by Luo et\u00a0al. and we did not do additional processing on their dataset. The size of the dataset used is shown in Table\u00a01, the training set contains 1419 positive samples and 1419 negative samples, and the test set has 355 positive samples and 355 negative samples. The ratio of positive to negative samples is 1:1 in both sets of data.\n(1)f\u03b4(K ) = A\u2212\u03b4A\u2212(\u03b4\u22121) \u00b7 \u00b7 \u00b7A\u22122A\u22121KA+1A+2 \u00b7 \u00b7 \u00b7A+(\u03b4\u22121)A+\u03b4"
        },
        {
            "heading": "Dataset Positive Negative",
            "text": ""
        },
        {
            "heading": "Feature extraction methods",
            "text": "Use of an appropriate sequence coding approach is essential for site identification. Researchers have created a number of feature encoding techniques to express RNA sequences with numerical vectors since the input of the majority of models is a numerical vector. As an illustration, we consider the encoding based on the structural or sequence information. In this research, we employ three of the most well-applied coding techniques at present, including one-hot, NCP, and ND [26, 27]."
        },
        {
            "heading": "One hot encoding",
            "text": "One-hot coding is one of the most prevalent coding techniques and is well-liked by scientists since it can effectively and simply represent nucleotide sequences. The four nucleotides A (adenine), C (cytosine), G (guanine), and U (uracil) are typically denoted by (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0) and (0, 0, 0, 1), accordingly.\nTherefore, a nucleotide sequence of length L = 41 is represented in this study as a 41 \u00d7 4 two-dimensional matrix, where all matrix elements are 0 and 1.\nNucleotide chemical property (NCP) and\u00a0nucleotide density (ND)) The chemical characteristics of nucleotides (NCP), which was proposed by Bari et\u00a0 al. [28], based on the construction of chemical structures of nucleotides, have been used in many recent investigations [29\u201331].\n1. The nucleotides are classified into these two categories based on the various ring configurations. As purines, A and G are represented by the number 1, whereas pyrimidines, C and U, are denoted by the number 0. 2. According to their chemical functions, nucleotides are separated into two groups: those representing amino groups, designated by the number 1, such as the nucleotides A and C, and those representing keto groups, denoted by the number 0, such as the nucleotides G and U. 3. Based on the different strengths of the hydrogen bond interactions between base pairs, the nucleotides are divided into two groups. One party comprised the strong interactions and is represented by 1, which is A and U, while the other group represents the weak interactions and is represented by 0, which is G and C.\nIn this way, each nucleotide is represented by the following three-dimensional vector.\nwhere xi = { 1, Hi \u2208 {A,G} 0, Hi \u2208 {C ,U} denotes the ring structures, yi = 1, Hi \u2208 {A,G} 0, Hi \u2208 {G,U} indicates the chemical efficiency, zi = {\n1, Hi \u2208 {A,U} 0, Hi \u2208 {C ,G} represents the interaction strength\nof hydrogen bonds. The frequency and location distribution information of each nucleotide can be displayed in the nucleotide density (ND). The density (di) of a nucleotide can be calculated as di = n/i, where n is the number of times the nucleotide appears before the i-th position\n(2)Hi = ( xi, yi, zi )\n(including the i-th position). For example, the density of A for the sequence \"AGT AUU CA\" is 1, 0.50, and 0.375 in the first, fourth, and eighth bits, respectively. Likewise, U is 0.20, 0.33 for positions 5 and 6, respectively, etc.\nCombining the chemical properties and density of nucleotides for encoding, then each nucleotide can be encoded as a four-dimensional vector shown in Eq.\u00a0(3).\nwhere l stands for the sequence\u2019s length. Each sequence data of length 41 nt can be encoded as a two-dimensional numerical matrix of 41 \u00d7 4."
        },
        {
            "heading": "Classification model",
            "text": "It is necessary to select the right model in order to correctly anticipate the m6Am sites. As the main network structure in this study, three deep learning models were selected, and stacking was then employed to integrate them for site prediction."
        },
        {
            "heading": "DenseNet and\u00a0attention",
            "text": ""
        },
        {
            "heading": "DenseNet",
            "text": "Considering the DenseNet [32], a dense connectivity technique, each network layer is connected to the next by a feedforward connection that transfers data across layers. In order to prevent model overfitting, the gradient disappearance problem is effectively addressed, feature propagation is enhanced, feature reuse is promoted, and the number of parameters is drastically reduced. It has been demonstrated that DenseNet outperforms conventional CNNs because it focuses on both low-level and high-level feature information based on a dense hopping connection mechanism to satisfy the goal of mutual and complementary information transfer. Figure\u00a02 shows the connecting mechanism.\nWang et\u00a0al. [21] employed DenseNet to predict Lysine Acetylation Sites and achieved great performance. Jia et\u00a0al. [33] successfully implemented the lysine succinylation sites prediction in the DenseNet network in while utilizing an attention module to assess the significance of various feature information. As a result, we were motivated to use the\n(3)Ni = { xi, yi, zi, di } (i = 1, 2, 3, . . . l)\nmodel\u2019s denseblock module to record feature data at various levels. The output of all the preceding layers is passed on to the next layer as input by each layer in the DenseNet. Therefore, L(L + 1)/2 connections exist across all layers of a DenseNet with X layers. In other words, Eq.\u00a0(4) represents the output of the network\u2019s L-th layer.\nwhere H(\u2219) stands for the non-linear transformation function and eLU and conv1D are included."
        },
        {
            "heading": "SENet",
            "text": "We investigated incorporating attention mechanisms into the model to help the model learn crucial feature knowledge in the principle of earlier studies [21, 34]. We investigated the individual and joint impacts of channel attention, spatial attention, and Squeeze-and-Excitation Networks (SENet). For instance, adding channel attention at the end of the dense net output and adding SENet attention after each dense block inside the DenseNet constitute the combined application of the attention mechanism. The best results, according to ablation investigations, came from applying compressed attention by itself.\nSince the attention layer is directly related to the input matrix, it is important to note that we introduced it before DenseNet. This helps the model pay attention to the underlying data and supports the identification of critical location information to avoid distraction. The results of the experiment showed how valuable an attention layer like this is for improving the accuracy of model predictions.To increase the weight of important information and sharpen the attention on it, SENet is added concurrently after each denseblock to the feature map information output. The standard implementation of SENet looks like this.First, the input feature map is initially subjected to globelAvgPooling, which results in the feature map\u2019s spatial dimension being compressed. Second, to reduce dimensionality and suit the correlation between channels, a fully connected operation is performed on the compressed feature map.Next, the compressed feature map is connected in its entirety. The downscaled feature map is upscaled in the third phase such that Sigmoid can be used to obtain the normalized weights between 0 and 1.Finally, to create the final feature map weighting, the normalized weights are added to the features of each channel.\nSpecially, this study\u2019s SENet is a modified version of the original SENet. In order to achieve feature map information weighting while reusing the original feature map to prevent information loss, the concept of residual network was specifically used to add the original feature map to the matrix created after compression."
        },
        {
            "heading": "DCNN and\u00a0BiLSTM",
            "text": "Holschneider et\u00a0al. [35] initially announced dilation convolution, which added intervals to conventional convolution [36] while maintaining the resolution of the feature map. In contrast to standard convolution, dilation convolution contains an additional parameter called the dilation rate, which is primarily used to describe the size of the dilation. It is a normal convolution when the dilation rate is 1.\n(4)xi = Hi([x0, x1, . . . , xi\u22121])\nWang et\u00a0al. [23] developed the integrated multiscale deep learning predictor EMDLP, which combined inflated convolutional neural network (DCNN) with BiLSTM for the prediction of RNA methylation. Shortly after, Liu et\u00a0 al. [37] proposed MSNet-4mC, which combined residual network concepts to identify 4mC loci and used DCNN to extract feature map data at various scales. We adapted the joint application of DCNN and BiLSTM to the loci prediction of m6Am after being encouraged by the prior studies. Starting with sequence data, the learning function f(x) of m6Am divides into four segments: one-hot encoding, dilated convolution to extract features, splicing feature map, and extracting contextual information using BiLSTM as shown in Eq.\u00a0(5).\nThe formula for the dilated convolution in a one-dimensional circumstance is given in Eq.\u00a0 (6). Different dilution rates can be thought of as adding different of blank gaps among each convolution kernel.\nwhere xi\u00a0is the i-th input item, yi\u00a0is the i-th DCNN array\u2019s output, \u03c9\u00a0is the filter\u2019s weight, N is the filter\u2019s longer, and k\u00a0is referred to by the dilution rates (DR).\nThe dilution rate for each of the three blocks of DCNNs in the DCNN stage is 1, 2, and 3, the information of the feature map is learned from three different sensory fields. And, each DCNN block consists of a max-pooling layer with a dropout unit, a dilated convolutional layer with the rectified linear unit (ReLU) as its active function, and a dilated convolutional layer."
        },
        {
            "heading": "MSRN and\u00a0BiGRU",
            "text": "To find the circRNA-RBP interaction locations, Niu et\u00a0 al. [23] employed a deep multiscale residual network and a network made up of BiGRU\u00a0with a self-attention mechanism. Both MSRN and BiGRU can effectively represent high-level features and are competent at learning local and global contextual information. Thus, aiming at predicting the m6Am sites, we attempted to cascade multiple CNNs of various scales and use them in conjunction with BiGRU. The residuals are introduced in the CNN cascade to ensure that important feature map features are not lost during the convolution phase. So as to prevent information loss, the model also includes BiGRU, which handles the longterm dependencies of the sequences and maintains important aspects utilizing a range of gating functions.\nFirst, we extracted features from a one-hot encoded feature map using six cascaded multi-scale residual blocks (MSRBs), each of which consists of three convolutional layers and 64 convolutional kernels.The output of each MSRB is then integrated to produce global feature fusion. A further 1D convolution and average pooling procedure is then carried out with 192 convolution filters.\nSecond, to improve the recognition performance of the model and to make up for the fact that the multiscale residual network can only extract sequence correlation\n(5)h = f (x) = fBiLSTM ( fconcat ( fDCNN ( fone-hot-encoding (x) )))\n(6)yi = f\n(\nN \u2211 n=1 xi+k\u2217n\u03c9n + b\n)\nand not context-linked information, the output of the deep multiscale residual network is fed into BiGRU to obtain contextual information [38]."
        },
        {
            "heading": "Stacking ensemble",
            "text": "In general, a prediction task will produce the different prediction outcomes in distinct predictors. Ensemble learning can combine numerous classifiers to obtain the prediction results that are superior to those by a single classifier. Among them, stacking is a key data science technique that depends on the outcomes of numerous models. By the stacking approach, the prediction outcomes of various models are trained once again as features, and the resulting prediction consequences frequently beat those of a single strong model.\nDenseNet, DCNN, and MSRN were the three classifiers we intended to use in this study as the basic classifiers in the first layer. In particular, in order to prevent the information loss and overfitting, the outputs of the first-layer\u2019s three classifiers were mixed with the original dataset as the input for the second-layer\u2019s classifier. Here, the second-layer classifier that we used was a straightforward logistic regression model. Figure\u00a03 displays the structural framework of the stacking ensemble model."
        },
        {
            "heading": "Performance evaluation",
            "text": "The foundation for evaluating the effectiveness of various models is the employment of common and scientific measures. The following four metrics are commonly used to predict performance for binary classification problems [39, 40] in general machine learning, as represented by the following metric equations:\nwhere respectively, TP, TN, FP, and FN stand for the quantity of incorrect predictions in the positive classification, the quantity of incorrect predictions in the negative classification, the number of accurate predictions in the positive category, and the number of correct predictions in the negative category. In addition, the model\u2019s efficiency is often evaluated using the area under the receiver operating characteristic curve (AUROC) and the area under the precision and recall curves (AUPR)."
        },
        {
            "heading": "Result and\u00a0discussion",
            "text": "Contrasting various feature extraction techniques Regarding our experiments in the feature extraction section, we use the three feature encoding techniques one-hot, NCP, and ND. The majority of studies [15, 18, 20] use NCP in conjunction with ND. There are three possible combinations in this manner: one-hot alone, NCP and ND combined, and one-hot and NCP, ND combined. As indicated in Tables\u00a0 2 and 3, we compare the performance of different feature extraction approaches by performing fivefold cross-validation on the training set and independent tests on the test set, where the best predicted results are shown in bold.\nWe used one-hot coding as the only coding method for RNA sequence data as the model input data, because Tables\u00a0 2 and 3 show that when one-hot coding alone was used as the feature coding method, and the important evaluation indexes like Sn, Sp, ACC in cross-validation and independent testing were higher than other individual or combined coding methods.\nThe best experimental results are shown in bold\nOne hot 86.62 \u00b1 0.11 88.94 \u00b1 0.09 87.78 \u00b1 0.09 0.7590 \u00b1 0.1725 0.8778 \u00b1 0.0878 0.8428 \u00b1 0.1078 NCP and ND 84.64 \u00b1 0.08 84.29 \u00b1 0.07 84.47 \u00b1 0.07 0.6908 \u00b1 0.1294 0.8447 \u00b1 0.0654 0.7948 \u00b1 0.0756 One-hot, NCP and ND 84.08 \u00b1 0.07 85.06 \u00b1 0.07 84.57 \u00b1 0.06 0.6928 \u00b1 0.1209 0.8457 \u00b1 0.0609 0.7977 \u00b1 0.0738"
        },
        {
            "heading": "Encoding methods Sn (%) Sp (%) ACC (%) MCC AUC AUR",
            "text": ""
        },
        {
            "heading": "Comparison of\u00a0models with\u00a0different denseblocks",
            "text": "The parameters of the predictor are optimized in DenseNet by setting different numbers of denseblocksand the performance of the model is compared by ACC and MCC values. It can be clearly seen in Fig.\u00a04 that the predictor performs best when DenseNet picks 6denseblocks.\nModel architecture ablation experiment When choosing models, ablation studies were carried out to evaluate which of the three models\u2014or which conjunction of the three\u2014performed better. Table\u00a04 and Fig.\u00a05 display the predictions made by the three deep learning models alone and in conjunction. Similar to Table\u00a0 4, the mark \"\u221a\" in the row of every deep learning model denotes the model\u2019s selection for this study; meanwhile, the absence of mark \"\u221a\" (i.e. blank)\u2014denotes the unselecting of the prediction model.\nTable\u00a0 4 and Fig.\u00a0 5 clearly show that when employing stacking to combine the three deep models DenseNet, DCNN, and MSRN, ACC and MCC for the model were greater than those of the other cases on the train and test sets. Therefore, to extract features from the original data and forecast the m6Am sites in this study, we integrated DenseNet, DCNN, and MSRN using stacking."
        },
        {
            "heading": "Comparative analysis of\u00a0other models",
            "text": "We compared the performance of EMDL_m6Am with a number of representative models, including the conventional machine learning model SVM, XGBoost and\u00a0 the deep learning model CNN and BiLSTM. The results of the fivefold cross-validation of various models on the training set were shown in Fig.\u00a06. This demonstrated that the deep learning model outperformed machine learning in the extraction of features from huge datasets. Additionally, it was clear that EMDL_m6Am exceeds other models in terms of accuracy when predicting the m6Am sites.\nTo assess the prediction performance of EMDL_m6Am, we alse compared EMDL_ m6Am with several advanced models for analysis, including: Cross Stage Partial DenseNet (CSPNet) [41], VGG-16 [42], ResNet [43], VGG-19 [44], Inception V3. These models performed differently on the independent test set, as shown in Table\u00a05. Among them, VGG-16 scored the highest in Sn, but the Sp score was too low, lost the balance between Sn and Sp, and had too much deviation for high prediction accuracy. In contrast, our model EMDL_m6Am achieved a balance between Sn and Sp with a deviation of less than 2.25%, and obtained the highest Sp, MCC, Acc, AUC, AUPR, Pre, and F1 scores among several models, yielding the best prediction results overall. To clearly demonstrate the superiority of EMDL_m6Am, we plotted Fig.\u00a07 to show the performance of several models."
        },
        {
            "heading": "Predictor Sn Sp ACC MCC AUC AUPR",
            "text": "We even farther confirmed the effectiveness of EMDL_m6Am by contrasting it with other present predictors for predicting m6Am sites in RNA sequences, including MultiRM, m6AmPred, and DLm6Am. The four models all used the same dataset to ensure the validity of the experimental comparison. Tables\u00a06 and 7 presented the findings of the fivefold cross-validation of the four models on the training and test sets. It was evident that EMDL_m6Am had significantly better prediction performance on the training set than the other three models, and that it had 7% more Sn, 10% more Sp, 7%\u20138% more ACC, and 7%\u20138% more MCC than the most recent model, DLm6Am. When used to balanced datasets, AUPR is less accurate and is less effective and informative for dichotomizing since it is susceptible to sample distribution. Table\u00a07 showed that EMDL_m6Am performed better than the other three models on the independent test set, which also indicated that EMDL_m6Am had good generalization ability. A direct viewing comparison of the two predictors was shown in Fig.\u00a08. This demonstrated that EMDL_m6Am outperformed the current state-ofthe-art model DLm6Am."
        },
        {
            "heading": "Predictor Sn Sp ACC MCC AUC AUPR",
            "text": "To test the robustness of the model and to evaluate the performance of the model on unbalanced datasets, we used the full transcript dataset and the mature RNA dataset from m6AmPred [18] on m6Am. It is worth noting that we used the original unbalanced dataset, in which the full transcript dataset contains 2447 positive samples and the mature RNA dataset includes 1673 positive samples, with the ratio of positive to negative samples being 1:4. The full transcript dataset and the mature RNA dataset were randomly divided into a training set and a test set in the ratio of 8:2. Our model EMDL_ m6Am without any non-equilibrium processing on the dataset, only used the network framework structure of the model for feature extraction and weight assignment to get the final prediction results. Finally, the comparison of the results of EMDL_m6Am and m6AmPred on the two datasets was shown in Table\u00a08.\nAs shown in Table\u00a08, on the full transcript dataset, the Sn, ACC and MCC values of EMDL_m6Am were higher than those of m6AmPred, and only the Sp values were all slightly lower than it. The same was true on the mature RNA dataset. Collectively, our model EMDL_m6Am outperformed m6AmPred, and also illustrated that EMDL_m6Am performed equally well on the unbalanced dataset with good generalization ability.\nIn order to verify the robustness of EMDL_m6Am, we randomly selected negative samples several times to conduct five tenfold cross-validation experiments. The results of the experiments were shown in Fig.\u00a09, and the results of the five tenfold cross-validation experiments were similar without too much difference. This indicated that EMDL_ m6Am had stable experimental results for selecting different sets of negative samples."
        },
        {
            "heading": "Dataset Methods Sn Sp ACC MCC",
            "text": "Sequence analysis of\u00a0 m6Am sites and\u00a0T\u2011SNE visualization of\u00a0EMDL_m6Am In this study, we explored the frequency of occurrence of 40 nucleotide bases around the m6Am site on RNA sequences to find potential consensus motifs for the sequences. We used an efficient tool, TWO Sample Logo [45], to discover position-specific sign composition differences at the m6Am site. In this study, adenine (A) is at the center of the RNA sequence fragment with 20 nucleotides both before and after it. The experimental results were shown in Fig.\u00a0 10. Nucleotides such as C(cytosine) and U(uracil) were highly represented near both m6Am site and nonm6Am site, and both appeared in the left position, which was common to both. However, the frequencies and positions of nucleotides at other positions of m6Am site and non-m6Am site were different, for example, G (guanine), C (cytosine) and U (uracil) were in high proportions near the right side of m6Am site. The frequencies of each nucleotide at the front end of the sequence and the back end of the sequence of non-m6Am site were similar to the extent that their expression was not obvious. Such analysis indicated that the distances and frequencies between different nucleotides in the sequence played a crucial role in distinguishing m6Am sites from nonm6Am sites.\nIn addition, we used t-distributed stochastic neighbor embedding (t-SNE) to visualize the two data features. One wasthe projection of the features by one-hot coding\nof the original training data (Fig.\u00a0 11a); The other was the total feature projection into two-dimensional space after stitching the important features learned by EMDL_ m6Am (3 dimensions) and the original training data one hot encoded features (41*5 dimensions) (Fig.\u00a011b). As can be seen from the Fig.\u00a011, when no prediction is made using EMDL_m6Am, it is not possible to distinguish between positive and negative samples. Conversely, the separation boundary between m6Am sites (red data points) and non-m6Am sites (blue data points) is very clear after extracting significant features using the three models, which indicates that the proposed EMDL_m6Am has high predictive performance."
        },
        {
            "heading": "Conclusions",
            "text": "M6Am plays a key role in the regulation of RNA and in the identification and treatment of obesity genes and some cancers, therefore, it is crucial to develop predictors that can help detect m6Am sites. In this work, we proposed a new predictor, EMDL_m6Am, by stacking three deep learning models together to perform m6Am site detection in RNA sequences. It has several advantages over previous studies such as (1) EMDL_m6Am does not need to contain a complex feature extraction process like traditional machine learning, it feature coding is simple and advanced feature extraction is done by the model framework. (2) Traditional CNN cannot extract complex features, in this study, we take an ensemble approach by stacking three powerful deep learning models to extract useful features from different dimensions. Also, we compared multiple traditional machine learning models, advanced deep learning models, and different predictors to highlight the predictive performance of EMDL_m6Am.\nIn addition, EMDL_m6Am may help to predict other more RNA post-modification sites as a way to discover their novel functions. In future studies, it may be possible to eliminate some of the modules with overlapping functions in the three models to simplify the models, or to explore some of the RNA post-modification sites with unspecified functions.\nAbbreviations m6Am N6,2\u2032-O-methyladenosine CNN Convolutional neural network DenseNet Dense convolutional network DCNN Inflated convolutional network MSRN Deep multiscale residual network Sn Sensitivity Sp Specificity ACC Accuracy MCC Mathew correlation coefficient ROC Receiver operating characteristics AUC Area under ROC curve PseEIIP Pseudo-EIIP NCP Nucleotide chemical property ND Nucleotide density BiGRU Bidirectional gating recurrent unit SENet Squeeze-and-excitation networks LSTM Long short-term memory BiLSTM Bidirectional long short-term memory ReLU Rectified linear unit MSRBs Multi-scale residual blocks TP True positive TN True negative FP False positive FN False negative AUPR The precision and recall curves AUROC The area under the receiver operating characteristic curve XGBoost Extreme gradient boosting t-SNE T-distributed stochastic neighbor embedding\nAcknowledgements The authors are grateful for the constructive comments and suggestions made by the reviewers.\nAuthor contributions The studies were created and planned by J. J. and Z. W. Z. W carried out the feature extraction, model building, deep learning, and performance assessment. The manuscript was written by Z. W. and revised by J. J and M. S. This work was supervised by J. J. and M. S. The final manuscript was written with input from all authors, who also contributed to the paper\u2019s substance.\nFunding This work was sponsored in part by the National Science Foundation of China (Nos. 61761023, 62162032, and 31760315), the Natural Science Foundation of Jiangxi Province, China (Nos. 20202BABL202004 and 20202BAB202007), the Scientific Research Plan of the Department of Education of Jiangxi Province, China (GJJ190695). These funders had no role in the study design, data collection and analysis, decision to publish or preparation of manuscript.\nAvailability of data and materials It is simple to extract the dataset and source code for this work from (https:// github. com/ 13133 989982/ EMDL- m6Am)."
        },
        {
            "heading": "Declarations",
            "text": "Ethics approval and consent to participate Not applicable.\nConsent for publication Not applicable.\nCompeting interests The authors declare that they have no competing interests.\nReceived: 20 February 2023 Accepted: 20 October 2023\nReferences 1. Boccaletto P, Machnicka MA, Purta E, Pi\u0105tkowski P, Bagi\u0144ski B, Wirecki TK, et al. MODOMICS: a database of RNA modifica-\ntion pathways. 2017 update. Nucl Acids Res. 2018;46:D303-7. 2. Jonkhout N, Tran J, Smith MA, Schonrock N, Mattick JS, Novoa EM. The RNA modification landscape in human disease.\nRNA. 2017;23:1754\u201369.\n3. Desrosiers R, Friderici K, Rottman F. Identification of methylated nucleosides in messenger RNA from Novikoff hepatoma cells. Proc Natl Acad Sci USA. 1974;71:3971\u20135. 4. Wei C, Gershowitz A, Moss B. N6, O2\u2019-dimethyladenosine a novel methylated ribonucleoside next to the 5\u2019 terminal of animal cell and virus mRNAs. Nature. 1975;257:251\u20133. 5. Ben-Haim MS, Pinto Y, Moshitch-Moshkovitz S, Hershkovitz V, Kol N, Diamant-Levi T, et al. Dynamic regulation of N6,2\u2032-Odimethyladenosine (m6Am) in obesity. Nat Commun. 2021;12:7185. 6. Schwartz S, Mumbach MR, Jovanovic M, Wang T, Maciag K, Bushkin GG, et al. Perturbation of m6A writers reveals two distinct classes of mRNA methylation at internal and 5\u2019 sites. Cell Rep. 2014;8:284\u201396. 7. Benak D, Kolar F, Zhang L, Devaux Y, Hlavackova M. RNA modification m6Am: the role in cardiac biology. Epigenetics. 2023;18:2218771. 8. Cesaro B, Tarullo M, Fatica A. Regulation of Gene Expression by m6Am RNA Modification. Int J Mol Sci. 2023;24:2277. 9. Fernandez Rodriguez G, Cesaro B, Fatica A. Multiple Roles of m6A RNA Modification in Translational Regulation in Can-\ncer. Int J Mol Sci. 2022;23:8971. 10. Zhuo W, Sun M, Wang K, Zhang L, Li K, Yi D, et al. m6Am methyltransferase PCIF1 is essential for aggressiveness of gastric\ncancer cells by inhibiting TM9SF1 mRNA translation. Cell Discov. 2022;8:48. 11. Mauer J, Luo X, Blanjoie A, Jiao X, Grozhik AV, Patil DP, et al. Reversible methylation of m6Am in the 5\u2032 cap controls mRNA\nstability. 2017:43. 12. Pandey RR, Delfino E, Homolka D, Roithova A, Chen K-M, Li L, et al. The mammalian cap-specific m6Am RNA methyl-\ntransferase PCIF1 regulates transcript levels in mouse tissues. Cell Rep. 2020;32:108038. 13. Boulias K, Toczyd\u0142owska-Socha D, Hawley BR, Liberman N, Takashima K, Zaccara S, et al. Identification of the m6Am\nmethyltransferase PCIF1 reveals the location and functions of m6Am in the transcriptome. Mol Cell. 2019;75:631-643.e8. 14. Akichika S, Hirano S, Shichino Y, Suzuki T, Nishimasu H, Ishitani R, et al. Cap-specific terminal N 6-methylation of RNA by\nan RNA polymerase II-associated methyltransferase. Science. 2019;363:eaav0080. 15. Hawley BR, Jaffrey SR. Transcriptome-wide mapping of m6 A and m6 Am at single-nucleotide resolution using miCLIP.\nCurr Protoc Mol Biol. 2019;126:e88. 16. Koh CWQ, Goh YT, Goh WSS. Atlas of quantitative single-base-resolution N6-methyl-adenine methylomes. Nat Com-\nmun. 2019;10:5636. 17. Sun H, Li K, Zhang X, Liu J, Zhang M, Meng H, et al. m6Am-seq reveals the dynamic m6Am methylation in the human\ntranscriptome. Nat Commun. 2021;12:4778. 18. Jiang J, Song B, Chen K, Lu Z, Rong R, Zhong Y, et al. m6AmPred: Identifying RNA N6, 2\u2032-O-dimethyladenosine (m6Am)\nsites based on sequence-derived information. Methods. 2022;203:328\u201334. 19. Song Z, Huang D, Song B, Chen K, Song Y, Liu G, et al. Attention-based multi-label neural networks for integrated predic-\ntion and interpretation of twelve widely occurring RNA modifications. Nat Commun. 2021;12:4011. 20. Luo Z, Su W, Lou L, Qiu W, Xiao X, Xu Z. DLm6Am: a deep-learning-based tool for identifying N6,2\u2032-O-dimethyladenosine\nsites in RNA sequences. IJMS. 2022;23:11026. 21. Wang H, Zhao H, Yan Z, Zhao J, Han J. MDCAN-Lys: a model for predicting succinylation sites based on multilane dense\nconvolutional attention Network. Biomolecules. 2021;11:872. 22. Wang H, Yan Z, Liu D, Zhao H, Zhao J. MDC-Kace: a model for predicting lysine acetylation sites based on modular\ndensely connected convolutional networks. IEEE Access. 2020;8:214469\u201380. 23. Niu M, Zou Q, Lin C. CRBPDL: Identification of circRNA-RBP interaction sites using an ensemble neural network\napproach. PLoS Comput Biol. 2022;18:1\u201317. 24. Jia J, Wu G, Qiu W. pSuc-FFSEA: predicting lysine succinylation sites in proteins based on feature fusion and stacking\nensemble algorithm. Front Cell Dev Biol. 2022;10:894874. 25. Li W, Godzik A. Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences. Bioin-\nformatics. 2006. https:// doi. org/ 10. 1093/ bioin forma tics/ btl158. 26. Chen W, Tran H, Liang Z, Lin H, Zhang L. Identification and analysis of the N6-methyladenosine in the Saccharomyces\ncerevisiae transcriptome. Sci Rep. 2015;5:13859. 27. Rehman MU, Tayara H, Chong KT. DL-M6A: identification of N6-methyladenosine sites in mammals using deep learning\nbased on different encoding schemes. IEEE/ACM Trans Comput Biol Bioinform. 2022. 28. Bari ATMG, Reaz MR, Choi H-J, Jeong B-S. DNA encoding for splice site prediction in large DNA sequence. In: Hong B,\nMeng X, Chen L, Winiwarter W, Song W, editors. Database systems for advanced applications. Berlin: Springer; 2013. p. 46\u201358.\n29. Yang H, Lv H, Ding H, Chen W, Lin H. iRNA-2OM: a sequence-based predictor for Identifying 2\u2019-O-Methylation sites in homo sapiens. J Comput Biol. 2018;25:1266\u201377. 30. Chen W, Feng P, Tang H, Ding H, Lin H. RAMPred: identifying the N1-methyladenosine sites in eukaryotic transcriptomes. Sci Rep. 2016;6:31080. 31. Chen W, Tang H, Lin H. MethyRNA: a web server for identification of N6-methyladenosine sites. J Biomol Struct Dyn. 2017;35:683\u20137. 32. Huang G, Liu Z, van der Maaten L, Weinberger KQ. Densely connected convolutional networks. 2017. p. 4700\u20138. 33. Jia J, Wu G, Li M, Qiu W. pSuc-EDBAM: predicting lysine succinylation sites in proteins based on ensemble dense blocks\nand an attention module. Preprint. In Review; 2022. 34. Jia J, Sun M, Wu G, Qiu W, Jia J, Sun M, et al. DeepDN_iGlu: prediction of lysine glutarylation sites based on attention\nresidual learning method and DenseNet. MBE. 2023;20:2815\u201330. 35. Holschneider M, Kronland-Martinet R, Morlet J, Tchamitchian Ph. A real-time algorithm for signal analysis with the help\nof the wavelet transform. In: Combes J-M, Grossmann A, Tchamitchian P, editors. Wavelets. Berlin: Springer; 1990. p. 286\u201397.\n36. Ku T, Yang Q, Zhang H. Multilevel feature fusion dilated convolutional network for semantic segmentation. Int J Adv Rob Syst. 2021. https:// doi. org/ 10. 1177/ 17298 81421 10076 65. 37. Liu C, Song J, Ogata H, Akutsu T. MSNet-4mC: learning effective multi-scale representations for identifying DNA N4-methylcytosine sites. Bioinformatics. 2022:btac671.\n\u2022 fast, convenient online submission \u2022 thorough peer review by experienced researchers in your field \u2022 rapid publication on acceptance \u2022 support for research data, including large and complex data types \u2022 gold Open Access which fosters wider collaboration and increased citations maximum visibility for your research: over 100M website views per year \u2022\nAt BMC, research is always in progress.\nLearn more biomedcentral.com/submissions\nReady to submit your research ? Choose BMC and benefit from:\n38. Chaabane M, Williams R, Stephens A, Park J. circDeep: deep learning approach for circular RNA classification from other long non-coding RNA. Bioinformatics (Oxford, England). 2019;36. 39. Kha Q-H, Ho Q-T, Le NQK. Identifying SNARE proteins using an alignment-free method based on multiscan convolutional neural network and PSSM profiles. J Chem Inf Model. 2022;62:4820\u20136. 40. Le NQK, Ho Q-T, Nguyen V-N, Chang J-S. BERT-promoter: an improved sequence-based predictor of DNA promoter using BERT pre-trained model and SHAP feature selection. Comput Biol Chem. 2022;99:107732. 41. Wang C-Y, Liao H-YM, Wu Y-H, Chen P-Y, Hsieh J-W, Yeh I-H. CSPNet: a new backbone that can enhance learning capability of CNN. 2020. p. 390\u20131. 42. Guan Q, Wang Y, Ping B, Li D, Du J, Qin Y, et al. Deep convolutional neural network VGG-16 model for differential diagnosing of papillary thyroid carcinomas in cytological images: a pilot study. J Cancer. 2019;10:4876\u201382. 43. He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. 2016. p. 770\u20138. 44. Xiao J, Wang J, Cao S, Li B. Application of a novel and improved VGG-19 network in the detection of workers wearing\nmasks. J Phys Conf Ser. 2020;1518:012041. 45. Vacic V, Iakoucheva LM, Radivojac P. Two sample logo: a graphical representation of the differences between two sets of\nsequence alignments. Bioinformatics. 2006;22:1536\u20137."
        },
        {
            "heading": "Publisher\u2019s Note",
            "text": "Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations."
        }
    ],
    "title": "EMDL_m6Am: identifying N6,2\u2032-O-dimethyladenosine sites based on stacking ensemble deep learning",
    "year": 2023
}