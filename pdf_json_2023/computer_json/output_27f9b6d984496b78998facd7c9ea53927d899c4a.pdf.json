{
    "abstractText": "Our proposed method, RESETOX (REdo SEarch if TOXic), addresses the issue of Neural Machine Translation (NMT) generating translation outputs that contain toxic words not present in the input. The objective is to mitigate the introduction of toxic language without the need for re-training. In the case of identified added toxicity during the inference process, RESETOX dynamically adjusts the keyvalue self-attention weights and re-evaluates the beam search hypotheses. Experimental results demonstrate that RESETOX achieves a remarkable 57% reduction in added toxicity while maintaining an average translation quality of 99.5% across 164 languages. Our code is available at: https://github.com/mt-upc/ ReSeTOX WARNING: the current paper contains examples that may be offensive.",
    "authors": [
        {
            "affiliations": [],
            "name": "Javier Garc\u00eda Gilabert"
        },
        {
            "affiliations": [],
            "name": "Carlos Escolano"
        },
        {
            "affiliations": [],
            "name": "Marta R. Costa-juss\u00e0"
        }
    ],
    "id": "SP:f8b4f8241b05e26247b58239c2a7e1c6bca79dae",
    "references": [
        {
            "authors": [
                "Marta R. Costa-juss\u00e0",
                "Eric Smith",
                "Christophe Ropers",
                "Daniel Licht",
                "Jean Maillard",
                "Javier Ferrando",
                "Carlos Escolano"
            ],
            "title": "Toxicity in multilingual machine translation at scale",
            "year": 2023
        },
        {
            "authors": [
                "David Dale",
                "Elena Voita",
                "Lo\u00efc Barrault",
                "Marta R"
            ],
            "title": "Detecting and mitigating hallucinations in machine translation: Model internal workings alone do well, sentence similarity even better",
            "venue": "Costa-jussa\u0300",
            "year": 2022
        },
        {
            "authors": [
                "Bryan Eikema",
                "Wilker Aziz."
            ],
            "title": "Sampling-based approximations to minimum Bayes risk decoding for neural machine translation",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 10978\u201310993, Abu",
            "year": 2022
        },
        {
            "authors": [
                "Farshid Faal",
                "Ketra Schmitt",
                "Jia Yuan Yu."
            ],
            "title": "Reward modeling for mitigating toxicity in transformer-based language models",
            "venue": "Applied Intelligence, 53(7):8421\u20138435.",
            "year": 2022
        },
        {
            "authors": [
                "Fangxiaoyu Feng",
                "Yinfei Yang",
                "Daniel Cer",
                "Naveen Arivazhagan",
                "Wei Wang."
            ],
            "title": "Languageagnostic BERT sentence embedding",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Pa-",
            "year": 2022
        },
        {
            "authors": [
                "Javier Ferrando",
                "Gerard I. G\u00e1llego",
                "Belen Alastruey",
                "Carlos Escolano",
                "Marta R. Costa-juss\u00e0."
            ],
            "title": "Towards opening the black box of neural machine translation: Source and target interpretations of the transformer",
            "venue": "Proceedings of the 2022 Conference",
            "year": 2022
        },
        {
            "authors": [
                "Shaikh",
                "Anastasia Shimorina",
                "Hendrik Strobelt",
                "Nishant Subramani",
                "Wei Xu",
                "Diyi Yang",
                "Akhila Yerukola",
                "Jiawei Zhou"
            ],
            "title": "The GEM benchmark: Natural language generation, its evaluation and metrics",
            "year": 2021
        },
        {
            "authors": [
                "Philipp Koehn."
            ],
            "title": "Statistical significance tests for machine translation evaluation",
            "venue": "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 388\u2013 395, Barcelona, Spain. Association for Computa-",
            "year": 2004
        },
        {
            "authors": [
                "Todor Markov",
                "Chong Zhang",
                "Sandhini Agarwal",
                "Tyna Eloundou",
                "Teddy Lee",
                "Steven Adler",
                "Angela Jiang",
                "Lilian Weng"
            ],
            "title": "A holistic approach to undesired content detection in the real world",
            "year": 2023
        },
        {
            "authors": [
                "Cynthia Gao",
                "Vedanuj Goswami",
                "Francisco Guzm\u00e1n",
                "Philipp Koehn",
                "Alexandre Mourachko",
                "Christophe Ropers",
                "Safiyyah Saleem",
                "Holger Schwenk",
                "Jeff Wang"
            ],
            "title": "No language left behind: Scaling human-centered machine translation",
            "year": 2022
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311\u2013318, Philadelphia,",
            "year": 2002
        },
        {
            "authors": [
                "Maja Popovi\u0107."
            ],
            "title": "chrf: character n-gram f-score for automatic mt evaluation",
            "venue": "Proceedings of the tenth workshop on statistical machine translation, pages 392\u2013395.",
            "year": 2015
        },
        {
            "authors": [
                "Maarten Sap",
                "Dallas Card",
                "Saadia Gabriel",
                "Yejin Choi",
                "Noah A. Smith."
            ],
            "title": "The risk of racial bias in hate speech detection",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1668\u20131678, Florence,",
            "year": 2019
        },
        {
            "authors": [
                "Khetam Al Sharou",
                "Lucia Specia."
            ],
            "title": "A taxonomy and study of critical errors in machine translation",
            "venue": "Proceedings of the 23rd Annual Conference of the European Association for Machine Translation, pages 171\u2013180, Ghent, Belgium. European As-",
            "year": 2022
        },
        {
            "authors": [
                "Eric Michael Smith",
                "Melissa Hall",
                "Melanie Kambadur",
                "Eleonora Presani",
                "Adina Williams."
            ],
            "title": "I\u2019m sorry to hear that\u201d: Finding new biases in language models with a holistic descriptor dataset",
            "venue": "Proceedings of the 2022 Conference on Empirical Meth-",
            "year": 2022
        },
        {
            "authors": [
                "Irene Solaiman",
                "Christy Dennison."
            ],
            "title": "Process for adapting language models to society (PALMS) with values-targeted datasets",
            "venue": "Advances in Neural Information Processing Systems.",
            "year": 2021
        },
        {
            "authors": [
                "Lucia Specia",
                "Fr\u00e9d\u00e9ric Blain",
                "Marina Fomicheva",
                "Chrysoula Zerva",
                "Zhenhao Li",
                "Vishrav Chaudhary",
                "Andr\u00e9 F.T. Martins."
            ],
            "title": "Findings of the WMT 2021 shared task on quality estimation",
            "venue": "Proceedings of the Sixth Conference on Machine",
            "year": 2021
        },
        {
            "authors": [
                "Yoad Tewel",
                "Yoav Shalev",
                "Roy Nadler",
                "Idan Schwartz",
                "Lior Wolf."
            ],
            "title": "Zero-shot video captioning with evolving pseudo-tokens",
            "venue": "arXiv preprint arXiv:2207.11100.",
            "year": 2022
        },
        {
            "authors": [
                "Yoad Tewel",
                "Yoav Shalev",
                "Idan Schwartz",
                "Lior Wolf."
            ],
            "title": "Zerocap: Zero-shot image-to-text generation for visual-semantic arithmetic",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 17918\u2013",
            "year": 2022
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in Neural Information Processing Systems, pages 5998\u20136008.",
            "year": 2017
        },
        {
            "authors": [
                "Jing Xu",
                "Da Ju",
                "Margaret Li",
                "Y-Lan Boureau",
                "Jason Weston",
                "Emily Dinan."
            ],
            "title": "Recipes for safety in open-domain chatbots",
            "venue": "arXiv preprint arXiv:2010.07079.",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "WARNING: the current paper contains examples that may be offensive."
        },
        {
            "heading": "1 Introduction",
            "text": "The definition of toxicity provided by Sharou and Specia (2022) characterizes it as instances where a translation may incite hate, violence, profanity, or abuse towards individuals or groups based on religion, race, gender, and more (Sharou and Specia, 2022). Language generation systems are susceptible to generating toxic content triggered by certain prompts (Gehrmann et al., 2021). Unlike Machine Translation (MT) systems that are conditioned on a given source input, unconditioned language generation systems are more susceptible to this safety concern. However, when the purpose of translation is to faithfully represent the source, the presence of deleted or added toxicity in the translation output is undoubtedly a significant mistake. The addition of toxicity can have a more negative impact on user perception compared to its omission, leading to a significant decrease in user trust in the MT system. Previous studies have highlighted the causes\nof added toxicity in translation, including unbalanced training data (where one side of the parallel corpus contains toxicity while the other does not) and the generation of toxic tokens during the decoding process (Costa-juss\u00e0 et al., 2023). Overall, the existence of (added) toxicity remains one of the most critical safety concerns in language generation, adversely affecting user experience and posing a threat to the usability of these models.\nOur proposed method, RESETOX (REdo SEarch if TOXic), addresses the issue of added toxicity by re-learning the search process. Specifically, when added toxicity is detected in the output, we do one gradient descent iteration in the decoder to modify the attention keys and values according to an objective function that optimizes a combination of toxicity mitigation and translation quality. Then, we re-score the hypothesis from the beam search. This approach enables us to mitigate added toxicity\nar X\niv :2\n30 5.\n11 76\n1v 1\n[ cs\n.C L\n] 1\n9 M\nay 2\n02 3\nby 57% while maintaining a translation quality of 99.5%. In Figure 1, we provide several translation examples that demonstrate the effectiveness of RESETOX. These examples illustrate how our method is capable of replacing toxic words with the correct translation (first example), potentially using alternative words that may not fully convey the source meaning (second example), or simply removing the toxic word (third example)."
        },
        {
            "heading": "2 Related Work",
            "text": "Within the field of language generation, there exists a wide range of studies and tools that focus on toxicity detection. Notable examples include the task of toxicity classification by Jigsaw and the utilization of tools such as Perspective AI1.\nEfforts have also been made to address the generation of toxic content. One comprehensive example is the work by Markov et al. (2023), which emphasizes the mitigation of undesired content. Their approach encompasses various aspects such as the development of content taxonomies and labeling instructions, ensuring data quality control, implementing an active learning pipeline to capture rare events, and employing diverse methods to enhance the robustness of the language model and prevent overfitting. In a broader sense, mitigation in language generation often involves the application of safety filters on top of the language model (LM) (Xu et al., 2020). Alternatively, finetuning the LM can be performed using supervised learning (Solaiman and Dennison, 2021) or reinforcement learning techniques (Faal et al., 2022). Another approach suggests modifying the hidden states of the model during inference. For instance, PPLM (Dathathri et al., 2020) proposes utilizing an attribute classifier to adjust the hidden states of the model towards a less toxic direction. Similar ideas to PPLM have been proposed to guide the LM towards a desired direction (Tewel et al., 2022b,a).\nIn the case of MT, which involves conditioned language generation, the focus of mitigating added toxicity is to ensure that the translated text is both free from any additional toxic elements and remains faithful to the source language. Within the realm of MT, the study of toxicity errors has predominantly revolved around detection, particularly in the context of the WMT critical error detection task (Specia et al., 2021). This task aims to predict binary scores at the sentence level, indicating\n1https://perspectiveapi.com/\nwhether a translation contains a critical error, which extends beyond toxicity. To classify critical errors, Sharou and Specia (2022) have provided a taxonomy. Toxicity is examined within this task in terms of both added and deleted content. However, there are limited works that specifically address toxicity mitigation in the field of MT. The primary approach that we are aware of involves filtering unbalanced toxicity in parallel training corpora (NLLB Team et al., 2022). In our work, we introduce a novel approach to mitigate added toxicity in MT without the need for re-training nor fine-tuning."
        },
        {
            "heading": "3 Background: Toxicity detection tools",
            "text": "ETOX (Costa-juss\u00e0 et al., 2023) is toxicity detection tool based on word-lists. Toxicity lists help detecting strings that are always toxic regardless of context (e.g., fuck, asshole) as well as strings for which toxicity depends on context (e.g., tits, prick). ETOX uses toxicity lists to match words and classify the sentences as toxic if typically one or more words from the toxic lists are identified. This strategy has the huge shortcoming of not identifying non-lexical toxicity. The risks of low performance of this tool also include the fact that contextdependent toxic strings can constitute either true positives or false positives.However, ETOX has several large advantages which make it an adequate tool for our experiments. First, previous human evaluation of the tool (Costa-juss\u00e0 et al., 2023) reports no lack of morphological variants, and a low rate of false positive rates for most of the languages evaluated. Second, ETOX is highly multilingual and covers 200 languages. Last, but not least, being transparent compared to other types of classifiers (Sap et al., 2019).\nDetoxify is an open source library to detect toxic comments, built using PyTorchLightnin and huggingface, trained with Jigsaw \u2019s KaggleDatasets2. Detoxify is available in 7 languages: English, French, Spanish, Italian, Portuguese, Turkish, and Russian. The classifier returns a score between 0 and 1, with higher score meaning higher toxicity."
        },
        {
            "heading": "4 Proposed Mitigation Methodology",
            "text": "We propose a modification of the Transformer inference (Vaswani et al., 2017) that is able to mitigate added toxicity.\n2https://www.kaggle.com/c/jigsaw-unintended-bias-intoxicity-classification"
        },
        {
            "heading": "4.1 Context: auto-regressive process in the Transformer",
            "text": "The encoder-decoder model, has L layers of Transformer decoder blocks. In each decoder block we have key-value pairs for the self attention and cross attention mechanisms. Recall that the self attention mechanism computes attention weights that model token interactions by calculating the similarity between queries (Q) and keys (K). The output of the self attention block is then a weighted average between the attention weights and learned value functions (V ). This can be formally expressed as:\nSa[X] = V \u00b7 Softmax [ KTQ\u221a dk ] (1)\nwhere Softmax is a function that takes a matrix as an input and applies the softmax operation independently to each column of the matrix and dk is the dimension of the queries and keys.\nIn the case of the cross attention mechanism, queries are computed from the decoder while keys and values are computed from the encoder.\nLet Csi and C c i be the key-value pairs for the self attention and cross attention from the last iterations respectively:\nCsi = [(K l i , V l i )]l\u2264L C c i = [(K\u0302 l i , V\u0302 l i )]l\u2264L (2)\nwhere K li and V l i are the key and value embeddings of the self attention in the l-th decoder block generated at all time-steps from 0 to i. Similarly, K\u0302 li and V\u0302 l i are the key and value embeddings of the cross attention. Several efficient implementations of encoder-decoder models keep the keyvalue pairs from last iterations to accelerate the decoding of the model. The autoregressive process of the transformer can be written as follows:\noi+1 =M(xi, C s i , C c i ) (3)\nwhere oi+1 denotes the probability distribution of the next token."
        },
        {
            "heading": "4.2 Loss in the auto-regressive process",
            "text": "Beam search is the most widely adopted decoding method in MT. This technique maintains k (beam size) hypotheses for each inference step and selects the most probable complete hypothesis as the final translation. Our proposed method, RESETOX, conditionally updates the decoder self-attention matrices when toxicity is detected in the partially generated translation. First, a toxicity classifier is applied\nto identify toxic sentences. If toxicity is detected, the inference step is repeated with new modified self-attention matrices, resulting in a more suitable translation.\nTo update the decoder self-attention matrices, a loss function is computed at each time step which will be used to modify Csi and C c i towards a less toxic direction. The proposed loss has two competing objectives. The first objective aims to mitigate addded toxicity, which is achieved by employing a toxicity classifier that determines whether a given sentence is toxic or not. Let Sik be the sentence generated at step i with the last token being token k. The mitigation loss is computed as the crossentropy between the optimized distribution of the pre-trained language model and the distribution defined by the toxicity classifier:\nLm(C s i , C c i ) = \u2212 M\u2211 k=1 oki+1 \u00b7 log \u03b8TC(k) (4)\nwhere oki+1 \u2208 oi+1 is the probability of token k for the distribution probability of the next token obtained using equation 3 and \u03b8TC(k) is defined as:\n\u03b8TC(k) = exp(1\u2212 TC(Sk))\u2211M j=1 exp(1\u2212 TC(Sj))\n(5)\nHere, TC(Sk) measures the toxicity in Sk. We use 1\u2212 TC(Sk) as we need \u03b8TC to assign higher probabilities to non-toxic tokens. This mitigation loss is computed only for the top M most probable tokens according to the original distribution oi+1.\nEnsuring translation faithfulness while decreasing toxicity is a critical factor. During the optimization process, updating the context can cause a shift in the original distribution of the language model, resulting in sentences that are not necessarily toxic but lack faithfulness. To address this issue, a faithfulness loss term is used to ensure that the generated text remains faithful to the input. The faithfulness loss is defined as\nLf (o\u0302i+1, oi+1) = N\u2211 k=1 (o\u0302ki+1 \u00b7 log o\u0302ki+1)\u2212 (o\u0302ki+1 \u00b7 log oki+1)\n(6)\nwhere oki+1 and o\u0302 k i+1 denote the probability of token k after and before updating the key-value pairs respectively.\nFinally, the optimization problem can be formulated as follows:\nmin C\u0302si , C\u0302 c i\nL(C\u0302si , C\u0302 c i ) =\nmin C\u0302si , C\u0302 c i\n\u03b1 Lm(C\u0302 s i , C\u0302 c i ) + (1\u2212 \u03b1)Lf (o\u0302i+1, oi+1)\n(7) where o\u0302i+1 is computed using equation 3 with C\u0302si , C\u0302 c i and oi+1 is the distribution probability with the unmodified context. In this formulation, the optimization process of balancing translation faithfulness and toxicity mitigation is controlled by the hyperparameter \u03b1 \u2208 [0, 1], which scales the relative importance of these competing objectives. This optimization is carried out iteratively during inference. We make gradient updates to C\u0302si and C\u0302 c i as follows:\nC\u0302si \u2190\u2212 C\u0302si + \u03bb \u2207Csi L(C\u0302si , C\u0302ci ) \u2016L(C\u0302si , C\u0302ci )\u20162\n(8)\nC\u0302ci \u2190\u2212 C\u0302ci + \u03bb \u2207Cci L(C\u0302si , C\u0302ci ) \u2016L(C\u0302si , C\u0302ci )\u20162\n(9)\nWhen generating a new token, we perform one single update of the key-value pairs. This single update can be done in the key-value pairs from the cross attention; from the self attention or from both. Figure 2 shows an example of the RESETOX method when the toxicity classifier detects added toxicity. For this case, there is an update of the key-value pairs that allows to re-score the beam alternatives based on equation 7 and, in this example, choose a token that is non-toxic (puant instead of putain)."
        },
        {
            "heading": "5 Experiments",
            "text": ""
        },
        {
            "heading": "5.1 Data and Implementation",
            "text": "Datasets We experiment with two datasets. On the one hand, HOLISTICBIAS (Smith et al., 2022) consists of over 472k English sentences (e.g., \u201cI am a disabled parent.\u201d) used in the context of a two-person conversation. Previous work (Costajuss\u00e0 et al., 2023) has shown that HOLISTICBIAS provides a good setting for analyzing added toxicity because it triggers true toxicity, compared to standard previously explored datasets such as FLORES-200 (NLLB Team et al., 2022). We use HOLISTICBIAS to quantify added toxicity. We use the translations available from github 3 and in particular, only the outputs that have added toxicity. These outputs are available for 164 languages out of the 200 of NLLB because of tokenization issues or inaccuracies of the word-lists as motivated in the original paper (Costa-juss\u00e0 et al., 2023). However, this dataset is monolingual and we can not compute reference-based translation quality evaluation.\nAlternatively, on the other hand, we use FLORES200 to compute the reference-based translation quality. This test set is only used to make sure that RESETOX does not decrease the translation quality in cases with no added toxicity or false positives because differently from previous dataset, this one does not contain true positive toxic outputs for the NLLB model (Costa-juss\u00e0 et al., 2023).\nImplementation details The baseline system is the open-sourced NLLB-200 distilled model of 600M parameters available from HuggingFace 4. We follow the standard setting (beam search with beam size 5, limiting the translation length to 100\n3https://github.com/facebookresearch/stopes/tree/main/ demo/toxicity-alti-hb/alti\n4https://huggingface.co/facebook/nllb-200-distilled600M\ntokens). We test RESETOX with two toxicity classifiers ETOX and detoxify, as explained in section 3. We use the versions of the tools freely available in github 5,6, repectively. We integrate both in the auto-regressive loss as explained in 4.2. We generate the new translation by performing a single update of the keys-values of the self attention of the decoder. See section 5.3 for ablation study of different of these parameters.\nWe use the sacrebleu implementation of chrF (Popovic\u0301, 2015), and BLEU (Papineni et al., 2002) to compute the translation quality when we have a reference translation (with FLORES-200). We use the same tool to compute statistical significance with bootstrapping (Koehn, 2004). We use the cosine similarity between LaBSE (Feng et al., 2022) sentence embeddings provided by huggingface\u2019s implementation 7 to compute the translation quality when we have no reference translation (for HOLISTICBIAS). LaBSE embeddings have been proved useful to evaluate the faithfulness of the translation when no reference is available (Dale et al., 2022)."
        },
        {
            "heading": "5.2 Automatic evaluation",
            "text": "Table 1 shows the results for 3 different systems including the baseline system (NLLB 600M) and the same model with the toxicity mitigation applied using two different toxicity classifiers: detoxify and ETOX. Results report performance on HOLISTICBIAS in terms of added toxicity (i.e. detoxify and ETOX) and translation quality (i.e. LaBSE). For toxicity computed on detoxify we include the translation output detoxify score (score) as well as the difference between the source and output detoxify score (|4|). For ETOX we only report the translation output score because the source ETOX score is zero (Costa-juss\u00e0 et al., 2023).\nWhen RESETOX uses the ETOX toxicity classifier, the added toxicity reduction is of 65.8% in terms of ETOX and 58.9% in terms of detoxify. In this case, RESETOX keeps a 95.4% of translation quality in terms of LaBSE and 99.5% in terms of BLEU on the FLORES-200 dataset. When RESETOX uses the detoxify toxicity classifier, the added toxicity reduction is of 73.9% in terms of ETOX and 70.6% in terms of detoxify. In this case, RESETOX keeps a 94.2% of translation quality in terms\n5https://github.com/facebookresearch/stopes/tree/main/ demo/toxicity-alti-hb/ETOX\n6https://github.com/unitaryai/detoxify 7https://huggingface.co/sentence-transformers/LaBSE\nof LaBSE and 99.5% in terms of BLEU on the FLORES-200 dataset. As mentioned in previous works (NLLB Team et al., 2022; Costa-juss\u00e0 et al., 2023), FLORES-200 does not have real toxicity in the source (NLLB Team et al., 2022). In particular, another previous study (Costa-juss\u00e0 et al., 2023) showed by manual inspection that the translation outputs of the NLLB-200 dense model (3b) for 7 languages only contained extremely minor real toxicity for 2 languages (Kinyarwanda and Chinese Simplified). For the languages in table 1, and for the model we are using, we found 1 example for Spanish, Turkish and Italian, 2 examples for Portuguese, 3 for French and 1 for Russian, none of which are real added toxicity. Some of these examples are shown in figure 4 in the appendix C. Therefore, these particular languages when translating FLORES-200 allows us to understand the behaviour of RESETOX in a non-toxic dataset that generates no added toxicity. We successfully prove that RESETOX does not significantly affect the translation quality (with the exception of BLEU in Portuguese) when there is no added toxicity or only false positives.\nOur experiments show that RESETOX performance varies slightly in terms of (added) toxicity mitigation when changing the toxicity classifier, observing a higher mitigation when using detoxify than when using ETOX. However, there is consistency in maintenance of translation quality independently of the tool used. Also, there is no bias by using the same tool in the method and in the evaluation. This motivates our next experiments which are evaluating RESETOX for another 158 languages (in addition to the previous 6) with only the ETOX tool. In this case, we use ETOX both in the method itself and in the evaluation, since we are\nnot aware of any other toxic classifiers that scale to that volume of languages.\nFigure 3 shows the summary of results for these 164 languages. We average according to the amount of resources8 (NLLB Team et al., 2022). Results show that the reduction in added toxicity is higher for low-resourced languages. In average among all languages, RESETOX reduces added toxicity to more than half (57%). Appendix D shows the detailed results in terms of ETOX, BLEU and chrF for each of the 158 languages (complimentary to the 6 languages in table 1)."
        },
        {
            "heading": "5.3 Analysis",
            "text": "In order to determine the best configuration of RESETOX that lead to results in previous section, we experimented with different hyper-parameters. Figure 4 shows the values of detoxify, ETOX and BLEU (vertical axis) for different values of the\n8High-resource language as a language for which NLLB has at least 1 million sentences of aligned textual data (or bitext) with another language.\nweight between added toxicity and quality score from equation 7 (horizontal axis). In particular, we check the best weight; a conditional or full update; and updates in the decoder self and/or cross attention. Finally, we compare RESETOX with an alternative baseline which would be a hard filter of removing all ETOX words in the translation output.\nToxicity mitigation vs quality score trade-off Our method has to achieve a trade-off between mitigating added toxicity and keeping the translation quality. This is expressed in the loss where we combine a weight for added toxicity mitigation and quality score (i.e. translation faithfulness). In order to decide about this weight, we experimented with different values. Based on the results, we decide to use 0.8 as weight for the quality score.\nConditional update of keys and values We compare the RESETOX performance when we update keys and values only for the toxic outputs versus updating always. We observe that updating only for the toxic outputs achieves the best trade-\noff between added toxicity mitigation and keeping translation quality.\nSelf and/or cross attention updates We compare the RESETOX performance when updating self, cross or both attentions in the decoder. We observe that updating both at the same time leads to a much higher drop of the translation quality compared to separately updating self or cross-attention. There is not a big difference between updating self or cross attention, but self-attention has slightly better results both in added toxicity drops and keeping the translation quality.\nRESETOX vs removing toxic words From looking at the RESETOX outputs one could ask if removing toxic words form the toxicity word-lists could work better or comparable. The problem of the approach of removing words is that the fluency of the output gets dramatically affected, e.g. outputing sentences like Hola soy un abuelo sin. We can see this by comparing perplexity. We observe that for several languages (see appendix B), perplexity increases 2.5x up to 4x times. While perplexity increases are kept lower than 2x from the baseline to RESETOX. The latter explains why the baseline system adds toxicity in the translation output."
        },
        {
            "heading": "5.4 Human evaluation",
            "text": "Three independent Spanish native annotators did pair-wise comparisons among 200 random Englishto-Spanish outputs from HOLISTICBIAS of the baseline system, and the systems implementing RESETOX with detoxify and ETOX. Annotators use guidelines in appendix A and ranked systems\nin terms of translation quality (faithfullness) and amount of added toxicity. We computed fleiss kappa among annotators, and in all cases agreement was above 0.72. We used majority voting to consolidate results which are shown in Figure 5. Comparison between baseline and RESETOX (either detoxify or ETOX) shows the outperformance of using RESETOX both in terms of adequacy and added toxicity. When comparing detoxify and ETOX implementations within RESETOX, we observe slightly higher translation quality and added toxicity reduction when using detoxify."
        },
        {
            "heading": "5.5 Interpretability",
            "text": "We use ALTI+ (Ferrando et al., 2022) to analyse the input attributions in relation to the reduction in added toxicity. Input attributions are a type of\nlocal interpretability that assigns a score between 0 and 1 to each of the output tokens. This indicates the proportion each of the output tokens focuses on the source tokens. A score close to 1 means that the token highly focuses on the source tokens, whereas a score close to 0 means that the output token highly focuses on the previously predicted target tokens.\nFigure 6 shows the average ALTI+ input attributions and RESETOX added toxicity mitigation for low and high resource languages. There is a higher RESETOX added toxicity mitigation when there is lower source contribution. This is coherent with the nature of our method which modifies the attention weights to select the better decoder hypothesis. RESETOX has a tendency to better mitigate added toxicity that comes from hallucination rather than mistranslated added toxicity9. RESETOX succeeds in mitigating added toxicity cases that arise from a lack of attention to the source input but not when the added toxicity comes from mistranslations learnt for example from a misalignment in the training parallel corpus. For this, other methodologies like filtering unbalanced toxicity (NLLB Team et al., 2022) that require retraining are more effective. There is a negative correlation between average source contribution and RESETOX added toxicity mitigation of -0.07 for high resource languages and -0.39 for low resource languages."
        },
        {
            "heading": "5.6 Gender performance",
            "text": "HOLISTICBIAS is composed by patterns, descriptors and nouns. Nouns are distributed among 3 genders: female, male and neutral. There are 12\n9Based on definitions from previous work (Costa-juss\u00e0 et al., 2023) hallucinated added toxicity means that the toxic element in the translated sentence does not appear to have any corresponding elements in the source sentence; whereas mistranslated added toxicity means that the toxic element found in the translation can be considered as a mistranslation of a nontoxic element found in the source sentence.\nfemale nouns10; another 11 male nouns11; and 9 neutral nouns12. This allows us to compute the amount of toxicity by gender. Table 2 shows the total toxicity of the baseline and the percentage of toxicity mitigation as a function of gender for all languages (total) and separated for high and low resource languages. While there is a large difference in toxicity amount by gender (male exhibits more toxicity), there is only a slight deviation towards mitigating different genders, which varies depending on the languages that we are averaging. Therefore, we can say that RESETOX performance is similar for different genders. This is coherent with the fact that the toxicity detection tool that we are using, ETOX, is free from gender morphological bias as it covers all morphological inflections of the words in the lists (Costa-juss\u00e0 et al., 2023)."
        },
        {
            "heading": "6 Conclusions and further work",
            "text": "This paper presents RESETOX to mitigate added toxicity in machine translation at inference time.\n10woman, lady, gal, girl, mother, mom, daugther, wife, grandmother, grandma, sister, sista and their plural forms\n11man, bro, guy, boy, father, dad, son, husband, grandfather, grandpa, brother and their plural form\n12individual, person, kid, parent, child, spouse, grandparent, sibling, veteran and their plural\nThis method becomes first of its kind to be applied to the particular case of conditional language generation. For this particular application, added toxicity mitigation was only applied at the training stage by filtering unbalanced toxicity (NLLB Team et al., 2022) of parallel corpora. We have shown that RESETOX, in average, mitigates added toxicity to more than half for 164 languages while almost entirely keeping the translation quality."
        },
        {
            "heading": "7 Limitations",
            "text": "RESETOX does not totally eliminate added toxicity. Moreover, when finding alternatives to the toxic translation, it relies on the variety of the beam search to choose a better option than the toxic word. Most of the time the correct translation does not appear in the beam search. Here, as further work, RESETOX would benefit from applying methods that optimize the variety of the beam (Eikema and Aziz, 2022).\nA possible limitation of our method is the increase in inference time. First, for each inference step, the toxicity classifier is applied to decide if the conditional update is applied. In addition, when toxicity is detected, self-attention matrices must be updated, and the inference step is redone. Assuming that the standard beam search technique has a linear cost with respect to the number of tokens to generate n, with a cost of O(k2 \u2217 n) with a constant k for the beam size used. When using our technique, we have to add these two steps to our calculation resulting in an asymptotic growth of O(k2 \u2217 c \u2217 n+ k2 \u2217m) where c is the cost of the toxicity classifier at each step and m is the number of inference steps where a conditional update is applied. As gradient descent is significantly faster than an inference step, we exclude it from this calculation. While our method introduces additional computations, the cost remains linear with the number of tokens translated. In our experiments, most tokens are not detected as toxicity, leading to only slightly longer translation times compared to standard beam search decoding."
        },
        {
            "heading": "8 Ethical Statement",
            "text": "We are aware that toxicity classifiers may contain bias towards certain demographics. Our method heavily depends on using toxicity classifiers that define toxicity in a particular way. In our experiments, we use two toxicity classifiers. From one side, ETOX uses word-lists that allow for trans-\nparency, but detoxify uses anotated that and may lead to certain biases. In particular, when a sentence contains words associated with swearing, insults, or profanity, it is highly probable for the sentence to be classified as toxic, regardless of the author\u2019s tone. For example: I am tired of writing this stupid essay is determined as toxic while I am tired of writing this essay is not."
        },
        {
            "heading": "Acknowledgements",
            "text": "The work at the UPC from the first and second author was partially funded by the \u201dEuropean Union NextGenerationEU/PRTR\u201d under the project ROBIN (PLEC2021-007859)."
        },
        {
            "heading": "A Human Evaluation Guidelines",
            "text": "1- Rank the translation outputs according to translation adequacy. Which translation output is the most adequate compared to the source sentence?\nUse \u201cA\u201d if system A is better than \u201cB\u201d. Use \u201cN\u201d if both outputs have similar adequacy.\nCorner cases: In the event of having to compare a translation which wrongly translates a phrase of the sentence and another translation which does not translate that segment, the latter is a better system. Example: \u201cI used to be a shaggy boy.Yo sol\u00eda ser un chico de mierda.Yo sol\u00eda ser un chico.\u201d, the latter is better. 2- Rank the translation outputs according to added toxicity level. Which translation output is the less toxic? Use \u201cN\u201d if outputs have similar level of added toxicity. Use \u201cA\u201d if system A has lower added toxicity than \u201cB\u201d. Use \u201cN\u201d if both outputs have similar added toxicity."
        },
        {
            "heading": "B Ablation study by removing toxic words",
            "text": "As commented in section 5.3, Table 3 reports the perplexity of the translation outputs of the baseline, RESETOX and removing toxic words available in toxicity-lists from NLLB (NLLB Team et al., 2022). In order to measure the perplexity, we used the open-sourced BLOOM model of 1,7B parameters from HuggingFace13."
        },
        {
            "heading": "C Examples of toxicity outputs in FLORES-200",
            "text": "Figure 4 shows examples for Italian, Spanish and Portuguese. We observe no real added toxicity. We conclude that for these languages, we can only use FLORES-200 to understand how our method performs in non-toxic datasets that generate no real added toxicity."
        },
        {
            "heading": "D Results for 158 languages",
            "text": "Table 5 shows the results in HOLISTICBIAS in terms of ETOX and in FLORES-200 in terms of\n13https://huggingface.co/bigscience/bloom-1b7\nBLEU and chrF. While there is added toxicity reduction for all languages, translation quality only decreases significantly both in BLEU and chrF in 37 languages. Figure 7 shows the percentage of added toxicity reduction for each of the 158 languages.\nSource: Please treat the site with all of the dignity, solemnity and respect it deserves. Do not make jokes about the Holocaust or Nazis.\nHolistic Bias FLORES 200\nLanguage Code Resource Model ETOX BLEU CHRF\nBulgarian bul_Cyrl High Baseline 1407 35.75 63.15 RESETOXETOX 868 35.7 63.11\nKazakh kaz_Cyrl High Baseline 36 18.0 51.55 RESETOXETOX 9 18.02 51.54\nHalh Mongolian khk_Cyrl Low Baseline 380 9.58 40.58 RESETOXETOX 55 9.4 40.56\nKyrgyz kir_Cyrl Low Baseline 720 12.75 46.63 RESETOXETOX 556 12.71 46.53\nMacedonian mkd_Cyrl High Baseline 965 28.67 58.66 RESETOXETOX 760 28.65 58.63\nSerbian srp_Cyrl Low Baseline 234 27.56 56.28 RESETOXETOX 126 27.51 56.3\nTatar tat_Cyrl Low Baseline 0 16.49 48.44 RESETOXETOX 0 16.49* 48.44*\nTajik tgk_Cyrl Low Baseline 27 19.92 49.67 RESETOXETOX 13 19.77 49.58\nUkrainian ukr_Cyrl High Baseline 69 24.79 53.4 RESETOXETOX 31 24.76 53.41\nAmharic amh_Ethi Low Baseline 1064 12.47 40.4 RESETOXETOX 482 12.38 40.16*\nTigrinya tir_Ethi Low Baseline 374 4.25 24.45 RESETOXETOX 196 4.25 24.46\nGeorgian kat_Geor Low Baseline 9 12.92 51.12 RESETOXETOX 4 12.69* 50.89*\nGreek ell_Grek High Baseline 2079 24.1 50.87 RESETOXETOX 1560 24.1* 50.87*\nChinese (Simplified) zho_Hans High Baseline 13 0.96 25.08 RESETOXETOX 0 0.96 24.9*\nChinese (Traditional) zho_Hant High Baseline 0 1.32 16.62 RESETOXETOX 0 1.32 16.63\nHebrew heb_Hebr High Baseline 2830 23.83 53.73 RESETOXETOX 1649 23.74 53.63\nEastern Yiddish ydd_Hebr Low Baseline 0 8.87 38.44 RESETOXETOX 0 8.87 38.44\nAcehnese (Latin script) ace_Latn Low Baseline 135 9.43 40.01 RESETOXETOX 38 9.27* 39.91\nAfrikaans afr_Latn High Baseline 431 36.42 64.59 RESETOXETOX 72 36.3* 64.49*\nAkan aka_Latn Low Baseline 347 9.7 35.03 RESETOXETOX 63 9.6 34.91\nTosk Albanian als_Latn High Baseline 2745 28.62 57.16 RESETOXETOX 2636 28.29* 56.89*\nAsturian ast_Latn Low Baseline 148 24.3 55.54 RESETOXETOX 11 24.25 55.51\nCentral Aymara ayr_Latn Low Baseline 19 3.29 31.15 RESETOXETOX 0 3.34 31.19\nNorth Azerbaijani azj_Latn Low Baseline 488 12.27 44.1 RESETOXETOX 351 12.26 44.08\nBambara bam_Latn Low Baseline 1151 6.27 30.64 RESETOXETOX 304 6.31 30.59\nBalinese ban_Latn Low Baseline 293 14.76 47.12 RESETOXETOX 100 14.73 47.09\nBemba bem_Latn Low Baseline 1191 8.69 39.25 RESETOXETOX 221 8.62* 38.98*\nHolistic Bias FLORES 200\nLanguage Code Resource Model ETOX BLEU CHRF\nBanjar (Latin script) bjn_Latn Low Baseline 51 17.12 49.57 RESETOXETOX 12 16.96* 49.36*\nBosnian bos_Latn High Baseline 482 26.91 56.93 RESETOXETOX 301 26.84* 56.85*\nBuginese bug_Latn Low Baseline 82 6.03 35.93 RESETOXETOX 31 5.99 35.84\nCatalan cat_Latn High Baseline 1673 37.85 62.93 RESETOXETOX 220 37.94 62.96\nCebuano ceb_Latn Low Baseline 29 29.04 57.33 RESETOXETOX 3 29.03 57.32\nCzech ces_Latn High Baseline 189 27.65 55.54 RESETOXETOX 71 27.63 55.49\nChokwe cjk_Latn Low Baseline 674 2.06 23.44 RESETOXETOX 318 2.09 23.43\nCrimean Tatar crh_Latn Low Baseline 348 12.85 45.17 RESETOXETOX 183 12.71 44.91*\nWelsh cym_Latn Low Baseline 0 33.13 58.6 RESETOXETOX 0 33.16 58.62\nDanish dan_Latn High Baseline 221 40.78 65.41 RESETOXETOX 85 40.5* 65.19*\nGerman deu_Latn High Baseline 191 34.91 62.2 RESETOXETOX 71 34.89 62.13\nSouthwestern Dinka dik_Latn Low Baseline 25725 3.51 21.13 RESETOXETOX 11737 3.51 21.06\nDyula dyu_Latn Low Baseline 2009 1.65 19.19 RESETOXETOX 1263 1.63 19.18\nEsperanto epo_Latn Low Baseline 0 32.96 61.85 RESETOXETOX 0 32.86 61.84\nEstonian est_Latn High Baseline 1027 19.49 53.27 RESETOXETOX 622 19.45 53.23\nBasque eus_Latn High Baseline 4377 14.77 52.97 RESETOXETOX 745 14.68 52.8*\nEwe ewe_Latn Low Baseline 7012 11.76 38.0 RESETOXETOX 2820 11.31* 37.47*\nFaroese fao_Latn Low Baseline 377 20.57 45.91 RESETOXETOX 142 20.58 45.87\nFijian fij_Latn Low Baseline 3754 17.68 46.24 RESETOXETOX 1633 17.59 46.13\nFinnish fin_Latn High Baseline 1935 18.93 53.08 RESETOXETOX 1348 18.93 53.05\nFon fon_Latn Low Baseline 8580 2.49 18.68 RESETOXETOX 4195 2.48 18.85\nFriulian fur_Latn Low Baseline 409 28.01 54.7 RESETOXETOX 115 27.52* 54.31*\nNigerian Fulfulde fuv_Latn Low Baseline 347 1.95 20.38 RESETOXETOX 232 1.96 20.39\nWest Central Oromo gaz_Latn Low Baseline 10 3.52 37.28 RESETOXETOX 2 3.52 37.28\nScottish Gaelic gla_Latn Low Baseline 1416 15.42 48.04 RESETOXETOX 462 15.4 48.01\nIrish gle_Latn Low Baseline 732 23.29 50.04 RESETOXETOX 325 23.14* 49.94*\nGalician glg_Latn Low Baseline 420 32.09 59.24 RESETOXETOX 50 32.03 59.24\nHolistic Bias FLORES 200\nLanguage Code Resource Model ETOX BLEU CHRF\nGuarani grn_Latn Low Baseline 1135 8.98 37.66 RESETOXETOX 489 8.98 37.66\nHaitian Creole hat_Latn Low Baseline 291 23.22 52.22 RESETOXETOX 68 23.19 52.2\nHausa hau_Latn Low Baseline 406 23.44 51.53 RESETOXETOX 34 23.45 51.54\nCroatian hrv_Latn High Baseline 577 25.0 55.16 RESETOXETOX 388 24.94 55.08*\nIlocano ilo_Latn Low Baseline 1446 23.41 53.18 RESETOXETOX 709 23.07* 53.0\nIndonesian ind_Latn High Baseline 14220 43.25 68.46 RESETOXETOX 12338 43.01* 68.16*\nIcelandic isl_Latn High Baseline 13 19.8 46.74 RESETOXETOX 7 19.81 46.73\nJavanese jav_Latn Low Baseline 524 26.28 55.41 RESETOXETOX 179 26.22* 55.35*\nKabyle kab_Latn Low Baseline 4 6.41 29.28 RESETOXETOX 0 6.33 29.26\nJingpho kac_Latn Low Baseline 55 11.17 37.79 RESETOXETOX 15 11.18 37.8\nKamba kam_Latn Low Baseline 0 4.46 29.44 RESETOXETOX 0 4.43 29.41\nKabiy\u00e8 kbp_Latn Low Baseline 0 5.64 25.6 RESETOXETOX 0 5.64* 25.6*\nKabuverdianu kea_Latn Low Baseline 57 17.54 46.42 RESETOXETOX 9 17.57 46.36\nKikuyu kik_Latn Low Baseline 538 10.58 37.56 RESETOXETOX 127 10.49* 37.38*\nKinyarwanda kin_Latn Low Baseline 1623 15.46 47.62 RESETOXETOX 549 15.5 47.48*\nKimbundu kmb_Latn Low Baseline 901 2.96 28.54 RESETOXETOX 46 2.96 28.48\nNorthern Kurdish kmr_Latn Low Baseline 0 10.21 39.03 RESETOXETOX 0 10.21* 39.03*\nCentral Kanuri (Latin script) knc_Latn Low Baseline 0 2.21 17.95 RESETOXETOX 0 2.2 17.94\nKikongo kon_Latn Low Baseline 2751 17.54 47.11 RESETOXETOX 1903 17.54 47.1\nLigurian lij_Latn Low Baseline 3 15.5 45.46 RESETOXETOX 0 15.52 45.46\nLimburgish lim_Latn Low Baseline 8 10.77 44.57 RESETOXETOX 0 10.7 44.5*\nLingala lin_Latn Low Baseline 340 17.65 49.62 RESETOXETOX 134 17.66 49.54\nLithuanian lit_Latn High Baseline 390 19.67 52.06 RESETOXETOX 224 19.67 52.05\nLombard lmo_Latn Low Baseline 24 6.24 35.16 RESETOXETOX 2 6.24 35.1\nLatgalian ltg_Latn Low Baseline 26 14.79 43.46 RESETOXETOX 3 14.81 43.5\nLuxembourgish ltz_Latn Low Baseline 34 22.11 54.22 RESETOXETOX 6 22.1 54.2\nLuba-Kasai lua_Latn Low Baseline 1234 6.31 37.64 RESETOXETOX 317 6.07* 37.42*\nHolistic Bias FLORES 200\nLanguage Code Resource Model ETOX BLEU CHRF\nGanda lug_Latn Low Baseline 246 7.26 39.31 RESETOXETOX 16 7.25 39.3\nLuo luo_Latn Low Baseline 23855 10.47 40.06 RESETOXETOX 16351 10.24* 39.84*\nMizo lus_Latn Low Baseline 2148 9.83 37.44 RESETOXETOX 662 9.7* 37.23*\nStandard Latvian lvs_Latn High Baseline 889 18.32 47.96 RESETOXETOX 113 18.25 47.88\nMinangkabau (Latin script) min_Latn Low Baseline 20488 18.38 50.32 RESETOXETOX 14152 18.27* 50.24\nMaltese mlt_Latn High Baseline 74 24.15 63.28 RESETOXETOX 22 24.14 63.25\nMossi mos_Latn Low Baseline 820 3.48 22.57 RESETOXETOX 210 3.5 22.65\nMaori mri_Latn Low Baseline 163 19.27 45.13 RESETOXETOX 49 19.15* 45.1\nDutch nld_Latn High Baseline 74 25.23 56.24 RESETOXETOX 29 25.31 56.23\nNorwegian Nynorsk nno_Latn Low Baseline 54 25.04 54.61 RESETOXETOX 19 24.9* 54.48*\nNorwegian Bokm\u00e5l nob_Latn Low Baseline 1489 30.72 59.2 RESETOXETOX 1222 30.64* 59.15\nNorthern Sotho nso_Latn Low Baseline 3 22.11 51.28 RESETOXETOX 1 22.11 51.29\nNuer nus_Latn Low Baseline 51 5.41 27.52 RESETOXETOX 5 5.41 27.54\nNyanja nya_Latn Low Baseline 939 13.7 48.73 RESETOXETOX 585 13.68 48.73\nOccitan oci_Latn Low Baseline 39 33.17 60.78 RESETOXETOX 1 32.65* 60.31*\nPapiamento pap_Latn Low Baseline 4019 25.56 52.82 RESETOXETOX 2679 25.15* 52.55*\nPlateau Malagasy plt_Latn Low Baseline 270 16.03 52.11 RESETOXETOX 109 15.98 52.02\nPolish pol_Latn High Baseline 179 18.41 48.58 RESETOXETOX 77 18.39 48.55\nAyacucho Quechua quy_Latn Low Baseline 0 2.09 27.18 RESETOXETOX 0 2.12 27.15\nRomanian ron_Latn High Baseline 221 34.04 60.69 RESETOXETOX 68 33.81* 60.47*\nRundi run_Latn Low Baseline 377 11.47 43.36 RESETOXETOX 121 11.49 43.27*\nSango sag_Latn Low Baseline 5 9.06 36.0 RESETOXETOX 1 8.95 35.87\nSicilian scn_Latn Low Baseline 14268 5.92 37.26 RESETOXETOX 9330 5.81 37.21\nSlovak slk_Latn High Baseline 23 28.56 56.4 RESETOXETOX 14 28.47 56.35\nSlovenian slv_Latn High Baseline 575 25.01 53.43 RESETOXETOX 425 24.99 53.39*\nSamoan smo_Latn Low Baseline 2854 25.56 49.67 RESETOXETOX 1190 25.32* 49.37*\nShona sna_Latn Low Baseline 103 12.9 48.23 RESETOXETOX 93 12.87 48.17\nHolistic Bias FLORES 200\nLanguage Code Resource Model ETOX BLEU CHRF\nSomali som_Latn Low Baseline 99 11.54 45.77 RESETOXETOX 58 11.5 45.72\nSouthern Sotho sot_Latn High Baseline 18571 18.37 48.49 RESETOXETOX 14650 18.35 48.49\nSardinian srd_Latn Low Baseline 24 25.56 54.71 RESETOXETOX 9 25.39* 54.58*\nSwati ssw_Latn Low Baseline 0 9.91 47.75 RESETOXETOX 0 9.82 47.66\nSundanese sun_Latn Low Baseline 184 18.37 50.62 RESETOXETOX 64 18.25* 50.53*\nSwedish swe_Latn High Baseline 333 39.62 65.13 RESETOXETOX 88 39.8* 65.19\nSwahili swh_Latn High Baseline 569 32.08 60.75 RESETOXETOX 229 32.02 60.61*\nSilesian szl_Latn Low Baseline 166 16.98 47.49 RESETOXETOX 68 16.97 47.45\nTagalog tgl_Latn High Baseline 446 31.37 58.08 RESETOXETOX 299 31.27 58.07\nTok Pisin tpi_Latn Low Baseline 3590 18.33 42.94 RESETOXETOX 1419 17.09* 41.88*\nTswana tsn_Latn High Baseline 11558 21.04 49.18 RESETOXETOX 4475 20.92 49.08*\nTsonga tso_Latn Low Baseline 2885 21.57 52.12 RESETOXETOX 2117 21.56 52.1\nTurkmen tuk_Latn Low Baseline 556 10.69 40.33 RESETOXETOX 377 10.52 40.32\nTumbuka tum_Latn Low Baseline 1179 9.96 37.71 RESETOXETOX 831 9.89* 37.63\nTwi twi_Latn Low Baseline 29683 11.2 37.27 RESETOXETOX 7573 10.01* 35.82*\nUmbundu umb_Latn Low Baseline 35 2.34 30.07 RESETOXETOX 22 2.35 30.1\nNorthern Uzbek uzn_Latn High Baseline 0 15.48 52.79 RESETOXETOX 0 15.51 52.61*\nVenetian vec_Latn Low Baseline 1177 14.63 48.99 RESETOXETOX 895 14.43* 48.91\nVietnamese vie_Latn High Baseline 2370 38.46 56.47 RESETOXETOX 1085 38.48 56.48\nWaray war_Latn Low Baseline 3734 28.59 56.11 RESETOXETOX 2052 28.59 56.1\nWolof wol_Latn Low Baseline 1 4.99 24.67 RESETOXETOX 0 5.0 24.65\nXhosa xho_Latn High Baseline 0 13.67 53.03 RESETOXETOX 0 13.67 53.02\nYoruba yor_Latn Low Baseline 18735 4.29 24.08 RESETOXETOX 16099 4.26 24.04\nStandard Malay zsm_Latn High Baseline 797 37.57 65.74 RESETOXETOX 508 37.53 65.71\nZulu zul_Latn High Baseline 34 17.24 56.66 RESETOXETOX 6 17.23 56.65\nCentral Atlas Tamazight tzm_Tfng Low Baseline 13 5.37 28.21 RESETOXETOX 4 5.23* 27.83*\nDzongkha dzo_Tibt Low Baseline 0 0.52 39.24 RESETOXETOX 0 0.52* 39.24*"
        }
    ],
    "title": "ReSeTOX: Re-learning attention weights for toxicity mitigation in machine translation",
    "year": 2023
}