{
    "abstractText": "Local news articles are a subset of news that impact users in a geographical area, such as a city, county, or state. Detecting local news (Step 1) and subsequently deciding its geographical location as well as radius of impact (Step 2) are two important steps towards accurate local news recommendation. Naive rulebased methods, such as detecting city names from the news title, tend to give erroneous results due to lack of understanding of the news content. Empowered by the latest development in natural language processing, we develop an integrated pipeline that enables automatic local news detection and contentbased local news recommendations. In this paper, we focus on Step 1 of the pipeline, which highlights: (1) a weakly supervised framework incorporated with domain knowledge and auto data processing, and (2) scalability to multi-lingual settings. Compared with Stanford CoreNLP NER model, our pipeline has higher precision and recall evaluated on a real-world and human-labeled dataset. This pipeline has potential to more precise local news to users, helps local businesses get more exposure, and gives people more information about their neighborhood safety.",
    "authors": [
        {
            "affiliations": [],
            "name": "Deven Santosh Shah"
        },
        {
            "affiliations": [],
            "name": "Shiying He"
        },
        {
            "affiliations": [],
            "name": "Gosuddin Kamaruddin Siddiqi"
        }
    ],
    "id": "SP:d5cc860f84f3fe01f8996af8c189df44eb883bb1",
    "references": [
        {
            "authors": [
                "Florian Alt",
                "Alireza Sahami Shirazi",
                "Albrecht Schmidt",
                "Urs Kramer",
                "Zahid Nawaz."
            ],
            "title": "Locationbased crowdsourcing: extending crowdsourcing to the real world",
            "venue": "Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Ex-",
            "year": 2010
        },
        {
            "authors": [
                "Peter Bell",
                "Catherine Lai",
                "Clare Llewellyn",
                "Alexandra Birch",
                "Mark Sinclair."
            ],
            "title": "A system for automatic broadcast news summarisation, geolocation and translation",
            "venue": "Sixteenth Annual Conference of the International Speech Communication Associa-",
            "year": 2015
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners. Advances in neural information processing",
            "year": 2020
        },
        {
            "authors": [
                "Alexis Conneau",
                "Kartikay Khandelwal",
                "Naman Goyal",
                "Vishrav Chaudhary",
                "Guillaume Wenzek",
                "Francisco Guzm\u00e1n",
                "Edouard Grave",
                "Myle Ott",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Unsupervised cross-lingual representation learning at scale",
            "venue": "arXiv",
            "year": 2019
        },
        {
            "authors": [
                "Tatiana Santos Gon\u00e7alves",
                "Pedro Jer\u00f3nimo",
                "Jo\u00e3o Carlos Correia."
            ],
            "title": "Local news and geolocation technology in the case of portugal",
            "venue": "Publications, 9(4):53.",
            "year": 2021
        },
        {
            "authors": [
                "Chloe Kliman-Silver",
                "Aniko Hannak",
                "David Lazer",
                "Christo Wilson",
                "Alan Mislove."
            ],
            "title": "Location, location, location: The impact of geolocation on web search personalization",
            "venue": "Proceedings of the 2015 internet measurement conference, pages 121\u2013",
            "year": 2015
        },
        {
            "authors": [
                "Christopher D Manning",
                "Mihai Surdeanu",
                "John Bauer",
                "Jenny Rose Finkel",
                "Steven Bethard",
                "David McClosky."
            ],
            "title": "The stanford corenlp natural language processing toolkit",
            "venue": "Proceedings of 52nd annual meeting of the association for computational linguis-",
            "year": 2014
        },
        {
            "authors": [
                "Khumukcham Robindro",
                "Kshetrimayum Nilakanta",
                "Deepen Naorem",
                "Ningthoujam Gourakishwar Singh."
            ],
            "title": "An unsupervised content based news personalization using geolocation information",
            "venue": "2017 International Conference on Computing, Com-",
            "year": 2017
        },
        {
            "authors": [
                "Avijit Shah",
                "Topojoy Biswas",
                "Sathish Ramadoss",
                "Deven Santosh Shah."
            ],
            "title": "Distantly supervised semantic text detection and recognition for broadcast sports videos understanding",
            "venue": "Proceedings of the 29th ACM International Conference on Multimedia,",
            "year": 2021
        },
        {
            "authors": [
                "Deven Shah",
                "H Andrew Schwartz",
                "Dirk Hovy."
            ],
            "title": "Predictive biases in natural language processing models: A conceptual framework and overview",
            "venue": "arXiv preprint arXiv:1912.11078.",
            "year": 2019
        },
        {
            "authors": [
                "Golsa Tahmasebzadeh",
                "Endri Kacupaj",
                "Eric M\u00fcllerBudack",
                "Sherzod Hakimov",
                "Jens Lehmann",
                "Ralph Ewerth."
            ],
            "title": "Geowine: Geolocation based wiki, image, news and event retrieval",
            "venue": "Proceedings of the 44th International ACM SIGIR Confer-",
            "year": 2021
        },
        {
            "authors": [
                "Heli V\u00e4\u00e4t\u00e4j\u00e4",
                "Teija Vainio",
                "Esa Sirkkunen."
            ],
            "title": "Location-based crowdsourcing of hyperlocal news: Dimensions of participation preferences",
            "venue": "Proceedings of the 17th ACM international conference on Supporting group work, pages 85\u201394.",
            "year": 2012
        },
        {
            "authors": [
                "Sankaranarayanan"
            ],
            "title": "tweets(User Generated Content) on the Twitter platform to gather breaking news in the area. They also proposed an importance score defining a particular news article\u2019s importance to a neighborhood",
            "year": 2009
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Local news has always been a constant source of interest because of more relevancy to the individuals comparing with national or international news. People love to remain informed about the news and events happening in and around their neighborhood and find ways to connect with the community. Detecting this local news and showcasing it to the right audience will help them to achieve this. Not only does it benefit the local users and news publishers, but showcasing geolocation-specific news articles can drive user engagement (Robindro et al., 2017) for the products of digital news recommendation. These local news articles could be of different types like crime, events, food and drink, healthcare,\npolitics, college-level sports, real estate, etc. Some examples of these types of local news articles are:\n\u2022 Crime: \u201cSan Jose Police arrest 74-year-old Fresno man in connection to homicide\u201d1\n\u2022 Food and restaurants: \u201cCarmel\u2019s MuchAnticipated New Fine Dining Restaurant Chez Noir Opens Friday\u201d2\n\u2022 Real estate: \u201cSee where home prices have been rising the fastest in Washington\u201d3\n\u2022 Law: \u201cLegislature must remake water laws for a drier California\u201d4\n\u2022 Sports: \u201cSamson Ebukam\u2019s strong second year continues in win over Rams\u201d5\nHence, keeping the users informed is a two-step process, (1) detecting whether an article is a local news article, (2) determining the geolocation and the impact radius of the local news article, so that we could serve right news articles to the right audience. In this paper, we will primarily focus on the former task. We define local news articles that impact a specific set of users at the city/county/state level.\nMany papers have researched local news. These research papers rely on the geolocation mentioned in the article to serve the local news to their respective users (Tahmasebzadeh et al., 2021; Bell et al., 2015; Robindro et al., 2017; Sankaranarayanan\n1https://www.cbsnews.com/sanfrancisco/news/san-josepolice-arrest-74-year-old-fresno-man-in-connection-tohomicide/\n2https://sf.eater.com/2022/10/5/23389267/chez-noiropen-new-carmel-restaurant-jonny-black\n3https://www.msn.com/en-us/money/realestate/seewhere-home-prices-have-been-rising-the-fastest-inwashington/ss-AA153W3H\n4https://calmatters.org/commentary/2022/10/legislaturemust-step-up-for-water-rights-of-all-californians/\n5https://sports.yahoo.com/samson-ebukam-strongsecond-continues-120006770.html\nar X\niv :2\n30 1.\n08 14\n6v 2\n[ cs\n.I R\n] 1\n0 M\nay 2\n02 3\net al., 2009). However, having a geolocation mentioned in the article doesn\u2019t necessarily mean the article is local and is impacting the local population. We came across multiple issues on relying on geolocation extraction to treat the article as a local news article. These are:\n1. Articles of National Importance: We came across multiple news articles in which the geolocation is mentioned. However, it impacted more than just the local population of the geolocation. These news articles were indifferent to the location name present in them. For instance: \u201cRyvid Anthem Launch Edition Electric Bike Preorders Are Now Open\u201d; this article has Irvine, CA mentioned in its body, but the article impacts more than just the local population of Irvine, CA6.\n2. Articles reported from a location: The geolocation were the locations from which the news article is being reported from but the news is not about that location. For instance: \u201cLaboratory to study dark matter opens 1km under Australian town\u201d7 is a science and space related article with Melbourne and Australia in its body and title. \u201cPrince Harry makes surprise visit to Mozambique ahead of trip back to UK\u201d is apparently talking about a celebrity8. These articles will certainly raise interests from broader readers more than the residents from the localized areas mentioned in the context. Therefore it is limited to just showcasing the news to the local audience.\n3. Difficult to detect geolocation: We also found multiple news articles in which the geolocation wasn\u2019t present. Still, acronyms of those locations are present, for instance: \u201cWWU students receive racist emails encouraging violence against Black students\u201d9, \u201cSPD updates employee policies on tattoos, jewelry, hair styles, gender language\u201d10,\n6https://www.rideapart.com/news/604729/ryvid-anthemlaunch-preorders-open/\n7https://www.pressreader.com/usa/the-guardianusa/20220820/282248079355210\n8https://metro.co.uk/2022/08/18/prince-harry-makessurprise-visit-to-mozambique-ahead-of-trip-back-to-uk17208363/\n9https://www.kiro7.com/news/local/video-wwu-studentsreceive-racist-emails-encouraging-violence-against-blackstudents/ab9d52e5-75e1-4b13-b8b3-6e0c352ee4d4/\n10https://komonews.com/news/local/spd-seattle-policedepartment-employee-policy-tattoo-jewelry-hair-style-beard-\nWWU for Western Washington University, or SPD for Seattle Police Department. Detecting these acronyms and mapping them to the correct location is a difficult task. Techniques (Tahmasebzadeh et al., 2021; Robindro et al., 2017; Bell et al., 2015; Sankaranarayanan et al., 2009) relying on geolocation in the article would miss out on these types of local news articles to be showcased to the right audience.\nDetecting whether an article is a local news article is not only a mere extraction of location names or a certain piece of keywords. It needs a comprehensive systematization of the contextual information, summarization of the article, and then predicting the possibility of the news documents that will attract interest from users in particular location affinity. It is essential to develop an advanced algorithm to understand human language.\nThus, we propose a solution to train a local news classifier. Our major contributions include: (1) serving local news as a two-step process, (2) a weakly supervised framework to gather weakly supervised data along with click statistics of users to train a deep learning model, and (3) an approach to scale the model to non-English languages."
        },
        {
            "heading": "2 Related Work",
            "text": "While this is a first attempt at defining the local news and determining it by developing a deep learning model, other techniques exist that do not precisely differentiate between local and non-local news articles but primarily focuses on showcasing news article based on the geolocation of the user. Tahmasebzadeh et al. (2021); Bell et al. (2015); Robindro et al. (2017), rely on extracting the local news as news articles having any geolocation information present in them. As we mentioned in section 1, not all geolocation-mentioned news articles are local and have a local impact. These studies are theoretical and not in production to serve the geolocation-specific local news. Tahmasebzadeh et al. (2021) proposed using geolocation and structural type extracted from an image to showcase local news of that area. Their geolocation extraction as a classification task makes it difficult to scale it worldwide. Bell et al. (2015), focused on Automatic Speech Recognition (ASR) to convert the audio news from news broadcasting channels to\ngender-language-recruiting-application-officer-king-county\ntextual content to showcase to the users. Robindro et al. (2017) proposed a study where showcasing news articles belonging to the same geolocation as the user would drive user engagement.\nSankaranarayanan et al. (2009) proposed using tweets on the Twitter platform to gather breaking news in the area. Unlike Google News, Bing News, and Yahoo! News, they gather breaking news from User Generated Content (UGC). They also proposed an importance score defining a particular news article\u2019s importance to a neighborhood. Selecting the users manually wouldn\u2019t help scale the system worldwide. This technique was theoretical and not in production.\nIn the field of Journalism, Gon\u00e7alves et al. (2021); V\u00e4\u00e4t\u00e4j\u00e4 et al. (2012) focused on the idea of participatory journalism to help crowdsource the local news to the community\u2019s people. They would rely on the geolocation extracted from the mobile application as the location of the post/news (Alt et al., 2010). Gon\u00e7alves et al. (2021) focused on coping with the challenges local journalism is facing in Portugal. The neighborhood\u2019s people will be encouraged to share photos, videos, and posts about the news, and local journalists will pick it up if it seems a critical issue like crime. These techniques will require the manual intervention of determining the needle in a haystack of posts, figuring out the credibility of the users posting, and it would be difficult to scale it worldwide.\nKliman-Silver et al. (2015) presents a study showcasing the importance of user personalization using Google search results based on user\u2019s geolocation. They showcase that the queries that are indifferent to the location, for instance, \u201cJoe Biden\u201d or \u201cabortion\u201d only show a minor change in the search results for different user locations. However, maximum changes are observed for queries like \u201cStarbucks\u201d and \u201cKFC\u201d. This can further be extended to showcase local news articles based on the precise location of the user (Alt et al., 2010).\nDetecting local news would be the first step in moving forward in the user geolocation-based personalization in the news domain, followed by the geolocation detection and recognition from the article. In this paper, we primarily focus on the first step, i.e., detecting local news articles. If we don\u2019t detect local news and don\u2019t show it to the right audience, it will degrade the user experience."
        },
        {
            "heading": "3 Methodology",
            "text": ""
        },
        {
            "heading": "3.1 Problem formulation",
            "text": "As we mentioned earlier, we define serving local news to the users as a two-step process, (1) detecting whether an article is a local news article, (2) determining the geolocation of the article to be served to the right audience. These two tasks form the basis for informing users about their city/county/state. We define local news as news articles that impact a specific segment of users at the city/county/state level. Our approach to determining local news is to develop a scalable multi-lingual local news classifier trained on a weakly supervised dataset. We will discuss various techniques used to curate the weakly supervised training dataset in Section 4."
        },
        {
            "heading": "3.2 Model Overview",
            "text": "We trained a binary classification model by using XLM-RoBERTa (XLM-R)(Conneau et al., 2019) model as our base model. We chose XLM-R as it is a transformer-based multi-lingual model with pre-learned multi-lingual associations in 100 different languages, allowing us to quickly transfer learn the model learned in the English language to other languages. These multi-lingual associations enable us to scale the classifier to different languages instead of having a separate local classifier model for different languages without losing much on the precision and recall of the English language data. We fine-tuned XLM-R by attaching convolution filters to capture 2, 3, and 4 grams which are eventually connected to a dense layer to calculate the probability of the article being a local news. More details on the model\u2019s scalability to other languages can be found in section 4."
        },
        {
            "heading": "3.3 Prediction Algorithm / Features Used",
            "text": "Four different features were used in the binary classification model for training and inference. These are:\n\u2022 Topics: To capture topics of the article, we ran various off-the-shelf and in-house trained topic models, like important keywords extractor, Term Frequency-Inverse Document Frequency(TF-IDF), and Latent Dirichlet Analysis(LDA).\n\u2022 Tag-line: We use an in-house trained extractive summarization model to extract the tagline from the body of the article.\n\u2022 Title: The title is extracted from the article.\n\u2022 URL Features: Features extracted from the URL proved fruitful in gaining higher precision and recall of the classifier model. The URL is split by \u2018/\u2019. With initial model training and analysis, we found the model is biased towards the publisher names instead of basing the decision on the article\u2019s content. Hence, we filtered out the publisher name (recognized as the domain name in the URL) and all the numbers present in the URL. Some URLs also contain the title of the article. In case 80% of the words overlap between the last segment of the URL, which normally contains the title, and the extracted title of the article, we filter out the title segment of the URL.\nThese features are then concatenated and fed into the Binary Local News classification model for training and inference."
        },
        {
            "heading": "4 Dataset Preparation",
            "text": "To gather weakly supervised labeled training data, we used multiple weak supervision techniques and various knowledge constraints (Shah et al., 2021). The weak supervision techniques are illustrated as follows:\n\u2022 Publisher marked local articles: We used the publisher marked local articles as positives and non-local articles as negatives. However, these labels had a lot of noise. Below are the techniques used to refine the dataset further.\n\u2022 Publisher-to-location affinity: We mined the user click logs and calculated the affinity of the publisher to a location. The steps to calculate the publisher-to-location affinity are (as shown in figure 1):\n\u2013 Gather all the articles published by the publisher in a time frame.\n\u2013 Calculate an aggregated click counts across all articles published by a publisher grouped by the cities where they were showcased.\n\u2013 Pick only those cities which have number of clicks > 50 and calculate it\u2019s click distribution.\n\u2013 Calculate the gap ratio between the values of the city with max distribution and every other city (discussed in Section 4.1).\n\u2013 Choose cities with a gap ratio < 0.25 as the cities the publisher has an affinity for.\n\u2013 Classify the publisher as a strong local publisher if the number of chosen cities in same state is < 10. For instance, KOMO-TV Seattle is a local publisher with an affinity to the cities in King county, Washington, US.\n\u2013 Classify the publisher as a strong nonlocal publisher if the chosen cities are across more than two states. For instance, FOX News is a national news agency having an affinity to various cities across different states like New York, California, Michigan, etc.\n\u2013 Classify the rest publishers as ambiguous, such as Associated Press, because they broadcast both local and non-local news articles.\n\u2013 Label the articles published by strong local and non-local publishers as local and non-local, respectively.\nAfter applying these techniques, the dataset will still have noise, for example, local publishers may also cover national news articles and vice versa. However, by combining all the knowledge constraints, the noise can be further reduced.\nThe publisher-to-location affinity was used to train the binary classification model only on the English data for bootstrapping the data of non-English languages (discussed in Section 4). We came up with article-to-location affinity similar to publisher-to-location affinity to correct the labels and generate an all-language weakly supervised dataset to eventually train a multi-lingual local classifier model.\n\u2022 Distant Supervision: From our raw data, we matched the canonical URL and title of the\nlicensed articles with the URL and the title of the non-licensed articles, respectively. Matching aims to get similar content from non-licensed news and increase the dataset size and diversity, as the features extracted from the non-licensed content would differ.\n\u2022 Bootstrapping: Bootstrapping helped us further reduce the noise from the non-English language training dataset. We trained a binary local news classifier model on the English language data. The Precision-Recall numbers of this model are presented in the Table 3. We used the model trained on English language to detect whether articles from any other languages are local by translating them into English using GPT-3 (Brown et al., 2020). Suppose the article from a different language is already marked as local, however, the new trained model predicts with a high probability that it is non-local (local probability < 0.2), then we corrected the label to non-local and vice versa.\n\u2022 Neural Machine Translations (NMT): Due to the scarcity of news articles in other languages, we had to increase the dataset size to make the model understand the local characteristics of a particular language to avoid label bias in the training dataset (Shah et al., 2019). To increase the dataset size further for languages like German, Italian, Spanish, Japanese, French, Portuguese, Russian, Chinese, and Korean, we used GPT-3 (Brown et al., 2020) for translations. Both front and back translations are used to generate the dataset (as shown in Figure 2):\n\u2013 Front translations: Translate local contents from the English to the target languages. Front translations helped maintain the precision of the model trained on English language data.\n\u2013 Back translations: Translate the data from different languages to English and then back to their original language. This keeps the same semantics of the news articles while the changed words allows the model to expand its vocabulary and improve the precision and recall on nonEnglish data.\nThis resulted noise-reduced weakly supervised dataset was used for the proposed multi-lingual\nbinary classification model."
        },
        {
            "heading": "4.1 Test Dataset",
            "text": "We manually labeled and created UHRS11 hitapp to crowdsource the labeling of news articles from both English and non-English languages. The localnews distribution of the test set across different markets is shown in the table 1.\nGap Ratio: Gap Ratio is the metric that we utilize to filter out outliers in the data based on their distributions. The steps to calculate the gap ratio are as follows:\n1. Calculate the distribution of values for a key/column/index.\n2. Calculate the gap between the distributions of a key with the key having the max distribution. We formulated it as:\nxgap = x\u2212 xmaxDistribution xmaxDistribution\nwhere x is the distribution of a key, xmaxDistribution is the distribution value of the key having the maximum distribution\n11https://prod.uhrs.playmsn.com/UHRS/\nshare, xgap is the gap between the distribution of a particular key, and the key having the maximum distribution value.\n3. Choose those keys whose gap ratio is < 0.25; Increasing this threshold will result in capturing more outliers, decreasing the threshold will make the outlier selection stricter."
        },
        {
            "heading": "5 Experiment Details",
            "text": "We trained the model on an Azure compute server with a 2.4GHz CPU and 1 Tesla V100 GPU. We extracted 5.2 million articles across 10 markets and 6 different languages and then split the dataset into 90%-10% as training and validation sets. Table 2 shows the training data distribution across different markets.\nLanguage w/o NMT w/ NMTData size % of local articles Data size % of local articles\nEnglish 4466533 23.50% 4466533 23.50%\nnon-English 726718 49.41% 952287 60.85% Market Data size % of local articles Data size % of local articles EN-AU 562242 9.26% 562242 9.26% EN-CA 706091 17.80% 706091 17.80% EN-GB 725554 13.22% 725554 13.22% EN-IN 633173 1.40% 633173 1.40% EN-US 1839473 41.70% 1839473 41.70% DE-DE 104080 27.46% 216721 64.69% ES-MX 148324 57.52% 181527 64.78% FR-FR 161953 54.22% 171666 56.29% IT-IT 211942 59.13% 213525 58.88% JA-JP 100419 31.92% 168848 58.86%\nTable 2: Local news training set distribution aggregated and market-breakdown.\nWe didn\u2019t perform hyperparameter tuning and used the default parameters to fine-tune the Roberta-XLM model (Conneau et al., 2019). We used cross-entropy loss as our loss function with Adam optimizer."
        },
        {
            "heading": "6 Results",
            "text": "The model performance on the test set is measured by precision and recall as the metric. Since we want to improve user engagement in the local news segment, our primary focus is improving the precision at the recall cost. We chose Stanford\u2019s CoreNLP NER model (Manning et al., 2014) where geolocation presents in the articles as local news as baseline. Table 3 and 4 depict precision-recall of the baseline and trained local news classifier model. The performances reported are at the prediction score cut-off of 0.5. From the table, the multi-lingual local classifier model outperforms the NER model on precision. Interestingly, on the non-English segment, the NER model has a slightly better recall. This is explainable as local news are\nsupposed to have a geolocation name presented in the article, however the inverse isn\u2019t true. Geolocation presents in the article is only a sufficient condition for an article to be classified as a local content as we introduced in Section 1. Therefore, this local classifier model achieves a strong performance on precision while keeping a similar recall as the NER model.\nThe detailed performance on per market are shown in table 4. The local classifier model trained on the multi-lingual data set with NMT maintains good performance on local news identification in most of the market segments.\nLanguage English Lo-cal Classifier Local Classifier w/o NMT Local Classifier NER Model P R P R P R P R English 0.902 0.518 0.914 0.472 0.883 0.763 0.52 0.747 Non-English - - 0.873 0.298 0.895 0.386 0.687 0.421\nTable 3: Aggregated precision/recall numbers on English and non-English language data sets\nMarket English Lo-cal Classifier Local Classifier w/o NMT Local Classifier NER Model P R P R P R P R en-us 0.937 0.894 0.909 0.909 0.952 0.902 68.27 0.744 en-ca 0.918 0.647 0.904 0.541 0.864 0.836 0.540 0.779 en-gb 0.843 0.654 0.881 0.485 0.881 0.766 0.511 0.636 en-au 1.000 0.260 0.901 0.666 0.875 0.710 0.377 0.826 en-in 0.600 0.044 0.729 0.518 0.801 0.720 0.500 0.770 de-de - - 0.905 0.627 0.923 0.438 0.820 0.532 es-mx - - 0.870 0.643 0.900 0.739 0.468 0.507 es-us - - 0.824 0.628 0.820 0.659 0.588 0.722 fr-ca - - 0.862 0.788 0.895 0.695 0.826 0.329 fr-fr - - 0.878 0.318 0.869 0.220 0.536 0.494 it-it - - 0.969 0.524 0.951 0.530 0.860 0.437 ja-jp - - 0.769 0.109 0.846 0.121 0.000 0.000\nTable 4: Precision/recall numbers per market"
        },
        {
            "heading": "7 Conclusion",
            "text": "In this paper, we propose an integrated pipeline for local news recommendation in two steps (1) detecting local news and (2) determining the geolocation and the impact radius of the article. The first step is the primary focus of this paper. This is achieved by a multi-lingual model incorporated with multiple weakly supervised methods. We conducted comprehensive experiments on a real-world dataset from 6 different languages. The results show that our model is able to detect the local news precisely with the scalability to multiple languages.\nLimitations\nThere is good potential to improve the local news classifier for non-English languages. Lack of clean training data couldn\u2019t help us achieve higher recall in non-English languages. We hope this paper encourages further research in improving the local\nnews classifier in non-English languages to keep people informed."
        },
        {
            "heading": "A Appendices",
            "text": "A.1 Case Studies Several research papers rely on the geolocation information present in the article to detect it as a local news article. Tahmasebzadeh et al. (2021) proposed using geolocation and structural type extracted from an image to showcase local news of that area. However, their focus is on news articles belonging to 14 different structural entities like Skyscraper, Square, Historic Site, Waterfall, Tourist Attraction, Museum, Building, Religious Building, Tower, Castle, Bridge, and Monument. The predicted geolocation and the structure type are used to determine the entity from the Wikidata. Hence, their recall decreases to capture only those entities in the Wikidata. They have used ResNets to determine the geolocation in the image, which they have developed as a classification problem making it difficult to scale it worldwide. The entities determined from the Wikidata are used to retrieve news articles from Event Registry. The news articles would get restricted to the structural entities in an area. They won\u2019t be able to capture the local news articles about crime, real estate, science, politics, and weather, to name a few.\nBell et al. (2015) also presented a technique in which extraction of local news relies only on the\ngeolocation mentioned in the article. Their primary focus was on using Automatic Speech Recognition(ASR) to convert the audio news published by news broadcasting agencies to text and use extractive summarization techniques to extract ten crucial sentences from the text. They also extract the geolocation information using a Named Entity Recognition (NER) model and match it with Open Street Map. However, they do not mention how they would determine if the news article is local. They didn\u2019t mention the process of training the NER model. If they used an off-the-shelf NER (Manning et al., 2014), they would miss out on local articles having geolocation information in the form of acronyms like SFPD, WWU, etc., as we mentioned in the Section 1.\nSankaranarayanan et al. (2009) proposed using tweets(User Generated Content) on the Twitter platform to gather breaking news in the area. They also proposed an importance score defining a particular news article\u2019s importance to a neighborhood. They manually select the users who post the news. They used Na\u00efve Bayes to differentiate it as news or junk. They cluster the tweets and use the geolocation mentioned in the tweet and the user\u2019s location to determine the geolocation foci of the cluster. This foci is considered the geolocation of all the tweets falling in that cluster. The tweet may not have geolocation present; it might not belong to any cluster but will be forced to join a particular cluster and get it geotagged. Or the tweet may belong to a different geolocation than the one it is assigned to in a cluster. It is difficult to scale the framework worldwide as it involves manually selecting the users who post the news. It is difficult to determine the credibility of the users who post on Twitter. This technique is theoretical and not in Production.\nA.2 Use Case\nAnother critical use case of this model across news recommendation products is to identify local news from national publishers and non-local news from local publishers. This provides insights on analyzing the documents and our partners which brings more business impacts for the users and partners. The aggregated precision/recall numbers on these two segments are shown in table 5. As the publisher segments can be treated as one of the priors of the news articles to be classified as local or non-local, for the segment of national publishers, we use the cut-off of 0.7 to report the performance and 0.5 for\nlocal publishers as prediction cut-off. The model shows the high precision on these two segments."
        }
    ],
    "title": "What\u2019s happening in your neighborhood? A Weakly Supervised Approach to Detect Local News",
    "year": 2023
}