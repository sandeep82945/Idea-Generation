{
    "abstractText": "Aim/Purpose To gain insight into the opinions and reviews of Malaysian university students regarding e-learning systems, thereby improving the quality and services of these systems and resolving any problems, concerns, and issues that may exist within the institution. Background This exploratory study examines the students\u2019 perceptions of e-learning in Malaysia based on Sentiment Analysis (SA) to gain a clear insight into their feelings about the quality of e-learning systems and related services in Malaysian universities to determine whether these opinions are positive or negative. Methodology The data was collected from Twitter; the Full Archive Search API Premium v1.1 tire was chosen to access the tweets from November 1, 2019, to December 30, 2020. The R programming language library package \u201crtweet\u201d was applied to access the search API and query the tweets. To classify students\u2019 opinions, sentiment analysis-based Machine Learning (ML) with Support Vector Machine (SVM) was utilized. Rapid Miner, a statistical and data mining tool, was used to determine the sentiment of tweets and the accuracy of the ML algorithm. After preparing the data, RapidMiner was used to pre-process and classify the final 1201 tweets based on sentiment, and National Research Council (NRC) wordStudents\u2019 Perceptions of E-Learning in Malaysian Universities 440 emotion lexicon was used to detect the presence of eight emotions in the tweets. The confusion matrix is used to determine the classifier\u2019s performance. Contribution This research provided evidence for the effective use of sentiment analysis as an indicator that may contribute to the development of educational systems, specifically, e-learning systems in Malaysian universities. Findings Based on the findings, the majority of students have a positive opinion about elearning systems in Malaysian universities. Precisely, the results showed that 65% of sentiments were classified as positive and 35% as negative. Moreover, among the eight emotions, the majority of the tweets expressed a higher level of trust, anticipation, and joy. Recommendations for Practitioners The study findings could help classify the teachers\u2019 strengths and weaknesses graphically based on the students\u2019 positive and negative feedback. These findings would also help decision-makers and educationalists be more aware of students\u2019 feelings (sentiments) and concerns. Thus, using social media sentiment analysis should be encouraged as a valuable source of information that may assist their educational decision-making, e-learning development, and performance evaluation. Recommendations for Researchers The findings may encourage other researchers to apply SA based ML approach and use Twitter as a data source to discover users\u2019 opinions about certain issues in learning and teaching processes. Impact on Society Our study confirmed that social media data could provide valuable and supportive information about educational systems and procedures in e-learning for appropriate decision-making regarding future development and strategies. Future Research Future work can experiment with other classification models and different ML classification algorithms as well as other feature extraction methods and compare the results to find the best accuracy that can improve the classification results",
    "authors": [
        {
            "affiliations": [],
            "name": "Reem Sulaiman"
        }
    ],
    "id": "SP:b01e551c3a493809de0ea1cd3222007df391d136",
    "references": [
        {
            "authors": [
                "A. Abbasi",
                "H. Chen",
                "A. Salem"
            ],
            "title": "Sentiment analysis in multiple languages: Feature selection for opinion classification in web forums",
            "venue": "ACM Transactions on Information Systems (TOIS),",
            "year": 2008
        },
        {
            "authors": [
                "A. Abdelrazeq",
                "D. Jan\u00dfen",
                "C. Tummel",
                "S. Jeschke",
                "A. Richert"
            ],
            "title": "Sentiment analysis of social media for evaluating universities",
            "venue": "Automation, Communication and Cybernetics in Science and Engineering",
            "year": 2016
        },
        {
            "authors": [
                "D. Aggarwal",
                "S. Mittal",
                "V. Bali"
            ],
            "title": "Prediction model for classifying students based on performance using machine learning techniques",
            "venue": "International Journal of Recent Technology and Engineering,",
            "year": 2019
        },
        {
            "authors": [
                "M.N. Al-Nuaimi",
                "O.S. Al Sawafi",
                "S.I. Malik",
                "M. Al-Emran",
                "Y.F. Selim"
            ],
            "title": "Evaluating the actual use of learning management systems during the Covid-19 pandemic: An integrated theoretical model",
            "venue": "Interactive Learning Environments,",
            "year": 2022
        },
        {
            "authors": [
                "H.S. AL-Rubaiee",
                "R. Qiu",
                "K. Alomar",
                "D. Li"
            ],
            "title": "Sentiment analysis of Arabic tweets in e-learning",
            "venue": "Journal of Computer Science,",
            "year": 2016
        },
        {
            "authors": [
                "A.R. Alaei",
                "S. Becken",
                "B. Stantic"
            ],
            "title": "Sentiment analysis in tourism: Capitalizing on big data",
            "venue": "Journal of Travel Research,",
            "year": 2019
        },
        {
            "authors": [
                "N. Altrabsheh",
                "M. Cocea",
                "S. Fallahkhair"
            ],
            "title": "November). Sentiment analysis: towards a tool for analysing real-time students feedback",
            "venue": "In 2014 IEEE 26th international conference on tools with artificial intelligence (pp. 419423)",
            "year": 2014
        },
        {
            "authors": [
                "N. Altrabsheh",
                "M.M. Gaber",
                "Cocea",
                "June"
            ],
            "title": "SA-E: Sentiment analysis for education",
            "venue": "5th KES International Conference on Intelligent Decision Technologies",
            "year": 2096
        },
        {
            "authors": [
                "X. Bai"
            ],
            "title": "Predicting consumer sentiments from online text",
            "venue": "Decision Support Systems,",
            "year": 2011
        },
        {
            "authors": [
                "L. Balachandran",
                "Kirupananda",
                "December"
            ],
            "title": "Online reviews evaluation system for higher education institution: An aspect based sentiment analysis tool",
            "year": 2017
        },
        {
            "authors": [
                "F.F. Balahadia",
                "M.C.G. Fernando",
                "Juanatas",
                "I. C",
                "May"
            ],
            "title": "Teacher\u2019s performance evaluation tool using opinion mining with sentiment analysis",
            "venue": "IEEE region 10 symposium (TENSYMP) (pp. 95-98)",
            "year": 2016
        },
        {
            "authors": [
                "R. Baragash",
                "Aldowah",
                "March"
            ],
            "title": "Sentiment analysis in higher education: A systematic mapping review",
            "venue": "Journal of Physics: Conference Series (Vol. 1860,",
            "year": 1860
        },
        {
            "authors": [
                "J.A. Beverly"
            ],
            "title": "Public relations models and dialogic communication in the Twitterverse: An analysis of how colleges and universities are engaging their public through Twitter [Doctoral disseration, University of Southern Mississippi",
            "year": 2013
        },
        {
            "authors": [
                "U. Bhaumik",
                "D.K. Yadav"
            ],
            "title": "Sentiment analysis using Twitter",
            "venue": "Advances in Intelligent Systems and Computing,",
            "year": 2021
        },
        {
            "authors": [
                "H.H. Binali",
                "C. Wu",
                "Potdar",
                "June"
            ],
            "title": "A new significant area: Emotion detection in e-learning using opinion mining techniques",
            "venue": "In 2009 3rd IEEE international conference on digital ecosystems and technologies (pp. 259-264)",
            "year": 2009
        },
        {
            "authors": [
                "E. Boiy",
                "P. Hens",
                "K. Deschacht",
                "Moens",
                "M. F",
                "June"
            ],
            "title": "Automatic sentiment analysis in on-line text",
            "venue": "In Proceedings of the 11th International Conference on Electronic Publishing ELPUB (pp. 349-360),",
            "year": 2007
        },
        {
            "authors": [
                "G.S. Chauhan",
                "P. Agrawal",
                "Y.K. Meena"
            ],
            "title": "Aspect-based sentiment analysis of students\u2019 feedback to improve teaching\u2013learning process",
            "year": 2019
        },
        {
            "authors": [
                "F. Clarizia",
                "F. Colace",
                "M. De Santo",
                "M. Lombardi",
                "F. Pascale",
                "Pietrosanto",
                "January"
            ],
            "title": "E-learning and sentiment analysis: A case study",
            "venue": "In Proceedings of the 6th international conference on information and education technology (pp. 111-118)",
            "year": 2018
        },
        {
            "authors": [
                "A. Cobo",
                "R. Rocha",
                "C. Rodr\u00edguez-Hoyos"
            ],
            "title": "Evaluation of the interactivity of students in virtual learning environments using a multicriteria approach and data mining",
            "venue": "Behaviour & Information Technology,",
            "year": 2014
        },
        {
            "authors": [
                "C. Coman",
                "L.G. \u021a\u00eeru",
                "L. Mese\u0219an-Schmitz",
                "C. Stanciu",
                "M.C. Bularca"
            ],
            "title": "Online teaching and learning in higher education during the coronavirus pandemic: Students\u2019 perspective",
            "year": 2020
        },
        {
            "authors": [
                "Denecke",
                "April"
            ],
            "title": "Using sentiwordnet for multilingual sentiment analysis",
            "venue": "IEEE 24th international conference on data engineering workshop (pp. 507-512)",
            "year": 2008
        },
        {
            "authors": [
                "V. Dhanalakshmi",
                "D. Bino",
                "Saravanan",
                "A. M",
                "March"
            ],
            "title": "Opinion mining from student feedback data using supervised learning algorithms",
            "venue": "In 2016 3rd MEC international conference on big data and smart city (ICBDSC) (pp. 1-5)",
            "year": 2016
        },
        {
            "authors": [
                "A. Dhir",
                "K. Buragga",
                "A.A. Boreqqah"
            ],
            "title": "Tweeters on campus: Twitter a learning tool in classroom",
            "venue": "Journal of Universal Computer Science,",
            "year": 2013
        },
        {
            "authors": [
                "El-Halees",
                "June"
            ],
            "title": "Mining opinions in user-generated contents to improve course evaluation",
            "venue": "ICSECS",
            "year": 2011
        },
        {
            "authors": [
                "G.G. Esparza",
                "A. de-Luna",
                "A.O. Zezzatti",
                "A. Hernandez",
                "J. Ponce",
                "M. \u00c1lvarez",
                "Jesus Nava",
                "J. D",
                "June"
            ],
            "title": "A sentiment analysis model to analyze students reviews of teacher performance using support vector machines",
            "venue": "In International Symposium on Distributed Computing and Artificial Intelligence (pp. 157-164)",
            "year": 2017
        },
        {
            "authors": [
                "H.E. Froehlich",
                "R.R. Gentry",
                "M.B. Rust",
                "D. Grimm",
                "B.S. Halpern"
            ],
            "title": "Public perceptions of aquaculture: evaluating spatiotemporal patterns of sentiment around the world",
            "venue": "PloS one,",
            "year": 2017
        },
        {
            "authors": [
                "R. Hajrizi",
                "K.P. Nu\u00e7i"
            ],
            "title": "Aspect-based sentiment analysis in education",
            "venue": "domain. arXiv preprint arXiv:2010.01429",
            "year": 2020
        },
        {
            "authors": [
                "O. Harfoushi",
                "D. Hasan",
                "R. Obiedat"
            ],
            "title": "Sentiment analysis algorithms through azure machine learning: Analysis and comparison",
            "venue": "Modern Applied Science,",
            "year": 2018
        },
        {
            "authors": [
                "M.A. Ibrahim",
                "N. Salim"
            ],
            "title": "Sentiment analysis of Arabic tweets: With special reference restaurant tweets",
            "venue": "International Journal of Computer Science Trends and Technology (IJCST),",
            "year": 2016
        },
        {
            "authors": [
                "E. \u0130skender",
                "G.B. Bat\u0131"
            ],
            "title": "Comparing Turkish universities entrepreneurship and innovativeness index\u2019s rankings with sentiment analysis results on social media",
            "venue": "Procedia-Social and Behavioral Sciences,",
            "year": 2015
        },
        {
            "authors": [
                "A. Ituma"
            ],
            "title": "An evaluation of students\u2019 perceptions and engagement with e-learning components in a campus based university",
            "venue": "Active Learning in Higher Education,",
            "year": 2011
        },
        {
            "authors": [
                "A.P. Jain",
                "Dandannavar",
                "July"
            ],
            "title": "Application of machine learning techniques to sentiment analysis",
            "venue": "In 2016 2nd International Conference on Applied and Theoretical Computing and Communication Technology (iCATccT) (pp. 628-632)",
            "year": 2016
        },
        {
            "authors": [
                "Y.H. Jiang",
                "S.S. Javaad",
                "L. Golab"
            ],
            "title": "Data mining of undergraduate course evaluations",
            "venue": "Informatics in Education,",
            "year": 2016
        },
        {
            "authors": [
                "P. Kaewyong",
                "A. Sukprasert",
                "N. Salim",
                "Phang",
                "F. A",
                "October"
            ],
            "title": "The possibility of students\u2019 comments automatic interpret using lexicon based sentiment analysis to teacher evaluation",
            "venue": "In 3rd International Conference on Artificial Intelligence and Computer Science",
            "year": 2015
        },
        {
            "authors": [
                "M. Karthiga",
                "N. Aravindhraj",
                "Priyanka",
                "April"
            ],
            "title": "Machine learning-based sentiment analysis of Twitter data",
            "venue": "In 2019 International Conference on Advances in Computing and Communication Engineering (ICACCE) (pp",
            "year": 2019
        },
        {
            "authors": [
                "M.W. Kearney"
            ],
            "title": "rtweet: Collecting and analyzing Twitter data",
            "venue": "Journal of Open Source Software,",
            "year": 2019
        },
        {
            "authors": [
                "Z. Kechaou",
                "M.B. Ammar",
                "Alimi",
                "A. M",
                "April"
            ],
            "title": "Improving e-learning with sentiment analysis of users\u2019 opinions",
            "venue": "IEEE global engineering education conference (EDUCON) (pp. 1032-1038)",
            "year": 2011
        },
        {
            "authors": [
                "K.J. Kelly"
            ],
            "title": "The effectiveness of Twitter as a communication tool in college recruitment [Doctoral dissertation, Texas A&M University-Kingsville",
            "year": 2013
        },
        {
            "authors": [
                "V. Kharde",
                "P. Sonawane"
            ],
            "title": "Sentiment analysis of twitter data: a survey of techniques",
            "venue": "arXiv preprint arXiv:1601.06971",
            "year": 2016
        },
        {
            "authors": [
                "M. Khatoon",
                "W. Aisha Banu",
                "A.A. Zohra",
                "S. Chinthamani"
            ],
            "title": "Sentiment analysis on tweets",
            "venue": "Software Engineering",
            "year": 2019
        },
        {
            "authors": [
                "R. Kimmons",
                "J.P. Carpenter",
                "G. Veletsianos",
                "D.G. Krutka"
            ],
            "title": "Mining social media divides: An analysis of K-12 US school uses of Twitter",
            "venue": "Learning, media and technology,",
            "year": 2018
        },
        {
            "authors": [
                "R. Kimmons",
                "G. Veletsianos",
                "S. Woodward"
            ],
            "title": "Institutional uses of Twitter in US higher education",
            "venue": "Innovative Higher Education,",
            "year": 2017
        },
        {
            "authors": [
                "V. Kotu",
                "B. Deshpande"
            ],
            "title": "Chapter 9 - Text mining",
            "year": 2015
        },
        {
            "authors": [
                "C.K. Leong",
                "Y.H. Lee",
                "W.K. Mak"
            ],
            "title": "Mining sentiments in SMS texts for teaching evaluation",
            "venue": "Expert systems with applications,",
            "year": 2012
        },
        {
            "authors": [
                "Y.M. Li",
                "T.Y. Li"
            ],
            "title": "Deriving market intelligence from microblogs",
            "venue": "Decision Support Systems,",
            "year": 2013
        },
        {
            "authors": [
                "B. Liu"
            ],
            "title": "Sentence subjectivity and sentiment classification",
            "year": 2012
        },
        {
            "authors": [
                "E. Marrese-Taylor",
                "J.D. Vel\u00e1squez",
                "F. Bravo-Marquez"
            ],
            "title": "A novel deterministic approach for aspectbased opinion mining in tourism products reviews",
            "venue": "Expert systems with applications,",
            "year": 2014
        },
        {
            "authors": [
                "W. Medhat",
                "A. Hassan",
                "H. Korashy"
            ],
            "title": "Sentiment analysis algorithms and applications: A survey",
            "venue": "Ain Shams Engineering Journal,",
            "year": 2014
        },
        {
            "authors": [
                "S.M. Mohammad",
                "P.D. Turney"
            ],
            "title": "Crowdsourcing a word-emotion association lexicon",
            "venue": "Computational Intelligence,",
            "year": 2013
        },
        {
            "authors": [
                "M. Mujahid",
                "E. Lee",
                "F. Rustam",
                "P.B. Washington",
                "S. Ullah",
                "A.A. Reshi",
                "I. Ashraf"
            ],
            "title": "Sentiment analysis and topic modeling on tweets about online education during COVID-19",
            "venue": "Applied Sciences,",
            "year": 2021
        },
        {
            "authors": [
                "T. Mullen",
                "Collier",
                "July"
            ],
            "title": "Sentiment analysis using support vector machines with diverse information sources",
            "venue": "In Proceedings of the 2004 conference on empirical methods in natural language processing (pp. 412418)",
            "year": 2004
        },
        {
            "authors": [
                "M. Munezero",
                "C.S. Montero",
                "M. Mozgovoy",
                "Sutinen",
                "November"
            ],
            "title": "Exploiting sentiment analysis to track emotions in students\u2019 learning diaries",
            "venue": "In Proceedings of the 13th Koli Calling International Conference on Computing Education Research (pp. 145-152)",
            "year": 2013
        },
        {
            "authors": [
                "H. Newman",
                "Joyner",
                "June"
            ],
            "title": "Sentiment analysis of student evaluations of teaching",
            "venue": "In International conference on artificial intelligence in education (pp. 246-250)",
            "year": 2018
        },
        {
            "authors": [
                "R. Oramas Bustillos",
                "R. Zatarain Cabada",
                "M.L. Barr\u00f3n Estrada",
                "Y. Hern\u00e1ndez P\u00e9rez"
            ],
            "title": "Opinion mining and emotion recognition in an intelligent learning environment",
            "venue": "Computer Applications in Engineering Education,",
            "year": 2019
        },
        {
            "authors": [
                "A. Ortigosa",
                "J.M. Mart\u00edn",
                "R.M. Carro"
            ],
            "title": "Sentiment analysis in Facebook and its application to elearning",
            "venue": "Computers in Human Behavior,",
            "year": 2014
        },
        {
            "authors": [
                "N. Oscar",
                "P.A. Fox",
                "R. Croucher",
                "R. Wernick",
                "J. Keune",
                "K. Hooker"
            ],
            "title": "Machine learning, sentiment analysis, and tweets: An examination of Alzheimer\u2019s disease stigma on Twitter",
            "venue": "Journals of Gerontology Series B: Psychological Sciences and Social Sciences,",
            "year": 2017
        },
        {
            "authors": [
                "V.S. Pagolu",
                "K.N. Reddy",
                "G. Panda",
                "Majhi",
                "October"
            ],
            "title": "Sentiment analysis of Twitter data for predicting stock market movements",
            "venue": "In 2016 International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES) (pp. 1345-1350)",
            "year": 2016
        },
        {
            "authors": [
                "B. Pang",
                "L. Lee",
                "S. Vaithyanathan"
            ],
            "title": "Thumbs up? Sentiment classification using machine learning techniques",
            "venue": "arXiv preprint cs/0205070",
            "year": 2002
        },
        {
            "authors": [
                "S. Persada",
                "A. Oktavianto",
                "B. Miraja",
                "R. Nadlifatin",
                "P. Belgiawan",
                "A.A.N. Perwira Redi"
            ],
            "title": "Public perceptions of online learning in developing countries: A study using the ELK stack for sentiment analysis on Twitter",
            "venue": "International Journal of Emerging Technologies in Learning (iJET),",
            "year": 2020
        },
        {
            "authors": [
                "N.A. Rahman",
                "Z.A. Zukarnain",
                "N.A.M. Zain",
                "R. Yusof"
            ],
            "title": "An exploratory sequential sentiment analysis of online learning during the movement control order in Malaysia",
            "venue": "Malaysian Journal of Learning and Instruction,",
            "year": 2021
        },
        {
            "authors": [
                "Y.B. Rajabalee",
                "M.I. Santally"
            ],
            "title": "Learner satisfaction, engagement and performances in an online module: Implications for institutional e-learning policy",
            "venue": "Education and Information Technologies,",
            "year": 2021
        },
        {
            "authors": [
                "C. Ramasubramanian",
                "R. Ramya"
            ],
            "title": "Effective pre-processing activities in text mining using improved porter\u2019s stemming algorithm",
            "venue": "International Journal of Advanced Research in Computer and Communication Engineering,",
            "year": 2013
        },
        {
            "authors": [
                "C.L. Santos",
                "P. Rita",
                "J. Guerreiro"
            ],
            "title": "Improving international attractiveness of higher education institutions based on text mining and sentiment analysis",
            "venue": "International Journal of Educational Management,",
            "year": 2018
        },
        {
            "authors": [
                "F. Seraji",
                "H.A. Kasani",
                "S. Aghazadeh",
                "S.S. Rahnamoo",
                "R. Bakhtiari"
            ],
            "title": "Online-only learning challenges in higher education in COVID-19 era: A research synthesis",
            "venue": "Quarterly of Iranian Distance Education Journal (Articles in Press)",
            "year": 2022
        },
        {
            "authors": [
                "M.S. Shail"
            ],
            "title": "Using micro-learning on mobile applications to increase knowledge retention and work performance: A review of literature",
            "venue": "Cureus, 11(8),",
            "year": 2019
        },
        {
            "authors": [
                "L. Shen",
                "M. Wang",
                "R. Shen"
            ],
            "title": "Affective e-learning: Using \u201cemotional\u201d data to improve learning in pervasive learning environment",
            "venue": "Journal of Educational Technology & Society,",
            "year": 2009
        },
        {
            "authors": [
                "M. Shoeb",
                "J. Ahmed"
            ],
            "title": "Sentiment analysis and classification of tweets using data mining",
            "venue": "International Research Journal of Engineering and Technology (IRJET),",
            "year": 2017
        },
        {
            "authors": [
                "C. Sindhu",
                "D.V. Vyas",
                "Pradyoth",
                "April"
            ],
            "title": "Sentiment analysis based product rating using textual reviews",
            "venue": "In 2017 International conference of Electronics, Communication and Aerospace Technology (ICECA) (Vol",
            "year": 2017
        },
        {
            "authors": [
                "K. Singhal",
                "B. Agrawal",
                "N. Mittal"
            ],
            "title": "Modeling Indian general elections: Sentiment analysis of political Twitter data",
            "venue": "Information Systems Design and Intelligent Applications (pp",
            "year": 2015
        },
        {
            "authors": [
                "M. Sivakumar",
                "U.S. Reddy"
            ],
            "title": "2017, November). Aspect based sentiment analysis of students opinion using machine learning techniques",
            "venue": "Paper presented at the 2017 International Conference on Inventive Computing and Informatics (ICICI) (pp. 726-731)",
            "year": 2017
        },
        {
            "authors": [
                "D. Song",
                "H. Lin",
                "Z. Yang"
            ],
            "title": "September). Opinion mining in e-learning system. Paper presented at the 2007 IFIP international conference on network and parallel computing workshops",
            "venue": "(NPC",
            "year": 2007
        },
        {
            "authors": [
                "A.R. Sulthana",
                "A. Jaithunbi",
                "L.S. Ramesh"
            ],
            "title": "Sentiment analysis in twitter data using data analytic techniques for predictive modelling",
            "venue": "Journal of Physics: Conference Series,",
            "year": 2018
        },
        {
            "authors": [
                "V. Vyas",
                "V. Uma"
            ],
            "title": "An extensive study of sentiment analysis tools and binary classification of tweets using rapid miner",
            "venue": "Procedia Computer Science,",
            "year": 2018
        },
        {
            "authors": [
                "C.T. Weber",
                "S. Syed"
            ],
            "title": "Interdisciplinary optimism? Sentiment analysis of Twitter data",
            "venue": "Royal Society Open Science,",
            "year": 2019
        },
        {
            "authors": [
                "M.R. Yaakub",
                "F.Z.M. Zaki",
                "M.I.A. Latiffi",
                "S. Danby"
            ],
            "title": "December). Sentiment analysis of preschool teachers\u2019 perceptions on ICT use for young children",
            "venue": "Paper presented at the 2019 IEEE International Conference on Engineering, Technology and Education (TALE) (pp. 1-6)",
            "year": 2019
        },
        {
            "authors": [
                "J. Zhou",
                "Ye",
                "J.-m"
            ],
            "title": "Sentiment analysis in education research: A review of journal publications",
            "venue": "Interactive Learning Environments,",
            "year": 2020
        },
        {
            "authors": [
                "Z.A. Zulkifli",
                "N. Aznan"
            ],
            "title": "machine: A COVID-19 case study",
            "venue": "Journal of Islamic, Social, Economics and Development,",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "Accepting Editor Lalitha Jonnavithula \u2502Received: May 11, 2022\u2502 Revised: August 16, September 12, September 15, September 16, 2022 \u2502 Accepted: September 19, 2022. Cite as: Baragash, R. S., Aldowah, H., & Umar, I. N. (2022). Students\u2019 perceptions of e-learning in Malaysian universities: Sentiment analysis based machine learning approach. Journal of Information Technology Education: Research, 21, 439-463. https://doi.org/10.28945/5024\n(CC BY-NC 4.0) This article is licensed to you under a Creative Commons Attribution-NonCommercial 4.0 International License. When you copy and redistribute this paper in full or in part, you need to provide proper attribution to it to ensure that others can later locate this work (and to ensure that others do not accuse you of plagiarism). You may (and we encourage you to) adapt, remix, transform, and build upon the material for any non-commercial purposes. This license does not permit you to use this material for commercial purposes.\nregarding e-learning systems, thereby improving the quality and services of these systems and resolving any problems, concerns, and issues that may exist within the institution.\nBackground This exploratory study examines the students\u2019 perceptions of e-learning in Malaysia based on Sentiment Analysis (SA) to gain a clear insight into their feelings about the quality of e-learning systems and related services in Malaysian universities to determine whether these opinions are positive or negative.\nMethodology The data was collected from Twitter; the Full Archive Search API Premium v1.1 tire was chosen to access the tweets from November 1, 2019, to December 30, 2020. The R programming language library package \u201crtweet\u201d was applied to access the search API and query the tweets. To classify students\u2019 opinions, sentiment analysis-based Machine Learning (ML) with Support Vector Machine (SVM) was utilized. Rapid Miner, a statistical and data mining tool, was used to determine the sentiment of tweets and the accuracy of the ML algorithm. After preparing the data, RapidMiner was used to pre-process and classify the final 1201 tweets based on sentiment, and National Research Council (NRC) word-\nemotion lexicon was used to detect the presence of eight emotions in the tweets. The confusion matrix is used to determine the classifier\u2019s performance.\nContribution This research provided evidence for the effective use of sentiment analysis as an indicator that may contribute to the development of educational systems, specifically, e-learning systems in Malaysian universities.\nFindings Based on the findings, the majority of students have a positive opinion about elearning systems in Malaysian universities. Precisely, the results showed that 65% of sentiments were classified as positive and 35% as negative. Moreover, among the eight emotions, the majority of the tweets expressed a higher level of trust, anticipation, and joy.\nRecommendations for Practitioners\nThe study findings could help classify the teachers\u2019 strengths and weaknesses graphically based on the students\u2019 positive and negative feedback. These findings would also help decision-makers and educationalists be more aware of students\u2019 feelings (sentiments) and concerns. Thus, using social media sentiment analysis should be encouraged as a valuable source of information that may assist their educational decision-making, e-learning development, and performance evaluation.\nRecommendations for Researchers\nThe findings may encourage other researchers to apply SA based ML approach and use Twitter as a data source to discover users\u2019 opinions about certain issues in learning and teaching processes.\nImpact on Society Our study confirmed that social media data could provide valuable and supportive information about educational systems and procedures in e-learning for appropriate decision-making regarding future development and strategies.\nFuture Research Future work can experiment with other classification models and different ML classification algorithms as well as other feature extraction methods and compare the results to find the best accuracy that can improve the classification results\nKeywords e-learning systems, sentiment analysis, machine learning, university student"
        },
        {
            "heading": "INTRODUCTION",
            "text": "E-learning has become one of the most effective approaches for supporting students learning, especially during the current COVID-19 pandemic (AL-Nuaimi et al., 2022). Due to the COVID-19 pandemic, educational institutions were forced to adopt e-learning to maintain academic activities. Students play a key role in the educational systems; their reviews and opinions are important to improve the institutional problems, matters, and issues (Seraji et al., 2022). Educational institutions are progressively interested in knowing students\u2019 opinions about their institution, learning quality, teaching evaluation, and other services they provide to students for future improvements (Baragash & Aldowah, 2020; Kaewyong et al., 2015). On the other hand, the increasing competition between universities has led students to conduct in-depth analysis for choosing where to study. Since students are unable to visit every university before making a decision, they are highly influenced by what former students write on social media sites (Abdelrazeq et al., 2016). Students freely express their opinions and share their experiences on social media, which can strongly impact on the reputation of universities and may affect their chances of selection. Thus, knowing students\u2019 opinions allows universities to gain a more comprehensive view of the their services quality and to address some important aspects that may be relevant to their target students (Balachandran & Kirupananda, 2017).\nMost campus-based universities, including Malaysian universities, are incorporating e-learning into student learning as an essential component of higher education in order to improve their learning environment and increase potential students (Clarizia et al., 2018). Therefore, universities must gain deep knowledge about students\u2019 perceptions, opinions, and sentiments towards their learning services, specifically e-learning that influences their decision-making when it comes to choosing their university (Dhanalakshmi et al., 2016; Rajabalee & Santally, 2021).\nE-learning mainly refers to the use of computer technologies and information systems to build and design learning experiences, as well as to improve learning and teaching processes in a non-traditional learning environment. Hence, as a prerequisite for developing effective e-learning systems, it is imperative to have certain knowledge of students\u2019 opinions and build an evaluation based on their perceptions (Coman et al., 2020). Sentiment analysis (SA) is a non-intrusive analysis method that enables us to identify and evaluate students\u2019 opinions, reactions, impressions, emotions, and perspectives in text. There is a growing body of published research on SA because it is pervasive across industries and has become one of the most effective topics in numerous fields, including education (Zhou & Ye, 2020). The application of SA in educational settings holds many potentials for improving the learning opportunities and the communication pathways between universities and their students. In the context of e-learning, the SA method helps to study students\u2019 opinions and sentiments (emotions) to explore their experience and satisfaction about the effectiveness of e-learning systems and the quality of related services. This data about the students emotions towards the e-learning can act as feedback for the university decision-makers (Ortigosa et al., 2014). It can significantly reflect students\u2019 learning status, providing the theoretical basis necessary to pursue and review the future plans for learning and teaching practices.\nSocial media platforms such as Twitter, Facebook, Tumblr, and Instagram are potential sources of student opinions because students primarily use them to express their emotions, reactions, and daily activities (Khatoon et al., 2019). This increasing prevalence of social media among students has produced a vast amount of data that universities can use to their advantage by analyzing student opinions and learning experiences (AL-Rubaiee et al., 2016). Unlike to traditional methods such as questionnaires, non-intrusive analysis techniques such as SA will help the educational institution to understand and analyze the actual perceptions and opinions being posted by students to \u201cpositive\u201d and \u201cnegative\u201d. Institutions can benefit greatly from the ability to detect and comprehend what students like and dislike about online systems, services, courses, instructors, learning and teaching methods (Hajrizi & Nu\u00e7i, 2020). However, not much work was carried out in applying SA in the educational context, particularly in analyzing students\u2019 perceptions and feelings towards e-learning in Malaysia to gain useful knowledge about their opinions and reviews in terms of the quality of such systems and related services (Zhou & Ye, 2020; Zulkifli & Aznan, 2022). Therefore, this study applied SA to investigate students\u2019 opinions and emotions towards the e-learning system in Malaysian universities and its related services based on their Twitter posts.\nThe remainder of this paper is organized as follows: the next section provides the study\u2019s literature review. This is followed by a description of the study\u2019s research methodology, and then a presentation of the results and discussion of the findings. Finally, the conclusion and future works are presented."
        },
        {
            "heading": "LITERATURE REVIEW",
            "text": "Since the early 2000s, SA or opinion mining has been an active research field (Khatoon et al., 2019). Although earlier studies on SA have focused on the classification of product reviews (Denecke, 2008; Marrese-Taylor et al., 2014; Mullen & Collier, 2004; Pang et al., 2002; Sindhu et al., 2017), SA has only recently received a great interest from the academic community. This section reviews the existing literature to shed light on SA-based ML and its application in the higher education context.\nSENTIMENT ANALYSIS BASED MACHINE LEARNING"
        },
        {
            "heading": "Sentiment analysis-based ML: \u201cThe concept\u201d",
            "text": "Sentiment analysis (SA) is a field of text mining, Natural Language Processing (NLP), and computational linguistics (Bai, 2011). It refers to a set of techniques that analyze opinions (text data) and sort them into positive, negative, or neutral sentiments. The analysis of these opinions can help institutions and companies gain insight into how individuals think about their services, product features, quality, and brands whenever they need to make a decision (Medhat et al., 2014). The studies of SA have proven its usefulness for understanding students\u2019 attitudes and perceptions for educational purposes, such as evaluation of teacher performance (Balahadia et al., 2016; Esparza et al., 2017), elearning (Binali et al., 2009; Clarizia et al., 2018; Ortigosa et al., 2014; Song et al., 2007), teaching evaluation (Chauhan et al., 2019; Leong et al., 2012; Newman & Joyner, 2018), students\u2019 learning (Munezero et al., 2013), students\u2019 feedback (Altrabsheh et al., 2014; Chauhan et al., 2019; Dhanalakshmi et al., 2016), universities evaluation (Abdelrazeq et al., 2016; Santos et al., 2018), universities ranking (\u0130skender & Bat\u0131, 2015), improving international universities attractiveness (Santos et al., 2018), learning tools usage evaluation (Dhir et al., 2013), as a news platform (Kimmons et al., 2017), and recruitment tool (Kelly, 2013).\nThere are three main approaches for SA classification, including machine learning-based approach (ML), which applies several popular machine learning algorithms, the lexicon-based approach, which uses a dictionary containing positive and negative words to identify the sentiment polarity, and hybrid approach, which is a combination of both approaches, ML and lexicon-based approach (Jain & Dandannavar, 2016). The Lexicon-based approach has a drawback that the strength of sentiment classification depends on the lexicon size, and once the lexicon size increases, this approach becomes time-consuming and more erroneous (Jain & Dandannavar, 2016). While the ML learning approach is based on the popular ML algorithms to solve the SA as a common text classification problem that takes advantage of syntactic and linguistic features.\nAn efficient and effective data classification procedure is SA classification-based ML algorithms that accurately predict the target category for each case in the data. The classification is performed using a specific algorithm called a classifier (Shoeb & Ahmed, 2017); there are different algorithms such as support vector machines (SVM), Na\u00efve Bayes (NB), maximum entropy (ME), K Nearest Neighbor (KNN), and Bayesian networks (BN).\nAlso, there are many steps for performing SA classification on Twitter data using ML algorithms, as shown in Figure 1. Once the dataset is collected, the first step is to pre-process the data (Tweets) using NLP-based techniques. The next step is the feature extraction to extract sentiment related features. Lastly, a model is trained using ML classifiers and the model performance can be tested based on accuracy, precision, recall, and F-measure (F1-score) (Jain & Dandannavar, 2016).\nData Collection\nPreprocessing\nFeature\nExtraction\nFeature Matrix Evaluation ML-Classifier\nFigure 1. SA Classification based ML approach\nThe bag-of-words method, which is commonly used for SA, assumes word independence and disregards the importance of subjective and semantic information in the text, resulting in feature space with high dimensionality. ML algorithms are able to reduce this high-dimensional feature space by using feature selection techniques that identify important features only by removing the noisy and irrelevant features. Therefore, ML-based SA approach is gaining prominence in today\u2019s research field.\nFurthermore, there are two methods for sentiment classification using ML approaches, supervised learning and unsupervised learning methods. The supervised learning method uses a labeled training dataset (inputs) that enables the classification model to learn using classification algorithms and predict the value of new inputs. Alternatively, the unsupervised learning method does not use a labeled dataset because it is difficult to find these labels (Medhat et al., 2014). Thus, it is trained using datasets involving a set of inputs (Oramas Bustillos et al., 2019). The supervised methods are more popular and widely used for text classification, which is the focus of this study, and they rely on training and test datasets. The training dataset is used to learn the dataset, while the testing dataset is used to verify the algorithm\u2019s performance (Harfoushi et al., 2018).\nBased on the above explanations, the goal of SA based ML approach is to find opinions, identify sentiments, and classify polarity (Medhat et al., 2014). The most common type of SA is \u2018polarity detection,\u2019 which includes classifying statements as positive, neutral, or negative and can thus be considered a classification process, as illustrated in Figure 1."
        },
        {
            "heading": "Sentiment analysis based ML: \u201cPrevious studies\u201d",
            "text": "Much research has been conducted recently in the field of SA and ML by classifying users\u2019 perceptions and opinions into positive or negative sentiments. For instance, SA-based ML can be used in the educational context to monitor and evaluate students\u2019 performance, assist lecturers to improve the effectiveness of their teaching, understand the student mindset, get feedback from students about learning and teaching processes, help the students to improve their studies, and evaluate performance and ranking of the universities (Sivakumar & Reddy, 2017). The literature review showed that SA based ML could be applied to improve educational institutions, specifically universities. In this regard, Altrabsheh et al. (2013) conducted a study to analyze students\u2019 real time feedback from Twitter using SA and ML algorithms. The findings of the study indicated that SA for students\u2019 real-time feedback is an effective method for lecturers to enhance their teaching. Likewise, Dhanalakshmi et al. (2016) carried out a study to explore opinion mining to find the polarity of student feedback based on predefined features of learning and teaching using a combination of ML algorithms and NLP techniques on student feedback data. The use of the combination algorithms was to compare the results to reach better performance with respect to various evaluation measures. As a result, two SA models based on the SVM and NB algorithms were proposed with the aim of extracting useful data about users\u2019 sentiments and reactions in critical situations.\nTo develop e-learning systems that effectively meet the needs and requirements of users, it is crucial for the developers of e-learning systems to understand students\u2019 opinions and evaluations of the services provided. Gaining the users\u2019 perceptions at an early stage helps to reduce future risks and improve development strategies. In this respect, Song et al. (2007) applied ML algorithms to identify the sentiment of opinions from the social media pages in which users discuss their personal opinions and their evaluation of the services. The evaluation process was performed using the SVM algorithm to train the models that help to determine the opinions and to identify the content-value pair. The findings indicated that e-learning system development would benefit greatly from the application of ML with a high level of analysis precision to extract opinions and SA. Furthermore, Shen et al. (2009) applied SA-based SVM to explore the emotion evolution in order to predict emotions in elearning and how emotion feedback can be used to enhance learning experiences and proposed an effective e-learning model. According to the findings of the emotion revolution, the two most important and frequently occurring emotions in e-learning are engagement and confusion. The study\u2019s findings also suggested that using emotional data could improve e-learning platforms and allow\nlecturers to better understand the emotional states of distant learners. In addition, to identify problems that may arise during system operation in a timely manner and to address them immediately, Kechaou et al. (2011) carried out a study to examine the structure of e-learning blogs and forums. They proposed a learning-based sentiment classification algorithm to classify students\u2019 opinions of the system service into positive and negative to improve its performance. Based on the SVM method, three commonly used feature selection methods involving Information Gain, Mutual Information, and chi-square statistics were examined and developed. According to the study\u2019s conclusion, such an analysis could help improve the e-learning system by providing a better understanding of users\u2019 opinions.\nOn the other hand, Ibrahim and Salim (2016) carried out a study on the SA of Arabic tweets at document level. Different classifiers like NB, SVM, and KNN were applied on the data to find the best result. The study\u2019s findings showed that SVM is the best classifier to use with Arabic tweets. SVMs were also used by Li and Li (2013) as a sentiment polarity classifier, and they proposed a mechanism that provides a compact numeric summarization of opinions on Twitter or any micro-blogs platforms. In addition, Boiy et al. (2007) compared the performance of three classifiers for SA-based online text classification including SVM, NB multinomial, and ME classifier to comprehend how individuals feel about specific topics. The results revealed that there was no statistically significant difference in the performance of the three classifiers.\nThus, SVM was chosen among the studies due to its high robustness in learning many different tasks, its power of discrimination, and its ability to provide accurate results with optimality. According to Kotu and Deshpande (2015), SVM\u2019s main advantages include application flexibility, robustness (small changes in data do not necessitate expensive remodeling), and overfitting resistance (the boundaries of classes within datasets can be appropriately described with only a few support vectors). According to previous research, the SVM algorithm has high precision and accuracy when compared to other algorithms, and SVM classifiers have achieved high classification performance on sentiment classification tasks of various types of data such as web forum postings, movie reviews, and social media platform data (Abbasi et al., 2008; AL-Rubaiee et al., 2016; Kharde & Sonawane, 2016; Ortigosa et al., 2014; Vyas & Uma, 2018; Weber & Syed, 2019). Hence, the SVM model was chosen for this study to analyze and classify students\u2019 opinion sentiments due to its high level of classification accuracy and verified efficiency (Karthiga et al., 2019).\nTWITTER SENTIMENT ANALYSIS Social media is an umbrella term for a collection of web-based applications, such as Twitter, Facebook, and Pinterest that allow an individual to post or share views, ideas, sentiments, and opinions from anywhere at any time (Khatoon et al., 2019). Twitter is a microblogging platform that allows individuals worldwide to post and share their opinions and views on different issues daily. This interaction process between thousands of users has resulted in a massive amount of data being generated daily (Weber & Syed, 2019). This data flow can provide an opportunity to study group behavior on a large scale (Bhaumik & Yadav, 2021). Thus, it is increasingly being acknowledged that Twitter data can provide valuable information and insights into individuals\u2019 opinions, health, and lives (Weber & Syed, 2019). Therefore, Twitter data SA has been applied across various topics and disciplines such as computer science, medical, and environmental sciences (Froehlich et al., 2017; Kharde & Sonawane, 2016; Oscar et al., 2017). Due to the breadth of the literature on social media platforms, the focus of this study will be on the pertinent literature on the use of Twitter data, especially in an educational context. Twitter data used in educational technologies has only increased in recent years (Kimmons et al., 2018). The usage of Twitter data by educational institutions is varied and some researchers discussed how Twitter data could be used as a public relations tool (Beverly, 2013), to investigate the effectiveness of e-learning (Clarizia et al., 2018; Mujahid et al., 2021), to evaluate teaching (Chauhan et al., 2019; Newman & Joyner, 2018), to classify feedback (Chauhan et al., 2019; Dhanalakshmi et al., 2016), and to evaluate universities (Abdelrazeq et al., 2016; Santos et al., 2018). Twitter has become\nan essential component of contemporary educational institutions, due to its concise communication method and following functionality. Hence, analyzing students\u2019 opinions on this platform may help decision-makers gain a better understanding of how they perceive the learning and teaching processes to improve future plans.\nSENTIMENT ANALYSIS IN EDUCATIONAL CONTEXT (RELATED STUDIES) Researchers have used social media SA, particularly Twitter, to gauge public opinion on a wide range of topics, from e-commerce and marketing to tourism and politics (Alaei et al., 2019; Karthiga et al., 2019; Pagolu et al., 2016; Singhal et al., 2015). This section focuses on educational context-related studies that provide clear insight into the application of SA and its benefits. According to the literature, SA can be used in educational settings to help instructors improve their teaching effectiveness and students improve their learning (Sivakumar & Reddy, 2017). Universities, schools, and other educational institutions are becoming increasingly interested in implementing quality measures that provide indicators for evaluation and funding decisions (Santos et al., 2018). Administrators are interested in the opinions of the public and students regarding their institution, learning quality, teaching evaluation, and other services provided to students to make future improvements (Baragash & Aldowah, 2020; Kaewyong et al., 2015).\nNumerous studies are interested in tweets SA in various educational settings. For example, Abdelrazeq et al. (2016) used SA to analyze the Twitter platform as the source of data for evaluating universities; the tweets were collected from nine universities in Germany. Their findings established that Twitter sentiments could support the universities ranking system by analyzing tweets\u2019 statements and opinions of students and teachers in higher education systems. An additional study by Kimmons et al. (2017) employed data mining and quantitative methods to collect and analyze Twitter accounts of higher education in the US. They concluded that institutions should reconsider their use of Twitter and seek more meaningful ways to promote their educational communities and society. Moreover, a study was carried out by Persada et al. (2020) to explore the public perceptions of online learning based on the post reading activities on Twitter platform. The findings revealed a positive student attitude toward online learning and provided some insight into student preferences regarding e-learning applications. In addition, researchers utilized SA to collect and investigate student opinions in order to identify information regarding the student learning experience and the teacher\u2019s performance. For instance, Balahadia et al. (2016) used SA tools and ML algorithm NB to identify the strengths and weaknesses of the teaching staff based on positive and negative feedback from the students. While Newman and Joyner (2018) used SA tools named VADER (Valence Aware Dictionary and sentiment Reasoner) to analyze student evaluations of teaching on a course by comparing the positive and negative valences and identifying frequently used keywords in comments. The findings highlighted the significance of SA as a tool for analyzing student evaluations of teaching, as it provides a quick overview of positive and negative factors in a single course.\nAlthough there are many e-learning issues that can be dealt with using SA-based ML, little research on SA has primarily concentrated on e-learning, with scant research conducted on its effects on education policymaking (AL-Rubaiee et al., 2016; Munezero et al., 2013; Newman & Joyner, 2018). For instance, SA-based ML can be applied to study emotional reactions toward a given system or task (Balachandran & Kirupananda, 2017), evaluate students interactivity in e-learning environments (Cobo et al., 2014), evaluate online courses (El-Halees, 2011; Jiang et al., 2016), evaluate e-learning tools and services (Caminero et al., 2013; Ituma, 2011), and evaluate teaching and learning strategies (Kaewyong et al., 2015; Leong et al., 2012; Song et al., 2007).\nThe focus of this study is on students\u2019 sentiment towards e-learning systems in Malaysian universities to gain knowledge about students\u2019 opinions and reviews. In the Malaysian context, the majority of existing studies have primarily focused on users\u2019 emotions during the Covid-19 pandemic. For instance, in a study conducted by Zulkifli and Aznan (2022), the SA method was applied to analyze Twitter users\u2019 sentiments regarding online teaching in an e-learning system during the Covid-19\npandemic. The study found that the majority of Twitter users had positive reviews about the online teaching and that the SVM algorithm was the best classifier in terms of accuracy compared to other algorithms. While SA using WhatsApp data was performed at a public university in Malaysia by Rahman et al. (2021) to analyze students\u2019 sentiments about their routine changes in learning during the Covid-19 pandemic, the results of the study showed that students had neutral sentiments during the pandemic period, reflecting a sense of ignorance among students and an unwillingness to engage in fully online learning. The results also showed that the students had a negative sentiment towards online learning on a large scale during this period. In contrast, the study by Yaakub et al. (2019) used SA to understand the early childhood teachers\u2019 perception of young students\u2019 use of ICT and the dataset was obtained from two countries, Malaysia and Australia. The results showed that most teachers had a positive feeling about the benefits of ICT use. There is a dearth of research on SA for social media in university environments and the education field in Malaysia. Consequently, the main contribution of this study is to utilize SA as a supportive indicator for evaluating e-learning in Malaysian universities by identifying \u201cpositive\u201d and \u201cnegative\u201d sentiments to comprehend students\u2019 e-learning experiences."
        },
        {
            "heading": "METHODOLOGY",
            "text": "In this study, sentiment classification is employed based on the ML approach using Rapid Miner software to classify students\u2019 perceptions of the e-learning system in Malaysian universities into two classes: positive and negative. The classification of Twitter data using ML algorithms requires multiple steps. The first step, following the collection of the dataset, is to pre-process the data using NLPbased techniques. Next, sentiment-related features are extracted through feature extraction. Finally, ML classifiers are used to train a model, and the model\u2019s performance can be evaluated using accuracy, precision, recall, and the F-measure (F1-score) (Jain & Dandannavar, 2016), and the confusion matrix is used to determine the classifier\u2019s performance on the test data that defines the true values of the actual positives and actual negatives. The methodology process is described in Figure 2, and each step is explained in detail in the following subsections.\nDATA COLLECTION Twitter Application Programming Interface (API) provides many methods to access this data with restrictions due to privacy and security issues. Twitter has two APIs for data access. One is the Twitter REST API that allows the developers to access core Twitter data that includes status data, user information, and updated timelines. The other one is the Streaming API that provides near real-time high-volume access to Tweets in sampled and filtered form (Sulthana et al., 2018).\nSearch API, which is part of Twitter\u2019s REST API, offers three tiers: Standard, Premium, and Enterprise. Unlike the Twitter API standard tire, the premium Search provides access to the past 30 days of Twitter data or the full history of Twitter data dependent on the endpoint selected; the Full-archive endpoint provides access to Tweets since the first tweet posted in 2006, up to 500 tweets per data request with rate limit of 50 per month (\u201cSearch API: Premium,\u201d n.d.). In this study, the Full Archive Search API Premium v1.1 tire was chosen to access the tweets from November 1, 2019, to December 30, 2020. The R programming language library package \u201crtweet\u201d was applied to access the search API and query the tweets (Kearney, 2019), using RStudio1.2.1335, the integrated development environment for R.\nKEYWORDS The raw data was collected by specifying a set of keywords and metadata such as language, location, and date range. The query keywords and specific hashtags that were used to collect tweets related to students\u2019 perceptions of e-learning are \u201conline learning\u201d, \u201c#online_learning\u201d, \u201celearning\u201d, and \u201c#elearning\u201d combined with additional keywords, \u201cuniversity\u201d and \u201cuniversities\u201d. These keywords were chosen because they are most commonly associated with e-learning, and in order to obtain as much data as possible when combined with additional filtering of keywords and metadata.\nIn this study, data collected between November 1, 2019, and December 30, 2020, included Englishlanguage tweets that originated from Malaysia. The search was for approximately one month to collect the data in different periods of time, as shown in Figure 3; for each period, the search was run many times until observing meaningful data. Four datasets were extracted separately from Twitter\nand combined into one dataset, resulting in 15003 English tweets. The returned data contain user information, the tweet content, the user\u2019s status, and the unique ID associated with the tweet, location, user data, and more. Retweets were not included in the dataset to avoid bias in the results, as the model will be biased if the dataset used to train the model contains several tweets with the same text.\nFor initial pre-processes, R programming \u201ctm\u201d package was used to clean the irregularities from the text data by removing links, numbers, special characters like /, @ and | and unnecessary white spaces. After the initial pre-process, the duplicate, unclear, and irrelevant posts were removed, resulting in a final sample of 9462 tweets. These removed tweets also included the tweets that shared photos and videos but did not contain much text; tweets that were not from a specific person but were essentially advertisements for news or companies, and the tweets that were not from students. In addition, four experts with five years of experience and above in e-learning were invited to assess the text data. The experts identified about 2337 tweets that were not discussing any aspects of e-learning systems or not from students\u2019 perspectives.\nFigure 3. Data Selection Process\nN= 7125\nTo RapidMiner for Sentiment Classification\n(Final N =1201 Tweets)\nN1= 4299\nN2= 2967\nN3= 3871\nData collection from Twitter from November 1, 2019 to December 30, 2020\nManually Filter Data\n(N = 5541)\nUsing Text Analytics Tool\n(N= 5924)\nExperts Data Assessment\n(N=2337)\nN= 9462\nN1= Nov. 2019-Jan. 2020\nN2= Feb.-April 2020\nN3= May-Aug. 2020\nN4= Sep.-Dec. 2020\nDATA ANALYSIS TOOLS There are numerous tools for processing and analyzing data to gain insight into online content for a specific purpose. Rapid Miner was ultimately selected to analyze the data (Tweets) after being compared to tools such as Weka and R. The selection process was based on its efficiency, ease of use, and availability of many features that differentiate it from the other available tools. It is an open-source software and data mining tool used in data science. It provides an integrated environment that can be used in ML, data preparation (pre-processing), text mining, modelling, predictive analytics, evaluation, and deployment. It also provides the flexibility to create ensemble models using its operators. For this purpose, Rapid Miner offers more than 1000 drag-and-drop operators that can be used easily to implement data mining and SA operations. It comprises several operators, and each operator has a specific use and requirements. For instance, the Read Excel operator is used to input data (read the data in excel file). Also there are several operators that are used in this study to prepare and classify the data, as will be explained in the data pre-processing section. Finally, the text data was captured from Twitter, filtered, evaluated, and stored in a spreadsheet having about 1201 rows.\nDATA PRE-PROCESSING The quality of the final classification of SA is highly dependent on the preparation of the data prior to classification (Ramasubramanian & Ramya, 2013). Thus, it is essential before extracting the subjective features to standardize certain tokens of tweets and avoid the fatal errors that may affect the performance of the ML algorithm (Sindhu et al., 2017). For pre-processing, the Nominal to Text operator was used first to make RapidMiner treat the data as text. The next step was to add an operator named ProcessDocumentsFromFiles, where various pre-processing steps were performed using different appropriate operators. These steps are as follows:\n1. Case Conversion operator: was used to transform all the words into lower cases. 2. Tokenization operator: to split the sentences into words or a sequence of tokens to be re-\nmoved by stop word operator. 3. Filter Stopwords (English)/ Stop-words-removal: This operator is commonly used to\nremove stop words that do not have information (no meaning), do not have any sentiment from the input text, and will not help distinguish between positive and negative perceptions such as a, an, is, are, that, which, the, has, have.\n4. Filter tokens by length: This operator customizes and reduces the word\u2019s length (token sets) to remove words according to their length. The words were filtered, and only the words with a maximum length of 20 and a minimum length of 3 were retained. 5. Stemming: Stemming refers to a simple process of cutting off word endings to remove derived suffixes, or it is the process of converting words back to their base in the form of tokens using stem operator called stem Porter. 6. Generate n-Grams (Terms): N-grams are sequences of n items from the piece of text.\nBased on these steps, only data containing words that could play a role in indicating the sentiment of the tweet were left. Furthermore, word vector representations were also generated using the TFIDF method. All the aforementioned processes of data pre-processing and word vector generation were performed using ProcessDocumentsFromFiles. All the pre-processing steps are shown in Figure 4.\nOPINION CLASSIFICATION Although Twitter posts (tweets) are short, a post can still contain more than one sentence that mentions multiple subjects. To find out how strong an opinion is on a related topic, a subjective opinion evaluation is required before the sentiment classification model is performed. Based on the literature, opinions could be categorized into two types: subjective and objective (Bai, 2011). Subjective opinions usually express more personal perceptions, for example, \u201celearning is good\u201d is a subjective statement because it represents an opinion. Contrarily, objective opinions lack sentiment opinion or subjectivity and are descriptions of the essential information about an object or an entity (Li & Li, 2013), for example, \u201conline classes require a computer and internet services\u201d, this sentence is a fact and general information rather than an opinion (Liu, 2012). Since the aim of this study is to integrate students\u2019 perceptions of e-learning, subjective opinions are more important.\nIn general, a greater portion of sentimental words will be used in sentences when users express their feelings related to describing the objective information. Hence, the opinion subjectivity of a post can be defined as the average intensity of the sentimental words in all sentences in a post that mentions the topic. To evaluate the subjectivity level of opinions, Text analytics tool that uses NLP and ML was used to extract required information from a text or file containing sentimental and emotional words. Text analytic platform allows real-time social media monitoring and data analysis directly in Microsoft Excel, generating powerful reports on sentiment, entities, or keywords as well as creating dynamic word clouds based on the current data flow. Then, RapidMiner is used as a data mining tool to classify and evaluate the data (students\u2019 Tweets).\nSENTIMENT CLASSIFICATION WITH SVM CLASSIFIER This study employs SVM approach to predict positive and negative sentiments from the tweets related to the students\u2019 perception of e-learning in Malaysian universities and make decisions based on the selected support vectors (Kechaou et al., 2011).\nThe data set is first classified as positive or negative and is shown by feature vectors. Then, the classifier uses these vectors as training data to identify similar features and to classify the data in a specific class. The SVM classifier uses the training set to learn and train itself regarding the text differentiating attributes and testing the classifier performance using the test dataset. The Set Role operator was used to identify which values to use as labels. The \u2018label\u2019 role is one of the most important roles in RapidMiner that indicates which attribute is the predicted class when used in any modeling operator. Figure 5 illustrates the modelling process using RapidMiner.\nA cross validation operator was used to train and test the classifier simultaneously. The data was divided into ten sets and, basically, ten different classification models were created. Each model was tested against the remaining fold, and this process was repeated ten times. The first nine sets were used for training, and the final set was used for testing. The model is trained and tested in each run or iteration, with a different combination of nine sets used as training data and a new set used as testing data. Once all the permutations are completed, this process is stopped. To check accuracy, performance and apply model operators were used. Performance Operator was employed to measure the performance of the model, whereas Apply Model operator was used to run the model on the test data to see how it performs, as shown in Figure 6.\nTo evaluate the performance, four main metrics are commonly used to evaluate the performance of the classifier and estimate the effectiveness and quality of the classification algorithm (Oramas Bustillos et al., 2019). These metrics are accuracy, recall, precision, and F-measure. Accuracy is the most important and popular measure of classification process, which refers to the ratio of total classifications that are accurate to the total number of datasets. Precision measures the exactness of the classifier result and can be defined as the ratio of true positives to the total number of positives that are predicted, whereas recall measures the completeness of the classifier result and refers to the ratio of true positives with the total positives in the dataset (Vyas & Uma, 2018). F-Measure, also called F1-Score, is a combination of precision and recall. The F1-Score is very helpful as it provides a single measure that rates a system by precision and recall. In binary classification, the outcome is either positive or negative. The four metrics were calculated automatically by RapidMiner based on the following equations:\nAccuracy = (TP+TN)/(TP+TN+FP+FN)\nPrecision = TP/(TP+FP)\nRecall = TP/(TP+FN)\nF-measure = 2*Precision*Recall / Precision+ Recall\nwhere TP refers to the number of true positive predictions for the class, FN the number of false negative prediction cases, FP the number of false positive prediction cases, and TN the number of\nFigure 5. Training a sentiment classifier with SVM\nFigure 6. Sub-Process Cross-Validation operator\ntrue negative prediction cases (Aggarwal et al., 2019; Kechaou et al., 2011; Kharde & Sonawane, 2016). Table 1 displays the confusion matrix used for the validation process. This matrix is a combination of four outcomes as follows.\nIn the first phase, the tweets were classified as positive and negative; to add multi-sentiment values the NRC sentiment dictionary was used in the second phase. Sentiment analysis using the National Research Council (NRC) sentiment lexicon was applied to examine the presence of eight basic emotions (\u201canger\u201d, \u201c fear\u201d, \u201canticipation\u201d, \u201ctrust\u201d, \u201csurprise\u201d, \u201csadness\u201d, \u201cjoy\u201d, and \u201cdisgust\u201d) (Mohammad & Turney, 2013). This NRC lexicon used the get_nrc_sentiment function from the \u2018Syuhzet\u2019 package in R to obtain sentiments. Joy and confidence represent positive sentiments. In contrast, words such as sadness, anger, fear, and disgust were used to convey negative sentiments. Anticipation and surprise can be both positive and negative, depending on the situation."
        },
        {
            "heading": "RESULT AND DISCUSSION",
            "text": "The SA-based ML approach was used to explore students\u2019 opinions towards different e-learning systems in Malaysia via Twitter platform. More than 15,000 tweets were collected from Twitter, and the final dataset included 1,201 tweets for SA. The pre-processing stage involves performing intensive processing steps for each tweet before passing the refined tweets to the classifier. In addition, the data was first classified into subjective and objective opinions to avoid the tweets that do not express a strong sentiment that may negatively affect the classifier\u2019s accuracy and performance. Thus, the focus was only on the tweets expressing strong sentiments.\nPrimarily, the text analytics tool classified data into four main groups: Positive, Negative, Natural, and ValidationError. Only positive and negative tweets are passed to the classifier and all tweets classified as Natural and ValidationError were manually deleted. Based on the results, almost more than half of the data contained subjective opinions. Precisely, 51.34 % of the total data are subjective and 48.66 % are objective as presented in Table 2. The subjective opinions such as \u201cI am always anxious in online classes\u201d and \u201cI\u2019ve been surprisingly pleased with the online university studying\u201d, while the objective sentences such as, \u201cOnline learning is a whole new game\u201d and \u201cIf they mandated online learning, they would need to provide us with laptops and internet access\u201d.\nThis indicates that opinion sentences represent an important part of the total sentences, which to some extent support the use of Twitter as a source of opinions to understand the users\u2019 reviews about educational systems and evaluate learning and teaching processes in general.\nThe SVM model was trained and used to classify the tweets into classes for opinion mining (opinion polarity). For training purposes, the tweets were classified into two types of labels: positive and negative. The dataset of 1201 labelled training tweets was divided into two parts: Training set and Test set.\nThe training set included 80% of the randomly selected tweets used to train and validate the model, while test set included a random sample of 20% of the data used to test the model\u2019s performance. These labels were used to train the classifier based on the predicted labels of the testing dataset. In addition, evaluation was performed by 10-fold cross validation, and the performance of sentiment classification was evaluated by the recall, precision, accuracy, and F-Measure values. The performance evaluation values compare the original class label and the predicted class label in the test dataset. Usually, in SA-based classification, model performance is evaluated by the number of correctly predicted tweet sentiments in relation to incorrectly predicted tweet sentiments (Shoeb & Ahmed, 2017).\nTable 3 shows the performance measures of SVM based classifiers in terms of precision and recall.\nSimilarly, Table 4 demonstrates the classifier\u2019s performance in terms of Accuracy, Recall, Precision, and F-Measure.\nAs shown in the table, with accuracy of 84.75 %, recall of 64.99 %, precision of 87.86 %, and FMeasure of 83.3%, our study shows significant findings regarding opinion classification in educational context. Figure 7 displays the performance of the model.\nFigure 7. Performance Visualization\nThe results obtained through SVM classifier emphasized that it is possible to perform SA on social data such as Twitter and Facebook with high accuracy. These results are consistent with results obtained by Ortigosa et al. (2014) who asserted that adaptive e-learning systems could use this information to support personalized learning and to understand the students\u2019 sentiments towards e-learning systems, particularly in the online learning environment.\nThe results of this study also showed that SVM classifier is able to predict positive and negative sentiments from the tweets and the overall performance can be considered very good. Thus, SVM classifier can be used for SA classification in different educational contexts, particularly in e-learning, with the highest accuracy results among the other classifiers (AL-Rubaiee et al., 2016; Esparza et al., 2017; Ortigosa et al., 2014). It could be said that applying SA-based ML techniques in educational settings could be helpful in predicting learning problems and understanding related issues based on students\u2019 posts and comments in social media, where they can express their views freely. The comparison of the findings and performance of SVM classifier in our study with prior studies that applied SVM classifier demonstrated its reliability. For instance, AL-Rubaiee et al. (2016) conducted a study to implement sentiment classification regarding university students\u2019 opinions using different ML algorithms. The results showed that SVM achieved higher accuracy than the other algorithms. Likewise, in a study by Weber and Syed (2019), the authors applied several ML algorithms to select the best performing classification algorithm on the target tweets. The results showed that the SVM classifier performs the best.\nAfter classifying the sentiments on the basis of their polarization, the findings of the study could identify students positive and negative emotions towards the e-learning system in Malaysian universities. This would enable decision makers to address such opinions as feedback for future improvement. The results revealed that the majority of students have positive opinions about e-learning in Malaysian universities, as shown in Table 5.\nPrecisely, 65 % of the data (tweets) have a positive opinion and 35 % have negative opinions. The positive results showed that students who had appropriate facilities, such as easy access to e-learning systems, available resources, a reliable internet connection, and ease of communication with their colleagues and lecturers, are satisfied and get precise benefits from the e-learning systems. Figure 8 illustrates the model\u2019s prediction over the dataset and provides a general description of the generated data as a mix of positive and negative tweets.\nThe most frequent keywords in the dataset related to e-learning are visualized using word clouds as shown in Figure 9. The top five words and phrases used most frequently in the tweets are online, learning, student, e-learning, and university.\nAmong the eight emotions, trust and joy are considered positive, while anger, sadness, fear, and disgust are considered negative. Surprise and anticipation are determined by the context, whether positive or negative. For example, in this tweet \u201cI\u2019ve been surprisingly pleased with the online university studying\u201d is determined as \u2018\u2018positive surprise\u2019\u2019 due to the context in the sentence. The collected tweets were analyzed using the eight emotion-based classifications as shown in Figure 10. Almost all students expressed a higher level of trust, anticipation, and joy in their tweets, followed by mixed feelings of fear, sadness, and surprise.\nFigure 8. Sentiments Visualization\nFigure 9. The word cloud of the most frequent keywords\nOverall, this study revealed that students have mostly positive perceptions (65%) towards e-learning in Malaysian universities. These types of posts were mostly about students\u2019 feelings connected to elearning systems in universities. For instance, the findings revealed that some of the positive tweets such as \u201cThe best thing in elearning is work group, very joyful\u201d, \u201cI\u2019ve been surprisingly pleased with the online university studying\u201d and \u201cthe lecturer online short videos lessons are helpful and awesome\u201d. The tweets have discussed the advantages of e-learning as a method that provide them with new skills that can be a great contribution to building their confidence. Another advantage of their opinions is that micro-lessons on e-learning are helpful in gaining knowledge effectively. These types of lessons are relatively small, focused topics consisting of extensive learning activities and through the constant use of micro-lessons, the retention level of students will be increased (Shail, 2019). In addition, some tweets explained how group tools in e-learning systems could assist them in organizing group projects, sharing information, and keeping learning safe and secure. They also state that using e-learning system assessment tools is a simple way to evaluate their performance, and communication and collaboration tools enable them to self-access, organize, and research. Everything has changed because of the global health crisis, but e-learning has an advantage that is still possible and in high demand. Therefore, some of the students\u2019 tweets have discussed e-learning during Covid-19 pandemic, and how e-learning platforms played a major role in facilitating learning process in the current situation, helping them to continue their studies, and keeping them safe from any potential risks. In this case, expressions such as happy, joyful, pleased, satisfied, easy, good, like and many other positive expressions were used.\nHowever, a significant minority of the students have a negative perception of e-learning (35%). These types of posts mainly focused on the downsides associated with using e-learning systems, such as \u201cI don\u2019t learn from online learning, so I don\u2019t like it\u201d and \u201cI can\u2019t manage my tasks, elearning so difficult\u201d. In addition, students mostly discussed their bad feelings due to the bad internet connection when they were off campus which made it difficult for them to access learning resources in the elearning system and thus affected their progress. They also were concerned on how to handle the assignments and projects. On the other hand, some of the negative tweets stated that not all students\nhave equal experience and knowledge to use these platforms easily, as well as not all students can access online learning. Other tweets stated that when developing e-learning systems, learners\u2019 prior knowledge should be taken into consideration. Additionally, sone students have complained in some tweets about spending long hours on computers and other devices, emphasizing the importance of incorporating variety into e-learning. Others argue that these systems are impairing their social abilities and increasing their workloads and study time. In this case, expressions such as anxious, worry, stressed, sad, bad, missed, difficult, and many other negative expressions were used.\nThus, our study confirmed that SA of Twitter data could provide valuable and supportive information about educational systems and procedures in e-learning for appropriate decision-making regarding future development and strategies."
        },
        {
            "heading": "LIMITATIONS",
            "text": "This study has several limitations. First, this was limited to exploring Malaysian university students\u2019 perceptions, and thus excluded the lecturer. Secondly, this study was limited to tweets in English language, therefore the results are limited to students who tweet in English only. Thirdly, this study primarily drew its findings from Twitter, excluding other social media platforms such as Facebook, Instagram, and YouTube."
        },
        {
            "heading": "CONCLUSION AND FUTURE WORK",
            "text": "This study aims to leverage the sentiment analysis on social media platforms to measure students\u2019 polarity towards e-learning using machine learning. Understanding students\u2019 perceptions and feeling toward the e-learning system is expected to help in giving a clear insight to system designers and educational policymakers to implement the necessary interventions and measures to rectify the situation. The students express their opinions about their learning on social media platforms such as Twitter, especially during Covid-19 pandemic. Sentiment Analysis was performed on a sample of data collected from Twitter (tweets) to discover students\u2019 opinions and insights over e-learning systems in Malaysian universities. Twitter is a powerful source of data as individuals worldwide interact together on a common social media platform to discuss various issues. Thus, it provides ample scope for researchers to fetch a massive amount of raw data. This raw data was used to analyze the opinion of the target sample. For this purpose, the ML-based approach was used to predict the polarity of the tweets. Specifically, the support vector machine algorithm (SVM) was applied for text classification. To process and analyze the data, a variety of tools are available to gain insight into online content for a specific purpose and any institution. After evaluating some tools, Rapid Miner was chosen as a mining tool in this study to deduce positive and negative sentiments from the tweets. The Rapid Miner text mining operators were applied to the data prior to applying the SVM classifier for testing and training. The training dataset was used to generate a model that predicts the labels of the testing dataset. Then, these labels were used to train the classifier and the results of prediction were finally done by the SVM classifier to predict the tweets\u2019 polarity. The final data contained 1,201 Tweets, and students\u2019 Tweets were classified into two types of labels: positive and negative. 65 % of data had a positive opinion about e-learning systems in Malaysian universities, and 35 % had negative opinions. For performance evaluation, four important metrics were calculated to evaluate the model\u2019s performance, and the classification results in terms of accuracy, recall, precision, and F1-score. The findings showed that SVM performs expertly and extremely well, achieving 84.75% accuracy in identifying sentiments, 87.86 % precision, 64.99% recall, and F1-Score 74.62 %.\nHence, the finding suggests that sentiment analysis has great potential to improve teaching and learning process in universities by analyzing sentiment and satisfaction factors in students\u2019 posts, comments, and feedback that help instructors and administrators understand students\u2019 problematic areas to take immediate action. The massive volume of data generated by social media platforms and many other sources is largely unused data that can be effectively used with the application, such as SA based ML approach. Therefore, these findings may also encourage other researchers to apply SA-\nbased ML approach and use Twitter as a data source to discover users\u2019 opinions about certain issues in learning and teaching processes.\nOur study emphasized that Twitter sentiment analysis can provide accurate and useful data for future planning and help developers enhance the services of institutions. This study can be expanded to include multiple datasets, such as Facebook, educational systems, and other blogs, to gain a comprehensive understanding of the opinions of Malaysian university students regarding the e-learning system. In addition, future work can experiment with other classification models and different ML classification algorithms as well as other feature extraction methods and compare the results to find the best accuracy that can improve the classification results."
        },
        {
            "heading": "FUNDING",
            "text": "This work was funded by short-term research grant (304/PMEDIA/6315363), Universiti Sains Malaysia, Penang, Malaysia."
        },
        {
            "heading": "ETHICAL",
            "text": "This study did not require ethical committee approval because it processed Twitter data and it complied with the platform\u2019s terms."
        },
        {
            "heading": "CONFLICT OF INTEREST",
            "text": "The authors declare that no conflict of interest would prejudice the impartiality of this scientific work."
        }
    ],
    "title": "MALAYSIAN UNIVERSITIES: SENTIMENT ANALYSIS BASED MACHINE LEARNING APPROACH",
    "year": 2023
}