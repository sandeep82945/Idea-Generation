{
    "abstractText": "This paper studies convergence properties of inexact iterative solution schemes for bilevel optimization problems. Bilevel optimization problems emerge in control-aware design optimization, where the system design parameters are optimized in the outer loop and a discrete-time control trajectory is optimized in the inner loop, but also arise in other domains including machine learning. In the paper an interconnection of proximal gradient algorithms is proposed to solve the inner loop and outer loop optimization problems in the setting of controlaware design optimization and robustness is analyzed from a control-theoretic perspective. By employing input-to-state stability arguments, conditions are derived that ensure convergence of the interconnected scheme to the optimal solution for a class of the bilevel optimization problem.",
    "authors": [
        {
            "affiliations": [],
            "name": "Torbj\u00f8rn Cunis"
        },
        {
            "affiliations": [],
            "name": "Ilya Kolmanovsky"
        }
    ],
    "id": "SP:7d4470a3c1252f31bbdbc51ed080639b1fc89836",
    "references": [
        {
            "authors": [
                "M. Pontil"
            ],
            "title": "Bilevel programming for hyperparam",
            "year": 2018
        },
        {
            "authors": [],
            "title": "Coupling optimization methods and",
            "year": 1988
        },
        {
            "authors": [
                "F.R. Wirth"
            ],
            "title": "Nonconservative discrete-time iss",
            "year": 2018
        },
        {
            "authors": [
                "N.T. Toan"
            ],
            "title": "Differential stability of discrete optimal",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n21 1.\n10 79\n8v 1\n[ m\nat h.\nO C\n] 1\n9 N\nov 2\n02 2\nKeywords: Input-to-state stability, Optimal control theory, Proximal gradient descent, Stability of nonlinear systems, Time-distributed optimization."
        },
        {
            "heading": "1. INTRODUCTION",
            "text": "In bilevel optimization (see Colson et al., 2007, and references therein) the cost function and/or constraints of a high-level optimization problem are informed by the optimal value function of an lower-level optimization problem which, in turn, is parametrized by the decision variables of the higher level optimization problem.\nBilevel optimization has numerous applications. For instance, in control co-design (see, e.g., Garcia-Sanz, 2019), plant and controller parameters need to be simultaneously optimized, while in control-aware design (such as described by Cunis et al., 2022), system design parameters are optimized in the outer loop subject to the existence of an admissible state and control trajectory determined through the inner-loop optimization. In those works, the problem is reformulated in such a way that the gradients of the value function of the inner loop optimization problem with respect to the parameters are employed for the outer loop optimization. Cunis et al. (2022) argued that from the perspective of the integration with existing gradientbased multi-disciplinary design optimization solvers, such an approach is preferable to simultaneous optimization with respect to design and controller parameters. In that work, such an approach is employed for optimizing wing shape parameters subject to glide slope following maneuver constraints at landing of a supersonic aircraft.\nBennett et al. (2008) and Franceschi et al. (2018) have discussed bilevel optimization problems in machine learning, where the outer-loop optimization is performed with respect to the hyperparameters of the machine learning solution. The implementation of robust reference gover\u22c6 Partially supported by United States Air Force Office of Scientific Research Grant number FA9550-20-1-0385.\nnors (see, e.g., Garone et al., 2017, and references therein) involves outer loop optimization with respect to the reference command and the inner loop optimization with respect to the disturbance sequence aimed at maximizing constraint violation. Finally, leader-follower and Stackelberg games lend themselves naturally to bilevel programming (see, e.g., Basilico et al., 2017).\nTypical for these bilevel optimization problems is that evaluating value function and and gradient of the innerloop optimization is computationally expensive. In this paper, a prototypical problem in bilevel optimization which is typical of control-aware design is considered. Here, an optimal control problem is solved in the inner loop and a parameter optimization problem being solved in the outer loop subject to the solution of the inner loop. The aim is to demonstrate that the exact solution of the innerloop optimization problem is not necessary for the overall convergence of the bilevel optimization. This has obvious advantages when the time to compute the solution and the available computing power are restricted.\nMore specifically, we focus on a class of bilevel optimization problems where a discrete-time linear quadratic optimal control problem with input constraints is solved in the inner loop and both the linear model and the quadratic cost function depend on the parameter of the outer-loop optimization problem. The optimal value function of the inner loop optimization problem, which is thus a function of the parameter, is to be minimized subject to additional constraints on the parameter. Within this setting, we propose a framework for the analysis of bilevel optimization based on inexact proximal gradient algorithms, where the number of iterations of the inner-loop optimizer remains fixed. Thus, the gradient of the inner-loop value function computed only approximately is used for a proximal\ngradient descent with respect to the outer-loop decision variables. By exploiting the control-theoretic notion of input-to-state stability (ISS) and a small gain theorem in the analysis, we derive sufficient conditions for asymptotic stability and convergence of the overall bilevel optimization algorithm.\nNotation N and R are the sets of natural and real numbers, respectively. The extended real numbers are R = R \u222a {\u221e}. A convex function f : Rn \u2192 R is proper if and only if its domain, {x \u2208 Rn | f(x) \u2264 \u221e}, is nonempty. For some m \u2208 N, the set of positive semi-definite (resp., positive definite) matrices in Rm\u00d7m is denoted by S+m (resp., S++m ). The Euclidean norm and inner product on R n are denoted by | \u00b7 | and \u3008\u00b7, \u00b7\u3009. For a function \u03b1 : R\u22650 \u2192 R\u22650 we write that \u03b1 \u2208 K if and only if \u03b1 is continuous, positive definite, and strictly increasing; and that \u03b1 \u2208 K\u221e if and only if \u03b1 \u2208 K as well as \u03b1(r) \u2192 \u221e if r \u2192 \u221e. Moreover,KL is the class of continuous functions \u03b2 : R\u22650 \u00d7 R\u22650 \u2192 R\u22650 satisfying \u03b2(\u00b7, s) \u2208 K for all s \u2265 0 and \u03b2(r, \u00b7) is decreasing with lims\u2192\u221e \u03b2(r, s) = 0 for all r \u2265 0."
        },
        {
            "heading": "2. PRELIMINARIES",
            "text": "Given a proper convex and lower semicontinuous function f : Rn \u2192 R, the proximity operator of f maps x to the unique solution of\nproxf (x) = argmin y\u2208Rn\nf(y) + 1\n2 |x\u2212 y|2\nfor all x \u2208 Rn. If f is the indicator function of a convex set C \u2282 Rn, the proximity operator of f corresponds to a projection onto C.\nWe make extensive use of the fact that the proximity operator is nonexpansive as detailed in the next statement. Further properties can be found in the appendix.\nProperty 1. (Rockafellar, 1976). Let f : Rn \u2192 R be a proper convex and lower semicontinuous function and take \u03bd > 0; the proximity operator satisfies\u2223\u2223 prox\u03bdf (x1)\u2212 prox\u03bdf (x2)\n\u2223\u2223 \u2264 |x1 \u2212 x2| for all x1, x2 \u2208 R n."
        },
        {
            "heading": "2.1 Problem Statement",
            "text": "Consider a system represented by a parameter-dependent model of the form\nxk+1 = A(p)xk +B(p)uk + e(p) (1)\nwith initial condition x0 \u2208 R n, control input uk \u2208 R m, k \u2208 N, and parameter p \u2208 Rl; the functions A : Rl \u2192 Rn\u00d7n, B : Rl \u2192 Rn\u00d7m, and e : Rl \u2192 Rn are smooth.\nWe define the finite-horizon quadratic cost\nJ = 1\n2 x\u22a4NS(p)xN +\n1\n2\nN\u22121\u2211\nk=0\n( x\u22a4k Q(p)xk + u \u22a4 k R(p)uk ) , (2)\nwhere N \u2208 N is the horizon, which is evaluated on the trajectories of (1) for a specified initial condition x0. We assume that R : Rl \u2192 S++m and Q,S : R\nl \u2192 S+n are smooth. Collecting u = (u\u22a40 , . . . , u \u22a4 N\u22121) \u22a4, the state sequence x = (x\u22a41 , . . . , x \u22a4 N ) \u22a4 satisfies\nx = A\u0302(p)x0 + B\u0302(p)u+ e\u0302(p)\nfor some constant x0, where A\u0302(p) and B\u0302(p) are matrixvalued and e\u0302(p) is vector valued; and the cost J is a quadratic function in u and smooth in p, viz.\nJ(u, p) = u\u22a4H(p)u+ g(p)\u22a4u+ c(p) (3)\nwhere H(p) is matrix-valued, g(p) is vector-valued, and c(p) is scalar; all functions are smooth in p. Note that, under our assumptions, H(p) is positive-definite.\nSuppose P : Rl \u2192 R and U : RNm \u2192 R are proper convex and lower semicontinuous penalty functions for p and u, respectively, with compact domains P and U . Given some p \u2208 Rl, the cost function J(p,u)+U(u) is strongly convex in u with optimal value J\u0304 : p 7\u2192 minu J(u, p) + U(u) and thus has a unique optimal solution u\u0304(p). We consider the following optimization problem.\nProblem 2. Minimize J\u0304(p) + P (p) for p \u2208 Rl.\nWe adopt the bilevel proximal gradient descent algorithm\np\u2113+1 = proxP [ p\u2113 \u2212 \u03bd\u2207\u0302pJ(u \u2113+1, p\u2113)\u22a4 ]\n(4a)\nu\u2113+1 = Argmin\u03ba J(\u00b7, p \u2113) + U(\u00b7) (4b)\nwith \u03ba, \u2113 \u2208 N and \u03bd > 0, where Argmin\u03ba denotes a \u03ba-step suboptimal solution to the parametrized optimal control\nproblem and \u2207\u0302pJ denotes the vector of estimated partial derivatives of J\u0304 at p\u2113 based on the suboptimal solution u\u2113+1.\nWithout state constraints, the optimal control solution can be approximated by the inner-loop finite-horizon proximal gradient descent iteration\nu\u2113k+1 = proxU [ u\u2113k \u2212 \u00b5\u2207uJ(u \u2113 k, p \u2113)\u22a4 ]\n(5a)\nu\u2113+10 = u \u2113 \u03ba (5b)\nfor all k \u2208 {0, . . . , \u03ba\u2212 1} and with \u00b5 > 0.\nDenote by P\u22c6 \u2282 P the set of minima of J\u0304 +P . We aim to prove a sufficient condition on \u00b5 and \u03bd as well as \u03ba such that\np\u2113 \u2192 P\u22c6 and u \u03ba \u2113 \u2192 u\u0304(p \u2113) (6)\nas \u2113 \u2192 \u221e.\nThe dynamics in (4) can be viewed as an interconnection of discrete-time systems, where the state of one system \u2013 here, the parameter p and current solution u \u2013 enters as disturbance into the other \u2013 through the estimated partial derivative vector and parametrized optimization, respectively. To describe a stable behaviour of the interconnection, we make use of the notion of input-to-state stability (ISS) firstly introduced by Sontag (1995). As P\u22c6 may consist of more than one element, we rely on a since developed generalization called \u03c9ISS."
        },
        {
            "heading": "2.2 Size functions",
            "text": "Let X \u2286 Rn be an open set and A \u2282 X be compact. A measurement function (on X) is a continuous function \u03c9 : X \u2192 R\u22650 that is positive semidefinite.\nDefinition 3. A measurement function \u03c9 on X is a size function for A if and only if \u03c9 vanishes exactly on A as well as \u03c9(\u03bek) \u2192 \u221e for any sequence {\u03bek}k\u22650 \u2282 X, if either \u03bek \u2192 \u2202X or |\u03bek| \u2192 \u221e.\nSize functions have also been called proper indicators (Kellett and Dower, 2012; Noroozi et al., 2018). If X is the full space, then the distance mapping\ndistA(x) def\n= min \u03be\u2208A |x\u2212 \u03be|\nis a simple example for a size function. The following result allows us to compare size functions and to establish a notion of equivalence.\nLemma 4. (Sontag, 2022, Corollary 2.7). Let \u03c91 : X \u2192 R\u22650 be a size function for A; then any measurement function \u03c92 on X is a size function (for A) if and only if there exists \u03b11, \u03b12 \u2208 K\u221e satisfying\n\u03b11(\u03c91(x)) \u2264 \u03c92(x) \u2264 \u03b12(\u03c91(x))\nfor all x \u2208 X. \u2701"
        },
        {
            "heading": "2.3 \u03c9-Input-to-State Stability",
            "text": "We consider the nonlinear, nonautonomous system on X\nxk+1 = f(xk, uk) (\u03a3)\nwith k \u2265 0, where f : X\u00d7 Rm \u2192 X is continuous.\nDefinition 5. Let \u03c9 be a measurement function on X; the system (\u03a3) is \u03c9-input-to-state stable if and only if there exists \u03b2 \u2208 KL and \u03b3 \u2208 K such that for all x0 \u2208 X and {uk}k\u22650 \u2208 \u2113 \u221e m the solution {xk}k\u22650 satisfies\n\u03c9(xk) \u2264 max{\u03b2(\u03c9(x0), k), \u03b3(\u2016{uk}\u2016\u221e)}\nfor all k \u2265 0, where \u2016{uk}\u2016\u221e def = supk\u22650 |uk|.\nIf \u03c9 is a size function, then Definition 5 reduces to the classical definition of input-to-state stability (for A on X) as introduced by Sontag and Wang (1995). However, it also generalizes notions such as state-independent inputto-output stability (Kellett and Dower, 2012). As for classical input-to-state stability, system (\u03a3) is \u03c9-inputto-state stable if (and only if) there exists a continuous function V : X \u2192 R\u22650, called \u03c9ISS Lyapunov function, and gains \u03b11, \u03b12, \u03b13 \u2208 K\u221e and \u03b3 \u2208 K satisfying \u03b13 < id and\n\u03b11(\u03c9(x)) \u2264 V (x) \u2264 \u03b12(\u03c9(x)) (7a)\nV (f(x, u)) \u2264 max{\u03b13(V (x)), \u03b3(|u|)} (7b)\nfor all x \u2208 X and u \u2208 Rm (Noroozi et al., 2018, Theorem 7).\nRemark 6. If \u03c9 is a size function, the second condition for an \u03c9ISS Lyapunov function can equivalently be written as an implication\n\u03c9(x) \u2265 \u03c7(|u|) \u21d2 V (f(x, u))\u2212 V (x) \u2264 \u2212\u03c1(V (x))\nwhere \u03c1 is a positive definite function and \u03c7 \u2208 K. In particular, the ISS gain is\n\u03b3(r) = max{V (f(x, u)) |V (x) \u2264 \u03c7(r), |u| \u2264 r}\nfor all r \u2265 0.\nWe now consider an interconnection of \u2118 \u2208 N nonlinear systems\nxi(k+1) = fi(x1k, . . . , xRk, uik) (\u03a3i)\nwith x = (x1, . . . , x\u2118) \u2208 X and ui \u2208 R mi , where fi : X \u00d7 Rmi \u2192 Xi are continuous functions, for all i \u2208 I = {1, . . . , \u2118}. Let \u2016 \u00b7 \u2016 be a monotonic norm on R\u2118.\nTheorem 7. (Noroozi et al., 2018, Theorem 10). Suppose, for any i \u2208 I, that \u03c9i is a measurement function on Xi and the subsystem (\u03a3i) has an \u03c9iISS Lyapunov function\nWi : Xi \u2192 R\u22650 and gains \u03b3 x i1, . . . , \u03b3 x i\u2118, \u03b3 u i \u2208 K \u222a {0}, such that \u03b3xii < id and\nWi(fi(x, ui)) \u2264 max j\u2208I\n{\u03b3xij(Wj(xj)), \u03b3 u i (|ui|)}\nfor all (x, ui) \u2208 X\u00d7R mi ; define\n\u03c9\u0302 : (x1, . . . , x\u2118) 7\u2192 \u2016(\u03c91(x1), . . . , \u03c9\u2118(x\u2118))\u2016\nif \u03b3xi1 \u25e6 \u00b7 \u00b7 \u00b7 \u25e6 \u03b3 x ir < id for any r \u2208 N and {i1, . . . , ir} \u2286 I, then the interconnection (\u03a31, . . . ,\u03a3\u2118) is \u03c9\u0302-input-to-state stable. \u2701"
        },
        {
            "heading": "2.4 Sensitivity of Optimal Control",
            "text": "Take any p \u2208 P . The minimizer u\u0304(p) is the unique solution of the generalized equation (Dontchev, 2021)\nLp(u) def = \u2207uJ(u, p) + \u2202U(u) \u220b 0, u \u2208 U , (8)\nwhere \u2202U(u) is the subdifferential of U at u. The inverse of the set-valued mapping Lp is\nL\u22121p : \u03b4 7\u2192 {u \u2208 U | \u03b4 \u2208 Lp(u)}\nBy strong convexity, u\u03b4 \u2208 L \u22121 p (\u03b4) if and only if u\u03b4 is the (unique) solution of the perturbed optimization problem\nmin u\nJ(u, p) + U(u)\u2212 \u03b4\u22a4u\nand the mapping \u03b4 7\u2192 u\u03b4 is Lipschitz continuous (Dontchev, 2021, Theorem 11.1). In other words, Lp is strongly regular 1 at u\u0304(p) for 0 and hence, the solution map u\u0304(\u00b7) is Lipschitz continuous around p (Dontchev, 2021, Theorem 8.5). Moreover, we have that\n\u2207pJ\u0304(p) = \u2207pJ(u, p)| u=u\u0304(p) (9)\nby virtue of Toan (2021, Theorem 3.1)."
        },
        {
            "heading": "3. STABILITY ANALYSIS",
            "text": "We study the dynamics of an interconnection of finite-step proximal gradient descent algorithms and derive sufficient conditions for (4) to be asymptotically stable with respect to P\u22c6. To that extend, we show that both the outer and inner optimization are \u03c9-input-to-state stable with respect to appropriate measurement functions and prove that, assuming the sufficient condition of Theorem 7 is satisfied, \u03c9\u0302 is a size function for P\u22c6. Moreover, we will argue that the small-gain condition can always be met if the number of inner iterations \u03ba is sufficiently large.\nRecall that, under moderate assumptions for the cost function, the proximal gradient descent algorithm asymptotically converges to a fixed point if the step size is chosen to be smaller than or equal to the inverse of the Lipschitz constant of the gradient.\nAssumption 8. The gradients \u2207pJ\u0304(\u00b7) and \u2207uJ(\u00b7, p) are Lipschitz continuous (for all p \u2208 P) with constants \u03bd\u22121 and \u00b5\u22121, respectively, or larger.\nSince \u2207pJ(u, \u00b7) is smooth, u\u0304(\u00b7) is locally Lipschitz, and P is compact, as well as \u2207uJ(\u00b7, p) being linear in u, Lipschitz continuity of the gradients follows a fortiori. Under Assumption 8, the solution {uk}k\u22650 of (5) for a fixed p \u2208 P converges to u\u0304(p) if k \u2192 \u221e.\n1 A set-valued map L : \u03be \u21d2 \u03b6 is said to be strongly regular at \u03be0 for \u03b60 \u2208 L(\u03be0) if and only if L\u22121(\u03b6) has a single value \u03be close to \u03be0 for all \u03b6 around \u03b60.\nWe propose to estimate the gradient of J\u0304 by the partial derivative\n\u2207\u0302pJ(u, p) = \u2207pJ(u, p) (10)\nThe interconnection now deviates from the nominal in two points: The parameter of the inner iteration changes during the optimization and the gradient for the outer iteration is perturbed by the error between u\u2113\u03ba and u\u0304(p \u2113)."
        },
        {
            "heading": "3.1 Parametrized Gradient Descent",
            "text": "Input-to-state stability of parametrized optimization algorithms has previously been studied, e.g., by LiaoMcPherson et al. (2020). That work considered the change of parameter and optimization error for input and state, respectively. We are going to generalize the result to obtain \u03c9-input-to-state stability for the proximal gradient descent. We start by rewriting the \u03ba-step update by (5) to\nu\u2113+1 = g\u03ba(u \u2113, p\u0303\u2113,\u2206p\u2113) (11a)\np\u0303\u2113+1 = p\u0303\u2113 +\u2206p\u2113 (11b)\nwhere g\u03ba : R Nm\u00d7Rl\u00d7Rl \u2192 RNm is obtained by repeating the proximal gradient descent (5) for \u03ba times with fixed parameter p\u2113 = p\u0303\u2113+\u2206p\u2113. Here, the additional state p\u0303 \u2208 R l represents the previous parameter, that is, p\u0303\u2113 = p\u2113\u22121 for all \u2113 > 0. We introduce the measurement function\n\u03c9u : (u, p\u0303) 7\u2192 \u2016u\u2212 u\u0304(p\u0303)\u20162\nfor the augmented state (u, p\u0303) of (11). Since the proximity operator is nonexpansive (Property 1), any solution {u\u2113k}k\u22650 of (5) satisfies the contraction property\n\u03c9u(u \u2113 k, p \u2113) \u2264 \u03b7k\u03c9u(u \u2113 0, p \u2113) (12)\nfor any k \u2265 0, where the convergence rate \u03b7 \u2208 (0, 1) follows from strong convexity of J(\u00b7, p) and Assumption 8. We obtain the following result.\nLemma 9. Let u \u2208 RNm and p\u0303,\u2206p \u2208 Rl; the dynamics in (11) satisfy the dissipation-type inequality\n\u03c9u(u+, p\u0303+) \u2264 \u03b7 \u03ba\u03c9u(u, p\u0303) + \u03bb\u22c6\u03b7 \u03ba|\u2206p|\nif u+ = g\u03ba(u, p\u0303,\u2206p) and p\u0303+ = p\u0303+\u2206p, where \u03bb\u22c6 \u2265 0 is the Lipschitz constant of the optimal solution u\u0304(\u00b7) on P .\nProof. From the triangle inequality, we obtain\n\u03c9u(u, p\u0303+\u2206p) = \u2016u\u2212 u\u0304(p\u0303+\u2206p)\u20162 \u2264 \u2016u\u2212 u\u0304(p\u0303)\u20162 + \u2016u\u0304(p\u0303+\u2206p)\u2212 u\u0304(p\u0303)\u20162\n\u2264 \u03c9u(u, p\u0303) + \u03bb\u22c6|\u2206p| (13)\nand combining (12) and (13) yields the desired result. \u2737\nIt remains to prove that \u03c9u is an \u03c9uISS Lyapunov function.\nProposition 10. The \u03ba-step update of the proximal gradient descent, as given in (11), is \u03c9u-input-to-state stable with gain \u03b3\u03ba; and \u03b3 \u2032 \u03ba \u2192 0 uniformly as \u03ba \u2192 \u221e.\nProof. Let u+ = g\u03ba(u, p\u0303,\u2206p) and p\u0303+ = p\u0303+\u2206p for some u \u2208 RNm and p\u0303,\u2206p \u2208 Rl and choose \u01eb \u2208 (0, 1); by virtue of Lemma 9, we have that\n\u03c9u(u+, p\u0303+) \u2264 (1 \u2212 \u01eb)\u03c9u(u, p\u0303) def = \u03b1(\u03c9u(u, p\u0303))\nif (1 \u2212 \u03b7\u03ba \u2212 \u01eb)\u03c9u(u, p\u0303) \u2265 \u03bb\u22c6\u03b7 \u03ba|\u2206p|; and\n\u03c9u(u+, p\u0303+) < \u03bb\u22c6 \u03b7\u03ba + 1\n1\u2212 \u03b7\u03ba \u2212 \u01eb \u03b7\u03ba|\u2206p|\ndef = \u03b3\u03ba(|\u2206p|)\notherwise. If \u01eb is sufficiently small, we have that \u03b1, \u03b3\u03ba \u2208 K\u221e as well as\n\u03c9u(u+, p\u0303+) \u2264 max{\u03b1(\u03c9u(u, p\u0303)), \u03b3\u03ba(|\u2206p|)}\nproving that \u03c9u is an \u03c9uISS Lyapunov function. Moreover, \u03b3\u03ba is linear with \u03b3 \u2032 \u03ba \u2192 0 as \u03ba \u2192 \u221e by l\u2019Ho\u0302pital\u2019s rule. \u2737\nIn other words, (11) is input-to-output stable, with input \u2206p and output u, independently of the state p\u0303 \u2013 that is, the actual parameter p.\nRemark 11. \u03c9u-input-to-state stability of (11) can also be viewed as parametrized input-to-state stability of the original proximal gradient descent algorithm. In contrast, LiaoMcPherson et al. (2020) proved input-to-state stability with both p and \u2206p as inputs (although the gain on p was zero)."
        },
        {
            "heading": "3.2 Perturbed Gradient Descent",
            "text": "In recent work, Sontag (2022) established input-to-state stability of a perturbed steepest descent algorithm with respect to the set of minimizers P\u22c6, under the assumptions that the cost function and norm of the gradient are size functions for P\u22c6. Convergence of proximal gradient schemes under perturbed gradients was studied in earlier works (Lemaire, 1988; Tossings, 1994) and more recently by Atchade\u0301 et al. (2017).\nBuilding upon those previous works, we prove input-tostate stability of the proximal gradient descent scheme with perturbed gradient, as given in (4a). We start with the simplified iteration\np\u2113+1 = T\u03bd(p \u2113, d) def = proxP [ p\u2113 \u2212 \u03bd(\u2207J\u0304(p\u2113)\u22a4 + d) ] (14)\nwhere d \u2208 Rl is a perturbation for the gradient. Adopting from Sontag (2022), we make the following assumptions.\nAssumption 12. The cost function J\u0304 satisfies:\n\u2022 the function J\u22c6 : p 7\u2192 (J\u0304+P )(p)\u2212j \u22c6 is a size function\nfor P\u22c6, where j \u22c6 is the global minimum of J\u0304 + P ;\n\u2022 the function \u039b : p 7\u2192 |T\u03bd(p, 0) \u2212 p| is a size function for P\u22c6.\nSince P has a compact domain, J\u22c6 is a size function if and only if J\u0304 + P is positive definite with respect to P\u22c6. Moreover, the assumption on \u039b is equivalent to the necessary conditions for optimality being sufficient, too. If P \u2261 0, as for gradient descent, \u039b(p) corresponds to |\u2207J\u0304(p)| for all p \u2208 Rl.\nTheorem 13. Let \u03c9p : R l \u2192 R\u22650 be a size function for P\u22c6; the dynamics in (14) are \u03c9p-input-to-state stable.\nProof. Take p, d \u2208 Rl; since T\u03bd(p, d) \u2208 P , we have that\n(J\u0304 + P )(T\u03bd(p, d))\u2212 (J\u0304 + P )(p)\n\u2264 \u2212(2\u03bd)\u22121|T\u03bd(p, d)\u2212 p| 2 \u2212 \u03b1\u22121\u3008T\u03bd(p, d)\u2212 p,\u2212\u03bdd\u3009\n(15a)\nby Lemma 17. Rewriting T\u03bd(p, d) \u2212 p and applying the triangle inequality to both sides we obtain\u2223\u2223\u039b(p)\u2212 \u03bd|d|\n\u2223\u2223 \u2264 |T\u03bd(p, d)\u2212 p| \u2264 \u039b(p) + \u03bd|d| and thus, (15a) yields\nJ\u22c6(T\u03bd(p, d))\u2212 J\u22c6(p) \u2264 \u2212(2\u03bd) \u22121\u039b(p)2 + 2\u039b(p)|d|+ \u03bd|d|2\n(15b)\nwhere rewriting the left-hand side is trivial. We now argue with Sontag (2022, Proof of Theorem 4) that, since J\u22c6 and \u039b both are size functions for P\u22c6, there exists K\u221e functions b1 and b2 satisfying\nb1J\u22c6(p) \u2264 \u039b(p) \u2264 b2J\u22c6(p)\nfor all p \u2208 Rl, where linearity of b1 and b2 can be assumed without loss of generality for P is compact.\nInserting the inequalities into (15b), we have that, for all p, d \u2208 Rl,\nJ\u22c6(T\u03bd(p, d))\u2212 J\u22c6(p) \u2264 \u2212cJ\u22c6(p) 2 + 2b2J\u22c6(p)|d| + \u03bd|d| 2\n(15c)\nfor some c > 0 satisfying c \u2264 b21(2\u03bd) \u22121. Choose \u03c7 > 0 such that, for all p, d \u2208 Rl,\nJ\u22c6(T\u03bd(p, d)) \u2264 J\u22c6(p)\u2212 \u03c1J\u22c6(p) 2\nif J\u22c6(p) \u2265 \u03c7|d|, where \u03c1 > 0; and otherwise,\nJ\u22c6(T\u03bd(p, d)) \u2264 \u03c7|d|+ \u03c70|d| 2\nwith \u03c70 > 0. Hence, as J\u22c6 \u25e6 T\u03bd is upper-bounded, there exists \u03b1 \u2208 (0, 1) and \u03b3 > 0 satisfying\nJ\u22c6(T\u03bd(p, d)) \u2264 max{\u03b1J\u22c6(p), \u03b3|d|}\nfor all p, d \u2208 Rl, proving that J\u22c6 is an \u03c9pISS-Lyapunov function for (14). This concludes the proof. \u2737\nIt rests to prove input-to-state stability if the gradient perturbation is caused by the estimation error of (10). From (9), we have that the i-th component of the gradient error vector satisfies\u2223\u2223[\u2207pJ\u0304 \u2212 \u2207\u0302pJ ] i (p,u)\n\u2223\u2223 \u2264 (u\u0304(p)\u2212 u)\u22a4\u2207piH(p)(u\u0304(p)\u2212 u) + |\u2202pig(p) \u22a4(u\u0304(p)\u2212 u)| (16)\nwhere\u2207pi denotes the element-wise partial derivative with respect to the i-th component of p \u2208 Rl. Since U is compact, there exists \u0325 > 0 such that\u2223\u2223[\u2207pJ\u0304 \u2212 \u2207\u0302pJ ] (p,u)\n\u2223\u2223 \u2264 \u0325|u\u0304(p)\u2212 u| for all (p,u) \u2208 P \u00d7 U . We conclude with the following result.\nCorollary 14. The dynamics in (4a) are \u03c9p-input-to-state stable with respect to the input u\u0304(p) \u2212 u for any size function \u03c9p for P\u22c6 on R l. \u2701"
        },
        {
            "heading": "3.3 Interconnected Gradient Descent",
            "text": "We are going to prove asymptotic stability of the bilevel proximal gradient scheme by application of the small-gain theorem.\nSuppose {(p\u2113,u\u2113)}\u2113\u22650 \u2282 P \u00d7 U is a solution to the interconnection of (4) and (5); for any \u2113 > 0, take p\u0303\u2113+1 = p\u2113 and \u2206p\u2113 = p \u2113 \u2212 p\u2113\u22121 and recall that\n\u03c9u(u \u2113+1, p\u0303\u2113+1) \u2264 max{\u03b1\u03ba\u03c9u(u \u2113, p\u0303\u2113), \u03b3\u03ba|\u2206p \u2113|} (17a)\nJ\u22c6(p\u0303 \u2113+1) \u2264 max{\u03b10J\u22c6(p\u0303 \u2113), \u03b30\u0325\u03c9u(u \u2113, p\u0303\u2113)} (17b)\nwhere \u03b10, \u03b1\u03ba \u2208 (0, 1), \u03b30, \u03b3\u03ba,\u0325 > 0, and \u03c9u(u, p) \u2261 |u\u0304(p)\u2212 u| have been obtained beforehand, as well as\n|\u2206p\u2113| \u2264 \u039b(p\u0303\u2113) + \u03bd\u0325\u03c9u(u \u2113, p\u0303\u2113) (17c)\nby Lemma 18.\nProposition 15. There exists K \u2208 N such that, for all \u03ba \u2265 K, the interconnection of (4) and (5) is asymptotically stable with respect to the set\n\u2126 = {(u\u0304(p), p) | p \u2208 P\u22c6}\nand |\u2206p\u2113| \u2192 0 as \u2113 \u2192 \u221e.\nProof. Take b > 0 such that \u039b(p) \u2264 bJ\u22c6(p) for all p \u2208 R l; from (17) and Lemma 9 we obtain\n|\u2206p\u2113+1| \u2264 \u039b(p\u0303\u2113+1) + \u03bd\u0325\u03c9u(u \u2113+1, p\u0303\u2113+1)\n\u2264 \u03bd\u0325\u03bb\u22c6\u03b7 \u03ba|\u2206p\u2113|+ \u03bd\u0325\u03b7 \u03ba\u03c9u(u \u2113, p\u0303\u2113)\n+ bmax{\u03b10J\u22c6(p\u0303\u2113), \u03b30\u0325\u03c9u(u \u2113, p\u0303\u2113)}\n\u2264 \u03bd\u0325\u03bb\u22c6\u03b7 \u03ba|\u2206p\u2113|+max { (1 + \u03bd\u03b7\u03ba(b\u03b30) \u22121)b\u03b10J\u22c6(p\u0303\u2113),\n(\u03bd\u03b7\u03ba + b\u03b30)\u0325\u03c9u(u \u2113, p\u0303\u2113)\n}\nIf K is sufficiently large, then \u03bd\u0325\u03bb\u22c6\u03b7 K \u2208 (0, 1) and, repeating the argument in Proposition 10, we obtain \u033a \u2208 (0, 1) and \u03d1 > 0 satisfying, for all \u03ba \u2265 K,\n|\u2206p\u2113+1| \u2264 max{\u033a|\u2206p\u2113|, \u03b31J\u22c6(p\u0303\u2113), \u03b32\u03c9u(u \u2113, p\u0303\u2113)} (18)\nwith \u03b31 = \u03d1(b+ \u03bd\u03b7 \u03ba\u03b30 \u22121)\u03b10 and \u03b32 = \u03d1(\u03bd\u03b7 \u03ba + b\u03b30)\u0325.\nCombining (17) with (18) yields an interconnection of three \u03c9ISS-Lyapunov functions for u, p\u0303, and \u2206p. Clearly, if K is sufficiently large, then\n\u03b32 \u00b7 \u03b3\u03ba < 1\n\u03b30 \u00b7 \u03b31 \u00b7 \u03b3\u03ba < 1\nand by virtue of Theorem 7, the interconnection of (4) and (5) is \u03c9\u0302-input-to-state stable, where\n\u03c9\u0302 : (p\u0303,u,\u2206p) = \u2016(\u03c9p(p\u0303), \u03c9u(u, p\u0303), |\u2206p|)\u2016\nfor all \u03ba \u2265 K. We claim that \u03c9\u0302 is a size function for \u2126\u00d7{0}: Take (p\u0303,u,\u2206p) \u2208 Rl \u00d7 RNm \u00d7 Rl, then \u03c9\u0302(p\u0303,u,\u2206p) = 0 if and only if p\u0303 \u2208 P\u22c6, u = u\u0304(p\u0303), and |\u2206p| = 0. Suppose \u03a0 \u2282 Rl is compact; then, for any (p\u0303,u) \u2208 \u03a0\u00d7 RNm,\n\u03c9u(u, p\u0303) \u2265 |u| \u2212 |u\u0304(p\u0303)| \u2265 |u| \u2212 \u03c5\u03a0\nwhere \u03c5\u03a0 = maxp\u2208\u03a0 |u\u0304(p)| < \u221e by Lipschitz continuity of u\u0304(\u00b7) on \u03a0. Hence, since \u03c9p is a size function and \u2016 \u00b7 \u2016 is monotone, \u03c9\u0302(p\u0303,u,\u2206p) \u2192 \u221e as either |p| \u2192 \u221e, |u| \u2192 \u221e, or |\u2206p| \u2192 \u221e.\nWe conclude that (p\u0303\u2113,u \u2113) \u2192 \u2126 and |\u2206p\u2113| \u2192 0 as \u2113 \u2192 \u221e. Noting that \u2206p\u2113 = p \u2113 \u2212 p\u0303\u2113, this is the desired result. \u2737"
        },
        {
            "heading": "4. SPECIAL CASE",
            "text": "We have shown that the bilevel optimization scheme converges asymptotically to the optimal solution even if the inner-loop problem is solved inexactly. However, specific conditions for the optimization problem of (1) and (2) to satisfy Assumption 12 remain an open research question. In order to illustrate our theoretic results we consider the case that the parameters only enters through an additive linear term, viz.\nxk+1 = Axk +Buk + Ep (19)\nand the quadratic cost is constant in the parameter. In this scenario, the parameter may correspond to the initial condition of the optimal control problem or an additional input that is constant over the control horizon. The innerloop cost function now simplifies to\nJ(u, p) = (u, p)\u22a4H(u, p) + g\u22a4(u, p) + c (20)\nwhere the block matrix H is positive semidefinite by positive definiteness of Q and R. Hence, the cost J is convex in (u, p) and, since U is convex, J\u0304(p) = minu J(u, p)+U(u) is convex too. Consequently, P\u22c6 is convex and the necessary conditions for optimality are sufficient, that is, \u039b(p) = 0 if and only if p \u2208 P\u22c6. Assumption 12 thus holds since\nJ\u22c6(p) \u2265 P (p) and \u039b(p) \u2265 distP(p) diverge for |p| \u2192 \u221e. Moreover, the gradient of J is linear in u and p, viz.\n\u2207pJ(u, p) = (u, p) \u22a4Hp + g \u22a4 p\nand its Lipschitz constant is equal to \u2016Hp\u2016. We conclude from the results of the previous section that the bilevel optimization is asymptotically stable if the number of inner-loop iterations \u03ba is sufficiently large."
        },
        {
            "heading": "5. CONCLUSION",
            "text": "We have shown that convergence conditions for a class of bilevel optimization problems with inexactly implemented proximal gradient optimization can be derived using inputto-state stability arguments. Future work will focus on broadening the class of problems and optimization algorithms for which similar approaches can be followed as well as on applications to real world problems motivating this work."
        }
    ],
    "year": 2022
}