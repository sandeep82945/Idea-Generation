{
    "abstractText": "The traditional way of sentence-level event detection involves two important subtasks: trigger identification and trigger classifications, where the identified event trigger words are used to classify event types from sentences. However, trigger classification highly depends on abundant annotated trigger words and the accuracy of trigger identification. In a real scenario, annotating trigger words is time-consuming and laborious. For this reason, we propose a trigger-free event detection model, which transforms event detection into a two-tower model based on machine reading comprehension and prompt learning. Compared to existing trigger-based and trigger-free methods, experimental studies on two event detection benchmark datasets (ACE2005 and MAVEN) have shown that the proposed approach can achieve competitive performance.",
    "authors": [
        {
            "affiliations": [],
            "name": "Tongtao Ling"
        },
        {
            "affiliations": [],
            "name": "Lei Chen"
        },
        {
            "affiliations": [],
            "name": "Huangxu Sheng"
        },
        {
            "affiliations": [],
            "name": "Zicheng Cai"
        },
        {
            "affiliations": [],
            "name": "Hai-Lin Liu"
        }
    ],
    "id": "SP:60639a542f3a591fb8553164d4baa51cfd679305",
    "references": [
        {
            "authors": [
                "Q. Li",
                "J. Li",
                "J. Sheng",
                "S. Cui",
                "J. Wu",
                "Y. Hei",
                "H. Peng",
                "S. Guo",
                "L. Wang",
                "A. Beheshti",
                "P.S. Yu"
            ],
            "title": "A survey on deep learning event extraction: Approaches and applications",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems pp. 1\u201321",
            "year": 2022
        },
        {
            "authors": [
                "Y. Chen",
                "L. Xu",
                "K. Liu",
                "D. Zeng",
                "J. Zhao"
            ],
            "title": "Event extraction via dynamic multipooling convolutional neural networks",
            "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP). pp. 167\u2013176",
            "year": 2015
        },
        {
            "authors": [
                "L. Sha",
                "F. Qian",
                "B. Chang",
                "Z. Sui"
            ],
            "title": "Jointly extracting event triggers and arguments by dependency-bridge rnn and tensor-based argument interaction",
            "venue": "Proceedings of the AAAI conference on artificial intelligence. vol. 32",
            "year": 2018
        },
        {
            "authors": [
                "X. Wang",
                "X. Han",
                "Z. Liu",
                "M. Sun",
                "P. Li"
            ],
            "title": "Adversarial training for weakly supervised event detection",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT). pp. 998\u20131008",
            "year": 2019
        },
        {
            "authors": [
                "V.D. Lai",
                "T.H. Nguyen",
                "F. Dernoncourt"
            ],
            "title": "Extensively matching for few-shot learning event detection",
            "venue": "Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events. pp. 38\u201345",
            "year": 2020
        },
        {
            "authors": [
                "S. Liu",
                "Y. Li",
                "F. Zhang",
                "T. Yang",
                "X. Zhou"
            ],
            "title": "Event detection without triggers",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)",
            "year": 2019
        },
        {
            "authors": [
                "Z. Zhang",
                "X. Kong",
                "Z. Liu",
                "X. Ma",
                "E. Hovy"
            ],
            "title": "A two-step approach for implicit event argument detection",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL). pp. 7479\u20137485",
            "year": 2020
        },
        {
            "authors": [
                "X. Li",
                "J. Feng",
                "Y. Meng",
                "Q. Han",
                "F. Wu",
                "J. Li"
            ],
            "title": "A unified MRC framework for named entity recognition",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL). pp. 5849\u20135859",
            "year": 2020
        },
        {
            "authors": [
                "T. Schick",
                "H. Sch\u00fctze"
            ],
            "title": "Exploiting cloze-questions for few-shot text classification and natural language inference",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL). pp. 255\u2013269",
            "year": 2021
        },
        {
            "authors": [
                "J. Devlin",
                "M.W. Chang",
                "K. Lee",
                "K. Toutanova"
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT). pp. 4171\u20134186",
            "year": 2019
        },
        {
            "authors": [
                "A. Vaswani",
                "N. Shazeer",
                "N. Parmar",
                "J. Uszkoreit",
                "L. Jones",
                "A.N. Gomez",
                "L. Kaiser",
                "I. Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems 30",
            "year": 2017
        },
        {
            "authors": [
                "D. Ahn"
            ],
            "title": "The stages of event extraction",
            "venue": "Proceedings of the Workshop on Annotating and Reasoning about Time and Events. pp. 1\u20138",
            "year": 2006
        },
        {
            "authors": [
                "S. Cui",
                "B. Yu",
                "T. Liu",
                "Z. Zhang",
                "X. Wang",
                "J. Shi"
            ],
            "title": "Edge-enhanced graph convolution networks for event detection with syntactic relation",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020. pp. 2329\u20132339",
            "year": 2020
        },
        {
            "authors": [
                "S. Yang",
                "D. Feng",
                "L. Qiao",
                "Z. Kan",
                "D. Li"
            ],
            "title": "Exploring pre-trained language models for event extraction and generation",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL). pp. 5284\u20135294",
            "year": 2019
        },
        {
            "authors": [
                "Y. Wei",
                "S. Liu",
                "J. Lv",
                "X. Xi",
                "H. Yan",
                "W. Ye",
                "T. Mo",
                "F. Yang",
                "G. Wan"
            ],
            "title": "DESED: Dialogue-based explanation for sentence-level event detection",
            "venue": "Proceedings of Sentence-level Event Detection without Triggers 13 the 29th International Conference on Computational Linguistics (COLING). pp. 2483\u20132493",
            "year": 2022
        },
        {
            "authors": [
                "M. Seo",
                "A. Kembhavi",
                "A. Farhadi",
                "H. Hajishirzi"
            ],
            "title": "Bidirectional attention flow for machine comprehension",
            "venue": "arXiv preprint arXiv:1611.01603",
            "year": 2016
        },
        {
            "authors": [
                "Y. Shen",
                "P.S. Huang",
                "J. Gao",
                "W. Chen"
            ],
            "title": "Reasonet: Learning to stop reading in machine comprehension",
            "venue": "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. pp. 1047\u20131055",
            "year": 2017
        },
        {
            "authors": [
                "J. Liu",
                "Y. Chen",
                "K. Liu",
                "W. Bi",
                "X. Liu"
            ],
            "title": "Event extraction as machine reading comprehension",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). pp. 1641\u20131651",
            "year": 2020
        },
        {
            "authors": [
                "J. Zhao",
                "H. Yang"
            ],
            "title": "Trigger-free event detection via derangement reading comprehension",
            "venue": "arXiv preprint arXiv:2208.09659",
            "year": 2022
        },
        {
            "authors": [
                "T. Brown",
                "B. Mann",
                "N. Ryder",
                "M. Subbiah",
                "J.D. Kaplan",
                "P. Dhariwal",
                "A. Neelakantan",
                "P. Shyam",
                "G. Sastry",
                "A Askell"
            ],
            "title": "Language models are few-shot learners",
            "venue": "Advances in neural information processing systems 33, 1877\u20131901",
            "year": 2020
        },
        {
            "authors": [
                "P. Liu",
                "W. Yuan",
                "J. Fu",
                "Z. Jiang",
                "H. Hayashi",
                "G. Neubig"
            ],
            "title": "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
            "venue": "ACM Computing Surveys 55(9), 1\u201335",
            "year": 2023
        },
        {
            "authors": [
                "Y. Wei",
                "T. Mo",
                "Y. Jiang",
                "W. Li",
                "W. Zhao"
            ],
            "title": "Eliciting knowledge from pretrained language models for prototypical prompt verbalizer",
            "venue": "Artificial Neural Networks and Machine Learning \u2013 ICANN 2022. pp. 222\u2013233",
            "year": 2022
        },
        {
            "authors": [
                "G. Doddington",
                "A. Mitchell",
                "M. Przybocki",
                "L. Ramshaw",
                "S. Strassel",
                "R. Weischedel"
            ],
            "title": "The automatic content extraction (ACE) program \u2013 tasks, data, and evaluation",
            "venue": "Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC)",
            "year": 2004
        },
        {
            "authors": [
                "X. Wang",
                "Z. Wang",
                "X. Han",
                "W. Jiang",
                "R. Han",
                "Z. Liu",
                "J. Li",
                "P. Li",
                "Y. Lin",
                "J. Zhou"
            ],
            "title": "MAVEN: A Massive General Domain Event Detection Dataset",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). pp. 1652\u20131671",
            "year": 2020
        },
        {
            "authors": [
                "D. Wadden",
                "U. Wennberg",
                "Y. Luan",
                "H. Hajishirzi"
            ],
            "title": "Entity, relation, and event extraction with contextualized span representations",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). pp. 5784\u20135789",
            "year": 2019
        },
        {
            "authors": [
                "Y. Lin",
                "H. Ji",
                "F. Huang",
                "L. Wu"
            ],
            "title": "A joint neural model for information extraction with global features",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL). pp. 7999\u20138009",
            "year": 2020
        },
        {
            "authors": [
                "S. Hochreiter",
                "J. Schmidhuber"
            ],
            "title": "Long short-term memory",
            "venue": "Neural computation 9(8), 1735\u20131780",
            "year": 1997
        },
        {
            "authors": [
                "H. Yan",
                "X. Jin",
                "X. Meng",
                "J. Guo",
                "X. Cheng"
            ],
            "title": "Event detection with multi-order graph convolution and aggregated attention",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). pp. 5766\u20135770",
            "year": 2019
        },
        {
            "authors": [
                "Y. Lu",
                "H. Lin",
                "J. Xu",
                "X. Han",
                "J. Tang",
                "A. Li",
                "L. Sun",
                "M. Liao",
                "S. Chen"
            ],
            "title": "Text2Event: Controllable sequence-to-structure generation for end-to-end event extraction",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP). pp. 2795\u20132806",
            "year": 2021
        },
        {
            "authors": [
                "I.H. Hsu",
                "K.H. Huang",
                "E. Boschee",
                "S. Miller",
                "P. Natarajan",
                "K.W. Chang",
                "N. Peng"
            ],
            "title": "DEGREE: A data-efficient generation-based event extraction model",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT). pp. 1890\u20131908",
            "year": 2022
        },
        {
            "authors": [
                "T. Wolf",
                "L. Debut",
                "V. Sanh",
                "J. Chaumond",
                "C. Delangue",
                "A. Moi",
                "P. Cistac",
                "T. Rault",
                "R. Louf",
                "M Funtowicz"
            ],
            "title": "Transformers: State-of-the-art natural language processing",
            "venue": "Proceedings of the 2020 conference on empirical methods in natural language processing (EMNLP). pp. 38\u201345",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Keywords: Event detection \u00b7 Prompt learning \u00b7 Machine reading comprehension."
        },
        {
            "heading": "1 Introduction",
            "text": "Information extraction (IE) is an important application of Natural Language Processing (NLP). Event detection (ED) is a fundamental part of IE, aiming at identifying trigger words and classifying event types, which could be divided into two sub-tasks: trigger identification and trigger classification [1]. For example, consider the following sentence \u201cTo assist in managing the vessel traffic, Chodkiewicz hired a few sailors, mainly Livonian\u201d. The trigger words are \u201cassist\u201d and \u201chired\u201d, the trigger-based event detection model is used to locate the position of the trigger words and classify them into the corresponding event types, Assistance and Employment respectively.\nNowadays, mainstream research on ED focuses on the trigger-based methods, which means first recognizing triggers and then classifying event types [2,3,4]. This way transforms the ED task into a multi-stage classification problem, and the result of trigger identification can also affect trigger classification. Therefore, it is crucial to identify trigger words correctly, and this way requires datasets\nar X\niv :2\n30 6.\n14 17\n6v 1\n[ cs\n.C L\n] 2\n5 Ju\ncontaining multiple annotated trigger words and event types [5]. However, it is time-consuming to annotate trigger words in a real scenario, especially in a long sentence. Due to the expensive annotation of the corpus, the application of existing ED approaches is greatly limited. It should be noted that trigger words can provide additional information for trigger classification, but event triggers may not be essential for ED [6].\nFrom a problem-solving perspective, the goal of ED is to categorize the event types, and therefore, triggers can be seen as an intermediate result of this task [6]. To alleviate manual effort, in this paper, we aim to explore how to detect events without triggers. Event detection can be considered a text classification problem if the event triggers are missing. But three challenges should be solved: (1) Multi-label problem: since a sentence can contain multiple events or no events at all, which is called a multi-label text classification problem in NLP. (2) Insufficient event information: triggers are important and helpful for ED [2,7]. Without trigger words, the ED model may lack sufficient information to detect the event type, and we need to find other ways to enrich the semantic information of the sentence to learn the correlation between the sentence and the event type. (3) Imbalance Data Distribution: the data distribution in the real world is long-tail, which means that most event types have only a small number of instances and many sentences may not have events occurring. The goal of ED is also to evaluate its ability in the long-tail scenario.\nTo address these challenges, we propose a trigger-free method via machine reading comprehension (MRC) [8] and prompt learning [9] and decompose ED into a two-tower model. Figure 1 illustrates the architecture of our proposed model with two parts: reading comprehension encoder (RCE) and event type classifier (ETC). In the first-tower, we use BERT [10] as the backbone of RCE, and the input sentence concatenates with all event tokens are fed into BERT simultaneously1. Such a way is inspired by the MRC task, extracting event types is formalized as extracting answer position for the given sequence of event type tokens. In other words, the input sentences are deemed as \u201cQuestion\u201d and the sequence of event type tokens deemed as \u201cAnswer\u201d. This way allows BERT to automatically learn semantic relations between the input sentences and event tokens through self-attention mechanism [11]. In the second-tower, we use the same backbone of RCE and utilize prompt learning methods to predict event types. Specifically, when adding the prompt \u201cThis sentence describes a [MASK] event\u201d after the original sentence, this prompt can be viewed as a cloze-style question and the answer is related to the target event type. Therefore, ETC aims to fill the [MASK] token and can output the scores for each vocabulary token. We only use event type tokens in vocabulary and predict event types that score higher than the \u27e8none\u27e9 event type. In the inference time, only when these two-tower models predict results are correct can they be used as the final correct answer. In our example from Figure 1, RCE can predict the answer tokens are\n1 For example, we convert event token employment to \u201c\u27e8employment\u27e9\u201d and add it to vocabulary. All events operate like this. In addition, we add a special token \u201c\u27e8none\u27e9\u201d that no events have occurred.\n\u27e8assistance\u27e9 and \u27e8employment\u27e9 respectively. In addition, since \u27e8assistance\u27e9 and \u27e8employment\u27e9 both have higher values than \u27e8none\u27e9, we predict Assistance and Employment as the event type in this sentence.\nIn summary, we propose a two-tower model to solve the ED task without triggers and call our model ED PRC: Event Detection via Prompt learning and machine Reading Comprehension. The main contributions of our work are: (1) We propose a trigger-free event detection method based on prompt learning and machine reading comprehension that does not require triggers. The machine reading comprehension method can capture the semantic relations between sentence and event tokens. The prompt learning method can evaluate the scores of all event tokens in vocabulary; (2) Our experiments can achieve competitive results compared with other trigger-based methods and outperform other trigger-free methods on two event detection datasets (ACE2005 and MAVEN); (3) Further analysis of attention weight also indicates that our trigger-free model can identify the relation between input sentences and events, and appropriate prompts in a specific topic can guide pre-trained language models to predict correct events."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Sentence-level Event Detection",
            "text": "Conventional sentence-level event detection models based on pattern matching methods mainly utilize syntax trees or regular expressions [12]. These pattern-\nmatching methods largely rely on the expression form of text to recognize triggers and classify them into event types in sentences, which fails to learn in-depth features from plain text that contains complex semantic relations. With the rapid development of deep learning, most ED models are based on artificial neural networks such as convolutional neural networks (CNN) [2], recurrent neural network (RNN) [3], graph neural network (GNN) [13] and transformer network [14], and other pre-trained language models [10,15]."
        },
        {
            "heading": "2.2 Machine Reading Comprehension",
            "text": "Machine reading comprehension (MRC) is a challenging task in natural language processing (NLP). Given a question and a passage, the goal of MRC is to extract answer spans from the passage [16,17]. In a general way, it is divided into two binary classifiers, predicting the starting and ending spans of the passage. Over the past few years, there has been a trend of transforming event extraction tasks to MRC question answering. For example, Liu et al. [18] explicitly cast event extraction as a MRC task, which transfers event schema into questions and then retrieves answers as results. Zhao et al. [19] proposes Derangement mechanism on a machine Reading Comprehension (DRC) framework and leverages the selfattention mechanism to absorb semantic relations between context and events."
        },
        {
            "heading": "2.3 Prompt Learning",
            "text": "In recent years, prompt-based methods have shown great success in a range of NLP tasks. Compared to the typical model fine-tuning paradigm, prompt-tuning can elicit knowledge from the pre-trained language model (e.g., BERT [10] and GPT3 [20]) by adding prompts to the raw input, called prompt learning [9]. This new paradigm can design various prompts to adapt different downstream tasks (e.g., text classification, relation extraction and text generation), which narrow the gap between the pre-trained tasks and downstream tasks and greatly reduce the training time [21]. Prompt-based learning approaches allow PLMs to have a priori knowledge of a particular downstream task, which contributes to the final performance [22]."
        },
        {
            "heading": "3 Methodology",
            "text": "In this section, we present the details of the proposed ED PRC for sentence-level event detection without triggers."
        },
        {
            "heading": "3.1 Task Description",
            "text": "Formally, denote S, Y as sentence set and event type set, respectively. S = {xi|i \u2208 [1,M ]} contains M sentences, and each sentence xi in S is a token sequence xi = (w1, w2, ..., wL) with maximum length L. In sentence-level event detection, given a sentence xi and its ground-truth yi \u2208 Y, Y = {e1, e2, ..., eN},\nwe need to detect the corresponding event types for each instance. For sentences where no event occurred, we add a special token \u201c\u27e8None\u27e9\u201d as their event type. This task can be reformulated as a multi-label classification problem with N +1 event types."
        },
        {
            "heading": "3.2 Reading Comprehension Encoder",
            "text": "Inspired by the machine reading comprehension (MRC) task, we utilize BERT as a backbone to design a reading comprehension encoder due to its capability in learning contextual representations of the input sequence. We describe it as follows:\nInput = [CLS] Sentence [SEP] Events (1)\nwhere Sentence is the input sentence and Events is the set of event types (also including \u201c\u27e8None\u27e9\u201d). [CLS] and [SEP] are special tokens in BERT. For some event types such as \u201cBusiness:Lay off\u201d fails to map to a single token according to the vocabulary. In this case, we employ an angle bracket around each event type and remove the prefix, e.g., the event type of \u201cBusiness:Lay off\u201d is converted to a lower-case \u201c\u27e8lay off\u27e9\u201d. Then, we add N +1 event tokens to the vocabulary and randomly initialize its embeddings. We aim to make use of BERT to learn the relation between the input sentence and event types and yield precise event token representations.\nAfter that, we get the hidden-states of the last layer of BERT:\nh[CLS], h w 1 , ..., h w L , h[SEP ], h e 1, ..., h e N , h e N+1 = BERT (Input) (2)\nwhere hwi is the hidden state of the i-th input token. This setup is close to MRC that chooses the correct option to answer question \u201cWhat happened in the sentence?\u201d. Unlike traditional fine-tuning methods that utilize the [CLS] token to complete classification, we use the hidden states of event tokens to predict the probability of each token being the correct answer. The representation of event tokens:\nE = he1, ..., h e N , h e N+1 (3)\nwhere E \u2208 RN\u00d7D, D is the vector dimension of BERT. The probability of each event token as follows:\nP = softmax(E \u00b7W ) \u2208 RN\u00d72 (4)\nwhere W \u2208 RD\u00d72 is the weight matrix to learn. Each row of P is the probability of the corresponding event type. During training time, we therefore have the following loss for predictions:\nLRCE = CE(P, Y ) (5)\nwhere Y is the ground-truth label of each event token ei being the correct answer."
        },
        {
            "heading": "3.3 Event Type Classifier",
            "text": "We describe the implementation of ETC in this subsection. Inspired by the clozestyle prompt learning paradigm for text classification with pre-trained language models, event type classification can be realized by filling the [MASK] answer using a prompt function.\nFirst, the prompt function wraps the input sentence by inserting pieces of natural language text. For prompt function fp, as illustrated in Figure 1, we use \u201c[SENTENCE] This sentence describes a [MASK] event\u201d as a prompt function for our model. Let M be pre-trained language model (i.e., BERT), and x be the input sentence. The prediction score of each token v in vocabulary being filled in [MASK] token can be computed as:\npv = M([MASK] = v|fp(x)) (6)\nAfter that, the other key of prompt learning is answer engineering. We aim to construct a mapping function from event token space to event type space. In the first tower (RCE), it learns the relation between the input sentence and event tokens. RCE and ETC share the same weights of BERT. Then, we only select tokens in Y = {e1, e2, ..., eN} and compute the scores of event tokens:\npe = \u03c3(pv|v \u2208 Y) (7)\nwhere \u03c3(\u00b7) determines which function to transform the scores into the probability of event tokens, such as softmax.\nFinally, as shown in Figure 1, we predict all event tokens that score higher than the \u201c\u27e8None\u27e9\u201d token as the predicted result. In our example, since both \u201c\u27e8assistance\u27e9\u201d and \u201c\u27e8employment\u27e9\u201d have higher scores than \u201c\u27e8None\u27e9\u201d, we predict Assistance and Employment as target event types.\nIn the process of training, we calculate two losses due to the problem of imbalance data distribution. The first loss is defined as:\nL1 = 1 |T | \u2211 t\u2208T log exp(M([MASK] = t|fp(x)))\u2211 t\u2032\u2208{t,\u27e8none\u27e9} exp(M([MASK] = t\u2032|fp(x))) (8)\nwhere T is the set of event tokens that score higher than \u201c\u27e8None\u27e9\u201d in the sentence. The second loss is defined as follows:\nL2 = log exp(M([MASK] = \u27e8none\u27e9|fp(x)))\u2211\nt\u2032\u2208{\u27e8none\u27e9}\u222aT exp(M([MASK] = t\u2032|fp(x))) (9)\nwhere T is the set of event tokens that score lower than \u201c\u27e8None\u27e9\u201d in the sentence. Note that in Equation 8, we only compare the prediction scores that higher than the \u201c\u27e8None\u27e9\u201d event token. The reason is that we aim to improve the score of each event token that is higher than \u201c\u27e8None\u27e9\u201d. In Equation 9, we compare to event tokens that lower than the \u201c\u27e8None\u27e9\u201d, which can decrease the score of them. The overall training objective to be minimized is as follows:\nLETC = 1\nM \u2211 x\u2208S (L1 + L2) (10)\nIn the training time, our model can then be trained by minimizing the following loss:\nL = LRCE + LETC (11)"
        },
        {
            "heading": "4 Experiments",
            "text": "In this section, we introduce the dataset, evaluation metrics, implementation details, and experimental results."
        },
        {
            "heading": "4.1 Dataset and Evaluation",
            "text": "To evaluate the potential of ED PRC under different size datasets, we conducted our experiments on two event detection benchmark datasets, ACE2005 [23] and MAVEN [24]. Details of statistics are available in Table 1.\n\u2013 ACE2005 is the most widely used multilingual dataset for event extraction. We use the English version which contains 599 documents and 33 event types. Following previous pre-processing for data split, we adopt two variants: ACE05-E [25] and ACE05-E+ [26]. Compared to ACE05-E, ACE05-E+\nadd pronoun roles and multi-token event triggers. \u2013 MAVEN is a large event detection dataset constructed from Wikipedia and\nFrameNet, covering 4,480 documents and 168 event types.\nFor data split and preprocessing, following previous work [25,26,24], we split 599 documents of ACE2005 into 529/30/40 for train/dev/test set, respectively. Then, we use the same processing that splits 4480 documents of MAVEN into 2913/710/857 for train/dev/test set respectively.\nFollowing the widely-used metrics for event detection [2], we use precision (P), recall (R) and mirco F1-score (F1) to evaluate results."
        },
        {
            "heading": "4.2 Baseline",
            "text": "We compare our method to baselines with trigger-based and trigger-free methods. For trigger-based methods, we compare with: (1)DMCNN [2], which utilizes a convolutional neural network (CNN) and a dynamic multi-pooling mechanism to learn sentence-level features; (2)BiLSTM [27], which uses bi-directional long short-term memory network (LSTM) to capture the hidden states of triggers and classify them into corresponding event types; (3)MOGANDED [28], which proposes multi-order syntactic relations in dependency trees to improve event detection; (4)BERT [10], fine-tuning BERT on the ED task via a sequence labeling manner; (5)DMBERT [4], which adopts BERT as backbone and utilizes a dynamic multi-pooling mechanism to aggregate textual features. For triggerfree methods, we compare with: (6)TBNNAM [6], the first work on detecting events without triggers, which uses LSTM and attention mechanisms to detect events; (7)TEXT2EVENT [29], proposing a sequence-to-sequence model and\nextracting events from the text in an end-to-end manner; (8)DEGREE [30], formulating event detection as a conditional generation problem and extracting final predictions from the generated sentence with a deterministic algorithm.\nWe re-implemented some trigger-based baselines for comparison, including DMCNN, BiLSTM, MOGANDED, BERT and DMBERT. The other baseline results are from the original paper."
        },
        {
            "heading": "4.3 Implementation Details",
            "text": "The proposed model is implemented on the basis of Transformers toolkit [31] and PyTorch. We employ bert-base-uncased2 as the backbone and use AdamW as optimizer with a learning rate of 2e-5, max gradient norm of 1.0 and weight decay 5e-5. The maximum sequence length is set to 128 for ACE2005 and 256 for MAVEN. The dropout rate is set to 0.3 and batch size is set to 8. Our model is trained for 10 epochs and chooses the checkpoint with the best validation performance on the development set. We run all experiments on a single Nvidia RTX 3090 GPU. Our code is available at https://github.com/ rickltt/event_detection."
        },
        {
            "heading": "4.4 Main Results",
            "text": "We report main results in Table 2. Compared with trigger-free methods, we can find out that our method achieves a much better performance than other triggerfree baselines (TBNNAM, TEXT2EVENT and DEGREE). Obviously, ED PRC can achieve improvements of 0.4% (73.3% v.s. 73.7%) F1 score of the best triggerfree baseline (DEGREE) in ACE05-E, and 2.1% (71.8% v.s. 73.9%) F1 score of TEXT2EVENT in ACE05-E+. It proves the overall superiority and effectiveness of our model in the absence of triggers. Compared to trigger-based methods,\n2 https://huggingface.co/bert-base-uncased\ndespite the absence of trigger annotations, ED PRC can achieve competitive results with other trigger-based baselines, which is only 0.4% (73.7% vs. 74.1%) in ACE05-E and 0.3% (73.9% vs. 74.2%) in ACE05-E+ less than the best triggerbased baseline (DMBERT). The result shows that prompt-based method can greatly utilize pre-trained language models to adapt ED task and our MRC module is capable of learning relations between the input text and the target event tokens under low trigger clues scenario.\nTo further evaluate the effectiveness of our model on large-scale corpora, we show the result of MAVEN on various trigger-based baselines and our model in Table 3. We can see that our model also can achieve competitive performance on various trigger-based baselines, reaching 69.1% F1 score. Compared with CNN-based (DMCNN), RNN-based (BiLSTM) and GNN-based (MOGANED) method, BERT-based methods (BERT, DMBERT and ED PRC) can outperform high improvements, which indicates pre-trained language models can greatly capture contextual representation of input text. However, ED PRC can achieve only improvements of 0.1% (67.2% v.s. 67.3%) F1 score on BERT and is 0.8% (67.3% v.s. 68.1%) less than DMBERT. This can be attributed to more triggers and events on MAVEN than that on ACE2005. We conjecture that trigger-based event detection models can greatly outperform trigger-free models when sufficient event information is available. All in all, our ED PRC is proven competitive in both ACE2005 dataset and MAVEN dataset."
        },
        {
            "heading": "5 Analysis",
            "text": "In this section, we demonstrate further analysis and give an insight into the effectiveness of our method."
        },
        {
            "heading": "5.1 Effective of Reading Comprehension Encoder",
            "text": "Figure 2 shows a few examples with different target event types and their attention weight visualizations learned by the reading comprehension encoder. In the first case, the target event type is \u201cPersonnel:End-Position\u201d and our reading comprehension encoder successfully captures this feature by giving \u201c\u27e8end\u2212org\u27e9\u201d a high attention score. In addition, in the second case, it is a negative sample that no event happened in this sentence and our reading comprehension encoder can correctly give a high attention score for \u201c\u27e8none\u27e9\u201d and give low attention scores for other event tokens. Moreover, three events occur in the third case, \u201cJustice:Trial-Hearing\u201d, \u201cJustice:Charge-Indict\u201d and \u201cPersonnel:End-Position\u201d, respectively. Our approach can also give high attention scores to \u201c\u27e8trial \u2212 hearing\u27e9\u201d, \u201c\u27e8charge \u2212 indict\u27e9\u201d and \u201c\u27e8end \u2212 org\u27e9\u201d. We argue that, although triggers are absent, our model can learn the relations between input text and event tokens and assign the ground-truth event tokens with high attention scores."
        },
        {
            "heading": "5.2 Effective of Different Prompts",
            "text": "Generally, as the key factor in prompt learning, the prompt can be divided into two categories: hard prompt and soft prompt. The hard prompt is also called a discrete template, which inserts tokens into the original input sentence. Soft prompt is also called continuous template, which is a learnable prompt that does not need any textual templates. To further analyze the influence of different prompts, we design four simple manual prompts (hard prompt) to predict event types: (1) What happened? [SENTENCE] This sentence describes a [MASK] event; (2) [SENTENCE]What event does the previous sentence describe? It was a [MASK] event; (3) [SENTENCE] It was [MASK]; (4) A [MASK] event: [SENTENCE]. For soft prompt, we insert four trainable tokens into the original sentence, such as \u201c[TOKEN] [TOKEN] [SENTENCE] [TOKEN] [TOKEN] [MASK]\u201d. The results of our method on ACE2005 are shown in Table 4.\nPrompt 1 and Prompt 2 perform similarly, and both of them work better than Prompt 3. The reason for this may be that Prompt 3 provides less information and less topic-specific. And both Prompt 1 and Prompt 2 add a common phrase \u201csentence describe\u201d and a question to prompt the model to focus on the previous sentence. Unlike previous prompts, Prompt 4 puts [MASK] at the beginning of a sentence, and the result indicates that it might be slightly better to put the [MASK] at the end of the sentence. Compared with hard prompt, soft prompt eliminate the need for manual human design and construct trainable tokens that be optimized during training time. The result of soft prompt achieve performance that was fairly close to the hard prompt."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this paper, we transform sentence-level event detection to a two-tower model via prompt learning and machine reading comprehension, which can detect events without trigger words. By using machine reading comprehension framework to formulate a reading comprehension encoder, we can learn the relation between input text and event tokens. Besides, we utilize prompt-based learning methods to construct an event type classifier and final predictions are based on two towers. To make effective use of prompts, we design four manual hard prompts and compare with soft prompt. Experiments and analyses show that ED PRC can even achieves competitive performance compared to mainstream approaches using annotated triggers. In the future, we are interested in exploring more event detection methods without triggers by using prompt learning or other techniques.\nAcknowledgements This work was supported in part by the National Natural Science Foundation of China (62006044, 62172110), in part by the Natural Science Foundation of Guangdong Province (2022A1515010130), and in part by the Programme of Science and Technology of Guangdong Province (2021A0505110004)."
        }
    ],
    "title": "Sentence-level Event Detection without Triggers via Prompt Learning and Machine Reading Comprehension",
    "year": 2023
}