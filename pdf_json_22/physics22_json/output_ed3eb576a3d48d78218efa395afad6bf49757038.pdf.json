{
    "abstractText": "Spatial sound field interpolation relies on suitable models to both conform to available measurements and predict the sound field in the domain of interest. A suitable model can be difficult to determine when the spatial domain of interest is large compared to the wavelength or when spherical and planar wavefronts are present or the sound field is complex, as in the near-field. To span such complex sound fields, the global reconstruction task can be partitioned into local subdomain problems. Previous studies have shown that partitioning approaches rely on sufficient measurements within each domain, due to the higher number of model coefficients. This study proposes a joint analysis of all local subdomains, while enforcing self-similarity between neighbouring partitions. More specifically, the coefficients of local plane wave representations are sought to have spatially smooth magnitudes. A convolutional model of the sound field in terms of plane wave filters is formulated and the inverse reconstruction problem is solved via the alternating direction method of multipliers. The experiments on simulated and measured sound fields suggest, that the proposed method both retains the flexibility of local models to conform to complex sound fields and also preserves the global structure to reconstruct from fewer measurements.",
    "authors": [
        {
            "affiliations": [],
            "name": "Manuel Hahmann"
        },
        {
            "affiliations": [],
            "name": "Efren Fernandez-Grande"
        }
    ],
    "id": "SP:84d46c6cea41df9719c724717551b7d99739c4f9",
    "references": [],
    "sections": [
        {
            "heading": "A convolutional plane wave model for sound field reconstruction",
            "text": "Manuel Hahmann1 and Efren Fernandez-Grande1, a)\nAcoustic Technology Group, Department of Electrical Engineering, Technical University of Denmark, Building 352, \u00d8rsteds Plads, 2800 Kgs. Lyngby, Denmark\nSpatial sound field interpolation relies on suitable models to both conform to available measurements and predict the sound field in the domain of interest. A suitable model can be difficult to determine when the spatial domain of interest is large compared to the wavelength or when spherical and planar wavefronts are present or the sound field is complex, as in the near-field. To span such complex sound fields, the global reconstruction task can be partitioned into local subdomain problems. Previous studies have shown that partitioning approaches rely on sufficient measurements within each domain, due to the higher number of model coefficients. This study proposes a joint analysis of all local subdomains, while enforcing self-similarity between neighbouring partitions. More specifically, the coefficients of local plane wave representations are sought to have spatially smooth magnitudes. A convolutional model of the sound field in terms of plane wave filters is formulated and the inverse reconstruction problem is solved via the alternating direction method of multipliers. The experiments on simulated and measured sound fields suggest, that the proposed method both retains the flexibility of local models to conform to complex sound fields and also preserves the global structure to reconstruct from fewer measurements.\nI. INTRODUCTION\nSound field reconstruction methods enable spatial interpolation of sound fields from a set of discrete measurements. Such spatial characterization of sound fields is key in applications such as sound field analysis,1\u20138 sound field control,9\u201313 in simulation software (interpolation from a coarser to a finer grid),14 and for navigation of a sound field in auralization and spatial audio.15\u201319 Often, the sound field at hand is dominated by wavefronts of specific geometry, and a matching propagation model is sufficient to approximate the measurements and interpolate the sound field. Typical approaches use for example plane waves2,5,6,20,21 or spherical harmonics10,12,22 (in free or near field).\nWhen considering areas significantly larger than the acoustic wavelength, parts of the sound field can show significant influence of reflections, scattering, diffraction or varying wavefront curvature.7\u20139,19 To model fields across such large domains, typical approaches include wave expansions with a high number of terms, or dividing the global domain into smaller local subdomains. For example, plane waves have been proposed to interpolate between two local spherical harmonic decompositions.23 Another approach is to analyse the sound field in terms of independent overlapping subdomains, as it is common in other disciplines like image processing.24 In acoustic field analysis, subdomain representations using plane waves (also called ray space analysis) have been explored.25\u201327 Sparse subdomain representations have been examined for beamforming,28 and sound field reconstruction using plane waves29 and functions learned from measured sound fields.27\nSuch locally variant representations increase the number of model coefficients to span more complex obser-\na)Electronic mail: efgr@dtu.dk\nvations. However, independent local representations of sound fields ignore the continuous nature of wave propagation. Even diffuse fields, which exhibit the shortest possible correlation length, are commonly described as a superposition of infinitely many plane waves with random incidence angles and phases.30\u201332 It is therefore reasonable to assume spatial similarity between sound field representations in overlapping subdomains.\nConvolutional models express a given field in terms of a set of subdomain-size filters, convolved with a spatial coefficient map. The spatial coefficient map preserves the spatial context of subdomains and allows for joint analysis of neighbouring partitions, thereby capturing both the fine structure and large-scale features of the field.33\u201335 Such convolutional approaches often exploit sparsity to find optimal local filter coefficients. They are then known as convolutional or shift-invariant sparse coding in audio and image processing36\u201338 and parallels to convolutional neural networks exist.39 Convolutional analysis has previously been proposed for beamforming40, also in form of neural networks for spatial sound field interpolation41 and source localization.42\nIn this study, we express a monochromatic sound field in terms of a locally variant planar wave model. In a convolutional formulation, we enforce continuity between local representations to exploit observations in neighboring subdomains. In this way, we not only accommodate local phenomena, but also capture the global structure of the sound field (by context between neighbours). Specifically, we enforce spatially smooth coefficients in a joint analysis of all local plane wave representations. In addition to global continuity, we also require sparsity within each local subdomain. Because the spatial frequencies are bandlimited, sparse approximations enable reconstructions even from few observations within each local subdomain.2,43,44\nTo test the proposed continuous convolutional plane wave model, we reconstruct: in Sec. III A a simulated sound field in near field of a monopole, radially across a\nar X\niv :2\n20 8.\n11 32\n4v 2\n[ ee\nss .A\nS] 7\nN ov\n2 02\n2\nlinear array, in Sec. III B a simulated field of a monopole interferring with a plane wave across a 2D aperture and in Sec. III C the experimentally captured reverberant high-frequency sound field in a classroom across a large 2D aperture. The reconstruction is formulated as an Alternating Direction Method of Multipliers (ADMM) problem.45 Where applicable, steps are solved in frequency domain, where the convolution transforms to a multiplication.46,47 To enable reconstruction across a limited and sparsely sampled aperture, mask decoupling is applied.48,49 As benchmarks, global and independent local plane wave reconstructions are included in the tests."
        },
        {
            "heading": "II. THEORY",
            "text": "This section explains the sound field modelling and reconstruction approaches included in this study: the conventional linear superposition model in II A, the partitioning of the reconstruction domain into independent, overlapping subdomains in II B, the convolutional model to facilitate spatially smooth local coefficients in II C, its solution via ADMM in II D, and the assessment of reconstructed sound fields in II E."
        },
        {
            "heading": "A. Global sound field model and reconstruction",
            "text": "The true acoustic pressure p \u2208 CN at frequency f and N positions r \u2208 R3 within a domain \u2126 is assumed to be modelled as a linear combination of basis functions\np = Hx , (1)\nwhere x \u2208 CM are the coefficients and H \u2208 CN\u00d7M contains the M basis functions. For example, plane propagating waves e\u2212jk Tr are often used to model reverberant or far-fields, where k is the wavenumber vector (\u2016k\u20162 = 2\u03c0/\u03bb, \u03bb is the wavelength). In the case of plane waves, the n,mth element of H is e\u2212jk T mrn , with rn denoting the nth position and km the wavenumber vector from the mth incidence direction.\nFor the equation to hold, H must span the observed sound pressure field p over the complete domain \u2126. An observation of the sound pressure field is\npobs = Mp + n = Hobsx + n , (2)\nwhere M \u2208 {0, 1}Nobs\u00d7N is a binary mask selecting the Nobs available observations from the sound field p. Hobs = MH is the model at the observed positions and n is an error vector, that accounts for measurement noise and model error.\nAn optimal set of coefficients x\u0302 is found by inversion of Eq. (2). To arrive to a stable solution, regularization is necessary as H is typically ill-conditioned or rankdeficient.50 Typically, a structure in the coefficients is imposed, such as in\nx\u0302 = arg min x \u2016Hobsx\u2212 pobs\u201622 + \u03b2 \u2016x\u20161 , (3)\nin which case a `1-norm penalty is applied to promote a sparse structure in the coefficients and \u00b7\u0302 denotes an estimate. The sound field is then reconstructed as\np\u0302 = Hx\u0302 , (4)\nwhere p\u0302 \u2208 CN is the reconstructed sound pressure at N reconstruction positions."
        },
        {
            "heading": "B. Local subdomain sound field model",
            "text": "When reconstructing the sound field over large spatial domains (i.e. much larger than the acoustic wavelength), it is useful to partition the global domain \u2126 into smaller, overlapping subdomains \u2126sub. Correspondingly, the sound field p can be described by a collection of S subdomain sound fields ps \u2208 CNs\nP = [R1p \u00b7 \u00b7 \u00b7RSp] = [p1 \u00b7 \u00b7 \u00b7pS ] , P \u2208 CNs\u00d7S . (5)\nRs \u2208 {0, 1}Ns\u00d7N is a binary extraction operator to select the Ns positions contained in the s\nth subdomain \u2126s. The partitioning is illustrated on the left side of Fig. 1. For simplicity, all subdomains within a sound field are considered to have the same extent, such that Ns is constant. Specifically, this study considers subdomains of extent one wavelength \u03bb in each dimension of the aperture. Note that Eq. (5) yields a redundant representation of the sound field if the subdomains overlap (NsS \u2265 N).\nA sound field can then be reconstructed within each subdomain of the partitioned observations Pobs, for example by applying the procedure in Sec. II A and finding coefficients x\u0302x via Eq. (3) to estimate each p\u0302s. This yields the collection of reconstructed subdomain sound\nfields [see center right in Fig. 1].\nP\u0302 = HsX\u0302 , (6)\nwhere Hs are the model functions at the desired positions within each local subdomain, for example Hs = R1H, and\nX\u0302 = [x\u03021 \u00b7 \u00b7 \u00b7 x\u0302S ] , X\u0302 \u2208 CM\u00d7S (7)\nthe estimated local coefficients. The reconstructed field p\u0302 is reassembled from P\u0302 as the mean of overlapping subdomain representations [see right side of Fig. 1],\np\u0302 = W \u2211 s RTs p\u0302s , (8)\nwhere the diagonal matrix W = diag( \u2211 sR T s 1Ns)\n\u22121 normalizes by the spatial overlap of the subdomains and 1Ns denotes a vector of Ns ones.\nSuch partitioning approaches counteract model mismatch, which occurs if a global model is suboptimal. For example in the global sound field model of Eq. (1), the chosen model functions in H might not span observations of a sound field across a large spatial domain.\nEstimating independent coefficients for each subdomain allows for arbitrarily different wave components in each subdomain. Such independent treatment of local representations disregards the similarity or even redundancy between sound fields in nearby or overlapping local subdomains.\nThe coefficients in the local subdomain sound field model can also be understood as a collection of coefficient maps xm \u2208 CS , the rows in X = [xT1 \u00b7 \u00b7 \u00b7xTM ]T. The mth row in X contains a coefficient for the mth local model function across all S subdomain locations. When plane waves are used, the coefficient map xm contains the spatial distribution of coefficients for the mth plane wave across subdomain representations."
        },
        {
            "heading": "C. Convolutional sound field model",
            "text": "This study explores, how the spatial variations across xm, the rows of X, can be taken into account for reconstruction, such that the global structure (or topology) of the sound field can be preserved. For the remainder of the paper, we consider the reconstruction positions on a regular grid (containing also the measured positions as a subset). Further, we assume subdomains of equal size and with full overlap, such that S = N , the number of subdomains equals the number of positions in p (circular boundary conditions).\nThe true sound field across an L-dimensional aperture can be rewritten as a sum of M convolutions:\np = M\u2211 m=1 hm ~ L\u00b7 \u00b7 \u00b7~ xm , (9)\nwhere hm \u2208 CNs describes the mth local filter (the mth column of Hs), for example a plane wave. ~ L\u00b7 \u00b7 \u00b7~ denotes a circular convolution along L \u2208 1, 2, 3 spatial dimensions. For example for L = 1, the nth element of p is,\np(n) = \u2211 m (hm ~ xm)(n)\n= \u2211 m ( Ns\u2211 k=0 hm(k)xm ((N + n\u2212 k)%N) ) ,\nwhere n = 1, . . . N and % is the modulo operation. Compared to the collection of local sound fields in Sec. II B, this convolutional model reflects the spatial relations of coefficients and enables a joint analysis of all local representations in the global field. For example, each subdomain representation can take the coefficients in nearby subdomains into account. We propose to estimate the coefficients of Eq. (9) as\nX\u0302 = arg min X\n1\n2 \u2225\u2225\u2225\u2225\u2225M (\u2211\nm\nhm ~ L\u00b7 \u00b7 \u00b7~ xm ) \u2212 pobs \u2225\u2225\u2225\u2225\u2225 2\n2\n(10)\n+ \u00b5\n2 \u2211 m \u2211 l \u2016\u2206lxm\u201622 + \u03b2 \u2211 m \u2016xm\u20161 ,\nThe `1 penalty promotes sparse coefficients, notably applied on the global coefficient vector. A penalty on the spatial differences of the coefficients promotes smooth coefficient maps x\u0302m, weighted by the regularization parameter \u00b5. Specifically, \u2206lxm are the first order finite differences of the mth coefficient map along the lth dimension. For example, when the considered aperture (and therefore xm) is one-dimensional, it is \u2206xm = [xm1\u2212xm2, xm2\u2212xm3 \u00b7 \u00b7 \u00b7xmS\u2212xm1]T. Smooth coefficient maps x\u0302m enforce similarity between nearby and overlapping representations, which seems particularly suitable for sound fields."
        },
        {
            "heading": "D. Convolutional reconstruction via ADMM",
            "text": "To reconstruct a sound field via the convolutional model, we solve Eq. (10) via the alternating direction method of multipliers (ADMM)45 and rewrite Eq. (10) in matrix form\nx\u0302 = arg min x\n1 2 \u2016MD\u2217x\u2212 pobs\u201622 (11) + \u00b5\n2 \u2211 m \u2211 l \u2016G\u2217lxm\u2016 2 2 + \u03b2 \u2016x\u20161 ,\nwhere x \u2208 CMN are the stacked columns of X and D\u2217 \u2208 CN\u00d7MN is convolutional dictionary matrix such that D\u2217x = \u2211 m hm ~\nL\u00b7 \u00b7 \u00b7 ~ xm (e.g. for L = 1, D\u2217 is block-circulant with block Hs). G\u2217lxm calculates the\nfirst order finite differences of the mth coefficient map along the lth dimension. In the one-dimensional case, G\u2217 is a circulant matrix with the first row [1,\u22121,01\u00d7S\u22122], where 01\u00d7S\u22122 is a row vector of S \u2212 2 zeros.\nTo solve Eq. (11), we split the variables and reformulate the joint problem34,48,49 as\nminimize x,y0,y1\n1 2 \u2016My0 \u2212 pobs\u201622 + \u00b5 2 \u2211 m \u2211 l \u2016G\u2217lx\u2016 2 2 + \u03b2 \u2016y1\u20161\n(12)\nsubject to Ax\u2212 y = 0 ,\nwhere A = [ D\u2217 I ] and y = [ y0 y1 ] .\nThe ADMM steps in the kth iteration are\nxk+1 = arg min x\n\u00b5\n2 \u2211 m \u2211 l \u2016G\u2217lxm\u2016 2 2 (13)\n+ \u03c1\n2\n\u2225\u2225Ax\u2212 yk + uk\u2225\u22252 2\nyk+1 = arg min y\n1 2 \u2016My0 \u2212 pobs\u201622 + \u03b2 \u2016y1\u20161 (14)\n+ \u03c1\n2 \u2225\u2225\u2225Axk+1 \u2212 y + uk\u2225\u2225\u22252 2\nuk+1 = uk + Axk+1 \u2212 yk+1 , (15)\nwhere u = [u0,u1] T is the dual variable. The upper index k indicates the state before the kth iteration (omitted further on for readability). In spatial frequency domain, the convolutional matrices reduce to their transformed filters and Eq. (13) reduces to52( \u00b5G\u0303HG\u0303 + \u03c1D\u0303HD\u0303 ) x\u0303k+1 = D\u0303H (y\u03030 \u2212 u\u03030) + (y\u03031 \u2212 u\u03031) ,\n(16) which can be efficiently solved via the Sherman-Morrison formula47,53 and where \u00b7\u0303 indicates frequency domain quantities. Also, G\u0303HG\u0303 = \u2211 l G\u0303 H l G\u0303l, where G\u0303l is the frequency transformed finite difference matrix in the lth dimension. To align dimensions of D\u0303 to the sound field p\u0303, zeropadding is typically applied to the local filters hm (corresponding to [HTs ,0M\u00d7N\u2212Ns ] T, i.e. the first M columns of D\u2217). Instead, we obtain D\u0303 from plane waves functions evaluated over the complete sound field (i.e. the global plane wave expansion H). Equations (14) and (15) are separable, such that\ny0 k+1 = arg min\ny0\n1 2 \u2016My0 \u2212 pobs\u201622 (17)\n+ \u03c1\n2 \u2225\u2225\u2225y0 \u2212 (D\u2217xk+1 + u0k)\u2225\u2225\u22252 2\ny1 k+1 = arg min y1 \u03b2 \u2016y1\u20161 (18)\n+ \u03c1\n2 \u2225\u2225y1 \u2212 (xk+1 + u1k)\u2225\u222522 u0 k+1 = u0 k + D\u2217x\nk+1 \u2212 y0k+1 (19) u1 k+1 = u1 k + xk+1 \u2212 y1k+1 , (20)\nwhere the y0 update Eq. (17) has an efficient closed-form solution in frequency domain\ny\u0303k+10 = ( M\u0303HM\u0303 + \u03c1I )\u22121 ( M\u0303p\u0303obs + \u03c1 ( D\u0303x\u0303 k+1 + u\u0303k0 )) .\n(21)\ny1 is updated by soft-thresholding, separable along the elements of y1,\ny1 k+1 = S\u03b2/\u03c1 ( xk+1 + u1 k ) , (22)\nwhere S is the shrinkage operator\nS\u03b1(z) = sign(z) max(0, |z| \u2212 \u03b1) . (23)"
        },
        {
            "heading": "E. Assessment of reconstructed sound fields",
            "text": "To assess a reconstructed pressure field p\u0302, it is compared to the true field p in terms of the normalized mean square error NMSE and the spatial similarity C. The NMSE is\nNMSE = 20 log10 ( \u2016p\u0302\u2212 p\u20162 \u2016p\u20162 ) . (24)\nThe spatial similarity C is assessed as\nC = \u2223\u2223p\u0302Hp\u2223\u22232 (p\u0302Hp\u0302) (pHp) , (25)\nsuch that C = 0 indicates no similiarity and C = 1 means the fields are indistinguishable."
        },
        {
            "heading": "III. RESULTS",
            "text": "To demonstrate the proposed approach, we reconstruct simulated and measured sound fields. The proposed method is implemented with help of the SPORCO Python package54 and included as supplementary material.51"
        },
        {
            "heading": "A. Reconstruction along the radial distance from a monopole",
            "text": "The first experiment reconstructs the sound field by a monopole at the end of a linear microphone array, see Fig. 2(a). The sound pressure is simulated radially across ten wavelengths (\u03bb), spanning the near-field and the farfield of the monopole. The linear array consists of 31 microphones at 0.5\u03bb to 10.5\u03bb radial distance and with spacing of \u03bb/3. Three reconstruction methods are compared:\ni) global plane waves with least squares (no regularization in Eq. (3));\nii) local independent plane waves using compressive sensing, i.e. finding sparse representations via Eq. (3) for each local partition separately, then overlap and average;\niii) convolutional sparse plane waves with smooth coefficients via Eq. (10).\nAll three reconstruction methods use the same set of plane waves, with wavenumber \u2016k\u20162 = 2\u03c0\u03bb and 21 incidence angles equally spaced along a semicircle [0 \u00b7 \u00b7 \u00b7\u03c0]. This experiment interpolates from observations with resultion \u03bb/3 to a grid spacing of \u03bb/24. The aperture of length 10\u03bb contains N = 241 reconstruction positions. The local approaches operate use subdomains of size one wavelength. In this example, each subdomain contains Ns = 25 reconstruction points and at most 4 observations. Both sides of the domain are padded with Ns \u2212 1 zeros, to reduce artifacts from circular wrapping. The zero-padded domain has size N \u2032 = N + 2(Ns \u2212 1) = 289 and is partitioned in S = N \u2032 fully overlapping subdomains. After reconstruction, the sound field is cropped again to the original size N . For comparison, the local approaches determine MS = 21 \u00d7 289 coefficients compared to M = 21 in the global model.\nThe reconstructions p\u0302 are shown in Fig. 2(b) and the error p\u0302 \u2212 p in Fig. 2(c). All methods yield good re-\nconstructions. The error is lowest for the smooth convolutional model, where smooth coefficients (plane wave magnitude and direction) among neighbouring representations are enforced. Methods using locally variant plane wave coefficients are flexible enough to approximate all measurements (the error is zero at measurement positions). Still, they rely on sufficient measurements within a local partition to yield good predictions. The global plane wave model can not conform to all measurements across the array, because of the mismatch between the radial decay of the sound field and propagating plane waves.\nThe experiment is repeated for varying distances between the monopole source and the microphone array. The normalized spatial mean squared error (24) is shown in Fig. 3. When the array is close to the monopole, local representations improve reconstructions due to the field\u2019s high curvature and strong decay with distance. The proposed smooth-convolutional approach gives the most accurate reconstructions up to 0.7\u03bb. The error decreases with distance for all methods, due to the less pronounced magnitude decay in the field. The further the array is placed in far field, the more the true field approaches planar characteristics, such that also the global model fits to the observations well and yields the best predictions. It is to note that in an application scenario, the reconstruction quality depends on many factors, such as the aperture size, curvature of wavefronts within the aperture, number and distribution of measurements available and not at least the evaluation criteria.\nB. 2D reconstruction: monopole and plane wave\nThe approach is tested for a two-dimensional aperture of size (5\u03bb)2 in the plane z = 0. The sound field is generated by interference of a monopole at (0,0,\u03bb/8) with a plane wave propagating in k/k = (kx, ky, kz)/k = (0.38,\u22120.76, 0.52). Four plane wave reconstructions are\ntested:\ni) global plane waves with ridge regression (`2-norm regularization in Eq. (3), parameter \u03b2 via leaveone-out cross-validation);\nii) local independent, sparse plane waves (solving Eq. (3) via least-angle regression, regularization via leave-one-out cross-validation);\niii) convolutional sparse plane waves without smooth coefficients (\u00b5 = 0 in Eq. (10));\niv) convolutional sparse plane waves with smooth coefficients via Eq. (10).\nAll models use plane waves with propagation angles distributed in a fibonacci grid (kz \u2265 0 hemisphere). The global method i) uses M = 1000 propagation angles, the local methods ii-iv) M = 100 angles. The reconstruction grid is regular with spacing of d = \u03bb/10 between positions (N = 512). The local subdomains and filters in methods ii)-iv) have size \u03bb2 (i.e. Ns = (b\u03bb/dc + 1)2 = 112 discrete positions). For methods iii) and iv), the domain is zeropadded (with \u221a Ns\u22121 in each direction) to avoid artifacts from circular convolutions (N \u2032 = ( \u221a N + 2( \u221a Ns \u2212 1))2 = 3481). The regularization parameters are tuned to \u03b2 = 1 \u00d7 10\u22125, \u00b5 = 1 \u00d7 10\u22123 (0 for iii) ), \u03c1 = 1 \u00d7 10\u22125, and the ADMM iterations are stopped after 500 iterations. Note that this demonstration showcase exhibits a high signal to noise ratio. In less favourable conditions, the regularization would likely need to be adjusted.\nThe results are shown in Fig. 4. For reconstructions from 100 microphones, the global and the proposed approach with smooth local coefficients capture the spatial phenomena better than the two other approaches ii) and iii), which only rely on local and global sparsity. The spatially invariant (global) and slowly varying (proposed) models prescribe the necessary spatial structure\nto reconstruct from few measurements. Both methods exploit measurements across a larger spatial range and capture the global structure of the sound field, which is critical in sparsely sampled scenarios (see Fig. 4(b) and (e) vs. (c-d). When more microphones are available, spatially variant (local) models benefit from their flexibility to model complex sound fields. The global approach exhibits artefacts around the monopole due to the strong decay and curvature of the wavefronts in this region. The proposed approach balances local flexibility with global structure and yield good reconstructions in both cases. Note that method iii) and the proposed method iv) apply the same shrinkage threshold \u03b2/\u03c1 to all local coefficients (see Eq. (22)). Dynamic regularization could further improve the results, as it was observed for the independent local approach ii) (which uses cross-validation to find an optimal \u03b2 for each subdomain).\nThe particle velocity and sound intensity xy-vector fields of the reconstructions from 300 microphones (second row Fig. 4) are shown in Fig. 5. Global representations can not conform to the drastic spatial variations close to the monopole, all particle velocity vectors point outwards from (x, y) = (0, 0). Local approaches recover the fine structure of particle velocity and intensity also around the monopole."
        },
        {
            "heading": "C. Experimental reconstruction with real data: classroom measurement",
            "text": "The same methods i)-iv) from Sec. III B (and parameters) are used to reconstruct the enclosed reverberant sound field in a classroom (DTU building 352, Lyngby, Denmark), shown in Fig. 6. The room dimensions are (lx, ly, lz) = (6.63, 9.45, 2.97) m, the reverberation time approx. T60 = 0.5 s, the Schro\u0308der frequency fS \u2248 240 Hz.\n150 ms 1\n2 0 2\n0\n2 4 y [ ]\ntrue Re{uxy} 2 Wm 2\n2 0 2\n0\n2\n4 Re{Ixy}\n2 0 2 x [ ]\n0\n2\n4\ny [\n]\nglobal\n2 0 2 x [ ]\n0\n2\n4\n55\n60\n65\nL u [d\nB re\nl u re\nf]\n55\n60 65 L u [d B re l u\nre f]\n50\n55\n60\n65\nL I [d\nB re\nl I re\nf]\n50\n55\n60\n65\nL I [d\nB re\nl I re\nf]\n150 ms 1\ny [\n]\ntrue Re{uxy} 2 Wm 2Re{Ixy}\n2 0 2 x [ ]\n0\n2\n4\ny [\n]\nlocal independent\n2 0 2 x [ ]\n0\n2\n4\nL u [d\nB re\nl u re\nf]\n55\n60\n65\nL u [d\nB re\nl u re\nf]\nL I [d\nB re\nl I re\nf]\n50\n55\n60\n65\nL I [d\nB re\nl I re\nf]\n150 ms 1\ny [\n]\ntrue Re{uxy} 2 Wm 2Re{Ixy}\nconv. smooth\nL u [d\nB re\nl u re\nf]\nL I [d\nB re\nl I re\nf]\nThe room is furnished and its walls are somewhat irregular, with wooden floor, scattering elements on the walls and absorbing ceiling. A loudspeaker (BM6, Dynaudio, Skanderborg, Denmark) placed in a room corner was used to excite the room with 10 s logarithmic sweeps from 20 Hz to 20 kHz. A total of 4761 frequency responses were measured using a robotic arm (UR5, Universal Robots, Odense, Denmark) with a 1/2 inch free\nfield condenser microphone (Bru\u0308el&Kja\u0308er, N\u00e6rum, Denmark). The positions are distributed over a 1.7\u00d7 1.7 m2 planar aperture with N = 692 positions on a regular grid with 2.5 cm spacing. We refer the reader to 27 for more information on the room and measurements and to 55 for the dataset.\nThe sound field in the classroom is reconstructed at 1000 Hz from 98 and 295 measurements, distributed with uniform probability (and a minimum distance of 7 cm) across the aperture. Reconstructions using i-iv) and measured reference (\u201ctrue\u201d) of the classroom sound field are shown in Fig. 7 for the two cases with Nobs = 98 and 295. To reconstruct from few measurements, it is necessary to capture the global structure of the sound field, as in the global and the proposed approach (Fig. 7(b) and (d)). Models based on local representations conform easier to many measurements due to their higher number of coefficients (Fig. 7(i-k)). Specifically in this test, subdomains of size \u03bb2 contain Ns = 24\n2 discrete reconstruction positions, such that local models use a total of ii) MN = 476100 and with padding iii+iv) MN \u2032 = M( \u221a N + 2( \u221a Ns \u2212 1))2 = 1322500 coefficients compared to 1000 in the global model. The proposed approach combines both local flexibility and joint global analysis. As a consequence, it yields the highest similarity and lowest reconstruction errors when compared to the measured field.\nThe benefit of smooth coefficients shows when comparing the two convolutional approaches. Both seek a sparse approximation of the measurements, but spatial continuity is required to reconstruct sound fields successfully via local representations. Also the local independent approach yields smooth reconstructions, namely by averaging of overlapping partitions. However, a joint analysis of nearby representations is needed to align nearby coefficients and hence, indirectly exploit nearby measurements. In this study, the sparsity constraint enables feasible reconstructions also when only few measurements are available within a local subdomain and the inverse problem is severely underdetermined. As such, it is not the goal to represent the sound field using the fewest\n1.1 1.5 2.0 2.5 3.0\n3.5\n4.0\n4.5\ny [ m\n] 1000 Hz, Nobs=98 (2.00 mics per )\n(a) pobs\n1.1 1.5 2.0 2.5 3.0\n3.5\n4.0\n4.5\nC = 0.73 NMSE = -5.66 dB\n(b) p global\n1.1 1.5 2.0 2.5 3.0\n3.5\n4.0\n4.5\nC = 0.57 NMSE = -3.32 dB\n(c) p local independent\n1.1 1.5 2.0 2.5 3.0\n3.5\n4.0\n4.5\nC = 0.54 NMSE = -3.24 dB\n(d) p conv. sparse\n1.1 1.5 2.0 2.5 3.0\n3.5\n4.0\n4.5\nC = 0.75 NMSE = -6.05 dB\n(e) p conv. smooth\n1.1 1.5 2.0 2.5 3.0\n3.5\n4.0\n4.5\n(f) p true\n1.1 1.5 2.0 2.5 x [m]\n3.0\n3.5\n4.0\n4.5\ny [ m\n]\n1000 Hz, Nobs=295 (3.46 mics per )\n(g) pobs\n1.1 1.5 2.0 2.5 x [m]\n3.0\n3.5\n4.0\n4.5\nC = 0.96 NMSE = -13.71 dB\n(h) p global\n1.1 1.5 2.0 2.5 x [m]\n3.0\n3.5\n4.0\n4.5\nC = 0.96 NMSE = -14.26 dB\n(i) p local independent\n1.1 1.5 2.0 2.5 x [m]\n3.0\n3.5\n4.0\n4.5\nC = 0.91 NMSE = -10.09 dB\n(j) p conv. sparse\n1.1 1.5 2.0 2.5 x [m]\n3.0\n3.5\n4.0\n4.5\nC = 0.98 NMSE = -16.61 dB\n(k) p conv. smooth\n1.1 1.5 2.0 2.5 x [m]\n3.0\n3.5\n4.0\n4.5\n(l) p true\n20\n10\n0\n10\n20\n10\n0\n10\n20\n10\n0\n10\n20\n10\n0\n10\n20\n10\n0\n10\n20\n10\n0\n10\n[d B\nre l <\np2 t ru\ne >\n]\n20\n10\n0\n10\n20\n10\n0\n10\n20\n10\n0\n10\n20\n10\n0\n10\n20\n10\n0\n10\n20\n10\n0\n10\n[d B\nre l <\np2 t ru\ne >\n]\nFIG. 7. (Color online) Reconstructions of the sound pressure field in a classroom, from 98 (top row) and 295 microphones (bottom row). Left to right: measurements, reconstructions using global plane waves, independent local sparse representations, joint analysis with global sparsity, joint analysis with global sparsity and continuity, true reference. The aligned color scale is in dB, relative to the spatial mean of the squared true pressure field, < p2true >.\nnumber of coefficients, but local sparsity is a means of exploiting the available measurements.\nThe experiment in Fig. 7 is extended to other frequencies and reconstruct the sound field in the classroom from 500 Hz to 2 kHz using a fixed number of microphones. The NMSE results in Fig. 8 show that the proposed approach yields good reconstructions when average distance between measurements is lower than \u03bb/2. The proposed approach yields significant improvement with errors close to (see Fig. 8(a)), or lower than global plane waves (for sufficient measurements, see Fig. 8(b,c))."
        },
        {
            "heading": "IV. CONCLUSION",
            "text": "This study formulates a sound field model as a spatial convolution between a global coefficient map and local plane wave filters. This model leads to a joint analysis of all local representations, while keeping their spatial relation (and thereby the global structure of the field) intact. By penalizing the spatial differences of plane wave coefficients, continuity between neighboring representations is enforced in terms of amplitude and direction of the plane waves. In this way, each local representation has to be consistent with its neighbours, and can therefore utilise nearby observations. The experiments indicate that the proposed approach both conforms to complex spatial sound fields and also preserves the global structure of the sound field. Compared to other local models using locally sparse coding in terms of plane waves, the proposed approach attains better reconstructions of sound fields when few measurements are available. When measurements are very scarcely distributed, an expansion of the entire global field in terms of plane waves yields the best reconstructions. However, when sufficient measurements are available, the experiments indicate that local\nrepresentation models conform best to fields of higher complexity. This is shown for the reconstruction of the sound pressure, as well as for the reconstruction of particle velocity and sound intensity vector fields, where the improvements are even more substantial."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "This work is funded by VILLUM Fonden through VILLUM Young Investigator grant number 19179 for the project \u2018Large-scale Acoustic Holography\u2019.\n1F. Jacobsen and E. Tiana Roig, \u201cMeasurement of the sound power incident on the walls of a reverberation room with near field acoustic holography,\u201d Acustica United w. Acta Acustica 96(1), 76\u201381 (2010). 2S. A. Verburg and E. Fernandez-Grande, \u201cReconstruction of the sound field in a room using compressive sensing,\u201d J. Acoust. Soc. Am. 143(6), 3770\u20133779 (2018). 3Y. Haneda, Y. Kaneda, and N. Kitawaki, \u201cCommon-acousticalpole and residue model and its application to spatial interpolation and extrapolation of a room transfer function,\u201d IEEE Trans. Sp. Audio Proc. 7(6), 709\u2013717 (1999). 4R. Mignot, L. Daudet, and F. Ollivier, \u201cRoom reverberation reconstruction: Interpolation of the early part using compressed sensing,\u201d IEEE/ACM Trans. Audio, Speech, Lang. Process. 21(11), 6562745, 2301\u20132312 (2013). 5R. Mignot, G. Chardon, and L. Daudet, \u201cLow frequency interpolation of room impulse responses using compressed sensing,\u201d IEEE/ACM Trans. Audio, Speech, Lang. Process. 22(1), 205\u2013 216 (2014). 6M. Nolan, S. A. Verburg, J. Brunskog, and E. Fernandez-Grande, \u201cExperimental characterization of the sound field in a reverberation room,\u201d J. Acoust. Soc. Am. 145(4), 2237\u20132246 (2019). 7I. B. Witew, M. Vorla\u0308nder, and N. Xiang, \u201cSampling the sound field in auditoria using large natural-scale array measurements,\u201d J. Acoust. Soc. Am. 141(3), EL300\u2013EL306 (2017). 8E. Branda\u0303o and E. Fernandez-Grande, \u201cAnalysis of the sound field above finite absorbers in the wave-number domain,\u201d J. Acoust. Soc. Am. 151(5), 3019\u20133030 (2022).\n500 700 1000 1250 1600 2000 Frequency [Hz]\n20 15 10\n5 0\nNM SE\n[d B]\ndm = /2\n(a) 80 measurements\nConvolutional Global\nLocal independent\n500 700 1000 1250 1600 2000 Frequency [Hz]\n20 15 10\n5 0\nNM SE\n[d B]\ndm = /2\n(b) 160 measurements\n(c) 320 measurements\n9F. M. Heuchel, D. Caviedes-Nozal, J. Brunskog, and F. T. Agerkvist, \u201cLarge-scale outdoor sound field control,\u201d J. Acoust. Soc. Am. 148(4), 2392\u20132402 (2020). 10D. Caviedes-Nozal, F. M. Heuchel, J. Brunskog, N. A. B. Riis, and E. Fernandez-Grande, \u201cA bayesian spherical harmonics source radiation model for sound field control,\u201d J. Acoust. Soc. Am. 146(5), 3425\u20133435 (2019). 11F. M. Heuchel, E. Fernandez-Grande, F. T. Agerkvist, and E. Shabalina, \u201cActive room compensation for sound reinforcement using sound field separation techniques,\u201d J. Acoust. Soc. Am. 143(3), 1346\u20131354 (2018). 12T. Betlehem and T. D. Abhayapala, \u201cTheory and design of sound field reproduction in reverberant rooms,\u201d J. Acoust. Soc. Am. 117(4), 2100\u20132111 (2005). 13M. B. M\u00f8ller, J. K. Nielsen, E. Fernandez-Grande, and S. K. Olesen, \u201cOn the influence of transfer function noise on sound zone control in a room,\u201d IEEE/ACM Trans. Audio, Speech, Lang. Process. 27(9), 1405\u20131418 (2019). 14N. Borrel-Jensen, A. P. Engsig-Karup, and C.-H. Jeong, \u201cPhysics-informed neural networks for one-dimensional sound field predictions with parameterized sources and impedance\nboundaries,\u201d JASA Express Letters 1(12), 122402 (2021). 15J. G. Tylka and E. Y. Choueiri, \u201cEvaluation of techniques for\nnavigation of higher-order ambisonics,\u201d J. Acoust. Soc. Am. 141(5), 3511\u20133511 (2017). 16J. G. Tylka and E. Y. Choueiri, \u201cFundamentals of a parametric method for virtual navigation within an array of ambisonics microphones,\u201d J. Audio Eng. Soc. 68(3), 120\u2013137 (2020). 17F. Winter, F. Schultz, and S. Spors, \u201cLocalization properties of data-based binaural synthesis including translatory headmovements,\u201d Proceedings of Forum Acusticum 2014- (2014). 18F. Schultz and S. Spors, \u201cData-based binaural synthesis including rotational and translatory head-movements,\u201d in Audio Eng. Soc. Conf.: Sound Field Control - Eng. and Percep. (2013). 19E. Fernandez-Grande, D. Caviedes-Nozal, M. Hahmann, X. Karakonstantis, and S. A. Verburg, \u201cReconstruction of room impulse responses over extended domains for navigable sound field reproduction,\u201d in Proceed. Int. Conf. Immers. 3D Audio, IEEE (2021), p. 8 pp. 20F. Jacobsen and P. M. Juhl, Fundamentals of general linear acoustics (Wiley, London, 2013). 21A. Moiola, R. Hiptmair, and I. Perugia, \u201cPlane wave approximation of homogeneous helmholtz solutions,\u201d Zeitschrift Fur Angewandte Mathematik Und Physik 62(5), 809\u2013837 (2011). 22M. Pezzoli, M. Cobos, F. Antonacci, and A. Sarti, \u201cSparsitybased sound field separation in the spherical harmonics domain,\u201d in IEEE Int. Conf. Acoust. Sp. Sig. Process. (ICASSP) (2022), pp. 1051\u20131055. 23J. G. Tylka and E. Y. Choueiri, \u201cPerformance of linear extrapolation methods for virtual sound field navigation,\u201d J. Audio Eng. Soc. 68(3), 138\u2013156 (2020). 24M. Elad and M. Aharon, \u201cImage denoising via sparse and redundant representations over learned dictionaries,\u201d IEEE Trans. Image Process. 15(12), 3736\u20133745 (2006). 25D. Markovic, L. Bianchi, S. Tubaro, and A. Sarti, \u201cExtraction of acoustic sources through the processing of sound field maps in the ray space,\u201d IEEE/ACM Trans. Audio, Speech, Lang. Process. 24(12), 2481\u20132494 (2016). 26D. Markovic, F. Antonacci, A. Sarti, and S. Tubaro, \u201cSoundfield imaging in the ray space,\u201d IEEE/ACM Trans. Audio, Speech, Lang. Process. 21(12), 2493\u20132505 (2013). 27M. Hahmann, S. A. Verburg, and E. Fernandez-Grande, \u201cSpatial reconstruction of sound fields using local and data-driven functions,\u201d J. Acoust. Soc. Am. 150(6), 4417\u20134428 (2021). 28C. Jin, F. Antonacci, and A. Sarti, \u201cRay space analysis with sparse recovery,\u201d in 2017 IEEE Works. Appl. Si. Process. Aud. Acous. (WASPAA) (2017), pp. 239\u2013243. 29S. Yu, C. Jin, F. Antonacci, and A. Sarti, \u201cSparse recovery beamforming and upscaling in the ray space,\u201d in IEEE Int. Conf. Acoust. Sp. Sig. Process. (ICASSP) (2021), pp. 776\u2013780. 30P. Morse and R. Bolt, \u201cSound waves in rooms,\u201d Reviews of Modern Physics 16(2), 0069\u20130150 (1944). 31M. Schro\u0308der, \u201cEigenfrequenzstatistik und anregungsstatistik in ra\u0308umen - modellversuche mit elektrischen wellen,\u201d Acustica 4(4), 456\u2013468 (1954). 32A. D. Pierce, Acoustics. An introduction to its physical principles and applications (McGraw-Hill, New York, 1981). 33V. Papyan, J. Sulam, and M. Elad, \u201cWorking locally thinking globally: Theoretical guarantees for convolutional sparse coding,\u201d IEEE Trans. Signal Process. 65(21), 7997798, 5687\u20135701 (2017). 34B. Wohlberg, \u201cConvolutional sparse representations with gradient penalties,\u201d ICASSP, IEEE Int. Conf. Acoust., Speech and Sig. Proc. - Proceedings 2018-, 8462151 (2018). 35M. J. Bianco and P. Gerstoft, \u201cTravel time tomography with adaptive dictionaries,\u201d IEEE Trans. Comput. Imaging 4(4), 499\u2013 511 (2018). 36R. Grosse, R. Raina, H. Kwong, and A. Y. Ng, \u201cShift-invariant sparse coding for audio classification,\u201d Proc. Conf. on Uncert. in Art. Int. 149\u2013158 (2007). 37M. M\u00f8rup, L. K. Hansen, S. M. Arnfred, L.-H. Lim, and\nK. H. Madsen, \u201cShift invariant multi-linear decomposition of neuroimaging data,\u201d Neuroimage 42(4), 1439\u20131450 (2008). 38D. Batenkov, Y. Romano, and M. Elad, \u201cOn the global-local dichotomy in sparsity modeling,\u201d Applied and Numerical Harmonic Analysis 1\u201353 (2017). 39V. Papyan, Y. Romano, and M. Elad, \u201cConvolutional neural networks analyzed via convolutional sparse coding,\u201d J. Machine Learning Research 18, 1\u201352 (2017). 40R. Cohen and Y. C. Eldar, \u201cSparse convolutional beamforming for ultrasound imaging,\u201d IEEE Trans. Ultras, Ferroel., and Freq. Control 65(12), 2390\u20132406 (2018). 41F. Llu\u0301\u0131s, P. Mart\u0301\u0131nez-Nuevo, M. Bo M\u00f8ller, and S. Ewan Shepstone, \u201cSound field reconstruction in rooms: Inpainting meets super-resolution,\u201d J. Acoust. Soc. Am. 148(2), 649 (2020). 42P.-A. Grumiaux, S. Kitic\u0301, L. Girin, and A. Gue\u0301rin, \u201cA survey of sound source localization with deep learning methods,\u201d J. Acoust. Soc. Am. 152(1), 107\u2013151 (2022). 43P. Gerstoft, C. F. Mecklenbra\u0308uker, W. Seong, and M. Bianco, \u201cIntroduction to compressive sensing in acoustics,\u201d J. Acoust. Soc. Am. 143(6), 3731\u20133736 (2018). 44E. J. Candes and M. B. Wakin, \u201cAn introduction to compressive sampling,\u201d IEEE Signal Process. Mag. 25(2), 21\u201330 (2008). 45S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, \u201cDistributed optimization and statistical learning via the alternating direction method of multipliers,\u201d Foundations and Trends in Machine Learning 3(1), 1\u2013122 (2010). 46F. Heide, W. Heidrich, and G. Wetzstein, \u201cFast and flexible con-\nvolutional sparse coding,\u201d in Proc. IEEE Conf. on Comp. Vision and Pattern Rec. (CVPR) (2015), pp. 5135\u20135143. 47B. Wohlberg, \u201cEfficient algorithms for convolutional sparse representations,\u201d IEEE Trans. Image Processing 25(1), 7308045 (2016). 48B. Wohlberg, \u201cBoundary handling for convolutional sparse representations,\u201d Proceedings - International Conference on Image Processing, Icip 2016-, 7532675, 1833\u20131837 (2016). 49B. Wohlberg and P. Rodriguez, \u201cConvolutional sparse coding: Boundary handling revisited,\u201d (2017). 50P. C. Hansen, Rank-Deficient and Discrete Ill-Posed Problems: Numerical Aspects of Linear Inversion (SIAM, Philadelphia, 1998), pp. 1\u201316. 51See the code repository https://github.com/manvhah/ convolutional_plane_waves to run experiments. 52F. Heide, W. Heidrich, and G. Wetzstein, \u201cFast and flexible convolutional sparse coding,\u201d Proc. IEEE Conf. on Comp. Vision and Pattern Rec. (CVPR) 07-12-, 7299149, 5135\u20135143 (2015). 53B. Wohlberg, \u201cEfficient convolutional sparse coding,\u201d in Proc. IEEE Int. Conf. on Acoust., Speech, and Sig. Process. (ICASSP) (2014), pp. 7173\u20137177. 54B. Wohlberg, \u201cSPORCO: A Python package for standard and convolutional sparse representations,\u201d in Proceed. of the 15th Python in Science Conf., Austin, TX, USA (2017), pp. 1\u20138. 55M. Hahmann, S. A. Verburg, and E. Fernandez-Grande, \u201cAcoustic frequency responses in a conventional classroom\u201d Dataset doi: 10.11583/DTU.13315286 (2021)."
        }
    ],
    "title": "A convolutional plane wave model for sound field reconstruction",
    "year": 2022
}