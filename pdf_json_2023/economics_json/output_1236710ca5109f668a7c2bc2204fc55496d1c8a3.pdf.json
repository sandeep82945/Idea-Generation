{
    "abstractText": "This paper offers a framework for the study of strategic behavior in proxy voting, where non-active voters delegate their votes to active voters. We further study how proxy voting affects the strategic behavior of non-active voters and proxies (active voters) under complete and partial information. We focus on the median voting rule for singlepeaked preferences. Our results show strategyproofness with respect to non-active voters. Furthermore, while strategyproofness does not extend to proxies, we show that the outcome is bounded and, under mild restrictions, strategic behavior leads to socially optimal outcomes. We further show that our results extend to partial information settings, and in particular for regret-averse agents.",
    "authors": [
        {
            "affiliations": [],
            "name": "Gili Bielous"
        }
    ],
    "id": "SP:c3381e2c582f790173a2161d28c41dd4b0990088",
    "references": [
        {
            "authors": [
                "N. Alon",
                "M. Feldman",
                "O. Lev",
                "M. Tennenholtz"
            ],
            "title": "How robust is the wisdom of the crowds",
            "venue": "In Twenty-Fourth International Joint Conference on Artificial Intelligence. Citeseer,",
            "year": 2015
        },
        {
            "authors": [
                "G. Bielous",
                "R. Meir"
            ],
            "title": "Proxy manipulation for better outcomes",
            "venue": "In MultiAgent Systems: 19th European Conference, EUMAS 2022,",
            "year": 2022
        },
        {
            "authors": [
                "D. Black"
            ],
            "title": "On the rationale of group decision-making",
            "venue": "Journal of political economy,",
            "year": 1948
        },
        {
            "authors": [
                "S. Br\u00e2nzei",
                "I. Caragiannis",
                "J. Morgenstern",
                "A. Procaccia"
            ],
            "title": "How bad is selfish voting",
            "venue": "In Proceedings of the AAAI conference on artificial intelligence,",
            "year": 2013
        },
        {
            "authors": [
                "I. Caragiannis",
                "E. Micha"
            ],
            "title": "A contribution to the critique of liquid democracy",
            "venue": "In IJCAI,",
            "year": 2019
        },
        {
            "authors": [
                "G. Cohensius",
                "S. Manor",
                "R. Meir",
                "E. Meirom",
                "A. Orda"
            ],
            "title": "Proxy voting for better outcomes",
            "venue": "In AAMAS\u201917,",
            "year": 2017
        },
        {
            "authors": [
                "V. Conitzer",
                "T. Walsh",
                "L. Xia"
            ],
            "title": "Dominating manipulations in voting with partial information",
            "venue": "In Twenty-Fifth AAAI Conference on Artificial Intelligence,",
            "year": 2011
        },
        {
            "authors": [
                "Y. Desmedt",
                "E. Elkind"
            ],
            "title": "Equilibria of plurality voting with abstentions",
            "venue": "In Proceedings of the 11th ACM conference on Electronic commerce,",
            "year": 2010
        },
        {
            "authors": [
                "A. Downs"
            ],
            "title": "An economic theory of democracy",
            "venue": "Harper & Row New York,",
            "year": 1957
        },
        {
            "authors": [
                "B. Dutta",
                "M.O. Jackson",
                "M. Le Breton"
            ],
            "title": "Strategic candidacy and voting procedures",
            "year": 2001
        },
        {
            "authors": [
                "M. Feldman",
                "A. Fiat",
                "S. Obraztsova"
            ],
            "title": "Variations on the hotelling-downs model",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2016
        },
        {
            "authors": [
                "W.V. Gehrlein",
                "D. Lepelley"
            ],
            "title": "Voting paradoxes and group coherence: the Condorcet efficiency of voting rules",
            "venue": "Springer Science & Business Media,",
            "year": 2010
        },
        {
            "authors": [
                "M. Ghodsi",
                "M. Latifian",
                "M. Seddighin"
            ],
            "title": "On the distortion value of the elections with abstention",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2019
        },
        {
            "authors": [
                "A. Gibbard"
            ],
            "title": "Manipulation of voting schemes: a general result",
            "venue": "Econometrica: journal of the Econometric Society,",
            "year": 1973
        },
        {
            "authors": [
                "P. G\u00f6lz",
                "A. Kahng",
                "S. Mackenzie",
                "A.D. Procaccia"
            ],
            "title": "The fluid mechanics of liquid democracy",
            "venue": "ACM Transactions on Economics and Computation,",
            "year": 2021
        },
        {
            "authors": [
                "U. Grandi",
                "A. Loreggia",
                "F. Rossi",
                "K.B. Venable",
                "T. Walsh"
            ],
            "title": "Restricted manipulation in iterative voting: Condorcet efficiency and borda score",
            "venue": "In Algorithmic Decision Theory: Third International Conference,",
            "year": 2013
        },
        {
            "authors": [
                "A. Reijngoud",
                "U. Endriss"
            ],
            "title": "Voter response to iterated poll information",
            "year": 2006
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n30 5.\n10 96\n9v 1\n[ cs\n.G T\n] 1\n8 M\nay 2\nKeywords: Computational Social Choice \u00b7 Proxy Voting \u00b7 Strategic Voting \u00b7 Strategyproofness."
        },
        {
            "heading": "1 Introduction",
            "text": "In the age of internet, we see an increase of platforms and mechanisms for collective decision-making. However, many of these platforms suffer from low participation rates [Schaupp and Carter, 2005; Jo\u0308nsson and O\u0308rnebring, 2011]. Thus, while there is an increase in the ability of individuals to influence collective decision-making in many areas, most decisions are made by a small, non-elected and non-representative groups of active voters. Partial participation may increase vote distortion [Ghodsi et al., 2019] (the worst-case ratio between the social cost of the candidate elected and the optimal candidate, first defined in [Procaccia and Rosenschein, 2006]); lead to counter-intuitive equilibria [Desmedt and Elkind, 2010]; and significantly decrease the likelihood of selecting the Condorcet winner (when it exists) [Gehrlein and Lepelley, 2010]. Above all, when the outcome of an election only considers a fraction of all opinions, it is unreasonable to assume that they accurately reflect the aggregated opinions of the collective.\nProxy voting, a long standing practice in politics and corporates [Riddick and Butcher, 1991], and an up-and-coming practice in e-voting and participatory democracies [Petrik, 2009], aims at mitigating the adverse effects of partial participation. Non-active voters (followers) delegate their vote to another active voter (proxy),\nthereby at least having some influence on the outcome. Cohensius et al. [2017] proposed a model where the voters are sampled from a given distribution of non-atomic voters. Among them are a subset of proxies, with voting power proportional to the population mass that delegates to them. The outcomes of various voting rules, in particular the median voting rule, as determined by the voters are compared against the outcome via proxy voting. They show that for most settings, the outcome via proxy voting improves the accuracy with respect to the aggregated social preference of the entire population.\nHowever, such delegation changes the power dynamic of voters by shifting some of the voting power to proxies. While much consideration is granted in the literature of social choice for the strategic behavior of voters [Gibbard, 1973; Satterthwaite, 1975] and candidates [Dutta et al., 2001; Sabato et al., 2017], there is little consideration of the strategic behavior of proxies or followers in proxy-mediated settings. Cohensius et al. [2017] consider strategic participation (i.e. selecting to participate or abstain) with mostly positive results. Notably, they show convergence to an equilibrium with the same accuracy as without strategic behavior using proxy voting. Yet they pose the question of strategic behavior of followers as an open question, which was part of the inspiration to the current study.\nMoreover, it is common to study strategic behavior in adversarial settings assuming complete information. This makes sense as a worst-case assumption for strategyproofness, but treating uncertainty is unavoidable when we are trying to model actual strategic voting and predict its implications (for an overview of uncertainty in voting and equilibrium models, see Meir [2018] Chapters 6 and 8). In the context of proxy voting, assuming full information is even less reasonable: by delegating their vote, followers may wish to avoid the cognitive strain, time loss and other costs associated with determining and communicating their position. Thus, a setting that requires followers to explicitly define their positions negates these benefits of proxy voting for followers.\nTherefore, it makes more sense that active voters set their strategies based on partial information on the positions of potential followers. While there are many ways to model such uncertainty, we adopt the framework of Reijngoud and Endriss [2012] that allows for simple and flexible definition of information sets."
        },
        {
            "heading": "1.1 Related Work",
            "text": "The effects of delegation on the accuracy of results have been recently studied in the context of liquid democracy, a delegation model where voters may continue to transitively delegate their votes. Kahng et al. [2021]; Caragiannis and Micha [2019] show that the concentration of power in liquid democracy can be so severe that it leads to low accuracy with respect to an assumed ground truth. Subsequent work attempted to limit power concentration, either by an impartial planner [Go\u0308lz et al., 2021] or in by altering the delegation mechanism Halpern et al. [2021]. In contrast, as previously mentioned Cohensius et al. [2017] achieved positive results for one-step (proxy) delegation.\nThere are two closely related spatial models to our setting. The first is the model of Cohensius et al. [2017] mentioned above. The second is Strategic Candidacy Games proposed by Sabato et al. [2017], where candidates are assumed to have self-supporting preferences over possible outcomes. Thus, candidates have incentives to strategize even when they cannot guarantee their own win. Their results show the existence of a Nash equilibrium for Condorcet-consistent voting rules for voters with symmetric single-peaked preferences and every set of preferences for candidates. Our model differs and generalizes in the following sense. First, in our model, candidates\u2019 preferences are based on the outcome, not the identities of candidates. In particular, the preferences are determined ex-post for a given state. Second, candidates in Sabato et al. [2017] are weightless, while voters (equivalent to followers in our model) are atomic. Our results demonstrate a stronger claim than the mere existence of a Nash Equilibrium, even for this generalized model. In particular, we show convergence to NE similar to the one described by their work (subject to certain restrictions). As a result, our work significantly expands upon theirs. Moreover, some of our results become trivialized when proxies are non-atomic."
        },
        {
            "heading": "1.2 Contribution and Paper Structure",
            "text": "The use of spatial models for the study of behavior and results of voting mechanisms have been first introduced by Hotelling [1929] and Downs [1957]. Our model follows this approach, is too a spatial model, assuming the political spectrum is represented as positions on the real line. We focus on the median voting rule that has been shown to be (group) strategyproof for single-peaked preferences [Black, 1948; Moulin, 1980].\nIt is important to stress that the objectives of candidates in Hotelling-Downs is different than our setting. Proxies want to maximize the outcome with respect to their preferences whereas in HD candidates wish to maximize their votes. While vote maximizing seems like a winning strategy in this context, in fact the winning strategy is to restructure the partition of votes. We show this in some section.\nOur initial study considers strategyproofness and manipulability with respect to both followers and proxies positions. Then, we consider sequences where proxies react to other proxies\u2019 actions. Finally, we turn to study strategic behavior in partial information settings.\nOur contribution is as follows:\n\u2013 Followers never have an incentive to misreport their position (or, equivalently, to follow a proxy other than the nearest one).[Section 3] \u2013 Proxy voting with the median voting rule is manipulable with respect to proxy positions, and we provide a complete characterization of manipulable scenarios.[Section 3] \u2013 In sequences of manipulations, the outcome of each step is bounded.[Section 4] \u2013 Under mild restrictions, sequences of manipulations converge to an optimal\nequilibrium.[Section 4]\n\u2013 Manipulations under partial information may converge to a worse equilibrium than without delegation.[Section 5] \u2013 If agents are regret-averse, then manipulations converge to a socially optimal equilibrium even with partial information.[Section 5] A preliminary version of this paper was presented in EUMAS2022 [Bielous and Meir,\n2022]. In this version, we offer two significant additions to our results. First, we generalize our positive results for unrestricted manipulations by providing a bound on the outcome in strategic proxy settings. Second, in this version we show that our results extend beyond complete information settings to partial information scenarios. We show that even with limited information, the proxy voting framework retains its desirable properties. In particular, we examine the implications for regret-averse agents and find that our results hold in these cases as well.\nBy investigating the effects of strategic behavior in proxy voting under different information conditions, our study contributes to a deeper understanding of the dynamics and potential benefits of this voting mechanism."
        },
        {
            "heading": "2 Model and Preliminaries",
            "text": "We define the model of Strategic Proxy Games (SPG) as follows.\nModel. Our basic model follows the one in by Cohensius et al. [2017]. There is a set of proxies (active agents)M = {1, ...,m}, and a set of followersN = {1, ..., n}. We refer to the set of all agents N \u222aM as \u2019voters\u2019. Each voter 1 \u2264 i \u2264 n +m has a position pi \u2208 R along the political spectrum. True positions are p \u2208 R\nm+n, where p|M := (pj)j\u2208M and p|N := (pi)i\u2208N . A state is a vector s \u2208 R\nm, such that sj is the position Proxy j declares. We denote by ( s\u2212j , s \u2032 j )\nthe state that is equal to s except for the strategy of Proxy j, that is s\u2032j .\nDelegation. We assume that each follower delegates their vote to the nearest proxy (this is known as the Tullock delegation model [Tullock, 1967]). Formally, given a vector of positions p and a state s, each Follower i \u2208 N delegates their vote to Proxy j \u2208 M , where\n\u03d5i (s) := argminj\u2208M |sj \u2212 pi|\nWe assume the existence of a deterministic tie-breaking scheme that only depends on the state of voters. All proxies delegate their vote to themselves.\nPreferences Voters are assumed to have single-peaked preferences with peak at pi. That is, for every x, y \u2208 R, if x < y \u2264 pi, then Voter i prefers y to x, and if pi \u2264 x < y, then Voter i prefers x to y. For followers we further assume preferences are symmetric, that is, for every x, y \u2208 R, if |x\u2212 pi| < |y \u2212 pi|, then Follower i prefers x to y. Thus, preferences of voters are consistent with the delegation model.\nExample 1. Consider the SPG appearing in Figure 1. There are two proxies {1, 2} with positions p1 = \u22121 and p2 = 1.5. There is a single follower {3} with position p3 = 0. In the truthful state s = p|M = (\u22121, 1.5), the follower delegates their vote to \u03d53 (s) = 1. Thus, there are two votes to \u22121 and a single vote to 1.5.\nWeighted median. Given a finite vector ~s \u2208 Rm such that each si \u2208 ~s has weight wsi \u2208 R +, let W = \u2211 si\u2208~s wsi . The weighted median of ~s, denoted med(~s;w), is si \u2208 ~s such that\n\u2211\n{sj\u2208~s\\{si}:sj\u2264si}\nwsj \u2264 W\n2 and\n\u2211\n{sj\u2208~s\\{si}:sj\u2265si}\nwsj \u2264 W\n2 .\nThat is, the sum of weights of elements that are smaller than si is at most half the total sum of weights, and the same holds for the sum of weights of elements that are larger than si.\nWeighted median voting rule. Next, we define the Weighted Median voting rule. The weight of each proxy is defined as the number of delegations to them. Then, the weighted median voting rule (WM) selects the position that is the weighted median of proxy positions. Formally:\nmed(s, p|N) := med((s, p|N ); 1)\nis the unweighted median of all voters (proxies and followers) at state s, and the weighted median is\nwm(s, p|N ) := med(s;w) where wj := |{i \u2208 N : \u03d5i(s) = j}|+ 1,\nand we often omit p|N when clear from context. Ties break lexicographically. At state s, the WM voting rule selects wm(s, p|N) \u2208 R as the winner. Note that wm(s) = sj for some j \u2208 M , and we denote this selected proxy by j\u2217(s, p|N ) \u2208 M . We denote the median and weighted median in the true state p by med := med(p) and wm := wm(p), respectively.\nThe WM winner in Example 1 is the position \u22121. This is because the proxy at \u22121 receives a total of 2 votes from the single follower who delegates to them, whereas the proxy at 1.5 receives 1 vote.\nStrategyproofness and Manipulations. We say that a voter is truthful if they declare their true position pi. Voters may lie about their positions, and we assume that voters are rational, that is, they lie only if by lying the outcome changes in their favor.\nWe say that p\u2032i 6= pi is a manipulation for voter i \u2208 N \u222aM if voter i strictly prefers wm(p\u2032) to wm(p), where p\u2032 = (p\u2212i, p \u2032 i).\nA voting rule is strategyproof if for every vector of true positions p, no voter has a manipulation; otherwise, it is manipulable. The Median voting rule, i.e. the voting rule that selects the unweighted median is known to be (group) strategyproof for single-peaked preferences [Black, 1948; Moulin, 1980], and thus in particular to voters who try to minimize their distance as in our model."
        },
        {
            "heading": "3 Strategyproofness of Weighted Median",
            "text": ""
        },
        {
            "heading": "3.1 Manipulation by Followers",
            "text": "We begin our analysis by showing that strategyproofness extends to Weighted Median with respect to followers\u2019 positions. In their work, Cohensius et al. [2017] demonstrate that for any distribution of followers and proxies, the WM winner is the proxy who is closest to the true median. That is, the proxy j\u2217 selected by the weighted median rule is the one closest to the (unweighted) median of the entire population. Equivalently, it is the proxy selected by the median voter in the population. Formally, let i\u2217 be the median voter in profile (s, p|N ). Then:\nLemma 1 (Cohensius et al. [2017]).\nj\u2217(s) = \u03d5i\u2217(s) = argminj\u2208M |sj \u2212med(s, p|N ) |.\nNext, we prove that for WM, followers do not have manipulations. Note that for followers, manipulations are in effect delegation to another proxy.\nTheorem 1. WM is strategyproof w.r.t followers\u2019 positions.\nProof. Assume towards contradiction that for some p, there exists a follower i \u2208 N who has a manipulation p\u2032i, and denote p \u2032 = (p\u2212i, p \u2032 i). W.l.o.g, assume pi \u2265 med(p). By Lemma 1 the weighted median rule returns the proxy j \u2208 M closest to med(p) before the manipulation, and j\u2032 (who is closest to med(p\u2032)) after the manipulation.\nAccordingly, the winning positions before and after are pj = wm(p|M , p|N ) and pj\u2032 = wm(p|M , p\n\u2032|N ). As p\u2032i is a manipulation, we have that pj\u2032 is strictly closer to pi than pj , and in particular j 6= j\u2032. This must mean that med(p\u2032) 6= med(p), and by strategyproofness of the unweighted median, med(p\u2032) < med(p) < pi.\nBy monotonicity of the unweighted median this means p\u2032i < pi, and thus pj\u2032 < pj . One of the following must hold:\n\u2013 pi \u2264 pj\u2032 < pj : Since med(p) \u2264 pi, it follows that j is closer to med(p) than j\u2032, in contradiction to the definition of j. \u2013 pj\u2032 < pj \u2264 pi: This is not a manipulation for i, as the outcome gets farther away.\n\u2013 pj\u2032 < pi < pj : Since pi \u2265 med(p), and since |med(p)\u2212 pj | \u2264 |med(p) \u2212 pj\u2032 |, we get |pi \u2212 pj | < |pi \u2212 pj\u2032 |. Thus, by symmetric single-peakedness Follower i prefers pj to pj\u2032 , in contradiction to p \u2032 i being a manipulation. \u2293\u2294\nRemark 1. Another interpretation of Theorem 1 is that under the weighted median voting rule, it is a dominant strategy for a follower to support her nearest proxy. In other words, the theorem justifies the Tullock delegation model.\nAs Theorem 1 shows that WM is strategyproof with respect to the positions of followers, we can henceforth consider them as non-strategic agents. In what follows, followers are considered to always be truthful. In particular, the position vector p|N is fixed."
        },
        {
            "heading": "3.2 Manipulation by Proxies",
            "text": "We continue to analyze the strategic behavior of proxies. While we obtain a positive result of strategyproofness when only followers are strategic, the same does not hold for proxies, as demonstrated by the following example.\nExample 2. Recall the SPG appearing in Example 1. The truthful WM winner is wm(s) = \u22121, and the winning proxy is 1. Consider the state s = (p1, 1\u2212 \u03b5) for some 0 < \u03b5 < 2.\nThe single follower delegates their vote to Proxy 2. There are two votes to s2 = 1 \u2212 \u03b5 and only one vote to s1 = \u22121, thus, wm(s) = 1 \u2212 \u03b5. As preferences are single-peaked and Proxy 2\u2019s peak is at p2 = 1.5, we get that Proxy 2 strictly prefers 1\u2212 \u03b5 to \u22121. Hence, 1\u2212 \u03b5 is a manipulation for Proxy 2.\nThe counter-example presented in Example 2 can be easily expanded to any number of followers and proxies. However, rather than formally constructing such example, The following theorem provides a complete characterization of manipulable scenarios. As a consequence, it shows that manipulations exist under very simple and reasonable conditions.\nTheorem 2. There is a proxy that has a manipulation in the truthful state p|M iff it holds that pj 6= med for all 1 \u2264 j \u2264 m, and there are proxies j, j\n\u2032 \u2208 M such that pj < med < pj\u2032 .\nProof. \u201c\u21d0\u201d Suppose pj < med < pj\u2032 , and w.l.o.g. let j be the closest proxy to the median, so j\u2217(p) = j, and wm = pj . As preferences are single-peaked, Proxy j\u2032 prefers med to wm(p). We proceed by showing that moving to p\u2032j\u2032 = med is a manipulation for Proxy j\u2032, as in Fig. 3.\nIndeed, denote p\u2032 = (p\u2212j , p \u2032 j\u2032). Since pj , p \u2032 j\u2032 are on the same side of med, we have that the position of the median does not change, i.e., med(p\u2032) = med. By Lemma 1 we get that wm(p\u2032) is the proxy closest to med(p\u2032), whose position is p\u2032j\u2032 = med. Since wm(p \u2032) = p\u2032j\u2032 is strictly between pj\u2032 and wm, this is a manipulation for j\u2032. \u201c\u21d2\u201d. If there is some proxy k such that pk = med, then by Lemma 1, med is the WM winner. Therefore, every proxy with position at med have their peak outcome, so there is no more preferred outcome for them. Consequently they do not have a manipulation. Further, no position is closer to med, thus no other proxy can change the outcome by reporting a position that is closer to the median. Therefore, they can only manipulate by reporting a position that changes the position of the median.\nAssume towards contradiction that there is such a proxy k with a manipulation p\u2032k, and let p \u2032 = (p\u2212k, p \u2032 k). W.l.o.g assume that pk > med. Then, the position of the median would only change in p\u2032 if Proxy k reports a position on the other side of med, i.e. p\u2032k < med. We get that med(p\n\u2032) < med. Since p\u2032k is a manipulation, the outcome of p\u2032 holds\nwm(p\u2032) \u2264 med(p\u2032) < med = wm < pk.\nThe first inequality is since med(p\u2032) is the maximal position p\u2032i < med for any i \u2208 M \u222a N . By single-peakedness k prefers med to wm(p\u2032), in contradiction to p\u2032k being a manipulation.\nFinally, assume that for all proxies pk \u2264 wm < med. Clearly the proxy j who is closest to med have no manipulation since their position pj wins. Also note that in any manipulation p\u2032k we have med(p\n\u2032) \u2265 med. The only way for k to change the outcome is by becoming the winner themselves, i.e. reporting a position closer to med(p\u2032) than pj . However since pj < med \u2264 med(p\n\u2032), we have pk < wm = pj < wm(p \u2032) and thus Proxy k strictly loses from such a move. \u2293\u2294"
        },
        {
            "heading": "4 Manipulations for Better Outcomes",
            "text": "Consider the manipulation described in the proof of Theorem 2. The outcome of the manipulated state is the true median, which is the outcome of the median\nvoting rule with complete participation. That is, in this case the manipulation has a positive effect on the accuracy of the outcome!\nManipulations are often beneficial. The example above may seem counter-intuitive, but it is in fact common that strategic behavior improves the outcome, even when applied repeatedly by all voters. This is true especially in simple voting rules like Plurality, as manipulations play a form of compromise that lets voters avoid socially-inferior outcomes. This was shown both in theoretical analysis Grandi et al. [2013] and in simulations Meir et al. [2014]; Grandi et al. [2013].\nEvaluation. This brings about the natural question does strategic voting of proxies always improve the outcome? We note that in general, questions about \u2018good outcomes\u2019 in voting are tricky, since there are numerous ways to evaluate the outcome of a voting rule, e.g. if we define the optimum to be the outcome of the used rule itself on the truthful votes (as in Bra\u0302nzei et al. [2013]), then strategic behavior is bad by definition.\nHowever, in the context of delegation on the real line, a natural evaluation metric is the distance to the \u2018ideal point\u2019 that would be selected if everyone had voted, i.e. to med(p). This is exactly the approach followed by [Cohensius et al., 2017], when showing (non-strategic) delegation improves the outcome.\nAnother natural measure is the social cost, i.e. the sum of distances of all voters from the selected position. When using the median voting rule without delegation, the two goals coincide, as the median is known to minimize the social cost. However a good approximation of the true median may have poor social cost, and vice versa. 3\nFollowing Cohensius et al. [2017], we adopt the distance to the true median as our goal, but also discuss the implications on social cost where relevant.\nConvergence. When discussing strategic behavior, an even more fundamental question than welfare is stability. A hierarchy for notions of stability in iterative voting is explained in Meir [2018]. For example, under Plurality with a mild assumption on voters\u2019 behavior it is known that iterative voting always converges to a pure Nash equilibrium Meir [2017]. In candidacy games, which are equivalent to our setting with weightless proxies, it was shown that a pure Nash equilibrium\n3 Suppose there are k followers and 1 proxy j on 0, k+2 followers on 1, and a second proxy j\u2032 on 2 \u2212 \u03b5. Then j\u2032 is the closest proxy to med = 1 (and thus selected by WM), but has social cost of 3k +\u0398(1), whereas j has social cost of k +\u0398(1).\nConversely, if j\u2032 is on 1+2/k, then j still minimizes the social cost, but its distance from med is \u0398(k) larger than that of j\u2032.\nexists Sabato et al. [2017], but there are no results regarding convergence, or regarding the more general model where proxies have weights.\nIn this section and the next one, we therefore study both the conditions under which iterative voting by strategic proxies is guaranteed to converge, and bounds on the distance of the final outcome from the true median of the population."
        },
        {
            "heading": "4.1 Dynamics and Convergence",
            "text": "Policies. A policy for proxy j \u2208 M is a function that maps a state to a strategy. Formally, let S = Rm be the set of all possible states for the proxies, then, a policy for j is a function \u03c0j : S \u2192 R.\nBetter-responses. For every j \u2208 M and every state s, we say that the position s\u2032j is a better-response to s if j strictly prefers the outcome of ( s\u2212j, s \u2032 j ) to the outcome of s. We denote the set of better-responses of j to s by Bjs. We say that a policy is a better-response policy for j if for every s, the strategy selected by the policy is a better response to s, that is \u03c0j (s) \u2208 B j s. A better-response policy is said to be best-response policy, if the outcome of the selected strategy is most preferred by the proxy within their better-response set. Note that a best-response policy may not exist.\nTruth-oriented. A proxy j is truth-oriented if their policy selects their true position whenever it is in their better-response set, and is weakly better than any other strategy. Formally, for every s, if pj \u2208 B j s and j prefers wm(s\u2212j , pj) to wm (\ns\u2212j , s \u2032 j\n)\nfor every s\u2032j \u2208 B j s, then \u03c0j (s) = pj . Truth-orientation is closely\nrelated to truth-bias proposed by Meir et al. [2010]. Truth-biased agents would resort to truth if it is weakly better than any other strategy, in particular when the better-response set is empty. Truth-orientation is a weaker requirement, as truth is only compared to better-responses.\nDynamics. A dynamics s\u0303 = (st) \u221e t=0 is a (possibly infinite) series of states, where st is the state after step t. We assume that the initial state is truthful, i.e., s0 = p|M .\nThen, for every t > 0 there is a single proxy j = jt \u2208 M changing position from st\u22121j to s t j according to their policy \u03c0j . Thus\nst = ( st\u22121\u2212j , s t j ) = ( st\u22121\u2212j , \u03c0j ( st\u22121 )) .\nWe do not assume any particular order over proxies\u2019 turns, except that there is no starvation. That is, every proxy eventually gets to play again, an infinite number of times.\nRecall that the winner in state s is denoted by j\u2217(s). We denote by j\u2217(t) and wmt the winner at time t and their position, respectively. Thus, j\u2217(t) = j\u2217(st) and wmt = stj\u2217(t) = wm(s\nt). We further denote by medt := med(st) the median at step t.\nWe further denote by by j\u2217 := j\u2217(s0) the winner of the initial state, thus pj\u2217 = wm(p) = wm.\nAt a given state s, we denote by \u2206(s) := |med(s) \u2212 wm(s) | the distance between the unweighted median and the weighted median (the winner). We also denote \u2206t := \u2206(st) and \u2206 := \u2206(s0).\nThe standard setting for the study of on-going dynamics in voting is Iterative Voting [Meir, 2017]. However, since our model involves an infinite action set, the terminology and results cannot be applied in a straightforward way. We address it when relevant. Instead, we say that a dynamics s\u0303 converges if it has a limit.\nA state s is a pure Nash equilibrium (PNE) if for every j \u2208 M it holds that Bjs = \u2205, that is, no proxy has a better-response to s.\nWe start our analysis with bounding the distance from the true median that the outcome can converge to. For the rest of this section, we show that for every step in a better-response dynamics from truth, the current median and outcome are bounded in a neighborhood of med with radius \u2206.\nTheorem 3. Assume all proxies are truth-oriented. For every step t \u2265 0 in a better-response dynamics s\u0303 by proxy j, if j\u2019s peak is left of med then stj \u2264 med +\u2206; and if their peak is right of med, then med\u2212\u2206 \u2264 stj.\nRemark 2. We point out that if proxies are weightless, as in the model by Sabato et al. [2017], then the theorem trivially holds. This is since med(s) = med(p) at every state, and thus \u2206t can only become smaller at every step, as the current proxy moves closer to med(p) to become the new winner.\nConsider a truthful state where the peak of the initial winner pj\u2217 is left of the median. For a better-response dynamics from this truthful state, we prove the following lemma:\nLemma 2. Assume all proxies are truth-oriented. If for every 0 \u2264 t\u2032 \u2264 t, and for all j \u2208 M s.t. pj \u2265 med(p) it holds that s t\u2032\nj \u2265 med \u2212\u2206 = pj\u2217 , then for the truthful winner j\u2217 it holds that pj\u2217 \u2264 s t j\u2217\nProof. Assume false, and let 0 < t0 \u2264 t be the first step that the truthful winner j\u2217 moves to the left of their peak, that is, st0j\u2217 < pj\u2217 \u2264 s t0\u22121 j\u2217 . In particular this means that j\u2217 is the moving proxy at t0 \u2212 1. Since no proxy with peak right of med reported a position left of med \u2212 \u2206 prior to t, it follows that the median at every step prior to t is right of med\u2212\u2206. This is in particular true at t0 \u2264 t, that is, med\u2212\u2206 \u2264 medt0 . It follows that st0j\u2217 < pj\u2217 = med\u2212\u2206 \u2264 med\nt0 . We argue that this contradicts the assumption that proxies are truth-oriented. One of the following must hold. Either st0j\u2217 is the winning position at t0, in which case pj\u2217 is closer to the current median and can therefore win. Since the peak is the optimal outcome for j\u2217, it is in their better-response set, the outcome is weakly better than the outcome of every other strategy in Bj \u2217\nst0 . Otherwise, since\nst0j\u2217 is a better-response to s t0\u22121, it must be that by reporting st0j\u2217 the position of the median changed, such that j\u2217(t0) 6= j \u2217 is closer to medt0 than medt0\u22121. Again since t0, t0 \u2212 1 \u2264 t we get that pj\u2217 \u2264 med t0 ,medt0\u22121. Thus, reporting\npj\u2217 would have the same effect on the position of the median as s t0 j\u2217 . Therefore, pj\u2217 is weakly better than any other better-response. Figure 5 demonstrates the possible scenarios. \u2293\u2294\nNote that by symmetry the same hold for the case where the truthful winner\u2019s peak is right of the median. We turn to prove Theorem 3.\nProof. Assume that there was no violation up to step t \u2265 0. In particular, this imply that med\u2212\u2206 \u2264 medt \u2264 med +\u2206.\nConsider a proxy j, and let s\u2032j be a possible strategy for j such that s\u2032j /\u2208 [med\u2212\u2206,med +\u2206]. If s \u2032 j is on the same side of the median as pj , then this is not a violation. Otherwise, s\u2032j is a better-response iff it is between pj and wm(s t), the winning position at t. This is because otherwise, s\u2032j would either have no effect on the outcome, or the outcome would be further than wm(st) to their peak. Note that this also implies that wm(st) /\u2208 [med\u2212\u2206,med +\u2206]. By lemma 2, we have that stj\u2217 \u2208 [med\u2212\u2206,med +\u2206]. Thus, wm(s\nt) /\u2208 [med\u2212\u2206,med +\u2206] only if wm(st) and stj\u2217 are not on the same side of the median. Moreover, it must be that medt is between med and the position of the current winner wm(st). However, if medt 6= med, then there is a proxy with a reported position in st that is between medt and wm(st) such that their peak is on the other side of med than medt. This contradicts Lemma 1, thus, all violations are not in the better-response set of the proxies, and there is no violation at step t. \u2293\u2294\nCorollary 1. For every state st in a better-response dynamics s\u0303 with truthoriented proxies, both the median and the outcome of st are in the interval [med\u2212\u2206,med +\u2206].\nThe bound on the outcome shows that strategic behavior in proxy voting can reduce the distance between the outcome and the true median. However, it does not convergence to a stable state (equilibrium), or even a reduced social cost. In what follows, we discuss conditions for both."
        },
        {
            "heading": "4.2 Monotone Policies",
            "text": "Monotonicity justification Consider the better-response set of some proxy j with peak pj < med(s) at state s. While it is possible that sj is on the same side of med(s) and there are better responses on both sides, the following must hold:\n\u2013 There is at least one better response s\u2032j \u2264 med(s); \u2013 j weakly prefers any better-response s\u2032j \u2264 med(s) to any s \u2032\u2032 j > med(s), due\nto single-peakedness.\nTherefore, it is reasonable to assume that proxies restrict their policies so as to select a position that is on the same side of the median as their true position.4 In the following discussion, we restrict policies to ones that preserves the integrity of proxies positions with respect to the median.\nMonotonicity Formally, we say that a better-response dynamics s\u0303 is monotone if for every j \u2208 M , we have for any j \u2208 M s.t. pj \u2264 med, and any step t, that \u03c0j (s t) \u2264 med (and likewise for pj \u2265 med. Note that for every state s t of a monotone better-response s\u0303, the median of st is med.\nObservation 1 Under monotone dynamics, medt = med for all t.\nThis is since the same set of voters (followers and proxies) remain on each side of the med."
        },
        {
            "heading": "4.3 Narrowing in on the Median",
            "text": "Our goal in this section is to prove that that any monotone better-response dynamics converges to the true median. The problem is that this may not hold at every step, which requires some extra work.\nThe following Lemma shows that any better-response in a monotone betterresponse dynamics where the winning proxy is not the moving proxy strictly decreases the distance to the median.\nLemma 3. Let s\u0303 be a monotone better-response dynamics. Then, for every t \u2265 0 if jt+1 6= j\u2217(t), then \u2206t+1 < \u2206t.\n4 This assumption is somewhat similar to a \u2018no overbidding\u2019 assumption in auctions.\nProof. By Lemma 1, for every k \u2208 M it holds that\n|wm ( st+1 ) \u2212med| \u2264 |st+1k \u2212med|.\nIn particular, this holds for j\u2217(t) \u2208 M . We get:\n|wm ( st+1 ) \u2212med| \u2264 |st+1 j\u2217(t) \u2212med|\nSince jt+1 6= j\u2217(t), it holds that s\u2032(t+ 1) is a better-response for st, so |st+1\nj\u2217(t+1) \u2212med| 6= |s t+1 j\u2217(t) \u2212med|. Hence:\n\u2206t+1 = |wm ( st+1 ) \u2212med| < |wm ( st ) \u2212med| = \u2206t. \u2293\u2294\nWhile Lemma 3 shows that moves made by proxies with reported position not at the current outcome must reduce the distance to the true median, it is possible for winning proxies to move in a way that increase the distance to the median. Figure 7 describe a proxy that makes 2 consecutive steps. The first makes them the winning proxy, the next is a better-response. As they remain the winning proxy, the outcome after the second step is further from the median.\nMeta-moves. We call sequences of consecutive better-responses by the same winning proxy meta-move. Formally, a meta-move of length \u2113 from st is a subsequence of steps in a better-response dynamics s\u0303 such that:\n\u2013 jt+1 6= j\u2217(t) and j\u2217(t+ 1) = jt+1. That is, in state st, the proxy jt moves in a way that makes them the winner. \u2013 Let \u2113 > 0 such that for every 1 \u2264 i \u2264 \u2113 it holds that jt+i = jt+1 = j\u2217(t+ 1). In other words, after jt+1 becomes the winning proxy at step t + 1, they continue to make consecutive better-responses for \u2113 steps.\nThe following shows that while local manipulations within a meta-move can increase the current distance to the true median (as Figure 7 demonstrates), meta-moves globally decrease the distance to the true median.\nLemma 4. For every meta-move of length \u2113 from st of a monotone betterresponse dynamics s\u0303, it holds that \u2206t+\u2113 < \u2206t.\nProof. By Lemma 1, monotonicity and since for every 1 \u2264 i \u2264 \u2113 it holds that jt+i = j\u2217(t+ 1) 6= j\u2217(t), we get that \u2206t+i \u2264 \u2206t. Furthermore, since s\u2032(t+ 1) is a better-response for jt+1, it must be that the outcome of st+1 is not equal to the outcome of st. We get that for every i, s\u2032(t+ i) is a better-response and therefore s\u2032(t+ i) 6= s\u2032(t+ 1). Thus \u2206t+i 6= \u2206t. In particular, this holds for i = \u2113. \u2293\u2294\nLemma 3 and Lemma 4 together provide a complete analysis of the betterresponse sets for proxies, and show that the better-response set strictly decreases after each (meta) move. However, this alone is not sufficient for convergence.\nExample 3. Recall the setting appearing in Example 1. Define \u03b11 = 1 4 , and for every t \u2208 N, define \u03b1t+1 = 1 2\u03b1t. We define the following policy for j \u2208 M :\n\u03c0j ( st ) = med\u2212 sign (med\u2212 pj) ( \u2206t \u2212 \u03b1t )\nFor every t \u2208 N we get that\n\u2206t+1 = |wm ( st+1 ) \u2212med|\n= |med\u2212 sign ( med\u2212 pj\u2217(t+1) ) ( \u2206t \u2212 \u03b1t ) \u2212med| = |\u2212sign ( med\u2212 pj\u2217(t+1) ) ( \u2206t \u2212 \u03b1t ) | = \u2206t \u2212 \u03b1t\nAs \u03b1t = 1 2\u03b1t\u22121, we get\u2206 t+1 = \u22061\u2212 \u2211t\u22122 i=0 1 2i\u03b11 = \u2206 1\u2212\u03b11 \u2211t\u22122 i=0 1 2i . As t \u2192 \u221e, we get that the distance to the median converges to \u22061\u22122\u03b11 = \u2206 1\u22122 14\u2206 1 = 12\u2206 1, and the outcome oscillates between \u2212 12 and 1 2 . Thus the best-response dynamics diverges. Figure 8 shows a schematic of this dynamic.\nIterative Voting comparison. Note that Example 3 not only shows that monotone better-response dynamics need not converge, it also shows a key difference between our setting and Iterative Voting. We say that a dynamic is acyclic if there are no recurring states. For finite action sets, i.e., when the space of available better-responses for each agent is finite, acyclicity implies convergence. Example 3 demonstrates that for infinite action spaces this may not hold.\nInterpretation of alpha. In effect, \u03b1t is the amount by which the outcome gets closer to the true median between steps. As \u2206t decreases, so does the leeway that proxies have to improve the outcome for themselves. While it is reasonable that \u03b1t decreases as \u2206\nt decreases, Example 3 captures the behavior in which \u03b1t decreases at a higher rate than \u2206t.\nBy restricting policies such that \u03b1t and \u2206 t decrease at the same rate, we can obtain convergence. Moreover, this guarantees that \u2206t itself converges to 0, meaning that the outcome converges to the true median.\nWhile the example above shows that even monotone policies may diverge, this relies one the gaps between \u2206t becoming smaller and smaller. Fix some constant \u03b1 < 1. We say that a meta step is big if \u2206t+\u2113 < \u03b1\u2206t, and otherwise it is small.\nCorollary 2. Consider a monotone better-response dynamics, and suppose there is only a finite number of small steps between any two big steps. Then the dynamics converges, and the limit PNE is the true median.\nProof. After T big meta steps, we have that |med\u2212 wm(s) | < \u03b1T\u2206 \u2192 0. \u2293\u2294\nMoreover, the corollary still holds if \u03b1 is not a constant but increases towards 1 over time, as long as this does not occur too fast.5\nWhy are there big steps? We argue that it is not reasonable that proxies will insist on small steps forever as in Example 3.\nTo see why, note that while smaller steps are preferable to the moving proxy, this benefit get smaller and smaller. On the other hand, the fraction of small meta-steps from all better-responses becomes smaller over time, so almost every better-response is big.\nWhy this result is good. The true median is the outcome of the median voting rule. It is both Condorcet consistent and the minimal sum of distances from voters\u2019 true preferences. Thus, the median of all voters reflects the social optimum. As such, Corollary 2 implies that the strategic behavior of proxies (with the above restrictions) can in fact produce a socially optimal and stable outcome."
        },
        {
            "heading": "4.4 Discretization",
            "text": "Justify discretization In many real-world applications, the assumption that voters can express any position on the political spectrum R is unreasonable. Voters are unlikely to distinguish between positions that are too similar, and this is the case both for selecting their truthful position, and distinguishing between different proxy positions for delegation. In computerized settings, there is some limited resolution to the expression of preferences (e.g. a temperature or a monetary amount). As it turns out, any such limit eliminates the possibility of oscillation we encountered in the previous section.\nIn this section, we assume w.l.o.g that the political spectrum is restricted to the set of all integers Z.\n5 For example, we can allow \u03b1k = max(\u03b1, 1\u2212 1 k ), at the k\u2019th big meta step.\nConvergence for discrete spaces. For discrete spaces, every monotone policy meets the conditions of Corollary 2. This is due to the fact that every betterresponse made by a proxy with position that is not the current weighted median must decrease the distance to the true median by at least 1 (as the minimal distance between every distinct possible positions). Thus, the conditions are met for \u03b1 = 1 \u2212 1\n\u22061 . Therefore, for discrete spaces, every monotone better-response\ndynamics converges, and the outcome is the true median, which is the socially optimal outcome.\nBest response. Furthermore, for discrete spaces (in contrast to continuous) there is a well-defined best-response, that is to reposition at a distance that is one step closer to the true median than the current winner on their opposite side of the median. In particular, the best-response is monotone.\nConnection to Iterative Voting. Following the terminology of [Meir, 2017], a game has the Finite Best Response Property (FBRP) from truth if from any truthful state, when restricted to best-responses, the dynamics converges. Thus, SPGs with WM are FBRP from truth.\nHowever, for non-monotone policies convergence to a socially worse outcome is possible. We show tis in Appendix A.\nOur conjecture is that convergence holds for the non-discrete case as well, and that ultimately proxies would have an incentive to deviate back to their original side of the median. Yet, this is a matter of future research."
        },
        {
            "heading": "5 Partial Information",
            "text": "In previous sections we assumed that the proxies have complete information about the positions of proxies and followers alike. This assumption is common when analyzing adversarial behavior. However, is it reasonable in a proxy voting setting?\nRecall that one of the applications of proxy voting is to mitigate the adverse effects of partial participation, where voters want to avoid explicitly reporting their positions. Moreover, followers may not even know their exact position; instead, they only know how to rank proxies based on proximity. Thus, followers can still delegate their vote without the additional cognitive strain of determining their exact position.\nIn this section we relax the assumption of complete information. First, it is worth noting that when proxies have no information about the positions of followers, proxy voting becomes strategyproof. To see this, consider the states appearing in Figure 9\nIn the bottom state, the proxy at \u221220 can manipulate the outcome by deviating to \u22125. However, in the top state, the proxy has no manipulation. When proxies have no information except proxies positions, the proxies cannot distinguish between the two states. Thus, proxies do not even know if they have a valid manipulation, let alone find one.\nHowever assuming no information at all sounds too restrictive, and we would like to consider intermediate cases that are more reasonable.\nOutline summary for section. For the rest of this section, we first describe formally a less restrictive setting for the study of partial information. Then, we show that when only partial information is made available to voters, the strategic behavior of proxies may converge to a worse social outcome than the truthful state."
        },
        {
            "heading": "5.1 Model",
            "text": "Information sets. We employ the framework described in [Reijngoud and Endriss, 2012]. In this setting, a poll information function (PIF) \u03c3 maps each state s to an information set \u03c3 (s). For example, in a Plurality voting scenario, we can think of a PIF that returns the score of each candidate, or just the candidate ranking, or even just the name of the winning candidate. The set \u03c3 (s) is then communicated to all voters.\nIntuitively, we can think of the PIF as the results of a poll that is broadcast publicly after all private information is collected.\nPoll information with delegation. What information is likely to become public in our setting? Clearly the proxies\u2019 positions, as otherwise followers will not be able to delegate. Other than that, we only assume that the identity (and position) of the winner is announced.\nIn this section only we use p instead of p|N for the followers\u2019 positions, to simplify notation. To avoid confusion, we use s0 rather than p|M for proxies\u2019 true positions.\nWe thus denote by \u03c3winner the PIF that takes as input the state s (proxies\u2019 current positions) and followers\u2019 true positions p and returns (s,wm(s, p)). That is, reveals the proxies\u2019 positions and the winner. Since this is the only PIF we use in this work, we just write \u03c3.\nIn this setting, proxies are unable to distinguish between states that yield the same information by \u03c3. Recall the two states from Figure 9. When only proxy positions are communicated by \u03c3, the states are indistinguishable by the proxies. However, proxies can deduce an equivalent set of states that are consistent with\nthe information available to them. In particular, both states in Figure 9 would be in the same set.\nFormally, at any state s, the proxies know only the identity of the winner j\u2217, and their positions. We define the set of possible profiles as\nP \u03c3(s, j\u2217) := {p \u2208 Rn : \u03c3(s, p) = (s, j\u2217)}.\nThese are all possible positions of followers that are compatible with the revealed information.\nWhile in the previous sections j\u2217 = j\u2217(s) could be implicitly inferred from proxies\u2019 positions s (since p was known), in this section the state is defined as (s, j\u2217), i.e. it explicitly contains all known information.\nDominating manipulations. Following the terminology of [Conitzer et al., 2011], we define a dominating manipulation for Proxy j as a position s\u2032j that satisfy the following conditions. First, by reporting s\u2032j , there exists a profile p\n\u2032 \u2208 P \u03c3(s, j\u2217) that when combined with s\u2032j , results in a more preferable outcome. Second, for all other profiles in P \u03c3(s, j\u2217), it is the case that j weakly prefers them over the current outcome.\nMore formally, let \u227bj be a full order over all possible outcomes that define j\u2019s true preferences. Then, s\u2032j dominates sj in state (s, j \u2217) if for any profile p \u2208 P \u03c3(s, j\u2217) it holds that wm (\ns\u2212j, s \u2032 j , p\n)\n<j wm(s, p) = sj\u2217 , and the preference is strict for at least some p\u2032 \u2208 P \u03c3(s, j\u2217).\nIn the special case where \u03c3 returns the true followers\u2019 positions (no uncertainty), dominating manipulations are just better-responses."
        },
        {
            "heading": "5.2 Convergence under Partial Information",
            "text": "In appendix B, we show that dominating-manipulations dynamics may converge to a worse social outcome than the truthful state. However, while this is possible for general policies, it is not the case for policies that can guarantee monotonicity. In this section, we find a sufficient condition for convergence to the true median for the partial information setting.\nWe say that a policy for Proxy j \u2208 M is strong-monotone if for every state (s, j\u2217) and every profile p \u2208 P \u03c3(s, j\u2217), it holds that sj and \u03c0j(s) are on the same side of med(s, p). Note that for complete information, strong-monotone policies are reduced to monotone policies.\nThe median interval. For a dynamics s\u0303, let str, s t \u2113 be the positions of the closest proxies to the winner from right and left respectively at t. Let It := {med(st, p) : p \u2208 P \u03c3(st, j\u2217(st))} be the interval of possible positions for the median in st, and denote \u2113t, rt the lower and upper bounds of It, respectively.\nWe define an interval It recursively as follows. For t = 0, set I0 = ( s0r+s 0 j\u2217 2 , s0\u2113+s 0 j\u2217 2 ) .\nFor every t > 0 define It as follows:\n\u2013 If j\u2217 6= jt\u22121 then It = It\u22121 \u2229\n(\nstr+s t j\u2217(0) 2 , st\u2113+s t j\u2217(0) 2\n)\n.\n\u2013 Otherwise, if st\u22121 j\u2217(t) < s t j\u2217(t) set I\nt = It\u22121 \u2229 [\nst j\u2217(t),\u221e\n)\n, else if st\u22121 j\u2217(t) > s t j\u2217(t)\nset It = It\u22121 \u2229 (\n\u2212\u221e, st j\u2217(t)\n]\nRemark 3. Note that the position wm(st) is known to proxies even though the profile p is unknown, since wm(st) = stj\u2217 and both of s\nt and j\u2217 = j\u2217(st) are known. Hence the proxies can indeed infer It from the information they know.\nStrong-monotone dominating manipulations for non-winning proxies. Then, the set of dominating manipulations at state (st, j\u2217) that are also strong-monotone for Proxy j with pj \u2264 wm(s t) is the open interval:\n( min{st\u2113,wm ( st ) \u2212 2|wm ( st ) \u2212 \u2113t|},wm ( st )) ,\nif \u2113t < wm(st), and empty otherwise. The set for proxies on the other side of the median is similar with respect to rt.\nStrong-monotone dominating manipulations for winning proxies. For winning proxies, they have a dominating manipulation only if their current position is between their peak and It, and the closest proxy on the other side of It is farther than their position. That is, w.l.o.g assume that pj\u2217(t) < wm(s\nt) < \u2113t, and |rt \u2212 str| > |r\nt \u2212 wm(st)|. In this case, their set is (rt \u2212 |rt \u2212 wm(st)|,wm(st)). This is the equivalent of a meta-move in this setting. Their set is empty in any other case since either any beneficial deviation may cross the median, or a deviating may have a negative outcome.\nWe get that a policy is strong monotone if it holds that if the position of a proxy is left (right) of \u2113t (rt), then their resulting strategy would have the same orientation with respect to It. Furthermore, as It decreases with every step of a moving proxy, and that in turn decreases the set of strong-monotone dominating manipulations for each proxy, these sets are monotonically decreasing. If we impose a similar restriction as in the proof of Corollary 2, we get convergence with the true median as an outcome with a similar argument."
        },
        {
            "heading": "5.3 Rationalizing Monotonicity",
            "text": "In decision theory, the concept of regret is often used to model types of agents. Given a strategic decision made under uncertainty, the regret is the difference in utilities between the outcome, and the optimal strategy that the agent could use ex-post. A regret-averse or risk-neutral agent would select the strategy that minimizes the maximal regret.\nIn what follows, we show that the minimax-regret policy guarantees monotonicity, and therefore if all proxies are regret-averse then even with partial information convergence to the true median is guaranteed.\nThe following theorem shows that the minimax-regret strategy is strongmonotone.\nTheorem 4. If the policy of every proxy is strong-monotone in a dynamics up to step t \u2265 0, then the minimax-regret strategy of every proxy is strong-monotone.\nProof. First, consider a proxy j with peak pj left of the current winner. For a possible strategy s\u2032j , we calculate the maximal regret by distinguishing between the possible values of s\u2032j :\n\u2013 s\u2032j \u2264 \u2113 t \u2212 |\u2113t \u2212 wm(st)|\u2013 if the median is right of the current winner, then\nex-post there is nothing Proxy j can do to change the outcome in their favor, thus the regret is 0. Otherwise, the optimal position for them is the position symmetric to the current winner with respect to the median, whereas by reporting s\u2032j the outcome does not change. Thus, the difference in utility is the distance between the current winner and the optimal position. The maximal regret is reached when the median is at \u2113t (up \u03b5 > 0) and is equal to 2 \u00b7 |\u2113t \u2212 wm(st)|. \u2013 s\u2032j \u2265 wm(s t)\u2013 It is still possible that the median is (weakly) left of the current\nwinner. By reporting a position that is right of the current winner the median would be bounded by the current winner and therefore the outcome will not change. Thus, the maximal regret is at least 2 \u00b7 |\u2113t \u2212 wm(st)|. \u2013 \u2113t\u2212|\u2113t\u2212wm(st)| < s\u2032j < wm(s t)\u2013 as in the first case, if the median is right of\nthe current winner then the regret is 0. Otherwise, for every possible position of medt, the optimal strategy for j ex-post is optt = medt\u2212|medt\u2212wm(st)|. Therefore, if optt < s\u2032j then the regret is s \u2032 j \u2212 opt\nt. Otherwise, s\u2032j is further than the current winner from the current median and thus the outcome will not change. Hence, the regret is wm(st) \u2212 optt. We get that the maximal regret is maxmedt{wm(s t)\u2212 optt, ( s\u2032j \u2212 opt t ) \u00b7 1optt<s\u2032 j }.\nIf |\u2113t \u2212 wm(st)| = 0, then the regret for the first case is 0, for the second it is positive and there are no strategies that fit the last case. Thus, the minimaxregret strategy in this case is the set (\u2212\u221e, \u2113t), and every position in this set is strong-monotone.\nOtherwise, for the last case, 2\u00b7|\u2113t\u2212wm(st)| bounds the regret from above and for the other cases it bounds the regret from below, therefore the minimax regret must be attained for \u2113t\u2212|\u2113t\u2212wm(st)| < s\u2032j < wm(s\nt). We argue that the minimax regret is attained at \u2113t. First, for s\u2032j = \u2113\nt, the maximal regret is |\u2113t\u2212wm(st)|. To see this, if optt > \u2113\nt then the regret is given by wm(st) \u2212 optt \u2264 |\u2113t \u2212 wm(st)|. Otherwise, the regret is given by\n\u2113t \u2212 optt \u2264 \u2113t \u2212 ( \u2113t \u2212 |\u2113t \u2212 wm ( st ) | ) = |\u2113t \u2212 wm ( st ) |.\nNext, for \u2113t < s\u2032j < wm(s t), if medt = \u2113t + \u03b5 for \u03b5 > 0 then\noptt = \u2113t \u2212 |\u2113t \u2212 wm ( st ) |+ 2\u03b5\nthus the regret is s\u2032j \u2212 opt t > |\u2113t \u2212 wm(st)|. Finally, for s\u2032j < \u2113 t then if medt = wm(st)+s\u2032j\n2 + \u03b5 then the regret is wm(s t)\u2212 optt > |\u2113t \u2212 wm(st)|.\nWe get that the minimax-regret strategy for Proxy j is \u2113t \u2264 medt. Thus, it is strong-monotone.\nFor proxies with positions right of the current winner, the analysis is symmetric for rt.\nFor the winning proxy, if their reported position is at their peak, then it is the optimal position for them regardless of the underlying state. Thus, it is also their minimax-regret strategy (the maximal regret of their peak is 0).\nOtherwise, w.l.o.g assume that the winning proxy\u2019s truthful position (peak) is left of their current position. By definition of It and since all steps until t are strong-monotone, it follows that \u2113t \u2265 wm(st).\nConsider the current position of the winning proxy. Their maximal regret is attained for the case that the median is at their current position, in this case their optimal position is at distance min{|str \u2212 wm(s t)|, |st\u2113 \u2212 wm(s t)|} left of their position (up to \u03b5). Thus, their maximal regret at this position is bounded from below by min{|str \u2212 wm(s t)|, |st\u2113 \u2212 wm(s t)|}. For every position right of their current position, for the same case the regret would be at least min{|str \u2212 wm(st)|, |st\u2113 \u2212 wm(s\nt)|}, so it bounds the maximal regret from below. Finally, for every position left of their current position, if the median is at rt \u2212 \u03b5 then the winning position would be str, so the regret is bounded from below by |s t r \u2212 wm(st)| \u2265 min{|str\u2212wm(s t)|, |st\u2113\u2212wm(s\nt)|}. Thus, their minimax-regret strategy is their current position, which is strong-monotone. \u2293\u2294\nRemark 4. Note that the minimax-regret policy is also in the set of dominating manipulations.\nConsequently, it follows that if the policy of all proxies is minimax-regret, then the resulting dynamics is strong-monotone and therefore converges to the true median."
        },
        {
            "heading": "6 Conclusions and Future Work",
            "text": "We introduced Strategic Proxy Games, a framework to study strategic behavior of proxies in voting mechanisms.\nFirst, we demonstrated that in this model, the extension of the median voting rule to the weighted median voting rule via proxy voting maintains strategyproofness with respect to followers\u2019 positions. In particular, this suggests that with respect to follower positions, the delegation scheme is optimal for followers preferences. Our study uses the Tullock delegation scheme, however, other delegation models have been studied in the literature. In the one-step delegation domain, Green-Armytage [2015] consider delegation that accounts for small errors in assessment of positions, and Alon et al. [2015] consider social connections that influence the weight of proxies. Exploring the impact of different delegation models on the outcome of proxy voting and the strategic behavior of followers and proxies would be an interesting direction for future research. We point out that many of our results depend on the fact that the proxy who attracts the median voter wins. Our conjecture is that for delegation models that correlate well with distance the same property hold, and would yield similar results. In this research we focused on the median voting rule. We plan to study the implication of strategic proxy behavior in higher dimensions, as well as with other voting rules.\nWe continued to study the strategic behavior of proxies, and showed that while strategyproofness does not extend to proxy voting, the distance of the outcome in a setting of repeated manipulations is bounded by the distance of the truthful outcome. Thus, in terms of distance, manipulations can only have a positive impact on the outcome. Moreover, when proxies maintain the integrity of their positions with respect to the median, the outcome converges to the social optimum. We further show that for discrete spaces, non-monotonicity can result in a worse social outcome. The combination of the above results show that in the context of proxy voting, both complete truthfulness and unbounded manipulation are sub-optimal. The assumption of monotonicity is a compromise between these extremities. In future work, we plan to further study non-monotone settings. In particular, we showed that truth-orientation bounds the distance of the outcome for the social optimum. We conjecture that under the stronger assumption of truth-bias, proxies would have an incentive to revert to a monotone state.\nFinally, we study the implications of partial information to the strategic behavior of proxies. While our results show that the outcome may increase the social cost, we also show that for policies that guarantee to be monotone, in particular minimax-regret, would converge to the social optimum. While the public information for voters that we consider is very minimal, i.e. it only includes the winning position and the positions of proxies, it may be possible to achieve the same positive results with even less information available. A particular case of interest is when the winning position is not made public, rather an estimate of it. This case may be more realistic for several reasons. First, if voters positions are estimated, then the outcome can be an estimate as well. This may be appropriate\nfor settings where followers, for reason of e.g. cognitive strain or privacy, wish to communicate an interval of approved positions that expresses an estimate of their peak. This setting is somewhat related to that of Green-Armytage [2015] mentioned above, and the setting proposed by Feldman et al. [2016], where candidates admit attraction intervals, and voters may select any candidate that attracts them. Moreover, approximate positions of voters are more realistic in the context of polls. Another possibility is to allow for more strategic depth for proxies, where they communicate an approximate positions in an effort to maximize support.\nAcknowledgements. This research was supported by the Israel Science Foundation (ISF; Grant No. 2539/20)."
        },
        {
            "heading": "A Convergence to sub-optimal outcome for discrete spaces",
            "text": "Consider the following SPG. The set of proxies is M = {1, 2, 3, 4, 5} with positions p4 = p3 = p2 = \u221213, p1 = \u221211 and p5 = 12. In addition, there are four followers N = {6, 7, 8, 9} such that p6 = p7 = 5, p8 = 1 and p9 = 0 is the true median. For the truthful state the winner is Proxy 1 and the outcome is \u221211. The social cost is\nSC = 3 \u00b7 |\u221213\u2212 (\u221211)|+ |0\u2212 (\u221211)|+ |1\u2212 (\u221211)|+ 2 \u00b7 |5\u2212 (\u221211)|+ |12\u2212 (\u221211)|\n= 3 \u00b7 2 + 11 + 12 + 2 \u00b7 16 + 23 = 84\nNext, Proxy 5 is the only proxy that has a better-response, and they report the position s\u2032(0) = 10 and wins. At the next steps, Proxies 2, 3 and 4 are the moving one-by-one, reporting the positions 9, 8 and 7 respectively. At each step the moving proxy also wins, and it can be easily verifies that these positions are better responses. Then, Proxy 1 reports s\u2032(5) = 4, and wins. Consider the state (\ns5\u22125, 6 )\n. Recall that we assume the existence of a deterministic tie-breaking scheme. We distinguish between the following:\n\u2013 Proxy 1 wins at position 4. In this case, Proxy 5 reports the position 5, that is s6 = (\ns5\u22125, 6 )\n. We argue that this a PNE. For Proxy 5, since the distance of Proxy 1 from the current median 5 in s6 is 1, and 1 would win the tiebreak if Proxy 5 reports 6, then their better-response set is empty. For the other proxies, since Proxy 5\u2019s reported position is at the current median, they cannot get closer to the median. Moreover, no single proxy can change the position of the current median. Therefore, they do not have a better response.\n\u2013 Proxy 5 wins at position 6. In this case 5 reports the position 6, that is, s6 = (\ns5\u22125, 6 ) . Then Proxy 1 reports 5, i.e. s7 = ( s6\u22121, 5 )\n. We argue that this is a PNE, with a similar argument.\nFigure 11 demonstrates the dynamics for the first case.\nIn either case we get a PNE where the outcome is 5. The social cost is\nSC\u2032 = 3 \u00b7 |\u221213\u2212 5|+ |\u221211\u2212 5|+ |0\u2212 5|+ |1\u2212 5|+ |12\u2212 5|\n= 3 \u00b7 18 + 16 + 5 + 4 + 7 = 86\nThat is strictly greater than the social cost of the truthful outcome. Note that for the unrestricted (non-discrete) setting, this is not a PNE since the winner in either case has a better-response, for example by reporting a position that is at a distance of 0.5 from the median in the direction of their peak."
        },
        {
            "heading": "B Convergence to sub-optimal outcome for incomplete information",
            "text": "Consider the SPG appearing in Figure 12.\nThe true positions are p = (\u221230, 90,\u221250, 0, 10). There are two proxies M = {1, 2} with positions p1 = \u221230 and p2 = 90, and 3 followers. Note that proxies and followers are unaware to the positions of other followers. The median is 0, and the weighted median is \u221230. The social cost is:\nSC = |\u221250\u2212 (\u221230)|+ |\u221230\u2212 (\u221230)|\n+ |\u221230\u2212 0|+ |\u221230\u2212 10|+ |\u221230\u2212 90|\n= 20 + 0 + 30 + 40 + 120 = 210\nThe proxies can deduce from their available information that the true median is in the interval (\u2212\u221e, 30).\nNext, for Proxy 2, consider the position s12 \u2032 = 29. Note that it is a dominating\nmanipulation. The outcome of s2 = ( s1\u22122, s 1 2 \u2032 ) is s12 \u2032 = 29. It follows that the true median is in the interval (\u22120.5, 30). In particular, note that the new information that the proxies get has no effect on the right bound of the interval.\nNext, for Proxy 1 in s2, the only information that Proxy 1 has is that their position is \u221230, and that the position of Proxy 2 in s2 is 29, and it is the outcome of s2. Consider the position s21 \u2032 = 25. Again, this is a dominating manipulation for Proxy 1. The outcome of s3 = ( s2\u22121, s 2 1 \u2032 ) is s21 \u2032 = 25. Therefore, the true median is in the interval (\u22120.5, 27).\nConsider s3. For Proxy 1, since the true median can be at 27\u2212\u03b5 for every \u03b5 > 0, every position left of their current position may prove to be further than Proxy 2\u2019s position in s3, resulting in a worse outcome. Thus, their set of dominating manipulations is empty. The set of dominating manipulations for Proxy 2 is (25, 29). For every position s32 \u2032 \u2208 (25, 29), the outcome of ( s3\u22122, s 3 2 \u2032 ) is s32 = 25. The true median is in the interval ( \u22120.5, 25+s32 \u2032\n2\n)\nand the set of dominating\nmanipulations for Proxy 2 is ( 25, s32 \u2032 ) . Note that this holds for every t \u2265 3 s.t. for every 3 \u2264 t\u2032 \u2264 t the position of Proxy 1 in st \u2032 is 25. That is, the outcome is 25, the true median is in the interval ( 25, 25+st2 \u2032\n2\n)\n, the set of dominating\nmanipulations for Proxy 1 is empty, and the set of dominating manipulations for Proxy 2 is ( 25, st2 \u2032 ) . Thus, Proxy 1\u2019s position does not change, and the sequence of positions of Proxy 2 is monotonically decreasing and bounded, therefore it has a limit. We get that the dynamics converges, and the outcome of the limit state is 25. Figure 13 demonstrates the dynamics.\nThe social cost of the outcome is\nSC\u2032 = |\u221250\u2212 25|+ |\u221230\u2212 25|\n+ |0\u2212 25|+ |10\u2212 25|+ |90\u2212 25|\n= 75 + 55 + 25 + 15 + 65 = 235\nNote that complete information prevents the convergence demonstrated by this counter-example. With complete information, the true median is public information. Proxy 1 can exploit this to strategically report a symmetric position on the opposite side of their peak. Thus, their better-response set is not empty."
        }
    ],
    "title": "Strategic Proxy Voting on the Line",
    "year": 2023
}