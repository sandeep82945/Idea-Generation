"While future work should automatically perform the animation creation process from video data, the manual animation creation step in this study allows us to validate the Sim2Real portion given human-level feature extraction, enabling us to identify specific underlying social signals for each emotion (7 for each emotion), which are now available for use in our 3D models."

"However, more research is needed to investigate these hypotheses."

"This could mean that the next step for more inclusive and accurate facial expression recognition systems could incorporate audiovisual data processing."

"More advanced applications can be used for this task to generate more realistic synthetic datasets, and to explore other variations including age, non-binary gender, or conditions impacting facial development."