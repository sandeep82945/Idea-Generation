{
    "abstractText": "In recent years, with the popularity of artificial intelligence (AI) applications, financial market forecasting based on deep learning models has gotten more attention in academia and industry. According to statistics, a long short-term memory network (LSTM) is the first choice for deep learning to deal with the financial time series predicting problems due to its internal memory that can process incoming input with the previous state. However, most of the research used the raw financial time series data composed of opening, closing, highest, lowest price, and transactional time as learning features to feed into models. This study proposed a novel approach focusing on appropriate structures that can organize the price activities as a bell shape curve and identify the greed and fear in the market with deep convolutional neural networks. In addition, this study also considered the influence of time causality on patterns. It is difficult to accurately catch the rapid changes in the market, especially the causal link between various patterns and trend reversal behavior while using only static features extracted by AI models. We designed disparate methods while generating images that could keep the time-variant features on structures and be extracted by convolutional neural networks. Each image was labeled as the upward trend to downward trend, downward trend to upward trend, and trend did not change according to reversals of overall price direction. Finally, to evaluate the availability of the trained model, two-stage experiments were carried out. The first stage of the experiment mainly evaluated the accuracy and profitability of trades following the models, and the second stage considered practical trading rules such as the stop-loss mechanism. The results of the first and second stages showed the proposed models had better profitability and extremely well-matched classification capabilities when compared with the state-of-the-art deep learning models. INDEX TERMS Algorithmic trading, convolutional neural network, deep learning, financial time series forecasting, market profile, price structure, time causality, trend reversals.",
    "authors": [
        {
            "affiliations": [],
            "name": "CHERN-BIN JU"
        },
        {
            "affiliations": [],
            "name": "AN-PIN CHEN"
        }
    ],
    "id": "SP:6f93c86b1aac97f7859719e48b7eb2139b5d70bd",
    "references": [
        {
            "authors": [
                "O.B. Sezer",
                "M.U. Gudelek",
                "A.M. Ozbayoglu"
            ],
            "title": "Financial time series forecasting with deep learning : A systematic literature review: 2005\u20132019",
            "venue": "Appl. Soft Comput., vol. 90, May 2020, Art. no. 106181, doi: 10.1016/j.asoc.2020.106181.",
            "year": 2020
        },
        {
            "authors": [
                "O.B. Sezer",
                "A.M. Ozbayoglu"
            ],
            "title": "Financial trading model with stock bar chart image time series with deep convolutional neural networks",
            "venue": "Intelligent Automation and Soft Computing, vol. 26, no. 2, pp. 323\u2013334, 2020, doi: 10.31209/2018.100000065.",
            "year": 2020
        },
        {
            "authors": [
                "P. J"
            ],
            "title": "Steidlmayer,Markets andMarket Logic",
            "venue": "Chicago, IL, USA: Porcupine Press,",
            "year": 1984
        },
        {
            "authors": [
                "J.F. Dalton",
                "E.T. Jones",
                "R.B. Dalton"
            ],
            "title": "Mind Over Markets: Power Trading withMarket Generated Information, 2nd ed",
            "year": 1999
        },
        {
            "authors": [
                "R.L. Galvez",
                "A.A. Bandala",
                "E.P. Dadios",
                "R.R.P. Vicerra",
                "J.M.Z. Maningo"
            ],
            "title": "Object detection using convolutional neural networks",
            "venue": "Proc. TENCON IEEE Region Conf., Oct. 2018, pp. 2023\u20132027.",
            "year": 2018
        },
        {
            "authors": [
                "E. Hoseinzade",
                "S. Haratizadeh"
            ],
            "title": "CNNpred: CNN-based stock market prediction using a diverse set of variables",
            "venue": "Expert Syst. Appl., vol. 129, pp. 273\u2013285, Sep. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "Y. LeCun",
                "L. Bottou",
                "Y. Bengio",
                "P. Haffner"
            ],
            "title": "Gradient-based learning applied to document recognition",
            "venue": "Proc. IEEE, vol. 86, no. 11, pp. 2278\u20132324, Nov. 1998, doi: 10.1109/5.726791.",
            "year": 1998
        },
        {
            "authors": [
                "B. Hu",
                "Z. Lu",
                "H. Li",
                "Q. Chen"
            ],
            "title": "Financial trading model with stock bar chart image time series with deep convolutional neural networks",
            "venue": "Intell. Automat. Soft Comput., vol. 26, no. 2, pp. 323\u2013334, 2020, doi: 10.31209/2018.100000065.",
            "year": 2020
        },
        {
            "authors": [
                "S. Hochreiter",
                "J. Schmidhuber"
            ],
            "title": "Long short-term memory",
            "venue": "Neural Comput., vol. 9, no. 8, pp. 1735\u20131780, 1997. 12864 VOLUME 10, 2022 C.-B. Ju, A.-P. Chen: Identifying Financial Market Trend Reversal Behavior With Structures of Price Activities",
            "year": 1997
        },
        {
            "authors": [
                "H. Maqsood",
                "I. Mehmood",
                "M. Maqsood",
                "M. Yasir",
                "S. Afzal",
                "F. Aadil",
                "M.M. Selim",
                "K. Muhammad"
            ],
            "title": "A local and global event sentiment based efficient stock exchange forecasting using deep learning",
            "venue": "Int. J. Inf. Manage., vol. 50, pp. 432\u2013451, Feb. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A. Krizhevsky",
                "I. Sutskever",
                "G.E. Hinton"
            ],
            "title": "ImageNet classification with deep convolutional neural networks",
            "venue": "Proc. Adv. Neural Inf. Process. Syst. (NIPS), vol. 25. Stateline, NV, USA, Dec. 2012, pp. 1097\u20131105.",
            "year": 2012
        },
        {
            "authors": [
                "A. Karpathy",
                "G. Toderici",
                "S. Shetty",
                "T. Leung",
                "R. Sukthankar",
                "L. Fei-Fei"
            ],
            "title": "Large-scale video classification with convolutional neural networks",
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2014, pp. 1725\u20131732.",
            "year": 2014
        },
        {
            "authors": [
                "O.B. Sezer",
                "A.M. Ozbayoglu"
            ],
            "title": "Algorithmic financial trading with deep convolutional neural networks: Time series to image conversion approach",
            "venue": "Appl. Soft Comput., vol. 70, pp. 525\u2013538, Sep. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "C.-C. Lin",
                "C.-S. Chen",
                "A.-P. Chen"
            ],
            "title": "Using intelligent computing and data stream mining for behavioral finance associated with market profile and financial physics,\u2019\u2019Appl",
            "venue": "Soft Comput.,",
            "year": 2018
        },
        {
            "authors": [
                "C.-C. Chen",
                "Y.-C. Kuo",
                "C.-H. Huang",
                "A.-P. Chen"
            ],
            "title": "Applying market profile theory to forecast Taiwan index futures market",
            "venue": "Expert Syst. Appl., vol. 41, no. 10, pp. 4617\u20134624, Aug. 2014.",
            "year": 2014
        },
        {
            "authors": [
                "D. Li",
                "D. Yu"
            ],
            "title": "Deep learning: Methods and applications",
            "venue": "Found. Trends Signal Process., vol. 7, nos. 3\u20134, pp. 197\u2013387, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "Y. LeCun",
                "Y. Bengio",
                "G. Hinton"
            ],
            "title": "Deep learning",
            "venue": "Nature, vol. 521, pp. 436\u2013444, Feb. 2015.",
            "year": 2015
        },
        {
            "authors": [
                "J.L. Elman"
            ],
            "title": "Finding structure in time",
            "venue": "Cognit. Sci., vol. 14, no. 2, pp. 179\u2013211, Mar. 1990.",
            "year": 1990
        },
        {
            "authors": [
                "M.I. Jordan"
            ],
            "title": "Serial order: A parallel distributed processing approach",
            "venue": "Advances in Psychology, vol. 121. 1997, pp. 471\u2013495, doi: 10.1016/S0166-4115(97)80111-2.",
            "year": 1997
        },
        {
            "authors": [
                "M. Sundermeyer",
                "R. Schl\u00fcter",
                "H. Ney"
            ],
            "title": "LSTM neural networks for language modeling",
            "venue": "Proc. Interspeech, Sep. 2012, pp. 1\u20134.",
            "year": 2012
        },
        {
            "authors": [
                "K. Chen",
                "Y. Zhou",
                "F. Dai"
            ],
            "title": "A LSTM-based method for stock returns prediction: A case study of China stock market",
            "venue": "Proc. IEEE Int. Conf. Big Data (Big Data), Oct. 2015, pp. 2823\u20132824.",
            "year": 2015
        },
        {
            "authors": [
                "M. Hiransha",
                "E.A. Gopalakrishnan",
                "V.K. Menon"
            ],
            "title": "NSE stock market prediction using deep-learning models",
            "venue": "Proc. Comput. Sci., vol. 132, pp. 1351\u20131362, Jan. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "K. Khare",
                "O. Darekar",
                "P. Gupta",
                "V.Z. Attar"
            ],
            "title": "Short term stock price prediction using deep learning",
            "venue": "Proc. 2nd IEEE Int. Conf. Recent Trends Electron., Inf. Commun. Technol. (RTEICT), May 2017, pp. 482\u2013486.",
            "year": 2017
        },
        {
            "authors": [
                "X. Zhang",
                "Y. Tan"
            ],
            "title": "Deep stock ranker: A LSTM neural network model for stock selection",
            "venue": "Proc. Int. Conf. Data Mining Big Data. Cham, Switzerland: Springer, 2018, pp. 614\u2013623.",
            "year": 2018
        },
        {
            "authors": [
                "S. Selvin",
                "R. Vinayakumar",
                "E.A. Gopalakrishnan",
                "V.K. Menon",
                "K.P. Soman"
            ],
            "title": "Stock price prediction using LSTM, RNN and CNN-sliding window model",
            "venue": "Proc. Int. Conf. Adv. Comput., Commun. Informat. (ICACCI), Sep. 2017, pp. 1643\u20131647.",
            "year": 2017
        },
        {
            "authors": [
                "I.E. Livieris",
                "E. Pintelas",
                "P. Pintelas"
            ],
            "title": "A CNN-LSTM model for gold price time-series forecasting",
            "venue": "Neural Comput. Appl., vol. 32, no. 23, pp. 17351\u201317360, 2020, doi: 10.1007/s00521-020-04867-x.",
            "year": 2020
        },
        {
            "authors": [
                "M. Kearns"
            ],
            "title": "A bound on the error of cross validation using the 43 approximation and estimation rates, with consequences for the training-test split",
            "venue": "Proc. Adv. Neural Inf. Process. Syst., 1996, pp. 183\u2013189.",
            "year": 1996
        },
        {
            "authors": [
                "A.-P. Chen",
                "Y.-C. Hsu"
            ],
            "title": "Dynamic physical behavior analysis for financial trading decision support [application notes",
            "venue": "IEEE Comput. Intell. Mag., vol. 5, no. 4, pp. 19\u201323, Nov. 2010.",
            "year": 2010
        },
        {
            "authors": [
                "J. Dhaene andM.J. Goovaerts"
            ],
            "title": "Dependency of risks and stop-loss order",
            "venue": "ASTIN Bull., vol. 26, no. 2, pp. 201\u2013212, Nov. 1996.",
            "year": 1996
        }
    ],
    "sections": [
        {
            "text": "INDEX TERMS Algorithmic trading, convolutional neural network, deep learning, financial time series forecasting, market profile, price structure, time causality, trend reversals.\nI. INTRODUCTION Financial time series forecasting is undoubtedly one of the top topics that researchers in academia and industry have desired to solve for a long time. During the past decade, many studies tried to apply machine learning methods to discover the behavior of the financial market. Recently, the emergence of deep learning models has improved research results that significantly outperform previous models.\nDeep learning is one of the popular research fields in artificial intelligence (AI), and it has been popularly applied\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Chien-Ming Chen .\nto many applications in our life. For instance, recurrent neural networks (RNN) and long short-term memory (LSTM) networks are used for speech recognition because they can consider not only current input but previous states at the same time. This feature makes them perform well for sequence and time series data. According to statistics [1], LSTM networks are the first choice to deal with the financial market forecasting problems by learning the raw time series data composed of opening, closing, the highest, and lowest price during a time as features. However, there are many different participants with diverse timeframes in the market, such as longterm investors, short-term traders, day traders, and scalpers. The market is influenced by their wide variety of timeframes\nVOLUME 10, 2022 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 12853\nand motivations such as speculating, hedging trading, and arbitrage, resulting in lots of noise in market price. These excessive noises may be too sensitive to learn the correct features to discover the trend behavior from the raw time series data. To cite an instance, raising up the price can be caused by a new buying business, or it may be carried out by an old buying business such as short-covering order.\nAnother common deep learning method is convolutional neural networks (CNN). It is widely used in computer vision because of its powerful ability to extract important features from images. With the powerful image classification ability of CNN, Sezer and Ozbayoglu [2] proposed CNN-BI using a 2-D CNN directly input closing price chart images without introducing any other time series data. This is the first attempt in the literature to adopt CNN to train a trading model. However, the financial market is a dynamic environment, and it is affected by not only a snapshot of patterns also its development characteristic with time. For example, a downward trend auction occurred last week, but a responsive buying just showed up three days ago. It would be classified the whole activities into a downward trend and omit the responsive buying, but it should start to reverse to an upward trend in the near time. Therefore, exploring the influence of time causality on features has become a very important topic.\nA novel approach for analyzing the behavior of dynamic financial markets was proposed in this paper, which focused on appropriate structures of price activities that can identify the trend reversals with deep CNNs. In addition, this study also considered the time-variant extracted features. A series of extracted patterns with different occurred time could imply the behavior of financial market trend reversal. Equation (1) illustrated the idea of our perspective: yt is the trend reversal result predicted by the models, and it is the function of extracted patterns and occurred time t. If the observed time period is from t to t-n and there are m extracted patterns, the (1) can be expressed as the interaction of a series of patterns that occurred at time ti during the observed period from t to t-n.\nyt = f (patterns, t) = f ({ pattern0, pattern1 . . . , patternm } , {t, . . . t \u2212 n} ) = f ({ patternt0, pattern t\u22121 0 , \u00b7 \u00b7 \u00b7 pattern t\u2212n m }) (1)\nFig. 1 demonstrated the process of the proposed approach. First, to generate the images be able to utilize the power of the deep CNN, we adopted market profile theory [3], [4] to convert financial time series data into proper structures represented with text market profiles. In order to come up with a representation containing the characters of the time, we used different linear interpolation to convert the Time Price Opportunities (TPO) in profiles into greyscale values so that the generated images can maintain the time-variant features in structures. Next, images were grouped with the sliding window method and labeled with \u2018\u2018downward trend to upward trend,\u2019\u2019 \u2018\u2018upward trend to downward trend,\u2019\u2019 and \u2018\u2018trend did not change\u2019\u2019 based on the current trend in the\ngrouped image and whether the trend will reverse. Finally, training the model with CNNs and its predicted results were evaluated using out-of-sample data.\nThe experimental results showed that the proposed method significantly outperformed the model trained by state-of-theart benchmark models with raw financial time series data in terms of profitability after two stages of different trading mechanism analyses. Furthermore, the two models have extremely well-matched classification capabilities for identifying the trend reversal behavior. Therefore, the proposed approach is an exemplary method and could effectively discover the reversal behavior in the financial market, providing investors a reference for better rewards.\nThe contributions of this study are briefly summarized as follows. (I) Constructing a deep CNN model to forecast the trend reversals of the financial market by converting appropriate structures of price activities from market profile theory as learning features. (II) In order to emphasize the influence of time causality on patterns, disparate methods were designed to convert structure shapes to images with different grayscale values so that the time-variant features could be extracted from structures instead of obtaining static features by CNNs. (III) This was probably the first attempt using market profile theory with deep learning methods in financial market behavior forecasting to the best of our knowledge. (IV) To evaluate the better-converted structure style, two types of formats to compare performance were arranged. (V) An available model for identifying the reversals based on overall price direction was proposed.\nII. RELATED TECHNIQUES AND WORKS A. MACHINE LEARNING AND DEEP LEARNING AI has recently become one of the most important research and application topics. Machine learning is a branch of AI. It is an intelligent way to learn from data, trainmodels that can make decisions automatically or as a decision support system for humans. Nowadays, machine learning has been widely used in many fields, such as image recognition, video analysis, object detection, financial time series prediction, weather forecasting, marketing, and medical image research [5], [6]. Moreover, the emergence of deep learning has led to another research with results that significantly outperform\n12854 VOLUME 10, 2022\nprevious models. The CNN is a type of deep learning network widely used in our lives, especially in the computer vision field, because of its powerful recognition ability. The simple architecture of the CNNs is LeNet, proposed by Yann [7] for digit recognition. Beyond image classification and recognition problems, CNN can also help us with financial time series prediction.\nCNN consists of convolutional layers, pooling layers, and multiple fully-connected layers neural networks with many weights and biases that need to be trained with data. Unlike a traditional neural network, CNN shares the weights among neurons to reduce the number of parameters and avoid falling into an overfitting problem [8].\nThe convolution process convolves the original image with a specific filter which randomly generates several patterns. Its role is to obtain the boundary between some features and objects in the picture so that the input picture can be judged according to these extracted characters in the future. The pooling process is not only to reduce the number of features and parameters but also to reduce the computational complexity. A common pooling method is max pooling, as it picks the maximum value in the matrix. It retains all important feature information and improves the efficiency of the CNN. The fully-connected layers connect the features after the previously mentioned processes and the classifying labels. The whole process of CNN is illustrated in Fig. 2.\nIn literature, CNN is not preferred for time series data analytics. According to statistics, LSTM networks are the first choice to deal with the forecasting problems with OCHL datasets due to their memory cell connection [9], [10]. However, this study transformed financial time series data into market structure shapes with price activities and market profile theory. Through the different transforming processes, thousands of images were generated, and they could be regarded as feature graphs that were 2-D vectors full of the trend reversal characteristics at a specific time. Therefore, the financial time series forecasting problem is implicitly converted into an image classification problem. CNN had the potential to extract the characteristics from the structure shape images.\nKrizhevsky et al. [11] proposed AlexNet, a trained CNN model, achieved a top-5 error rate of 15.3% that successfully classified 1.2 million images into 1000 different classes in the ImageNet datasets. The accuracy is beyond the past research results. Karpathy et al. [12] provided an empirical evaluation of CNNs on large-scale video classification.\nThey used one-million YouTube videos belonging to 487 classes. The results showed significant performance improvements compared to the baselines. The results of both [11] and [12] indicate that the CNN is suitable for image recognition and classification.\nSezer et al. [14] proposedCNN-TAusing a 2-DCNNbased on image processing properties. By converting 15 different technical indicators financial time series into 2-D images. They used Dow Jones 30 stock prices and ETFs as data. The results indicated that the built model CNN-TA performed well against the Buy & Hold, SMA, MLP, and even LSTM models. The CNN-TA gained average 6% more than the LSTM model in annualized return. According to the literature, CNN has good image recognition and classification capabilities. CNN-TA is a novel application that uses technical indicators to generate images to predict stock prices. However, the selection of technical indicators is handcrafted, and it is less meaningful to combine the calculated values of technical indicators into a picture. In this study, we directly used the transactional price of the raw data to perform structure shape conversion. In addition, through market profile theory, the transformed structure was meaningful due to the interaction between time and price. The next section will discuss the market profile structure shape.\nB. MARKET PROFILE THEORY Market profile is a text chart proposed by Steidlmayer [3] in 1984 and published on CBOT in 1985. Market profile mainly uses the information generated by the market and presents it in a bell curve. The bell curve concept is derived from the normal distribution in statistics. Steidlmayer believes that most of the trading results after a period of trading time should be concentrated in the center of the transactional price range. The center area is called the value area, composed of 70% trades, and the remaining extreme area is called excess price. The excess price above value area is recognized as too expensive to buy, while the excess price below value area is considered too cheap so that no one is willing to sell. Both up and bottom excess include 15% trades under normal circumstances. Fig. 3 illustrates the appearance of market profile.\nBy keeping tracking the transactional market data comprised of time and price, market profile could reveal the direction of the market trend once the evidence of controlled timeframe is uncovered. The basic building blocks of the market profile are called TPO. Every defined time period is designated by a letter. For example, the first time period is denoted as \u2018\u2018A,\u2019\u2019 and the second is denoted as \u2018\u2018B.\u2019\u2019 The defined time period can be a day of a week, an hour of a day, or any time segment. A market profile usually consists of at least five time periods. If a certain price is traded during a given time period, the corresponding letter is marked next to the price. Fig. 4 shows the complete profile composed of fivetime periods (from A to E). Suppose the current market is dominated by long-term buyers, a higher probability of market prices rising. On the contrary, if the market is dominated\nVOLUME 10, 2022 12855\nby long-term sellers, there is a higher chance of falling, occurring a downward trend in the market. The remaining behavior that market trend is non-trend if it is analyzed that there are no long-term buyers and sellers in the current market, the future price may fluctuate within a narrow price interval.\nSteidlmayer extracts some special patterns from themarket profile to help traders understand which way the market is trying to go. There are three important patterns: (a) Pointer of control, POC (b) Value area, VA (c) Tail. POC indicates the most concentrated price range of transactions after a period of trading time, as illustrated in Fig. 4. The transactional price has been traded among the most time periods, and it means that every participant in the market agrees with the price, so that market price is balanced around the price. VA expands the concept of POC, making the balanced price be a range of price. Just like counting the height of students of the same race on campus, it would show a distribution similar to the normal distribution. The price is accepted by themarket participants should be within a certain range above and below the POC. The market profile uses the concept of one standard deviation in statistics to define the range. It refers to approximately 70 percent of the transaction range near the point of control as VA. Most transactions will be dealt with in the VA if no major political and economic events or news may change the participants\u2019 perception of market value.\nThe third pattern is tail. The emergence of the tail is because short-term traders with greed and fear overreact to some event or news, resulting in an imbalance of supply and demand between short-term buyers and sellers. As the price moves away from the value area, long-term traders such as larger institutions and commercial participants in the marketplace would take advantage of the price. A tail occurs while the long-term participants act quickly, making the price rotate back into VA. In market profile, a tail appears when there are at least two single prints on the bottom of the profile or just the opposite, at the top of the profile, as shown in Fig. 4. Therefore, a tail is considered an important key: buying tails indicate the end of a downward auction, whereas selling tails\nindicate the end of an upward auction. Fig. 5 demonstrates an example of the trend reversal from a downward trend to an upward trend. In addition, a buying tail is also called a support area, and a selling tail is also called a pressure area. Shortterm traders would use support and pressure to trade, for example, buy when the price is close to the support area, and sell when the price is close to the pressure area. The greater the range between pressure and support, the more active market transactions because diverse prices can be traded to meet the needs of market participants.\nThe three patterns mentioned above formmore meaningful structures of price activities than the raw time series data or calculated values of technical indicators. Undoubtedly, more than three patterns in the market profile structure. With the help of the market profile, market participants can understand the financial market trend reversal behavior.\nLin et al. [14] used the market profile theory and neural network to build the model that conducted empirical experiments on intraday trading. They adopted values of POC, VA, price range, and tail as the input and fed into fully connected neural networks for forecasting a short-term market trend.\n12856 VOLUME 10, 2022\nTheir experiments showed that the levels of accuracy and profitability among different short-term trading periods were significantly better than the random trading strategy model. The results confirmed the effectiveness of market profile theory. Chen et al. [15] proposed qualitative and quantitative methods to compute a market profile indicator by implementing the market profile theory on neural network architecture. The experimental results showed the quantitative market profile indicators had better trend-predicting ability in the long-term forecasting period. Moreover, they also suggested that the combination of long-term and short-term changes in the market can enhance forecasting performance and profitability.\nThe literature mentioned above showed that the market profile theory is an effective method to help discover a financial market trend. In this paper, we use the market profile to convert time series data into meaningful structure images. In addition to the POC, VA, Tail, and other patterns proposed by Steidlmayer, the powerful feature extraction capabilities of the CNNs are used to discover various features that can identify the key trend reversal behavior.\nC. RECURRENT NEURAL NETWORK The RNN is another type of deep learning network that has been widely used in nature language processing and speech recognition. Such as language translation application and sequential data processing [16], [17] because of its internal memory that can process incoming input with the previous state. The RNN model architecture is composed of different non-independent hidden layers so that it can take the current and previous input data into account at the same time. Therefore, RNN would perform well when dealing with sequential data. Fig. 6 illustrates the two basic structures of RNN. An Elman network is a three-layer network with an additional cell that connects to a hidden layer. The cell will pass the previous value of the hidden layer. Jordan networks are similar to Elman networks but the additional cell connecting to the output layer. Two structures of networks can maintain a short memory and perform sequence-prediction tasks [18], [19]. Equation (2) and (3) shows the forward pass of the Jordan network illustrated in Fig. 6. a(t): the hidden layer vector; \u03c3a, \u03c3y: activation function; Wi, Wh, Wo: weight matrices to be learned; ba, by: bias vector to be learned; y(t): output vector of the network.\na(t) = \u03c3a ( Wix(t) +Why(t\u22121) + ba ) (2)\ny(t) = \u03c3y ( Woa(t) + by ) (3)\nLSTM are one of the variants of the RNN. LSTM can avoid vanishing gradient problems when the RNN model updates theweights by controllingwhat is added and removed from memory in the hidden layers [20]. This is conducted by using a combination of three gates: (a) a forget gate, (b) an input gate, and (c) an output gate expressed in Fig. 7. Equation (4)-(9) shows the forward pass of the LSTM unit with the three gates. X(t): input data vector; f(t): forget gate\u2019s\nactivation vector; i(t): input gate\u2019s activation vector; o(t): output gate\u2019s activation vector; g(t): new memory be added to memory cell state activation vector; c(t): memory cell sate vector; h(t): output vector of LSTM unit; \u03c3 : sigmoid activation function; W, U: weight matrices to be learned; tanh: hyperbolic tangent activation function; b: bias vector to be learned; \u2217: Hadamard product.\nf (t) = \u03c3 ( x(t)Wf + h(t\u22121)Uf + bf ) (4)\ni(t) = \u03c3 ( x(t)Wi + h(t\u22121)Ui + bi ) (5)\no(t) = \u03c3 ( x(t)Wo + h(t\u22121)Uo + bo ) (6)\ng(t) = tanh ( x(t)Wg + h(t\u22121)Ug + bg ) (7)\nc(t) = f (t) \u2217 C(t\u22121) + g(t) \u2217 i(t) (8) h(t) = o(t) \u2217 c(t) (9)\nIn literature, most deep learning research used LSTM to solve the financial time series forecasting problems with the OCHLV datasets consisting of the opening price, highest price, lowest price, closing price, and trade volume of a specific timeframe. Chen et al. [21] used LSTM to predict China stock return by transforming 30-days transactional data with ten learning features composed by OCHLV of SSE index and stocks into a sequence. The results showed that LSTM is better than the random prediction model. Hiransha et al. [22] compared MLP, LSTM, RNN, and CNN with the stock price. They fed OCHLV, turnover, and number of trades to those models. After trained, the models were used for predicting the stock price of five stocks from NSE and NYSE. They concluded that deep learning models outperform the ARIMA model, the traditional method used for time series forecasting. Khare et al. [23] employed LSTM for intraday price prediction and proved the postulates of Inefficient Market Hypotheses. Zhang and Tan [24] implemented DeepStockRanker, an LSTM-based model for predicting the future return ranking of stocks by employing 11 values of technical indicators. By selecting the highly-ranked stocks predicted by the model, the results showed LSTM model approach significantly outperforms state-of-the-art techniques such as SVR andRBM.Based on a survey of previous works, LSTM is one of the common models used for solving financial time series forecasting problems. In addition, Selvin et al. [25] used RNN, LSTM, and CNN for predicting the price of three stocks of the National\nVOLUME 10, 2022 12857\nStock Exchange of India. Their result showed that CNN gave more accurate results than the other two models. Recently, Livieris et al. [26] proposed a model named CNN-LSTM. They conducted experiments for the accurate prediction of gold price and movement. The result showed CNN-LSTM model was against the LSTM model, too. Therefore, in this paper, the LSTM, CNN, and CNN-LSTM methods would be employed as our control groups models and compared with our proposed method.\nIII. PROPOSED METHOD A. RESEARCH DESIGN For the research model in this paper, a novel model that utilized structures of price activities to discover the trend reversal behavior was proposed. In addition, considering the influence of time causality on features was the key to solving the financial time series forecasting problems. This paper arranged a series of experiments to probe the importance of the structures and time. The first stage of experiments tried to validate the significance of proposed structures. In this stage, a preliminary experiment was conducted to see which way of presenting recording methods was proper for generating structures. There were two experimental groups to evaluate the effectiveness, including the single structure and multiple structures. The single structure organized all price activities in a largemarket profile for analyzing the trend after twenty-five days. By contrast, multiple structures recorded price activities in a structure every five days, so there was a total of five shapes of the structure. After the preliminary experiment, different occurred time was also considered by presenting the time as a feature within a shape or between shapes. Different pixel grayscale values were used to express the time causality when generating the structures\u2019 images. According to the transaction date of OCHL or the sequence number of structures in the images, disparate linear interpolation was performed for calculating the pixel grayscale values ranging from 0 to 255. Fig. 8 and Fig. 9 demonstrated the corresponding grayscale values after calculating based on twenty-fiveday OCHL data in experiments.\nThe experimental groups were designed in accordance with the experiments mentioned above and divided into four groups: Experimental Group A (EGA): twenty-five-day OCHL data was converted into a single shape of the grayscale structure in an image. The sample image of EGA was illustrated\nin Fig. 10 (a), and its grayscale values in the structure varied with the transaction date of OCHL, as demonstrated in Fig. 8. Experimental Group B (EGB): twenty-five-day OCHL data was converted into five shapes of the grayscale structure in an image. Each structure recorded five days of price activities. The sample image of EGB was illustrated in Fig. 10 (b). The grayscale value of these shapes was all black as an experiment regardless of the influence of time causality in the experimental groups, as shown in Fig. 9. Experimental Group C (EGC): twenty-five-day OCHL data was converted into five shapes of the grayscale structure in an image. Each structure recorded five days of price activities. The sample image of EGC was illustrated in Fig. 10 (c), and its grayscale values of shapes varied with the sequence of structures to emphasize the influence of time causality on features between five shapes, as shown in Fig 9. Experimental Group D (EGD): twenty-five-day OCHL data was converted into five shapes of the grayscale structure in an image. Each structure recorded five days of price activities. The sample image of EGDwas shown in Fig. 10 (d). The grayscale values of shapes varied with the transaction date of OCHL within each structure to stress the influence of time causality in every shape, as demonstrated in Fig. 9.\nB. DATA COLLECTION The research goal of this paper was to discover the trend behavior by market structures of price activities. In order to validate the proposed approach, we collected the futures data of the S&P 500 since its huge amount of transaction volume and great facilitation. The data source was the daily transaction data provided by barchart.com. The sample of data was shown in Fig. 11, including the date, the opening price of the day, the highest price of the day, the lowest price of the day, and the closing price of the day. The five fields were called raw data and composed for a candlestick bar which is the least element in financial time series analysis.\nThe experimental period of samples was collected from January 3, 2000, to December 31, 2020. A total of 5291 data\n12858 VOLUME 10, 2022\nwas obtained. The data was divided into training data and testing data to verify the effectiveness of the training network. The experiment used the ideal ratio of 80-20 for split, according to Kearns [27]. The training period was from January 3, 2000, to December 31, 2016. In comparison, the testing period was from the beginning of 2017 to the end transactional day of 2020.\nC. CALCULATE THE STRUCTURES OF PRICE ACTIVITIES In order to generate the structures of price activities, market profile theory was adopted to convert the raw time series data to text profile according to the time, opening, closing, highest and lowest price. Algorithm 1 described the process\nof generating the structure from raw data. In this paper, the time interval was set to one day, and the price interval was set to five points. The basic element in the market profile is called TPO, which is a set of letters fromA to Z. Every alphabet represents a defined time. After inputting our collected S&P daily transactional data, the structure can be generated based on a defined time interval and a price interval.\nAlgorithm 1 GenerateStructureFromRawData() Input Financial time series data (OCHL) OutputTextMarket Profile Structure 1: define timeInterval = 1 day 2: define priceInterval = 5 point 3: while(dataRowCount<numberOfData) do 4: MP = createMPDictionary<price,ListTPO>() 5: TPO =MapDataTimeToTPO(data.Time) 6: for p=data.Highest; p>=data.Lowest; p=p-priceInterval 7: if (!MP.containsKey(p)) 8: MP.addKey(p) 9: if (!MP[p] contains TPO) 10: MP[p].push(TPO) 11: dataRowCount++ 12: return output\nD. LABELING METHOD In the labeling process, each input image is labeled to represent the trend reversal behavior. Let ct be the closing price of a day, and ct\u221210 and ct\u22125 be the closing price ten days and five days ago. To identify the trend reverses from current time t to 5 days later time t+5 for models. Three labels yt are defined in (10). The value of 0 means the trend reverses from an upward trend to a downward trend, and the value of 2 means the trend reverses from a downward trend to an upward trend. The value of 1 means that the trend does not change.\nyt =  0, if ct\u22125 > ct\u221210 and ct > ct\u22125 and ct+5 < ct 2, if ct\u22125 < ct\u221210 and ct < ct\u22125 and ct+5 > ct 1, otherwise\n(10)\nAfter learning the trend reversal behavior, corresponding actions including \u2018Buy action,\u2019 \u2018Sell action,\u2019 and \u2018No action\u2019 are taken by the determination of trend reversal behavior for evaluating the financial performance. A buy action was taken when the trend would transit from downward trend to upward trend. A sell action was taken while the trend would transit from upward trend to downward trend. In the remaining situation, no action is taken since there is no clear evidence to change the trend.\nE. SLIDING WINDOW We adopted a sliding window method while converting futures daily data of S&P 500 to grayscale images of\nVOLUME 10, 2022 12859\nthe structure. Therefore, every twenty-five-day OCHL daily data was included in an image. For example, the input image i contained OCHL data from ti\u221224 to ti, and the next image started from ti\u221223 to ti+1. Fig. 12 illustrated this sliding windows approach.\nF. CNN NETWORKS In the learning phase, each of the experimental groups was conducted by the CNN, which is successfully applied for image classification. The networks structure in this study consisted of eight layers, including input layers, three convolutional layers, two max pooling layers, fully connected layers, and an output layer. The combination of eight layers was similar to the LeNet CNN structures, the successful network in handwritten digits classification. We had tried the deeper networks such as ResNet or DenseNet, but the performance was not as good as shallow networks due to the overfitting problem in the training datasets. It may cause by the number of our input grayscale image data which was converted from the financial time series. Although twenty years of daily transactional data was collected and transformed with the sliding window method, the total amount of input data was roughly 5,300 images. The complete network structures were illustrated in Table 1.\nG. CONTROL GROUPS According to the related works mentioned in Part II, three state-of-the-art benchmark models were employed as the control groups. Control Group A (CGA) used the LSTM networks as the training model; Control Group B (CGB) employed CNN; Control Group C (CGC) applied CNNLSTM networks. In order to compare with the experimental\ngroups, the input data was the financial time series data with the same range as experimental groups. Every record consisted of twenty-five-day transactional data. In addition, according to the recommendation of Chen and Hsu [28], applying the first-order value can increase the learning effect of neural networks. The input data fed into the LSTM and CNN-LSTM networks were processed by first-order differential and transformed the value between 0 and 1. The CNN model was fed with raw time series data as an ablation experiment and compared with the proposed model.\nH. RESEARCH RESTRICTION AND TRADING STRATEGY There were some concerns and restrictions in this study illustrated as follows: First of all, the transaction cost was calculated in this research. The futures contract of ES transaction cost was set to 2 ticks. Secondly, the slippage of every transaction did not consider, and transferring positions to the next delivery contract was also skipped. Besides, the initial capital was set to $11,000 US dollars which was the required initial margin by exchanger CME. Last but not least, to complete the whole transaction based on all model predictions, a margin call occurring when the value of our margin account drops and fails to meet the account\u2019s maintenance margin requirement was not considered.\nIV. RESULTS AND ANALYSIS This study consisted of two stages of experiments, which contained four experimental groups and three control groups. All of them were conducted on S&P 500 mini futures. In the learning phase, twenty-five-day transactional data from the NYSE exchanger was fed into the input layer of each network in every experimental group and control group.\nTo evaluate the proposed methods in this paper, the following evaluation measures were adopted throughout this section: accuracy, precision, total profit, average profit per transaction (APpT), annualized return (AR), and profit to loss ratio (PL). All formulas for measures were illustrated in (11)-(17). The first two measures represent the classifier performance of the proposed model. Accuracy expresses whether the trained classifier distinguishes among the trend reversal classes, \u2018downward trend to upward trend,\u2019 \u2018upward trend to downward trend,\u2019 and \u2018trend not change.\u2019 In addition, precision shows the profitable ability to do buy and sell action after model prediction. The other assessment measures evaluated the financial performance of trained models by implementing a simulation environment to examine the empirical trading results in the financial market based on the model predictions. Algorithm 2 summarized all processes of this study.\nAccuracy\n= Number of Labels clssified Correctly Number of Labels Need to Classify\n(11)\nPrecision\n= Number of Profitable Trade Number of Entering Trade\n(12)\n12860 VOLUME 10, 2022\nTotal Profit (%)\n= Final Value of Capital \u2212 Initial Value of Capital\nInitial Value of Capital \u00d7 100 (13)\nTotal Profit (USD)\n= Final Value of Capital \u2212 Initial Value of Capital\n(14)\nAPpT\n= Total Profit(USD)\nNumber of Entering Trade (15)\nAR\n= ( 1+\nTotal Profit(%) 100\n) 1 number of years\n\u2212 1 (16)\nPL\n= Average Profit of Profitable Trade\nAverage Loss of Loss Trade (17)\nIn the first stage, a preliminary experiment was carried out. The first two experimental groups (EGA, EGB) investigated the effectiveness of two types of generated structures based on market profile theory. All transactional data was merged into a single structure in EGA. In contrast with the merged structure, EGB split data into five structures. The results in Table 2 recommend that separating data into numerous structures be the better formation. As illustrated in Table 2, EGB outperformed EGA, which is considered a single structure. The average annualized return for EGB was over 42%, whereas EGA average annualized return was 1%. Although the two experimental groups performed equally in accuracy, there was a significant difference between the two models in financial performance comparison. Therefore, models in EGC and EGD were based on multiple structures.\nAfter the preliminary experiment, proposed models were compared with the state-of-the-art models trained with time series data mentioned in the literature. The first stage was designed for investigating model prediction: while the model suggested \u2018downward trend to upward trend,\u2019 acquire a long ES futures position and sell it five days later. Otherwise, short a position when model forecasted \u2018upward trend to downward trend\u2019 and bought covering after the forecast number of days (five days). Moreover, two rules were considered in the second stage to make the experimental result more practical. In the second stage, it considered general rules while trading: taking maximum risk and trend continuation into account. Neither long nor short positions were closed when the model predicted the same trend reversal behavior as the current position. Furthermore, long and short positions should set the maximum stop-loss to prevent the models from constantly predicting the reversing to upward trend when the market continues to fall. The results and analysis of the two stages were illustrated in the following subsection A and B.\nA. STAGE 1 - INVESTIGATING MODEL PERFORMANCE The first stage evaluated the classifier performance. The results based on predictions of four models\n(EGB, EGC, EGD, CGA, CGB, CGC) showed in Table 3. All experimental and control groups\u2019 accuracy rates were close to 60%. Although the CGA trained by the LSTM network performed best with an accuracy rate of 64.78%, the accuracy of the proposed experimental group, EGB, and EGD, is about 64%. The accuracy of the two groups is almost the same. Besides, the precision of models among experimental and control groups was approximately the same except for CGC with 52%. In the financial performance evaluation, the average annualized return of the experimental groups was higher than 40%. It was much higher than all models in control groups. The profit to loss ratio (P/L) of all the experimental groups was higher than the control groups in Table 3, indicating that proposed models could obtain more rewards while profiting but smaller losses when they failed. The results showed that the classifier trained with proposed structures did identify the moment that trend reversed from downward trend to upward trend and upward trend to downward trend.\nAlgorithm 2 ALLProcess() Input Financial time series data (OCHL)\n1: Phase Get TextMP 2: dataset = GenerateStructureFromRawData() 3: if(createMultipleMP) 4: groupDataset = multipleMP(5) 5: else 6: groupDataset = singleMP(5) 7: Phase Data Labeling 8: calculatingLabel(groupDataset) 9: Phase Image Creation 10: images = converToGrayImages(groupDataset) 11: convertImages = covertGrayImagesByTimeCausality (images,experimentName) 12: Phase Train Model 13: trainData = splitData(startDataTime, 2016) 14: testData = splitData(2017, endDataTime) 15: model = createCNN() 16: model.train(trainData) 17: Phase Model Performance Evaluation 18: model.test(testData) 19: Phase Financial Performance Evaluation 20: realEnv = createRealEnv(risk) 21: predictions = model.predict(testData) 22: realEnv.evaluatePerformance(predictions,stageName)\nB. STAGE 2 \u2013 PRACTICAL PERFORMANCE As mentioned earlier, the second stage conducted more practical experiments with two general trading rules. First, a position should be kept rather than closed when the signal of predicting the trend reversal did not change. Second, to avoid taking huge risks, a stop-loss order has to be set while acquiring an initial long and short position. The stop-loss is a commonly-used mechanism to handle it in\nVOLUME 10, 2022 12861\nfinancial trading [29], [30]. It keeps away from suffering huge losses during a trade if the model predicts trend reversal behavior is continuously identical with the current position. Table 4 and Table 5 showed the results after setting a 2% and a 5% stop-loss order. When Table 4 and Table 5 were analyzed, it was observed that experimental group models performed well under any risk allowance. The average annualized return of the EGB model was over 30.5%, the average annualized return of the EGC model was over 41%, and the average annualized return of the EGD model was at least 24.8%. Each profit to loss ratio of experimental groups was\nover 1.0 showing the profitable ability while considering different preferred risk values. In contrast with the experimental groups, all the control groups performed worse than the first stage while taking only 2% risk. It is not intuitive to see that the CGA with higher precision than experimental groups, but the total profit is negative. The model based on the correct prediction to do the transaction should profit, not lose money. However, not only precision but the expected return was the key to making the profit. It was possible to lose money with high precision if the model failed to manage the losses well. Fig. 13 demonstrated trading distributions of\n12862 VOLUME 10, 2022\ntrading return for EGC and CGA at the second stage of the experiment set a 2% stop-loss, showing that CGA suffered a greater number of large losses when it failed to detect the market reversals. In addition, EGB made more huge profits when it was correct. As increasing the risk allowance, control groups performed better. When allowed risk was 5%, the average annualized return of the CGA model was 25%, and the average annualized return of CGC was 25.1%. It showed that LSTM and CNN-LSTM network models trained by time series data might be profitable when high risk is allowed. In contrast with most control groups, the models trained with proposed structures performed well under the 2% risk allowance. The 2% risk setting achieved better financial performance, demonstrating that the models had outstanding ability to identify trend reversals. Lower stop loss provides a greater number of transactions so that more opportunities for making profits. In addition, the precision of taking 2% risk was slightly lower than the 5% risk preference. Taking a higher risk can bear the latency of trend reversals. However, it may cause a huge loss if the model mistakes the reversal of the trend and decreases trading chances. CGB was the worst of all the models. Although its precision was not bad, it failed to manage the expected return since the poor value of profit to loss ratio.\nFig. 14 analyzed experimental and control groups\u2019 financial performance details among the first and second stages with different risk preferences. The overall performance of EGC was the best and stable. The average profit per transaction exceeded $600, which was better than EGB. It demonstrated the importance of the influence of time causality. The different grayscale values among structures provide the order of extracted patterns that can help the model discover the trend reversal behavior.\nC. STATISTICAL SIGNIFICANCE TEST This study investigated the novel approach as follows: (a) To investigate whether CNNs could extract the trend reversal behavior from proposed structures of price activities. (b) To prove the proposedmodels canmake a profit in practice\nand perform better than common models with sequence data (c) To explore themodels that consider time causality is better than the models without time causality.\nIn this section, a statistical significance test was used to examine and compare the financial performance between each experimental and control group. At first, F-test was applied to test the population variances of financial performance among our models to select the right formula to carry out the T-test. The statistical significance test results of proposed models compared with models for control groups were tabulated in Table 6 and Table 7. It was worth noting that the annualized return of CGB performed not well. Since the base of (16) was negative, the t-test was performed only at the second stage of the experiment, which set a 5% stoploss. The null hypothesis was expressed as:\nH0 = \u00b5b \u2265 \u00b5a (18)\nTable 6 showed the first result that the null hypothesis was rejected at the preliminary experiment of the first stage, which meant splitting data into five structures was better than merging into a single structure. In addition, all the remaining experimental groups indicated the trading performance of the proposed models was significantly better than the control groups. It showed that the proposed model did detect the trend switching behaviors and take the corresponding right actions in the financial market. However, the test result between EGB, EGC, and EGD accepted the null hypothesis, expressing that considering the time causality with structures has no significant difference at the first stage. It indicated that converting the time series data into structure images based on the market profile theory fed into CNNs could be a good model to identify the trend reversal.\nThe second stage compared the performance of eachmodel in a more realistic context of the transactional environment. Table 7 showed the T-test results under the different proportions of stop-loss. Under the 2% stop loss setting, all null hypothesis was rejected, proposed models had better profitability than the control groups. As increased to a 5% stoploss setting, the profitability of EGC was still significantly better than all the control groups. The results in Table 3-7\nVOLUME 10, 2022 12863\npresented the performance of the EGC against the state-ofthe-art deep learning models.\nV. CONCLUSION In this research, we proposed a deep learning method that utilized a CNNwith structures of price activities as input to identify trend reversal behavior. First, we adopted market profile theory to generate the structure to convert the financial time series data to a text market profile. Second, using disparate linear interpolation to convert TPO in profile into grayscale values, so that structure images were created. At first, single structure and multiple structures images were fed into CNN networks to learn the feature of trend change and compared. The multiple structures were superior to the single structure so that we focused on multiple structures. In addition, we also considered the patterns with time causality that need to integrate time with structure images by modifying the linear interpolation range to emphasize the importance of time.\nTo evaluate the model performance, S&P 500 daily mini futures data was collected as our financial time series data to carry out the simulated trades based on model prediction.\nA long position would be held while the trend changed from a downward trend to an upward trend. On the other hand, a short position would be acquired when the model predicted the trend changed from an upward trend to a downward trend. If the trend did not change, no transaction was made. Ultimately, two stages of different trading mechanisms were designed to analyze both the model performance and the financial performance among the models. For the financial performance, the first stage results showed that all the experimental groups that extracted the features from multiple structures were significantly better than the control groups that utilized the state-of-the-art deep learning models, including LSTM networks, CNN, and CNN-LSTM networks which learning from time series data. Our proposed model has similar classification capabilities to those networks for the model performance. More complicated but close to real-life trades were carried out at the second stage. We considered holding positions longer and setting a stop-loss. As a result, almost all the experimental groups were performed very well against the control groups when allowing 2% risk. In addition, the model fed with structures integrated with the characters of time emphasizing the occurred time between shapes performed best among experimental groups in financial performance evaluation, indicating the importance of the influence of time causality on features. In the future, we will try to add the characters of the volume or other technical analysis methods into the deep learningmodel. Furthermore, ensemble learning with the traditional machine learning method is also considered to improve the model\u2019s accuracy. In the age of AI, our proposed model that could identify trend reversals will help investors avoid the dilemma of chasing highs and killing lows and increase the efficiency of their capital utilization.\nREFERENCES [1] O. B. Sezer, M. U. Gudelek, and A. M. Ozbayoglu, \u2018\u2018Financial time\nseries forecasting with deep learning : A systematic literature review: 2005\u20132019,\u2019\u2019 Appl. Soft Comput., vol. 90, May 2020, Art. no. 106181, doi: 10.1016/j.asoc.2020.106181. [2] O. B. Sezer and A. M. Ozbayoglu, \u2018\u2018Financial trading model with stock bar chart image time series with deep convolutional neural networks,\u2019\u2019 Intelligent Automation and Soft Computing, vol. 26, no. 2, pp. 323\u2013334, 2020, doi: 10.31209/2018.100000065. [3] J. P. Steidlmayer,Markets andMarket Logic. Chicago, IL, USA: Porcupine Press, 1984. [4] J. F. Dalton, E. T. Jones, and R. B. Dalton, Mind Over Markets: Power Trading withMarket Generated Information, 2nd ed. Greenville, SC, USA: Traders Press, 1999. [5] R. L. Galvez, A. A. Bandala, E. P. Dadios, R. R. P. Vicerra, and J. M. Z. Maningo, \u2018\u2018Object detection using convolutional neural networks,\u2019\u2019 in Proc. TENCON IEEE Region Conf., Oct. 2018, pp. 2023\u20132027. [6] E. Hoseinzade and S. Haratizadeh, \u2018\u2018CNNpred: CNN-based stock market prediction using a diverse set of variables,\u2019\u2019 Expert Syst. Appl., vol. 129, pp. 273\u2013285, Sep. 2019. [7] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, \u2018\u2018Gradient-based learning applied to document recognition,\u2019\u2019 Proc. IEEE, vol. 86, no. 11, pp. 2278\u20132324, Nov. 1998, doi: 10.1109/5.726791. [8] B. Hu, Z. Lu, H. Li, and Q. Chen, \u2018\u2018Financial trading model with stock bar chart image time series with deep convolutional neural networks,\u2019\u2019 Intell. Automat. Soft Comput., vol. 26, no. 2, pp. 323\u2013334, 2020, doi: 10.31209/2018.100000065. [9] S. Hochreiter and J. Schmidhuber, \u2018\u2018Long short-term memory,\u2019\u2019 Neural Comput., vol. 9, no. 8, pp. 1735\u20131780, 1997.\n12864 VOLUME 10, 2022\n[10] H. Maqsood, I. Mehmood, M. Maqsood, M. Yasir, S. Afzal, F. Aadil, M. M. Selim, and K. Muhammad, \u2018\u2018A local and global event sentiment based efficient stock exchange forecasting using deep learning,\u2019\u2019 Int. J. Inf. Manage., vol. 50, pp. 432\u2013451, Feb. 2020. [11] A. Krizhevsky, I. Sutskever, and G. E. Hinton, \u2018\u2018ImageNet classification with deep convolutional neural networks,\u2019\u2019 in Proc. Adv. Neural Inf. Process. Syst. (NIPS), vol. 25. Stateline, NV, USA, Dec. 2012, pp. 1097\u20131105. [12] A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, and L. Fei-Fei, \u2018\u2018Large-scale video classification with convolutional neural networks,\u2019\u2019 in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2014, pp. 1725\u20131732. [13] O. B. Sezer and A. M. Ozbayoglu, \u2018\u2018Algorithmic financial trading with deep convolutional neural networks: Time series to image conversion approach,\u2019\u2019 Appl. Soft Comput., vol. 70, pp. 525\u2013538, Sep. 2018. [14] C.-C. Lin, C.-S. Chen, and A.-P. Chen, \u2018\u2018Using intelligent computing and data stream mining for behavioral finance associated with market profile and financial physics,\u2019\u2019Appl. Soft Comput., vol. 68, pp. 756\u2013764, Jul. 2018, doi: 10.1016/j.asoc.2017.08.008. [15] C.-C. Chen, Y.-C. Kuo, C.-H. Huang, and A.-P. Chen, \u2018\u2018Applying market profile theory to forecast Taiwan index futures market,\u2019\u2019 Expert Syst. Appl., vol. 41, no. 10, pp. 4617\u20134624, Aug. 2014. [16] D. Li and D. Yu, \u2018\u2018Deep learning: Methods and applications,\u2019\u2019 Found. Trends Signal Process., vol. 7, nos. 3\u20134, pp. 197\u2013387, 2014. [17] Y. LeCun, Y. Bengio, and G. Hinton, \u2018\u2018Deep learning,\u2019\u2019 Nature, vol. 521, pp. 436\u2013444, Feb. 2015. [18] J. L. Elman, \u2018\u2018Finding structure in time,\u2019\u2019 Cognit. Sci., vol. 14, no. 2, pp. 179\u2013211, Mar. 1990. [19] M. I. Jordan, \u2018\u2018Serial order: A parallel distributed processing approach,\u2019\u2019 in Advances in Psychology, vol. 121. 1997, pp. 471\u2013495, doi: 10.1016/S0166-4115(97)80111-2. [20] M. Sundermeyer, R. Schl\u00fcter, and H. Ney, \u2018\u2018LSTM neural networks for language modeling,\u2019\u2019 in Proc. Interspeech, Sep. 2012, pp. 1\u20134. [21] K. Chen, Y. Zhou, and F. Dai, \u2018\u2018A LSTM-based method for stock returns prediction: A case study of China stock market,\u2019\u2019 in Proc. IEEE Int. Conf. Big Data (Big Data), Oct. 2015, pp. 2823\u20132824. [22] M. Hiransha, E. A. Gopalakrishnan, and V. K. Menon, \u2018\u2018NSE stock market prediction using deep-learning models,\u2019\u2019 Proc. Comput. Sci., vol. 132, pp. 1351\u20131362, Jan. 2018. [23] K. Khare, O. Darekar, P. Gupta, and V. Z. Attar, \u2018\u2018Short term stock price prediction using deep learning,\u2019\u2019 in Proc. 2nd IEEE Int. Conf. Recent Trends Electron., Inf. Commun. Technol. (RTEICT), May 2017, pp. 482\u2013486. [24] X. Zhang and Y. Tan, \u2018\u2018Deep stock ranker: A LSTM neural network model for stock selection,\u2019\u2019 in Proc. Int. Conf. Data Mining Big Data. Cham, Switzerland: Springer, 2018, pp. 614\u2013623. [25] S. Selvin, R. Vinayakumar, E. A. Gopalakrishnan, V. K. Menon, and K. P. Soman, \u2018\u2018Stock price prediction using LSTM, RNN and CNN-sliding window model,\u2019\u2019 in Proc. Int. Conf. Adv. Comput., Commun. Informat. (ICACCI), Sep. 2017, pp. 1643\u20131647. [26] I. E. Livieris, E. Pintelas, and P. Pintelas, \u2018\u2018A CNN-LSTM model for gold price time-series forecasting,\u2019\u2019 Neural Comput. Appl., vol. 32, no. 23, pp. 17351\u201317360, 2020, doi: 10.1007/s00521-020-04867-x.\n[27] M. Kearns, \u2018\u2018A bound on the error of cross validation using the 43 approximation and estimation rates, with consequences for the training-test split,\u2019\u2019 in Proc. Adv. Neural Inf. Process. Syst., 1996, pp. 183\u2013189. [28] A.-P. Chen and Y.-C. Hsu, \u2018\u2018Dynamic physical behavior analysis for financial trading decision support [application notes],\u2019\u2019 IEEE Comput. Intell. Mag., vol. 5, no. 4, pp. 19\u201323, Nov. 2010. [29] J. Dhaene andM. J. Goovaerts, \u2018\u2018Dependency of risks and stop-loss order,\u2019\u2019 ASTIN Bull., vol. 26, no. 2, pp. 201\u2013212, Nov. 1996. [30] M.-E. Wu, J.-H. Syu, J. C.-W. Lin, and J.-M. Ho, \u2018\u2018Effective fuzzy system for qualifying the characteristics of stocks by random trading,\u2019\u2019 IEEE Trans. Fuzzy Syst., early access, Aug. 18, 2021, doi: 10.1109/ TFUZZ.2021.3105192.\nCHERN-BIN JU received the B.S. degree from the Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan, in 2011, and the M.S. degree from the Institute of Information Management, National Chiao Tung University, Hsinchu, in 2013. He is currently pursuing the Ph.D. degree with the Institute of Information Management, National Yang Ming Chiao Tung University, Hsinchu. He also works as a Senior Researcher at Chunghwa Telecom Laboratories,\nTaiwan. His research interests include machine and deep learning, automatic trading systems in the financial market, the Internet of Things, big data, and data analytics.\nAN-PIN CHEN received the B.S. degree from the Department of Agricultural Engineering, National Taiwan University, Taiwan, and the M.S. and Ph.D. degrees in industrial engineering from the University of Southern California. He is currently a Professor with the Institute of Information Management, National Yang Ming Chiao Tung University. He is also the Chair Professor at Asia University, Taiwan. His current research interests include decision support systems, data mining,\nfinancial engineering, knowledge management, and computational intelligence applications in the area of finance. He was elected to a fellow of the Chinese Society for Management of Technology, in 2020.\nVOLUME 10, 2022 12865"
        }
    ],
    "title": "Identifying Financial Market Trend Reversal Behavior With Structures of Price Activities Based on Deep Learning Methods",
    "year": 2022
}