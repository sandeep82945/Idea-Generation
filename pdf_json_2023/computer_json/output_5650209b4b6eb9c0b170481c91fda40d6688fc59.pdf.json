{
    "abstractText": "We propose a method to incorporate the intensity information of a target lesion on CT scans in training segmentation and detection networks. We first build an intensity-based lesion probability (ILP) function from an intensity histogram of the target lesion. It is used to compute the probability of being the lesion for each voxel based on its intensity. Finally, the computed ILP map of each input CT scan is provided as additional supervision for network training, which aims to inform the network about possible lesion locations in terms of intensity values at no additional labeling cost. The method was applied to improve the segmentation of three different lesion types, namely, small bowel carcinoid tumor, kidney tumor, and lung nodule. The effectiveness of the proposed method on a detection task was also investigated. We observed improvements of 41.3% \u2192 47.8%, 74.2% \u2192 76.0%, and 26.4% \u2192 32.7% in segmenting small bowel carcinoid tumor, kidney tumor, and lung nodule, respectively, in terms of per case Dice scores. An improvement of 64.6% \u2192 75.5% was achieved in detecting kidney tumors in terms of average precision. The results of different usages of the ILP map and the effect of varied amount of training data are also presented.",
    "authors": [
        {
            "affiliations": [],
            "name": "Seung Yeon Shin"
        },
        {
            "affiliations": [],
            "name": "Thomas C. Shen"
        },
        {
            "affiliations": [],
            "name": "Ronald M. Summers"
        },
        {
            "affiliations": [],
            "name": "Seung Yeon Shina"
        }
    ],
    "id": "SP:11e944b3f5912492b6a912cc9f1f48bb3a50ff0d",
    "references": [
        {
            "authors": [
                "Y.A. Ayalew",
                "K.A. Fante",
                "M.A. Mohammed"
            ],
            "title": "Modified u-net for liver cancer segmentation from computed tomography images with a new class balancing method",
            "venue": "BMC Biomedical Engineering",
            "year": 2021
        },
        {
            "authors": [
                "M. Black",
                "G. Sapiro",
                "D. Marimont",
                "D. Heeger"
            ],
            "title": "Robust anisotropic diffusion",
            "venue": "IEEE Transactions on Image Processing",
            "year": 1998
        },
        {
            "authors": [
                "T.M. Buzug"
            ],
            "title": "Computed tomography, in: Springer handbook of medical technology",
            "year": 2011
        },
        {
            "authors": [
                "J. Cai",
                "Y. Tang",
                "K. Yan",
                "A.P. Harrison",
                "J. Xiao",
                "G. Lin",
                "L. Lu"
            ],
            "title": "Deep lesion tracker: Monitoring lesions in 4d longitudinal imaging",
            "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2021
        },
        {
            "authors": [
                "\u00d6. \u00c7i\u00e7ek",
                "A. Abdulkadir",
                "S.S. Lienkamp",
                "T. Brox",
                "O. Ronneberger"
            ],
            "title": "2016. 3d u-net: Learning dense volumetric segmentation from sparse annotation",
            "year": 2016
        },
        {
            "authors": [
                "S. Diederich"
            ],
            "title": "Pulmonary nodules: do we need a separate algorithm for non-solid lesions",
            "venue": "Cancer Imaging",
            "year": 2009
        },
        {
            "authors": [
                "E.A. Eisenhauer",
                "P. Therasse",
                "J. Bogaerts",
                "L.H. Schwartz",
                "D. Sargent",
                "R. Ford",
                "J. Dancey",
                "S. Arbuck",
                "S. Gwyther",
                "M Mooney"
            ],
            "title": "New response evaluation criteria in solid tumours: revised recist guideline (version 1.1)",
            "venue": "European journal of cancer",
            "year": 2009
        },
        {
            "authors": [
                "A. Fedorov",
                "R. Beichel",
                "J. Kalpathy-Cramer",
                "J. Finet",
                "J.C. Fillion-Robin",
                "S. Pujol",
                "C. Bauer",
                "D. Jennings",
                "F. Fennessy",
                "M. Sonka",
                "J. Buatti",
                "S. Aylward",
                "J.V. Miller",
                "S. Pieper",
                "R. Kikinis"
            ],
            "title": "3d slicer as an image computing platform for the quantitative imaging network",
            "venue": "Magnetic Resonance Imaging",
            "year": 2012
        },
        {
            "authors": [
                "K. He",
                "X. Zhang",
                "S. Ren",
                "J. Sun"
            ],
            "title": "Deep residual learning for image recognition, in: 2016",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2016
        },
        {
            "authors": [
                "R. Vasdev",
                "M. Peterson",
                "S. McSweeney",
                "S. Peterson",
                "A. Kalapara",
                "N. Sathianathen",
                "N. Papanikolopoulos",
                "C. Weight"
            ],
            "title": "The state of the art in kidney and kidney tumor segmentation in contrast-enhanced ct imaging: Results of the kits19 challenge",
            "venue": "Medical Image Analysis",
            "year": 2021
        },
        {
            "authors": [
                "M.S. Hughes",
                "S.C. Azoury",
                "Y. Assadipour",
                "D.M. Straughan",
                "A.N. Trivedi",
                "R.M. Lim",
                "G. Joy",
                "M.T. Voellinger",
                "D.M. Tang",
                "Venkatesan",
                "A.M"
            ],
            "title": "Prospective evaluation and treatment of familial carcinoid small intestine neuroendocrine tumors",
            "venue": "(si-nets). Surgery",
            "year": 2016
        },
        {
            "authors": [
                "F. Isensee",
                "P.F. Jaeger",
                "S.A. Kohl",
                "J. Petersen",
                "K.H. Maier-Hein"
            ],
            "title": "nnu-net: a self-configuring method for deep learning-based biomedical image segmentation",
            "venue": "Nature methods",
            "year": 2021
        },
        {
            "authors": [
                "P.F. Jaeger",
                "S.A.A. Kohl",
                "S. Bickelhaupt",
                "F. Isensee",
                "T.A. Kuder",
                "H.P. Schlemmer",
                "K.H. Maier-Hein"
            ],
            "title": "Retina U-Net: Embarrassingly Simple Exploitation of Segmentation Supervision for Medical Object Detection",
            "year": 2020
        },
        {
            "authors": [
                "R. Jasti",
                "L.R. Carucci"
            ],
            "title": "Small bowel neoplasms: A pictorial review",
            "venue": "RadioGraphics",
            "year": 2020
        },
        {
            "authors": [
                "B. Kamble",
                "S.P. Sahu",
                "R. Doriya"
            ],
            "title": "A review on lung and nodule segmentation",
            "year": 2020
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "3rd International Conference on Learning Representations,",
            "year": 2015
        },
        {
            "authors": [
                "T.Y. Lin",
                "P. Dollar",
                "R. Girshick",
                "K. He",
                "B. Hariharan",
                "S. Belongie"
            ],
            "title": "Feature pyramid networks for object detection",
            "venue": "in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
            "year": 2017
        },
        {
            "authors": [
                "T.Y. Lin",
                "P. Goyal",
                "R. Girshick",
                "K. He",
                "P. Dollar"
            ],
            "title": "Focal loss for dense object detection",
            "venue": "in: Proceedings of the IEEE International Conference on Computer Vision (ICCV)",
            "year": 2017
        },
        {
            "authors": [
                "Y.P. Lin",
                "H.H. Hsu",
                "K.H. Ko",
                "C.M. Chu",
                "Y.C. Chou",
                "W.C. Chang",
                "T.H. Chang"
            ],
            "title": "Differentiation of malignant and benign incidental breast lesions detected by chest multidetector-row computed tomography: Added value of quantitative enhancement analysis",
            "venue": "PLOS ONE",
            "year": 2016
        },
        {
            "authors": [
                "L. Liu",
                "Y.Y. Tsui",
                "M. Mandal"
            ],
            "title": "Skin lesion segmentation using deep learning with auxiliary task",
            "venue": "Journal of Imaging 7. URL: https://www. mdpi.com/2313-433X/7/4/67,",
            "year": 2021
        },
        {
            "authors": [
                "I. Loshchilov",
                "F. Hutter"
            ],
            "title": "Decoupled weight decay regularization",
            "venue": "in: International Conference on Learning Representations. URL: https:// openreview.net/forum?id=Bkg6RiCqY7",
            "year": 2019
        },
        {
            "authors": [
                "J. Ma",
                "Z. Wei",
                "Y. Zhang",
                "Y. Wang",
                "R. Lv",
                "C. Zhu",
                "C. Gaoxiang",
                "J. Liu",
                "C. Peng",
                "L. Wang",
                "J. Chen"
            ],
            "title": "How distance transform maps boost segmentation cnns: An empirical study",
            "venue": "Proceedings of the Third Conference on Medical Imaging with Deep Learn-",
            "year": 2020
        },
        {
            "authors": [
                "E. Parzen"
            ],
            "title": "On Estimation of a Probability Density Function and Mode",
            "venue": "The Annals of Mathematical Statistics 33,",
            "year": 1962
        },
        {
            "authors": [
                "J. Pedrosa",
                "G. Aresta",
                "C. Ferreira",
                "M. Rodrigues",
                "P. Leit\u00e3o",
                "A.S. Carvalho",
                "J. Rebelo",
                "E. Negr\u00e3o",
                "I. Ramos",
                "A. Cunha",
                "A. Campilho"
            ],
            "title": "Lndb: A lung nodule database on computed tomography",
            "venue": "URL: https: //arxiv.org/abs/1911.08434,",
            "year": 2019
        },
        {
            "authors": [
                "A.C. Phan",
                "V.Q. Vo",
                "T.C. Phan"
            ],
            "title": "A hounsfield value-based approach for automatic recognition of brain haemorrhage",
            "venue": "Journal of Information and Telecommunication",
            "year": 2019
        },
        {
            "authors": [
                "H. Ryu",
                "S.Y. Shin",
                "J.Y. Lee",
                "K.M. Lee",
                "Kang",
                "H.j",
                "J. Yi"
            ],
            "title": "Joint segmentation and classification of hepatic lesions in ultrasound images using deep learning",
            "venue": "European radiology",
            "year": 2021
        },
        {
            "authors": [
                "S.Y. Shin",
                "S. Lee",
                "I.D. Yun",
                "H.Y. Jung",
                "Y.S. Heo",
                "S.M. Kim",
                "K.M. Lee"
            ],
            "title": "A novel cascade classifier for automatic microcalcification detection",
            "venue": "PLOS ONE",
            "year": 2015
        },
        {
            "authors": [
                "S.Y. Shin",
                "S. Lee",
                "I.D. Yun",
                "S.M. Kim",
                "K.M. Lee"
            ],
            "title": "Joint weakly and semi-supervised deep learning for localization and classification of masses in breast ultrasound images",
            "venue": "IEEE Transactions on Medical Imaging",
            "year": 2019
        },
        {
            "authors": [
                "S.Y. Shin",
                "T.C. Shen",
                "S.A. Wank",
                "R.M. Summers"
            ],
            "title": "Improving small lesion segmentation in CT scans using intensity distribution supervision: application to small bowel carcinoid tumor",
            "year": 2023
        },
        {
            "authors": [
                "C.H. Sudre",
                "W. Li",
                "T. Vercauteren",
                "S. Ourselin",
                "M. Jorge Cardoso"
            ],
            "title": "Generalised dice overlap as a deep learning loss function for highly unbalanced segmentations",
            "year": 2017
        },
        {
            "authors": [
                "R.M. Summers",
                "A. Huang",
                "J. Yao",
                "S.R. Campbell",
                "J.E. Dempsey",
                "A.J. Dwyer",
                "M. Franaszek",
                "D.S. Brickman",
                "I. Bitter",
                "N. Petrick",
                "A.K. Hara"
            ],
            "title": "Assessment of polyp and mass histopathology by intravenous contrast\u2013enhanced ct colonography",
            "venue": "Academic Radiology",
            "year": 2006
        },
        {
            "authors": [
                "Y. Tang",
                "Y. Zhu",
                "J. Xiao",
                "R.M. Summers"
            ],
            "title": "E2Net: An edge enhanced network for accurate liver and tumor segmentation on ct scans",
            "venue": "Medical Image Computing and Computer Assisted Intervention \u2013 MICCAI 2020,",
            "year": 2020
        },
        {
            "authors": [
                "L. Weninger",
                "Q. Liu",
                "D. Merhof"
            ],
            "title": "Multi-task learning for brain tumor segmentation",
            "year": 2020
        },
        {
            "authors": [
                "Z. Zhao",
                "H. Chen",
                "L. Wang"
            ],
            "title": "A coarse-to-fine framework for the 2021 kidney and kidney tumor segmentation challenge. URL: https:// openreview.net/forum?id=6Py5BNBKoJt",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "This article has been accepted for publication in Computerized Medical Imaging and Graphics. DOI: https://doi.org/10.1016/j.compmedimag.2023.102259\n1\nar X\niv :2\n30 7.\n05 80\n4v 1\n[ ee\nss .I\nV ]\n1 1\nJu l 2\n02 3\nGraphical Abstract\nImproving Segmentation and Detection of Lesions in CT Scans Using Intensity Distribution Supervision\nSeung Yeon Shin, Thomas C. Shen, Ronald M. Summers\nHighlights\nImproving Segmentation and Detection of Lesions in CT Scans Using Intensity Distribution Supervision\nSeung Yeon Shin, Thomas C. Shen, Ronald M. Summers\n\u2022 Intensity values in CT scans, i.e., Hounsfield unit, convey important information.\n\u2022 A method to incorporate the intensity information of a target lesion in training is proposed.\n\u2022 An intensity distribution of a target lesion is used to define an auxiliary task.\n\u2022 It informs the network about possible lesion locations based on intensity values.\n\u2022 A relative improvement of 2.4% (16.9%) was obtained in segmenting (detecting) kidney tumors.\nImproving Segmentation and Detection of\nLesions in CT Scans\nUsing Intensity Distribution Supervision\nSeung Yeon Shina,\u2217, Thomas C. Shena, Ronald M. Summersa\naImaging Biomarkers and Computer-Aided Diagnosis Laboratory, Radiology and Imaging Sciences, Clinical Center, National Institutes of Health, Bethesda, 20892, MD, USA\nAbstract\nWe propose a method to incorporate the intensity information of a target lesion on CT scans in training segmentation and detection networks. We first build an intensity-based lesion probability (ILP) function from an intensity histogram of the target lesion. It is used to compute the probability of being the lesion for each voxel based on its intensity. Finally, the computed ILP map of each input CT scan is provided as additional supervision for network training, which aims to inform the network about possible lesion locations in terms of intensity values at no additional labeling cost. The method was applied to improve the segmentation of three different lesion types, namely, small bowel carcinoid tumor, kidney tumor, and lung nodule. The effectiveness of the proposed method on a detection task was also investigated. We observed improvements of 41.3% \u2192 47.8%, 74.2% \u2192 76.0%, and 26.4% \u2192 32.7% in segmenting small bowel carcinoid tumor, kidney tumor, and lung nodule, respectively, in terms of per case Dice scores. An improvement of 64.6% \u2192 75.5% was achieved in detecting kidney tumors in terms of average precision. The results of different usages of the ILP map and the effect of varied amount of training data are also presented.\nKeywords: Lesion segmentation, lesion detection, supervision, intensity distribution, Hounsfield unit, computed tomography, carcinoid tumor, kidney tumor, lung nodule\n\u2217Corresponding author: ssy2280@gmail.com\nPreprint submitted to Computerized Medical Imaging and Graphics July 13, 2023"
        },
        {
            "heading": "1. Introduction",
            "text": "Identification and quantification of abnormalities are the first objectives of medical image acquisition (Eisenhauer et al., 2009; Shin et al., 2019; Ryu et al., 2021). According to the result, immediate treatments can be done, or follow-up studies are triggered for surveillance (Cai et al., 2021).\nAbnormalities can arise at various locations in the body, such as different tissues and organs. When finding a particular type of lesion, it is often coupled with segmentation of an organ/tissue that can contain the lesion, e.g., liver and liver tumor segmentation (Ayalew et al., 2021). These two related tasks can be considered either sequentially or jointly. In the first case, organ segmentation can benefit the following lesion identification by restricting the region of interest and thus by enabling more detailed inspection within it (Shin et al., 2015; Kamble et al., 2020). Meanwhile, the latter facilitates joint optimization of the relevant tasks and thus can lead to an enhancement of them. In the work of Tang et al. (2020), liver and liver tumor segmentations are performed jointly using a single shared network to utilize the correlation between them. Features learned for organ segmentation would be relevant to contained lesions since they reside within the organ.\nNevertheless, it is not always possible to train the organ segmentation together with the target lesion segmentation since it requires additional groundtruth (GT) segmentations of the organ. Indeed, a clinician aims to find and mark abnormalities, but not an entire organ, which hinders the mentioned joint or sequential modeling in most cases.\nTo boost the lesion segmentation without requiring additional supervision, there have been many attempts (Weninger et al., 2020; Liu et al., 2021; Ma et al., 2020). Weninger et al. (2020) utilized a multi-task learning network, which performs an image reconstruction task in parallel with tumor segmentation, for brain tumors in magnetic resonance imaging (MRI) scans. By having a shared encoder and separate decoders for each task, training a part of the network, i.e., auto-encoder part, using scans without annotations is enabled. In the work of Liu et al. (2021), lesion edge prediction is used as an auxiliary task to help the segmentation of skin lesions. Two tasks can interact with each other within the network and boost each other\u2019s performance in turn. As a noticeable trend, incorporating distance transform maps of GT into segmentation networks has been tried in many different works in past years, which were summarized in the work of Ma et al. (2020). Interestingly, most of the benchmark methods showed no or minor improvement against\n2\nthe baseline for tumor segmentation while they performed more preferably for organ segmentation. Challenges of tumor segmentation compared to organ segmentation, such as various locations, shapes, and sizes, are mentioned as a potential reason.\nIn terms of lesion detection, Jaeger et al. (2020) developed the Retina UNet architecture based on the Retina Net (Lin et al., 2017b). The decoding part of the Retina Net is augmented by additional high-resolution feature levels, and semantic lesion segmentation is performed on top of them to boost the detection task. Despite its effectiveness, it assumes that segmentation annotations are available together with detection annotations, which is not always the case.\nIn computed tomography (CT) scans, intensity values, i.e., Hounsfield unit (HU), convey important information on the substance of each region, e.g., air, fat, and bone (Buzug, 2011). Therefore, they can be used in identifying a particular organ, tissue, or lesion (Petersenn et al., 2015; Lin et al., 2016; Phan et al., 2019; Summers et al., 2006). In the work of Petersenn et al. (2015), a HU threshold of 13 or 21 is suggested to discriminate malignant adrenal tumors from benign ones in unenhanced CT scans. In the work of Lin et al. (2016), a combined use of lesion morphology and HU values improved the diagnostic accuracy in differentiating benign and malignant incidental breast lesions on contrast-enhanced chest CT scans. In the work of Phan et al. (2019), a specific threshold range of [40, 90] is used to determine areas of hemorrhage on brain CT scans.\nIn this paper, we propose a method to incorporate the intensity information of a target lesion on CT scans in training segmentation and detection networks. Instead of using hard thresholds as in the previous works (Petersenn et al., 2015; Lin et al., 2016; Phan et al., 2019), an intensity distribution of a target lesion is first built and used to effectively locate regions where the lesions are possibly situated. The intensity distribution can be achieved by investigating intensity values within available GT lesion segmentations or can be provided as prior information. More specifically, an intensity-based lesion probability (ILP) function constructed from an intensity histogram is used to compute the probability of being lesion for each voxel, and this soft label map is provided for network training as an auxiliary task. It informs the network about our region of interest, which could contain target lesions, based on the intensity. Compared to the organ segmentation trained jointly with lesion identification tasks, our new task can be understood as a soft and possibly disconnected surrogate of organ segmentation, and it requires\n3\nno additional annotation cost. We demonstrate the effectiveness of the proposed method by conducting experiments on three different datasets: 1) an in-house small bowel carcinoid tumor dataset, 2) the KiTS21 dataset (Heller et al., 2021) for kidney tumors, and 3) the LNDb dataset for lung nodules (Pedrosa et al., 2019). The main contributions of our work are as follows. (1) We extend the idea of our previous paper (Shin et al., 2023) to the segmentation of different lesions at different body locations to verify its generability. (2) We further investigate the effectiveness of the proposed method in several aspects, namely with varied amount of training data, in comparison to the joint organ segmentation, and even on a detection task."
        },
        {
            "heading": "2. Datasets",
            "text": ""
        },
        {
            "heading": "2.1. Small Bowel Carcinoid Tumor Dataset",
            "text": "Carcinoid tumor is a rare neoplasm (small bowel neoplasms including carcinoid tumors account for 0.5% of all cancers in the United States (Jasti and Carucci, 2020)) and found predominantly within the gastrointestinal tract (50 \u2212 71.4%) and especially in the small bowel (24 \u2212 44%) (Hughes et al., 2016). They are often less than a centimeter in size (Hughes et al., 2016).\nOur carcinoid tumor dataset is composed of 24 preoperative abdominal CT scans collected at the National Institutes of Health Clinical Center. Each scan is from a unique patient who underwent surgery and had at least one carcinoid tumor within the small bowel. We note that creating a large dataset for small bowel carcinoid tumors is more difficult than for other more prevalent diseases.\nAll scans are intravenous and oral contrast-enhanced. An oral contrast agent of Volumen was used. Each patient has both arterial and venous phase scans, and either of them was selectively used according to the relevant description in the corresponding radiology report (18 arterial and 6 venous phase scans). They were acquired using 0.5, 1, or 2 mm slice thickness. All scans were cropped manually along the z-axis to include from the diaphragm through the pelvis. We will call this the SBCT dataset.\nTo achieve GT segmentation of tumors, we used \u201cSegment Editor\u201d module in 3DSlicer (Fedorov et al., 2012). The corresponding radiology report and an available 18F-DOPA PET scan were referred to for help in locating\n4\ntumors. 88 tumors were annotated in total. We use five-fold cross-validation for this dataset."
        },
        {
            "heading": "2.2. The KiTS21 Dataset",
            "text": "Kidney cancer is the sixth and the ninth most common cancer for men and women, respectively, in the United States (Cancer.Net, 2022). The KiTS21 dataset aims to accelerate the development of automatic segmentation tools for renal tumors and surrounding anatomy. The KiTS21 cohort includes patients who underwent nephrectomy for suspected renal malignancy (Heller et al., 2021). Preoperative CT scans of these patients were collected to compose the dataset. The official training set comprises 300 CT scans from 300 unique patients who had at least one kidney tumor.\nAll scans are contrast-enhanced and were acquired in the late arterial phase. Every scan has corresponding GT segmentations of the kidney, tumor, and cyst. In this work, we focus on segmenting tumors while leaving cysts unattended since cysts are benign and clinically less relevant than tumors. We refer the authors to the dataset description paper (Heller et al., 2021) for more information. For experiments, we divide the dataset into training/validation/test sets at a ratio of 7:1:2."
        },
        {
            "heading": "2.3. The LNDb Dataset",
            "text": "Lung cancer is the leading cause of cancer death, which makes up almost 25% of all cancer deaths (American Cancer Society, 2022). Being a possible indicator of lung cancer, lung nodules show various shapes and characteristics. Thus, the identification and characterization of them are not trivial and prone to high inter-observer variability (Pedrosa et al., 2019).\nThe LNDb dataset includes 294 intravenous contrast-enhanced CT scans from 294 unique patients. Fifty-eight scans among them were withheld by the organizers for the test set and the remaining 236 scans are available. Among all identified lesions (nodule \u2265 3 mm, nodule < 3 mm, non-nodule), only nodules that are greater than or equal to 3 mm were segmented during the annotation process, and they will be segmented in this work. Thirty-five scans have been excluded since they have an empty segmentation map with the above-mentioned reason, resulting in 201 remained scans (236 \u2212 35 = 201).\nIn this work, we especially focus on improving the segmentation of nonsolid nodules since they are more likely to be malignant than solid nodules\n5\nand more difficult to identify due to their fuzzy appearance and lower incidence (Diederich, 2009). We utilized nodule texture ratings (1\u2212 5) provided in the dataset, where 1 denotes closer to non-solid nodules and 5 denotes closer to solid nodules. According to these ratings, we classified each segmented nodule into two groups, namely, non-solid (\u2264 2) or solid (> 2). Nineteen scans were identified to have at least one non-solid nodule after manual inspection. We note that these 19 scans can also contain solid nodules. Finally, they are used for two-fold cross-validation while the remaining 182 (= 201\u221219) scans are included as training images for every fold training."
        },
        {
            "heading": "3. Methods",
            "text": ""
        },
        {
            "heading": "3.1. Intensity Distribution Supervision",
            "text": "Figure 1 presents the intensity histogram of target lesions of each dataset. They were computed by aggregating intensity values within GT lesion segmentations of each dataset. Images were smoothed using anisotropic diffusion (Black et al., 1998) before the histogram construction. To make a smooth evaluable function from the discontinuous histogram, we perform kernel density estimation (Parzen, 1962). It is a method used to estimate the probability density function based on kernels as basis functions. We used \u2018gaussian kde\u2019 function of SciPy Python library, which uses Gaussian kernels with automatic bandwidth determination. The resulting function is then rescaled to have the maximum value of 1. While it could be less precise, the ILP function can be provided also by a user as prior information.\nThe resulting ILP functions are superimposed with their corresponding histograms in Figure 1. They enable faster calculation of the ILP for a large set of voxels (a whole CT scan) than using the histogram. The ILP function, f ILP , is used to compute the probability of being part of the target lesion for each voxel according to its intensity value. Given an input image volume X = {xi}Ni=1, the corresponding ILP volume Y ILP is defined as:\nY ILP = {yILPi }Ni=1 = {f ILP (xi)}Ni=1, (1)\nwhere N is the number of voxels. An example of the computed ILP volume is visualized in Figure 2. It is then provided to a network as the label map of an auxiliary task. It informs the network about our region of interest, which could contain target lesions, especially in terms of intensity values. Compared to the organ segmentation trained jointly with lesion identification tasks, our\n6\nnew task can be understood as a soft and possibly disconnected surrogate of organ segmentation, and it requires no additional labeling effort."
        },
        {
            "heading": "3.2. Network Training",
            "text": ""
        },
        {
            "heading": "3.2.1. Lesion Segmentation Network",
            "text": "The proposed intensity distribution supervision can be easily used for a lesion segmentation network. Figure 2 visualizes the data used for the network training. Given an input image volume X, the corresponding ILP volume Y ILP is generated using the ILP function f ILP . Then, it is used as supervision for network training together with the segmentation GT, Y segm.\nFor simplicity, we use a network with two output channels, which is similar to the one for joint liver and liver tumor segmentation (Tang et al., 2020). However, the second output channel of our network predicts the ILP in place\n7\nof organ segmentation. The generated GT ILP volume Y ILP is used as supervision for this channel.\nA new loss term for the added task, LILP , is incorporated into training accordingly as shown in Figure 2. Cross-entropy loss is used to measure the dissimilarity between the GT and the prediction of the ILP. Finally, the overall loss function for training the lesion segmentation network is defined as:\nL = Lsegm + \u03bbLILP (2)\nwhere Lsegm is the segmentation loss and \u03bb is the relative weight for the ILP loss LILP . We use the generalized Dice loss (Sudre et al., 2017) for Lsegm.\n8"
        },
        {
            "heading": "3.2.2. Lesion Detection Network",
            "text": "Our intensity distribution supervision can be also used to enhance detectors that are based on feature pyramid networks (FPNs) (Lin et al., 2017a), such as the Retina Net (Lin et al., 2017b), with the same philosophy as the Retina U-Net (Jaeger et al., 2020). Figure 3 explains the concept. In the Retina U-Net, to exploit available GT segmentation of lesions, the decoding part of the Retina Net is augmented by additional high-resolution feature levels, and semantic lesion segmentation is performed on top of them. Despite its effectiveness, it is not feasible if the GT segmentation is unavailable.\nOur ILP map Y ILP , which is generated from each input image volume X using the ILP function f ILP can replace the GT segmentation. The same ILP loss LILP is applied as in the segmentation network. Finally, the overall loss function for training the lesion detection network is defined as:\nL = Ldet + \u03bbLILP (3)\n9\nwhere Ldet is the typical detection loss for classification and box regression, and \u03bb is the relative weight for LILP ."
        },
        {
            "heading": "3.3. Evaluation Details",
            "text": ""
        },
        {
            "heading": "3.3.1. Lesion Segmentation",
            "text": "We first used our own version of the 3D U-Net (C\u0327ic\u0327ek et al., 2016) to have more control over the training/test procedures and thus verify the pure impact of using the proposed intensity distribution supervision. Then, we further attempted to combine it with the self-configuring nnU-Net (Isensee et al., 2021) to achieve more optimized performance. Within this framework, the \u20183D\u2019 full resolution \u2018U-Net\u2019 was used again but with higher complexity in terms of the network size, data augmentation, and test time method. We note that the proposed method of using intensity information can be used for any other segmentation networks.\nThe ILP functions in Figure 1 were used for each dataset. Especially for the LNDb dataset, we used the function of non-solid nodules (Figure 1(c)) to emphasize them more during training since our goal is to improve the segmentation of them. Their distribution is wider than that of small bowel carcinoid tumors or kidney tumors because they are located in the lung parenchyma. Nevertheless, it is distinguishable from that of solid nodules (Figure 1(d)).\nHyperparameters related to each method and each dataset are summarized in Table 1. The learning rates and \u03bb were chosen through the grid search for both methods. While the other values were chosen through the grid search again by ourselves for the 3D U-Net, they were chosen automatically for the self-configuring nnU-Net. We used the AdamW optimizer (Loshchilov and Hutter, 2019) for the 3D U-Net. The SGD with a momentum of 0.99 was used for the nnU-Net. In all of the implemented networks, 3x3x3 convolution kernels are used except 1x1x1 kernels for the final inference layer.\nFor data augmentation, various geometric and photometric augmentation methods that are available in their implementation (https://github.com/MICDKFZ/nnUNet) were used as is for the nnU-Net. The whole set of photometric augmentations was turned on or off in its entirety to check their relevance in each dataset. Meanwhile, selective sets of augmentations were used for the 3D U-Net after performing an investigation on the effect of each method for each dataset. While only image rotation was used for the SBCT and the LNDb datasets, image scaling and elastic deformations were used as well for\n10\nthe KiTS21 dataset. In test time, a test time augmentation method of image mirroring was used for the nnU-Net.\nFor evaluation, we use per case and per lesion Dice scores. The per case Dice score denotes an average Dice score per scan. In calculating the per lesion Dice scores, tight local image volumes around each tumor were taken into account. Paired t-tests are conducted to show the statistical significance of the proposed method. We used an NVIDIA Tesla V100 32GB GPU to conduct experiments."
        },
        {
            "heading": "3.3.2. Lesion Detection",
            "text": "For all compared methods, the same backbone FPN (Lin et al., 2017a) based on a ResNet50 (He et al., 2016) was used. We used the Adam optimizer (Kingma and Ba, 2015) with a learning rate of 10\u22124. 0.003 was used for \u03bb of Eq. 3. The training was conducted using image patches of size 96 \u00d7 96 \u00d7 64, which were sampled from scans that have isotropic voxels of 2\u00d7 2\u00d7 2 mm3. The batch size of 8 was used. For data augmentation, image scaling, rotation, mirroring, and elastic deformations were used.\nFor experiments, we used the KiTS21 dataset, which has the biggest number of scans. We report average precision (AP) with an intersection over union threshold of 0.1, following the method of Jaeger et al. (2020).\n11"
        },
        {
            "heading": "4. Results",
            "text": ""
        },
        {
            "heading": "4.1. Lesion Segmentation",
            "text": ""
        },
        {
            "heading": "4.1.1. Experiments on the SBCT Dataset",
            "text": "Quantitative Results. Table 2 presents quantitative results of segmentation methods, which differ in the ways of using the intensity distribution information. We used the 3D U-Net (C\u0327ic\u0327ek et al., 2016) to verify the pure effect of the different usages of the intensity distribution information.\nApplying post-processing to the prediction of the segmentation network, where the ILP volume Y ILP is multiplied with the network predicted probability map, rather worsened the performance (\u20183D U-Net + PP\u2019). This postprocessing could oversimply rule out lesions that have intensity values deviating from the built intensity distribution. We also tried using the ILP volume as an additional input channel instead of as additional supervision (\u20183D U-Net + ILP(in)\u2019). It can be another way to highlight our region of interest at the input level. However, it performed merely on par with the baseline that does not use this additional information.\nOn the other hand, the proposed method, \u20183D U-Net + ILP\u2019, showed clear improvements for all types of Dice scores when compared to the baseline. The proposed method of using the intensity distribution supervision\n12\ndoes not entail any additional labeling effort. The ILP function can be constructed and included in training by looking up already available CT scans and corresponding GT tumor segmentation.\nWe also investigate the effect of having the precise intensity model of a target. \u20183D U-Net + ILP(shifted)\u2019 is the proposed method but uses another ILP function that is +100 shifted from the original one. The shifted function does not reflect the actual intensity distribution of the target anymore. It performed rather worse than the baseline.\nAll methods including the proposed method showed higher Dice scores for relatively larger tumors (\u2265 125 mm3, which is approximately \u2265 6 mm diameter) than for all tumors.\nQualitative Results. Figure 4 presents example segmentation results of small bowel carcinoid tumor. Compared to the baseline method that is trained without the intensity distribution supervision, the proposed method segments more tumors (first and second rows). The last row shows a failure case, where\n13\nthe proposed method missed a blurry small tumor."
        },
        {
            "heading": "4.1.2. Experiments on the KiTS21 Dataset",
            "text": "Quantitative Results. Table 3 presents quantitative results of different segmentation methods on the KiTS21 dataset. We first used different versions of the 3D U-Net that were augmented using different additional supervision, and again used the nnU-Net for more optimized performance. We also incorporated the proposed intensity distribution supervision in training the winning method of the KiTS21 challenge (Zhao et al., 2021).\nIn the 3D U-Net based comparison, the proposed method (\u20183D U-Net + ILP\u2019) outperformed the baseline (\u20183D U-Net\u2019). We further compare it against a multi-task learning network that performs organ (kidney) segmentation together with lesion (kidney tumor) segmentation, which is \u20183D U-Net + organ\u2019 in Table 3. As our ILP map informs the network about our region of interest, which could contain target lesions, in terms of intensity values, organ segmentation supervision could do the same in a stricter way, i.e., kidney\n14\ntumors can exist within the kidney. The proposed method performed on par with the organ-segmentation-augmented method, which requires additional labeling effort while the proposed method does not.\nThe proposed method (\u2018nnU-Net + ILP\u2019) still outperformed the baseline (\u2018nnU-Net\u2019) when the nnU-Net was used. The test time augmentation method of the nnU-Net could decrease the performance gap by benefiting an under-performed method more. We note that the proposed method could be not well harmonized with photometric augmentations since they randomly distort original voxel values and thus can change the physical meaning that each voxel originally has on CT scans. We found in this dataset that photometric augmentations do not really help in improving the performance even for the baseline method (\u2018nnU-Net + photo aug.\u2019). Thus, only geometric augmentations were used. \u2018nnU-Net + organ\u2019 showed a better performance than the proposed method, but it used an additional annotation of the kidney.\nWe also incorporated the proposed intensity distribution supervision in training the winning method of the KiTS21 challenge (Zhao et al., 2021). The method is composed of three steps (networks), which are coarse kidney segmentation, fine kidney segmentation, and tumor segmentation. Therefore, it uses GT segmentations of the kidney and tumor for training of the first and second networks, and the last network, respectively. Since there is no publicly available code, we have used our own implementation for the experiment. When the intensity distribution supervision was incorporated in the last tumor segmentation step at no additional labeling cost, a better performance was again achieved (\u2018Zhao et al. (2021) + ILP\u2019).\nFigure 5 shows the segmentation performances on the KiTS21 dataset, depending on the number of training images. Given the original training set of 210 images, 90, 120, 150, or 180 images were randomly sampled to conduct the experiments. The same validation and test sets of 30 and 60 images, respectively, were used for all training set sizes. The proposed method consistently outperformed the baseline for all experiments, with a margin of around 2%.\nQualitative Results. Figure 6 shows example segmentation results on the KiTS21 dataset. The proposed method segments tumors more precisely (first and second rows) by utilizing the intensity distribution supervision when compared to the baseline. The last row shows a failure case, where the tumor was missed by both the baseline and proposed methods.\n15"
        },
        {
            "heading": "4.1.3. Experiments on the LNDb Dataset",
            "text": "Quantitative Results. Table 4 presents quantitative segmentation results on the LNDb dataset. As mentioned in Section 2, we tried to improve the segmentation of non-solid nodules in this work by incorporating their intensity distribution information into network training. For both the 3D U-Net and nnU-Net, the inclusion of the intensity distribution supervision (+ ILP in Table 4) helped in segmenting non-solid nodules better thus resulting in the performance improvement also for all nodules, except for the per lesion Dice scores of the 3D U-Net. Per lesion Dice score, by definition, does not take into account FPs that are apart from GT lesions. On the other hand, it focuses on segmentation quality around GT lesions. Therefore, FNs are considered more important than FPs in calculating it. The proposed method with the 3D U-Net reduced FPs but induced FNs, which led to increased per case Dice scores but decreased per lesion Dice scores. Nevertheless, the added intensity distribution supervision on non-solid nodules helped in segmenting them while overcoming their fuzzy appearance and underrepresentation in the dataset.\n16\nQualitative Results. Figure 7 presents example segmentation results on the LNDb dataset. Compared to the baseline method, the proposed method segments more nodules (first and second rows)."
        },
        {
            "heading": "4.2. Lesion Detection",
            "text": ""
        },
        {
            "heading": "4.2.1. Quantitative Results",
            "text": "Table 5 presents quantitative results of detection methods that differ in augmenting the baseline Retina Net (Lin et al., 2017b) on the KiTS21 dataset. The network architecture of each method is explained in Figure 3 and the corresponding text. The Retina U-Net (Jaeger et al., 2020) exploiting lesion segmentation supervision, which is assumed to be available together with detection GTs, outperformed the Retina Net, as suggested in the work of Jaeger et al. (2020). When the lesion segmentation supervision was replaced with the proposed ILP supervision, it outperformed the baseline Retina Net again and further outperformed the Retina U-Net. While\n17\nthe ILP function could be less precise, it can be constructed using a small number of GT lesion segmentations or can be even provided by a user as prior information. Also, while the Retina Net was used as the baseline here, the proposed method can be used to enhance any detectors that are based on FPNs in the same manner."
        },
        {
            "heading": "4.2.2. Qualitative Results",
            "text": "Figure 8 shows example detection results on the KiTS21 dataset. The incorporated intensity distribution information helped in locating a tumor (first row) and eliminating a false positive (second row). The bottom two rows represent failure cases. In the third row, a false positive was detected by the proposed method on the heterogeneous stomach, which resembles a kidney with a tumor in appearance. In the last row, the tumor that has\n18\nsimilar intensity values as the rest of the kidney was missed by the proposed method."
        },
        {
            "heading": "5. Discussion",
            "text": "We have presented a method to incorporate the intensity information of a target lesion on CT scans in training segmentation and detection networks. An ILP function constructed from an intensity histogram of a target lesion is used to effectively locate regions where the lesions are possibly situated. The ILP map of each input CT scan is provided as additional supervision for network training. It aims to inform the network about our region of interest, which could contain target lesions, especially in terms of intensity values. It requires no additional labeling effort.\n19\nThe method has been applied to improve the segmentation of three different lesion types, namely, small bowel carcinoid tumors, kidney tumors,\n20\nand lung nodules. The effectiveness of the proposed method on a detection task has been also investigated for kidney tumors. Our findings from the experiments are: 1) The proposed method of using the ILP as additional supervision performs better than other usages of it, such as for post-processing and as an additional input channel (Table 2). 2) Having a precise and generalizable intensity distribution is important for the success of the method (Table 2). 3) It can be effectively used with the nnU-Net for more optimized performance (Table 3). 4) It performs favorably against a method that exploits another supervision such as organ segmentation (Table 3). 5) Consistent performance gains can be expected over varying training set sizes (Figure 5). 6) It can be considered to boost the performance of an underrepresented lesion type (Table 4). 7) It can be used to enhance a detector such as the Retina Net (Lin et al., 2017b) (Table 5).\nCarcinoid tumors in our SBCT dataset are small (Figure 4). Lung nodules in the LNDb dataset are also small (mostly less than a centimeter (Pedrosa et al., 2019)) as exemplified in Figure 7. Even small numbers of false positive and false negative voxels have a big impact on the Dice score of small lesions. Nevertheless, the proposed method showed clear improvements compared to the baseline. We also note that we segmented nodules from an entire CT scan, whereas the segmentation is conducted when nodule centroids are given for each scan in the LNDb challenge. Our task is more challenging, which makes achieving high Dice scores difficult again.\nFor the KiTS21 dataset, we incorporated the proposed intensity distribution supervision also in training the challenge winning method (Zhao et al., 2021). Although the efficacy of the proposed method was verified, our result is not directly comparable with theirs since they used more training images (240 vs. 210). While they divided the dataset into only training and validation sets (a separate test set available for the challenge period), we divided it into training/validation/test sets to enable a strict evaluation within the available data. Also, we did not use their postprocessing method of counting the number of voxels for each connected component and thresholding them based on their sizes, since that heuristics is not always relevant.\nIn terms of network training, typical segmentation and detection losses are used together with the ILP loss for the segmentation and detection tasks, respectively (Eq. 2 and Eq. 3). The proposed method provides an additional opportunity to consider the intensity information of the target lesion in an explicit way while retaining learning about other aspects by the typical loss terms. A lesion that is not distinct by the ILP model still can be identified\n21\nby the other aspects. For example, in the third row of Figure 8, the tumor that is not distinct from the kidney by intensity values was still detected by the proposed method.\nIn this work, for each target lesion, the experiments have been conducted on a single dataset acquired using a particular imaging protocol. The proposed method would be less applicable across datasets that were acquired using different imaging protocols since the intensity distribution of the target lesion can be diffused and incoherent. Also, we took a relatively simple implementation for incorporating the intensity information of the target lesion in the network training. For the same objective, a better approach can be explored.\nIn future work, we plan to study the effect of incorporating unsupervised images into training since the proposed intensity distribution supervision enables training on them. The proposed method can be further applied to different target lesions.\nData Availability\nThe code is available at https://github.com/rsummers11/CADLab/tree /master/intensity distribution supervision"
        },
        {
            "heading": "Acknowledgment",
            "text": "This research was supported by the Intramural Research Program of the National Institutes of Health, Clinical Center. The research used the highperformance computing facilities of the NIH Biowulf cluster.\nConflicts of Interest\nPotential financial interest: Author Ronald M. Summers receives royalties from iCAD, Philips, Scan Med, PingAn, and Translation Holdings and has received research support from Ping An (CRADA)."
        }
    ],
    "title": "Improving Segmentation and Detection of Lesions in CT Scans Using Intensity Distribution Supervision",
    "year": 2023
}