{
    "abstractText": "The vast majority of text transformation techniques in NLP are inherently limited in their ability to expand input space coverage due to an implicit constraint to preserve the original class label. In this work, we propose the notion of sibylvariance (SIB) to describe the broader set of transforms that relax the labelpreserving constraint, knowably vary the expected class, and lead to significantly more diverse input distributions. We offer a unified framework to organize all data transformations, including two types of SIB: (1) Transmutations convert one discrete kind into another, (2) Mixture Mutations blend two or more classes together. To explore the role of sibylvariance within NLP, we implemented 41 text transformations, including several novel techniques like Concept2Sentence and SentMix. Sibylvariance also enables a unique form of adaptive training that generates new input mixtures for the most confused class pairs, challenging the learner to differentiate with greater nuance. Our experiments on six benchmark datasets strongly support the efficacy of sibylvariance for generalization performance, defect detection, and adversarial robustness.",
    "authors": [
        {
            "affiliations": [],
            "name": "Fabrice Harel-Canada"
        },
        {
            "affiliations": [],
            "name": "Muhammad Ali Gulzar"
        },
        {
            "affiliations": [],
            "name": "Nanyun Peng"
        },
        {
            "affiliations": [],
            "name": "Miryung Kim"
        }
    ],
    "id": "SP:44bbe185814c0b8e80a0802b1554ad479e6af55b",
    "references": [
        {
            "authors": [
                "Moustafa Alzantot",
                "Yash Sharma",
                "Ahmed Elgohary",
                "Bo-Jhang Ho",
                "Mani B. Srivastava",
                "Kai-Wei Chang."
            ],
            "title": "Generating natural language adversarial examples",
            "venue": "CoRR, abs/1804.07998.",
            "year": 2018
        },
        {
            "authors": [
                "E. Barr",
                "M. Harman",
                "P. McMinn",
                "M. Shahbaz",
                "Shin Yoo."
            ],
            "title": "The oracle problem in software testing: A survey",
            "venue": "IEEE Transactions on Software Engineering, 41:507\u2013525.",
            "year": 2015
        },
        {
            "authors": [
                "Kevin W. Bowyer",
                "Nitesh V. Chawla",
                "Lawrence O. Hall",
                "W. Philip Kegelmeyer."
            ],
            "title": "SMOTE: synthetic minority over-sampling technique",
            "venue": "CoRR, abs/1106.1813.",
            "year": 2011
        },
        {
            "authors": [
                "Olivier Chapelle",
                "Jason Weston",
                "L\u00e9on Bottou",
                "Vladimir Vapnik."
            ],
            "title": "Vicinal risk minimization",
            "venue": "Advances in Neural Information Processing Systems, volume 13. MIT Press.",
            "year": 2001
        },
        {
            "authors": [
                "Jiaao Chen",
                "Zichao Yang",
                "Diyi Yang."
            ],
            "title": "Mixtext: Linguistically-informed interpolation of hidden space for semi-supervised text classification",
            "venue": "CoRR, abs/2004.12239.",
            "year": 2020
        },
        {
            "authors": [
                "T. Chen",
                "S. Cheung",
                "S. Yiu."
            ],
            "title": "Metamorphic testing: A new approach for generating next test cases",
            "venue": "ArXiv, abs/2002.12543.",
            "year": 2020
        },
        {
            "authors": [
                "Corinna Cortes",
                "Vladimir Vapnik."
            ],
            "title": "Supportvector networks",
            "venue": "Machine learning, 20(3):273\u2013297.",
            "year": 1995
        },
        {
            "authors": [
                "Ekin D. Cubuk",
                "Barret Zoph",
                "Jonathon Shlens",
                "Quoc V. Le."
            ],
            "title": "Randaugment: Practical data augmentation with no separate search",
            "venue": "CoRR, abs/1909.13719.",
            "year": 2019
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: pre-training of deep bidirectional transformers for language understanding",
            "venue": "CoRR, abs/1810.04805.",
            "year": 2018
        },
        {
            "authors": [
                "Terrance DeVries",
                "Graham W. Taylor"
            ],
            "title": "Dataset augmentation in feature space",
            "year": 2017
        },
        {
            "authors": [
                "Terrance Devries",
                "Graham W. Taylor."
            ],
            "title": "Improved regularization of convolutional neural networks with cutout",
            "venue": "CoRR, abs/1708.04552.",
            "year": 2017
        },
        {
            "authors": [
                "Steven Y. Feng",
                "Varun Gangal",
                "Jason Wei",
                "Sarath Chandar",
                "Soroush Vosoughi",
                "Teruko Mitamura",
                "Eduard Hovy"
            ],
            "title": "A survey of data augmentation approaches for nlp",
            "year": 2021
        },
        {
            "authors": [
                "Ji Gao",
                "Jack Lanchantin",
                "Mary Lou Soffa",
                "Yanjun Qi."
            ],
            "title": "Black-box generation of adversarial text sequences to evade deep learning classifiers",
            "venue": "CoRR, abs/1801.04354.",
            "year": 2018
        },
        {
            "authors": [
                "Hongyu Guo."
            ],
            "title": "Nonlinear mixup: Out-ofmanifold data augmentation for text classification",
            "venue": "AAAI.",
            "year": 2020
        },
        {
            "authors": [
                "Hongyu Guo",
                "Yongyi Mao",
                "Richong Zhang."
            ],
            "title": "Augmenting data with mixup for sentence classification: An empirical study",
            "venue": "CoRR, abs/1905.08941.",
            "year": 2019
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Kevin Gimpel."
            ],
            "title": "Bridging nonlinearities and stochastic regularizers with gaussian error linear units",
            "venue": "CoRR, abs/1606.08415.",
            "year": 2016
        },
        {
            "authors": [
                "Qiang Hu",
                "Yuejun Guo",
                "Maxime Cordy",
                "Xiaofei Xie",
                "Lei Ma",
                "Mike Papadakis",
                "Yves Le Traon"
            ],
            "title": "An empirical study on data distribution-aware test selection for deep learning enhancement",
            "year": 2022
        },
        {
            "authors": [
                "Yu Jiang",
                "Vivek Natarajan",
                "Xinlei Chen",
                "Marcus Rohrbach",
                "Dhruv Batra",
                "Devi Parikh"
            ],
            "title": "Pythia v0.1: the winning entry to the VQA challenge 2018",
            "year": 2018
        },
        {
            "authors": [
                "Di Jin",
                "Zhijing Jin",
                "Joey Tianyi Zhou",
                "Peter Szolovits."
            ],
            "title": "Is BERT really robust? natural language attack on text classification and entailment",
            "venue": "CoRR, abs/1907.11932.",
            "year": 2019
        },
        {
            "authors": [
                "Akbar Karimi",
                "Leonardo Rossi",
                "Andrea Prati."
            ],
            "title": "AEDA: an easier data augmentation technique for text classification",
            "venue": "CoRR, abs/2108.13230.",
            "year": 2021
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba."
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "Cite arxiv:1412.6980Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015.",
            "year": 2014
        },
        {
            "authors": [
                "Alex Krizhevsky",
                "Ilya Sutskever",
                "Geoffrey E Hinton."
            ],
            "title": "Imagenet classification with deep convolutional neural networks",
            "venue": "Advances in Neural Information Processing Systems, volume 25. Curran Associates, Inc.",
            "year": 2012
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Veselin Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "BART: denoising sequence-to-sequence pretraining for natural language",
            "year": 2019
        },
        {
            "authors": [
                "Jinfeng Li",
                "Shouling Ji",
                "Tianyu Du",
                "Bo Li",
                "Ting Wang."
            ],
            "title": "Textbugger: Generating adversarial text against real-world applications",
            "venue": "CoRR, abs/1812.05271.",
            "year": 2018
        },
        {
            "authors": [
                "Bill Yuchen Lin",
                "Ming Shen",
                "Yu Xing",
                "Pei Zhou",
                "Xiang Ren."
            ],
            "title": "Commongen: A constrained text generation dataset towards generative commonsense reasoning",
            "venue": "CoRR, abs/1911.03705.",
            "year": 2019
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized BERT pretraining approach",
            "venue": "CoRR, abs/1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Andrew L. Maas",
                "Raymond E. Daly",
                "Peter T. Pham",
                "Dan Huang",
                "Andrew Y. Ng",
                "Christopher Potts."
            ],
            "title": "Learning word vectors for sentiment analysis",
            "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Hu-",
            "year": 2011
        },
        {
            "authors": [
                "Leland McInnes",
                "John Healy",
                "James Melville"
            ],
            "title": "Umap: Uniform manifold approximation and projection for dimension reduction",
            "year": 2020
        },
        {
            "authors": [
                "John X. Morris",
                "Eli Lifland",
                "Jin Yong Yoo",
                "Jake Grigsby",
                "Di Jin",
                "Yanjun Qi"
            ],
            "title": "Textattack: A framework for adversarial attacks, data augmentation, and adversarial training in nlp",
            "year": 2020
        },
        {
            "authors": [
                "Md. Rizwan Parvez",
                "Tolga Bolukbasi",
                "Kai-Wei Chang",
                "Venkatesh Sarigrama."
            ],
            "title": "Building a robust text classifier on a test-time budget",
            "venue": "CoRR, abs/1808.08270.",
            "year": 2018
        },
        {
            "authors": [
                "Luis Perez",
                "Jason Wang."
            ],
            "title": "The effectiveness of data augmentation in image classification using deep learning",
            "venue": "CoRR, abs/1712.04621.",
            "year": 2017
        },
        {
            "authors": [
                "Yada Pruksachatkun",
                "Satyapriya Krishna",
                "Jwala Dhamala",
                "Rahul Gupta",
                "Kai-Wei Chang."
            ],
            "title": "Does robustness improve fairness? approaching fairness with word substitution robustness methods for text classification",
            "venue": "CoRR, abs/2106.10826.",
            "year": 2021
        },
        {
            "authors": [
                "Joaquin Qui\u00f1onero-Candela",
                "Masashi Sugiyama",
                "Anton Schwaighofer",
                "Neil D. Lawrence"
            ],
            "title": "When training and test sets are different: Characterizing learning transfer",
            "year": 2009
        },
        {
            "authors": [
                "Marco T\u00falio Ribeiro",
                "Tongshuang Wu",
                "Carlos Guestrin",
                "Sameer Singh."
            ],
            "title": "Beyond accuracy: Behavioral testing of nlp models with checklist",
            "venue": "ACL.",
            "year": 2020
        },
        {
            "authors": [
                "Connor Shorten",
                "T. Khoshgoftaar."
            ],
            "title": "A survey on image data augmentation for deep learning",
            "venue": "Journal of Big Data, 6:1\u201348.",
            "year": 2019
        },
        {
            "authors": [
                "Patrice Simard",
                "Yann LeCun",
                "John S. Denker",
                "Bernard Victorri."
            ],
            "title": "Transformation invariance in pattern recognition-tangent distance and tangent propagation",
            "venue": "Neural Networks: Tricks of the Trade, This Book is an Outgrowth of a 1996",
            "year": 1998
        },
        {
            "authors": [
                "Richard Socher",
                "Alex Perelygin",
                "Jean Wu",
                "Jason Chuang",
                "Christopher D. Manning",
                "Andrew Ng",
                "Christopher Potts."
            ],
            "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
            "venue": "Proceedings of the 2013 Conference on",
            "year": 2013
        },
        {
            "authors": [
                "Nitish Srivastava",
                "Geoffrey Hinton",
                "Alex Krizhevsky",
                "Ilya Sutskever",
                "Ruslan Salakhutdinov."
            ],
            "title": "Dropout: A simple way to prevent neural networks from overfitting",
            "venue": "Journal of Machine Learning Research, 15(56):1929\u20131958.",
            "year": 2014
        },
        {
            "authors": [
                "Mukund Sundararajan",
                "Ankur Taly",
                "Qiqi Yan."
            ],
            "title": "Axiomatic attribution for deep networks",
            "venue": "ArXiv, abs/1703.01365.",
            "year": 2017
        },
        {
            "authors": [
                "Alex Warstadt",
                "Amanpreet Singh",
                "Samuel R Bowman."
            ],
            "title": "Neural network acceptability judgments",
            "venue": "arXiv preprint arXiv:1805.12471.",
            "year": 2018
        },
        {
            "authors": [
                "Jason W. Wei",
                "Kai Zou."
            ],
            "title": "EDA: easy data augmentation techniques for boosting performance on text classification tasks",
            "venue": "CoRR, abs/1901.11196.",
            "year": 2019
        },
        {
            "authors": [
                "Qingsong Wen",
                "Liang Sun",
                "Xiaomin Song",
                "Jingkun Gao",
                "Xue Wang",
                "Huan Xu."
            ],
            "title": "Time series data augmentation for deep learning: A survey",
            "venue": "CoRR, abs/2002.12478.",
            "year": 2020
        },
        {
            "authors": [
                "Qizhe Xie",
                "Zihang Dai",
                "Eduard H. Hovy",
                "Minh-Thang Luong",
                "Quoc V. Le."
            ],
            "title": "Unsupervised data augmentation",
            "venue": "CoRR, abs/1904.12848.",
            "year": 2019
        },
        {
            "authors": [
                "Zhilin Yang",
                "Zihang Dai",
                "Yiming Yang",
                "Jaime G. Carbonell",
                "Ruslan Salakhutdinov",
                "Quoc V. Le."
            ],
            "title": "Xlnet: Generalized autoregressive pretraining for language understanding",
            "venue": "CoRR, abs/1906.08237.",
            "year": 2019
        },
        {
            "authors": [
                "Mao Ye",
                "Chengyue Gong",
                "Qiang Liu."
            ],
            "title": "SAFER: A structure-free approach for certified robustness to adversarial word substitutions",
            "venue": "CoRR, abs/2005.14424.",
            "year": 2020
        },
        {
            "authors": [
                "Sangdoo Yun",
                "Dongyoon Han",
                "Seong Joon Oh",
                "Sanghyuk Chun",
                "Junsuk Choe",
                "Youngjoon Yoo."
            ],
            "title": "Cutmix: Regularization strategy to train strong classifiers with localizable features",
            "venue": "CoRR, abs/1905.04899.",
            "year": 2019
        },
        {
            "authors": [
                "Hongyi Zhang",
                "Moustapha Ciss\u00e9",
                "Yann N. Dauphin",
                "David Lopez-Paz."
            ],
            "title": "mixup: Beyond empirical risk minimization",
            "venue": "CoRR, abs/1710.09412.",
            "year": 2017
        },
        {
            "authors": [
                "Jie M. Zhang",
                "Mark Harman",
                "Lei Ma",
                "Yang Liu."
            ],
            "title": "Machine learning testing: Survey, landscapes and horizons",
            "venue": "CoRR, abs/1906.10742.",
            "year": 2019
        },
        {
            "authors": [
                "Wei Emma Zhang",
                "Quan Z. Sheng",
                "Ahoud Alhazmi",
                "Chenliang Li."
            ],
            "title": "Adversarial attacks on deep-learning models in natural language processing: A survey",
            "venue": "ACM Trans. Intell. Syst. Technol., 11(3).",
            "year": 2020
        },
        {
            "authors": [
                "Xiang Zhang",
                "Junbo Jake Zhao",
                "Yann LeCun."
            ],
            "title": "Character-level convolutional networks for text classification",
            "venue": "CoRR, abs/1509.01626.",
            "year": 2015
        },
        {
            "authors": [
                "Zhun Zhong",
                "Liang Zheng",
                "Guoliang Kang",
                "Shaozi Li",
                "Yi Yang."
            ],
            "title": "Random erasing data augmentation",
            "venue": "CoRR, abs/1708.04896.",
            "year": 2017
        },
        {
            "authors": [
                "Jun-Yan Zhu",
                "Taesung Park",
                "Phillip Isola",
                "Alexei A. Efros."
            ],
            "title": "Unpaired image-to-image translation using cycle-consistent adversarial networks",
            "venue": "CoRR, abs/1703.10593.",
            "year": 2017
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Automatically generating new data is a critical component within modern machine learning pipelines. During training, data augmentation can expose models to a larger portion of potential input space, consistently leading to better generalization and performance (Simard et al., 1998; Krizhevsky et al., 2012; Perez and Wang, 2017). After training, creating effective test instances from existing data can expose specific model failure modes and provide actionable corrective feedback (Zhang et al., 2019; Ribeiro et al., 2020).\nWhile many techniques can artificially expand labeled training sets or test suites, nearly all of them\nare class-preserving. That is to say, the model outputs are invariant (INV) with respect to the transformations. This cautious constraint ensures the new data does not lie in an out-of-distribution null class which might impede the learning objective. However, it also requires more conservative transforms that inherently limit the degree of diversification.\nIn this work, we propose and extensively investigate the potential of sibylvariant (SIB) transformations that knowably vary the expected class. From the Greek sibyls, or oracles, the term parallels the oracle construction problem in software testing (Barr et al., 2015). In a nutshell, sibylvariants either fully transmute a datum from one class ci to another cj , or mix data from multiple classes together to derive a new input with a soft label that reflects the mixed membership. In this way, SIB can more strongly perturb and diversify the underlying distribution. Moreover, SIB makes possible a new type of adaptive training by synthesizing data from frequently confused class pairs, challenging the model to differentiate with greater refinement.\nIn the following sections, we position SIB within a broader conceptual framework for all data transforms (Section 2) and highlight several newly proposed techniques (Section 3). To support a comprehensive evaluation of how SIB may complement or even surpass its INV counterparts, we implemented 41 new and existing techniques into an open source tool called Sibyl. Equipped with the framework and tool, we evaluate 3 central research questions:\n\u2022 RQ1. Generalization Performance. Does training on SIB-augmented data improve model accuracy on the original test set?\n\u2022 RQ2. Defect Detection. For models trained on the original dataset, how effective are SIB tests at inducing misclassifications?\n\u2022 RQ3. Adversarial Robustness. Are models trained on SIB-augmented data more robust to existing adversarial attack algorithms?\nar X\niv :2\n20 5.\n05 13\n7v 1\n[ cs\n.C L\n] 1\n0 M\nay 2\n02 2\nOur comprehensive evaluation encompasses 6 text classification datasets, 11 transformation pipelines, and 3 different levels of data availability. In total, we trained 216 models and generated over 30 million new training inputs, 480,000 testing inputs, and 3,300 adversarial inputs. In the generalization study, SIB attained the highest accuracies in 89% (16 out of 18) of experimental configurations, with the adaptive mixture mutations being the most consistently effective. SIB also revealed the greatest number of model defects in 83% (5 out of 6) of the testing configurations. Lastly, of all the experimental configurations where adversarial robustness was improved over the no-transform baseline, 92% (11 out of 12) of them involved SIB. Overall, our findings strongly support the efficacy of sibylvariance for generalization performance, defect detection, and adversarial robustness.\nLastly, we describe how SIB may operate theoretically and discuss potential threats to validity (Section 5) before contrasting it with related work (Section 6). The source code for Sibyl and our experiments is available at: https://github. com/UCLA-SEAL/Sibyl."
        },
        {
            "heading": "2 Sibylvariance",
            "text": "All data transformations in the classification setting can be categorized into one of two types:\n\u2022 Invariant (INV) preserves existing labels. {TINV (Xi), yi} \u2192 {Xj , yi}\nwhere Xi 6= Xj (1)\nFor example, contracting \u201cWhat is the matter?\u201d to \u201cWhat\u2019s the matter?\u201dshould preserve a model behavior for sentiment analysis.\n\u2022 Sibylvariant (SIB) changes an existing label in a knowable manner.\nTSIB({Xi, yi})\u2192 {Xj , yj} where Xi 6= Xj and yi 6= yj .\n(2)\nSIB transforms both the input Xi to Xj and the output label from yi to yj label, corresponding to the new Xj ; such transformation is analogous to mutating an input and setting a corresponding oracle in metamorphic testing (Chen et al., 2020b). For example, performing a verb-targeted antonym substitution on \u201cI love pizza.\u201d to generate \u201cI hate pizza.\u201d has the effect of negating the original semantics and will knowably affect the outcome of binary sentiment analysis.\nIt is important to note that transformation functions are not inherently INV nor SIB. The same exact transformation may have a different effect on expected model behavior depending on the particular classification task. For example, random word insertions generally have an INV effect on topic classification tasks, but would be SIB with respect to grammaticality tasks (Warstadt et al., 2018)."
        },
        {
            "heading": "2.1 Sibylvariant Subtypes",
            "text": "SIB can be further refined based on the types and degree of semantic shift in newly generated data:\n\u2022 Transmutation changes one discrete kind into another, excluding the existing label, L\\{yi},\nTSIB({Xi, yi})\u2192 {Xj , yj} where Xi 6= Xj and yj \u2208 L\\{yi}.\n(3)\nCritically, the newly created data points retain stylistic and structural elements of the original that help boost diversity.\n\u2022 Mixture Mutation mixes inputs from multiple classes and interpolates the expected behavior into a mixed label distribution (i.e. soft label). Equivalently, we have:\nTSIB({Xi, yi})\u2192 {Xj , yj} where Xi 6= Xj and yj \u2208 |L|\u22c2 l \u03bbl (4)\nwhere the final term indicates a \u03bb-degree of membership in each label l belonging to the expected input space and is normalized as a probability distribution (i.e. \u2211 l \u03bbl = 1). For example, a document with topic \u2018surfing\u2019 can be combined with another document with topic \u2018machine learning\u2019 to yield a new label with probability mass placed on both topics. While mixture mutations may seem unnatural, the intuition is that humans can recognize mixed examples and adjust their predictions accordingly. Models ought to do the same."
        },
        {
            "heading": "2.2 Adaptive Sibylvariant Training",
            "text": "One unique and promising aspect of SIB is to target specific class pairings dynamically during training. In much the same way that a human teacher might periodically assess a students\u2019 understanding and alter their lesson plan accordingly, Sybil computes a confusion matrix and constructs more examples containing classes for which the model has the most difficulty differentiating. For example,\nif a topic model most frequently misclassifies \u2018science\u2019 articles as \u2018business,\u2019 adaptive SIB (denoted as \u03b1SIB) will generate new blended examples of those classes in every mini-batch until the next evaluation cycle. At that point, if the model confuses \u2018science\u2019 for \u201chealth,\u201d \u03b1SIB will construct new mixtures of those classes and so on. Sybil supports built-in runtime monitoring for \u03b1SIB training."
        },
        {
            "heading": "3 Transformations",
            "text": "In Sybil, we defined 18 new transforms and adapt 23 existing techniques from prior work (Ribeiro et al., 2020; Morris et al., 2020; Wei and Zou, 2019) to expand the coverage of SIB and INV text transformations. At a high level, Table 1 shows these 41 transforms organized into 8 categories: Mixture (i.e., blending text), Generative (i.e. concept-based text generation), Swap (e.g., substituting antonyms, synonyms, hypernyms, etc.), Negation (e.g., adding or removing negation), Punctuation (e.g., adding or removing punctuation), Text Insert (e.g., adding negative, neutral, or positive phrases), Typos (e.g. adding various typos), and Emojis (e.g. adding or removing positive or negative emoji). We highlight several signature transforms here and provide a more detailed listing in Appendix A.\nConcept2Sentence (C2S). C2S is a two step process: (1) extract a short list of key concepts from a document and (2) generate a new sentence that retains critical semantic content of the original while varying its surface form, style, and even subject matter. To accomplish this, we leveraged integrated gradients (Sundararajan et al., 2017; Pierse, 2021) to produce saliency attributions that identify the most relevant tokens for a given class label. We then generate a well-composed sentence from the extracted concepts using a pre-trained BART (Lewis et al., 2019) model fine-tuned on the CommonGen dataset (Lin et al., 2019).\nPrior to generation, it is possible to apply other transformations to the extracted concepts to encourage diversity or knowably alter the label. For example, on the left hand side of Figure 1 an antonym substitution produces a SIB effect by changing the extracted concepts from [\u2019stupid\u2019, \u2019worse\u2019] to [\u2019intelligent\u2019, \u2019better\u2019]. The new sentence exhibits a change in subject and style, but is correctly transmuted to have positive sentiment. C2S is thus an extremely promising transformation for diversifying text along both INV and SIB directions.\nTextMix, SentMix, and WordMix. Mixture mutations, like mixup (Zhang et al., 2017) and cutmix (Yun et al., 2019) from the image domain, take a batch of inputs and blend them together to form new inputs with an interpolated loss and they have shown robustness to adversarial attacks. TextMix translates this idea to the text domain by merging two inputs and interpolating a soft label according to the proportion of tokens belonging to the constituent classes. While TextMix does\na straightforward concatenation, SentMix shuffles the sentences and thus encourages long-range comprehension. WordMix concatenates and shuffles all words, encouraging keyword-to-topic understanding when sentence structure is compromised."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Transformation Pipelines & Datasets",
            "text": "To compare the potential of INV, SIB, and both (INVSIB) in aggregate, we construct a transformation pipeline (TP ) (Cubuk et al., 2019; Xie et al., 2019), where we uniformly sample n transformations of the selected kind to generate new {Xi, yi} pairs. We also create TP s that apply a single transform, TSINGLE, to highlight the efficacy of C2S, TextMix, SentMix, WordMix and their adaptive versions, prefixed with \u03b1. In total, we evaluate 11 TP s per dataset, shown in Table 2.\nDue to space limitations, we report the top performing TP of each kind using an asterisk (*). INV* represents the best from TINV and TC2S, while SIB* represents the best from TSIB and the mixture mutations. For RQ1, we also compare against TMix (Chen et al., 2020a), EDA (Wei and Zou, 2019), and AEDA (Karimi et al., 2021). TMix is a recent hidden-space mixture mutation for text, as opposed to Sybil\u2019s direct mixture mutation on the input space with greater transparency and examinability. EDA and AEDA are examples of recent INV transformations. Full results are available in the appendices.\nWe study six benchmarks for two kinds of NLP tasks: topic classification and sentiment analysis. Table 3 summarizes their relevant details. To simulate different levels of resource availability, we create three data subsets with by varying number of examples per class \u2014 10, 200, and 2500. These subsets were expanded 30\u00d7 via augmentation for each TP . In total, we generated 144 new datasets\n(144 = 6 benchmarks * 3 levels of data availability * 8 TP s which persist data. \u03b1SIB is runtime only.)"
        },
        {
            "heading": "4.2 Model Setting",
            "text": "We used a bert-base-uncased model (Devlin et al., 2018) with average pooling of encoder output, followed by a dropout layer (Srivastava et al., 2014) with probability 0.1, and a single linear layer with hidden size 768 and GELU (Hendrycks and Gimpel, 2016) activation. Maximum sentence length was set to 250. We use a batch size 16, an Adam optimizer (Kingma and Ba, 2014) with a linear warmup, a 0.1 weight decay, and compute accuracy every 2, 000 steps. All models were trained for 30 epochs on eight Nvidia RTX A6000 GPUs, with early stopping. In total, we constructed 198 different models.\nFor all TP s that produce a soft-label, we use a multi-class cross-entropy loss and computed performance via a weighted top-k accuracy,\nk\u2211 j \u03bbl \u00b7 1(yl = y\u0302j), (5)\nwhere \u03bbj is the degree of class membership, 1(\u00b7) is the indicator function, and yj and y\u0302j are the indices of the j-th largest predicted score for the ground truth label and predicted label, respectively."
        },
        {
            "heading": "4.3 RQ1. Generalization Performance",
            "text": "For RQ1, we explore how model accuracy on the original test set is influenced by training data augmented with INV and SIB transformations. Table 4 shows the results on six benchmarks with three levels of data availability.\nWe observe the most significant performance gains when training 10 examples per class \u2014accuracy is improved by 4.7% on average across all datasets and by a maximum of up to 15% for IMDB. Figure 2 shows that as the number of labeled training data increases, a dominant trend emerged \u2014TSIB always generalized better to unseen test data. In fact, the only kind of transformation to always outperform both TORG and TMix is SIB*. Figure 3 shows the performance delta between INV* and SIB* against the TORG baseline at 200 examples per class. For every dataset, either \u03b1SentMix or \u03b1TextMix is the best performing TP , while INV* actually leads to performance decreases for DBPedia, Yahoo! Answers, and IMDB.\nOne key reason that aided SIB in attaining strong performance is the use of adaptive training. On average, crafting new examples that target the\nmodel\u2019s primary confusions during training added approximately 1% to accuracy relative to mixing classes uniformly at random. This shows another unique benefit of sibylvariance that is not transferable to its INV counterparts.\nWhile our full scale experiments show a clear trend that SIB generally outperforms INV, we primarily evaluated TP s combining multiple transforms instead of assessing the efficacy of each in isolation. Initially, this was a logistical decision due to computational limitations. To investigate each transformation\u2019s effect individually, we conducted a small scale experiment training 756 models ((39 transformations + 3 \u03b1SIB) \u00d7 6 datasets \u00d7 3 runs)\non 10 examples per class with a 3\u00d7 augmentation multiplier. Based on this experiment, we then computed each transform\u2019s performance by averaging the accuracy change relative to a TORIG baseline across all datasets. Table 5 shows the top ten best performing transforms, six of which employ SIB techniques. These results expand support for the overall conclusion that sibylvariance represents an especially effective class of transformations for improving generalization performance.\nGeneralization Performance. Models trained upon SIB-augmented data attained the highest test set accuracy in 89% (16 out of 18) of experimental configurations, with the adaptive mixture mutations being the most consistently effective."
        },
        {
            "heading": "4.4 RQ2. Defect Detection",
            "text": "For RQ2, we assess how generating new tests with INV and SIB can expose defective model behavior. A single test is simply an {Xi, yi} pair and a test suite is a set of such tests. Defective behavior is misclassification, which is measured via a test suite\u2019s accuracy. For each dataset D, we select a high-performing BERT model trained only on the original dataset without any augmentation. Then for each of eight TP s (excluding \u03b1SIB relevant to training only), we create 100 test suites, each containing 100 randomly sampled tests. This yields a total of 480,000 tests. We then report an average accuracy for each D and TP pair.\nFigure 4 shows how defect detection is enabled by INV and SIB. With the exception of Yahoo! Answers, the models scored nearly perfect accuracy on TORIG; however, when the same models are tested using data generated with INV and SIB, they struggle to generalize. Test data synthesized with SIB can reveal most defects in these models, indicating the value of sibylvariance in constructing test oracles for ML models in the absence of\nexpensive human labeling and judgements. Tests which lie outside the expected input distribution are not likely to be fair nor actionable. Since SIB transforms generally perturb data more aggressively than INV ones, they likewise possess more potential for creating unreasonable, out-of-domain tests of model quality. However, the positive results in RQ1 may justify the use of SIB transformations as reasonable for testing. Had the newly transformed data truly belonged to a different distribution, model performance on the in-domain test set should have decreased as a result of dataset shift (Qui\u00f1onero-Candela et al., 2009; Hu et al., 2022). In fact, we observed the opposite as model performance was consistently improved. This suggests that SIB transforms yield data that is tenably indomain and therefore may complement INV transforms in exposing defective model behavior.\nWe theorize that the effectiveness of SIBgenerated tests comes from the expanded objectives it permits. For example, TTextMix assess whether the\nmodel can recognize which classes are present and to what degree. TSentMix does the same but further scrutinizes long-range comprehension by broadly distributing related topic sentences. Datasets with lengthy inputs are particularly vulnerable to transformations of this kind. Lastly, TWordMix forces the model to forgo reliance on text structure and evaluates keyword comprehension amidst noisy contexts. In contrast, most INV transformations involve minor changes \u2014 e.g. expand contractions \u2014 and test the aspect of language already well modeled from extensive pre-training. The INV C2S transform is an exception that drastically alters input and thus reveals more defects than other TINV pipelines.\nDefect Detection. Models tested with SIBtransformed data exhibited the greatest number of defects in 83% (5 out of 6) of experimental configurations."
        },
        {
            "heading": "4.5 RQ3. Adversarial Robustness",
            "text": "For RQ3, we assess whether models trained on INV or SIB are more resilient to adversarial attacks than models trained on an original data. An adversarial text input is typically obtained via semantic preserving (i.e. invariant) perturbations to legitimate examples in order to deteriorate the model performance. The changes are typically generated by ascending the gradient of the loss surface with respect to the original example and improving robustness to adversarial attacks is a necessary precondition for real-world NLP deployment.\nWe select three attack algorithms based on their popularity and effectiveness: (1) TextFooler (Jin et al., 2019), (2) DeepWordBug (Gao et al., 2018), and (3) TextBugger (Li et al., 2018), all as implemented in TextAttack (Morris et al., 2020). We focus on models trained with 10 examples per class because the largest changes in generalization performance are more likely to exhibit the clearest trend for adversarial robustness. For each of 11 models and 3 attacks, we randomly sample 100 inputs from the original data and perturb them to create a total of 3,300 adversarial examples.\nTable 6 shows that, of all the cases where adversarial robustness is improved over TORIG, 92% of them involve SIB. On average, SIB*-trained models improve robustness by 4%, while INV*-trained models sustain a 1% decrease. Topic classification is made more robust via training with augmented data. Consistently, T\u03b1-SentMix produces the most resilient models. For sentiment analysis, improved generalization performance enabled by SIB does not necessarily lead to improved robustness to existing adversarial attacks. The underlying sentiment models trained with augmented data improves generalization over TORIG by an average of 5%. However, counter-intuitively, the models are not more robust to the three attacks than TORIG and that Pearson correlation is -0.28 between accuracy and adversarial robustness. This finding motivates future work to investigate why there is a negative correlation and how to design SIB such that accuracy improvement also translates to corresponding adversarial robustness.\nAdversarial Robustness. Of all the experimental configurations where adversarial robustness was improved over the notransform baseline, 92% (11 out of 12) of them involved models trained on SIBaugmented data."
        },
        {
            "heading": "5 Discussion",
            "text": "How does sibylvariance help? The primary purpose of data transformations in ML is to diversify datasets in the neighborhood of existing points, a principle formalized as Vicinal Risk Minimization (VRM) (Chapelle et al., 2001). Synthetic examples can be drawn from a vicinal distribution to find similar but different points that enlarge the original data distribution. For instance, within image classification, it is common to define the vicinity of an image as the set of its random crops, axal reflections, and other label-preserving INV transforms. While VRM can expose ML models to more diverse input space and consequently reduce generalization errors, the neighborhoods created by INV are relatively restricted. This is due to the label-preserving constraint limiting the degree of perturbation freedom on the original data.\nSIB effectively expands the vicinity relation via transmutations and mixture mutations. Newly created data can claim full or mixed membership in target classes. To support our intuition, we vi-\nsualize the effects of various transformations on SST-2 (Socher et al., 2013). Figure 5 presents the UMAP-reduced (McInnes et al., 2020) [CLS] tokens produced by a BERT transformer for sentiment classification. Figure 5a shows that the classes are initially well separated and high performance can be obtained by selecting any separating surface between the two clusters. However, a more reasonable choice for the best boundary is one that exhibits the largest margin between classes \u2014 the very intuition behind Support Vector Machines (Cortes and Vapnik, 1995). Figure 5d suggests that a model trained on mixture mutations is likely to arrive at a boundary with the lowest loss. For example, in 5d, the augmented examples in green provide additional loss feedback from uncovered portions of the input space to encourage a decision boundary that maximizes the margin between class clusters. A similar expectation may hold for SIB in Figure 5c. However, the effects of INV transforms shown in Figure 5b do not appear to support such margin maximization.\nThreats to Validity. External threats to validity include the generalization of our results to model architectures dissimilar to BERT (i.e. bert-base-uncased). It is possible that larger autoencoder models like RoBERTa (Liu et al., 2019) and auto-regressive models like XLNet (Yang et al., 2019) may respond differently to SIB transformations. Secondly, while the framework of sibylvariance is applicable to all data types, we have only provided empirical results supporting their efficacy for text classification models. We leave the exploration of SIB applications to image, time series, and other domains to future work.\nInternal threats include how we derived mixed labels for generated text. We assumed that the critical semantics can be approximated via the ratio of words contributed by source text. This assumption may not account for other linguistic interaction and thus could lead to suboptimal labels. However, SIB did significantly improve upon the INV and the\nORIG baselines in the RQ1 generalization study, suggesting that the constructed soft labels still reflected useful semantics. This indirectly supports the validity of SIB-transformed data for testing in RQ2, although we acknowledge that additional caution is required for using any aggressively modified, synthetic data as a substitute for real data for the purpose of exposing defective model behavior."
        },
        {
            "heading": "6 Related Work",
            "text": "In this section, we broadly cover data transformations within and outside of the text domain because our proposed framework for sibylvariance is applicable to all classification contexts.\nData Augmentation. Effective data augmentation is a key factor enabling superior model performance on a wide range of tasks (Krizhevsky et al., 2012; Jiang et al., 2018; Xie et al., 2019). In many cases, practitioners leverage domain knowledge to reinforce critical invariances in the underlying data. In computer vision, for example, translation invariance is the idea that no matter where the objects of interest reside within an image, the model will still classify them correctly. Image translations and random crops encourage this more generalized conceptualization within the model (Simard et al., 1998) and all other transforms have a similar goal: reinforce a particular invariance that helps the learner perform well on future unseen data.\nNumerous techniques have been proposed to assist with this learning objective and thereby improve generalization. Random erasing (Zhong et al., 2017; Devries and Taylor, 2017) and noise injection (Wen et al., 2020; Xie et al., 2019) support invariance to occlusions and promote robust features. Interpolating (Bowyer et al., 2011) and extrapolating (DeVries and Taylor, 2017) nearest neighbors in the input / feature space reinforces a linear relationship between the newly created data and the supervision signal while reducing class imbalance. However, nearly all of these approaches, and many others (Shorten and Khoshgoftaar, 2019;\nFeng et al., 2021), are label-preserving and therefore limited in their capacity to induce deeper learning of invariant concepts.\nSibylvariant transforms enjoy several desirable aspects of INV transformations while mitigating their drawbacks. Similar to feature space functions (DeVries and Taylor, 2017), mixture mutations do not require significant domain knowledge. Like approaches that reduce dataset imbalance (Bowyer et al., 2011), SIB transforms can increase class representation through mixed membership or targeted transmutations that inherit diverse characteristics of the source inputs. In all cases, relaxing the labelpreserving constraint enables SIB functions to both complement and enhance the learning of critical invariances by further expanding the support of the dataset in new directions.\nAdversarial Attacks & Robustness. Adversarial attacks are a special class of INV transformations that simultaneously minimize perturbations to the input while maximizing the perception of change to a learner. This task is more difficult within the NLP domain due to the discrete nature of text, but several works (Alzantot et al., 2018; Zhang et al., 2020) have proven successful at inducing model errors. Real-world use of NLP requires resilience to such attacks and our work complements robust training (Parvez et al., 2018) and robust certification (Ye et al., 2020; Pruksachatkun et al., 2021) to produce more reliable models.\nEmerging Sibylvariant Transforms. Specific transformations designed to alter the expected class of an input have existed prior to this work (Zhang et al., 2017; Yun et al., 2019; Guo, 2020; Zhu et al., 2017), albeit primarily in the image domain and also in a more isolated, ad hoc fashion. Among our primary contributions is to propose a unifying name, framework, and taxonomy for this family of sibylvariant functions. Furthermore, most prior works introduce a single transformation and evaluate its efficacy on training alone. In contrast, we proposed several novel transformations, a new adaptive training routine, and evaluated the broader impacts of 41 INV and SIB transforms on training, defect detection, and robustness simultaneously.\nRecently published examples of SIB mixture mutations for text (Guo et al., 2019; Chen et al., 2020a) differ from ours in several important ways. Prior work operates exclusively within the hidden space inside specific models, which limits transferability between different algorithm types. All of our\ntransformations operate in the input space, which is both more general and more challenging because we have to contend with rules of grammar and style. However, this also provides greater transparency. Furthermore, because our overall approach samples from 41 different transformations, we are able to exercise a broader range of model behaviors. For example, SentMix is designed to encourage longrange understanding, while other transforms evoke their own specific objectives. Any individual transformation is inherently more limited, e.g. TMix can only encourage the model to behave linearly for borderline cases."
        },
        {
            "heading": "7 Conclusion",
            "text": "Inspired by metamorphic testing, we proposed the notion of sibylvariance to jointly transform both input and output class (Xi, yi) pairs in a knowable way. To explore the potential of sibylvariance, we define 18 new text transformations and adapt 23 existing transformations into an open source tool called Sybil. In particular, we define several types of mixture mutations and design a novel concept-based text transformation technique utilizing salience attribution and neural sentence generation. Across six benchmarks from two different NLP classification tasks, we systematically assess the effectiveness of INV and SIB for generalization performance, defect detection, and adversarial robustness. Our extensive evaluation shows that many SIB transforms, and especially the adaptive mixture mutations, are extremely effective. SIB achieves the highest training accuracy in 89% of the experimental configurations. When used for testing, SIB test suites reveal the greatest number of model defects in 5 out of 6 benchmarks. Finally, models trained on SIB-augmented data improve adversarial robustness 11\u00d7 more often than those trained on INV-augmented data."
        },
        {
            "heading": "Acknowledgements",
            "text": "This work is supported in part by National Science Foundations via grants CCF-2106420, CCF2106404, CNS-2106838, CCF-1764077, CHS1956322, CCF-1723773, ONR grant N00014-18-12037, Intel CAPA grant, Samsung, and a CISCO research contract. We would also like to thank Atharv Sakhala for early contributions to the Sybil project as well as Jason Teoh, Sidi Lu, Aaron Hatrick, Sean Gildersleeve, Hannah Pierce, and all the anonymous reviewers for their many helpful suggestions."
        },
        {
            "heading": "B Other Possible Text Transformations",
            "text": ""
        },
        {
            "heading": "C Sibylvariant Subtype Examples",
            "text": ""
        },
        {
            "heading": "D RQ1. Detailed Training Results",
            "text": ""
        },
        {
            "heading": "E RQ2. Detailed Defect Detection Results",
            "text": ""
        },
        {
            "heading": "F RQ3. Detailed Robustness Results",
            "text": ""
        }
    ],
    "title": "Sibylvariant Transformations for Robust Text Classification",
    "year": 2022
}