{
    "abstractText": "We present a novel reinforcement learning (RL) based task allocation and decentralized navigation algorithm for mobile robots in warehouse environments. Our approach is designed for scenarios in which multiple robots are used to perform various pick up and delivery tasks. We consider the problem of joint decentralized task allocation and navigation and present a two level approach to solve it. At the higher level, we solve the task allocation by formulating it in terms of Markov Decision Processes and choosing the appropriate rewards to minimize the Total Travel Delay (TTD). At the lower level, we use a decentralized navigation scheme based on ORCA that enables each robot to perform these tasks in an independent manner, and avoid collisions with other robots and dynamic obstacles. We combine these lower and upper levels by defining rewards for the higher level as the feedback from the lower level navigation algorithm. We perform extensive evaluation in complex warehouse layouts with large number of agents and highlight the benefits over state-of-the-art algorithms based on myopic pickup distance minimization and regret-based task selection. We observe improvement up to 14% in terms of task completion time and up-to 40% improvement in terms of computing collision-free trajectories for the robots.",
    "authors": [
        {
            "affiliations": [],
            "name": "Aakriti Agrawal"
        },
        {
            "affiliations": [],
            "name": "Senthil Hariharan"
        },
        {
            "affiliations": [],
            "name": "Amrit Singh Bedi"
        },
        {
            "affiliations": [],
            "name": "Dinesh Manocha"
        }
    ],
    "id": "SP:002b6ba12982fd1593af65267ce95dac2ce0eb19",
    "references": [
        {
            "authors": [
                "C.R. Weisbin",
                "G. Rodriguez"
            ],
            "title": "Nasa robotics research for planetary surface exploration",
            "venue": "IEEE Robotics & Automation Magazine, vol. 7, no. 4, pp. 25\u201334, 2000. 1",
            "year": 2000
        },
        {
            "authors": [
                "J.S. Jennings",
                "G. Whelan",
                "W.F. Evans"
            ],
            "title": "Cooperative search and rescue with a team of mobile robots",
            "venue": "1997 8th International Conference on Advanced Robotics. Proceedings. ICAR\u201997. IEEE, 1997, pp. 193\u2013200. 1",
            "year": 1997
        },
        {
            "authors": [
                "J. Tilley"
            ],
            "title": "Automation, robotics, and the factory of the future",
            "venue": "McKinsey. https://www. mckinsey. com/business-functions/operations/ourinsights/automation-robotics-and-the-factory-of-the-future, 2017. 1",
            "year": 2017
        },
        {
            "authors": [
                "M. Liu",
                "H. Ma",
                "J. Li",
                "S. Koenig"
            ],
            "title": "Task and path planning for multiagent pickup and delivery",
            "venue": "Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2019. 1",
            "year": 2019
        },
        {
            "authors": [
                "F. Xue",
                "H. Tang",
                "Q. Su",
                "T. Li"
            ],
            "title": "Task allocation of intelligent warehouse picking system based on multi-robot coalition",
            "venue": "KSII Transactions on Internet and Information Systems, vol. 13, no. 7, 2019. 1, 2",
            "year": 2019
        },
        {
            "authors": [
                "H. Ma",
                "J. Li",
                "T.K.S. Kumar",
                "S. Koenig"
            ],
            "title": "Lifelong multi-agent path finding for online pickup and delivery tasks",
            "venue": "2017. 1, 6",
            "year": 2017
        },
        {
            "authors": [
                "A. Khamis",
                "A. Elmogy",
                "F. Karray"
            ],
            "title": "Complex task allocation in mobile surveillance systems",
            "venue": "Journal of Intelligent and Robotic Systems, vol. 64, pp. 33\u201355, 10 2011. 1",
            "year": 2011
        },
        {
            "authors": [
                "M.B. Dias",
                "A. Stentz"
            ],
            "title": "A free market architecture for distributed control of a multirobot system",
            "venue": "2000. 1",
            "year": 2000
        },
        {
            "authors": [
                "M. Goldenberg",
                "A. Felner",
                "R. Stern",
                "G. Sharon",
                "N. Sturtevant",
                "R.C. Holte",
                "J. Schaeffer"
            ],
            "title": "Enhanced partial expansion a",
            "venue": "J. Artif. Int. Res., vol. 50, no. 1, p. 141\u2013187, May 2014. 1, 5",
            "year": 2014
        },
        {
            "authors": [
                "J. van den Berg",
                "S.J. Guy",
                "M. Lin",
                "D. Manocha"
            ],
            "title": "Reciprocal nbody collision avoidance",
            "venue": "Robotics Research. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011, pp. 3\u201319. 1, 2, 4",
            "year": 2011
        },
        {
            "authors": [
                "M. Phillips",
                "M. Likhachev"
            ],
            "title": "Sipp: Safe interval path planning for dynamic environments",
            "venue": "IEEE ICRA. IEEE, 2011, pp. 5628\u20135635. 1",
            "year": 2011
        },
        {
            "authors": [
                "G. Sharon",
                "R. Stern",
                "A. Felner",
                "N.R. Sturtevant"
            ],
            "title": "Conflict-based search for optimal multi-agent pathfinding",
            "venue": "Artificial Intelligence, vol. 219, pp. 40\u201366, 2015. [Online]. Available: https://www.sciencedirect. com/science/article/pii/S0004370214001386 1",
            "year": 2015
        },
        {
            "authors": [
                "S.H. Arul",
                "D. Manocha"
            ],
            "title": "V-rvo: Decentralized multi-agent collision avoidance using voronoi diagrams and reciprocal velocity obstacles",
            "venue": "2021. 1",
            "year": 2021
        },
        {
            "authors": [
                "R. Luna",
                "K.E. Bekris"
            ],
            "title": "Push and swap: Fast cooperative pathfinding with completeness guarantees",
            "venue": "IJCAI, 2011. 1",
            "year": 2011
        },
        {
            "authors": [
                "T. Schouwenaars",
                "B. De Moor",
                "E. Feron",
                "J. How"
            ],
            "title": "Mixed integer programming for multi-vehicle path planning",
            "venue": "2001 European Control Conference (ECC), 2001, pp. 2603\u20132608. 1",
            "year": 2001
        },
        {
            "authors": [
                "D. Mellinger",
                "A. Kushleyev",
                "V. Kumar"
            ],
            "title": "Mixed-integer quadratic program trajectory generation for heterogeneous quadrotor teams",
            "venue": "2012 IEEE International Conference on Robotics and Automation, 2012, pp. 477\u2013483. 1",
            "year": 2012
        },
        {
            "authors": [
                "P. Velagapudi",
                "K. Sycara",
                "P. Scerri"
            ],
            "title": "Decentralized prioritized planning in large multirobot teams",
            "venue": "2010 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2010, pp. 4603\u2013 4609. 1",
            "year": 2010
        },
        {
            "authors": [
                "L. Cohen",
                "T. Uras",
                "T.S. Kumar",
                "S. Koenig"
            ],
            "title": "Optimal and bounded-suboptimal multi-agent motion planning",
            "venue": "Twelfth Annual Symposium on Combinatorial Search, 2019. 1",
            "year": 2019
        },
        {
            "authors": [
                "D. Wilkie",
                "J. Van Den Berg",
                "D. Manocha"
            ],
            "title": "Generalized velocity obstacles",
            "venue": "2009 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2009, pp. 5573\u20135578. 1",
            "year": 2009
        },
        {
            "authors": [
                "J. Alonso-Mora",
                "A. Breitenmoser",
                "M. Rufli",
                "P. Beardsley",
                "R. Siegwart"
            ],
            "title": "Optimal reciprocal collision avoidance for multiple non-holonomic robots",
            "venue": "Distributed autonomous robotic systems. Springer, 2013, pp. 203\u2013216. 1",
            "year": 2013
        },
        {
            "authors": [
                "Z. Chen",
                "J. Alonso-Mora",
                "X. Bai",
                "D.D. Harabor",
                "P.J. Stuckey"
            ],
            "title": "Integrated task assignment and path planning for capacitated multiagent pickup and delivery",
            "venue": "IEEE Robotics and Automation Letters, vol. 6, no. 3, pp. 5816\u20135823, 2021. 1, 6",
            "year": 2021
        },
        {
            "authors": [
                "P. Fiorini",
                "Z. Shiller"
            ],
            "title": "Motion planning in dynamic environments using velocity obstacles",
            "venue": "The International Journal of Robotics Research, vol. 17, no. 7, pp. 760\u2013772, 1998. 2",
            "year": 1998
        },
        {
            "authors": [
                "J. van den Berg",
                "M. Lin",
                "D. Manocha"
            ],
            "title": "Reciprocal velocity obstacles for real-time multi-agent navigation",
            "venue": "2008 IEEE International Conference on Robotics and Automation, 2008, pp. 1928\u20131935. 2",
            "year": 2008
        },
        {
            "authors": [
                "J. Van Den Berg",
                "J. Snape",
                "S.J. Guy",
                "D. Manocha"
            ],
            "title": "Reciprocal collision avoidance with acceleration-velocity obstacles",
            "venue": "2011 IEEE International Conference on Robotics and Automation. IEEE, 2011, pp. 3475\u20133482. 2",
            "year": 2011
        },
        {
            "authors": [
                "J. Alonso-Mora",
                "A. Breitenmoser",
                "M. Rufli",
                "P. Beardsley",
                "R. Siegwart"
            ],
            "title": "Optimal Reciprocal Collision Avoidance for Multiple Non- Holonomic Robots",
            "year": 2013
        },
        {
            "authors": [
                "D. Zhou",
                "Z. Wang",
                "S. Bandyopadhyay",
                "M. Schwager"
            ],
            "title": "Fast, online collision avoidance for dynamic vehicles using buffered voronoi cells",
            "venue": "IEEE Robotics and Automation Letters, vol. 2, no. 2, pp. 1047\u2013 1054, 2017. 2",
            "year": 2017
        },
        {
            "authors": [
                "T. Fan",
                "P. Long",
                "W. Liu",
                "J. Pan"
            ],
            "title": "Distributed multi-robot collision avoidance via deep reinforcement learning for navigation in complex scenarios",
            "venue": "The International Journal of Robotics Research, 2020. 2",
            "year": 2020
        },
        {
            "authors": [
                "S.H. Semnani",
                "H. Liu",
                "M. Everett",
                "A. de Ruiter",
                "J.P. How"
            ],
            "title": "Multi-agent motion planning for dense and dynamic environments via deep reinforcement learning",
            "venue": "IEEE Robotics and Automation Letters, vol. 5, no. 2, pp. 3221\u20133226, 2020. 2",
            "year": 2020
        },
        {
            "authors": [
                "Q. Tan",
                "T. Fan",
                "J. Pan",
                "D. Manocha"
            ],
            "title": "Deepmnavigate: Deep reinforced multi-robot navigation unifying local & global collision avoidance",
            "venue": "2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2020, pp. 6952\u20136959. 2",
            "year": 2020
        },
        {
            "authors": [
                "M. Yousefikhoshbakht",
                "F. Didehvar",
                "F. Rahmati"
            ],
            "title": "Modification of the ant colony optimization for solving the multiple traveling salesman problem",
            "venue": "Romanian Journal of Information Science and Technology, vol. 16, no. 1, pp. 65\u201380, 2013. 2",
            "year": 2013
        },
        {
            "authors": [
                "J. Li",
                "Q. Sun",
                "M. Zhou",
                "X. Dai"
            ],
            "title": "A new multiple traveling salesman problem and its genetic algorithm-based solution",
            "venue": "2013 IEEE International Conference on Systems, Man, and Cybernetics, 2013, pp. 627\u2013632. 2",
            "year": 2013
        },
        {
            "authors": [
                "B.P. Gerkey",
                "M.J. Matari\u0107"
            ],
            "title": "A formal analysis and taxonomy of task allocation in multi-robot systems",
            "venue": "The International Journal of Robotics Research, vol. 23, no. 9, pp. 939\u2013954, 2004. [Online]. Available: https://doi.org/10.1177/0278364904045564 2",
            "year": 2004
        },
        {
            "authors": [
                "A. Khamis",
                "A. Hussein",
                "A. Elmogy"
            ],
            "title": "Multi-robot Task Allocation: A Review of the State-of-the-Art",
            "venue": "Cham: Springer International Publishing,",
            "year": 2015
        },
        {
            "authors": [
                "I. Tkach",
                "Y. Edan"
            ],
            "title": "Multi-agent Task Allocation",
            "venue": "Cham: Springer International Publishing,",
            "year": 2020
        },
        {
            "authors": [
                "N. Baras",
                "A. Chatzisavvas",
                "D. Ziouzios",
                "M. Dasygenis"
            ],
            "title": "Improving automatic warehouse throughput by optimizing task allocation and validating the algorithm in a developed simulation tool",
            "venue": "Automation, vol. 2, no. 3, pp. 116\u2013126, 2021. [Online]. Available: https://www.mdpi.com/2673-4052/2/3/7 2",
            "year": 2021
        },
        {
            "authors": [
                "M. Badreldin",
                "A. Hussein",
                "A. Khamis"
            ],
            "title": "A comparative study between optimization and market-based approaches to multi-robot task allocation.",
            "venue": "Advances in Artificial Intelligence",
            "year": 2013
        },
        {
            "authors": [
                "L. Brunet",
                "H.-L. Choi",
                "J. How"
            ],
            "title": "Consensus-based auction approaches for decentralized task assignment",
            "venue": "AIAA guidance, navigation and control conference and exhibit, 2008, p. 6839. 2",
            "year": 2008
        },
        {
            "authors": [
                "S. Choudhury",
                "J.K. Gupta",
                "M.J. Kochenderfer",
                "D. Sadigh",
                "J. Bohg"
            ],
            "title": "Dynamic multi-robot task allocation under uncertainty and temporal constraints",
            "venue": "Autonomous Robots, pp. 1\u201317, 2021. 2",
            "year": 2021
        },
        {
            "authors": [
                "S. Raja",
                "G. Habibi",
                "J.P. How"
            ],
            "title": "Communication-aware consensusbased decentralized task allocation in communication constrained environments",
            "venue": "IEEE Access, vol. 10, pp. 19 753\u201319 767, 2022. 2",
            "year": 2022
        },
        {
            "authors": [
                "Y. Chen",
                "U. Rosolia",
                "A.D. Ames"
            ],
            "title": "Decentralized task and path planning for multi-robot systems",
            "venue": "IEEE Robotics and Automation Letters, vol. 6, no. 3, pp. 4337\u20134344, 2021. 2",
            "year": 2021
        },
        {
            "authors": [
                "P. Ghassemi",
                "S. Chowdhury"
            ],
            "title": "Decentralized task allocation in multi-robot systems via bipartite graph matching augmented with fuzzy clustering",
            "venue": "International design engineering technical conferences and computers and information in engineering conference, vol. 51753. American Society of Mechanical Engineers, 2018, p. V02AT03A014. 2",
            "year": 2018
        },
        {
            "authors": [
                "L. Liu",
                "D.A. Shell"
            ],
            "title": "Optimal market-based multi-robot task allocation via strategic pricing.",
            "venue": "in Robotics: Science and Systems,",
            "year": 2013
        },
        {
            "authors": [
                "G.A. Korsah",
                "A. Stentz",
                "M.B. Dias"
            ],
            "title": "A comprehensive taxonomy for multi-robot task allocation",
            "venue": "The International Journal of Robotics Research, vol. 32, no. 12, pp. 1495\u20131512, 2013. 4",
            "year": 2013
        },
        {
            "authors": [
                "L. Wang",
                "Q. Cai",
                "Z. Yang",
                "Z. Wang"
            ],
            "title": "Neural policy gradient methods: Global optimality and rates of convergence",
            "venue": "CoRR, vol. abs/1909.01150, 2019. [Online]. Available: http://arxiv.org/abs/1909. 01150 5",
            "year": 1909
        },
        {
            "authors": [
                "A. Vaswani",
                "N. Shazeer",
                "N. Parmar",
                "J. Uszkoreit",
                "L. Jones",
                "A.N. Gomez",
                "\u0141. Kaiser",
                "I. Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "NeuRIPS, 2017. 5",
            "year": 2017
        },
        {
            "authors": [
                "L. Zhang",
                "T. Hu",
                "Y. Min",
                "G. Wu",
                "J. Zhang",
                "P. Feng",
                "P. Gong",
                "J. Ye"
            ],
            "title": "A taxi order dispatch model based on combinatorial optimization",
            "venue": "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD \u201917. New York, NY, USA: Association for Computing Machinery, 2017, p. 2151\u20132159. 6",
            "year": 2017
        },
        {
            "authors": [
                "F.A. Tillman",
                "T.M. Cain"
            ],
            "title": "An upperbound algorithm for the single and multiple terminal delivery problem",
            "venue": "Management Science, vol. 18, no. 11, pp. 664\u2013682, 1972. 6",
            "year": 1972
        },
        {
            "authors": [
                "S.K.X. Zheng",
                "C. Tovey",
                "R. Borie",
                "P. Kilby",
                "V. Markakis",
                "P. Keskinocak"
            ],
            "title": "Agent coordination with regret clearing",
            "venue": "AAAI, 2008. 6",
            "year": 2008
        },
        {
            "authors": [
                "R. Stern",
                "N. Sturtevant",
                "A. Felner",
                "S. Koenig",
                "H. Ma",
                "T. Walker",
                "J. Li",
                "D. Atzmon",
                "L. Cohen",
                "T. Kumar",
                "E. Boyarski",
                "R. Bart\u00e1k"
            ],
            "title": "Multiagent pathfinding: Definitions, variants, and benchmarks",
            "venue": "06 2019. 6",
            "year": 2019
        },
        {
            "authors": [
                "L. Cohen",
                "T. Uras",
                "S. Koenig"
            ],
            "title": "Feasibility study: Using highways for bounded-suboptimal multi-agent path finding",
            "venue": "Eighth Annual Symposium on Combinatorial Search, 2015. 6",
            "year": 2015
        },
        {
            "authors": [
                "H. Ma",
                "D. Harabor",
                "P.J. Stuckey",
                "J. Li",
                "S. Koenig"
            ],
            "title": "Searching with consistent prioritization for multi-agent path finding",
            "venue": "AAAI, vol. 33, no. 01, 2019, pp. 7643\u20137650. 6",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "I. INTRODUCTION Multiple robots are ubiquitous and are used to perform various tasks in different applications such as planetary exploration [1], search and rescue missions [2], and automated manufacturing [3]. Recently, there has been considerable interest in using robots for warehouse automation. These environments are based on large-scale fulfillment centers that organize inventory using several movable pods. The pods get transported by a team of robots to different picking stations, where each item gets picked by a human operator [4], [5].\nA key issue is designing a multi-robot decision making system that can improve the overall throughput and result in safe navigation of robots. The overall problem consists of two challenges for each robot: task allocation and navigation. The problem is challenging because these two parts are coupled with each other. The task allocation controls the starting and destination of the navigation part, and the navigation part decides the next tasks to be allocated. As large numbers of robots are deployed, another key challenge is collision-free path computation. Not only does each robot needs to avoid collisions with static obstacles and other moving robots in the scene, but it must also avoid any dynamic obstacles or humans moving in the environment.\nIn the existing literature, the problems of multi robot task allocation and multi robot navigation are assumed\n1University of Maryland, College Park, MD, USA {agrawal5,sarul1,amritbd,dmanocha}@umd.edu\n2This work was supported in part by ARO Grants W911NF1910069, W911NF2110026 and U.S. Army Cooperative Agreement W911NF2120076\nto be decoupled and solved separately [6]. The tasks are typically allocated based on greedy and auction based approaches [7], [8]. The navigation paths can be computed via different centralized or decentralized algorithm [9]\u2013[14]. In centralized navigation systems [11], [12], [15], [16], a single controller plans the path of all agents and instructs the agent in real time during execution. Agents, also need to provide feedback to the central controller in real time. This approach is regarded as more stable, provides better guarantees in terms of reaching the goal, avoids deadlock, and can handle narrow passages in the environment. However, a centralized system requires major investment in terms of a central control system, a communication system and a highly accurate navigation system. Furthermore, it creates a bottleneck [17]. A failure in terms of centralized computation could lead to complete system failure or small errors or miscommunication can lead to accidents, since the robots cannot make independent collision-free navigation decisions. Furthermore, these centralized techniques may not be able to handle unstructured environments with human co-workers or unknown obstacles. Some of the MAPF methods used in such warehouses generate piece-wise linear paths that involve \u201cstop and turn\u201d maneuvers, and this may not work well for non-holonomic agents [18].\nIn this work, our goal is to develop efficient methods that can utilize decentralized navigation schemes [10], as they can handle dynamic obstacles and unknown environments. These decentralized methods can scale to a large number of agents without using a centralized controller and perform local navigation to compute collision-free trajectories. Furthermore, they can be used for robots with car-like or nonholonomic constraints [19], [20]. Moreover, we would like to treat these two problems of task allocation and navigation as part of an overall coupled warehouse automation system [21] to improve the overall efficiency in terms of task completion time and navigation metrics.\nMain Results: We present a novel and coupled solution for multi-robot task allocation and decentralized navigation (DC-MRTA). In our coupled task-allocation formulation, tasks are allocated to the agents simultaneously during navigation. We use a reinforcement learning (RL)-based strategy that can be combined with state-of-the-art decentralized MAPF methods [10]. Our goal is to assign tasks in a manner that the total time taken to do nothing called total travel time (TTD) is minimized. It also further improves the (makespan). Our approach is general and does not make any assumptions about the environment or the number of robots or the tasks. The main novel results include:\nar X\niv :2\n20 9.\n02 86\n5v 1\n[ cs\n.R O\n] 7\nS ep\n2 02\n2\n\u2022 We propose a novel two level approach for the problem of joint decentralized task allocation and navigation in warehouse environments. We formulate the problem of decentralized multi-robot task allocation as a Markov Decision Processes and use a reinforcement learning (RL) based strategy to solve it, which can be combined with any decentralized navigation method.\n\u2022 We present a novel coupled architecture to solve the problem in a warehouse environment. Our architecture can handle variable number of robots and tasks, which is particularly important in decentralized navigation settings.\n\u2022 The rewards for the high level RL method are defined based on the feedback from the low-level navigation algorithm. In particular, we use total travel delay (TTD), which is generated from the decentralized navigation algorithm, as a reward to train the policy for task allocation. The trained policy can be easily combined with other decentralized methods like ORCA.\nWe perform extensive evaluations and compare against the state-of-the-art greedy baselines myopic pickup distance minimization (MPDM) and regret-based task-selection (RBTS). We test performance on different warehouse layouts with varying number of robots and show an improvement of up to 14% in terms of task completion time for 500 tasks. Our scales well with the number of agents and can handle thousands of agents. For dense scenarios, our approach also reduces the number of inter-agent collisions by 40%."
        },
        {
            "heading": "II. RELATED WORK",
            "text": ""
        },
        {
            "heading": "A. Multi-Robot Decentralized Navigation",
            "text": "Multi-robot navigation is a widely researched topic in robotics and related areas that involves the computation of collision-free paths for robots in a multi-agent setting. Centralized and decentralized methods are two categories of navigation algorithms that differ based on the decisionmaking entity and available knowledge of its environment.\nOur approach is based on decentralized planners, where the agents use the knowledge of their local environment to make independent navigation decisions. The agent\u2019s local information includes the position (and velocity) and the dimension information of their neighbors. Velocity Obstacles (VO) [22] presents an influential class of decentralized algorithms that compute a set of velocities that could result in a collision. RVO [23] improve upon VO by accounting for the agent\u2019s reactive behavior, thus reducing oscillations in trajectories. RVO was further posed as a linear convex optimization in ORCA [10] and extended to different agent dynamics [24], [25]. Buffered Voronoi Cell (BVC) [26] constructs retracted Voronoi cells to limit the agent\u2019s local motion to free space. In contrast to VO-based methods, BVC only uses the position information of its neighbors. Decentralized methods can be scaled to large number of agents, however it is difficult to guarantee optimality or deadlock-free navigation especially in obstacle rich environments or narrow passages. More recently, RL-based methods [27]\u2013[29] can also be used to\nimprove the collision avoidance performance and compute shorter time to goal. Our approach is general and can be combined with any of these decentralized schemes."
        },
        {
            "heading": "B. Multi-Robot Task Allocation (MRTA)",
            "text": "MRTA involves the opti9mal assignment of robots to tasks. It is a variant of the multiple Traveling Salesman Problem (mTSP), which is known to be NP-hard to solve optimally [30], [31]. Extensive surveys are available in [32]\u2013 [34]. Warehouse task allocation is studied as integer linear program in [5]. In [35], an optimal task allocation algorithm is proposed for heterogeneous agents. These methods, optimisation based, assume all agents are available at once for optimal matching.\nThus are two widely used approaches for solving these problems: (1) market-based approaches and (2) optimizationbased approaches for different environments [36]. Auctionbased approaches [37] (CBBA, CBAA), which are part of market-based approaches, have also been proposed for decentralized task allocation. These algorithms use local information to assign tasks and consensus to improve global objective. Variants of CBBA have been proposed [38] like deep-RL based communication aware variants [39] for environments with limited bandwidth. We use one regret based auction method in our baseline comparisons.\nThere is some work [40]\u2013[42] on decentralized taskallocation and navigation. [40] is a RL based method coupled with navigation but does not show scalability. [41] proposes a decentralised task-robot matching method based on bipartite graph. It performs task-clustering followed by maximal matching for task allocation. Overall its performance is about 7 \u2212 28% of the optimal cost obtained using centralized schemes. These decentralised methods have not been tested along with decentralised navigation algorithms, complex environments and large number of robots and tasks."
        },
        {
            "heading": "III. BACKGROUND AND PROBLEM FORMULATION",
            "text": "In this section, we give an overview of our problem of task allocation and navigation in complex, warehouse environments."
        },
        {
            "heading": "A. Decentralized Multi-Robot Task Allocation and Navigation",
            "text": "We consider a group of n holonomic, disk shaped robots operating in an environment W \u2282 R2. For any agent Ai, its geometry is represented by Ai. The agent\u2019s position is given by pi, and we consider our agents to be velocity (vi) controlled. Agents within a defined sensing radius of agent i are considered its neighbors, and are represented by the set Ni. We formulate a decentralized navigation problem where each robot makes independent decision to perform these tasks and avoid collisions with other agents and static/dynamic obstacles using the local environment knowledge. We assume each agent Ai knows its neighbors\u2019 positions, where neighbors are agents located within a certain radius of Ai. This information can be obtained using perception or communication modules. Overall, Agent Ai\nlocal knowledge includes pj ,vj j \u2208 Ni. Similarly, it has a representation of all the obstacles in the environment. We use the standard A* method to compute a path for each agent that avoids collisions with all the static obstacles.\nA task is represented by a tuple (oi,di) which includes the origin oi and destination di locations in the environment. The goal is to allocate a task to available agent i effectively. After the task assignment, the agent\u2019s goal is set as Gi = {oi,di}, as it represents the pickup and drop location. This is an important difference here from the standard decentralized navigation problems where there is no dependence of goal on another task allocation module. Instead the time taken by the navigation algorithm to compute a path also affects the performance of the task allocation scheme."
        },
        {
            "heading": "B. Metrics",
            "text": "Our goal is to design a scheme where we consider singletask robots which execute only a single task at any given time. We assume that all the tasks are single robot tasks and task assignment is instantaneous, where the task is instantaneously allocated at each decision timestep. Our approach is designed in terms of a sequential-lifelong solution, where new tasks are continuously generated and task is allocated to a robot as soon as it becomes available. We would like to maximize the sum of utilities over time, that is, assign tasks at each instant in such a way that the total time taken to execute a specific number of tasks makespan as well as TTD is minimized. TTD is defined as the time taken to travel from the current location of the robot pi to the starting location of the allocated task oi.\nGiven a specific task, our next step is to navigate the robot from their current position pi to oi, and then to di, while remaining collision-free. At any timestep, an agent Ai is said to be collision-free provided its geometry (Ai)\ndoes not overlap with its neighbors or static or dynamic obstacles. Assuming m obstacles in the environment, their geometries can be represented by Oj , j \u2208 1, 2, ...,m. The agent sequentially reaches the goals in the goal set (G) while avoiding collisions. That is, at each time step the agent moves towards its immediate goal (gi \u2208 Gi = {oi,di}). Our goal is to design navigation methods that tend to reduce or eliminate any collisions.\nmin \u2016gi\u2212pi\u2016 Ai \u2229 Aj = \u2205, \u2200j \u2208 Ni Ai \u2229 Oj = \u2205, \u2200j \u2208 {1, 2, ...,m}.\n(1)\nOn reaching the destination location (di), the task is considered to be complete and the agent is once again available to be allocated a task. We note that in problem (1), the objective \u2016gi \u2212 pi\u2016 is not fixed and depends upon the task allocation. Therefore, jointly solving the problem for optimal gi at each i, and then designing robot trajectories is difficult in practice."
        },
        {
            "heading": "IV. DC-MRTA: OUR TWO LEVEL COUPLED APPROACH",
            "text": "In this section, we present our approach to solve the joint problem in Equation (1) using a two level scheme. Our proposed solution is summarized in Fig. 1 and algorithm 1. On the higher level, we design a reinforcement learning based task allocation strategy, and on the lower level, a multi robot decentralized navigation algorithm (ORCA) is used. We describe both the levels next in detail."
        },
        {
            "heading": "A. Lower level:Decentralized Navigation",
            "text": "We first consider the case when gi fixed. We consider simple navigation schemes based on A* and also use Optimal Reciprocal Collision Avoidance (ORCA) algorithm to move the robot to that goal location with no inter-agent collisions.\nThe specification of gi actually comes from the higher level task allocation algorithm. Given n homogeneous, diskshaped agents with position pi, velocity vi, and radius ri, ORCA computes a suitable collision-free velocity to drive each agent towards their respective goal location gi, while avoiding collisions with other obstacles and agents.\nFor any two agents i, j, the V O\u03c4i|j is a set of relative velocities that can lead to collision within the time horizon \u03c4 . Geometrically, it is represented by\nV O\u03c4i|j = {v|\u2200t \u2208 [0, \u03c4 ], tv \u2208 D(pj \u2212 pi, ri + rj)}, (2)\nwhere, D(p, r) represents a disk with center p and radius r. Assuming the agent uses the velocities vopti and v opt j , the agents are collision bound if vopti \u2212 v opt j \u2208 V O\u03c4i|j . Let u be the closest point on the boundary of V O\u03c4i|j . Then, u provides the minimum change in relative velocity to avoid collision. Taking n as the outward normal at (vopti \u2212 v opt j ) + u, the set of collision-free velocities for agent i can be represented geometrically as a half-plane, given by\nORCA\u03c4i|j = {v|(v \u2212 (v opt i +\n1 2 u)) \u00b7 n \u2265 0}.\nA suitable velocity is chosen from the set ORCA\u03c4i|j by minimizing the distance with vprefi which is the agent\u2019s preferred velocity directed towards the goal.\nORCA uses these conservative constraints to provide collision avoidance guarantees [10]. For each neighboring agent, the ORCA constraint is represented as a half-plane (Equation 2). If there is a feasible solution to the linear programming formulation, that provides a sufficient condition. However, there may be no feasible solution, especially if there are dense scenarios with a large number of agents in close proximity or narrow passages. In other words, scenarios with high level of congestion can result in possible collisions. Our goal is to design a task-allocation scheme such that it tends to minimize congestion. As a result, we need to develop methods that can: \u2022 The task allocation procedure needs to choose appro-\npriate task positions, (di), for a robot such that it is not in close proximity to the other agents or result in congested scenarios. Another goal is to avoid deadlock scenarios where some agents can block other scenarios or multiple agents are in narrow passages. \u2022 The decentralized navigation scheme uses local information for collision avoidance with the agents and obstacles. The underlying scheme used to modify the velocity of each agent to avoid collisions is used to design the appropriate reward functions for our RL methods."
        },
        {
            "heading": "B. Higher Level: RL based Task Allocation",
            "text": "The problem of multi-robot task allocation is mainly solved via optimization methods in the existing literature [43]. Such methods won\u2019t work in our setting because we are working with decentralized navigation schemes and account for the criteria highlighted above. Since robots behave independently in the warehouse environment, they become\navailable at different time instances. This makes it hard to solve with existing optimization based approaches, especially we also take into account the constraints of the navigation scheme. Additionally, the number of robots and tasks is also not fixed a priori which further makes the problem more challenging. To address these issues, we formulate the problem as a reinforcement leaning based task allocation in warehouse environments. The RL formulation is non-trivial because it requires defining a Markov Decision Process (MDP) which includes the design of state spaces, action spaces, and rewards etc. We proceed next to describe this MDP in detail.\nAn MDP here is defined by a tupleM := (S,A, R, P, \u03b3), where state space S, action space A, and R(s, a) denotes the reward. Here P describes the transition probability matrix where Pa(s, s\u2032) is the probability of transition to state s\u2032 \u2208 S from state s \u2208 S after taking action a \u2208 A. In MDP, \u03b3 \u2208 (0, 1) denotes the discount factor. To solve the problem, we need to explicitly define the terms in MDP M. We denote time instance as t \u2208 N, M as number of robots given by R = {1, 2, \u00b7 \u00b7 \u00b7 ,M}. The task allocation flow is described as follows.\nAfter the task allocation at t, we remove the allocated task from the queue and a new task is added. Since we are looking at the joint task allocation and navigation problem, we assume for tractability that only one robot is available at any instance t. We take one step further from t to t + 1 as soon as a robot becomes available. Next, we define in detail the state space S, action space A, and reward R for the warehouse environment.\nState: Each task i \u2208 P is mathematically represented by a tuple (oi,di, ki, li), where oi is the origin of the task, di is the destination, ki denotes the distance between the selected robot\u2019s current position to oi, and li is the length (distance between oi and di) of the task. Each robot j \u2208 R is also represented by a tuple (pj , rj), where pj is position (X \u2212 Y coordinates) in the 2D map and rj is the time left to complete the allocated task (i.e., the task completion time). Let jsel denotes the available robot for task allocation. Then, the state s encapsulates the robots\u2019 positions, their task completion times, and the task list P , which consists of tuples (oi,di, ki, li) for all the tasks and the selected robot jsel. Collectively, we write the state s :={ (pj , rj)\u2200j\u2208R, (oi,di, ki, li)\u2200i\u2208P , jsel } and the collection of all possible states s constitutes the state space S. Action: An action a in the environment is used to select which task to execute from the list of N available tasks in the queue. We define a policy \u03c0 : S \u2192 D(A) (here D denotes the set of possible distributions defined over A) which takes the current state as input and outputs a distribution across the all possible actions a \u2208 A. Note that in our formulation, A constitutes the list of all available tasks from which we need to select a particular task for the selected robot jsel. During the training time, we select the action a \u223c \u03c0(\u00b7 \u00b7 \u00b7 | s) where \u03c0(\u00b7 | s) is the probability distribution across the tasks. During the test time, we select the action in a deterministic manner by choosing a task to accomplish with maximum\nprobability in \u03c0(\u00b7 | s). Further, it is important to choose the specific policy architecture for our approach. In the literature, common choices for policy is to define a deep neural network (DNN) [44] denoted as \u03c0\u03b8(\u00b7 | s), where \u03b8 corresponds to neural network weights. The design of policy architecture is important because it actually defines the space of policies over which we search for the optimal actions. One could try a simple NN architecture where we pass all the available robot information (locations, availability) to the network and train it. But unfortunately, such simple designs doesn\u2019t result in convergence and also not scalable with respect to number of robots and tasks. Hence, we carefully designed the architecture using attention based mechanisms [45] to make sure that policy network supports variable number of robots and tasks."
        },
        {
            "heading": "C. Coupling via Reward Design",
            "text": "Designing the reward signal for any RL problem is the most crucial part. This is because the reward function decides the behavior of the policy we are interested in. We could design the reward in multiple ways which would eventually decide whether there is any coupling between the lower level (navigation) and higher level (task allocation). One simple way to design a reward for the task allocation would be to just consider 0/1 reward (reward is zero if the task is accomplished, otherwise 1). This reward makes sense, but it completely decouples the task allocation from navigation algorithm trajectories. For instance, this reward would be agnostic to any collision which occurs during the robot navigation, as highlighted in Section IV(A).\nIn our approach, we use a more intelligent way to design rewards called coupled rewards, which utilizes information from navigation algorithm to design efficient task allocation policy. For instance, we define our reward as\nreward = \u22121 (Time(oi,pi)) , (3)\nwhere pi is the current location of the robot, and (Time(oi,pi)) evaluates the time a robot takes to travel from pi to oi. This is also known as Total Travel Delay (TTD) and we are interested in minimizing it. This is evaluated by navigating the robot in the environment via a lower level decentralized navigation algorithm and hence creates a coupling between lower and upper levels.\nState-Transitions: At current state st, we have a task list in queue P and one available robot (say i \u2208 R). At this state, we take action at according to a policy \u03c0(\u00b7 | st) that decides which task would be allocated to the free robot. The selected task is removed from the list, new task gets added to the list, and the robot becomes unavailable. Our algorithm will wait until next robot becomes available which would mark our new state st+1. Note that the state transitions do not happen at regular time intervals here.\nV. IMPLEMENTATION AND RESULTS\nIn this section, we describe the implementation of our network architecture and analyze its performance in different settings by varying the number of robots, task generation\nAlgorithm 1 Decentralised Task-Allocation and Navigation Let s := { (pj , rj)\u2200j\u2208R, (oi,di, ki, li)\u2200i\u2208P , jsel } be cur-\nrent state of the system. Each robot j \u2208 R is executing a task (oj ,dj) Robot\u2019s current position is denoted as pj . Let time be t while True do\nUpdate pj for all j \u2208 R by unit amount using ORCA. t\u2190 t+ 1 if Any pj == dj then\njsel \u2190 j (ojsel ,djsel)\u2190 MRTA(jsel, s)\nend if end while\nfunction MRTA(jsel, s) RL-policy takes state s as input and selects a task i \u2208 P as action. (ojsel ,djsel)\u2190 (oi,di) return (ojsel ,djsel) end function\nschemes, layouts and navigation schemes. During training, we have used two different planning or navigation techniques to compute the reward : direct navigation and A*. In the direct navigation approach, the Euclidean distance between the robot position and task origin is used to evaluate the cost at each instant t. Our A* navigation scheme takes into account the static obstacles in a scene and computes collision-free paths for the agents. As mentioned earlier Sec. IV(C), the negative of this calculated cost is defined as the reward in the environment and it also serves as a heuristic to reduce congestion. A. A*+ORCA:Decentralized Navigation\nOur task allocation runs on model trained only on A* for a specific layout as that accounts for the static obstacles and uses that information to choose the appropriate rewards. During testing, we also evaluated our method using a combination of A* and ORCA decentralised navigation algorithms along with direct navigation and A* navigation algorithms. In this case, the ORCA formulation tries to avoid collisions between the moving agents. In order to travel through static obstacles, we need a global navigation algorithm which can generate trajectory points between start and goal points. We use single agent A* [9] to find the shortest path between two locations that avoids the obstacles. That path is used as the initial guidance (or preferred velocity) for ORCA agent. It is modified to avoid collisions with other agents or dynamic obstacles.\nThe default parameters used in our implementation are radius is 1.5 unit, time-step is 0.25 seconds, max velocity is 2 units/sec."
        },
        {
            "heading": "B. Baselines",
            "text": "We compare our algorithm, DC-MRTA, with minimum pickup distance minimization (MPDM) and regret based task\nselection (RBTS) as our baselines. Both these baselines are used in prior literature.\n1) MPDM: algorithm chooses the task that is closest to the robot. It is optimal if there is only one robot in the system and the task utility equals the distance of the robot to the task start position [46]. MPDM is the one of the widely used baseline model used for comparison in the literature for decoupled task allocation and navigation [6].\n2) RBTS: We use a modified version of RBTS used in [21]. It is inspired from [47], [48]. For every task in the list, find the distance to the closest robot. Subtract the distance of the selected robot to each of these tasks with the previous quantity. Choose the task with the maximum value (i.e., the maximum regret).\nFor all our benchmarks, we run the test on a fixed task set by fixing the seed of the random number generator and report TTD values for them. We train our model on the Nvidia GeForce RTX 2080Ti GPU with 11GB of memory, for 5 different environments and batch size of 32. We run the training for 4 million iterations, which takes around 12 hours with our A* navigation algorithm. The network architecture is large and GPU usage during training is usually less than 5-10 %. Next, we describe the different experimental settings and results."
        },
        {
            "heading": "VI. EVALUATION",
            "text": ""
        },
        {
            "heading": "A. Experimental Setting",
            "text": "We generate tasks randomly in the environment using a designated method as explained below. We further explain the layout generation in detail, which we use for testing the proposed algorithm.\nTask and Layout Generation: To the best of our knowledge, real data sets are not available for the problem of multirobot task allocation and navigation. Mostly in literature, a synthetic procedure is used to generate data and then test the proposed algorithms [49]. In this work, we utilize the designated method for task generation (see [49] for further details on this method). The idea is to define different regions for pickup and delivery tasks and then generate random samples from them [50], [51]. For the layout generation, the authors in [49] describes publically available warehouse\nlayouts generated through Asprilo. Asprilo is an open source framework used to simulate automated warehouse scenarios [49]. We generate different layouts with varying the level of compactness for a specific size (see Fig. 2)."
        },
        {
            "heading": "B. Simple Navigation Schemes",
            "text": "We highlight the results in Table I for direct navigation and A* navigation, respectively. We use the layouts as shown in Fig 2 for this evaluation. In this setting, training and testing is performed on the same navigation algorithm i.e. direct and A*."
        },
        {
            "heading": "C. Navigation with Multi-Agent Collision Avoidance",
            "text": "We evaluate the performance of DC-MRTA on all the layouts in Fig. 2 and compare the performance for 10 and 100 robots summarized in II. We train on A* navigation algorithm and test on A*+ORCA (explained in section VA). The task queue length is 10 for all cases. As shown in Table II, DC-MRTA outperforms greedy (MPDM) as well as regret-based (RBTS) baselines for all layouts and navigation scenarios. We also see that for 100 agents improvement is lesser as compared to 10 agents. This is because crowding situation occurs more with 100 agents and our decentralised navigation scheme has to spend time to avoid obstacles. Thus it deviates from the time duration taught during training. But still it performs better than our baselines. We show visualisation of unallocated tasks left after 42.5 seconds for our method and MPDM baseline in Fig. 3."
        },
        {
            "heading": "D. Collision Values",
            "text": "We show number of inter-agent collisions with 10 agents using A* and A*+ORCA navigation methods."
        },
        {
            "heading": "E. Scalability",
            "text": "We show that DC-MRTA is scalable by performing experiments with up to 1000 robots. For direct navigation, we used a 300\u00d7300 grid layout with no obstacles. For A* we used a 256\u00d7256 grid size of layout C. The results are summarized in Table IV. We note that DC-MRTA outperforms the baselines even for higher number of robots and tasks."
        },
        {
            "heading": "VII. CONCLUSION, LIMITATIONS, AND FUTURE WORK",
            "text": "We present a novel approach for the problem of joint task allocation and decentralized multi-robot navigation in a complex warehouse environments. We propose a novel two level coupled approach approach, where lower level collision free decentralized navigation is combine with high level RL-based task allocation. The reward functions for the RL method are defined based on the feedback from the navigation method. We have evaluated our method on complex environments and obtain up to 14% improvement over prior methods in terms of task completion time. Our RL model can be combined with any decentralized method, and we highlight its benefits in terms of collision avoidance using ORCA.\nOur approach has some limitations. The decentralized schemes may not always result in optimal trajectories, or collision-free paths. Our formulation of coupled rewards can be further improved based on other feedback that takes into account agent density and congestion. Our approach is limited to homogeneous agents with simple dynamics and assume that all agents have precise information about the obstacles in the scene. There are many avenues for future work. We would like to evaluate other rewards functions that can help reduce the congestion or challenging configurations at runtime. We would like to further evaluate the performance, where the layout changes or there are dynamic, human-like obstacles. Another interesting future line of work we aim to explore is limited communication. This means that the agents in decentralised system even though cannot communicate with the central server, it can communicate with other surrounding agents. They will then take actions in coordination with the neighboring agents."
        }
    ],
    "title": "DC-MRTA: Decentralized Multi-Robot Task Allocation and Navigation in Complex Environments",
    "year": 2022
}