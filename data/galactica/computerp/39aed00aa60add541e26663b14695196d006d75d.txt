The success of automated medical image analysis depends on large-scale and expert-annotated training sets. Unsupervised domain adaptation (UDA) has been raised as a promising approach to alleviate the burden of labeled data collection. However, they generally operate under the closed-set adaptation setting assuming an identical label set between the source and target domains, which is over-restrictive in clinical practice where new classes commonly exist across datasets due to taxonomic inconsistency. While several methods have been presented to tackle both domain shifts and incoherent label sets, none of them take into account the common characteristics of the two issues and consider the learning dynamics along network training. In this work, we propose optimization trajectory distillation, a unified approach to address the two technical challenges from a new perspective. It exploits the lowrank nature of gradient space and devises a dual-stream distillation algorithm to regularize the learning dynamics of insufficiently annotated domain and classes with the external guidance obtained from reliable sources. Our approach resolves the issue of inadequate navigation along network optimization, which is the major obstacle in the taxonomy adaptive cross-domain adaptation scenario. We evaluate the proposed method extensively on several tasks towards various endpoints with clinical and open-world significance. The results demonstrate its effectiveness and improvements over previous methods. Code is available at https://github.com/camwew/TADA-MI. 1. conclusion In this paper, we study the taxonomy adaptive crossdomain adaptation paradigm, which allows incoherent label sets between source and target datasets. To jointly address the data distribution bias and category gap, we propose a unified framework which performs cross-domain and cross-class optimization trajectory distillation to calibrate the learning dynamics of insufficiently annotated domain and classes. Historical self-distillation is further devised to attain a well-generalizable solution via regulating gradient distributions. 
It indicates that by enforcing the similarity between the gradients w.r.t. novel and anchor classes, we could drive the model to reduce the empirical loss on novel classes along optimization and thereby attain a well-generalizable solution. 3. implementation details  3.1. nuclei segmentation and recognition  3.1.1 datasets and preprocessing Accurate detection, segmentation, and classification of nuclei serve as essential prerequisites for various clinical and research studies within the digital pathology field [23]. Inconsistent taxonomy for nuclei categorization is common across different institutes, which results in the unmatched label sets among datasets. In this regard, we use PanNuke [17] and Lizard [22] as the source and target dataset, respectively. PanNuke contains 481 visual fields cropped from whole-slide images along with 189,744 annotated nuclei. It follows a categorization schema where nuclei are divided into five classes, including neoplastic, non-neoplastic epithelial, inflammatory, connective, and dead cells. We discard the “dead” class as it does not exist in most image patches. To ensure the dataset has a uniform data distribution, we use all images from the breast tissue to formulate the source dataset. Lizard consists of 291 image regions with an average size of 1016×917 pixels from the colon tissue and annotates 495,179 nuclei. It adopts a categorization schema different to PanNuke that there are six classes in total, i.e., neutrophil, eosinophil, plasma, lymphocyte, epithelial, and connective cells. We use the Dpath subset as the target dataset. For preprocessing, all the visual fields with divergent size are randomly cropped into image patches of 128×128 pixels. CutMix [70] is used to augment the target dataset.TP,FP,FN are the true positive, false positive, and false negative detection predictions, respectively. (y, ŷ) represents the pair of ground truth and predicted segmentation mask. IoU is the intersection over union score. 3.2. cancer tissue phenotyping  3.2.1 datasets and preprocessing Identifying distinct tissue phenotypes is an essential step towards systematic profiling of the tumor microenvironment in pathological examination [31]. Previous works are mostly limited to the discrimination of two classes of tissue: tumor and stroma [41], while recent studies argue that recognizing more heterogeneous tissues brings clinical value [33]. We therefore propose to perform adaptation from a dataset with only two categories of tissue to another dataset with several novel classes. In particular, we select images of tumor and stroma tissue from the CRC-TP [31] to form the source dataset. CRC-TP contains 20 H&E-stained colorectal cancer (CRC) slides obtained from 20 different patients. Region-level tissue phenotype annotations are provided by expert pathologists. To ensure a unique category label can be assigned to each image, patches are extracted at 20× magnification with the size of 150×150 pixels. The patch-wise tissue phenotypes are decided based on the majority of their content. Kather [33] is then regarded as the target dataset. It consists of 5000 150 × 150 pathology image patches sampled from 10 anonymized CRC tissue slides. Other than tumor and stroma tissue, Kather includes six novel tissue types, i.e., complex stroma, immune cells, debris, normal mucosal glands, adipose tissue, background, and thus poses an 8-class classification problem. 3.2.2 network architectures and parameter settings For experiments, we employ ResNet-101 as the image encoder and thereupon add two classification heads on top to perform 2-class and 8-class discrimination, respectively. During training, cross-entropy loss and Adam optimizer with learning rate 1e − 4 are used to optimize the model with a batch size of 4. λ and κ are set to 10 and 100. 3.3. skin lesion diagnosis  3.3.1 datasets and preprocessing Automatic fine-grained skin lesion recognition remains a global challenge in dermatology. By taking a step further than the basic benign/malignant differentiation, identifying the specific subtypes of lesions demonstrates significant diagnostic value [58]. We hereby assign a benign/malignant discrimination dataset as the source domain, and a fine-grained multi-disease dataset as the target domain. HAM10000 is a dermatoscopic image dataset collected from different populations and modalities [59]. After preprocessing procedures including histogram correction, sample filtering, and center crop, 10015 dermatoscopic images with lesions of seven diagnostic categories in total are provided. It contains four subtypes of benign lesions (melanocytic nevi (NV), benign keratinocytic lesions (BKL), dermatofibromas (DF), and vascular lesions (VASC)) and three subtypes of malignant ones (melanomas (MEL), basal cell carcinomas (BCC), and actinic keratoses intraepithelial carcinomas (AKIEC)). We use the face subset with only coarse two-class annotations as the source domain and the lower extremity subset with fine-grained seven-class annotations as the target domain. All images are randomly cropped to the size of 160× 160 pixels before being forwarded to the network. 3.4. overall experiment settings For all experiments, we implement our method with Pytorch and conduct training on a NVIDIA GeForce RTX 3090 GPU with 24GB of memory. Gradient backpropagation is performed for each mini-batch using BackPACK [12]. Following previous works in UDA [7], each dataset is randomly split into 80%/20% as the training/test sets. For novel classes in the target dataset, we sample few (5/10) samples with corresponding labels to formulate the support set. The remaining target data is left unlabeled. Data augmentation techniques such as rotation and horizontal/vertical flip are employed during training. Please refer to the source code for more details. It is noted that although from the technical perspective, skin lesion diagnosis is a multi-class classification problem similar to cancer tissue phenotyping, they differ largely in the task context. Specifically, skin lesion diagnosis is more
like an object recognition task where its decision is dominated by the local attributes of lesions, while cancer tissue phenotyping relies on the global structure of the whole pathology images, instead of focusing on a salient object. 4. additional experiment results  4.1. visualization We provide additional qualitative results on the three benchmarks. The comparison results shown in Fig. 5 demonstrate the superiority of our method to detect each nucleus and delineate its boundary, as well as differentiating nuclei of various types with their detailed biological features. The t-SNE visualization in Fig. 6 shows that our method could discover the underlying embedding structures of various classes even with very limited labeled data. 4.2. results with more annotations In this section, we compare our method with previous state-of-the-art approaches for cross-domain adaptation
when more labeled samples are available in the target domain. The results for nuclei segmentation and recognition with 30 labeled target samples are shown in Table 5. The overall improvements of our method under this setting are consistent with previous experiment results. It validates the effectiveness of our method under different levels of support. 4.3. extended experiments on diverse tasks We further evaluate our method on two medical image tasks beyond pathology analysis and one general visual recognition task, where the medical image tasks include pneumonia screening in radiology and diabetic retinopathy grading in fundus photography. For radiology analysis, we adopt covid-kaggle [51] and Chest-Montreal [11] for TADA from normal/pneumonia coarse screening to finegrained pneumonia diagnosis. For fundus, DDR [37] and APTOS19 [32] are used to construct a TADA setting with two novel classes (grade level 3, 4). In these settings, distribution shifts exist across domains due to differences in image acquisition protocols among multiple cohorts. For general visual task, we adopt OfficeHome [61] and evaluate on “Artist” and “Real-world” domains. Experiments are conducted in 10-shot regime and the corresponding results are presented in Table 6. Through comparison with SOTA methods, the effectiveness and broader applicability of our
method are proved. 4.4. extended key component analysis In Table 7, we demonstrate the effectiveness of our method’s key components. It complements the ablation study performed in the main text from a cumulative perspective. From the results, we observe that all the proposed modules are beneficial for improving the cross-domain adaptation performance. In particular, the employment of the cross-class distillation module contributes to a significant performance gain for target-private classes. For instance, it attains 3.48% and 2.18% improvements in terms of mF1* and mPQ* under 10-shot scheme. It verifies the effectiveness of our method to perform optimization trajectory distillation across domains and classes towards strong model generalization. 4.5. extended hyperparameter sensitivity analysis We further analyze the choices of hyperparameters and their impacts on model performance in Fig. 7. We vary the values of K and T , which denote the volumes of memory bank employed in the cross-domain/class distillation and historical self-distillation modules. The choice of τ in Eq. (6) which coordinates the identification of principle subspace is also studied. The results indicate that the choices of those hyperparameters do not have a significant influence as long as they are set within reasonable intervals. Compared with them, the choices of λ in Eq. (8) and κ in Eq. (11) demonstrate more importance and are required to be carefully decided. 4.6. robustness to support sample selection To evaluate the robustness of our method against the randomness during few-shot sample selection, we run the experiments for 10 times with different sets of labeled samples
in the target domain. The averaged results are presented in Table 8. It demonstrates that our method consistently outperforms the competing approaches under diverse settings, which indicates its strong robustness.