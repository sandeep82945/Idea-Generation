{
    "abstractText": "Music Structure Analysis (MSA) consists of representing a song in sections (such as \u201cchorus\u201d, \u201cverse\u201d, \u201csolo\u201d etc), and can be seen as the retrieval of a simplified organization of the song. This work presents a new algorithm, called Convolutive Block-Matching (CBM) algorithm, devoted to MSA. In particular, the CBM algorithm is a dynamic programming algorithm, applying on autosimilarity matrices, a standard tool in MSA. In this work, autosimilarity matrices are computed from the feature representation of an audio signal, and time is sampled on the barscale. We study three different similarity functions for the computation of autosimilarity matrices. We report that the proposed algorithm achieves a level of performance competitive to that of supervised State-of-the-Art methods on 3 among 4 metrics, while being unsupervised.",
    "authors": [
        {
            "affiliations": [],
            "name": "Axel Marmoret"
        },
        {
            "affiliations": [],
            "name": "J\u00e9r\u00e9my E. Cohen"
        },
        {
            "affiliations": [],
            "name": "Fr\u00e9d\u00e9ric Bimbot"
        }
    ],
    "id": "SP:3ab874cac3264cffccf630ecda049e34c4c5dbf4",
    "references": [
        {
            "authors": [
                "J. Paulus",
                "M. M\u00fcller",
                "A. Klapuri"
            ],
            "title": "State of the art report: Audio-based music structure analysis",
            "venue": "International Society for Music Information Retrieval Conference (ISMIR), 2010, pp. 625\u2013636.",
            "year": 2010
        },
        {
            "authors": [
                "O. Nieto",
                "G.J. Mysore",
                "C.-I. Wang",
                "J.B. Smith",
                "J. Schl\u00fcter",
                "T. Grill",
                "B. McFee"
            ],
            "title": "Audio-based music structure analysis: Current trends, open challenges, and applications",
            "venue": "Transactions of the International Society for Music Information Retrieval, vol. 3, no. 1, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A. Marmoret",
                "J. Cohen",
                "F. Bimbot"
            ],
            "title": "as seg: module for computing and segmenting autosimilarity matrices",
            "venue": "2022. [Online]. Available: https://gitlab.inria.fr/amarmore/ autosimilarity segmentation",
            "year": 2022
        },
        {
            "authors": [
                "M. Goto",
                "H. Hashiguchi",
                "T. Nishimura",
                "R. Oka"
            ],
            "title": "RWC Music Database: Popular, Classical and Jazz Music Databases",
            "venue": "International Society for Music Information Retrieval Conference (ISMIR), 2002, pp. 287\u2013288.",
            "year": 2002
        },
        {
            "authors": [
                "J.B. Smith",
                "J.A. Burgoyne",
                "I. Fujinaga",
                "D. De Roure",
                "J.S. Downie"
            ],
            "title": "Design and creation of a large-scale database of structural annotations",
            "venue": "International Society for Music Information Retrieval Conference (ISMIR), 2011, pp. 555\u2013560.",
            "year": 2011
        },
        {
            "authors": [
                "J. Foote"
            ],
            "title": "Automatic audio segmentation using a measure of audio novelty",
            "venue": "IEEE International Conference on Multimedia and Expo. Proceedings Latest Advances in the Fast Changing World of Multimedia. IEEE, 2000, pp. 452\u2013455.",
            "year": 2000
        },
        {
            "authors": [
                "K. Jensen"
            ],
            "title": "Multiple scale music segmentation using rhythm, timbre, and harmony",
            "venue": "EURASIP Journal on Advances in Signal Processing, vol. 2007, pp. 1\u201311, 2006.",
            "year": 2007
        },
        {
            "authors": [
                "G. Sargent",
                "F. Bimbot",
                "E. Vincent"
            ],
            "title": "Estimating the structural segmentation of popular music pieces under regularity constraints",
            "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 25, no. 2, pp. 344\u2013358, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "B. McFee",
                "D. Ellis"
            ],
            "title": "Analyzing song structure with spectral clustering",
            "venue": "International Society for Music Information Retrieval Conference (ISMIR), 2014, pp. 405\u2013410.",
            "year": 2014
        },
        {
            "authors": [
                "J. Serra",
                "M. M\u00fcller",
                "P. Grosche",
                "J.L. Arcos"
            ],
            "title": "Unsupervised music structure annotation by time series structure features and segment similarity",
            "venue": "IEEE Transactions on Multimedia, vol. 16, no. 5, pp. 1229\u20131240, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "T. Grill",
                "J. Schl\u00fcter"
            ],
            "title": "Music boundary detection using neural networks on combined features and two-level annotations",
            "venue": "International Society for Music Information Retrieval Conference (ISMIR), 2015, pp. 531\u2013537.",
            "year": 2015
        },
        {
            "authors": [
                "M.C. McCallum"
            ],
            "title": "Unsupervised learning of deep features for music segmentation",
            "venue": "2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019, pp. 346\u2013350.",
            "year": 2019
        },
        {
            "authors": [
                "J.-C. Wang",
                "J.B. Smith",
                "W.-T. Lu",
                "X. Song"
            ],
            "title": "Supervised metric learning for music structure feature",
            "venue": "International Society for Music Information Retrieval Conference (ISMIR), 2021, pp. 730\u2013737.",
            "year": 2021
        },
        {
            "authors": [
                "J. Salamon",
                "O. Nieto",
                "N.J. Bryan"
            ],
            "title": "Deep embeddings and section fusion improve music segmentation",
            "venue": "International Society for Music Information Retrieval Conference (ISMIR), 2021, pp. 594\u2013601.",
            "year": 2021
        },
        {
            "authors": [
                "M. Mauch",
                "K.C. Noland",
                "S. Dixon"
            ],
            "title": "Using musical structure to enhance automatic chord transcription",
            "venue": "International Society for Music Information Retrieval Conference (ISMIR), 2009, pp. 231\u2013236.",
            "year": 2009
        },
        {
            "authors": [
                "M. Fuentes",
                "B. McFee",
                "H.C. Crayencour",
                "S. Essid",
                "J.P. Bello"
            ],
            "title": "A music structure informed downbeat tracking system using skip-chain conditional random fields and deep learning",
            "venue": "2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019, pp. 481\u2013485.",
            "year": 2019
        },
        {
            "authors": [
                "S. B\u00f6ck",
                "F. Korzeniowski",
                "J. Schl\u00fcter",
                "F. Krebs",
                "G. Widmer"
            ],
            "title": "Madmom: A new python audio and music signal processing library",
            "venue": "Proceedings of the 24th ACM international conference on Multimedia, 2016, pp. 1174\u20131178.",
            "year": 2016
        },
        {
            "authors": [
                "A. Marmoret",
                "J.E. Cohen",
                "F. Bimbot"
            ],
            "title": "Barwise compression schemes for audio-based music structure analysis",
            "venue": "19th Sound and Music Computing Conference, SMC 2022. Sound and music Computing network, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "B. McFee"
            ],
            "title": "librosa/librosa: 0.8.1rc2.",
            "venue": "Zenodo, May 2021. [Online]. Available:",
            "year": 2021
        },
        {
            "authors": [
                "R. Bellman"
            ],
            "title": "On the theory of dynamic programming",
            "venue": "Proceedings of the national Academy of Sciences, vol. 38, no. 8, pp. 716\u2013719, 1952.",
            "year": 1952
        },
        {
            "authors": [
                "T.H. Cormen",
                "C.E. Leiserson",
                "R.L. Rivest",
                "C. Stein"
            ],
            "title": "Introduction to algorithms, 3rd ed",
            "venue": "MIT press,",
            "year": 2009
        },
        {
            "authors": [
                "A. Marmoret",
                "J.E. Cohen",
                "N. Bertin",
                "F. Bimbot"
            ],
            "title": "Uncovering audio patterns in music with nonnegative tucker decomposition for structural segmentation",
            "venue": "International Society for Music Information Retrieval Conference (ISMIR), 2020, pp. 788\u2013794.",
            "year": 2020
        },
        {
            "authors": [
                "C. Raffel",
                "B. McFee",
                "E.J. Humphrey",
                "J. Salamon",
                "O. Nieto",
                "D. Liang",
                "D.P.W. Ellis",
                "Raffel"
            ],
            "title": "mir eval: A transparent implementation of common MIR metrics",
            "venue": "International Society for Music Information Retrieval Conference (ISMIR), 2014, pp. 367\u2013372.",
            "year": 2014
        },
        {
            "authors": [
                "O. Nieto",
                "J.P. Bello"
            ],
            "title": "Systematic exploration of computational music structure research",
            "venue": "International Society for Music Information Retrieval Conference (ISMIR), 2016, pp. 547\u2013553.",
            "year": 2016
        },
        {
            "authors": [
                "Y. Shiu",
                "H. Jeong",
                "C.-C.J. Kuo"
            ],
            "title": "Similarity matrix processing for music structure analysis",
            "venue": "Proceedings of the 1st ACM workshop on Audio and music computing multimedia, 2006, pp. 69\u201376.",
            "year": 2006
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014 Music Structure Analysis, Audio Signals, Barwise Music Processing"
        },
        {
            "heading": "1. INTRODUCTION",
            "text": "Citing Paulus et al. [1], \u201c[...] it is the structure, or the relationships between the sound events that create musical meaning\u201d. Following that statement, the Music Structure Analysis task (MSA) was developed, focusing on the retrieval of the structure in a song [2], which can be seen as retrieving a simplified description of the organization of a song at the macroscopic scale. In particular, this work focuses on a \u201cflat\u201d estimation, i.e. a single-level estimation, as opposed to a hierarchical level of structure. This paper specifically studies the subtask of structural segmentation of audio signals, consisting of estimating the boundaries between different sections, i.e. estimating the time instances which separate consecutive sections on the basis of an audio recording.\nThis task is generally solved focusing on one or several criteria among four: homogeneity, novelty, repetition and regularity [2]. The homogeneity criterion assumes that musical elements (notes, chords, tonality, timbre, ...) should be similar to constitute a section. Novelty is the counterpart of homogeneity, considering that boundaries must be placed between consecutive musical elements that are highly contrastive. Both are generally studied jointly. Repetition does not consider segments locally, but rather relies on a global approach of the song, to catch recurring motifs (for instance a melodic line). The rationale is that motifs, which may be individually heterogeneous, constitute segments when they are repeated. Finally, the regularity criterion assumes that, within a song, segments should be of comparable sizes.\n\u2217With the support of ANR JCJC LoRAiA ANR-20-CE23-0010.\nIn this article, we introduce a new algorithm to perform unsupervised music segmentation. Our contribution is the design of a (customizable) cost function which relies on homogeneity and regularity, which can be optimized using dynamic programming. This results in an efficient unsupervised segmentation technique1, as supported by a comparison with State-of-the-Art unsupervised and supervised methods. The algorithm is implemented in the open-source as seg toolbox [3].\nThis article is organized as follows: Section 2 presents the autosimilarity matrix, on which the CBM algorithm detailed in Section 3 is applied, and Section 4 presents experimental results, conducted on both RWC Pop and SALAMI datasets [4, 5]."
        },
        {
            "heading": "1.1. Related work",
            "text": "Music structure is frequently estimated using an \u201cautosimilarity matrix\u201d, presented in Section 2. In a nutshell, an autosimilarity matrix is a square matrix presenting the similarity between each pair of time instances in the song. For instance, the kernel of Foote [6] uses autosimilarity matrices, and exploits the homogeneity/novelty criteria, estimating boundaries as points of high dissimilarity between the recent past and the near future.\nJensen [7] developed an optimization problem minimizing the average self-dissimilarity (in an autosimilarity matrix) of each segment, as a way to account for the homogeneity of each segment. This optimization problem is solved by dynamic programming. Sargent et al. [8] later extended this optimization paradigm by adding prior knowledge on the segment sizes in the form of constraints.\nMcFee & Ellis [9] developed an algorithm based on spectral clustering, interpreting the repetition of musical content as principally connected vertices in a graph. The structure is then obtained by studying the eigenvectors of the Laplacian of this graph, forming cluster classes for segmentation.\nSerra\u0300 et al. [10] developed \u201cStructural Features\u201d, which, by design, encode both repetitive and homogeneous parts. The rationale of these features is to account for the musical content of several consecutive frames, then used to compute the similarity. Boundaries are obtained as points of high novelty between consecutive structural features.\nThe most recent techniques often make use of neural networks, e.g. [11, 12, 13, 14]. In particular, the work of Grill & Schlu\u0308ter [11], based on a Convolutional Neural Network (CNN) which directly\n1We acknowledge that the use of a learning-based toolbox for the bar estimation, as well as annotated examples to fit internal hyperparameters and draw hypotheses, constitute a form of supervision, that can be qualified as \u201cweak supervision\u201d.\nar X\niv :2\n21 0.\n15 35\n6v 3\n[ cs\n.S D\n] 2\n6 Se\np 20\n23\noutputs estimated boundaries, may be considered as State-of-theArt in the structural segmentation task. On the other hand, the other neural network-based techniques [12, 13, 14] develop deep embeddings on which are computed autosimilarity matrices, then postprocessed into estimated boundaries (using either the algorithm of Foote [6] or of McFee & Ellis [9])."
        },
        {
            "heading": "2. AUTOSIMILARITY MATRIX",
            "text": ""
        },
        {
            "heading": "2.1. Barwise TF matrix",
            "text": "We consider that bars are well suited to express patterns and sections in Western modern music (our case study). In particular, we assume that musical sections start and end on downbeats, which is experimentally confirmed by works such as [15, 16] where the use of structural information improves the estimation of downbeats. The direct consequence is the need for a powerful tool to estimate bars, in our case the madmom toolbox [17].\nThus, and following our previous work [18], we decide to represent music as barwise spectrograms, with a fixed number of time frames T per bar, set to T = 96. In practice, this article focuses on the Barwise TF matrix defined in [18], consisting of a matrix of size B\u00d7TF , B being the number of bars in the song (i.e. a dimension accounting for the barscale), and TF the vectorization of both time (at barscale) and frequency dimensions into a Time-Frequency dimension. Following the work of Grill & Schlu\u0308ter [11], in what follows the frequency dimension corresponds to the Log Mel feature (i.e. the logarithm of Mel coefficients) with F = 80, and are computed using the librosa toolbox [19]."
        },
        {
            "heading": "2.2. Similarity function",
            "text": "Given a Barwise TF matrix X \u2208 RB\u00d7TF , an autosimilarity of X is defined as a matrix A(X) \u2208 RB\u00d7B where each coefficient A(X)ij represents the similarity between two bars Xi and Xj \u2208 RTF , such that A(X)ij = s(Xi, Xj), subject to a similarity function s(). Three similarity functions are studied:\n- Cosine similarity, the normalized dot products between two\nvectors: scos(Xi, Xj) = \u27e8Xi,Xj\u27e9\n\u2225Xi\u22252\u2225Xj\u22252 .\n- Covariance similarity, the Cosine similarity of the centered matrix X , i.e. denoting as x\u0304 \u2208 RTF the average of all bars in the song: scov(Xi, Xj) =\n\u27e8Xi\u2212x\u0304,Xj\u2212x\u0304\u27e9 \u2225Xi\u2212x\u0304\u22252\u2225Xj\u2212x\u0304\u22252 .\n- The Radial Basis Function (RBF), a kernel function where\nsRBF (Xi, Xj) = exp ( \u2212\u03b3 \u2225\u2225\u2225 Xi\u2225Xi\u22252 \u2212 Xj\u2225Xj\u22252 \u2225\u2225\u222522 ) . Parameter \u03b3 is set relatively to the standard deviation of the pairwise Euclidean distances, i.e. denoting as\n\u03c3 = std 1<i,j<B,i\u0338=j (\u2225\u2225\u2225 Xi\u2225Xi\u22252 \u2212 Xj\u2225Xj\u22252 \u2225\u2225\u222522 ) , we set \u03b3 = 1 2\u03c3 .\nThese three autosimilarities are presented in Fig. 1. Note that the self-similarity of a vector is equal to one in these similarity functions, and corresponds to the main diagonal of the autosimilarity matrix."
        },
        {
            "heading": "3. CONVOLUTIVE \u201cBLOCK-MATCHING\u201d ALGORITHM",
            "text": "Formally, given a musical song sampled in time as B bars, structural segmentation can be defined as finding a set of boundaries\n(located on downbeats) Z representing the start of all segments, i.e. Z = {\u03b6i \u2208 J1, BK, i \u2208 J1, EK}, with E \u2264 B the number of estimated boundaries. The i-th segment Si is exactly the interval composed of the bars between two consecutive boundaries, i.e. Si = J\u03b6i, \u03b6i+1J.\nStarting from an autosimilarity matrix, structural segmentation is obtained using the Convolutive \u201cBlock-Matching\u201d segmentation algorithm (CBM). In a nutshell, the CBM algorithm is based on the definition of a score function u applied on segments, and the segmentation of the song results in the maximum total score of the segments, i.e. denoting as \u0398 the set of all possible segmentations:\nZ\u2217 = argmax Z\u2208\u0398 E\u22121\u2211 i=1 u(J\u03b6i, \u03b6i+1J). (1)"
        },
        {
            "heading": "3.1. Problem modeling",
            "text": "The optimization problem defined in (1) can be solved using dynamic programming [20]. In particular, following [7], by considering each bar as a vertex and each segment between two bars as an edge, a segmentation can be reinterpreted as a path in a Directed Acyclic Graph. By assigning the segment score as the length of the associated edge, the optimal segmentation can be reframed as the problem of finding the longest path in the graph. Precisely, the solution is computed as presented in the \u201cSingle-Source Shortest Paths in Directed Acyclic Graphs\u201d problem (for a critical path) [21, Chap. 24], as the graph is topologically sorted (due to the chronological order of bars in the song), and composed of a single vertex as origin (the first bar of the song)."
        },
        {
            "heading": "3.2. Score function",
            "text": "The score function in the CBM algorithm, defining the optimization problem to be solved, is inspired from the work of Sargent et al. [8], which extended the score function of Jensen [7] in order to take into account both the homogeneity and the regularity criteria. For a segment Si of size n, this results in a mixed score function:\nu(Si) = u K(Si)\u2212 \u03bbp(n). (2)\nIn details, (2) is the weighted sum of two terms: uK(Si), evaluating the homogeneity of the segment using convolution kernels (Section 3.2.1), and p(n), a penalization term related to the regularity of the segment (Section 3.2.2). Parameter \u03bb is a weighting parameter, fitted during the experiments.\n3.2.1. Convolution kernels\nGiven an autosimilarity matrix A(X), the convolution score uK(Si) of segment Si is computed by evaluating the autosimilar-\nity values restricted to that segment, denoted as ASi(X), and represents (to some extent) the inner similarity of this segment. In practice, this is obtained by weighting the different values in the autosimilarity, in a convolution operation between the autosimilarity and a (fixed) \u201cconvolution\u201d kernel matrix K of the size of the segment, such as:\nuK(Si) = 1\n\u03bd n n\u2211 k=1 n\u2211 l=1 ASi(X)klKkl. (3)\nThe convolution is normalized by the size of the segment n, and by a parameter \u03bd, scaled on the convolution values in this particular song. Parameter \u03bd is set as the maximal convolution value obtained by sliding a kernel of size 8 on this autosimilarity, i.e. the highest score among all possible segments of size 8.\nIn the CBM algorithm, the design of the convolution kernel defines how to transform bar similarities into segment homogeneity, which is of particular importance. A very simple kernel is a kernel matrix full of ones, i.e. K = 1n\u00d7n, resulting in the sum of all the values in the autosimilarity. Still, we consider that the main diagonal in the autosimilarity is not informative regarding the overall similarity in the segment, as its values are normalized to one, thus Kii = 0, \u2200i. Hereafter are presented two ways for designing kernels.\nFull kernel: The first kernel is called the full kernel, and corresponds to a matrix full of 1 (except on the diagonal where it is equal to 0). The full kernel captures the average value of similarities in this segment (without the self-similarity values). Practically,\ndenoting as Kf the full kernel, Kfij = { 1 if i \u0338= j 0 if i = j .\nBand kernel: The second kernel design, called band kernel, emphasizes on short-term similarity: the score is computed on a few bars in the segment only, depending on their temporal proximity (only the closest bars are considered). In practice, this is obtained by setting every entry to 0, except for some upper- and sub-diagonals, where they are set to 1. The number of upper- and sub-diagonals is a parameter, corresponding to the maximal number of neighbouring bars considered to evaluate the similarity. Denoting as v the number of bands, the v-band kernel Kvb is defined as:\nKvbij = { 1 if 1 \u2264 |i\u2212 j| \u2264 v 0 if i = j or |i\u2212 j| > v .\nFig. 2 presents the full, 3-band and 7-band kernels of size 10.\n3.2.2. Penalty function\nThe regularity function is based on prior knowledge, and aims at enforcing particular sizes of segments, which are known to be common in a number of music genres, notably Western modern music. In particular, as presented in [8, 18], some sizes of segments are most common in the annotations. In particular, in the SALAMI dataset [5], as presented in Fig. 3, most segments are of size 8,\nand the remaining segments are generally of size 4, 12 or 16. Finally, even segments are more common than segments of odd sizes. Hence, the regularity function models this distribution, as:\np(n) =  0 if n = 8 1 4 else if n \u2261 0 (mod 4) 1 2\nelse if n \u2261 0 (mod 2) 1 otherwise\n(4)"
        },
        {
            "heading": "4. EXPERIMENTS",
            "text": "The CBM algorithm being a segmentation algorithm, it is evaluated on the structural segmentation task on both RWC Pop and SALAMI datasets [4, 5]. The SALAMI dataset is restricted to the test subset defined in [11]. The remainder of the dataset is used to fix parameter \u03bb, in a learning scheme. On the RWC Pop dataset, \u03bb is fitted in a 2- fold cross-validation scheme, by splitting the dataset in two subsets: songs with odd vs. even numbers, as in [22]. For both datasets, parameter \u03bb takes its values between 0.1 and 2, with a step of 0.1.\nWe evaluate the algorithm on the Hit-Rate metrics, comparing a set of estimated boundaries with a set of annotations. In particular, an estimated boundary \u03b6ei \u2208 Ze is considered to be correct if it is close (with respect to a tolerance t) to an annotated boundary \u03b6aj \u2208 Za, i.e. |\u03b6ei \u2212 \u03b6aj | \u2264 t. Tolerances are set to 0.5s and 3s, following the standards in MSA [2]. The segmentation is finally evaluated with Precision, Recall and F-measure, computed using the mir eval toolbox [23]. Only F-measures are shown here (F0.5s and F3s).\nThe autosimilarity matrices are computed with the three similarity functions (Cosine, Covariance and RBF), and computed with the full, 3-band, 7-band and 15-band kernels. Segmentation results are presented in Fig. 4 and Fig. 5 for the RWC Pop and SALAMI datasets respectively.\nThese results exhibit a clear advantage of using the Covariance and RBF similarity functions compared to the Cosine similarity function. The best results on both datasets are obtained with the RBF similarity function. The design of the kernel is also largely impacting the segmentation results. In these experiments, the 7- band and the 15-band are respectively the best-performing kernels on the RWC Pop and SALAMI datasets.\nFig. 6 and Fig. 7 compare the best results obtained with the CBM algorithm with those of the State-of-the-Art algorithms. In this comparison, the CBM algorithm largely outperforms the other unsupervised segmentation methods, most of the supervised algorithms, and is competitive with the global (supervised) State-of-theArt [11]. These results are promising and show the potential of the CBM algorithm, which is performing well despite its relative simplicity.\nAll State-of-the-Art algorithms use beat-aligned features, except [11] which uses a fixed hop length and [13] which uses downbeat-aligned features. In details, results for [6, 9, 10] are computed with the MSAF toolbox [24], and realigned on downbeats in\npost-processing. Results for the CNN [11] are extracted from the 2015 MIREX contest. Results for [12, 13, 14] are obtained from the articles themselves."
        },
        {
            "heading": "5. CONCLUSIONS",
            "text": "This article has presented different autosimilarity matrices, computed at the barscale, hence studying several distinctive ways to represent similarities between pairs of bars in a song. These autosimilarities are then processed by the CBM algorithm, estimating boundaries between structural sections.\nThe CBM algorithm achieves levels of performance outperforming the current unsupervised State-of-the-Art [6, 9, 10, 12] and comparable to those of the global (supervised) State-of-theArt [11].\nOverall, the design of the kernel strongly impacts the segmentation results. Hence, future work could focus on studying alternative\ntypes of kernels, for example using normalized values in the kernel (as in [25]) and normalizing the score associated with each kernel by the number of nonzero values instead of the size of the kernel.\nConvolution kernels studied in this article focus on the homogeneity of each segment, but different kernels could be considered in order to account for the repetition criterion, e.g. those of Shiu et al. [25]. The kernel values could depend on the particular song or dataset considered. Of particular interest could be the learning of such kernels instead of an (empirical) definition.\nPenalty values for the different cases were set quite empirically, and would benefit from further investigations.\nThis work opens new paths towards future progress in structural segmentation methods, for which we hope that the open-source as seg toolbox [3] provided with this work2 will contribute.\n2https://gitlab.inria.fr/amarmore/autosimilarity segmentation//tree/WASPAA23"
        },
        {
            "heading": "6. REFERENCES",
            "text": "[1] J. Paulus, M. Mu\u0308ller, and A. Klapuri, \u201cState of the art report: Audio-based music structure analysis,\u201d in International Society for Music Information Retrieval Conference (ISMIR), 2010, pp. 625\u2013636.\n[2] O. Nieto, G. J. Mysore, C.-I. Wang, J. B. Smith, J. Schlu\u0308ter, T. Grill, and B. McFee, \u201cAudio-based music structure analysis: Current trends, open challenges, and applications,\u201d Transactions of the International Society for Music Information Retrieval, vol. 3, no. 1, 2020.\n[3] A. Marmoret, J. Cohen, and F. Bimbot, \u201cas seg: module for computing and segmenting autosimilarity matrices,\u201d 2022. [Online]. Available: https://gitlab.inria.fr/amarmore/ autosimilarity segmentation\n[4] M. Goto, H. Hashiguchi, T. Nishimura, and R. Oka, \u201cRWC Music Database: Popular, Classical and Jazz Music Databases,\u201d in International Society for Music Information Retrieval Conference (ISMIR), 2002, pp. 287\u2013288.\n[5] J. B. Smith, J. A. Burgoyne, I. Fujinaga, D. De Roure, and J. S. Downie, \u201cDesign and creation of a large-scale database of structural annotations,\u201d in International Society for Music Information Retrieval Conference (ISMIR), 2011, pp. 555\u2013560.\n[6] J. Foote, \u201cAutomatic audio segmentation using a measure of audio novelty,\u201d in IEEE International Conference on Multimedia and Expo. Proceedings Latest Advances in the Fast Changing World of Multimedia. IEEE, 2000, pp. 452\u2013455.\n[7] K. Jensen, \u201cMultiple scale music segmentation using rhythm, timbre, and harmony,\u201d EURASIP Journal on Advances in Signal Processing, vol. 2007, pp. 1\u201311, 2006.\n[8] G. Sargent, F. Bimbot, and E. Vincent, \u201cEstimating the structural segmentation of popular music pieces under regularity constraints,\u201d IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 25, no. 2, pp. 344\u2013358, 2016.\n[9] B. McFee and D. Ellis, \u201cAnalyzing song structure with spectral clustering,\u201d in International Society for Music Information Retrieval Conference (ISMIR), 2014, pp. 405\u2013410.\n[10] J. Serra, M. Mu\u0308ller, P. Grosche, and J. L. Arcos, \u201cUnsupervised music structure annotation by time series structure features and segment similarity,\u201d IEEE Transactions on Multimedia, vol. 16, no. 5, pp. 1229\u20131240, 2014.\n[11] T. Grill and J. Schlu\u0308ter, \u201cMusic boundary detection using neural networks on combined features and two-level annotations,\u201d in International Society for Music Information Retrieval Conference (ISMIR), 2015, pp. 531\u2013537.\n[12] M. C. McCallum, \u201cUnsupervised learning of deep features for music segmentation,\u201d in 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019, pp. 346\u2013350.\n[13] J.-C. Wang, J. B. Smith, W.-T. Lu, and X. Song, \u201cSupervised metric learning for music structure feature,\u201d in International Society for Music Information Retrieval Conference (ISMIR), 2021, pp. 730\u2013737.\n[14] J. Salamon, O. Nieto, and N. J. Bryan, \u201cDeep embeddings and section fusion improve music segmentation,\u201d in International Society for Music Information Retrieval Conference (ISMIR), 2021, pp. 594\u2013601.\n[15] M. Mauch, K. C. Noland, and S. Dixon, \u201cUsing musical structure to enhance automatic chord transcription,\u201d in International Society for Music Information Retrieval Conference (ISMIR), 2009, pp. 231\u2013236.\n[16] M. Fuentes, B. McFee, H. C. Crayencour, S. Essid, and J. P. Bello, \u201cA music structure informed downbeat tracking system using skip-chain conditional random fields and deep learning,\u201d in 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019, pp. 481\u2013485.\n[17] S. Bo\u0308ck, F. Korzeniowski, J. Schlu\u0308ter, F. Krebs, and G. Widmer, \u201cMadmom: A new python audio and music signal processing library,\u201d in Proceedings of the 24th ACM international conference on Multimedia, 2016, pp. 1174\u20131178.\n[18] A. Marmoret, J. E. Cohen, and F. Bimbot, \u201cBarwise compression schemes for audio-based music structure analysis,\u201d in 19th Sound and Music Computing Conference, SMC 2022. Sound and music Computing network, 2022.\n[19] B. McFee et al., \u201clibrosa/librosa: 0.8.1rc2.\u201d Zenodo, May 2021. [Online]. Available: https://doi.org/10.5281/zenodo. 4792298\n[20] R. Bellman, \u201cOn the theory of dynamic programming,\u201d Proceedings of the national Academy of Sciences, vol. 38, no. 8, pp. 716\u2013719, 1952.\n[21] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction to algorithms, 3rd ed. MIT press, 2009.\n[22] A. Marmoret, J. E. Cohen, N. Bertin, and F. Bimbot, \u201cUncovering audio patterns in music with nonnegative tucker decomposition for structural segmentation,\u201d in International Society for Music Information Retrieval Conference (ISMIR), 2020, pp. 788\u2013794.\n[23] C. Raffel, B. McFee, E. J. Humphrey, J. Salamon, O. Nieto, D. Liang, D. P. W. Ellis, and Raffel, \u201cmir eval: A transparent implementation of common MIR metrics,\u201d in International Society for Music Information Retrieval Conference (ISMIR), 2014, pp. 367\u2013372.\n[24] O. Nieto and J. P. Bello, \u201cSystematic exploration of computational music structure research,\u201d in International Society for Music Information Retrieval Conference (ISMIR), 2016, pp. 547\u2013553.\n[25] Y. Shiu, H. Jeong, and C.-C. J. Kuo, \u201cSimilarity matrix processing for music structure analysis,\u201d in Proceedings of the 1st ACM workshop on Audio and music computing multimedia, 2006, pp. 69\u201376."
        }
    ],
    "title": "CONVOLUTIVE BLOCK-MATCHING SEGMENTATION ALGORITHM WITH APPLICATION TO MUSIC STRUCTURE ANALYSIS",
    "year": 2023
}