{
    "abstractText": "Recognizing the language of ambiguous texts has become a main challenge in language identification (LID). When using multilingual applications, users have their own language preferences, which can be regarded as external knowledge for LID. Nevertheless, current studies do not consider the inter-personal variations due to the lack of user annotated training data. To fill this gap, we introduce preferenceaware LID and propose a novel unsupervised learning strategy. Concretely, we construct pseudo training set for each user by extracting training samples from a standard LID corpus according to his/her historical language distribution. Besides, we contribute the first user labeled LID test set called \u201cU-LID\u201d. Experimental results reveal that our model can incarnate user traits and significantly outperforms existing LID systems on handling ambiguous texts. Our code and benchmark have been released.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Xingzhang Ren"
        },
        {
            "affiliations": [],
            "name": "Baosong Yang"
        },
        {
            "affiliations": [],
            "name": "Dayiheng Liu"
        },
        {
            "affiliations": [],
            "name": "Haibo Zhang"
        },
        {
            "affiliations": [],
            "name": "Xiaoyu Lv"
        },
        {
            "affiliations": [],
            "name": "Liang Yao"
        },
        {
            "affiliations": [],
            "name": "Jun Xie"
        }
    ],
    "id": "SP:ae1b5f958d4be6f3833ce1ca2a3aebcdde7c7ddb",
    "references": [
        {
            "authors": [
                "Tianchi Bi",
                "Liang Yao",
                "Baosong Yang",
                "Haibo Zhang",
                "Weihua Luo",
                "Boxing Chen."
            ],
            "title": "Constraint translation candidates: A bridge between neural query translation and cross-lingual information retrieval",
            "venue": "CoRR, abs/2010.13658.",
            "year": 2020
        },
        {
            "authors": [
                "Andrea Ceolin."
            ],
            "title": "Comparing the performance of cnns and shallow models for language identification",
            "venue": "Proceedings of the Eighth Workshop on NLP for Similar Languages, Varieties and Dialects, pages 102\u2013112.",
            "year": 2021
        },
        {
            "authors": [
                "Bharathi Raja Chakravarthi",
                "Gaman Mihaela",
                "Radu Tudor Ionescu",
                "Heidi Jauhiainen",
                "Tommi Jauhiainen",
                "Krister Lind\u00e9n",
                "Nikola Ljube\u0161i\u0107",
                "Niko Partanen",
                "Ruba Priyadharshini",
                "Christoph Purschke"
            ],
            "title": "Findings of the vardial evaluation campaign",
            "year": 2021
        },
        {
            "authors": [
                "Tommi Jauhiainen",
                "Heidi Jauhiainen",
                "Krister Lind\u00e9n."
            ],
            "title": "Naive bayes-based experiments in romanian dialect identification",
            "venue": "Proceedings of the Eighth Workshop on NLP for Similar Languages, Varieties and Dialects, pages 76\u201383.",
            "year": 2021
        },
        {
            "authors": [
                "Tommi Jauhiainen",
                "Marco Lui",
                "Marcos Zampieri",
                "Timothy Baldwin",
                "Krister Lind\u00e9n."
            ],
            "title": "Automatic language identification in texts: A survey",
            "venue": "volume 65, pages 675\u2013782.",
            "year": 2019
        },
        {
            "authors": [
                "Armand Joulin",
                "Edouard Grave",
                "Piotr Bojanowski",
                "Tom\u00e1s Mikolov"
            ],
            "title": "Bag of tricks for efficient",
            "year": 2017
        },
        {
            "authors": [
                "Yoon Kim."
            ],
            "title": "Convolutional neural networks for sentence classification",
            "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special",
            "year": 2014
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba."
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.",
            "year": 2015
        },
        {
            "authors": [
                "Tom Kocmi",
                "Ondrej Bojar."
            ],
            "title": "Lanidenn: Multilingual language identification on character window",
            "venue": "CoRR, abs/1701.03338.",
            "year": 2017
        },
        {
            "authors": [
                "Philipp Koehn."
            ],
            "title": "Statistical significance tests for machine translation evaluation",
            "venue": "EMNLP.",
            "year": 2004
        },
        {
            "authors": [
                "Juntao Li",
                "Chang Liu",
                "Jian Wang",
                "Lidong Bing",
                "Hongsong Li",
                "Xiaozhong Liu",
                "Dongyan Zhao",
                "Rui Yan."
            ],
            "title": "Cross-lingual low-resource set-todescription retrieval for global e-commerce",
            "venue": "The Thirty-Fourth AAAI Conference on Artificial Intelli-",
            "year": 2020
        },
        {
            "authors": [
                "Huan Lin",
                "Liang Yao",
                "Baosong Yang",
                "Dayiheng Liu",
                "Haibo Zhang",
                "Weihua Luo",
                "Degen Huang",
                "Jinsong Su."
            ],
            "title": "Towards user-driven neural machine translation",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "Marco Lui",
                "Timothy Baldwin"
            ],
            "title": "langid.py: An off-the-shelf language identification tool. In The 50th Annual Meeting of the Association for Computational Linguistics",
            "venue": "Proceedings of the System Demonstrations,",
            "year": 2012
        },
        {
            "authors": [
                "Marco Lui",
                "Jey Han Lau",
                "Timothy Baldwin."
            ],
            "title": "Automatic detection and language identification of multilingual documents",
            "venue": "Trans. Assoc. Comput. Linguistics, 2:27\u201340.",
            "year": 2014
        },
        {
            "authors": [
                "Martin Majlis",
                "Zdenek Zabokrtsk\u00fd."
            ],
            "title": "Language richness of the web",
            "venue": "Proceedings of the Eighth International Conference on Language Resources and Evaluation, LREC 2012, Istanbul, 3851",
            "year": 2012
        },
        {
            "authors": [
                "Gabriel Pereyra",
                "George Tucker",
                "Jan Chorowski",
                "Lukasz Kaiser",
                "Geoffrey E. Hinton."
            ],
            "title": "Regularizing neural networks by penalizing confident output distributions",
            "venue": "5th International Conference on Learning Representations, ICLR 2017, Toulon,",
            "year": 2017
        },
        {
            "authors": [
                "Roland Sch\u00e4fer."
            ],
            "title": "Commoncow: Massively huge web corpora from commoncrawl data and a method to distribute them freely under restrictive EU copyright laws",
            "venue": "Proceedings of the Tenth International Conference on Language Resources and Eval-",
            "year": 2016
        },
        {
            "authors": [
                "Juliane Stiller",
                "Maria G\u00e4de",
                "Vivien Petras."
            ],
            "title": "Ambiguity of queries and the challenges for query language detection",
            "venue": "CLEF 2010 LABs and Workshops, Notebook Papers, 22-23 September 2010, Padua, Italy, volume 1176 of CEUR Workshop Pro-",
            "year": 2010
        },
        {
            "authors": [
                "Shuo Sun",
                "Suzanna Sia",
                "Kevin Duh."
            ],
            "title": "Clireval: Evaluating machine translation as a cross-lingual information retrieval task",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, ACL",
            "year": 2020
        },
        {
            "authors": [
                "Ritiz Tambi",
                "Ajinkya Kale",
                "Tracy Holloway King."
            ],
            "title": "Search query language identification using weak labeling",
            "venue": "Proceedings of The 12th Language Resources and Evaluation Conference, LREC 2020, Marseille, France, May 11-16, 2020, pages",
            "year": 2020
        },
        {
            "authors": [
                "J\u00f6rg Tiedemann",
                "Santhosh Thottingal."
            ],
            "title": "OPUS-MT - building open translation services for the world",
            "venue": "Proceedings of the 22nd Annual Conference of the European Association for Machine Translation, EAMT 2020, Lisboa, Portugal, Novem-",
            "year": 2020
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N. Gomez",
                "Lukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in Neural Information Processing Systems 30: Annual Conference on Neural",
            "year": 2017
        },
        {
            "authors": [
                "Duy-Tin Vo",
                "Richard Khoury."
            ],
            "title": "Language identification on massive datasets of short messages using an attention mechanism CNN",
            "venue": "IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2020, The",
            "year": 2020
        },
        {
            "authors": [
                "Yu Wan",
                "Baosong Yang",
                "Derek Fai Wong",
                "Lidia Sam Chao",
                "Liang Yao",
                "Haibo Zhang",
                "Boxing Chen."
            ],
            "title": "Challenges of Neural Machine Translation for Short Texts",
            "venue": "Computational Linguistics, pages 1\u201321.",
            "year": 2022
        },
        {
            "authors": [
                "Fei Xia",
                "Carrie Lewis",
                "William D. Lewis."
            ],
            "title": "The problems of language identification within hugely multilingual data sets",
            "venue": "Proceedings of the International Conference on Language Resources and Evaluation, LREC 2010, 17-23 May 2010, Val-",
            "year": 2010
        },
        {
            "authors": [
                "Linlong Xu",
                "Baosong Yang",
                "Xiaoyu Lv",
                "Tianchi Bi",
                "Dayiheng Liu",
                "Haibo Zhang."
            ],
            "title": "Leveraging advantages of interactive and non-interactive models for vector-based cross-lingual information retrieval",
            "venue": "CoRR, abs/2111.01992.",
            "year": 2021
        },
        {
            "authors": [
                "Liang Yao",
                "Baosong Yang",
                "Haibo Zhang",
                "Boxing Chen",
                "Weihua Luo."
            ],
            "title": "Domain transfer based data augmentation for neural query translation",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 4521\u20134533,",
            "year": 2020
        },
        {
            "authors": [
                "Liang Yao",
                "Baosong Yang",
                "Haibo Zhang",
                "Weihua Luo",
                "Boxing Chen."
            ],
            "title": "Exploiting neural query translation into cross lingual information retrieval",
            "venue": "CoRR, abs/2010.13659. 3852",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Findings of the Association for Computational Linguistics: ACL 2022, pages 3847 - 3852 May 22-27, 2022 c\u00a92022 Association for Computational Linguistics"
        },
        {
            "heading": "1 Introduction",
            "text": "Language identification (LID) is widely applied in a range of web services where a multitude of languages may be presented, such as translation systems, search engines, and social media (Yao et al., 2020a; Sun et al., 2020; Li et al., 2020; Bi et al., 2020; Xu et al., 2021). It predicts the natural language that a text is written in, and decides which language-specific model to invoke in downstream natural language processing (NLP) tasks (Lui et al., 2014; Yao et al., 2020b; Tambi et al., 2020).\nSeveral recent studies have well tackled LID by designing a feature set for a traditional or neural classifier (Kocmi and Bojar, 2017; Vo and Khoury, 2020; Jauhiainen et al., 2021). However, these researches merely explore textual information regardless of external knowledge about the user. In a real-world scenario, there exists large amount of\n\u2217Baosong Yang is the corresponding author. 1https://github.com/xzhren/PreferenceAwareLID\nambiguous user inputs, such as texts with falsefriend, code-switching, and misspelling, as shown in Table 1. On the one hand, the languages of these texts are difficult (even impossible) to be explicitly identified without external knowledge. On the other hand, for different users, a good LID should flexibly give different results to the same ambiguous input, thus conforming to users\u2019 intention (Lin et al., 2021). It can be said that classifying ambiguous user inputs remains a main challenge in LID (Xia et al., 2010; Stiller et al., 2010).\nWhen drawing on a multilingual NLP application, every person has his/her own accustomed languages. The historical behavior implicitly mirrors the user language preference and can be exploited for LID. To this end, we propose a task named preference-aware LID, where the historical language distribution of a user is leveraged for the disambiguation of mistakable texts, and guides LID to predict different languages for different users.\nA major bottleneck for this task lies in the lack of well-labeled training data. In particular, it is unavailable to obtain large amount of ambiguous texts labeled with different languages by different users. To overcome this issue, we propose a novel unsupervised strategy that builds synthetic data for each user via sampling natural training examples according to his/her historical language distribution.\n3847\nWe build our model upon Transformer (Vaswani et al., 2017) and introduce two kinds of extensions. One is directly revising the predicted probability of LID using the user language preference. In order to maintain the robustness, the other encodes the user traits into inductive bias.\nOur models are trained using a publicly available dataset extracted from Wikipedia. Towards evaluating the effectiveness, we construct a user-driven LID test set \u201cU-LID\u201d. The benchmark consists of 21 languages, each of which contains 500 examples collected from a real-world translation system and labeled by users. Extensive analyses demonstrate the superiority and the robustness of our approach on recognizing error-prone cases."
        },
        {
            "heading": "2 Preliminary",
            "text": "Problem Formulation Given an input text X , the vanilla LID model with parameter \u03b8 predicts the probability of the language y by P (y|X; \u03b8). As an extension of conventional LID, preferenceaware LID considers the traits of each user, thus facilitating the classifying of ambiguous texts. In this paper, we treat the language preference of user as the external knowledge, which can be implicitly embodied in historical language distribution D(u) of user u. Consequently, our task aims to model P ( y(u)|X,D(u); \u03b8 ) , as illustrated in Figure 1.\nUser Annotated Test Set In order to assess the effectiveness of the proposed method, we construct a preference-aware LID test set called \u201cU-LID\u201d. The training instance is represented as a triplet \u3008X,D(u), y(u)\u3009. The samples are collected from a real-world translation system - Alibaba Translate.2 We mine user annotated data as follows: Given a user input, the translation system first returns a predicted language label and the associated translation results. When the user is dissatisfied with the prediction result, he/she may change the predicted language label. We argue that this operation not only reflects the user intention concerning the language, but also implies that the classification of the current input is error-prone. Accordingly, we collect texts whose predicted labels are revised by users. The test set is further manually checked and carefully desensitized by linguistic experts to maintain the data quality. Finally, the benchmark consists of 21 languages and 11,031 samples.3 The\n2https://translate.alibaba.com 3Including: English (en), Chinese (zh), Russian (ru), Portuguese (pt), Spanish (es), French (fr), German (de), Italian\naverage word count in each sample is 2.08, and the average number with respect to character is 13.27."
        },
        {
            "heading": "3 Methodology",
            "text": ""
        },
        {
            "heading": "3.1 Preference-Aware Model",
            "text": "Our model is built upon the advanced neuralbased model \u2013 Transformer (Vaswani et al., 2017). Given an input query X , the output token representations can be formally expressed as: Z = Transformer(X).\nThe final probability distribution is calculated by assigning an output layer:\nY = softmax(WoZ + bo), (1)\nwhere Z denotes the mean of the token representations Z. Wo \u2208 RL\u00d7H , bo \u2208 RL are trainable parameters with H being the hidden size and L being the number of languages. softmax(\u00b7) represents a non-linear function that is used to normalize the probability distribution of labels.\nWe propose the preference-aware model to leverage user language preference into LID includes two types of approaches:\nRevision-Based Model Intuitively, we can multiply the output Y and the user language preference D(u) directly. The final distribution is revised as:\nY (u) = softmax(Y D(u)). (2)\nIn this paradigm, we regard D(u) as a reviser at the model training time. Note that, revision-based model can be also exploited in a plug-and-play fashion without any model training.\n(it), Dutch (nl), Japanese (ja), Korean (ko), Arabic (ar), Thai (th), Hindi (hi), Hebrew (he), Vietnamese (vi), Turkish (tr), Polish (pl), Indonesian (id), Malay (ms), and Ukrainian (uk).\nRepresentation-Based Model A natural alternative is to encode language preference into a representation, which is then served as an inductive bias in the output layer. Here, we assign L trainable language embeddings We \u2208 RL\u00d7L. The user representation is the weighted sum of language embeddings regarding to user language distribution: WeD (u). We modified Equation 1 as follows:\nY (u) = softmax(WoZ +WeD (u) + bo). (3)"
        },
        {
            "heading": "3.2 Unsupervised Training",
            "text": "The main challenge of our task lies in the lack of user annotated training data. It is hard to construct large amount of training examples in the triplet form \u3008X,D(u), yu\u3009. Although we construct a test set by mining user operations on switching languages, such kind of approach depends on expensive manual review due to the massive noises.\nTo tackle this problem, we propose a novel unsupervised training strategy, as illustrated in Figure 2. In an existing LID training corpus T , each text is labeled to a language. Given the user historical language distribution D(u), we sample a subset T (u) from T and guarantee the language distribution of T (u) to be consistent with D(u). Nevertheless, most people only use one or two languages, making their historical distribution concentrated on a few languages. Immediately utilizing D(u) to sample examples for training may cause overconfidence problem. Firstly, the model may tend to overlook either the user information or the input text. Secondly, texts of which language frequency is relatively low in D(u) may fail to be correctly classified, especially for those languages not appearing in the user\u2019s historical inputs. Accordingly, we borrow the idea of up-sampling (Pereyra et al.,\n2017; Wan et al., 2022) into our approach. The final sampling distribution can be calculated as:\nS(u) = softmax((1\u2212 \u03b1)D(u) + \u03b1/L). (4)\nHere, we set \u03b1 = 0.01 and collect 100 examples for each user as default. Besides, in order to maintain the robustness and cope with the situation that the user\u2019s historical input is none or inaccessible, we treat the uniform distribution as D(u), then supplement the same number of standard training examples to that in current synthetic corpus."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Experimental Setting",
            "text": "Data Setting We collect 100 thousand (K) users from the log of the real-world translation system Alibaba Translate. Considering the standard LID corpus T , we follow Vo and Khoury (2020) to extract the natural training data from the released datasets: W2C corpus (Majlis and Zabokrtsk\u00fd, 2012), Common Crawl corpus (Sch\u00e4fer, 2016) and Tatoeba (Tiedemann and Thottingal, 2020). Finally T consists of 21 languages, each of which contains 5 million (M) samples. We examine models on U-LID test set. Moreover, in order to investigate the robustness of our methods on conventional LID task, we further collect a publicly available test set KB-21 from Kocmi and Bojar (2017), using a subset of 21 languages. KB-21 consists of 2,100 samples, the average amounts of words and characters in each sample are 4.47 and 34.90, respectively.\nImplementation Details We follow the Base model setting as Vaswani et al. (2017), excepting that the number of layers is set to 1 for the computational efficiency.4 To avoid the problem of outof-vocabulary, we follow existing LID approaches to exploit character-based embedding (Jauhiainen et al., 2019), in which vocabulary size is set to 15K.\nIn this study, 1-Layer TRANSFORMER model is served as baseline. We reimplement widely used text classification models, FASTTEXT (Joulin et al., 2017) and TEXTCNN (Kim, 2014) as well as recent LID approach ATTENTIONCNN (Vo and Khoury, 2020), as listed in Table 2. In addition, we reproduced a state-of-the-art model Naive Bayes (Jauhiainen et al., 2021) in VarDial2021 task (Chakravarthi et al., 2021). Moreover, we also examine popular LID systems on our LID tasks,\n4We verified that complex networks marginally contribute to LID, which is consistent with findings in Ceolin (2021).\nincluding Langid.py5 (Lui and Baldwin, 2012) and LanideNN6 (Kocmi and Bojar, 2017).\nFor training, we used Adam optimizer (Kingma and Ba, 2015) with the same learning rate schedule as Vaswani et al. (2017) and 8k warmup steps. Each batch consists of 1,024 examples and dropout rate is set to a constant of 0.1. Models are trained on a single Tesla P100 GPU.\nConsidering the compared models, we exploit 1-3 gram to extract characters and words for FASTTEXT (Joulin et al., 2017). As to TEXTCNN (Kim, 2014), we apply six filters with the size of 3, 3, 4, 4, 5, 5 and a hidden size of 512. For computational efficiency, 1 layer network is used as default if no confusion is possible. Other configurations of our reimplementations are same to common settings described in corresponding literature or the released source codes."
        },
        {
            "heading": "4.2 Results",
            "text": "The results are concluded in Table 2. Our models significantly outperform the compared methods over 17%-22% accuracy on U-LID task, indicating the effectiveness of the utilization of user information. Specifically, treating user\u2019s language preference as a reviser performs best on U-LID, while\n5https://github.com/saffsd/langid.py 6https://github.com/kocmitom/LanideNN\ndeclining the quality on KB-21. We attribute this to the overconfidence of revision-based model on user historical language distribution, which weakens the learning of LID model on original text classification. It is encouraging to see that revision-based model without training can yields considerable result on U-LID, in the meanwhile, does not affect the quality on KB-21 by feeding the uniform historical distribution. By contrast, representationbased model alleviates the overconfidence problem and achieves good performance in both U-LID and KB-21. Accordingly, we use representation-based model as the default setting in subsequent analyses."
        },
        {
            "heading": "4.3 Analysis",
            "text": "Robustness Analysis User\u2019s language preference greatly affects our model. The less the user historical inputs, the higher the uncertainty of user preference is. Accordingly, the robustness of our model is necessary to be assessed. We plot Figure 3 to show the effects of the number of historical inputs. Obviously, revision-based model yields lower accuracy when there exists relatively bare user historical information, verifying our hypothesis that the model suffers from the problem of overconfidence on historical language distribution. On the contrary, representation-based model draws a more smooth line, which demonstrates its robustness.\nQualitative Analysis Table 1 shows several identification results. In the first two cases, \u201cvelo\u201d is a Spanish and French false-friend. The third example is code-switching in which \u201chuawei y7\u201d is a mobile phone module, preceded by a Spanish word which means \u201ccase\u201d. For the last case, \u201ckello\u201d presents a misspelled English word \u201chello\u201d. Results indicate that vanilla LID model fails to correctly identify these cases, while our model can exactly predict distinct results that conform to the user intention."
        },
        {
            "heading": "5 Conclusion",
            "text": "We explore preference-aware LID. Major contributions of our work are four-fold: 1) We introduce preference-aware LID task that leverages user language preference to improve LID. We hope our work can attract more attention to explore techniques on this topic; 2) We propose a novel unsupervised strategy to guide model to take user historical language distribution into account; 3) We collect U-LID and make it publicly available, which may contribute to the subsequent researches on LID; and 4) Extensive analyses indicate the effectiveness and robustness of our method, verifying that LID can profit from personality information to make the results conform to user intention."
        },
        {
            "heading": "Acknowledgments",
            "text": "We thank anonymous reviewers for valuable comments. This research was supported by National Key R&D Program of China under Grant No.2018YFB1403202."
        }
    ],
    "title": "Unsupervised Preference-Aware Language Identification",
    "year": 2022
}