{
    "abstractText": "Multi-site resting-state functional magnetic resonance imaging (rs-fMRI) data can facilitate learning-based approaches to train reliable models on more data. However, significant data heterogeneity between imaging sites, caused by different scanners or protocols, can negatively impact the generalization ability of learned models. In addition, previous studies have shown that graph convolution neural networks (GCNs) are effective in mining fMRI biomarkers. However, they generally ignore the potentially different contributions of brain regionsof-interest (ROIs) to automated disease diagnosis/prognosis. In this work, we propose a multi-site rs-fMRI adaptation framework with attention GCN (A2GCN) for brain disorder identification. Specifically, the proposed A2GCN consists of three major components: (1) a node representation learning module based on GCN to extract rs-fMRI features from functional connectivity networks, (2) a node attention mechanism module to capture the contributions of ROIs, and (3) a domain adaptation module to alleviate the differences in data distribution between sites through the constraint of mean absolute error and covariance. The A2GCN not only reduces data heterogeneity across sites, but also improves the interpretability of the learning algorithm by exploring important ROIs. Experimental results on the public ABIDE database demonstrate that our method achieves remarkable performance in fMRI-based recognition of autism",
    "authors": [
        {
            "affiliations": [],
            "name": "Ying Chu"
        },
        {
            "affiliations": [],
            "name": "Haonan Ren"
        },
        {
            "affiliations": [],
            "name": "Lishan Qiao"
        },
        {
            "affiliations": [],
            "name": "Mingxia Liu"
        }
    ],
    "id": "SP:8401df52c35f027d605ac815bb5ab88f4ff86c2a",
    "references": [
        {
            "authors": [
                "R.L. Buckner",
                "F.M. Krienen",
                "B.T. Yeo"
            ],
            "title": "Opportunities and limitations of intrinsic functional connectivity MRI",
            "venue": "Nat. Neurosci",
            "year": 2013
        },
        {
            "authors": [
                "P.J. McCarty",
                "A.R. Pines",
                "B.L. Sussman",
                "S.N. Wyckoff",
                "A. Jensen",
                "R. Bunch",
                "V.L. Boerwinkle",
                "R.E. Frye"
            ],
            "title": "Resting State Functional Magnetic Resonance Imaging Elucidates Neurotransmitter Deficiency in Autism Spectrum Disorder",
            "venue": "J. Pers. Med",
            "year": 2021
        },
        {
            "authors": [
                "F.Z. Subah",
                "K. Deb",
                "P.K. Dhar",
                "T. Koshiba"
            ],
            "title": "A deep learning approach to predict Autism Spectrum Disorder using multisite resting-state fMRI",
            "venue": "Appl. Sci",
            "year": 2021
        },
        {
            "authors": [
                "M.J. Walsh",
                "G.L. Wallace",
                "S.M. Gallegos",
                "B.B. Braden"
            ],
            "title": "Brain-based sex differences in autism spectrum disorder across the lifespan: A systematic review of structural MRI, fMRI, and DTI findings",
            "year": 2021
        },
        {
            "authors": [
                "S. Shrivastava",
                "U. Mishra",
                "N. Singh",
                "A. Chandra",
                "S. Verma"
            ],
            "title": "Control or autism-classification using convolutional neural networks on functional MRI",
            "venue": "In Proceedings of the 2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT),",
            "year": 2020
        },
        {
            "authors": [
                "K. Niu",
                "J. Guo",
                "Y. Pan",
                "X. Gao",
                "X. Peng",
                "N. Li",
                "H. Li"
            ],
            "title": "Multichannel deep attention neural networks for the classification of Autism Spectrum Disorder using neuroimaging and personal characteristic data",
            "year": 2020
        },
        {
            "authors": [
                "A. Yamashita",
                "N. Yahata",
                "T. Itahashi",
                "G. Lisi",
                "T. Yamada",
                "N. Ichikawa",
                "M. Takamura",
                "Y. Yoshihara",
                "A. Kunimatsu",
                "N Okada"
            ],
            "title": "Harmonization of resting-state functional MRI data across multiple imaging sites via the separation of site differences into sampling bias and measurement bias",
            "venue": "PLoS Biol",
            "year": 2019
        },
        {
            "authors": [
                "J. Lee",
                "E. Kang",
                "E. Jeon",
                "H.I. Suk"
            ],
            "title": "Meta-modulation Network for Domain Generalization in Multi-site fMRI Classification",
            "venue": "In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, Virtual Event,",
            "year": 2021
        },
        {
            "authors": [
                "Y. Zhang",
                "T. Liu",
                "M. Long",
                "M. Jordan"
            ],
            "title": "Bridging theory and algorithm for domain adaptation",
            "venue": "In Proceedings of the International Conference on Machine Learning (PMLR), Long Beach, CA, USA,",
            "year": 2019
        },
        {
            "authors": [
                "A. Farahani",
                "S. Voghoei",
                "K. Rasheed",
                "H.R. Arabnia"
            ],
            "title": "A brief review of domain adaptation",
            "venue": "Adv. Data Sci. Inf. Eng",
            "year": 2021
        },
        {
            "authors": [
                "K. You",
                "M. Long",
                "Z. Cao",
                "J. Wang",
                "M.I. Jordan"
            ],
            "title": "Universal domain adaptation",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2019
        },
        {
            "authors": [
                "X. Jiang",
                "L. Zhang",
                "L. Qiao",
                "D. Shen"
            ],
            "title": "Estimating functional connectivity networks via low-rank tensor approximation with applications to MCI identification",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2019
        },
        {
            "authors": [
                "X. Xing",
                "Q. Li",
                "H. Wei",
                "M. Zhang",
                "Y. Zhan",
                "X.S. Zhou",
                "Z. Xue",
                "F. Shi"
            ],
            "title": "Dynamic spectral graph convolution networks with assistant task training for early MCI diagnosis",
            "venue": "In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, Shenzhen, China,",
            "year": 2019
        },
        {
            "authors": [
                "B. Jie",
                "C.Y. Wee",
                "D. Shen",
                "D. Zhang"
            ],
            "title": "Hyper-connectivity of functional networks for brain disease diagnosis",
            "venue": "Med. Image Anal",
            "year": 2016
        },
        {
            "authors": [
                "Y. Zhang",
                "X. Jiang",
                "L. Qiao",
                "M. Liu"
            ],
            "title": "Modularity-Guided Functional Brain Network Analysis for Early-Stage Dementia Identification",
            "venue": "Front. Neurosci",
            "year": 2021
        },
        {
            "authors": [
                "D. Zhang",
                "J. Huang",
                "B. Jie",
                "J. Du",
                "L. Tu",
                "M. Liu"
            ],
            "title": "Ordinal pattern: A new descriptor for brain connectivity networks",
            "venue": "IEEE Trans. Med. Imaging",
            "year": 2018
        },
        {
            "authors": [
                "M. Niepert",
                "M. Ahmed",
                "K. Kutzkov"
            ],
            "title": "Learning convolutional neural networks for graphs",
            "venue": "In Proceedings of the International Conference on Machine Learning (PMLR),",
            "year": 2016
        },
        {
            "authors": [
                "T.N. Kipf",
                "M. Welling"
            ],
            "title": "Semi-supervised classification with graph convolutional networks",
            "venue": "arXiv 2016,",
            "year": 2016
        },
        {
            "authors": [
                "R. Anirudh",
                "J.J. Thiagarajan"
            ],
            "title": "Bootstrapping graph convolutional neural networks for Autism spectrum disorder classification",
            "venue": "In Proceedings of the ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brighton,",
            "year": 2019
        },
        {
            "authors": [
                "M. Cao",
                "M. Yang",
                "C. Qin",
                "X. Zhu",
                "Y. Chen",
                "J. Wang",
                "T. Liu"
            ],
            "title": "Using DeepGCN to identify the Autism spectrum disorder from multi-site resting-state data",
            "venue": "Biomed. Signal Process. Control",
            "year": 2021
        },
        {
            "authors": [
                "S. Yu",
                "S. Wang",
                "X. Xiao",
                "J. Cao",
                "G. Yue",
                "D. Liu",
                "T. Wang",
                "Y. Xu",
                "B. Lei"
            ],
            "title": "Multi-scale enhanced graph convolutional network for early mild cognitive impairment detection",
            "venue": "In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention,",
            "year": 2020
        },
        {
            "authors": [
                "S. Parisot",
                "S.I. Ktena",
                "E. Ferrante",
                "M. Lee",
                "R. Guerrero",
                "B. Glocker",
                "D. Rueckert"
            ],
            "title": "Disease Prediction Using Graph Convolutional Networks: Application to Autism Spectrum Disorder and Alzheimer\u2019s Disease",
            "venue": "Med. Image Anal",
            "year": 2018
        },
        {
            "authors": [
                "A. Di Martino",
                "C.G. Yan",
                "Q. Li",
                "E. Denio",
                "F.X. Castellanos",
                "K. Alaerts",
                "J.S. Anderson",
                "M. Assaf",
                "S.Y. Bookheimer",
                "M Dapretto"
            ],
            "title": "The Autism brain imaging data exchange: Towards a large-scale evaluation of the intrinsic brain architecture in Autism",
            "year": 2014
        },
        {
            "authors": [
                "S. Abu-El-Haija",
                "A. Kapoor",
                "B. Perozzi",
                "J. Lee"
            ],
            "title": "N-GCN: Multi-scale graph convolution for semi-supervised node classification",
            "venue": "In Proceedings of the Uncertainty In Artificial Intelligence (PMLR), Virtual,",
            "year": 2020
        },
        {
            "authors": [
                "M. Zhang",
                "Z. Cui",
                "M. Neumann",
                "Y. Chen"
            ],
            "title": "An end-to-end deep learning architecture for graph classification",
            "venue": "In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Y. Chen",
                "G. Ma",
                "C. Yuan",
                "B. Li",
                "H. Zhang",
                "F. Wang",
                "W. Hu"
            ],
            "title": "Graph convolutional network with structure pooling and joint-wise channel attention for action recognition",
            "venue": "Pattern Recognit",
            "year": 2020
        },
        {
            "authors": [
                "S.I. Ktena",
                "S. Parisot",
                "E. Ferrante",
                "M. Rajchl",
                "M. Lee",
                "B. Glocker",
                "D. Rueckert"
            ],
            "title": "Metric learning with spectral graph convolutions on brain connectivity networks",
            "year": 2018
        },
        {
            "authors": [
                "L. Wang",
                "K. Li",
                "X.P. Hu"
            ],
            "title": "Graph convolutional network for fMRI analysis based on connectivity neighborhood",
            "venue": "Netw. Neurosci. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "D. Yao",
                "J. Sui",
                "E. Yang",
                "P.T. Yap",
                "D. Shen",
                "M. Liu"
            ],
            "title": "Temporal-adaptive graph convolutional network for automated identification of major depressive disorder using resting-state fMRI",
            "venue": "In Proceedings of the International Workshop on Machine Learning in Medical Imaging,",
            "year": 2020
        },
        {
            "authors": [
                "S. Gadgil",
                "Q. Zhao",
                "A. Pfefferbaum",
                "E.V. Sullivan",
                "E. Adeli",
                "K.M. Pohl"
            ],
            "title": "Spatio-temporal graph convolution for resting-state fMRI analysis",
            "venue": "In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention,",
            "year": 2020
        },
        {
            "authors": [
                "G. Csurka"
            ],
            "title": "A comprehensive survey on domain adaptation for visual applications",
            "venue": "Domain Adapt. Comput. Vis. Appl",
            "year": 2017
        },
        {
            "authors": [
                "H. Guan",
                "Y. Liu",
                "E. Yang",
                "P.T. Yap",
                "D. Shen",
                "M. Liu"
            ],
            "title": "Multi-site MRI harmonization via attention-guided deep domain adaptation for brain disorder identification",
            "venue": "Med. Image Anal. 2021,",
            "year": 1020
        },
        {
            "authors": [
                "H. Guan",
                "M. Liu"
            ],
            "title": "Domain adaptation for medical image analysis: A survey",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2021
        },
        {
            "authors": [
                "M. Wang",
                "W. Deng"
            ],
            "title": "Deep visual domain adaptation: A survey",
            "venue": "Neurocomputing",
            "year": 2018
        },
        {
            "authors": [
                "M. Ingalhalikar",
                "S. Shinde",
                "A. Karmarkar",
                "A. Rajan",
                "D. Rangaprakash",
                "G. Deshpande"
            ],
            "title": "Functional connectivity-based prediction of Autism on site harmonized ABIDE dataset",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2021
        },
        {
            "authors": [
                "J. Zhang",
                "M. Liu",
                "Y. Pan",
                "D. Shen"
            ],
            "title": "Unsupervised conditional consensus adversarial network for brain disease identification with structural MRI",
            "venue": "In Proceedings of the International Workshop on Machine Learning in Medical Imaging, Shenzhen, China,",
            "year": 2019
        },
        {
            "authors": [
                "C. Cangea",
                "P. Veli\u010dkovi\u0107",
                "N. Jovanovi\u0107",
                "T. Kipf",
                "P. Li\u00f2"
            ],
            "title": "Towards sparse hierarchical graph classifiers",
            "venue": "arXiv 2018,",
            "year": 2018
        },
        {
            "authors": [
                "J. Lee",
                "I. Lee",
                "J. Kang"
            ],
            "title": "Self-attention graph pooling",
            "venue": "In Proceedings of the International Conference on Machine Learning (PMLR), Long Beach, CA, USA,",
            "year": 2019
        },
        {
            "authors": [
                "B. Sun",
                "K. Saenko"
            ],
            "title": "Deep coral: Correlation alignment for deep domain adaptation",
            "venue": "In Proceedings of the European Conference on Computer Vision, Amsterdam, The Netherlands,",
            "year": 2016
        },
        {
            "authors": [
                "M. Wang",
                "D. Zhang",
                "J. Huang",
                "P.T. Yap",
                "D. Shen",
                "M. Liu"
            ],
            "title": "Identifying Autism Spectrum Disorder with multi-site fMRI via low-rank domain adaptation",
            "venue": "IEEE Trans. Med. Imaging",
            "year": 2019
        },
        {
            "authors": [
                "C. Craddock",
                "S. Sikka",
                "B. Cheung",
                "R. Khanuja",
                "S.S. Ghosh",
                "C. Yan",
                "Q. Li",
                "D. Lurie",
                "J. Vogelstein",
                "R Burns"
            ],
            "title": "Towards automated analysis of connectomes: The configurable pipeline for the analysis of connectomes (C-PAC)",
            "venue": "Front. Neuroinform. 2013,",
            "year": 2013
        },
        {
            "authors": [
                "N. Tzourio-Mazoyer",
                "B. Landeau",
                "D. Papathanassiou",
                "F. Crivello",
                "O. Etard",
                "N. Delcroix",
                "B. Mazoyer",
                "M. Joliot"
            ],
            "title": "Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain",
            "year": 2002
        },
        {
            "authors": [
                "M. Wu",
                "S. Pan",
                "C. Zhou",
                "X. Chang",
                "X. Zhu"
            ],
            "title": "Unsupervised domain adaptive graph convolutional networks",
            "venue": "In Proceedings of the Web Conference",
            "year": 2020
        },
        {
            "authors": [
                "L. Van der Maaten",
                "G. Hinton"
            ],
            "title": "Visualizing data using t-SNE",
            "venue": "J. Mach. Learn. Res. 2008,",
            "year": 2008
        },
        {
            "authors": [
                "M. Xia",
                "J. Wang",
                "Y. He"
            ],
            "title": "BrainNet Viewer: A network visualization tool for human brain connectomics",
            "venue": "PLoS ONE 2013,",
            "year": 2013
        },
        {
            "authors": [
                "D. Sussman",
                "R. Leung",
                "V. Vogan",
                "W. Lee",
                "S. Trelle",
                "S. Lin",
                "D. Cassel",
                "M. Chakravarty",
                "J. Lerch",
                "E Anagnostou"
            ],
            "title": "The Autism puzzle: Diffuse but not pervasive neuroanatomical abnormalities in children with ASD",
            "year": 2015
        },
        {
            "authors": [
                "L. Sun",
                "Y. Xue",
                "Y. Zhang",
                "L. Qiao",
                "L. Zhang",
                "M. Liu"
            ],
            "title": "Estimating sparse functional connectivity networks via hyperparameter-free learning model",
            "venue": "Artif. Intell. Med",
            "year": 2021
        },
        {
            "authors": [
                "K. He",
                "H. Fan",
                "Y. Wu",
                "S. Xie",
                "R. Girshick"
            ],
            "title": "Momentum contrast for unsupervised visual representation learning",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Citation: Chu, Y.; Ren, H.; Qiao, L;\nLiu, M. Resting-State Functional MRI\nAdaptation with Attention Graph\nConvolution Network for Brain\nDisorder Identification. Brain Sci.\n2022, 12, 1413. https://doi.org/\n10.3390/brainsci12101413\nAcademic Editor: Muthuraman\nMuthuraman\nReceived: 18 September 2022\nAccepted: 17 October 2022\nPublished: 20 October 2022\nPublisher\u2019s Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished maps and institutional affil-\niations.\nCopyright: \u00a9 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: domain adaptation; multi-site data; graph convolutional networks; autism; resting-state functional MRI"
        },
        {
            "heading": "1. Introduction",
            "text": "Resting-state functional magnetic resonance imaging (rs-fMRI) is an imaging technique that uses blood-oxygen-level-dependent (BOLD) signals to obtain functional graphs of brain activity while subjects are at rest [1]. Compared with other fMRI techniques, rsfMRI has advantages because it is non-invasive and has high tissue resolution, and it can skillfully detect the difference between the functional activity network of the human brain under pathological conditions and that of the normal human brain [2]. At the same time, benefiting from the progress of scanning hardware and scanning technology, as well as the rapid development of computer vision technology, rs-fMRI has gradually become one of the effective means to study the human brain in recent years. Relying on rs-fMRI technology, researchers have made remarkable achievements in the auxiliary diagnosis, pathogenesis research, objective biomarker search and other aspects of mental disorders such as Autism Spectrum Disorder (ASD) and Major Depressive Disorder [3,4]. Currently, the application of machine learning/deep learning in natural image analysis is very successful. In contrast, its use in the analysis of neuroimaging data presents some unique problems, including dimensional disaster, small sample size, and limited true labels [5,6]. With the continued efforts of researchers, public multi-site neuroimage datasets, increasing the sample size and statistical power of data, are helping to promote the\nBrain Sci. 2022, 12, 1413. https://doi.org/10.3390/brainsci12101413 https://www.mdpi.com/journal/brainsci\nadoption of data-driven machine learning/deep learning techniques. However, the study of multi-site datasets will face another important challenge. That is, the distribution of data between sites is often quite different due to external factors such as different scanners or protocols [7,8]. This will severely limit the generalization ability of machine/deep learning models, as such algorithms often start with the assumption that all data remain the same distribution [9\u201311]. Studies have shown that detection of abnormal low-frequency fluctuations in the BOLD signals caused by pathological changes in the resting state will facilitate the analysis of brain connectivity and provide scientific and reliable treatment options before and after surgery [12]. Typically in studies of neuroimaging data, brain functional connectivity networks (FCNs) attempt to establish a potential causal link between two regions-of-interest (ROIs) based on linear temporal correlations [13]. Previous studies usually use statistical measures of FCNs (including betweenness centrality, degree centrality, and other features) to construct prediction models [14,15]. These practices often rely on extensive expert knowledge and are subjective, expensive, and time-consuming. FCN is usually defined as a complex non-Euclidean space graph structure [16]. In recent years, graph neural networks, especially graph convolutional networks (GCNs), have become one of the effective tools to deal with irregular graph data. GCN is a natural extension of the convolutional neural network in a graph domain [17,18]. It can be used as a feature extractor to learn node feature information and structure information end-to-end at the same time, which is the best choice for graph data learning task at present [19,20]. When GCN is naturally used to analyze rs-fMRI data, comprehensive mapping of brain FC patterns can effectively describe the functional activity of the brain [21,22]. However, existing studies usually ignore the potential contribution of different brain functional regions to the diagnosis of brain diseases, thus affecting the interpretability of the GCN model. As shown in Figure 1, we construct a domain adaptation model with attention GCN (A2GCN) of multi-site rs-fMRI for ASD diagnosis. For the convenience of description, we set a known site as the source domain, and define the site to be predicted as the target domain. In this paper, we focus on the classification task of graphs. Therefore, we first construct the corresponding FCNs based on the rs-fMRI data of subjects from the source/target domains, and take the FCNs as the corresponding source/target graphs. Then, we use GCN as a feature extractor to capture the nodes/ROIs representations from the source/target graphs respectively through the graph convolution layers. In addition, the node attention mechanism is applied to explore the contribution weight of nodes/ROIs automatically. Finally, the objective function composed of multiple loss functions is jointly optimized, so as to establish a cross-domain classification model with a wider application range. We will use rs-fMRI data from the three sites (NYU, UM, UCLA) of the public ABIDE database [23] to identify ASD patients from healthy controls (HCs) to evaluate the performance of our approach. The rest of this work is shown below: In Section 2, we briefly review the related research results of this work. In Section 3, we present our method and experimental setup. In Section 4, we introduce the data used in this work, the competing algorithms, and report the performance of different algorithms. At the same time, ablation experiments are added to investigate the contribution of key components in our proposed model. In Section 5, we discuss several extension studies related to this work and propose future related work. Finally, in Section 6, we summarize our proposed method."
        },
        {
            "heading": "2. Related Work",
            "text": ""
        },
        {
            "heading": "2.1. Graph Convolution Network for fMRI Analysis",
            "text": "At present, the application of deep learning framework, especially the graph convolutional networks (GCNs) model, to graph-structured data has aroused a warm response worldwide [24,25]. GCN is used to advance the feature learning of the network, which integrates the central node characteristics and graph topology information in the convolutional layer [26]. In particular, GCN has achieved impressive results in helping researchers build mathematical models for computer-assisted diagnosis of brain diseases and process and analyze neuroimaging data quickly and efficiently [27]. For example, Wang et al. [28] defined a GCN architecture based on features of fMRI for brain disorder analysis. Based on the spatiotemporal information of rs-fMRI time series, Yao et al. [29] constructed time-adaptive GCN architecture to study the periodic characteristics of the human brain. Gadgil et al. [30] focused on the short subsequence of BOLD signal, so as to construct a spatio-temporal GCN architecture and explore the non-stationary properties of FC. Traditional GCN research usually regards feature representations of each node as independently and equally. That is, they did not consider the unique contribution of each specific node/ROI to rs-fMRI analysis. In this paper, we will establish a ROI/node feature attention mechanism based on GCN to learn potential functional dependencies among brain regions, which allows us to identify those most informative brain regions for diagnosis. This will significantly improve the interpretability of GCN models for automated fMRI analysis."
        },
        {
            "heading": "2.2. Domain Adaptation for Brain Disorder Diagnosis",
            "text": "Data acquired from multiple imaging sites are correlated but distributed differently, which is a classic domain adaptation problem [31,32]. According to the latest research, domain adaptation related algorithms can be roughly summarized into two categories: (1) supervised domain adaptation. The target domain samples contain a large or small amount of label information; (2) unsupervised domain adaptation. There is no data label available for the target domain [33]. This work will focus on the problem of unsupervised domain adaptation, that is, samples from the source domain contain complete data labels, while samples from the target domain to be analyzed have no label information, which is more valuable and challenging for applications. In recent years, in order to achieve domain alignment, many cross-domain classification algorithms have been proposed, including\nadaptive methods based on discrepancy, adversarial learning and data reconstruction [34]. In recent years, domain adaptation technology has also achieved remarkable results in the field of medical imaging. Ingalhalikar et al. [35] coordinated multi-site neuroimaging data based on empirical Bayes formula to improve the accuracy of brain diagnostic classification. Guan et al. [32] defined a multi-site domain attention model based on deep learning for brain disease recognition. Zhang et al. [36] constructed an unsupervised domain adversarial network and established a brain disease prediction model with good classification performance. In this paper, we adopt the classical domain adaptation algorithm, that is, calculate the mean absolute error (MAE) and covariance of the source domain and the target domain at the same time, so as to guide the gradual alignment of node features learned from different domains and alleviate the domain offset problem."
        },
        {
            "heading": "3. Methodology",
            "text": "In this section, we will first describe the concepts and notation related to the unsupervised domain adaptation problem (as shown in Table 1), and then introduce our approach in detail."
        },
        {
            "heading": "3.1. Notation and Problem Formulation",
            "text": "In general, a feature space X of data and its marginal probability distribution P(X) will form a domain D. In this work, the source domain data from the distribution P(Xs) can be expressed as Xs \u2208 RMs\u00d7Ds ; target domain data from distribution P(Xt) can be represented as Xt \u2208 RMt\u00d7Dt , where Ds and Dt are the feature dimension, and Ms and Mt are defined as the sample size in the source domain and target domain, respectively. In the unsupervised domain adaptation problem, the feature space and label space of the data from the source domain and the target domain are usually consistent, but the data distribution is different, that is, P(Xs) 6= P(Xt). Our goal is to use the information learned from the source domain to assist in the graph classification task of a completely unmarked target domain. Our task is to build a good graph classification model for the target domain without any label based on labeled source domain. In this article, we focus on representation learning of nodes on a graph. Therefore, we first build a graph for each subject of the source domain and target domain. A subject from the source domain is represented as a graph Gs = (Vs, As, Xs, Ys), where Vs represents a labeled collection of nodes in Gs, and As \u2208 RNs\u00d7Ns represents the weighted adjacency matrix to quantify the connection strength between nodes. Ns = |Vs| represents the number of nodes/ROIs of Gs. Xs \u2208 RNs\u00d7Ds is the eigenmatrix of graph Gs, and the i-th row of Xs is the eigenvector related to node i. Ys \u2208 RMs is the label of Gs. In this paper, the label value of normal people is 0 and the category label of patients is 1. Similarly, each\nsubject from the target domain is also defined as a graph Gt = (Vt, At, Xt), which is a completely unlabeled network. Vt is the node set. Nt = |Vt| is the number of nodes/ROIs in Gt. At \u2208 RNt\u00d7Nt is the weighted adjacency matrix. Xt \u2208 RNt\u00d7Dt represents the feature matrix of Gt."
        },
        {
            "heading": "3.2. Proposed Method",
            "text": "The model A2GCN designed in this paper mainly includes three modules: node representation learning, node attention mechanism and domain adaptation module as shown in Figure 2. In addition, our model will be described in detail below.\n3.2.1. Node Representation Learning\nTo facilitate the classification task of downstream graphs, we use GCN to capture the node representation information on each graph. First, we used the preprocessed BOLD signal to calculate the Pearson\u2019s correlation coefficient (PC) between nodes on the graph, and defined it as the functional connectivity eij \u2208 [\u22121, 1] of the i-th and j-th brain regions, as follows:\neij = (vi \u2212 v\u0304i)>(vj \u2212 v\u0304j)\u221a (vi \u2212 v\u0304i)>(vi \u2212 v\u0304i) \u221a (vj \u2212 v\u0304j)>(vj \u2212 v\u0304j)\n(1)\nwhere vi \u2208 Rts, vi \u2208 Vs or Vt, and it is the average time series signal from the i-th ROI. ts is the number of time points of the ROI. In addition, the v\u0304i represents the mean vector corresponding to vi.\nThus, for the graph, the adjacency matrix Ak \u2208 RNk\u00d7Nk will be defined as:\nAkij = { 1, i = j\u2223\u2223eij\u2223\u2223, otherwise (2)\nwhere k represents source domain s or target domain t. At the same time, for simplicity and convenience, we describe the feature matrix Xk \u2208 RNk\u00d7Nk , of each graph through the correlation coefficient (i.e., Xkij = eij). According to the traditional GCN model, given the input feature matrix Xk and adjacency matrix Ak, the output of the l + 1-th hidden layer of the neural network H is:\nH(l+1) = \u03c3(D\u0303\u2212 1 2 AkD\u0303\u2212 1 2 H(l)W(l)) (3)\nwhere D\u0303\u2212 1 2 AkD\u0303\u2212 1 2 is the normalization of the adjacency matrix Ak, and D\u0303ii = \u03a3j Akij. W is the trainable weight matrix, that is, the parameters of the network; \u03c3(\u00b7) is the activation function, and the ReLU function is used here. H(l) represents the feature matrix of the layer l network. l = 0, then H = Xk.\n3.2.2. Node Attention Mechanism\nFor each graph, the potential impact of nodes/ROIs features learned from the GCN module on related brain diseases is different. Therefore, this paper proposes a node attention mechanism module to automatically mine the weight of nodes on the graph. See Figure 2 for details. After learning the node representation module, we naturally obtain new embedded representations of the source and target domains, that is, Hs \u2208 RN\u00d7D from the source domain graph and Ht \u2208 RN\u00d7D from the target domain graph. At this point, N = Ns = Nt, that is, the brains of subjects from different domains will be divided into the same number of functional areas. In addition, D = Ds = Dt. Then, max pooling is performed on Hk to generate the comprehensive representation of nodes, i.e., Hkmax. We send the composite node representations to the two fully connected layers respectively to automatically generate the node\u2019s attention score, i.e., Hkatt, and it is defined as:\nHkatt = \u03c3(W k Hkmax + B k) (4)\nwhere Bk is the bias term. The dimension of hidden layer of full connection layer is N, and N. The sigmoid function as a nonlinear activation function is used to constrain each element in the range [0, 1]. Among them, the ROIs that contribute more to the predicted results for the model will be assigned more weight, while the brain regions that contribute less will be assigned less weight.\nTherefore, the final node representation is expressed as:\nZk = Hkatt Hk + Hk (5)\nwhere represents the dot product operation, which weights the features of each extracted node.\n3.2.3. Domain Adaptation Module\nFor cross-domain classification, we propose to jointly optimize the three losses to reduce domain shift. Graph-level classification tasks typically use the readout operation to extract graph representations [37,38]. This can lead to missing important information, which can negatively affect feature alignment between domains. Therefore, we will choose to use mean absolute error (MAE) loss (LM) and CORAL loss [39] (LA) respectively to align features before and after the readout operation. MAE Loss LM: Considering the reality, we believe that, for the same disease and the same classification task, the node representation of the graph obtained from different domains should have a certain consistency.\nLM(Zs, Zt) = 1 N \u00d7M\u00d7 D N\n\u2211 i=1 |Zis \u2212 Zi t| (6)\nwhere M = Ms = Mt is the number of samples in source or target domains.\nCORAL Loss LA: First, readout graph-level representations of nodes using average pooling and max pooling:\nGk = 1 N\nN\n\u2211 i=1 Zik\u2016max i=1 N Zik (7)\nwhere \u2016 denotes concatenation. Meanwhile, CORAL loss is defined as the covariance distance of the features of source domain and target domain:\nLA(Gs, Gt) = 1\n4D2 \u2016Cs \u2212 Ct\u20162F (8)\nwhere \u2016 \u00b7 \u2016 represents the Frobenius norm. The covariance of source domain (Cs) or target domain (Ct) is:\nCk = 1 M\u2212 1 (Gi k>Gik \u2212 (I>Gik)>(I>Gik) M ) (9)\nwhere I is a column vector with all elements 1, and i \u2208 {1, \u00b7 \u00b7 \u00b7 , M}. Cross Entropy Loss LC . Take the cross entropy loss as the source domain classifier loss. Its objective is to minimize the classification loss of the source domain data when the data label is intact:\nLC( fC(Gs), Ys) = \u2212 1 Ms Ms\n\u2211 i=1\nYislog(Y\u0302i s ) (10)\nwhere Yis represents the real category label of the i-th graph of source domain, and Y\u0302i s represents the label prediction result of the i-th graph of source domain. We set two fully connected layers fC as the label classifier for the source domain.\nFinally, we obtain the overall objective function of model A2GCN:\nL = LC + \u03b31LM + \u03b32LA (11)\nwhere \u03b31 and \u03b32 are hyperparameters used to balance the contribution weights of LC , LM and LA."
        },
        {
            "heading": "3.3. Implementation",
            "text": "The proposed A2GCN model is implemented based on PyTorch platform. For fair comparison, we will use the same epoch and learning rate for all involved domain adaptation learning tasks, that is, the epoch is set to 150, the learning rate is 0.0001, and Adam is used as the optimizer to optimize the model. This A2GCN is composed of two layers of the graph convolution layer and two layers of the fully connected layer, and the output feature dimensions are set as 32 \u2192 32 \u2192 64 \u2192 2. The convolution layer is nonlinearly activated using the ReLU function, and the dropout of the fully connected layer is 0.4. In order to extract more discriminative pathological features and establish a cross-domain classification model with good performance, we divided the model training into two stages. According to Equation (11), we first pre-train the node representation learning and attention mechanism module for 50 epochs. LC is set to 0. Both the hyperparameters \u03b31 and \u03b32 are set to 1. In the second stage, the above modules and category classifiers are further jointly trained for 100 epochs through Equation (11), while both the balance parameters \u03b31 and \u03b32 are set to 0.5."
        },
        {
            "heading": "4. Experiments",
            "text": ""
        },
        {
            "heading": "4.1. Data",
            "text": "To evaluate the effectiveness of our proposed approach, we use NYU, UM, and UCLA from the public Autism Brain Imaging Data Exchange (ABIDE) website (http:// fcon_1000.projects.nitrc.org/indi/abide/ (accessed on 20 September 2022)) to validate our model. Meanwhile, the data from these three sites have also been used by Wang et al. [40]. Specifically, the NYU site included 164 subjects, including 71 with ASD and 93 with HC. The UM site included 113 subjects, 48 with ASD, and 65 with HC. The UCLA site included 74 subjects, 36 with ASD, and 38 with HC. We built the graph based on these three sites. The phenotypic information of the subjects involved in this study is shown in Table 2. The rs-fMRI data are from the Preprocessed Connectome Project initiative (http://preprocessed-connectomes-project.org (accessed on 20 September 2022)). Rs-fMRI data collected at different sites will be preprocessed by a widely accepted pipeline (the Configurable Pipeline for the Analysis of Connectomes (C-PAC) [41]). The steps of preprocessing mainly include: (1) slice timing, head motion correction, (2) nuisance signal regression (ventricular, cerebrospinal fluid (CSF), white matter signal, etc.), (3) template spatial standardization of the Montreal Neurological Institute (MNI) [42], and (4) temporal filtering. Then, we use the classical AAL atlas to divide each subject\u2019s brain into 116 functional regions and extract their average time series. Finally, each subject can generate a corresponding symmetric functional connectivity matrix based on the extracted signals, and the size of the matrix is 116\u00d7 116 (according to Equation (2)). The element of the matrix represents the PC between paired ROIs."
        },
        {
            "heading": "4.2. Experimental Settings",
            "text": "In this study, we will establish a classification model through four cross-site prediction tasks: NYU\u2192UM, NYU\u2192UCLA, UM\u2192NYU, UM\u2192UCLA. The dataset before the arrow is defined as the source domain, and the dataset after the arrow is set as the target domain. The source domain samples all contained complete category labels, while the target domain subjects had no label information. Considering the limited number of samples, we will use all source/target domain samples for training and testing all target domain subjects. In order to make the result more reasonable, we repeat the training process 10 times, and take the mean value and standard deviation of each algorithm as the final result. In this study, we will set seven metrics to evaluate the performance of the model, including: Accuracy (ACC), Precision (Pre), Recall (Rec), F1-Score (F1), Balanced accuracy (BAC), Negative predictive value (NPV), and Area under curve (AUC). The greater the value of these indexes, the better the classification performance of the model. These metrics are calculated as follows: ACC = TP+TNTP+FN+FP+TN , Pre = TP TP+FP , Rec = TP TP+FN , NPV = TN TN+FN , BAC = TP2(TP+FN)+ TN 2(TN+FP) , F1 = 2Pre\u00d7Rec Pre+Rec . The TN, TP, FN, and FP represent True Negative, True Positive, False Negative, and False Positive, respectively."
        },
        {
            "heading": "4.3. Competing Methods",
            "text": "In this work, we compare the proposed A2GCN with five single-domain models: (1) Degree centrality (DC), (2) Feature fusion using betweenness centrality and degree centrality (BD), (3) Feature fusion using betweenness centrality, degree centrality, and closeness centrality (BDC), (4) Deep neural networks (DNN), and (5) Graph convolutional networks (GCN). At the same time, we compare A2GCN with three state-of-the-art domain adaptation methods: (1) Cross-domain model based on multi-layer perceptron (DNNC), (2) Maximum Mean Discrepancy (MMD), and (3) Domain Adversarial Neural Network (DANN). More details of these competing methods are introduced below.\n(1) DC: This method measures the degree of nodes in the FCNs as the features of subjects. Specifically, according to Equation (2), for each subject, we can generate FCN of the size of 116\u00d7 116, where each element in FCN is the correlation coefficient between node pairs calculated by PC. First, the degree centrality (DC) indexes of each node in the FCN are calculated. Then, the model DC takes the 116\u00d7 1-dimensional feature vector representation obtained by computing DC for each subject as the input of the SVM classifier. (2) BD: This method combines the betweenness centrality (BC) and DC of nodes as the features of subjects. Based on Equation (2), the FCN of each subject is obtained, and then the BC and DC of nodes are respectively calculated. The BC and DC are concatenated into 232\u00d7 1-dimensional vectors according to rows, used as the input of SVM. (3) BDC: To mitigate the lack of information or noise pollution caused by manually defined features, we further calculate the BC, DC, and closeness centrality (CC) of the node of each subject FCN. The model BDC is further sequentially splicing the DC, BC, and CC values of each subject to form a feature representation of 348\u00d7 1-dimensional as the input of the SVM classifier. (4) DNN: According to the classical practice, we take the FCN of the subject in the upper triangle and pull it into a vector. In order to prevent dimensional disaster, the principal component analysis (PCA) algorithm limits the dimension of variables to 64 dimensions. Then, the features after dimensionality reduction are used as the input of model DNN. The model DNN is composed of two fully connected layers, and the output dimension is: 16\u2192 2. (5) GCN: GCN can combine the topological structure of the graph to deeply mine the potential information of nodes. Our A2GCN is inspired by GCN. Obviously, if we set \u03b31 = 0, \u03b32 = 0, A2GCN will crash to GCN. Similar to our proposed A2GCN method, first, we construct the source and target graphs, respectively, based on the FCNs of the subjects. Then, based on the source graphs, the cross entropy loss is optimized to train the classification model with good performance. Finally, the GCN model is applied directly to the target graphs to make prediction. The model GCN consists of two convolutional layers and two fully connected layers, and the output dimension is: 32\u2192 32\u2192 64\u2192 2. (6) DNNC: We transform our A2GCN model feature extractor GCN into multi-layer perceptron (MLP) to construct a simple cross-domain classification model. The model inputs are the same as the settings for the DNN model above. The output dimension of the network is set to 32 \u2192 2. At the same time, add CORAL loss minimization domain offset. The covariance between the sample features of the source domain and the target domain is defined as CORAL loss. Meanwhile, CORAL loss can minimize the domain offset without additional parameters. This method is basic and efficient, and it is also one of the losses used in our A2GCN. (7) MMD: The Maximum Mean Discrepancy (MMD) method aims to reduce differences of the domain distribution by MMD. This deep transfer model uses the GCN as a feature extractor. MAE loss and CORAL loss in our model are replaced by the MMD loss [9]. Then, the two-layer MLP is used as a category classifier for MMD. The number of neurons in the output layer of convolution layer and fully connected layer\nis consistent with our A2GCN method. The reference code (https://github.com/ jindongwang/transferlearning (accessed on 20 September 2022)) is publicly available.\n(8) DANN: The Domain Adversarial Neural Network (DANN) [43] is a domain adaptive method based on confrontational learning. The DANN method uses a gradient inversion layer (GRL) as Q\u03bb(x) = x with a reversal gradient \u2202Q\u03bb \u2202x = \u2212\u03bbI to train\na domain classifier. The adaptation parameter \u03bb of GRL refers to [43,44]. Here, x represents the representation of the extracted graph. The two-layer fully connected layer is used as the domain classifier of DANN to establish the adversarial loss. The hidden layer dimension is set to 64\u2192 2; the dropout is 0.4, and ReLU is responsible for nonlinear activation. Then, the two-layer MLP is used as a category classifier for DANN. Dimensions of the output layer of the convolution layer or fully connected layer are consistent with A2GCN.\nNote that the three conventional machine learning methods (i.e., DC, BD, and BDC) and two deep learning methods (i.e., DNN and GCN) are single-domain approaches, while the three deep learning methods (i.e., DNNC, MMD, and DANN) are state-of-the-art domain adaptation methods for cross-domain classification."
        },
        {
            "heading": "4.4. Results",
            "text": "The quantitative results of the A2GCN and several competing methods in ASD vs. HC classification will be reported in Table 3. We observe the following interesting findings.\n(1) The four cross-domain classification models (i.e., DNNC, MMD, DANN, and A2GCN) achieved better results in most cases compared with several single-domain classification models (i.e., DC, BDC, DNN, and GCN). This means that the introduction of domain adaptation learning module helps to enhance the classification performance of the model, which may benefit from the transferable feature representation across sites learned by the model. (2) Graph-based (i.e., GCN, MMD, DANN, and A2GCN)) methods usually produce better classification results than traditional classical methods based on manually defined node features (i.e., DC, BD, and BDC) and network embeddings (i.e., DNN and DNNC). Because these traditional methods only consider the characteristics of nodes, however, those methods that use GCN as feature extractors can update and aggregate the features of nodes on the graph end-to-end with the help of the underlying topology information of FCNs, in order to learn more discriminative node representation, which may be more beneficial for ASD auxiliary diagnosis. (3) The experimental results of the proposed A2GCN consistently outperform all competing methods. This indicates that A2GCN can achieve effective domain adaptation and reduce data distribution differences, thus improving the robustness of the model. (4) Compared with three advanced cross-domain methods (i.e., DNNC, MMD, and DANN), our proposed A2GCN method has a competitive advantage in various domain adaptation tasks. This may be because our method adds node attention mechanism modules, which can make intelligent use of different contributions of brain regions. Meanwhile, our method adopts MAE loss and CORAL loss to align different domains step by step. These operations can partially alleviate the negative effects of noisy areas."
        },
        {
            "heading": "4.5. Ablation Study",
            "text": "The proposed A2GCN contains two key components, namely, node attention mechanism module and domain adaptation module. To evaluate the contribution of these two parts, we compare the proposed A2GCN with its three variants:\n(1) A2GCN_A: Similar to the A2GCN method, firstly, the source graph and the target graph are respectively constructed based on the subject\u2019s FCNs. Then, the node representation on the source graph is learned based on GCN. At the same time, the node attention mechanism model mentioned in Section 3.2.2 is added to set different weight values for different nodes/brain regions of the source graph. Then, cross entropy is used to calculate the classification loss. Finally, the model trained in the source domain is applied to the prediction of the target domain graph. (2) A2GCN_M: First, based on the subject\u2019s FCNs, the model constructs the source graph and the target graph respectively. Then, according to the node representation learning module in Section 3.2.1, the node features on the source graph and the target graph are simultaneously learned based on GCN. Then, the node attention mechanism module in Section 3.2.2 is added, and the weighted node features are used to calculate the MAE loss between domains (domain adaptation module). Finally, the cross entropy is used to calculate the classification loss. (3) A2GCN_C: First, the model uses FCNs to construct source and target graphs. Like A2GCN, this model learns the node features of different domains based on GCN according to the node representation learning module in Section 3.2.1. Then, after the readout operation, the CORAL loss (domain adaptation module) between domains is calculated based on the extracted graph representation vector. The cross entropy is used to calculate the classification loss of the source domain.\nIn Figure 3, we report the corresponding ACC and AUC values. As shown in Figure 3, we can find that the performance of three variants A2GCN_A (without domain adaptation module), A2GCN_M (with attention mechanism module and part of domain adaptation module), and A2GCN_C (without domain attention mechanism module) are significantly\ndegraded in the corresponding transfer learning task. In particular, A2GCN_A achieved the worst performance in most cases. The underlying reason could be that attention mechanisms play a role in extracting more discriminative features. In addition, it also shows that using MAE loss and CORAL loss to align the learned features step by step during training can reduce the data information loss caused by readout-related pooling operations, thus significantly improving the robustness and transmission performance of A2GCN. More results on the influence of parameters and model pre-training can be found in Supplementary Materials."
        },
        {
            "heading": "5. Discussion",
            "text": ""
        },
        {
            "heading": "5.1. Visualization of Data Distribution",
            "text": "To visually demonstrate the features learned through the proposed A2GCN, we use the t-SNE [45] tool to visualize the data distribution of different imaging sites before and after domain adaptation. In Figure 4, the blue and red dots represent the source and target domains, respectively. To visualize the regional heterogeneity before domain adaptation, we flattened the upper triangle of the FCN matrix for each sample of each site. The vector representation is obtained, which is further reduced to 64 dimensions by the PCA method as the original representation of the sample. From Figure 4a, we can observe that there is a significant domain shift between the distribution of the source domain and the target domain. We use the t-SNE algorithm to visualize feature distribution of the source and target domains after the feature extractor GCN in different cross-site classification tasks (through A2GCN), with results reported in Figure 4b. In Figure 4b, red and blue dots are closely clustered together. This means that the distributions of the node representations of the two domains learned by our method are close, and the domain heterogeneity has been substantially reduced. At the same time, we calculated the Frobenius norm of the covariance (CF) between samples in the source domain and the target domain, which is used to measure the difference of data distribution between different sites. It is observed that the CF between different sites is significantly reduced after domain adaptation. These results show that A2GCN can effectively extract transferable features and reduce domain shift."
        },
        {
            "heading": "5.2. Most Informative Brain Regions",
            "text": "One of the main focuses of this work is to use interpretable deep learning algorithms to discover the underlying differences between ASD and HC subjects. An interesting question is to identify the most informative brain regions for ASD detection. In the task of \u201cNYU\u2192UM\u201d, we randomly select 10 subjects from the UM site. We then extract the features of these subjects after the attention mechanism module, select 19 brain regions with strong correlation, and visualize them using BrainNet [46] tool, with results shown in Figure 5. In Figure 5, the color of brain regions is randomly assigned, and the stick-like connections between brain regions indicate strong FC between them. For ASD vs. HC\nclassification, we find that the most informative brain regions include the hippocampus, parahippocampal gyrus, putamen lentiform, and the vicinity of thalamus, which is also consistent with previous studies [47,48]. It validates the potential application value of our model in the discovery of rs-fMRI biomarkers for ASD identification, thus helping to improve the interpretability of learning algorithms in automated brain disease detection."
        },
        {
            "heading": "5.3. Limitations and Future Work",
            "text": "Although our proposed A2GCN method has achieved good results in the prediction of ASD, there is still challenging work to be considered in the future. First, in our current work, only knowledge transfer between a single source domain and a target domain is considered. It is also interesting to explore the shared features of multiple source domains to reduce the heterogeneity of data and thus improve the learning performance of the target domain. Second, the size of the training sample is relatively small. We hope to add unlabeled samples from other public datasets to assist in pre-training the proposed network in a semi-supervised learning manner, aiming to further improve model generalization capability [49]."
        },
        {
            "heading": "6. Conclusions",
            "text": "In this paper, we construct a multi-site unsupervised rs-fMRI domain adaptation framework (A2GCN) with an attention mechanism for ASD diagnosis. The framework automatically extracts rs-fMRI features from brain FCNs with the help of the GCN model. The attention mechanism is used to explore the contribution of different brain regions to the automatic detection of brain diseases and explore the interpretable features of brain regions. In addition, our method explores mean absolute error and covariance-based constraints to alleviate data distribution differences among imaging sites. We evaluate our proposed method using rs-fMRI data from a real multi-site dataset (ABIDE). Experimental results show that the A2GCN has significant advantages over several advanced methods.\nSupplementary Materials: The following supporting information can be downloaded at: https: //www.mdpi.com/article/10.3390/brainsci12101413/s1, Figure S1: Classification performance by the proposed model based on different parametric values. The abscissa represents the ratio of MAE loss to CORAL loss (\u03b31:\u03b32) during model training; Figure S2: Impact of pre-training times on model classification results. The abscissa represents the epoch values set during the pre-training process.\nAuthor Contributions: Conceptualization, M.L.; methodology, Y.C.; software, Y.C.; investigation, Y.C.; writing\u2014original draft preparation, Y.C.; writing\u2014review and editing, L.Q. and H.R.; supervision, M.L.; project administration, M.L. and L.Q. All authors have read and agreed to the published version of the manuscript.\nFunding: This research received no external funding.\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability Statement: All data used in this study are available from the corresponding author on reasonable request.\nAcknowledgments: Y.C, H.R., and L.Q. were partly supported by the National Natural Science Foundation of China (Nos. 62176112, 61976110 and 11931008), the Taishan Scholar Program of Shandong Province, and the Natural Science Foundation of Shandong Province (No. ZR202102270451).\nConflicts of Interest: The authors declare no conflict of interest."
        }
    ],
    "title": "Resting-State Functional MRI Adaptation with Attention Graph Convolution Network for Brain Disorder Identification",
    "year": 2022
}