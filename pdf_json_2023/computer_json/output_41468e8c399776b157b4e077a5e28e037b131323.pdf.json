{
    "abstractText": "Modern text classification systems have impressive capabilities but are infeasible to deploy and use reliably due to their dependence on prompting and billion-parameter language models. SetFit (Tunstall et al., 2022) is a recent, practical approach that fine-tunes a Sentence Transformer under a contrastive learning paradigm and achieves similar results to more unwieldy systems. Text classification is important for addressing the problem of domain drift in detecting harmful content, which plagues all social media platforms. Here, we propose Like a Good Nearest Neighbor (LAGONN), an inexpensive modification to SetFit that requires no additional parameters or hyperparameters but modifies input with information about its nearest neighbor, for example, the label and text, in the training data, making novel data appear similar to an instance on which the model was optimized. LAGONN is effective at the task of detecting harmful content and generally improves SetFit\u2019s performance. To demonstrate LAGONN\u2019s value, we conduct a thorough study of text classification systems in the context of content moderation under four label distributions.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Luke Bates"
        },
        {
            "affiliations": [],
            "name": "Iryna Gurevych"
        }
    ],
    "id": "SP:b0b89c4b78f6d15a7f5287c99578ad04e892bd3e",
    "references": [
        {
            "authors": [
                "Neel Alex",
                "Eli Lifland",
                "Lewis Tunstall",
                "Abhishek Thakur",
                "Pegah Maham",
                "C. Jess Riedel",
                "Emmie Hine",
                "Carolyn Ashurst",
                "Paul Sedille",
                "Alexis Carlier",
                "Michael Noetel",
                "Andreas Stuhlm\u00fcller"
            ],
            "title": "RAFT: A real-world few-shot text classification",
            "year": 2021
        },
        {
            "authors": [
                "Valerio Basile",
                "Cristina Bosco",
                "Elisabetta Fersini",
                "Debora Nozza",
                "Viviana Patti",
                "Francisco Manuel Rangel Pardo",
                "Paolo Rosso",
                "Manuela Sanguinetti"
            ],
            "title": "SemEval-2019 task 5: Multilingual detection of hate speech against immigrants",
            "year": 2019
        },
        {
            "authors": [
                "Thomas Davidson",
                "Dana Warmsley",
                "Michael Macy",
                "Ingmar Weber"
            ],
            "title": "Automated hate speech",
            "year": 2017
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association",
            "year": 2019
        },
        {
            "authors": [
                "Ullrich K.H. Ecker",
                "Stephan Lewandowsky",
                "John Cook",
                "Philipp Schmid",
                "Lisa K. Fazio",
                "Nadia Brashier",
                "Panayiota Kendeou",
                "Emily K. Vraga",
                "Michelle A. Amazeen"
            ],
            "title": "The psychological drivers of misinformation belief and its resistance",
            "year": 2022
        },
        {
            "authors": [
                "Gregory Koch",
                "Richard Zemel",
                "Ruslan Salakhutdinov"
            ],
            "title": "Siamese neural networks for one-shot image recognition",
            "venue": "In ICML Deep Learning Workshop,",
            "year": 2015
        },
        {
            "authors": [
                "Haokun Liu",
                "Derek Tam",
                "Mohammed Muqeeth",
                "Jay Mohta",
                "Tenghao Huang",
                "Mohit Bansal",
                "Colin Raffel."
            ],
            "title": "Few-shot parameter-efficient finetuning is better and cheaper than in-context learning",
            "venue": "arXiv preprint arXiv:2205.05638.",
            "year": 2022
        },
        {
            "authors": [
                "Jiachang Liu",
                "Dinghan Shen",
                "Yizhe Zhang",
                "Bill Dolan",
                "Lawrence Carin",
                "Weizhu Chen"
            ],
            "title": "What makes good in-context examples for GPT-3",
            "venue": "In Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction",
            "year": 2022
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Christopher D. Manning",
                "Prabhakar Raghavan",
                "Hinrich Sch\u00fctze."
            ],
            "title": "Introduction to Information Retrieval",
            "venue": "Cambridge University Press, USA.",
            "year": 2008
        },
        {
            "authors": [
                "Todor Markov",
                "Chong Zhang",
                "Sandhini Agarwal",
                "Tyna Eloundou",
                "Teddy Lee",
                "Steven Adler",
                "Angela Jiang",
                "Lilian Weng."
            ],
            "title": "A holistic approach to undesired content detection",
            "venue": "arXiv preprint arXiv:2208.03274.",
            "year": 2022
        },
        {
            "authors": [
                "James O\u2019Neill",
                "Polina Rozenshtein",
                "Ryuichi Kiryo",
                "Motoko Kubota",
                "Danushka Bollegala"
            ],
            "title": "I wish I would have loved this one, but I didn\u2019t \u2013 a multilingual dataset for counterfactual detection in product review",
            "venue": "In Proceedings of the 2021 Conference",
            "year": 2021
        },
        {
            "authors": [
                "Christian S. Perone",
                "Roberto Pereira Silveira",
                "Thomas S. Paula."
            ],
            "title": "Evaluation of sentence embeddings in downstream and linguistic probing tasks",
            "venue": "arXiv preprint arXiv:1806.06259.",
            "year": 2018
        },
        {
            "authors": [
                "Guangyuan Piao."
            ],
            "title": "Scholarly text classification with sentence bert and entity embeddings",
            "venue": "Trends and Applications in Knowledge Discovery and Data Mining, pages 79\u201387, Cham. Springer International Publishing.",
            "year": 2021
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "SentenceBERT: Sentence embeddings using Siamese BERTnetworks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu-",
            "year": 2019
        },
        {
            "authors": [
                "Stephen Robertson",
                "Hugo Zaragoza."
            ],
            "title": "The probabilistic relevance framework: Bm25 and beyond",
            "venue": "Found. Trends Inf. Retr., 3(4):333\u2013389.",
            "year": 2009
        },
        {
            "authors": [
                "Timo Schick",
                "Hinrich Sch\u00fctze."
            ],
            "title": "Exploiting cloze-questions for few-shot text classification and natural language inference",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Vol-",
            "year": 2021
        },
        {
            "authors": [
                "Timo Schick",
                "Hinrich Sch\u00fctze."
            ],
            "title": "It\u2019s not just size that matters: Small language models are also few-shot learners",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
            "year": 2021
        },
        {
            "authors": [
                "Timo Schick",
                "Hinrich Sch\u00fctze."
            ],
            "title": "True fewshot learning with Prompts\u2014A real-world perspective",
            "venue": "Transactions of the Association for Computational Linguistics, 10:716\u2013731.",
            "year": 2022
        },
        {
            "authors": [
                "Yusuke Shido",
                "Hsien-Chi Liu",
                "Keisuke Umezawa."
            ],
            "title": "Textual content moderation in C2C marketplace",
            "venue": "Proceedings of the Fifth Workshop on e-Commerce and NLP (ECNLP 5), pages 58\u201362, Dublin, Ireland. Association for Computational Lin-",
            "year": 2022
        },
        {
            "authors": [
                "Kaitao Song",
                "Xu Tan",
                "Tao Qin",
                "Jianfeng Lu",
                "TieYan Liu."
            ],
            "title": "Mpnet: Masked and permuted pretraining for language understanding",
            "venue": "Advances in Neural Information Processing Systems, volume 33, pages 16857\u201316867. Curran Associates, Inc.",
            "year": 2020
        },
        {
            "authors": [
                "Robyn Speer",
                "Joshua Chin",
                "Catherine Havasi"
            ],
            "title": "Conceptnet 5.5: An open multilingual graph of general knowledge",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2017
        },
        {
            "authors": [
                "Lewis Tunstall",
                "Nils Reimers",
                "Unso Eun Seo Jo",
                "Luke Bates",
                "Daniel Korat",
                "Moshe Wasserblat",
                "Oren Pereg."
            ],
            "title": "Efficient few-shot learning without prompts",
            "venue": "arXiv preprint arXiv:2209.11055.",
            "year": 2022
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141 ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc.",
            "year": 2017
        },
        {
            "authors": [
                "Soroush Vosoughi",
                "Deb Roy",
                "Sinan Aral."
            ],
            "title": "The spread of true and false news online",
            "venue": "Science, 359(6380):1146\u20131151.",
            "year": 2018
        },
        {
            "authors": [
                "Alex Wang",
                "Yada Pruksachatkun",
                "Nikita Nangia",
                "Amanpreet Singh",
                "Julian Michael",
                "Felix Hill",
                "Omer Levy",
                "Samuel Bowman."
            ],
            "title": "Superglue: A stickier benchmark for general-purpose language understanding systems",
            "venue": "Advances in Neural Infor-",
            "year": 2019
        },
        {
            "authors": [
                "Shuohang Wang",
                "Yichong Xu",
                "Yuwei Fang",
                "Yang Liu",
                "Siqi Sun",
                "Ruochen Xu",
                "Chenguang Zhu",
                "Michael Zeng."
            ],
            "title": "Training data is more valuable than you think: A simple and effective method by retrieving from training data",
            "venue": "Proceedings of the",
            "year": 2022
        },
        {
            "authors": [
                "William Yang Wang."
            ],
            "title": "Liar, liar pants on fire\u201d: A new benchmark dataset for fake news detection",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 422\u2013426, Vancouver, Canada.",
            "year": 2017
        },
        {
            "authors": [
                "Teven Le Scao",
                "Sylvain Gugger",
                "Mariama Drame",
                "Quentin Lhoest",
                "Alexander Rush."
            ],
            "title": "Transformers: State-of-the-art natural language processing",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing:",
            "year": 2020
        },
        {
            "authors": [
                "Yichong Xu",
                "Chenguang Zhu",
                "Shuohang Wang",
                "Siqi Sun",
                "Hao Cheng",
                "Xiaodong Liu",
                "Jianfeng Gao",
                "Pengcheng He",
                "Michael Zeng",
                "Xuedong Huang."
            ],
            "title": "Human parity on commonsenseqa: Augmenting self-attention with external attention",
            "venue": "arXiv",
            "year": 2021
        },
        {
            "authors": [
                "Meng Ye",
                "Karan Sikka",
                "Katherine Atwell",
                "Sabit Hassan",
                "Ajay Divakaran",
                "Malihe Alikhani."
            ],
            "title": "Multilingual content moderation: A case study on reddit",
            "venue": "arXiv preprint arXiv:2302.09618.",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Text classification is the most important tool for NLP practitioners, and there has been substantial progress in advancing the state-of-the-art, especially with the advent of large, pretrained language models (PLM) (Devlin et al., 2019). Modern research focuses on in-context learning (Brown et al., 2020), pattern exploiting training (Schick and Sch\u00fctze, 2021a,b, 2022), or parameter efficient fine-tuning (Liu et al., 2022a). State-of-theart methods have achieved impressive results on the SuperGLUE (Wang et al., 2019) and RAFT (Alex et al., 2021) few-shot benchmarks. However, they are difficult to use because of their reliance on\n1Code and data: https://github.com/UKPLab/lagonn"
        },
        {
            "heading": "LaGoNN LaGoNN",
            "text": "billion-parameter PLMs and prompt engineering. Constructing prompts is not trivial and may require domain expertise.\nOne exception to these cumbersome systems is SetFit. SetFit does not rely on prompting or billion-parameter PLMs, and instead fine-tunes a pretrained Sentence Transformer (ST) (Reimers and Gurevych, 2019) under a contrastive learning paradigm. SetFit has comparable performance to more unwieldy systems while being one to two orders of magnitude faster to train and run inference.\nAn important application of text classification is aiding or automating content moderation, which is the task of determining the appropriateness of user-generated content on the Internet (Roberts, 2017). From fake news to toxic comments to hate speech, it is difficult to browse social media without being exposed to potentially dangerous posts that may have an effect on our ability to reason (Ecker et al., 2022). Misinformation spreads at alarming\nar X\niv :2\n30 2.\n08 95\n7v 2\n[ cs\n.C L\n] 2\nM ar\n2 02\n3\nrates (Vosoughi et al., 2018), and an ML system should be able to quickly aid human moderators. While there is work in NLP with this goal (Markov et al., 2022; Shido et al., 2022; Ye et al., 2023), a general, practical and open-sourced method that is effective across multiple domains remains an open challenge. Novel fake news topics or racial slurs emerge and change constantly. Retraining of ML-based systems is required to adapt this concept drift, but this is expensive, not only in terms of computation, but also in terms of the human effort needed to collect and label data.\nSetFit\u2019s performance, speed, and low cost would make it ideal for effective content moderation, however, this type of text classification poses a challenge for even state-of-the-art approaches. For example, detecting hate speech on Twitter (Basile et al., 2019), a subtask on the RAFT few-shot benchmark, appears to be the most difficult dataset; at time of writing, it is the only task where the human baseline has not been surpassed, yet SetFit is among the top ten most performant systems.2\nHere, we propose a modification to SetFit, called Like a Good Nearest Neighbor (LAGONN). LAGONN introduces no parameters or hyperparameters and instead modifies input text by retrieving information about the nearest neighbor (NN) seen during optimization (see Figure 1). Specifically, we append the label, distance, and text of the NN in the training data to a new instance and encode this modified version with an ST. By making input data appear more similar to instances seen during training, we inexpensively exploit the ST\u2019s pretrained or fine-tuned knowledge when considering a novel example. Our method can also be applied to the linear probing of an ST, requiring no expensive fine-tuning of the large embedding model. Finally, we propose a simple alteration to the SetFit training procedure, where we fine-tune the ST on a subset of the training data. This results in a more efficient and performant text classifier that can be used with LAGONN. We summarize our contributions as follows:\n1. We propose LAGONN, an inexpensive modification to SetFit- or ST-based text classification.\n2. We suggest an alternative training procedure to the standard fine-tuning of SetFit, that can\n2https://huggingface.co/spaces/ought/ raft-leaderboard (see \"Tweet Eval Hate\").\nbe used with or without LAGONN, and results in a cheaper system with similar performance to the more expensive SetFit.\n3. We perform an extensive study of LAGONN, SetFit, and standard transformer fine-tuning in the context of content moderation under different label distributions."
        },
        {
            "heading": "2 Related Work",
            "text": "There is not much work on using sentence embeddings as features for classification despite the pioneering work being roughly five years old (Perone et al., 2018). STs are pretrained with the objective of maximizing the distance between semantically distinct text and minimizing the distance between text that is semantically similar in feature space. They are composed of a Siamese and triplet architecture that encodes text into dense vectors which can be used as features for ML. STs were first used to encode text for classification by Piao (2021), however, the authors relied on pretrained representations.\nSetFit uses a contrastive learning paradigm from computer vision (Koch et al., 2015) to fine-tune STs. The embedding model is fine-tuned with a distance-based loss function, like cosine similarity, such that examples belonging to different labels are separated in feature space. This approach can relatively easily and quickly train a strong, few-shot text classifier, transforming the ST from a sentence encoder to a topic encoder.\nMost related to LAGONN is work done by Xu et al. (2021), who showed that retrieving and concatenating text from training data and external sources, such as ConceptNet (Speer et al., 2017) and the Wikitionary3 definition, can be viewed as a type of external attention that does not modify the architecture of the Transformer in question answering. Liu et al. (2022b) used PLMs, including STs, and k-NN lookup to prepend examples that are similar to a GPT-3 query sample to aid in prompt engineering for in-context learning. Wang et al. (2022) demonstrated that prepending and appending training data can benefit PLMs in the tasks of summarization, language modelling, machine translation, and question answering, using BM25 as their retrieval model for speed (Manning et al., 2008; Robertson and Zaragoza, 2009).\nWe alter the SetFit training procedure by using fewer examples to adapt the embedding model for\n3https://www.wiktionary.org/\nmany-shot learning. LAGONN decorates input text with its nearest neighbor\u2019s gold label, Euclidean distance, and text from the training data to exploit the ST\u2019s optimized representations. Compared to retrieval-based methods, LAGONN uses the same model for both retrieval and encoding, which can be fine-tuned via SetFit. We only retrieve information from the training data for text classification."
        },
        {
            "heading": "3 Like a Good Nearest Neighbor",
            "text": "Xu et al. (2021) formulate a type of external attention, where textual information is retrieved from\nmultiple sources and added to text input to give the model stronger reasoning ability without altering the internal architecture. Inspired by this approach, LAGONN exploits pretrained and finetuned knowledge through external attention, but the information we retrieve comes only from data used during optimization. We consider an embedding function, f , that is called on both training and test data, f(Xtrain) and f(Xtest). Considering its success and speed on realistic, few-shot data and our goal of practical content moderation, we choose an ST that can be fine-tuned with SetFit as our\nembedding function.\nEncoding training data and nearest neighbors LAGONN first uses a pretrained Sentence Transformer to embed training text in feature space, f(Xtrain). We perform NN lookup with scikitlearn (Buitinck et al., 2013) on the resulting embeddings and query the second closest NN (k=2). We do not use the NN because it is the example itself.\nNearest neighbor information We extract text from the second nearest neighbor and use it to decorate the original example. We experimented with different text that LAGONN could use. The first configuration we consider is the gold label and Euclidean distance of the NN, which we call LABEL. We then considered the gold label, distance, and the text of the NN, which we refer to as TEXT. Finally, we tried the same format as TEXT but for all possible labels, which we call BOTH (see Table 1 and Figure 2).4 Information from the second NN is appended to the text following a separator token to indicate this instance is composed of multiple sequences. While the BOTH and TEXT configurations are arguably the most interesting, we find LABEL to result in the most performant version of LAGONN, and this is the version about which we report results.\nTraining LAGONN encodes the modified training data and optionally fine-tunes the embedding model via SetFit, f(Xtrainmod). After finetuning, we train a classifier CLF (f(Xtrainmod)), like logistic regression.\nInference LAGONN uses information from the nearest neighbor in the training data to modify input text. We compute the embeddings on the test data, f(Xtest), and query the NN lookup, selecting the NN (k=1) in the training data and extracting information from the training text. LAGONN then decorates the input instance with information from the NN in the training data. Finally, we encode the modified data with the embedding model and call the classifier, CLF (f(Xtestmod)).\nIntuition As f is the same function, we hypothesize that LAGONN\u2019s modifications will make a novel instance more semantically similar to its NNs in the training data. The resulting representation should be more akin to an instance on which the embedding model and classifier were optimized.\n4LAGONN requires a mapping from the label to the text the label represents, for example, 0 \u2013 positive and 1 \u2013 negative.\nOur method also leverages both distance-based (NN lookup) and probabilistic algorithms (logistic regression) for its final prediction."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Data and label distributions",
            "text": "In our experiments, we study LAGONN\u2019s performance on four binary and one ternary classification dataset related to the task of content moderation. Each dataset is composed of a training, validation, and test split.\nHere, we provide a summary of the five datasets we studied. LIAR was created from Politifact5 for fake news detection and is composed of the data fields context, speaker, and statement, which are labeled with varying levels of truthfulness (Wang, 2017). We used a collapsed version of this dataset where a statement can only be true or false. We did not use speaker, but did use context and statement, separated by a separator token. Quora Insincere Questions6 is composed of neutral and toxic questions, where the author is not asking in good faith. Hate Speech Offensive7 has three labels and is composed of tweets that can contain either neutral text, offensive language, or hate speech (Davidson et al., 2017). Amazon Counterfactual8 contains sentences from product reviews, and the labels can be \"factual\" or \"counterfactual\" (O\u2019Neill et al., 2021). \"Counterfactual\" indicates that the customer said something that cannot be true. Finally, Toxic Conversations9 is a dataset of comments where the author wrote a comment with unintended bias10 (see Table 2). We study our system by simulating growing training data over ten discrete steps sampled under four different label distributions: extreme, imbalanced, moderate, and balanced (see Table 3). On each step we add 100 examples (100 on the first, 200 on the second, etc.) from the training split sampled under one of the four ratios.11 On each\n5https://www.politifact.com/ 6https://www.kaggle.com/c/\nquora-insincere-questions-classification 7https://huggingface.co/datasets/hate_speech_ offensive 8https://huggingface.co/datasets/SetFit/ amazon_counterfactual_en 9https://huggingface.co/datasets/SetFit/toxic_ conversations 10https://www.kaggle.com/c/ jigsaw-unintended-bias-in-toxicity-classification/ overview\n11For Hate Speech Offensive, 0 and 2 denote undesirable text and 1 denotes neither.\nstep, we train our method with the sampled data and evaluate on the test split. Considering growing training data has two benefits: 1) We can simulate a streaming data scenario, where new data is labeled and added for training and 2) We can investigate each method\u2019s sensitivity to the number of training examples. We sampled over five seeds, reporting the mean and standard deviation."
        },
        {
            "heading": "4.2 Baselines",
            "text": "We compare LAGONN against standard finetuning, linear probing of a Sentence Transformer, and two versions of SetFit, detailed below.\nRoBERTa RoBERTa-base is a pretrained language model (Liu et al., 2019) that we fine-tuned with the transformers library (Wolf et al., 2020). We select two versions of RoBERTa-base: an expensive version, where we perform standard finetuning on each step (RoBERTafull) and a cheaper version, where we freeze the model body after step one and update the classification head on subsequent steps (RoBERTafreeze). We set the learning rate to 1e\u22125, train for a maximum of 70 epochs, and use early stopping, selecting the best model after training. We consider RoBERTafull an upper bound as it has the most trainable parameters and requires the most time to train of all our methods.\nLinear probe We perform linear probing of a pretrained Sentence Transformer by fitting logistic regression with default hyperparameters on the training embeddings on each step. We choose this\nbaseline because LAGONN can be applied as a modification in this scenario. We select MPNET (Song et al., 2020) as the ST, for SetFit, and for LAGONN.12 We refer to this method as Probe.\nLogistic regression Here, we perform standard fine-tuning with SetFit on the first step, and then on subsequent steps, freeze the embedding model and retrain only the classification head. We choose this baseline as LAGONN also uses logistic regression as its final classifier and refer to this method as Log Reg.\nk-nearest neighbors Similar to the above baseline, we fine-tune the embedding model via SetFit, but swap out the classification head for a kNN classifier, where k = 3. We select this baseline as LAGONN also relies on an NN lookup. k = 3 was chosen during our development stage as it yielded the strongest performance. We refer to this method as kNN.\nSetFit For this baseline we perform standard fine-tuning with SetFit on each step. On the first step, this method is equivalent to Log Reg.\nLAGONN cheap This method modifies the training and test data via LAGONN before fitting a logistic regression classifier. Even without adapting the embedding model, as the training data grow, modifications made to the test data may change. We refit the classification head on each step and refer to this method as LAGONNcheap, which is comparable to Probe.\nLAGONN On the first step, we use LAGONN to modify our training data and then perform standard fine-tuning with SetFit. On subsequent steps, we freeze the embedding model and use it to modify our data. We fit logistic regression on each step and refer to this method as LAGONN. It is comparable to Log Reg.\nLAGONN expensive This version is identical to LAGONN, except we fine-tune the embedding model on each step. We refer to this method as LAGONNexp and it is comparable to SetFit. On the first step, this method is equivalent to LAGONN."
        },
        {
            "heading": "5 Results",
            "text": "Table 4 and Figure 3 show our results. In the cases of the extreme and imbalanced regimes, Set-\n12https://huggingface.co/sentence-transformers/ paraphrase-mpnet-base-v2\nFit\u2019s performance steadily increases with the number of training examples. As the label distribution shifts to the balanced regime, however, SetFit\u2019s performance quickly saturates or even degrades as the number of training examples grows. LAGONN, RoBERTafull, and Log Reg, other finetuned PLM classifiers, do not exhibit this behavior. LAGONNexp, being based on SetFit, exhibits a similar trend, but the performance degradation is mitigated; on the 10th step of Amazon Counterfactual in Table 4 SetFit\u2019s performance decreased by\n9.7, while LAGONNexp only fell by 3.7.\nLAGONN and LAGONNexp generally outperform Log Reg and SetFit, respectively, often resulting in a more stable model, as reflected in the standard deviation. We find that LAGONN and LAGONNexp exhibit stronger predictive power with fewer examples than RoBERTafull despite having fewer trainable parameters. For example, on the first step of Insincere Questions under the extreme setting, LAGONN\u2019s performance is more than 10 points higher.\nLAGONNcheap outperforms all other methods on the Insincere Questions dataset for all balance regimes, despite being the third fastest (see Table 5) and having the second fewest trainable parameters. We attribute this result to the fact that this dataset is composed of questions from Quora13 and our ST backbone was pretrained on similar data. This intuition is supported by Probe, the cheapest method, which despite having the fewest trainable parameters, shows comparable performance."
        },
        {
            "heading": "5.1 SetFit for efficient many-shot learning",
            "text": "Respectively comparing SetFit to Log Reg and LAGONNexp to LAGONN suggests that finetuning the ST embedding model on moderate or balanced data hurts model performance as the number of training samples grows. We therefore hypothesize that randomly sampling a subset of training data to fine-tune the encoder, freezing, embedding the remaining data, and training the classifier will result in a stronger model.\nTo test our hypothesis, we add two models to our experimental setup: SetFitlite and LAGONNlite. SetFitlite and LAGONNlite are respectively equivalent to SetFit and LAGONNexp, except after the fourth step (400 samples), we freeze the encoder and only retrain the classifier on subsequent steps, similar to Log Reg and LAGONN.\nFigure 4 shows our results with these two new 13https://www.quora.com/\nmodels. As expected, in the cases of extreme and imbalanced distributions, LAGONNexp, SetFit, and RoBERTaexp, are the strongest performers on Toxic Conversations. We note very different results for both LAGONNlite and SetFitlite compared to LAGONNexp and SetFit on Toxic Conversations and Amazon Counterfactual under the moderate and balanced label distributions. As their expensive counterparts start to plateau or degrade on the fourth step, the predictive power of these two new models dramatically increases, showing improved or comparable performance to RoBERTafull, despite being optimized on less data; for example, LAGONNlite reaches an average precision of approximately 55 after being optimized on only 500 examples. RoBERTafull does not exhibit similar performance until the tenth step. Finally, we point out that LAGONN-based methods generally provide a performance boost for SetFit-based classification."
        },
        {
            "heading": "5.2 LAGONN\u2019s computational expense",
            "text": "LAGONN is more computationally expensive than Sentence Transformer- or SetFit-based text classification. LAGONN introduces additional inference with the encoder, NN-lookup, and string modification. As the computational complexity of transformers increases with sequence length (Vaswani et al., 2017), additional expense is created when LAGONN appends textual information before in-\nference with the ST. In Table 5, we provide a speed comparison between Probe, Log Reg, SetFit, and LAGONN classification computed on the same hardware. On average, LAGONN introduced 24.2 additional seconds of computation compared to its relative counterpart."
        },
        {
            "heading": "6 Discussion",
            "text": "Modern research has achieved impressive results on a variety of text classification tasks and with limited training data. SetFit is one such example and can be used practically, but based on our results, the task of text classification for content moderation presents a challenge even for state-of-the-art approaches. It is imperative that we develop reliable methods that can be feasibly and quickly applied. These methods should be as inexpensive as possible such that we can re-tune them for novel forms of hate speech, toxicity, and fake news.\nOur results suggest that LAGONNexp or SetFit, relatively expensive techniques, can detect harmful content when dealing with imbalanced label distributions, as is common with realistic datasets. This finding is intuitive from the perspective that less common instances are more difficult to learn and require more effort. The exception to this would be our examination of Insincere Questions, where LAGONNcheap excelled. This highlights the fact that we can inexpensively extract pretrained knowledge if PLMs are chosen with care.\nStandard fine-tuning with SetFit does not help performance on more balanced datasets that are not few-shot. SetFit was developed for few-shot learning, but we have observed that it should not be applied \"out of the box\" to balanced, non-fewshot data. This can be detrimental to performance and has a direct effect on our approach. However,\nwe have observed that LAGONN can stabilize SetFit\u2019s predictions and reduce its performance drop. Figures 3 and 4 show that when the label distribution is moderate or balanced (see Table 3), SetFit plateaus, yet less expensive systems, such as LAGONN, continue to learn. We believe this is due to SetFit\u2019s fine-tuning objective, which optimizes a Sentence Transformer using cosine similarity loss to separate examples belonging to different labels in feature space by assuming independence between labels. This may be too strong an assumption as we optimize with more examples, which is counter-intuitive for data-hungry transformers. RoBERTafull, optimized with cross-entropy loss, generally showed improved performance as we added training data.\nWhen dealing with balanced data, it is sufficient to fine-tune the Sentence Transformer via SetFit with 50 to 100 examples per label, while 150 to 200 instances appear to be sufficient when the training data are moderately balanced. The encoder can then be frozen and all available data embedded to train a classifier. This improves performance and is more efficient than full-model fine-tuning. LAGONN is directly applicable to this case, boosting the performance of SetFitlite without introducing trainable parameters. In this setup, all models fine-tuned on Hate Speech Offensive exhibited similar, upward-trending learning curves, but we note the speed of LAGONN relative to RoBERTafull or SetFit (see Figure 4 and Table 5)."
        },
        {
            "heading": "7 Conclusion",
            "text": "We have proposed LAGONN, a simple and inexpensive modification to Sentence Transformer- or SetFit-based text classification. LAGONN does not introduce any trainable parameters or new hyperparameters, but typically improves SetFit\u2019s performance. To demonstrate the merit of LAGONN, we examined text classification systems in the context of content moderation under four label distributions on five datasets and with growing training data. To our knowledge, this is the first work to examine SetFit in this way. When the training labels are imbalanced, expensive systems, such as LAGONNexp are performant. However, when the distribution is balanced, standard fine-tuning with SetFit can actually hurt model performance. We have therefore proposed an alternative fine-tuning procedure to which LAGONN can be easily utilized, resulting in a powerful, but inexpensive system capable of\ndetecting harmful content."
        },
        {
            "heading": "8 Acknowledgments",
            "text": "We would like to thank Derek Hommel and Nils Reimers for sharing inspiring discussions with us. We would also like to extend our gratitude to Tom Aarsen, Max Glockner, Yongxin Huang, Timour Igamberdiev, Sukannya Purkayastha, and Kexin Wang for their invaluable feedback on an early draft of our manuscript. This work was funded by the German Federal Ministry of Education and Research and the Hessian Ministry of Science and the Arts (HMWK) within the projects \"The Third Wave of Artificial Intelligence - 3AI\", hessian.AI, and within their joint support of the National Research Center for Applied Cybersecurity ATHENE."
        },
        {
            "heading": "9 Limitations",
            "text": "In the current work, we have only considered text data, but social media content can of course consist of text, images, and videos. As LAGONN depends only on an embedding model, an obvious extension to our approach would be examining the modifications we suggest, but on multimodal data. This is an interesting direction that we leave for future research. We have also considered English data, but harmful content can appear in any language. The authors demonstrated that SetFit is performant on multilingual data, the only necessary modification being the underlying pretrained ST. We therefore suspect that LAGONN would behave similarly on non-English data, but this is not something we have tested ourselves. In order to examine our system\u2019s performance under different label-balance distributions, we restricted ourselves to binary and ternary text classification tasks, and LAGONN therefore remains untested when there are more than three labels. We did not study our method when there are fewer than 100 examples, and investigating LAGONN in a few-shot learning setting is fascinating topic for future study."
        },
        {
            "heading": "10 Ethics Statement",
            "text": "It is our sincere goal that our work contributes to the social good multiple ways. We first hope to have furthered research on text classification that can be feasibly applied to combat undesirable content, such as misinformation, on the Internet, which could potentially cause someone harm. To this end, we have tried to describe our approach as accurately as possible and released our code, such that\nour work is transparent and can be easily reproduced and expanded upon. We hope that we have also created a useful but efficient system which reduces the need to expend energy in the form expensive computation. For example, LAGONN does not rely on billion-parameter language models that demand thousand-dollar GPUs to use. LAGONN makes use of GPUs no more than SetFit, despite being more computationally expensive. We have additionally proposed a simple method to make SetFit, an already relatively inexpensive method, even more efficient."
        },
        {
            "heading": "A Appendix",
            "text": ""
        },
        {
            "heading": "A.1 Observations about LAGONN",
            "text": "Our original goal was to construct a system that did not need to be updated after step one and could simply perform inference on subsequent steps, an active learning setup. While the performance of this version of LAGONN did not degrade, it also did not appear to learn anything and we found it necessary update parameters on each step. We additionally tried fine-tuning the embedding model via SetFit first before modifying data, however, this hurt performance in all cases. We include this information for transparency and because we find it interesting.\nA.2 Additional results for initial experiments\nHere we provide additional results from our initial experimental setup that, due to space limitations, could not be included in the main text. We note that a version of LAGONN outperforms or has the same performance of all methods, including our upper bound RoBERTafull, on 54% of all displayed results, and is the best performer relative to Sentence Transformer-based methods on 72%. This excludes LAGONNcheap. This method showed strong performance on the Insincere Questions dataset, but hurts performance in other cases. In cases, when SetFit-based methods do outperform our system, the performances are comparable, yet they can be quite dramatic when LAGONN-based methods are the strongest. Below, we report the mean average precision \u00d7100 for all methods over five seeds with the standard deviation, except in the case of Hate Speech Offensive, where the evaluation metric is the macro-F1. Each table shows the results for given dataset and a given label-balance distribution on the first, fifth, and ten step followed by the average for all ten steps. The Liar dataset seems to be the most difficult for all methods. This is expected because it does not include enough context to determine the truth of a statement."
        },
        {
            "heading": "Method Toxic Conversations",
            "text": ""
        },
        {
            "heading": "Method Toxic Conversations",
            "text": ""
        },
        {
            "heading": "Method Toxic Conversations",
            "text": ""
        },
        {
            "heading": "Method Toxic Conversations",
            "text": "A.3 Additional results for second experiment\nHere we provide additional results from our second set of experiments that, due to space limitations, could not be included in the main text. We note that a version of LAGONN outperforms or has the same performance of all methods, including our upper bound RoBERTafull, on 60% of all displayed results, and is the best performer relative to Sentence Transformer-based methods on 65%. This excludes LAGONNcheap. This method showed strong performance on the Insincere Questions dataset, but hurts performance in other cases. In cases, when SetFit-based methods do outperform our system, the performances are comparable, yet they can be quite dramatic when LAGONN-based methods are the strongest. Below, we report the mean average precision \u00d7100 for all methods over five seeds with the standard deviation, except in the case of Hate Speech Offensive, where the evaluation metric is the macro-F1. Each table shows the results for given dataset and a given label-balance distribution on the first, fifth, and ten step followed by the average for all ten steps. Liar appears to be the most difficult dataset for all methods. This is expected because it does not include enough context to determine the truth of a statement."
        },
        {
            "heading": "Method Toxic Conversations",
            "text": ""
        },
        {
            "heading": "Method Toxic Conversations",
            "text": ""
        },
        {
            "heading": "Method Amazon Counterfactual",
            "text": ""
        },
        {
            "heading": "Method Hate Speech Offensive",
            "text": ""
        },
        {
            "heading": "Method Hate Speech Offensive",
            "text": ""
        },
        {
            "heading": "Method Hate Speech Offensive",
            "text": ""
        },
        {
            "heading": "Method Toxic Conversations",
            "text": ""
        },
        {
            "heading": "Method Toxic Conversations",
            "text": "A.4 Examples of LAGONN modified text WARNING: Some of the examples below are of an offensive nature. Please view with caution.\nIn this section, we provide examples of how LAGONNexp modifies test text from the datasets we studied under the BOTH configuration. We choose this configuration because the information it appends from a NN in the training data to a test instance encapsulates both the LABEL and the TEXT configuration. LAGONNexp was trained under a balanced distribution and five examples per label were chosen randomly on the first, fifth, and tenth step to demonstrate how the same test instance might be decorated with different training examples as the training data grow. We recognize that some the images below are difficult to see and have made the images and .csv files available with our code and data files. Note that MPNET\u2019s separator token is </s>, not [SEP]."
        }
    ],
    "title": "Like a Good Nearest Neighbor: Practical Content Moderation with Sentence Transformers",
    "year": 2023
}