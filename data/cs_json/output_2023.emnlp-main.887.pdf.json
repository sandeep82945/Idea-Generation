{
    "abstractText": "In Natural Language Generation (NLG) tasks, for any input, multiple communicative goals are plausible, and any goal can be put into words, or produced, in multiple ways. We characterise the extent to which human production varies lexically, syntactically, and semantically across four NLG tasks, connecting human production variability to aleatoric or data uncertainty. We then inspect the space of output strings shaped by a generation system\u2019s predicted probability distribution and decoding algorithm to probe its uncertainty. For each test input, we measure the generator\u2019s calibration to human production variability. Following this instance-level approach, we analyse NLG models and decoding strategies, demonstrating that probing a generator with multiple samples and, when possible, multiple references, provides the level of detail necessary to gain understanding of a model\u2019s representation of uncertainty.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Mario GiulianelliM\u2217Joris BaanM"
        },
        {
            "affiliations": [],
            "name": "Wilker Aziz"
        },
        {
            "affiliations": [],
            "name": "Raquel Fern\u00e1ndez"
        },
        {
            "affiliations": [],
            "name": "Barbara Plank"
        }
    ],
    "id": "SP:59c396085dcd5b5627712b71d56ccf046f9d1b25",
    "references": [
        {
            "authors": [
                "Laura Aina",
                "Tal Linzen."
            ],
            "title": "The language model understood the prompt was ambiguous: Probing syntactic uncertainty through generation",
            "venue": "Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 42\u2013",
            "year": 2021
        },
        {
            "authors": [
                "Fernando Alva-Manchego",
                "Louis Martin",
                "Antoine Bordes",
                "Carolina Scarton",
                "Beno\u00eet Sagot",
                "Lucia Specia."
            ],
            "title": "ASSET: A dataset for tuning and evaluation of sentence simplification models with multiple rewriting transformations",
            "venue": "Proceedings of the 58th",
            "year": 2020
        },
        {
            "authors": [
                "Fernando Alva-Manchego",
                "Carolina Scarton",
                "Lucia Specia."
            ],
            "title": "The (Un)Suitability of Automatic Evaluation Metrics for Text Simplification",
            "venue": "Computational Linguistics, 47(4):861\u2013889.",
            "year": 2021
        },
        {
            "authors": [
                "John Langshaw Austin."
            ],
            "title": "How to do things with words",
            "venue": "Clarendon Press, Oxford.",
            "year": 1975
        },
        {
            "authors": [
                "Joris Baan",
                "Wilker Aziz",
                "Barbara Plank",
                "Raquel Fernandez."
            ],
            "title": "Stop measuring calibration when humans disagree",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing.",
            "year": 2022
        },
        {
            "authors": [
                "Joris Baan",
                "Nico Daheim",
                "Evgenia Ilia",
                "Dennis Ulmer",
                "Haau-Sing Li",
                "Raquel Fern\u00e1ndez",
                "Barbara Plank",
                "Rico Sennrich",
                "Chrysoula Zerva",
                "Wilker Aziz."
            ],
            "title": "Uncertainty in natural language generation: From theory to applications",
            "venue": "arXiv preprint",
            "year": 2023
        },
        {
            "authors": [
                "Claartje Barkhof",
                "Wilker Aziz."
            ],
            "title": "Statistical model criticism of variational auto-encoders",
            "venue": "arXiv preprint arXiv:2204.03030.",
            "year": 2022
        },
        {
            "authors": [
                "Anja Belz",
                "Ehud Reiter."
            ],
            "title": "Comparing automatic and human evaluation of NLG systems",
            "venue": "11th Conference of the European Chapter of the Association for Computational Linguistics, pages 313\u2013 320, Trento, Italy. Association for Computational",
            "year": 2006
        },
        {
            "authors": [
                "Christopher M. Bishop."
            ],
            "title": "Pattern Recognition and Machine Learning (Information Science and Statistics)",
            "venue": "Springer-Verlag, Berlin, Heidelberg.",
            "year": 2006
        },
        {
            "authors": [
                "Ond\u0159ej Bojar",
                "Christian Buck",
                "Christian Federmann",
                "Barry Haddow",
                "Philipp Koehn",
                "Johannes Leveling",
                "Christof Monz",
                "Pavel Pecina",
                "Matt Post",
                "Herve SaintAmand",
                "Radu Soricut",
                "Lucia Specia",
                "Ale\u0161 Tamchyna"
            ],
            "title": "Findings of the 2014 workshop",
            "year": 2014
        },
        {
            "authors": [
                "Sebastian Borgeaud",
                "Guy Emerson."
            ],
            "title": "Leveraging sentence similarity in natural language generation: Improving beam search using range voting",
            "venue": "Proceedings of the Fourth Workshop on Neural Generation and Translation, pages 97\u2013109, Online.",
            "year": 2020
        },
        {
            "authors": [
                "Elia Bruni",
                "Raquel Fern\u00e1ndez."
            ],
            "title": "Adversarial evaluation for open-domain dialogue generation",
            "venue": "Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue, pages 284\u2013288, Saarbr\u00fccken, Germany. Association for Computational",
            "year": 2017
        },
        {
            "authors": [
                "Hyung Won Chung",
                "Le Hou",
                "Shayne Longpre",
                "Barret Zoph",
                "Yi Tay",
                "William Fedus",
                "Eric Li",
                "Xuezhi Wang",
                "Mostafa Dehghani",
                "Siddhartha Brahma"
            ],
            "title": "Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416",
            "year": 2022
        },
        {
            "authors": [
                "Lorenzo De Mattei",
                "Huiyuan Lai",
                "Felice Dell\u2019Orletta",
                "Malvina Nissim"
            ],
            "title": "Human perception in natural language generation",
            "venue": "In Proceedings of the 1st Workshop on Natural Language Generation,",
            "year": 2021
        },
        {
            "authors": [
                "Mingkai Deng",
                "Bowen Tan",
                "Zhengzhong Liu",
                "Eric Xing",
                "Zhiting Hu."
            ],
            "title": "Compression, transduction, and creation: A unified framework for evaluating natural language generation",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural",
            "year": 2021
        },
        {
            "authors": [
                "Yuntian Deng",
                "Volodymyr Kuleshov",
                "Alexander Rush."
            ],
            "title": "Model criticism for long-form text generation",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2022
        },
        {
            "authors": [
                "Armen Der Kiureghian",
                "Ove Ditlevsen"
            ],
            "title": "Aleatory or epistemic? Does it matter",
            "venue": "Structural safety,",
            "year": 2009
        },
        {
            "authors": [
                "Shrey Desai",
                "Greg Durrett."
            ],
            "title": "Calibration of pre-trained transformers",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 295\u2013302, Online. Association for Computational Linguistics.",
            "year": 2020
        },
        {
            "authors": [
                "Daniel Deutsch",
                "Rotem Dror",
                "Dan Roth."
            ],
            "title": "On the limitations of reference-free evaluations of generated text",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 10960\u201310977, Abu Dhabi, United Arab",
            "year": 2022
        },
        {
            "authors": [
                "Bryan Eikema",
                "Wilker Aziz."
            ],
            "title": "Is MAP decoding all you need? the inadequacy of the mode in neural machine translation",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 4506\u20134520, Barcelona, Spain (Online). Inter-",
            "year": 2020
        },
        {
            "authors": [
                "Bryan Eikema",
                "Wilker Aziz."
            ],
            "title": "Sampling-based approximations to minimum Bayes risk decoding for neural machine translation",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 10978\u201310993, Abu",
            "year": 2022
        },
        {
            "authors": [
                "Angela Fan",
                "Mike Lewis",
                "Yann Dauphin."
            ],
            "title": "Hierarchical neural story generation",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 889\u2013898, Melbourne, Australia. Association",
            "year": 2018
        },
        {
            "authors": [
                "Patrick Fernandes",
                "Ant\u00f3nio Farinhas",
                "Ricardo Rei",
                "Jos\u00e9 G.C. de Souza",
                "Perez Ogayo",
                "Graham Neubig",
                "Andre Martins."
            ],
            "title": "Quality-aware decoding for neural machine translation",
            "venue": "Proceedings of the 2022 Conference of the North American Chap-",
            "year": 2022
        },
        {
            "authors": [
                "Marina Fomicheva",
                "Shuo Sun",
                "Lisa Yankovskaya",
                "Fr\u00e9d\u00e9ric Blain",
                "Francisco Guzm\u00e1n",
                "Mark Fishel",
                "Nikolaos Aletras",
                "Vishrav Chaudhary",
                "Lucia Specia."
            ],
            "title": "Unsupervised quality estimation for neural machine translation",
            "venue": "Transactions of the Association",
            "year": 2020
        },
        {
            "authors": [
                "Sebastian Gehrmann",
                "Elizabeth Clark",
                "Thibault Sellam."
            ],
            "title": "Repairing the cracked foundation: A survey of obstacles in evaluation practices for generated text",
            "venue": "arXiv preprint arXiv:2202.06935. 14359",
            "year": 2022
        },
        {
            "authors": [
                "Sebastian Gehrmann",
                "Hendrik Strobelt",
                "Alexander Rush."
            ],
            "title": "GLTR: Statistical detection and visualization of generated text",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 111\u2013116,",
            "year": 2019
        },
        {
            "authors": [
                "Mario Giulianelli",
                "Raquel Fern\u00e1ndez."
            ],
            "title": "Analysing human strategies of information transmission as a function of discourse context",
            "venue": "Proceedings of the 25th Conference on Computational Natural Language Learning, pages 647\u2013660, Online.",
            "year": 2021
        },
        {
            "authors": [
                "Mario Giulianelli",
                "Sarenne Wallbridge",
                "Raquel Fern\u00e1ndez."
            ],
            "title": "Information value: Measuring utterance predictability as distance from plausible alternatives",
            "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2023
        },
        {
            "authors": [
                "Taisiya Glushkova",
                "Chrysoula Zerva",
                "Ricardo Rei",
                "Andr\u00e9 F.T. Martins."
            ],
            "title": "Uncertainty-aware machine translation evaluation",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3920\u20133938, Punta Cana, Dominican Republic.",
            "year": 2021
        },
        {
            "authors": [
                "Joseph Y Halpern."
            ],
            "title": "Reasoning about uncertainty",
            "venue": "MIT press.",
            "year": 2017
        },
        {
            "authors": [
                "Tatsunori B. Hashimoto",
                "Hugh Zhang",
                "Percy Liang."
            ],
            "title": "Unifying human and statistical evaluation for natural language generation",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-",
            "year": 2019
        },
        {
            "authors": [
                "Ari Holtzman",
                "Jan Buys",
                "Li Du",
                "Maxwell Forbes",
                "Yejin Choi."
            ],
            "title": "The curious case of neural text degeneration",
            "venue": "International Conference on Learning Representations.",
            "year": 2019
        },
        {
            "authors": [
                "Eyke H\u00fcllermeier",
                "Willem Waegeman."
            ],
            "title": "Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods",
            "venue": "Machine Learning, 110(3):457\u2013506.",
            "year": 2021
        },
        {
            "authors": [
                "Kristiina Jokinen."
            ],
            "title": "Goal formulation based on communicative principles",
            "venue": "COLING 1996 Volume 2: The 16th International Conference on Computational Linguistics.",
            "year": 1996
        },
        {
            "authors": [
                "Daphne Koller",
                "Nir Friedman."
            ],
            "title": "Probabilistic graphical models: principles and techniques",
            "venue": "MIT press.",
            "year": 2009
        },
        {
            "authors": [
                "Lorenz Kuhn",
                "Yarin Gal",
                "Sebastian Farquhar."
            ],
            "title": "Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation",
            "venue": "International Conference on Learning Representations.",
            "year": 2022
        },
        {
            "authors": [
                "Willem JM Levelt."
            ],
            "title": "Speaking: From intention to articulation",
            "venue": "MIT press.",
            "year": 1993
        },
        {
            "authors": [
                "Stephen C Levinson."
            ],
            "title": "Pragmatics",
            "venue": "Cambridge University Press.",
            "year": 1983
        },
        {
            "authors": [
                "Jiwei Li",
                "Michel Galley",
                "Chris Brockett",
                "Jianfeng Gao",
                "Bill Dolan."
            ],
            "title": "A diversity-promoting objective function for neural conversation models",
            "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
            "year": 2016
        },
        {
            "authors": [
                "Yanran Li",
                "Hui Su",
                "Xiaoyu Shen",
                "Wenjie Li",
                "Ziqiang Cao",
                "Shuzi Niu."
            ],
            "title": "DailyDialog: A manually labelled multi-turn dialogue dataset",
            "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),",
            "year": 2017
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "ROUGE: A package for automatic evaluation of summaries",
            "venue": "Text Summarization Branches Out, pages 74\u201381, Barcelona, Spain. Association for Computational Linguistics.",
            "year": 2004
        },
        {
            "authors": [
                "Ryan Lowe",
                "Michael Noseworthy",
                "Iulian Vlad Serban",
                "Nicolas Angelard-Gontier",
                "Yoshua Bengio",
                "Joelle Pineau."
            ],
            "title": "Towards an automatic Turing test: Learning to evaluate dialogue responses",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for",
            "year": 2017
        },
        {
            "authors": [
                "David JC MacKay."
            ],
            "title": "Information theory, inference and learning algorithms",
            "venue": "Cambridge University Press.",
            "year": 2003
        },
        {
            "authors": [
                "Andrey Malinin",
                "Mark Gales."
            ],
            "title": "Uncertainty estimation in autoregressive structured prediction",
            "venue": "International Conference on Learning Representations.",
            "year": 2020
        },
        {
            "authors": [
                "Clara Meister",
                "Ryan Cotterell."
            ],
            "title": "Language model evaluation beyond perplexity",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
            "year": 2021
        },
        {
            "authors": [
                "Clara Meister",
                "Martina Forster",
                "Ryan Cotterell."
            ],
            "title": "Determinantal beam search",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
            "year": 2021
        },
        {
            "authors": [
                "Cotterell."
            ],
            "title": "Locally typical sampling",
            "venue": "Transac-",
            "year": 2023
        },
        {
            "authors": [
                "Marc\u2019Aurelio Ranzato"
            ],
            "title": "Analyzing uncertainty",
            "year": 2018
        },
        {
            "authors": [
                "Jing Zhu"
            ],
            "title": "Bleu: a method for automatic evalu",
            "year": 2002
        },
        {
            "authors": [
                "Ilya Sutskever"
            ],
            "title": "Improving language under",
            "year": 2018
        },
        {
            "authors": [
                "Wei Li",
                "Peter J Liu"
            ],
            "title": "Exploring the limits",
            "year": 2020
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "SentenceBERT: Sentence embeddings using Siamese BERTnetworks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu-",
            "year": 2019
        },
        {
            "authors": [
                "Harvey Sacks",
                "Emanuel A. Schegloff",
                "Gail Jefferson."
            ],
            "title": "A simplest systematics for the organization of turn-taking for conversation",
            "venue": "Language, 50(4):696\u2013735.",
            "year": 1974
        },
        {
            "authors": [
                "Ananya B. Sai",
                "Akash Kumar Mohankumar",
                "Siddhartha Arora",
                "Mitesh M. Khapra."
            ],
            "title": "Improving dialog evaluation with a multi-reference adversarial dataset and large scale pretraining",
            "venue": "Transactions of the Association for Computational Linguistics, 8:810\u2013",
            "year": 2020
        },
        {
            "authors": [
                "John R Searle."
            ],
            "title": "Speech acts: An essay in the philosophy of language, volume 626",
            "venue": "Cambridge University Press.",
            "year": 1969
        },
        {
            "authors": [
                "Thibault Sellam",
                "Dipanjan Das",
                "Ankur Parikh."
            ],
            "title": "BLEURT: Learning robust metrics for text generation",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7881\u20137892, Online. Association for Computational",
            "year": 2020
        },
        {
            "authors": [
                "Raphael Shu",
                "Hideki Nakayama",
                "Kyunghyun Cho."
            ],
            "title": "Generating diverse translations with sentence codes",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1823\u20131827, Florence, Italy. Association for Compu-",
            "year": 2019
        },
        {
            "authors": [
                "Koustuv Sinha",
                "Prasanna Parthasarathi",
                "Jasmine Wang",
                "Ryan Lowe",
                "William L. Hamilton",
                "Joelle Pineau."
            ],
            "title": "Learning an unreferenced metric for online dialogue evaluation",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational",
            "year": 2020
        },
        {
            "authors": [
                "Katherine Stasaski",
                "Marti Hearst."
            ],
            "title": "Semantic diversity in dialogue with natural language inference",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
            "year": 2022
        },
        {
            "authors": [
                "Katherine Stasaski",
                "Marti A Hearst."
            ],
            "title": "Pragmatically appropriate diversity for dialogue evaluation",
            "venue": "arXiv preprint arXiv:2304.02812.",
            "year": 2023
        },
        {
            "authors": [
                "Mirac Suzgun",
                "Luke Melas-Kyriazi",
                "Dan Jurafsky."
            ],
            "title": "Follow the wisdom of the crowd: Effective text generation via minimum bayes risk decoding",
            "venue": "arXiv preprint arXiv:2211.07634. 14361",
            "year": 2022
        },
        {
            "authors": [
                "Guy Tevet",
                "Jonathan Berant."
            ],
            "title": "Evaluating the evaluation of diversity in natural language generation",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 326\u2013346, Online.",
            "year": 2021
        },
        {
            "authors": [
                "J\u00f6rg Tiedemann",
                "Santhosh Thottingal."
            ],
            "title": "OPUSMT \u2014 Building open translation services for the World",
            "venue": "Proceedings of the 22nd Annual Conferenec of the European Association for Machine Translation (EAMT), Lisbon, Portugal.",
            "year": 2020
        },
        {
            "authors": [
                "Chris van der Lee",
                "Albert Gatt",
                "Emiel van Miltenburg",
                "Emiel Krahmer."
            ],
            "title": "Human evaluation of automatically generated text: Current trends and best practice guidelines",
            "venue": "Computer Speech & Language, 67:101151.",
            "year": 2021
        },
        {
            "authors": [
                "Ashwin Vijayakumar",
                "Michael Cogswell",
                "Ramprasaath Selvaraju",
                "Qing Sun",
                "Stefan Lee",
                "David Crandall",
                "Dhruv Batra."
            ],
            "title": "Diverse beam search for improved description of complex scenes",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Nathaniel Weir",
                "Jo\u00e3o Sedoc",
                "Benjamin Van Durme."
            ],
            "title": "COD3S: Diverse generation with discrete semantic signatures",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5199\u20135211, Online. As-",
            "year": 2020
        },
        {
            "authors": [
                "Gian Wiher",
                "Clara Meister",
                "Ryan Cotterell."
            ],
            "title": "On decoding strategies for neural text generators",
            "venue": "Transactions of the Association for Computational Linguistics, 10:997\u20131012.",
            "year": 2022
        },
        {
            "authors": [
                "Wei Xu",
                "Chris Callison-Burch",
                "Courtney Napoles."
            ],
            "title": "Problems in current text simplification research: New data can help",
            "venue": "Transactions of the Association for Computational Linguistics, 3:283\u2013297.",
            "year": 2015
        },
        {
            "authors": [
                "Wei Xu",
                "Courtney Napoles",
                "Ellie Pavlick",
                "Quanze Chen",
                "Chris Callison-Burch."
            ],
            "title": "Optimizing statistical machine translation for text simplification",
            "venue": "Transactions of the Association for Computational Linguistics, 4:401\u2013415.",
            "year": 2016
        },
        {
            "authors": [
                "Weizhe Yuan",
                "Graham Neubig",
                "Pengfei Liu."
            ],
            "title": "BARTScore: Evaluating generated text as text generation",
            "venue": "Advances in Neural Information Processing Systems, volume 34, pages 27263\u201327277. Curran Associates, Inc.",
            "year": 2021
        },
        {
            "authors": [
                "Tianyi Zhang",
                "Varsha Kishore",
                "Felix Wu",
                "Kilian Q. Weinberger",
                "Yoav Artzi."
            ],
            "title": "BERTScore: Evaluating text generation with BERT",
            "venue": "International Conference on Learning Representations.",
            "year": 2020
        },
        {
            "authors": [
                "Xingxing Zhang",
                "Yiran Liu",
                "Xun Wang",
                "Pengcheng He",
                "Yang Yu",
                "Si-Qing Chen",
                "Wayne Xiong",
                "Furu Wei."
            ],
            "title": "Momentum calibration for text generation",
            "venue": "arXiv preprint arXiv:2212.04257.",
            "year": 2022
        },
        {
            "authors": [
                "Yizhe Zhang",
                "Siqi Sun",
                "Michel Galley",
                "Yen-Chun Chen",
                "Chris Brockett",
                "Xiang Gao",
                "Jianfeng Gao",
                "Jingjing Liu",
                "Bill Dolan."
            ],
            "title": "DIALOGPT : Largescale generative pre-training for conversational response generation",
            "venue": "Proceedings of the 58th An-",
            "year": 2020
        },
        {
            "authors": [
                "Yao Zhao",
                "Misha Khalman",
                "Rishabh Joshi",
                "Shashi Narayan",
                "Mohammad Saleh",
                "Peter J Liu."
            ],
            "title": "Calibrating sequence likelihood improves conditional language generation",
            "venue": "arXiv preprint arXiv:2210.00045.",
            "year": 2022
        },
        {
            "authors": [
                "Ming Zhong",
                "Yang Liu",
                "Da Yin",
                "Yuning Mao",
                "Yizhu Jiao",
                "Pengfei Liu",
                "Chenguang Zhu",
                "Heng Ji",
                "Jiawei Han."
            ],
            "title": "Towards a unified multidimensional evaluator for text generation",
            "venue": "arXiv preprint arXiv:2210.07197.",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 14349\u201314371 December 6-10, 2023 \u00a92023 Association for Computational Linguistics"
        },
        {
            "heading": "1 Introduction",
            "text": "Humans display great variability in language production, in particular when the context or the task are open-ended, such as in storytelling or in dialogue. Given a story prompt, for example, there are many plausible ways in which different humans (or a single writer, if asked multiple times) may tell the story (Fan et al., 2018). We refer to this phenomenon as production variability. Production variability in humans has two main sources. First, when situated in a context, speakers may entertain variable communicative goals (Searle, 1969; Sacks et al., 1974; Austin, 1975), and the number and variety of plausible communicative goals depends on the production task (Jokinen, 1996). Translation, for instance, defines the communicative goal almost unequivocally while a dialogue context might allow for a wide variety of communicative goals (expressed, e.g., as a request, an assertion,\n\u2217Equal contribution. 1https://github.com/dmg-illc/nlg-uncertainty-probes\nor a yes-no question). The second source of variability is the fact that even when context and communicative goal are fixed, speakers\u2019 linguistic realisations of the communicative goal may vary (Levelt, 1993). Both sources of variability apply to individuals as well as to populations: if an expert is asked to simplify a complicated sentence multiple times, they may perform different rewriting transformations (e.g., paraphrasing, reordering, or sentence splitting) and produce different texts (Alva-Manchego et al., 2021); the same is true if multiple experts are asked to perform a task (Xu et al., 2015). If we are to regard a Natural Language Generation (NLG) system (or text generator) as a good model of human production, it should capture the variability observed in humans.\nText generators combine two mechanisms: (i) an underlying statistical model\u2014typically, an autoregressive factorisation of the probability of sequences, with conditional token probabilities predicted by a neural network; and (ii) an iterative decoding algorithm that chains samples from next token distributions into a complete production. To-\n14349\ngether these two mechanisms specify a probability distribution over sequences of tokens, which can be regarded as a representation of the model\u2019s uncertainty about productions for a given generation context (see Baan et al. (2023) for a detailed discussion). In this work, we assess whether this representation of uncertainty is in compliance with production variability exhibited by a population of humans\u2014which in turn, we argue, can be regarded as an expression of aleatoric uncertainty, i.e., irreducible uncertainty due to the stochastic nature of the data generating process (Der Kiureghian and Ditlevsen, 2009; H\u00fcllermeier and Waegeman, 2021). In other words, we compare the distribution over productions of a text generator against the distribution over the productions of a population of human speakers, given the same context (Figure 1).\nQuantifying the closeness in distribution between a text generator and a human population is difficult: we only have an iterative view into the generator\u2019s distribution; the \u2018human distribution\u2019 is an implicit or even hypothetical object; and in both cases, the sample space is large or even unbounded. We can, however, compare these two objects via the samples they produce and assess their statistical distance\u2014which is what we propose here. For each individual generation context, we compare scalar properties of generations (through repeated model sampling) and human productions (using multireference NLG datasets). In particular, we probe for lexical, syntactic, and semantic distance between productions, thus allowing for a quantitative and interpretable assessment of uncertainty.\nWe find that the uncertainty of neural text generators is higher than justified by human production variability in open-ended tasks, like story generation and open-domain dialogue; and that it is lower on more constrained tasks, like machine translation and text simplification. Popular decoding algorithms, which bias away from the distribution of the generator\u2019s underlying statistical model (e.g., top-k, top-p, or locally typical, rather than ancestral sampling), have a limited impact on the generator\u2019s ability to faithfully represent human variability. We complement our quantitative assessments with a detailed analysis of individual generation contexts, which sheds light on whether a generator has robustly learned to reproduce degrees and aspects of human variability plausible for the communicative task.\nBeyond the experimental results obtained on our\nselection of models and tasks, our work has important implications for NLG evaluation and data collection. Multiple samples and, when possible, multiple references, should be used to assess the statistical fit of text generators. Our approach, complementary to other types of automatic evaluation, makes model assessments particularly insightful and trustworthy because it does not judge a model only by a single output but also, intuitively, by what it could have generated\u2014and it does so for each individual input in the test set. We therefore hope our framework will be used by the community as an evaluation criterion for NLG systems, especially to assess them in more open-ended tasks."
        },
        {
            "heading": "2 Related Work",
            "text": "Automatic approaches to the evaluation of NLG systems are of high practical importance: they allow for model selection at scale and power qualityaware decoding algorithms (Borgeaud and Emerson, 2020; Eikema and Aziz, 2020; Fernandes et al., 2022; Suzgun et al., 2022). In spite of their known limitations (Gehrmann et al., 2022), they are a necessary complement to human evaluation (Belz and Reiter, 2006; van der Lee et al., 2021).\nReference-based evaluation. The most common way of automatically evaluating text generators is via metrics that estimate the similarity between candidate generations and references, such as BLEU (Papineni et al., 2002), ROUGE (Lin, 2004), COMET (Rei et al., 2020), BLEURT (Sellam et al., 2020), and BertScore (Zhang et al., 2020a). Reference-based metrics are less suited for open-ended tasks such as story generation and dialogue, where a single reference (or even a handful) cannot be representative of the large space of plausible communicative goals and realisations.\nReference-free evaluation. A popular, referencefree alternative is to train evaluation models that discriminate human from model output (e.g., Bruni and Fern\u00e1ndez, 2017; Gehrmann et al., 2019; Hashimoto et al., 2019), score the appropriateness of input-output pairs (e.g., Sinha et al., 2020; Fomicheva et al., 2020), or model human judgements directly (e.g., Lowe et al., 2017; De Mattei et al., 2021; Rei et al., 2021). Neural language models themselves have been proposed as evaluators (e.g., Yuan et al., 2021; Deng et al., 2021) and used to assess generations along interpretable evaluation dimensions (Zhong\net al., 2022), yet they have been criticised for being biased (toward models similar to the evaluator) and thus limited in their ability to evaluate generated text (Deutsch et al., 2022).\nStatistical evaluation. Statistical evaluation compares model generations to human productions in distribution through real-valued statistics (e.g., Zipf\u2019s coefficient, type-token ratio, length) as opposed to strings themselves. These statistics are typically compared marginally, at the corpus level (Eikema and Aziz, 2020; Meister and Cotterell, 2021; Pillutla et al., 2021; Pimentel et al., 2022), supporting general claims about model performance in relation to humans. More recently, Barkhof and Aziz (2022) and Deng et al. (2022) compared statistics at the instance level, supporting claims about models\u2019 performance in relation to humans for individual inputs. In this work, we craft statistics that evaluate generators\u2019 uncertainty at the instance level against the variability over sequences observed in multi-reference NLG datasets. Although evaluating uncertainty is gaining traction in NLP (e.g., Desai and Durrett, 2020; Glushkova et al., 2021; Baan et al., 2022), there is relatively little work on sequence-level uncertainty (Ott et al., 2018; Malinin and Gales, 2020; Aina and Linzen, 2021; Kuhn et al., 2022).\nDiversity in NLG. Our analysis is related to NLG studies on output diversity. Some have evaluated diversity induced by different models and NLG decoding strategies\u2014yet do not use human levels of variability as a target (Wiher et al., 2022)\u2014or have used human judgements to evaluate diversity metrics themselves (Tevet and Berant, 2021; Stasaski and Hearst, 2022). Others have developed diversity-enhancing objective functions (Li et al., 2016) and decoding algorithms (Vijayakumar et al., 2018; Shu et al., 2019; Weir et al., 2020; Meister et al., 2021). In our study, where the aim is to evaluate the uncertainty of NLG systems, we focus on unbiased sampling and the most widely used decoding algorithms."
        },
        {
            "heading": "3 Probing Language Processes for",
            "text": "Production Variability\nWe interpret language production, by humans or NLG systems, as captured by a probability distribution over natural language strings (productions), a random variable Y , given a linguistic context X = x. The context x can be a source sentence\nin translation, a story prompt in story generation, or more generally the input to a language process. In turn, a production is a piece of text y such as a single translation, a story, or more generally the output of a language process.2"
        },
        {
            "heading": "3.1 Production Variability",
            "text": "For any language process, production variability is fully characterised by a conditional probability distribution pY |X=x representing uncertainty about the output Y given input X = x. Intuitively, the uniform distribution maximises production variability and the Dirac delta (one-hot) distribution minimises it. Analysing this distribution is difficult. Notably, for human language processes, we do not have an explicit representation of pY |X=x. This prevents a direct comparison through measures of statistical divergence, or summaries like entropy. Through data collection we can, however, draw conditional samples from the human language process (i.e., gather references given a context). On the other hand, for NLG models, we do have an algorithmic representation of pY |X=x, which is usually sufficient to enable sampling, but the unbounded sample space and lack of conditional independence assumptions make statistical divergence and summaries like entropy intractable.3\nInstead, we propose to analyse language processes through their samples. This in turn introduces other difficulties, as text is a highdimensional, structured, non-numerical data type. For tractable analysis, we exploit a set of real-valued and interpretable statistics, or production probes, to re-express a language process distribution in terms of how, given an input, its outputs relate to outputs of another language process. When both processes are independent humans performing a task, we obtain a sense of how plausible human productions relate (or vary with respect) to other plausible human productions, along a linguistically interpretable dimension. When we swap one or both processes for an NLG model, we obtain tools to analyse how model generations relate to plausible human productions, thus assessing a model\u2019s representation of uncertainty against the variability observed in humans.\n2Notation. Random variables are denoted by uppercase letters (e.g., Y ), outcomes are lowercased (e.g., y), and pY |X=x denotes the probability distribution of Y given X=x.\n3In Appendix A, we discuss issues with entropy in more detail\u2014how it is both difficult to estimate and interpret for text generators.\nSpecifically, given a context x, two language processes with distributions pY\u0302 |X=x and pY |X=x, and a choice of distance metric k(\u00b7, \u00b7) \u2208 R, our probe for production variability is a real random variable k(Y\u0302 , Y ). This random variable captures the joint distribution of distance between any two outputs drawn conditionally from the two processes. The distribution of the probe k(Y\u0302 , Y ) is also intractable, but we can estimate it via simulation by drawing productions from the processes and assessing the distance metric on sampled pairs, as illustrated in Figure 1.\nConsider analysing the human process (\u00a7 5) through k(Y, Y ): when multiple realisations of the output are dissimilar (e.g., given the input \u2018How is your day?\u2019 and outputs \u2018Fantastic, thank you!\u2019 and \u2018I asked you first\u2019) production variability is high along the dimension captured by k."
        },
        {
            "heading": "3.2 Production Probes",
            "text": "We instantiate our production probes with three distance functions. They return values from 0 to 1. We hope that future work will experiment with alternative probes that may capture other linguistic or extra-linguistic levels of analysis.\nLexical: The fraction of distinct n-grams in two strings, with n\u2208 [1, 2, 3] (i.e., number of nonmatching n-gram occurrences divided by the total number of n-grams in both strings).\nSyntactic: Analogous to lexical distance but on part-of-speech tag n-grams.4\nSemantic: The cosine distance between the sentence embeddings of two strings (Reimers and Gurevych, 2019).5\n4From spaCy, en_core_web_md (Honnibal et al., 2020). 5sentence-transformers/all-distilroberta-v1"
        },
        {
            "heading": "4 Experimental Setup",
            "text": ""
        },
        {
            "heading": "4.1 Data and Models",
            "text": "We experiment with four NLG datasets that contain 5+ human references per input instance and for which we expect humans to display different degrees of production variability. For each tasks, we select models that are publicly available, are reasonably sized, have been used previously on the task, and are conventionally accepted as suitable for it.6 All datasets are in English; for translation, the target language is German. Table 1 (Appendix C) shows relevant statistics. The reference collection procedure varies across datasets and we discuss how this may impact our analysis in the Limitations section.\nMachine translation. We use 500 sentences from the WMT-14 En-De test set (newstest2014; Bojar et al., 2014), which have been annotated by Ott et al. (2018) with 10 additional reference translations produced by as many human translators. As a generator, we use Helsinki-NLP\u2019s TransformerAlign model trained on Opus-MT (Tiedemann and Thottingal, 2020).\nText simplification. We use the 2,000 instances of the ASSET validation set (Alva-Manchego et al., 2020). For each source sentence, originally from the TurkCorpus (Xu et al., 2016), ASSET includes 10 additional simplifications by as many crowdsource annotators. On this dataset, we test Flan-T5-large (Chung et al., 2022), an instruction-finetuned version of the T5 language model (Raffel et al., 2020), which we further finetune on the ASSET training set.\n6For text simplification, we did not find any available trained model, so we used a versatile model like FlanT5.\nStorytelling (story generation). We use the 759 instances from the WritingPrompts test set (Fan et al., 2018) for which at least 5 human references are available. Prompts and stories are originally scraped from r/WritingPrompts, a Reddit forum of stories written by online users in response to story prompts designed by other users. The number of stories available per prompt (9.56 \u00b1 7.67) varies from 5 to 92. We use GPT2-large (Radford et al., 2018) finetuned on the WritingPrompts training set.\nOpen-domain dialogue. We use the development set of DailyDialog++ (Sai et al., 2020), which contains 5 additional references for 1,028 conversations from the DailyDialog corpus (Li et al., 2017). The dialogues are short (less than 8 turns) and cover a broad list of topics; for each dialogue, 2-3 annotators were asked to generate 1-3 alternative responses.7 For this task, we use the pretrained DialoGPT-medium (Zhang et al., 2020b)."
        },
        {
            "heading": "4.2 Decoding algorithms",
            "text": "We experiment with five decoding algorithms: unbiased (ancestral or forward) sampling (Bishop, 2006; Koller and Friedman, 2009), temperature scaling, top-k sampling (Fan et al., 2018), nucleus sampling (Holtzman et al., 2019), and locally typical sampling (Meister et al., 2023). For all decoding algorithms, we set the maximum sequence length to 100 (cf. Table 1, Appendix C)."
        },
        {
            "heading": "5 Human Production Variability Across NLG Tasks",
            "text": "Consider pY |X=x the distribution that describes the human language process, and define the following special case for human production variability:\nHk(x) := k(Y, Y ) . (1)\nEstimating this probe by drawing pairs of human productions provides an interpretable view on plausible variability\u2014i.e., aleatoric uncertainty\u2014along the dimension captured by k. Figure 2 shows Hk(x) marginalised over inputs for the four NLG tasks. We use unigram distance for the lexical probe, POS bigram distance for the syntactic probe, and cosine distance for the semantic probe. High distance indicates high variability, and vice versa.\n7The DailyDialog++ annotators are also instructed to avoid short generic responses such as \u2018Sure\u2019 and to write, instead, meaningful responses with at least 8-10 words.\nTranslation and text simplification. Humans show low production variability in these two tasks. While translations of a given source sentence are more lexically and semantically varied, simplifications exhibit a higher degree of syntactic variability, probably as a result of the instructions used during data collection (writers were asked to use varying rewriting transformations). Overall, low levels of variability are to be expected as, in both tasks, content preservation is part of the communicative goal.\nStory generation. Variability in story generation is strongly dependent on the probe. It is low at the syntactic level\u2014close to translation and simplification\u2014while lexical and semantic probes place this task closer to open-domain dialogue. Stories generated from a given prompt may vary a lot in content, but basic syntactic structures and lexical material are shared. Although this task can be a priori perceived at least as \u2018open-ended\u2019 as dialogue, lower levels of variability may result from contextual factors specific to the WritingPrompts dataset that we are not explicitly modelling, such as writers reading stories contributed by other users.\nOpen-domain dialogue. We observe the highest production variability in this task across all probes. Many output pairs are lexically and syntactically completely dissimilar, as indicated by the rightmost bin in Figures 2a and 2b. Lexical variability is even more extreme when looking at bigrams and trigrams (Figure 7 in Appendix D) suggesting that while responses rarely share words or phrases, they still sometimes convey similar meaning (Figure 2c). Overall, the fact that dialogue appears to be the most open-ended task can be explained by the wide variety of communicative goals that can plausibly follow from a dialogue context and, in part, by the fact that individual annotators produced multiple responses for the DailyDialog++ dataset and thus were able to monitor the diversity of their outputs."
        },
        {
            "heading": "6 Do Neural Text Generators Reproduce Human Production Variability?",
            "text": "Consider, now, a second language process: a text generator with distribution pY\u0302 |X=x. We study this generator\u2019s uncertainty about outputs given an input x under two lenses. In \u00a7 6.1, we study how outputs vary with respect to one another, which is analogous to human production variability Hk(x). We refer to this as the generator\u2019s self-variability:\nMk(x) := k(Y\u0302 , Y\u0302 ) . (2)\nIn \u00a7 6.2, instead, we study how model generations vary with respect to a language process known to be plausible: a human language process pY |X=x. We refer to this as cross-variability:\nCk(x) := k(Y\u0302 , Y ) . (3)\nOur expectation is that generators with a good representation of aleatoric uncertainty reproduce human production variability along both axes. As we employ a distance metric, it may look like we should regard a model as a good approximation to the human process whenever Ck(x) concentrates about small positive values. To some extent this is the interpretation exploited by most automatic evaluation metrics (single- or multi-reference). In this work, we refrain from taking any one human production as a \u2018reference\u2019 to be closely \u2018matched\u2019; rather, we take statistical properties of human productions as illustrative of plausible variability and thus targets to be reproduced. We quantify deviation from plausible human variability by estimating a notion of statistical divergence."
        },
        {
            "heading": "6.1 The Underlying Statistical Model",
            "text": "In this section, we criticise the underlying statistical model (as a result of parameter estimation via MLE) using unbiased sampling. As models observe variability only marginally (multiple references are rarely used during training), it is interesting to study if their self-variability is calibrated to human variability: given individual input instances, do distances between unbiased model samples distribute similarly to distances between human productions? To distinguish over-estimation from under-estimation of variability, we report a signed notion of divergence, \u00b5Mk(x) \u2212 \u00b5Hk(x). When Mk(x) and Hk(x) distribute similarly, their mean\ndifference is low for a given x. Positive differences imply that models overestimate variability, i.e., model samples vary more with respect to one another than human samples do. Negative differences indicate that models underestimate variability.\nFigure 3 shows how mean differences distribute across each task-specific test set for the models in Section 4. We use up to 10 human productions (5 for dialogue) and 10 generations. The first two rows show that \u00b5Mk(x)\u2212\u00b5Hk(x) distributes far below 0 for translation (OpusMT) and somewhat below 0 for simplification (Flan-T5), indicating that the two models substantially underestimate variability.8 The opposite is true for dialogue and story generation: both GPT-2 and DialoGPT moderately overestimate the open-endedness of these tasks. We also inspect cross-variability \u00b5Ck(x)\u2212\u00b5Hk(x), finding similar patterns, with slightly better over-\n8OpusMT uses label smoothing, which is known to harm the distribution of unbiased samples along dimensions such as n-gram and skip-bigram counts (Eikema and Aziz, 2020).\nall cross-variability calibration for translation and simplification (Figure 8, Appendix D)."
        },
        {
            "heading": "6.2 The Effect of Decoding Algorithms",
            "text": "We now study text generators obtained by varying the sampling procedure.9 We analyse their representation of uncertainty by assessing the divergence between the distribution of generator-human cross-variability C(x) and human variability H(x). While \u00b5Ck(x) \u2212 \u00b5Hk(x) can inform us about the direction of miscalibration, we observe only a handful of cases where different decoding strategies yield both under- and over-estimation for the same model (see Figures 10 and 11 in Appendix D). Instead, as we sometimes observe distributions with multiple modes\u2014causing their difference in means to paint an incomplete picture\u2014we additionally report a measure of divergence that is more robust to such multi-modal distributions: the Wasserstein 1-Distance DW1(\u00b7, Hk(x)).10 Results for selfvariability M(x) and mean distance can be found in Appendix D, Figures 9 to 11.\nHuman control group. The blue curve in Figure 4 shows how DW1(Ck(x), Hk(x)) distributes over inputs for unbiased samples from GPT-2 on story generation. To contextualise this observation\n9This leads to a probability distribution whose pmf is hard if at all possible to characterise, meaning we cannot easily assess the probability of an outcome under the new distribution. But we have an explicit sampler for this new distribution, which is all our analysis tools require.\n10Indeed, we find several cases where DW1signals stronger miscalibration compared to D\u00b5. For an additional discussion about DW1 , see Appendix B.\nwe report a human control group (the orange curve): this is DW1 measured between two human populations (i.e., we make two disjoint samples from the available human productions for each prompt, use those to estimate Hk(x) and an analogous H\u0302k(x), and compute DW1(H\u0302k(x), Hk(x))). We can now appreciate what is a plausible Wasserstein distance curve between two human-based processes, and with that, we can better discern that this particular system gives good but not perfect representation to human levels of production variability (note the overlap between the two distributions). Upon visual inspection of divergence distributions (like Figure 4) for different sampling strategies, we find similar shapes. We exploit this finding and summarise each divergence distribution using its mean. This is shown in Figure 5, which presents results for many decoding settings, tasks and probes. The leftmost red dots indicate the human control group.11 We observe that two human groups agree more on the meaning of translations and simplifications than on their form, while for story generation the two groups agree more on surface form and basic structures and less on the semantic content of the stories.\nResults. Overall, Figure 5 shows that most decoding settings are close to unbiased sampling, which in turn is in the same ballpark (mean Wasserstein distance always lower than 0.1) as the human control. This indicates that text generators\n11No control condition is shown for open-domain dialogue as the five references contained in DailyDialog++ are too few to create a control group.\ncapture the space of plausible human productions well when coupled with most decoding algorithms, though not as well as another human language process. Decoding settings form many clusters, and for all tasks except open-domain dialogue, unbiased samples best match human variability. This suggests that, within the limits of decoding configurations typically considered as appropriate, different token-level decoding strategies often have a similar effect on a generator\u2019s ability to reproduce human production variability along our three probes. Altogether, these findings inform us about an often neglected aspect of decoding algorithms, namely their effect on the model\u2019s representation of uncertainty (rather than their ability to select individual high-quality generations)."
        },
        {
            "heading": "7 Qualitative Instance-Level Analysis",
            "text": "We now qualitatively analyse individual inputs for which a generator\u2019s uncertainty is miscalibrated to human variability\u2014as detected by DW1 . For each task, we use up to 10 human productions (5 for dialogue) and 10 generations. Figures accompanying the examples in this section are in Appendix E. While it is not a replacement for more standard NLG evaluation procedures, we argue that this level of analysis is complementary and crucial to gain deeper understanding of a generator\u2019s representation of uncertainty.\nVariability underestimation in translation and simplification. We have seen that in translation and simplification, generators\u2019 self-variability is lower than human variability (\u00a7 6.1). We now zoom in on examples from these two tasks, inspecting instances that show inadequate model fit on all linguistic levels (i.e., DW1(Mk(x), Hk(x)) is high for all k). The most severe cases of miscalibration for OpusMT are all instances of variability underestimation.12 For most of these, generations are virtually or completely identical, while a few present slightly higher but still substantially lower variability than human productions. For example, ten humans translated the phrase \u2018reacted cautiously\u2019 in the English source sentence \u2018Several companies have thus far reacted cautiously when it comes to hiring\u2019 in six different ways (\u2018vorsichtig reagiert\u2019, \u2018zur\u00fcckhaltend reagiert\u2019, \u2018mit Vorsichtsma\u00dfnahmen\n12We select instances with DW1 >0.3 for unigram distance and DW1 >0.2 for POS bigram and semantic distance. These thresholds are chosen based on distribution plots of instancelevel distances (see, e.g., Figure 2b).\nreagiert\u2019, \u2018reagierten mit Zur\u00fcckhaltung\u2019, \u2018mit Vorsicht reagiert\u2019, \u2018reagierten verhalten\u2019) while all ten generated samples contain the German phrase \u2018vorsichtig reagiert\u2019, signalling that the generator\u2019s lexical rephrasing abilities do not generalise to this input instance. For text simplification, we focus on instances where Flan-T5\u2019s uncertainty is not calibrated to human syntactic variability.13 We observe that simplifications sampled from the generator are always syntactically more similar to each other than humans\u2019, indicating that the generator struggles to capture an important aspect of text simplification: that many semantically equivalent rewritings are possible if a text\u2019s syntactic structure is altered.\nVariability overestimation in dialogue. According to our estimates of human variability (\u00a7 5), dialogue is the most open-ended task on all linguistic levels. We have hypothesised that this is due to the large variety of communicative act types plausible given any dialogue context. We have also seen that DialoGPT generally overestimates production variability (\u00a7 6.1)\u2014Figure 1 is one such example. Now we further inspect instances where cross-variability is miscalibrated with respect to human outputs.14 We find that the generator\u2019s bad fit can be due to very short and generic responses (e.g., \u2018Well...\u2019, \u2018haha\u2019, \u2018Ahem\u2019, \u2018Well done!\u2019), but is more often due to the presence of fluent yet very diverse and often inadequate samples. For such instances, not only is the generator\u2019s crossvariability miscalibrated\u2014self-variability, too, is overestimated on all linguistic levels. In particular, the generator\u2019s poor calibration to lexical and syntactic variability is related to its inability to choose the correct dialogue acts (or favouring an excessive variety of dialogue acts). In an example instance where the last dialogue turn goes \u2018I\u2019ve got a business call that I really need to take\u2019, humans all reply with short affirmative responses (\u2018Okay! Please.\u2019, \u2018Well! Go on.\u2019, \u2018Sure, why not!\u2019, \u2018Sure! Go ahead.\u2019, \u2018Yes! Sure.\u2019) while the model\u2019s responses are mostly lengthy statements, sometimes not particularly coherent ones (e.g., \u2018You don\u2019t need a business call. You need a friend\u2019).\nVariability in lack of situational grounding. We have observed that human-written stories in the WritingPrompts dataset show lower variability than human dialogue responses, and hypothesised\n13DW1(Mk(x), Hk(x))>0.2; k is POS bigram distance. 14DW1(Ck(x), Hk(x)) > 0.2 for all k in {unigram dis-\ntance, POS bigram distance, cosine distance}.\nthat this may be in part due to contextual pressures that constrain variability (\u00a7 5). We now analyse instances flagged by our probe as cases of badly calibrated semantic cross-variability for GPT-2.15 For one of these, the prompt refers to a portion of the situational context the model does not have access to (\u2018all top level comments in this prompt take place in the same world, so make them all fit together\u2019). Because they are conditioned on and reuse that context, human stories are quite similar to each other; generations, instead, show much higher pairwise distance both when sampled jointly with the human productions (see Figure 6) and with themselves. The lack of relevant situational grounding makes the model more uncertain than it should be for this instance."
        },
        {
            "heading": "8 Conclusion",
            "text": "Variability is an intrinsic property of human language production. Text generators, if they are to be considered as good statistical models of human written production, should exhibit plausible levels of variability. However, in NLG, the widespread practice is (i) collecting only one \u2018reference\u2019 production for each input and (ii) evaluating only a single generation. To appreciate the impact of this incongruity empirically, we analyse multiplereference datasets for four NLG tasks, and show that each task has its own plausible levels of lexical, syntactic, and semantic variability. We connect production variability to aleatoric uncertainty, the irreducible uncertainty of the language production process, and evaluate neural text generators in terms of whether their representation of uncertainty is calibrated to the levels of variability observed\n15DW1(Ck(x), Hk(x)) > 0.3; k is cosine distance.\nin humans. We find that NLG models overestimate production variability in open-ended tasks and underestimate it in more constrained tasks, and that most popular decoding algorithms all have a similar, limited effect on the generators\u2019 ability to reproduce human variability.\nWe advocate for more widespread usage of instance-level probing of NLG systems as a way to evaluate their statistical fit, not just along the dimensions we cover in this study but with respect to any other quality of interest. This approach contrasts with corpus-level analyses of NLG systems (e.g., Pillutla et al., 2021; Meister and Cotterell, 2021; Pimentel et al., 2022) and thanks to its greater interpretability, it builds trust in the ability of generators to reproduce human-like statistics when situated in specific linguistic contexts rather than \u2018globally\u2019, over a possibly heterogeneous corpus. In the future, we plan to devise new ways of improving the calibration of models\u2019 uncertainty (Zhao et al., 2022; Zhang et al., 2022), e.g., steering generators with sequence-level decoding algorithms (Eikema and Aziz, 2022), and to investigate the relation between uncertainty and perceived generation quality (e.g., Kuhn et al., 2022): while we use human levels of variability as a target, desirable levels of variability may deviate from human statistics for specific applications.\nFuture work should also study production variability as a function of a more complex notion of discourse context (Giulianelli and Fern\u00e1ndez, 2021; Giulianelli et al., 2023) and attempt to disentangle uncertainty over communicative goals and realisations (Stasaski and Hearst, 2023). This is an important avenue not only toward more practically useful generators but also toward reliable computational models of language production.\nLimitations\nOur analysis relies on multiple-reference datasets, which are scarce for NLG tasks. Even though, for single-reference datasets, we cannot perform a similar instance-level analysis, this fact does not entail that the observations we make do not apply to such datasets\u2014we might simply not have the data to expose them.\nImpact of data collection. The way in which multiple references are gathered may impact the variability in productions. For example, asking a single annotator to produce several distinct references might artificially increase the diversity of responses. Conversely, asking several independent annotators might decrease diversity for they may resort to similar responses that quckly come to mind (or, in fact, the opposite if they interpret the linguistic context differently). To summarise, there are two levels of uncertainty in human production data: one is on the individual level, the other is on the population level. In this work, we do not distinguish these two, although the analysis tools that we propose allow for it. For example, one could collect human productions from one individual (e.g., for personalisation) or from sub-populations (e.g. to improve fit for underrepresented communities).\nOther quality dimensions. It is possible that a model fits various statistical properties of the human process (under Mk(x), under Ck(x), and for various choices of k) meanwhile none of its probable responses are humanly-accepted as a whole. This is why we shall think of our tools as statistical probes. We indeed find interesting instances that show good fit in terms of our distance probes but whose outputs may be perceived as inadequate. Manual inspection reveals that a marriage proposal in one of the dialogues (Figure 16 in the Appendix) is followed by a few incoherent model responses (e.g.., \u2018Thank you. It\u2019s not a question of the strength or weakness of the plot. I think it all falls within my capacity.\u2019), some dispreferred ones (\u2018If you want to have a hug?\u2019; see Levinson, 1983), and some with negative affect (\u2018I don\u2019t need your love. I know where you are coming from and I trust you will do the same.\u2019). Exhaustively defining all aspects of perceived quality (or human-likeness) is a strenuous endeavour which is highly dependent on the use case of the generation system. Our probes can be replaced with (possibly asymmetric) quality metrics which capture aspects (e.g., affective\ncontent, toxicity, or readability) that are considered relevant for any given application."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank Arabella Sinclair, Claire Gardent, Clara Meister, Christopher Lucas, Ehud Reiter, Sarenne Wallbridge, and the ILLC\u2019s Dialogue Modelling Group for inspiring discussions. We also thank the MaiNLP group for feedback on earlier drafts of this paper. MG and RF are supported by the European Research Council (ERC) under the European Union\u2019s Horizon 2020 research and innovation programme (grant agreement No. 819455). JB is supported by the ELLIS Amsterdam Unit. WA is supported by the EU\u2019s Horizon Europe research and innovation programme (grant agreement No. 101070631, UTTER). BP is supported by the European Research Council (ERC) (grant agreement No. 101043235)."
        },
        {
            "heading": "A A Note on Entropy",
            "text": "Entropy is an information-theoretic concept that is often used to summarise uncertainty about a random variable. As useful as it may be in various contexts, entropy is not itself a complete characterisation of uncertainty (e.g., two different distributions may have the same entropy, yet represent different uncertainty about their respective random variables). As we discuss in \u00a7 3.1, uncertainty about a random variable is fully represented by its underlying probability distribution (Halpern, 2017, Chapter 2).\nConsider a discrete random variable X with distribution pX and probability mass function (pmf) pX(x). Define the surprisal of an outcome X = x as the quantity \u2212 log pX(x). Then, Shannon entropy (or just entropy for short) is defined as the surprisal of X taken in expectation under pX (MacKay, 2003). Due to the unbounded sample space and lack of conditional independence assumptions, entropy is intractable to compute for neural text generators. In some cases a Monte Carlo (MC) estimate of entropy can be formed with a reasonable amount of computation. For example, consider an autoregressive language model that assigns probability f(x; \u03b8) to a complete sequence x using a neural network with parameters \u03b8 (e.g., an LSTM or Transformer). When we use ancestral sampling (Bishop, 2006) to decode from this model obtaining a sample x(s), the surprisal of x(s) is directly available via \u2212 log f(x; \u03b8), and the sample mean \u2212 1S \u2211S s=1 log f(x\n(s); \u03b8) for S ancestral samples forms an unbiased MC estimate for the entropy of X . In most cases, however, the\ngenerator\u2019s pmf is unknown and the surprisal of an outcome is not available. That is the case, for example, whenever we employ decoding algorithms that bias away from the underlying distribution of the autoregressive LM\u2014top-p, top-k, typical sampling are all good examples. The resulting pmf is then hard (or impossible) to characterise.\nFurthermore, as much as Shannon entropy can be interpreted in its own information-theoretic terms, it is not immediately obvious how it can inform an analyst interested in the generator\u2019s faithfulness to human production variability. That said, the analyst may be interested in knowing, for example, that the entropy of the generator is similar to that of the \u2018human distribution\u2019 regardless of their ability to assign any useful interpretation to entropy proper. While we accept some analyst out there may be curious about that question, we refrain from performing such an analysis ourselves because (a) MC estimation is not available for most of the popular decoders we wanted to analyse, and (b) estimating the entropy of the human distribution requires a faithful model of it (that is, we need a perfectly faithful text generator to play the role of a \u2018gold standard\u2019)."
        },
        {
            "heading": "B A Note on the Wasserstein 1-Distance",
            "text": "The Wasserstein 1-Distance W1(\u00b7, \u00b7) quantifies a notion of distance between two probability measures and is particularly convenient for it can be estimated using Dirac deltas (samples from those measures; Peyr\u00e9 et al., 2019) more easily than alternatives such as Kolmogorov\u2013Smirnov and total variation distance (which require binning the measurements into empirical cdfs/pdfs). W1(Mk(x), Hk(x)) and W1(Ck(x), Hk(x)) have an interpretation in terms of \u2018mass\u2019 (in units of k) that has to be moved, on average, to transform one set of samples into another."
        },
        {
            "heading": "C Data Statistics",
            "text": "Table 1 shows relevant statistics for the four multiple-reference datasets presented in \u00a7 4."
        },
        {
            "heading": "D Additional Figures",
            "text": "Figure 7 shows human production variability over lexical and syntactic unigrams, bigrams, and trigrams (complementing Figure 2 in the main paper). Figure 8 shows the distribution of \u00b5Ck(x) \u2212 \u00b5Hk(x) over instances for our four tasks (complementing Figure 3 in the main paper). Figures 9 to 11 show\nmean divergences across tasks, probes, and decoding algorithms (complementing Figure 5 in the main paper)."
        },
        {
            "heading": "E Examples Discussed in the Qualitative Instance-Level Analysis",
            "text": "Figures 12-16 show examples of model fitness for the instances discussed in \u00a7 7."
        },
        {
            "heading": "F Decoding Configurations",
            "text": "Tables 2 to 5 show mean divergences for all the analysed decoding strategies, in terms of Wasserstein 1-Distance as well as mean distance."
        }
    ],
    "title": "What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability",
    "year": 2023
}