{
    "abstractText": "Currently in the petroleum industry, operators often flare the produced gas instead of commodifying it. The flaring magnitudes are large in some states, which constitute problems with energy waste and CO2 emissions. In North Dakota, operators are required to estimate and report the volume flared. The questions are, how good is the quality of this reporting, and what insights can be drawn from it? Apart from the company-reported statistics, which are available from the North Dakota Industrial Commission (NDIC), flared volumes can be estimated via satellite remote sensing, serving as an unbiased benchmark. Since interpretation of the Landsat 8 imagery is hindered by artifacts due to glow, the estimated volumes based on the Visible Infrared Imaging Radiometer Suite (VIIRS) are used. Reverse geocoding is performed for comparing and contrasting the NDIC and VIIRS data at different levels, such as county and oilfield. With all the data gathered and preprocessed, Bayesian learning implemented by Markov chain Monte Carlo methods is performed to address three problems: county level model development, flaring time series analytics, and distribution estimation. First, there is heterogeneity among the different counties, in the associations between the NDIC and VIIRS volumes. In light of such, models are developed for each county by exploiting hierarchical models. Second, the flaring time series, albeit noisy, contains information regarding trends and patterns, which provide some insights into operator approaches. Gaussian processes are found to be effective in many different pattern recognition scenarios. Third, distributional insights are obtained through unsupervised learning. The negative binomial and Gaussian mixture models are found to effectively describe the oilfield flare count and flared volume distributions, respectively. Finally, a nearest-neighbor-based approach for operator level monitoring and analytics is introduced.",
    "authors": [
        {
            "affiliations": [],
            "name": "Rong Lu"
        },
        {
            "affiliations": [],
            "name": "Jennifer L. Miskimins"
        }
    ],
    "id": "SP:54a3c532b779a0eef8f08c811ee843a8ce2a52be",
    "references": [
        {
            "authors": [
                "Y.S. Abu-Mostafa",
                "M. Magdon-Ismail",
                "Lin",
                "H.-T."
            ],
            "title": "Learning From Data, first edition",
            "venue": "Pasadena, CA: AMLBook.",
            "year": 2012
        },
        {
            "authors": [
                "R.P. Adams",
                "I. Murray",
                "D.J.C. MacKay"
            ],
            "title": "Tractable Nonparametric Bayesian Inference in Poisson Processes with Gaussian Process Intensities",
            "venue": "Paper presented at the 26th Annual International Conference on Machine Learning, New York, NY, USA, 14-18 June. https://doi.org/10.1145/1553374.1553376.",
            "year": 2009
        },
        {
            "authors": [
                "A. Alexeyev",
                "M. Ostadhassan",
                "Mohammed",
                "R. A"
            ],
            "title": "Well Log Based Geomechanical and Petrophysical Analysis of the Bakken Formation",
            "venue": "Paper presented at the 51st U.S. Rock Mechanics/Geomechanics Symposium, San Francisco, California, USA, 25-28 June. ARMA-2017-0942.",
            "year": 2017
        },
        {
            "authors": [
                "A. Andorra"
            ],
            "title": "A principled Bayesian workflow, with Michael Betancourt",
            "venue": "https : // podcasts .apple .com/us/podcast/6- a- principled- bayesian- workflow- with- michael betancourt/id1483485062?i=1000461447241. (accessed 30 October 2020).",
            "year": 2020
        },
        {
            "authors": [
                "C. Andrieu",
                "N. de Freitas",
                "A Doucet"
            ],
            "title": "An Introduction to MCMC for Machine Learning",
            "venue": "Machine Learning",
            "year": 2003
        },
        {
            "authors": [
                "S. Bandyopadhyay"
            ],
            "title": "CSM MATH 532, Lecture Notes: Spatial Statistics",
            "venue": "Colorado School of Mines.",
            "year": 2018
        },
        {
            "authors": [
                "A. Berk",
                "G.P. Anderson",
                "Acharya",
                "P. K"
            ],
            "title": "MODTRAN5: 2006 Update",
            "venue": "Paper presented at the Defense and Security Symposium, Orlando (Kissimmee), Florida, USA, 17-21 April. https://doi.org/10.1117/12.665077.",
            "year": 2006
        },
        {
            "authors": [
                "M. Betancourt"
            ],
            "title": "Comment on GitHub issue (Wishart fails with valid arguments)",
            "venue": "https://github.com/pymc-devs/pymc3/issues/538#issuecomment-94153586. (accessed 30 October 2020).",
            "year": 2015
        },
        {
            "authors": [
                "M. Betancourt"
            ],
            "title": "Robust Gaussian Processes in Stan",
            "venue": "https://betanalpha.github.io/ assets/case studies/gp part1/part1.html. (accessed 30 October 2020).",
            "year": 2017
        },
        {
            "authors": [
                "M. Betancourt"
            ],
            "title": "Robust Statistical Workflow with RStan",
            "venue": "https://betanalpha.github. io/assets/case studies/rstan workflow.html. (accessed 30 October 2020). 121",
            "year": 2017
        },
        {
            "authors": [
                "M. Betancourt"
            ],
            "title": "Conditional Probability Theory (For Scientists and Engineers)",
            "venue": "https:",
            "year": 2018
        },
        {
            "authors": [
                "M. Betancourt"
            ],
            "title": "Towards A Principled Bayesian Workflow. https://betanalpha.github",
            "venue": "github.io/assets/case studies/modeling and inference.html. (accessed",
            "year": 2020
        },
        {
            "authors": [
                "B.M. Bolker"
            ],
            "title": "io/assets/case studies/principled bayesian workflow.html",
            "year": 2020
        },
        {
            "authors": [
                "A. A:1010933404324. Burkov"
            ],
            "title": "The Hundred-page Machine Learning Book, first edition",
            "year": 2019
        },
        {
            "authors": [
                "Columbia",
                "Canada: Leanpub. Campello",
                "R.J.G. B",
                "D. Moulavi",
                "J. Sander"
            ],
            "title": "Density-Based Clustering Based",
            "year": 2013
        },
        {
            "authors": [
                "B. Carpenter",
                "A. Gelman",
                "M Hoffman"
            ],
            "title": "Stan: A Probabilistic Programming",
            "year": 2017
        },
        {
            "authors": [
                "M.P. Deisenroth",
                "R.D. Turner",
                "Huber",
                "M. F"
            ],
            "title": "Robust Filtering and Smoothing",
            "venue": "vVw66F6&index=7&t=0s. (accessed",
            "year": 2020
        },
        {
            "authors": [
                "A.D. Kennedy",
                "Pendleton",
                "B. J"
            ],
            "title": "Hybrid Monte Carlo",
            "venue": "Physics Letters",
            "year": 1987
        },
        {
            "authors": [
                "C.D. Elvidge",
                "K. Baugh",
                "Zhizhin",
                "M. N"
            ],
            "title": "Supporting International Efforts",
            "venue": "prices. (accessed",
            "year": 2020
        },
        {
            "authors": [
                "C.D. Elvidge",
                "M.N. Zhizhin",
                "K Baugh"
            ],
            "title": "Methods for Global Survey of Natural Gas Flaring from Visible Infrared Imaging Radiometer Suite Data",
            "venue": "Energies 9 (1). https: //doi.org/10.3390/en9010014.",
            "year": 2015
        },
        {
            "authors": [
                "C.D. Elvidge",
                "M.N. Zhizhin",
                "K Baugh"
            ],
            "title": "Extending Nighttime Combustion Source Detection Limits with Short Wavelength VIIRS Data",
            "venue": "Remote Sensing 11 (4). https://doi.org/10.3390/rs11040395.",
            "year": 2019
        },
        {
            "authors": [
                "C.D. Elvidge",
                "M.N. Zhizhin",
                "Hsu",
                "F.-C"
            ],
            "title": "VIIRS Nightfire: Satellite Pyrometry at Night",
            "venue": "Remote Sensing 5 (9): 4423\u20134449. https://doi.org/10.3390/rs5094423.",
            "year": 2013
        },
        {
            "authors": [
                "M. Ester",
                "Kriegel",
                "H.-P.",
                "J Sander"
            ],
            "title": "A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise",
            "venue": "Paper presented at the 2nd International Conference on Knowledge Discovery and Data Mining, Portland, Oregon, USA, 2-4 August.",
            "year": 1996
        },
        {
            "authors": [
                "J.H. Friedman"
            ],
            "title": "Greedy Function Approximation: A Gradient Boosting Machine",
            "venue": "The Annals of Statistics 29 (5): 1189\u20131232.",
            "year": 2001
        },
        {
            "authors": [
                "A. Gelman",
                "J.B. Carlin",
                "Stern",
                "H. S"
            ],
            "title": "Bayesian Data Analysis, third edition",
            "venue": "Boca Raton, Florida: Chapman & Hall/CRC.",
            "year": 2013
        },
        {
            "authors": [
                "A. Gelman",
                "J. Hill"
            ],
            "title": "Data Analysis Using Regression and Multilevel/Hierarchical Models, first edition",
            "venue": "New York, NY: Cambridge University Press.",
            "year": 2006
        },
        {
            "authors": [
                "A. Gelman"
            ],
            "title": "N is never large",
            "venue": "https://statmodeling.stat.columbia.edu/2005/07/31/ n is never larg/. (accessed 30 October 2020).",
            "year": 2015
        },
        {
            "authors": [
                "A. Gelman",
                "D.B. Rubin"
            ],
            "title": "Inference from Iterative Simulation Using Multiple Sequences",
            "venue": "Statistical Science 7 (4): 457\u2013472.",
            "year": 1992
        },
        {
            "authors": [
                "Google Earth."
            ],
            "title": "Satellite imagery showing gas flaring being conducted on a well location in North Dakota",
            "venue": "https://earth.google.com/web. (accessed 30 October 2020).",
            "year": 2019
        },
        {
            "authors": [
                "T. Hastie",
                "R. Tibshirani",
                "J. Friedman"
            ],
            "title": "The Elements of Statistical Learning, second edition",
            "venue": "New York, NY: Springer. https://doi.org/10.1007/978-0-387-84858-7.",
            "year": 2009
        },
        {
            "authors": [
                "K. He",
                "X. Zhang",
                "S Ren"
            ],
            "title": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification",
            "venue": "Paper presented at the 2015 IEEE International Conference on Computer Vision, Santiago, Chile, 7-13 December. https://doi.org/10. 1109/ICCV.2015.123. 124",
            "year": 2015
        },
        {
            "authors": [
                "G.E. Hinton",
                "R.R. Salakhutdinov"
            ],
            "title": "Reducing the Dimensionality of Data with Neural Networks",
            "venue": "Science 313 (5786): 504\u2013507. https://doi.org/10.1126/science.1127647.",
            "year": 2006
        },
        {
            "authors": [
                "M.D. Hoffman",
                "A. Gelman"
            ],
            "title": "The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo",
            "venue": "Journal of Machine Learning Research 15 (47): 1593\u20131623.",
            "year": 2014
        },
        {
            "authors": [
                "M.I. Jordan",
                "T.M. Mitchell"
            ],
            "title": "Machine Learning: Trends, Perspectives, and Prospects",
            "venue": "Science 349 (6245): 255\u2013260. https://doi.org/10.1126/science.aaa8415.",
            "year": 2015
        },
        {
            "authors": [
                "M.I. Jordan",
                "T. Broderick"
            ],
            "title": "UCB STAT 260, Lecture 1: History and De Finetti\u2019s Theorem",
            "venue": "https://people.eecs.berkeley.edu/\u223cjordan/courses/260-spring10/lectures/ lecture1.pdf. (accessed 30 October 2020).",
            "year": 2010
        },
        {
            "authors": [
                "N. Kazakov",
                "J.L. Miskimins"
            ],
            "title": "Application of Multivariate Statistical Analysis to Slickwater Fracturing Parameters in Unconventional Reservoir Systems",
            "venue": "Paper presented at the SPE Hydraulic Fracturing Technology Conference, The Woodlands, Texas, USA, 24-26 January. SPE-140478-MS. https://doi.org/10.2118/140478-MS.",
            "year": 2011
        },
        {
            "authors": [
                "A. Krizhevsky",
                "I. Sutskever",
                "G.E. Hinton"
            ],
            "title": "ImageNet Classification with Deep Convolutional Neural Networks",
            "venue": "Paper presented at the 26th Conference on Neural Information Processing Systems, Lake Tahoe, Nevada, USA, 3-6 December.",
            "year": 2012
        },
        {
            "authors": [
                "R. Kumar",
                "C. Carroll",
                "A Hartikainen"
            ],
            "title": "Arviz a Unified Library for Exploratory Analysis of Bayesian Models in Python",
            "venue": "Journal of Open Source Software 4 (33). https: //doi.org/10.21105/joss.01143.",
            "year": 2019
        },
        {
            "authors": [
                "B. Lambert"
            ],
            "title": "A Student\u2019s Guide to Bayesian Statistics, first edition",
            "venue": "London, UK: SAGE Publications Ltd.",
            "year": 2018
        },
        {
            "authors": [
                "D. Lewandowski",
                "D. Kurowicka",
                "H. Joe"
            ],
            "title": "Generating Random Correlation Matrices Based on Vines and Extended Onion Method",
            "venue": "Journal of Multivariate Analysis 100 (9): 1989\u20132001. https://doi.org/10.1016/j.jmva.2009.04.008.",
            "year": 2009
        },
        {
            "authors": [
                "H. Li"
            ],
            "title": "Statistical Learning Methods, second edition",
            "venue": "Beijing: Tsinghua University Press.",
            "year": 2019
        },
        {
            "authors": [
                "D.J.C. MacKay"
            ],
            "title": "Introduction to Gaussian Processes",
            "venue": "NATO ASI Series F Computer and Systems Sciences 168: 133\u2013166. 125",
            "year": 1998
        },
        {
            "authors": [
                "D.J.C. MacKay"
            ],
            "title": "Information Theory, Inference and Learning Algorithms, first edition",
            "venue": "Cambridge, UK: Cambridge University Press.",
            "year": 2003
        },
        {
            "authors": [
                "O. Martin"
            ],
            "title": "Bayesian Analysis with Python, second edition",
            "venue": "Birmingham, UK: Packt Publishing Ltd.",
            "year": 2018
        },
        {
            "authors": [
                "R. McElreath"
            ],
            "title": "Statistical Rethinking: A Bayesian Course with Examples in R and Stan, first edition",
            "venue": "Boca Raton, Florida: Chapman & Hall/CRC.",
            "year": 2015
        },
        {
            "authors": [
                "R. McElreath"
            ],
            "title": "Statistical Rethinking: A Bayesian Course with Examples in R and Stan, second edition",
            "venue": "Boca Raton, Florida: Chapman & Hall/CRC.",
            "year": 2020
        },
        {
            "authors": [
                "L. McInnes",
                "J. Healy",
                "S. Astels"
            ],
            "title": "Hdbscan: Hierarchical Density Based Clustering",
            "venue": "Journal of Open Source Software 2 (11). https://doi.org/10.21105/joss.00205.",
            "year": 2017
        },
        {
            "authors": [
                "T.M. Mitchell"
            ],
            "title": "Machine Learning, first edition",
            "venue": "New York, NY: McGraw-Hill, Inc.",
            "year": 1997
        },
        {
            "authors": [
                "NASA."
            ],
            "title": "Landsat 8",
            "venue": "https://landsat.gsfc.nasa.gov/landsat-8/. (accessed 30 October 2020).",
            "year": 2019
        },
        {
            "authors": [
                "NASA."
            ],
            "title": "Landsat 8 Overview",
            "venue": "https://landsat.gsfc.nasa.gov/landsat-8/landsat-8overview/. (accessed 30 October 2020).",
            "year": 2020
        },
        {
            "authors": [
                "North Dakota Industrial Commission."
            ],
            "title": "North Dakota Industrial Commission Order 24665 Policy/Guidance Version 041718",
            "venue": "https://www.dmr.nd.gov/oilgas/GuidancePolicy NorthDakotaIndustrialCommissionorder24665.pdf. (accessed 30 October 2020).",
            "year": 2014
        },
        {
            "authors": [
                "R.S. Olson",
                "W. La Cava",
                "Z Mustahsan"
            ],
            "title": "Data-driven Advice for Applying Machine Learning to Bioinformatics Problems",
            "venue": "arXiv e-prints. arXiv:1708.05070 (in press; posted 8 August 2017).",
            "year": 2017
        },
        {
            "authors": [
                "P. Orbanz",
                "Y.W. Teh"
            ],
            "title": "Bayesian Nonparametric Models",
            "venue": "Encyclopedia of Machine Learning, ed. C. Sammut and G. I. Webb. Boston, MA: Springer. https://doi.org/10. 1007/978-0-387-30164-8 66.",
            "year": 2010
        },
        {
            "authors": [
                "O. Papaspiliopoulos",
                "G.O. Roberts",
                "M. Sk\u00f6ld"
            ],
            "title": "A General Framework for the Parametrization of Hierarchical Models",
            "venue": "Statistical Science 22 (1): 59\u201373. https://doi. org/10.1214/088342307000000014.",
            "year": 2007
        },
        {
            "authors": [
                "F. Pedregosa",
                "G. Varoquaux",
                "A Gramfort"
            ],
            "title": "Scikit-learn: Machine Learning in Python",
            "venue": "Journal of Machine Learning Research 12 (85): 2825\u20132830. 126",
            "year": 2011
        },
        {
            "authors": [
                "S. Roberts",
                "M. Osborne",
                "M Ebden"
            ],
            "title": "Gaussian Processes for Time-series Modelling",
            "year": 2013
        },
        {
            "authors": [
                "F. rsta.2011.0550. Rosenblatt"
            ],
            "title": "The Perceptron: A Probabilistic Model for Information Storage",
            "year": 1958
        },
        {
            "authors": [
                "C. 1037/h0042519. Rudin"
            ],
            "title": "Stop Explaining Black Box Machine Learning Models for High Stakes",
            "year": 2019
        },
        {
            "authors": [
                "T.V. Wiecki",
                "C. Fonnesbeck"
            ],
            "title": "Probabilistic Programming in Python",
            "year": 2016
        },
        {
            "authors": [
                "L.G. Valiant"
            ],
            "title": "A Theory of the Learnable",
            "venue": "Communications of the ACM 27 (11): 1134\u20131142. https://doi.org/10.1145/1968.1972.",
            "year": 1984
        },
        {
            "authors": [
                "J. VanderPlas",
                "A.J. Connolly",
                "\u017d Ivezi\u0107"
            ],
            "title": "Introduction to Astroml: Machine Learning for Astrophysics",
            "venue": "Paper presented at the 2012 Conference on Intelligent Data Understanding, Boulder, Colorado, USA, 24-26 October. https://doi.org/10.1109/CIDU. 2012.6382200.",
            "year": 2012
        },
        {
            "authors": [
                "V.N. Vapnik"
            ],
            "title": "The Nature of Statistical Learning Theory, first edition",
            "venue": "New York, NY: Springer. https://doi.org/10.1007/978-1-4757-3264-1.",
            "year": 2000
        },
        {
            "authors": [
                "S. Watanabe"
            ],
            "title": "Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory",
            "venue": "Journal of Machine Learning Research 11: 3571\u20133594.",
            "year": 2010
        },
        {
            "authors": [
                "Wikipedia."
            ],
            "title": "Visible Infrared Imaging Radiometer Suite",
            "venue": "https://en.wikipedia.org/wiki/ Visible Infrared Imaging Radiometer Suite. (accessed 30 October 2020).",
            "year": 2019
        },
        {
            "authors": [
                "D.H. Wolpert"
            ],
            "title": "The Lack of A Priori Distinctions Between Learning Algorithms",
            "venue": "Neural Computation 8 (7): 1341\u20131390. https://doi.org/10.1162/neco.1996.8.7.1341.",
            "year": 1996
        },
        {
            "authors": [
                "World Bank."
            ],
            "title": "Global Gas Flaring Reduction Partnership (GGFR) Flaring Data",
            "venue": "https: //www.worldbank.org/en/programs/gasflaringreduction#7. (accessed 30 October 2020).",
            "year": 2019
        },
        {
            "authors": [
                "J. Yu"
            ],
            "title": "Machine Learning: From Axioms to Algorithms, first edition",
            "venue": "Beijing: Tsinghua University Press.",
            "year": 2017
        },
        {
            "authors": [
                "X. Yu",
                "W. Trainor-Guitton",
                "J.L. Miskimins"
            ],
            "title": "A Data Driven Approach in Screenout Detection for Horizontal Wells",
            "venue": "Paper presented at the SPE Hydraulic Fracturing Technology Conference and Exhibition, The Woodlands, Texas, USA, 4-6 February. SPE199707-MS. https://doi.org/10.2118/199707-MS. 128",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "APPLICATION OF MACHINE\nLEARNING TO GAS\nFLARING\nby\nRong Lu\nar X\niv :2\n30 1.\n04 14\n1v 1\n[ cs\n.L G\n] 1\n1 Ja\nn 20\n23\n\u00a9 Copyright by Rong Lu, 2020\nAll Rights Reserved\nA thesis submitted to the Faculty and the Board of Trustees of the Colorado School of Mines in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Petroleum Engineering).\nGolden, Colorado Date\nSigned: Rong Lu\nSigned: Dr. Jennifer L. Miskimins\nThesis Advisor\nGolden, Colorado Date\nSigned: Dr. Jennifer L. Miskimins\nProfessor and Head Department of Petroleum Engineering\nii\nABSTRACT\nCurrently in the petroleum industry, operators often flare the produced gas instead of commodifying it. The flaring magnitudes are large in some states, which constitute problems with energy waste and CO2 emissions. In North Dakota, operators are required to estimate and report the volume flared. The questions are, how good is the quality of this reporting, and what insights can be drawn from it?\nApart from the company-reported statistics, which are available from the North Dakota Industrial Commission (NDIC), flared volumes can be estimated via satellite remote sensing, serving as an unbiased benchmark. Since interpretation of the Landsat 8 imagery is hindered by artifacts due to glow, the estimated volumes based on the Visible Infrared Imaging Radiometer Suite (VIIRS) are used. Reverse geocoding is performed for comparing and contrasting the NDIC and VIIRS data at different levels, such as county and oilfield.\nWith all the data gathered and preprocessed, Bayesian learning implemented by Markov chain Monte Carlo methods is performed to address three problems: county level model development, flaring time series analytics, and distribution estimation. First, there is heterogeneity among the different counties, in the associations between the NDIC and VIIRS volumes. In light of such, models are developed for each county by exploiting hierarchical models. Second, the flaring time series, albeit noisy, contains information regarding trends and patterns, which provide some insights into operator approaches. Gaussian processes are found to be effective in many different pattern recognition scenarios. Third, distributional insights are obtained through unsupervised learning. The negative binomial and Gaussian mixture models are found to effectively describe the oilfield flare count and flared volume distributions, respectively. Finally, a nearest-neighbor-based approach for operator level monitoring and analytics is introduced.\niii\nTABLE OF CONTENTS\nABSTRACT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iii\nLIST OF FIGURES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vii\nLIST OF TABLES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xii\nLIST OF SYMBOLS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiii\nLIST OF ABBREVIATIONS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xvii\nACKNOWLEDGMENTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xix\nDEDICATION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xxi\nCHAPTER 1 INTRODUCTION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1 Research Goal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 Dissertation Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.3 Outline and Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\nCHAPTER 2 LITERATURE REVIEW . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.1 Satellite Image Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.2 Bayesian Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3 Markov Chain Monte Carlo . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.4 Machine Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n2.5 Analytics Toolset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\nCHAPTER 3 DATA PREPROCESSING AND EXPLORATORY DATA ANALYSIS . 17\n3.1 Data Gathering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.1.1 Landsat 8 Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\niv\n3.1.2 VIIRS Estimated Volumes . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.1.3 NDIC Monthly Production Reports . . . . . . . . . . . . . . . . . . . . 18\n3.1.4 NDIC Shapefiles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.2 Satellite Image Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n3.3 Reverse Geocoding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.4 Correlational Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.5 State Level Flaring Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\nCHAPTER 4 COUNTY LEVEL FLARING MODEL . . . . . . . . . . . . . . . . . . 32\n4.1 Learning the Heterogeneity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n4.2 Hierarchical Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n4.3 Data Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n4.4 Model Specification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n4.5 Model Reparameterization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n4.6 Model Fitting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n4.7 Model Extensibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\nCHAPTER 5 FLARING TIME SERIES ANALYTICS . . . . . . . . . . . . . . . . . . 52\n5.1 Learning the Flaring Pattern and Behavior . . . . . . . . . . . . . . . . . . . . 52\n5.2 Gaussian Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n5.2.1 Mean Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n5.2.2 Covariance Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n5.2.3 Inference and Model Reparameterization . . . . . . . . . . . . . . . . . 56\n5.3 Suite of Models for Pattern Recognition . . . . . . . . . . . . . . . . . . . . . 57\n5.3.1 Modeling Proportion of Gas Flared . . . . . . . . . . . . . . . . . . . . 57\nv\n5.3.2 Modeling Proportion of Wells Flaring . . . . . . . . . . . . . . . . . . . 63\n5.3.3 Modeling Flare Detection Count . . . . . . . . . . . . . . . . . . . . . . 66\n5.3.4 Modeling Proportion of Oil Flared . . . . . . . . . . . . . . . . . . . . 70\n5.3.5 Modeling Scale Factor between VIIRS and NDIC . . . . . . . . . . . . 74\n5.3.6 Predicting NDIC Flared Volume . . . . . . . . . . . . . . . . . . . . . . 80\n5.3.7 A Look Back at the Prior Choices . . . . . . . . . . . . . . . . . . . . . 81\nCHAPTER 6 UNSUPERVISED LEARNING FROM MULTIPLE PERSPECTIVES . 83\n6.1 Learning the Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n6.2 Probability Model Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\n6.3 Modeling VIIRS Detection Count . . . . . . . . . . . . . . . . . . . . . . . . . 85\n6.4 Modeling Flared Volume . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91\n6.4.1 Model Specification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n6.4.2 Model Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n6.4.3 Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\nCHAPTER 7 DISCUSSION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\n7.1 Operator Level Monitoring and Analytics . . . . . . . . . . . . . . . . . . . . 102\n7.2 Warnings Regarding Inconsistencies . . . . . . . . . . . . . . . . . . . . . . . 106\n7.3 Caveats in Petroleum Data Analytics . . . . . . . . . . . . . . . . . . . . . . 111\nCHAPTER 8 CONCLUSIONS AND RECOMMENDATIONS . . . . . . . . . . . . . 117\n8.1 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\n8.2 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\nvi\nLIST OF FIGURES\nFigure 1.1 Top 30 countries ranked by flared gas volume in 2018. . . . . . . . . . . . . 1\nFigure 1.2 The time series show the trend of gas flaring for the top two states in the United States (EIA 2019a). . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\nFigure 1.3 This Google Earth imagery shows gas flaring being conducted on a well location in North Dakota (Google Earth 2019). . . . . . . . . . . . . . . . . 3\nFigure 1.4 Part of the original poster (Earth Observation Group at Payne Institute 2019) which uses one year accumulation of VIIRS low light imaging data to showcase human activities, e.g., gas flaring, fishing, and city lights. . . . 4\nFigure 2.1 Landsat 8\u2019s spatial resolution (NASA 2020). . . . . . . . . . . . . . . . . . 8\nFigure 2.2 The evolution of four random walk Metropolis Markov chains (Carpenter 2020), each started in a different location. . . . . . . . . . . . . . . . . . . 14\nFigure 2.3 The flowchart adapted from (Betancourt 2020) shows a principled Bayesian workflow. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\nFigure 3.1 A screenshot of the top \u223c50 rows in the October 2018 production report. Each row corresponds to a well. There are in total 17,135 rows in this\nspreadsheet, with the first row being the header. . . . . . . . . . . . . . . 19\norders of magnitude less than that of VIIRS (around 1 m2). . . . . . . . . 21\nFigure 3.3 A count plot showing the distribution of cluster sizes: clearly there are a certain number of large clusters (as shown by the tail to the right). . . . . 22\nFigure 3.4 A large flare consisting of many hot pixels (detections), which is found by running the nightfire algorithm on L8 images. Both the Band 6\n(grayscale image) and the KMZ view are shown and provided by Christopher D. Elvidge (personal communication). . . . . . . . . . . . . . 22\nFigure 3.5 A heat map showing the pairwise Spearman correlations between the original time series\u2019 monthly observations. . . . . . . . . . . . . . . . . . . 25\nvii\nFigure 3.6 A heat map showing the pairwise Spearman correlations between the time series after applying the first differences. . . . . . . . . . . . . . . . . 26\nFigure 3.7 Visualizations of both the NDIC and VIIRS reportings. . . . . . . . . . . 27\nFigure 3.8 Posterior distributions (left column) and trace plots (right column) for the state level flaring model. . . . . . . . . . . . . . . . . . . . . . . . . . 29\nFigure 3.9 Intervals are constructed using posterior predictive samples. . . . . . . . . 30\nFigure 4.1 Scatterplots of NDIC and VIIRS reportings for different counties. . . . . . 36\nFigure 4.2 Scatterplots of NDIC and VIIRS reportings for different counties, without sharing neither x- nor y-axis for all the subplots. . . . . . . . . . 38\nFigure 4.3 LKJcorr(\u03b7 = eta) probability density. . . . . . . . . . . . . . . . . . . . . 40\nFigure 4.4 Posterior distributions and trace plots of the slopes for each county. . . . 43\nFigure 4.5 Posterior distributions and trace plots of the intercepts for each county. . 44\nFigure 4.6 A forest plot showing the uncertainties around each county\u2019s slope estimate. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\nFigure 4.7 A forest plot showing the uncertainties around each county\u2019s intercept estimate. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\nFigure 4.8 Correlation between the intercepts and slopes. . . . . . . . . . . . . . . . 48\nFigure 5.1 Posterior distributions and trace plots for the Blue Buttes Oilfield gas flaring proportion model. . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\nFigure 5.2 Posterior predictive samples showing the gas flaring proportion variations at the Blue Buttes Oilfield. . . . . . . . . . . . . . . . . . . . . . . . . . . 60\nFigure 5.3 Posterior distributions and trace plots for the Operator A gas flaring proportion model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\nFigure 5.4 Posterior predictive samples showing the gas flaring proportion variations of Operator A. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\nFigure 5.5 Posterior distributions and trace plots for the Blue Buttes Oilfield well flaring proportion model. . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\nviii\nFigure 5.6 Posterior predictive samples showing the well flaring proportion variations at the Blue Buttes Oilfield. . . . . . . . . . . . . . . . . . . . . 64\nFigure 5.7 Posterior distributions and trace plots for the Operator A well flaring proportion model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\nFigure 5.8 Posterior predictive samples showing the well flaring proportion variations of Operator A. . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\nFigure 5.9 Posterior distributions and trace plots for the Blue Buttes Oilfield flare count model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\nFigure 5.10 Posterior predictive samples showing the flare count variations at the Blue Buttes Oilfield. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\nFigure 5.11 Posterior distributions and trace plots for the North Dakota flare count model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\nFigure 5.12 Posterior predictive samples showing the flare count variations in North Dakota. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\nFigure 5.13 Posterior distributions and trace plots for the Blue Buttes Oilfield BOE flaring proportion model. . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\nFigure 5.14 Posterior predictive samples showing the BOE flaring proportion variations at the Blue Buttes Oilfield. . . . . . . . . . . . . . . . . . . . . 72\nFigure 5.15 Posterior distributions and trace plots of the BOE flaring proportion model for Operator A. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\nFigure 5.16 Posterior predictive samples showing the BOE flaring proportion variations of Operator A. . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\nFigure 5.17 Posterior distributions and trace plots for the North Dakota VIIRS-NDIC scale factor model. . . . . . . . . . . . . . . . . . . . . . . . 77\nFigure 5.18 Posterior predictive samples showing the scale factor variations of North Dakota. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\nFigure 5.19 Posterior distributions and trace plots for the Blue Buttes Oilfield VIIRS-NDIC scale factor model. . . . . . . . . . . . . . . . . . . . . . . . 79\nFigure 5.20 Posterior predictive samples showing the scale factor variations in the Blue Buttes Oilfield. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\nix\nFigure 5.21 Posterior predictive samples showing predictions of the scale factor for the next six months. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\nFigure 6.1 Effective usage of histograms can be surprisingly subtle. . . . . . . . . . . 84\nFigure 6.2 A histogram for the distribution of the oilfield detection counts from October 2018. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\nFigure 6.3 Posterior distributions and trace plots for the oilfield detection counts distribution, fitted with the data from October 2018. . . . . . . . . . . . . 88\nFigure 6.4 Histograms for the distribution of the oilfield detection counts from October 2018. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\nFigure 6.5 Histograms for the distribution of the oilfield detection counts from October 2018, with the y-axis clipped to better present those counts which are greater than zero. . . . . . . . . . . . . . . . . . . . . . . . . . 90\nFigure 6.6 Histogram for the distribution of the oilfield flared volumes from Q4 2018. . 92\nFigure 6.7 Distribution of the oilfield flared volume magnitudes from Q4 2018. . . . 93\nFigure 6.8 Ten random draws from a Dirichlet prior with \u03b1 = (6, 6, 6, 6, 6, 6, 6). . . . 95\nFigure 6.9 GMM inference results with different K\u2019s. . . . . . . . . . . . . . . . . . . 97\nFigure 6.10 WAIC values with different K\u2019s. . . . . . . . . . . . . . . . . . . . . . . . 98\nFigure 6.11 A scatterplot of oil production and flared gas volumes for different oilfields in Q4 2018. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\nFigure 7.1 Examples of good fits between the NDIC and VIIRS reported volumes, at the operator level. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\nFigure 7.2 Examples of poor fits between the NDIC and VIIRS reported volumes, at the operator level. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\nFigure 7.3 Time series of the two example operators whose reporting did not quite align with the VIIRS detected trends/patterns. The points or periods in time for which the company-reported data were significantly different\nfrom the satellite detections are annotated. . . . . . . . . . . . . . . . . 107\nFigure 7.4 A more comprehensive time series plot for Operator D. . . . . . . . . . 109\nFigure 7.5 A more comprehensive time series plot for Operator E. . . . . . . . . . 110\nx\nFigure 7.6 A neural network designed for the hypothetical well performance classification problem. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\nxi\nLIST OF TABLES\nTable 2.1 Resolutions of Landsat 8 and VIIRS . . . . . . . . . . . . . . . . . . . . . . . 7\nTable 3.1 Parameter Estimates of State Level Flaring Model . . . . . . . . . . . . . . 28\nTable 4.1 North Dakota County Abbreviations . . . . . . . . . . . . . . . . . . . . . . 37\nTable 4.2 Parameter Estimates of County Level Flaring Model . . . . . . . . . . . . . 49\nTable 6.1 Parameter Estimates of Oilfield Detection Count Distribution . . . . . . . . 88\nTable 7.1 Units for Operator Time Series in Figures 7.4 and 7.5 . . . . . . . . . . . 111\nTable 7.2 Publication Count Rise on OnePetro . . . . . . . . . . . . . . . . . . . . . 112\nTable 8.1 Models Developed in this Dissertation . . . . . . . . . . . . . . . . . . . . 119\nxii\nLIST OF SYMBOLS\nVectors and matrices are in bold type. A subscript asterisk, such as in y\u2217, indicates reference to a test set quantity or a prediction.\nGeneral Nomenclature\n`2 norm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \u2016\u00b7\u2016 Data set: D = {(xi, yi) | i = 1, . . . , n} . . . . . . . . . . . . . . . . . . . . . . . . . . . . D\nNatural numbers with zero . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . N0\nPi (italic) representing a variable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \u03c0\nPi (upright) denoting the transcendental constant (3.14159 \u00b7 \u00b7 \u00b7 ) . . . . . . . . . . . . . \u03c0\nPrediction for a test input x\u2217 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . y\u2217 Proportional to; e.g., p(x | y) \u221d p(x, y) means that p(x | y) is equal to p(x, y) times a factor which is independent of x . . . . . . . . . . . . . . . \u221d\nReal numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . R\nUniversal quantifier: for all x . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \u2200x\na is defined as b . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . a := b\nb is defined as a . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . a =: b\nn-dimensional vector space of real numbers . . . . . . . . . . . . . . . . . . . . . . . . . Rn\nProbability and Statistics\nConditional probability density function . . . . . . . . . . . . . . . . . . . . . . . . p(\u00b7 | \u00b7)\nExpectation; expectation of g(x) when x \u223c p . . . . . . . . . . . . . . . . . . E or Ep[g(x)] Probability density function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . p(\u00b7)\nxiii\nProbability mass function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . P (\u00b7)\nRandom variable X is distributed according to p . . . . . . . . . . . . . . . . . . . X \u223c p\nVariance; variance of g(x) when x \u223c p . . . . . . . . . . . . . . . . . . . . . V or Vp[g(x)]\nProbability Distributions\nBinomial distribution with parameters n, p . . . . . . . . . . . . . . . . . . Binomial(n, p)\nCategorical distribution with parameter p . . . . . . . . . . . . . . . . . . Categorical(p)\nContinuous uniform distribution with parameters a, b . . . . . . . . . . . . . Uniform(a, b)\nDirichlet distribution with parameter \u03b1 . . . . . . . . . . . . . . . . . . . . . Dirichlet(\u03b1)\nDistribution over Cholesky decomposed covariance matrices with parameters \u03b7, \u03c3 . . . . . . . . . . . . . . . . . . LKJCholeskyCov(\u03b7, \u03c3)\nExponential distribution with parameter \u03bb . . . . . . . . . . . . . . . . . . Exponential(\u03bb)\nGamma distribution with parameters \u03b1, \u03b2 . . . . . . . . . . . . . . . . . . . Gamma(\u03b1, \u03b2)\nHalf-Cauchy distribution with parameter \u03b3 . . . . . . . . . . . . . . . . . . Half-Cauchy(\u03b3)\nHalf-Normal distribution with parameter \u03c3 . . . . . . . . . . . . . . . . . . Half-Normal(\u03c3)\nLKJ distribution with parameter \u03b7 . . . . . . . . . . . . . . . . . . . . . . . . LKJcorr(\u03b7)\nMultivariate Gaussian distribution with parameters \u00b5, \u03a3 . . . . . . . . MVNormal(\u00b5, \u03a3)\nNegative binomial distribution with parameters \u00b5, \u03c6 . . . . . . . . . . . NegBinomial(\u00b5, \u03c6)\nPoisson distribution with parameter \u03bb . . . . . . . . . . . . . . . . . . . . . . Poisson(\u03bb)\nStudent\u2019s t-distribution with parameters \u03bd, \u00b5, \u03c3 . . . . . . . . . . . . . Student-t(\u03bd, \u00b5, \u03c3)\nUnivariate Gaussian distribution with parameters \u00b5, \u03c3 . . . . . . . . . . . . . . . N (\u00b5, \u03c3)\nGaussian Processes\nCovariance function evaluated at x and x\u2032 . . . . . . . . . . . . . . . . . . . . . . k(x,x\u2032)\nxiv\nGaussian process: f \u223c GP(m(x), k(x,x\u2032)), the function f is distributed as a Gaussian process . . . . . . . . . . . . . . . . . . . . . . . . . . . GP\nMean function evaluated at x . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . m(x)\nVector of latent function values, f = (f(x1), . . . , f(xn)) > . . . . . . . . . . . . . . . . . . f\nVectors and Matrices\nCholesky decomposition: L is a lower triangular matrix such that L \u00b7 L> = K . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Cholesky(K)\nIdentity matrix of size n\u00d7 n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . In Transpose of matrix L . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . L>\nVector of all 0\u2019s of length n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 0n\nVector of all 1\u2019s of length n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1n\nVector of parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \u03b8\nStandard Functions Inverse-logit function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . logit\u22121(\u00b7)\nNatural exponential function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . exp(\u00b7)\nNatural logarithm function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . log(\u00b7)\nUnits\nbarrels of oil equivalent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . BOE\nbarrels per day . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . bbl/day\nbillion cubic meter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . bcm\nday . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . d\ndollars per barrel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . $/bbl\ndollars per million Btu . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . $/MMBtu\nxv\nkelvin . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . K\nkilometer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . km\nmegawatt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . MW\nmeter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . m\nmillion cubic feet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . MMcf\nthousand cubic feet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Mcf\nthousand cubic feet per barrel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Mcf/bbl\nxvi\nLIST OF ABBREVIATIONS\nAutoregressive integrated moving average . . . . . . . . . . . . . . . . . . . . . . ARIMA\nCredible interval . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . CI\nDeep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . DL\nDensity-Based Spatial Clustering of Applications with Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . DBSCAN\nEnergy Information Administration . . . . . . . . . . . . . . . . . . . . . . . . . . . . EIA\nExempli gratia (Latin: for example) . . . . . . . . . . . . . . . . . . . . . . . . . . . . e.g.\nGas oil ratio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . GOR\nGaussian mixture model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . GMM\nGaussian process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . GP\nHamiltonian Monte Carlo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . HMC\nHierarchical Density-Based Spatial Clustering of Applications with Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . HDBSCAN\nHighest density interval . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . HDI\nId est (Latin: that is) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . i.e.\nIndependent and identically distributed . . . . . . . . . . . . . . . . . . . . . . . . . . i.i.d.\nInterquartile range . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . IQR\nKernel density estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . KDE\nLandsat 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . L8\nLong short-term memory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . LSTM\nMarkov chain Monte Carlo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . MCMC\nxvii\nMaximum a posteriori . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . MAP\nMaximum likelihood estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . MLE\nNational Aeronautics and Space Administration . . . . . . . . . . . . . . . . . . . . NASA\nNational Oceanic and Atmospheric Administration . . . . . . . . . . . . . . . . . NOAA\nNorth American Datum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . NAD\nNorth Dakota Industrial Commission . . . . . . . . . . . . . . . . . . . . . . . . . . NDIC\nPrediction interval . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . PI\nRadiant heat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . RH\nRight-hand side . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . RHS\nShort-wave infrared . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . SWIR\nVIIRS Nightfire . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . VNF\nVisible Infrared Imaging Radiometer Suite . . . . . . . . . . . . . . . . . . . . . . . VIIRS\nWorld Geodetic System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . WGS\nZero-inflated Poisson . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ZIP\nZero-inflated negative binomial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ZINB\nxviii"
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "In the very first place, I want to express my deepest appreciation to my advisor, Dr. Jennifer L. Miskimins. Dr. Miskimins has been my MS/PhD advisor and mentor since 2011. Since I returned to Mines to start my PhD in 2017, Dr. Miskimins has been providing me with the best guidance, the greatest support, and the most opportunities that I could imagine. During the first semester, I worked as a lab assistant in the High Bay; in a later semester, I worked as a teaching assistant in her well stimulation course; ever since I started to become interested in machine learning, she has provided me with a huge number of opportunities to connect with different groups of people, for brainstorming and pursuing my research interest. To a certain extent, I feel like I finally become a \u201cqualified\u201d FAST student member, thanks to all of these precious experience. What I have achieved, including this dissertation, would have never been possible without the guidance and support from Dr. Miskimins. Her world-class technical expertise, attitudes toward work/life, and art of managing different teams at various levels are what I hope I can learn from in my career and personal life.\nI am deeply grateful to my dissertation committee members: Dr. Soutir Bandyopadhyay, Dr. Alfred W. Eustes III, Dr. Yilin Fan, and Prof. Jim Crompton. My competency in my research field, as well as the shape of this dissertation are built with the help of those fruitful discussions and insightful comments from them.\nI am indebted to my mentors, colleagues, and friends from the Payne Institute for Public Policy. Especially, I want to thank Dr. Mikhail N. Zhizhin, Dr. Christopher D. Elvidge, and Dr. Morgan D. Bazilian. It is such an eye-opening experience for me to work with these world-class experts in remote sensing and satellite imagery. I would particularly like to thank Dr. Zhizhin for his help, insights, and time.\nI am really grateful to Dr. Bandyopadhyay and Dr. Luis Tenorio from the AMS Department, for their fantastic teaching, knowing me personally and motivating me to work hard. Looking\nxix\nback at what I have learned in machine learning which makes this dissertation possible, taking their classes are definitely the most important resources for myself (excuse me for not being a probabilist at this moment). By taking their statistical methods classes, I started to appreciate what really is machine learning, and falling in love with mathematics, more specifically, probability theory and statistical modeling.\nThe TA experience at Mines makes me a better PhD student. What I have learned, technical or non-technical, made their way into this dissertation. I want to thank Prof. Crompton, Dr. Eustes, Dr. Mark G. Miller, Dr. Linda A. Battalora, and Dr. Miskimins for providing me with those valuable TA opportunities. I am grateful to all of my students for their support and feedback.\nI want to thank Dr. Yu-Shu Wu, Dr. Xiaolong Yin, and Dr. Yilin Fan for their care, support, and encouragement throughout my PhD study. I would like to thank Denise Winn-Bower, Rachel McDonald, and Joe Chen for their help.\nI really appreciate the feedback from the FAST member companies\u2019 representatives. A lot of the discussions and the reflections following those were incorporated into this dissertation. Especially, I want to thank Ty Woodworth for his time and help, in the process of collecting plunger lift data for me. I got very warm welcomes every time I visited their Windsor office in Northern Colorado. Ty kindly introduced me to the team he led, and I got the great opportunities to ask questions and discuss with many field experts in different areas. Those discussions helped me tremendously.\nSpecial thanks go to the open source community. In the process of conducting this research and typesetting this dissertation, I benefited a lot from the ecosystems around Linux/GNU, TEX/LATEX, and Python. Especially, I want to thank the people behind PyMC3, a probabilistic programming language that this dissertation is heavily dependent upon.\nLast but not least, I would like to thank my family and friends. Thank you to my beloved wife Xiaodan, for all her love, support, and delicious dishes. I also want to thank my parents and parents-in-law for their support, encouragement, and understanding.\nxx\nI dedicate this work to my mother, Dr. Lingying Ni, and my father, Mr. Honggang Lu.\n\u8c01\u8a00\u5bf8\u8349\u5fc3\uff0c\u62a5\u5f97\u4e09\u6625\u6656\u3002\nxxi\nCHAPTER 1\nINTRODUCTION\nCurrently in the petroleum industry, for wells which produce both crude oil and natural gas, operators often choose to flare the produced gas instead of commodifying it. The rationales behind such decisions are multifold. Variations in natural gas price can be an important factor, especially when the processing and transportation cost is higher than the value of gas (Srivastava et al. 2019). The amount of gas being flared each year on a national level is huge, and an increasing trend can be observed for the top flaring countries (Figure 1.1).\nSource: NOAA, Colorado School of Mines, GGFR\nThe new ranking \u2013 top 30 flaring countries (2014 \u2013 2018)\nRanked by 2018 flare volume Million m3 gas/year flared\nP ub\nlic D\nis cl\nos ur\ne A\nut ho\nriz ed\nP ub\nlic D\nis cl\nos ur\ne A\nut ho\nriz ed\nP ub\nlic D\nis cl\nos ur\ne A\nut ho\nriz ed\nP ub\nlic D\nis\ncl\nos ur\ne A\nut\nho\nriz ed\nFigure 1.1: Top 30 countries ranked by flared gas volume in 2018. United States ranks No. 4 and has a large increase from 2017 to 2018 (World Bank 2019).\nDue to the boom of unconventional resources (e.g., shale gas reservoirs) development in the recent decade, the United States has been among the top flaring countries in terms\n1\nof total volume flared. This is backed by the data from the U.S. Energy Information Administration (EIA) (2019) showing North Dakota, which is underlain by the Bakken Formation, and Texas, which houses the Permian Basin and the Eagle Ford Shale, are the top two flaring states since 2013. The two states\u2019 annual flaring volume time series are shown in Figure 1.2. Some flaring sites can be clearly identified from Google Earth\u2019s imagery (Figure 1.3).\nNatural gas flaring constitutes a problem of energy waste and CO2 emissions. In recent years, various organizations and government agencies have advocated reducing or eliminating routine gas flaring. For example, the North Dakota Industrial Commission (NDIC) introduced a gas flaring regulatory policy (Order 24665) in 2014, with goals of reducing flaring in different aspects (e.g., volume of gas flared). The World Bank launched the \u201cZero Routine Flaring by 2030\u201d initiative in 2015. To monitor and benchmark flaring activity\u2019s magnitude, a precise and accurate method to obtain quantitative flaring information is desirable. However, in certain situations, this information is only available through self-reporting mechanisms.\n2\nInaccuracies might be introduced either intentionally or unintentionally.\nSatellite remote sensing is one unbiased approach for solving this problem. It can help detect active flares especially during nighttime and can be used to calibrate the estimation for flared gas volume. For this work, two different types of sensors are considered, including the Landsat 8 (L8)\u2019s Operational Land Imager (OLI) and Thermal Infrared Sensor (TIRS), as well as the Visible Infrared Imaging Radiometer Suite (VIIRS) that is on the Suomi National Polar-orbiting Partnership (NPP) and NOAA-20 satellites. In the remainder of this dissertation, they are referred to as L8 and VIIRS, respectively. An example of detecting flaring with VIIRS low light imaging data is shown in Figure 1.4."
        },
        {
            "heading": "1.1 Research Goal",
            "text": "This research is undertaken to achieve the following goals:\n\u2022 Evaluate the methodology for estimating flared gas volume leveraging satellite imagery;\nand,\n3\n\u2022 Find insights into operators\u2019 gas flaring behavior."
        },
        {
            "heading": "1.2 Dissertation Objectives",
            "text": "To achieve the goals outlined in Section 1.1, more specific objectives are listed below:\n1. Compare and contrast the flaring data from VIIRS and NDIC.\n\u2022 Compare the VIIRS flared volumes to the NDIC, using the NDIC as a benchmark.\n2. Evaluate the effectiveness of using Landsat 8 nighttime images to improve flare detection\nand volume estimation.\n\u2022 Determine the detection limits of Landsat 8 and compare it with VIIRS\u2019 capabili-\nties.\n3. Investigate operator approaches for gas flaring.\n4\n\u2022 Determine the correlation between gas price / oil price / oil production and flared\ngas volume.\n\u2022 Evaluate if the North Dakota regulatory policy (Order 24665) achieved its goals.\n\u2022 Develop a model that can predict flared gas volume at a state level.\n4. Find any hidden structure/clusters from all the producing entities."
        },
        {
            "heading": "1.3 Outline and Contributions",
            "text": "The main contribution of this dissertation is demonstrating that Bayesian learning\nimplemented by Markov chain Monte Carlo methods is very effective in flaring data analytics. A series of parametric and nonparametric machine learning models are developed for various analytics goals and granularities, providing direct guidance for future modeling endeavors. To demonstrate the effectiveness and robustness, they are all tested with real data. The superiority of this approach is based on the fact that the inference stage is entirely probabilistic, in that the parametric uncertainties arising from probable models as well as the stochastic uncertainties arising from noisy observations are all properly characterized and quantified. It makes the extracted insights robust and interpretable for decision- and policy-making by, for example, a state government.\nIn Chapter 2, a literature review is given for the state of the art in satellite imagery\nprocessing, Bayesian inference, Markov chain Monte Carlo methods, and machine learning.\nIn Chapter 3, the data gathering processes are discussed. Results from some exploratory\ndata analysis are presented.\nIn Chapter 4, county level models are built to study the correlations between VIIRS and\nNDIC, and to explore the heterogeneity among the counties in North Dakota.\nIn Chapter 5, flaring time series analytics is presented for the purposes of revealing trends\nand patterns at different levels.\nIn Chapter 6, unsupervised learning is applied on flaring data to characterize the latent\nstructures.\n5\nIn Chapter 7, a method of operator level monitoring and analytics is introduced, and\nsome discussions about applying Bayesian learning are given.\nIn Chapter 8, major conclusions drawn are presented. Recommendations based on this\nwork are given. A number of future research areas are outlined.\n6\nCHAPTER 2\nLITERATURE REVIEW\nIn the 1990s, the World Bank started gathering nighttime satellite images, from which big cities and oilfields were both bright and needed to be sorted using extra information. The situation changed in 2012 when infrared data became available from VIIRS (Rassenfoss and Zborowski 2018). One of the data products, VIIRS Nightfire (VNF) specializes in natural gas flaring observation and is even able to distinguish between biomass burning and gas flaring (Elvidge et al. 2017).\nVNF\u2019s development was based upon VIIRS imagery. To improve the performance of flare detection and gas volume estimation, other sources of information, such as L8 imagery, can be leveraged. Table 2.1 presents a comparison of L8 and VIIRS spatial and temporal resolutions (NASA 2019; Wikipedia 2019). Figure 2.1 illustrates L8\u2019s spatial resolution. In addition, L8 collects data in 11 different spectral bands of the electromagnetic spectrum. VIIRS has 22 bands. Both L8 and VIIRS are in near-polar orbits of the earth and can reveal rich features in the landscape. Therefore, L8 should be able to identify smaller gas flares compared to VIIRS\u2019 capability, although its longer satellite revisit time poses a challenge to identify less persistent flares. More details on the processing steps of VNF are discussed in Section 2.1, the essence of which will be applied to L8.\nNowadays, one resource which is more than abundant is data. For a certain discipline or research field, new sources of data bring in new dimensions of information, such as satellite images are now playing a role in gas flaring analytics. How to analyze data effectively and intelligently to gain insights is a central problem. In the petroleum engineering domain, for example, data driven approaches have been proposed to analyze stimulation treatments (Kazakov and Miskimins 2011) and predict screenouts (Yu et al. 2020). Machine learning is a powerful tool for this purpose. It is at the core of artificial intelligence and data science, and lies at the intersection of statistics and computer science (Jordan and Mitchell 2015). Frameworks in computational learning theory, such as the PAC learning proposed by Valiant (1984), help provide a theoretical backbone for some learning algorithms.\nOne subset of machine learning, deep learning (DL), had its debut in 2006 when Hinton and Salakhutdinov introduced Deep Belief Networks (DBN), but it did not gain wide acceptance until 2012 when AlexNet showed the breakthrough performance on classification accuracy in the ImageNet competition (Krizhevsky et al. 2012). AlexNet is a DL-based model (more\n8\nspecifically a convolutional neural network) and achieved an error rate of 15.3 %, which is more than 10 % lower than the runner-up. DL dominated the competition thereafter, and DL-based models finally surpassed human performance on the classification data set in 2015 (He et al. 2015).\nAlthough neural network-based models have gained much success in recent years, it should be noted that no one type of model can always be the best candidate for all problems. This has been formally shown by Wolpert (1996), and is usually referred to as the \u201cno free lunch\u201d (NFL) theorem. More recently, Olson et al. (2017) empirically assessed 13 classification algorithms on 165 different problem sets, and the results aligned with the theorem: even the union of the top five best performing algorithms cannot dominate all of the problem sets.\nIn the following sections, a detailed review is given for the aspects below, which serve as\nthe foundation and inspiration for this work:\n1. Satellite image processing\n2. Bayesian inference\n3. Markov chain Monte Carlo\n4. Machine learning\n5. Analytics toolset"
        },
        {
            "heading": "2.1 Satellite Image Processing",
            "text": "Satellite images are utilized to estimate flared gas volume. The fire detection algorithm based on Planck curve fitting and physical laws, known as VIIRS Nightfire (VNF) due to Elvidge et al. (2013), serves as a starting point for analyzing L8 images in this research. The method consists of several major steps:\n1. Detection of hot pixels\nDuring nighttime, the sensors mainly record instrument noise which approximately follows a Gaussian distribution, except for the few pixels that contain an infrared\n9\nemitter such as a gas flare. Therefore hot pixels can be identified by setting a cutoff on the tail of the distribution, e.g., those pixels with digital numbers exceeding the mean plus four standard deviations.\n2. Noise filtering\nHot pixels that are detected in only one spectral band are treated as noise and filtered out.\n3. Atmospheric correction\nLosses in radiance due to scattering and absorption effects can be corrected. MODTRAN \u00ae 5 (Berk et al. 2006), parameterized with atmospheric water vapor and temperature profiles, is used to derive the correction coefficients for each spectral band.\n4. Planck curve fitting\nPlanck curves are modeled for gas flares, which appear as gray bodies because they are sub-pixel sources. Therefore the output of the fitting is an estimate of the temperature and an emission scaling factor (the emissivity term in the Planck function). The latter is used subsequently to estimate the source area.\n5. Calculation of source area\nThe source area S is calculated using\nS = \u03b5A , (2.1)\nwhere \u03b5 is the emission scaling factor and A is the size of the pixel footprint.\n6. Calculation of radiant heat\nThe radiant heat is calculated using the Stefan\u2013Boltzmann law:\nRH = \u03c3T 4S , (2.2)\n10\nwhere RH is the radiant heat in MW, \u03c3 is the Stefan\u2013Boltzmann constant, T is the temperature in K, and S is the source area in m2.\nOnce RH is obtained, previous work by Elvidge et al. (2015) developed a calibration for estimating flared gas volume, utilizing nation-level flaring reporting provided by Cedigaz (2015) and state-level reporting from Texas and North Dakota. The developed calibration can then be applied to each individual flaring site worldwide for estimation of flared gas volume, etc."
        },
        {
            "heading": "2.2 Bayesian Inference",
            "text": "Bayesian inference leverages conditional probability theory to establish a formal procedure for learning from data (Betancourt 2018). Bayesian models provide full joint probability distributions p(D,\u03b8) over observable data D and unobservable model parameters \u03b8. The essence of Bayesian analysis is to obtain the posterior distribution p(\u03b8 | D), which characterizes the conditional probability of parameters \u03b8 given some data D. It can be derived through Bayes\u2019 theorem:\np(\u03b8 | D) = p(D | \u03b8) p(\u03b8) p(D) (2.3a)\n= p(D | \u03b8) p(\u03b8)\u222b p(D | \u03b8\u2032) p(\u03b8\u2032) d\u03b8\u2032 (2.3b) \u221d p(D | \u03b8) p(\u03b8) , (2.3c)\nwhere p(D | \u03b8) is the likelihood (also referred to as the observation model) which denotes how likely the data is given a certain set of parameters, and p(\u03b8) is the prior which models the probability of the parameters before observing any data. The prior encodes domain expertise. Once some observations are given, it is updated into a posterior which quantifies how consistent the model configurations are with both the domain knowledge and the observed data (Betancourt 2018). After the posterior is obtained, most if not all inferential questions can then be answered with posterior expectation values of certain functions (Betancourt\n11\n2019):\nEp[g(\u03b8)] =\n\u222b g(\u03b8) p(\u03b8 | D) d\u03b8 , (2.4)\nwhere g(\u03b8) is the function encoding some inferential question (e.g., where in the model configuration space the posterior concentrates).\nPredictions can be made in the form of a posterior predictive distribution: p(y\u2217 | x\u2217,D) = \u222b p(y\u2217 | \u03b8,x\u2217) p(\u03b8 | D) d\u03b8 , (2.5)\nwhere y\u2217 is the predictions based on the training set D for a test input x\u2217. Essentially this is integrating the prediction p(y\u2217 | \u03b8,x\u2217) over the posterior distribution of parameters (Rasmussen and Williams 2006). Note that by giving the final results in terms of a probability distribution, richer information and more reliable inferences are accessed compared to merely giving a point estimate through MLE or MAP (as some machine learning models do under the frequentist framework). This is achieved by incorporating into the inference process the uncertainty in the posterior parameter estimate. Other benefits include posterior predictive checks, which are conducted by checking for auto-consistency between generated data (y\u2217) and observed data (y)."
        },
        {
            "heading": "2.3 Markov Chain Monte Carlo",
            "text": "Many of the integration problems central to Bayesian statistics, including those in Equations 2.4 and 2.5, are analytically intractable. A class of sampling algorithms, known as Markov chain Monte Carlo (MCMC), can be applied to approximate these (Andrieu et al. 2003). Suppose for some function of interest f(x), the objective is to obtain its integral, with respect to a non-standard target distribution p(x) from which samples cannot be drawn directly:\nI(f) = \u222b f(x) p(x) dx . (2.6)\nBy constructing Markov chains that have p(x) as the invariant distribution, MCMC samplers, while traversing the sample space X , are able to generate samples x(i) that mimic samples\n12\ndrawn directly from the target distribution p(x). In other words, this mechanism makes it possible to draw a set of samples {x(i)}Ni=1 from p(x).\nThen, by the Monte Carlo principle, the integral I(f) can be approximated with a sum\nIN(f):\nIN(f) = 1\nN N\u2211 i=1 f(x(i)) a.s.\u2212\u2212\u2212\u2212\u2192 N\u2212\u2192\u221e I(f) = \u222b f(x) p(x) dx . (2.7)\nThat is, the estimate IN(f) is unbiased and by the strong law of large numbers, it will converge almost surely (a.s.) to I(f). That\u2019s why MCMC is a powerful tool in Bayesian analysis. In practice, the Metropolis-Hastings (MH) algorithm and Gibbs sampling have been popular MCMC methods (Andrieu et al. 2003), but only when the parameter space is not too high-dimensional (McElreath 2020).\nDue to limited computing resources, it is impossible to run Markov chains infinitely long. In other words, inference has to be made based on finitely many draws. One approach, which is effectively leveraged in this research, is to run multiple chains in parallel and monitor various statistics for diagnosing non-convergence. Besides the effective sample size per transition of the Markov chain, the Gelman-Rubin statistic (Gelman and Rubin 1992), denoted by R\u0302, is used in this dissertation. The R\u0302 statistic quantifies whether the ensemble of Markov chains initialized from diffuse points in parameter space finally converge to the same equilibrium phase (Betancourt 2017b). When R\u0302 is sufficiently close to 1 (for example R\u0302 < 1.05), convergence is declared to be achieved. As an example, Figure 2.2 presents how four chains are started in different corners but approach stationarity and convergence after a certain number of iterations.\nFor many of the problems in practice, including the models in this dissertation, the parameter space is very high-dimensional and involves highly curving regions. The MetropolisHastings algorithm and Gibbs sampling are far from efficient in these situations. Hamiltonian Monte Carlo (HMC), originally proposed by Duane et al. (1987), really outshines the other algorithms at this point and is the main sampling strategy adopted in this dissertation.\n13\nSpecifically, No-U-Turn Sampler (NUTS) introduced by Hoffman and Gelman (2014), which is an extension to HMC, is employed for sampling from posterior distributions."
        },
        {
            "heading": "2.4 Machine Learning",
            "text": "Machine learning was defined by Mitchell (1997) as computers improving automatically through experience. It can also be viewed as a function estimation problem (Vapnik 2000), or as the process of extracting important patterns and trends from data (Hastie et al. 2009).\nIn terms of tasks, common types of learning consist of supervised, unsupervised, semi-\nsupervised, and reinforcement (Burkov 2019). Let xi \u2208 X \u2286 Rd represent input, and yi \u2208 Y represent target, then the goals of the first two types are:\n\u2022 Supervised learning aims to use the dataset, consisting of X = {xi}ni=1 and y = {yi}ni=1,\nto produce a model that is able to predict an output (yj) given some new/unseen input (xj), i.e., learning the underlying mapping f : X \u2192 Y .\n\u2022 Unsupervised learning is used to find the hidden patterns in X; in this case there does\nnot exist any labels (y) or predefined targets.\n14\nAnother variation of learning is online learning, in which case training data is fed to the algorithm continuously or one example at a time (Abu-Mostafa et al. 2012). In other words, streaming data is available that the algorithm has to process on the run. This is different from batch learning, where data is provided beforehand and \u201cfrozen\u201d during the learning process. Online learning can be applied to the different tasks as discussed above (supervised and others).\nIn terms of model characteristics, machine learning models can be categorized into parametric and nonparametric models. Parametric models are characterized by a fixed number of parameters, whereas nonparametric models have an infinite-dimensional parameter space. For example, in the latter case the parameter space can be the set of continuous functions in a regression setting (Orbanz and Teh 2010). In this dissertation, supervised and unsupervised learning are leveraged while exploiting both parametric and nonparametric models.\nFrom Bayesian\u2019s perspective, machine learning is essentially computing the posterior (de Freitas 2013), which is then used for inference and prediction tasks. This is conducted exactly through Equation 2.3a. In practice, machine learning conducted under Bayesian\u2019s framework follows a principled workflow (Figure 2.3), which is adapted for the modeling in this dissertation."
        },
        {
            "heading": "2.5 Analytics Toolset",
            "text": "For the past five to ten years, prosperity in contributions and progress in the open source community has been witnessed. Ecosystems around Python, R, and Julia have been prototyped, tested, and deployed in production environments in various industries. Powerful probabilistic programming languages (PPL), for example Stan (Carpenter et al. 2017) and PyMC3 (Salvatier et al. 2016), have become the workhorse for Bayesian machine learning.\nThe majority of this work is implemented in Python. Specifically, Bayesian learning is performed by leveraging PyMC3. Some analytic visualizations are produced employing ArviZ (Kumar et al. 2019). Geospatial operations are performed with the help of GeoPan-\n15\ndas (Jordahl et al. 2020). Satellite imagery is processed and analyzed in MATLAB, with implementations mainly following Elvidge et al. (2013).\n16\nCHAPTER 3\nDATA PREPROCESSING AND EXPLORATORY DATA ANALYSIS\nIn this chapter, an overview of the flaring data is given. Some other variables which might be correlated with the flaring statistics are also considered. Exploratory data analysis is performed for choosing the subset of the variables as the focus in this dissertation. A state level model is developed in the end which motivates the work in the next two chapters."
        },
        {
            "heading": "3.1 Data Gathering",
            "text": "Four sources of data, L8 satellite images, VIIRS estimated flared volumes, NDIC monthly production reports, and county/oilfield shapefiles for North Dakota were gathered for the analysis used in this research."
        },
        {
            "heading": "3.1.1 Landsat 8 Images",
            "text": "In total, 167 images (since 2013) were downloaded from Google Cloud using the criteria\nbelow:\n\u2022 From five Path/Row\u2019s: 126/216, 126/217, 126/218, 127/216, and 127/217.\nAccording to the Worldwide Reference System (WRS), the satellite imagery of any portion of the world can be queried using Path and Row numbers. These five Path/Row\u2019s cover the majority of the areas in North Dakota that have production and flaring activities.\n\u2022 Nighttime images.\nOnly nocturnal Landsat 8 imagery are used for the purpose of flare detection.\n\u2022 Cloud cover less than 10 %.\nImages with low cloud cover percentages reveal more clearly land features including gas flares, and thus are ideal for validating the developed methodologies.\n17\n\u2022 GeoTIFF Data Product.\nBoth the georeferencing information and the raw images of all the spectral bands are preserved through the GeoTIFF format, which are necessary for the analysis."
        },
        {
            "heading": "3.1.2 VIIRS Estimated Volumes",
            "text": "The VIIRS flare inventory and estimated volume dataset obtained from Mikhail N. Zhizhin (personal communication) are used in this dissertation. This dataset includes monthly flare detection records in North America from March 2012 to December 2018 (both inclusive) with their associated:\n\u2022 Timestamps giving the specific month\n\u2022 Latitudes and longitudes in WGS 84 coordinates\n\u2022 Flared volume estimations in bcm"
        },
        {
            "heading": "3.1.3 NDIC Monthly Production Reports",
            "text": "All the monthly production reports from May 2015 to April 2020 (both inclusive) which have flaring information have been downloaded from NDIC. There is one Excel spreadsheet per month; each row corresponds to a well (that was active in that month), and columns are for various types of information, including flared gas volume (estimated and reported by operator), oilfield, oil production, etc. A screenshot of the top \u223c50 rows in one of the spreadsheets is displayed in Figure 3.1."
        },
        {
            "heading": "3.1.4 NDIC Shapefiles",
            "text": "The shapefiles for the counties and oilfields in North Dakota are downloaded from the NDIC GIS Map Server. All the polygons are described in NAD 27 coordinates. The shapefiles are for reverse geocoding the satellite detection locations to readable addresses, specifically which county and oilfield is a flare located in.\n18\nF ig\nu re\n3. 1:\nA sc\nre en\nsh ot\nof th\ne to\np \u223c\n50 ro\nw s\nin th\ne O\nct ob\ner 20\n18 p ro\nd u ct\nio n\nre p\nor t.\nE ac\nh ro\nw co\nrr es\np on\nd s\nto a\nw el\nl. T\nh er\ne ar e in to ta l 17 ,1 35 ro w s in th is sp re ad sh ee t, w it h th e fi rs t ro w b ei n g th e h ea d er .\n19"
        },
        {
            "heading": "3.2 Satellite Image Processing",
            "text": "As discussed in Section 3.1.1, all the available L8 images have been downloaded. They are processed in batch, following the workflow as outlined in Section 2.1. To compare and contrast with VIIRS\u2019 performance, specifically the nighttime combustion source detection limits, all the flares detected from all of the L8 images are gathered and used to generate the source area versus temperature scattergram shown in Figure 3.2.\nAlthough it is expected that L8 would pick up smaller flares than VIIRS (which is capable of detecting flares around the size of a whole cooktop area), the majority of the detections as indicated on the scattergram are too small for natural gas flaring. To verify if some hot pixels are clustered together and actually representing a single flare or flaring site, HDBSCAN (Campello et al. 2013) with an implementation due to McInnes et al. (2017) is executed on every L8 detection map to find out if large blobs of hot pixels are present. HDBSCAN is a density-based clustering algorithm which keeps all the advantages of the original DBSCAN (Ester et al. 1996), for example the capacity of finding clusters of arbitrary shapes. It also outperforms DBSCAN by being able to build clusters of varying density (Burkov 2019). Further, to get the most accurate results in this case, haversine metric is chosen to handle the great-circle distances between the hot pixels; leaf clustering is used instead of the default Excess of Mass method to produce more fine grained clusters. The clustering results are illustrated in Figure 3.3.\nTo verify whether these clusters are really single flares or they are actually a large number of neighboring wells (in which case each hot pixel still represents an individual flare), they are tracked down by looking further into each detection map (KMZ file). It is found that some large blobs of hot pixels are clustered and indeed represent single (huge) flares. One of the examples is shown in Figure 3.4. This poses a challenge to situations where an accurate estimate of the flare count is needed.\nThe reason for this processing artifact is that, for large flares, there is glow surrounding the flare that was treated as many individual combustion sources. There are potential approaches\n20\n21\nto mitigate this to make the interpretation and estimation out of L8 more accurate. In this work, the flares detected from VIIRS and the gas volumes estimated out of those are the focus for analytics.\n22"
        },
        {
            "heading": "3.3 Reverse Geocoding",
            "text": "By reverse geocoding, the county information of every VIIRS flare that is in North Dakota can be retrieved. For most of the flares, the oilfield information is also retrievable. Thereafter, the flaring statistics from VIIRS and NDIC can be compared and contrasted at different levels, for a certain point or period of time.\nShapefiles as discussed in Section 3.1.4 are used. With the help of GeoPandas, the\nprocedures for extracting counties and oilfields are the same:\n1. Read the VIIRS records into a geospatial data object, with their original coordinates in\nWGS 84.\n2. Read the shapefile into a geospatial data object, with its original coordinates in NAD\n27.\n3. Transform all the geometries in the shapefile to WGS 84 coordinates.\n4. Perform a spatial join of the two data objects to get the county or oilfield information\nfor each flare, if a specific county/oilfield\u2019s polygon and the flare intersect, i.e., having any boundary or interior point in common."
        },
        {
            "heading": "3.4 Correlational Analysis",
            "text": "To study the correlations between oil/gas prices, flaring statistics, and production performance, various time series are extracted for May 2015 to December 2018 (both inclusive). The below list describes all the variables used with their associated labels:\nVIIRS flared vol monthly flared gas volume from VIIRS\nNDIC flared vol monthly flared gas volume from NDIC\nWTI oil price WTI crude oil price given by EIA (2020b)\nHenry Hub gas price Henry Hub natural gas price given by EIA (2020a)\n23\nNDIC oil prod monthly oil production from NDIC\nNDIC gas prod monthly gas production from NDIC\nVIIRS flare count monthly flare detections count from VIIRS\nNDIC flaring well count monthly wells count which conduct flaring from NDIC\nNDIC GOR ratio of the NDIC gas production to the NDIC oil production\nFirst, the monthly observations are extracted from each time series, and Spearman\u2019s \u03c1 is employed to measure the statistical dependence between the variables. Spearman\u2019s \u03c1 is a rank correlation, which quantifies the correlation between the rankings of two variables. Compared to Pearson\u2019s r, it assesses monotonic relationships which can be nonlinear and is more robust to outliers, therefore is used in this section. The pairwise correlations between the variables are presented in Figure 3.5. Since a correlation matrix is always symmetric with unit diagonals, only the lower triangular part without the diagonal is plotted to minimize the information redundancy.\nIt can be observed that most pairs show positive correlations. Financial factors (i.e., the oil and gas prices) are not among any of the highly correlated pairs (e.g., above 0.80). Nevertheless, it is indicated that the NDIC and VIIRS reportings have a positive correlation, and oil production is positively correlated with flared gas volume.\nIn this analysis, due to the nature of the procedure (i.e., extract the monthly data and then measure the rank correlations), all the information on the time scale is neglected. To explore the correlations in the context of time series, the first differences (i.e., lag-1 differences) are taken for each variable\ny\u2032t = yt \u2212 yt\u22121, (3.1)\nand then pairwise Spearman\u2019s \u03c1 is evaluated and visualized in Figure 3.6. In this case, there aren\u2019t many pairs of variables which are highly correlated, except the oil and gas production are shown to be monotonically related on the lag-1 differences, which is unsurprising. In the\n24\nremainder of this dissertation, the focus is put on flaring and production related statistics instead of the financial factors.\n25"
        },
        {
            "heading": "3.5 State Level Flaring Model",
            "text": "In this section, a regression model is built for the purpose of investigating the statistical relationships between the NDIC and VIIRS reportings. Data from both sources are visualized in Figure 3.7, which demonstrate a positive correlation.\nAssuming a Gaussian observation model for the NDIC reporting with the location parameter encoding VIIRS\u2019 information, the model is specified through Expressions 3.2a\u2013\n26\n3.2e:\n\u03b1 \u223c Half-Normal(0.2) (3.2a) \u03b2 \u223c Gamma(2, 2) (3.2b) \u03c3 \u223c Half-Cauchy(0.1) (3.2c) \u00b5i = \u03b1 + \u03b2 \u00d7 VIIRSi (3.2d)\nNDICi \u223c N (\u00b5i, \u03c3) (3.2e)\nwhere \u03b1 is the intercept and \u03b2 is the slope, both of which are constrained to be non-negative based on the nature of flaring volume; \u03c3 is the standard deviation in the Gaussian likelihood function, which has to be non-negative as well; \u00b5i is the expected NDIC reporting of month i, while NDICi and VIIRSi are the observed data (i.e., reported volumes) from NDIC and VIIRS in month i, respectively. The notation used in defining this model communicates the data generating process unambiguously and is adopted throughout this dissertation. Priors and hyperpriors are on the top while the observation model is at the bottom. The prior distributions for this model and all the others in this dissertation are chosen following the principles below:\n27\n1. Prefer weakly informative priors, i.e., choose the priors based on the domain expertise\nat hand before observing any data. They should be strong enough to reflect the domain expertise and be weak enough to \u201clet the data speak\u201d, i.e., let the likelihood dominate when there is a decent amount of data. For example, a prior of a gamma distribution with mean E\u03b2 = 2/2 = 1 is placed on \u03b2, reflecting the assumption that the satellite interpretation workflow gives the same flared volume as the NDIC reporting, before one observes any data.\n2. Prefer priors with soft constraints as opposed to hard constraints, i.e., follow Cromwell\u2019s\nrule. For example, \u03b1, \u03b2 and \u03c3 all have prior distributions with support on R>0 or R\u22650. Counterexamples include using a triangular distribution or a continuous uniform distribution as the prior for such quantities, for which the author does not recommend.\n3. Prefer maximum entropy distributions, i.e., make the most conservative assumptions\nbased on all the information at hand (obeying all the known constraints). For example, the Gaussian and the binomial distributions are maximum entropy distributions and used in this dissertation, the fact of which can be formally shown leveraging the definition of Kullback\u2013Leibler (KL) divergence.\nOnce the priors and likelihood are established, four Markov chains of Hamiltonian Monte Carlo are run in parallel to sample from the posterior. The parameter estimates are reported in Table 3.1, and the posterior distributions and trace plots are presented in Figure 3.8. The four chains are plotted separately with different colors. The x-axis of the trace plot shows the number of iterations. This layout is used consistently for the remainder of this dissertation.\nUtilizing the model and the trace, posterior predictive samples are generated to construct the intervals (Figure 3.9). Point estimates and point predictions are easy to obtain for a certain machine learning model, however it is the properly constructed intervals that will provide insights into the uncertainty for decision making. The author would like to emphasize the importance of quantifying uncertainties when using machine learning, no matter for inference, prediction, or building intermediate models for integration into physics-based models. This is unfortunately neglected or ignored in some of the applications/publications in the petroleum engineering domain. The importance of properly quantifying the uncertainties will also be stressed in the following chapters.\nWhenever only one model specification is needed for making point predictions, it can be\nrecovered by the parameter estimates from Table 3.1:\nNDICi = 0.061 + 0.535\u00d7 VIIRSi , (3.3)\n29\nwhere NDICi and VIIRSi are flared volumes in bcm of month i. The model also provides clear interpretations for the NDIC reporting regression mean, on the whole state level:\n1. The intercept indicates on average there is 90 % probability that 0.04 bcm to 0.08 bcm\nreported volume per month will not be captured by the current VIIRS processing workflow. The posterior mean is 0.061 bcm (\u2248 2150 MMcf).\n2. The slope indicates on average when satellite estimated volume increases by one unit,\nunder 90 % probability the NDIC reporting will increase by 0.48 unit to 0.59 unit. The posterior mean is 0.535 unit.\nThis model, while serving as a decent calibration and estimation tool for NDIC reporting on the state level, makes the assumption that the heterogeneity within the state (e.g., among different counties) is negligible and all the monthly observations are conditionally independent\n30\nand identically distributed (i.i.d.). For the scenarios in which these assumptions do not hold, other types of models can be built and are discussed in Chapter 4 and Chapter 5.\n31\nCHAPTER 4\nCOUNTY LEVEL FLARING MODEL\n\u201cMultilevel regression deserves to be the default form of regression.\u201d\n\u2014 McElreath (2015)"
        },
        {
            "heading": "4.1 Learning the Heterogeneity",
            "text": "In this chapter, the author explores the heterogeneity in correlations between the statereported and satellite-detected flaring statistics, among different counties in North Dakota. The motivations are threefold:\n1. Provide more granular insights than merely investigating the whole state\u2019s flaring\nstatistics.\n2. Compare and contrast different counties\u2019 reporting consistencies with the baseline (i.e.,\nthe satellite detections).\n3. Develop a dedicated model for each county for calibration and prediction purposes."
        },
        {
            "heading": "4.2 Hierarchical Model",
            "text": "A common problem in learning from data is modeling individuals or units of a population.\nFor example, building models for different counties in a state, or for different well pads in an oilfield. Usually from domain expertise, it is expected that the units would demonstrate some differences, however they do not necessarily represent completely independent data generating processes. In other words, the units are different in some ways, while being similar in others. Unfortunately, the following two common modeling approaches are extreme and not ideal:\n1. Complete pooling\n32\n\u2022 This ignores heterogeneity and assumes that the observations from all the units are\ngenerated/described by the exact same process. One set of parameters is learned for the whole population. In this situation, the variance might be smaller, however the bias could be huge.\n2. No pooling\n\u2022 This lets each unit learn its own set of parameters from its own data. The\nassumption is that the information from each unit tells one nothing about any other unit. In this situation, the bias might be smaller, however the variance could be huge.\nIn practice, neither of these approaches will be able to generalize well for insight extraction or prediction tasks, due to the total generalization error being large. In fact, these two extremes can be compromised by explicitly modeling the entire population of units. That is, in order to investigate the correlations among the individual units, an explicit model is introduced for the population. In the learning phase, the individual posteriors are used to fit some population distribution, while the information of the population is then fed back to the individuals. What happens in this case is that the individuals with diffuse likelihood functions (e.g. with less data) are dragged more towards the population distribution, whereas the individuals which are well informed by their data will have their posteriors mostly unchanged. In this process, dynamic regularization is achieved, i.e., the total generalization error is much smaller by partially pooling the data and balancing between the bias and variance.\nIn the context of county level model development, the question is now how might one model the population. To motivate the choice of a particular class of models, some characteristics of the counties have to be examined. In this work, the counties are considered to be exchangeable, i.e., the joint probability p(\u03b81,\u03b82, . . . ,\u03b8n) is invariant to permutation of the indices, where \u03b8i, i = 1, 2, . . . , n is the parameters for the i-th county. That is, for any permutation \u03c0,\np(\u03b81,\u03b82, . . . ,\u03b8n) = p(\u03b8\u03c01 ,\u03b8\u03c02 , . . . ,\u03b8\u03c0n) . (4.1)\n33\nFurthermore, the list of counties can grow, i.e., although one might only look at a few counties at this point, in the future new counties in terms of flaring activities might be considered.\nIf a population being modeled is exchangeable, and the population can grow arbitrarily large, de Finetti\u2019s theorem shows that the only distribution that respects exchangeability is a hierarchical distribution:\np(\u03b81,\u03b82, . . . ,\u03b8n) = \u222b [ n\u220f i=1 p(\u03b8i | \u03c6) ] p(\u03c6) d\u03c6 , (4.2)\nwhere \u03c6 is a population parameter (which can be generalized to multiple population parameters) and p(\u03c6) is a population prior. It asserts an important fact that if exchangeable data is used for analytics, there must exist a population model (Jordan and Broderick 2010). This provides guidance for the development of the county level flaring models in this chapter.\nEquivalently, the individual and population parameters can be fitted jointly, achieving a\ndynamic pooling of the data:\np(\u03b81,\u03b82, . . . ,\u03b8n, \u03c6) = [ n\u220f i=1 p(\u03b8i | \u03c6) ] p(\u03c6) , (4.3)\nin which process not only the \u03b8\u2019s but also \u03c6 are learned. After adding the observations component (D = {(xj, yj) | j = 1, . . . ,m}) to it, the joint model becomes:\np ({ yj,xj,\u03b8county[j], \u03c8j }m j=1 , \u03c6 ) = [ m\u220f j=1 p(yj | xj,\u03b8county[j], \u03c8j) p(\u03b8county[j] | \u03c6) ] p(\u03c6) , (4.4)\nwhere \u03b8county[j] stands for the parameters for the j-th observation based on its county assignment, and \u03c8 are some other parameters in the likelihood function that are not necessarily distributed according to a population model. Equation 4.4 characterizes a hierarchical model that fits nicely into the Bayesian framework and is exploited for building the models in this chapter.\nAs a fundamental approach to model heterogeneity, hierarchical models have been depended upon routinely in various fields including ecological science (Bolker 2008), political science (Gelman and Hill 2006), and biological science (McElreath 2015). The author believes\n34\nthat they should be widely accepted and utilized in the petroleum engineering domain as well, where the dataset is usually presented in hierarchies. For example, the shale gas wells in a given basin were completed by different oilfield service companies. The information can then be pooled among the service companies. A further discussion is given in Section 7.3. One caveat, though, is that de Finetti\u2019s theorem is based on the assumption that the population (of units) is exchangeable and can grow arbitrarily large. Just like every other assumption in machine learning, it should not be taken for granted and does not always hold. In the context of county level flaring model development, one might argue that there are currently 53 counties in North Dakota and there might not be many new counties (as administrative divisions) in any finite amount of time. In that regard, the author agrees with the claim of Box et al. (2009) that, since assumptions \u201care never exactly true\u201d, what shall be sought is the useful models as opposed to the correct ones. That is the goal for applying the hierarchical models in this chapter.\nIt is worth noting that the terminologies are not consistent when referring to these types of models: some argue that hierarchical model and multilevel model are different names for the same modeling technique (Bolker 2008; McElreath 2015), while others tried to differentiate them (Carpenter 2019). In this dissertation, the model assumptions are communicated via the mathematical structures instead of the terminologies, by writing out the full model definitions whenever possible."
        },
        {
            "heading": "4.3 Data Description",
            "text": "After performing the reverse geocoding as outlined in Section 3.3, there are twelve counties found to have reported flaring activities from both VIIRS and NDIC. For each county\u2019s historical data from May 2015 to December 2018 (both inclusive), only the months that have reported volumes from both sources are extracted. A scatterplot for each of the 12 counties is presented in Figure 4.1, where the county abbreviations follow the convention from the NDIC monthly production reports. Table 4.1 lists the full county names associated with each abbreviation.\n35\nIt can be seen that the flaring magnitudes in terms of the flared volumes are quite diverse for the different counties. To better visualize all of them, a zoomed-in view for each county is shown in Figure 4.2. It becomes clear that most of the counties except SLP and GV have more than \u223c12 data points; however, only the four counties in the top row (i.e., MCK, DUN, WIL and MTL) have the largest amount of data and indicate stronger positive correlations between VIIRS and NDIC.\nFor the purpose of building county level models and investigating the heterogeneity among the counties, the no pooling option discussed in the previous section will fail. Especially with counties SLP (which has 3 observations) and GV (which has 2 observations), if a linear\n36\nmodel such as Equation 3.2d is fitted, the learned slope parameters \u03b2county will have point estimates \u03b2\u0302slp \u2248 0 and \u03b2\u0302gv 0 with their associated samples. The interpretation of the slope parameter (which was discussed right after Equation 3.3) implies that such inferences are never possible. Some other counties, even with more data points (e.g., MCL), suffer from the noise levels in their observations. Using their own dataset will frustrate accurate inferences. Therefore, in order to build models robustly at a county level, the hierarchical model discussed in the previous section is exploited."
        },
        {
            "heading": "4.4 Model Specification",
            "text": "Motivated by the discussions in Section 4.2, partial pooling is performed by explicitly modeling the entire population of counties. In this way, the counties such as MCL can leverage the information from other counties to learn their own parameters. Counties with\n\u201cstrong data\u201d (i.e., very informative data which makes the likelihood dominate the structure\nof the posterior), such as those in the top row of Figure 4.2, indicate a positive correlation between VIIRS and NDIC. Therefore, a similar strategy as in Model 3.2 is adopted for the counties, i.e., one set of slope and intercept is learned for each county.\n37\nSince the slope and intercept are very interpretable, the meanings of which were discussed right after Equation 3.3, partial pooling is also enabled across parameter types (i.e., intercepts and slopes). In other words, knowing how much flared volume is missed from VIIRS (i.e., the information carried by the intercept) might improve learning how VIIRS and NDIC will covary (i.e., the information carried by the slope). Specifically, a population model with a multivariate normal density is used for the different counties\u2019 parameters.\nThe hierarchical model is specified through Expressions 4.5a\u20134.5j:\n\u00b5\u03b1 \u223c Half-Normal(0.1) (4.5a) \u00b5\u03b2 \u223c Gamma(2, 2) (4.5b)\n38\n\u03c3\u03b1 \u223c Half-Normal(0.1) (4.5c) \u03c3\u03b2 \u223c Half-Normal(0.1) (4.5d) \u03c3 \u223c Half-Normal(0.05) (4.5e) R \u223c LKJcorr(2) (4.5f)\n\u03a3 = ( \u03c3\u03b1 0 0 \u03c3\u03b2 ) \u00b7R \u00b7 ( \u03c3\u03b1 0 0 \u03c3\u03b2 ) (4.5g)\n[ \u03b1county \u03b2county ] \u223c MVNormal [\u00b5\u03b1 \u00b5\u03b2 ] ,\u03a3  (4.5h) \u00b5j = \u03b1county[j] + \u03b2county[j] \u00d7 VIIRSj (4.5i)\nNDICj \u223c N (\u00b5j, \u03c3) (4.5j)\nwhere:\n\u00b5\u03b1 is the average intercept for all the counties; \u00b5\u03b2 is the average slope for all the counties; \u03c3\u03b1 is the standard deviation among different counties\u2019 intercepts; \u03c3\u03b2 is the standard deviation among different counties\u2019 slopes; \u03c3 is the the standard deviation in NDIC reporting within the counties; R is the correlation matrix distributed according to an LKJ distribution. It is 2-by-2\nin size and encodes the correlation between the intercepts and slopes;\n\u03a3 is the covariance matrix for the population model, which is constructed by multi-\nplying the correlation matrix from both sides by a diagonal matrix of standard deviations;\n\u03b1county and \u03b2county are the intercept and slope for each county, whose prior distributions\nare defined by a two-dimensional Gaussian population model;\ncounty[j] (in the subscript) denotes the county index, i.e., county[j] \u2208 {k \u2208 N0 |\nk \u2264 11}, such that \u03b1county[j] and \u03b2county[j] are the intercept and slope for the j-th observation based on its county assignment;\nVIIRSj is the VIIRS reported volume of the j-th observation;\n39\n\u00b5j denotes the underlying flared volume of the j-th observation; NDICj is the NDIC reported volume of the j-th observation.\nThe LKJ distribution due to Lewandowski, Kurowicka, and Joe (2009) is a distribution over positive-definite symmetric matrices with unit diagonals, i.e., correlation matrices. In the model specification above, it directly influences the prior for the covariance matrix. Before it was introduced and when HMC was not widely applicable, the usual choices for modeling covariance matrices were Wishart or inverse-Wishart distributions, due to their nice conjugacy properties. However, LKJ is better suited for modern Bayesian computational settings (Betancourt 2015; Lambert 2018) and therefore employed in this work.\nLKJ has a single parameter \u03b7, which can be interpreted as the shape parameter of a symmetric beta distribution (Gelman et al. 2013). As \u03b7 gets larger, the prior is more skeptical of large correlations in the matrix, i.e., providing regularizing effects. The probability density of LKJ with a few \u03b7 values are displayed in Figure 4.3. In this work, LKJcorr(\u03b7 = 2) is chosen to define a weakly informative and regularizing prior.\nModel 4.5, while being expressive in the data generating process, is a centered parameterization of the hierarchical structure (Papaspiliopoulos et al. 2007). In this parameterization,\n40\nthe hierarchical parameters (such as \u03b2county) and the lower-level parameters in the prior (e.g., \u00b5\u03b2 and \u03c3\u03b2) are tightly coupled, and they are highly correlated in the posterior. Since this model involves complex geometries and interactions in the posterior, HMC is leveraged for sampling. When there is not a lot of data (which is the case for the current NDIC and VIIRS reportings), this parameterization leads to very inefficient sampling and nonconvergences (Stan Development Team 2020). The noncentered parameterization is preferable in these cases and therefore employed for building the county level models."
        },
        {
            "heading": "4.5 Model Reparameterization",
            "text": "Reparameterization of hierarchical models can be applied to any distribution in the location-scale family, for which the normal distribution is a good candidate. In the case of reparameterizing a multivariate normal prior, suppose the prior for \u03b8 is a multivariate normal with mean vector \u00b5 and covariance matrix \u03a3 (such as Expression 4.5h), then a noncentered parameterization is given by:\n\u03b8\u0303 \u223c MVNormal(0n, In) (4.6a) \u03d5 = \u00b5+ L \u00b7 \u03b8\u0303 (4.6b)\nwhere \u03b8\u0303 has the same dimensions as \u03b8 and all of its elements i.i.d. according to N (0, 1), L satisfies L \u00b7 L> = \u03a3, and \u03d5 recovers the exact same prior distribution for \u03b8. This reparameterization leads to more efficient sampling by reducing the dependence between \u00b5, L, and \u03b8\u0303. One choice for L is the Cholesky factor of \u03a3, which provides implementation convenience for the multivariate normal cases (Stan Development Team 2020) and is adopted in this work.\nThe noncentered county level model is specified through Expressions 4.7a\u20134.7j, with the\nreparameterized part (corresponding to Model 4.5) highlighted in blue:\n\u00b5\u03b1 \u223c Half-Normal(0.1) (4.7a) \u00b5\u03b2 \u223c Gamma(2, 2) (4.7b)\n41\n\u03c3\u03b1 \u223c Half-Normal(0.1) (4.7c) \u03c3\u03b2 \u223c Half-Normal(0.1) (4.7d) \u03c3 \u223c Half-Normal(0.05) (4.7e)\nL \u223c LKJCholeskyCov ( \u03b7 = 2, [ \u03c3\u03b1 \u03c3\u03b2 ]\u1d40) (4.7f)[\nz\u03b1 z\u03b2\n] \u223c MVNormal [0 0 ] , ( 1 0 0 1 ) (4.7g) [ \u03b1county \u03b2county ] = [ \u00b5\u03b1 \u00b5\u03b2 ] + L \u00b7 [ z\u03b1 z\u03b2 ] (4.7h)\n\u00b5j = \u03b1county[j] + \u03b2county[j] \u00d7 VIIRSj (4.7i) NDICj \u223c N (\u00b5j, \u03c3) (4.7j)\nwhere:\nL is the Cholesky factor of the covariance matrix which has LKJ distributed correla-\ntions;\nz\u03b1 and z\u03b2 are the standardized intercept and slope for each county.\nThe rest of the symbols have the same meaning as in Model 4.5. The noncentered model imposes the exact same probabilistic structure as in Model 4.5, and is implemented for making inference on each county\u2019s parameters."
        },
        {
            "heading": "4.6 Model Fitting",
            "text": "Four chains are sampled from the posterior distributions. The posterior distributions and trace plots for the slopes and intercepts are presented in Figure 4.4 and Figure 4.5, respectively. Well mixing and convergence have been achieved as shown by the trace plots.\nTo better compare and contrast the different counties\u2019 parameters, the forest plots of 90 % highest density intervals (HDI) for the slopes and intercepts are given in Figure 4.6 and Figure 4.7, respectively. In both figures, counties are ordered by the VIIRS reported volumes, and those with the least amount of estimated volumes (such as SLP and GV) are at the bottom. The thin lines present the 90 % HDI\u2019s and the thicker line segments stand for\n42\n43\n44\nthe interquartile ranges (IQR). The points represent the posterior means.\nIn the case of the slopes (Figure 4.6), it can be seen the top four counties are quite diverse. MTL has the largest point estimate in the entire population (\u03b2\u0302mtl > 0.6) while\n45\nDUN has the smallest one (\u03b2\u0302dun < 0.5). Furthermore, the HDI\u2019s for DUN and MTL rarely overlap, indicating that it is almost certain that MTL has a larger slope than DUN. The counties with fewer observations (remaining eight counties) have greater uncertainties in their parameter estimates, while all of their point estimates are pulled towards the partially-pooled mean which is between 0.5 and 0.6. When there is not enough data for some counties, the hierarchical model strives to reinforce information sharing among different counties, thus providing more sensible results and also quantifying the uncertainties in such processes. From domain expertise, these results make more physical sense than the no-pooling estimates discussed in Section 4.3 (i.e., \u03b2\u0302slp \u2248 0 and \u03b2\u0302gv 0).\nIn the case of the intercepts (Figure 4.7), there is also heterogeneity among the counties.\nIn particular, by plotting a dotted line labeling the zero intercept, some counties are found to likely have zero intercept (e.g., zero is covered by the IQR or HDI) while others have intercepts that are significantly different from zero. It might not be surprising to get close-to-zero intercepts and greater uncertainties for those counties with less data (such as SLP and GV), however it is interesting to obtain the HDI for MTL that covers zero. Recall that the intercept parameter can be interpreted as the NDIC reported volume which is not captured by VIIRS. This finding for MTL, along with the fact that MTL has the largest slope point estimate (where a larger slope denotes closer proximity to the satellite estimation), convinces the author that MTL used to have persistent and stronger gas flares. They kept VIIRS from missing the flaring events in general, and lead to the reported volumes from NDIC and VIIRS being closer to each other. On the contrary, DUN\u2019s smaller slope and larger intercept characterize its flares as sporadic and weaker. One thing worth mentioning is that, with the current interpretation of the intercept, it does not make much physical sense to have negative intercepts. Although every county has positive point estimates for their intercepts, some counties\u2019 HDI\u2019s show coverage over the negative values. This is a limitation of choosing a 2D Gaussian population model for the intercepts and slopes. Since the 2D Gaussian is supported on R2, in the context of some counties having \u201cweak data\u201d, negative values make\n46\nan appearance in their HDI\u2019s.\nThe discussions above naturally lead to the question of whether the slopes and intercepts are correlated. It turns out that, by partially pooling the different types of parameters, a probable negative correlation between the slopes and intercepts is revealed (Figure 4.8). The correlation is learned from the heterogeneity in flare characteristics among the counties:\n\u2022 Persistent flares yield smaller intercepts and larger slopes.\n\u2022 Sporadic flares yield larger intercepts and smaller slopes.\nIn other words, intercepts and slopes covary in the entire population of counties. By pooling information across parameter types, what the model learns in the intercept can improve learning about slopes, and vice versa. With this \u201cexperience\u201d or \u201cknowledge\u201d, the hierarchical model will be able to quickly update its expectation for any new counties\u2019 parameters even with just a few observations in the beginning. It should be noted that there is also some probability mass for the positive correlation values, i.e., the negative correlation is not very strong. This could be due to that some counties do not have a lot of data at this time. The posterior will be updated as more data is brought in.\nFinally, the parameter estimates are reported in Table 4.2, from which the parametric model for each county can be recovered, and then deployed in calibration and prediction usage scenarios."
        },
        {
            "heading": "4.7 Model Extensibility",
            "text": "Looking back at the hierarchical model and the reparameterization strategy from the\nprevious sections, there are four potential deployment scenarios that are worth discussing. They demonstrate the extensibility and flexibility of the chosen approach in the context of flaring data analytics:\n1. New counties are present in terms of the reported flaring statistics from both VIIRS\nand NDIC.\n47\n1.0 0.5 0.0 0.5 1.0 Correlation\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nD en\nsi ty\nprior\nposterior\nHDI\u2019s would become narrower and narrower as more and more data are available, and since the hierarchical model pools information among the counties, these counties will contribute to updating the population model\u2019s and other counties\u2019 parameters. Similar to Item 1 above, Model 4.7 does not need modifying and can be re-fitted with the new data.\n3. Sample sizes among counties become more unbalanced.\nIn general, when there is a lot of data for each county, the centered parameterization (Model 4.5) is more efficient. When the sample size is not large, which is the case for the current VIIRS and NDIC reportings, the noncentered parameterization (Model 4.7) is better. However, the parameterization for hierarchical models is not a monolithic tactic. If the reported flaring data becomes very unbalanced across counties, e.g., some counties have a huge amount of data whereas others have very little data, then each county can be parameterized differently. More specifically,\n\u2022 For the counties that have strong data such that their likelihood functions dominate,\ncentered parameterization can be applied through Expressions 4.5f\u20134.5h.\n\u2022 For the counties that have weak data such that their prior models dominate,\nnoncentered parameterization can be applied through Expressions 4.7f\u20134.7h.\nAll in all, this is still one hierarchical model which defines the exact same probabilistic structure as Model 4.5 or Model 4.7, but avoids inefficiencies and non-convergences in the sampling from posteriors.\n4. Oilfield level heterogeneity needs to be examined.\nUnder the assumptions that the oilfields in North Dakota are exchangeable and the population of oilfields (which conduct flaring) can grow, the hierarchical model developed in this chapter can be directly applied to investigate the heterogeneity in different oilfields\u2019 parameters. Following the reverse geocoding as discussed in Section 3.3, there\n50\nare 258 oilfields that have both NDIC and VIIRS reportings for the same study period as in this chapter. Some oilfields have very few observations and can benefit from the hierarchical model through pooling information among the entire population of oilfields. Furthermore, due to the number of oilfields being relatively large, the population model could be learned with more ease (because more information is available for the population). In the case of the county level model developed in this chapter, since there are only 12 individuals (counties) in the population, some uncertainties about the population are inevitably present and reflected through the posteriors.\nThe models developed in this chapter, while capturing the heterogeneity among the different counties in North Dakota, rely on the assumption that all the monthly observations within a certain county are conditionally i.i.d. For situations where the temporal structure has to be taken into consideration, other types of models can be built and are discussed in the next chapter.\n51\nCHAPTER 5\nFLARING TIME SERIES ANALYTICS\n\u201cWere neural networks over-hyped, or have we underestimated the power of smoothing methods? I think both these propositions are true.\u201d\n\u2014 MacKay (2003)"
        },
        {
            "heading": "5.1 Learning the Flaring Pattern and Behavior",
            "text": "In this chapter, the author develops a generic framework for revealing flaring patterns\nand behaviors. The main challenges are fourfold:\n1. Observed data are noisy.\n\u2022 Companies estimate the flaring volumes and conduct self-reporting. Satellites\ncould miss some events. However, having knowledge about the underlying process is vital in lots of situations including when the state and local governments need to make key decisions based on the data. In the meantime, understanding the underlying process helps with anomaly detection by differentiating between true anomalies in reporting and ordinary noise or stochasticity.\n2. A probabilistic approach is desirable to be adopted.\n\u2022 A set of most probable functions (characterizing the underlying process) are\npreferable over one single best fit function.\n3. The observations of a certain entity are time series.\n\u2022 The temporal structure is intrinsic to the dataset and thus must be harnessed.\n4. The framework should be generic enough for automated insights extraction.\n52\n\u2022 There are more than 200 operators and 500 oilfields operating in North Dakota.\nChoosing a specific parametric form of model (e.g., ARIMA or LSTM) for each entity and then fitting the model to the data is not only time consuming, but also prevents easy integration into automation pipelines (for extracting insights for example).\nIt is striking that the elegant properties of Gaussian process make it a natural choice to\ntackle all of these challenges and is therefore employed in this chapter."
        },
        {
            "heading": "5.2 Gaussian Process",
            "text": "A Gaussian process (GP) can be viewed as a distribution over infinite-dimensional Hilbert space of functions. It is formally defined as \u201ca collection of random variables, any finite number of which have a joint Gaussian distribution\u201d (Rasmussen and Williams 2006). Gaussian processes are extremely powerful nonparametric learning techniques, which provide a composite of flexibility and interpretability. They are well suited to problems which necessitate principled handling of uncertainty and interpretation, in the presence of noisy and dynamic datasets. Such scenarios include smoothing (Deisenroth et al. 2012) and time series modeling (Roberts et al. 2013). They are also well established in different fields under various names, for example kriging in geostatistics and Kalman filters both correspond to Gaussian processes (MacKay 1998).\nIn this work, the motivation is to develop a generic framework for recognizing the underlying unknown processes f(x) which reflect flaring strategies and behaviors. Thus inference is conducted directly in the function space employing GP as a prior. A Gaussian process is completely specified by its mean function m(x) and covariance function k(x,x\u2032) (Bandyopadhyay 2018), which are defined as:\nm(x) = E[f(x)] , (5.1) k(x,x\u2032) = E[(f(x)\u2212m(x))(f(x\u2032)\u2212m(x\u2032))] , (5.2)\n53\nand the function distributed as a Gaussian process is denoted by\nf(x) \u223c GP ( m(x), k(x,x\u2032) ) . (5.3)"
        },
        {
            "heading": "5.2.1 Mean Function",
            "text": "In this work, the mean functions are always chosen to be zero, since there is no prior knowledge on the mean of the latent processes. In the meantime, for GPs with a zero mean function, the mean of the posterior process is not confined to be zero (Rasmussen and Williams 2006). All the latent functions modeled with a GP prior in this dissertation follow\nf(x) \u223c GP ( 0, k(x,x\u2032) ) , (5.4)\nwhere k is some covariance function."
        },
        {
            "heading": "5.2.2 Covariance Function",
            "text": "Covariance function, also known as kernel, is the crucial ingredient in a GP, as it encodes one\u2019s assumptions about how the function should behave by defining similarity. The fundamental assumption is that data points with inputs x which are close would have similar target values y. This assumption is usually very reasonable in areas including time series modeling, and it is theoretically backed by Tobler\u2019s first law of geography. The covariance functions used in this dissertation include:\n1. The Mate\u0301rn class of covariance functions, which is given by:\nk\u03bd(r) = 21\u2212\u03bd\n\u0393(\u03bd)\n( \u221a\n2\u03bd r\n`\n)\u03bd K\u03bd ( \u221a 2\u03bd r\n`\n) , (5.5)\nwhere \u0393(\u00b7) is the gamma function, K\u03bd is a modified Bessel function of the second kind of order \u03bd, r =\u2016x\u2212 x\u2032\u2016, and ` is the lengthscale controlling the smoothness from one perspective: large ` characterizes functions which change slowly and can be reliably extrapolated further away.\nThe Mate\u0301rn covariance functions can be written as a product of an exponential and a polynomial of order p, when \u03bd is half-integer: \u03bd = p+1/2, p \u2208 N0. The hyperparameter\n54\n\u03bd controls the smoothness from another perspective: when \u03bd = 1/2, the Mate\u0301rn kernel becomes the exponential kernel (continuous but not differentiable); as \u03bd \u2192 \u221e, it becomes the exponentiated quadratic kernel (infinitely differentiable). Rasmussen and Williams (2006) argued that the most interesting cases for machine learning would be \u03bd = 3/2 and \u03bd = 5/2.\nFor gas flaring time series, as operators might change flaring strategy at any given time due to policy changes, gas processing facility deployment, gas price fluctuation, etc., the latent process might not be as smooth as infinitely differentiable. Instead the Mate\u0301rn kernel is harnessed which is capable of inducing non-smooth function realizations to handle those discontinuities. Specifically the Mate\u0301rn kernel with \u03bd = 5/2 is chosen for this dissertation with the input space X \u2286 R1:\nkmate\u0301rn52(x, x \u2032; `) := ( 1 + \u221a 5(x\u2212 x\u2032)2\n` + 5(x\u2212 x\u2032)2 3`2\n) exp [ \u2212 \u221a\n5(x\u2212 x\u2032)2 `\n] , (5.6)\nwhere x vary over the time domain.\n2. The standard periodic kernel due to MacKay (1998):\nkperiodic(x, x \u2032;T, `) := exp ( \u2212sin 2(\u03c0|x\u2212 x\u2032| 1 T )\n2`2\n) , (5.7)\nwhere T denotes the period. This kernel is used for modeling seasonal behaviors.\n3. The white noise kernel, which is given by:\nkWhiteNoise(x, x \u2032; \u03b4) := \u03b42In, (5.8)\nwhere \u03b42 is the variance of the noise. In this dissertation, the usage of the white noise kernel is for stabilizing the computation of the covariance matrix. Adding a small value of diagonal shift will try to guarantee the resulting covariance matrix is always positive semi-definite.\n55\nA nice property is that the sum and product of the established kernels are still valid\nkernels. This fact is also exploited in the model building process in this work."
        },
        {
            "heading": "5.2.3 Inference and Model Reparameterization",
            "text": "In practice, one always works with a dataset of finite size. In such situations, a multivariate\nnormal prior distribution is placed on the vector of function values f ,\nf \u223c MVNormal(mx, Kxx) , (5.9)\nwhere the vector mx and the matrix Kxx are the mean function and covariance function evaluated over the inputs x.\nA key question which has significant impact on the inference is how to learn the hyperparameters from data. A natural (and popular) approach is to conduct maximum likelihood estimation, i.e., generating point estimates leveraging the data. However, as Betancourt (2017a) showed with experiment results, both regularized and unregularized maximum marginal likelihood have limited performance in terms of fitting robustly and recovering the true data generating process. Technically, given a particular kernel with particular hyperparameters, a GP does not support an entire Hilbert space but only a slice through that space; changing the hyperparameters by an infinitesimal amount yields a different slice which has no overlap with the original one. Therefore in this dissertation, a full Bayesian approach is taken for the GP inference, i.e., the entire Hilbert space of functions is considered by taking into account all of the possible hyperparameters for a specific kernel.\nFor the class of problems which have Gaussian observation models, GP has nice closed-form posterior results. However, for the situations which do not have Gaussian observation models, for examples the ones in this dissertation which employ Student-t or Poisson likelihood, there does not exist analytical solutions. HMC as discussed in Section 2.3 is used to sample from the posteriors.\nSpecifically, the noncentered parameterization of the latent multivariate Gaussian is\nexploited. The reparameterized model is\n56\nf\u0303 \u223c MVNormal(0n, In) (5.10a) L = Cholesky(Kxx) (5.10b)\nf = mx + L \u00b7 f\u0303 (5.10c)\nwhich defines the same distribution as Expression 5.9 but induces a nicer posterior geometry for HMC to explore and sample from (Betancourt 2017a).\nOnce the learning on hyperparameters is done, posterior predictive distribution of the\nlatent function values which are not part of the original dataset is obtained by f\u2217 | f \u223c MVNormal ( m\u2217 + K > x\u2217K \u22121 xx (f \u2212mx), K\u2217\u2217 \u2212K>x\u2217K\u22121xxKx\u2217 ) , (5.11)\nwhere m\u2217 is the mean function evaluated at the new inputs, K\u2217\u2217 is the covariance between the new inputs, and Kx\u2217 is the covariance between the original inputs and the new inputs."
        },
        {
            "heading": "5.3 Suite of Models for Pattern Recognition",
            "text": "This section presents models built from various angles, with the goal of providing a\ncoherent framework for learning the flaring pattern and behavior in a principled manner. Each model is tested on real flaring data from North Dakota. Whenever more granular analytics capabilities are demonstrated through investigations at oilfield level or operator level, the data from a major producing field, the Blue Buttes Oilfield (Alexeyev et al. 2017), and one operator, denoted by \u2018Operator A\u2019 are used."
        },
        {
            "heading": "5.3.1 Modeling Proportion of Gas Flared",
            "text": "The proportion of gas production that is flared is an indicator of flaring intensity and energy efficiency. It is interesting to investigate whether the proportion has changed over a period of time for certain operators and oilfields. The model is specified through Expressions 5.12a\u2013 5.12i:\n` \u223c Gamma(2, 1) (5.12a) \u03b7 \u223c Half-Cauchy(5) (5.12b)\n57\n\u03bd \u223c Gamma(2, 0.1) (5.12c) \u03c3\u03022 \u223c Half-Cauchy(5) (5.12d) k = \u03b72 \u00d7 kmate\u0301rn52(x, x\u2032; `) (5.12e) f \u223c GP(0, k) (5.12f) \u03c0i = logit\n\u22121(f(xi)) (5.12g) \u00b5i = \u03c0i \u00d7Gi (5.12h) Fi \u223c Student-t(\u03bd, \u00b5i, 1/\u03c3\u03022) (5.12i)\nwhere:\n` is the lengthscale for the Mate\u0301rn kernel; \u03b7 is the marginal deviation parameter controlling how strongly the latent functions\nvary in the output space;\n\u03bd is the degrees of freedom for the Student-t likelihood; \u03c3\u03022 controls the inverse scaling parameter of the Student-t likelihood (analogous to\nthe precision of a Gaussian distribution);\nk is the covariance function for the GP; f denotes the latent process, which is distributed according to the GP; \u03c0i is the underlying flaring gas proportion of month i. Since proportion is bounded\nbetween 0 and 1, the inverse-logit function is applied to the latent process;\nGi is the total gas production of month i; \u00b5i denotes the underlying flared volume of month i; Fi is the reported flared volume, which is modeled using a Student-t observation\nmodel.\nThe reasoning behind choosing a Student-t observation model is to make the model specification be able to generalize to as many entities as possible and be robust to (potentially many) outliers and noisy data points. This is due to the fact that at this time, operators have to estimate the flared volume by their own procedures and conduct reporting, in which case inaccuracies are introduced unintentionally or intentionally. The heavier tail of Student\u2019s\n58\nt-distribution is a natural decision in modeling to deal with those phenomena. This line of thought, i.e., design models that are generic and robust, is indeed reflected in choosing the half-Cauchy priors (which are heavy-tailed and very weakly informative) and GP as a nonparametric regression technique.\nTo demonstrate this model\u2019s capability on real data, both the Blue Buttes Oilfield and Operator A are tested. The production and flared volumes coming from NDIC are used. For the oilfield, the posterior distributions and trace plots of the hyperparameters are presented in Figure 5.1. The posterior predictive samples for the underlying process of gas flaring proportions (\u03c0i) are demonstrated in Figure 5.2, which depict the trend very clearly. The colored bands have the below coverage for the posterior samples:\n\u2022 The darkest colored band (in the center at a certain x location) represents the 49th\npercentile to 51st percentile;\n\u2022 The lightest colored band (characterized by the widest interval at a certain x location)\nrepresents the 1st percentile to 99th percentile.\nAdditionally, 30 random samples are drawn from the GP posterior and plotted on the same figure, showing as thin lines. The latent functions do not go through all the observed data points, in which case the model would have been overfitted; instead they present the possible functions which are most compatible with the data as well as the assumptions inherent in the model. On one hand, the insights are already obtained, i.e., the underlying process is inferred. On the other hand, this serves as an anomaly detection tool. For example, the state government might be interested to look into that observed data in the second half of 2019 which deviated quite a lot from the \u201ctrue\u201d process, e.g. to audit the reporting for that month or to investigate what had happened that led to a sudden huge drop in flaring in just one month.\nWith the exact same model specification, the model is also run with the operator\u2019s data. The posterior distributions and trace plots of the hyperparameters are presented in Figure 5.3.\n59\n60\nThe posterior predictive samples for the underlying process of gas flaring proportions (\u03c0i) are demonstrated in Figure 5.4. It can be seen this operator\u2019s flaring proportion time series is more jagged than the Blue Buttes Oilfield (which is operated by more than five companies). A operator can change flaring strategies more swiftly which can be captured as well. Nevertheless the long-term trend is also available. Comparing Figure 5.1 and Figure 5.3, it can be seen the posterior distributions are very different. However the priors for them were specified in the exact same way. This showcases the power of Bayesian approach. Taking ` as an example, a Gamma(2, 1) prior is placed on it. However, after conditioning on the data, the operator model reports smaller lengthscale values on average (indicating jagged processes), whereas the oilfield model reports larger lengthscale values (suggesting smoother processes).\n61\nOrder 24665, which is established by the North Dakota Industrial Commission, defines\nthe gas capture percentage pcap as\npcap = Gsold +Gused +Gproc\nGprod , (5.13)\nwhere:\nGsold is the monthly gas sold; Gused is the monthly gas used on lease; Gproc is the monthly gas processed; Gprod is the monthly gas produced.\nSince North Dakota bans the venting of natural gas (U.S. Department of Energy 2019b), it is obvious the model developed in this section provides a powerful tool for NDIC to evaluate compliance with the gas capture goals: at a given month i, pcap = 1\u2212 \u03c0i. Furthermore, when looking at the model specification, there is nothing special that encodes the data sources and location information. A user of this model is free to use satellite estimation as the observed data or apply it to the Permian Basin, and conduct inference on the flaring proportion. This is a benefit from using nonparametric and interpretable models as opposed to black box\n62\nmodels (such as the neural networks, in which case the learned weights and bias inside the network provide little or no domain insights). The author hopes this section provides a comprehensive view in terms of how and why to use GP, with real data. Models built and presented in later sections follow a similar flow."
        },
        {
            "heading": "5.3.2 Modeling Proportion of Wells Flaring",
            "text": "The proportion of wells that conduct flaring in a month can reflect a company\u2019s flaring strategy and is an indicator of flaring magnitude. It is interesting to investigate how this indicator varies for a certain entity in a certain time period. The model is specified through Expressions 5.14a\u20135.14f:\n` \u223c Gamma(2, 1) (5.14a) \u03b7 \u223c Half-Cauchy(5) (5.14b) k = \u03b72 \u00d7 kmate\u0301rn52(x, x\u2032; `) (5.14c) f \u223c GP(0, k) (5.14d) pi = logit\n\u22121(f(xi)) (5.14e) Wi \u223c Binomial(Ni, pi) (5.14f)\nwhere pi is the unobserved \u201ctrue\u201d proportion of wells that conduct flaring in month i, Ni is the total number of active wells in month i, and Wi is the observed (i.e., estimated and reported by company) number of wells that conduct flaring in month i. The rest of the symbols have the same meaning as in Model 5.12.\nTo demonstrate this model\u2019s capability on actual data, both the Blue Buttes Oilfield and Operator A are tested. For the oilfield, the posterior distributions and trace plots of the hyperparameters are presented in Figure 5.5. The posterior predictive samples for the underlying process of well flaring proportion (pi) are demonstrated in Figure 5.6. The visualization strategy (different colors represent different percentiles, etc.) is the same as in Section 5.3.1.\n63\nWith the exact same model specification, this model is also tested with the operator\u2019s data. The posterior distributions and trace plots of the hyperparameters are presented in Figure 5.7. The posterior predictive samples for the underlying process of well flaring proportion (pi) are demonstrated in Figure 5.8. Comparing the two sets of figures from the oilfield and the operator, it can be seen:\n64\n1. With the same prior placed on the lengthscale `, the oilfield model learns from the data\nand gives a posterior mode around 5.5, whereas the operator model gives a posterior mode around 10.0. This is also reflected in the posterior samples time series plot: the oilfield experienced some well flaring proportion changes in relative shorter time periods, whereas the operator underwent changes on a longer time span.\n2. The oilfield\u2019s posterior samples time series show narrower percentile bands while the\noperator\u2019s show wider percentile bands. This is due to the fact that the operator chosen here had smaller number of wells than the oilfield. Since the binomial observation model is used for each month\u2019s flaring well count, this naturally represents and quantifies the uncertainties (i.e., binary data contains less information especially when the sample size is small), as well as aligns with the expectation that when there is more data, there should be less uncertainties; when there is less data, there should be more uncertainties.\nThis really showcases how and why to encode domain expertise in flaring data analytics while exploiting machine learning models, which is also the reason to choose the Bayesian approach. One could fit a black box model either with target values Wi \u2208 R, or without any probabilistic view (e.g., to optimize for the best deterministic function mapping in the\n65\nhypothesis space). But either of those would be fundamentally flawed. Domain expertise indicates the well count has to be a non-positive integer, i.e., Wi \u2208 N0. Furthermore, neither the NDIC reporting nor the satellite estimation is ever produced in a noise-free environment, and therefore probabilistic modeling is a must. Compared to frequentist machine learning, Bayesian learning is entirely probabilistic and gives one the capability and freedom to encode his/her domain expertise."
        },
        {
            "heading": "5.3.3 Modeling Flare Detection Count",
            "text": "Satellite detected flare count provides an unbiased indicator of flaring intensity. How this\nindicator varies in a certain time period for a certain entity is valuable information to obtain. The model is specified through Expressions 5.15a\u20135.15f. Essentially the latent process is modeled as a Gaussian Cox process (Adams et al. 2009), where the Poisson process has varying intensity across time domain and a GP prior is placed on this intensity.\n` \u223c Gamma(2, 1) (5.15a) \u03b7 \u223c Half-Cauchy(5) (5.15b) k = \u03b72 \u00d7 kmate\u0301rn52(x, x\u2032; `) (5.15c)\n66\nf \u223c GP(0, k) (5.15d) \u03bbi = exp ( f(xi) ) (5.15e) Ci \u223c Poisson(\u03bbi) (5.15f)\nwhere \u03bbi is the unobserved flaring intensity (\u201ctrue\u201d count) in month i and Ci is the reported VIIRS detection count in month i. Since \u03bbi is bounded to be positive, the natural exponential function is applied to the latent process. The rest of the symbols have the same meaning as in Model 5.12.\nFor the task of flaring pattern recognition, the author believes this approach (leveraging a Gaussian Cox process) is a nicer surrogate than a popular change point model presented in (Davidson-Pilon 2015; Salvatier et al. 2016; Stan Development Team 2020), which is specified by:\ne \u223c Exponential(re) (5.16a) l \u223c Exponential(rl) (5.16b) s \u223c Uniform(1, T ) (5.16c) Ci \u223c Poisson(i < s ? e : l) (5.16d)\nwhere e and l are the early and late rates respectively, re and rl controls the priors for the early and late rates, s is the change point, T is the total time period, and the rate in the Poisson likelihood is decided through a ternary conditional operator (?:). The reason is that, although this model could be generalized to more than one change point, its usage is restricted by the assumption that any period between two adjacent change points has a constant rate. This limitation becomes obvious when analyzing the actual flaring data in the discussions below, and is a major disadvantage of the change point model.\nThe Gaussian Cox process model is tested with the Blue Buttes Oilfield\u2019s data. Since only VIIRS data is used, the whole time series is analyzed beginning in 2012. The posterior distributions and trace plots of the hyperparameters are presented in Figure 5.9. The posterior predictive samples for the underlying process of flare count (Ci) are demonstrated\n67\nin Figure 5.10. The visualization strategy (different colors represent different percentiles, etc.) is the same as in Section 5.3.1. From the time series plot, it can be seen the observations from 2014 to 2017 can possibly be described by a change point model (with late 2015 being a potential change point), but the steady growth before and after that time span will frustrate accurate inference with such a model.\n68\nThis model\u2019s inference results serve as a type of confirmation, if not evidence, in terms of whether or not an entity achieves the goal/target in reducing the number of wells flaring, when the detection count is used as a surrogate for the number of wells flaring. In practice, reducing the number of wells flaring is exactly the second goal of the regulatory policy introduced by the North Dakota Industrial Commission in 2014. If the state government is interested in this order\u2019s effectiveness from a macroscopic standpoint, the model can also be used to conduct inferences with the state level data. In this case, the posterior distributions and trace plots of the hyperparameters are presented in Figure 5.11. The posterior predictive samples for the underlying process of flare count (Ci) are demonstrated in Figure 5.12.\nThe percentile bands in this case are quite narrow, which indicate greater confidence in the inferences about the data generating process given the model assumptions. By not (over)fitting to each and every observation, interesting patterns are discovered, for example in every year there is one and only one peak that happened around June. It is worth pointing out that there is no model that can tell the modeler if his/her assumptions are good, only domain expertise might. This model employing a Poisson observation model could be considered \u201crigid\u201d due to the fact that a Poisson likelihood has only one parameter \u03bb (to\n69\ncontrol both the mean and variance) and, furthermore, when \u03bb is large as in this scenario, a Poisson distribution is well approximated by a normal distribution. Whenever the state government believes that overdispersion might exist, other observation models such as the negative binomial distribution could be considered. In such cases, only Expression 5.15f needs to be changed to the negative binomial likelihood, with a prior added for the overdispersion parameter. The specific parameterization is given by Equation 6.4 in Section 6.3. This really showcases both the flexibility and interpretability of taking a Bayesian approach for high-stakes decision making areas including flaring data analytics."
        },
        {
            "heading": "5.3.4 Modeling Proportion of Oil Flared",
            "text": "As crude oil (as opposed to natural gas) is the main commodity at this time, the amount of gas in a barrel of oil equivalent (BOE) that is flared provides an indicator of production efficiency due to flaring. In this work, the normalized quantity, proportion of oil production being flared, is used such that the model specification is generic for large and small entities. The model is specified through Expressions 5.17a\u20135.17j:\n` \u223c Gamma(2, 1) (5.17a)\n70\n\u03b7 \u223c Half-Cauchy(5) (5.17b) \u03bd \u223c Gamma(2, 0.1) (5.17c) \u03c3\u03022 \u223c Half-Cauchy(5) (5.17d) k = \u03b72 \u00d7 kmate\u0301rn52(x, x\u2032; `) (5.17e) f \u223c GP(0, k) (5.17f) \u03c0i = logit\n\u22121(f(xi)) (5.17g) \u00b5i = \u03c0i \u00d7Oi (5.17h)\nc = 6 Mcf\n1 BOE (5.17i)\nFi/c =: Ei \u223c Student-t(\u03bd, \u00b5i, 1/\u03c3\u03022) (5.17j)\nwhere:\n\u03c0i is the underlying flaring BOE proportion of month i; Oi is the total oil production of month i; \u00b5i denotes the \u201ctrue\u201d flared BOE of month i; c denotes the conversion factor that 6 Mcf equals 1 BOE, given by the United States\nGeological Survey (2000);\nEi is the reported flared BOE, which is modeled using a Student-t observation model.\nThe rest of the symbols have the same meaning as in Model 5.12. To test this model\u2019s performance on real data, both the Blue Buttes Oilfield and Operator A are used. For the oilfield, the posterior distributions and trace plots of the hyperparameters are presented in Figure 5.13. The posterior predictive samples for the underlying process of BOE flaring proportion (\u03c0i) are demonstrated in Figure 5.14. The visualization strategy (different colors represent different percentiles, etc.) is the same as in Section 5.3.1.\nWith the exact same model specification, this model is also tested with the operator\u2019s data. The posterior distributions and trace plots of the hyperparameters are presented in Figure 5.15. The posterior predictive samples for the underlying process of BOE flaring proportion (\u03c0i) are demonstrated in Figure 5.16.\nComparing the two sets of figures from the oilfield and the operator, it can be observed:\n71\n72\n1. With the same prior placed on the lengthscale `, which has a mean of 2 (months), both\nmodels have updated the posterior to move away from this mean, reflecting a long range variation. The oilfield has a posterior mode about 1 year while the operator has a mode around 15 months. The operator has much larger reporting variability, shown by the parameter \u03c3\u03022.\n2. With a Student-t likelihood, both models demonstrate robustness to outliers and\noverfitting. This can be seen from the oilfield\u2019s late 2019 observations and the operator\u2019s early 2016 observations. For the posterior function samples, shown as the thin lines, some of them are indeed pulled towards those \u201coutliers\u201d. However, the percentile plots\n73\n(shown as the colored bands) are not impacted and those really can be interpreted as the trend which is most compatible with the data and the assumptions. This built-in Occam\u2019s razor of the Bayesian approach when choosing appropriate priors is very impressive. In many of the frequentist machine learning methods, if the regularization strategy is not implemented well especially when the sample size is not huge enough for the asymptotic properties to kick in, outliers become \u201cinfluential observations\u201d that will have a huge undesirable effect on the inference results."
        },
        {
            "heading": "5.3.5 Modeling Scale Factor between VIIRS and NDIC",
            "text": "Both NDIC and VIIRS reporting give (estimated) flared gas volume. The scale factor\nbetween the two sources provides insights into whether NDIC reporting is consistent:\n1. for different entities (e.g., among a group of operators), and\n2. for one entity when looking at a certain time period.\nThis is based on the fact that the satellite detection processing algorithm is unbiased and consistent. Item 2 is particularly interesting in terms of time series analytics. The model is specified through Expressions 5.18a\u20135.18n:\n74\n`mat \u223c Gamma(8, 2) (5.18a) \u03b7mat \u223c Half-Cauchy(5) (5.18b) T \u223c N (12, 1) (5.18c) `per \u223c Gamma(4, 3) (5.18d) \u03b7per \u223c Half-Cauchy(5) (5.18e) \u03bd \u223c Gamma(2, 0.1) (5.18f) \u03c3\u03022 \u223c Half-Cauchy(5) (5.18g) kmat = \u03b7 2 mat \u00d7 kmate\u0301rn52(x, x\u2032; `mat) (5.18h) kper = \u03b7 2 per \u00d7 kperiodic(x, x\u2032;T, `per) (5.18i)\nkwn = kWhiteNoise(x, x \u2032; \u03b4 = 1e\u22126) (5.18j)\nf \u223c GP(0, kmat + kper + kwn) (5.18k) \u03b2i = exp ( f(xi) ) (5.18l)\n\u00b5i = \u03b2i \u00d7 VIIRSi (5.18m) NDICi \u223c Student-t(\u03bd, \u00b5i, 1/\u03c3\u03022) (5.18n)\nwhere:\n`mat is the lengthscale for the Mate\u0301rn kernel; \u03b7mat is the marginal deviation for the Mate\u0301rn kernel; T is the period for the periodic kernel; `per is the lengthscale for the periodic kernel; \u03b7per is the marginal deviation for the periodic kernel; kmat is the Mate\u0301rn kernel (component); kper is the periodic kernel (component); kwn is the white noise kernel (component); f denotes the latent process, which is distributed according to a GP whose covariance\nfunction is the sum of 3 kernels;\n\u03b2i is the underlying scale factor between VIIRS and NDIC of month i. Since this scale\nfactor is bounded to be positive, the natural exponential function is applied to\n75\nthe latent process;\nVIIRSi is the VIIRS reported volume of month i; \u00b5i denotes the underlying flared volume of month i; NDICi is the NDIC reported volume of month i, which is modeled using a Student-t\nobservation model.\nThe rest of the symbols have the same meaning as in Model 5.12. The reason for adding a periodic kernel is to investigate if there are any seasonal patterns. Maintaining a proper Bayesian workflow lets the data speak for itself, i.e., whether there exists seasonal behaviors or not, as shown by the two case studies in this section.\nThe model is first fitted with the state level data to investigate the macroscopic reporting consistency. The posterior distributions and trace plots of the hyperparameters are presented in Figure 5.17. The posterior predictive samples for the underlying process of the scale factor variations (\u03b2i) are demonstrated in Figure 5.18. The visualization strategy (different colors represent different percentiles, etc.) is the same as in Section 5.3.1. From the posterior time series plot, it can be seen in general the volumes from NDIC reporting is smaller than that of VIIRS reporting, except for the times when the total flaring magnitude was small (indicated by the smaller points). More importantly, within each and every year from 2015 to 2018, there is a decreasing trend in the values of the scale factor (\u03b2i) around midyear. Each year\u2019s latent process from Q2 to Q3 can be viewed as a \u201cseesaw\u201d, with July being the middle pivot point and the months after July always going down. Note that within each year, the NDIC reporting of flared volumes might increase steadily or a lot (which was actually happening from the time series plot in Figure 3.7), however this scale factor declining trends indicate the satellites observed much greater flaring activities than what was reported by the companies! This finding suggests that the NDIC reporting is very likely not consistent throughout the year, and the state government should be concerned that some companies might underreport their flared volumes especially in the second half of the year.\n76\n77\nA interesting question arises: is this seasonal behavior universal across all the entities? The answer is unfortunately no, which indicates some operators likely reported their flared volume in an inconsistent manner throughout the entire year. In fact, if the Blue Buttes Oilfield data is used to fit the model, rather consistent behavior is observed. In this case, the posterior distributions and trace plots of the hyperparameters are presented in Figure 5.19. The posterior predictive samples for the underlying process of the scale factor variations (\u03b2i) are demonstrated in Figure 5.20. With the exact same model specification incorporating the periodic kernel, no apparent seasonal behaviors are discerned by the inference process. There are much uncertainties around the time of early 2016, where the point sizes indicate the overall flaring magnitudes were small as observed from VIIRS, and the NDIC reported volumes were actually larger than that of VIIRS. This could be due to the truncation effects instead of the reporting inconsistencies, i.e., when the flares are sporadic and weaker, they are not easily captured by the satellites, resulting in a truncated sample for the VIIRS processing workflow. By applying this model and workflow to the other major producing fields, it will likely pick up the ones who have the \u201cseesaw\u201d behaviors in their reporting.\n78\n79"
        },
        {
            "heading": "5.3.6 Predicting NDIC Flared Volume",
            "text": "GP is not only fully capable of making predictions once the model hyperparameters are learned, but it can provide rigorously constructed intervals quantifying uncertainties as well through Expression 5.11, for which many of the frequentist machine learning methods fail to do. The author chooses to present one particular prediction case study, that is to predict NDIC reported volume based on the projected scale factor between VIIRS and NDIC. This will be a particular interesting deployment scenario once fast satellite detection/estimation is available, which takes less time than waiting on company reports followed by compiling everything into an analytics-ready format.\nThe predictions are generated in the form of posterior predictive samples. Along with the historical observations, the predictions of the scale factor for the next six months are presented in Figure 5.21. The very wide percentile bands in the forecasting indicate that the seasonal behaviors will likely take effect again, however with great uncertainties. If point predictions (i.e., without the prediction intervals) are needed, one can always use the posterior mean, mode, etc. to construct that \u201cbest\u201d function; however this showcases why predicting\n80\nthe future is generally very difficult and uncertainties should always be properly characterized."
        },
        {
            "heading": "5.3.7 A Look Back at the Prior Choices",
            "text": "Looking back at the suite of models developed, the set of priors for the latent functions have been the same (except the scale factor model where a periodic kernel is added). However the posteriors are all updated (i.e., \u201clearned\u201d) based on each dataset and modeling goal. This means the below set of priors\n` \u223c Gamma(2, 1) (5.19a) \u03b7 \u223c Half-Cauchy(5) (5.19b) k = \u03b72 \u00d7 kmate\u0301rn52(x, x\u2032; `) (5.19c) f \u223c GP(0, k) (5.19d)\nserves as a generic framework and can be recommended for flaring time series analytics in general, in a GP context. Notice this prior choice gives latent function values in the unconstrained space, i.e., f(x) \u2208 R. However, in many situations, the domain expertise\n81\nindicates the quantities of interest live in constrained space, such as:\n\u2022 R>0 for Poisson rate parameter when modeling count data, and\n\u2022 [0, 1] for binomial success probability when modeling flaring well proportion.\nTo better reflect the domain expertise, the link functions can be leveraged. For the above scenarios, the log link function and the logit link function can be applied, respectively. Although this prior configuration is the result of several design iterations and tested with real data, there is no reason to think that it is optimal for every entity. Indeed, the model for scale factor between VIIRS and NDIC has bespoke components in its priors. The Stan Development Team (2020) also gave some general prior choice recommendations for GP.\nThe whole suite of models demonstrate full capability of harnessing the temporal structure in flaring time series at different levels for different entities. This provides huge potential for extracting insights from noisy monthly data streams. For the situations where cross-sectional data analytics is desirable, for example when the latest monthly data is available and the state government needs insights from merely that month (before appending it to the whole historical data for a longitudinal study), other types of models can be built. Such is discussed in the next chapter.\n82\nCHAPTER 6\nUNSUPERVISED LEARNING FROM MULTIPLE PERSPECTIVES\n\u201cEstimation of densities is a universal problem of statistics (knowing the densities one can solve various problems).\u201d\n\u2014 Vapnik (2000)"
        },
        {
            "heading": "6.1 Learning the Distribution",
            "text": "In this chapter, the author studies how to describe the flaring related quantities\u2019 distribution among the oilfields in North Dakota in a cross-sectional setting. That is, data collected for one point or a period of time (such as a certain month or quarter) is analyzed. In this setting, the data used for learning is unlabeled:\nU = {x1, x2, . . . , xN} , (6.1)\nwhere xi, i = 1, 2, . . . , N , are the observations for the i-th oilfield. Thus unsupervised learning is naturally applied. The model to be learned is in the form of a conditional probability distribution P\u03b8(x | z) where z is some latent structure and \u03b8 represents the parameters.\nThis has many application scenarios in practice. When the latest month\u2019s or quarter\u2019s data is available, the government of North Dakota might need distributional insights of the population (of oilfields), preferably beyond some forms of the order statistics (such as the five-number summary). This cross-sectional study is especially valuable and worth conducting when a direct comparison with previous months/quarters (which can be either the immediately previous one, or the same month/quarter in previous years) is desirable, or deeper understanding of the population is needed, such as looking for potential clusters among the entities.\n83"
        },
        {
            "heading": "6.2 Probability Model Estimation",
            "text": "The task of learning distributions is a probability model estimation problem in unsupervised settings (Li 2019). It sometimes takes the form of density estimation, which is considered by some statisticians as the most fundamental topic in probabilistic machine learning (Yu 2017). A basic and common technique, the histogram, can be easily misused which leads to biased understanding of the dataset (Figure 6.1).\nIn general, assuming that the data is generated by a probability model, the structure and parameters of that model are learned from the data. The type of the structure, i.e., the set of possible probability models is usually given (assumed), while the specifics of the structure and the parameters have to be learned. The goal is to find the model structure and the parameters which are most likely to have generated the data.\nThe probability model can be a mixture model or a graphical model. In this dissertation, the mixture model is considered, where the assumption is that data comes from a mixture of distributions. Mathematically, mixture models describe a distribution p(x) by a convex combination of K base distributions:\n84\np(x) = K\u2211 k=1 \u03c0kpk(x) (6.2a)\nK\u2211 k=1 \u03c0k = 1, \u03c0k \u2265 0, (6.2b)\nwhere pk are the components in the mixture and \u03c0k are the mixture weights. Mixture models can be interpreted as the overall population being a combination of distinct subpopulations. Mixture models can be generalized to the continuous cases as well. For example, both the negative binomial distribution and Student\u2019s t-distribution can be thought of a mixture of some continuous distributions (Martin 2018).\nIn the model representation P\u03b8(x | z), x stands for the observations which can be discrete\nor continuous quantities; z represents the latent structure which is a discrete random variable. The model is parameterized by \u03b8. When the model is assumed to be a mixture type, z represents the different components. The knowledge of the model structure and parameters are learned from the data U = {x1, x2, . . . , xN}, where in this work xi \u2208 X \u2286 R1, i = 1, 2, . . . , N , is the observation for the i-th oilfield."
        },
        {
            "heading": "6.3 Modeling VIIRS Detection Count",
            "text": "In Section 5.3.3, methods are developed for analyzing the time series of VIIRS detection count for any given oilfield. This section tackles the problem of how to extract insights from any given month\u2019s flare detection count in North Dakota\u2019s oilfields. Specifically, by learning from each oilfield\u2019s detection count, the population of the oilfields is summarized, through which the state government can gain distributional insights.\nFollowing the general form in Section 6.2, this problem becomes a special case that the latent structure z does not exist, i.e., satisfying P\u03b8(x | z) = P\u03b8(x), where x represents the detection count. It is when estimating conditional probability distributions becomes estimating probability distributions, therefore, only estimating the parameters of P\u03b8(x) is enough. Density estimation in classical statistics, for instance the Gaussian parameters\n85\nestimation, is an example of such scenarios.\nSince the count data is modeled, the author compares the four observation models below\nwith many randomly chosen months\u2019 data:\n1. Poisson likelihood\n2. Negative binomial likelihood\n3. Zero-inflated Poisson (ZIP) likelihood\n4. Zero-inflated negative binomial (ZINB) likelihood\nItems 3 and 4 above are experimented with because many of the oilfields in North Dakota did not have detection records from VIIRS for a given month. Therefore, zero-inflated models are tried as well. Through the posterior predictive checks, it is found that the negative binomial observation model fits data in the most compatible manner, which is employed in this work.\nThe model is specified through Expressions 6.3a\u20136.3c:\n\u00b5 \u223c Gamma(2, 1) (6.3a) \u03c6 \u223c Exponential(1) (6.3b) Ci \u223c NegBinomial(\u00b5, \u03c6) (6.3c)\nwhere Ci denotes the detection count for the i-th oilfield. The probability mass function of the negative binomial likelihood is parameterized by a location parameter \u00b5 \u2208 R>0, and an overdispersion parameter \u03c6 \u2208 R>0, in the following way:\nP (X = n | \u00b5, \u03c6) = \u0393(\u03c6+ n) n! \u0393(\u03c6)\n( \u00b5\n\u00b5+ \u03c6\n)n( \u03c6\n\u00b5+ \u03c6\n)\u03c6 for n \u2208 N0 , (6.4)\nwhere \u0393(\u00b7) is the gamma function. Through this parameterization, the expectation and variance of a random variable X \u223c P are:\nE[X] = \u00b5 and V[X] = \u00b5+ \u00b52\n\u03c6 . (6.5)\n86\nAs the negative binomial distribution describes a Poisson random variable whose rate parameter is gamma distributed, and due to the fact that Poisson(\u00b5) has variance \u00b5, the learned parameters provide nice interpretations for the state government:\n\u2022 \u00b5 indicates a mean intensity from the detection count\u2019s perspective, just like the\ninterpretation of a Poisson\u2019s rate parameter. The larger the value of \u00b5, the more flare detections are present on average at an oilfield level.\n\u2022 \u03c6 indicates the heterogeneity among the oilfields in North Dakota. Specifically, \u00b52/\u03c6 is\nthe additional variance above that of a Poisson with rate \u00b5. The smaller the value of \u03c6, the more oilfields with extreme detection counts (away from \u00b5) are present.\nTo demonstrate this model\u2019s compatibility with the observations, the data from October 2018 is used. There are 506 oilfields in total. The distribution of the detection count for all the oilfields is illustrated in Figure 6.2.\n87\nAfter fitting Model 6.3, the posterior distributions and trace plots of the hyperparameters\nare presented in Figure 6.3. The parameter estimation results are reported in Table 6.1.\nParameter Variable Point Estimate 90 % CI\n\u00b5 Intensity 1.005 (0.814, 1.200) \u03c6 Heterogeneity 0.168 (0.135, 0.202)\nThe point estimate for the intensity parameter \u00b5 is relatively small (\u00b5\u0302 \u2248 1), which possibly results from the model being overwhelmed by the large number of zero counts. However, by inspecting the histogram from Figure 6.2, the tail of the distribution definitely extends far beyond \u00b5\u0302. Therefore, posterior predictive checks are performed to scrutinize Model 6.3\u2019s compatibility with the observations.\nThese types of checks substantially harness the information from the samples drawn from the posterior distributions. By combining the uncertainty about the parameters, as described by the posterior, with the uncertainty about the outcomes, as described by the likelihood, the generative model is employed to simulate the implied observations. Subsequently, posterior predictive plots are generated to display the model-based predictions along with the raw data. Such a plot for the detection count distribution model is given in Figure 6.4.\n88\nIn Figure 6.4, the histograms for the original VIIRS observations, as well as all of the posterior predictive simulations are displayed. Each set of the parameter values (of \u00b5 and \u03c6) are used in simulating one synthetic snapshot of the oilfields in North Dakota for October 2018, and there are in total 12,000 snapshots (constructed by the samples from the four Markov chains, each of which was setup for 3000 sampling iterations). Every histogram is visualized through an unfilled line chart, i.e., rendering the \u201cstep\u201d histogram.\nThrough Figure 6.4, it appears that the model is very compatible with the observations from October 2018, in that there is no obvious and consistent discrepancy between the observed and simulated data. To delve into the tail behaviors, i.e., beyond the zero count, a zoomed-in view is depicted in Figure 6.5. A few discrepancies are observed from this view, for example, when the count Ci = 11 and Ci = 12. One thing to note is that, with such a low mean (\u00b5\u0302 \u2248 1), even with a relatively large overdispersion (\u03c6\u0302 \u2248 0.2), the model would still be surprised by the high detection count, e.g., when Ci \u2265 20.\n89\nThe thorough performance of Model 6.3 that is characterized by a negative binomial likelihood, and the complicatedness of the real data manifest themselves through the posterior predictive checks. As discussed earlier in Section 6.3, the negative binomial likelihood was compared with three other likelihoods (Poisson, ZIP and ZINB) on many randomly chosen months, and found to outperform them in terms of the compatibility with the data in general. In fact, there are some months\u2019 data that are distributed in a \u201ccleaner\u201d way, i.e., almost perfectly described by Model 6.3. The author chooses not to cherry-pick those data, in the hope of not misleading the readers about the performance of the developed model.\nNevertheless, the simplicity, interpretability, and effectiveness of Model 6.3 proves itself in the mission of modeling detection count distribution. In practice, the state government can benefit from this model in the two use cases below:\n1. When the latest month\u2019s data becomes available, Model 6.3 can be fitted to obtain an\nestimate for \u00b5 and \u03c6. These parameter estimates along with the credible intervals can be compared with those from the earlier times. In the case of the discussions above, the\n90\nlearned parameters can be compared either with August/September from 2018, or with October from 2016/2017. From the comparison, it provides insights into whether there are more detection counts on average (characterized by a larger \u00b5), or if more oilfields with an atypical number of detections are spotted (characterized by a smaller \u03c6).\n2. After the model is fitted, it is recommended to perform the posterior predictive checks\nas demonstrated in Figure 6.4 and Figure 6.5, to identify any issues of the fits. The list of the oilfields which have large deviations from the simulated data, especially those on the far tail (e.g., when Ci \u2265 20), are worth tracking. That is, to investigate whether the \u201canomalies\u201d from each month are random samples from the population or do not change from month to month. This provides further understanding of how the oilfields population behave, from the perspective of the detection count.\nA distributional summary of the detection counts exhibits only one facet of the flaring landscape, while the flared volumes distribution provides another crucial one, which is discussed next."
        },
        {
            "heading": "6.4 Modeling Flared Volume",
            "text": "In this section, the VIIRS estimated flared volumes for different oilfields are studied from a distributional point of view. The dataset from a three-month period is analyzed for demonstration purposes. Specifically, following the reverse geocoding as discussed in Section 3.3, all the oilfields\u2019 cumulative flared volumes during Q4 2018 are computed and compiled for analysis.\nThere are in total 152 oilfields that have VIIRS reported volumes in this time span. The data is highly skewed (Figure 6.6). Therefore, for each oilfield, the order of magnitude of the flared volume (in bcm) is computed for the analysis, instead of working with the original absolute volumes.\nFrom an applied perspective, taking the log of a measure converts the measure into\nmagnitudes (McElreath 2015), which is applied to each oilfield\u2019s flared volume:\n91\nLi = log(Fi), (6.6)\nwhere Fi is the original flared volume in bcm, and Li is the flared volume magnitude, both of which are for the i-th oilfield. In this dissertation, base e is always used for the logarithm (i.e., natural logarithm). A univariate distribution of the magnitudes is visualized in Figure 6.7.\nAmong the three approaches used to visualize the distribution, only the rug plot does not lead to subtleties due to the hyperparameters used. However, as a 1D scatter plot, its representation ability is naturally limited. The histogram suffers from the problem as illustrated in Figure 6.1. The curve is generated by kernel density estimation (KDE). For a given dataset as defined in Equation 6.1, KDE represents the underlying distribution as:\np\u0302(x) = 1\nNh N\u2211 i=1 K (x\u2212 xi h ) , (6.7)\nwhere K(\u00b7) is a kernel function and h is a bandwidth parameter. To generate Figure 6.7, the Gaussian kernel is used, which is given by:\n92\nK(z) = 1\u221a 2\u03c0 exp\n( \u2212z 2\n2\n) , (6.8)\nand h is chosen based on Scott\u2019s rule.\nSince the bandwidth plays a similar role as the bin size in histograms, KDE can also lead to the same issue as in histograms. Nevertheless, all three (the rug plot, histogram and KDE) agree that a single Gaussian approximation of the density which generates this data would be a poor approximation. Therefore, Gaussian mixture model (GMM) is employed to represent the data, i.e. the base distributions in Model 6.2 are chosen to be Gaussians. GMM provides more expressive modeling capabilities and also possibilities for clustering."
        },
        {
            "heading": "6.4.1 Model Specification",
            "text": "As discussed earlier, since the flared volume is a continuous quantity, density estimation is applicable and tackled with GMM. At first, the data generating process is considered, which paves the way for potential clustering applications. That is, each data point Li (defined in\n93\nEquation 6.6) is assumed to be generated by exactly one mixture component. The number of components, K, is unknown, and up to seven components are tried to fit the dataset visualized in Figure 6.7. A relatively small number of components are experimented, because as the number of components increases, it becomes more difficult to interpret the modeling results. The model is specified through Expressions 6.9a\u20136.9i, \u2200K \u2208 {2, . . . , 7}:\n\u03b1 = (\u03b11, . . . , \u03b1K) = 6 \u00b7 1K (6.9a) p \u223c Dirichlet(\u03b1) (6.9b) zi \u223c Categorical(p) (6.9c) l1 = min{L1, . . . , Ln} (6.9d) l2 = max{L1, . . . , Ln} (6.9e)\n\u00b5\u0303k = l1 + (k \u2212 1) ( l2 \u2212 l1 K \u2212 1 ) , k = 1, . . . , K (6.9f) \u00b5k \u223c N (\u00b5\u0303k, 2), k = 1, . . . , K (6.9g) \u03c3k \u223c Half-Normal(2), k = 1, . . . , K (6.9h)\nLi | (zi = j) \u223c N (\u00b5j, \u03c3j) j \u2208 {1, . . . , K} (6.9i)\nwhere:\n\u03b1 is the vector of concentration parameters for the Dirichlet distribution, which is a\nmultivariate generalization of the beta distribution;\np is the simplex of probabilities for the mixture components, which is assigned\na Dirichlet prior. This prior with each value inside \u03b1 being 6, is a weakly informative prior, expecting any pk inside p could be bigger or smaller than the others. Ten random draws from Dirichlet([6, 6, 6, 6, 6, 6, 6]) are displayed in Figure 6.8;\nzi is the probable mixture component that the i-th oilfield belongs to; l1 and l2 are the lower and upper bound for {Li}ni=1, respectively; \u00b5\u0303k is used in \u201cinitializing\u201d the location of the k-th mixture component, and {\u00b5\u0303k}Kk=1 essentially represent the K evenly spaced points between [l1, l2];\n94\n\u00b5k is the mean for the k-th Gaussian component; \u03c3k is the standard deviation for the k-th Gaussian component; Li is the flared volume magnitude of the i-th oilfield, which is generated by the\nmixture component zi.\nModel 6.9, while unambiguously expressing the assumed generative process, relies on sampling the discrete latent variables zn, which is controlled by a categorical mixing distribution. This reliance causes slow mixing and ineffective exploration of the posterior distribution. An equivalent parameterization which addresses these problems is to marginalize out the z parameter. The marginalized model is specified through Expressions 6.10a\u20136.10h, \u2200K \u2208 {2, . . . , 7}:\n\u03b1 = (\u03b11, . . . , \u03b1K) = 6 \u00b7 1K (6.10a) w \u223c Dirichlet(\u03b1) (6.10b) l1 = min{L1, . . . , Ln} (6.10c) l2 = max{L1, . . . , Ln} (6.10d)\n\u00b5\u0303k = l1 + (k \u2212 1) ( l2 \u2212 l1 K \u2212 1 ) , k = 1, . . . , K (6.10e)\n95\n\u00b5k \u223c N (\u00b5\u0303k, 2), k = 1, . . . , K (6.10f) \u03c3k \u223c Half-Normal(2), k = 1, . . . , K (6.10g) Li \u223c K\u2211 j=1 wj N (\u00b5j, \u03c3j) (6.10h)\nwhere w are the mixture weights (i.e., mixing proportions), and the rest of the symbols have the same meaning as in Model 6.9. The likelihood function, defined in Expression 6.10h, corresponds with the density of a mixture model expressed in its general form (Equation 6.2a).\nModel 6.10 is implemented and fitted six times (\u2200K \u2208 {2, . . . , 7}) to compare the inference results with different number of components specified. For each K, rapid mixing and fast convergence of the Markov chains are obtained. The modeling results are displayed in Figure 6.9, where the KDE (same as in Figure 6.7) and the Gaussian components inferred are plotted along with the posterior samples.\nIt can be observed that, when using a mixture of Gaussians, the multimodal features can be represented in a relative effortlessly way, and all the mean fits are quite close to the one obtained with KDE. As the number of components increases, for example when K = 6 or K = 7, the mean density estimation using GMM resembles KDE more closely, but the samples from the posterior show more stochasticity, which is an indicator of potential overfitting. This naturally leads to the question of how to decide the number of components for this dataset."
        },
        {
            "heading": "6.4.2 Model Comparison",
            "text": "Choosing the best K is a model comparison problem, for which there does not exist a silver bullet. In this dissertation, the author chooses to take the information criteria approach, specifically leveraging the widely applicable information criterion (WAIC) introduced by Watanabe (2010). Information criteria provide a theoretical estimate of the relative out-ofsample KL divergence (McElreath 2020), and thus a lower value is better. Following Martin (2018) and McElreath (2020), WAIC is computed by:\n96\nWAIC(y,\u0398) = \u22122\u00d7 lppd(y,\u0398) + 2pwaic (6.11a)\n= \u22122 n\u2211 i=1 log\n( 1\nS S\u2211 j=1\np(yi | \u0398j) )\n+ 2 n\u2211 i=1 V\u0398[log p(yi | \u0398j)] , (6.11b)\nwhere:\ny denotes the observations and yi is the i-th observation; \u0398 is the posterior distribution and \u0398j is the j-th set of sampled parameter values;\n97\nS is the number of posterior samples; lppd(\u00b7) calculates the log pointwise predictive density; pwaic is the penalty term given by summing up the variance in the log-likelihood over\nthe S posterior samples, for each observation i.\nFundamentally, model comparison is performed by leveraging Occam\u2019s razor, i.e., parsimonious models are preferred in light of predictive performance. The models are compared based on their WAIC values, which are summarized using Figure 6.10.\nIt can be seen that the model with two Gaussian components are the best (smallest WAIC), however, there are considerable overlaps among all of the models when the estimated standard error is taken into consideration. Considering the fact that K = 2 gives the simplest model, also that there are only 152 observations (oilfields) in this dataset, the GMM with two components would be the best choice.\n98"
        },
        {
            "heading": "6.4.3 Clustering",
            "text": "When looking at the developed model from a latent variable perspective (Model 6.9), it becomes obvious that the mixture model serves as a natural candidate for solving clustering tasks, in that every observation (Li) can be drawn from one of the K data generating processes, each with its own set of parameters, N (Li | \u00b5k, \u03c3k). Since a probabilistic model is built, for the purpose of clustering, a reasonable choice is to assign a data point to the mixture component (i.e., cluster) with the highest posterior probabilities (which are also interpreted as the responsibilities). In the case of the 2-component GMM trained from the previous sections, for a particular observation x, the probability that it belongs to cluster one (z = 1) can be computed using Bayes\u2019 theorem (Equation 2.3a):\np(z = 1 | x) = p(z = 1)N (x | \u00b51, \u03c31) p(z = 1)N (x | \u00b51, \u03c31) + p(z = 2)N (x | \u00b52, \u03c32) , (6.12)\nwhere every part in the formula can be obtained from the posterior samples (e.g., using the posterior means).\nClustering, as an unsupervised approach, can be used to reveal the hidden groups in the observations. In the case of the oilfield flaring magnitudes data in this chapter, the two clusters can be directly mapped to concepts such as major and minor flaring fields. However, it is usually the deeper insights into what caused these clusters that the state government is mostly interested in, for the sake of decision- and policy-making for example. If the oilfields belonging to the major flaring cluster seem to be a volatile membership when more months/quarters data are analyzed, the variations in flared volumes are possibly tied more closely to company strategies and movements. On the other hand, if there exists a group of oilfields that are found to join the major flaring cluster on a regular basis, this could provide a perspective in regards to where to construct the next natural gas processing plants, i.e., the locations/capacities of the new gas plants should be optimized based on those oilfields\u2019 situations.\n99\nIn this chapter, the dataset compiled for unsupervised learning is univariate, i.e., xi \u2208 X \u2286 R1. GMM are also suitable for the density estimation and clustering tasks when the data goes beyond 1D. As an example, for the same oilfields studied for Q4 2018, if their oil production volumes are extracted from NDIC, a scatterplot of gas flaring versus oil production magnitudes is shown in Figure 6.11. It is very possible that the density of the underlying distribution can be modeled by a bivariate normal distribution or a 2D GMM. In such cases, the mixture components become multivariate normal distributions, and the component covariance matrices can be constructed with the help of the LKJ distribution (which is employed in Models 4.5 and 4.7). The developed density model can be used, for example, in anomaly detections, looking for any oilfields which have a tendency to creep toward the upper left corner (characterized by very little oil production and a huge flaring magnitude). Similar to all the inferences presented throughout this dissertation, one advantage of doing such is that the decision making can be based on some consistent metrics (such as probability scores), instead of some criteria based on human eyeballing or improvising."
        },
        {
            "heading": "102 103 104 105 106 107",
            "text": "100\nThis concludes the statistical modeling journey of this dissertation. In the next chapter, discussions are presented on one extension scenario and one bigger picture viewpoint, from applying Bayesian learning to flaring data.\n101\nCHAPTER 7 DISCUSSION\nThis chapter discusses the possibility of operator level monitoring and analytics, potential result inconsistencies, and relates the endeavors of learning from flaring data to the larger process of applying machine learning in the petroleum engineering domain."
        },
        {
            "heading": "7.1 Operator Level Monitoring and Analytics",
            "text": "Up till this point, the satellite-detected flaring statistics have been applied to the state, county, and oilfield levels. This is made possible by the reverse geocoding discussed in Section 3.3. An ideal application scenario is operator level monitoring and analytics by leveraging the information from the satellite detections.\nUnfortunately, assigning flares to corresponding companies is not a straightforward operation. One possible solution is to make use of the shapefiles of the leases, which are not provided by NDIC. Some data vendors have such files in their database. However, after spending some effort investigating the lease shapefiles from one vendor, the author believes it is possible to create more problems than solving the existing ones, when bringing in such information. In particular, some reasons include:\n\u2022 Multiple companies exist on a single lease.\n\u2022 The company names from the lease shapefiles do not always correspond with those on\nthe NDIC monthly production reports.\n\u2022 Some leases in the vendor\u2019s database miss start date or end date data.\n\u2022 It takes time for the vendor to compile and digitize such information, which makes the\navailable lease shapefiles not up to date.\n102\nNevertheless, for such an important use case, the author managed to develop a nearestneighbor-based approach which partly solves the problem (Algorithm 7.1). The essence of this approach is to cautiously assign the closest well\u2019s operator to each satellite-detected flare. The closest wells are found based on the corresponding time window. For example, for the flares detected in January 2016, only the active wells reported on the NDIC production report from the same month are looked up. The function FindClosestOperator() returns the closest operator (OPj) for each VIIRS detection, as well as the calculated distance (dj) between each pair (of flare and well). The distance is calculated based on the haversine metric, i.e., the great-circle distance, thus the Earth radius (RE) is needed. The function is essentially performing the k-nearest-neighbors (k-NN) search for k = 1. When the sample is as large as in this case, i.e., there are usually a few hundred VIIRS detections and more than 15,000 wells for each month, linear scanning each well\u2019s location for each VIIRS detection is too slow. Therefore, in this work, the function internally depends on a ball tree implementation from scikit-learn (Pedregosa et al. 2011) for speedup on the k-NN search.\nOnce the 2-tuple, (OPj, dj), is obtained for each VIIRS detection, some logics are implemented to decide whether to drop or keep the operator assignment. The idea is straightforward: the assignment is immediately kept or discarded, when dj is very small or very large, respectively. If dj is mid-range, i.e., dsecure \u2264 dj \u2264 dcutoff, the assignment will be in effect, only if the flare and the operator are found to be located on the same township/range/section. The township/range/section shapefiles, as part of the input for Algorithm 7.1, are available from the NDIC GIS Map Server. The reverse geocoding follows the exact same procedure as in Section 3.3. After the processing is completed, a small portion of the VIIRS detections are not used for operator level analytics, because either they are too far away from the reported well locations, or the townships/ranges/sections fail to match. It should be noted that, the pseudocode for Algorithm 7.1 is written in a way that illustrates the precise details in the data processing logics. For the implementation in this work, some of the for-loops are replaced by the vectorized operations for enhanced performance.\n103\nAlgorithm 7.1: Nearest-Neighbor-Based Flare Owner Assignment\nInput: both VIIRS and NDIC reportings in WGS 84 coordinates, the township/range/section shapefiles for North Dakota, dsecure, dcutoff, RE Output: operators being assigned to most VIIRS detections\n1 n\u2190 number of months 2 for i\u2190 1 to n do 3 VIIRSi \u2190 the i-th month\u2019s observations from VIIRS 4 NDICi \u2190 the i-th month\u2019s reportings from NDIC 5 (OP, d)\u2190 FindClosestOperator(VIIRSi, NDICi, RE) 6 m\u2190 number of records in OP or d 7 for j \u2190 1 to m do 8 OPj \u2190 the closest operator found on the j-th record 9 dj \u2190 the distance between the flare and the closest well, for the j-th record\n10 if dj > dcutoff then 11 drop OPj 12 else if dj < dsecure then 13 keep OPj 14 else 15 if township/range/section agree then 16 keep OPj 17 else 18 drop OPj 19 end 20 end 21 end 22 end\nThe developed approach is tested with real flaring data from North Dakota. For the\ndemonstrated cases in this section, the values below are chosen for Algorithm 7.1:\ndsecure = 300 m (7.1a) dcutoff = 800 m (7.1b)\nRE = 6371 km (7.1c)\nSome operators are found to show positive correlations between the NDIC and VIIRS reported volumes. Examples of two operators, denoted by Operator B and Operator C, are shown in Figure 7.1. The axes\u2019 meanings are the same as in the right panel of Figure 3.7. The\n104\nlegend shows the results of fitting Equation 3.2d by ordinary least squares (OLS). R2adj stands for the adjusted R2. Although the differences in \u03b2\u0302operator indicate that there is heterogeneity among the different companies, these operators show some consistency in terms of their own reporting and have good matches with the VIIRS data up to a scale factor (as the intercepts are very close to zero).\nHowever, some operators (e.g., Operator D and Operator E) show discrepancies between their reportings and the satellite-detected flaring statistics, which are manifested through the poor fits (Figure 7.2). Certainly, a poor fit with the linear model does not indicate much on its own. Nonetheless, there exists a pattern in both scatterplots that, some points seem to be \u201cpushed down\u201d towards the x-axis. If the time series of these two operators are drawn, it shows that this behavior is due to company-reported volumes leveling off for a certain period of time (Figure 7.3). The VIIRS curves in the time series imply that there were flaring intensity variations for those times. This workflow, driven by Algorithm 7.1, is capable of raising a flag when it comes across datasets like these, and can serve as a powerful monitoring\n105\nand analytics tool, however, strong cautions need to be applied.\nThe introduced approach, although it looks promising, is by no means a one-stop solution and has the potential for being misapplied. First, there is the possibility of misassigning the satellite-detected flares to the operators. Whenever the concern is raised, further investigations can be conducted by looking into the detection maps as well as the satellite imagery of the operators\u2019 production sites. In addition, this method is more effective for the relatively large producing/flaring operators, because when a company conducts very little flaring, the truncation effects discussed for the peak in Figure 5.20 are magnified."
        },
        {
            "heading": "7.2 Warnings Regarding Inconsistencies",
            "text": "Given the resolution of the satellite imagery, assigning specific flaring volumes to a given operator is fraught with challenges. Although the VIIRS processing workflow is capable of picking up flares with areas around 1 m2 (Figure 3.2(a)), the pixel footprint is much larger (Table 2.1). Since the latitude and longitude of the pixel center is stored for each individual VIIRS observation (Elvidge et al. 2015), when multiple operators have sub-pixel combustion\n106\nsources, it makes flare owner assignment extremely challenging. In such situations, conclusions reached by merely benchmarking company reporting against VIIRS reporting would likely be inaccurate. In fact, in the realm of NDIC reporting, warnings must be issued regarding any inconsistencies in those results, with considerations from three aspects. First, the report from the U.S. Department of Energy (2019a) presents data supporting that North Dakota\n107\nshows closer agreement between the NOAA estimations and state reportings (of flared gas volumes), when compared with Texas and New Mexico. Second, flaring is preferred over venting because methane (the main component of natural gas) is more potent than carbon dioxide which is the main product of flaring (EIA 2019b). Since North Dakota bans venting, the massive flaring magnitude indicates that the direct release of gas into the atmosphere is minimized. Third, estimation of flaring volumes is inherently a difficult task. When it is not practicable to meter the flared gas, the Canadian Association of Petroleum Producers (2002) gives guidelines on available volume estimation methods. Every category of methods, no matter using rules of thumb, or experimentally determined correlations, or process simulators, has its own limitations and accuracy issues. Considering the fact that the VIIRS volumes used in this work were largely calibrated using the Cedigaz reported data (Section 2.1), which has its own error bars (Elvidge et al. 2015), the difference between company reporting and VIIRS reporting is inconclusive and unsurprising, especially when the standard error of the difference is larger than the difference itself.\nBy inspecting a more comprehensive profile of time series, both Operator D and Operator E from the previous section are self-consistent in their reportings to the NDIC. Their time series are displayed in Figure 7.4 and Figure 7.5, respectively. The variables and associated labels (shown in the legends) follow the same definitions from Section 3.4. The units for all the variables are given in Table 7.1. Clearly, the reported flared volumes show good correspondence with the gas production and GOR profiles. Some rapid variations in their flared volumes match the fluctuations in the gas prices, i.e., when the gas price drops, the operators tend to flare more, whereas when the gas price reaches peak, there is little flaring. In summary, to nail down the decisions and conclusions with regard to operator reporting quality, better resolution satellite data and a more comprehensive review of the time series profiles are required.\n108\n109\n110"
        },
        {
            "heading": "7.3 Caveats in Petroleum Data Analytics",
            "text": "As a petroleum engineer, the author is thrilled to witness the oil and gas industry and academia are embracing data-driven mindsets and solutions, while being part of it through writing this dissertation. However, there are certainly areas that could be continuously improved, and this section provides a discussion on one of those. That is, extending a cautious welcome to some black box models.\nThe pervasive influence of some black box models in the recent years can be seen by performing a rough search on OnePetro (Table 7.2). One thing to note is that, from an algorithmic point of view, these methods are rather \u201cglass boxes\u201d as opposed to \u201cblack boxes\u201d, i.e., everything under the hood in terms of implementation is well understood. For example, backpropagation, which is the core of neural network training, is based on the chain rule. However, for a given task, the learned parameters inside the network provide little or no insights for the problem domain. Therefore, it is considered a black box.\nThe wide adoption of such models is largely due to the availability of the open source libraries, for example in the Python ecosystem, construction and training of neural networks become much simpler thanks to TensorFlow and PyTorch, and gradient boosting models can be built within a few lines of code with the help of XGBoost, LightGBM, or CatBoost. In other words, with the mathematical details of those statistical routines abstracted away, for a practitioner, implementing those models is almost as easy as pushing a Learning button on\n111\nTable 7.2: Publication Count Rise on OnePetro\nExact Phrase Searched\nYear Method Introduced\nPublication Count\n2010\u20132014 2015\u20132019\nneural network 1958\u2020 843 2044 gradient boosting 2001\u2021 1 110 random forest 2001\u00a7 9 245\n\u2020 Based on (Rosenblatt 1958) \u2021 Based on (Friedman 2001) \u00a7 Based on (Breiman 2001)\na GUI.\nUnfortunately, easiness in the implementation does not imply appropriateness for the\nproblem. In particular, those black box models face the challenges below:\n1. How to incorporate domain expertise.\nA lot of the black box models in the frequentist framework make the assumption that the observations are conditionally i.i.d. The hope is that by feeding a huge number of i.i.d. samples to a universal approximator, such as a neural network, some function for prediction can be optimized with a certain accuracy. For some applications, the domain expertise is often encoded in the feature selection process. For example, to train a model to predict oil production, the analyst might choose some completion parameters other than the API well number or well name, as input features.\nHowever, in the author\u2019s opinion, this way of incorporating domain expertise is still a shallow one, which is far from what the oil and gas industry have accumulated in many decades. For example, the phenomena of well interference through fracture hits leave the assumption of some neighboring wells being i.i.d. in an unfavorable position. Another example would be, when looking at a populations of wells from one basin that are completed by N oilfield service companies, domain expertise might indicate that, each company deserves its own model while each company is not completely\n112\nindependent from others in terms of the completion technologies, etc. In this situation, the hierarchical model employed in Chapter 4 might be a better choice, in which case a lot of the prior knowledge about the different service companies can be incorporated into the population model.\n2. How to interpret the results.\nAs discussed earlier, the black box models suffer from the interpretability issues. Using the shale gas wells example from Item 1 above, if a black box model is trained, it is impossible (at this point) to attribute the failure in capturing the well interference effects to a certain part of the neural network, or to a certain portion of the decision trees (in the case of gradient boosted trees or random forest). Rudin (2019) asserted that people should \u201cstop explaining black box machine learning models\u201d and use interpretable models for high-stakes decisions. In the petroleum industry, there are a number of high-stakes decision scenarios, such as real-time well integrity anomaly detection and production forecasting in a high well cost context. Blindly applying black box models to those scenarios might involve serious losses. In terms of providing interpretability, the Bayesian approach employed throughout this dissertation is much more effective. Each and every assumption is expressed in the generative model through either the priors or the likelihood.\n3. How to quantify the uncertainties, especially in the context of risk management and\ndecision making.\nAlong the lines of Item 2 above, error bars are vital, especially in high-stakes prediction applications. In the case of predicting oil production using a trained data-driven model, point prediction results such as 1000 bbl/day are not really insightful. In fact, if the 95 % prediction interval (PI) is 1000\u00b1 50 bbl/day, that point prediction becomes more informative. However, if the 95 % PI is 1000\u00b1 1500 bbl/day, that same point prediction is unhelpful or misleading. What shall be reported instead is either the considered\n113\nmodel yields much uncertainty in this given task, or there is possibility that the entity will not produce anything at all.\nIt should be noted that, the \u201895\u2019 in the CI/PI is not a \u201cmagic number\u201d. A state government or an oil company might want to make decisions based on 73 % or 99.6 % confidence, or any other arbitrary choices. What really matters is the necessity of a principled way to quantify the uncertainties in machine learning-based estimations/predictions, such that any intervals can be computed. As presented throughout this dissertation, the Bayesian approach provides full capacity and flexibility is this regard. In fact, for parameter estimates, the author chooses to give 90 % CI instead of the \u201cconventional\u201d 95 %, to emphasize that this should be a domain\u2019s consideration rather than a statistical one.\nA lot of the black box models in the frequentist framework, however, fall short of this requirement. Maximum likelihood estimation (MLE), which is fundamentally relied upon by some frequentist learning methods, enjoys really nice properties and is capable of quantifying uncertainties, but only when a massive amount of data is at hand such that the asymptotic properties could take effect. Unfortunately, that is not the case in many scenarios for the petroleum engineering domain, which is discussed next.\n4. How to mitigate overfitting when the data is not \u201cbig\u201d.\nTwo aspects are worth discussing here. For one thing, the big data is not everywhere. Indeed, the author believes that the claim of Gelman (2015) that, \u201csample sizes are never large\u201d, applies to a lot of problems in the petroleum industry. The reason is that, if the data were large, the analyst would already be on to the next problem for which more data is needed. For example, a sample of 500 producing wells in the Bakken Formation could make some general study possible. When the analyst has access to a dataset of more than 15,000 wells, some granular insights are desirable. Especially, if partial pooling is needed among the different service companies/operators, different\n114\nmembers of the formation, or different completion technologies, data for some units of the population could be very small (which happens for the analysis in Chapter 4).\nOn the other hand, the sample size should be inspected in the light of model complexity. The number of parameters provides one measure of such. For example, consider a hypothetical classification problem, whose goal is to determine if a given well will deliver good or average or poor production performance. Ten completion parameters (features) are available to train the multilayer perceptron illustrated in Figure 7.6.\nIn this (small) neural network, the number of parameters np is given by:\nnp = 11\u00d7 20 + 21\u00d7 10 + 11\u00d7 3 = 463, (7.2)\nwhen considering a single bias node for every layer except the last one. To train this model, a dataset of 500 wells would definitely be a small sample. There is still possibility to train such a model with a small sample, however, great efforts in regularization have to be made, in the hope that the neural network will learn something that can be generalized, instead of merely memorizing the observed samples (i.e., overfitting).\n115\nBy utilizing the regularizing priors, the Bayesian approach\u2019s built-in Occam\u2019s razor greatly mitigate the risk of overfitting. In particular, Bayesian nonparametric models, such as the Gaussian processes employed in Chapter 5, are very attractive in a sense that the sizes of models are allowed to grow with the size of data (Orbanz and Teh 2010). This makes the developed model flexible while being robust to overfitting.\nAlthough the Bayesian learning models (such as the ones developed in this work) have outstanding merits and deserve wider utilization in petroleum data analytics, they are not cure-alls. Recently researchers have started to stress the necessity of bespoke statistical models (Andorra 2020; McElreath 2020). The argument is that, off-the-shelf models, no matter neural networks or generalized linear models, interrupt the incorporation of domain expertise. This is especially relevant in the field of petroleum engineering. For instance, when conducting data-driven analysis for hydraulic fracturing performance, it makes sense to bring in the fracture propagation models to the machine learning workflow. That way, statistical models are motivated by the physically informed models. The Bayesian framework, as employed throughout this dissertation, readily embraces this strategy, in that the domain knowledge, which is represented by differential equations for example, can be inserted into the generative model. One advantage is that a lot of the parameters will have direct scientific meanings, and more informative priors can be placed based on scientific constraints, field experience, etc. The final outcome should be better inferences and predictions.\n116\nCHAPTER 8\nCONCLUSIONS AND RECOMMENDATIONS\nIn this dissertation, the effectiveness of a full Bayesian approach has been observed in learning models from natural gas flaring data. The author hopes this work contributes to the understanding of the options and considerations when applying data-driven approaches to gas flaring. In closing, this chapter presents the major conclusions and recommendations for future work."
        },
        {
            "heading": "8.1 Conclusions",
            "text": "The major conclusions are:\n1. Bayesian learning implemented using Hamiltonian Monte Carlo can be effectively\napplied to real problems in gas flaring analytics, in both supervised and unsupervised settings. The advantages of the Bayesian approach indicate it deserves wider usage in the petroleum engineering domain in general; these advantages are listed below:\n(a) Petrotechnical domain expertise can be incorporated in a principled way.\n(b) Model interpretability is drastically improved, facilitating communications with\npetroleum engineers.\n(c) Quantification of uncertainty leads to more robust decision making, which is\nimportant for oil exploration and production companies.\n(d) The built-in Occam\u2019s razor makes the model less prone to overfitting, in the\ncontext of noisy field measurements.\n2. The development of a suite of models (Table 8.1), with both parametric and nonpara-\nmetric techniques, provides guidance on how insights can be extracted from various\n117\nangles. The presented models are designed and tested to be able to generalize to different entities at various levels.\n3. To investigate the heterogeneity among the different entities (such as counties or\noilfields), partial pooling is recommended, because some entities have very little data.\n4. Gaussian processes demonstrate very attractive traits in revealing the patterns and\ntrends from flaring time series. A set of priors with the Mate\u0301rn 5/2 kernel works very well across different modeling goals, observation models, and data sources.\n5. From a distributional point of view, the negative binomial and Gaussian mixture models\nare good representations of the oilfield flare counts and flared volumes, respectively. The learned parameters and structures are very interpretable. Hidden clusters are found by fitting Gaussian mixture models.\n6. A nearest-neighbor-based approach for operator level monitoring and analytics is\nintroduced. Its performance is tested on real data and defendable results are obtained. However, better resolution satellite data is needed for the scenario of multiple operators\u2019 wells being very close to each other.\n7. All the dissertation objectives (Section 1.2) have been achieved. In particular, the flared\nvolumes missed from VIIRS for the state and each county are estimated via fitting the intercept parameter and reported in Table 3.1 and Table 4.2. The nighttime combustion source detection limits of Landsat 8, without being corrected for artifacts due to glow, are determined and reported in Figure 3.2(b). Correlations between financial factors, production performance, and flared volumes at a state level are computed using Spearman\u2019s \u03c1 and reported in Figure 3.5 and Figure 3.6 for the original data and lag-1 differences, respectively. Most pairs of the variables do not show strong correlations on the lag-1 differences. Robust Gaussian process modeling serves as a generic framework for addressing the rest of the objectives, including demonstrating operator approaches,\n118\nevaluating if the goals of the North Dakota regulatory policy (Order 24665) have been achieved, and predicting NDIC flared volumes."
        },
        {
            "heading": "8.2 Future Work",
            "text": "3. Hierarchical Gaussian processes.\nThe models in Chapter 5 are learned from each entity\u2019s own data. It would be interesting to see how far the scheme of partial pooling (Chapter 4) can be taken. Can pooling across different entities via hierarchical Gaussian processes improve the inferences?\n4. Spatial-temporal analysis.\nOne step further from Item 3 above, the efficacy of spatial-temporal models (which allow for pooling information across time and space) are worth investigating. Are neighboring entities exhibiting close resemblance in flaring behaviors?\n5. Unify everything under Bayesian nonparametrics.\nThe model comparison for GMMs in Chapter 6 depends on specifying the potential numbers of clusters a priori. In fact, Dirichlet process, as an infinite-dimensional generalization of the Dirichlet distribution, is nonparametric and allows for automatically choosing the number of necessary clusters. Considering the effectiveness of GP (Chapter 5), it would be interesting to see how far the nonparametric models can be taken in flaring data analytics. Can all of the gas flaring analytics problems be addressed in an unified framework of Bayesian nonparametrics?\n120"
        }
    ],
    "year": 2023
}