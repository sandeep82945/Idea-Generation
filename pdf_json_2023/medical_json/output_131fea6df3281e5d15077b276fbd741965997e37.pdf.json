{
    "abstractText": "Building a score from a questionnaire to predict a binary gold standard is a common research question in psychology and health sciences. When building this score, researchers may have to choose between statistical performance and simplicity. A practical question is to what extent it is worth sacrificing the former to improve the latter. We investigated this research question using real data, in which the aim was to predict an alcohol use disorder (AUD) diagnosis from 20 self-reported binary questions in young Swiss men (n = 233, mean age = 26). We compared the statistical performance using the area under the ROC curve (AUC) of (a) a \u201crefined score\u201d obtained by logistic regression and several simplified versions of it (\u201csimple scores\u201d): with (b) 3, (c) 2, and (d) 1 digit(s), and (e) a \u201csum score\u201d that did not allow negative coefficients. We used four estimation methods: (a) maximum likelihood, (b) backward selection, (c) LASSO, and (d) ridge penalty. We also used bootstrap procedures to correct for optimism. Simple scores, especially sum scores, performed almost identically or even slightly better than the refined score (respective ranges of corrected AUCs for refined and sum scores: 0.828\u20130.848, 0.835\u20130.850), with the best performance been achieved by LASSO. Our example data demonstrated that simplifying a score to predict a binary outcome does not necessarily imply a major loss in statistical performance, while it may improve its implementation, interpretation, and acceptability. Our study thus provides further empirical evidence of the potential benefits of using sum scores in psychology and health sciences.",
    "authors": [
        {
            "affiliations": [],
            "name": "Valentin Rousson"
        },
        {
            "affiliations": [],
            "name": "Bastien Tr\u00e4chselID"
        },
        {
            "affiliations": [],
            "name": "Katia Iglesias"
        },
        {
            "affiliations": [],
            "name": "St\u00e9phanie BaggioID"
        }
    ],
    "id": "SP:3909a71674cdbd2a4ddea2787bd11d696f250744",
    "references": [
        {
            "authors": [
                "HCW de Vet",
                "CB Terwee",
                "LB Mokkink",
                "DL. Knol"
            ],
            "title": "Measurement in medicine: A practical guide",
            "venue": "PLOS ONE The cost of simplicity PLOS ONE | https://doi.org/10.1371/journal.pone.0294671 November",
            "year": 2011
        },
        {
            "authors": [
                "Edelsbrunner PA"
            ],
            "title": "A model and its fit lie in the eye of the beholder: Long live the sum score",
            "venue": "Frontiers in Psychology",
            "year": 2022
        },
        {
            "authors": [
                "C DiStefano",
                "M Zhu",
                "D. Mindrila"
            ],
            "title": "Understanding and using factor scores: Considerations for the applied researcher",
            "venue": "Practical Assessment, Research & Evaluation",
            "year": 2009
        },
        {
            "authors": [
                "Grice JW",
                "Harris RJ"
            ],
            "title": "A comparison of regression and loading weights for the computation of factor scores",
            "venue": "Multivariate Behavioral Research",
            "year": 1998
        },
        {
            "authors": [
                "V Rousson",
                "T. Gasser"
            ],
            "title": "Simple component analysis",
            "venue": "Journal of the Royal Statistical Society: Series C (Applied Statistics)",
            "year": 2004
        },
        {
            "authors": [
                "Vines SK"
            ],
            "title": "Simple principal components",
            "venue": "Journal of the Royal Statistical Society Series C (Applied Statistics)",
            "year": 2000
        },
        {
            "authors": [
                "Wackwitz JH",
                "Horn JL"
            ],
            "title": "On obtaining the best estimates of factor scores within an ideal simple structure",
            "venue": "Multivariate Behavioral Research",
            "year": 1971
        },
        {
            "authors": [
                "McNeish D",
                "Wolf MG"
            ],
            "title": "Thinking twice about sum scores",
            "venue": "Behavior Research Methods",
            "year": 2020
        },
        {
            "authors": [
                "D. McNeish"
            ],
            "title": "Psychometric properties of sum scores and factor scores differ even when their correlation is 0.98: A response to Widaman and Revelle",
            "venue": "Behavior Research Methods. 2022",
            "year": 2016
        },
        {
            "authors": [
                "KF Widaman",
                "W. Revelle"
            ],
            "title": "Thinking thrice about sum scores, and then some more about measurement and analysis",
            "venue": "Behavior Research Methods. 2022",
            "year": 2022
        },
        {
            "authors": [
                "H. Wainer"
            ],
            "title": "Estimating coefficients in linear models: It don\u2019t make no nevermind",
            "venue": "Psychological Bulletin",
            "year": 1976
        },
        {
            "authors": [
                "Dawes RM"
            ],
            "title": "The robust beauty of improper linear models in decision making",
            "venue": "American Psychologist",
            "year": 1979
        },
        {
            "authors": [
                "P Bobko",
                "PL Roth",
                "MA. Buster"
            ],
            "title": "The usefulness of unit weights in creating composite scores: A literature review, application to content validity, and meta-analysis",
            "venue": "Organizational Research Methods",
            "year": 2007
        },
        {
            "authors": [
                "EW Steyerberg",
                "AJ Vickers",
                "NR Cook",
                "T Gerds",
                "M Gonen",
                "N Obuchowski"
            ],
            "title": "Assessing the Performance of Prediction Models: A Framework for Traditional and Novel Measures. Epidemiology",
            "venue": "PMID:",
            "year": 2001
        },
        {
            "authors": [
                "Babyak MA"
            ],
            "title": "What you see may not be what you get: a brief, nontechnical introduction to overfitting in regression-type models",
            "venue": "Psychosom Med",
            "year": 2004
        },
        {
            "authors": [
                "D. McNeish"
            ],
            "title": "Limitations of the sum-and-alpha approach to measurement in behavioral research. Policy Insights from the Behavioral and Brain Sciences",
            "year": 2022
        },
        {
            "authors": [
                "S Baggio",
                "B Tr\u00e4chsel",
                "V Rousson",
                "S Rothen",
                "J Studer",
                "S Marmet"
            ],
            "title": "Identifying an accurate selfreported screening tool for alcohol use disorder: evidence from a Swiss, male population-based assessment",
            "venue": "Addiction (Abingdon,",
            "year": 2020
        },
        {
            "authors": [
                "K Iglesias",
                "F Sporkert",
                "J-B Daeppen",
                "G Gmel",
                "S. Baggio"
            ],
            "title": "Comparison of self-reported measures of alcohol-related dependence among young Swiss men: a study protocol for a cross-sectional controlled sample",
            "venue": "BMJ Open",
            "year": 2018
        },
        {
            "authors": [
                "G Gmel",
                "C Akre",
                "M Astudillo",
                "C B\u00e4hler",
                "S Baggio",
                "N Bertholet"
            ],
            "title": "The Swiss Cohort Study on Substance Use Risk Factors\u2013findings of two waves. SUCHT",
            "year": 2015
        },
        {
            "authors": [
                "JR Knight",
                "H Wechsler",
                "M Kuo",
                "M Seibring",
                "ER Weitzman",
                "MA. Schuckit"
            ],
            "title": "Alcohol abuse and dependence among U.S. college students",
            "venue": "J Stud Alcohol",
            "year": 2002
        },
        {
            "authors": [
                "C Meneses-Gaya",
                "AW Zuardi",
                "SR Loureiro",
                "JEC Hallak",
                "C Trzesniak",
                "JM de Azevedo Marques"
            ],
            "title": "Is the full version of the AUDIT really necessary? Study of the validity and internal construct of its abbreviated versions",
            "venue": "Alcohol Clin Exp Res",
            "year": 2010
        },
        {
            "authors": [
                "A Berney",
                "M Preisig",
                "M-L Matthey",
                "F Ferrero",
                "BT. Fenton"
            ],
            "title": "Diagnostic interview for genetic studies (DIGS): inter-rater and test-retest reliability of alcohol and drug diagnoses",
            "venue": "Drug and Alcohol Dependence",
            "year": 2002
        },
        {
            "authors": [
                "BF Grant",
                "DA Dawson",
                "FS Stinson",
                "PS Chou",
                "W Kay",
                "R. Pickering"
            ],
            "title": "The Alcohol Use Disorder and Associated Disabilities Interview Schedule-IV (AUDADIS-IV): reliability of alcohol consumption, tobacco use, family history of depression and psychiatric diagnostic modules in a general population sample",
            "venue": "Drug and Alcohol Dependence",
            "year": 2003
        },
        {
            "authors": [
                "M Dupuis",
                "S Baggio",
                "Y Henchoz",
                "S Deline",
                "A N\u2019Goran",
                "J Studer"
            ],
            "title": "Risky single occasion drinking frequency and alcohol-related consequences: can abstinence during early adulthood lead to alcohol problems",
            "venue": "Swiss Med Wkly",
            "year": 2014
        },
        {
            "authors": [
                "H Wechsler",
                "A Davenport",
                "G Dowdall",
                "B Moeykens",
                "S. Castillo"
            ],
            "title": "Health and behavioral consequences of binge drinking in college. A national survey of students at 140 campuses",
            "venue": "JAMA",
            "year": 1994
        },
        {
            "authors": [
                "TA Gerds",
                "T Cai",
                "M. Schumacher"
            ],
            "title": "The performance of risk prediction models",
            "venue": "Biom J",
            "year": 2008
        },
        {
            "authors": [
                "EW Steyerberg",
                "MJ Eijkemans",
                "FE Harrell",
                "JD. Habbema"
            ],
            "title": "Prognostic modeling with logistic regression analysis: in search of a sensible strategy in small data sets",
            "venue": "Med Decis Making",
            "year": 2001
        },
        {
            "authors": [
                "H. Akaike"
            ],
            "title": "Information theory and an extension of the maximum likelihood principle",
            "venue": "Selected Papers of Hirotugu Akaike. Springer Series in Statistics",
            "year": 1998
        },
        {
            "authors": [
                "G James",
                "D Witten",
                "T Hastie",
                "R. Tibshirani"
            ],
            "title": "An introduction to statistical learning with applications in R",
            "year": 2014
        },
        {
            "authors": [
                "EW Steyerberg",
                "FE Harrell",
                "GJ Borsboom",
                "MJ Eijkemans",
                "Y Vergouwe",
                "JD. Habbema"
            ],
            "title": "Internal validation of predictive models: efficiency of some procedures for logistic regression analysis",
            "venue": "J Clin Epidemiol",
            "year": 2001
        }
    ],
    "sections": [
        {
            "text": "Building a score from a questionnaire to predict a binary gold standard is a common\nresearch question in psychology and health sciences. When building this score, researchers\nmay have to choose between statistical performance and simplicity. A practical question is\nto what extent it is worth sacrificing the former to improve the latter. We investigated this\nresearch question using real data, in which the aim was to predict an alcohol use disorder\n(AUD) diagnosis from 20 self-reported binary questions in young Swiss men (n = 233, mean\nage = 26). We compared the statistical performance using the area under the ROC curve\n(AUC) of (a) a \u201crefined score\u201d obtained by logistic regression and several simplified versions\nof it (\u201csimple scores\u201d): with (b) 3, (c) 2, and (d) 1 digit(s), and (e) a \u201csum score\u201d that did not\nallow negative coefficients. We used four estimation methods: (a) maximum likelihood, (b)\nbackward selection, (c) LASSO, and (d) ridge penalty. We also used bootstrap procedures\nto correct for optimism. Simple scores, especially sum scores, performed almost identically\nor even slightly better than the refined score (respective ranges of corrected AUCs for\nrefined and sum scores: 0.828\u20130.848, 0.835\u20130.850), with the best performance been\nachieved by LASSO. Our example data demonstrated that simplifying a score to predict a\nbinary outcome does not necessarily imply a major loss in statistical performance, while it\nmay improve its implementation, interpretation, and acceptability. Our study thus provides\nfurther empirical evidence of the potential benefits of using sum scores in psychology and\nhealth sciences."
        },
        {
            "heading": "Introduction",
            "text": "Composite scores are widely used in psychology and health sciences. Guidelines are available for the development and validation of these scores, but recommendations for analytical strategies are less common [1]. Composite scores can be calculated at different levels of complexity [2]. The simplest composite score would be a sum score, in which the possible values are restricted to be either +1 or 0. In this sum score, all questions with a non-zero coefficient have the same positive weight. More sophisticated approaches to composite scores include the use\nPLOS ONE | https://doi.org/10.1371/journal.pone.0294671 November 27, 2023 1 / 10\na1111111111\nOPEN ACCESS\nCitation: Rousson V, Tra\u0308chsel B, Iglesias K, Baggio S (2023) Evaluating the cost of simplicity in score building: An example from alcohol research. PLoS ONE 18(11): e0294671. https://doi.org/10.1371/ journal.pone.0294671\nEditor: Sathishkumar Veerappampalayam Easwaramoorthy, Sunway University, MALAYSIA\nReceived: March 21, 2023\nAccepted: October 20, 2023\nPublished: November 27, 2023\nPeer Review History: PLOS recognizes the benefits of transparency in the peer review process; therefore, we enable the publication of all of the content of peer review and author responses alongside final, published articles. The editorial history of this article is available here: https://doi.org/10.1371/journal.pone.0294671\nCopyright: \u00a9 2023 Rousson et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\nData Availability Statement: Data and code are available as supplementary materials.\nFunding: This study was supported by Swiss National Research Foundation (no. 10001C_173418/1). The funders had no role in\nof restricted value ranges (e.g., +1, -1 or 0) or linear combinations of the items. Such composite scores (\u201crefined scores\u201d) can be developed using logistic regression models with a gold standard as the response variable and the items as predictors. These approaches allow for unequal weighting of questions."
        },
        {
            "heading": "Controversy on simple scores",
            "text": "The use of simple or refined scores has been much discussed and is still currently debated. First, it has been discussed in the context of scores obtained from factor or principal component analyses [3\u20137] with conflicting conclusions. While two recent studies warned that sum scores may be too imprecise for use in rigorous research applications [8, 9], another study presented an example where little was gained from the use of factor score estimates (i.e., refined scores) compared to simpler sum scores [10]. A third opinion paper also concluded that sum scores are suitable to build scores [2]. In the context of linear regression modeling, previous studies suggested that equal regression weights might be a reasonable choice [11\u201313], especially if predictors are standardized, with a modest loss of accuracy compared to unequal weight [11]. To our knowledge, the use of simple or refined scores was not discussed in the context of logistic regression. Further empirical investigations are therefore needed to better understand the benefits and limitations of simple or refined scores in this analytical context, as stated in recent studies [10, 13]."
        },
        {
            "heading": "Understudied perspectives",
            "text": "An interesting perspective that has been neglected in previous research is to identify the cost of simplicity. To facilitate implementation, interpretation, and acceptability, simple scores sacrifice some of the statistical performance for the sake of simplicity. If the loss of statistical performance does not appear to be substantial, this would argue in favor of using a simple rather than a refined score.\nIn addition, when evaluating the statistical performance of a score, it is important to con-\nsider problems of overfitting, also known as optimism, and to attempt to correct for them [14]. Overfitting occurs, for example, when a regression model includes too many predictors, but also when it is selected from a large family of candidate models, e.g., via automated variable selection [15]. Overfitting may lead to replicability issues, a critical issue in psychology and health sciences [16]. Simple scores may be less prone to overfitting than refined scores. This may be an unexplored advantage of simple scores over refined scores."
        },
        {
            "heading": "Objective of the study",
            "text": "The aim of the present study was therefore to investigate and evaluate the cost of simplicity using real-life data, where the aim was to predict a diagnosis of alcohol use disorder (AUD) diagnosis from 20 self-reported binary questions. Unlike factor analysis, where a score is developed to measure a theoretical construct that is not observable, we had the advantage of having a gold standard against which to compare our predictions. It was therefore possible to objectively compare the statistical performance (including optimism) of refined and simple scores obtained by different methods."
        },
        {
            "heading": "Materials and methods",
            "text": ""
        },
        {
            "heading": "Design",
            "text": "We re-used data from a prospective cross-sectional study designed to identify an accurate screening tool for AUD [17, 18]. The study was approved by the Ethics Committee of the\nPLOS ONE | https://doi.org/10.1371/journal.pone.0294671 November 27, 2023 2 / 10\nstudy design, data collection and analysis, decision to publish, or preparation of the manuscript.\nCompeting interests: The authors have declared that no competing interests exist.\nCanton of Vaud (no. 2017\u201300776). Participants signed a written informed consent for the study and an additional consent form to accept the reuse of their data in further projects. The authors did not have access to any information that could identify individual participants during or after data collection."
        },
        {
            "heading": "Participants",
            "text": "Data were collected from October 2017 to June 2018 in a sample of young Swiss men. They were recruited from the Cohort Study on Substance Use and Risk Factors (C-SURF) [19]. Inclusion criteria were 1) being a French-speaking participant, 2) completing the second follow-up questionnaire (from 2016 to 2018), and 3) having a valid email (n = 2,668). Eligible participants were invited to complete the ten-question version of the Alcohol Use Disorder Identification Test (AUDIT) [20] online (1,371 respondents, response rate = 51.4%). Participants were then selected using a stratified sampling strategy: those with a high AUDIT score (\ufffd13) and those with a low score (<13) [21]. The final sample size was 233 (total response rate = 70.6%, 68.9% in the low-strata group and 72.0% in the high-strata group)."
        },
        {
            "heading": "Diagnosis of AUD",
            "text": "A binary variable measured the presence or absence of AUD, assessed with a clinician-administered diagnostic interview (Diagnostic Interview for Genetic Studies (DIGS) [22]) and representing the gold standard. The DIGS has a high inter-rater agreement and a good concordance with clinical diagnoses from medical records [22]. At the time of the study, the DIGS had not been adapted to the DSM-5 criteria. To address this limitation, we replaced the DSM-IV question on legal problems (removed in DSM-5) with a question on craving (added in DSM-5). AUD was defined as at least mild (cut-off score = 2) in the previous twelve months."
        },
        {
            "heading": "Self-reported AUD and alcohol-related consequences",
            "text": "A set of 20 binary questions (1 = yes/0 = no, hereafter Q1-Q20) designed to screen for AUD was used to predict the gold standard. Participants self-reported the presence or absence of the eleven DSM-5 AUD criteria [20, 23] and of nine alcohol-related consequences [20, 24, 25] in the previous twelve months. The questions are listed in S1 Table."
        },
        {
            "heading": "Analytical strategy",
            "text": "The sample size was calculated for the original study purpose [17, 18]. As AUD was overrepresented in our study sample, we focused on discrimination rather than on calibration [14] when assessing the statistical performance of our scores. Score performance was measured using the area under the ROC curve (AUC) [26]."
        },
        {
            "heading": "Refined score",
            "text": "Our aim was to build a score that best predicted the gold standard (AUD) from the responses given to questions Q1-Q20. We fitted a logistic regression model with the gold standard as the outcome and questions Q1-Q20 as binary predictors. Coefficients were used for the score."
        },
        {
            "heading": "Simple scores",
            "text": "We defined four simple scores. First, we simplified non-zero coefficients with m = 3, 2 or 1 possible digit(s) (see S1 File for details). A fourth simple score allowed zero or positive coefficients, but not negative coefficients, is called a \u201csum score\u201d. This is because in our example data, all 20 predictors were designed to be positively associated with the gold standard. In such\nPLOS ONE | https://doi.org/10.1371/journal.pone.0294671 November 27, 2023 3 / 10\na context, having negative coefficients may undermine the acceptability of a simple score, so it is tempting to remove negative coefficients (set them to zero). This is consistent with the recommendation of Steyerberg et al. [27], who advocate \u201cusing qualitative information on the sign of the effect of predictors\u201d."
        },
        {
            "heading": "Methods",
            "text": "For both refined and simple scores, we first used maximum likelihood estimation (MLE). Then, to reduce the number of predictors in the model, we used the well-known backward elimination procedure (hereafter BACKWARD), which consists of starting with a model including all the predictors and eliminating the least significant predictor at each step of an iterative procedure. We used the Akaike criterion to select the best model [28]. We also used other more modern methods for fitting a model with many predictors with penalized maximum likelihood, i.e., the LASSO or RIDGE penalty (also called the L1 or L2 penalty, respectively), where the coefficients defining the score are shrunk towards zero [29]. The LASSO penalty sets some coefficients exactly to zero, making the resulting score more parsimonious.\nFinally, the results may be too optimistic. One reason is that our scores were derived and\nevaluated from the same data. For BACKWARD, another reason is that we used a strict model selection. To correct for optimism, we applied a bootstrapping procedure, as described and recommended by Steyerberg et al. [30]. Note that for BACKWARD and LASSO, the resulting model did not necessarily include the same number of predictors in each bootstrap resample.\nIn each resample and for each method, we calculated two AUCs: one using the data from the bootstrap resample and one using the data from the original sample. Optimism was estimated as the difference between these two AUCs, averaged over the 500 bootstrap resamples.\nAnalyses were performed using R software. For the LASSO and RIDGE procedures, we\napplied the default parameters implemented in the glmnet library (version 4.1\u20133). The statistical code and dataset are available as supplementary material."
        },
        {
            "heading": "Results",
            "text": "The proportion of patients with AUD was 33.5% (n = 78) (mean age = 27.00). The proportion of patients answering \u201cyes\u201d to the different questions ranged from 4% (Q18) to 67% (Q6). All questions were significantly positively associated with the gold standard, with odds-ratios ranging from 1.89 (for Q20) to 13.08 (for Q11), except for one question (Q20). Table 1 summarizes this information and also shows the sensitivity and specificity achieved by each question, as well as the AUC, which ranged from 0.525 (for Q20) to 0.679 (for Q4).\nThe main results for the refined and simples scores and different methods are shown in\nTable 2. For the refined score, the AUC for MLE was 0.890, higher than the AUCs when each individual question was considered as a predictor. Using the BACKWARD procedure, the final model included eight questions (Q2, Q4, Q5, Q8, Q9, Q10, Q14 and Q15) and the AUC was 0.876. We obtained AUCs of 0.887 for LASSO (Q1, Q2, Q4, Q5, Q7, Q8, Q10, Q11, Q12, Q13, Q14, Q15 and Q17, other coefficients set to zero) and 0.881 for RIDGE. The coefficients assigned to the different questions for the four methods considered (MLE, BACKWARD, LASSO, RIDGE) are plotted in the four panels of the first column of Fig 1. None of these scores are simple since all non-zero coefficients are different from each other. It is worth noting that some coefficients were negative for MLE and RIDGE.\nIn bootstrap analyses, we estimated an optimism of 0.052, 0.047, 0.045 and 0.039 for MLE,\nBACKWARD, LASSSO and RIDGE, respectively. Finally, corrected AUCs were obtained by subtracting the estimated optimism from the observed AUCs, yielding 0.838, 0.828, 0.848 and 0.846, respectively (see Table 2).\nPLOS ONE | https://doi.org/10.1371/journal.pone.0294671 November 27, 2023 4 / 10\nThe simple scores obtained with m = 3, 2 or 1 possible digit(s) are plotted in the second, third, and fourth columns of Fig 1 for the four methods. Unlike the refined score plotted in the first column of Fig 1, the non-zero coefficients of these simple scores are not all different from each other.\nObserved and corrected AUCs for all simple scores are shown in Table 2. Optimism was\nsystematically lower for simple scores than for the refined score. Among the simple scores, the optimism was also systematically lower with m = 1 than with m = 2 digits and with m = 2 than"
        },
        {
            "heading": "Question Proportion yes Sensitivity Specificity AUC OR P-value",
            "text": "with m = 3 digits. After correcting for optimism, the best performance in terms of AUC was obtained with the simplified LASSO with m = 3 digits, with a corrected AUC of 0.852, which was even better than the refined score obtained with LASSO (with a corrected AUC of 0.848).\nFinally, the fifth column of Fig 1 shows the sum scores obtained by the four methods by set-\nting the negative coefficients to zero. For BACKWARD and LASSO, they were identical to the one-digit simple scores. These scores are sums of 15, 8, 13 and 18 questions for MLE, BACKWARD, LASSO and RIDGE, respectively. The observed and corrected AUCs for these sum scores are shown in Table 2. Optimism was even lower for sum scores than for simple scores. The corrected AUCs for sum scores were of 0.848, 0.835, 0.849 and 0.850, respectively. Except for BACKWARD, which was slightly above, the sum scores obtained via MLE, LASSO or RIDGE performed almost as well (or even better than) the refined score via LASSO (with a corrected AUC of 0.848). In particular, the sum score via LASSO with a corrected AUC of 0.849 and only 13 questions could be a good final choice for this example, as the resulting score is not only simple but also parsimonious.\nhttps://doi.org/10.1371/journal.pone.0294671.g001\nPLOS ONE | https://doi.org/10.1371/journal.pone.0294671 November 27, 2023 6 / 10\nIt should be noted that the sum score used by Baggio et al. [17] for these data included 12\ninstead of 13 questions. It was not obtained as a simplified version of a refined score, but as the sum score minimizing the Akaike criterion among all 2^20\u20131 = 1\u2019048\u2019575 possible sums, achieving an observed AUC of 0.872 and a corrected AUC of 0.841."
        },
        {
            "heading": "Discussion",
            "text": "In this study, we attempted to simplify and evaluate the statistical performance in terms of AUC of refined and simple scores obtained by different methods using data from alcohol research where the aim was to predict an AUD from 20 binary questions.\nAmong the refined score methods, the best performance was achieved by LASSO with a\ncorrected AUC of 0. 848. The MLE method had the highest observed AUC (0.890), but it was the most optimistic method (i.e., the most prone to overfitting). However, as we only had 78 cases of AUD in our dataset, a model with 20 predictors did not follow the rule of thumb of 10 required events per predictor. This could lead to overfitting, although this rule of thumb should not be taken too strictly and has recently been questioned [31].\nAmong the ways of defining simple scores and related methods, a simple score with 3 digits\nusing LASSO was the best, even better than the refined score (corrected AUC = 0.852). Other simple scores, especially sum scores, performed almost identically or even slightly better than the refined score obtained with some methods, illustrating the fact that simplifying a score does not necessarily imply a major loss in statistical performance. Indeed, the sum score had the highest corrected AUCs for MLE, BACKWARD, and RIDGE.\nOverall, the more constrained the coefficients were, the less prone a method was to overfit-\nting. Simple scores, and even more, sum scores, are less prone to overfitting than the refined score because they are less data-dependent due to the restrictions imposed on their possible values. Therefore, the simplification of a refined score does not necessarily come at the cost of sacrificing statistical performance. Such considerations were anticipated by in a previous study in the context of linear regression [11] and factor analysis [10]. The latter found that factor scores could lead to greater indeterminacy than sum scores [10]. Estimates of the former may vary from sample to sample, whereas sum scores have identical weights in all samples. Our study illustrated and confirmed this finding in the context of logistic regression.\nIt should be noted that the corrected AUCs provided in our data are only sample estimates\nof the true AUC that would be obtained by applying a score to the entire population of interest. As the confidence intervals calculated around them would largely overlap, we would not be able to conclude that the corrected AUCs for a simple score would be \u201csignificantly higher\u201d than the corrected AUCs for the refined score. However, the reverse would also be true (the corrected AUCs for the refined score would not be significantly higher than the corrected AUCs for some simple scores) and this may already be sufficient justification for using a simple score in practice. In any case, researchers should not be discouraged a priori from striving for simplicity, as the sacrifice of statistical performance may be very small. This is in line with recent conclusions [10], which also noted that sum scores are easier to implement than factor scores.\nThese recommendations are based on a single, albeit real, data example, which constitutes a study limitation. In addition, the sample size was relatively small, which did not allow splitting the dataset into train and test sets. Therefore, we do not claim or advocated that it is possible to replace refined scores with simple scores in all practical cases. Rather, we encourage researchers and methodologists developing screening tools to evaluate the cost of simplicity along the lines presented here, including a correction for optimism, with their own data. Their results would provide a sound basis and some justification for deciding whether to retain a refined score or replace it with a simple score. Although researchers and statisticians have\nPLOS ONE | https://doi.org/10.1371/journal.pone.0294671 November 27, 2023 7 / 10\ndifferent views on the use of simple scores, there is a consensus on the need to take psychometrics seriously and to provide justification for the preferred scoring methods [2, 8, 10, 16]."
        },
        {
            "heading": "Conclusion",
            "text": "To conclude, our example data demonstrated that simplifying a score to predict a binary outcome does not necessarily imply a major loss in statistical performance, while potentially improving its implementation, interpretation, and acceptability. Our study thus provided further empirical evidence of the potential benefits of using sum scores in psychology and health sciences. Future studies should examine other practical or simulated cases to further evaluate the cost of simplicity and provide robust empirical evidence on this controversial issue."
        },
        {
            "heading": "Supporting information",
            "text": "S1 Checklist. PLOS ONE clinical studies checklist. (DOCX)"
        },
        {
            "heading": "S2 Checklist. STROBE statement\u2014checklist of items that should be included in reports of observational studies.",
            "text": "(DOCX)"
        },
        {
            "heading": "S1 Table. Items for self-reported alcohol use disorders and alcohol-related consequences.",
            "text": "(DOCX)"
        },
        {
            "heading": "S1 File. Simplification algorithm.",
            "text": "(DOCX)"
        },
        {
            "heading": "S2 File. R code.",
            "text": "(R)"
        },
        {
            "heading": "S1 Data. Database.",
            "text": "(TXT)"
        },
        {
            "heading": "Author Contributions",
            "text": "Conceptualization: Valentin Rousson, Bastien Tra\u0308chsel, Katia Iglesias, Ste\u0301phanie Baggio.\nData curation: Katia Iglesias, Ste\u0301phanie Baggio.\nFormal analysis: Valentin Rousson, Bastien Tra\u0308chsel.\nFunding acquisition: Ste\u0301phanie Baggio.\nInvestigation: Katia Iglesias.\nMethodology: Valentin Rousson, Bastien Tra\u0308chsel, Katia Iglesias, Ste\u0301phanie Baggio.\nProject administration: Ste\u0301phanie Baggio.\nSupervision: Valentin Rousson, Katia Iglesias.\nWriting \u2013 original draft: Valentin Rousson.\nWriting \u2013 review & editing: Bastien Tra\u0308chsel, Katia Iglesias, Ste\u0301phanie Baggio."
        }
    ],
    "title": "Evaluating the cost of simplicity in score building: An example from alcohol research",
    "year": 2023
}