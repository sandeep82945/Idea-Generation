{
    "abstractText": "Tour itinerary planning and recommendation are challenging problems for tourists visiting unfamiliar cities. Many tour recommendation algorithms only consider factors such as the location and popularity of Points of Interest (POIs) but their solutions may not align well with the user\u2019s own preferences and other location constraints. Additionally, these solutions do not take into consideration of the users\u2019 preference based on their past POIs selection. In this paper, we propose POIBERT, an algorithm for recommending personalized itineraries using the BERT language model on POIs. POIBERT builds upon the highly successful BERT language model with the novel adaptation of a language model to our itinerary recommendation task, alongside an iterative approach to generate consecutive POIs. Our recommendation algorithm is able to generate a sequence of POIs that optimizes time and users\u2019 preference in POI categories based on past trajectories from similar tourists. Our tour recommendation algorithm is modeled by adapting the itinerary recommendation problem to the sentence completion problem in natural language processing (NLP). We also innovate an iterative algorithm to generate travel itineraries that satisfies the time constraints which is most likely from past trajectories. Using a Flickr dataset of seven cities, experimental results show that our algorithm out-performs many sequence prediction algorithms based on measures in recall, precision and F1-scores.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ngai Lam"
        },
        {
            "affiliations": [],
            "name": "Kwan Hui Lim"
        }
    ],
    "id": "SP:da54bdba748fbbf1a614a55cba7060a99ee0da66",
    "references": [
        {
            "authors": [
                "I.R. Brilhante",
                "J.A. Macedo",
                "F.M. Nardini",
                "R. Perego",
                "C. Renso"
            ],
            "title": "On planning sightseeing tours with TripBuilder",
            "venue": "Information Processing & Management, vol. 51, no. 2, pp. 1\u201315, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "D. Chen",
                "C.S. Ong",
                "L. Xie"
            ],
            "title": "Learning points and routes to recommend trajectories",
            "venue": "Proceedings of the 25th ACM CIKM\u201916, 2016, pp. 2227\u20132232.",
            "year": 2016
        },
        {
            "authors": [
                "A. Gionis",
                "T. Lappas",
                "K. Pelechrinis",
                "E. Terzi"
            ],
            "title": "Customized tour recommendations in urban areas",
            "venue": "Proceedings of WSDM\u201914, 2014, pp. 313\u2013322.",
            "year": 2014
        },
        {
            "authors": [
                "K.H. Lim",
                "J. Chan",
                "S. Karunasekera",
                "C. Leckie"
            ],
            "title": "Tour recommendation and trip planning using location-based social media: a survey",
            "venue": "Knowledge and Information Systems, pp. 1\u201329, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J. He",
                "X. Li",
                "L. Liao"
            ],
            "title": "Category-aware next point-of-interest recommendation via listwise bayesian personalized ranking",
            "venue": "Proceedings of the 26th International Joint Conference on Artificial Intelligence, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "A. Vaswani",
                "N. Shazeer",
                "N. Parmar",
                "J. Uszkoreit",
                "L. Jones",
                "A.N. Gomez",
                "L. u. Kaiser",
                "I. Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "Advances in Neural Information Processing Systems, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, Eds., vol. 30. Curran Associates, Inc., 2017.",
            "year": 2017
        },
        {
            "authors": [
                "K.H. Lim"
            ],
            "title": "Recommending tours and places-of-interest based on user interests from geo-tagged photos",
            "venue": "Proceedings of the 2015 ACM SIGMOD on PhD Symposium, ser. SIGMOD \u201915 PhD Symposium. New York, NY, USA: Association for Computing Machinery, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "S. Wang",
                "L. Hu",
                "Y. Wang",
                "L. Cao",
                "Q.Z. Sheng",
                "M. Orgun"
            ],
            "title": "Sequential recommender systems: Challenges, progress and prospects",
            "venue": "Proceedings of the International Joint Conferences on Artificial Intelligence (IJCAI-19)."
        },
        {
            "authors": [
                "P. Fournier-Viger",
                "A. Gomariz",
                "T. Gueniche",
                "A. Soltani",
                "C. Wu.",
                "V.S. Tseng"
            ],
            "title": "SPMF: a Java Open-Source Pattern Mining Library",
            "venue": "Journal of Machine Learning Research (JMLR), vol. 15, pp. 3389\u20133393, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "P. Zhao",
                "A. Luo",
                "Y. Liu",
                "F. Zhuang",
                "J. Xu",
                "Z. Li",
                "V.S. Sheng",
                "X. Zhou"
            ],
            "title": "Where to go next: A spatio-temporal gated network for next poi recommendation",
            "venue": "IEEE TKDE, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Sohrabi",
                "K. Ziarati",
                "M. Keshtkaran"
            ],
            "title": "A greedy randomized adaptive search procedure for the orienteering problem with hotel selection",
            "venue": "European Journal of Operational Research, vol. 283, no. 2, pp. 426\u2013440, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "M. De Choudhury",
                "M. Feldman",
                "S. Amer-Yahia",
                "N. Golbandi",
                "R. Lempel",
                "C. Yu"
            ],
            "title": "Automatic construction of travel itineraries using social breadcrumbs",
            "venue": "Proceedings of the 21st ACM Conference on Hypertext and Hypermedia, 2010, pp. 35\u201344.",
            "year": 2010
        },
        {
            "authors": [
                "D.C. Munmun",
                "F. Moran",
                "A.-Y. Sihem",
                "G. Nadav",
                "L. Ronny",
                "Y. Cong"
            ],
            "title": "Munmun de choudhury and moran feldman and sihem amer-yahia and nadav golbandi and ronny lempel and cong yu",
            "venue": "Proceedings of the 19th international conference on World wide web, 2010, pp. 1083\u20131084.",
            "year": 2010
        },
        {
            "authors": [
                "S. Halder",
                "K.H. Lim",
                "J. Chan",
                "X. Zhang"
            ],
            "title": "Poi recommendation with queuing time and user interest awareness",
            "venue": "Data Mining and Knowledge Discovery, pp. 1\u201331, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "K.H. Lim",
                "J. Chan",
                "C. Leckie",
                "S. Karunasekera"
            ],
            "title": "Personalized trip recommendation for tourists based on user interests, points of interest visit durations and visit recency",
            "venue": "Knowledge and Information Systems, vol. 54, no. 2, pp. 375\u2013406, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "G. Cai",
                "K. Lee",
                "I. Lee"
            ],
            "title": "Itinerary recommender system with semantic trajectory pattern mining from geo-tagged photos",
            "venue": "Expert Systems with Applications, vol. 94, pp. 32\u201340, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "T. Kurashima",
                "T. Iwata",
                "G. Irie",
                "K. Fujimura"
            ],
            "title": "Travel route recommendation using geotagged photos",
            "venue": "Knowledge and information systems, vol. 37, no. 1, pp. 37\u201360, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "C.-Y. Sun",
                "A.J. Lee"
            ],
            "title": "Tour recommendations by mining photo sharing social media",
            "venue": "Decision Support Systems, vol. 101, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "G. Cai",
                "K. Lee",
                "I. Lee"
            ],
            "title": "Itinerary recommender system with semantic trajectory pattern mining from geo-tagged photos",
            "venue": "Expert Systems with Applications, vol. 94, pp. 32\u201340, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "S. Halder",
                "K.H. Lim",
                "J. Chan",
                "X. Zhang"
            ],
            "title": "Efficient itinerary recommendation via personalized poi selection and pruning",
            "venue": "Knowledge and Information Systems, vol. 64, no. 4, pp. 963\u2013993, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "M. Roondiwala",
                "H. Patel",
                "S. Varma"
            ],
            "title": "Predicting stock prices using lstm",
            "venue": "Science and Research (IJSR), pp. 1754 \u2013 1756, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "A.V.K"
            ],
            "title": "Word2vec. in: Pro machine learning algorithms",
            "venue": "CoRR, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "P. Bojanowski",
                "E. Grave",
                "A. Joulin",
                "T. Mikolov"
            ],
            "title": "Enriching word vectors with subword information",
            "venue": "Transactions of the Association for Computational Linguistics, vol. 5, pp. 135\u2013146, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "J. Pennington",
                "R. Socher",
                "C.D. Manning"
            ],
            "title": "Glove: Global vectors for word representation",
            "venue": "Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), 2014, pp. 1532\u20131543.",
            "year": 2014
        },
        {
            "authors": [
                "N.L. Ho",
                "K.H. Lim"
            ],
            "title": "User preferential tour recommendation based on poi-embedding methods",
            "venue": "26th International Conference on Intelligent User Interfaces - Companion, ser. IUI \u201921 Companion. New York, NY, USA: Association for Computing Machinery, 2021, p. 46\u201348.",
            "year": 2021
        },
        {
            "authors": [
                "J. Liu",
                "K.L. Wood",
                "K.H. Lim"
            ],
            "title": "Strategic and Crowd-Aware Itinerary Recommendation",
            "venue": "Proceedings of the 2020 ECML- PKDD\u201920, Sep 2020.",
            "year": 2020
        },
        {
            "authors": [
                "K. Lim",
                "X. Wang",
                "J. Chan",
                "S. Karunasekera",
                "C. Leckie",
                "Y. Chen",
                "C.L. Tan",
                "F.Q. Gao",
                "T.K. Wee"
            ],
            "title": "Perstour: A personalized tour recommendation and planning system",
            "venue": "HT, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "S. Hochreiter",
                "J. Schmidhuber"
            ],
            "title": "Long short-term memory",
            "venue": "Neural Computation, vol. 9, no. 8, pp. 1735\u20131780, Nov 1997.",
            "year": 1997
        },
        {
            "authors": [
                "F.A. Gers",
                "J. Schmidhuber",
                "F. Cummins"
            ],
            "title": "Learning to forget: Continual prediction with lstm",
            "venue": "Neural Computation, vol. 12, no. 10, pp. 2451\u20132471, 2000.",
            "year": 2000
        },
        {
            "authors": [
                "K. Cho",
                "B. van Merri\u00ebnboer",
                "D. Bahdanau",
                "Y. Bengio"
            ],
            "title": "On the properties of neural machine translation: Encoder\u2013decoder approaches",
            "venue": "Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation. Doha, Qatar: Association for Computational Linguistics, Oct. 2014, pp. 103\u2013111.",
            "year": 2014
        },
        {
            "authors": [
                "I. Sutskever",
                "O. Vinyals",
                "Q.V. Le"
            ],
            "title": "Sequence to sequence learning with neural networks",
            "venue": "Advances in neural information processing systems, 2014, pp. 3104\u20133112.",
            "year": 2014
        },
        {
            "authors": [
                "H X."
            ],
            "title": "Pre-trained models: Past, present and future",
            "venue": "AI Open, vol. 2, pp. 225\u2013250, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "K. Potdar",
                "T.S. Pardawala",
                "C.D. Pai"
            ],
            "title": "A comparative study of categorical variable encoding techniques for neural network classifiers",
            "venue": "International Journal of Computer Applications, vol. 175, no. 4, pp. 7\u20139, Oct 2017.",
            "year": 2017
        },
        {
            "authors": [
                "E. Loginova",
                "S. Varanasi",
                "G. Neumann"
            ],
            "title": "Towards end-to-end multilingual question answering",
            "venue": "Information Systems Frontiers, vol. 23, pp. 227\u2013241, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "L. Wasserman"
            ],
            "title": "All of statistics : a concise course in statistical inference",
            "venue": "New York: Springer,",
            "year": 2010
        },
        {
            "authors": [
                "T. Gueniche",
                "P. Fournier-Viger",
                "V.S. Tseng"
            ],
            "title": "Compact prediction tree: A lossless model for accurate sequence prediction",
            "venue": "Advanced Data Mining and Applications, H. Motoda, Z. Wu, L. Cao, O. Zaiane, M. Yao, and W. Wang, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2013, pp. 177\u2013188.",
            "year": 2013
        },
        {
            "authors": [
                "T. Gueniche",
                "P. Fournier-Viger",
                "R. Raman",
                "V.S. Tseng"
            ],
            "title": "Cpt+: Decreasing the time/space complexity of the compact prediction tree",
            "venue": "Advances in Knowledge Discovery and Data Mining, T. Cao, E.-P. Lim, Z.-H. Zhou, T.-B. Ho, D. Cheung, and H. Motoda, Eds. Cham: Springer International Publishing, 2015, pp. 625\u2013636.",
            "year": 2015
        },
        {
            "authors": [
                "V.N. Padmanabhan",
                "J.C. Mogul"
            ],
            "title": "Using predictive prefetching to improve world wide web latency",
            "venue": "COMPUTER COMMUNICATION REVIEW, vol. 26, pp. 22\u201336, 1996.",
            "year": 1996
        },
        {
            "authors": [
                "J. Cleary",
                "I. Witten"
            ],
            "title": "Data compression using adaptive coding and partial string matching",
            "venue": "IEEE Transactions on Communications, vol. 32, no. 4, pp. 396\u2013402, 1984.",
            "year": 1984
        },
        {
            "authors": [
                "Pitkow",
                "P. Pirolli"
            ],
            "title": "Mining longest repeated subsequences to predict world wide web surfing",
            "venue": "2nd USENIX Symposium on Internet Technologies & Systems. Boulder, CO: USENIX Association, Oct. 1999.",
            "year": 1999
        },
        {
            "authors": [
                "R. Ktistakis",
                "P. Fournier-Viger",
                "S.J. Puglisi",
                "R. Raman"
            ],
            "title": "Succinct bwt-based sequence prediction",
            "venue": "Database and Expert Systems Applications, S. Hartmann, J. K\u00fcng, S. Chakravarthy, G. Anderst-Kotsis, A. M. Tjoa, and I. Khalil, Eds. Cham: Springer International Publishing, 2019, pp. 91\u2013101.",
            "year": 2019
        },
        {
            "authors": [
                "T. Wolf",
                "L. Debut",
                "V. Sanh",
                "J. Chaumond",
                "C. Delangue",
                "A. Moi",
                "P. Cistac",
                "T. Rault",
                "R. Louf",
                "M. Funtowicz",
                "J. Brew"
            ],
            "title": "Huggingface\u2019s transformers: State-of-the-art natural language processing",
            "venue": "CoRR, vol. abs/1910.03771, 2019.",
            "year": 1910
        }
    ],
    "sections": [
        {
            "text": "Our recommendation algorithm is able to generate a sequence of POIs that optimizes time and users\u2019 preference in POI categories based on past trajectories from similar tourists. Our tour recommendation algorithm is modeled by adapting the itinerary recommendation problem to the sentence completion problem in natural language processing (NLP). We also innovate an iterative algorithm to generate travel itineraries that satisfies the time constraints which is most likely from past trajectories. Using a Flickr dataset of seven cities, experimental results show that our algorithm out-performs many sequence prediction algorithms based on measures in recall, precision and F1-scores.\nIndex Terms\u2014Recommendation Systems, Personalisation, Neural Networks, Word Embedding, LSTM, BERT, Self-Attention, Transformer\nI. INTRODUCTION\nTour recommendation and planning are challenging problems faced by many tourists, due to the constraints in time and locality; additionally they may not be familiar with the city or country [1]\u2013[3]. Most visitors usually follow guide books/websites to plan their daily itineraries or use recommendation systems that suggest places-of-interest (POIs) based on popularity [4]. However, these are not optimized in terms of time feasibility, localities and users\u2019 preferences [4], [5].\nIn recent years, the Transformer model has become the state-of-the-art solution for many NLP tasks. Compared to other architectures, such as Recurrent Neural Network (RNN) and LSTM, a Transformer-based model processes the entire input data all at once. Additionally the attention mechanism provides the context for any position in the input sequence, allowing more parallelism with good performance quality; hence less time is required for training and optimization are needed [6].\nIn this paper, we propose POIBERT, a Transformer-word embedding model to recommend POIs as a sequence of itinerary based on historical data with consideration of the locations, and also traveling time between these POIs. Figure 1 shows the overall workflow of itinerary prediction of the POIBERT model.\nWe compare our proposed methods with other sequence prediction algorithms and conclude that our algorithms can achieve an average of F1-scores of up to 59.2% accuracy in our experiments. In this paper, we make the following contributions:\n\u2022 We model our Tour Recommendation problem as a sequential recommendation problem in reinforcement learning: to recommend the subsequent POIs (items) in a user\u2019s travel schedule, given a set of trajectories in the form of user \u2212 POI tuples (item) of interactions(checkin records) [8]. The solution of this problem is a reinforcement learning algorithm that is flexible in different environments (i.e. cities.) \u2022 We propose two approaches to solving the tour recommendation problem, namely: (1) POILSTM - A Long Short-Term Memory framework, and, (2) POIBERT - a Transformer-based mechanism. These two models take users\u2019 trajectories as inputs and process as a long sequence of user-item interaction for our recommendation algorithms. \u2022 We use the Bootstrapping method in statistics to estimate the duration of visits with confidence intervals using a method of random sampling. More accurate estimation (with confidence intervals) of POI duration also results in a realistic and compact scheduling of itineraries. \u2022 We have conducted thorough experiments on our proposed solutions against state-of-art solutions in sequence prediction and classic algorithms (SPMF Data Mining Library [9].) Experimentation results show that our solution out-performs other baseline algorithms. \u2022 Additionally, our proposed solution has the advantage of adapting to different scenario (cities/datasets) without modification. In particular, we recorded a performance increase, as much as 19.9% in our Delhi dataset, measured in terms of average F1-scores.\nThe remaining of this paper is organized as follows: In Section II we give a background to the Tour Recommendation978-1-6654-8045-1/22/$31.00 \u00a92022 IEEE\nar X\niv :2\n21 2.\n13 90\n0v 1\n[ cs\n.I R\n] 1\n6 D\nec 2\n02 2\nand discuss the state-of-the-art to the itinerary prediction problem. In Section III we formally define the problem and notations to our solution. In Section IV we describe our experiment framework and other baseline algorithms we used for solution evaluation. Finally, we summarize the paper with further work of extension in Section V."
        },
        {
            "heading": "II. RELATED WORK",
            "text": ""
        },
        {
            "heading": "A. Tour Recommendation",
            "text": "Tour planning is an essential, but tedious task for tourists visiting an unfamiliar city. Many visitors often get recommendation from guide books or websites to plan their daily itineraries; this will be time-consuming and sub-optimal. Next POI prediction [5], [10] and tour planning [4], [11] are two related problems: Next-location prediction and recommendation aim to identify the next POI that is most likely to visited based on historical trajectories.\nPersonalized tour recommendation has been proposed with the use of photos and their meta-information such as timestamps and GPS-locations provided by Location-based Social Networks (LBSN). Tour itinerary can be generated based on user interests from his/her visit history. Previous works focus\non recommending popular POIs in terms of posted photos with geo-tags [7], [12]\u2013[14]. Other works utilized geo-tagged photos posted in LBSN to determine POI related information for making various types of tour recommendation [15]\u2013[20].\nFurthermore, tour itinerary recommendation has the challenges of planning a connected itinerary of POIs that appeal to the users\u2019 interest preferences, without users taking unnecessary routes and spending extra time/distance. At the same time, there is a need to satisfy tourists\u2019 temporal and spatial constraints such as limited time and budget."
        },
        {
            "heading": "B. Sequence Prediction",
            "text": "Sequence prediction is a well-studied machine learning task; this task involves predicting the next symbol(s) or word based on the previously observed sequence of symbols. Sequence prediction can be applied to solve the tour recommendation problem, by treating POIs as words as inputs.\nSequence Prediction is widely used in the areas of timeseries forecasting and product recommendation. It is different from other prediction algorithms; the order of sequence is important to get an accurate result, examples include predicting stock prices [21]. Existing solutions to Sequence Prediction include word-embedding by considering POI-to-\nPOI similarity using techniques such as Word2Vec, GloVe and FastText [22]\u2013[25]. Many recommendation systems for planning tours consider broad POI categories but some of their recommendations do not align well with travelers\u2019 preferences together with locational constraints in their trips. Some recommendation system dynamically propose routes by taking into consideration all possible solutions generated by different agents system [26].\nPersonalized recommendation of tour planning is proposed by using the technique of POI-embedding methods providing a finer representation of POI categories [27]. Recently, advances in Machine Learning (ML) and Artificial Intelligence (AI) algorithms allow for more advanced representation of sequential data, particularly in the area of Natural Language Processing.\nC. LSTM models\nFirst proposed in 1994, the Long Short-Term Memory is an RNN with long-term dependencies in the input sequences [28]. A LSTM network consists of memory blocks, or cells, which are capable of storing information known as states. During the training phase of LSTM, two states are transferred to (or from, respectively) the next (prior, respectively) cell, known as the cell state and the hidden state. The memory blocks of LSTM are used as the memory and the flow and termination of information is done through three gates:\n1) Input Gate: it is responsible for the addition of information to the cell state. The gate applies the sigmoid function to the input state determine information to be added to the cell state. 2) Forge Gate: this gate determines a subset of information to be removed from the cell state; information that is less importance is removed by applying a filter function [29]. 3) Output Gate: The Output gate organizes the information for the output to other LSTM cells. The basic implementation of LSTM applies the tanh function cell state and the sigmoid for filtering of information. The output of this gate is subsequently fed as the input gate of the next state.\nThe input layer of the LSTM network takes in as input a vector of a fixed length and output a vector of fixed length. In an extension of LSTM, the Encoder-Decoder LSTM has two more additional components then the basic LSTM network: the encoder and decoder. The encoder of the model extracts a fixed-length vector representation from a variablelength input sentence. Experiments suggest that the encoderdecoder LSTM model performs well on short sentences without unknown words. The performance of the LSTM method was shown to degrade as with input text size [30], [31]."
        },
        {
            "heading": "D. Transformer models",
            "text": "Transformer is a learning model designed to process sequential input data. It adopts the mechanism of self-attention having use primarily in NLP and Computer Vision [6]. Bidirectional Encoder Representations from Transformers (BERT) is a transformer-based machine learning technique, developed by Google [32] for language translation. BERT models have\nbecome the state-of-art baseline in NLP experiments. BERT is trained using 1) Masked-Language Modeling (MLM), and, 2) Next Sentence Prediction (NSP) with more application other than its original language tasks. Moreover, BERT is shown to achieve high accuracy in Classification tasks such as sentiment analysis [33]."
        },
        {
            "heading": "III. PROBLEM FORMULATION AND ALGORITHMS",
            "text": "In this section, we start with the definition of tour recommendation problem and a list of notations used in Table I. Given a set of travelers, Sh, visiting a city with |P | pointsof-interest, we denote a traveler, u \u2208 U , in a sequence of (poi, time) tuples, Sh = [(p1, t1), (p2, t2)... (pk, tk)], where k is the number of check-in or photos posted to LBSN, for all pi \u2208 POIs and ti as the timestamps of the photos taken. Given also, a starting POI-s0 \u2208 POIs together with all the photos taken at s0, the problem in this paper is to recommend a sequence of POIs in which travelers are likely to visit based on the past trajectories from a dataset collected, using the Transformer model.\nWe first propose \u201cPOILSTM\u201d, an LSTM model that encodes users\u2019 trajectories with consideration of the travelers\u2019 locations and distances traveled to recommend a tour itinerary with estimated duration. We also propose \u201cPOIBERT\u201d, an algorithm for prediction of itinerary based on the MLM algorithm in BERT, discussed in Section III-B.\nA. POILSTM- Itinerary Prediction Algorithm using LSTM\nWe model the itinerary prediction problem as a prediction in an Encoder-Decoder LSTM. Each input vector to the POILSTM network represents a vector representing of user\u2019s visit from a POI transiting to the next POI (with embedded details, such as time and distance traveled). During the training phase of POILSTM, each POI in a trajectory is passed to the input layer of the LSTM network as an encoded vector, one at a time using the encoder function. This process is repeated for all POIs in all trajectories in the training dataset,\ndiscussed in Figure 1. When the LSTM network is trained sufficiently for a number of steps (epochs), the output of the LSTM network is a prediction of the next POI (as one-hot embedding) and its estimated duration (in hours) in floating point format.) POI itinerary can be predicted by repeatedly decoding the output of POILSTM, by passing in the previous output information of trajectory iteratively as an encoded vector.\nThe function time(i, j) returns the time spent from vi to vj and dist(i, j) returns the distance the user(u) traveled from step-i through step-j. Additionally, putk\u22122 , p u tk\u22121\nand putk are represented as onehot embedding [34].\nAlgorithm 1 Prediction model in POILSTM Require: vu, T imeLimit : time budget\n1: Set Activation Function: Softmax 2: Set Optimizer: RMSprop 3: Let i = 1, T = 0, seq = {} 4: SubFunction: LSTM encode seq(vutk) = 5: time(k \u2212 1, k)\u2295 time(1, k) \u2295 6: dist(k \u2212 1, k) \u2295 dist(1, k) \u2295 7: putk\u22122 \u2295 p u tk\u22121 \u2295 putk 8: repeat 9: x\n(t) i \u2190 LSTM encode seq(vpu=pi)1\n10: compute a(t) and h(t) 11: compute o(t) 12: Let (pi, ti)\u2190 decode(o(t)) 13: seq \u2190 seq \u2295 pi 14: T \u2190 T + ti 15: i\u2190 i+ 1 16: until T \u2265 TimeLimit 17: return seq\nB. POIBERT - a BERT model for POI Itinerary Prediction\nGenerally, a BERT model uses a self-attention mechanism that is able to learn the general trend of a language; the trained model can then be used for downstream tasks, such as language translation and question answering [35]. When used in practice, a pre-trained BERT model can significantly improve the results in prediction based on a number of benchmarks. To perform an itinerary prediction in our POIBERT model, we pass in a set of sentences consisting of POIs and relevant information to predict the next POI which is most likely to occur using the MLM prediction model.\na) Training of POIBERT Model: We propose a novel POIBERT Model in the space of POIs and users\u2019 itineraries. The original implementation of BERT train MLM by masking 15% of words. The POIBERT prediction algorithm is to predict the masked POI (word), based on the context provided by other words (representing POIs or POI categories) without masks. We use Algorithm 2 to translate users\u2019 trajectories into sentences of POIs(words) which are subsequently trained by the POIBERT model for the itinerary prediction task.\nFigure 2 outlines a function to transform users\u2019 trajectories to sentences of words representing POIs or categories of POIs for POIBERT training. The time complexity of the function is O(NK2), where N is the total number of POIs in the dataset and K represents the maximum number of POIs in any trajectory.\nAlgorithm 2 Training Data Generation for POIBERT Require: tryju,\u2200u \u2208 Users\n1: for all u \u2208 users do 2: for all tryj seq \u2208 tryju do 3: Let n\u2190 |tryj seq| 4: Let {p1..pn} \u2190 poi id(tryj seq) 5: Let {c1..cn} \u2190 theme(tryj seq) 6: // where the functions poi id(...) and theme(...) 7: // return POI id (and theme, resp.) projections. 8: Output: \u22001 \u2264 i < j \u2264 n, 9: \u201c{ci, pi, .., pj\u22121, cj\u22121} \u2192 pj\u201d\n10: end for 11: end for\nb) Itinerary Prediction: Given an initial POI, p1, and the ending POI, pk from traveler\u2019s specification, we propose an algorithm to predict a sequence of POIs which travelers are most likely to visit as ordered list, based of historical trajectories recorded in the dataset. The POIBERT algorithm is inspired by the MLM training process of BERT, where the prediction algorithm identifies the masked words based on the context of a sentence. As outlined in Algorithm 3, the algorithm searches for the next relevant POI between the initial POI and destination POI, and insert it to the predicted itinerary.\nAlgorithm 3 Itinerary Prediction Algorithm in POIBERT Require: p1, pk: starting/ending POIs\nTimeLimit: time budget of itinerary 1: Let seq \u2190 {p1, pk} 2: repeat 3: forall j \u2208 {2..|seq| \u2212 1} 4: Let queryj \u2190 {p1, c1, pj\u22121, cj\u22121,[MASK], pj , cj , ..., pk, ck} 5: seq \u2190 ArgMaxj\u2208{2..|seq|\u22121}(Unmask(queryj)) 6: until\n\u2211 poi\u2208seq duration(poi) \u2265 TimeLimit\n7: return seq"
        },
        {
            "heading": "C. Estimation of duration of visits",
            "text": "Getting a realistic estimate of duration of visits to our predicted POIs are crucial in our solution. Any over-estimation (or under-estimation) of duration to the predicted POIs will affect the time-sensitive trajectories output from the algorithm, hence affecting the recall- and precision-scores. In this section, we estimate the duration of visits using a statistical method: bootstrapping by calculating the confidence-interval of duration in the trajectories [36]. Due to the high variance in\nFlickr Dataset\nduration of visit to the POIs, it is not practical to estimate the duration by merely taking the averages of all visitors\u2019 duration to the POIs.\nWe note that Bootstrapping does not assume the input data to follow any statistic distribution. It treats the original samples as the real population and draws random samples from the data. Then, bootstrapping creates more samples so one can make a better estimation of population by the procedure of sub-sampling randomly with replacement. This method is used to estimate the duration of visits at the POIs given that there are less samples visiting to some POIs that are less popular. Algorithm 4 outlines the steps of getting the 90% confidence intervals of duration of visit to a POI-i, \u2200i \u2208 POIs."
        },
        {
            "heading": "IV. EXPERIMENTS AND RESULTS",
            "text": "We use a dataset of photos uploaded to the Flickr platform, which consists of trajectories of 5,654 users from 7 different cities, tagged with meta-information, such as the date and GPS location. Using this data-set, one can construct the travel trajectories by sorting the photos by time, mapping the photos to the POIs as identified by the GPS location, resulting in the users\u2019 trajectories as a sequence of time sensitive POI-IDs."
        },
        {
            "heading": "A. Datasets",
            "text": "We use the Flickr datasets prepared for our evaluation of algorithms [27]. In total, there are close to 120K photos, or\nAlgorithm 4 Estimate Duration of Visit to POI Require: poi id \u2208 POIs Require: confidence level \u03b1 Require: number of replicates B Require: Tryju,\u2200u \u2208 Users\n1: SubFunc. getSamples(poi id): 2: for all u \u2208 users do 3: for all tryj seq \u2208 tryju do 4: for all p \u2208 tryj seq do 5: Output activities if p == poi id 6: end for 7: end for 8: end for 9:\n10: Let X \u2190 getSamples(poi id) 11: Sample x\u22171, x\u22172, ..x\u2217n with replacement from sample X .\nRepeat B iterations2. 12: Let F \u2217 be the empirical distribution 13: Calculate (100\u2212 \u03b1)% confidence intervals for F \u2217\ncheck-in records, from 4701 users in seven popular cities. Table II describes more details about each dataset and information about the trajectories of these cities.\na) Training and Test Set: Our data-sets are split into Training and Testing data-sets. Firstly, we organize photos by the Trajectory-IDs, then these trajectories are sorted according to their last check-in times (in ascending order). To obtain the Training dataset, the first 80% of Trajectories (based on their photos) are set aside as Training Data. The remaining data is used as the Testing Data. This segregation of Training and Test data avoids the problem of having a trajectory covering over both Training and Testing Data sets."
        },
        {
            "heading": "B. Performance of Algorithms",
            "text": "Experiments were conducted for each city in the dataset. We regard all users\u2019 trajectories (with at least 3 POIs) in the training set as sequences of POI (corpus). To compare the performance of our models, we trained different sequence prediction models using different hyper-parameters. We then used the Test set to evaluate the accuracy of the trained models: for each of the trajectory in the testing set (known as history-list), we treat the first (and last, respective) POI as the source (and destination, respectively) POI and try to predict the intermediate POIs of the trajectory, given in a time boxed event of history-list. We evaluated the effectiveness of POIBERT and POILSTM prediction algorithms in terms of F1, precision (Tp) and recall (Tr) scores of the predicted POIs against the actual trajectories, as below: Let Sp be the predicted sequence of POIs from the algorithm and Sh be the actual sequence from the trajectories, we evaluate our algorithms based on: \u2022 Tr(Sh, Sp) =\n|Sh\u2229Sp| |Sp|\n\u2022 Tp(Sh, Sp) = |Sh\u2229Sp| |Sh| \u2022 F1 score(Sh, Sp) = 2Tr(\u2022)Tp(\u2022) Tr(\u2022)+Tp(\u2022)"
        },
        {
            "heading": "C. Baseline Algorithms",
            "text": "Our proposed models are compared with other sequence prediction algorithms as baseline algorithms: \u2022 SPMF algorithms - this package consists of data mining\nalgorithms including: CPT [37], CPT+ [38], TDAG [39], First-order and All-k-Order Markov Chains [40], [41]. Our experiments predict an itinerary by repeatedly asking for the next token (represented as the next POI to visit) when time limit is not exhausted. \u2022 SUBSEQ : the algorithm uses a Succinct Wavelet Tree structure to maintain a list of training sequences for sequence prediction [42]. \u2022 SEQ2SEQ : this model adopts a multilayered LSTM to map the input sequence to a vector with a fixed size or dimension [31]. The prediction is facilitated by another deep LSTM to decode the target sequence. The default prediction model of SEQ2SEQ is to output a sentence of words which may consist of duplicated words. We modified the prediction model to return a series of unique POIs instead.\nSome baseline algorithms only predict one token or POI, we iteratively predict more tokens until the time limit of the itinerary is reached. For the propose of algorithms evaluation,\nall experimentation of baseline algorithms are conducted in the same setting as in Section IV-B, sharing the same training and testing data."
        },
        {
            "heading": "D. Experimental Results",
            "text": "We evaluated the effectiveness of our proposed algorithms on different cities. We constructed the travel histories by chronologically sorting the photos, which resulted in the users\u2019 trajectories. These trajectories are then regarded as sentences for inputs to our proposed training models with different hyper-parameters. Results are summarized by comparing the accuracy of the predicted itineraries (i.e. Recall / Precision / F1 scores,) as shown in Table III.\nIn Table IV, we also compare the performance of POIBERT and POIBERT against 8 baseline algorithms. Overall, experimental results show that our POILSTM and POIBERT itinerary prediction algorithms achieve significant accuracy in itinerary prediction tasks; the proposed POIBERT prediction algorithm is scale-able and adaptable in parallel environment. Our experiments also show that the POIBERTprediction algorithm achieves F1 scores of at least 47% accuracy across all cities and different parameter settings. In particular, we recorded an average of 74.8% in our Osaka dataset; experiments in Delhi also show an increase of 19.99% (from 58.238% up to 69.848%) in F1 score.\nIn Table V, we compare the number of POIs in users\u2019 trajectories and their predicted itineraries by POIBERT. POIBERT is able to recommend more relevant, and compact trajectories relative to the actual trajectories, while not compromising the quality of the recommendation model."
        },
        {
            "heading": "V. CONCLUSION",
            "text": "In this paper, we study the problem of tour itinerary recommendation to identify users\u2019 preference on POIs and make the appropriate recommendation of itineraries with time constraints. To solve this problem, we propose POIBERT that builds upon the highly successful BERT model with the novel adaptation of a language model to this itinerary recommendation task, along with an iterative approach to generating POIs. Our iterative POIBERT prediction algorithm can reliably uncover a user\u2019s preference in a tour by only using a pair of initial and destination POIs. Our experiments show the effectiveness of our proposed algorithm for predicting relevant POIs in terms of F1-scores. In our experiments on 7 cities, our POIBERT algorithm outperforms 8 baseline algorithms measured in averaged F1-scores. Future works include further adaptation and more in-depth evaluation of other language models for this itinerary recommendation task and creating a HuggingFace interface module for POIBERT [43]."
        },
        {
            "heading": "ACKNOWLEDGMENT",
            "text": "This research is funded in part by the Singapore University of Technology and Design under grant SRG-ISTD-2018-140. The computational work was partially performed on resources of the National Super-Computing Centre, Singapore."
        }
    ],
    "title": "POIBERT: A Transformer-based Model for the Tour Recommendation Problem",
    "year": 2022
}