{
    "abstractText": "Accelerator performance often deteriorates with time during a long period of operation due to secular changes in the machine components or the surrounding environment. In many cases, some tuning knobs are effective in compensating the performance drifts and optimization methods can be used to find the ideal machine setting. However, such intervention usually cannot be done without interrupting user operation as the optimization algorithms can substantially impact the machine\u2019s performance. We propose an optimization algorithm, Safe Robust Conjugate Direction Search, which can perform accelerator tuning while keeping the machine performance within a designated safe envelope. The algorithm builds probability models of the objective function using Lipschitz continuity of the function as well as characteristics of the drifts and applies to the selection of trial solutions to ensure the machine operates safely during tuning. The algorithm can run during normal user operation constantly, or periodically, to compensate for the performance drifts. Simulation and online tests have been done to validate the performance of the algorithm.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zhe Zhang"
        },
        {
            "affiliations": [],
            "name": "Minghao Song"
        },
        {
            "affiliations": [],
            "name": "Xiaobiao Huang"
        }
    ],
    "id": "SP:78d36dea28c958250fd824cbbbc53acba310fcc1",
    "references": [
        {
            "authors": [
                "J.A. Nelder",
                "R. Mead"
            ],
            "title": "A simplex method for function minimization, Comput",
            "venue": "J 7,",
            "year": 1965
        },
        {
            "authors": [
                "X. Huang",
                "J. Corbett",
                "J. Safranek",
                "J. Wu"
            ],
            "title": "An algorithm for online optimization of accelerators",
            "venue": "Nucl. Instrum. Methods Phys. Res., Sect. A 726,",
            "year": 2013
        },
        {
            "authors": [
                "J. Kennedy",
                "R. Eberhart"
            ],
            "title": "Particle swarm optimization, in Proceedings of ICNN\u201995\u2014International Conference on Neural Networks, Perth, WA, Australia",
            "venue": "(IEEE, New York,",
            "year": 1995
        },
        {
            "authors": [
                "J. Duris",
                "D. Kennedy",
                "A. Hanuka",
                "J. Shtalenkova",
                "A. Edelen",
                "P. Baxevanis",
                "A. Egger",
                "T. Cope",
                "M. McIntire",
                "S. Ermon",
                "D. Ratner"
            ],
            "title": "Bayesian Optimization of a Free-Electron Laser",
            "venue": "Phys. Rev. Lett. 124,",
            "year": 2020
        },
        {
            "authors": [
                "Y. Sui",
                "A. Gotovos",
                "J. Burdick",
                "A. Krause"
            ],
            "title": "Safe exploration for optimization with Gaussian processes",
            "venue": "Proceedings of the 32nd International Conference on Machine Learning,",
            "year": 2015
        },
        {
            "authors": [
                "J. Kirschner",
                "M. Mutny",
                "N. Hiller",
                "R. Ischebeck",
                "A. Krause"
            ],
            "title": "Adaptive and safe Bayesian optimization in high dimensions via one-dimensional subspaces",
            "venue": "Proceedings of the 36th International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "M.J.D. Powell"
            ],
            "title": "An efficient method for finding the minimum of a function of several variables without calculating derivatives, Comput",
            "venue": "J. 7,",
            "year": 1964
        },
        {
            "authors": [
                "W.H. Press",
                "S.A. Teukolsky",
                "W.T. Vetterling",
                "B.P. Flannery"
            ],
            "title": "Numerical Recipes: The Art of Scientific Computing, 3rd ed",
            "venue": "MINGHAO SONG, and XIAOBIAO HUANG PHYS. REV. ACCEL. BEAMS",
            "year": 2007
        }
    ],
    "sections": [
        {
            "text": "Optimization method to compensate accelerator performance drifts\nZhe Zhang , Minghao Song ,* and Xiaobiao Huang \u2020\nSLAC National Accelerator Laboratory, Menlo Park, California 94025, USA\n(Received 15 May 2022; accepted 17 November 2022; published 8 December 2022)\nAccelerator performance often deteriorates with time during a long period of operation due to secular changes in the machine components or the surrounding environment. In many cases, some tuning knobs are effective in compensating the performance drifts and optimization methods can be used to find the ideal machine setting. However, such intervention usually cannot be done without interrupting user operation as the optimization algorithms can substantially impact the machine\u2019s performance. We propose an optimization algorithm, Safe Robust Conjugate Direction Search, which can perform accelerator tuning while keeping the machine performance within a designated safe envelope. The algorithm builds probability models of the objective function using Lipschitz continuity of the function as well as characteristics of the drifts and applies to the selection of trial solutions to ensure the machine operates safely during tuning. The algorithm can run during normal user operation constantly, or periodically, to compensate for the performance drifts. Simulation and online tests have been done to validate the performance of the algorithm.\nDOI: 10.1103/PhysRevAccelBeams.25.122801\nI. INTRODUCTION\nOnline optimization is an effective approach to find accelerator settings with high performance. In online optimization, a number of machine control parameters (i.e., tuning knobs) are varied by an optimization algorithm to minimize or maximize the objective function, which represents the machine performance and is measured experimentally for each machine setting. Efficient optimization algorithms are key to online optimization. Popular optimization algorithms for online accelerator applications include Nelder-Mead simplex [1], robust conjugate direction search (RCDS) [2], particle swarm [3], and Bayesian optimization [4]. Typically, when the algorithm suggests new trial solutions, the step size from known solutions is not restricted and the performance of the trial solution is not guaranteed. During an optimization run, as the algorithm gradually discovers machine settings with high performance, it can also produce solutions with poor performance, which cannot be tolerated for normal user operation. Therefore, online optimization is usually performed during dedicated\nmachine development or study shifts. Oftentimes, after the ideal machine setting is found, it is delivered to a user operation for days or weeks, until the next window for tuning becomes available. However, in many cases, an ideal machine setting will not maintain high performance during the long period of user operation. Small variations in the accelerator components, caused by or coupled with variations in the surrounding environment, can cause the machine\u2019s performance to drift with time. The underlying causes of the performance drift are not always known; even if a connection with certain environmental factors can be established, the relationship is often not adequately deterministic to build reliable feedforward control. On the other hand, the performance drift can usually be compensated by tuning some control knobs. Unfortunately, as such tuning can only be done during dedicated shifts, one has to either tolerate the deteriorating machine performance or interrupt the operation schedule to add a tuning session. In this study, we propose a safe tuning method that can be used during user operation. The new algorithm is called safe robust conjugate direction search (RCDS-S). It employs iterative one-dimensional (1D) optimization over a conjugate direction set in a similar manner as the RCDS method. However, its 1D optimization is done in a more prudent and informed fashion, which employs a probability model of the objective function to assess the risk of exceeding a safety threshold by the trial solution. The probability model includes the combined effect of the innate variation of the objective function and the slow drift with time. To the best of our knowledge, this is the first *Also at Illinois Institute of Technology, Chicago, IL 60616, USA. \u2020xiahuang@slac.stanford.edu Published by the American Physical Society under the terms of the Creative Commons Attribution 4.0 International license. Further distribution of this work must maintain attribution to the author(s) and the published article\u2019s title, journal citation, and DOI.\nPHYSICAL REVIEW ACCELERATORS AND BEAMS 25, 122801 (2022)\n2469-9888=22=25(12)=122801(10) 122801-1 Published by the American Physical Society\ntime an algorithm is proposed to compensate accelerator performance drifts through safe tuning during operation. The proposed method is similar to an earlier method [5,6], in that both studies make use of the Lipschitz continuity properties of the objective function. However, there are significant differences between the two methods. In Ref. [6], a safe domain is identified through the Lipschitz continuous condition, over which Gaussian process optimization is performed. In our method, the Lipschitz continuity condition is used to select trial solutions based on the need to explore the parameter space and the safety requirement; the trial solutions are used in a parabolic fitting to determine the location of the minimum. The new method has been successfully tested with a reallife problem in both simulations and experiments. The test problem is the kicker-bump matching of a storage ring. In the tests, the amplitude of a kicker is modulated independently, while the amplitudes of the other two kickers are tuned by the algorithm. It was shown that the objective function can be kept below a prespecified threshold during the tuning period. A beam steering for optimal injection efficiency problem is also used to test the algorithm in simulation. This paper is organized as follows: Section II describes the RCDS-S algorithm. Section III shows the application of RCDS-S to two simulated drifting accelerator problems. Section IV presents experimental results when the method is applied to a real accelerator. Section V discusses an alternative approach to model the system drift and shows a few preliminary test results. Section VI gives the conclusion."
        },
        {
            "heading": "II. THE RCDS-S METHOD",
            "text": "Our goal of the study is to develop an optimization method that can be used to optimize accelerator performance during user operation by keeping the performance above a certain threshold. Such a method could be termed a \u201csafe\u201d optimization algorithm. A safe optimization algorithm could be used to compensate for the performance drift with time, as it can run in the background continuously, periodically, or as needed. To achieve the goal, it is necessary to first understand the sources of the danger in the usual \u201cunsafe\u201d methods, before a cure can be found. In the following, we first discuss the uncertainty of the objective function as it is probed. By constructing a probability model of the uncertainty and using it to guide the selection of new trial solutions, we devised a safe 1D optimization method. Combining this safe 1D optimization method and the conjugate direction search method, we arrived at the new algorithm, RCDS-S."
        },
        {
            "heading": "A. Modeling uncertainty of an objective function",
            "text": "In this study, we cast an optimization problem to minimize the objective function with a set of tuning knobs,\nf\u00f0x\u00de, where elements of x are the knob values. An online optimization problem has measurement errors, therefore,\ny \u00bc f\u00f0x\u00de \u00fe \u03f5;\nwhere \u03f5 \u223c N\u00f00; \u03c32n\u00de, \u03c3n is the standard deviation of measurement errors. In online optimization, the optimization algorithm continues to sample the objective function by evaluating new trial solutions. The sampling results are used by the algorithm to determine the next trial solution. Depending on the efficiency of the algorithm, the overall trend among all the trial solutions is to improve the objective function. However, for the traditional algorithms, a trial solution at any time could correspond to poor performance, as they typically do not limit the step size with the predicted performance. In this case, the intrinsic variation of the objective function in the parameter space poses a danger. To be able to suggest a safe trial solution, the algorithm has to have a sort of model about the unknown objective function. Our approach is to simply limit the gradient of the function. Mathematically, the objective function is assumed to be L-Lipschitz continuous, which means for any x;x0 \u2208 D, where D is the domain of the function, we have\nkf\u00f0x\u00de \u2212 f\u00f0x0\u00dek \u2264 L \u00b7 kx \u2212 x0k:\nConsidering noise, it leads to\ny \u2264 y0 \u00fe L \u00b7 kx \u2212 x0k \u00fe ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi \u03c32 \u00fe \u03c320 q \u00b7 \u03f5\u0302;\nwhere \u03c3 and \u03c30 are the noise levels at x and x0, respectively, y and y0 are the measured objective values at x and x0, and \u03f5\u0302 \u223c N\u00f00; 1\u00de. Clearly, the expectation of y satisfies\nE\u00f0y\u00de \u2264 y0 \u00fe L \u00b7 kx \u2212 x0k \u00bc Emax\u00f0x\u00de:\nThe goal of the safety search method is to keep the objective function below a certain safety threshold, for any trial solutions, the algorithm proposes during the optimization. Let the safety threshold be h, point x would be a safe point, i.e., y \u2264 h, if\n\u03f5\u0302 \u2264 h \u2212 Emax ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n\u03c32 \u00fe \u03c320 p : \u00f01\u00de\nThe probability for Eq. (1) to hold for point x is\np\u00f0x\u00de \u00bc 1 2 1\u00fe erf\nh \u2212 Emax\u00f0x\u00de ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n2\u00f0\u03c32 \u00fe \u03c320\u00de p\n; \u00f02\u00de\nwhere erf\u00f0\u00b7\u00de is the error function. The second source of danger in online tuning is the drift, or the time-dependent variation, of the objective function. Without further information about the specific optimization\n122801-2\nproblem, the drift can be modeled as a random walk process. Under this assumption, the uncertainty of the measurement becomes a time-varying random variable,\ny \u00bc f\u00f0x\u00de \u00fe \u03f5\u00f0t\u00de:\nWhen the drift at one point x is treated as a Gaussian random walk process, the measured function value differs from the original value by a random amount, whose standard deviation increases with time according to\n\u03c3t \u00bc ffiffi t p \u03c3d;\nwhere \u03c3d is the drift rate, with \u03c32d representing the increase of the variance within a unit time interval, and t is the time elapsed from a reference point. It would be reasonable to assume that noise and drift are not coupled, therefore \u03f5\u00f0t\u00de \u223c N\u00f00; \u03c32n \u00fe \u03c32t \u00de. Combined with Eq. (1), we have\n\u03f5\u0302 \u2264 h \u2212 Emax ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n2\u03c32n \u00fe t\u03c32d q ; \u00f03\u00de\nwhich is used to update Eq. (2).\nB. 1D safety exploration without drift\nBy applying the probability model of the objective function to the 1D subspace, i.e., along a line in the parameter space, we can develop a strategy to safely explore the linear space. The idea is that we calculate the safety probability for all points (i.e., potential trial solutions) along the full viable range, using each previous observation point based on Eq. (2). For any candidate point, we take the maximum of all the calculated probabilities as the estimated safety probability for that point. For example, if five observations are given, we have five probabilities, p1\u2013p5, calculated from the observations at position x, and the final assigned safety probability of x is p\u00f0x\u00de \u00bc max\u00f0p1; p2; p3; p4; p5\u00de. In this way, we obtain a safety probability curve along the line. To determine the next point to sample, we introduce a performance indicator (PI): safety probability threshold ps, which indicates the required safety probability for safe exploration. For example, ps \u00bc 0.99 means the algorithm should only choose the point as the candidate where the assigned safety probability is higher than 0.99. With the safety probability threshold defined, the safety region can be computed. To illustrate the 1D safety exploration strategy, we introduce a simple test function,\ny \u00bc f\u00f0x\u00de \u00fe \u03f5 \u00bc C\u00f0x \u2212 \u03bc\u00de2 \u00fe \u03c3n\u03f5\u0302; \u00f04\u00de\nwhere C \u00bc L=\u00bd2max\u00f0\u03bc; 1 \u2212 \u03bc\u00de , \u03bc \u2208 \u00bd0; 1 , x \u2208 \u00bd0; 1 , \u03c3n is the standard deviation of a Gaussian noise, \u03f5\u0302 is a random\nvariable that obeys the standard normal distribution. This test function f\u00f0x\u00de is L-Lipschitz continuous. In this case study, we choose Lipschitz constant L \u00bc 1 and safety threshold h \u00bc 0.2 while \u03bc and \u03c3n are set to 0.4 and 0.01, respectively. Figure 1 shows an example of the safety probability curve and the safety region (highlighted in green) when seven observation points are given. Similar to the RCDS method, the purpose of line exploration is to collect enough data points to bracket the minimum and to perform a parabola fitting. Before the minimum is bracketed, it would be preferred to expand the sample coverage region as far as possible. Therefore, the next data point is chosen to be one of two edge points of the safety region, usually the one further away from the known observation points. When the trial solution is evaluated, it becomes an observation point. The exploration process described above\n122801-3\nrepeats until we have enough data points to do a parabola fitting. A complete 1D safety exploration process is visualized in Fig. 2, and the corresponding parabola fitting is shown in Fig. 3. More detailed logic and the implementation of safety exploration along one direction can be found in Algorithm 1. In the algorithm, n is the iteration index, and Sn and On are the sets of solutions (positions) and objectives of the observations at iteration n, respectively. C denotes the set of all the candidate solutions, and Cs denotes the set of the safe candidate solutions. The safety exploration algorithm has three exit conditions, which indicate the exploration is successful, aborted as no safe\ncandidates are available, or the maximum number of trial solutions are attempted but without success, respectively.\nC. 1D safety exploration with drift\nAs discussed earlier, when drift to the objective function is introduced, the calculation of the safety probability changes [see Eq. (3)]. Intuitively, an older observation would become less reliable than the newer observations. As a consequence, the contribution of each observation to the safety probability calculation differs with measurement time. The 1D safety exploration procedure is applicable to the case with drift, only with the changes to the safety probability calculation. We will use the same test problem, shown in Eq. (4), for illustrating and testing, but with modulation to the minimum position \u03bc to simulate the systematic drift,\n\u03bc\u00f0t\u00de \u00bc \u03bc0 \u00fe \u03c3d sin 2\u03c0t p ;\nwhere p and \u03c3d are the period and amplitude of the modulation, respectively. The test function with drift, f\u00f0x; t\u00de, is shown in Fig. 4, where the red line indicates the drifting of the minimum position. Figure 5 is the snapshot of the safety probability at the end of the safety exploration. Clearly, the calculated safety probability curve is altered significantly compared to the case without drift (see Fig. 1). The observation points (orange triangles) to the right side are older samples, which have less impact on the safety curve, as expected. The evolution of the safety probability over the test problem domain during the safety exploration is shown in Fig. 6.\nAlgorithm 1: 1D Safety exploration."
        },
        {
            "heading": "1 n \u2190 0, S0 \u2190 \u00bdx0 , O0 \u2190 \u00bdy0 . Initialize C",
            "text": "2 while n < Nmax do 3 Check if the peak has already been bracketed, and try to perform parabola fitting with Sn and On 4 if peak is bracketed and parabola fitting succeeded then 5 Terminate the exploration. Report error code 0, peak position xp; 6 else 7 For each candidate in C, calculate the safety probability p based on Sn and On; 8 Cs \u2190 candidates with safety probability p > ps; 9 while range\u00f0Cs\u00de \u2208 range\u00f0Sn\u00de do 10 Lower down the safety probability threshold ps; 11 if ps is below a lower limit \u03f5 then 12 Give up the exploration. Report error code 1; 13 end 14 Cs \u2190 candidates with safety probability p > ps; 15 end 16 Select candidate from Cs that has maximum distance from Sn as the next position-to-sample xn\u00fe1 17 Evaluate xn\u00fe1 to get yn\u00fe1; 18 Sn\u00fe1 \u2190 Sn \u00fe \u00bdxn\u00fe1 , On\u00fe1 \u2190 On \u00fe \u00bdyn\u00fe1 ; 19 n \u2190 n\u00fe 1; 20 end 21 end 22 Report error code -1;\n122801-4"
        },
        {
            "heading": "D. The RCDS-S algorithm",
            "text": "Combining the scheme of iterative 1D optimization over conjugate directions [7], the safety 1D exploration discussed in previous sections, and the use of parabolic fitting to determine the minimum [2], we arrive at the RCDS-S algorithm. The algorithm logic flow is provided in Algorithm 2. Note that i and n in the algorithm are the iteration index and the evaluation index, respectively. In the algorithm implementation, we choose to normalize all parameters to within the range of [0, 1]. In the following, we discuss two aspects regarding the application of the method in more detail. First, after each iteration, when the algorithm has gone through all directions, one could replace one of the existing\ndirections with the new direction that goes from the previous minimum to the new minimum. In the traditional Powell method, this decision is done by assessing an additional point in the new direction and using the result to estimate the potential gain from the direction [8]. However, the additional evaluation could be unsafe. As a simple solution, the RCDS-S algorithm provides an option to always replace or not replace the direction. The option of not replacing the direction is expected to be more suitable in cases where a conjugate direction set is available through model calculation or analysis of past measurement data. The second important aspect is the choice of hyperparameters for safety exploration. The two most critical hyperparameters in the modeling of the safety probability are the Lipschitz constant Lv in normalized decision space and the drift rate \u03c3d in time. Choosing good values for these two parameters is crucial to the safety performance of the proposed algorithm. Compared to the ideal value, a smaller L would result in less safe exploration by increasing the chance of sampling an unsafe point. On the other hand, a larger L encourages more conservative exploration that wastes more points for each direction and would lead to slower convergence. Slow convergence is problematic,\nAlgorithm 2: RCDS-S.\n1 i \u2190 0, n \u2190 0. Initialize the conjugate direction setM \u2208 Rm\u00d7m, initial solution x0 \u2208 Rm. Define vk \u2254 colk\u00f0M\u00de;\n/* Imax and Nmax are maximum number of iterations and evaluations, respectively */ 2 while i < Imax and n < Nmax do 3 d \u2190 0, \u03b7 \u2190 0; 4 for k \u00bc 1 to m do 5 Perform safety exploration at xk\u22121 along vk to find extremum xk 6 if yk\u22121 \u2212 yk > d then 7 d \u2190 yk\u22121 \u2212 yk 8 \u03b7 \u2190 k; 9 end 10 n \u2190 n\u00fe number of evaluations in safety exploration; 11 end 12 if replace direction then 13 vm\u00fe1 \u2190 unit vector alongxm \u2212 x0; 14 Perform safety exploration at xm along vm\u00fe1 to find extremum xm\u00fe1; 15 n \u2190 n\u00fe number of evaluations in safety exploration; 16 x0 \u2190 xm\u00fe1;\n/* discarding the direction of largest decrease */\n17 for k \u00bc \u03b7 to m do 18 vk \u2190 vk\u00fe1; 19 end 20 else 21 x0 \u2190 xm; 22 end 23 i \u2190 i\u00fe 1; 24 end\n122801-5\nespecially for the drifting case, as it can cause the algorithm to fail to follow the drifting optimum. The hyperparameters can be obtained before applying the algorithm to a specific problem by analyzing historic data or performing additional measurements. For example, the maximum drifting rate \u03c3d can be estimated by observing the variation of the objective function over a long period of timewhen no knobs are varied (constant scan). The Lipschitz L parameter can be determined through conjugate direction scans, which are to perform full-range linear scans over the directions in the initial conjugate direction set of the normalized decision space. The maximum absolute gradient of all the scanned directions can be used as the Lv parameter. Examples of the constant scan and the conjugate direction scans are shown in Fig. 7. In the algorithm, we use one L parameter for all directions. In the case when no direction is replaced during the execution of the algorithm, a different L value could be provided for each direction. A more accurate hyperparameter could lead to better safety and efficiency. Because the RCDS-S algorithm relies on probability models to choose trial solutions and these models strongly depend on the accuracy of hyperparameters, we do not expect all trial solutions are guaranteed to be safe. There could be times when the algorithm fails to follow the drift. At other times, even when the algorithm is following the drift, there could be occasional trial solutions that exceed the safety threshold. Therefore, while the algorithm tends to allow safe exploration of the parameter space, it is not recommended for high risk applications."
        },
        {
            "heading": "E. Application conditions",
            "text": "Here, we semitheoretically analyze the condition where RCDS-S may apply. Equation (3) shows the relationship between the step size and the safety level. If we define \u03b7 as\n\u03b7 \u00bc h \u2212 Emaxffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi 2\u03c32n \u00fe t\u03c32d q ;\nwhich is a measure of the safety level, where \u03b7 \u00bc 1, 2, 3 corresponds to a safety probability of approximately 0.841, 0.977, and 0.999, respectively. For simplicity purposes, without loss of generality, we assume \u03b7 \u00bc 1 in the following analysis. Combining with the definition of Emax, we can calculate the maximum safe step size smax:\nsmax \u00bc m \u2212\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi 2\u03c32n \u00fe \u03c4\u03c32d q\nL ;\nwherem is the safety margin (difference between the safety threshold and the optimal objective value) and \u03c4 is the sampling time for one data point. Noting that all the objective-related variables can be normalized by the noise level \u03c3n to make them dimensionless quantities, the form of the above equation can be further simplified as\nsmax \u00bc m\u0302 \u2212\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi 2\u00fe \u03c4\u03c3\u03022d q\nL\u0302 ;\nwhere m\u0302 \u00bc m=\u03c3n, \u03c3\u0302d \u00bc \u03c3d=\u03c3n, L\u0302 \u00bc L=\u03c3n are normalized safety margin, normalized drift rate, and normalized Lipschitz constant, respectively. One simple requirement is that smax has to be larger than 0,\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi 2\u00fe \u03c4\u03c3\u03022d q \u2264 m\u0302; \u00f05\u00de\nso thatRCDS-Shas room for exploring. This condition puts a limit on the drift rate \u03c3d; but it says nothing about the capability of RCDS-S to follow the drift. Within one iteration, RCDS performs a 1D scan to bracket the minimum and fit for the optimum in each conjugate direction. It would be reasonable to assume that, if the system drift is not significant during one iteration, RCDS-S has a good chance to locate the optimum and thus be able to follow the trend of the drift. It is straightforward to show that, to bracket the minimum of one direction on an L-Lipschitz continuous function with a 0.97 confidence level, the maximum travel distance \u0394 would be around 12=L\u0302. If there are D optimization variables, the total time needed for RCDS-S to complete one iteration would be\nT \u00bc \u0394 smax D\u03c4 \u00bc 12D\u03c4 L\u0302smax :\nTherefore, the expectation value of the drift of the optimum within one iteration, normalized by \u03c3n, is\n\u03b4\u0302T \u00bc ffiffiffi T p \u03c3\u0302d:\nLet \u03b4\u0302\u03c4 \u00bc ffiffi \u03c4 p \u03c3\u0302d, the above equation above becomes\n122801-6\n12D \u03b4\u03022\u03c4 \u03b4\u03022T \u00fe ffiffiffiffiffiffiffiffiffiffiffiffi 2\u00fe \u03b4\u03022\u03c4 q \u00bc m\u0302: \u00f06\u00de\nGiven the normalized margin m\u0302, drift during one sample point \u03b4\u0302\u03c4, and dimensionD, Eq. (6) allows us to estimate the normalized drift of the objective in one iteration. The relationship curves for a few \u00f0m\u0302; D\u00de sets are visualized in Fig. 8. If the value of \u03b4\u0302T is too large, it would be difficult for RCDS-S to follow the drift trend. If \u03b4\u0302T is too small, the drift is relatively slow, in which case, one could consider pushing the safety threshold toward the optimum. For example, in the experimental test case discussed in section IV, the value of \u03b4\u0302T is approximately 0.25 when the modulation period is 800. In experiments, we found that the method would not work if the drift speed is doubled (corresponding to \u03b4\u0302T \u2248 0.5)."
        },
        {
            "heading": "III. SIMULATION TESTS",
            "text": "Simulation studies were conducted to test the performance of the RCDS-S algorithm in online optimizations for drifting problems. Two simulated accelerator test problems are used. The first problem is kicker-bump matching for a storage ring, with a 2D decision space. The second one is the steering of the injected beam in the booster to storage ring (BTS) transport line to maximize injection efficiency [2], which is a 4D problem."
        },
        {
            "heading": "A. Kicker-bump matching safety optimization",
            "text": "The Stanford Positron and Electron Asymmetric Ring-III (SPEAR3) storage ring has three injection kickers that, ideally, form a closed orbit bump when fired. In reality, the kicker bump is not strictly closed, leading to residual oscillations after the kickers are fired. The purpose of the kicker bump matching program is to find the kicker setting that minimizes the residual oscillations.\nIn the test, the strength of one kicker, K1, is modulated in a sinusoidal form to simulate the systematic drift, as shown in\nv\u00f0t\u00de \u00bc v0 \u00fe \u03c3d sin\n2\u03c0\np \u00f0t\u00fe t0\u00de \u2212 sin\n2\u03c0\np t0\n; \u00f07\u00de\nwhere p is the drifting period, \u03c3d is the drifting amplitude, t0 is the time origin, v0 is the initial value of the modulated variable. The strengths of theother two kickers,K2 andK3, are used as tuning knobs of the optimization problem. The rms turnby-turn horizontal orbit from 256 turns of residual oscillations is used as the objective function. A Gaussian noise with strength \u03c3n is added to the objective. The problem is normalized so that the knob values vary between 0 and 1. For the algorithm tests, we set p \u00bc 800, \u03c3n \u00bc 3 \u03bcm, \u03c3d \u00bc 0.1. Note that \u03c3d here is dimensionless since the strength of the modulated kicker K1 has been normalized. Based on the two prescans discussed in the last section, the Lipschitz constant L and strength of Gaussian random walk \u03c3g are chosen to be 2000 and 0.2, respectively. The safety threshold h can be varied to change the safety search difficulty. In the tests, the safety threshold is set to 40 \u03bcm, which is only slightly higher than most of the observed values of the noisy objective at the initial solution. The tests have been run multiple times, and the performance is stable. A typical test is shown in Fig. 9. The top\n122801-7\nplot compares the objective function over one modulation period for three cases: no optimization, tuning with RCDS, and tuning with RCDS-S. The test result shows that RCDSS is able to follow the drift and seek the optimum while keeping the objectives of the trial solutions well below the safety threshold. RCDS is also very efficient for the test problem. However, since it is not aware of the safety threshold, the proposed solutions are not guaranteed to be safe."
        },
        {
            "heading": "B. BTS injection efficiency safety optimization",
            "text": "The RCDS-S algorithm has also been tested with a 4D problem in simulation. The test problem is to maximize the injection efficiency with steering knobs in the BTS transport line. Two pairs of upstream correctors, one pair in each transverse plane, are modulated according to Eq. (7) to simulate systematic drift. Two pairs of correctors, also one pair for each plane, toward the end of the transport line are used as tuning knobs to compensate for the trajectory drift and its impact on injection efficiency. The objective function is the negated injection efficiency, to comply with the minimization convention used in RCDS-S. The noise level \u03c3n is set to 0.05 and the drift period p \u00bc 800. The drift amplitude is large enough such that the injection efficiency drops to zero for half of the modulation period. The safety threshold is set to \u22120.5 (i.e., corresponding to a 50% injection efficiency). Figure 10 shows the results of a typical test run. The RCDS-S algorithm keeps the injection efficiency near the maximum and its trial solutions are mostly within the safe region. In comparison, the RCDS algorithm not only exceeds the safety threshold but also occasionally fails to follow the drifting."
        },
        {
            "heading": "IV. EXPERIMENTAL APPLICATION OF THE RCDS-S ALGORITHM",
            "text": "The RCDS-S method has been applied experimentally to the kicker-bump matching problem on the SPEAR3 storage ring to demonstrate its capability to compensate for drifts in\nonline optimization. The setup of the problem is the same as was discussed in the previous section of the simulation. The goal is to minimize the residual oscillation as seen by a turn-by-turn beam position monitor. The voltage amplitude of one kicker (K1) is modulated with a period of 800 data points, with an interval of 2 s between data points. The noise level was measured right before the algorithm test and was found to be 5 \u03bcm. The initial solution is the same as the operation setting which would give the best objective if the system is not drifting. Two rounds of tests were performed with the experimental setup. For the first round, the safety threshold is set to 60 \u03bcm. As it succeeded, we set the safety threshold to 50 \u03bcm for the second round. The results for the second round are shown in Fig. 11, where the objective function for RCDS-S for one modulation period is compared to the results of RCDS and the case without tuning. The experimental performance is similar to the simulation cases for both RCDS-S and RCDS. The objective function has a larger variance for the evaluated trail solutions in experiments. This could be due to the higher measurement noise level. RCDS-S would explore until it brackets the peak of the objective curve, and hence, the higher the noise level is, the wider the exploration range would be, for the 1D exploration to gain the same level of confidence that a peak has been bracketed.\n122801-8\nAnother behavior that has been observed in the experiment is that RCDS-S had a few small violation solutions for both rounds. This could be due to a mismatch between the true Lv of the experiment problem and the one we applied in the algorithm (that comes from the simulation). Using a larger Lv could reduce the violation rate at the expense of more trial solutions per direction, and consequently would increase the probability of RCDS-S failing to follow the systematic drift."
        },
        {
            "heading": "V. ALTERNATIVE APPROACH TOMODEL DRIFT",
            "text": "In Sec. II A, the systematic drift is modeled as an increasing uncertainty with time. With this model, we are not incorporating any prior knowledge about the drift behavior of the system. It may be possible to improve the predictive capability of the model if the drift trend is included. In the general case, the objective function can be seen as a function of both the tuning knobs and time,\ny \u00bc f\u00f0x; t\u00de \u00fe \u03f5:\nSimilar to the variation of knobs, one simple assumption about the dependence on time is that the rate of change has an upper limit. In this case, in addition to the L-Lipschitz continuous condition on x, we also assume the objective function to be \u03c3d-Lipschitz continuous on t:\nkf\u00f0x; t1\u00de \u2212 f\u00f0x; t2\u00dek \u2264 \u03c3dkt1 \u2212 t2k:\nTherefore, based on the observation of a point x0 that was measured at a time \u2212t (relative to the current time), we have\nkf\u00f0x; 0\u00de \u2212 f\u00f0x0;\u2212t\u00dek \u2264 kf\u00f0x; 0\u00de \u2212 f\u00f0x;\u2212t\u00dek \u00fe kf\u00f0x;\u2212t\u00de \u2212 f\u00f0x0;\u2212t\u00dek\n\u2264 Lkx \u2212 x0k \u00fe \u03c3dt\nFollowing the same path as in the derivation of Eq. (1), we have\n\u03f5\u0302 \u2264 h \u2212 Emax \u2212 \u03c3dt ffiffiffiffiffiffiffi\n2\u03c32n p ; \u00f08\u00de\nwhere Emax is as defined previously, which is the maximum expected value at point x without drift. This alternative approach to perform a 1D safety exploration is applied to the test problem discussed in Sec. II C. The efficiency is found to be similar to the Gaussian random walk approach. However, the evolution of the safety probability curves, and consequently the sampled points, is quite different for the two cases. The time sensitivity of the alternative approach is higher than the original one, i.e., the impact of the older data points on the safety probability curve decays faster, as shown in Fig. 12. For example, the three points on the right side\nalmost have no impact on the safety probability curve. The evolution of the safety probability during the 1D exploration is visualized in Fig. 13."
        },
        {
            "heading": "VI. CONCLUSIONS",
            "text": "In this study, we propose an optimization algorithm (RCDS-S) that combines robust conjugate direction search and a new 1D safety exploration algorithm to optimize noisy, drifting machine performances online, while keeping the machine performance within a designated safe envelope. The 1D safety exploration algorithm makes use of Lipschitz continuity of the objective function and properties of a Gaussian random walk process for the drift to build a probability model of the drifting function, with\n122801-9\nwhich to suggest safe trial solutions. The proposed algorithm has been successfully tested on simulated and experimental accelerator tuning problems."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "This work was supported by the U.S. Department of Energy, Office of Science, Office of Basic Energy Sciences, under Contract No. DE-AC02-76SF00515.\n[1] J. A. Nelder and R. Mead, A simplex method for function minimization, Comput. J 7, 308 (1965). [2] X. Huang, J. Corbett, J. Safranek, and J. Wu, An algorithm for online optimization of accelerators, Nucl. Instrum. Methods Phys. Res., Sect. A 726, 77 (2013). [3] J. Kennedy and R. Eberhart, Particle swarm optimization, in Proceedings of ICNN\u201995\u2014International Conference on Neural Networks, Perth, WA, Australia (IEEE, New York, 1995), Vol. 4, pp. 1942\u20131948.\n[4] J. Duris, D. Kennedy, A. Hanuka, J. Shtalenkova, A. Edelen, P. Baxevanis, A. Egger, T. Cope, M. McIntire, S. Ermon, and D. Ratner, Bayesian Optimization of a Free-Electron Laser, Phys. Rev. Lett. 124, 124801 (2020). [5] Y. Sui, A. Gotovos, J. Burdick, and A. Krause, Safe exploration for optimization with Gaussian processes, in Proceedings of the 32nd International Conference on Machine Learning, ICML\u201915, Lille, France (Microtome Publishing, Brookline, MA, 2015), pp. 997\u20131005. [6] J. Kirschner, M. Mutny, N. Hiller, R. Ischebeck, and A. Krause, Adaptive and safe Bayesian optimization in high dimensions via one-dimensional subspaces, in Proceedings of the 36th International Conference on Machine Learning, Long Beach, CA (Microtome Publishing, Brookline, MA, 2019), pp. 3429\u20133438. [7] M. J. D. Powell, An efficient method for finding the minimum of a function of several variables without calculating derivatives, Comput. J. 7, 155 (1964). [8] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery, Numerical Recipes: The Art of Scientific Computing, 3rd ed. (Cambridge University Press, New York, NY, 2007).\n122801-10"
        }
    ],
    "title": "Optimization method to compensate accelerator performance drifts",
    "year": 2022
}