{
    "abstractText": "In online marketplaces, customers have access to hundreds of reviews for a single product. Buyers often use reviews from other customers that share their type\u2014such as height for clothing, skin type for skincare products, and location for outdoor furniture\u2014to estimate their values, which they may not know a priori. Customers with few relevant reviews may hesitate to make a purchase except at a low price, so for the seller, there is a tension between setting high prices and ensuring that there are enough reviews so that buyers can confidently estimate their values. Simultaneously, sellers may use reviews to gauge the demand for items they wish to sell. In this work, we study this pricing problem in an online learning setting where the seller interacts with a set of buyers of finitely many types, one by one, over a series of T rounds. At each round, the seller first sets a price. Then a buyer arrives and examines the reviews of the previous buyers with the same type, which reveal those buyers\u2019 ex-post values. Based on the reviews, the buyer decides to purchase if they have good reason to believe that their ex-ante utility is positive. Crucially, the seller does not know the buyer\u2019s type when setting the price, nor even the distribution over types. We provide a no-regret algorithm that the seller can use to obtain high revenue. When there are d types, after T rounds, our algorithm achieves a problemindependent \u00d5(T d) regret bound. However, when the smallest probability qmin that any given type appears is large, specifically when qmin \u2208 \u03a9(d\u22122/3T\u22121/3), then the same algorithm achieves a \u00d5(T q \u22121/2 min ) regret bound. Our algorithm starts by setting lower prices initially so as to (i) boost the number of reviews and increase the accuracy of future buyers\u2019 value estimates while also (ii) allowing the seller to identify which customers need to be targeted to maximize revenue. This mimics real-world pricing dynamics. We complement these upper bounds with matching lower bounds in both regimes, showing that our algorithm is minimax optimal up to lower-order terms. Work done while the author was a PhD student at UC Berkeley. 1 ar X iv :2 30 2. 09 70 0v 2 [ cs .G T ] 1 1 Se p 20 23",
    "authors": [
        {
            "affiliations": [],
            "name": "Wenshuo Guo"
        }
    ],
    "id": "SP:5281320f7899a06a652427bf58e668c69d46c830",
    "references": [
        {
            "authors": [
                "Daron Acemoglu",
                "Ali Makhdoumi",
                "Azarakhsh Malekian",
                "Asuman Ozdaglar"
            ],
            "title": "Learning from reviews: The selection effect and the speed of learning",
            "year": 2022
        },
        {
            "authors": [
                "Itai Ashlagi",
                "Constantinos Daskalakis",
                "Nima Haghpanah"
            ],
            "title": "Sequential mechanisms with ex-post participation guarantees",
            "venue": "In ACM Conference on Economics and Computation",
            "year": 2016
        },
        {
            "authors": [
                "Omar Besbes",
                "Marco Scarsini"
            ],
            "title": "On information distortions in online ratings",
            "venue": "Operations Research,",
            "year": 2018
        },
        {
            "authors": [
                "Subir Bose",
                "Gerhard Orosel",
                "Marco Ottaviani",
                "Lise Vesterlund"
            ],
            "title": "Dynamic monopoly pricing and herding",
            "venue": "The RAND Journal of Economics,",
            "year": 2006
        },
        {
            "authors": [
                "Etienne Boursier",
                "Vianney Perchet",
                "Marco Scarsini"
            ],
            "title": "Social learning in non-stationary environments",
            "venue": "In International Conference on Algorithmic Learning Theory (ALT),",
            "year": 2022
        },
        {
            "authors": [
                "Mark Braverman",
                "Jieming Mao",
                "Jon Schneider",
                "Matt Weinberg"
            ],
            "title": "Selling to a no-regret buyer",
            "venue": "In ACM Conference on Economics and Computation",
            "year": 2018
        },
        {
            "authors": [
                "Christophe Chamley"
            ],
            "title": "Rational herds: Economic models of social learning",
            "year": 2004
        },
        {
            "authors": [
                "Shuchi Chawla",
                "Nikhil R Devanur",
                "Anna R Karlin",
                "Balasubramanian Sivan"
            ],
            "title": "Simple pricing schemes for consumers with evolving values",
            "venue": "Games and Economic Behavior,",
            "year": 2022
        },
        {
            "authors": [
                "Davide Crapis",
                "Bar Ifrach",
                "Costis Maglaras",
                "Marco Scarsini"
            ],
            "title": "Monopoly pricing in the presence of social learning",
            "venue": "Management Science,",
            "year": 2017
        },
        {
            "authors": [
                "Nikhil R Devanur",
                "Yuval Peres",
                "Balasubramanian Sivan"
            ],
            "title": "Perfect Bayesian equilibria",
            "venue": "Conference on Neural Information Processing Systems (NeurIPS),",
            "year": 2019
        },
        {
            "authors": [
                "Bar Ifrach",
                "Costis Maglaras",
                "Marco Scarsini",
                "Anna Zseleva"
            ],
            "title": "Bayesian social learning",
            "year": 2020
        },
        {
            "authors": [
                "Ali Kakhbod",
                "Giacomo Lanzani",
                "Hao Xing"
            ],
            "title": "Heterogeneous Learning in Product Markets",
            "venue": "reviews. Operations Research,",
            "year": 2019
        },
        {
            "authors": [
                "2023. Robert Kleinberg",
                "Tom Leighton"
            ],
            "title": "The value of knowing a demand curve: Bounds on regret for",
            "year": 2023
        }
    ],
    "sections": [
        {
            "text": "In this work, we study this pricing problem in an online learning setting where the seller interacts with a set of buyers of finitely many types, one by one, over a series of T rounds. At each round, the seller first sets a price. Then a buyer arrives and examines the reviews of the previous buyers with the same type, which reveal those buyers\u2019 ex-post values. Based on the reviews, the buyer decides to purchase if they have good reason to believe that their ex-ante utility is positive. Crucially, the seller does not know the buyer\u2019s type when setting the price, nor even the distribution over types. We provide a no-regret algorithm that the seller can use to obtain high revenue. When there are d types, after T rounds, our algorithm achieves a problemindependent O\u0303(T 2/3d1/3) regret bound. However, when the smallest probability qmin that any given type appears is large, specifically when qmin \u2208 \u2126(d\u22122/3T\u22121/3), then the same algorithm achieves a O\u0303(T 1/2q\n\u22121/2 min ) regret bound. Our algorithm starts by setting lower prices initially so\nas to (i) boost the number of reviews and increase the accuracy of future buyers\u2019 value estimates while also (ii) allowing the seller to identify which customers need to be targeted to maximize revenue. This mimics real-world pricing dynamics. We complement these upper bounds with matching lower bounds in both regimes, showing that our algorithm is minimax optimal up to lower-order terms.\n\u2217Work done while the author was a PhD student at UC Berkeley.\nar X\niv :2\n30 2.\n09 70\n0v 2\n[ cs\n.G T\n] 1"
        },
        {
            "heading": "1 Introduction",
            "text": "The rapid growth of e-commerce, now accounting for 22% of global retail sales1, has allowed customers to make far more informed purchase decisions than ever before. Potential buyers can gain insights from thousands of reviews before deciding whether to purchase an item. Customers often use reviews by buyers who share their \u201ctype\u201d\u2014such as body type for clothes or skin type for skincare products\u2014to develop high-fidelity estimates of how much they value different items, which are quantities they may be uncertain of before purchasing.\nWhen learning from reviews, a customer\u2019s purchase decision is no longer just a function of the item\u2019s price but also of how certain the customer is about her valuation, which in turn depends on the earlier sales and reviews of the items. This leads to a tension between setting revenue-optimal prices while ensuring that buyers have enough reviews to confidently estimate their values. This tension is perhaps most clear for customers of rare types (for example, particularly tall or short individuals shopping for clothing) who may find only a few reviews from similar customers and, due to this uncertainty, may only be willing to buy at relatively low prices.\nWe introduce a model that simultaneously captures the seller\u2019s pricing problem, the buyers\u2019 learning problem, and the modus through which the buyers learn: reviews. We study how a seller\u2014who is uncertain about the buyers\u2019 type distribution\u2014can learn to set high-revenue prices when the buyers themselves are uncertain about their own values and are learning from reviews. Thus, there is information uncertainty on both sides of the market: the seller has uncertainty about which buyer will arrive and the buyers\u2019 type distribution, but the buyer, who knows their type, suffers from the uncertainty about their ex-ante value. Both sides of the market are operating with significantly less information than has historically been assumed in mechanism design. We study this pricing problem with an online sequential learning model where the seller attempts to sell identical copies of an item to a series of distinct buyers over T timesteps. Each buyer has one of d types drawn from a distribution P, and a buyer of type i has an ex-ante value of \u03b8i for the item.\nAt each timestep t, the seller sets a price pt. Although the seller knows the ex-ante values \u03b81, . . . , \u03b8d and thus has some limited information about the buyers (for example, from market research), he does not know the buyer\u2019s type on each round nor even the distribution P. A buyer on any round could be of (i) a high-value type, but who is uncertain of their value since their type has few reviews, and thus may be hesitant to make a purchase except at a low price, (ii) of a high-value type, and who is more certain of their value since their type has many reviews, and thus is willing to purchase at a high price, or (iii) of a low-value type whom the seller should not target even if they were absolutely certain of their value since it leads to small per-purchase revenue.\nIf a buyer of type i purchases the item, they will leave a review communicating their ex-post value for the item, which is a random variable with mean \u03b8i. To decide whether to purchase, a new buyer evaluates reviews left by buyers of type i who bought the item in the past. Specifically, the buyer at round t \u2208 [T ] uses the past reviews to select a threshold \u03c4t and chooses to buy as long as pt \u2264 \u03c4t. If the buyer\u2019s threshold \u03c4t is too pessimistic\u2014for example, it always equals zero no matter the reviews\u2014then optimizing revenue would be hopeless. In our model, we bound the level of pessimism that the buyer can display: we assume that \u03c4t is at least a lower confidence bound we denote LBt that equals the average of the reviews left by buyers with the same type, minus an uncertainty term that depends on the number of such reviews. Intuitively, the buyer can be\n1https://www.trade.gov/ecommerce-sales-size-forecast\nconfident that their ex-ante value is at least LBt with high probability, so they always buy if they have good reason to believe that their ex-ante utility (value minus price) will be positive.\nThe ex-post value is the actual experience of the buyer and is different from the ex-ante value due to exogenous stochastic factors that cannot be known at the time of purchase (for example, manufacturing defects, color on the website not matching the actual color). Hence, the buyer decides based on their ex-ante value when there is complete information. In our problem, the buyer does not even know their ex-ante value and uses reviews from previous buyers (whose reviews are based on their actual experiences, i.e., ex-post values) to update their estimate of the ex-ante value (as the expected ex-post value is the ex-ante value)."
        },
        {
            "heading": "1.1 Our contributions",
            "text": "We provide a no-regret learning algorithm for the seller that balances setting high-revenue prices with soliciting reviews from rare but high-value customers.\nKey technical challenges. The seller does not know the current buyer\u2019s type on each round a priori, which means the prices are anonymous. Moreover, this means the seller does not know the number of reviews that the buyer will use to construct their value estimate. If the buyer on round t has a rare type, then the lower confidence bound LBt will be low, and thus the seller would have to set a low price to ensure a purchase and a review. Suppose this rare type of buyer\u2019s ex-ante value is high enough. In that case, it may be worthwhile to initially set a low price to solicit enough reviews to ensure future purchases at a higher price, thereby winning over these rare but high-value customers. The seller, however, has to decide which buyers to win over without knowing the type of the buyer on each round, nor even the distribution over types (and, thus, which types are common and which are rare). He may, therefore, wastefully offer a low price to a high-value buyer with a common type\u2014meaning that LBt is near the buyer\u2019s ex-ante value\u2014who would be willing to buy at a higher price. If a rare buyer\u2019s value is high enough, it may be worthwhile to set a low price to ensure future purchases at a higher price. However, if the buyer\u2019s type is exceedingly rare, the seller will lose too much revenue by setting such a low price. The challenge is that the seller has to decide which buyers to target without knowing the distribution over types.\nAlgorithm overview. With this intuition in mind, our algorithm maintains a set St at each step t consisting of buyer types with a sufficiently high value that are not exceedingly rare. It gradually refines this set over the T rounds. Intuitively, St is the set of buyers the algorithm targets. To refine St, the algorithm has two phases. In the first phase, the algorithm offers the item for free for a carefully chosen number of rounds, observing i.i.d. samples from the type distribution. The algorithm sets St to be the set of types appearing in a sufficiently large fraction of rounds, as in Figure 1a. In the second phase, the algorithm sets the price low enough to ensure that buyers in St always buy the item, as in Figure 1b. It successively eliminates types from St that contribute too little revenue.\nRegret upper bound and proof overview. In this model, we define regret as the difference between (1) the algorithm\u2019s total expected revenue and (2) the expected revenue of the optimal fixed price if the buyers bought whenever their ex-ante value was larger than the price, i.e., max pPri\u223cP [\u03b8i \u2265 p].\nWe contend with several sources of regret. The first phase of the algorithm, where the item is sold for free, inevitably leads to regret, so it must be made as brief as possible. The algorithm then completely disregards the buyer types that appeared too rarely during that phase. This results in a subset Q \u2286 [d] of buyer types that appear sufficiently often. In the second phase, the algorithm only attempts to optimize revenue with respect to the buyers in Q instead of the entire set [d], which contributes to regret. Finally, the buyers themselves do not know their ex-ante values, whereas, under our regret benchmark, buyers buy whenever their ex-ante value is larger than the price.\nWe obtain our final regret bound by analyzing these three sources of error. Our bound depends on the smallest probability that any given type appears, which we denote as qmin. If qmin is not tiny\u2014specifically, qmin > 2d \u22122/3T\u22121/3\u2014then we obtain a regret bound that scales with \u221a T , as desired. In particular, our regret upper bound is O\u0303(T 1/2q \u22121/2 min +T\n1/3d2/3). Otherwise, for arbitrary qmin, our regret bound scales with T 2/3 as O\u0303 ( T 2/3d1/3 + T 1/3d2/3 ) .\nRegret lower bound and proof overview. Typical bandit lower bounds rely on hypothesis testing arguments to show that any algorithm would struggle to distinguish between similar problems but with different optimal outcomes. Such an analysis would not capture the main difficulty in our setting: how fast customers can estimate their ex-ante values from past reviews. Instead, our proof leverages the buyers\u2019 uncertainty to establish a \u2126\u0303 ( T 2/3d1/3 ) worst-case lower bound and a \u2126\u0303(T 1/2q \u22121/2 min ) lower bound when qmin is large. This establishes the optimality of our algorithm.\nOur proof constructs a hard problem instance where buyer types with low probability of appearance have comparable ex-ante values to types with high probability of appearance. On each round, an algorithm should decide whether it wishes to target low-probability customers who may be less certain about their value due to fewer reviews and consequently have small LBt. Keeping prices low to do so leads to low revenue in the current round, but ignoring low-probability customers by choosing a high price risks losing potentially high per-purchase revenue in the future. By carefully choosing the probability of appearance in our construction, we obtain a tight lower bound.\nOur lower bound proof also provides insights that support the structure of our learning algorithm. If the seller knew the type distribution, he could choose a threshold a priori and only target customer types with probability larger than that threshold. Our proof illustrates that no policy could do essentially better than this thresholding approach: it does not help significantly to dynamically change which types the seller targets based on appearance probability. Our algorithm\nexhibits a similar behavior even though the seller does not know the type distribution: it uses the first phase to discard low-probability types, focusing on the remaining types in the second phase."
        },
        {
            "heading": "1.2 Related work",
            "text": "Learning to price when buyers do not know their values. Learning to price when buyers do not know their values requires new machinery beyond classic pricing algorithms and auction design. Prior works propose different strategies for the seller when the buyers learn through various means. One line of work studies bidding strategies for buyers who do not know their values in auction settings [Feng et al., 2018, Weed et al., 2016, Kandasamy et al., 2023]. Another line of work considers selling repeatedly to a single buyer while the buyer is learning from their own experience at each round [Papadimitriou et al., 2022, Ashlagi et al., 2016, Chawla et al., 2022]. However, a significant limitation in practice is that buyers on online platforms do not necessarily return repeatedly to buy the same item and can only obtain feedback from previous buyers via reviews. In this paper, we study the seller\u2019s pricing strategy when the buyers can only learn from past reviews.\nIfrach et al. [2019] consider a similar pricing problem for the seller when the buyers learn from reviews. However, their model is limited to one buyer type, where the buyers\u2019 values for the item are i.i.d. random variables from a fixed distribution. In contrast, we study the setting where there are multiple buyer types. Moreover, the seller does not know the frequency of each type and the type of buyer who arrives at each round, which leads to crucial difficulties in our analysis.\nLearning to price when buyers know their values. Zhao and Chen [2020] study a setting where the buyers know their values, but the seller does not know the distribution over buyers\u2019 values. Reviews give the seller more information about this distribution than purchase decisions alone would. Zhao and Chen [2020] present an algorithm that uses the (non-noisy) reviews to obtain a O\u0303 ( T 1/2 ) regret bound. In contrast, if the seller only observes purchase decisions and not\nreviews, Kleinberg and Leighton [2003] provide a \u2126 ( T 2/3 ) lower bound. While they show that this\nbound can be improved to \u0398\u0303 ( T 1/2 ) , it requires additional distributional assumptions.\nSelling to no-regret buyers who know their values. In situations where buyers know their values, the buyer may strategically improve their purchase decisions or bidding strategy over repeated interactions to achieve a higher accumulated utility. No-regret learning has been explored as a model of buyer behavior [Braverman et al., 2018, Deng et al., 2019, Nekipelov et al., 2015, Devanur et al., 2014]. In this literature, buyers know their values but may use no-regret algorithms to learn how to bid. In comparison, in this paper, we work with buyers who do not know their values and need to estimate them from historical reviews. This leads to different dynamics. For example, suppose a seller repeatedly sets the Myerson reserve price. In that case, any buyer who knows her value a priori and uses a no-regret algorithm will eventually learn to submit a winning bid. However, a buyer without a reasonable estimate of her value may consider the Myerson price too high and will not buy. Interestingly, a seller dealing with either type of learner may benefit from selling the item for a low price early on, but for two very different reasons. In our setting, this will give buyers of a given type the opportunity to refine their estimated value and will encourage future buyers of the same type to buy at higher prices if their value is indeed high. On the other hand, as Braverman et al. [2018] show, giving items for free to agents who are learning to bid will\naccrue welfare (as long as agents are allowed to overbid), which the algorithm can then extract in future rounds by setting prices that are higher than agent values.\nBuyers\u2019 social learning from reviews. Our work is also related to a rich literature on buyer behavior and social learning from reviews when buyers do not know their values [Ifrach et al., 2019, Boursier et al., 2022, Han and Anderson, 2020, Chamley, 2004, Besbes and Scarsini, 2018, Bose et al., 2006, Crapis et al., 2017, Kakhbod et al., 2021, Acemoglu et al., 2022]. Much of the research on social learning from reviews can be categorized into two groups depending on whether the decision model is Bayesian or non-Bayesian. In the Bayesian model, Ifrach et al. [2019], Acemoglu et al. [2022], and Boursier et al. [2022] study a setting where the buyers decide whether to purchase the item by calculating posterior probabilities about the item\u2019s quality given the past reviews.\nIt may be computationally challenging for buyers to compute Bayesian updates, so several papers relax this assumption [Crapis et al., 2017, Besbes and Scarsini, 2018]. Besbes and Scarsini [2018], for example, study both fully rational Bayesian buyers and buyers with limited rationality who can only observe the average of the past reviews. Under these two extremes, they analyze the conditions under which buyers can recover a product\u2019s true quality based on their observed feedback. Unlike our paper, the buyers have private signals about the item for sale, influencing their purchase decisions. Our model can be seen as situated between these two extremes because the purchase decisions depend on the average of the past reviews and the number of those reviews. Moreover, whereas Besbes and Scarsini [2018] analyze risk-neutral buyers, we study a form of risk aversion where buyers may not purchase even if the price is below the average reviews.\nUnlike this prior research, we do not assume all buyers share a specific decision policy. Instead, we identify a broad family of decision policies under which our results hold. In particular, we only require that the buyer purchases the item if the price is sufficiently low."
        },
        {
            "heading": "2 Notation and online learning setup",
            "text": "In our model, an item is sold repeatedly to a sequence of distinct buyers over a series of T rounds. Each buyer has a type i \u2208 [d], and there is an unknown distribution P over the types [d]. We use the notation qi = Prj\u223cP [j = i] and qmin = mini\u2208[d] qi.\nThe ex-ante value of a buyer with type i \u2208 [d] is \u03b8i \u2208 [0, 1]. If a buyer with type i \u2208 [d] purchases the item, their ex-post value is drawn from a distribution Di with support [0, 1] and mean \u03b8i. The seller knows \u03b81, . . . , \u03b8d but not the distributions P,D1, . . . ,Dd. For ease of analysis, we assume that the seller has ordered the types such that \u03b81 \u2264 \u03b82 \u2264 \u00b7 \u00b7 \u00b7 \u2264 \u03b8d, but the buyers are unaware of this ordering. This assumption is not necessary for the results to hold.\nAt each timestep t \u2208 [T ]:\n1. There is a set \u03c3t\u22121 of reviews which describe past buyers\u2019 types and their ex-post values.\n2. The seller first sets a price pt \u2208 [0, 1].\n3. A buyer arrives with type it \u223c P. They observe the past reviews of buyers with type it: \u03a6it,t = {v : (i, v) \u2208 \u03c3t\u22121 and i = it}. They decide whether to purchase the item using \u03a6it,t. We describe the buyer\u2019s purchasing model in more detail in Section 2.1. Observe that the seller is unaware of the buyer\u2019s type it when they set the price.\n4. If the buyer purchases the item, they pay pt and leave a review of (it, vt) describing both their type and their ex-post value vt \u223c Dit . In this case, \u03c3t = \u03c3t\u22121 \u222a {(it, vt)}, and otherwise, \u03c3t = \u03c3t\u22121.\nOur assumptions and model reflect practical e-commerce settings. First, quite often, it is reasonable to assume that sellers know customers\u2019 ex-ante values as they may have inside information. For instance, a skincare product vendor may know that a particular product works better on some skin types. However, buyers may not simply trust the seller if they were to publish this value, as the seller has every incentive to overstate this value to maximize revenue. A buyer would instead decide if a product is suitable for her via independent reviews from other customers. Second, for fairness reasons, in e-commerce platforms, sellers typically have to publish a single price for all customers and cannot sell the item at individualized prices. Third, if a buyer does not purchase an item, they will not leave a review, and the seller has no way of knowing their type or ex-post value."
        },
        {
            "heading": "2.1 Buyers\u2019 purchasing model",
            "text": "At time step t, the agent\u2019s purchase decision is defined by a threshold \u03c4t(\u03c3t\u22121, it) \u2265 0 that takes as input their type it and the reviews left by past agents. Intuitively, \u03c4t(\u03c3t\u22121, it) represents the agent\u2019s estimate of their value \u03b8it based on past reviews. The agent purchases the item if pt \u2264 \u03c4t(\u03c3t\u22121, it).\nA conservative agent would choose \u03c4t(\u03c3t\u22121, it) to be low in order to always guarantee that \u03c4t(\u03c3t\u22121, it) \u2264 \u03b8it , so that they only purchase when their ex-ante utility is non-negative. An extreme example of this type of conservatism would set \u03c4t(\u03c3t\u22121, it) = 0, meaning that the agent would only purchase the item if offered for free. Optimizing revenue with such a conservative agent would be hopeless. Therefore, we impose the following natural lower bound on \u03c4t(\u03c3t\u22121, it):\nDefinition 2.1. Let \u03a6t \u2286 \u03c3t\u22121 be the reviews left by agents with type it:\n\u03a6t = {v : (i, v) \u2208 \u03c3t\u22121 and i = it} .\nLet LBt be the average of these reviews minus a standard confidence term:\nLBt = 0 if \u03a6t = \u2205,max{ 0, 1|\u03a6t|\u2211v\u2208\u03a6t v \u2212\u221a 12|\u03a6t| ln t\u03b7} else. We say that the agent on round t is \u03b7-pessimistic if, \u03c4t(\u03c3t\u22121, it) \u2265 LBt.\nThis uncertainty term corresponds to the standard confidence interval defined by the Hoeffding bound. Intuitively, as a buyer sees more reviews from his type, this uncertainty decreases, and he is more certain about his ex-ante valuation. The ln t term is necessary to construct a valid confidence interval for an arbitrary algorithm as the data may not be independent (see Appendix A): the algorithm\u2019s price may depend on previous reviews, which in turn will affect future buyers and reviews. This ln t term is not fundamental\u2014the lower bound does not use it.\nIntuitively, the agents can be confident that regardless of the policy used by the seller, with probability 1 \u2212 \u03b7, for all rounds t \u2208 [T ], \u03b8it \u2265 LBt. We prove this formally in Appendix A. Therefore, if the price is lower than LBt, an \u03b7-pessimistic agent will buy the item as they can be confident, based on past reviews, that their ex-ante utility \u03b8it \u2212 pt will be non-negative. This restriction bounds the level of pessimism that the agents can display and thus makes it possible to set reasonable prices. We clip this lower confidence bound at 0 since valuations are always in [0, 1].\nAlgorithm 1: TypeElimination\nInput: Number of timesteps t\u03bb, number of types d, parameter \u03bb \u2208 [0, 1] for t = 1, . . . , t\u03bb do\nSet pt = 0 Buyer with type it arrives and purchases item Buyer leaves review (it, vt), where vt \u223c Dit\nend for i \u2208 [d] do\nSet\nqi = 1\nt\u03bb t\u03bb\u2211 t=1 I(it = i)\n\u25b7 Calculate the fraction of rounds each type appeared end\nSet Q = { i : qi \u2265 3\u03bb4 } \u25b7 Set of types that appeared at least a (3\u03bb/4)-fraction of rounds Output: Q"
        },
        {
            "heading": "2.2 Regret",
            "text": "We define regret as the difference between:\n1. The algorithm\u2019s total expected revenue, and\n2. (baseline) The expected revenue of the optimal fixed price if the agents bought whenever their ex-ante value was larger than the price.\nUnder the baseline that we compete with, both the buyer and the seller are equipped with more information than in the learning problem: the seller knows all distributions P,D1, . . . ,Dd and the buyers know their ex-ante values \u03b81, . . . , \u03b8d. Therefore, the seller knows a priori which customers to target to maximize revenue. Moreover, since the buyers do not need to learn their ex-ante values from reviews, the seller can extract higher revenue than they could from uncertain buyers who may only buy when the price is likely lower than their ex-ante value.\nFormally, let bt \u2208 {0, 1} indicate whether or not the buyer bought on round t \u2208 [T ] and let p\u2217 = argmaxp\u2208[0,1] pPri\u223cP [\u03b8i \u2265 p] be the price with highest expected revenue if the agents bought whenever their ex-ante value was larger than the price. Regret is defined as\nE [RT ] = Tp\u2217 Pr i\u223cP [\u03b8i \u2265 p\u2217]\u2212 E [ T\u2211 t=1 ptbt ] . (1)"
        },
        {
            "heading": "3 Online Pricing Algorithm",
            "text": "This section describes our algorithm, which has two phases: Algorithm 1 and 2. It is defined by a parameter \u03bb > 0. (We will choose \u03bb = d\u22122/3T\u22121/3 to obtain optimal trade-offs).\nOur algorithm has two phases. In the first phase (Algorithm 1), the algorithm sets a price of 0 for t\u03bb = \u0398(ln(dT )/\u03bb) rounds. The agent will buy the item at each round since the price is 0 and leave a review. This allows the algorithm to obtain i.i.d. samples from the type distribution\nAlgorithm 2: Online pricing with reviews\nInput: Number of timesteps T , number of types d, \u03b7 \u2208 [0, 1] such that the agents are \u03b7-pessimistic, parameter \u03bb \u2208 [0, 1] Set t\u03bb def = 32 ln(dT 2) \u03bb + 1 Set St\u03bb+1 = TypeElimination(t\u03bb, d, \u03bb) \u25b7 St is the set of \u201cactive types\u201d for t = t\u03bb + 1, . . . , T do\nfor i \u2208 St do Compute \u03a6it = {vs : (i, vs) \u2208 \u03c3t\u22121} and\nLBit = { 0 if \u03a6it = \u2205 max { 1 |\u03a6it| \u2211 v\u2208\u03a6it v \u2212 \u221a 1 2|\u03a6it| ln T \u03b7 , 0 } else\nend Set price pt = mini\u2208St {min {\u03b8i,LBit}} \u25b7 pt is the smallest LBit or \u03b8i of any active type bt = I(buyer buys at price pt) \u25b7 We prove that if it \u2208 St, then bt = 1 if bt = 1 then\nThe buyer leaves a review (it, vt) where vt \u223c Dit end\nSet \u03c1t = \u221a\nln(dT 2) 2(t\u2212t\u03bb)\nfor i \u2208 St do \u00b5i,t = 1 t\u2212t\u03bb \u2211t s=t\u03bb+1\n\u03b8i \u00b7 I(bs = 1 \u2227 \u03b8is \u2265 \u03b8i \u2227 is \u2208 Q) \u25b7 Estimate of rev (\u03b8i, Q) p\u00b5i,t = \u00b5i,t + \u03c1t \u25b7 Upper confidence bound q\u00b5i,t = \u00b5i,t \u2212 \u03c1t \u25b7 Lower confidence bound end Set i0 = min {i \u2208 St : p\u00b5i,t \u2265 maxk\u2208St q\u00b5k,t} \u25b7 For i < i0, rev (\u03b8i, Q) is likely too small Set St+1 = St \u2229 {i0, i0 + 1, . . . , d} \u25b7 Eliminate types i < i0\nend\nP. In phase 2 (Algorithm 2), i.e, the remaining T \u2212 t\u03bb rounds, the algorithm will ignore types that appeared too rarely during phase 1\u2014in particular, on fewer than a (3\u03bb/4)-fraction of rounds. Intuitively, customers of these types have a low probability of appearance and thus will have more uncertainty about their values due to fewer reviews. The uncertainty term will cause the lower confidence bound LBt in Definition 2.1 to be small. As the seller will have to choose a low price to target these customers (even if their ex-ante value is large), they may have to forego higher revenue from more frequent customer types. Therefore, it is not worthwhile for the algorithm to target these customers. We use Q to denote the buyer types that appeared on at least a (3\u03bb/4)-fraction of rounds.\nTo describe the algorithm\u2019s second phase, we will use the notation\nrev(p,Q) = p Pr i\u223cP\n[\u03b8i \u2265 p and i \u2208 Q] ,\nto denote the expected revenue of a price p restricted to buyers in Q and p\u2217(Q) = argmax rev(p,Q). In this phase, Algorithm 2 will ignore the extremely rare buyers not in Q and aim to set prices that\ncompete with p\u2217(Q). In the analysis, we will show that by competing with p\u2217(Q), Algorithm 2 also competes with the optimal price p\u2217.\nObserve that p\u2217(Q) = \u03b8iQ for some iQ \u2208 Q. On each round t > t\u03bb of the second phase, Algorithm 2 maintains a set St of \u201cactive types\u201d such that iQ is likely in St. Algorithm 2 sets the price pt low enough to ensure that if the current type it is in St, then the buyer will buy. In particular, we define LBit as the largest price the seller can set to ensure a purchase from a buyer of type i. We then set the price pt to be the smallest LBi,t or \u03b8i of any active type i \u2208 St (we include \u03b8i for ease of analysis). If the buyer purchases the item, they leave a review (it, vt) where vt \u223c Dit .\nNext, for each active type i \u2208 St, the seller estimates rev(\u03b8i, Q). We denote this estimate as \u00b5i,t along with upper and lower confidence bounds p\u00b5i,t and q\u00b5i,t. We will describe this estimate more in Section 4. When estimating the revenue for different prices via the averages \u00b5i,t, we only use samples from the second phase. Doing so leads to a cleaner analysis, allowing us to separate the randomness in eliminating low probability types to determine the set Q from the randomness of estimating rev(\u03b8i, Q). However, when constructing the lower confidence bound LBi,t for customers of type i, we use reviews from all rounds. This is to be expected, as customers will use all past reviews when making a purchasing decision.\nAlgorithm 2 defines\ni0 = min { i \u2208 St : p\u00b5i,t \u2265 max\nk\u2208St q\u00b5k,t } to be the smallest active type such that \u03b8i0 may plausibly be p\n\u2217(Q). For all i < i0, the upper confidence bound on rev (\u03b8i, Q) is small (p\u00b5i,t < maxk\u2208St q\u00b5k,t), so it is unlikely that \u03b8i = p\n\u2217(Q). Algorithm 2 concludes round t by eliminating all types i < i0 from the active set."
        },
        {
            "heading": "4 Regret upper bounds",
            "text": "We now state our main upper bounds on regret (Equation (1)).\nTheorem 4.1. Suppose the agents are \u03b7-pessimistic. If qmin \u2264 2\u03bb then\nE[RT ] = O\n( ln(dT )\n\u03bb + Td\u03bb+\n\u221a T ln(dT ) +\n\u221a T\n\u03bb ln\ndT\n\u03b7\n) ,\nand if qmin > 2\u03bb, then\nE[RT ] = O\n( ln(dT )\n\u03bb + \u221a T ln(dT ) +\n\u221a T\nqmin ln\ndT\n\u03b7\n) .\nTheorem 4.1 implies the following corollary for the specific choice of \u03bb = d\u22122/3T\u22121/3.\nCorollary 4.2. Suppose the agents are \u03b7-pessimistic. Setting \u03bb = d\u22122/3T\u22121/3, we have that if qmin \u2264 2d\u22122/3T\u22121/3 then\nE[RT ] = O ( T 2/3d1/3 + T 1/3d1/3 \u221a ln dT \u03b7 + \u221a T ln(dT ) + T 1/3d2/3 ln(dT ) ) ,\nand if qmin > 2d \u22122/3T\u22121/3, then\nE[RT ] = O\n(\u221a T\nqmin ln\ndT\n\u03b7 + T 1/3d2/3 ln(dT )\n) .\nWe note that while the worst-case regret scales with T 2/3, it improves to \u221a T when all types appear with large enough probability since customers of all types will be able to form accurate estimates of their values quickly. We emphasize that our algorithm and analysis are markedly different from explore-then-commit (ETC) style algorithms in stochastic bandit settings, which share a similar two-phase strategy and have T 2/3 regret. First, the first \u2018explore\u2019 phase of ETC algorithms is much longer (typically O\u0303(T 2/3) rounds) than our Phase 1, which lasts only O\u0303(T 1/3) rounds. ETC algorithms also focus on learning all unknowns in their first phase, while here, its only purpose is to eliminate low probability types. Second, in the \u2018commit\u2019 phase of ETC algorithms, typically, no learning is required, while in our second phase, the algorithm is still learning the optimal price. Third, unlike our algorithm, ETC algorithms cannot obtain \u221a T regret even under favorable conditions [Garivier et al., 2016]. Fourth, we reiterate that the T 2/3 worst-case regret is due to the uncertainty on the buyers\u2019 side, which is a challenge specific to our setting.\nWe will first provide an overview of our proof, with the full proof to follow in Section 4.1.\nProof sketch of Theorem 4.1. The terms of our regret bounds in Theorem 4.1 arise from the following steps of our analysis. The first phase immediately contributes O ( ln(dT )\n\u03bb\n) to the regret since\nthe item is sold for free during that phase. At the end of the first phase, Algorithm 1 discards the types that appeared too infrequently, resulting in a set Q, and only aims to maximize revenue over Q. When qmin \u2264 2\u03bb, we prove that competing with p\u2217(Q) rather than p\u2217([d]) contributes Td\u03bb to the regret. Meanwhile, when qmin > 2\u03bb, we prove that with high probability, Q = [d], and thus p\u2217(Q) = p\u2217([d]), so there is no impact on regret.\nIn order to gradually learn a price that competes with p\u2217(Q), Algorithm 2 maintains estimates \u00b5i,t of rev(\u03b8i, Q) = \u03b8i Prj\u223cP [\u03b8j \u2265 \u03b8i and j \u2208 Q] for the active types i \u2208 St. The error of these estimates contributes a factor of O (\u221a T ln(dT ) ) to the regret. This step of the analysis takes some care because we cannot observe at each round t whether or not it \u2208 Q, provided the buyer did not buy the item. If we were able to observe whether it \u2208 Q, we could simply set\n\u00b5i,t = 1\nt\u2212 t\u03bb t\u2211 s=t\u03bb+1 \u03b8i \u00b7 I(\u03b8is \u2265 \u03b8i and is \u2208 Q),\nand the concentration would follow from a Hoeffding bound. Instead, we set\n\u00b5i,t = 1\nt\u2212 t\u03bb t\u2211 s=t\u03bb+1 \u03b8i \u00b7 I(bs = 1, \u03b8is \u2265 \u03b8i, and is \u2208 Q),\nbut nonetheless prove that it is a good estimate of rev (\u03b8i, Q). To do so, we show that for all active types i \u2208 St and all rounds s \u2264 t of Algorithm 2,\nI(\u03b8is \u2265 \u03b8i and is \u2208 Q) = I(bs = 1, \u03b8is \u2265 \u03b8i, and is \u2208 Q), (2)\nso we can still apply a Hoeffding bound (taking into account that the set St is a random variable). If bs = 1, then clearly Equation (2) holds. Otherwise, is \u0338\u2208 Ss because any buyer in Ss will always\nbuy. We show that this means that either is \u0338\u2208 Q or\u2014based on the way that types are eliminated from the active sets\u2014\u03b8is < \u03b8i, so Equation (2) holds in this case as well.\nFinally, the agents themselves are learning as the algorithm progresses, which increases the regret since our benchmark is the expected revenue of the optimal price if the agents buy whenever their ex-ante value is larger than the price. When qmin \u2264 2\u03bb, the fact that the agents are learning contributes O (\u221a T \u03bb ln dT \u03b7 ) to the regret and when qmin > 2\u03bb, it contributes O (\u221a T qmin ln dT\u03b7 ) ."
        },
        {
            "heading": "4.1 Proof of the regret upper bound (Theorem 4.1)",
            "text": "In this section, we prove Theorem 4.1. The proof relies on a handful of helper lemmas which we prove in Appendix B.\nProof of Theorem 4.1. In this proof, on each round t > t\u03bb, we use the notation p \u2032 t = mini\u2208St \u03b8i. We split the regret into five terms as follows:\nRT = T\u2211 t=1 p\u2217([d])I (\u03b8it \u2265 p\u2217([d]))\u2212 T\u2211 t=1 ptbt = Z1 + Z2 + Z3 + Z4 + Z5.\nThe first term Z1 = p \u2217([d])t\u03bb \u2264 32 ln(dT 2) \u03bb + 1 measures the revenue lost from offering the item for free for the first t\u03bb rounds. The second term\nZ2 = \u2211 t>t\u03bb p\u2217([d])I (\u03b8it \u2265 p\u2217([d]))\u2212 \u2211 t>t\u03bb p\u2217([d])I (\u03b8it \u2265 p\u2217([d]) and it \u2208 Q)\n= \u2211 t>t\u03bb p\u2217([d])I (\u03b8it \u2265 p\u2217([d]) and it \u0338\u2208 Q)\nrelates to the revenue lost due to the fact that we only aim to compete with the optimal price for relatively-common types\u2014namely those in Q\u2014as does the third term\nZ3 = \u2211 t>t\u03bb p\u2217([d])I (\u03b8it \u2265 p\u2217([d]) and it \u2208 Q)\u2212 \u2211 t>t\u03bb p\u2217(Q)I (\u03b8it \u2265 p\u2217(Q) and it \u2208 Q) .\nThe fourth term Z4 = \u2211 t>t\u03bb p\u2217(Q)I (\u03b8it \u2265 p\u2217(Q) and it \u2208 Q)\u2212 \u2211 t>t\u03bb p\u2032tI ( \u03b8it \u2265 p\u2032t and it \u2208 Q ) relates the cumulative revenue of the optimal price over Q\u2014that is, p\u2217(Q)\u2014to the cumulative revenue of the \u201cproxy\u201d price p\u2032t = mini\u2208St \u03b8i. Finally, the last term\nZ5 = \u2211 t>t\u03bb p\u2032tI ( \u03b8it \u2265 p\u2032t and it \u2208 Q ) \u2212 \u2211 t>t\u03bb ptbt\nrelates the cumulative revenue of the proxy price p\u2032t to the algorithm\u2019s cumulative revenue. In the following claims, we bound Z2, Z3, Z4, and Z5. The full proofs are in Appendix B.\nClaim 4.3. If qmin \u2264 2\u03bb then E[Z2] \u2264 Td\u03bb+ 1 and if qmin > 2\u03bb, then E[Z2] \u2264 1.\nProof sketch of Claim 4.3. First, we bound Z2 as follows: Z2 = \u2211 t>t\u03bb p\u2217([d])I (\u03b8it \u2265 p\u2217([d]) and it \u0338\u2208 Q) \u2264 \u2211 t>t\u03bb p\u2217([d])I (it \u0338\u2208 Q) \u2264 \u2211 t>t\u03bb I (it \u0338\u2208 Q) . Recall from Algorithm 1 that qi is the fraction of times that type i appears in phase 1 and let G be the event that for all i \u2208 [d] such that qi \u2265 \u03bb, we have that qi \u2265 3\u03bb4 , which means that i \u2208 Q. In other words, when G happens, [d] \\Q \u2286 {qi : qi < \u03bb}. In Lemma B.1, we prove that Pr[Gc] \u2264 1T , so E[Z2] \u2264 E[Z2 | G] + T Pr[Gc] \u2264 E[Z2 | G] + 1.\nNext, since Q is a random variable, we condition on it as well: E[Z2 | G] = \u2211\nQ\u2032\u2286[d]\nE[Z2 | Q = Q\u2032,G] Pr[Q = Q\u2032 | G].\nIf [d] \\Q\u2032 \u0338\u2286 {qi : qi < \u03bb}, then Pr[Q = Q\u2032 | G] = 0. For any Q\u2032 such that [d] \\Q\u2032 \u2286 {qi : qi < \u03bb}, we prove\nE[Z2 | Q = Q\u2032,G] = \u2211 t>t\u03bb \u2211 i \u0338\u2208Q\u2032 Pr [it = i] .\nIf qmin \u2264 2\u03bb, then \u2211 t>t\u03bb \u2211 i \u0338\u2208Q\u2032 Pr [it = i] \u2264 \u2211 t>t\u03bb \u2211 i \u0338\u2208Q\u2032 \u03bb \u2264 Td\u03bb,\nwhich implies that E[Z2] \u2264 Td\u03bb+ 1. The case where qmin > 2\u03bb follows similarly.\nClaim 4.4. E[Z3] \u2264 0.\nProof sketch of Claim 4.4. In this proof we bound Z3 = \u2211 t>t\u03bb p\u2217([d])I (\u03b8it \u2265 p\u2217([d]) and it \u2208 Q)\u2212 \u2211 t>t\u03bb p\u2217(Q)I (\u03b8it \u2265 p\u2217(Q) and it \u2208 Q) . (3)\nWe begin by conditioning the first term of Equation (3) on Q since it is a random variable:\nE [\u2211 t>t\u03bb p\u2217([d])I (\u03b8it \u2265 p\u2217([d]) and it \u2208 Q) ] = \u2211\nQ\u2032\u2286[d] \u2211 t>t\u03bb p\u2217([d]) Pr [ \u03b8it \u2265 p\u2217([d]) and it \u2208 Q\u2032 | Q = Q\u2032 ] Pr[Q = Q\u2032]\n\u2264 \u2211\nQ\u2032\u2286[d]\n(T \u2212 t\u03bb) p\u2217(Q\u2032) Pr i\u223cP\n[ \u03b8i \u2265 p\u2217(Q\u2032) and i \u2208 Q\u2032 ] Pr[Q = Q\u2032], (4)\nwhere the final inequality follows from the definition of p\u2217(Q\u2032). Next, for the second term of Equation (3),\nE [\u2211 t>t\u03bb p\u2217(Q)I (\u03b8it \u2265 p\u2217(Q) and it \u2208 Q) ]\n= \u2211\nQ\u2032\u2286[d]\nE [\u2211 t>t\u03bb p\u2217(Q\u2032)I ( \u03b8it \u2265 p\u2217(Q\u2032) and it \u2208 Q\u2032 ) | Q = Q\u2032 ] Pr[Q = Q\u2032]\n= \u2211\nQ\u2032\u2286[d]\n(T \u2212 t\u03bb) p\u2217(Q\u2032) Pr i\u223cP\n[ \u03b8i \u2265 p\u2217(Q\u2032) and i \u2208 Q\u2032 ] Pr[Q = Q\u2032].\nCombined with Equation (4), we have that E[Z3] \u2264 0. Claim 4.5. E[Z4] \u2264 5 + 4 \u221a 2T ln(dT 2).\nProof sketch of Claim 4.5. In this claim, we bound Z4 = \u2211 t>t\u03bb p\u2217(Q)I (\u03b8it \u2265 p\u2217(Q) and it \u2208 Q)\u2212 \u2211 t>t\u03bb p\u2032tI ( \u03b8it \u2265 p\u2032t and it \u2208 Q ) (5)\nwhere p\u2032t = mini\u2208St \u03b8i. Beginning with the first term of this equation, we prove that\u2211 t>t\u03bb E [p\u2217(Q)I (\u03b8it \u2265 p\u2217(Q) and it \u2208 Q)] = \u2211 t>t\u03bb E [rev(p\u2217(Q), Q)] . (6)\nMoving on to the second term of Equation (5), we prove that for any t > t\u03bb, E [ p\u2032tI ( \u03b8it \u2265 p\u2032t and it \u2208 Q )] = E [ rev ( p\u2032t, Q )] . (7)\nCombining Equations (6) and (7), we have that E[Z4] \u2264 \u2211 t>t\u03bb E [ rev (p\u2217(Q), Q)\u2212 rev ( p\u2032t, Q )] . (8)\nNext, for all t > t\u03bb, let Bt be the event that:\n1. iQ \u2208 St and\n2. rev(p\u2217(Q), Q)\u2212 rev (p\u2032t, Q) \u2264 4\u03c1t\u22121 (where \u03c1t\u03bb = 1).\nAlso, let Ct = \u22c2t\ns=t\u03bb+1 Bs. In Lemma B.2, we prove that Pr [Cct ] \u2264 1T . By Equation (8),\nE[Z4] \u2264 E [\u2211 t>t\u03bb rev (p\u2217(Q), Q)\u2212 rev ( p\u2032t, Q ) \u2223\u2223\u2223\u2223\u2223 CT ] + T Pr [CcT ] \u2264 \u2211 t>t\u03bb 4\u03c1t\u22121 + 1\nwhich implies the result. Claim 4.6. If qmin \u2264 2\u03bb, then E[Z5] \u2264 4 \u221a 2T \u03bb ln dT 2 \u03b7 +3 and if qmin > 2\u03bb, E[Z5] \u2264 4 \u221a T qmin ln dT 2 \u03b7 +2.\nProof sketch of Claim 4.6. On each round t > t\u03bb, recall that\nLBit = { 0 if \u03a6it = \u2205 max { 1 |\u03a6it| \u2211 v\u2208\u03a6it v \u2212 \u221a 1 2|\u03a6it| ln T \u03b7 , 0 } else.\nLet jt = argminj\u2208St \u03b8j , so p \u2032 t = \u03b8jt . We prove that\nZ5 \u2264 \u2211 t>t\u03bb p\u2032tI ( \u03b8it \u2265 p\u2032t \u2227 it \u2208 Q \u2227 bt = 0 ) + \u2211 t>t\u03bb (p\u2032t \u2212 pt)bt.\nSince pt \u2264 p\u2032t, we have that Z5 \u2264 \u2211 t>t\u03bb p\u2032tI ( \u03b8it \u2265 p\u2032t \u2227 it \u2208 Q \u2227 bt = 0 ) + \u2211 t>t\u03bb ( p\u2032t \u2212 pt ) .\nBy definition of the pricing rule, if it \u2208 St, then bt = 1. Therefore, if bt = 0, then either it \u0338\u2208 Q or it \u2208 Q \\ St. Since St contains every i \u2208 Q with i > jt, we can conclude that if it \u2208 Q \\ St, then \u03b8it < \u03b8jt = p \u2032 t. Therefore, I (\u03b8it \u2265 p\u2032t \u2227 it \u2208 Q \u2227 bt = 0) = 0, which means that\nE [Z5] \u2264 E [\u2211 t>t\u03bb p\u2032t \u2212 pt ] .\nLet j\u2032t = argminj\u2208St LBjt, which means that pt = mini\u2208St {min {\u03b8i,LBit}} = min { p\u2032t,LBj\u2032tt } .\nWe also know that p\u2032t = \u03b8jt \u2264 \u03b8j\u2032t . Therefore,\nE [Z5] \u2264 E [\u2211 t>t\u03bb max { 0, \u03b8j\u2032t \u2212 LBj\u2032tt }] .\nLet E1 be the event that for all t > t\u03bb, |\u03a6i,t| \u2265 12qmin(t \u2212 1) for all i \u2208 St. In Lemma B.4, we prove that if qmin > 2\u03bb, then Pr [Ec1] \u2264 1T . Also, let H be the event that for all t > t\u03bb and all i \u2208 St,\n|\u03a6it|\u03b8i \u2264 \u2211 v\u2208\u03a6it v +\n\u221a 1\n2 |\u03a6it| ln(dT 2).\nIn Lemma B.7, we prove that Pr[Hc] \u2264 1T . Suppose that qmin > 2\u03bb. In this case,\nE [Z5] \u2264 E [\u2211 t>t\u03bb max { 0, \u03b8j\u2032t \u2212 LBj\u2032tt } \u2223\u2223\u2223\u2223\u2223 E1 \u2227H ] + 2\n= E \u2211 t>t\u03bb max 0, \u03b8j\u2032t \u2212 1|\u03a6j\u2032tt| \u2211\nv\u2208\u03a6j\u2032tt\nv +\n\u221a 1\n2|\u03a6j\u2032tt| ln\n1\n\u03b7  \u2223\u2223\u2223\u2223\u2223\u2223\u2223 E1 \u2227H + 2. Under events E1 and H,\nE[Z5] \u2264 E [\u2211 t>t\u03bb \u221a ln(dT 2) 2|\u03a6j\u2032tt| + \u221a 1 2|\u03a6j\u2032tt| ln 1 \u03b7 \u2223\u2223\u2223\u2223\u2223 E1 \u2227H ] + 2\nand by definition of the event E1,\nE[Z5] \u2264 E [\u2211 t>t\u03bb \u221a ln(dT 2) 2|\u03a6j\u2032tt| + \u221a 1 2|\u03a6j\u2032tt| ln 1 \u03b7 \u2223\u2223\u2223\u2223\u2223 E1 \u2227H ] + 2\n\u2264 T\u2211 t=2\n(\u221a ln(dT 2)\nqmin(t\u2212 1) +\n\u221a 1\nqmin(t\u2212 1) ln\n1\n\u03b7\n) + 2 \u2264 4 \u221a T\nqmin ln\ndT 2\n\u03b7 + 2.\nThe proof when qmin < 2\u03bb follows similarly.\nThe final regret bound follows by combining these claims.\nWe conclude this section by providing a proof sketch of one of the lemmas we used in Theorem 4.1. The full proof and the remaining lemmas are in Appendix B. This lemma shows that for all active types i \u2208 St, \u00b5i,t is indeed a good estimate of rev (\u03b8i, Q) = \u03b8i Prj\u223cP [\u03b8j \u2265 \u03b8i and j \u2208 Q]. As we described in the proof sketch of Theorem 4.1, this takes some care because we cannot observe at each round t whether or not it \u2208 Q, provided the buyer did not buy the item.\nLemma 4.7. For all t > t\u03bb, let At be the event rev (\u03b8i, Q) \u2208 [q\u00b5i,t, p\u00b5i,t] for all i \u2208 St. Then Pr[Act ] \u2264 1T 2 .\nProof sketch. Recall that p\u00b5i,t = \u00b5i,t + \u03c1t and q\u00b5i,t = \u00b5i,t \u2212 \u03c1t with\n\u03c1t =\n\u221a ln(dT 2)\n2 (t\u2212 t\u03bb) .\nWe also define the related quantities for all i \u2208 [d] and all Q\u2032 \u2286 [d]:\n\u03b3i,t(Q \u2032) =\n1\nt\u2212 t\u03bb t\u2211 s=t\u03bb+1 \u03b8i \u00b7 I ( \u03b8is \u2265 \u03b8i \u2227 is \u2208 Q\u2032 ) ,\np\u03b3i,t(Q \u2032) = \u03b3i,t(Q \u2032) + \u03c1t, and q\u03b3i,t(Q \u2032) = \u03b3i,t(Q \u2032) \u2212 \u03c1t. By a Hoeffding bound, for all Q\u2032 \u2286 [d] and i \u2208 [d],\nPr [ rev ( \u03b8i, Q \u2032) \u0338\u2208 [q\u03b3i,t(Q\u2032), p\u03b3i,t(Q\u2032)]] \u2264 1 dT 2 .\nWe claim that for any i \u2208 St and any s > t\u03bb,\nI(bs = 1 \u2227 \u03b8is \u2265 \u03b8i \u2227 is \u2208 Q) = I (\u03b8is \u2265 \u03b8i \u2227 is \u2208 Q) , (9)\nwhich means that \u00b5i,t = \u03b3i,t(Q), p\u00b5i,t = p\u03b3i,t(Q), and q\u00b5i,t = q\u03b3i,t(Q). To see why, if bs = 1, then clearly Equation (9) holds. Otherwise, suppose bs = 0, in which case I(bs = 1 \u2227 \u03b8is \u2265 \u03b8i \u2227 is \u2208 Q) = 0. Then is \u0338\u2208 Ss because any buyer in Ss will always buy by the definition of the pricing rule. Let js = min {j \u2208 Ss} . Since Ss contains every element in Q larger than js, we know that either:\n1. is \u0338\u2208 Q, in which case I (\u03b8is \u2265 \u03b8i \u2227 is \u2208 Q) = 0, or\n2. is \u2208 Q but is \u0338\u2208 Ss, which means that \u03b8is < \u03b8js . Since i \u2208 St, it must be that i \u2208 Ss, so \u03b8is < \u03b8js \u2264 \u03b8i. In this case, I (\u03b8is \u2265 \u03b8i \u2227 is \u2208 Q) = 0 as well.\nTherefore, Equation (9) holds. The fact that \u00b5i,t = \u03b3i,t(Q), p\u00b5i,t = p\u03b3i,t(Q), and q\u00b5i,t = q\u03b3i,t(Q) for all i \u2208 St implies that\nPr[Act ] = Pr (\u2203i \u2208 St s.t. rev (\u03b8i, Q) \u0338\u2208 [q\u00b5i,t, p\u00b5i,t]) \u2264 Pr (\u2203i \u2208 [d] s.t. rev (\u03b8i, Q) \u0338\u2208 [q\u03b3i,t(Q), p\u03b3i,t(Q)])\n\u2264 d\u2211\ni=1\nPr (rev (\u03b8i, Q) \u0338\u2208 [q\u03b3i,t(Q), p\u03b3i,t(Q)]) . (10)\nThe result now follows from a union bound."
        },
        {
            "heading": "5 Regret lower bounds",
            "text": "In this section, we state our regret lower bounds. Recall that qmin = mini\u2208[d] Prj\u223cP [j = i] denotes the minimum probability of appearance among all types. Let RT (A,P ) denote the regret after T rounds when using an algorithm A on a problem P . Our theorem below presents two lower bounds that correspond to our upper bounds. First, we prove a qmin independent \u2126\u0303 ( T 2/3d1/3 ) lower bound\non the regret. Next, when qmin is large, we show that \u2126\u0303 (\u221a T/qmin ) regret is still unavoidable.\nTheorem 5.1. For T \u2208 \u2126 ( d (ln(1/\u03b7))2 (ln d)3/2 ) ,\ninf A sup P\nRT (A,P ) \u2265 1\n4 T\n2/3(d\u2212 1)1/3 ( ln 1\n\u03b7\n)1/3 \u2212 2T 1/2 \u2208 \u2126 ( T 2/3d 1/3 ( ln 1\n\u03b7\n)1/3) .\nNext, suppose qmin \u2265 q0T def = T\u22121/3(d\u2212 1)\u22122/3 (ln (1/\u03b7))1/3. Then for T \u2208 \u2126\n( d (ln(1/\u03b7))2 (ln d)3/2 ) ,\ninf A sup P ; qmin\u2265q0T\nRT (A,P ) \u2265 1\n4\n\u221a T\nqmin ln\n1 \u03b7 \u2212 2T 1/2 \u2208 \u2126\n(\u221a T\nqmin ln\n1\n\u03b7\n) .\nComparing this with Corollary 4.2, we see that our algorithm is minimax optimal, up to constants and polylog terms. This is the case even when qmin is larger than \u2126\u0303(T\n\u22121/3d\u22122/3) where\u221a T rates are possible. As we mentioned at the end of Section 1.1, our proof reveals interesting properties about the structure of an optimal policy; we discuss these in detail at the end of this section.\nProof of Theorem 5.1. Unlike typical proofs of lower bounds in stochastic bandit settings, which usually rely on hypothesis testing arguments, our result stems from the buyers\u2019 uncertainty about their values. To demonstrate this, we will construct a representative problem instance and show that any algorithm will do poorly on this instance.\nConstruction. For all types j \u2208 [d], we set the ex-post value distribution to be Dj = Unif(1 \u2212 2/ \u221a T , 1). Hence, for all j \u2208 [d], \u03b8j = 1\u2212 1/ \u221a T . Next, we define the type distribution P as shown below. Here q < 1/d is a parameter we will specify later in the proof.\n\u2200 j \u2208 {1, . . . , d\u2212 1}, qj = Pr i\u223cP [i = j] = q, qd = Pr i\u223cP [i = d] = 1\u2212 q(d\u2212 1). (11)\nWe will use the following threshold functions for each buyer of each type. Recall that \u03a6i,t\u22121 = {v; (i, v) \u2208 \u03c3t\u22121} denotes the reviews in \u03c3t\u22121 left by customers of type i.\n\u03c4t(\u03c3t\u22121, i) = max  1|\u03a6i,t\u22121| \u2211 v\u2208\u03a6i,t\u22121 v \u2212 \u221a 1 2|\u03a6i,t\u22121| ln 1 \u03b7 , 0  . Note that \u03c4t(\u03c3t\u22121, it) is larger than LBt as defined in Definition 2.1 and satisfies the \u03b7\u2212pessimistic agents\u2019 assumption. We will also assume that the seller knows the type distribution P; this additional information can only help the seller. Despite this, we show that if buyers choose conservative threshold functions, T 2/3 regret is unavoidable.\nThe optimal price for the above construction is p\u2217 = \u03b81 = \u00b7 \u00b7 \u00b7 = \u03b8d = 1 \u2212 1/ \u221a T . The seller could simply set this price if all buyers knew their ex-ante values. However, when buyers learn their values from past observations, the confidence of their estimates shrinks only with the number of observations of their type. In particular, if q is very small, then a seller might find it beneficial to ignore customers of the first d\u2212 1 types and set the highest possible price that can still attract customers of type d. On the other hand, if q is large, the higher price may not warrant the revenue foregone by ignoring the first d\u22121 types. By carefully choosing q, we can balance these trade-offs to obtain the tightest lower bound. We have set the value of all types to be equal in this construction to simplify some of our calculations, but it is not hard to see how this phenomenon affects pricing decisions for the seller.\nSet up and notation. For brevity, we use the following notation for the sample mean of observations, the number of observations, and the threshold function for type i on round t.\npEi,t\u22121 def =\n1 |\u03a6i,t\u22121| \u2211\nv\u2208\u03a6i,t\u22121\nv, N\u0303i,t\u22121 def = |\u03a6i,t\u22121|,\n\u03c4i,t def = \u03c4t(\u03c3t\u22121, i) = max { pEi,t\u22121 \u2212 \u221a 1\n2N\u0303i,t\u22121 ln\n( 1\n\u03b7\n) , 0 } . (12)\nNext, let \u03c4 \u2032t denote the maximum of the threshold functions of the first d\u2212 1 types on round t and i\u2032t denote the corresponding maximizer.\ni\u2032t = argmax j\u2208{1,...,d\u22121} \u03c4j,t, \u03c4 \u2032 t = \u03c4i\u2032t,t. (13)\nRecall that on each round t, a seller\u2019s policy chooses a price pt based on all past information \u03c3t\u22121 and possibly some source of external randomness. We next define W1,t,W2,t,W3,t below based on how pt compares to the threshold functions:\nW1,t = I(pt \u2264 \u03c4 \u2032t), W2,t = I(\u03c4 \u2032t < pt \u2264 \u03c4d,t), W3,t = I(\u2200 j \u2208 [d], \u03c4j,t < pt). (14)\nHere, W1,t is 1 when the price pt is smaller than the thresholds for any of the first d \u2212 1 types, W2,t is 1 when pt is larger than the thresholds for all d \u2212 1 types but smaller than the threshold \u03c4d,t for type d (note that W2,t can be 1 only when \u03c4 \u2032 t < \u03c4d,t), and W3,t is 1 when pt is larger than all thresholds. It is easy to verify that exactly one of W1,t,W2,t,W3,t is 1 on any given round.\nLower bounding the instantaneous regret. We can decompose the expected revenue revt = ptbt on round t, conditioned on the price pt and history \u03c3t\u22121 as follows.\nE[revt|\u03c3t\u22121, pt] = E[ptbt|\u03c3t\u22121, pt] = \u2211 i\u2208[d] pt E[bt|\u03c3t\u22121, pt, it = i] Pr[it = i|\u03c3t\u22121, pt]\n= \u2211 i\u2208[d] pt1(pt \u2264 \u03c4i,t)qi\n= \u2211\ni\u2208[(d\u22121)]\npt1(pt \u2264 \u03c4i,t)q + pt1(pt \u2264 \u03c4d,t)qd. (15)\nIn the third step we have used the fact that that the probability of appearance of a type does not depend on the history or the price chosen, hence Pr[it = i|\u03c3t\u22121, pt] = Prj\u223cP [j = i] = qi. Second, we note that for a customer of type i, they will purchase if and only if the price is smaller than their threshold; therefore E[bt|\u03c3t\u22121, pt, it = i] = 1(pt \u2264 \u03c4i,t). The following lemma upper bounds E[revt|pt] in terms of the Wi,t terms defined in (14). Lemma 5.2. E[revt|\u03c3t\u22121, pt] \u2264 W1,t\u03c4 \u2032t +W2,tqd\u03c4d,t.\nProof of Lemma 5.2. We will consider four exhaustive cases for pt and analyze the right-hand side of the inequality in the claim as a function of W1,t and W2,t, which we denote as RHS(W1,t,W2,t).\n1. pt \u2264 min {\u03c4 \u2032t , \u03c4d,t}: Here, W1,t = 1 and W2,t = 0. Using (15), we obtain E[revt|pt] \u2264 (d \u2212 1)ptq + ptqd = pt \u2264 \u03c4 \u2032t = RHS(1, 0).\n2. \u03c4 \u2032t < pt \u2264 \u03c4d,t: Here, W1,t = 0 and W2,t = 1. Using (15), E[revt|pt] = ptqd \u2264 \u03c4d,tqd = RHS(0, 1).\n3. \u03c4d,t < pt \u2264 \u03c4 \u2032t : Here, W1,t = 1 and W2,t = 0. Using (15), we obtain\nE[revt|pt] \u2264 pt(d\u2212 1)q < pt \u2264 \u03c4 \u2032t = RHS(1, 0).\nSome of terms in the first summation in (15) may be 0, but we can bound it by pt(d \u2212 1)q regardless.\n4. pt > max {\u03c4 \u2032t , \u03c4d,t}: Here, W1,t = W2,t = 0. Using (15), E[revt|pt] = 0 = RHS(0, 0).\nEquipped with this lemma, we can now lower bound the instantaneous regret on round t conditioned on the price pt and history \u03c3t\u22121, which we denote as E[rt|\u03c3t\u22121, pt]:\nE[rt|\u03c3t\u22121, pt] = E[p\u2217 \u2212 revt|\u03c3t\u22121, pt] \u2265 W1,t \u00b7 (p\u2217 \u2212 \u03c4 \u2032t) +W2,t \u00b7 (p\u2217(d\u2212 1)q + qd(p\u2217 \u2212 \u03c4d,t)) +W3,t \u00b7 p\u2217. (16)\nRecall that i\u2032t is the index such that \u03c4 \u2032 t = \u03c4i\u2032t,t as defined in (13) and N\u0303i\u2032t,t\u22121 is the number of observations of type i\u2032t in \u03c3t\u22121 as defined in (12). We can further lower bound Equation (16) by using the fact that\np\u2217 \u2212 \u03c4 \u2032t = p\u2217 \u2212 \u03c4i\u2032t,t = p \u2217 \u2212max { pEi\u2032t,t\u22121 \u2212 \u221a 1\n2N\u0303i\u2032t,t\u22121 ln\n( 1\n\u03b7\n) , 0 } . (17)\nSince the support of each ex-post value distribution is bounded within an \u00b11/ \u221a T interval of p\u2217, Equation (17) implies that\np\u2217 \u2212 \u03c4 \u2032t \u2265 p\u2217 \u2212max\n{ p\u2217 +\n1\u221a T\n\u2212 \u221a\n1\n2N\u0303i\u2032t,t\u22121 ln\n( 1\n\u03b7\n) , 0 }\n= min\n{\u221a 1\n2N\u0303i\u2032t,t\u22121 ln\n( 1\n\u03b7\n) \u2212 1\u221a\nT , p\u2217\n}\n= min\n{\u221a 1\n2N\u0303i\u2032t,t\u22121 ln\n( 1\n\u03b7\n) , 1 } \u2212 1\u221a\nT . (18)\nThe same argument guarantees that p\u2217\u2212\u03c4d,t \u2265 \u2212 1\u221aT . Combining this inequality with Equations (16) and (17), and recalling that W1,t +W2,t +W3,t = 1, we have that\nE[rt|\u03c3t\u22121, pt] \u2265 W1,tmin\n{\u221a 1\n2N\u0303i\u2032t,t\u22121 ln\n( 1\n\u03b7\n) , 1 } +W2,tp\n\u2217(d\u2212 1)q +W3,tp\u2217 \u2212 1\u221a T . (19)\nUpper bounding N\u0303i\u2032t,t\u22121. To convert the above instantaneous bound to a lower bound on the cumulative regret, we will need to control N\u0303i\u2032t,t\u22121 which counts the number of reviews in \u03c3t\u22121 by customers of type i\u2032t. Observing that i \u2032 t \u2208 [(d \u2212 1)] which means that the appearance probability of i\u2032t is q, we define the following event E below. Lemma 5.3 upper bounds the probability of this event.\nE = { \u2200 j \u2208 [(d\u2212 1)],\u2200 t \u2264 T, N\u0303j,t\u22121 \u2264 2q(T \u2212 1) } . (20)\nLemma 5.3. Let T \u2265 3q ln(2d) + 1. Then, Pr[E ] \u2265 1/2.\nProof of Lemma 5.3. Note that\nN\u0303i,t\u22121 = t\u22121\u2211 s=1 1(bs = 1, is = i)\ncounts the number of times a customer of type i made a purchase. Let\nNi,t\u22121 = t\u22121\u2211 s=1 1(is = i)\nbe the number of times a customer of type i arrived. Since Ni,T\u22121 \u2265 N\u0303i,t\u22121, the Chernoff bound implies that\nPr[\u2203t \u2264 T such that N\u0303i,t\u22121 > 2q(T \u2212 1)] \u2264 Pr[Ni,T\u22121 > 2q(T \u2212 1)] \u2264 exp ( q(T \u2212 1)\n3\n) \u2264 1\n2d .\nThe last step uses the condition on T . The claim follows via a union bound over j \u2208 [d\u2212 1].\nLower bound on cumulative regret. We are now ready to lower bound regret. By Equation (19),\nE[RT ] \u2265 E  T\u2211 t=1 ( W1,tmin {\u221a 1 2N\u0303i\u2032t,t\u22121 ln ( 1 \u03b7 ) , 1 } +W2,tp\n\u2217(d\u2212 1)q +W3,tp\u2217\ufe38 \ufe37\ufe37 \ufe38 rt \u2212 1\u221a T ) . Conditioning on the event E ,\nE[RT ] \u2265 \u2212 \u221a T + E [ T\u2211 t=1 rt \u2223\u2223\u2223\u2223\u2223 E ] Pr[E ] + E [ T\u2211 t=1 rt \u2223\u2223\u2223\u2223\u2223 Ec ] Pr[Ec]\nand by Lemma 5.3,\nE[RT ] \u2265 \u2212 \u221a T + 1\n2 E [ T\u2211 t=1 rt \u2223\u2223\u2223\u2223\u2223 E ] \u2212 T \u00b7 1\u221a T\n\u2265 \u22122 \u221a T + 1\n2 E [ T\u2211 t=1 W1,tmin {\u221a 1 4qT ln ( 1 \u03b7 ) , 1 } +W2,tp \u2217(d\u2212 1)q +W3,tp\u2217 \u2223\u2223\u2223\u2223\u2223 E ] .\nFor T > 14q ln ( 1 \u03b7 ) ,\nE[RT ] \u2265 \u22122 \u221a T + 1\n2 E [ T\u2211 t=1 W1,t \u221a 1 4qT ln ( 1 \u03b7 ) +W2,tp \u2217(d\u2212 1)q +W3,tp\u2217 \u2223\u2223\u2223\u2223\u2223 E ] .\nWe will use the notation Mi,t = \u2211t\ns=1Wi,s for i \u2208 {1, 2, 3} which counts the number of times each Wi,s was 1 in the first t rounds. Note that M1,t+M2,t+M3,t = t since exactly one of W1,s,W2,s,W3,s is 1 on any round s. With this notation, we have that\nE[RT ] \u2265 \u22122 \u221a T + 1\n2 E\n[ M1,T \u221a 1\n4qT ln\n( 1\n\u03b7\n) +M2,T p \u2217(d\u2212 1)q +M3,T p\u2217 \u2223\u2223\u2223\u2223\u2223 E ] . (21)\nWe note that M1,T ,M2,T ,M3,T are random quantities that depend on the execution of the algorithm. However, we can use the fact that they are non-negative and thatM1,T+M2,T+M3,T = T to obtain a lower bound as follows.\nE[RT ] \u2265 \u22122 \u221a T + 1\n2 inf\nx1,x2,x3>0 x1+x2+x3=T\n( x1 \u221a 1\n4qT ln\n( 1\n\u03b7\n) + x2p \u2217(d\u2212 1)q + x3p\u2217 ) .\nAs (d\u2212 1)q \u2264 1, for any choice (x\u20321, x\u20322, x\u20323) for (x1, x2, x3) such that x\u20323 > 0, we can obtain a lower value for the term in parentheses via (x\u20321, x \u2032 2 + x \u2032 3, 0). Therefore, the above expression simplifies to:\nE[RT ] \u2265 \u22122 \u221a T + 1\n2 inf 0\u2264x\u2264T\n( x \u221a 1\n4qT ln\n( 1\n\u03b7\n) + (T \u2212 x)p\u2217(d\u2212 1)q ) . (22)\nFinally, we are taking the infimum of a linear function in the bounded interval [0, T ], so the infimum lies at one of the end points x = 0 or x = T . Therefore,\nE[RT ] \u2265 \u22122 \u221a T + 1\n2 min\n{\u221a T\n4q ln\n( 1\n\u03b7\n) , Tp\u2217(d\u2212 1)q }\n\u2265 \u22122 \u221a T + 1\n2 min\n{\u221a T\n4q ln\n( 1\n\u03b7\n) , Tp\u2217(d\u2212 1)q } . (23)\nPutting it all together. To complete the proof, first note that for all T \u2265 4, p\u2217 \u2265 1/2; hence, the second term inside the min can be upper bounded by 12T (d\u22121)q. To obtain a qmin independent bound, we set q = T\u22121/3(d\u2212 1)\u22122/3(ln(1/\u03b7))1/3 to obtain the first result of the theorem.\nNext, since qmin = q for this problem, we have that when\nqmin > q 0 T = T \u22121/3(d\u2212 1)\u22122/3 (ln (1/\u03b7))1/3 ,\nthe minimum is the first of the two terms in (23). This leads to our second lower bound.\nOur construction uses p\u2217 close to 1 to simplify some of the calculations in the analysis, but a similar analysis is possible for any p\u2217 bounded away from 0. Second, while our construction sets the ex-ante value \u03b8j to be the same for all types, a similar result can be shown in cases where a low probability type has ex-ante value similar to or larger than the ex-ante value of high probability types. Third, recall that we have assumed in this proof that the seller knows the type distribution P. If it is unknown, as was shown in our upper-bound analysis, the seller only really needs to estimate the low probability types and the expected revenue when targeting the remaining types, both of which can be done at rates T 1/3 and T 1/2 respectively without having to learn P entirely. The T 2/3 bottleneck arises as the seller needs to wait for the buyers\u2019 estimates of their values become accurate.\nWe also make the following observation via Equations (21)\u2013(23). Intuitively, M1,T in (21) denotes the number of times the seller\u2019s policy targeted the low probability types, M2,T denotes the number of times it targeted the high probability type while ignoring the low probability types, and M3,T is the number of times it targeted none of the types. Equation (22) states that any reasonable policy will never ignore all customer types, choosing M3,T = 0. On the other hand, the fact that the infimum in (23) lies in one of two extremes (M1,T ,M2,T ) \u2208 {(0, T ), (T, 0)} indicates that any reasonable policy cannot do significantly better than a policy which chooses ahead of time to target all customer types or only focus on the high probability types. Intuitively, this means that the seller\u2019s policy can decide ahead of time which customers it wants to ignore due to a low probability of appearance. In other words, it does not significantly help to change which types you target on different rounds based on their appearance probability. Interestingly, this is precisely the behavior of our algorithm as well; it uses a small initial phase of at most T 1/3 rounds to identify and eliminate low probability types. From thereon, it only targets the remaining high probability types."
        },
        {
            "heading": "6 Conclusion",
            "text": "We proposed no-regret online pricing strategies when both sides of the market learn from reviews. Our algorithm strategically sets lower prices during its early phase to boost sales from customers with rare types and high values. Reviews from the early phase benefit future buyers in the long run. Our algorithm carefully trades off the revenue loss due to discounts from the initial phase and future gains. Our lower bound demonstrates that our algorithm is optimal up to lower order and constant terms. To the best of our knowledge, this is the first result on online pricing when both the seller learns to price and buyers with different types learn from reviews.\nFuture directions. Many questions remain open for future research. We assumed that purchases always come with a noisy review. An interesting direction would be providing pricing strategies when the reviews are left with varying probabilities, which mimics real-world buyer behaviors.\nWe studied myopic buyers who make their purchase decisions based on estimates of their exante values from historical reviews, regardless of the seller\u2019s policy. What if the buyers appear over several rounds and may behave strategically to purchase at lower future prices?\nWe take a frequentist perspective on this problem. It is also possible to take a Bayesian view of this problem and impose a prior on the ex-ante value so that the buyer starts with some prior information. We expect adapting our main proof intuitions to that setting is possible. The main differences would be: (i) we would use Bayesian credible intervals instead of frequentist confidence intervals for the \u03b7-pessimism definition, (ii) we would control the Bayes\u2019 risk when estimating the ex-ante values instead of frequentist concentration arguments, and (iii) our final regret could have a nuanced dependence on this prior which may offer tighter bounds.\nAnother direction would be to explore the case where the seller does not know the buyers\u2019 ex-ante values. The key challenge would be related to the regret benchmark: we compete with the optimal price if the buyers knew their own ex-ante values and bought whenever their ex-ante value was above the price (thus, the buyers are not learning). To compete with this benchmark, we require unbiased estimates of the revenue of different prices if the buyers bought when their ex-ante value was above the price. Computing these unbiased estimates is challenging: if a buyer does not buy on a given round, the algorithm does not learn their type, so it cannot tell whether the buyer has a low ex-ante value or he has a high value but a low confidence bound. If the seller knows the buyers\u2019 ex-ante values, we can circumvent this subtle challenge, as we explain in the proof sketch of Theorem 4.1. However, this is not possible if the ex-ante values are unknown."
        },
        {
            "heading": "A Additional details about \u03b7-pessimistic agents",
            "text": "Intuitively, in Definition 2.1, LBt serves as a lower confidence bound on the buyer\u2019s value who arrives at round t. The buyers can be confident that, regardless of the policy used by the seller, with probability 1\u2212 \u03b7, for all rounds t \u2208 [T ], \u03b8it \u2265 LBt. We show this formally below.\nLemma A.1. Denote the type of the buyer who arrives at round t as it. On all rounds t, with probability at least 1\u2212 \u03b7, LBt \u2264 \u03b8it.\nProof. Let us consider a sequence of T rewards {v\u0303i1, \u00b7 \u00b7 \u00b7 v\u0303iT } for each buyer type i \u2208 [d] generated beforehand, where each reward is a random reward sample drawn from Di. Each time a buyer with type i arrives and makes a purchase, it obtains an ex-post value from the reward sequence {v\u0303i1, \u00b7 \u00b7 \u00b7 v\u0303iT } in order. For example, if the type of the buyer who arrives on round t is it, then if that buyer makes a purchase, their ex-post value will be v\u0303it,|\u03a6i,t|+1.\nFirst, we will show that Pr (LBt > \u03b8j | it = j) \u2264 \u03b7 for any j \u2208 [d]. At any round t, notice that if |\u03a6t| = 0, then LBt = 0, the conclusion trivially holds since \u03b8j > 0 for all j \u2208 [d]. When |\u03a6t| > 0:\nPr ( LBt > \u03b8j \u2223\u2223\u2223\u2223it = j) = Pr ( max { 0, 1\n|\u03a6t| \u2211 v\u2208\u03a6t v \u2212\n\u221a 1\n2|\u03a6t| ln\nt\n\u03b7\n} > \u03b8j \u2223\u2223\u2223\u2223it = j )\n= Pr\n( 1\n|\u03a6t| \u2211 v\u2208\u03a6t v \u2212\n\u221a 1\n2|\u03a6t| ln\nt \u03b7 > \u03b8j \u2223\u2223\u2223\u2223it = j )\n= Pr  1 |\u03a6t| |\u03a6t|\u2211 s=1 v\u0303js \u2212 \u221a 1 2|\u03a6t| ln t \u03b7 > \u03b8j \u2223\u2223\u2223\u2223it = j \n\u2264 Pr ( \u2203\u2113 \u2208 [t\u2212 1], s.t. 1\n\u2113 \u2113\u2211 s=1 v\u0303js \u2212 \u221a 1 2\u2113 ln t \u03b7 > \u03b8j \u2223\u2223\u2223\u2223it = j )\n\u2264 t\u22121\u2211 \u2113=1 Pr\n( 1\n\u2113 \u2113\u2211 s=1 v\u0303js \u2212 \u221a 1 2\u2113 ln t \u03b7 > \u03b8j \u2223\u2223\u2223\u2223it = j ) .\nHere, the second step uses the fact that \u03b8j \u2265 0. In the fifth step, we have used the fact that |\u03a6t| is a random quantity, which depends on the specific algorithm, but with support [(t\u2212 1)]. The last step follows from a union bound over (t\u2212 1) rounds.\nNote that for any fixed j \u2208 [d], the event 1\u2113 \u2211\u2113 s=1 v\u0303js\u2212 \u221a 1 2\u2113 ln T \u03b7 > \u03b8j is independent of the value\nof it. Therefore, by Hoeffding inequality, for any \u2113 \u2208 [t\u2212 1] and j \u2208 [d], we have that\nPr\n( 1\n\u2113 \u2113\u2211 s=1 v\u0303js \u2212 \u221a 1 2\u2113 ln t \u03b7 > \u03b8j \u2223\u2223\u2223\u2223it = j ) = Pr ( 1 \u2113 \u2113\u2211 s=1 v\u0303js \u2212 \u221a 1 2\u2113 ln t \u03b7 > \u03b8j ) \u2264 \u03b7 t .\nPutting this together we have:\nPr (LBt > \u03b8j | it = j) \u2264 (t\u2212 1) \u03b7\nt \u2264 \u03b7.\nLastly, by the law of total probability, Pr (LBt > \u03b8it) = \u2211 j\u2208[d] Pr (LBt > \u03b8j | it = j) \u00b7 Pr (it = j) \u2264 \u2211 j\u2208[d] \u03b7 \u00b7 Pr (it = j) \u2264 \u03b7,\nwhich completes the proof."
        },
        {
            "heading": "B Additional proofs about regret upper bound (Section 4.1)",
            "text": "Claim 4.3. If qmin \u2264 2\u03bb then E[Z2] \u2264 Td\u03bb+ 1 and if qmin > 2\u03bb, then E[Z2] \u2264 1.\nProof. First, we bound Z2 as follows: Z2 = \u2211 t>t\u03bb p\u2217([d])I (\u03b8it \u2265 p\u2217([d]) and it \u0338\u2208 Q) \u2264 \u2211 t>t\u03bb p\u2217([d])I (it \u0338\u2208 Q) \u2264 \u2211 t>t\u03bb I (it \u0338\u2208 Q) .\nRecall from Algorithm 1 that qi is the fraction of times that type i appears in phase 1 and let G be the event that for all i \u2208 [d] such that qi \u2265 \u03bb, we have that qi \u2265 3\u03bb4 , which means that i \u2208 Q. In other words, when G happens, [d] \\Q \u2286 {qi : qi < \u03bb}. In Lemma B.1, we prove that Pr[Gc] \u2264 1T , so E[Z2] \u2264 E[Z2 | G] + T Pr[Gc] \u2264 E[Z2 | G] + 1.\nNext, since Q is a random variable, we condition on it as well: E[Z2 | G] = \u2211\nQ\u2032\u2286[d]\nE[Z2 | Q = Q\u2032,G] Pr[Q = Q\u2032 | G].\nIf [d] \\ Q\u2032 \u0338\u2286 {qi : qi < \u03bb}, then Pr[Q = Q\u2032 | G] = 0. Moreover, for any Q\u2032 such that [d] \\ Q\u2032 \u2286 {qi : qi < \u03bb},\nE[Z2 | Q = Q\u2032,G] \u2264 E [\u2211 t>t\u03bb I ( it \u0338\u2208 Q\u2032 ) \u2223\u2223\u2223\u2223\u2223 Q = Q\u2032,G ]\n= \u2211 t>t\u03bb Pr [ it \u0338\u2208 Q\u2032 | Q = Q\u2032,G ] = \u2211 t>t\u03bb \u2211 i \u0338\u2208Q\u2032 Pr [ it = i | Q = Q\u2032,G ] .\nThe event (Q = Q\u2032 \u2227 G) depends only on the first t\u03bb timesteps, so it is independent of the event that it = i for t > t\u03bb. Therefore,\nE[Z2 | Q = Q\u2032,G] = \u2211 t>t\u03bb \u2211 i \u0338\u2208Q\u2032 Pr [it = i] .\nIf qmin > 2\u03bb, then {qi : qi < \u03bb} = \u2205, so the only Q\u2032 such that [d] \\Q\u2032 \u2286 {qi : qi < \u03bb} is Q\u2032 = [d]. In this case, \u2211\nt>t\u03bb \u2211 i \u0338\u2208Q\u2032 Pr [it = i] = 0,\nso E[Z2 | G] = 0 and finally, E[Z2] \u2264 1. Otherwise, qmin \u2264 2\u03bb, so \u2211\nt>t\u03bb \u2211 i \u0338\u2208Q\u2032 Pr [it = i] \u2264 \u2211 t>t\u03bb \u2211 i \u0338\u2208Q\u2032 \u03bb \u2264 Td\u03bb,\nso E[Z2 | G] \u2264 Td\u03bb \u2211 Q\u2032\u2286[d] Pr[Q = Q\u2032 | G] \u2264 Td\u03bb\nand finally, E[Z2] \u2264 Td\u03bb+ 1.\nClaim 4.4. E[Z3] \u2264 0.\nProof. In this proof we bound Z3 = \u2211 t>t\u03bb p\u2217([d])I (\u03b8it \u2265 p\u2217([d]) and it \u2208 Q)\u2212 \u2211 t>t\u03bb p\u2217(Q)I (\u03b8it \u2265 p\u2217(Q) and it \u2208 Q) . (24)\nWe begin by conditioning the first term of Equation (24) on Q since it is a random variable:\nE [\u2211 t>t\u03bb p\u2217([d])I (\u03b8it \u2265 p\u2217([d]) and it \u2208 Q) ]\n= \u2211\nQ\u2032\u2286[d]\np\u2217([d])E [\u2211 t>t\u03bb I ( \u03b8it \u2265 p\u2217([d]) and it \u2208 Q\u2032 ) | Q = Q\u2032 ] Pr[Q = Q\u2032]\n= \u2211\nQ\u2032\u2286[d] \u2211 t>t\u03bb p\u2217([d]) Pr [ \u03b8it \u2265 p\u2217([d]) and it \u2208 Q\u2032 | Q = Q\u2032 ] Pr[Q = Q\u2032]. (25)\nThe event that Q = Q\u2032 only depends on the first t\u03bb timesteps, so it is independent of the event (\u03b8it \u2265 p\u2217([d]) \u2227 it \u2208 Q\u2032) for t > t\u03bb. Therefore, for t > t\u03bb,\np\u2217([d]) Pr [ \u03b8it \u2265 p\u2217([d]) and it \u2208 Q\u2032 | Q = Q\u2032 ] = p\u2217([d]) Pr [ \u03b8it \u2265 p\u2217([d]) and it \u2208 Q\u2032 ] \u2264 max\np\u2208[0,1] pPr\n[ \u03b8it \u2265 p and it \u2208 Q\u2032 ] = p\u2217(Q\u2032) Pr [ \u03b8it \u2265 p\u2217(Q\u2032) and it \u2208 Q\u2032 ] .\nCombining this fact with Equation (25), we have that\nE [\u2211 t>t\u03bb p\u2217([d])I (\u03b8it \u2265 p\u2217([d]) and it \u2208 Q) ] \u2264 \u2211\nQ\u2032\u2286[d]\n(T \u2212 t\u03bb) p\u2217(Q\u2032) Pr i\u223cP\n[ \u03b8i \u2265 p\u2217(Q\u2032) and i \u2208 Q\u2032 ] Pr[Q = Q\u2032]. (26)\nNext, for the second term of Equation (24),\nE [\u2211 t>t\u03bb p\u2217(Q)I (\u03b8it \u2265 p\u2217(Q) and it \u2208 Q) ]\n= \u2211\nQ\u2032\u2286[d]\nE [\u2211 t>t\u03bb p\u2217(Q\u2032)I ( \u03b8it \u2265 p\u2217(Q\u2032) and it \u2208 Q\u2032 ) | Q = Q\u2032 ] Pr[Q = Q\u2032].\nAs before, the event that Q = Q\u2032 only depends on the first t\u03bb timesteps, so it is independent of the event (\u03b8it \u2265 p\u2217(Q\u2032) \u2227 it \u2208 Q\u2032) for t > t\u03bb. Therefore,\nE [\u2211 t>t\u03bb p\u2217(Q)I (\u03b8it \u2265 p\u2217(Q) and it \u2208 Q) ] = \u2211\nQ\u2032\u2286[d]\n(T \u2212 t\u03bb) p\u2217(Q\u2032) Pr i\u223cP\n[ \u03b8i \u2265 p\u2217(Q\u2032) and i \u2208 Q\u2032 ] Pr[Q = Q\u2032].\nCombined with Equation (26), we have that E[Z3] \u2264 0.\nClaim 4.5. E[Z4] \u2264 5 + 4 \u221a 2T ln(dT 2).\nProof. In this claim, we bound Z4 = \u2211 t>t\u03bb p\u2217(Q)I (\u03b8it \u2265 p\u2217(Q) and it \u2208 Q)\u2212 \u2211 t>t\u03bb p\u2032tI ( \u03b8it \u2265 p\u2032t and it \u2208 Q ) , (27)\nwhere p\u2032t = mini\u2208St \u03b8i. Beginning with the first term of this equation, for any t > t\u03bb,\nE [p\u2217(Q)I (\u03b8it \u2265 p\u2217(Q) and it \u2208 Q)] = \u2211\nQ\u2032\u2286[d]\nE [ p\u2217(Q\u2032)I ( \u03b8it \u2265 p\u2217(Q\u2032) and it \u2208 Q\u2032 ) | Q = Q\u2032 ] Pr[Q = Q\u2032].\nThe event (\u03b8it \u2265 p\u2217(Q\u2032) \u2227 it \u2208 Q\u2032) is independent of the event that Q = Q\u2032, so\nE [ p\u2217(Q\u2032)I ( \u03b8it \u2265 p\u2217(Q\u2032) and it \u2208 Q\u2032 ) | Q = Q\u2032 ] = E [ p\u2217(Q\u2032)I ( \u03b8it \u2265 p\u2217(Q\u2032) and it \u2208 Q\u2032 )] = rev(p\u2217(Q\u2032), Q\u2032).\nTherefore,\u2211 t>t\u03bb E [p\u2217(Q)I (\u03b8it \u2265 p\u2217(Q) and it \u2208 Q)] = \u2211 t>t\u03bb \u2211 Q\u2032\u2286[d] rev(p\u2217(Q\u2032), Q\u2032) Pr[Q = Q\u2032]\n= \u2211 t>t\u03bb E [rev(p\u2217(Q), Q)] . (28)\nMoving on to the second term of Equation (27), we have that for any t > t\u03bb, E [ p\u2032tI ( \u03b8it \u2265 p\u2032t and it \u2208 Q )] = \u2211\nQ\u2032\u2286[d] \u2211 S\u2032\u2286Q\u2032 E [ min i\u2208S\u2032 \u03b8i \u00b7 I ( \u03b8it \u2265 min i\u2208S\u2032 \u03b8i and it \u2208 Q\u2032 ) \u2223\u2223\u2223\u2223 Q = Q\u2032, St = S\u2032]Pr[Q = Q\u2032, St = S\u2032]. (29) The event that Q = Q\u2032 only depends on the first t\u03bb timesteps and the event that St = S\n\u2032 only depends on the first t\u22121 timesteps. Therefore, the event (\u03b8it \u2265 mini\u2208S\u2032 \u03b8i and it \u2208 Q\u2032) is independent of the event (Q = Q\u2032 and St = S \u2032). This means that\nE [ min i\u2208S\u2032 \u03b8i \u00b7 I ( \u03b8it \u2265 min i\u2208S\u2032 \u03b8i and it \u2208 Q\u2032 ) \u2223\u2223\u2223\u2223 Q = Q\u2032, St = S\u2032] = E [ min i\u2208S\u2032 \u03b8i \u00b7 I ( \u03b8it \u2265 min i\u2208S\u2032 \u03b8i and it \u2208 Q\u2032\n)] =rev ( min i\u2208S\u2032 \u03b8i, Q \u2032 ) .\nCombined with Equation (29), we have that\nE [ p\u2032tI ( \u03b8it \u2265 p\u2032t and it \u2208 Q )] = \u2211\nQ\u2032\u2286[d] \u2211 S\u2032\u2286Q\u2032 rev ( min i\u2208S\u2032 \u03b8i, Q \u2032 ) Pr[Q = Q\u2032, St = S \u2032]\n= E [ rev ( p\u2032t, Q )] . (30)\nCombining Equations (28) and (30), we have that E[Z4] \u2264 \u2211 t>t\u03bb E [ rev (p\u2217(Q), Q)\u2212 rev ( p\u2032t, Q )] . (31)\nNext, for all t > t\u03bb, let Bt be the event that:\n1. iQ \u2208 St and\n2. rev(p\u2217(Q), Q)\u2212 rev (p\u2032t, Q) \u2264 4\u03c1t\u22121 (where \u03c1t\u03bb = 1).\nAlso, let Ct = \u22c2t\ns=t\u03bb+1 Bs. In Lemma B.2, we prove that Pr [Cct ] \u2264 1T . By Equation (31), we have\nthat\nE[Z4] \u2264 E [\u2211 t>t\u03bb rev (p\u2217(Q), Q)\u2212 rev ( p\u2032t, Q ) \u2223\u2223\u2223\u2223\u2223 CT ] + T Pr [CcT ]\n\u2264 \u2211 t>t\u03bb 4\u03c1t\u22121 + 1\n\u2264 5 + 4 T\u2211 t=1\n\u221a ln(dT 2)\n2t \u2264 5 + 4 \u221a 2T ln(dT 2).\nClaim 4.6. If qmin \u2264 2\u03bb, then E[Z5] \u2264 4 \u221a 2T \u03bb ln dT 2 \u03b7 +3 and if qmin > 2\u03bb, E[Z5] \u2264 4 \u221a T qmin ln dT 2 \u03b7 +2.\nProof. On each round t > t\u03bb, recall that\nLBit = { 0 if \u03a6it = \u2205 max { 1 |\u03a6it| \u2211 v\u2208\u03a6it v \u2212 \u221a 1 2|\u03a6it| ln T \u03b7 , 0 } else.\nLet jt = argminj\u2208St \u03b8j , so p \u2032 t = \u03b8jt . Then\nZ5 = \u2211 t>t\u03bb p\u2032tI ( \u03b8it \u2265 p\u2032t and it \u2208 Q ) \u2212 \u2211 t>t\u03bb ptbt\n= \u2211 t>t\u03bb p\u2032tI ( \u03b8it \u2265 p\u2032t and it \u2208 Q ) \u2212 \u2211 t>t\u03bb (p\u2032t + (p \u2032 t \u2212 pt))bt\n= \u2211 t>t\u03bb p\u2032t ( I ( \u03b8it \u2265 p\u2032t and it \u2208 Q ) \u2212 bt ) + \u2211 t>t\u03bb (p\u2032t \u2212 pt)bt\n\u2264 \u2211 t>t\u03bb p\u2032tI ( \u03b8it \u2265 p\u2032t \u2227 it \u2208 Q \u2227 bt = 0 ) + \u2211 t>t\u03bb (p\u2032t \u2212 pt)bt.\nSince pt \u2264 p\u2032t, we have that\nZ5 \u2264 \u2211 t>t\u03bb p\u2032tI ( \u03b8it \u2265 p\u2032t \u2227 it \u2208 Q \u2227 bt = 0 ) + \u2211 t>t\u03bb ( p\u2032t \u2212 pt ) .\nBy definition of the pricing rule, if it \u2208 St, then bt = 1. Therefore, if bt = 0, then either it \u0338\u2208 Q or it \u2208 Q \\ St. Since St contains every i \u2208 Q with i > jt, we can conclude that if it \u2208 Q \\ St, then \u03b8it < \u03b8jt = p \u2032 t. Therefore, I (\u03b8it \u2265 p\u2032t \u2227 it \u2208 Q \u2227 bt = 0) = 0, which means that\nE [Z5] \u2264 E [\u2211 t>t\u03bb p\u2032t \u2212 pt ] .\nLet j\u2032t = argminj\u2208St LBjt, which means that pt = mini\u2208St {min {\u03b8i,LBit}} = min { p\u2032t,LBj\u2032tt } .\nWe also know that p\u2032t = \u03b8jt \u2264 \u03b8j\u2032t . Therefore,\nE [Z5] \u2264 E [\u2211 t>t\u03bb max { 0, \u03b8j\u2032t \u2212 LBj\u2032tt }] .\nFor the remainder of our analysis, we will require the following events:\n\u2022 Let E1 be the event that for all t > t\u03bb, |\u03a6i,t| \u2265 12qmin(t\u2212 1) for all i \u2208 St. In Lemma B.4, we prove that if qmin > 2\u03bb, then Pr [Ec1] \u2264 1T .\n\u2022 Similarly, let E2 be the event that for all t > t\u03bb, |\u03a6i,t| \u2265 14\u03bb(t \u2212 1) for all i \u2208 St such that qi \u2265 \u03bb2 . In Lemma B.5, we prove that if qmin \u2264 2\u03bb, then Pr[E c 2] \u2264 1T .\n\u2022 Let F be the event that for all i \u2208 [d] such that qi \u2264 \u03bb2 , we have that qi < 3\u03bb 4 , which means\nthat i \u0338\u2208 Q. In Lemma B.6, we prove that Pr[Fc] \u2264 1T .\n\u2022 Let H be the event that for all t > t\u03bb and all i \u2208 St,\n|\u03a6it|\u03b8i \u2264 \u2211 v\u2208\u03a6it v +\n\u221a 1\n2 |\u03a6it| ln(dT 2).\nIn Lemma B.7, we prove that Pr[Hc] \u2264 1T .\nWe now split our analysis into two cases depending on whether or not qmin > 2\u03bb. Suppose that qmin > 2\u03bb. In this case,\nE [Z5] \u2264 E [\u2211 t>t\u03bb max { 0, \u03b8j\u2032t \u2212 LBj\u2032tt } \u2223\u2223\u2223\u2223\u2223 E1 \u2227H ] + T Pr[(E1 \u2227H)c]\n\u2264 E [\u2211 t>t\u03bb max { 0, \u03b8j\u2032t \u2212 LBj\u2032tt } \u2223\u2223\u2223\u2223\u2223 E1 \u2227H ] + 2\n= E \u2211 t>t\u03bb max 0, \u03b8j\u2032t \u2212 1|\u03a6j\u2032tt| \u2211\nv\u2208\u03a6j\u2032tt\nv +\n\u221a 1\n2|\u03a6j\u2032tt| ln\n1\n\u03b7  \u2223\u2223\u2223\u2223\u2223\u2223\u2223 E1 \u2227H + 2. Under events E1 and H,\nE[Z5] \u2264 E [\u2211 t>t\u03bb \u221a ln(dT 2) 2|\u03a6j\u2032tt| + \u221a 1 2|\u03a6j\u2032tt| ln 1 \u03b7 \u2223\u2223\u2223\u2223\u2223 E1 \u2227H ] + 2\nand by definition of the event E1,\nE[Z5] \u2264 E [\u2211 t>t\u03bb \u221a ln(dT 2) 2|\u03a6j\u2032tt| + \u221a 1 2|\u03a6j\u2032tt| ln 1 \u03b7 \u2223\u2223\u2223\u2223\u2223 E1 \u2227H ] + 2\n\u2264 T\u2211 t=2\n(\u221a ln(dT 2)\nqmin(t\u2212 1) +\n\u221a 1\nqmin(t\u2212 1) ln\n1\n\u03b7\n) + 2\n\u2264 4\n\u221a T\nqmin ln\ndT 2\n\u03b7 + 2.\nMeanwhile, suppose that qmin < 2\u03bb. When F happens, for all t > t\u03bb, St \u2286 Q \u2286 { i : qi > \u03bb 2 } , so\nwhen both E2 and F happen, |\u03a6i,t| \u2265 14\u03bb(t\u2212 1) for all t > t\u03bb and i \u2208 St. Therefore,\nE [Z5] \u2264 E [\u2211 t>t\u03bb max { 0, \u03b8j\u2032t \u2212 LBj\u2032tt } \u2223\u2223\u2223\u2223\u2223 E2 \u2227 F \u2227H ] + T Pr[(E2 \u2227 F \u2227H)c]\n\u2264 E [\u2211 t>t\u03bb max { 0, \u03b8j\u2032t \u2212 LBj\u2032tt } \u2223\u2223\u2223\u2223\u2223 E2 \u2227 F \u2227H ] + 3\n= E \u2211 t>t\u03bb max 0, \u03b8j\u2032t \u2212 1|\u03a6j\u2032tt| \u2211\nv\u2208\u03a6j\u2032tt\nv +\n\u221a 1\n2|\u03a6j\u2032tt| ln\n1\n\u03b7  \u2223\u2223\u2223\u2223\u2223\u2223\u2223 E2 \u2227 F \u2227H + 3. When E2, F , and H all happen,\nE [Z5] \u2264 E [\u2211 t>t\u03bb \u221a ln(dT 2) 2|\u03a6j\u2032tt| + \u221a 1 2|\u03a6j\u2032tt| ln 1 \u03b7 \u2223\u2223\u2223\u2223\u2223 E2 \u2227 F \u2227H ] + 3\nand by definition of E2 \u2227 F ,\nE [Z5] \u2264 E [\u2211 t>t\u03bb \u221a ln(dT 2) 2|\u03a6j\u2032tt| + \u221a 1 2|\u03a6j\u2032tt| ln 1 \u03b7 \u2223\u2223\u2223\u2223\u2223 E2 \u2227 F \u2227H ] + 3\n\u2264 T\u2211 t=2\n(\u221a 2 ln(dT 2)\n\u03bb(t\u2212 1) +\n\u221a 2\n\u03bb(t\u2212 1) ln\n1\n\u03b7\n) + 3\n\u2264 4\n\u221a 2T\n\u03bb ln\ndT 2\n\u03b7 + 3.\nLemma 4.7. For all t > t\u03bb, let At be the event rev (\u03b8i, Q) \u2208 [q\u00b5i,t, p\u00b5i,t] for all i \u2208 St. Then Pr[Act ] \u2264 1T 2 .\nProof. Recall that p\u00b5i,t = \u00b5i,t + \u03c1t and q\u00b5i,t = \u00b5i,t \u2212 \u03c1t with\n\u03c1t =\n\u221a ln(dT 2)\n2 (t\u2212 t\u03bb) .\nWe also define the related quantities for all i \u2208 [d] and all Q\u2032 \u2286 [d]:\n\u03b3i,t(Q \u2032) =\n1\nt\u2212 t\u03bb t\u2211 s=t\u03bb+1 \u03b8i \u00b7 I ( \u03b8is \u2265 \u03b8i \u2227 is \u2208 Q\u2032 ) ,\np\u03b3i,t(Q \u2032) = \u03b3i,t(Q \u2032) + \u03c1t, and q\u03b3i,t(Q \u2032) = \u03b3i,t(Q \u2032)\u2212 \u03c1t. By a Hoeffding bound, for all Q\u2032 \u2286 [d] and all i \u2208 [d],\nPr [ rev ( \u03b8i, Q \u2032) \u0338\u2208 [q\u03b3i,t(Q\u2032), p\u03b3i,t(Q\u2032)]] \u2264 1 dT 2 .\nWe claim that for any i \u2208 St and any s > t\u03bb,\nI(bs = 1 \u2227 \u03b8is \u2265 \u03b8i \u2227 is \u2208 Q) = I (\u03b8is \u2265 \u03b8i \u2227 is \u2208 Q) , (32)\nwhich means that \u00b5i,t = \u03b3i,t(Q), p\u00b5i,t = p\u03b3i,t(Q), and q\u00b5i,t = q\u03b3i,t(Q). To see why, if bs = 1, then clearly Equation (32) holds. Otherwise, suppose bs = 0, in which case I(bs = 1 \u2227 \u03b8is \u2265 \u03b8i \u2227 is \u2208 Q) = 0. Then is \u0338\u2208 Ss because any buyer in Ss will always buy by definition of the pricing rule. Let js = min {j \u2208 Ss} . Since Ss contains every element in Q larger than js, we know that either:\n1. is \u0338\u2208 Q, in which case I (\u03b8is \u2265 \u03b8i \u2227 is \u2208 Q) = 0, or\n2. is \u2208 Q but is \u0338\u2208 Ss, which means that \u03b8is < \u03b8js . Since i \u2208 St, it must be that i \u2208 Ss, so \u03b8is < \u03b8js \u2264 \u03b8i. In this case, I (\u03b8is \u2265 \u03b8i \u2227 is \u2208 Q) = 0 as well.\nTherefore, Equation (32) holds. The fact that \u00b5i,t = \u03b3i,t(Q), p\u00b5i,t = p\u03b3i,t(Q), and q\u00b5i,t = q\u03b3i,t(Q) for all i \u2208 St implies that\nPr[Act ] = Pr (\u2203i \u2208 St s.t. rev (\u03b8i, Q) \u0338\u2208 [q\u00b5i,t, p\u00b5i,t]) \u2264 Pr (\u2203i \u2208 [d] s.t. rev (\u03b8i, Q) \u0338\u2208 [q\u03b3i,t(Q), p\u03b3i,t(Q)])\n\u2264 d\u2211\ni=1\nPr (rev (\u03b8i, Q) \u0338\u2208 [q\u03b3i,t(Q), p\u03b3i,t(Q)]) . (33)\nThe set Q is a random variable, so we must condition on it to bound Equation (33):\nPr (rev (\u03b8i, Q) \u0338\u2208 [q\u03b3i,t(Q), p\u03b3i,t(Q)]) = \u2211\nQ\u2032\u2286[d]\nPr ( rev ( \u03b8i, Q \u2032) \u0338\u2208 [q\u03b3i,t(Q\u2032), p\u03b3i,t(Q\u2032)] | Q = Q\u2032)Pr[Q = Q\u2032]. Since the event that Q = Q\u2032 and the event that rev (\u03b8i, Q\n\u2032) \u0338\u2208 [q\u03b3i,t(Q\u2032), p\u03b3i,t(Q\u2032)] depend on disjoint timesteps, the two events are independent. Therefore,\nPr (rev (\u03b8i, Q) \u0338\u2208 [q\u03b3i,t(Q), p\u03b3i,t(Q)]) = \u2211\nQ\u2032\u2286[d]\nPr ( rev ( \u03b8i, Q \u2032) \u0338\u2208 [q\u03b3i,t(Q\u2032), p\u03b3i,t(Q\u2032)])Pr [Q = Q\u2032] \u2264 1\ndT 2 \u2211 Q\u2032\u2286[d] Pr [ Q = Q\u2032 ] = 1\ndT 2 ,\nso the result follows from Equation (33).\nThe next lemma shows that for more common types with qi \u2265 \u03bb, the fraction of times qi that that type appears during Algorithm 1 is large enough that i is added to Q.\nLemma B.1. Let G be the event that for all i such that qi \u2265 \u03bb, we have that qi \u2265 3\u03bb4 . Then Pr[Gc] \u2264 1T .\nProof. Fix an index i such that qi \u2265 \u03bb. Then\nPr [ qi < 3\u03bb\n4\n] = Pr [ t\u03bb\u2211 t=1 I(it = i) < \u03bbt\u03bb \u00b7 3 4 ] \u2264 exp ( \u2212\u03bbt\u03bb 32 ) \u2264 1 dT .\nThe lemma the follows by a union bound over all i \u2208 [d].\nThe next lemma proves that the expected revenue (with respect to agents in Q) of the smallest active price min {\u03b8i : i \u2208 St} is converging to the optimal revenue rev(p\u2217(Q), Q) as t grows. Later in the analysis, we will show\u2014at a high level\u2014that since the algorithm sets a price within a neighborhood of min {\u03b8i : i \u2208 St}, its revenue is converging to that of p\u2217(Q). For this next lemma, recall that p\u2217(Q) = \u03b8iQ for some iQ \u2208 Q. The proof is similar to that of standard successive arm elimination algorithms [e.g., Zhao and Chen, 2020].\nLemma B.2. For all t > t\u03bb, let jt = min{j \u2208 St}. Let Bt be the event that:\n1. iQ \u2208 St and\n2. rev(p\u2217(Q), Q)\u2212 rev (\u03b8jt , Q) \u2264 4\u03c1t\u22121 (where \u03c1t\u03bb = 1).\nAlso, let Ct = \u22c2t\ns=t\u03bb+1 Bs. Then Pr [Cct ] \u2264 1T .\nProof. We begin by partitioning Cct into the disjoint events\nCct = Cct\u03bb+1 \u222a ( Ct\u03bb+1 \u2229 B c t\u03bb+2 ) \u222a \u00b7 \u00b7 \u00b7 \u222a (Ct\u22121 \u2229 Bct ) .\nSince these events are disjoint, Pr [Cct ] = Pr [ Cct\u03bb+1 ] + Pr [ Ct\u03bb+1 \u2229 B c t\u03bb+2 ] + \u00b7 \u00b7 \u00b7+ Pr [Ct\u22121 \u2229 Bct ] . (34)\nBeginning with the first summand, Pr [ Cct\u03bb+1 ] = Pr [ Bct\u03bb+1 ] = 0 because St\u03bb = Q, so iQ \u2208 St\u03bb , and 4\u03c1t\u03bb > 1. Next, for s > t\u03bb + 1,\nPr [Cs\u22121 \u2229 Bcs] = Pr  s\u22121\u22c2 s\u2032=t\u03bb+1 Bs\u2032 \u2229 Bcs  \u2264 Pr [Bs\u22121 \u2229 Bcs] . (35) We will prove that Bs\u22121 \u2229 Bcs implies Acs\u22121, which will allow us to apply Lemma 4.7.\nClaim B.3. The event Bs\u22121 \u2229 Bcs implies Acs\u22121.\nProof. Proof of Claim B.3] First suppose Bs\u22121 happens and iQ \u0338\u2208 Ss (so Bcs happens). Since Bs\u22121 happens, we know that iQ \u2208 Ss\u22121 but since iQ \u0338\u2208 Ss, it must be that iQ was eliminated at the end of round s\u2212 1. This means that p\u00b5iQ,s\u22121 < maxk\u2208Ss\u22121 q\u00b5k,s\u22121. Let k\u2032 = argmaxk\u2208Ss\u22121 q\u00b5k,s\u22121. Then\nrev(p\u2217(Q), Q)\u2212 q\u00b5iQ,s\u22121 \u2265 rev (\u03b8k\u2032 , Q)\u2212 q\u00b5iQ,s\u22121 = rev (\u03b8k\u2032 , Q)\u2212 p\u00b5iQ,s\u22121 + 2\u03c1s\u22121 > rev (\u03b8k\u2032 , Q)\u2212 q\u00b5k\u2032,s\u22121 + 2\u03c1s\u22121. (36)\nSuppose that rev (\u03b8k\u2032 , Q) \u2265 q\u00b5k\u2032,s\u22121. Then Equation (36) implies that\n2\u03c1s\u22121 < rev(p \u2217(Q), Q)\u2212 q\u00b5iQ,s\u22121 = rev(p \u2217(Q), Q)\u2212 (p\u00b5iQ,s\u22121 \u2212 2\u03c1s\u22121)\nso rev(p\u2217(Q), Q) > p\u00b5iQ,s\u22121. Therefore, either rev (\u03b8k\u2032 , Q) < q\u00b5k\u2032,s\u22121 or rev(p \u2217(Q), Q) > p\u00b5iQ,s\u22121, which means that Acs\u22121 happens. Meanwhile, suppose Bs\u22121 happens and iQ \u2208 Ss but rev(p\u2217(Q), Q)\u2212 rev (\u03b8js , Q) > 4\u03c1s\u22121 (so Bcs happens). Then\nrev(p\u2217(Q), Q)\u2212 q\u00b5iQ,s\u22121 + p\u00b5js,s\u22121 \u2212 rev (\u03b8js , Q) > p\u00b5js,s\u22121 \u2212 q\u00b5iQ,s\u22121 + 4\u03c1s\u22121. (37)\nAgain, let k\u2032 = argmaxk\u2208Ss\u22121 q\u00b5k,s\u22121. Since js \u2208 Ss, it must be that p\u00b5js,s\u22121 \u2265 q\u00b5k\u2032,s\u22121, or else js would have been eliminated at the end of round s\u2212 1. Combining this fact with Equation (37), we have that\nrev(p\u2217(Q), Q)\u2212 q\u00b5iQ,s\u22121 + p\u00b5js,s\u22121 \u2212 rev (\u03b8js , Q) > q\u00b5k\u2032,s\u22121 \u2212 q\u00b5k\u2032,s\u22121 + 4\u03c1s\u22121 = 4\u03c1s\u22121.\nThis means that either:\n1. 2\u03c1s\u22121 < rev(p \u2217(Q), Q)\u2212q\u00b5iQ,s\u22121 = rev(p\u2217(Q), Q)\u2212p\u00b5iQ,s\u22121+2\u03c1s\u22121, or in other words p\u00b5iQ,s\u22121 <\nrev(p\u2217(Q), Q), meaning Acs\u22121 happens, or\n2. 2\u03c1s\u22121 < p\u00b5js,s\u22121\u2212 rev (\u03b8js , Q) = q\u00b5js,s\u22121+2\u03c1s\u22121\u2212 rev (\u03b8js , Q), or in other words, rev (\u03b8js , Q) < q\u00b5js,s\u22121, meaning Acs\u22121 happens.\nTherefore, the claim holds. Claim B.3, Equation (35), and Lemma 4.7 imply that Pr [Cs\u22121 \u2229 Bcs] \u2264 Pr [ Acs\u22121 ] \u2264 1 T 2 , so by Equation (34), we have that Pr [Cct ] < 1T .\nThe next lemma will prove that for all rounds t > t\u03bb of Algorithm 2 and all active types i \u2208 St, there are a non-trivial number of reviews by buyers of type i. The following lemma holds when qmin > 2\u03bb, and Lemma B.5 holds when qmin \u2264 2\u03bb.\nLemma B.4. Suppose that qmin > 2\u03bb. Let E1 be the event that on each round t > t\u03bb, |\u03a6i,t| \u2265 1 2qmin(t\u2212 1) and all i \u2208 St. Then Pr[E c 1] \u2264 1T .\nProof. Fix any t > t\u03bb. We will show that\nPr [ \u2203i \u2208 St such that |\u03a6i,t| < 1\n2 qmin(t\u2212 1)\n] \u2264 1\nT 2 .\nBy definition, |\u03a6i,t| = \u2211t\u22121 s=1 I(bs = 1 \u2227 is = i). If |\u03a6i,t| were equal to \u2211t\u22121\ns=1 I(is = i), then the claim would hold immediately by a Chernoff bound. However, we do not know at each round s whether is = i provided the buyer does not make a purchase. Therefore, we also define the random variable Xi,t = \u2211t\u22121 s=1 I(is = i). We claim that for all i \u2208 St, |\u03a6i,t| = Xi,t. This is because we know that i \u2208 Ss for all s \u2264 t and by definition of the pricing rule, if is = i, then bs = 1. Therefore,\nPr [ \u2203t > t\u03bb, \u2203i \u2208 St such that |\u03a6i,t| < 1\n2 qmin(t\u2212 1) ] = Pr [ \u2203t > t\u03bb,\u2203i \u2208 St such that Xi,t < 1\n2 qmin(t\u2212 1) ] \u2264 Pr [ \u2203t > t\u03bb,\u2203i \u2208 [d] such that Xi,t < 1\n2 qmin(t\u2212 1) ] \u2264\nd\u2211 i=1 T\u2211 t=t\u03bb+1 Pr [ Xi,t < 1 2 qmin(t\u2212 1) ] . (38)\nBy a Chernoff bound,\nPr [ Xi,t \u2264 1\n2 qmin(t\u2212 1)\n] \u2264 Pr [ Xi,t \u2264 1\n2 qi(t\u2212 1) ] \u2264 exp ( \u2212qi(t\u2212 1)\n8 ) \u2264 exp ( \u2212qmin(t\u2212 1)\n8 ) \u2264 exp ( \u2212\u03bb(t\u2212 1)\n4 ) \u2264 1\ndT 2 .\nThe lemma now follows from Equation (38).\nWe now prove a similar result for the case where qmin \u2264 2\u03bb.\nLemma B.5. Suppose that qmin \u2264 2\u03bb. Let E2 be the event that for all t > t\u03bb, |\u03a6i,t| \u2265 14\u03bb(t\u2212 1) for all i \u2208 St such that qi \u2265 \u03bb2 . Then Pr[E c 2] \u2264 1T .\nProof. Let Q0 = { i : qi \u2265 \u03bb2 } . Fix any t > t\u03bb. We will show that\nPr [ \u2203i \u2208 St \u2229Q0 such that |\u03a6i,t| < 1\n4 \u03bb(t\u2212 1)\n] \u2264 1\nT 2 .\nBy definition, |\u03a6i,t| = \u2211t\u22121\ns=1 I(bs = 1\u2227 is = i). As in the proof of Lemma B.4, we define the random variable Xi,t = \u2211t\u22121 s=1 I(xs = ei). As in that proof, for all i \u2208 St, |\u03a6i,t| = Xi,t (this is because we know that i \u2208 Ss for all s \u2264 t and by definition of the pricing rule, if is = i, then bs = 1.).\nTherefore,\nPr [ \u2203t > t\u03bb, \u2203i \u2208 St \u2229Q0 such that |\u03a6i,t| < 1\n4 \u03bb(t\u2212 1) ] = Pr [ \u2203t > t\u03bb, \u2203i \u2208 St \u2229Q0 such that Xi,t < 1\n4 \u03bb(t\u2212 1) ] \u2264 Pr [ \u2203t > t\u03bb, \u2203i \u2208 Q0 such that Xi,t < 1\n4 \u03bb(t\u2212 1) ] \u2264 \u2211 i\u2208Q0 T\u2211 t=t\u03bb+1 Pr [ Xi,t < 1 4 \u03bb(t\u2212 1) ] . (39)\nBy a Chernoff bound, for any i \u2208 Q0,\nPr [ Xi,t < 1\n4 \u03bb(t\u2212 1)\n] \u2264 Pr [ Xi,t < 1\n2 qi(t\u2212 1) ] \u2264 exp ( \u2212qi(t\u2212 1)\n8 ) \u2264 exp ( \u2212\u03bb(t\u2212 1)\n16 ) \u2264 1\ndT 2 .\nThe lemma therefore follows from Equation (39).\nWe next observe that for all very rare types with qi \u2264 \u03bb/2, the fraction of times qi that that type appears during Algorithm 1 is small. Therefore, i is not added to the set Q and is ignored for the remainder of the algorithm.\nLemma B.6. Let F be the event that for all i \u2208 [d] such that qi \u2264 \u03bb2 , we have that qi \u2264 3\u03bb 4 . Then Pr[Fc] \u2264 1T .\nProof. Fix an index i such that qi \u2264 \u03bb2 . Then\nPr [ qi \u2265 3\u03bb\n4\n] = Pr [ t\u03bb\u2211 t=1 I(it = i) \u2265 \u03bbt\u03bb 2 \u00b7 3 2 ] \u2264 exp ( \u2212\u03bbt\u03bb 24 ) = 1 dT .\nThe lemma the follows by a union bound over all i \u2208 [d].\nOur final lemma proves that for all active types i \u2208 St, the average reviews of agents with this type is close to the true ex-ante value \u03b8i. This helps us ensure that the price we set is not too low.\nLemma B.7. Let H be the event that for all t > t\u03bb and all i \u2208 St,\n|\u03a6it|\u03b8i \u2264 \u2211 v\u2208\u03a6it v +\n\u221a 1\n2 |\u03a6it| ln(dT 2).\nThen Pr[Hc] \u2264 1T .\nProof. Fix any t > t\u03bb. Let v1, . . . , vt\u22121 be the buyers\u2019 ex-post values (which are defined even if the buyer didn\u2019t buy on a particular round s as vs \u223c Dis). For each i \u2208 [d], let Rit = {s < t : is = i} be the set of rounds in which the buyer had type i. Since any buyer i \u2208 Ss will buy if is = i, we have that |\u03a6it| = |Rit| and \u2211\nv\u2208\u03a6it v = \u2211 s\u2208Rit vs.\nTherefore,\nPr \u2203i \u2208 St such that |\u03a6it|\u03b8i > \u2211 v\u2208\u03a6it v + \u221a 1 2 |\u03a6it| ln(dT 2)  \u2264 Pr\n\u2203i \u2208 [d] such that |Rit|\u03b8i > \u2211 s\u2208Rit vs + \u221a 1 2 |Rit| ln(dT 2)  \u2264\nd\u2211 i=1 Pr |Rit|\u03b8i > \u2211 s\u2208Rit vs + \u221a 1 2 |Rit| ln(dT 2)  =\nd\u2211 i=1 \u2211 R\u2286[t\u22121] Pr\n[ |R|\u03b8i >\n\u2211 s\u2208R vs +\n\u221a 1\n2 |R| ln(dT 2) \u2223\u2223\u2223\u2223\u2223 Rit = R ] Pr[Rit = R]. (40)\nFor any s \u2208 R, E [vs | Rit = R] = \u03b8i. Therefore,\nPr [ |R|\u03b8i >\n\u2211 s\u2208R vs +\n\u221a 1\n2 |R| ln(dT 2) \u2223\u2223\u2223\u2223\u2223 Rit = R ] \u2264 1 dT 2 .\nThe lemma therefore follows from Equation (40) and a union bound over all rounds t > t\u03bb."
        }
    ],
    "title": "Leveraging Reviews: Learning to Price with Buyer and Seller Uncertainty",
    "year": 2023
}