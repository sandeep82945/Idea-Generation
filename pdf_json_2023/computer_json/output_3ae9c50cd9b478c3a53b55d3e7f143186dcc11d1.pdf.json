{
    "abstractText": "Weak feature representation problem has influenced the performance of few-shot classification task for a long time. To alleviate this problem, recent researchers build connections between support and query instances through embedding patch features to generate discriminative representations. However, we observe that there exists semantic mismatches (foreground/ background) among these local patches, because the location and size of the target object are not fixed. What is worse, these mismatches result in unreliable similarity confidences, and complex dense connection exacerbates the problem. According to this, we propose a novel Clustered-patch Element Connection (CEC) layer to correct the mismatch problem. The CEC layer leverages Patch Cluster and Element Connection operations to collect and establish reliable connections with high similarity patch features, respectively. Moreover, we propose a CECNet, including CEC layer based attention module and distance metric. The former is utilized to generate a more discriminative representation benefiting from the global clustered-patch features, and the latter is introduced to reliably measure the similarity between pair-features. Extensive experiments demonstrate that our CECNet outperforms the state-ofthe-art methods on classification benchmark. Furthermore, our CEC approach can be extended into few-shot segmentation and detection tasks, which achieves competitive performances.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jinxiang Lai"
        },
        {
            "affiliations": [],
            "name": "Siqian Yang"
        },
        {
            "affiliations": [],
            "name": "Junhong Zhou"
        },
        {
            "affiliations": [],
            "name": "Wenlong Wu"
        },
        {
            "affiliations": [],
            "name": "Xiaochen Chen"
        },
        {
            "affiliations": [],
            "name": "Jun Liu"
        },
        {
            "affiliations": [],
            "name": "Bin-Bin Gao"
        },
        {
            "affiliations": [],
            "name": "Chengjie Wang"
        }
    ],
    "id": "SP:ef4882a70b0694d26f0e7382e562bd954f7ae423",
    "references": [
        {
            "authors": [
                "Marcin Andrychowicz",
                "Misha Denil",
                "Sergio Gomez",
                "Matthew W Hoffman",
                "David Pfau",
                "Tom Schaul",
                "Brendan Shillingford",
                "Nando De Freitas"
            ],
            "title": "Learning to learn by gradient descent by gradient descent",
            "venue": "NeurIPS,",
            "year": 2016
        },
        {
            "authors": [
                "James Atwood",
                "Don Towsley"
            ],
            "title": "Diffusion-convolutional neural networks",
            "venue": "NeurIPS,",
            "year": 2016
        },
        {
            "authors": [
                "Zhou Bolei",
                "Khosla Aditya",
                "Lapedriza Agata",
                "Oliva Aude",
                "Torralba Antonio"
            ],
            "title": "Learning deep features for discriminative localization",
            "venue": "CVPR,",
            "year": 2016
        },
        {
            "authors": [
                "Joan Bruna",
                "Wojciech Zaremba",
                "Arthur Szlam",
                "Yann LeCun"
            ],
            "title": "Spectral networks and locally connected networks on graphs",
            "venue": "arXiv preprint arXiv:1312.6203,",
            "year": 2013
        },
        {
            "authors": [
                "Wei-Yu Chen",
                "Yen-Cheng Liu",
                "Zsolt Kira",
                "Yu-Chiang Frank Wang",
                "Jia-Bin Huang"
            ],
            "title": "A closer look at few-shot classification",
            "venue": "ICLR,",
            "year": 2019
        },
        {
            "authors": [
                "Micha\u00ebl Defferrard",
                "Xavier Bresson",
                "Pierre Vandergheynst"
            ],
            "title": "Convolutional neural networks on graphs with fast localized spectral filtering",
            "venue": "NeurIPS,",
            "year": 2016
        },
        {
            "authors": [
                "Carl Doersch",
                "Ankush Gupta",
                "Andrew Zisserman"
            ],
            "title": "Crosstransformers: spatially-aware fewshot transfer",
            "venue": "NeurIPS,",
            "year": 2020
        },
        {
            "authors": [
                "Nanqing Dong",
                "Eric Xing"
            ],
            "title": "Fewshot semantic segmentation with prototype learning",
            "venue": "BMVC,",
            "year": 2018
        },
        {
            "authors": [
                "Mark Everingham",
                "Luc Van Gool",
                "Christopher KI Williams",
                "John Winn",
                "Andrew Zisserman"
            ],
            "title": "The pascal visual object classes (voc) challenge",
            "venue": "International journal of computer vision, 88(2):303\u2013338,",
            "year": 2010
        },
        {
            "authors": [
                "Qi Fan",
                "Wei Zhuo",
                "Chi-Keung Tang",
                "Yu-Wing Tai. Few-shot object detection with attentionrpn",
                "multi-relation detector"
            ],
            "title": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "venue": "pages 4013\u20134022,",
            "year": 2020
        },
        {
            "authors": [
                "Zhibo Fan",
                "Yuchen Ma",
                "Zeming Li",
                "Jian Sun. Generalized few-shot object detection without forgetting"
            ],
            "title": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "venue": "pages 4527\u2013 4536,",
            "year": 2021
        },
        {
            "authors": [
                "Chelsea Finn",
                "Pieter Abbeel",
                "Sergey Levine"
            ],
            "title": "Model-agnostic meta-learning for fast adaptation of deep networks",
            "venue": "ICML,",
            "year": 2017
        },
        {
            "authors": [
                "Gidaris",
                "Komodakis",
                "2019] Spyros Gidaris",
                "Nikos Komodakis"
            ],
            "title": "Generating classification weights with gnn",
            "year": 2019
        },
        {
            "authors": [
                "Justin Gilmer",
                "Samuel S Schoenholz",
                "Patrick F Riley",
                "Oriol Vinyals",
                "George E Dahl"
            ],
            "title": "Neural message passing for quantum chemistry",
            "venue": "ICML,",
            "year": 2017
        },
        {
            "authors": [
                "Ryan Grainger",
                "Thomas Paniagua",
                "Xi Song",
                "Tianfu Wu"
            ],
            "title": "Learning patch-tocluster attention in vision transformer",
            "venue": "arXiv preprint arXiv:2203.11987,",
            "year": 2022
        },
        {
            "authors": [
                "Ruibing Hou",
                "Hong Chang",
                "MA Bingpeng",
                "Shiguang Shan",
                "Xilin Chen"
            ],
            "title": "Cross attention network for few-shot classification",
            "venue": "NeurIPS,",
            "year": 2019
        },
        {
            "authors": [
                "Hu et al",
                "2021] Hanzhe Hu",
                "Shuai Bai",
                "Aoxue Li",
                "Jinshi Cui",
                "Liwei Wang"
            ],
            "title": "Dense relation distillation with context-aware aggregation for few-shot object detection",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Xie Jiangtao",
                "Long Fei",
                "Lv Jiaming",
                "Wang Qilong",
                "Li Peihua"
            ],
            "title": "Joint distribution matters: Deep brownian distance covariance for few-shot classification",
            "venue": "CVPR,",
            "year": 2022
        },
        {
            "authors": [
                "Lai Jinxiang",
                "Yang Siqian"
            ],
            "title": "Adaptive multi distance metrics for few-shot classification",
            "venue": "arXiv,",
            "year": 2022
        },
        {
            "authors": [
                "Bingyi Kang",
                "Zhuang Liu",
                "Xin Wang",
                "Fisher Yu",
                "Jiashi Feng",
                "Trevor Darrell. Few-shot object detection via feature reweighting"
            ],
            "title": "In Proceedings of the IEEE/CVF International Conference on Computer Vision",
            "venue": "pages 8420\u20138429,",
            "year": 2019
        },
        {
            "authors": [
                "Thomas N. Kipf",
                "Max Welling"
            ],
            "title": "Semi-supervised classification with graph convolutional networks",
            "venue": "ICLR,",
            "year": 2017
        },
        {
            "authors": [
                "Alex Krizhevsky",
                "Ilya Sutskever",
                "Geoffrey E Hinton"
            ],
            "title": "Imagenet classification with deep convolutional neural networks",
            "venue": "NeurIPS,",
            "year": 2012
        },
        {
            "authors": [
                "Kwonjoon Lee",
                "Subhransu Maji",
                "Avinash Ravichandran",
                "Stefano Soatto"
            ],
            "title": "Meta-learning with differentiable convex optimization",
            "venue": "CVPR,",
            "year": 2019
        },
        {
            "authors": [
                "Ron Levie",
                "Federico Monti",
                "Xavier Bresson",
                "Michael M Bronstein"
            ],
            "title": "Cayleynets: Graph convolutional neural networks with complex rational spectral filters",
            "venue": "TSP, 67(1):97\u2013109,",
            "year": 2018
        },
        {
            "authors": [
                "Justin Liang",
                "Namdar Homayounfar",
                "Wei-Chiu Ma",
                "Yuwen Xiong",
                "Rui Hu",
                "Raquel Urtasun"
            ],
            "title": "Polytransform: Deep polygon transformer for instance segmentation",
            "venue": "CVPR,",
            "year": 2020
        },
        {
            "authors": [
                "Tsung-Yi Lin",
                "Michael Maire",
                "Serge Belongie",
                "James Hays",
                "Pietro Perona",
                "Deva Ramanan",
                "Piotr Doll\u00e1r",
                "C Lawrence Zitnick"
            ],
            "title": "Microsoft coco: Common objects in context",
            "venue": "ECCV,",
            "year": 2014
        },
        {
            "authors": [
                "Tsung-Yi Lin",
                "Michael Maire",
                "Serge Belongie",
                "James Hays",
                "Pietro Perona",
                "Deva Ramanan",
                "Piotr Doll\u00e1r",
                "C Lawrence Zitnick"
            ],
            "title": "Microsoft coco: Common objects in context",
            "venue": "ECCV,",
            "year": 2014
        },
        {
            "authors": [
                "Weide Liu",
                "Chi Zhang",
                "Guosheng Lin",
                "Fayao Liu"
            ],
            "title": "CRNet: Cross-reference networks for fewshot segmentation",
            "venue": "CVPR,",
            "year": 2020
        },
        {
            "authors": [
                "Yongfei Liu",
                "Xiangyi Zhang",
                "Songyang Zhang",
                "Xuming He"
            ],
            "title": "Part-aware prototype network for few-shot semantic segmentation",
            "venue": "ECCV,",
            "year": 2020
        },
        {
            "authors": [
                "Chen Liu",
                "Yanwei Fu",
                "Chengming Xu",
                "Siqian Yang",
                "Jilin Li",
                "Chengjie Wang",
                "Li Zhang"
            ],
            "title": "Learning a few-shot embedding model with contrastive learning",
            "venue": "AAAI,",
            "year": 2021
        },
        {
            "authors": [
                "Boudiaf Malik",
                "Kervadec Hoel",
                "Imtiaz Masud Ziko",
                "Piantanida Pablo",
                "Ben Ayed Ismail"
            ],
            "title": "and Dolz Jose",
            "venue": "Few-shot segmentation without meta-learning: A good transductive inference is all you need? In CVPR,",
            "year": 2021
        },
        {
            "authors": [
                "Tsendsuren Munkhdalai",
                "Hong Yu"
            ],
            "title": "Meta networks",
            "venue": "ICML,",
            "year": 2017
        },
        {
            "authors": [
                "Khoi Nguyen",
                "Sinisa Todorovic"
            ],
            "title": "Feature weighting and boosting for few-shot segmentation",
            "venue": "ICCV,",
            "year": 2019
        },
        {
            "authors": [
                "Alex Nichol",
                "Joshua Achiam",
                "John Schulman"
            ],
            "title": "On first-order meta-learning algorithms",
            "venue": "arXiv preprint arXiv:1803.02999,",
            "year": 2018
        },
        {
            "authors": [
                "Mathias Niepert",
                "Mohamed Ahmed",
                "Konstantin Kutzkov"
            ],
            "title": "Learning convolutional neural networks for graphs",
            "venue": "ICML,",
            "year": 2016
        },
        {
            "authors": [
                "Limeng Qiao",
                "Yuxuan Zhao",
                "Zhiyuan Li",
                "Xi Qiu",
                "Jianan Wu",
                "Chi Zhang"
            ],
            "title": "Defrcn: Decoupled faster r-cnn for few-shot object detection",
            "venue": "ICCV,",
            "year": 2021
        },
        {
            "authors": [
                "Kate Rakelly",
                "Evan Shelhamer",
                "Trevor Darrell",
                "Alyosha Efros",
                "Sergey Levine"
            ],
            "title": "Conditional networks for few-shot semantic segmentation",
            "venue": "ICLR Workshop,",
            "year": 2018
        },
        {
            "authors": [
                "Sachin Ravi",
                "Hugo Larochelle"
            ],
            "title": "Optimization as a model for few-shot learning",
            "venue": "ICLR,",
            "year": 2017
        },
        {
            "authors": [
                "Mengye Ren",
                "Eleni Triantafillou",
                "Sachin Ravi",
                "Jake Snell",
                "Kevin Swersky",
                "Joshua B Tenenbaum",
                "Hugo Larochelle",
                "Richard S Zemel"
            ],
            "title": "Meta-learning for semi-supervised few-shot classification",
            "venue": "ICLR,",
            "year": 2018
        },
        {
            "authors": [
                "Mamshad Nayeem Rizve",
                "Salman Khan",
                "Fahad Shahbaz Khan",
                "Mubarak Shah"
            ],
            "title": "Exploring complementary strengths of invariant and equivariant representations for few-shot learning",
            "venue": "CVPR,",
            "year": 2021
        },
        {
            "authors": [
                "Amirreza Shaban",
                "Shray Bansal",
                "Zhen Liu",
                "Irfan Essa",
                "Byron Boots"
            ],
            "title": "One-shot learning for semantic segmentation",
            "venue": "BMVC,",
            "year": 2018
        },
        {
            "authors": [
                "Mennatullah Siam",
                "Boris N Oreshkin",
                "Martin Jagersand"
            ],
            "title": "AMP: Adaptive masked proxies for few-shot segmentation",
            "venue": "ICCV,",
            "year": 2019
        },
        {
            "authors": [
                "Christian Simon",
                "Piotr Koniusz",
                "Richard Nock",
                "Mehrtash Harandi"
            ],
            "title": "Adaptive subspaces for few-shot learning",
            "venue": "CVPR,",
            "year": 2020
        },
        {
            "authors": [
                "Jake Snell",
                "Kevin Swersky",
                "Richard Zemel"
            ],
            "title": "Prototypical networks for few-shot learning",
            "venue": "NeurIPS,",
            "year": 2017
        },
        {
            "authors": [
                "Jong-Chyi Su",
                "Subhransu Maji"
            ],
            "title": "and Bharath Hariharan",
            "venue": "When does self-supervision improve few-shot learning? In ECCV,",
            "year": 2020
        },
        {
            "authors": [
                "Bo Sun",
                "Banghuai Li",
                "Shengcai Cai",
                "Ye Yuan",
                "Chi Zhang"
            ],
            "title": "Fsce: Few-shot object detection via contrastive proposal encoding",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7352\u20137362,",
            "year": 2021
        },
        {
            "authors": [
                "Yonglong Tian",
                "Yue Wang",
                "Dilip Krishnan",
                "Joshua B Tenenbaum"
            ],
            "title": "and Phillip Isola",
            "venue": "Rethinking few-shot image classification: a good embedding is all you need? In ECCV,",
            "year": 2020
        },
        {
            "authors": [
                "Zhuotao Tian",
                "Hengshuang Zhao",
                "Michelle Shu",
                "Zhicheng Yang",
                "Ruiyu Li",
                "Jiaya Jia"
            ],
            "title": "Prior guided feature enrichment network for few-shot segmentation",
            "venue": "TPAMI,",
            "year": 2020
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "NeurIPS,",
            "year": 2017
        },
        {
            "authors": [
                "Oriol Vinyals",
                "Charles Blundell",
                "Timothy Lillicrap",
                "Daan Wierstra"
            ],
            "title": "et al",
            "venue": "Matching networks for one shot learning. In NeurIPS,",
            "year": 2016
        },
        {
            "authors": [
                "Kaixin Wang",
                "Jun Hao Liew",
                "Yingtian Zou",
                "Daquan Zhou",
                "Jiashi Feng"
            ],
            "title": "Panet: Few-shot image semantic segmentation with prototype alignment",
            "venue": "ICCV,",
            "year": 2019
        },
        {
            "authors": [
                "Haochen Wang",
                "Xudong Zhang",
                "Yutao Hu",
                "Yandan Yang",
                "Xianbin Cao",
                "Xiantong Zhen"
            ],
            "title": "Fewshot semantic segmentation with democratic attention networks",
            "venue": "ECCV,",
            "year": 2020
        },
        {
            "authors": [
                "Xin Wang",
                "Thomas E Huang",
                "Trevor Darrell",
                "Joseph E Gonzalez",
                "Fisher Yu"
            ],
            "title": "Frustratingly simple few-shot object detection",
            "venue": "arXiv preprint arXiv:2003.06957,",
            "year": 2020
        },
        {
            "authors": [
                "Wenhai Wang",
                "Enze Xie",
                "Xiang Li",
                "Deng-Ping Fan",
                "Kaitao Song",
                "Ding Liang",
                "Tong Lu",
                "Ping Luo",
                "Ling Shao"
            ],
            "title": "Pyramid vision transformer: A versatile backbone for dense prediction without convolutions",
            "venue": "ICCV,",
            "year": 2021
        },
        {
            "authors": [
                "Davis Wertheimer",
                "Luming Tang",
                "Bharath Hariharan"
            ],
            "title": "Few-shot classification with feature map reconstruction networks",
            "venue": "CVPR,",
            "year": 2021
        },
        {
            "authors": [
                "Jiaxi Wu",
                "Songtao Liu",
                "Di Huang",
                "Yunhong Wang. Multi-scale positive sample refinement for few-shot object detection. In European conference on computer vision"
            ],
            "title": "pages 456\u2013472",
            "venue": "Springer,",
            "year": 2020
        },
        {
            "authors": [
                "Shuang Wu",
                "Wenjie Pei",
                "Dianwen Mei",
                "Fanglin Chen",
                "Jiandong Tian",
                "Guangming Lu"
            ],
            "title": "Multifaceted distillation of base-novel commonality for fewshot object detection",
            "venue": "ECCV,",
            "year": 2022
        },
        {
            "authors": [
                "Yang Xiao",
                "Renaud Marlet"
            ],
            "title": "Few-shot object detection and viewpoint estimation for objects in the wild",
            "venue": "ECCV,",
            "year": 2020
        },
        {
            "authors": [
                "Yang Xiao",
                "Renaud Marlet. Few-shot object detection",
                "viewpoint estimation for objects in the wild. In European conference on computer vision"
            ],
            "title": "pages 192\u2013210",
            "venue": "Springer,",
            "year": 2020
        },
        {
            "authors": [
                "Chengming Xu",
                "Yanwei Fu",
                "Chen Liu",
                "Chengjie Wang",
                "Jilin Li",
                "Feiyue Huang",
                "Li Zhang",
                "Xiangyang Xue"
            ],
            "title": "Learning dynamic alignment via meta-filter for few-shot learning",
            "venue": "CVPR,",
            "year": 2021
        },
        {
            "authors": [
                "Luo Xu",
                "Wei Longhui",
                "Wen Liangjian",
                "Yang Jinrong",
                "Xie Lingxi",
                "Xu Zenglin",
                "Tian Qi"
            ],
            "title": "Rectifying the shortcut learning of background for few-shot learning",
            "venue": "NeurIPS,",
            "year": 2021
        },
        {
            "authors": [
                "Xiaopeng Yan",
                "Ziliang Chen",
                "Anni Xu",
                "Xiaoxi Wang",
                "Xiaodan Liang",
                "Liang Lin"
            ],
            "title": "Meta r-cnn: Towards general solver for instance-level low-shot learning",
            "venue": "Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9577\u20139586,",
            "year": 2019
        },
        {
            "authors": [
                "Boyu Yang",
                "Chang Liu",
                "Bohao Li",
                "Jianbin Jiao",
                "Qixiang Ye"
            ],
            "title": "Prototype mixture models for few-shot semantic segmentation",
            "venue": "ECCV,",
            "year": 2020
        },
        {
            "authors": [
                "Liu Yang",
                "Zhang Weifeng",
                "Xiang Chao",
                "Zheng Tu",
                "Cai Deng",
                "He Xiaofei"
            ],
            "title": "Learning to affiliate: Mutual centralized learning for few-shot classification",
            "venue": "CVPR,",
            "year": 2022
        },
        {
            "authors": [
                "Chi Zhang",
                "Guosheng Lin",
                "Fayao Liu",
                "Jiushuang Guo",
                "Qingyao Wu",
                "Rui Yao"
            ],
            "title": "Pyramid graph networks with connection attentions for region-based oneshot semantic segmentation",
            "venue": "ICCV,",
            "year": 2019
        },
        {
            "authors": [
                "Chi Zhang",
                "Guosheng Lin",
                "Fayao Liu",
                "Rui Yao",
                "Chunhua Shen"
            ],
            "title": "CANet: Class-agnostic segmentation networks with iterative refinement and attentive few-shot learning",
            "venue": "CVPR,",
            "year": 2019
        },
        {
            "authors": [
                "Chi Zhang",
                "Yujun Cai",
                "Guosheng Lin",
                "Chunhua Shen"
            ],
            "title": "Deepemd: Few-shot image classification with differentiable earth mover\u2019s distance and structured classifiers",
            "venue": "CVPR,",
            "year": 2020
        },
        {
            "authors": [
                "Xiaolin Zhang",
                "Yunchao Wei",
                "Yi Yang",
                "Thomas S Huang"
            ],
            "title": "SG-one: Similarity guidance network for one-shot semantic segmentation",
            "venue": "IEEE Transactions on Cybernetics,",
            "year": 2020
        },
        {
            "authors": [
                "Sixiao Zheng",
                "Jiachen Lu",
                "Hengshuang Zhao",
                "Xiatian Zhu",
                "Zekun Luo",
                "Yabiao Wang",
                "Yanwei Fu",
                "Jianfeng Feng",
                "Tao Xiang",
                "Philip HS Torr"
            ],
            "title": "et al",
            "venue": "Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers. In CVPR,",
            "year": 2021
        },
        {
            "authors": [
                "Chen Zhengyu",
                "Ge Jixie",
                "Zhan Heshen",
                "Huang Siteng",
                "Wang Donglin"
            ],
            "title": "Pareto selfsupervised training for few-shot learning",
            "venue": "CVPR,",
            "year": 2021
        },
        {
            "authors": [
                "Xizhou Zhu",
                "Weijie Su",
                "Lewei Lu",
                "Bin Li",
                "Xiaogang Wang",
                "Jifeng Dai"
            ],
            "title": "Deformable detr: Deformable transformers for end-to-end object detection",
            "venue": "ICLR,",
            "year": 2020
        },
        {
            "authors": [
                "Wu Zonghan",
                "Pan Shirui",
                "Chen Fengwen",
                "Long Guodong",
                "Zhang Chengqi",
                "S. Yu Philip"
            ],
            "title": "A comprehensive survey on graph neural networks",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems,",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "In contrast to general deep learning task [Krizhevsky et al., 2012], Few-Shot Learning (FSL) aims to learn a transferable classifier with amount seen images (base class) and few labeled unseen images (novel class). Due to the lack of effective features from unseen classes, a robust feature embedding model is indispensable. Recent researchers[Hou et al., 2019; Rizve et al., 2021; Xu et al., 2021a] manage to design an embedding network for generating more discriminative features.\n\u2217Corresponding Author\nTraditional Cross Attention\nOur Clustered-patch Element Connection\n(Local info)\n(Global info)\nPatch Cluster\n(Local info)\nReliable & Concise connection\nInaccurate\nAccurate\nUnreliable & Redundant connection\nSupport\nQuery\nPatch Dense Connection\nCollect Similar Patches\nFigure 1: Comparison between traditional Cross Attention and our Clustered-patch Element Connection. The proposed Clusteredpatch Element Connection, which utilizes the global info Cp integrated from support feature P to perform element connection with query Q leading to a confident and clear connection, is able to generate a more clear and precise relation map than Cross Attention. The detailed Patch Cluster operation is illustrated in Fig.2. The visualization comparisons are referred to Fig.4(a).\nSpecifically, cross attention based methods [Hou et al., 2019; Xu et al., 2021a; Xu et al., 2021b] focus on reducing the background noise and highlighting the target region to generate more discriminative representations. The core idea of these methods is to divide extracted features into patches and connect all local patch features. However, as shown in Fig.1, we observe that the target object may be located randomly with different scales among the query images. Hence, these methods suffer two main problems: inconsistent seman-\nar X\niv :2\n30 4.\n10 09\n3v 2\n[ cs\n.C V\n] 1\n0 M\nay 2\n02 3\ntic in feature space, and unreliable and redundant connections. To tackle these problems, we propose a Clustered-patch Element Connection (CEC) layer which consists of Patch Cluster and Element Connection operations. In detail, given inputs features P (support) and Q (query), CEC layer firstly obtains the global clustered-patch Cp features by Patch Cluster operation as illustrated in Fig.2, then performs Element Connection on Q by using Cp, and finally produces a more discriminative representation Q\u0304. Patch Cluster aims to collect the objects in source feature P that are similar to the reference patch inQ, which adaptively alignments the P intoCP to obtain a consistent semantic feature for each patch of Q. Then, with the global clustered-patch features, CEC layer generates more reliable and concise connections than cross attention.\nAccording to CEC layer, we find the key of generating accurate relation map is to obtain appropriate clustered-patch features. In this paper, four solutions are introduced to perform Patch Cluster, including MatMul, Cosine, GCN and Transformer. Different from the naive MatMul and Cosine modes, we propose the meta-GCN and Transformer based Patch Cluster operations to obtain a more robust clusteredpatch by implementing additional feature refinement. The insight of meta-GCN is constructing a dynamic correlationbased adjacent for each current input pair-features, other than the static GCN [Kipf and Welling, 2017] using a fixed adjacent. Besides, the transformer structure obtains global information via modeling a spatio-temporal correlation among instances, which generates a more accurate relation map.\nAlong with the description of CEC mechanism, we propose three CEC-based modules: (I) The Clustered-patch Element Connection Module (CECM) distinguishes the background and the object for each image pair (support and query) at the feature level adaptively, which gives a more precise highlights at the regions of target object; (II) The Self-CECM enhances the semantic feature of target object in a self-attention manner to make the representation more robust; (III) The Clusteredpatch Element Connection Distance (CECD) is a CEC-based distance metric which measures the similarity between pairfeatures via the obtained reliable relation map.\nFor few-shot classification task, we introduce a novel Clustered-patch Element Connection Network (CECNet) as illustrated in Fig.3, which learns a generalize-well embedding benefiting from auxiliary tasks, generates a discriminative representation via CECM and Self-CECM, and measures a reliable similarity map via CECD. Furthermore, we derive a novel CEC-based embedding module named CEC Embedding (CECE), which can be applied into few-shot semantic segmentation (FSSS) and few-shot object detection (FSOD) tasks. We simply stack the proposed CECE after the backbone network of the existing FSSS and FSOD methods, which achieves consistent improvements around 1%\u2212 3%.\nTo summarize, our main contributions are: \u2022 We propose a Clustered-patch Element Connection (CEC) layer to strengthen the target regions of query features by element-wisely connecting them with the global clusteredpatch features. Four different CEC modes are introduced, including MatMul, Cosine, GCN and Transformer. \u2022 We derive three CEC-based modules: CECM and SelfCECM modules are utilized to produce more discriminative\nPatch Cluster\nrepresentations, and CECD is able to measure a reliable similarity map. \u2022 With CEC-based modules and auxiliary tasks, a novel CECNet model is designed for few-shot classification. CECNet improves state-of-the-arts on few-shot classification benchmark, and the experiments demonstrate that our method is effective in FSL. \u2022 Furthermore, our CECE (i.e. CEC-based embedding module) can be extended into few-shot segmentation and detection tasks, which achieves performance improvements around 1%\u2212 3% on the corresponding benchmarks."
        },
        {
            "heading": "2 Related Work",
            "text": "Few-Shot Learning The FSL algorithms aim to recognize novel categories with few labeled images, and a categorydisjoint base set with abundant images is provided for pretraining. The classic FSL tasks include few-shot classification [Finn et al., 2017; Vinyals et al., 2016; Snell et al., 2017; Hou et al., 2019; Tian et al., 2020a], semantic segmentation [Zhang et al., 2020b; Siam et al., 2019; Malik et al., 2021] and object detection [Kang et al., 2019; Wang et al., 2020b; Qiao et al., 2021]. More introductions are presented in APPENDIX. In a word, the existing FSL methods lack a uniform function to control the connections among the patches between support and query instances semantically. Other Related Works are introduced in APPENDIX, such as Auxiliary Task for FSL [Hou et al., 2019; Rizve et al., 2021], Graph Convolutional Network (GCN) [Bruna et al., 2013], and Transformer [Vaswani et al., 2017]."
        },
        {
            "heading": "3 Problem Definition",
            "text": ""
        },
        {
            "heading": "3.1 Few-Shot Classification",
            "text": "A classic few-shot classification problem is specified as a N -way K-shot task, which means solving a N -class classification problem with only K labeled instances provided per class. In the recent investigations[Hou et al., 2019; Snell et al., 2017], the source dataset is divided into three category-disjoint parts: training set Xtrain, validation set Xval and test set Xtest. Moreover, the episodic training\nmechanism is widely adopted. An episode consists of two sets (randomly sampling inN categories): support and query. Let S = {(xsi , ysi )} ns i=1 (ns = N \u00d7 K) denote the support set, and Q = {(xqi , y q i )} nq i=1 denote the query set. Note that ns and nq are the size of corresponding sets. Especially, S = {S1,S2, ...,Sk}, where Sk denotes the support set of the kth category in S. Specifically, let (P , Q) \u2208 Rhw\u00d7c denote the support and query features, which are extracted from support subset and query instance (Sk, xq). Note that c, h, w are channel number, height, width of features, respectively."
        },
        {
            "heading": "3.2 Cross Attention",
            "text": "The traditional Cross Attention [Hou et al., 2019] proves that highlighting target regions could generate more discriminative representations, leading to accuracy improvements for FSL. The key is to generate an fine-grained relation map RQ \u2208 Rhw to represent the target regions in Q \u2208 Rhw\u00d7c. Then, a spatial-wise feature attention can be obtained through RQ Q, where is the Element-wise Product. The traditional Cross Attention produces relation map RQ for Q by:\nRQ = h\n( P\n||P ||2\n( Q\n||Q||2\n)T) , (1)\nwhere h is a CNN-based layer to refine the correlation matrix P||P ||2 ( Q ||Q||2 )\nT \u2208 Rhw\u00d7hw. According to Eq.1, the Cross Attention produces relation map by Local-to-Local fully connection among local feature patches of P and Q. In detail, (Pi, Qj) \u2208 R1\u00d7c represent a pair of support feature patch and query feature patch among (P,Q) \u2208 Rhw\u00d7c . As shown in Fig.1, the target object may be located unregularly among the query images at different scale, which results in inconsistent semantic in feature space, i.e feature patches Pi and Qj may be semantically inconsistent. This semantically inconsistent problem causes low confident correlation between patches, and the complex Local-to-Local fully connection further accumulates this inaccurate bias, which affect the quality of the generated relation map.\nTo establish concise and clear connections among global and local features, we propose a Clustered-patch Element Connection layer (CEC), which consists of two key operations: Patch Cluster and Element Connection."
        },
        {
            "heading": "4 Clustered-patch Element Connection",
            "text": ""
        },
        {
            "heading": "4.1 Patch Cluster",
            "text": "As illustrated in Fig.2, Patch Cluster operation obtains a set Cp, named Clustered-patch, via collecting those objects in support feature set P , which are similar to the reference patch in Q. We define a generic Patch Cluster operation fPC as:\nCp = fPC(Q,P ) = \u03c6 (g (Q,P )P ) . (2)\nHere P is the input source feature, Q is the input reference feature, and Cp \u2208 Rhw\u00d7c is the output Clustered-patch. A pairwise function g computes an affinity matrix representing relationship between Q and P . The clustered patches can be refined by function \u03c6. In detail, we divide the source image into w \u00d7 h patches. Here, w and h are the same as the size\nof the features in P , which is convenient for element connection operation. A Clustered-patch Cp \u2208 Rhw\u00d7c collects w \u00d7 h clusters. Each cluster collects the patch-features in P = [P1, P2, ..., Phw] \u2208 Rhw\u00d7c that are similar to the corresponding patch-feature in the reference patch-features in Q. Therefore, Cp is semantically similar to Q.\nTo implement the Patch Cluster operation, we give four solutions including MatMul, Cosine, GCN and Transformer. MatMul A simplest way to obtain the clustered patches is treating MatMul operation as the pairwise function g (in Eq.(2)) and not implementing any further embedding refinement. Formally,\nCp = \u03c3 ( QPT ) P, (3)\nwhere \u03c3 is softmax function. Cosine A simple extension of the MatMul version is to compute cosine similarity in feature space. Formally,\nCp = \u03c3\n( Q\n||Q||2\n( P\n||P ||2\n)T) P. (4)\nGCN GCN [Kipf and Welling, 2017] updates the input features P via utilizing a pre-defined adjacent matrix A \u2208 Rhw\u00d7hw and a learnable weight matrix W \u2208 Rc\u00d7c. Formally, the updated features Gp \u2208 Rhw\u00d7c can be expressed as: Gp = \u03b4(APW ), where \u03b4(\u00b7) is the nonlinear activation function (Sigmoid(\u00b7) or ReLU(\u00b7)). However, the adjacent matrix A used in GCN is fixed for all inputs after training, which is not able to recognize the new categories in few-shot task. Comparing Eq.(2) and the definition of GCN, we observe that the affinity matrix g (Q,P ) can be considered as the adjacent matrix A, because they all try to describe the relationship between features P and Q. Hence, we derive a meta-GCN through replacing the static adjacent matrix with the dynamic affinity matrix. Formally, the meta-GCN based Patch Cluster operation is derived as follows:\nCp = \u03b4 [ \u03c3 ( Q\n||Q||2\n( P\n||P ||2\n)T) PW ] . (5)\nTransformer The Transformer[Vaswani et al., 2017] based Patch Cluster operation is defined as follows:\nCp = FFN{\u03c3[(WqQ)(WkPT )]WvP}, (6)\nwhere, FFN is the Feed-Forward Network in transformer, Wq,Wk,Wv are learnable weights (e.g. convolution layers)."
        },
        {
            "heading": "4.2 Element Connection",
            "text": "According to the global semantic features Cp obtained from Patch Cluster operation, element Connection operation generates the relation map RQ for Q by simply computing the patch-wise cosine similarity between Q and Cp. Finally, we obtain a rectified discriminative representation by the Element Connection operation fEC :\nQ\u0304 = fEC(Q,C p) = ( \u03c3 ( RQ ) + 1 ) Q,\nwhere, RQ =\n( Q\n||Q||2 \u2297 C\np\n||Cp||2\n) \u2208 Rhw,\n(7)\nwhere,\u2297 is Patch-wise Dot Product, is Element-wise Product. The nth position of RQ is RQn = Qn ||Qn||2 \u00b7 Cpn ||Cpn||2 , where \u00b7 is Dot Product. The visualizations of the CEC-based relation map RQ are shown at the last column in Fig.4(b). Overall, the Clustered-patch Element Connection (CEC) layer is able to highlight the regions of Q that are semantically similar to P . Formally, CEC layer fCEC is expressed as:\nQ\u0304 = fCEC(Q,P ) = fEC (Q, fPC(Q,P )) . (8)"
        },
        {
            "heading": "4.3 Discussion",
            "text": "Compared with traditional Cross Attention, the key point of our Clustered-patch Element Connection is to perform the Global-to-Local element connection between the Clusteredpatch Cp (global) and query Q (local). It is able to generate a more clear and precise relation map, as shown in Fig. 4(a) visualizations. As demonstrated in Tab. 2, our CEC-based approach achieves 4% accuracy improvement than the traditional Cross Attention based CAN [Hou et al., 2019].\nGenerally, the advantages of our Clustered-patch Element Connection are: (I) The relation map generated by Element Connection is more confident than Cross Attention, because the global Clustered-patch feature Cp is more stable and representative than the local feature P . (II) Element Connection (1-to-1 patch-connection) has more clear connection relationship than Cross Attention (1-to-hw patch-connection).\nMoreover, the respective advantages of different solutions for realizing Patch Cluster are: (I) These four solutions can be divided into two groups: fixed (i.e. MatMul and Cosine) and learnable (i.e. GCN and Transformer) solutions. The fixed solutions can be used to perform patch clustering without additional learnable parameters, while the learnable solutions are data-driven to refine the affinity matrix or clustered-patch. (II) According to experimental results in Tab. 2, the learnable solutions are better than the fixed ones when they are applied as a embedding layer for feature enhancing (i.e. CECM defined in Eq. 9), which indicates that the learnable solutions can generate better embedding features. In contrast, according to Tab. 3, the fixed solutions are better than the learnable ones when they are applied as the distance metric for measuring similarity (i.e. CECD defined in Eq. 11), which indicates fixed solutions can obtain more reliable similarity scores."
        },
        {
            "heading": "5 CEC Network for Few-Shot Classification",
            "text": ""
        },
        {
            "heading": "5.1 CEC Module and Self-CEC Module",
            "text": "According to the CEC layer mentioned above, we propose two derivative modules: the CEC Module (CECM) and the Self-CEC Module (self-CECM). The CECM is able to highlight the mutual similar regions via learning the semantic relevance between pair feature. Specifically, CECM transfers the input pair-features (P , Q) \u2208 Rhw\u00d7c into more discriminative representations (P\u0304 , Q\u0304) \u2208 Rhw\u00d7c. Formally, its function fCECM is expressed as:\n(Q\u0304, P\u0304 ) = fCECM (Q,P ),\nwhere, Q\u0304 = fCEC(Q,P ), P\u0304 = fCEC(P,Q). (9)\nThe Self-CECM enhances the semantic feature of target object via self-connection, which turns the input Q into Q\u0304 \u2208 Rhw\u00d7c. Formally, Self-CECM function fSCECM is expressed as:\nQ\u0304 = fSCECM (Q) = fCEC(Q,Q). (10)\nThe CECM exploit the relation between P and Q via Q\u0304 = fCEC(Q,P ), while Self-CECM exploit the relation between the input itself via Q\u0304 = fCEC(Q,Q), i.e. Self-CECM explores the relation between the patches of input image. Because we assume that patch-features of the target are mutually similar, Self-CECM can enhance the target region by clustering the similar regions."
        },
        {
            "heading": "5.2 CECNet Framework",
            "text": "Then, we give the overall Clustered-patch Element Connection Network (CECNet). The framework is shown in Fig.3, which integrates CECM, Metric Classifier and Finetune Classifier for few-shot classification task, and Rotation Classifier and Global Classifier for the auxiliary tasks. The network involves three stages: Base Training, Novel Finetuning and Novel Inference. Base Training As illustrated in Fig.3, every image xq in query set Q = {(xqi , y q i )} nq i=1 is rotated with [0\n\u25e6, 90\u25e6, 180\u25e6, 270\u25e6] and outputs a rotated Q\u0303 = {(x\u0303qi , y\u0303 q i )} nq\u00d74 i=1 . The support subset Sk and the rotated query instance x\u0303q are processed by the embedding f\u03b8 and produces the prototype feature P k = 1|Sk| \u2211 xsi\u2208Sk f\u03b8(x s i ) and query feature Q = f\u03b8(x\u0303\nq) \u2208 Rc\u00d7h\u00d7w, respectively. Then each pair-features (P k, Q) are processed via CECM to enhance the mutually similar regions and generates more discriminative features (P\u0304 k, Q\u0304k) for the subsequent classification. Note that the inputs and outputs of CECM will be reshaped to satisfied its format. Finally, CECNet is optimized via multi-task loss contributing from metric classifier and auxiliary tasks. Novel Fine-tuning The Fine-tune Classifier consists of SelfCECM and a linear layer as shown in Fig.3. In fine-tuning phase, the pre-trained embedding f\u03b8 is frozen, and the Finetune Classifier is optimized with cross-entropy loss. Novel Inference In inductive inference, the overall prediction of CECNet is Y = YM + YF , where YM and YF are the results of Metric and Fine-tune Classifiers respectively."
        },
        {
            "heading": "5.3 Metric Classifier",
            "text": "As illustrated in Eq. 7, the proposed CEC layer is able to generate a reliable relation map RQ. The relation map RQ can also be utilized as a similarity map, and the mean of RQ is the similarity score. Therefore, we obtain the CECD distance metric dCECD which is expressed as:\ndCECD(Q\u0304, P\u0304 ) =\n( Q\u0304\n||Q\u0304||2 \u2297 C\np\u0304\n||C p\u0304||2\n) \u2208 Rhw. (11)\nWith the proposed CECD distance metric, the Metric Classifier make predictions by measuring the similarity between the query and the N support classes. Following [Hou et al., 2019], the patch-wise classification strategy is used to produce precise feature representations. In detail, each patchwise feature Q\u0304kn at n th spatial position of Q\u0304k, is recognized\nas N classes. And the probability of predicting Q\u0304kn as k th class is:\nY\u0302 (y = k|Q\u0304kn) = exp (Rkn)\u2211N i=1 exp (R i n) ,\nwhere, Rk = dCECD(Q\u0304 k, P\u0304 k) \u2208 Rhw,\n(12)\nwhere, the similarity map Rk is obtained by the CECD distance metric formulated in Eq. 11, and the similarity score Rkn is the n th position of Rk."
        },
        {
            "heading": "5.4 Fine-tune Classifier",
            "text": "The Fine-tune Classifier consists of Self-CECM and a linear layer. It predicts the query feature Q\u0304 into N categories by a linear layer WF . And its loss is computed as:\nLF = PCE ( WF (Q\u0304), N q )\n= \u2212 nq\u2211 i=1 h\u00d7w\u2211 n=1 Nqi log ( \u03c3 ( WF (Q\u0304n)i )) ,\n(13)\nwhere, PCE is patch-wise cross-entropy, and Nqi is the ground truth of xqi with N categories of few-shot task."
        },
        {
            "heading": "5.5 Objective functions in Base Training",
            "text": "Metric Loss The metric classification loss with the groundtruth few-shot label y\u0303q is:\nLM = \u2212 nq\u2211 i=1 h\u00d7w\u2211 n=1 log Y\u0302 (y = y\u0303qi |(Q\u0304n)i). (14)\nAuxiliary Loss The loss of Global Classifier is LG = PCE(WG(Q\u0304), D\nq), where Dqi is the global category of x\u0303qi with D classes of train set, and WG is a fullyconnected layer. Similarly, the loss of Rotation Classifier is LR = PCE(WR(Q\u0304), Bq), whereBqi is the rotation category of x\u0303qi with four classes, and WR is a fully-connected layer.\nMulti-Task Loss Then, inspired by [Jinxiang and Siqian, 2022], the overall loss is defined as:\nL = 1 2 LM + \u2211 j=G,R ( (\u03bb+ wj)Lj + log\n1\n(\u03bb+ wj)\n) , (15)\nwhere w = 12\u03b12 and \u03b1 is a learnable variable. The hyperparameter \u03bb is utilized to balance the few-shot and auxiliary tasks, of which the influence is studied in Tab. 4."
        },
        {
            "heading": "6 Experiments on Few-Shot Classification",
            "text": "Datasets The two popular FSL classification benchmark datasets are miniImageNet and tieredImageNet, where detailed introductions are presented in APPENDIX. Experimental Setup We report the mean accuracy by testing 2000 episodes randomly sampled from meta-test set. According to Tab. 4, the hyperparameter \u03bb is set to 1.0 and 2.0 for ResNet-12 and WRN-28, respectively. Other implementation details can be found in our public code."
        },
        {
            "heading": "6.1 Comparison with State-of-the-arts",
            "text": "As shown in Tab.1, we compare with the state-of-the-art fewshot methods on miniImageNet and tieredImageNet datasets. It shows that our CECNet outperforms the existing SOTAs, which demonstrates the effectiveness and strength of our CEC based methods. Different from existing metric-based methods [Zhang et al., 2020a; Yang et al., 2022; Jiangtao et al., 2022] extracting support and query features independently, our CECNet enhances the semantic feature regions of mutually similar objects and obtains more discriminative representations. Comparing to the metric-based Meta-DeepBDC [Jiangtao et al., 2022], CECNet achieves 1.98% higher accuracy on 1-shot. Some metric-based methods [Xu et al., 2021a; Hou et al., 2019] apply cross attention, while our CECNet still surpasses DANet [Xu et al., 2021a] with an accuracy improvement up to 2.36% under WRN-28 backbone, which demonstrates the strength of our Clustered-patch Element Connection."
        },
        {
            "heading": "6.2 Ablation Study",
            "text": "Influence of CECM As shown in Tab.2, comparing CECNet to ProtoG, it shows consistent improvements on 1/5-shot classifications, because our CECM enhances the mutually similar regions and produces more discriminative representations. Comparing with CAN adopting cross attention module CAM, our CECNet achieves obvious improvements up to 4.06% on 1-shot task. The results of CECM(M), CECM(C), CECM(G) and CECM(T) show that CECM is not sensitive to alternative modes such as MatMul, Cosine, GCN and Transformer, which indicates the generic Patch Cluster behavior is the key insight for the improvements.\nInfluence of CECD As shown in Tab.3 without attention module, comparing CECNet to ProtoG, it shows consistent improvements, because our CECD distance metric can obtain a more reliable similarity map. Besides, the results show that the best combination is CECM(T) + CECD(C).\nInfluence of Multi-Task Loss In Tab.4 with the integration of auxiliary tasks, our CECNet obtains large improvements, which indicates that learning a good embedding is helpful.\nInfluence of CECM+CECD As shown in Tab.5, comparing to ProtoG (no-attention + cosine), our methods adopting CECM(T) + cosine and no-attention + CECD(C) achieve\nobvious improvements, which demonstrates the effectiveness of the proposed CECM and CECD. The combination of CECM(T) + CECD(C) obtains further performance gains.\nInfluence of Self-CECM As illustrated in Tab.6, the baseline is the Metric Classifier of CECNet, and the competitor is Fine-tune Classifier with only Linear layer. By comparing\nSelf-CECM+Linear to Linear, it shows consistent improvements, which demonstrates the usefulness of Self-CECM. By comparing Metric+Fine-tune to Metric Classifier, it shows an improvement on 5-shot classification."
        },
        {
            "heading": "6.3 Visualization Analysis",
            "text": "Fig.4(a) shows the class activation maps [Bolei et al., 2016] of our CECNet and CAN [Hou et al., 2019]. Comparing CECNet to its Embedding, CECNet can highlight the target object which is unseen in the pre-training stage. Comparing to CAN, CECNet is more accurate and has larger receptive fields. The essential is that our Clustered-patch Element Connection utilizes the global info to implement element connection leading to a more confident correlation and a more clear connection. Fig.4(b) shows the visualizations of the CECbased relation map RQ generated by CECNet via Eq.7. Our CEC approach produces a high-quality relation map with a more complete region for the target."
        },
        {
            "heading": "7 Applications on FSSS and FSOD Tasks",
            "text": "In this section, we first introduce a novel CEC-based embedding module named CEC Embedding (CECE). Then, we extend the proposed CECE into few-shot semantic segmentation (FSSS) and object detection (FSOD) tasks. The experimental results in Tab.7 and Tab.8 show that our CECE can achieve performance improvements around 1% \u2212 3%, and more extensive results are presented in APPENDIX. CEC Embedding fCECE is expressed as:\nQ\u2032 = fCECE(Q) = fCEC(Q,WE). (16)\nwhere, {Q,Q\u2032} \u2208 Rhw\u00d7c are the input and output features respectively, and WE \u2208 Rne\u00d7c are learnable weights (pytorch code is WE = nn.Embedding(ne, c), and ne represents the number of semantic groups, and the empirical setting is ne = 5). The proposed CECE can enhance the target\nregions of input features that are semantically similar to WE , where WE contains the semantic information of base categories after trained on the base dataset.\nCECE Applications As an embedding module, our CECE can be stacked after the backbone network. To verify the effectiveness of the proposed CECE, we insert it into the FSSS method RePRI [Malik et al., 2021] and FSOD method MFDC [Wu et al., 2022], via stacking CECE after their backbones. As illustrated in Tab.7 and Tab.8, our CECE can make consistent improvements upon RePRI and MFDC methods."
        },
        {
            "heading": "8 Conclusion",
            "text": "We propose a novel Clustered-patch Element Connection network (CECNet) for few-shot classification. Firstly, we design a Clustered-patch Element Connection (CEC) layer, which strengthens the target regions of query features by element-wisely connecting them with the clustered-patch features. Then three useful CEC-based modules are derived: CECM and Self-CECM generate more discriminative features, and CECD distance metric obtains a reliable similarity map. Extensive experiments prove that our method is effective, and achieves the state-of-the-arts on few-shot classification benchmark. Furthermore, our CEC approach can be extended into few-shot segmentation and detection tasks, which achieves competitive improvements."
        },
        {
            "heading": "A Related Work",
            "text": "Few-Shot Classification The representative inductive fewshot classification approaches include parameter-generating based, optimization-based, metric-learning based, and embedding-based methods. Parameter-generating methods [Munkhdalai and Yu, 2017; Gidaris and Komodakis, 2019] consider the model as a parameter generating network. Optimization-based methods can rapidly adapt to unseen categories with a few samples by learning a well-initialized model [Nichol et al., 2018; Finn et al., 2017] or a good optimizer [Andrychowicz et al., 2016; Ravi and Larochelle, 2017]. Metric-learning based methods [Vinyals et al., 2016; Snell et al., 2017; Xu et al., 2021a; Hou et al., 2019] classify an image by measuring similarity between it and the labeled samples. Embedding-based methods [Tian et al., 2020a; Rizve et al., 2021; Zhengyu et al., 2021] aim to learn a generalize-well embedding, then further fine-tune a linear classifier on novel categories.\nAuxiliary Task for FSL Recent works have demonstrated the effectiveness of introducing auxiliary tasks to FSL, which leads to a performance improvement via sharing parameters across tasks. In CAN [Hou et al., 2019], a Global Classifier was proposed as the supervised auxiliary task for FSL. Some self-supervised based auxiliary tasks are applied for FSL, including contrastive learning [Liu et al., 2021], rotation prediction [Su et al., 2020] and geometric prediction [Rizve et al., 2021].\nFew-Shot Semantic Segmentation Early few-shot semantic segmentation methods apply a dual-branch architecture [Shaban et al., 2018; Dong and Xing, 2018; Rakelly et al., 2018], one segmenting query-images with the prototypes learned by the other branch. In recently, the dual-branch architecture is unified into a single-branch, using the same embedding for support and query images [Zhang et al., 2020b; Siam et al., 2019; Wang et al., 2019; Yang et al., 2020; Liu et al., 2020b]. These methods aim to leverage better guidance for the segmentation of query-images [Zhang et al., 2020b; Nguyen and Todorovic, 2019; Wang et al., 2020a; Zhang et al., 2019a], via learning better class-specific representations [Wang et al., 2019; Liu et al., 2020a; Liu et al., 2020b; Yang et al., 2020; Siam et al., 2019] or iteratively refining [Zhang et al., 2019b].\nFew-Shot Object Detection Existing few-shot object detection approaches can be divided into two paradigms: metalearning based [Kang et al., 2019; Xiao and Marlet, 2020b; Fan et al., 2020; Hu et al., 2021] and transfer learning based [Wang et al., 2020b; Wu et al., 2020; Sun et al., 2021; Fan et al., 2021; Qiao et al., 2021; Wu et al., 2022]. The majority of meta-learning approaches adopt feature reweighting or its variants to aggregate query and support features, which predict detections conditioned on support sets. Differently, the transfer learning based approaches firstly train the detectors on base set, then fine-tune the task-head layer on novel set, which achieve competitive results comparing to meta-learning approaches.\nGraph Convolutional Network (GCN) GCN [Bruna et al., 2013; Atwood and Towsley, 2016] extends convolution to\ngraph domain. Its representative directions are spectral-based [Defferrard et al., 2016; Levie et al., 2018] and spatial-based [Niepert et al., 2016; Gilmer et al., 2017] methods. In [Zonghan et al., 2020], more comprehensive reviews of GCN are introduced. Transformer Transformer is an attention-based architecture with powerful learning ability, which has been applied in many computer vision tasks, such as classification [Wang et al., 2021], detection[Zhu et al., 2020] and segmentation[Zheng et al., 2021; Liang et al., 2020]."
        },
        {
            "heading": "B Comparison to Relevant Works",
            "text": "(I) The FRN [Wertheimer et al., 2021] and CTX [Doersch et al., 2020] are embedding modules, which uses support features to reconstruct or represent query feature. DeepEMD [Zhang et al., 2020a] is a distance metric, which measures the similarity of pairs via the optimal matching cost. However, our CEC is a more general layer, which can be applied as an embedding module CECE, an attention module CECM or a distance metric CECD. (II) Similar to traditional Cross Attention, DeepEMD performs Locala-to-Local fully connection, which still suffers the semantically inconsistent problem due to different scale objects. Differently, the essence of our CEC is performing the Global-to-Local element connection between the Clustered-patchCp (global) and queryQ (local). Besides, our Patch Cluster is a generic concept. Despite the introduced four solutions, both FRN and CTX may also be modified to perform Patch Cluster. Specifically, CTX is similar to our MatMul mode, while FRN attempts to reconstruct Q from P via solving the linear least-squares problem min(|Q \u2212 WP |). (III) PaCa (Patch-to-Cluster Attention) [Grainger et al., 2022] performs self-clustering among patches of P , while our Patch Cluster performs referencecluster among P with Q as the specific cluster center to find semantic relationship."
        },
        {
            "heading": "C Few-Shot Classification Datasets",
            "text": "We conduct experiments on miniImageNet, tieredImageNet and CIFAR-FS datasets. Following [Hou et al., 2019], the\n100 categories of miniImageNet dataset are split into 64, 16 and 20 categories for train, validation and test respectively. The tieredImageNet dataset [Ren et al., 2018] consists of 608 categories, which are divided into 351, 97 and 160 categories for train, validation and test respectively. CIFAR-FS dataset randomly splits 100 classes of CIFAR-100 into 64, 16, and 20 categories corresponding to train, validation, and test."
        },
        {
            "heading": "D Comparison on CIFAR-FS",
            "text": "As shown in Tab. 9, we compare with the state-of-the-art fewshot methods on CIFAR-FS datasets. It shows that our CECNet outperforms the existing SOTAs, which demonstrates the effectiveness and strength of our CECNet."
        },
        {
            "heading": "E CEC Classifier",
            "text": "Despite the derived CEC-based four modules, such as CECM and Self-CECM attention modules, CECD distance metric, and CECE embedding module, we further introduce a novel CEC Classifier (CECC) for few-shot learning.\nOur CECNet is mete-learning based approach, while the recent works show that supervised-learning based few-shot classification methods [Chen et al., 2019; Tian et al., 2020a; Xu et al., 2021b] also achieve very competitive accuracy performance. In [Chen et al., 2019], a cosine classifier is introduced for supervised-learning based few-shot classification. Inspired by the cosine classifier [Chen et al., 2019], our CECD(C) distance metric can be modified into a Clustered-\npatch Element Connection Classifier (CECC), formally:\nCECC(Q) = CECD(W,Q) =\n( W\n||W ||2 \u2297 C\nq\n||Cq||2\n) \u2208 RD,\n(17) where, W \u2208 RD\u00d7c are learnable weights, D is the all categories of train set.\nE.1 COSOC+CECC The COSOC [Xu et al., 2021b] approach achieves very competitive performance in few-shot classification, which adopts a complicated multi-stage framework, including pre-training backbone by contrastive learning, data clustering, generating cropped data, training backbone by cosine classifier and inference with Shared Object Concentrator (SOC). Based on COSOC method, we replace the cosine classifier with the proposed CECC, which obtains the COSOC+CECC approach. The results in Tab. 10 show that our CECC is able to boost the performance upon COSOC."
        },
        {
            "heading": "F Applications on FSSS and FSOD Tasks",
            "text": "As shown in Tab.11, Tab.12, Tab.13, and Tab.14, our CECE can achieve performance improvements around 1%\u2212 3% on few-shot semantic segmentation and object detection tasks. FSSS: Datasets and Setting PASCAL-5i and COCO-20i Datasets: PASCAL-5i is built from PASCAL VOC [Everingham et al., 2010]. The 20 object categories are split into 4 folds. For each fold, 15 categories are utilized for training and the remaining 5 classes for testing. COCO-20i is built from MS-COCO [Lin et al., 2014a]. COCO-20i dataset is divided into 4 folds with 60 base classes and 20 test classes in each fold.\nEvaluation Setting: Following [Liu et al., 2020b], the mean Intersection over Union (mIoU) is adopted for evaluation, and we report average mIoU over 5 runs of 1000 tasks.\nFSOD: Datasets and Setting PASCAL VOC and COCO Datasets: PASCAL VOC [Everingham et al., 2010] are randomly sampled into 3 splits, and each contains 20 categories. For each split, there are 15 base and 5 novel categories. Each novel class has K = 1, 2, 3, 5, 10 objects sampled from the train/val set of VOC2007 and VOC2012 for training, and the test set of VOC2007 for testing. COCO [Lin et al., 2014b] use 60 categories disjoint with VOC as base set, and the remaining 20 categories are novel set with K = 1, 2, 3, 5, 10, 30 shots. The total 5k images randomly sampled from the validation set are utilized for testing, while the rest for training.\nEvaluation Setting: Following [Wang et al., 2020b; Qiao et al., 2021], we conduct experiments on the evaluation setting of generalized few-shot object detection (G-FSOD)."
        }
    ],
    "title": "Clustered-patch Element Connection for Few-shot Learning",
    "year": 2023
}