{
    "abstractText": "Emotion Recognition in Conversations (ERC) has been gaining increasing importance as conversational agents become more and more common. Recognizing emotions is key for effective communication, being a crucial component in the development of effective and empathetic conversational agents. Knowledge and understanding of the conversational context are extremely valuable for identifying the emotions of the interlocutor. We thus approach Emotion Recognition in Conversations leveraging the conversational context, i.e., taking into attention previous conversational turns. The usual approach to model the conversational context has been to produce context-independent representations of each utterance and subsequently perform contextual modeling of these. Here we propose context-dependent embedding representations of each utterance by leveraging the contextual representational power of pretrained transformer language models. In our approach, we feed the conversational context appended to the utterance to be classified as input to the RoBERTa encoder, to which we append a simple classification module, thus discarding the need to deal with context after obtaining the embeddings since these constitute already an efficient representation of such context. We also investigate how the number of introduced conversational turns influences our model performance. The effectiveness of our approach is validated on the open-domain DailyDialog dataset and on the task-oriented EmoWOZ dataset.",
    "authors": [
        {
            "affiliations": [],
            "name": "Patr\u00edcia Pereira"
        },
        {
            "affiliations": [],
            "name": "Helena Moniz"
        },
        {
            "affiliations": [],
            "name": "Isabel Dias"
        },
        {
            "affiliations": [],
            "name": "Joao Paulo Carvalho"
        }
    ],
    "id": "SP:67b3e366035f9c308437bc08834d90fb45c46cf5",
    "references": [
        {
            "authors": [
                "Antoine Bosselut",
                "Hannah Rashkin",
                "Maarten Sap",
                "Chaitanya Malaviya",
                "Asli Celikyilmaz",
                "Yejin Choi."
            ],
            "title": "Comet: Commonsense transformers for automatic knowledge graph construction",
            "venue": "arXiv preprint arXiv:1906.05317.",
            "year": 2019
        },
        {
            "authors": [
                "Pawe\u0142 Budzianowski",
                "Tsung-Hsien Wen",
                "Bo-Hsiang Tseng",
                "I\u00f1igo Casanueva",
                "Stefan Ultes",
                "Osman Ramadan",
                "Milica Ga\u0161i\u0107."
            ],
            "title": "MultiWOZ - a largescale multi-domain Wizard-of-Oz dataset for taskoriented dialogue modelling",
            "venue": "Proceedings of the",
            "year": 2018
        },
        {
            "authors": [
                "Ankush Chatterjee",
                "Kedhar Nath Narahari",
                "Meghana Joshi",
                "Puneet Agrawal."
            ],
            "title": "Semeval-2019 task 3: Emocontext contextual emotion detection in text",
            "venue": "Proceedings of the 13th international workshop on semantic evaluation, pages 39\u201348.",
            "year": 2019
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv preprint arXiv:1810.04805.",
            "year": 2018
        },
        {
            "authors": [
                "Paul Ekman."
            ],
            "title": "Basic emotions",
            "venue": "Handbook of cognition and emotion, 98(45-60):16.",
            "year": 1999
        },
        {
            "authors": [
                "Jeffrey L Elman."
            ],
            "title": "Distributed representations, simple recurrent networks, and grammatical structure",
            "venue": "Machine learning, 7(2):195\u2013225.",
            "year": 1991
        },
        {
            "authors": [
                "Shutong Feng",
                "Nurul Lubis",
                "Christian Geishauser",
                "Hsien-chin Lin",
                "Michael Heck",
                "Carel van Niekerk",
                "Milica Gasic."
            ],
            "title": "Emowoz: A large-scale corpus and labelling scheme for emotion recognition in task-oriented dialogue systems",
            "venue": "Proceedings of",
            "year": 2022
        },
        {
            "authors": [
                "Deepanway Ghosal",
                "Navonil Majumder",
                "Alexander Gelbukh",
                "Rada Mihalcea",
                "Soujanya Poria"
            ],
            "title": "COSMIC: COmmonSense knowledge for eMotion",
            "year": 2020
        },
        {
            "authors": [
                "Alex Graves",
                "Santiago Fern\u00e1ndez",
                "J\u00fcrgen Schmidhuber."
            ],
            "title": "Bidirectional lstm networks for improved phoneme classification and recognition",
            "venue": "International conference on artificial neural networks, pages 799\u2013804. Springer.",
            "year": 2005
        },
        {
            "authors": [
                "Sepp Hochreiter",
                "J\u00fcrgen Schmidhuber."
            ],
            "title": "Long short-term memory",
            "venue": "Neural computation, 9(8):1735\u2013 1780.",
            "year": 1997
        },
        {
            "authors": [
                "Diederik P Kingma",
                "Jimmy Ba."
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv preprint arXiv:1412.6980.",
            "year": 2014
        },
        {
            "authors": [
                "John Lafferty",
                "Andrew McCallum",
                "Fernando CN Pereira"
            ],
            "title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
            "year": 2001
        },
        {
            "authors": [
                "Jiangnan Li",
                "Zheng Lin",
                "Peng Fu",
                "Weiping Wang."
            ],
            "title": "Past, present, and future: Conversational emotion recognition through structural modeling of psychological knowledge",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, pages",
            "year": 2021
        },
        {
            "authors": [
                "Yanran Li",
                "Hui Su",
                "Xiaoyu Shen",
                "Wenjie Li",
                "Ziqiang Cao",
                "Shuzi Niu."
            ],
            "title": "Dailydialog: A manually labelled multi-turn dialogue dataset",
            "venue": "arXiv preprint arXiv:1710.03957.",
            "year": 2017
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Navonil Majumder",
                "Soujanya Poria",
                "Devamanyu Hazarika",
                "Rada Mihalcea",
                "Alexander Gelbukh",
                "Erik Cambria."
            ],
            "title": "Dialoguernn: An attentive rnn for emotion detection in conversations",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2019
        },
        {
            "authors": [
                "Saif M Mohammad."
            ],
            "title": "Ethics sheet for automatic emotion recognition and sentiment analysis",
            "venue": "Computational Linguistics, 48(2):239\u2013278.",
            "year": 2022
        },
        {
            "authors": [
                "Patr\u00edcia Pereira",
                "Helena Moniz",
                "Joao Paulo Carvalho."
            ],
            "title": "Deep emotion recognition in textual conversations: A survey",
            "venue": "arXiv preprint arXiv:2211.09172.",
            "year": 2022
        },
        {
            "authors": [
                "Soujanya Poria",
                "Erik Cambria",
                "Devamanyu Hazarika",
                "Navonil Majumder",
                "Amir Zadeh",
                "Louis-Philippe Morency."
            ],
            "title": "Context-dependent sentiment analysis in user-generated videos",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for Compu-",
            "year": 2017
        },
        {
            "authors": [
                "Soujanya Poria",
                "Navonil Majumder",
                "Rada Mihalcea",
                "Eduard Hovy."
            ],
            "title": "Emotion recognition in conversation: Research challenges, datasets, and recent advances",
            "venue": "IEEE Access, 7:100943\u2013100953.",
            "year": 2019
        },
        {
            "authors": [
                "Weizhou Shen",
                "Junqing Chen",
                "Xiaojun Quan",
                "Zhixian Xie."
            ],
            "title": "Dialogxl: All-in-one xlnet for multiparty conversation emotion recognition",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 13789\u201313797.",
            "year": 2021
        },
        {
            "authors": [
                "Weizhou Shen",
                "Siyue Wu",
                "Yunyi Yang",
                "Xiaojun Quan."
            ],
            "title": "Directed acyclic graph network for conversational emotion recognition",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International",
            "year": 2021
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems, 30.",
            "year": 2017
        },
        {
            "authors": [
                "Teven Le Scao",
                "Sylvain Gugger",
                "Mariama Drame",
                "Quentin Lhoest",
                "Alexander Rush."
            ],
            "title": "Transformers: State-of-the-art natural language processing",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System",
            "year": 2020
        },
        {
            "authors": [
                "Peixiang Zhong",
                "Di Wang",
                "Chunyan Miao."
            ],
            "title": "Knowledge-enriched transformer for emotion detection in textual conversations",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th Interna-",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Emotion Recognition in Conversations (ERC) is useful in automatic opinion mining, emotion-aware conversational agents and assisting modules for therapeutic practices. There is thus an increasing interest in endowing machines with efficient emotion recognition modules."
        },
        {
            "heading": "A: Look, here is a nice pair of shoes for you to train!",
            "text": "Knowledge and understanding of the conversational context, i.e., of the previous conversation turns, are extremely valuable in identifying the emotions of the interlocutors (Poria et al., 2019) (Chatterjee et al., 2019) (Pereira et al., 2022).\nResearch in automatic emotion recognition using machine learning techniques dates back to the end of the 20th century. However, the use of the conversational context as an auxiliary information for the classifiers, did not appear until publicly available conversational datasets became more common.\nState-of-the-art ERC works leverage not only state-of-the-art pre-trained-language models such as BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019), but also deep, complex architectures to model several factors that influence the emotions in the conversation (Pereira et al., 2022). Such fac-\nar X\niv :2\n30 4.\n08 21\n6v 2\n[ cs\n.C L\n] 3\nJ un\n2 02\n3\ntors usually pertain to self and inter-speaker emotional influence and the context and emotion of preceeding utterances.\nIn this paper we argue that the powerful representation capabilities of pre-trained language models can be leveraged to model context without the need of additional elaborate classifier architectures, allowing for much simpler and efficient architectures. Furthermore, it is our contention that the Transformer, the backbone of our chosen language model, is better at preserving the contextual information since it has a shorter path of information flow than the RNNs typically used for context modelling. In this line, we rely on the RoBERTa language model and resort to a simple classification module to preserve the contextual information.\nThe usual approach to model the conversational context has been to produce context independent representations of each utterance and subsequently perform contextual modeling of those representations. State-of-the art approaches start by resorting to embedding representations from language models and employ gated or graph neural network architectures to perform contextual modelling of these embedding representations at a later step. In our much simpler and efficient proposed approach, we produce context-dependent embedding representations of each utterance, by feeding not only the utterance but also its conversational context to the language model. We thus discard the need to deal with context after obtaining the embeddings since these constitute already an efficient representation of such context.\nOur experiments show that by leveraging context in this way, one can obtain state-of-the-art results with RoBERTa and a simple classification module, surpassing more complex state-of-the-art models."
        },
        {
            "heading": "2 Related Work",
            "text": "Amongst the first works considering contextual interdependences among utterances is the one by Poria et al. (Poria et al., 2017). It uses LSTMs to extract contextual features from the utterances. These gated recurrent networks make it possible to share information between consecutive utterances while preserving its order.\nA more elaborate model also leveraging gated recurrent networks is DialogueRNN (Majumder et al., 2019), which uses GRUs to model the speaker, context and emotion of preceding utterances by keeping a party state and a global state that are used to\nmodel the final emotion representation. Gated recurrent networks have a long path of information flow which makes it difficult to capture long term dependencies. These can be better captured with the Transformer which a has shorter path of information flow. Its invention in 2017 (Vaswani et al., 2017) led to a new state-of-the-art in several Natural Language Processing tasks.\nAmongst the first works leveraging the Transformer is the Knowledge-Enriched Transformer (KET) (Zhong et al., 2019). It uses its self-attention to model context and response. It also makes use of an external knowledge base, a graph of concepts that is retrieved for each word.\nFollowing the invention of Transformers, pretrained language models brought about another new state-of-the art in 2019. Since their invention, most state-of-the art ERC works resorted to encoder pre-trained language models (Shen et al., 2021a) (Ghosal et al., 2020) (Li et al., 2021).\nCOSMIC (Ghosal et al., 2020) leverages RoBERTa Large as feature extractor. Furthermore, it makes use of the commonsense transformer model COMET (Bosselut et al., 2019) in order to extract commonsense features. Five bi-directional GRUs model a context state, internal state, external state, intent state, and emotion state that influence the final emotion classification.\nPsychological (Li et al., 2021) also uses RoBERTa Large for utterance encoding and COMET. For conversation-level encoding it constructs a graph of utterances to model the actions and intentions of the speaker along with the interactions with other utterances. It uses COMET to introduce commonsense knowledge into the graph edge representations and processes this graph using a graph transformer network."
        },
        {
            "heading": "3 Methodology",
            "text": "We describe how we obtain a contextual embedding representation of the sentence and its context with RoBERTa, how we pool the contextual embeddings, our classification module and how we obtain the emotion labels. These processes can be observed in Figure 2."
        },
        {
            "heading": "3.1 Task definition",
            "text": "Given a conversation, a sequence of ui utterances with corresponding emotioni from a predefined set of emotions, the aim of the task of ERC is to correctly assign an emotion to each utterance of the\nconversation. An utterance consists in a sequence of wit tokens representing its Ti words\nui = (wi1, wi2, ..., wiTi) (1)\nThe usual approach for this task has been to produce context independent representations of each utterance and perform contextual modeling of these. In our approach we produce context-dependent representations of each utterance that represent not only the utterance but also a given number of previous utterances from the conversation."
        },
        {
            "heading": "3.2 Context-dependent feature extraction",
            "text": "For context-dependent feature extraction, we feed as input to RoBERTa the utterance we intend to classify, ui, concatenated with its conversational context corresponding to the number c of previous utterances in the conversation, (ui\u22121, ui\u22122, ..., ui\u2212c). Concretely, we feed ui to the model, preceded by the [CLS] token and suceded by the [SEP] token, followed by the previous turns ui\u22121 up to ui\u2212c, separated by the [SEP] token."
        },
        {
            "heading": "3.3 Pooling",
            "text": "The RoBERTa encoder outputs several layers of embeddings representing the utterance, and in our approach, also the preceding utterances it receives\nas input. Each layer comprises several tokens, being the number of tokens the same as the number of input tokens. Each token is a vector with dimension corresponding to the RoBERTa hidden size.\nFrom these embeddings one can extract a suitable representation for the sentence. Choosing all tokens from all layers would yield an extremely memory demanding classification layer and may not yield the best model performance. Thus we choose the first embedding from the last layer L, the [CLS] which is used for classification, as in Equation 2.\npooledi = RoBERTaL,[CLS](inputi) (2)"
        },
        {
            "heading": "3.4 Emotion Classification",
            "text": "The classification module that follows RoBERTa is a linear fully connected layer, applying a linear transformation to the pooled encoder output data. Its input size is the RoBERTa encoder hidden size and its output size is the number of emotion classes.\nThe final label probability distribution is yielded by applying the softmax operation to the output of the classification head and the predicted label is the one with the highest probability:\nemotioni = argmax(Softmax(poolediW T+b))\n(3)"
        },
        {
            "heading": "4 Experimental Setup",
            "text": ""
        },
        {
            "heading": "4.1 Training",
            "text": "Our model is based on RoBERTa-base from the Transformers library by Hugging Face (Wolf et al., 2020). It is trained with the cross-entropy loss with logits. The Adam (Kingma and Ba, 2014) optimizer is used with an initial learning rate of 1e-5 and 5e-5, for the encoder and the classification head, respectively with a layer-wise decay rate of 0.95 after each training epoch for the encoder. The encoder is frozen for the first epoch. The batch size is set to 4. Gradient clipping is set to 1.0. As stopping criteria, early stopping is used to terminate training if there is no improvement after 5 consecutive epochs on the validation set over macro-F1, for a maximum of 10 epochs. The checkpoint used in testing is the one that achieves the highest macro-F1 score on the validation set."
        },
        {
            "heading": "4.2 Evaluation",
            "text": "We evaluate the performance of our model with the macro F1-score. The reported results are yielded\nfrom an average of 5 runs corresponding to 5 distinct random seeds that are kept for a meaningful comparison of all experiments. This average is motivated by the fact that results for the same experiment obtained with different random seeds can have a variability of about 3 in macro F1-score which is a large deviation given that our proposed approach yields an improvement of that magnitude and comparison between state-of-the-art models are based on improvements of less than 1 F1score. This procedure is in line with several authors that also resort to 5 run averages (Li et al., 2021) (Zhong et al., 2019) (Shen et al., 2021a) (Shen et al., 2021b).\nOur code is publicly available1."
        },
        {
            "heading": "4.3 Datasets",
            "text": "We evaluate our approach on the chit-chat DailyDialog (Li et al., 2017) dataset and on the taskoriented EmoWOZ (Feng et al., 2022) dataset."
        },
        {
            "heading": "4.3.1 DailyDialog",
            "text": "DailyDialog is built from websites used to practice English dialogue in daily life. It is labelled with the six Ekman\u2019s basic emotions (Ekman, 1999), anger, disgust, fear, happiness, sadness and surprise, or neutral. The publicly available splits of Yanran are used."
        },
        {
            "heading": "4.3.2 EmoWOZ",
            "text": "EmoWOZ is derived from MultiWOZ (Budzianowski et al., 2018), one of the largest multi-domain corpora benchmark dataset for various dialogue tasks. User utterances are annotated with either fear, dissatisfaction, apologetic, abusive, excited, satisfied or neutral emotions.\nThe statistics and proportion of labels in the datasets are presented in Tables 1 and 2, respectively.\n1http://github.com/patricia-pereira/ cd-erc\nFrom Table 1 it can be noted that EmoWOZ has almost double the amount of average turns per dialogue than DailyDialog.\nFrom Table 2 it can be observed that both datasets are imbalanced, not only for its dominant majority neutral class, but also for the relative imbalance between minority classes. Therefore, we have opted to use the macro-F1 score for evaluation in order to promote consistent performance across all classes."
        },
        {
            "heading": "5 Results and Analysis",
            "text": ""
        },
        {
            "heading": "5.1 Iterating towards the ideal approach",
            "text": "We have performed extensive experiments in order to obtain our ideal model architecture. From experimenting different approaches to pool the various layers of embeddings RoBERTa provides to choosing which classification module to employ withing a wide variety of deep learning architectures, we put forward our experiments in this subsection."
        },
        {
            "heading": "5.1.1 Fine-tuning",
            "text": "Fine-tuning, the modification of the pre-trained RoBERTa\u2019s weights along with the classification head during training with the target dataset, is a determinant procedure for the success of our approach.\nIn our experiments we observed that if we did not fine-tune the language model and just trained the classification head, the model would always predict the majority neutral class. This supports the notion that pre-trained-language models are useful for a wide variety of tasks but need to be fine-tuned for the specific task at hand."
        },
        {
            "heading": "5.1.2 Pooling",
            "text": "We have performed experiments with several pooling alternatives. From average pooling, max pool-\ning, concatenation of the CLS token of more than 1 last layers to the concatenation of the CLS token with the result from average pooling. All these pooling alternatives resulted in lower performance than choosing the CLS token of the last layer. This might suggest a high representative power for the CLS token, which is proposed for classification, and discards the need for directly considering other tokens for this task."
        },
        {
            "heading": "5.1.3 Classification module",
            "text": "We have also performed alternative experiments with other classification modules than our simple classification head. These consisted in passing the pooled embeddings through Recurrent Neural Networks (Elman, 1991), uni (Hochreiter and Schmidhuber, 1997) and bi-directional (Graves et al., 2005) Long Short-Term Memory Networks and a Conditional Random Field (Lafferty et al., 2001) before feeding them to the classification head. Performance was lower in all alternative experiments when compared to our main approach of using a simple classification head. These results may indicate that our approach leveraging RoBERTa\u2019s representational power for context suffices and there is no apparent need for modelling the context with complex classification modules, after obtaining our context-dependent embedding utterance representations."
        },
        {
            "heading": "5.2 Overall Performance",
            "text": "For each of the datasets, we have performed experiments without introducing any context (c = 0) to introducing 4 previous conversation turns (c = 4), for which the overal performance operationalized by the macro-F1 metric is reported in Table 3. Our results are an average of 5 runs.\nIt can be observed that introducing previous conversational context turns leads to an increase in macro-F1 score. As hypothesised, providing no\ncontext is never the best option. This shows that the introduction of an adequate number of context turns directly as the language model input significantly improves model performance. In general performance increases with the introduction of each additional context turn up to the ideal number of turns and then it decreases. Overall, it can be concluded that the ideal number of introduced context turns for ERC in both datasets is 3."
        },
        {
            "heading": "5.3 Performance on each emotion label",
            "text": "For each dataset, we report the results on each individual emotion label and also present the confusion matrices for the best determined c value. Our results are an average of 5 runs.\nThe individual emotion label F1-scores for the DailyDialog dataset are presented in Table 4.\nIt can be observed that for more than half of the labels, Anger, Fear, Sadness and Neutral, the ideal context to be provided is 3 turns which maximise their F1-scores, and also the macro-F1 score on Table 3, and for the other labels the ideal context is 4 turns for Disgust, 2 turns for Happiness and 1 turn for Surprise. As expected, providing no context is never the best option.\nThe confusion matrix for c = 3 corresponding to the highest macro-F1 score is displayed on Figure 3, in which the label nomenclature and order is the same as in table 4 but with neutral as the first label.\nThis matrix indicates that majority of the errors are due to classifying utterances as neutral instead of assigning a non-neutral emotion. The classifier also displays some confusion in discerning between Happiness and Surprised.\nThe individual emotion label F1-scores for the EmoWOZ dataset are presented in Table 5.\nIt can be observed that for 4 of the labels, Dissatistfied, Excited, Satisfied and Neutral, the ideal context to be provided is 4 turns which maximise their F1-scores. Regarding the other labels the ideal context is 2 for Fear, 3 for Abusive, and surprisingly 0 turns for Apologetic, which might indicate that this emotion is very explicit in this dataset.\nThe confusion matrix for c = 3 corresponding to the highest macro-F1 score is displayed on Figure 4, in which the label nomenclature and order is the same as in table 5 but with neutral as the first label.\nThis matrix indicates that majority of the errors are due to classifying utterances as neutral instead of assigning a non-neutral emotion, as in happens with the DailyDialog dataset.\nFig. 3. Confusion Matrix for the DailyDialog dataset with the introduction of c=3 conversational turns\nTABLE V MODEL PERFORMANCE ON EACH INDIVIDUAL EMOTION LABEL ON THE EMOWOZ DATASET WITH THE INTRODUCTION OF c CONVERSATIONAL TURNS\nFear Diss Apol Abus Exc Sat Neu c=0 35.72 45.18 74.93 25.21 46.96 90.09 92.53 c=1 32.97 57.97 72.47 42.97 47.07 89.75 93.01 c=2 38.91 66.24 73.37 44.79 48.13 89.73 93.74 c=3 37.89 68.02 72.49 47.73 47.64 89.76 93.81 c=4 35.15 69.57 73.00 30.09 50.89 90.23 94.03"
        },
        {
            "heading": "It can be observed that for 4 of the labels, Dissatistfied,",
            "text": "Excited, Satisfied and Neutral, the ideal context to be provided is 4 turns which maximise their F1-scores. Regarding the other labels the ideal context is 2 for Fear, 3 for Abusive, and surprisingly 0 turns for Apologetic, which might indicate that this emotion is very explicit in this dataset.\nThe confusion matrix for c = 3 corresponding to the highest macro-F1 score is displayed on Figure 4, in which the label nomenclature and order is the same as in table V but with neutral as the first label.\nThis matrix indicates that majority of the errors are due to classifying utterances as neutral instead of assigning a nonneutral emotion, as in happens with the DailyDialog dataset."
        },
        {
            "heading": "It is worth noting that our results are an average of 5 runs",
            "text": "and the final model is determined via performance on the validation set. Therefore, the fluctuation in individual label F1scores does not hinder the representativity of our results and these fluctuations may occur between results from the other reported state-of-the-art models.\nD. Comparison with state-of-the-art\nWe further compare our approach to other state-of-the-art approaches that also resort to the RoBERTa or BERT pretrained-language models. This allows for a fair comparison between approaches given that using this language model brings\nmeans of utterance feature extraction. Regarding DailyDialog results, we compare our approach to COSMIC [8], RoBERTa and RoBERTa DialogueRNN, implemented by the authors of COSMIC, and the Psychological model [13], all models described in Section II. Concerning the performance on the EmoWOZ dataset, we compare out approach to COSMIC, BERT and BERT DialogueRNN, tested by the authors of EmoWOZ [7], since for this dataset the authors obtained a most suitable uterrance representation using BERT instead of RoBERTa. Results are displayed on table VI and are an average of 5 runs.\nTABLE VI COMPARISON WITH STATE-OF-THE-ART WORKS\nDailyDialog EmoWOZ macro-F1 macro-F1\nRoBERTa [8] / BERT [7] 48.20 55.80 RoBERTa [8] / BERT [7] + DialogueRNN 49.65 57.10\nContextBERT [7] - 59.70 COSMIC [8] / [7] 51.05 61.12 Psychological [13] 51.95 -\nOurs 51.23 65.33\nRegarding performance on the DailyDailog dataset, our approach outperforms not only the simple RoBERTa/BERT, but also RoBERTa/BERT in a more elaborate gated neural network model such as DialogueRNN and COSMIC. The Psychological model has a slightly higher performance than ours. It may be due to the fact that it leverages a large commonsense knowledge base and an elaborate classifier architecture, while we opted for a minimalistic classification module. Concerning performance on the EmoWOZ dataset, our approach outperforms all baselines by a wide margin, setting a new state of the art for task-oriented emotion datasets.\nFigure 3: Confusion Matrix for the D ilyDialog dataset with the introduction of c=3 conversational turns\nIt is worth noting that our results are an average\nof 5 runs and the final model is determined via\nperformance on the validation set. Therefore, the fluctuation in individual label F1-scores does not hinder the representativity of our results and these fluctuations may occur between results from the other reported state-of-the-art models."
        },
        {
            "heading": "5.4 Comparison with state-of-th -art",
            "text": "We further compare our approach to other state-ofthe-art approaches that also resort to the RoBERTa or BERT pre-trained-language models. This allows for a fair comparison between approaches\nFig. 3. Confusion Matrix for the DailyDialog dataset with the introduction of c=3 conversational turns\nTABLE V MODEL PERFORMANCE ON EACH INDIVIDUAL EMOTION LABEL ON THE EMOWOZ DATASET WITH THE INTRODUCTION OF c CONVERSATIONAL TURNS\nFear Diss Apol Abus Exc Sat Neu c=0 35.72 45.18 74.93 25.21 46.96 90.09 92.53 c=1 32.97 57.97 72.47 42.97 47.07 89.75 93.01 c=2 38.91 66.24 73.37 44.79 48.13 89.73 93.74 c=3 37.89 68.02 72.49 47.73 47.64 89.76 93.81 c=4 35.15 69.57 73.00 30.09 50.89 90.23 94.03\nIt can be observed that for 4 of the labels, Dissatistfied, Excited, Satisfied and Neutral, the ideal context to be provided is 4 turns which maximise their F1-scores. Regarding the other labels the ideal ontext is 2 for Fear, 3 f r Abusive, and surprisingly 0 turns for Apologetic, which might indicate that this emotion is very explicit in this dataset.\nThe confusion matrix for c = 3 corresponding to the highest macro-F1 score is displayed on Figure 4, in which the label nomenclature and order is the same as in table V but with neutral as the first label.\nThis matrix indicates that majority of the errors are due to classifying utterances as neutral instead of assigning a nonneutral emotion, as in happens with the DailyDialog dataset.\nIt is worth noting that our results are an average of 5 runs and the final model is determined via performance on the validation set. Therefore, the fluctuation in individual label F1scores does not hinder the representativity of our results and these fluctuations may occur between results from the other reported state-of-the-art models.\nD. Comparison with state-of-the-art\nWe further compare our approach to other state-of-the-art approaches that also resort to the RoBERTa or BERT pretrained-language models. This allows for a fair comparison between approaches given that using this language model brings\nmeans of utterance feature extraction. Regarding DailyDialog results, we compare our approach to COSMIC [8], RoBERTa and RoBERTa DialogueRNN, implemented by the authors of COSMIC, and the Psychological model [13], all models described in Section II. Concerning the performance on the EmoWOZ dataset, we compare out approach to COSMIC, BERT and BERT DialogueRNN, tested by the authors of EmoWOZ [7], since for this dataset the authors obtained a most suitable uterrance representation using BERT instead of RoBERTa. Results are displayed on table VI and are an average of 5 runs.\nTABLE VI COMPARISON WITH STATE-OF-THE-ART WORKS\nDailyDialog EmoWOZ macro-F1 macro-F1\nRoBERTa [8] / BERT [7] 48.20 55.80 RoBERTa [8] / BERT [7] + DialogueRNN 49.65 57.10\nContextBERT [7] - 59.70 COSMIC [8] / [7] 51.05 61.12 Psychological [13] 51.95 -\nOurs 51.23 65.33\nRegarding performance on the DailyDailog dataset, our approach outperforms not only the simple RoBERTa/BERT, but also RoBERTa/BERT in a more elaborate gated neural network model such as DialogueRNN and COSMIC. The Psychological model has a slightly higher performance than ours. It may be due to the fact that it leverages a large commonsense knowledge base and an elaborate classifier architecture, while we opted for a minimalistic classification module. Concerning performance on the EmoWOZ dataset, our approach outperforms all baselines by a wide margin, setting a new state of the art for task-oriented emotion datasets.\nure 4: Co fusion Matrix for the EmoWOZ datase with the introduction of c=3 conversational turns\ngiven that usi g this language model bri gs great p rformance increases when compared to using other means of utterance feature extraction. Regarding DailyDialog results, we compare our approach t C SMIC (Ghosal et al., 2020), RoBERTa and RoBERTa DialogueRNN, implem nted by the authors of COSMIC, and the Psychological model (Li et al., 2021), all models described in Section 2. Concerning the performance on the EmoWOZ dataset, we compare out approach to COSMIC, BERT and BERT DialogueRNN, tested by the au-\nthors of EmoWOZ (Feng et al., 2022), since for\nthis dataset the authors obtained a more suitable\n6\nuterrance representation using BERT instead of RoBERTa. Results are displayed on table 6 and are an average of 5 runs.\nRegarding performance on the DailyDailog dataset, our approach outperforms not only the simple RoBERTa/BERT, but also RoBERTa/BERT in a more elaborate gated neural network model such as DialogueRNN and COSMIC. The Psychological model has a slightly higher performance than ours. It may be due to the fact that it leverages a large commonsense knowledge base and an elaborate classifier architecture, while we opted for a minimalistic classification module. Concerning performance on the EmoWOZ dataset, our approach outperforms all baselines by a wide margin, setting a new state of the art for task-oriented emotion datasets."
        },
        {
            "heading": "5.5 Case Studies",
            "text": "On Table 7 we can compare the performance of our contextual classifier when considering the ideal 3 context turns on both datasets versus not considering any context at all.\nIn the first example, from the DailyDialog dataset, A offers B assistance, so B asks A to view the apartment, to which A sadly apologizes informing B that B will not be able to view it. The classifier that does not consider context classifies this last apology as neutral. However, given the context of the conversation, A should not be neutral since A is unable to assist B which was A\u2019s initial purpose. The contextual classifier is able to consider this, thus correctly classifying A\u2019s utterance with the emotion Sadness.\nIn the second example, also from the DailyDialog dataset, A gives B a good idea to which B happily reacts and thanks A. A happily reacts to B\u2019s acknowledgments, especially since B mentioned A\u2019s was a \"wonderful idea\". The classifier that does not consider context classifies A\u2019s final reac-\ntion to B as neutral, since A\u2019s utterance is a merely \"No problem. Good luck\", not being able to recognize A\u2019s positive reaction to B\u2019s acknowledgements. The contextual classifier, however, having this utterances into account, correctly classifies A\u2019s final reaction with the emotion Happiness.\nIn the last example, from the EmoWOZ dataset, B is merely answering A\u2019s question of what day B would like to travel. The classifier that does not consider context takes into account the words \"please\" and \"vacation\" which bias the classification towards the emotion Excited. The contextual classifier might grasp that \"please\" is used as a polite expression and \"vacation\" is just the object of the phrase, thus correctly classifying the utterance as neutral."
        },
        {
            "heading": "6 Conclusions and Future Work",
            "text": "In this work we have leveraged context-dependent embedding utterrance representations for Emotion Recognition in Conversations. Our approach of producing context-dependent representations of each utterance contrasted with the usual approach of producing context independent representations of each utterance and subsequently performing contextual modeling of these. It consisted in feeding a variable number of previous conversational turns appended to the utterance to be classified as input to the state-of-the-art pre-trained-language model RoBERTa, to which we appended a simple classification module. We further investigated how the number of introduced conversational turns influenced our model performance. We concluded that the introduction of an adequate number of context turns directly as the language model input significantly improves model performance.\nFurthermore, we attained state-of-the-art results on the widely used DailyDialog dataset and established a new state-of-the-art by a wide margin on the EmoWOZ dataset, which are usually yielded by\nmore elaborate classifiers resorting to larger stateof-the-art pre-trained-language models and more complex classification modules.\nFor future work, from adequately capturing the conversation context, the focus of our approach, to capturing several other factors that influence the emotions in the conversation, such as self and inter-speaker emotional influence and the emotion of preceeding utterances, various architectures comprising not only state-of-the art language models for embeddings but also combining our context-dependent embedding utterance representation with more elaborate classification modules can be used.\nFinally, we put forward important ethical aspects pertaining to Emotion Recognition in Conversations. These are, for example and not limited to, whether an ERC module should be developed or used for a certain purpose, which data to collect, the subjects behind the data, diversity, inclusiveness, privacy, control and possible biases and misuses of the application (Mohammad, 2022). Research taking into account these aspects will benefit the community with better ERC modules for current and novel applications."
        },
        {
            "heading": "7 Acknowledgements",
            "text": "This work was supported by Funda\u00e7\u00e3o para a Ci\u00eancia e a Tecnologia (FCT), through Portuguese national funds Ref. UIDB/50021/2020, Ag\u00eancia Nacional de Inova\u00e7\u00e3o (ANI), through the project CMU-PT MAIA Ref. 045909, RRP and Next Generation EU project Center for Responsible AI Ref. C645008882-00000055, and the COST Action Multi3Generation Ref. CA18231."
        }
    ],
    "title": "Context-Dependent Embedding Utterance Representations for Emotion Recognition in Conversations",
    "year": 2023
}