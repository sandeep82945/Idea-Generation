{
    "abstractText": "Using arch-jumping functions and properties of the arch factorization of words, we propose a new algorithm for computing the subword circular universality index of words. We also introduce the subword universality signature for words, that leads to simple algorithms for the universality indexes of SLP-compressed words.",
    "authors": [
        {
            "affiliations": [],
            "name": "J. Veron"
        }
    ],
    "id": "SP:5d26505ce331b2f67797ce892990941b1e43dd45",
    "references": [
        {
            "authors": [
                "KKMS21. M. Kosche",
                "T. Ko\u00df",
                "F. Manea",
                "S. Siemer"
            ],
            "title": "Absent subsequences in words",
            "venue": "In Proc. 15th Int. Conf. Reachability Problems (RP 2021),",
            "year": 2021
        },
        {
            "authors": [
                "KKMS22. M. Kosche",
                "T. Ko\u00df",
                "F. Manea",
                "S. Siemer"
            ],
            "title": "Combinatorial algorithms for subsequence matching: A survey",
            "venue": "In Proc. 12th Int. Workshop NonClassical Models of Automata and Applications (NCMA 2022),",
            "year": 2022
        },
        {
            "authors": [
                "KS15. P. Karandikar",
                "Ph. Schnoebelen"
            ],
            "title": "Generalized Post embedding problems",
            "venue": "Theory of Computing Systems,",
            "year": 2015
        },
        {
            "authors": [
                "KS19. P. Karandikar",
                "Ph. Schnoebelen"
            ],
            "title": "The height of piecewise-testable languages and the complexity of the logic of subwords",
            "venue": "Logical Methods in Comp. Science,",
            "year": 2019
        },
        {
            "authors": [
                "Loh12. M. Lohrey"
            ],
            "title": "Algorithmics on SLP-compressed strings: A survey",
            "venue": "Groups Complexity Cryptology,",
            "year": 2012
        },
        {
            "authors": [
                "Mat98. O. Matz"
            ],
            "title": "On piecewise testable, starfree, and recognizable picture languages",
            "venue": "In Proc. Int. Conf. Foundations of Software Science and Computation Structures (FOSSACS \u201998),",
            "year": 1998
        },
        {
            "authors": [
                "Ph. Schnoebelen"
            ],
            "title": "On flat lossy channel machines",
            "venue": "In Proc. 29th EACSL Conf. Computer Science Logic (CSL 2021),",
            "year": 2021
        },
        {
            "authors": [
                "Sim72. I. Simon"
            ],
            "title": "Hierarchies of Event with Dot-Depth One",
            "venue": "PhD thesis, University of Waterloo, Dept. Applied Analysis and Computer Science,",
            "year": 1972
        },
        {
            "authors": [
                "Sim75. I. Simon"
            ],
            "title": "Piecewise testable events",
            "venue": "In Proc. 2nd GI Conf. on Automata Theory and Formal Languages,",
            "year": 1975
        },
        {
            "authors": [
                "Sim03. I. Simon"
            ],
            "title": "Words distinguished by their subwords",
            "venue": "In Proc. 4th Int. Conf. on Words (WORDS",
            "year": 2003
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n30 4.\n11 93\n2v 1\n[ cs\n.F L\n] 2\n4 A\npr 2"
        },
        {
            "heading": "1 Introduction",
            "text": "A subword of a given word is obtained by removing some letters at arbitrary places. For example, abba is a subword of abracadabra, as witnessed by the underlined letters. Subwords are a fundamental notion in formal language theory and in algorithmics but they are not as well-behaved as factors, a special case of subwords where the kept letters correspond to an interval inside the original word.1\nWords and languages can be characterised or compared via their subwords. For example, we can distinguish u1 = nationalists from u2 = antinationalists by the subword x = ino. Indeed, only u2 has x as a subword. We say that x is a distinguisher (also, a separator) between u1 and u2. Observe that ino is a shortest distinguisher between the two words.2 In applications one may want to distinguish between two similar DNA strings, or two traces of some program execution: in these situations where inputs can be huge, finding a short distinguishing subword requires efficient algorithms [Sim03]. When considering the usual first-order logic of words (i.e., labelled linear orders), a distinguisher x can be seen as a \u03a31 formula separating the two words.\nDefinability by subwords. These considerations led Imre Simon to the introduction of piecewise-testable languages in his 1972 Phd thesis [Sim72,Sim75]: these languages can be defined entirely in terms of forbidden and required subwords.\n\u22c6 Work partially supported by Labex DigiCosme (project ANR-11-LABEX-0045DIGICOSME) operated by ANR as part of the program \u00ab Investissement d\u2019Avenir \u00bb Idex Paris-Saclay (ANR-11-IDEX-0003-02). 1 Some papers use the terminology \u201csubwords\u201d for factors, and \u201cscattered subwords\u201d or \u201cscattered factors\u201d for subwords. We follow [SS83]. 2 This is a very rare situation with the English lexicon, where different words almost always admit a length-2 distinguisher. To begin with, two words can already admit a length-1 distinguisher unless they use exactly the same set of letters.\nIn logical terms, this corresponds to B\u03a31-definability, see [DGK08]. Piecewise testability is an important and fundamental concept, and it has been extended to, among others, trees [BSS12,GS16], picture languages [Mat98], or words over arbitrary scattered linear orderings [CP18].\nFrom a descriptive complexity point of view, a relevant measure is the length of subwords used in defining piecewise-testable languages, or in distinguishing between two individual words. Equivalently, the required length for these subwords is the required number of variables for the B\u03a31 formula. This measure was investigated in [KS19] where it is an important new tool for bounding the complexity of decidable logic fragments.\nSubword universality. Barker, Day et al. introduced the notion of subword universality: a word u is k-universal if all words of length at most k are subwords of u [BFH+20,DFK+21]. They further define the subword universality index \u03b9(u) as the largest k such that u is k-universal. Their motivations come, among others, from works in reconstructing words from subwords [DPFD19] or computing edit distance [DFK+21], see also the survey in [KKMS22]. In [BFH+20], the authors prove several properties of \u03b9(u), e.g., when u is a palindrome, and further introduce the circular subword universality index \u03b6(u), which is defined as the largest \u03b9(u\u2032) for u\u2032 a conjugate of u. Alternatively, \u03b6(u) can be seen as the subword universality index \u03b9([u]\u223c) for a circular word (also called necklace, or cyclic word), i.e., an equivalence class of words modulo conjugacy.\nWhile it is easy to compute \u03b9(u), computing \u03b6(u) is trickier but [BFH+20] proves several bounds relating \u03b6(u) to the values of \u03b9(un) for n \u2208 N. This is leveraged in [FGN21] where an O(|u| \u00b7 |A|) algorithm computing \u03b6(u) is given. That algorithm is quite indirect, with a delicate and nontrivial correctness proof. Further related works are [KKMS21] where, given that \u03b9(u) = k, one is interested in all the words of length k + 1 that do not occur as subwords of u, [FHH+22] where one considers words that are just a few subwords away from k-universality, and [KKMP22] where the question whether u has a k-universal factor of given length is shown to be NP-complete.\nOur contribution. In this paper we introduce new tools for studying subword (circular) universality. First we focus on the arch factorizations (introduced by H\u00e9brard [H\u00e9b91]) and show how arch jumping functions lead to simple proofs of combinatorial results on subword universality indexes, allowing a new and elegant algorithm for computing \u03b6(u). These arch-jumping functions are implicit in some published constructions and proofs (e.g., in [FK18,FGN21,KKMS21]) but studying them explicitly brings simplifications and improved clarity.\nIn a second part we give bilinear-time algorithms that compute the universality indexes \u03b9 and \u03b6 for compressed words. This is done by introducing a compact subword universality signature that can be computed compositionally. These algorithms and the underlying ideas can be useful in the situations we mentioned earlier since long DNA strings or program execution traces are usually very repetitive, so that handling them in compressed form can entail huge savings in both memory and communication time.\nMore generally this is part of a research program on algorithms and logics for computing and reasoning about subwords [KS15,HSZ17,KS19,GLHK+20]. In that area, handling words in compressed form raises additional difficulties. For example it is not known whether one can compute efficiently the length of a shortest distinguisher between two compressed words. Let us recall here that reasoning on subwords is usually harder than reasoning on factors, and this is indeed true for compressed words: While deciding whether a compressed X is a factor of a compressed Y is polynomial-time, deciding whether X is a subword of Y is intractable (in PSPACE and PP-hard, see [Loh12, Sect. 8]). However, in the special case where one among X or Y is a power word, i.e., a compressed word with restricted nesting of concatenation and exponentiation, the subword relation is polynomial-time, a result crucial for the algorithms in [Sch21] where one handles exponentially long program executions in compressed forms.\nOutline of the paper. Section 2 recalls all the necessary definitions for subwords and universality indexes. Section 3 introduces the arch-jumping functions, relates them to universality indexes and proves some basic combinatorial results. Then Section 4 provides a simple algorithm for the circular universality index. In Section 5 we introduce the subword universality signature of words and show how they can be computed compositionally. Finally Section 6 considers SLPcompressed words and their subword universality indexes."
        },
        {
            "heading": "2 Basic notions",
            "text": "Words and subwords. Let A = {a, b, . . .} be a finite alphabet. We write u, v, w, s, t, x, y . . . for words in A\u2217. Concatenation is denoted multiplicatively while \u03b5 denotes the empty word. When u = u1u2u3 we say that u1 is a prefix, u2 is a factor, and u3 is a suffix, of u. When u = vw we may write v\n\u22121u to denote w, the suffix of u one obtains after removing its v prefix. When u = v0w1v1w2 \u00b7 \u00b7 \u00b7wnvn, the concatenation w1w2 \u00b7 \u00b7 \u00b7wn is a subword of u, i.e., a subsequence obtained from u by removing some of its letters (possibly none, possibly all). We write u 4 v when u is a subword of v.\nA word u = a1 \u00b7 \u00b7 \u00b7 a\u2113 has length \u2113, written |u| = \u2113, and we let A(u) def = {a1, . . . , a\u2113} denote its alphabet, a subset of A. We let Cuts(u) = {0, 1, . . . , \u2113} \u2286 N denote the set of cutting positions inside u, i.e., positions between u\u2019s letters, where u can be split: for 0 \u2264 i \u2264 j \u2264 \u2113, we let u(i, j) denote the factor ai+1ai+2 \u00b7 \u00b7 \u00b7 aj . With this notation, u(0, j) is u\u2019s prefix of length j, and u(i, \u2113) is the suffix (u(0, i))\u22121u. Note also that u(i, i) = \u03b5 and u(i, j) = u(i, k)u(k, j) whenever the factors are defined. If u = u1u2, we say that u2u1 is a conjugate of u. For i \u2208 Cuts(u), the i-th conjugate of u is u(i, \u2113)u(0, i) and is denoted by u\u223ci. Finally uR def = a\u2113 \u00b7 \u00b7 \u00b7a1 denotes the mirror of u.\nRich words and arch factorizations. A word u \u2208 A\u2217 is rich if it contains at least one occurrence of each letter a \u2208 A, otherwise we say that it is incomplete. A rich word having no rich strict prefix is an arch. The mirror of an arch is\ncalled a co-arch (it is generally not an arch). Observe that an arch (or a co-arch) necessarily ends (respectively, starts) with a letter that occurs only once in it.\nThe arch factorization of u, introduced by Hebrard [H\u00e9b91], is a decomposition u = s1 \u00b7 \u00b7 \u00b7 sm \u00b7 r of u into m+ 1 factors given by the following: \u2014 if u is not rich then m = 0 and r = u, \u2014 otherwise let s1 be the shortest prefix of u that is rich (it is an arch) and let s2, . . . , sm, r be the arch factorization of the suffix (s1) \u22121u.\nWe write r(u) for the last factor in u\u2019s factorization, called the rest of u. For example, with A = {a, b, c}, the arch factorization of uex = baccabbcbaabacba is bac \u00b7 cab \u00b7 bcba \u00b7 abac \u00b7 ba, with m = 4 and r(uex) = ba. Thus the arch factorization is a leftmost decomposition of u into arches, with a final rest r(u).\nThere is a symmetric notion of co-arch factorization where one factors u as u = r\u2032 \u00b7 s\u20321 \u00b7 \u00b7 \u00b7 s \u2032 m such that r\n\u2032 is incomplete and every s\u2032i is a co-arch, i.e., a rich factor whose first letter occurs only once.\nAll the above notions assume a given underlying alphabet A, and we should speak more precisely of \u201cA-rich\u201d words, \u201cA-arches\u201d, or \u201crest rA(u)\u201d. When A is understood, we retain the simpler terminology and notation.\nSubword universality. In [BFH+20], Barker et al. define the subword universality index of a word u, denoted \u03b9A(u), or just \u03b9(u), as the largest m \u2208 N such that any word of length m in A\u2217 is a subword of u.\nIt is clear that \u03b9(u) = m iff the arch factorization of u has m arches. Hence one can compute \u03b9(u) in linear time simply by scanning u from left to right, keeping track of letter appearances in consecutive arches, and counting the arches [BFH+20, Prop. 10]. Using that scanning algorithm for \u03b9, one sees that the following equalities hold for all words u, v:\n\u03b9(u v) = \u03b9(u) + \u03b9 ( r(u)v ) , r(u v) = r ( r(u)v ) . (1)\nBarker et al. further define the circular subword universality index of u, denoted \u03b6(u), as the largest \u03b9(u\u2032) for u\u2032 a conjugate of u. Obviously, one always has \u03b6(u) \u2265 \u03b9(u). Note that \u03b6(u) can be strictly larger that \u03b9(u), e.g., with A = {a, b} and u = aabb one has \u03b9(u) = 1 and \u03b6(u) = 2. These descriptive complexity measures are invariant under mirroring of words, i.e., \u03b9(uR) = \u03b9(u) and \u03b6(uR) = \u03b6(u), and monotonic w.r.t. the subword ordering:\nu 4 v =\u21d2 \u03b9(u) \u2264 \u03b9(v) \u2227 \u03b6(u) \u2264 \u03b6(v) . (2)\nThe behaviour of \u03b6 can be deceptive. For example, while \u03b9 is superadditive, i.e., \u03b9(uv) \u2265 \u03b9(u) + \u03b9(v) \u2014just combine eqs. (1) and (2)\u2014 we observe that \u03b6(uv) < \u03b6(u) + \u03b6(v) can happen, e.g., with u = ab and v = bbaa."
        },
        {
            "heading": "3 Arch-jumping functions and universality indexes",
            "text": "Let us fix a word w = a1a2 \u00b7 \u00b7 \u00b7 aL of length L. We now introduce the \u03b1 and \u03b2 arch-jumping functions that describe the reading of an arch starting from some\nposition inside w. For i \u2208 Cuts(w), we let\n\u03b1(i) = min{j | A ( w(i, j) ) = A}, \u03b2(j) = max{i | A ( w(i, j) ) = A}.\nThese are partial functions: \u03b1(i) and \u03b2(j) are undefined when w(i, L) or, respectively, w(0, j), does not contain all the letters from A. See Figure 1 for an illustration.\nThe following properties are easily seen to hold for all i, j \u2208 dom(\u03b1):\n\u03b1(i) \u2265 i+ |A| , i \u2264 j =\u21d2 \u03b1(i) \u2264 \u03b1(j) , (3)\n\u03b2(\u03b1(i)) \u2265 i , \u03b1(\u03b2(\u03b1(i))) = \u03b1(i) . (4)\nSince \u03b2 is a mirror version of \u03b1, it enjoys similar properties that we won\u2019t spell out here.\nRemark 3.1. As will be seen in the rest of this section, the arch jumping functions are a natural and convenient tool for reasoning about arch factorizations. Similar concepts can certainly be found in the literature. Already in [H\u00e9b91], H\u00e9brard writes p(n) for what we write \u03b1n(0), i.e., the n-times iteration \u03b1(\u03b1(\u00b7 \u00b7 \u00b7 (\u03b1(0)) \u00b7 \u00b7 \u00b7 )) of \u03b1 on 0: the starting point for the p(n)\u2019s is fixed, not variable. In [FK18], Fleischer and Kufleitner use rankers like Xa and Yb to jump from a current position in a word to the next (or previous) occurrence of a given letter, here a and b: this can specialise to our \u03b1 and \u03b2 if one knows what is the last letter of the upcoming arch. In [KKMS21] minArch corresponds exactly to our \u03b1, but there minArch is a data structure used to store information, not a notational tool for reasoning algebraically about arches."
        },
        {
            "heading": "3.1 Subword universality index via jumping functions",
            "text": "The connection between the jumping function \u03b1 and the subword universality index \u03b9(w) is clear:\n\u03b9(w) = max { n \u2223 \u2223 \u03b1n(0) is defined } . (5)\nFor example, w in Figure 1 has \u03b13(0) = 10 = |w| so \u03b9(w) = 3. We can generalise Equation (5): \u03b9(w) = n implies \u03b1p(0) \u2264 \u03b2n\u2212p(|w|) for all p = 0, . . . , n, and the reciprocal holds. We can use this to prove the following:\nProposition 3.2. \u03b9(u v) \u2264 \u03b9(u) + \u03b9(v) + 1.\nProof. Write n and n\u2032 for \u03b9(u) and \u03b9(v). Thus, on w = u v with L = |u| + |v|, one has \u03b1n+1(0) > |u| and \u03b2n \u2032+1(L) < |u|. See Fig. 2. Hence \u03b9(w) < n+ n\u2032 + 2.\nWe can also reprove a result from [BFH+20]:\nProposition 3.3. \u03b9(u uR) = 2\u03b9(u).\nProof. Write n for \u03b9(u). When w = u uR and L = |w|, the factor w ( \u03b1n(0), \u03b2n(L) ) is r(u) \u00b7 r(u)R hence is not rich. Thus \u03b1n+1(0) > |u|+ |r(u)R| = \u03b2n(L), entailing \u03b9(u uR) < 2n+ 1."
        },
        {
            "heading": "3.2 Subword circular universality index via jumping functions",
            "text": "The jumping functions can be used to study the circular universality index \u03b6(u). For this we consider the word w = u u obtained by concatenating two copies of u, so that L = 2\u2113. Now, instead of considering the conjugates of u, we can consider the factors w(i, i+ \u2113) of w: see Figure 3.\nThis leads to a characterisation of \u03b6(u) in terms of \u03b1 on w = u u:\n\u03b6(u) = max 0\u2264i<\u2113\nmax { n \u2223 \u2223 \u03b1n(i) \u2264 i+ \u2113 }\n(6)\nor, using u\u223c\u2113 = u\u223c0,\n= max 0<i\u2264\u2113\nmax { n \u2223 \u2223 \u03b1n(i) \u2264 i+ \u2113 } . (7)\nBounding \u03b6(u). For k = 0, . . . ,m, we write \u03bbk for the cumulative length |s1 \u00b7 \u00b7 \u00b7 sk| of the k first arches of u, i.e., we let \u03bbk def = \u03b1k(0).\nThe following Lemma and its corollary are a version of Lemma 20 from [BFH+20] but we give a different proof.\nLemma 3.4. Let u and u\u2032 be two conjugate words. (a) \u03b9(u)\u2212 1 \u2264 \u03b9(u\u2032) \u2264 \u03b9(u) + 1. (b) If furthermore r(u) = \u03b5 then \u03b9(u\u2032) \u2264 \u03b9(u).\nProof. Let s1 \u00b7 \u00b7 \u00b7 sm \u00b7 r be the arch factorization of u and assume that u \u2032 = u\u223ci as depicted in Figure 3. (a) If the position i falls inside some arch sp of u (or inside the rest r) we see that sp+1 \u00b7 \u00b7 \u00b7 sm \u00b7 s1 \u00b7 \u00b7 \u00b7 sp\u22121 is a subword of u\n\u2032 hence \u03b9(u\u2032) \u2265 m \u2212 1. This gives \u03b9(u)\u2212 1 \u2264 \u03b9(u\u2032), and the other inequality is obtained by exchanging the roles of u and u\u2032. (b) If furthermore r = \u03b5, then \u03bbp\u22121 \u2264 i < \u03bbp for some p. Looking at u\n\u2032 as a factor of w = u2 (and assuming that \u03b1m+1(i) is defined) we deduce \u03b1m+1(i) \u2265 \u03b1m+1(\u03bbp\u22121) = \u03bbp + \u2113 > i+ \u2113. This proves \u03b9(u \u223ci) < m+ 1.\nCorollary 3.5. (a) \u03b9(u) \u2264 \u03b6(u) \u2264 \u03b9(u) + 1. (b) Furthermore, if r(u) = \u03b5, then \u03b6(u) = \u03b9(u).\n4 An O(|u| \u00b7 |A|) algorithm for \u03b6(u)\nThe following crucial lemma shows that computing \u03b6(u) does not require checking all the conjugates u\u223ci for 0 \u2264 i < \u2113.\nLemma 4.1. Let u = a1 \u00b7 \u00b7 \u00b7 a\u2113 be a rich word with arch factorization s1 \u00b7 \u00b7 \u00b7 sm \u00b7r. (a) There exists some 0 < d \u2264 \u03bb1 def = |s1| such that \u03b6(u) = \u03b9(u\n\u223cd). (b) Furthermore, there exists a \u2208 A such that d = min{i | ai = a}, i.e., d can be chosen as a position right after a first occurrence of a letter in u.\nProof. Let n = \u03b6(u). For (a) it is enough to show that \u03b9(u\u223cd) \u2265 n for some d \u2208 (0, \u03bb1].\nBy Equation (7) there exists some 0 < i0 \u2264 \u2113 such that \u03b1 n(i0) \u2264 i0 + \u2113. We consider the sequence i0 < i1 < \u00b7 \u00b7 \u00b7 < in given by ik+1 = \u03b1(ik). If in \u2264 \u2113 then taking d = 1 works: monotonicity of \u03b1 entails \u03b1n(d) \u2264 \u03b1n(i0) \u2264 \u2113 and we deduce \u03b9(u\u223cd) \u2265 n. Clearly d = 1 fulfils (b).\nSo assume in > \u2113 and let k be the largest index such that ik \u2264 \u2113 (hence k < n). Since \u03b1(\u2113) = \u2113 + \u03bb1 (recall \u03bb1 def = |s1|), monotonicity of \u03b1 entails ik+1 = \u03b1(ik) \u2264 \u2113+ \u03bb1, i.e., ik+1 lands inside the first arch of the second copy of u in w.\nLet now d def = ik+1 \u2212 \u2113 so that u \u223cd = w(d, d + \u2113) = w(d, ik+1). Since \u03b1n\u2212k\u22121(ik+1) = in \u2264 i0+\u2113, one has \u03b1 n\u2212k\u22121(d) \u2264 i0 hence \u03b9 ( w(d, i0) ) \u2265 n\u2212k\u22121. We also have \u03b9 ( w(i0, ik+1) ) = k + 1 since ik+1 = \u03b1 k+1(i0). This yields\n\u03b9(u\u223cd) = \u03b9 ( w(d, d + \u2113) ) \u2265 (n\u2212 k \u2212 1) + (k + 1) = n ,\nentailing (a). For (b) observe that w(ik+1 \u2212 1, ik+1) is the last letter of an arch across the end of the first u in w to the beginning of the second u in w. Since it is the first occurrence of this letter in this arch, it is also in u. Since d is ik+1 shifted to the first copy of u, (b) is fulfilled.\nAlgorithm 4.2 (Computing \u03b6(u)). For each position d such that u(d\u2212 1, d) is the first occurrence of a letter in u, one computes \u03b9(u\u223cd) (in time O(|u|) for each d), and returns the maximum value found. \u2293\u2294\nThe correctness of this algorithm is given by Lemma 4.1 (if u is not rich, \u03b6(u) = 0 and this will be found out during the computation of \u03b9(u\u223c1)). It runs in time O(|A| \u00b7 |u|) since there are at most |A| values for d, starting with d = 1.\nThere are two heuristic improvements that can speed up the algorithm3:\n\u2013 As soon as we have encountered two different values \u03b9(u\u223cd) 6= \u03b9(u\u223cd \u2032\n), we can stop the search for a maximum in view of corollary 3.5.(a). For example, for u = aabaccb, the first occurrences of a, b, and c, are with d = 1, 3 and 5. So one starts with computing \u03b9(u\u223c1) = \u03b9(abaccb a) = 2. Then one computes \u03b9(u\u223c3) = \u03b9(accb aab) = 1. Now, and since we have encountered two different values, we may conclude immediately that \u03b6(u) = 2 without the need to compute \u03b9(u\u223c5). \u2013 When computing some \u03b9(u\u223cd) leads us to notice r(u\u223cd) = \u03b5, we can stop the search in view of corollary 3.5.(b). For example, and again with u = aabaccb, the computation of \u03b9(u\u223c1) led us to the arch-factorization u\u223c1 = abac \u00b7 cba \u00b7 \u03b5, with 2 arches and with r(u\u223c1) = \u03b5. We may conclude immediately that \u03b6(u) = \u03b9(u\u223c1) = 2 without trying the remaining conjugates.\nObserve that the above algorithm does not have to explicitly build u\u223cd. It is easy to adapt any naive algorithm for \u03b9(u) so that it starts at some position d and wraps around when reaching the end of u."
        },
        {
            "heading": "5 Subword universality signatures",
            "text": "In this section, we write \u03b9\u2217(u), r\u2217(u), etc., to denote the values of \u03b9(u), r(u), etc., when one assumes that A(u) is the underlying alphabet. This notation is less heavy than writing, e.g., \u03b9A(u)(u), but it is needed since we shall consider simultaneously \u03b9\u2217(u) and \u03b9\u2217(v) when A(u) 6= A(v), i.e., when the two universality indexes have been obtained in different contexts.\nWhen u is a word, we define a function Su on words via:\nSu(x) = \u2329 \u03b9\u2217(xu), A ( r\u2217(xu) )\u232a for all x such that A(u) 6\u2286 A(x). (8)\nIn other words, Su(x) is a summary of the arch factorization of xu: it records the number of arches in xu and the letters of the rest r\u2217(xu), assuming that the alphabet is A(xu).\n3 They do not improve the worst-case complexity.\nNote that Su(x) is only defined when A(u) 6\u2286 A(x), i.e., when at least one letter from u does not appear in x. With this restriction, Su(x) and Su(x\n\u2032) coincide (or are both undefined) whenever A(x) = A(x\u2032). For this reason, we sometimes write Su(B), where B is a set of letters, to denote any Su(x) with A(x) = B.\nWe are now almost ready to introduce the main new object: a compact data structure with enough information for computing Su on arbitrary arguments.\nWith a word u we associate e(u), a word listing the letters of u in the order of their first appearance in u. For example, by underlining the first occurrence of each letter in u = ccacabcbba we show e(u) = cab. We also write f(u) for the word listing the letters of u in order of their last occurrence: in the previous example f(u) = cba.\nDefinition 5.1. The subword universality signature of a word u is the pair \u03a3(u) = \u3008e(u), su\u3009 where su is Su restricted to the strict suffixes of e(u).\nExample 5.2. With u = aabac we have:\n\u03a3(u) =\n\n  \n  \ne(u) = abc\nsu =\n\n\n\n\u03b5 7\u2192 \u2329 1,\u2205 \u232a c 7\u2192 \u2329 1, {a, c} \u232a\nbc 7\u2192 \u2329 2,\u2205 \u232a\nin view of: \u03b5 \u00b7 u = aabac \u00b7 \u03b5 c \u00b7 u = caab \u00b7 ac\nbc \u00b7 u = bca \u00b7 abac \u00b7 \u03b5\nNB: the strict suffixes of e(u) are \u03b5, c and bc.\nWhile finite (and quite small) \u03a3(u) contains enough information for computing Su on any argument x on any alphabet. One can use the following algorithm:\nAlgorithm 5.3 (Computing Su(x) from \u03a3(u)). Given inputs x and \u03a3(u) = \u3008e(u), su\u3009 we proceed as follows: (a) Retrieve A(u) from e(u). Check that A(u) 6\u2286 A(x), since otherwise Su(x) is undefined. (b) Now with x \u2208 dom(Su), let y be the longest suffix of e(u) with A(y) \u2286 A(x) \u2014necessarily y is a strict suffix of e(u)\u2014 and extract \u3008ny, By\u3009 from su(y). (c.1) If A(x) \u2286 A(u), return Su(x) = \u3008ny, By\u3009. (c.2) Similarly, if ny = 1 return Su(x) = \u3008ny, By\u3009. (c.3) Otherwise return Su(x) = \u30081, A(u)\u3009.\nProof (of correctness). Assume x \u2208 dom(Su). Since u contains a letter not appearing in x, the first arch of xu ends inside u, so let us consider the factorization u = u1u2 such that xu1 is the first arch of xu (see picture below, where e(u) is underlined).\n\u00b7 \u00b7 \u00b7 c \u00b7 \u00b7 \u00b7 d \u00b7 \u00b7 \u00b7 a \u00b7 \u00b7 \u00b7 e \u00b7 \u00b7 \u00b7 b \u00b7 \u00b7 \u00b7\nx u\nu1 u2\n\u03b1\u2217 ? ?\nNow u1 has a last letter, say a, that appears only once in u1 and not at all in x. Observe that a letter b appears after a in e(u) iff it does not appear in u1, and thus must appear in x. Hence the y computed in step (b) is the suffix of e(u) after a (in the above picture y would be eb).\nIf A(x) \u2286 A(u) then y u1 is rich, and is in fact an arch since its last letter, a, appears only once. So Su(x) and Su(y) coincide and step (c.1) is correct.\nIn case A(x) 6\u2286 A(u), both x and u contain some letters that are absent from the other word, so necessarily \u03b9\u2217(xu) = 1 and r\u2217(xu) = u2. There only remains to compute A(u2) from \u03a3(u). We know that su(y) = \u3008ny, By\u3009. If ny > 1 this means that u2 contains at least another A(u)-arch, so A(u2) = A(u) and step (c.3) is correct. If ny = 1 this means that y u only has one arch, namely y u1, and By provides A(u2): step (c.2) is correct in this case.\nRemark 5.4 (Space and time complexity for Algorithm 5.3). For simplifying our complexity evaluation, we assume that there is a fixed maximum size for alphabets so that storing a letter a \u2208 A uses space O(1), e.g., 64 bits. When storing \u03a3(u), the e(u) part uses space O(|A|). Now su can be represented in space O(|A| log |u|) when e(u) and f(u) are known: it contains at most |A| pairs \u3008nx, Bx\u3009 where x is a suffix of e(u) and Bx is always the alphabet of a strict suffix of f(u): x and Bx can thus be represented by a position (or a letter) in e(u) and f(u). The nx values each need at most log |u| bits.\nRegarding time, the algorithm runs in time O ( |x|+ |\u03a3(u)|+ |A(u)| ) . \u2293\u2294"
        },
        {
            "heading": "5.1 Universality indexes from signatures",
            "text": "Obviously the signature \u03a3(u) contains enough information for retrieving \u03b9\u2217(u): this is found in su(\u03b5). More interestingly, one can also retrieve \u03b6\u2217(u):\nProposition 5.5. Let u be a word with \u03b9\u2217(u) = m. Then \u03b6\u2217(u) = m+1 iff there exists a strict suffix x of e(u) with su(x) = \u3008nx, Bx\u3009 such that nx = m+ 1 and A(x) \u2286 Bx. Otherwise \u03b6\u2217(u) = m.\nProof. (\u21d0): assume su(x) = \u3008m+1, Bx\u3009 with A(x) \u2286 Bx. Thus \u03b9\u2217(xu) = m+1. Factor u as u = u1u2r such that xu1 is the first arch of xu and such that r = r\u2217(xu) is its rest. Then u2 contains m arches and Bx = A(r). Let now u\u2032 def = r u1u2. We claim that \u03b9\u2217(u\n\u2032) = m + 1. Indeed r u1 is rich since xu1 is rich and A(x) \u2286 A(r), so \u03b9\u2217(r u1u2) \u2265 m+ 1. Since u\n\u2032 and u are conjugates, we deduce \u03b6\u2217(u) = \u03b9\u2217(u\n\u2032) = m+ 1 from Corollary 3.5.(a). (\u21d2): assume \u03b6\u2217(u) = m+ 1. By Lemma 4.1 we know that \u03b9\u2217 ( u\u223ci )\n= m + 1 for some position 0 < i \u2264 \u03bb1 falling just after a first occurrence of a letter in u. Looking at factors of w = u u as we did before, we have \u03b1m+1(i) \u2264 i+ \u2113, leading to j def = \u03b1m(i) \u2264 \u2113 (see picture below).\nb \u00b7 \u00b7 \u00b7 a \u00b7 \u00b7 \u00b7 d \u00b7 \u00b7 \u00b7 b \u00b7 \u00b7 \u00b7 a \u00b7 \u00b7 \u00b7 d \u00b7 \u00b7 \u00b7\n0 \u03bb1 \u03bb2 \u03bbm \u2113 \u03bb1 + \u2113 2\u2113\ni j i + \u2113\nu u\n\u03b1\nDefine now x as the suffix of e(u) that contains all letters in u(i, \u03bb1), that is, all underlined letters to the right of i. This is a strict suffix since i > 0. Now xu(0, i) is rich, and u(i, j) is made of exactly m arches, so \u03b9\u2217(xu) = nx = m+1 and r\u2217(xu) = u(j, \u2113). Then Bx = A ( u(j, \u2113) )\nand w(j, i+\u2113) is rich, so w(j, \u2113) contains all letters missing from w(i, i + \u2113) = u(0, i). In other words Bx \u2287 A(x), concluding the proof.\nCorollary 5.6 (Computing universality indexes from signatures). One can compute \u03b9\u2217(u) and \u03b6\u2217(u) from \u03a3(u) in time (|A| + log |u|) O(1).\nActual implementations can use heuristics based on Lemma 3.4.(b): if su(\u03b5) = \u3008m,\u2205\u3009 then \u03b6\u2217(u) = m."
        },
        {
            "heading": "5.2 Combining signatures",
            "text": "Subword universality signatures can be computed compositionally.\nAlgorithm 5.7 (Combining signatures). The following algorithm takes as input the signatures \u03a3(u) and \u03a3(v) of any two words and computes \u03a3(u v):\n(a) Retrieve A(u) and A(v) from e(u) and e(v), then compute e(u v) as e(u) e\u2032 where e\u2032 is the subword of e(v) that only retains the letters from A(v) rA(u). (b) Consider now any strict suffix x of e(u v) and compute suv(x) as follows: (b.1) If A(v) 6\u2286 A(x) \u222aA(u) then let suv(x) def = Sv ( x e(u) ) , using Algorithm 5.3. (b.2) If A(v) \u2286 A(x) \u222a A(u), then A(u) 6\u2286 A(x). Write \u2329 n,B \u232a\nfor su(x):\n(b.2.1) If now A(v) \u222aB 6= A(x) \u222a A(u) then let suv(x) def =\n\u2329 n,A(v) \u222aB \u232a .\n(b.2.2) Otherwise retrieve sv(B) = \u2329 n\u2032, B\u2032 \u232a and let suv(x) def = \u2329 n+ n\u2032, B\u2032 \u232a .\nProof (of correctness). Step (a) for e(u v) is correct. In step (b) we want to compute Su v(x). Now x (u v) = (xu) v so Su v(x) coincides with Sv(xu) when the latter is defined . This is the case in step (b.1) where one computes Sv(xu) by replacing xu with x e(u), an argument with same alphabet (recall that the algorithm does not have access to u itself). In step (b.2) where Sv(xu) is not defined, computing Su(x) provides n and B = A(r) for the arch factorization xu = s1 \u00b7 \u00b7 \u00b7 sn \u00b7 r of xu. We can continue with the arch factorization of r v and combine the two sets of arches if these factorizations rely on the same alphabet: this is step (b.2.2). Otherwise, r v only uses a subset of the letters of xu. There won\u2019t be a new arch, only a longer rest: r\u2217(xu v) = r v. Step (b.2.1) is correct.\nNote that Algorithm 5.7 runs in time O ( |A(u v)|+ |\u03a3(u)|+ |\u03a3(v)| )\nand that the result has linear size |\u03a3(u v)| = O(|\u03a3(u)|+ |\u03a3(v)|)."
        },
        {
            "heading": "6 Universality indexes for SLP-compressed words",
            "text": "We are now ready to compute the universality indexes of SLP-compressed words. Recall that an SLP X is an acyclic context-free grammar in Chomsky normal\nform where furthermore each non-terminal has only one production rule, i.e., the grammar is deterministic (see survey [Loh12]). SLPs are the standard mathematical model for compression of texts and files and, modulo polynomial-time encodings, it encompasses most compression schemes used in practice.\nFormally, an SLP X with m rules is a list \u3008N1 \u2192 \u03c11; \u00b7 \u00b7 \u00b7 ;Nm \u2192 \u03c1m\u3009 of production rules where each right-hand side \u03c1i is either a letter a from A or a concatenation Nj Nj\u2032 of two nonterminals with j, j\n\u2032 < i. It has size |X | = O(m logm) when A is fixed.\nEach nonterminal Ni encodes a word, its expansion, given inductively via:\nexp(Ni) def =\n{\na if \u03c1i = a,\nexp(Nj) exp(Nj\u2032 ) if \u03c1i = Nj Nj\u2032 .\nFinally, the expansion exp(X) of the SLP itself is the expansion exp(Nm) of its last nonterminal. This is a word (or file) of length 2O(|X|) and one of the main goals in the area of compressed data science is to develop efficient methods for computing relevant information about exp(X) directly from X , i.e., without actually decompressing the word or file.\nIn this spirit we can state:\nTheorem 6.1. The universality indexes \u03b9 ( exp(X) ) and \u03b6 ( exp(X) ) can be computed from an SLP X in bilinear time O ( |A| \u00b7 |X | ) .\nProof. One just computes \u03a3 ( exp(N1) ) , . . . , \u03a3 ( exp(Nk) )\nfor the non-terminals N1, . . . , Nk of X . If Ni is associated with a production rule Ni \u2192 Ni1Ni2 , we compute \u03a3 ( exp(Ni) ) by combining \u03a3 ( exp(Ni1) ) and \u03a3 ( exp(Ni2) )\nvia Algorithm 5.7 (recall that i1, i2 < i since the grammar is acyclic). If Ni is associated with a production Ni \u2192 a for some a \u2208 A, then \u03a3 ( exp(Ni) )\n= \u03a3(a) is trivial. In the end we can extract the universality indexes of exp(X), defined as exp(Nk), from \u03a3 ( exp(Nk) )\nusing Corollary 5.6. Note that all signatures have size O(|A| \u00b7 |X |) since for any u = exp(Ni), log |u| is in O(|X |). With the analysis of Algorithm 5.7 and Corollary 5.6, this justifies the claim about complexity."
        },
        {
            "heading": "7 Conclusion",
            "text": "We introduced arch-jumping functions and used them to describe and analyse the subword universality and circular universality indexes \u03b9(u) and \u03b6(u). In particular, this leads to a simple and elegant algorithm for computing \u03b6(u).\nIn a second part we defined the subword universality signatures of words, a compact data structure with enough information for extracting \u03b9(u) and \u03b6(u). Since one can efficiently compute the signature of u v by composing the signatures of u and v, we obtain a polynomial-time algorithm for computing \u03b9(X) and \u03b6(X) when X is a SLP-compressed word. This raises our hopes that one can compute some subword-based descriptive complexity measures on compressed words, despite the known difficulties encountered when reasoning about subwords."
        }
    ],
    "year": 2023
}