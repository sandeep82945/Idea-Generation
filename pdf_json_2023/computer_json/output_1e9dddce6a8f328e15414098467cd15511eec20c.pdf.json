{
    "abstractText": "The problem of navigating an unmanned aerial vehicle (UAV) in an unknown environment is addressed with a novel model predictive control (MPC) formulation, named multitrajectory MPC (mt-MPC). The objective is to safely drive the vehicle to the desired target location by relying only on the partial description of the surroundings provided by an exteroceptive sensor. This information results in time-varying constraints during the navigation among obstacles. The proposed mt-MPC generates a sequence of position set points that are fed to control loops at lower hierarchical levels. To do so, the mt-MPC predicts two different state trajectories, a safe one and an exploiting one, in the same finite horizon optimal control problem (FHOCP). This formulation, particularly suitable for problems with uncertain time-varying constraints, allows one to partially decouple constraint satisfaction (safety) from cost function minimization (exploitation). Uncertainty due to modeling errors and sensors noise is taken into account as well, in a set membership (SM) framework. Theoretical guarantees of persistent obstacle avoidance are derived under suitable assumptions, and the approach is demonstrated experimentally out-of-the-laboratory on a prototype built with off-the-shelf components.",
    "authors": [
        {
            "affiliations": [],
            "name": "Danilo Saccani"
        }
    ],
    "id": "SP:96c8385dbbfe3aba2553e465182cfd88aba2608a",
    "references": [
        {
            "authors": [
                "S.A. Bagloee",
                "M. Tavana",
                "M. Asadi",
                "T. Oliver"
            ],
            "title": "Autonomous vehicles: Challenges, opportunities, and future implications for transportation policies",
            "venue": "J. Mod. Transp., vol. 24, pp. 284\u2013303, Dec. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "R. Bishop"
            ],
            "title": "A survey of intelligent vehicle applications worldwide",
            "venue": "Proc. IEEE Intell. Vehicles Symp., Oct. 2000, pp. 25\u201330.",
            "year": 2000
        },
        {
            "authors": [
                "S. Tang",
                "V. Kumar"
            ],
            "title": "Autonomous flight",
            "venue": "Annu. Rev. Control, Robot., Auton. Syst., vol. 1, pp. 29\u201352, May 2018.",
            "year": 2018
        },
        {
            "authors": [
                "S. Aggarwal",
                "N. Kumar"
            ],
            "title": "Path planning techniques for unmanned aerial vehicles: A review, solutions, and challenges",
            "venue": "Comput. Commun., vol. 149, pp. 270\u2013299, Jan. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "T. Paul",
                "T.R. Krogstad",
                "J.T. Gravdahl"
            ],
            "title": "Modelling of UAV formation flight using 3D potential field",
            "venue": "Simul. Model. Pract. Theory, vol. 16, no. 9, pp. 1453\u20131462, 2008.",
            "year": 2008
        },
        {
            "authors": [
                "Y.-B. Chen",
                "G.-C. Luo",
                "Y.-S. Mei",
                "J.-Q. Yu",
                "X.-L. Su"
            ],
            "title": "UAV path planning using artificial potential field method updated by optimal control theory",
            "venue": "Int. J. Syst. Sci., vol. 47, no. 6, pp. 1407\u20131420, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "R. Geraerts"
            ],
            "title": "Planning short paths with clearance using explicit corridors",
            "venue": "Proc. IEEE Int. Conf. Robot. Autom., May 2010, pp. 1997\u20132004.",
            "year": 2010
        },
        {
            "authors": [
                "Z. Chengjun",
                "M. Xiuyun"
            ],
            "title": "Spare a search approach for UAV route planning",
            "venue": "Proc. IEEE Int. Conf. Unmanned Syst. (ICUS), Oct. 2017, pp. 413\u2013417.",
            "year": 2017
        },
        {
            "authors": [
                "M. Kothari",
                "I. Postlethwaite"
            ],
            "title": "A probabilistically robust path planning algorithm for UAVs using rapidly-exploring random trees",
            "venue": "J. Intell. Robot. Syst., vol. 71, pp. 231\u2013253, Dec. 2013.",
            "year": 2013
        },
        {
            "authors": [
                "A. Bemporad",
                "C.A. Pascucci",
                "C. Rocchi"
            ],
            "title": "Hierarchical and hybrid model predictive control of quadcopter air vehicles",
            "venue": "Proc. ADHS, 2009, pp. 14\u201319.",
            "year": 2009
        },
        {
            "authors": [
                "H. Oleynikova",
                "M. Burri",
                "Z. Taylor",
                "J. Nieto",
                "R. Siegwart",
                "E. Galceran"
            ],
            "title": "Continuous-time trajectory optimization for online UAV replanning",
            "venue": "Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), Oct. 2016, pp. 5332\u20135339.",
            "year": 2016
        },
        {
            "authors": [
                "D.Q. Mayne",
                "M.M. Seron",
                "S.V. Rakovi\u0107"
            ],
            "title": "Robust model predictive control of constrained linear systems with bounded disturbances",
            "venue": "Automatica, vol. 41, no. 2, p. 219\u2013224, 2005.",
            "year": 2005
        },
        {
            "authors": [
                "L. Chisci",
                "G. Zappa"
            ],
            "title": "Robustifying a predictive controller against persistent disturbances",
            "venue": "Proc. Eur. Control Conf. (ECC), Aug. 1999, pp. 2419\u20132424.",
            "year": 1999
        },
        {
            "authors": [
                "L. Chisci",
                "J.A. Rossiter",
                "G. Zappa"
            ],
            "title": "Systems with persistent disturbances: Predictive control with restricted constraints",
            "venue": "Automatica, vol. 37, no. 7, pp. 1019\u20131028, 2001.",
            "year": 2001
        },
        {
            "authors": [
                "A. Richards",
                "J.P. How"
            ],
            "title": "Aircraft trajectory planning with collision avoidance using mixed integer linear programming",
            "venue": "Proc. Amer. Control Conf., vol. 3, May 2002, pp. 1936\u20131941.",
            "year": 2002
        },
        {
            "authors": [
                "A. Bemporad",
                "C. Rocchi"
            ],
            "title": "Decentralized linear time-varying model predictive control of a formation of unmanned aerial vehicles",
            "venue": "Proc. IEEE Conf. Decis. Control Eur. Control Conf., Dec. 2011, pp. 7488\u20137493.",
            "year": 2011
        },
        {
            "authors": [
                "M.A. Mousavi",
                "Z. Heshmati",
                "B. Moshiri"
            ],
            "title": "LTV-MPC based path planning of an autonomous vehicle via convex optimization",
            "venue": "Proc. 21st Iranian Conf. Electr. Eng. (ICEE), May 2013, pp. 1\u20137.",
            "year": 2013
        },
        {
            "authors": [
                "S. Sharma"
            ],
            "title": "QCQP-tunneling: Ellipsoidal constrained agent navigation",
            "venue": "Proc. IASTED Int. Conf. Robot., 2011, doi: 10.2316/P.2011.752-010.",
            "year": 2011
        },
        {
            "authors": [
                "R. Deits",
                "R. Tedrake"
            ],
            "title": "Computing large convex regions of obstaclefree space through semidefinite programming",
            "venue": "Algorithmic Foundations of Robotics XI. Cham, Switzerland: Springer, 2015, pp. 109\u2013124.",
            "year": 2015
        },
        {
            "authors": [
                "S. Liu"
            ],
            "title": "Planning dynamically feasible trajectories for quadrotors using safe flight corridors in 3-D complex environments",
            "venue": "IEEE Robot. Autom. Lett., vol. 2, no. 3, pp. 1688\u20131695, Feb. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "J. Tordesillas",
                "B.T. Lopez",
                "M. Everett",
                "J.P. How"
            ],
            "title": "FASTER: Fast and safe trajectory planner for navigation in unknown environments",
            "venue": "IEEE Trans. Robot., vol. 38, no. 2, pp. 922\u2013938, Apr. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S. Hrabar"
            ],
            "title": "Reactive obstacle avoidance for rotorcraft UAVs",
            "venue": "Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., Sep. 2011, pp. 4967\u20134974.",
            "year": 2011
        },
        {
            "authors": [
                "J. Park",
                "N. Cho"
            ],
            "title": "Collision avoidance of hexacopter UAV based on LiDAR data in dynamic environment",
            "venue": "Remote Sens., vol. 12, no. 6, p. 975, Mar. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Sharma",
                "M.E. Taylor"
            ],
            "title": "Autonomous waypoint generation strategy for on-line navigation in unknown environments",
            "venue": "Proc. IROS Workshop Robot Motion Planning, Online, Reactive, Real-Time, Jul. 2012, pp. 37\u201348.",
            "year": 2012
        },
        {
            "authors": [
                "V.J. Hodge",
                "R. Hawkins",
                "R. Alexander"
            ],
            "title": "Deep reinforcement learning for drone navigation using sensor data",
            "venue": "Neural Comput. Appl., vol. 333, pp. 1\u201319, Mar. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "C. Greatwood",
                "A.G. Richards"
            ],
            "title": "Reinforcement learning and model predictive control for robust embedded quadrotor guidance and control",
            "venue": "Auto. Robots, vol. 43, no. 7, pp. 1681\u20131693, Oct. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "S. Bansal",
                "V. Tolani",
                "S. Gupta",
                "J. Malik",
                "C. Tomlin"
            ],
            "title": "Combining optimal control and learning for visual navigation in novel environments",
            "venue": "Proc. Conf. Robot Learn., 2020, pp. 420\u2013429.",
            "year": 2020
        },
        {
            "authors": [
                "K.P. Wabersich",
                "M.N. Zeilinger"
            ],
            "title": "A predictive safety filter for learning-based control of constrained nonlinear dynamical systems",
            "venue": "Automatica, vol. 129, Jul. 2021, Art. no. 109597.",
            "year": 2021
        },
        {
            "authors": [
                "J. Tordesillas",
                "B.T. Lopez",
                "J.P. How"
            ],
            "title": "Faster: Fast and safe trajectory planner for flights in unknown environments",
            "venue": "Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), Nov. 2019, pp. 1934\u20131940.",
            "year": 2019
        },
        {
            "authors": [
                "J.P. Alsterda",
                "M. Brown",
                "J.C. Gerdes"
            ],
            "title": "Contingency model predictive control for automated vehicles",
            "venue": "Proc. Amer. Control Conf. (ACC), Jul. 2019, pp. 717\u2013722.",
            "year": 2019
        },
        {
            "authors": [
                "D. Saccani",
                "L. Fagiano"
            ],
            "title": "Autonomous UAV navigation in an unknown environment via multi-trajectory model predictive control",
            "venue": "Proc. Eur. Control Conf. (ECC), Jun. 2021, pp. 1577\u20131582.",
            "year": 2021
        },
        {
            "authors": [
                "M. Milanese",
                "C. Novara"
            ],
            "title": "Unified set membership theory for identification, prediction and filtering of nonlinear systems",
            "venue": "Automatica, vol. 47, no. 10, pp. 2141\u20132151, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "M. Lauricella",
                "L. Fagiano"
            ],
            "title": "Set membership identification of linear systems with guaranteed simulation accuracy",
            "venue": "IEEE Trans. Autom. Control, vol. 65, no. 12, pp. 5189\u20135204, Dec. 2020, doi: 10.1109/TAC.2020.2970146.",
            "year": 2020
        },
        {
            "authors": [
                "J. Fuentes-Pacheco",
                "J. Ruiz-Ascencio",
                "J.M. Rend\u00f3n-Mancha"
            ],
            "title": "Visual simultaneous localization and mapping: A survey",
            "venue": "Artif. Intell. Rev., vol. 43, no. 1, pp. 55\u201381, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "L. Ljung"
            ],
            "title": "System identification",
            "venue": "Signal Analysis and Prediction (Applied and Numerical Harmonic Analysis), A. Proch\u00e1zka, J. Uhl\u0131r\u0303, P. W. J. Rayner, and N. G. Kingsbury, Eds. Boston, MA, USA: Birkh\u00e4user, 1998, doi: 10.1007/978-1-4612-1768-8_11. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 16 IEEE TRANSACTIONS ON CONTROL SYSTEMS TECHNOLOGY",
            "year": 1998
        },
        {
            "authors": [
                "T. Schouwenaars",
                "J. How",
                "E. Feron"
            ],
            "title": "Receding horizon path planning with implicit safety guarantees",
            "venue": "Proc. Amer. control Conf., vol. 6, Jun. 2004, pp. 5576\u20135581.",
            "year": 2004
        },
        {
            "authors": [
                "D. Mayne"
            ],
            "title": "Robust and stochastic model predictive control: Are we going in the right direction?",
            "venue": "Annu. Rev. Control,",
            "year": 2016
        },
        {
            "authors": [
                "S. Formentin",
                "M. Lovera"
            ],
            "title": "Flatness-based control of a quadrotor helicopter via feedforward linearization",
            "venue": "Proc. IEEE Conf. Decis. Control Eur. Control Conf., Dec. 2011, pp. 6171\u20136176.",
            "year": 2011
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014 Learning for control, model predictive control (MPC), safe autonomous navigation, uncertainty quantification, unmanned aerial vehicles (UAVs).\nI. INTRODUCTION\nIN THE last decade, technological advancements haveallowed unmanned aerial vehicles (UAVs) to become more and more common in our everyday life [1], [2]. Great research progress has been made across multiple areas, showing that relatively cheap civil drones can take off, carry out complex missions, and land without any human intervention. At the same time, autonomous UAV missions belong to the spectrum of safety-critical applications, where the use of algorithms that\nManuscript received 21 January 2022; revised 13 June 2022; accepted 30 September 2022. This work was supported in part by the Italian Ministry of University and Research (MUR), PRIN 2017 program, under Grant 201732RS94 \u201cSystems of Tethered Multicopters,\u201d and in part by the European Union\u2019s Horizon 2020 Research and Innovation Program, under the Marie Sk\u0142odowska\u2013Curie Grant 953348 \u201cEmbedded Learning and Optimization for the Next Generation of Smart Industrial Control Systems (ELO-X).\u201d Recommended by Associate Editor F. Dabbene. (Corresponding author: Lorenzo Fagiano.)\nDanilo Saccani and Lorenzo Fagiano are with the Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano, 20133 Milan, Italy (e-mail: danilo.saccani@polimi.it; lorenzo.fagiano@polimi.it).\nLeonardo Cecchin is with Robert Bosch GmbH, 70465 Stuttgart, Germany (e-mail: leonardo.cecchin@de.bosch.com).\nColor versions of one or more figures in this article are available at https://doi.org/10.1109/TCST.2022.3216989.\nDigital Object Identifier 10.1109/TCST.2022.3216989\ndo not account for uncertainty and robust constraint satisfaction can lead to catastrophic effects, such as injury to people, loss or harm to property/equipment, or environmental damage. The design of motion planning algorithms in safety-critical applications must trade-off a risk-aware approach, which guarantees the safety of the system and the environment, and the exploitation of the vehicle capabilities without falling into a too conservative behavior. We consider here the problem of guaranteeing collision-free autonomous navigation from an initial point to a target position in an unknown environment. This problem presents several challenges: from rather usual requirements, such as the compliance with actuator constraints and vehicle dynamics [3], to the need to guarantee collision avoidance despite uncertainties both in the environment and in the system dynamics and sensing capabilities, at the same time keeping computational complexity small enough to enable the real-time applicability of the algorithm in real-world tasks."
        },
        {
            "heading": "A. Related Work",
            "text": "When a description of the environment is available, different approaches can be found in the literature to provide a collision-free path [4]. Sampling-based techniques, such as potential field methods [5], [6], cell decomposition [7], or roadmaps (e.g., A* [8], rapidly exploring random trees [9]), have been widely studied, providing a reliable way to perform offline path planning.\nTo include the vehicle\u2019s dynamics and manage constraints, model predictive control (MPC) [10], [11] has been investigated as well. Robust MPC approaches have been widely explored to consider disturbances and/or model mismatch. Robustness is usually achieved by tightening the constraints in the optimization, as shown in [12], [13], and [14]. Bemporad et al. [10] and Richards and How [15] use an integer variable to account for the intersection of the predicted trajectory with an obstacle, obtaining in this way a mixed-integer quadratic or linear program (MIQP or MILP) to be solved at each time step in a receding horizon fashion. By under-approximating the free space with convex polytopes, instead, it is possible to solve the problem without using integer variables (see, e.g., [16], [17]). The resulting linear, but time-variant constraints allow one to use a linear time-varying MPC formulation to compute a dynamically feasible and collision-free trajectory. The main drawback of these approaches is the need for a suitable discretization of the environment and the increasing complexity of the problem\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nwith the number of obstacles and/or convex regions used in the approximation. The inner approximation with convex sets of safe regions has been widely studied as well. Several optimization-based approaches have been proposed (see, e.g., [16], [18], [19]) where the position of known obstacles is exploited to obtain the largest convex set in the free area. These approaches, however, do not guarantee the belonging of the current vehicle\u2019s position to the obtained set, and they require an a priori description of the environment, as a set of convex polytopes or as a map. On the contrary, in this work, we assume that no map is initially available and exploit only local sensor measurements.\nIndeed, when the environment is partially or totally unknown, or it could be different from the prior information, the system must rely on local information collected by the available sensors to compute a feasible trajectory. Different approaches can be found in the literature that exploit directly the available information provided by exteroceptive sensors either to build a local map of the environment [20], [21] or for reactive obstacle avoidance (see, e.g., [22], [23]). Liu et al. [20] use convex optimization to derive piecewise polynomial trajectories for the navigation of an UAV in a partially unknown environment. A 3-D light detection and ranging (LiDAR) is used to build a local map, which is employed to compute convex connected polyhedra modeling the obstacle-free space and considered as linear inequality constraints in a quadratic program (QP) for trajectory optimization. However, the trajectory planning approaches available in the literature, despite providing an obstacle-free trajectory, only consider constraints on kinematic quantities and do not include, in the problem setup, the vehicle\u2019s dynamical response and the related uncertainty, due to, e.g., model mismatch or external disturbances. Other existing works dealing with this problem adopt reinforcement learning (RL) methods [24], [25], which employ directly the sensor measurements. All these methods often obtain good performance and the planning of obstacle-free trajectories but with little regard to safety guarantees, here considered in the form of constraint satisfaction and persistent obstacle avoidance. Other approaches exploit prior knowledge about the system to ensure safety, by combining optimal control and learning (see, e.g., [26], [27], [28]). This problem is particularly challenging, since the feasible path must be replanned online, as new parts of the environment are discovered. In this case, the control logic has to balance two conflicting aspects: safety, that is to avoid the online discovered obstacles, and exploitation, that is to reach the desired target in short time.\nTo deal with this balancing issue, in this work, we propose a novel MPC approach that we find particularly suitable for time-varying systems or constraints, named multitrajectory MPC (mt-MPC). To trade-off safety and exploitation in an intuitive way, the mt-MPC considers different future state trajectories in the same finite horizon optimal control problem (FHOCP), enabling a partial decoupling between constraint satisfaction (safety) and cost function minimization (exploitation). In [21] and [29], a control approach is proposed for the trajectory planning of a UAV equipped with a sensor that detects the surrounding partially unknown environment. The\napproach also relies in this case on a multitrajectory concept and proposes the application to several practical scenarios. On the other hand, the approach only considers a triple integrator as dynamics of the vehicle and does not provide theoretical guarantees on constraints satisfaction, which is one of the objectives of this work. A related MPC formulation has been proposed in [30], where the FHOCP trades-off the behavior of a nominal and a contingency model of a selfdriving car. While Alsterda et al. [30] try to find a contingency maneuver in case of an unexpected change in the system, here, we consider multiple trajectories to exploit as much as possible the current knowledge of the environment and to reduce the conservatism of a guaranteed collision-free approach. Finally, a preliminary version of the mt-MPC approach appeared in our recent work [31], where a 2-D navigation problem is considered and a simulation study is presented. In this article, we deliver many additional contributions, as described next."
        },
        {
            "heading": "B. Contributions",
            "text": "We propose and demonstrate experimentally the use of mt-MPC to drive safely a multicopter drone, equipped with an exteroceptive sensor, to a goal point in an a priori unknown environment. The control structure is hierarchical: at low level, state-feedback controllers stabilize the vehicle\u2019s trajectories and track the set points provided by the high-level mt-MPC. The navigation in an unknown environment leads to timevarying constraints, such that standard receding horizon strategies do not guarantee recursive feasibility anymore. To address this problem, we propose a modified receding horizon implementation and prove the existence of a feasible trajectory at each time step, hence persistent obstacle avoidance, under the assumption of time invariant environment. To guarantee this property also in the presence of model-plant mismatch and disturbances, we quantify the model uncertainty in terms of bounds on the prediction error by exploiting a set membership (SM) framework [32], [33]. Thus, we address both environment uncertainty and model uncertainty, at the same time providing a method to quantify the latter from experimental data. All these aspects are relevant in real-world applications, yet they are rarely considered altogether in previous contributions, where the focus is either on the environment or on robust control starting from a given uncertainty model (e.g., disturbance bounds or model sets) without mentioning how this is derived. The resulting MPC law is a dynamic statefeedback one, in contrast with most of the literature where a static state-feedback controller is obtained. In addition, we also address two application-specific problems: the need to derive a convex under-approximation of the free space around the drone exploiting only local sensor measurements, in order to formulate the FHOCP as a convex QP, and the need to navigate around obstacles that stand between the drone and its target. Regarding the approximation of the free space, we present an approach that is computationally efficient and guarantees that the drone belongs to the derived set, which is needed to formally guarantee obstacle avoidance. Compared with our preliminary work [31], the main novel contributions are as follows: the quantification of model uncertainty from data, the development and theoretical analysis of a mt-MPC approach\nthat guarantees robust obstacle avoidance against such uncertainty, the extension to 3-D motion, and the experimental test on a real-world, out-of-the-laboratory drone prototype.\nThis article is organized as follows. After an overview of the system and the problem formulation in Section II, in Section III, we describe the employed control-oriented model, characterize the model uncertainty, and present the approach to derive a convex under-approximation of the free space, in order to plan safe trajectories. Then, Section IV is concerned with the mt-MPC formulation and its properties. Finally, Sections V and VI provide the simulation and experimental results, respectively, and Section VII concludes this article."
        },
        {
            "heading": "C. Notation",
            "text": "We denote with t \u2208 R the continuous time variable, with k \u2208 Z the discrete time index with sampling time Ts , with N the set of positive integers, and Nba = {n \u2208 N | a \u2264 n \u2264 b}. Bold symbols indicate vectors, and \u00b7T is the matrix transpose operation. 0a\u00d7b and Ia denote a matrix of zeros with a rows and b columns and the a-by-a identity matrix, respectively. ||v|| = (vT v)1/2 denotes the two norm of vector v, and ||v||A = (vT Av)1/2 denotes the two norm of vector v weighted by matrix A \u2265 0 (positive semidefinite). The notations \u00b7\u0303, \u00b7\u0302 represent a sample and an estimate of a given variable, respectively. The sum of two sets A, B \u2286 Rn, denoted as A \u2295 B, is {a + b | a \u2208 A, b \u2208 B}, while A B is {x \u2208 Rn | x + b \u2208 A, \u2200b \u2208 B}. For an ordered set of points Sv = {Sv1, . . . ,S vnv } \u2208 R3, we denote with chull(Sv ) their convex hull. Finally, let E (W ) = {e : eT W e \u2264 1} be the ellipsoidal set centered at the origin with shape matrix W = W T > 0."
        },
        {
            "heading": "II. SYSTEM AND ENVIRONMENT MODELS, PROBLEM FORMULATION",
            "text": "The three main ingredients defining the problem at hand are as follows: the autonomous system, the exteroceptive\nsensor used to gather information about the environment, and the environment itself. These elements are presented in the Sections II-A\u2013II-C culminating in a more precise problem formulation."
        },
        {
            "heading": "A. Multicopter Vehicle and Preliminary Dataset",
            "text": "We consider an inertial, right-handed coordinate system (x f , y f , z f ) with origin at ground level, (x f , y f ) coordinates defining a plane parallel to the ground, and z f coordinate positive above ground level. The autonomous vehicle features a hierarchical control structure. From the point of view of the high-level controller, the control input is the variable\nu(k) = ux f (k), uy f (k), uz f (k) T = pref(k) \u2208 R3 (1) which is the position reference provided to the low-level controller; see Fig. 1. The latter is in charge of tracking such a position reference. Note that any low-level controller (e.g., the one of a commercial flight controller, as in our experimental tests) can be considered, as long as it is able to stabilize the drone\u2019s trajectories and to track the given reference with good performance (possible tracking errors due to disturbances are captured by our method to quantify uncertainty, described in Section III-C). Neglecting the attitude dynamics that are managed by the low-level control loops, we can represent the feedback-controlled drone as a nonlinear time-invariant system featuring as state the vehicle position p(k) and velocity v(k)\nx(k) = px f (k), py f (k), pz f (k), v x f (k), v y f (k), v z f (k) T (2) and as input u(k); thus, we have x(k) \u2208 R6 and u(k) \u2208 R3. We also denote with a\u0304 \u2208 R3 and v\u0304 \u2208 R3 the vehicle\u2019s maximum acceleration and velocity, respectively. If the drone\u2019s yaw is relevant, for example, to point a given sensor to a desired direction, this can be easily added as further state. Here, for simplicity, we focus on missions that require the drone to reach a given target position without any yaw angle specification. We also assume that a finite number of measured pairs (u\u0303(k), x\u0303(k)) are available from preliminary tests, for\nexample, carried out by a human operator or, as in our experimental application, by automated step reference sequences. We denote the collected dataset as follows:\nM\u0303=\u0307 (u\u0303( j), x\u0303( j)) \u2200 j \u2208 NNs0\n(3)\nwhere Ns + 1 is the number of input\u2013output pairs in the dataset. We assume that these data are affected both by process disturbance (e.g., wind) and measurement noise.\nLet x (k + j ; u\u0304), j > 0, be the state trajectory of the nonlinear system at time k + j , obtained by applying the constant reference position u\u0304 starting from the initial condition x(k). Let the scalar r > 0 be a given distance bound. We consider the following assumption on the feedback-controlled vehicle.\nAssumption 1: There exists a convex set PW , such that \u2200r \u2200x(k) \u2200u\u0304 : || p(k) \u2212 u\u0304|| \u2264 r, \u2203 j(r) :\n\u00d7 x(k + j ; u\u0304) \u2212 u\u0304 03\u00d71\n\u2208 PW \u2200 j \u2265 j(r).\nAssumption 1 states that for any given distance r , there exists a time instant j(r), such that for all constant references u\u0304 that are closer than r to the starting position p(k), the vector of position tracking errors at time k + j belongs to the convex set PW ,\u2200 j > j(r).\nThis assumption is related to the stability of the trajectories of the system at hand and to the boundedness of exogenous process disturbances. In the considered application, it is a reasonable assumption, considering the presence of a stabilizing, reference-tracking low-level position controller. The convex set PW can be estimated directly from the dataset (3), as shown in our experimental results in Section VI."
        },
        {
            "heading": "B. Sensor Setup",
            "text": "We assume to receive, at each time step k, the measurements of vehicle\u2019s position p(k) and velocity v(k) together with the readings of an exteroceptive sensor able to partially detect the surrounding obstacles. The vehicle position and velocity can be measured with the use of a global positioning system (GPS) device or estimated exploiting exteroceptive sensors and simultaneous localization and mapping (SLAM) approaches [34]. As for the exteroceptive sensor, we assume to receive a 3-D point cloud providing a discretization of the environment around the drone, as shown in Fig. 2. In practice, this can be achieved with 3-D LiDAR sensors and/or stereocameras. Without loss of generality, we assume to receive a grid of points lying on directions that are equally spaced over a unit-sphere centered at the drone\u2019s position, and we denote with \u03c1(k) \u2208 RM the vector readings provided at time k by the sensor. The length of \u03c1(k) is M = Ma Me = (2\u03c0/\u03b1a)(\u03c0/\u03b1e), where \u03b1a and \u03b1e are the azimuth and elevation angular resolutions, respectively. Denoting with ia and ie two indexes spanning the sampled azimuth and elevation values, each measurement corresponds to a vector\nsi (k) = \u03c1i (k) \u23a1 \u23a3cos (ie\u03b1e) cos (ia\u03b1a)cos (ie\u03b1e) sin (ia\u03b1a)\nsin (ie\u03b1e)\n\u23a4 \u23a6, ia \u2208 NMa\u221210 , ie \u2208 NMe\u221210\n(4)\nwhere \u03c1i(k) is the i th entry of vector \u03c1(k) and i = Maie + ia. We finally denote with rL the range of the sensor, assumed for simplicity to be the same along any direction."
        },
        {
            "heading": "C. Environment Model and Problem Formulation",
            "text": "We consider a time-invariant environment composed of No, generally non-convex, 3-D obstacles with variable cross section; see Fig. 3 for an example. In this framework, each obstacle can be described as a compact set Oi \u2208 R3, i = 1, . . . , No. We define the overall obstacles\u2019 set O as follows:\nO .= No\ni=1 Oi . (5)\nWe are now in position to formalize the problem considered in this work. Given the dataset M\u0303, identify a \u201ccontroloriented\u201d model of the feedback-controlled vehicle together with a bound on the prediction error with respect to the real system. Then, exploiting these information, design a highlevel discrete-time navigation logic that makes use of the sensor measurements \u03c1(k) and the state feedback x(k) to\ncompute, at each time step k, the input u(k) in order to move the UAV from a given initial position p(0) /\u2208 O toward a target position pt(k) \u2208 R3 in a safe way, i.e., such that p(k) /\u2208 O,\u2200k \u2265 0 despite the various sources of uncertainty."
        },
        {
            "heading": "III. CONTROL-ORIENTED MODEL AND CONVEX APPROXIMATION OF THE ENVIRONMENT",
            "text": "Two key elements to address the problem at hand are a suitable model of the system together with the associated uncertainty consistent with the dataset (3) and the exploitation of sensor measurements to describe the surrounding environment. We describe next these elements, which will be employed in the mt-MPC formulation described in Section IV."
        },
        {
            "heading": "A. Control-Oriented Model",
            "text": "The considered system is composed of the nonlinear dynamics of the drone in closed loop with the low-level position controller. From the point of view of the high-level navigation strategy, linear dynamics well approximate the behavior of the closed-loop system. Furthermore, the choice of a linear time-invariant (LTI) model allows us to cast the optimal control problem as a QP, that we can solve in real time also on relatively low-power hardware, as shown in Section VI. To obtain the control-oriented model, we consider the following continuous time double integrator with state feedback:\np\u0307(t) v\u0307(t) = 03\u00d73 I3 \u2212Kvel Kpos \u2212 Kvel p(t) v(t) + 03\u00d73 Kvel Kpos u(t)\np(t) = I3 03\u00d73 Cp p(t) v(t)\nv(t) = 03\u00d73 I3 Cv p(t) v(t)\n(6)\nand we denote with\na(t) = Kvel Kpos(u(t) \u2212 p(t)) \u2212 v(t)\n(7)\nthe drone acceleration vector. Kpos \u2208 R3\u00d73 and Kvel \u2208 R 3\u00d73 are suitable gain matrices representing the position and\nvelocity feedback loops that can be tuned by carrying out a system identification procedure to obtain a closed-loop system response as close as possible to the one of the actual nonlinear system. We then convert (6) to discrete time with sampling time Ts , obtaining the desired control-oriented model of the form\nx(k + 1) = A Kpos, Kvel x(k) + B Kpos, Kvel u(k) (8a) p(k) = Cp x(k) (8b) v(k) = Cv x(k) (8c)\nwhere the input u(k) and the state x(k) of the positioncontrolled system are defined in (1) and (2). Thus, the LTI model (8) features u(k) as input, consistently with our setup, and its state includes both position and velocity, making it possible to easily include, in the predictive control strategy, constraints on these quantities and on the accelerations as well, through the linear, static equation (7). In turn, acceleration bounds can be chosen to account for the maximum limits on propellers\u2019 thrust and roll/pitch angles that are used to maneuver, thus achieving coherence between the LTI control-oriented model and the performance limits of the actual nonlinear system.\nWe consider the following assumption on the nominal model.\nAssumption 2:\n\u2200u\u0304 \u2200x(k) : x(k) \u2212 u\u0304 03\u00d71\n\u2208 PW , \u2203D = DT > 0.\n1) A(Kpos, Kvel)x(k) + B(Kpos, Kvel)u\u0304 \u2208 E (D). 2) PW \u2286 E (D). 3) E (D) \u2286 V .\nHere, V is the set of admissible states accounting for the drone\u2019s acceleration and velocity limits.\nIn practice, Assumption 2 is satisfied if the control-oriented model is asymptotically stable, and it can be verified by taking the sublevel set of the Lyapunov function V (x) = xT Dx that contains the polytope PW in its interior (this condition can be checked via Linear Matrix Inequalities; see, e.g., [35]) and such that state constraints are satisfied for all points in it. Suitable convex programs can be used to check this condition as well, as shown in Section VI.\nRemark 1: In order to obtain a convex QP in the final implementation, in the following, we will consider the convex polytopic outer approximations of the ellipsoidal set E (D), denoted as PD . Alternatively, one can retain an ellipse, which leads to a convex quadratically constrained QP (QCQP).\nB. Identification of the Control-Oriented Model\nExploiting the dataset (3), we identify the gain matrices Kpos and Kvel of the control-oriented model. According to best practices [36], we divide the dataset in two parts: one is used for the identification phase (identification set), while performance is assessed on the remaining part (validation set). We carry out the identification with a simulation error\nmethod (SEM)\nmin Kpos,Kvel\nNs k=1 x\u0302(k) \u2212 x\u0303(k) 2\ns.t. x\u0302(0) = x\u0303(0) x\u0302(k + 1) = A Kpos, Kvel x\u0302(k) +B Kpos, Kvel u\u0303(k)\u2200k \u2208 NNs\u221210 . (9)\nThe use of a simulation error criterion and the fact that A(Kpos, Kvel) \u2208 R6\u00d76 and B(Kpos, Kvel) \u2208 R6\u00d73 depend nonlinearly on Kpos and Kvel make (9) a non-LP (NLP).\nRemark 2: For the sake of notational simplicity, from now on, we denote simply with A and B the matrices A(Kpos, Kvel) and B(Kpos, Kvel) with the parameters identified by solving the NLP (9)."
        },
        {
            "heading": "C. Derivation of Prediction Uncertainty Bounds",
            "text": "The identified model is a linear, low dimensional approximation of the nonlinear system dynamics. To obtain a navigation logic able to robustly guarantee safety, we, thus, need to derive bounds on the prediction error due to linearization, process and measurement disturbances, and neglected dynamics. On the other hand, the uncertainty bounds shall be not too conservative, to avoid unnecessary performance degradation. In most contributions on robust MPC, these bounds are initially given together with the model, but, in practice, they have to be derived from data. We provide here a systematic procedure to do this, in an SM framework. Since we are interested in prediction bounds on the drone\u2019s position, let us consider the output equation (8b).\nThe n-steps-ahead predictor of the control-oriented model (8) for the i th output, denoted as p\u0302n,i , is\np\u0302n,i(k) = Cp,i An x\u0303(k) +Cp,i\nn j=1 A j\u22121 B u\u0303(k + n \u2212 j) (10)\nwhere Cp,i is the i th row of the output matrix Cp in (8b) and i = 1, 2, 3. We define the measured regressor \u03d5\u0303n \u2208 R6+3n as follows: \u03d5\u0303n(k) = x\u0303(k)T u\u0303(k)T u\u0303(k + 1)T \u00b7 \u00b7 \u00b7 u\u0303(k + n \u2212 1)T T\n(11)\nand the vector of the identified parameters for the i th output \u03b8\u0302n,i \u2208 R6+3n is\n\u03b8\u0302n,i = Cp,i A n Cp,i A n\u22121 B Cp,i An\u22122 B \u00b7 \u00b7 \u00b7 Cp,i AB Cp,i B T .\n(12)\nWe can then reorganize the dataset M\u0303 for each n-steps-ahead prediction n = 1, . . . , N , where N \u2208 N is the considered prediction horizon, by collecting sampled regressors and corresponding output values\nM\u0303n,i=\u0307 \u03d5\u0303n(k), p\u0303n,i(k) \u2200k \u2208 NNs0 (13)\nwhere p\u0303n,i(k) is the i th component of the sampled n-stepsahead position, available in the dataset.\nThen, (10) can be compactly rewritten as follows: p\u0302n,i(k) = \u03d5\u0303n(k)T \u03b8\u0302n,i . (14)\nWe can now estimate the error bound between the measured position and the corresponding n-steps-ahead prediction given by a linear model via the following LP:\n\u03bbn,i = min \u03b8n,i , \u03bb\u2208R+ \u03bb (15a)\ns.t. | p\u0303n,i \u2212 \u03d5\u0303Tn \u03b8n,i | \u2264 \u03bb \u2200 \u03d5\u0303n, p\u0303n,i \u2208 M\u0303n,i . (15b)\nThis LP is always feasible and returns a positive value when the constraints generated by the data (15b) are informative enough to support from below the bound \u03bb; otherwise, we have \u03bb = 0. As proven in [33], due to the finiteness of the dataset M\u0303n,i , the computed value of \u03bbn,i is an under-approximation of the global (with respect to all possible regressors) error bound \u03b5\u0304n,i . To estimate the latter, we, thus, include a scaling factor \u03bc > 1\n\u02c6\u0304\u03b5n,i = \u03bc\u03bbn,i , \u03bc > 1. (16) We are now in position to define the feasible parameter set (FPS), i.e., the set of all the possible parameters of a predictor of the form (14) compatible with the available information. This set is the following convex polytope:\nn,i=\u0307 \u03b8n,i : | p\u0303n,i \u2212 \u03d5\u0303Tn \u03b8n,i | \u2264 \u02c6\u0304\u03b5n,i \u2200 \u03d5\u0303n, p\u0303n,i \u2208 M\u0303n,i . (17)\nThe FPS can be finally used to compute, for each prediction step n, the wanted worst case prediction error bound associated with the identified model (14) with parameters \u03b8\u0302n,i\n\u03c4n,i = max k=0,...,Ns max \u03b8\u2208 n,i \u03d5\u0303n(k)T \u03b8 \u2212 \u03b8\u0302n,i + \u02c6\u0304\u03b5n,i . (18) Namely, this bound is the worst case discrepancy between the prediction provided by the identified linear model and that of any other model that is consistent with the data up to the error bound (16). Since also \u03c4n,i is an under-approximation of the actual bound, a second scaling factor \u03b7 > 1 is introduced to account for the finite dataset\n\u03c4\u0302n,i = \u03b7\nmax k=0,...,Ns max \u03b8\u2208 n,i\n\u03d5\u0303n(k)T \u03b8 \u2212 \u03b8\u0302n,i\n+ \u02c6\u0304\u03b5n,i , \u03b7 > 1. (19)\nThe estimation procedure is carried out for each row of matrix Cp in (8b), eventually obtaining the 3-D worst case prediction error bound \u03c2\u0302 n .\nRemark 3: Larger scaling factors \u03bc and \u03b7 result in larger uncertainty bounds to take into account possible new data that may invalidate the prior assumptions and/or estimated bounds. In a real application, it is easy to observe when these factors are too small by checking if the FPS (17) becomes empty when new data (i.e., additional inequalities) are considered. On the other hand, to understand if \u03bc and \u03b7 are too large, one can evaluate empirically the conservativeness with ad hoc tests or directly by analyzing the data of the system in operation and comparing it with the bounds, as we show in Section VI.\nAlgorithm 1 Convex Under-Approximation of the Free Space"
        },
        {
            "heading": "D. Convex Under-Approximation of the Free Space",
            "text": "Let us denote with L(k) .= {s0(k), . . . , sM\u22121(k)} \u2208 R\n3 the M readings (4) of the exteroceptive sensor at time k. Let dstep > 0 be a user-defined distance. Moreover, we consider the user-selected quantities \u03b2a > \u03b1a and \u03b2e > \u03b1e, i.e., azimuth and elevation angular resolution intervals defining a number nv of equally spaced candidate vertices on the unit sphere centered at the drone position. Then, the proposed routine to build a convex under-approximation of the obstacle-free region is given by Algorithm 1.\nFirst (lines 1\u20135), a regular polyhedron with nv vertices lying on the ball B( p(k), dmin(k)) = {w \u2208 R3 : w \u2212 p(k) = dmin(k)} is built. Then (lines 6\u201315), an arbitrarily chosen vertex is radially translated outward with respect to the center by the user-defined quantity dstep, and a convex hull of the new sequence of vertices is computed. If the obtained hull does not contain any points of L(k) and its vertices are closer than the maximum detection range rL , the polyhedron Sv is updated (line 10), and the next vertex is considered for the expansion. Otherwise, the last expansion is removed and the position of that vertex is blocked (line 12). The cycle stops when all the auxiliary variables \u03b3i are true (line 7), which means that either all vertices are blocked or they have reached the maximum distance rL from the drone.\nWhen the process is completed for all the vertices, the algorithm returns the wanted polytope S(k). To take into account the size of the drone, its maximum encumbrance is removed from the sensor readings. As an example, Fig. 4 shows a few iterations of Algorithm 1.\nRemark 4: Differently from other approaches in the literature, Algorithm 1 ensures by construction that the current position of the drone, p(k), is always in the interior of S(k), i.e., in the safe set. Moreover, this approach returns a valid convex under-approximation of the free space also when stopped at an intermediate step, which is an advantage when a strict real-time implementation is needed. The parameters \u03b2a and \u03b2e can be tuned to trade-off the polytope accuracy with the required computational time, their limit being the resolution of the sensor."
        },
        {
            "heading": "IV. MULTITRAJECTORY MPC",
            "text": "When the environment is unknown and the vehicle has to rely only on real-time local information, a common approach to guarantee safety in a receding horizon framework is to consider a trajectory able to stop the vehicle inside the obstacle-free set S(k) within the prediction horizon N \u2208 N; see, e.g., [37]. This can be achieved imposing an admissible steady state, or, as in our case, a safe terminal set at the end of the predicted trajectory. Furthermore, a robust approach must be adopted to account for the model uncertainty. To this regard, robust and stochastic MPCs have been widely studied [38]. In these approaches, the optimal trajectory is conservatively computed to include all, or a statistically representative part of, possible uncertainty realizations. However, in this case, the use of such approaches can lead to a too conservative behavior. Moreover, the safe set S(k) considered at each time step k is a convex under-approximation of the free space that generally changes over time and can possibly evolve in a favorable way for the sake of pursuing the given target. Therefore, on the one hand, we want to robustly guarantee safety at each time step, ensuring that there exists a maneuver able to keep the vehicle in a safe area before a collision occurs. On the other hand, we want to limit the conservativeness of the approach considering a possible, hopefully favorable, evolution of the safe set at the next time step. The proposed mt-MPC technique\naims at managing these conflicting objectives, by planning two trajectories: a \u201csafe\u201d one, guaranteed to be contained in the safe set and to reach a safe state also considering the model uncertainty, and an \u201cexploiting\u201d one, which assumes that the current constraints are too conservative and can, thus, violate them. The two trajectories feature the same input at the current step and separate only afterward in the prediction. To better illustrate this concept, let us consider the 2-D example in Fig. 5, showing on the left the multitrajectory approach and on the right a standard, single-trajectory one. The trajectories shown are computed by solving an FHOCP using the control-oriented model (8) and aiming to reach a target beyond the safe set. The single-trajectory approach forces all the predicted trajectory to lie within the safe set, minimizing the average distance from the target. This solution is optimal for the current safe set, but it does not consider a possible favorable evolution of the latter at the next time step. On the other hand, the multitrajectory approach plans a much better (yet currently unfeasible) exploiting trajectory, but still retaining a safe alternative in case the constraints\u2019 set does not expand toward the target. Since the approach is implemented in receding horizon, the potential advantage is apparent by comparing the position reached at the first predicted time step by the two approaches; see Fig. 5.\nLet us denote with x Ii|k the state of the exploiting trajectory of system (8) at time k + i predicted at time k, and with x I Ii|k that of the safe trajectory. Considering a finite horizon N \u2208 N, such that N \u2265 j(rL) (see Assumption 1), we introduce the two input sequences\nU I = u I T 0|k u I T 1|k \u00b7 \u00b7 \u00b7 u I T N\u22121|k T\n(20)\nU I I = u I I T 0|k u I I T 1|k \u00b7 \u00b7 \u00b7 u I I T N\u22121|k T\n(21)\npertaining to the exploiting and safe trajectories, respectively. We consider the following cost function to track a\ntarget pt(k):\nJ x(k), U, pt(k) = N i=1 pIi|k \u2212 pt(k) 2Q (22)\nwhere Q \u2208 R3\u00d73 is a symmetric positive-definite weighting matrix, and vector U = [U I T U I I T ]T \u2208 R3(2N).\nTo include in the FHOCP the worst case prediction error bound \u03c2\u0302 n computed in Section III-C, we tighten along the horizon N the set S(k) computed with Algorithm 1. To this end, let us define the uncertainty hyper-rectangles at each prediction step n as follows:\nTn = p \u2208 R3 : | p| \u2264 \u03c2\u0302 n \u2200n \u2208 NN\u221211 (23)\nTN = p \u2208 R3 : | p| \u2264 max n=1,...,N \u03c2\u0302 n\n(24)\nwhere all inequalities are elementwise. Then, the polytope S(k) is tightened along the horizon as follows: Si (k) = S(k) Ti \u2200i \u2208 NN1 (25)\nleading to the sequence of convex polytopes\nS\u0304(k) = Si (k) \u2200i \u2208 NN1 . (26) We are now in position to formulate the multitrajectory FHOCP, denoted as P(x(k), S\u0304(k), pt (k))\nmin U J x(k), U, pt (k)\n(27a)\ns.t. uI0|k = uI I0|k (27b) x I,I I0|k = x(k) (27c) x I,I Ii+1|k = Ax I,I Ii|k + BuI,I Ii|k \u2200i \u2208 NN\u221210 (27d) pI,I Ii|k = Cp x I,I Ii|k \u2200i \u2208 NN0 (27e) v\nI,I I i|k = Cv x I,I Ii|k \u2200i \u2208 NN0 (27f) \u2212 v\u0304 \u2264 v I,I Ii|k \u2264 v\u0304 \u2200i \u2208 NN0 (27g) \u2212 a\u0304 \u2264 aI,I Ii|k \u2264 a\u0304 \u2200i \u2208 NN\u221210 (27h) pI Ii|k \u2208 Si (k) \u2200i \u2208 NN1 (27i) u I Ii|k = u I Ii\u22121|k \u2200i \u2208 NN\u22121N\u22121\u2212 j (rL ) (27j) pI IN |k \u2208 SN PD (27k)\nwhere all equalities and inequalities are elementwise, the predicted acceleration ai|k pertaining to the exploiting and safe trajectories is defined as aI,I Ii|k = Kvel(Kpos(u I,I Ii|k \u2212 pI,I Ii|k ) \u2212 v I,I Ii|k ), and a\u0304 and v\u0304 are the maximum acceleration and velocity vectors, respectively. Constraints (27c)\u2013(27h) are meant to be applied to both safe and exploit trajectories. The FHOCP (27) is a convex QP that, if feasible, can be solved efficiently for a global minimizer. We denote its solution as U\u2217(x(k), S\u0304(k), pt (k)) = [U I \u2217 T U I I \u2217T]T and the corresponding optimal predicted state trajectories, with all elements stacked in single column vectors, as X I\u2217(x(k), S\u0304(k), pt(k)) \u2208 R6N and X I I\u2217(x(k), S\u0304(k), pt (k)) \u2208 R6N . The optimal control problem results to be divided in two predictions: 1) the trajectory X I , considered in the cost function, pointing to the desired reference and 2) the trajectory X I I , which, instead, satisfies\nAlgorithm 2 Multitrajectory MPC\ntightened state and terminal constraints (27i), (27j), and (27k) ensuring the existence of an obstacle-free trajectory.\nAt any time k, let us denote with l(k) < k the latest sampling instant, such that the FHOCP P(x(l(k)), S\u0304(l(k)), pt (l(k))) was feasible and with m(k) \u2208 [1, N \u2212 1] a counter used inside our algorithm. Then, we propose the following receding horizon strategy.\nSince, for a time-invariant environment, the safe set generated by Algorithm 1 depends only on x(k), the mt-MPC approach results in a dynamic, state-feedback control law with internal states l(k) and m(k) and input pt (k)\nm(k + 1) = \u03b6 (x(k), l(k), m(k)) l(k + 1) = \u03be(x(k), l(k))\nu(k) = \u03ba x(k), l(k), m(k), pt (k) (28) where functions \u03b6 : R6 \u00d7 N \u00d7 N \u2192 N, \u03be : R6 \u00d7 N \u2192 N, and \u03ba : R6 \u00d7 N \u00d7 N \u00d7 R3 \u2192 R3 are implicitly defined by Algorithm 2. The resulting closed-loop system is\nm(k + 1) = \u03b6 (x(k), l(k), m(k)) l(k + 1) = \u03be(x(k), l(k)) x(k + 1) = x k; \u03ba x(k), l(k), m(k), pt (k) . (29)\nIn Algorithm 2, the role of variable l(k) and of the corresponding set S\u0304(l(k)) is to keep track of the last polytopic approximation of the free space that yielded a feasible problem. This is introduced to cope with the time-varying nature of the safe convex set S(k). The role, instead, of variable m(k) is to select, if needed, suitable control inputs in the safe trajectory to guarantee that an input leading to an obstacle-free trajectory can be issued notwithstanding the measurement noise and prediction uncertainty. Such a guarantee holds, however, only\nwhen unknown but static obstacles are considered, as in our problem. In the presence of time-varying obstacles, additional assumptions and different approaches would be required, currently subject of our research.\nThe mt-MPC approach guarantees an obstacle-free trajectory, as shown by the following result.\nLemma 1: Assume that the FHOCP (27) at time k = 0 is feasible and that p(0) /\u2208 O, i.e., the drone is initially in the obstacle-free region. Moreover, assume that for all x(k) and all sequences [u I I T0|k , uI I T1|k , . . . , uI I TN\u22121|k]T , we have that the estimated uncertainty bounds are not violated, i.e., pI I (k + n) \u2208 pI In|k \u2295 \u03c2\u0302 n, \u2200n \u2264 N . Then, the trajectory of the close loop system (29) is such that p(k) /\u2208 O, \u2200k > 0.\nProof: At k = 0, problem P(x(0), S\u0304(0), pt(0)) is solved, m(1) is set to 1, and l(1) is set to 0. For any k \u2265 0, let us denote with U I I\u2217 = [uI I\u2217T0|k , uI I\u2217T1|k , . . . , u I I\u2217TN\u22121|k]T the optimal safe input sequence computed by the mt-MPC algorithm, be it by solving P(x(k), S\u0304(k), pt (k)) or P(x(k), S\u0304(l(k)), pt(k)) (see Algorithm 2), with x I I\u2217j |k the j th element of the safe trajectory and pI I\u2217j |k = Cp x I I\u2217j |k the corresponding position.\nThen, at each k > 0, there are three possibilities. 1) If P(x(k), S\u0304(k), pt (k)) is feasible, then at time k + 1,\nwe have p(k + 1) \u2208 pI I\u22171|k \u2295 \u03c2\u0302 1 \u2208 S(k); see (27d), (27i), and (25). 2) Conversely, if P(x(k), S\u0304(k), pt (k)) is not feasible, but problem P(x(k), S\u0304(l(k)), pt(k)) is feasible, the latter is solved. Thus, in this case, we have p(k +1) \u2208 pI I\u22171|k \u2295 \u03c2\u0302 1 \u2208 S(l(k)). 3) Finally, if both P(x(k), S\u0304(k), pt(k)) and P(x(k), S\u0304(l(k)), pt (k)) are not feasible, we apply the m(k)th element in the tail of the safe optimal input sequence obtained with the last feasible problem P(x(l(k)), S\u0304(l(k)), pt (l(k))), i.e., uI I\u2217m(k)|l(k) .\nSince P(x(l(k)), S\u0304(l(k)), pt(l(k))) satisfies constraint (27i), we have p(k + 1) \u2208 pI I\u2217m(k)+1|l(k) \u2295 \u03c2\u0302m(k)+1 \u2208 S(l(k)), \u2200m(k) \u2264 N \u2212 1. Therefore, we have that, in all cases 1)\u20133), p(k + 1) belongs to a set S( j), with j \u2264 k. Now, by construction (see Algorithm (1)), whenever p( j) /\u2208 O, then the corresponding set S( j) is an under-approximation of the obstacle-free region, i.e., S( j) \u2229 Oi = \u2205, \u2200i = 1, . . . , No, meaning that in all cases 1)\u20133), we have p(k + 1) /\u2208 O. We, thus, demonstrated that p(k) /\u2208 O \u21d2 p(k + 1) /\u2208 O. The result is then proven by induction, considering that p(0) /\u2208 O by assumption. Finally, if case C) is encountered repeatedly, the last feasible safe set point may be applied until the end of the horizon. In this case, the drone state ends up in a positively invariant set because of constraint (27k). Then, p(k) \u2208 SN (l(k)) PD , leading to a new feasible problem P(x(k), S\u0304(l(k)), pt (k)) [case 2)], where constraints (27c)\u2013(27k) are satisfied by the trivial safe trajectory U I I = [uI I\u2217TN\u22121|l(k), . . . , u I I\u2217 T\nN\u22121|l(k)]T by Assumption 2. Remark 5: The FHOCP (27), from an implementation point of view, can be simplified by imposing a terminal equality constraint instead of (27j), imposing that the last step of the safe trajectory is a steady state and, then, artificially extending the horizon by a time interval larger than j(rL ). In this case,\nto take into account the model mismatch, (24) should be modified to include the horizon i = 1, . . . , N + j(rL )."
        },
        {
            "heading": "A. Temporary Target Shifting Strategy",
            "text": "A common problem in optimization-based autonomous navigation without mapping is the possibility that the system is in front of an obstacle that is between the current drone position and the target, as shown in Fig. 6. In such a situation, if no countermeasure is taken, the drone might simply stop at a locally optimal position, because any allowed lateral movement would temporarily imply a growth of distance from the target. To avoid this situation, we propose a strategy named temporary target shifting. Let f t = pt (k) \u2212 p(k) be the vector connecting the drone to the target. When the sensor readings whose angular position is closest to that of direction f t do not detect any obstacle (up to the maximum range rL ), the original target pt (k) is used. Otherwise, a temporary target p\u0302t (k) is chosen as follows. Consider the set of indexes corresponding to the sensor readings reporting the maximum distance\nI(k) = j\u0304 : j\u0304 = arg max i=0,...,M\u22121 \u03c1 i(k) . (30)\nThen, the temporary target is obtained as the sensor reading, among those with index j\u0304 \u2208 I, that is closest to the target\np\u0302t (k) = min j\u0304\u2208I s j\u0304(k) \u2212 f t . (31)\nThis strategy is illustrated in Fig. 6 as well. The temporary target p\u0302t (k) is then held constant until the drone reaches it within a certain tolerance, or until the target direction becomes obstacle-free again, whichever condition happens first. This choice avoids situations where the drone starts moving back and forth behind an obstacle, because the temporary target is periodically switched between the two visible edges. If more than one solution to (31) exists, we take the one with smallest index j\u0304 . This approach yields good results in most cases with bounded obstacles, but still does not guarantee that the target is eventually reached if the obstacles\u2019 shapes are too\ncomplicated. In those cases, a mapping strategy shall be added, to incrementally explore the environment and save information on it until finding the path to the target. Mapping is outside the scope of this work, but can be well combined with our approach."
        },
        {
            "heading": "V. SIMULATION RESULTS",
            "text": "The effectiveness of the proposed approach has been evaluated first via numerical simulations according to the layout reported in Fig. 1. In this case, the nonlinear drone dynamics with the low-level position controller have been simulated with the model described in [39]. The employed system and control parameters are reported in Table I. The QP (27) is solved using MATLAB1 quadprog running on a Quad-Core Intel Core i7 (3.6 GHz, 32 GB) on MATLAB 2020b under MS Windows. Fig. 7 shows the UAV during navigation in a typical simulation test where the convex under-approximation S(k), the \u201csafe\u201d trajectory, and the \u201cexploiting\u201d one can be easily distinguished. The approach exhibits good performance, driving quickly the drone to its target without collisions. On average, in our tests, the numerical solution of the QP (27) required about 45 ms per sampling step and about 0.1 s in addition to run Algorithm 1. As mentioned in Remark 4, the latter can also be safely interrupted if a strict real-time implementation is needed, at the cost of smaller safe set.\nWe compared the mt-MPC approach with a standard MPC, which still employs Algorithms 1 and 2, however, with a single trajectory in the FHOCP, subject to all the operational and safety constraints. We used the same tuning parameters in the cost function for the two approaches (see Table I). In the single-trajectory MPC, the following FHOCP is considered:\nmin U N i=1 || pi|k \u2212 pt (k)||2Q\n1Registered trademark.\ns.t. x0|k = x(k) xi+1|k = Axi|k + Bui|k \u2200i \u2208 NN\u221210 pi|k = Cp xi|k \u2200i \u2208 NN0 vi|k = Cv xi|k \u2200i \u2208 NN0 \u2212v\u0304 \u2264 vi|k \u2264 v\u0304 \u2200i \u2208 NN0 pi|k \u2208 Si (k) \u2200i \u2208 NN0 \u2212a\u0304 \u2264 ai|k \u2264 a\u0304 \u2200i \u2208 NN\u221210 ui|k = ui\u22121|k \u2200i \u2208 NN\u22121N\u22121\u2212 j(rL ) xN |k \u2208 SN PD .\nTo ensure persistent obstacle avoidance, we applied again Algorithm 2. Fig. 8 shows a comparison between the resulting closed-loop trajectories. Both drive the UAV to its target without collisions, however, obtaining different paths. For\na more thorough comparison, we ran a series of Nsim = 1000 problems with randomly generated initial state, obstacles, and target, but all presenting a layout qualitatively similar to that of Fig. 8, i.e., where the drone has to traverse an area with many unknown obstacles. In each test i , we measured the cumulative closed-loop tracking error Ji = Tik=0 || p(k) \u2212 pti ||2. Furthermore, we considered the following average quantity as performance indicator:\nJ\u0304 = 1 Nsim Nsim i=1 Ji .\nFinally, we also compared the computational effort required to solve the FHOCP in the two cases. The obtained results indicate that the mt-MPC improves the average tracking error (\u22127.2%) with respect to the standard MPC technique, however, with a higher computational time [+32% to solve the QP (27)]. The presented results, together with the simulations in a 2-D scenario presented in [31], thus, confirm that the approach has good potential in terms of performance improvement, at the cost of higher computational effort in this application."
        },
        {
            "heading": "VI. EXPERIMENTAL RESULTS",
            "text": "To demonstrate the performance of the presented mt-MPC, we implemented it on an autonomous multicopter drone and carried out experiments out-of-the-laboratory in our test site."
        },
        {
            "heading": "A. Test Site and Prototype Drone",
            "text": "We ran the experiments in an outdoor facility of Politecnico di Milano at Spino d\u2019Adda (45.4\u25e6 N , 9.5\u25e6 E), near Milan, Northern Italy. A view of the site test is shown in Fig. 9(a). We conducted experiments with a DJI S1000+ octocopter, shown in Fig. 9(b). The frame has a diagonal wheelbase of 1045 mm with eight motors that rotate at 400 rpm/V.\nThe drone is equipped with two planar LiDAR SICK T i M5xx series sensors, each one with 270\u25e6 range fused together to obtain a 360\u25e6 field of view. Each sensor has a scanning frequency of 15 Hz, a range of rL = 10 m, and an angular resolution of \u03b1s = 0.33\u25e6. Due to the planar nature of the sensors used, we fixed the reference vertical position to a constant value in the tests. The low-level position controller is provided by a DJI A3 flight control unit equipped with a built-in inertial measurement unit (IMU) featuring a standard GPS compass. We implemented the high-level controller on an Odroid-XU4 embedded system, featuring an octa-core Exynos 5422 big.LITTLE processor running Linux Ubuntu 18 and robot operating system (ROS) Melodic. The flight controller has an ROS interface via the DJI onboard SDK, allowing the Odroid to send reference commands and receiving sensors feedback via ROS to/from the A3 unit."
        },
        {
            "heading": "B. ROS Implementation",
            "text": "An overview of nodes and topics communication through an ROS graph diagram is shown in Fig. 10. The two LiDARs provide to the /s1000_interface node their measurements at a frequency of 15 Hz. The node elaborates the measurements and publishes a message of type\nLaserScan with the merged measurements, together with a PoseStamped message defining the desired final position target. The /temp_target_generator node is in charge of providing the temporary target to the /mt_MPC node following the procedure described in Section IV-A at a frequency of 5 Hz. The node exploits the LiDAR measurements, the final target, and the GPS position of the drone published by the /dji_sdk node at a frequency of 50 Hz. The LiDAR measurements are also exploited by the /polytope_matrices_generation node, where Algorithm 1 is implemented, that publishes the polytope S(k) with a custom message PolytopeMatricesStamped at a frequency of 5 Hz. Finally, the /mt_MPC node receives the target, the free polytope, and the state feedback, and it executes Algorithm 2 and publishes a position reference at a frequency of 3 Hz. The latter is then sent to a /position_controller node that publishes a velocity reference to the /dji_sdk node. The ROS implementation of the approach is available at https://github.com/ DaniloSaccani/mt_MPC."
        },
        {
            "heading": "C. Model Identification and Error Bound Estimation",
            "text": "To test the presented approach, we have collected position step responses in closed loop, recording the position and velocity of the vehicle with a sampling frequency of 100 H z, while the high-level control unit was sending predefined position references to the low-level DJI A3 flight controller. We identified the control-oriented model (8) as described in\nSection III-B. Fig. 11 shows a comparison between the measured p\u0303x f and v\u0303 x f and the estimated model. Then, we exploited the dataset to estimate the worst case prediction error bound \u03c2\u0302 n considering the scaling factors \u03bc = \u03b7 = 1.02. Fig. 12 shows the obtained values of \u03bbn,i (15) and the worst case prediction error bound \u03c4\u0302n,i (19) along x f and y f for an horizon N = 30 in the validation dataset. As it can be noticed, the worst case simulation error bound \u03c4\u0302n,i has a maximum value of about 3 m, which is reasonable considering the GPS noise, the presence of little wind, and the model-plant mismatch. The constant j(rL ), that represents the settling time of the low-level position controller to reach a target placed at a distance rL , can be roughly estimated from the ratio (rL/v\u0304) and in our case is j(rL) = 16. We estimated the set PW from the data by taking the convex hull of the steady-state samples of the tracking error, as shown in Fig. 13\nPW = chull x\u0303(k + j ; \u02dc\u0304u) \u2212 \u02dc\u0304u03\u00d71 .\nAs pointed out in Section II-A, in practice, Assumption 1 is satisfied if the low level controller is properly tuned, and it is able to stabilize the drone\u2019s trajectories and to track the given reference."
        },
        {
            "heading": "D. MPC Implementation",
            "text": "We translated the developed algorithms in Python and integrated them within ROS [40]. To obtain a strictly convex optimization problem, which improves the solution speed and\nnumerical stability, we included in the cost function (22) a term that penalizes the rate of change of the input\nJ x(k), U, pt (k) = N i=1 pIi|k \u2212 pt(k) 2Q + N\u22121 i=0\nu I,I Ii|k 2 R (32)\nwhere R \u2208 R3\u00d73 is a suitable weight matrix for the input variation. To avoid unnecessary conservativeness in the input variation, we have chosen a weight Q much larger than R to prioritize the tracking of the desired target, i.e., Q = 6 \u00b7 I3 and R = 0.5 \u00b7 I3. The set PD has been selected as a polytopic outer-approximation of the ellipsoidal set xT Dx \u2264 \u03b4, where \u03b4 and D have been obtained with the following optimization problem that returns the minimum-volume sublevel set of a Lyapunov function {x \u2208 R6|xT Dx \u2264 \u03b4} containing the convex hull of the steady state error samples (33), as shown at the\nbottom of the next page. Fig. 13 shows the sets PW and E (D) together with the steady state data considered (x\u0303(k + j ; \u02dc\u0304u) \u2212 \u02dc\u0304u\n03\u00d71\n! ), \u2200 j > j(rL), and the evolution of the sim-\nulated tracking error according to the model (8). To assess the belonging of the ellipsoidal set E (D) to the admissible set V according to acceleration and velocity constraints as described in Assumption 2, the following two checks have been performed:\nack < a\u0304, vck < v\u0304\nwhere ack and vck are the solutions of the following two problems, formulated componentwise:\nack = max x(k) |a(k)| s.t. x(k) \u2208 E (D)\nvck = max x(k) |v(k)| s.t. x(k) \u2208 E (D)\nwhere a(k) = Kvel(Kpos(u(k) \u2212 p(k)) \u2212 v(k)) as described in (7).\nRemark 6: Assumption 2 implies the stability of the identified control-oriented model. We checked this condition after the identification procedure, and, as highlighted in (33), we have considered the system\u2019s trajectory starting from steady-state error samples that satisfy the constraints obtained from experimental data.\nAs mentioned in Remark 5, we have replaced the constraint (27j) in the FHOCP (27) with a terminal zero-velocity constraint v I IN |k = 03\u00d71, and we have then artificially extended the horizon N by j(rL ) time steps when needed, to reduce the computational effort required to solve the problem.\nFig. 12 presents a visualization of the prediction horizon and of the uncertainty bounds until the terminal step N + j(rL). The optimization problem (27) has been solved with Operator Splitting Quadratic Program (OSQP) solver [41] in the ROS node of the MPC law. We have properly selected the horizon N and the sampling time Ts in order to obtain a real-time implementation of the algorithm while still capturing the dynamic motion of the drone. In particular, using Ts = 0.3s and N = 8, the average execution times per sampling step of the QP (27) is about 0.1 s, and about 20 ms in addition to run Algorithm 1 with the available 2-D LiDAR. Fig. 14 shows the trajectory obtained with the mt-MPC approach and some of\nmin D,\u03b4\nlog det D\u22121\ns.t. AT D A \u2212 D < 0,\nD > 0 \" x\u0303 k + j ; \u02dc\u0304u \u2212 \u02dc\u0304u\n03\u00d71\n!#T D \" x k + j ; \u02dc\u0304u \u2212 \u02dc\u0304u\n03\u00d71\n!# \u2264 \u03b4 \u2200 j > j(rL) (33)\nthe safe sets at different time steps during the tests. Videos of the experimental setup and mt-MPC trajectories computation are available at https://youtu.be/-_kOhl6AI68.\nFig. 15 shows the boxplots of the execution times during experimental tests. Note that the computation time required to solve Algorithm 1 is drastically smaller in this implementation than in the one required in the simulations presented in Section V, due to the planar nature of the considered exteroceptive sensor."
        },
        {
            "heading": "VII. CONCLUSION",
            "text": "A novel MPC formulation, named mt-MPC, has been presented, where multiple trajectories are considered in the same optimization problem to trade-off conflicting objectives. The approach has been applied to the autonomous navigation of a multicopter drone in a priori unknown environment. An SM approach has been used to estimate the prediction error of a model obtained from measured data. A novel approach to approximate the feasible set with a convex polytope exploiting only real-time measurements of an exteroceptive sensor has been used, together with a strategy to guarantee obstacle avoidance in case of time-invariant environment and considering the computed prediction uncertainty. The obstacle-avoidance property has been theoretically proven and demonstrated experimentally. The experiments and simulation results show that mt-MPC can be implemented in real time on the considered low-cost hardware and safely navigate the system to destination, consistently with our theoretical analysis. Current research is aimed to apply the mt-MPC concept to reconfigurable and/or nonlinear systems, to include additional learning components in the problem, and to consider dynamic obstacles in the environment."
        }
    ],
    "title": "Multitrajectory Model Predictive Control for Safe UAV Navigation in an Unknown Environment",
    "year": 2022
}