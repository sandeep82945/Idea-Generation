{
    "abstractText": "We introduce the ARMORD methods as novel approaches to enhancing the adversarial robustness of deep learning models. These methods are based on a new class of optimal-transport-regularized divergences, constructed via an infimal convolution between an information divergence and an optimal-transport (OT) cost. We use these as tools to enhance adversarial robustness by maximizing the expected loss over a neighborhood of distributions, a technique known as distributionally robust optimization. Viewed as a tool for constructing adversarial samples, our method allows samples to be both transported, according to the OT cost, and re-weighted, according to the information divergence. We demonstrate the effectiveness of our method on malware detection and image recognition applications and find that, to our knowledge, it outperforms existing methods at enhancing the robustness against adversarial attacks. ARMORD yields the robustified accuracy of 98.29% against FGSM and 98.18% against PGD on the MNIST dataset, reducing the error rate by more than 19.7% and 37.2% respectively compared to prior methods. Similarly, in malware detection, a discrete (binary) data domain,ARMORD improves the robustified accuracy under rFGSM attack compared to the previous best-performing adversarial training methods by 37.0% while lowering false negative and false positive rates by 51.1% and 57.53%, respectively.",
    "authors": [
        {
            "affiliations": [],
            "name": "A PREPRINT"
        },
        {
            "affiliations": [],
            "name": "Jeremiah Birrell"
        },
        {
            "affiliations": [],
            "name": "Mohammadreza Ebrahimi"
        }
    ],
    "id": "SP:d6607748439ed97adb5d8ae61fa4d5e9ddb1553f",
    "references": [
        {
            "authors": [
                "A. Ahmadi-Javid"
            ],
            "title": "Entropic value-at-risk: A new coherent risk measure",
            "venue": "Journal of Optimization Theory and Applications,",
            "year": 2012
        },
        {
            "authors": [
                "Abdullah Al-Dujaili",
                "Alex Huang",
                "Erik Hemberg",
                "Una-May O\u2019Reilly"
            ],
            "title": "Adversarial deep learning for robust detection of binary encoded malware",
            "venue": "IEEE Security and Privacy Workshops (SPW),",
            "year": 2018
        },
        {
            "authors": [
                "Anish Athalye",
                "Nicholas Carlini",
                "David Wagner"
            ],
            "title": "Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples",
            "venue": "In International conference on machine learning,",
            "year": 2018
        },
        {
            "authors": [
                "Sina Baharlouei",
                "Fatemeh Sheikholeslami",
                "Meisam Razaviyayn",
                "Zico Kolter"
            ],
            "title": "Improving adversarial robustness via joint classification and multiple explicit detection classes",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2023
        },
        {
            "authors": [
                "Aharon Ben-Tal",
                "Marc Teboulle"
            ],
            "title": "An old-new concept of convex risk measures: The optimized certainty equivalent",
            "venue": "Mathematical Finance,",
            "year": 2007
        },
        {
            "authors": [
                "Aharon Ben-Tal",
                "Dimitris Bertsimas",
                "David B. Brown"
            ],
            "title": "A soft robust model for optimization under ambiguity",
            "venue": "Operations Research,",
            "year": 2010
        },
        {
            "authors": [
                "Aharon Ben-Tal",
                "Dick den Hertog",
                "Anja De Waegenaere",
                "Bertrand Melenberg",
                "Gijs Rennen"
            ],
            "title": "Robust solutions of optimization problems affected by uncertain probabilities",
            "venue": "Management Science,",
            "year": 2013
        },
        {
            "authors": [
                "Jeremiah Birrell",
                "Paul Dupuis",
                "Markos A. Katsoulakis",
                "Yannis Pantazis",
                "Luc Rey-Bellet"
            ],
            "title": "f,\u0393)-Divergences: Interpolating between f-divergences and integral probability metrics",
            "venue": "Journal of Machine Learning Research,",
            "year": 2022
        },
        {
            "authors": [
                "Jeremiah Birrell",
                "Yannis Pantazis",
                "Paul Dupuis",
                "Luc Rey-Bellet",
                "Markos Katsoulakis"
            ],
            "title": "Function-space regularized R\u00e9nyi divergences",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Jose Blanchet",
                "Karthyek Murthy"
            ],
            "title": "Quantifying distributional model risk via optimal transport",
            "venue": "Mathematics of Operations Research,",
            "year": 2019
        },
        {
            "authors": [
                "Jose Blanchet",
                "Daniel Kuhn",
                "Jiajin Li",
                "Bahar Taskesen"
            ],
            "title": "Unifying Distributionally Robust Optimization via Optimal Transport Theory",
            "venue": "arXiv e-prints, art",
            "year": 2023
        },
        {
            "authors": [
                "V.I. Bogachev"
            ],
            "title": "Weak Convergence of Measures. Mathematical Surveys and Monographs",
            "venue": "American Mathematical Society,",
            "year": 2018
        },
        {
            "authors": [
                "Michel Broniatowski",
                "Amor Keziou"
            ],
            "title": "Minimization of divergences on sets of signed measures",
            "venue": "Studia Scientiarum Mathematicarum Hungarica,",
            "year": 2006
        },
        {
            "authors": [
                "Nicholas Carlini",
                "Anish Athalye",
                "Nicolas Papernot",
                "Wieland Brendel",
                "Jonas Rauber",
                "Dimitris Tsipras",
                "Ian Goodfellow",
                "Aleksander Madry",
                "Alexey Kurakin"
            ],
            "title": "On evaluating adversarial robustness",
            "year": 1902
        },
        {
            "authors": [
                "D.L. Cohn"
            ],
            "title": "Measure Theory. Birkh\u00e4user Boston, 2013. ISBN 9781489903990",
            "venue": "URL https://books.google.com/ books?id=rgXyBwAAQBAJ",
            "year": 2013
        },
        {
            "authors": [
                "Erick Delage",
                "Yinyu Ye"
            ],
            "title": "Distributionally robust optimization under moment uncertainty with application to data-driven problems",
            "venue": "Operations Research,",
            "year": 2010
        },
        {
            "authors": [
                "Dupuis",
                "Paul",
                "Mao",
                "Yixiang"
            ],
            "title": "Formulation and properties of a divergence used to compare probability measures without absolute continuity",
            "venue": "ESAIM: COCV,",
            "year": 2022
        },
        {
            "authors": [
                "G.B. Folland"
            ],
            "title": "Real Analysis: Modern Techniques and Their Applications. Pure and Applied Mathematics: A Wiley Series of Texts, Monographs and Tracts",
            "venue": "URL https://books.google.com/ books?id=wI4fAwAAQBAJ",
            "year": 2013
        },
        {
            "authors": [
                "Rui Gao",
                "Anton Kleywegt"
            ],
            "title": "Distributionally robust stochastic optimization with Wasserstein distance",
            "venue": "Mathematics of Operations Research,",
            "year": 2023
        },
        {
            "authors": [
                "Joel Goh",
                "Melvyn Sim"
            ],
            "title": "Distributionally robust optimization and its tractable approximations",
            "venue": "Operations Research,",
            "year": 2010
        },
        {
            "authors": [
                "Ian Goodfellow"
            ],
            "title": "Gradient masking causes CLEVER to overestimate adversarial perturbation size",
            "venue": "arXiv preprint arXiv:1804.07870,",
            "year": 2018
        },
        {
            "authors": [
                "Ian J Goodfellow",
                "Jonathon Shlens",
                "Christian Szegedy"
            ],
            "title": "Explaining and harnessing adversarial examples",
            "venue": "arXiv preprint arXiv:1412.6572,",
            "year": 2014
        },
        {
            "authors": [
                "Kathrin Grosse",
                "Nicolas Papernot",
                "Praveen Manoharan",
                "Michael Backes",
                "Patrick McDaniel"
            ],
            "title": "Adversarial examples for malware detection",
            "venue": "In Computer Security\u2013ESORICS 2017: 22nd European Symposium on Research in Computer Security, Oslo, Norway,",
            "year": 2017
        },
        {
            "authors": [
                "Zhaolin Hu",
                "L Jeff Hong"
            ],
            "title": "Kullback-Leibler divergence constrained distributionally robust optimization",
            "venue": "Available at Optimization Online,",
            "year": 2013
        },
        {
            "authors": [
                "Zico Kolter",
                "Aleksander Madry"
            ],
            "title": "Towards deep learning models resistant to adversarial attacks",
            "venue": "In Adversarial Robustness - Theory and Practice,",
            "year": 2018
        },
        {
            "authors": [
                "Henry Lam"
            ],
            "title": "Recovering best statistical guarantees via the empirical divergence-based distributionally robust optimization",
            "venue": "Operations Research,",
            "year": 2019
        },
        {
            "authors": [
                "F. Liese",
                "I. Vajda"
            ],
            "title": "On divergences and informations in statistics and information theory",
            "venue": "IEEE Transactions on Information Theory,",
            "year": 2006
        },
        {
            "authors": [
                "Aleksander Madry",
                "Aleksandar Makelov",
                "Ludwig Schmidt",
                "Dimitris Tsipras",
                "Adrian Vladu"
            ],
            "title": "Towards deep learning models resistant to adversarial attacks",
            "venue": "In International Conference on Learning Representations,",
            "year": 2018
        },
        {
            "authors": [
                "Peyman Mohajerin Esfahani",
                "Daniel Kuhn"
            ],
            "title": "Data-driven distributionally robust optimization using the Wasserstein metric: performance guarantees and tractable reformulation",
            "venue": "Mathematical Programming,",
            "year": 2018
        },
        {
            "authors": [
                "Nagarajan Natarajan",
                "Inderjit S. Dhillon",
                "Pradeep Ravikumar",
                "Ambuj Tewari"
            ],
            "title": "Learning with noisy labels",
            "venue": "In NIPS,",
            "year": 2013
        },
        {
            "authors": [
                "X. Nguyen",
                "M.J. Wainwright",
                "M.I. Jordan"
            ],
            "title": "Estimating divergence functionals and the likelihood ratio by convex risk minimization",
            "venue": "IEEE Transactions on Information Theory,",
            "year": 2010
        },
        {
            "authors": [
                "Nicolas Papernot",
                "Patrick McDaniel",
                "Somesh Jha",
                "Matt Fredrikson",
                "Z Berkay Celik",
                "Ananthram Swami"
            ],
            "title": "The limitations of deep learning in adversarial settings",
            "venue": "IEEE European symposium on security and privacy (EuroS&P),",
            "year": 2016
        },
        {
            "authors": [
                "Nicolas Papernot",
                "Patrick McDaniel",
                "Ian Goodfellow",
                "Somesh Jha",
                "Z Berkay Celik",
                "Ananthram Swami"
            ],
            "title": "Practical black-box attacks against machine learning",
            "venue": "In Proceedings of the 2017 ACM on Asia conference on computer and communications security,",
            "year": 2017
        },
        {
            "authors": [
                "J.P. Ponstein"
            ],
            "title": "Approaches to the Theory of Optimization",
            "venue": "URL https://books.google.com/books?id=GaNB2B677wgC",
            "year": 2004
        },
        {
            "authors": [
                "Aditi Raghunathan",
                "Jacob Steinhardt",
                "Percy Liang"
            ],
            "title": "Certified defenses against adversarial examples",
            "venue": "In International Conference on Learning Representations,",
            "year": 2018
        },
        {
            "authors": [
                "Hamed Rahimian",
                "Sanjay Mehrotra"
            ],
            "title": "Frameworks and results in distributionally robust optimization",
            "venue": "Open Journal of Mathematical Optimization,",
            "year": 2022
        },
        {
            "authors": [
                "Soroosh Shafieezadeh-Abadeh",
                "Daniel Kuhn",
                "Peyman Mohajerin Esfahani"
            ],
            "title": "Regularization via mass transportation",
            "venue": "Journal of Machine Learning Research,",
            "year": 2019
        },
        {
            "authors": [
                "Matthew Staib",
                "Stefanie Jegelka"
            ],
            "title": "Distributionally robust optimization and generalization in kernel methods",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "C. Villani"
            ],
            "title": "Optimal Transport: Old and New. Grundlehren der mathematischen Wissenschaften",
            "venue": "URL https://books.google.com/books?id=hV8o5R7_5tkC",
            "year": 2008
        },
        {
            "authors": [
                "Yisen Wang",
                "Difan Zou",
                "Jinfeng Yi",
                "James Bailey",
                "Xingjun Ma",
                "Quanquan Gu"
            ],
            "title": "Improving adversarial robustness requires revisiting misclassified examples",
            "venue": "In International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Wolfram Wiesemann",
                "Daniel Kuhn",
                "Melvyn Sim"
            ],
            "title": "Distributionally robust convex optimization",
            "venue": "Operations Research,",
            "year": 2014
        },
        {
            "authors": [
                "Qinyu Wu",
                "Jonathan Yu-Meng Li",
                "Tiantian Mao"
            ],
            "title": "On Generalization and Regularization via Wasserstein Distributionally Robust Optimization",
            "venue": "arXiv e-prints, art",
            "year": 2022
        },
        {
            "authors": [
                "Jonathan Yu-Meng Li",
                "Tiantian Mao"
            ],
            "title": "A General Wasserstein Framework for Data-driven Distributionally Robust Optimization: Tractability and Applications",
            "venue": "arXiv e-prints, art",
            "year": 2022
        },
        {
            "authors": [
                "Hongyang Zhang",
                "Yaodong Yu",
                "Jiantao Jiao",
                "Eric Xing",
                "Laurent El Ghaoui",
                "Michael Jordan"
            ],
            "title": "Theoretically principled trade-off between robustness and accuracy",
            "venue": "In International conference on machine learning,",
            "year": 2019
        },
        {
            "authors": [
                "Luhao Zhang",
                "Jincheng Yang",
                "Rui Gao"
            ],
            "title": "A simple and general duality proof for Wasserstein distributionally robust optimization",
            "venue": "arXiv e-prints, art",
            "year": 2022
        },
        {
            "authors": [
                "Nguyen"
            ],
            "title": "Here we prove a number of key properties of the OT-regularized divergences",
            "venue": "Broniatowski",
            "year": 2010
        },
        {
            "authors": [
                "Birrell"
            ],
            "title": "divergencesDf (\u00b7\u2225\u03bc) are LSC and have compact sublevel sets",
            "year": 2022
        },
        {
            "authors": [
                "Birrell"
            ],
            "title": "\u03b51A. Then \u03c6\u03b5 \u2208Mb(\u03a9), hence the variational representation of f -divergences",
            "year": 2022
        },
        {
            "authors": [
                "Following Kolter",
                "Madry"
            ],
            "title": "2018), the image detector is a 4-layer CNN with 32",
            "year": 2018
        },
        {
            "authors": [
                "Al-Dujaili"
            ],
            "title": "In experiments with adversarial labels, i.e., ARMOR\u03b1 (advs,l) and ARMOR\u03b1 (advs,l + nat), the step size for learning \u1ef9 was the same as for x\u0303 in all cases (i.e., 0.01 for MNIST and 0.02 for malware). C.4.1 Hyperparameters in Image Experiments for Enhancing Adversarial Robustness: Table 1 \u2022 ARMORKL (advs): \u03b5 = 5e\u2212 4, L = 1e\u2212 1, q = 1.5, lr\u03bb = 2e\u2212 4, and l2",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "Keywords adversarial robustness, deep learning, information divergence, optimal transport, distributionally robust optimization"
        },
        {
            "heading": "1 Introduction",
            "text": "Machine learning and specifically deep learning models are known to be vulnerable to adversarial samples: inputs intentionally and meticulously modified by an adversary to evade/mislead the classification model (Papernot et al., 2016; Goodfellow et al., 2014). One common and effective way to enhance a model\u2019s robustness against this vulnerability is to include adversarial samples during the training process, known as adversarial training. However, adversarial training is often challenging, as it is hard to maintain the model\u2019s performance generalizability while also enhancing its adversarial robustness (Carlini et al., 2019; Zhang et al., 2019); improvements in one goal can negatively affect the other. To date, a large body of prominent defense mechanisms for enhancing adversarial robustness can be classified into two main categories: (1) certifiable approaches Baharlouei et al. (2023); Raghunathan et al. (2018) that can guarantee the absence of adversarial examples misclassified by the model for a specific input, (2) adversarial training with gradient masking (Papernot et al., 2017), robust optimization (Madry et al., 2018), and regularization (Zhang et al., 2019). Despite attractive guarantees, the former category often operates on a convex relaxation of the original model rather than the original model and tend to have inferior performance compared to approaches in the latter category (Wang et al., 2020;\n\u2217Correspondence to ebrahimim@usf.edu\nar X\niv :2\n30 9.\n03 79\n1v 1\n[ cs\n.L G\n] 7\nAthalye et al., 2018). Within the second category, the gradient masking approaches have been shown to be prone to giving a false sense of robustness (Athalye et al., 2018; Goodfellow, 2018).\nIn the robust optimization approach, the loss function L\u03b8, depending on parameters \u03b8 \u2208 \u0398, is maximized over a metric-space ball centered at the training samples xi, leading to the optimization problem\ninf \u03b8 EPn\n[ sup\ny:d(x,y)\u2264\u03f5 L\u03b8(y)\n] , (1)\nwhere Pn = 1n \u2211n i=1 \u03b4xi is the empirical distribution; see Madry et al. (2018). In this paper we propose a new adversarial robustness method that is a generalization of the robust optimization approach, using tools from distributionally robust optimization (DRO). In DRO a stochastic optimization problem\ninf \u03b8 EP [L\u03b8] (2)\nis regularized by maximizing over a neighborhood of distributions, U(P ), around the baseline distribution P , leading to the DRO problem\ninf \u03b8 sup Q\u2208U(P )\nEQ[L\u03b8] . (3)\nThis formalizes an uncertainty in the underlying distribution P and can protect against overfitting, leading to better out-of-sample performance; see Rahimian & Mehrotra (2022) for an overview of DRO. For general distribution neighborhoods (3) is an intractable infinite dimensional problem but if U has the appropriate structure then one can derive tractable finite dimensional reformulations of the DRO problem. Prior DRO approaches employ various types of distribution neighborhoods, such as moment constraints Goh & Sim (2010); Delage & Ye (2010); Wiesemann et al. (2014), Kullback-Leibler (KL) and f -divergence neighborhoods Ben-Tal et al. (2010); Ahmadi-Javid (2012); Hu & Hong (2013); Ben-Tal et al. (2013); Lam (2019), MMD Staib & Jegelka (2019), Wasserstein neighborhoods Mohajerin Esfahani & Kuhn (2018); Shafieezadeh-Abadeh et al. (2019); Wu et al. (2022); Yu-Meng Li & Mao (2022); Gao & Kleywegt (2023), and more general optimal-transport (OT) neighborhoods Blanchet & Murthy (2019).\nIn this work we propose a novel class of divergences for comparing probability distributions, which we call the optimal-transport-regularized divergences, and use these to construct distribution neighborhoods for use in DRO (6). We demonstrate their effectiveness in adversarial training, where our method can be viewed as a combination of robust optimization and regularization, as well as in improving performance generalizability. While preparing this work a new approach to generalizing OT-DRO via the use of conditional moment constraints was proposed in Blanchet et al. (2023); this approach reduces to special cases of our framework, the finite-dimensional f -divergence and KL reformulations (see Theorem A.21 and Eq. 15-16 below) under appropriate assumptions (see their Theorems 4.1, 5.1, and Proposition 5.1). Here we prove a number of new properties of the OT-regularized divergences (see Section 2.1) and our focus is on demonstrating the effectiveness of the OT-regularized divergence method as a novel approach to enhancing adversarial robustness in deep-learning, where we find it leads to substantial performance gains.\nOptimal-Transport-Regularized Divergences: The new divergences that we introduce in this work are defined as an infimal convolution between an optimal transport cost, C, and an information divergence, D, e.g., an f -divergence, D = Df Liese & Vajda (2006), of which the KL-divergence is one example. More precisely, given an optimal transport cost function c(x, y) and an information divergence, D, we define the OT-regularized divergence, Dc, of a distribution Q with respect to a distribution P by\nDc(Q\u2225P ) := inf \u03b7\u2208P(X ) {D(\u03b7\u2225P ) + C(\u03b7,Q)} , (4)\nwhere P(X ) denotes the set of probability distributions on the space X and the optimal transport cost associated with the cost function c is given by\nC(\u00b5, \u03bd) := inf \u03c0:\u03c01=\u00b5,\u03c02=\u03bd\n\u222b c(x, y)\u03c0(dxdy) (5)\n(\u03c0i denote the marginals of \u03c0 \u2208 P(X \u00d7X )). Intuitively, one can view (4) as specifying a cost via a two-step procedure for transforming P into Q. First, one redistributes the probability-mass in P to form an intermediate distribution \u03b7, paying the cost D(\u03b7\u2225P ) (we say redistribute because we focus on D that are information divergences, meaning they are computable in terms of the likelihood ratio d\u03b7/dP , though most of our theorems in Appendix A apply more generally). Second, one performs optimal transport to transform \u03b7 into Q, paying the cost C(\u03b7,Q). The optimal intermediate measure \u03b7\u2217 determines the final cost Dc(Q\u2225P ). The infimal convolution structure, including the bound Dc(Q\u2225P ) \u2264 min{D(Q\u2225P ), C(P,Q)}, causes Dc to inherit properties from both D and C and allows it to interpolate\nbetween these two extremes; see Section 2.1. The ability to handle both transport and redistribution is also a feature of the newly proposed DRO framework in Blanchet et al. (2023). Note that we don\u2019t assume that c(x, y) = dq(x, y) for some metric d and power q. This cost-function generality will be important in the applications studied in Section 3. The OT-regularized divergences are related to the \u0393-divergences defined in Dupuis, Paul & Mao, Yixiang (2022), (f,\u0393)-divergences defined in Birrell et al. (2022) and the IC-\u0393-R\u00e9nyi divergences from Birrell et al. (2023), but here we utilize optimal transport costs as opposed to integral-probability-metric (IPM) regularization of information divergences. We found that OT-regularization is more naturally suited to adversarial robustness methods than IPM regularization in general. Also, those prior works focused on the equality of the primal and dual formulas for the divergence, which facilitates applications to GANs; here we focus on adversarial robustness, which requires different techniques.\nWe use the OT-regularized divergences to define distribution neighborhoods with neighborhood size \u03f5 > 0, leading to the DRO problem\ninf \u03b8 sup Q:Dc(Q\u2225Pn)\u2264\u03f5\nEQ[L\u03b8] . (6)\nThe OT-regularized-divergence neighborhoods are qualitatively different from both f -divergence and Wasserstein neighborhoods, as they allow for a combination of probability-mass transport and redistribution when forming the perturbed distributions, Q. This allows for the support of Q to be strictly larger than that of Pn (as in Wasserstein DRO) and also for the probability of widely separated modes to be re-weighted, something that is not possible with Wasserstein neighborhoods. When used as a tool for enhancing adversarial robustness, we call (6) the ARMORD methods, standing for Adversarially Robust Deep Learning Models with Optimal-Transport-Regularized Divergences.\nIn Section 2 we show how (6) can be converted into a computationally tractable form as well as list a number of properties of the OT-regularized divergences, thus demonstrating that they are well-behaved mathematical objects; precise statements and proofs are found in Appendix A. In Section 3 we test the ARMORD methods on a pair of adversarial robustness problems, applying it to MNIST digit and malware classification. We find the proposed method outperforms existing adversarial training methods, e.g., it obtains the robustified accuracy of 98.29% against FGSM and 98.18% against PGD40 on the MNIST dataset, reducing the error rate by more than 19.7% and 37.2% respectively compared to prior methods. In malware detection, ARMORD improves the robustified accuracy under rFGSM50 attack compared to the previous best-performing adversarial training methods by 37.0% while lowering false negative and false positive rates by 51.1% and 57.53%, respectively."
        },
        {
            "heading": "2 OT-Regularized Divergences: DRO Identity and Properties",
            "text": "In general, the DRO problem (6) is an intractable infinite dimensional optimization problem. However, for appropriate choices of D one can derive a finite dimensional reformulation that leads to computationally efficient implementations. In this section we provide a formal derivation of the key identity. For a rigorous proof, and statement of the required assumptions, see Appendix A.2.\nNoting that C is jointly convex and assuming that D is convex in its first argument (as is the case when D is an f -divergence) one can see from (4) that Dc is convex in its first argument. Therefore the DRO problem is a convex optimization problem and one can compute\nsup Q:Dc(Q\u2225Pn)\u2264\u03f5\nEQ[L\u03b8] (7)\n= inf \u03bb>0 {\u03bb\u03f5+ sup Q\u2208P(X ) {EQ[L\u03b8]\u2212 \u03bbDc(Q\u2225Pn)}} (8)\n= inf \u03bb>0 {\u03bb\u03f5+ sup Q,\u03b7\u2208P(X ) {EQ[L\u03b8]\u2212 \u03bbD(\u03b7\u2225Pn)\u2212 \u03bbC(\u03b7,Q)}} (9)\n= inf \u03bb>0 {\u03bb\u03f5+ sup \u03b7\u2208P(X ) {\u2212\u03bbD(\u03b7\u2225Pn) + sup Q\u2208P(X ) sup \u03c0:\u03c01=\u03b7,\u03c02=Q {EQ[L\u03b8]\u2212 \u03bb\n\u222b cd\u03c0}}} (10)\n= inf \u03bb>0 {\u03bb\u03f5+ \u03bb sup \u03b7\u2208P(X ) {\u2212D(\u03b7\u2225Pn) + sup\n\u03c0x(dy)\n\u222b \u222b L\u03b8(y)/\u03bb\u2212 c(x, y)\u03c0x(dy)\u03b7(dx)}} (11)\n= inf \u03bb>0 {\u03f5\u03bb+ \u03bb sup \u03b7\u2208P(X ) { \u222b sup y\u2208X {\u03bb\u22121L\u03b8(y)\u2212 c(x, y)}\u03b7(dx)\u2212D(\u03b7\u2225Pn)}} . (12)\nThe equality (8) is obtained using strong duality, lines (9) and (10) are obtained using the definitions (4) and (5) of Dc and C along with properties of suprema and infima, (11) recognizes that the suprema over Q and \u03c0 can be rewritten as a supremum over probability kernels \u03c0x(dy), and finally (12) uses the fact that the supremum over\nprobability kernels achieves the pointwise supremum of the integrand. To this point, the derivation closely follows that of Mohajerin Esfahani & Kuhn (2018) for Wasserstein DRO. Note that effect of the OT cost is to replace the loss L\u03b8 with what we call the OT-regularized loss\nLc\u03b8,\u03bb(x) := sup y\u2208X {\u03bb\u22121L\u03b8(y)\u2212 c(x, y)} , (13)\nwhich is known as the c-transform in the optimal transport literature; see Definition 5.2 in Villani (2008). The importance of the c-transformed loss for Wasserstein DRO is well known; see the references to prior work on Wasserstein and OT-DRO in the introduction. The supremum over y \u2208 X in (13) can be thought of as selecting an adversarial sample that is paired with each real sample, x; we will return to this adversarial perspective in Section 3. The coefficient \u03bb can be thought of as a dynamical penalty weight, selected according to the optimization (12), which is tied to the neighborhood size \u03f5; this perspective is most apparent in (8).\nThe new ingredient in our OT-regularized-divergence DRO framework is the optimization over \u03b7 in (12). This can be recognized as the convex-conjugate of \u03b7 7\u2192 D(\u03b7\u2225Pn) and for certain choices of D, in particular for the f -divergences which we now focus on, this term can be reformulated as a finite dimensional convex optimization problem. Using the generalization of the Gibbs variational principle to f -divergences, see Theorem 4.2 in Ben-Tal & Teboulle (2007), one has\nsup \u03b7\u2208P(X ) {E\u03b7[g]\u2212Df (\u03b7\u2225P )} = inf \u03c1\u2208R {\u03c1+ EP [f\u2217(g \u2212 \u03c1)]} , (14)\nwhere f\u2217 is the Legendre transform of f . Using this we obtain the following finite-dimensional reformulation of the DRO problem\ninf \u03b8\u2208\u0398 sup Q:Dcf (Q\u2225Pn)\u2264\u03f5 EQ[L\u03b8] = inf \u03bb>0,\u03c1\u2208R,\u03b8\u2208\u0398\n{ \u03f5\u03bb+ \u03c1+ \u03bb 1\nn n\u2211 i=1 f\u2217(Lc\u03b8,\u03bb(xi)\u2212 \u03c1/\u03bb)\n} . (15)\nHere we made the change of variables \u03c1\u2192 \u03c1/\u03bb so that the objective function is jointly convex in \u03bb, \u03c1 (see Corollary A.22). Note that the new variables \u03bb, \u03c1 simply augment the minimization over model parameters \u03b8 by adding two real variables. In Section 3 we will experiment with the KL divergence and the family of \u03b1-divergences. An explicit formula for f\u2217 in the case of \u03b1-divergences is given in (29). In the KL-divergence case the minimization over \u03c1 can be evaluated analytically, yielding\ninf \u03b8\u2208\u0398 sup Q:KLc(Q\u2225Pn)\u2264\u03f5 EQ[L\u03b8] = inf \u03bb>0,\u03b8\u2208\u0398\n{ \u03f5\u03bb+ \u03bb log ( 1\nn n\u2211 i=1 exp(Lc\u03b8,\u03bb(xi))\n)} . (16)\nWe will refer to either of (15) or (16) as the outer minimization problem and will call (13) the inner maximization problem. Stripping away the minimization over model parameters \u03b8, the outer minimizer can be viewed as computing the optimal adversarial re-weighting of the samples (i.e., the probability-mass redistribution step). This is a complement to the inner maximizer, which constructs the optimally transported adversarial samples. See Appendix B for further details on this perspective.\nRelation to Adversarial Training: The robust-optimization adversarial training method (1) is a special case of OT-DRO. This can be seen by using the optimal-transport cost function c\u03f5(x, y) :=\u221e1d(x,y)>\u03f5 and letting D(\u00b5\u2225\u03bd) =\u221e1\u00b5\u0338=\u03bd in (12) (so that Dc\u03f5 = C\u03f5, the OT cost) which, after simplifying, results in the identity\ninf \u03b8\n1\nn n\u2211 i=1 sup d(xi,y)\u2264\u03f5 L\u03b8(y) = inf \u03b8 sup Q:C\u03f5(Q,Pn)\u2264\u03f5 EQ[L\u03b8] . (17)\nThe ARMORD methods are therefore a generalization of both (1) and OT-DRO to other distribution neighborhoods which have qualitatively different structure. Furthermore, depending on the choice of OT cost function, DRO with OT-regularized divergences places a greater robustness requirement on the solution in the sense that {Q : C\u03f5(Q,Pn) \u2264 \u03f5} \u2282 {Q : Dd(Q\u2225P ) \u2264 \u03f5}, where the cost function on the right-hand side is c(x, y) = d(x, y). This implies that the more general OT-regularized-divergence distribution neighborhoods can provide qualitatively new types of robustness (i.e., beyond the shifting of samples within an allowed neighborhood), such as miss-specification of the mass of widely-separated modes. The latter feature contributes non-trivially to the performance of the ARMORD methods (see Appendix C.7). Our methods also allow for the use of general cost functions, beyond the choices c = c\u03f5 or c = dq for some power q. This freedom is also a key ingredient in the effectiveness of the ARMORD methods, as we demonstrate in Section 3."
        },
        {
            "heading": "2.1 Properties of the OT-Regularized Divergences",
            "text": "The OT-regularized divergences have many attractive mathematical properties, making them well suited to DRO as well as other statistical learning tasks. We summarize a number of these properties here; see Appendix A for precise statements of the required assumptions along with proofs. Given appropriate assumptions on D and c one has the following:\n1. Dc(\u03bd\u2225\u00b5) \u2265 0 and Dc(\u03bd\u2225\u00b5) = 0 if and only if \u03bd = \u00b5; see Theorem A.7. This divergence property implies that Dc(\u03bd\u2225\u00b5) can be interpreted as measuring the discrepancy between \u03bd and \u00b5.\n2. There exists an optimal intermediate distribution that solves the minimization problem in the definition (4), i.e., there exists \u03b7\u2217 such that\nDc(\u03bd\u2225\u00b5) = D(\u03b7\u2217\u2225\u00b5) + C(\u03b7\u2217, \u03bd) (18)\nand this \u03b7\u2217 is unique under appropriate assumptions. See Theorem A.9. 3. Dc(\u03bd\u2225\u00b5) is convex in \u03bd (see Lemma A.4). This implies that the DRO neighborhoods {Q : Dc(Q\u2225Pn) \u2264 \u03f5}\nare convex sets and is also key in the derivation of the DRO identity (12). 4. Dc(\u03bd\u2225\u00b5) is lower semicontinuous in \u03bd (see Theorem A.11). This property is useful for theoretical purposes\nand it implies that the DRO neighborhoods {Q : Dc(Q\u2225Pn) \u2264 \u03f5} are closed sets. 5. Dc interpolates between D and C in the following sense: For r > 0 define the scaled cost function cr = rc.\nThen\nlim r\u21920+\nr\u22121Dcr (\u03bd\u2225\u00b5) = C(\u00b5, \u03bd) (see Theorem A.12) (19)\nand\nlim r\u2192\u221e\nDcr (\u03bd\u2225\u00b5) = D(\u03bd\u2225\u00b5) (see Theorem A.13). (20)\nInformally, this property implies that DRO over both D and C neighborhoods can be viewed as special cases of DRO over Dc neighborhoods. More specifically, (19) indicates that when r is sufficiently small, DRO over the neighborhood {Q : Dcr (Q\u2225Pn) \u2264 r\u03f5} is approximately the same as DRO over the neighborhood {Q : C(Pn, Q) \u2264 \u03f5}. Similarly, (20) indicates that when r is sufficiently large, DRO over the neighborhood {Q : Dcr (Q\u2225Pn) \u2264 \u03f5} is approximately the same as DRO over the neighborhood {Q : D(Q\u2225Pn) \u2264 \u03f5} (see Theorems A.23 and A.24 for precise statements). Therefore if one includes the scale factor r and neighborhood size \u03f5 as tunable hyperparameters (as we do in the experiments in Section 3) then the special cases of C and D neighborhoods will be (approximately) explored in the process of tuning an ARMORD method.\nWe note that these properties do not require the distributions to have compact support, except for the DRO interpolation results in Theorems A.23 and A.24."
        },
        {
            "heading": "3 Experiments",
            "text": "In this section we test the ARMORD adversarial robustness methods on two classification problems: MNIST digit classification and malware detection, featuring continuous and discrete data, respectively. Specifically, we use the OT-regularized \u03b1-divergence method (15), denoted ARMOR\u03b1, and the OT-regularized KL-divergence method (16), denoted ARMORKL. Before presenting the results of these experiments we introduce the OT cost functions and OT-regularized losses that will be used and give further details on the experimental setup and benchmarks.\nRobust Classification Using Adversarial Samples: First consider optimal transport cost functions of the form\nc((x, y), (x\u0303, y\u0303)) = L\u2225x\u2212 x\u0303\u2225q +\u221e1y \u0338=y\u0303 (21)\non the spaceX = D\u00d7{0, ..., Nc\u22121} (i.e., samples inD \u2282 Rd with label fromNc classes). This applies a q-Wasserstein cost on the first component (sample) but infinite cost on changing the second component (label). The hyperparameter L > 0 allows one to choose how much weight is placed on the OT cost, as compared to the information divergence cost in Dc. The OT-regularized loss is then\nLc\u03b8,\u03bb(x, y) = sup x\u0303\u2208D {\u03bb\u22121L\u03b8(x\u0303, y)\u2212 L\u2225x\u2212 x\u0303\u2225q} , (22)\nand corresponds to the construction of a new sample, x\u0303, adversarial to the original sample x but keeping the original label y. We consider the choice of vector norm to be a hyperparameter, selected from \u2113p, p \u2208 [1,\u221e], and use the\ncross-entropy loss, L\u03b8(x\u0303, y) = CE(\u03d5\u03b8(x\u0303), y) where \u03d5\u03b8 is the neural network (NN) classifier with NN-parameters \u03b8. The adversarial loss (22) can then be used in either of the outer minimizers (15) or (16) (or, more generally, Eq. 12 for some other D, provided one can compute its convex conjugate) to obtain an ARMORD method. We use the notation advs to denote methods that employ adversarial samples constructed via (22).\nRobust Classification Using Adversarial Class Labels and Adversarial Samples: We will also utilize OT cost functions that allow the class labels to be perturbed in the inner maximizer. To do this we consider the sample space to be X = D \u00d7P({0, ..., Nc \u2212 1}) where P({0, ..., Nc \u2212 1}) is the space of probability vectors on the set of labels, with the original class labels mapped to the corresponding one-hot vectors. We relax the term\u221e1y \u0338=y\u0303 in (21) to allow for the perturbation of class labels. Allowing for too much label uncertainly will destroy any predictive ability of the classifier, as is also the case with adversarial perturbation of samples, but we find that a small amount improves robustness. To this end, we consider OT cost functions of the form\nc((x, p), (x\u0303, p\u0303)) = L\u2225x\u2212 x\u0303\u2225q +Kg\u03b4(OT (p, p\u0303)) , (23) where OT is the optimal transport cost (with cost function 1i \u0338=j) between the probability vectors p and p\u0303, i.e., OT (p, p\u0303) = 1 \u2212 \u2211N i=1 min{pi, p\u0303i}, and g\u03b4 : [0, \u03b4) \u2192 [0,\u221e) is increasing, continuous, and satisfies g\u03b4(0) = 0, limz\u2192\u03b4\u2212 g\u03b4(z) =\u221e; we then extend the definition via g\u03b4|[\u03b4,\u221e) :=\u221e. K > 0 is a new cost coefficient hyperparameter and \u03b4 is a new hyperparameter that determines the maximum amount by which the class probabilities can change. More specifically, if the original sample has p = 1k (i.e., a one-hot vector with a 1 in the k\u2019th position, corresponding to the label being k) then OT (p, p\u0303) = 1 \u2212 p\u0303k and so the cost (23) will force the adversarial label to have p\u0303k > 1 \u2212 \u03b4. In particular we only use \u03b4 \u2208 (0, 1/2] so that the predicted class is never changed; the class probabilities are only relaxed from being either 0 or 1 to being in [0, 1]. Therefore, we do not consider labels to be noisy in the sense discussed in, e.g., Natarajan et al. (2013); Shafieezadeh-Abadeh et al. (2019). We consider this only as a tool to enhance robustness. In our experiments we take g\u03b4(z) = z/(1\u2212 z/\u03b4). The inner maximizer with original sample and label being (x, 1k) is then\nLc\u03b8,\u03bb(x, 1k) = sup (x\u0303,p\u0303)\u2208X : p\u0303k>1\u2212\u03b4\n{ \u03bb\u22121L\u03b8(x\u0303, p\u0303)\u2212 L\u2225x\u2212 x\u0303\u2225q \u2212K\n1\u2212 p\u0303k 1\u2212 (1\u2212 p\u0303k)/\u03b4\n} . (24)\nWe let the baseline loss, L\u03b8, be the KL divergence between the adversarial probability vector, p\u0303, and the classifier output \u03d5\u03b8(x\u0303) (in the form of a probability vector); note that this is the same as the cross entropy when the label is one-hot but when the labels are relaxed to general probability vectors in the inner maximizer then they differ by the entropy of p\u0303. We use the notation advs,l to denote methods that employ both adversarial labels and adversarial samples, constructed via (24).\nExperimental Setup: To evaluate the performance of our proposed method, we consider the application of adversarial robustness in two fundamental deep learning tasks: image recognition and malware detection. For the image recognition task we use the MNIST dataset with 50,000 digits in the training and 10,000 in the test set. For the malware detection task, we use the dataset provided by Al-Dujaili et al. (2018), which includes a total of 54,690 binary encoded malware and benign Windows Portable Executables (PEs) partitioned into training (60%), validation (20%), and test set (20%). Each data point is represented as a 22,761-dimensional binary feature vector denoting the existence of a particular feature in the executable. The target detector models for image and malware data sets were a 4-layer convolutional neural network (CNN) and a 3-layer feed-forward network, respectively, for which the architecture details are given in Appendix C.3. In the binary encoded malware application there is an extra requirement: For the adversarial sample to be functional and preserve malicious malware functionality only bit flips from 0 to 1 are acceptable and not vice versa Al-Dujaili et al. (2018); this gives the problem an inherent asymmetry. Following the guidelines in Carlini et al. (2019), we consider a threat model characterizing the adversary\u2019s goal, knowledge, and capabilities detailed in Appendix C.1.\nBenchmark Methods and Evaluation Metrics: Following Wang et al. (2020); Madry et al. (2018), for the image application, we consider adversarial training with Fast Gradient Sign Method (FGSM) and Projected Gradient Method (PGDk). Additionally, we consider TRADES (Zhang et al., 2019) and MART (Wang et al., 2020). In the malware application, we consider adversarial training with r_FGSMk (Al-Dujaili et al., 2018) and the method proposed by Grosse et al. (2017). We note that Al-Dujaili et al. (2018) proposes several variants for their adversarial training method among which r_FGSMk produces the best results. Consistent with Al-Dujaili et al. (2018), we consider three evaluation metrics: accuracy, false negative rate (FNR), and false positive rate (FPR) as well-established evaluation metrics. For TRADES and MART, as FNR and FPR are not reported, we compare their reported accuracy to our proposed methods."
        },
        {
            "heading": "3.1 Experiment 1: Enhancing the Adversarial Robustness of Deep Learning-based Image Detectors",
            "text": "Here we present the results of our experiments on MNIST, where ARMORD\u2019s hyperparameters are tuned with the goal of enhancing adversarial robustness under attack. Table 1 summarizes these results for the non-robust model,\nbenchmark methods (FGSM , PGD, TRADES, and MART ), as well as variations of our proposed ARMORD method. Implementation details are provided in Appendix C. The best hyperparameters for ARMORD were attained via a small grid-search on a parameter space identified in Appendix C.4. To ensure a fair comparison, we closely followed the same settings as in (Kolter & Madry, 2018). As shown in Table 1, our proposed ARMOR\u03b1 (advs,l+nat) achieves the accuracy of 98.18%, FNR of 1.83%, and FPR of 0.20% under PGD attack and simultaneously achieves the accuracy of 98.29%, FNR of 1.72%, and FPR of 0.19% under FGSM attack, outperforming all benchmark methods and the non-robust model across all three evaluation metrics. ARMOR\u03b1 (advs + nat) yields the second best performance. Desirably, we observe that in many cases, the performance generalizability under not attack is also improved as a result of enhancing adversarial robustness with ARMORD (see \u201cNo Attack\" columns in Table 1).\nNote: Best metrics are shown in bold font. The numbers for methods that outperform the non-robust model and prior adversarial robustness methods across all three metrics are underlined.\nTo further illustrate the effectiveness of the proposed method, we examine a subset of MNIST test digits for which the performance of the FGSM, PGD, and our ARMOR\u03b1 (advs,l + nat) methods differ, i.e., the digits for which at least one, but not all three of these methods failed under adversarial attack. This subset consists of 225 digits out of the 10,000 digit MNIST test set. The models robustified with FGSM, PGD, and our method correctly classified 54 digits (24.00%), 100 digits (44.44%), and 198 digits (88.00%) out of this set, respectively. Figure 1 shows the results on 12 randomly selected examples from the constructed set of 225 digits. We see that our method exhibits significantly greater robustness on this subset of digits, and on the test set overall (see Table 1), though there remains a subset of \u201cdifficult\" samples on which all three methods fail under adversarial attack. Figure 1a depicts the performance of the non-robust model under the PGD attack for the random sample described above, while Figure 1b, Figure 1c, and Figure 1d show the corresponding performance under PDG attack of the same CNN model robustified by adversarial training with FGSM, PDG, and our proposed ARMOR\u03b1 (advs,l + nat) method respectively."
        },
        {
            "heading": "3.2 Experiment 2: Enhancing the Adversarial Robustness of Deep Learning-based Malware Detectors",
            "text": "Next we present our results on malware detection, where we closely followed the settings from Al-Dujaili et al. (2018). Appendix C provides the implementation details. Similar to the MNIST experiments, the best hyperparameters for our ARMORD were attained via a small grid-search on the parameter space in Appendix C.4. Table 2 shows the malware experiment results for the non-robust model, benchmark models (the method proposed by Grosse et al. (2017) and rFGSMk), as well as variations of our ARMORD method. As observed in Table 2, our proposed ARMOR\u03b1 (advs,l) achieves the accuracy of 83.31%, FNR of 2.44% and FPR of 42.0% against rFGSM50 attack outperforming, the benchmark methods and the non-robust model across all three evaluation metrics. ARMOR\u03b1 (advs,l) also attains the lowest FNR against rFGSM50 and the lowest FNR against Grosse et al.\u2019s attack. We note that, as shown in Table 2, the best performance under attack for Grosse et al. occurs when the adversarial training adopts the same method for inner maximizer. This is aligned with the findings in Al-Dujaili et al. (2018) (see their Table III).\nNote: Best metrics are shown in bold font. The numbers for methods that outperform the non-robust model and prior adversarial robustness methods across all three metrics are underlined."
        },
        {
            "heading": "4 Conclusion",
            "text": "In this work we proposed the ARMORD methods for enhancing adversarial robustness of deep learning models. These methods are based on a new class of divergences for comparing probability distributions, the optimal-transportregularized divergences Dc, which are defined as an infimal convolution between an information divergence D (such\nas KL) and an optimal-transport cost C. We demonstrated that these new tools have many attractive mathematical properties, making them well suited to applications in statistical learning. The ARMORD methods were tested on a pair of classification problems representing both continuous (MNIST digits) and discrete data (malware), where we found them to outperform existing methods for enhancing adversarial robustness. For instance,ARMORD achieves the robustified accuracy of 98.29% against FGSM and 98.18% against PGD40 on the MNIST dataset, outperforming prior adversarial training methods. For malware detection, ARMORD improves the robustified accuracy under rFGSM50 attack compared to the best-performing extant adversarial training method by 37.0% while lowering false negative and false positive rates by 51.1% and 57.53%, respectively. These experiments were all done using ARMORD where D was an f -divergence, however the majority of the rigorous theoretical development we provide in Appendix A applies to a much more general class of D\u2019s. The search for cases beyond D = Df where Dc can be efficiently and effectively applied to adversarial robustness, or to other statistical learning tasks, is an interesting direction for future work."
        },
        {
            "heading": "Reproducibility Statement",
            "text": "To facilitate reproducibility of the results presented in this paper we include implementation details in Appendix C. Specifically, Appendix C.2 contains pseudocode for the method, Appendix C.3 provides the target networks\u2019 structure used for the malware and image applications, Appendix C.4 provides the hyperparameters that yielded the results reported in Tables 1, 2, 3, and 4, Appendix C.5 discusses the implementation of the adv + nat methods, and Appendix C.6 discusses the implementation of the adva methods."
        },
        {
            "heading": "Author Contributions",
            "text": "Both authors have made equal contribution to this work."
        },
        {
            "heading": "Acknowledgments",
            "text": "We would like to thank Abdullah Al-Dujaili (MIT CSAIL) for sharing the binary encoded malware dataset with us."
        },
        {
            "heading": "A Properties of the OT-Regularized Divergences: Rigorous Statements and Proofs",
            "text": "In this appendix we rigorously develop the definition and properties of the optimal-transport-regularized divergences that were introduced formally above. Here we will let X be a Polish space (i.e., a complete separable metric space) with its Borel \u03c3-algebra (denoted B(X )) and P(X ) will denote the space of Borel probability measures on X . A pre-divergence will be a mapping D : P(X ) \u00d7 P(X ) \u2192 [0,\u221e] such that D(\u00b5\u2225\u00b5) = 0 for all \u00b5 \u2208 P(X ). We will say that D has the divergence property if D(\u00b5\u2225\u03bd) = 0 iff \u00b5 = \u03bd. A cost function on X will be a lower semicontinuous (LSC) function c : X \u00d7 X \u2192 [0,\u221e]. The associated optimal-transport (OT) cost is defined by C : P(X )\u00d7 P(X )\u2192 [0,\u221e],\nC(\u00b5, \u03bd) := inf \u03c0\u2208P(X\u00d7X ): \u03c01=\u00b5,\u03c02=\u03bd\n\u222b cd\u03c0 , (25)\nwhere \u03c0i denote the marginal distributions. It is a simple exercise to check that if c(x, x) = 0 for all x then C(\u00b5, \u00b5) = 0 for all \u00b5 and if c(x1, x2) = 0 iff x1 = x2 then C(\u00b5, \u03bd) = 0 iff \u00b5 = \u03bd. Also recall that C is convex and is LSC in the product of Prokhorov metric topologies. This follows from Kantorovich duality; see Theorem 5.10 in Villani (2008).\nAll subsequent topological statements regarding probability distributions will refer to the Prokhorov metric topology (i.e., the topology of weak convergence).\nGiven the above ingredients we now define the class of optimal-transport regularized divergences that are employed in this work. Definition A.1. Let D be a pre-divergence and c a cost function. The OT-regularized divergence, Dc : P(X ) \u00d7 P(X )\u2192 [0,\u221e], is defined by\nDc(\u03bd\u2225\u00b5) := inf \u03b7\u2208P(X ) {D(\u03b7\u2225\u00b5) + C(\u03b7, \u03bd)} . (26)\nIn the main text we frequently referred to D(\u03b7\u2225\u00b5) as an information divergence, meaning it is computable in terms of d\u03b7/d\u00b5, and the experiments in Section 3 utilized the f -divergences, D = Df , which satisfy this property. However our rigorous development in this appendix will be stated more generally. The search for cases beyond D = Df where Dc can be efficiently applied to adversarial robustness, or to other statistical learning tasks, is an interesting direction for future work. Throughout Section A.1 we provide remarks indicating how the theorems proven here can be applied to OT-regularized f -divergences. We use the following definition of f -divergences. Definition A.2. For a, b \u2208 [\u2212\u221e,\u221e] that satisfy \u2212\u221e \u2264 a < 1 < b \u2264 \u221e we define F1(a, b) to be the set of convex functions f : (a, b)\u2192 R with f(1) = 0. For f \u2208 F1(a, b), the corresponding f -divergence between \u03bd, \u00b5 \u2208 P(X ) is defined by\nDf (\u03bd\u2225\u00b5) = { EP [f(d\u03bd/d\u00b5)], \u03bd \u226a \u00b5 \u221e, \u03bd \u0338\u226a \u00b5 , (27)\nwhere the definition of f in (27) is extended to [a, b] by continuity and is set to\u221e on [a, b]c. Remark A.3. For certain choices of f one can assign a meaningful finite value to Df (\u03bd\u2225\u00b5) even when \u03bd \u0338\u226a \u00b5 Liese & Vajda (2006) but the definition (27) is more convenient for our purposes. That alternative definition agrees with (27) for the choices of f used in the experiments in Section 3.\nIn our numerical experiments we use the KL divergence, defined via fKL(z) = z log(z), and the \u03b1-divergences, defined via\nf\u03b1(z) = z\u03b1 \u2212 1 \u03b1(\u03b1\u2212 1) , \u03b1 > 1 . (28)\nThe Legendre transform of f\u03b1 will also be required\nf\u2217\u03b1(z) = \u03b1 \u22121(\u03b1\u2212 1)\u03b1/(\u03b1\u22121) max{z, 0}\u03b1/(\u03b1\u22121) + 1\n\u03b1(\u03b1\u2212 1) , \u03b1 > 1 . (29)"
        },
        {
            "heading": "A.1 Properties of the OT-Regularized Divergences",
            "text": "Here we prove a number of key properties of the OT-regularized divergences. Lemma A.4 (Convexity). Let D be a pre-divergence, c be a cost function, and \u00b5 \u2208 P(X ). If P 7\u2192 D(P\u2225\u00b5) is convex then P 7\u2192 Dc(P\u2225\u00b5) is convex. Remark A.5. f -divergences satisfy this convexity property. In fact, the map (Q,P ) \u2192 Df (Q\u2225P ) is convex for all f \u2208 F1(a, b). This follows from the variational representation of f -divergences; see Nguyen et al. (2010), Broniatowski & Keziou (2006) and also Proposition B.1 in Birrell et al. (2022).\nProof. C is convex on P(X )\u00d7 P(X ) and so (\u03b7, \u03bd) 7\u2192 D(\u03b7\u2225\u00b5) + C(\u03b7, \u03bd) is convex. Therefore the infimum over \u03b7 is convex in \u03bd.\nLemma A.6 (Pre-Divergence Property). Let D be a pre-divergence and c be a cost function that satisfies c(x, x) = 0 for all x. Then Dc is a pre-divergence.\nProof. We need to show that Dc(\u00b5\u2225\u00b5) = 0 for all \u00b5 \u2208 P(X ). To do this we bound the definition by its value at \u03b7 = \u00b5 to obtain\n0 \u2264 Dc(\u00b5\u2225\u00b5) \u2264 D(\u00b5\u2225\u00b5) + C(\u00b5, \u00b5) = 0 , (30)\nwhere C(\u00b5, \u00b5) = 0 follows from the assumption on c.\nTheorem A.7 (Divergence Property). Let D be a pre-divergence and c be a cost function that satisfy the following properties.\n1. If D(\u00b5n\u2225\u00b5)\u2192 0 then \u00b5n \u2192 \u00b5 weakly.\n2. c(x1, x2) = 0 iff x1 = x2."
        },
        {
            "heading": "Then Dc has the divergence property.",
            "text": "Remark A.8. In Theorem A.28 below we show that the f -divergences satisfy the weak convergence property under mild assumptions and hence this theorem can be applied to OT-regularized f -divergences.\nProof. If \u00b5 = \u03bd then 0 \u2264 Dc(\u03bd\u2225\u00b5) \u2264 D(\u00b5\u2225\u00b5) + C(\u00b5, \u03bd) = C(\u03bd, \u03bd) = 0. Hence Dc(\u03bd\u2225\u00b5) = 0. Conversely if Dc(\u03bd\u2225\u00b5) = 0 then there exists a sequence \u03b7n \u2208 P(X ) such that D(\u03b7n\u2225\u00b5) + C(\u03b7n, \u03bd)\u2192 0, i.e., D(\u03b7n\u2225\u00b5)\u2192 0 and C(\u03b7n, \u03bd)\u2192 0. By the weak convergence property of D we have \u03b7n \u2192 \u00b5 weakly. C is LSC, therefore\nC(\u00b5, \u03bd) \u2264 lim n\u2192\u221e C(\u03b7n, \u03bd) = 0 (31)\nand we can conclude that C(\u00b5, \u03bd) = 0. The assumption on c then implies \u00b5 = \u03bd.\nNext we provide conditions under which the infimum in (26) has a (unique) solution. Theorem A.9. Let D be a pre-divergence, c a cost function, and \u00b5, \u03bd \u2208 P(X ). If the mapping P 7\u2192 D(P\u2225\u00b5) is LSC and has compact sublevel sets (i.e., {P : D(P\u2225\u00b5) \u2264M} is compact for all M \u2208 R) then there exists \u03b7\u2217 \u2208 P(X ) such that\nDc(\u03bd\u2225\u00b5) = D(\u03b7\u2217\u2225\u00b5) + C(\u03b7\u2217, \u03bd) . (32)"
        },
        {
            "heading": "If P 7\u2192 D(P\u2225\u00b5) is strictly convex on the set where it is finite and Dc(\u03bd\u2225\u00b5) <\u221e then this \u03b7\u2217 is unique.",
            "text": "Remark A.10. For f \u2208 F1(a, b) the f -divergencesDf (\u00b7\u2225\u00b5) are LSC and have compact sublevel sets for all \u00b5, provided that f\u2217 is finite everywhere; see Corollary B.2 and Lemma B.5 in Birrell et al. (2022). If f is strictly convex on (a, b) then Df (\u00b7\u2225\u00b5) is strictly convex on the set where it is finite; see Lemma B.6 in Birrell et al. (2022). Therefore Theorem A.9 can be applied to OT-regularized f -divergences for appropriate choices of f .\nProof. If Dc(\u03bd\u2225\u00b5) = \u221e then the definition (26) implies that (32) holds for all \u03b7\u2217 \u2208 P(X ). Now consider the case where Dc(\u03bd\u2225\u00b5) <\u221e. Take \u03b7n such that Dc(\u03bd\u2225\u00b5) = limn(D(\u03b7n\u2225\u00b5) + C(\u03b7n, \u03bd)). Without loss of generality we can assume that D(\u03b7n\u2225\u00b5) \u2264 Dc(\u03bd\u2225\u00b5) + 1 <\u221e for all n, i.e., \u03b7n are all contained in a sublevel set of D(\u00b7\u2225\u00b5), which is compact by assumption. Therefore there exists a weakly convergent subsequence \u03b7nj \u2192 \u03b7\u2217. Lower semicontinuity of D(\u00b7\u2225\u00b5) and of C then implies lim infj D(\u03b7nj\u2225\u00b5) \u2265 D(\u03b7\u2217\u2225\u00b5) and lim infj C(\u03b7nj , \u03bd) \u2265 C(\u03b7\u2217, \u03bd). Therefore\nDc(\u03bd\u2225\u00b5) = lim j (D(\u03b7nj\u2225\u00b5) + C(\u03b7nj , \u03bd)) \u2265 D(\u03b7\u2217\u2225\u00b5) + C(\u03b7\u2217, \u03bd) . (33)\nThe reverse inequality is obvious from the definition of Dc, hence we can conclude\nDc(\u03bd\u2225\u00b5) = D(\u03b7\u2217\u2225\u00b5) + C(\u03b7\u2217, \u03bd) . (34) Now consider the case where P 7\u2192 D(P\u2225\u00b5) is also strictly convex on the set where it is finite. Suppose there exist distinct \u03b7\u2217,1, \u03b7\u2217,2 \u2208 P(X ) such that\nDc(\u03bd\u2225\u00b5) = D(\u03b7\u2217,1\u2225\u00b5) + C(\u03b7\u2217,1, \u03bd) = D(\u03b7\u2217,2\u2225\u00b5) + C(\u03b7\u2217,2, \u03bd) . (35)\nLetting \u03b7\u2217 = 12 (\u03b7\u2217,1 + \u03b7\u2217,2) we can use convexity of C and strict convexity of D(\u00b7\u2225\u00b5) to compute\nDc(\u03bd\u2225\u00b5) \u2264D(\u03b7\u2217\u2225\u00b5) + C(\u03b7\u2217, \u03bd) (36)\n< 1\n2 D(\u03b7\u2217,1\u2225\u00b5) +\n1 2 D(\u03b7\u2217,2\u2225\u00b5) + 1 2 C(\u03b7\u2217,1, \u03bd) + 1 2 C(\u03b7\u2217,2, \u03bd)\n= 1 2 Dc(\u03bd\u2225\u00b5) + 1 2 Dc(\u03bd\u2225\u00b5) = Dc(\u03bd\u2225\u00b5) .\nThis is a contradiction, therefore we can conclude the optimizer is unique.\nUsing Theorem A.9 we can proveDc(\u00b7\u2225\u00b5) is LSC; see Remark A.10 for the application to OT-regularized f -divergences. Theorem A.11 (Lower Semicontinuity). Let D be a pre-divergence, c a cost function, \u00b5 \u2208 P(X ), and assume that D(\u00b7\u2225\u00b5) is LSC and has compact sublevel sets. Then \u03bd 7\u2192 Dc(\u03bd\u2225\u00b5) is LSC.\nProof. Let \u03bdn, \u03bd \u2208 P(X ) with \u03bdn \u2192 \u03bd weakly and define M := lim infnDc(\u03bdn\u2225\u00b5). If M =\u221e then we clearly have lim infnD\nc(\u03bdn\u2225\u00b5) \u2265 Dc(\u03bd\u2225\u00b5) so suppose M <\u221e. Therefore, fixing \u03b4 > 0, there exists N such that for all n \u2265 N we have infj\u2265nDc(\u03bdj\u2225\u00b5) < M + \u03b4. Hence we can construct a subsequence jk such that Dc(\u03bdjk\u2225\u00b5) < M + \u03b4 for all k. Theorem A.9 implies that there exists \u03b7\u2217,n such that\nDc(\u03bdn\u2225\u00b5) = D(\u03b7\u2217,n\u2225\u00b5) + C(\u03b7\u2217,n, \u03bdn) (37)\nfor all n, and so\nM + \u03b4 > Dc(\u03bdjk\u2225\u00b5) = D(\u03b7\u2217,jk\u2225\u00b5) + C(\u03b7\u2217,jk , \u03bdjk) (38)\nfor all k. In particular, the \u03b7\u2217,jk are contained in the compact sublevel set {D(\u00b7\u2225\u00b5) \u2264M + \u03b4}. Therefore there exists a convergent subsequence \u03b7\u2217,jk\u2113 \u2192 \u03b7\u2217. Lower semicontinuity of D(\u00b7\u2225\u00b5) and C then implies\nM + \u03b4 \u2265 lim inf \u2113 (D(\u03b7\u2217,jk\u2113 \u2225\u00b5) + C(\u03b7\u2217,jk\u2113 , \u03bdjk\u2113 )) (39)\n\u2265 lim inf \u2113 D(\u03b7\u2217,jk\u2113 \u2225\u00b5) + lim inf\u2113 C(\u03b7\u2217,jk\u2113 , \u03bdjk\u2113 ))\n\u2265D(\u03b7\u2217\u2225\u00b5) + C(\u03b7\u2217, \u03bd) \u2265Dc(\u03bd\u2225\u00b5) .\nTaking \u03b4 \u2192 0+ and recalling the definition of M completes the proof.\nFinally, we prove a pair of results showing that Dc reduces to either D or C in certain limits. Therefore one can think of Dc as a type of interpolation between D and C. To apply these theorems to the case D = Df , see Remarks A.8 and A.10. Theorem A.12 (Interpolation). Let D be a pre-divergence, c be a cost function, and \u00b5, \u03bd \u2208 P(X ) that satisfy the following.\n1. The mapping P 7\u2192 D(P\u2225\u00b5) is LSC and has compact sublevel sets.\n2. D(\u00b5n\u2225\u00b5)\u2192 0 implies \u00b5n \u2192 \u00b5 weakly.\nFor r > 0 define the cost function cr = rc. Then\nlim r\u21920+\nr\u22121Dcr (\u03bd\u2225\u00b5) = C(\u00b5, \u03bd) for all \u00b5, \u03bd \u2208 P(X ). (40)\nProof. From the definitions we have\nr\u22121Dcr (\u03bd\u2225\u00b5) = inf \u03b7\u2208P(X ) {r\u22121D(\u03b7\u2225\u00b5) + C(\u03b7, \u03bd)} (41)\nand the right-hand side is non-increasing in r. Therefore for rn \u2198 0 we have\nlim n r\u22121n D crn (\u03bd\u2225\u00b5) = sup n r\u22121n D crn (\u03bd\u2225\u00b5) \u2264 C(\u00b5, \u03bd) , (42)\nwhere the inequality comes from bounding (26) by its value at \u03b7 = \u00b5. We will show that the assumption that this inequality is strict leads to a contradiction, which will complete the proof. If the inequality is strict thenDcrn (\u03bd\u2225\u00b5) <\u221e for all n and Theorem A.9 implies the existence of \u03b7\u2217,n such that\nD(\u03b7\u2217,n\u2225\u00b5) \u2264 D(\u03b7\u2217,n\u2225\u00b5) + rnC(\u03b7\u2217,n, \u03bd) = Dcrn (\u03bd\u2225\u00b5) \u2264 rn sup m r\u22121m D crm (\u03bd\u2225\u00b5) <\u221e . (43)\nTaking n\u2192\u221e we see thatD(\u03b7\u2217,n\u2225\u00b5)\u2192 0 and therefore \u03b7\u2217,n \u2192 \u00b5 weakly. C is LSC, therefore lim infn C(\u03b7\u2217,n, \u03bd) \u2265 C(\u00b5, \u03bd). Combining these we have\nC(\u00b5, \u03bd) > sup n r\u22121n D crn (\u03bd\u2225\u00b5) \u2265 lim inf n (r\u22121n D(\u03b7\u2217,n\u2225\u00b5) + C(\u03b7\u2217,n, \u03bd)) (44)\n\u2265 lim inf n C(\u03b7\u2217,n, \u03bd) \u2265 C(\u00b5, \u03bd) . (45)\nThis is a contradiction, hence the proof is complete.\nTheorem A.13 (Interpolation). Let D be a pre-divergence, c be a cost function, and \u00b5, \u03bd \u2208 P(X ) that satisfy the following.\n1. The mapping P 7\u2192 D(P\u2225\u00b5) is LSC and has compact sublevel sets.\n2. c(x1, x2) = 0 iff x1 = x2.\nFor r > 0 define the cost function cr = rc. Then\nlim r\u2192\u221e\nDcr (\u03bd\u2225\u00b5) = D(\u03bd\u2225\u00b5) for all \u00b5, \u03bd \u2208 P(X ). (46)\nProof. From the definitions we have\nDcr (\u03bd\u2225\u00b5) = inf \u03b7\u2208P(X ) {D(\u03b7\u2225\u00b5) + rC(\u03b7, \u03bd)} \u2264 D(\u03bd\u2225\u00b5) (47)\nand the left-hand side is non-decreasing in r. Therefore for rn \u2197\u221e we have\nlim n\u2192\u221e Dcrn (\u03bd\u2225\u00b5) = sup n Dcrn (\u03bd\u2225\u00b5) \u2264 D(\u03bd\u2225\u00b5) . (48)\nAssuming this inequality is strict will lead to a contradiction, thus completing the proof. Suppose that supnD crn (\u03bd\u2225\u00b5) < D(\u03bd\u2225\u00b5). Theorem A.9 implies the existence of \u03b7\u2217,n such that\nDcrn (\u03bd\u2225\u00b5) = D(\u03b7\u2217,n\u2225\u00b5) + rnC(\u03b7\u2217,n, \u03bd) . (49)\nIn particular, supnD(\u03b7\u2217,n\u2225\u00b5) \u2264 supnDcrn (\u03bd\u2225\u00b5) <\u221e and therefore \u03b7\u2217,n all lie in a sublevel set of D(\u00b7\u2225\u00b5), which is compact. Hence there exists a weakly convergent subsequence \u03b7\u2217,nj \u2192 \u03b7\u2217. Next we show that \u03b7\u2217 = \u03bd. To do this, note that\n\u221e > sup n Dcrn (\u03bd\u2225\u00b5) \u2265 sup n rnC(\u03b7\u2217,n, \u03bd) (50)\nand therefore limn C(\u03b7\u2217,n, \u03bd) = 0. Lower semicontinuity implies 0 = limj C(\u03b7\u2217,nj , \u03bd) \u2265 C(\u03b7\u2217, \u03bd) \u2265 0 and so C(\u03b7\u2217, \u03bd) = 0. The cost function has the property c(x1, x2) = 0 iff x1 = x2, hence we can conclude that \u03b7\u2217 = \u03bd. To complete the proof we can use the lower semicontinuity of D(\u00b7\u2225\u00b5) to compute\nD(\u03bd\u2225\u00b5) > sup n Dcrn (\u03bd\u2225\u00b5) \u2265 lim inf j D(\u03b7\u2217,nj\u2225\u00b5) \u2265 D(\u03b7\u2217\u2225\u00b5) = D(\u03bd\u2225\u00b5) . (51)\nThis is a contradiction and so the proof is complete."
        },
        {
            "heading": "A.2 DRO Using OT-Regularized Divergences",
            "text": "In this section we provide rigorous proofs for the key identities that transform the DRO problem over OT-regularizeddivergence neighborhoods into a computationally tractable form. This will involve the construction of regularized loss functions, as defined below.\nDefinition A.14. Given a loss function L : X \u2192 R we define the corresponding family of OT-regularized losses by\nLc\u03bb(x) := sup y\u2208X {L(y)/\u03bb\u2212 c(x, y)} , \u03bb > 0 . (52)\nLc\u03bb is known as the c-transform in the optimal transport literature; see Definition 5.2 in Villani (2008).\nIn the main text we use DRO as a tool for enhancing adversarial robustness, and there we consider distribution neighborhoods of the form {Q : Dc(Q\u2225Pn) \u2264 \u03f5}, where the baseline distribution is an empirical measure Pn. However, it can be useful to have a proof of the DRO identity for the neighborhoods {Q : Dc(Q\u2225P ) \u2264 \u03f5} with a general baseline distribution P and so we study this more general problem below. A key tool will be the following interchangeability result, which has previously been used in Wasserstein and OT DRO; see the discussion in Zhang et al. (2022). For completeness we provide a proof of the version employed in this work; our proof mimics the strategy used for the more general result stated in Zhang et al. (2022). Below we will use the notationM\u00b5 for the completion of a \u03c3-algebra,M, with respect to a measure \u00b5, we will denote the completion of \u00b5 by \u00b5, andM\u2217 will denote the \u03c3-algebra of universally measurable sets (with respect toM). Lemma A.15 (Interchangeability). Let \u00b5 \u2208 P(X ) and \u03d5 : X \u00d7 X \u2192 [\u2212\u221e,\u221e] be measurable. Then x 7\u2192 supy\u2208X \u03d5(x, y) is a B(X )\u2217-measurable function and\nsup \u03c0\u2208P(X\u00d7X ):\u03c01=\u00b5 E\u03c0[\u03d5] = \u222b sup y\u2208X \u03d5(x, y)\u00b5(dx) . (53)\nRemark A.16. In (53) we use the convention\u221e\u2212\u221e := \u2212\u221e to ensure all integrals therein are defined, though when using this result in the proof of Theorem A.17 below we will have further assumptions that guarantee all integrals are defined without any such convention.\nProof. Define \u03a6 = supy\u2208X \u03d5(\u00b7, y). For a \u2208 R we have\n{x : \u03a6(x) > a} = {x : \u2203y, \u03d5(x, y) > a} , (54)\nwhich is the projection of the measurable set \u03d5\u22121((a,\u221e]) onto its first component. Therefore the measurable projection theorem (see, e.g., Proposition 8.4.4 in Cohn (2013)) implies {x : \u03a6(x) > a} is B(X )\u2217-measurable. The rays (a,\u221e] for a \u2208 R generate the \u03c3-algebra on [\u2212\u221e,\u221e], hence \u03a6 is universally measurable as claimed. To prove (53), first suppose \u222b \u03a6\u2212d\u00b5 <\u221e, where \u03a6\u2212 denotes the negative part of \u03a6. Define \u03a6n = min{n,\u03a6\u2212 1/n} and note that min{0,\u03a6 \u2212 1} \u2264 \u03a6n < \u03a6, and \u03a6n \u2197 \u03a6. The \u03a6n are universally measurable, therefore Cn := {(x, y) \u2208 X \u00d7 X : \u03d5(x, y) > \u03a6n(x)} are B(X )\u00b5 \u2297 B(X )-measurable. For every x \u2208 X we have \u03a6n(x) < \u03a6(x) = supy\u2208X \u03d5(x, y), hence there exists y \u2208 X such that (x, y) \u2208 Cn. Therefore the projection of Cn onto its first component equals X . The measurable selection theorem, Corollary 8.5.4 in Cohn (2013), then implies that there exists Tn : X \u2192 X that is ((B(X )\u00b5)\u2217,B(X ))-measurable such that the graph of Tn is contained in Cn. Using the result of Cohn Ex. 8.4.2(b) we have (B(X )\u00b5)\u2217 = B(X )\u00b5, therefore Tn is (B(X )\u00b5,B(X ))-measurable. The map \u03c8 : x 7\u2192 (x, Tn(x)) is (B(X )\u00b5,B(X ) \u2297 B(X ))-measurable and the pushforward measure \u03c8#\u00b5 \u2208 P (X \u00d7X ) satisfies (\u03c8#\u00b5)1 = \u00b5, therefore\nsup \u03c0\u2208P(X\u00d7X ):\u03c01=\u00b5\nE\u03c0[\u03d5] \u2265 E\u03c8#\u00b5[\u03d5] = \u222b \u03d5(x, Tn(x))\u00b5(dx) \u2265 \u222b \u03a6nd\u00b5 , (55)\nwhere in the last inequality we used the fact that the graph of Tn is contained in Cn. We have the lower bound \u03a6n \u2265 \u2212\u03a6\u2212 \u2212 1 \u2208 L1(\u00b5) and therefore we can use the monotone convergence theorem to obtain\nsup \u03c0\u2208P(X\u00d7X ):\u03c01=\u00b5 E\u03c0[\u03d5] \u2265 lim n\u2192\u221e\n\u222b \u03a6nd\u00b5 = \u222b \u03a6d\u00b5 . (56)\nThis also trivially holds if \u222b \u03a6\u2212d\u00b5 =\u221e due to our convention\u221e\u2212\u221e := \u2212\u221e. The reverse inequality follows easily from the bound \u03a6(x) \u2265 \u03d5(x, y) for all x and y, together with the fact that there exists a B(X )-measurable function that equals \u03a6 \u00b5-a.s.\nNow we derive a formula that relates the convex conjugate of Dc(\u00b7\u2225P ) to the convex conjugate of D(\u00b7\u2225P ). This is a useful result in its own right and is a key ingredient in solving the DRO problem.\nTheorem A.17. Suppose we have the following:\n1. A measurable function L : X \u2192 [\u2212\u221e,\u221e) that is bounded below or is bounded above.\n2. A distribution P \u2208 P(X ).\n3. A pre-divergence, D, such that D(\u00b7\u2225P ) is convex.\n4. A cost function, c, that satisfies c(x, x) = 0 for all x \u2208 X .\nThen for \u03bb > 0 we have\nsup Q\u2208P(X ):\nDc(Q\u2225P )<\u221e\n{EQ[L]\u2212 \u03bbDc(Q\u2225P )} = sup Q\u2208P(X ):\nD(Q\u2225P )<\u221e\n{EQ[\u03bbLc\u03bb]\u2212 \u03bbD(Q\u2225P )} , (57)\nwhere Lc\u03bb (defined in Eq. 52) is a universally measurable function. Remark A.18. In Theorem A.17 and in the following, when it is convenient for simplifying notation we use the same symbol to denote a probability measure and its completion, as the correct interpretation is easily resolved by examining the measurably of the integrand. When needed for clarity, we will again use Q to denote the completion of Q \u2208 P(X ).\nProof. Universal measurability of Lc\u03bb follow from the interchangability result, Lemma A.15. To prove (57), first suppose that L is bounded above. Using the definitions of Dc and C we can compute\nsup Q\u2208P(X ):Dc(Q\u2225P )<\u221e\n{EQ[L]\u2212 \u03bbDc(Q\u2225P )} (58)\n= sup Q\u2208P(X )\n{ EQ[L]\u2212 \u03bb inf\n\u03b7\u2208P(X ) {D(\u03b7\u2225P ) + C(\u03b7,Q)}\n}\n=\u03bb sup \u03b7\u2208P(X )\n{ sup\nQ\u2208P(X ) {EQ[L/\u03bb]\u2212 C(\u03b7,Q)} \u2212D(\u03b7\u2225P )\n}\n=\u03bb sup \u03b7\u2208P(X ):D(\u03b7\u2225P )<\u221e\n{ sup\nQ\u2208P(X )\n{ sup\n\u03c0:\u03c01=\u03b7,\u03c02=Q\n{\u222b \u03bb\u22121L(y)\u2212 c(x, y)\u03c0(dxdy) }} \u2212D(\u03b7\u2225P ) }\n=\u03bb sup \u03b7\u2208P(X ):D(\u03b7\u2225P )<\u221e\n{ sup\n\u03c0:\u03c01=\u03b7\n{\u222b \u03bb\u22121L(y)\u2212 c(x, y)\u03c0(dxdy) } \u2212D(\u03b7\u2225P ) } =\u03bb sup\n\u03b7\u2208P(X ):D(\u03b7\u2225P )<\u221e {\u222b sup y\u2208X {\u03bb\u22121L(y)\u2212 c(x, y)}\u03b7(dx)\u2212D(\u03b7\u2225P ) } , (59)\nwhere we used the interchangability result, Lemma A.15, to obtain the last line. The assumption that L is bounded above, and hence EQ[L] \u2208 [\u2212\u221e,\u221e) for all Q, ensured that\u221e\u2212\u221e was not encountered in (58)-(59). Recalling the definition (52) this completes the proof when L is bounded above. Now suppose L is bounded below. Define Ln(x) := min{L(x), n}, n \u2208 Z+. These are measurable, are bounded above, and supnEQ[Ln] = EQ[L] for all Q by the monotone convergence theorem. Hence we can use (58)-(59) to obtain\nsup Q\u2208P(X ):Dc(Q\u2225P )<\u221e\n{EQ[L]\u2212 \u03bbDc(Q\u2225P )} (60)\n=sup n sup Q\u2208P(X ):Dc(Q\u2225P )<\u221e\n{EQ[Ln]\u2212 \u03bbDc(Q\u2225P )}\n=sup n sup Q\u2208P(X ):D(Q\u2225P )<\u221e\n{ \u03bb \u222b (Ln)c\u03bb(x)Q(dx)\u2212 \u03bbD(Q\u2225P ) } = sup Q\u2208P(X ):D(Q\u2225P )<\u221e { \u03bb sup n \u222b (Ln)c\u03bb(x)Q(dx)\u2212 \u03bbD(Q\u2225P )\n} = sup Q\u2208P(X ):D(Q\u2225P )<\u221e {\u03bbEQ[Lc\u03bb]\u2212 \u03bbD(Q\u2225P )} ,\nwhere we again used the monotone convergence theorem in the final equality (note that the functions (Ln)c\u03bb are bounded below uniformly in n). This proves the claim when L is bounded below and so the proof is complete.\nIn particular, when D = Df is an f -divergence we can further evaluate the convex conjugate of Df to obtain a formula that only involves expectations with respect to P .\nCorollary A.19. Suppose we have the following:\n1. A measurable function L : X \u2192 [\u2212\u221e,\u221e) that is bounded below or is bounded above.\n2. A distribution P \u2208 P(X ) such that L\u2212 \u2208 L1(P ), where L\u2212 denotes the negative part of L.\n3. f \u2208 F1(a, b) with a \u2265 0.\n4. A cost function, c, that satisfies c(x, x) = 0 for all x \u2208 X .\nThen for \u03bb > 0 we have\nsup Q\u2208P(X ):Dcf (Q\u2225P )<\u221e\n{EQ[L]\u2212 \u03bbDcf (Q\u2225P )} = \u03bb inf \u03c1\u2208R {\u03c1+ EP [f\u2217(Lc\u03bb \u2212 \u03c1)]} , (61)\nwhere the definition of f\u2217 is extended by f\u2217(\u00b1\u221e) :=\u221e.\nProof. Df is a pre-divergence and Df (\u00b7\u2225P ) is convex, hence Theorem A.17 gives\nsup Q\u2208P(X ):Dcf (Q\u2225P )<\u221e {EQ[L]\u2212 \u03bbDcf (Q\u2225P )} = \u03bb sup Q\u2208P(X ):Df (Q\u2225P )<\u221e {EQ[L c \u03bb]\u2212Df (Q\u2225P )} . (62)\nfor all \u03bb > 0. We have Lc\u03bb(x) \u2265 L(x)/\u03bb and so (Lc\u03bb)\u2212 \u2264 L\u2212/\u03bb \u2208 L1(P ). Therefore (Lc\u03bb)\u2212 \u2208 L1(P ) and we can employ the Gibbs variational principle for f -divergences (see Theorem 4.2 in Ben-Tal & Teboulle (2007)) for f -divergences gives\nsup Q:Df (Q\u2225P )<\u221e\n{EQ[L c \u03bb]\u2212Df (Q\u2225P )} = inf \u03c1\u2208R {\u03c1+ EP [f \u2217(Lc\u03bb \u2212 \u03c1)]} . (63)\nWe revert to explicit completion notation here to clarify a technical point. Theorem 4.2 from Ben-Tal & Teboulle (2007) assumes measurability of the integrand and not universal measurability. However one can easily prove that (63) still follows by first replacing Lc\u03bb with a B(X )-measurable function that agrees with it P -a.s. and then using the fact that Df (Q\u2225P ) < \u221e implies Q \u226a P ; see Definition (A.2). Also, the result in Ben-Tal & Teboulle (2007) assumes the integrand on the left-hand side of (63) is in L1(P ) but the case where the positive part is not integrable is easily checked to yield infinity on both sides of the identity. Combining (63) and (62) completes the proof.\nBefore proceeding to the DRO problem we need a lemma regarding the finiteness of expectations as the distribution ranges over an OT-regularized-divergence neighborhood.\nLemma A.20. Suppose we have the following:\n1. A measurable function L : X \u2192 [\u2212\u221e,\u221e].\n2. A distribution P \u2208 P(X )\n3. A pre-divergence, D, such that D(\u00b7\u2225P ) is convex.\n4. A cost function, c, that satisfies c(x, x) = 0 for all x \u2208 X .\nSuppose there exists \u03f5 > 0 such that L \u2208 L1(Q) for all Q \u2208 P(X ) that satisfy Dc(Q\u2225P ) \u2264 \u03f5. Then L \u2208 L1(Q) for all Q that satisfy Dc(Q\u2225P ) <\u221e.\nProof. The assumptions imply that Dc is a pre-divergence (see Lemma A.6) and Dc(\u00b7\u2225P ) is convex (see Lemma A.4). Take any Q with Dc(Q\u2225P ) < \u221e and define Qt = tQ + (1 \u2212 t)P for t \u2208 (0, 1). By convexity and the pre-divergence property we have Dc(Qt\u2225P ) \u2264 tDc(Q\u2225P ). We assumed Dc(Q\u2225P ) <\u221e, hence there exists t \u2208 (0, 1) with Dc(Qt\u2225P ) \u2264 \u03f5. This implies L \u2208 L1(Qt) and so \u221e > EQt [|L|] = tEQ[|L|] + (1 \u2212 t)EP [|L|]. We have t \u2208 (0, 1), therefore we can conclude EQ[|L|] <\u221e as claimed.\nWe are now ready to consider the DRO problem for general P . We also allow for an explicitDc penalty term, in addition to maximizing over the distribution neighborhood, though we do not employ such a penalty term in the experiments in Section 3.\nTheorem A.21. Suppose we have the following:\n1. A distribution P \u2208 P(X ).\n2. A measurable function L : X \u2192 [\u2212\u221e,\u221e) such that one of the following two conditions hold:\n(a) L is bounded below. (b) L is bounded above and L\u2212 \u2208 L1(P ).\n3. A pre-divergence, D, such that D(\u00b7\u2225P ) is convex.\n4. A cost function, c, that satisfies c(x, x) = 0 for all x \u2208 X .\nThen for \u03f5 > 0, \u03ba \u2265 0 we have\nsup Q:Dc(Q\u2225P )\u2264\u03f5\n{EQ[L]\u2212 \u03baDc(Q\u2225P )} (64)\n= inf \u03bb>0 {\u03bb\u03f5+ (\u03bb+ \u03ba) sup Q\u2208P(X ):D(Q\u2225P )<\u221e {EQ[Lc\u03bb+\u03ba]\u2212D(Q\u2225P )}} .\nProof. We will show that\nsup Q:Dc(Q\u2225P )\u2264\u03f5 {EQ[L]\u2212 \u03baDc(Q\u2225P )} = inf \u03bb>0 {\u03bb\u03f5+ sup Q:Dc(Q\u2225P )<\u221e {EQ[L]\u2212 (\u03bb+ \u03ba)Dc(Q\u2225P )}} . (65)\nCombining this with the result of Theorem A.17 will then complete the proof. If there exists Q such that Dc(Q\u2225P ) \u2264 \u03f5 and EQ[L+] = \u221e then it is straightforward to see that both sides of (65) equal\u221e. Therefore it suffices to consider the case where EQ[L+] < \u221e for all Q satisfying Dc(Q\u2225P ) \u2264 \u03f5. Applying Lemma A.20 to L+ then implies L+ \u2208 L1(Q) for all Q satisfying Dc(Q\u2225P ) < \u221e. Therefore the F : Q 7\u2192 EQ[L] \u2212 \u03baDc(Q\u2225P ) is a concave map from {Q : Dc(Q\u2225P ) < \u221e} to [\u2212\u221e,\u221e) and Q 7\u2192 Dc(Q\u2225P ) is a convex constraint. P satisfies F [P ] \u2208 R and Dc(P\u2225P ) < \u03f5. Therefore Slater\u2019s constraint qualification condition holds (see, e.g., Theorem 3.11.2 in Ponstein (2004)) and we can conclude strong duality\nsup Q:Dc(Q\u2225P )\u2264\u03f5\n{EQ[L]\u2212 \u03baDc(Q\u2225P )} (66)\n= inf \u03bb>0 {\u03bb\u03f5+ sup Q:Dc(Q\u2225P )<\u221e {EQ[L]\u2212 (\u03ba+ \u03bb)Dc(Q\u2225P )}} .\nWe note that the infimum can be restricted to \u03bb > 0 (rather than \u03bb \u2265 0) due to the lower bound on the constraint function, Dc(\u00b7\u2225P ) \u2265 0. This proves the claim.\nIf D is an f -divergence, the convex conjugate term (i.e., the supremum over Q) in (64) can be evaluated by the same method as in Corollary A.19 and the result is a two-dimensional convex optimization problem. Corollary A.22. Suppose we have the following:\n1. A distribution P \u2208 P(X ).\n2. A measurable function L : X \u2192 [\u2212\u221e,\u221e) such that one of the following two conditions hold:\n(a) L is bounded below. (b) L is bounded above and L\u2212 \u2208 L1(P ).\n3. f \u2208 F1(a, b) where a \u2265 0.\n4. A cost function, c, that satisfies c(x, x) = 0 for all x \u2208 X .\nDefine f\u2217(\u00b1\u221e) :=\u221e. Then for \u03f5 > 0, \u03ba \u2265 0 we have\nsup Q:Dcf (Q\u2225P )\u2264\u03f5\n{EQ[L]\u2212 \u03baDcf (Q\u2225P )} (67)\n= inf \u03bb>0,\u03c1\u2208R\n{\u03bb\u03f5+ \u03c1+ (\u03bb+ \u03ba)EP [f\u2217(Lc\u03bb+\u03ba \u2212 \u03c1/(\u03bb+ \u03ba))]}\nand the objective function for the minimization, (0,\u221e)\u00d7 R\u2192 (\u2212\u221e,\u221e],\n(\u03bb, \u03c1) 7\u2192 \u03bb\u03f5+ \u03c1+ (\u03bb+ \u03ba)EP [f\u2217(Lc\u03bb+\u03ba \u2212 \u03c1/(\u03bb+ \u03ba))] , (68)\nis convex.\nProof. Equation (67) follows from applying Theorem A.21 to D = Df and then evaluating the convex conjugate of Df (\u00b7\u2225P ) by the same method as in Corollary A.19. To prove convexity of the objective function, first note that for all x the maps hx(t) := supy{tL(y)\u2212 c(x, y)} are convex in t \u2208 (0,\u221e) and either hx > \u2212\u221e or hx(t) = \u2212\u221e for all t. f\u2217 is convex and it is straightforward to check that a \u2265 0 implies f\u2217 is non-decreasing on (\u2212\u221e,\u221e]. These facts together imply that (t, \u03c1) 7\u2192 f\u2217(hx(t)\u2212\u03c1) are convex on (0,\u221e)\u00d7R for all x. Linearity of the expectation then implies H(t, \u03c1) := EP [f\n\u2217(hx(t)\u2212 \u03c1)] is convex (note that f\u2217(z) \u2265 z and so the assumptions on L imply that H(t, \u03c1) > \u2212\u221e). Therefore the perspective of H , given by (\u03bb, t, \u03c1) 7\u2192 \u03bbH(t/\u03bb, \u03c1/\u03bb), is convex on (0,\u221e)\u00d7 (0,\u221e)\u00d7 R. Composing with the affine map (\u03bb, \u03c1) 7\u2192 (\u03bb+\u03ba, 1, \u03c1) and adding the linear term \u03bb\u03f5+ \u03c1 results in a convex function on (0,\u221e)\u00d7R. Substituting in the definitions of H and hx we see that this function equals (68), thereby completing the proof.\nFinally, we derive limiting formulas for the DRO problem, analogous to the interpolation results for Dc, Theorems A.12 and A.13. Though we don\u2019t use those theorems directly, the method of proof is similar and the conclusions align with what one expects in light of those results. We do require the more stringent assumption that X is compact, which is often the case in practice.\nTheorem A.23. Suppose the Polish space X is compact and that we have the following:\n1. An upper semicontinuous (USC) function L : X \u2192 [\u2212\u221e,\u221e).\n2. A distribution P \u2208 P(X ).\n3. A pre-divergence D such that D(\u00b7\u2225P ) is LSC and D(\u00b5n\u2225P )\u2192 0 implies \u00b5n \u2192 P weakly.\n4. A cost-function c.\nFor r > 0 define the cost functions cr = rc. Then for \u03f5 > 0 we have\nlim r\u21920+ sup Q:Dcr (Q\u2225P )\u2264r\u03f5 EQ[L] = sup Q:C(P,Q)\u2264\u03f5 EQ[L] . (69)"
        },
        {
            "heading": "If L\u03b8 : X \u2192 [\u2212\u221e,\u221e), \u03b8 \u2208 \u0398, is a family of USC functions then",
            "text": "lim r\u21920+ inf \u03b8\u2208\u0398 sup Q:Dcr (Q\u2225P )\u2264r\u03f5 EQ[L\u03b8] = inf \u03b8\u2208\u0398 sup Q:C(P,Q)\u2264\u03f5 EQ[L\u03b8] . (70)\nProof. Compactness of X and upper semicontinuity of L implies that L has a maximizer and hence L is bounded above. In particular, the expecations are all well-defined. The bound Dcr (Q\u2225P ) \u2264 rC(P,Q) implies\nsup Q:C(P,Q)\u2264\u03f5 EQ[L] \u2264 sup Q:Dcr (Q\u2225P )\u2264r\u03f5 EQ[L] (71)\nfor all r > 0. Define Kr \u2261 {Q : Dcr (Q\u2225P ) \u2264 r\u03f5} and note that r2 \u2264 r1 implies Kr2 \u2282 Kr1 , hence the right-hand side of (71) is non-decreasing in r. D(\u00b7\u2225P ) is LSC, therefore it has closed sublevel sets. X is a compact Polish space, therefore P(X ) is compact (see, e.g., page 117 of Bogachev (2018)). Therefore the sublevel sets of D(\u00b7\u2225P ) are also compact. Theorem A.11 then implies Dcr (\u00b7\u2225P ) is LSC for all r and so the Kr are closed sets, hence also compact. L is USC and bounded above, therefore the Portmanteau theorem implies that Q 7\u2192 EQ[L] is USC, hence it achieves its maximum on Kr, i.e., there exists Qr \u2208 Kr such that\nsup Q\u2208Kr EQ[L] = EQr [L]. (72)\nTake rn \u2198 0+. Compactness of P(X ) implies the existence of a weakly convergent subsequence Qj := Qrnj \u2192 Q\u2217. Upper semicontinuity then implies lim supj EQj [L] \u2264 EQ\u2217 [L]. By Theorem A.9 there exist \u03b7\u2217,j \u2208 P(X ) such that\n\u03f5 \u2265 1 rnj D crnj (Qj\u2225P ) = 1 rnj D(\u03b7\u2217,j\u2225P ) + C(\u03b7\u2217,j , Qj) . (73)\nIn particular we see that limj\u2192\u221eD(\u03b7\u2217,j\u2225P ) = 0. The assumptions on D therefore imply that \u03b7\u2217,j \u2192 P weakly. Now we can use lower semicontinuity of C to compute\nC(P,Q\u2217) \u2264 lim inf j C(\u03b7\u2217,j , Qj) \u2264 lim inf j\n1\nrnj D crnj (Qj\u2225P ) \u2264 \u03f5 . (74)\nTherefore Q\u2217 \u2208 {Q : C(P,Q) \u2264 \u03f5}. Putting these pieces together we find\nsup Q:C(P,Q)\u2264\u03f5 EQ[L] \u2265EQ\u2217 [L] \u2265 lim sup j EQrnj [L] = lim sup j sup\nQ\u2208Krnj\nEQ[L] (75)\n\u2265 inf r>0 sup Q:Dcr (Q\u2225P )\u2264r\u03f5 EQ[L] = lim r\u21920+ sup Q:Dcr (Q\u2225P )\u2264r\u03f5 EQ[L] ,\nwhere the last equality follows from the fact that the right-hand side is non-decreasing in r. Combining this inequality with (71) completes the proof of (69). If one has a family of USC functions L\u03b8 then apply (69) for each \u03b8 and note that the limit as r \u2192 0+ is an infimum, hence one can commute the infimum over \u03b8 with the limit r \u2192 0+ to obtain (70).\nTheorem A.24. Suppose the Polish space X is compact and that we have the following:\n1. An USC function L : X \u2192 [\u2212\u221e,\u221e).\n2. A distribution P \u2208 P(X ).\n3. A pre-divergence D such that D(\u00b7\u2225P ) is LSC.\n4. A cost-function c that satisfies c(x1, x2) = 0 iff x1 = x2.\nFor r > 0 define the cost functions cr = rc. Then for \u03f5 > 0 we have\nlim r\u2192\u221e sup Q:Dcr (Q\u2225P )\u2264\u03f5 EQ[L] = sup Q:D(Q\u2225P )\u2264\u03f5 EQ[L] . (76)"
        },
        {
            "heading": "If L\u03b8 : X \u2192 [\u2212\u221e,\u221e), \u03b8 \u2208 \u0398, is a family of USC functions then",
            "text": "lim r\u2192\u221e inf \u03b8\u2208\u0398 sup Q:Dcr (Q\u2225P )\u2264\u03f5 EQ[L\u03b8] = inf \u03b8\u2208\u0398 sup Q:D(Q\u2225P )\u2264\u03f5 EQ[L\u03b8] . (77)\nThe proof of Theorem A.24 is similar to that of Theorem A.23, with slight differences that are motivated by the proof of Theorem A.13; we omit the details."
        },
        {
            "heading": "A.3 Weak Convergence and f -Divergences",
            "text": "In this section we show that f -divergences can be used to prove weak convergence of measures; this is needed in Theorem A.7 as well as to apply many of the properties from Appendix A.1 to OT-regularized f -divergences. In fact, we will prove the stronger setwise convergence property. In this section we letMb(\u2126) denote the set of bounded measurable real-valued functions on a measurable space (\u2126,M). Definition A.25. Let {\u00b5n}\u221en=1, \u00b5 be probability measures on the measurable space (\u2126,M). We say that \u00b5n \u2192 \u00b5 setwise if limn\u2192\u221e \u00b5n(A) = \u00b5(A) for all A \u2208M.\nFirst recall that setwise convergence implies convergence of integrals; we provide a simple proof of this fact. Lemma A.26. Let (\u2126,M) be a measurable space and \u00b5n, \u00b5 be probability measures on \u2126. If \u00b5n \u2192 \u00b5 setwise then\u222b \u03d5d\u00b5n \u2192 \u222b \u03d5d\u00b5 for all \u03d5 \u2208Mb(\u2126).\nRemark A.27. In particular, if (\u2126,M) is a metric space with the Borel \u03c3-algebra then this implies \u00b5n \u2192 \u00b5 weakly.\nProof. Let \u03d5 \u2208Mb(\u2126). Take a sequence of simple functions \u03d5j that converge uniformly to \u03d5 (see, e.g., Theorem 2.10 in Folland (2013)). With these we can compute\n| \u222b \u03d5d\u00b5n \u2212 \u222b \u03d5d\u00b5| \u2264| \u222b \u03d5d\u00b5n \u2212 \u222b \u03d5jd\u00b5n|+ | \u222b \u03d5jd\u00b5n \u2212 \u222b \u03d5jd\u00b5|+ | \u222b \u03d5jd\u00b5\u2212 \u222b \u03d5d\u00b5|\n\u2264\u2225\u03d5\u2212 \u03d5j\u2225\u221e(\u00b5n(\u2126) + \u00b5(\u2126)) + | \u222b \u03d5jd\u00b5n \u2212 \u222b \u03d5jd\u00b5| . (78)\nThe fact that \u03d5j are simple and \u00b5n \u2192 \u00b5 setwise implies that | \u222b \u03d5jd\u00b5n \u2212 \u222b \u03d5jd\u00b5| \u2192 0 as n\u2192\u221e for all j, hence\nlim sup n\u2192\u221e\n| \u222b \u03d5d\u00b5n \u2212 \u222b \u03d5d\u00b5| \u2264 2\u2225\u03d5\u2212 \u03d5j\u2225\u221e (79)\nfor all j. Taking j \u2192\u221e completes the proof.\nWe now prove that convergence of an f -divergence to zero implies setwise convergence under mild assumptions on f .\nTheorem A.28. Let (\u2126,M) be a measurable space, f \u2208 F1(a, b), and define w0 := f \u2032+(1) (where f \u2032+ denotes the right derivative of f , which exists because f is convex). Suppose w0 \u2208 {f\u2217 <\u221e}o (Ao denotes the interior of the set A) and f is strictly convex on a neighborhood of 1. If Pn, P are probability measures on \u2126 and either Df (Pn\u2225P )\u2192 0 or Df (P\u2225Pn)\u2192 0 then Pn \u2192 P setwise. If (\u2126,M) is a metric space with the Borel \u03c3-algebra then we can further conclude Pn \u2192 P weakly.\nProof. Take any probability measures Q1, Q2 on (\u2126,M) and A \u2208M. For all \u03f5 > 0 we define \u03d5\u03f5 = w0 + \u03f51A. Then \u03d5\u03f5 \u2208Mb(\u2126), hence the variational representation of f -divergences (see Proposition B.1 in Birrell et al. (2022)) implies\nDf (Q1\u2225Q2) \u2265EQ1 [\u03d5\u03f5]\u2212 EQ2 [f\u2217(\u03d5\u03f5)] (80) =w0 + \u03f5Q1(A)\u2212 EQ2 [f\u2217(w0 + \u03f51A)] .\nWe have assumed that w0 \u2208 {f\u2217 < \u221e}o, hence there exists \u03b4 > 0 with B\u03b4(w0) \u2282 {f\u2217 < \u221e}. Using properties of the Taylor expansion of convex functions (see Liese & Vajda (2006)) along with the identities f\u2217(w0) = w0 and (f\u2217)\u2032+(w0) = 1 (see Lemma A.9 in Birrell et al. (2022)) we can compute\nf\u2217(y) =f\u2217(w0) + (f \u2217)\u2032+(w0)(y \u2212 w0) +Rf\u2217(w0, y) (81)\n=y +Rf\u2217(w0, y) \u2264y + |y \u2212 w0||(f\u2217)\u2032+(y)\u2212 (f\u2217)\u2032+(w0)|\nfor all y \u2208 B\u03b4(w0). Letting \u03f5 < \u03b4 we have range(w0 + \u03f51A) \u2282 B\u03b4(w0) and so\nf\u2217(w0 + \u03f51A) \u2264w0 + \u03f51A + |w0 + \u03f51A \u2212 w0||(f\u2217)\u2032+(w0 + \u03f51A)\u2212 (f\u2217)\u2032+(w0)| (82) =w0 + \u03f51A + \u03f51A|(f\u2217)\u2032+(w0 + \u03f5)\u2212 (f\u2217)\u2032+(w0)| .\nHence\nDf (Q1\u2225Q2) \u2265w0 + \u03f5Q1(A)\u2212 EQ2 [w0 + \u03f51A + \u03f51A|(f\u2217)\u2032+(w0 + \u03f5)\u2212 (f\u2217)\u2032+(w0)|] (83) =\u03f5[Q1(A)\u2212Q2(A)(1 + |(f\u2217)\u2032+(w0 + \u03f5)\u2212 (f\u2217)\u2032+(w0)|)] .\nNow let Pn, P be probability measures on \u2126 and consider the following two cases.\n1. Suppose Df (Pn, P )\u2192 0. Then letting Q1 = Pn and Q2 = P in the above we get\n0 = lim sup n\nDf (Pn\u2225P ) (84)\n\u2265\u03f5[lim sup n Pn(A)\u2212 P (A)(1 + |(f\u2217)\u2032+(w0 + \u03f5)\u2212 (f\u2217)\u2032+(w0)|)] (85)\nfor all \u03f5 \u2208 (0, \u03b4). If lim supn Pn(A) > P (A) then by right-continuity of (f\u2217)\u2032+ (the right-derivative of a convex function), for \u03f5 small enough the term in brackets in (85) is positive, which is a contradiction. Therefore lim supn Pn(A) \u2264 P (A). This holds for all A \u2208 M, hence for a given A we can apply it to Ac to get lim supn Pn(A\nc) \u2264 P (Ac), hence lim infn Pn(A) \u2265 P (A). Together these bounds imply limn Pn(A) = P (A) for all A \u2208M, hence Pn \u2192 P setwise.\n2. Suppose Df (P, Pn)\u2192 0. Letting Q1 = P and Q2 = Pn we have\n0 = lim sup n\nDf (P\u2225Pn) (86)\n\u2265\u03f5[P (A)\u2212 lim inf n Pn(A)(1 + |(f\u2217)\u2032+(w0 + \u03f5)\u2212 (f\u2217)\u2032+(w0)|)] .\nIf P (A) > lim infn Pn(A) then for \u03f5 sufficiently small we again find the term in brackets to be positive, which is a contradiction. Hence P (A) \u2264 lim infn Pn(A) for all A \u2208 M. Applying this to Ac and combining the results gives limn\u2192\u221e Pn(A) = P (A) for all A \u2208M. Hence Pn \u2192 P setwise.\nIf (\u2126,M) is a metric space with the Borel \u03c3-algebra then we can further conclude Pn \u2192 P weakly by using Lemma A.26.\nB Interpreting the Outer Minimizer: Adversarial Sample Weights\nStripping away the infimum over model parameters, \u03b8, the outer minimizer (15) can be interpreted as the computation of optimal weights for the adversarial samples, where optimality is defined in part by the chosen f -divergence. This is a complement to the inner maximizer (13) which constructs the optimally transported adversarial samples, according to the chosen OT cost function. In this appendix we present a formal derivation that elucidates this interpretation.\nLet yi(\u03bb) be the solution to the inner maximizer (13) with x = xi as a function of \u03bb and let \u03bb\u2217 and \u03c1\u2217 be the optimal scaling and shift parameters for the outer minimizer at a fixed \u03b8 (we suppress the \u03b8-dependence of yi, \u03bb\u2217, and \u03c1\u2217 in the notation). Here we (formally) show that outer minimization problem can then be rewritten as\ninf \u03bb>0,\u03c1\u2208R\n{ \u03f5\u03bb+ \u03c1+ \u03bb 1\nn n\u2211 i=1 f\u2217(Lc\u03b8,\u03bb(xi)\u2212 \u03c1/\u03bb) } = EQ\u2217,\u03b8 [L\u03b8] (87)\nwhere the optimal adversarial distribution is\nQ\u2217,\u03b8 := n\u2211 i=1 1 n (f\u2217)\u2032(Lc\u03b8,\u03bb\u2217(xi)\u2212 \u03c1\u2217/\u03bb\u2217)\u03b4yi(\u03bb\u2217) . (88)\nIn other words, the optimal adversarial distribution is supported on the optimal adversarial samples and the weight of the i\u2019th sample is changed from 1/n to pi where\npi := 1\nn (f\u2217)\u2032(Lc\u03b8,\u03bb\u2217(xi)\u2212 \u03c1\u2217/\u03bb\u2217) . (89)\nNote that f\u2217 is non-decreasing due to f being infinite on (\u2212\u221e, 0) (see Definition A.2 and Corollary A.22), hence pi \u2265 0. In addition, the pi\u2019s sum to 1 as shown in (92) below. Convexity of f\u2217 implies that (f\u2217)\u2032 is also non-decreasing, hence the pi\u2019s shift more weight towards the samples where the OT-regularized loss is larger, as would be expected for an adversarial re-weighting. In some cases, such as for the \u03b1-divergences, f\u2217 is constant on (\u2212\u221e,M) for some M (for the \u03b1-divergences, M = 0; see Eq. 29). Samples with Lc\u03b8,\u03bb\u2217(xi) < \u03c1\u2217/\u03bb\u2217 +M therefore have their weighting changed to 0. Intuitively, one can consider those samples as having sufficiently small OT-regularized loss and so the method moves its attention away from them to focus on more troublesome samples. Part of the task of the outer minimizer is to dynamically determine the optimal threshold for \"sufficient smallness\", as set by \u03c1\u2217/\u03bb\u2217 (note that this threshold changes with \u03b8, as \u03bb\u2217 and \u03c1\u2217 are both \u03b8-dependent).\nThe following is a formal derivation of (87) where we assume that X = Rd, exact optimizers exist, and all functions are sufficiently smooth. First, by taking the gradient of the objective function for the inner maximizer (13) with respect to y and evaluating at the optimizer yi(\u03bb), we find \u03bb\u22121\u2207yL\u03b8(yi(\u03bb))\u2212\u2207yc(xi, yi(\u03bb)) = 0 (90) for all \u03bb. Differentiating the objective function in (87) with respect to \u03c1 we find\n\u2202\u03c1|\u03c1=\u03c1\u2217(\u03f5\u03bb\u2217 + \u03c1+ \u03bb\u2217 1\nn n\u2211 i=1 f\u2217(Lc\u03b8,\u03bb\u2217(xi)\u2212 \u03c1/\u03bb\u2217)) (91)\n=1 + \u03bb\u2217 1\nn n\u2211 i=1 (f\u2217)\u2032(Lc\u03b8,\u03bb\u2217(xi)\u2212 \u03c1\u2217/\u03bb\u2217)(\u2212\u03bb \u22121 \u2217 ) = 0 ,\ni.e.,\n1\nn n\u2211 i=1 (f\u2217)\u2032(Lc\u03b8,\u03bb\u2217(xi)\u2212 \u03c1\u2217/\u03bb\u2217) = 1 . (92)\nIn particular, this implies that the pi\u2019s in (89) sum to 1. We next differentiate the objective function with respect to \u03bb to obtain\n\u03f5+ 1\nn \u2211 i f\u2217(Lc\u03b8,\u03bb\u2217(xi)\u2212 \u03c1\u2217/\u03bb\u2217) (93)\n+ \u03bb 1\nn \u2211 i (f\u2217)\u2032(Lc\u03b8,\u03bb\u2217(xi)\u2212 \u03c1\u2217/\u03bb\u2217)(\u2202\u03bb|\u03bb=\u03bb\u2217L c \u03b8,\u03bb(xi) + \u03c1\u2217/\u03bb 2 \u2217) = 0 ,\nwhere we can use (90) to simplify \u2202\u03bbLc\u03b8,\u03bb(xi) =\u2212 \u03bb\u22122L\u03b8(yi(\u03bb)) + (\u03bb\u22121\u2207yL\u03b8(yi(\u03bb))\u2212\u2207yc(xi, yi(\u03bb))) \u00b7 y\u2032i(\u03bb) (94) =\u2212 \u03bb\u22122L\u03b8(yi(\u03bb)) . Combining (92), (93), and (94) we can compute\n\u03f5\u03bb\u2217 + \u03c1\u2217 + \u03bb\u2217 1\nn \u2211 i f\u2217(Lc\u03b8,\u03bb\u2217(xi)\u2212 \u03c1\u2217/\u03bb\u2217) (95)\n= 1\nn \u2211 i (f\u2217)\u2032(Lc\u03b8,\u03bb\u2217(xi)\u2212 \u03c1\u2217/\u03bb\u2217)(L\u03b8(yi(\u03bb\u2217))\u2212 \u03c1\u2217)\u2212 \u03bb\u2217 1 n \u2211 i f\u2217(Lc\u03b8,\u03bb\u2217(xi)\u2212 \u03c1\u2217/\u03bb\u2217)\n+ \u03c1\u2217 + \u03bb\u2217 1\nn \u2211 i f\u2217(Lc\u03b8,\u03bb\u2217(xi)\u2212 \u03c1\u2217/\u03bb\u2217)\n= 1\nn \u2211 i (f\u2217)\u2032(Lc\u03b8,\u03bb\u2217(xi)\u2212 \u03c1\u2217/\u03bb\u2217)L\u03b8(yi(\u03bb\u2217)) .\nRecalling the definition of \u03bb\u2217 and \u03c1\u2217, this implies the claimed equality (87).\nC Implementation Details\nTo foster reproducability of our results, we provide the threat model, pseudocode for the OT-regularized-divergence adversarial robustness methods, the target network structures used in the malware and image applications, and the hyperparameters that yielded the results in Tables 1, 2, 3, and 4."
        },
        {
            "heading": "C.1 Threat Model",
            "text": "Following the guidelines in Carlini et al. (2019), we consider the following threat model characterizing the adversary\u2019s goal, knowledge, and capabilities in implementing ARMORD as a method for enhancing adversarial robustness.\n1. Adversaries goal: The adversaries goal is to generate adversarial samples that force the image/malware detector to make erroneous predictions. To avoid restrictive assumptions, any wrong classification is considered as a successful attack.\n2. Adversary\u2019s knowledge: To avoid restrictive assumptions, we assume that the adversary has complete knowledge of the inner workings of the target model (i.e., white-box access). This aligns with the Kerckhoff\u2019s principle that mandates security even if system details are known to the adversary.\n3. Adversary\u2019s Capabilities: The adversary can apply arbitrary modifications to natural samples of any class (e.g., both malicious and benign in the binary classification case)."
        },
        {
            "heading": "C.2 Algorithm Pseudocode",
            "text": "In this appendix we provide pseudocode for the methods proposed in this work. We will refer to the objective functions (96)- (99) therein, where \u03d5\u03b8 denotes the target model (i.e., classifier) and CE denotes the cross-entropy loss. The following applies to the adversarial samples methods (i.e., advs), obtained from the cost function (21); the generalization to both adversarial samples and labels (i.e., advs,l) using (23) is described following Algorithm 1.\n1. Inner Maximizer Objective with Adversarial Samples (see Eq. 22):\nAs(x, x\u0303, y, \u03bb, \u03b8) := \u03bb \u22121CE(\u03d5\u03b8(x\u0303), y)\u2212 L\u2225x\u2212 x\u0303\u2225q . (96)\n2. Inner Maximizer Objective with Adversarial Labels and Samples (see Eq. 24):\nAs,l(x, x\u0303, y, y\u0303, \u03bb, \u03b8) := \u03bb \u22121(CE(\u03d5\u03b8(x\u0303), p\u0303)\u2212 CE(y\u0303, p\u0303))\u2212 L\u2225x\u2212 x\u0303\u2225q \u2212Kg\u03b4(1\u2212 p\u0303k) , (97)\nwhere g\u03b4(z) = z/(1\u2212 z/\u03b4), p\u0303 = Softmax(y\u0303) is the adversarial label probability-vector, y = 1k is a one-hot encoded label corresponding to the class being k, and p\u0303k is the k\u2019th component of p\u0303.\n3. KL-Divergence Outer Minimizer Objective (see Eq. 16):\nAKLw (x, x\u0303, y, \u03bb, \u03b8) := \u03f5\u03bb+ \u03bb log\n( 1\nB B\u2211 i=1 exp(As(xi, x\u0303i, yi, \u03bb, \u03b8))\n) . (98)\n4. f -Divergence Outer Minimizer Objective (see Eq. 15):\nAfw(x, x\u0303, y, \u03bb, \u03c1, \u03b8) := \u03f5\u03bb+ \u03c1+ \u03bb 1\nB B\u2211 i=1 f\u2217(As(xi, x\u0303i, yi, \u03bb, \u03b8)\u2212 \u03c1/\u03bb) . (99)\nIn the examples in Section 3 we use the \u03b1-divergences, for which f\u2217\u03b1 is given in (29).\nLines 3-8 of Algorithm 1 implement the inner maximizer, wherein the adversarial samples x\u0303i are constructed, and lines 9-15 implement one step of the outer minimizer. To incorporate adversarial labels into Algorithm 1 one can make the following modifications. First, after line 4 in Algorithm 1 add the initialization\ny\u0303i \u2190 log((Nc \u2212 1)(2\u2212 \u03b4)/\u03b4)yi , (100) where Nc is the total number of classes and yi is the one-hot encoded label for the sample xi; this corresponds to initializing the adversarial label probabilities so that the probability of the given class is 1\u2212 \u03b4/2, with the remaining probability-mass equally distributed over the other classes (other initialization strategies are certainly possible, but we did not experiment with any alternatives). Second, within the inner maximizer replace As in line 6 with As,l (97) and after line 6 add the update\ny\u0303i \u2190 y\u0303i + lry\u0303\u2207y\u0303As,l(xi, x\u0303i, yi, y\u0303i, \u03bb, \u03b8) . (101)\nAlgorithm 1 Adversarially Robust Deep Learning Models with Optimal-Transport-Regularized Divergences (ARMORD)\nInput: Labeled training data {xi, yi}, target model \u03d5\u03b8 depending on NN-parameters \u03b8, number of training epochs N , minibatch size B, information divergence D (D = KL or D = Df ), number of inner maximizer iterations M , learning rates lrx\u0303, lr\u03bb, and lr\u03b8, other hyperparameters listed in Appendix C.4. Output: robustified model \u03d5\u03b8 1: for n = 1, . . . , N do 2: Sample a minibatch Bn 3: for (xi, yi) \u2208 Bn do 4: x\u0303i \u2190 xi 5: for m = 1, . . . ,M do 6: x\u0303i \u2190 x\u0303i + lrx\u0303\u2207x\u0303As(xi, x\u0303i, yi, \u03bb, \u03b8) \u25b7 See (96) 7: end for 8: end for 9: if D = KL then 10: \u03bb\u2190 \u03bb\u2212 lr\u03bb\u2207\u03bbAKLw (x, x\u0303, y, \u03bb, \u03b8) \u25b7 See (98) 11: \u03b8 \u2190 \u03b8 \u2212 lr\u03b8\u2207\u03b8AKLw (x, x\u0303, y, \u03bb, \u03b8) 12: else if D = Df then 13: (\u03bb, \u03c1)\u2190 (\u03bb, \u03c1)\u2212 lr\u03bb\u2207(\u03bb,\u03c1)Afw(x, x\u0303, y, \u03bb, \u03c1, \u03b8) \u25b7 See (99) 14: \u03b8 \u2190 \u03b8 \u2212 lr\u03b8\u2207\u03b8Afw(x, x\u0303, y, \u03bb, \u03c1, \u03b8) 15: end if 16: end for\nFinally, in the outer minimizers, replace As with As,l (97) in the definitions of AKLw (98) in lines 10-11 and A f w (99) in lines 13-14.\nThe modifications to Algorithm 1 (specifically, to the outer minimizers) that yield the adv + nat and adva methods are outlined in Appendices C.5 and C.6 respectively below.\nFail-safe Mechanisms Used in Training In our implementation we adopted the following two fail-safe mechanisms to ensure that quantities remain in their specified domains:\n\u2022 In the rare instance that \u03bb becomes negative due to large learning rates, we used a fail-safe mechanism in which we applied the Softplus function, Softplus(z) = log(1 + exp(z)) to \u03bb to ensure it remains positive during the learning process.\n\u2022 advs,l methods: In the rare event that in (24) we obtain p\u0303k \u2264 1 \u2212 \u03b4 (where y = 1k is the one-hot encoded label) due to large learning rates in updating y\u0303 (where p\u0303 = Softmax(y\u0303)) we override the updated value by resetting it to the same value used to initialize the adversarial training loop; see (100)."
        },
        {
            "heading": "C.3 Target Networks\u2019 Structure",
            "text": "The malware detector is a feed-forward neural network with 3 hidden layers each with 300 ReLU-activated neurons. The output layer uses a negative log-likelihood loss and training of the NN-parameters was done using the ADAM optimization with a 0.001 learning rate, a minibatch of size 16, learned over 150 epochs Al-Dujaili et al. (2018). Following Kolter & Madry (2018); Madry et al. (2018), the image detector is a 4-layer CNN with 32, 32, 64, and 64 square filter of size 3 in each hidden layer with ReLU activations, trained with SGD optimizer over 10 epochs (with a learning rate of 1e\u2212 1 for the first 4 epochs and a reduced learning rate of 1e\u2212 2 afterwards), and minibatch of size 100."
        },
        {
            "heading": "C.4 Parameter Search Space and Selected Hyperparameters",
            "text": "1. The distribution neighborhood size \u03f5 > 0 in (15)-(16): The value was selected from \u03f5 \u2208 {1e\u2212 4, 2e\u2212 4, 4e\u2212 4, 5e\u2212 4, 6e\u2212 4, 7e\u2212 4, 8e\u2212 4, 1e\u2212 3, 2e\u2212 3, 4e\u2212 3, 5e\u2212 3, 6e\u2212 3, 7e\u2212 3, 8e\u2212 3, 1e\u2212 2, 2e\u2212 2, 4e\u2212 2, 5e\u2212 2, 6e\u2212 2, 7e\u2212 2, 8e\u2212 2, 1e\u2212 1, 2e\u2212 1, 4e\u2212 1, 5e\u2212 1, 6e\u2212 1, 7e\u2212 1, 8e\u2212 1, 1e\u2212 2, 1e\u2212 1, 1.0, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 10.0}.\n2. The coefficient L > 0 in the cost functions (21) and (23): The value was selected from L \u2208 {1e\u2212 5, 2e\u2212 5, 5e\u2212 5, 8e\u2212 5, 1e\u2212 4, 2e\u2212 4, 5e\u2212 4, 8e\u2212 4, 1e\u2212 3, 2e\u2212 3, 5e\u2212 3, 8e\u2212 3, 1e\u2212 2, 2e\u2212 2, 3e\u2212 2, 5e\u2212 2, 8e\u2212 2, 1e\u2212 1, 2e\u2212 1, 5e\u2212 1, 8e\u2212 1, 1.0, 2.0, 5.0, 10.0}.\n3. The coefficient K > 0 in the cost function (23): The value was selected from K \u2208 {2e \u2212 3, 5e \u2212 3, 8e \u2212 3, 2e \u2212 2, 5e \u2212 2, 8e \u2212 2, 2e \u2212 1, 5e \u2212 1, 8e \u2212 1, 1.0, 1.5e1, 5e1, 8e1, 1e2, 1.5e2, 2e2, 4.5e2, 5e2, 1e3}\n4. The parameter \u03b4 in the cost function (23): The value was selected from \u03b4 \u2208 {1e\u2212 1, 2e\u2212 1, 3e\u2212 1, 4e\u2212 1}\n5. The power q > 0 in the cost functions (21) and (23): The value was selected from q \u2208 {0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 4.0, 5.0}.\n6. The \u03b1-divergence parameter (28), \u03b1 > 1: The value was selected from \u03b1 \u2208 {1.5, 1.8, 2.0, 2.5, 3.0, 3.5, 4.0, 5.0, 6.0}.\n7. The vector norm in the cost functions (21) and (23) was selected from \u21131, \u21132, and \u2113\u221e. 8. The learning rate lr\u03bb used for both \u03bb and \u03c1, the real parameters in the outer minimizers (15) and (16):\nThe value was selected from lr\u03bb \u2208 {2e\u2212 4, 5e\u2212 4, 8e\u2212 4, 2e\u2212 3, 5e\u2212 3, 8e\u2212 3, 2e\u2212 2, 5e\u2212 2, 8e\u2212 2, 1e\u2212 1, 2e\u2212 1}\n9. The coefficient t \u2208 [0, 1] for the loss of original samples (1\u2212 t denotes the coefficient for the loss of adversarial samples) in the nat methods (see Appendix C.5): The value was selected from t \u2208 {1e\u2212 1, 2e\u2212 1, . . . , 9e\u2212 1}.\nFor the asymmetric methods (see Appendix C.6) we always use s = 1/2 and did not test other values. Following Kolter & Madry (2018), the step size parameter for learning x\u0303 in the inner maximizer for all MNIST experiments was fixed to 0.01. Following Al-Dujaili et al. (2018), this parameter was fixed to 0.02 for all malware experiments. In experiments with adversarial labels, i.e., ARMOR\u03b1 (advs,l) and ARMOR\u03b1 (advs,l + nat), the step size for learning y\u0303 was the same as for x\u0303 in all cases (i.e., 0.01 for MNIST and 0.02 for malware)."
        },
        {
            "heading": "C.4.1 Hyperparameters in Image Experiments for Enhancing Adversarial Robustness: Table 1",
            "text": "\u2022 ARMORKL (advs): \u03f5 = 5e\u2212 4, L = 1e\u2212 1, q = 1.5, lr\u03bb = 2e\u2212 4, and \u21132 norm. \u2022 ARMORKL (advs + nat): \u03f5 = 1.0, L = 8e\u2212 2, q = 2.0, lr\u03bb = 2e\u2212 3, t = 0.5, and \u2113\u221e norm. \u2022 ARMOR\u03b1 (advs): \u03f5 = 6e\u2212 4, L = 1e\u2212 1, q = 2.0, \u03b1 = 2.0, lr\u03bb = 5e\u2212 4, and \u21132 norm. \u2022 ARMOR\u03b1 (advs + nat): \u03f5 = 2.0, L = 3e\u2212 2, q = 1.5, lr\u03bb = 8e\u2212 4, \u03b1 = 2.5, t = 0.5, and \u2113\u221e norm. \u2022 ARMOR\u03b1 (advs,l + nat): \u03f5 = 3.0, L = 3e \u2212 2, q = 1.5, lr\u03bb = 8e \u2212 4, \u03b1 = 2.5, t = 0.5, and \u21132 norm, \u03b4 = 0.1, K = 8e\u2212 2."
        },
        {
            "heading": "C.4.2 Hyperparameters in Image Experiments for Enhancing Test Generalizability: Table 3",
            "text": "\u2022 ARMORKL (advs): \u03f5 = 5e\u2212 4, L = 1e\u2212 1, q = 1.5, lr\u03bb = 2e\u2212 4, and \u21132 norm. \u2022 ARMORKL (advs + nat): \u03f5 = 4e\u2212 3, L = 8e\u2212 3, q = 2.0, lr\u03bb = 2e\u2212 3, t = 0.5, and \u21132 norm. \u2022 ARMOR\u03b1 (advs): \u03f5 = 5e\u2212 4, L = 1e\u2212 1, q = 2.5, \u03b1 = 5.0, lr\u03bb = 5e\u2212 4, and \u21132 norm. \u2022 ARMOR\u03b1 (advs + nat): \u03f5 = 2.0, L = 3e\u2212 2, q = 1.5, lr\u03bb = 8e\u2212 4, \u03b1 = 2.5, t = 0.5, and \u2113\u221e norm. \u2022 ARMOR\u03b1 (advs,l+nat): \u03f5 = 3.0, L = 3e\u22122, q = 1.5, lr\u03bb = 8e\u22124, \u03b1 = 2.5, t = 0.5, \u2113\u221e norm, \u03b4 = 0.1,\nand K = 8e\u2212 2."
        },
        {
            "heading": "C.4.3 Hyperparameters in Malware Experiments for Enhancing Adversarial Robustness: Table 2",
            "text": "\u2022 ARMORKL (advs): \u03f5 = 1e\u2212 1, L = 1e\u2212 2, q = 2.0, lr\u03bb = 2e\u2212 3, and \u2113\u221e norm. \u2022 ARMORKL (advas ): \u03f5 = 1e\u2212 2, L = 5e\u2212 3, q = 1.5, lr\u03bb = 2e\u2212 3, and \u2113\u221e norm. \u2022 ARMORKL (advs + nat): \u03f5 = 1e\u2212 1, L = 1e\u2212 2, q = 2.0, lr\u03bb = 2e\u2212 4, t = 0.5, and \u2113\u221e norm. \u2022 ARMORKL (advas + nat): \u03f5 = 3.5, L = 1e\u2212 3, q = 2.0, lr\u03bb = 8e\u2212 3, t = 0.5, and \u2113\u221e norm. \u2022 ARMOR\u03b1 (advs): \u03f5 = 3.0, L = 3e\u2212 2, q = 2.0, \u03b1 = 2.5, lr\u03bb = 8e\u2212 4, and \u2113\u221e norm. \u2022 ARMOR\u03b1 (advas ): \u03f5 = 1e\u2212 2, L = 1e\u2212 2, q = 2.0, \u03b1 = 1.5, lr\u03bb = 2e\u2212 4, and \u2113\u221e norm. \u2022 ARMOR\u03b1 (advs + nat): \u03f5 = 3.0, L = 3e\u2212 2, q = 1.5, lr\u03bb = 8e\u2212 4, \u03b1 = 2.5, t = 0.5, and \u2113\u221e norm. \u2022 ARMOR\u03b1 (advas + nat): \u03f5 = 3.0, L = 1e\u2212 3, q = 2.0, lr\u03bb = 8e\u2212 4, \u03b1 = 2.5, t = 0.5, and \u2113\u221e norm. \u2022 ARMOR\u03b1 (advs,l): \u03f5 = 3.0, L = 3e\u2212 2, q = 2.0, lr\u03bb = 8e\u2212 4, \u03b1 = 2.5, t = 0.5, \u2113\u221e norm, \u03b4 = 0.4, and K = 450."
        },
        {
            "heading": "C.4.4 Hyperparameters in Malware Experiments for Enhancing Test Generalizability: Table 4",
            "text": "\u2022 ARMORKL (advs): \u03f5 = 7e\u2212 1, L = 5e\u2212 5, q = 2.0, lr\u03bb = 2e\u2212 3, and \u21131 norm. \u2022 ARMORKL (advas ): \u03f5 = 1e\u2212 2, L = 5e\u2212 3, q = 1.5, lr\u03bb = 2e\u2212 3, and \u21131 norm. \u2022 ARMORKL (advs + nat): \u03f5 = 2e\u2212 1, L = 5e\u2212 5, q = 2.0, lr\u03bb = 2e\u2212 4, t = 0.5, and \u21131 norm. \u2022 ARMORKL (advas + nat): \u03f5 = 3.5, L = 1e\u2212 3, q = 2.0, lr\u03bb = 8e\u2212 3, t = 0.5, and \u2113\u221e norm. \u2022 ARMOR\u03b1 (advs): \u03f5 = 3.0, L = 3e\u2212 2, q = 2.0, \u03b1 = 2.5, lr\u03bb = 8e\u2212 4, and \u2113\u221e norm. \u2022 ARMOR\u03b1 (advas ): \u03f5 = 2e\u2212 1, L = 5e\u2212 5, q = 2.0, \u03b1 = 2.5, lr\u03bb = 2e\u2212 4, and \u21131 norm. \u2022 ARMOR\u03b1 (advs + nat): \u03f5 = 7e\u2212 1, L = 1e\u2212 2, q = 2.0, lr\u03bb = 2e\u2212 4, \u03b1 = 2.5, t = 0.5, and \u2113\u221e norm. \u2022 ARMOR\u03b1 (advas + nat): \u03f5 = 4e\u2212 1, L = 5e\u2212 5, q = 2.0, lr\u03bb = 2e\u2212 4, \u03b1 = 2.5, t = 0.5, and \u21131 norm. \u2022 ARMOR\u03b1 (advs,l): \u03f5 = 4e \u2212 1, L = 5e \u2212 5, q = 2.0, lr\u03bb = 2e \u2212 4, \u03b1 = 2.5, t = 0.5, \u21131 norm, \u03b4 = 0.4,\nand K = 150."
        },
        {
            "heading": "C.5 Robust Optimization Using a Mixture of Adversarial and Natural Samples",
            "text": "The best performance in the experiments presented in Section 3 was often obtained using a mixture of adversarial samples along with the original training data (called the natural samples) and their corresponding losses. This can be viewed as DRO over distribution neighborhoods of the form\nUD c\n\u03f5,t (Pn) := {tPn + (1\u2212 t)Q : Dc(Q\u2225Pn) \u2264 \u03f5} , \u03f5 > 0, t \u2208 (0, 1) , (102)\nas we have\ninf \u03b8\u2208\u0398 sup Q\u2208UDc\u03f5,t (Pn) EQ[L\u03b8] = inf \u03b8\u2208\u0398\n{ tEPn [L\u03b8] + (1\u2212 t) sup\nQ:Dc(Q\u2225Pn)\u2264\u03f5 EQ[L\u03b8]\n} . (103)\nThe supremum over Q on the right-hand side of (103) can then be evaluated by the method discussed in Section 2 and the resulting expression is used in what we call the adv+ nat methods. More specifically, the advs variants refer to the use of adversarial samples constructed via the OT-regularized loss (22) while advs,l refers to the use of adversarial samples together with adversarial labels, both of which are constructed via the OT-regularized loss (24)."
        },
        {
            "heading": "C.6 Asymmetric Robust Optimization",
            "text": "In many cases the training samples are naturally partitioned into distinct components, with corresponding empirical distributions Pn,0 and Pn,1 (e.g., distinct class labels), and one wishes to robustify only one component of the partition (e.g., to protect against false negative adversarial attacks but not false positives). In such cases one can formulate the DRO problem in an asymmetric manner as follows. Define the baseline distribution Pn,s = (1\u2212 s)Pn,0 + sPn,1 for some s \u2208 (0, 1) and define the distribution neighborhoods\nUa,D c\n\u03f5 (Pn,s) := {(1\u2212 s)Pn,0 + sQ : Dc(Q\u2225Pn,1) \u2264 \u03f5} . (104)\nThe corresponding DRO problem can be rewritten as\ninf \u03b8\u2208\u0398 sup Q\u2208Ua,D c \u03f5 (Pn,s) EQ[L\u03b8] = inf \u03b8\u2208\u0398\n{ (1\u2212 s)EPn,0 [L\u03b8] + s sup\nQ:Dc(Q\u2225Pn,1)\u2264\u03f5 EQ[L\u03b8]\n} , (105)\nwhere one can clearly see that the objective on the right-hand side is non-robust in Pn,0 but uses OT-regularizeddivergence robust optimization for the Pn,1 component. The parameter s weights the relative importance of the partition components in the overall loss; it can be chosen to correspond to the relative sizes of the partition components (i.e., so that Pn,s = Pn) or it can be used as a hyperparameter. The supremum over Q on the right-hand side of (105) can be evaluated by the method discussed in Section 2 and the resulting expression is used in what we call the adva methods. Similar to the notation in Appendix C.5, the advas variants refer to the use of adversarial samples constructed via the OT-regularized loss (22) while advas,l refers to the use of adversarial samples together with adversarial labels, both of which are constructed via the OT-regularized loss (24). This method can easily be extended to partitions with more than two components, though we only utilize two components in Section 3.\nAsymmetric Robust Optimization Using a Mixture of Adversarial and Natural Samples: One can combine asymmetry with the use of natural samples. To do this, choose a mixing parameter t \u2208 (0, 1) and define the distribution\nneighborhoods\nUa,D c\n\u03f5,t (Pn,s) :={tPn,s + (1\u2212 t)((1\u2212 s)Pn,0 + sQ) : Dc(Q\u2225Pn,1) \u2264 \u03f5} (106) ={(1\u2212 s)Pn,0 + tsPn,1 + (1\u2212 t)sQ : Dc(Q\u2225Pn,1) \u2264 \u03f5} .\nThe corresponding DRO problem can be rewritten as\ninf \u03b8\u2208\u0398 sup Q\u2208Ua,D c\n\u03f5,t (Pn,s)\nEQ[L\u03b8] (107)\n= inf \u03b8\u2208\u0398\n{ (1\u2212 s)EPn,0 [L\u03b8] + tsEPn,1 [L\u03b8] + (1\u2212 t)s sup\nQ:Dc(Q\u2225Pn,1)\u2264\u03f5 EQ[L\u03b8]\n} .\nOnce again, the supremum over Q on the right-hand side can be evaluated by the method discussed in Section 2 and the resulting expression is used in what we call the adva + nat methods.\nC.7 Interpolating between OT-Regularized-Df and OT Methods\nHere we describe a general procedure for modifying an f -divergence into a one-parameter family, Df\u03b2 , so that the resulting OT-regularized-Df\u03b2 method interpolates between OT DRO and OT-regularized-Df DRO. In particular, this enables us to examine the effect of \"turning off\" the information divergence component of the method, i.e., the adversarial sample weights (see Appendix B).\nGiven an f -divergence, Df , and \u03b2 \u2208 (0, 1] define\nf\u03b2(z) = \u03b2f((z \u2212 1 + \u03b2)/\u03b2) , (108)\n(not to be confused with the \u03b1-divergences, Eq. 28). The f\u03b2 are convex and f\u03b2(1) = 0 for all \u03b2, hence Df\u03b2 is a well-defined family of divergences with \u03b2 = 1 giving the original f -divergence. It is straightforward to compute the Legendre transform of f\u03b2 in terms of that of f ,\nf\u2217\u03b2(z) = \u03b2f \u2217(z) + (1\u2212 \u03b2)z . (109)\nTherefore one can use f\u03b2 to define an OT-regularized-divergence DRO problem and simplify it as follows\ninf \u03b8\u2208\u0398 sup Q:Dcf\u03b2 (Q\u2225Pn)\u2264\u03f5 EQ[L\u03b8] (110)\n= inf \u03bb>0,\u03c1\u2208R,\u03b8\u2208\u0398\n{ \u03f5\u03bb+ \u03b2(\u03c1+ \u03bb 1\nn n\u2211 i=1 f\u2217(Lc\u03b8,\u03bb(xi)\u2212 \u03c1/\u03bb)) + (1\u2212 \u03b2)\u03bb 1 n n\u2211 i=1 Lc\u03b8,\u03bb(xi)\n} .\nAs \u03b2 \u2192 0+ the objective function in (110) approaches that of OT-DRO and so (110) can be thought of as a mixture of OT DRO and OT-regularized-Df DRO. Moreover, the mixing parameter \u03b2 sets a lower bound on the adversarial sample weights (89), with pi \u2265 (1\u2212 \u03b2)/n. In the KL case one can evaluate the infimum over \u03c1 in (110) to obtain\ninf \u03b8\u2208\u0398 sup Q:KLc\u03b2(Q\u2225Pn)\u2264\u03f5\nEQ[L\u03b8] (111)\n= inf \u03bb>0,\u03b8\u2208\u0398\n{ \u03f5\u03bb+ \u03b2\u03bb log ( 1\nn n\u2211 i=1 exp(Lc\u03b8,\u03bb(xi))\n) + (1\u2212 \u03b2)\u03bb 1\nn n\u2211 i=1 Lc\u03b8,\u03bb(xi)\n} .\nWhen Df is an \u03b1-divergence we denote the method (110) by ARMOR\u03b1,\u03b2 . We denote the method (111) by ARMORKL\u03b2 . In our tests on MNIST we found that the performance degrades significantly as \u03b2 decreases to 0, both in terms of adversarial robustness or performance generalizability (see Figure 2). This implies that the information divergence, and the adversarial sample weights which it generates, contributes non-trivially to the success of the method."
        },
        {
            "heading": "D Additional Experiments",
            "text": "In this section, we present the results of our experiments where ARMORD\u2019s hyperparameters are tuned with the goal of enhancing performance generalizability on the test set. Table 3 and Table 4 summarize these results on MNIST and the malware dataset, respectively. As shown in Table 3, on MNIST, our proposed ARMOR\u03b1 (advs + nat) achieves the accuracy of 99.30%, FNR of 0.70%, and FPR of 0.08%, outperforming all benchmark methods across all three evaluation metrics. ARMOR\u03b1 (advs,l + nat) yields the second best performance generalizability (99.28% accuracy, 0.73% FNR, and 0.08% FPR). Additionally, it is observed that in almost all cases, the performance under attack is also improved as a result of adversarial training with our proposed method. As observed in Table 4, on the malware dataset, our proposed ARMOR\u03b1 (advs,l) achieves the accuracy of 93.9%, FNR of 5.19% and FPR of 9.97% outperforming the benchmark methods and the non-robust methods across all three evaluation metrics.\nNote: Best metrics are shown in bold font. The numbers for methods that outperform the non-robust model and prior adversarial robustness methods across all three metrics are underlined.\nNote: Best metrics are shown in bold font. The numbers for methods that outperform the non-robust model and prior adversarial robustness methods across all three metrics are underlined."
        }
    ],
    "title": "ADVERSARIALLY ROBUST DEEP LEARNING WITH OPTIMAL-TRANSPORT-REGULARIZED DIVERGENCES",
    "year": 2023
}