{
    "abstractText": "We design and evaluate a mixed reality real-time communication system for remote assistance during CPR emergencies. Our system allows an expert to guide a first responder, remotely, on how to give first aid. RGBD cameras capture a volumetric view of the local scene including the patient, the first responder, and the environment. The volumetric capture is augmented onto the remote expert\u2019s view to spatially guide the first responder using visual and verbal instructions. We evaluate the mixed reality communication system in a research study in which participants face a simulated emergency. The first responder moves the patient to the recovery position and performs chest compressions as well as mouth-to-mask ventilation. Our study compares mixed reality against videoconferencing-based assistance using CPR performance measures, cognitive workload surveys, and semi-structured interviews. We find that more visual communication including gestures and objects is used by the remote expert when assisting in mixed reality compared to videoconferencing. Moreover, the performance and the workload of the first responder during simulation do not differ significantly between the two technologies.",
    "authors": [
        {
            "affiliations": [],
            "name": "Manuel Rebol"
        },
        {
            "affiliations": [],
            "name": "Alexander Steinmaurer"
        },
        {
            "affiliations": [],
            "name": "Florian Gamillscheg"
        },
        {
            "affiliations": [],
            "name": "Krzysztof Pietroszek"
        },
        {
            "affiliations": [],
            "name": "Christian G\u00fctl"
        },
        {
            "affiliations": [],
            "name": "Colton Hood"
        },
        {
            "affiliations": [],
            "name": "Adam Rutenberg"
        }
    ],
    "id": "SP:e5363c49a9f31d15b8a97a7e9516f39535e5e5c5",
    "references": [
        {
            "authors": [
                "B. Abella",
                "J. Alvarado",
                "H. Myklebust",
                "D. Edelson",
                "A. Barry",
                "N. O\u2019Hearn",
                "T. Hoek",
                "L. Becker"
            ],
            "title": "Quality of cardiopulmonary resuscitation during in-hospital cardiac arrest",
            "venue": "The journal of the American Medical Association 293, 305\u201310",
            "year": 2005
        },
        {
            "authors": [
                "D. Andersen",
                "V. Popescu",
                "M. Cabrera",
                "A. Shanghavi",
                "B. Mullis",
                "S. Marley",
                "G. Gomez",
                "J. Wachs"
            ],
            "title": "An augmented reality-based approach for surgical telementoring in austere environments",
            "venue": "Military Medicine 182, 310\u2013315",
            "year": 2017
        },
        {
            "authors": [
                "D. Anton",
                "G. Kurillo",
                "A.Y. Yang",
                "R. Bajcsy"
            ],
            "title": "Augmented telemedicine platform for real-time remote medical consultation",
            "venue": "MultiMedia Modeling: 23rd International Conference, MMM 2017, Reykjavik, Iceland, January 4-6, 2017, Proceedings, Part I 23. pp. 77\u201389. Springer",
            "year": 2017
        },
        {
            "authors": [
                "R. Azuma",
                "Y. Baillot",
                "R. Behringer",
                "S. Feiner",
                "S. Julier",
                "B. MacIntyre"
            ],
            "title": "Recent advances in augmented reality",
            "venue": "IEEE Computer Graphics and Applications 21(6), 34\u201347",
            "year": 2001
        },
        {
            "authors": [
                "E. Barsom",
                "M. Graafland",
                "M. Schijven"
            ],
            "title": "Systematic review on the effectiveness of augmented reality applications in medical training",
            "venue": "Surgical Endoscopy 30",
            "year": 2016
        },
        {
            "authors": [
                "W. Birkfellner",
                "M. Figl",
                "K. Huber",
                "F. Watzinger",
                "F. Wanschitz",
                "J. Hummel",
                "R. Hanel",
                "W. Greimel",
                "P. Homolka",
                "R. Ewers",
                "H. Bergmann"
            ],
            "title": "A head-mounted operating binocular for augmented reality visualization in medicine - design and initial evaluation",
            "venue": "IEEE Transactions on Medical Imaging 21(8), 991\u2013997",
            "year": 2002
        },
        {
            "authors": [
                "T. Blome",
                "A. Diefenbach",
                "S. Rudolph",
                "K. Bucher",
                "S. von Mammen"
            ],
            "title": "Vreanimate \u2014 non-verbal guidance and learning in virtual reality",
            "venue": "Proocedings of the International Conference on Virtual Worlds and Games for Serious Applications (VS-Games). pp. 23\u201330",
            "year": 2017
        },
        {
            "authors": [
                "J. Carmigniani",
                "B. Furht",
                "M. Anisetti",
                "P. Ceravolo",
                "E. Damiani",
                "M. Ivkovic"
            ],
            "title": "Augmented reality technologies, systems and applications",
            "venue": "Multimedia Tools and Applications 51, 341\u2013377",
            "year": 2010
        },
        {
            "authors": [
                "D. Cave",
                "T. Aufderheide",
                "J. Beeson",
                "A. Ellison",
                "A. Gregory",
                "M. Hazinski",
                "L. Hiratzka",
                "K. Lurie",
                "L. Morrison",
                "V. Mosesso",
                "V. Nadkarni",
                "J. Potts",
                "R. Samson",
                "M. Sayre",
                "S. Schexnayder"
            ],
            "title": "Importance and implementation of training in cardiopulmonary resuscitation and automated external defibrillation in schools a science advisory from the american heart association",
            "venue": "Circulation 123, 691\u2013706",
            "year": 2011
        },
        {
            "authors": [
                "A. Cheng",
                "F. Overly",
                "D. Kessler",
                "V.M. Nadkarni",
                "Y. Lin",
                "Q. Doan",
                "J.P. Duff",
                "N.M. Tofil",
                "F. Bhanji",
                "M. Adler",
                "A. Charnovich",
                "E.A. Hunt",
                "L.L. Brown"
            ],
            "title": "Perception of cpr quality: Influence of cpr feedback, just-in-time cpr training and M. Rebol et al., \u201dCPR Emergency Assistance Through Mixed Reality Communication\u201d The Version of Record of this contribution is published in Augmented Intelligence and Intelligent Tutoring Systems and is available online at https://doi.org/10.1007/978-3-031-32883-1",
            "venue": "M. Rebol et al. provider role. Resuscitation",
            "year": 2015
        },
        {
            "authors": [
                "A. Christopoulos",
                "N. Pellas",
                "J. Kurczaba",
                "R. Macredie"
            ],
            "title": "The effects of augmented reality-supported instruction in tertiary-level medical education",
            "venue": "British Journal of Educational Technology 53(2), 307\u2013325",
            "year": 2022
        },
        {
            "authors": [
                "T. Coles",
                "N. John",
                "D. Gould",
                "D. Caldwell"
            ],
            "title": "Integrating haptics with augmented reality in a femoral palpation and needle insertion training simulation",
            "venue": "IEEE T. Haptics 4, 199\u2013209",
            "year": 2011
        },
        {
            "authors": [
                "M. Duarte",
                "L. Santos",
                "J. Guimar\u00e3es J\u00fanior",
                "M. Peccin"
            ],
            "title": "Learning anatomy by virtual reality and augmented reality. a scope review",
            "venue": "Morphologie 104(347),",
            "year": 2020
        },
        {
            "authors": [
                "J. Fromm",
                "M. Mirbabaie",
                "S. Stieglitz"
            ],
            "title": "The potential of augmented reality for improving occupational first aid",
            "venue": "Proceedings of the International Conference on Wirtschaftsinformatik",
            "year": 2019
        },
        {
            "authors": [
                "T.H. Fr\u00f8land",
                "I. Heldal",
                "E. Ersv\u00e6r",
                "G. Sj\u00f8holt"
            ],
            "title": "State-of-the-art and future directions for using augmented reality head mounted displays for first aid live training",
            "venue": "Proceedings of the International Conference on e-Health and Bioengineering (EHB). pp. 1\u20136",
            "year": 2020
        },
        {
            "authors": [
                "E.J. Gallagher",
                "G. Lombardi",
                "P. Gennis"
            ],
            "title": "Effectiveness of Bystander Cardiopulmonary Resuscitation and Survival Following Out-of-Hospital Cardiac Arrest",
            "venue": "The journal of the American Medical Association 274(24), 1922\u20131925",
            "year": 1995
        },
        {
            "authors": [
                "E. Girau",
                "F. Mura",
                "S. Bazurro",
                "M. Casadio",
                "M. Chirico",
                "F. Solari",
                "M. Chessa"
            ],
            "title": "A mixed reality system for the simulation of emergency and first-aid scenarios",
            "venue": "Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). pp. 5690\u20135695",
            "year": 2019
        },
        {
            "authors": [
                "D. Harris",
                "M. Wilson",
                "S. Vine"
            ],
            "title": "Development and validation of a simulation workload measure: the simulation task load index (sim-tlx)",
            "venue": "Virtual Reality 24(4),",
            "year": 2020
        },
        {
            "authors": [
                "S.G. Hart",
                "L.E. Staveland"
            ],
            "title": "Development of nasa-tlx (task load index): Results of empirical and theoretical research",
            "venue": "Human mental workload 1(3), 139\u2013183",
            "year": 1988
        },
        {
            "authors": [
                "J. Johnson",
                "D. Rodrigues",
                "G. Madhuri",
                "N. Weibel"
            ],
            "title": "Holocpr: Designing and evaluating a mixed reality interface for time-critical emergencies",
            "venue": "Proceedings of the EAI International Conference. pp. 67\u201376",
            "year": 2018
        },
        {
            "authors": [
                "C. Kamphuis",
                "E. Barsom",
                "M. Schijven",
                "L. Christoph"
            ],
            "title": "Augmented reality in medical education? Perspectives on medical education",
            "year": 2014
        },
        {
            "authors": [
                "M. Kim",
                "J. Park",
                "N. Rhee",
                "S. Je",
                "S. Hong",
                "Y. Lee",
                "Chung",
                "s.p.",
                "S. Kim"
            ],
            "title": "Efficacy of veinviewer in pediatric peripheral intravenous access: A randomized controlled trial",
            "venue": "European journal of pediatrics 171, 1121\u20135",
            "year": 2012
        },
        {
            "authors": [
                "K. Kuyt",
                "S.H. Park",
                "T.P. Chang",
                "T. Jung",
                "R. MacKinnon"
            ],
            "title": "The use of virtual reality and augmented reality to enhance cardio-pulmonary resuscitation: a scoping review",
            "venue": "Advances in Simulation 6(1),",
            "year": 2021
        },
        {
            "authors": [
                "Laerdal"
            ],
            "title": "Little anne qcpr",
            "venue": "https://laerdal.com/us/products/ simulation-training/resuscitation-training/little-anne-qcpr/",
            "year": 2022
        },
        {
            "authors": [
                "C. Lin",
                "D. Andersen",
                "V. Popescu",
                "E. Rojas-Mu\u00f1oz",
                "M.E. Cabrera",
                "B. Mullis",
                "B. Zarzaur",
                "K. Anderson",
                "S. Marley",
                "J. Wachs"
            ],
            "title": "A first-person mentee secondperson mentor ar interface for surgical telementoring",
            "venue": "Proceedings of the IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMARAdjunct). pp. 3\u20138",
            "year": 2018
        },
        {
            "authors": [
                "N. Mahmud",
                "J. Cohen",
                "K. Tsourides",
                "T. Berzin"
            ],
            "title": "Computer vision and augmented reality in gastrointestinal endoscopy",
            "venue": "Gastroenterology Report 3",
            "year": 2015
        },
        {
            "authors": [
                "D. Mizell"
            ],
            "title": "Augmented reality applications in aerospace",
            "venue": "Proceedings of the IEEE and ACM International Symposium on Augmented Reality",
            "year": 2000
        },
        {
            "authors": [
                "A. Nee",
                "S. Ong",
                "G. Chryssolouris",
                "D. Mourtzis"
            ],
            "title": "Augmented reality applications in design and manufacturing",
            "venue": "CIRP Annals 61(2),",
            "year": 2012
        },
        {
            "authors": [
                "B.A. Ponce",
                "E.W. Brabston",
                "S. Zu",
                "S.L. Watson",
                "D. Baker",
                "D. Winn",
                "B.L. Guthrie",
                "M.B. Shenai"
            ],
            "title": "Telemedicine with mobile devices and augmented reality for early postoperative care",
            "venue": "Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society. pp. 4411\u20134414",
            "year": 2016
        },
        {
            "authors": [
                "M. Rebol",
                "C. G\u00fctl",
                "K. Pietroszek"
            ],
            "title": "Real-time gesture animation generation from speech for virtual human interaction",
            "venue": "Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. CHI EA \u201921,",
            "year": 2021
        },
        {
            "authors": [
                "M. Rebol",
                "C. G\u00fctl",
                "K. Pietroszek"
            ],
            "title": "Passing a non-verbal turing test: Evaluating gesture animations generated from speech",
            "venue": "2021 IEEE Virtual Reality and 3D User Interfaces (VR). pp. 573\u2013581",
            "year": 2021
        },
        {
            "authors": [
                "M. Rebol",
                "K. Pietroszek"
            ],
            "title": "Artificial Reality Continuum",
            "venue": "pp. 1\u20137. Springer International Publishing, Cham (2020),",
            "year": 2020
        },
        {
            "authors": [
                "M. Rebol",
                "K. Pietroszek",
                "C. Ranniger",
                "C. Hood",
                "A. Rutenberg",
                "N. Sikka",
                "C. Guetl"
            ],
            "title": "Collaborative system design of mixed reality communication for medical training",
            "venue": "Proceedings of the 56th Hawaii International Conference on System Sciences. pp. 418\u2013427",
            "year": 2023
        },
        {
            "authors": [
                "M. Rebol",
                "K. Pietroszek",
                "C. Ranniger",
                "C. Hood",
                "A. Rutenberg",
                "N. Sikka",
                "D. Li",
                "C. G\u00fctl"
            ],
            "title": "Mixed reality communication for medical procedures: Teaching the placement of a central venous catheter",
            "venue": "2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR). pp. 346\u2013354",
            "year": 2022
        },
        {
            "authors": [
                "K. Tang",
                "D. Cheng",
                "E. Mi",
                "P. Greenberg"
            ],
            "title": "Augmented reality in medical education: a systematic review",
            "venue": "Canadian Medical Education Journal 11",
            "year": 2019
        },
        {
            "authors": [
                "A. Travers",
                "T. Rea",
                "B. Bobrow",
                "D. Edelson",
                "R. Berg",
                "M. Sayre",
                "M. Berg",
                "L. Chameides",
                "R. O\u2019Connor",
                "R. Swor"
            ],
            "title": "Part 4: Cpr overview: 2010 american heart association guidelines for cardiopulmonary resuscitation and emergency cardiovascular care",
            "venue": "Circulation 122, S676\u201384",
            "year": 2010
        },
        {
            "authors": [
                "S. Wang",
                "M. Parsons",
                "J. Stone-McLean",
                "P. Rogers",
                "S. Boyd",
                "K. Hoover",
                "O. Meruvia-Pastor",
                "M. Gong",
                "A. Smith"
            ],
            "title": "Augmented reality as a telemedicine platform for remote procedural training",
            "venue": "Sensors 17, 2294",
            "year": 2017
        },
        {
            "authors": [
                "R. Zajtchuk",
                "R.M. Satava"
            ],
            "title": "Medical applications of virtual reality",
            "venue": "(sep",
            "year": 1997
        }
    ],
    "sections": [
        {
            "text": "Keywords: Mixed Reality \u00b7 CPR \u00b7 Remote collaboration."
        },
        {
            "heading": "1 Introduction",
            "text": "In recent years interest and popularity in Augmented Reality (AR) devices have increased drastically and have attracted the attention of the research world and consumers alike [8]. AR has many possible applications that range from entertainment and education to design and manufacturing [8], [21], [28]. AR can be described as a technique that augments the real world with virtual computergenerated information or content with which the user is able to interact [4] [8].\nM. Rebol et al., \u201dCPR Emergency Assistance Through Mixed Reality Communication\u201d The Version of Record of this contribution is published in Augmented Intelligence and Intelligent\nTutoring Systems and is available online at https://doi.org/10.1007/978-3-031-32883-1 38.\n1\nar X\niv :2\n31 2.\n09 15\n0v 1\n[ cs\n.H C\n] 1\nAs opposed to Virtual Reality (VR) approaches, where users are fully immersed in the virtual environment and have no connection to the real world, AR tries to superimpose virtual objects upon the user\u2019s surroundings [8]. AR technology is not restricted to head-mounted displays (HMD) but is also used in handheld devices like smartphones and tablets [4]. The virtual objects that are embedded in the real world provide information to the user, which can help in performing tasks, such as by helping workers through the electrical wire system of an aircraft [8], [27]. In the past few years AR has progressed immensely and more and more AR applications and devices have entered the market. In medicine, AR technology has enormous potential, where HMDs are for example an essential tool in computer-aided surgery (CAS) [6]. In this field, AR can provide useful information to surgeons in a less distracting manner, compared to information on a monitor [6]. In addition to surgical settings, AR has been used in endoscopic procedures [26], needle puncture procedures [22] and in training for complex surgical procedures [12]. Aside from practical applications, AR has gained a lot of attention in the field of medical education like anatomy, where teaching methods have not changed significantly over the last century. [13]. In the medical field, learning predominantly involves workplace training, which is time-consuming, not very cost-efficient, and comes with some risk [21]. AR can offer a safer learning environment, where concepts can be practiced without the fear of making errors [21]. One area where proper training is particularly important is cardiopulmonary resuscitation (CPR) [9]. Cardiac arrest is a significant public health problem, with approximately 350,000 people per year in the US and Canada alone receiving CPR [36]. Well-executed and timely CPR has a significant impact on survival and neurological outcome, which is why in 2011 the American Heart Association (AHA) published a recommendation for mandatory CPR training starting at school-age [10], [9]. However, multiple studies have shown that even when carried out by healthcare professionals, CPR quality is often poor [1], [16]. With its visual feedback, AR technology can be a valuable tool for guiding responders.\n2 M. Rebol et al., \u201dCPR Emergency Assistance Through Mixed Reality Communication\u201d The Version of Record of this contribution is published in Augmented Intelligence and Intelligent\nTutoring Systems and is available online at https://doi.org/10.1007/978-3-031-32883-1 38.\nIn this research project, we introduce a mixed reality system, where the user is guided by a remote expert in performing first aid (Figure 1). Our RGBD cameras allow for three-dimensional visual information that helps the user through the steps. Within this project, we conducted an evaluation with 30 participants separated into two groups. Both groups were given the same tasks. They had to give first aid to a lifeless person, bring the person into the recovery position, and start with CPR after the person stopped breathing. We compared instruction via the mixed reality (MR) approach (group A) with video-based communication (group B). We analyzed objective metrics of CPR quality recorded by the CPR mannequin and data from users including workload surveys and interviews. We conclude our main contributions as follows:\n1. We introduce an MR communication system designed for remote first aid assistance. 2. We conducted a comparison between MR communication technology and video-based communication. 3. The project team measured workload and performance when giving assisted first aid in MR and videoconferencing.\nThe paper is structured as follows: Section 2 gives an overview of past research on Extended Reality (XR) applications for first aid assistance. In Section 3, we discuss the design of the MR communication system, focusing on the different views and their interaction with each other and the devices and software that were used. We evaluate the presented MR communication system in a research study described in Section 4. After introducing the study procedure, we present and discuss the results that were obtained. In the end, we summarize the work and give an outlook on future work."
        },
        {
            "heading": "2 Related Work",
            "text": "Extended Reality (XR) [32] has been a valuable communication tool especially in medicine. In medical education, AR-supported instructions assist students in demanding tasks by offering a realistic learning environment in which they can develop their theoretical knowledge through didactics, as well as improve their practical skills through interactive simulation [35], [11]. In the field of telemedicine, a field that uses communication technology to diagnose and treat patients remotely, AR has developed great potential. Wang et al. [37] developed a telemedicine mentoring application using Microsoft\u2019s HoloLens. Their application allows remote experts to guide trainees through complex medical situations with hand gestures that were then displayed in the AR environment of the trainee. Their study, which examined the usability in a trauma setting revealed that their AR setup was regarded as more immersive than other telemedicine approaches. Similarly, Lin et al. [25] used AR in a surgical setting in combination with a Microsoft HoloLens. Their study, which used a lower-leg fasciotomy as a training task, revealed that participants who used the headset received a higher performance score and reported higher usability. In surgical settings, AR allows\nM. Rebol et al., \u201dCPR Emergency Assistance Through Mixed Reality Communication\u201d The Version of Record of this contribution is published in Augmented Intelligence and Intelligent\nTutoring Systems and is available online at https://doi.org/10.1007/978-3-031-32883-1 38.\n3\nsurgeons to better concentrate on the operating field in comparison to traditional telemedical approaches, where surgeons are often forced to shift their focus to screens for receiving assistance from an expert, which can result in more errors [2]. Andersen et al. [2] used a different approach, which features a tablet PC that is located between the local surgeon and the patient. The tablet captures live video that is sent to the remote expert. The remote expert can then annotate the video with graphical information, which is then sent back to the local surgeon\u2019s screen. The user study found that participants who used the AR approach completed the tasks with higher accuracy and fewer distractions. Besides surgical settings, XR technology has been also used for consultation purposes. Anton et al. [3] used a combination of AR and VR devices to build a telemedicine system for remote consultations. Their setup consists of an AR client, that captures 3D surface information of the environment, which is then transmitted to the remote expert via a communication module, which enables peer-to-peer connection. On the physician side, the VR client receives the streamed data and is responsible for the rendering on a 3D display, which allows the physician to examine the information and interact with it. In the field of postoperative care, Ponce et al. [29] used AR on mobile devices in their study to let physicians virtually examine the patient over a long distance. Their application allows users to interact with each other via mobile devices e.g. with visual annotations on the patient\u2019s screen. Their user study revealed that the 96% of the patients regarded the setup as useful, while physicians were slightly less satisfied with 89.6% of them expressing that the application was useful."
        },
        {
            "heading": "2.1 Extended Reality for First Aid Assistance",
            "text": "Multiple studies have demonstrated the potential of extended reality for assisting users in first aid. Already in 1997 Zajtchuk and Satava [38] pointed out the potential of VR for medical education. Kuyt et al. [23] included 42 articles in their review on the evolution of XR approaches for CPR training. Their study indicated that the number of both VR and AR applications for resuscitation training is rapidly growing. Due to the high rise of AR-related CPR publications and advancements in technology in recent years, the proportion of AR-related articles is expected to rise in the future. The study concludes that XR shows great potential for CPR training environments, which will likely result in innovations and novel applications. As an example, Girau1 et al. [17] proposed a VR-based training application for first aid, using an HTC Vive headset and a real mannequin to provide haptic feedback. Similarly, Blome et al. [7] also described a VR setup that uses a non-verbal approach for teaching and practicing reanimation. In contrast to VR, where users are fully immersed in their virtual environment, AR shifts the focus of the user\u2019s interaction to the real world [5]. It follows that AR applications can represent tasks in the real world more realistically than their VR-based counterparts. Some studies have already shown the potential of AR in medical education and first aid assistance. Fromm et al. [14] developed a concept for an AR application that teaches users first aid. The study revealed that an AR application would help users in emergency situations\n4 M. Rebol et al., \u201dCPR Emergency Assistance Through Mixed Reality Communication\u201d The Version of Record of this contribution is published in Augmented Intelligence and Intelligent\nTutoring Systems and is available online at https://doi.org/10.1007/978-3-031-32883-1 38.\nin an intuitive and quick manner. Johnson et al. [20] used Microsoft\u2019s HoloLens for building HoloCPR, an AR application that provides real-time instructions for CPR. The subsequent evaluation revealed how the use of such devices can result in a better reaction time and improved accuracy. Fr\u00f8land et al. [15] also used Microsoft HoloLens for developing a training environment for trauma first aid. In their study, they simulated an emergency, where a patient suffered from severe bleeding that had to be stopped by the participants."
        },
        {
            "heading": "3 Designing Mixed Reality Communication for First Aid Assistance",
            "text": "We designed the mixed reality (MR) communication system in consultation with a first aid instructor. The domain expert described the information required to understand the emergency situation. Moreover, the domain expert suggested how visual communication can be supported using virtual objects. The detailed system design approach and implementation details approach were described in [33] and [34], respectively."
        },
        {
            "heading": "3.1 Augmented Views",
            "text": "Both the expert and the first responder wear the Microsoft Hololens 2 headmounted display (HMD) to communicate. In addition, to the view, the HMD\nM. Rebol et al., \u201dCPR Emergency Assistance Through Mixed Reality Communication\u201d The Version of Record of this contribution is published in Augmented Intelligence and Intelligent\nTutoring Systems and is available online at https://doi.org/10.1007/978-3-031-32883-1 38.\n5\noffers head and hand tracking. Head tracking is needed to anchor augmented objects in the physical environment. Thus, alignment between the views and visual interaction on a shared view is possible. Hand tracking allows for gesture communication between the users of the system.\nRemote Expert The remote expert\u2019s view is dominated by a mesh view of the local first responder\u2019s scene. The view is captured by Microsoft Azure Kinect RGBD cameras at the local scene. The remote expert can switch between two different RGBD cameras to get a volumetric view of the local scene. The RGBD cameras are positioned such that they capture the patient, the first responder, and the environment. In future versions of the system, the HMD-included camera can be used to capture the local scene instead of the separate RGBD camera. We used a separate Azure Kinect camera because the current Microsoft Hololens depth sensor does not provide sufficient quality.\nIn addition to the mesh view, the remote expert is presented with an augmented video feed from the local scene. The 1920\u00d7 1080 video feed provides the remote expert with a high-quality view of the local scene including details the mesh view misses because of limitations of the time-of-flight technology.\nBesides the views of the local scene, the remote expert sees augmented objects which they can use to visually guide the first responder. The remote expert can manipulate the objects, i.e. resize, rotate, move, using gestures.\nFirst Responder The first responder\u2019s view is dominated by the physical environment. The augmented information for the first responder is kept to a minimum such that they can focus on the emergency. The augmented information for the first responder consists of augmented objects, the expert\u2019s augmented hands, and a video feed showing the remote expert. The first responder\u2019s MR communication role is passive. They see augmented objects and screens but do not actively manipulate them."
        },
        {
            "heading": "3.2 Interaction",
            "text": "The remote expert and the first responder can verbally communicate using audio. Moreover, the mixed reality system supports visual communication using gestures and case-specific augmented objects. For first aid, we provide a 3D holographic model that demonstrates the rescue position, hands illustrating the chest compression position, and an object to show the depth of the chest compressions. Only the remote expert actively manipulates augmented objects and screens in MR using gestures. The first responder manipulates the physical environment. We show the devices used given the research study setup in Figure 2."
        },
        {
            "heading": "4 Research Study",
            "text": "We evaluated the proposed MR system in a research study in which we compare it against videoconferencing-based communication. Our research focused\n6 M. Rebol et al., \u201dCPR Emergency Assistance Through Mixed Reality Communication\u201d The Version of Record of this contribution is published in Augmented Intelligence and Intelligent\nTutoring Systems and is available online at https://doi.org/10.1007/978-3-031-32883-1 38.\non understanding how MR communication can be used in medical emergencies. We measured the workload between video-only and MR assistance and analyzed how it differs. Moreover, we were interested in whether higher performance can be achieved when using MR for emergency assistance compared to video-only communication in the context of first aid / CPR."
        },
        {
            "heading": "4.1 Study Design",
            "text": "Subjects Altogether, 30 participants were recruited as first responders. The study participants did not receive information about the content of the training prior to arrival at the test site, to prevent preparation and more closely simulate an unexpected emergency. Informed consent was obtained, and subjects were randomized to either test condition. All training sessions were conducted by a single expert who has over ten years of professional experience in first-aid training.\nRoom Setup Expert and first responder were placed in separate rooms to ensure that all communications occurred through the specified modality; room setup remained otherwise static for both conditions. Each room contained a patient actor who simulated an unconscious but still breathing patient, a CPR mannequin (Laerdal Little Anne QCPR mannequin) capable of measuring metrics of CPR quality that are aligned with AHA guidelines [24], and a mask for ventilation. We show the MR setup in Figure 2, and videoconference setup (Cisco Webex) in Figure 3.\nFirst Aid Training We illustrate the four main steps actively performed by the first responder in Figure 4. The responder first assessed the patient actor to determine that they were unconscious but breathing, and placed the patient in\nM. Rebol et al., \u201dCPR Emergency Assistance Through Mixed Reality Communication\u201d The Version of Record of this contribution is published in Augmented Intelligence and Intelligent\nTutoring Systems and is available online at https://doi.org/10.1007/978-3-031-32883-1 38.\n7\nthe recovery position. The responder then continued to monitor the patient\u2019s breathing. After a defined period the patient actor held their breath to simulate cardiac arrest, at which time a CPR mannequin replaced the patient. The responder then provided chest compressions and mouth-to-mask ventilation. In total each participant was instructed to give CPR for 4 minutes. Metrics of CPR quality such as rate and depth of compression were recorded from the mannequin during this time.\nSurveys At the conclusion of the simulation, participants completed a demographic survey, the NASA Task Load Index (NASA-TLX) [19] and the Simulation Task Load Index (SIM-TLX) [18], both metrics of cognitive workload. Finally, the MR group also completed an MR-specific questionnaire. The expert instructor completed NASA- and SIM-TLX once after completing the training.\n(a) Recovery position (b) Breathing check (c) Chest compres. (d) Ventilation\nFig. 4: First aid steps. We present the 4 main steps of the first aid simulation. The first responder performs steps (a) and (b) on a patient actor and steps (c) and (d) on a CPR mannequin."
        },
        {
            "heading": "4.2 Results and Discussion",
            "text": "Subject Demographics We illustrate the first responder demographics in Table 1.\nCPR Performance Data for 25 learners (13 video and 12 AR) was included; 5 data samples were removed due to mannequin malfunction. There was no significant difference in CPR performance when comparing video and MR conditions\n8 M. Rebol et al., \u201dCPR Emergency Assistance Through Mixed Reality Communication\u201d The Version of Record of this contribution is published in Augmented Intelligence and Intelligent\nTutoring Systems and is available online at https://doi.org/10.1007/978-3-031-32883-1 38.\nfor any CPR performance category (2 sample, 2 tailed t test with significance of \u03b1 = 0.05). The data is presented in Table 2. We noticed a trend towards better ventilation and worst compression score in AR.\nWorkload We illustrate the overall results of both workload surveys, NASATLX and SIM-TLX, for first responders and the expert in Table 3. The expert reported a lower overall workload for both surveys when using the MR technology compared to videoconferencing. The first responders reported similar workload between the two technologies. A two-sample two-tailed t-test was not able to show a significant difference (\u03b1 = 0.05) between the groups. The mean overall workload is similar when comparing the two technologies.\nWe present the per-category workload results for first responders in Figure 5 to give a more in-depth insight. The physical demand was the highest during the first aid emergency. We posit that this is related to the physical exertion during chest compressions. The SIM-TLX signals three interesting trends. The video-assisted first responders reported higher frustration but lower distraction and perceptual strain than the MR communications group.We propose that the higher frustration with video results from two factors. First, instructions involving physical space must be communicated via 2D video and voice, which must then be translated into actions, rather than by using virtual objects to provide visual demonstration of the necessary action. Secondly, the first responders must switch gaze from the task at hand to the video, in order to compare their own progress with the instructor\u2019s directions. In AR, visual communication is more\nM. Rebol et al., \u201dCPR Emergency Assistance Through Mixed Reality Communication\u201d The Version of Record of this contribution is published in Augmented Intelligence and Intelligent\nTutoring Systems and is available online at https://doi.org/10.1007/978-3-031-32883-1 38.\n9\nsimilar to in-person because the views are aligned, and pointing gestures and augmented object demonstrations can be used. The higher perceptual strain reported by the MR group may also be due to the relative increase in visual information presented to and processed by the learner in the MR mode. Higher distraction ratings in the MR group may result from the limited field of view (FOV) of the Hololens 2 headset, and the need to locate or track instructor input outside the FOV. We argue that this can be improved by only showing them the remote hands when necessary, for example when the remote expert decides to point or gesture actively.\nMixed Reality Survey The first responders noted in the open-ended questions that they especially liked the gestural communication including pointing by the remote expert. They highlighted the importance of visual communication in stressful situations. When asked about problems with the MR system, some participants noted that the visual instructions were not always given at the best position such that they had to look around to see the augmented instructions. When asked about what they liked about the experience, the expert reported: \u201cI really liked the possibility to have additional holograms illustrating hand positions or rescue positions. This helped to provide faster help and spend less time with instructions. Additionally, the different camera perspectives were great for evaluating the quality of the CPR (chest compressions and ventilation).\u201d The negative aspects were: \u201cThe initial setup of the 2D and 3D areas was sometimes a bit cumbersome. When moving the cube (a handle for moving the location of the visual feeds) the area did not move adequately. Sometimes the connection got lost due to some reason but restarting the system was not a big deal.\u201d The expert was also asked about features that could be added: \u201cSome participants complained that audio and visual instructions can be a bit overwhelming. Therefore, a visual way to show the frequency of chest compressions would be great. Especially for the rescue position, a 3D object with movable joints (knee, arm, etc.) would be helpful to show how to bring a person to the rescue position (instead of an object of the already correct position).\u201d\nDiscussion Although the application of MR devices seems to be futuristic within the context of emergency situations, it enables interesting perspectives. Many countries have successfully implemented guided first aid instructions over an emergency call. A (3D) video channel could provide additional information to the emergency call center regarding the set measures and their quality.\nAlthough the MR and video groups did not differ significantly in terms of CPR performance in this study, the use of MR with truly novice first responders may be more beneficial during complex maneuvers, for instance, to evaluate and demonstrate head tilt-chin lift for ventilation.\nSimilar to AEDs, which are usually close to an emergency situation in urban areas, MR devices could be co-located with them to initiate an emergency call or request additional support from the emergency call center.\nAnalyzing the combined performance and workload results, we conclude that the technology is well-suited for emergencies because the usage is intuitive. The remote expert only required brief guidance on how the MR technology works. Furthermore, the first responders put on their HMD only about 30 seconds before the actual simulation started. Moreover, assuming that the technology has a learning curve, better MR results can be expected after using the technology longer or more frequently.\nBroader Impact MR technologies are used for communication across industries. Since first aid emergencies are stressful and complex procedures, we believe that the technology can not only be used for other medical procedures including medical training, but also across domains. An example could be remote repair\nM. Rebol et al., \u201dCPR Emergency Assistance Through Mixed Reality Communication\u201d The Version of Record of this contribution is published in Augmented Intelligence and Intelligent\nTutoring Systems and is available online at https://doi.org/10.1007/978-3-031-32883-1 38.\n11\nemergencies where a local operator needs to receive guidance from a remote expert to complete the task as quickly and accurately as possible. Similar to giving CPR, spatial information and visual communication including pointing, gestures, and augmented objects seem invaluable."
        },
        {
            "heading": "4.3 Limitation",
            "text": "One of the main concerns of this research study is its feasibility for deployment in real-life emergency situations. However, due to the rapid development and spread of AR technologies such devices and application areas are increasing. We believe that as HMDs become lighter and slimmer, sooner than later people will wear MR devices in their everyday lives. Thus, what now seems futuristic, will become relevant in the near future.\nThe current setup requires some time and experience to be installed. In emergency situations this is not possible. However, the setup can be faster and require fewer devices as technology progresses. For example, instead of Azure Kinect RGBD cameras, the Hololens 2 integrated RGBD cameras could be used to transmit spatial information to the remote expert. This would make the system more portable and easy to deploy in emergencies. Similarly, communication computers can be replaced by handheld phones or better HMD-integrated hardware.\nThe current research study was conducted on a local network. However, the MR system was designed for remote data transfer over the internet. Especially, given recent 5G developments, bandwidth and latency deficiencies have already been resolved in many parts of the world.\nThe limitation of low 3D mesh quality when the system is used outdoors because of the interference of natural infrared light with the time of flight sensor technology can be tackled by using prerecorded volumetric information. Moreover, machine learning can be used to fill in missing information and provide the remote expert with a higher-quality 3D mesh view."
        },
        {
            "heading": "5 Conclusion",
            "text": "We presented the design and the evaluation of a mixed reality (MR) communication system for first aid. The system allows a remote expert to guide a local first responder through giving first aid. Compared to help over phone and videoconferencing, the MR system allows for augmented visual instructions such as gestures, annotations, and object demonstrations. Moreover, the remote instructor is presented with a volumetric view which gives them spatial information, important for various medical procedures.\nWe evaluated the MR system in a research study in which we compared MR against videoconferencing. We found that overall, the results including objective CPR mannequin performance and subjective workload measures remain similar between the technologies. We identified many new opportunities that MR offers for an expert to visually guide a first responder. The results show that visual guides do help first responders.\n12 M. Rebol et al., \u201dCPR Emergency Assistance Through Mixed Reality Communication\u201d The Version of Record of this contribution is published in Augmented Intelligence and Intelligent\nTutoring Systems and is available online at https://doi.org/10.1007/978-3-031-32883-1 38.\nIn future work, we will analyze how MR can be used for other medical procedures. Moreover, we are interested in combining prerecorded procedural guidance including avatars ([31], [30]) for the local operator with active help from the remote expert in problematic situations. This would standardize the process and allow the remote expert to save energy by reducing repetitive instructing and only intervening in critical situations when the first responder needs additional guidance.\nAcknowledgements. The work is supported by National Science Foundation grant no. 2026505 and 2026568."
        }
    ],
    "title": "CPR Emergency Assistance Through Mixed Reality Communication",
    "year": 2023
}