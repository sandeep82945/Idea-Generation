{
    "abstractText": "COPYRIGHT \u00a9 2023 Helkala, Lucas, Barrett and Syse. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms. Editorial: Ethical challenges in AI-enhanced military operations",
    "authors": [
        {
            "affiliations": [],
            "name": "Murat Kantarcioglu"
        },
        {
            "affiliations": [],
            "name": "Kirsi Marjaana Helkala"
        },
        {
            "affiliations": [],
            "name": "George Lucas"
        },
        {
            "affiliations": [],
            "name": "Edward Barrett"
        },
        {
            "affiliations": [],
            "name": "Henrik Syse"
        }
    ],
    "id": "SP:bea05028cb46359720c8c6ca8e18c220f9806aa1",
    "references": [
        {
            "authors": [
                "M. Regan",
                "J. Davidovic"
            ],
            "title": "Just preparation for war and AI-enabled weapons",
            "venue": "Front. Big Data",
            "year": 2023
        }
    ],
    "sections": [
        {
            "text": "TYPE Editorial PUBLISHED 19 June 2023 DOI 10.3389/fdata.2023.1229252"
        },
        {
            "heading": "OPEN ACCESS",
            "text": ""
        },
        {
            "heading": "EDITED AND REVIEWED BY",
            "text": "Murat Kantarcioglu, The University of Texas at Dallas, United States\n*CORRESPONDENCE Kirsi Marjaana Helkala\nkirsi.helkala@gmail.com\nRECEIVED 26 May 2023 ACCEPTED 06 June 2023 PUBLISHED 19 June 2023"
        },
        {
            "heading": "CITATION",
            "text": "Helkala KM, Lucas G, Barrett E and Syse H (2023) Editorial: Ethical challenges in AI-enhanced military operations. Front. Big Data 6:1229252. doi: 10.3389/fdata.2023.1229252"
        },
        {
            "heading": "COPYRIGHT",
            "text": "\u00a9 2023 Helkala, Lucas, Barrett and Syse. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms."
        },
        {
            "heading": "Editorial: Ethical challenges in",
            "text": ""
        },
        {
            "heading": "AI-enhanced military operations",
            "text": ""
        },
        {
            "heading": "Kirsi Marjaana Helkala1,2*, George Lucas3, Edward Barrett4 and Henrik Syse2",
            "text": "1Norwegian Defence Cyber Academy, Norwegian Defence University College, Oslo, Norway, 2Peace Research Institute Oslo, Oslo, Norway, 3Department of Leadership, Ethics and Law, U.S. Naval Academy, Annapolis, MD, United States, 4Stockdale Center, U.S. Naval Academy, Annapolis, MD, United States"
        },
        {
            "heading": "KEYWORDS",
            "text": "artificial intelligence (AI), military ethics, virtue ethics, conventional combat, cyber conflict, strategic planning\nEditorial on the Research Topic\nEthical challenges in AI-enhanced military operations\nThis Research Topic primarily focuses on the people\u2014military personnel throughout the command structure\u2014who serve in combat settings with AI-enabled machines. In a battlespace where machine autonomy is increasingly assuming functions once restricted to human beings, maintaining clear lines of human responsibility is of paramount importance. Clarifying this issue should improve ethical instruction within military training and educational institutions, as well as change how AI developers design their technologies. In turn, this will render ethical guidelines better tailored to the battlefield scenarios military personnel will confront in the future.\nThis collection aims to yield moral guidelines for the variety of military uses of AI\ntechnology, primarily in three areas:\nConventional armed conflict/battlefield combat; Cyber military operations and cyber conflict; Strategic planning for war and data-driven battlefield management.\nAdditionally, these essays examine the impact on the competency and character of human operators, inter alia, through the lens of virtue ethics. That is, they focus on individual character and the cultivation of moral predispositions that empower us to act responsibly amid the challenges to personal and professional life increasingly posed by the use of artificial intelligence in cyber security, kinetic warfare, and intelligence and strategic planning.\nWithin cyber security, AI-based tools can be used in both offensive and defensive cyber applications, from malware detection, network intrusion, and phishing and spam detection to intelligent threats and tools for attacking AI models. AI-based systems and their use in the kinetic battlefield encompass autonomous vehicles, drones, and swarms. Finally, intelligence systems that enable the examination and analysis of large data sets and integration of inputs from a vast array of sources enable ever-more effective planning, battlefield management, surveillance, and development of data-driven strategies focused on defense and national security (as is currently happening in Ukraine).\nThis Research Topic of \u201cFrontiers in Big Data\u201d originated as part of a project (\u201cWarring with Machines: Artificial Intelligence and the Relevance of Virtue Ethics\u201d) at the Peace Research Institute Oslo (PRIO) focused on the uses and ethical impact of AI in military settings and special operations. Most of the papers were refereed and presented initially at international conferences\nFrontiers in BigData 01 frontiersin.org\nheld in Rome (and co-organized by PRIO and Notre Dame University\u2019s Technology Ethics Center), at the McCain Conference in Annapolis, USA (organized by the Stockdale Center at the US Naval Academy in association with PRIO), as well as at annual conferences of the International Society of Military Ethics in Europe and the USA. Others were received in response to an international CFP through the Loop Science Network.\nThe papers encompass four research areas, each addressing the challenges of AI-enhanced military operations: (1) Artificial Intelligence and the Ethics of Warfare; (2) The Impact of Military Reliance on AI upon Human War Fighters and Their Control of Warfare; (3) Dignity and Respect; and (4) Gender Bias in Narratives of War.\nThe first topic includes a paper published separately from this Research Topic by Frontiers, namely, Regan and Davidovic (2023) \u201cJust Preparation for War and AI-Enabled Weapons\u201d, as well as the papers \u201cThe Comparative Ethics of Artificialintelligence Methods for Military Applications\u201d by Rowe, and \u201cThe PRC Considers Military AI Ethics: Can Autonomy be Trusted?\u201d by Metcalf. All three address AI in warfare from a military ethics perspective, addressing proper preparation and testing, the ethics of different algorithms in use, and the deeply political way in which the military ethics of AI is understood in China.\nThe second topic is addressed by Hovd in the paper \u201cTools of War and Virtue-Institutional Structures as a Source of Ethical Deskilling\u201d, which analyses military virtues as a species of moral virtues mediated by institutional and technological structures, meaning that professional roles and institutional structures are constitutive parts of what makes these virtues what they are, and thus the most likely source of ethical deskilling. The paper \u201cOn the Purpose of Meaningful Human Control\u201d by Davidovic critically discusses and analyses calls for proper control of AI-enabled weapons systems, focusing on the purpose of such control, while \u201cThe Ethics of AI-assisted War Fighter Enhancement Research and Experimentation\u201d by Moreno et al. discusses the problem of AI-wired war fighters facing affronts to cognitive liberty and to psychological and physiological health, as well as obstacles to integrating into military and civil society during their service and upon discharge, emphasizing the importance of ethics in the research underlying the use of such technologies.\nThe third topic includes the paper \u201cResolving Responsibility Gaps for Lethal Autonomous Weapon Systems\u201d by Taylor Smith, in which the author suggests an understanding of collective responsibility for AI outcomes that can help resolve the \u201cproblem of many hands\u201d and \u201cresponsibility gaps\u201d. It also includes Kahn\u2019s \u201cLethal Autonomous Weapons Systems and Respect for Human Dignity\u201d, which discusses whether actions involving the use of AI-enhanced weapons can respect human dignity. Kahn suggests criteria for the possibility of answering that question in the affirmative. Finally, \u201cLethal Autonomous Weapons Systems, Revulsion, and Respect\u201d by Dean raises the issue of respect for\npublic opinion and conventional attitudes as one develops lethal autonomous weapons systems, those opinions and attitudes often being very skeptical toward the development of such weaponry.\nThe fourth and last topic is addressed by Fisher in \u201cThe Role of Gender in Providing Expert Advice on Cyber Conflict and Artificial Intelligence to Military Personnel\u201d. Fisher argues that, as the role of cyber and AI grows in military operations, there is a need for military institutions to take gender into account in both training and policy, not least due to the fact that gender stereotypes attach to the role of cyber-engineer.\nTogether, these papers focus on the impact of current and anticipated military uses of AI-augmented technologies within the framework of military ethics and the just war tradition, as well as unique individual moral challenges that such technologies present. The effect of AI-augmentation on conceptions of human dignity, respect, and gender roles in military settings is found to be particularly problematic. Specific responses and remedies to the major problems described are proposed where feasible."
        },
        {
            "heading": "Author contributions",
            "text": "Each contributing author to this collection participated in conceptualization of their topic, writing of the original draft and subsequent revisions, and funding acquisition for the overall project. The editors approved the final submitted version."
        },
        {
            "heading": "Acknowledgments",
            "text": "We express our sincere gratitude to all the authors who proposed their work, all the researchers who took care to provide their most constructive comments and suggestions, and to the Frontiers team for their support. We are grateful for the support of the Research Council of Norway that contributed funding (for the \u201cWarring with Machines\u201d project) toward the publication of this collection as an e-Book."
        },
        {
            "heading": "Conflict of interest",
            "text": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest."
        },
        {
            "heading": "Publisher\u2019s note",
            "text": "All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.\nFrontiers in BigData 02 frontiersin.org"
        }
    ],
    "title": "Editorial: Ethical challenges in AI-enhanced military operations",
    "year": 2023
}