{
    "abstractText": "The low-cost Inertial Measurement Unit (IMU) can provide orientation information and is widely used in our daily life. However, IMUs with bad calibration will provide inaccurate angular velocity and lead to rapid drift of integral orientation in a short time. In this paper, we present the Calib-Net which can achieve the accurate calibration of low-cost IMU via a simple deep convolutional neural network. Following a carefully designed mathematical calibration model, Calib-Net can output compensation components for gyroscope measurements dynamically. Dilation convolution is adopted in Calib-Net for spatiotemporal feature extraction of IMU measurements. We evaluate our proposed system on public datasets quantitively and qualitatively. The experimental results demonstrate that our Calib-Net achieves better calibration performance than other methods, what is more, and the estimated orientation with our Calib-Net is even comparable with the results from visual inertial odometry (VIO) systems.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ruihao Li"
        },
        {
            "affiliations": [],
            "name": "Chunlian Fu"
        },
        {
            "affiliations": [],
            "name": "Wei Yi"
        },
        {
            "affiliations": [],
            "name": "Xiaodong Yi"
        }
    ],
    "id": "SP:68e3f159c5cda705f365426802f87ff561fca31f",
    "references": [
        {
            "authors": [
                "N. Ahmad",
                "R.A.R. Ghazilla",
                "N.M. Khairi",
                "V. Kasi"
            ],
            "title": "Reviews on Various Inertial Measurement Unit (IMU) Sensor Applications",
            "venue": "Ijsps 1, 256\u2013262. doi:10.12720/ijsps.1.2.256-262",
            "year": 2013
        },
        {
            "authors": [
                "A. Barrau",
                "S. Bonnabel"
            ],
            "title": "A Mathematical Framework for IMU Error Propagation with Applications to Preintegration,\u201d in 2020 IEEE International Conference on Robotics and Automation (ICRA) (IEEE), Paris, France, May 31\u2013August 31, 2020, 5732\u20135738",
            "venue": "doi:10.1109/icra40945.2020.9197492",
            "year": 2020
        },
        {
            "authors": [
                "M. Brossard",
                "A. Barrau",
                "S. Bonnabel"
            ],
            "title": "AI-IMUDead-Reckoning",
            "venue": "IEEE Trans. Intell. Veh. 5, 585\u2013595. doi:10.1109/tiv.2020.2980758",
            "year": 2020
        },
        {
            "authors": [
                "M. Brossard",
                "S. Bonnabel",
                "A. Barrau"
            ],
            "title": "Denoising IMU Gyroscopes with Deep Learning for Open-Loop Attitude Estimation",
            "venue": "IEEE Robotics Automation Lett. 5, 4796\u20134803. doi:10.1109/lra.2020.3003256",
            "year": 2020
        },
        {
            "authors": [
                "C. Campos",
                "R. Elvira",
                "J.J.G. Rodr\u00edguez",
                "J.M. Montiel",
                "J.D. Tard\u00f3s"
            ],
            "title": "ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual\u2013Inertial, and Multimap SLAM",
            "venue": "IEEE Trans. Robotics.",
            "year": 2021
        },
        {
            "authors": [
                "C. Campos",
                "J.M. Montiel",
                "J.D. Tard\u00f3s"
            ],
            "title": "Inertial-only Optimization for Visual-Inertial Initialization,\u201d in 2020 IEEE International Conference on Robotics and Automation (ICRA) (IEEE), Paris, France, May 31\u2013August 31, 2020, 51\u201357",
            "venue": "doi:10.1109/icra40945.2020.9197334",
            "year": 2020
        },
        {
            "authors": [
                "C. Chen",
                "X. Lu",
                "A. Markham",
                "N. Trigoni"
            ],
            "title": "IONet: Learning to Cure the Curse of Drift in Inertial Odometry,",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "C. Chen",
                "X. Lu",
                "J. Wahlstrom",
                "A. Markham",
                "N. Trigoni"
            ],
            "title": "Deep Neural Network Based Inertial Odometry Using Low-Cost Inertial Measurement Units",
            "venue": "IEEE Trans. Mobile Comput.",
            "year": 2019
        },
        {
            "authors": [
                "C. Chen",
                "S. Rosa",
                "Y. Miao",
                "C.X. Lu",
                "W. Wu",
                "A Markham"
            ],
            "title": "Selective Sensor Fusion for Neural Visual-Inertial Odometry,",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2019
        },
        {
            "authors": [
                "R. Clark",
                "S. Wang",
                "H. Wen",
                "A. Markham",
                "N. Trigoni"
            ],
            "title": "VINet: VisualInertial Odometry as a Sequence-To-Sequence Learning Problem,",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, San Francisco, United States,",
            "year": 2017
        },
        {
            "authors": [
                "M.A. Esfahani",
                "H. Wang",
                "K. Wu",
                "S. Yuan"
            ],
            "title": "AbolDeepIO: A Novel Deep Inertial Odometry Network for Autonomous Vehicles",
            "venue": "IEEE Trans. Intell. Transportation Syst. 21, 1941\u20131950. doi:10.1109/LRA.2019.2959507",
            "year": 2019
        },
        {
            "authors": [
                "M.A. Esfahani",
                "H. Wang",
                "K. Wu",
                "S. Yuan"
            ],
            "title": "OriNet: Robust 3-D Orientation Estimation with a Single Particular IMU",
            "venue": "IEEE Robotics Automation Lett. 5, 399\u2013406.",
            "year": 2019
        },
        {
            "authors": [
                "P. Furgale",
                "J. Rehder",
                "R. Siegwart"
            ],
            "title": "Unified Temporal and Spatial Calibration for Multi-Sensor Systems,\u201d in 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems, Tokyo, Japan, November 3\u20137, 2013 (IEEE), 1280",
            "venue": "doi:10.1109/iros.2013.6696514",
            "year": 2013
        },
        {
            "authors": [
                "P. Geneva",
                "K. Eckenhoff",
                "W. Lee",
                "Y. Yang",
                "G. Huang"
            ],
            "title": "OpenVINS: A Research Platform for Visual-Inertial Estimation,\u201d in 2020 IEEE International Conference on Robotics and Automation (ICRA) (IEEE), Paris, France, May 31\u2013August 31, 2020, 4666\u20134672",
            "venue": "doi:10.1109/icra40945.2020.9196524",
            "year": 2020
        },
        {
            "authors": [
                "S. Jadon"
            ],
            "title": "A Survey of Loss Functions for Semantic Segmentation,\u201d in 2020 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB) (IEEE), Via del Mar, Chile, October 27\u201329, 2020",
            "venue": "doi:10.1109/cibcb48159.2020.9277638",
            "year": 2020
        },
        {
            "authors": [
                "E. Nebot",
                "H. Durrant-Whyte"
            ],
            "title": "Initial Calibration and Alignment of Low-Cost Inertial Navigation Units for Land Vehicle Applications",
            "venue": "J. Robotic Syst. 16, 81\u201392. doi:10.1002/(sici)1097-4563(199902)16:2<81:aid-rob2>3.0.co; 2-9",
            "year": 1999
        },
        {
            "authors": [
                "F. Nobre",
                "C. Heckman"
            ],
            "title": "Learning to Calibrate: Reinforcement Learning for Guided Calibration of Visual-Inertial Rigs",
            "venue": "Int. J. Robotics Res. 38, 1388\u20131402. doi:10.1177/0278364919844824",
            "year": 2019
        },
        {
            "authors": [
                "T. Qin",
                "P. Li",
                "S. Shen"
            ],
            "title": "VINS-mono: A Robust and Versatile Monocular Visual-Inertial State Estimator",
            "venue": "IEEE Trans. Robot. 34, 1004\u20131020. doi:10.1109/ tro.2018.2853729",
            "year": 2018
        },
        {
            "authors": [
                "T. Qin",
                "S. Shen"
            ],
            "title": "Online Temporal Calibration for Monocular Visual-Inertial Systems,\u201d in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE), Madrid, Spain, October 1\u20135, 2018, 3662\u20133669",
            "venue": "doi:10.1109/iros.2018.8593603",
            "year": 2018
        },
        {
            "authors": [
                "J. Rehder",
                "J. Nikolic",
                "T. Schneider",
                "T. Hinzmann",
                "R. Siegwart"
            ],
            "title": "Extending Kalibr: Calibrating the Extrinsics of Multiple IMUs and of Individual Axes,\u201d in IEEE International Conference on Robotics and Automation (ICRA) (IEEE), Stockholm, Sweden, May 16\u201321, 2016, 4304\u20134311",
            "venue": "doi:10.1109/icra.2016.7487628",
            "year": 2016
        },
        {
            "authors": [
                "J. Rehder",
                "R. Siegwart"
            ],
            "title": "Camera/IMU Calibration Revisited",
            "venue": "IEEE Sensors J. 17, 3257\u20133268. doi:10.1109/jsen.2017.2674307",
            "year": 2017
        },
        {
            "authors": [
                "J. Rohac",
                "M. Sipos",
                "J. Simanek"
            ],
            "title": "Calibration of Low-Cost Triaxial Inertial Sensors",
            "venue": "IEEE Instrum. Meas. Mag. 18, 32\u201338. doi:10.1109/ mim.2015.7335836",
            "year": 2015
        },
        {
            "authors": [
                "D. Tedaldi",
                "A. Pretto",
                "E. andMenegatti"
            ],
            "title": "A Robust and Easy to Implement Method for IMU Calibration without External Equipments,",
            "venue": "IEEE International Conference on Robotics and Automation",
            "year": 2014
        },
        {
            "authors": [
                "H. Yan",
                "Q. Shan",
                "Y. Furukawa"
            ],
            "title": "RIDI: Robust IMU Double Integration,\u201d in Proceedings of the European Conference on Computer Vision, Munich, Germany, September 8\u201314, 2018 (ECCV)), 621\u2013636",
            "venue": "doi:10.1007/978-3-030-01261-8_38",
            "year": 2018
        },
        {
            "authors": [
                "Y. Yang",
                "P. Geneva",
                "X. Zuo",
                "G. Huang"
            ],
            "title": "Online Imu Intrinsic Calibration: Is it Necessary",
            "venue": "in\u201d Proc. Of the Robotics: Science and Systems. Corvallis, Oregon, 716\u2013720.",
            "year": 2020
        },
        {
            "authors": [
                "Z. Zhang",
                "D. Scaramuzza"
            ],
            "title": "A Tutorial on Quantitative Trajectory Evaluation for Visual (-inertial) Odometry,",
            "venue": "in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "Calib-Net: Calibrating the Low-Cost IMU via Deep Convolutional Neural Network Ruihao Li 1, Chunlian Fu2, Wei Yi 1* and Xiaodong Yi 1\n1Artificial Intelligence Research Center (AIRC), Defense Innovation Institute, Beijing, China, 2Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China\nThe low-cost Inertial Measurement Unit (IMU) can provide orientation information and is widely used in our daily life. However, IMUs with bad calibration will provide inaccurate angular velocity and lead to rapid drift of integral orientation in a short time. In this paper, we present the Calib-Net which can achieve the accurate calibration of low-cost IMU via a simple deep convolutional neural network. Following a carefully designed mathematical calibration model, Calib-Net can output compensation components for gyroscope measurements dynamically. Dilation convolution is adopted in Calib-Net for spatiotemporal feature extraction of IMU measurements. We evaluate our proposed system on public datasets quantitively and qualitatively. The experimental results demonstrate that our Calib-Net achieves better calibration performance than other methods, what is more, and the estimated orientation with our Calib-Net is even comparable with the results from visual inertial odometry (VIO) systems.\nKeywords: IMU calibration, deep neural network, orientation estimation, spatio-temporal, visual inertial odometry\n1 INTRODUCTION\nLow-cost inertial measurement units (IMU) are widely used in our daily life (Nebot and DurrantWhyte, 1999; Ahmad et al., 2013; Rehder and Siegwart, 2017). Cheap IMU can provide the attitude and position information by integrating three-axis angular velocity measurements and three-axis linear acceleration measurements. Many devices (such as smartphones, autonomous robots, AR/VR devices, etc) are equipped with low-cost IMU sensors to obtain inertial measurements in order to achieve different features. However, the accuracy of IMU is easily affected by calibration parameters include scaling factors, axes misalignments, etc. Inaccurate calibration will produce imprecise angular velocity and linear acceleration, and the integration operation will lead to rapid error accumulation and estimation drift.\nIn order to limit the drift as much as possible, precise IMU calibration must be performed for both inertial odometry (IO) and visual-inertial odometry (VIO). A lot of research about IMU calibration or camera/IMU calibration are studied in the past several years. Most methods (Furgale et al., 2013; Rohac et al., 2015; Rehder et al., 2016) prefer to design a mathematical model and take calibration model parameters as constant values. External devices are usually needed for the pre-calibration procedure. Online calibration methods (Qin and Shen, 2018; Yang et al., 2020) which optimize the spatio-temporal camera/IMU model parameters all together are proved effective for the tracking performance of VIO systems. As deep learning technology has achieved great success in the past decade, many researchers also introduce deep learning technology into tasks like orientation estimation (Esfahani et al., 2019b), inertial\nEdited by: Xuebo Zhang,\nNankai University, China\nReviewed by: Zuyuan Zhu,\nUniversity of Essex, United Kingdom Yan Zhuang,\nDalian University of Technology, China Xunyu Zhong,\nXiamen University, China\n*Correspondence: Wei Yi yi_wei_cs@163.com\nSpecialty section: This article was submitted to Robot and Machine Vision,\na section of the journal Frontiers in Robotics and AI\nReceived: 08 September 2021 Accepted: 15 November 2021 Published: 03 January 2022\nCitation: Li R, Fu C, Yi W and Yi X (2022) CalibNet: Calibrating the Low-Cost IMU via Deep Convolutional Neural Network.\nFront. Robot. AI 8:772583. doi: 10.3389/frobt.2021.772583\nFrontiers in Robotics and AI | www.frontiersin.org January 2022 | Volume 8 | Article 7725831\nORIGINAL RESEARCH published: 03 January 2022 doi: 10.3389/frobt.2021.772583\nodometry (Chen et al., 2018; Esfahani et al., 2019a; Brossard et al., 2020a), visual-inertial odometry (Clark et al., 2017; Chen et al., 2019b), and most of them adopt the recurrent neural network which is memory consuming and computing consuming.\nIn this paper, we propose a lightweight and efficient deep convolutional neural network for low-cost IMU calibration. It is designed based on a mathematical model and is trained driven by historical data. The proposed method can calibrate the IMU measurements dynamically. By using the calibrated IMU measurements, accurate orientation estimation can be obtained and the results can even be comparable with VIO methods.\nOur contribution can be summarized as below: \u2022 We present a deep convolutional neural network called Calib-Net for low-cost IMU calibration. The Calib-Net adopts dilation convolution for spatio-temporal feature extraction, and learns to produce the compensation for gyroscope measurements dynamically. \u2022We introduce a mathematical calibration model to construct the training and calibration framework. Both constant calibration matrix (3 \u00d7 3) and Calib-Net hyperparameters can be trained and optimized driven by a carefully designed loss function. \u2022 We implement the proposed framework and validate it quantitatively and qualitatively on public datasets. The experimental evaluations show that our Calib-Net achieves satisfactory performance in IMU calibration, and is also fruitful for VIO systems.\nThe rest of this paper is organized as follows. Section 2 introduces the related works of IMU calibration and orientation estimation. Section 3 introduces the overview architecture of the proposed calibration framework. Section 4 describes the details of the used mathematical model, neural network architecture, and the loss function. Section 5 presents the results of experimental evaluations. Finally, the conclusion is drawn in Section 6."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "In the late 1990s, Nebot and Durrant-Whyte (1999) presented an inertial error model for gyros and accelerometers aiming at the IMU calibration for vehicle applications. Tedaldi et al. (2014) proposed an IMU calibration method without using external equipments, they need to move the IMU device by hand and place it in multiple static positions. Based on a specific sensor error model, Rohac et al. (2015) performed the low-cost inertial sensor calibration to obtain the model parameters using the nonlinear optimization under static conditions. Furgale et al. (2013) present the open-source Kalibr toolbox for the spatial and temporal calibration of multiple sensors (cameras/IMUs). Afterward, Rehder et al. (2016) extended the Kalibr toolbox and enabled precise IMU intrinsic calibration following an inertial noise model. They Rehder and Siegwart (2017) then further improved the calibration method by introducing the displacement of individual accelerometer axes into the mathematical noise\nmodel. Barrau and Bonnabel (2020) recently adopted Lie group for IMU error propagation. These calibration methods usually adopt different inertial model variants and estimate the parameters of these sensor error models. For the calibration methods above, the parameters (scale factors, misalignment errors, offsets, etc.) are usually taken as constant values. Nevertheless, these parameters are always varying as time goes on and the environment changes.\nAiming at the visual-inertial navigation system, Qin and Shen (2018) presented an online calibration method to optimize model parameters dynamically, and proposed VINS-mono system (Qin et al., 2018) which is one of the state-of-the-art visual-inertial systems. Yang et al. (2020) studied and discussed the necessity and importance of online IMU intrinsic calibration for visual-inertial navigation systems, and proved that online calibration is helpful for improving fusion performance. They also demonstrated an open-source visual-inertial odometry system called OpenVINS (Geneva et al., 2020). Campos et al. took the IMU measurement uncertainty into account (Campos et al., 2020), and proposed to use maximum a posteriori (MAP) estimation during IMU initialization in the ORB-SLAM3 system (Campos et al., 2021). Most of these methods rely on a mathematical model and need to calibrate every device before use.\nAs to the usage of deep learning in IMU calibration and propagation, Yan et al. (2018) proposed to use the machine learning technology to regress velocity vector with linear accelerations and angular velocities as inputs. Nobre and Heckman (2019) proposed to model the IMU calibration as a Markov Decision Process (MDP) and use reinforcement learning to achieve the regression of calibration parameters. Clark et al. (2017) presented VINet which takes the visual-inertial odometry problem as a sequence-to-sequence learning problem to solve and avoids manual camera/IMU calibration operation. Chen et al. (2018) introduced IONet for inertial odometry using the recurrent neural network. Ionet formulates the odometry as an optimization problem based on the neural network and estimates the trajectories with raw measurements as network input. Afterward, they Chen et al. (2019a) further extended the network and also used it to predict model uncertainty. However, the above learning methods usually adopt neural networks with large weights which will consume lots of computation resources.\nEsfahani et al. (2019b) presented a recurrent neural network called OriNet for orientation estimation. 3D orientation can be obtained by OriNet with only low-cost IMUmeasurements as the network input. They Esfahani et al. (2019a) also proposed AbolDeepIO which simulates the noise model during training and achieves robust inertial odometry with a novel deep neural network. Instead of using recurrent neural networks, Brossard et al. (2020b) adopted a convolutional neural network to estimate the orientation with an IMU device. They Brossard et al. (2020a) further achieved accurate and robust dead-reckoning with only a commercial IMU. The Kalman filter is introduced and a deep neural network is utilized to predict the dynamic parameters of the filter.\nFrontiers in Robotics and AI | www.frontiersin.org January 2022 | Volume 8 | Article 7725832"
        },
        {
            "heading": "3 METHODS",
            "text": ""
        },
        {
            "heading": "3.1 Mathematical Model for Low-Cost IMU Calibration",
            "text": ""
        },
        {
            "heading": "3.2 Architecture Overview",
            "text": "The overview of our proposed framework is shown in Figure 1. Calib-Net takes sequential gyroscope measurements and acceleration measurements as the input, and outputs the compensation for raw IMU measurements. Dilation convolution is utilized for spatio-temporal feature extraction instead of recurrent neural networks. By designing a mathematical calibration model, the measurements can be dynamically calibrated and corrected with the network output. In this way, accurate orientation can be directly obtained through simple integration. Based on only hundred seconds of labeled data, the hyperparameters of the Calib-Net and the constant model parameters (matrix includes) can be optimized at the same time driven by a carefully designed loss function.\nFor a typical low-cost Inertial Measurement Unit (IMU), it usually consists of a three-axis gyroscope, a three-axis accelerometer, and sometimes a magnetometer. The three-axis gyroscope can provide angular velocity information, the threeaxis accelerometer can provide the linear acceleration information. Considering the noise and bias of the sensor measurements (Rehder et al., 2016), the IMU sensor model can be represented as below:\n\u03c9\u0302t a\u0302t [ ] C \u03c9t at [ ] + b\u03c9t bat [ ] + n\u03c9t nat [ ] (1) Where angular velocity \u03c9t \u2208 R3 and linear acceleration at \u2208 R3 are the measurements of gyroscope and accelerometer, b\u03c9t \u2208 R 3 and bat \u2208 R 3 are the gyroscope and accelerometer bias, n\u03c9t \u2208 R 3 and nat \u2208 R\n3 are additive zero-mean Gaussian noises for gyroscope and accelerometer, angular velocity\n\u03c9\u0302t \u2208 R3 and linear acceleration a\u0302t \u2208 R3 are the calibrated measurements which would be used for integration. The C is the intrinsic calibration matrix (approximate equals to I6) for the IMU model (Rehder et al., 2016), and can be modeled as:\nC C\u03c9 C\u00d7 03\u00d73 Ca [ ] (2) Where C\u03c9 contains scale factor and axis misalignment for gyroscope measurements, Ca contains scale factor and axis misalignment for accelerometer measurements, both C\u03c9 and Ca are approximately equal to identity matrix I3. C\u00d7 is the coefficient matrix. It indicates the effect that the linear accelerometer has on the gyroscope, and is approximately equal to 03\u00d73. So the gyroscope measurement (angular velocity) model can be represented as:\n\u03c9\u0302t C\u03c9\u03c9t + C\u00d7at + b\u03c9t + n\u03c9t C\u03c9\u03c9t + \u0394\u03c9t (3) In the formula above, we abbreviate the compensation component for gyroscope measurements as:\n\u0394\u03c9t C\u00d7at + b\u03c9t + n\u03c9t (4) Where the compensation component \u0394\u03c9t is related to both gyroscope measurements and accelerometer measurements. By integrating the corrected angular velocity \u03c9\u0302t, we can achieve the estimation of 3D rigid rotation follows the equation below:\nRt+\u0394T RtExp \u03c9\u0302t\u0394T( ) (5) Where Rt \u2208 SO(3) and Rt+\u0394T \u2208 SO(3) are the rotation matrices. t is the timestamp that IMU outputs measurements, and \u0394T is the minimal time interval between two consecutive IMU readings. In our case, the IMU runs at 200 Hz, and the \u0394T is 5 ms. Exp (\u00b7) is the exponential map for SO(3). As indicated in the above formula, incorrect \u03c9\u0302t will lead to continuous error accumulation as more integrations propagate.\nFrontiers in Robotics and AI | www.frontiersin.org January 2022 | Volume 8 | Article 7725833"
        },
        {
            "heading": "3.3 Calib-Net for IMU Measurement Correction",
            "text": "As shown in Eq. 3 and Figure 1, C\u03c9 and \u0394\u03c9t play an important role in IMU calibration and orientation estimation. In most cases, C\u03c9 will be taken as a constant matrix, and \u0394\u03c9t is a small timevarying vector affected by many factors. In our proposed calibration system, we use the Caib-Net to estimate the compensation part \u0394\u03c9t for angular velocity measurements. The detailed structure of the Calib-Net is shown in Figure 2. It takes the long temporal sequential gyroscope measurements and accelerometer measurements as the network input, and network can be represented as below:\n\u0394\u03c9t F \u03c9t\u2212k\u0394T, at\u2212k\u0394T, . . . ,\u03c9t, at( ) (6) Where k is the number of IMU readings used as the input of the proposed Calib-Net. F (\u00b7) represents the nonlinear function that the Calib-Net stands for. Dilation convolution is adopted to extract spatio-temporal features of IMU measurements. As shown in Figure 3, by introducing the dilation convolution, the historically temporal measurements are fed into the network and used for feature extraction. Dilation size in dilation convolution indicates the spacing between the convolution kernel points, so with different kernel sizes and dilation sizes, different temporal IMU readings will be taken\naccordingly. To be specific, the length of the input depends on the product of kernel size and dilation size. In the presented network shown in Figure 2, the maximum product value is 448 which means the network will take k 448 IMU readings as the network input.\nThe Calib-Net is composed of two dilation convolutional layers, one residual block, and two fully connected layers. The residual block includes two dilation convolutional layers and one shortcut. The detailed configuration of each layer is given in Figure 2. As to the matrixC\u03c9, we set it to the trainable variable. In this way, following the mathematical model shown in Figure 1, the parameters of Calib-Net and \u0394\u03c9t can be trained and optimized driven by the carefully designed loss function."
        },
        {
            "heading": "3.4 Loss Function for Regression",
            "text": "There are many losses that are widely used for solving the regression problem (Jadon, 2020). The losses include L1 Loss using Mean Square Error (MSE), L2 Loss using Mean Absolute Error (MAE), Huber Loss using Smooth Mean Absolute Error, etc. L1 Loss is robust to outliers. however, its gradient is always the same during the training and is still large even faced with small loss values. In this way, it is hard and inefficient for L1 Loss to find the minima at the end of training. On the contrary, L2 Loss is sensitive to outliers, but it is easier for L2 Loss to find a stable solution. Huber loss combines the advantages of L1 Loss and L2 Loss, it is more robust to outliers than L2 Loss and can decrease the gradient around the minima.\nIn our proposed Calib-Net, we choose to use the log hyperbolic cosine (log-cosh) loss for gyroscope measurement correction regression. Compared with the Huber Loss, it approximately equals (y \u2212 y\u2032)2/2 for the small loss and to |y \u2212 y\u2032| \u2212 log(2) for the large loss, so it has all the advantages of Huber Loss and is twice differentiable for both small loss and large loss. The loss function is defined as below:\nL y, y\u2032( ) \u2211n i 1 log cosh y \u2212 y\u2032( )( ) (7)\nFIGURE 3 | The illustration of 1D Dilation Convolution. Dilation size indicates the spacing between the convolution kernel points.\nFrontiers in Robotics and AI | www.frontiersin.org January 2022 | Volume 8 | Article 7725834\nWhere y is the label (ground truth) of orientation in our case, and y\u2032 is the estimated orientation using the calibrated gyroscope value (namely angular velocity).\nWe also use multi-scale orientation loss to achieve better calibration performance. The orientation is estimated through the integration of calibrated angular velocity. So we adopt\nFrontiers in Robotics and AI | www.frontiersin.org January 2022 | Volume 8 | Article 7725835\ndifferent time intervals to compute the loss and perform the backpropagation driven by the loss. The loss used for network training is shown below:\nL \u2211n i 1 L\u0394t +\u2211 n/2 i 1 L2\u0394t +\u2211 n/4 i 1 L4\u0394t +/ + Ln\u0394t (8)\nWhere n \u00b7\u0394t is the maximum time interval used for computing the loss, and its value is n 2x. By carefully selecting different \u0394t and n using the trial and error method, we can adopt the suitable rotation transformation combination to train the calibration parameters."
        },
        {
            "heading": "4 EXPERIMENTAL EVALUATION",
            "text": "In this section, we evaluate the performance of our proposed Calib-Net using the public EuROC dataset Burri et al. (2016). Both quantitive and qualitative experiments are performed for comparison. We first compare the orientation estimation performance of our Calib-Net with different deep learning methods. Then we replace the gyroscope measurements used for the OpenVINS system with the calibrated angular velocity\nfrom our Calib-Net, and compare the performance with state-ofthe-art VIO methods.\nFor the training of our Calib-Net, most computers with a normally configured GPU are enough. In our case, we use a desktop equipped with an Intel i7-8700K CPU with 3.7-GHz and an Nvidia GeForce GTX 1060 GPU with 6 GB memory. The framework of Calib-Net is implemented based on PyTorch. We use the ADAM optimizer for the network training, the learning rate is set to 0.01, and the weight decay is 0.1. The consine anneal warm restart scheduler is adopted for network learning. The weight parameter for logcosh loss is 1e6. The IMU runs at 200 Hz, so the \u0394T is 5 ms in our case. For loss computing, we set \u0394t to 80 ms and n to 2 (as illustrated in Eq. 8) which means we use 16 and 32 IMU readings for integration. We training the network for 1,200 epochs and it only takes about 8.5min with the Nvidia GTX 1060 GPU which can be reached easily. For the test procedure, our proposed lightweight Calib-Net can easily reach real-time performance for calibration and orientation estimation (the IMU reading is 200 Hz)."
        },
        {
            "heading": "4.1 Calibration Performance Evaluation Among Learning-Based Methods",
            "text": "We first evaluate the proposed Calib-Net by comparing the orientation estimation performance with other learning-based methods. Absolute Orientation Error (AOE) is adopted as the evaluation metric. We choose the evaluation tool (Zhang and Scaramuzza, 2018) to compute the metric. Except for AOE, we also adopt the yaw error as the metric as achieving the accurate yaw angle estimation is most difficult for IMU.\nThe public EuROC dataset (Burri et al., 2016) is used for the evaluation, and the uncalibrated ADIS16448 IMU is adopted in the dataset. We take MH_01_easy, MH_03_medium, MH_05_difficult, V1_02_medium, V2_01_easy, V2_03_difficult as the training sequences, and take MH_02_easy, MH_04_difficult, V1_01_easy, V1_03_difficult, V2_02_medium as the testing sequences. As shown in Table 1, our proposed Calib-Net outperforms the raw IMU data in terms of the orientation estimation and yaw\nFrontiers in Robotics and AI | www.frontiersin.org January 2022 | Volume 8 | Article 7725836\nestimation. When comparing with the state-of-the-art learningbased calibration methods, our framework defeats both OriNet (Esfahani et al., 2019b) and GyroNet (Brossard et al., 2020b) on most sequences. What is more, OriNet (Esfahani et al., 2019b) adopts the Long Short-Term Memory (LSTM) component for spatio-temporal feature extraction and needs larger GPU memory. Our framework adopts dilation convolutions and proper loss function which construct an easy (less hyperparameters) but efficient (better feature learning) neural network.\nWe also plot the estimated orientation in Figure 4 to give a more compact demonstration of our system\u2019s performance. The blue line indicates the ground truth of the orientation (roll, yaw, pitch), the red line indicates the estimated orientation with our Calib-Net, the green line indicates the estimated orientation with the GyroNet, and the yellow line indicates estimated orientation from the raw IMU data. All orientations here are got only through the integration of the angular velocity. As shown in the figure, when using the raw IMU data to perform orientation estimation, the errors will be accumulated and the integrated orientation will drift in a short time due to inaccurate calibration. Our Calib-Net (red line) is most close to the ground truth and achieves the best performance among these methods."
        },
        {
            "heading": "4.2 Calibration Performance Evaluation",
            "text": "Using VIO Methods In order to further prove the effectiveness of our proposed framework, we also introduce the calibrated angular velocity from our Calib-Net into a well-known VIO system (OpenVINS) which achieves state-of-the-art performance recently. The new VIO system combined with our Calib-Net is called OpenVINS*. We present the quantitative orientation estimation results in Table 2. As shown in the table, OpenVINS* performs better than OpenVINS in most cases, and achieves the best mean results in terms of orientation and yaw estimation.We also plot the trajectories with these methods in Figure 5. The OpenVINS* with carefully calibrated angular velocity achieves better performance in trajectory estimation. This proves that our proposed Calib-Net can accurately correct the angular velocity measurements and the calibrated angular velocity is fruitful for VIO systems.\nWhen comparing the estimated orientation of Calib-Net (shown in table I) with that of VIO methods (shown in table II), we can find that our Calib-Net can even compete with VIO methods in terms of orientation estimation. What is more, the average yaw error of our Calib-Net is 0.87\u00b0, and it performs better than all VIO methods which include Open-VINS* with 1.11\u00b0, Open-VINS with 1.37\u00b0, VINS-Mono with 2.14\u00b0. This further indicates that a carefully calibrated low-cost IMU can achieve similar (even better in some aspects) performance when comparing with visual-inertial methods."
        },
        {
            "heading": "5 CONCLUSION AND FUTURE WORK",
            "text": "In this paper, we present a light-weight deep convolutional neural network for low-cost IMU calibration which is called Calib-Net. A mathematical calibration model is introduced to design the training and calibration framework. Dilation convolution is adopted for spatio-temporal feature extraction of IMU measurements. Driven by a carefully designed loss function, the Calib-Net can be optimized to output the compensation for raw gyroscope measurements. Corresponding experimental evaluations are performed to prove the effectiveness of our proposed Calib-Net. The results show that our framework achieves quite good calibration performance and the orientation estimation performance of our Calib-Net can even compete with state-of-the-art VIO methods. However, the generalization ability of the proposed network to different types of IMU is still challenging, and we would like to try more datasets and study more about it. What is more, we plan to use the deep neural network to perform odometry to deadreckon both translation and rotation. We also consider introducing deep learning technology for visual-inertial odometry.\nDATA AVAILABILITY STATEMENT\nPublicly available datasets were analyzed in this study. This data can be found here: https://projects.asl.ethz.ch/datasets/.\nAUTHOR CONTRIBUTIONS\nRL and WY propose the idea, RL and CF design and implement the experiment. All authors contribute to the writing and data analysis. All authors agree to be accountable for the content of the work.\nFUNDING\nThis work was supported by Science and Technology Innovation 2030 Major Project under Grant No. 2020AAA0104802. It was also supported by the National Natural Science Foundation of China under Grant No. 61903377 and Grant No. 91948303."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "The authors would like to thank Martin Brossard for his kindly help and insightful discussion.\nFrontiers in Robotics and AI | www.frontiersin.org January 2022 | Volume 8 | Article 7725837"
        }
    ],
    "title": "Calib-Net: Calibrating the Low-Cost IMU via Deep Convolutional Neural Network",
    "year": 2021
}