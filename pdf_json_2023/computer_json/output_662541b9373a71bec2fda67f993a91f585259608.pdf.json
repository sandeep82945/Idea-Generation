{
    "abstractText": "Machine reading comprehension (MRC) methods have shown great success in many datasets, but existing methods fail to achieve satisfactory results in low-resource scenarios. In addition, existing MRC models suffer from a notable decrease in performance when confronted with scenes different from the training data. Thus, it is hard to transfer knowledge between domains. In this paper, we propose an adaptive metalearning framework to learn and transfer the shared knowledge. The framework is based on model-agnostic meta-learning algorithm, aiming to aggregate meta-knowledge among multi-source datasets. Furthermore, for better adaptation to different target domain, we investigate an adaptive adversarial training strategy to obtain domain-specific meta-knowledge. We empirically adopt three large-size datasets as source domains and five small-size datasets as target domains, and extensive experiments show the effectiveness of our framework.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zhe Wen"
        },
        {
            "affiliations": [],
            "name": "Yatao Qi"
        },
        {
            "affiliations": [],
            "name": "Huan Liu"
        },
        {
            "affiliations": [],
            "name": "Zheng Lin"
        },
        {
            "affiliations": [],
            "name": "Weiping Wang"
        }
    ],
    "id": "SP:a49c9bac1e979bb4a31bd54ce17e92503ba62b7c",
    "references": [
        {
            "authors": [
                "J. Devlin",
                "M.-W. Chang",
                "K. Lee",
                "K. Toutanova"
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv preprint arXiv:1810.04805, 2018.",
            "year": 1810
        },
        {
            "authors": [
                "A. Talmor",
                "J. Berant"
            ],
            "title": "Multiqa: An empirical investigation of generalization and transfer in reading comprehension",
            "venue": "ACL, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "C. Finn",
                "P. Abbeel",
                "S. Levine"
            ],
            "title": "Model-agnostic meta-learning for fast adaptation of deep networks",
            "venue": "ICML, 2017, pp. 1126\u20131135.",
            "year": 2017
        },
        {
            "authors": [
                "P. Jiang",
                "A. Wu",
                "Y. Han",
                "Y. Shao",
                "M. Qi",
                "B. Li"
            ],
            "title": "Bidirectional adversarial training for semi-supervised domain adaptation.",
            "venue": "in IJCAI,",
            "year": 2020
        },
        {
            "authors": [
                "P. Rajpurkar",
                "J. Zhang",
                "K. Lopyrev",
                "P. Liang"
            ],
            "title": "Squad: 100,000+ questions for machine comprehension of text",
            "venue": "arXiv preprint arXiv:1606.05250, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "A. Trischler",
                "T. Wang",
                "X. Yuan",
                "J. Harris",
                "A. Sordoni",
                "P. Bachman",
                "K. Suleman"
            ],
            "title": "Newsqa: A machine comprehension dataset",
            "venue": "arXiv preprint arXiv:1611.09830, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "J. Welbl",
                "P. Stenetorp",
                "S. Riedel"
            ],
            "title": "Constructing datasets for multihop reading comprehension across documents",
            "venue": "TACL, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "D. Dua",
                "Y. Wang",
                "P. Dasigi",
                "G. Stanovsky",
                "S. Singh",
                "M. Gardner"
            ],
            "title": "Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs",
            "venue": "arXiv preprint arXiv:1903.00161, 2019.",
            "year": 1903
        },
        {
            "authors": [
                "A. Abujabal",
                "R.S. Roy",
                "M. Yahya",
                "G. Weikum"
            ],
            "title": "Comqa: A community-sourced dataset for complex factoid question answering with paraphrase clusters",
            "venue": "arXiv preprint arXiv:1809.09528, 2018.",
            "year": 1809
        },
        {
            "authors": [
                "A. Talmor",
                "J. Berant"
            ],
            "title": "Repartitioning of the complexwebquestions dataset",
            "venue": "arXiv preprint arXiv:1807.09623, 2018.",
            "year": 1807
        },
        {
            "authors": [
                "C. Clark",
                "K. Lee",
                "M.-W. Chang",
                "T. Kwiatkowski",
                "M. Collins",
                "K. Toutanova"
            ],
            "title": "Boolq: Exploring the surprising difficulty of natural yes/no questions",
            "venue": "Proceedings of NAACL-HLT, 2019, pp. 2924\u20132936.",
            "year": 2019
        },
        {
            "authors": [
                "D. Golub",
                "P.-S. Huang",
                "X. He",
                "L. Deng"
            ],
            "title": "Two-stage synthesis networks for transfer learning in machine comprehension",
            "venue": "arXiv eprints, pp. arXiv\u20131706, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "X. Liu",
                "K. Liu",
                "X. Li",
                "J. Su",
                "Y. Ge",
                "B. Wang",
                "J. Luo"
            ],
            "title": "An iterative multi-source mutual knowledge transfer framework for machine reading comprehension.",
            "venue": "in IJCAI,",
            "year": 2020
        },
        {
            "authors": [
                "D. Friedman",
                "B. Dodge",
                "D. Chen"
            ],
            "title": "Single-dataset experts for multidataset question answering",
            "venue": "arXiv preprint arXiv:2109.13880, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Conneau",
                "G. Lample"
            ],
            "title": "Cross-lingual language model pretraining",
            "venue": "Advances in neural information processing systems, vol. 32, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "Z. Yang",
                "Z. Dai",
                "Y. Yang",
                "J. Carbonell",
                "R.R. Salakhutdinov",
                "Q.V. Le"
            ],
            "title": "Xlnet: Generalized autoregressive pretraining for language understanding",
            "venue": "NeurIPS, vol. 32, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "Y. Liu",
                "M. Ott",
                "N. Goyal",
                "J. Du",
                "M. Joshi",
                "D. Chen",
                "O. Levy",
                "M. Lewis",
                "L. Zettlemoyer",
                "V. Stoyanov"
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692, 2019.",
            "year": 1907
        },
        {
            "authors": [
                "J. Liu",
                "M. Yu",
                "Y. Chen",
                "J. Xu"
            ],
            "title": "Cross-domain slot filling as machine reading comprehension: A new perspective",
            "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 30, pp. 673\u2013685, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Y.-A. Chung",
                "H.-Y. Lee",
                "J. Glass"
            ],
            "title": "Supervised and unsupervised transfer learning for question answering",
            "venue": "NAACL-HLT, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Y. Hua",
                "Y.-F. Li",
                "G. Haffari",
                "G. Qi",
                "W. Wu"
            ],
            "title": "Retrieve, program, repeat: complex knowledge base question answering via alternate metalearning",
            "venue": "arXiv preprint arXiv:2010.15875, 2020.",
            "year": 2010
        },
        {
            "authors": [
                "S. Li",
                "X. Wang",
                "Y. Cao",
                "F. Xue",
                "Z. Yan",
                "H. Zha"
            ],
            "title": "Self-supervised deep visual odometry with online adaptation",
            "venue": "CVPR, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "D. Guo",
                "D. Tang",
                "N. Duan",
                "M. Zhou",
                "J. Yin"
            ],
            "title": "Coupling retrieval and meta-learning for context-dependent semantic parsing",
            "venue": "ACL, 2019.",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Natural Language Understanding, Machine Reading Comprehension, Meta Learning, Adversarial Training.\nI. INTRODUCTION\nMachine reading comprehension (MRC) attempts to answer many kinds of questions, including simple questions and multihop reasoning questions, after reading a document or multiple documents.Recently, MRC models based on the manner of fine-tuning the pre-trained language model for downstream tasks, have achieved acceptable performance [1]. However, these models still rely on an adequate scale of the training data in the target domain. When confronted with the lowresource MRC task, even the performance of models based on pre-training deteriorates significantly.\nAs shown in Figure 1, as the scale of the labeled data reduced, the performance of BERT-based MRC model decreases by a large margin. Specifically, when approximately 40% data is used for training, the performance curve falls sharply. In fact, for some domains, the lack of adequate labeled data makes it difficult to train a domain-specific MRC model with satisfactory performance. Therefore, it is of great importance and necessity to solve the low-resource problem in MRC.\nAn intuitive solution is to generalize or transfer knowledge learned in resource-rich domains to resource-poor domains. [2] trained models on one or more source MRC datasets, and then evaluated their performance on a target domain, either without any additional target training examples (generalization) or with additional target examples (transfer). They found that current\nCorresponding author. DOI reference number: 10.18293/SEKE2023-179.\nmodels over-fit to the particular training set and generalize poorly even to similar datasets. Besides, they also investigated the effect of knowledge transfer based on domain-level similarities and fine-tuning. Despite some improvements, the shared knowledge among multiple datasets of source domains has not been fully exploited. Although each MRC dataset involves the use of different expertise, there is still substantial overlap in the abilities required to answer questions across these datasets. Therefore, we believe it is meaningful to effectively exploit the shared knowledge among multiple datasets, and use them to promote the language understanding of the low-resource setup.\nFor a target domain, the learning objective is to find an optimal model that is well adapted to the current data. However, due to the lack of sufficient training samples, the optimal parameters oscillate with time during training. Therefore, it is difficult to learn an acceptable model with insufficient data. To address this issue, we propose an adaptive meta-learning framework for multi-source domain adaptation of MRC. The intuition behind the framework is that the past experience over multiple source domains can be used to facilitate the adaptation to a new environment. Specifically, we employ a model-agnostic meta-learning (MAML) algorithm [3] to aggregate the meta-knowledge from multiple source domains. The main focus of this paper is not to propose a new metalearning algorithm, but to explore whether the representative meta-learning algorithm MAML is suitable for many-to-one machine reading comprehension scenario, and how to improve the domain transfer ability under the MAML framework.\nSince meta-knowledge is transferred, there is still a gap between source domains and target domains. Especially when\nthe difference of data distribution is large, the performance of domain adaptation will be highly affected. To fill the domain gap, one possible way is to generate adversarial examples through adding imperceptible perturbations on inputs, which can be used to improve the model robustness [4]. However, the traditional adversarial training adds noises with the gradient of the source domain, which is futile to cross the domain gap. It may even broaden the gap. To solve this issue, we design an adaptive meta-learning framework based on adaptive adversarial training strategy, and employ gradient of the target domain to guide adversarial examples generation in the source domain. Therefore, we can obtain domain-specific meta-knowledge, rather than the fixed one.\nThe main contributions can be summarized as follows: \u2022 To overcome the challenge of low-resource MRC, we\npropose an adaptive meta-learning framework. With this framework, the meta knowledge across multiple source domains can be learned, which is further used to enhance the target-domain MRC ability. Besides, it can be easily combined with arbitrary MRC models like BERT. \u2022 To bridge the gap between domains in meta-learning, we devise an adaptive adversarial training strategy. It helps obtain the domain-specific meta knowledge. For both the generality and the individuality are taken into consideration, it is more suitable for each target domain. \u2022 We evaluate our model on three resource-rich source datasets and five resource-poor target datasets, and the results demonstrate that the proposed model consistently outperforms state-of-the-art baselines considerably."
        },
        {
            "heading": "II. METHODOLOGY",
            "text": ""
        },
        {
            "heading": "A. Task Definition",
            "text": "In general, MRC tasks can be categorized into the extractive setting and the multiple-choice setting. To facilitate knowledge transfer, we formulate all the MRC datasets to the extractive type. Therefore, the example in all datasets contains a question, a paragraph, and an answer whose content is a local context extracted from the original paragraph.\nFormally, given the paragraph P and a question Q, the goal of MRC is to extract an answer span [s, e] from P , where s denotes the start position and e denotes the end position in P ."
        },
        {
            "heading": "B. Framework of Adaptive Meta-Learning",
            "text": "Our adaptive meta-learning framework consists of two parts: Multi-source Meta-Learning (MML) and Adaptive Adversarial Training (AAT). In the process of MML, the meta-knowledge is learned on the merged data of multiple source domains DS = {DS1 , DS2 , ..., DSn} through MAML [3].\nIn the process of AAT, the adaptive adversarial examples are generated, which can be used in MML to encourage the meta-model to learn toward the target domain. Specifically, the generation of adaptive adversarial samples D\u0303STi is guided by the gradient of the target domain {DT1 , DT2 , ..., DTm}, respectively. Then, D\u0303STi participates in the meta-learning process together with DS in a data-augmentation way. The details of adaptive meta-learning are summarized in Algorithm 1.\nAlgorithm 1 The procedure of Adaptive Meta-Learning Input: Multi-source data DS , target data DTi , three sets of parameters \u03b8\u2217, \u03b8\u0302, \u03b8t, and their learning rate \u03b1, \u03b2, \u03b3 Output: Optimized parameters \u03b8\u2217\n1: Initialize \u03b8\u2217, \u03b8\u0302, \u03b8t; 2: Fine-tune the target model parameters \u03b8t on data DTi :\n\u03b8t \u2032 = \u03b8t \u2212 \u03b3\u2207\u03b8tL(f(\u03b8t, DTi ));\n3: for all XS from DS do 4: Compute gradients on \u03b8t with data XS , and generate\nadversarial samples: X\u0303S = XS + \u03bb \u2217 \u2207\u03b8t\n5: end for 6: Merge D\u0303S and DS , get new source dataDS \u2032 ; 7: while not convergent do 8: Sample data {DS1 , ..., DSK} from DS\u2032 ; 9: for i = 1 to K do\n10: Sample support set DSiSup from D Si and train the\nmodel \u03b8\u0302: \u03b8\u0302\u2032 = \u03b8\u0302 \u2212 \u03b1\u2207\u03b8\u0302L(f(\u03b8\u0302, DSup))\n11: Sample query set DSiQue from D Si and compute\ngradients for accumulation: \u03b8\u0302acc+ = \u03b8\u0302, \u2207\u03b8\u0302acc+ = \u2207\u03b8\u0302L(f(\u03b8\u0302, DQue))\n12: end for 13: Meta model update: \u03b8\u2217 = \u03b8\u0302acc/K, \u03b8\u2217\u2032 = \u03b8\u2217 \u2212 \u03b2\u2207\u03b8\u0302acc/K; 14: end while 15: Transfer \u03b8\u2217 as the initial parameters to the downstream\ntask DTi and fine-tune."
        },
        {
            "heading": "C. Multi-source Meta-Learning",
            "text": "MML is used to aggregate the meta-knowledge from multiple resources. In the meta-learning problem setting, the goal is to learn models that can learn new tasks from small amounts of data. To achieve this, meta-learning algorithms require a set of meta-training and meta-testing tasks drawn from a certain distribution. The key assumption of learning-to-learn is that the tasks in this distribution share common structure that can be exploited for faster learning of new tasks.\nThere are two sets of model parameters required in metalearning. One set of parameters is used for the meta-training task denoted as \u03b8\u0302, another set is used for the meta-testing task denoted as \u03b8\u2217. For a downstream task, \u03b8\u2217 is employed for model initialization and to be fine tuned afterward. The process of MML is described as follows:\nMeta-learning involves multiple sampling data subsets DSample = {DS1 , DS2 , ..., DSK}. Each sampling subset DSi includes a support set and a query set, denoted as DSi = {DSiSup, D Si Que}, and each pair of the support set and the query set is sampled from the same distribution. Fast Optimization In a sampling subset, we utilize the support set DSiSup to optimize \u03b8\u0302. This process can be regarded as applying DSiSup as the training data to train a model, and the model parameters are optimized by stochastic gradient descent.\n\u03b8\u0302\u2032 = \u03b8\u0302 \u2212 \u03b1\u2207\u03b8\u0302LDSiSup(f(\u03b8\u0302)), (1)\nwhere L denotes the cross-entropy loss function, and \u03b1 denotes the learning rate.\nGradients Calculation After the previous step, we can obtain a set of optimized parameters. Then, we utilize these parameters to calculate the gradients on the respective query set. This process can be regarded as applying DSiQue as the development data to evaluate the sampled task.\nGradients Accumulation Next, the gradients of multiple sampled data points are accumulated. Since the accumulation operation considers the gradient direction generated from various subsets, it can be regarded as the shared knowledge across multi-domain being learned.\nParameters Update The cumulative gradient is used to update the parameters of the meta-model. Each update of \u03b8\u2217 is seen as one step of training for meta-model. The formula used to update the parameters is as follows:\n\u03b8\u2217\u2032 = \u03b8\u2217 \u2212 \u03b2\u2207\u03b8\u0302acc/K, (2)\nwhere \u03b8\u0302acc denotes the accumulative gradients on the parameters \u03b8\u0302, and \u03b2 is the learning rate, and K is the number of sampling tasks.\nTarget Fine-tuning Through multiple iterations of the above steps, a set of meta-model parameters \u03b8\u2217 is learned. Then, we fine-tune the target model with the initial parameters \u03b8\u2217 and the target dataset DTi , to enable the model to be close to the target domain."
        },
        {
            "heading": "D. Adaptive Adversarial Training",
            "text": "Under the framework of meta-learning, we further propose Adaptive Adversarial Training (AAT) aiming to bridge the gap between domains. It is based on the idea of improving model generalization capability by adversarial training. Adversarial training uses a mixture of adversarial and original examples\nto train a model to make it more robust. Here, the adversarial examples are in the form of continuous vectors instead of actual texts in natural languages. Specifically, adversarial examples are slightly different from original examples, and they are generated by adding imperceptible perturbation to the embeddings of the original examples. We first feed the source data DS into a frozen well-trained target domain network, and then generate adversarial samples D\u0303STi in the direction of the target domain. The process of AAT is described as follows:\nPerturbator Training To generate adversarial samples more adapted to the target domain, we take the target model as a perturbator. After fine-tuning on the target data DTi , we acquire a target model \u03b8t, which is used to generate directional perturbations. The perturbator is optimized as:\n\u03b8t \u2032 = \u03b8t \u2212 \u03b3\u2207\u03b8tL(f(\u03b8t, DTi )), (3)\nwhere \u03b3 is the learning rate and L denotes the cross-entropy loss function in MRC\nAdversarial Examples Generation Next, the perturbator \u03b8t and the multi-source data DS are used to generate the adaptive adversarial examples. Specifically, the objective of this step is to increase the loss of the target model, given Xs sampled from DS and its added perturbation generated from DTi . Through multiple iterations of the above step, we can obtain the set of adaptive adversarial examples D\u0303STi corresponding to D\nS . Then, D\u0303STi is used to train the meta-model in MML, as well as the previous source-domain data."
        },
        {
            "heading": "III. EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "A. Datasets",
            "text": "In the experiments, we choose eight reading comprehension datasets with different sizes. According to the size of each dataset, we briefly divide the datasets into source domain and target domain. Specifically, three larger ones SQuAD [5], NewsQA [6] and HotpotQA [7] are merged into multi-source data, and five smaller ones DROP [8], WikiHop [7], ComQA [9], ComplexQuestion [10] and BoolQ [11] are regarded as target dataset respectively.\nOur adaptive meta-learning method transfers the metaknowledge aggregated from multi-source domain datasets to each target dataset. Due to the insufficient computation resources, we randomly sample 100K examples from each source dataset and combine them as the whole source-domain dataset."
        },
        {
            "heading": "B. Baselines",
            "text": "We mainly compare our method with several popular pretrained models, which present state-of-the-art performance in recent MRC tasks. These pre-trained models are directly finetuned on target dataset. Besides, we also compare our method with the single-source transfer method and the multi-source transfer method. For all methods, we adopt the Exact Match (EM) and the F1 score as our evaluation metrics.\nBERT, XLM, XLNet, RoBERTa: They are Transformerbased pre-trained language models.\nSynNet: SynNet [12] is a data augmentation method using a two-stage synthesis network for MRC.\nIMM: IMM [13] is an iterative multi-source mutual knowledge transfer framework for MRC.\nMADE: MADE [14] is to model multi-dataset question answering with an ensemble of single-dataset experts, by training a collection of dataset-specific adapter modules that share an underlying Transformer model.\nSingleSource-T: We use BERT to train a MRC model on single-source dataset, and then transfer the trained model to target domain and fine-tune it with target dataset.\nMultiQA: MultiQA [2] is a BERT based MRC model, which is trained on merged multi-source dataset, and then transfer the trained model to the target domain.\nSingleSource-M: We use MAML to learn meta knowledge on single-source dataset, and then transfer the meta knowledge to target domain and retrain it with target dataset.\nMultiQA-M: We use MAML to learn meta knowledge on merged multi-source dataset, and then transfer the meta knowledge to target domain and retrain it with target dataset."
        },
        {
            "heading": "C. Experimental Setup",
            "text": "In the experiments, for each target domain and each baseline model, only 300 labeled samples are used for domain adaptation. For the MRC task, it can be seen as a low-resource scenario, because a few hundreds of samples are insufficient to learn a robust model. In the MADE [14], all the 300 examples are used to fine-tune the adapters. In the meta-learning, the 300 samples are divided into support set and query set. The number of the support set and the query set are set to 280 and 20 respectively. We implement our model based on the Transformers released by Hugging Face, running on a TITAN RTX GPU. The reported experimental results of our model are average of 5 runs. Following the settings of MultiQA [2], we set the training batch size to 24 and three learning rate \u03b1, \u03b2, \u03b3 uniformly to 3e-5. We set maximum length of input sequence to 384. The length of some documents exceeds the limitation, thus we tailor the original document into pieces with the sliding window size of 384 and sliding stride of 128. All models adopt Adam with \u03b21 = 0.9, \u03b22 = 0.999 for optimization and generally converge after 2 epochs."
        },
        {
            "heading": "D. Overall Performance",
            "text": "In order to evaluate the effectiveness of the proposed method, we test various baselines on five target datasets. Table I presents the main experimental results. From Table I, we can make three important observations.\nFirst, the models whose knowledge transferred from multiple source datasets perform better than those transferred from the single dataset in most cases. For the BERT-based (non-meta) knowledge transfer methods, MultiQA performs consistently better than NewsQA-T, HotpotQA-T and SQuADT, on EM and F1 respectively. For the meta knowledge transfer methods, MultiQA-M achieves a notable performance gain against NewsQA-M, HotpotQA-M and SQuAD-M. This is in accordance with our intuition, which indicates that there are\nshared abilities required to answer questions across different datasets, and exploring the shared abilities from multiple source datasets instead of the single one is helpful to improve the performance of the target-domain MRC.\nSecond, MultiQA-M performs better than the fine-tuned methods, including BERT, XLM [15], XLNet [16] and Roberta [17], and also outperforms the traditional knowledge transfer methods, including SynNet, IMM and MultiQA. The reason for the unsatisfactory results of fine-tuned methods mainly lies in the lack of sufficient training data for the target domain, and high-capacity parameters of the pre-training models. In general, pre-trained representations improve generalization, but their effect is moderate when the training data is insufficient. Besides, due to the meta-knowledge over multiple source domains promoting the fast convergence and adaptation to the target domain, transferring meta-knowledge is superior to the traditional knowledge. It suggests that meta-learning over multiple source domains is good at capturing the shared knowledge regardless of the data imbalance and different focus.\nThird, our model achieves the best performance on all target datasets, and outperforms the baselines by a large margin. It indicates that not only the meta-knowledge but also the domain-specific meta-knowledge contribute to the effectiveness of our model. From the experimental results, we can infer that, in view of the meta-knowledge, there is still a gap between source domains and target domains. And correspondingly, the proposed adaptive meta-learning strategy is effective to fill the gap. Because different meta-knowledge can be obtained in the direction of different target domain under our design, the domain-specific meta-knowledge is well adapted to each target domain. In general, our design takes both generality and individuality into account, which is more appropriate for multi-source domain adaptation in MRC.\nAs shown in Table I, our model and MADE model have different strengths on the target domain datasets. In fact, the two models follow two different technique lines, thus having\ndifferent expertise. Specifically, MADE is based on adapters, which provide a parameter-efficient alternative for the full fine-tuning in which we can only fine-tune lightweight neural network layers on top of pre-trained weights. However, our method is based on meta-learning, which helps optimize parameters to give better predictions in shorter time. Though the performance of two models is almost comparable, our method has two advantages. First, our method is model-agnostic and can be easily equipped with various machine learning models, including but not limited to pre-trained language models. Second, our method can train a more generalized model, which facilitates the learning of a novel task. For example, MADE performs better on WikiHop, ComQA and ComplexQuestion, but performs dramatically worse on Drop and BoolQ. Maybe it is because the former ones are all collected from Wikipedia, resulting in the similar question answering process, whereas Drop is crowd-sourced and adversarially created, and BoolQ provides quite different question type. By contrast, our method performs relatively stable among these datasets.\nBesides, it is worth noting that the results in Table I are lower than those reported in the Leaderboards. The reasons lie in two aspects. First and foremost, the goal of our work is not to design a highly complicated model or pre-processing technique to significantly surpass the existing methods. Instead, we hope to explore a direction for MRC domain adaptation and other similar transfer learning problems. In fact, some of the top ranked models on the Leaderboards are based on super large-scale language models, e.g., T5 and GPT3. Due to the limitation of computational capacity, we finally adopt the widely used Bert-base as our backbone model, but the proposed cross-domain method can be easily combined with the existing models. Second, the datasets used for the manuscript and the Leaderboards are different. In our work,\nfor each target domain, only 300 labeled samples are used for domain adaptation, while for the Leaderboards all labeled samples could be used.\nTo better measure the impact of randomness on the dataset, we have additionally compared the randomly sampling 100K data with intentionally selected 100K data from the multisource dataset. Specifically, the intentionally selected 100K samples are ranked alphabetically. Figure 3 presents the comparison results. As seen from Figure 3, our model performs basically equal on two kinds of datasets. It proves that our proposed method is less susceptible to the randomness on the quality of the combined multi-source dataset, to some extent."
        },
        {
            "heading": "E. Ablation Study",
            "text": "The main highlight of our work is the application of adaptive adversarial training in meta-learning for multi-source domain adaptation of MRC. To evaluate the effect of adaptive adversarial training, we compare our framework with its following variants: (1) Meta-learning without adversarial training. (2) Meta-learning with traditional adversarial training, i.e., the perturbations are added in the direction of the source domain. (3) Meta-learning with adaptive adversarial training, i.e., the perturbations are added in the direction of the target domain.\nOwing to the limitation of space, Figure 4 only illustrates the comparison results on four target datasets. From Figure 4, we can observe that compared with general meta-learning, the introduction of traditional adversarial training does not improve performance. In fact, the effectiveness of adversarial training mainly owns to its ability of local smoothness around data points, and pushing decision boundary away from data points. However, the generated examples surround the original examples, which has only limited ability to fill the domain gap. In order to guide the direction of generating adversarial examples from source domains towards target domain,\nwe further propose adaptive adversarial training. Moreover, traditional adversarial training under transfer scenario may further widen the gap between the source domain and target domain, thus resulting in a performance drop. Overall, it is surprising to find that meta-learning with adaptive adversarial training significantly outperforms the meta-learning with or without traditional adversarial training. The reason is that the proposed adaptive adversarial training can guide the generation of adversarial examples to the direction of the target domain, then the model trained with these adversarial examples can boost the adaptation ability."
        },
        {
            "heading": "IV. RELATED WORK",
            "text": "a) Transfer learning for MRC: MRC is a challenging Natural Language Processing research field with wide applications [18]. To address the low-resource MRC problem, previous studies usually use pre-trained language models to enhance the performance of MRC models, such as BERT. Meanwhile, many efforts have been made to use transfer learning methods to improve MRC performance in target domain via datasets in source domain, among which finetuning is the most common technique [19].\nRecently, [20] presented an alternate meta-learning framework for complex question answering over knowledge bases, which jointly and alternately optimized a retriever to select questions, and a programmer to produce an answer. However, this framework is designed for the scenario of question distributional bias within the same dataset instead of learning shared knowledge among different datasets. Differently, we aim to learn and transfer the shared knowledge among multiple MRC datasets through adaptive meta-learning. MADE [14] and our work share the similar motivation, but lie in different technique lines. MADE is based on adapter, which can be used as a parameter-efficient alternative to fine-tuning. We provide a investigation of meta learning combined with adaptive adversarial training, which is a missing part in the literature.\nb) Meta-Learning: Meta-learning exploits inherent structures in data to learn more effective learning rules for fast domain adaptation [21]. To make the model sensitive to the new task, one popular direction of meta-learning is to train a meta-learner to learn how to update the parameters of the target model. [3] proposed Model Agnostic Meta-Learning (MAML) that constrains the learning rule for the model and uses stochastic gradient descent to quickly adapt networks to new tasks. This pattern has been widely used to adapt deep networks to resource-poor environments. S2A [22] first trained a retriever and a programmer separately, and then established a meta-learning task for questions and employed MAML to finetune the programmer, based on the similar samples found by the retriever. Unlike the above works, we apply MAML to the multi-domain MRC task with an adaptive adversarial training in its framework, and it encourages the learned knowledge to fit each target domain well."
        },
        {
            "heading": "V. CONCLUSION",
            "text": "In this work, we propose an adaptive meta-learning framework for multi-source domain adaptation of MRC. With this framework, we can learn the meta-knowledge, which implies the shared abilities of reading comprehension, across multiple source datasets. Furthermore, an adaptive adversarial training strategy is devised to obtain domain-specific meta-knowledge, which fills the gap between source and target domains. Extensive experiments demonstrate that our framework establishes a state-of-the-art baseline for low-resource MRC."
        }
    ],
    "title": "Multi-source Machine Reading Comprehension with Meta-Learning and Adaptive Adversarial Training",
    "year": 2023
}