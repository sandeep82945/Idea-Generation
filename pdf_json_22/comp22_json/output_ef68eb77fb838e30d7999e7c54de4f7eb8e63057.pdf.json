{
    "abstractText": "Chinese Spell Checking (CSC) task aims to detect and correct Chinese spelling errors. Recently, related researches focus on introducing character similarity from confusion set to enhance the CSC models, ignoring the context of characters that contain richer information. To make better use of contextual information, we propose a simple yet effective Curriculum Learning (CL) framework for the CSC task. With the help of our model-agnostic CL framework, existing CSC models will be trained from easy to difficult as humans learn Chinese characters and achieve further performance improvements. Extensive experiments and detailed analyses on widely used SIGHAN datasets show that our method outperforms previous state-of-the-art methods. More instructively, our study empirically suggests that contextual similarity is more valuable than character similarity for the CSC task.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ding Zhang"
        },
        {
            "affiliations": [],
            "name": "Yinghui Li"
        },
        {
            "affiliations": [],
            "name": "Qingyu Zhou"
        },
        {
            "affiliations": [],
            "name": "Shirong Ma"
        },
        {
            "affiliations": [],
            "name": "Yangning Li"
        },
        {
            "affiliations": [],
            "name": "Yunbo Cao"
        },
        {
            "affiliations": [],
            "name": "Hai-Tao Zheng"
        }
    ],
    "id": "SP:a04a99402f90dce097ed97e6d2b9ec7257d07bd4",
    "references": [
        {
            "authors": [
                "Haithem Afli",
                "Zhengwei Qiu",
                "Andy Way",
                "P\u00e1raic Sheridan."
            ],
            "title": "Using SMT for OCR error correction of historical texts",
            "venue": "LREC. European Language Resources Association (ELRA).",
            "year": 2016
        },
        {
            "authors": [
                "Yoshua Bengio",
                "J\u00e9r\u00f4me Louradour",
                "Ronan Collobert",
                "Jason Weston."
            ],
            "title": "Curriculum learning",
            "venue": "ICML, volume 382 of ACM International Conference Proceeding Series, pages 41\u201348. ACM.",
            "year": 2009
        },
        {
            "authors": [
                "Xingyi Cheng",
                "Weidi Xu",
                "Kunlong Chen",
                "Shaohua Jiang",
                "Feng Wang",
                "Taifeng Wang",
                "Wei Chu",
                "Yuan Qi."
            ],
            "title": "Spellgcn: Incorporating phonological and visual similarities into language models for chinese spelling check",
            "venue": "ACL, pages 871\u2013881. As-",
            "year": 2020
        },
        {
            "authors": [
                "Xuxin Cheng",
                "Qianqian Dong",
                "Fengpeng Yue",
                "Tom Ko",
                "Mingxuan Wang",
                "Yuexian Zou."
            ],
            "title": "M3ST: mix at three levels for speech translation",
            "venue": "CoRR, abs/2212.03657.",
            "year": 2022
        },
        {
            "authors": [
                "Xuxin Cheng",
                "Zhihong Zhu",
                "Hongxiang Li",
                "Yaowei Li",
                "Yuexian Zou."
            ],
            "title": "SSVMR: saliencybased self-training for video-music retrieval",
            "venue": "CoRR, abs/2302.09328.",
            "year": 2023
        },
        {
            "authors": [
                "Yiming Cui",
                "Wanxiang Che",
                "Ting Liu",
                "Bing Qin",
                "Shijin Wang",
                "Guoping Hu."
            ],
            "title": "Revisiting pretrained models for chinese natural language processing",
            "venue": "EMNLP (Findings), volume EMNLP 2020 of Findings of ACL, pages 657\u2013668. Association for",
            "year": 2020
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: pre-training of deep bidirectional transformers for language understanding",
            "venue": "NAACL-HLT (1), pages 4171\u20134186. Association for Computational Linguistics.",
            "year": 2019
        },
        {
            "authors": [
                "Fei Dong",
                "Yue Zhang."
            ],
            "title": "Automatic features for essay scoring - an empirical study",
            "venue": "EMNLP, pages 1072\u20131077. The Association for Computational Linguistics.",
            "year": 2016
        },
        {
            "authors": [
                "Zifa Gan",
                "Hongfei Xu",
                "Hongying Zan."
            ],
            "title": "Selfsupervised curriculum learning for spelling error correction",
            "venue": "EMNLP (1), pages 3487\u20133494. Association for Computational Linguistics.",
            "year": 2021
        },
        {
            "authors": [
                "Li Huang",
                "Junjie Li",
                "Weiwei Jiang",
                "Zhiyu Zhang",
                "Minchuan Chen",
                "Shaojun Wang",
                "Jing Xiao."
            ],
            "title": "Phmospell: Phonological and morphological knowledge guided chinese spelling check",
            "venue": "ACL/IJCNLP (1), pages 5958\u20135967. Association for",
            "year": 2021
        },
        {
            "authors": [
                "Tom Kocmi",
                "Ondrej Bojar."
            ],
            "title": "Curriculum learning and minibatch bucketing in neural machine translation",
            "venue": "arXiv preprint arXiv:1707.09533.",
            "year": 2017
        },
        {
            "authors": [
                "Hongxiang Li",
                "Meng Cao",
                "Xuxin Cheng",
                "Zhihong Zhu",
                "Yaowei Li",
                "Yuexian Zou."
            ],
            "title": "Generating templated caption for video grounding",
            "venue": "CoRR, abs/2301.05997.",
            "year": 2023
        },
        {
            "authors": [
                "Yinghui Li",
                "Shirong Ma",
                "Qingyu Zhou",
                "Zhongli Li",
                "Li Yangning",
                "Shulin Huang",
                "Ruiyang Liu",
                "Chao Li",
                "Yunbo Cao",
                "Haitao Zheng."
            ],
            "title": "Learning from the dictionary: Heterogeneous knowledge guided fine-tuning for Chinese spell checking",
            "venue": "In",
            "year": 2022
        },
        {
            "authors": [
                "Yinghui Li",
                "Qingyu Zhou",
                "Yangning Li",
                "Zhongli Li",
                "Ruiyang Liu",
                "Rongyi Sun",
                "Zizhen Wang",
                "Chao Li",
                "Yunbo Cao",
                "Hai-Tao Zheng"
            ],
            "title": "2022b. The past mistake is the future wisdom: Error-driven contrastive probability optimization for chinese spell",
            "year": 2022
        },
        {
            "authors": [
                "Yichan Liang",
                "Jianheng Li",
                "Jian Yin."
            ],
            "title": "A new multi-choice reading comprehension dataset for curriculum learning",
            "venue": "ACML, volume 101 of Proceedings of Machine Learning Research, pages 742\u2013757. PMLR.",
            "year": 2019
        },
        {
            "authors": [
                "Cao Liu",
                "Shizhu He",
                "Kang Liu",
                "Jun Zhao."
            ],
            "title": "Curriculum learning for natural answer generation",
            "venue": "IJCAI, pages 4223\u20134229. ijcai.org.",
            "year": 2018
        },
        {
            "authors": [
                "Shulin Liu",
                "Tao Yang",
                "Tianchi Yue",
                "Feng Zhang",
                "Di Wang."
            ],
            "title": "PLOME: pre-training with misspelled knowledge for chinese spelling correction",
            "venue": "ACL/IJCNLP (1), pages 2991\u20133000. Association for Computational Linguistics.",
            "year": 2021
        },
        {
            "authors": [
                "Shirong Ma",
                "Yinghui Li",
                "Rongyi Sun",
                "Qingyu Zhou",
                "Shulin Huang",
                "Ding Zhang",
                "Li Yangning",
                "Ruiyang Liu",
                "Zhongli Li",
                "Yunbo Cao",
                "Haitao Zheng",
                "Ying Shen"
            ],
            "title": "Linguistic rules-based corpus generation for native Chinese grammatical error correc",
            "year": 2022
        },
        {
            "authors": [
                "Petru Soviany",
                "Radu Tudor Ionescu",
                "Paolo Rota",
                "Nicu Sebe."
            ],
            "title": "Curriculum learning: A survey",
            "venue": "arXiv preprint arXiv:2101.10382.",
            "year": 2021
        },
        {
            "authors": [
                "Yuen-Hsien Tseng",
                "Lung-Hao Lee",
                "Li-Ping Chang",
                "Hsin-Hsi Chen."
            ],
            "title": "Introduction to SIGHAN 2015 bake-off for chinese spelling check",
            "venue": "SIGHAN@IJCNLP, pages 32\u201337. Association for Computational Linguistics.",
            "year": 2015
        },
        {
            "authors": [
                "Dingmin Wang",
                "Yan Song",
                "Jing Li",
                "Jialong Han",
                "Haisong Zhang."
            ],
            "title": "A hybrid approach to automatic corpus generation for chinese spelling check",
            "venue": "EMNLP, pages 2517\u20132527. Association for Computational Linguistics.",
            "year": 2018
        },
        {
            "authors": [
                "Shih-Hung Wu",
                "Chao-Lin Liu",
                "Lung-Hao Lee."
            ],
            "title": "Chinese spelling check evaluation at SIGHAN bake-off 2013",
            "venue": "SIGHAN@IJCNLP,",
            "year": 2013
        },
        {
            "authors": [
                "Heng-Da Xu",
                "Zhongli Li",
                "Qingyu Zhou",
                "Chao Li",
                "Zizhen Wang",
                "Yunbo Cao",
                "Heyan Huang",
                "XianLing Mao."
            ],
            "title": "Read, listen, and see: Leveraging multimodal information helps chinese spell checking",
            "venue": "ACL/IJCNLP (Findings), volume",
            "year": 2021
        },
        {
            "authors": [
                "Junjie Yu",
                "Zhenghua Li."
            ],
            "title": "Chinese spelling error detection and correction based on language model, pronunciation, and shape",
            "venue": "CLP 2014, page 220.",
            "year": 2014
        },
        {
            "authors": [
                "Ruiqing Zhang",
                "Chao Pang",
                "Chuanqiang Zhang",
                "Shuohuan Wang",
                "Zhongjun He",
                "Yu Sun",
                "Hua Wu",
                "Haifeng Wang."
            ],
            "title": "Correcting chinese spelling errors with phonetic pre-training",
            "venue": "ACL/IJCNLP (Findings), volume ACL/IJCNLP 2021 of Findings",
            "year": 2021
        },
        {
            "authors": [
                "Shaohua Zhang",
                "Haoran Huang",
                "Jicong Liu",
                "Hang Li."
            ],
            "title": "Spelling error correction with soft-masked BERT",
            "venue": "ACL, pages 882\u2013890. Association for Computational Linguistics.",
            "year": 2020
        },
        {
            "authors": [
                "Zhihong Zhu",
                "Weiyuan Xu",
                "Xuxin Cheng",
                "Tengtao Song",
                "Yuexian Zou."
            ],
            "title": "A dynamic graph interactive framework with label-semantic injection for spoken language understanding",
            "venue": "CoRR, abs/2211.04023.",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Chinese Spell Checking (CSC) aims to detect and correct spelling errors contained in Chinese text (Li et al., 2022b; Ma et al., 2022). CSC is receiving more and more attention because it benefits many applications, such as essay scoring (Dong and Zhang, 2016), OCR (Afli et al., 2016), and ASR (Wang et al., 2018). As a fundamental NLP task, CSC is challenging because the Chinese spelling errors are mainly caused by confusing characters, i.e., phonologically/visually similar characters (Liu et al., 2021). As shown in Table 1, \u201c\u66f0(yue\u0304, say)\u201d and \u201c\u65e5(r\u00ec, day)\u201d are confusing due to their similar strokes.\nTo enable CSC models to handle confusion characters better, the pre-defined confusion set (i.e., the set of phonologically/visually similar characters) has been long regarded as a good external resource.\n\u2217 indicates equal contribution. \u2020 Corresponding author: Hai-Tao Zheng. (E-mail:\nzheng.haitao@sz.tsinghua.edu.cn)\nMany previous works (Liu et al., 2021; Zhang et al., 2020) have aimed to leverage the confusion set to introduce phonological/visual similarities into the CSC models. However, these existing methods simply focus on the character similarity provided by the confusion set, but ignore the context of the characters. In fact, in a sentence with a spelling error, the context of the error position provides more useful information that facilitates the CSC process. For example, in Table 1, if the model pays attention to \u201c\u5e3d\u5b50(hat)\u201d in the context, it will easily associate the wrong character \u201c\u5e26(d\u00e0i, bring)\u201d with the correct character \u201c\u6234(d\u00e0i, wear)\u201d. Therefore, we believe that the contextual similarity of the characters is more important for CSC than the character similarity.\nIn this paper, we aim to enhance CSC models by introducing contextual similarity of Chinese characters. Considering that the CSC task itself is inseparable from human learning, we hope that the model can learn like a human learns to correct spelling errors. We all know that for a student who is just beginning to learn Chinese characters, the teacher always teaches him or her from easy to difficult. Therefore, inspired by the process of humans learning Chinese characters, we also want to guide the model to learn from easy to hard. And this motivation just coincides with curriculum learning.\nThe core idea of curriculum learning is to train models from easy to hard (Soviany et al., 2021).\nar X\niv :2\n20 7.\n09 21\n7v 3\n[ cs\n.C L\n] 2\n8 Fe\nb 20\n23\nAnd the key to curriculum learning is to design a mechanism to measure the difficulty of samples. Benefiting from this mechanism, we naturally use the contextual similarity of characters as the metric for measuring the sample\u2019s difficulty, so as to organize the scattered training samples into ordered samples for model training. Specifically, we train the model in the order from samples with low contextual similarity to samples with high contextual similarity. Hence, the model achieves better performance than only using the traditional character similarity of confusion set. Moreover, our curriculum learning framework is model-agnostic so that it brings stable improvements for most existing CSC models.\nThe contributions of our work are summarized as: (1) We empirically verify that contextual similarity is more valuable than character similarity in the CSC task, which is instructive for future works. (2) We propose a simple yet effective curriculum learning framework that enhances the CSC models to explicitly focus on the contextual similarity between Chinese characters. (3) We achieve new state-of-the-art performance on SIGHAN benchmarks and conduct extensive analyses to demonstrate the effectiveness of our proposed method."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Chinese Spell Checking",
            "text": "In the field of CSC (Li et al., 2022a), many works focus on constructing and employing confusion set\nto guide the models to correct the erroneous characters. SpellGCN (Cheng et al., 2020) employs graph convolutional network and pre-defined confusion set (Wu et al., 2013) to generate candidate characters for the CSC task. PLOME (Liu et al., 2021) and MLM-phonetics (Zhang et al., 2021) optimize the masking mechanism of masked language models via confusion set and achieves previous state-ofthe-art performance. Besides, REALISE (Xu et al., 2021) designs BERT-based fusion network to capture multi-modal information, including phonetic and graphic knowledge.\nTo the best of our knowledge, existing CSC works improve model performance by introducing character similarity provided by confusion set, but has not made the model focus on contextual similarity of Chinese characters. As a matter of fact, the context of the spelling error position is able to provide vital information for CSC task. In this paper, it is the first time that contextual similarity is applied successfully into the CSC task."
        },
        {
            "heading": "2.2 Curriculum Learning",
            "text": "The idea of Curriculum Learning is to train models from easy to hard, which is proposed in (Bengio et al., 2009). With the great success in CV (Cheng et al., 2023; Li et al., 2023), Curriculum Learning has attracted many researchers to apply this strategy to all kinds of NLP (Zhu et al., 2022) tasks, which include Machine Translation (Kocmi and Bojar, 2017; Cheng et al., 2022), Question answering (Liu\net al., 2018), Reading Comprehension (Liang et al., 2019). For CSC, although Self-Supervised Curriculum Learning has been employed in (Gan et al., 2021), it is only integrated into a particular model. In our work, the universality of Curriculum Learning is the first time to be demonstrated for CSC. And our designed CL framework is model-agnostic for most existing CSC models. Besides, different from (Gan et al., 2021), our work focuses more on contextual similarity."
        },
        {
            "heading": "3 Proposed approach",
            "text": ""
        },
        {
            "heading": "3.1 Study Motivation",
            "text": "The core of our work is how to make the CSC models explicitly pay more attention to the context of Chinese characters. Therefore, we propose to use contextual similarity as the metric to measure the difficulty of samples in curriculum learning.\nBased on detailed observation, we get the follow-\ning two obvious facts: (1) A sample is more difficult if it has more wrong characters. (2) A sample is more difficult if the wrong character it contains is more similar to the corresponding correct character. According to these two facts, we design a specific difficulty evaluation strategy and propose the curriculum learning framework for CSC. More specifically, as shown in Figure 1, our curriculum learning framework is divided into two parts: Difficulty Evaluation and Curriculum Arrangement, which will be described in Sections 3.2 and 3.3."
        },
        {
            "heading": "3.2 Difficulty Evaluation",
            "text": "In Difficulty Evaluation, we assign a difficulty score to each training sample in the whole training set S. For each sample, we employ an encoder E(.) (e.g., BERT or other CSC models), to transform the characters in the wrong sequence si and correct sequence ti to the corresponding contextual representations E(si) and E(ti).\nAfter obtaining the contextual representations of the wrong/correct sentence, we use the representation corresponding to the wrong position to calculate the cosine similarity, and then the similarities corresponding to all positions with an error are summed up as the difficulty score of the sample:\ndi = \u2211 j\u2208Wi E(si)j \u00b7 E(ti)j ||E(si)j || \u00b7 ||E(ti)j || , (1)\nwhere di is the difficulty score of i-th sample, Wi are the positions with error."
        },
        {
            "heading": "3.3 Curriculum Arrangement",
            "text": "In this section, we describe an Annealing method to arrange all the training samples S into an ordered curriculum based on the difficulty scores that are introduced in Section 3.2.\nFirstly, we sort all training samples in ascending order of their difficulty scores and split them into k subsets {S1, S2, ..., Sk}. Note that these subsets are non-overlapping for preventing over-fitting and improving the generalization performance. Then we arrange a learning curriculum which contains k + 1 training stages. At the i-th stage (i \u2264 k), we further split each of the k subsets {S1, S2, ..., Sk} into k parts by order of difficulty. For each subset Sj , we obtain {Sj,1, Sj,2, ..., Sj,k} and use the i-th part Sj,i for this i-th stage, thus the final training set Ci = {S1,i, S2,i, ..., Sk,i} is employed for the i-th stage. It is worth mentioning that the training set Ci will be shuffled for maintaining local stochastics within i-th stage.\nFor the former k stages, the model is trained on the Ci for one epoch one after another to lead the model learning from easy to difficult. At the last stage (i.e., the k + 1-th stage ), the model is trained on the whole training set S for fitting the original data distribution."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Datasets",
            "text": "Following previous works (Zhang et al., 2020; Xu et al., 2021), we use the same training data which contains SIGHAN 13/14/15 (Wu et al., 2013; Yu and Li, 2014; Tseng et al., 2015) and a generated pseudo dataset (Wang et al., 2018). Additionally, to ensure fairness, models\u2019 performance is evaluated on the same test data as our baselines, from the test datasets of SIGHAN 13/14/15."
        },
        {
            "heading": "4.2 Baseline Methods",
            "text": "We select strong confusion set-based models as baselines: SpellGCN (Cheng et al., 2020) applies GCNs to learn the character similarity from confusion set. PLOME (Liu et al., 2021) designs pre-training strategy based on the confusion set. MLM-phonetics(Zhang et al., 2021) introduces phonetic similarity into masked language models from confusion set. REALISE (Xu et al., 2021) extracts and mixes semantic, phonetic, and graphic information. In addition, we select three popular CSC models to be combined with our proposed CL method: BERT (Devlin et al., 2019) directly fine-tunes the BERTBASE on the CSC training data. Soft-Masked BERT (Zhang et al., 2020) utilizes the confusion set to generate sufficient training data. MacBERT (Cui et al., 2020) improves the masking strategy of BERT and adds a full connection layer to detect errors. These BERT-based CSC models are all convenient to obtain the contextual representations of Chinese characters."
        },
        {
            "heading": "4.3 Experimental Setup",
            "text": "During the training phase, we follow the hyperparameters of Soft-Masked-Bert (Zhang et al., 2020). For Soft-Masked-BERT , we maintain a learning rate 2e \u2212 5 and fine-tune the parameters with Adam. As for MacBERT (Cui et al., 2020), the learning-rate is set to 5e\u2212 5, the batch size is set to 32. The k is empirically set to in our method. During the testing phase, we evaluate the models in both detection and correction utilizing sentencelevel accuracy, precision, recall, and F1 score."
        },
        {
            "heading": "4.4 Experimental Results",
            "text": "Table 2 shows the results of our CL method compared to baselines. We can see that, by reordering the training data, our method yields consistent gain with a large margin against all baselines.\nParticularly, unlike most models which leverage character similarity, our method achieves better performance by explicitly focusing on contextual similarity. Besides, the significant improvements over three models (i.e., Soft-Masked BERT, BERT, and MacBERT) verify the model-agnostic characteristic of our framework."
        },
        {
            "heading": "4.5 Ablation Study",
            "text": "To explore the contribution of each component in our curriculum learning framework, we conduct ablation studies with the following settings: 1) only\nusing difficulty evaluation to sort training samples for the training process of MacBERT, 2) only using curriculum arrangement to randomly arrange training stages for the training process of MacBERT, and the training samples of each stage are randomly selected. 3) Besides, to verify the advantage of contextual similarity, we also use the confusion set-based character similarity as the difficulty metric in our CL framework.\nFrom Table 3, we observe that both difficulty evaluation and curriculum arrangement bring improvements for MacBERT, which indicates the rationality of these two modules we design. Particularly, the greater improvements that only using difficulty evaluation brings to MacBERT than only using curriculum arrangement and using character similarity reflects the correctness of our motivation that contextual similarity is more valuable than character similarity in the CSC task."
        },
        {
            "heading": "4.6 Parameter Study",
            "text": "The key parameter in our framework is the number of subsets k, so it is essential to study its effects. Figure 2 illustrates the performance change of CL (MacBERT), we find that when the value of k reaches a certain value, the performance of\nthe model does not improve anymore. In fact, this phenomenon is consistent with the process of human learning. Imagine that when the courses are divided too trivially (that is, when the value of k is too large), it is difficult for humans to learn effective knowledge from too many courses. Therefore, it is critical to choose the best k, although there are stable improvements based on MacBERT at all values of k."
        },
        {
            "heading": "4.7 Case Study",
            "text": "In the first example of Table 4, \u201c\u6bcf(me\u030ci)\u201d is the wrong character\uff0c\u201c\u7f8e(me\u030ci)\u201d is the corrected character. The two characters are only acoustically similar. Therefore, the low difficulty score evaluated by our CL(MacBERT) of this example is reasonable. In the second example, the erroneous character \u201c\u9020(z\u00e0o)\u201d is easily to be detected and corrected to \"\u5750(zu\u00f2)\" by using the information of \"\u8d70\u8def(walk)\" as well as \"\u516c\u4ea4(bus)\" in the context. The difficulty score of the latter example is also significantly higher than the first example. This verifies the effectiveness of our designed difficulty scoring function and suggests that the model has learned how to distinguish between highly and slightly similar spelling errors."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this paper, we aim to exploit the contextual similarity of characters to obtain better CSC performance than character similarity contained in traditional confusion set. Additionally, we propose a simple yet effective curriculum learning framework for the CSC task. With the help of such a modelagnostic framework, most existing CSC models significantly perform better. In the future, it would be a very interesting direction to apply the core idea of our work to more scenarios such as Chinese grammatical error correction."
        },
        {
            "heading": "Acknowledgements",
            "text": "This research is supported by the National Natural Science Foundation of China (Grant No.62276154), AMiner.Shenzhen SciBrain Fund, Research Center for Computer Network (Shenzhen) Ministry of Education, Beijing Academy of Artificial Intelligence (BAAI), the Natural Science Foundation of Guangdong Province (Grant No. 2021A1515012640), Basic Research Fund of Shenzhen City (Grant No. JCYJ20210324120012033 and JSGG20210802154402007), and Overseas Cooperation Research Fund of Tsinghua Shenzhen International Graduate School (Grant No. HW2021008)."
        }
    ],
    "title": "Contextual Similarity is More Valuable than Character Similarity: An Empirical Study for Chinese Spell Checking",
    "year": 2023
}