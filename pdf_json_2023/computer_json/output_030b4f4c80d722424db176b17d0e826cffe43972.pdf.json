{
    "abstractText": "Drug discovery relies on predicting drug-target interaction (DTI), which is an important challenging task. The purpose of DTI is to identify the interaction between drug chemical compounds and protein targets. Traditional wet lab experiments are time-consuming and expensive, that\u2019s why in recent years, the use of computational methods based on machine learning has attracted the attention of many researchers. Actually, a dry lab environment focusing more on computational methods of interaction prediction can be helpful in limiting search space for wet lab experiments. In this paper, a novel multi-stage approach for DTI is proposed that called SRX-DTI. In the first stage, combination of various descriptors from protein sequences, and a FP2 fingerprint that is encoded from drug are extracted as feature vectors. A major challenge in this application is the imbalanced data due to the lack of known interactions, in this regard, in the second stage, the One-SVM-US technique is proposed to deal with this problem. Next, the FFS-RF algorithm, a forward feature selection algorithm, coupled with a random forest (RF) classifier is developed to maximize the predictive performance. This feature selection algorithm removes irrelevant features to obtain optimal features. Finally, balanced dataset with optimal features is given to the XGBoost classifier to identify DTIs. The experimental results demonstrate that our proposed approach SRX-DTI achieves higher performance than other existing methods in predicting DTIs. The datasets and source code are available at: https://github.com/Khojasteh-hb/SRXDTI.",
    "authors": [
        {
            "affiliations": [],
            "name": "Hakimeh Khojasteh"
        },
        {
            "affiliations": [],
            "name": "Jamshid PirgaziID"
        },
        {
            "affiliations": [],
            "name": "Ali Ghanbari Sorkhi"
        }
    ],
    "id": "SP:3cb17df09b62aaddf169535c7376a17a79499f62",
    "references": [
        {
            "authors": [
                "J.E. Rood",
                "A. Regev"
            ],
            "title": "The legacy of the human genome project",
            "venue": "Science, 2021",
            "year": 2021
        },
        {
            "authors": [
                "A Farag"
            ],
            "title": "Identification of FDA approved drugs targeting COVID-19 virus by structure-based drug repositioning",
            "year": 2020
        },
        {
            "authors": [
                "Mahmud S.H"
            ],
            "title": "PreDTIs: prediction of drug\u2013target interactions based on multiple feature information using gradient boosting framework with data balancing and feature selection techniques",
            "venue": "Briefings in bioinformatics,",
            "year": 2021
        },
        {
            "authors": [
                "Zhang Y.-F"
            ],
            "title": "SPVec: a Word2vec-inspired feature representation method for drug-target interaction prediction",
            "venue": "Frontiers in chemistry, 2020",
            "year": 2020
        },
        {
            "authors": [
                "M Kanehisa"
            ],
            "title": "From genomics to chemical genomics: new developments in KEGG",
            "venue": "Nucleic acids research,",
            "year": 2006
        },
        {
            "authors": [
                "M Kanehisa"
            ],
            "title": "KEGG for integration and interpretation of large-scale molecular data sets",
            "venue": "Nucleic acids research,",
            "year": 2012
        },
        {
            "authors": [
                "Wishart D.S"
            ],
            "title": "DrugBank 5.0: a major update to the DrugBank database for 2018",
            "venue": "Nucleic acids research,",
            "year": 2018
        },
        {
            "authors": [
                "S Kim"
            ],
            "title": "PubChem 2019 update: improved access to chemical data",
            "venue": "Nucleic acids research,",
            "year": 2019
        },
        {
            "authors": [
                "Davis M.I"
            ],
            "title": "Comprehensive analysis of kinase inhibitor selectivity",
            "venue": "Nature biotechnology,",
            "year": 2011
        },
        {
            "authors": [
                "X. Chen",
                "Z.L. Ji",
                "Y.Z. Chen"
            ],
            "title": "TTD: therapeutic target database",
            "venue": "Nucleic acids research,",
            "year": 2002
        },
        {
            "authors": [
                "F Zhu"
            ],
            "title": "Update of TTD: therapeutic target database",
            "venue": "Nucleic acids research,",
            "year": 2010
        },
        {
            "authors": [
                "D Szklarczyk"
            ],
            "title": "STITCH 5: augmenting protein\u2013chemical interaction networks with tissue and affinity data",
            "venue": "Nucleic acids research,",
            "year": 2016
        },
        {
            "authors": [
                "S Akbar"
            ],
            "title": "iHBP-DeepPSSM: Identifying hormone binding proteins using PsePSSM based evolutionary features and deep learning approach",
            "venue": "Chemometrics and Intelligent Laboratory Systems,",
            "year": 2020
        },
        {
            "authors": [
                "H Jing"
            ],
            "title": "Connecting the dots on vertical transmission of SARS-CoV-2 using protein-protein interaction network analysis\u2013potential roles of placental ACE2 and ENDOU",
            "venue": "Placenta,",
            "year": 2021
        },
        {
            "authors": [
                "Y Liu"
            ],
            "title": "Significance-based essential protein discovery",
            "venue": "IEEE/ACM Transactions on Computational Biology and Bioinformatics,",
            "year": 2020
        },
        {
            "authors": [
                "Q. An",
                "L. Yu"
            ],
            "title": "A heterogeneous network embedding framework for predicting similarity-based drugtarget interactions",
            "venue": "Briefings in bioinformatics,",
            "year": 2021
        },
        {
            "authors": [
                "Sorkhi A.G"
            ],
            "title": "Drug\u2013target interaction prediction using unifying of graph regularized nuclear norm with bilinear factorization",
            "venue": "BMC bioinformatics,",
            "year": 2021
        },
        {
            "authors": [
                "Z Mousavian"
            ],
            "title": "Drug\u2013target interaction prediction from PSSM based evolutionary information",
            "venue": "Journal of pharmacological and toxicological methods,",
            "year": 2015
        },
        {
            "authors": [
                "H Shi"
            ],
            "title": "Predicting drug-target interactions using Lasso with random forest based on evolutionary information and chemical structure. Genomics, 2019",
            "venue": "p. 1839\u20131852",
            "year": 2018
        },
        {
            "authors": [
                "Y Wang"
            ],
            "title": "RoFDT: Identification of Drug&ndash;Target Interactions from Protein Sequence and Drug Molecular Structure Using Rotation Forest",
            "venue": "Biology, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Mahmud S.H"
            ],
            "title": "iDTi-CSsmoteB: identification of drug\u2013target interaction based on drug chemical structure and protein sequence using XGBoost with over-sampling technique SMOTE",
            "venue": "IEEE Access, 2019",
            "year": 2019
        },
        {
            "authors": [
                "Guo L.-X"
            ],
            "title": "A novel circRNA-miRNA association prediction model based on structural deep neural network embedding",
            "venue": "Briefings in Bioinformatics,",
            "year": 2022
        },
        {
            "authors": [
                "K Huang"
            ],
            "title": "DeepPurpose: a deep learning library for drug\u2013target interaction prediction",
            "venue": "Bioinformatics, 2020",
            "year": 2020
        },
        {
            "authors": [
                "X Su"
            ],
            "title": "A deep learning method for repurposing antiviral drugs against new viruses via multi-view nonnegative matrix factorization and its application to SARS-CoV-2",
            "venue": "Briefings in bioinformatics,",
            "year": 2022
        },
        {
            "authors": [
                "Q Yin"
            ],
            "title": "DeepDrug: A general graph-based deep learning framework for drug-drug interactions and drug-target interactions prediction",
            "venue": "biorxiv,",
            "year": 2022
        },
        {
            "authors": [
                "L Jiang"
            ],
            "title": "Identifying drug\u2013target interactions via heterogeneous graph attention networks combined with cross-modal similarities",
            "venue": "Briefings in Bioinformatics,",
            "year": 2022
        },
        {
            "authors": [
                "Y Yamanishi"
            ],
            "title": "Prediction of drug\u2013target interaction networks from the integration of chemical and genomic",
            "venue": "spaces. Bioinformatics,",
            "year": 2008
        },
        {
            "authors": [
                "Wishart D.S"
            ],
            "title": "DrugBank: a comprehensive resource for in silico drug discovery and exploration",
            "venue": "Nucleic acids research,",
            "year": 2006
        },
        {
            "authors": [
                "I Schomburg"
            ],
            "title": "BRENDA, the enzyme database: updates and major new developments",
            "venue": "Nucleic acids research,",
            "year": 2004
        },
        {
            "authors": [
                "S G\u00fcnther"
            ],
            "title": "SuperTarget and Matador: resources for exploring drug-target relationships",
            "venue": "Nucleic acids research,",
            "year": 2007
        },
        {
            "authors": [
                "O\u2019Boyle N.M"
            ],
            "title": "Open Babel: An open chemical toolbox",
            "venue": "Journal of cheminformatics,",
            "year": 2011
        },
        {
            "authors": [
                "B.A. Alpay",
                "M. Gosink",
                "D. Aguiar"
            ],
            "title": "Evaluating molecular fingerprint-based models of drug side effects against a statistical control",
            "venue": "Drug Discovery Today,",
            "year": 2022
        },
        {
            "authors": [
                "M. Bhasin",
                "G.P. Raghava"
            ],
            "title": "Classification of nuclear receptors based on amino acid composition and dipeptide composition",
            "venue": "Journal of Biological Chemistry,",
            "year": 2004
        },
        {
            "authors": [
                "V. Saravanan",
                "N. Gautham"
            ],
            "title": "Harnessing computational biology for exact linear B-cell epitope prediction: a novel amino acid composition-based feature descriptor",
            "venue": "Omics: a journal of integrative biology,",
            "year": 2015
        },
        {
            "authors": [
                "Lee T.-Y"
            ],
            "title": "Exploiting maximal dependence decomposition to identify conserved motifs from a group of aligned signal sequences",
            "venue": "PMID:",
            "year": 2011
        },
        {
            "authors": [
                "Chou K.-C"
            ],
            "title": "Using amphiphilic pseudo amino acid composition to predict enzyme subfamily",
            "venue": "classes. Bioinformatics,",
            "year": 2004
        },
        {
            "authors": [
                "Baig T.I"
            ],
            "title": "Ilipo-pseaac: identification of lipoylation sites using statistical moments and general pseaac",
            "venue": "Computers, Materials and Continua,",
            "year": 2022
        },
        {
            "authors": [
                "X. Cheng",
                "X. Xiao",
                "K.-C. Chou"
            ],
            "title": "pLoc-mHum: predict subcellular localization of multi-location human proteins via general PseAAC to winnow out the crucial GO information",
            "venue": "Bioinformatics, 2018",
            "year": 2018
        },
        {
            "authors": [
                "Shen H.-B",
                "Chou K.-C"
            ],
            "title": "Nuc-PLoc: a new web-server for predicting protein subnuclear localization by fusing PseAA composition and PsePSSM",
            "venue": "Protein Engineering, Design & Selection,",
            "year": 2007
        },
        {
            "authors": [
                "B Yu"
            ],
            "title": "Accurate prediction of subcellular location of apoptosis proteins combining Chou\u2019s PseAAC and PsePSSM based on wavelet denoising. Oncotarget, 2017",
            "venue": "PLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August",
            "year": 2023
        },
        {
            "authors": [
                "D.T. Jones"
            ],
            "title": "Protein secondary structure prediction based on position-specific scoring matrices",
            "venue": "Journal of molecular biology,",
            "year": 1999
        },
        {
            "authors": [
                "Altschul S.F"
            ],
            "title": "Gapped BLAST and PSI-BLAST: a new generation of protein database search programs",
            "venue": "Nucleic acids research,",
            "year": 1997
        },
        {
            "authors": [
                "K.C. Chou"
            ],
            "title": "Prediction of protein cellular attributes using pseudo-amino acid composition",
            "venue": "Proteins: Structure, Function, and Bioinformatics,",
            "year": 2001
        },
        {
            "authors": [
                "Z Chen"
            ],
            "title": "iFeature: a python package and web server for features extraction and selection from protein and peptide sequences. Bioinformatics, 2018",
            "venue": "PMID:",
            "year": 2018
        },
        {
            "authors": [
                "M.A. Arefeen",
                "S.T. Nimi",
                "M.S. Rahman"
            ],
            "title": "Neural network-based undersampling techniques",
            "venue": "IEEE Transactions on Systems, Man, and Cybernetics: Systems,",
            "year": 2020
        },
        {
            "authors": [
                "J Li"
            ],
            "title": "Rare event prediction using similarity majority under-sampling technique",
            "venue": "in International Conference on Soft Computing in Data Science",
            "year": 2017
        },
        {
            "authors": [
                "Mahmud S.H"
            ],
            "title": "Prediction of drug-target interaction based on protein features using undersampling and feature selection techniques with boosting",
            "venue": "Analytical biochemistry,",
            "year": 2020
        },
        {
            "authors": [
                "Yen S.-J",
                "Lee Y.-S"
            ],
            "title": "Cluster-based under-sampling approaches for imbalanced data distributions",
            "venue": "Expert Systems with Applications,",
            "year": 2009
        },
        {
            "authors": [
                "B Sch\u00f6lkopf"
            ],
            "title": "Estimating the support of a high-dimensional distribution",
            "venue": "Neural computation,",
            "year": 2001
        },
        {
            "authors": [
                "Ferri F.J"
            ],
            "title": "Comparative study of techniques for large-scale feature selection, in Machine Intelligence and Pattern Recognition",
            "year": 1994
        },
        {
            "authors": [
                "T.K. Ho"
            ],
            "title": "The random subspace method for constructing decision forests",
            "venue": "IEEE transactions on pattern analysis and machine intelligence,",
            "year": 1998
        },
        {
            "authors": [
                "Meng F.-R"
            ],
            "title": "Prediction of drug\u2013target interaction networks from the integration of protein sequences and drug chemical structures. Molecules, 2017",
            "venue": "PLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August",
            "year": 2023
        }
    ],
    "sections": [
        {
            "text": "Drug discovery relies on predicting drug-target interaction (DTI), which is an important chal-\nlenging task. The purpose of DTI is to identify the interaction between drug chemical com-\npounds and protein targets. Traditional wet lab experiments are time-consuming and\nexpensive, that\u2019s why in recent years, the use of computational methods based on machine\nlearning has attracted the attention of many researchers. Actually, a dry lab environment\nfocusing more on computational methods of interaction prediction can be helpful in limiting\nsearch space for wet lab experiments. In this paper, a novel multi-stage approach for DTI is\nproposed that called SRX-DTI. In the first stage, combination of various descriptors from\nprotein sequences, and a FP2 fingerprint that is encoded from drug are extracted as feature\nvectors. A major challenge in this application is the imbalanced data due to the lack of\nknown interactions, in this regard, in the second stage, the One-SVM-US technique is pro-\nposed to deal with this problem. Next, the FFS-RF algorithm, a forward feature selection\nalgorithm, coupled with a random forest (RF) classifier is developed to maximize the predic-\ntive performance. This feature selection algorithm removes irrelevant features to obtain opti-\nmal features. Finally, balanced dataset with optimal features is given to the XGBoost\nclassifier to identify DTIs. The experimental results demonstrate that our proposed\napproach SRX-DTI achieves higher performance than other existing methods in predicting\nDTIs. The datasets and source code are available at: https://github.com/Khojasteh-hb/SRX-"
        },
        {
            "heading": "DTI.",
            "text": ""
        },
        {
            "heading": "1. Introduction",
            "text": "The main phase in the drug discovery process is to identify interactions between drugs and targets (or proteins), which can be performed by in vitro experiments. Identifying drug-target interaction plays a vital role in drug development that aims to identify new drug compounds for known targets and find new targets for current drugs [1,2]. The expansion of the human\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 1 / 25\nOPEN ACCESS\nCitation: Khojasteh H, Pirgazi J, Ghanbari Sorkhi A (2023) Improving prediction of drug-target interactions based on fusing multiple features with data balancing and feature selection techniques. PLoS ONE 18(8): e0288173. https://doi.org/ 10.1371/journal.pone.0288173\nEditor: Prabina Kumar Meher, ICAR Indian Agricultural Statistics Research Institute, INDIA\nReceived: February 8, 2023\nAccepted: June 21, 2023\nPublished: August 3, 2023\nPeer Review History: PLOS recognizes the benefits of transparency in the peer review process; therefore, we enable the publication of all of the content of peer review and author responses alongside final, published articles. The editorial history of this article is available here: https://doi.org/10.1371/journal.pone.0288173\nCopyright: \u00a9 2023 Khojasteh et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\nData Availability Statement: The source code of the method along with datasets is freely available at https://github.com/Khojasteh-hb/SRX-DTI.\ngenome project has provided a better diagnosis of disease, early detection of certain diseases, and identifying drug-target interactions (DTIs) [3]. Although significant efforts have been done in previous years, only a limited number of drug candidates have been permitted to reach the market by the Food and Drug Administration (FDA) whereas the maximum number of drug candidates have been rejected during clinical verifications, due to side effects or low efficacy [4]. Moreover, the cost of a new chemistry-based drug is often 2.6 billion dollars, and it takes typically 15 years to finish the drug development and approval procedure. This issue has been changing into a bottleneck to identifying the targets of any candidate drug molecules [2,5]. The experiment-based methods involve high cost, time-consuming, and small-scale limitations that motivate researchers to constantly develop computational methods for the exploitation of new drugs [2,6,7]. These computational methods offer a more efficient and costeffective approach to drug discovery, allowing researchers to explore a larger range of potential drug candidates and predict their efficacy before investing significant resources into experimental testing. On the other side, the availability of online databases in this area, such as KEGG [8,9], DrugBank [10], PubChem [11], Davis [12], TTD [13,14], and STITCH [15] have been influencing Machine Learning (ML) researchers to develop high throughput computational methods.\nDrug discovery involves identifying molecules that can effectively target and modulate the\nfunction of disease-related proteins. Besides developing computational methods for predicting drug-target interactions (DTIs), studying protein-protein interactions (PPIs) has also become a top priority for drug discovery, especially due to the SARS-CoV-2 pandemic [16\u201319]. Proteins are responsible for various essential processes in vivo via interactions with other molecules. Dysfunctional proteins are often responsible for diseases, making them crucial targets for the drug discovery process [20,21]. Abnormal PPIs can support the development of lifethreatening diseases like cancer, further emphasizing the importance of identifying critical proteins and their interactions. Therefore, developing computational methods for identifying critical proteins in PPIs has become an important branch of drug discovery and treatment development [21,22]. In summary, understanding both DTIs and PPIs is critical for successful drug discovery. While this paper focuses on DTI prediction, it is important to consider PPI analysis as well in order to identify potential drug targets and improve the efficacy of drug development efforts.\nThe prior methods in DTI prediction can be mainly categorized into similarity-based meth-\nods and feature-based methods. In similarity-based methods, similar drugs or proteins are considered to find similar interaction patterns. These methods use many different similarity measures based on drug chemical similarity and target sequence similarity to identify drug-target interaction [23\u201325]. Feature-based methods consider drug\u2013target interaction prediction as a binary classification problem and different classification algorithms such as Support Vector Machine (SVM) [26], random forest [27], rotation forest [28,29], XGBoost [30], and deep learning [31\u201335] have been employed to identify new interactions.\nVarious machine learning (ML) methods have been applied for drug-target prediction.\nMousavian et al. utilized a support vector machine with features extracted from the Position Specific Scoring Matrix (PSSM) of proteins and molecular substructure fingerprint of drugs [26]. Shi et al. presented the LRF-DTIs method based on random forest, using pseudo-position specific scoring matrix (PsePSSM) and FP2 molecular fingerprint to extract features from proteins and drugs, and employing Lasso dimensionality reduction and Synthetic Minority Oversampling Technique (SMOTE) to handle unbalanced data [27]. Wang et al. proposed two methods based on Rotation Forest: RFDT, which used a PSSM descriptor and drug fingerprint as feature vectors [29], and RoFDT, which combined feature-weighted Rotation Forest (FwRF) with protein sequence encoded as PSSM, and drug structure fingerprints [28]. These\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 2 / 25\nFunding: The author(s) received no specific funding for this work.\nCompeting interests: The authors have declared that no competing interests exist.\nmethods have shown promising results in predicting DTIs. Moreover, Mahmud et al. [30] proposed a computational model, called iDTi-CSsmoteB for the identification of DTIs. They utilized PSSM, amphiphilic pseudo amino acid composition (AM-PseAAC), and dipeptide PseAAC descriptors to present protein and molecular substructure fingerprint (MSF) to present drug molecule structure. Then, the oversampling SMOTE technique was applied to handle the imbalance of datasets, and the XGBoost algorithm as a classifier to predict DTIs.\nThe increase in the volume and diversity of data has led to the development of various deep\nlearning platforms and libraries, such as DeepPurpose [32] and DeepDrug [35]. DeepPurpose [32] takes the SMILES format of the drug and amino acid sequence of the protein as input and transforms it into a specific format using a specific function. This format is then converted into a vector representation to be used in subsequent steps. This library provides eight encoders using different modalities of compounds, as well as utility functions to load pre-trained models and predict new drugs and targets. Yin et al. [35] proposed another deep learning framework called DeepDrug. Furthermore, variants of graph neural networks such as graph convolutional networks (GCNs) [35], graph attention networks (GATs) [36,37], and gated graph neural networks (GGNNs) [31,33,34] have been developed for DTI prediction.\nWe introduce SRX-DTI, a novel ML-based method for improving drug-target interaction\nprediction. First, we generate various descriptors for protein sequences, including Amino Acid Composition (AAC), Dipeptide Composition (DPC), Grouped Amino Acid Composition (GAAC), Dipeptide Deviation from Expected Mean (DDE), Pseudo Amino Acid Composition (PseAAC), Pseudo-Position-Specific Scoring Matrix (PsePSSM), Composition of K-spaced Amino Acid Group Pairs (CKSAAGP), Grouped Dipeptide Composition (GDPC), and Grouped Tripeptide Composition (GTPC). The drug is encoded as FP2 molecular fingerprint. Second, we use the technique namely Under Sampling by One-class Support Vector Machine (One-SVM-US) to balance the data, and the positive and negative samples are constructed using drug-target interaction information on the extracted features. Then, we perform the FFS-RF algorithm to select the optimal subset of features. Finally, after comparing various ML classifiers, we choose the XGBoost classifier to predict DTIs using 5-Fold cross-validation (CV). We evaluate the performance of our method using several metrics, including AUROC, AUPR, ACC, SEN, SPE, and F1-score. Our method achieves high AUROC values of 0.9920, 0.9880, 0.9788, and 0.9329 for EN, GPCR, IC, and NR, respectively. These results demonstrate that SRX-DTI outperforms existing methods for DTI prediction.\nThe rest of the paper is organized as follows: Materials and methods section describes the\ndetail of the gold standard datasets, feature extraction, data balancing, and feature selection, we utilized in this paper. In the Results and discussion section, performance evaluation and experimental results are provided. Finally, the Conclusions section summarizes the conclusions."
        },
        {
            "heading": "2. Materials and methods",
            "text": "In this study, we propose a novel method of drug-target interaction prediction, which is called SRX-DTI. In the first step, drug chemical structures (SMILE format) and protein sequences (FASTA format) are collected from DrugBank and KEGG databases using their specific access IDs. In the next step, different feature extraction methods are applied to drug compounds and protein sequences to create a variety of features. Drug-target pair vectors are made based on known interactions and extracted features. Afterward, a balancing technique is utilized on DTI vectors to deal with imbalanced datasets, and drug\u2013target features are selected through the FFS-RF to boost prediction performance. Finally, the XGBoost classifier is used on the balanced datasets with optimal features to predict DTIs. A schematic diagram of our proposed SRX-DTI model is shown in Fig 1.\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 3 / 25"
        },
        {
            "heading": "2.1 Drug\u2013Target datasets",
            "text": "In this research, four golden standard datasets, including enzymes (EN), G-protein-coupled receptors (GPCR), ion channel (IC), and nuclear receptors (NR) released by Yamanishi et al. [38] are explored as benchmark datasets to evaluate the performance of the proposed SRX-DTI method in DTI prediction. All these datasets are freely available from http://web.kuicr.kyotou.ac.jp/supp/yoshi/drugtarget/. Yamanishi et al. [38] extracted information about drug-target interactions from DrugBank [39], KEGG [8,9], BRENDA [40], and SuperTarget [41]. The numbers of known interactions including enzymes, ion channels, GPCRs, and nuclear receptors are 2926, 1476, 635, and 90 respectively. The SRX-DTI model is also evaluated on the Davis Kinase binding affinity dataset [12]. The original Davis dataset represents 30,056 affinity bindings interactions between 442 proteins and 68 drug molecules. Here, we filter the dataset by removing all interactions with affinity < 7, resulting in the dataset used in this research. Finally, 2502 interactions are considered between proteins and drug molecules in the Davis dataset. A brief summary of these datasets is given in Table 1."
        },
        {
            "heading": "3. Feature extraction methods",
            "text": "In order to better identify drug-protein interactions, it seems advantageous to extract different features from drugs and targets. This allows us to have more complete information about the\nhttps://doi.org/10.1371/journal.pone.0288173.g001\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 4 / 25\nknown interactions and increase the detection rate. A brief summary of the ten groups of features is given in Table 2. Notice that there are two types of features. Drug related features and target related features in nine groups A, B, C, D, E, F, G, H, and I. In the following, these features are described, respectively. Whereas data diversity in the predictive models is very important, various subsets of these groups have been examined to select appropriate subsets. Based on drug and target descriptors, we constructed four subsets of features (AB, CD, EF, and GHI), which are given in Table 3. Also, notice that the drug features are coupled with singular target groups and these subsets. These four subsets have been selected to preserve certain properties of whole feature groups and at the same time, keep diversity in them."
        },
        {
            "heading": "3.1 Drug features",
            "text": "For drug compounds, different types of descriptors can be defined based on various types of drug properties such as FP2, FP3, FP4, and MACCS [42\u201344]. Some studies showed that these descriptors are molecular structure fingerprints that effectively represent the drug [27,45,46]. In this study, the FP2 format fingerprint is used to present drug compounds. This molecular fingerprint of the drug was extracted through these steps:\nStep 1: For each drug, molecular structure as mol format is downloaded from the KEGG data-\nbase (https://www.kegg.jp/kegg/drug/) by using its drug ID.\nStep 2: The OpenBabel Software (available from http://openbabel.org/) is downloaded and\ninstalled.\nStep 3: The drug molecules with mol file format are converted into the FP2 format molecular\nfingerprint using the OpenBabel software. The FP2 format molecular fingerprint is a"
        },
        {
            "heading": "Datasets Drugs Targets Interactions",
            "text": "https://doi.org/10.1371/journal.pone.0288173.t001"
        },
        {
            "heading": "Descriptor Number of Features Feature Type Feature Group",
            "text": "https://doi.org/10.1371/journal.pone.0288173.t002\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 5 / 25\nhexadecimal digit sequence of length 256 that is converted to a drug molecule 256-dimensional vector as a decimal digit sequence between 0 and 15."
        },
        {
            "heading": "3.2 Target features",
            "text": "A) Amino acid composition (AAC): The amino acid composition [47] is a vector of 20 dimensions, which calculates the frequencies of all 20 natural amino acids (i.e. \u201cACDEFGHIKLMNPQRSTVWY\u201d) as:\nft \u00bc N t\u00f0 \u00de\nN ; t 2 A;C;D; . . . ;Yf g \u00f01\u00de\nwhere N(t) is the number of amino acid type t, while N is the length of a protein sequence. B) Dipeptide composition (DPC): The Dipeptide Composition [48] gives 400 descriptors for protein sequence. It is calculated as:\nD r; s\u00f0 \u00de \u00bc Nrs\nN 1 ; t 2 A;C;D; . . . ;Yf g \u00f02\u00de\nwhere Nrs is the number of dipeptides represented by amino acid types r and s and N denotes the length of protein.\nC) Grouped Amino Acid Composition (GAAC): In the GAAC encoding [49], the 20\namino acid types are considered five classes according to their physicochemical properties. GAAC descriptor is the frequency of each amino acid group, which is calculated as:\nf g\u00f0 \u00de \u00bc N g\u00f0 \u00de\nN ; t 2 g1; g2; g3; g4; g5f g \u00f03\u00de\nN gt\u00f0 \u00de \u00bc X N t\u00f0 \u00de; t 2 g \u00f04\u00de\nwhere N(g) is the number of amino acids in group g, N(t) is the number of amino acid type t, and N is the length of protein sequence.\nD) Dipeptide Deviation from Expected mean (DDE): The Dipeptide Deviation from\nExpected mean [48] is a feature vector, which is constructed by computing three parameters, i.e. dipeptide composition (Dc), theoretical mean (Tm), and theoretical variance (Tv). These three parameters and the DDE are defined as follows. Dc(r, s), the dipeptide composition measure for the dipeptide \u2018rs\u2019, is given as:\nDc r; s\u00f0 \u00de \u00bc Nrs\nN 1 ; r; s 2 A;C;D; . . . ;Yf g \u00f05\u00de"
        },
        {
            "heading": "Feature Combination Number of Features",
            "text": "https://doi.org/10.1371/journal.pone.0288173.t003\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 6 / 25\nwhere Nrs is the number of dipeptides represented by amino acid types r and s and N is the length of protein. Tm(r, s), the theoretical mean, is given by:\nTm r; s\u00f0 \u00de \u00bc Cr CN \ufffd Cs CN\n\u00f06\u00de\nwhere Cr is the number of codons, coding for the first amino acid, and Cs is the number of codons, coding for the second amino acid in the given dipeptide \u2018rs\u2019 and CN is the total number of possible codons. Tv(r, s), the theoretical variance of the dipeptide \u2018rs\u2019, is given by:\nTv r; s\u00f0 \u00de \u00bc Tm r; s\u00f0 \u00de 1 Tm r; s\u00f0 \u00de\u00f0 \u00de\nN 1 \u00f07\u00de\nFinally, DDE(r, s) is calculated as:\nDDE r; s\u00f0 \u00de \u00bc Dc r; s\u00f0 \u00de Tm r; s\u00f0 \u00deffiffiffiffiffiffiffiffiffiffiffiffiffiffi\nTv r; s\u00f0 \u00de p \u00f08\u00de\nE) Pseudo Amino Acid composition (PseAAC): To avoid completely losing the sequenceorder information, the concept of PseAAC (pseudo amino acid composition) was proposed by Chou [50]; The idea of PseAAC has been widely used in bioinformatics including proteomics [51], system biology [52], such as predicting protein structural class [53], predicting protein subcellular localization [54], predicting DNA-binding proteins [55] and many other applications. In contrast with AAC which includes 20 components with each reflecting the occurrence frequency for One of the 20 native amino acids in a protein, the PseAAC contains a set of greater than 20 discrete factors, where the first 20 represent the components of its conventional amino acid composition while the additional factors are a series of rank-different correlation factors along a protein chain. According to the concept of PseAAC [50], any protein sequence formulated as a PseAAC vector given by:\nx \u00bc x1; x2; . . . ; x19; x20; x20\u00fe1; . . . ; x20\u00fel \ufffd \ufffdT ; \u00f0l < L\u00de \u00f09\u00de\nwhere L is the length of protein sequence, and \u03bb is the sequence-related factor that choosing a different integer for, will lead to a dimension-different PseAAC. Each of the components can be defined as follows:\nxu \u00bc\nfi X20\ni\u00bc1 fi \u00fe w\nXl\nk\u00bc1 tk\n; 1 \ufffd u \ufffd 20\nwtu 20 X20\ni\u00bc1 fi \u00fe w\nXl\nk\u00bc1 tk\n; 20\u00fe 1 \ufffd u \ufffd 20\u00fe l \u00f010\u00de\n8 > > <\n> > :\nwhere w is the weight factor, and fi indicates the frequency at i \u2212 th AA in protein sequence. The \u03c4k, the k-th tier correlation factor reflects the sequence order correlation between all the kth most contiguous residues as formulated by:\ntk \u00bc 1\nL K\nXL K\ni\u00bc1\nJi;i\u00fek;K < L \u00f011\u00de\nwith\nJi;i\u00fek \u00bc 1\nG\nXG\nq 1\nFq Ri\u00fek \ufffd Fq Ri\u00f0 \u00de h i2\n\u00f012\u00de\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 7 / 25\nwhere Fq(Ri) is the q-th function of amino acid Ri, and \u0393 is the total number of the functions considered. In this research, the protein functions which are considered, includes hydrophobicity value, hydrophilicity value, and side chain mass of amino acid. Therefore, the total number of functions \u0393 is 3. In this study, \u03bb is set to 1 and W is set to 0.05. The output characteristic dimensions of each target protein are 28 for the PseAAC descriptor.\nF) Pseudo position specific scoring matrix (PsePSSM): To represent characteristics of the\namino acid (AA) sequence for protein sequences, the pseudo-position specific scoring matrix (PsePSSM) features introduced by Shen et al. [56] are used. The pseudo-position specific scoring matrix (PsePSSM) features encode the protein sequence\u2019s evolution and information which have been broadly used in bioinformatics research [16,56,57].\nFor each target sequence P with L amino acid residues, PSSM is used as its descriptor pro-\nposed by Jones et al. [58]. The position-specific scoring matrix (PSSM) with a dimension of L\u00d720 can be defined as:\nPPSSM \u00bc\nM1!1 M1!2 . . . M1!20 M2!1 M2!2 . . . M2!20\n.. . .. . .. . .. .\nMi!1 Mi!2 . . . Mi!20 .. . .. . .. . .. . ML!1 ML!2 . . . ML!20\n2\n6 6 6 6 6 6 6 6 4\n3\n7 7 7 7 7 7 7 7 5\n\u00f013\u00de\nwhere Mi,j indicates the score of the amino acid residue in the ith position of the protein sequence being mutated to amino acid type j during the evolution process. Here, for simplifying the formulation, it is used the numerical codes 1, 2,. . ., 20 to represent the 20 native amino acid types according to the alphabetical order of their single character codes. It can be searched using the PSI-BLAST [59] in the Swiss-Prot database. A positive score shows that the corresponding residue is mutated more frequently than expected, and a negative score is just the contrary.\nIn this work, the parameters of PSI-BLAST are set as the threshold of E-value equals 0.001, the maximum number of iterations for multiple searches equals 3, and the rest of the parameters by default. Each element in the original PSSM matrix was normalized to the interval (0, 1) using Eq (14):\nMi!j \u00bc 1\n1\u00fe exp Mi!j \ufffd \ufffd \u00f014\u00de\nHowever, due to different lengths in target sequences, making the PSSM descriptor as a uni-\nform representation can be helpful, one possible representation of the protein sample P is:\nPPSSM \u00bc M1;M2; . . . ;M20 \ufffd \ufffd\n\u00f015\u00de\nwhere T is the transpose operator, and\nMj \u00bc 1\nL\nXL\ni\u00bc1\nMi!j j \u00bc 1; 2; . . . ; 20\u00f0 \u00de \u00f016\u00de\nwhere Mi!j is the average score of the amino acid residues in the protein P changed to the jth amino acid residue after normalization, Mj represents the average score of the amino acid residue in protein P being mutated amino acid type j during the process of evolution. However, if\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 8 / 25\nPPSSM of Eq (13) represents the protein P, all the sequence-order information would be lost. To avoid complete loss of the sequence-order information, the concept of the pseudo amino acid composition introduced by Chou [60], i.e. instead of Eq (11), we use position-specific scoring matrix (PsePSSM) to represent the protein P:\nPlpsePSSM \u00bc M1;M2; . . . ; M20;G 1 1 ;G1 2 ; . . . ; G1 20 ;Gl 1 ;Gl 2 ; . . . ; Gl 20\n\ufffd \ufffd T \u00f017\u00de\nwhere\nGlj \u00bc 1\nL l\nXL l\ni\u00bc1\n\ufffd Mi!j M i\u00fel\u00f0 \u00de!j \ufffd2\nj \u00bc 1; 2; . . . ; 20; 0 \ufffd l \ufffd L\u00f0 \u00de \u00f018\u00de\nwhere Glj represents the correlation factor of the j - th amino acid and \u03bb is the continuous distance along the protein sequence. This means that G1j is the relevant factor coupled along the most continuous PSSM score on the protein chain of amino acid type j, G2j is the second closest PSSM score by coupling, and so on. Therefore, a protein sequence can be defined as Eq (15) using PsePSSM and produces a 20 + 20 \u00d7 \u03bb-dimensional feature vector. In this study, \u03bb is set to 10. The output characteristic dimension of each target protein is 220 for the PsePSSM descriptor.\nG) Composition of k-spaced amino acid group pairs (CKSAAGP): The Composition of\nk-Spaced Amino Acid Group Pairs (CKSAAGP) [61] defines the frequency of amino acid group pairs separated by any k residues (the default maximum value of k is set as 5). If k = 0, the 0-spaced group pairs are represented as:\nNg1g1 Ntotal ; Ng1g2 Ntotal ; Ng1g3 Ntotal ; . . . ; Ng5g5 Ntotal\n\ufffd \ufffd\n25\n\u00f019\u00de\nwhere the value of each descriptor indicates the composition of the corresponding residue group pair in a protein sequence. For a protein of length P and k = 0, 1, 2, 3, 4 and 5, the values of Ntotal are P\u20141, P\u20142, P\u20143, P\u20144, P\u20145 and P\u20146 respectively.\nH) Grouped dipeptide composition (GDPC): The Grouped Di-Peptide Composition\nencoding [61] is a vector of 25 dimensions, which is another variation of the DPC descriptor. It is defined as:\nf r; s\u00f0 \u00de \u00bc Nrs\nN 1 ; r; s 2 g1; g2; g3; g4; g5f g \u00f020\u00de\nwhere Nrs is the number of dipeptides represented by amino acid types r and s and N denotes the length of a protein.\nI) Grouped tripeptide composition (GTPC): The Grouped Tri-Peptide Composition\nencoding [61] is also a variation of the TPC descriptor, which generates a vector of 125 dimensions, defined as:\nf r; s\u00f0 \u00de \u00bc Nrst\nN 2 ; r; s; t 2 g1; g2; g3; g4; g5f g \u00f021\u00de\nwhere Nrst is the number of tripeptides represented by amino acid types r, s and t. N denotes the length of a protein. Algorithm 1. UnderSampling by One-class SVM (One-SVM-US). 1: nminority number of minority class samples 2: nmajority number of majority class samples 3: df [1. . .. nmajority] Majority class Samples 4: df [1. . .. nminority] Minority class Samples\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 9 / 25\n5: Model OneClassSVM(df [1. . . .nmajority]) // One-class SVM with RBF kernel and 6: // \u03b3 = 1/nmajority 7: scores Model.makeDecision(df [1. . . .nmajority]) 8: Q maxscores decisionFunction(scores) 9: outlierScores Q-scores 10: sortedScores sort(outlierScores) 11: SelectedIndices = sortedScores [1. . . .nminority] 12: X1 = {} 13: for each index 2 selectedIndices do 14: X1 = X1 [ df [index] 15: endfor 16: FinalData = X1 [ df [1. . . .nminority]"
        },
        {
            "heading": "4. Data balancing technique",
            "text": "The experiment datasets that we used in this study were highly imbalanced. Imbalanced datasets can present a challenge for many machine learning algorithms, as they may prioritize the majority class and ignore the minority class, leading to poor performance on the minority class. Different techniques have been utilized to balance the imbalanced dataset, such as random undersampling [26,62,63], cluster undersampling [64,65], and SMOTE technique [27,30]. To address the issue of imbalanced data in our study, we developed a new undersampling algorithm called One-SVM-US, which uses One-class Support Vector Machine (SVM) to deal with imbalanced data. The steps of the One-SVM-US algorithm were implemented as Algorithm 1. In the first step, the known DTIs are considered positive samples. For enzymes, ion channels, GPCRs, nuclear receptors, and the Davis dataset, the number of positives is 2926, 1476, 635, 90, and 2502, respectively. In the next step, the algorithm considers all of the possible interactions in five datasets as negative samples except the ones that have been known as positive. By performing the One-SVM-US algorithm, it would result in a balanced dataset with equal numbers of positive and negative samples.\nA One-Class Support Vector Machine (One-class SVM) [66], is a semi-supervised global\nanomaly detector. This algorithm needs a training set that contains only one class. The OneSVM-US technique based on One-class SVM considers all possible combinations of drug and target by discarding those that are positive samples. This algorithm uses a hypersphere to encompass all of the instances instead of using a hyperplane to separate two classes of samples. We apply the RBF kernel for SVM. The setting for the parameter \u03b3 was investigated, which was the simple heuristic \u03b3 = 1/no. of data points. To compute the outlier score, first, the maximum value of the decision function is obtained by:\nQ \u00bc max x decision function x0\u00f0 \u00de \u00f022\u00de\nwhere x refers to the vector of scores. Then, we obtained the outlier score as follows:\noutlier scores \u00bc Q decision function x\u00f0 \u00de \u00f023\u00de\nThen, the outlier scores are sorted in ascending and the nminority samples are selected from the sorted list. The final data is constructed from the combination of the minority class from the original experimental dataset and the majority class chosen by the proposed method. Even though, we would like to mention that Algorithm 1 performs effectively to make balanced datasets.\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 10 / 25"
        },
        {
            "heading": "5. Feature selection technique",
            "text": "Considering that reducing the number of input features can lead to both reducing the computational cost of modeling and, in some cases, improving the performance of the model. We develop a feature selection algorithm with RF, called FFS-RF. This algorithm was developed and implemented based on the forward feature selection (FFS) technique [67] that coupled with RF to obtain optimal features in DTI. The RF approach [68] is an ensemble method that combines a large number of individual binary decision trees. The performance of the RF model in feature selection was evaluated by a 5-fold CV to construct an effective prediction framework. Forward feature selection is an iterative process, which begins with an empty set of features. After each iteration, it keeps adding on a feature and evaluates the performance to check whether it is improving the performance or not. The FFS-RF technique continues until the addition of a new feature does not improve the performance of the model, as outlined in Algorithm 2 step by step. Algorithm 2. Forward Feature Selection algorithm with RF (FFS-RF). 1: FS0 = ; 2: F0 = {f1, f2, . . ., fn} 3: i = 0 4: opt = 0 5: iter = 0 6: while (i < n) 7: k = size (F(i)) 8: max = 0 9: feature = 0 10: for j from 1 to k 11: score = eval (F(i)j) 12: if (score > max) 13: max = score 14: feature = F(i)j 15: endif 16: endfor 17: if (max > opt) 18: opt = max 19: iter = i 20: endif 21: FS(i+1) = F(i) + feature 22: F(i+1) = F(i) \u2212 feature 23: i++ 24: endwhile"
        },
        {
            "heading": "6. Results and discussion",
            "text": "In this section, we explain the experimental results of our proposed method in DTI prediction. We implemented all the phases, i.e., features extraction, data balancing, and classifiers of the proposed model in Python language (Python 3.10 version) using the Scikit-learn library. Some of the target descriptors were calculated by the iFeature package [61] and the rest of them were implemented in Python language. OpenBabel Software was used to extract fingerprint descriptors from drugs. All of the implantations were performed on a computer with a processor 2.50 GHz Intel Xeon Gold 5\u20132670 CPU and 64 GB RAM."
        },
        {
            "heading": "6.1 Performance evaluation",
            "text": "Most of the methods in DTI prediction [5,6,26,30] have utilized 5-fold cross validation (CV) to assess the power of the model to generalize. We also use the 5-fold CV to estimate the skill of\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 11 / 25\nthe SRX-DTI model on new data and make a fair comparison with the other state-of-the-art methods. The drug\u2013target datasets were split into 5 subsets where each subset was used as a testing set. In the first iteration, the first subset is used to test the model and the rest are used to train the model. In the second iteration, 2nd subset is used as the testing set while the rest serves as the training set. This process is repeated until each fold of the 5 folds is used as the testing set. Then, the performance is reported as the average of the five validation results for drug-target datasets.\nIn this study, we perform three types of analyses. First, the importance of feature extraction\nis discussed. Secondly, we investigate the impact of our balancing technique (One-SVM-US) versus the random undersampling technique on CV results. Finally, the effectiveness of the feature selection method is analyzed.\nWe used the following evaluation metrics to assess the performance of the proposed model:\naccuracy (ACC), sensitivity (SEN), specificity (SPE), and F1 Score.\nACC \u00bc TP \u00fe TN\nTP \u00fe FP \u00fe TN \u00fe FN \u00f024\u00de\nSEN \u00bc TP\nTP\u00fe FN \u00f025\u00de\nSPE \u00bc TN\nTN \u00fe FP \u00f026\u00de\nF1 \u00bc 2TP\n2TP\u00fe FP\u00fe FN \u00f027\u00de\nwhere based on four metrics, namely true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN) are to present an overview of performance. Moreover, we used AUROC (Area Under Receiver Operating Characteristic curve) to show the power of discrimination of the model between the positive class and the negative class. The AUPR (Area Under Precision Recall curve) was also used which would be more informative when there is a high imbalance in the data [69]."
        },
        {
            "heading": "6.2 The effectiveness of feature groups",
            "text": "We constructed nine different feature groups namely A, B, C, D, E, F, G, H, and I, which all were coupled with drug features to assess the effects of the different sets of features on the performance of the different classifiers including SVM, RF, MLP, and XGBoost. The feature groups have already been reported in Table 2. We also created some subsets from the groups (AB, CD, EF, and GHI), which are given in Table 3. The selection of the best combination can be considered an optimization problem. Here, we combine feature descriptors based on nonmonotonic information and the performance results we get for different classifiers in single feature groups.\nWe performed experiments to test the effectiveness of the feature groups. In the experi-\nments, we changed the feature groups and applied the random undersampling technique to balance datasets. Statistics of the prediction performance for different classifier models are given in Tables 4 and 5.\nFocus on the EN dataset, we compared the DTI prediction performance of four different\nclassifiers on nine feature groups and four subsets of them. We also highlighted several possible characteristics that could be considered to select the best classifier in DTI prediction. The\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 12 / 25\nresults indicated that XGBoost is competitive in predicting interactions. We also made some subsets from single groups namely: AB, CD, EF, and GHI. Two classifiers include MLP and XGBoost had close performance and outperforms other ML methods to predict DTIs."
        },
        {
            "heading": "6.3 The influence of the data balancing techniques",
            "text": "Imbalanced data classification is a significant challenge for predictive modeling. Most of the machine learning algorithms used for classification were designed around the assumption of an equal number of samples for each class. Imbalanced data lead to biased prediction results in\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 13 / 25\nML problems. The drug\u2013target datasets are highly imbalanced. The number of known DTI (positive samples) is significantly smaller than that of unknown DTI (negative samples), which causes to achieve poor performance results of the prediction model. To make balancing in datasets, we used the One-SVM-US technique to build a powerful model. Here, we make experiments to compare the One-SVM-US technique and random undersampling technique to balance datasets in the model. The experimental results are shown in Tables 6\u20138, which reveal the efficiency of the One-SVM-US algorithm.\nWe observe from Table 6 that the model performance on balanced with Random under-\nsampling and balanced with One-SVM-US in group AB. The results show a significant preference for the AUROC, AUPR, ACC, SEN, SPE, and F1 evaluation metrics by applying OneSVM-US. For the EN dataset, the model achieved AUROC values of 0.9920 in One-SVM-US, and 0.8753 in Random undersampling. In the case of the GPCR dataset, the model obtained AUROC values of 0.9880 and 0.7866, in One-SVM-US and Random undersampling, respectively. For the IC dataset, the model yielded an AUROC of 0.9788 in One-SVM-US and 0.8513 in Random undersampling. Similarly, AUROC values of the model using NR data are 0.9329 in One-SVM-US and 0.6496 in Random undersampling."
        },
        {
            "heading": "EN AB SVM 0.9133 0.9023 0.8429 0.8396 0.8462 0.8425",
            "text": "diction results of ACC, SEN, SPE, and F1 on balanced data with One-SVM-US are 0.9901, 0.9947, 0.9967, and 0.9956, which are 0.1895, 0.1456, 0.208, and 0.176 higher than those balanced with Random undersampling, respectively. These prediction results show that the OneSVM-US technique obtains a comparatively advantageous performance. In the case of GPCR, IC, and NR datasets, the ACC, SEN, SPE, and F1 results for balanced data with One-SVM-US and balanced with Random undersampling are in Table 6. The values of these metrics are also shown in Table 7 for group EF. To better analyze the proposed methods, the ROC curves of two data balancing techniques are shown in Fig 2a\u20132d. These curves demonstrate discriminative ability in group AB, the ROC curve using the One-SVM-US covers the largest area, which is higher than the Random undersampling. The ROC curves of group EF are also shown in Fig 3a\u20133d, which also cover the larger area in the One-SVM-US technique in comparison with the Random undersampling technique.\nWe can see from Table 8 that the model performance on balanced with Random under-\nsampling and balanced with One-SVM-US on the Davis dataset. It can be observed that the proposed One-SVM-US exhibits a similar performance in all datasets. For the Davis dataset, the model AUROC values are 0.9786, 0.9839, 0.9756, and 0.9696 in groups AB, CD, EF, and GHI, respectively. For each feature group, the One-SVM-US technique performs better in terms of AUPR 0.9848, 0.9896, 0.9835, and 0.9781 for groups AB, CD, EF, and GHI, respectively. These results demonstrate that the balanced dataset using One-SVM-US significantly outperforms the balanced dataset using Random undersampling in the case of ROC curves. The accuracy of the XGBoost classifier has been improved after utilizing the One-SVM-US. For all five datasets on the SEN, SPE, and F1 metrics, the results are significantly better in\nOne-SVM-US. Ultimately, One-SVM-US is the efficient method to make balanced datasets to reduce bias and boost the model\u2019s performance."
        },
        {
            "heading": "6.4 The effectiveness of feature selection technique",
            "text": "Feature selection is extremely important in ML because it primarily serves as a fundamental technique to direct the use of informative features for a given ML algorithm. Feature selection techniques are especially indispensable in scenarios with many features, which is known as the curse of dimensionality. The solution is to decrease the dimensionality of the feature space via a feature selection method.\nA feature selection technique by selecting an optimal subset of features reduces the\ncomputational cost. Various feature selection techniques have been utilized in DTI prediction [1,6,64]. The wrapper-based methods refer to a category of supervised feature selection methods that uses a model to score different subsets of features to finally select the best one. Forward selection is one of the Wrapper based methods, which starts from a null model with zero features and adds them greedily one at a time to maximize the model performance.\nhttps://doi.org/10.1371/journal.pone.0288173.g002\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 16 / 25\nHere, we use the FFS-RF algorithm to find the optimal subset and maximize performance. Table 9 indicates the performance results of FFS-RF on the EN dataset in groups AB, CD, EF, and GHI. Table 9 shows ACC, AUROC, and AUPR metrics of the FFS-RF method which reduces the input features to the model. The worth of the FFS-RF is clearly observable; For the EN dataset, we just use 8 features instead of 676 features in group AB, 10 features instead of\nhttps://doi.org/10.1371/journal.pone.0288173.g003\n661 features in group CD, 7 features instead of 504 features in group EF, and 10 features instead of 556 features in group GHI. Moreover, the ACC of the FFS-RF method is 100%, 98%, 98%, and 99% in groups AB, CD, EF, and GHI, respectively. The AUROC and AUPR scores are approximately 0.99 in all four groups. In the case of the EN dataset, the feature groups AB and EF had the best and the worst model performance. So, we performed the FFS-RF method on the remaining datasets, i.e. GPCR, IC, and NR for these feature groups. The ACC, AUROC, and AUPR metrics are shown in Tables 10 and 11 for groups AB and EF, respectively. In group AB, the best feature dimensions selected by FFS-RF are 8, 10, 7, and 10, respectively, which ACC scores are 100%, 99%, 96%, and 97%. The AUROC values of group AB for FFS-RF are 0.9910, 0.9854, 0.9715, and 0.9217. In this group, 0.9968, 0.9924, 0.9769, and 0.9282 are obtained for the AUPR metric. We can see a similar pattern for group EF. Thus, FFS-RF is an effective method to avoid overfitting, improve prediction performance and reduce experimental cost."
        },
        {
            "heading": "6.5 Selection of predictor model",
            "text": "In this study, we focus on four classifiers: SVM, Random Forest (RF), MLP, and XGBoost. To evaluate these classifier models, we apply Cross Validation (CV) technique to select an appropriate predictor model for our problem. The results of the different predictive models are shown for the EN dataset in group AB in Table 12. To make an obvious comparison of prediction effects, the results are also demonstrated as a bar graph for the EN dataset in Fig 4. Comparison among the prediction results of the EN dataset from Table 12 reveals that the highest results of AUROC, AUPR, ACC, SEN, SPE, and F1 obtained by the XGBoost algorithm are 0.9920, 0.9975, 0.9901, 0.9947, 0.9967, and 0.9956, respectively. The overall prediction ACC of SVM, RF, MLP, and XGBoost is 0.8698, 0.9863, 0.8956, and 0.9901, respectively. The XGBoost ACC is 12%, 0.38%, and 9.45% higher than that obtained by SVM, RF, and MLP classifiers. The prediction performance of the XGBoost classifier is premier than the other three classifiers.\nTo make a better evaluation, we compare the DTI prediction performance of classifier\nmodels using the benchmark Yamanishi and Davis datasets. For each classifier, we use the balanced datasets with optimal features to predict DTIs. Table 13 provides a comparison of the XGBoost for SRX-DTI, as the best performing method, and RF, as the second-best performing\nmethod under the 5-Fold CV on four datasets in groups AB and EF. Table 14 also reports the AUROC values under the 5-Fold CV on the Davis dataset. Average AUROC (Mean) values and standard deviation (Std) are also given in Tables 13 and 14 for each classifier model. These results indicate that the XGBoost outperforms other methods in different folds. Therefore, we select the XGBoost classifier as a classification algorithm to predict DTIs. Most of the classifiers pose low standard deviations which reveals our proposed model is a noise-resistant ML method and it does not depend on the classifier and dataset very much. Eventually, we can see the acceptable performance in most of the classifiers."
        },
        {
            "heading": "6.6 Comparison with other methods",
            "text": "During the last decade, different machine learning frameworks have been proposed to predict DTIs. Some of the proposed methods use feature selection techniques and some of those do not use feature selection. Most of the studies (as well as our approach) have used the dataset proposed by Yamanishi et al. [38] to assess the prediction ability of the proposed methods. To evaluate the effectiveness of our method, we consider six drug\u2013target methods under the AUROC values for the same dataset under the 5-fold CV. In the following, we compare the AUROC of the SRX-DTI model with the other state-of-the-art methods proposed by Mousavian et al. [26], Li et al. [70], Meng et al. [71], Wang et al. [29], Mahmud et al. [64], Wang et al. [28], and Mahmud et al. [6]. The AUROCs generated by these models are listed in Table 15. As seen in the table, the AUROC of the proposed model is superior in comparison with the AUROC of other methods in all the datasets.\nAverage AUROC values of SRX-DTI on EN, GPCR, IC, and NR are 0.9920, 0.9880, 0.9788,\nand 0.9329, respectively. It should be considered that most of the existing models are without a"
        },
        {
            "heading": "Classifier AUROC AUPR ACC SEN SPE F1",
            "text": "https://doi.org/10.1371/journal.pone.0288173.g004\nPLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 19 / 25\nfeature selection phase [26,28,29,70,71]. Training the model with more features can lead to overfitting and reduce the power of generalization in the model. Whereas we can achieve the AUROC of 0.9920 in group AB by using just eight features instead of using all 676 features. This is significantly valuable in terms of computational cost. Moreover, our balancing method superlatively addresses the imbalance problem in the datasets, and feature selection techniques select an optimal subset of features for five datasets. Ultimately, the XGBoost classifier is so scalable that can perform better in comparison with other classifiers for identifying the new DTIs."
        },
        {
            "heading": "7. Conclusion",
            "text": "The identification of drug-target interactions through experimentation is a costly and timeconsuming process. Therefore, the development of computational methods for identifying"
        },
        {
            "heading": "Dataset AB EF",
            "text": "PLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 20 / 25\ninteractions between drugs and target proteins has become a critical step in reducing the search space for laboratory experiments. In this work, we proposed a novel framework for predicting drug-target interactions. Our approach is unique in that we use a variety of descriptors for target proteins. We implement the One-SVM-US technique to address unbalanced data. The most important advantage of the proposed method is developing the FFS-RF algorithm to find an optimal subset of features to reduce computational cost and improve prediction performance. We also compare the performance of four classifiers on balanced datasets with optimal features, ultimately selecting the XGBoost classifier to predict DTIs in our model. We then employ the XGBoost classifier to predict DTIs on five benchmark datasets. Our SRX-DTI model achieved good prediction results, which showed that the proposed method outperforms other methods to predict DTIs.\nThe only limitation of this work can be the necessity of feature engineering in comparison\nwith deep learning methods. However, the feature selection technique can also be considered a knowledge discovery tool that provides an understanding of the problem through the analysis of the most relevant features. On the other side, deep neural networks (DNNs) require large amounts of data to learn parameters, but our proposed model work on small data. This research showed that our robust framework is capable of capturing more potent and"
        },
        {
            "heading": "Dataset Mousavian et al. [26] Li et al. [70] Meng et al. [71] Wang et al. [29] Mahmud et al. [64] Wang et al. [28] Mahmud et al. [6] Proposed method",
            "text": "PLOS ONE | https://doi.org/10.1371/journal.pone.0288173 August 3, 2023 21 / 25\ninformative features among massive features. Furthermore, the proposed framework poses resistance against noise and it is a data-independent machine learning method."
        },
        {
            "heading": "Author Contributions",
            "text": "Conceptualization: Jamshid Pirgazi.\nData curation: Jamshid Pirgazi, Ali Ghanbari Sorkhi.\nFormal analysis: Hakimeh Khojasteh, Jamshid Pirgazi, Ali Ghanbari Sorkhi.\nInvestigation: Hakimeh Khojasteh, Jamshid Pirgazi, Ali Ghanbari Sorkhi.\nMethodology: Hakimeh Khojasteh.\nProject administration: Jamshid Pirgazi.\nSoftware: Hakimeh Khojasteh.\nSupervision: Jamshid Pirgazi.\nValidation: Hakimeh Khojasteh.\nVisualization: Hakimeh Khojasteh, Ali Ghanbari Sorkhi.\nWriting \u2013 original draft: Hakimeh Khojasteh.\nWriting \u2013 review & editing: Hakimeh Khojasteh, Jamshid Pirgazi, Ali Ghanbari Sorkhi."
        }
    ],
    "title": "Improving prediction of drug-target interactions based on fusing multiple features with data balancing and feature selection techniques",
    "year": 2023
}