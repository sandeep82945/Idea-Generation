{
    "abstractText": "In this study, the signal-channel blind source separation (SCBSS) problem has been addressed using a novel approach. The approach is based on combining the adaptive mode separation-based wavelet transform with adaptive mode separation (AMSWT) and the densitybased clustering with sparse reconstruction. The approach is performed in Time frequency domain and in reverberant environment. First, using the Fourier transform, the amplitude spectrum of the observed mixture signal is obtained. Then, using variational scaling and wavelet functions, the AMSWT is introduced to adaptively extract spectral intrinsic components (SIC). To obtain a better time-frequency distribution, the AMSWT is applied to each mode. Thus, the SCBSS problem is transformed into a non-underdetermined. Then, for each frequency bin; the density-based clustering, reformulated to eigenvector clustering problem, is performed to estimate the mixing matrix. Finally, the sparse reconstruction is introduced to reconstruct the estimated source. The proposed approach has been evaluated using an objective measure of separation quality. According to experimental results, the proposed approach presents a powerful method to solve the SCBSS problem, and provide better separation performances than the existing methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "abdellah kacha"
        },
        {
            "affiliations": [],
            "name": "KEMIHA Mina"
        }
    ],
    "id": "SP:63a0431c5cac71638a567eb54a35381c997fbf15",
    "references": [
        {
            "authors": [
                "S. Al-Baddai",
                "K. Al-Subari",
                "A.M. Tom\u00e9",
                "G. Volberg",
                "E.W. Lang"
            ],
            "title": "Combining EMD with ICA to Analyze Combined EEG-fMRI Data",
            "venue": "In Proceedings of the MIUA, Egham, UK,",
            "year": 2014
        },
        {
            "authors": [
                "X. Zeng",
                "S. Li",
                "G.J. Li",
                "Y. Zhou",
                "D.H. Mo"
            ],
            "title": "Fetal ECG extraction by combining singlechannel SVD and cyclostationarity-based blind source separation",
            "venue": "Int. J. Signal Process 2013,",
            "year": 2013
        },
        {
            "authors": [
                "S. Wilson",
                "J. Yoon"
            ],
            "title": "Bayesian ICA-based source separation of Cosmic Microwave Background by a discrete functional approximation",
            "venue": "arXiv 2010,",
            "year": 2010
        },
        {
            "authors": [
                "B.A. Draper",
                "K. Baek",
                "M.S. Bartlett",
                "J.R. Beveridge"
            ],
            "title": "Recognizing faces with PCA and ICA",
            "venue": "Comput. Vis. Image Underst. 2003,",
            "year": 2003
        },
        {
            "authors": [
                "A.-K. Takahata",
                "E.-Z. Nadalin",
                "R. Ferrari",
                "L.-T. Duarte",
                "R. Suyama",
                "R.-R. Lopes",
                "J.M.-T. Romano",
                "M. Tygel",
                "Unsupervised processing of geophysical signals"
            ],
            "title": "a review of some key aspects of blind deconvolution and blind source separation",
            "venue": "IEEE Signal Process. Mag. 29(4), 27-35",
            "year": 2012
        },
        {
            "authors": [
                "A. Nagathil",
                "C. Weihs",
                "K. Neumann",
                "R. Martin"
            ],
            "title": "``Spectral complexity reduction of music signals based on frequency-domain reduced-rank approximations: An evaluation with cochlear implant",
            "venue": "listeners,'' J. Acoust. Soc. Amer., vol. 142,",
            "year": 2017
        },
        {
            "authors": [
                "X. Liu",
                "A. Srivastava",
                "K. Gallivan"
            ],
            "title": "Optimal Linear Representations of Images for Object Recognition",
            "venue": "In Proceedings of the 2003 Conference on Computer Vision and Pattern RecognitionWorkshop, Madison, WI,",
            "year": 2003
        },
        {
            "authors": [
                "J. Yang",
                "D.B. Williams"
            ],
            "title": "MIMO Transmission Subspace Tracking with Low Rate Feedback",
            "venue": "In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, Philadelphia, PA, USA,",
            "year": 2005
        },
        {
            "authors": [
                "A. Eronen"
            ],
            "title": "Musical Instrument Recognition Using ICA-Based Transform of Features and Discriminatively Trained HMMs",
            "venue": "In Proceedings of the Seventh International Symposium on Signal Processing and Its Applications, Paris, France,",
            "year": 2003
        },
        {
            "authors": [
                "R.B. Randall"
            ],
            "title": "``A history of cepstrum analysis and its application to mechanical problems,'",
            "venue": "Mech. Syst. Signal Process.,",
            "year": 2017
        },
        {
            "authors": [
                "J. Traa",
                "P. Smaragdis"
            ],
            "title": "Multichannel source separation and tracking with RANSAC and directional statistics",
            "venue": "IEEE/ACM Trans. Audio, Speech, Language Process",
            "year": 2014
        },
        {
            "authors": [
                "D. Nuzillard",
                "A. Bijaoui"
            ],
            "title": "Blind source separation and analysis of multispectral astronomical images",
            "venue": "Astron Astrophys Suppl Ser. 147(1),",
            "year": 2000
        },
        {
            "authors": [
                "I. Bekkerman",
                "J. Tabrikian"
            ],
            "title": "Target detection and localization using mimo radars and sonars",
            "venue": "IEEE Trans. Signal Process",
            "year": 2006
        },
        {
            "authors": [
                "A. Cichocki",
                "S. Amari"
            ],
            "title": "Adaptive Blind Signal and Image Processing",
            "year": 2003
        },
        {
            "authors": [
                "Z. Duan",
                "Y. Zhang",
                "C. Zhang",
                "Z. Shi"
            ],
            "title": "Unsupervised Single-Channel Music Source Separation by Average Harmonic Structure Modeling",
            "venue": "IEEE Trans. Audio Speech Lang. Process",
            "year": 2008
        },
        {
            "authors": [
                "C. F\u00e9votte",
                "N. Bertin",
                "J.-L. Durrieu"
            ],
            "title": "Nonnegative matrix factorization with the itakurasaito divergence: With application to music analysis,",
            "venue": "Neural Comput.,",
            "year": 2009
        },
        {
            "authors": [
                "B. Wang",
                "M.D. Plumbley"
            ],
            "title": "Investigating Single-Channel Audio Source Separation Methods Based on Non-Negative Matrix Factorization",
            "venue": "In Proceedings of the ICA Research Network InternationalWorkshop, Liverpool,",
            "year": 2006
        },
        {
            "authors": [
                "B. Mijovic",
                "M. De Vos",
                "I. Gligorijevi \u0301c",
                "J. Taelman",
                "S. Van Hu_el"
            ],
            "title": "Source Separation From Single-Channel Recordings by Combining Empirical-Mode Decomposition and Independent Component Analysis",
            "venue": "IEEE Trans. Biomed. Eng. 2010,",
            "year": 2010
        },
        {
            "authors": [
                "NE. Huang",
                "Z. Shen",
                "SR. Long",
                "MC. Wu",
                "HH. Shih",
                "Q. Zheng",
                "NC. Yen",
                "CC. Tung",
                "HH. Liu"
            ],
            "title": "The empirical mode decomposition and the Hilbert spectrum for nonlinear and nonstationary time series analysis",
            "venue": "In proceedings of The Royal Society A Mathematical Physical and Engineering Sciences 454(1971),",
            "year": 1998
        },
        {
            "authors": [
                "Y. Litvin",
                "I. Cohen"
            ],
            "title": "Single-Channel Source Separation of Audio Signals Using Bark Scale wavelet packet decomposition",
            "venue": "j. signal process. syst",
            "year": 2010
        },
        {
            "authors": [
                "Lin Li",
                "Charles K. Chui",
                "Qingtang Jiang"
            ],
            "title": "Direct Signal Separation via Extraction of Local Frequencies With Adaptive Time-Varying Parameters",
            "venue": "IEEE transactions on signal processing,",
            "year": 2022
        },
        {
            "authors": [
                "Xun Chen",
                "Aiping Liu",
                "Joyce Chiang",
                "Z. Jane Wang",
                "Martin J. McKeown",
                "Rabab K. Ward"
            ],
            "title": "Removing Muscle Artifacts From EEG Data: Multichannel or Single-Channel Techniques",
            "venue": "IEEE SENSORS JOURNAL,",
            "year": 2016
        },
        {
            "authors": [
                "Fangyu Li",
                "Bangyu Wu",
                "Naihao Liu",
                "Ying Hu",
                "Hao Wu"
            ],
            "title": "Seismic Time Frequency Analysis via Adaptive Mode Separation-Based Wavelet Transform\u2019",
            "venue": "IEEE geoscience and remote sensing letters,",
            "year": 2020
        },
        {
            "authors": [
                "J. Gilles"
            ],
            "title": "Empirical wavelet transform,",
            "venue": "IEEE Trans. Signal Process.,",
            "year": 2013
        },
        {
            "authors": [
                "K. Dragomiretskiy",
                "D. Zosso"
            ],
            "title": "Variational mode decomposition,",
            "venue": "IEEE Trans. Signal Process.,",
            "year": 2014
        },
        {
            "authors": [
                "J. Yang",
                "Y. Guo",
                "Z. Yang"
            ],
            "title": "Under-Determined Convolutive Blind Source Separation Combining Density-Based Clustering and Sparse Reconstruction in Time-Frequency Domain",
            "venue": "IEEE transactions on circuits and systems\u2013i: regular papers,",
            "year": 2019
        },
        {
            "authors": [
                "T. Barker",
                "T. Virtanen"
            ],
            "title": "Blind Separation of Audio Mixtures Through Nonnegative Tensor Factorization of Modulation spectrograms",
            "venue": "IEEE/ACM transactions on audio, speech, and language processing,",
            "year": 2016
        },
        {
            "authors": [
                "R. M"
            ],
            "title": "Hestenes, \u201cMultiplier and gradient methods,",
            "venue": "J. Optim. Theory Appl.,",
            "year": 1969
        },
        {
            "authors": [
                "J.-J. Yang",
                "H.-L. Liu"
            ],
            "title": "Blind identification of the underdetermined mixing matrix based on",
            "venue": "Kweighted hyperline clustering,\u201d Neurocomputing,",
            "year": 2015
        },
        {
            "authors": [
                "E. Habets"
            ],
            "title": "Room impulse response (RIR) generator,",
            "year": 2008
        },
        {
            "authors": [
                "Wei Liu",
                "Siyuan Cao",
                "Yangkang Chen"
            ],
            "title": "Applications of variational mode decomposition in seismic time-frequency analysis GEOPHYSICS",
            "venue": "(SEPTEMBER-OCTOBER",
            "year": 2016
        }
    ],
    "sections": [
        {
            "text": "In this study, the signal-channel blind source separation (SCBSS) problem has been\naddressed using a novel approach. The approach is based on combining the adaptive mode separation-based wavelet transform with adaptive mode separation (AMSWT) and the densitybased clustering with sparse reconstruction. The approach is performed in Time frequency domain and in reverberant environment. First, using the Fourier transform, the amplitude spectrum of the observed mixture signal is obtained. Then, using variational scaling and wavelet functions, the AMSWT is introduced to adaptively extract spectral intrinsic components (SIC). To obtain a better time-frequency distribution, the AMSWT is applied to each mode. Thus, the SCBSS problem is transformed into a non-underdetermined. Then, for each frequency bin; the density-based clustering, reformulated to eigenvector clustering problem, is performed to estimate the mixing matrix. Finally, the sparse reconstruction is introduced to reconstruct the estimated source. The proposed approach has been evaluated using an objective measure of separation quality. According to experimental results, the proposed approach presents a powerful method to solve the SCBSS problem, and provide better separation performances than the existing methods."
        },
        {
            "heading": "1 Introduction",
            "text": "The blind sources separation (BSS) aim to separates the sources signals from the mixed\nsignals without any information. Applications for BSS include medical imaging and engineering [1, 2], astrophysics [3], image processing [4], geophysical data processing [5], speech processing [6,7], detection and radar localization [8], communication systems [9], automatic transcription of speech [10], musical instrument identification [11], mechanical flaw detection [12], multichannel telecommunications [13], multi-spectral astronomical imaging [14] and speech recognition [15].\nThe BSS categories are described in the literature as being linear and nonlinear,\ninstantaneous and convolutive, over-complete and underdetermined. The convolutive BSS is demonstrated to be an effective way to represent the speech signal mixing mechanism in a reverberant environment [16, 17]. Either the time domain or the frequency domain can be used to formulate the BSS problem. The BSS can be also treated in time-frequency domain (TF) where the computational efficiency of BSS algorithms is higher.\nIn most situations and for many practical uses, only one-channel recording is available. This\nparticular instance of the under-determined source separation problem called single channel source separation (SCSS), and has been the subject of many studies. In order to address the single channel audio source separation problem, numerous strategies have been introduced in the literature [18]. In [19] the authors attempt to combine the maximum-likelihood estimation and NMF based on Itakura-Saito divergence measurement. The Short Time Fourier Transform (STFT) representation of a single channel observed signal has been subjected to the nonnegative matrix factorization (NMF) approach in [20], although the method necessitates the use of extra training data. A combination of empirical mode decomposition (EMD) and ICA, as well as wavelet transformations, have been suggested in [21], although wavelet transforms need some specified basis functions to represent a signal, there is no rigorous mathematical theory underpinning the EMD or its improved algorithms [22]. The bark scale aligned wavelet packet decomposition has been introduced in [23], and the separation step has been performed using the Gaussian mixture model (GMM), which was employed before the Fourier transform. In [24] the authors propose the variational mode decomposition (VMD) method to solve the SCBSS problem. The separation process is performed using joint approximate diagonalization based on fourth-order cumulant matrices. In [25] authors present a novel method in noisy environment. The method is based on selecting the time-frequency (TF) units of signal presence and computing the mixture spectral amplitude, the separation process is performed based on TF masking. In [26] an adaptive signal separation operation (ASSO) has been proposed. The method is performed by introducing a time-varying parameter that adapts locally to Ifs, and using linear chirp (linear frequency modulation). The single-channel technique has been explored for muscle artifact removal from multichannel EEG in [27].\nThe classic TF resolution is computed using the STFT transformation, this TF resolution\ndoes not reflect the time-varying information; in addition, the STFT yields a time-frequency resolution with only uniform frequency and time resolutions. A new Adaptive Mode SeparationBased Wavelet Transform (AMSWT) has been proposed in [29] based on [29, 30]. The AMSWT method involves solving a recursive optimization problem in order to adaptively extract spectral intrinsic components (SIC). The limited support of each spectral mode is implemented in order to\nestablish the spectral boundaries for wavelets bank configuration. Then, the created wavelets bank configuration using the obtained spectral boundaries to highlight the spectrum information. The AMSWT strategy is a fully adaptive one that doesn't require prior knowledge.\nIn [31] a new method to solve the under-determined BSS problem for convolutive mixture is\nproposed. The method is based on combining Density-based grouping and sparse source reconstruction. The method is performed in time-frequency domain. The density-based clustering is introduced to estimate the mixing matrix. The method is performed based on a certain local dominant assumption; the mixing matrix estimate is converted as an eigenvector clustering issue. The rank-one structure of the local covariance matrices of the mixture TF vectors is first used to extract the eigenvectors. By combining weight clustering and density-based clustering, these eigenvectors are subsequently grouped and tweaked to provide an approximated mixing matrix. The sparse reconstruction is performed for sources estimation by using the iterative Lagrange multiplier\napproach, the source reconstruction is converted into a \u2113\ud835\udc5d-norm minimization. In this paper a new method has been proposed to solve the SCBSS problem. The method is based on combining the AMSWT [28] and density-based clustering with sparse reconstruction method introduced in [31]. The method is performed in three stages. The amplitude spectrum of the observed mixture signal is obtained using STFT. The convolution in the time domain can be approximated by a multiplication in the STFT domain. Then, a better TF resolution is obtained using the variational scaling and wavelet functions, which are applied on the spectral intrinsic components (SIC), this one is adaptively extracted using the AMSWT. By creating virtual multichannel signals of the TF resolution, the single channel has been changed into a nonunderdetermined problem. Then, for each TF resolution and for each frequency bin, the densitybased clustering which is converted to eigenvector clustering problem, combined with the sparse reconstruction, which is converted to a sparse reconstruction minimization problem, these approaches are respectively performed for each TF resolution to estimate the mixing matrix and estimated sources reconstruction. The BSSeval is introduced to evaluate the proposed method in terms of source-to-distortion ratio (SDR), source-to-artifact ratio (SAR), source-to-interference ratio (SIR), and compared to the BSS performance results obtained via VDM method [24], adaptive spectrum amplitude estimator and masking method [25] and the nonnegative tensor factorization of modulation spectrograms method [32].\nThe following sections make up the remaining content: the SCBSS problem formulation is\npresented in the second section, the adaptive mode separation-based wavelet transform is introduced in the third section. The fourth section shows Density-based Clustering method; the fifth\nsection presents the Source Reconstruction. The main steps of the proposed algorithm with the application of this algorithm in the simulation experiments and the comparison results with other algorithms in the sixth section; finally, conclusions and discussions are given in the seventh section."
        },
        {
            "heading": "2 Convolutive Mixing System Model",
            "text": "Let \ud835\udc31\ud835\udc31(\ud835\udc61) = [\ud835\udc65\ud835\udc651(\ud835\udc61), . . , \ud835\udc65\ud835\udc65\ud835\udc40(\ud835\udc61)]\ud835\udc47 a vector of M observed sources abstained via the mixing of N independent sources \ud835\udc2c(\ud835\udc61) = [\ud835\udc601(\ud835\udc61), . . , \ud835\udc60\ud835\udc41(\ud835\udc61)]\ud835\udc47. The BSS problem aim to estimate the \ud835\udc41 sources from the \ud835\udc40 mixtures. The convolutive mixture is occurs by the propagation of the sound through space and multiple paths which cause the reflections from different objects, especially in rooms and closed environments. The convolutive mixture is modeled as the flowing equation:\n\ud835\udc65\ud835\udc65\ud835\udc57(\ud835\udc61) =\u2211\u2211\u210e\ud835\udc57\ud835\udc56(\ud835\udc58)\ud835\udc60\ud835\udc56(\ud835\udc61 \u2212 \ud835\udc58)\ud835\udc3e\u22121\ud835\udc58=0\ud835\udc41\ud835\udc56=1 (1) The matrix form is given as :\n\ud835\udc65\ud835\udc65(\ud835\udc61) = \ud835\udc6f \u2217 \ud835\udc60(\ud835\udc61) = \u2211\ud835\udc6f\ud835\udc58\ud835\udc60(\ud835\udc61 \u2212\ud835\udc3e\u22121\ud835\udc58=0 \ud835\udc58) (2) where \u210e\ud835\udc57\ud835\udc56 denotes the impulse response from source \ud835\udc56 to sensor \ud835\udc57, and \ud835\udc6f is an \ud835\udc40x\ud835\udc41 matrix that contains the kth filter coefficients.\nThe only one-channel recording is accessible in most cases and for many practical purposes.\nNumerous studies have examined this instance known as single channel source separation. In this case = 1 . The convoltuvive SCBSS in time-frequency domain is described as the following equation: \ud835\udc4b(\ud835\udc53, \ud835\udc61) =\u2211\ud835\udc65\ud835\udc65\ud835\udc56(\ud835\udc53, \ud835\udc61\ud835\udc41\ud835\udc56=0 ) (3) The traditional source separation techniques are ineffective in this scenario. The SCSS study area in which the issue might be viewed as a single observation combined with numerous unidentified sources."
        },
        {
            "heading": "3 Adaptive Mode Separation-Based Wavelet Transform",
            "text": "The STFT is used to calculate the classic TF resolution, which has an even bandwidth\ndistribution across all frequency channels, and suffers from the TF resolution limitation due to the fixed window size. The speech signal is described as being substantially non-periodic and non-\nstationary. Therefore, using the STFT transform will result in mistakes, particularly when complex transitory phenomena like voice mixing occur in the signal under study.\nTo each mode, the AMSWT performs a time-frequency analysis using variational scaling\nand wavelet functions. The method is built on the ADMM solver [33], which then defines a bank of variational scaling functions and wavelets depending on the spectral boundaries that have been\ndefined. As a result, the approximate coefficients are derived by multiplying the analyzed signal \ud835\udc65\ud835\udc65 by the variational scaling function inner product. However, the inner product of the analyzed signal \ud835\udc65\ud835\udc65 with variational wavelets yields the detailed coefficients, which are given by the following formulae respectively: \ud835\udc4a\ud835\udc65\ud835\udc65(0, \ud835\udc61) = \u2329\ud835\udc65\ud835\udc65, \u22051\u232a = \u222b\ud835\udc65\ud835\udc65(\ud835\udf0f)\u2205\u03051(\ud835\udf0f \u2212 \ud835\udc61)\ud835\udc51\ud835\udf0f (4) and \ud835\udc4a\ud835\udc65\ud835\udc65(\ud835\udc58, \ud835\udc61) = \u2329\ud835\udc65\ud835\udc65, \ud835\udf13\ud835\udc58\u232a = \u222b\ud835\udc65\ud835\udc65(\ud835\udf0f)?\u0305?\ud835\udc58(\ud835\udf0f \u2212 \ud835\udc61)\ud835\udc51\ud835\udf0f (5) where \ud835\udc65\ud835\udc65 is the input signal. In [28], under the amplitude-modulated frequency-modulated (AM-FM) assumption, the\nintrinsic modes \ud835\udc62(\ud835\udc61) have distinguishable features in the frequency domain. Using the alternate direction method of multiplier (ADMM) solver, the spectral modes can be adaptively obtained, similar to intrinsic mode functions (IMF) extraction, to estimate compact modes:\nmin\ud835\udc62\ud835\udc58,\ud835\udf14\ud835\udc58 {\u2211\u2016\ud835\udf15\ud835\udc61 [(\ud835\udeff(\ud835\udc61) + \ud835\udc57\ud835\udf0b\ud835\udc61) \u2217 \ud835\udc62\ud835\udc58(\ud835\udc61)] \ud835\udc52\ud835\udc57\ud835\udf14\ud835\udc58\ud835\udc61\u201622\ud835\udc58 }\ud835\udc60. \ud835\udc61. \u2211\ud835\udc62\ud835\udc58 = \ud835\udc65\ud835\udc65(\ud835\udc61)\ud835\udc3e (6)\nWhere \ud835\udc65\ud835\udc65(\ud835\udc61) is the signal to be decomposed under the constraint that over all modes should be the input signal. \ud835\udeff(. ) is a Dirac impulse. (\ud835\udeff(\ud835\udc61) + \ud835\udc57\ud835\udf0b\ud835\udc61) \u2217 \ud835\udc62\ud835\udc58(\ud835\udc61) denotes the original data and its Hilbert transform. \ud835\udc62\ud835\udc58, \ud835\udf14\ud835\udc58 and \ud835\udc58 denote the modes and their central frequencies and the mode number respectively.\nThe spectral segmentation boundary number can be determined empirically using the\nequation below. ?\u0303? = \ud835\udc5a\ud835\udc56\ud835\udc5b{\ud835\udc5b \u2208 \u2124+|\ud835\udc5b \u2265 2\ud835\udf0c ln\ud835\udc41} (7) where \ud835\udc41 presents the signal length and \ud835\udf0c is the scaling exponent determined by the detrended fluctuation analysis (DFA).\nAccording to [28], the equation is solved using a quadratic penalty term, the parameter \ud835\udf06 design the Lagrangian multiplier to render the problem unconstrained,. \ud835\udc3f(\ud835\udc62\ud835\udc58, \ud835\udf14\ud835\udc58, \ud835\udf06 ) = \ud835\udf02\u2211\u2016\ud835\udeff\ud835\udc61[(\ud835\udeff(\ud835\udc61) + \ud835\udc57\ud835\udf0b\ud835\udc61) \u2217 \ud835\udc62\ud835\udc58(\ud835\udc61)]\ud835\udc52\ud835\udc57\ud835\udf14\ud835\udc58\ud835\udc61\u201622\ud835\udc58 + \u2329\ud835\udf06, \ud835\udc65\ud835\udc65 \u2212\u2211 \ud835\udc62\ud835\udc58\ud835\udc3e \u232a + \u2016\ud835\udc65\ud835\udc65 \u2212\u2211 \ud835\udc62\ud835\udc58\ud835\udc3e \u201622 (8) therefore \ud835\udc62\ud835\udc58 is determined recursively as\n?\u0302?\ud835\udc58\ud835\udc5b+1(\ud835\udf14) = \ud835\udc4b\ud835\udc4b(\ud835\udf14) \u2212 \u2211 ?\u0302?\ud835\udc56\ud835\udc5b+1(\ud835\udf14) + ?\u0302?\ud835\udc5b2\ud835\udc56\u2260\ud835\udc571 + 2\ud835\udf02(\ud835\udf14 \u2212 \ud835\udf14\ud835\udc58\ud835\udc5b)2 (9) where \ud835\udc4b\ud835\udc4b(\ud835\udf14), \ud835\udc62?\u0302?(\ud835\udf14) and ?\u0302? (\ud835\udf14) denote the Fourier transform of the input signal \ud835\udc65\ud835\udc65(\ud835\udc61), the mode function \ud835\udc62\ud835\udc56(\ud835\udc61) and \ud835\udf06(\ud835\udc61) respectively. \ud835\udf02 denotes the balancing parameter of the data-fidelity constraint. The center frequencies \ud835\udf14\ud835\udc58\ud835\udc5b+1 are updated as the center of gravity of the corresponding mode\u2019s power spectrum using the following equation\n\ud835\udf14\ud835\udc58\ud835\udc5b+1 = \u222b \ud835\udf14|?\u0302?\ud835\udc58\ud835\udc5b+1(\ud835\udf14)|2\ud835\udc51\ud835\udf14\u221e0\u222b |?\u0302?\ud835\udc58\ud835\udc5b+1(\ud835\udf14)|2\u221e0 \ud835\udc51\ud835\udf14 (10) As a result, rather than using a predefined wavelet bank, we create adaptive wavelet banks\nbased on spectral modes and their corresponding center frequencies, which represent the intrinsic components.\nAuthors in [28] used the mode bandwidth and central frequencies to define the boundaries\nbetween each mode, however in the literature, some authors just used the average of the two central frequencies as the spectral boundary, which ignores the spectrum distribution.\nWe consider the \ud835\udc58\ud835\udc61\u210e mode with the mean frequency \ud835\udf14\ud835\udc58 and a spectral bandwidth \ud835\udefd\ud835\udc58, then the boundary \ud835\udec0\ud835\udc58 between \ud835\udc58\ud835\udc61\u210e the and the \ud835\udc58 + 1 mode is given by the following equation\n\ud835\udec0\ud835\udc58 = \ud835\udf14\ud835\udc58 + \ud835\udefd\ud835\udc582 + \ud835\udf14\ud835\udc58+1 \u2212 \ud835\udefd\ud835\udc58+122 (11) where \ud835\udec0\ud835\udc58 = 0 and \ud835\udec0\ud835\udc58 = \ud835\udf0b. The authors apply the same notion used in the production of both Littlewood\u2013Paley and Meyer's wavelets [34] for variational scaling functions and wavelets based on spectral boundaries. \u2205\u0302\ud835\udc58 and ?\u0302?\ud835\udc58 are respectively defined by the following equation, with \ud835\udefe is the parameter that ensures no overlap between the two consecutive transitions.\n\u2205\u0302\ud835\udc58 = { 1, \ud835\udf14 \u2264 (1 \u2212 \ud835\udefe)\ud835\udec0\ud835\udc58cos (\ud835\udf0b2 \ud835\udefc(\ud835\udefe, \ud835\udec0\ud835\udc58)) , (1 \u2212 \ud835\udefe)\ud835\udec0\ud835\udc58 \u2264 \ud835\udf14 \u2264 (1 + \ud835\udefe)\ud835\udec0\ud835\udc580 otherwise (12)\nand\n?\u0302?\ud835\udc58 = { 1, (1 + \ud835\udefe)\ud835\udec0\ud835\udc58 \u2264 \ud835\udf14 \u2264 (1 \u2212 \ud835\udefe)\ud835\udec0\ud835\udc58+1cos (\ud835\udf0b2 \ud835\udefc(\ud835\udefe, \ud835\udec0\ud835\udc58+1)) , (1 \u2212 \ud835\udf06)\ud835\udec0\ud835\udc58+1 \u2264 \ud835\udf14 \u2264 (1 + \ud835\udf06)\ud835\udec0\ud835\udc58+1sin (\ud835\udf0b2 \ud835\udefc(\ud835\udefe, \ud835\udec0\ud835\udc58)) , (1 \u2212 \ud835\udf06)\ud835\udec0\ud835\udc58 \u2264 \ud835\udf14 \u2264 (1 + \ud835\udf06)\ud835\udec0\ud835\udc58 0 otherwise\n(13)\nWhere \ud835\udefc(\ud835\udefe, \ud835\udec0\ud835\udc58) = \ud835\udefd{( 12\ud835\udefe\ud835\udec0\ud835\udc58) [|\ud835\udf14| \u2212 (1 \u2212 \ud835\udefe)\ud835\udec0\ud835\udc58]}] and \ud835\udefd(\ud835\udc65) is an arbitrary function defined as follow:\n\ud835\udefd(\ud835\udc65) = {0, \ud835\udc65 \u2264 01, \ud835\udc65 > 1\ud835\udefd(\ud835\udc65) + \ud835\udefd(1 \u2212 \ud835\udc65) = 1, 0 < \ud835\udc65 < 1 (14) The algorithm adaptive mode separation-based wavelet transform is summarized as following: Step1 : Time frequency presentation Input : Observed mixture.\n Using the Fourier transform, obtain the amplitude spectrum signal.  Obtain the appropriate spectrum spectral modes (segments). Execute the first inner loop and the second inner loop to update \ud835\udc62\ud835\udc58 according to equation (9); and update \ud835\udf14\ud835\udc58 according to equation (10); respectively  Compute proper spectral boundaries using equation (11). Then, using equation (12)\nand (13), the bank of variational scaling functions and wavelets based on the spectral boundaries is defined.  Finally, using equations (4) and (5) respectively, apply variational scaling and wavelet functions to each mode to obtain the time-frequency distribution.\nOutput: time frequency distribution (TF) of observed mixture."
        },
        {
            "heading": "4 Density-based Clustering",
            "text": "In [31] the authors introduce the eigenvector clustering as an alternative to estimate the mixing matrix. The eigenvector clustering is based on two factors, such as the local density \ud835\udf0c\ud835\udc5e, and the minimum distance \ud835\udeff\ud835\udc5e that may be taken between point q and any additional points with a higher density, are given respectively by the following equations \ud835\udf0c\ud835\udc5e \u225c \u2211\ud835\udc52\u2212\ud835\udf10\ud835\udc5e\ud835\udc582\ud835\udf0f\ud835\udc502\ud835\udc58\u2260\ud835\udc5e (15) and \ud835\udeff\ud835\udc5e = min\ud835\udc58:\ud835\udf0c\ud835\udc58>\ud835\udf0c\ud835\udc5e(\ud835\udf10\ud835\udc5e\ud835\udc58) (16) where the region for each data point is defined by a cutoff distance \ud835\udf0f\ud835\udc50, and \ud835\udc7d denote the similarity matrix whose elements \ud835\udf10\ud835\udc5e\ud835\udc58. From the eigenvectors \ud835\udc68 whose elements \ud835\udc82\ud835\udc5e, the similarity matrix \ud835\udc7d is generated as follow:\n\ud835\udc7d \u225c [\ud835\udf1011 \u22ef \ud835\udf101\ud835\udc44\u22ee \u22f1 \u22ee\ud835\udf10\ud835\udc441 \u22ef \ud835\udf10\ud835\udc44\ud835\udc44] (17)\nwhere \ud835\udf10\ud835\udc5e\ud835\udc58 = \u2016\ud835\udc82\ud835\udc5e \u2212 (\ud835\udc82\ud835\udc5e\ud835\udc3b\ud835\udc82\ud835\udc58)\u2016\ud835\udc392 and \ud835\udc5e, \ud835\udc58 = 1, . . , \ud835\udc44 The eigenvector extraction is based on the local covariance matrix \ud835\udc79\ud835\udc5e\u03a7 where \ud835\udc79\ud835\udc5e\u03a7 =\u2211 \ud835\udf0e\ud835\udc56,\ud835\udc5e2 \u210e\ud835\udc56\u210e\ud835\udc56\ud835\udc3b\ud835\udc41\ud835\udc56=1 where \u210e\ud835\udc56 is called as steering vector representing each direction of mixing matrix. According to [31], there is at least one sub-block indexed as \ud835\udc5e\ud835\udc56 for which the associated local covariance \ud835\udc79\ud835\udc5e\ud835\udc56\u03a7 where the local covariance matrix has roughly a rank-one structure. In [29], this conditions is exploited, the authors applies eigenvalue decomposition (EVD) to the local\ncovariance matrix of \ud835\udc79\ud835\udc5e\u03a7 resulting in the following equation: \ud835\udc79\ud835\udc5e\u03a7 = \ud835\udc7c\ud835\udc5e\ud835\udeba\ud835\udc5e\ud835\udc7c\ud835\udc5e\ud835\udc3b (18) where \ud835\udc7c\ud835\udc5e and \ud835\udeba\ud835\udc5e denote the eigenvector matrix and eigenvalue matrix respectively.\nThe extracted vector denoted \ud835\udc1a\ud835\udc5e corresponds to the largest eigenvalue of \ud835\udeba\ud835\udc5e, and also presents the first eigenvector in \ud835\udc7c\ud835\udc5e. To obtain an eigenvector matrix described by \ud835\udc00 \u225c [\ud835\udc1a1, \u2026 , \ud835\udc1a\ud835\udc44], the eigenvector extraction is done sub-block wisely.\nAccording to [31], the global maximum in the density indexed as \ud835\udc5e\u2217 has a minimum distance \ud835\udeff\ud835\udc5e\u2217 defined as follows: \ud835\udeff\ud835\udc5e\u2217 = max\ud835\udc5e,\ud835\udc58=1,\u2026,\ud835\udc44(\ud835\udf10\ud835\udc5e\ud835\udc58) if \ud835\udf0c\ud835\udc5e\u2217 = max\ud835\udc5e=1,\u2026,\ud835\udc44(\ud835\udf0c\ud835\udc5e) (19) The two components are multiplied together to provide the following score: \ud835\udefe\ud835\udc5e = \ud835\udf0c\ud835\udc5e \u00d7 \ud835\udeff\ud835\udc5e (20) To get {\ud835\udefe\ud835\udc5e}\ud835\udc5e=1\ud835\udc44 , the scores from the equation (20) are applied to all of the sub-blocks. The obtained scores are then rated in order of decreasing order, as a result, the eigenvectors with the greatest \ud835\udc41 scores are retrieved as clusters, which are denoted by \ud835\udc02 \u225c [\ud835\udc841, . . . , \ud835\udc84\ud835\udc41]. As mentioned in [31], it would be difficult to cluster eigenvectors using solely the densitybased strategy described above. To address this issue, a weight clustering approach to further tune the projected clusters introduced in [35] is used. The procedures of weighted eigenvector clustering can be concluded in three steps.\nFirst, the eigenvector is weighted by a kernel function defined as follow:\n\ud835\udc83\ud835\udc5e\ud835\udc58 \u225c \ud835\udc52\ud835\udf14\ud835\udc5e\ud835\udc582 \ud835\udf0f02\u2044 \ud835\udc82\ud835\udc5e (21)\nwhere \ud835\udc58 = 1, . . , \ud835\udc41 and \ud835\udf14\ud835\udc5e\ud835\udc58 = \u2016\ud835\udc82\ud835\udc5e \u2212 (\ud835\udc82\ud835\udc5e\ud835\udc3b \ud835\udc84\ud835\udc58) \ud835\udc84\ud835\udc58\u2016\ud835\udc392 . Then, the weighted covariance matrix is created an given as : \ud835\udc79\ud835\udc58b =\u2211\ud835\udc83\ud835\udc5e\ud835\udc58\ud835\udc44\ud835\udc5e=1 \ud835\udc83\ud835\udc5e\ud835\udc58\ud835\udc3b (22) Finally, the EVD is applied to the weighted covariance matrix \ud835\udc79\ud835\udc58\ud835\udc4f given as follow \ud835\udc79\ud835\udc58b = \ud835\udc7c\ud835\udc5e\ud835\udc58\ud835\udeba\ud835\udc5e\ud835\udc58\ud835\udc7c\ud835\udc5e\ud835\udc58\ud835\udc3b (23) As an updated of cluster \ud835\udc84\ud835\udc58 where \ud835\udc58 = 1, . . . , \ud835\udc41, the eigenvector that corresponds to the largest eigenvalue from the equation (23) is extracted.\nThe mixing matrix estimation algorithm is summarized as the following steps:\nStep2 : Mixing Matrix Estimation Input : X which present the TF resolution of observed signal whose element \ud835\udc31\ud835\udc51. For each blocks q \u2208 Q do\n Calculate the local covariance matrix of \ud835\udc11q\u03a7 using ?\u0302?\ud835\udc53,\ud835\udc5e\ud835\udebe = 1\ud835\udc5d \u2211 \ud835\udc31\ud835\udc53,\ud835\udc51 \ud835\udc31\ud835\udc53,\ud835\udc51\ud835\udc3b\ud835\udc5e\ud835\udc43\ud835\udc51=\ud835\udc5e(\ud835\udc43\u22121)+1  Construct the eigenvector matrix \ud835\udc00 from the equation (18). End\n Using the eigenvector matrix \ud835\udc00, compute the similarity matrix defined by equation (17) For each blocks q \u2208 Q do  Calculate the local density \u03c1q and the minimum distance \u03b4q and the score \u03b3q using\nequations (15), (16), and (20) respectively\nEnd  Calculate \u03b4q\u2217 using equation (19), then, obtain de score sequence \u03a5 = [\u03b31, \u2026 , \u03b3\ud835\udc44].  To get the score sequence of \u03a5, reorder the eigenvector matrix with the same\npermutation of decreasing alignment. So, To get the estimated clusters \ud835\udc02 = [\ud835\udc1c1, \u2026 , \ud835\udc1c\ud835\udc41], truncate the first \ud835\udc41 reordered eigenvectors.\nFor \ud835\udc58 = 1 \ud835\udc61\ud835\udc5c \ud835\udc41 \ud835\udc51\ud835\udc5c For each sub-blocks q \u2208 Q do  Calculate the weighted eigenvector \ud835\udc1bqk using \ud835\udc1aq and \ud835\udc1ck, then calculate \ud835\udc11qkb using\nrespectively equations (21) and (22)  calculate ?\u0303?k using equation (23) end end\nOutput: Estimated mixing matrix ?\u0302? ."
        },
        {
            "heading": "5 Source Reconstruction",
            "text": "In [31] the sparsity-based method is introduced as an alternative to reconstruct the estimated source signal. Using a \u2113\ud835\udc5d-norm based-minimization measurement (the convergence is guarantee for 0 < \ud835\udc5d < 1), the method consists to convert the source reconstruction problem to a sparse\nreconstruction minimization problem. A designed iterative Lagrange multiplier approach with an appropriate initialization procedure is used to solve this minimization problem.\nThe source reconstruction is performed to find the sparsest term of \ud835\udc60\ud835\udc51. For this, the maximum posterior likelihood of \ud835\udc60\ud835\udc51 is given as the following equation max\ud835\udc60\ud835\udc51 \u220f\ud835\udc43(|\ud835\udc60\ud835\udc56,\ud835\udc51|)\ud835\udc41\ud835\udc56=1 \ud835\udc60. \ud835\udc61. \ud835\udc31\ud835\udc51 = ?\u0302?\ud835\udc60\ud835\udc51 (24) where the complex-valued super-Gaussian distribution \ud835\udc43(|\ud835\udc60\ud835\udc56,\ud835\udc51|) is given by the following equation: \ud835\udc43(|\ud835\udc60\ud835\udc56,\ud835\udc51|) = \ud835\udc5d \ud835\udefe1/\ud835\udc5d\u0393(1\ud835\udc5d) \ud835\udc52\u2212|\ud835\udc60\ud835\udc56,\ud835\udc51|\ud835\udc5d (25) where \ud835\udc5d and \ud835\udefe control shape and variance of the probability function. \u0393 denoted the gamma function. \ud835\udc07 design the estimated mixing matrix. The problem returns to solve the equivalent optimization problem given as follow:\nmin\ud835\udc60\ud835\udc51 \u2211|\ud835\udc60\ud835\udc56,\ud835\udc51|\ud835\udc5d\ud835\udc41\ud835\udc56=1 \ud835\udc60. \ud835\udc61. \ud835\udc31\ud835\udc51 = ?\u0302?\ud835\udc60\ud835\udc51 (26) The Lagrange multiplier method is introduced to solve the optimization problem. Hence, the problem is reformulated to an unconstrained optimization problem as follows:\nmin\ud835\udc60\ud835\udc51,\ud835\udefc \u2131(\ud835\udc60\ud835\udc51, \ud835\udefc) \u225c\u2211|\ud835\udc60\ud835\udc56,\ud835\udc51|\ud835\udc5d\ud835\udc41\ud835\udc56=1 + \ud835\udefc\ud835\udc3b(\ud835\udc31\ud835\udc51 \u2212 ?\u0302?\ud835\udc60\ud835\udc51) (27) where \ud835\udefc design the Lagrange multiplier. The problem implicit solution is given as follow: \ud835\udc60\ud835\udc51 = \u03a8\u22121( \ud835\udc60\ud835\udc51) ?\u0302?\ud835\udc3b (?\u0302? \u03a8\u22121(\ud835\udc60\ud835\udc51 )?\u0302?\ud835\udc3b )\u22121 \ud835\udc31\ud835\udc51 (28) where\n\u03a8\u22121( \ud835\udc60\ud835\udc51) \u225c [|\ud835\udc601,\ud835\udc51|2\u2212\ud835\udc5d \u22ef 0\u22ee \u22f1 \u22ee0 \u22ef |\ud835\udc60\ud835\udc41,\ud835\udc51|2\u2212\ud835\udc5d] The iterative scheme to obtain the solution \ud835\udc60\ud835\udc51 is given as follow:\n?\u0302?\ud835\udc51(\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f+1) = { \u03a8\u22121( ?\u0302?\ud835\udc51(\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f))?\u0302?\ud835\udc3b (?\u0302? \u03a8\u22121(?\u0302?\ud835\udc51(\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f))?\u0302?\ud835\udc3b )\u22121 \ud835\udc31\ud835\udc51 \ud835\udc56\ud835\udc53 \u2016?\u0302?\ud835\udc51(\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f)\u20160 \u2265 \ud835\udc40 \u03a8\u22121( ?\u0302?\ud835\udc51(\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f))?\u0302?\ud835\udc3b (?\u0302? (\u03a8\u22121( ?\u0302?\ud835\udc51(\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f)) + \ud835\udf16\ud835\udc08)\u22121 ?\u0302?\ud835\udc3b )\u22121 \ud835\udc31\ud835\udc51 \ud835\udc52\ud835\udc59\ud835\udc60\ud835\udc52\ud835\udc56\ud835\udc53 \u2016?\u0302?\ud835\udc51(\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f)\u2016 < \ud835\udc40 (29) The source reconstruction algorithm is summarized as the following steps Input : Time frequency presentation of observed signal denoted X whose element \ud835\udc31\ud835\udc51 and Estimated mixing matrix ?\u0302?\n For each frequency bin d  Initialize the sources a ?\u0302?\ud835\udc51(0) = \u2211 \ud835\udf14\ud835\udc57y\ud835\udc57,\ud835\udc51\ud835\udc36\ud835\udc41\ud835\udc40\ud835\udc57=1  Repeat  Update ?\u0302?\ud835\udc51(\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f) using equation 29  \ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f = \ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f + 1  Until \u2016?\u0302?\ud835\udc51(\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f)\u2016\ud835\udc5d\ud835\udc5d \u2212 \u2016?\u0302?\ud835\udc51(\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc5f+1)\u2016\ud835\udc5d\ud835\udc5d is less than a given threshold.  End\nOutput: time frequency presentation of estimated sources."
        },
        {
            "heading": "6 Result and discussion",
            "text": "In order to investigate the effectiveness of the proposed method, numerical simulations have\nbeen performed in reverberant environment. The TIMIT database [36] and NOIZEUS database [37] were used to build the speech dataset, which was chosen at random (available online). The\nsampling rate for the voice signals is \ud835\udc53\ud835\udc60 = 16 \ud835\udc58\ud835\udc3b\ud835\udc67, and the speakers might be either female or male. Using the technique outlined in [38], the propagation environment is simulated as a reverberant room shown by figure 1. The room impulse response from source \ud835\udc56 to sensor is illustrated by figure 2. By adjusting the reverberant time, a variety of convolutive mixed signals can be produced. It is crucial to evaluating the transmission duration of signal decay to 60 dB in order to reflect the room reverberation.\nThe spectrum of the observed signal is obtained by the STFT transformation; where the\nconvolution in the time domain is transformed into multiplication in the STFT domain. AMSWT approach is introduced to obtain an optimal spectral mode separation, by applying wavelet and variational scaling to each mode, the TF output with high time frequency resolution is produced, the following steps are given by algorithm 1. Thus, the SCBSS problem is transformed into a nonunderdetermined problem by establishing virtual multi-channel signals of the TF resolution of the\nobserved signals. Then, the \ud835\udc40 time-frequency presentation of the mixture is divided into \ud835\udc44 nonoverlapping blocks.\nAs a pre-processing step at the mixing matrix estimation stage, the TF resolution of the observed signal, for each frequency bin \ud835\udc31\ud835\udc51 is whitened. The whitening process is performed using the eigenvector matrix \ud835\udc14\ud835\udc31, and the eigenvalue matrix \ud835\udeba\ud835\udc31 of \ud835\udc38(\ud835\udc31\ud835\udc51\ud835\udc31\ud835\udc51\ud835\udc3b), and expressed by the following equation \ud835\udc31\ud835\udc51\ud835\udc64 = \ud835\udeba\ud835\udc31\u22121/2\ud835\udc14\ud835\udc31\ud835\udc3b\ud835\udc31\ud835\udc51. The estimation of the mixing matrix is reformulated into an eigenvector clustering issue. First, the local covariance matrices of mixture signal\u2019s rank-one structure was used to extract the\neigenvectors; Secondly, a density-based clustering technique was used to create clusters from these eigenvectors; Third, the clusters were modified using a lightweight clustering approach to produce the estimated mixing matrix, the steps are summarized by algorithm 2.\nThe ambiguity of scaling is solved by rescaling the estimated mixing matrix by restricting\nthe first row. The order of the reconstructed sources is aligned, by grouping the nearby source TF vectors based on their correlation, in terms of power ratio, in order to resolve the permutation ambiguity [31].\nThe post-processing stage involves de-whitening the predicted mixing matrix by ?\u0302? =\ud835\udc14x\ud835\udeba\ud835\udc311/2?\u0303?. Then, the source reconstruction is reformulated into a sparse minimization problem, whose solution was achieved using an initialization-corrected iterative Lagrange multiplier approach as\nsummarized in algorithm 3. The algorithm outputs are the TF resolution of the \ud835\udc41 estimated sources Finally, the estimated sources are obtained in TF resolution, which are transformed into time domain using the modified method proposed in [39]. The proposed method is summarized by the flowchart shown in figure 3.\nThe BSSeval toolbox [40] is used to analyze the performance of the proposed approach. The estimated sources are expressed as ?\u0302? = \ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc61 + \ud835\udc52\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc53 + \ud835\udc52\ud835\udc5b\ud835\udc5c\ud835\udc56\ud835\udc60\ud835\udc52 + \ud835\udc52\ud835\udc4e\ud835\udc5f\ud835\udc61\ud835\udc56\ud835\udc53 for the objective performance criteria measurement, where \ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc61 refers to the source signals, \ud835\udc52\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc53 stands for interference from other sources, \ud835\udc52\ud835\udc5b\ud835\udc5c\ud835\udc56\ud835\udc60\ud835\udc52 stands for distortion brought on by noise, and \ud835\udc52\ud835\udc4e\ud835\udc5f\ud835\udc61\ud835\udc56\ud835\udc53 includes all other artifacts introduced by the separation algorithm.\nIn [31] the parameter \ud835\udc5d plays a significant impact in source reconstruction performance. Many tests have been performed using different \ud835\udc5d value to assess the effect of SDRs using the given Dataset. The table displays the obtained SDRs with p parameters varying from 0.1 to 0.9.\nThe table presents the SDRs evaluation obtained via the proposed method using various value of p which characterizes the \u2113\ud835\udc5d-norm based-minimization measurement method, as can be seen, the SDR marginally increases as p increases and reaches its max when p = 0.7. For improved performance, the parameter p is set to 0.7 in the subsequent experiments. Changing the p parameter\nvalue to take advantage of the source sparsity prove that the sparse reconstruction based on \u2113\ud835\udc5d-norm based-minimization approach is a flexible framework.\nThe estimated sources performances are evaluated using the source-to-distortion ratio\n(SDR), the source-to-artifact ratio (SAR) and the source-to-interference ratio (SIR) criterions, and compared with the estimated sources performances obtained via VDM method [24], adaptive spectrum amplitude estimator and masking method [25] and the nonnegative tensor factorization of\nmodulation spectrograms method [32]. The SDR, SAR and SIR are defined by the following equation:\n\ud835\udc46\ud835\udc37\ud835\udc45 = 10 log10 \u2016\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc61\u20162\u2016\ud835\udc52\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc53 + \ud835\udc52\ud835\udc5b\ud835\udc5c\ud835\udc56\ud835\udc60\ud835\udc52 + \ud835\udc52\ud835\udc4e\ud835\udc5f\ud835\udc61\ud835\udc56\ud835\udc53\u20162 (30)\n\ud835\udc46\ud835\udc34\ud835\udc45 = 10 log10 \u2016\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc61 + \ud835\udc52\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc53 + \ud835\udc52\ud835\udc5b\ud835\udc5c\ud835\udc56\ud835\udc60\ud835\udc52\u20162\u2016\ud835\udc52\ud835\udc4e\ud835\udc5f\ud835\udc61\ud835\udc56\ud835\udc53\u20162 (31)\n\ud835\udc46\ud835\udc3c\ud835\udc45 = 10log10 \u2016\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc61\u20162\u2016\ud835\udc52\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc53\u20162 (32) The figure 4 presents a comparison evaluated by the mean square errors (MSEs) [26] between the original signal and the estimated sources obtained via the proposed method and the estimates sources obtained via VDM method [24], adaptive spectrum amplitude estimator and masking method [25] and the nonnegative tensor factorization of modulation spectrograms method [32]. The comparison has been performed for various reverberation conditions where the reverberation time is varied from 100 ms to 500 ms. As can be observed the proposed method provide in smaller MSE even highly reverberant environment.\nThe figures 5, 6 and 7 present respectively, a comparison in term of SDR, SAR and SIR\nbetween the estimated sources obtained via the proposed method, and the estimates sources via VDM method [24], adaptive spectrum amplitude estimator and masking method [25] and the nonnegative tensor factorization of modulation spectrograms method [32]. The comparison has been performed for various reverberation times where the reverberation time is varied from 100 ms to 500 ms.\nAs can be seen, the proposed method results in a better performance in terms of the three\nperformance criteria compared to VDM, the adaptive spectrum amplitude estimator and masking, and the nonnegative tensor factorization of modulation spectrograms methods in reverberant environment. The proposed method results in higher performance criteria even in highly reverberant environment."
        },
        {
            "heading": "7 Conclusion",
            "text": "A new method to solve the SCBSS problem has been presented. The method is combining\nthe adaptive mode separation-based wavelet transform with adaptive mode separation (AMSWT)\nand the density-based clustering with sparse reconstruction. The SCBSS problem is transformed\ninto a non-underdetermined. The method operates in the time-frequency domain and in reverberant\nenvironment. The proposed method has been tested on speech datasets constructed from TIMIT and\nNOIZEUS databases for various reverberation time conditions. The simulations results indicate the\nsmaller MSE criteria and the high values of SIR, SAR and SDR. The simulations results\ndemonstrate the effectiveness of the proposed method to solve the SCBSS problem even in highly\nreverberant environment"
        }
    ],
    "title": "Single-Channel Blind Source Separation using Adaptive Mode Separation- Based Wavelet Transform and Density-Based Clustering with Sparse Reconstruction",
    "year": 2022
}