{
    "abstractText": "End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios. Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jianguo Zhang"
        },
        {
            "affiliations": [],
            "name": "Stephen Roller"
        },
        {
            "affiliations": [],
            "name": "Kun Qian"
        },
        {
            "affiliations": [],
            "name": "Zhiwei Liu"
        },
        {
            "affiliations": [],
            "name": "Rui Meng"
        },
        {
            "affiliations": [],
            "name": "Shelby Heinecke"
        },
        {
            "affiliations": [],
            "name": "Huan Wang"
        },
        {
            "affiliations": [],
            "name": "Silvio Savarese"
        },
        {
            "affiliations": [],
            "name": "Caiming Xiong"
        }
    ],
    "id": "SP:c5f36c15ef2c6893cddb987e337ba1406d8c9863",
    "references": [
        {
            "authors": [
                "Namo Bang",
                "Jeehyun Lee",
                "Myoung-Wan Koo."
            ],
            "title": "Task-optimized adapters for an end-to-end task-oriented dialogue system",
            "venue": "ACL Findings.",
            "year": 2023
        },
        {
            "authors": [
                "Pawe\u0142 Budzianowski",
                "Tsung-Hsien Wen",
                "Bo-Hsiang Tseng",
                "Inigo Casanueva",
                "Stefan Ultes",
                "Osman Ramadan",
                "Milica Ga\u0161i\u0107."
            ],
            "title": "Multiwoz\u2013a largescale multi-domain wizard-of-oz dataset for taskoriented dialogue modelling",
            "venue": "EMNLP.",
            "year": 2018
        },
        {
            "authors": [
                "Moya Chen",
                "Paul A Crook",
                "Stephen Roller."
            ],
            "title": "Teaching models new apis: Domain-agnostic simulators for task oriented dialogue",
            "venue": "arXiv preprint arXiv:2110.06905.",
            "year": 2021
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "venue": "NAACL-HLT, pages 4171\u20134186.",
            "year": 2019
        },
        {
            "authors": [
                "Emily Dinan",
                "Stephen Roller",
                "Kurt Shuster",
                "Angela Fan",
                "Michael Auli",
                "Jason Weston."
            ],
            "title": "Wizard of wikipedia: Knowledge-powered conversational agents",
            "venue": "arXiv preprint arXiv:1811.01241.",
            "year": 2018
        },
        {
            "authors": [
                "Yihao Feng",
                "Shentao Yang",
                "Shujian Zhang",
                "Jianguo Zhang",
                "Caiming Xiong",
                "Mingyuan Zhou",
                "Huan Wang."
            ],
            "title": "Fantastic rewards and how to tame them: A case study on reward learning for task-oriented dialogue systems",
            "venue": "ICLR.",
            "year": 2023
        },
        {
            "authors": [
                "Jianfeng Gao",
                "Michel Galley",
                "Lihong Li."
            ],
            "title": "Neural approaches to conversational ai",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts, pages 2\u20137.",
            "year": 2018
        },
        {
            "authors": [
                "Silin Gao",
                "Ryuichi Takanobu",
                "Wei Peng",
                "Qun Liu",
                "Minlie Huang."
            ],
            "title": "Hyknow: End-to-end taskoriented dialog modeling with hybrid knowledge management",
            "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages",
            "year": 2021
        },
        {
            "authors": [
                "Donghoon Ham",
                "Jeong-Gwan Lee",
                "Youngsoo Jang",
                "Kee-Eung Kim."
            ],
            "title": "End-to-end neural pipeline for goal-oriented dialogue systems using gpt-2",
            "venue": "ACL, pages 583\u2013592.",
            "year": 2020
        },
        {
            "authors": [
                "Wanwei He",
                "Yinpei Dai",
                "Min Yang",
                "Jian Sun",
                "Fei Huang",
                "Luo Si",
                "Yongbin Li."
            ],
            "title": "Unified dialog model pre-training for task-oriented dialog understanding and generation",
            "venue": "SIGIR, pages 187\u2013200.",
            "year": 2022
        },
        {
            "authors": [
                "Wanwei He",
                "Yinpei Dai",
                "Yinhe Zheng",
                "Yuchuan Wu",
                "Zheng Cao",
                "Dermot Liu",
                "Peng Jiang",
                "Min Yang",
                "Fei Huang",
                "Luo Si"
            ],
            "title": "Galaxy: A generative pre-trained model for task-oriented dialog with semi-supervised learning and explicit policy injec",
            "year": 2022
        },
        {
            "authors": [
                "Ehsan Hosseini-Asl",
                "Bryan McCann",
                "Chien-Sheng Wu",
                "Semih Yavuz",
                "Richard Socher."
            ],
            "title": "A simple language model for task-oriented dialogue",
            "venue": "NeurIPS, 33:20179\u201320191.",
            "year": 2020
        },
        {
            "authors": [
                "Gautier Izacard",
                "Edouard Grave."
            ],
            "title": "Leveraging passage retrieval with generative models for open domain question answering",
            "venue": "EACL.",
            "year": 2021
        },
        {
            "authors": [
                "Vladimir Karpukhin",
                "Barlas Oguz",
                "Sewon Min",
                "Patrick Lewis",
                "Ledell Wu",
                "Sergey Edunov",
                "Danqi Chen",
                "Wen-tau Yih."
            ],
            "title": "Dense passage retrieval for opendomain question answering",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural",
            "year": 2020
        },
        {
            "authors": [
                "Mojtaba Komeili",
                "Kurt Shuster",
                "Jason Weston."
            ],
            "title": "Internet-augmented dialogue generation",
            "venue": "arXiv preprint arXiv:2107.07566.",
            "year": 2021
        },
        {
            "authors": [
                "Harrison Lee",
                "Raghav Gupta",
                "Abhinav Rastogi",
                "Yuan Cao",
                "Bin Zhang",
                "Yonghui Wu."
            ],
            "title": "Sgd-x: A benchmark for robust generalization in schemaguided dialogue systems",
            "venue": "AAAI, volume 36, pages 10938\u201310946.",
            "year": 2022
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Veselin Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "2020a. Bart: Denoising sequence-to-sequence pre-training for natural language",
            "year": 2020
        },
        {
            "authors": [
                "Patrick Lewis",
                "Ethan Perez",
                "Aleksandra Piktus",
                "Fabio Petroni",
                "Vladimir Karpukhin",
                "Naman Goyal",
                "Heinrich K\u00fcttler",
                "Mike Lewis",
                "Wen-tau Yih",
                "Tim Rockt\u00e4schel"
            ],
            "title": "Retrieval-augmented generation for knowledge-intensive nlp",
            "year": 2020
        },
        {
            "authors": [
                "Zhaojiang Lin",
                "Andrea Madotto",
                "Genta Indra Winata",
                "Pascale Fung."
            ],
            "title": "Mintl: Minimalist transfer learning for task-oriented dialogue systems",
            "venue": "EMNLP, pages 3391\u20133405.",
            "year": 2020
        },
        {
            "authors": [
                "Qi Liu",
                "Lei Yu",
                "Laura Rimell",
                "Phil Blunsom."
            ],
            "title": "Pretraining the noisy channel model for task-oriented dialogue",
            "venue": "Transactions of the Association for Computational Linguistics, 9:657\u2013674.",
            "year": 2021
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311\u2013318.",
            "year": 2002
        },
        {
            "authors": [
                "Baolin Peng",
                "Chunyuan Li",
                "Jinchao Li",
                "Shahin Shayandeh",
                "Lars Liden",
                "Jianfeng Gao."
            ],
            "title": "Soloist: Buildingtask bots at scale with transfer learning and machine teaching",
            "venue": "Transactions of the Association for Computational Linguistics, 9:807\u2013824.",
            "year": 2021
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J Liu"
            ],
            "title": "Exploring the limits",
            "year": 2019
        },
        {
            "authors": [
                "Abhinav Rastogi",
                "Xiaoxue Zang",
                "Srinivas Sunkara",
                "Raghav Gupta",
                "Pranav Khaitan."
            ],
            "title": "Schemaguided dialogue state tracking task at dstc8",
            "venue": "arXiv preprint arXiv:2002.01359.",
            "year": 2020
        },
        {
            "authors": [
                "Abhinav Rastogi",
                "Xiaoxue Zang",
                "Srinivas Sunkara",
                "Raghav Gupta",
                "Pranav Khaitan."
            ],
            "title": "Towards Scalable Multi-domain Conversational Agents: The Schema-Guided Dialogue Dataset",
            "venue": "AAAI.",
            "year": 2020
        },
        {
            "authors": [
                "Abhinav Rastogi",
                "Xiaoxue Zang",
                "Srinivas Sunkara",
                "Raghav Gupta",
                "Pranav Khaitan."
            ],
            "title": "Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, vol-",
            "year": 2020
        },
        {
            "authors": [
                "Kurt Shuster",
                "Spencer Poff",
                "Moya Chen",
                "Douwe Kiela",
                "Jason Weston."
            ],
            "title": "Retrieval augmentation reduces hallucination in conversation",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3784\u20133803.",
            "year": 2021
        },
        {
            "authors": [
                "Yixuan Su",
                "Lei Shu",
                "Elman Mansimov",
                "Arshit Gupta",
                "Deng Cai",
                "Yi-An Lai",
                "Yi Zhang."
            ],
            "title": "Multi-task pre-training for plug-and-play task-oriented dialogue system",
            "venue": "arXiv preprint arXiv:2109.14739.",
            "year": 2021
        },
        {
            "authors": [
                "Tian Xie",
                "Xinyi Yang",
                "Angela S Lin",
                "Feihong Wu",
                "Kazuma Hashimoto",
                "Jin Qu",
                "Young Mo Kang",
                "Wenpeng Yin",
                "Huan Wang",
                "Semih Yavuz"
            ],
            "title": "Converse\u2013a tree-based modular task-oriented dialogue system",
            "venue": "arXiv preprint arXiv:2203.12187",
            "year": 2022
        },
        {
            "authors": [
                "Yunyi Yang",
                "Yunhao Li",
                "Xiaojun Quan."
            ],
            "title": "Ubar: Towards fully end-to-end task-oriented dialog systems with gpt-2",
            "venue": "AAAI.",
            "year": 2021
        },
        {
            "authors": [
                "Xiaoxue Zang",
                "Abhinav Rastogi",
                "Srinivas Sunkara",
                "Raghav Gupta",
                "Jianguo Zhang",
                "Jindong Chen"
            ],
            "title": "Multiwoz 2.2: A dialogue dataset with additional annotation corrections and state tracking baselines",
            "venue": "In Proceedings of the 2nd Workshop on Natural",
            "year": 2020
        },
        {
            "authors": [
                "Jianguo Zhang",
                "Kazuma Hashimoto",
                "Chien-Sheng Wu",
                "Yao Wang",
                "S Yu Philip",
                "Richard Socher",
                "Caiming Xiong."
            ],
            "title": "Find or classify? dual strategy for slot-value predictions on multi-domain dialog state tracking",
            "venue": "Proceedings of the Ninth Joint Confer-",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Task-oriented dialogue (TOD) systems play an important role in various applications, such as restaurant booking, alarm setting, and recommendations (Gao et al., 2018; Xie et al., 2022). These systems can be broadly categorized into two groups: pipeline-based dialogue systems and end-to-end dialogue systems. Pipeline-based dialogue systems consist of four separate modules: a natural language understanding (NLU) module to detect user intents, a dialogue state tracking (DST) module to track user belief states across dialogue turns, a dialogue management (DM) module to decide system actions based on dialogue states, and a natural language generation (NLG) module to generate\n1This work was partially conducted during Jianguo\u2019s internship and Stephen\u2019s full-time employment at Meta AI Research (FAIR).\nnatural-language responses. However, the pipelinebased approach is annotation-intensive, prone to error propagation, and challenging to scale (HosseiniAsl et al., 2020; Zhang et al., 2020; Feng et al., 2023).\nRecently, various approaches have been proposed to utilize sequence-to-sequence models for generating dialogue states and responses in an endto-end manner (Ham et al., 2020; Lin et al., 2020; Yang et al., 2021; Gao et al., 2021; Chen et al., 2021; Peng et al., 2021; Liu et al., 2021; He et al., 2022b; Feng et al., 2023). Compared with the pipeline-based systems, these approaches demonstrate effectiveness on public datasets requiring fewer direct annotations, such as user intents and dialogue acts. Additionally, they leverage the capabilities of large-scale pre-trained language models, such as GPT-2 (Radford et al., 2019), T5 (Raffel et al., 2019), and BART (Lewis et al., 2020a), for improved performance in NLU and NLG tasks. However, these approaches are limited in their ability to dynamically handle both existing and emergar X iv :2\n30 8.\n08 16\n9v 1\n[ cs\n.C L\n] 1\n6 A\nug 2\n02 3\ning intents and slots, particularly in the context of unseen dialogue scenarios such as new domains and services (Hosseini-Asl et al., 2020; Peng et al., 2021; Rastogi et al., 2020a).\nSimultaneously, research on open-domain question answering and dialogue systems has explored the use of retrieval-augmented models. These models retrieve relevant information from a passage, database, APIs, etc., and incorporate it into the generation process, improving answer quality or dialogue responses (Karpukhin et al., 2020; Izacard and Grave, 2021; Dinan et al., 2018; Lewis et al., 2020b; Shuster et al., 2021). Inspired by these ideas, we combine both worlds and propose an end-to-end TOD framework with a retrieval system that addresses the challenge of handling both existing and zero-shot unseen dialogue scenarios.\nOur approach involves training the end-to-end TOD models with a cache that contains accessible domains, intents, slots, and APIs. The cache can be constructed based on the schema or database, or by extracting information from accessible dialogues when the schema or database is not fully accessible. The cache serves as a reference point, allowing the models to ground their responses in the retrieved information. By incorporating a retrieval module and leveraging this cache of knowledge, our system enhances the flexibility and adaptability to handle both existing and unseen intents and slots. It also ensures robust performance in novel dialogue domains and services where the model hasn\u2019t been explicitly trained. Figure 1 shows an illustrative example of our approach, demonstrating how the RETRIEVAL module retrieves relevant information, such as slots in this case, from the cache to enrich the system\u2019s understanding and generate more accurate responses. The APICALL represents the dialogue states from the system side, and APIRESP returns information from external API interactions between the system and system databases.\nTo build an accurate end-to-end TOD system with the benefits of a simple cache, we fine-tune a retrieval module to effectively retrieve the most relevant and informative information from the cache, using a Top-N retrieval strategy. Then we integrate the retrieval module into the generative model to facilitate end-to-end TOD generation. We evaluate our approach on the publicly available Google Schema-Guided Dialogue dataset (SGD) (Rastogi et al., 2020b), which includes a significant number of unseen dialogue domains and services in the\ndevelopment and test sets.\nThe contributions of this paper are as follows: (1) We design a simple yet effective end-to-end TOD framework with a cache that enables dynamic handling of intents and slots. The framework is compatible with existing pre-trained generative models, and enhances the system\u2019s robustness. (2) We provide experimental results that demonstrate the superior performance of our approach compared to strong baselines. It achieves 6.7% improvement in non-empty joint goal accuracy, demonstrating the effectiveness in handling various dialogue scenarios, including the challenging zero-shot unseen dialogues. (3) We conduct comprehensive ablation studies and analyses to provide insights into the impact of different components and design choices within our framework."
        },
        {
            "heading": "2 Related Work",
            "text": "End-to-End TOD Systems End-to-end TOD models have shown promising performance on public dataset (Ham et al., 2020; Lin et al., 2020; Yang et al., 2021; Gao et al., 2021; Chen et al., 2021; Peng et al., 2021; Liu et al., 2021; He et al., 2022a,b; Feng et al., 2023; Bang et al., 2023). These approaches typically follow common patterns: (1) Rely on powerful pre-trained seq2seq models. (2) Use language modeling objectives to generate NLU and NLG outputs, sometimes augmented with auxiliary multi-task goals like DST loss. (3) Either fine-tune models directly on the target dataset or conduct pre-training on multiple TOD dialogue datasets. (4) Employ data augmentation techniques such as back-translation and entity replacement due to the challenges in collecting large-scale TOD corpora. For example, HosseiniAsl et al. (2020) fine-tunes DistilGPT2 for TOD. The model generates user belief states and system responses in an auto-regressive way. Peng et al. (2021) introduces two auxiliary tasks for belief state prediction and grounded response generation and pre-train language models first on multitple TOD dataset. Gao et al. (2021) enables the belief state to interact with both structured and unstructured knowledge. Feng et al. (2023) designs a reward-function learning objective to guide the model\u2019s generation. While these methods have demonstrated effectiveness on public datasets, they have limitations in handling unseen dialogue scenarios such as unseen domains and services.\nRetrieval-Augmented Models Retrieval augmented approaches have been widely used in open-domain question answering. For instance, Karpukhin et al. (2020) proposes a BERTbased (Devlin et al., 2019) dual-encoder framework to retrieve passages from Wikipedia, which is further incorporated into open-domain conversations to reduce hallucination and enrich engagement with users (Shuster et al., 2021; Komeili et al., 2021). These models retrieve information related to the query from a knowledge base of sentences and ground the generation response on this information (Dinan et al., 2018; Lewis et al., 2020b). Inspired by these works, we explore the integration of retrieval modules into end-to-end TOD systems, leveraging the retrieval-augmented approach to enhance the system\u2019s performance in handling both existing and novel dialogue scenarios."
        },
        {
            "heading": "3 TOD Systems with a Simple Cache",
            "text": "We present an end-to-end transformer-based framework with a simple cache that is compatible with multiple generative models, including BART, T5, GPT2, etc. Our framework enables dynamic handling of intents, slots, and APIs while maintaining flexibility in choosing the backbone model.\nGenerally, our framework consists of two parts: a retrieval model for retrieving the most relevant and informative information from the cache, and an end-to-end TOD model that generates APICALLs and system responses based on the dialogue history and the retrieved information. The retrieval model functions by retrieving intents, slots, APIs, and other relevant information from the cache.\nFigure 2 illustrates one simple variant of our framework, which is an encoder-decoder architecture. In this variant, the retrieved information such as slots are stacked together. We also introduce another variant in Sec. 4.2, where each retrieved information is concatenated with the dialogue history and then all the information are concatenated together before being sent to the decoder."
        },
        {
            "heading": "3.1 Construction of Cache",
            "text": "In this section, we describe the construction of a simple cache that provides necessary information for the model\u2019s referencing and grounding procedure. The cache consists of intents, slots, and APIs extracted from the schema and database. In cases where the schema or database is not fully accessible, we extract information from accessible dia-\nlogues. During training, it is important to note that the cache exclusively contains information relevant to the training dialogues and does not incorporate any unseen information of dialogues in the test set.\nSince there are different ways to construct a cache, we design various templates to formalize the retrieved information. Table 1 presents several templates that we utilize. One example is the \u201cAPIinformation\u201d template, where an API includes all the intents and relevant slots mentioned throughout the whole dialogue. Although this template may contain redundant information as some intents and slots may not be mentioned initially, it allows us to evaluate the model\u2019s ability to disregard irrelevant details.\nIn addition to the listed templates, we explore several other templates with special tokens such as \u201c[INTENT] intent name [SLOT] slot name\u201d, as well as different orderings of intents and slots, such as \u201cintent name, intent description, slot name, slot description\u201d and \u201cintent name, slot name, intent description, slot description\u201d. We conduct an indepth analysis of the effects of different cache templates in the experimental section."
        },
        {
            "heading": "3.2 Retrieval Module",
            "text": "After constructing the cache, we fine-tune a retrieval model to effectively retrieve the most relevant and informative information for the dialogue context. Given a dialogue history c, the TOD system utilizes a retrieval module to retrieve TopN most relevant information s1, . . . , sN from the cache. Firstly, based on the dialogue history, the system triggers the retrieval module to generate an APICALL, which includes relevant mentioned intents, slots and values. Subsequently, the system continues to use the retrieval module to generate a system response based on all previous information.\nTo ensure accurate retrieval from the cache, we fine-tune a dense passage retriever (DPR) model (Karpukhin et al., 2020), which is a BERTbased dual-encoder framework optimized via contrastive learning. Specifically, we obtain the hidden representation hc for the dialogue history using an encoder model, e.g., hc = BERTc(c). Similarly, we use another BERT encoder to obtain the feature representation hs for each retrieved information entry from the cache, i.e., hs = BERTs(s). The similarity between the dialogue history and the retrieved information entry is: sim(c, s) = hTc \u2299 hs.\nFor each dialogue history, there are n relevant\n(positive) entries and m irrelevant (negative) entries, where n and m may vary as each dialogue history would contain different active intents and slots. Our objective is to learn a function that minimizes the distance between pairs of relevant dialogue histories and information entries than the irrelevant pairs. The corresponding loss function for a specific pair is as follows:\nLapi(c, s + 1 , s \u2212 1 , . . . , s \u2212 m) = \u2212 log exp(sim(hc,hs+1 ))\u2211m\nj=1 exp(sim(hc,hs\u2212j ))\n.\n(1)\nOnce the retrieval module is fine-tuned, it is incorporated into the end-to-end sequence-tosequence task-oriented dialogue generative model. The parameters of the retrieval module remain fixed during training of the generative model.\nNegative Sampling In the training process, we employ negative sampling to include retrieved information entries that are irrelevant to the dialogue history. We utilize both natural and hard negative pairs to enhance the robustness and performance of the retrieval module.\nFor natural negative pairs, we consider pairs such as \u201cirrelevant intent, irrelevant slots\u201d as counterparts to the positive pairs of \u201crelevant intent, rele-\nvant slots\u201d. Additionally, we construct hard negative pairs that pose a more challenge to the retrieval module. These hard negative pairs include combinations such as \u201crelevant intent, irrelevant slots from the same relevant intent\u201d and \u201cirrelevant intents that are semantically similar to the relevant intent, along with relevant slots from the relevant intent\u201d. By incorporating these hard negative pairs, we encourage the retrieval module to learn to differentiate between relevant and irrelevant information effectively."
        },
        {
            "heading": "3.3 End-to-End TOD Systems",
            "text": "Our end-to-end TOD framework generates the APICALL and system response in an auto-regressive manner. Figure 1 provides an example of this process. The APICALL represents the dialogue states from the system side, and same with previous work (Hosseini-Asl et al., 2020; Peng et al., 2021), it is an intermediate step of the system response generation, and they share the same model framework to generate tokens autoregressively.\nFor each dialogue turn, the TOD framework triggers the retrieval module twice. The system first retrieves the Top-N information entries from the\nconstructed cache, i.e.,\nTop-N info = Retrieval(c) . (2)\nThen it generates an APICALL using the retrieved information, i.e.,\nAPICALL = TOD(c,Top-N info) . (3)\nAfter that the TOD framework retrieves another set of Top-N information entries from the cache, considering the generated APICALL, i.e.,\nTop-N info = Retrieval(c,APICALL,APIRESP) , (4)\nwhere APIRESP is automatically obtained from corresponding API, without the need for prediction.\nFinally, the system generates a system response using the following inputs:\nResponse = TOD(c, APICALL, APIRESP, Top-N slots) . (5)"
        },
        {
            "heading": "4 Experimental Settings",
            "text": ""
        },
        {
            "heading": "4.1 Dataset",
            "text": "A substantial number of end-to-end TOD works (Hosseini-Asl et al., 2020; Peng et al., 2021; Lin et al., 2020; Yang et al., 2021; Su et al., 2021; He et al., 2022b; Feng et al., 2023) commonly employ the MultiWOZ datasets (Budzianowski et al., 2018; Zang et al., 2020). However, these studies primarily focus on full-shot and few-shot learning, and the scope for zero-shot evaluation appears somewhat constrained given that MultiWOZ only has five domains and approximately 35 slots, all of them are presented in the training set. In contrast, our work aims to assess the system across large-scale multi-domain dialogue scenarios. We utilize the Google Schema-Guided Dialogue (SGD) dataset (Rastogi et al., 2020c). 1 SGD provides a more expansive dialogue landscape with over 16,000 multi-domain conversations that span more than 16 domains, 26 services, and 200 slots. Notably, the SGD includes a significant number of unseen domains/APIs in both the development and test sets, thereby increasing the complexity and diversity of the dataset. A substantial 45% of the dialogue turns in the development set, and a significant 77% of the dialogue turns in the test set, incorporate at least one service not included in the training set. Table 2 summarizes the statistics of SGD.\n1SGD processed dataset."
        },
        {
            "heading": "4.2 Models",
            "text": "In term of baselines, we adopt (Lin et al., 2020; Chen et al., 2021) and implement their model MinTL (BART-Large). We also implement T5DST from (Lee et al., 2022), which achieves strong performance on MultiWOZ 2.2 (Zang et al., 2020). Since our end-to-end TOD framework is compatible with existing pre-trained generative models, we experiment with BART, GPT2 and T5. Interestingly, we found that BART-Large (406M) perform comparably with T5-Large (770M), despite having fewer parameters. Moreover, it outperformed many models developed by teams in DSTC8 (Rastogi et al., 2020a), where the majority of models are BERT-based classification models. Thus, we select BART-Large as our primary backbone model.\nInspired by previous model designs in opendomain question answering (Lewis et al., 2020b; Izacard and Grave, 2021), we design two variants for end-to-end TOD systems. The first, named Fusion-in-Decoder TOD (FiD-TOD), is illustrated in Figure 2, In this model, the retrieved information such as slots, are stacked together. Notably, when the retrieval model is not incorporated, FiD-TOD becomes identical to MinTL (BART-Large). The second variant FiD-TOD-NoStack, is depicted in Figure 3 and is used as ablation study. In this model, the retrieved information is not directly stacked, and instead, the dialogue history is concatenated with each retrieved information entry and then sent to the shared encoder.\nRegarding the generative model, we truncate the tokens of dialogue history to 256, and retrieve Top5 most relevant information entries from the cache, unless otherwise specified. For DPR fine-tuning, we align one hard negative pair to each positive pair. We employ the preset hyperparameters from the ParLAI code, 2 such as setting the learning rate to 5e-5, batch size to 32, etc. Initially, we conducted experiments with slight alterations in hyperparameters and observed no statistically significant difference on performance. We selected the best model based on its performance on the\n2ParLAI platform.\ndevelopment set. The retrieve model is fine-tuned up to 3 epochs based on open-sourced DPR (Karpukhin et al., 2020), and the generative model is fine-tuned up to 4 epochs with an overall batch size of 64 on 8 Nvidia Tesla V100 GPUs. All experiments are based on public code from the ParLAI platform."
        },
        {
            "heading": "4.3 Evaluation Metrics",
            "text": "We evaluate the end-en-end TOD framework using the following ParLAI metrics: (1) Top-N accuracy: It evaluates the retrieval module through checking whether the ground-truth slot appears in the TopN predicted candidates (Karpukhin et al., 2020). (2) Joint Goal Accuracy (Overall JGA): It evaluates whether the predicted APICALL on both seen and unseen services is correct or not, specifically. JGA is 1 if the model correctly predicts all intent, slots and corresponding values in the APICALL. Otherwise, JGA is 0. (3) Non-Empty JGA: It evaluates whether overall JGA is correct if the model calls the API on both seen and unseen scenarios. In SGD, most dialogue turns would not trigger an API\nretrieval, resulting in empty APICALLs, and identifying Empty JGA is relatively quite easy (Chen et al., 2021). Moreover, most services, intents and slots in the test set are unseen. Therefore, we focus on Non-Empty APICALL turns and treat it as the most crucial metric for evaluating the model\u2019s performance on both seen scenarios and its zeroshot generalization ability on unseen scenarios. (4) Token EM: It evaluates the utterance-level token accuracy. Roughly corresponds to perfection under greedy search (generative only). (5) Perplexity (PPL): It measures the generative model\u2019s ability to predict individual tokens. (6) BLEU-4: It measures the BLEU score (Papineni et al., 2002) between the predicted system response and the reference response."
        },
        {
            "heading": "5 Experimental Results",
            "text": ""
        },
        {
            "heading": "5.1 End-to-End TOD Performance",
            "text": "Table 3 shows the overall performance on the test set. FiD-TOD outperforms baselines across most metrics. Specifically, it improves the essential NLU metric, i.e., Non-Empty JGA, by 6.7%. This demonstrates the model\u2019s enhanced capability in handling both seen dialogue scenarios and, notably, its capacity for zero-shot handling of unseen scenarios. As MinT (BART-Large) corresponds to the FiD-TOD without the retrieval model from the cache, this comparison highlights the significant benefits that our design brings to the handling of unseen dialogs. Additionally, the other metrics related to NLG are also slightly improved."
        },
        {
            "heading": "5.2 Retrieval Performance",
            "text": "We hope the model can generalize well as there could be many new intents and slots in real world.\nGeneral As shown in Table 4, our model shows effective Top-5 retrieval accuracy on the test set, keeping in mind that more than half of the services and slots are unseen in this set. The model shows good Top-1 accuracy and above 96% Top-5 accuracy, demonstrating strong abilities for handling both seen and unseen intents and slots. Compared to only using names, adding related service and intent descriptions improves the Top-1 accuracy by more than 5%. This suggests that incorporating descriptions can enhance the model\u2019s ability to generalize to unseen dialogue scenarios.\nAPI-information When evaluating the \u201cAPIinformation\u201d, where a single API entry in the cache encompasses all intents and slots information for the whole dialogue. We see that the model has high Top-1 accuracy and Top-5 accuracy. This suggests that the model has a high potential to retrieve all the related intents and slots information with a single retrieval attempt.\nOrders and Special Tokens We test with different templates, such as switching orders of intents and slots, and find no significant differences. We also find that adding the special tokens \u201cINTENT\u201d and \u201cSLOT\u201d slightly decreases the Top-1 accuracy.\nNegative Sampling Experiments with both normal and hard negative pairs, including varying numbers of hard negative pairs, showed no significant impact on retrieval performance. This could be attributed to the fact that, unlike longer passages\nin question answering, dialogue intents, slots, and APIs are generally easier to distinguish when they are referenced in the dialogue context."
        },
        {
            "heading": "5.3 Performance of Variants of Cache on End-to-End TOD",
            "text": "As our design involves several templates for the cache, we aim to assess the impact of various cache templates on the performance of the end-to-end TOD system. Table 5 shows that FiD-TOD using only names already outperforms MinT (BARTLarge), and adding descriptions further improves the performance. For instance, FiD-TOD with cache template \u201cINTENT: intent name, service description, intent description, SLOT: slot name, slot description\u201d surpassess both MinT (BART-Large) and FiD-TOD with cache template \u201cINTENT: intent name, SLOT: slot name\u201d by 7.4% and 2.7% in terms of Non-Empty JGA, respectively.\nInfluence of Irrelevant Information on the Endto-End TOD Given the potential emergence of unseen intents and slots in real-world scenarios, it is challenging to expect a perfect retrieval module.\nIn this section, we first investigate the ability of the TOD to ignore irrelevant retrieved information. In this section, we first investigate \u201cthe TOD\u2019s ability in learning to ignore irrelevant retrieved information\u201d. Table 6 shows the corresponding results. As described in Sec 3.1, API-information includes all intents and slots for the whole dialogue. The retrieval module exhibits an 84.4% Top-1 accuracy in retrieving all slot information in a single attempt, as shown in Table 4. However, when setting N to 5, the retriever returns similar yet irrelevant information despite a near 100% Top-5 recall accuracy.\nThis results in the inclusion of lots of irrelevant intents and slots into the generative model. Interestingly, \u201cAPI-information (N=1)\u201d performs similar to \u201cAPI-information (N=5)\u201d, suggesting that the TOD is capable of learning to ignore irrelevant retrieved information.\nSecond, we investigate \u201cif the TOD generator relies more on the retriever when all retrieved information entries are stacked together\u201d. In pursuit of this objective, we compare FiD-TOD and FiDTOD-NoStack, with the difference being whether the retrieved information entries are handled collectively or separately. As shown in Row 3 of Table 6, FiD-TOD-NoStack performs slightly worse when not stacking all retrieved information directly with a single dialogue context. This could be attributed to the design of FiD-TOD-NoStack, which results in repeated dialogue context during each retrieval attempt and may hinder the retrieved information.\nError Analysis Despite the retrieval module demonstrating relatively high Top-5 accuracy, there is still room for improvement in the Joint Goal Accuracy (JGA). Therefore, we examine potential reasons for this discrepancy. Table 7 shows one most frequently appeared error type, where the retrieval module successfully retrieve Top-5 information entries from the cache. In terms of APICALL prediction, the TOD accurately generates the intent and associated values. Among the generated slots,\u201ccity\u201d and \u201cparty size\u201d are semantically similar to \u201clocation\u201d and \u201cnumber of seats\u201d, respectively. However, the two generated slots are incor-\nrect as they belongs to different services. Upon further inspection, we find these terms are from the training cache. This suggests that the TOD generator does not completely rely on the retriever, and it tends to memorize the training slot information entries from the training cache, pointing towards the need for better generalized abilities. Furthermore, approximately 20% dialogue turns on the developments set shows this issue, suggesting a huge space to improve the performance. We hypothesize that data augmentation, such as entity replacements in dialogue history, could be one possible way to mitigate this problem. We leave further exploration of this issue to future work."
        },
        {
            "heading": "6 Conclusion",
            "text": "This paper aims to enhance the performance of end-to-end TOD systems by incorporating a simple cache. We begin by constructing a simple cache containing intents and slots. Subsequently, we finetune a retrieval module to extract the most relevant information entries. Next, we train the end-to-end TOD model, enabling it to reference and ground both the dialogue history and the retrieved information during TOD generation. Experimental results, based on a large-scale SGD dataset, demonstrate that our approach outperforms strong baselines."
        },
        {
            "heading": "7 Acknowledgements",
            "text": "We extend our gratitude to Moya Chen, Paul A. Crook, and Hu Xu for their insightful discussions. Additionally, we appreciate the valuable feedback provided by our anonymous reviewers."
        }
    ],
    "title": "Enhancing Performance on Seen and Unseen Dialogue Scenarios using Retrieval-Augmented End-to-End Task-Oriented System",
    "year": 2023
}