{
    "abstractText": "Recent approaches to causal inference have focused on causal effects defined as contrasts between the distribution of counterfactual outcomes under hypothetical interventions on the nodes of a graphical model. In this article we develop theory for causal effects defined with respect to a different type of intervention, one which alters the information propagated through the edges of the graph. These information transfer interventions may be more useful than node interventions in settings in which causes are non-manipulable, for example when considering race or genetics as a causal agent. Furthermore, information transfer interventions allow us to define path-specific decompositions which are identified in the presence of treatment-induced mediator-outcome confounding, a practical problem whose general solution remains elusive. We prove that the proposed effects provide valid statistical tests of mechanisms, unlike popular methods based on randomized interventions on the mediator. We propose efficient non-parametric estimators for a covariance version of the proposed effects, using data-adaptive regression coupled with semi-parametric efficiency theory to address model misspecification bias while retaining \u221a n-consistency and asymp*corresponding author: ivan.diaz@nyu.edu",
    "authors": [],
    "id": "SP:979a7e330d058e56723636b3388f399655f33335",
    "references": [],
    "sections": [
        {
            "text": "ar X\niv :2\n20 5.\n08 00\n0v 4\nRecent approaches to causal inference have focused on causal effects defined as contrasts between the distribution of counterfactual outcomes under hypothetical interventions on the nodes of a graphical model. In this article we develop theory for causal effects defined with respect to a different type of intervention, one which alters the information propagated through the edges of the graph. These information transfer interventions may be more useful than node interventions in settings in which causes are non-manipulable, for example when considering race or genetics as a causal agent. Furthermore, information transfer interventions allow us to define path-specific decompositions which are identified in the presence of treatment-induced mediator-outcome confounding, a practical problem whose general solution remains elusive. We prove that the proposed effects provide valid statistical tests of mechanisms, unlike popular methods based on randomized interventions on the mediator. We propose efficient non-parametric estimators for a covariance version of the proposed effects, using data-adaptive regression coupled with semi-parametric efficiency theory to address model misspecification bias while retaining \u221a n-consistency and asymp-\n*corresponding author: ivan.diaz@nyu.edu\ntotic normality. We illustrate the use of our methods in two examples using publicly available data."
        },
        {
            "heading": "1 Introduction",
            "text": "Statistical causal inference is primarily concerned with quantifying the strength of causal relations through so-called causal effects, which are defined as contrasts between distributions under hypothetical modifications to the data generating mechanisms. These hypothetical modifications are often called interventions, and the variables resulting from the interventions are often called counterfactuals (Woodward, 2003). Counterfactual causal effects can be classified into two types according to the interventions that define them: agency and non-agency causal effects. Agency causal effects are defined with respect to interventions that can be carried out in the real world, at least in principle. For example, a clinical researcher may be interested in evaluating mortality rates in a hypothetical world where all patients are given a certain treatment, and compare them with mortality rates in a hypothetical world where no patient is given the treatment, resulting in the so-called average treatment effect. On the other hand, non-agency causal effects do not require that interventions are feasible. For example, a clinical researcher may be interested in evaluating the strength of the causal relation between a biomarker and mortality through a hypothetical increase of one unit in the biomarker, without regards to whether or how this increase can be brought about. Analyses involving agency causal effects often have the goal of recommending one of the actions under evaluation, and are therefore of high importance to decision makers. This has led to some philosophers (e.g., Menzies and Price, 1993) and statisticians (e.g., Holland, 1986; Herna\u0301n and Taubman, 2008; Herna\u0301n, 2016) to hold the view that causal inference is only useful if it evaluates agency effects,1 although that view has been vigorously contested, both in philosophy (e.g., Woodward, 2003) as well as in statistics and related disciplines (e.g., Glymour and Glymour, 2014; Krieger and Davey Smith, 2016; Daniel et al., 2016; Vandenbroucke et al., 2016; Glymour and Spiegelman, 2017; Pearl, 2018, 2019a,b).\n1This view is often called \u201cthe interventionist view of causality\u201d (e.g., Robins et al., 2022), although that designation is a misnomer since all counterfactual views of causality, whether they are agency or non-agency, involve interventions (Woodward, 2003). A more appropriate label would be \u201cthe agency view of causality\u201d (Menzies and Price, 1993).\nIn this article we propose a type of non-agency causal effect based on so-called information interventions, which are heuristically defined as modifications to the information transferred through the edges of a causal graph. This view of causality as transfer of information has been advocated in philosophy (e.g., Collier, 1999; Illari and Russo, 2014; Hausman and Woodward, 2004; Malinsky, 2018; Weinberger, 2021) and has been previously used in statistics (e.g., Janzing et al., 2013; Schwartz et al., 2016; Pearl, 2018, 2019a; Gong and Zhu, 2019; Pearl, 2019b; Gong and Zhu, 2021; Scho\u0308lkopf, 2022), although causal effects defined using interventions on the information transferred along the edges are far less common than effects that use interventions on the nodes of the causal graph.2 In order to distinguish between measures of causality defined through interventions on the nodes vs the edges of a causal graph, we use the expression causal effect to refer to the former and the expression causal influence to refer to the latter.\nThe information interventions we develop have roots in stochastic interventions (e.g., Korb et al., 2004; Robins et al., 2004; Didelez et al., 2006; Eberhardt and Scheines, 2007; D\u0131\u0301az and van der Laan, 2013; Young et al., 2014; Chaves et al., 2015), which are defined as interventions where the nodes of a causal graph are intervened on and replaced by random draws from user-given distributions. Examples of stochastic interventions include incremental propensity score interventions (Kennedy, 2019; Wen et al., 2021), and interventions that shift the exposure distribution in an additive or multiplicative scale (D\u0131\u0301az and van der Laan, 2012; D\u0131\u0301az and Hejazi, 2020; D\u0131\u0301az et al., 2021b, 2022a).\nAlthough we use ideas from the literature on stochastic interventions, we depart from that literature in that we are not interested in intervening on the nodes of the graph, but merely use random draws from a distribution to aid in describing functional dependencies between variables in a structural equation system. We propose to use stochastic interventions as a means to define operations on a causal model that remove or emulate the information transferred by a node along certain edges of interest, while leaving the node unaffected. Measures of causal influence thus defined can be interpreted outside of an agency view of causality, as measures of counterfactual functional dependence. In other words, the causal influence measures we propose may be considered of a descriptive rather than a prescriptive nature in the sense that they unveil causal relations prevalent in the world, but do not tell us about\n2Following the cited literature, we use the phrase \u201cinformation transfer\u201d to refer to the interventions used in the paper.\nHowever, our use of the word information does not necessarily correspond its use in the field of \u201cinformation theory\u201d.\nactions that would yield different outcomes.\nNon-agency interventions may be useful for studying causes that are non-manipulable or for which manipulations are difficult to conceptualize or of no substantive interest. A common characteristic of those causes (e.g., race, gender, genetics) is that their effect is often mediated by other attributes which are more amenable to manipulation by intervention. For example, the causal relation between racial discrimination and health disparities in the US population is mediated by socioeconomic factors (Williams and Rucker, 2000). Likewise, the causal relation between polygenic risk scores and individual traits or disease is often mediated by physiological or environmental processes that occur in childhood or adulthood. (see e.g., Elkrief et al., 2021; Yang et al., 2022). Thus, the eventual development of feasible actions to bring about changes (e.g., to reduce discrimination or to mitigate genetic risks) requires an a-priori understanding of the intervening mechanisms. This understanding can be achieved using mediation or path analysis. Natural direct and indirect effects (Robins and Greenland, 1992; Pearl, 2001) are a popular approach for mediation analysis, but they are not identified in the presence of treatment-induced mediator-outcome confounding (Avin et al., 2005). A solution to this problem which has gained traction in the applied literature is the use of randomized interventional effects (VanderWeele et al., 2014). Recent research (Miles, 2022) has uncovered an important limitation of these effects, namely that they fail to satisfy the sharp null mediational criterion, meaning that the effect through the mediator can be non-zero even when there is no structural relation that operates through the mediator for any individual in the population. In this paper we demonstrate how information interventions can be used to define novel path-specific causal influence measures. We prove that the proposed measures have an important property that they satisfy appropriately defined path-specific sharp null criteria, meaning that they take their null value when there is no mechanism operating through the path under consideration. This means that the proposed path-specific measures of causal influence can be used to identify and estimate the strength of causal mechanisms, even in the presence of mediator-outcome confounders affected by treatment.\nThe paper is organized as follows. In \u00a72 we introduce the notation and the causal model used in the paper. In \u00a73 we introduce the novel measure of causal influence based on non-agency information transfer interventions. In \u00a75 we discuss a path-analysis method that uses these interventions, and\nwe prove that this method satisfies appropriately defined path-specific sharp null criteria, providing correct tests for mechanisms. In \u00a76 we present a decomposition that uses information interventions to achieve a path-specific decomposition of agency causal effects, specifically the average treatment effect. In \u00a77 we develop non-parametric efficient estimators for some of the causal influence measures proposed, and in \u00a78 we present the results of applying the methods to two publicly available datasets. We conclude in \u00a79 with a brief discussion of connections to recent literature and directions of future research."
        },
        {
            "heading": "2 Notation, data, and causal model",
            "text": "Assume that we observe n independent and identically distributed copiesX1, . . . , Xn ofX = (W,A,Z, M, Y ) \u223c P. We use a Structural Causal Model (SCM, Pearl, 2000) to study causal relations. A SCM is a 4-tuple \u3008U,X,F ,P\u3009, where U are exogenous variables, X are endogenous variables, F is a set of functions used to determine the value of X , and P is a set of allowed distributions on U (Bareinboim et al., 2022). The SCM used in this paper assumes the following.\nA1. Assume that X is generated according to:\nW = fW (UW ); A = fA(W,UA); Z = fZ(A,W,UA);\nM = fM(Z,A,W,UM); Y = fY (M,Z,A,W,UY ).\n(1)\nwhere the functions f are deterministic but otherwise unrestricted. Furthermore, assumeUA\u22a5 (UY , UM , UZ) |W , UZ\u22a5 (UY , UM) | (A,W ), and UM\u22a5UY | (A,W,Z).\nWe simplify the presentation of the model by considering a single W with little loss of generality, but we could split it into several factors according to whether they are confounders of only some of the subsequent relations. We are interested in quantifying the strength of the causal relation betweenA and Y , and understanding the extent to which that relation operates through the various paths between the endogenous variables X . We illustrate those pathways in the causal graph depicted in Figure 1. For illustrative convenience we do not depict the exogenous variables; correlations between them could\nbe depicted through bi-directed arrows (see Pearl (2000) for the construction of a causal graph from an SCM). Variables such as Z, which are affected by A and are a common cause of the mediator\nand outcome, are often referred to as intermediate confounders. In this causal graph, one may be interested in mediation analysis in the sense of quantifying all paths from A to Y that involve M (indirect paths) vs all other paths (direct paths). An alternative and arguably more complete analysis would involve understanding the causal relation between A and Y as it operates through each path A \u2192 Y , A \u2192 Z \u2192 Y , A \u2192 Z \u2192 M \u2192 Y , and A \u2192 M \u2192 Y . We refer to the former goal as mediation analysis, and to the latter as path-analysis."
        },
        {
            "heading": "3 Measuring the strength of causal relations",
            "text": "The concept of causal influence is generally defined as the existence of a directed path between two variables (Pearl and Verma, 1995). A formal definition of the causal influence of A on Y in terms of the non-parametric structural equation model can be constructed as follows.\nDefinition 1 (Causal influence). For fixed a, let the counterfactual variable Y (a) be defined as the solution in Y of the equations (1) under the interventionA = a. That is, Y (a) = fY (M(a), Z(a), a,W, UY ) with M(a) = fM(Z(a), a,W, UM) and Z(a) = fZ(a,W, UZ). The variable A is said to have a causal influence on Y if and only if supa,a\u2032 |Y (a)\u2212 Y (a\u2032)| > 0 with positive probability.\nFor binary treatments, the concept of causal influence as stated above is related to Fisher\u2019s sharp null hypothesis of no individual treatment effect H0 : Yi(1) = Yi(0) for all i \u2208 {1, . . . , n}. Recent\napproaches to causal inference have focused on quantifying causal influence through causal effects, which are usually understood as changes in the probability distribution of X under hypothetical interventions that modify the value of the variable A. In this paper, we propose an alternative way to quantify causal influence, using an approach based on intervening on the information transferred along edges in the causal graph depicted in Figure 1. In general, we will require that measures for causality satisfy the following properties:\nP1 (Sharp null criterion). A causality measure satisfies the sharp null criterion if it is null whenever there is no causal influence.\nP2 (Monotonicity criterion). A causality measure satisfies the monotonicity criterion if (i) it is less than its null value whenever Y (a) is monotone decreasing in a almost surely, and (ii) it is greater than its null value whenever Y (a) is monotone increasing in a almost surely.\nWhile this criterion is trivially satisfied by many causal effects, it has been recently uncovered that it is not satisfied by widely adopted approaches to mediation analysis. In \u00a74 we prove that our proposed path-specific causal influence measures satisfy a version of this criterion adapted to pathanalysis. Before we describe our proposed definitions of intervention on information transferred along edges, we review causal effects defined with respect to interventions on nodes."
        },
        {
            "heading": "3.1 Causal effects",
            "text": "A general definition of causal effect based on node interventions is as follows (adapted from Pearl, 2000):\nDefinition 2 (Causal effect of a node intervention). Given a fixed value a, the causal effect of the intervention A = a is defined as a comparison between the probability distributions of the counterfactual variables Y (a) and Y (a0), for a reference level a0.\nAs stated in the definition, to define the causal effect of A on Y one needs to specify an intervention to the node corresponding to A in the SCM (1). For example, consider an intervention that removes the equation fA from the SCM and replaces it with assignment to a fixed value A = a. The\ncounterfactual outcome in this hypothetical intervened world is Y (a) = fY (M(a), Z(a), a,W, UY ), denoting outcome that would have been observed in a world where, contrary to fact, A had been equal to a with probability one. The causal effect of A on Y may then be defined in terms of contrasts of the distribution of the potential outcomes Y (a) : a \u2208 A. For example, for binary A, a common choice is to use the average treatment effect ATE = E[Y (1)\u2212 Y (0)] as an effect measure.\nThe above definition has been generalized in multiple directions, for example to allow dynamic interventions that might depend onW (e.g., Robins, 2004; van der Laan et al., 2005; Cain et al., 2010), modified treatment policies whereby the intervention might depend on bothA andW (e.g., D\u0131\u0301az and Hejazi, 2020; D\u0131\u0301az et al., 2021b, 2022a), as well as stochastic interventions whereby the post-intervention exposure is a random draw from a user-given distribution (e.g., Wen et al., 2021)."
        },
        {
            "heading": "3.2 Causal influence based on information interventions",
            "text": ""
        },
        {
            "heading": "3.2.1 A motivating experimental design",
            "text": "To motivate the definitions that follow, we fist discuss audit studies, which are a type of experiment to study discrimination common in social sciences (Gaddis, 2018). Although there are many types of audit studies, on a basic level they can be described as a research design where the experimenter prompts some type of interaction with the research subjects (e.g., a letter, a job or housing application, a diagnosis, etc.), randomly varying the attributes under evaluation (e.g., gender, race), and then assesses the behavior of the research subject. To ground ideas, consider the following examples.\nShapiro et al. (2018) study implicit biases in periviability counseling among neonatologists caring for pregnant women by using implicit association tests (IATs Greenwald et al., 1998). The experiment consisted of showing different neonatologists a vignette of a woman in imminent labor, where the patient\u2019s race and socioeconomic status in the vignette were randomized. The neonatologists were then asked to indicate how likely they were to recommend comfort care vs intensive care, and the difference in recommendation across randomized races were assessed. Bertrand and Mullainathan (2004) performed a similar experiment to study the effect of perceived race on labor market discrimination, where they randomized racial cues such in the candidate\u2019s resume such as the name. Cheng and Florick\n(2020) assess the value of study abroad experience in the labor market. Their experiment consisted of submitting resumes to job listings posted on a popular online job site, where other resume attributes are held constant but study abroad experience is randomized within job posting.\nA key feature of all of these examples is that the intervention is performed on the information given to a decision-maker (clinicians, recruiters, etc.) rather than the causes (e.g., a person\u2019s race, socioeconomic status, study abroad experience), which are left unmodified. The definitions that follow can be seen as a formalization of the interventions intended by these audit studies."
        },
        {
            "heading": "3.2.2 Proposed interventions on information transferred along edges",
            "text": "We propose to measure the causal influence of A on Y based on the impact on the joint distribution of (A, Y ) of intervening on the information transferred along all directed paths from A to Y in Figure 1. We first define an intervention where no information is transferred along any of these paths. Specifically, let A denote a noise variable defined as a random draw from the distribution of A conditional on W . Note that in some applications it may be more reasonable to define A as a random draw from the conditional distribution of A given a subset of V \u2286 W . In the interest of simplifying notation we pursue a definition based on a random draw conditional on W .\nTo remove the information transferred along all paths between A and Y , one possibility is to transfer noise along the edges in S = {A\u2192 Y,A\u2192 M,A\u2192 Z}. which corresponds to the following data generating mechanism:\nW = fW (UW ); A = fA(W,UA); Z(A) = fZ(A,W,UA);\nM(A) = fM(Z(A), A,W, UM); Y (A) = fY (M(A), Z(A), A,W, UY ).\n(2)\nThe above counterfactual represents interventions that remove the influence of A on Y along all edges in the set S and replace it by transferring noise. We will therefore use the alternative notation YS for Y (A). This notation will be useful when we define counterfactuals that intervene on the information transferred along different sets of edges, such as those required for path analysis.\nRemark 1. The above interventions are stochastic versions of the info-interventions proposed by\nGong and Zhu (2019). These interventions are similar to the inflation operation proposed by Wolfe et al. (2019), but are different in at least two aspects. First, our goal is to quantify the effect of a given cause on a given outcome, whereas the goal of inflation operations is to assess whether a particular data distribution is compatible with a given graphical model. Furthermore, our interventions are performed at the individual level, whereas the inflation operation is performed at the population level by altering the probability distribution of the data.\nThese interventions may be of interest when, instead of considering interventions on an individual\u2019s A, we consider a hypothetical joint intervention on the mechanisms downstream of A such that the functional dependence on of these variables on their causal parents are modified. For example, Z = fZ(A,W,UZ) is replaced by Z = fZ(A,W,UZ). The form of the function fZ remains the same but one of its inputs changes. To further illustrate the relevance of this definition, consider a problem where one is interested in the causal influence of gender A on wages Y , mediated by work sector M and field of study Z. The correlation between gender A and the counterfactual Z(A) is interpreted as the correlation between gender and the field of study that would be observed in a hypothetical world where field of study preferences and opportunities were as if a person\u2019s actual gender did not play a role in their field of study preferences and opportunities.\nThis information transfer intervention allows us to define causal influence measures as follows:\nDefinition 3 (Measure of causal influence). Let P(y, a) denote the distribution of Y conditional on A, and let PS(y, a) denote the distribution of YS conditional on A. Let D denote any functional contrasting two distributions such that D(P,P) = 0. The strength of the causal influence of A on Y can be defined as any contrast D(P,PS) between (moments of) P(y, a) and PS(y, a).\nRemark 2. This definition is related to the definition of causal strength given by Sprenger (2018); Fitelson and Hitchcock (2011). The difference with our definition is that we are interested in a system where the information transferred along by the causal agent is changed to be noise, whereas the definition in these works focuses on contrasts where the causal agent is turned on vs off.\nTo further see why Definition 3 is a sensible measure of causal influence, consider the original SCM (1) and its associated causal graph in Figure 1. In this model A and Y may be associated due\nto two different types of relations: (i) any of the directed paths from A to Y , or (ii) undirected paths operating through common causes (e.g., W or U). In contrast, in the intervened SCM (2), A and YS can only be associated due paths operating through to common causes. Therefore, a contrast between the joint distributions P(y, a) and PS(y, a) provides a measure of the information transferred through paths from A to Y . These ideas are formalized in the following property:\nProposition 1. Any contrast D(P,PS) between (moments of) P(y, a) and PS(y, a) satisfies the sharp null criterion P1.\nProof This follows after noticing that YS = Y whenever A has no causal influence on Y .\nNote, however, that the counterfactual SCM (2) should not be used in general to define individual causal effects, sinceAmay be equal to A by chance for any given individual. Furthermore, contrasting the marginal distributions of YS and Y may also be misleading, as these distributions may also be equal by study design, e.g., in a completely randomized trial with binary treatment.\nTo properly place the definition of the measure of causal influence D(P,PS) in the context of\ncausality research, it is useful to consider Judea Pearl\u2019s \u201chierarchy (or ladder) of causation\u201d (Pearl and Mackenzie, 2018). The hierarchy consists of three layers: associational, agential,3 and counterfactual, which correspond to \u201cthe ordinary human activities of seeing, doing, and imagining, respectively.\u201d (Bareinboim et al., 2022). In this hierarchy, the distribution PS(a, y) may be seen as that of the outcome and cause in an imagined world where the cause under evaluation Y does not causally affect any of downstream variables (Z,M, Y ). Although we operationalize this imagined world through the counterfactual distribution PS(a, y) and associated counterfactual variables, there are a multiple other ways in which this imagined world could have been operationalized.\nTo illustrate the utility of Definition 3, we now present a number of examples of how these distri-\nbutions can be contrasted.\n3The agential layer is often referred to as \u201cinterventional\u201d, although this is possibly a misnomer since the counterfactual\nlayer also uses interventions (Woodward, 2003).\nExample 1 (Covariance decomposition). Consider the covariance decomposition\nCov(A, Y ) = Cov(A, Y \u2212 YS) \ufe38 \ufe37\ufe37 \ufe38\ncausal influence\n+Cov(A, YS) \ufe38 \ufe37\ufe37 \ufe38\nconfounding\n.\nBy definition, A does not have a causal influence on YS . Any association between A and YS is due to common causes, which means that Cov(A, YS) is a measure of confounding. On the other hand, Cov(A, Y \u2212 YS) = Cov(A, Y ) \u2212 Cov(A, YS) is a contrast of covariances comparing hypothetical worlds that only differ in the influence through paths from A to Y , which is present in Cov(A, Y ) but not in Cov(A, YS). Thus, Cov(A, Y \u2212 YS) quantifies the causal influence of A on Y . Furthermore, it recovers the sign of the individual effects in the following sense:\nTheorem 1. The above covariance decomposition satisfies the monotonicity criterion P2.\nExample 2 (Regression of residuals). Consider the function f(a) = E[Y \u2212 YS | A = a], where we note that this parameter measures the strength of the association in a hypothetical world where the influence of A on Y is removed (and therefore all association is due to confounding) and compares it to the association observed in the actual world.\nExample 3 (Kullback-Leibler divergence). Another measure of causal influence may be given by the Kullback-Leibler divergence D(P,PS) = EP [ log (\np(Y,A) pS(Y,A)\n)]\n, where p(y, a) is the density of (Y,A)\nand pS(y, a) is the density of (YS, A).\nRemark 3. Janzing et al. (2013) also propose a measure of causal influence based on the KullbackLeibler divergence, but their proposal differs from ours in two ways. First, our interventional densities allow for random draws A conditional on the past, theirs do not. Second, their measure of causal influence is based on a contrast of the distribution of the complete data X with and without an intervention. While using the distribution of the complete data X yields causal influence measures with important properties (see properties P0-P4 in Janzing et al., 2013), adopting a definition based on the distribution of (A, Y ) allows the construction of optimal estimators which would not be possible under the definition that contrasts the full data distributions.\nThe parameters described in Examples 1-3 have an interesting structural interpretation in terms of a quantification of the dependence of the function fY in the SCM on the variable A. In other words, these parameters quantify how much nature\u2019s causal mechanisms use information on A to assign the outcome value. The following theorem provides an expression that can be used to identify the joint distribution of (YS, A) under the standard assumption of no unmeasured confounders.\nTheorem 2 (Identification). Under the assumed SCM (A1) we have PS(YS \u2264 y | A = a) = E[P(Y \u2264 y |W ) | A = a].\nNote that identification of this causal influence parameter does not require the positivity assumption P(g(a | W )) > 0 that is required to assess the effect of many node interventions. Furthermore, if A is randomized, this identification result reduces to P(Y \u2264 y | A = a), in agreement with the idea that the causal relation between A and Y is not confounded in a randomized experiment.\nCorollary 1. Under the assumed SCM (A1) we have Cov(A, Y \u2212YS) = \u03b8 and Cov(A, YS) = \u03c4 , where \u03b8 = E {[A\u2212 E(A | W )] [Y \u2212 E(Y |W )]}, and \u03c4 = Cov {E(A |W ),E(Y | W )}. Furthermore, we have f(a) = E[Y \u2212 E(Y | W ) | A = a].\nRemark 4. The expectation of the conditional covariance \u03b8 has been previously used for causal inference as a means to study other causal effects, such as the variance-weighted ATE (Li et al., 2011). Furthermore, it forms the basis to construct the partial correlation coefficient, which has a long but non-rigorous history as a measure of causality in applications (Ellett and Ericson, 1986), for example in the context of genomics (e.g., Freudenberg et al., 2009). Its role in conditional independence testing has been previously studied by Shah and Peters (2020). However, we know of no previous result that provides an interpretation of the expected conditional covariance as a causal effect in terms of formal interventions in a causal model. In addition, this result provides a causal interpretation of the well known law of total covariance as a decomposition of the covariance between A and Y in terms of a pure causal influence \u03b8 and a pure confounding effect \u03c4 . Furthermore, identification of the contrast E[Y \u2212 YS | A = a] involves regressing the orthogonalized outcome Y \u2212 E(Y | W ) on the treatment variable A. This is a procedure commonly used in applied studies aiming to estimate causal inference effects (e.g., in genomics) but its interpretation in a formal causal inference framework has not been\npreviously articulated. This illustrates that causal our proposed causal influence measures formalize vague notions of causality that are already present in scientists minds.\nThe counterfactual YS involves information transfer interventions that remove all the information transferred along edges in S. In this article we will also use an information transfer operation that emulates information transferred along certain paths. Consider, for example, the paths A \u2192 Z \u2192 Y and A\u2192 Z \u2192 M \u2192 Y . Let ZA denote a draw from the distribution of Z conditional on (A,W ), and consider the counterfactual variable Y (A,ZA,M(A,ZA)). In this counterfactual variable, we have emulated the information transferred along the paths A \u2192 Z \u2192 Y and A \u2192 Z \u2192 M \u2192 Y by information transferred along synthetic paths A \u2192 ZA \u2192 Y and A \u2192 ZA \u2192 M \u2192 Y , respectively. Interestingly, the distribution of this counterfactual variable is identified by P(Y \u2264 y | A = a), suggesting that this information transfer intervention preserves the relation that operates through the original paths. While this kind of intervention is not very useful to define total causal influence of A on Y , it will be fundamental in \u00a74 when we present the path analysis methods using causal influence.\nIn the next section we discuss a major advantage of the information transfer interventions introduced in this section, namely the ability to provide measures of direct and indirect causal influence. We will show that these interventions allow the decomposition of the total causal influence into an influence and an effect that operates through each specific path. Importantly, we show that this decomposition is possible even in the presence of mediator-outcome confounders which are affected by exposure, a problem whose solution has been elusive in the causal inference literature that focuses on the causal effect of actions. We start our presentation with a brief discussion of the problems with existing approaches to mediation analysis using causal effects."
        },
        {
            "heading": "4 Causal effects and implications for path and mediation analysis",
            "text": "Mediation analysis is the task of decomposing the total causal influence of A on Y into an influence that operates through M and an influence that operates through all other mechanisms. This can be done by decomposing the total causal influence of the previous section into influence that operates the pathways A \u2192 Y and A \u2192 Z \u2192 Y (so-called direct influence), and influence that operates through\nthe pathways A\u2192M \u2192 Y and A\u2192 Z \u2192 M \u2192 Y (so-called indirect influence).\nDefinition 4 (Causal influence through a mediator). For fixed a\u0304 = (a0, a1, a2), define the counterfactual variable Y (a0,M(a1)) as the solution in Y of the equations (1) under the intervention A = a0 and M = M(a1). That is, Y (a0,M(a1)) = fY (M(a1), Z(a0), a0,W, UY ) with M(a1) = fM(Z(a1), a1,W, UM) and Z(a0) = fZ(a0,W, UZ). The variable A is said to have a causal influence on Y through M if and only if supa\u0304 |Y (a0,M(a1)) \u2212 Y (a0,M(a2))| > 0 holds with positive probability.\nFor binary exposures, this definition of causal influence is equivalent to the sharp mediation null H0 : Y (a,M(1)) = Y (a,M(0)) for a \u2208 {0, 1}. As before, it will be desirable that parameters that measure the influence of A on Y operating through M satisfy the following properties (Miles, 2022):\nP3 (Mediational sharp null criterion). A measure of the causal influence of A on Y through M is said to satisfy the mediational sharp null criterion if it is null whenever there is no causal influence through the mediator M .\nIn addition, it may be desirable that mediation analyses that seek to unveil mechanisms satisfy the following property, which we present in an additive scale but can be equivalently stated in a multiplicative or other scales:\nP4 (Total influence decomposition). A pair of measurements of direct and indirect influence are said to decompose a measure of total influence if they add up to the total influence.\nHaving established the above desiderata for a measure of influence through a mediator, we now review two of the major mediation frameworks recently proposed: natural direct and indirect effects, and randomized interventional direct and indirect effects. We discuss the lack of identifiability of natural effects in the presence of a mediator-outcome confounder affected by treatment, and discuss the fact that randomized mediational effects do not satisfy the sharp mediational null criterion. These shortcomings were originally described by Avin et al. (2005) and Miles (2022), respectively. We then move onto discussing our proposal for mediation analysis based on the causal influence measures proposed in the previous section, and show how our proposal can be used to address those shortcomings."
        },
        {
            "heading": "4.1 Natural direct and indirect effects",
            "text": "In the case of a binary exposureA, the average treatment effect E(Y (1)\u2212Y (0)) is a common measure of the effect of the action A = 1 vs the action A = 0. Natural mediation effects decompose the ATE into effects that operate through the mediator M and effects that operate through all other causes. Specifically, we have\nE[Y (1)\u2212 Y (0)] = E[Y (1,M(1))\u2212 Y (0,M(0))]\n= E[Y (1,M(1))\u2212 Y (1,M(0))] \ufe38 \ufe37\ufe37 \ufe38\nNatural indirect effect (NIE)\n+E[Y (1,M(0))\u2212 Y (0,M(0))) \ufe38 \ufe37\ufe37 \ufe38\nNatural direct effect (NDE)\n,\nwhere the first equality follows by definition of Y (a,M(a)) : a \u2208 {0, 1} and the second by adding and subtracting E[Y (1,M(0))]. Inspection of the above formulas reveal why the NIE measures the effect through M and the NDE measures the effect through all other mechanisms. The NIE is the result of comparing the outcome in a hypothetical world where A = 1 is fixed while M is varied from what it would have been under A = 1 to what it would have been under A = 0. The NDE is the result of comparing the outcome in a hypothetical world where A is varied from A = 1 to A = 0 while fixing M to what it would have been under A = 0.\nWhile the NIE and NDE provide a useful and intuitive decomposition of the ATE into effects that operate through M vs all other mechanisms, and satisfy P3 and P4, these effects are not identified in the causal graph 1 (Avin et al., 2005). To understand why identification fails, it is useful to consider a simplified model where W = \u2205, all the errors U are mutually independent, and the edges A\u2192M and A\u2192 Y have been removed. It can be proved that in this model we have\nE[Y (1,M(0))] = \u2211\nm,z,z\u2032\nE[Y (Z = z,M = m)]P(M(Z = z\u2032) = m)P(Z(A = 1) = z, Z(A = 0) = z\u2032),\nwhere we have enriched the notation to add the intervention node in the index of the counterfactual variables. While P(Y (Z = z,M = m) = y) and P(M(Z = z\u2032) = m) are identifiable in this model, P(Z(A = 1) = z, Z(A = 0) = z\u2032) is not (for a counterexample, see Table 1 of Avin et al., 2005), leading to lack of identifiability of the NIE and NDE. The variable Z is often referred to as a recanting\nwitness because it operates as an direct mechanism through the path A \u2192 Z \u2192 Y and as an indirect mechanism through the path A \u2192 Z \u2192 M \u2192 Y , leading to the lack of identifiability of either the direct or the indirect effect.\nMultiple alternatives exist to conduct mediation analysis in the presence of intermediate confounding. For example, if the relation A \u2192 Z is monotonic, Tchetgen Tchetgen and VanderWeele (2014) showed that the NDE and NIE are point-identified and Rudolph et al. (2023) developed nonparametric estimators for the identifying functionals. Alternatively, Miles et al. (2015) gave partial identification bounds for the NDE and NIE. A third option is to target a different definition of direct and indirect effects, for example using the methods. Along these lines, much of the recent literature on mediation analysis has focused on randomized interventional effects (Didelez et al., 2006; van der Laan and Petersen, 2008; VanderWeele et al., 2014; D\u0131\u0301az et al., 2021a). We discuss the definition, interpretation, and identification of these randomized interventional effects below."
        },
        {
            "heading": "4.2 Randomized interventional direct and indirect effects",
            "text": "Consider a random draw G(a) from the distribution of M(a) conditional on W . Randomized mediational effects are concerned with interventions that set the mediator to G(1) and G(0) instead of M(1) and M(0). Specifically, the randomized mediational effects are defined as follows:\nE[Y (1, G(1))\u2212 Y (0, G(0))] \ufe38 \ufe37\ufe37 \ufe38\nTotal effect\n= E[Y (1, G(1))\u2212 Y (1, G(0))] \ufe38 \ufe37\ufe37 \ufe38\nRandomized indirect effect\n+E[Y (1, G(0))\u2212 Y (0, G(0))] \ufe38 \ufe37\ufe37 \ufe38\nRandomized direct effect\n.\nThe first limitation of randomized mediational effects is that they do not satisfy P4 in the sense that they do not decompose the ATE, but rather decompose an alternative treatment effect given by the left hand side of the above expression which is defined in terms of interventions on both A and M .\nUnlike the NIE and NDE, randomized mediational effects are identified in the model in the SCM (1).\nVanderWeele et al. (2014) show that the above randomized interventional indirect effect is identified as\nE[Y (a,G(a\u2032))] =\n\u222b\nE(Y | m, z, a, w)dP(z | a,w)dP(m | a\u2032, w)dP(w) (3)\nunder the assumption that there are no unmeasured confounders of the relations A \u2192 M , A \u2192 Y ,\nand M \u2192 Y . However, Miles (2022) has recently uncovered an important limitation of these effects, namely that they fail to satisfy the mediational sharp null criterion P3. One counterexample involves creating an SCM with independent errors, W = \u2205, and an exogenous binary variable UZ such that M(a) =M(a\u2032) in the event UZ = 1 and Y (a,m \u2032) = Y (a,m) in the event UZ = 0 for all a, a \u2032, and m, such that there is no causal influence of A on Y operating through M (Definition 1). It is easy to see that the randomized interventional indirect effect in this example equals\n\u222b\nE(Y | m, z, a)dP(z | a)[dP(m | a)\u2212 dP(m | a\u2032)],\nwhich is generally not null, and would only be null if UZ was observed and conditioned upon in all the above quantities. The interested reader is referred to Miles (2022) for more details and counterexamples.\nIn what follows we propose a mediation analysis strategies based on the information transfer interventions introduced in \u00a73, and show that this approach overcomes the limitations of the interventional effects discussed in this section."
        },
        {
            "heading": "5 Path analysis using causal influence",
            "text": "In this section, we propose a decomposition of the causal influence of A on Y into influence that operates through each of the paths A \u2192 Y , A \u2192 Z \u2192 Y , A \u2192 Z \u2192 M \u2192 Y , and A \u2192 M \u2192 Y . We first state the properties that are desirable of measures of such path-specific influence. In this section, we will use counterfactual variables indexed by interventions on (A,Z,M), and define Y (a, z,m) = fY (m, z, a,W, UY ), M(a, z) = fM(z, a,W, UM), and Z(a) = fZ(a,W, UZ).\nDefinition 5 (Path-specific causal influence). For fixed a\u0304 = (a0, a1, a2, a3, a4), define the counterfactual variable Y (a1, Z(a2),M(a3, Z(a4))). The variable A is said to have a causal influence on Y through each path P1, P2, P3, P4 if and only if the following conditions hold with positive probability\nP5 (Path-specific sharp null criterion). For j = 1, 2, 3, 4, a measure of the causal influence operating through path Pj satisfies the path-specific sharp null criterion if it is null whenever there is no causal influence through Pj .\nIn addition, it will be important that the measures of the causal influence through each path recover the direction of the mechanism in some sense. Miles (2022) operationalized this idea using the following property:\nP6 (Path-specific monotonicity criterion). For j = 1, 2, 3, 4, a measure of the causal influence operating through path Pj satisfies the monotonicity criterion if (i) it is less than its null value whenever Y (a1, Z(a2),M(a4, Z(a3))) is decreasing in aj almost surely, and (ii) it is greater than its null value whenever Y (a1, Z(a2),M(a4, Z(a3))) is increasing in aj almost surely, for all as : s 6= j.\nOur proposed method for path analysis will require to specify a set of interventions that sequentially remove the information transferred through the paths P1, P2, P3, and P4. To construct the interventions, we first define the sets Sj = {P1, . . . , Pj} for j = 1, 2, 3, 4. Then, let A and ZA denote a random draw from the distribution of A and Z conditional on W , respectively. Let ZA denote a random draw from the distribution of Z conditional on (A,W ). The notation ZA indicates that ZA does not transfer information from A onto the descendants of Z, whereas the notation ZA indicates that ZA transfers information from A onto the descendants of Z. In this sense, an intervention that assigns Z as ZA can be thought of as an edge-emulation intervention. Although the emulation of the information transferred along the edge is not perfect (e.g., ZA cannot transfer information from UZ intoM), it will be sufficient\nfor purposes of defining path-specific causal influence. Define the following counterfactual variables:\nYS0 = Y (A,Z(A),M(A,Z(A))), YS1 = Y (A,Z(A),M(A,Z(A))), YS2 = Y (A,Z(A),M(A,Z(A))), YS3 = Y (A,Z(A),M(A,Z(A))), YS4 = Y (A,Z(A),M(A,Z(A))),\nA straightforward measurement of the causal influence through path Pj could be achieved through a contrast of the distributions P(YSj \u2264 y | A = a) and P(YSi\u22121 \u2264 y | A = a), for j = 1, 2, 3, 4. (A related definition of path-specific influence is proposed by Zhang and Bareinboim (2018) in terms of a covariance contrast and using atomic interventions.) However, some of these causal influence measures are not identified due to the recanting witness problem outlined in the previous section. Specifically, the probability distribution of YS2 is not identifiable because Z operates as a recanting witness through the paths A \u2192 Z \u2192 Y and A \u2192 Z \u2192 M \u2192 Y . This means that the causal influence through the path A\u2192 Z \u2192 Y , defined as a contrasts between P(YS2 \u2264 y | A = a) and P(YS1 \u2264 y | A = a) is not identified. The same is true for the causal influence through the path A\u2192 Z \u2192M \u2192 Y , defined as a contrasts between P(YS3 \u2264 y | A = a) and P(YS2 \u2264 y | A = a).\nFortunately, the edge emulation-intervention can be used to solve this problem. Specifically, denote\nYSj with Y (0) Sj , and let\nY (1) S1 = Y (A,Z(A),M(A,ZA)), Y (1) S2 = Y (A,Z(A),M(A,ZA)), (4) Y (2) S2 = Y (A,ZA,M(A,Z(A))), Y (2) S3 = Y (A,ZA,M(A,Z(A))).\nThen we have the following definition.\nDefinition 6 (Measure of causal influence through a path). For i = 0, 1, 2, 3, 4 and k = 0, 1, 2, let\nP (k) Sj (y, a) denote the distribution of (Y (k) Sj , A). Let D denote any functional contrasting two distributions. The strength of the causal influence of A on Y operating through path Pj can be defined as any contrast D(P (0) Sj\u22121 ,P (0) Sj ) for paths not involving the recanting witness Z (i.e., P1 and P4), as D(P (1) S1 ,P (2) S2 ) for the path P2, and as D(P (2) S2 ,P (2) S3 ) for P3.\nRemark 5. The above interventions are stochastic versions of those proposed in Gong and Zhu (2021), but are also different in that we vary the information about A transferred along a pathway, using different kinds of interventions depending on the pathway under measurement. This has important implications, as it allows us to prove important desiderata for path-analysis effect decompositions such as path-specific sharp null criteria (Theorem 3), as well as a result stating that the path-specific measures decompose the total effect (Theorem 4).\nIn Theorem 3 below we show that the above definition satisfies the path-specific null criterion,\nmeaning that these parameters may be used to test the null hypothesis of no path-specific effect.\nTheorem 3. The contrasts defined in Definition 6 satisfy the path-specific sharp null criterion P5 with respect to each path Pj .\nNote that the definitions of the counterfactuals Y (1) S1 , Y (1) S2 , Y (2) S2 , and Y (2) S3 , entail intervening on\nthe information that is transferred along certain paths. For example, in Y (1) S1 the influence of A on Y operating through the pathA\u2192 Z \u2192 M \u2192 Y operates by means of the random draw ZA, whereas the influence operating through the pathA\u2192 Z \u2192 Y operates through the natural value of Z. These edge emulation interventions substitute a pathA\u2192 Z \u2192 \u00b7 \u00b7 \u00b7 \u2192 Y by a synthetic pathA\u2192 ZA \u2192 \u00b7 \u00b7 \u00b7 \u2192 Y that transfer the same information as the original path. The edge-emulation intervention is what allow us to do away with the recanting witness problem to obtain causal influence measures that satisfy the path-specific sharp null criterion.\nThe above definitions allow us to test the null hypothesis of no causal influence through each path. A related goal is to decompose the total influence of A on Y into influences operating through each path. This is achievable only for some contrasts D (e.g., it is not achievable for the Kullback-Leibler divergence of Example 3). Specifically, we have the following result which is presented in an additive scale but could also be proved for a multiplicative scale.\nTheorem 4 (Decomposition of the total influence into path-specific influences). Assume that the contrast function D is linear in the sense that D(P, F) = D(P,G) + D(G, F) for any distributions F, P, and G. Define the path-specific influences \u03b8P1 = D(P (0) S0 ,P (0) S1 ), \u03b8P2 = D(P (1) S1 ,P (1) S2 ), \u03b8P3 = D(P (2) S2 ,P (2) S3 ), and \u03b8P4 = D(P (0) S3 ,P (0) S4 ), as well as the parameter \u03b8P2\u2228P3 = D(P (0) S1 ,P (1) S1 ) + D(P (1) S2 ,P (2) S2 ) +D(P (2) S3 ,P (0) S3 ). Then we have the following decomposition of the total causal influence \u03b8 = D(PS0 ,PS4):\n\u03b8 = \u03b8P1 + \u03b8P2 + \u03b8P3 + \u03b8P4 + \u03b8P2\u2228P3 .\nClearly, the covariance contrast and the expectation contrast of Examples 1 and 2 satisfy the assumption of the theorem. In the above decomposition, the parameter \u03b8P2\u2228P3 appears as a consequence of the addition of the counterfactuals in Equation (4). As the notation implies, this parameter is equal to zero if there is no influence through the path P2, or there is no influence through the path P3. This result is proved formally in Proposition 2 below. Intuition for this may be obtained as follows. The contrasts D(P (0) 1 ,P (0) 2 ) and D(P (0) 2 ,P (0) 3 ), which would readily yield measures of the influence through paths P2 and P3, respectively, are not identified because the distribution P (0) 2 is not identified due to the recanting witness problem. However, the contrast \u03b8P2\u2227P3 = D(P (0) 1 ,P (0) 3 ) is identified, and it measures the influence operating through P2 and P3. That is, \u03b8P2\u2227P3 = 0 if there is no causal influence operating through P2 nor P3. This highlights the difficulty in measuring the influence through paths P2 and P3 separately. The above theorem decomposes \u03b8P2\u2227P3 into an influence measure \u03b8P2 that operates only through P2, an influence measure \u03b8P3 that operates only through P3, and an influence measure \u03b8P2\u2228P3 that operates through P2 or P3. This latter parameter is zero if the influence going trough either of these paths is null. Furthermore, as demonstrated in the following lemma, the parameter is null whenever there is no intermediate confounding by Z.\nProposition 2. Assume the contrast D is linear as in Theorem 4. In addition, assume that D is such that D(P, F) = \u2211\nS\u2208S D(P(\u00b7 | S), F(\u00b7 | S))P(S) for any partition S of the sample space, and that\nit satisfies D(F, F) = 0. Let U denote the range of U = (UW , UA, UZ , UM , UY ). Assume U can be partitioned in sets U1, U2, and U3 such that the following hold almost surely\n\u2022 supa\u0304 |Z(a1)\u2212 Z(a0)| = 0 in U1, and\n\u2022 supz\u0304 |M(z1)\u2212 Z(z0)| = 0 in U2, and\n\u2022 supz\u0304 |Y (z1)\u2212 Y (z0)| = 0 in U3.\nThen \u03b8P2\u2228P3 = 0.\nImportantly, the above proposition implies that whenever there is no intermediate confounding, the path-specific decomposition is exact in the sense that it satisfies property P4. We now illustrate the proposed path-analysis based on the covariance decomposition of Example 1.\nExample 1 (Continued). LetD denote the covariance contrast defined as D(P,PS) = Cov(A, Y \u2212YS) for (Y,A) \u223c P and (YS, A) \u223c PS . Then, for \u03b8 = Cov(A, Y \u2212 YS), we have\n\u03b8 = \u03b8P1 + \u03b8P2 + \u03b8P3 + \u03b8P4 + \u03b8P2\u2228P3 ,\nwhere \u03b8P1 = Cov(A, Y (0) S0 \u2212 Y (0)S1 ), \u03b8P2 = Cov(A, Y (1) S1 \u2212 Y (1)S2 ), \u03b8P3 = Cov(A, Y (2) S2 \u2212 Y (2)S3 ), \u03b8P3 = Cov(A, Y (0) S3 \u2212 Y (0)S4 ), and\n\u03b8P2\u2228P3 = Cov(A, Y (0) S1 \u2212 Y (1)S1 + Y (1) S2 \u2212 Y (2)S2 + Y (2) S3 \u2212 Y (0)S3 ). (5)\nFurthermore, we have:\nTheorem 5. The covariance contrasts \u03b8P1 , \u03b8P2 , \u03b8P3 , and \u03b8P4 satisfy the path-specific monotonicity criterion P6.\nWright (1921, 1923, 1934) proposed a covariance decomposition for Cov(A, Y ) in terms of pathspecific coefficients in the context of linear models and in the absence of an intermediate confounder Z. An immediate consequence of the above results is that our covariance decomposition generalizes Wright\u2019s approach to a non-parametric model in the presence of intermediate confounding. Zhang and Bareinboim (2018) provide an alternative generalization that is unidentifiable in the presence of intermediate confounders Z.\nWe now present identification formulas for the probability distributions involved in computation of\nthe measures of causal influence of Definition 6.\nA2 (Overlap). For a fixed value a, assume the following hold for all w such that p(w) > 0:\n\u2022 p(z | a, w) > 0 implies p(z | a\u2032, w) > 0 for all a\u2032 such that p(a\u2032 | w) > 0.\n\u2022 p(m | z, a, w) > 0 implies p(m | z\u2032, a\u2032, w) > 0 for all (a\u2032, z\u2032, z) such that p(a\u2032 | w) > 0,\np(z | a, w) > 0, and p(z\u2032 | a, w) > 0.\n\u2022 p(m | z, a, w) > 0 implies p(m | z\u2032, a\u2032, w) > 0 for all (a\u2032, z\u2032, z) such that p(a\u2032 | w) > 0,\np(z | a\u2032, w) > 0, and p(z\u2032 | a\u2032, w) > 0.\nTheorem 6 (Identification of path-specific causal influence). Under the assumed SCM (A1) plus A2. the path-specific counterfactual distributions are identified as follows\nP(Y (0) S0 \u2264 y | A = a) = F(y | A = a), P(Y (0) S1 \u2264 y | A = a) = E [\u222b F(y | a\u2032, Z,M,W )dP(a\u2032 |W ) | A = a ] , P(Y (1) S1 \u2264 y | A = a) = E [\u222b F(y | a\u2032, z,M,W )dP(z | a,W )dP(a\u2032 | W ) | A = a ] , P(Y (1) S2 \u2264 y | A = a) = P(Y (2)S2 \u2264 y | A = a)\n= E\n[\u222b F(y | a\u2032, z,M,W )dP(z, a\u2032 | W ) | A = a ] ,\nP(Y (2) S3\n\u2264 y | A = a) = E [\u222b F(y | a\u2032, z,m,W )dP(m | a, z\u2032,W )dP(z | a\u2032,W )dP(z\u2032, a\u2032 |W ) | A = a ] ,\nP(Y (0) S3\n\u2264 y | A = a) = E [\u222b F(y | a\u2032, z,m,W )dP(m | a, z,W )dP(z, a\u2032 |W ) | A = a ] ,\nP(Y (0) S4 \u2264 y | A = a) = E [F(y | W ) | A = a] .\nAt this point it is important to note that the ideas of information transfer interventions discussed in this paper can also be used to obtain a decomposition of the average treatment effect into path-specific effects analogous to the decomposition of Theorem 4. We discuss such an extension in \u00a76 of the supplement.\nIn the following section, we discuss efficient non-parametric estimation of the covariance influence discussed in Example 1. Efficient non-parametric estimation of the other parameters discussed in this paper is also possible, but we defer the development of such estimators to future work."
        },
        {
            "heading": "6 Extension to path analysis using causal effects",
            "text": "This section presents results where we use the information transfer interventions introduced to construct a decomposition of the average effect of a binary treatment into path-specific effects that satisfy path-specific null criteria, analogous to the decomposition constructed for measures of causal influence. A decomposition of the ATE is important for questions that require an agency view of causality, as the ATE can be used to quantify the effect of a hypothetical but feasible intervention. The methods we present below decompose the ATE, which can have an agency interpretation of causality, into path-specific effects that do not correspond to an agency interpretation of causality. Readers interested in decompositions that have an agency interpretation are encouraged to consult the literature on so-called separable effects (e.g., Robins and Richardson, 2010; Stensrud et al., 2022a,b; Robins et al., 2022).4 Briefly, these works achieve identifiability of mediation parameters under an additional structural assumption stating that treatment/exposure can be separated into disjoint components whose effect operate independently through each of the different causal pathways. Agency interventions are then conceptualized on each separable component. Our goal in this section is to define mediation parameters for the common case where such structural information is unavailable, at the expense of abandoning the agency interpretation of the path-specific effects.\nConsider the ATE \u03c8 = E[Y (1)\u2212 Y (0)] introduced in \u00a73.1, and note that under our assumed SCM we have Y (a) = Y (a, Z(a),M(a, Z(a))). Then we could use the following counterfactuals to define path-specific effects:\nYS0 = Y (1, Z(1),M(1, Z(1))), YS1 = Y (0, Z(1),M(1, Z(1))), YS2 = Y (0, Z(0),M(1, Z(1))), (6) YS3 = Y (0, Z(0),M(1, Z(0))), YS4 = Y (0, Z(0),M(0, Z(0))),\n4Some of this work uses the expression \u201cinterventionist view of causality\u201d to refer to their methods. The expression \u201cagency view of causality\u201d would have been more appropriate as all counterfactual causal inference involves interventions.\nwhere the causal effect operating through path Pj is defined as E[YSj\u22121 \u2212 YSj ]. As before, the probability distribution of YS2 is not identified due to the recanting witness Z. However, we can achieve an effect decomposition into path-specific effects using information transfer interventions as follows. Let Za denote a random draw from the distribution of Z(a) conditional on W . Define\nY \u2032S1 = Y (0, Z(1),M(1, Z1)), Y \u2032S2 = Y (0, Z(0),M(1, Z1)), Y \u2032\u2032S2 = Y (0, Z0,M(1, Z(1))), Y \u2032\u2032S3 = Y (0, Z0,M(1, Z(0))),\nwhere, in comparison to the definitions in (6), we have emulate the information transferred through some paths by means of the random draws Z1 and Z0. For example, in Y \u2032 S2 , the effect of the action A = 1 operating through the path A = 1 \u2192 Z(1) \u2192 M \u2192 Y is emulated by the effect operating through a path A = 1 \u2192 Z1 \u2192 M \u2192 Y . This allows us to achieve the following identifiable effect decomposition:\nTheorem 7 (Decomposition of the average treatment effect into path-specific effects). Define the pathspecific causal effects as\n\u03c8P1 = E(YS0 \u2212 YS1) \u03c8P2 = E(Y \u2032 S1 \u2212 Y \u2032S2) \u03c8P3 = E(Y \u2032\u2032 S2 \u2212 Y \u2032\u2032S3) \u03c8P4 = E(YS3 \u2212 YS4),\nas well as the parameter\n\u03c8P2\u2228P3 = E(YS1 \u2212 Y \u2032S1 + Y \u2032S2 \u2212 Y \u2032\u2032S2 + Y \u2032\u2032S3 \u2212 YS3).\nThen we have the following decomposition of the average treatment effect \u03c8 = E(YS0 \u2212 YS4):\n\u03c8 = \u03c8P1 + \u03c8P2 + \u03c8P3 + \u03c8P4 + \u03c8P2\u2228P3.\nAs in the previous section, we have the following result showing that this decomposition of the\ntotal causal effect satisfies the path-specific null criterion:\nTheorem 8. The contrasts defined in Theorem 7 satisfy the path-specific sharp null criterion P5 with respect to each path Pj .\nFurthermore, in this case \u03c8P2\u2228P3 is also an effect operating through either A \u2192 Z \u2192 Y or A \u2192 Z \u2192 M \u2192 Y , which is equal to zero whenever there is no effect through at least one of these paths (e.g., if Z is not an intermediate confounder):\nProposition 3. Let U denote the range of U = (UW , UA, UZ , UM , UY ). Assume U can be partitioned in sets U1, U2, and U3 such that the following hold almost surely\n\u2022 Z(1) = Z(0) in U1, and\n\u2022 supz\u0304 |M(z1)\u2212 Z(z0)| = 0 in U2, and\n\u2022 supz\u0304 |Y (z1)\u2212 Y (z0)| = 0 in U3.\nThen \u03c8P2\u2228P3 = 0.\nIn order to present identification results for the above decomposition, we will require the following\noverlap assumption which guarantees that the functionals defined in Theorem 9 are well defined.\nA3 (Overlap assumption for decomposition of the ATE). Assume the following hold for all w such that p(w) > 0\n\u2022 p(a | w) > 0 for a \u2208 {0, 1}.\n\u2022 p(z | A = 1, w) > 0 implies p(z | A = 0, w) > 0.\n\u2022 p(m | A = 1, z\u2032, w) > 0 implies p(m | A = 0, z, w) > 0 for all (z, z\u2032) such that p(z | a\u2032, w) > 0\nand p(z\u2032 | a\u22c6, w) > 0 and for a\u2032, a\u22c6 \u2208 {0, 1}.\nTheorem 9 (Identification of the path-specific decomposition of the average treatment effect). AssumeA3. Then, for a\u2032 = 1 and a\u22c6 = 0, we have the following under the assumed SCM:\nE(YS0) = E{E(Y | a\u2032,W )},\nE(YS1) = E\n[\u222b E(Y | a\u22c6, z,m,W )dP(z,m | a\u2032,W ) ] ,\nE(Y \u2032S1) = E\n[\u222b E(Y | a\u22c6, z,m,W )dP(z | a\u2032,W )dP(m | a\u2032,W ) ] ,\nE(Y \u2032S2) = E(Y \u2032\u2032 S2 ) = E\n[\u222b E(Y | a\u22c6, z,m,W )dP(z | a\u22c6,W )dP(m | a\u2032,W ) ] ,\nE(Y \u2032\u2032S3) = E\n[\u222b E(Y | a\u22c6, z,m,W )dP(z | a\u22c6,W )dP(m | a\u2032, z\u2032,W )dP(z\u2032 | a\u22c6,W ) ] ,\nE(YS3) = E\n[\u222b E(Y | a\u22c6, z,m,W )dP(z | a\u22c6,W )dP(m | a\u2032, z,W ) ] ,\nE(YS4) = E{E(Y | a\u22c6,W )}.\nThe proofs of the results in this section follow steps identical to the proofs of the results in \u00a75, where we note that for binary A the causal influence parameter \u03b8 = Cov(A, Y \u2212YS) and the ATE \u03c8 = E[Y (1)\u2212 Y (0)] are connected through the relation \u03b8 = E{p(W )2(1 \u2212 p(W ))2E[Y (1)\u2212 Y (0) | W ]}, for p(w) = P(A = 1 | W = w)."
        },
        {
            "heading": "7 Efficient estimation of the path-specific influence using the co-",
            "text": "variance contrast\nIn this section we discuss estimation of the covariance parameters presented in Example 1, and specifically the causal influence decomposition in (5). Note that, to estimate these covariances, it will be sufficient to construct an estimator of the parameter \u03c4kj = E[f(A)Y (k) Sj ] for a general function f . Applications to f(A) = A and f(A) = 1 will allow us to obtain estimates of E[AY (k) Sj ] and E[Y (k) Sj ], which together with E[A] constitute the basis for computing the covariance parameters E[AY (k) Sj ]\u2212E[A]E[Y (k)Sj ].\nNote also that estimation of E[f(A)Y (0) S0 ] = E[f(A)Y ] and E[A] is straightforward by means of empirical averages. Thus, in the remaining of this section we focus on estimation of \u03c4kj for (k, j) \u2208 {(0, 1), (1, 1), (1, 2), (2, 3), (0, 3), (0, 4)}. For the sake of simplicity, we pursue estimators assuming that A, Z, and M are discrete random variables, although some of the efficiency theory results of this section such as Theorem 10 and the efficiency bound hold for arbitrary variables.\nThe identification formulas in Theorem 6 provide a relatively easy approach to obtain estimators of \u03c4kj . For example, given any regression estimate of E[Y | A = a,M = m,Z = z,W = w] and an estimate of the probabilities P(M = m,Z = z, A = a | W = w), an estimator may be constructed by plugging in these estimates in the identification formulas. If the models for these regression and probabilities are parametric and correctly specified, a maximum likelihood plug-in estimation strategy is optimal in the sense that the estimators converge to the optimal normal distribution at \u221a n-rate. However, if the model is non-parametric, a plug-in estimation strategy results in first-order bias, which must be corrected.\nThe general methods to characterize this first-order bias are rooted in semi-parametric estimation theory (e.g., von Mises, 1947; Begun et al., 1983; Bickel et al., 1997; van der Vaart, 1998; Robins et al., 2009), and in the theory for doubly robust estimation using estimating equations (Robins, 2000; Robins et al., 1994; van der Laan and Robins, 2003; Bang and Robins, 2005). Under this theory, the first-order bias is characterized in terms of the so-called canonical gradient. This canonical gradient also characterizes the efficiency bound in the non-parametric model, and is therefore also known as the efficient influence function. Importantly, knowledge of the canonical gradient allows the development of estimators under slow convergence rates for the nuisance parameters involved. This is important because flexible regression and estimation methods involving model selection must be used when the model is non-parametric, and those flexible estimation methods often fail to be consistent at parametric rate, though they may be consistent at slower rates.\nThe following theorem illustrates the sense in which general plug-in estimators are biased in the non-parametric model, and provides a characterization of the bias in terms of the canonical gradient \u03d5kj . The specific formulas of the gradient for each duple (k, j) are useful to construct the estimators, but they are cumbersome and somewhat uninformative, so we relegate their presentation to the\nsupplementary materials.\nTheorem 10 (First order von-Mises expansion). Let \u03c4kj (G) denote the \u03c4 k j parameter evaluated at a distribution G. Then, for any pair of distributions P and G, we have the following:\n\u03c4kj (G)\u2212 \u03c4kj (P) = \u2212EP[\u03d5kj (X ;G)] +Rkj (G,P),\nwhere Rkj (G,P) is a second-order term of the form\nRkj (G,P) = \u2211\nl\n\u222b\n\u03c9(G,P){\u03bal(G)\u2212 \u03bal(P)}{\u03bdl(G)\u2212 \u03bdl(P)}dP,\nfor functionals \u03c9, \u03ba, and \u03bd that vary with (i, k). The specific form of each canonical gradient \u03d5kj and second order term Rkj (G,P) is given in the supplement.\nAn application of the above theorem with G equal to an estimate P\u0302 of the true probability distribution P reveals that a plug-in estimation strategy is generally biased in first-order, and provides a representation of the bias as \u2212EP[\u03d5kj (X ; P\u0302)]. Importantly, this theorem also provides an avenue to correct for this first order bias. Specifically, the first order bias may be estimated through the empirical average of \u03d5kj (Xj ; P\u0302) across observations i. If this bias is added back to the plug-in estimator \u03c4 k j (P\u0302), one would expect that the resulting estimator is unbiased in first-order. This idea is formalized below in Theorem 11.\nThe canonical gradient and the above reasoning are at the center of several recent estimation methods that leverage machine learning and flexible regression, such as the targeted learning framework (van der Laan and Rubin, 2006; van der Laan and Rose, 2011, 2018), and double machine learning (Chernozhukov et al., 2018). An important feature of these approaches is the use of cross-fitting, which will allow us to obtain n1/2-convergence of our estimators while avoiding entropy conditions that may be violated by data adaptive estimators of the nuisance parameters (Zheng and van der Laan, 2011; Chernozhukov et al., 2018). Let P1, . . . ,PV denote a random partition of the data set into V prediction sets of approximately the same size. That is, Pv \u2282 {1, . . . , n}; \u22c3J j=1Pv = D; and Pv\u2229Pv\u2032 = \u2205. In addition, for each v, the associated training sample is given by Tv = D \\ Pv.\nOur proposed estimator only requires estimation of the conditional expectation of Y given (M,Z,A,W ),\nwhich will be denoted by m, the probability mass function of M given (Z,A,W ), denoted by pM , the probability mass function of Z given (A,W ), denoted by pZ , and the probability mass function of A given W , denoted by pA. Let \u03b7 = (m, pM , pZ , pZ), and note that the canonical gradients \u03d5 k j can be written as functions \u03d5kj (X ; \u03b7). Let v(i) denote the prediction set to which observation i belongs, and let \u03b7\u0302v(i) denote an estimator of \u03b7 obtained using training data Tv(i). Then, the estimator of \u03c4kj is defined as\n\u03c4\u0302kj = 1\nn\nn\u2211\ni=1\n\u03d5\u0304(Xj , \u03b7\u0302v(i)),\nwhere \u03d5\u0304 is the uncentered canonical gradient given in the supplementary materials.\nThe following theorem provides the conditions under which the above estimator is expected to be\nefficient and asymptotically normal:\nTheorem 11 (Asymptotic linearity of the proposed estimator). Assume that Rkj (\u03b7\u0302, \u03b7) = oP(n \u22121/2) and that\n\u2022 P{pM(M = m | A,Z,W ) < cM} = P{p\u0302M(M = m | A,Z,W ) < cM} = 1 for a constant cM and for all m,\n\u2022 P{pZ(Z = z | A,W ) < cZ} = P{p\u0302Z(Z = z | A,W ) < cZ} = 1 for a constant cZ , and that\n\u2022 P{pA(A = a |W ) < cA} = P{p\u0302A(A = a | W ) < cA} = 1 for a constant cA and for all a.\nThen\n\u03c4\u0302kj \u2212 \u03c4kj = 1\nn\nn\u2211\ni=1\n\u03d5kj (Xi; \u03b7) + oP(n \u22121/2).\nThe proof of this theorem is sketched in the supplementary materials. The arguments are standard in the analysis of estimators in the targeted learning and double machine learning frameworks. The above theorem implies that an estimator \u03b8\u0302Pj of \u03b8Pj constructed through an application of the above estimator to f(A) = A and f(A) = 1 is also asymptotically linear. An application of the Delta method and the central limit theorem then yields\nn1/2(\u03b8\u0302Pj \u2212 \u03b8Pj ) N(0, \u03c32),\nwhere \u03c32 is the non-parametric efficiency bound, which allows the construction of Wald-type confidence intervals."
        },
        {
            "heading": "8 Illustrations using real data",
            "text": "In this section we apply the covariance path-specific decomposition analysis proposed in the previous section to estimating path-specific causal relations in two examples using publicly available data. In the first example, we re-analyze the data from a recent study examining gender differences in wage expectations among students at two Swiss institutions of higher education (Fernandes et al., 2021). In the second example, we re-analyze data from a nationally representative randomized experiment on how the framing of media discourse shapes public opinion and immigration policy (Brader et al., 2008). The datasets are publicly available in the causalweight (Bodory and Huber, 2021) and mediation (Tingley et al., 2014) R packages, respectively. Code to reproduce our analyses is available at https://github.com/idiazst/causal_influence. All nuisance parameters were estimated with extreme gradient tree boosting where the hyperparameters are chosen from a random grid of size 100 using the caret (Kuhn, 2021) library in R."
        },
        {
            "heading": "8.1 Gender differences in wage expectations",
            "text": "In this study, the authors administered a survey to 804 students at the University of Fribourg and the University of Applied Sciences in Bern in the year 2017. The survey contained a number of questions regarding wage expectations, as well as a number of variables related to wages such as the study program (business, economics, communication, and business informatics), job or educational plans after finishing the studies, the intended industry (trade, transport, hospitality, communication, finance, etc.), as well as other variables such as the age, parents education, nationality, and home ownership. We study the causal relation between gender (A) and wage expectations three years after graduation (Y ) study program (Z) and whether a student plans to continue obtaining further education or work full time after graduation (M) as mediators. The outcome Y is recorded in a scale of 0-16, where 0 means less than 3500 Swiss Franc (CHF) gross per month, 1 means 3500-4000 CHF, 2=4000-4500 CHF, etc., and 16=more than 11000 CHF. For simplicity and illustration purposes we treat Y as a\nnumerical variable.\nThe results of our analysis are presented in Table 2. We conclude that most of the influence of gender on wages expectation 3 years after graduation operates through pathways independent of degree and plans after study, which is a result similar to the original result of Fernandes et al. (2021). Unlike the results in Fernandes et al. (2021), which decompose the average treatment effect into direct and indirect effects, the interpretation of the estimates in Table 2 do not require to interpret hypothetical and infeasible interventions that would modify someone\u2019s gender. Instead, we compute the causal covariance between gender and wage expectations \u03b8, and decompose it into path-specific covariances."
        },
        {
            "heading": "8.2 Media discourse and public opinion and immigration policy",
            "text": "In this study, the authors examine whether and how elite discourse affects public opinion and action on immigration policy. They conducted a randomized experiment in which 265 subjects are exposed to different media stories about immigration. They employed a 2\u00d7 2 design in which they manipulate ethnic cues by altering the picture and name of an immigrant featured in a hypothetical New York Times story (white European vs Latin American). They also manipulate the tone of the story, focusing on whether positive or negative consequences of immigration, as well as conveying positive or negative attitudes of governors and other citizens towards immigration. Our treatment variable A will take values 0, 1, or 2, with 0 denoting a positive story about a white European, 1 denoting a negative story about a white European immigrant or a positive story about a Latin American immigrant, and 2 denoting a negative story about a Latin American immigrant. The authors also collected information on age, education, gender, and income of the study participants, which we denote with W . A major\nhypothesis of the study was that anxiety and is an important mediator of the causal influence of the framing of the story on negative attitude towards immigration. Anxiety M was measured using a numerical scale from 3 to 12 where 3 indicates the most negative feeling. Perceived harm Z caused by immigration was also measured in a scale between 2 and 8. The outcome of interest Y is a four-point scale measuring a subject\u2019s attitude towards increased immigration where larger values indicate more negative attitudes.\nThe results of the analysis are presented in Table 3. These results largely agree with the results of the original research article, with the difference that these analyses provide more nuance in the sense that most of the influence of the framing of the story on negative attitudes towards immigration is mediated directly by anxiety through pathways that do not involve perceived harm from immigration."
        },
        {
            "heading": "9 Discussion",
            "text": "Our proposed approach to measuring causal influence by information transfer interventions can be used in algorithmic fairness. As an example, consider the methods proposed by Nabi et al. (2019) to learn fair optimal treatment policies. Their approach to fairness relies on constructing a distribution where undesirable causal pathways are \u201cremoved\u201d and then learning optimal treatment policies with respect to this fair but unobserved distribution. Their approach to estimating a fair distribution relies on measuring the path-specific effects, and then finding the closest (e.g., in KL-divergence) distribution to the observed data distribution under the constraint that these path-specific effects are null. Because our proposed path-specific measures satisfy sharp null criteria, the approach of Nabi et al. (2019) to fairness could be adapted to use our proposed path-specific effects to learn fair distributions.\nOur proposal also shares connections to the general theory of causal interventions presented by Shpitser and Tchetgen Tchetgen (2016). In their work, the authors generalize and unify many interesting targets of causal inference through the use of so-called edge- and path-interventions, defined as interventions on the source node of the edge or path, where the intervention operates only for the purpose of the specific outgoing path. Our approach to achieving identification of path-specific causal influence and path-specific causal effects also entails a type of path-intervention. The difference with the approach of Shpitser and Tchetgen Tchetgen (2016) is that we do not restrict the path-intervention to the source node, but instead intervene on nodes in the other positions in the path. Specifically, by allowing path-interventions to be defined in terms of the recanting witness node, we are able to define path-specific effects which are non-parametrically identifiable. A general theory for path-intervention that allow for interventions on nodes other than the source node seems to be an important direction of future work. The interventions we propose also share connections with the interventions proposed by Malinsky (2018). These general \u201cmacro-level\u201d interventions focus on hypothetical worlds where the structural equations had been replaced for alternative, user-given equations. Some of our information transfer interventions can be interpreted in this way, for example by noticing that the distribution of the outcome in a hypothetical world where we set A = A is equal to the distribution of the outcome where the argument a is marginalized out from the structural function fA, where the marginalization is with respect to the distribution P(a |W ).\nOur discussion centers around a structural definition of causal influence interpreted as the strength of dependence of the structural functions on their arguments (see, e.g., Definition 1) This criterion for causal influence may be too strong in some cases. For example Sprenger (2018) argues for a probabilistic rather than structural definition of causal influence. We conjecture that our proposed measures of causal influence would also satisfy probabilistic null criteria, but leave the proof of those results to future work.\nCompared to the natural direct and indirect effects available in the literature, our proposal allows for the definition of parameters that are identified in the presence of a recanting witness. While changing the inferential target allowed us to bypass the recanting witness problem, this strategy comes at a price. Specifically, our parameters do not exactly decompose the total effect/influence into path-specific pa-\nrameters. As detailed in Theorem 4, the decomposition we obtain involves an extra parameter that is equal to zero only in the absence of a recanting witness.\nLastly, there are multiple interesting directions for future work that build on the ideas presented in this paper. The first is that the order of the decomposition we pursue where we proceed sequentially by intervening on the paths P1, P2, P3, and P4 is arbitrary. Other orderings for these paths can also be considered and may be of more practical relevance in certain applications. The second is that the ideas we present can be generalized to construct path-specific effects for multiple ordered mediators and for situations with time-varying treatments, mediators, and covariates. The definition of path-specific parameters that measure causal influence in those settings remains an open problem. Furthermore, estimation of existing mediational parameters such as interventional effects is notoriously hard in longitudinal settings (see e.g., D\u0131\u0301az et al., 2022b) and we believe the ideas introduced in this article can be useful to solve problems in that setting."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was supported through a Patient-Centered Outcomes Research Institute (PCORI) Project Program Award (ME-2021C2-23636-IC)."
        },
        {
            "heading": "1 Proofs of results in the paper",
            "text": ""
        },
        {
            "heading": "1.1 Proposition 1",
            "text": "Proof Assume without loss of generality that E(A) = 0. This follows from application of Lemma 2 below to X = A, L = (W,UM , UZ , UY ) and\nf(X,L) = fY (W,A, fZ(W,A,UZ), fM (W,A, fZ(W,A,UZ), UM ), UY ),\nafter noticing that P(A | W,UM , UZ , UY ) = P(A | W ) by assumption of the NPSEM, and that E[X(f(X,L)\u2212 E(f(X,L) | L)) = Cov(A,Y \u2212 \u222b Y (a)dP(a | W )) = Cov(A,Y \u2212 Y (A)).\nLemma 1. Let (X,L) \u223c P any random variables, and let f(x, y) be a function such that f(\u00b7, y) is increasing for all y. Assume that E(X) = 0. Define (\u03c1, \u03b2) = argminR(g, b), where\nR(g, b) = E[f(X,L) \u2212 g(L)\u2212 bX]2. *corresponding author: ivan.diaz@nyu.edu\nThen \u03b2 \u2265 0. Likewise, if f(\u00b7, y) is decreasing for all y, then \u03b2 \u2264 0.\nProof By standard arguments of projections in L2(P ) spaces, it can be seen that \u03c1(L) = E[f(X,L)\u2212bX | L]\nfor any b. This yields\nR(\u03c1, \u03b2) = E{[f(X,L) \u2212 E(f(X,L)|L)]2}\n\u2212 2\u03b2E{(X \u2212 E(X | L))(f(X,L) \u2212 E[f(X,L) | L])} + \u03b22E[E2(X | L)] = E{[f(X,L) \u2212 E(f(X,L)|L)]2} \u2212 2\u03b2E{(X \u2212 E(X | L))(f(X,L) \u2212 f(E(X | L), L))} + \u03b22E[E2(X | L)],\nwhere the second equality follows by adding and subtracting f(E(X | L), L) to the second factor of the second term. By monotonicity, the term (X \u2212 E(X | L))(f(X,L) \u2212 f(E(X | L), L) is positive everywhere. Thus, if \u03b2 < 0, then R(\u03c1, |\u03b2|) < R(\u03c1, \u03b2), contradicting the definition of \u03b2 and proving the lemma.\nWe also have the following general result\nLemma 2. Let (X,L) \u223c P any random variables, and let f(x, y) be a function such that f(\u00b7, y) is increasing for all y. Then E[X(f(X,L) \u2212 E(f(X,L) | L))] \u2265 0.\nProof Continuing with the definition of \u03b2 in the above lemma, notice that E(X2)\u03b2 = E[X(f(X,L) \u2212\nE(f(X,L) | L))], which proves the result."
        },
        {
            "heading": "1.2 Theorem 2",
            "text": "Proof We have\nP(YS \u2264 y | A = a) = \u222b P(YS \u2264 y | A = a\u2032,W = w,A = a)dPS(a\u2032, w | A = a)\n=\n\u222b\nP(Y (a\u2032) \u2264 y | W = w,A = a)dP(a\u2032 | W = w)dP(w | A = a)\n=\n\u222b\nP(Y (a\u2032) \u2264 y | W = w,A = a\u2032)dP(a\u2032 | W = w)dP(w | A = a)\n= \u222b P(Y \u2264 y | W = w,A = a\u2032)dP(a\u2032 | W = w)dP(w | A = a)\n=\n\u222b\nP(Y \u2264 y | W = w)dP(w | A = a),\nThe first line follows by the law of iterated expectation, the second line by independence of A on all other data conditional on W and by the fact that A is distributed as A conditional on W , the third line follows by the assumption of the theorem, the fourth line because Y (a\u2032) = Y in the event A = a\u2032, and the last line by definition."
        },
        {
            "heading": "1.3 Theorem 3",
            "text": "Proof The proof of Theorem 3 proceeds as follows. We will prove the statement of the Theorem for each contrast of path separately.\n1. For P1, assume that P{supa\u0304 |Y (a1, Z(a2),M(a3, Z(a4))) \u2212 Y (a0, Z(a2),M(a3, Z(a4)))| = 0} = 1.\nThen we have\nY (0) S0 = Y (A,Z(A),M(A,Z(A))) = Y (A,Z(A),M(A,Z(A))) = Y (0) S1\nalmost surely, where the second equality follows by assumption.\n2. For P2, assume that P{supa\u0304,m\u0304 |Y (a1, Z(a2),M(a3, Z(a4))) \u2212 Y (a1, Z(a0),M(a3, Z(a4)))| = 0} = 1.\nThen we have\nP(Y (1) S2 \u2264 y | A = a) = P[Y (1)S2 \u2264 y | U \u2208 U1, A = a]P(U \u2208 U1 | A = a)\n+ P[Y (1) S2 \u2264 y | U \u2208 U2, A = a]P(U \u2208 U2 | A = a),\nwhere U1 and U2 are the sets of the first statement of Lemma 3 given below. We have\nY (1) S2 = Y (A,Z(A),M(A,ZA)) = Y (A,Z(A),M(A,ZA)) = Y (1) S1\na.s. in the event U \u2208 U1. We also have Z(A) = Z(A) a.s., and therefore Y (1)S2 = Y (1) S1 in the event U \u2208 U2. 3. For P3, assume that P{supa\u0304,m\u0304 |Y (a1, Z(a2),M(a3, Z(a4))) \u2212 Y (a1, Z(a2),M(a3, Z(a0)))| = 0} = 1.\nThen we have\nP(Y (2) S3 \u2264 y | A = a) = P[Y (2)S3 \u2264 y | U \u2208 U1, A = a]P(U \u2208 U1 | A = a)\n+ P[Y (2) S3 \u2264 y | U \u2208 U2, A = a]P(U \u2208 U2 | A = a) + P[Y (2) S3 \u2264 y | U \u2208 U3, A = a]P(U \u2208 U3 | A = a),\nwhere U1, U2 and U3 are the sets of the second statement of Lemma 3. We have\nY (2) S3 = Y (A,ZA,M(A,Z(A))) = Y (A,ZA,M(A,Z(A))) = Y (2) S2\na.s. in the event U \u2208 U1. We also have M(A,Z(A)) = M(A,Z(A)) a.s. in the event U \u2208 U2, and therefore Y (2) S3 = Y (2) S2 . Lastly, in the event U \u2208 U3 we have Z(A) = Z(A) a.s., and therefore Y (2) S3 = Y (2) S2 . 4. For P4, assume that P{supa\u0304,m\u0304 |Y (a1, Z(a2),M(a3, Z(a4))) \u2212 Y (a1, Z(a2),M(a0, Z(a4)))| = 0} = 1.\nThen we have\nP(Y (0) S4 \u2264 y | A = a) = P[YS4 \u2264 y | U \u2208 U1, A = a]P(U \u2208 U1 | A = a)\n+ P[YS4 \u2264 y | U \u2208 U2, A = a]P(U \u2208 U2 | A = a),\nwhere U1 and U2 and U3 are the sets of the third statement of Lemma 3. We have\nY (0) S4 = Y (A,Z(A),M(A,Z(A))) = Y (A,Z(A),M(A,Z(A))) = Y (0) S3\na.s. in the event U \u2208 U1. We also have M(A,Z(A)) = M(A,Z(A)) a.s. in the event U \u2208 U2, and therefore Y (0) S4 = Y (0) S3 ."
        },
        {
            "heading": "1.4 Theorem 5",
            "text": "Proof The proof of this result follows steps analogous to those in the proof of Proposition 1. Therefore, we will only sketch the arguments of the proof for P2. Assume E(A) = 0 and that Y (a1, Z(a2),M(a4, Z(a3))) is\nincreasing in a2 for all (a1, a3, a4, uY , w). This implies that Y (a1, Z(a2),M(a4, z)) is increasing in a2 for all (a1, z, a4, uY , w). Define vY = (uY , uM , uZ), and let (\u03c1, \u03b2P2) = argminLP2(r, b), where\nLP2(r, b) = E{Y (A\u0304, Z(A),M(A,ZA))\u2212 r(W,M(A,ZA), VY )\u2212 bA}2\nBy Lemma 1, \u03b2P2 \u2265 0. The proposition follows because, as before, E[Var(A | W )]\u03b2P2 = \u03b8P2 , and therefore \u03b8P2 and \u03b2P2 have the same sign."
        },
        {
            "heading": "1.5 Theorem 6",
            "text": "Proof We will prove the results for each random variable at a time. First, note that\nP(Y (0) S1 \u2264 y | A = a) =\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | A = a, Z(a) = z,M(a, z) = m,W = w,A = a\u2032]\u00d7\ndP(a\u2032 | w)dP(Z(a) = z | a,w)dP(M(a, z) = m | Z(a) = z, a, w)dP(w | a)\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | A = a,W = w]dP(a\u2032 | w)dP(z | a,w)dP(m | z, a, w)dP(w | a)\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | a\u2032, z,m,w]dP(a\u2032 | w)dP(z | a,w)dP(m | z, a, w)dP(w | a)\n=\n\u222b\nP[Y \u2264 y | a\u2032, z,m,w]dP(a\u2032 | w)dP(z | a,w)dP(m | z, a, w)dP(w | a),\nwhere the first equality follows by law of iterated expectation, the second one by the independence assumptions on the errors U and definition of counterfactuals M(a, z) and Z(a), and the fourth one by definition of the counterfactual Y (a, z,m). Note that, to simplify notation, we removed the random variables from the right hand side of the | symbol in the above probabilities.\nWe also have\nP(Y (1) S1 \u2264 y | A = a) =\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | A = a, Z(a) = z,M(a, z\u2032) = m,W = w,ZA = z\u2032, A = a\u2032]\u00d7 dP(a\u2032 | w)dP(Z(a) = z | a,w)dP(M(a, z\u2032) = m | Z(a) = z, a, w)dP(z\u2032 | a,w)dP(w | a)\n= \u222b P[Y (a\u2032, z,m) \u2264 y | A = a,W = w]dP(a\u2032 | w)dP(z | a,w)dP(m | z\u2032, a, w)dP(z\u2032 | a,w)dP(w | a)\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | a\u2032, z,m,w]dP(a\u2032 | w)dP(z | a,w)dP(m | z\u2032, a, w)dP(z\u2032 | a,w)dP(w | a)\n=\n\u222b\nP[Y \u2264 y | a\u2032, z,m,w]dP(a\u2032 | w)dP(z | a,w)dP(m | a,w)dP(w | a).\nFurthermore,\nP(Y (1) S2 \u2264 y | A = a) =\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | A = a, Z(a\u2032) = z,M(a, z\u2032) = m,W = w,ZA = z\u2032, A = a\u2032]\u00d7 dP(a\u2032 | w)dP(z\u2032 | a,w)dP(M(a, z\u2032) = m | Z(a\u2032) = z, a, w)dP(Z(a\u2032) = z | a,w)dP(w | a)\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | A = a,W = w]dP(a\u2032 | w)dP(z\u2032 | a,w)dP(m | z\u2032, a, w)dP(z | a\u2032, w)dP(w | a)\n=\n\u222b\nP[Y \u2264 y | a\u2032, z,m,w]dP(a\u2032 | w)dP(z\u2032 | a,w)dP(m | z\u2032, a, w)dP(z | a\u2032, w)dP(w | a)\n=\n\u222b\nP[Y \u2264 y | a\u2032, z,m,w]dP(a\u2032 | w)dP(m | a,w)dP(z | a\u2032, w)dP(w | a)\n=\n\u222b\nP[Y \u2264 y | a\u2032, z,m,w]dP(z, a\u2032 | w)dP(m,w | a)\nand,\nP(Y (2) S2 \u2264 y | A = a) =\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | A = a, Z(a) = z\u2032,M(a, z\u2032) = m,W = w,ZA = z,A = a\u2032]\u00d7 dP(a\u2032 | w)dP(z | a\u2032, w)dP(M(a, z\u2032) = m | Z(a) = z\u2032, a, w)dP(Z(a) = z\u2032 | a,w)dP(w | a)\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | A = a,W = w]dP(a\u2032 | w)dP(z | a\u2032, w)dP(m | z\u2032, a, w)dP(z\u2032 | a,w)dP(w | a)\n=\n\u222b\nP[Y \u2264 y | a\u2032, z,m,w]dP(a\u2032 | w)dP(z | a\u2032, w)dP(m | z\u2032, a, w)dP(z\u2032 | a,w)dP(w | a)\n=\n\u222b\nP[Y \u2264 y | a\u2032, z,m,w]dP(z, a\u2032 | w)dP(m,w | a)\nIn addition,\nP(Y (2) S3 \u2264 y | A = a) =\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | A = a, Z(a\u2032) = z\u2032,M(a, z\u2032) = m,W = w,ZA = z,A = a\u2032]\u00d7 dP(z | a\u2032, w)dP(M(a, z\u2032) = m | Z(a\u2032) = z\u2032, a, w)dP(Z(a\u2032) = z\u2032 | a,w)dP(a\u2032 | w)dP(w | a)\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | A = a,W = w]dP(z | a\u2032, w)dP(m | z\u2032, a, w)dP(z\u2032 | a\u2032, w)dP(a\u2032 | w)dP(w | a)\n=\n\u222b\nP[Y \u2264 y | a\u2032, z,m,w]dP(z | a\u2032, w)dP(m | z\u2032, a, w)dP(z\u2032 | a\u2032, w)dP(a\u2032 | w)dP(w | a),\nAs well as,\nP(Y (0) S3 \u2264 y | A = a) =\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | A = a, Z(a\u2032) = z,M(a, z) = m,W = w,A = a\u2032]\u00d7\ndP(a\u2032 | w)dP(M(a, z) = m | Z(a\u2032) = z, a, w)dP(Z(a\u2032) = z | a,w)dP(w | a)\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | A = a,W = w]dP(a\u2032 | w)dP(m | z, a, w)dP(z | a\u2032, w)dP(w | a)\n=\n\u222b\nP[Y \u2264 y | a\u2032, z,m,w]dP(a\u2032 | w)dP(m | z, a, w)dP(z | a\u2032, w)dP(w | a)\n=\n\u222b\nP[Y \u2264 y | a\u2032, z,m,w]dP(z, a\u2032 | w)dP(m | z, a, w)dP(w | a),\nLastly,\nP(Y (0) S4 \u2264 y | A = a) =\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | A = a, Z(a\u2032) = z,M(a\u2032, z) = m,W = w,A = a\u2032]\u00d7\ndP(a\u2032 | w)dP(M(a\u2032, z) = m | Z(a\u2032) = z, a, w)dP(Z(a\u2032) = z | a,w)dP(w | a)\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | A = a,W = w]dP(a\u2032 | w)dP(m | z, a\u2032, w)dP(z | a\u2032, w)dP(w | a)\n=\n\u222b\nP[Y (a\u2032, z,m) \u2264 y | m,a, z, w]dP(a\u2032 | w)dP(m | z, a\u2032, w)dP(z | a\u2032, w)dP(w | a)\n=\n\u222b\nP[Y \u2264 y | m,a\u2032, z, w]dP(a\u2032 | w)dP(m | z, a\u2032, w)dP(z | a\u2032, w)dP(w | a)\n=\n\u222b\nP[Y \u2264 y | w]dP(w | a)."
        },
        {
            "heading": "1.6 Proposition 2",
            "text": "First, note that in the event U \u2208 U1 we have Y (0)S1 = Y (0) S3 , Y (2) S2 = Y (2) S3 , and Y (1) S1 = Y (1) S2 . In the event U \u2208 U2 we have Y\n(0) S1 = Y (1) S1 , Y (2) S2 = Y (2) S3 , and Y (1) S2 = YS3 . Furthermore, in the event U \u2208 U3 we have Y (0) S1 = Y (2) S2 ,\nY (1) S1 = Y (1) S2 , and Y (2) S3 = Y (0) S3 .\nWe have\nD(P (0) S1 ,P (1) S1 ) = D(P (0) S3 (\u00b7 | U1),P(1)S2 (\u00b7 | U1))P(U1) (7)\n+D(P (2) S2 (\u00b7 | U3),P(1)S2 (\u00b7 | U3))P(U3). (8)\nD(P (1) S2 ,P (2) S2 ) = D(P (1) S2 (\u00b7 | U1),P(2)S3 (\u00b7 | U1))P(U1) (9)\n+D(P (0) S3 (\u00b7 | U2),P(2)S3 (\u00b7 | U2))P(U2) (10) +D(P (1) S2 (\u00b7 | U3),P(2)S2 (\u00b7 | U3))P(U3). (11)\nD(P (2) S3 ,P (0) S3 ) = D(P (2) S3 (\u00b7 | U1),P(0)S3 (\u00b7 | U1))P(U1) (12)\n+D(P (2) S3 (\u00b7 | U2),P(0)S3 (\u00b7 | U2))P(U2). (13)\nBy the assumptions of the lemma we have (7)+(9)+(12) = 0, (8)+(11) = 0, and (10)+(13) = 0, concluding the proof of the lemma."
        },
        {
            "heading": "2 Theorem 10",
            "text": "We first give the form of the canonical gradients, and then prove the result. The canonical gradients are given by \u03d5 (k) j (X;P) = \u03d5\u0304 (0) 1 (X;P) \u2212 \u03c4kj (P), where\n\u03d5\u0304 (0) 1 (X;P) =\nh (0) 1 (M,Z,W )\np(M,Z | A,W ){Y \u2212 E(Y | A,Z,M,W )}\n+\n\u222b\nf(a)E(Y | A, z,m,W )dP(m, z, a | W )\n\u2212 \u222b f(a)E(Y | a\u2032, z,m,W )dP(m, z, a | W )dP(a\u2032 | W )\n+ f(A)\n\u222b\nE(Y | a\u2032, Z,M,W )dP(a\u2032 | W )\n\u03d5 (1) 1 (X;P) =\nh (1) 1 (M,Z,W )\np(M,Z | A,W ){Y \u2212 E(Y | A,Z,M,W )}\n+ \u222b f(a)E(Y | A, z,m,W )dP(m | a,W )dP(z | a,W )dP(a | W ) \u2212 \u222b f(a)E(Y | a\u2032, z,m,W )dP(m | a,W )dP(z | a,W )dP(a | W )dP(a\u2032 | W )\n+ f(A)\n\u222b\nE(Y | a\u2032, Z,m,W )dP(m | A,W )dP(a\u2032 | W )\n\u2212 f(A) \u222b E(Y | a\u2032, z,m,W )dP(m | A,W )dP(z | A,W )dP(a\u2032 | W )\n+ f(A)\n\u222b\nE(Y | a\u2032, z,M,W )dP(z | A,W )dP(a\u2032 | W )\n\u03d5\u0304 (1) 2 (X;P) =\nh (1) 2 (M,W )\np(M | Z,A,W ){Y \u2212 E(Y | A,Z,M,W )}\n+\n\u222b\nf(a)E(Y | A,Z,m,W )dP(m | a,W )dP(a | W )\n\u2212 \u222b f(a)E(Y | a\u2032, z,m,W )dP(m | a,W )dP(a | W )dP(z, a\u2032 | W )\n+ f(A)\n\u222b\nE(Y | a\u2032, z,M,W )dP(z, a\u2032 | W )\n\u03d5\u0304 (2) 3 (X;P) =\nh (2) 3 (M,A,W )\np(M | Z,AW ){Y \u2212 E(Y | A,Z,M,W )}\n+\n\u222b\nf(a)E(Y | A,Z,m,W )dP(m | a, z\u2032,W )dP(z\u2032 | A,W )dP(a | W )\n\u2212 \u222b f(a)E(Y | a\u2032, z,m,W )dP(m | a, z\u2032,W )dP(z\u2032 | a\u2032,W )dP(z | a\u2032,W )dP(a | W )dP(a\u2032 | W ) + f(A)\np(Z | A,W )\n\u222b\nE(Y | a\u2032, z,M,W )dP(z | a\u2032,W )p(Z | a\u2032,W )dP(a\u2032 | W )\n\u2212 f(A) p(Z | A,W )\n\u222b\nE(Y | a\u2032, z,m,W )dP(m | A,Z,W )dP(z | a\u2032,W )p(Z | a\u2032,W )dP(a\u2032 | W )\n+\n\u222b\nf(a)E(Y | A, z,m,W )dP(z | A,W )dP(m | a, Z,W )dP(a | W )\n\u2212 \u222b f(a)E(Y | A, z,m,W )dP(m | a, z\u2032,W )dP(z | A,W )dP(z\u2032 | A,W )dP(a | W )\n+ f(A)\n\u222b\nE(Y | a\u2032, z,m,W )dP(m | A, z\u2032,W )dP(z | a\u2032,W )dP(z\u2032 | a\u2032,W )dP(a\u2032 | W )\n\u03d5\u0304 (0) 3 (X;P) =\nh (0) 3 (M,Z,W )\np(M | Z,A,W ){Y \u2212 E(Y | A,Z,M,W )}\n+ f(A)\np(Z | A,W )\n\u222b\nE(Y | a\u2032, Z,M,W )p(Z | a\u2032,W )dP(a\u2032 | W )\n+ f(A)\np(Z | A,W )\n\u222b\nE(Y | a\u2032, Z,m,W )dP(m | A,Z,W )p(Z | a\u2032,W )dP(a\u2032 | W )\n+\n\u222b\nf(a)E(Y | A,Z,m,W )dP(m | a, Z,W )dP(a | W )\n\u2212 \u222b f(a)E(Y | a\u2032, z,m,W )dP(m | a, z,W )dP(z | a\u2032,W )dP(a | W )dP(a\u2032 | W )\n+ f(A)\n\u222b\nE(Y | a\u2032, z,m,W )dP(m | A, z,W )dP(z | a\u2032,W )dP(a\u2032 | W )\n\u03d5\u0304 (0) 4 (X;P) = h (0) 4 (W ){Y \u2212 E(Y | W )}+ f(A)E(Y | W )\nwhere\nh (0) 1 (M,Z,W ) =\n\u222b\nf(a)p(M,Z | a,W )dP(a | W )\nh (1) 1 (M,Z,W ) =\n\u222b\nf(a)p(Z | a,W )p(M | a,W )dP(a | W )\nh (1) 2 (M,W ) =\n\u222b\nf(a)p(M | a,W )dP(a | W )\nh (2) 3 (M,A,W ) =\n\u222b\nf(a)p(M | a, z\u2032,W )dP(z\u2032 | A,W )dP(a | W )\nh (0) 3 (M,Z,W ) =\n\u222b\nf(a)p(M | a, Z,W )dP(a | W )\nh (0) 4 (W ) =\n\u222b\nf(a)dP(a | W ).\nProof The proof of the theorem proceeds as follows. We prove the result for (i, k) = (0, 1) and (i, k) = (1, 1), the other results can be obtained using the same arguments. We assume the distributions G and P have densities g and p dominated by a measure \u03bb. We use \u222b fd\u03bb to denote \u222b f(x)d\u03bb(x), and use \u222b bf \u2032g\u22c6h\u2032\u22c6d\u03bb to denote \u222b b(m, z, a, w)f(m, z, a\u2032, w)g(m, z\u22c6 , a, w)h(m, z\u22c6, a\u2032, w)\u03bb(m, z, z\u22c6, a, a\u2032, w).\nFor (i, k) = (0, 1), we have\n\u03c4 (0) 1 (G)\u2212 \u03c4 (0) 1 (P) + EP[\u03d5 (0) 1 (X;G)] =\n=\n\u222b\nf gMgZgA\ng\u2032Mg \u2032 Z\n(m\u2032P \u2212m\u2032G)p\u2032Mp\u2032Zp\u2032ApWd\u03bb\n+\n\u222b\nfm\u2032GgMgZgAp \u2032 ApWd\u03bb\u2212\n\u222b\nfm\u2032GgMgZgAg \u2032 ApWd\u03bb\n+\n\u222b\nfm\u2032GpMpZpAg \u2032 ApWd\u03bb\u2212\n\u222b\nfm\u2032GpMpZpAp \u2032 ApWd\u03bb\n=\n\u222b\nf\n(\np\u2032Mp \u2032 Z g\u2032Mg \u2032 Z \u2212 1 ) ( m\u2032P \u2212m\u2032G ) gMgZgAp \u2032 ApWd\u03bb\n+\n\u222b\nf (gMgZgA \u2212 pMpZpA) ( mPp \u2032 A \u2212mGg\u2032A ) pWd\u03bb.\nLikewise, for (i, k) = (1, 1), we have\n\u03c4 (1) 1 (G)\u2212 \u03c4 (1) 1 (P) + EP[\u03d5 (1) 1 (X;G)] =\n= \u222b f g\u22c6Mg \u22c6 ZgZgA\ng\u2032Mg \u2032 Z\n(m\u2032P \u2212m\u2032G)p\u2032Mp\u2032Zp\u2032ApWd\u03bb\n+\n\u222b\nfm\u2032Gg \u22c6 Mg \u22c6 ZgZgAp \u2032 ApWd\u03bb\u2212\n\u222b\nfm\u2032Gg \u22c6 Mg \u22c6 ZgZgAg \u2032 ApWd\u03bb\n+\n\u222b\nfm\u2032Gg \u22c6 Mg \u22c6 ZpZgAg \u2032 ApWd\u03bb\u2212\n\u222b\nfm\u2032Gg \u22c6 Mg \u22c6 ZgZgAg \u2032 ApWd\u03bb\n+\n\u222b\nfm\u2032Gp \u22c6 Mp \u22c6 ZgZpAg \u2032 ApWd\u03bb\u2212\n\u222b\nfm\u2032Pp \u22c6 Mp \u22c6 ZpZpAp \u2032 ApWd\u03bb\n=\n\u222b\nf\n(\np\u2032Mp \u2032 Z g\u2032Mg \u2032 Z \u2212 1 ) (m\u2032P \u2212m\u2032G)g\u22c6Mg\u22c6ZgZgAp\u2032ApWd\u03bb\n+\n\u222b\nfm\u2032Pg \u22c6 Mg \u22c6 ZgZgAp \u2032 ApWd\u03bb\u2212\n\u222b\nfm\u2032Gg \u22c6 Mg \u22c6 ZgZgAg \u2032 ApWd\u03bb\n+\n\u222b\nfm\u2032Gg \u22c6 Mg \u22c6 ZpZgAg \u2032 ApWd\u03bb\u2212\n\u222b\nfm\u2032Gg \u22c6 Mg \u22c6 ZgZgAg \u2032 ApWd\u03bb\n+\n\u222b\nfm\u2032Gp \u22c6 Mp \u22c6 ZgZpAg \u2032 ApWd\u03bb\u2212\n\u222b\nfm\u2032Pp \u22c6 Mp \u22c6 ZpZpAp \u2032 ApWd\u03bb\n+\n\u222b\nfm\u2032Gp \u22c6 Mp \u22c6 ZpZpAg \u2032 ApWd\u03bb\u2212\n\u222b\nfm\u2032Gp \u22c6 Mp \u22c6 ZpZpAg \u2032 ApWd\u03bb\n=\n\u222b\nf\n(\np\u2032Mp \u2032 Z g\u2032Mg \u2032 Z \u2212 1 ) (m\u2032P \u2212m\u2032G)g\u22c6Mg\u22c6ZgZgAp\u2032ApWd\u03bb\n+\n\u222b\nf(m\u2032Pp \u2032 A \u2212m\u2032Gg\u2032A)g\u22c6Mg\u22c6ZgZgApWd\u03bb\n+\n\u222b\nfm\u2032Gg \u22c6 Mg \u22c6 Z(pZ \u2212 gZ)gAg\u2032ApWd\u03bb\n+\n\u222b\nfm\u2032Gp \u22c6 Mp \u22c6 Z(gZ \u2212 pZ)pAg\u2032ApWd\u03bb\n+\n\u222b\nf(m\u2032Gg \u2032 A \u2212m\u2032Pp\u2032A)p\u22c6Mp\u22c6ZpZpApWd\u03bb\n=\n\u222b\nf\n(\np\u2032Mp \u2032 Z g\u2032Mg \u2032 Z \u2212 1 ) (m\u2032P \u2212m\u2032G)g\u22c6Mg\u22c6ZgZgAp\u2032ApWd\u03bb\n+\n\u222b\nf(m\u2032Pp \u2032 A \u2212m\u2032Gg\u2032A)(g\u22c6Mg\u22c6ZgZgA \u2212 p\u22c6Mp\u22c6ZpZpA)pWd\u03bb\n+\n\u222b\nfm\u2032G(g \u22c6 Mg \u22c6 ZgA \u2212 p\u22c6Mp\u22c6ZpA)(pZ \u2212 gZ)g\u2032ApWd\u03bb"
        },
        {
            "heading": "2.1 Proof of Theorem 11",
            "text": "Proof To simplify notation we remove the index j and superindex k from \u03c4kj to simplify notation. Let Pn,v denote the empirical distribution of the prediction set Pv, and let Gn,v denote the associated empirical process\n\u221a n/J(Pn,v \u2212 P). Note that\n\u03c4\u0302 = 1\nV\nV \u2211\nv=1\nPn,v\u03d5\u0304(\u00b7; \u03b7\u0302v), \u03c4 = P\u03d5\u0304(\u00b7; \u03b7).\nThus,\n\u221a n{\u03c4\u0302 \u2212 \u03c4} = Gn{\u03d5\u0304(\u00b7; \u03b7) \u2212 \u03c4}+Rn,1 +Rn,2,\nwhere\nRn,1 = 1\u221a V\nV \u2211\nv=1\nGn,v{\u03d5\u0304(\u00b7; \u03b7\u0302v)\u2212 \u03d5\u0304(\u00b7; \u03b7)}, Rn,2 = \u221a n\nJ\nV \u2211\nv=1\nP{\u03d5\u0304(\u00b7; \u03b7\u0302v)\u2212 \u03c4}.\nIt remains to show that Rn,1 and Rn,2 are oP (1). Theorem 10 together with the assumption that R (k) j (\u03b7\u0302, \u03b7) = oP(n \u22121/2) shows that Rn,2 = oP(1). For Rn,1 we use empirical process theory to argue conditional on the training sample Tv. In particular, Lemma 19.33 of van der Vaart (1998) applied to the class of functions F = {\u03d5\u0304(\u00b7; \u03b7\u0302v)\u2212 \u03d5\u0304(\u00b7; \u03b7)} (which consists of one element) yields\nE\n{\n\u2223 \u2223Gn,v(\u03d5\u0304(\u00b7; \u03b7\u0302v)\u2212 \u03d5\u0304kj (\u00b7; \u03b7)) \u2223 \u2223\n\u2223 \u2223 \u2223 \u2223 Tv } . 2C log 2\nn1/2 + ||\u03d5\u0304(\u00b7; \u03b7\u0302v)\u2212 \u03d5\u0304(\u00b7; \u03b7)||(log 2)1/2\nThe assumption R (k) j (\u03b7\u0302, \u03b7) = oP(n \u22121/2) can only hold if \u03b7\u0302 \u2212 \u03b7 = oP(1), therefore the right hand side is oP(1). Lemma 6.1 of Chernozhukov et al. (2018) may now be used to argue that conditional convergence implies unconditional convergence, concluding the proof."
        },
        {
            "heading": "3 Auxiliary results",
            "text": "Lemma 3. Let U denote the range of U = (UW , UA, UZ , UM , UY ). The following statements are true:\n1. P{supa\u0304 |Y (a1, Z(a2),M(a3, Z(a4)))\u2212 Y (a1, Z(a0),M(a3, Z(a4)))| = 0} = 1 implies U can be parti-\ntioned into sets U1 and U2 such that\n(a) P{supa\u0304,z\u0304 |Y (a1, z1,M(a3, Z(a4)))\u2212 Y (a1, z2,M(a3, Z(a4)))| = 0 | U \u2208 U1} = 1, and (b) P{supa\u0304 |Z(a2)\u2212 Z(a0)| = 0 | U \u2208 U2} = 1,\nwhere z1 \u2208 supp{Z(a2)} and z2 \u2208 supp{Z(a0)}.\n2. P{supa\u0304 |Y (a1, Z(a2),M(a3, Z(a4)))\u2212 Y (a1, Z(a2),M(a3, Z(a0)))| = 0} = 1 implies U can be parti-\ntioned into sets U1, U2, and U3 such that\n(a) P{supa\u0304,m\u0304 |Y (a1, Z(a2),m1)\u2212 Y (a1, Z(a2),m2)| = 0 | U \u2208 U1} = 1, and (b) P{supa\u0304,z\u0304 |M(a3, z1)\u2212M(a3, z2)| = 0 | U \u2208 U2} = 1, and (c) P{supa\u0304 |Z(a4)\u2212 Z(a0)| = 0 | U \u2208 U3} = 1\nwhere m1 \u2208 supp{M(a3, Z(a4))} and m2 \u2208 supp{M(a3, Z(a0))}, and z1 \u2208 supp{Z(a4)} and z2 \u2208 supp{Z(a0)}.\n3. P{supa\u0304 |Y (a1, Z(a2),M(a3, Z(a4)))\u2212 Y (a1, Z(a2),M(a0, Z(a4)))| = 0} = 1 implies U can be parti-\ntioned into sets U1 and U2 such that\n(a) P{supa\u0304,m\u0304 |Y (a1, Z(a2),m1)\u2212 Y (a1, Z(a2),m2)| = 0 | U \u2208 U1} = 1, and (b) P{supa\u0304 |M(a3, Z(a4))\u2212M(a0, Z(a4))| = 0 | U \u2208 U2} = 1,\nwhere m1 \u2208 supp{M(a3, Z(a4))}, and m2 \u2208 supp{M(a0, Z(a4))}.\nProof We show the proof for the third statement, assuming a discrete variable M . The other statements can be proved using parallel arguments. The statement is of the form if p then q, we will prove the contrapositive if not q then not p. We have\n|Y (a1, Z(a2),M(a3, Z(a4))) \u2212 Y (a1, Z(a2),M(a0, Z(a4)))| = \u2211\nm6=m\u2032\n|Y (a1, Z(a2),m) \u2212 Y (a1, Z(a2),m\u2032)|1{M(a3, Z(a4)) = m,M(a0, Z(a4)) = m\u2032}.\nAssume there is a set U\u22c6 \u2286 U with P(U\u22c6) > 0 and values a\u0304, m1 \u2208 supp{M(a3, Z(a4))}, and m2 \u2208 supp{M(a0, Z(a4))} such that Y (a1, Z(a2),m1) 6= Y (a1, Z(a2),m2) and M(a3, Z(a4)) 6= M(a0, Z(a4)) in U\u22c6 (i.e., assume not q). Then,\n|Y (a1, Z(a2),M(a3, Z(a4))) \u2212 Y (a1, Z(a2),M(a0, Z(a4)))| \u2265\n|Y (a1, Z(a2),m1)\u2212 Y (a1, Z(a2),m2)|1{M(a3, Z(a4)) = m1,M(a0, Z(a4)) = m2}.\nThe probability that the term in the right hand side is positive is greater than zero in U\u22c6 (i.e., not p), concluding the proof of the claim."
        }
    ],
    "year": 2023
}