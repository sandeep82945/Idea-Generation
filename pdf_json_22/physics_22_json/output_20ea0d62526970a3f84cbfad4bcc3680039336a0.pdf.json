{
    "abstractText": "In this paper, we consider the problem of feature reconstruction from incomplete X-ray CT data. Such incomplete data problems occur when the number of measured X-rays is restricted either due to limit radiation exposure or due to practical constraints, making the detection of certain rays challenging. Since image reconstruction from incomplete data is a severely ill-posed (unstable) problem, the reconstructed images may suffer from characteristic artefacts or missing features, thus significantly complicating subsequent image processing tasks (e.g., edge detection or segmentation). In this paper, we introduce a framework for the robust reconstruction of convolutional image features directly from CT data without the need of computing a reconstructed image first. Within our framework, we use non-linear variational regularization methods that can be adapted to a variety of feature reconstruction tasks and to several limited data situations. The proposed variational regularization method minimizes an energy functional being the sum of a feature dependent datafitting term and an additional penalty accounting for specific properties of the features. In our numerical experiments, we consider instances of edge reconstructions from angular under-sampled data and show that our approach is able to reliably reconstruct feature maps in this case.",
    "authors": [
        {
            "affiliations": [],
            "name": "Simon G\u00f6ppel"
        },
        {
            "affiliations": [],
            "name": "Markus Haltmeier"
        }
    ],
    "id": "SP:5a4ca008fa3cc5ba98983008d7cddce118c47694",
    "references": [
        {
            "authors": [
                "L. YU",
                "X. Liu",
                "S. Leng",
                "J.M. Kofler",
                "J.C. Ramirez-Giraldo",
                "M. Qu",
                "J. Christner",
                "J.G. Fletcher",
                "C.H. McCollough"
            ],
            "title": "Radiation dose reduction in computed tomography: Techniques and future perspective",
            "venue": "Imaging Med",
            "year": 2009
        },
        {
            "authors": [
                "D.J. Brenner",
                "C.D. Elliston",
                "E.J. Hall",
                "W.E. Bredon"
            ],
            "title": "Estimated Risks of Radiation-Induced Fatal Cancer from Pediatric CT",
            "venue": "Am. J. Roentgenol",
            "year": 2001
        },
        {
            "authors": [
                "R. Nelson"
            ],
            "title": "Thousands of new cancers predicted due to increased use of CT",
            "venue": "Medscape News,",
            "year": 2009
        },
        {
            "authors": [
                "I. Shuryak",
                "R.K. Sachs",
                "D.J. Brenner"
            ],
            "title": "Cancer Risks After Radiation Exposure in Middle Age",
            "venue": "J. Natl. Cancer Inst. 2010,",
            "year": 2010
        },
        {
            "authors": [
                "F. Natterer"
            ],
            "title": "The Mathematics of Computerized Tomography; Classics in Applied Mathematics; Society for Industrial and Applied Mathematics: Philadelphia",
            "venue": "PA, USA,",
            "year": 2001
        },
        {
            "authors": [
                "J. Frikel",
                "E.T. Quinto"
            ],
            "title": "Characterization and reduction of artifacts in limited angle tomography",
            "venue": "Inverse Probl",
            "year": 2013
        },
        {
            "authors": [
                "A.K. Jain"
            ],
            "title": "Fundamentals of Digital Image Processing; Prentice-Hall, Inc.: Englewood Cliff",
            "venue": "NJ, USA,",
            "year": 1989
        },
        {
            "authors": [
                "B. J\u00e4hne"
            ],
            "title": "Digital Image Processing",
            "year": 2005
        },
        {
            "authors": [
                "A.K. Louis"
            ],
            "title": "Combining Image Reconstruction and Image Analysis with an Application to Two-Dimensional Tomography",
            "venue": "SIAM J. Imaging Sci. 2008,",
            "year": 2008
        },
        {
            "authors": [
                "A.K. Louis"
            ],
            "title": "Feature reconstruction in inverse problems",
            "venue": "Inverse Probl. 2011,",
            "year": 2011
        },
        {
            "authors": [
                "E.J. Candes",
                "J. Romberg",
                "T. Tao"
            ],
            "title": "Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information",
            "venue": "IEEE Trans. Inf. Theory",
            "year": 2006
        },
        {
            "authors": [
                "J. Frikel",
                "S. G\u00f6ppel",
                "M. Haltmeier"
            ],
            "title": "Combining Reconstruction and Edge Detection in Computed Tomography",
            "venue": "Eds.; Springer: Wiesbaden,",
            "year": 2021
        },
        {
            "authors": [
                "B.N. Hahn",
                "A.K. Louis",
                "M. Maisl",
                "C. Schorr"
            ],
            "title": "Combined reconstruction and edge detection in dimensioning",
            "venue": "Meas. Sci. Technol",
            "year": 2013
        },
        {
            "authors": [
                "G. Rigaud",
                "A. Lakhal"
            ],
            "title": "Image and feature reconstruction for the attenuated Radon transform via circular harmonic decomposition of the kernel",
            "venue": "Inverse Probl",
            "year": 2015
        },
        {
            "authors": [
                "Rigaud",
                "G. Compton"
            ],
            "title": "Scattering Tomography: Feature Reconstruction and Rotation-Free Modality",
            "venue": "SIAM J. Imaging Sci. 2017,",
            "year": 2017
        },
        {
            "authors": [
                "V. Elangovan",
                "R.T. Whitaker"
            ],
            "title": "From sinograms to surfaces: A direct approach to the segmentation of tomographic data",
            "venue": "In International Conference on Medical Image Computing and Computer-Assisted Intervention; Springer: Berlin/Heidelberg, Germany,",
            "year": 2001
        },
        {
            "authors": [
                "M. Storath",
                "A. Weinmann",
                "J. Frikel",
                "M. Unser"
            ],
            "title": "Joint image reconstruction and segmentation using the Potts model",
            "venue": "Inverse Probl",
            "year": 2015
        },
        {
            "authors": [
                "M. Burger",
                "C. Rossmanith",
                "X. Zhang"
            ],
            "title": "Simultaneous reconstruction and segmentation for dynamic SPECT imaging",
            "venue": "Inverse Probl. 2016,",
            "year": 2016
        },
        {
            "authors": [
                "M. Romanov",
                "A.B. Dahl",
                "Y. Dong",
                "P.C. Hansen"
            ],
            "title": "Simultaneous tomographic reconstruction and segmentation with class priors",
            "venue": "Inverse Probl. Sci. Eng. 2016,",
            "year": 2016
        },
        {
            "authors": [
                "L. Shen",
                "E.T. Quinto",
                "S. Wang",
                "M. Jiang"
            ],
            "title": "Simultaneous reconstruction and segmentation with the Mumford-Shah functional for electron tomography",
            "venue": "Inverse Probl. Imaging 2018,",
            "year": 2018
        },
        {
            "authors": [
                "Z. Wei",
                "B. Liu",
                "B. Dong",
                "L. Wei"
            ],
            "title": "A Joint Reconstruction and Segmentation Method for Limited-Angle X-Ray Tomography",
            "venue": "IEEE Access 2018,",
            "year": 2018
        },
        {
            "authors": [
                "L. Desbat"
            ],
            "title": "Efficient sampling on coarse grids in tomography",
            "venue": "Inverse Probl",
            "year": 1993
        },
        {
            "authors": [
                "A. Faridani"
            ],
            "title": "Sampling theory and parallel-beam tomography",
            "year": 2004
        },
        {
            "authors": [
                "A. Faridani"
            ],
            "title": "Fan-beam tomography and sampling theory. In The Radon Transform, Inverse Problems, and Tomography; AMS: Atlanta, Georgia",
            "year": 2006
        },
        {
            "authors": [
                "F. Natterer"
            ],
            "title": "Sampling and resolution in CT",
            "venue": "In Computerized Tomography (Novosibirsk,",
            "year": 1993
        },
        {
            "authors": [
                "P. Rattey",
                "A.G. Lindgren"
            ],
            "title": "Sampling the 2-D Radon transform",
            "venue": "IEEE Trans. Acoust. Speech Signal Process",
            "year": 1981
        },
        {
            "authors": [
                "C.A. Micchelli",
                "T.J. Rivlin"
            ],
            "title": "A survey of optimal recovery",
            "venue": "In Optimal Estimation in Approximation Theory; Springer: Berlin/Heidelberg, Germany,",
            "year": 1977
        },
        {
            "authors": [
                "J. Canny"
            ],
            "title": "A computational approach to edge detection",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "year": 1986
        },
        {
            "authors": [
                "D. Marr",
                "E. Hildreth"
            ],
            "title": "Theory of edge detection",
            "venue": "Proc. R. Soc. London. Ser. B. Biol. Sci",
            "year": 1980
        },
        {
            "authors": [
                "A. Beck",
                "M. Teboulle"
            ],
            "title": "A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems",
            "venue": "SIAM J. Imaging Sci. 2009,",
            "year": 2009
        },
        {
            "authors": [
                "T. Bubba",
                "A. Hauptmann",
                "S. Huotari",
                "J. Rimpel\u00e4inen",
                "S. Siltanen"
            ],
            "title": "Tomographic X-ray data of a lotus root filled with attenuating objects",
            "venue": "arXiv 2016,",
            "year": 2016
        },
        {
            "authors": [
                "G. Zangerl",
                "M. Haltmeier"
            ],
            "title": "Multi-Scale Factorization of the Wave Equation with Application to Compressed Sensing Photoacoustic Tomography",
            "venue": "arXiv 2020,",
            "year": 2020
        },
        {
            "authors": [
                "H. Jiang"
            ],
            "title": "Photoacoustic Tomography; Taylor & Francis",
            "venue": "Boca Raton, FL,",
            "year": 2014
        },
        {
            "authors": [
                "M. Haltmeier",
                "M. Sandbichler",
                "T. Berer",
                "J. Bauer-Marschallinger",
                "P. Burgholzer",
                "L. Nguyen"
            ],
            "title": "A New Sparsification and Reconstruction Strategy for Compressed Sensing Photoacoustic Tomography",
            "venue": "J. Acoust. Soc. Am",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "Citation: G\u00f6ppel, S.; Frikel, J.;\nHaltmeier, M. Feature Reconstruction\nfrom Incomplete Tomographic Data\nwithout Detour. Mathematics 2022, 10,\n1318. https://doi.org/10.3390/\nmath10081318\nAcademic Editor: Jakub Nalepa\nReceived: 1 February 2022\nAccepted: 13 April 2022\nPublished: 15 April 2022\nPublisher\u2019s Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished maps and institutional affil-\niations.\nCopyright: \u00a9 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: computed tomography; Radon transform; reconstruction; limited data; sparse data; feature reconstruction; edge detection"
        },
        {
            "heading": "1. Introduction",
            "text": "Computed tomography (CT) has established itself as one of the standard tools in bio-medical imaging and non-destructive testing. In medical imaging, the relatively high radiation dose that is used to produce high-resolution CT images (and that patients are exposed to) has become a major clinical concern [1\u20134]. The reduction of the radiation exposure of a patient while ensuring the diagnostic image quality constitutes one of the main challenges in CT. In addition to patient safety, the reduction of scanning times and costs also constitute important aspects of dose reduction, which is often achieved by reducing the X-ray energy level (leading to higher noise levels in the data) or by reducing the number of collected CT data (leading to incomplete data), cf. [1]. Low-dose scanning scenarios are also relevant for in vivo scanning used for biological purposes and for fast tomographic imaging in general. However, due to the limited amount of data, reconstructed images suffer from low signal-to-noise ratio or substantial reconstruction artifacts. In this work, we particularly consider incomplete data situations, e.g., that arise in a sparse or limited view setup, where CT data is collected only with respect to a small number of X-ray directions or within a small angular range. The intentional reduction of the angular sampling rate leads to an under-determined and severely ill-posed image reconstruction problem, c.f. [5]. As a consequence, the reconstructed image quality can be substantially degraded, e.g., by artefacts or missing features [6], and this can also effect complicate subsequent image processing tasks (such as edge detection or segmentation)\nMathematics 2022, 10, 1318. https://doi.org/10.3390/math10081318 https://www.mdpi.com/journal/mathematics\nthat are often employed within a CAD pipeline (computer aided diagnosis). Therefore, the development of robust feature detection algorithms for CT that ensure the diagnostic image quality is an important and very challenging task. In this paper, we introduce a framework for feature reconstruction directly from incomplete tomographic data, which is in contrast to the classical 2-step approach where reconstruction and feature detection are performed in two separate steps.\n1.1. Incomplete Tomographic Data\nIn this article, we consider the parallel beam geometry and use the 2D Radon transform R f : S1 \u00d7R \u2192 R as a model for the (full) CT data generation process, where S1 denotes the unit circle in R2 and f : R2 \u2192 R is a function representing the sought tomographic image (CT scan). Here, the value R f (\u03b8, s) represents one X-ray measurement over a line in R2 that is parametrized by the normal vector \u03b8 \u2208 S1 and the signed distance from the origin s \u2208 R. In what follows, we consider incomplete data situations where the Radon data are available on a circular scanning trajectory and only for a small number of directions, given by \u0398 := {\u03b81, . . . , \u03b8m}. We denote the angularly sampled tomographic Radon data by R\u0398 f := (R f )|\u0398\u00d7R. In this context, the (semi-discrete) CT data R\u0398 f will be called incomplete if the Radon transform is insufficiently sampled with respect to the directional variable. Prominent instances of incomplete data situations are: sparse angle setup, where the directions in \u0398 are sparsely distributed over the full angular range [0, \u03c0]; annd limited view setup, where \u0398 covers only small part of the full angular range [0, \u03c0]. Precise mathematical criteria of (in-)sufficient sampling can be derived from the Shannon sampling theory. Those criteria are based on the relation between the number of directions m = |\u0398| and the bandwidth of f , cf. [5]. In this work, we will mainly focus on the sparse angle case, with uniformly distributed directions \u03b81, . . . , \u03b8m on a half-circle, e.g., directions \u03b8k := \u03b8(\u03d5k) = (cos(\u03d5k), sin(\u03d5k))> with uniformly distributed angles \u03d5k \u2208 [0, \u03c0).\n1.2. Feature Reconstruction in Tomography\nIn the following, we consider image features that can be extracted from a CT scan f \u2208 L2(R2) by a convolution with a kernel U \u2208 L1(R2). In this context, the notion of a feature map will refer to the convolution product f ~ U, and the convolution kernel U will be called the feature extraction filter. Examples of feature detection tasks that can be realized by a convolution include edge detection, image restoration, image enhancement, or texture filtering [7]. For example, in the case of edge detection, the filter U can be chosen as a smooth approximation of differential operators, e.g., of the Laplacian operator [8]. In our practical examples, we will mainly focus on edge detection in tomography. However, the proposed framework also applies to more general feature extraction tasks. In many standard imaging setups, image reconstruction and feature extraction are realized in two separate steps. However, as pointed out in [9], this 2-step approach can lead to unreliable feature maps since feature extraction algorithms have to account for inaccuracies that are present in the reconstruction. This is particularly true for the case of incomplete CT data as those reconstructions may contain artefacts. Hence, combining these two steps into an approach that computes feature maps directly from CT data can lead to a significant performance increase, as was already pointed out in [9,10]. In this work, we account for this fact and extend the results of [9,10] to a more general setting and, in particular, to limited data situations.\n1.3. Main Contributions and Related Work\nIn this paper, we propose a framework to directly reconstruct the feature map U ~ f from the measured tomographic data. Our approach is based on the forward convolution identity for the Radon transform, which is R( f ~ U) = (R f ) ~s (RU), where on the right hand side the convolution is taken with respect to the second variable of the Radon transform, cf. [5]. This identity implies that, given (semi-discrete) CT data, the feature map satisfies the (discretized) equation R\u0398h = y\u0398, where y\u0398 = R\u0398 f ~s R\u0398U is the modified\n(preprocessed) CT data. Therefore, the sought feature map can be formally computed by applying a discretized version of the inverse Radon transform to y\u0398, i.e., as h\u0398 = R\u22121\u0398 (y\u0398). In the case of full data (sufficient sampling), this can be accurately and efficiently computed by using the well-known filtered backprojection (FBP) algorithm with the filter R\u0398U. However, if the CT data are incomplete, this approach would lead to unreliable feature maps since in such situations the FBP is known to produce inaccurate reconstruction results, cf. [5,6]. In order to account for data incompleteness, we propose to replace the inverse R\u22121\u0398 by a suitable regularization method that is also able to deal with undersampled data. More concretely, we propose to reconstruct the (discrete) feature map h\u0398 by the minimizing the following Tikhonov-type functional:\nh\u0398 \u2208 arg min h 1 2 \u2016R\u0398h\u2212 u\u0398 ~s y\u0398\u20162 + r(h) .\nThis framework offers a flexible way to incorporate a priori information about the feature map into the reconstruction and, in this way, to account for the missing data. For example, from the theory of compressed sensing, it is well known that sparsity can help to overcome the classical Nyquist\u2013Shannon\u2013Whittaker\u2013Kotelnikov paradigm [11]. Hence, whenever the sought feature map is known to be sparse (e.g., in case of edge detection), sparse regularization techniques can be easily incorporated into this framework. Approaches that combine image reconstruction and edge detection have been proposed for the case of full tomographic data, e.g., in [9,10]. Although the presented work follows the spirit of [9,10], it comes with several novelties and advantages. On a formal level, our approach is based on the forward convolution identity, in contrast to the dual convolution identity, given by (R\u2217u)~ f = R\u2217(u~s R f ), that is employed in [9,10]. The latter requires full (properly sampled) data, since the backprojection operator R\u2217 integrates over the full angular range (requiring proper sampling in the angular variable). In contrast, our framework is applicable to incomplete Radon data situations, since the forward convolutional identity (used in our approach) can be applied to more general situations. Moreover, in order to recover the feature map U ~ f , we use non-linear regularization methods that can be adapted to a variety of situations and incorporate different kinds of prior information. From this perspective, our approach also offers more flexibility. A similar approach was presented in our recent proceedings article [12], where the main focus was on the stable recovery of the image gradient from CT data and its application to Canny edge detection. Following the ideas of [9,10], similar feature detection methods were also developed for other types of tomography problems, e.g., in [13\u201315]. Besides that, we are not aware of any further results concerning convolutional feature reconstruction from incomplete X-ray CT data. Combinations of reconstruction and segmentation have also been presented in the literature for different types of tomography problems, e.g., in [16\u201322]. As a commonality to our approach, many of those methods are based on the minimization of an energy functional of the form \u2016R\u0398 f \u2212 y\u20162 + r( f \u2217U), incorporating feature maps as prior information. Important examples include Mumford\u2013Shah-like approaches [17,19,21,22] or the Potts model [18]. Additionally, geometric approaches for computing segmentation masks directly from tomographic data were employed in [16].\n1.4. Outline\nFollowing the introduction in Section 1, Section 2 provides some basic facts about the Radon transform, sampling and sparse recovery. In Section 3, we introduce the proposed feature reconstruction framework and present several examples of convolutional feature reconstruction filters, along with corresponding data filters, mainly focusing on the case of edge detection. Experimental results will be presented in Section 4. We conclude with a summary and outlook given in Section 5."
        },
        {
            "heading": "2. Materials and Methods",
            "text": "In this section, we recall some basic facts about the 2D Radon transform, including important identities and sampling conditions. In particular, we define the sub-sampled Radon transform that will be used throughout this article. Although, our presentation is restricted to the 2D case (because this makes the presentations more concise and clear), the presented concepts can be easily generalized to the d-dimensional setup.\n2.1. The Radon Transform\nLet S(R2) denote the Schwartz space on R2 (space of smooth functions that are rapidly decaying together with all their derivatives) and S(S1 \u00d7 R) denote the Schwartz space over S1 \u00d7R as the space of all smooth functions that are rapidly decaying together with all their derivatives in the second component, cf. [5]. We consider the Radon transform as an operator between those Schwartz spaces, R : S(R2)\u2192 S(S1 \u00d7R), which is defined via\nR f (\u03b8, s) := \u222b \u221e \u2212\u221e f (s\u03b8 + t\u03b8\u22a5)dt, (1)\nwhere s \u2208 R, \u03b8 \u2208 S1 and \u03b8\u22a5 denotes the rotated version of \u03b8 by \u03c0/2 counterclockwise (in particular, \u03b8\u22a5 is a unit vector perpendicular to \u03b8). The value R f (\u03b8, s) represents one X-ray measurement along the X-ray path that is given by the line L(\u03b8, s) = {x \u2208 R2 : \u3008x, \u03b8\u3009 = s}. Since L(\u2212\u03b8,\u2212s) = L(\u03b8, s), the following symmetry property holds for the Radon transform, R f (\u2212\u03c6,\u2212s) = R f (\u03b8, s). Hence, it is sufficient to know the values of Radon transform only on a half-circle. Such data is therefore considered to be complete. The dual transform (backprojection operator) is defined as R\u2217 : S(S1 \u00d7R)\u2192 S(R2),\nR\u2217g(x) := \u222b S1 g(\u03b8, \u03b8 \u00b7 x)d\u03b8. (2)\nThe Radon transform is a well defined linear and injective operator, and several analytic properties are well-known. One of the most important properties is the so-called Fourier slice theorem that describes the relation between the Radon and the Fourier transforms. In order to state this relation, we first recall that the Fourier transform is defined as F : S(Rd) \u2192 S(Rd), F f (\u03be) := (2\u03c0)\u2212d/2 \u222b Rd f (x)e\n\u2212ix\u00b7\u03be dx for d \u2208 N. Whenever convenient, we will also use the abbreviated notation f\u0302 (\u03be) := F f (\u03be). The Fourier transform is a linear isomorphism on the Schwartz space S(Rd), and its inverse is given by f\u030c (x) := F\u22121 f (x) = (2\u03c0)\u2212d/2 \u222b R2 f (\u03be)e\nix\u00b7\u03be d\u03be. In what follows, we will denote the convolution of two functions f , g : Rd \u2192 R by f ~ g(x) := \u222b Rd f (x \u2212 y)g(y)dy, where d \u2208 N. Moreover, for functions g \u2208 S(S1 \u00d7 R), the Fourier transform Fsg will refer to the 1DFourier transform of g with respect to the second variable. Analogously, g ~s h will denote the convolution of g, h : S1 \u00d7R\u2192 R with respect to the second variable.\nLemma 1 (Properties of the Radon transform).\n(R1) Fourier slice theorem: \u2200 f \u2208 S(R2) \u2200(\u03b8, s) \u2208 S1 \u00d7R : FsR f (\u03b8, \u03c3) = \u221a\n2\u03c0 \u00b7 F f (\u03b8\u03c3). (R2) Convolution identity: \u2200U, f \u2208 S(R2) : R( f ~U) = R f ~s RU. (R3) Dual convolution identity: \u2200u \u2208 S(S1 \u00d7R) \u2200 f \u2208 S(R2) : R\u2217u ~ f = R\u2217(u ~s R f ). (R4) Intertwining with Derivatives: \u2200\u03b1 \u2208 N2 \u2200 f \u2208 S(R2) : R\u2202\u03b1x f = \u03b8\u03b1\u2202 |\u03b1| s R f (R5) Intertwining with Laplacian: \u2200 f \u2208 S(R2) : R\u2206x f = \u22022s R f .\nProof. All identities are derived in [5] (Chapter II).\nThe approach that we are going to present in Section 3 is based on the convolution identity (R2) and can be formulated for an arbitrary spatial dimension d \u2265 2. For the sake of clarity we consider two spatial dimensions d = 2. In this case, we will use the parametrization of S1 given by \u03b8(\u03d5) := (cos(\u03d5), sin(\u03d5))> with \u03d5 \u2208 [0, \u03c0). Then\n\u03b8\u22a5(\u03d5) = (\u2212 sin(\u03d5), cos(\u03d5))>. For the Radon transform, we will (with some abuse of notation) write\nR f (\u03d5, s) := R f (\u03b8(\u03d5), s).\n2.2. Sampling the Radon Transform\nSince in practice one has to deal with discrete data, we are forced to work with discretized (sampled) versions of the Radon transform. In this context, questions about proper sampling arise. In order to understand what it means for the CT data to be complete (properly sampled) or incomplete (improperly sampled), we recall some basic facts from the Shannon sampling theory for the Radon transform for the case of parallel scanning geometry (see for example [5] (Section III)). In what follows, we assume that f is compactly supported on the unit disc D \u2286 R2 and consider sampled CT data R f (\u03d5j, sl) with N\u03d5 \u2208 N equispaced angles \u03d5j in [0, \u03c0) and Ns equispaced values sl in [\u22121, 1] for the s-variable, i.e.,\n(\u03d5j, s`) = (\nj\u03c0 N\u03d5 , ` Ns\n) for (j, `) \u2208 {0, . . . , N\u03d5 \u2212 1} \u00d7 {\u2212Ns, . . . , Ns} . (3)\nFor the given sampling points (3) and a finite dimensional subspace X0 \u2286 S(Rd), we define the discrete Radon transform as\nR : X0 \u2192 RN\u03d5\u00d7(2Ns+1) : f 7\u2192 (R f (\u03b8j, s`))j,` . (4)\nThe basic question of classical sampling theory in the context of CT is to find conditions on the class of images f \u2208 X0 and on the sampling points under which the sampled data R f uniquely determines the unknown function f . Sampling theory for CT has been studied, for example, in [23\u201327]. While the classical sampling theory (e.g., in the setting of classical signal processing) works with the class of band-limited functions, the sampling conditions in the context of CT are typically derived for the class of essentially band-limited functions.\nRemark 1 (Band-limited and essentially band-limited functions). A function f \u2208 L2(R2) is called b-band-limited if its Fourier transform F f (\u03be) vanishes for \u2016\u03be\u2016 > b. A function f is called essentially b-band-limited if f\u0302 (\u03be) is negligible for \u2016\u03be\u2016 \u2265 b in the sense that e0( f , b) :=\u222b \u2016\u03be\u2016\u2265b |F f (\u03be)|d\u03be is sufficiently small; see [5]. One reason for working with essentially band-limited functions in CT is that functions with compact support cannot be strictly band-limited. However, the quantity e0( f , b) can become arbitrarily small for functions with compact support.\nThe bandwidth b is crucial for the correct sampling conditions and the calculation of appropriate filters. If X0 consists of essentially b-band-limited functions that vanish outside the unit disc D, then the correct sampling conditions are given by [5]\n(N\u03d5, Ns) := ( dbe, db/\u03c0e ) . (5)\nObviously, as the bandwidth b increases, the step sizes \u03c0/N\u03d5 and 1/Ns have to decrease in order such that (5) is satisfied. Thus, if the bandwidth b is large, a large number measurements (roughly 2b2/\u03c0) have to be collected. As a consequence, for high-resolution imaging, the sampling conditions require a large number of measurements. Thus, in practical applications, high-resolution imaging in CT also leads to large scanning times and to high doses of X-ray exposure. A classical approach for dose reduction consists of the reduction of X-ray measurements. For example, this can be achieved by angular undersampling, where Radon data is collected only for a relatively small number of directions \u0398 \u2286 {\u03b80, . . . , \u03b8N\u03d5\u22121}.\nDefinition 1 (Sub-sampled Radon transform). Let (N\u03d5, Ns) be defied by (5) and let X0 be the set of essentially b-band-limited functions that vanishes outside the unit disc D (note that in that\ncase, the discrete Radon transform defined in (4) is correctly sampled). For \u0398 \u2286 {\u03b80, . . . , \u03b8N\u03d5\u22121}, we call\nR\u0398 : X0 \u2192 R|\u0398|\u00d7(2Ns+1) : f 7\u2192 (R f )|\u0398\u00d7{\u2212Ns ,...,Ns} (6)\nthe sub-sampled discrete Radon transform. We will also use the semi-discrete Radon transform R\u0398 f := (R f )|\u0398\u00d7R, where we only sample in the angular direction but not in the radial direction.\nIf we perform actual undersampling, where the number of directions in \u0398 is much less than N\u03d5, then the linear equation R\u0398 f = y\u0398 will be severely under-determined, and its solution requires additional prior information (e.g., sparsity of the feature map)."
        },
        {
            "heading": "3. Feature Reconstruction from Incomplete Data",
            "text": "In this section, we present our approach for feature map reconstruction from incomplete data. For a given bandwidth b, we let X0 denote the set of essentially b-band-limited functions that vanishes outside D. Furthermore, we assume that the set of directions {\u03b80, . . . , \u03b8N\u03d5\u22121} is chosen according to the sampling conditions (5).\nProblem 1 (Feature reconstruction task). Let \u0398 \u2286 {\u03b80, . . . , \u03b8N\u03d5\u22121} and let y\u0398 : \u0398\u00d7R\u2192 R be the noisy subsampled (semi-discrete) CT data with \u2016R\u0398 f \u2212 y\u0398\u2016 \u2264 \u03b4, where f \u2208 X0 is the true but unknown image and \u03b4 > 0 is the known noise level. Given a feature extraction filter U : R2 \u2192 R, our goal is to estimate the feature map U ~ f from the (undersampled) data y\u0398.\nRemark 2. 1. From a general perspective, Problem 1 is related to the field of optimal recovery [28], where the goal is to estimate certain features of an element in a space X0 from noisy indirect observations; 2. Depending on the particular choice of the filter U, Problem 1 corresponds to several typical\ntasks in tomography. For example, if U is chosen as an approximation of the Delta distribution, Problem 1 is equivalent to the classical image reconstruction problem. In fact, the filtered backprojection algorithm (FBP) is derived in this way from the dual convolution identity (R3) for the full data case, cf. [5]. Another instance of Problem 1 is edge reconstruction from tomographic data y\u0398. For example, this can be achieved by choosing the feature extraction filter U as the Laplacian of an approximation to the Delta distribution (e.g., Laplacian of Gaussian (LoG)). Then, Problem 1 boils down to an approximate recovery of the Laplacian of f , which is used in practical edge-detection algorithms (e.g., LoG-filter [7,8]);\n3. Traditionally, the solution of Problem 1 is realized via the 2-step approach: First, by estimating f and, secondly, by applying convolution in order to estimate the feature map U ~ f . This 2-step approach has several disadvantages: Since image reconstruction in CT is (possibly severely) ill-posed, the fist step might introduce huge errors in the reconstructed image. Those errors will also be propagated through the second (feature extraction) step, which itself can be ill-posed and even further amplify errors. In order to reduce the error propagation of the first step, regularization strategies are usually applied. The choice of a suitable regularization strategy strongly depends on the particular situation and on the available prior information about the sought object f . However, the recovery of f requires different prior knowledge than feature extraction. This mismatch can lead to a substantial loss of performance in the feature detection step; 4. In order to overcome the limitations mentioned in the remark above, image reconstruction and edge detection were combined in [9,10], where explicit formulas for estimating the edge map have been derived using the method of approximate inverse. This approach is also based on the dual convolution identity (R3) and is closely related to the standard filtered backprojection (FBP) algorithm. However, this approach is not applicable to the case of undersampled data, since [9,10] employ the dual convolutional identity (R3) and calculate the reconstruction filters of the form R\u2217\u0398u. In this calculation, in order to achieve a good approximation of the integral in (2), a properly sampled Radon data is required.\nTo overcome the limitations mentioned in the remark above, we derive a novel framework for feature reconstruction in the next subsection (based on the forward convolutional identity (R3)) that does not make use of the continuous backprojection and, hence, can be applied to more general situations.\n3.1. Proposed Feature Reconstruction\nOur proposed framework for solving the feature reconstruction Problem 1 is based on the forward convolution identity (R2) stated in Lemma 1. Because the convolution on the right-hand side of (R2) acts only on the second variable, the convolution identity is not affected by the subsampling in the angular direction. Therefore, we have\nR\u0398( f ~U) = u\u0398 ~s R\u0398 f with u\u0398 := R\u0398U. (7)\nFormally, the solution of (7) takes the form f ~ U = R\u22121\u0398 (u\u0398 ~s R\u0398 f ). If the data are properly sampled, this can be accurately and efficiently computed by applying the FBP algorithm to the filtered CT data y\u0398 = u\u0398 ~s R\u0398 f . In this context, the data filter u\u0398 needs to be precomputed (from a given feature extraction filter U) in a filter design step. However, if the data R\u0398 f are not properly sampled, the Equations (7) are underdetermined and, in this case, FBP does not produce accurate results, cf. [5,6]. In order to account for data incompleteness and to stably approximate the feature map f ~ U, a priori information about the specific feature kernel U or the feature map f ~U needs to be integrated into the reconstruction procedure. As a flexible way for doing this, we propose to approximate the inverse R\u22121\u0398 by the following variational regularization scheme:\n1 2 \u2016R\u0398h\u2212 u\u0398 ~s y\u0398\u201622 + r(h)\u2192 minh\u2208X0 . (8)\nHere, y\u0398 : \u0398 \u00d7 R \u2192 R denotes the noisy (semi-discrete data), and r : X0 \u2192 [0, \u221e] is a regularization (penalty) term.\nExample 1.\n1. IMAGE RECONSTRUCTION: Here, the feature extraction filter U = U\u03b1 is chosen as an approximation to the Delta distribution. For example, as U = g\u03b1 with\ng\u03b1(x) = 1\n2\u03c0\u03b12 exp\n( \u2212\u2016x\u2016 2\n2\u03b12\n) , \u03b1 > 0 (9)\nbeing the Gaussian kernel. Another way of choosing U for reconstruction purposes is through ideal low-pass filters U\u03b1 that are defined in the frequency domain via FU\u03b1 = \u03c7D(0,\u03b1\u22121), where \u03b1 > 0, D(0, \u03b1\u22121) \u2282 R2 denotes a ball in R2 with radius 1/\u03b1, and \u03c7A is the characteristic function of the set A \u2286 R2. It can be shown that in both cases, U\u03b1 ~s f \u2192 f as \u03b1\u2192 0. These filters and its variants are often used in the context of the FBP algorithm.\n2. GRADIENT RECONSTRUCTION: Here U = U\u03b1 is chosen as a partial derivative of an\napproximation of the Delta distribution. For example, as U\u03b1 = (U (1) \u03b1 , U (2) \u03b1 ) with U (i) \u03b1 := \u2202g\u03b1 \u2202xi\n, i = 1, 2. This way, one obtains an approximation of the gradient of f via\n\u2207x f = (U(1)\u03b1 ~ f , U (2) \u03b1 ~ f ) =: U\u03b1 ~ f ,\nwhere in the last equation above we applied the convolution ~ componentwise. Such approximations of the gradient are, for example, used inside the well-known Canny edge detection algorithm [29].\n3. LAPLACIAN RECONSTRUCTION: Analogously to the gradient approximation, U is chosen to be the Laplacian of an approximation to the Delta distribution. A prominent example, is\nthe Laplacian of Gaussian (LoG), i.e., U\u03b1 = \u2206xg\u03b1, also known as the Marr\u2013Hildreth operator. This operator is also used for edge detection, corner detection and blob detection, cf. [30].\nDepending on the problem at hand, there are several different ways of choosing the regularizer r(h). Prominent examples in the case of image reconstruction include total variation (TV) or the `1 norm (possibly in the context of some basis of frame expansion). For the reconstruction of the derivatives (or edges in general), we will use the `1 norm as the regularization term because derivatives of images can be assumed to be sparse and because the problem (8) can be efficiently solved in this case.\n3.2. Filter Design\nThe first step in our framework is a filter design for (8). That is, given a feature extraction kernel U, we first need to calculate the corresponding filter u\u0398 = R\u0398U for the CT data, cf. (7). In our setting, filter design therefore amounts to the evaluation of the Radon transform of U. In contrast to our approach, the filter design step of [9] consists of calculating a solution of the dual equation U = R\u2217u given the feature extraction filter U. As discussed above, the latter case requires full data and might be computationally more involved. From this perspective, filter design required by our approach offers more flexibility and can be considered somewhat simpler. We now discuss some of the Examples 1 in more detail and calculate the associated CT data filters u\u0398. In particular, we focus on the Gaussian approximations of the Delta distributions stated in (9). In a first step, we compute the Radon transform of a Gaussian.\nLemma 2. The Radon transform of the Gaussian g\u03b1, defined by (9), is given by\nRg\u03b1(\u03d5, s) = 1\n\u03b1 \u221a 2\u03c0 \u00b7 exp\n( \u2212 s 2\n2\u03b12\n) . (10)\nSince the Gaussian g\u03b1 converges to the Delta distribution as \u03b1 \u2192 0, the smoothed version f\u03b1 := f ~ g\u03b1 constitutes an approximation to f for small values of \u03b1. In order to obtain approximations to partial derivatives of f , we note that \u2202 f\u03b1\u2202xi = f ~ \u2202g\u03b1 \u2202xi . Hence, using the feature extraction filters U(i)\u03b1 := \u2202g\u03b1 \u2202xj\n, the Problem 1 amounts to reconstructing partial derivatives of f . Using this observation together with Lemma 2 and the property (R4), we can explicitly calculate data filters used in different edge reconstruction algorithms (such as Canny or for the Marr\u2013Hildreth operator).\nProposition 1. Let the Gaussian g\u03b1 be defined by (9).\n1. GRADIENT RECONSTRUCTION: For the feature extraction filter Ugrad := \u2207xg\u03b1, the corresponding data filter ugrad = (u (1) \u03b1 , u (2) \u03b1 ) is given by\nugrad(\u03d5, s) = RUgrad(\u03d5, s) = \u2212 s\n\u03b13 \u221a 2\u03c0 \u00b7 exp\n( \u2212 s 2\n2\u03b12\n) \u00b7 \u03b8(\u03d5) (11)\nNote that in (11), the notation RUgrad refers to a vector-valued function that is defined by a componentwise application of the Radon transform (cf. Example 1, No. 2).\n2. LAPLACIAN RECONSTRUCTION: For the feature extraction filter U\u03b1 := \u2206xg\u03b1, the corresponding data filter is given by\nuLoG(\u03d5, s) = RULoG(\u03d5, s) = 1\n\u03b13 \u221a 2\u03c0 \u00b7 exp\n( \u2212 s 2\n2\u03b12\n) \u00b7 ( s2 \u03b12 \u2212 1 )\n(12)\nFrom Proposition 1, we immediately obtain an explicit reconstruction formula for the approximate computation of the gradient and of the Laplacian of f \u2208 S(R2):\n\u2207x f\u03b1 = R\u22121(ugrad ~s R f ) and \u2206x f\u03b1 = R\u22121(uLoG ~s R f ).\nBoth of the above formulas are of the FBP type and can be implemented using the standard implementations of the FBP algorithm with a modified filter. This approach has the advantage that only one data-filtering step has to be performed, followed by the standard backprojection operation. In order to derive FBP filters for the gradient and Laplacian reconstruction, let us first note that R\u22121 = R\u2217 \u25e6\u039b, where the operator \u039b acts on the second variable and is defined in the Fourier domain by Fs(\u039bg)(\u03d5, \u03c9) = (4\u03c0)\u22121 \u00b7 |\u03c9| \u00b7 (Fsg)(\u03d5, \u03c9) for g \u2208 S(S1 \u00d7R), cf. [5]. Now, using the relations for the Fourier transform in 1D, F(d f /dx)(\u03c9) = i \u00b7 \u03c9 \u00b7 f\u0302 (\u03c9), F(d2 f /dx2)(\u03c9) = \u2212\u03c92 f\u0302 (\u03c9) and F( f \u2217 g) = \u221a 2\u03c0 \u00b7 f\u0302 \u00b7 g\u0302. Together with\nFs(Rg\u03b1)(\u03d5, s) = 1\u221a 2\u03c0 \u00b7 exp\n( \u2212\u03b1 2s2\n2\n) , (13)\nwe obtain the following result.\nProposition 2. Let the FBP filters Wgrad = Wgrad(\u03d5, s) and WLoG = WLoG(\u03d5, s) be given in the Fourier domain (componentwise) by\nFsWgrad(\u03d5, \u03c9) = 1\n4\u03c0 \u00b7 i \u00b7\u03c9 \u00b7 |\u03c9| \u00b7 exp\n( \u2212\u2212\u03b1 2s2\n2\n) \u00b7 \u03b8(\u03d5), (14)\nand\nFsWgrad(\u03d5, \u03c9) = \u2212 1\n4\u03c0 \u00b7 |\u03c9|3 \u00b7 exp\n( \u2212\u2212\u03b1 2s2\n2\n) , (15)\nwhere \u03d5 \u2208 (0, 2\u03c0) and \u03c9 \u2208 R. Then, for f \u2208 S(R2), we have\n\u2207x f\u03b1 = R\u2217(Wgrad ~s R f ) and \u2206x f\u03b1 = R\u2217(WLoG ~s R f ). (16)\nSince the FBP algorithm is a regularized implementation of R\u22121 (cf. [5]), a standard toolbox implementation could be used in practice in order to compute \u2207x f\u03b1 and \u2206x f\u03b1. To this end, one only needs to use the modified filters for the FBP, provided in (14) and (15), instead of the standard FBP filter (such as Ram-Lak). Again, let us emphasize that the reconstruction formulae (16) can only be used in the case of properly sampled CT data. If the CT data does not satisfy the sampling requirements, e.g., in case of angular undersampling, this FBP algorithm will produce artifacts which can substantially degrade the performance of edge detection. In such cases, our framework (8) should be used in combination with a suitable regularization term. In the context of edge reconstruction, we propose to use `1 regularization in combination with `2 regularization. This approach will be discussed in the next section. So far, we have constructed data filters for the approximation of the gradient and Laplacian in the spatial domain, cf. Proposition 1, and derived according to FBP filters in the Fourier domain in Proposition 2. In a similar fashion, one can derive various related examples by replacing the Gaussian by feature kernels whose Radon transform is known analytically. Another way of obtaining practically relevant data filters (for a wide class of feature filters) is to derive expressions for the data filters in the Fourier domain (i.e., filter design in the Fourier domain). In the following, we provide two basic examples for filter design in the Fourier domain. To this end, we will employ the Fourier slice theorem, cf. Lemma 1, (R1).\nRemark 3.\n1. LOWPASS LAPLACIAN: The Laplacian of the ideal lowpass is defined as\nUb = \u2206xF\u22121(\u03c7D(0,b)),\nwhere b is the bandwidth of Ub. Using the property (R5), we get R(Ub) = \u2202 2 \u2202s2 R(F \u22121(\u03c7D(0,b))). By the Fourier slice theorem, we obtain\nFs(R(Ub))(\u03d5, \u03c9) = \u2212\u03c92\u03c7D(0,b)(\u03c9 \u00b7 \u03b8(\u03d5)) = \u2212\u03c92\u03c7[\u2212b,b](\u03c9).\nHence, the associated data filter is given by\nub(\u03d5, s) := RUb(\u03d5, s) = \u22022\n\u2202s2 F\u22121s (\u03c7[\u2212b,b])(s) = \u221a 2 \u03c0 \u00b7 \u2202 2 \u2202s2 sin(bs) s\n= \u221a 2 \u03c0 \u00b7 ( 2 sin(bs) s3 \u2212 2b cos(bs) s2 \u2212 b 2 sin(bs) s ) . (17)\nBecause ub is b-band-limited, the convolution with the filter (17) can be discretized systematically whenever the underlying image is essentially b-band-limited. To this end, assume that the function f has bandwidth b. Then, y = R f has bandwidth b as well (with respect to the second variable), and therefore, the continuous convolution R f ~s ub can be exactly computed via discrete convolution. Using discretization (3) and taking s` = \u03c0b \u00b7 `, we obtain from (17) the discrete filter\nub(\u03d5, s`) = \u2212 \u221a\n2 \u03c0 \u00b7 b3 \u00b7  1 3 , if ` = 0,\n2 \u00b7 (\u22121)` \u03c02`2\nif ` 6= 0. (18)\nAccording to one-dimensional Shannon sampling theory, we compute y ~s ub via discrete convolution with the filter coefficients given in (18).\n2. RAM\u2013LAK-TYPE FILTER: Consider the feature extraction filter\nUb,1 = \u2206x F\u22121 [ \u03c7D(0,b) \u00b7 (1\u2212 \u2016 \u00b7 \u2016)+ ] ,\nwhere (1\u2212 \u2016 \u00b7 \u2016)+ := max {0, 1\u2212 \u2016 \u00b7 \u2016}. Note that for b \u2265 1, we have ub,1 = u1,1, since in this case \u03c7D(0,b) \u00b7 (1\u2212 \u2016 \u00b7 \u2016)+ = (1\u2212 \u2016 \u00b7 \u2016)+. Hence, we consider the case b \u2264 1. In a similar fashion as above, we obtain\nub,1 := RUb,1(\u03d5, s) = \u22022\n\u2202s2 F\u22121s\n[ \u03c7[\u2212b,b] \u00b7 (1\u2212 | \u00b7 |) ] (s)\n= \u22022 \u2202s2 [ F\u22121s [\u03c7[\u2212b,b]](s)\u2212 F\u22121s [| \u00b7 | \u00b7 \u03c7[\u2212b,b]](s) ] . (19)\nEvaluating ub,1 at s` = \u03c0b \u00b7 `, we get\nub,1(\u03b8, s`) = \u221a 2 \u03c0 \u00b7 b3 \u00b7  3b\u2212 4 12\nif ` = 0\n3b\u2212 2 \u03c02`2\nif ` is even\n\u22123b\u2212 2 \u03c02`2 + 12b \u03c04`4 if ` is odd .\n(20)\nAgain, we can evaluate y ~s ub,1 via discrete convolution with the filter coefficients (20).\nFinally, let us note that there are several other examples for feature reconstruction filters for which one can derive explicit formulae of corresponding data filters in a similar way as we did in this section, for example, in the case of approximation of Gaussian derivatives of higher order or for band-limited versions of derivatives."
        },
        {
            "heading": "4. Numerical Results",
            "text": "In our numerical experiments, we focus on the reconstruction of edge maps. To this end, we use our framework (8) in combination with feature extraction filters that we have derived in Proposition 1 and in Remark 3. Since the gradient and the Laplacian of an image have relatively large values only around edges and small values elsewhere, we aim at exploiting this sparsity and, hence, use a linear combination r(h) = \u00b5\u2016\u2207h\u201622 + \u03bb\u2016h\u20161 as a regularizer in (8). The resulting minimization problem then reads\n1 2 \u2016R\u0398h\u2212 u\u0398 ~s y\u0398\u201622 + \u00b5\u2016\u2207h\u201622 + \u03bb\u2016h\u20161 \u2192 minh\u2208X0 . (21)\nIf \u00b5 = 0, this approach reduces to the `1 regularization which is known to favor a sparse solution. If \u00b5 6= 0, the additional H1-term increases the smoothness of the recovered edges. In order to numerically minimize (21), we use the fast iterative shrinkagethresholding algorithm (FISTA) of [31]. Here, we apply the forward step to 12\u2016R\u0398h\u2212 u\u0398 ~s y\u0398\u201622 + \u00b5\u2016\u2207h\u201622 and the backward step to \u03bb\u2016h\u20161. The discrete `p norms are defined by \u2016h\u2016p = (\u2211Ni,j=1|hij|p) 1 p and the discrete Radon transform R\u0398 is computed via the composite trapezoidal rule and bilinear interpolation. The adjoint Radon transform R\u2217\u0398 is implemented as a discrete backprojection following [5].\n4.1. Reconstruction of the Laplacian Feature Map\nWe first investigate the feasibility of the proposed approach for recovering the Laplacian of the initial image. For our first experiment, we use a simple phantom image which is defined as a characteristic function of the union of three (overlapping) discs. For these synthetic data, we obtain precise edge information, and therefore, the results and edge reconstruction quality can be easily interpreted. The image is chosen to be of size N \u00d7 N pixels, with N = 200, cf. Figure 1a. Since, according to the sampling condition (5), full aliasing free angular sampling requires d\u03c0Nse = 472 samples in the s-variable, we computed tomographic data at 2Ns + 1 = 301 equally spaced signed distances s` \u2208 [\u22121.5, 1.5] and at N\u03d5 = 40 equally spaced directions in [0, \u03c0). This data is properly sampled in the s-variable, but undersampled in the angular variable \u03d5, cf. Figure 1b. In all following numerical simulations, the regularization parameter \u03bb > 0 and the tuning parameter \u00b5 \u2265 0 of (21) have been chosen manually. The development of automated parameter selection is beyond the scope of this paper. From this data, we computed the approximate Laplacian reconstruction, shown in Figure 1c, using the standard FBP algorithm in combination with the LoG-filtered data uLoG ~s y\u0398 that we computed in a preprocessing step using the LoG data filter from Proposition 1. It can be clearly observed that FBP introduces prominent undersampling artefacts (streaks), so that many edges in the calculated feature map are not related to the actual image features. This shows that the edge maps computed by FBP (from undersampled data) can include unreliable information and even falsify the true edge information (since artefacts and actual edges superimpose). In a more realistic setup, this could be even worse, since artefacts may not be that clearly distinguishable from actual edges.\nFigure 2 shows reconstructions of feature maps from noise-free CT data that we computed using our framework (21) for three different choices of feature extraction filters and for two different sets of regularization parameters. The first row of Figure 2 shows reconstructions with \u00b5 = 0 and \u03bb = 0.001 using 1000 iterations of the FISTA algorithm, whereas the second row shows reconstructions that were computed using an additional H1-term with \u03bb = \u00b5 = 0.001 and using 500 iterations of the FISTA algorithm. In contrast to the FBP-LoG reconstruction (shown in Figure 1c), the undersampled artefacts have been removed in all cases. As expected, the use of `1 regularization without an additional H1 smoothing (shown in first row) produces sparser feature maps as opposed to the reconstruction shown in the second row. However, we also observed that the iterative reconstruction based only on the `1 minimization (without the H1 term) sometimes has trouble reconstructing the object boundaries properly. In fact, we found that a proper reconstruction of boundaries is quite sensitive to the choice of the `1 regularization parameter. If this parameter was chosen to be too large, we observed that the boundaries could be incomplete or even disappear. Since the `1 regularization parameter controls the sparsity of the reconstructed feature map, this observation is actually not surprising. By including an additional H1 regularization term, the reconstruction results become less sensitive to the choice of regularization parameters. In order to simulate real world measurements more realistically, we added Gaussian noise to the CT data that we used in the previous experiment. Using this noisy data, we calculated reconstructions via (21) in combination with the Ram\u2013Lak-type filter (20) using three different sets of regularization parameters and 1000 iterations of the FISTA algorithm in each case. The reconstruction using the parameters \u03bb = 0 and \u00b5 = 0.001 (i.e., only H1 regularization was applied) is shown in Figure 3a. The reconstruction in Figure 3b uses only `1 regularization, i.e., \u00b5 = 0 and \u03bb = 0.001, and the reconstruction in Figure 3b applies both regularization terms with \u03bb = \u00b5 = 0.001. In both reconstructions shown in Figure 3b,c, the recovered features are much more apparent than for pure H1 regularization. As in the noise-free situation, we observe that the (pure) `1 regularization might generate discontinuous boundaries, whereas the combined H1-`1 regularization results in smoother and (seemingly) better represented edges. Note that a form of salt-andpepper noise is observed in the reconstructions that include the `1 penalty. We attribute this to the thresholding procedure within FISTA and the rather small regularization parameter. Increasing the regularization parameter would reduce the amount of noise, but would potentially remove some of the desired boundaries.\n(a) LoG: \u00b5 = 0, \u03bb = 0.001 (b) Lowpass:\u00b5 = 0, \u03bb = 0.001 (c) Ram-Lak: \u00b5 = 0, \u03bb = 0.001\n(d) LoG: \u00b5 = \u03bb = 0.001 (e) Lowpass: \u00b5 = \u03bb = 0.001 (f) Ram-Lak: \u00b5 = \u03bb = 0.001\n(a) Ram-Lak: \u00b5 = 0.001, \u03bb = 0 (b) Ram-Lak: \u00b5 = 0, \u03bb = 0.001 (c) Ram-Lak: \u00b5 = \u03bb = 0.001\nFigure 3. RECONSTRUCTIONS OF LAPLACIAN FEATURE MAPS FROM NOISY DATA. The reconstruction in (a) was calculated using only H1 regularization, in (b) using only `1 regularization, and in (c) using combined `1 and H1 regularization.\n4.2. Edge Detection\nOne main application of our framework for the reconstruction of approximate image gradients or approximate Laplacian feature maps is in edge detection. Clearly, feature maps that contain less artefacts can be expected to provide more accurate edge maps. For this experiment, we used a modified phantom image that is shown in Figure 4a. In contrast to the previously used phantom, this image also includes weaker edges that are more challenging to detect. For this phantom, we generated CT data using the same\nsampling scheme as in our first experiment (Section 4.1) and computed the LoG-feature maps f ~ULoG using the FBP approach (cf. Figure 4b) and using our approach (cf. Figure 4c) with \u00b5 = 0, \u03bb = 0.002, and 100 iterations of the FISTA algorithm for (21). Subsequently, we generated corresponding binary edge maps by extracting the zero-crossings of these LoGfeature maps (cf. Figure 4d,e) by using MATLAB edge functions. Note that this procedure is a standard edge detection algorithm known as the LoG edge detector, cf. [30]. For both methods, we took a standard deviation of \u03b1 = 1.3 for the application of the Gaussian smoothing and a threshold of t = 0.005 for the detection of the zero crossings. As can be clearly seen from the results, the edge detection based on our approach (cf. Figure 4d) is able to also detect the weaker edges inside the large disc. In contrast, edge detection in combination with the FBP-LoG feature map was not able to detect the edge set correctly due to strong undersampling artefacts.\nIn our last experiment, we presented edge detection results for real, noisy CT scans of a lotus root [32]. This gives an estimation on the feature reconstruction quality for real life applications, i.e., much more complex data, where the sought feature maps are generally much more complicated compared to our synthetic phantom above. Note that similar reconstructions were presented in [12]. In order to obtain parallel-beam CT data that fit our implementation of R\u0398, we rebinned the lotus data (originally measured in a fan beam geometry) and downsampled it to 2Ns + 1 = 739 signed distances and N\u03d5 = 36 directions, cf. Figure 5d. The Gaussian gradient feature map was computed in two ways: firstly, by applying FBP to the filtered CT data with the data filter (11), cf. Figure 5b; and secondly, by using our approach (8) with \u00b5 = 0 and \u03bb = 0.01 and by applying 50 iterations of the FISTA algorithm, cf. Figure 5c. The resulting image size was 521\u00d7 521. The standard deviation for the Gaussian smoothing was chosen as \u03b1 = 6, and for the Canny edge detection we used the same lower threshold 0.1 and upper threshold 0.15. In order to calculate binary edge maps (shown in Figure 5e,f), we used the Canny edge detector\n(cf. [29]) in combination with the pointwise magnitude of the Gaussian gradient maps |\u2207Ugrad ~ f |. Again, it was observed that the calculation of the Gaussian gradient map using our approach leads to more reliable edge detection results.\nRemark 4. In all of our experiments, especially in Figures 1\u20134, we used phantoms that are piecewise constant images. Our intention here was to examine the performance of our method on phantoms with well-defined geometric edges. However, we would like to note that for such piecewise constant imagesl a two-step approach that combines total variation (TV) reconstruction and edge detection, is expected to produce excellent results, too. This is mainly because piecewise constant images are well represented by the TV-model. In general, the performance of edge detectors that are realized within a two-step approach heavily relies on the a priori assumptions and on the use of suitable priors for the underlying image class. In contrast, our approach aims at reconstructing image features directly from CT data. Therefore, we only need to incorporate an a priori assumption about image features into our framework, which can be formulated independently of the underlying image class. In this sense, our approach is conceptually different from the two-step approach and can be applied in a general imaging situation. In case of edge-reconstruction form CT data, we have shown that a suitable a priori assumption is the sparsity of edge maps (in the pixel domain) and that these apriori assumptions can be efficiently incorporated into our framework by using the `1-prior, yielding numerically efficient algorithms."
        },
        {
            "heading": "5. Conclusions",
            "text": "In this paper, we proposed a framework for the reconstruction of features maps directly from incomplete tomographic data without the need of reconstructing the tomographic image f first. Here, a feature map refers to the convolution U ~ f where U is a given convolution kernel and f is the underlying object. Starting from the forward convolution\nidentity for the Radon transform, we introduced a variational model for feature reconstruction, which was formulated using the discrepancy term \u2016R\u0398h\u2212 u\u0398 ~s y\u0398\u201622 and a general regularizer r(h). In contrast to existing approaches, such as [9,10], our framework does not require full data and, due to the variational formulation, also offers a flexible way for integrating a priori information about the feature map into the reconstruction. In several numerical experiments, we have illustrated that our method can outperform classical feature reconstruction schemes, especially if the CT data is incomplete. Although we mostly focused on the reconstruction of feature maps that are used for edge detection purposes, our framework can be adapted for a wide range of problems. Specifically, such extensions of our framework require the convolutional features to satisfy certain equations that are derived from the data of the original inverse problem. Recently, such equations have been derived for photoacoustic tomography [33]. A rigorous convergence analysis of the presented scheme remains an open issue. Another direction of further research may include the extension of the proposed approach to non-sparse, non-convolutional features and generalization to other types of tomographic problems such as photoacoustic imaging [34]. Additionally, multiple feature reconstruction (similar to the method [33,35]) seems to be an interesting future research direction.\nAuthor Contributions: S.G. carried out the numerical implementation and validation of the proposed approach. He also drafted the manuscript. M.H. and J.F. participated in designing and writing the article. All authors read and approved the final manuscript.\nFunding: The work of M.H. was supported by the Austrian Science Fund (FWF) project P 30747- N32. The contribution by S.G is part of a project that has received funding from the European Union\u2019s Horizon 2020 research and innovation programme under the Marie Sk\u0142odowska-Curie grant agreement No 847476. The views and opinions expressed herein do not necessarily reflect those of the European Commission.\nConflicts of Interest: The authors declare no conflict of interest.\nReferences 1. YU, L.; Liu, X.; Leng, S.; Kofler, J.M.; Ramirez-Giraldo, J.C.; Qu, M.; Christner, J.; Fletcher, J.G.; McCollough, C.H. Radiation dose reduction in computed tomography: Techniques and future perspective. Imaging Med. 2009, 1, 65\u201384. [CrossRef] [PubMed] 2. Brenner, D.J.; Elliston, C.D.; Hall, E.J.; Bredon, W.E. Estimated Risks of Radiation-Induced Fatal Cancer from Pediatric CT. Am. J. Roentgenol. 2001, 176, 289\u2013296. [CrossRef] [PubMed] 3. Nelson, R. Thousands of new cancers predicted due to increased use of CT. Medscape News, 17 December 2009. 4. Shuryak, I.; Sachs, R.K.; Brenner, D.J. Cancer Risks After Radiation Exposure in Middle Age. J. Natl. Cancer Inst. 2010, 3, 1628\u20131636. [CrossRef] [PubMed] 5. Natterer, F. The Mathematics of Computerized Tomography; Classics in Applied Mathematics; Society for Industrial and Applied Mathematics: Philadelphia, PA, USA, 2001. 6. Frikel, J.; Quinto, E.T. Characterization and reduction of artifacts in limited angle tomography. Inverse Probl. 2013, 29, 12. [CrossRef] 7. Jain, A.K. Fundamentals of Digital Image Processing; Prentice-Hall, Inc.: Englewood Cliff, NJ, USA, 1989. 8. J\u00e4hne, B. Digital Image Processing; Springer: Berlin/Heidelberg, Germany, 2005; pp. 397\u2013434. 9. Louis, A.K. Combining Image Reconstruction and Image Analysis with an Application to Two-Dimensional Tomography. SIAM J. Imaging Sci. 2008, 1, 188\u2013208. [CrossRef] 10. Louis, A.K. Feature reconstruction in inverse problems. Inverse Probl. 2011, 27, 6. [CrossRef] 11. Candes, E.J.; Romberg, J.; Tao, T. Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information. IEEE Trans. Inf. Theory 2006, 52, 489\u2013509. [CrossRef] 12. Frikel, J.; G\u00f6ppel, S.; Haltmeier, M. Combining Reconstruction and Edge Detection in Computed Tomography. In Bildverarbeitung\nf\u00fcr die Medizin 2021; Palm, C., Deserno, T.M., Handels, H., Maier, A., Maier-Hein, K., Tolxdorff, T., Eds.; Springer: Wiesbaden, Germany, 2021; pp. 153\u2013157.\n13. Hahn, B.N.; Louis, A.K.; Maisl, M.; Schorr, C. Combined reconstruction and edge detection in dimensioning. Meas. Sci. Technol. 2013, 24, 125601. [CrossRef] 14. Rigaud, G.; Lakhal, A. Image and feature reconstruction for the attenuated Radon transform via circular harmonic decomposition of the kernel. Inverse Probl. 2015, 31, 025007. [CrossRef] 15. Rigaud, G. Compton Scattering Tomography: Feature Reconstruction and Rotation-Free Modality. SIAM J. Imaging Sci. 2017, 10, 2217\u20132249. [CrossRef]\n16. Elangovan, V.; Whitaker, R.T. From sinograms to surfaces: A direct approach to the segmentation of tomographic data. In International Conference on Medical Image Computing and Computer-Assisted Intervention; Springer: Berlin/Heidelberg, Germany, 2001; pp. 213\u2013223. 17. Klann, E.; Ramlau, R.; Ring, W. A Mumford-Shah level-set approach for the inversion and segmentation of SPECT/CT data. Inverse Probl. Imaging 2011, 5, 137. [CrossRef] 18. Storath, M.; Weinmann, A.; Frikel, J.; Unser, M. Joint image reconstruction and segmentation using the Potts model. Inverse Probl. 2015, 31, 025003. [CrossRef] 19. Burger, M.; Rossmanith, C.; Zhang, X. Simultaneous reconstruction and segmentation for dynamic SPECT imaging. Inverse Probl. 2016, 32, 104002. [CrossRef] 20. Romanov, M.; Dahl, A.B.; Dong, Y.; Hansen, P.C. Simultaneous tomographic reconstruction and segmentation with class priors. Inverse Probl. Sci. Eng. 2016, 24, 1432\u20131453. [CrossRef] 21. Shen, L.; Quinto, E.T.; Wang, S.; Jiang, M. Simultaneous reconstruction and segmentation with the Mumford-Shah functional for electron tomography. Inverse Probl. Imaging 2018, 12, 1343\u20131364. [CrossRef] 22. Wei, Z.; Liu, B.; Dong, B.; Wei, L. A Joint Reconstruction and Segmentation Method for Limited-Angle X-Ray Tomography. IEEE Access 2018, 6, 7780\u20137791. [CrossRef] 23. Desbat, L. Efficient sampling on coarse grids in tomography. Inverse Probl. 1993, 9, 251. [CrossRef] 24. Faridani, A. Sampling theory and parallel-beam tomography. In Sampling, Wavelets, and Tomography; Applied and Numerical Harmonical Analysis; Birkh\u00e4user Boston: Boston, MA, USA, 2004; pp. 225\u2013254. 25. Faridani, A. Fan-beam tomography and sampling theory. In The Radon Transform, Inverse Problems, and Tomography; AMS: Atlanta, Georgia, 2006; Volume 63, pp. 43\u201366. 26. Natterer, F. Sampling and resolution in CT. In Computerized Tomography (Novosibirsk, 1993); VSP: Utrecht, The Netherlands, 1995; pp. 343\u2013354. 27. Rattey, P.; Lindgren, A.G. Sampling the 2-D Radon transform. IEEE Trans. Acoust. Speech Signal Process. 1981, 29, 994\u20131002. [CrossRef] 28. Micchelli, C.A.; Rivlin, T.J. A survey of optimal recovery. In Optimal Estimation in Approximation Theory; Springer: Berlin/Heidelberg, Germany, 1977; pp. 1\u201354. 29. Canny, J. A computational approach to edge detection. IEEE Trans. Pattern Anal. Mach. Intell. 1986, PAMI-8, 679\u2013698. [CrossRef] 30. Marr, D.; Hildreth, E. Theory of edge detection. Proc. R. Soc. London. Ser. B. Biol. Sci. 1980, 207, 187\u2013217. 31. Beck, A.; Teboulle, M. A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems. SIAM J. Imaging Sci. 2009, 2, 183\u2013202. [CrossRef] 32. Bubba, T.; Hauptmann, A.; Huotari, S.; Rimpel\u00e4inen, J.; Siltanen, S. Tomographic X-ray data of a lotus root filled with attenuating objects. arXiv 2016, arXiv:1609.07299. 33. Zangerl, G.; Haltmeier, M. Multi-Scale Factorization of the Wave Equation with Application to Compressed Sensing Photoacoustic Tomography. arXiv 2020, arXiv:2007.14747. 34. Jiang, H. Photoacoustic Tomography; Taylor & Francis: Boca Raton, FL, USA, 2014. 35. Haltmeier, M.; Sandbichler, M.; Berer, T.; Bauer-Marschallinger, J.; Burgholzer, P.; Nguyen, L. A New Sparsification and\nReconstruction Strategy for Compressed Sensing Photoacoustic Tomography. J. Acoust. Soc. Am. 2018, 143, 3838\u20133848. [CrossRef]"
        }
    ],
    "title": "Feature Reconstruction from Incomplete Tomographic Data without Detour",
    "year": 2022
}