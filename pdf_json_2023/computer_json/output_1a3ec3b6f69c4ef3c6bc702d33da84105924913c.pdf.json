{
    "abstractText": "Early detection and analysis of lung cancer involve a precise and efficient lung nodule segmentation in computed tomography (CT) images. However, the anonymous shapes, visual features, and surroundings of the nodules as observed in the CT images pose a challenging and critical problem to the robust segmentation of lung nodules. This article proposes a resource-efficient model architecture: an end-to-end deep learning approach for lung nodule segmentation. It incorporates a Bi-FPN (bidirectional feature network) between an encoder and a decoder architecture. Furthermore, it uses the Mish activation function and class weights of masks with the aim of enhancing the efficiency of the segmentation. The proposed model was extensively trained and evaluated on the publicly available LUNA-16 dataset consisting of 1186 lung nodules. To increase the probability of the suitable class of each voxel in the mask, a weighted binary cross-entropy loss of each sample of training was utilized as network training parameter. Moreover, on the account of further evaluation of robustness, the proposed model was evaluated on the QIN Lung CT dataset. The results of the evaluation show that the proposed architecture outperforms existing deep learning models such as U-Net with a Dice Similarity Coefficient of 82.82% and 81.66% on both datasets.",
    "authors": [
        {
            "affiliations": [],
            "name": "Chandra Sekhara Rao Annavarapu"
        },
        {
            "affiliations": [],
            "name": "Nikhil Varma Keetha"
        },
        {
            "affiliations": [],
            "name": "Praveen Kumar Donta"
        }
    ],
    "id": "SP:b62186487a93b65ad5573dd7e2df3336b419b36b",
    "references": [
        {
            "authors": [
                "H. MacMahon",
                "J.H. Austin",
                "G. Gamsu",
                "C.J. Herold",
                "J.R. Jett",
                "D.P. Naidich",
                "E.F. Patz Jr.",
                "S.J. Swensen"
            ],
            "title": "Guidelines for management of small pulmonary nodules detected on CT scans: A statement from the Fleischner Society",
            "venue": "Radiology",
            "year": 2005
        },
        {
            "authors": [
                "T. Kubota",
                "A.K. Jerebko",
                "M. Dewan",
                "M. Salganicoff",
                "A. Krishnan"
            ],
            "title": "Segmentation of pulmonary nodules of various densities with morphological approaches and convexity models",
            "venue": "Med. Image Anal",
            "year": 2011
        },
        {
            "authors": [
                "S. Zhang",
                "X. Chen",
                "Z. Zhu",
                "B. Feng",
                "Y. Chen",
                "W. Long"
            ],
            "title": "Segmentation of small ground glass opacity pulmonary nodules based on Markov random field energy and Bayesian probability difference",
            "venue": "Biomed. Eng. Online",
            "year": 2020
        },
        {
            "authors": [
                "O. Ronneberger",
                "P. Fischer",
                "T. Brox"
            ],
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "venue": "In Proceedings of the International Conference on Medical image Computing and Computer-Assisted Intervention, Munich, Germany,",
            "year": 2015
        },
        {
            "authors": [
                "J.M. Kuhnigk",
                "V. Dicken",
                "L. Bornemann",
                "A. Bakai",
                "D. Wormanns",
                "S. Krass",
                "H.O. Peitgen"
            ],
            "title": "Morphological segmentation and partial volume analysis for volumetry of solid pulmonary lesions in thoracic CT scans",
            "venue": "IEEE Trans. Med. Imaging",
            "year": 2006
        },
        {
            "authors": [
                "S. Diciotti",
                "S. Lombardo",
                "M. Falchini",
                "G. Picozzi",
                "M. Mascalchi"
            ],
            "title": "Automated segmentation refinement of small lung nodules in CT scans by local shape analysis",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2011
        },
        {
            "authors": [
                "P.P. Rebou\u00e7as Filho",
                "A.C. da Silva Barros",
                "J.S. Almeida",
                "J. Rodrigues",
                "V.H.C. de Albuquerque"
            ],
            "title": "A new effective and powerful medical image segmentation algorithm based on optimum path snakes",
            "venue": "Appl. Soft Comput",
            "year": 2019
        },
        {
            "authors": [
                "V. Dharmalingham",
                "D. Kumar"
            ],
            "title": "A model based segmentation approach for lung segmentation from chest computer tomography images. Multimed",
            "venue": "Tools Appl",
            "year": 2019
        },
        {
            "authors": [
                "L. Lu",
                "P. Devarakota",
                "S. Vikal",
                "D. Wu",
                "Y. Zheng",
                "M. Wolf"
            ],
            "title": "Computer aided diagnosis using multilevel image features on large-scale evaluation",
            "venue": "In Proceedings of the International MICCAI Workshop on Medical Computer Vision, Nagoya, Japan,",
            "year": 2013
        },
        {
            "authors": [
                "A.M. Santos",
                "A.O. de Carvalho Filho",
                "A.C. Silva",
                "A.C. de Paiva",
                "R.A. Nunes",
                "M. Gattass"
            ],
            "title": "Automatic detection of small lung nodules in 3D CT data using Gaussian mixture models, Tsallis entropy and SVM",
            "venue": "Eng. Appl. Artif. Intell",
            "year": 2014
        },
        {
            "authors": [
                "M. Prabukumar",
                "L. Agilandeeswari",
                "K. Ganesan"
            ],
            "title": "An intelligent lung cancer diagnosis system using cuckoo search optimization and support vector machine classifier",
            "venue": "J. Ambient. Intell. Humaniz. Comput. 2019,",
            "year": 2019
        },
        {
            "authors": [
                "L. Gon\u00e7alves",
                "J. Novo",
                "A. Campilho"
            ],
            "title": "Hessian based approaches for 3D lung nodule segmentation",
            "venue": "Expert Syst. Appl",
            "year": 2016
        },
        {
            "authors": [
                "J. Jung",
                "H. Hong",
                "J.M. Goo"
            ],
            "title": "Ground-glass nodule segmentation in chest CT images using asymmetric multi-phase deformable model and pulmonary vessel removal",
            "venue": "Comput. Biol. Med",
            "year": 2018
        },
        {
            "authors": [
                "K.Y. Devi",
                "M. Sasikala"
            ],
            "title": "Labeling and clustering-based level set method for automated segmentation of lung tumor stages in CT images",
            "venue": "J. Ambient. Intell. Humaniz. Comput",
            "year": 2021
        },
        {
            "authors": [
                "W. Shen",
                "M. Zhou",
                "F. Yang",
                "D. Yu",
                "D. Dong",
                "C. Yang",
                "Y. Zang",
                "J. Tian"
            ],
            "title": "Multi-crop convolutional neural networks for lung nodule malignancy suspiciousness classification",
            "venue": "Pattern Recognit",
            "year": 2017
        },
        {
            "authors": [
                "Y. Feng",
                "P. Hao",
                "P. Zhang",
                "X. Liu",
                "F. Wu",
                "H. Wang"
            ],
            "title": "Supervoxel based weakly-supervised multi-level 3D CNNs for lung nodule detection and segmentation",
            "venue": "J. Ambient. Intell. Humaniz. Comput",
            "year": 2019
        },
        {
            "authors": [
                "S. Wang",
                "M. Zhou",
                "O. Gevaert",
                "Z. Tang",
                "D. Dong",
                "Z. Liu",
                "J. Tian"
            ],
            "title": "A multi-view deep convolutional neural networks for lung nodule segmentation",
            "venue": "In Proceedings of the 2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Jeju Island, Republic of Korea,",
            "year": 2017
        },
        {
            "authors": [
                "X. Huang",
                "W. Sun",
                "T.L.B. Tseng",
                "C. Li",
                "W. Qian"
            ],
            "title": "Fast and fully-automated detection and segmentation of pulmonary nodules in thoracic CT scans using deep convolutional neural networks",
            "venue": "Comput. Med. Imaging Graph",
            "year": 2019
        },
        {
            "authors": [
                "S. Kumar",
                "S. Raman"
            ],
            "title": "Lung nodule segmentation using 3-dimensional convolutional neural networks. In Proceedings of the Soft Computing for Problem Solving: SocProS 2018",
            "venue": "Vellore, India,",
            "year": 2018
        },
        {
            "authors": [
                "R. Li",
                "C. Xiao",
                "Y. Huang",
                "H. Hassan",
                "B. Huang"
            ],
            "title": "Deep learning applications in computed tomography images for pulmonary nodule detection and diagnosis: A review",
            "venue": "Diagnostics",
            "year": 2022
        },
        {
            "authors": [
                "M. Havaei",
                "A. Davy",
                "D. Warde-Farley",
                "A. Biard",
                "A. Courville",
                "Y. Bengio",
                "C. Pal",
                "P.M. Jodoin",
                "H. Larochelle"
            ],
            "title": "Brain tumor segmentation with deep neural networks. Med",
            "venue": "Image Anal",
            "year": 2017
        },
        {
            "authors": [
                "W. Sun",
                "B. Zheng",
                "W. Qian"
            ],
            "title": "Automatic feature learning using multichannel ROI based on deep structured algorithms for computerized lung cancer diagnosis",
            "venue": "Comput. Biol. Med",
            "year": 2017
        },
        {
            "authors": [
                "X. Zhao",
                "W. Sun",
                "W. Qian",
                "S. Qi",
                "J. Sun",
                "B. Zhang",
                "Z. Yang"
            ],
            "title": "Fine-grained lung nodule segmentation with pyramid deconvolutional neural network. In Proceedings of the Medical Imaging 2019: Computer-Aided Diagnosis. International Society for Optics and Photonics",
            "venue": "Volume 10950,",
            "year": 2019
        },
        {
            "authors": [
                "J. Long",
                "E. Shelhamer",
                "T. Darrell"
            ],
            "title": "Fully convolutional networks for semantic segmentation",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2015
        },
        {
            "authors": [
                "\u00d6. \u00c7i\u00e7ek",
                "A. Abdulkadir",
                "S.S. Lienkamp",
                "T. Brox",
                "O. Ronneberger"
            ],
            "title": "3D U-Net: Learning dense volumetric segmentation from sparse annotation",
            "venue": "In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, Athens, Greece,",
            "year": 2016
        },
        {
            "authors": [
                "S. Wang",
                "M. Zhou",
                "Z. Liu",
                "D. Gu",
                "Y. Zang",
                "D. Dong",
                "O. Gevaert",
                "J. Tian"
            ],
            "title": "Central focused convolutional neural networks: Developing a data-driven model for lung nodule segmentation",
            "venue": "Med. Image Anal",
            "year": 2017
        },
        {
            "authors": [
                "H. Cao",
                "H. Liu",
                "E. Song",
                "C.C. Hung",
                "G. Ma",
                "X. Xu",
                "R. Jin",
                "J. Lu"
            ],
            "title": "Dual-branch residual network for lung nodule segmentation",
            "venue": "Appl. Soft Comput",
            "year": 2020
        },
        {
            "authors": [
                "J. Rocha",
                "A. Cunha",
                "A.M. Mendon\u00e7a"
            ],
            "title": "Conventional Filtering Versus U-Net Based Models for Pulmonary Nodule Segmentation in CT Images",
            "venue": "J. Med. Syst",
            "year": 2020
        },
        {
            "authors": [
                "G. Singadkar",
                "A. Mahajan",
                "M. Thakur",
                "S. Talbar"
            ],
            "title": "Deep Deconvolutional Residual Network Based Automatic Lung Nodule Segmentation",
            "venue": "J. Digit. Imaging",
            "year": 2020
        },
        {
            "authors": [
                "W.F. Chen",
                "H.Y. Ou",
                "H.Y. Lin",
                "C.P. Wei",
                "C.C. Liao",
                "Y.F. Cheng",
                "C.T. Pan"
            ],
            "title": "Development of Novel Residual-Dense-Attention (RDA) U-Net Network Architecture for Hepatocellular Carcinoma Segmentation",
            "venue": "Diagnostics 2022,",
            "year": 1916
        },
        {
            "authors": [
                "A. Miko\u0142ajczyk",
                "M. Grochowski"
            ],
            "title": "Data augmentation for improving deep learning in image classification problem",
            "venue": "In Proceedings of the 2018 International Interdisciplinary PhD Workshop (IIPhDW), Swinoujscie, Poland,",
            "year": 2018
        },
        {
            "authors": [
                "C. Shorten",
                "T.M. Khoshgoftaar"
            ],
            "title": "A survey on image data augmentation for deep learning",
            "venue": "J. Big Data 2019,",
            "year": 2019
        },
        {
            "authors": [
                "R. LaLonde",
                "U. Bagci"
            ],
            "title": "Capsules for object segmentation",
            "venue": "arXiv 2018,",
            "year": 2018
        },
        {
            "authors": [
                "D. Misra"
            ],
            "title": "Mish: A Self Regularized Non-Monotonic Neural Activation Function",
            "venue": "arXiv 2019,",
            "year": 2019
        },
        {
            "authors": [
                "M. Tan",
                "R. Pang",
                "Q.V. Le"
            ],
            "title": "Efficientdet: Scalable and efficient object detection",
            "venue": "arXiv 2019,",
            "year": 2019
        },
        {
            "authors": [
                "Y. Bengio",
                "Y. Grandvalet"
            ],
            "title": "No unbiased estimator of the variance of k-fold cross-validation",
            "venue": "J. Mach. Learn. Res. 2004,",
            "year": 2004
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv 2014,",
            "year": 2014
        },
        {
            "authors": [
                "R. Caruana",
                "S. Lawrence",
                "C.L. Giles"
            ],
            "title": "Overfitting in neural nets: Backpropagation, conjugate gradient, and early stopping",
            "venue": "In Proceedings of the Advances in Neural Information Processing Systems, Denver CO, USA,",
            "year": 2000
        },
        {
            "authors": [
                "C. Jacobs",
                "E.M. van Rikxoort",
                "T. Twellmann",
                "E.T. Scholten",
                "P.A. de Jong",
                "J.M. Kuhnigk",
                "M. Oudkerk",
                "H.J. de Koning",
                "M. Prokop",
                "C Schaefer-Prokop"
            ],
            "title": "Automatic detection of subsolid pulmonary nodules in thoracic computed tomography",
            "venue": "images. Med. Image Anal",
            "year": 2014
        },
        {
            "authors": [
                "A.A. Setio",
                "C. Jacobs",
                "J. Gelderblom",
                "B. van Ginneken"
            ],
            "title": "Automatic detection of large pulmonary solid nodules in thoracic",
            "venue": "CT images. Med. Phys",
            "year": 2015
        },
        {
            "authors": [
                "E.M. van Rikxoort",
                "B. de Hoop",
                "M.A. Viergever",
                "M. Prokop",
                "B. van Ginneken"
            ],
            "title": "Automatic lung segmentation from thoracic computed tomography scans using a hybrid approach with error detection",
            "venue": "Med. Phys. 2009,",
            "year": 2009
        },
        {
            "authors": [
                "S.G. Armato III",
                "G. McLennan",
                "L. Bidaut",
                "M.F. McNitt-Gray",
                "C.R. Meyer",
                "A.P. Reeves",
                "B. Zhao",
                "D.R. Aberle",
                "C.I. Henschke",
                "E.A Hoffman"
            ],
            "title": "The lung image database consortium (LIDC) and image database resource initiative (IDRI): A completed reference database of lung",
            "venue": "nodules on CT scans. Med. Phys",
            "year": 2011
        },
        {
            "authors": [
                "A.A.A. Setio",
                "A. Traverso",
                "T. De Bel",
                "M.S. Berens",
                "C. van den Bogaard",
                "P. Cerello",
                "H. Chen",
                "Q. Dou",
                "M.E. Fantacci",
                "B Geurts"
            ],
            "title": "Validation, comparison, and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images: The LUNA16 challenge",
            "venue": "Med. Image Anal",
            "year": 2017
        },
        {
            "authors": [
                "J. Kalpathy-Cramer",
                "J.B. Freymann",
                "J.S. Kirby",
                "P.E. Kinahan",
                "F.W. Prior"
            ],
            "title": "Quantitative imaging network: Data sharing and competitive AlgorithmValidation leveraging the cancer imaging archive",
            "venue": "Transl. Oncol",
            "year": 2014
        },
        {
            "authors": [
                "K. Clark",
                "B. Vendt",
                "K. Smith",
                "J. Freymann",
                "J. Kirby",
                "P. Koppel",
                "S. Moore",
                "S. Phillips",
                "D. Maffitt",
                "M Pringle"
            ],
            "title": "The Cancer Imaging Archive (TCIA): Maintaining and operating a public information repository",
            "venue": "J. Digit. Imaging",
            "year": 2013
        },
        {
            "authors": [
                "K. Jayashree",
                "N. Sandy"
            ],
            "title": "Multi-site collection of lung ct data with nodule segmentations",
            "venue": "J. Digit. Imaging",
            "year": 2015
        },
        {
            "authors": [
                "J. Kalpathy-Cramer",
                "B. Zhao",
                "D. Goldgof",
                "Y. Gu",
                "X. Wang",
                "H. Yang",
                "Y. Tan",
                "R. Gillies",
                "S. Napel"
            ],
            "title": "A comparison of lung nodule segmentation algorithms: Methods and results from a multi-institutional study",
            "venue": "J. Digit. Imaging",
            "year": 2016
        },
        {
            "authors": [
                "A. Chon",
                "N. Balachandar",
                "P. Lu"
            ],
            "title": "Deep Convolutional Neural Networks for Lung Cancer Detection; Standford University",
            "year": 2017
        },
        {
            "authors": [
                "S. Valverde",
                "A. Oliver",
                "E. Roura",
                "S. Gonz\u00e1lez-Vill\u00e0",
                "D. Pareto",
                "J.C. Vilanova",
                "L. Rami\u00f3-Torrent\u00e0",
                "\u00c0. Rovira",
                "X. Llad\u00f3"
            ],
            "title": "Automated tissue segmentation of MR brain images in the presence of white matter lesions",
            "venue": "Med. Image Anal",
            "year": 2017
        },
        {
            "authors": [
                "G. Kang",
                "K. Liu",
                "B. Hou",
                "N. Zhang"
            ],
            "title": "3D multi-view convolutional neural networks for lung nodule classification",
            "venue": "PLoS ONE 2017,",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "Citation: Annavarapu, C.S.R.;\nParisapogu, S.A.B.; Keetha, N.V.;\nDonta, P.K.; Rajita, G. A\nBi-FPN-Based Encoder\u2013Decoder\nModel for Lung Nodule Image\nSegmentation. Diagnostics 2023, 13,\n1406. https://doi.org/10.3390/\ndiagnostics13081406\nAcademic Editor: Francis Bui\nReceived: 12 March 2023\nRevised: 2 April 2023\nAccepted: 4 April 2023\nPublished: 13 April 2023\nCopyright: \u00a9 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: segmentation; deep learning; computed tomography; medical image analysis"
        },
        {
            "heading": "1. Introduction",
            "text": "According to data released by the World Health Organization (WHO) on 3 February 2020, cancer is one of the leading causes of premature death in 134 of 183 countries. It has been observed that, especially in 2018, most of the prominent cancer deaths are due to lung cancer (1.76 million deaths). Detection and analysis of the lung nodules at an early stage facilitate efficient treatment and drastically improve a patient\u2019s chance of survival [1]. CT scans are a widely used and highly accurate format for the purpose of screening and analyzing lung nodules, especially in differentiating the nodules from other structures. Moreover, the precise segmentation of these nodules is critical, considering the heterogeneity of the size, texture, location, and shape of the nodules, and the fact that their intensity may differ within the borders [2]. There are various types of lung nodules as observed in Figure 1 such as adhesion-type (juxtapleural and juxta-vascular), isolated, cavitary, calcified, small, and ground-glass opacity (GGO) nodules [3]. Another challenge lies in the segmentation of lung nodules, which is found in the case of nodules with small diameter and intensity comparable to that of the surrounding noise, which thereby hinders the down-sampling potential of the segmentation network, where the network cannot extract more in-depth semantic network features [4]. It significantly impacts the accuracy of the extraction of feature maps of large nodules. Based on these\nDiagnostics 2023, 13, 1406. https://doi.org/10.3390/diagnostics13081406 https://www.mdpi.com/journal/diagnostics\nreasons, a robust segmentation network is necessary to accommodate the large-scale nodule (various types) problem.\nRecently, convolutional neural networks (CNN) have become the mainstream architecture in the field of computer vision. One such architecture, the U-Net, is an encoder\u2013 decoder-like CNN architecture, which has shown exceptional results in segmentation of biomedical images [5]. Many modified U-Net architectures have achieved significant results in different domains of biomedical imaging. However, CNN architectures that are implemented for the task of lung nodule segmentation are still immature. Therefore, the development of advanced architectures dealing with the shortcomings of previous architectures is essential. To deal with the challenges of efficient feature extraction and adaptation to heterogeneity of lung nodules, this paper proposes a modified U-Net architecture with a weighted bidirectional feature network (U-Det), which is appropriate for the segmentation of many forms of lung nodules. Figure 2 illustrates the pipeline of the proposed model.\nContributions\nThe list of the following elements provides technical contributions of this research:\n1. The proposed U-Det model uses a bidirectional feature network (Bi-FPN), which functions as a feature enricher, integrating multi-scale feature fusion for efficient feature extraction. 2. Applying a data augmentation technique to deal with the small-size dataset prevents the model from over-fitting and provides better segmentation results. 3. Implementing the Mish activation function, due to its strong regularization effects, provides enhanced model training and segmentation efficiency. 4. Comparing the proposed U-Det model to the existing U-Net to the existing U-Net shows its high segmentation performance on small nodules and various categories of other pulmonary nodules."
        },
        {
            "heading": "2. Background and Related Work",
            "text": "This section describes the existing conventional and machine-learning-based segmentation approaches for lung nodule segmentation."
        },
        {
            "heading": "2.1. Conventional Approaches",
            "text": "Many conventional approaches, such as morphological methods, region-growing processes, energy-based optimization techniques, and machine learning methods, were proposed for lung nodule segmentation in the literature. In morphological methods, morphology-based operations and those based on shape hypothesis were applied to isolate lung nodules by selecting the connected region [6]. However, the isolation of lung nodules using morphological operations did not perform efficiently [7]. Following that, regiongrowing methods were proposed to improve lung nodule segmentation but it was observed that these methods were unable to segment juxta-vascular and juxtapleural nodules and were only well suited to isolate calcified nodules [3]. In this case, for region-growing methods, the convergence condition and irregular-shaped nodules create difficulty due to the breach of the shape hypothesis. Similarly, energy based-optimization methods were also proposed for lung nodule segmentation. These methods consist of a level set function for the characterization of the image, and an energy function to typically turn the segmentation task into an energy minimization problem [8]. However, juxtapleural nodules and low contrast nodules such as GGO nodules drastically affect the improvement of lung nodule segmentation."
        },
        {
            "heading": "2.2. Machine-Learning-Based Approaches",
            "text": "In the past decade, many machine-learning\u2013based methods were proposed for lung nodule segmentation [9]. An example of one such approach is the hybrid model for classifying the lung nodules with high-level feature maps proposed by Lu et al. [10]. Further, methods based on modified support vector machines were suggested to detect small lung nodules in 3D CT scans [11,12]. Down the line, researchers also developed 3D large-scale nodule segmentation techniques based on the Hessian strategy in combination with neural networks [13]. Similarly, segmentation approaches based on multi-phase models [14], unsupervised k-means clustering, and level set algorithms [15] were also proposed. Among the recently developed deep learning-based approaches for segmentation, CNN is a multi-layered neural network that learns to map original image files and corresponding labels hierarchically, and to change the segmentation task into the classification of voxels [16,17]. For instance, Wang et al. introduced a multi-view CNN (MV-CNN) for nodule segmentation [18]. Further, Huang et al. developed a fast and fully automated detection and segmentation approach for pulmonary nodules in thoracic CT scans using deep convolutional neural networks [19]. Moreover, the authors Subham and Raman developed a lung nodule segmentation approach Using 3-dimensional convolutional neural networks [20]. A good review is also available on pulmonary nodule detection and diagnosis using deep learning applications in computed tomography images [21]. Moreover, Havaei et al. in [22] proposed a cascaded variant of CNN (Cascaded-CNN) for brain tumor segmentation. Further extending the use of CNN to lung nodule segmentation, Shen et al. proposed a multi-crop CNN (MC-CNN) to extract salient nodule features and classify malignancy [16]. Furthermore, Wang et al. in [18] introduced a multi-view deep CNN (MV-DCNN), and Sun et al. in [23] introduced a three multi-channel region of interest (RoI)-based CNN (MCROI-CNN) for lung nodule segmentation and displayed the effectiveness of CNN over existing computer-aided diagnosis systems. Further expanding work on CNN-based architectures, Zhao et al. have advocated an enhanced pyramid deconvolution network for increasing performance on lung nodule segmentation which blends low-level fine-grained characteristics with high-level functional characteristics [24]. On the other hand, fully convolutional networks [25] are a different approach for CT image segmentation. For example, the architectures 2D U-Net and 3D U-Net, proposed by Ronnerberger et al. and Ciccek et al., respectively, are better adapted to biomedical imaging [5,26]. The fully convolutional network U-Net (FCN-UNET) architecture is a convolutional network architecture used for fast and precise segmentation of images. Similarly, the central focused CNN (CF-CNN) proposed by Wang et al. is a data-driven method without involving the shape hypothesis. It showed strong performance for the segmentation\nof juxtapleural nodules [27]. Moreover, Cao et al. recently proposed incorporating intensity features into the CNN architecture by implementing a dual-branch residual network (DB-ResNet) [28]. Segmentation 2D convolutional U-Network (SegU-Net), a U-Net-based architecture, has also been suggested for lung nodule segmentation [29]. For pre-processing, Wang et al. and Cao et al. implemented weighted sampling of training data to deal with the comparatively smaller size of the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) dataset [27,28]. The input slice of a CT scan is cropped to a smaller size with a random weighted sampling strategy to increase the size of the training dataset in the abovementioned method. Recently, Singadkar et al. proposed another approach toward lung nodule segmentation based on a deep deconvolutional residual network (DDRN) [30]. In DDRN, the approach was based on an encoder\u2013decoder architecture with one-directional long-skip connections. Moreover, Wen-Fan Chen et al. developed a residual-dense-attention (RDA) U-Net network architecture for hepatocellular carcinoma segmentation [31]."
        },
        {
            "heading": "3. Proposed Method",
            "text": "This section explains the following three phases of the proposed model: (1) data augmentation, (2) model architecture, and (3) training and post-processing. Figure 3 visualizes the proposed U-Det model architecture."
        },
        {
            "heading": "3.1. Data Augmentation",
            "text": "Due to the constraints of much available training data in medical image segmentation, data augmentation helps in preventing the model from over-fitting. It also improves the generalization capability of the network on data outside the training set. Along with that, it plays a vital role in building robust deep learning pipelines [32,33]. A data augmentation strategy instead of a sampling strategy was applied to input CT images of size 512\u00d7 512 for maintaining the same input size in the proposed model. Data augmentation methods applied in the proposed network are scale, flip, shift, rotate, salt and pepper noise, and elastic deformations [34]. By applying these small transformations to images during training, variety was created in the training dataset and robustness of the proposed model was improved."
        },
        {
            "heading": "3.2. Model Architecture",
            "text": "The architecture of the proposed model is an end-to-end deep learning approach for lung nodule segmentation, inspired by the encoder\u2013decoder backbone of U-Net, and the feature enricher Bi-FPN. The proposed U-Det architecture is designed to take a 512\u00d7 512 image as an input and a 512 \u00d7 512 mask as output. It consists of three sections: the contraction, Bi-FPN, and the expansion section of depth 5, which behave similarly to an\nencoder, feature enricher, and decoder. Table 1 shows the corresponding layers of the model, along with their respective parameters.\nInitially, the contraction section takes the augmented CT image, a slice of the CT scan. Here, the repeated application of two 3\u00d7 3 convolutions (with the \u2018same\u2019 padding) is applied using Equation (1)\nC[m, n] = (I \u00d7 k)[m, n] = \u2211 i \u2211 j k[i, j].I[m\u2212 i, n\u2212 j], (1)\nwhere C[m, n] represents the kernel convolution, I and k denote the input image and kernel, respectively, and \u2018m\u2019 and \u2018n\u2019 represent the number of \u2018training samples\u2019 and \u2018features\u2019, respectively. Further, each convolution is followed by a recently proposed non-linear Mish activation function [35], to perform strong regularization during the forward and backward pass of the model, the formula of which is shown in Equation (2)\nf (x) = x. tanh(\u03c9(x)), (2)\nwhere \u03c9(x) is the Softplus activation function given by ln(1 + ex). Mish implements a self-gating function, in which the input given to the gate is a scalar. The property of self-gating helps in replacing the activation functions (point-wise functions) such as rectified linear unit (ReLU). Here, the input of the gating function is a scalar with no requirement of modifying network parameters. The properties of Mish, being aboveunbounded, below-bounded, non-monotonic, and smooth, play a vital part in maximizing neural network outcomes. Hence, Mish enables considerable time improvements during the forward and backward pass on Graphics Processing Unit (GPU) inference when Compute Unified Device Architecture (CUDA) is enabled and improves the efficiency of the model. Further, a 2\u00d7 2 max-pooling operation of stride \u20182\u2019 is applied for down-sampling of the input image features. Here, at depth 4, a dropout layer with a dropout factor of 0.5 is used for the regularization of the model. The feature maps of the corresponding five depths of the contraction path are then fed as input to the Bi-FPN, as illustrated in Figure 3. For efficient feature extraction, Bi-FPN implemented in the proposed method is based on conventional top-down Feature Pyramid Networks (FPN) [36]. It infuses efficient bidirectional cross-scale connections and weighted feature fusion into the model. In the Bi-FPN, multi-scale feature fusion aims to fuse features at different resolutions to obtain efficient feature extractions. In contrast, the one-way flow of information inherently limits\nconventional top-down FPN. Thus, Bi-FPN does not consist of nodes with only one input edge because if a node has only one input with no feature fusion, it will contribute less to the feature network to infuse different features. Moreover, the Bi-FPN has one top-down and one bottom-up path, thereby allowing the bidirectional flow of features from one depth to another in the feature network. The Bi-FPN also incorporates additional weight for each input during feature fusion, thereby learning the importance of a particular input feature. In the Bi-FPN, dynamic learning behavior and accurate fast normalized fusion (one of the methods of incorporating weights during feature fusion) are implemented. Moreover, for improved efficiency, depth-wise separable convolution followed by batch normalization and non-linear ReLU activation function are implemented. Through the bidirectional cross-scale connections, the Bi-FPN enriches the feature maps at each depth of the network and provides an efficient fusion of features across various depths of the encoder\u2013decoder architecture. Incorporating a bidirectional feature network aims to improve the efficiency of feature extraction at each level of the backbone architecture and enrich the feature vectors, thus allowing a fusion of lower-level fine-grained and higher-level semantic features. As illustrated in Figure 3, the inputs of the Bi-FPN are the feature maps of the corresponding five depths of the contraction path of the backbone architecture. Then, the outputs of Bi-FPN are fed into the expansion path of the backbone network. Inside the expansion section, the outputs of Bi-FPN are each combined with a decoder architecture to obtain a combination of lower-level fine-grained features with high-level semantic features. Each step in the expansion path consists of an up-sampling of the feature map followed by a 2\u00d7 2 convolution (up-convolution), which halves the number of feature channels at each depth. The feature vectors obtained after up-sampling are concatenated with the corresponding feature vectors from the Bi-FPN. The concatenation operation is followed by two 3\u00d7 3 convolutions (with the \u2018same\u2019 padding), and each is followed by the Mish activation function. In the final layer of the expansion section, the obtained 512\u00d7 512\u00d7 64 feature map undergoes two 3 \u00d7 3 convolutions, which are again followed by the Mish activation function. Then a 1\u00d7 1 convolution block and a sigmoid activation function are applied as the final operation. Thus, they obtain logits corresponding to the mask of the input CT image of 512\u00d7 512."
        },
        {
            "heading": "3.3. Training and Post-Processing",
            "text": "The network training aims to increase the probability of the suitable class of each voxel in the mask. In respect to that, a weighted binary cross-entropy loss of each sample for training was utilized. The positive pixels, by the ratio of negative-to-positive voxels, in the training set were weighted to implement weighted binary cross-entropy. Since the size of the positive class in a lung nodule mask is relatively smaller compared to that of the negative class, the training set\u2019s class weight is positive, thereby increasing the punishment for getting a positive value wrong. So the network will learn to be less biased toward outputting negative voxels due to the class imbalance in the masks. The weighted binary cross-entropy loss is formulated as follows:\nLoss = \u22121 N\nN\n\u2211 i=1 [\u03c9p \u00d7 yi log y\u0302i + (1\u2212 yi) log (1\u2212 y\u0302i)], (3)\nwhere, N represents the number of samples, \u03c9p represents the positive prediction weights, yi represents the ground truth, and y\u0302i indicates the prediction of the U-Det model.In the training approach, K-fold cross-validation [37] was utilized to obtain an accurate measure of the generalizing capability of the proposed model. Furthermore, to deal with the generation of augmented training CT images and corresponding ground truths, generators were implemented to augment input images and the generation of corresponding ground truth labels. For model optimization, the Adam model optimization algorithm [38], which updates network weights requiring little hyper-parameter fine-tuning, was utilized with the\nfollowing hyper-parameters: the initial learning rate is 0.0001, Beta_1 = 0.99, Beta_2 = 0.999, and the decay rate is 1 \u00d7 10\u22126. Moreover, a batch size of two samples was chosen based on the memory size of the GPU for training the model. Further, the early stopping training strategy [39] was applied to prevent over-fitting. Additionally, the strategy of reducing the learning rate of the optimizer once the model\u2019s performance reaches a plateau was utilized. In the post-processing phase, the proposed model was designed to save the final obtained masks in a raw, metal (.mhd) format, storing volumetric data such as CT scans."
        },
        {
            "heading": "4. Data and Experiments",
            "text": "This section explains the details regarding the dataset, implementation, and evaluation metrics."
        },
        {
            "heading": "4.1. Data",
            "text": "For the experimentation and training of the proposed model, the approach utilized the publicly available dataset of the Lung Nodule Analysis 2016 (LUNA16) grand challenge [40\u201342], which is derived from the public LIDC-IDRI dataset [43,44]. In total, 888 CT scans are included in the dataset. Figure 4 illustrates the histogram of the nodule amount and diameter of nodules for the LUNA16 dataset. In addition to the LUNA16 dataset, the Quantitative Imaging Network (QIN) [45] Lung CT Segmentation dataset was used to evaluate the effectiveness of the proposed model. The QIN dataset contains 41 CT scans of non-small-cell lung cancer collected from different sources, such as LIDC, Reference Image Database to Evaluate Therapy Response (RIDER), Stanford University Medical Center, the Moffitt Cancer Center, and the Columbia University Phantom [46\u201348]. This dataset contains a total of 52 lung CT nodules across the 41 CT scans.\nIn the pre-processing phase, the CT images and ground truth masks were generated from CT scans, utilizing the Kaggle Data Science Bowl 2017 Competition based on annotations and a mask creation algorithm [49]. By using this method we obtained a total of 1166 CT images with corresponding ground truth masks. Further, it was partitioned into a training and a test subset containing 922 and 244 images, respectively, and we applied\nK-fold cross-validation of 4-folds during model training. The two subsets showed identical statistical distribution in their clinical characteristics, as depicted in Table 2. Furthermore, the same pre-processing strategy was used on the QIN dataset with the provided lung nodule locations to generate 156 CT images with corresponding ground truth masks.\nMalignancy 2.95 \u00b1 0.92 3.03 \u00b1 1.00 Note: The range for all distinctive feature values except diameter was observed between 1 and 5. The \u2018Margin\u2019 characteristic shows nodule edge clarity. Both \u2018Spiculation\u2019 and \u2018Lobulation\u2019 indicate the shape characteristics of the nodule. \u2018Subtlety\u2019 explains the contrast between the nodule zone and its surrounding areas. \u2018Malignancy\u2019 reflects the possibility of this characteristic in a nodule."
        },
        {
            "heading": "4.2. Evaluation Metrics",
            "text": "The Dice Similarity Coefficient (DSC) was used as the key evaluation metric for assessing the segmentation performance of the U-Det model. It is a commonly used metric to calculate the difference between the outcomes of two segmentations [22,50]. In addition to the abovementioned metrics, the sensitivity (SEN) and positive predictive value (PPV) were used as additional evaluation metrics, and are formulated as follows\nDSC = 2\u00d7V(Gt \u2229 Sv) V(Gt) + V(Sv) , (4)\nSEN = V(Gt \u2229 Sv)\nV(Gt) , (5)\nPPV = V(Gt \u2229 Sv)\nV(Sv) , (6)\nwhere \u201cGt\u201d represents the ground truth labels, and \u201cSv\u201d represents the segmentation results of the proposed model. Here, the volume size measured in voxel units is represented by \u201cV\u201d."
        },
        {
            "heading": "4.3. Implementation Details",
            "text": "The experimental implementation was performed using TensorFlow (Version 2.1) deep learning framework (GPU version), Python 3.6 was the language used for coding, and CUDA 10.2 was applied for accelerated training. The experiment was carried out using Google cloud platform on a virtual instance equipped with 4 vCPUs, 15GB memory, and an SSD drive of 500 GB. During the model\u2019s training, acceleration was performed using NVIDIA Tesla T4 GPU (14 GB video memory), and it needed about 8 h of training (20 epochs) to converge. The following link provides the source code of the implementation https://github.com/Nik-V9/U-Det, accessed on 11 March 2023."
        },
        {
            "heading": "5. Experimental Results",
            "text": "This section covers the details of the ablation study, overall performance of the proposed method, and experimental results."
        },
        {
            "heading": "5.1. Ablation Experiment",
            "text": "An ablation experiment was designed, based on the U-Net architecture with the LUNA16 test set, to verify the effectiveness of each component in the proposed architecture. The outcomes of this experiment are displayed in Table 3.\n5.1.1. Effect of Mish Activation Function\nFrom Table 3, U-Net + Mish indicates the incorporation of the Mish activation function instead of the ReLU activation function of the original U-Net architecture. The DSC score of the original U-Net was 77.84%. It can be noticed that after implementing the Mish function in U-Net, this score was increased to 78.82%. On the other hand, an encoder consisting of the contraction path of the U-Net along with the Bi-FPN was implemented. On adding the Mish activation function to the abovementioned architecture, the DSC score became 80.22%. Moreover, a version of the proposed U-Det model with ReLU was applied, which performed marginally inferior to the Mish version. It can be observed that the percentage increase in performance due to Mish was nearly 1.3. Thus it is evident that the Mish activation function is useful in the U-Det model.\n5.1.2. Effect of Bi-FPN\nIn the description of Table 3, it can be discovered that Encoder + Bi-FPN replaced the backbone architecture with only a contraction path and the Bi-FPN functioned as the feature enricher and decoder. It can be observed that this architecture showed an improvement over the basic U-Net and achieved a DSC of 79.21%. Moreover, the ReLU version of the U-Det model is an incorporation of the Bi-FPN in the U-Net architecture; here, the DSC score showed 81.63%, which was a significant improvement over the original U-Net. In addition to the above, even though the Bi-FPN is less computationally expensive than the U-Net architecture\u2019s expansive path in terms of parameters, the Encoder + BiFPN successfully incorporates multiple feature fusions. The multi-feature fusion allows simultaneous feature map enhancement, thereby showing improvement over the U-Net architecture. In addition to that, the multiple implementations of Bi-FPN may serve as a decoder pathway, but it results in more complexity, computational expense and did not result in significant improvement in our study. Thus it can be inferred that the implementation of Bi-FPN between the expansive and contractive paths proved to be very effective in the proposed model.\n5.1.3. Effect of Bi-FPN + Expansion Path\nThe combination of Bi-FPN and the expansion path (ReLU version of the U-Det model) was much more productive compared to the Encoder + Bi-FPN; it exhibited a DSC score of 81.63%. The addition of the expansion path of U-Net to the Encoder + Bi-FPN model helped in the proper up-sampling of low-level features and a combination of feature maps from Bi-FPN, thereby enabling the efficient fusion of high-level semantic features with low-level features.\n5.1.4. Conclusion of the Ablation Study\nFrom the observation of the DSC score of the U-Det model in Table 3 (82.82%), it is evident that the proposed U-Det model shows significant improvement over U-Net. Additionally, the effectiveness of all components and their culmination in the proposed model was verified through the ablation study."
        },
        {
            "heading": "5.2. Overall Performance",
            "text": "The histogram of the DSC values and the total amount of nodules, centered on every sample in the LUNA16 test set, is plotted in Figure 5 for better evaluation of the output of the U-Det model on the test set. From Figure 5, it can be quickly concluded that most of the nodules have a DSC value greater than 0.8.\nFor verifying the effectiveness of the Bi-FPN, the DSC results on the LUNA16 test set were compared with those of the original U-Net architecture. It can be observed that the U-Net model had a DSC of 77.84%, whereas the proposed model obtained a DSC of 82.82%, representing robust performance in the task of segmentation. Furthermore, by containing fewer parameters than the original U-Net architecture, the proposed U-Det model has shown its potential for efficient feature extraction and segmentation. The segmentation results of complex cases, including attached (juxtapleural and juxtavascular) and small-size nodules from both the LUNA16 and QIN Lung CT datasets, are shown in Figure 6. On observation of the results, it becomes apparent that the U-Det model outperforms the ground truth labels indicating the generalization potential of the model. The mean DSC outcomes on various lung nodule types from both datasets are shown in Tables 4 and 5. By examining the experimental data shown in Tables 4 and 5, it can be observed that the U-Det model\u2019s potential for robust segmentation does not depend upon the type of nodule as it has shown exceptional performance on even small-size nodules."
        },
        {
            "heading": "6. Discussion",
            "text": "The following distinctions are noted when the proposed work is compared with similar other approaches.\n\u2022 To overcome the challenge of segmentation of nodules having small diameter and an intensity comparable to that of the surrounding noise, the proposed model used Bi-FPN, which functioned as a feature enricher, integrating multi-scale feature fusion for the purpose of efficient feature extraction. \u2022 The proposed method applied a data augmentation technique to prevent the model from over-fitting and to obtain better segmentation results. \u2022 The comparison of the proposed model with others showed high segmentation performance on small nodules and various other categories of pulmonary nodules.\nFor the experimental comparison, the results of the proposed method on LUNA16 dataset were compared with the results of methods reported in the literature such as MV-CNN [51], MCROI-CNN [23], MC-CNN [16], FCN-UNET [5], MV-DCNN [18], CFCNN [27], and Cascaded-CNN [22]. It can be observed that the U-Det model performs\ncomparably to human experts; the efficiency of the segmentation (in terms of DSC) of the four radiologists who worked on the LUNA16 is known to be 82.25%. Moreover, the proposed model was compared with models ranging from the original U-Net to various other recent convolution networks, including DDRN [30] and DB-ResNet [28]. In Tables 6 and 7, and Figures 7 and 8, the quantified results of the various methods on the LUNA16 test set and QIN Lung CT Segmentation dataset are represented. The outputs are shown as \u2019mean \u00b1 standard deviation\u2019. As depicted in Tables 6 and 7, the proposed method showed better performance than the existing segmentation methods on both datasets, indicating the robustness of the model.\nTable 6. Quantitative segmentation results of the proposed model compared to different types of model architectures on LUNA16 dataset.\nLUNA16 Test Set\nQIN Lung CT Segmentation Dataset\nNetwork Architecture DSC (%) SEN (%) PPV (%)\nFCN-UNET 75.26 \u00b1 11.82 76.65 \u00b1 16.42 77.21 \u00b1 11.57\nCF-CNN 77.23 \u00b1 11.53 80.12 \u00b1 17.07 76.65 \u00b1 12.20\nMV-DCNN 77.89 \u00b1 10.64 81.29 \u00b1 15.60 76.95 \u00b1 11.62\nCascaded-CNN 78.89 \u00b1 11.89 87.20 \u00b1 12.44 76.74 \u00b1 13.52\nDB-ResNet 80.01 \u00b1 11.46 88.13 \u00b1 12.34 79.13 \u00b1 14.12\nDDRN 80.56 \u00b1 11.08 83.57 \u00b1 11.78 78.65 \u00b1 13.86\nProposed Method 81.66 \u00b1 10.09 91.11 \u00b1 12.01 80.05 \u00b1 13.34\nEven though the MV-CNN [51], FCN-UNET [5], MCROI-CNN [23], MC-CNN [16], Cascaded-CNN [22], and CF-CNN [27] methods achieved good results, DDRN [30], DBResNet [28], and U-Det showed better performance compared to them. Although the DB-ResNet achieved good performance in various cases, its performance was hindered in the cases where the size of the nodule was less than 6 mm [28]. Similarly, for DDRN, the performance of the model was hindered when it was weakly supervised with the ground truth masks and also in the cases where the nodule size was small [30]. In contrast, the proposed method outperformed the ground truth segmentation masks and showed excellent generalization capability, as depicted in Figure 6. Further, Figure 9 illustrates the U-Det model\u2019s performance in challenging cases such as small nodules (<6 mm), cavitary nodules, and juxta-vascular and juxtapleural nodules from the LUNA16 dataset. This observation confirmed that the proposed model showed efficient performance on various nodules, including nodules of less than 6 mm."
        },
        {
            "heading": "7. Conclusions",
            "text": "Lung CT image segmentation plays a vital role in the analysis of lung images, which helps in the identification of lung cancer. For lung nodule image segmentation, this paper proposed a deep-learning-based encoder\u2013decoder model (U-Det) using Bi-FPN as a feature\nenricher by incorporating multi-scale feature fusion. The proposed method demonstrated encouraging precision in the segmentation of the lung nodules and obtained 82.82% and 81.66% DSC scores for the LUNA16 and QIN datasets, respectively. A comparison with similar approaches also showed the efficient performance of the proposed approach. It also achieved efficient segmentation results in daunting cases such as cavitary nodules, GGO nodules, juxtapleural nodules, and small nodules of less than 6 mm. There are several areas of interest for further research. We employ a Bi-FPN to achieve a multi-scale fusion of features from 2D CT slices in the current work. However, it would be interesting to leverage the spatial information obtained from features of a voxel-based 3D CT scan representation. When fused across a multi-scale, these spatial features could potentially help models distinguish 3D properties and eccentricity of lung nodules for both segmentation and classification. Hence, future work will focus on developing a 3D capsule network based on the components of U-Det for fully automated malignancy classification and voxel-based segmentation of lung cancer.\nAuthor Contributions: Conceptualization, C.S.R.A. and S.A.B.P.; supervision, C.S.R.A. and S.A.B.P.; methodology, N.V.K.; resources, P.K.D.; validation, N.V.K.; writing\u2014review and editing, S.A.B.P., P.K.D. and G.R.; writing\u2014original draft preparation, N.V.K.; funding acquisition, P.K.D.; visualization, G.R.; investigation, N.V.K. All authors have read and agreed to the published version of the manuscript.\nFunding: This research received no external funding.\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability Statement: More details can be found at https://github.com/Nik-V9/U-Det.\nConflicts of Interest: The authors declare no conflict of interest."
        }
    ],
    "title": "A Bi-FPN-Based Encoder\u2013Decoder Model for Lung Nodule Image Segmentation",
    "year": 2023
}