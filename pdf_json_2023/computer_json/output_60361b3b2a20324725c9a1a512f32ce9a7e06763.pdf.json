{
    "abstractText": "Social recommendation systems based on the graph neural network (GNN) have received a lot of research-related attention recently because they can use social information to improve recommendation accuracy and because of the benefits derived from the excellent performance of the graph neural network in graphic data modeling. A large number of excellent studies in this area have been proposed one after another, but they all share a common requirement that the data should be centrally stored. In recent years, there have been growing concerns about data privacy. At the same time, the introduction of numerous stringent data protection regulations, represented by general data protection regulations (GDPR), has challenged the recommendation models with conventional centralized data storage. For the above reasons, we have designed a flexible model of recommendation algorithms for social scenarios based on federated learning. We call it the federated graph neural network for recommendation systems (FedGR). Previous related work in this area has only considered GNN, social networks, and federated learning separately. Our work is the first to consider all three together, and we have carried out a detailed design for each part. In FedGR, we used the graph attention network to assist in modeling the implicit vector representation learned by users from social relationship graphs and historical item graphs. In order to protect data privacy, we used FedGR flexible data privacy protection by incorporating traditional cryptography encryption techniques with the proposed \u201cnoise injection\u201d strategy, which enables FedGR to ensure data privacy while minimizing the loss of recommended performance. We also demonstrate a different learning paradigm for the recommendation model under federation. Our proposed work has been validated on two publicly available popular datasets. According to the experimental results, FedGR has decreased MAE and RMSE compared with previous work, which proves its rationality and effectiveness.",
    "authors": [
        {
            "affiliations": [],
            "name": "Chuang Ma"
        },
        {
            "affiliations": [],
            "name": "Xin Ren"
        },
        {
            "affiliations": [],
            "name": "Guangxia Xu"
        },
        {
            "affiliations": [],
            "name": "Bo He"
        }
    ],
    "id": "SP:e0ac3d6448c8e0b286d02efc7ff1a3779b2cab7b",
    "references": [
        {
            "authors": [
                "R. Qiu",
                "J. Li",
                "Z. Huang",
                "H. Yin"
            ],
            "title": "Rethinking the item order in session-based recommendation with graph neural networks",
            "venue": "In Proceedings of the 28th ACM International Conference on Information and Knowledge Management, Beijing,",
            "year": 2019
        },
        {
            "authors": [
                "W. Fan",
                "Y. Ma",
                "Q. Li",
                "Y. He",
                "E. Zhao",
                "J. Tang",
                "D. Yin"
            ],
            "title": "Graph neural networks for social recommendation",
            "venue": "In Proceedings of the The World Wide Web Conference,",
            "year": 2019
        },
        {
            "authors": [
                "D. Wang",
                "P. Cui",
                "W. Zhu"
            ],
            "title": "Structural deep network embedding",
            "venue": "In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data",
            "year": 2016
        },
        {
            "authors": [
                "E. Nasiri",
                "K. Berahmand",
                "Y. Li"
            ],
            "title": "Robust graph regularization nonnegative matrix factorization for link prediction in attributed networks. Multimed",
            "venue": "Tools Appl",
            "year": 2023
        },
        {
            "authors": [
                "L. Wu",
                "P. Sun",
                "Y. Fu",
                "R. Hong",
                "X. Wang",
                "M. Wang"
            ],
            "title": "A neural influence diffusion model for social recommendation",
            "venue": "In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval,",
            "year": 2019
        },
        {
            "authors": [
                "G. Xu",
                "X. Wu",
                "J. Liu",
                "Y. Liu"
            ],
            "title": "A community detection method based on local optimization in social networks",
            "venue": "IEEE Netw",
            "year": 2020
        },
        {
            "authors": [
                "K. Berahmand",
                "M. Mohammadi",
                "F. Saberi-Movahed",
                "Y. Li",
                "Y. Xu"
            ],
            "title": "Graph regularized nonnegative matrix factorization for community detection in attributed networks",
            "venue": "IEEE Trans. Netw. Sci. Eng",
            "year": 2023
        },
        {
            "authors": [
                "G. Xu",
                "J. Dong",
                "C. Ma",
                "J. Liu",
                "U.G.O. Cliff"
            ],
            "title": "A Certificateless Signcryption Mechanism Based on Blockchain for Edge Computing",
            "venue": "IEEE Internet Things J. 2022",
            "year": 2022
        },
        {
            "authors": [
                "C. Wu",
                "F. Wu",
                "Y. Cao",
                "Y. Huang",
                "X. Xie"
            ],
            "title": "Fedgnn: Federated graph neural network for privacy-preserving recommendation",
            "venue": "arXiv 2021,",
            "year": 2021
        },
        {
            "authors": [
                "C. Dwork"
            ],
            "title": "Differential privacy: A survey of results",
            "venue": "In Proceedings of the International Conference on Theory and Applications of Models of Computation, Xi\u2019an, China,",
            "year": 2008
        },
        {
            "authors": [
                "C. Gentry"
            ],
            "title": "Fully homomorphic encryption using ideal lattices",
            "venue": "In Proceedings of the Forty-First Annual ACM Symposium on Theory of Computing, Bethesda, MD, USA,",
            "year": 2009
        },
        {
            "authors": [
                "M. Hao",
                "H. Li",
                "X. Luo",
                "G. Xu",
                "H. Yang",
                "S. Liu"
            ],
            "title": "Efficient and privacy-enhanced federated learning for industrial artificial intelligence",
            "venue": "IEEE Trans. Ind. Inform",
            "year": 2019
        },
        {
            "authors": [
                "G. Xu",
                "W. Li",
                "J. Liu"
            ],
            "title": "A social emotion classification approach using multi-model fusion",
            "venue": "Future Gener. Comput. Syst",
            "year": 2020
        },
        {
            "authors": [
                "H. Ma",
                "H. Yang",
                "M.R. Lyu",
                "I. Sorec King"
            ],
            "title": "Social recommendation using probabilistic matrix factorization",
            "venue": "In Proceedings of the 17th ACM Conference on Information and Knowledge Management, Napa Valley, CA,",
            "year": 2008
        },
        {
            "authors": [
                "M. Jamali",
                "M. Ester"
            ],
            "title": "A matrix factorization technique with trust propagation for recommendation in social networks",
            "venue": "In Proceedings of the Fourth ACM Conference on Recommender Systems,",
            "year": 2010
        },
        {
            "authors": [
                "W. Fan",
                "Y. Ma",
                "Q. Li",
                "J. Wang",
                "G. Cai",
                "J. Tang",
                "D. Yin"
            ],
            "title": "A graph neural network framework for social recommendations",
            "venue": "IEEE Trans. Knowl. Data Eng",
            "year": 2020
        },
        {
            "authors": [
                "L. Wu",
                "J. Li",
                "P. Sun",
                "R. Hong",
                "Y. Ge",
                "M. Wang"
            ],
            "title": "Diffnet++: A neural influence and interest diffusion network for social recommendation",
            "venue": "IEEE Trans. Knowl. Data Eng",
            "year": 2020
        },
        {
            "authors": [
                "R.v.d. Berg",
                "T.N. Kipf",
                "M. Welling"
            ],
            "title": "Graph convolutional matrix completion",
            "venue": "arXiv 2017,",
            "year": 2017
        },
        {
            "authors": [
                "M. Defferrard",
                "X. Bresson",
                "P. Vandergheynst"
            ],
            "title": "Convolutional neural networks on graphs with fast localized spectral filtering",
            "venue": "Adv. Neural Inf. Process",
            "year": 2016
        },
        {
            "authors": [
                "R. Ying",
                "R. He",
                "K. Chen",
                "P. Eksombatchai",
                "W.L. Hamilton",
                "J. Leskovec"
            ],
            "title": "Graph convolutional neural networks for web-scale recommender systems",
            "venue": "In Proceedings of the 24th ACM Sigkdd International Conference on Knowledge Discovery & Data",
            "year": 2018
        },
        {
            "authors": [
                "W. Hamilton",
                "Z. Ying",
                "J. Leskovec"
            ],
            "title": "Inductive representation learning on large graphs",
            "venue": "Adv. Neural Inf. Process. Syst. 2017,",
            "year": 2017
        },
        {
            "authors": [
                "W. Wang",
                "W. Zhang",
                "S. Liu",
                "Q. Liu",
                "B. Zhang",
                "L. Lin",
                "H. Zha"
            ],
            "title": "Beyond clicks: Modeling multi-relational item graph for session-based target behavior prediction",
            "venue": "In Proceedings of the The Web Conference",
            "year": 2020
        },
        {
            "authors": [
                "K. Cho",
                "B. Van Merri\u00ebnboer",
                "C. Gulcehre",
                "D. Bahdanau",
                "F. Bougares",
                "H. Schwenk",
                "Y. Bengio"
            ],
            "title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation",
            "year": 2014
        },
        {
            "authors": [
                "M. Ammad-Ud-Din",
                "E. Ivannikova",
                "S.A. Khan",
                "W. Oyomno",
                "Q. Fu",
                "K.E. Tan",
                "A. Flanagan"
            ],
            "title": "Federated collaborative filtering for privacy-preserving personalized recommendation systems",
            "venue": "arXiv 2019,",
            "year": 2019
        },
        {
            "authors": [
                "D. Chai",
                "L. Wang",
                "K. Chen",
                "Q. Yang"
            ],
            "title": "Secure federated matrix factorization",
            "venue": "IEEE Intell. Syst",
            "year": 2020
        },
        {
            "authors": [
                "J. Mills",
                "J. Hu",
                "G. Min"
            ],
            "title": "Communication-efficient federated learning for wireless edge intelligence in IoT",
            "venue": "IEEE Internet Things J. 2019,",
            "year": 2019
        },
        {
            "authors": [
                "H. Ma",
                "D. Zhou",
                "C. Liu",
                "M.R. Lyu",
                "I. King"
            ],
            "title": "Recommender systems with social regularization",
            "venue": "In Proceedings of the Fourth ACM International Conference on Web Search and Data",
            "year": 2011
        },
        {
            "authors": [
                "H. Guo",
                "R. Tang",
                "Y. Ye",
                "Z. Li",
                "X. He"
            ],
            "title": "DeepFM: A factorization-machine based neural network for CTR prediction",
            "venue": "arXiv 2017,",
            "year": 2017
        },
        {
            "authors": [
                "Z. Liu",
                "L. Yang",
                "Z. Fan",
                "H. Peng",
                "P.S. Yu"
            ],
            "title": "Federated social recommendation with graph neural network",
            "venue": "ACM Trans. Intell. Syst. Technol. (TIST) 2022,",
            "year": 2022
        },
        {
            "authors": [
                "S. Wu",
                "F. Sun",
                "W. Zhang",
                "X. Xie",
                "B. Cui"
            ],
            "title": "Graph neural networks in recommender systems: A survey",
            "venue": "ACM Comput. Surv",
            "year": 2022
        },
        {
            "authors": [
                "S. Reddi",
                "Z. Charles",
                "M. Zaheer",
                "Z. Garrett",
                "K. Rush",
                "J. Kone\u010dn\u1ef3",
                "S. Kumar",
                "H.B. McMahan"
            ],
            "title": "Adaptive federated optimization",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Citation: Ma, C.; Ren, X.; Xu, G.; He,\nB. FedGR: Federated Graph Neural\nNetwork for Recommendation\nSystems. Axioms 2023, 12, 170.\nhttps://doi.org/10.3390/\naxioms12020170\nAcademic Editor: Harish Garg\nReceived: 28 December 2022\nRevised: 20 January 2023\nAccepted: 23 January 2023\nPublished: 7 February 2023\nCopyright: \u00a9 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: social recommendation; graph neural network; federated learning; privacy protection"
        },
        {
            "heading": "1. Introduction",
            "text": "Recommendation systems have gradually attracted more and more attention in recent years [1,2]. When both are parties involved in recommendation systems, users and businesses can benefit. Graph neural networks (GNNs) have gradually become common in various fields due to their excellent performance in graph-data processing [3]. Therefore, the use of GNNs techniques in recommendation systems has become popular, and the corresponding recommendation problem has been transformed into a link-prediction problem in GNNs [4]. Numerous recent works have started to incorporate the social information of target users into recommendation model construction [2,5,6]. Thus, the low-dimensional representations of the surrounding neighbors are normally either averaged or fused with the low-dimensional representations of the target user\u2019s historical behavioral data using the attention mechanism to obtain a final more accurate low-dimensional representation of the user. Although the recommendation performance of recommendation systems has\nAxioms 2023, 12, 170. https://doi.org/10.3390/axioms12020170 https://www.mdpi.com/journal/axioms\nbeen nicely improved by combining graph neural networks and user social network information [7], they all face a common problem: that data needs to be stored centrally [8,9]. Moreover, centralized storage has drawn public attention to data privacy and security issues. In addition, the recent introduction of a series of data privacy regulations, represented by the GDPR (https://gdpr-info.eu/ (accessed on 1 April 2022)), not only reflects the strict attitude of public institutions towards data privacy issues but also indicates that data privacy security should be an essential consideration in the construction of recommendation systems. Distributed data storage, which corresponds to centralized storage, has the property of data protection at the physical level, but it is also prone to data-island problems. Google formally proposed the concept of federated learning in 2016 in an attempt to find a balance between privacy protection and efficient use of data. However, they all suffer from these common drawbacks as follows. (1) In order to ensure the data security of users, traditional cryptographic technologies such as local differential privacy (LDP) [10] and homomorphic encryption (HE) [11] are generally introduced into federated learning to protect user data. However, some proof of work traditional differential privacy may not fit into the federation learning framework at all [12]. By summarizing these previous works, we propose the innovative work of federated graph neural network for recommendation systems(FedGR). It has effectively addressed the aforementioned challenges. First of all, in order to solve the discomfort of traditional cryptography in federated learning and the huge decline in recommendation performance, we have adopted two privacy protection methods in FedGR, \u201d encryption decryption\u201d and \u201d noise-injection\u201d. By combining these two means, the degradation of recommendation performance can be controlled to the greatest extent and lead to excellent data privacy protection capabilities. Second, to reduce the load on the edge nodes and the communication load during model aggregation, we adopt a split model design where the item model is placed at the server side and the user model is left at the edge nodes. The benefits of this approach are diverse. Finally, we introduce the corresponding feature information for each item in the item model. We tested our proposed FedGR on two real datasets and showed significant improvements in both MAE and RMSE compared to some past federated recommendation work. The main contributions of our work are as follows: we are the first to apply the split-model approach to social recommendation in a federated learning framework and propose a novel data protection approach in a federated learning framework. The efficient combination of traditional cryptographic techniques and joint learning with the burden of complex models on edge nodes is addressed. Our content is organized as follows. We present our related work in Section 2, and then we elaborate on the details of our proposed work in Section 3. In Section 4, we will validate the effectiveness of our work on the Ciao and Epinions datasets, and finally we will conclude the paper and present directions for our future research work."
        },
        {
            "heading": "2. Related Work",
            "text": "In this section, we present the three areas most relevant to our work, namely, (1) social recommendation, (2) the graph neural network for recommendation systems, and (3) privacy-protection recommendation."
        },
        {
            "heading": "2.1. Social Recommendation",
            "text": "People in the same social circle tend to have similar interests [13], and they share their interests with each other; therefore, social networks are an essential source of improving the accuracy of recommendation systems. We classify social recommendation into two broad categories: traditional methods based on matrix factorization and deep learning models based on GNNs. Prior to the popularity of GNNs, researchers mainly used social information as a regularization term to constrain the final user representation and enrich the single-user representation. SoRec [14] proposed a cofactor decomposition approach that shares a common potential user feature matrix decomposed by user scores and social relations. SocialMF [15] considered that the behavior of user u is influenced by its direct\nneighbors Nu. Therefore, the author takes the weighted average of the potential eigenvector of user u direct neighbor as the potential eigenvector estimate of user u. Following the emergence of GNNs, a large body of work has demonstrated their efficiency in social recommendation. Graphrec [2] and Graphrec+ [16] are from the same team. In both works, the authors use GNNs to learn user embeddings and item embeddings from social relationship graphs and historical item graphs and then pass these two embeddings through a multilayer perceptron to predict the final ratings. DiffNet [5] and DiffNet++ [17] use GNNs to model users\u2019 social relationships and interactive items, arguing that users\u2019 interests are diffused in the network, and the central user\u2019s propensity to consume is influenced by both low-order and high-order users to further improve the recommendations accuracy. Figure 1 below is a schematic diagram of social recommendation."
        },
        {
            "heading": "2.2. Graph Neural Network for Recommendation Systems",
            "text": "Applications of GNNs in recommendation systems can be divided into general recommendation and sequential recommendation, where the former is static and does not incorporate temporal information. The latter is dynamical. Therefore, we will also discuss the application of GNNs in recommender systems in two aspects. Figure 2 shows the two most salient relations of GNN in the recommendation systems.\n2.2.1. For General Recommendation\nGNNs can enhance user and item representation learning by explicitly encoding synergistic signals through node aggregation, which is more flexible and convenient for modeling multi-hop information than other models. GC-MC [18] uses GCN [19] as an encoder to learn user embedding and item embedding from user\u2013item bipartite graph of\nuser items and is used to predict and complete the missing values in the scoring matrix. PinSAGE [20] is a recall algorithm proposed by Pinterest based on GraphSAGE [21], which learns aggregation functions directly instead of fixed nodes, thus differing from Transductive learning methods such as GCN. This is more in line with the changing needs of graph nodes in realistic situations.\n2.2.2. For Sequential Recommendation\nConverting sequential data into a sequential graph allows for more flexible primitive transformations for item selection, and GNNs can capture complex user interest preferences implicit in sequential behavior through a ring structure. HetGNN [22] constructs an edge between two consecutive item items with the same sequence as the edge type using all of the user\u2019s behavior sequences. FGNN [1] uses GRU [23] with an attention mechanism to iteratively update user preferences with item representation of sequence concept. A large body of past work has shown that GNN-based models have shown strong advantages in the recommendation domain. Therefore, in our work, we also adopt GNNs applied to user-model learning, and we mainly use GAT [24] ."
        },
        {
            "heading": "2.3. Privacy-Protection Recommendation",
            "text": "As one of the early representative works in federation recommendation, in FCF [25], each edge user trains a local model using their own historical data, user embedding is updated locally, and finally only item embedding gradient data is uploaded to the server, but the gradient information may still leak some sensitive user data, so FedMF [26] authors additional use homomorphic encryption technique to protect the uploaded gradient information. As an early exploration of federated learning in the recommendation domain, the above two methods effectively protect the user embeddings and item embeddings, but they do not protect the interaction information between using items and learn some higher-order information. As a representative of federated learning in the field of recommendation systems in recent years, FedGNN [9] has demonstrated a fresh design idea. In order to protect data privacy, it has introduced two innovative technologies, namely, \u201cLocal Differential Privacy (LDP)\u201d and \u201cpseudo item labeling\u201d, on the framework of federated learning to protect user data. Unfortunately, FedGNN does not consider social information, which is an effective auxiliary to learn information in the learning process of low-dimensional representations, and its user model and item model are located at the edges, which imposes a large burden on model aggregation and local storage. By thoroughly considering the advantages and disadvantages of the above work, we proposed FedGR, which effectively combines GNNs, federated learning, and privacy protection technology and has considerably improved the recommendation performance."
        },
        {
            "heading": "3. Proposed Framework",
            "text": "In this section, we detail the details of our proposed FedGR framework. In the following, we will first introduce the notation and its associated conceptual definitions, as shown in Table 1."
        },
        {
            "heading": "3.1. Model Overview",
            "text": "In this subsection, we present the overall architecture of FedGR and the overall model architecture is shown in Figure 3. In our FedGR, we jointly work with multiple edge servers to train a unified recommendation model. The whole implementation is as follows: Step 1, the server will randomly initialize a user model and send it to each edge server after encryption processing; step 2, each edge node will retrieve the local database to obtain the current user\u2019s historical interactive item sequence and send it to the server to obtain the embedding vector of the corresponding item after \u201dnoise injection\u201d and \u201dencryption decryption\u201d processing; step 3, the local user model will be trained for specified rounds; step 4, the local model will be uploaded to the server and aggregated to form a unified global model through FedAVG [27] algorithm; and step 5, the server distributes the aggregated model to the edge nodes. Repeat steps 2\u20135 above until the number of training rounds is specified."
        },
        {
            "heading": "3.2. Item Model",
            "text": "In this section, we explain the learning process of item embeddings. Denote the set of features of item i. In our work, we incorporate the features of item i into the learning of hidden vectors for item representation. This enables better learning of individualized features among different item vectors. In FedGR, our item model employs a simple multilayer perceptron network that can be flexibly replaced for different application scenarios. The specific algorithmic steps are shown in Algorithm 1.\nAlgorithm 1 Item Embedding\nInput: feature set of item i Fi = f1, f2 \u00b7 \u00b7 \u00b7 fn\nOutput: representation of item qi 1: // embedding representation of each feature. 2: for k in Fi do 3: MLPembedding(k)\u2192 FEki 4: end for 5: // Connect all feature vectors and do feature crossing through multi-layer fully con-\nnected network . 6: CONCAT(FEi)\u2192 mid_var 7: MLP(mid_var)\u2192 qi 8: //the final embedding representation of item i . 9: return qi\nThe input is a series of features of item i. Step 1 loops through all of the features of the input item. For item i, the initial state of each feature is represented by numbers. First, each feature is vectorized through the embedding layer on the right side of Figure 3, and all features are converted from numerical representation to low-dimensional vector representation. This prevents the sparsity problem caused by the lack of features of some items. The effective feature information crossover can be performed later . Step 2: After the embedding layer, each feature forms an embedding vector of uniform length. Through the multi-layer perceptron (MLP), each feature vector is effectively crossed through the MLP network to learn useful information from each other. Step 3: The final low-dimensional vector representation of item i is obtained through the transformation of vectors."
        },
        {
            "heading": "3.3. User Model",
            "text": "The main function of the user model is to learn a vector representation of the user by combining the historical behavioral data of the user with the contact information of the user\u2019s social friends. First, we will build the user\u2013item graph and user\u2013user graph based on the local history and social information of the users. We use \u03c8i,\u00b5i, which represents the embedded representation that user i learned from the item graph and the embedded representation that user i learned from the social graph, respectively. These two vectors play a role in the end-user embedding representation construction from different perspectives, and we combine the learned representations from the two graph spaces. Finally, pi represents the vector representation of user i. In the following subsections, we present the details of each module and the corresponding implementation algorithms.\n3.3.1. Item Graph Representation\nThe user\u2013item graph contains information not only about the items the user has historically interacted with but also about the user\u2019s attitude. Here, rij , as a real value representation, can reflect whether the user i has a positive or negative attitude towards the historical interactive item j. In the data set, we use rij, adopting the \u201dfive-point scale\u201d, which is not limited. Algorithm 2 gives us an ensemble learning example of user embeddings.\nAlgorithm 2 Item Graph Representation\nInput: Input of the user\u2013item graph and the embedding representation of the corresponding item (obtained from the server side)\nGIi , E h i\nOutput: user\u2013item embedding representation \u03c8i 1: //Represent all scoring data as a low-dimensional vector . 2: MLPembedding(rij)\u2192 eij 3: //obtain user\u2013item embedding(every item) 4: CONCAT(Ehi , ei)\u2192 mid_var 5: MLP(mid_var)\u2192 \u03c5i 6: // Calculate the attention weight coefficient of items to users. 7: CONCAT(\u03c5i, embeddingi)\u2192 mid_var 8: MLP(mid_var)\u2192 \u03b1i 9: // the finally user\u2013item embedding representation 10: MLP(\u03b1i \u03c5i)\u2192 \u03c8i. 11: return \u03c8i\nAlgorithm 2 obviously presents the detailed process of learning the user\u2019s representation \u03c8i. Step 0: The user\u2013item graph and item embeddings are fed into the algorithm as initial information. In addition, we inject a lot of noise data through \u201dnoise injection\u201d to protect the user\u2019s real consumption data. The default score for these noisy data is zero. We will first set rij converted to low-dimensional representation eij, and we use ei, which represents all rating-embedding sets of user i. Since our item embeddings are pre-trained on the server side, we can directly fuse the original embedding representation of the item with the current user-rated embedding of the item. Use the following Equation (1) as follows:\nCONCAT(Ehi , ei) (1)\nwhere Ehi represents the embedded set representation of user i historical items, and ei represents the embedding set of user i ratings on the corresponding items. There are two ways to aggregate the historical interaction items of all users. One is to use simple mean values as weight coefficients in the aggregation process. The alternative is to use the attention mechanism for aggregation to differentiate the aggregation weight of each item. Indeed, the latter is better. The attention network is defined as Equation (2):\n\u03b1ij = W2 \u00b7 \u03c3(W1 \u00b7 CONCAT(\u03c5ij, embeddingi) + b1) + b2 (2)\nwhere \u03c5ij represents the unified representation of the user i rating embedding of item j and the initial embedding of item j, and embeddingi represents the initial embedding of user i. Item aggregation use follows Equation (3) representation:\n\u03c8i = MLP(\u03b1i \u03c5i) (3)\n\u03c5i denotes the uniform representation of all items embedding and corresponding rating embedding in the item graph of user i, represents the point between vectors, and \u03b1i denotes the set of all corresponding weight coefficients.\n3.3.2. Social Aggregation\nSimilar to previous works that learn embedding representations from user\u2013item pairs, we also introduce an attention mechanism in the social relationship aggregation process, where the influence of different friends is different and reflected by different attention weighting coefficients. The exact procedure is shown in Algorithm 3.\nAlgorithm 3 Social Representation\nInput: input social graph/user\u2013friend\u2013item graph/friends item-embedding set\nGsi , G f i , E f i\nOutput: user i social embedding representation \u00b5i 1: // calc the friends j user\u2013item embedding representation, use Algorithm 2 2: MLP(\u03b1j \u03c5j)\u2192 \u03c8j 3: // calc the user\u2013user attention score 4: MLP(CONCAT(embeddingi, \u03c8j))\u2192 \u03b2ij 5: //cacl the user i social embedding representation use all friends j and attention score 6: MLP(\u03b2i \u03c8 f i )\u2192 \u00b5i\n7: return \u00b5i\nThe embeddings corresponding to the user social graph, friend history item interaction graph, and friend history consumption item are fed into the model as raw data. Similar to Algorithm 2, since the initial scores of all friends on items are numerical scores from 1 to 5, they need to be represented as low-dimensional vectors first. The item embeddings and score embeddings can then be fused through a multi-layer neural network. The specific formula is as follows Equation (4):\nMLP(CONCAT(E fi , ei))\u2192 \u03c5i (4)\nHere, E fi denotes the embedding representation of all first-order friends of user i that have consumed items, and ei is the corresponding rating embedding. The computation of the attention scores between friends and consumed items is similar to the one in Equation (2), but the attention scores of first-order friends and their history items should be computed first before the user and user attention scores are calculated. The calculation formula of the user\u2013user attention score is shown in step 5 of Algorithm 3, where embeddingi represents the initial embedding representation of the current user to be calculated and \u03c8 fi represent the embedded representation set learned by all friends of user i from their corresponding historical product graph. The final \u03b2i is the set of weight coefficients of user i\u2019s friends. Through algorithm 3, we can obtain the embedding representation of user i in the social relationship graph by combining the influence of different first-order friends as follows in Equation (5).\n\u00b5i = MLP(\u03b2i \u03c8 f i ) (5)\nUltimately, user i learns the final low-dimensional vector representations from the user\u2013item graph and user\u2013user graph, respectively, \u03c8i and \u00b5i,\u2295 representative vector splicing. Therefore, the final low-dimensional vector learned by user i from user model is characterized by the following Equation (6):\npi = MLP(\u03c8i \u2295 \u00b5i) (6)"
        },
        {
            "heading": "3.4. Security Model",
            "text": "In our proposed work, we innovatively adopt two approaches to secure user data privacy. We can flexibly adjust the data privacy protection strength and optimize the recommendation performance for different recommendation scenarios. First, in step 2 as shown in Figure 3, the edge node obtains the embedding representation of the corresponding item from the server through the real personal history item ID, and first, the \u201dNoise Injection\u201d operation will be performed locally. The relevant formulation is as follows: In our proposed work, we innovatively adopt two approaches to secure user data privacy. The relevant formula is shown as follows in Equations (7) and (8):\n\u2206i = hi + hnoisei (7)\nlen(hnoisei ) = e \u00b7 len(hi) (8)\nIn the above formula, hi represents the item ID set that user i has genuinely consumed, and hnoisei represents the items that user i has not consumed. It is the forged data added by \u201dnoise injection\u201d. Together, they form the ID set \u2206i. This can effectively confuse the \u201dthief\u201d to speculate about the real consumption habits and relevant data of user i. In Function (8), the hyperparameter e is used to control the proportion of \u201dnoisy data\u201d added. The greater the level of privacy protection, the better, but at the same time, the performance drops. Through our experiments, we observed that when e, a favorable balance between privacy protection and recommendation performance can be achieved when e \u2208 (0.2, 0.35). After the noise injection process, the second security protection can be entered:module in our framework \u201dencryption-decryption\u201d module. The specific implementation is shown in Figure 4.\nThe data set \u2206i, which is processed by the previous \u201cnoise injection\u201d, is firstly encrypted by a symmetrical encryption model; it is particularly suitable for encrypting a large number of model parameters and can effectively protect large files. In FedGR, we use it to encrypt the original data, which will eventually generate two parts: the encrypted data containing the original data and the symmetric encryption key. However, since symmetric encryption uses the same key in both the encryption and decryption phases, there is a risk of losing the secret key. Thus, after the file is symmetrically encrypted, asymmetric encryption is performed on the symmetric encryption secret key, which is signed using the private key stored locally by the edge server. At this point, the files transmitted to the server include noisy data with symmetric encryption, and symmetric encryption keys with asymmetric encryption processing. After receiving these two, similar to the client requesting data from the server, when the server distributes model parameters and item-embedding to the client, it will also go through the \u201cencryption-decryption\u201d module. The difference is that \u201dnoise injection\u201d will not be performed on the server. Next, the client puts the noisy item embeddings into the user model for training to obtain the final model parameters, which are clearly trained from the noisy data, and it is also difficult for the thief to intercept the model parameters to invert the corresponding user consumption behavior data."
        },
        {
            "heading": "4. Experiment",
            "text": "In this section, we will select several benchmark models from different perspectives and evaluate the performance of our proposed FedGR model on two real data sets.\n4.1. Experimental Settings 4.1.1. Datasets\nWe chose two highly popular publicly available social datasets, Ciao and Epinions (http://www.cse.msu.edu/~tangjili/trust.html (accessed on 1 April 2022)), which are extremely commonly used in social recommendation scenarios and have been used for\nperformance evaluation in a large number of works in this domain. Specifically, what is crucial for our work is that both datasets contain categorical information, which we can incorporate as essential feature information in the term-representation learning process. The statistics of the two datasets are shown in Table 2.\n4.1.2. Evaluation Metrics\nWe use two extremely popular evaluation metrics: MAE (mean absolute error) and RMSE (root mean square error), both of which are the most commonly used metrics to measure the accuracy of variables and mainly reflect the scale of deviation of the predicted value from the true value. Smaller values for both metrics represent better performance. The specific calculation formula of these two formulas is shown Equations (9) and (10):\nMAE(X, h) = 1 m\nm\n\u2211 i=1 |h(X(i))\u2212 y(i)| (9)\nRMSE(X, h) = \u221a 1 m m\n\u2211 i=1 (h(X(i))\u2212 y(i))2 (10)\nwhere h(X(i)) and y(i), respectively, represent the predicted value and the real value, and m represents the total number of data.\n4.1.3. Parameter Settings\nIn our tests, we adopt a modern way of dividing the datasets, which we call UBC (userbased cutting). In the past, data partitioning for federated learning works were essentially based on centralized training dataset cuts, but we argue that this is not realistic and that it is more reasonable to partition edge users based on features learned by federated learning. Suppose M represents the set of all edge user nodes, M = mt, mv, me, where mt represents the training user set, mv represents the validation user set, and me represents the test user set. In total, 80% of the user set is divided into the training set, 10% into the validation set, and 10% into the test set. In all experiments, we initialize the parameters based on Gaussian distributions. We also control the number of first-order users, mainly to prevent some edge users from having good social ties and a much higher than average number of first-order friends, while others only have a small number of first-order friends or even no social relation, leading to biased learning results, so we set the number of friends to 5, 10, 15, 20. The embedding size d is tuned from 8, 16, 32, 64; the noise ratio in FedGR is chosen as 0, 0.1, 0.2, 0.3, 0.4, 0.5; and for the comparison method with local differential privacy protection, we set a gradient clipping threshold of 0.3, a laplace noise length of 0.1, a learning rate chosen as 0.1, 0.05, 0.01, and the number of local edge users training before each model training. Finally, the training stopping criterion is to reach the pre-defined number of training rounds.\n4.1.4. Baselines\nIn order to evaluate our proposed framework more comprehensively, we have selected three groups of methods to compare with the FedGR method, including the traditional social recommendation systems model (SoReg, SocialMF), the recommendation model combined with deep graph neural network technology (GraphRec, GCMC+SN), and the recommendation systems model with privacy (FeSoG, FedMF).\nSoReg [28]: A factor analysis recommendation algorithm based on the probability matrix decomposition. SocialMF [29]: Introducing trust propagation in matrix decomposition, the user indicates that friends close to that user indicate. GraphRec [2]: Graph neural networks are used to learn user embeddings and item embeddings from user history product graphs and social graphs. GCMC+SN [25]: A graph-neural-network-based recommendation model is used to generate embeddings for each user in the social network using the node2vec technique. FeSoG [30]: A social recommendation system with privacy protection, using local differential privacy (LDP) and pseudo-item labeling as a means of user data privacy protection. FedMF [26]: The representation of each user is computed by matrix factorization, and homomorphic encryption is used to protect the user data from disclosure."
        },
        {
            "heading": "4.2. Quantitative Results",
            "text": "The performance of all compared models is shown in Table 3, and for a more visual observation, we generate Figure 5.\nWe have the following observations from the data in the results. (1) Although both are based on social information for recommendation prediction, it is obvious that the GraphRec, GCMC+SN model combined with deep neural network ultimately performs better on both datasets than SoReg and SocialMF using traditional matrix decomposition techniques. (2) With the same dataset, all recommendation models based on the federated learning approach perform worse than the centralized framework processing. (3) The models that incorporate the graph neural network technology all perform better than those that do not incorporate the graph neural network technology. (4) Among all of the federated recommendation methods, our proposed FedGR has the best performance. The main reasons for this are as follows: firstly, we add item category information as a feature to the item-embedding learning process, which enriches the item-embedding representation. Second, we add a graph neural network to the user model to construct the social graph and item graph of the user. We effectively learn the hidden vector representations of the users. Thirdly, our proposed two privacy protection methods can minimize the degradation of recommendation performance under the premise of privacy protection, especially our \u201dEncryption-Decryption\u201d method, which fundamentally does not produce the degradation of recommendation performance."
        },
        {
            "heading": "4.3. Analysis of Parameters",
            "text": "In this section, we analyze some of the main hyperparameters in FedGR that determine the performance of FedGR, including (a) the number of friends in the social relation grap; (b) the number of items in the item graph; (c) the number of \u201dnoise items\u201d into the user\u2013item graph construction; for each parameter with different values, we mainly use the MSE and RMSE values as measures. The results are shown in Figure 6.\nAs shown in (a), the number of first-order friends has a strong influence on the final MAE/RMSE when the social graph is constructed, in FedGR; initially, when the number of users is less than 15, the MAE/RMSE all show a rapid decreasing trend, mainly because as the number of friends increases, it can provide more learning for the user representations\u2019 more valid information for the learning of user representations. However, when the number of friends is larger than 15, the decline starts to slow down, and even after 25, both MAE/RMSE show a slight rebound trend, although the increase in rebound varies. We believe that the reasons for this are manifold and can be summarized into two main aspects: (1) there are a large number of users whose first-order number of friends is originally not 15; and (2) too many friends will introduce noisy data that interfere with the target user\u2019s prediction and reduce the overall performance of the final model. By looking at the figure shown in (b), we can see that a similar situation to that in figure (a) arises. Figure (c) shows an entirely different dynamic from (a,b), where MAE/RMSE both increase with the increase in noise ratio. We found that in FedGR, if the noise item is set to 0, the performance is even better than some proposed social recommendation models in the past, but as the number of noise items increases, the MSE/RMSE both tend to rise rapidly, so knowing how to minimize the performance loss in social recommendation while protecting data privacy and security has been a key concern in this area."
        },
        {
            "heading": "5. Conclusions and Future Work",
            "text": "In this paper, we innovatively propose a federated learning framework based on a split-model social recommendation framework, which we call FedGR. To the best of our\nknowledge, our work is the first social recommendation systems model that decouples the user and item models and is privacy-protected. FedGR brings the advantages of GNN and social information to the recommendation systems and brings great accuracy to them. At the same time, in response to recent privacy protection concerns, our work builds on previous frontier work in federated learning. The combination of the two makes FedGR exhibit excellent performance. In FedGR, we achieve a excellent trade-off between privacy protection and recommendation performance while providing users with a lot of flexibility. To improve the recommendation performance, we incorporate the feature type information of items when retraining the item embeddings, and we propose two privacy preserving methods to improve privacy protection and minimize the loss in the recommendation performance. Finally, we compare our proposed FedGR with several different reference types on several real public datasets and show the effectiveness of our work on all datasets. Although, FedGR has shown its validity, we believe that it still has the following problems. (1) It does not consider the time series information of users\u2019 consumption. In our work, we purely consider the types of items consumed by users in the past, but the reality is that users\u2019 interests alter over time, which has been well established in recent years by a large amount of work on sequential and session recommendations [31]. (2) In FedGR, we are still using the more traditional FedAvg model parameter aggregation approach, although there has been a lot of work in the past that has confirmed its effectiveness and is extremely popular. However, simply averaging over all model parameters as different model parameters may result in some loss of model performance. Recently, there has been a lot of work proposing an aggregation approach similar to the attention mechanism [32], where the final model parameters are obtained by summing different weight values according to the variability of each edge user. Therefore, our future work will consider introducing the recurrent neural network (RNN) or transformer and alternative technologies to explore the evolution of user interests, which are closer to the actual situation. Second, we will introduce a better federated learning algorithm to replace the FedAVG algorithm we currently use. Moreover, all of our work will still be conducted under the topic of socially recommended privacy protection.\nAuthor Contributions: X.R. undertook this study and drafted the manuscript. B.H. sorted out the relevant literature and evaluated its applicability. G.X. and C.M. provided professional technical guidance on the implementation details of the article and summarized and reviewed the contents of the manuscript. All authors read and approved the final manuscript.\nFunding: This work is supported by the National Natural Science Foundation of China (Grant No. 62272120, 62106030), the Technology Innovation and Application Development Projects of Chongqing (Grant No. cstc2021jscx-gksbX0032, cstc2021jscx-gksbX0029), the Research Program of Basic Research and Frontier Technology of Chongqing (Grant No. cstc2021jcyj-msxmX0530), and the Key R & D plan of Hainan Province (Grant No. ZDYF2021GXJS006).\nAcknowledgments: The authors would like to thank the editor and anonymous reviewers for their valuable comments and suggestions on this paper.\nConflicts of Interest: Authors declare no conflict of interest."
        }
    ],
    "title": "FedGR: Federated Graph Neural Network for Recommendation Systems",
    "year": 2023
}