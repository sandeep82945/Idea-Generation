{
    "abstractText": "In recent years, computer vision-based structural displacement acquisition technique has received wide attention and research due to the advantages of easy deployment, low-cost, and non-contact. However, the displacement field acquisition of large-scale structures is a challenging topic as a result of the contradiction of camera field-of-view and resolution. This paper presents a large-scale structural displacement field calculation framework with integrated computer vision and physical constraints using only one camera. First, the full-field image of the large-scale structure is obtained by processing the multi-view image using image stitching technique; second, the full-field image is meshed and the node displacements are calculated using an improved template matching method; and finally, the non-node displacements are described using shape functions considering physical constraints. The developed framework was validated using a scaled bridge model and evaluated by the proposed evaluation index for displacement field calculation accuracy. This paper can provide an effective way to obtain displacement fields of large-scale structures efficiently and cost-effectively.",
    "authors": [
        {
            "affiliations": [],
            "name": "Yapeng Guo"
        },
        {
            "affiliations": [],
            "name": "Peng Zhong"
        },
        {
            "affiliations": [],
            "name": "Yi Zhuo"
        },
        {
            "affiliations": [],
            "name": "Fanzeng Meng"
        },
        {
            "affiliations": [],
            "name": "Shunlong Li"
        }
    ],
    "id": "SP:19a62725ce9ab566d0fb7b8772415b141046fab0",
    "references": [
        {
            "authors": [
                "C.-Z. Dong",
                "F.N. Catbas"
            ],
            "title": "A review of computer vision\u2013based structural health monitoring at local and global levels",
            "venue": "Struct. Health Monit",
            "year": 2020
        },
        {
            "authors": [
                "D. Feng",
                "M.Q. Feng"
            ],
            "title": "Experimental validation of cost-effective vision-based structural health monitoring",
            "venue": "Mech. Syst. Signal Process",
            "year": 2017
        },
        {
            "authors": [
                "Y. Liu",
                "Y. Li",
                "D. Wang",
                "S. Zhang"
            ],
            "title": "Model Updating of Complex Structures Using the Combination of Component Mode Synthesis and Kriging Predictor",
            "venue": "Sci. World J. 2014,",
            "year": 2014
        },
        {
            "authors": [
                "Y. Liu",
                "S. Zhang"
            ],
            "title": "Damage Localization of Beam Bridges Using Quasi-Static Strain Influence Lines Based on the BOTDA Technique",
            "venue": "Sensors 2018,",
            "year": 2018
        },
        {
            "authors": [
                "Y.J. Cha",
                "W. Choi",
                "O. B\u00fcy\u00fck\u00f6zt\u00fcrk"
            ],
            "title": "Deep learning-based crack damage detection using convolutional neural networks",
            "venue": "Comput. -Aided Civil. Infrastruct. Eng",
            "year": 2017
        },
        {
            "authors": [
                "X. Kong",
                "J. Li"
            ],
            "title": "Vision-based fatigue crack detection of steel structures using video feature tracking",
            "venue": "Comput. -Aided Civil. Infrastruct. Eng",
            "year": 2018
        },
        {
            "authors": [
                "L. Ramana",
                "W. Choi",
                "Y.-J. Cha"
            ],
            "title": "Fully automated vision-based loosened bolt detection using the Viola\u2013Jones algorithm",
            "venue": "Struct. Health Monit",
            "year": 2018
        },
        {
            "authors": [
                "Y. Xu",
                "S. Li",
                "D. Zhang",
                "Y. Jin",
                "F. Zhang",
                "N. Li",
                "H. Li"
            ],
            "title": "Identification framework for cracks on a steel structure surface by a restricted Boltzmann machines algorithm based on consumer-grade camera",
            "venue": "images. Struct. Control. Health Monit. 2018,",
            "year": 2018
        },
        {
            "authors": [
                "Y. Bao",
                "Z. Shi",
                "J.L. Beck",
                "H. Li",
                "T.Y. Hou"
            ],
            "title": "Identification of time-varying cable tension forces based on adaptive sparse timefrequency analysis of cable vibrations",
            "venue": "Struct. Control. Health Monit. 2017,",
            "year": 2017
        },
        {
            "authors": [
                "Y. Huang",
                "J.L. Beck",
                "H. Li"
            ],
            "title": "Bayesian system identification based on hierarchical sparse Bayesian learning and Gibbs sampling with application to structural damage assessment",
            "venue": "Comput. Methods Appl. Mech. Eng",
            "year": 2017
        },
        {
            "authors": [
                "H. Li",
                "C.M. Lan",
                "Y. Ju",
                "D.S. Li"
            ],
            "title": "Experimental and Numerical Study of the Fatigue Properties of Corroded Parallel Wire Cables",
            "venue": "J. Bridge Eng",
            "year": 2012
        },
        {
            "authors": [
                "H. Li",
                "C.-X. Mao",
                "J.-P. Ou"
            ],
            "title": "Experimental and theoretical study on two types of shape memory alloy devices",
            "venue": "Earthq. Eng. Struct. Dyn",
            "year": 2008
        },
        {
            "authors": [
                "S. Li",
                "S. Wei",
                "Y. Bao",
                "H. Li"
            ],
            "title": "Condition assessment of cables by pattern recognition of vehicle-induced cable tension",
            "venue": "ratio. Eng. Struct",
            "year": 2018
        },
        {
            "authors": [
                "S. Li",
                "S. Zhu",
                "Y.-L. Xu",
                "Z.-W. Chen",
                "H. Li"
            ],
            "title": "Long-term condition assessment of suspenders under traffic loads based on structural monitoring system: Application to the Tsing Ma Bridge",
            "venue": "Struct. Control. Health Monit",
            "year": 2012
        },
        {
            "authors": [
                "S. Sony",
                "S. Laventure",
                "A. Sadhu"
            ],
            "title": "A literature review of next-generation smart sensing technology in structural health monitoring",
            "venue": "Struct. Control. Health Monit. 2019,",
            "year": 2019
        },
        {
            "authors": [
                "B.F. Spencer",
                "V. Hoskere",
                "Y. Narazaki"
            ],
            "title": "Advances in Computer Vision-Based Civil Infrastructure Inspection and Monitoring",
            "venue": "Engineering 2019,",
            "year": 2019
        },
        {
            "authors": [
                "A. Bernasconi",
                "M. Carboni",
                "L. Comolli",
                "R. Galeazzi",
                "A. Gianneo",
                "M. Kharshiduzzaman"
            ],
            "title": "Fatigue Crack Growth Monitoring in Composite Bonded Lap Joints by a Distributed Fibre Optic Sensing System and Comparison with Ultrasonic Testing",
            "venue": "J. Adhes",
            "year": 2016
        },
        {
            "authors": [
                "P. Zamani",
                "A. Jaamialahmadi",
                "L.F.M. da Silva",
                "K. Farhangdoost"
            ],
            "title": "An investigation on fatigue life evaluation and crack initiation of Al-GFRP bonded lap joints under four-point bending",
            "venue": "Compos. Struct",
            "year": 2019
        },
        {
            "authors": [
                "A. Moradi",
                "M. Shariati",
                "P. Zamani",
                "R. Karimi"
            ],
            "title": "Experimental and numerical analysis of ratcheting behavior of A234 WPB steel elbow joints including corrosion defects",
            "venue": "Proc. Inst. Mech. Eng. Part. L J. Mater. Des. Appl",
            "year": 2022
        },
        {
            "authors": [
                "P. Zamani",
                "L. Fm da Silva",
                "R. Masoudi Nejad",
                "D. Ghahremani Moghaddam",
                "B. Soltannia"
            ],
            "title": "Experimental study on mixing ratio effect of hybrid graphene nanoplatelet/nano-silica reinforcement on the static and fatigue life of aluminum-to-GFRP bonded joints under four-point bending",
            "venue": "Compos. Struct",
            "year": 2022
        },
        {
            "authors": [
                "A. Djabali",
                "L. Toubal",
                "R. Zitoune",
                "S. Rechak"
            ],
            "title": "Fatigue damage evolution in thick composite laminates: Combination of X-ray tomography, acoustic emission and digital image correlation",
            "venue": "Compos. Sci. Technol",
            "year": 2019
        },
        {
            "authors": [
                "D. Feng",
                "M.Q. Feng"
            ],
            "title": "Computer vision for SHM of civil infrastructure: From dynamic response measurement to damage detection\u2014A review",
            "venue": "Eng. Struct",
            "year": 2018
        },
        {
            "authors": [
                "Y. Xu",
                "J.M.W. Brownjohn"
            ],
            "title": "Review of machine-vision based methodologies for displacement measurement in civil structures",
            "venue": "J. Civil. Struct. Health Monit. 2018,",
            "year": 2018
        },
        {
            "authors": [
                "D. Feng",
                "M.Q. Feng"
            ],
            "title": "Vision-based multipoint displacement measurement for structural health monitoring",
            "venue": "Struct. Control. Health Monit. 2016,",
            "year": 2016
        },
        {
            "authors": [
                "T. Aoyama",
                "L. Li",
                "M. Jiang",
                "T. Takaki",
                "I. Ishii",
                "H. Yang",
                "C. Umemoto",
                "H. Matsuda",
                "M. Chikaraishi",
                "A. Fujiwara"
            ],
            "title": "Vision-Based Modal Analysis Using Multiple Vibration Distribution Synthesis to Inspect Large-Scale Structures",
            "venue": "J. Dyn. Syst. Meas. Control",
            "year": 2018
        },
        {
            "authors": [
                "L. Luo",
                "M.Q. Feng",
                "Z.Y. Wu"
            ],
            "title": "Robust vision sensor for multi-point displacement monitoring of bridges in the field",
            "venue": "Eng. Struct",
            "year": 2018
        },
        {
            "authors": [
                "D. Lydon",
                "M. Lydon",
                "J.M.d. Rinc\u00f3n",
                "S.E. Taylor",
                "D. Robinson",
                "E. O\u2019Brien",
                "F.N. Catbas"
            ],
            "title": "Development and Field Testing of a Time-Synchronized System for Multi-Point Displacement Calculation Using Low-Cost Wireless Vision-Based Sensors",
            "venue": "IEEE Sens. J. 2018,",
            "year": 2018
        },
        {
            "authors": [
                "Y. Xu",
                "J. Brownjohn",
                "D. Kong"
            ],
            "title": "A non-contact vision-based system for multipoint displacement monitoring in a cable-stayed footbridge",
            "venue": "Struct. Control. Health Monit. 2018,",
            "year": 2018
        },
        {
            "authors": [
                "Q.S. Song",
                "J.R. Wu",
                "H.L. Wang",
                "Y.S. An",
                "G.W. Tang"
            ],
            "title": "Computer vision-based illumination-robust and multi-point simultaneous structural displacement measuring method",
            "venue": "Mech. Syst. Signal. Process",
            "year": 2022
        },
        {
            "authors": [
                "Z. Lai",
                "I. Alzugaray",
                "M. Chli",
                "E. Chatzi"
            ],
            "title": "Full-field structural monitoring using event cameras and physics-informed sparse identification",
            "venue": "Mech. Syst. Signal. Process",
            "year": 2020
        },
        {
            "authors": [
                "Z. Shang",
                "Z. Shen"
            ],
            "title": "Multi-point vibration measurement and mode magnification of civil structures using video-based motion processing",
            "venue": "Autom. Constr",
            "year": 2018
        },
        {
            "authors": [
                "Y. Yang",
                "C. Dorn",
                "C. Farrar",
                "D. Mascarenas"
            ],
            "title": "Blind, simultaneous identification of full-field vibration modes and large rigid-body motion of output-only structures from digital video measurements",
            "venue": "Eng. Struct",
            "year": 2020
        },
        {
            "authors": [
                "Y. Yang",
                "L. Sanchez",
                "H. Zhang",
                "A. Roeder",
                "J. Bowlan",
                "J. Crochet",
                "C. Farrar",
                "D. Mascarenas"
            ],
            "title": "Estimation of full-field, full-order experimental modal model of cable vibration from digital video measurements with physics-guided unsupervised machine learning and computer vision",
            "venue": "Struct. Control. Health Monit. 2019,",
            "year": 2019
        },
        {
            "authors": [
                "Y. Narazaki",
                "F. Gomez",
                "V. Hoskere",
                "M.D. Smith",
                "B.F. Spencer"
            ],
            "title": "Efficient development of vision-based dense three-dimensional displacement measurement algorithms using physics-based graphics models",
            "venue": "Struct. Health Monit. Int. J. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "Y. Narazaki",
                "V. Hoskere",
                "B.A. Eick",
                "M.D. Smith",
                "B.F. Spencer"
            ],
            "title": "Vision-based dense displacement and strain estimation of miter gates with the performance evaluation using physics-based graphics models",
            "venue": "Smart Struct. Syst",
            "year": 2019
        },
        {
            "authors": [
                "S. Bhowmick",
                "S. Nagarajaiah"
            ],
            "title": "Identification of full-field dynamic modes using continuous displacement response estimated from vibrating edge video",
            "venue": "J. Sound Vib",
            "year": 2020
        },
        {
            "authors": [
                "S. Bhowmick",
                "S. Nagarajaiah"
            ],
            "title": "Spatiotemporal compressive sensing of full-field Lagrangian continuous displacement response from optical flow of edge: Identification of full-field dynamic modes",
            "venue": "Mech. Syst. Signal. Process",
            "year": 2022
        },
        {
            "authors": [
                "S. Bhowmick",
                "S. Nagarajaiah",
                "Z. Lai"
            ],
            "title": "Measurement of full-field displacement time history of a vibrating continuous edge from video",
            "venue": "Mech. Syst. Signal. Process",
            "year": 2020
        },
        {
            "authors": [
                "L. Luan",
                "J. Zheng",
                "M.L. Wang",
                "Y. Yang",
                "P. Rizzo",
                "H. Sun"
            ],
            "title": "Extracting full-field subpixel structural displacements from videos via deep learning",
            "venue": "J. Sound. Vib",
            "year": 2021
        },
        {
            "authors": [
                "W. Cheung",
                "G. Hamarneh"
            ],
            "title": "n-SIFT: N-dimensional scale invariant feature transform",
            "venue": "Trans. Img. Proc. 2009,",
            "year": 2012
        },
        {
            "authors": [
                "M.A. Fischler",
                "R.C. Bolles"
            ],
            "title": "Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography",
            "venue": "Commun. ACM",
            "year": 1981
        },
        {
            "authors": [
                "C. Rother",
                "V. Kolmogorov",
                "A. Blake"
            ],
            "title": "GrabCut\u201d: Interactive foreground extraction using iterated graph cuts",
            "venue": "In Proceedings of the SIGGRAPH 2004: 31st Annual Conference on Computer Graphics and Interactive Techniques,",
            "year": 2004
        },
        {
            "authors": [
                "S. Vicente",
                "V. Kolmogorov",
                "C. Rother"
            ],
            "title": "Graph cut based image segmentation with connectivity priors",
            "venue": "In Proceedings of the 2008 IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2008
        }
    ],
    "sections": [
        {
            "text": "Citation: Guo, Y.; Zhong, P.; Zhuo, Y.;\nMeng, F.; Di, H.; Li, S. Displacement\nField Calculation of Large-Scale\nStructures Using Computer Vision\nwith Physical Constraints: An\nExperimental Study. Sustainability\n2023, 15, 8683. https://doi.org/\n10.3390/su15118683\nAcademic Editor: Mahmoud Bayat\nReceived: 6 March 2023\nRevised: 20 April 2023\nAccepted: 19 May 2023\nPublished: 27 May 2023\nCopyright: \u00a9 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: displacement field; large-scale structure; computer vision; physical constraint; experimental study; photographic image"
        },
        {
            "heading": "1. Introduction",
            "text": "Displacement information, especially structural displacement field information, is essential for accurate service condition assessment of large-scale engineering structures. The analysis of structural displacements allows for the sensing of local or global damage to the structure, and is an important basic response type for structural modal identification, damage identification, and safety assessment [1\u20138]. Therefore, many types of displacement sensing devices have been used in structural health monitoring systems or structural inspection process [9\u201314], which can be divided into contact-based and non-contact-based. Contact-based sensing methods include optic fiber sensors, piezoelectric sensors, strain gauge sensors, linear variable differential transformer (LVDT) and GPS, of which the latter two are the most commonly used [15\u201320]. The limitation of these two methods is the need for complex installations close to the structure. LVDT measures the relative displacement of a structure to a stationary point, meaning that a stationary point close to the structure must be set free from any vibration, which is often difficult to find in practice. GPS calculates the displacement by measuring the coordinates of the equipment installed on the structure. In addition to being expensive, the measurement accuracy is very limited, usually\u00b11.5 cm in the horizontal direction and\u00b12 cm in the vertical direction. The non-contact-based displacement sensor has the advantage of remote measurement without the need for complex installation on the structure. As a widely used non-contact sensor,\nSustainability 2023, 15, 8683. https://doi.org/10.3390/su15118683 https://www.mdpi.com/journal/sustainability\nSustainability 2023, 15, 8683 2 of 17\nlaser displacement sensor needs a stationary point similar to LVDT, but the measurement distance cannot be considerably far due to the limitation of laser intensity. Non-contact-based sensing methods include X-ray tomography, digital image correlation (DIC), and computer vision-based approaches. The first two are the primary choices for displacement or strain measurement of small-scale structures, such as laboratory specimens, but the measurement equipment is expensive and there are limitations, such as limited measurement range [21]. Vision-based displacement sensors have received extensive attention from researchers due to their low-cost, long measurement distance, multiple measurement points, and high measurement accuracy [22,23]. Vision-based structural displacement measurement calculates the displacement of a structure by comparing the position changes in the same pixels of different frames of the time-series images (video) of the structure remotely captured by cameras. Template matching and its variants are often used to find the location of the same pixel in different frames, namely, tracking. To reduce the difficulty of tracking, initial research has been carried out to increase the recognizability of the appearance by matching artificial markers or targets installed at the location of the structure. With the improvement of the complexity and robustness of algorithms, satisfactory accuracy can be obtained by directly using the natural texture of the structure for tracking. Feng and Feng [24] proposed a multi-point simultaneous extraction method of structural displacement based on two improved template matching methods (using only one camera). Aoyama et al. [25] developed a multiple vibration distribution synthesis method to perform modal analysis on large-scale structures by using a multithread active vision system and a galvanometer mirror to perform quasi-real-time observation of multiple points of the structure. Luo et al. [26] proposed a set of image processing algorithms after analyzing the problems in practical outdoor applications, including the use of gradient-based template matching method, sub-pixel method, and camera vibration elimination method. Due to the limited field-of-view of a single camera, Lydon et al. [27] developed multi-point displacement measurement system for large-scale structures using multiple time-synchronized wireless cameras and successfully applied it to actual bridge displacement measurements. Xu et al. [28] presented a multi-point displacement extraction method for real cable-stayed pedestrian bridges using consumer-grade cameras and computer vision algorithms. To solve the problem that the traditional image methods are not robust enough to the change in ambient light intensity, Song et al. [29] proposed the use of fully convolutional network and conditional random field to segment the structural part from the image in order to extract the multi-point displacement combined with the digital image correlation method. These methods are aimed at extracting the displacement of one or several positions of the structure to be measured, namely, local displacement measurement. Compared with local displacement, full-field displacement information of structures can provide more abundant structural state information for finite element model updating, material performance parameter identification, and structural condition assessment [30]. By comparing the displacement field of the key surface of the structure at different service times, the global performance change in the structure can be reflected. Thanks to its distributed sensing characteristics, it can also reflect the local performance change in the structure, to realize the global and local structural performance evaluation. In addition, the visual sensor has the advantage of large-scale dense sensing, and thus it is more meaningful to conduct vision-based structural full-field displacement measurement. Compared with previous tracking methods, such as digital image correlation or template matching, the phase-based method fits the full-field information acquisition and can obtain subpixel displacement measurement accuracy. Shang and Shen [31] proposed the use of the phasebased optical flow method to obtain the full-field vibration map of the structure and use the motion magnification technology to identify the modal parameters. Yang et al. [32,33] used the physics-guided unsupervised machine learning vision method to identify the full-field vibration modes of stay cables, and for the vibration structure with large rigid body displacement, a vision-based simultaneous identification method of rigid body displacement and structural vibration was also proposed, which was verified on the laboratory model.\nSustainability 2023, 15, 8683 3 of 17\nNarazaki et al. [34,35] developed a vision-based algorithm for measuring the dense threedimensional displacement field of structures, and optimized the algorithm parameters using a laboratory truss model. Bhowmick and Nagarajaiah [36\u201338] proposed the use of the continuous edges of the structure in the image as texture features and the combination of the optical flow method to extract the full-field displacement of the structure, and verified it on the three-layer steel frame model in the laboratory. To further simplify the measurement process of structural full-field displacement, Luan et al. [39] developed a deep learning extraction framework for structural full-field displacement based on convolutional neural networks, which realized real-time measurement of full-field subpixel displacement and verified it on a laboratory model. These studies have greatly promoted the development of structural full-field displacement measurement. However, since most of the work has been verified by small-scale laboratory models, a main problem in actual large-scale structural full-field displacement measurement is not involved: Full-field structure image acquisition. In vision-based structural displacement measurement, each pixel can be regarded as a sensor, and the actual distance it represents is the resolution of the measurement system. Although the accuracy can be further improved by means of subpixel technology, it can only be amplified by an extremely limited multiple. Therefore, obtaining a full-field image of the structure with sufficient resolution is the basis of full-field displacement measurement. Due to the small size of the laboratory model, the field-of-view of a camera can cover the entire structure with good resolution. However, actual civil structures tend to be large; therefore, if only one camera will be used to shoot all the structure, this will result in an extremely low resolution, and to maintain the resolution, the camera\u2019s field-of-view is quite small to cover the whole structure. To solve the image acquisition and processing problem in full-field displacement measurement of large-scale structures, this paper presents a novel calculation framework of large-scale structural displacement field. To alleviate the contradiction between camera field-of-view and resolution, image stitching technology based on multi-view images is proposed to generate large-scale structure full-field images. To improve the efficiency of displacement extraction and consider the physical rules, the node and non-node displacement extraction technology based on meshing and structural shape function is developed. The contribution of this paper is that the plane displacement field of large-scale structure can be obtained by using only a single camera and an automatic rotating platform, which greatly simplifies the process and cost of displacement field acquisition. Specifically, this paper first proposes a sensing system for the plane displacement field of large structures, which can automatically image and stitch large structures through a rotating platform. Second, this paper proposes a node and non-node meshing method for large-scale structural planes, and develops a displacement calculation method for nodes and nonnodes, respectively. The non-node displacement calculation considers physical constraints and accelerates the displacement calculation process. The remainder of this paper is organized as follows. Section 2 describes the details of the proposed structural displacement field calculation framework. Section 3 illustrates the verification results and discusses the key parameters of the presented method. Finally, Section 4 concludes the study."
        },
        {
            "heading": "2. Structural Displacement Field Calculation Framework",
            "text": "The proposed calculation framework of structural displacement field is shown in Figure 1. The proposed method can perform two-dimensional fast imaging and fast calculation of displacement field for key planes of large-scale structures. First, a camera set on the automatic rotation device is used to shoot the large-scale structure to obtain a multi-view structure image, it should be noted that the rotating plane is horizontal, namely, the optical axis of the camera is ensured to be horizontal. Second, the full-field structure image is generated by using image stitching technology. Finally, the full-field image is discretized and meshed, the displacement at the node is calculated by the improved template matching method, and the displacement at the non-node is calculated by the\nSustainability 2023, 15, 8683 4 of 17\nshape function considering the physical rules, to obtain the displacement field of the large-scale structure.\nSustainability 2023, 15, x FOR PEER REVIEW 4 of 17\nview structure image, it should be noted that the rotating plane is horizontal, namely, the optical axis of the camera is ensured to be horizontal. Second, the full-field structure image is generated by using image stitching technology. Finally, the full-field image is discretized and meshed, the displacement at the node is calculated by the improved template matching method, and the displacement at the non-node is calculated by the shape function considering the physical rules, to obtain the displacement field of the large-scale structure.\nFigure 1. Overall framework of the proposed structural displacement field calculation method.\n2.1. Large-Scale Structure Full-Field Image Generation Using Image Stitching To obtain high-resolution full-field images of large-scale structures, this paper proposes a full-field image generation method that rotates and moves a single camera to capture multiple partial structure images and stitch them together. The proposed generation method is divided into three steps: (1) Image preprocessing (used to solve the problem of inconsistent depth of field); (2) image registration (used to align and stitch multi-view images); (3) structure foreground segmentation (used to extract the structure in the fullfield image).\n2.1.1. Image Preprocessing Multi-view imaging of large-scale structures by rotating the camera is usually convenient. However, it is accompanied by the fact that the same structure plane has different depth of field in different images (foreshortening effects) due to the angle problem during each imaging. Only unifying the structural planes in all images can ensure no distortion in the subsequent stitching process. This can be achieved by rotating the camera imaging\nFigure 1. Overall framework of the proposed structural displacement field calculation method."
        },
        {
            "heading": "2.1. Large-Scale Structure Full-Field Image Generation Usi g Image St tching",
            "text": "To obtain high-resolution full-field images of large-scale structures, this paper propose a full-field image generation ethod th t rotates an moves single cam ra to capture multiple partial structure im ges and stitch them together. The proposed generation method is divide into three steps: (1) Image preprocessing (used to solve the problem of inconsistent depth of field); (2) image registration (used to align and stitch multi-view images); (3) structure foreground segmentation (used to extract the structure in the fullfield image).\n2.1.1. Image Preprocessing\nMulti-view imaging of large-scale structures by rotating the camera is usually convenient. However, it is accompanied by the fact that the same structure plane has different depth of field in different images (foreshortening effects) due to the angle problem during each imaging. Only unifying the structural planes in all images can ensure no distortion in the subsequent stitching process. This can be achieved by rotating the camera imaging plane around the intersection of the optical axis and the imaging plane to be parallel to the structure plane. This paper proposes the use of perspective transformation to re-project the original camera imaging surface to a new structure plane. The homography matrix is usually used to describe the transformation between these two-dimensional planes. The homography\nSustainability 2023, 15, 8683 5 of 17\nmatrix can be solved by finding the coordinates of four points in the old and new images. Since the rotation vector and translation vector can be measured when the camera takes multi-view images, the corresponding new coordinates of the four points can be calculated based on these two vectors to achieve image preprocessing.\n2.1.2. Image Registration\nThe preprocessed image needs to be stitched into a full-field image after removing the interference factors. Usually, the feature points of each image are calculated based on feature point detection algorithms, and the same feature points in the two images are matched with each other to calculate the homography matrix representing the transformation. Due to the different external conditions during image shooting, the overlapping areas of adjacent images will also be different, the image fusion method is needed to make the stitching effect more natural. In this paper, the scale-invariant feature transform (SIFT) algorithm [40] is used to detect local feature points in the image. SIFT features still show good feature detection results and strong robustness even in complex environments, such as scale changes, image rotation, and brightness changes. The SIFT algorithm will simultaneously generate the coordinates of the feature points and the corresponding descriptors. For two feature points with descriptors of Q = (r1, r2, . . . , rn) and S = (s1, s2, . . . , sn), the Euclidean distance is calculated to evaluate their similarity. The fast library for approximate nearest neighbors (FLANN) is used to match the feature point sets in two adjacent images. Using the K-D (k-dimensional) tree, all the feature points in the image are divided into left and right sub-tree spaces according to the root nodes of different dimensions. Then, the root nodes are determined in the sub-tree space, and the space is divided again until the space is empty, namely, all the feature points are divided. After using FLANN, there will inevitably be mismatches. If it is included in the calculation of homography matrix, there will be apparent errors in splicing. In this paper, random sample consensus (RANSAC) algorithm [41] is used to filter and only retain the correct matching feature points. The direct average fusion method is used to recalculate and replace the pixel value of the overlapping area using the average pixel value of adjacent images.\n2.1.3. Structure Foreground Segmentation\nStructure full-field image includes not only the structure itself, but also inevitably includes sensors, bearings, background interference, etc. However, the displacement field of the structure is only generated in the structure itself, and the other objects must be removed. Therefore, this paper uses the GrabCut algorithm [42] to extract the foreground that contains only structures. The GrabCut algorithm is an improvement of the GraphCut algorithm [43], which is mainly reflected in the following aspects. First, to simplify the user interaction operation, we only need to roughly mark the rectangular box containing the foreground object, and the outside of the box is the background. Second, rather than gray histogram, Gaussian mixture model (GMM) is used to estimate the probability of pixels belonging to the foreground and background, and the calculation results are more reliable and accurate. Third, segmentation is not a one-time completion; therefore, through continuous iteration, we update the calculation parameters in order that the image segmentation quality is improved. After users mark the bounding box, all pixels outside the box belong entirely to the background, and the pixels inside the box may belong to both the foreground and background. Therefore, it is only necessary to segment the connection relationship between pixels in the box to separate the foreground and background."
        },
        {
            "heading": "2.2. Structure Image Discretization and Displacement Field Calculation",
            "text": "Based on the finite element concept in the physical model, the proposed computer vision-based structural displacement field calculation with physical constraints can be\nSustainability 2023, 15, 8683 6 of 17\ndivided into three steps: First, the continuous structural foreground image is discretized, and the mesh is drawn within the foreground image. The structure is divided into several regions by using the mesh. Second, the displacement of structural grid nodes is calculated based on the improved template matching method. Third, the shape function is constructed to establish the relationship between the displacement at the grid nodes and the displacement at the non-nodes in the grid, the displacement of the nodes is transferred to the non-nodes by the shape function to generate a complete displacement field. Since the shape function is a continuous function, the generated displacement field is also continuous.\n2.2.1. Image Preprocessing\nAfter determining the mesh size, the horizontal and vertical lines of the mesh are drawn on the full-field image. The grid has not abandoned the background part, which is a full-size grid, as shown in Figure 2. It is a regular rectangular grid discretization of the whole image.\nSustainability 2023, 15, x FOR PEER REVIEW 6 of 17\nbackground. Therefore, it is only necessary to segment the connection relationship between pixels in the box to separate the foreground and background."
        },
        {
            "heading": "2.2. Structure Image Discretization and Displacement Field Calculation",
            "text": "Based on the finite element concept in the physical model, the proposed computer vision-based structural displacement field calculation with physical constraints can be divided into three steps: First, the continuous structural foreground image is discretized, and the mesh is drawn within the foregro nd image. The st ucture is divided into s veral regions by using the mesh. Second, the displace ent of structural grid no s is calculated based on the improved template matching method. Third, the shape function is constructed to stablish the relationship between the displacement at the grid nodes and he displ cement at the non-nodes in the grid, the displacement of the nodes is transferred to the non-nodes by the shape function to gener te a complete displacement field. Since t e shape function is a continuous function, the generated is lace e t el is also continuous."
        },
        {
            "heading": "2.2.1. Image Preprocessing",
            "text": "After determining the mesh size, the horizontal and vertical lines of the mesh are drawn on the full-field image. The grid has not abandoned the background part, which is a full-size grid, as shown in Figure 2. It is a regular rectangular grid discretization of the whole image.\nSimilar to foreground extraction, it is also necessary to generate the boundary of the displacement field on the full-size grid. First, the binary threshold processing is performed on the structure foreground extraction image. The background is set to 0 and the structure is set to 1 to form a binary foreground image, called a mask. To retain as many pixels as possible and ensure that the boundary of the foreground extraction has some surplus pixel space, the structure element with a kernel of 3 \u00d7 3 is used to expand the morphological processing of the binary image, and finally the expanded structure image mask is formed. Each pixel of the mask and the corresponding pixel of the full-size grid map are bitwise and calculated, namely, 1 and 1 = 1, 0 and 1 = 0, to retain the grid within the structural range. The endpoints of the above dividing line are connected to form a grid with boundary. The grid division has been initially formed, as shown in Figure 3.\nFigure 3. Structure region grid of the full-field structure image.\nThe grid that does not contact the boundary is a regular rectangular grid, but the grid rules that contact the boundary are different, and further fine division needs to be\nFigure 2. Full-size grid of the full-field structure image.\nSimilar to foreground extraction, it is also necessary to generate the boundary of the displacement field on the full-size grid. First, the binary threshold processing is performed on the structure foreground extraction image. The background is set to 0 and the structure is set to 1 to form a binary foreground image, called a mask. To retain as many pixels as possible and ensure that the boundary of the foreground extraction has some surplus pixel space, the structure element with a kernel of 3 \u00d7 3 is used to expand the morphological processing of the binary image, and finally the expanded structure image mask is formed. Each pixel of the mask and the corresponding pixel of the full-size grid map are bitwise and calculated, namely, 1 and 1 = 1, 0 and 1 = 0, to retain the grid within the structural range. The endpoints of the above dividing line are connected to form a grid with boundary. The grid division has been initially formed, as shown in Figure 3.\nSustainability 2023, 15, x FOR PEER REVIEW 6 of 17\nbackground. Therefore, it is only necessary to segment the connection relationship between pixels in the box to separate the foreground and background."
        },
        {
            "heading": "2.2. Structure Image Discretization and Displacement Field Calculation",
            "text": "Based on the finite element concept in the physical model, the proposed computer vision-based structural displacement field calculation with physical constraints can be divided into three steps: First, the continuous structural foreground image is discretized, and the mesh is drawn within the foreground image. The structure is divided into several regions by using the mesh. Second, the displacement of structural grid nodes is calculated based on the improved template matching method. Third, the shape function is constructed to establish the relationship between the displacement at the grid nodes and the displacement at the non-nodes in the grid, the displacement of the nodes is transferred to the non-nodes by the shape function to generate a complete displacement field. Since the shape function is a continuous function, the generated displacement field is also continuous."
        },
        {
            "heading": "2.2.1. Image Preprocessing",
            "text": "After d termining the mes size, the h rizontal an vertical lines of the mesh are drawn on the full-field image. The grid has not ab ndoned the background par , which is a full-size rid, as shown in Figure 2. It is a regular rectangular grid discretization of the whole image.\nSi ilar to foreground extraction, it is also necessary to generate the boundary of the displacement field on the full-size grid. First, the binary threshold processing is performed on the structure foreground extraction image. The background is set to 0 and the structure is set to 1 to form a binary foreground image, called a mask. To retain as many pixels as possible and ensure that the boundary of the foreground extraction has some surplus pixel space, the structure element with a kernel of 3 \u00d7 3 is used to expand the morphological processing of the binary image, and finally the expanded structure image mask is formed. Each pixel of the mask and the corresponding pixel of the full-size grid map are bitwise and calculated, namely, 1 and 1 = 1, 0 and 1 = 0, to retain the grid within the structural range. The endpoints of the above dividing line are connected to form a grid with boundary. The grid division has been initially formed, as shown in Figure 3.\nFigure 3. Structure region grid of the full-field structure image.\nThe grid that does not contact the boundary is a regular rectangular grid, but the grid rules that contact the boundary are different, and further fine division needs to be\nFigure 3. Structure region grid of the full-field structure image.\nThe grid tha do s not contact the boundary is a regular rectangular grid, but th grid rules that contact the boundary are different, and further fine division needs to be completed. The grid shapes at the edge are trapezoid, pentagon, and triangle. To unify shape and refinement, the trapezoid and pentagon are divided into several triangles. To date, the division of the entire displacement field grid is completed, and the division unit has only rectangles and triangles (as shown in Figure 4), which is convenient for subsequent construction of shape functions according to the unit shape.\nSustainability 2023, 15, 8683 7 of 17\nSustainability 2023, 15, x FOR PEER REVIEW 7 of 17\ncompleted. The grid shapes at the edge are trapezoid, pentagon, and triangle. To unify shape and refinement, the trapezoid and pentagon are divided into several triangles. To date, the division of the entire displacement field grid is completed, and the division unit has only rectangles and triangles (as shown in Figure 4), which is convenient for subsequent construction of shape functions according to the unit shape."
        },
        {
            "heading": "2.2.2. Node Displacement Calculation Using Template Matching",
            "text": "Template matching belongs to the digital correlation technology [2]. First, determine the template image, generate a window of the same size as the template image, and traverse the window from the upper left corner to the lower right corner in the image to be matched. Through correlation calculation, the correlation coefficient between all window images and template images is obtained, and a matrix with integer pixels is generated. The window corresponding to the peak of the correlation coefficient is the location of the template image in the image to be matched. The core of template matching lies in the correlation calculation. The normalized sum of squared differences (NSSD) is based on the sum of squared differences to calculate the difference between the gray values of the template image and the window image pixel points. The method is simple. Although the gray value can be normalized, the effect of white noise can be weakened, but the amount of computation is quite large and it is very sensitive to illumination. The normalized cross-correlation function (NCC) is to multiply the pixel values of points on the same pixel coordinates of two images of equal size, and then compare them with the square sum root of the pixel values of all pixels of the two images. Since in the calculation process, all the pixel values are squared and then the root number is processed, which can well weaken the influence of image white noise. Although the normalized cross-correlation function can resist white noise, it cannot solve the problem of brightness inconsistency. When the same pattern is in different brightness environments, the normalized cross-correlation function calculated similarity is very low. Therefore, to solve this shortcoming, the zero-mean normalized cross-correlation function (ZNCC) is improved based on the normalized cross-correlation function named R (x, y) (shown in Equations (1) and (2)). In the calculation process, the pixel value of all pixels ( , ( , )x yS m n )is subtracted from the average value of the image pixel value ( ,x yavS ), thereby weakening the influence of the image brightness on the calculation result. In Equations (1) and (2), M and N are the height and width of the template image, m, n, x, and y are parameters, T (m, n) is the gray value, and Tav is the average gray value.\n( ) ( ){ }\n( ) ( )\n, ,\n2 2 , ,\n1 1\n1 1 1 1\n, , ( , )\n, ,\nx y x y av av\nx y\nn\nx y av a\nM N\nm n\nM N M N\nm n m v\nS m n S T m n T R x y\nS m n S T m n T\n= =\n= = = =\n \u2212 \u2212    =\n \u2212 \u22c5 \u2212   \n\n \n(1)\n( ) ( ) 1 , 1 1 , 1\n1 1,, , M\nx y x y av av\nN M N\nm n m n S S m n T T m n MN MN= = = = = =  (2)\n2.2.3. Non-Node Displacement Calculation Using Shape Function\nFigure 4. Final grid of the full-field structure image.\n2.2.2. Node Displacement Calculation Using Template Matching\nTemplate matching belongs to the digital correlation technology [2]. First, determine the template image, generate a window of the same size as the template image, and traverse the window from the upper left corner to the lower right corner in the image to be matched. Through correlation calculation, the correlation coefficient between all window images and template images is obtained, and a matrix with integer pixels is generated. The window corresponding to the peak of the correlation coefficient is the location of the template image in the image to be matched.\nr f t l t t i li s i t c rr l ti l l ti . r li s f iff ( ) i t f iff t l l t t iff t ee t l es f l t\n. e t i l . lthough the gray alue can e r lize , t e ff t , t t f t ti i it l it i\ni i t ill i ti . e r alize cr ss-c rr l ti f ti ( ) i t lti l i l l s f i t l t l ,\nr t it t r t f l l s f ll i l f i . i c i t c lc l ti r , ll t i l l s r r t t i , i ll i i i i . lt t li ss-correlation function can resi t white noise, it cannot solve the problem of brightness inconsistency. When t same pattern is i different brightness enviro ments, the normalized cross-correlation function calculated similarity is very low. Therefore, to solve this shortcoming, the zero-mean nor alized cross-correlation function (ZNCC) is improved based on the normalized cross-correlation function named R (x, y) (shown in Equations (1) and (2)). In the calculation process, the pixel value of all pixels (Sx,y(m, n))is subtracted from the average value of the image pixel value (Sx,yav ), thereby weakening the influence of the image brightness on the calculation result. In Equations (1) and (2), M and N are the height and width of the template image, m, n, x, and y are parameters, T (m, n) is the gray value, and Tav is the average gray value.\nR(x, y) =\nM \u2211\nm=1\nN \u2211\nn=1\n{[ Sx,y(m, n) Sx,yav ] [T(m, n)\u2212 Tav] } \u221a\nM \u2211\nm=1\nN \u2211\nn=1\n[ Sx,y(m, n)\u2212 Sx,yav ]2 \u00b7 \u221a M \u2211\nm=1\nN \u2211\nn=1 [T(m, n)\u2212 Tav]\n2\nSx,yav = 1\nMN\nM\n\u2211 m=1\nN\n\u2211 n=1\nSx,y(m, n), Tav = 1\nMN\nM\n\u2211 m=1\nN\n\u2211 n=1 T(m, n) (2)\n. . . - i l t l l i\nFor non-node displacement, it is necessary to transfer the node displacement to each grid element by means of the idea of finite element shape function in the physical model [44]. Triangular and rectangular element shape functions are constructed according to the element types of the previous mesh generation results.\n(1) Rectangular bilinear element shape function.\nSustainability 2023, 15, 8683 8 of 17\nThe rectangular element has four nodes; therefore, the analysis model of rectangular bilinear element is adopted, and there are eight node displacement parameters. To simplify the results, the rectangular coordinates are transformed into regular coordinates for analysis by means of coordinate transformation, as shown in Figure 5.\nSustainability 2023, 15, x FOR PEER REVIEW 8 of 17\nFor non-node displacement, it is necessary to transfer the node displacement to each grid element by means of the idea of finite element shape function in the physical model [44]. Triangular and rectangular element shape functions are constructed according to the element types of the previous mesh generation results.\n(1) Rectangular bilinear element shape function. The rectangular element has four nodes; therefore, the analysis model of rectangular\nbilinear element is adopted, and there are eight node displacement parameters. To simplify the results, the rectangular coordinates are transformed into regular coordinates for analysis by means of coordinate transformation, as shown in Figure 5.\nGiven the displacement ui of each node i, the displacement function of each point in the element is:\n)( , i iu uN\u03be \u03b7 = (7) (2) Triangular element shape function. Since the shape function of triangular element in the rectangular coordinate system\nwill be more complex, the area coordinate is introduced for analysis. As shown in Figure 6, i, j, k are triangular element nodes, and P is any point in the element, which is connected to each node. Then, \u0394ijk is divided into three parts, which are denoted as:\nGiven the displacement ui of each node i, the displacement function of each point in the element is:\nu(\u03be, \u03b7) = \u2211 Niui (7) (2) Triangular element shape function. Since the shape fu ction of tria gular element i the rectangular coordinate system\nwill be more complex, the area coordinate is introduced for a alysis. As sho n in Figure 6, i, j, k are triangula element odes, and P is an point in the element, which is connected to each node. Then, \u2206ijk is divided into three parts, which are denoted as:  \u2206i = \u2206Pjk \u2206j = \u2206Pki \u2206k = \u2206Pij \u2206 = \u2206i + \u2206j + \u2206k = \u2206ijk (8)\nSustainability 2023, 15, 8683 9 of 17Sustainability 2023, 15, x FOR PEER REVIEW 9 of 17\nj\nk\nj k\ni\ni\nPjk Pki Pij\nijk \u0394 = \u0394 \u0394 = \u0394 \u0394 = \u0394  \u0394 = \u0394 + \u0394 + \u0394 = \u0394\n(8)\nThe position of point P can be represented by rectangular coordinates, and can also be represented by \u0394i, \u0394j, \u0394k.\n( , , )llL l i j k \u0394\n= = \u0394\n(9)\nThen, the position of point P can also be determined by Ll, which is called area coordinate.\nLet the point P coordinate be (x, y), then the area divided into three parts is: 1\n1 1 2\n1 j ji\nk k\nx y x y i j k i x y \u2192 \u2192= \u2192\u0394\n(10)\nThe unit area is: 1\n1 1 2\n1\ni i\nk k\nj j x y x y x y \u0394 =\n(11)\nTherefore, the area coordinate is:\n( ) ( )\n1 11 1 1 12\n1 2\nk k k\nj\nk\ni i i\nj j ji i\ny x x x x y\ny x x x\nia b x c y\nL\ni j k\n \u0394 = = \u2212 +\n+ \u2192\n\u0394 \n= + \u0394\n\u2192\n\n\u2192\n\u0394\n(12)\n( ) i j k k j i j k\ni k j\na i y x y y y i j\nc k x x\nx b  = \n=\n\u2212 = \u2212 \u2192\n\n\u2192  \u2192 \u2212\n(13)\nAccording to the properties of shape functions, Li, Lj, and Lk are the shape functions of triangular elements. The displacement of each point inside the triangular element is calculated by Equation (7).\nFigure 6. Area coordinate of triangular element.\nThe position of point P can be represented by rectangular coordinates, and can also be represented by \u2206i, \u2206j, \u2206k.\nLl = \u2206l \u2206 (l = i, j, k) (9)\nThen, the position of point P can also be determined by Ll, which is called area coordinate.\nLet the point P coordinate be (x, y), then the area divided into three parts is:\n\u2206i = 1 2 \u2223\u2223\u2223\u2223\u2223\u2223 x y 1 xj yj 1 xk yk 1 \u2223\u2223\u2223\u2223\u2223\u2223 i\u2192 j\u2192 k\u2192 i (10) The unit area is:\n\u2206 = 1 2 \u2223\u2223\u2223\u2223\u2223\u2223 xi yi 1 xj yj 1 xk yk 1 \u2223\u2223\u2223\u2223\u2223\u2223 (11) Therefore, the area coordinate is:\nLi = \u2206i \u2206 = 1 2\u2206 ( \u2223\u2223\u2223\u2223yj 1yk 1 \u2223\u2223\u2223\u2223\u2212 y\u2223\u2223\u2223\u2223xj 1xk 1 \u2223\u2223\u2223\u2223+ 1\u2223\u2223\u2223\u2223xj xjxk xk \u2223\u2223\u2223\u2223)\n= 12\u2206 (ai + bix + ciy) (i\u2192 j\u2192 k\u2192 i) (12)\n ai = xjyk \u2212 xkyj\nbi = yj \u2212 yk ci = xk \u2212 xj\n(i\u2192 j\u2192 k\u2192 i) (13)\nAccording to the properties of shape functions, Li, Lj, and Lk are the shape functions of triangular elements. The displacement of each point inside the triangular element is calculated by Equation (7)."
        },
        {
            "heading": "3. Validation Results and Discussion",
            "text": ""
        },
        {
            "heading": "3.1. Full-Field Image Generation Results",
            "text": "The bridge model used in this test is a side span of organic glass three-span continuous beam. To reduce the structural stiffness, the side span pier was removed and turned into a cantilever beam structure (2644 mm long). The camera is consumer-grade (Sony \u03b1-6000) with a resolution of 6000 \u00d7 4000. The structure was photographed from left to right using a fully automatic rotating pan-tilt control platform installed on a static tripod, as shown in Figure 7. The rotation speed was 2 degrees per second, and a total of 20 structural images were obtained. To verify the accuracy of the proposed method for displacement measurement, artificial targets of known sizes (20 mm \u00d7 20 mm) were placed at 200 mm, 400 mm, 800 mm, 1300 mm, 1800 mm, and 2200 mm from the beam end, two LVDT displacement sensors were installed 400 mm and 1300 mm, respectively. Four loading cases\nSustainability 2023, 15, 8683 10 of 17\nwere tested (different loadings placed at the cantilever end to excite different displacement fields of the structure were kept for 2 min, as shown in Figure 8).\nSustainability 2023, 15, x FOR PEER REVIEW 10 of 17"
        },
        {
            "heading": "3. Validation Results and Discussion",
            "text": ""
        },
        {
            "heading": "3.1. Full-Field Image Generation Results",
            "text": "The bridge model used in this test is a side span of organic glass three-span continuous beam. To reduce the structural stiffness, the side span pier was removed and turned into a cantilever beam structure (2644 mm long). The camera is consumer-grade (Sony \u03b16000) with a resolution of 6000 \u00d7 4000. The structure was photographed from left to right using a fully automatic rotating pan-tilt control platform installed on a static tripod, as shown in Figure 7. The rotation speed was 2 degrees per second, and a total of 20 structural images were obtained. To verify the accuracy of the proposed method for displacement measurement, artificial targets of known sizes (20 mm \u00d7 20 mm) were placed at 200 mm, 400 mm, 800 mm, 1300 mm, 1800 mm, and 2200 mm from the beam end, two LVDT displacement sensors were installed 400 mm and 1300 mm, respectively. Four loading cases were tested (different loadings placed at the cantilever end to excite different displacement fields of the structure were kept for 2 min, as shown in Figure 8).\nFigure 7. Schematic diagram of the rotation shooting process.\nFigure 8. Four different loading cases.\nThe preprocessing method was used to process the obtained 20 images to eliminate the foreshortening effect. The full-field image of the structure obtained by image stitching is shown in Figure 9. The conversion coefficient represents the actual distance represented by a pixel in the image. According to the artificial target, the conversion coefficient error of each part of the whole field image is calculated to be within 1%, which shows the effectiveness of the preprocessing algorithm. The structure foreground segmentation result is shown in Figure 10.\ni re 7. Sc e atic ia ra f t e r tati s ti r cess.\nSustainability 2023, 15, x FOR PEER REVIEW 10 of 17"
        },
        {
            "heading": "3. Validation Results and Discussion",
            "text": ""
        },
        {
            "heading": "3.1. Full-Field Image Generation Results",
            "text": "The bridge model used in this test is a side span of organic glass three-span continuous beam. To reduce the structural stiffness, the side span pier was removed and turned into a cantilever beam structure (2644 mm long). The camera is consumer-grade (Sony \u03b16000) with a resolution of 6000 \u00d7 4000. The structure was photographed from left to right using a fully automatic rotating pan-tilt control platform installed on a static tripod, as shown in Figure 7. The rotation speed was 2 degrees per second, and a total of 20 structural images were obtained. To verify the accuracy of the proposed method for displacement measurement, artificial targets of known sizes (20 mm \u00d7 20 mm) were placed at 200 mm, 400 mm, 800 mm, 1300 mm, 1800 mm, and 2200 mm from the beam end, two LVDT displacement sensors were installed 400 mm and 1300 mm, respectively. Four loading cases were tested (different loadings plac d at the cantilever end to excite ifferent displacement fields of the structure were kept for 2 min, as shown in Figure 8).\nFigure 7. Schematic diagram of the rotation shooting process.\nFigure 8. Four different loading cases.\nThe preprocessing method was used to process the obtained 20 images to eliminate the foreshortening effect. The full-field image of the structure obtained by image stitching is shown in Figure 9. The conversion coefficient represents the actual distance represented by a pixel in the image. According to the artificial target, the conversion coefficient error of each part of the whole field image is calculated to be within 1%, which shows the effectiveness of the preprocessing algorithm. The structure foreground segmentation result is shown in Figure 10.\nFigure 8. Four different loading cases.\nThe preprocessing method was used to process the obtained 20 images to eliminate the foreshortening effect. The full-field image of the structure obtained by image stitching is shown in Figure 9. The conversion coefficient represents the actual distance represented by a pixel in the image. According to the artificial target, the conversion coefficient error of each part of the whole field image is calculated to be within 1%, which shows the effectiveness of the preprocessing algorithm. The structure foreground segmentation result is shown in Figure 10.\nSustainability 2023, 15, x FOR PEER REVIEW 10 of 17"
        },
        {
            "heading": "3. Validation Results and Discussion",
            "text": ""
        },
        {
            "heading": "3.1. Full-Field Image Generation Results",
            "text": "The bridge model used in this test is a ide span of organic gl s three-span conti uous beam. To reduce the structural stiffness, the sid span pier was re oved and turned into a cantilev r beam structure (2644 mm long). The camera is consumer-grad (S ny \u03b16000) with a resolution of 6000 \u00d7 4000. The structure was photographed from left to right using a fully automatic ng pan-tilt control platform installed on static tripod, as shown in Figur 7. The rotation speed was 2 degrees per second, and a t tal f 20 structural i ages wer obtained. To verify the accuracy of the proposed ethod for displace-\nent measurement, artificial targets of known sizes (20 m \u00d7 20 mm) wer placed at 200 mm, 400 m, 800 mm, 1300 mm, 1800 mm, and 2200 mm from the beam end, two LVDT displacem nt s nsors were installed 400 mm and 1300 mm, respectively. Four loading cases w re tested (different loadings placed at the cantilever end to excite different displacement fields of the structure were kept for 2 min, as shown in Figure 8).\nFigure 7. Schematic diagram of the rotation shooting process.\ni r . o r iffer t l i c s s.\nThe preprocessing method was used to process he obtained 20 images to eliminate the f reshortening effect. The full-field imag of the structure obtaine by imag stitching is shown in Figure 9. The conversion coefficient represen s actual d stanc represented by a pixel in the image. According to the artificial target, e conversion coefficient rror of each part of the whol field image is calculated to b within 1%, which shows th effectiveness of the preprocessing algorithm. The structure foreground segmentation result is shown in Figure 10."
        },
        {
            "heading": "3.2. Displacement Field Calculation Results",
            "text": "The node displacement is calculated by the above method, and the conversion coefficient obtained by calibration is 0.073734 mm/pixel. Compared with the key point displacement of the LVDT set by 400 mm and 1300 mm, the results are shown in Table 1. The maximum node displacement error calculated by the proposed method is 5.4%, which shows the effectiveness and accuracy of the proposed method.\nTable 1. Comparison of key node displacement calculated by the proposed method and LVDT.\nLoading Case 400 mm (mm) 1300 mm (mm)\nLVDT Proposed Error Error (%) LVDT Proposed Error Error (%) 1 8.356 8.455 0.099 1.2 2.901 2.895 0.006 0.2 2 12.381 12.454 0.073 0.6 4.229 4.002 0.227 5.4 3 16.354 16.574 0.220 1.3 5.662 5.485 0.177 3.1 4 20.466 20.504 0.038 0.2 7.048 6.877 0.171 2.4\nAverage - - - 0.826 - - - 2.7\nIn the generated full-field image, the lowest of the bridge structure is about 500 pixels, and the highest is about 1600 pixels. The size of the template in template matching technique is set to 81 \u00d7 81, and the mesh size is set to 400 \u00d7 400. With the initial state image as a reference, the proposed method was used to calculate the structural displacement field for four loading cases, and the results are shown in Figures 11\u201314. The calculated structural displacement field conforms to the law of structural mechanics and the displacement change is continuous, which can preliminarily validate the feasibility of the proposed method.\nFigure 11. Calculated structural displacement field for Case 1.\nFigure 12. Calculated structural displacement field for Case 2."
        },
        {
            "heading": "3.2. isplace e t ield alc latio es lts",
            "text": "is lace ent is calculated by the above method, and the conversion coefficient obtained by calibration is 0.0 734 mm/pixel. Compared with the key point displac ment of the LVDT set by 400 mm and 1300 mm, the results are shown in Table 1.\nSustainability 2023, 15, 8683 11 of 17\nThe maximum node displacement error calculated by the proposed method is 5.4%, which shows the effectiveness and accuracy of the proposed method.\nTable 1. Comparison of key node displacement calculated by the proposed method and LVDT.\nLoading Case 400 mm (mm) 1300 mm (mm)\nLVDT Proposed Error Error (%) LVDT Proposed Error Error (%)\n1 8.356 8.455 0.099 1.2 2.901 2.895 0.006 0.2 2 12.381 12.454 0.073 0.6 4.229 4.002 0.227 5.4 3 16.354 16.574 0.220 1.3 5.662 5.485 0.177 3.1 4 20.466 20.504 0.038 0.2 7.048 6.877 0.171 2.4 Average - - - 0.826 - - - 2.7\nIn the generated full-field image, the lowest of the bridge structure is about 500 pixels, and the highest is about 1600 pixels. The size of the template in template matching technique is set to 81 \u00d7 81, and the mesh size is set to 400 \u00d7 400. With the initial state image as a reference, the proposed method was used to calculate the structural displacement field for four loading cases, and the results are shown in Figures 11\u201314. The calculated structural displacement field conforms to the law of structural mechanics and the displacement change is continuous, which can preliminarily validate the feasibility of the proposed method.\nSustainability 2023, 15, x FOR PEER REVIEW 11 of 17\nFigure 10. Structure foreground segmentation result."
        },
        {
            "heading": "3.2. Displacement Field Calculation Results",
            "text": "The node displacement is calculated by the above method, and the conversion coefficient obtained by calibration is 0.073734 mm/pixel. Compared with the key point displacement of the LVDT set by 400 mm and 1300 mm, the results are shown in Table 1. The maximum node displacement error calculated by the proposed method is 5.4%, which shows the effectiveness and accuracy f the proposed meth d.\nTable 1. Comparison of key node displacement calculated by the proposed method and LVDT.\nLoading Case 400 mm (mm) 1300 mm (mm)\nLVDT Proposed Error Error (%) LVDT Proposed Error Error (%) 1 8.356 8.455 0.099 1.2 2.901 2.895 0.006 0.2 2 12.381 12.454 0.073 0.6 4.229 4.002 0.227 5.4 3 16.354 16.574 0.220 1.3 5.662 5.485 0.177 3.1 4 20.466 20.504 0.038 0.2 7.048 6.877 0.171 2.4\nAverage - - - 0.826 - - - 2.7\nIn the generated full-field image, the lowest of the bridge structure is about 500 pixels, and the highest is about 1600 pixels. The size of the template in template matching technique is set to 81 \u00d7 81, and the mesh size is set to 400 \u00d7 400. With the initial state image as a reference, the proposed method was used to calculate the structural displace ent field for four loading cases, and the res lts are shown in Figures 11\u201314. The calculate struct ral displacement field conforms to the law of structural mech nics and the displacem nt change is c ntinu us, which can preli inarily vali ate the feasibility of th proposed method.\nFigure 11. Calculated structural displacement field for Case 1.\nFigure 11. Calculated structural displacement field for Case 1.\nSustainability 2023, 15, x FOR PEER REVIEW 11 of 17\nFigure 10. Structure foreground segmentation result."
        },
        {
            "heading": "3.2. Displacement Field Calculation Results",
            "text": "The node displacement is calculated by the above method, and the conversion coefficient obtained by calibration is 0.073734 mm/pixel. Compared with the key point displacement of the LVDT set by 400 mm and 1300 mm, the results are shown in Table 1. The maximum node displacement error calculated by the proposed method is 5.4%, which shows the effectiveness and accuracy of the proposed ethod.\nTable 1. Comparison of key node displacement calculated by the proposed method and LVDT.\nLoading Case 400 mm (mm) 1300 mm (mm)\nLVDT Proposed Error Error (%) LVDT Proposed Error Error (%) 1 8.356 8.455 0.099 1.2 2.901 2.895 0.006 0.2 2 12.381 12.454 0.073 0.6 4.229 4.002 0.227 5.4 3 16.354 16.574 0.220 1.3 5.662 5.485 0.177 3.1 4 20.466 20.504 0.038 0.2 7.048 6.877 0.171 2.4\nAverage - - - 0.826 - - - 2.7\nIn the generated full-field image, the lowest of the bridge structure is about 500 pixels, and the highest is about 1600 pixels. The size of the template in template matching technique is set to 81 \u00d7 81, and the mesh size is set to 400 \u00d7 400. With the initial state image as a reference, the proposed method was used to calculate the structural displacement field for four loading cases, and the results are shown in Figures 11\u201314. The calculated structural displacement field conforms to the law of structural mechanics and the displacement change is continuous, which can preliminarily validate the feasibility of the proposed method.\nFigure 11. Calculated structural displace ent field for Case 1.\nSustainability 2023, 15, x FOR PEER REVIEW 12 of 17\nTo quantitatively evaluate the accuracy of the structural displacement field calculated by the proposed method, the corresponding finite element model was established and updated according to the geometric size and material properties of the bridge model used in the experiment (the objective is the displacement difference at the position of LVDT). The bridge material is plexiglass, the density is 1155 kg/m3, the elastic modulus is 2.2 GPa, and the Poisson\u2019s ratio is 0.38. When meshing the model, the cutting plane is defined per 10 mm from the cantilever end, and the web plate height direction has 10 nodes, as shown in Figure 15.\nFigure 15. Finite element model of the employed bridge model.\nThe distance from the cantilever end to the 2600 mm on the side of the web plate is also 10 \u00d7 261 = 2610 nodes. The consolidation end of the model is completely consolidated, and the displacement load is applied to the section at 400 mm and 1300 mm from the cantilever end to simulate the actual load. The finite element software Abaqus was used to simulate the displacement field corresponding to the initial state and four working conditions, the displacement fields calculated by the finite element model are shown in Figures 16\u201319. Considering the displacement field dimension calculated by the proposed method, the corresponding displacement fields of different load cases generated by the finite element model are extracted.\nFigure 16. Calculated structural displacement field by the finite element model for Case 1.\nSustainability 2023, 15, 8683 12 of 17\nSustainability 2023, 15, x FOR PEER REVIEW 12 of 17\nFigure 13. Calculated structural displacement field for Case 3.\nFigure 14. Calculated structural displacement field for Case 4.\nTo quantitatively evaluate the accuracy of the structural displacement field calculated by the proposed method, the corresponding finite element model was established and updated according to the geometric size and material properties of the bridge model used in the experiment (the objective is the displacement difference at the position of LVDT). The bridge material is plexiglass, the density is 1155 kg/m3, the elastic modulus is 2.2 GPa, and the Poisson\u2019s ratio is 0.38. When meshing the model, the cutting plane is defined per 10 mm from the cantilever end, and the web plate height direction has 10 nodes, as shown in Figure 15.\nFigure 15. Finite element model of the employed bridge model.\nThe distance from the cantilever end to the 2600 mm on the side of the web plate is also 10 \u00d7 261 = 2610 nodes. The consolidation end of the model is completely consolidated, and the displacement load is applied to the section at 400 mm and 1300 mm from the cantilever end to simulate the actual load. The finite element software Abaqus was used to simulate the displacement field corresponding to the initial state and four working conditions, the displacement fields calculated by the finite element model are shown in Figures 16\u201319. Considering the displacement field dimension calculated by the proposed method, the corresponding displacement fields of different load cases generated by the finite element model are extracted.\nFigure 16. Calculated structural displacement field by the finite element model for Case 1.\nFigure 14. Calculated structural displacement field for Case 4.\nTo quantitatively evaluate the accuracy of the structural displace ent field calculated by t e ro ose et o , t e corres o i g ite ele e t o el as establis e a\nate acc r i t t e e etric size a aterial r erties f t e ri e el se i t ri t (t e j cti e is t e is lace ent difference at the position of LVDT).\ni t i l i l i l , t it i 3, the elastic modulus is 2.2 GPa, t i \u2019 ti i . . s i t l, t tti l e is r\nt l t i t ir i , s i i .\nSustainability 2023, 15, x FOR PEER REVIEW 12 of 17\nFigure 13. Calculated structural displacement field for Case 3.\nFigure 14. Calculated structural displacement field for Case 4.\nTo quantitatively evaluate the accuracy of the structural displacement field calculated by the proposed method, the corresponding finite element model was established and updated according to the geometric size and material properties of the bridge model used in the experiment (the objective is the displacement difference at the position of LVDT). The bridge material is plexiglass, the density is 1155 kg/m3, the elastic modulus is 2.2 GPa, and the Poisson\u2019s ratio is 0.38. When meshing the model, the cutting plane is defined per 10 mm from the cantilever end, and the web plate height direction has 10 nodes, as shown in Figure 15.\nFigure 15. Finite element model of the employed bridge model.\nThe distance from the cantilever end to the 2600 mm on the side of the web plate is also 10 \u00d7 261 = 2610 nodes. The consolidation end of the model is completely consolidated, and the displacement load is applied to the section at 400 mm and 1300 mm from the cantilever end to simulate the actual load. The finite element software Abaqus was used to simulate the displacement field corresponding to the initial state and four working conditions, the displacement fields calculated by the finite element model are shown in Figures 16\u201319. Considering the displacement field dimension calculated by the proposed method, the corresponding displacement fields of different load cases generated by the finite element model are extracted.\nFigure 16. Calculated structural displacement field by the finite element model for Case 1.\ni r . i ite ele e t l f t l i l.\nist fr the cantilever end to the 2600 m on the side of the w b plate is also 10 \u00d7 261 = 2610 nodes. The cons lidation end of the model is completely cons lidate , and the displacement load is pplied to the sec ion at 400 mm and 1300 mm from the cantilever end to simulate the actual load. The finite element softwar Abaqus was used to sim late the displacement field corresponding to the initial state and four working condit ons, the\nisplacement fields calculated by the finite eleme t model are shown in Figures 16\u201319. Considering the displacem nt fie d dimension calculated by the proposed meth d, the corresponding displacement fields of differ nt load cases generated by the fini element model are x racted.\nSustainability 2023, 15, x FOR PEER REVIE 12 of 17\nFigure 13. alculated structural displace ent field for ase 3.\nFigure 14. alculated structural displace ent field for ase 4.\nTo quantitatively evaluate the accuracy of the structural displace ent field calculated by the proposed ethod, the corresponding finite ele ent odel as established and updated according to the geo etric size and aterial properties of the bridge odel used in the experi ent (the objective is the displace ent di erence at the position of L T). The bridge aterial is plexiglass, the density is 1155 kg/ 3, the elastic odulus is 2.2 Pa, and the Poisson\u2019s ratio is 0.38. hen eshing the odel, the cutting plane is defined per 10 fro the cantilever end, and the eb plate height direction has 10 nodes, as sho n in Figure 15.\nFigure 15. Finite ele ent odel of the e ployed bridge odel.\nThe distance fro the cantilever end to the 2600 on the side of the eb plate is also 10 \u00d7 261 = 2610 nodes. The consolidation end of the odel is co pletely consolidate , and the displace ent load is applied to the section at 400 and 1300 fro the cantilever end to si ulate the actual load. The finite ele ent soft are baqus as used o si ulate th displace ent fiel corresponding to he initial state and four orking cond tions, th displace ent fiel s calculated by the finite ele ent del are sho n in Figures 16\u201319. onsidering the displace ent field di ension calculated by the proposed\nethod, the corresponding displace ent fields of di rent load cases g nerated by the finit ele ent odel are extracted.\nFigure 16. alculated structural displace ent field by the finite ele ent odel for ase 1. Fig re 16. alc late str ct ral is lace e t el by t e ite ele e t o el for ase 1.\nSustainability 2023, 15, x FOR PEER REVIEW 13 of 17\nFigure 17. Calculated structural displacement field by the finite element model for Case 2.\nFigure 18. Calculated structural displacement field by the finite element model for Case 3.\nFigure 19. Calculated structural displacement field by the finite element model for Case 4.\nTo evaluate the similarity of two displacement fields (F1, F2), the normalized correlation coefficient R (F1, F2) is proposed as the evaluation index. The calculation method is shown in Equation (14), where M and N are the number of rows and columns of the displacement field, and F (m, n) is the displacement value at the position of the displacement field (m, n). In addition, the deviation between data is an important index to measure the difference of displacement field. The difference between two displacement field data is defined as the root mean square deviation D (F1, F2), and its calculation method is shown in Equation (15).\n( ) ( )\n( ) ( )\n1 1\n2 1\n2 1 1 1\n2\n1\n2\n1 2\n1\n, , ( , )\n, ,\nM N\nm n\nM N M N\nm n m n\nF m n F m n R F F\nF m n F m n\n= =\n= = = =\n\u22c5   =\n\u22c5      \n\n \n(14)\n( ) ( )( )2 1 1 2\n1 1 2\n, , ( , )\nM N\nm n F m n F m n\nD NM\nF F = =  \u2212  \n= \u00d7\n\n(15)\nFigure 20 shows the quantitative evaluation results of the structural displacement field under different load conditions calculated by the proposed method. The R values of the calculation results of the proposed method and the finite element model are higher than 0.9995, indicating that the overall trend of the calculated displacement field is similar to the real displacement field. The D values are all less than 0.304 mm, and the relative offset obtained by dividing the D value by the maximum displacement field of the four load cases is less than 1.2%, which verifies the accuracy of the proposed method.\nFigure 17. Calculated structural displacement field by the finite element model for Case 2.\nSustainability 2023, 15, 8683 13 of 17\nSustainability 2023, 15, x FOR PEER REVIEW 13 of 17\nFigure 17. Calculated structural displacement field by the finite element model for Case 2.\nFigure 18. Calculated structural displacement field by the finite element model for Case 3.\nFigure 19. Calculated structural displacement field by the finite element model for Case 4.\nTo evaluate the similarity of two displacement fields (F1, F2), the normalized correlation coefficient R (F1, F2) is proposed as the evaluation index. The calculation method is shown in Equation (14), where M and N are the number of rows and columns of the displacement field, and F (m, n) is the displacement value at the position of the displacement field (m, n). In addition, the deviation between data is an important index to measure the difference of displacement field. The difference between two displacement field data is defined as the root mean square deviation D (F1, F2), and its calculation method is shown in Equation (15).\n( ) ( )\n( ) ( )\n1 1\n2 1\n2 1 1 1\n2\n1\n2\n1 2\n1\n, , ( , )\n, ,\nM N\nm n\nM N M N\nm n m n\nF m n F m n R F F\nF m n F m n\n= =\n= = = =\n\u22c5   =\n\u22c5      \n\n \n(14)\n( ) ( )( )2 1 1 2\n1 1 2\n, , ( , )\nM N\nm n F m n F m n\nD NM\nF F = =  \u2212  \n= \u00d7\n\n(15)\nFigure 20 shows the quantitative evaluation results of the structural displacement field under different load conditions calculated by the proposed method. The R values of the calculation results of the proposed method and the finite element model are higher than 0.9995, indicating that the overall trend of the calculated displacement field is similar to the real displacement field. The D values are all less than 0.304 mm, and the relative offset obtained by dividing the D value by the maximum displacement field of the four load cases is less than 1.2%, which verifies the accuracy of the proposed method.\nFigure 18. Calculated structural displacement field by the finite element model for Case 3.\nSustainability 2023, 15, x FOR PEER REVIEW 13 of 17\nFigure 17. Calculated structural displacement field by the finite element model for Case 2.\nFigure 18. Calculated structural displace ent field by the finite ele ent odel for Case 3.\nFigure 19. Calculated structural displacement field by the finite element model for Case 4.\nTo evaluate the similarity of two displacement fields (F1, F2), the normalized correlation coefficient R (F1, F2) is proposed as the evaluation index. The calculation method is shown in Equation (14), where M and N are the number of rows and columns of the displacement field, and F (m, n) is the displacement value at the position of the displacement field (m, n). In addition, the deviation between data is an important index to measure the difference of displacement field. The difference between two displacement field data is defined as the root mean square deviation D (F1, F2), and its calculation method is shown in Equation (15).\n( ) ( )\n( ) ( )\n1 1\n2 1\n2 1 1 1\n2\n1\n2\n1 2\n1\n, , ( , )\n, ,\nM N\nm n\nM N M N\nm n m n\nF m n F m n R F F\nF m n F m n\n= =\n= = = =\n\u22c5   =\n\u22c5      \n\n \n(14)\n( ) ( )( )2 1 1 2\n1 1 2\n, , ( , )\nM N\nm n F m n F m n\nD NM\nF F = =  \u2212  \n= \u00d7\n\n(15)\nFigure 20 shows the quantitative evaluation results of the structural displacement field under different load conditions calculated by the proposed method. The R values of the calculation results of the proposed method and the finite element model are higher than 0.9995, indicating that the overall trend of the calculated displacement field is similar to the real displacement field. The D values are all less than 0.304 mm, and the relative offset obtained by dividing the D value by the maximum displacement field of the four load cases is less than 1.2%, which verifies the accuracy of the proposed method.\nFigure 19. Calculated structural displacement field by the finite element model for Case 4.\nTo evaluate the similarity of two displacement fields (F1, F2), the normalized correlation coefficient R (F1, F2) is propose as the evaluation index. The calculation method is shown i Equation (14), where M and N are the number of rows and columns of the displace e t field, and F (m, n) is the displacement v lue at the position of the displacement field (m, n). In addition, the deviation betw en data is a important index to measure the\nifference of displac ment field. The difference between two displace nt field data is defined as the root mean square deviation D (F1, F2), and its calculation method is shown in Equation (15).\nR(F1, F2) =\nM \u2211\nm=1\nN \u2211\nn=1 [F1(m, n) \u00b7 F2(m, n)]\u221a\nM \u2211\nm=1\nN \u2211\nn=1 [F1(m, n)]\n2\n\u00b7 \u221a M \u2211\nm=1\nN \u2211\nn=1 [F2(m, n)]\n2 (14)\nD(F1, F2) =\n\u221a\u221a\u221a\u221a\u221a M\u2211m=1 N\u2211n=1 [ (F1(m, n)\u2212 F2(m, n))2 ] M\u00d7 N (15)\nFigure 20 shows the qua titative eval ation results of the structural isplacement field under different load conditions calculated by the proposed method. The R values of the calculation results of the proposed method and the finite element model are higher than 0.9995, indicating that the overall trend of the calculated displacement field is similar to the real displacement field. The D values are all less than 0.304 mm, and the relative offset obtained by dividing the D value by the maximum displacement field of the four load cases is less than 1.2%, which verifies the accuracy of the proposed method.\nSustainability 2023, 15, 8683 14 of 17 Sustainability 2023, 15, x FOR PEER REVIEW 14 of 17"
        },
        {
            "heading": "3.3. The Influence of Different Mesh Sizes",
            "text": "As one of the important parameters of the proposed method, the mesh size affects the number of meshes and nodes in the full-field structural image. In the full-field bridge image of this experiment, the minimum structural height is only 500 pixels, and thus the mesh size should not be greater than 500. To study the influence of mesh size on the calculation of structural displacement field, five different meshes of 200 \u00d7 200, 250 \u00d7 250, 300 \u00d7 300, 350 \u00d7 350, and 400 \u00d7 400 were used to divide the image. The local meshes near the consolidation end are shown in Figure 21.\nFigure 21. Local meshes near the consolidation end with different mesh sizes.\nThe R and D values of the structural displacement field calculated with different mesh sizes are calculated, respectively. The results are shown in Figure 22. The R and D values corresponding to the five mesh sizes are basically unchanged, which verifies that the mesh size has no significant effect on the calculation accuracy of the structural\nFigure 20. Quantitative evaluation results of the structural displacement field: (a) R (F1, F2); (b) D (F1, F2)."
        },
        {
            "heading": "3.3. he I fluence of Different Mesh Sizes",
            "text": "one of the important paramet rs of the prop sed method, the m sh size aff cts ber of meshes and nodes in the full-field struct ral image. In the full-fie d bridge\ni f this experiment, the minimum structural height is only 500 pixels, and thus the esh size should not be greater than 500. To study the influence of esh size on the calculation of structural displacement field, five different meshes of 200 \u00d7 200, 250 \u00d7 250, 300 \u00d7 300, 350 \u00d7 350, and 400 \u00d7 400 were used to divide the image. The local meshes near the consolidation end are shown in Figure 21.\nSustainability 2023, 15, x FOR PEER REVIEW 14 of 17\nFig re 20. Quantitative evaluation results of the structural displacement field: a) R (F1, F2); (b) D (F1, F2).\n3.3. The Influence of Diff rent Mesh Sizes As one of the import nt parameters of the proposed method, the mesh size affects the nu ber of meshes and nodes in the full-field structural image. In the full-field bridge image of this experiment, the minimum structural height is only 500 pixels, and thus the mesh size should not be greater than 500. To study the influence of mesh size on the calculation of structural displacement eld, five different meshes of \u00d7 2 0, 250 \u00d7 250, 300 \u00d7 0 , 350 \u00d7 350, and 400 \u00d7 400 wer use to ivide the image. The local meshes near the consolidation end are shown in Figure 21.\nFigure 21. Local meshes near the consolidation end with different mesh sizes.\nThe R and D values of the structural displacement field calculated with different mesh sizes are calculated, respectively. The results are shown in Figure 22. The R and D values corresponding to the five mesh sizes are basically unchanged, which verifies that the mesh size has no significant effect on the calculation accuracy of the structural\nFigure 21. Local meshes near the consolidation end with different mesh sizes.\nThe R and D values of the structural displacement field calculated with different mesh sizes are calculated, respectively. The results are shown in Figure 22. The R and D values\nSustainability 2023, 15, 8683 15 of 17\ncorresponding to the five mesh sizes are basically unchanged, which verifies that the mesh size has no significant effect on the calculation accuracy of the structural displacement field. However, considering that the larger the mesh size, the fewer the number of generated mesh and nodes, namely, the higher the calculation efficiency, it is recommended that the mesh size can be as large as possible within the allowable range. Therefore, the selection principle of grid size is to ensure that the maximum grid size is based on ensuring at least one complete grid in the short side direction of the structure.\nSustainability 2023, 15, x FOR PEER REVIEW 15 of 17\ndispl cement field. However, considering that the larger the mesh size, the fewer the number of generated mesh and nodes, namely, the higher the calculation efficiency, it is recommended that the mesh size can be as large as possible within the allowable range. Therefore, the selection principle of grid size is to ensure that the maximum grid size is based on ensuring at least one complete grid in the short side direction of the structure.\nIn this paper, a displacement field calculation framework of large-scale structures based on computer vision with physical constraints is proposed. Only a single camera is used to solve the contradiction between imaging field-of-view and resolution, and the accurate acquisition of large-scale structural displacement field is realized. The specific conclusions can be drawn as follows. It is feasible to use the camera set on the automatic rotating device to obtain high-resolution images of large-scale structures, and then use image stitching technology to generate panoramic images of structures. The laboratory bridge model (2644 mm long) is used to verify the proposed framework, and an updated finite element model is established for quantitative evaluation. The evaluation index R is greater than 0.9995, and the D value is less than 0.304 mm, which validate the accuracy of the proposed method. The parameter sensitivity analysis of mesh size, one of the important parameters, is conducted. The mesh size has no significant effect on the accuracy, but considering the computational efficiency, the mesh size can obtain the upper limit of the allowable range. In this paper, the displacement field of a large structure is obtained at a small hardware cost, but the limitation is that it can only be used for static or quasi-static deformation of the structure, and cannot realize real-time calculation of the dynamic displacement field. This is due to the fact that the use of automatic rotating device for image shooting requires time that cannot be ignored. Future work will focus on improving the workflow of the rotating device or using multi-lens cameras for simultaneous shooting to minimize image acquisition time and further improve the efficiency of the algorithm to achieve realtime acquisition of dynamic displacement fields.\nAuthor Contributions: Conceptualization, Y.G. and S.L.; methodology, P.Z.; resources, Y.Z.; data curation, Y.G., Y.Z., F.M. and H.D.; writing\u2014original draft preparation, Y.G. and P.Z.; writing\u2014 review and editing, Y.G.; visualization, P.Z.; supervision, S.L.; funding acquisition, S.L. All authors have read and agreed to the published version of the manuscript.\nFunding: Financial support for this study was provided by the China Railway Design Corporation R&D Program [2020YY240604].\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability Statement: Not applicable."
        },
        {
            "heading": "4. onclusions",
            "text": "In this paper, a displacement field calculation framework of large-scale structures based on computer vision with physical constraints is proposed. Only a single camera is used to solve the contradiction between imaging field-of-view and resolution, and the accurate acquisition of large-scale structural displacement field is realized. The specific conclusions can be drawn as follows. It is feasible to use the camera set on the automatic rotating device to obtain high-resolution images of large-scale structures, and then use image stitching technology to generate panoramic images of structures. The laboratory bridge model (2644 mm long) is used to verify the proposed framework, and an updated finite ele ent model is established for quantitative evaluation. The evaluation index R is greater than 0.9995, and the D value is less than 0.304 mm, which validate the accuracy of the proposed method. The parameter sensitivity alysis of esh size, one of he important parameters, is conducted. The mesh size ha no significant effect on the accuracy, but considering the computational efficiency, the mesh size can obtain the upper limit of the allowable range. In this paper, the displacement field of a large structure is obtained at a small hardware cost, but the limitation is that it can only be used for static or quasi-static deformation of the structure, and cannot realize real-time calculation of the dynamic displacement field. This is due to the fact that the use of automatic rotating device for image shooting requires time that cannot be ignored. Future work will focus on improving the workflow of the rotating device or using multi-lens cameras for simultaneous shooting to minimize image acquisition time and further improve the efficiency of the algorithm to achieve real-time acquisition of dynamic displacement fields.\nAuthor Contributions: Conceptualization, Y.G. and S.L.; methodology, P.Z.; resources, Y.Z.; data curation, Y.G., Y.Z., F.M. and H.D.; writing\u2014original draft preparation, Y.G. and P.Z.; writing\u2014review and editing, Y.G.; visualization, P.Z.; superv sion, S.L.; funding acquisition, S.L. All authors have read and agreed to the published version of the manuscript.\nFunding: Financial support for this study was provided by the China Railway Design Corporation R&D Program [2020YY240604].\nInstitutional Review Board Statement: Not applicable.\nSustainability 2023, 15, 8683 16 of 17\nInformed Consent Statement: Not applicable.\nData Availability Statement: Not applicable.\nConflicts of Interest: The authors declare no conflict of interest.\nReferences 1. Dong, C.-Z.; Catbas, F.N. A review of computer vision\u2013based structural health monitoring at local and global levels. Struct. Health Monit. 2020, 20, 692\u2013743. [CrossRef] 2. Feng, D.; Feng, M.Q. Experimental validation of cost-effective vision-based structural health monitoring. Mech. Syst. Signal Process. 2017, 88, 199\u2013211. [CrossRef] 3. Liu, Y.; Li, Y.; Wang, D.; Zhang, S. Model Updating of Complex Structures Using the Combination of Component Mode Synthesis and Kriging Predictor. Sci. World J. 2014, 2014, 476219. [CrossRef] 4. Liu, Y.; Zhang, S. Damage Localization of Beam Bridges Using Quasi-Static Strain Influence Lines Based on the BOTDA Technique. Sensors 2018, 18, 4446. [CrossRef] [PubMed] 5. Cha, Y.J.; Choi, W.; B\u00fcy\u00fck\u00f6zt\u00fcrk, O. Deep learning-based crack damage detection using convolutional neural networks. Comput. -Aided Civil. Infrastruct. Eng. 2017, 32, 361\u2013378. [CrossRef] 6. Kong, X.; Li, J. Vision-based fatigue crack detection of steel structures using video feature tracking. Comput. -Aided Civil. Infrastruct. Eng. 2018, 33, 783\u2013799. [CrossRef] 7. Ramana, L.; Choi, W.; Cha, Y.-J. Fully automated vision-based loosened bolt detection using the Viola\u2013Jones algorithm. Struct. Health Monit. 2018, 18, 422\u2013434. [CrossRef] 8. Xu, Y.; Li, S.; Zhang, D.; Jin, Y.; Zhang, F.; Li, N.; Li, H. Identification framework for cracks on a steel structure surface by a\nrestricted Boltzmann machines algorithm based on consumer-grade camera images. Struct. Control. Health Monit. 2018, 25, e2075. [CrossRef]\n9. Bao, Y.; Shi, Z.; Beck, J.L.; Li, H.; Hou, T.Y. Identification of time-varying cable tension forces based on adaptive sparse timefrequency analysis of cable vibrations. Struct. Control. Health Monit. 2017, 24, e1889. [CrossRef] 10. Huang, Y.; Beck, J.L.; Li, H. Bayesian system identification based on hierarchical sparse Bayesian learning and Gibbs sampling with application to structural damage assessment. Comput. Methods Appl. Mech. Eng. 2017, 318, 382\u2013411. [CrossRef] 11. Li, H.; Lan, C.M.; Ju, Y.; Li, D.S. Experimental and Numerical Study of the Fatigue Properties of Corroded Parallel Wire Cables. J. Bridge Eng. 2012, 17, 211\u2013220. [CrossRef] 12. Li, H.; Mao, C.-X.; Ou, J.-P. Experimental and theoretical study on two types of shape memory alloy devices. Earthq. Eng. Struct. Dyn. 2008, 37, 407\u2013426. [CrossRef] 13. Li, S.; Wei, S.; Bao, Y.; Li, H. Condition assessment of cables by pattern recognition of vehicle-induced cable tension ratio. Eng. Struct. 2018, 155, 1\u201315. [CrossRef] 14. Li, S.; Zhu, S.; Xu, Y.-L.; Chen, Z.-W.; Li, H. Long-term condition assessment of suspenders under traffic loads based on structural monitoring system: Application to the Tsing Ma Bridge. Struct. Control. Health Monit. 2012, 19, 82\u2013101. [CrossRef] 15. Sony, S.; Laventure, S.; Sadhu, A. A literature review of next-generation smart sensing technology in structural health monitoring. Struct. Control. Health Monit. 2019, 26, e2321. [CrossRef] 16. Spencer, B.F.; Hoskere, V.; Narazaki, Y. Advances in Computer Vision-Based Civil Infrastructure Inspection and Monitoring. Engineering 2019, 5, 199\u2013222. [CrossRef] 17. Bernasconi, A.; Carboni, M.; Comolli, L.; Galeazzi, R.; Gianneo, A.; Kharshiduzzaman, M. Fatigue Crack Growth Monitoring in Composite Bonded Lap Joints by a Distributed Fibre Optic Sensing System and Comparison with Ultrasonic Testing. J. Adhes. 2016, 92, 739\u2013757. [CrossRef] 18. Zamani, P.; Jaamialahmadi, A.; da Silva, L.F.M.; Farhangdoost, K. An investigation on fatigue life evaluation and crack initiation of Al-GFRP bonded lap joints under four-point bending. Compos. Struct. 2019, 229, 111433. [CrossRef] 19. Moradi, A.; Shariati, M.; Zamani, P.; Karimi, R. Experimental and numerical analysis of ratcheting behavior of A234 WPB steel elbow joints including corrosion defects. Proc. Inst. Mech. Eng. Part. L J. Mater. Des. Appl. 2022, 237, 451\u2013468. [CrossRef] 20. Zamani, P.; Fm da Silva, L.; Masoudi Nejad, R.; Ghahremani Moghaddam, D.; Soltannia, B. Experimental study on mixing ratio effect of hybrid graphene nanoplatelet/nano-silica reinforcement on the static and fatigue life of aluminum-to-GFRP bonded joints under four-point bending. Compos. Struct. 2022, 300, 116108. [CrossRef] 21. Djabali, A.; Toubal, L.; Zitoune, R.; Rechak, S. Fatigue damage evolution in thick composite laminates: Combination of X-ray tomography, acoustic emission and digital image correlation. Compos. Sci. Technol. 2019, 183, 107815. [CrossRef] 22. Feng, D.; Feng, M.Q. Computer vision for SHM of civil infrastructure: From dynamic response measurement to damage detection\u2014A review. Eng. Struct. 2018, 156, 105\u2013117. [CrossRef] 23. Xu, Y.; Brownjohn, J.M.W. Review of machine-vision based methodologies for displacement measurement in civil structures. J. Civil. Struct. Health Monit. 2018, 8, 91\u2013110. [CrossRef] 24. Feng, D.; Feng, M.Q. Vision-based multipoint displacement measurement for structural health monitoring. Struct. Control. Health Monit. 2016, 23, 876\u2013890. [CrossRef]\nSustainability 2023, 15, 8683 17 of 17\n25. Aoyama, T.; Li, L.; Jiang, M.; Takaki, T.; Ishii, I.; Yang, H.; Umemoto, C.; Matsuda, H.; Chikaraishi, M.; Fujiwara, A. Vision-Based Modal Analysis Using Multiple Vibration Distribution Synthesis to Inspect Large-Scale Structures. J. Dyn. Syst. Meas. Control. 2018, 141, 031007. [CrossRef] 26. Luo, L.; Feng, M.Q.; Wu, Z.Y. Robust vision sensor for multi-point displacement monitoring of bridges in the field. Eng. Struct. 2018, 163, 255\u2013266. [CrossRef] 27. Lydon, D.; Lydon, M.; Rinc\u00f3n, J.M.d.; Taylor, S.E.; Robinson, D.; O\u2019Brien, E.; Catbas, F.N. Development and Field Testing of a Time-Synchronized System for Multi-Point Displacement Calculation Using Low-Cost Wireless Vision-Based Sensors. IEEE Sens. J. 2018, 18, 9744\u20139754. [CrossRef] 28. Xu, Y.; Brownjohn, J.; Kong, D. A non-contact vision-based system for multipoint displacement monitoring in a cable-stayed footbridge. Struct. Control. Health Monit. 2018, 25, e2155. [CrossRef] 29. Song, Q.S.; Wu, J.R.; Wang, H.L.; An, Y.S.; Tang, G.W. Computer vision-based illumination-robust and multi-point simultaneous structural displacement measuring method. Mech. Syst. Signal. Process. 2022, 170, 108822. [CrossRef] 30. Lai, Z.; Alzugaray, I.; Chli, M.; Chatzi, E. Full-field structural monitoring using event cameras and physics-informed sparse identification. Mech. Syst. Signal. Process. 2020, 145, 106905. [CrossRef] 31. Shang, Z.; Shen, Z. Multi-point vibration measurement and mode magnification of civil structures using video-based motion processing. Autom. Constr. 2018, 93, 231\u2013240. [CrossRef] 32. Yang, Y.; Dorn, C.; Farrar, C.; Mascarenas, D. Blind, simultaneous identification of full-field vibration modes and large rigid-body motion of output-only structures from digital video measurements. Eng. Struct. 2020, 207, 110183. [CrossRef] 33. Yang, Y.; Sanchez, L.; Zhang, H.; Roeder, A.; Bowlan, J.; Crochet, J.; Farrar, C.; Mascarenas, D. Estimation of full-field, full-order experimental modal model of cable vibration from digital video measurements with physics-guided unsupervised machine learning and computer vision. Struct. Control. Health Monit. 2019, 26, e2358. [CrossRef] 34. Narazaki, Y.; Gomez, F.; Hoskere, V.; Smith, M.D.; Spencer, B.F. Efficient development of vision-based dense three-dimensional displacement measurement algorithms using physics-based graphics models. Struct. Health Monit. Int. J. 2021, 20, 1841\u20131863. [CrossRef] 35. Narazaki, Y.; Hoskere, V.; Eick, B.A.; Smith, M.D.; Spencer, B.F. Vision-based dense displacement and strain estimation of miter gates with the performance evaluation using physics-based graphics models. Smart Struct. Syst. 2019, 24, 709\u2013721. [CrossRef] 36. Bhowmick, S.; Nagarajaiah, S. Identification of full-field dynamic modes using continuous displacement response estimated from vibrating edge video. J. Sound Vib. 2020, 489, 115657. [CrossRef] 37. Bhowmick, S.; Nagarajaiah, S. Spatiotemporal compressive sensing of full-field Lagrangian continuous displacement response from optical flow of edge: Identification of full-field dynamic modes. Mech. Syst. Signal. Process. 2022, 164, 108232. [CrossRef] 38. Bhowmick, S.; Nagarajaiah, S.; Lai, Z. Measurement of full-field displacement time history of a vibrating continuous edge from video. Mech. Syst. Signal. Process. 2020, 144, 106847. [CrossRef] 39. Luan, L.; Zheng, J.; Wang, M.L.; Yang, Y.; Rizzo, P.; Sun, H. Extracting full-field subpixel structural displacements from videos via deep learning. J. Sound. Vib. 2021, 505, 116142. [CrossRef] 40. Cheung, W.; Hamarneh, G. n-SIFT: N-dimensional scale invariant feature transform. Trans. Img. Proc. 2009, 18, 2012\u20132021. [CrossRef] 41. Fischler, M.A.; Bolles, R.C. Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography. Commun. ACM 1981, 24, 381\u2013395. [CrossRef] 42. Rother, C.; Kolmogorov, V.; Blake, A. \u201cGrabCut\u201d: Interactive foreground extraction using iterated graph cuts. In Proceedings of the SIGGRAPH 2004: 31st Annual Conference on Computer Graphics and Interactive Techniques, Los Angeles, CA, USA, 8\u201312 August 2004; pp. 309\u2013314. 43. Vicente, S.; Kolmogorov, V.; Rother, C. Graph cut based image segmentation with connectivity priors. In Proceedings of the 2008 IEEE Conference on Computer Vision and Pattern Recognition, Anchorage, AK, USA, 23\u201328 June 2008; pp. 1\u20138. 44. Stevenson, R. Optimality of a Standard Adaptive Finite Element Method. Found. Comput. Math. 2007, 7, 245\u2013269. [CrossRef]\nDisclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."
        }
    ],
    "title": "Displacement Field Calculation of Large-Scale Structures Using Computer Vision with Physical Constraints: An Experimental Study",
    "year": 2023
}