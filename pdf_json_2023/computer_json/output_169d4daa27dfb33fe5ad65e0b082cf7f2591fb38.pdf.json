{
    "abstractText": "Algebraic effects & handlers have become a standard approach for side-effects in functional programming. Their modular composition with other effects and clean separation of syntax and semantics make them attractive to a wide audience. However, not all effects can be classified as algebraic; some need a more sophisticated handling. In particular, effects that have or create a delimited scope need special care, as their continuation consists of two parts\u2014in and out of the scope\u2014and their modular composition introduces additional complexity. These effects are called scoped and have gained attention by their growing applicability and adoption in popular libraries. While calculi have been designed with algebraic effects & handlers built in to facilitate their use, a calculus that supports scoped effects & handlers in a similar manner does not yet exist. This work fills this gap: we present \u03bbsc , a calculus with native support for both algebraic and scoped effects & handlers. It addresses the need for polymorphic handlers and explicit clauses for forwarding unknown scoped operations to other handlers. Our calculus is based on Eff, an existing calculus for algebraic effects, extended with Koka-style row polymorphism, and consists of a formal grammar, operational semantics, a (type-safe) type-and-effect system and type inference. We demonstrate \u03bbsc on a range of examples.",
    "authors": [
        {
            "affiliations": [],
            "name": "WENHAO TANG"
        }
    ],
    "id": "SP:5f717cbdf44d7c6473f3d030a8d33c4f0e3a64b7",
    "references": [
        {
            "authors": [
                "Andrej Bauer",
                "Matija Pretnar"
            ],
            "title": "An effect system for algebraic effects and handlers",
            "venue": "Algebra and Coalgebra in Computer Science 5th International Conference,",
            "year": 2013
        },
        {
            "authors": [
                "Andrej Bauer",
                "Matija Pretnar"
            ],
            "title": "Programming with algebraic effects and handlers",
            "venue": "Journal of Logical and Algebraic Methods in Programming,",
            "year": 2015
        },
        {
            "authors": [
                "Jonathan Immanuel Brachth\u00e4user",
                "Philipp Schuster",
                "Klaus Ostermann"
            ],
            "title": "Effects as capabilities: Effect handlers and lightweight effect polymorphism",
            "venue": "Proc. ACM Program. Lang.,",
            "year": 2020
        },
        {
            "authors": [
                "Neil Ghani",
                "Tarmo Uustalu"
            ],
            "title": "Explicit substitutions and higher-order syntax",
            "venue": "In Proceedings of the 2003 ACM SIGPLAN Workshop on Mechanized Reasoning about Languages with Variable Binding,",
            "year": 2003
        },
        {
            "authors": [
                "Daniel Hillerstr\u00f6m",
                "Sam Lindley"
            ],
            "title": "Liberating effects with rows and handlers",
            "venue": "In Proceedings of the 1st International Workshop on Type-Driven Development, TyDe 2016,",
            "year": 2016
        },
        {
            "authors": [
                "Alexis King"
            ],
            "title": "eff \u2013 screaming fast extensible effects for less, 2019",
            "year": 2019
        },
        {
            "authors": [
                "Oleg Kiselyov",
                "KC Sivaramakrishnan"
            ],
            "title": "Eff directly in ocaml",
            "venue": "Electronic Proceedings in Theoretical Computer Science,",
            "year": 2018
        },
        {
            "authors": [
                "Oleg Kiselyov",
                "Amr Sabry",
                "Cameron Swords",
                "Ben Foppa"
            ],
            "title": "extensible-effects: An alternative to monad transformers, 2019",
            "year": 2019
        },
        {
            "authors": [
                "Daan Leijen"
            ],
            "title": "Extensible records with scoped labels",
            "venue": "Revised Selected Papers from the Sixth Symposium on Trends in Functional Programming,",
            "year": 2005
        },
        {
            "authors": [
                "Daan Leijen"
            ],
            "title": "Koka: Programming with row polymorphic effect types",
            "venue": "Electronic Proceedings in Theoretical Computer Science, 153,",
            "year": 2014
        },
        {
            "authors": [
                "Daan Leijen"
            ],
            "title": "Type directed compilation of row-typed algebraic effects",
            "venue": "In Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages,",
            "year": 2017
        },
        {
            "authors": [
                "Sam Lindley",
                "Conor McBride",
                "Craig McLaughlin"
            ],
            "title": "Do be do be do",
            "venue": "In Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages,",
            "year": 2017
        },
        {
            "authors": [
                "Paul Blain Levy",
                "John Power",
                "Hayo Thielecke"
            ],
            "title": "Modelling environments in call-by-value programming languages",
            "venue": "Inf. Comput.,",
            "year": 2003
        },
        {
            "authors": [
                "Sandy Maguire"
            ],
            "title": "polysemy: Higher-order, low-boilerplate free monads, 2019",
            "year": 2019
        },
        {
            "authors": [
                "Robin Milner"
            ],
            "title": "A theory of type polymorphism in programming",
            "venue": "J. Comput. Syst. Sci.,",
            "year": 1978
        },
        {
            "authors": [
                "Eugenio Moggi"
            ],
            "title": "An abstract view of programming languages",
            "venue": "Technical Report ECS-LFCS-90113,",
            "year": 1989
        },
        {
            "authors": [
                "Eugenio Moggi"
            ],
            "title": "Notions of computation and monads",
            "venue": "Information and Computation,",
            "year": 1991
        },
        {
            "authors": [
                "Aleksandar Nanevski"
            ],
            "title": "A modal calculus for exception handling",
            "year": 2005
        },
        {
            "authors": [
                "Gordon D. Plotkin",
                "John Power"
            ],
            "title": "Algebraic operations and generic effects",
            "venue": "Appl. Categorical Struct.,",
            "year": 2003
        },
        {
            "authors": [
                "Gordon Plotkin",
                "Matija Pretnar"
            ],
            "title": "Handlers of algebraic effects",
            "venue": "Programming Languages and Systems,",
            "year": 2009
        },
        {
            "authors": [
                "Matija Pretnar"
            ],
            "title": "An introduction to algebraic effects and handlers. invited tutorial paper",
            "venue": "Electronic Notes in Theoretical Computer Science,",
            "year": 2015
        },
        {
            "authors": [
                "Maciej Pir\u00f3g",
                "Sam Staton"
            ],
            "title": "Backtracking with cut via a distributive law and left-zero monoids",
            "venue": "J. Funct. Program.,",
            "year": 2017
        },
        {
            "authors": [
                "Maciej Pir\u00f3g",
                "Tom Schrijvers",
                "Nicolas Wu",
                "Mauro Jaskelioff"
            ],
            "title": "Syntax and semantics for operations with scopes",
            "venue": "In Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science,",
            "year": 2018
        },
        {
            "authors": [
                "Didier R\u00e9my"
            ],
            "title": "Type inference for records in a natural extension of ml. In Theoretical Aspects of Object-Oriented Programming: Types, Semantics, and Language Design",
            "year": 1994
        },
        {
            "authors": [
                "Rob Rix",
                "Patrick Thomson",
                "Nicolas Wu",
                "Tom Schrijvers"
            ],
            "title": "fused-effects: A fast, flexible, fused effect system, 2018",
            "year": 2018
        },
        {
            "authors": [
                "KC Sivaramakrishnan",
                "Stephen Dolan",
                "Leo White",
                "Tom Kelly",
                "Sadiq Jaffer",
                "Anil Madhavapeddy"
            ],
            "title": "Retrofitting effect handlers onto ocaml",
            "venue": "In Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation,",
            "year": 2021
        },
        {
            "authors": [
                "Patrick Thomson",
                "Rob Rix",
                "Nicolas Wu",
                "Tom Schrijvers"
            ],
            "title": "Fusing industry and academia at github (experience report)",
            "venue": "Proc. ACM Program. Lang.,",
            "year": 2022
        },
        {
            "authors": [
                "Philip Wadler"
            ],
            "title": "Monads for functional programming",
            "venue": "Advanced Functional Programming, First International Spring School on Advanced Functional Programming Techniques, B\u030aastad,",
            "year": 1995
        },
        {
            "authors": [
                "Nicolas Wu",
                "Tom Schrijvers",
                "Ralf Hinze"
            ],
            "title": "Effect handlers in scope",
            "venue": "In Proceedings of the 2014 ACM SIGPLAN Symposium on Haskell, Haskell",
            "year": 2014
        },
        {
            "authors": [
                "Zhixuan Yang",
                "Marco Paviotti",
                "Nicolas Wu",
                "Birthe van den Berg",
                "Tom Schrijvers"
            ],
            "title": "Structured handling of scoped effects",
            "venue": "In Ilya Sergey, editor, Programming Languages and Systems 31st European Symposium on Programming,",
            "year": 2022
        },
        {
            "authors": [
                "Jeremy Yallop",
                "Leo White"
            ],
            "title": "Lightweight higher-kinded polymorphism",
            "venue": "Functional and Logic Programming,",
            "year": 2014
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n30 4.\n09 69\n7v 2\n[ cs\n.P L\n] 2\n1. Introduction\nWhile monads [Mog89, Mog91, Wad95] have long been the go-to approach for modelling effects, algebraic effects & handlers [PP03, PP09] are gaining steadily more traction. They offer a more structured and modular approach to composing effects, based on an algebraic model. The approach consists of two parts: effects denote the syntax of operations, and handlers interpret them by means of structural recursion. By composing handlers that each interpret only a part of the syntax in the desired order, one can modularly build an interpretation for the entire program. Algebraic effects & handlers have been adopted in several libraries such as (e.g., fused-effects [RTWS18], extensible-effects [KSSF19], Eff in OCaml [KS18]) and languages (e.g., Links [HL16], Koka [Lei17], Effekt [BSO20]).\nKey words and phrases: algebraic effects, scoped effects, calculus, operational semantics, type- and effect system.\n*These authors contributed equally to this work\nPreprint submitted to Logical Methods in Computer Science\n\u00a9 R. Bosman, B. van den Berg, W. Tang, and T. Schrijvers CC\u00a9 Creative Commons\nAlthough the modular approach of algebraic effects & handlers is desirable for every effectful program, it is not always applicable. In particular, those effects that have or introduce a delimited scope (e.g., exceptions, concurrency, local state) are not algebraic. Essentially, these so-called scoped effects [WSH14] split the program in two: a scoped computation where the effect is in scope, and a continuation where it is out of scope. This separation breaks algebraicity, which states operations commute with sequencing. Modeling scoped effects as handlers [PP03] has been proposed as a way of encoding scoped effects in an algebraic framework. However, this comes at the cost of modularity [YPW+22]. Instead, a calculus that provides scoped effects & handlers as native features is required. The growing interest in scoped effects & handlers, evidenced by their adoption at GitHub [TRWS22] and in Haskell libraries (e.g., eff [Kin19], polysemy [Mag19], fused-effects [RTWS18]), motivates the need for such a calculus. This paper aims to fill this gap in the literature: we present \u03bbsc , a calculus that puts scoped effects & handlers on formal footing. Our main source of inspiration is Eff [BP13, BP15, Pre15], a calculus for algebraic effects & handlers, effectively easing programming with those features. Although Eff is an appropriate starting point, the extension to support scoped effects & handlers is non-trivial, for two reasons. First, scoped effects require polymorphic handlers, which we support by adding let-polymorphism and F\u03c9-style type operators. Second, we need to be able to forward unknown operations in order to keep the desired modularity. Whereas algebraic effects & handlers have a generic (and implicit) forwarding mechanism, scoped effects & handlers need an explicit forwarding clause in order to allow sufficient freedom in their implementation. In what follows, we formalize \u03bbsc, after introducing the appropriate background (Section 2) and informally motivating the challenges and design choices of our calculus (Section 3). We make the following contributions:\n\u2022 We design a formal syntax for \u03bbsc terms, types and contexts (Section 4). \u2022 We provide an operational semantics (Section 5). \u2022 We define the type-and-effect system of \u03bbsc (Section 6). \u2022 We formulate and prove \u03bbsc\u2019s metatheoretical properties (Section 6). \u2022 We show the usability of our calculus on a range of examples (Section 7). \u2022 We give a type inference algorithm and show it sound and complete with respect to the declarative type-and-effect system (Appendix F). \u2022 We provide an interpreter of our calculus with type inference in which we implement all our examples (supplementary material).\n2. Background & Motivation\nThis section provides the necessary background and motivates our goal. We review algebraic effects & handlers as a modular approach to composing side-effects in effectful programs. Next, we present scoped effects & handlers: effects that have or create a delimited scope (such as once for nondeterminism [PSWJ18, WSH14]), and motivate the need for a calculus with built-in support for these scoped effects.\n2.1. Algebraic effects & handlers. Algebraic effects & handlers consist of operations, denoting their syntax, and handlers, denoting their semantics. This separation gives us modular composition, which has intrinsic value and allows controlling effect interaction.\n2.1.1. Algebraic Operations. Effects are denoted by a name (or label) and characterized by a signature A _ B , taking a value of type A and producing a value of type B . For example, choose : () _ Bool takes a unit value and produces a boolean (e.g., nondeterministically). Operations invoke effects, combining the op keyword, an effect to invoke, a parameter passed to the effect, and a continuation, containing the rest of the program.\ncND = op choose () (b . if b then return 1 else return 2)\nIn accordance with its signature, choose is passed (), and in the supplied contination b has type Bool. As a result, cND is a computation that returns either 1 or 2.\nSome operations commute with sequencing. For example:\ndo x \u2190 op choose () (b . if b then return 1 else return 2) ; return x 2\n\u2261 op choose () (b .do x \u2190 if b then return 1 else return 2 ; return x 2)\nThis equivalence is an instance of the algebraicity property, and operations are algebraic if they satisfy this property. Algebraicity states that the sequencing of a computation c2 after an operation op \u2113 v (y . c1) is equivalent to sequencing the same computation after the continuation of this operation:\ndo x \u2190 op \u2113 v (y . c1) ; c2 \u2261 op \u2113 v (y .do x \u2190 c1 ; c2)\n2.1.2. Handlers. Handlers give meaning to operations. For example, handler hND interprets choose nondeterministically:\nhND = handler {return x 7\u2192 return [x ] , op choose k 7\u2192 do xs \u2190 k true ;do ys \u2190 k false ; xs ++ys }\nThis handler has two clauses. The first clause returns a singleton list in case a value x is returned. The second clause, which interprets choose, executes both branches by applying the continuation k to both true and false, and concatenates their resulting lists with the (++)-operator. We apply hND to cND with the \u22c6-operator to obtain both of its results:\nhND \u22c6 cND \u2217 [1, 2]\nAlgebraic effects & handlers bring several interesting advantages. Most interestingly, their separation of syntax and semantics allows a modular composition of different effects, which in turn allows for altering the meaning of a program by different effect interactions.\n2.1.3. Modular Composition. Effects can be composed by combining different primitive operations. For example, computation cc,g below uses get : () _ String in addition to choose.\ncc,g = op choose () (b . if b then return 1 else op get () (x . return x ))\nInstead of having to write a handler for each combinations of effects, algebraic effects & handlers allow us to write a handler specific for the effect get, and to compose it with the existing handler hND.\nhget = handler {return x 7\u2192 return x , op get k 7\u2192 k 2}\nWhen composing handlers hND \u22c6 (hget \u22c6 cc,g), hget is applied first, and handles get. Since hget does not contain a clause for choose, it leaves (we say \u201cforwards\u201d) the choose operation to be handled by another handler. This forwarding behavior is key to the modular reuse and composition of handlers. Handler hND then takes care of the remaining effects.\nhND \u22c6 (hget \u22c6 cc,g) \u2217 hND \u22c6 cND \u2217 [1, 2]\n2.1.4. Effect Interaction. One of the valuable features of the modular composition of algebraic effects & handlers is that effects can interact differently by applying their handlers in a different order. Consider the effect inc : () _ Int, which produces an (incremented) integer. The handler hinc turns computations into state-passing functions.\nhinc = handler {return x 7\u2192 return (\u03bbs . return (x , s)) , op inc k 7\u2192 return (\u03bbs .do s \u2032 \u2190 s + 1 ;do k \u2032 \u2190 k s \u2032 ; k \u2032 s \u2032)}\nThe state s represents the current counter value. On every occurrence of inc, the incremented value is passed to the continuation twice: (1) for updating the counter value and (2) for returning the result of the operation. The latter is for the continuation and the former for serving the next inc operation. We use syntactic sugar to apply the initial counter value to the result of hinc.\nruninc s c \u2261 do c \u2032 \u2190 hinc \u22c6 c ; c \u2032 s\nComputation cinc combines choose and inc:\ncinc = op choose () (b . if b then op inc () (x . x + 5)\nelse op inc () (y . y + 2))\nWhen handling inc first, each choose branch gets the same initial counter value.\nhND \u22c6 runinc 0 cinc \u2217 hND \u22c6 op choose () (b .do p\n\u2032 \u2190 hinc \u22c6 (if b then op inc () (x . x + 5) else op inc () (y . y + 2)) ; p\u2032 0)\n\u2217 return [(6, 1), (3, 1)]\nIn contrast, when handling choose first, the counter value is threaded through the successive branches.\nruninc 0 (hND \u22c6 cinc)\n\u2217 runinc 0 (do xs \u2190 hND \u22c6 op inc () (x . x + 5) do ys \u2190 hND \u22c6 op inc () (y . y + 2))\nreturn xs ++ys)\n\u2217 ([6, 4], 2)\n2.2. Scoped effects. Not all effects are algebraic. For example, some have a delimited scope. Consider the once : () _ () operation, which takes a computation that contains choose calls and returns only its first result [PSWJ18]. Subscripting \u2717 to indicate an erroneous example, we could attempt to syntactically write this as the algebraic operation op once\u2717 () (y . c) and try to limit the first of two choose operations. We extend hND with a clause for once.\nconce\u2717 = do p \u2190 op once\u2717 () ( .op choose () (b . return b)) do q \u2190 op choose () (b . return b)\nreturn (p, q)\nhonce\u2717 = handler { . . . , op once\u2717 k 7\u2192 do ts \u2190 k () ; head ts }\nWe intend for honce\u2717 \u22c6 conce\u2717 to return [(true, true), (true, false)] as the first choose is limited by once\u2717 to only return the first alternative. The second choose is out of scope of once\u2717, so should still return both results. However, algebraicity pulls the the second choose inside the scope of once\u2717:\nhonce\u2717 \u22c6 (do p \u2190 op once\u2717 () ( .op choose () (b . return b)) do q \u2190 op choose () (b . return b)\nreturn (p, q))\nhonce\u2717 \u22c6 op once\u2717 () ( .do p \u2190 op choose () (b . return b)\ndo q \u2190 op choose () (b . return b) return (p, q))\n\u2217 [(true, true)]\nThere are many more examples of operations that have a scope; we present them in Section 7:\n\u2022 catch for catching exceptions that are raised during program execution; \u2022 local for creating local variables (local state); \u2022 call for creating a scope in a nondeterministic program, where branches can be cut using the algebraic cut operation; \u2022 depth for bounding the depth in the depth-bounded search strategy;\nFollowing Wu et al. [WSH14], we call them scoped operations. Plotkin and Power [PP03] have already realised that algebraic effects are unable to represent so-called generic effects (e.g., scoped) and propose to model them as handlers. Although used [TRWS22], their solution it is problematic in terms of modularity [WSH14, YPW+22]: it merges syntax and semantics, as they define some effects as handlers. In Section 7 we revisit this issue, showing attempts at encoding scoped effects as handlers, their problems, and how \u03bbsc remedies the situation. The goal of this work is to implement scoped effects while maintaining a separation between syntax and semantics, and thus preserve modular composition and control over effect interaction. It follows a line of research [PSWJ18, WSH14, YPW+22] that has developed denotational semantic domains, backed by categorical models. What is lacking from the literature is a calculus that allows programming with both algebraic and scoped operations and their handlers.\n3. Design Decisions & Challenges\nThis section informally discusses the design of \u03bbsc , a novel calculus with support for scoped effects & handlers as built-in features. We present our main challenges and design choices.\n3.1. Eff with Koka-based Row Typing. Our calculus is based on Eff [Pre15, BP13, BP15], an existing calculus for algebraic effects & handlers. It supports row-based typing in the style of Koka [Lei17]. Computations have types of shape A ! \u3008E \u3009, where A is the type of the value returned by the computation, and E is a collection effects that can occur during its evaluation. For example, Bool,Bool !\u3008choose, once\u3009 is a type of conce.\nHandlers turn one computation into another. Their type reflects that: handlers of type A ! \u3008E \u3009 \u21d2 B ! \u3008F \u3009 take a computation of type A ! \u3008E \u3009 and return a computation of type B ! \u3008F \u3009. For example, honce handles choose and once.\nhonce : (Bool,Bool) ! \u3008choose, once\u3009 \u21d2 List (Bool,Bool) ! \u3008\u3009\n3.2. Scoped Effects as Built-in Operations. As we argued in Section 2.2, modeling scoped effects like once as handlers comes at the cost of modularity. To retain this modularity, we add scoped effects as built-in operations with a new notation, signalled by the sc keyword.\nsc once () (y . c1) (z . c2)\nSimilar to algebraic operations, scoped operations feature a label once to identify the effect, a parameter\u2014in this case ()\u2014, and a continuation (z . c2). However, scoped operations differ from algebraic operations by their additional scoped computation (y . c1). For once, the scoped computation entails the computation to be restricted to the first result (i.e. the computation in scope). The dataflow allows for a value y to be passed from the operation to c1 and a value z from c1 to c2.\nAdding scoped operations gives rise to a variant of the algebraicity property, which models the desired behavior of sequencing for scoped operations: scoped operations commute with sequencing in the continuation, but leave the scoped computation intact.\ndo x \u2190 sc \u2113sc v (y . c1) (z . c2) ; c3 \u2261 sc \u2113 sc v (y . c1) (z .do x \u2190 c2 ; c3)\nUsing once as a scoped operation correctly restrict only the first choose:\nconce = sc once () ( . op choose () (b . return b)) (p .do q \u2190 op choose () (b . return b) ; return (p, q)) honce = handler { . . . , sc once p k 7\u2192 do ts \u2190 p () ;do t \u2190 head ts ; k t } honce \u22c6 conce \u2217 [(true, true), (true, false)]\nThis novel representation for scoped effects & handlers also brings in additional complexity. Whereas algebraic operations contain a single subcomputation, scoped operations contain two of them: the scoped computation and the continuation. The result of the scoped computation is the argument of the continuation: they must agree on a type of this result, which we name the scoped result type. For example, consider conce, with overall type (Bool,Bool)!\u3008once ; choose\u3009. Its scoped result type is (a singular) Bool: it is the type that is produced by the scoped computation, and consumed by the continuation.\nsc once () ( .op choose () (b . return b) \ufe38 \ufe37\ufe37 \ufe38\n()\u2192 Bool !\u3008once ;choose\u3009\n) (p .do q \u2190 op . . . return (p, q) \ufe38 \ufe37\ufe37 \ufe38\nBool \u2192(Bool,Bool)!\u3008once ;choose\u3009\n)\nDealing with the presence of this scoped computation type is tricky, and introduces two complications. First, since the type does not occur in the computation\u2019s overall type, polymorphic handlers are required to handle scoped effects. Second, the scoped result type describes a dependency between the scoped computation and continuation: if one changes its type, the other must match this. This makes generic forwarding impossible: it alters the type of the scoped computation, but does not make up for it in the continuation.\n3.3. Polymorphic Handlers. Applying a handler to a computation involves recursively applying the handler to the computation\u2019s subcomputations as well. In the case of algebraic effects, these subcomputations always have the same type as the operation itself, as witnessed by the algebraicity property. This means that calculi that only support algebraic effects & handlers, such as Eff, can (and do) type handlers monomorphically, without severe limitations. However, typing scoped effect handlers monomorphically does limit their implementation freedom: it only allows scoped operations of which the scoped result type matches the operation\u2019s overall type. For example, consider the type (Bool,Bool)!\u3008choose ; once\u3009 \u21d2 List (Bool,Bool)!\u3008\u3009 we previously assigned to honce. This monomorphic type requires the scoped result type to be (Bool,Bool) as well, as it is the only type of computation monomorphic honce can handle. This is not the case for conce: as established, its scoped result type is Bool (see above). Therefore, scoped computations such as conce, cannot be handled by monomorphic handlers. The solution is to let handlers abstract over the value type of computations, allowing for the handling of scoped operations with any scoped result type. This way, honce can be typed as follows:\nhonce : \u2200 \u03b1 .\u03b1 !\u3008choose ; once\u3009 \u21d2 List \u03b1 !\u3008\u3009\nWith this polymorphic typing in place, honce \u22c6 conce can now be evaluated by polymorphic recursion. To support this, \u03bbsc features let-polymorphism, F\u03c9-style type operators, and requires all handlers for scoped effects to be polymorphic.\n3.4. Forwarding Unknown Operations. In order to retain the modularity of composing different effects, as discussed in Section 2.1.3, we write dedicated handlers that interpret only their part of the syntax, and forward all remaining operations to other handlers. For algebraic effects forwarding happens generically. For example, consider the forwarding of honce applied to an algebraic operation with inc.\nhonce \u22c6 op inc () (y . return y) op inc () (y . honce \u22c6 return y)\nOne might hope to forward scoped effects in a similar way. For example, consider applying honce to scoped operation catch : String _ Bool for catching exceptions.\nccatch = sc catch \"err\" (b . if b then return 1 else return 2) (x . return x )\nhonce \u22c6 ccatch \u2717 sc catch \"err\" (b . honce \u22c6 if b then return 1 . . .) (x . honce \u22c6 return x )\nUnfortunately, this does not work. Again, the hurdle is in the scoped result type. In particular, honce introduces a type operator List when handling a computation. The scoped computation now has type Bool \u2192 List Int !\u3008catch\u3009, whereas the continuation has type Int\u2192 List Int !\u3008catch\u3009.\nsc catch \"err\" (b . honce \u22c6 if b then return 1 else . . .\ufe38 \ufe37\ufe37 \ufe38 Bool\u2192 List Int ! \u3008catch\u3009 ) (x . honce \u22c6 return x\ufe38 \ufe37\ufe37 \ufe38 Int \u2192List Int ! \u3008catch\u3009 )\nIndeed, applying a handler to a computation changes its type: not only does it remove labels from the effect row, it also may apply a type operator \u2014in this case List\u2014to the type. For scoped operations this is problematic, as the return type of the scoped computation has changed (List Int), whereas the continuation still expects the original type (Int). Thus, scoped effects cannot be forwarded generically. Therefore, we require that every handler\nis equipped with an explicit forwarding clause for unknown scoped operations. When a handler is defined it is clear what type operator the handler applies. With this information it is possible to define a way of bridging the type discrepancy. For example, honce mitigates the discrepancy between List Int and Int by settling the scoped result type on List Int: in the forwarding clause of honce, concatMap ensures that the transformed continuation now takes a value of type List Int as argument.\nhonce = handler { . . . , fwd f p k 7\u2192 f (p, (\u03bbz . concatMap z k))}\nWe implement forwarding by means of a function f , which is a partial application of sc \u2113 v : it takes the pair of a (possibly transformed) scoped computation p\u2032 and continuation k \u2032 and re-introduces the to-be-forwarded scoped operation with these parameters.\nf = \u03bb(p\u2032, k \u2032) . sc \u2113 v (y . p\u2032 y) (z . k \u2032 z )\nThe concatMap is standardly defined as follows.\nconcatMap : \u2200 \u03b1 \u03b2 \u00b5 . List \u03b2 \u2192\u00b5 (\u03b2 \u2192\u00b5 List \u03b1)\u2192\u00b5 List \u03b1\nconcatMap [ ] f = return [ ] concatMap (b : bs) f = do as \u2190 f b ; as \u2032 \u2190 concatMap bs f ; as ++as \u2032\nIn what follows, we put our calculus on formal footing, discussing its syntax, operational semantics and type-and-effect system.\n4. Syntax\nAs stated, \u03bbsc is based on Eff [BP13, BP15]. Before adding support for scoped effects, we have altered Eff from its presentation in [BP13, BP15] in two ways. Firstly, we have made a number of cosmetic changes that arguably improve the readability of the calculus. Secondly, we adopt row-based typing in the style of Koka [Lei17]. Figure 1 displays the syntax of \u03bbsc . The extensions to (our version of) Eff made to support scoped effects are highlighted throughout our presentation of \u03bbsc . The extensions can be summarized by two new handler clauses, a new operation call and the inclusion of let-polymorphism in the terms, and type variables in the types.\n4.1. Terms. Like Eff we implement fine-grained call-by-value semantics [LPT03]. Therefore, terms are split into inert values and computations that can be reduced.\nComputations. For computations, return can be used to return values. Handlers can be applied to values by usage of the \u22c6-operator. As seen before, computations may be sequenced by means of do-statements (do x \u2190 c1 ; c2). Applications reduce, so are computations. As discussed in Section 3.3, to support polymorphic handlers we support let-polymorphism and thus let-bindings. Finally, a computation may be the invocation of an effect by means of an operation.\nTo be able to differentiate between algebraic and scoped effects, we add the effect keyword sc to model scoped effects. Consequently, op now ranges over algebraic effects only. Furthermore, we annotate labels with either op or sc to indicate if they are the label of an algebraic or scoped effect, respectively. We implicitly assume any label \u2113 occurs either as an algebraic or scoped effect label. Like their algebraic counterparts, scoped effect operations feature a label \u2113op or \u2113sc, argument v and continuation (y . c) or (z . c2). In addition, scoped\neffect operations feature a scoped computation (y . c1). This way, the scope of effect \u2113 sc is delimited: (scoped) computation (y . c1) is in scope, continuation (z . c2) is not.\nValues. Values consist of the unit value (), value pairs (v1, v2), variables x , functions \u03bbx . c and handlers h. Handlers h have three kinds of clauses: one return clause, zero or more operation clauses, and a forwarding clause.\nThe return clause return x 7\u2192 c denotes that the result x of a computation is processed by computation c.\nAlgebraic operation clauses op \u2113op x k 7\u2192 c specify that handling an effect with label \u2113op, parameter x and continuation k is processed by computation c (e.g., hND, hget, hinc). In this rule, k is an object-level variable just like x . For scoped effect clauses the extension is analogous to the operation case: we take the algebraic clause and add support for a scoped computation, which in the case for the clause has the form of parameter p.\nFinally, as motivated in Section 3.4, we have forwarding clauses of shape fwd f p k 7\u2192 cf , that deal with forwarding unknown scoped operation with some label \u2113\nsc. Computations cf have access to the scoped computation p and continuation k of the unknown effect they are forwarding. Furthermore, cf should be able to call \u2113\nsc. Instead of bringing \u2113sc into scope, we pass it f which in turn invokes \u2113sc. This achieves a simpler type system at no cost to the expressivity of forwarding clauses.\n4.2. Types. Like terms, types are split: values have value types A,B , computations have computation types C,D. Value types consist of the unit type (), pair types (A,B), function types A\u2192 C, handler types C \u21d2 D, type variables \u03b1 and abstraction over them \u03bb\u03b1 .A, and type application M A. Following convention and to allow for meaningful examples, we may add base value types to the calculus, such as String, Int and Bool. Functions take a value of type A as argument and return a computation of type C; handlers take a computation of type C as argument and return a computation of type D.\nA computation type A !\u3008E \u3009 consists of a value type A, representing the type of the value the computation evaluates to, and an effect type E , representing the effects that may be called during this evaluation. Different from Eff, we implement effect types as effect rows using row polymorphism [Lei05] in the style of Koka [Lei17]. Therefore, rows E are represented as collections of the previously discussed atomic labels \u2113op, optionally terminated by a row variable \u00b5. Finally, we can abstract over both type and row variables, giving rise to type schemes \u03c3.\n5. Operational Semantics\nFigure 2 displays the small-step operational semantics of \u03bbsc . Here, relation c c \u2032 denotes that computation c steps to computation c\u2032, with \u2217 its reflexive, transitive closure. The highlighted rules deal with the extensions that support scoped effects. The following discussion of the semantics is exemplified by snippets of derivations of computations1used in Section 2. We refer to Appendix A for the full version of these derivations.\nRules E-AppAbs and E-Let deal with function application and let-binding, respectively, and are standard. The rest of the rules consist of two parts: sequencing and handling.\nSequencing. For sequencing computations do x \u2190 c1 ; c2, we distinguish between the situation where c1 can take a step (E-Do), and where c1 is in normal form (return, op, or sc). First, if c1 returns a value v , we substitute v for x in c2 (E-DoRet). Second, if c1 is an algebraic operation, we rewrite the computation using the algebraicity property (E-DoOp), bubbling up the algebraic operation to the front of the computation. Third, the new case, where c1 is a scoped operation, is analogous: the generalization of the algebraicity property (Section 3.2) is used to rewrite the computation (E-DoSc).\nHandling. For handling computations with a handler of the form h \u22c6 c, we distinguish six situations. First, if possible, c takes a step (E-Hand); in the other cases, c is in normal form. If c returns a value v , we use the handler\u2019s return clause return x 7\u2192 cr , switching evaluation to cr with x replaced by v (E-HandRet).\nIf computation c is an algebraic operation op \u2113op v (y . c1), its label is looked up in the handler h. If the handler contains an algebraic clause with this label, evaluation switches to the clause\u2019s computation c (E-HandOp), with v substituted for parameter x and continuation k replaced by a function that, given the original argument y , contains the already-handled continuation. For example, hND \u22c6 cND (p. 3) reduces as follows.\nhND \u22c6 cND do xs \u2190 (\u03bbb . hND \u22c6 if b then return 1 else return 2) true do ys \u2190 (\u03bbb . hND \u22c6 if b then return 1 else return 2) false\n1Following convention, these examples may contain elements not present in our calculus, such as integers and if-then-else statements. These may be viewed as syntactic sugar for their Church encodings.\nc c\u2032 Computation reduction\n(\u03bbx . c) v c [v / x ] E-AppAbs\nlet x = v in c c [v / x ] E-Let\nc1 c \u2032 1\ndo x \u2190 c1 ; c2 do x \u2190 c \u2032 1 ; c2 E-Do do x \u2190 return v ; c2 c2 [v / x ] E-DoRet\ndo x \u2190 op \u2113op v (y . c1) ; c2 op \u2113 op v (y .do x \u2190 c1 ; c2)\nE-DoOp\nxs ++ys\n\u2217 return [1, 2]\nIn case h does not contain a clause for label \u2113op, the effect is forwarded (E-FwdOp). Algebraic effects can be forwarded generically: we re-invoke the operation and recursively apply the handler to continuation c1. For example, during the application of runinc in hND \u22c6 runinc 0 cinc (p. 4), choose is forwarded:\nhND \u22c6 runinc 0 cinc hND \u22c6 do p\n\u2032 \u2190 op choose () (b . hinc \u22c6 if b then op inc () (x . x + 5) else op inc () (y . y + 2)) ; p\u2032 0\n\u2217 return [(6, 1), (3, 1)]\nIf computation c is a scoped operation sc \u2113sc v (y . c1) (z . c2), we again distinguish two situations: the case where h contains a clause for \u2113sc, and where it does not. If h contains a clause for label \u2113sc, evaluation switches to the clause\u2019s computation c (E-HandSc), with v substituted for parameter x . Both the scoped computation and the continuation are\nreplaced by a function that contains the already-handled computations c1 and c2. For example, this happens for the scoped operation once in honce \u22c6 conce (p. 6).\nhonce \u22c6 conce do ts \u2190 (\u03bb . honce \u22c6 op choose (b . return b)) () do t \u2190 head ts (\u03bbp . honce \u22c6 (do q \u2190 op choose (b . return b) ; return (p, q))) t\n\u2217 return [(true, true), (true, false)]\nWhen h does not contain a clause for label \u2113sc, we must forward the effect. As we argued in Section 3.4, forwarding scoped effects cannot happen generically, but rather proceeds via the handler\u2019s forwarding clause fwd f p k 7\u2192 cf . From there, evaluation switches to computation cf , in which the usages of scoped computation p and continuation k are replaced by their already-handled equivalents. Computation cf may reinvoke the unkown scoped operation \u2113sc by means of the parameter f which, when called with a scoped computation p\u2032 and continuation k \u2032 invokes the unkown scoped operation using the passed computations sc \u2113sc v (y . p\u2032 y) (z . k \u2032 z ). For a computation, consider again the example described in Section 3.4. Even though we have not given any semantics to catch yet (we will do so in Section 7.1), we know honce does not contain a clause for catch. As described, catch must be forwarded, addressing the type mismatch between the handled scoped computation and handled continuation with concatMap.\nhonce \u22c6 ccatch (\u03bb(p\u2032, k \u2032) . sc catch \"err\" (b . p\u2032 b) (x . k \u2032 x ))\n((\u03bbb . honce \u22c6 if b then return 1 else return 2) , (\u03bbz . concatMap z (\u03bbx . honce \u22c6 return x )))\nsc catch \"err\" (b . (\u03bbb . honce \u22c6 if b then return 1 else return 2) b)\n(x . (\u03bbz . concatMap z (\u03bbx . honce \u22c6 return x )) x )\n6. Type-and-Effect System\nThis section presents the type-and-effect system of \u03bbsc . As before, we distinguish between values, computations and handlers.\n6.1. Value typing. Figure 3 displays the typing rules for values. Rules T-Var, T-Unit, T-Pair and T-Abs type variables, units, pairs and term abstractions, respectively, and are standard. Rule T-EqV expresses that typing holds up to equivalence of types. The full type equivalence relation (A \u2261 B), which also uses the equivalence of rows (E \u2261\u3008\u3009 F ), is included in Appendix B. However, these relations can be described as the congruence closure of the following two rules.\n(\u03bb \u03b1 .A) B \u2261 A [B / \u03b1 ] Q-AppAbs\n\u21131 6= \u21132\n\u21131 ; \u21132 ;E \u2261\u3008\u3009 \u21132 ; \u21131 ;E R-Swap\nRuleQ-AppAbs captures type application, following F\u03c9, and R-Swap captures the insignificance of the order in effect rows, following Koka\u2019s row typing approach.\n\u0393 \u22a2 v : \u03c3 Value Typing\n(x : \u03c3) \u2208 \u0393\n\u0393 \u22a2 x : \u03c3 T-Var\n\u0393 \u22a2 () : () T-Unit\n\u0393 \u22a2 v1 :A \u0393 \u22a2 v2 : B\n\u0393 \u22a2 (v1, v2) : (A,B) T-Pair\n\u0393 \u22a2 c : C Computation Typing\n\u0393 \u22a2 v1 : A\u2192 C \u0393 \u22a2 v2 : A\n\u0393 \u22a2 v1 v2 : C T-App\n\u0393 \u22a2 c1 :A !\u3008E \u3009 \u0393, x :A \u22a2 c2 : B !\u3008E \u3009\n\u0393 \u22a2 do x \u2190 c1 ; c2 : B !\u3008E \u3009 T-Do\nThe final four value typing rules deal with generalization and instantiation of type variables and row variables. Rule T-Inst instantiates the type variables \u03b1 in a type scheme with a value type A. Rule T-Gen is its dual, abstracting over a type variable. The rules for row variables are similar: T-InstEff instantiates row variable with an effect row E ; T-GenEff abstracts over a row variable. The definition of well-scopedness for types \u0393 \u22a2 \u03c3 and effect rows \u0393 \u22a2 E is straightforward (Appendix C).\n6.2. Computation typing. Figure 4 shows the rules for computation typing. Rules TApp and T-Do capture application and sequencing, and are standard. Like value typing,\ntyping of computations holds up to equivalence of types (T-EqC). Rule T-Let is part of our extension of Eff, as scoped effects require introducing let-polymorphism.\nRule T-Ret assigns a computation type to a return statement. This type consists of the value v in the return, together with a effect row E . Notice that, as in Koka, this row can be freely chosen.\nRule T-Hand types handler application. The typing rules for handlers and their clauses are discussed in Section 6.3. A handler of type C \u21d2 D denotes a handler that transforms computations of type C to a computation of type D .\nRule T-Op types algebraic effects. Looking up label \u2113op in \u03a3 yields a signature Aop _ Bop, where Aop is the type of the operation\u2019s parameter v , and Bop is the type of argument y of the continuation. The resulting effect row includes \u2113op. Indeed, \u2113 \u2208 E means that there is some E \u2032 such that E \u2261\u3008\u3009 \u2113 ;E\n\u2032. Finally, the operation\u2019s type equals that of continuation c. Similarly, rule T-Sc types scoped effects. Again, looking up label \u2113sc in \u03a3 yields signature Asc _ Bsc where Asc corresponds to the type of the operation\u2019s parameter v . However, where Bop in the algebraic case refers to the continuation\u2019s argument, Bsc now describes the scoped computation\u2019s argument. This leaves the the scoped result type undescribed by the signature, but as discussed in Section 3.3, this freedom is exactly what we want. As for the effect rows, T-Sc requires the rows of the scoped computation to match.\n6.3. Handler typing. The typing rules for handlers and handler clauses are shown in Figure 5. It consists of four judgments. Judgment \u0393 \u22a2 return x 7\u2192 cr : M A !\u3008E \u3009 types return clauses, \u0393 \u22a2 oprs : M A !\u3008E \u3009 types operation clauses, and \u0393 \u22a2 fwd f p k 7\u2192 c : M A !\u3008E \u3009 types forwarding clauses. Finally, \u0393 \u22a2 h : \u2200 a . \u03b1 !\u3008F \u3009 \u21d2 M \u03b1 !\u3008E \u3009 types handlers, using the first three judgments.\nReturn Clauses. Rule T-Return types return clauses of the form return x 7\u2192 cr . It binds variable x to type A, adds it to the context, and returns the type M A !\u3008E \u3009 of cr as the type of the return clause.\nOperation Clauses. The judgment \u0393 \u22a2 oprs :M A !\u3008E \u3009 denotes that all operations in the sequence of operations oprs have type M A !\u3008E \u3009. The base case T-Empty types the empty sequence. The other two cases require the head of the sequence (either op or sc) to have the same type as the tail.\nRule T-OprOp types algebraic operation clauses op \u2113op x k 7\u2192 c. Looking up label \u2113op in \u03a3 yields signature Aop _ Bop, where Aop describes the type of parameter x , and Bop the type of the argument of continuation k . In order for an operation op to have type M A !\u3008E \u3009, c should have the same type. Once again, the case for typing a scoped clause sc \u2113sc x p k 7\u2192 c (T-OprSc) is similar to its algebraic equivalent, extended to include the scoped computation. Notice the type of p and k when typing c. First, as \u03bbsc allows freedom in the scoped result type, the type variable \u03b2 is used for this type. Second, as shown in the operational semantics (rule E-HandSc), for a clause sc \u2113sc x p k 7\u2192 c, computation c uses the already-handled subcomputations p and k . Therefore, type operator M occurs in the scoped result type as well as in the continuation\u2019s result type:\np : Bsc \u2192 M \u03b2 !\u3008E \u3009 k : \u03b2 \u2192 M A !\u3008E \u3009\nThis means that, even though our focus on mitigating the type mismatch between scoped computation and continuation so far has been on forwarding unknown scoped effects, the same applies when handling known scoped effects, where computation c accounts for this discrepancy.\nForwarding Clause. Rule T-Fwd types forwarding clauses of the form fwd f p k 7\u2192 cf . As the forwarding clause needs to be able to forward any scoped effect in E , it cannot make any assumptions about the specific operation \u2113sc : Asc _ Bsc to expect. Instead, it abstracts over the operation and treats all possibilities uniformly. This abstraction comes in two parts. Firstly, the function f abstracts over the possible scoped operation calls sc \u2113sc v . Secondly, the type variable \u03b1 abstracts over the possible argument types Bsc of the scoped computation, and type variable \u03b2 over the scoped result type.\np : \u03b1\u2192 M \u03b2 !\u3008E \u3009 k : \u03b2 \u2192 M A !\u3008E \u3009\nNotice the difference between the type of p and k and the arguments of function f : it expects as argument (p\u2032, k \u2032) a transformed version of the scoped computation and continuation so that they agree on the intermediate type. An intuitive solution would be to transform the scoped computation and continuation as follows to agree on type M \u03b2.\np\u2032 : \u03b1\u2192 M \u03b2 !\u3008E \u3009 k \u2032 :M \u03b2 \u2192 M A !\u3008E \u3009\nHowever, in some situation we require a more general type \u03b3. For example, when our type constructor M deals with a state, we require uncurrying of the result type to apply k (e.g., hinc, hstate, hdepth). A similar reasoning goes for the result type of k\n\u2032 and f . Consequently, the type of p\u2032 and k \u2032 are as follows:\np\u2032 : \u03b1\u2192 \u03b3 !\u3008E \u3009 k \u2032 : \u03b3 \u2192 \u03b4 !\u3008E \u3009\nTransforming the original scoped computation and continuation to agree on this type is the exact purpose of our explicit forwarding clauses.\nHandler. Rule T-Handler types handlers with a polymorphic type of the form \u2200 \u03b1 .\u03b1 ! \u3008F \u3009 \u21d2 M \u03b1 ! \u3008E \u3009. A handler consists of a return-clause (T-Return), zero or more operation clauses (T-Empty, T-OprOp and T-OprSc), and a forwarding clause (T-Fwd). All clauses should agree on their result type M \u03b1 ! \u3008E \u3009. Notice that E denotes a collection with at least the labels of the present algebraic and scoped operation clauses in the handler (computed by the labels-function).\n6.4. Syntax-directed version of \u03bbsc. Appendix D contains a syntax-directed version of \u03bbsc , which we prove type safe, and serves as the specification of our type inference algorithm. The syntax-directed version was obtained by the following three transformations. First we removed rule T-EqV, which re-types expressions to some equivalent type. This rule is used to make types line up exactly at the site of applications, for example by changing the order of the labels in effect rows. As a consequence, in the syntax directe version we essentially inline T-EqV wherever it is needed. Secondly, we removed the rules dealing with generalisation and instantiation (T-Inst, T-InstEff, T-Gen and T-GenEff). Instead, whenever rules insist on some kind of polymorphism on some subderivation, we extend the environment with fresh type variables, and generlize over them locally, instead of via axillary rules. Finally, as dealing with higher-kinded polymorphism is orthogonal to our work (and real programming languages like Haskell and OCaml already have their solutions for higherkinded polymorphism [YW14]), we avoid higher-order unification by annotating handlers with the type operator they apply (e.g. handlerM {. . .} instead of handler {. . .}, avoiding higher-order unification, which is undecidable).\n6.5. Metatheory. The type-and-effect system of \u03bbsc is type safe. In this section we briefly state the theorems to show this; the proofs and used lemmas can be found in Appendix E. We prove type safety by proving Subject Reduction and Progress. As values are inert , these theorems range over computations only. The formulation of Subject Reduction is standard:\nTheorem 6.1 (Subject Reduction). If \u0393 \u22a2 c : C and c c\u2032, then there exists a C \u2032 such that C \u2261 C \u2032 and \u0393 \u22a2 c\u2032 : C \u2032.\nApart from an additional normal form sc \u2113sc v (y . c1) (z . c2), progress is standard as well:\nTheorem 6.2 (Progress). If \u00b7 \u22a2 c : C, then either: \u2022 there exists a computation c\u2032 such that c c\u2032, or\n\u2022 c is in a normal form, which means it is in one of the following forms: (1) c = return v, (2) c = op \u2113op v (y . c\u2032), or (3) c = sc \u2113sc v (y . c1) (z . c2).\n6.6. Type Inference. Appendix F contains an inference algorithm for \u03bbsc, based on the approach of Hindley-Milner [Mil78] and Koka [Lei14]. Here, we extend the various typing judgments with a derived substitution \u03b8. For rules with multiple recursive clauses, unifications made during later branches of the inference algorithm are reflected in the result of earlier branches by applying the resulting substitutions to any type derived before. We prove it sound and complete w.r.t. the syntax-directed version as described in Section 6.4.\n7. Examples\nNow that we have formalized the calculus we can cover some examples. This serves two purposes. First, we will highlight how scoped effects as handlers, the solution proposed by Plotkin and Power [PP03] is problematic, even though it is applied in the real world [TRWS22]. We have postponed doing so, because now that we have formally introduced a calculus, we can immediately show how \u03bbsc addresses these issues. The first two examples in this section (exceptions with catch and reader with local) therefore contain both an attempt at encoding them as an handler, as well as a proper encoding as a sc in \u03bbsc. Secondly, the examples exemplify the expressivity of \u03bbsc.\nTo enhance readability, we write the examples in a higher-level syntax following Eff\u2019s conventions: we use top-level definitions, coalesce values and computations, implicitly sequence steps and insert return where needed. Furthermore, we drop trivial return continuations of operations:\nop \u2113op x \u2261 op \u2113op x (y . return y) sc \u2113sc x (y . c1) \u2261 sc \u2113 sc x (y . c1) (z . return z )\n7.1. Exceptions. Wu et al. [WSH14] have shown how to catch exceptions with a scoped operation. Raising an exception is an algebraic operation raise : String _ Empty, and catching an exception is a scoped operation catch : String _ Bool. For example, consider that we are dealing with a counter with a maximum value of 10. The following computation increases the counter by 1 and raises an exception when the counter exceeds 10:\nincr = do x \u2190 op inc () ; if x > 10 then op raise \"Overflow\" (y . absurd y) else return x\nClearly, if we start with a state of 8 and call inc thrice, we end up with an exception. We want to define a catch operation that executes an alternative computation should an exception be thrown.\n7.1.1. Catch as handler. One might attempt to write catch as a handler. However, as we will see, this method does not have the same modularity and expressivity as our calculus because it cannot achieve the local update semantics [WSH14].\nhexcept\u2717 = handler {return x 7\u2192 right x ,op raise e 7\u2192 left e } catch\u2717 c1 c2 \u2261 handler {return x 7\u2192 return x , op raise 7\u2192 c2 } \u22c6 c1 ccatch\u2717 = do incr ; catch\u2717 (do incr ;do incr ; return \"success\")\n(return \"fail\")\nBy handling exceptions before state we obtain global update semantics:\n(runinc 8 (hexcept\u2717 \u22c6 ccatch\u2717) \u2217 (right \"fail\", 11)\nHowever, when handling exceptions after state, we would expect local update semantics, i.e. right (\"fail\", 9). However, we again get the global update semantics:\nhexcept\u2717 \u22c6 (runinc 8 ccatch\u2717) \u2217 (right \"fail\", 11)\nHow can this be? By implementing catch\u2717 as a handler, we have lost the separation between syntax and semantics: catch\u2717 is supposed to denote syntax, but it contains semantics in the form of a handler. Since we apply catch\u2717 to a computation (ccatch\u2717), any containing raise will have already been handled by catch\u2717 before hinc is applied. In other words, we have lost modular composition, and therefore control over the interactions of effects.\n7.1.2. Catch as scoped effect. Let us define ccatch that defines catch as an sc:\nccatch = do incr ; sc catch \"Overflow\" (b .\nif b then (do incr ;do incr ; return \"success\") else return \"fail\")\nThe scoped computation\u2019s true branch is the program that may raise exceptions, while the false branch deals with the exception. Our handler interprets exceptions in terms of a sum type data \u03b1+ \u03b2 = left \u03b1 | right \u03b2, where left v denotes an exception and right v a result.\nhexcept : \u2200 \u03b1 \u00b5 .\u03b1 ! \u3008raise ; catch ;\u00b5\u3009 \u21d2 String+ \u03b1 !\u3008\u00b5\u3009 hexcept = handler\n{return x 7\u2192 right x , op raise e 7\u2192 left e , sc catch e p k 7\u2192 do x \u2190 p true ;\ncase x of left e \u2032 | e \u2032 = e \u2192 exceptMap (p false) k \u2192 exceptMap x k\n, fwd f p k 7\u2192 f (p,\u03bbz . exceptMap z k)}\nThe return clause and algebraic operation clause for raise construct a return value and raise an exception e by calling the right and left constructors, respectively. The scoped operation clause for catch catches an exception e. If the scoped computation in p true raises an exception e, it is caught by catch and replaced by the scoped computation (p false). Otherwise, it continues with p true and its results are passed to the continuation k . For forwarding we essentially return the exception if z fails (left e), and we apply the continuation k to z if z succeeds (right x ).\nexceptMap : \u2200 \u03b1 \u03b2 \u00b5 .String+ \u03b2 \u2192\u00b5 (\u03b2 \u2192\u00b5 String+ \u03b1)\u2192\u00b5 String+ \u03b1 exceptMap z k = case z of left e \u2192 left e\nright x \u2192 k x\nGiven an intial counter value 8, we can handle the program ccatch with hexcept and hinc. Different orders of the application of handlers give us different semantics of the interaction of effects [WSH14]. Handling exceptions before increments yields us global updates:\nruninc 8 (hexcept \u22c6 ccatch) \u2217 (right \"fail\", 11)\nAlthough an exception is raised and caught, the final value is still updated to 11 by the two inc operations and exceeds the maximum value of our counter. When handling exceptions after increments, we obtain the local update semantics:\nhexcept \u22c6 (runinc 9 ccatch) \u2217 right (\"fail\", 9)\n7.2. Reader with Local. Reader entails an ask operation that lets one read the (integer) state that is passed around. The scoped effect local takes a function f which alters the state, and a computation for which the state should be altered, after which the state should be returned to its original state. 2 For example, in sc local (\u03bbi . i \u22172) (op ask ()) (op ask ()), the first ask receives a state that is doubled, whereas the second ask receives the original state. To exemplify the problems that arise when implementing local as a handler, our example uses effect foo, which is simply mapped to ask by hfoo:\nhfoo = handler {return x 7\u2192 return x ,op foo k 7\u2192 do x \u2190 op ask () (y . k y)}\n7.2.1. Local as a handler. Whereas the lack of effect interaction control in example of catch as a handler could be described as unfortunate, in the case for ask there is arguably only one correct interaction, which is not the one that arises from scoped effects as handlers. Consider clocal below, which includes foo, which is mapped to ask by hfoo.\nlocal\u2717 f c \u2261 handler {return x 7\u2192 return x , op ask 7\u2192 x \u2190 ask ; return f x } \u22c6 c\nhread\u2717 = handler {return x 7\u2192 \u03bbm . (x ,m),op ask k 7\u2192 \u03bbm . k m m } runread\u2717 s c \u2261 do c \u2032 \u2190 hread\u2717 \u22c6 c ; c \u2032 s clocal\u2717 = do x \u2190 op ask () ;do y \u2190 op foo () local\u2717 (\u03bba \u2192 2 \u2217 a) (z \u2190 op ask () ; u \u2190 op foo () ; return (x , y , z , u))\nSince hfoo introduces ask, we must (re)apply hread after applying hfoo. Since foo is mapped to ask, in clocal\u2717 we expect x to be equal to y , and z equal to u. Starting with the reader state set to 1, we expect the result ((1, 1, 2, 2), 1). Instead, we get:\nrunread 1 \u22c6 (hfoo \u22c6 clocal\u2717) \u2217 ((1, 1, 2, 1), 1) .\n2The operation signature of local requires polymorphic parameter types like local : (\u2200 \u00b5 . Int \u2192\u00b5 Int) _ (), which we do not support. It is easy to extend operations in \u03bbsc with prenex polymorphic parameter types without any need of other mechanism for higher-rank polymorphism.\nAgain, how can this be? The cause is the same as the example with catch: since we encode the semantics of local\u2717 in its definition, we are forced to perform the handling at the moment of application. Notice that foo is not caught by local\u2717! Therefore, f is only applied to the ask. When foo is mapped to ask by hfoo, local\u2717\u2019s effect will already have triggered, which is why f is not applied to it.\n7.2.2. Local as scoped effect. Using a scoped effect we can properly encode local:\nhread : \u2200 \u03b1 \u00b5 .\u03b1 ! \u3008ask ; local ;\u00b5\u3009 \u21d2 (Int\u2192 \u00b5 (\u03b1, Int))!\u3008\u00b5\u3009 hread = handler {return x 7\u2192 \u03bbm . (x ,m) , op ask k 7\u2192 \u03bbm . k m m\n, sc local f p k 7\u2192 \u03bbm .do (x , )\u2190 p () (f m) ; k x m , fwd f p k 7\u2192 \u03bbm . f (\u03bby . p y m,\u03bb(z ,m \u2032) . k z m \u2032)}\nrunread s c \u2261 do c \u2032 \u2190 hread \u22c6 c ; c \u2032 s clocal = do x \u2190 op ask () ;do y \u2190 op foo () ; sc local (\u03bba \u2192 2 \u2217 a)\n(do z \u2190 op ask () ;do u \u2190 op foo () ; return (x , y , z , u))\nNote that the forwarding clause of hstate is the same as the forwarding clause of hinc in Section 5. Since local is now purely syntax, we can apply hfoo before hread, and have hread handle the ask that hfoo outputs:\nrunread 1 (hfoo \u22c6 clocal) runread 1 (x \u2190 op ask () ; y \u2190 op ask () ; sc local (\u03bba \u2192 2 \u2217 a)\n(do z \u2190 op ask () ;do u \u2190 op foo () ; return (x , y , z , u))\n7.3. Nondeterminism with Cut. The algebraic operation cut : () _ () provides a different flavor of pruning nondeterminism that has its origin as a Prolog primitive. The idea is that cut prunes all remaining branches and only allows the current branch to continue. Typically, we want to keep the effect of cut local. This is achieved with the scoped operation call : () _ (), as proposed by Wu et al. [WSH14]. To handle cut and call, we use the CutList datatype [PS17].\ndata CutList \u03b1 = opened (List \u03b1) | closed (List \u03b1)\nWe can think of opened v as a list that may be extended and closed v as a list that may not be extended with further elements. This intention is captured in the appendCutList function, which discards the second list if the constructor of the first list is closed.\nappendCutList : \u2200 \u03b1 \u00b5 .CutList \u03b1\u2192 \u00b5 CutList \u03b1\u2192\u00b5 CutList \u03b1 appendCutList (opened xs) (opened ys) = opened (xs ++ys) appendCutList (opened xs) (closed ys) = closed (xs ++ys) appendCutList (closed xs) = closed xs\nThe handler for nondeterminism with cut is defined as follows:\nhcut : \u2200 \u03b1 \u00b5 .\u03b1 ! \u3008choose ; fail ; cut ; call ;\u00b5\u3009 \u21d2 CutList \u03b1 !\u3008\u00b5\u3009 hcut = handler {return x 7\u2192 opened [x ]\n, op fail 7\u2192 opened [ ] , op choose x k 7\u2192 appendCutList (k true) (k false) , op cut k 7\u2192 close (k ())\n, sc call p k 7\u2192 concatMapCutList (open (p ())) k , fwd f p k 7\u2192 f (p,\u03bbz . concatMapCutList z k)}\nThe operation clause for cut closes the cutlist and the clause for call (re-)opens it when coming out of the scope.\nclose : \u2200 \u03b1 \u00b5 .CutList \u03b1\u2192\u00b5 CutList \u03b1 close (closed as) = closed as\nclose (opened as) = closed as\nopen : \u2200 \u03b1 \u00b5 .CutList \u03b1\u2192\u00b5 CutList \u03b1 open (closed as) = opened as\nopen (opened as) = opened as\nThe function concatMapCutList is the cutlist counterpart of concatMap which takes the extensibility of CutList (signalled by opened and closed) into account when concatenating.\nconcatMapCutList : \u2200 \u03b1 \u03b2 \u00b5 .CutList \u03b2 \u2192 \u00b5 (\u03b2 \u2192\u00b5 CutList \u03b1)\u2192\u00b5 CutList \u03b1 concatMapCutList (opened [ ]) f = return (opened [ ]) concatMapCutList (closed [ ]) f = return (closed [ ]) concatMapCutList (opened (b : bs)) f = do as \u2190 f b ; as \u2032 \u2190 concatMapCutList (opened bs) f ; appendCutList as as \u2032 concatMapCutList (closed (b : bs)) f = do as \u2190 f b ; as \u2032 \u2190 concatMapCutList (closed bs) f ; appendCutList as as \u2032\nIn Section 7.5, we give an example usage of cut to improve parsers.\n7.4. Depth-Bounded Search. The handlers for nondeterminism shown in Section 7 implement the depth-first search (DFS) strategy. However, with scoped effects and handlers we can implement other search strategies, such as depth-bounded search (DBS) [YPW+22], which uses the scoped operation depth : Int _ () to bound the depth of the branches in the scoped computation. The handler uses return type Int \u2192\u00b5 List (\u03b1, Int). Here, the Int parameter is the current depth bound, and the result is a list of (\u03b1, Int) pairs, where \u03b1 denotes the result and Int reflects the remaining global depth bound.3\nhdepth : \u2200 \u03b1 \u00b5 .\u03b1 ! \u3008choose ; fail ; depth ;\u00b5\u3009 \u21d2 (Int\u2192 \u00b5 List (\u03b1, Int))!\u3008\u00b5\u3009 hdepth = handler\n{return x 7\u2192 \u03bbd . [(x , d)] , op fail 7\u2192 \u03bb . [ ] , op choose x k 7\u2192 \u03bbd . if d \u2261 0 then [ ] else k true (d \u2212 1) ++k false (d \u2212 1) , sc depth d \u2032 p k 7\u2192 \u03bbd . concatMap (p () d \u2032) (\u03bb(v , ) . k v d) , fwd f p k 7\u2192 \u03bbd . f (\u03bby . p y d ,\u03bbvs . concatMap vs (\u03bb(v , d) . k v d))}\n3These pairs (\u03b1, Int) differ from Yang et al.\u2019s [YPW+22]\u2019s \u03b1 in order to make the forwarding clause work.\nFor the depth operation, we locally use the given depth bound d \u2032 for the scoped computation p and go back to using the global depth bound d for the continuation k . In case of an unknown scoped operation, the forwarding clause just threads the depth bound through, first into the scoped computation and from there into the continuation. For example, the following program (Figure 6) has a local depth bound of 1 and a global depth bound of 2. It discards the results 2 and 3 in the scoped computation as they appear after the second choose operation, and similarly, the results 5 and 6 in the continuation are ignored.\ncdepth = sc depth 1\n( .do b1 \u2190 op choose () ; if b1 then return 1 else do b2 \u2190 op choose () ; if b2 then return 2 else return 3) (x .do b1 \u2190 op choose () ; if b1 then return x else do b2 \u2190 op choose () ; if b2 then return 4 else do b3 \u2190 op choose () ; if b3 then return 5 else return 6)\n>>> (hdepth \u22c6 cdepth) 2 [(1, 1), (4, 0)]\nThe result is [(1, 1), (4, 0)], where the tuple\u2019s second parameter represents the global depth bound. Notice that choose operations in the scoped computation depth do not consume the global depth bound in the handler. For a different implementation, we refer to the Supplementary Material.\n7.5. Parsers. A parser effect can be achieved by combining the nondeterminism-with-cut effect and a token-consuming effect [WSH14]. The latter features the algebraic operation token : Char _ Char where op token t consumes a single character from the implicit input string; if it is t , it is passed on to the continuation; otherwise the operation fails. The token handler has result type String \u2192\u3008fail ;\u00b5\u3009 (\u03b1,String): it threads through the remaining part of the input string. Observe that the function type signals it may fail, in case the token does not match.\nhtoken : \u2200 \u03b1 \u00b5 .\u03b1 ! \u3008token ; fail ;\u00b5\u3009 \u21d2 (String\u2192 \u3008fail ;\u00b5\u3009 (\u03b1,String))!\u3008fail ;\u00b5\u3009 htoken = handler\n{return x 7\u2192 \u03bbs . (x , s) , op token x k 7\u2192 \u03bbs . case s of [ ] \u2192 failure ()\n(x \u2032 : xs)\u2192 if x \u2261 x \u2032 then k x xs else failure ()\n, fwd f p k 7\u2192 \u03bbs . f (\u03bby . p y s,\u03bb(t , s) . k t s)}\nWe give an example parser for a small expression language, in the typical parser combinator style, built on top of the token-consumer and nondeterminism. For convenience, it uses the syntactic sugar x \u22c4 y \u2261 op choose (b . if b then x else y).\ndigit : \u2200 \u00b5 . ()\u2192 Char ! \u3008token ; choose ;\u00b5\u3009 digit = op token \u20190\u2019 \u22c4 op token \u20191\u2019 \u22c4 . . . \u22c4 op token \u20199\u2019 many1 : \u2200 \u03b1 \u00b5 . (()\u2192 \u00b5 \u03b1)\u2192\u00b5 List \u03b1 many1 p = do a \u2190 p () ;do as \u2190 many1 p \u22c4 return [ ] ; return (a : as) expr\u2032 : \u2200 \u00b5 . ()\u2192 Int ! \u3008token ; choose ;\u00b5\u3009 expr\u2032 = do i \u2190 term () ;do op token \u2019+\u2019 ;do j \u2190 expr\u2032 () ;\nreturn (i + j ) \u22c4 do i \u2190 term () ; return i\nterm : \u2200 \u00b5 . ()\u2192 Int ! \u3008token ; choose ;\u00b5\u3009 term = do i \u2190 factor () ;do op token \u2019*\u2019 ;do j \u2190 term () ;\nreturn (i \u2217 j ) \u22c4 do i \u2190 factor () ; return i factor : \u2200 \u00b5 . ()\u2192 Int ! \u3008token ; choose ;\u00b5\u3009\nfactor = do ds \u2190 many1 digit ; return (read ds) \u22c4 do op token \u2019(\u2019 ;do i \u2190 expr\u2032 () ;do op token \u2019)\u2019 ; return i\nThe expr\u2032 parser is naive and can be improved by two types of refactoring: (1) factoring out the common prefix in the two branches, and (2) pruning the second branch when the first branch successfully consumes a +.\nexpr : \u2200 \u00b5 . ()\u2192 Int ! \u3008token ; choose ; cut ;\u00b5\u3009\nexpr = do i \u2190 term () ; sc call () ( . (do op token \u2019+\u2019 ;op cut () ;\nj \u2190 expr () ; return (i + j )) \u22c4 i)\nHere is how we invoke the parser on an example input.\n>>> hcut \u22c6 (htoken \u22c6 expr ()) \"(2+5)*8\" opened [(56, \"\"), (7, \"*8\")]\nThere are two results in the cutlist. Usually we are only interested in the full parsers, i.e., those that have consumed the entire input string.\n8. Related Work\nIn this section, we discuss related work on algebraic effects, scoped effects, and effect systems.\n8.1. Algebraic Effects & Handlers. Many research languages for algebraic effects have been proposed, including Eff [BP13, Pre15], Frank [LMM17], Effekt [BSO20], or have been extended to include them, such as Links [HL16], Koka [Lei17], and Multicore OCaml [SDW+21].\nThere are also many packages for writing effect handlers in general purpose languages [KSSF19, KS18, RTWS18, Mag19, Kin19]. Yet, as far as we know, \u03bbsc is the first calculus that supports scoped effects & handlers.\nIn contrast with this line of work on algebraic effects, Nanevski [Nan05] provides an alternative view of exceptions based on comonads that characterizes monadic effects as \u201cpersistent\u201d.\n8.2. Effect Systems. Most languages with support for algebraic effects are equipped with an effect system to keep track of the effects that are used in the programs. There is already much work on different approaches to effect systems for algebraic effects.\nEff [BP13, Pre15] uses an effect system based on subtyping relations. Each type of computation is decorated with an effect type \u2206 to represent the set of operations that might be invoked. The subtyping relations are used to extend the effect type \u2206 with other effects, which makes it possible to compose programs in a modular way. We did not choose to use the subtyping-based effect types in \u03bbsc as that would require complex subtyping for type operators.\nRow polymorphism is another mainstream approach to effect systems. Links [HL16] uses the Re\u0301my style row polymorphism [Re\u0301m94], where the row types are able to represent the absence of labels and each label is restricted to appear at most once. Koka [Lei17] uses row polymorphism based on scoped labels [Lei05], which allows duplicated labels and as a result is easier to implement. We can use row polymorphism to write handlers that handle particular effects and forward other effects represented by a row variable. In \u03bbsc , we opted for an effect system similar to Koka\u2019s, mainly because of its brevity. We believe that the Links-style effect system should also work well with scoped effects.\n8.3. Scoped Effects & Handlers. Wu et al. [WSH14] first introduced the idea of scoped effects & handlers to solve the problem of separating syntax from semantics in programming with effects that delimit the scope. They proposed a higher-order syntax, an approach to scoped effects & handlers that has already been implemented in several Haskell packages [RTWS18, Mag19, Kin19]. They use higher-order signatures, which impose less restrictions on the shape of the signatures of scoped operations and allow programmers to delimit the scopes in a freer way than \u03bbsc . The cost of this freedom is the need for programmers to write more functions to distribute handlers for each signature. The higher-order signatures are also not suitable for use in a calculus as the signatures of operations are usually characterised by a pair of types in a calculus. Pirog et al. [PSWJ18] and Yang et al. [YPW+22] have developed denotational semantic domains of scoped effects, backed by category theorical models. The key idea is to generalize the denotational approach of algebraic effects & handlers that is based on free monads and their unique homomorphisms. Indeed, the underlying category can be seen as a parameter. Then, by shifting from the base category of types and functions to a different (indexed or functor) category, scoped operations and their handlers turn out to be \u201cjust\u201d an instance of the generalized notion of algebraic operations and handlers with the same structure and properties. We focus on a calculus for scoped effects instead of the denotational semantics of scoped effects. We make a simplification with respect to Yang et al. [YPW+22] where we avoid duplication of the base algebra and endoalgebra (for the outer and inner scoped respectively), and thus duplication of the scoped effect clauses in our handlers. With respect to Pirog et al. [PSWJ18], we specialize the generic endofunctor \u0393 with signatures A\u2113 _ B\u2113 of endofunctors of the form A \u00d7 (B \u2192 \u2212). Our \u03bbsc calculus uses a similar idea to the \u2018explicit substitution\u2019 monad of Pirog et al. [PSWJ18], a generalization of Ghani\nand Uustalu\u2019s [GU03] monad of explicit substitutions where each operation is associated with two computations representing the computation in scope and out of the scope (continuation) respectively. While the composition of scoped effects has not been considered in their categorical models, we introduced forwarding clauses for the composition, and further restrict handlers to be polymorphic to simplify handling and composing scoped effects.\n9. Conclusion and Future Work\nIn this work, we have presented \u03bbsc , a novel calculus in which scoped effects & handlers are built-in. We have started from Eff, extended with row-typing in the style of Koka, and added scoped effect clauses and operations, polymorphic handlers, and explicit forwarding clauses. Finally, we have demonstrated the usability of \u03bbsc by implementing a range of examples. Although we have given many useful and compelling examples, we acknowledge that, just like algebraic effects, scoped effects are not encompassing (e.g. bracketing). We believe that the features to support scoped effect in \u03bbsc are orthogonal to other language features and can be added to any programming language with algebraic effects, polymorphism and type operators. Scoped effects require every handler in \u03bbsc to be polymorphic and equipped with an explicit forwarding clause. This breaks backwards compatibility: calculi that support only algebraic effects, such as Eff, miss an explicit forwarding clause for scoped operations and allow monomorphic handlers. Actually this problem can be easily solved by kinds and kind polymorphism. The core idea is that we extend \u03bbsc with two kinds op and sc for effect types, such that \u0393 \u22a2 E : op means effect type E only contains algebraic operations, and \u0393 \u22a2 E : sc means effect type E may contain some scoped operations. Then, for handlers of type A !\u3008E \u3009 \u21d2 M A !\u3008F \u3009 which lack forwarding clauses, we can just add the condition \u0393 \u22a2 E : op to their typing rules. We have a prototype implementation of this idea, but we leave the full specification and extension of it to future work.\nReferences\n[BP13] Andrej Bauer and Matija Pretnar. An effect system for algebraic effects and handlers. In Reiko Heckel and Stefan Milius, editors, Algebra and Coalgebra in Computer Science - 5th International Conference, CALCO 2013, Warsaw, Poland, September 3-6, 2013. Proceedings, volume 8089 of Lecture Notes in Computer Science, pages 1\u201316. Springer, 2013. doi:10.1007/978-3-642-40206-7\\_1. [BP15] Andrej Bauer and Matija Pretnar. Programming with algebraic effects and handlers. Journal of Logical and Algebraic Methods in Programming, 84(1):108\u2013123, 2015. Special Issue: The 23rd Nordic Workshop on Programming Theory (NWPT 2011) Special Issue: Domains X, International workshop on Domain Theory and applications, Swansea, 5-7 September, 2011. URL: https://www.sciencedirect.com/science/article/pii/S2352220814000194, doi:https://doi.org/10.1016/j.jlamp.2014.02.001. [BSO20] Jonathan Immanuel Brachtha\u0308user, Philipp Schuster, and Klaus Ostermann. Effects as capabilities: Effect handlers and lightweight effect polymorphism. Proc. ACM Program. Lang., 4(OOPSLA), November 2020. doi:10.1145/3428194. [GU03] Neil Ghani and Tarmo Uustalu. Explicit substitutions and higher-order syntax. In Proceedings of the 2003 ACM SIGPLAN Workshop on Mechanized Reasoning about Languages with Variable Binding, MERLIN \u201903, page 1\u20137, New York, NY, USA, 2003. Association for Computing Machinery. doi:10.1145/976571.976580.\n[HL16] Daniel Hillerstro\u0308m and Sam Lindley. Liberating effects with rows and handlers. In Proceedings of the 1st International Workshop on Type-Driven Development, TyDe 2016, page 15\u201327, New York, NY, USA, 2016. Association for Computing Machinery. doi:10.1145/2976022.2976033. [Kin19] Alexis King. eff \u2013 screaming fast extensible effects for less, 2019. https://github.com/hasura/eff. [KS18] Oleg Kiselyov and KC Sivaramakrishnan. Eff directly in ocaml. Electronic Proceedings in Theoretical Computer Science, 285:23\u201358, Dec 2018. URL: http://dx.doi.org/10.4204/EPTCS.285.2, doi:10.4204/eptcs.285.2. [KSSF19] Oleg Kiselyov, Amr Sabry, Cameron Swords, and Ben Foppa. extensible-effects: An alternative to monad transformers, 2019. https://hackage.haskell.org/package/extensible-effects. [Lei05] Daan Leijen. Extensible records with scoped labels. In Marko C. J. D. van Eekelen, editor, Revised Selected Papers from the Sixth Symposium on Trends in Functional Programming, TFP 2005, Tallinn, Estonia, 23-24 September 2005, volume 6 of Trends in Functional Programming, pages 179\u2013194. Intellect, 2005. [Lei14] Daan Leijen. Koka: Programming with row polymorphic effect types. Electronic Proceedings in Theoretical Computer Science, 153, 06 2014. doi:10.4204/EPTCS.153.8. [Lei17] Daan Leijen. Type directed compilation of row-typed algebraic effects. In Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages, POPL 2017, page 486\u2013499, New York, NY, USA, 2017. Association for Computing Machinery. doi:10.1145/3009837.3009872. [LMM17] Sam Lindley, Conor McBride, and Craig McLaughlin. Do be do be do. In Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages, POPL 2017, page 500\u2013514, New York, NY, USA, 2017. Association for Computing Machinery. doi:10.1145/3009837.3009897. [LPT03] Paul Blain Levy, John Power, and Hayo Thielecke. Modelling environments in call-by-value programming languages. Inf. Comput., 185(2):182\u2013210, 2003. doi:10.1016/S0890-5401(03)00088-9. [Mag19] Sandy Maguire. polysemy: Higher-order, low-boilerplate free monads, 2019. https://hackage.haskell.org/package/polysemy. [Mil78] Robin Milner. A theory of type polymorphism in programming. J. Comput. Syst. Sci., 17(3):348\u2013 375, 1978. doi:10.1016/0022-0000(78)90014-4 . [Mog89] Eugenio Moggi. An abstract view of programming languages. Technical Report ECS-LFCS-90113, Edinburgh University, Department of Computer Science, June 1989. [Mog91] Eugenio Moggi. Notions of computation and monads. Information and Computation, 93(1):55 \u2013 92, 1991. Selections from 1989 IEEE Symposium on Logic in Computer Science. doi:https://doi.org/10.1016/0890-5401(91)90052-4 . [Nan05] Aleksandar Nanevski. A modal calculus for exception handling. 01 2005. [PP03] Gordon D. Plotkin and John Power. Algebraic operations and generic effects. Appl. Categorical Struct., 11(1):69\u201394, 2003. doi:10.1023/A:1023064908962. [PP09] Gordon Plotkin and Matija Pretnar. Handlers of algebraic effects. In Giuseppe Castagna, editor,\nProgramming Languages and Systems, pages 80\u201394, Berlin, Heidelberg, 2009. Springer Berlin Heidelberg. doi:10.1007/978-3-642-00590-9\\_7.\n[Pre15] Matija Pretnar. An introduction to algebraic effects and handlers. invited tutorial paper. Electronic Notes in Theoretical Computer Science, 319:19\u201335, 2015. The 31st Conference on the Mathematical Foundations of Programming Semantics (MFPS XXXI). URL: https://www.sciencedirect.com/science/article/pii/S1571066115000705, doi:https://doi.org/10.1016/j.entcs.2015.12.003. [PS17] Maciej Piro\u0301g and Sam Staton. Backtracking with cut via a distributive law and left-zero monoids. J. Funct. Program., 27:e17, 2017. doi:10.1017/S0956796817000077. [PSWJ18] Maciej Piro\u0301g, Tom Schrijvers, Nicolas Wu, and Mauro Jaskelioff. Syntax and semantics for operations with scopes. In Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science, LICS \u201918, page 809\u2013818, New York, NY, USA, 2018. Association for Computing Machinery. doi:10.1145/3209108.3209166. [Re\u0301m94] Didier Re\u0301my. Type inference for records in a natural extension of ml. In Theoretical Aspects of Object-Oriented Programming: Types, Semantics, and Language Design. Citeseer, 1994.\n[RTWS18] Rob Rix, Patrick Thomson, Nicolas Wu, and Tom Schrijvers. fused-effects: A fast, flexible, fused effect system, 2018. https://hackage.haskell.org/package/fused-effects. [SDW+21] KC Sivaramakrishnan, Stephen Dolan, Leo White, Tom Kelly, Sadiq Jaffer, and Anil Madhavapeddy. Retrofitting effect handlers onto ocaml. In Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation, PLDI 2021, page 206\u2013221, New York, NY, USA, 2021. Association for Computing Machinery. doi:10.1145/3453483.3454039. [TRWS22] Patrick Thomson, Rob Rix, Nicolas Wu, and Tom Schrijvers. Fusing industry and academia at github (experience report). Proc. ACM Program. Lang., 6(ICFP):496\u2013511, 2022. doi:10.1145/3547639. [Wad95] Philip Wadler. Monads for functional programming. In Johan Jeuring and Erik Meijer, editors, Advanced Functional Programming, First International Spring School on Advanced Functional Programming Techniques, B\u030aastad, Sweden, May 24-30, 1995, Tutorial Text, volume 925 of Lecture Notes in Computer Science, pages 24\u201352. Springer, 1995. doi:10.1007/3-540-59451-5\\_2 . [WSH14] Nicolas Wu, Tom Schrijvers, and Ralf Hinze. Effect handlers in scope. In Proceedings of the 2014 ACM SIGPLAN Symposium on Haskell, Haskell \u201914, page 1\u201312, New York, NY, USA, 2014. Association for Computing Machinery. doi:10.1145/2633357.2633358. [YPW+22] Zhixuan Yang, Marco Paviotti, Nicolas Wu, Birthe van den Berg, and Tom Schrijvers. Structured handling of scoped effects. In Ilya Sergey, editor, Programming Languages and Systems - 31st European Symposium on Programming, ESOP 2022, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2022, Munich, Germany, April 2-7, 2022, Proceedings, volume 13240 of Lecture Notes in Computer Science, pages 462\u2013491. Springer, 2022. doi:10.1007/978-3-030-99336-8\\_17. [YW14] Jeremy Yallop and Leo White. Lightweight higher-kinded polymorphism. In Michael Codish and Eijiro Sumii, editors, Functional and Logic Programming, pages 119\u2013135, Cham, 2014. Springer International Publishing.\nContents \u2022 Appendix A Semantic Derivations, p. 29 \u2022 Appendix B Type Equivalence Rules, p. 33 \u2022 Appendix C Well-scopedness Rules, p. 34 \u2022 Appendix D Syntax-directed version of \u03bbsc , p. 35 \u2022 Appendix E Metatheory, p. 39 \u2022 Appendix F Type Inference, p. 43\nAppendix A. Semantic Derivations\nThis Appendix contains semantic derivations of different handler applications that are used in the examples throughout this paper.\nA.1. Nondeterminism.\nhND \u22c6 cND \u2261 hND \u22c6 op choose () (b . if b then return 1 else return 2) {- E-HandOp -}\ndo xs \u2190 (\u03bby . hND \u22c6 if b then return 1 else return 2) true do ys \u2190 (\u03bby . hND \u22c6 if b then return 1 else return 2) false xs ++ys\n{- E-AppAbs -} do xs \u2190 hND \u22c6 if true then return 1 else return 2 do ys \u2190 (\u03bby . hND \u22c6 if b then return 1 else return 2) false\nxs ++ys\n{- reducing if -} do xs \u2190 hND \u22c6 return 1 do ys \u2190 (\u03bby . hND \u22c6 if b then return 1 else return 2) false\nxs ++ys\n{- E-HandRet -} do ys \u2190 (\u03bby . hND \u22c6 if b then return 1 else return 2) false\n[1] ++ys\n\u2217 {- similar to above (the first branch of if) -} [1] ++[2]\n{- reducing ++ -} return [1, 2]\nA.2. Increment.\nhND \u22c6 runinc 0 cinc \u2261 hND \u22c6 (\u03bbc p .do p \u2032 \u2190 hinc \u22c6 p ; p \u2032 c) 0 cinc {- E-AppAbs -} hND \u22c6 do p \u2032 \u2190 hinc \u22c6 cinc ; p \u2032 0\n\u2261 {- definition of cinc -}\nhND \u22c6 do p \u2032 \u2190 hinc \u22c6 op choose () (b . if b then op inc () (x . x + 5)\nelse op inc () (y . y + 2)) ; p\u2032 0\n{- E-FwdOp -} hND \u22c6 do p \u2032 \u2190 op choose () (b . hinc \u22c6 if b then op inc () (x . x + 5)\nelse op inc () (y . y + 2)) ; p\u2032 0\n{- E-Hand and E-DoOp -} hND \u22c6 op choose () (b .do p\n\u2032 \u2190 hinc \u22c6 if b then op inc () (x . x + 5) else op inc () (y . y + 2) ; p\u2032 0)\n{- E-HandOp -}\ndo xs \u2190 (\u03bbb . hND \u22c6 do p \u2032 \u2190 hinc \u22c6 if b then op inc () (x . x + 5)\nelse op inc () (y . y + 2) ; p\u2032 0) true ;\ndo ys \u2190 (\u03bbb . hND \u22c6 do p \u2032 \u2190 hinc \u22c6 if b then op inc () (x . x + 5)\nelse op inc () (y . y + 2) ; p\u2032 0) false ;\nxs ++ys\n{- E-AppAbs -} do xs \u2190 hND \u22c6 do p \u2032 \u2190 hinc \u22c6 if true then op inc () (x . x + 5)\nelse op inc () (y . y + 2) ; p\u2032 0\ndo ys \u2190 (\u03bbb . hND \u22c6 do p \u2032 \u2190 hinc \u22c6 if b then op inc () (x . x + 5)\nelse op inc () (y . y + 2) ; p\u2032 0) false ;\nxs ++ys\n{- reducing if -} do xs \u2190 hND \u22c6 (do p \u2032 \u2190 hinc \u22c6 op inc () (x . x + 5) ; p \u2032 0) do ys \u2190 (\u03bbb . hND \u22c6 do p \u2032 \u2190 hinc \u22c6 if b then op inc () (x . x + 5)\nelse op inc () (y . y + 2) ; p\u2032 0) false ;\nxs ++ys\n{- E-HandOp -} do xs \u2190 hND \u22c6 (do p\n\u2032 \u2190 return (\u03bbs .do s \u2032 \u2190 s + 1 ; do k \u2032 \u2190 (\u03bbx . hinc \u22c6 (x + 5)) s \u2032 ; k \u2032 s \u2032) ; p\u2032 0)\ndo ys \u2190 (\u03bbb . hND \u22c6 do p \u2032 \u2190 hinc \u22c6 if b then op inc () (x . x + 5)\nelse op inc () (y . y + 2) ; p\u2032 0) false ;\nxs ++ys\n{- E-DoRet -} do xs \u2190 hND \u22c6 (\u03bbs .do s \u2032 \u2190 s + 1 ; k \u2032 \u2190 (\u03bbx . hinc \u22c6 (x + 5)) s \u2032 ; k \u2032 s \u2032) 0 do ys \u2190 (\u03bbb . hND \u22c6 do p \u2032 \u2190 hinc \u22c6 if b then op inc () (x . x + 5)\nelse op inc () (y . y + 2) ; p\u2032 0) false ;\nxs ++ys\n\u2217 {- E-AppAbs and reducing + -}\ndo xs \u2190 hND \u22c6 (hinc \u22c6 (return 6)) 1 do ys \u2190 (\u03bbb . hND \u22c6 do p\n\u2032 \u2190 hinc \u22c6 if b then op inc () (x . x + 5) else op inc () (y . y + 2) ; p\u2032 0) false ;\nxs ++ys\n{- E-HandRet -}\ndo xs \u2190 (\u03bbs . return (6, s)) 1 do ys \u2190 (\u03bbb . hND \u22c6 do p\n\u2032 \u2190 hinc \u22c6 if b then op inc () (x . x + 5) else op inc () (y . y + 2) ; p\u2032 0) false ;\nxs ++ys\n{- E-AppAbs -} do xs \u2190 hND \u22c6 return (6, 1) do ys \u2190 (\u03bbb . hND \u22c6 do p\n\u2032 \u2190 hinc \u22c6 if b then op inc () (x . x + 5) else op inc () (y . y + 2) ; p\u2032 0) false ;\nxs ++ys\n{- E-HandOp -} do xs \u2190 return [(6, 1)] do ys \u2190 (\u03bbb . hND \u22c6 do p\n\u2032 \u2190 hinc \u22c6 if b then op inc () (x . x + 5) else op inc () (y . y + 2) ; p\u2032 0) false ;\nxs ++ys\n{- E-DoRet -} do ys \u2190 (\u03bbb . hND \u22c6 do p\n\u2032 \u2190 if b then hinc \u22c6 op inc () (x . x + 5) else hinc \u22c6 op inc () (y . y + 2) ; p \u2032 0) false ;\n[(6, 1)] ++ys\n\u2217 {- similar to above (the first branch of if) -} do ys \u2190 return [(3, 1)] [(6, 1)] ++ys \u2217 {- E-DoRet -}\n[(6, 1)] ++[(3, 1)]\n\u2217 {- reducing ++ -} return [(6, 1), (3, 1)]\nA.3. Once.\nhonce \u22c6 conce {- E-HandSc -}\ndo ts \u2190 (\u03bby . honce \u22c6 op choose () (x . return x )) () ; do t \u2190 head ts ;\n(\u03bbp . honce \u22c6 (do q \u2190 op choose (b . return b) ; return (p, q))) t\n{- E-Do and E-AppAbs -} do ts \u2190 honce \u22c6 op choose () (x . return x ) ; do t \u2190 head ts ;\n(\u03bbp . honce \u22c6 (do q \u2190 op choose (b . return b) ; return (p, q))) t\n{- E-Do and E-HandOp -} do ts \u2190 do xs \u2190 (\u03bbx . honce \u22c6 return x ) true ;do ys \u2190 (\u03bbx . honce \u22c6 return x ) false ;\nxs ++ys ;\ndo t \u2190 head ts ; (\u03bbp . honce \u22c6 (do q \u2190 op choose (b . return b) ; return (p, q))) t\n{- E-Do and E-AppAbs -} do ts \u2190 do xs \u2190 honce \u22c6 return true ;do ys \u2190 honce \u22c6 return false ; xs ++ys ; do t \u2190 head ts ;\n(\u03bbp . honce \u22c6 (do q \u2190 op choose (b . return b) ; return (p, q))) t\n{- E-Do and E-HandRet -} do ts \u2190 do xs \u2190 return [true ] ;do ys \u2190 return [false] ; xs ++ys ; do t \u2190 head ts ;\n(\u03bbp . honce \u22c6 (do q \u2190 op choose (b . return b) ; return (p, q))) t\n\u2217 {- E-DoRet -} do ts \u2190 [true, false ] ; do t \u2190 head ts ;\n(\u03bbp . honce \u22c6 (do q \u2190 op choose (b . return b) ; return (p, q))) t \u2217 {- E-DoRet -}\n(\u03bbp . honce \u22c6 (do q \u2190 op choose (b . return b) ; return (p, q))) true {- E-AppAbs -}\nhonce \u22c6 (do q \u2190 op choose (b . return b) ; return (true, q)) \u2217 {- similar to A.1 (handling of choose) -}\nreturn [(true, true), (true, false)]\nAppendix B. Type Equivalence Rules\nThis appendix shows the type equivalence rules of \u03bbsc . Figures 7 and 8 contains the rules. Rules Q-AppAbs and Q-Swap deserve special attention. The other rules are straightforward.\nAppendix C. Well-scopedness Rules\nThis appendix shows the well-scopedness rules of \u03bbsc . Figure 9 contains the rules.\nAppendix D. Syntax-directed version of \u03bbsc\nThis section describes the syntax-direction version of \u03bbsc . It is this version we prove type safe in Appendix E. Furthermore, it serves as the specification of our type inference algorithm as described in Appendix F. The syntax-directed rules can be found in Figure 10 for value typing, Figure 11 for computation and Figure 12 for handler typing.\nThe syntax-directed system is obtained by incorporating the non-syntax-directed rules into the syntax-directed-ones where needed. In particular, we inline the non-syntax-directed rules for equivalence (T-EqV and T-EqC) into the syntax-directed rules that mention the same type or row twice in their assumptions (e.g., SD-App, SD-Do). Similarly, we inline the rules T-Inst, T-InstEff, T-Gen and T-GenEff for instantiating and generalizing type and row variables. The generalization is incorporated into the rule for let-bindings (T-Let). Instantiation is incorporated into the variable rule (T-Var) using \u03c3 6 A defined in Figure 13. Instantiation is also incorporated into the handler rule: we implicitly instantiate \u03b1 with an arbitrary type A, which results in a monomorphically typed handler. However, since SD-Handler insists on sufficiency polymorphic handler clauses, we can still handle scoped effects by polymorphic recursion. Figure 14 displays declarative and syntax-directed typing derivations for both inline handler application (h \u22c6 c) as well as let-bound handlers. As can be seen in the first derivation, in the case of inline handler application, the declarative system derives a polymorphically typed handler, which is instantiated. The syntax-directed system essentially combines these steps, as can be seen in the second derivation. In the case of a let-bound handler, the declarative system keeps the polymorphic handler type as-is (third derivation). The syntax-directed system however instantiates and then immediately generalizes handlers, as can be seen in the fourth derivation.\nThe other rules of the declarative system are syntax-directed and remain unchanged.\n\u0393 \u22a2 c : C Computation Typing\n\u0393 \u22a2 v1 : A1 \u2192 C \u0393 \u22a2 v2 :A2 A1 \u2261 A2\n\u0393 \u22a2 v1 v2 : C SD-App\n\u0393 \u22a2 c1 : A !\u3008E1\u3009 \u0393, x :A \u22a2 c2 : B !\u3008E2\u3009 E1 \u2261 E2\n\u0393 \u22a2 do x \u2190 c1 ; c2 : B !\u3008E2\u3009 SD-Do\n\u0393 \u22a2M return x 7\u2192 cr :M A !\u3008E \u3009 \u0393 \u22a2M oprs :M A !\u3008E \u3009\n\u0393 \u22a2M fwd f p k 7\u2192 cf :M A !\u3008E \u3009\nReturn-, operation-, and forwarding-clause typing\n\u0393, x :A1 \u22a2 cr :M A2 !\u3008E \u3009 A1 \u2261 A2\n\u0393 \u22a2M return x 7\u2192 cr :M A !\u3008E2\u3009 SD-Return\n\u0393 \u22a2M \u00b7 :M A !\u3008E \u3009 SD-Empty\n\u0393 \u22a2M oprs :M A1 !\u3008E1\u3009 (\u2113 op : Aop _ Bop) \u2208 \u03a3\n\u0393, x :Aop, k : Bop \u2192 M A1 !\u3008E1\u3009 \u22a2 c :M A2 !\u3008E2\u3009 M A1 !\u3008E1\u3009 \u2261 M A2 !\u3008E2\u3009\n\u0393 \u22a2M op \u2113 op x k 7\u2192 c, oprs :M A2 !\u3008E2\u3009\nSD-OprOp\n\u0393 \u22a2M oprs :M A1 !\u3008E1\u3009 (\u2113 sc : Asc _ Bsc) \u2208 \u03a3 \u03b2 /\u2208 \u0393\n\u0393, \u03b2, x :Asc, p :Bsc \u2192 M \u03b2 !\u3008E1\u3009, k : \u03b2 \u2192 M A1 !\u3008E1\u3009 \u22a2 c :M A2 !\u3008E2\u3009 M A1 !\u3008E1\u3009 \u2261 M A2 !\u3008E2\u3009\nAppendix E. Metatheory\nE.1. Lemmas.\nLemma E.1 (Canonical forms). \u2022 If \u00b7 \u22a2 v :A\u2192 C then v is of shape \u03bbx . c. \u2022 If \u00b7 \u22a2 v : C \u21d2 D then v is of shape h.\nLemma E.2 (Generalisation-equivalence). If \u03c31 6 A1 and \u03c31 \u2261 \u03c32, then there exists a A2 such that A1 \u2261 A2 and \u03c32 6 A2.\nLemma E.3 (Generalisation-instantiation). If \u0393, \u03b1, \u00b5 \u22a2 v : A and \u2200 \u03b1 \u2200 \u00b5 .A 6 B, then \u0393 \u22a2 v : B.\nLemma E.4 (Preservation of types under term substitution). Given \u03931, \u03b1, \u00b5 \u22a2 v : A1 and A1 \u2261 A2 we have that: \u2022 If \u03931, x : \u2200 \u03b1 \u2200 \u00b5 .A2,\u03932 \u22a2 c : C1, then there exists a C2 such that C1 \u2261 C2 and \u03931,\u03932 \u22a2 [v / x ] c : C2. \u2022 If \u03931, x : \u2200 \u03b1 \u2200 \u00b5 .A2,\u03932 \u22a2 v : B1, then there exists a B2 such that B1 \u2261 B2 and \u03931,\u03932 \u22a2 [v / x ] v : B2.\nProof. By mutual induction on the typing derivations. The only interesting case, SD-Var, requires us to show that, given \u03931, x : \u2200 \u03b1 \u2200 \u00b5 .A2,\u03932 \u22a2 y : B1, there exists a B2 such that B1 \u2261 B2 and \u03931,\u03932 \u22a2 [v /x ] y :B2. If x 6= y , it is trivial. If x = y , then \u2200 \u03b1 \u2200 \u00b5 .A2 6 B1, which means by Lemma E.2 there exists a B2 such that B1 \u2261 B2 and \u2200 \u03b1 \u2200 \u00b5 .A1 6 B2, which means the result follows from Lemma E.3.\nLemma E.5 (Preservation of types under type substitution). If \u03931, \u03b1,\u03932 \u22a2 c :C and \u03931 \u22a2 B, then \u03931, [B / \u03b1 ] \u03932 \u22a2 c : [B / \u03b1 ] C.\nLemma E.6 (Unused binding insertion). If \u03931,\u03932 \u22a2 c :C and x /\u2208 c then \u03931, x :A,\u03932 \u22a2 c :C.\nLemma E.7 (Handlers are polymorphic). If \u0393 \u22a2 h : A !\u3008F \u3009 \u21d2 M A !\u3008E \u3009 and \u0393 \u22a2 B, then \u0393 \u22a2 h : B !\u3008F \u3009 \u21d2 M B !\u3008E \u3009.\nLemma E.8 (Op membership). If \u0393 \u22a2 oprs : C and op \u2113op x k 7\u2192 c \u2208 oprs, then there exists oprs1 and oprs2 such that oprs = oprs1,op \u2113 op k \u22a2 c, oprs2 and \u0393 \u22a2 op \u2113 op x k 7\u2192 c, oprs2 : C.\nLemma E.9 (Sc membership). If \u0393 \u22a2 oprs :C and (sc \u2113sc x p k 7\u2192 c) \u2208 h, then there exists oprs1 and oprs2 such that oprs = oprs1, sc \u2113 sc x p k 7\u2192 c, oprs2 and \u0393 \u22a2 sc \u2113 sc x p k 7\u2192 c, oprs2 : C.\nE.2. Subject reduction.\nTheorem 6.1 (Subject Reduction). If \u0393 \u22a2 c : C and c c\u2032, then there exists a C \u2032 such that C \u2261 C \u2032 and \u0393 \u22a2 c\u2032 : C \u2032.\nProof. Assume, without loss of generality, that C = B !\u3008F \u3009 for some B , F . Proceed by induction on the derivation c c\u2032.\n\u2022 E-AppAbs: Inversion on \u0393 \u22a2 (\u03bbx . c) v :B !\u3008F \u3009 (SD-App) gives \u0393 \u22a2 \u03bbx . c :A1 \u2192 B !\u3008F \u3009 (1), \u0393 \u22a2 v : A2 (2), and A1 \u2261 A2 (3). Inversion on fact 1 (SD-Abs) gives \u0393, x : A1 \u22a2 c : B !\u3008F \u3009 (4), which means the goal follows from facts 2 and 4 and Lemma E.4.\n\u2022 E-Let: Inversion on \u0393 \u22a2 let x = v in c : B !\u3008F \u3009 (SD-Let) gives \u0393 \u22a2 v : A (1), \u03c3 = gen (A,\u0393) (2), and \u0393, x :\u03c3 \u22a2 c :B !\u3008F \u3009 (3), which means the goal follows from facts 1 and 3 and Lemma E.4. \u2022 E-Do: Follows from the IH. \u2022 E-DoRet: Inversion on \u0393 \u22a2 do x \u2190 return v in c : B !\u3008F2\u3009 (SD-Do) gives \u0393 \u22a2 return v : A !\u3008F1\u3009 (1) and \u0393, x : A \u22a2 c : B !\u3008F2\u3009 (2). Inversion on (1) (SD-Ret) gives \u0393 \u22a2 v :A (3). The case follows from facts 2 and 4 and Lemma E.4. \u2022 E-DoOp: Similar to E-DoSc. By inversion on \u0393 \u22a2 do x \u2190 op \u2113op v (y . c1) in c2 :B !\u3008F2\u3009 (SD-Do) we have that \u0393 \u22a2 op \u2113op v (y . c1) : A !\u3008F1\u3009 (1), \u0393, x : A \u22a2 c2 : B !\u3008F2\u3009 (2), and F1 \u2261 F2 (3). From inversion on fact 1 (SD-Op) it follows that \u2113\nop :Aop _ Bop \u2208 \u03a3 (4), \u0393 \u22a2 v :A1 (5), Aop \u2261 A1 (6), \u0393, y :Bop \u22a2 c1 :A !\u3008F1\u3009 (7), and \u2113\nop \u2208 F1 (8). Lemma E.6 on (2) gives us \u0393, y : Bop, x : A \u22a2 c2 : B !\u3008F2\u3009 (9). Facts 3, 7 and 9 and rule SD-Do give us \u0393, y : Bop \u22a2 do x \u2190 c1 in c2 : B !\u3008F2\u3009 (10). Our goal then follows from facts 4, 5, 6, 8, and 10 and rule SD-Op. \u2022 E-DoSc: Similar to E-DoOp. By inversion on \u0393 \u22a2 do x \u2190 sc \u2113sc v (y . c1) (z . c2) in c3 : B !\u3008F3 \u3009 (SD-Do) we have that \u0393 \u22a2 sc \u2113sc v (y . c1) (z . c2) : A !\u3008F2\u3009 (1), \u0393, x : A \u22a2 c3 : B !\u3008F3 \u3009 (2), and F2 \u2261 F3 (2.1). From inversion on fact 1 (SD-Sc) it follows that \u2113sc : Asc _ Bsc \u2208 \u03a3 (3), \u0393 \u22a2 v : A1 (4), Asc \u2261 A1 (5), \u0393, y : Bsc \u22a2 c1 : B\n\u2032 !\u3008F1\u3009 (6), \u0393, z : B \u2032 \u22a2 c2 : A !\u3008F2\u3009 (7), F1 \u2261 F2 (8), and \u2113\nsc \u2208 F2 (9). Lemma E.6 on (2) gives us \u0393, z : B \u2032, x : A \u22a2 c3 : B !\u3008F3 \u3009 (10), which means facts 2.1, 7 and 10 and rule SD-Do give us \u0393, z : B \u2032 \u22a2 do x \u2190 c2 in c3 : B !\u3008F3 \u3009 (11). Our goal then follows from facts 3, 4, 5, 6, 8 9, and 11 and rule SD-Sc. \u2022 E-Hand: Follows from the IH. \u2022 E-HandRet: By inversion on \u0393 \u22a2 h \u22c6 return v : B !\u3008F2\u3009 (SD-Hand) we have that \u0393 \u22a2 h : C1 \u21d2 B !\u3008F2\u3009 (1), \u0393 \u22a2 return v : C2 (2), and C1 \u2261 C2 (3). Inversion on fact 1 (SD-Handler) gives B = M A2, C1 = A2 !\u3008E \u3009, and \u0393, \u03b1 \u22a2M return x 7\u2192 cr :M \u03b1 !\u3008F2\u3009 (4). Based on fact (3) we get that C2 = A2 \u2032 !\u3008E \u2032\u3009, A2 \u2261 A2 \u2032 (4), and E \u2261 E \u2032 (5).\nInversion on fact 4 (SD-Return) gives \u0393, \u03b1, x :A1 \u22a2 cr :M \u03b1 !\u3008F2\u3009 (5) and A1 \u2261 A2 (6). Inversion on fact 2 (SD-Ret) gives \u0393 \u22a2 v : A2 \u2032 (7). From facts 4-8 and Lemma E.4, we get that \u0393, \u03b1 \u22a2 [v\u03bbx ] cr :M \u03b1 !\u3008F2\u3009 (8). We obtain our goal from fact 8 and Lemma E.5. \u2022 E-HandOp: By inversion on \u0393 \u22a2 h \u22c6 op \u2113op v (y . c1) : B !\u3008F2\u3009 (SD-Hand) we have that \u0393 \u22a2 h : C1 \u21d2 B !\u3008F2\u3009 (1), \u0393 \u22a2 op \u2113\nop v (y . c1) : C2 (2), and C1 \u2261 C2 (3). Inversion on fact 1 (SD-Handler) gives B = M A2, C1 = A2 !\u3008E \u3009, and \u0393, \u03b1 \u22a2M oprs : M \u03b1 !\u3008F2\u3009 (4). Based on fact (3) we get that C2 = A2 \u2032 !\u3008E \u2032\u3009, A2 \u2261 A2 \u2032 (4), and E \u2261 E \u2032 (5). Inversion on fact 2 (SD-Op) gives us \u2113op :Aop _ Bop \u2208 \u03a3 (6), \u0393 \u22a2 v :A1 (7), Aop \u2261 A1 (8), \u0393, y : Bop \u22a2 c1 : A2\n\u2032 !\u3008E \u2032\u3009 (9), and \u2113op \u2208 E \u2032 (10). By Lemma E.8 we get that \u0393, \u03b1 \u22a2M op \u2113\nop x k 7\u2192 c, oprs2 :M \u03b1 !\u3008F2\u3009 (11). Inversion on fact 11 (SD-OprOp) gives that \u0393, \u03b1 \u22a2M oprs :M \u03b1 !\u3008F1\u3009 (12), (\u2113\nop : Aop _ Bop) \u2208 \u03a3 (13), \u0393, \u03b1, x : Aop, k : Bop \u2192 M \u03b1 !\u3008F1\u3009 \u22a2 c :M \u03b1 !\u3008F2\u3009 (14), and F1 \u2261 F2 (15). Facts 1, 4 and 9 in combination with constructors SD-Abs and ST-Hand gives us that \u0393 \u22a2 \u03bby . h \u22c6 c1 : Bop \u2192 M A2 !\u3008F2\u3009 (16). The goal follows from facts 7, 8, 14 and 16 and lemmas Lemmas E.4 and E.5. \u2022 E-FwdOp By inversion on \u0393 \u22a2 h \u22c6 op \u2113op v (y . c1) : B !\u3008F2\u3009 (SD-Hand) we have that \u0393 \u22a2 h : C1 \u21d2 B !\u3008F2\u3009 (1), \u0393 \u22a2 op \u2113\nop v (y . c1) : C2 (2), and C1 \u2261 C2 (3). Inversion on fact 1 (SD-Handler) gives B = M A2, and C1 = A2 !\u3008E \u3009. Based on fact (3) we get that C2 = A2 \u2032 !\u3008E \u2032\u3009, A2 \u2261 A2 \u2032 (4), and E \u2261 E \u2032 (5). Inversion on fact 2 (SD-Op) gives us \u2113op :Aop _ Bop \u2208 \u03a3 (6), \u0393 \u22a2 v :A1 (7), Aop \u2261 A1 (8), \u0393, y :Bop \u22a2 c1 :A2 \u2032 !\u3008E \u2032\u3009 (9), and\n\u2113op \u2208 E \u2032 (10). The goal follows from facts 1, 4, 5, 6, 7, 8, 10, constructors SD-Hand and SD-Op, and Lemma E.6. \u2022 E-HandSc: By inversion on \u0393 \u22a2 h \u22c6 op \u2113op v (y . c1) : B !\u3008F2\u3009 (SD-Hand) we have that \u0393 \u22a2 h : C1 \u21d2 B !\u3008F2\u3009 (1), \u0393 \u22a2 \u2113\nsc v (y . c1) (z . c2) : C2 (2), and C1 \u2261 C2 (3). Inversion on fact 1 (SD-Handler) gives B = M A2, C1 = A2 !\u3008E1\u3009, and \u0393, \u03b1 \u22a2M oprs :M \u03b1 !\u3008F2\u3009 (4). Based on fact (3) we get that C2 = A2 \u2032 !\u3008E2\u3009, A2 \u2261 A2 \u2032 (5), and E1 \u2261 E2 (6). Inversion on fact 2 (SD-Sc) gives us \u2113sc :Asc _ Bsc \u2208 \u03a3 (7), \u0393 \u22a2 v :A1 (8), Asc \u2261 A1 (9), \u0393, y :Bsc \u22a2 c1 : A3 !\u3008E3\u3009 (10), \u0393, z : A3 \u22a2 c2 : A2 \u2032 !\u3008E2\u3009 (11), E3 \u2261 E2 (12), and \u2113 sc \u2208 E2 (13). Lemma E.8 we get that \u0393, \u03b1 \u22a2M op \u2113 op x k 7\u2192 c, oprs2 :M \u03b1 !\u3008F2\u3009 (13.1). Inversion\non fact 13.1 (SD-OprSc gives \u2113sc \u2208 \u03a3 (14), \u03b2 fresh (15), \u0393, \u03b1, \u03b2, x : Asc, p : Bsc \u2192 M \u03b2 !\u3008F3 \u3009, k : \u03b2 \u2192 M \u03b1 !\u3008F3 \u3009 \u22a2 c : M \u03b1 !\u3008F2\u3009 (16), and F2 \u2261 F3 (17). Facts 1, 5, 6, 10 and 12, constructors SD-Abs and SD-Hand and Lemmas E.6 and E.7 give us that \u0393, \u03b2 \u22a2 \u03bby . h \u22c6 c1 :p :Bsc \u2192 M \u03b2 !\u3008F2\u3009 (18). Facts 1, 5, 6 and 11 and constructors SD-Abs and SD-Hand and Lemma E.6 give us that \u0393, \u03b2 \u22a2 \u03bbz . h \u22c6 c2 :\u03b2 \u2192 M A2 !\u3008F2\u3009 (19). The goal now follows from facts 8, 9, 16, 17 and 18 and Lemma E.4. \u2022 E-FwdSc By inversion on \u0393 \u22a2 h \u22c6 op \u2113op v (y . c1) : B !\u3008F2\u3009 (SD-Hand) we have that \u0393 \u22a2 h : C1 \u21d2 B !\u3008F2\u3009 (1), \u0393 \u22a2 \u2113\nsc v (y . c1) (z . c2) : C2 (2), and C1 \u2261 C2 (3). Inversion on fact 1 (SD-Handler) gives B = M A2, C1 = A2 !\u3008E1\u3009, and \u0393, \u03b1 \u22a2M fwd f p k 7\u2192 cf : M \u03b1 !\u3008F2\u3009 (4). Based on fact (3) we get that C2 = A2 \u2032 !\u3008E2\u3009, A2 \u2261 A2 \u2032 (5), and E1 \u2261 E2 (6). Inversion on fact 2 (SD-Sc) gives us \u2113 sc : Asc _ Bsc \u2208 \u03a3 (7), \u0393 \u22a2 v : A1 (8), Asc \u2261 A1 (9), \u0393, y : Bsc \u22a2 c1 : A3 !\u3008E3\u3009 (10), \u0393, z : A3 \u22a2 c2 :A2 \u2032 !\u3008E2\u3009 (11), E3 \u2261 E2 (12), and \u2113sc \u2208 E2 (13). Inversion on fact 4 (SD-Fwd) gives Ap = \u03b1 \u2032 \u2192 M \u03b2 !\u3008F1\u3009, A\u2032p = \u03b1 \u2032 \u2192 \u03b3 !\u3008F1\u3009, Ak = \u03b2 \u2192 M A4 !\u3008F1\u3009, A \u2032 k = \u03b3 \u2192 \u03b4 !\u3008F1\u3009, \u0393, \u03b1, \u03b1 \u2032, \u03b2, p : Ap , k : Ak , f : \u2200 \u03b3 \u03b4 . (A\u2032p ,A \u2032 k )\u2192 \u03b4 !\u3008F1\u3009 \u22a2 cf :M \u03b1 !\u3008F2\u3009 (14) and M A1 !\u3008F1\u3009 \u2261 M \u03b1 !\u3008F2\u3009 (15). Facts 1, 6, 10 and 12, constructors SD-Abs and SD-Hand and Lemmas E.6 and E.7 give us that \u0393, \u03b1, y : Bsc \u22a2 h \u22c6 c1 :M A3 !\u3008F2\u3009 (16) Facts 1, 6, 10 and 12, constructors SD-Abs and SD-Hand and Lemma E.6 give us that \u0393, \u03b1 \u22a2 \u03bbz . h \u22c6 c2 : A3 \u2192 M A4 !\u3008F2\u3009 (17) Facts 7, 8, 9, 13, the fact that \u2113sc /\u2208 labels (oprs), constructors SD-Abs, SD-App and SD-Var and Lemma E.6 give us that \u0393, \u03b1, (p\u2032, k \u2032) : \u2200 \u03b3 \u03b4 . (Bsc \u2192 \u03b3 !\u3008F1\u3009, \u03b3 \u2192 \u03b4 !\u3008F1\u3009) \u22a2 sc \u2113sc v (y . p\u2032 y) (z . k \u2032 z ) : \u03b4 !\u3008F1\u3009 (18). Our goal then follows from facts 14, 15, 16, 17, 18 and Lemma E.4.\nE.3. Progress.\nTheorem 6.2 (Progress). If \u00b7 \u22a2 c : C, then either:\n\u2022 there exists a computation c\u2032 such that c c\u2032, or \u2022 c is in a normal form, which means it is in one of the following forms: (1) c = return v, (2) c = op \u2113op v (y . c\u2032), or (3) c = sc \u2113sc v (y . c1) (z . c2).\nProof. By induction on the typing derivation \u00b7 \u22a2 c : C.\n\u2022 SD-App: Here, \u00b7 \u22a2 v1 v2. Since v1 has type A \u2192 B !\u3008F \u3009, by Lemma E.1 it must be of shape \u03bbx . c, which means we can step by rule E-AppAbs. \u2022 SD-Do: Here, \u00b7 \u22a2 do x \u2190 c1 in c2 : C. By the induction hypothesis, c1 can either step (in which case we can step by E-Do), or it is a computation result. Every possible form has a corresponding reduction: if c1 = return v we can step by E-DoRet, if\nc1 = op \u2113 op v (y . c) we can step by E-DoOp, and if sc \u2113op v (y . c\u20321) (z . c \u2032 2) we can step\nby E-DoSc. \u2022 SD-Let: Here, \u00b7 \u22a2 let x = v in c : C, which means we can step by E-Let. \u2022 SD-Ret, SD-Op, and SD-Sc: all of these are computation results (forms 1, 2, and 3, resp.). \u2022 SD-Hand: Here \u00b7 \u22a2 v \u22c6 c :M A !\u3008F \u3009. By Lemma E.1, v is of shape h. By the induction hypothesis, c can either step (in which case we can step by E-Hand), or it is in a normal form. Proceed by case split on the three forms. (1) Case c = return v . Since \u00b7 \u22a2 h : C \u21d2 D, there must be some (return x 7\u2192 cr ) \u2208 h\nwhich means we can step by rule E-HandRet. (2) Case c = op \u2113op v (y . c\u2032). Depending on (op \u2113op x k 7\u2192 c) \u2208 h we can step by\nE-HandOp or E-FwdOp. (3) Case c = sc \u2113sc v (y . c1) (z . c2). If (sc \u2113\nsc x p k 7\u2192 c) \u2208 h, we can step by E-HandSc. If not, since \u00b7 \u22a2 h : C \u21d2 D, there must be some (fwd f p k 7\u2192 cf ) \u2208 h which means we can step by rule E-FwdSc.\nAppendix F. Type Inference\nF.1. Algorithmic Syntax. For type inference, we follow the approach of Koka [Lei14]. The syntax for types in our algorithmic system can be found in Figure 15. We add unification\nvariables \u03b1\u0302 for types and \u00b5\u0302 for rows to our syntax. The hat on types A\u0302, C\u0302, rows E\u0302 and\ncontexts \u0393\u0302 indicate that they may contain unification variables. Furthermore, we add unification worklists U to represent the collection of types or rows that need to be unified.\nThe type equivalence for algorithmic types is a trivial extension of type equivalence for the declarative system (Figure 7). The well-scopedness rules are also a trivial extension of Figure 9. Notice that we do not record unification variables in the contexts, so they are not checked in the well-scopedness rules. Finally, notice that we do not allow free type variables in the annotation of type operators M .\nF.2. Algorithmic Rules. Our type inference algorithm consists of algorithmic typing rules\nthat output a type A\u0302 and a substitution \u03b8. The judgment \u0393\u0302 \u22a2 v : A\u0302 \u22a3 \u03b8 states that under \u0393\u0302, a value v has algorithmic type A\u0302, giving a substitution \u03b8. This algorithm is based on Hindley-Milner\u2019s algorithm W [Mil78], assigning types or unification variables to each (sub)term and generating substitutions by solving unification constraints, originating from algorithmic rules.\nThe algorithmic type inference rules can be found in Figure 16 for values, Figure 17\nfor computations, and Figure 18 for handlers. In these rules, we use unification A\u0302 \u223c B\u0302 : \u03b8 which states that two types A\u0302 and B\u0302 can be unified, giving rise to a substitution \u03b8. The\nsame holds for the unification of rows E\u0302 \u223c F\u0302 : \u03b8 and the unification of computation types C\u0302 \u223c D\u0302 : \u03b8. We discuss the unification algorithm in more detail in Appendix F.3.\nThe most interesting case is the algorithmic handler rule. Here, we derive (unification) types for each of the subterms and require them to be a computation type with a type\nvariable (e.g., A\u03021 = \u03b1\u03021). Furthermore, all derived types of the subterms should be equivalent. We express this by unifying them (e.g., \u03b82\u03b1\u03021 !\u3008E\u03021\u3009 \u223c \u03b1\u03022 !\u3008E\u03022\u3009 : \u03b83). Then, we implicitly instantiate the resulting type using some fresh unification variable \u03b1\u03024.\nIn these inference rules, we use uv (A\u0302) to represent the set of unification variables in A\u0302. Furthermore, we use rng (\u03b8) to indicate the range of the substitution \u03b8.\n\u0393\u0302 \u22a2M return x 7\u2192 cr :M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b8 \u0393\u0302 \u22a2M oprs :M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b8\n\u0393\u0302 \u22a2M fwd f p k 7\u2192 c :M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b8\nReturn, operation, and forwarding typing\nF.3. Unification Algorithm. Our unification algorithm works in two steps, as shown in Figure 20.\nFirst, we \u03b2-reduce the value types and computation types (Figure 21). Then, we unify types or rows that occur in the unification worklist step by step (Figure 22). The unification algorithm _ transforms a unification worklist U1 and an initial substitution \u03b81 into a new unification worklist U2 and substitution \u03b82. It can be split in three parts. The first part deals with computation types. The unification of two computation types boils down to separately unifying their value types and row types. The second part concerns the unification of value types. We first pattern match on unit types, handler types, function types and tuples. Two (unification) type variables with the same name are considered equal.\nUnifying a unification variable with a type A\u0302 means substituting this unification variable\nby A\u0302 in the given substitution as well as in all occurrences in the remaining unification worklist.\nThe reasoning for unifying two rows is similar. The function find\u2113 E\u0302 extracts the label\n\u2113 from E\u0302 and returns the remaining part:\nfind\u2113 \u3008\u3009 = error find\u2113 \u00b5 = (\u00b5 \u2032, [\u3008\u2113 ;\u00b5\u2032\u3009 / \u00b5 ]) where \u00b5\u2032 is a fresh variable find\u2113 \u3008\u2113 \u2032 ; E\u0302\u3009 = (E\u0302, \u2205) where \u2113 = \u2113\u2032 find\u2113 \u3008\u2113 \u2032 ; E\u0302\u3009 = (\u3008\u2113\u2032 ; E\u0302\u2032\u3009, \u03b8) where \u2113 6= \u2113\u2032 and (E\u0302\u2032, \u03b8) = find\u2113 E\u0302\nThe function tail E\u0302 returns the last row variable if E\u0302 is open, and returns \u3008\u3009 if E\u0302 is closed.\nF.4. Lemmas for Proof. In order to prove the soundness and completeness of our type inference algorithm with respect to the declarative type system, we require the following helper lemmas. Figure 23 displays instantiation of contexts. The following lemmas hold for this instantiation.\nLemma F.1 (Instantiation instantiates bindings)."
        },
        {
            "heading": "If \u0393\u0302 \u0393 ; \u03b8 and x : \u03c3\u0302 \u2208 \u0393\u0302 then there exists some \u03c3 = \u03b8\u03c3\u0302 such that x : \u03c3 \u2208 \u0393.",
            "text": "Lemma F.2 (Inverse of Instantiation instantiates bindings). If \u0393\u0302 \u0393 ; \u03b8 and x : \u03c3 \u2208 \u0393\nthen there exists x : \u03c3\u0302 \u2208 \u0393\u0302 such that \u03c3 = \u03b8\u03c3\u0302.\nThe following lemma states that we can move substitutions from being instantiated to be applied to the context, and back.\nLemma F.3 (Moving subtitutions to instantiation).\nOne can move instantiations \u03b81 from being applied to \u0393\u0302 to being generated by environment instantiation and back. That is, \u03b81\u0393\u0302 \u0393 ; \u03b82 \u21d0\u21d2 \u0393\u0302 \u0393 ; \u03b82\u03b81.\nThe following lemma states that inferred substitutions are domain-restricted, i.e. they only substitute the unification variables in the context the and inferred type.\nLemma F.4 (Inferred substitutions are domain-restricted).\n\u2022 For all \u0393\u0302 \u22a2 v : A\u0302 \u22a3 \u03b8, \u03b8 = \u03b8|\u0393\u0302\u03b8|A\u0302. \u2022 For all \u0393\u0302 \u22a2 c : C\u0302 \u22a3 \u03b8, \u03b8 = \u03b8|\u0393\u0302\u03b8|C\u0302 .\nThe notation \u03b8|\u0393\u0302 represents the substitution generated by removing all substitution of\nunification variables that are not in \u0393\u0302 from \u03b8. Similarly, the notation \u03b8| A\u0302 (\u03b8| C\u0302 ) represents the substitution generated by removing all substitution of unification variables that are not\nin A\u0302 (C\u0302) from \u03b8. The following lemma states that we can split a substitution with respect to its domain restriction.\nLemma F.5 (Substitution split w.r.t domain restriction). If \u03b81 = \u03b82|\u0393\u0302, then there exists \u03b8 such that \u03b82 = \u03b8\u03b81.\nThe following lemma states that the unification algorithm is sound.\nLemma F.6 (Unification unifies). After unification, subtituted terms are equivalent. That is:\n\u2022 A\u0302 \u223c B\u0302 : \u03b8 =\u21d2 \u03b8A\u0302 \u2261 \u03b8B\u0302 \u2022 C\u0302 \u223c D\u0302 : \u03b8 =\u21d2 \u03b8C\u0302 \u2261 \u03b8D\u0302 \u2022 E\u0302 \u223c F\u0302 : \u03b8 =\u21d2 \u03b8E\u0302 \u2261 \u03b8F\u0302\nDually, the following lemma states that unification gives a principal unifier.\nLemma F.7 (Unification gives a principal unifier). The unification algorithm gives a principal unifier. That is:\n\u2022 \u03b8A\u0302 \u2261 \u03b8B\u0302 implies there exists \u03b81, \u03b82 such that A\u0302 \u223c B\u0302 : \u03b81, \u03b8 = \u03b82\u03b81. \u2022 \u03b8E\u0302 \u2261 \u03b8F\u0302 implies there exists \u03b81, \u03b82 such that E\u0302 \u223c F\u0302 : \u03b81, \u03b8 = \u03b82\u03b81. \u2022 \u03b8C\u0302 \u2261 \u03b8D\u0302 implies there exists \u03b81, \u03b82 such that C\u0302 \u223c D\u0302 : \u03b81, \u03b8 = \u03b82\u03b81.\nThe same holds for the instantiation algorithm. The following lemma states that it is sound and uses two helper lemmas to prove it.\nLemma F.8 (Algorithmic to declarative instantiation).\nFor all \u03c3\u0302 6 A\u0302 there exists a \u03b8 such that \u03b8\u03c3\u0302 6 \u03b8 A\u0302.\nProof. By induction on \u03c3\u0302 6 A\u0302, using Lemmas F.9 and F.10.\nLemma F.9 (Substitution/instantiation inlining). If \u03b1 /\u2208 \u03b8 then \u03b8[\u03b1\u0302 / \u03b1 ] \u03c3\u0302 = [\u03b8\u03b1\u0302 / \u03b1 ] \u03b8\u03c3\u0302.\nLemma F.10 (Substitution/instantiation inlining \u2013 Effects). If \u00b5 /\u2208 \u03b8 then \u03b8[\u00b5\u0302 / \u00b5 ] \u03c3\u0302 = [\u03b8\u00b5\u0302 / \u00b5 ] \u03b8\u03c3\u0302.\nThe following lemma is essentially the dual of Lemma F.8.\nTheorem F.11 (Declarative to algorithmic instantiation). For all \u03c3 6 A and \u03b8\u03c3\u0302 = \u03c3, there exists A\u0302 and \u03b8\u2032 such that \u03c3\u0302 6 A\u0302 and \u03b8\u2032\u03b8A\u0302 = A\nProof. Mutual induction on \u03c3 6 A and \u03c3\u0302 6 A\u0302.\nF.5. Soundness. In words, soundness states that all algorithmic typing judgments have a declarative counterpart. For proving this property, we ignore the differences in the domain of substitutions, which implies that the notion of equality is implicitly restricted to the substitution domain.\nTheorem F.12 (Soundness). All algorithmic typing judgments have a declarative counterpart:\n\u2022 \u2200 \u0393\u0302, v , A\u0302, \u03b8inf : if \u0393\u0302 \u22a2 v : A\u0302 \u22a3 \u03b8inf then \u2200 \u0393, \u03b8inst: if \u03b8inf\u0393\u0302 \u0393 ; \u03b8inst and \u2200 \u03b8 : \u0393 \u22a2 \u03b8 and \u03b8\u03b8instA\u0302 = A\nthen \u0393 \u22a2 v :A. \u2022 \u2200 \u0393\u0302, c, C\u0302, \u03b8inf : if \u0393\u0302 \u22a2 c : C\u0302 \u22a3 \u03b8inf then \u2200 \u0393, \u03b8inst: if \u03b8inf\u0393\u0302 \u0393 ; \u03b8inst and \u2200 \u03b8 : \u0393 \u22a2 \u03b8 and \u03b8\u03b8instC\u0302 = C then \u0393 \u22a2 c : C. \u2022 \u2200 \u0393\u0302,M , x , cr , A\u0302, E\u0302, \u03b8inf : if \u0393\u0302 \u22a2M return x 7\u2192 cr :M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b8inf\nthen \u2200 \u0393, \u03b8inst: if \u03b8inf\u0393\u0302 \u0393 ; \u03b8inst and \u2200 \u03b8 : \u0393 \u22a2 \u03b8 and \u03b8\u03b8inst(M A\u0302 !\u3008E\u0302\u3009) = M A !\u3008E \u3009\nthen \u0393 \u22a2 return x 7\u2192 cr :M A !\u3008E \u3009.\n\u2022 \u2200 \u0393\u0302,M , oprs , A\u0302, E\u0302, \u03b8inf : if \u0393\u0302 \u22a2M oprs :M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b8inf then \u2200 \u0393, \u03b8inst: if \u03b8inf\u0393\u0302 \u0393 ; \u03b8inst and \u2200 \u03b8 : \u0393 \u22a2 \u03b8 and \u03b8\u03b8inst(M A\u0302 !\u3008E\u0302\u3009) = M A !\u3008E \u3009\nthen \u0393 \u22a2 oprs :M A !\u3008E \u3009.\n\u2022 \u2200 \u0393\u0302,M , f , p, k , c, A\u0302, E\u0302, \u03b8inf : if \u0393\u0302 \u22a2M fwd f p k 7\u2192 c :M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b8inf then \u2200 \u0393, \u03b8inst: if \u03b8inf \u0393\u0302 \u0393 ; \u03b8inst and \u2200 \u03b8 : \u0393 \u22a2 \u03b8 and \u03b8\u03b8inst(M A\u0302 !\u3008E\u0302\u3009) = M A !\u3008E \u3009\nthen \u0393 \u22a2 fwd f p k 7\u2192 c :M A !\u3008E \u3009.\nProof. We prove the statement by mutual induction on these judgments. In what follows we ignore the differences in the domain of substitutions, implicitly restricting the notion of equality to the substitution domain."
        },
        {
            "heading": "Value typing.",
            "text": "A-Var We know that \u0393\u0302 \u22a2 x : A\u0302 \u22a3 \u2205 so we can choose \u0393, \u03b8inst such that \u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8instA\u0302 = A for some A (2).\nFrom Lemma F.1, (1) and (x : \u03c3\u0302) \u2208 \u0393\u0302 (A-Var), we have that (x : \u03b8inst\u03c3\u0302) \u2208 \u0393.\nFrom Lemma F.8, \u03c3\u0302 6 A\u0302 (A-Var) and (2), we have that \u03b8\u03b8inst\u03c3\u0302 6 \u03b8\u03b8instA\u0302.\nAs \u03b8 is applied after instantiation with \u03b8inst, it has no influence on \u03c3\u0302. Thus \u03b8\u03b8inst\u03c3\u0302 \u2261 \u03b8inst\u03c3\u0302 \u2261 \u03c3 (4).\nThus, we have that (x : \u03c3) \u2208 \u0393 and \u03c3 6 A (2) (4) so that \u0393 \u22a2 x :A (SD-Var). A-Unit Trivial case. A-Pair We know that \u0393\u0302 \u22a2 (v1, v2) : (\u03b82A\u0302, B\u0302) \u22a3 \u03b82..1 so we can choose \u0393, \u03b8inst such that\n\u03b82..1\u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst(\u03b82A\u0302, B\u0302) = (A,B) for some A,B (2).\nFrom the induction hypothesis for v1 we have the following: if \u0393\u0302 \u22a2 v1 : A\u0302 \u22a3 \u03b81 (A-Pair) then \u03b81\u0393\u0302 \u0393 ; \u03b8inst\u03b82 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b82A\u0302 = A (2) then \u0393 \u22a2 v1 : A.\nFrom the induction hypothesis for v2 we have the following: if \u03b81\u0393\u0302 \u22a2 v2 : B\u0302 \u22a3 \u03b82 (A-Pair) then \u03b82..1\u0393\u0302 \u0393 ; \u03b8inst (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8instB\u0302 = B (2) then \u0393 \u22a2 v2 : B .\nFrom (SD-Pair) we conclude that \u0393 \u22a2 (v1, v2) : (A,B).\nA-Abs We know that \u0393\u0302 \u22a2 \u03bbx . c : \u03b8inf \u03b1\u0302\u2192 C\u0302 \u22a3 \u03b8inf so we can choose \u0393, \u03b8inst such that \u03b8inf \u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst(\u03b8inf \u03b1\u0302\u2192 C\u0302) = A\u2192 C for some A, C (2).\nFrom the induction hypothesis for c we have the following:\nif \u0393\u0302, x : \u03b1\u0302 \u22a2 c : C\u0302 \u22a3 \u03b8inf (A-Abs) then \u03b8inf \u0393\u0302, x : \u03b1\u0302 \u03931 ; \u03b8inst (Lemma F.3, (1)) and \u2200 \u03b8 .\u03931 \u22a2 \u03b8 and \u03b8\u03b8instC\u0302 = C (2)\nthen \u03931 \u22a2 c : C.\nFrom (Lemma F.3), (1) and (2), we know that \u03931 = \u0393, x : \u03b8inst\u03b1\u0302 = \u0393, x : A, where \u03b8inst\u03b1\u0302 = \u03b8\u03b8inst\u03b8inf \u03b1\u0302 = A because only \u03b8inst influences the instantiation of \u03b1\u0302.\nFrom (SD-Abs) we conclude that \u0393, x :A \u22a2 \u03bbx . c : A\u2192 C.\nA-Handler We know that \u0393\u0302 \u22a2 handlerM {return x 7\u2192 cr , oprs , fwd f p k 7\u2192 cf } :\n\u03b1\u03024 !\u3008F\u0302 \u3009 \u21d2 M \u03b1\u03024 !\u3008\u03b85E\u03023\u3009 \u22a3 \u03b85..1 so we can choose \u0393, \u03b8inst such that \u03b85..1\u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst(\u03b1\u03024 !\u3008F\u0302 \u3009 \u21d2 M \u03b1\u03024 !\u3008\u03b85E\u03023\u3009) = \u03b1 !\u3008F \u3009 \u21d2 M \u03b1 !\u3008E \u3009 for some M , \u03b1,E ,F (2).\nFrom the induction hypothesis for fwd f p k 7\u2192 cf we have the following: if \u03b83..1\u0393\u0302 \u22a2M fwd f p k 7\u2192 cf :M \u03b1\u03023 !\u3008E\u03023\u3009 \u22a3 \u03b84 (A-Handler) then \u03b84\u03b83..1\u0393\u0302 \u0393 ; \u03b8inst\u03b85 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b85(M \u03b1\u03023 !\u3008E\u03023\u3009) = M \u03b1 !\u3008E \u3009 since (2) and \u03b1\u03024 = \u03b85\u03b1\u03023 (A-Hanlder) then \u0393 \u22a2 fwd f p k 7\u2192 cf :M \u03b1 !\u3008E \u3009.\nFrom the induction hypothesis for oprs we have the following:\nif \u03b81\u0393\u0302 \u22a2M oprs :M \u03b1\u03022 !\u3008E\u03022\u3009 \u22a3 \u03b82 (A-Handler) then \u03b82..1\u0393\u0302 \u0393 ; \u03b8inst\u03b85..3 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b85..3(M \u03b1\u03022 !\u3008E\u03022\u3009) = M \u03b1 !\u3008E \u3009 (3) then \u0393 \u22a2 oprs :M \u03b1 !\u3008E \u3009.\nwhere (3): \u03b8\u03b8inst\u03b85..3(M \u03b1\u03022 !\u3008E\u03022\u3009) (Lemma F.6, A-Handler)\n= \u03b8\u03b8inst\u03b85(M \u03b1\u03023 !\u3008E\u03023\u3009) (2), (A-Handler) = M \u03b1 !\u3008E \u3009\nFrom the induction hypothesis for return x 7\u2192 cr we have the following: if \u0393\u0302 \u22a2M return x 7\u2192 cr :M \u03b1\u03021 !\u3008E\u03021\u3009 \u22a3 \u03b81 (A-Handler) then \u03b81\u0393\u0302 \u0393 ; \u03b8inst\u03b85..2 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b85..2(M \u03b1\u03021 !\u3008E\u03021\u3009) = M \u03b1 !\u3008E \u3009 (4) then \u0393 \u22a2 return x 7\u2192 cr :M \u03b1 !\u3008E \u3009.\nwhere (4): \u03b8\u03b8inst\u03b85..2(M \u03b1\u03021 !\u3008E\u03021\u3009) (Lemma F.6, A-Handler)\n= \u03b8\u03b8inst\u03b85..3(M \u03b1\u03022 !\u3008E\u03022\u3009) (3) = M \u03b1 !\u3008E \u3009\nFurthermore, we have that \u3008F\u0302 \u3009 = \u3008labels (oprs) ; \u03b85E\u03023\u3009 and since substitutions preserve equivalence also F = \u03b8\u03b8instF\u0302 \u2261\u3008\u3009 labels (oprs) ; \u03b8\u03b8inst\u03b85E\u03023 = labels (oprs) ;E .\nFrom (SD-Handler) we conclude that \u0393 \u22a2 handlerM {return x 7\u2192 cr , oprs , fwd f p k 7\u2192 cf } : A !\u3008F \u3009 \u21d2 M A !\u3008E \u3009."
        },
        {
            "heading": "Computation typing.",
            "text": "A-App We know that \u0393\u0302 \u22a2 v1 v2 : \u03b83(\u03b1\u0302 !\u3008\u00b5\u0302\u3009) \u22a3 \u03b83..1 so we can choose \u0393, \u03b8inst such that\n\u03b83..1\u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83(\u03b1\u0302 !\u3008\u00b5\u0302\u3009) = C for some C (2).\nFrom the induction hypothesis for v2 we have the following: if \u03b81\u0393\u0302 \u22a2 v2 : A\u03022 \u22a3 \u03b82 (A-App) then \u03b82\u03b81\u0393\u0302 \u0393 ; \u03b8inst\u03b83 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83A\u03022 = A for some A (3) then \u0393 \u22a2 v2 : A.\nFrom the induction hypothesis for v1 we have the following: if \u0393\u0302 \u22a2 v1 : A\u03021 \u22a3 \u03b81 (A-App) then \u03b81\u0393\u0302 \u0393 ; \u03b8inst\u03b83..2 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83..2A\u03021 = A\u2192 C (4) then \u0393 \u22a2 v1 : A\u2192 C.\nwhere (4): \u03b8\u03b8inst\u03b83..2A\u03021 (Lemma F.6, A-App)\n= \u03b8\u03b8inst\u03b83(A\u03022 \u2192 \u03b1\u0302 !\u3008\u00b5\u0302\u3009) = \u03b8\u03b8inst\u03b83(A\u03022)\u2192 \u03b8\u03b8inst\u03b83\u03b1\u0302 !\u3008\u00b5\u0302\u3009 (2), (3) = A\u2192 C\nFrom (SD-App) we conclude that \u0393 \u22a2 v1 v2 : C.\nA-Let We know that \u0393\u0302 \u22a2 let x = v in c : C\u0302 \u22a3 \u03b82..1 so we can choose \u0393, \u03b8inst such that \u03b82..1\u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8instC\u0302 = C for some C (2).\nFrom the induction hypothesis for v we have the following:\nif \u0393\u0302, \u03b1, \u00b5 \u22a2 v : A\u0302 \u22a3 \u03b81 with \u03b1, \u00b5 /\u2208 \u0393\u0302 (A-Let) then \u03b81\u0393\u0302, \u03b1, \u00b5 \u03931 ; \u03b8inst (Lemma F.3, (1)) where \u03931 = \u0393, \u03b8inst\u03b82..1\u03b1, \u03b8inst\u03b82..1\u00b5 = \u0393, \u03b1, \u00b5, because \u03b1, \u00b5 /\u2208 \u03b82..1 and \u2200 \u03b8 .\u03931 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b82A\u0302 = A for some A (3) then \u03931 \u22a2 v : A.\nFrom the induction hypothesis for c we have the following:\nif \u03b81\u0393\u0302, x : \u03c3\u0302 \u22a2 c : C\u0302 \u22a3 \u03b82 with \u03c3\u0302 = \u2200 \u03b1 .\u2200 \u00b5 .\u2200 \u03b1\u0302 .\u2200 \u00b5\u0302 . A\u0302 (A-Let) then \u03b82(\u03b81\u0393\u0302, x : \u03c3\u0302) \u03932 ; \u03b8inst) (Lemma F.3, (1)) and \u2200 \u03b8 .\u03932 \u22a2 \u03b8 and \u03b8\u03b8instC\u0302 = C (2) then \u0393 \u22a2 c : C.\nFrom (Lemma F.3), (1) and (3), we know that \u03932 = \u0393, x : \u03b8inst\u03b82(\u2200 \u03b1 .\u2200 \u00b5 .\u2200 \u03b1\u0302 .\u2200 \u00b5\u0302 . A\u0302) = \u0393, x : \u2200 \u03b1 .\u2200 \u00b5 .A, where dom (\u03b8inst\u03b82) \u2229 (uv (A\u0302) \\ uv (\u03b81\u0393\u0302)) = \u2205.\nFrom (SD-Let) we conclude that \u0393 \u22a2 let x = v in c : C.\nA-Ret We know that \u0393\u0302 \u22a2 return v : A\u0302 !\u3008\u00b5\u0302\u3009 \u22a3 \u03b8inf so we can choose \u0393, \u03b8inst such that\n\u03b8inf \u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst(A\u0302 !\u3008\u00b5\u0302\u3009) = A !\u3008E \u3009 for some A,E (2).\nFrom the induction hypothesis for v we have the following:\nif \u0393\u0302 \u22a2 v : A\u0302 \u22a3 \u03b8inf (A-Ret) then \u03b8inf \u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8instA\u0302 = A (2) then \u0393 \u22a2 v :A.\nFrom (SD-Ret) we conclude that \u0393 \u22a2 return v :A !\u3008E \u3009.\nA-Do We know that \u0393\u0302 \u22a2 do x \u2190 c1 ; c2 : \u03b83(B\u0302 !\u3008F\u0302 \u3009) \u22a3 \u03b83..1 so we can choose \u0393, \u03b8inst such that \u03b83..1\u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83(B\u0302 !\u3008F\u0302 \u3009) = B !\u3008E \u3009 for some B ,E (2).\nFrom the induction hypothesis for c1 we have the following: if \u0393\u0302 \u22a2 c1 : A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b81 (A-Do) then \u03b81\u0393\u0302 \u0393 ; \u03b8inst\u03b83..2 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83..2(A\u0302 !\u3008E\u0302\u3009) = A !\u3008E \u3009 (3) then \u0393 \u22a2 c1 : A !\u3008E \u3009.\nwhere (3): \u03b8\u03b8inst\u03b83..2(A\u0302 !\u3008E\u0302\u3009) = \u03b8\u03b8inst\u03b83..2A\u0302 !\u3008\u03b8\u03b8inst\u03b83..2E\u0302\u3009 = A !\u3008\u03b8\u03b8inst\u03b83..2E\u0302\u3009 for some A (4) (Lemma F.6, A-Do)\n= A !\u3008\u03b8\u03b8inst\u03b83F\u0302 \u3009 (2) = A !\u3008E \u3009\nFrom the induction hypothesis for c2 we have the following: if \u03b81\u0393\u0302, x : A\u0302 \u22a2 c2 : B\u0302 !\u3008F\u0302 \u3009 \u22a3 \u03b82 (A-Do) then \u03b82(\u03b81\u0393\u0302, x : A\u0302) \u03932 ; \u03b8inst\u03b83 (Lemma F.3, (1)) and \u2200 \u03b8 .\u03932 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83(B\u0302 !\u3008F\u0302 \u3009) = B !\u3008E \u3009 (2) then \u03932 \u22a2 c2 : B !\u3008E \u3009.\nFrom (Lemma F.3), (1) and (4), we know that \u03932 = \u0393, x : \u03b8inst\u03b83..2A\u0302 = \u0393, x : A.\nFrom (SD-Do) we conclude that \u0393 \u22a2 do x \u2190 c1 ; c2 : B !\u3008E \u3009.\nA-Op We know that \u0393\u0302 \u22a2 op \u2113op v (y . c) : \u03b84(A\u0302 \u2032 !\u3008E\u0302\u3009) \u22a3 \u03b84..1 so we can choose \u0393, \u03b8inst such\nthat \u03b84..1\u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b84(A\u0302 \u2032 !\u3008E\u0302\u3009) = A !\u3008E \u3009 for some A,E (2).\nFrom the induction hypothesis for v we have the following:\nif \u0393\u0302 \u22a2 v : A\u0302 \u22a3 \u03b81 (A-Op) then \u03b81\u0393\u0302 \u0393 ; \u03b8inst\u03b84..2 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b84..2A\u0302 = Aop (3) then \u0393 \u22a2 v :Aop.\nwhere (3): \u03b8\u03b8inst\u03b84..2A\u0302 (Lemma F.6, A-Op) = \u03b8\u03b8inst\u03b84..2(Aop) = Aop\nFrom the induction hypothesis for c we have the following: if \u03b82\u0393\u0302, y :Bop \u22a2 c : A\u0302 \u2032 !\u3008E\u0302\u3009 \u22a3 \u03b83 (A-Op) then \u03b83(\u03b82..1\u0393\u0302, y : Bop) \u0393, y : Bop ; \u03b8inst\u03b84 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393, y : Bop \u22a2 \u03b8 and \u03b8\u03b8inst\u03b84(A\u0302 \u2032 !\u3008E\u0302\u3009) = A !\u3008E \u3009 (2) then \u0393, y :Bop \u22a2 c : A !\u3008E \u3009.\nFurthermore, from (A-Op) follows that (\u2113op : Aop _ Bop) \u2208 \u03a3. Following (A-Op) and Lemma F.6, we have that \u03b84\u3008E\u0302\u3009 \u2261 \u03b84\u3008\u2113 op ; \u00b5\u0302\u3009. Since substitutions preserve equivalence, we also have that E = \u03b8\u03b8inst\u03b84E\u0302 \u2261\u3008\u3009 \u03b8\u03b8inst\u03b84(\u2113 op ; \u00b5\u0302) = \u2113op,E \u2032 for some E \u2032 so that \u2113op \u2208 E .\nFrom (SD-Op) we conclude that \u0393 \u22a2 op \u2113op v (y . c) : A !\u3008E \u3009.\nA-Sc We know that \u0393\u0302 \u22a2 sc \u2113sc v (y . c1) (z . c2) : \u03b86(A\u0302 \u2032 !\u3008F\u0302 \u3009) \u22a3 \u03b86..1 so we can choose \u0393, \u03b8inst\nsuch that \u03b86..1\u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b86(A\u0302 \u2032 !\u3008F\u0302 \u3009) = A !\u3008E \u3009 for some A,E (2).\nFrom the induction hypothesis for v we have the following:\nif \u0393\u0302 \u22a2 v : A\u0302 \u22a3 \u03b81 (A-Sc) then \u03b81\u0393\u0302 \u0393 ; \u03b8inst\u03b86..2 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b86..2A\u0302 = Asc (3) then \u0393 \u22a2 v :Asc.\nwhere (3): \u03b8\u03b8inst\u03b86..2A\u0302 (Lemma F.6, A-Sc) = \u03b8\u03b8inst\u03b86..2(Asc) = Asc\nFrom the induction hypothesis for c1 we have the following: if \u03b82..1\u0393\u0302, y : Bsc \u22a2 c1 : B\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b83 (A-Sc) then \u03b83(\u03b82..1\u0393\u0302, y : Bsc) \u0393, y : Bsc ; \u03b8inst\u03b86..4 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393, y : Bsc \u22a2 \u03b8 and \u03b8\u03b8inst\u03b86..4(B\u0302 !\u3008E\u0302\u3009) = B !\u3008E \u3009 (4) then \u0393, y :Bsc \u22a2 c1 : B !\u3008E \u3009.\nwhere (4): \u03b8\u03b8inst\u03b86..4(B\u0302 !\u3008E\u0302\u3009) = \u03b8\u03b8inst\u03b86..4B\u0302 !\u3008\u03b8\u03b8inst\u03b86..4E\u0302\u3009 = B !\u3008\u03b8\u03b8inst\u03b86..4E\u0302\u3009 for some B (5) (Lemma F.6, A-Sc)\n= B !\u3008\u03b8\u03b8inst\u03b86F\u0302 \u3009 (2) = B !\u3008E \u3009\nFrom the induction hypothesis for c2 we have the following: if \u03b84..1\u0393\u0302, z : \u03b84B\u0302 \u22a2 c2 : A\u0302 \u2032 !\u3008F\u0302 \u3009 \u22a3 \u03b85 (A-Sc) then \u03b85(\u03b84..1\u0393\u0302, z :\u03b84B\u0302) \u03933 ; \u03b8inst\u03b86 (Lemma F.3, (1)) and \u2200 \u03b8 .\u03933 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b86(A\u0302 \u2032 !\u3008F\u0302 \u3009) = A !\u3008E \u3009 (2) then \u03933 \u22a2 c2 :A !\u3008E \u3009.\nFrom (Lemma F.3), (1) and (5), we know that \u03933 = \u0393, z : \u03b8inst\u03b86..4B\u0302 = \u0393, z : B .\nFurthermore, from (A-Sc) follows that (\u2113sc : Asc _ Bsc) \u2208 \u03a3. Following (A-Sc) and Lemma F.6, we have that \u03b84\u3008E\u0302\u3009 \u2261 \u03b84\u3008\u2113 sc ; \u00b5\u0302\u3009. Since substitutions preserve equivalence, we also have that E = \u03b8\u03b8inst\u03b86..4E\u0302 \u2261\u3008\u3009 \u03b8\u03b8inst\u03b86..4(\u2113 sc ; \u00b5\u0302) = \u2113sc,E \u2032 for some E \u2032 so that \u2113sc \u2208 E .\nFrom (SD-Sc) we conclude that \u0393 \u22a2 sc \u2113sc v (y . c1) (z . c2) : A !\u3008E \u3009.\nA-Hand We know that \u0393\u0302 \u22a2 v \u22c6 c : \u03b83(\u03b1\u0302 !\u3008\u00b5\u0302\u3009) \u22a3 \u03b83..1 so we can choose \u0393, \u03b8inst such that\n\u03b83..1\u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83(\u03b1\u0302 !\u3008\u00b5\u0302\u3009) = D for some D (2).\nFrom the induction hypothesis for c we have the following:\nif \u03b81\u0393\u0302 \u22a2 c : C\u0302 \u22a3 \u03b82 (A-Hand) then \u03b82..1\u0393\u0302 \u0393 ; \u03b8inst\u03b83 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83C\u0302 = C for some C (3) then \u0393 \u22a2 c : C.\nFrom the induction hypothesis for v we have the following:\nif \u0393\u0302 \u22a2 v : A\u0302 \u22a3 \u03b81 (A-Hand) then \u03b81\u0393\u0302 \u0393 ; \u03b8inst\u03b83..2 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83..2A\u0302 = C \u21d2 D (4) then \u0393 \u22a2 v : C \u21d2 D.\nwhere (4): \u03b8\u03b8inst\u03b83..2A\u0302 (Lemma F.6, A-App)\n= \u03b8\u03b8inst\u03b83(C\u0302 \u21d2 \u03b1\u0302 !\u3008\u00b5\u0302\u3009) = \u03b8\u03b8inst\u03b83(C\u0302)\u21d2 \u03b8\u03b8inst\u03b83\u03b1\u0302 !\u3008\u00b5\u0302\u3009 (2), (3) = C \u21d2 D\nFrom (SD-Hand) we conclude that \u0393 \u22a2 v \u22c6 c :D."
        },
        {
            "heading": "Return clause.",
            "text": "A-Return We know that \u0393\u0302 \u22a2M return x 7\u2192 cr : \u03b82..1(M \u03b1\u0302 !\u3008\u00b5\u0302\u3009) \u22a3 \u03b82..1 so we can choose \u0393, \u03b8inst such that\n\u03b82..1\u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b82..1(M \u03b1\u0302 !\u3008\u00b5\u0302\u3009) = M A !\u3008E \u3009 for some M ,A,E (2).\nFrom the induction hypothesis for cr we have the following: if \u0393\u0302, x : \u03b1\u0302 \u22a2 cr : C\u0302 \u22a3 \u03b81 (A-Abs)\nthen \u03b81(\u0393\u0302, x :\u03b1\u0302) \u03931 ; \u03b8inst\u03b82 (Lemma F.3, (1)) and \u2200 \u03b8 .\u03931 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b82C\u0302 = M A !\u3008E \u3009 (3) then \u03931 \u22a2 cr :M A !\u3008E \u3009.\nwhere (3): \u03b8\u03b8inst\u03b82C\u0302 (Lemma F.6, A-Return) = \u03b8\u03b8inst\u03b82..1(M \u03b1\u0302 !\u3008\u00b5\u0302\u3009) (2) = M A !\u3008E \u3009\nFrom (Lemma F.3), (1) and (2), we know that \u03931 = \u0393, x : \u03b8inst\u03b82..1\u03b1\u0302 = \u0393, x : A, where \u03b8inst\u03b82..1\u03b1\u0302 = \u03b8\u03b8inst\u03b82..1\u03b1\u0302 = A because \u03b8 does not influence the instantiation of \u03b1\u0302.\nFrom (SD-Return) we conclude that \u0393 \u22a2 return x 7\u2192 cr :M A !\u3008E \u3009."
        },
        {
            "heading": "Operation clauses.",
            "text": "A-Empty Trivial case: We know that \u0393\u0302 \u22a2M \u00b7 :M \u03b1\u0302 !\u3008\u00b5\u0302\u3009 \u22a3 \u2205 so we can choose \u0393, \u03b8inst such that\n\u0393\u0302 \u0393 ; \u03b8inst and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst(M \u03b1\u0302 !\u3008\u00b5\u0302\u3009) = M A !\u3008E \u3009 for some M ,A,E .\nFrom (SD-Empty) we conclude that \u0393 \u22a2 \u00b7 :M A !\u3008E \u3009.\nA-OprOp We know that \u0393\u0302 \u22a2M op \u2113 op x k 7\u2192 c, oprs : \u03b83..2(M A\u0302 !\u3008E\u0302\u3009) \u22a3 \u03b83..1 so we can\nchoose \u0393, \u03b8inst such that \u03b83..1\u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83..2(M A\u0302 !\u3008E\u0302\u3009) = M A !\u3008E \u3009 for some M ,A,E (2).\nFrom the induction hypothesis for oprs we have the following:\nif \u0393\u0302 \u22a2M oprs :M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b81 (A-OprOp) then \u03b81\u0393\u0302 \u0393 ; \u03b8inst\u03b83..2 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83..2M A\u0302 !\u3008E\u0302\u3009 = M A !\u3008E \u3009 (2) then \u0393 \u22a2 oprs :M A !\u3008E \u3009.\nFrom the induction hypothesis for c we have the following:\nif \u03b81\u0393\u0302, x :Aop, k : Bop \u2192 M A\u0302 !\u3008E\u0302\u3009 \u22a2 c : C \u22a3 \u03b82 (A-OprOp) then \u03b82(\u03b81\u0393\u0302, x : Aop, k : Bop \u2192 M A\u0302 !\u3008E\u0302\u3009) \u03932 ; \u03b8inst\u03b83 (Lemma F.3, (1)) and \u2200 \u03b8 .\u03932 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83C = M A !\u3008E \u3009 (3) then \u03932 \u22a2 c :M A !\u3008E \u3009.\nwhere (3): \u03b8\u03b8inst\u03b83C\u0302 (Lemma F.6, A-OprOp)\n= \u03b8\u03b8inst\u03b83..2(M A\u0302 !\u3008E\u0302\u3009) (2) = M A !\u3008E \u3009\nFrom (Lemma F.3), (1) and (2), we know that \u03932 = \u0393, x :Aop, k :Bop \u2192 \u03b8inst\u03b83..2(M A\u0302 !\u3008E\u0302\u3009) = \u0393, x : Aop, k : Bop \u2192 M A !\u3008E \u3009.\nFrom (SD-OprOp) we conclude that \u0393 \u22a2 op \u2113op x k 7\u2192 c, oprs :M A !\u3008E \u3009.\nA-OprSc We know that \u0393\u0302 \u22a2M sc \u2113 sc x p k 7\u2192 c, oprs : \u03b83..2(M A\u0302 !\u3008E\u0302\u3009) \u22a3 \u03b83..1 so we can\nchoose \u0393, \u03b8inst such that \u03b83..1\u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83..2(M A\u0302 !\u3008E\u0302\u3009) = M A !\u3008E \u3009 for some M ,A,E (2).\nFrom the induction hypothesis for oprs we have the following:\nif \u0393\u0302 \u22a2M oprs :M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b81 (A-OprOp) then \u03b81\u0393\u0302 \u0393 ; \u03b8inst\u03b83..2 (Lemma F.3, (1)) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83..2M A\u0302 !\u3008E\u0302\u3009 = M A !\u3008E \u3009 (2) then \u0393 \u22a2 oprs :M A !\u3008E \u3009.\nFrom the induction hypothesis for c we have the following:\nif \u03b81\u0393\u0302, \u03b2, x : Asc, p : Bsc \u2192 M \u03b2 !\u3008E \u3009, k : \u03b2 \u2192 M A\u0302 !\u3008E\u0302\u3009 \u22a2 c : C \u22a3 \u03b82 (A-OprOp) then \u03b82(\u03b81\u0393\u0302, \u03b2, x : Asc, p : Bsc \u2192 M \u03b2 !\u3008E \u3009, k : \u03b2 \u2192 M A\u0302 !\u3008E\u0302\u3009) \u03932 ; \u03b8inst\u03b83 (Lemma F.3, (1)) and \u2200 \u03b8 .\u03932 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b83C = M A !\u3008E \u3009 (3) then \u03932 \u22a2 c :M A !\u3008E \u3009.\nwhere (3): \u03b8\u03b8inst\u03b83C\u0302 (Lemma F.6, A-OprSc)\n= \u03b8\u03b8inst\u03b83..2(M A\u0302 !\u3008E\u0302\u3009) (2) = M A !\u3008E \u3009\nFrom (Lemma F.3), (1) and (2), we know that \u03932 = \u0393, \u03b2, x :Asc, p :Bsc \u2192 M \u03b2 !\u3008E\u0302\u3009, k :\u03b2 \u2192 \u03b8inst\u03b83..2(M A\u0302 !\u3008E\u0302\u3009) = \u0393, x :Asc, p :Bsc \u2192 M \u03b2 !\u3008E \u3009, k : \u03b2 \u2192 M A !\u3008E \u3009 because \u03b2 /\u2208 \u03b83..2.\nFrom (SD-OprSc) we conclude that \u0393 \u22a2 sc \u2113sc x p k 7\u2192 c, oprs :M A !\u3008E \u3009."
        },
        {
            "heading": "Forwarding clause.",
            "text": "A-Fwd We know that \u0393\u0302 \u22a2M fwd f p k 7\u2192 cf : \u03b82..1(M \u03b1\u0302 !\u3008\u00b5\u0302\u3009) \u22a3 \u03b82..1 so we can choose \u0393, \u03b8inst such that\n\u03b82..1\u0393\u0302 \u0393 ; \u03b8inst (1) and \u2200 \u03b8 .\u0393 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b82..1(M \u03b1\u0302 !\u3008\u00b5\u0302\u3009) = M A !\u3008E \u3009 for some M ,A,E (2).\nFrom the induction hypothesis for cf we have the following: if \u0393\u0302, \u03b1, \u03b2, p : A\u0302p , k : A\u0302k , f : \u2200 \u03b3 \u03b4 . (A\u0302 \u2032 p , A\u0302 \u2032 k )\u2192 \u03b4 !\u3008\u00b5\u0302\u3009) \u22a2 cf : C \u22a3 \u03b81 (A-OprOp) then \u03b81(\u0393\u0302, \u03b1, \u03b2, p : A\u0302p , k : A\u0302k , f : \u2200 \u03b3 \u03b4 . (A\u0302 \u2032 p , A\u0302 \u2032 k )\u2192 \u03b4 !\u3008\u00b5\u0302\u3009) \u03931 ; \u03b8inst\u03b82 (Lemma F.3, (1)) and \u2200 \u03b8 .\u03931 \u22a2 \u03b8 and \u03b8\u03b8inst\u03b82C = M A !\u3008E \u3009 (3) then \u03931 \u22a2 cf :M A !\u3008E \u3009.\nwhere (3): \u03b8\u03b8inst\u03b82C\u0302 (Lemma F.6, A-Fwd) = \u03b8\u03b8inst\u03b82..1(M \u03b1\u0302 !\u3008\u00b5\u0302\u3009) (2)\n= M A !\u3008E \u3009\nFrom (Lemma F.3), (1) and (2), we know that \u03931 = \u0393, \u03b8inst\u03b82..1\u03b1, \u03b8inst\u03b82..1\u03b2 p:\u03b8inst\u03b82..1A\u0302p , k : \u03b8inst\u03b82..1A\u0302k , f :\u2200 \u03b3 \u03b4 . (\u03b8inst\u03b82..1A\u0302 \u2032 p , \u03b8inst\u03b82..1A\u0302 \u2032 k )\u2192 \u03b8inst\u03b82..1(\u03b4 !\u3008\u00b5\u0302\u3009) = \u0393, \u03b1, \u03b2, p :Ap , k :Ak , f : \u2200 \u03b3 \u03b4 . (A\u2032p ,A \u2032 k )\u2192 M A !\u3008E \u3009.\nFrom (SD-Fwd) we conclude that \u0393 \u22a2 fwd f p k 7\u2192 cf :M A !\u3008E \u3009.\nF.6. Completeness. Completeness states that all declarative typing judgments have a algorithmic counterpart.\nTheorem F.13 (Completeness). All declarative typing judgments have an algorithmic counterpart:\n\u2022 If \u0393 \u22a2 v :A then for all \u0393\u0302 and \u03b8a , if \u0393\u0302 \u0393 ; \u03b8a then there exists A\u0302, \u03b8inf , \u03b8inst, \u03b8d such that \u03b8a = (\u03b8inst\u03b8inf)|\u0393\u0302, \u0393\u0302 \u22a2 v : A\u0302 \u22a3 \u03b8inf , and \u03b8d\u03b8instA\u0302 = A. \u2022 If \u0393 \u22a2 c : C then for all \u0393\u0302 and \u03b8a , if \u0393\u0302 \u0393 ; \u03b8a then there exists A\u0302, \u03b8inf , \u03b8inst, \u03b8d such that \u03b8a = (\u03b8inst\u03b8inf)|\u0393\u0302, \u0393\u0302 \u22a2 c : C\u0302 \u22a3 \u03b8inf , and \u03b8d\u03b8instC\u0302 = C. \u2022 If \u0393 \u22a2 return x 7\u2192 cr : M A !\u3008E \u3009 then for all \u0393\u0302 and \u03b8a , if \u0393\u0302 \u0393 ; \u03b8a then there exists\nA\u0302, \u03b8inf , \u03b8inst, \u03b8d such that \u03b8a = (\u03b8inst\u03b8inf)|\u0393\u0302, \u0393\u0302 \u22a2M return x 7\u2192 cr : M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b8inf , and \u03b8d\u03b8instM A\u0302 !\u3008E\u0302\u3009 = M A !\u3008E \u3009. \u2022 If \u0393 \u22a2 oprs :M A !\u3008E \u3009 then for all \u0393\u0302 and \u03b8a , if \u0393\u0302 \u0393 ; \u03b8a then there exists A\u0302, \u03b8inf , \u03b8inst, \u03b8d such that \u03b8a = (\u03b8inst\u03b8inf)|\u0393\u0302, \u0393\u0302 \u22a2M oprs :M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b8inf , and \u03b8d\u03b8instM A\u0302 !\u3008E\u0302\u3009 = M A !\u3008E \u3009. \u2022 If \u0393 \u22a2 fwd f p k 7\u2192 cf :M A !\u3008E \u3009 then for all \u0393\u0302 and \u03b8a , if \u0393\u0302 \u0393 ; \u03b8a then there exists\nA\u0302, \u03b8inf , \u03b8inst, \u03b8d such that \u03b8a = (\u03b8inst\u03b8inf)|\u0393\u0302, \u0393\u0302 \u22a2M fwd f p k 7\u2192 cf :M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b8inf , and \u03b8d\u03b8instM A\u0302 !\u3008E\u0302\u3009 = M A !\u3008E \u3009.\nProof. Note that by Lemma F.3, \u0393\u0302 \u0393 ; \u03b8a , and \u03b8a = (\u03b8inst\u03b8inf)|\u0393\u0302, we can derive that \u03b8inf \u0393\u0302 \u0393 ; \u03b8inst. In the following proof, we treat it as part of the conclusion of the theorem for simplicity. Also, we do not deal with the equivalence relations of types explicitly. All comparisons between types are considered to use equivalence relations implicitly.\nProve by mutual induction on these judgments."
        },
        {
            "heading": "Value typing.",
            "text": "SD-Var For any \u0393\u0302 \u0393 ; \u03b8a , let \u03b8inst = \u03b8a and \u03b8inf = \u2205. By Lemma F.2 and (x : \u03c3) \u2208 \u0393 we\nget that there exists (x : \u03c3\u0302) \u2208 \u0393\u0302 such that \u03b8a \u03c3\u0302 = \u03c3. By Theorem F.11 and \u0393 \u22a2 \u03b8a \u03c3\u0302 6 A, there exists \u03b8d and A\u0302 such that \u03b8d\u03b8aA\u0302 = A = \u03b8d\u03b8instA\u0302 and \u03c3\u0302 6 A\u0302. Then, \u0393 \u22a2 A gives us \u0393\u0302 \u22a2 A\u0302. Thus, by A-Var, we have \u0393\u0302 \u22a2 x : A\u0302 \u22a3 \u03b8inf . We also have \u03b8a = \u03b8inst\u03b8inf and \u03b8inf \u0393\u0302 \u0393 ; \u03b8inst. It is easy to check the conclusion is satisfied given \u03b8a , \u03b8inf , \u03b8inst, \u03b8d defined as above. SD-Unit Let \u03b8inst = \u03b8a and \u03b8d = \u03b8inf = \u2205. The conclusion follows from the assumptions. SD-Pair By the IH on v1, for any \u0393\u0302 \u0393 ; \u03b81, there exists \u03b82, \u03b83, \u03b84 such that \u03b81 = \u03b83\u03b82|\u0393\u0302 (\u0393\u0302),\n\u0393\u0302 \u22a2 v1 : A\u0302 \u22a3 \u03b82, \u03b82\u0393\u0302 \u0393 ; \u03b83 (1), and \u03b84\u03b83A\u0302 = A.\nThen we apply the IH on v2 to (1), there exists \u03b86, \u03b87, \u03b88 such that \u03b83 = \u03b87\u03b86|\u03b82\u0393\u0302, \u03b82\u0393\u0302 \u22a2 v2 : B\u0302 \u22a3 \u03b86, \u03b86\u03b82\u0393\u0302 \u0393 ; \u03b87, \u03b88\u03b87B\u0302 = B . By A-Pair, we have \u0393\u0302 \u22a2 (v1, v2) : (\u03b86A\u0302, B\u0302) \u22a3 \u03b86\u03b82. Setting \u03b8a = \u03b81, \u03b8inf = \u03b86\u03b82, \u03b8inst = \u03b87, and \u03b8d = \u03b84\u03b88, the conclusion is satisfied: \u2013 \u03b81 = \u03b87\u03b86\u03b82|\u0393\u0302 \u2013 \u03b86\u03b82\u0393\u0302 \u0393 ; \u03b87 \u2013 \u03b84\u03b88\u03b87(\u03b86A\u0302, B\u0302) = (A,B) (the new unification variables in A\u0302 and B\u0302 does not overlap) SD-Abs By IH on the function body c, for any \u0393\u0302, x : A\u0302 \u0393, x :A ; \u03b81, there exists \u03b82, \u03b83, \u03b84 such that \u03b81 = \u03b83\u03b82|\u0393\u0302 (\u0393\u0302), \u0393\u0302, x : A\u0302 \u22a2 c : C\u0302 \u22a3 \u03b82, \u03b82(\u0393\u0302, x : A\u0302) \u0393, x :A ; \u03b83, and \u03b84\u03b83C\u0302 = C.\nLet the arbitrary type A\u0302 be an fresh unification variable \u03b1\u0302, we have \u0393\u0302, x : \u03b1\u0302 \u22a2 c : C\u0302 \u22a3 \u03b82. By A-Abs, we have \u0393\u0302 \u22a2 \u03bbx . c : \u03b82\u03b1\u0302\u2192 C\u0302 \u22a3 \u03b82.\nSetting \u03b8a = \u03b81, \u03b8inf = \u03b82, \u03b8inst = \u03b83|\u03b82\u0393\u0302, and \u03b8d = \u03b84, the conclusion is satisfied.\nSD-Handler By the IH on the return clause, for any \u0393\u0302 \u0393 ; \u03b81, taking a fresh type\nvariable a that is not in \u0393\u0302 and \u0393. there exists \u03b82, \u03b83, \u03b84 such that \u03b81 = (\u03b83\u03b82)|\u0393\u0302, \u0393\u0302 \u22a2 return x 7\u2192 cr : M A\u03021 !\u3008E\u03021\u3009 \u22a3 \u03b82, \u03b82\u0393\u0302 \u0393 ; \u03b83, \u03b84\u03b83(M A\u03021 !\u3008E\u03021\u3009) = M a !\u3008E \u3009 (1). Because \u03b1 is a fresh type variable, A\u03021 must be an unification variable \u03b1\u03021.\nThen we apply the IH on the operation clauses oprs to \u03b82\u0393\u0302 \u0393 ; \u03b83, there exists \u03b86, \u03b87, \u03b88 such that \u03b83 = (\u03b87\u03b86)|\u03b82\u0393\u0302 (2), \u03b82\u0393\u0302 \u22a2 oprs : M A\u03022 !\u3008E\u03022\u3009 \u22a3 \u03b86, \u03b86\u03b82\u0393\u0302 \u0393 ; \u03b87 (3), \u03b88\u03b87(M A\u03022 !\u3008E\u03022\u3009) = M a !\u3008E \u3009 (4). Similarly, A\u03022 must be an unification variable \u03b1\u03022.\nBy (1), (2), and (4), we have \u03b84(\u03b87\u03b86)|\u03b82\u0393\u0302(M \u03b1\u03021 !\u3008E\u03021\u3009) = \u03b88\u03b87(M \u03b1\u03022 !\u3008E\u03022\u3009). Because the new unification variables in M \u03b1\u03021 !\u3008E\u03021\u3009 and M \u03b1\u03022 !\u3008E\u03022\u3009 do not overlap, we have \u03b88\u03b84\u03b87\u03b86(M \u03b1\u03021 !\u3008E\u03021\u3009) = \u03b88\u03b84\u03b87(M \u03b1\u03022 !\u3008E\u03022\u3009). By Lemma F.7, there exists \u03b8y , \u03b8x such that \u03b88\u03b84\u03b87 = \u03b8y\u03b8x and \u03b86(M \u03b1\u03021 !\u3008E\u03021\u3009) \u223c M \u03b1\u03022 !\u3008E\u03022\u3009 : \u03b8x . By restricting the domain to be \u03b86\u03b82\u0393\u0302, we have \u03b87|\u03b86\u03b82\u0393\u0302 = (\u03b8y\u03b8x )|\u03b86\u03b82\u0393\u0302 (5).\nBy (3) and (5), we have \u03b8x\u03b86\u03b82\u0393\u0302 \u0393 ; \u03b89, where \u03b89 = \u03b8y |\u03b8x \u03b86\u03b82\u0393\u0302. By the IH on the fwd clause, there exists \u03b810, \u03b811, \u03b812 such that \u03b89 = (\u03b811\u03b810)|\u03b8x \u03b86\u03b82\u0393\u0302 (6), \u03b8x\u03b86\u03b82\u0393\u0302 \u22a2 fwd f p k 7\u2192 cf :M A\u03023 !\u3008E\u03023\u3009 \u22a3 \u03b810, \u03b810\u03b8x\u03b86\u03b82\u0393\u0302 \u0393 ; \u03b811, \u03b812\u03b811(M A\u03023 !\u3008E\u03023\u3009) = M \u03b1 !\u3008E \u3009 (6). Similar to the above, A\u03023 must be an unification variable \u03b1\u03023.\nBy (4) and (7), we have \u03b88\u03b87(M A\u03022 !\u3008E\u03022\u3009) = \u03b812\u03b811(M A\u03023 !\u3008E\u03023\u3009). By (6) and the fact that new unification variables in M \u03b1\u03022 !\u3008E\u03022\u3009 and M \u03b1\u03023 !\u3008E\u03023\u3009 do not overlap, we have \u03b812\u03b8y\u03b811\u03b810\u03b8x (M A\u03022 !\u3008E\u03022\u3009) = \u03b812\u03b8y\u03b811(M A\u03023 !\u3008E\u03023\u3009). By Lemma F.7, there exists \u03b8 \u2032 y , \u03b8 \u2032 x such that \u03b812\u03b8y\u03b811 = \u03b8 \u2032 y\u03b8 \u2032 x and \u03b810\u03b8x (M A\u03022 !\u3008E\u03022\u3009) \u223c M A\u03023 !\u3008E\u03023\u3009 : \u03b8 \u2032 x . By restricting the domain to be \u03b810\u03b8x\u03b86\u03b82\u0393\u0302, we have \u03b811 = (\u03b8 \u2032 y\u03b8 \u2032 x )|\u03b810\u03b8x \u03b86\u03b82\u0393\u0302. Because \u03b8 \u2032 y\u03b8 \u2032 x (M \u03b1\u03023 !\u3008E\u03023\u3009) = \u03b812\u03b8y\u03b811(M \u03b1\u03023 !\u3008E\u03023\u3009) = M \u03b1 !\u3008E \u3009 and \u03b1 is fresh, we have that \u03b8 \u2032 x \u03b1\u03023 must be an unification variable \u03b1\u03024. Because \u03b8\u2032y \u03b1\u03024 = \u03b812\u03b8y\u03b811\u03b1\u03023 = \u03b812\u03b811\u03b1\u03023 = \u03b1, \u03b8 \u2032 y\u03b8 \u2032 x\u03b810\u03b8x\u03b86\u03b82\u0393\u0302 = \u03b811\u03b810\u03b8x\u03b86\u03b82\u0393\u0302 = \u0393, and \u03b1 /\u2208 \u0393, we have \u03b8\u2032y \u03b1\u03024 /\u2208 \u03b8 \u2032 y\u03b8 \u2032 x\u03b810\u03b8x\u03b86\u03b82\u0393\u0302, which leads to \u03b1\u03024 /\u2208 \u03b8 \u2032 x\u03b810\u03b8x\u03b86\u03b82\u0393\u0302 4.\nLet \u3008F\u0302 \u3009 = \u3008labels (oprs) ; \u03b8\u2032x E\u03023\u3009, by A-Handler, we have \u0393\u0302 \u22a2 handler {. . .} :\n\u03b1\u03024 !\u3008F\u0302 \u3009 \u21d2 M \u03b1\u03024 !\u3008\u03b8 \u2032 x E\u03023\u3009 \u22a3 \u03b8 \u2032 x\u03b810\u03b8x\u03b86\u03b82. Setting \u03b8a = \u03b81, \u03b8inf = \u03b8 \u2032 x\u03b810\u03b8x\u03b86\u03b82, \u03b8inst = \u03b8\u2032y |\u03b8\u2032x \u03b810\u03b8x \u03b86\u03b82\u0393\u0302 , and \u03b8d = \u03b8 \u2032 y , the conclusion is satisfied.\n4here \u03b1\u0302 /\u2208 \u0393\u0302 actually means \u03b1\u0302 /\u2208 fv (\u0393\u0302)"
        },
        {
            "heading": "Computation typing.",
            "text": "SD-Ret By the IH on the return value v , for any \u0393\u0302 \u0393 ; \u03b8a , there exists \u03b82, \u03b83, \u03b84 such\nthat \u03b8a = \u03b83\u03b82|\u0393\u0302, \u0393\u0302 \u22a2 return v : A\u0302 ! \u00b5\u0302 \u22a3 \u03b82, \u03b82 \u0393\u0302 \u0393 ; \u03b83, and \u03b84\u03b83A\u0302 = A. Take a fresh unification variable \u00b5\u0302, by A-Ret we have \u0393\u0302 \u22a2 return v : A\u0302 ! \u00b5\u0302 \u22a3 \u03b82. Setting \u03b8inf = \u03b82, \u03b8inst = \u03b83, and \u03b8d = [E / \u00b5\u0302 ]\u03b84, it is easy to check the conclusion is\nsatisfied. SD-App By the IH on v1, for any \u0393\u0302 \u0393 ; \u03b81, there exists \u03b82, \u03b83, \u03b84 such that \u03b81 = \u03b83\u03b82|\u0393\u0302 (\u0393\u0302),\n\u0393\u0302 \u22a2 v1 : A\u03021 \u22a3 \u03b82, \u03b82\u0393\u0302 \u0393 ; \u03b83, and \u03b84\u03b83A\u03021 = A\u2192 C. Then we apply the IH on v2 to the judgement \u03b82\u0393\u0302 \u0393 ; \u03b83, which gives us that there exists \u03b86, \u03b87, \u03b88 such that \u03b83 = \u03b87\u03b86|\u03b82\u0393\u0302, \u03b82\u0393\u0302 \u22a2 v2 : A\u03022 \u22a3 \u03b86, \u03b86\u03b82\u0393\u0302 \u0393 : \u03b87, and \u03b88\u03b87A\u03022 = A. Let C = B !\u3008E \u3009, and take fresh unification variables \u03b1\u0302, \u00b5\u0302, we have [B / \u03b1\u0302,E / \u00b5\u0302 ]\u03b88\u03b87(A\u03022 \u2192 \u03b1\u0302 !\u3008\u00b5\u0302\u3009) = A\u2192 C = \u03b84\u03b83A\u03021 = \u03b84\u03b87\u03b86A\u03021. Note that \u03b84 only substitutes new unification variables in \u03b83A\u03021 = \u03b87\u03b86A\u03021, and [B/\u03b1\u0302,E / \u00b5\u0302]\u03b88 only substitutes new unification variables in \u03b87(A\u03022 \u2192 \u03b1\u0302 !\u3008\u00b5\u0302\u3009), we have the equation [B /\u03b1\u0302,E /\u00b5\u0302]\u03b88\u03b84\u03b87(\u03b86A\u03021) = [B /\u03b1\u0302,E /\u00b5\u0302 ]\u03b88\u03b84\u03b87(A\u03022 \u2192 \u03b1\u0302 !\u3008\u00b5\u0302\u3009). By Lemma F.7, there exists \u03b810, \u03b89 such that \u03b86A\u03021 \u223c (A\u03022 \u2192 \u03b1\u0302 !\u3008\u00b5\u0302\u3009) : \u03b89 and [B / \u03b1\u0302,E / \u00b5\u0302]\u03b88\u03b84\u03b87 = \u03b810\u03b89. Restricting the domain to be \u0393\u0302, we have \u03b87 = (\u03b810\u03b89)|\u0393\u0302. By Lemma F.3, we have \u03b89\u03b86\u03b82\u0393\u0302 \u0393 : \u03b810|\u0393\u0302. By A-App, we have \u0393\u0302 \u22a2 v1 v2 : \u03b89\u03b1\u0302 !\u3008\u00b5\u0302\u3009 \u22a3 \u03b89\u03b86\u03b82. Setting \u03b8a = \u03b81, \u03b8inf = \u03b89\u03b86\u03b82, \u03b8inst = \u03b810|\u0393\u0302, and \u03b8d = [B / \u03b1\u0302,E / \u00b5\u0302], it is easy to check\nthe conclusion of the theorem is satisfied. SD-Do By the IH on c1, for any \u0393\u0302 \u0393 ; \u03b81, there exists \u03b82, \u03b83, \u03b84 such that \u03b81 = \u03b83\u03b82|\u0393\u0302,\n\u0393\u0302 \u22a2 c1 : A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b82, \u03b82\u0393\u0302 \u0393 ; \u03b83, and \u03b84\u03b83(A\u0302 !\u3008E\u0302\u3009) = A !\u3008E \u3009. By \u03b82\u0393\u0302 \u0393 ; \u03b83 and the fact that \u03b84 only substitutes unification variables in A\u0302, we have \u03b82\u0393\u0302, x : A\u0302 \u0393, x :A ; \u03b84\u03b83 (1).\nThen we apply the IH on c2 to (1), which gives that there exists \u03b86, \u03b87, \u03b88 such that \u03b84\u03b83 = \u03b87\u03b86|\u03b82\u0393\u0302,x :A\u0302, \u03b82\u0393\u0302, x :A\u0302 \u22a2 c2:B\u0302!F\u0302 \u22a3 \u03b86, \u03b86(\u03b82\u0393\u0302, x :A\u0302) \u0393, x :A:\u03b87, and \u03b88\u03b87(B\u0302 !\u3008F\u0302 \u3009) = B !\u3008E \u3009. We have \u03b88\u03b87F\u0302 = E and \u03b84\u03b83E\u0302 = E = \u03b87\u03b86E\u0302. Note that \u03b88 only substitutes new unification variables in \u03b87F\u0302 , we have \u03b88\u03b87F\u0302 = \u03b88\u03b87\u03b86E\u0302. Thus, by Lemma F.7, there exists \u03b89 and \u03b810 such that \u03b86E\u0302 \u223c F\u0302 : \u03b89, \u03b88\u03b87 = \u03b810\u03b89. Restricting the domain to be \u0393\u0302, we have \u03b87 = (\u03b810\u03b89)|\u0393\u0302. Thus, by Lemma F.3, we have \u03b89|\u0393\u0302\u03b86(\u03b82\u0393\u0302, x : A\u0302) \u0393, x :A : \u03b810|\u0393\u0302. By A-Do, we also have \u0393\u0302 \u22a2 do x \u2190 c1 ; c2 : \u03b89(B\u0302 !\u3008F\u0302 \u3009) \u22a3 \u03b89\u03b86\u03b82. Setting \u03b8a = \u03b81, \u03b8inf = \u03b89\u03b86\u03b82, \u03b8inst = \u03b810|\u0393\u0302, and \u03b8d = \u03b88, it is easy to check the conclusion is satisfied: \u2013 \u03b8a = \u03b81 = \u03b83\u03b82|\u0393\u0302 = \u03b84\u03b83\u03b82|\u0393\u0302 = \u03b87\u03b86\u03b82|\u0393\u0302 = (\u03b810\u03b89\u03b86\u03b82)|\u0393\u0302 = (\u03b8inst\u03b8inf)|\u0393\u0302 \u2013 \u0393\u0302 \u22a2 do x \u2190 c1 ; c2 : \u03b89(B\u0302 !\u3008F\u0302 \u3009) \u22a3 \u03b8inf \u2013 \u03b8inf \u0393\u0302 \u0393 ; \u03b8inst \u2013 \u03b8d\u03b8inst(B\u0302 !\u3008F\u0302 \u3009) = \u03b88\u03b810|\u0393\u0302\u03b89(B\u0302 !\u3008F\u0302 \u3009) = \u03b88\u03b810\u03b89(B\u0302 !\u3008F\u0302 \u3009) = \u03b88\u03b87(B\u0302 !\u3008F\u0302 \u3009) = B !\u3008E \u3009\nSD-Let By the IH on v , for all \u0393\u0302, \u03b1, \u00b5 \u0393, \u03b1, \u00b5 ; \u03b81, there exists \u03b82, \u03b83, \u03b84 such that \u03b81 =\n\u03b83\u03b82|\u0393\u0302, \u0393\u0302, \u03b1, \u00b5 \u22a2 v : A\u0302 \u22a3 \u03b82, \u03b82\u0393\u0302 \u0393 ; \u03b83, and \u03b84\u03b83A\u0302 = A. We define \u03b8x as the set of all substitutions in (\u03b84\u03b83)|A\u0302 which do not substitute any unification variable in fv (\u03b82\u0393\u0302). Let \u03c3 = \u2200 \u03b1 .\u2200 \u00b5 .A and \u03c3\u0302 = \u2200 \u03b1 .\u2200 \u00b5 . \u03b8x A\u0302. By \u03b84\u03b83A\u0302 = A, we have \u03b82\u0393\u0302, x : \u03c3\u0302 \u0393, x : \u03c3 ; \u03b83 (1).\nThen we apply the IH on c to (1), which gives us that there exists \u03b86, \u03b87, \u03b88 such that\n\u03b83 = \u03b87\u03b86|\u03b82\u0393\u0302, \u03b82\u0393\u0302, x : \u03c3\u0302 \u22a2 c : C\u0302 \u22a3 \u03b86 (2), \u03b86(\u03b82\u0393\u0302, x : \u03c3\u0302) \u0393, x : \u03c3 ; \u03b87, and \u03b88\u03b87C\u0302 = C.\nLet \u03b1\u0302 \u00b5\u0302 = uv (A\u0302) \u2212 uv (\u03b82\u0393\u0302) and \u03c3\u0302 \u2032 = \u2200 \u03b1 .\u2200 \u00b5 .\u2200 \u03b1\u0302 .\u2200 \u00b5\u0302 . A\u0302. If we replace the \u03c3\u0302 in (2) with \u03c3\u0302\u2032, by the fact that the substitution \u03b8x does not substitutes anything in \u03b82\u0393\u0302, the computation c is still well-typed, and there exists \u03b8y such that \u03b82\u0393\u0302, x : \u03c3\u0302 \u2032 \u22a2 c : C\u0302 \u2032 \u22a3 \u03b86 and \u03b8yC\u0302 \u2032 = C\u0302 and \u03b8y also does not substitutes anything in \u03b86\u03b82\u0393\u0302. Thus, \u03b82\u0393\u0302, x :\u03c3\u0302 \u2032 \u22a2 c:C\u0302 \u22a3 \u03b8y\u03b86. By A-Let, we have \u0393\u0302 \u22a2 let x = v in c : C\u0302 \u22a3 \u03b8y\u03b86\u03b82. Setting \u03b8a = \u03b81, \u03b8inf = \u03b8y\u03b86\u03b82, \u03b8inst = \u03b87, and \u03b8d = \u03b88, the conclusion is satisfied. SD-Op By the IH on v , for all \u0393\u0302 \u0393 ; \u03b81, there exists \u03b82, \u03b83, \u03b84 such that \u03b81 = \u03b83\u03b82|\u0393\u0302,\n\u0393\u0302 \u22a2 v : A\u0302\u2032 \u22a3 \u03b82, \u03b82\u0393\u0302 \u0393 ; \u03b83, and \u03b84\u03b83A\u0302 \u2032 = Aop. By Lemma F.7 and \u03b84\u03b83A\u0302 \u2032 = Aop, there exists \u03b8x , \u03b8y such that \u03b84\u03b83 = \u03b8y\u03b8x and A\u0302 \u2032 \u223c Aop : \u03b8x . By \u03b82\u0393\u0302 \u0393 ; \u03b83 and the fact that \u03b84 only substitutes new unification variables in A\u0302 \u2032, we have \u03b82\u0393\u0302 \u0393 ; \u03b84\u03b83. By restricting the domain to be \u03b82\u0393\u0302 and the fact that \u03b84 only substitutes new unification variables in A\u0302\u2032, we have (\u03b8y\u03b8x )|\u03b82\u0393\u0302 = (\u03b84\u03b83)|\u03b82\u0393\u0302 = \u03b83|\u03b82\u0393\u0302 = \u03b83. By \u03b82\u0393\u0302 \u0393 ; \u03b83 and Lemma F.3, we have \u03b8x\u03b82\u0393\u0302 \u0393 ; \u03b8z , where \u03b8z = \u03b8y |\u03b82\u0393\u0302.\nThen, we apply the IH on c to the juedgement \u03b8x\u03b82\u0393\u0302, y : Bop \u0393, y : Bop ; \u03b8z , there\nexists \u03b86, \u03b87, \u03b88 such that \u03b8z = \u03b87\u03b86, \u03b8x\u03b82\u0393\u0302, y : Bop \u22a2 c : A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b86, \u03b86(\u03b8x\u03b82\u0393\u0302, y : Bop) \u0393, y :Bop ; \u03b87, and \u03b88\u03b87(A\u0302 !\u3008E\u0302\u3009) = A !\u3008E \u3009. By Lemma F.7 and \u03b88\u03b87E\u0302 = E = \u03b88\u03b87E , there exists \u03b8\u2032x , \u03b8 \u2032 y such that \u03b88\u03b87 = \u03b8 \u2032 y\u03b8 \u2032 x and E\u0302 \u223c E : \u03b8 \u2032 x (1). Note that since \u2113\nop \u2208 E and the row type \u3008\u2113op ; \u00b5\u0302\u3009 is the most general type that explicitly contains label \u2113op, the unification of E\u0302 and \u3008\u2113op ; \u00b5\u0302\u3009 must succeed. Suppose E\u0302 \u223c \u3008\u2113op ; \u00b5\u0302\u3009 : \u03b89 (2) and E \u2261\u3008\u3009 \u2113 op ;E \u2032, by A-Op we have \u0393\u0302 \u22a2 op \u2113op v (y . c) : \u03b89(A\u0302 !\u3008E\u0302\u3009) \u22a3 \u03b89\u03b86\u03b8x\u03b82. Now we do a case analysis to prove that there exists \u03b810 such that \u03b87 = (\u03b810\u03b89)|\u03b86\u03b8x \u03b82\u0393\u0302: \u00b5\u0302 /\u2208 dom (\u03b89) : We have [E \u2032 / \u00b5\u0302]\u03b89E\u0302 = E . Thus, [E\n\u2032 / \u00b5\u0302]\u03b89 = (\u03b88\u03b87)|E\u0302. By Lemma F.5, there exists \u03b810 such that \u03b88\u03b87 = \u03b810[E \u2032 / \u00b5\u0302 ]\u03b89. By restircting the domains of the substitutions on both side of the equation to \u03b86\u03b8x\u03b82\u0393\u0302 and simplifying the equation, we have \u03b87 = (\u03b810\u03b89)|\u03b86\u03b8x \u03b82\u0393\u0302. \u00b5\u0302 \u2208 dom (\u03b89) : Let \u03b8 \u2032 9 be the substitution that generated from removing the substitution\nof \u00b5\u0302 from \u03b89. Suppose \u3008E \u3009 = \u3008\u2113 op ;E \u2032\u3009, by (1), we have \u03b8\u2032x [E \u2032 / \u00b5\u0302]E\u0302 = \u03b8\u2032x [E \u2032 / \u00b5\u0302]\u3008\u2113op ; \u00b5\u0302\u3009. By Lemma F.7 and (2), there exists \u03b811 such that \u03b8 \u2032 x [E\n\u2032 / \u00b5\u0302] = \u03b811\u03b89. Removing the substitution of \u00b5\u0302 from both sides of the equation, we have \u03b8\u2032x = \u03b811\u03b8 \u2032 9, where \u03b8 \u2032 9 is the substitution generated by removing the substitution of \u00b5\u0302 from \u03b89. Thus, by \u03b88\u03b87 = \u03b8 \u2032 y\u03b8 \u2032 x , we have \u03b88\u03b87 = \u03b8 \u2032 y\u03b811\u03b8 \u2032 9. By restricting the domain to be \u03b86\u03b8x\u03b82\u0393\u0302, we have \u03b87 = (\u03b8 \u2032 y\u03b811\u03b8 \u2032 9)|\u03b86\u03b8x \u03b82\u0393\u0302 = (\u03b8 \u2032 y\u03b811\u03b89)|\u03b86\u03b8x \u03b82\u0393\u0302\nFinally, setting \u03b8a = \u03b81, \u03b8inf = \u03b89\u03b86\u03b8x\u03b82, \u03b8inst = \u03b810|\u03b89\u03b86\u03b8x \u03b82\u0393\u0302 and \u03b8d = \u03b88, it is easy to check the conclusion is satisfied. SD-Sc By the IH on v , for any \u0393\u0302 \u0393 ; \u03b81, there exists \u03b82, \u03b83, \u03b84, such that \u03b81 = \u03b83\u03b82|\u0393\u0302,\n\u0393\u0302 \u22a2 v : A\u0302 \u22a3 \u03b82, \u03b82\u0393\u0302 \u0393 ; \u03b83, and \u03b84\u03b83A\u0302 = Asc. By Lemma F.7, there exists \u03b8y , \u03b8x such that \u03b84\u03b83 = \u03b8y\u03b8x and A\u0302 \u223c (Asc) : \u03b8x . By restricting the domain to be \u0393\u0302, we have \u03b83 = (\u03b84\u03b83)|\u03b82\u0393\u0302 = (\u03b8y\u03b8x )|\u03b82\u0393\u0302. By Lemma F.3, we have \u03b8x |\u0393\u0302\u03b82\u0393\u0302 \u0393 ; \u03b85 (1), where \u03b85 = \u03b8y |\u03b8x \u0393\u0302.\nThen we apply the IH on c1 to (1), which gives us that there exists \u03b86, \u03b87, \u03b88 such that \u03b85 = \u03b87\u03b86, \u03b8x\u03b82\u0393\u0302, y : Bsc \u22a2 c1 : B\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b86, \u03b86(\u03b8x\u03b82\u0393\u0302, y : Bsc) \u0393, y : Bsc ; \u03b87, and \u03b88\u03b87B\u0302 !\u3008E\u0302\u3009 = B !\u3008E \u3009. By Lemma F.7, there exists \u03b8 \u2032 y , \u03b8 \u2032 x such that \u03b88\u03b87 = \u03b8 \u2032 y\u03b8 \u2032 x and E\u0302 \u223c E :\u03b8\u2032x . Because \u2113 sc \u2208 E and \u3008\u2113sc ; \u00b5\u0302\u3009 is the most general row type containing label \u2113sc, there exists \u03b89 such that E\u0302 \u223c \u3008\u2113 sc ; \u00b5\u0302\u3009:\u03b89. By a similar case analysis to the SD-Sc case, we get that there exists \u03b810 such that \u03b87 = \u03b810\u03b89|\u03b86\u03b8x \u03b82\u0393\u0302. By Lemma F.3 and \u03b86\u03b8x\u03b82\u0393\u0302 \u0393 ; \u03b87, we have that \u03b89\u03b86\u03b8x\u03b82\u0393\u0302 \u0393 ; \u03b810, which implies \u03b89\u03b86\u03b8x\u03b82\u0393\u0302, z :\u03b89B\u0302 \u0393, z :B ; \u03b811 (2) where \u03b811 = \u03b88\u03b810.\nThen we apply the IH on c2 to (2), which gives us that there exists \u03b812, \u03b813, \u03b814 such that \u03b811 = \u03b813\u03b812, \u03b89\u03b86\u03b8x\u03b82\u0393\u0302, z : \u03b89B\u0302 \u22a2 c2 : A\u0302 \u2032 !\u3008F\u0302 \u3009 \u22a3 \u03b812, \u03b812(\u03b89\u03b86\u03b8x\u03b82\u0393\u0302, z : \u03b89B\u0302) \u0393, z :B ; \u03b813, and \u03b814\u03b813(A\u0302 \u2032 !\u3008F\u0302 \u3009) = A !\u3008E \u3009. By Lemma F.7, there exists \u03b8z , \u03b8w such that \u03b814\u03b813 = \u03b8z \u03b8w and F\u0302 \u223c E : \u03b8w . By restricting the domain to be \u0393\u0302 \u2032 = \u03b812\u03b89\u03b86\u03b8x\u03b82\u0393\u0302, we have \u03b813 = (\u03b814\u03b813)|\u0393\u0302\u2032 = (\u03b8z \u03b8w )|\u0393\u0302\u2032 .\nBy A-Sc, we have \u0393\u0302 \u22a2 sc \u2113sc v (y . c1) (z . c2) : \u03b8w (A\u0302 \u2032 !\u3008F\u0302 \u3009) \u22a3 \u03b8w\u03b812\u03b89\u03b86\u03b8x\u03b82. Setting\n\u03b8a = \u03b81, \u03b8inf = \u03b8w\u03b812\u03b89\u03b86\u03b8x\u03b82, \u03b8inst = \u03b8z |\u03b8w \u0393\u0302\u2032 , and \u03b8d = \u03b814, the conclusion is satisfied.\nSD-Hand By the IH on v , there exists \u03b82, \u03b83, \u03b84 such that \u03b81 = \u03b83\u03b82|\u0393\u0302, \u0393\u0302 \u22a2 v : A\u0302 \u22a3 \u03b82,\n\u03b82\u0393\u0302 \u0393 ; \u03b83 (1), and \u03b84\u03b83A\u0302 = C \u21d2 D. By \u03b83 = \u03b87\u03b86|\u03b82\u0393\u0302, we have \u03b84\u03b87(\u03b86A\u0302) = C \u21d2 D (1). Then we apply the IH on c to (1), which gives us that there exists \u03b86, \u03b87, \u03b88 such that \u03b83 = \u03b87\u03b86|\u03b82\u0393\u0302, \u03b82\u0393\u0302 \u22a2 c : C\u0302 \u22a3 \u03b86, \u03b86\u03b82\u0393\u0302 \u0393 ; \u03b87 (3), and \u03b88\u03b87C\u0302 = C. Taking two fresh unification variables \u03b1\u0302, \u00b5\u0302 and supposing D = A !\u3008E \u3009, we have [A / \u03b1\u0302,E / \u00b5\u0302 ]\u03b88\u03b87(C\u0302 \u21d2 \u03b1 !\u3008\u00b5\u3009) = C \u21d2 D (2).\nNotice that \u03b84 only substitutes new unification variables in A\u0302, and [A/ \u03b1\u0302,E / \u00b5\u0302 ]\u03b88 only substitutes new unification variables in (C\u0302 \u21d2 \u03b1 !\u3008\u00b5\u3009), we can combine (1) and (2) to get\nthe equation [A/\u03b1\u0302,E /\u00b5\u0302]\u03b88\u03b84\u03b87(\u03b86A\u0302) = [A/\u03b1\u0302,E /\u00b5\u0302]\u03b88\u03b84\u03b87(C\u0302 \u21d2 \u03b1 !\u3008\u00b5\u3009). By Lemma F.7, there exists \u03b8x , \u03b8y such that [A / \u03b1\u0302,E / \u00b5\u0302 ]\u03b88\u03b84\u03b87 = \u03b8y\u03b8x and \u03b86A\u0302 \u223c C\u0302 \u21d2 \u03b1\u0302 !\u3008\u00b5\u0302\u3009 : \u03b8x . By restricting the domain to be \u03b86\u03b82\u0393\u0302, we have \u03b87 = (\u03b8y\u03b8x )|\u03b86\u03b82\u0393\u0302.\nBy A-Hand, we have \u0393\u0302 \u22a2 v \u22c6 c : \u03b8x (\u03b1\u0302 !\u3008\u00b5\u0302\u3009) \u22a3 \u03b8x\u03b86\u03b82. By Lemma F.3 and (3), we have \u03b8x\u03b86\u03b82\u0393\u0302 \u0393 ; \u03b8y |\u03b8x \u03b86\u03b82\u0393\u0302. Setting \u03b8a = \u03b81, \u03b8inf = \u03b8x theta 6\u03b82, \u03b8inst = \u03b8y |\u03b8x \u03b86\u03b82\u0393\u0302, and \u03b8d = \u03b84, it is easy to check the conclusion is satisfied."
        },
        {
            "heading": "Return clause.",
            "text": "SD-Return Taking a fresh unification variable \u03b1\u0302, for any \u0393\u0302, x : \u03b1\u0302 \u0393, x : A ; \u03b81, there\nexists \u03b82, \u03b83, \u03b84 such that \u03b81 = \u03b83\u03b82|\u0393\u0302, \u0393\u0302, x : \u03b1\u0302 \u22a2 cr : C\u0302 \u22a3 \u03b82, \u03b82(\u0393\u0302, x : \u03b1\u0302) \u0393, x : A ; \u03b83 (1), and \u03b84\u03b83C\u0302 = M A !\u3008E \u3009. By (1), we have \u03b82\u0393\u0302 \u0393 ; \u03b83|\u03b82\u0393\u0302 (2).\nBecause \u03b81 = \u03b83\u03b82|\u0393\u0302 and \u03b81\u03b1\u0302 = A, we have M A ! E = [E / \u00b5\u0302 ]\u03b83\u03b82(M \u03b1\u0302 !\u3008\u00b5\u0302\u3009) = \u03b84\u03b83C\u0302. Note that \u03b84 only substitutes new unification variables in C\u0302, we have \u03b84[E / \u00b5\u0302]\u03b83\u03b82(M \u03b1\u0302 !\u3008\u00b5\u0302\u3009) = \u03b84[E / \u00b5\u0302]\u03b83C\u0302. By Lemma F.7, there exists \u03b8x , \u03b8y such that \u03b84[E / \u00b5\u0302]\u03b83 = \u03b8y\u03b8x and C\u0302 \u223c \u03b1\u0302 !\u3008\u00b5\u0302\u3009 : \u03b8x . By restricting the domain to be \u03b82\u0393\u0302, we have \u03b83|\u03b82\u0393\u0302 = (\u03b8y\u03b8x )|\u03b82\u0393\u0302.\nBy A-Return, we have \u0393\u0302 \u22a2 return x 7\u2192 cr : \u03b8x\u03b82(M \u03b1\u0302 !\u3008\u00b5\u0302\u3009) \u22a3 \u03b8x\u03b82. By (2) and Lemma F.3, we have \u03b8x\u03b82\u0393\u0302 \u0393 ; \u03b8y |\u03b8x \u03b82\u0393\u0302. Setting \u03b8a = \u03b81, \u03b8inf = \u03b8x\u03b82, \u03b8inst = \u03b8y |\u03b8x \u03b82\u0393\u0302, and \u03b8d = [E / \u00b5\u0302], it is easy to check the conclusion is satisfied."
        },
        {
            "heading": "Operation clauses.",
            "text": "SD-Empty Our goal is for any \u0393\u0302 \u0393 ; \u03b8a and fresh unification variables \u03b1\u0302, \u00b5\u0302, there\nexists \u03b8inf , \u03b8inst, \u03b8d such that \u03b8a = \u03b8inst\u03b8inf , \u0393\u0302 \u22a2 \u00b7 : M \u03b1\u0302 !\u3008\u00b5\u0302\u3009 \u22a3 \u03b8inf , \u03b8inf\u0393\u0302 \u0393 ; \u03b8inst, \u03b8d\u03b8inst(M \u03b1\u0302 !\u3008\u00b5\u0302\u3009) = M A !\u3008E \u3009. It is easy to check that setting \u03b8inf = \u2205, \u03b8inst = \u03b8a , and \u03b8d = [A / \u03b1\u0302,E / \u00b5\u0302] satisfies our goal. SD-OprOp By the IH on oprs , for any \u0393\u0302 \u0393 ; \u03b81, there exists \u03b82, \u03b83, \u03b84, A\u0302, E\u0302 such that\n\u03b81 = \u03b83\u03b82|\u0393\u0302, \u0393\u0302 \u22a2 oprs :M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b82, \u03b82\u0393\u0302 \u0393 ; \u03b83 (1), and \u03b84\u03b83(M A\u0302 !\u3008E\u0302\u3009) = M A !\u3008E \u3009 (2). Note that here we want \u03b84 to be minimal, i.e. \u03b84 = \u03b84|\u03b83(M A\u0302 ! \u3008E\u0302\u3009).\nBy (1) and (2), we have \u03b82\u0393\u0302, x : Aop, k : Bop \u2192 M A\u0302 !\u3008E\u0302\u3009 \u0393, x : Aop, k : Bop \u2192\nM A !\u3008E \u3009 ; \u03b84\u03b83 (3). Let \u0393\u0302 \u2032 = \u03b82\u0393\u0302, x : Aop, k : Bop \u2192 M A\u0302 !\u3008E\u0302\u3009 and \u0393 \u2032 = \u0393, x : Aop, k : Bop \u2192 M A !\u3008E \u3009. Applying the IH on c to (3), there exists \u03b86, \u03b87, \u03b88 such that \u03b84\u03b83 = \u03b87\u03b86|\u03b82\u0393\u0302,x :Aop,k :Bop\u2192M A\u0302 ! \u3008E\u0302\u3009, \u0393\u0302 \u2032 \u22a2 c : C\u0302 \u22a3 \u03b86, \u03b86\u0393\u0302 \u2032 \u0393\u2032 ; \u03b87, and \u03b88\u03b87C\u0302 = M A !\u3008E \u3009 (4).\nBy (2), (4), \u03b84\u03b83 = \u03b87\u03b86, and the fact that \u03b88 only substitutes new unification variables in C\u0302, we have \u03b88\u03b87\u03b86(M A\u0302 !\u3008E\u0302\u3009) = \u03b88\u03b87C\u0302. By Lemma F.7, there exists \u03b8y , \u03b8x such that \u03b88\u03b87 = \u03b8y\u03b8x and \u03b86(M A\u0302 !\u3008E\u0302\u3009) \u223c C\u0302 : \u03b8x . By restricting the domain to be \u03b82\u0393\u0302, we have \u03b87|\u03b82\u0393\u0302 = (\u03b8y\u03b8x )|\u03b82\u0393\u0302 (5).\nBy A-OprOp, we have \u0393\u0302 \u22a2M op \u2113 op x k 7\u2192 c, oprs : M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b8x\u03b86\u03b82. By \u03b86\u0393\u0302 \u2032 \u0393\u2032 ; \u03b87 and (5), we have \u03b8x\u03b86\u03b82\u0393\u0302 \u0393 ; \u03b8y |\u03b8x \u03b82\u0393\u0302. Setting \u03b8a = \u03b81, \u03b8inf = \u03b8x\u03b86\u03b82,\n\u03b8inst = \u03b8y |\u03b8x \u03b82\u0393\u0302, and \u03b8d = \u03b84, the conclusion is satisfied. SD-OprSc Similar to the case of SD-OprOp.\nBy the IH on oprs , for any \u0393\u0302 \u0393 ; \u03b81, there exists \u03b82, \u03b83, \u03b84, A\u0302, E\u0302 such that \u03b81 = \u03b83\u03b82|\u0393\u0302, \u0393\u0302 \u22a2 oprs : M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b82, \u03b82\u0393\u0302 \u0393 ; \u03b83 (1), and \u03b84\u03b83(M A\u0302 !\u3008E\u0302\u3009) = M A !\u3008E \u3009 (2). Note that here we want \u03b84 to be minimal, i.e. \u03b84 = \u03b84|\u03b83(M A\u0302 ! \u3008E\u0302\u3009).\nTake a fresh type variable \u03b2. By (1) and (2), we have \u03b82\u0393\u0302, \u03b2, x :Asc, p:Bsc \u2192 M \u03b2 !\u3008E\u0302\u3009, k : \u03b2 \u2192 M A\u0302 !\u3008E\u0302\u3009 \u0393, \u03b2, x : Asc, p : Bsc \u2192 M \u03b2 !\u3008E \u3009, k : \u03b2 \u2192 M A !\u3008E \u3009 ; \u03b84\u03b83 (3). Let \u0393\u0302\u2032 = \u03b82\u0393\u0302, \u03b2, x :Asc, p :Bsc \u2192 M \u03b2 !\u3008E\u0302\u3009, k : \u03b2 \u2192 M A\u0302 !\u3008E\u0302\u3009 and \u0393 \u2032 = \u0393, \u03b2, x :Asc, p :Bsc \u2192 M \u03b2 !\u3008E \u3009, k : \u03b2 \u2192 M A !\u3008E \u3009. Applying the IH on c to (3), there exists \u03b86, \u03b87, \u03b88 such that \u03b84\u03b83 = \u03b87\u03b86|\u03b82\u0393\u0302,x :Asc,p:Bsc\u2192M \u03b2 ! \u3008E\u0302\u3009,k :\u03b2\u2192M A\u0302 ! \u3008E\u0302\u3009, \u0393\u0302 \u2032 \u22a2 c : C\u0302 \u22a3 \u03b86, \u03b86\u0393\u0302 \u2032 \u0393\u2032 ; \u03b87, and \u03b88\u03b87C\u0302 = M A !\u3008E \u3009 (4). By (2), (4), \u03b84\u03b83 = \u03b87\u03b86, and the fact that \u03b88 only substitutes new unification variables in C\u0302, we have \u03b88\u03b87\u03b86(M A\u0302 !\u3008E\u0302\u3009) = \u03b88\u03b87C\u0302. By Lemma F.7, there exists \u03b8y , \u03b8x such that \u03b88\u03b87 = \u03b8y\u03b8x and \u03b86(M A\u0302 !\u3008E\u0302\u3009) \u223c C\u0302 : \u03b8x . By restricting the domain to be \u03b82\u0393\u0302, we have \u03b87|\u03b82\u0393\u0302 = (\u03b8y\u03b8x )|\u03b82\u0393\u0302 (5).\nSince \u03b2 is fresh, we have \u03b2 /\u2208 rng (\u03b82). By \u03b86\u0393\u0302 \u2032 \u0393\u2032 ; \u03b87, we have \u03b2 /\u2208 rng (\u03b86|\u0393\u0302\u2032).\nBecause \u03b87\u03b86(M A\u0302 !\u3008E\u0302\u3009) = M A !\u3008E \u3009, we have \u03b2 /\u2208 \u03b86(M A\u0302 !\u3008E\u0302\u3009). Thus, \u03b2 /\u2208 \u03b8x and \u03b2 /\u2208 \u03b86|C\u0302 . Thus, by Lemma F.4, we have \u03b2 /\u2208 rng (\u03b86). Finally, we have \u03b2 /\u2208 rng (\u03b8x\u03b86\u03b82).\nBy A-OprSc, we have \u0393\u0302 \u22a2M sc \u2113 sc x p k 7\u2192 c, oprs : M A\u0302 !\u3008E\u0302\u3009 \u22a3 \u03b8x\u03b86\u03b82. By \u03b86\u0393\u0302 \u2032 \u0393\u2032 ; \u03b87 and (5), we have \u03b8x\u03b86\u03b82\u0393\u0302 \u0393 ; \u03b8y |\u03b8x \u03b82\u0393\u0302. Setting \u03b8a = \u03b81, \u03b8inf = \u03b8x\u03b86\u03b82, \u03b8inst = \u03b8y |\u03b8x \u03b82\u0393\u0302, and \u03b8d = \u03b84, the conclusion is satisfied."
        },
        {
            "heading": "Forwarding clause.",
            "text": "SD-Fwd Take fresh unification variables \u03b1\u0302, \u00b5\u0302, fresh type variables \u03b1, \u03b2, and fresh type\nvariable names \u03b3, \u03b4. For any \u0393\u0302 \u0393 ; \u03b8a , we have \u0393\u0302, \u03b1, \u03b2, p : A\u0302p , k : A\u0302k , f :\u2200 \u03b3 \u03b4 . (A\u0302 \u2032 p , A\u0302 \u2032 k )\u2192 \u03b4 !\u3008\u00b5\u0302\u3009 \u0393, \u03b1, \u03b2, p : Ap , k : Ak , f : \u2200 \u03b3 \u03b4 . (A \u2032 p ,A \u2032 k ) \u2192 \u03b4 !\u3008E \u3009 ; [A / \u03b1\u0302,E / \u00b5\u0302]\u03b8a (1). All Ap ,Ak ,A \u2032 p ,A \u2032 k , A\u0302p , A\u0302k , A\u0302 \u2032 p , A\u0302 \u2032 k are defined the same as what are defined in rules SD-Fwd and A-Fwd. Let \u0393\u0302\u2032 = \u0393\u0302, \u03b1, \u03b2, p : A\u0302p , k : A\u0302k , f : \u2200 \u03b3 \u03b4 . (A\u0302 \u2032 p , A\u0302 \u2032 k ) \u2192 \u03b4 !\u3008\u00b5\u0302\u3009 and \u0393\n\u2032 = \u0393, \u03b1, \u03b2, p : Ap , k :Ak , f : \u2200 \u03b3 \u03b4 . (A \u2032 p ,A \u2032 k )\u2192 \u03b4 !\u3008E \u3009.\nApplying the IH on cf to (1), there exists \u03b82, \u03b83, \u03b84 such that\n\u03b83\u03b82|\u0393\u0302,p:A\u0302p ,k :A\u0302k ,f :\u2200 \u03b3 \u03b4 . (A\u0302\u2032p ,A\u0302\u2032k )\u2192\u03b4 ! \u3008\u00b5\u0302\u3009 = [A / \u03b1\u0302,E / \u00b5\u0302 ]\u03b8a , \u0393\u0302\n\u2032 \u22a2 cf : C\u0302 \u22a3 \u03b82, \u03b82\u0393\u0302 \u2032 \u0393\u2032 ; \u03b83 (2),\nand \u03b84\u03b83C\u0302 = M A !\u3008E \u3009. Because \u03b1\u0302 and \u00b5\u0302 are fresh, we have \u03b84[A / \u03b1\u0302,E / \u00b5\u0302]\u03b8a(m \u03b1\u0302 !\u3008\u00b5\u0302\u3009) = M A !\u3008E \u3009, which leads to \u03b84\u03b83\u03b82(m \u03b1\u0302 !\u3008\u00b5\u0302\u3009) = M A !\u3008E \u3009 = \u03b84\u03b83C\u0302. By Lemma F.7, there exists \u03b8x , \u03b8y such that \u03b84\u03b83 = \u03b8y\u03b8x and C\u0302 \u223c \u03b82(M \u03b1\u0302 !\u3008\u00b5\u0302\u3009) : \u03b8x . By restricting the domain to be \u03b82\u0393\u0302, we have \u03b83|\u03b82\u0393\u0302 = (\u03b8y , \u03b8x )|\u03b82\u0393\u0302.\nIt is obvious that \u03b3, \u03b4 /\u2208 rng (\u03b8x\u03b82) because they are bounded by universal quantifiers.\nBy \u03b86\u0393\u0302 \u2032 \u0393\u2032 ; \u03b87, we have \u03b1, \u03b2 /\u2208 rng (\u03b86|\u0393\u0302\u2032). Because \u03b87\u03b86(M A\u0302 !\u3008E\u0302\u3009) = M A !\u3008E \u3009, we have \u03b1, \u03b2 /\u2208 \u03b86(M A\u0302 !\u3008E\u0302\u3009). Thus, \u03b1, \u03b2 /\u2208 \u03b8x and \u03b1, \u03b2 /\u2208 \u03b86|C\u0302 . Thus, by Lemma F.4, we have \u03b1, \u03b2 /\u2208 rng (\u03b86). Finally, we have \u03b1, \u03b2, \u03b3, \u03b4 /\u2208 rng (\u03b8x\u03b86\u03b82).\nBy A-Fwd, we have \u0393\u0302 \u22a2M fwd f p k 7\u2192 cf : \u03b8x\u03b82(M \u03b1\u0302 !\u3008\u00b5\u0302\u3009) \u22a3 \u03b8x\u03b82. By (1) and Lemma F.3, we have \u03b8x\u03b82\u0393\u0302 \u0393 ; \u03b8y |\u03b8x \u03b82\u0393\u0302. Setting \u03b8inf = \u03b8x\u03b82, \u03b8inst = \u03b8y |\u03b8x \u03b82\u0393\u0302, and \u03b8d = [A / \u03b1\u0302,E / \u00b5\u0302], the conclusion is satisfied.\nF.7. Discussion. Our type inference algorithm works as is for most of the examples in Section 7. The type operators M used by a few handlers have additional type variables, which go beyond the basic type inference algorithm we have presented.\nFor example, the type of the handler of the reader with local handler in Section 7.2.2 is\nhread : \u2200 \u03b1 \u00b5 .\u03b1 ! \u3008ask ; local ;\u00b5\u3009 \u21d2 (Int\u2192 \u00b5 (\u03b1, Int))!\u3008\u00b5\u3009\nThus, for type inference, hread has the type annotation \u03bb\u03b1 . Int \u2192 \u00b5 (\u03b1, Int) which contains type variable \u00b5 that is bounded by \u2200 \u00b5 in the type of hread. Our basic algorithm does not allow free type variables in the annotation. We see several ways to generalize our algorithm to accommodate these examples. The first approach is to allow free type variables to occur in the type annotation and add the condition that the free variables in the annotation are not in the range of the inferred substitution of the handler typing judgment. This condition ensures that the free type variables in the annotation will not escape the lexical scope of the handler type. The new handler typing rule is shown in Figure 24. Another approach is to extend the type annotation of handlers from \u03bb\u03b1 .A to \u03bb\u03b1 .\u03bb\u00b5 .A to bind the extra type variable \u00b5. In this way, we also need to adjust the typing rules of the\n\u0393\u0302 \u22a2M return x 7\u2192 cr :M A\u03021 !\u3008E\u03021\u3009 \u22a3 \u03b81 A\u03021 = \u03b1\u03021 \u03b81\u0393\u0302 \u22a2M oprs :M A\u03022 !\u3008E\u03022\u3009 \u22a3 \u03b82 A\u03022 = \u03b1\u03022\nhandler and handler clauses to pass extra parameters to the type operatorM . This approach is less general than the first one, so we have used the first approach in our implementation.\nThis work is licensed under the Creative Commons Attribution License. To view a copy of this license, visit https://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, 171 Second St, Suite 300, San Francisco, CA 94105, USA, or Eisenacher Strasse 2, 10777 Berlin, Germany"
        }
    ],
    "title": "A Calculus for Scoped Effects & Handlers",
    "year": 2023
}