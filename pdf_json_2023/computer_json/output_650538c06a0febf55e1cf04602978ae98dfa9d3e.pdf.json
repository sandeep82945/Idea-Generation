{
    "abstractText": "\u00a9 The Author(s) 2023. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/. RESEARCH He et al. EURASIP Journal on Advances in Signal Processing (2023) 2023:68 https://doi.org/10.1186/s13634-023-01031-0 EURASIP Journal on Advances in Signal Processing",
    "authors": [
        {
            "affiliations": [],
            "name": "Tingting He"
        },
        {
            "affiliations": [],
            "name": "Biao Tian"
        },
        {
            "affiliations": [],
            "name": "Yu Wang"
        },
        {
            "affiliations": [],
            "name": "Shuai Li"
        },
        {
            "affiliations": [],
            "name": "Shiyou Xu"
        },
        {
            "affiliations": [],
            "name": "Zengping Chen"
        }
    ],
    "id": "SP:c5bec493655a5deae27615019a63663444cb7aef",
    "references": [
        {
            "authors": [
                "V.C. Chen",
                "M. Martorella"
            ],
            "title": "Inverse synthetic aperture radar imaging: Principles, algorithms and applications (Scitech",
            "year": 2014
        },
        {
            "authors": [
                "T. Sauer",
                "A. Schroth"
            ],
            "title": "Robust range alignment algorithm via hough transform in an isar imaging system",
            "venue": "IEEE Trans. Aerosp. Electron. Syst 31(3),",
            "year": 2002
        },
        {
            "authors": [
                "J. Wang",
                "D. Kasilingam"
            ],
            "title": "Global range alignment for isar",
            "venue": "IEEE Trans. Aerosp. Electron. Syst. 39(1),",
            "year": 2003
        },
        {
            "authors": [
                "D. Zhu",
                "W. Ling",
                "Y. Yu",
                "Q. Tao",
                "Z. Zhu"
            ],
            "title": "Robust isar range alignment via minimizing the entropy of the average range profile",
            "venue": "IEEE Geosci. Remote Sens. Lett. 6(2),",
            "year": 2009
        },
        {
            "authors": [
                "L. Zhang",
                "J.L. Sheng",
                "J. Duan",
                "M.D. Xing",
                "Z.J. Qiao",
                "Z. Bao"
            ],
            "title": "Translational motion compensation for isar imaging under low snr by minimum entropy",
            "venue": "EURASIP J. Adv. Signal Process 2013(1),",
            "year": 2013
        },
        {
            "authors": [
                "D.E. Wahl",
                "D.G.C.J.J.P.H"
            ],
            "title": "Eichel, Phase gradient autofocus-a robust tool for high resolution sar phase correction",
            "venue": "IEEE Trans. Aerosp. Electron. Syst",
            "year": 1994
        },
        {
            "authors": [
                "F. Berizzi",
                "G. Corsini"
            ],
            "title": "Autofocusing of inverse synthetic aperture radar images using contrast optimization",
            "venue": "IEEE Trans. Aerosp. Electron. Syst",
            "year": 1996
        },
        {
            "authors": [
                "P. Cao",
                "M. Xing",
                "G. Sun",
                "Y. Li",
                "Z. Bao"
            ],
            "title": "Minimum entropy via subspace for isar autofocus",
            "venue": "IEEE Geosci. Remote Sens. Lett. 7(1),",
            "year": 2010
        },
        {
            "authors": [
                "M. Xing",
                "R. Wu",
                "J. Lan",
                "Z. Bao"
            ],
            "title": "Migration through resolution cell compensation in isar imaging",
            "venue": "IEEE Geosci. Remote Sens. Lett. 1(2),",
            "year": 2004
        },
        {
            "authors": [
                "F.J.M. Munoz-Ferreras"
            ],
            "title": "Perez-Martfnez, Uniform rotational motion compensation for inverse synthetic aperture radar with non-cooperative targets",
            "venue": "Radar Sonar Navig",
            "year": 2008
        },
        {
            "authors": [
                "G. Xu",
                "M. Xing",
                "L. Zhang",
                "Y. Liu",
                "Y. Li"
            ],
            "title": "Bayesian inverse synthetic aperture radar imaging",
            "venue": "IEEE Geosci. Remote Sens. Lett. 8(6),",
            "year": 2011
        },
        {
            "authors": [
                "M.X.W. Chen",
                "B. Zheng"
            ],
            "title": "Keystone transformation based isar imaging at the low snr level",
            "venue": "J. Xidian Univ. 30(2),",
            "year": 2003
        },
        {
            "authors": [
                "D. Ustun",
                "C. Ozdemir",
                "A. Akdagli",
                "A. Toktas",
                "M.B. Bicer"
            ],
            "title": "A powerful method based on artificial bee colony algorithm for translational motion compensation of isar image",
            "venue": "Microw. Opt. Technol. Lett. 56(11),",
            "year": 2014
        },
        {
            "authors": [
                "Y. Li",
                "T. Zhang",
                "Z. Ding",
                "W. Gao",
                "J. Chen"
            ],
            "title": "An improved inverse synthetic aperture radar range alignment method based on maximum contrast",
            "venue": "J. Eng. 2019(19),",
            "year": 2019
        },
        {
            "authors": [
                "Y. Liu",
                "L. Wang",
                "G. Bi",
                "H. Liu",
                "H. Bi"
            ],
            "title": "Novel isar range alignment via minimizing the entropy of the sum range profile",
            "venue": "21st International Radar Symposium (IRS), pp",
            "year": 2020
        },
        {
            "authors": [
                "L. Liu",
                "F. Zhou",
                "M. Tao",
                "P. Sun",
                "Z. Zhang"
            ],
            "title": "Adaptive translational motion compensation method for isar imaging under low snr based on particle swarm optimization",
            "venue": "IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 8(11),",
            "year": 2015
        },
        {
            "authors": [
                "Z. Ding",
                "G. Zhang",
                "T. Zhang",
                "Y. Gao",
                "K. Zhu",
                "L. Li",
                "Y. Wei"
            ],
            "title": "An improved parametric translational motion compensation algorithm for targets with complex motion under low signal-to-noise ratios",
            "venue": "IEEE Trans. Geosci. Remote Sens. 60,",
            "year": 2022
        },
        {
            "authors": [
                "G. Xu",
                "M. Xing",
                "X.G. Xia",
                "Q.Q. Chen",
                "L. Zhang",
                "Z. Bao"
            ],
            "title": "High-resolution inverse synthetic aperture radar imaging and scaling with sparse aperture",
            "venue": "IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 8(8),",
            "year": 2015
        },
        {
            "authors": [
                "S. Jialian",
                "X. Mengdao",
                "Z. Lei",
                "M.Q. Mehmood",
                "Y. Lei"
            ],
            "title": "Isar cross-range scaling by using sharpness maximization",
            "venue": "Geosci. Remote Sens. Lett. IEEE 12(1),",
            "year": 2015
        },
        {
            "authors": [
                "S. Shao",
                "L. Zhang",
                "J. Wei",
                "H. Liu"
            ],
            "title": "Two-dimension joint super-resolution isar imaging with joint motion compensation and azimuth scaling",
            "venue": "IEEE Geosci. Remote Sens. Lett. 99,",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "\u00a9 The Author(s) 2023. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nKeywords: Inverse synthetic aperture radar (ISAR) imaging, Low signal-to-noise ratio (SNR), Particle swarm optimization (PSO), Motion compensation and azimuth scaling\n1 Introduction Due to the unique advantages such as all-day, all-weather, long range, and high resolution, ISAR is widely applied for noncooperative moving targets in two-dimensional (2-D) high-resolution imaging, feature extraction, classification and recognition in military and civil areas [1]. In most applications, range Doppler (RD) imaging algorithm is used to obtain the 2-D ISAR image from the echo signal of targets [2]. In ISAR scenarios, the target is often engaged in complicated maneuvers and therefore in order to achieve high-resolution ISAR image, the poor effect of imaging caused by the translational and rotational motion should be compensated before performing imaging processing.\n*Correspondence: tianb28@mail.sysu.edu.cn\n1 School of Electronics and Communication Engineering, Shenzhen Campus of Sun Yat-sen University, Shenzhen, China\nTMC introduces range shift and phase error. Therefore, conventional translational motion compensation is usually composed of two steps: range alignment and phase adjustment. In general, the algorithms for the accomplishment of range alignment [3\u20136] to consist of the maximum cross-correlation method between adjacent profiles and the minimum entropy method based on ISAR image. Also, the initial phase errors are then corrected by means of methods [7\u201310] such as phase gradient autofocus (PGA) or the optimization method based on image information. Moreover, due to the large rotational angle or size of target, the migration through range cell (MTRC) is introduced by rotation motion [11, 12]. Hence, the keystone transform (KT) is used to eliminate MTRC.\nHowever, in real applications, due to the long distance between the radar and the small target, noise is inevitable and the SNR is usually low because of the signal decay from long range and absorption of transmit medium, which will have a great influence on ISAR imaging by disturbing the correlation between adjacent echoes and defocusing the radar image. Hence, the cascaded processing approach gives rise to error transmission and insufficient robustness under low SNR. Therefore, the performance of the conventional compensation method above would degrade severely. In order to improve the inferior compensation performance under low SNR, [13] method for noise reduction of high-resolution range profiles (HRRPs) after coarse motion compensation weakens the influence aroused by noise. Nevertheless, HRRPs are submerged in strong noises due to the low SNR or the correlation among echo is greatly reduced due to the large correlation of noise and therefore the performance of range alignment is impaired. Thus, based on the insensitivity of KT to noise, [14] is proposed to accomplish compensation at low SNR by improving the signal-to-noise ratio of data through adjacent coherent accumulation. However, the method in [14] is unapplicable since the SNR is too low for autofocus. Hence, the global optimization method [5, 15\u201317] is proposed with minimum entropy or maximum contrast of the image. Based on minimization of the entropy of the average range profile or ISAR image, the optimal polynomial coefficient vector is solved by an iteration search. Based on optimization method, a method for translational compensation with parameters estimation is proposed in [18, 19]. Although the translational compensation is achieved effectively and accurately, the rotational velocity estimation is not obtained and therefore the rotational compensation and azimuth scaling is fail to accomplish. Based on parameterized compensational method, the method [20\u201322] for motion compensation with parameters estimation is proposed in which improves the performance of compensation strongly. However, the gradient and Hessian matrices are introduced in optimization algorithm resulting in large computational amount. Besides, to achieve rotational compensation, the velocity of rotation is required to obtain. But the coarse priori value of rotational velocity is hard to achieve while the Quasi-Newton method above is sensitive to the selection of initial value of the parameter.\nHence, a novel PSO-based method for high-resolution ISAR imaging under low SNR is proposed in this paper. Firstly, the translation is modeled as a polynomial and the rotation is converted into a function about center and effective velocity of rotation. In addition, the exponential phase term referring to motion compensation is constructed. Therefore, the issue of high-resolution ISAR imaging in low SNR environment is transformed into the optimal parameterized estimation problem. What is more, the entropy of the ISAR image corresponding to compensational phase is utilized as objective function to obtain the\noptimal polynomial coefficient vector based on PSO optimization algorithm, which performs well in global optimization. Thus, the high quality ISAR image after azimuth calibration is achieved with the optimal parameters above.\nThe paper is organized as follows. Section\u00a02 introduces the signal model of ISAR imaging. In Sect.\u00a03, the estimated polynomial coefficient vector based on PSO to achieve the compensation and the azimuth scaling is modeled. The experimental results on simulated and real data are presented in Sect.\u00a04 to verify the effectiveness and robustness of the proposed method. Finally, this paper ends with a brief conclusion in Sect.\u00a05."
        },
        {
            "heading": "2 Signal model of\u00a0ISAR imaging",
            "text": "The geometry of the ISAR imaging system is shown in Fig.\u00a01. XY defines a Cartesian coordinate system, where the origin O is the rotational center of the target. In the 2-D geometry, target motion is divided into translational motion and rotational motion.\nTherefore, assuming that the target consists of K scattering centers and the backward scattering amplitude of the kth scattering point is \u03c3k(k = 1, 2, . . . ,K ) . xk , yk is the initial abscissa and ordinate of scattering point P in the image projection plane and the instantaneous distance from the kth scattering point P to the radar can be expressed as\nwhere R0 denotes the radial distance between rotation center and radar at the initial time; tm is the slow time with 0 \u2264 tm \u2264 Ta , where Ta is the coherent processing interval (CPI); \ufffdRtrans(tm) is the instantaneous radial distance from the radar to the rotation center O, caused by translational motion, and also the movement of the target along the line of radar sight; \ufffdRrot(tm) , between the kth scattering point P and center O caused by rotational motion, can be expressed as the following equation according to the turntable model\nWhere \u03b8(tm) denotes the instantaneous rotational angle of target. In general, the rotation angle during the CPI for ISAR imaging is very small. Therefore, during a short dwell time, the effective angular motion can be assumed constant, representing by the effective rotational velocity \u03c9eff . Therefore, the instantaneous rotational angle of target is defined as \u03b8(tm) = \u03c9eff \u00b7 tm . By using the Taylor series, it can be approximated as\n(1)Rk ,m = R0 +\ufffdRtrans(tm)+\ufffdRrot(tm)\n(2)\ufffdRrot(tm) = xk sin [\u03b8(tm)]+ yk cos [\u03b8(tm)]\nSupposing that the radar transmits a linear frequency modulation (LFM) waveform, it leads to\nwhere t\u0302 \u2208 [ \u2212Tp/2,Tp/2 ]\nrepresents the fast time and t = t\u0302 + tm is the total time; Tp , f0 and \u03b3 = B/Tp refer to the pulse width, carrier frequency, and the frequency modulation rate, where B is the bandwidth. The received base band signal after quadrature demodulation can be expressed as\nwhere c denotes the light speed. Suppose the reference signal of matched filter is\nThus, after range compression by the matched filter processing method, the HRRPs can be expressed as\nIn Eq. (7), the first term is the envelop term, while the second term is the phase term. The radial distance \ufffdRtrans(tm) in envelop term and in phase term, caused by translation, leads to the offset of range profiles along the slow time \ufffdte(tm) = 2Rtrans(tm)/c and phase error \ufffd\u03c6(tm) = 4\u03c0Rtrans(tm)/ , respectively. In general, the max-correlation method and the PGA method are adopted to accomplish the alignment of range profiles and phase correction for translational compensation. Moreover, for some big targets or some targets with big \u03c9eff , the rotational distance \ufffdRrot(tm) = xk\u03c9efftm + yk in envelop term might exceeds one range cell leading to slant-range MTRC resulting in ISAR image blurring. Therefore, the KT is adopted to compensate the slant MTRC caused by rotation.\nAfter these steps of compensation with the methods above, it can be obtained\n(3) {\ncos \u03b8 [(tm)] \u2248 1 sin \u03b8 [(tm)] \u2248 \u03c9eff \u00b7 tm\n(4)s ( t\u0302, tm ) = rect\n(\nt\u0302\nTp\n)\nexp\n{\nj2\u03c0\n(\nf0t + 1\n2 \u03b3 t\u03022\n)}\n(5)s0 ( t\u0302, tm ) =\nK \u2211\nk=1\n\u03c3krect ( t\u0302\u22122Rk ,m/c Tp ) \u00b7 exp { j2\u03c0 (\n\u2212f0 2Rk ,m c + 1 2\u03b3 ( t\u0302 \u2212 2Rk ,m/c )2 )}\n(6)h ( t\u0302 ) = rect\n(\nt\u0302\nTp\n)\nexp { \u2212j\u03c0\u03b3 t\u03022 }\n(7)\nsr ( t\u0302, tm ) =\nK \u2211\nk=1\n\u03c3kTpsinc\n{\nB\n(\nt\u0302 \u2212 2Rk ,m\nc\n)}\nexp\n{\n\u2212j 4\u03c0Rk ,m\n}\n=\nK \u2211\nk=1\n\u03c3kTpsinc { B ( t\u0302 \u2212 2[R0+\ufffdRtrans(tm)+\ufffdRrot(tm)]c )} \u00b7 exp { \u2212j 4\u03c0 [R0+\ufffdRtrans(tm)+\ufffdRrot(tm)] }\n(8)sr ( t\u0302, tm ) =\nK \u2211\nk=1\n\u03c3kTpsinc\n[\nB\n(\nt\u0302 \u2212 2yk\nc\n)]\nexp\n(\n\u2212j4\u03c0 xk\u03c9efftm + yk\n)\nIt can be seen from (8) that the range resolution is\nBy using the Fourier transform of (9) in terms of tm , the high-resolution ISAR image of the receiver can be obtained\nIt can be seen from (10) that the azimuth resolution is"
        },
        {
            "heading": "3 Joint motion compensation and\u00a0azimuth scaling under\u00a0low SNR by\u00a0minimum entropy",
            "text": "The proposed method in this paper is mainly comprised of three steps based on parameters estimation by minimum entropy as follows. Firstly, the received incoherent signal is converted into coherent one reflecting the motion information. Also, motion of the target is modeled as formula of the polynomial coefficient vector to be estimated based on PSO by entropy minimization as objective function. Therefore, the parameters above are utilized to implement joint motion compensation and azimuth scaling."
        },
        {
            "heading": "3.1 The coherent processing of\u00a0the\u00a0incoherent signal",
            "text": "Since the radial range based on translation within the observation time changes greatly, the radar transmits signal in the form of pulse group to ensure that each pulse group is acquired with corresponding window. Suppose the reference range of the mth pulse is Rref and the width of sampling window is Twind . Therefore, Eq. (5) can be written as\nThus, assume that t\u0302 \u2212 Twind/2 is the reference fast time, the range profile after matched filtering is given by\nwhere is the wavelength and Rk ,m = Rk ,m \u2212 Rref. In this paper, the proposed method is based on the HRRPs that can reflect the target motion trajectory. Without the position of the windowing gate, the method is ineffective, which is also the limitation of this method. However, for new radar equipment, it is generally possible to use the data of narrowband ranging as a benchmark to accurately record the window position for wideband echo acquisition. Hence, in\n(9)\u03c1r = c\n2fs\n(10)sr ( t\u0302, fm ) =\nK \u2211\nk=1\n\u03c3kTpTasinc\n[\nB\n(\nt\u0302 \u2212 2yk\nc\n)]\nsinc\n[\nTa\n(\nfm \u2212 2xk\u03c9eff\n)]\n\u00b7 e\u2212 4\u03c0 fc c yk\n(11)\u03c1a = 2\ufffd\u03b8 =\n2\u03c9effTa\n(12)s0 ( t\u0302, tm ) =\nK \u2211\nk=1\n\u03c3krect ( t\u0302+(2Rref/c\u2212Twind/2)\u22122Rk ,m/c Tp )\n\u00b7 exp\n{\nj2\u03c0\n(\n\u2212f0 2Rk ,m c + 1 2\u03b3\n( t\u0302 + (\n2Rref c \u2212 Twind 2\n)\n\u2212 2Rk ,m c\n)2 )}\n(13)sr ( t\u0302, tm ) =\nK \u2211\nk=1\n\u03c3kTpsinc\n{\nB\n(\nt\u0302 \u2212 2\ufffdRk ,m\nc\n)}\nexp\n{\n\u2212j 4\u03c0\ufffdRk ,m\n}\norder to ensure the facility of the subsequent coherent compensation, by using the data of the windowing recorded from the radar, the windowing difference is compensated completely.\nThus, the HRRPs from (13) after coherent processing can be expressed as\nTherefore, the received coherent signal is taken as the input of the motion model of the target."
        },
        {
            "heading": "3.2 The motion modeling of\u00a0the\u00a0target",
            "text": "In general, due to the complex motion of the target, the radial translational motion of the maneuvering target is modeled as an L-order polynomial as shown in the following\nwhere \u03b1l is the coefficient of lth-order polynomial, l = [1, 2, . . . , L] , in which L is the total polynomial order. In practical scenarios, for stationary moving targets, the velocity of translational motion can be approximated as constant during the imaging accumulation time. Therefore, the majority of the translational motion is introduced by the low order terms while the higher order terms would not degrade the image quality too much. Hence, in order to avoid the disadvantages of high computational cost and overfitting, the second-order fitting accuracy is sufficient. Consequently, in this paper, the radial translational motion can be approximated to a second-order polynomial in order to obtain good prediction results. Therefore, the coefficient of first-order term is the velocity and the second-order term is corresponding to acceleration. Thus, the radial translational motion can be expressed as\nwhere v and a denotes the velocity and acceleration of the target, respectively. Moreover, in order to describe the change of the total instantaneous radial distance more precisely, the two-order Taylor series expansion is carried out for trigonometric functions as shown in the following\nThus, \ufffdRrot(tm) can be expressed as\nSubstituting (18) into (14), the HRRPs is given by\n(14)sr ( t\u0302, tm ) =\nK \u2211\nk=1\n\u03c3kTpsinc\n{\nB\n(\nt\u0302 \u2212 2Rk ,m\nc\n)}\nexp\n{\n\u2212j 4\u03c0Rk ,m\n}\n(15)\ufffdRtrans(tm) = L \u2211\nl=1\n\u03b1l(tm) l\n(16)\ufffdRtrans(tm) = \u03b11 \u00b7 tm + \u03b12 \u00b7 tm2 = v \u00b7 tm + 1\n2 a \u00b7 tm\n2\n(17) { cos [\u03b8(tm)] \u2248 1\u2212 1 2 (\u03c9eff \u00b7 tm) 2\nsin [\u03b8(tm)] \u2248 \u03c9eff \u00b7 tm\n(18)\ufffdRrot(tm) = xk\u03c9eff \u00b7 tm + yk \u2212 1\n2 yk(\u03c9eff \u00b7 tm)\n2\nSince the quadratic term is generally less than half one range cell due to the relatively small effect of rotation on the envelope of range profile, it is neglected in the envelope term. On the contrary, the range shift cause by rotation called as the slant-range MTRC and the quadratic term in the phase term called as the cross-range MTRC are preserved. Therefore, the translational motion error and the two terms involving MTRC need to be corrected.\nHence, in order to demonstrate the property of range shift and slant-range MTRC, (19) is converted into range frequency domain after the Fourier transform with respect to t\u0302 as shown in the following formula\nIn (20), the first exponential term refers to the Doppler frequency and the second one represents the translational motion error including range misalignment and phase error. The third and the last term are slant-range MTRC and cross-range MTRC, respectively.\nSuppose that the signal term converted by the ideal range profile is given by\nTherefore, substituting (21) into (20) and assuming that the slant-range MTRC has been compensated, after discretization, (20) is rewritten as\nwhere h denotes the range frequency bin index with \u2212H/2 \u2264 h \u2264 H/2\u2212 1 and m denotes the slow time index with \u2212M/2 \u2264 m \u2264 M/2\u2212 1 , with H and M referring to the total number of range bin and azimuth bin, respectively. fr and tm correspond to the sampling interval of range frequency and pulse repetition frequency. Moreover, yk is the ordinate of the kth scattering point which is can be expressed as\nwhere y0 denotes the ordinate of the rotational center. For clarity, considering the additive noise in the case of the low SNR and (22), the signal model in a discrete form can be expressed as\n(19)sr ( t\u0302, tm ) =\nK \u2211\nk=1\n\u03c3kTpsinc { B [ t\u0302 \u2212 2(R0+\ufffdRtrans(tm)+xk\u03c9efftm+yk)\nc\n]}\n\u00b7 exp\n{\n\u2212j 4\u03c0\n[\nR0+\ufffdRtrans(tm)+xk\u03c9efftm+yk\u2212 1 2 yk\u03c9 2 efft 2 m\n]\n}\n(20)sr ( fr , tm ) =\nK \u2211\nk=1\n\u03c3k exp { \u2212j 4\u03c0 ( xk\u03c9efftm + yk ) } \u00b7 exp {\n\u2212j 4\u03c0c ( fr + fc ) [R0+\ufffdRtrans(tm)] c\n}\n\u00b7 exp {\n\u2212j 4\u03c0 fr c ( xk\u03c9efftm + yk )\n}\n\u00b7 exp\n{\nj 2\u03c0 fcyk\u03c9\n2 efft 2 m\nc\n}\n(21)s\u0303r ( fr , tm ) =\nK \u2211\nk=1\n\u03c3k exp\n{\n\u2212j2\u03c0 fr 2 ( R0 + yk )\nc\n}\n\u00b7 exp\n{\n\u2212j 4\u03c0 ( xk\u03c9efftm + yk )\n}\n(22) sr(h,m) = s\u0303r(h,m) \u00b7 exp\n{\nj 2\u03c0\n\u00b7 yk\u03c9eff 2(m\ufffdtm) 2\n}\n\u00b7 exp\n{\n\u2212j 4\u03c0\nc\n( h\ufffdfr + f0 ) \u00b7\ufffdRtrans(m\ufffdtm)\n}\n(23)yk = ( n\u2212 y0 ) \u00b7 \u03c1r"
        },
        {
            "heading": "In (24), \u2299 is Hadamard product. S = [sr(h,m)]H\u00d7M \u2208 CH\u00d7M , X \u2208 CN\u00d7Mand N \u2208 CH\u00d7M",
            "text": "refer to the signal with error under low SNR in ( fr , tm )\ndomain, ideal signal in the scattering field and additive complex Gaussian white noise, respectively. T = [ exp ( j\u03d5T )]\nH\u00d7M\nstands for translational motion error and R = [ exp ( j\u03d5R )]\nH\u00d7M represents the cross-\nrange MTRC, where \u03d5T = \u22124\u03c0 ( h\ufffdfr + fc )\n\u00b7\ufffdRtrans(m\ufffdtm)/c and \u03d5R = 2\u03c0 ( n\u2212 y0 ) \u03c1r \u00b7 \u03c9eff 2(m\ufffdtm) 2/ . C = T\u2299 R is the matrix of the error. Moreover,\nFr =\n\n     \n1 1 1 \u00b7 \u00b7 \u00b7 1 1 \u03b1 \u03b12 \u00b7 \u00b7 \u00b7 \u03b1(H\u22121) 1 \u03b12 \u03b14 \u00b7 \u00b7 \u00b7 \u03b1(H\u22122) ... ... \u00b7 \u00b7 \u00b7 . . . ... 1 \u03b1(N\u22121) \u03b1(N\u22122) \u00b7 \u00b7 \u00b7 \u03b1\n\n     \nH\u00d7N\nis Fourier transform matrix in range domain\nand \u03b1 = exp(\u2212j2\u03c0/N ) , where N denotes the sampling numbers of columns of X . Hence, = [v, a, y0,\u03c9eff] is defined as the parameters vector and \u0302 = [ v\u0302, a\u0302, y\u03020, \u03c9\u0302eff ]\nis the estimation of the vector above. Therefore, in order to accomplish TMC and RMC, the signal in range frequency domain after motional compensation with the estimated parameters is shown in the following\nAfter applying inverse Fourier transform in range direction and Fourier transform in azimuth direction, (25) is transformed into 2-D ISAR image after compensation as shown in the following\nWhere Fa =\n\n     \n1 1 1 \u00b7 \u00b7 \u00b7 1 1 \u03b2 \u03b22 \u00b7 \u00b7 \u00b7 \u03b2(K\u22121) 1 \u03b22 \u03b24 \u00b7 \u00b7 \u00b7 \u03b2(K\u22122) ... ... \u00b7 \u00b7 \u00b7 . . . ... 1 \u03b2(M\u22121) \u03b2(M\u22122) \u00b7 \u00b7 \u00b7 \u03b2\n\n     \nM\u00d7K\nis Fourier transform matrix in azi-\nmuth domain and \u03b2 = exp(\u2212j2\u03c0/K ) , where K denotes the sampling numbers of lines of X.\nTMC is accomplished with the fine estimated parameters corresponding to translational motion. Due to the azimuth resolution corresponding to \u03c9eff from (11), RMC and azimuth scaling can be achieved simultaneously if the corresponding motion parameters, the ordinate of the rotational center and the effective rotational velocity, are accurately estimated.\nTherefore, in order to accomplish well-focus ISAR image, the achievement of motion compensation and azimuth scaling can be converted into an unconstrained optimization problem of obtaining the minimum or maximum of the cost function to estimate related parameters.\n(24)S = T\u2299 R \u2299 (FrX)+N = C\u2299 (FrX)+N\n(25)Sc = S\u2299 C\u0304\u0302\n(26)G [ g ( n, k; \u0302 )] =Fr H ScFa"
        },
        {
            "heading": "3.3 Joint motion compensation and\u00a0azimuth scaling based on\u00a0the\u00a0estimation of\u00a0motion parameters",
            "text": "In general, image entropy is used to measure the focusing effect of an image. The smaller the entropy, the better the focusing performance of the image. Hence, image entropy is taken as the cost function and the optimal estimated parameters can be achieved by the following formula\nwhere IE [ g ( n, k; \u0302 )] denotes the entropy of the ISAR image and it can be expressed as\nIn (28), Es is given by\nAs discussed above, the estimation of parameters to achieve motion compensation and azimuth scaling can be seen as a global optimization problem. PSO is an intelligent optimization algorithm with simple model, high efficiency, and high precision results. In practice, the acquisition of the coarse initial value of effective rotational velocity results in poor efficiency meanwhile there is no need for the initial value of parameters as input in PSO. Due to the superiority of PSO as mentioned above, the PSO optimization algorithm is adopted to achieve effective solution of optimization problems.\nIn PSO, a group of random particles are initialized which have only two attributes that velocity and position. The maximum velocity of particles is generally 10% to 20% of the each current estimated parameter search space and the corresponding initial velocity of particles is set to [\u2212vmax, vmax] . The initial position of the particles is the initial value of the each parameter to be estimated. The initial values of velocity and acceleration can be set from the target radial velocity data measured by narrowband signal transmitted by radar, which are the coarse initial values to accelerate convergence. The initial value of the vertical coordinate of the target rotation center is generally determined by the total numbers of the range cells. In addition, the target rotational velocity is generally not greater than 0.1rad/s and the initial value is set to 0.05. Moreover, considering that too few particles may lead to convergence of local optimal solutions and insufficient exploration of search space in highdimensional space, while too many particles may lead to low computational efficiency and overfitting, the number of particles for the PSO algorithm is set to 50 in this paper after adjustment and optimization in the experiment.\nThe minimum image entropy of each particle is achieved. In addition, individual extremum and global extremum are updated if the entropy value is lower than the previous optimal value and the global previous optimal value, respectively. After the two extremums are obtained, particles updating the velocity and position can be expressed as\n(27)\u0302 = arg min \u0302\n{ IE [ g ( n, k; \u0302 )]}\n(28)IE \ufffd g \ufffd n, k; \u0302 \ufffd\ufffd =\nN\u22121 \ufffd\nh=0\nM\u22121 \ufffd\nk=0\n\n  \u2212\n\ufffd \ufffd \ufffd g \ufffd n, k; \u0302 \ufffd\ufffd \ufffd \ufffd 2\nEs\n\n  ln\n\ufffd \ufffd \ufffd g \ufffd n, k; \u0302 \ufffd\ufffd \ufffd \ufffd 2\nEs\n(29)Es = N\u22121 \u2211\nh=0\nM\u22121 \u2211\nk=0\n\u2223 \u2223 \u2223g ( n, k; \u0302 )\u2223 \u2223 \u2223 2\nwhere i, v, \u0302 , and e denote the particle index, velocity, position and iteration index, respectively. In general, r1 and r2 denote the random values with rand (0,1). \u0302 e,pbest\ni is the individual best position of ith particle while \u0302 e,gbest represents the global optimal position. c1 and c2 are the learning factors. During the optimization iteration process, the two learning factors undergo different changes over time. The size of learning factors c1 and c2 determines the impact of particle self-awareness and social cognition on particle trajectories, reflecting the degree of information exchange between particles in groups. A larger c1 will cause too many particles to wander within the local range, while a larger c2 will prompt the particles to converge to the local minimum prematurely. Therefore, the learning factors are given by\nTherefore, at the beginning of optimization iteration, the social learning ability of particles is weak while the self-learning ability is strong, making it easy to achieve fast search and strengthen global search ability. In the later stage of optimization iteration, the selflearning ability of particles is weak while the social learning ability is strong, which is conducive to local fine search and converges to the global optimal solution with high accuracy. \u03c6 is the inertia weight coefficient. Large \u03c6 means that the PSO algorithm has strong global spatial search ability, while small \u03c6 is corresponding to strong local spatial search ability. Hence, \u03c6 is reduced nonlinearly, which makes the PSO algorithm have a strong ability to explore the whole solution space at the initial stage of the iteration, while at the later stage of the iteration, it can conduct refined search locally, which accelerates the convergence rate and improves the search accuracy of PSO, respectively. The inertia weight coefficient is given by\nwhere i and I denote particle index and the total number of particles. Moreover, the velocity rebound strategy is utilized to prevent the decrease in population diversity caused by particles out of the search interval. When the particle exceeds the position edge indicating the estimated parameter value exceeds the corresponding search space, the particle flies in the opposite direction with the original velocity value and the related estimated parameter value is changed into the particle position edge value set before. Therefore, the velocity and position of particle can be expressed as\nWhere i, v, \u0302 , and e denote the particle index, velocity, position and iteration index, respectively. lid and uid are the upper and lower limits of the search space.\n(30)\n\n\n\nvei = \u03c6v e\u22121 i + c1r1\n\ufffd\n\u0302 e,pbest i \u2212 \u0302 e\u22121 i\n\ufffd\n+ c2r2\n\ufffd\n\u0302 e,gbest \u2212 \u0302 e\u22121\n\ufffd\n\u0302 e i = \u0302 e\u22121 i + v e i\n(31) {\nc1 = c1s \u2212 (c1s \u2212 c1e) \u00b7 cos (\u03c6) c2 = c2s \u2212 (c2s \u2212 c2e) \u00b7 cos (\u03c6) , where\n{\nc1s = 2.5; c1e = 0.5; c2s = 0.5; c2e = 2.5;\n(32)\u03c6 = 0.9\u2212 (0.9\u2212 0.4) \u00b7 \u221a i\nI\n(33)veid = { ve\u22121id \ufffd\u0302 e\u22121 id \u2208 (lid ,uid)\n\u2212ve\u22121id \ufffd\u0302 e\u22121 id /\u2208 (lid ,uid)\n\ufffd\u0302eid =\n{\nlid \ufffd\u0302 e\u22121 id < lid uid \ufffd\u0302 e\u22121 id > uid"
        },
        {
            "heading": "3.4 The framework of\u00a0the\u00a0method",
            "text": "Detailed implementation procedures of the parameters estimation for compensation are given as follows.\nStep 1 After preprocessing consisting of range compression and coherent processing, the echo signal of the target including K scattering points is converted into HRRPs shown in (14). And, the cost function corresponding to the entropy of the ISAR image after compensation shown in (29) is constructed.\nStep 2 Initialization for the group of particles and parameters setting. Step 3 Start with the iteration and calculate the value of the fitness function Step 4 Determine the best solution of \u0302 e,pbest\ni and \u0302 e,gbest\nStep 5 Update the velocity and position of each particle Step 6 Repeat steps until the difference IE between the entropy of \u0302 e,gbest and\n\u0302 e\u22121,gbest\nis smaller than the given threshold \u03b5 Step 7 With the obtained optimal parameters, motion compensation and azimuth scaling are achieved. In summary, the flowchart of the proposed approach is shown in Fig.\u00a02. Given the fitness function referring to the entropy of the ISAR image after compensation. The optimal parameters to be estimated are obtained until the conditions for the end of iteration are satisfied. After the parameters are substituted into the exponential compensation terms, the high resolution ISAR 2-D image is obtained. Moreover, azimuth\nscaling is accomplished due to the accurate estimation of \u03c9\u0302eff . Therefore, the form and dimension features of the target are precisely achieved."
        },
        {
            "heading": "4 Experimental results and\u00a0discussion",
            "text": "In this section, the performance of the proposed algorithm in this paper is verified and analyzed through simulation and real data experiment. Firstly, the effectiveness of the algorithm in high-resolution compensated imaging of complex moving targets is validated compared with the two conventional compensation method. The two traditional methods are completed through cascaded processing, where the maximum cross-correlation method [2] and global optimal method [17] are adopted to achieve range alignment, respectively, PGA [7] to correct the phase error and KT [14] to solve MTRC, which are named the first method and the second method. Furthermore, the robustness of the estimation accuracy of the method under multiple SNRs is verified with the relative error results of the motion parameter estimation. Finally, simulated satellite facet data experiment and real data experiment are demonstrated the validity of the proposed algorithms."
        },
        {
            "heading": "4.1 The simulated data experiments",
            "text": ""
        },
        {
            "heading": "4.1.1 The simulated satellite point scattering data experiments",
            "text": "The satellite model is used for simulation experiments with 97 scattering points, whose transverse dimension is 30\u00a0m and longitudinal dimension is 35\u00a0m, as shown in Fig.\u00a03. In the simulation, the parameters of the set radar waveform signal are shown in Table\u00a01.\nDue to the large variation in radial range based on translation of the observed target within the radar imaging observation time, the radar transmits signal in the form of pulse group and each pulse group is acquired with corresponding window. Also, the echo signal is processed by pulse compression and therefore the radial motion track of the target reflected by the HRRPs presents random jump characteristics, as shown in Fig.\u00a04a.\nThe windowing difference is compensated by using the position of the windowing gate recorded by the radar. The obtained one-dimensional HRRPs is shown in Fig.\u00a04b. It can be seen from the diagram that the HRRPs after compensating the windowing difference\ncan reflect the motion information of the target and therefore motion compensation can be implemented after high-precision estimation of related parameters.\nIn general, the HRRPs image with a SNR below -5dB can be considered low SNR. In the wideband signal model, SNR is generally referred to the ratio of the average power of the target area to the average power of the noise, which can be expressed as\nwhere PS and PN denote the average power of the target area and the additive complex Gaussian noise, respectively. By adding Gaussian white noise to the simulation signal, the high SNR with a value of 20 dB and the low SNR with a value of \u2212 5 dB are set, respectively. The two conventional imaging compensation method and the motion parameter estimation compensation method proposed in this paper are used to perform high-resolution ISAR 2-D imaging for the simulation data under the two SNR.\nFigure\u00a05 shows the comparison of imaging results under high SNR. From the simulation results of conventional methods under the condition of high SNR shown in (a)\u2013 (d), it can be seen that compared with the results of this proposed method with fine\n(34)SNR = 10 \u00b7 log10\n(\nPS PN\n)\nestimated parameters in Table\u00a0 2, as shown in (f ) and (g), the performance of range alignment of HRRPs and the focusing of 2-D ISAR image are both relatively well. Moreover, due to the good performance of the global optimization, the focusing effect of ISAR image based on the second method is better than the first method. However, since the velocity and center of rotation is unavailable with the two conventional methods, the quality of the obtained ISAR image is relatively low due to the defocusing along the azimuth direction and azimuth calibration cannot be achieved. It can be seen from (e) that the minimum entropy iteration curve can achieve convergence in the 15th cycle.\nMoreover, as shown in Fig.\u00a05h, it can be seen that with the accurate y\u03020 , \u03c9\u0302eff , Eqs. (9) and (10), the size along azimuth direction and range direction are 28.85m and 35.50m, respectively. Therefore, the azimuth calibration is achieved by using the precisely estimated parameters. Thus, by applying the method in this paper, ISAR image is achieved efficiently and accurately.\nThe performance of ISAR imaging under low SNR is further simulated as shown in Fig.\u00a06. The one-dimensional HRRPs and two-dimensional image of the target with the two traditional methods are shown in (a)\u2013(d). It can be seen that in the case of low SNR, the alignment effect of HRRPs becomes worse, and it is difficult to focus, leading to the image blurring. In addition, because global optimization method is more robust to additive noise than the maximum cross-correlation method, the focusing effect of the second method is better than the first one. However, with the interference of the strong noise, based on the parameterized compensation algorithm, the ISAR image quality of the second method reduces while the parameters of the target can still be accurately estimated\nTable 2 The estimated parameters with PSO method\nv\u0302 ( m/s) a\u0302 ( m/s2) y\u03020 \u02c6\u03c9eff ( rad/s)\nSNR = 20 dB 40.1037 4.9995 1202.6 0.0390 SNR = \u2212 5 dB 39.9208 4.9992 1209.3 0.0390\nFig. 5 ISAR images under high SNR after compensation. a The alignment effect of the first method. b The imaging effect of the first method. c The alignment effect of the second method. d The imaging effect of the second method. e The convergence curve of parameter estimated iteration. f The alignment effect of the proposed method. g The imaging effect of the proposed method. h ISAR images after azimuth calibration\nin the proposed method, especially the effective rotational velocity with unknown initial value but high accuracy requirement shown in Table\u00a02 with aligned HRRPs and highresolution ISAR images. The iteration curve of the minimum entropy converges at the 15th cycle shown in (e) verifying the effectiveness of the proposed method in this paper under low SNR.\nIn addition, the azimuth scaling of the obtained ISAR image is achieved accurately shown in Fig.\u00a06f, where the size of azimuth and range direction are 28.85m and 35.50m due to fine estimated ordinate of Doppler center and effective rotational velocity shown in Table\u00a02 under the low SNR above.\nIn order to further verify the effect of this algorithm on target high-resolution ISAR imaging, adjust the SNR environment above, and set the SNR to change from 20dB to 0dB at an interval of \u2212 1 dB. In this experiment, the relative error between the estimation result of each parameter and the simulation true value is utilized as the evaluation index of the algorithm performance, as shown in Eq. (35), to verify the robustness of the method in this paper under various SNR conditions.\nwhere n denotes the number of experiments, p\u0302x denotes parameter estimation results of the xth experiment and p0 is true value of the parameter, respectively.\nThe relative error of the estimated motion parameters corresponding to different SNRs are plotted in Fig.\u00a0 7 which presents that with the reduction in the SNR, although the relative error curves of each parameter generally show an upward trend, they are close to zero and have a small fluctuation which illustrates the parameter estimation accuracy is high and almost not affected by the SNR. Therefore, the robustness of the algorithm in this paper to high-resolution ISAR imaging is validated.\n(35)\u03b4 = 1\nn\nn \u2211\nx=1\n\u2223 \u2223p\u0302x \u2212 p0 \u2223 \u2223\np0"
        },
        {
            "heading": "4.1.2 The simulated satellite facet scattering data experiments",
            "text": "On account of the complex electromagnetic scattering of real target, a three-dimensional (3-D) model of the satellite is utilized as the observed target as shown in Fig.\u00a08a contributing to further verify the effectiveness of this algorithm. From the projection of the model on the 2-D plane shown in Fig.\u00a08b, it can be seen that the transverse dimension and longitudinal dimension of the simulated model is set 11.5 m and 10.8 m, respectively. By adding Gaussian white noise to the simulation signal with a value of \u2212 5 dB, the conventional imaging compensation method and the proposed method are used to perform high-resolution ISAR two-dimensional imaging for the simulation data under low SNR.\nAfter the range compression, the HRRPs are obtained as shown in Fig.\u00a0 9a which is directly utilized for the compensation of traditional method. For subsequent coherent compensation, the coherent HRRPs are achieved after coherent processing as shown in Fig.\u00a09b taken for the compensation of the proposed algorithm.\nThe simulation results of two methods under the condition of low SNR as shown in Fig.\u00a010. It can be seen that with the two conventional method shown in (a)\u2013(d), the performance of range alignment of HRRPs and the focusing of two-dimensional ISAR image are bad, specifically in the part of the HRRP drowned in noise and the defocusing part of the ISAR image. As comparison, with the parameterized compensation algorithm, the motion parameters of the target can still be accurately estimated to achieve the aligned HRRP and high-resolution ISAR two-dimensional imaging, as shown in (f ) and (g). The iteration curve of the minimum entropy converges at the 20th cycle verifying the effectiveness of the proposed method in this paper under low SNR. From (h), one can see that the azimuth size and range size of the target in the ISAR image are 13.9 m and 10.5 m, respectively, which is approximately consistent with the model size. Hence, azimuth scaling of the obtained ISAR image is accomplished."
        },
        {
            "heading": "4.2 The real data experiments",
            "text": "In this section, the effectiveness of the proposed algorithm is verified by the measured data of Boeing 737 aircraft. Firstly, add white Gaussian noise to the data, and set the SNR\nto \u2212\u00a010\u00a0dB. The incoherent HRRPs and coherent HRRPs of the Boeing 737 aircraft are shown in Fig.\u00a011a and b.\nThe conventional method and the proposed method are used to compensate the real data, and the ISAR imaging results are shown in Fig.\u00a012. It can be seen from the figure that by applying the proposed algorithm, a well-focused image is obtained and the contour and structure information of the aircraft can be retained better due to the realization of azimuth calibration with the clearer tail and wing. In addition, the image entropy corresponding to the proposed algorithm is smaller under the condition of low SNR and therefore the proposed method can achieve high-resolution ISAR two-dimensional imaging."
        },
        {
            "heading": "5 Conclusion",
            "text": "Considering the practical constraints in achievement of high-resolution ISAR image under low SNR, a novel method joint motion compensation and azimuth scaling based on PSO is proposed in this letter. By analyzing the movement of the target and combining with the LFM signal of the radar echo, the exponential compensation term corresponding to HRRPs is obtained. After the compensation model is constructed, the entropy of ISAR image compensated is used as cost function. Therefore, the accuraterelated parameters are achieved by the minimum of the entropy with PSO algorithm. Due to the estimated parameters, the motion compensation and azimuth scaling are accomplished into the acquirement of ISAR image with high quality. The simulation and real data experiment are carried out to validate the high efficiency and accuracy of the proposed compensation method relative to traditional compensation method under low SNR. Moreover, the robustness of the proposed method to estimate related parameters is verified under multiple SNR. However, this model restricts the motion model, leading to limitations on specific scenarios. Therefore, motion compensation for ISAR imaging under low SNR is still open.\nAbbreviations 2-D Two-dimensional 3-D Three-dimensional CPI Coherent processing interval HRRPs High-resolution range profiles ISAR Inverse synthetic aperture radar KT Keystone transform LFM Linear frequency modulation MTRC Migration through range cell PGA Phase gradient autofocus PSO Particle swarm optimization RD Range Doppler RMC Rotational motion compensation SNR Signal-to-noise ratio TMC Translational motion compensation\nAcknowledgements The authors would like to thank the handing editor and the anonymous reviewers for their valuable comments and suggestions for this paper. This work was supported in part by Fundamental Research Funds for the Central Universities, Sun Yat-sen University (No. 22lgqb15), Guangdong Science and Technology Program (No. 2019ZT08X751), Shenzhen Science and Technology Program (No. KQTD20190929172704911), and Natural Science Foundation of Hunan Province (No. 2021JJ20056).\nFunding This work was supported in part by Fundamental Research Funds for the Central Universities, Sun Yat-sen University (No. 22lgqb15), Guangdong Science and Technology Program (No. 2019ZT08X751), Shenzhen Science and Technology Program (No. KQTD20190929172704911), and Natural Science Foundation of Hunan Province (No. 2021JJ20056).\nAvailability of data and materials The data that support the findings of this study are available from the unit of the author in School of Electronics and Communication Engineering in Sun Yat-sen University but restrictions apply to the availability of these data, which were used under license for the current study, and so are not publicly available. Data are however available from the authors upon reasonable request and with permission of the unit of the author in School of Electronics and Communication Engineering in Sun Yat-sen University.\nDeclarations\nEthics approval and consent to participate Not applicable\nConsent for publication Not applicable\nCompeting interests No competing interests.\nReceived: 24 March 2023 Accepted: 6 June 2023\nReferences 1. V.C. Chen, M. Martorella, Inverse synthetic aperture radar imaging: Principles, algorithms and applications (Scitech, 2014) 2. C.-C. Chen, H.C. Andrews, Target-motion-induced radar imaging. IEEE Trans. Aerosp. Electron. Syst. 1, 2\u201314 (1980) 3. T. Sauer, A. Schroth, Robust range alignment algorithm via hough transform in an isar imaging system. IEEE Trans.\nAerosp. Electron. Syst 31(3), 1173\u20131177 (2002) 4. J. Wang, D. Kasilingam, Global range alignment for isar. IEEE Trans. Aerosp. Electron. Syst. 39(1), 351\u2013357 (2003) 5. D. Zhu, W. Ling, Y. Yu, Q. Tao, Z. Zhu, Robust isar range alignment via minimizing the entropy of the average range\nprofile. IEEE Geosci. Remote Sens. Lett. 6(2), 204\u2013208 (2009) 6. L. Zhang, J.L. Sheng, J. Duan, M.D. Xing, Z.J. Qiao, Z. Bao, Translational motion compensation for isar imaging under\nlow snr by minimum entropy. EURASIP J. Adv. Signal Process 2013(1), 1\u201319 (2013) 7. D.E. Wahl, D.G.C.J.J. P.H. Eichel, Phase gradient autofocus-a robust tool for high resolution sar phase correction. IEEE\nTrans. Aerosp. Electron. Syst. 30(1), 827\u2013834 (1994) 8. F. Berizzi, G. Corsini, Autofocusing of inverse synthetic aperture radar images using contrast optimization. IEEE Trans.\nAerosp. Electron. Syst. 32(3), 1185\u20131191 (1996) 9. R.L. Morrison, M.N. Do, D.C. Munson, SAR image autofocus by sharpness optimization: a theoretical study. (2008) 10. P. Cao, M. Xing, G. Sun, Y. Li, Z. Bao, Minimum entropy via subspace for isar autofocus. IEEE Geosci. Remote Sens. Lett.\n7(1), 205\u2013209 (2010) 11. M. Xing, R. Wu, J. Lan, Z. Bao, Migration through resolution cell compensation in isar imaging. IEEE Geosci. Remote\nSens. Lett. 1(2), 141\u2013144 (2004) 12. J.M. Munoz-Ferreras, F. Perez-Martfnez, Uniform rotational motion compensation for inverse synthetic aperture radar\nwith non-cooperative targets. Radar Sonar Navig. IET 2, 25\u201334 (2008) 13. G. Xu, M. Xing, L. Zhang, Y. Liu, Y. Li, Bayesian inverse synthetic aperture radar imaging. IEEE Geosci. Remote Sens.\nLett. 8(6), 1150\u20131154 (2011) 14. M.X.W. Chen, B. Zheng, Keystone transformation based isar imaging at the low snr level. J. Xidian Univ. 30(2),\n155\u2013159 (2003) 15. D. Ustun, C. Ozdemir, A. Akdagli, A. Toktas, M.B. Bicer, A powerful method based on artificial bee colony algorithm for\ntranslational motion compensation of isar image. Microw. Opt. Technol. Lett. 56(11), 2691\u20132698 (2014) 16. Y. Li, T. Zhang, Z. Ding, W. Gao, J. Chen, An improved inverse synthetic aperture radar range alignment method\nbased on maximum contrast. J. Eng. 2019(19), 5467\u20135470 (2019) 17. Y. Liu, L. Wang, G. Bi, H. Liu, H. Bi, Novel isar range alignment via minimizing the entropy of the sum range profile. in\n2020 21st International Radar Symposium (IRS), pp. 135\u2013138 (2020). https:// doi. org/ 10. 23919/ IRS48 640. 2020. 92537 31 18. L. Liu, F. Zhou, M. Tao, P. Sun, Z. Zhang, Adaptive translational motion compensation method for isar imaging under\nlow snr based on particle swarm optimization. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 8(11), 5146\u20135157 (2015)\n19. Z. Ding, G. Zhang, T. Zhang, Y. Gao, K. Zhu, L. Li, Y. Wei, An improved parametric translational motion compensation algorithm for targets with complex motion under low signal-to-noise ratios. IEEE Trans. Geosci. Remote Sens. 60, 1\u201314 (2022). https:// doi. org/ 10. 1109/ TGRS. 2022. 32170 30 20. G. Xu, M. Xing, X.G. Xia, Q.Q. Chen, L. Zhang, Z. Bao, High-resolution inverse synthetic aperture radar imaging and scaling with sparse aperture. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 8(8), 4010\u20134027 (2015) 21. S. Jialian, X. Mengdao, Z. Lei, M.Q. Mehmood, Y. Lei, Isar cross-range scaling by using sharpness maximization. Geosci. Remote Sens. Lett. IEEE 12(1), 165\u2013169 (2015) 22. S. Shao, L. Zhang, J. Wei, H. Liu, Two-dimension joint super-resolution isar imaging with joint motion compensation and azimuth scaling. IEEE Geosci. Remote Sens. Lett. 99, 1\u20135 (2020)\nPublisher\u2019s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations."
        }
    ],
    "title": "Joint ISAR imaging and azimuth scaling under low SNR using parameterized compensation and calibration method with entropy minimum criterion",
    "year": 2023
}