{
    "abstractText": "School of Education and Music, Sanming University, Sanming 365004, China School of Information Engineering, Sanming University, Sanming 365004, China School of Computer Science and Technology, Hainan University, Haikou 570228, China Research and Innovation Department, Skyline University College, Sharjah 1797, UAE Faculty of Computer Sciences and Informatics, Amman Arab University, Amman 11953, Jordan School of Computer Science, Universiti Sains Malaysia, George Town, Pulau Pinang 11800, Malaysia",
    "authors": [
        {
            "affiliations": [],
            "name": "Di Wu"
        },
        {
            "affiliations": [],
            "name": "Shuang Wang"
        },
        {
            "affiliations": [],
            "name": "Qingxin Liu"
        },
        {
            "affiliations": [],
            "name": "Laith Abualigah"
        },
        {
            "affiliations": [],
            "name": "Heming Jia"
        }
    ],
    "id": "SP:ad045ca3437226d0be3a16e45241c82fc6e7fe02",
    "references": [
        {
            "authors": [
                "L. Abualigah",
                "A. Diabat"
            ],
            "title": "Advances in sine cosine algorithm: a comprehensive survey",
            "venue": "Artificial Intelligence Review, vol. 54, no. 4, pp. 2567\u20132608, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "L. Abualigah",
                "A. Diabat"
            ],
            "title": "A comprehensive survey of the grasshopper optimization algorithm: results, variants, and applications",
            "venue": "Neural Computing & Applications, vol. 32, no. 19, Article ID 15533, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "W. Deng",
                "X. Zhang",
                "Y. Zhou"
            ],
            "title": "An enhanced fast nondominated solution sorting genetic algorithm for multi-objective problems",
            "venue": "Information Sciences, vol. 585, pp. 441\u2013453, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Y. Kumar",
                "P.K. Singh"
            ],
            "title": "Improved cat swarm optimization algorithm for solving global optimization problems and its application to clustering",
            "venue": "Applied Intelligence, vol. 48, no. 9, pp. 2681\u20132697, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "E.Q. Wu",
                "M. Zhou",
                "D. Hu"
            ],
            "title": "Self-paced dynamic infinite mixture model for fatigue evaluation of pilots\u2019 brains",
            "venue": "IEEE Transactions on Cybernetics, pp. 1\u20136, IEEE, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "J.H. Holland"
            ],
            "title": "Genetic algorithms",
            "venue": "Scientific American, vol. 267, no. 1, pp. 66\u201372, 1992.",
            "year": 1992
        },
        {
            "authors": [
                "R. Storn",
                "K. Price"
            ],
            "title": "Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces",
            "venue": "Journal of Global Optimization, vol. 11, no. 4, pp. 341\u2013359, 1997.",
            "year": 1997
        },
        {
            "authors": [
                "S. Kirkpatrick",
                "C.D. Gelatt",
                "M.P. Vecchi"
            ],
            "title": "Optimization by simulated annealing",
            "venue": "Science, vol. 220, no. 4598, pp. 671\u2013680, 1983.",
            "year": 1983
        },
        {
            "authors": [
                "L. Abualigah",
                "A. Diabat",
                "S. Mirjalili",
                "M. Abd Elaziz",
                "A.H. Gandomi"
            ],
            "title": "0e arithmetic optimization algorithm",
            "venue": "Computer Methods in Applied Mechanics and Engineering, vol. 376, Article ID 113609, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "F. Asef",
                "V. Majidnezhad",
                "M.-R. Feizi-Derakhshi",
                "S. Parsa"
            ],
            "title": "Heat transfer relation-based optimization algorithm (HTOA)",
            "venue": "Soft Computing, vol. 25, no. 13, pp. 8129\u20138158, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "J. Kennedy",
                "R. Eberhart"
            ],
            "title": "Particle swarm optimization,\u201dvol",
            "venue": "Proceedings of the 1995 IEEE International Conference on Neural Networks, IEEE ICNN,",
            "year": 1995
        },
        {
            "authors": [
                "S. Mirjalili",
                "A.H. Gandomi",
                "S.Z. Mirjalili",
                "S. Saremi",
                "H. Faris",
                "S.M. Mirjalili"
            ],
            "title": "Salp swarm algorithm: a bio-inspired optimizer for engineering design problems",
            "venue": "Advances in Engineering Software, vol. 114, pp. 163\u2013191, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "S. Mirjalili",
                "S.M. Mirjalili",
                "A. Lewis"
            ],
            "title": "Grey wolf optimizer",
            "venue": "Advances in Engineering Software, vol. 69, pp. 46\u201361, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "S. Mirjalili",
                "A. Lewis"
            ],
            "title": "0e whale optimization algorithm",
            "venue": "Advances in Engineering Software, vol. 95, pp. 51\u201367, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "L. Abualigah",
                "D. Yousri",
                "M.A. Elaziz",
                "A.A. Ewees",
                "M.A.A. Alqaness",
                "A.H. Gandomi"
            ],
            "title": "Aquila optimizer: a novel meta-heuristic optimization algorithm",
            "venue": "Computers & Industrial Engineering, vol. 157, Article ID 107250, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "H. Jia",
                "X. Peng",
                "C. Lang"
            ],
            "title": "Remora optimization algorithm",
            "venue": "Expert Systems with Applications, vol. 185, p. 115665, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "R.V. Rao",
                "V.J. Savsani",
                "D.P. Vakharia"
            ],
            "title": "Teaching\u2013learning-based optimization: a novel method for constrained mechanical design optimization problems",
            "venue": "Computer-Aided Design, vol. 43, pp. 303\u2013315, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "A. Aouf",
                "L. Boussaid",
                "A. Sakly"
            ],
            "title": "TLBO-based adaptive neurofuzzy controller for mobile robot navigation in a strange environment",
            "venue": "Computational Intelligence and Neuroscience, vol. 2018, Article ID 3145436, 8 pages, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "M. Singh",
                "B.K. Panigrahi",
                "A.R. Abhyankar"
            ],
            "title": "Optimal coordination of directional over-current relays using teaching learning-based optimization (TLBO) algorithm",
            "venue": "International Journal of Electrical Power & Energy Systems, vol. 50, pp. 33\u201341, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "D.L. Gonzalez-Alvarez",
                "M.A. Vega-Rodriguez",
                "J.A. Gomez- Pulido",
                "J.M. Sanchez-Perez"
            ],
            "title": "Multiobjective teachinglearning-based optimization (MO-TLBO) for motif finding",
            "venue": "Proceedings of the IEEE International Conference on Intelligence and Informatics CINTI\u201912, pp. 1\u20136, IEEE, Budapest Hungary, November 2012.",
            "year": 2012
        },
        {
            "authors": [
                "F. Zou",
                "D. Chen",
                "Q. Xu"
            ],
            "title": "A survey of teaching\u2013learningbased optimization",
            "venue": "Neurocomputing, vol. 335, pp. 366\u2013383, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Y. Kumar",
                "P.K. Singh"
            ],
            "title": "A chaotic teaching learning based optimization algorithm for clustering problems",
            "venue": "Applied Intelligence, vol. 49, pp. 1036\u20131062, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "A. Taheri",
                "K. Rahimizadeh",
                "R.V. Rao"
            ],
            "title": "An efficient balanced teaching-learning-based optimization algorithm with individual restarting strategy for solving global optimization problems",
            "venue": "Information Sciences, vol. 576, pp. 68\u2013 104, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Ma",
                "X. Zhang",
                "J. Song",
                "L. Chen"
            ],
            "title": "A modified teachinglearning-based optimization algorithm for solving optimization problem",
            "venue": "KnowledgE \u2212 Based Systems, vol. 212, Article ID 106599, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Xu",
                "Z. Yang",
                "X. Li",
                "H. Kang",
                "X. Yang"
            ],
            "title": "Dynamic opposite learning enhanced teaching-learning-based optimization",
            "venue": "KnowledgE \u2212 Based Systems, vol. 188, Article ID 104966, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "H. Dong",
                "P. Wang",
                "B. Song"
            ],
            "title": "Kriging-assisted teachinglearning-based optimization (KTLBO) to solve computationally expensive constrained problems",
            "venue": "Information Sciences, vol. 556, pp. 404\u2013435, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Z. Ren",
                "R. Jiang",
                "F. Yang",
                "J. Qiu"
            ],
            "title": "A multi-objective elitist feedback teaching\u2013learning-based optimization algorithm 22 Computational Intelligence and Neuroscience and its application",
            "venue": "Expert Systems with Applications, vol. 188, Article ID 115972, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Zhang",
                "Z. Jin",
                "Y. Chen"
            ],
            "title": "Hybrid teaching-learningbased optimization and neural network algorithm for engineering design optimization problems",
            "venue": "KnowledgE \u2212 Based Systems, vol. 187, Article ID 104836, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A.V. Lakshmi",
                "P. Mohanaiah"
            ],
            "title": "WOA-TLBO: whale optimization algorithm with teaching-learning-based optimization for global optimization and facial emotion recognition",
            "venue": "Applied Soft Computing, vol. 110, Article ID 107623, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A.A. Heidari",
                "S. Mirjalili",
                "H. Faris",
                "I. Aljarah",
                "M. Mafarja",
                "H. Chen"
            ],
            "title": "Harris hawks optimization: algorithm and applications",
            "venue": "Future Generation Computer Systems, vol. 97, pp. 849\u2013872, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "F. Miarnaeimi",
                "G. Azizyan",
                "M. Rashki"
            ],
            "title": "Horse herd optimization algorithm: a naturE \u2212 inspired algorithm for high-dimensional optimization problems",
            "venue": "KnowledgE- \u2212 Based Systems, vol. 213, Article ID 106711, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Gupta",
                "K. Deep"
            ],
            "title": "A memory-based grey wolf optimizer for global optimization tasks",
            "venue": "Applied Soft Computing, vol. 93, Article ID 106367, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Wang",
                "K. Sun",
                "W. Zhang",
                "H. Jia"
            ],
            "title": "Multilevel thresholding using a modified ant lion optimizer with oppositionbased learning for color image segmentation",
            "venue": "Mathematical Biosciences and Engineering, vol. 18, pp. 3092\u20133143, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Li",
                "Y. Zhao",
                "J. Liu"
            ],
            "title": "Dynamic sine cosine algorithm for largE \u2212 scale global optimization problems",
            "venue": "Expert Systems with Applications, vol. 177, Article ID 114950, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "E. Talbi"
            ],
            "title": "Machine learning into metaheuristics: a survey and taxonomy of data-driven metaheuristics",
            "venue": "ACM Computing Surveys, vol. 54, pp. 1\u201332, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "M. Drugan"
            ],
            "title": "Reinforcement learning versus evolutionary computation: a survey on hybrid algorithms",
            "venue": "Swarm and Evolutionary Computation, vol. 44, pp. 228\u2013246, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "G. Lingam",
                "R.R. Rout",
                "D.V.L.N. Somayajulu"
            ],
            "title": "Adaptive deep Q-learning model for detecting social bots and influential users in online social networks",
            "venue": "Applied Intelligence, vol. 49, pp. 3947\u20133964, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "F. Liu",
                "G. Zeng"
            ],
            "title": "Study of genetic algorithm with reinforcement learning to solve the TSP",
            "venue": "Expert Systems with Applications, vol. 36, pp. 6995\u20137001, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "H. Samma",
                "J. Mohamad-Saleh",
                "S.A. Suandi",
                "B. Lahasan"
            ],
            "title": "Q-learning-based simulated annealing algorithm for constrained engineering design problems",
            "venue": "Neural Computing & Applications, vol. 32, pp. 5147\u20135161, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Q. Chen",
                "M. Huang",
                "Q. Xu",
                "H. Wang",
                "J. Wang"
            ],
            "title": "Reinforcement learning-based genetic algorithm in optimizing multidimensional data discretization scheme",
            "venue": "Mathematical Problems in Engineering, vol. 20, pp. 1\u201313, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Xu",
                "D. Pi"
            ],
            "title": "A reinforcement learning-based communication topology in particle swarm optimization",
            "venue": "Neural Computing & Applications, vol. 32, pp. 1\u201326, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "E. Emary",
                "H.M. Zawbaa",
                "C. Grosan"
            ],
            "title": "Experienced gray wolf optimization through reinforcement learning and neural networks",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems, vol. 29, pp. 681\u2013694, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M. Ghafoorian",
                "N. Taghizadeh",
                "H. Beigy"
            ],
            "title": "Automatic Abstraction in Reinforcement Learning Using Ant System Algorithm",
            "venue": "Proceedings of the AAAI Spring Symposium Series, pp. 9\u201314, Stanford, CA, USA, March 2017.",
            "year": 2017
        },
        {
            "authors": [
                "A. Seyyedabbasi",
                "R. Aliyev",
                "F. Kiani",
                "M.U. Gulle",
                "M.A. Shah"
            ],
            "title": "Hybrid algorithms based on combining reinforcement learning and metaheuristic methods to solve global optimization problems",
            "venue": "KnowledgE \u2212 Based Systems, vol. 222, Article ID 107044, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "H. Tizhoosh"
            ],
            "title": "Opposition-based learning: a new scheme for machine intelligence",
            "venue": "Proceedings of the International Conference on Computational Intelligence for Modelling, pp. 695\u2013701, Vienna, Austria, November 2005.",
            "year": 2005
        },
        {
            "authors": [
                "W. Long",
                "J. Jiao",
                "X. Liang",
                "S. Cai",
                "M. Xu"
            ],
            "title": "A random opposition-based learning grey wolf pptimizer",
            "venue": "IEEE Access, vol. 7, Article ID 113810, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "X. Yao",
                "Y. Liu",
                "G. Lin"
            ],
            "title": "Evolutionary programming made faster",
            "venue": "IEEE Transactions on Evolutionary Computation, vol. 3, pp. 82\u2013102, 1999.",
            "year": 1999
        },
        {
            "authors": [
                "J. Derrac",
                "S. Gar\u0107\u0131a",
                "D. Molina",
                "F. Herrera"
            ],
            "title": "A practical tutorial on the use of nonparametric statistical tests as a methodology for comparing evolutionary and swarm intelligence algorithms",
            "venue": "Swarm Evolut Comput, vol. 1, pp. 3\u201318, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "N.H. Awad",
                "M.Z. Ali",
                "P.N. Suganthan",
                "J.J. Liang",
                "B.Y. Qu"
            ],
            "title": "Problem Definitions and Evaluation Criteria for the CEC2017",
            "venue": "Special Session and Competition on Single Objective Real-Parameter Numerical Optimization, IEEE Congress on Evolutionary Computation, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "S.M. Li",
                "H.L. Chen",
                "M.J. Wang",
                "A.A. Heidari",
                "S. Mirjalili"
            ],
            "title": "Slime mould algorithm: a new method for stochastic optimization",
            "venue": "Future Generation Computer Systems, vol. 111, pp. 300\u2013323, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A. Faramarzi",
                "M. Heidarinejad",
                "S. Mirjalili",
                "A.H. Gandomi"
            ],
            "title": "Marine predators algorithm: a naturE- \u2212 inspired metaheuristic",
            "venue": "Expert Systems with Applications, vol. 152, Article ID 113377, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Mirjalili",
                "S.M. Mirjalili",
                "A. Hatamlou"
            ],
            "title": "Multi-verse optimizer: a naturE \u2212 inspired algorithm for global optimization",
            "venue": "Neural Computing & Applications, vol. 27, pp. 495\u2013513, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "Z.W. Geem",
                "J.H. Kim",
                "G.V. Loganathan"
            ],
            "title": "A new heuristic optimization algorithm: harmony search",
            "venue": "SIMU- LATION, vol. 76, pp. 60\u201368, 2001.",
            "year": 2001
        },
        {
            "authors": [
                "S. Mirjalili"
            ],
            "title": "SCA: a sine cosine algorithm for solving optimization problems",
            "venue": "KnowledgE \u2212 Based Systems, vol. 96, pp. 120\u2013133, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "G.A. Baykaso",
                "F.B. Ozsoydan"
            ],
            "title": "Adaptive firefly algorithm with chaos for mechanical design optimization problems",
            "venue": "Applied Soft Computing, vol. 36, pp. 152\u2013164, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "S. Saremi",
                "S. Mirjalili",
                "A. Lewis"
            ],
            "title": "Grasshopper optimisation algorithm: theory and application",
            "venue": "Advances in Engineering Software, vol. 105, pp. 30\u201347, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "B.S. Yildiz",
                "N. Pholdee",
                "S. Bureerat",
                "A.R. Yildiz",
                "S.M. Sait"
            ],
            "title": "Enhanced Grasshopper Optimization Algorithm Using Elite Opposition-Based Learning for Solving Real-World Engineering Problems",
            "venue": "Engineering with Computers, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A.H. Gandomi",
                "X.S. Yang",
                "A.H. Alavi"
            ],
            "title": "Cuckoo search algorithm: a metaheuristic approach to solve structural optimization problems",
            "venue": "Engineering with Computers, vol. 29, pp. 17\u201335, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "B. Abdollahzadeh",
                "F.S. Gharehchopogh",
                "S. Mirjalil"
            ],
            "title": "Artificial gorilla troops optimizer: a new naturE \u2212 inspired metaheuristic algorithm for global optimization problems",
            "venue": "International Journal of Intelligent Systems, vol. 36, pp. 1\u201372, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S. Mirjalili"
            ],
            "title": "Moth-flame optimization algorithm: a novel naturE \u2212 inspired heuristic paradigm",
            "venue": "KnowledgE \u2212 Based Systems, vol. 89, pp. 228\u2013249, 2015. Computational Intelligence and Neuroscience 23",
            "year": 2015
        },
        {
            "authors": [
                "S. Kaur",
                "L.K. Awasthi",
                "A.L. Sangal",
                "G. Dhiman"
            ],
            "title": "Tunicate swarm algorithm: a new bio-inspired based metaheuristic paradigm for global optimization",
            "venue": "Engineering Applications of Artificial Intelligence, vol. 90, pp. 1\u201329, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "H. Shayanfar",
                "F.S. Gharehchopogh"
            ],
            "title": "Farmland fertility: a new metaheuristic algorithm for solving continuous optimization problems",
            "venue": "Applied Soft Computing, vol. 71, pp. 728\u2013746, 2018. 24 Computational Intelligence and Neuroscience",
            "year": 2018
        }
    ],
    "sections": [
        {
            "heading": "Research Article",
            "text": "An Improved Teaching-Learning-Based Optimization"
        },
        {
            "heading": "Algorithm with Reinforcement Learning Strategy for Solving",
            "text": ""
        },
        {
            "heading": "Optimization Problems",
            "text": "Di Wu ,1 Shuang Wang ,2 Qingxin Liu ,3 Laith Abualigah ,4,5,6 and Heming Jia 2\n1School of Education and Music, Sanming University, Sanming 365004, China 2School of Information Engineering, Sanming University, Sanming 365004, China 3School of Computer Science and Technology, Hainan University, Haikou 570228, China 4Research and Innovation Department, Skyline University College, Sharjah 1797, UAE 5Faculty of Computer Sciences and Informatics, Amman Arab University, Amman 11953, Jordan 6School of Computer Science, Universiti Sains Malaysia, George Town, Pulau Pinang 11800, Malaysia\nCorrespondence shouldbeaddressed toShuangWang;wang_shuang9279@163.comandHeming Jia; jiaheminglucky99@126.com\nReceived 21 August 2021; Revised 1 December 2021; Accepted 22 February 2022; Published 24 March 2022\nAcademic Editor: Navid Razmjooy\nCopyright \u00a9 2022 DiWu et al. 0is is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\n0is paper presents an improved teaching-learning-based optimization (TLBO) algorithm for solving optimization problems, called RLTLBO. First, a new learning mode considering the effect of the teacher is presented. Second, the Q-Learning method in reinforcement learning (RL) is introduced to build a switching mechanism between two different learning modes in the learner phase. Finally, ROBL is adopted after both the teacher and learner phases to improve the local optima avoidance ability of RLTLBO. 0ese two strategies effectively enhance the convergence speed and accuracy of the proposed algorithm. RLTLBO is analyzed on 23 standard benchmark functions and eight CEC2017 test functions to verify the optimization performance. 0e results reveal that proposed algorithm provides effective and efficient performance in solving benchmark test functions. Moreover, RLTLBO is also applied to solve eight industrial engineering design problems. Compared with the basic TLBO and seven state-ofthe-art algorithms, the results illustrate that RLTLBO has superior performance and promising prospects for dealing with realworld optimization problems. 0e source codes of the RLTLBO are publicly available at https://github.com/WangShuang92/ RLTLBO."
        },
        {
            "heading": "1. Introduction",
            "text": "In recent years, real-world optimization problems have become increasingly complex and diverse in a wide range of fields and disciplines. Traditional (mathematical) optimization methods, such as Newton\u2019s method and the gradient descent method can no longer meet the needs for solving current optimization problems. 0us, nontraditional methods, especially metaheuristic algorithms, are becoming increasingly pervasive among researchers [1\u20133]. Metaheuristics are algorithms based on intuition or experience, that can provide a feasible solution at an acceptable cost (referring to computing time and computational resources),\nand the deviation between the feasible solution and the optimal solution may not be predicted in advance. Metaheuristic optimization algorithms have the merits of being flexible, having few parameters and avoiding local optima. Additionally, they can be rapidly deployed and thus have been utilized for solving various optimization problems over the past decades [4, 5]. Some of the most representative meta-heuristic algorithms are listed as follows: genetic algorithms (GA) [6], differential evolution algorithm (DE) [7], simulated annealing (SA) [8], arithmetic optimization algorithm (AOA) [9], heat transfer relation-based optimization algorithm (HTOA) [10], particle swarm optimization (PSO) [11], salp swarm algorithm (SSA) [12], grey wolf"
        },
        {
            "heading": "Hindawi",
            "text": "Computational Intelligence and Neuroscience Volume 2022, Article ID 1535957, 24 pages https://doi.org/10.1155/2022/1535957\noptimizer (GWO) [13], whale optimization algorithm (WOA) [14], aquila optimizer (AO) [15], remora optimization algorithm (ROA) [16], etc.\nTeaching-learning-based optimization (TLBO) is a meta-heuristic algorithm proposed by Rao et al. in 2011 [17]. 0e TLBO method is inspired by the teaching-learning process in a class and simulates the influence of a teacher on learners. Due to the advantages of rapid convergence, absence of algorithm-specific parameters and easy implementation, TLBO has become a viral optimization algorithm and has been successfully applied to real-world problems in diverse fields. Aouf et al. [18] applied TLBO to optimize the parameters of the ANFIS structure to obtain the optimal trajectory and traveling time to address the navigation problem of themobile robot in a strange environment. Singh et al. [19] studied the application of TLBO for optimal coordination of directional overcurrent relays (DOCRs) in a looped power system. Multiobjective TLBO was applied to solve the motif discovery problem (MDP) in the bioinformatics field by Gonzalez-Alvarez et al. [20], and obtained better solutions than other biology-based multiobjective evolutionary algorithms. All the above applications have suggested that TLBO can be effectively applied to many optimization problems in various fields.\n0e improvement and hybrid algorithms of TLBO and their applications have also been studied by several researchers [21]. Kumar and Singh [22] developed a chaotic version of TLBO with different chaotic mechanisms. A local search method was also incorporated to guide the search direction between local and global search and to improve the quality of solution. 0e application of clustering problems proved the effectiveness of this algorithm. Taheri et al. [23] proposed a balanced TLBO with three modifications, called BTLBO. A weighted mean replaced the mean value in the teacher phase to maintain the diversity. 0e tutoring phase was added as a powerful local search mechanism for exploiting regions around the best solution. 0e restarting phase was introduced to improve the exploration ability by replacing inactive learners with randomly initialized learners. Ma et al. [24] proposed amodified TLBO (MTLBO) by introducing a population groupmechanism into the basic TLBO. All students were divided into two groups and updated by different updating strategies. 0e MTLBO was also applied to establish the NOx emission model of a circulation fluidized bed boiler. Xu et al. [25] introduced dynamic-opposite learning (DOL) strategy into TLBO to overcome premature convergence. 0e asymmetric search space and the dynamic change in the characteristics of DOL help DOLTLBO to holistically improve the exploitation and exploration capabilities. Dong et al. [26] presented a KTLBO algorithm to achieve computationally expensive constrained optimization. 0e kriging-assisted two-phase optimization framework was used to alternately conduct global and local searches, achieving the search acceleration. KTLBO was also adopted to design the structure of a blended-wing-body underwater glider. Ren et al. [27] developed a multiobjective elitist feedback TLBO (MEFTO) for multiobjective optimization problems.0e elitism strategy was used to store the best solutions obtained thus far. 0e proposed feedback\nphase allowed students to choose whether to study directly with the teacher or tomotivate themselves, providing a novel way for students to improve themselves. Zhang et al. [28] proposed a hybrid algorithm based on TLBO and a neural network algorithm (NNA) named TLNNA to solve engineering optimization problems. 0e experimental results suggested that TLNNA has improved global search ability and fast convergence speed. By considering the features of the WOA and TLBO, Lakshmi and Mohanaiah [29] proposed a hybrid WOA-TLBO algorithm. 0is was also applied to solve the facial emotion recognition (FER) functional problem, and the reported results showed its effectiveness and high accuracy.\n0e TLBO variants proposed previously have improved searchability and accelerated the convergence process, but they still struggle with premature convergence and insufficient learning processes. 0us, in this paper we propose an improved TLBO algorithm to solve industrial engineering optimization problems. Given the characteristics of TLBO, reinforcement learning (RL) in machine learning is introduced to the learner phase, and enables the algorithm to choose a more suitable learning mode, which can train the search agents to perform more beneficial actions. In addition, a random opposition-based learning (ROBL) strategy is added after the whole learner phase to facilitate the convergence acceleration and avoid local optima. 0e proposed improved TLBO with RH and ROBL strategies is called RLTLBO. 0e standard and CEC2017 benchmark functions and eight engineering design problems are used to test the exploration and exploitation capabilities of the proposed method. 0e RLTLBO algorithm is compared with some existing algorithms, including the basic TLBO and the Salp Swarm Algorithm (SSA), which are considered the classical algorithms, the Aquila Optimizer (AO), Harris Hawks Optimization (HHO) [30], and Horse herd Optimization Algorithm (HOA) [31], which are the recent new methods, and thememory-based GreyWolf Optimizer (mGWO) [32], modified Ant Lion Optimizer (MALO) [33] and dynamic Sine Cosine Algorithm (DSCA) [34], which are the latest improved algorithms.0e experimental results show that the proposed RLTLBOmethod is superior to the state-of-the-art algorithms in exploration and exploitation capabilities. Moreover, eight industrial engineering design problems are applied to evaluate the effectiveness of the algorithm when solving real-world optimization problems.\n0e rest of this paper is organized as follows: Section 2 provides a brief overview of the basic TLBO, RL, and ROBL strategies. Section 3 describes the proposed RLTLBO algorithm in detail. Simulations, experiments and an analysis of the results are presented in Section 4. Section 5 describes industrial engineering design problems. Finally, Section 6 concludes the paper."
        },
        {
            "heading": "2. Related Work",
            "text": "2.1. Teaching-Learning-Based Optimization. 0e TLBO algorithm mimics the influence of a teacher on the output of learners, which can be reflected by learners\u2019 grades. As a highly learned person, the teacher gives their knowledge to\nthe learners. 0e outcome of the learners is affected by the quality of the teacher. It is obvious that learners trained by a good teacher can achieve better results in terms of their grades. 0e optimization process of TLBO is divided into two phases: the teacher phase and the learner phase.\n2.1.1. Teacher Phase. 0e teacher phase simulates the teaching process of a teacher. 0e best one in the class is selected as the teacher, and then the teacher tries their best to improve the overall level of the class. 0e teaching process can be formulated as follows:\nXnew \ufffd Xold + rand Xteacher \u2212 TF \u00b7 Mean( , (1)\nwhere Xnew and Xold represent the positions of the individual after and before learning, that is, the candidate solutions after and before updating. Xteacher is the position of the teacher, which is the best individual of the population. Mean indicates the average level of search agents in the population. TF is a teaching factor that determines the change of the mean value, and rand is a random number between 0 and 1. 0e value of TF can be either 1 or 2, which is a heuristic step and randomly decided with equal probability as TF\ufffd round (1 + rand (0, 1){2\u20131}).\n2.1.2. Learner Phase. In addition to learning new knowledge from the teacher, learners can also increase knowledge through interaction. In the mutual learning process, a learner can randomly learn knowledge from another learner with a better grade randomly. 0e expression of the learner phase can be written as follows:\nXnew \ufffd Xold + rand Xr1 \u2212 Xr2( f Xr1( <f Xr2( \nXold + rand Xr2 \u2212 Xr1( otherwise  , (2)\nwhere Xr1 and Xr2 indicate the positions of two learners randomly selected from the population. f (\u00b7) is the fitness value. 0e comparison between two learners determines the learning direction. 0e individual with a poor grade learns from the individual with a better grade. 0e new individual with improvements after learning will be accepted, otherwise rejected.\n0e flow chart of the TLBO algorithm is shown in Figure 1.\n2.2. Reinforcement Learning (RL). Machine learning algorithms are also widely used to solve various optimization problems [35]. Machine learning methods generally consist of four categories, as shown in Figure 2: supervised learning, unsupervised learning, semisupervised learning, and reinforcement learning (RL). In RL algorithms, the agent is trained to learn optimal actions in a complex environment. 0e agent is trained in different ways and uses its training experience in the subsequent actions. RL methods generally consist of model-free and model-based approaches. 0e model-free approaches can be divided into two subgroups: value-based and policy-based methods. 0e value-based algorithms are convenient for coordinating with\nmeta-heuristic algorithms because they are model-free and policy-free, providing higher flexibility [36]. In the valuebased RL approaches, the reinforcement agent learns from its actions and experience in the environment, such through reward and penalty. 0e agent measures the success of the action in completing the task goal through the reward penalty and then makes a decision based on its achievement.\n0e Q-Learning method is one of the representative algorithms among the value-based RL methods. In the Q-Learning method, the agent takes random actions and then obtains a reward or penalty. An experience is gradually constructed based on the agent\u2019s actions. 0roughout process of building experience, a table called Q-Table is defined [37]. 0e agent considers all possible actions and tries to update its state according to the Q-Table values to select the best action that maximizes the current state\u2019s maximal rewards. 0erefore, the agent in action determines whether to explore or exploit the environment.\nCompared to RL methods, meta-heuristic algorithms often require deep expert knowledge to establish the balance between different phases. RL methods can help discover optimal designs of parameters and more balanced strategies allowing the algorithm to switch between the exploration and exploitation phases. Metaheuristic methods usually operate with specific policies in certain situations, and thus, the dynamism is lower than that of RL algorithms, especially value-based methods. 0e agent in the value-based methods is online and operates beneficial actions through a rewardpenalty mechanism without following any policy. Many types of research have been presented in the literature regarding the combination of meta-heuristics and RL [38\u201344]."
        },
        {
            "heading": "2.3. Random Opposition-Based Learning (ROBL).",
            "text": "Random opposition-based learning (ROBL) is a variant of opposition-based learning (OBL) [45] proposed by Long et al. in 2019 [46]. OBL is a powerful optimization tool that simultaneously considers the fitness of an estimate and its corresponding opposite estimate to achieve a better candidate solution. In contrast from the basic OBL, ROBL utilizes a random term to improve the OBL strategy, which is defined as follows:\nxj \ufffd lj + uj \u2212 rand \u00d7 xj, j \ufffd 1, 2, . . . , n, (3)\nwhere xj and xj indicate the opposite and original solutions, uj and lj are the upper and lower bound of the problem in jth dimension.0e opposite solution is randomly selected in the opposite half of the search space. 0is solution is not only opposite, but also random, with a wider range of distributions. An example of ROBL solutions is shown in Figure 3. 0e opposite solution with a random term described by equation (3) is more stochastic than the basic OBL and can effectively help the algorithm jump out of the local optima."
        },
        {
            "heading": "3. The Proposed RLTLBO Algorithm",
            "text": "3.1. New Learning Mode. 0e basic TLBO algorithm performs the learner phase after the teacher phase in each iteration.0e search agent learns from other individuals in the\nlearner phase. However, in the actual learning process, students learning from each other varies from person to person. Different students might choose different learning modes, such as formal communications, group discussions, presentations, etc. Moreover, the students might adjust the\nlearning mode according to their learning situation during the learning process. 0erefore, in this paper, we introduce another learning mode to diversify the learning methods of the students, which can be described in the equations as follows:\nXnew \ufffd\nXold + rand 1 \u2212 t\nT  Xr3 +\nt\nT  Xteacher \u2212 Xold f Xr3( <f Xold( \nXold + rand 1 \u2212 t\nT  Xold +\nt\nT  Xteacher \u2212 Xr3 otherwise\n\u23a7\u23aa \u23aa\u23aa \u23a8\n\u23aa \u23aa\u23aa \u23a9\n, (4)\nwhere Xr3 is the position of a learner randomly selected from the population. t and T are the current and maximum number of iterations.\nIn this learning mode, the effect of the teacher is introduced. Sometimes the mutual learning between students is not always beneficial, and the partial intervention of the teacher is more helpful to students\u2019 improvement. Students will not only learn from each other but also ask the teacher for help. At the beginning of the iterations, the weight of mutual learning among students is larger, and the algorithm paysmore attention to random learning, which canmaintain population diversity and increase global searchability. In the later iteration stage, students consult more from the teacher and approach the teacher, enhancing the algorithms local searchability.\n3.2. Learner Phase with RL Strategy. To enable students to adjust their learning mode more effectively, Q-Learning in RL is introduced to complete the switching between both learning modes. 0e student uses Q-Table values as a guide to decide between different learning modes. 0e Q-table is\nupdated using a reward-penalty mechanism. 0e student selects the best state by calculating the benefit degree of each possible state and taking the leaning mode with the highest Q-values for the next step. 0e student obtains a reward or a penalty according to its actions after each step. 0e general pattern of the RL agent and environmental framework is shown in Figure 4.\nIn the Q-Learning method, a reward table is used to reward or penalize the agent for its action or state compositions, which users can provide. 0e reward table in this work contains the positive (+1) or negative (\u2212 1) rewards for each state and action couple. 0e Q-Table can be considered the agents experience, which should be assigned a zero value for all units in the beginning. Consequently, the student updates Q-Table using the Bellman equation (5) and prepares the Q-Table for the next iteration [44].\nQ(t+1) st, at( \u2190Qt st, at( \n+ \u03bb rt+1 + cMaxQt st+1 ,a( ) \u2212 Qt st, at(  , (5)\nwhere st and st + 1 indicate the current and the next state respectively, Qt and Qt + 1 are the current Q-value and preestimated Q-value for the next state st + 1, and at represents the current action. \u03bb and c are the learning rate value and discount factor, respectively, which are numbers between 0 and 1. 0e learning rate determines how fast the algorithm should learn and controls the convergence of the learning process.0e discount factor defines howmuch the algorithm learns from the mistake and controls the importance of future rewards. rt + 1 indicates the immediate reward or penalty an agent gets for taking current action.\nIn each iteration, the agent uses equation (5) to calculate and weight each possible state and action for the next step, before choosing the best action (learning mode 1 or learning mode (2) with the highest likelihood to get closer to the best optimal solution. Examples of the reward table and Q-Table are displayed in Figure 5. 0is RL strategy helps establish a switching mechanism between different learning modes in the learner phase and find themost suitable decision scheme. Four optional actions can occur as listed below:\n(1) When the student is learning in learning mode 1, they still decides to stay in learning mode 1\n(2) When the student is learning in learning mode 2, they still decides to stay in learning mode 2\n(3) When the student learns in learning mode 1, they decides to transition to learning mode 2\n(4) When the student learns in learning mode 1, they decides to transition to learning mode 2\n0emost important value of the RL strategy is to help the algorithm switch between different learning modes as and when needed during the learner phase. For the above reason, the algorithm can find better solutions faster and more effectively in the search space, considerably increasing the search efficiency. 0erefore, the convergence speed of the algorithm can be improved effectively.\n3.3. <e Detail of RLTLBO. In the improved TLBO algorithm, the teacher phase of basic TLBO is carried out first. 0en, the learner phase with RL strategy is implemented to\nachieve effective and efficient investigation in the search space. Finally, ROBL is added to enhance the ability of local optima avoidability.0e random opposite solution increases the probability of the algorithm finding a better solution. 0is variant of TLBO, which incorporates RL, is named RLTLBO.0e pseudocode and the flowchart of the proposed RLTLBO algorithm are shown in Algorithm 1 and Figure 6, respectively.\n3.4. Computational Complexity Analysis. RLTLBO mainly consists of three components: initialization, fitness evaluation, and position updating. In the initialization phase, the computational complexity of positions generated is O(N). 0en, the computational complexity of fitness evaluation for the solution is O(2\u00d7N) during the iteration process. Finally, we utilize ROBL to keep the algorithm from falling into local optima. 0us, the computational complexities of position updating of RLTLBO is O(2\u00d7N\u00d7D), where D is the dimension size of the problem. 0erefore, the total computational complexity of the proposed RLTLBO algorithm is O(3\u00d7N+ 2\u00d7N\u00d7D)."
        },
        {
            "heading": "4. Numerical Experiments and Results",
            "text": "In this section, two different kinds of benchmark functions are performed to evaluate the performance of the proposed RLTLBO algorithm. Standard benchmark functions are first tested to assess the algorithm in solving twenty-three simple numerical problems. 0en, the CEC2017 benchmark functions are utilized to evaluate the algorithm in solving complex numerical problems. 0e RLTLBO is compared with three types of existing algorithms, including the classic methods, TLBO and SSA, the recently proposed algorithms, HOA [31], AO, and HHO [30], and the improved algorithms, mGWO [32], MALO [33] and DSCA [34]. For the consistency of all tests, we set the population size to N \ufffd 30, the dimension size to D \ufffd 30, and the maximum number of iterations to T \ufffd 500. All algorithms are run 30 times independently, and the average values and standard deviations are presented as the final experimental results. All experiments are implemented in MATLAB R2020b on a PC with Intel (R) Core (TM) i5-9500 CPU @ 3.00 GHz and RAM 16GB memory on OS windows 10.\n4.1. Standard Benchmark Function Experiments. Standard benchmark functions [47] can be divided into three types: unimodal, multimodal and fixed-dimension multimodal functions. Unimodal functions only have one global optimum and no local optima, which can be used to evaluate an algorithm\u2019s convergence rate and exploitation capability. Multimodal and fixed-dimension multimodal functions have a global optimum and multiple local optima. 0is characteristic makes these functions effective for testing the exploration and local optima avoidance abilities of an algorithm. 0e benchmark function details are listed in Tables 1\u20133.\n-1\n-1+1\n+1\nLearning mode 1\nLearning mode 2\nLe ar\nni ng\nm od e 1 Le ar ni ng m od e 2 St at e\nAction\n(a)\n1.3\n3.5\n-0.6\n2.9\nLe ar\nni ng\nm od e 1 Le ar ni ng m od e 2\nLearning mode 1\nLearning mode 2\nSt at\ne\nAction\n(b)\n4.1.1. Qualitative Results. 0e data results of the 23 standard benchmark functions are shown in Table 4, and the optimal results are bolded. For the unimodal functions F1\u2013F7, the RLTLBO algorithm achieves the best results among all\ncomparative algorithms on most functions in average values and standard deviations, and only obtains worse results on F5\u2013F6. 0e RLTLBO obtains the theoretical optimum of F1 and F3. It can be concluded from the comparison results that\nFunction RLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA\nF1 Mean 0.00E+ 00 3.90E \u2212 79 4.26E \u2212 19 1.37E \u2212 03 2.55E \u2212 288 3.13E \u2212 136 2.34E \u2212 104 8.97E \u2212 98 1.30E \u2212 07Std 0.00E+ 00 6.59E \u2212 79 1.08E \u2212 18 1.56E \u2212 03 0.00E+ 00 1.21E \u2212 135 1.08E \u2212 103 4.16E \u2212 97 1.09E \u2212 07 F2 Mean 1.29E \u2212 223 4.17E \u2212 40 3.37E \u2212 12 6.86E+ 01 5.92E \u2212 171 4.44E \u2212 68 2.82E \u2212 53 1.34E \u2212 48 1.79E+ 00Std 0.00E+ 00 3.21E \u2212 40 2.54E \u2212 12 4.90E+ 01 0.00E+ 00 2.42E \u2212 67 1.13E \u2212 52 5.75E \u2212 48 1.15E+ 00 F3 Mean 0.00E+ 00 2.50E \u2212 17 6.41E \u2212 01 4.81E+ 03 1.43E \u2212 241 2.23E+ 02 2.22E \u2212 101 7.16E \u2212 79 1.61E+ 03Std 0.00E+ 00 4.35E \u2212 17 1.46E+ 00 2.18E+ 03 0.00E+ 00 5.03E+ 02 1.22E \u2212 100 3.56E \u2212 78 1.03E+ 03 F4 Mean 3.07E \u2212 221 1.72E \u2212 32 2.42E \u2212 03 1.64E+ 01 1.97E \u2212 134 5.04E \u2212 65 3.20E \u2212 53 2.51E \u2212 48 1.11E+ 01Std 0.00E+ 00 1.76E \u2212 32 3.02E \u2212 03 4.23E+ 00 1.08E \u2212 133 1.84E \u2212 64 1.75E \u2212 52 8.46E \u2212 48 3.74E+ 00 F5 Mean 2.65E+ 01 2.42E+ 01 2.64E+ 01 9.86E \u2212 01 2.85E+ 01 2.89E+ 01 6.82E \u2212 03 1.22E \u2212 02 2.55E+ 02Std 4.01E \u2212 01 7.41E \u2212 01 8.44E \u2212 01 5.21E+ 00 3.59E \u2212 01 7.45E \u2212 02 1.66E \u2212 02 1.79E \u2212 02 3.44E+ 02 F6 Mean 9.03E \u2212 02 2.57E \u2212 06 4.54E \u2212 01 5.00E \u2212 04 6.01E+ 00 6.46E+ 00 4.43E \u2212 05 9.58E \u2212 05 1.28E \u2212 07Std 1.15E \u2212 01 7.98E \u2212 06 3.20E \u2212 01 3.05E \u2212 04 1.61E \u2212 01 4.76E \u2212 01 6.15E \u2212 05 1.24E \u2212 04 1.13E \u2212 07 F7 Mean 3.57E \u2212 05 1.12E \u2212 03 4.61E \u2212 03 1.05E \u2212 04 2.54E \u2212 04 5.88E \u2212 02 9.62E \u2212 05 1.68E \u2212 04 1.81E \u2212 01Std 4.71E \u2212 05 3.06E \u2212 04 1.64E \u2212 03 7.89E \u2212 05 2.88E \u2212 04 4.10E \u2212 02 7.92E \u2212 05 1.36E \u2212 04 8.96E \u2212 02 F8 Mean \u2212 7.36E+ 03 \u2212 7.85E+ 03 \u2212 6.58E+ 03 \u2212 1.22E+ 04 \u2212 3.96E+ 03 \u2212 4.30E+ 03 \u2212 8.92E+ 03 \u2212 1.25E+ 04 \u2212 7.56E+ 03Std 6.78E+ 02 9.32E+ 02 1.24E+ 03 1.08E+ 03 4.31E+ 02 7.82E+ 02 3.77E+ 03 8.42E+ 01 7.07E+ 02\nRLTLBO has strong competitiveness in the unimodal functions, which indicates that the excellent exploitation capability comes from the RL mechanism.\nFor the multimodal and fixed-dimension multimodal functions F8\u2013F23, it can be seen from Table 4 that RLTLBO achieves the smallest average values and standard deviations on 12 of all 16 test functions compared to other methods, which indicates a very high accuracy and stability. Several poor results appear on F8 and F12\u2013F14, but they are not the worst results. 0e satisfying results on the multimodal and fixed-dimension multimodal functions prove that the exploration and local optima avoidance capabilities of the RLTLBO are excellent, which might be derived from the ROBL strategy.\nFigure 7 provides the convergence curves of RLTLBO and the comparative algorithms for 23 standard benchmark functions. 0e convergence rate reflected by convergence curves can show us the improvement of exploration and exploitation more intuitively. For F1\u2013F4, F7, F9\u2013F11, and F15\u2013F21, the RLTLBO presents a faster convergence speed than other meta-heuristic algorithms, and the convergence accuracy is also the best. 0e RLTLBO is ranked in the second position in terms of convergence speed for F22 and F23. For benchmark functions F5\u2013F6, F8, and F12\u2013F14, the RLTLBO does not perform very well, the same as the results in Table 4.\n4.1.2. <eWilcoxon Test. 0eWilcoxon rank-sum test [48] results are listed in Table 5, which can assess the statistical performance differences between the RLTLBO algorithm and the comparative algorithms. A p-value less than 0.05 indicates a substantial difference between the two compared methods. It is obvious that the overwhelming majority p-values in Table 5 are less than 0.05, indicating that there are statistically and substantial differences between RLTLBO and the other methods. Combining the results in Table 4, it can be concluded that the RLTLBO algorithm outperforms the others. 0e competitive results of RLTLBO indicate that this algorithm has high capabilities of exploration and exploitation. In summary, the RLTLBO algorithm provides better results than other comparative algorithms.\n4.2. CEC2017 Benchmark Function Experiments. Standard benchmark function experiments prove the superior performance on simple optimization problems of the proposed RLTLBO algorithm. CEC2017 [49], one of the most challenging test suites, can help check the performance of complex optimization problems. Some hybrid and composition functions are selected to further test the performance of RLTLBO. 0ese types of functions are precisely what the standard test functions do not have. 0e functional details and the comparison results are presented in Tables 6 and 7. As mentioned above, each method runs 30 times with\nTable 4: Continued.\nFunction RLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA\nF9 Mean 0.00E+ 00 1.41E+ 01 1.70E+ 01 8.44E+ 01 0.00E+ 00 5.06E+ 01 0.00E+ 00 0.00E+ 00 5.19E+ 01Std 0.00E+ 00 6.20E+ 00 9.11E+ 00 3.15E+ 01 0.00E+ 00 9.32E+ 01 0.00E+ 00 0.00E+ 00 1.88E+ 01 F10 Mean 8.88E \u2212 16 7.05E \u2212 15 1.14E+ 00 4.77E+ 00 8.88E \u2212 16 6.10E \u2212 15 8.88E \u2212 16 8.88E \u2212 16 2.62E+ 00Std 0.00E+ 00 1.60E \u2212 15 1.88E+ 00 2.64E+ 00 0.00E+ 00 2.42E \u2212 15 0.00E+ 00 0.00E+ 00 8.98E \u2212 01 F11 Mean 0.00E+ 00 3.29E \u2212 04 4.86E \u2212 03 6.05E \u2212 02 0.00E+ 00 1.18E \u2212 01 0.00E+ 00 0.00E+ 00 2.24E \u2212 02Std 0.00E+ 00 1.80E \u2212 03 9.13E \u2212 03 2.33E \u2212 02 0.00E+ 00 2.57E \u2212 01 0.00E+ 00 0.00E+ 00 1.45E \u2212 02 F12 Mean 8.32E \u2212 04 5.38E \u2212 07 3.51E \u2212 02 1.60E \u2212 05 8.37E \u2212 01 1.23E+ 00 3.04E \u2212 06 1.02E \u2212 05 7.22E+ 00Std 1.52E \u2212 03 2.76E \u2212 06 4.56E \u2212 02 1.16E \u2212 05 1.08E \u2212 01 2.42E \u2212 01 4.59E \u2212 06 1.12E \u2212 05 3.01E+ 00 F13 Mean 2.00E+ 00 7.41E \u2212 02 3.83E \u2212 01 1.70E \u2212 03 2.76E+ 00 3.08E+ 00 4.57E \u2212 05 8.69E \u2212 05 2.19E+ 01Std 1.17E+ 00 8.70E \u2212 02 2.15E \u2212 01 3.95E \u2212 03 5.11E \u2212 02 1.83E \u2212 01 1.18E \u2212 04 9.70E \u2212 05 1.44E+ 01 F14 Mean 1.06E+ 00 9.98E \u2212 01 9.98E \u2212 01 1.46E+ 00 1.35E+ 00 2.78E+ 00 4.06E+ 00 1.36E+ 00 1.16E+ 00Std 3.62E \u2212 01 0.00E+ 00 3.81E \u2212 12 7.69E \u2212 01 6.1E \u2212 01 2.07E+ 00 4.46E+ 00 9.52E \u2212 01 4.57E \u2212 01 F15 Mean 3.55E \u2212 04 3.82E \u2212 04 3.04E \u2212 03 1.40E \u2212 03 8.91E \u2212 04 6.77E \u2212 03 5.00E \u2212 04 4.01E \u2212 04 3.55E \u2212 03Std 1.02E \u2212 04 1.54E \u2212 04 6.91E \u2212 03 3.62E \u2212 03 3.99E \u2212 04 5.47E \u2212 03 1.10E \u2212 04 2.36E \u2212 04 6.71E \u2212 03 F16 Mean \u2212 1.03E+ 00 \u2212 1.03E+ 00 \u2212 1.03E+ 00 \u2212 1.03E+ 00 \u2212 1.03E+ 00 \u2212 9.99E \u2212 01 \u2212 1.03E+ 00 \u2212 1.03E+ 00 \u2212 1.03E+ 00Std 6.58E \u2212 16 6.95E \u2212 16 3.39E \u2212 08 1.65E \u2212 13 3.99E \u2212 04 3.29E \u2212 02 3.01E \u2212 04 3.76E \u2212 09 1.83E \u2212 14 F17 Mean 3.98E \u2212 01 3.98E \u2212 01 3.98E \u2212 01 3.98E \u2212 01 4.09E \u2212 01 3.99E \u2212 01 3.98E \u2212 01 3.98E \u2212 01 3.98E \u2212 01Std 0.00E+ 00 0.00E+ 00 6.52E \u2212 09 5.57E \u2212 14 1.06E \u2212 02 1.08E \u2212 03 1.09E \u2212 04 4.60E \u2212 06 7.21E \u2212 15 F18 Mean 3.00E+ 00 3.00E+ 00 3.00E+ 00 3.00E+ 00 3.00E+ 00 4.94E+ 00 3.03E+ 00 3.00E+ 00 3.00E+ 00Std 4.95E \u2212 16 1.24E \u2212 15 1.03E \u2212 07 5.76E \u2212 13 8.33E \u2212 04 6.82E+ 00 5.73E \u2212 02 3.88E \u2212 07 2.87E \u2212 13 F19 Mean \u2212 3.86E+ 00 \u2212 3.86E+ 00 \u2212 3.86E+ 00 \u2212 3.86E+ 00 \u2212 3.82E+ 00 \u2212 3.86E+ 00 \u2212 3.85E+ 00 \u2212 3.86E+ 00 \u2212 3.86E+ 00Std 2.71E \u2212 15 3.16E \u2212 15 1.08E \u2212 06 6.39E \u2212 13 2.33E \u2212 02 6.99E \u2212 04 6.96E \u2212 03 2.07E \u2212 03 1.09E \u2212 12 F20 Mean \u2212 3.31E+ 00 \u2212 3.30E+ 00 \u2212 3.23E+ 00 \u2212 3.23E+ 00 \u2212 2.80E+ 00 \u2212 3.25E+ 00 \u2212 3.16E+ 00 \u2212 3.08E+ 00 \u2212 3.23E+ 00Std 2.95E \u2212 02 4.12E \u2212 02 6.47E \u2212 02 5.14E \u2212 02 2.71E \u2212 01 9.05E \u2212 02 8.91E \u2212 02 1.22E \u2212 01 6.22E \u2212 02 F21 Mean \u2212 1.02E+ 01 \u2212 1.02E+ 01 \u2212 9.98E+ 00 \u2212 7.62E+ 00 \u2212 3.27E+ 00 \u2212 9.43E+ 00 \u2212 1.01E+ 01 \u2212 5.18E+ 00 \u2212 8.07E+ 00Std 6.04E \u2212 09 1.41E \u2212 03 9.30E \u2212 01 2.82E+ 00 1.54E+ 00 9.62E \u2212 01 2.09E \u2212 02 7.51E \u2212 01 3.28E+ 00 F22 Mean \u2212 1.04E+ 01 \u2212 1.01E+ 01 \u2212 1.04E+ 01 \u2212 7.06E+ 00 \u2212 3.87E+ 00 \u2212 9.36E+ 00 \u2212 1.04E+ 01 \u2212 5.08E+ 00 \u2212 9.32E+ 00Std 1.23E \u2212 07 1.25E+ 00 4.45E \u2212 04 3.48E+ 00 1.17E+ 00 1.69E+ 00 5.50E \u2212 02 6.94E \u2212 03 2.51E+ 00 F23 Mean \u2212 1.05E+ 01 \u2212 1.01E+ 01 \u2212 1.05E+ 01 \u2212 7.31E+ 00 \u2212 4.19E+ 00 \u2212 9.63E+ 00 \u2212 1.05E+ 01 \u2212 5.24E+ 00 \u2212 7.89E+ 00Std 1.57E \u2212 07 1.57E+ 00 3.42E \u2212 04 3.55E+ 00 1.11E+ 00 1.52E+ 00 2.23E \u2212 02 9.58E \u2212 01 3.59E+ 00\n0 10-300\n10-200\n10-150\n10-100\n10-50\n100\n10-200\nFi tn\nes s v\nal ue\ns\nFi tn\nes s v\nal ue\ns\n10-200\n10-2\n100\n102\n104\n106\n108\n10-150\n10-100\n10-50\n100\nFi tn\nes s v\nal ue\ns\nFi tn\nes s v\nal ue\ns\n10-6\n10-4\n10-2\n100\n102\n104\nFi tn\nes s v\nal ue\ns\n10-100\n100 F1\nRLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA\nF2 F3\nF4 F5 F6\n10-300\n10-200\nFi tn\nes s v\nal ue\ns\n10-100\n100\n100 200 300 Iteration\n400 500 0 100 200 300 Iteration\n400 500 0 100 200 300 Iteration\n400 500\n0 100 200 300 Iteration\n400 500 0 100 200 300 Iteration\n400 500 0 100 200 300 Iteration\n400 500\nRLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA\nRLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA\nRLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA\nRLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA\nRLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA\n10-4\n10-2\n100\n102\nFi tn\nes s v\nal ue\ns\n10-10\n-12000\n-10000\n-8000\n-6000\n-4000\n-2000\n0\n10-5\n100\nFi tn\nes s v\nal ue\ns\nFi tn\nes s v\nal ue\ns\nF7 F8 F9\n0 100 200 300 Iteration\n400 500 0 100 200 300 Iteration\n400 500 0 100 200 300 Iteration\n400 500\nRLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA RLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA RLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA\n10-15 10-15\n10-10 10-10\n10-5 10-5\n10-5\n100\n100\n100\n105\nFi tn\nes s v\nal ue\ns\nFi tn\nes s v\nal ue\ns\nFi tn\nes s v\nal ue\ns\nF10 F12F11\n0 100 200 300 Iteration\n400 500 0 100 200 300 Iteration\n400 500 0 100 200 300 Iteration\n400 500\nRLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA\nRLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA\nRLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA\nFigure 7: Continued.\nTable 5: p-Values from the Wilcoxon rank-sum test for the results in Table 4.\nFunction RLTLBO vs. TLBO mGWO MALO DSCA HOA AO HHO SSA F1 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 NaN 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 F2 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 04 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 F3 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 1.56E \u2212 02 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 F4 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 F5 6.10E \u2212 05 3.30E \u2212 01 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 8.54E \u2212 04 F6 6.10E \u2212 05 1.22E \u2212 04 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 F7 6.10E \u2212 05 6.10E \u2212 05 4.89E \u2212 01 6.10E \u2212 04 6.10E \u2212 05 4.89E \u2212 01 7.30E \u2212 02 6.10E \u2212 05 F8 0.010254 6.37E \u2212 02 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 1.21E \u2212 01 6.10E \u2212 05 5.61E \u2212 01 F9 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 NaN 1.25E \u2212 01 NaN NaN 6.10E \u2212 05 F10 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 NaN 6.10E \u2212 05 NaN NaN 6.10E \u2212 05 F11 NaN 1.95E \u2212 03 6.10E \u2212 05 NaN 3.12E \u2212 02 NaN NaN 6.10E \u2212 05 F12 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 F13 3.05E \u2212 04 6.10E \u2212 04 6.10E \u2212 05 3.89E \u2212 01 2.01E \u2212 03 6.10E \u2212 05 6.10E \u2212 05 3.05E \u2212 04 F14 NaN 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 F15 8.90E \u2212 01 2.01E \u2212 03 1.83E \u2212 04 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 8.36E \u2212 03 6.10E \u2212 05 F16 NaN 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 1.22E \u2212 04 6.10E \u2212 05 F17 NaN 6.10E \u2212 05 2.44E \u2212 04 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 9.76E \u2212 04 F18 NaN 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 F19 NaN 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 F20 8.52E \u2212 01 4.13E \u2212 02 1.35E \u2212 01 6.10E \u2212 05 2.01E \u2212 03 6.10E \u2212 05 6.10E \u2212 05 3.05E \u2212 04 F21 1.68E \u2212 01 6.10E \u2212 05 4.79E \u2212 02 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 1.03E \u2212 02 F22 6.25E \u2212 02 6.10E \u2212 05 2.56E \u2212 02 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 4.13E \u2212 02 F23 7.81E \u2212 03 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 2.56E \u2212 02\nTable 6: Descriptions of the benchmark functions from CEC2017.\nFunction Name Dim Range fmin Hybrid functions (N is basic number of functions) C13 Hybrid function 3 (N\ufffd 3) 10 [\u2212 100, 100] 1300 C14 Hybrid function 4 (N\ufffd 4) 10 [\u2212 100, 100] 1400 C15 Hybrid function 5 (N\ufffd 4) 10 [\u2212 100, 100] 1500 C19 Hybrid function 6 (N\ufffd 5) 10 [\u2212 100, 100] 1900 Composite functions (N is basic number of functions) C22 Composite function 2 (N\ufffd 3) 10 [\u2212 100, 100] 2200 C25 Composite function 5 (N\ufffd 5) 10 [\u2212 100, 100] 2500 C28 Composite function 8 (N\ufffd 6) 10 [\u2212 100, 100] 2800 C29 Composite function 9 (N\ufffd 6) 10 [\u2212 100, 100] 2900\nTable 7: Comparison results of algorithms on CEC2017.\nFunction RLTLBO TLBO mGWO MALO DSCA HOA AO HHO SSA\nC13 Mean 4.38E+ 03 6.04E+ 03 4.35E+ 03 1.78E+ 04 6.25E+ 05 1.53E+ 06 1.77E+ 04 1.70E+ 04 1.46E+ 04Std 2.76E+ 03 4.33E+ 03 2.99E+ 03 1.30E+ 04 4.55E+ 05 1.28E+ 06 1.39E+ 04 1.03E+ 04 1.29E+ 04 C14 Mean 1.46E+ 03 1.47E+ 03 1.47E+ 03 2.75E+ 03 4.78E+ 03 3.87E+ 03 2.36E+ 03 2.20E+ 03 3.35E+ 03Std 1.81E+ 01 2.40E+ 01 1.98E+ 01 2.02E+ 03 3.76E+ 03 1.99E+ 03 1.12E+ 03 1.05E+ 03 3.10E+ 03 C15 Mean 1.62E+ 03 1.73E+ 03 1.74E+ 03 8.28E+ 03 7.97E+ 03 2.49E+ 04 5.91E+ 03 7.35E+ 03 1.06E+ 04Std 5.96E+ 01 1.44E+ 02 2.36E+ 02 5.72E+ 03 3.62E+ 03 1.54E+ 04 2.16E+ 03 3.10E+ 03 7.51E+ 03 C19 Mean 2.00E+ 03 2.11E+ 03 2.65E+ 03 1.54E+ 04 3.37E+ 04 1.69E+ 04 2.10E+ 04 1.67E+ 04 8.46E+ 03Std 9.63E+ 00 3.19E+ 02 1.68E+ 03 1.23E+ 04 3.00E+ 04 1.34E+ 04 2.88E+ 04 1.37E+ 04 6.44E+ 03 C22 Mean 2.30E+ 03 2.30E+ 03 2.30E+ 00 2.30E+ 03 2.55E+ 03 2.47E+ 03 2.31E+ 03 2.41E+ 03 2.33E+ 03Std 1.99E+ 01 8.68E+ 00 9.25E \u2212 01 2.88E+ 01 8.10E+ 01 4.58E+ 02 5.85E+ 00 3.85E+ 02 1.69E+ 02 C25 Mean 2.92E+ 03 2.93E+ 03 2.92E+ 03 2.93E+ 03 3.12E+ 03 2.97E+ 03 2.94E+ 03 2.93E+ 03 2.92E+ 03Std 2.32E+ 01 2.41E+ 01 2.33E+ 01 2.38E+ 01 6.48E+ 01 2.35E+ 01 2.50E+ 01 6.24E+ 01 2.45E+ 01 C28 Mean 3.23E+ 03 3.30E+ 03 3.33E+ 03 3.31E+ 03 3.40E+ 03 3.50E+ 03 3.44E+ 03 3.45E+ 03 3.29E+ 03Std 1.15E+ 02 1.60E+ 02 1.12E+ 02 1.47E+ 02 9.48E+ 01 1.06E+ 02 1.09E+ 02 1.45E+ 02 1.68E+ 02 C29 Mean 3.18E+ 03 3.19E+ 03 3.17E+ 03 3.27E+ 03 3.38E+ 03 3.38E+ 03 3.26E+ 03 3.37E+ 03 3.27E+ 03Std 1.84E+ 01 2.16E+ 01 2.13E+ 01 6.15E+ 01 5.77E+ 01 6.58E+ 01 5.87E+ 01 1.20E+ 02 7.20E+ 01\n30 search agents and 500 iterations. From Table 7, the proposed RLTLBO achieves both the best average and standard deviation values on five of the eight all functions. For the remaining three functions, RLTLBO obtains one of the best average and standard deviation values.0e RLTLBO completely exceeds the TLBO, MALO, HOA, AO, HHO, and SSA methods completely. 0e statistical results are also listed in Table 8. 0ere are only seven p-values greater than 0.05 in all test functions, which means considerable differences between the RLTLBO and the compared methods. 0ese results suggest that RLTLBO can achieve great results on complex problems as well."
        },
        {
            "heading": "5. Experiments on Industrial Engineering Design Problems",
            "text": "In this section, eight well-known constrained industrial engineering design problems, including the welded beam design problem, pressure vessel design problem, tension and compression spring design problem, speed reducer design problem, three-bar truss design problem, car crashworthiness design problem, tubular column design problem, and frequency-modulated sound wave design problem, are solved to further verify the performance of the proposed RLTLBO algorithm.0e results of RLTLBO are compared to various optimization methods proposed in previous studies.\n5.1. Welded Beam Design Problem. 0e purpose of this problem is to minimize the cost of the welded beam (Figure 8). Four variables need to be optimized: the thickness of weld (h), the thickness of the bar (b), length of the bar (l), and height of the bar (t). 0e mathematical formulation is listed as follows:\nConsider z\u2192 \ufffd [z1, z2, z3, z4] \ufffd [h, l, t, b]. Minimize f( z\u2192) \ufffd 1.10471z21z2 + 0.04811z3z4 (14.0 + z2), subject to\ng1( z \u2192 ) \ufffd \u03c4( z\u2192) \u2212 \u03c4max \u2264 0, g2( z \u2192 ) \ufffd \u03c3( z\u2192) \u2212 \u03c3max \u2264 0, g3( z \u2192 ) \ufffd \u03b4( z\u2192) \u2212 \u03b4max \u2264 0, g4( z \u2192 ) \ufffd z1 \u2212 z4 \u2264 0, g5( z \u2192 ) \ufffd P \u2212 Pc( z \u2192 )\u2264 0, g6( z \u2192 ) \ufffd 0.125 \u2212 z1 \u2264 0, g7( z \u2192 ) \ufffd 1.10471z21 + 0.04811z3z4 14.0 + z2(  \u2212 5.0\u2264 0. \u23a7\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23a8 \u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23a9\n(6)\nVariable range\n0.1\u2264 z1 \u2264 2,\n0.1\u2264 z2 \u2264 10,\n0.1\u2264 z3 \u2264 10,\n0.1\u2264 z4 \u2264 2,\n\u23a7\u23aa \u23aa \u23aa\u23a8\n\u23aa \u23aa \u23aa\u23a9\n(7)\nwhere\n\u03c4( z\u2192) \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \u03c4\u20322 + 2\u03c4\u2032\u03c4\u2033 z2\n2R + \u03c4\u20332\n\n,\n\u03c4\u2032 \ufffd P\n\ufffd 2 \u221a z1z2\n, \u03c4\u2033 \ufffd MR\nJ , M \ufffd P L + z2 2  ,\nR \ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd z 2 2 4 + z1 + z3 2   2  ,\nJ \ufffd 2 \ufffd 2 \u221a z1z2\nz 2 2 12 + z1 + z3 2   2   ,\n\u03c3( z\u2192) \ufffd 6PL z4z 2 3 , \u03b4( z\u2192) \ufffd\n4PL3\nEz 3 3z4\n,\nPc( z \u2192\n) \ufffd 4.013E\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd z 2 3z 6 4/36  L 2 1 \u2212 z3 2L \ufffd\ufffd E 4G   ,\nP \ufffd 6000lb, L \ufffd 14in, \u03b4max \ufffd 0.25in,\nE \ufffd 30 \u00d7 106psi, G \ufffd 12 \u00d7 106psi,\n\u03c4max \ufffd 13600psi, \u03c3max \ufffd 30000psi.\n\u23a7\u23aa \u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23a8\n\u23aa \u23aa\u23aa \u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23a9\n(8)\n0e RLTLBO is compared to SMA [50], WOA, MPA [51], MVO [52], GA, and HS [53] methods. 0e comparison results presented in Table 9 show the superior of the RLTLBO algorithm with a smaller cost than other algorithms.\n5.2. Pressure Vessel Design Problem. 0e objective of this problem is to minimize the fabrication cost of the cylindrical pressure vessel to meet the pressure requirements. As shown in Figure 9, four structural parameters in this problem need to be minimized, including the thickness of the shell (Ts), the thickness of the head (0), inner radius (R), and the length of the cylindrical section without the head (L). 0e formulation of four optimization constraints can be described as follows:\nConsider x\u2192 \ufffd [x1 x2 x3 x4] \ufffd [Ts Th R L]. Minimize f( x\u2192) \ufffd 0.6224x1x3x4 + 1.7781x2x23 + 3.1661x21x4 + 19.84x21x3, subject to\ng1( x \u2192 ) \ufffd \u2212 x1 + 0.0193x3 \u2264 0,\ng2( x \u2192 ) \ufffd \u2212 x3 + 0.00954x3 \u2264 0,\ng3( x \u2192 ) \ufffd \u2212 \u03c0x23x4 \u2212 4 3 \u03c0x33 + 1296000\u2264 0,\ng4( x \u2192 ) \ufffd x4 \u2212 240\u2264 0.\n\u23a7\u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23a8\n\u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23a9\n(9)\nTable 8: p values from the Wilcoxon rank-sum test for the results in Table 7.\nFunction RLTLBO vs. TLBO mGWO MALO DSCA HOA AO HHO SSA C13 2.90E \u2212 02 3.59E \u2212 01 1.81E \u2212 02 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 3.36E \u2212 03 1.22E \u2212 04 C14 1.35E \u2212 01 4.37E \u2212 02 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 1.83E \u2212 04 6.10E \u2212 05 C15 3.36E \u2212 03 8.36E \u2212 03 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 C19 1.24E \u2212 02 3.30E \u2212 02 8.54E \u2212 04 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 C22 4.27E \u2212 03 4.13E \u2212 02 4.04E \u2212 02 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 8.47E \u2212 02 C25 5.61E \u2212 01 8.47E \u2212 01 8.47E \u2212 01 6.10E \u2212 05 2.01E \u2212 03 1.21E \u2212 02 1.69E \u2212 02 3.62E \u2212 01 C28 2.48E \u2212 02 1.51E \u2212 02 4.79E \u2212 02 1.81E \u2212 02 1.53E \u2212 03 6.10E \u2212 04 5.37E \u2212 03 4.21E \u2212 02 C29 4.54E \u2212 03 6.10E \u2212 04 6.10E \u2212 05 6.10E \u2212 05 6.10E \u2212 05 8.54E \u2212 04 6.10E \u2212 05 1.51E \u2212 02\nTable 9: Comparison results for the welded beam design problem.\nAlgorithm Optimum variables\nOptimum cost h l t b\nRLTLBO 0.205730 3.253000 9.036600 0.205730 1.695200 SMA [50] 0.205400 3.258900 9.038400 0.205800 1.696040 WOA [14] 0.205396 3.484293 9.037426 0.206276 1.730499 MPA [51] 0.205728 3.470509 9.036624 0.205730 1.724853 MVO [52] 0.205463 3.473193 9.044502 0.205695 1.726450 GA [6] 0.248900 6.173000 8.178900 0.253300 2.430000 HS [53] 0.244200 6.223100 8.291500 0.240000 2.380700\nVariable range\n0\u2264 x1 \u2264 99,\n0\u2264 x2 \u2264 99,\n10\u2264x3 \u2264 200,\n10\u2264x4 \u2264 200.\n\u23a7\u23aa \u23aa \u23aa\u23a8\n\u23aa \u23aa \u23aa\u23a9\n(10)\nFrom the results in Table 10, it is obvious that RLTLBO can obtain superior optimal values compared to AO, SMA, WOA, GWO, MVO, GA, and ES [54].\n5.3. Tension/Compression Spring Design Problem. 0is problem aims to minimize the weight of the tension/compression spring (Figure 10). 0ree variables need to be optimized, including the wire diameter (d), the number of active coils (N), and mean coil diameter (D). 0is problem can be described as follows:\nConsider x\u2192 \ufffd [x1 x2 x3] \ufffd [d D N]. Minimize f( x\u2192) \ufffd (x3 + 2)x2x21, subject to\ng1( x \u2192 ) \ufffd 1 \u2212 x 3 2x3\n71785x41 \u2264 0,\ng2( x \u2192 ) \ufffd 4x22 \u2212 x1x2\n12566 x2x 3 1 \u2212 x 4 1 \n+ 1\n5108x21 \u2264 0,\ng3( x \u2192 ) \ufffd 1 \u2212 140.45x1\nx 2 2x3 \u2264 0,\ng4( x \u2192 ) \ufffd x1 + x2\n1.5 \u2212 1\u2264 0.\n\u23a7\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23aa \u23aa \u23a8\n\u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23a9\n(11)\nVariable range\n0.05\u2264x1 \u2264 2.00,\n0.25\u2264x2 \u2264 1.30,\n2.00\u2264x3 \u2264 15.00.\n\u23a7\u23aa \u23a8 \u23aa\u23aa\u23a9 (12)\n0e RLTLBO is compared to AO, SSA, WOA, GWO, PSO, GA, and HS algorithms. Results are listed in Table 11 and show that the RLTLBO can obtain the best weight compared to all other algorithms.\n5.4. SpeedReducerDesignProblem. In this case, the purpose is to minimize the weight of the speed reducer (Figure 11). Seven variables are considered, including face width (x1), a module of teeth (x2), a discrete design variable on behalf of the teeth in the pinion (x3), length of the first shaft between bearings (x4), length of the second shaft between bearings (x5), diameters of the first shaft (x6), and diameters of the second shaft (x7). 0e mathematical formulation is listed as follows:\nMinimize\nf( x \u2192 ) \ufffd0.7854x1x 2 2 + 3.3333x 2 3 + 14.9334x3 \u2212 43.0934\n\u2212 1.508x1 x 2 6 + x 2 7  + 7.4777 x 3 6 + x 3 7 ,\n(13)\nsubject to\ng1( x \u2192 ) \ufffd 27\nx1x 2 2x3\n\u2212 1\u2264 0,\ng2( x \u2192 ) \ufffd 397.5\nx1x 2 2x 2 3\n\u2212 1\u2264 0,\ng3( x \u2192 ) \ufffd 1.93x34 x2x3x 4 6 \u2212 1\u2264 0,\ng4( x \u2192 ) \ufffd 1.93x35 x2x3x 4 7 \u2212 1\u2264 0,\ng5( x \u2192 ) \ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 745x4/x2x3(  2 + 16.9 \u00d7 106 \n110.0x36 \u2212 1\u2264 0,\ng6( x \u2192 ) \ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd 745x4/x2x3(  2 + 157.5 \u00d7 106 \n85.0x36 \u2212 1\u2264 0,\ng7( x \u2192 ) \ufffd x2x3\n40 \u2212 1\u2264 0,\ng8( x \u2192 ) \ufffd 5x2 x1 \u2212 1\u2264 0,\ng9( x \u2192 ) \ufffd x1 12x2 \u2212 1\u2264 0,\ng10( x \u2192 ) \ufffd 1.5x6 + 1.9\nx4 \u2212 1\u2264 0,\ng11( x \u2192 ) \ufffd 1.1x7 + 1.9\nx5 \u2212 1\u2264 0.\n\u23a7\u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23aa \u23aa \u23a8\n\u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23a9\n(14)\nVariable range\n2.6\u2264x1 \u2264 3.6,\n0.7\u2264x2 \u2264 0.8,\n17\u2264 x3 \u2264 28,\n7.3\u2264x4 \u2264 8.3,\n7.8\u2264x5 \u2264 8.3,\n2.9\u2264x6 \u2264 3.9,\n5.0\u2264x7 \u2264 5.5.\n\u23a7\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23a8\n\u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23a9\n(15)\nTable 10: Comparison results for the pressure vessel design problem.\nAlgorithm Optimum variables\nOptimum cost Ts 0 R L\nRLTLBO 0.7698901 0.4201098 42.536830 171.348900 5926.77920 AO [15] 1.0540000 0.1828060 59.621900 38.8050000 5949.22580 SMA [50] 0.7931000 0.3932000 40.671100 196.217800 5994.18570 WOA [14] 0.8125000 0.4375000 42.098270 176.638998 6059.74100 GWO [13] 0.8125000 0.4345000 42.089200 176.758700 6051.56390 MVO [52] 0.8125000 0.4375000 42.090738 176.738690 6060.80660 GA [6] 0.8125000 0.4375000 42.097398 176.654050 6059.94634 ES [54] 0.8125000 0.4375000 42.098087 176.640518 6059.74560\nTable 11: Comparison results for the tension/compression spring design problem.\nAlgorithm Optimum variables\nOptimum weight d D N\nRLTLBO 0.0551180 0.505900 5.1167000 0.01093800 AO [15] 0.0502439 0.352620 10.542500 0.01116500 SSA [12] 0.0512070 0.345215 12.004032 0.01267630 WOA [14] 0.0512070 0.345215 12.004032 0.01267630 GWO [13] 0.0516900 0.356737 11.288850 0.01266600 PSO [11] 0.0517280 0.357644 11.244543 0.01267470 GA [6] 0.0514800 0.351661 11.632201 0.01270478 HS [53] 0.0511540 0.349871 12.076432 0.01267060\nCompared to AO, PSO, AOA, GA, SCA [55], HS, and FA [56], RLTLBO achieves better results in the speed reducer problem, as shown in Table 12.\n5.5. <ree-Bar Truss Design Problem. 0e three-bar truss design problem aims to minimize the weight of a truss with three bars by controlling the length of three bars (A1, A2, and A3) (Figure 12). 0ree main constraints need to be satisfied, including deflection, stress, and buckling. 0e mathematical form of this problem is given:\nConsider x\u2192 \ufffd [x1 x2] \ufffd [A1 A2]. Minimize f( x\u2192) \ufffd (2 \ufffd 2 \u221a x1 + x2)\u2217 l subject to\ng1( x \u2192 ) \ufffd\n\ufffd 2 \u221a x1 + x2\ufffd\n2 \u221a\nx 2 1 + 2x1x2\nP \u2212 \u03c3 \u2264 0,\ng2( x \u2192 ) \ufffd x2\ufffd\n2 \u221a\nx 2 1 + 2x1x2\nP \u2212 \u03c3 \u2264 0,\ng3( x \u2192 ) \ufffd 1\n\ufffd 2 \u221a x2 + x1 P \u2212 \u03c3 \u2264 0.\n\u23a7\u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23a8\n\u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa\u23aa\u23a9\n(16)\nConsider 0\u2264x1, x2 \u2264 1, where l \ufffd 100cm, P \ufffd 2KN/ cm2, \u03c3 \ufffd 2KN/cm2.\n0e result of RLTLBO is listed in Table 13, compared to AO, SSA, AOA, MVO, and GOA [57]. It can be observed that RLTLBO outperforms other algorithms in the literature.\n5.6. Car Crashworthiness Design Problem. 0e car crashworthiness design problem aims to minimize the weight by optimizing eleven influence variables [58], including the thickness of B-Pillar inner (x1), B-pillar reinforcement (x2), floor side inner (x3), cross members (x4), door beam (x5), door beltline reinforcement (x6) and roof rail (x7), materials of B-Pillar inner (x8) and floor side inner (x9), barrier height (x10), and barrier hitting position (x11).0is problem can be formulated as follows.\nMinimize\nf( x \u2192 ) \ufffd weight, (17)\nsubject to\ng1( x \u2192 ) \ufffd Fa(load in abdomen)\u2264 1 kN, g2( x \u2192 ) \ufffd V \u00d7 Cu(dummy upper chest)\u2264 0.32m/s, g3( x \u2192 ) \ufffd V \u00d7 Cm(dummymiddle chest)\u2264 0.32m/s, g4( x \u2192 ) \ufffd V \u00d7 Cl(dummy lowere chest)\u2264 0.32m/s, g5( x \u2192 ) \ufffd \u0394ur(upper rib deflection)\u2264 32mm, g6( x \u2192 ) \ufffd \u0394mr(middle rib deflection)\u2264 32mm, g7( x \u2192 ) \ufffd \u0394lr(lower rib deflection)\u2264 32mm, g8( x \u2192 ) \ufffd F(public force)p \u2264 4kN,\ng9( x \u2192 ) \ufffd VMBP(velocity of V \u2212 pillar at middle point)\u2264 9.9mm/ms, g10( x \u2192 ) \ufffd VFD(velocity of front doorat V \u2212 pillar)\u2264 15.7mm/ms.\n\u23a7\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23a8\n\u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23aa \u23aa\u23a9\n(18)\nVariable range\n0.5\u2264 x1 \u2212 x7 \u2264 1.5,\nx8, x9 \u2208 (0.192, 0.345),\n\u2212 30\u2264x10, x11 \u2264 30.\n\u23a7\u23aa \u23a8\n\u23aa \u23a9\n(19)\n0e RLTLBO and DE, GA, FA, CS [59], GOA, and EOBL-GOA [58] are applied to solve the car crashworthiness problem. As shown in Table 14, compared to other methods, the proposed RLTLBO achieves the best result than others.\n5.7. Tubular Column Design Problem. 0e main intention is to find a minimum cost for a uniform column, making the tubular section be able to carry a compressive load P\ufffd 2,500 kgf. 0e column is made of a material with a yield stress (\u03c3y) of 500 kgf/cm2, a modulus of elasticity (E) of 0.85\u00d7106 kgf/ cm2, and a density (\u03c1) equal to 0.0025 kgf/cm3. 0e length (L) of the column is 250 cm. 0e cost of the column consists of material and construction costs. 0is problem is shown in Figure 13, and the optimization model of the problem is listed as follows.\nMinimize f(d, t) \ufffd 9.8dt + 2 d subject to\nTable 12: Comparison results for the speed reducer design problem.\nAlgorithm Optimum variables\nOptimum weight x1 x2 x3 x4 x5 x6 x7\nRLTLBO 3.497600 0.7000 17.0000 7.30000 7.800000 3.350060 5.285530 2995.43740 AO [15] 3.502100 0.7000 17.0000 7.30990 7.747600 3.364100 5.299400 3007.73280 PSO [11] 3.500100 0.7000 17.0002 7.51770 7.783200 3.350800 5.286700 3145.92200 AOA [9] 3.503840 0.7000 17.0000 7.30000 7.729330 3.356490 5.286700 2997.91570 GA [6] 3.510253 0.7000 17.0000 8.35000 7.800000 3.362201 5.287723 3067.56100 SCA [55] 3.508755 0.7000 17.0000 7.30000 7.800000 3.461020 5.289213 3030.56300 HS [53] 3.520124 0.7000 17.0000 8.37000 7.800000 3.366970 5.288719 3029.00200 FA [56] 3.507495 0.7001 17.0000 7.719674 8.080854 3.351512 5.287051 3010.13749\nTable 13: Comparison results for the threE \u2212 bar truss design problem.\nAlgorithm Optimum variables\nOptimum weight x1 x2\nRLTLBO 0.788420000000000 0.408110000000000 263.852300000000 AO [15] 0.792600000000000 0.396600000000000 263.868400000000 SSA [12] 0.788665410000000 0.408275784000000 263.895840000000 AOA [9] 0.793690000000000 0.394260000000000 263.915400000000 MVO [52] 0.788602760000000 0.408453070000000 263.895849900000 GOA [57] 0.788897555578973 0.407619570115153 263.895881496069\ng1 \ufffd P\n\u03c0dt\u03c3y \u2212 1\u2264 0,\ng2 \ufffd 8PL2\n\u03c03Edt d2 + t2  \u2212 1\u2264 0,\ng3 \ufffd 2.0 d \u2212 1\u2264 0,\ng4 \ufffd d\n14 \u2212 1\u2264 0,\ng5 \ufffd 0.2 t \u2212 1\u2264 0,\ng6 \ufffd t\n0.8 \u2212 1\u2264 0.\n\u23a7\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23a8\n\u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa\u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa\u23a9\n(20)\nFrom the comparison results in Table 15, we can see that RLTLBO can obtain superior optimal cost compared to mGWO, DSCA, HOA, AO, HHO, and CS."
        },
        {
            "heading": "5.8. Frequency-Modulated Sound Waves Design Problem.",
            "text": "0is problem aims to optimize the frequency-modulated (FM) synthesizer parameter in six dimensions [60]. 0e following equation is given for optimizationX \ufffd a1,\u03c91, a2\u03c92, a3,\u03c93  as a sound wave, where ai (i\ufffd 1, 2, 3) is the amplitude and \u03c9i (i\ufffd 1, 2, 3) is the angular frequency. 0is problem has the lowest value f(X \u2192 sol) \ufffd 0. 0e objective function is calculated based on the square errors between the target wave and the estimated wave. 0is problem is modeled as follows.\nMinimize\nf(X \u2192 ) \ufffd  100\nt\ufffd0 y(t) \u2212 y0(t)( \n2 , (21)\nwhere\ny(t) \ufffd a1 \u00b7 sin \u03c91 \u00b7 t \u00b7 \u03b8 + a2 \u00b7 sin \u03c92 \u00b7 t \u00b7 \u03b8 + a3 \u00b7 sin \u03c93 \u00b7 t \u00b7 \u03b8( ( ( ,\ny0(t) \ufffd (1.0) \u00b7 sin((5.0) \u00b7 t \u00b7 \u03b8 \u2212 (1.5) \u00b7 sin((4.8) \u00b7 t \u00b7 \u03b8 +(2.0) \u00b7 sin((4.9) \u00b7 t \u00b7 \u03b8))),\n\u03b8 \ufffd 2\u03c0 100 .\n\u23a7\u23aa \u23aa \u23aa \u23aa \u23a8\n\u23aa\u23aa \u23aa \u23aa \u23aa\u23a9\n(22)\n0e RLTLBO is compared with GWO, MFO [61], PSO, TSA [62], and FFA [63] algorithms, and the comparison results are listed in Table 16. It is obvious that the proposed method found a much better solution than the comparative algorithms.\nIn general, the excellent performance in solving industrial engineering design problems suggests that RLTLBO can be widely used in real-world optimization problems."
        },
        {
            "heading": "6. Conclusion",
            "text": "0is study presents an improved teaching-learning-based optimization algorithm (RLTLBO) by incorporating reinforcement learning (RL) and random opposition-based learning (ROBL) strategies. Because of the defect of the insufficient learning processes, a new learning model is proposed in the learner phase. 0e two different modes uniting the inherent learning mode are switched through the Q-learning mechanism in RL. 0is mechanism helps the individuals learn thoroughly, resulting in accelerating the convergence speed of the RLTLBO. To improve the ability of local optima avoidance, the ROBL strategy is appended after the teacher and learner phases. 0e proposed RLTLBO algorithm is tested using 23 standard and eight CEC2017 benchmark functions to analyze its search performance. Experimental results illustrate competitive\nresults compared to other state-of-the-art meta-heuristic algorithms. To further verify the superiority of RLTLBO, eight industrial engineering design problems are solved. 0e results are also very competitive with other comparative algorithms.\n0e code for RLTLBO is provided at https://github.com/ WangShuang92/RLTLBO and can be used formore practical problems. However, this algorithm still suffers with premature convergence on several benchmark functions, which can be studied in the future. Moreover, RLTLBO can only solve single objective problems. For future research, binary and multiobjective versions of RLTLBO can be considered. More applications of this algorithm in different fields are valuable works, including text clustering, scheduling problems, appliances management, parameter estimation, feature selection, test classification, image segmentation problems, network applications, sentiment analysis, etc."
        },
        {
            "heading": "Data Availability",
            "text": "0e data used to support the findings of this study are available from the corresponding author upon request."
        },
        {
            "heading": "Conflicts of Interest",
            "text": "On behalf of all authors, the corresponding author states that there are no conflicts of interest.\nTable 15: Comparison results for the tubular column design problem.\nAlgorithm Optimum variables\nOptimum cost d t\nRLTLBO 5.45120 0.29196 26.53130 mGWO 5.45080 0.29201 26.53270 DSCA 5.50250 0.29214 26.79030 HOA 5.26260 0.35487 28.86470 AO 5.46300 0.29656 26.83540 HHO 5.44380 0.29313 26.55820 CS [59] 5.45139 0.29196 26.53217\nTable 16: Comparison results for the frequency-modulated sound waves design problem.\nAlgorithm Optimum variables\nOptimum cost a1 \u03c91 a2 \u03c92 a3 \u03c93\nRLTLBO \u2212 0.97498 \u2212 5.0327 \u2212 1.5640 \u2212 4.7840 \u2212 2.0060 4.9055 0.21738 GWO [13] \u2212 0.66540 \u2212 0.1684 1.5173 \u2212 0.1287 \u2212 4.1335 \u2212 4.8997 8.47250 MFO [61] 0.61410 0.0432 \u2212 4.3251 4.7923 0.8339 0.1278 11.89690 PSO [11] \u2212 0.58860 5.0145 \u2212 3.2779 \u2212 4.9324 \u2212 0.8562 \u2212 0.1476 13.18070 TSA [62] 0.34150 4.7881 1.4309 0.1158 0.0975 0.5480 25.10520 FFA [63] \u2212 0.56270 0.0525 \u2212 3.4797 4.8930 1.1491 \u2212 4.8345 17.42910"
        },
        {
            "heading": "Acknowledgments",
            "text": "0is research was funded by National fund cultivation project of Sanming University (PYS2107 and PYT2105), the Sanming University Introduces High-level Talents to Start Scientific Research Funding Support Project (21YG01S, 20YG01, and 20YG14), Fujian Natural Science Foundation Project (2021J011128), Bidding project for higher education research of Sanming University (SHE2101), the Guiding Science and Technology Projects in Sanming City (2020-S-39, 2020-G-61, and 2021-S-8), the Educational Research Projects of Young and Middleaged Teachers in Fujian Province (JAT200638 and JAT200618), and the Scientific Research and Development Fund of Sanming University (B202029 and B202009), Open Research Fund of Key Laboratory of Agricultural Internet of 0ings in Fujian Province (ZD2101), Ministry of Education Cooperative Education Project (202002064014), School level education and teaching reform project of Sanming University (J2010306 and J2010305), Higher education research project of Sanming University (SHE2102 and SHE2013), and 2021 project of the 14th Five-year Plan of Education science in Fujian Province (FJJKBK21-138)."
        }
    ],
    "title": "An Improved Teaching-Learning-Based Optimization Algorithm with Reinforcement Learning Strategy for Solving Optimization Problems",
    "year": 2022
}