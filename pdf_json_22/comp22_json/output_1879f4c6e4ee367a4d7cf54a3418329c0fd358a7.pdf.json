{
    "abstractText": "The effectiveness of binary analysis tools and techniques is often measured with respect to how well they map to a ground truth. We have found that not all ground truths are created equal. This paper challenges the binary analysis community to take a long look at the concept of ground truth, to ensure that we are in agreement with definition(s) of ground truth, so that we can be confident in the evaluation of tools and techniques. This becomes even more important as we move to trained machine learning models, which are only as useful as the validity of the ground truth in the training.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jim Alves-Foss"
        },
        {
            "affiliations": [],
            "name": "Varsha Venugopal"
        }
    ],
    "id": "SP:3efccb02480988854f7b19bebf06e6b88cd942bd",
    "references": [
        {
            "authors": [
                "T. Bao",
                "D. Brumley"
            ],
            "title": "Byteweight: Recognizing functions in binary code",
            "year": 2014
        },
        {
            "authors": [
                "T. Bao",
                "J. Burket",
                "M. Woa",
                "R. Turner",
                "D. Brumley"
            ],
            "title": "Byteweight: Learning to recognize functions in binary code",
            "venue": "Proc. USENIX Security Symposium, 2014, pp. 845\u2013860.",
            "year": 2014
        },
        {
            "authors": [
                "DWARF Debugging Information Format Committee"
            ],
            "title": "DWARF debugging information format v 5",
            "venue": "2017.",
            "year": 2017
        },
        {
            "authors": [
                "C. Karamitas",
                "A. Kehagias"
            ],
            "title": "Efficient features for function matching between binary executables",
            "venue": "2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER), 2018, pp. 335\u2013345.",
            "year": 2018
        },
        {
            "authors": [
                "D. Kim",
                "E. Kim",
                "S.K. Cha",
                "S. Son",
                "Y. Kim"
            ],
            "title": "Revisiting binary code similarity analysis using interpretable feature engineering and lessons learned",
            "venue": "2021.",
            "year": 2021
        },
        {
            "authors": [
                "H. Koo",
                "S. Park",
                "T. Kim"
            ],
            "title": "A look back on a function identification problem",
            "venue": "Annual Computer Security Applications Conference, ser. ACSAC. New York, NY, USA: Association for Computing Machinery, 2021, p. 158\u2013168. [Online]. Available: https://doi.org/10.1145/3485832.3488018",
            "year": 2021
        },
        {
            "authors": [
                "K. Li",
                "M. Woo",
                "L. Jia"
            ],
            "title": "On the generation of disassembly ground truth and the evaluation of disassemblers",
            "venue": "Proc. of the 2020 ACM Workshop on Forming an Ecosystem Around Software Transformation, ser. FEAST\u201920. Association for Computing Machinery, 2020, p. 9\u201314. [Online]. Available: https://doi.org/10.1145/3411502.3418429",
            "year": 2020
        },
        {
            "authors": [
                "C. Pang",
                "R. Yu",
                "Y. Chen",
                "E. Koskinen",
                "G. Portokalidis",
                "B. Mao",
                "J. Xu"
            ],
            "title": "Sok: All you ever wanted to know about x86/x64 binary disassembly but were afraid to ask",
            "venue": "2021 IEEE Symposium on Security and Privacy (SP), pp. 833\u2013851, 2021. 7",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n21 0.\n15 07\n9v 1\n[ cs\n.C R\n] 2\n6 O\nct 2\n02 2\nI. INTRODUCTION\nBinary analysis research involves automatic analysis of executable binaries and a transformation of those binaries into some intermediate representation that allows for complex analysis. Part of this transformation involves the disassembly of the binary into low level constituent pieces: instructions and data, and also into more complex constructs: functions, classes, data structures. There have been many research projects and tools developed to assist with this process. The question is how good are they? To determine the effectiveness of the tools requires an understanding of the correct answers and then how well the tools map to those answers. These correct answers are the ground truth of the system.\nThere are many ways that researchers find the ground truth of the test suites they are using to evaluate their tools, and to generate results for publication. Unfortunately, this part of their work is often not seen as interesting and so the details of ground truth generation are not published in their papers, and scripts or directions for ground truth generation are not made available in the public repositories for the tools. Some readers may respond \u201cbut that is obvious\u201d or \u201cthat part is easy\u201d. Although we have heard these types of responses at meetings, the devil is in the details, and what may initially appear easy may not be the real ground truth. For example, the Byteweight project [1], [2] published results related to detecting function boundaries in binary executables. Their software returned start address and number of bytes in a function. Their script that was used to evaluate the correctness of the reported length actually reported any short lengths as correct. This was not\ndiscussed anywhere in the publication or documentation of the tools. We assume that this was a hack since the symbol tables of unstripped binaries generated by the Intel compiler icc include padding bytes as bytes of the preceding function, while the gcc compiler does not include these. Two different compilers generated two views of the ground truth. We would like to avoid these hacks in the future. In addition, there were instances of multiple symbols referencing the same function in some binaries. The analysis counted those functions twice. In a recent study, Koo et al. [9] generated a set of test suites to evaluate the function identification problem. A couple of the binaries did not have full symbol table information and therefore the \u201cground truth\u201d created for the study was initially incorrect. They examined this issue and adjusted their data, and explained it in their paper. This problem could have been easily missed in other studies.\nWe argue that there needs to be research into, and consensus on the evaluation/testing tools and the generation of test suites. Therefore when researchers evaluate the results of a new tool or technique, the community agrees with the measurements of the evaluation. In the general sense, we are talking about applying the science of instrumentation not only to our binary analysis tools, but to the tools that generate the ground truth values that we use to evaluate the binary analysis tools.\nThe purpose of this paper is to discuss the concepts of ground truth, to evaluate what has been published related to ground truth, and to start a dialog with the community to develop a set of standards for consistent ground truth determination. We would also like to see easily accessible and publicly available tools for ground truth generation and reporting.\nWe examined over 50 binary analysis papers, and found that many of them did not discuss how they calculated ground truth. Those that did, either used the generated symbol table, generated debug data, another tool such as IDA Pro, modified the compiler, or manually determined the ground truth. This paper summarizes the main categories of ground truth we found, the techniques to extract ground truth and possible confusion from this techniques.\nBefore we start, we want to mention that there have been other papers that touch on parts of this topic. One notable paper is by Pang et al. [12] that evaluates nine binary analysis tools/platforms. They instrument both clang and gcc compilers to determine the ground truth for disassembly, symbolization Workshop on Binary Analysis Research (BAR) 2022 24 April 2022, San Diego, CA, USA ISBN 1-891562-76-2 https://dx.doi.org/10.14722/bar.2022.23010 www.ndss-symposium.org\n(references to other code/data), function entries, and control flow graphs (indirect jumps and calls, tail calls and nonreturning functions). Li et al. [10] grab intermediate information from the compiler to generate their disassembly ground truth, in an attempt to validate ground truth. Another useful paper is by Kim et al. [8] that discusses a benchmark for binary code similarity analysis."
        },
        {
            "heading": "II. DEFINING GROUND TRUTH",
            "text": "The definition of ground truth, with respect to a binary executable, is context dependent. A lot depends on what the researchers are examining: correct decoding of instructions and data, mapping of binary to complex structures such as functions or data structures, or mapping of binary back to the source code. This context matters when evaluating the effectiveness of binary analysis tools. It also matters if we are examining normal code, obfuscated code or malware. For the purposes of this paper, we will primarily focus on normal code.\nCompilers perform optimizations, and may add or delete portions of the code, so that there is not an one-to-one mapping between source code and binary. Most compilers insert standard functions for code initialization and termination, and other may insert new optimized libraries (such as Intel compiler\u2019s embedded memory management routines [5]).\nTherefore, when researchers are analyzing a binary in the context of what the binary does, we argue that they must look at the binary as compiled. In the context of functions, researchers must first define what a function is, within the context of the binary, as compiled and linked. For example if a source code function is in-lined, it is no longer a function, and an analysis tool should not claim it found that function within the binary. A more difficult question we have to ask, is if the compiler optimizes out tail calls1, is a function that is only jumped to, instead of called, still a function?\nA. Instructions\nThe first category we examine is instructions versus data for disassembly of a binary. It is well known that it is hard to analyze a binary if the tool does not correctly identify instructions and data within the binary. Compilers, or hand written assembly may embed data within code sections of the binary, making it difficult to have precise determination of the mapping of bytes from the binary to instructions. Questions researchers should ask are:\n\u2022 Where do we obtain the ground truth about which bytes are instructions? Do we need to instrument the compiler, or is their sufficient details in the debug data?\n\u2022 What about instructions as data? There are some programs that run checksums over their own code, in this case code is data \u2013 most people will define that code as instructions. However, other programs may store portions of code that they copy to other parts of\n1A tail call exists when the final instruction of a function is a call to another function. An optimizing compiler will clean up the local function context, and then jump to the next function instead of using a call, saving the expense of a call and return.\nf i x syms ( ) : . . / b i n u t i l s 2 . 2 3 / b fd / l i n k e r . c :3208 080 b41c0 <f ix syms >:\n80 b41c0 : mov 0x4(%esp ) ,% eax 80 b41c4 : mov 0x8(%esp ) ,% edx\n080 b41c8 <f i x syms . > : 80 b41c8 : push %e s i 80 b41c9 : push %e d i\nListing 1. Multiple entry points from binary as_new (binutils v 2.23). Compiled with icc v 14.0.1, in 32-bit mode, -O2 option. Shown using AT&T syntax.\nmemory. This may be malicious, or may be part of a just-in-time compilation routine. Is that stored code really instructions, or just data?\nRecommendation: We recommend defining instructions as executable code as compiled into the binary. Instructions that are only meant to be copied, and are therefore used only as data, should be categorized based on location. If these are stored in a data section, then they are data. If these instructions are stored in a code section, they are code, even if they are never called or executed."
        },
        {
            "heading": "B. Functions",
            "text": "Let\u2019s take functions as the next example of a construct for which a researcher may want to find the ground truth. At a high level of abstraction, a function is a construct in a high level programming language. We can analyze source code and clearly find function names, types, parameters and boundaries. If a researcher is looking at binary differencing [3], traceability, or some other concept where there is a need to map the source code directly to its implementation in a binary, then the ground truth we are looking for must include that mapping.\nHowever, a compiler can apply many optimizations, and not directly map the source code to the executable code. For example, functions may be in-lined, where there is no actual function call within the binary, but rather the body of the function is directly compiled into the body of the calling function, effectively treating the function as a macro. There may be optimizations involving tail calls. In addition, compilers may optimize local variables so that they are stored in registers only, or do loop unrolling, or many other optimizations that prevent a direct mapping between source code and the binary. Therefore, we believe researchers must address the following questions:\n\u2022 Is there a need to map binary directly to source code? If so, what happens when a function is in-lined? What happens if the compiler creates multiple entry points to the function, or divides the function into two separate functions?\n\u2022 What is a function within the binary? Do we define a function with a strict adherence to the source code? What about a function with a tail call1? If the compiler optimizes away the call with a jump, are we jumping to a new function or to a disjoint portion of the same function? What about a compiler that allows a function to fall through to the next \u201cfunction\u201d?\n\u2022 Are uncalled functions still functions? Some compilers may optimize them away, while others do not.\n\u2022 Are compiler added functions, functions? There are several functions added by compilers, many are hand coded assembly.\n\u2022 Can functions have more than one entry point? Some compilers may insert multiple entry points for the same function. The Intel compiler does this in 32- bit mode (see discussion in Section III-A1, and see Listing 1). In addition, some compilers will optimize a function into multiple separate functions (See discussion of Listing 2 in Section III-A2.)\n\u2022 Besides function entry points, how do we define function boundaries? Some tools look for the start and end bytes of a function. Is the listed end byte the last byte of the last instruction? The first byte of the last instruction (for multibyte instructions)? The first byte after the last instruction? And how about padding between functions, does that belong to a specific function? What if the last instruction is unreachable?\nRecommendation: We recommend defining functions as logical units within the binary that have an entry point and one or more exit points and a collection of instructions in between. The exit may be a call to a non-returning function, a jump to the start of another function, or a return. This maps as closely as we can to the source code. We do not count in-line functions as functions, but rather treat them as if they were macros. We do count compiler inserted functions as functions, since they are in the binary. The hard part is determining the end of the function. Ideally we want to define a function as all of the bytes from the start of the function until the start of the next function, assuming functions are contiguous."
        },
        {
            "heading": "C. Function parameters and Local variables",
            "text": "It is possible that an optimizing compiler may remove or add parameters to a function, although we have only seen this in experimental compilers. As we mention in Section III-A2, some compilers can optimize the values of constant parameters and the ignore the passed in value. Compilers can also optimize away local variables, keeping the values only in a register. Therefore, we believe researchers must address the following questions:\n\u2022 How are you defining parameters? There is a need to map parameters back to source code, to registers or stack locations where they are stored, or maybe for data flow graphs. If a compiler optimizes away the use of a parameter, what is the ground truth in the mapping to source code, or to data flow graphs?\n\u2022 How are you defining local variables? There is also need to map local variables back to source code, to registers or stack locations where they are stored, or maybe for data flow graphs. If a compiler optimizes away the use of a local variable what is the ground truth in the mapping to source code, or to data flow graphs? Is there a need to understand the location of the local variables on the stack \u2013 since some compilers will change the order.\nRecommendation: We recommend defining parameters and local variables as those that are compiled into the binary. If the parameter or local variable is optimized away, it does not exist in the ground truth of the binary."
        },
        {
            "heading": "D. Cross references/pointers, Indirect jumps and calls",
            "text": "Within a code section there will be pointers/references to other code and data. Within a data section, there will be pointers/references to code and data. These pointers/references may be absolute values, or relative. We don\u2019t think there are too many questions related to these values as they are what they are.\nThere are jump tables, function pointers and other values that are used for indirect jumps and calls. The location of these values fits into this category as pointers/references to code. The question researchers have to ask here is:\n\u2022 Where do we obtain the ground truth about which bytes are these references/pointers? Some people recommend using relocation data for pointers, but that does not work well in position independent code which does not need as much relocation information.\nRecommendation: These values are what they are. We don\u2019t think instrumenting a compiler to find these values is the best long-term solution for generating the ground truth.If debug data contains all typing information, we can extract it from there. (See Section IV for further discussion)."
        },
        {
            "heading": "E. Special functions",
            "text": "Some functions do not return, and these affect the validity of control flow analysis. Also, some functions are inserted into the binary by the compiler, and are not linked to the source code. The question researchers have to ask here are:\n\u2022 For non-returning functions, where do we get the ground truth about this characteristic? We have seen tools that embed a list of non-returning standard library functions. This needs to be updated as libraries change, and may be language or even compiler dependent. In addition, use code can be non-returning if it always calls a non-returning function such as an error handling routing that then call exit or abort. How are these documented?\n\u2022 How does a non-returning function affect function analysis or control flow? Is an instruction after a call to a non-returning function part of the same function or not? We have seen fault-tolerant code that adds additional instructions after calls to non-returning functions, just in case an error results in a return. We have seen compilers that include additional function clean up instructions, because the compiler can not determine it is a non-returning function. The ground truth of the program must capture this.\n\u2022 How do we handle uncalled functions? Some of the compiler inserted functions are actually never called. If library is linked in, all of the functions in the library are usually included, not just the called ones. Are these unused, uncalled functions part of the ground truth?\n08055750 l F . t e x t 00000 c30 operand . . 0 080570 a0 l F . t e x t 00000330 i n t e g e r c o n s t a n t . . 0 08056 b60 l F . t e x t 00000540 i n t e g e r c o n s t a n t . . 2 08056840 l F . t e x t 00000320 i n t e g e r c o n s t a n t . . 3 08056520 l F . t e x t 00000320 i n t e g e r c o n s t a n t . . 4 0805 a7d0 l F . t e x t 00000 cb0 expr . . 0 080573 d0 l F . t e x t 00000 c80 expr . . 1 08058 f a 0 l F . t e x t 00000 cd0 operand 08056380 l F . t e x t 000001 a0 i n t e g e r c o n s t a n t . . 1\nListing 2. Symbol table from binary as new (binutils v 2.23). Compiled with icc v 14.0.1, in 32-bit mode, -O2 option.\ni n t e g e r c o n s t a n t . . 2 ( r a d i x i s 16) / d a t a / u s e n i x / Linux / b i n u t i l s \u2212 2 . 2 3 / gas / expr . c :360\nnumber = number * r a d i x + d i g i t ; 8056 baa : 8b d5 mov %ebp ,% edx 8056 bac : c1 ea 1 c s h r $0x1c ,% edx 8056 b a f : c1 e5 04 s h l $0x4 ,% ebp 8056 bb2 : c1 e6 04 s h l $0x4 ,% e s i\ni n t e g e r c o n s t a n t . . 3 ( r a d i x i s 2 ) / d a t a / u s e n i x / Linux / b i n u t i l s \u2212 2 . 2 3 / gas / expr . c :360\nnumber = number * r a d i x + d i g i t ; 805688 c : 8b d3 mov %ebx ,% edx 805688 e : 03 db add %ebx ,% ebx 8056890: c1 ea 1 f s h r $0x1f ,% edx 8056893: 03 c0 add %eax ,% eax\nListing 3. Code samples from binary as new (binutils v 2.23). Compiled with icc v 14.0.1, in 32-bit mode, -O2 option. Shown using AT&T syntax.\nRecommendation: Non-returning functions are special and need to be recognized and documented. OS system calls may need to be documented with the non-returning attribute. Everything should be recursively analyzable. Any functions inserted by the compiler or linker are still part of the binary and need to be treated as functions in the program."
        },
        {
            "heading": "III. EXAMPLES OF GROUND TRUTH CONFUSION",
            "text": "Many tools are designed to analyze binaries, in the wild. Therefore they may assume that the binaries are stripped of all metadata, including symbol tables and debug data. They may even assume that any symbol table or debug data in the binary may be deliberately incorrect to help thwart reverse engineering. This is a reasonable approach to take. However when we are conducting experimentation to determine how well a tool works, we have control over the experimentation test suite, and we can therefore be confident that any metadata is non-malicious. Researchers should also take care that the test suite is built in a way that allows generation of correct ground truth. For example, Koo et al. [9] mentioned that they had some test cases that were missing function data in the symbol table, although it existed in the debug data. We were able to rebuild these binaries with the full symbol table information. If we could not do this, we would recommend removing these outliers from the test data, if ground truth could not be reliably determined."
        },
        {
            "heading": "A. Compiler issues",
            "text": "Compilers will generate executables where there is not a direct one-to-one mapping from the source code. As an example, the following two examples cause confusion and\ndifficulty when generating ground truth related to function boundaries.\n1) Compiler insertion of multiple entry points: Listing 1 is a code snippet from the as-new binary, from binutils version 2.23, compiled with Intel compiler icc, version 14.0.1 into a 32-bit binary with the -O2 optimization option. Here we see two different entry points for the function fix_syms. The first entry allows for passing of parameters via the stack. These parameters are then stored in registers and then the code falls through to the next function. This allows for linking with other binaries that expect parameter passing on the stack, but leads to ground truth confusion.\nWhat is the ground truth in this case? The code is supporting two different calling conventions, with an optimized register convention being used for calls from functions within the same compilation unit. Is this one function or two? The symbol table says two.\n2) Compiler duplication/separation of functions: Listing 2 is a portion of the symbol table from the as-new program mentioned in Section III-A1. The first column is the byte address of the symbol, in this case the function start address. The next two columns include flags and a type of the symbol (in the example, all symbols are local and functions). The next column is the name of the section in the binary where the symbol is located, followed by the size \u2013 which is the length of the function.\nHere it is evident that the function integer_constant is compiled into 5 separate functions. This function takes a string and parses it into an integer, depending on the specified radix (base) of the number. An analysis of the code shows that the first argument of\ninteger_constant, the radix, is passed as a constant in this program. For calls to integer_constant..0 it is 10, for integer_constant..2 through integer_constant..4 it is 16, 2 and 8 respectively. There are no calls to integer_constant..1, where the radix is not one of the standard constants. The code makes very specific choices with respect to the value of radix. For each of these functions the compiler optimizes in the constant value of the radix, generating code for just the appropriate subset of the function for that radix. See code snippets in Listing 3, where the radix is 16 and then 2.\nWhat is the ground truth in this case? If we are mapping source code to binary, we have multiple mappings. If we are looking at individual functions in the binary, there are five functions for this one source function. If we are looking at parameters, we see that the first parameter is optimized out for four of the functions, and is not used, although it is still passed on the stack.\nB. IDA Pro\nIDA Pro [6] is a binary analysis tool that is used by a large portion of the community. It is a good tool with a lot of capabilities and features. However, it is still a tool, and is not necessarily the oracle of ground truth. We have seen papers and projects that say they use IDA Pro for their ground truth, such as [7]. This is the most concerning when they use it for ground truth that is then used for training a machine learning algorithm. The results are then compared to IDA Pro generated ground truth. So, although the experimental results may be favorable to the researchers, it does not mean that the trained and evaluated ground truth values are actually correct. The following are concrete examples of this.\nFor our research, we have compiled several different tool suites using several different compilers and compiler optimization flags. We compiled objdump, from the standard binutils package, using the clang compiler with -O2 optimization option for 32-bit Intel architecture under Linux, we got the code shown in Listing 4. Notice the jump pointer at address 0x8152ae7. IDA Pro was not able to interpret the target addresses and therefore assumed this was an end of a function, identifying 0x8152aee and 0x8152b12 as new functions. It also left code in address range 0x8152afa \u2013 0x8a52b11 as not within a single function. This error occured even with an unstripped binary with full debug information indicating the correct function start and size.\nWe compiled enscript with clang compiler (Version 6) using -flto (linktime optimization) and -O2 to get the code in Listing 5 for the function process_file. Here the LTO optimization results in some extra insertion of nops. IDA Pro indicates that the instruction starting at address 0x24540 is a new function, even though the symbol table includes the correct function boundaries. Also notice the stack adjustment and pushing of the frame pointer in addresses 0x24540 and 0x24543. IDA Pro could have been looking at the long set of nops or this pattern to make its determination.\nWe know that IDA Pro does take advantage of some of the metadata, because we found less errors when it was run on an unstripped binary versus stripped versions of the same binary, however it still has some issues with function\n08152 ad0 <get DW IDX name>: 8152 ad0 : movl 0x4(%esp ) ,% ecx 8152 ad4 : cmpl $ 0 x 1 f f f ,% ecx 8152 ada : j g 8152 a f 4 <get DW IDX name+0x24> 8152 adc : d e c l %ecx 8152 add : cmpl $0x4 ,% ecx 8152 ae0 : j a 8152 b30 <get DW IDX name+0x60> 8152 ae2 : movl $0x81f8d07 ,% eax 8152 ae7 : jmpl *0 x81f624c ( ,% ecx , 4 ) \u2212\u2212\u2212 M i s i d e n t i f i e d \u2212\u2212\u2212 8152 aee : movl $0x81f8d1b ,% eax 8152 a f 3 : r e t l \u2212\u2212\u2212 F o l l o w i n g Code Orphaned \u2212\u2212\u2212 8152 a f a : j e 8152 b24 <get DW IDX name+0x54> 8152 a f c : cmpl $0x2001 ,% ecx 8152 b02 : j e 8152 b2a <get DW IDX name+0x5a> 8152 b04 : cmpl $ 0 x 3 f f f ,% ecx 8152 b0a : j n e 8152 b30 <get DW IDX name+0x60> 8152 b0c : movl $0x81f8d5d ,% eax 8152 b11 : r e t l \u2212\u2212\u2212 M i s i d e n t i f i e d \u2212\u2212\u2212 8152 b12 : movl $0x81f8d2c ,% eax\n. . .\nListing 4. Example misindentified function entry in objdump utility (clang 32bit -O2 option), in AT&T syntax for Intel.\nboundary detection even on unstripped binaries. On a test of approximately 57,000 unstripped binaries, in 19% of the cases, there was not a perfect match between IDA Pro listed function starts and the function starts of the symbol table. In 1% of the cases, the resulting F1 statistic for correct function starts was less than 96%. Most of these cases occurred in evaluation of 32-bit binaries. Although this is not a horrible statistic, we want our ground truth to be 100% correct for validation.\nThe code in Listing 6 is derived from quotearg.c file, function quotearg buffer restyled. This is part of a standard gnu library for parsing command line arguments that is used by many common utilities. We compiled this library codes as part of a compilation of the coreutils suite of programs, using the intel compiler icc, with -O0 optimization and 64 bit Intel architecture under Linux. For this example, the library is part of the utility test. Here IDA Pro can not determine the target of the jump pointer instruction on line 0x4056bb and therefore reports that the instruction on line 0x4056bd is the start of a new function.\nAny tools that rely on IDA Pro, either as plug-ins or stand alone, should not just rely on IDA Pro when deriving the ground truth from the unstripped binaries."
        },
        {
            "heading": "C. Ghidra",
            "text": "Ghidra [11] is a reverse engineering tool developed by the National Security Agency, and was first publicly released in 2019. Ghidra has many capabilities similar to IDA Pro and can be used for disassembly, detection of function boundaries, etc. As with IDA Pro, it uses available debug and symbol table information. And, as with IDA Pro, it is not perfect in\nw h i l e ( f g e t s ( buf , s i z e o f ( buf ) , . . . 24516 : sub $0x4 ,% esp 24519: push %eax 2451 a : push $0x1000 2451 f : l e a 0 x1274 (%esp ) ,% ebp 24526: push %ebp 24527: c a l l 34 d10 <f g e t s @ p l t> 2452 c : add $0x10 ,% esp 2452 f : t e s t %eax ,% eax 24531: j e 24691 <p r o c e s s f i l e +0 x4581> 24537: xor %ebx ,%ebx 24539: nop 2453 a : nop 2453 b : nop 2453 c : nop 2453 d : nop 2453 e : nop 2453 f : nop\n\u2212\u2212\u2212 M i s i d e n t i f i e d \u2212\u2212\u2212 i = s t r l e n ( buf ) ;\n24540: sub $0xc ,% esp 24543: push %ebp 24544: c a l l 34 bd0 <s t r l e n @ p l t > 24549: add $0x10 ,% esp . . .\nListing 5. Example misindentified function entry (clang 32bit -O2 -flto options), in AT&T syntax for Intel.\n4056 b5 : add %rax ,% rdx 4056 b8 : mov (%rdx ) ,% r a x 4056 bb : jmpq *%r a x \u2212\u2212\u2212 M i s i d e n t i f i e d \u2212\u2212\u2212 4056 bd : movzbl \u22120x120(%rbp ) ,% eax 4056 c4 : movzbl %al ,% eax 4056 c7 : t e s t %eax ,% eax 4056 c9 : j e 40580 f\nListing 6. Example misinterpreted function end for function quotearg buffer restyled (icc 64bit -O0 option)\n408115: mov (%rax ,% rcx ,8 ) ,% r c x 408119: mov %edx , 0 x20(% r c x ) 40811 c : mov 0 x20d35d(% r i p ) ,% r c x 408123: mov %rbx ,(% rax ,% rcx , 8 ) 408127: pop %rbx 408128: jmpq 407640 40812 d : xor %ecx ,% ecx 40812 f : cmp %rbx ,% r c x 408132: j n e 4080 e5 408134: pop %rbx 408135: r e t q 408136: nopw %cs : 0 x0(%rax ,% rax , 1 ) 40813 d : 00 00 00\n\u2212\u2212\u2212 Miss ing F u n c t i o n \u2212\u2212\u2212 0000000000408140 <y y a l l o c >: 408140: jmpq 401450 <mal loc@pl t> 408145: d a t a 1 6 nopw %cs : 0 x0(%rax ,% rax , 1 ) 40814 c : 00 00 00 00\nListing 7. Example missing function entry (clang 64bit -O1), in AT&T syntax for Intel\ngenerating ground truth information. We have not seen papers that explicitly use Ghidra for ground truth, but it would not suprise us as more people begin to use it. In general Ghidra has done better, but as seen in Listing 7, for the states program (which is part of the enscript utility, Ghidra missed some function starts when analyzing the unstripped binary, even though they are listed in the symbol table. Therefore we can not always rely on it either for 100% accurate ground truth.\nAny tools that rely on Ghidra, either as plug-ins or stand alone, should not just rely on Ghidra when deriving the ground truth from the unstripped binaries."
        },
        {
            "heading": "D. Symbol Table",
            "text": "The symbol table in an unstripped binary contains information about functions and global variables (Listing 2 shows part of a symbol table). The problem we have found when using symbol tables for ground truth are:\n\u2022 They don\u2019t contain all of the information we want. For example, no mapping of which bytes are instructions. Jump tables and global pointers do not always have symbols.\n\u2022 There may not be a one-to-one mapping between function name symbols and source code. The example in Listing 2 shows just that case, where there are multiple binary functions for a specific source function. The example in Listing III-A1 shows multiple entry points for the same function. We have also seen aliases for functions, where two names point to the same function location.\n\u2022 Function lengths are not consistent. We found that the Intel compiler includes padding bytes in the function length in the symbol table, other compilers do not."
        },
        {
            "heading": "E. DWARF",
            "text": "We have seen several papers state that they use debug data for ground truth, but never elaborate further. When looking at DWARF debug data [4], we have seen several issues. First involves correctly interpreting the data. The HIGH PC value in a subprogram is the byte after the end of the function. However, it may be an absolute value or a relative value (length), which is not parsed correctly by some libraries/tools. Not all compilers include complete information in the DWARF data. It is a good source, but researchers have to be careful."
        },
        {
            "heading": "F. Compiler Hacks",
            "text": "There are a couple of tools that generate ground truth by hacking the compiler. One example of this is the work by Pang et al. [12], where the authors revise the compiler to emit all of the ground truth information they need. Li et al. [10] use intermediate representation, such as generated assembly code listings, to assist in the generation of their ground truth for disassembles.\nThese techniques only work for the compilers they are designed for, and therefore can not be reliably used for generalization of ground truth, even with newer versions of the same compilers."
        },
        {
            "heading": "IV. CONCLUSION",
            "text": "Knowing the ground truth is essential when evaluating the effectiveness of binary analysis tools. We have seen instances where the ground truth was incomplete, misleading, misinterpreted or even hacked to get results that the authors wanted. We are not saying that the authors deliberately misled the community, but rather did not focus on the importance of making sure the ground truth was correct. Most authors do not communicate the details of their generation of ground truth or the assumptions they made when doing the evaluation.\nWithout the existence of well vetted tools and/or data sets for ground truth, we will struggle with the ability to accurately build, evaluate and gauge binary analysis tools. If researchers then use incorrect ground truth when using machine learning or other automated analysis, the problem will just get worse. We recommend a discussion among the community about the types of ground truth metrics we need, the best ways to develop them, and a process for vetting and sharing ground truth generation tools.\nWe do not believe custom tools, such as compilers modifications, are a good long term solution to ground truth generation. Use of DWARF [4] debug data and the compiler generated symbol tables is a good start, but their limits need to be fully explored.\nEach method of generating a binary, different compilers, architectures, compiler optimizations, and source language creates challenges for binary analysis. We want our tools to be as accurate a possible. Creating good testsuites, with well documented and well create binaries is essential for validating the tools. When creating the testsuites, the researcher has control. They can ensure that all of the symbol table and other information is available in each binary in the testsuite. If, for some reason, it is not possible to have complete ground truth for a particular binary, it should be removed from the testsuite. This is permitted, since the idea of the testsuite is to validate the tools or algorithms, so we need 100% correct ground truth. Researchers should check to make sure their ground truth is correct, and they should clearly document how they arrived at the ground truth. Researchers should make scripts and programs for ground truth extraction and measurement of results to that ground truth publicly available."
        }
    ],
    "title": "The Inconvenient Truths of Ground Truth for Binary Analysis",
    "year": 2022
}