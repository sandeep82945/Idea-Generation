{
    "abstractText": "The surge in interest in Artificial Intelligence (AI) over the past decade has been driven almost exclusively by advances in Artificial Neural Networks (ANNs). While ANNs set state-of-the-art performance for many previously intractable problems, the use of global gradient descent necessitates large datasets and computational resources for training, potentially limiting their scalability for real-world domains. Spiking Neural Networks (SNNs) are an alternative to ANNs that use more brainlike artificial neurons and can use local unsupervised learning to rapidly discover sparse recognizable features in the input data. SNNs, however, struggle with dynamical stability and have failed to match the accuracy of ANNs. Here we show how an SNN can overcome many of the shortcomings that have been identified in the literature, including offering a principled solution to the dynamical \u201cvanishing spike problem\u201d, to outperform all existing shallow SNNs and equal the performance of an ANN. It accomplishes this while using unsupervised learning with unlabeled data and only 1/50th of the training epochs (labeled data is used only for a simple linear readout layer). This result makes SNNs a viable new method for fast, accurate, efficient, explainable, and re-deployable machine learning with unlabeled data.",
    "authors": [
        {
            "affiliations": [],
            "name": "Peter G. Stratton"
        },
        {
            "affiliations": [],
            "name": "Andrew Wabnitz"
        },
        {
            "affiliations": [],
            "name": "Chip Essam"
        },
        {
            "affiliations": [],
            "name": "Allen Cheung"
        },
        {
            "affiliations": [],
            "name": "Tara J. Hamilton"
        }
    ],
    "id": "SP:b9fec664c0270e56c6016c3c6e7986561e50be08",
    "references": [
        {
            "authors": [
                "K. Roy",
                "A. Jaiswal",
                "P. Panda"
            ],
            "title": "Towards spikebased machine intelligence with neuromorphic computing",
            "venue": "Nature, vol. 575, no. 7784, pp. 607-617, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "Y. LeCun",
                "Y. Bengio",
                "G. Hinton"
            ],
            "title": "Deep learning",
            "venue": "Nature, vol. 521, no. 7553, pp. 436-444, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "J. Lemley",
                "S. Bazrafkan",
                "P. Corcoran"
            ],
            "title": "Deep Learning for Consumer Devices and Services: Pushing the limits for machine learning, artificial intelligence, and computer vision",
            "venue": "IEEE Consumer Electronics Magazine, vol. 6, no. 2, pp. 48-56, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "N.C. Thompson",
                "K. Greenewald",
                "K. Lee",
                "G.F. Manso"
            ],
            "title": "The computational limits of deep learning",
            "venue": "arXiv:2007.05558, 2020.",
            "year": 2007
        },
        {
            "authors": [
                "J. Zhao",
                "R. Mortier",
                "J. Crowcroft",
                "L. Wang"
            ],
            "title": "Privacy-preserving machine learning based data analytics on edge devices",
            "venue": "presented at the Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society, 2018. MAKING A SPIKING NET WORK: ROBUST BRAIN-LIKE UNSUPERVISED MACHINE LEARNING",
            "year": 2018
        },
        {
            "authors": [
                "W.Y.B. Lim"
            ],
            "title": "Federated learning in mobile edge networks: A comprehensive survey",
            "venue": "IEEE Communications Surveys, vol. 22, no. 3, pp. 2031- 2063, 2020.",
            "year": 2031
        },
        {
            "authors": [
                "J. Park",
                "S. Samarakoon",
                "M. Bennis",
                "M. Debbah"
            ],
            "title": "Wireless network intelligence at the edge",
            "venue": "Proceedings of the IEEE, vol. 107, no. 11, pp. 2204- 2239, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "T. Masquelier",
                "R. Guyonneau",
                "S.J. Thorpe"
            ],
            "title": "Competitive STDP-based spike pattern learning",
            "venue": "Neural Computation, vol. 21, no. 5, pp. 1259-1276, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "A.J. Watt",
                "N.S. Desai"
            ],
            "title": "Homeostatic plasticity and STDP: keeping a neuron's cool in a fluctuating world",
            "venue": "Frontiers in Synaptic Neuroscience, vol. 2, p. 5, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "Y. LeCun"
            ],
            "title": "Deep learning hardware: past, present, and future",
            "venue": "2019 IEEE International Solid-State Circuits Conference-(ISSCC), 2019, pp. 12-19: IEEE.",
            "year": 2019
        },
        {
            "authors": [
                "Z.F. Mainen",
                "T.J. Sejnowski"
            ],
            "title": "Reliability of spike timing in neocortical neurons",
            "venue": "Science, vol. 268, no. 5216, pp. 1503-1506, 1995.",
            "year": 1995
        },
        {
            "authors": [
                "W. Singer"
            ],
            "title": "Time as coding space",
            "venue": "Current Opinion in Neurobiology, vol. 9, no. 2, pp. 189-194, 1999.",
            "year": 1999
        },
        {
            "authors": [
                "R. VanRullen",
                "R. Guyonneau",
                "S.J. Thorpe"
            ],
            "title": "Spike times make sense",
            "venue": "Trends in Neurosciences, vol. 28, no. 1, pp. 1-4, 2005.",
            "year": 2005
        },
        {
            "authors": [
                "E.M. Izhikevich"
            ],
            "title": "Polychronization: computation with spikes",
            "venue": "Neural Computation, vol. 18, no. 2, pp. 245-282, 2006.",
            "year": 2006
        },
        {
            "authors": [
                "R. Brette"
            ],
            "title": "Philosophy of the spike: rate-based vs. spike-based theories of the brain",
            "venue": "Frontiers in Systems Neuroscience, p. 151, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "P.O. Hoyer"
            ],
            "title": "Non-negative sparse coding",
            "venue": "Proceedings of the 12th IEEE Workshop on Neural Networks for Signal Processing: IEEE, 2002, pp. 557- 565.",
            "year": 2002
        },
        {
            "authors": [
                "B.A. Olshausen",
                "D.J. Field"
            ],
            "title": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images",
            "venue": "Nature, vol. 381, no. 6583, pp. 607-609, 1996.",
            "year": 1996
        },
        {
            "authors": [
                "A.J. Bell",
                "T.J. Sejnowski"
            ],
            "title": "The \u201cindependent components\u201d of natural scenes are edge filters",
            "venue": "Vision Research, vol. 37, no. 23, pp. 3327-3338, 1997.",
            "year": 1997
        },
        {
            "authors": [
                "R. Baddeley"
            ],
            "title": "Responses of neurons in primary and inferior temporal visual cortices to natural scenes",
            "venue": "Proceedings of the Royal Society of London. Series B: Biological Sciences, vol. 264, no. 1389, pp. 1775-1783, 1997.",
            "year": 1997
        },
        {
            "authors": [
                "P.T.P. Tang",
                "T.-H. Lin",
                "M. Davies"
            ],
            "title": "Sparse coding by spiking neural networks: Convergence theory and computational results",
            "venue": "arXiv preprint arXiv:.05475, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "S. Davidson",
                "S.B. Furber"
            ],
            "title": "Comparison of artificial and spiking neural networks on digital hardware",
            "venue": "Frontiers in Neuroscience, vol. 15, p. 345, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "H. Hazan",
                "D.J. Saunders",
                "D.T. Sanghavi",
                "H. Siegelmann",
                "R. Kozma"
            ],
            "title": "Lattice map spiking neural networks (LM-SNNs) for clustering and classifying image data",
            "venue": "Annals of Mathematics and Artificial Intelligence, vol. 88, no. 11, pp. 1237-1260, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A. Tavanaei",
                "M. Ghodrati",
                "S.R. Kheradpisheh",
                "T. Masquelier",
                "A. Maida"
            ],
            "title": "Deep learning in spiking neural networks",
            "venue": "Neural Networks, vol. 111, pp. 47- 63, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M. Diesmann",
                "M.-O. Gewaltig",
                "A. Aertsen"
            ],
            "title": "Stable propagation of synchronous spiking in cortical neural networks",
            "venue": "Nature, vol. 402, no. 6761, pp. 529- 533, 1999.",
            "year": 1999
        },
        {
            "authors": [
                "V. Litvak",
                "H. Sompolinsky",
                "I. Segev",
                "M. Abeles"
            ],
            "title": "On the transmission of rate code in long feedforward networks with excitatory\u2013inhibitory balance",
            "venue": "Journal of Neuroscience, vol. 23, no. 7, pp. 3006-3015, 2003.",
            "year": 2003
        },
        {
            "authors": [
                "A. Kumar",
                "S. Rotter",
                "A. Aertsen"
            ],
            "title": "Spiking activity propagation in neuronal networks: reconciling different perspectives on neural coding",
            "venue": "Nature Reviews Neuroscience, vol. 11, no. 9, pp. 615-627, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "T.P. Vogels",
                "L.F. Abbott"
            ],
            "title": "Signal propagation and logic gating in networks of integrate-and-fire neurons",
            "venue": "Journal of Neuroscience, vol. 25, no. 46, pp. 10786-10795, 2005.",
            "year": 2005
        },
        {
            "authors": [
                "H.S. Seung"
            ],
            "title": "Learning in spiking neural networks by reinforcement of stochastic synaptic transmission",
            "venue": "Neuron, vol. 40, no. 6, pp. 1063-1073, 2003.",
            "year": 2003
        },
        {
            "authors": [
                "P. Weidel",
                "R. Duarte",
                "A. Morrison"
            ],
            "title": "Unsupervised learning and clustered connectivity enhance reinforcement learning in spiking neural networks",
            "venue": "Frontiers in Computational Neuroscience, vol. 15, p. 18, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Lazar",
                "G. Pipa",
                "J. Triesch"
            ],
            "title": "SORN: a selforganizing recurrent neural network",
            "venue": "Frontiers in Computational Neuroscience, vol. 3, p. 23, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "P. Zheng",
                "C. Dimitrakakis",
                "J. Triesch"
            ],
            "title": "Network self-organization explains the statistics and dynamics of synaptic connection strengths in cortex",
            "venue": "PLoS Computational Biology, vol. 9, no. 1, p. e1002848, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "P. Fries",
                "D. Nikoli\u0107",
                "W. Singer"
            ],
            "title": "The gamma cycle",
            "venue": "Trends in Neurosciences, vol. 30, no. 7, pp. 309-316, 2007.",
            "year": 2007
        },
        {
            "authors": [
                "J.H. Lee",
                "T. Delbruck",
                "M. Pfeiffer"
            ],
            "title": "Training deep spiking neural networks using backpropagation",
            "venue": "Frontiers in Neuroscience, vol. 10, p. 508, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "C. van Vreeswijk",
                "H. Sompolinsky"
            ],
            "title": "Chaotic balanced state in a model of cortical circuits",
            "venue": "Neural Computation, vol. 10, no. 6, pp. 1321-1371, 1998.",
            "year": 1998
        },
        {
            "authors": [
                "G. Hennequin",
                "E.J. Agnes",
                "T.P. Vogels"
            ],
            "title": "Inhibitory plasticity: balance, control, and codependence",
            "venue": "Annual Review of Neuroscience, vol. 40, pp. 557-579, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "P. Stratton",
                "J. Wiles"
            ],
            "title": "Global segregation of cortical activity and metastable dynamics",
            "venue": "Frontiers in Systems Neuroscience, vol. 9, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "W. Maass",
                "T. Natschl\u00e4ger",
                "H. Markram"
            ],
            "title": "Realtime computing without stable states: A new framework for neural computation based on perturbations",
            "venue": "Neural Computation, vol. 14, no. 11, pp. 2531-2560, 2002. MAKING A SPIKING NET WORK: ROBUST BRAIN-LIKE UNSUPERVISED MACHINE LEARNING",
            "year": 2002
        },
        {
            "authors": [
                "P.U. Diehl",
                "M. Cook"
            ],
            "title": "Unsupervised learning of digit recognition using spike-timing-dependent plasticity",
            "venue": "Frontiers in Computational Neuroscience, vol. 9, p. 99, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "J. G\u00f6ltz"
            ],
            "title": "Fast and energy-efficient neuromorphic deep learning with first-spike times",
            "venue": "Nature Machine Intelligence, vol. 3, no. 9, pp. 823- 835, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "R.C. O'Reilly",
                "J.W. Rudy"
            ],
            "title": "Conjunctive representations in learning and memory: principles of cortical and hippocampal function",
            "venue": "Psychological Review, vol. 108, no. 2, p. 311, 2001.",
            "year": 2001
        },
        {
            "authors": [
                "S.R. Howard",
                "A. Avargu\u00e8s-Weber",
                "J.E. Garcia",
                "A.D. Greentree",
                "A.G. Dyer"
            ],
            "title": "Numerical ordering of zero in honey bees",
            "venue": "Science, vol. 360, no. 6393, pp. 1124-1126, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "T.J. Hamilton",
                "S. Afshar",
                "A. van Schaik",
                "J. Tapson"
            ],
            "title": "Stochastic electronics: A neuro-inspired design paradigm for integrated circuits",
            "venue": "Proceedings of the IEEE, vol. 102, no. 5, pp. 843-859, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "L.G. Wright"
            ],
            "title": "Deep physical neural networks trained with backpropagation",
            "venue": "Nature, vol. 601, no. 7894, pp. 549-555, 2022.",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "advances in Artificial Neural Networks (ANNs). While ANNs set state-of-the-art performance for many previously intractable problems, the use of global gradient descent necessitates large datasets and computational resources for training, potentially limiting their scalability for real-world domains. Spiking Neural Networks (SNNs) are an alternative to ANNs that use more brainlike artificial neurons and can use local unsupervised learning to rapidly discover sparse recognizable features in the input data. SNNs, however, struggle with dynamical stability and have failed to match the accuracy of ANNs. Here we show how an SNN can overcome many of the shortcomings that have been identified in the literature, including offering a principled solution to the dynamical \u201cvanishing spike problem\u201d, to outperform all existing shallow SNNs and equal the performance of an ANN. It accomplishes this while using unsupervised learning with unlabeled data and only 1/50th of the training epochs (labeled data is used only for a simple linear readout layer). This result makes SNNs a viable new method for fast, accurate, efficient, explainable, and re-deployable machine learning with unlabeled data.\nIndex Terms\u2014balanced networks, efficient learning, neuromorphic engineering, sparse parts-based features, spike propagation failure, spike timing dependent plasticity (STDP), spike timing neural networks, temporal coding, unsupervised local learning, vanishing spike problem\nI. INTRODUCTION\nIn recent years Deep Artificial Neural Networks (DNNs) have come to exceed state-of-the-art performance in many traditional Machine Learning (ML) domains, and have progressed in many domains that were previously inaccessible to ML approaches, such as face, image, video and speech recognition, and natural language understanding and generation. DNNs trained with gradient descent (GD) on an objective function in a process known as Deep Learning (DL) often excel at discovering complex features in their input data [1-3]. However DNNs also typically require exceptionally large\nThis research is supported by the Commonwealth of Australia as represented by the Defence Science and Technology Group of the Department of Defence. (Corresponding author: Peter G. Stratton).\nPeter G. Stratton was with University of Technology Sydney, Sydney, NSW 2007 Australia. He is now Associate Professor with the School of Electrical Engineering and Robotics, Queensland University of Technology, Brisbane Qld 4001, Australia (email: peter.stratton@qut.edu.au).\nAndrew Wabnitz is with Defence Science and Technology Group, Department of Defence, Edinburgh, SA 5111 Australia (email: andrew.wabnitz1@defence.gov.au).\nChip Essam is with Cuvos Pty. Ltd. Sydney, NSW 2000 Australia.\nnumbers of free parameters and commensurately sized training datasets [3, 4], meaning that they are poorly suited for many real-world applications where the problems are not necessarily static or a priori easy to capture explicitly, where training data may be sparse or expensive to collect, high power data servers are not available, there are real-time or latency constraints, communication channels may be unreliable or open to attack, adaptation or online training may be required, privacy or security is a factor, or any number of other reasons why relying on large, remote, power-hungry and unadaptive ML models may be inappropriate [5-7].\nAn emerging alternative to DNNs is Spiking Neural Networks (SNNs). Rather than continuous activation functions, SNNs use discrete events (spikes) to transmit information between neurons, and rather than learning through global gradient descent, SNNs can learn using local unsupervised correlation- or causation-based learning rules such as spike timing dependent plasticity (STDP [8, 9]) which strengthens connections between causally connected neurons (i.e. when one neuron elicits a spike in another neuron). Amid growing recognition of the practical and computational limits of DL and of supervised learning in general, many eminent DL researchers suggest that the path to further substantial progress in AI is through unsupervised learning [2, 10]. While some DNN architectures, such as autoencoders, adversarial networks and their variants, implement a form of \u201cself-supervised\u201d learning, they still require definition of an objective function and they still rely on global error feedback for training, and so they continue to suffer many of the same disadvantages as fully supervised DNNs.\nBoth brains and SNNs have the capacity to compactly and efficiently represent information in the timing of their discrete spikes [11-15]. Nevertheless, many SNN architectures rely on spike-rate coding as a proxy for the continuous activation functions of DNNs, but in doing so they forgo the potential advantages of spike-time coding. Spike-time coding using sparse spiking events is exceptionally efficient in terms of both\nAllen Cheung is an independent researcher. Tara J. Hamilton was with University of Technology Sydney, Sydney, NSW 2007 Australia. She is now with Cuvos Pty. Ltd. Sydney, NSW 2000 Australia and Adjunct Associate Professor with UTS (email: tara.hamilton@cuvos.com.au).\nAppendix proofs and Extended Data are available online. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.\nMAKING A SPIKING NET WORK: ROBUST BRAIN-LIKE UNSUPERVISED MACHINE LEARNING\nenergy requirements and information density, while simultaneously having high memory capacity and strong generalization ability [16-21]. Additionally, unsupervised local learning in SNNs is simple and fast, allowing them to learn more rapidly and with much improved data efficiency over DNNs [22, 23] (and also over SNNs that use approximations of gradient descent). Finally, dispensing with data labels, aside from a final simple linear readout stage if needed, means that collecting and curating training data is often quicker and cheaper than for DL, for which it can be an onerous task. We call SNNs that use spike timing to represent information, and that use unsupervised learning rules to train the weights: SpikeTiming Unsupervised Neural Networks (STUNNs).\nDespite their potential advantages, STUNNs and SNNs in general remain on the fringe of ML research. Several factors have likely contributed to this failure to attract significant attention:\n1. In multi-layer SNNs, spike propagation tends to fail as spikes pass between layers [24-27]; this has been called \u201cvanishing forward-spike propagation\u201d.\n2. There is a commonly perceived inadequacy of unsupervised learning for reliably solving logical NOT-like and XOR-like problems [27-29].\n3. The lack of an objective function means performance\nis often below comparable DNNs.\n4. Combining spike-time coding with unsupervised\nlearning has proven challenging [1, 21, 22].\nWe show that the first problem (vanishing spikes) has potentially had widespread, severe and yet relatively unrecognized impact on the capacity of SNNs to function effectively. Our solutions significantly advance the state-of-theart to the extent that a simple shallow STUNN using unsupervised local learning equals the performance of a shallow ANN on the MNIST task with only a fraction of the training. The solutions form a list of principles for robust unsupervised feature extraction using SNNs, and a new method for rapid and efficient machine learning with unlabeled datasets.\nII. METHODS\nWe implemented a spike timing unsupervised neural network (STUNN) that we called BLiTNet (Binned Linear Time Network). BLiTNet is an adaptation and extension of the Self Organizing Recurrent Network (SORN [30, 31]) to incorporate feedforward networks with multiple layers and to also incorporate sub-timestep resolution for the spike times. Like SORN, BLiTNet implements simple time-stepped neuron and synapse models that carry no state between timesteps (i.e. there are no membrane, synaptic or other time constants in the models). A timestep or time bin in the model is nominally equivalent to a gamma oscillation cycle in the brain. Gamma oscillations occur at 40-100 Hz and have been linked to active neural processing states, and the wavelength of 10-25 ms also approximates the time courses of neuron membranes and fast synaptic currents as well as spike timing dependent plasticity (STDP). This gamma-timestep abstraction allows the capture of\nactive neural processing dynamics in a lightweight model suitable for digital hardware implementation."
        },
        {
            "heading": "A. Core BLiTNet",
            "text": "In BLiTNet, neurons are organized into \ud835\udc41 layers, typically with an input layer, an output layer and zero or more intervening (feature) layers. Connectivity between the layers may be full, sparse or spatially localized. While neurons in the brain are either excitatory or inhibitory, in BLiTNet we allow individual neurons to project both types of connections to other neurons, which is a simplification we employ to reduce the total neuron count. Connections cannot change type (i.e. a connection is either excitatory or inhibitory and cannot change sign).\nAn excitatory connection from neuron \ud835\udc56 in layer \ud835\udc5a to neuron \ud835\udc57 in layer \ud835\udc5b is given by \ud835\udc4a\ud835\udc57\ud835\udc56 +\ud835\udc5b\ud835\udc5a and an inhibitory connection by \ud835\udc4a\ud835\udc57\ud835\udc56 \u2212\ud835\udc5b\ud835\udc5a. The network state \ud835\udc65 at time \ud835\udc61 is given by the vectors \ud835\udc65\ud835\udc5b (\ud835\udc61) of spike amplitudes in [0,1] for all layers \ud835\udc5b in 1. . \ud835\udc41, where 0 represents no spike, 1 represents a full-strength spike, and values between 0 and 1 represent intermediate-strength spikes. In the brain, neurons that are more strongly excited fire earlier in each gamma oscillation cycle, and thus the amplitude of the input to each neuron is re-coded into the oscillation phase, allowing for a readout of amplitude within each individual gamma cycle [32]. So even though each timestep in BLiTNet involves only one network state calculation, we conceptualize spike amplitude as the timing of the spike within the timestep (i.e. spikes occur with sub-timestep resolution). An amplitude of 1 denotes the start of the timestep and 0 the end (Ext Fig S10). The network state \ud835\udc65 therefore evolves as follows:\n\ud835\udc65\ud835\udc57 \ud835\udc5b(\ud835\udc61 + 1) = \u2211 \u2211 \ud835\udc65\ud835\udc56 \ud835\udc5a(\ud835\udc61)(\ud835\udc4a\ud835\udc57\ud835\udc56 +\ud835\udc5b\ud835\udc5a \u2212 \ud835\udc4a\ud835\udc57\ud835\udc56 \u2212\ud835\udc5b\ud835\udc5a)\ud835\udc56 \ud835\udc41 \ud835\udc5a=1 + \ud835\udf09\ud835\udc57 \ud835\udc5b(\ud835\udc61) +\n\ud835\udc50\ud835\udc57 \ud835\udc5b \u2212 \ud835\udf03\ud835\udc57 \ud835\udc5b (1)\nwhere \ud835\udf03 is the neuron threshold, \ud835\udf09 is a time-varying noise input uniformly distributed in [0,\ud835\udf09\ud835\udc5a\ud835\udc4e\ud835\udc65\n\ud835\udc5b ], and \ud835\udc50 is a constant input to the neuron. The activity vectors \ud835\udc65 are clipped in the range [0,1] where any \ud835\udc65 > 0 represents a spike. Initial thresholds are drawn from a uniform distribution in the range [0,\ud835\udf03\ud835\udc5a\ud835\udc4e\ud835\udc65 \ud835\udc5b ], with \ud835\udf03\ud835\udc5a\ud835\udc4e\ud835\udc65 \ud835\udc5b usually set to 0.1 or 0.2.\nConnections and thresholds are subject to plasticity rules. An excitatory connection \ud835\udc4a\ud835\udc57\ud835\udc56 +\ud835\udc5b\ud835\udc5a undergoes excitatory spike timing dependent plasticity (STDP) that strengthens the connection by a small amount \ud835\udf02\ud835\udc46\ud835\udc47\ud835\udc37\ud835\udc43 when neuron \ud835\udc56 fires in the timestep immediately prior to neuron \ud835\udc57 firing, and weakens the connection by the same amount when neuron \ud835\udc56 fires in the timestep immediately following neuron \ud835\udc57:\n\u25b3 \ud835\udc4a\ud835\udc57\ud835\udc56 +\ud835\udc5b\ud835\udc5a(\ud835\udc61) = \ud835\udf02\ud835\udc46\ud835\udc47\ud835\udc37\ud835\udc43(\ud835\udc61) [\ud835\udee9(\ud835\udc65\ud835\udc56 \ud835\udc5a(\ud835\udc61 \u2212 1))\ud835\udee9 (\ud835\udc65\ud835\udc57 \ud835\udc5b(\ud835\udc61)) \u2212\n\ud835\udee9(\ud835\udc65\ud835\udc56 \ud835\udc5a(\ud835\udc61))\ud835\udee9 (\ud835\udc65\ud835\udc57 \ud835\udc5b(\ud835\udc61 \u2212 1))] (2)\nwhere \ud835\udee9 is the Heaviside step function. If a connection goes negative it is reset to a small positive value \ud835\udf16 = 10\u22126. The STDP learning rate \ud835\udf02\ud835\udc46\ud835\udc47\ud835\udc37\ud835\udc43 is initialized to \ud835\udf02\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61 = 0.001 and then annealed during the \ud835\udc47 training iterations according to:\nMAKING A SPIKING NET WORK: ROBUST BRAIN-LIKE UNSUPERVISED MACHINE LEARNING\n\ud835\udf02\ud835\udc46\ud835\udc47\ud835\udc37\ud835\udc43(\ud835\udc61) = \ud835\udf02\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61 (1 \u2212 \ud835\udc61\n\ud835\udc47 )\n2\n(3)\nThe total excitatory weight to each postsynaptic neuron \ud835\udc57 is normalized to a constant \ud835\udc58 each timestep:\n\ud835\udc4a\ud835\udc57\ud835\udc56 +\ud835\udc5b\ud835\udc5a(\ud835\udc61) \u2190\n\ud835\udc58\ud835\udc5b\ud835\udc5a\ud835\udc4a\ud835\udc57\ud835\udc56 +\ud835\udc5b\ud835\udc5a(\ud835\udc61) \u2211 \ud835\udc4a\ud835\udc57\ud835\udc56 +\ud835\udc5b\ud835\udc5a(\ud835\udc61)\ud835\udc56\n(4)\nThis normalization rule preserves the relative strengths of the connections while inducing competition between the connections since one connection can increase in efficacy only by decreasing the others. For small or simple networks, setting \ud835\udc58 = 1 is adequate, but for larger networks:\n\ud835\udc58\ud835\udc5b\ud835\udc5a = (0.1 \ud835\udc5d\ud835\udc5b\ud835\udc5a)/\u2044 \ud835\udc53\ud835\udc5a\u0305\u0305 \u0305\u0305 (5)\nwhere \ud835\udc5d\ud835\udc5b\ud835\udc5a is the connection probability from layer \ud835\udc5a to layer \ud835\udc5b and \ud835\udc53\ud835\udc5a\u0305\u0305 \u0305\u0305 is the mean firing rate of neurons in layer \ud835\udc5a. Firing rate \ud835\udc53 \u2208 [0,1] is measured as the proportion of steps in which spikes occur. The normalization constant \ud835\udc58 creates larger weights for both sparser connections and lower presynaptic firing rates, ensuring that postsynaptic neurons continue to use the full range [0,1] for spike amplitudes. The constant 0.1 sets the mean spike amplitude in layer \ud835\udc5b, and is used rather than 1 because the latter would cause half the spikes to be clipped at maximum amplitude.\nInhibitory connections undergo inhibitory STDP that strengthens the connection by \ud835\udf02\ud835\udc46\ud835\udc47\ud835\udc37\ud835\udc43 when neuron \ud835\udc56 fires in the timestep immediately prior to neuron \ud835\udc57 (this rule is identical to excitatory STDP) and weakens the connection when neuron \ud835\udc56 fires and then neuron \ud835\udc57 does not fire in the timestep immediately following (this rule is different to excitatory STDP). Additionally, the weakening term is normalized by the firing rate of the postsynaptic neuron (\ud835\udc53\ud835\udc57) to balance the strengthening and weakening terms for sparsely firing postsynaptic neurons:\n\u25b3 \ud835\udc4a\ud835\udc57\ud835\udc56 \u2212\ud835\udc5b\ud835\udc5a(\ud835\udc61) = \ud835\udf02\ud835\udc46\ud835\udc47\ud835\udc37\ud835\udc43(\ud835\udc61) [\ud835\udee9(\ud835\udc65\ud835\udc56 \ud835\udc5a(\ud835\udc61 \u2212 1))\ud835\udee9 (\ud835\udc65\ud835\udc57 \ud835\udc5b(\ud835\udc61)) \u2212\n\ud835\udee9(\ud835\udc65\ud835\udc56 \ud835\udc5a(\ud835\udc61 \u2212 1))\ud835\udee9 (1 \u2212 \ud835\udc65\ud835\udc57 \ud835\udc5b(\ud835\udc61)) \ud835\udc53\ud835\udc57 \ud835\udc5b] (6)\nIf a connection goes positive it is reset to a small negative value \ud835\udf16 = \u221210\u22126. Inhibitory connections are not normalized to a fixed value. Their role is to balance the excitatory inputs which can vary considerably depending on input statistics, connection densities, target firing rates, etc. Instead, all inhibitory connections to a postsynaptic neuron increase slightly when net input to that neuron is positive, and decrease slightly when net input is negative:\n\ud835\udc4a\ud835\udc57\ud835\udc56 \u2212\ud835\udc5b\ud835\udc5a(\ud835\udc61) \u2190 \ud835\udc4a\ud835\udc57\ud835\udc56 \u2212\ud835\udc5b\ud835\udc5a(\ud835\udc61) (1 \u2212 \ud835\udf02\ud835\udc46\ud835\udc47\ud835\udc37\ud835\udc43(\ud835\udc61). \ud835\udee9(\u2211 \ud835\udc65\ud835\udc56 \ud835\udc5a(\ud835\udc61)\ud835\udc56 )) (7)\nIntrinsic threshold plasticity (ITP) adjusts the firing threshold of each neuron such that the neuron reaches a desired target firing rate:\n\ud835\udee5\ud835\udf03\ud835\udc57 \ud835\udc5b(\ud835\udc61) = \ud835\udf02\ud835\udc3c\ud835\udc47\ud835\udc43(\ud835\udc61) (\ud835\udee9 (\ud835\udc65\ud835\udc57 \ud835\udc5b(\ud835\udc61)) \u2212 \ud835\udc53\ud835\udc57 \ud835\udc5b) (8)\nwhere \ud835\udc53\ud835\udc57 \ud835\udc5b is the desired firing rate of neuron \ud835\udc57 in layer \ud835\udc5b. Unless otherwise stated, firing rates are set in a uniform distribution in [0.03,0.25]. If a threshold falls below 0 it is reset to 0 (i.e. neurons are not allowed to be spontaneously active). The ITP learning rate \ud835\udf02\ud835\udc3c\ud835\udc47\ud835\udc43 is initialized to 2\ud835\udf02\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61 and then annealed during the \ud835\udc47 training iterations according to:\n\ud835\udf02\ud835\udc3c\ud835\udc47\ud835\udc43(\ud835\udc61) = 2\ud835\udf02\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61 (1 \u2212 \ud835\udc61\n\ud835\udc47 )\n2\n(9)"
        },
        {
            "heading": "B. Spike forcing",
            "text": "In some cases we used \u201cspike forcing\u201d of neurons in the output layer to create a supervised spiking readout of the result that is represented in the underlying feature layer, by forcing output neurons to spike or not spike as required. Spike forcing is similar to the delta learning rule and to standard STDP except there are more learning cases to consider. Since there are two types of spikes \u2013 network spikes (those that are driven by the network), and forced spikes (those that are pre-specified) \u2013 there are four spiking conditions. A neuron could have:\n1. a forced spike and no network spike 2. a network spike and no forced spike 3. both forced and network spikes 4. neither forced nor network spikes\nFor training the neuron thresholds \ud835\udf03, the learning rules ensure that each neuron sets its threshold to spike when a forced spike is desired and not spike when a forced spike is not desired (Table I):\nFor training the connection weights \ud835\udc4a, the learning rules strengthen connections from input neurons that should cause output spikes, and weaken connections from input neurons that should not (Table II):\nMAKING A SPIKING NET WORK: ROBUST BRAIN-LIKE UNSUPERVISED MACHINE LEARNING\nNetwork of forward-connected layers of neurons. (c) An alternative feedforward architecture with additional inhibitory connections that approximately balance the excitatory connections. (d) Network gain function where gain = 1 invariably leads to vanishing spikes because of the positive threshold (x intercept). (e) For network gain > 1, activity will either vanish (solid arrows) or saturate (dashed arrows) from the stable firing rate (small black arrow) depending on finite-size fluctuations."
        },
        {
            "heading": "C. Signal propagation networks",
            "text": "Parameters were as specified above and in the main\nmanuscript, and as noted below.\n\u2022 For all networks: \ud835\udc41 = 10, \ud835\udc47 = 10000, \ud835\udf09\ud835\udc5a\ud835\udc4e\ud835\udc65 1 = 0.1\nand \ud835\udf09\ud835\udc5a\ud835\udc4e\ud835\udc65 2..\ud835\udc41 = 0 (i.e. noise drives the input layer only).\n\u2022 For networks with no plastic inhibition: \ud835\udf02\ud835\udc46\ud835\udc47\ud835\udc37\ud835\udc43 = 0. \u2022 For networks with plastic inhibition: \ud835\udf02\ud835\udc46\ud835\udc47\ud835\udc37\ud835\udc43 + = 0 and\n\ud835\udf02\ud835\udc46\ud835\udc47\ud835\udc37\ud835\udc43 \u2212 (0) = \ud835\udf02\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61 (i.e. no plasticity for excitatory connections).\n\u2022 For all networks that have equal target firing rates for\nall neurons: \ud835\udc53 = 0.1.\n\u2022 For the last network with a range of target firing rates:\n\ud835\udc53 uniformly distributed in [0.025,0.175].\n\u2022 For networks with constant input: \ud835\udc50 uniformly distributed in [0,0.099]."
        },
        {
            "heading": "D. Logical function networks",
            "text": "The network architectures were as shown in the main manuscript. For all networks, \ud835\udc47 = 10000, \ud835\udf09 = 0, \ud835\udf02\ud835\udc46\ud835\udc47\ud835\udc37\ud835\udc43 + (0) = \ud835\udf02\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61 and \ud835\udf02\ud835\udc46\ud835\udc47\ud835\udc37\ud835\udc43 \u2212 (0) = 0 (i.e. no plasticity for inhibitory connections)."
        },
        {
            "heading": "E. MNIST networks",
            "text": "Parameters were as specified above and in the main manuscript, and as noted below. For all networks: \ud835\udc41 = 3, \ud835\udc47 = 60000, \ud835\udf09 = 0 and \ud835\udc50 = 0.\nAll networks used 784 input neurons in the first layer, then variable numbers of feature-layer and output-layer neurons. The feature layer was trained first, then its learning rate was set to zero and the output layer was trained. Output neurons were split into 10 groups of equal size (one group for each digit) with each output neuron sampling a different subset of neurons in the feature layer due to sparse excitatory connectivity. Output neurons were trained with spike forcing. The weight matrices between layers were as follows:\n\ud835\udc4a+21: Full or spatially localized plastic connections as shown in manuscript.\n\ud835\udc4a\u221221: Sparse plastic connections with connection probability 0.015.\n\ud835\udc4a+32: Sparse plastic connections with connection probability between 0.2 and 0.3.\n\ud835\udc4a\u221232: Full or nearly full plastic connections with connection probability between 0.7 and 1.0.\nAfter training on the 60000 MNIST training digits, network\nperformance was assessed in two ways:\n1. The output neuron group with the most spikes was\nused to classify each of the 10000 test input digits.\n2. A decoder was trained using linear regression on the\nfeature layer for each training digit and was then used to classify each test digit."
        },
        {
            "heading": "F. Code availability",
            "text": "Code will be made available for non-commercial use.\nIII. RESULTS\nOur results are presented in three sections below. The first shows the etiology and resolution of the vanishing spike problem, or \u201cspike propagation failure\u201d. The second shows how the same solutions facilitate unsupervised learning of logic functions such as NOT and XOR. The last shows how the combination of these solutions improves state-of-the-art performance for shallow unsupervised learning of MNIST images.\nMAKING A SPIKING NET WORK: ROBUST BRAIN-LIKE UNSUPERVISED MACHINE LEARNING"
        },
        {
            "heading": "A. Solving Spike Propagation Failure",
            "text": "Neurons are leaky integrators of their input currents, which makes their response to constant input highly nonlinear and even discontinuous. An input current to a neuron that is smaller than the neuron\u2019s maximum leak current, even if applied indefinitely, will never lead to an output spike. With an input current just slightly larger than this specific threshold current, a typical neuron will spike rhythmically, for as long as the input is applied, with a period determined in large part by the time constant of the threshold leak current. Therefore there is a discontinuous jump from no spiking to spiking continuously at a constant low rate. For input currents substantially larger than the threshold current, a neuron enters an approximately linear regime that is affected less and less by the leak as the magnitude of the input current increases. For even higher input currents, a neuron\u2019s refractory period (i.e. the time following a spike during which a neuron is unable to fire again) begins to dominate and the firing rate begins to saturate. Beyond this level the firing rate plateaus, however this level of input is typically non-physiological and if sustained will usually lead to neuron death due to excito-toxicity. A typical single-neuron gain function is shown in Fig 1a.\nThe single-neuron gain function can be extended to a network of interconnected neurons where neurons are organized in layers, and where neurons in each layer are unidirectionally connected to (a subset of) neurons in the next layer (Fig 1b). For the same reason that a single neuron requires input current beyond a threshold in order to produce any output spikes, a network layer requires a certain number of input spikes from the previous layer to produce any output spikes of its own. A schematic plot of the network gain function showing the output layer firing rate against the input layer firing rate is analogous to the previous single-neuron gain function (Fig 1d and Extended Fig S1). The mapping from input layer population firing rate to output population firing rate (Fig 1d, dark black trace) shows the effect of the non-zero spike firing threshold. If the population firing rate of the first (input) layer begins at 600 Hz (bold arrow), the subsequent rate of the second layer will be lower, as shown by following the arrows. When this activity is then used as the input to the next layer, the resulting activity level is even lower. Activity entirely vanishes after propagating through several layers.\nIf the network gain is increased to greater than 1 (Fig 1e and Extended Fig S2), then there will be one input firing rate for which the input and output firing rates will be exactly equal (small dark\narrow). However, due to the quantized, all-or-nothing spike currents and the finite number of neurons in each layer (i.e. finite size effects), it is impossible to maintain this exact rate. Small variations from one moment to the next will accumulate. If the variation is downwards then on the next layer the downward drop will be magnified (due to gain > 1) and once again activity will quickly vanish (Fig 1e, solid arrows). Similarly, if the variation is upwards then this upward tendency is also magnified and activity will evolve into unconstrained spike avalanches where every neuron spikes continuously (Fig 1e, dashed arrows).\nWe simulated a network consisting of 10 layers of 100 neurons per layer, sequentially connected by random fixed-weight feedforward connections with 10% connection probability. Neurons in the bottom layer received random noise input. Every neuron used intrinsic threshold plasticity (ITP; see Methods) to reach a target firing rate of 0.1 (i.e. firing in 10% of the time-steps). As spiking activity propagated through the layers, input patterns that randomly contained fewer spikes than average were further under-represented in subsequent layers, while patterns with randomly more spikes provoked inordinately large responses, resulting in most of the network\u2019s spikes being elicited for only the largest input patterns (Fig 2a, left and top right panels). Even in just the propagation of activity from the first layer to the second, magnification of variations in activity levels are clear (i.e. input patterns that were randomly smaller (/larger) in the first layer recruited even less (/more) activity in the next layer). The number of neurons firing in each layer was strongly correlated with the number in the layer below (r=0.900, Fig 2a bottom right panel).\nNote that this signal propagation failure is independent of the neuron model being used; it applies from the simplest linear threshold unit all the way to the most biophysically detailed models, and indeed to real neurons. The only requirement is for the neuron to have a non-zero threshold and rectified output (see our novel analysis: Appendix). The default behaviour of SNNs is therefore to tend towards dynamical quiescence or saturation which, after spike propagation through several layers, diminishes their information-carrying capacity to essentially zero. This effect has been termed \u201cvanishing forward-spike propagation\u201d [1]. We name it \u201cspike propagation failure\u201d since the failure can be either quiescence (vanishing) or saturation (avalanche) [24-27]. The problem has been blamed on \u201cinappropriate weights and thresholds\u201d [33], but it is clear from the above that no weight settings could alleviate the problem, since these will only change the overall gain, while removing the threshold nonlinearity will\nMAKING A SPIKING NET WORK: ROBUST BRAIN-LIKE UNSUPERVISED MACHINE LEARNING\nseverely impact both the stability and computational capacity of the networks, since the system would be reduced to linear.\nA general solution to this problem within the ML literature has not been forthcoming. Apart from the few references cited above, there is surprisingly little recognition of the problem despite it being ubiquitous in all SNN models. The failure to recognize this issue, or to take it seriously enough, may have been at considerable detriment to SNN research.\nHowever, a basic solution is immediately available and is an important component of theories behind cortical dynamics and criticality in the brain. The idea is to use excitation/inhibition (E/I) balance; that is, that excitatory and inhibitory connections, and therefore dynamic synaptic currents, can be closely matched (Fig 1c). Within the context of recurrent SNNs and cortical dynamics, E/I balance ensures that network activity remains in a chaotic or critical regime since spikes are driven by small fluctuations in balance that are highly dependent on initial conditions and ongoing inputs [26, 27, 30, 34]. In the context of spikes propagating through a feedforward network [24, 25], balance removes the dependence of the activity level of layer n+1 (an+1) on the activity level of layer n (an). Therefore, rather than depending on the absolute magnitude of an, an+1 depends only on small deviations from the balance. The imperfections in balance can be spatial (connections that are sparse, random, or in some other manner not fully overlapping) and temporal (a delay between the arrival of excitatory and inhibitory signals). Due to the approximate E/I balance, the mean input to each neuron over time is close to zero rather than being positive, restoring the linearity of the network gain without upsetting the stability. In this regime, individual neurons can still have positive thresholds which allow them to fire sparsely rather than firing every time their inputs fluctuate above zero.\nFig 2b shows results from a network that used balancing\ninhibitory connections as shown in Fig 1c. Signal propagation was dramatically better but still imperfect. To further improve the propagation, three additional mechanisms with inspiration from neuroscience [35, 36] were considered:\n1. Inhibitory STDP [35] (i.e. plasticity of the balancing\ninhibition).\n2. Constant input to each neuron [36]. 3. Different target firing rates for each neuron.\nWhen applied individually, each of the three mechanisms made little difference to the signal correlation, at best reducing it to about r=0.85. However, when testing pairs of mechanisms, the pairing of inhibitory STDP and constant input made considerably more difference, reducing correlation to 0.505 (Fig 2c). The remaining pairings (different firing rates with respectively STDP and constant input) made little further improvement beyond the improvement using each mechanism individually.\nHowever, when all three mechanisms were applied together, the balance was much further improved, signals propagated without obstruction (Fig 2d), and signal correlation reduced to 0.111. Being driven predominantly by small fluctuations in the E/I balance, the network gain function was discontinuous (Fig 2d, bottom right)."
        },
        {
            "heading": "B. Solving XOR and NOT",
            "text": "The exclusive-OR function (XOR) has a long history in the neural network field. During the 1940\u2019s, 50\u2019s and 60\u2019s the Perceptron (network of linear threshold units) was investigated as a model of neural function, and interest in neural computation was flourishing. Then in the late 60\u2019s it was shown that the simple XOR problem, being linearly inseparable, could never be solved by a single-layer perceptron, and no training algorithms existed for\nmulti-layer perceptrons (MLPs). This realization contributed to the first \u201cAI winter\u201d, which for neural networks lasted until just after 1986 when it was shown that with a few clever techniques the chain-rule backpropagation algorithm could be applied to train MLPs, and the XOR problem could be solved by neural networks using supervised learning.\nNotwithstanding the kernel trick (where random projections from the input to a higher-dimensional feature space result in at least one dimension upon which features can be linearly separated [37]), an implicit assumption in the field that seems to dominate to this day is that unsupervised learning will struggle to reliably learn XOR and similar linearly inseparable problems, since there is no impetus (error signal or gradient) for the network to follow in order to construct the required representations (but see [28, 29]). Indeed, even to solve something as simple as the NOT function, implemented in an SNN with one input neuron and one output neuron, would require the output neuron to remain silent when the input neuron emits a spike, and for the output to spike when the input is silent. Clearly for any purely input-driven network this is not possible, and it is unclear how any unsupervised learning algorithm could learn this function [27].\nHere we show that minimally sized SNNs, using combinations of network balance, constant input, and a distribution of feature neuron firing rates (the same mechanisms that permit stable signal propagation), can trivially learn unsupervised spike temporal coding versions of all logic functions (Fig 3). For example, NOT can be solved by a feature neuron that receives an inhibitory connection from an input neuron, causing it to not emit a spike\nwhen the input neuron spikes, in combination with a constant input that causes it to emit a spike when the input neuron does not (Fig 3c). The learning in this case entails the neuron finding a suitable firing threshold that lies between the constant input and the constant input less the inhibitory connection weight. For this learning to work effectively the neuron needs to have a target firing rate that is the complement of the input neuron\u2019s rate, and then using intrinsic threshold plasticity (ITP) the neuron will converge onto a suitable threshold. In this basic example we simply choose a suitable target firing rate that matches the logical function result that we desire. In more complex cases, larger networks with a distribution of target firing rates over the population of feature neurons, in combination with sparse random connections (so that some neurons receive only excitatory connections from given inputs, some receive only inhibitory, some both, and some neither), can learn all logic functions simultaneously. Temporal coding allows the networks to solve these functions using the minimum possible number of spikes."
        },
        {
            "heading": "C. Solving MNIST with performance equalling ANNs",
            "text": "Using our Binned Linear-Time Network (BLiTNet) implementation of a STUNN, we trained a network using the MNIST dataset (784 input neurons) fully connected with plastic excitatory connections to 100 feature neurons (see Methods for details). With no inhibition in the network the results on the MNIST test set were very poor (Fig 4a). The initially imperfect network balance was worsened by the plasticity in a vicious feedback loop where the network would respond with more spikes\nMAKING A SPIKING NET WORK: ROBUST BRAIN-LIKE UNSUPERVISED MACHINE LEARNING\nto those digits that had more active pixels, i.e. more input spikes, and the plasticity would enhance that response even further, such that almost every feature neuron ultimately learned to respond only to the largest digits (0 and 8). Most SNN models incorporate some form of inhibition, and adding fixed balancing inhibition gave significantly improved results as expected, but the balance was still imperfect and many input digits failed to elicit any output spikes due to signal propagation failure (Fig 4b). However, with the addition of plasticity to the inhibition the network achieved excellent balance, and each feature neuron learned to respond to a different digit or in some cases superimposed combinations of several similar digits (Fig 4c). Those digits that were made up of the fewest pixels (i.e. the smallest inputs, such as \u20181\u2019) were wellrepresented only by this network. The plastic inhibition learned to approximate the negation of the excitatory connections (Extended Fig S4). The specific characteristics of the excitatory features that were learned were strongly influenced by the target firing rate of each feature neuron (Fig 5a, b and Extended Fig S5). For this reason, a distribution of firing rates across the neurons in the feature layer allowed the network to reliably capture a broad range of features that occurred with different frequencies in the input.\nWe tested many networks with different numbers of neurons in the feature and output layers, and different connection sparsities (Extended Fig S6 and S7). We found that using spatially localized receptive fields with plastic balancing inhibition and a range of firing rates for the feature neurons gave optimum performance (Fig 5c and Extended Fig S8). Results are summarized in Fig 5 (d and e). Previous best performance on MNIST using an unsupervised shallow SNN was 95.0% accuracy on the test set [38]. Using spike forcing of the output layer (i.e. a spiking readout of the features in the feature layer \u2013 see Methods) we achieved 96.0% accuracy using either 12996 feature neurons with 800 output neurons, or 6400 feature neurons with 1600 outputs (Fig 5d). Additionally, using a simple linear decoder on the feature layer with 12996 neurons we achieved an astounding 97.69% accuracy. For comparison, a shallow ANN trained with GD using a three-layer architecture (784\u2013128\u201310 units) achieves 97.6% accuracy after 5 epochs and 98.0% after 50 epochs. Adding units to the feature or output layers of the ANN does not improve performance. Recently an SNN trained with GD reached 97.2% after 40-50 epochs [39]. Our STUNN compares favourably to both, with 97.7% accuracy after only 1 epoch (continued training results in little or no further improvement).\nIV. DISCUSSION\nThe problem of signal propagation failure in feedforward SNNs is ubiquitous across all spiking neuron models as well as in real neural networks in the brain. The issue is rarely recognized in ML research using SNNs, and to the best of our knowledge its root cause has not been formally identified. We have shown analytically that the problem is caused by the nonlinear rectified neural gain function (see Appendix), and shown numerically that it severely impacts the ability of spikes to propagate reliably through even a very small number of neural layers. The solutions we have presented provide a list of\nprinciples for reliable signal propagation and for facilitating robust feature extraction in SNNs:\n1. Balancing inhibition compensates for the\nnonlinearities in the neural gain function.\n2. Inhibitory plasticity compensates for non-uniform\ninput statistics.\n3. Constant input prevents random-walk dynamics from\nhitting zero (i.e. from \u201cfalling off the edge\u201d)\n4. Firing rate distribution prevents spike correlations\ncaused by over-synchronization.\nAll these principles have their roots in neuroscience. While balancing inhibition has been used in ML applications before [29, 30, 37], we have shown that all four mechanisms are required to maintain near-perfect signal propagation. The cortex of the brain is known to operate in a state of dynamic balance between excitation and inhibition, and learning is known to engage inhibitory plasticity to maintain the balance. Cortical neurons also receive constant input from the brainstem (via the thalamus), the magnitude of which controls the dynamic cortical state and without which the cortex shuts down. Finally, cortical neurons display a broad range of firing rates. It is reasonable to propose that the brain uses these mechanisms for purposes similar to those shown here: for maintaining dynamical stability so that signals propagate reliably, and for improving functional computational outcomes such as feature extraction and logic calculations. While it may seem selfevident that improving the network dynamics will also improve computational function, the effectiveness of firing rate distributions for matching input feature frequencies, and of constant inputs for learning nonlinear logic functions, was unexpected. Note that perfect balance implies that firing rates from one layer to the next are uncorrelated, which would render spike rate coding inoperative, contrary to the temporal coding used here. Note also that perfect balance may not always be desirable; slight imperfections can potentially be used to route information through different neural circuits (Extended Fig S3).\nThe demonstration of unsupervised spike-time learning of logic problems including NOT and XOR, using minimal networks and minimal numbers of spikes, means that unsupervised learning in general, and STUNNs in particular, are applicable to a whole new class of problems. We showed how STUNNs can learn to solve logic functions of two inputs. For more than two inputs, there is clearly an explosion in the number of possible input combinations (2n), but this is offset by the exponential explosion in the number of possible combinations of learned feature representations and their logical complements (i.e. NOT(feature)). These combinatorial codes are possible with the sparse temporal codes used in this work but are not supported by the dense rate codes used elsewhere [28], unless networks are pre-wired into clusters [29] or otherwise hand-tuned [27]. However, the generalization of XOR to bitstrings of arbitrary length is called the bit parity problem, and while there is a simple procedure to calculate it sequentially, how to learn a general solution is still a topic of\nMAKING A SPIKING NET WORK: ROBUST BRAIN-LIKE UNSUPERVISED MACHINE LEARNING\nactive research [14]; even supervised learning cannot currently solve bit parity for arbitrary length strings.\nThe brain contains many neurons that hold conjunctive representations [40], and even bees have the ability to represent zero or the absence of a stimulus [41], although it has been unclear how. STUNNs with constant input to each feature neuron develop a specific, unique and identifiable feature-layer representation of an empty input layer, which helps explain how this feat could be accomplished by neural circuits (Extended Fig S9). Note that constant input was not used in the MNIST network since many MNIST pixels around the edges of the digits are always off, meaning that those feature neurons that developed representations to these blank regions were not helpful for identifying digits and were essentially wasted (Extended Fig S9). While the network outputs easily learned to ignore those specific neurons, overall performance suffered slightly due to there being effectively fewer useful feature neurons that actually represented the digits.\nAn important concept in STUNNs ties together the closely related ideas of 1. sparse excitatory and inhibitory connections contributing to transient departures from perfect balance; 2. a distribution of properties like firing rates and constant inputs to each neuron and; 3. the subsampling of the input space that is a consequence of the previous two ideas. Balance must be perfect or nearly so on average, but it is also important that it is imperfect for any given input in order for some neurons to fire while others are suppressed. Similarly, there should be a good chance of a neuron with a given target firing rate connecting to a certain subset of inputs for detecting a feature of matching frequency on those inputs. Likewise, neurons with a constant input need to receive stronger inhibitory than excitatory input from a feature or features in order to calculate NOT(feature/s). Sparse connections, a distribution of neuron properties, and a large number of feature neurons, are instrumental in ensuring that all this can occur. This is what we see in the brain and, fortuitously, this distribution of properties is perfect for implementation in cheap neuromorphic hardware because elements do not need to be constructed to be exactly alike with high precision. Instead, natural variations in hardware characteristics can be exploited in service of the learning algorithms [42, 43].\nSTUNNs, and unsupervised learning in general, need to discover all the available correlations/features in the data, because with no objective function gradient to follow there is no indication of which features will be required to solve any given problem. In contrast, DNNs will only develop representations of features that are useful for the given problem (i.e. that follow the gradient). For this reason, STUNNs need to be larger than DNNs for solving comparable tasks, at least during training. However this need not be a disadvantage:\n\u2022 First, since learning is local and representations are\nsparse, training speed is limited only by how long it takes to get a good sample of the input distribution, and not by global dependencies. Training is therefore lean and fast.\n\u2022 Second, STUNNs can potentially be pruned after\ntraining to retain only those features that are most useful for the final readout layer (if one is needed) or that have strong connections to downstream processing stages.\n\u2022 Third, labels are never required for training, only for\nthe final readout, so training data is usually easy and economical to collect.\n\u2022 Fourth, STUNNs can be re-tasked simply by retraining\nor recalculating the output layer, in contrast to DNNs. This capability should allow for near-flawless transfer learning, which we will investigate in future work.\n\u2022 Fifth, STUNNs generate intuitive, explainable, parts-\nbased features, somewhat akin to non-negative sparse codes [16], unlike DNNs for which features and decision boundaries are often counter-intuitive [44] rendering them difficult to interpret and prone to subtle and difficult-to-detect adversarial attacks. We leave detailed investigation of this characteristic of STUNNs for future work.\nIt should be clear that STUNNs are more suitable for learning scenarios where conventional GD for DNNs is limited by power, computational resource usage, training time, data collection and/or labeling requirements, lack of explainability or lack of transferability. While GD can lead to superhuman performance on certain well-constrained tasks for which a single objective can be explicitly defined, supervised methods are often brittle and highly dependent on the training dataset. For more general and difficult-to-define learning scenarios encompassing most real-world tasks, unsupervised learning will likely prove to be more generally useful. STUNNs use unsupervised local learning to swiftly build a complete, efficient dictionary of the input space, making them the best architecture to date for performing rapid, low-power machine learning using unlabeled data.\nREFERENCES\n[1] K. Roy, A. Jaiswal, and P. Panda, \"Towards spike-\nbased machine intelligence with neuromorphic computing,\" Nature, vol. 575, no. 7784, pp. 607-617, 2019.\n[2] Y. LeCun, Y. Bengio, and G. Hinton, \"Deep learning,\"\nNature, vol. 521, no. 7553, pp. 436-444, 2015.\n[3] J. Lemley, S. Bazrafkan, and P. Corcoran, \"Deep\nLearning for Consumer Devices and Services: Pushing the limits for machine learning, artificial intelligence, and computer vision,\" IEEE Consumer Electronics Magazine, vol. 6, no. 2, pp. 48-56, 2017.\n[4] N. C. Thompson, K. Greenewald, K. Lee, and G. F.\nManso, \"The computational limits of deep learning,\" arXiv:2007.05558, 2020.\n[5] J. Zhao, R. Mortier, J. Crowcroft, and L. Wang,\n\"Privacy-preserving machine learning based data analytics on edge devices,\" presented at the Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society, 2018.\nMAKING A SPIKING NET WORK: ROBUST BRAIN-LIKE UNSUPERVISED MACHINE LEARNING\n[6] W. Y. B. Lim et al., \"Federated learning in mobile\nedge networks: A comprehensive survey,\" IEEE Communications Surveys, vol. 22, no. 3, pp. 2031- 2063, 2020.\n[7] J. Park, S. Samarakoon, M. Bennis, and M. Debbah,\n\"Wireless network intelligence at the edge,\" Proceedings of the IEEE, vol. 107, no. 11, pp. 2204- 2239, 2019.\n[8] T. Masquelier, R. Guyonneau, and S. J. Thorpe,\n\"Competitive STDP-based spike pattern learning,\" Neural Computation, vol. 21, no. 5, pp. 1259-1276, 2009.\n[9] A. J. Watt and N. S. Desai, \"Homeostatic plasticity and\nSTDP: keeping a neuron's cool in a fluctuating world,\" Frontiers in Synaptic Neuroscience, vol. 2, p. 5, 2010.\n[10] Y. LeCun, \"Deep learning hardware: past, present, and\nfuture,\" in 2019 IEEE International Solid-State Circuits Conference-(ISSCC), 2019, pp. 12-19: IEEE.\n[11] Z. F. Mainen and T. J. Sejnowski, \"Reliability of spike\ntiming in neocortical neurons,\" Science, vol. 268, no. 5216, pp. 1503-1506, 1995.\n[12] W. Singer, \"Time as coding space?,\" Current Opinion\nin Neurobiology, vol. 9, no. 2, pp. 189-194, 1999.\n[13] R. VanRullen, R. Guyonneau, and S. J. Thorpe, \"Spike\ntimes make sense,\" Trends in Neurosciences, vol. 28, no. 1, pp. 1-4, 2005.\n[14] E. M. Izhikevich, \"Polychronization: computation\nwith spikes,\" Neural Computation, vol. 18, no. 2, pp. 245-282, 2006.\n[15] R. Brette, \"Philosophy of the spike: rate-based vs.\nspike-based theories of the brain,\" Frontiers in Systems Neuroscience, p. 151, 2015.\n[16] P. O. Hoyer, \"Non-negative sparse coding,\" in\nProceedings of the 12th IEEE Workshop on Neural Networks for Signal Processing: IEEE, 2002, pp. 557- 565.\n[17] B. A. Olshausen and D. J. Field, \"Emergence of\nsimple-cell receptive field properties by learning a sparse code for natural images,\" Nature, vol. 381, no. 6583, pp. 607-609, 1996.\n[18] A. J. Bell and T. J. Sejnowski, \"The \u201cindependent\ncomponents\u201d of natural scenes are edge filters,\" Vision Research, vol. 37, no. 23, pp. 3327-3338, 1997.\n[19] R. Baddeley et al., \"Responses of neurons in primary\nand inferior temporal visual cortices to natural scenes,\" Proceedings of the Royal Society of London. Series B: Biological Sciences, vol. 264, no. 1389, pp. 1775-1783, 1997.\n[20] P. T. P. Tang, T.-H. Lin, and M. Davies, \"Sparse\ncoding by spiking neural networks: Convergence theory and computational results,\" arXiv preprint arXiv:.05475, 2017.\n[21] S. Davidson and S. B. Furber, \"Comparison of\nartificial and spiking neural networks on digital hardware,\" Frontiers in Neuroscience, vol. 15, p. 345, 2021.\n[22] H. Hazan, D. J. Saunders, D. T. Sanghavi, H.\nSiegelmann, and R. Kozma, \"Lattice map spiking neural networks (LM-SNNs) for clustering and classifying image data,\" Annals of Mathematics and\nArtificial Intelligence, vol. 88, no. 11, pp. 1237-1260, 2020.\n[23] A. Tavanaei, M. Ghodrati, S. R. Kheradpisheh, T.\nMasquelier, and A. Maida, \"Deep learning in spiking neural networks,\" Neural Networks, vol. 111, pp. 47- 63, 2019.\n[24] M. Diesmann, M.-O. Gewaltig, and A. Aertsen,\n\"Stable propagation of synchronous spiking in cortical neural networks,\" Nature, vol. 402, no. 6761, pp. 529- 533, 1999.\n[25] V. Litvak, H. Sompolinsky, I. Segev, and M. Abeles,\n\"On the transmission of rate code in long feedforward networks with excitatory\u2013inhibitory balance,\" Journal of Neuroscience, vol. 23, no. 7, pp. 3006-3015, 2003.\n[26] A. Kumar, S. Rotter, and A. Aertsen, \"Spiking activity\npropagation in neuronal networks: reconciling different perspectives on neural coding,\" Nature Reviews Neuroscience, vol. 11, no. 9, pp. 615-627, 2010.\n[27] T. P. Vogels and L. F. Abbott, \"Signal propagation and\nlogic gating in networks of integrate-and-fire neurons,\" Journal of Neuroscience, vol. 25, no. 46, pp. 10786-10795, 2005.\n[28] H. S. Seung, \"Learning in spiking neural networks by\nreinforcement of stochastic synaptic transmission,\" Neuron, vol. 40, no. 6, pp. 1063-1073, 2003.\n[29] P. Weidel, R. Duarte, and A. Morrison, \"Unsupervised\nlearning and clustered connectivity enhance reinforcement learning in spiking neural networks,\" Frontiers in Computational Neuroscience, vol. 15, p. 18, 2021.\n[30] A. Lazar, G. Pipa, and J. Triesch, \"SORN: a self-\norganizing recurrent neural network,\" Frontiers in Computational Neuroscience, vol. 3, p. 23, 2009.\n[31] P. Zheng, C. Dimitrakakis, and J. Triesch, \"Network\nself-organization explains the statistics and dynamics of synaptic connection strengths in cortex,\" PLoS Computational Biology, vol. 9, no. 1, p. e1002848, 2013.\n[32] P. Fries, D. Nikoli\u0107, and W. Singer, \"The gamma\ncycle,\" Trends in Neurosciences, vol. 30, no. 7, pp. 309-316, 2007.\n[33] J. H. Lee, T. Delbruck, and M. Pfeiffer, \"Training deep\nspiking neural networks using backpropagation,\" Frontiers in Neuroscience, vol. 10, p. 508, 2016.\n[34] C. van Vreeswijk and H. Sompolinsky, \"Chaotic\nbalanced state in a model of cortical circuits,\" Neural Computation, vol. 10, no. 6, pp. 1321-1371, 1998.\n[35] G. Hennequin, E. J. Agnes, and T. P. Vogels,\n\"Inhibitory plasticity: balance, control, and codependence,\" Annual Review of Neuroscience, vol. 40, pp. 557-579, 2017.\n[36] P. Stratton and J. Wiles, \"Global segregation of\ncortical activity and metastable dynamics,\" Frontiers in Systems Neuroscience, vol. 9, 2015.\n[37] W. Maass, T. Natschl\u00e4ger, and H. Markram, \"Real-\ntime computing without stable states: A new framework for neural computation based on perturbations,\" Neural Computation, vol. 14, no. 11, pp. 2531-2560, 2002.\nMAKING A SPIKING NET WORK: ROBUST BRAIN-LIKE UNSUPERVISED MACHINE LEARNING\n[38] P. U. Diehl and M. Cook, \"Unsupervised learning of\ndigit recognition using spike-timing-dependent plasticity,\" Frontiers in Computational Neuroscience, vol. 9, p. 99, 2015.\n[39] J. G\u00f6ltz et al., \"Fast and energy-efficient\nneuromorphic deep learning with first-spike times,\" Nature Machine Intelligence, vol. 3, no. 9, pp. 823- 835, 2021.\n[40] R. C. O'Reilly and J. W. Rudy, \"Conjunctive\nrepresentations in learning and memory: principles of cortical and hippocampal function,\" Psychological Review, vol. 108, no. 2, p. 311, 2001.\n[41] S. R. Howard, A. Avargu\u00e8s-Weber, J. E. Garcia, A. D.\nGreentree, and A. G. Dyer, \"Numerical ordering of zero in honey bees,\" Science, vol. 360, no. 6393, pp. 1124-1126, 2018.\n[42] T. J. Hamilton, S. Afshar, A. van Schaik, and J.\nTapson, \"Stochastic electronics: A neuro-inspired design paradigm for integrated circuits,\" Proceedings of the IEEE, vol. 102, no. 5, pp. 843-859, 2014.\n[43] L. G. Wright et al., \"Deep physical neural networks\ntrained with backpropagation,\" Nature, vol. 601, no. 7894, pp. 549-555, 2022.\n[44] I. J. Goodfellow, J. Shlens, and C. Szegedy,\n\"Explaining and harnessing adversarial examples,\" arXiv preprint arXiv:1412.6572, 2014.\nPeter G. Stratton Queensland University of Technology, Australia. https://orcid.org/0000-0002-3312-7505\nPeter Stratton received his PhD in computer science and neural networks from The University of Queensland, Australia in 2002. He is currently an\nAssociate Professor in the School of Electrical Engineering and Robotics at the Queensland University of Technology, Brisbane, Australia, and a Principal Research Fellow in neuromorphic engineering. He was previously a Research Fellow in neuromorphic algorithms at the University of Technology Sydney. His neuroscience background comes from nearly 10 years at the Queensland Brain Institute. His primary research interest is to understand the computational principles that are implemented by nervous systems, and to apply these to complex engineering problems in information processing and robotics.\nAndrew Wabnitz, Defence Science and Technology Group. https://orcid.org/0000-0002-2038-4174\nAndrew Wabnitz received the B.E. (Hons) degree in electrical engineering from the University of Adelaide, Australia, in 2005, and the Ph.D. degree\nfrom the University of Sydney, Australia, in 2013. Andrew has\nover 10 years experience across industry, academia and defence working on projects involving embedded system design, software development and FPGA design for applications in biomedical devices, cyber security and space. He is currently a senior researcher of Cognitive Technologies in the Defence Science and Technology Group, Department of Defence, Australia. His primary research interests include neuromorphic computing, bio-inspired algorithm design, and the application of this technology to real-world problems.\nChip Essam, photograph and biography not available at the time of publication. https://orcid.org/0000-0003-4091-5304\nAllen Cheung, photograph and biography not available at the time of publication. https://orcid.org/0000-0001-9770-217X\nTara J. Hamilton (Member, IEEE) Cuvos Pty. Ltd. https://orcid.org/0000-0003-2630-7011\nTara Julia Hamilton is currently the Principal Scientist at Cuvos and an Adjunct Associate Professor at the University of Technology Sydney (UTS). Her research interests include: analog and mixed-signal integrated circuit design, neuromorphic systems, and bio-inspired machine learning. Tara is the author of over 120 research papers and 3 international patents. Tara works with leading health, defence, and technology companies and she is focused on developing innovative solutions to real-world problems.\nAppendix\nFig A1 shows a schematic diagram for recording a neuron's membrane potential.\nFig A1: Schematic diagram illustrating hypothetical membrane potential recording from an output neuron in a feed-forward spiking neural network model."
        },
        {
            "heading": "1. RC circuit model of a leaky integrate-and-fire (LIF) neuron",
            "text": "Fig A2: RC circuit model of the neuronal membrane.\nBased on the equivalent RC circuit model of the neuronal membrane (Fig A2), the governing equation for membrane potential dynamics is\n\u03c4m dV (t) dt =\u2212(V (t)\u2212V rest)+RI (t ) (1)\nwhere \u03c4m=RC is the membrane time constant, R is the electrical resistance of the membrane, C is the charge capacitance of the membrane, V (t) is the membrane potential at time t, V rest is the resting membrane potential, and I ( t) is the total current passing across the membrane at time t.\nVInput neurons\nOutput neuron"
        },
        {
            "heading": "2. Average current is proportional to input frequency",
            "text": "For a regular input spike train of frequency \u03bb in=1/\u0394t , we can compute the average input current.\nConsider a general synaptic current arising from one input spike:\nI1(t )=\u2211 j a j t k e\u2212t / \u03c4 j (2)\nwhere a j is a constant which weights the gamma distribution component with time constant \u03c4 j , and k\u22650 . The synaptic current model described by (2) generalizes commonly used examples from the SNN literature. For example, if k=0 , a1=I 0 and a2=\u2212I0 then the current profile for a single input spike occurring at t = 0 is given by I1(t )=I 0(e\n\u2212t / \u03c41 \u2013e\u2212t / \u03c42) (REF). Another example is k=1 and a=we /\u03c4 in which case I1(t )=(wt / \u03c4)e 1\u2212t / \u03c4 (NEST appendix, Jordan et al).\nSuppose the most recent spike of a regular input train occurred at t = 0. To find the average total current between t = 0 and t = \u0394t , it is necessary to sum the contributions from all previous spikes. Assuming linear summation of successive currents, the steady state average current is\nI\u221e= 1 \u0394t\u222b0\n\u0394t\nI\u221e(t)dt\n= 1 \u0394t\u222b0\n\u0394t\n(\u2211j=0 \u221e\nI1(t+j\u0394t ))dt =\u03bb in\u222b\n0\n\u221e\nI1(t )dt\n=\u03bb in\u222b 0\n\u221e\n[\u2211j a j t k e\u2212t / \u03c4 j]dt\n=\u03bb in\u2211 j [\u2212a j \u03c4 jk+1\u0393(k+1 ,t / \u03c4 j) ]0\n\u221e\n(3)\nwhere \u03bb in is the input spike rate, and \u0393(\u03b1 ,\u03b2)=\u222b \u03b2\n\u221e\nt\u03b1\u22121 e\u2212tdt is the (upper) incomplete gamma\nfunction. Since \u0393(\u03b1 ,0)=\u0393(\u03b1) and \u0393(\u03b1 ,\u221e)=0 we can write (3) as\nI\u221e=\u03bbin\u2211 j [a j \u03c4 jk+1\u0393(k+1)] (4)\nHence the steady state mean input current I\u221e is proportional to the input frequency \u03bb in ."
        },
        {
            "heading": "3. Output frequency is a nonlinear function of input current",
            "text": "Suppose the input current is constant, i.e., I ( t)=I input , and V (0)=V after , then integrating both sides of (1) w.r.t. t gives\n\u03c4m \u222b V after\nV (\u0394t )\nd V (t)=\u222b 0\n\u0394t\n(\u2212(V ( t)\u2212V rest )+RI input)dt (5)\nand whose solution is\nV (t)=V after+(V rest\u2212V after+RI input) (1\u2212e \u2212t / \u03c4m ) (6)\nIf a spike occurs at threshold membrane potential V thr , then (6) can be solved by setting V (t)=V thr to yield a nonlinear relationship between input current Iinput and output spike frequency \u03bbout :\n\u0394t=\u2212\u03c4m ln(1\u2212 V thr\u2212V afterV rest\u2212V after+RI input)= 1\u03bbout (7) There is a minimum current required to reach threshold:\nImin= V thr\u2212V rest R\n(8)\nwhich means that the Iinput \u2192 \u03bbout relationship is not smooth (in addition to being nonlinear).\nThe spiking neuron model may include a constant absolute refractory period t r immediately after every output spike, whereby the membrane potential is clamped to V after . That is equivalent to a delay of exactly t r before the beginning of every depolarization phase. Hence the ISI is\n\u0394t=t r\u2212\u03c4m ln(1\u2212 V thr\u2212V afterV rest\u2212V after+RI input )= 1\u03bbout (9)"
        },
        {
            "heading": "4. Output spike frequency is a nonlinear function of input spike frequency",
            "text": "Next we apply asymptotic mean current approximation (AMCA) to model postsynaptic spike trains.\nThe effect of a regular train of input spikes on membrane potential can be approximated by their average current (Fig A3):\nFig A3: Modelling postsynaptic spike trains using the asymptotic mean current approximation (AMCA). Top left: Regular input spike times (red) lead to periodic synaptic currents (black) and a stable average current (cyan). Top right: Numerically integrated membrane potential (black) is similar to the mean-current-approximation (cyan). Bottom left: Output spike frequency vs input spike frequency, using AMCA, including (solid line) and excluding (dotted line) an absolute refractory period. The result from a numerical simulation with absolute refractory period (black dot) shows the match with AMCA.\nWe can then combine (4) and (9) to obtain a relationship between the input and output spike frequencies:\n\u03bbout={ 1 tr\u2212\u03c4m ln(1\u2212 V thr\u2212V afterV rest\u2212V after+R\u03bb in\u2211 j a j \u03c4 j k+1\u0393(k+1)) if \u03bb in>\u03bbmin\n0 otherwise\n(10)\nwhere the minimum input frequency is\n\u03bbmin= V thr\u2212V rest\nR\u2211 j a j \u03c4 j\nk+1\u0393(k+1) (11)"
        },
        {
            "heading": "5. Maximizing input ISI entropy preserves nonlinearity",
            "text": "In the preceding analysis, input spike trains were assumed to be regular and hence have zero interspike interval (ISI) entropy. This means that at subthreshold input frequencies, there is no possibility of output spiking activity. However, if there is ISI variability, then it may be possible that occasional bursts of input activity can still cause spiking in an output neuron. To determine whether this phenomenon can reduce or even eliminate the nonlinearity between input and output frequencies, we repeat the earlier analysis assuming maximal ISI entropy, which is a Poisson spike train.\nSteady state synaptic current mean and variance for a Poisson input train\nUsing the synaptic current model of (2), the instantaneous mean current is, i.e.,\nET=E(lim\u0394t\u21920 1\u0394t\u222b0 \u0394t I\u221e(t)dt) = lim\n\u0394t\u21920 \u2211 j=0\n\u221e P(spike)( 1\u0394t\u222b0 \u0394t I 1(t+j\u0394t)dt) =\u03bbin\u222b\n0\n\u221e\nI 1(t)dt\n=\u03bbin\u2211 j [a j \u03c4 jk+1\u0393(k+1)]\n(12)\nwhere P(spike)=\u03bb in\u0394t is the probability of an input spike occurring in any time interval \u0394t . Note that ET denotes the steady state expected current for Poisson input trains, whereas I\u221e was used earlier to denote the steady state current averaged over a single interspike interval (ISI) of duration \u0394t=1/\u03bb in . While I\u221e (t) is a fixed current profile for regular input trains, it varies for Poisson input trains. Hence ET and I\u221e are derived differently, but yield identical results, i.e., ET=I\u221e .\nThe instantaneous variance of the synaptic current can be derived in a similar way:\nV T=V (lim\u0394 t\u21920 1\u0394t\u222b0 \u0394t I\u221e (t)dt) =\u03bb in\u222b\n0\n\u221e\n[\u2211j a j t k e\u2212t / \u03c4 j]\n2 d t\n=\u03bb in\u222b 0 \u221e (\u2211i \u2211j aia j t2k e \u2212t ( 1\u03c4 i+1\u03c4 j ))dt =\u03bb in[\u2211i \u2211j a ia j\u2212(1\u03c4i+1\u03c4 j )2k+1 \u0393(2k+1 ,t (1\u03c4i+1\u03c4 j ))]0 \u221e\n=\u03bb in\u2211 i \u2211 j\naia j\n(1\u03c4 i+1\u03c4 j ) 2k+1 \u0393(2k+1)\n(13)\nExample 1: if I1(t )=I 0(e \u2212t / \u03c41 \u2013e\u2212t / \u03c42) then k=0 , a1=I 0 and a2=\u2212I0 so (12) reduces to\nET=\u03bb in I 0 (\u03c41\u2212\u03c42 ) (14)\nand (13) reduces to\nV T=\u03bb in I 0 2 (\u03c41\u2212\u03c42)\n2\n2(\u03c41+\u03c42) (15)\nExample 2: if I1(t )=w t \u03c4 e 1\u2212t / \u03c4 , then k=1 and a=we /\u03c4 so (12) reduces to\nET=\u03bb inwe \u03c4 (16)\nand (13) reduces to\nV T=\u03bb in w2e2 \u03c4\n4 (17)\nCurrent and spike frequency distributions\nSince mean currents are strictly non-negative, we approximate the distribution as a truncated Gaussian. If the underlying parameters of the untruncated Gaussian are \u03bc and \u03c3,\npdf ( I ;\u03bc ,\u03c3)\u2248{1\u03c3 \u03d5( I\u2212\u03bc\u03c3 )1\u2212\u03a6 (\u2212\u03bc\u03c3 ) I\u22650 0 otherwise\n(18)\nwhere \u03d5(z)=e\u2212z 2/2/\u221a2\u03c0 and \u03a6( z)= 1\u221a2\u03c0 \u222b\u2212\u221e\nz\ne\u2212 z 2/2dz=1\n2 (1+erf (z /\u221a2)) . The average output\nfrequency is\n\u03bbout=\u222b pdf ( I ;\u03bc ,\u03c3)\u03bbout (I)d I (19)\nwhere\n\u03bbout (I )= 1\nt r\u2212\u03c4m ln(1\u2212 V thr\u2212V afterV rest\u2212V after+R I ) (20) To compute \u03bbout it is necessary to find the parameters of the truncated Gaussian, \u03bc and \u03c3 , across all \u03bb in . Since both ET and V T were shown earlier to be directly proportional to \u03bb in (see (12) and (13)), it is possible to empirically fit \u03bc and \u03c3 to yield the best match for each ET and V T . A more succinct alternative method is to use the inverse coefficient of variation.\nUsing the inverse coefficient of variation\nLet \u03b3=\u03bc/\u03c3 be the inverse of the coefficient of variation of the untruncated Gaussian. For all \u03bb in>\u03bb c , \u03bc and \u03c3 can be computed from \u03b3 , and hence \u03bbout can be found according to (19). The minimum \u03bbc can be found as follows.\nUsing the Poincar\u00e9 series of erfc() we can write\n1 2 erfc( x\u221a2)= e\n\u2212x2 /2\nx\u221a2\u03c0\u2211j=0 \u221e (\u22121) j (2 j\u22121)! ! x2 j\n(21)\nwhich, due to higher order terms vanishing, can be used to show that\nlim \u03b3\u2192\u2212\u221e\n(\u2212\u03b3\u22121\u03b3 )(1\u2212\u03a6(\u2212\u03b3))=\u03d5(\u2212\u03b3) (22)\nThis implies that V T=ET 2 . The cutoff frequency is thus\n\u03bbc=\n\u2211 i \u2211 j\nai a j\n(1\u03c4 i+1\u03c4 j ) 2k+1 \u0393(2k+1)\n\u2211 i \u2211 j ai a j \u03c4 i k+1 \u03c4 j k+1\u03932(k+1)\n(23)\nThis is the minimum input frequency which can be computed by using the parameter \u03b3 , corresponding to the limit as \u03b3=\u03bc/\u03c3\u2192\u2212\u221e .\nFor I1(t )=I 0(e \u2212t / \u03c41 \u2013e\u2212t / \u03c42) (23) reduces to\n\u03bbc= 1\n2(\u03c41+\u03c42) (24)\nFor I1(t )=w t \u03c4 e 1\u2212t / \u03c4 (23) reduces to\n\u03bbc= 1\n4 \u03c4 (25)\nBelow \u03bbc , \u03b3min is a constant computed by fitting (\u03bc ,\u03c3) to (ET ,V T) corresponding to \u03bbc .\nExamples of input-output frequency functions\nExample 1) Piecewise construction of input-output frequency function for Poisson input trains using I1(t )=I 0(e \u2212t / \u03c41 \u2013e\u2212t / \u03c42) (Fig A4):\n1) Low input frequencies: parameterized by input frequency 0<\u03bbin\u2264\u03bb c= 1\n2(\u03c41+\u03c42)\n\u03bamin= \u03d5(\u2212\u03b3min)\n1\u2212\u03a6(\u2212\u03b3min)\nV T=\u03bb in I 0 2 ( \u03c41\u2212\u03c42)\n2\n2(\u03c41+\u03c42) ET=\u03bbin I 0(\u03c41\u2212\u03c42)\n\u03c3=\u221a V T1\u2212\u03bamin(\u03bamin+\u03b3min) \u03bc=ET\u2212\u03bamin\u03c3\n(26)\n2) High input frequencies: parameterized by \u03b3=\u03bc/\u03c3\u2265\u03b3min\n\u03ba= \u03d5(\u2212\u03b3) 1\u2212\u03a6(\u2212\u03b3)\n\u03bb in= (\u03ba+\u03b3)2\n2(1\u2212\u03ba(\u03ba+\u03b3))(\u03c41+\u03c42) ET=\u03bb in I 0(\u03c41\u2212\u03c42)\n\u03c3= ET \u03ba+\u03b3\n\u03bc=ET\u2212\u03ba\u03c3\n(27)\n3) Linear interpolation between (1) and (2)\nNB: (18) and (19) are used for numerical integration in (1) and (2) to yield mean output frequency.\nFig A4: Piecewise construction of input-output frequency function for Poisson input trains. Left: Using \u03bbc , the corresponding ET and V T are computed, and the corresponding \u03bc and \u03c3 are fitted, giving \u03b3min . Below \u03bbc , treat \u03b3min and k as constants. Black lines: regular input trains (minimum ISI entropy) either with (solid) or without (dotted) absolute refractory period. Blue dots: SNN simulation results. Cyan line: mathematical model results. Model parameters: I0 = 100pA, \u03c41 = 10ms, \u03c42 = 2ms, \u03c4m = 16ms, tr = 2ms, R = 400M\u03a9, Vrest = -70mV, Vafter = -90mV, Vthr = -50mV. Right: As for Left but with different model parameters (I0 = 30pA, \u03c41 = 20ms, \u03c42 = 2ms, \u03c4m = 10ms, tr = 2ms, R = 800M\u03a9, Vrest = -70mV, Vafter = -90mV, Vthr = -55mV).\nExample 2) Piecewise construction of input-output frequency function for Poisson input trains using\nI1(t )=w t \u03c4 e 1\u2212t / \u03c4 :\n1) Low input frequencies: parameterized by input frequency 0<\u03bb\u2264\u03bbc= 1\n4 \u03c4\n\u03bamin= \u03d5(\u2212\u03b3min)\n1\u2212\u03a6(\u2212\u03b3min)\nV T= \u03bb inw 2 e2 \u03c4 4\nET=\u03bb inw e \u03c4\n\u03c3=\u221a V T1\u2212\u03bamin(\u03bamin+\u03b3min) \u03bc=ET\u2212\u03bamin\u03c3\n(28)\n2) High input frequencies: parameterized by \u03b3=\u03bc/\u03c3\u2265\u03b3min\n\u03ba= \u03d5(\u2212\u03b3) 1\u2212\u03a6(\u2212\u03b3)\n\u03bb in= (\u03ba+\u03b3)2\n4 \u03c4 (1\u2212\u03ba(\u03ba+\u03b3)) ET=\u03bb inw e \u03c4\n\u03c3= ET \u03ba+\u03b3\n\u03bc=ET\u2212\u03ba\u03c3\n(29)\n3) Linear interpolation between (1) and (2).\nNB: (18) and (19) are used for numerical integration in (1) and (2) to yield mean output frequency.\nFig A5: Piecewise construction of input-output frequency function for Poisson input trains. Left: As for Fig A4 using the NEST synaptic model. Model parameters: w = 100pA, \u03c4 = 10ms, \u03c4m = 16ms, tr = 2ms, R = 200M\u03a9, Vrest = -70mV, Vafter = -90mV, Vthr = -50mV. Right: NEST synaptic model with\ndifferent parameter values (w = 25pA, \u03c4 = 12ms, \u03c4m = 16ms, tr = 2ms, R = 450M\u03a9, Vrest = -70mV, Vafter = -90mV, Vthr = -50mV)."
        },
        {
            "heading": "6. Concurrent signal propagation failure and avalanche",
            "text": "At low network gains (Fig 1d), spikes eventually vanish when propagated through multiple layers, ultimately leading to total signal propagation failure. In contrast, when network gains are high, sparse input patterns vanish while dense input patterns avalanche, the latter causing saturated activity. In the case of variable input rates, such as random patterns, it is possible for both failure and avalanche to occur at different times within the same set of neurons (Fig 2a). We now consider the case when network gain is sufficiently high to prevent total signal propagation failure, while mean firing rates are capped to prevent constant saturated activity.\nSection 4 (minimum ISI entropy) and Section 5 (maximum ISI entropy) showed that the inputoutput frequency function is nonlinear. In all cases, \u03bbout :\u03bb in ratio was lowest for low frequencies. In the case of regular input trains, there was a threshold below which transmission failed immediately. For Poisson input trains, there was a reduction in the frequency, which, if propagated forward, would lead to eventual failure. So assuming that overall firing rates did not increase significantly across layers in a feedforward network (e.g., using ITP), low firing rates tend to produce even lower firing rates in successive layers, until signal propagation failure occurs.\nThe converse of the above phenomenon is that high frequency inputs are propagated. In the case of multiple input neurons, the highest possible input spike rates occur via temporal synchronization across multiple input neurons because there is no limit from the refractory period. Clearly, even random spike trains will occasionally synchronize by chance. However, if those high frequency input bursts are transmitted preferentially over the lower frequency asynchronous spikes, then multiple feedforward layers in a neural network will tend to propagate temporally correlated activity, even if they are spurious correlations.\nConsider a neuron in a feedforward neural network with 784 inputs (MNIST input size). Suppose the inputs are independent Poisson noise, each with an average spike rate of \u03bb0. The total average input spike rate is thus 784\u03bb0. In the time period for which \u03bb0 was computed, the probability that any single input neuron reaching some threshold number of spikes, nthr , is\nPr (n\u2265nthr|1 input )=\u2211 j=nthr\n\u221e e\u2212\u03bb 0\u03bb0 j\nj ! (30)\nIn contrast, the probability that the total input from all 784 input neurons reaches the same threshold is\nPr (n\u2265nthr|784 inputs)=\u2211 j=nthr\n\u221e e\u2212784 \u03bb0(784\u03bb0) j\nj ! (31)\nSince these are independent random spike trains, then any temporal alignment can be considered a spurious correlation. Threshold is reached far more frequently through spurious correlations between neurons than bursts of activity in any single neuron. For instance, if nthr=5 in a given time period at \u03bb0=0.02 , there are 4.9\u00d710\n7 -fold more postsynaptic spikes due to spurious correlations than bursts of activity from the 784 input neurons individually.\nThe combined effect of transmission failure at low input frequencies and bias towards spurious correlations at high input frequencies leads to the signal propagation failure-and-avalanche phenomenon described in the text and illustrated in Fig 2a.\nExtended Data\nExt Fig S1: The symptoms of spike propagation failure in a leaky integrate and fire (LIF) neuron model with network\ngain = 1. The blue population of input neurons (top panel) all fire randomly at a fixed rate (Poisson spike distribution).\nEach neuron from the orange output population randomly samples from 10% of these input neurons with uniformly\ndistributed connection weights from 0 to a maximum value, where the maximum is tuned to cause identical absolute\nchanges in firing rate in the outputs as in the inputs. The output rate tracks changes in the input rate (lower left panel),\nbut with reduced average firing rate. Plotting the input firing rate against the output firing rate (lower right panel)\nconfirms that this effect is analogous to the non-zero threshold of a single neuron.\nExt Fig S2: The symptoms of spike propagation failure in a leaky integrate and fire (LIF) neuron model with network\ngain > 1. The blue population of input neurons all fire randomly at a fixed rate (Poisson spike distribution). Each\nneuron from the orange output population randomly samples from 10% of these input neurons with uniformly\ndistributed connection weights from 0 to a maximum value, where the maximum is tuned to cause identical average\nfiring rate in the outputs as the inputs. Nevertheless, deviations from Poisson firing are clear in the orange output\npopulation. In particular, output population bursts occur when the input population rate is randomly higher, and pauses\nin output occur when the input population rate is randomly lower. This can be seen more clearly in the plot of\npopulation firing rates (lower left panel). The output tracks the input rate, but with magnified variability. Plotting the\ninput firing rate against the output firing rate (lower right panel) shows that the slope is greater than 1 and the intercept\nis not at 0.\nExt Fig S3: Independent routing of information using the nonlinearity of the spike response. This network contains one\ninput layer (blue) and two output layers (orange and red). Each output layer was connected to a subpopulation of\nneurons from the input layer. The output layers responded independently, controlled by the number of active neurons\nto which they were connected in the input layer. In other words, information from the input layer was routed\nindependently based only on the patterns of activity in that layer and the afferent connections. This is a supralinear\nrouting, mimicking winner-take-all mechanisms which are known to be computationally powerful, except here it is\naccomplished with no additional mechanisms like oscillations or even inhibition. While the depicted routing occurs\nrandomly, it is easy to imagine that the routing could potentially be learned through a mechanism such as reward-\nmodulated STDP, where connections are strengthened when they cause activity patterns that lead to reward.\n(a) (b) (c)\nExt Fig S4: Plastic balancing inhibition learned an approximate negation of the excitatory connections. (a) Excitatory\nconnection weights. (b) Sparse plastic inhibitory connection weights. (c) Sum of (a) and (b) showing that the excitatory\ndigit features were closely balanced by learned inhibition. Inhibitory connection probability was increased to 0.5 for this\nnetwork to emphasise the balancing effect.\nExt Fig S5: Feature weights in an MNIST network with 196 feature neurons (Top) and 100 output neurons (10 output\nneurons per digit - Bottom). The feature neurons are sorted in order of ascending firing rate (Top panel \u2013 from top left,\nacross then down; Bottom panel \u2013 from top to bottom). Output neurons are sorted on output digit (Bottom panel \u2013 from\nleft to right; i.e. digit 0 is output neurons 0-9, digit 1 is output neurons 10-19 etc.). As can be seen in both panels, 0\u2019s\ntend to be represented by neurons with mid to high firing rates while 1\u2019s are represented by neurons with low to mid\nfiring rates. This occurs because most 0\u2019s are similar and therefore appear often, causing neurons with high firing\nrates to attach to those features. Conversely, 1\u2019s are drawn with a wide distribution of orientations, meaning that any\ngiven orientation appears only rarely, causing neurons with low firing rates to attach to those features. Most other\ndigits are also biased towards a given firing rate range (e.g. 2\u2019s and 3\u2019s use mostly higher firing rates; 4\u2019s mostly lower;\netc.).\nExt Fig S6: Parameter sweeps across connection probabilities from the MNIST input layer to the feature layer show a\nsweet spot using sparse connectivity for both excitatory and inhibitory connections. Graphs show log error using a\nlinear decoder on the feature layer (lower values are better). Left panels: 100 feature neurons. Centre panels: 400\nfeature neurons. Right panels: 1600 feature neurons. Top row: Excitatory connection probability is varied while\nInhibitory is held constant (each curve is a constant inhibitory connectivity). Bottom row: Inhibitory connection\nprobability is varied while Excitatory is held constant. Solid black lines: mean performance. The dashed horizontal line\nat the top of each panel marks chance performance (10%), while the dashed line towards the bottom of each panel\nmarks the 95% correct level. Performance improves with increasing network size. For small networks, maximal\nexcitatory and minimal inhibitory connectivity appear to be optimal. However as network size increases a sweet spot emerges for connection probability around 2-6 = 0.016, meaning that each feature neuron receives on average 12\nexcitatory and 12 inhibitory connections from the input layer.\nExt Fig S7: The same information as the previous figure presented as heat maps; excitatory (Y axis) and inhibitory (X\naxis) connection probabilities vs log error. Yellow = high error; Blue = low error. On these log-log plots, the sweet spot\nat (-6,-6) that was identified above is clear for the 400 neuron network (centre panel) and the 1600 (right panel). The\ngeneral conclusions that can be drawn are that:\n\u25cf An exceptionally broad range of excitatory connectivity from 2-6 to 20 (0.016 to 1.0) gives good performance as\nlong as inhibitory connectivity is within a certain range.\n\u25cf There is a sparsity limit below which excitatory connections are too sparse to find all the correlations or hold\nall the necessary feature information.\n\u25cf Excitatory and inhibitory connections need to be roughly balanced, but balance that is too good (i.e. full or\nnearly full excitatory and inhibitory connectivity simultaneously) causes worse performance.\n(a)\n(b)\n(c)\n(d)\nExt Fig S8: By summing the connection weights of the feature neurons that fire to a given input, it is possible to\nreconstruct and visualise how the network is perceiving that input. Networks with 3200 feature neurons were trained\non MNIST, then the responses of the network to the first five digits in the test set were reconstructed. Since several of\nthese five digits are atypical examples, the reconstruction errors are particularly informative.\n(a) First five digits in the MNIST test set (converted to 1 bit per pixel).\n(b) Feature layer fully connected to the MNIST inputs. Except for the \u20181\u2019 the reconstructed digits are not entirely faithful\nto the original inputs. The \u20182\u2019 that is reconstructed as a \u20183\u2019 is the most extreme example. This error seems to occur for\ntwo reasons. 1. The network has no way of reproducing the long tail because this feature never (or almost never)\noccurred in the training set. 2. The long tail is also pushing the rest of the digit off-centre and for that reason it seems\nto be better at activating the features for a \u20183\u2019. Similarly, the slope of the upper line segment of the \u20187\u2019 is incorrect, the\nreconstruction of the \u20180\u2019 is too thin, and the reconstruction of the \u20184\u2019 looks somewhat like a \u20189\u2019. This network correctly\nclassified all digits except the \u20182\u2019 which it misclassified as \u20183\u2019. Clearly, trying to recognise an entire digit image at once\nis problematic, since there are too many ways that pixels can be arranged (i.e. a combinatorial explosion) and\ntherefore there are never enough feature neurons to represent all possible combinations. The feature neurons learn\n\u2018typical\u2019 digits, but they fail to represent all the individual idiosyncrasies that single instances of each digit can have.\nThese idiosyncrasies can cause spurious feature neuron firing that then cause misclassifications.\n(c) Feature layer sparsely connected to the MNIST inputs. The reconstructed digits are more faithful to the original\ninputs, but are noisy due to the random sparsity of the connections. The network still failed to represent the long tail of\nthe \u20182\u2019, but in this case it correctly classified all five digits. Using sparse rather than full connectivity resulted in more\naccurate and less stereotyped reconstructions, since the network was able to activate feature neurons in novel\ncombinations to represent novel inputs.\n(d) Each feature neuron fully connected to a 10x10 region of the MNIST input space. These spatially restricted\nreceptive fields limited the number of possible pixel combinations within each field to a tractable level. These fields\nwere then repeated across the full extent of the image, somewhat similar to one layer of a convolutional architecture.\nAs for (c) above, this network was able to activate feature neurons in novel combinations to represent novel inputs,\nbut due to the spatially limited extent of each receptive field in this case there was no extraneous noise. The digit\nreconstructions were the most faithful of all the considered architectures, and the network correctly classified all five\ndigits even though the long tail of the \u20182\u2019 still failed to be reconstructed. This architecture also maximised the\nclassification performance over the entire test set.\n(a)\n(b)\nExt Fig S9: Differences in features with and without constant input to each feature neuron. Note that constant input\nwas not used for the MNIST results in the main manuscript since many MNIST pixels around the edges of the digits\nare always off, meaning that those feature neurons that developed representations to these blank regions were not\nhelpful for identifying digits. The network outputs easily learned to ignore the unhelpful neurons but overall\nperformance suffered slightly due to there being effectively fewer useful feature neurons. (a) With constant input,\nsome neurons learned to respond to MNIST edge pixels that never actually fired (left panel). These \u2018features\u2019 were\nwasted since they never helped identify a digit (this wastage is an artefact of the MNIST dataset because it contains\ninput pixels that never fire during training). The sum of all the feature neuron connection weights (right panel) clearly\nshows the edge pixel responses. (b) Without constant input, each neuron connected only to input pixels that actually\nfired during training.\nExt Fig S10: Spikes occur with sub-timestep resolution, where neurons that receive stronger excitatory drive generate larger spikes (that conceptually occur earlier in the timestep) and also propagate stronger drive to downstream neurons."
        }
    ],
    "title": "MAKING A SPIKING NET WORK: ROBUST BRAIN-LIKE UNSUPERVISED MACHINE LEARNING Making a Spiking Net Work: Robust brain-like unsupervised machine learning"
}