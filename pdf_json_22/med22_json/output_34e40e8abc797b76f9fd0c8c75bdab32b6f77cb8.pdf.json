{
    "abstractText": "Most stroke survivors have difficulties completing activities of daily living (ADLs) independently. However, few rehabilitation systems have focused on ADLs-related training for gross and fine motor function together. We propose an ADLs-based serious game rehabilitation system for the training of motor function and coordination of both arm and hand movement where the user performs corresponding ADLs movements to interact with the target in the serious game. A multisensor fusion model based on electromyographic (EMG), force myographic (FMG), and inertial sensing was developed to estimate users\u2019 natural upper limb movement. Eight healthy subjects and three stroke patients were recruited in an experiment to validate the system\u2019s effectiveness. The performance of different sensor and classifier configurations on hand gesture classification against the arm position variations were analyzed, and qualitative patient questionnaires were conducted. Results showed that elbow extension/flexion has a more significant negative influence on EMG-based, FMG-based, and EMG+FMG-based hand gesture recognition than shoulder abduction/adduction does. In addition, there was no significant difference in the negative influence of shoulder abduction/adduction and shoulder flexion/extension on hand gesture recognition. However, there was a significant interaction between sensor configurations and algorithm configurations in both offline and real-time recognition accuracy. The EMG+FMG-combined multi-position classifier model had the best performance against arm position change. In addition, all the stroke patients reported their Manuscript received May 26, 2021; revised December 9, 2021 and February 4, 2022; accepted February 23, 2022. Date of publication March 3, 2022; date of current version March 18, 2022. This work was supported in part by the National Natural Science Foundation of China under Grant 51950410602; and in part by Xsens Technologies B.V., Enschede, The Netherlands. (Corresponding author: Peter B. Shull.) This work involved human subjects or animals in its research. Approval of all ethical and experimental procedures and protocols was granted by the Huashan Hospital Institutional Review Board (CHiCTR1800017568) and was performed in accordance with the Declaration of Helsinki. Xinyu Song, Shirdi Shankara Van De Ven, Hong Wang, and Peter B. Shull are with the State Key Laboratory of Mechanical Systems and Vibration, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: pshull@sjtu.edu.cn). Lanlan Liu is with Shanghai No.3 Rehabilitation Hospital, Shanghai 200436, China. Frank J. Wouda is with Xsens Technologies B.V., 7521PR Enschede, The Netherlands. This article has supplementary downloadable material available at https://doi.org/10.1109/TNSRE.2022.3156387, provided by the authors. Digital Object Identifier 10.1109/TNSRE.2022.3156387 ADLs-related ability could be restored by using the system. These results demonstrate that the multi-sensor fusion model could estimate hand gestures and gross movement accurately, and the proposed training system has the potential to improve patients\u2019 ability to perform ADLs.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xinyu Song"
        },
        {
            "affiliations": [],
            "name": "Shankara Van De Ven"
        },
        {
            "affiliations": [],
            "name": "Lanlan Liu"
        },
        {
            "affiliations": [],
            "name": "Frank J. Wouda"
        },
        {
            "affiliations": [],
            "name": "Peter B. Shull"
        }
    ],
    "id": "SP:0a33b27772379605abb9f968823889406636d319",
    "references": [
        {
            "authors": [
                "P.A. Isard",
                "J.F. Forbes"
            ],
            "title": "The cost of stroke to the national health service in Scotland",
            "venue": "Cerebrovascular Diseases, vol. 2, no. 1, pp. 47\u201350, 1992.",
            "year": 1992
        },
        {
            "authors": [
                "E. Taub",
                "D.M. Morris"
            ],
            "title": "Constraint-induced movement therapy to enhance recovery after stroke",
            "venue": "Current Atherosclerosis Rep., vol. 3, no. 4, pp. 279\u2013286, Jul. 2001.",
            "year": 2001
        },
        {
            "authors": [
                "G. Kwakkel",
                "R.C. Wagenaar",
                "J.W. Twisk",
                "G.J. Lankhorst",
                "J.C. Koetsier"
            ],
            "title": "Intensity of leg and arm training after primary middlecerebral-artery stroke: A randomised trial",
            "venue": "Lancet, vol. 354, no. 9174, pp. 191\u2013196, Jul. 1999.",
            "year": 1999
        },
        {
            "authors": [
                "S. Heins"
            ],
            "title": "Robotic-assisted serious game for motor and cognitive post-stroke rehabilitation",
            "venue": "Proc. IEEE 5th Int. Conf. Serious Games Appl. Health (SeGAH), Apr. 2017, pp. 1\u20138.",
            "year": 2017
        },
        {
            "authors": [
                "X. Song",
                "S. Chen",
                "J. Jia",
                "P.B. Shull"
            ],
            "title": "Cellphone-based automated Fugl-Meyer assessment to evaluate upper extremity motor function after stroke",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 27, no. 10, pp. 2186\u20132195, Oct. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "C. Winstein",
                "R. Varghese"
            ],
            "title": "Been there, done that, so what\u2019s next for arm and hand rehabilitation in stroke?",
            "venue": "Neurorehabilitation, vol. 43,",
            "year": 2018
        },
        {
            "authors": [
                "A. Kunkel"
            ],
            "title": "Constraint-induced movement therapy for motor recovery in chronic stroke patients",
            "venue": "Arch. Phys. Med. Rehabil., vol. 80, no. 6, pp. 624\u2013628, Jun. 1999.",
            "year": 1999
        },
        {
            "authors": [
                "E. Taub",
                "G. Uswatte",
                "V.W. Mark",
                "D.M. Morris"
            ],
            "title": "The learned nonuse phenomenon: Implications for rehabilitation",
            "venue": "Europa Medicophysica, vol. 42, no. 3, p. 241, 2006.",
            "year": 2006
        },
        {
            "authors": [
                "S.-Y. Chen",
                "C.J. Winstein"
            ],
            "title": "A systematic review of voluntary arm recovery in hemiparetic stroke: Critical predictors for meaningful outcomes using the international classification of functioning, disability, and health",
            "venue": "J. Neurolog. Phys. Therapy, vol. 33, no. 1, pp. 2\u201313, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "D.K. Zondervan"
            ],
            "title": "Home-based hand rehabilitation after chronic stroke: Randomized, controlled single-blind trial comparing the MusicGlove with a conventional exercise program",
            "venue": "J. Rehabil. Res. Develop., vol. 53, no. 4, pp. 457\u2013472, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "Q. Sun",
                "E. Gonzalez",
                "B. Abadines"
            ],
            "title": "A wearable sensor based hand movement rehabilitation and evaluation system",
            "venue": "Proc. 11th Int. Conf. Sens. Technol. (ICST), Dec. 2017, pp. 1\u20134.",
            "year": 2017
        },
        {
            "authors": [
                "C.J.C. Hung",
                "N. Perumal",
                "I. Elamvazuthi",
                "M.K. Tageldeen",
                "M.K.A.A. Khan",
                "S. Parasuraman"
            ],
            "title": "Home-based interactive rehabilitation system for hand",
            "venue": "Proc. 2nd IEEE Int. Symp. Robot. Manuf. Autom. (ROMA), Sep. 2016, pp. 1\u20135.",
            "year": 2016
        },
        {
            "authors": [
                "X. Chen"
            ],
            "title": "A wearable hand rehabilitation system with soft gloves",
            "venue": "IEEE Trans. Ind. Informat., vol. 17, no. 2, pp. 943\u2013952, Feb. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "X. Song",
                "L. Ding",
                "J. Zhao",
                "J. Jia",
                "P. Shull"
            ],
            "title": "Cellphone augmented reality game-based rehabilitation for improving motor function and mental state after stroke",
            "venue": "Proc. IEEE 16th Int. Conf. Wearable Implant. Body Sensor Netw. (BSN), May 2019, pp. 1\u20134.",
            "year": 2019
        },
        {
            "authors": [
                "Y.C. Du",
                "C.B. Shih",
                "S.C. Fan"
            ],
            "title": "An IMU-compensated skeletal tracking system using Kinect for the upper limb",
            "venue": "Microsyst. Technol., vol. 24, no. 10, pp. 4317\u20134327, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Z.-X. Yin",
                "H.-M. Xu"
            ],
            "title": "A wearable rehabilitation game controller using IMU sensor",
            "venue": "Proc. IEEE Int. Conf. Appl. Syst. Invention (ICASI), Apr. 2018, pp. 1060\u20131062.",
            "year": 2018
        },
        {
            "authors": [
                "S.I. Lee"
            ],
            "title": "Enabling stroke rehabilitation in home and community settings: A wearable sensor-based approach for upper-limb motor training",
            "venue": "IEEE J. Transl. Eng. Health Med., vol. 6, pp. 1\u201311, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "M. Panwar"
            ],
            "title": "Rehab-Net: Deep learning framework for arm movement classification using wearable sensors for stroke rehabilitation",
            "venue": "IEEE Trans. Biomed. Eng., vol. 66, no. 11, pp. 3026\u20133037, Nov. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "V.C.-L. Chiang",
                "K.-H. Lo",
                "K.-S. Choi"
            ],
            "title": "Rehabilitation of activities of daily living in virtual environments with intuitive user interface and force feedback",
            "venue": "Disab. Rehabil., Assistive Technol., vol. 12, no. 7, pp. 672\u2013680, Oct. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "V. Jayasree-Krishnan"
            ],
            "title": "RehabFork: An interactive game-assisted upper limb stroke rehabilitation system",
            "venue": "Proc. 42nd Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. (EMBC), Jul. 2020, pp. 5757\u20135760.",
            "year": 2020
        },
        {
            "authors": [
                "F. Delbressine"
            ],
            "title": "Motivating arm-hand use for stroke patients by serious games",
            "venue": "Proc. 34th Annu. Int. Conf. IEEE Eng. Med. Biol. Soc., Aug. 2012, pp. 3564\u20133567.",
            "year": 2012
        },
        {
            "authors": [
                "S. Jiang"
            ],
            "title": "Feasibility of wrist-worn, real-time hand, and surface gesture recognition via sEMG and IMU sensing",
            "venue": "IEEE Trans. Ind. Informat., vol. 14, no. 8, pp. 3376\u20133385, Aug. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "A. Fougner",
                "E. Scheme",
                "A.D.C. Chan",
                "K. Englehart",
                "\u00d8. Stavdah"
            ],
            "title": "Resolving the limb position effect in myoelectric pattern recognition",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 19, no. 6, pp. 644\u2013651, Dec. 2011.",
            "year": 2011
        },
        {
            "authors": [
                "Y. Yu",
                "X. Sheng",
                "W. Guo",
                "X. Zhu"
            ],
            "title": "Attenuating the impact of limb position on surface EMG pattern recognition using a mixed- LDA classifier",
            "venue": "Proc. IEEE Int. Conf. Robot. Biomimetics (ROBIO), Dec. 2017, pp. 1497\u20131502.",
            "year": 2017
        },
        {
            "authors": [
                "M. Jochumsen",
                "A. Waris",
                "E.N. Kamavuako"
            ],
            "title": "The effect of arm position on classification of hand gestures with intramuscular EMG",
            "venue": "Biomed. Signal Process. Control, vol. 43, pp. 1\u20138, May 2018.",
            "year": 2018
        },
        {
            "authors": [
                "A.K. Mukhopadhyay",
                "S. Samui"
            ],
            "title": "An experimental study on upper limb position invariant EMG signal classification based on deep neural network",
            "venue": "Biomed. Signal Process. Control, vol. 55, Jan. 2020, Art. no. 101669.",
            "year": 2020
        },
        {
            "authors": [
                "D. Yang",
                "W. Yang",
                "Q. Huang",
                "H. Liu"
            ],
            "title": "Classification of multiple finger motions during dynamic upper limb movements",
            "venue": "IEEE J. Biomed. Health Inform., vol. 21, no. 1, pp. 134\u2013141, Jan. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "J. Liu",
                "D. Zhang",
                "X. Sheng",
                "X. Zhu"
            ],
            "title": "Quantification and solutions of arm movements effect on sEMG pattern recognition",
            "venue": "Biomed. Signal Process. Control, vol. 13, no. 1, pp. 189\u2013197, Sep. 2014.",
            "year": 2014
        },
        {
            "authors": [
                "Y. Geng",
                "O.W. Samuel",
                "Y. Wei",
                "G. Li"
            ],
            "title": "Improving the robustness of real-time myoelectric pattern recognition against arm position changes in transradial amputees",
            "venue": "BioMed Res. Int., vol. 2017, pp. 1\u201310, Apr. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "Y. Teh",
                "L.J. Hargrove"
            ],
            "title": "Understanding limb position and external load effects on real-time pattern recognition control in amputees",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 28, no. 7, pp. 1605\u20131613, Jul. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "C. Lauretti",
                "A. Davalli",
                "R. Sacchetti",
                "E. Guglielmelli",
                "L. Zollo"
            ],
            "title": "Fusion of M-IMU and EMG signals for the control of trans-humeral prostheses",
            "venue": "Proc. 6th IEEE Int. Conf. Biomed. Robot. Biomechatronics (BioRob), Jun. 2016, pp. 1123\u20131128.",
            "year": 2016
        },
        {
            "authors": [
                "P.B. Shull",
                "S. Jiang",
                "Y. Zhu",
                "X. Zhu"
            ],
            "title": "Hand gesture recognition and finger angle estimation via wrist-worn modified barometric pressure sensing",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 27, no. 4, pp. 724\u2013732, Apr. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "P. Cai"
            ],
            "title": "Locally coupled electromechanical interfaces based on cytoadhesion-inspired hybrids to identify muscular excitationcontraction signatures",
            "venue": "Nature Commun., vol. 11, no. 1, pp. 1\u201312, Dec. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A.R. Fugl-Meyer",
                "L. J\u00e4\u00e4sk\u00f6",
                "I. Leyman",
                "S. Olsson",
                "S. Steglind"
            ],
            "title": "The post-stroke hemiplegic patient. 1. A method for evaluation of physical performance",
            "venue": "Scandin. J. Rehabil. Med., vol. 7, no. 1, pp. 13\u201331, 1974.",
            "year": 1974
        },
        {
            "authors": [
                "K. Englehart",
                "B. Hudgins"
            ],
            "title": "A robust, real-time control scheme for multifunction myoelectric control",
            "venue": "IEEE Trans. Biomed. Eng., vol. 50, no. 7, pp. 848\u2013854, Jul. 2003.",
            "year": 2003
        }
    ],
    "sections": [
        {
            "text": "Manuscript received May 26, 2021; revised December 9, 2021 and February 4, 2022; accepted February 23, 2022. Date of publication March 3, 2022; date of current version March 18, 2022. This work was supported in part by the National Natural Science Foundation of China under Grant 51950410602; and in part by Xsens Technologies B.V., Enschede, The Netherlands. (Corresponding author: Peter B. Shull.)\nThis work involved human subjects or animals in its research. Approval of all ethical and experimental procedures and protocols was granted by the Huashan Hospital Institutional Review Board (CHiCTR1800017568) and was performed in accordance with the Declaration of Helsinki.\nXinyu Song, Shirdi Shankara Van De Ven, Hong Wang, and Peter B. Shull are with the State Key Laboratory of Mechanical Systems and Vibration, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: pshull@sjtu.edu.cn).\nLanlan Liu is with Shanghai No.3 Rehabilitation Hospital, Shanghai 200436, China.\nFrank J. Wouda is with Xsens Technologies B.V., 7521PR Enschede, The Netherlands.\nThis article has supplementary downloadable material available at https://doi.org/10.1109/TNSRE.2022.3156387, provided by the authors.\nDigital Object Identifier 10.1109/TNSRE.2022.3156387\nADLs-related ability could be restored by using the system. These results demonstrate that the multi-sensor fusion model could estimate hand gestures and gross movement accurately, and the proposed training system has the potential to improve patients\u2019 ability to perform ADLs.\nIndex Terms\u2014 Upper limb rehabilitation, ADLs, natural movement estimation, EMG, FMG, IMU, serious game.\nI. INTRODUCTION\nSTROKE is a leading cause of death and long-term dis-ability [1]. Seventy-five percent of stroke survivors suffer from upper limb dysfunction, which limits their performance in daily life [2]. Effective rehabilitation should be longterm, repetitive, and intensive for stroke patients\u2019 neurological restoration [3], [4], [5]. Normally, patients in acute and subacute stages stay in the hospital, receiving conventional rehabilitation such as occupational therapies (OT) with the assistance of therapists, which is labor-intensive and consumes medical resources. Patients in the chronic stage should also continue effective upper limb motor function training in accordance with doctors\u2019 advice even after being discharged from the hospital. However, it is difficult for outpatients to persist due to boredom and lack of motivation [6]. In addition, patients may rely on the usage of the unaffected side to complete activities of daily living (ADLs) due to the dysfunction of the affected side in daily life [7], which could cause the gradual decline in motor function capacity of the affected side [8]. Sixty-five percent of patients in the chronic stage cannot integrate their affected side into their ADLs [9].\nMany wearable technologies have been developed to overcome these problems which could provide effective goal-oriented training to patients with upper limb dysfunction in multiple scenarios. Also, these technologies do not involve the same privacy issues as camera-based rehabilitation systems. Most motor training systems only focus on the recovery of one area. Some focus on hand function training to restore pinch strength, grip strength, flexibility, or stability [10]\u2013[13], while others just focus on gross upper limb training to restore endurance, joint mobility, or muscle strength [14]\u2013[16]. However, most of the movements in our daily lives are completed by coordinating arm and hand motions. Therefore, compared with the single training methods, the combined training of\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nthese two can better improve the coordination ability of the arm and hand, increase movement control ability, prevent spasming, and promote volitional movement.\nSome effective rehabilitation systems have also aimed to improve patients\u2019 skills in ADLs. Portable wearable systems were developed to monitor patients\u2019 ADLs and encourage them to use their affected side more in daily life to complete tasks [17], [18]. In addition, many systems designed to guide patients performing ADLs-related movements have been developed. A haptic-devices-based virtual training system could provide training for three ADLs tasks, where patients perform virtual tasks via manipulating the 3D-printed objects attached to haptic devices and a computer [19]. A RehabFork was developed to guide patients in performing eatingrelated movements [20]. A tangible tabletop combined with a wearable system was proposed to provide goal-oriented tasks and ADLs-related training [21]. All these systems simulate the life tasks pretty well, but they need additional instruments and grounded systems. In addition, these tangible or traction devices are fixed on the table, and predefined missions can only be performed on the table, which limits the training of gross upper limb motor function. To overcome these problems, a wearable multi-sensor-based rehabilitation system was developed and introduced in this paper. The system can estimate patients\u2019 natural upper limb movements. and lead patients to perform ADLs that combine gross upper limb movement and fine hand movement in serious games.\nElectromyography (EMG) has been widely used in hand movement estimation [22]. However, arm position variations degrade the accuracy of EMG-based hand gesture classification [23]. A significant amount of research has focused on addressing this problem to increase the robustness of prosthetic control. Different algorithms, classifier configurations, and training strategies have been proposed [23]\u2013[27]. The influence of static and dynamic arm movement, offline and real-time analysis, and healthy subjects and amputees were all included in previous studies [28]\u2013[30]. Inertial measurement units (IMU) have also been widely used with EMG to address the problem [23], [29], [31] and can be applied to motion detection. Both of these sensors play an important role in stroke rehabilitation. To estimate hand gestures, barometric pressure sensors have also been applied to measure the force myography (FMG) signals around the wrist [32] in previous research. Force myography is more sensitive to gestures with low strength compared to EMG [33] and could be compensatory to increase the accuracy. The influence of arm position change on FMG-based hand gesture estimation has not yet been studied to our knowledge, though it is explored in this study. A wearable multi-sensor fusion model could be a promising method to accurately estimate natural movements that combine gross movement and hand gestures.\nThe purpose of this paper is to analyze the robustness of different sensor and algorithm configurations against arm position change for hand gesture estimation and to find a sensor-fusion model that can optimize gesture recognition accuracy and stability in daily life. The study also aims to present an ADLs-based serious game rehabilitation system for the training of both arm and hand motor function. Eight\nhealthy subjects and three stroke patients with upper limb dysfunction were recruited in a pilot experiment to study the characteristics of different sensors and algorithm configurations and to validate the effectiveness of the rehabilitation system. We hypothesized that the multi-sensor-based model could recognize users\u2019 gross arm movement and estimate a variety of ADLs-related hand gestures in different arm positions accurately and that patients would be involved and enthusiastic while using the system."
        },
        {
            "heading": "II. SYSTEM DESIGN",
            "text": "A. System Structure\nThe natural-movement-estimation-based serious game rehabilitation system could provide users with ADLs-related movement training. The whole structure of the proposed system (Fig. 1) consists of five parts: natural human movements, a multi-sensor fusion system, an upper limb gross movement estimation algorithm, a hand gesture recognition algorithm, and a serious game. First, users perform predefined natural human upper limb movements, such as grasping a cup with a handle from a shelf. The kinematic information of the upper limb (including acceleration and orientation) is measured by IMUs attached to the upper arm and forearm. The physiological information, including electrical activity of forearm skeletal muscles and wrist tendon slide, is measured by the EMG electrodes around the forearm and the barometric pressure sensors around wrist, respectively. After preprocessing and feature extraction, IMU data are put into the gross arm movement estimation algorithm, and EMG and FMG data are used in the fine hand movement classification algorithm. The estimated arm position and hand gesture are the input for the ADLs-based serious game, which allows the users to interact with the target in the game and get audiovisual feedback, thereby guiding patients to perform rehabilitation training for natural upper limb movement function restoration in an immersive experience.\nB. System Design\nFine movements can be detected by the electromagnetic signal of forearm superficial muscles. Six EMG sensors of the Trigno Wireless EMG System (MAN-012-2-6, Delsys Inc., Natick, MA, USA) were applied in our system and were placed evenly around the user\u2019s forearm, about 8cm from the elbow (Fig. 1).\nWhen people perform hand and wrist movements, the wrist tendon slides, causing deformation on the wrist\u2019s surface. Thus, eight barometric pressure sensors (MPL115A2, Freescale Semiconductor Inc., Austin, TX, USA) covered by VytaFlex rubber were selected and attached evenly around the inner side of the wrist to measure the force myography (FMG). A microcontroller (STM32F401, STMicroelectronics, Geneva, Switzerland) was used to process FMG data.\nTwo 9-axis IMUs (MTw Awinda, Xsens Inc, Enschede, Netherlands) were attached to the outside of the arm. One was attached to the middle of the forearm, and the other was attached to the upper arm about 10cm above the elbow. The output data of the IMUs included 3-dimensional accelerations\nand quaternions. The kinematic data were used to estimate the gross upper limb movement.\nAn app was developed in MATLAB (MathWorks, Natick, MA, USA) for data collection and synchronization. The picture and text of the current target movement appear on the interface to prompt the user to perform corresponding movements. Data from EMG, FMG, and IMU were sampled at 2000 Hz, 90 Hz, and 40 Hz, respectively, and synchronized by corresponding triggers in different movements. All the data were saved automatically in.csv files at the end.\nA comprehensive and meaningful movement set was defined. The rehabilitation of shoulder motor function and elbow motor function are essential gross functions. Therefore, shoulder adduction (SAD), shoulder abduction (SAB), shoulder flexion (SF), shoulder extension (SE), elbow flexion (EF), and elbow extension (EE) were selected for the proposed system. The combination of these three DOFs results in eight different combinations, which corresponds to eight different positions in front of the body. In addition, seven hand gestures (Fig. 2) were selected from the Fugl-Meyer Assessment (FMA) [34]: mass flexion (MF), thumb adduction (TA), opposition (O), hook-like grasp (HG), wrist volar flexion (WF), wrist dorsiflexion (WE), and mass flexion with forearm pronation (MFFP), which are all meaningful fine movements for patients completing ADLs.\nThe game \u201cGet objects from the shelf\u201d was designed to train patients\u2019 motor function and improve their performance in ADLs (Fig. 2). In this game, the user stands in front of a shelf, which has eight blocks (2\u00d72\u00d72 in 3D: top and bottom, right and left, front and back), corresponding to eight different positions defined in the movement set. Different objects appear in different places on the shelf. Users need to get the objects by performing the correct corresponding movement: grasp a bottle, hold a glass of wine, grab a cup with a handle, grab a spoon, turn left, turn right, and grasp a cucumber with forearm pronation.\nThe subject\u2019s upper limb is at rest in the initial position (arm naturally hanging down) at the start of each round. The standard deviation of the Euclidean norm of three-axis acceleration for each 200ms window is extracted as the feature\nthat judges the state of upper limb movement. The moment when the feature is greater than the threshold is regarded as the beginning of the subject\u2019s upper limb movement. Then, when the feature drops below the threshold, we assume the subject has reached his target position, and the system starts to predict his upper limb position and hand gesture continuously. The game provides audiovisual feedback to the patients. If both\nthe arm position and fine movement have been performed and predicted successfully and simultaneously, the text \u201cexcellent\u201d appears on the screen, and the money on the screen increases by one. Subjects also hear a positive audio cue. Otherwise, the recognized current position will be displayed on the shelf at the corresponding position in the game through a small gray box, and the corresponding object of the estimated current hand gesture below the game\u2019s interface is highlighted in gray (Fig. 2). Then, the subject can adjust his arm position or hand gesture based on the current feedback. If the subject fails to complete the task within five seconds of the onset of the round, the round is deemed to be over. After each round, 1.5 seconds is left for the subject to return his upper limb to the initial position, and the timer stops during this 1.5s. Then, the game goes into the next round (Fig. 3). The serious game was written in Python based on the pygame library.\nC. Movement Estimation Algorithm During the preprocessing phase, a 20-500 Hz bandpass filter and a 50 Hz comb filter were applied to the raw EMG data. The abnormal values of FMG were deleted. Data from different movements were segmented automatically based on triggers corresponding to different movements. During the transition period between movements, related muscle activities erupt and cause a larger EMG amplitude. Thus, data of the first second and the last second of each movement in the training phase were removed to reduce interference.\nOverlapped segmentation was applied. A window with a 200ms length and 50ms step length was selected, which has good performance in EMG-based real-time classification. To synchronize the data, the same segmentation method was applied to all three kinds of sensors.\nConsidering that real-time feature extraction requires a relatively large computing source, frequency domain-based features were excluded. Four effective time-domain features for EMG signals were selected: Mean Absolute Value (MAV), Waveform Length (WL), Zero Crossings (ZC), and Slope Sign Changes (SSC) [35]. Two reliable time-domain features for FMG were selected: Mean Absolute Value (MAV) and Root\nMean Square (RMS). Two IMU features were also selected: standard deviation of the Euclidean norm of three-axis acceleration was calculated to analyze the state of the movement, and the mean value of quaternions was used to estimate the gross upper limb movement. Thus, 24 EMG features, 16 FMG features, and 10 IMU features resulted in a 50-dimentional feature array. Then, each feature was scaled and normalized by standardization.\nLinear discriminant analysis (LDA) has proven to be one of the most effective algorithms for real-time hand gesture classification [29]. It was chosen for both gross movement estimation and hand gesture classification in this study. There are three algorithm configurations\u2014single-position classifier (SPC), two-stage cascade classifier (CC), and multipleposition classifier (MPC)\u2014which were applied to estimate hand gestures [23], [29]. A single-position classifier is trained by data collected from a single arm position. A cascade classifier uses a classifier trained by the data collected from a specific single position detected during the test. Lastly, a multiple-position classifier is trained by data from all arm positions. These three LDA-based algorithms were applied in the proposed system, and their efficiency was analyzed in EMG-based, FMG-based, and EMG+FMG-based hand gesture recognition offline and online."
        },
        {
            "heading": "III. EXPERIMENTAL VALIDATION",
            "text": "An experiment was conducted to analyze the influence of arm position change on different sensor-based hand gesture recognition methods to validate the estimation accuracy and practicality of the proposed system. The experiment was pre-approved by the Huashan Hospital Institutional Review Board (CHiCTR1800017568) and was performed in accordance with the Declaration of Helsinki. Eight healthy subjects (male, 25.5 \u00b1 5.2, right-handed) and three stroke patients (male, 46.3\u00b18.1, right-handed, Brunnstrom stage greater than four) were recruited in this experiment. The inclusion criteria of stroke patients were: aged 18 to 80 with upper extremity dysfunction after stroke, mini-mental state examination (MMSE) score greater than 24, modified Ashworth scale for upper extremity spasticity less than three, and Brunnstrom stage for both hand and arm greater than four. Patients with pain in the upper extremity, neglect, or aphasia were excluded. An experienced clinician was also recruited and involved in the patients\u2019 experiment.\nFirst, the subjects were informed in detail of the experiment content and precautions. The gross movement and fine movement in the proposed movement set were carefully described to the subjects. Then, the instruction software was displayed to the subjects to familiarize them with the movements and experimental procedures. Subjects put on all the sensors with the help of a clinician; first, the subject\u2019s arm was shaved and wiped with alcohol pads, and then, EMG sensors were placed around their forearm evenly. Force myography sensors were attached to the underside of their wrist. One IMU was placed on the outside of the upper arm, and the other was placed on the outside of the central forearm. An elastic bandage was used to secure the sensors (Fig. 1).\nTABLE I QUESTIONNAIRE FOR ADLS-BASED SERIOUS-GAMES REHABILITATION SYSTEM\nFor offline data analysis and model training, a training phase was conducted. The healthy subjects were asked to perform nine sessions (nine positions), including eight positions in front of the body and one base position (arm naturally hanging down). One session consisted of three trials, with a one-minute break in between. Each trial consisted of seven hand gestures, each one lasted five seconds, and there was a two-second break between movements. After the training phase, the game\u2019s content was explained to subjects, and they watched an instructional demo of the game while taking a ten-minute break. During the break, the models for arm position and hand gesture recognition were trained. Then, subjects performed two practice trials before the formal test to get familiar with the naturalistic-movement-estimation-based serious game. Subjects then started to play formally for six sessions. Each session consisted of two trials, and each trial lasted 60 seconds with a 60-second break between trials. For the hand gesture recognition part, different methods were applied to test the system\u2019s real-time performance and the influence on hand gesture real-time classification caused by the arm position change and different included sensors. Sessions 1 and 2 used models trained by EMG signal alone, using MPC and CC (EMG-MPC and EMG-CC). Sessions 3 and 4 used models trained by FMG signal alone, using MPC and CC (FMG-MPC and FMG-CC). Sessions 5 and 6 used models trained by EMG and FMG signals together, using MPC and CC (EMG+FMG-MPC and EMG+FMG-CC).\nFor stroke patients, shorter testing periods were preferred, and the base position (arm naturally hanging down) was excluded. Only the other eight positions (corresponding to eight sessions) and one trial per session were required for these subjects\u2019 training phase. Two practice trials and five formal trials were required during the real-time gaming phase (Fig. 4). The EMG+FMG-MPC model was selected and applied to all stroke patient trials because pilot testing showed this model had the best performance. After the experiments, patients were asked to fill out a questionnaire about their experience playing the serious game and their subjective opinions on the proposed system (TABLE I). The questionnaire included seven questions, and each answer was scored on a scale of 1 to 5 (1: strongly agree, 2: agree, 3: neutral, 4: disagree, 5: strongly disagree).\nFig. 4. Example stroke patient playing the ADLs-based serious game wearing multiple sensors."
        },
        {
            "heading": "IV. STATISTICAL ANALYSIS",
            "text": "A. Effect of Arm Movement Change on Physiological-Information-Based Hand Gesture Recognition\nIn order to analyze the influence of different arm positions on EMG-based, FMG-based, and EMG+FMG-based hand gesture recognition, offline analysis was applied on the healthy subjects\u2019 data (TABLE II). Single-position classifier was applied to each position, and models trained by each position were used to estimate the hand gesture performed in each position. Leave-one-trial-out and cross-validation were applied to compare the differences between and within categories. The intra-class accuracies of different sensor configurations were compared to analyze the accuracies of different sensors without being affected by arm position change. In addition, the inter-class accuracies were also compared to study the performance of different sensor configurations while using SPC.\nIn addition, how these three arm-movement-related pair indicators (SAD/SAB, SF/SE, and EF/EE) influenced the hand gesture estimation was comprehensively analyzed. Four sessions with the same indicator were regarded as a group, and the other four sessions with the opposite indicator were regarded as the other group. The SAD group (sessions 1, 3, 5, 7) and SAB group (sessions 2, 4, 6, 8) were a pair. The SF group (sessions 1, 2, 5, 6) and SE group (sessions 3, 4, 7, 8) were a pair. The EF group (sessions 1, 2, 3, 4)\nand EE group (sessions 5, 6, 7, 8) were also a pair. For the two groups in each pair, the inter-group accuracies and intra-group accuracies were calculated offline when applying different sensor configurations accuracies. Training on two trials of each session in one group, testing on one trial of each session in the other group, and cross-validation was applied. For each sensor configuration, the intra-class accuracies of the different arm-movement-related indicators were calculated and compared. The inter-class accuracies were also calculated in these circumstances. In addition, the inter-class and intraclass accuracies of using the EMG+FMG-based model across all the arm-movement-related indicators were compared to the EMG-based model and FMG-based model.\nOne-way analysis of variance (ANOVA) was conducted to assess if there were differences. If there was a difference, a least significant difference procedure was used for post hoc analysis. The statistical significance was set to p<0.05.\nB. Effect of Different Sensor and Algorithm Configurations\nFirst, the offline analysis was performed on healthy subjects to study the sensor contribution and compare different algorithm configurations. The accuracy of three classification algorithms (MPC, CC, and SPC) while applying EMG alone, FMG alone, and EMG and FMG together were calculated to validate which method could most accurately recognize the hand gestures during natural human arm movement. Three trials per session were used to perform an offline test, using leave-one-trial-out cross-validation. In addition, to study the impact of data volume on the MPC algorithm, both two trials per session and one trial per session were used to train the MPC model, and these were then tested offline. In addition, the accuracy of arm position classification was analyzed offline to validate the performance of arm movement estimation and guarantee the feasibility of using CC. The performances of different algorithm configurations were compared when the same sensor configuration was applied. Also, the performances of different sensor configurations were compared when the same algorithm configuration was used. The hand gesture classification accuracies for each subject were calculated offline. Using the EMG+FMG-MPC method, a confusion matrix was made to show the recognition rate of each gesture and display the misclassification of gestures. The average accuracy of arm position estimation was also calculated.\nBoth the effectiveness of the proposed system and the real-time performance of hand gesture recognition affected by arm position change while applying different sensor and algorithm configurations were studied. The score measuring the effectiveness of the system was defined as the points obtained by subjects in each 60-second game. The average scores of the eight healthy subjects playing the serious game based on different methods\u2014EMG-MPC, EMG-CC, FMG-MPC, FMG-CC, EMG+FMG-MPC, and EMG+FMGCC\u2014were analyzed. The real-time performances of the six different configurations were compared by comparing healthy subjects\u2019 scores.\nTwo real-time indexes of healthy subjects playing the proposed serious game were also calculated. The real-time indexes were defined as: 1) response time: from the onset of the round to the start of the subject\u2019s movement, which refers to the period between \u2460 and \u2461 in Fig. 3; and 2) execution time: from the start of the subject\u2019s movement to the start of prediction, which refers to the period between \u2461 and \u2462 in Fig. 3. These indexes reflect subjects\u2019 ability to react in the game. Indexes of different trials were compared to study if there was a learning process for healthy subjects in the formal game trials.\nTwo-way repeated ANOVA was conducted to analyze the main effect of using different sensor configurations and different algorithms as well as the interaction effect between them. If there was a significant interaction between two variables, Bonferroni was used to adjust for multiple comparisons. The statistical significance was set to p<0.05.\nC. Effect of Stroke Patients Using the Proposed Rehabilitation System\nIn order to analyze the influence of the three pairs of arm position indicators on hand gesture recognition for stroke patients, the same grouping method as used for healthy subjects was applied, and the inter-group accuracies and intra-group accuracies were analyzed offline.\nTo validate the feasibility of stroke patients using the proposed rehabilitation system for training ADLs-based arm and hand motor function, the scores of stroke patients while playing the serious game were analyzed. The results from the questionnaire (TABLE I) were analyzed to assess patients\u2019 feelings about using the proposed system."
        },
        {
            "heading": "V. RESULTS",
            "text": "A. Effect of Arm Movement Change on Physiological-Information-Based Hand Gesture Recognition\nThe numbers which form a diagonal line from the top left to the bottom right of each table in Fig. 5 are the average intraclass classification accuracies from the eight healthy subjects, which refers to the training data and testing data from the same arm position where SPC was applied. On the other hand, the other numbers in each table that are not part of the diagonal line are the inter-class classification accuracies, which refer to the training data and testing data from different arm positions. The intra-class accuracies of FMG-alone-based hand gesture classification (which ranged from 88.2% to 97.4%, with an average accuracy of 92.7%) were higher (P < 0.05) than the EMG-alone-based intra-class accuracy (which ranged from 85.2% to 91.5%, with an average accuracy of 88.7%). The intra-class accuracies of EMG+FMG-based hand gesture classification (ranging from 93.6% to 98.2%, with an average accuracy of 95.6%) were higher than the intra-class accuracies of FMG-alone-based hand gesture classification (P < 0.05).\nThe FMG-alone-based inter-class accuracies ranged from 31.9% to 80.3%, with an average of 68.4%. The EMG-alonebased inter-class accuracies ranged from 57.0% to 85.0%, with an average accuracy of 78.9%. For EMG+FMG-based hand gesture classification, the inter-class accuracies ranged from 38.4% to 86.5%, with an average accuracy of 75.5%. There was no significant difference between these three inter-class accuracies (P > 0.05).\nThe intra-group and inter-group hand gesture recognition accuracy of the three indicator pairs\u2014SAD/SAB, SF/SE, and EF/EE\u2014averaged from the eight healthy subjects were analyzed with three different sensor combinations: EMG-based, FMG-based, and EMG+FMG-based (Fig. 6). The color gap between the main diagonal and the antidiagonal in each little block represents the negative influence of arm-movementrelated indicators to hand gesture recognition (Fig. 6). There was no significant difference between intra-group accuracies of SAD/SAB, SF/SE, and EF/EE (P > 0.05). There was also no significant difference between inter-group accuracies of SAD/SAB and the accuracies of SF/SE (P > 0.05).\nHowever, the inter-group accuracies of the SAD/SAB pair were significantly higher than EF/EE across all three different sensor combinations (P < 0.05). The accuracy of EF/EE was significantly lower than SF/SE when the EMG+FMG-based model was used (P < 0.05). In addition, the intra-group and inter-group accuracies of EMG+FMG-based hand gesture classification were higher than the accuracies while using either of these sensors alone (P < 0.05).\nB. Effect of Different Sensor and Algorithm Configurations\nApplying different sensor and algorithm configurations was analyzed offline on the eight healthy subjects (Fig. 7) (TABLE III). When using EMG alone, FMG alone, or EMG and FMG together, the offline classification accuracies of applying MPC with training on two trials per session (MPC-2) were 87.4%, 92.4%, and 96.7%, respectively. The performance of using MPC with training on one trial per session (MPC-1) were 86.4%, 91.6%, and 96.1%, respectively. Applying CC resulted in accuracies of 88.4%, 93.0%, and 95.5%. The results\nof two-way repeated ANOVA revealed that there was a significant interaction between sensor configurations and algorithm configurations (F (6) = 14.6, P < 0.05, \u03b72p = 0.676). For\neach sensor configuration, there was no significant difference in using MPC-2, MPC-1, and CC (P > 0.05). On the other hand, the offline accuracy of using SPC on all three sensor configurations was significantly lower than other algorithm configurations (P < 0.05), with 66.6%, 47.6%, and 57.0% accuracies. For the MPC-2 and MPC-1 algorithm configurations, the offline classification accuracy of using EMG and FMG together was significantly higher than using FMG alone (P < 0.05) or using EMG alone (P < 0.05). However, there was no significant difference between using EMG and FMG (P > 0.05) under MPC-2, MPC-1, or CC. In addition, EMG and FMG together had significantly better offline accuracy than FMG alone when CC was applied (P < 0.05). Force myography alone resulted in significantly lower accuracies compared to EMG alone (P < 0.05) or EMG and FMG together (P < 0.05) when applying SPC. Additionally, the average offline accuracy of arm position estimation for healthy subjects was 98.9%.\nOffline hand gesture recognition accuracy for each healthy subject ranged from 91.3% to 99.8%, with an average of 96.7%, when applying MPC on EMG and FMG together. The confusion matrix showed that HG and TA were easily misclassified with each other, and for EMG-based recognition, MF was easily misclassified as MFFP. In addition, O and TA were easily misclassified with each other when FMG was applied. The fusion of EMG and FMG improved the accuracy of classifying each hand gesture (Fig. 8).\nThe average real-time score (number of objects taken from the shelf) of the eight healthy subjects when applying EMG-MPC, EMG-CC, FMG-MPC, FMG-CC, EMG+FMG-MPC, and EMG+FMG-CC were 20.1, 21.8, 21.8, 13.4, 26.8, and 17.6, respectively (Fig. 9) (TABLE IV). The results of two-way repeated ANOVA revealed that there was a significant interaction between sensor configurations and algorithm configurations by analyzing the real-time score (F (2, 14) = 10.87, P < 0.05, \u03b72p = 0.608). For MPC, subjects could get higher scores when EMG+FMG was applied compared with EMG (P < 0.05) or FMG (P < 0.05) alone.\nFor CC, subjects\u2019 scored significantly lower when FMG was used compared to EMG (P < 0.05) alone or EMG+FMG (P < 0.05). When using EMG alone, there was no significant difference between using MPC or CC (P > 0.05). However, for both FMG and EMG+FMG, subjects could get significantly higher results by using MPC compared to CC (P > 0.05).\nFor healthy subjects, the response time ranged from 272ms to 365ms, and the execution time ranged from 843ms to 1001ms. There is no significant difference between applying different methods to these two indexes (P > 0.05).\nC. Effect of Stroke Patients Using the Proposed Rehabilitation System\nThe offline inter-group accuracies and intra-group accuracies of the three indicator pairs which related to three pair arm indicators were calculated on stroke patients (Fig. 10).\nThe stroke patients\u2019 average score was 9.3, which is lower than the average score of healthy subjects when the same configuration (EMG+FMG-MPC) was applied. The questionnaire results showed that all subjects strongly agreed that they felt accomplishment and no discomfort while playing the game. All the patients agreed or strongly agreed that using the proposed system could improve their motor function and cognitive function, and they could connect the game scene to real-life situations. They also thought their ADLs-related ability could be restored by using the system (TABLE I)."
        },
        {
            "heading": "VI. DISCUSSION",
            "text": "An ADLs-based serious game rehabilitation system was developed to provide patients with arm and hand motor function training via recognizing the natural movement of the patients\u2019 affected sides with a multi-sensor fusion model and providing audiovisual feedback through the serious game. In addition, the offline accuracies and real-time performance of hand gesture classification applied by different methods were analyzed to study the influence of arm position change on different sensor- and algorithm-configurations-based hand gesture recognition. The study found that EMG+FMG-MPC is the optimal sensor and algorithm configuration to reduce the negative impact of arm position changes on hand gesture recognition.\nOur findings demonstrate that arm position can influence the accuracy of EMG-based hand gesture classification, which aligns with previous findings. Yang et al. [27] analyzed the effectiveness of four training paradigms and found that hand gesture classification accuracy was significantly influenced by wrist pronation and supination. Similarly, in the presented study, the influence of EF/EE, SF/SE, and SAD/SAB on accuracy was systematically tested and analyzed, and findings demonstrated that SF/SF and SAD/SAB have no\nsignificant negative influence on EMG-based, FMG-based, or EMG+FMG-based hand gesture recognition. EF/EE has a more significant negative influence on EMG-based, FMG-based, or EMG+FMG-based hand gesture recognition than SAD/SAB. EF/EE has the most negative influence on EMG+FMG-based hand gesture recognition, followed by SF/SF and SAD/SAB (Fig. 6). Liu et al. [28] suggested that the relative shifting between sensors and subcutaneous muscle, muscle activities against gravity, and muscle activities for inertial compensation were significant contributing factors to the negative influence of arm position on accuracy. Fougner et al. [23] observed the negative impact of static arm position variations to EMG-based hand gesture classification and proposed MPC and CC configurations to reduce classification error. Also, Geng et al. [29] studied the performance of CC and MPC in real time on amputees, and the performances were improved by 8.7% and 12.7%, respectively, compared to SPC. Others have suggested a mixed-LDA classifier and neural network approaches to reduce arm-position-based classification errors [24], [26].\nFrom the offline results, most intra-class accuracies of FMG were higher than intra-class accuracies of EMG (Fig. 5). The EMG and FMG sensors can compensate for each other, with FMG being more sensitive with gestures with lower strength and EMG being the opposite. We can tell that misclassified hand gestures were different when EMG and FMG were applied separately. Each gesture\u2019s estimation accuracy largely improved when EMG and FMG were used together (Fig. 8). Both inter-group and intra-group accuracies were improved for each arm-related indicator pair when EMG and FMG were applied together compared with either sensor applied separately (Fig. 6). In addition, EMG and FMG sensor fusion also shows better performance when either MPC or CC algorithm were used (Fig. 7).\nThe offline effectiveness of each sensor and algorithm configuration were analyzed. Also, scores of healthy subjects under different sensor and algorithm configurations were compared and analyzed to study the real-time performances of the different configurations. Results showed significant interaction between sensor configurations and algorithm configurations in both offline and real-time recognition accuracy. For MPC, EMG+FMG showed better performance than the other sensor configurations in both offline and real time. However, other simple main effects showed some differences. For CC, there was no significant difference between using EMG or FMG offline, but FMG performed worst in real-time recognition. For all sensor configurations, there was no significant difference between MPC and CC offline. However, in real time, MPC resulted in higher accuracy than CC when FMG or EMG+FMG was used. These results indicate that hand gesture recognition via measuring the tendon slide of the wrist had the same robustness against arm position change as hand gesture estimation based on forearm muscle activities measuring. On the other hand, the movement of the hand caused more shifting between FMG sensors and wrist skin than the shifting that happened between the EMG sensors and forearm skin. Finding an FMG-based skin-attached wristband that is not easy\nto shift or loosen could be a solution to address the problem. Results also indicated that EMG+FMG-MPC was the best configuration to reduce the negative impact of arm position change.\nMost ADLs-related training systems [19]\u2013[21] can only provide patients with table tasks, which limits the training of comprehensive gross movement. The ADLs monitor systems [17], [18] can only classify a few rough movements, which is not suitable to expand into active rehabilitation systems. The proposed system could accurately estimate both hand gestures and arm positions in which patients could perform natural ADLs movements. The patients were asked to perform various functional tasks in the entire area in front of them to complete the simulated tasks of the serious game. According to clinical scales, the selected stroke patients had no significant cognitive dysfunction, and their upper limb motor function impairment was mild. However, their scores while playing the serious game were much worse than healthy subjects. We observed that patients were slower in performing the right hand gesture in the right position and may have problems with hand and arm coordination which still need long-term training. Audiovisual feedback can help patients adjust their movements in real time to complete tasks. The proposed serious game system seems effective, comprehensive, and attractive, which could make patients more immersed in function training and could be beneficial for regaining ADLs ability and neurological restoration. In addition, the system is wearable with no extra grounded devices and can be used in both a clinical environment and the home.\nA. Limitation There are still some limitations of this system that could be improved in future work. We used the given targets in the serious game as golden labels. However, we ignored if subjects were actually performing the movement the game required them to do. We did not recognize the gestures subjects were intending to perform for a given target. Therefore, we cannot get exact accuracies of different models. In the presented study, average scores that subjects obtained by using different sensor and algorithm configurations were compared to evaluate the real-time performance for different models. A formal, realtime experiment excluding serious games (such as the Motion Test) should be conducted in future research. Also, we tried to eliminate learning effects by providing several practice trials before the formal experiment began to allow subjects to become familiar with the system. Enough rest time was provided to subjects to avoid fatigue. However, the order of the sessions in this study was fixed, which could potentially lead to learning effects or fatigue effects. Future studies should randomize the order of sessions. In addition, only male subjects were recruited in the study. Female participants should also be included in the future to achieve a balanced gender distribution.\nThis pilot study was intended to demonstrate initial feasibility of this system for healthy subjects and stroke patients. Future follow-up research should focus on increasing the sample size. The effect of the training data volume on estimation\nmodel accuracy of stroke patients also needs to be validated in future work. The serious game scene could be further developed to provide a more immersive environment: the shelf can be more vivid to provide more instinctive depth information, and the position of the user\u2019s arm can be represented by the form of a hand instead of a gray picture. In addition, a white-box-based arm position estimation algorithm can be developed to increase the generalizability of the system. It is also necessary to comprehensively consider the displacement of the sensor due to re-wearing and the impact of arm position variance on the recognition accuracy. Finally, a long-term randomized control trial should be designed and conducted on stroke patients to validate if the proposed system can improve arm and hand motor function and restore patients\u2019 ability to perform ADLs.\nACKNOWLEDGMENT The authors would like to thank all the subjects and clinicians for their participation in this study, and also would like to thank Dr. Kim Sunesen for his input on the study design.\nREFERENCES [1] P. A. Isard and J. F. Forbes, \u201cThe cost of stroke to the national health\nservice in Scotland,\u201d Cerebrovascular Diseases, vol. 2, no. 1, pp. 47\u201350, 1992. [2] E. Taub and D. M. Morris, \u201cConstraint-induced movement therapy to enhance recovery after stroke,\u201d Current Atherosclerosis Rep., vol. 3, no. 4, pp. 279\u2013286, Jul. 2001. [3] G. Kwakkel, R. C. Wagenaar, J. W. Twisk, G. J. Lankhorst, and J. C. Koetsier, \u201cIntensity of leg and arm training after primary middlecerebral-artery stroke: A randomised trial,\u201d Lancet, vol. 354, no. 9174, pp. 191\u2013196, Jul. 1999. [4] S. Heins et al., \u201cRobotic-assisted serious game for motor and cognitive post-stroke rehabilitation,\u201d in Proc. IEEE 5th Int. Conf. Serious Games Appl. Health (SeGAH), Apr. 2017, pp. 1\u20138. [5] X. Song, S. Chen, J. Jia, and P. B. Shull, \u201cCellphone-based automated Fugl-Meyer assessment to evaluate upper extremity motor function after stroke,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 27, no. 10, pp. 2186\u20132195, Oct. 2019. [6] C. Winstein and R. Varghese, \u201cBeen there, done that, so what\u2019s next for arm and hand rehabilitation in stroke?\u201d Neurorehabilitation, vol. 43, no. 1, pp. 3\u201318, 2018. [7] A. Kunkel et al., \u201cConstraint-induced movement therapy for motor recovery in chronic stroke patients,\u201d Arch. Phys. Med. Rehabil., vol. 80, no. 6, pp. 624\u2013628, Jun. 1999. [8] E. Taub, G. Uswatte, V. W. Mark, and D. M. Morris, \u201cThe learned nonuse phenomenon: Implications for rehabilitation,\u201d Europa Medicophysica, vol. 42, no. 3, p. 241, 2006. [9] S.-Y. Chen and C. J. Winstein, \u201cA systematic review of voluntary arm recovery in hemiparetic stroke: Critical predictors for meaningful outcomes using the international classification of functioning, disability, and health,\u201d J. Neurolog. Phys. Therapy, vol. 33, no. 1, pp. 2\u201313, 2009. [10] D. K. Zondervan et al., \u201cHome-based hand rehabilitation after chronic stroke: Randomized, controlled single-blind trial comparing the MusicGlove with a conventional exercise program,\u201d J. Rehabil. Res. Develop., vol. 53, no. 4, pp. 457\u2013472, 2016. [11] Q. Sun, E. Gonzalez, and B. Abadines, \u201cA wearable sensor based hand movement rehabilitation and evaluation system,\u201d in Proc. 11th Int. Conf. Sens. Technol. (ICST), Dec. 2017, pp. 1\u20134. [12] C. J. C. Hung, N. Perumal, I. Elamvazuthi, M. K. Tageldeen, M. K. A. A. Khan, and S. Parasuraman, \u201cHome-based interactive rehabilitation system for hand,\u201d in Proc. 2nd IEEE Int. Symp. Robot. Manuf. Autom. (ROMA), Sep. 2016, pp. 1\u20135. [13] X. Chen et al., \u201cA wearable hand rehabilitation system with soft gloves,\u201d IEEE Trans. Ind. Informat., vol. 17, no. 2, pp. 943\u2013952, Feb. 2021. [14] X. Song, L. Ding, J. Zhao, J. Jia, and P. Shull, \u201cCellphone augmented reality game-based rehabilitation for improving motor function and mental state after stroke,\u201d in Proc. IEEE 16th Int. Conf. Wearable Implant. Body Sensor Netw. (BSN), May 2019, pp. 1\u20134.\n[15] Y. C. Du, C. B. Shih, and S. C. Fan, \u201cAn IMU-compensated skeletal tracking system using Kinect for the upper limb,\u201d Microsyst. Technol., vol. 24, no. 10, pp. 4317\u20134327, 2018. [16] Z.-X. Yin and H.-M. Xu, \u201cA wearable rehabilitation game controller using IMU sensor,\u201d in Proc. IEEE Int. Conf. Appl. Syst. Invention (ICASI), Apr. 2018, pp. 1060\u20131062. [17] S. I. Lee et al., \u201cEnabling stroke rehabilitation in home and community settings: A wearable sensor-based approach for upper-limb motor training,\u201d IEEE J. Transl. Eng. Health Med., vol. 6, pp. 1\u201311, 2018. [18] M. Panwar et al., \u201cRehab-Net: Deep learning framework for arm movement classification using wearable sensors for stroke rehabilitation,\u201d IEEE Trans. Biomed. Eng., vol. 66, no. 11, pp. 3026\u20133037, Nov. 2019. [19] V. C.-L. Chiang, K.-H. Lo, and K.-S. Choi, \u201cRehabilitation of activities of daily living in virtual environments with intuitive user interface and force feedback,\u201d Disab. Rehabil., Assistive Technol., vol. 12, no. 7, pp. 672\u2013680, Oct. 2017. [20] V. Jayasree-Krishnan et al., \u201cRehabFork: An interactive game-assisted upper limb stroke rehabilitation system,\u201d in Proc. 42nd Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. (EMBC), Jul. 2020, pp. 5757\u20135760. [21] F. Delbressine et al., \u201cMotivating arm-hand use for stroke patients by serious games,\u201d in Proc. 34th Annu. Int. Conf. IEEE Eng. Med. Biol. Soc., Aug. 2012, pp. 3564\u20133567. [22] S. Jiang et al., \u201cFeasibility of wrist-worn, real-time hand, and surface gesture recognition via sEMG and IMU sensing,\u201d IEEE Trans. Ind. Informat., vol. 14, no. 8, pp. 3376\u20133385, Aug. 2018. [23] A. Fougner, E. Scheme, A. D. C. Chan, K. Englehart, and \u00d8. Stavdah, \u201cResolving the limb position effect in myoelectric pattern recognition,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 19, no. 6, pp. 644\u2013651, Dec. 2011. [24] Y. Yu, X. Sheng, W. Guo, and X. Zhu, \u201cAttenuating the impact of limb position on surface EMG pattern recognition using a mixedLDA classifier,\u201d in Proc. IEEE Int. Conf. Robot. Biomimetics (ROBIO), Dec. 2017, pp. 1497\u20131502. [25] M. Jochumsen, A. Waris, and E. N. Kamavuako, \u201cThe effect of arm position on classification of hand gestures with intramuscular EMG,\u201d Biomed. Signal Process. Control, vol. 43, pp. 1\u20138, May 2018. [26] A. K. Mukhopadhyay and S. Samui, \u201cAn experimental study on upper limb position invariant EMG signal classification based on deep neural network,\u201d Biomed. Signal Process. Control, vol. 55, Jan. 2020, Art. no. 101669. [27] D. Yang, W. Yang, Q. Huang, and H. Liu, \u201cClassification of multiple finger motions during dynamic upper limb movements,\u201d IEEE J. Biomed. Health Inform., vol. 21, no. 1, pp. 134\u2013141, Jan. 2017. [28] J. Liu, D. Zhang, X. Sheng, and X. Zhu, \u201cQuantification and solutions of arm movements effect on sEMG pattern recognition,\u201d Biomed. Signal Process. Control, vol. 13, no. 1, pp. 189\u2013197, Sep. 2014. [29] Y. Geng, O. W. Samuel, Y. Wei, and G. Li, \u201cImproving the robustness of real-time myoelectric pattern recognition against arm position changes in transradial amputees,\u201d BioMed Res. Int., vol. 2017, pp. 1\u201310, Apr. 2017. [30] Y. Teh and L. J. Hargrove, \u201cUnderstanding limb position and external load effects on real-time pattern recognition control in amputees,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 28, no. 7, pp. 1605\u20131613, Jul. 2020. [31] C. Lauretti, A. Davalli, R. Sacchetti, E. Guglielmelli, and L. Zollo, \u201cFusion of M-IMU and EMG signals for the control of trans-humeral prostheses,\u201d in Proc. 6th IEEE Int. Conf. Biomed. Robot. Biomechatronics (BioRob), Jun. 2016, pp. 1123\u20131128. [32] P. B. Shull, S. Jiang, Y. Zhu, and X. Zhu, \u201cHand gesture recognition and finger angle estimation via wrist-worn modified barometric pressure sensing,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 27, no. 4, pp. 724\u2013732, Apr. 2019. [33] P. Cai et al., \u201cLocally coupled electromechanical interfaces based on cytoadhesion-inspired hybrids to identify muscular excitationcontraction signatures,\u201d Nature Commun., vol. 11, no. 1, pp. 1\u201312, Dec. 2020. [34] A. R. Fugl-Meyer, L. J\u00e4\u00e4sk\u00f6, I. Leyman, S. Olsson, and S. Steglind, \u201cThe post-stroke hemiplegic patient. 1. A method for evaluation of physical performance,\u201d Scandin. J. Rehabil. Med., vol. 7, no. 1, pp. 13\u201331, 1974. [35] K. Englehart and B. Hudgins, \u201cA robust, real-time control scheme for multifunction myoelectric control,\u201d IEEE Trans. Biomed. Eng., vol. 50, no. 7, pp. 848\u2013854, Jul. 2003."
        }
    ],
    "title": "Activities of Daily Living-Based Rehabilitation System for Arm and Hand Motor Function Retraining After Stroke",
    "year": 2022
}