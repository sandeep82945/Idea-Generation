{
    "abstractText": "Recent years have seen significant advances in quantum/quantum-inspired technologies capable of approximately searching for the ground state of Ising spin Hamiltonians. The promise of leveraging such technologies to accelerate the solution of difficult optimization problems has spurred an increased interest in exploring methods to integrate Ising problems as part of their solution process, with existing approaches ranging from direct transcription to hybrid quantum-classical approaches rooted in existing optimization algorithms. While it is widely acknowledged that quantum computers should augment classical computers, rather than replace them entirely, comparatively little attention has been directed toward deriving analytical characterizations of their interactions. In this paper, we present a formal analysis of hybrid algorithms in the context of solving mixed-binary quadratic programs (MBQP) via Ising solvers. We show the exactness of a convex copositive reformulation of MBQPs, allowing the resulting reformulation to inherit the straightforward analysis of convex optimization. We propose to solve this reformulation with a hybrid quantum-classical cutting-plane algorithm. Using existing complexity results for convex cutting-plane algorithms, we deduce that the classical portion of this hybrid framework is guaranteed to be polynomial time. This suggests that when applied to NP-hard problems, the complexity of the solution is shifted onto the subroutine handled by the Ising solver.",
    "authors": [
        {
            "affiliations": [],
            "name": "ROBIN BROWN"
        }
    ],
    "id": "SP:ea4968543c0d9b457249c4fe446a5545737d6e7c",
    "references": [
        {
            "authors": [
                "M.W. Johnson",
                "M.H. Amin",
                "S. Gildert",
                "T. Lanting",
                "F. Hamze",
                "N. Dickson",
                "R. Harris",
                "A.J. Berkley",
                "J. Johansson",
                "P. Bunyk"
            ],
            "title": "Quantum annealing with manufactured spins",
            "venue": "Nature, vol. 473, no. 7346, pp. 194\u2013198, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "E. Farhi",
                "J. Goldstone",
                "S. Gutmann"
            ],
            "title": "A quantum approximate optimization algorithm",
            "venue": "arXiv preprint arXiv:1411.4028, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "T. Honjo",
                "T. Sonobe",
                "K. Inaba",
                "T. Inagaki",
                "T. Ikuta",
                "Y. Yamada",
                "T. Kazama",
                "K. Enbutsu",
                "T. Umeki",
                "R. Kasahara"
            ],
            "title": "100,000-spin coherent Ising machine",
            "venue": "Science advances, vol. 7, no. 40, p. eabh0952, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "C. Gambella",
                "A. Simonetto"
            ],
            "title": "Multiblock ADMM heuristics for mixed-binary optimization on classical and quantum computers",
            "venue": "IEEE Transactions on Quantum Engineering, vol. 1, pp. 1\u201322, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "C.-Y. Chang",
                "E. Jones",
                "Y. Yao",
                "P. Graf",
                "R. Jain"
            ],
            "title": "On Hybrid Quantum and Classical Computing Algorithms for Mixed-Integer Programming",
            "venue": "arXiv e-prints, pp. arXiv\u20132010, 2020.",
            "year": 2010
        },
        {
            "authors": [
                "Z. Zhao",
                "L. Fan",
                "Z. Han"
            ],
            "title": "Hybrid Quantum Benders\u2019 Decomposition For Mixed-integer Linear Programming",
            "venue": "arXiv preprint arXiv:2112.07109, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "N.G. Paterakis"
            ],
            "title": "Hybrid Quantum-Classical Multi-cut Benders Approach with a Power System Application",
            "venue": "arXiv preprint arXiv:2112.05643, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S. Burer"
            ],
            "title": "On the copositive representation of binary and continuous nonconvex quadratic programs",
            "venue": "Mathematical Programming, vol. 120, no. 2, p. 479\u2013495, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "A. Yurtsever",
                "T. Birdal",
                "V. Golyanik"
            ],
            "title": "Q-FW: A Hybrid Classical-Quantum Frank-Wolfe for Quadratic Binary Optimization",
            "venue": "arXiv preprint arXiv:2203.12633, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "D. Venturelli",
                "D. Marchand",
                "G. Rojo"
            ],
            "title": "Job shop scheduling solver based on quantum annealing",
            "venue": "Proc. of ICAPS-16 Workshop on Constraint Satisfaction Techniques for Planning and Scheduling (COPLAS), 2016, pp. 25\u201334.",
            "year": 2016
        },
        {
            "authors": [
                "S. Harwood",
                "C. Gambella",
                "D. Trenev",
                "A. Simonetto",
                "D. Bernal",
                "D. Greenberg"
            ],
            "title": "Formulating and solving routing problems on quantum computers",
            "venue": "IEEE Transactions on Quantum Engineering, vol. 2, pp. 1\u201317, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "C.F. Negre",
                "H. Ushijima-Mwesigwa",
                "S.M. Mniszewski"
            ],
            "title": "Detecting multiple communities using quantum annealing on the D-Wave system",
            "venue": "Plos one, vol. 15, no. 2, p. e0227538, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A. Lucas"
            ],
            "title": "Ising formulations of many NP problems",
            "venue": "Frontiers in physics, p. 5, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "A. Callison",
                "N. Chancellor"
            ],
            "title": "Hybrid quantum-classical algorithms in the noisy intermediate-scale quantum era and beyond",
            "venue": "Physical Review A, vol. 106, no. 1, p. 010101, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "S. Boyd",
                "N. Parikh",
                "E. Chu",
                "B. Peleato",
                "J. Eckstein"
            ],
            "title": "Distributed optimization and statistical learning via the alternating direction method of multipliers",
            "venue": "Foundations and Trends\u00aein Machine learning, vol. 3, no. 1, pp. 1\u2013122, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "S. Diamond",
                "R. Takapoui",
                "S. Boyd"
            ],
            "title": "A general system for heuristic minimization of convex functions over non-convex sets",
            "venue": "Optimization Methods and Software, vol. 33, no. 1, pp. 165\u2013193, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Y. Wang",
                "W. Yin",
                "J. Zeng"
            ],
            "title": "Global convergence of ADMM in nonconvex nonsmooth optimization",
            "venue": "Journal of Scientific Computing, vol. 78, no. 1, pp. 29\u201363, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "H. Attouch",
                "J. Bolte",
                "B.F. Svaiter"
            ],
            "title": "Convergence of descent methods for semi-algebraic and tame problems: proximal algorithms, forward\u2013backward splitting, and regularized Gauss\u2013Seidel methods",
            "venue": "Mathematical Pro- 18 gramming, vol. 137, no. 1, pp. 91\u2013129, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "M. Booth",
                "S. Reinhardt",
                "A. Roy"
            ],
            "title": "Partitioning Optimization Problems for Hybrid Classical/Quantum Execution",
            "venue": "D-Wave, Tech. Rep., 2017.",
            "year": 2017
        },
        {
            "authors": [
                "F. Glover",
                "S. Hanafi"
            ],
            "title": "Tabu search and finite convergence",
            "venue": "Discrete Applied Mathematics, vol. 119, no. 1-2, pp. 3\u201336, 2002.",
            "year": 2002
        },
        {
            "authors": [
                "H. Alghassi",
                "R. Dridi",
                "S. Tayur"
            ],
            "title": "Graver bases via quantum annealing with application to non-linear integer programs",
            "venue": "arXiv preprint arXiv:1902.04215, 2019.",
            "year": 1902
        },
        {
            "authors": [
                "T. Albash",
                "D.A. Lidar"
            ],
            "title": "Adiabatic quantum computation",
            "venue": "Reviews of Modern Physics, vol. 90, no. 1, p. 015002, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "P. Hauke",
                "H.G. Katzgraber",
                "W. Lechner",
                "H. Nishimori",
                "W.D. Oliver"
            ],
            "title": "Perspectives of quantum annealing: Methods and implementations",
            "venue": "Reports on Progress in Physics, vol. 83, no. 5, p. 054401, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "M. Cerezo",
                "A. Arrasmith",
                "R. Babbush",
                "S.C. Benjamin",
                "S. Endo",
                "K. Fujii",
                "J.R. McClean",
                "K. Mitarai",
                "X. Yuan",
                "L. Cincio"
            ],
            "title": "Variational quantum algorithms",
            "venue": "Nature Reviews Physics, vol. 3, no. 9, pp. 625\u2013644, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "J.R. McClean",
                "J. Romero",
                "R. Babbush",
                "A. Aspuru-Guzik"
            ],
            "title": "The theory of variational hybrid quantum-classical algorithms",
            "venue": "New Journal of Physics, vol. 18, no. 2, p. 023023, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "L. Bittel",
                "M. Kliesch"
            ],
            "title": "Training variational quantum algorithms is np-hard",
            "venue": "Physical review letters, vol. 127, no. 12, p. 120502, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "E. Farhi",
                "A.W. Harrow"
            ],
            "title": "Quantum supremacy through the quantum approximate optimization algorithm",
            "venue": "arXiv preprint arXiv:1602.07674, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "J. Preskill"
            ],
            "title": "Quantum computing in the nisq era and beyond",
            "venue": "Quantum, vol. 2, p. 79, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "A. Uvarov",
                "J.D. Biamonte"
            ],
            "title": "On barren plateaus and cost function locality in variational quantum algorithms",
            "venue": "Journal of Physics A: Mathematical and Theoretical, vol. 54, no. 24, p. 245301, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "M. Willsch",
                "D. Willsch",
                "F. Jin",
                "H. De Raedt",
                "K. Michielsen"
            ],
            "title": "Benchmarking the quantum approximate optimization algorithm",
            "venue": "Quantum Information Processing, vol. 19, no. 7, pp. 1\u201324, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "M.P. Harrigan",
                "K.J. Sung",
                "M. Neeley",
                "K.J. Satzinger",
                "F. Arute",
                "K. Arya",
                "J. Atalaya",
                "J.C. Bardin",
                "R. Barends",
                "S. Boixo"
            ],
            "title": "Quantum approximate optimization of non-planar graph problems on a planar superconducting processor",
            "venue": "Nature Physics, vol. 17, no. 3, pp. 332\u2013336, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y.R. Sanders",
                "D.W. Berry",
                "P.C. Costa",
                "L.W. Tessler",
                "N. Wiebe",
                "C. Gidney",
                "H. Neven",
                "R. Babbush"
            ],
            "title": "Compilation of fault-tolerant quantum heuristics for combinatorial optimization",
            "venue": "PRX Quantum, vol. 1, no. 2, p. 020312, 2020.",
            "year": 2031
        },
        {
            "authors": [
                "Y. Yamamoto",
                "K. Aihara",
                "T. Leleu",
                "K.-i. Kawarabayashi",
                "S. Kako",
                "M. Fejer",
                "K. Inoue",
                "H. Takesue"
            ],
            "title": "Coherent Ising machines\u2014Optical neural networks operating at the quantum limit",
            "venue": "npj Quantum Information, vol. 3, no. 1, pp. 1\u201315, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "N. Mohseni",
                "P.L. McMahon",
                "T. Byrnes"
            ],
            "title": "Ising machines as hardware solvers of combinatorial optimization problems",
            "venue": "Nature Reviews Physics, pp. 1\u201317, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Y. Shim",
                "A. Jaiswal",
                "K. Roy"
            ],
            "title": "Ising computation based combinatorial optimization using spin-hall effect (she) induced stochastic magnetization reversal",
            "venue": "Journal of Applied Physics, vol. 121, no. 19, p. 193902, 2017.",
            "year": 1939
        },
        {
            "authors": [
                "D. Pierangeli",
                "G. Marcucci",
                "C. Conti"
            ],
            "title": "Large-scale photonic ising machine by spatial light modulation",
            "venue": "Physical review letters, vol. 122, no. 21, p. 213902, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M.N. Bojnordi",
                "E. Ipek"
            ],
            "title": "Memristive boltzmann machine: A hardware accelerator for combinatorial optimization and deep learning",
            "venue": "2016 IEEE International Symposium on High Performance Computer Architecture (HPCA). IEEE, 2016, pp. 1\u201313.",
            "year": 2016
        },
        {
            "authors": [
                "S. Matsubara",
                "M. Takatsu",
                "T. Miyazawa",
                "T. Shibasaki",
                "Y. Watanabe",
                "K. Takemoto",
                "H. Tamura"
            ],
            "title": "Digital annealer for high-speed solving of combinatorial optimization problems and its applications",
            "venue": "2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). IEEE, 2020, pp. 667\u2013672.",
            "year": 2020
        },
        {
            "authors": [
                "P.L. McMahon",
                "A. Marandi",
                "Y. Haribara",
                "R. Hamerly",
                "C. Langrock",
                "S. Tamate",
                "T. Inagaki",
                "H. Takesue",
                "S. Utsunomiya",
                "K. Aihara"
            ],
            "title": "A fully programmable 100-spin coherent ising machine with all-to-all connections",
            "venue": "Science, vol. 354, no. 6312, pp. 614\u2013617, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "J. Chou",
                "S. Bramhavar",
                "S. Ghosh",
                "W. Herzog"
            ],
            "title": "Analog coupled oscillator based weighted ising machine",
            "venue": "Scientific reports, vol. 9, no. 1, p. 14786, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "T. Albash",
                "D.A. Lidar"
            ],
            "title": "Demonstration of a scaling advantage for a quantum annealer over simulated annealing",
            "venue": "Physical Review X, vol. 8, no. 3, p. 031016, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "L. Henriet",
                "L. Beguin",
                "A. Signoles",
                "T. Lahaye",
                "A. Browaeys",
                "G.-O. Reymond",
                "C. Jurczak"
            ],
            "title": "Quantum computing with neutral atoms",
            "venue": "Quantum, vol. 4, p. 327, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "D. Bertsekas"
            ],
            "title": "Convex optimization theory",
            "venue": "Athena Scientific,",
            "year": 2009
        },
        {
            "authors": [
                "K.G. Murty",
                "S.N. Kabadi"
            ],
            "title": "Some NP-complete problems in quadratic and nonlinear programming",
            "venue": "Mathematical Programming, vol. 39, no. 2, pp. 117\u2013129, 1987.",
            "year": 1987
        },
        {
            "authors": [
                "P.A. Parrilo"
            ],
            "title": "Structured Semidefinite Programs and Semialgebraic Geometry Methods in Robustness and Optimization",
            "venue": "Ph.D. dissertation, Massachusetts Inst. of Technology, 2000.",
            "year": 2000
        },
        {
            "authors": [
                "J.B. Lasserre"
            ],
            "title": "Global optimization with polynomials and the problem of moments",
            "venue": "SIAM Journal on optimization, vol. 11, no. 3, pp. 796\u2013817, 2001.",
            "year": 2001
        },
        {
            "authors": [
                "M. D\u00fcr",
                "F. Rendl"
            ],
            "title": "Conic optimization: a survey with special focus on copositive optimization and binary quadratic problems",
            "venue": "EURO Journal on Computational Optimization, vol. 9, p. 100021, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S. Burer"
            ],
            "title": "Copositive programming",
            "venue": "Handbook on semidefinite, conic and polynomial optimization. Springer, 2012, pp. 201\u2013218.",
            "year": 2012
        },
        {
            "authors": [
                "M. D\u00fcr"
            ],
            "title": "Copositive programming\u2013a survey",
            "venue": "Recent advances in optimization and its applications in engineering. Springer, 2010, pp. 3\u201320.",
            "year": 2010
        },
        {
            "authors": [
                "S. Boyd",
                "L. Vandenberghe"
            ],
            "title": "Localization and cutting-plane methods",
            "venue": "From Stanford EE 364b lecture notes, 2007.",
            "year": 2007
        },
        {
            "authors": [
                "L.A. Rademacher"
            ],
            "title": "Approximating the centroid is hard",
            "venue": "Proceedings of the twenty-third annual symposium on Computational geometry, 2007, pp. 302\u2013305.",
            "year": 2007
        },
        {
            "authors": [
                "A.Y. Levin"
            ],
            "title": "An algorithm for minimizing convex functions",
            "venue": "Doklady Akademii Nauk, vol. 160, no. 6. Russian 19 Academy of Sciences, 1965, pp. 1244\u20131247.",
            "year": 1965
        },
        {
            "authors": [
                "N.Z. Shor"
            ],
            "title": "Cut-off method with space extension in convex programming problems",
            "venue": "Cybernetics, vol. 13, no. 1, pp. 94\u201396, 1977.",
            "year": 1977
        },
        {
            "authors": [
                "D.B. Yudin",
                "A.S. Nemirovski"
            ],
            "title": "Evaluation of the information complexity of mathematical programming problems",
            "venue": "Ekonomika i Matematicheskie Metody, vol. 12, pp. 128\u2013142, 1976.",
            "year": 1976
        },
        {
            "authors": [
                "L.G. Khachiyan"
            ],
            "title": "Polynomial algorithms in linear programming",
            "venue": "USSR Computational Mathematics and Mathematical Physics, vol. 20, no. 1, pp. 53\u201372, 1980.",
            "year": 1980
        },
        {
            "authors": [
                "L.G. Khachiyan",
                "S.P. Tarasov",
                "I. Erlikh"
            ],
            "title": "The method of inscribed ellipsoids",
            "venue": "Soviet Math. Dokl, vol. 37, no. 1, 1988, pp. 226\u2013230.",
            "year": 1988
        },
        {
            "authors": [
                "Y. Nesterov",
                "A. Nemirovski"
            ],
            "title": "Self-concordant functions and polynomial time methods in convex programming",
            "venue": "USSR Academy of Sciences, Central Economic&Mathematical Institute, Moscow, 1989.",
            "year": 1989
        },
        {
            "authors": [
                "P.M. Vaidya"
            ],
            "title": "A new algorithm for minimizing convex functions over convex sets",
            "venue": "30th Annual Symposium on Foundations of Computer Science. IEEE Computer Society, 1989, pp. 338\u2013343.",
            "year": 1989
        },
        {
            "authors": [
                "D.S. Atkinson",
                "P.M. Vaidya"
            ],
            "title": "A cutting plane algorithm for convex programming that uses analytic centers",
            "venue": "Mathematical Programming, vol. 69, no. 1, pp. 1\u201343, 1995.",
            "year": 1995
        },
        {
            "authors": [
                "D. Bertsimas",
                "S. Vempala"
            ],
            "title": "Solving convex programs by random walks",
            "venue": "Journal of the ACM (JACM), vol. 51, no. 4, pp. 540\u2013556, 2004.",
            "year": 2004
        },
        {
            "authors": [
                "Y.T. Lee",
                "A. Sidford",
                "S.C.-w. Wong"
            ],
            "title": "A faster cutting plane method and its implications for combinatorial and convex optimization",
            "venue": "2015 IEEE 56th Annual Symposium on Foundations of Computer Science. Ieee, 2015, pp. 1049\u20131065.",
            "year": 2015
        },
        {
            "authors": [
                "C. Guo",
                "M. Bodur",
                "J.A. Taylor"
            ],
            "title": "Copositive duality for discrete markets and games",
            "venue": "arXiv preprint arXiv:2101.05379, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "R. Badenbroek",
                "E. de Klerk"
            ],
            "title": "An analytic center cutting plane method to determine complete positivity of a matrix",
            "venue": "INFORMS Journal on Computing, vol. 34, no. 2, pp. 1115\u20131125, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "K.M. Anstreicher"
            ],
            "title": "Testing copositivity via mixed\u2013integer linear programming",
            "venue": "Linear Algebra and its Applications, vol. 609, pp. 218\u2013230, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "M. D\u00fcr",
                "J.-B. Hiriart-Urruty"
            ],
            "title": "Testing copositivity with the help of difference-of-convex optimization",
            "venue": "Mathematical Programming, vol. 140, no. 1, pp. 31\u201343, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "J.-B. Hiriart-Urruty",
                "A. Seeger"
            ],
            "title": "A variational approach to copositive matrices",
            "venue": "SIAM review, vol. 52, no. 4, pp. 593\u2013629, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "C. Br\u00e1s",
                "G. Eichfelder",
                "J. J\u00fadice"
            ],
            "title": "Copositivity tests based on the linear complementarity problem",
            "venue": "Computational Optimization and Applications, vol. 63, no. 2, pp. 461\u2013493, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "W. Xia",
                "J.C. Vera",
                "L.F. Zuluaga"
            ],
            "title": "Globally solving nonconvex quadratic programs via linear integer programming techniques",
            "venue": "INFORMS Journal on Computing, vol. 32, no. 1, pp. 40\u201356, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "F. Khosravi",
                "U. Yildiz",
                "A. Scherer",
                "P. Ronagh"
            ],
            "title": "Non-convex quadratic programming using coherent optical networks",
            "venue": "arXiv preprint arXiv:2209.04415, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "E. De Klerk",
                "D.V. Pasechnik"
            ],
            "title": "Approximation of the stability number of a graph via copositive programming",
            "venue": "SIAM Journal on Optimization, vol. 12, no. 4, pp. 875\u2013892, 2002.",
            "year": 2002
        },
        {
            "authors": [
                "T.F. R\u00f8nnow",
                "Z. Wang",
                "J. Job",
                "S. Boixo",
                "S.V. Isakov",
                "D. Wecker",
                "J.M. Martinis",
                "D.A. Lidar",
                "M. Troyer"
            ],
            "title": "Defining and detecting quantum speedup",
            "venue": "science, vol. 345, no. 6195, pp. 420\u2013424, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "R. Quintero",
                "D. Bernal",
                "T. Terlaky",
                "L.F. Zuluaga"
            ],
            "title": "Characterization of QUBO reformulations for the maximum k-colorable subgraph problem",
            "venue": "Quantum Information Processing, vol. 21, no. 3, pp. 1\u201336, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "S. Kim",
                "M. Kojima"
            ],
            "title": "Strong duality of a conic optimization problem with two cones and a single equality constraint",
            "venue": "arXiv preprint arXiv:2111.03251, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S. Karimi",
                "P. Ronagh"
            ],
            "title": "Practical integer-to-binary mapping for quantum annealers",
            "venue": "Quantum Information Processing, vol. 18, no. 4, pp. 1\u201324, 2019.",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "approximately searching for the ground state of Ising spin Hamiltonians. The promise of leveraging such technologies to accelerate the solution of difficult optimization problems has spurred an increased interest in exploring methods to integrate Ising problems as part of their solution process, with existing approaches ranging from direct transcription to hybrid quantum-classical approaches rooted in existing optimization algorithms. While it is widely acknowledged that quantum computers should augment classical computers, rather than replace them entirely, comparatively little attention has been directed toward deriving analytical characterizations of their interactions. In this paper, we present a formal analysis of hybrid algorithms in the context of solving mixed-binary quadratic programs (MBQP) via Ising solvers. We show the exactness of a convex copositive reformulation of MBQPs, allowing the resulting reformulation to inherit the straightforward analysis of convex optimization. We propose to solve this reformulation with a hybrid quantum-classical cutting-plane algorithm. Using existing complexity results for convex cutting-plane algorithms, we deduce that the classical portion of this hybrid framework is guaranteed to be polynomial time. This suggests that when applied to NP-hard problems, the complexity of the solution is shifted onto the subroutine handled by the Ising solver.\n1. Introduction. Recent years have seen significant advances in quantum and quantum-inspired Ising solvers, such as quantum annealers [1], quantum approximate optimization circuits [2], or coherent Ising machines [3]. These are devices/methodologies designed to solve optimization problems of the form: minz\u2208{\u22121,1}n \u2211 i,j Ji,jzizj + \u2211 i hizi, where Ji,j , hi are real coefficients and zi \u2208 {\u22121, 1} are discrete variables to be optimized over. The promise of leveraging such technologies to speed up the solution of complex optimization problems has spurred many researchers to explore how Ising solvers can be applied to problems in various domains.\nA standard approach has emerged where an optimization problem is directly transcribed into an Ising problem, and the returned solution is taken at face value or with minimal post-processing. While this method works well for problems that organically have an Ising form, sequences of reformulations can result in ill-conditioning of the problem in terms of the number of additional variables, the coupling strengths, and the optimization landscape. Most unnaturally, however, relying solely on the Ising solver means forgoing the advantages of already powerful classical computers.\nIn an effort to introduce meaningful interplay between classical and quantum computers, a few authors have proposed decomposition methods based on the Alternating Direction Method of Multipliers (ADMM), [4], or Benders Decomposition (BD), [5, 6, 7]. Critically, when ADMM is applied to non-convex problems, it is not guaranteed to converge. When it does, it is often to a local optimum without convergence guarantees to global optimality. On the other hand, while it may be possible to derive optimality guarantees using BD, proving convergence typically relies on an exhaustive search through the \u201ccomplicating variables\u201d. This makes it unclear whether such an algorithmic scaffold is primed to take advantage of speed-ups that the Ising solver may offer.\nContributions. Our work is motivated by the desire to rigorously analyze the interplay between classical and quantum machines in hybrid algorithms. Such analysis is a cornerstone for articulating and setting standards for hybrid quantum-classical optimization algorithms. Specifically, we espouse convergent hybrid quantum-classical algorithms that (1) use Ising solvers as a primitive while offering some resilience to their heuristic nature and (2) have polynomial complexity in the classical portions of the algorithm. To this end, the contribution of this paper is an algorithmic framework that satisfies these key desiderata. Concretely,\n1. We revisit and prove strong duality of a result in [8] to show that the convex copositive formulation of many mixed-binary quadratic optimization problems is exact. Neglecting the challenges of working with copositive matrices, convex programs are a well-understood class of optimization problems with a wide variety of efficient solution algorithms. By reformulating mixed-binary quadratic programs as copositive programs, we open the door for hybrid-quantum classical algorithms that are based on existing convex optimization algorithms. 2. To solve the copositive programs, we propose a novel hybrid quantum-classical optimization algorithm based on cutting-plane algorithms, a well-established class of convex optimization\n\u2217 Stanford University, Autonomous Systems Laboratory \u2020 USRA Research Institute for Advanced Computer Science (RIACS) \u2021 NASA Quantum Artificial Intelligence Laboratory (QuAIL)\nar X\niv :2\n20 7.\n13 63\n0v 2\n[ m\nat h.\nO C\n] 2\n6 M\nay 2\n02 3\nalgorithms. We show that the complexity of the portion of the algorithm handled by the classical computer has polynomial scaling. This analysis suggests that when applied to NPhard problems, the complexity of the solution is shifted onto the subroutine handled by the Ising solver. 3. We conducted benchmarking based on the maximum clique problem to validate our theoretical claims and evaluate potential speed-ups from using a stochastic Ising solver in lieu of a state-of-the-art deterministic solver or an Ising heuristic. Results indicate that the Ising formulation of the subproblems of the hybrid algorithm is efficient versus a MIP formulation in Gurobi, and the hybrid algorithm is competitive even against a non-hybridized Ising formulation of the full problem solved by simulated annealing. While preparing this manuscript, a hybrid quantum-classical method relying upon a Frank-Wolfe method was published [9]. This work also leverages a similar copositive reformulation of quadratic binary optimization problems. We highlight the differences between that work and the one in our manuscript below. This manuscript considers the optimization problem class of mixed-binary quadratic programs, while in [9], the authors propose their method for quadratic binary optimization problems, a subcase of the problems considered herein. Moreover, we provide proof of the exactness and strong duality for copositive/completely positive optimization stemming from the mixed-integer quadratic reformulation, addressing an open question in the field. In their manuscript, [9] conjectures the results proved in this manuscript to be true. Finally, our solution method, which is based on cutting-plane algorithms, has a potential exponential speed-up in runtime compared to Frank-Wolfe algorithms.\n1.1. Related Work. One dominant method for mapping optimization problems into Ising problems is through direct transcription. This process typically involves discretizing continuous variables and passing constraints into the objective through a penalty function; the returned solution is often taken at face value or with minimal post-processing to enforce feasibility. Owing to its simplicity, this process has found applications in a variety of problems, including jobshop scheduling [10], routing problems [11], community detection [12], and all of Karp\u2019s 21 NP-complete models [13], among others. Critically, unless a problem organically takes an Ising form, this approach often requires many auxiliary variables (spins), introduces large skews in the coupling coefficients, and can result in poor conditioning of the optimization landscape, thus limiting the problems that can be solved on near-term devices. Similarly, extending the class of applicable problem instances requires deriving increasingly complex sequences of reformulations, each of which reduces the solubility of the final reformulation. More importantly, an algorithm with minimal interactions between classical and quantum computers disregards the bountiful successes of classical computers in the past decades. This has inspired some researchers to examine how quantum computers can be used to augment classical computers instead of replacing them entirely [14].\nAs an alternative to direct transcription, there is a burgeoning body of literature exploring the potential of decomposition methods for designing hybrid quantum-classical algorithms. These generally refer to algorithms that divide effort between a classical and quantum computer, with each computer informing the computation carried out by the other. Among these, algorithms based on the Benders Decomposition (BD) are gaining traction. BD is particularly effective for problems characterized by \u201ccomplicating variables\u201d, for which the problem becomes easy once these variables are fixed. For example, a mixed-integer linear program (MILP) becomes a linear program (LP) once the integer variables are fixed\u2013the integers are the complicating variables. BD iterates between solving a master problem over the complicating variables and sub-problems where the complicating variables are fixed, whose solution is used to generate cuts for the master problem. Both [5] and [6] consider mixed-integer programming (MIP) problems where the integer variables are linked to the continuous variables through a polyhedral constraint and leverage a reformulation where dependence on the continuous variables is expressed as constraints over the extreme rays and points of the original feasible region. Because the number of extreme rays and points may be exponentially large, the constraints are not written down in full but are iteratively generated from the solutions of the sub-problems. The master problem is an integer program consisting of these constraints and is solved using the quantum computer. Notably, the generated constraint set may be large, with the worst case being the generation of the entire constraint set, resulting in a large number of iterations. The approach in [7] attempts to mitigate this by generating multiple cuts per iteration and selecting the most informative subset of these cuts. Instead of using the quantum computer to solve the master problem, the quantum computer is used to heuristically select cuts based on a minimum set cover or maximum coverage metric. While this may effectively reduce the number of iterations and size of the constraint set, the\nmaster problem is often an integer program that may be computationally intractable. For each of the proposed approaches, it is unclear how the complexity of the problem is distributed through the solution process\u2013for example, for [5, 6] the complexity might show up in the number of iterations, and for [7] it might show up when solving the master problem. Consequently, it is ambiguous whether BD-based approaches can take advantage of a speed-up in the Ising solver, even if one were to exist.\nAnother decomposition that has been explored is based on the Alternating Direction Method of Multipliers (ADMM)[4]. This is an algorithm to decompose large-scale optimization problems into smaller, more manageable sub-problems [15]. While originally designed for convex optimization, ADMM has shown great success as a heuristic for non-convex optimization as well, [16], and significant progress has been made towards explaining its success in such settings [17]. In [4], the authors propose an ADMM-based decomposition with three sub-problems: the first being over just the binary variables, the second being the full problem with a relaxed copy of the binary variables, and the third being a term that ties the binary variables and their relaxed copies together. For quadratic pure-binary problems, the authors show that the algorithm converges to a stationary point of the augmented Lagrangian, which may not be a global optimizer\u2013convergence to a global optimum is only guaranteed under the more stringent Kurdyka- Lojasiewicz conditions on the objective function [18]. Unfortunately, the assumptions guaranteeing convergence to a stationary point fail in the presence of continuous variables.\nA third class of decomposition proposed and implemented in the qbsolv solver is based on tabu search [19]. qbsolv can be seen as iterating between a large-neighborhood local search (using an Ising solver) and tabu improvements to locally refine the solution (using a classical computer), where previously found solutions are removed from the search space in each iteration. During the local search phase, subsets of the variables are jointly optimized while the remaining variables are fixed to their current values. The solution found in this phase is then used to initialize the tabu search algorithm, and the process is repeated for a fixed number of iterations. Critically, it is unclear whether the algorithm is guaranteed to converge and, if so, what its optimality guarantees are. While finite convergence of tabu search is investigated in [20], it relies on either recency or frequency memory that ensures an exhaustive search of all potential solutions.\nAnother approach for purely integer programming problems is based on the computation of a Graver basis through the computation of the integer null-space of the constraint set as proposed in [21]. This null-space computation is posed as a quadratic unconstrained binary optimization (QUBO) and then post-processed to obtain the Graver basis of the constraint set, a test-set of the problem. The test-set provides search directions for an augmentation-based algorithm. For a convex objective, it provides a polynomial oracle complexity in converging to the optimal solution. The authors initialize the problem by solving a feasibility-based QUBO and extend this method to non-convex objectives by allowing multiple starting points for the augmentation. The multistart procedure also alleviates the requirement for computing the complete Graver basis of the problem, which grows exponentially with the problem\u2019s size. Considering an incomplete basis or non-convex objectives makes the Graver Augmentation Multistart Algorithm (GAMA) a heuristic for general integer programming problems, and it cannot address problems with continuous variables.\nIn this paper, we seek to address a gap in the literature on a rigorous theory of hybrid quantumclassical optimization. By elucidating the hidden convex structure of non-convex problems, we pave the way for hybrid algorithms based on efficient convex optimization. We show that algorithms derived through this approach inherit the straightforward analysis of convex optimization without sacrificing the potential benefits of quantum computing for non-convex problems.\n1.2. Quantum/Quantum-inspired Ising Solvers. Adiabatic quantum computing (AQC) is a quantum computation paradigm that operates by initializing a system in the ground stateof an initial Hamiltonian (i.e., the optimal solution of the corresponding objective function) and slowly sweeping the system to an objective Hamiltonian. This Hamiltonian, referred to as the cost Hamiltonian, maps the objective function of the classical Ising model onto a system with as many quantum bits, or qubits, as original variables in the Ising model. The adiabatic theorem of quantum mechanics states that if the system evolution is \u201csufficiently slow\u201d, the system ends up in the ground state of the desired Hamiltonian. Here, \u201csufficiently slow\u201d depends on the minimum energy gap between the ground and the first excited state throughout the system evolution [22]. Since the evaluation of the minimal gap is mostly intractable, one is forced to phenomenologically \u201cguess\u201d the evolution\u2019s speed, and if it is too fast, the undesired non-adiabatic transitions can occur. Additionally, real devices are plagued with various incarnations of physical noise, such as thermal fluctuations or decoherence effects, that can hamper computation. The situation is further exacerbated by the challenge of\nachieving dense connectivity between qubits\u2013densely connected problems are embedded in devices by chaining together multiple physical qubits to represent one logical qubit. The heuristic computational paradigm that encompasses the additional noise and non-quantum effects is known as Quantum Annealing (QA)\u2013 [23] provides a review on QA with a focus on possible routes towards solving the open questions in the field.\nAn alternative paradigm to AQC is the gate-based model of quantum computing. Within the gate-based model, Variational Quantum Algorithms (VQAs) is a class of hybrid quantum-classical algorithms that can be applied to optimization [24]. VQAs share a common operational principle where the \u201closs function\u201d of a parameterized quantum circuit is measured on a quantum device and evaluated on a classical processor, and a classical optimizer is used to update (or \u201ctrain\u201d) the circuit\u2019s parameters to minimize the loss. VQAs are often interpreted as a quantum analog to machine learning, leaving many similar questions open regarding their trainability, accuracy, and efficiency. Most similar in spirit to this work is a theory of variational hybrid quantum-classical algorithms proposed in [25]. However, they primarily focus on algorithmic improvements to the quantum portion, with discussion of the classical optimization being limited to empirical evaluations of existing derivative-free optimization algorithms. More recently, [26] analyzed the complexity of training VQAs, and through reductions from the maximum cut problem, showed that it is NP-hard. The analysis presented in this paper complements these prior works in developing a more complete picture of the interplay between quantum and classical computers.\nThe quantum approximate optimization algorithm (QAOA) is a specific instance of a VQA where the structure of the quantum circuit is the digital analog of adiabatic quantum computing [2]. QAOA operates by alternating the application of the cost Hamiltonian and a mixing Hamiltonian; the number of alternating blocks is referred to as the circuit depth. For each one of the alternating steps, either mixing or cost application, a classical optimizer needs to determine how long each step should be performed, encoded as rotation angles. Optimizing the expected cost function with respect to the rotation angles is a continuous low-dimensional non-convex problem. QAOA is designed to optimize cost Hamiltonians, such as the ones derived from classical Ising problems. Performance guarantees can be derived for QAOA with well-structured problems, given that the optimal angles are found in the classical optimization step. Although approximation guarantees have not been derived for arbitrary cost Hamiltonians, even depth-one QAOA circuits have non-trivial performance guarantees for specific problems and cannot be efficiently simulated on classical computers [27], thus bolstering the hope for a speed-up in near-term quantum machines. Moreover, the algorithm\u2019s characteristics, such as relatively shallow circuits, make it amenable to be implemented in currently available noisy intermediate-scale quantum (NISQ) computers compared to other algorithms requiring fault-tolerant quantum devices [28]. While QAOA\u2019s convergence to optimal solutions is known to improve with increased circuit depth and to succeed in the infinite depth limit following its equivalence to AQC, its finite depth behavior has remained elusive due to the challenges in analyzing quantum many-body dynamics and other practical complications such as decoherence when implementing long quantum circuits, compilation issues, and hardness of the optimal angle classical problem [29]. Even considering these complications, QAOA has been extensively studied and implemented in current devices [30, 31], becoming one of the most popular alternatives to address combinatorial optimization problems modeled as Ising problems using gate-based quantum computers. Several other quantum heuristics for Ising problems have been proposed, usually requiring fault-tolerant quantum computers. We direct the interested reader to a recent review on the topic [32].\nAn alternative physical system for solving Ising problems that has emerged is coherent Ising machines (CIMs), which are optically pumped networks of coupled degenerate optical parametric oscillators. As the pump strength increases, the equilibrium states of an ideal CIM correspond to the Ising Hamiltonian\u2019s ground states encoded by the coupling coefficients. Large-scale prototypes of CIMs have achieved impressive performance in the lab, thus driving the theoretical study of their fundamental operating principles. While significant advances have been made on this front, we still lack a clear theoretical understanding of the CIMs\u2019 computational performance. Since a thorough understanding of the CIM is limited by our capacity to prove theorems about complex dynamic systems, near-term usage of CIMs must treat them as a heuristic rather than a device with performance guarantees [33]. Even so, there are empirical observations that in many cases, the median complexity of solving Ising problems using CIM scales as exp \u221a N where N is the size of the problem [34], making it a potential approach to solve these problems efficiently in practice. We note that there are other types of Ising machines, including classical thermal annealers (based on magnetic devices [35], optics [36], memristors [37], and digital hardware accelerators [38]), dynamical-systems solvers (based on\noptics [39] and electronics [40]), superconducting-circuit quantum annealers [41], and neutral atoms arrays [42]. We direct the interested reader to [34], which provides a recent review and comparison of various methods for constructing Ising machines and their operating principles.\nWhile there is optimism regarding improvements to and our understanding of quantum technology in the coming decades, few expect that they will replace classical computers entirely. We believe that the method presented in this paper is an approach to algorithm design that anticipates a future where quantum computers and classical computers work in tandem. In particular, we envision a mature theory of hybrid algorithms that clearly delineates how quantum and classical computers should complement each other.\nOrganization. In Section 2, we present notation, terminology, and the problem setting covered by our approach. In Section 3, we introduce the proposed framework, including convex reformulation via copositive programming, a high-level overview of cutting-plane algorithms, and a specific discussion of their application to copositive programming. Section 4 provides numerical experiments supporting our assertions about the proposed approach. Finally, we conclude and highlight future directions in Section 5.\n2. Preliminaries.\n2.1. Notation and Terminology. In this paper, we solely work with vectors and matrices defined over the real numbers and reserve lowercase letters for vectors and uppercase letters for matrices. We will also follow the convention that a vector x \u2208 Rn is to be treated as a column vector, i.e., equivalent to a matrix of dimension n\u00d7 1. For a matrix M , we use Mi,j to denote the entry in the ith row and jth column, Mi,\u2217 denotes the entire ith row, and M\u2217,j denotes the entire jth column. In the text, we frequently use block matrices with structured zero entries; we use \u00b7 as shorthand for zero entries. We use 1 to denote the all-ones vectors and 1{j} to denote the jth standard basis vector (i.e., a vector where all entries are zero except for a 1 for the jth entry). The p-norm of a vector\nv \u2208 Rn is defined as \u2225v\u2225p := ( \u2211n i=1 v p i ) 1/p . We reserve the letter I to denote the identity matrix. For two matrices, M and N , we use \u27e8M, N\u27e9 = Tr(M\u22a4N) to denote the matrix inner product. Note that for two vectors, Tr(x\u22a4y) = x\u22a4y because x\u22a4y is a scalar, so the matrix inner product is consistent with the standard inner product on vectors. For sets, SM + SN := {M + N | M \u2208 SM , N \u2208 SN} is their Minkowski sum, SM \u222a SN their union, and SM \u2229 SN their intersection. For a cone, K, its dual cone is defined as K\u2217 = {X | \u27e8X, K\u27e9 \u2265 0,\u2200K \u2208 K}. While we work with matrix cones in this paper, this definition of dual cones is consistent with vector cones as well. In this paper, the two cones we will work with are the cone of completely positive matrices and the cone of copositive matrices. The cone of completely positive (CP) matrices, C\u2217, is the set of matrices that have a factorization with entry-wise non-negative entries:\n(2.1) C\u2217n := {X \u2208 Rn\u00d7n | X = \u2211 k x(k)(x(k))\u22a4, x(k) \u2208 Rn\u22650}\nThe cone of copositive matrices, C, is the set of matrices defined by: (2.2) Cn := {X \u2208 Rn\u00d7n | v\u22a4Xv \u2265 0, \u2200v \u2208 Rn\u22650} As suggested by the notation, the cones of completely positive and copositive matrices are duals of each other. We use Sn++ to denote the cone of positive definite matrices.\nIn this paper, we will use the terms Ising problem and quadratic unconstrained binary optimization (QUBO) interchangeably. An Ising problem is an optimization problem of the form: minz\u2208{\u22121,1}n \u2211 i,j Ji,jzizj + \u2211 i hizi, where Ji,j , hi are real coefficients and zi \u2208 {\u22121, 1} are discrete variables to be optimized over. A QUBO, which is an optimization problem of the form minx\u2208{0, 1}n \u2211 i,j Qi,jxixj can be reformulated as an Ising problem using the change of variable\nz = 2x \u2212 1. This translates to coefficients in the Ising problem Ji,j = 14Qi,j , hi = 12 \u2211 j Qi,j ,\nand a constant offset of 14 \u2211 i,j Qi,j .\n2.2. Problem Setting. In this paper, we consider mixed-binary quadratic programs (MBQP) of the form:\n(MBQP)\nminimize x \u2208 Rn\nx\u22a4Qx + 2c\u22a4x\nsubject to Ax = b, A \u2208 Rm\u00d7n, b \u2208 Rm, x \u2265 0, xj \u2208 {0, 1}, j \u2208 B\nwhere the set B \u2286 {1, . . . , n} indexes which of the n variables are binary. This is a general class of problems that encompasses problems including QUBOs, standard quadratic programming, the maximum stable set problem, and the quadratic assignment problem. Because mapping to an Ising problem can also be equivalently expressed as a QUBO, many problems tackled with Ising solvers thus far pass through a formulation similar to the form of Problem (MBQP). Using the result in [8, Sec. 3.2], the formulation considered in this paper can be extended to include constraints of the form xixj = 0 that force at least one of xi or xj to be zero, i.e., complementarity constraints. For ease of notation, this extension is left out of the present discussion.\n3. Proposed Methodology. In this section, we will discuss our proposed methodology for solving Problem (MBQP) given access to Ising solvers. Our result relies on a convex reformulation of Problem (MBQP) as a copositive program. Leveraging convexity, we propose to solve the problem using cutting-plane algorithms. These belong to a broad class of convex optimization algorithms whose standard components give rise to a natural separation between the role of the Ising solver versus a classical computer.\nWe first state Burer\u2019s exact reformulation of Problem (MBQP) as a completely positive program and its dual copositive program. We then show that under mild conditions (i.e., feasibility and boundedness) of the original MBQP, the copositive and completely positive programs exhibit strong duality. We will then introduce the class of cutting-plane algorithms and summarize the complexity guarantees of several well-known variants. Finally, we explicitly show how cutting-plane algorithms can be used to solve copositive optimization problems given a copositivity oracle and discuss how to implement a copositivity oracle using an Ising solver.\n3.1. Convex formulation as a copositive program. In his seminal work, Burer showed that MBQPs can be represented exactly as completely positive programs of the form:\n(CPP)\nminimize X \u2208 Rn\u00d7n, x \u2208 Rn\n\u2329( Q c\nc\u22a4 \u00b7\n) , ( X x\nx\u22a4 1 )\u232a subject to \u2329( \u00b7 12A \u22a4 i,\u2217\n1 2Ai,\u2217 \u00b7\n) , ( X x\nx\u22a4 1 )\u232a = bi, i = 1, . . . ,m,\u2329(\nA\u22a4i,\u2217Ai,\u2217 \u00b7 \u00b7 \u00b7\n) , ( X x\nx\u22a4 1 )\u232a = b2i , i = 1, . . . ,m,\u2329(\n\u22121{j}1{j}\u22a4 121{j} 1 21{j} \u22a4 \u00b7\n) , ( X x\nx\u22a4 1 )\u232a = 0, j \u2208 B,(\nX x x\u22a4 1 ) \u2208 C\u2217n+1,\nwhere exactness means that Problems (MBQP) and (CPP) have the same optimal objective and for an optimal solution, (x\u2217, X\u2217), of (CPP), x\u2217 lies within the convex hull of optimal solutions for (MBQP) [8, Theorem 2.6]. Similar to semi-definite programming (SDP) relaxations, the completely positive formulation involves lifting the variables in (MBQP) to a matrix variable representing their first and second-degree monomials, making the objective function and constraints linear. Unlike SDP relaxations, however, the complete positivity constraint is sufficient for ensuring that the feasible region of (CPP) is exactly the convex hull of the feasible region of (MBQP). This distinction is what ensures that the optimal value of (CPP) is exactly that of (MBQP), whereas for an SDP relaxation, the optimal solution may lie outside of the convex hull of (MBQP), resulting in a lower objective value (i.e., a relaxation gap).\nTaking the dual of (CPP) yields a copositive optimization problem of the form [43, Section 5.9]:\n(COP) maximize \u00b5, \u03bb, \u03b3 \u03b3 + m\u2211 i=1 \u00b5 (lin) i bi + \u00b5 (quad) i b 2 i\nsubject to M(\u00b5, \u03bb, \u03b3) \u2208 Cn+1,\nwhere\n(3.1)\nM(\u00b5, \u03bb, \u03b3) := ( Q c\nc\u22a4 \u00b7\n) \u2212 m\u2211 i=1 \u00b5 (lin) i ( \u00b7 12A \u22a4 i,\u2217 1 2Ai,\u2217 \u00b7 ) \u2212 m\u2211 i=1 \u00b5 (quad) i ( A\u22a4i,\u2217Ai,\u2217 \u00b7 \u00b7 \u00b7 ) \u2212 \u2211 j\u2208B \u03bbj ( \u22121{j}1{j}\u22a4 121{j} 1 21{j} \u22a4 \u00b7 ) \u2212 \u03b3 ( \u00b7 \u00b7 \u00b7 1 )\nis a parametrized linear combination of the constraint matrices. The dual copositive program has a linear objective and a single copositivity constraint\u2014this is a convex optimization problem. While weak duality always holds between an optimization problem and its dual, strong duality is not generally guaranteed. Showing that strong duality holds is critical for ensuring convergence of specific optimization algorithms and exactness when solving the dual problem as an alternative to solving the primal.\nTheorem 3.1 (Strong Duality). If Problem (MBQP) is feasible with bounded feasible region, then strong duality holds between Problems (CPP) and (COP) (i.e., min (CPP) = max (COP)).\nProof Sketch. Our proof proceeds by first showing strong duality between the alternative representation of (CPP) (using a homogenized formulation of the equality constraints) and its dual. By showing that the optimal value of (COP) is lower-bounded by the optimal value of this homogenized dual problem, we can sandwich the optimal values of Problems (CPP) and (COP) by those of a primal-dual pair that has been shown to exhibit strong duality. The complete proof of this result is provided in Appendix 6.1.\nIn prior work, characterization of the duality gap between Problems (CPP) and (COP) has remained elusive because the feasible region of Problem (CPP) never has an interior, thus prohibiting straightforward application of Slater\u2019s constraint qualification. This result is significant because it shows that under mild conditions, the copositive formulation is exact. This means that the optimal values of Problems (MBQP) and (COP) are equivalent, so solving Problem (COP) is a valid alternative to solving Problem (MBQP). Moreover, the optimal solution of Problem (CPP) can be recovered from the optimal solution of Problem (COP) by optimizing the Lagrangian function with respect to the optimal dual variables [44, Prop 5.3.3], albeit by solving a completely positive program. The framework developed in this paper will ultimately produce approximate solutions for Problems (CPP) and (COP), which we anticipate can be used to speed up the solution process of a purely classical solver for (MBQP)\u2013how to do so is a question we leave to future work.\nWhile Problems (CPP) and (COP) are both convex, neither resolve the difficulty of Problem (MBQP) as even checking complete positivity (resp. copositivity) of a matrix is NP-hard (resp. coNP-complete) [45]. Instead, they should be viewed as \u201cpackaging\u201d the complexity of the problem entirely in the copositivity/complete positivity constraint. There are a number of classical approaches for (approximately) solving copositive/completely positive programs directly, such as the sum of squares hierarchy [46, 47], feasible descent method in the completely positive cone, approximations of the copositive cone by a sequence of polyhedral inner and outer approximations, among others [48, 49, 50]. In this paper, we will exploit the innate synergy between checking copositivity, which is most naturally posed as a quadratic minimization problem, and solving Ising problems. This perspective is suggestive of a hybrid quantum-classical approach where the quantum computer is responsible for checking feasibility (i.e., the \u201chard part\u201d) of the copositive program while the classical computer directs the search towards efficiently reducing the search space.\n3.2. Cutting-Plane/Localization Algorithms. Cutting-plane/localization algorithms are convex optimization algorithms that divide labor between checking feasibility\u2013abstracted as a separation oracle\u2013and optimization of the objective 1. In this section, we provide a high-level overview of each algorithmic step and summarize both the runtime and oracle complexities of several well-known variants; these complexity measures will ultimately correspond to the complexity of the sub-routine handled by the classical computer and the number of calls to the Ising solver, respectively.\nWhile cutting-plane algorithms are often used to solve both constrained and unconstrained optimization problems, they are generally evaluated in terms of their complexity when solving the feasibility problem.\nDefinition 3.2 (Feasibility Problem). For a set of interest S \u2282 Rm, which can only be accessed through a separation oracle, the feasibility problem is concerned with either finding a point in the set x \u2208 S or proving that S does not contain a ball of radius r.\nDefinition 3.3 (Separation Oracle). A separation oracle for a set S, OracleS(\u00b7) takes as input a point x \u2208 Rm and either returns True if x \u2208 S or a separating hyperplane if x \u0338\u2208 S. A separating\n1The term \u201ccutting-plane algorithm\u201d overloaded in the literature, with one class referring very explicitly to those designed for convex/quasi-convex optimization problems (for a pedagogical reference, we refer the interested reader to [51]) and the second referring more broadly to algorithms that iteratively generate cuts (including algorithms for integer programming and non-convex optimization). In this work, we refer specifically to those designed for convex/quasiconvex optimization.\nhyperplane is defined by a vector, a \u2208 Rm and scalar b \u2208 R such that a\u22a4s \u2264 b for all s \u2208 S but a\u22a4x \u2265 b. The feasibility problem formulation is non-restrictive because these methods can be readily adapted to solving quasi-convex optimization problems with only a simple modification to the separation oracle. In particular, if the separation oracle indicates feasibility and returns a vector g \u2208 Rm where any vectors x, y \u2208 Rm with f(y) < f(x) implies that g\u22a4y \u2265 g\u22a4x, this serves as a separating hyperplane for the subset of the feasible region that has a better objective than the test point. If f is subdifferentiable, any subgradient g \u2208 \u2202f(x) satisfies this condition, and for Problem (COP), choosing g as the objective\u2019s coefficient vector is sufficient.\nAlthough there are many variations of cutting-plane algorithms, at a high level, they follow a standard template that consists of alternating between checking feasibility of a test point, updating an outer approximation of the feasible region, and judiciously selecting the next test point. This standard template is summarized in Algorithm 1. An overview of the Ellipsoid algorithm is included in the Appendix as a representative example of cutting-plane algorithms, and we direct the interested reader to the references listed in Table 1 for specific implementation details. By choosing subsequent test points to be the center of the outer approximation, the algorithm is guaranteed to make consistent progress in reducing the search space (where the metric of progress may also vary across cuttingplane algorithms). Intuitively, cutting plane algorithms can be considered a high-dimensional analog of binary search.\nAlgorithm 1: Cutting-plane meta-algorithm (feasibility problem)\nInput: S0 \u2286 Rm (Initial Set) with Vol(S0) \u2264 R Output: x \u2208 S or False if S does not contain a ball of volume r x\u2190 Center(S0); k \u2190 0; while Oracle(x) is not True and Vol(Sk) \u2265 r do\nSk+1 \u2190 Add Cut(Sk, Oracle(x)); x\u2190 Center(Sk+1); k \u2190 k + 1;\nend if Oracle(x) is True then\nreturn x; else\nreturn False ; end\nA number of well-known variants of cutting-plane algorithms are summarized in Table 1. Differences across instantiations of cutting-plane algorithms vary in how subsequent test points are chosen, how the outer approximation is updated, and how progress in decreasing the outer approximation\u2019s size is measured. Each of the surveyed variants strikes a different balance between the computational effort needed to compute a good center versus the resolution used to represent the outer approximation. Critically, except for the Center of Gravity method, all cutting-plane algorithms summarized in Table 1 have a polynomial complexity in the dimension of the optimization variables in terms of both oracle queries and total runtime excluding the oracle calls (i.e., the total complexity of adding the cuts and generating test points). This suggests that if a cutting-plane algorithm were applied to Problem (COP), the complexity of the problem is offloaded onto the separation oracle\u2013this is the subroutine we propose to handle using an Ising solver.\n3.3. Application to copositive optimization. Now that we have introduced cutting-plane algorithms, we are in a position to discuss their application to the copositive program (COP). First, we will show how a copositivity oracle can be readily transformed into a separation oracle for the feasible region of Problem (COP). We will conclude with a discussion of how a copositivity oracle can be implemented using an Ising solver. Formally, we define a copositivity oracle as follows:\nDefinition 3.4 (Copositivity Oracle). A copositivity oracle takes as input a matrix, M , and either returns True if M is copositive or returns a vector z \u2208 Rn\u22650 such that z\u22a4Mz < 0 (a \u201ccertificate of non-copositivity\u201d).\nA copositivity oracle can be turned into a separation oracle for the feasible region of Problem\n(COP) by expanding the terms in z\u22a4M(\u00b5\u0302, \u03bb\u0302, \u03b3\u0302)z. Explicitly, a test point, (\u00b5\u0302, \u03bb\u0302, \u03b3\u0302), is infeasible if\nand only if M(\u00b5\u0302, \u03bb\u0302, \u03b3\u0302) is not copositive. Given M(\u00b5\u0302, \u03bb\u0302, \u03b3\u0302) as input, the copositivity oracle returns a certificate of non-copositivity z \u2208 Rn+1\u22650 such that z\u22a4M(\u00b5\u0302, \u03bb\u0302, \u03b3\u0302)z < 0. In contrast, feasibility means that z\u22a4M(\u00b5, \u03bb, \u03b3)z \u2265 0. Equivalently, the halfspace defined by\nb = z\u22a4 ( Q c\nc\u22a4 \u00b7\n) z,(3.2)\na[\u00b5 (lin) i ] = z\n\u22a4 ( \u00b7 12A \u22a4 i,\u2217\n1 2Ai,\u2217 \u00b7\n) z,(3.3)\na[\u00b5 (quad) i ] = z\n\u22a4 ( A\u22a4i,\u2217Ai,\u2217 \u00b7\n\u00b7 \u00b7\n) z,(3.4)\na[\u03bbj ] = z \u22a4 ( \u22121{j}1{j}\u22a4 121{j}\n1 21{j}\n\u22a4 \u00b7\n) z,(3.5)\na[\u03b3] = z\u22a4 ( \u00b7 \u00b7 \u00b7 1 ) z,(3.6)\nis a separating hyperplane for (\u00b5\u0302, \u03bb\u0302, \u03b3\u0302), where we use symbolic indexing to explicitly denote which variable each coefficient corresponds to. Explicitly, the inner product between a and (\u00b5, \u03bb, \u03b3) is given by\n(3.7) a\u22a4(\u00b5, \u03bb, \u03b3) = \u2211 i a[\u00b5 (lin) i ]\u00b5 (lin) i + \u2211 i a[\u00b5 (quad) i ]\u00b5 (quad) i + \u2211 j a[\u03bbj ]\u03bbj + a[\u03b3]\u03b3.\nThis shows that given a copositivity oracle, constructing a separation oracle for Problem (COP), of dimension O(m) and copositivity constraints on matrices of size O(n), entails evaluating O(m) vector-matrix-vector products, each of dimension O(n). The cutting-plane algorithms presented in Section 3.2 can then be applied without further modification.\nWe note that the application of cutting-plane algorithms to copositive optimization has been explored from a classical perspective in [63], which considered their application to discrete markets and games, and [64], which applied the algorithm to detect complete positivity of matrices. We believe our work is complementary to these prior works. While our work relies on the off-the-shelf application of well-known cutting-plane variants, the algorithmic modifications in [63], and [64] provide insight for further improving our framework. For example, the cutting plane algorithm in [63] is readily hybridized leveraging our proposed approach\u2013we do not explore this extension in this paper due to their lack of convergence guarantees, while those of the variants presented are central to our theoretical analysis. Moreover, the problem settings considered in these works serve as inspiration for additional applications that can be addressed with Ising solvers. On the other hand, the proof of strong duality (Theorem 3.1) can be applied to address questions that were left open in [63]. We emphasize that the contribution of this work is not the copositive reformulation or a novel cutting-plane algorithm but rather the insight that these ideas are synergistic with recent advances in quantum(-inspired) computing. In particular, copositive optimization is useful for deriving and analyzing new hybrid algorithms rooted in existing convex optimization algorithms, thus filling a gap in the hybrid algorithms literature.\nChecking copositivity of M(\u00b5, \u03bb, \u03b3) is naturally posed as the following (possibly non-convex) quadratic minimization problem\n(3.8)\nminimize z \u2208 Rn+1\u22650\nz\u22a4M(\u00b5, \u03bb, \u03b3)z\nsubject to ||z||p \u2264 1,\nwhere a matrix is copositive if and only if min (3.8) is non-negative2. There are several alternative approaches for checking copositivity [65, 66, 67, 68, 69]; however, they are typically derived with Problem (3.8) as the starting point and designed to exploit particular properties of Problem (3.8). By choosing p =\u221e, Problem (3.8) can be approximated by a QUBO where an approximation of the matrix M , M\u0302 , is used such that the optimization variables z\u0302 represent a binary expansion of z with k bits as follows:\n(QUBO) minimize z\u0302 z\u0302\u22a4M\u0302(\u00b5, \u03bb, \u03b3)z\u0302\nsubject to z\u0302 \u2208 {0, 1}k(n+1).\nExplicitly, M\u0302(\u00b5, \u03bb, \u03b3) and M(\u00b5, \u03bb, \u03b3) are related as follows:\nM\u0302(\u00b5, \u03bb, \u03b3) = D\u22a4M(\u00b5, \u03bb, \u03b3)D,(3.9)\nwhere\nD := 1 2k \u2212 1  20 \u00b7 \u00b7 \u00b7 2k\u22121 0 \u00b7 \u00b7 \u00b7 0 \u00b7 \u00b7 \u00b7 0 \u00b7 \u00b7 \u00b7 0 0 \u00b7 \u00b7 \u00b7 0 20 \u00b7 \u00b7 \u00b7 2k\u22121 \u00b7 \u00b7 \u00b7 0 \u00b7 \u00b7 \u00b7 0 ... ... ... ... ... ... ... ... ...\n... 0 \u00b7 \u00b7 \u00b7 0 0 \u00b7 \u00b7 \u00b7 0 \u00b7 \u00b7 \u00b7 20 \u00b7 \u00b7 \u00b7 2k\u22121  ,(3.10) The construction of (QUBO) is detailed in Appendix 6.2. The explicit implementation of Oracle(\u00b7) is summarized in Algorithm 2. Critically, the constraints of (3.8) are implied by the natural domain of the Ising solver, mitigating the need to tune coefficients in a penalty method carefully.\n3.4. Discussion. In summary, we propose to solve Problem (MBQP) by constructing the equivalent copositive formulation in (COP) and applying any variant of Algorithm 1. Within Algorithm 1, the implementation of Oracle(\u00b7) is specified by Algorithm 2. This process is depicted in Figure 1. Now that we have presented our method in full, several comments are in order.\nComputational complexity. While the stated complexity of the cutting-plane algorithms is applicable to any problem, it is suggestively stated in terms of the variable m. This notational overload is a deliberate choice because the dimension of the dual copositive program is equal to the total number of constraints in Problem (CPP), which is 2m + |B|+ 1 = O(m). The number of constraints can be\n2While copositivity is defined as a condition over all of Rn+1\u22650 , quadratic scaling of the objective ensures that optimizing over a norm ball is sufficient for detecting copositivity.\nAlgorithm 2: Separation oracle, Oracle(\u00b7) Input: (\u00b5\u0302, \u03bb\u0302, \u03b3\u0302) (Test point) Output: {\nTrue if (\u00b5\u0302, \u03bb\u0302, \u03b3\u0302) is feasible\nSeparating hyperplane for (\u00b5\u0302, \u03bb\u0302, \u03b3\u0302) otherwise\n// Solve (QUBO) using an Ising solver\nz\u2217 \u2190 arg min z\u0302\n(QUBO)\nif min (QUBO) \u2265 0 then return True ; else\nz = Dz\u2217(3.11) b = z\u22a4 ( Q c\nc\u22a4 \u00b7\n) z(3.12)\na[\u00b5 (lin) i ] = z\n\u22a4 ( \u00b7 12A \u22a4 i,\u2217\n1 2Ai,\u2217 \u00b7\n) z(3.13)\na[\u00b5 (quad) i ] = z\n\u22a4 ( A\u22a4i,\u2217Ai,\u2217 \u00b7\n\u00b7 \u00b7\n) z(3.14)\na[\u03bbj ] = z \u22a4 ( \u22121{j}1{j}\u22a4 121{j}\n1 21{j}\n\u22a4 \u00b7\n) z(3.15)\na[\u03b3] = z\u22a4 ( \u00b7 \u00b7 \u00b7 1 ) z(3.16)\nreturn a, b;\nend\nreduced to m + |B| + 1 using the homogenized completely positive reformulation presented in Appendix 6.1\u2013while this will have no impact on the asymptotic complexity of the method, it can result in a practical reduction in runtime. If TQ represents the oracle complexity of a particular method, the total additional overhead of converting the copositivity oracle into a separation oracle is given by O(mn2TQ).\nDiscretization size. Discretization of the copositivity check automatically introduces an approximation to the copositivity checks. The approximation fidelity is improved as the number of discretization points is increased, although it is limited by the hardware. Not only does representing a finer discretization require more qubits, but it also results in a greater skew in the coefficients of the Ising Hamiltonian\u2013this becomes challenging since many existing hardware platforms have limited precision in their implementable couplings. In contrast, too coarse of a discretization runs the risk of missing the certificate of non-copositivity entirely. This suggests that the discretization scheme should be well-tailored to the problem at hand; Appendix 6.2 provides guidance for choosing a discretization size based on the coefficients of the Ising Hamiltonian. A promising alternative is to circumvent discretization entirely, and apply quantum(-inspired) solvers that natively solve continuous variable box-constrained quadratic programs, such as the coherent continuous-variable machine (CCVM) recently proposed in [70].\nMultiple cuts. Following standard convention, this work assumes that the copositivity oracle returns a single value. In contrast, in practice, many of the aforementioned Ising solvers are heuristics that involve multiple readouts. Each of these reads can be used to construct a cut, where negative, zero, and positive Ising objective values correspond to deep, neutral, and shallow cuts, respectively. Adding multiple cuts during each iteration is a possible heuristic for improving the convergence rate of the cutting-plane algorithm. While the true ground state corresponds to the deepest cut, the convergence rate guarantees stated in Table 1 hold so long as a neutral or deep cut is added at each iteration. Consequently, the proposed approach is not overly reliant on the Ising solver\u2019s ability to\nidentify the ground state and is resilient to heuristics. Critically, this raises the question of how to proceed if the Ising solver fails to return a certificate of non-copositivity, which will likely depend on problem specifics, such as the current outer approximation, the objective values of the samples, and the solver itself. For example, if the Ising solver returns positive but small solutions, depending on the current outer approximation, the addition of shallow cuts can still reduce the search space. On the other hand, if all non-zero solutions result in a large objective value, one could increase confidence that the test point is feasible by increasing the number of discretization points and readouts.\n4. Experiments. We conducted an investigation of the proposed method on the maximum clique problem, which finds the largest complete subgraph of a graph. Given a graph, the maximum clique problem can be formulated as a completely positive program\n(4.1)\nmaximize X \u2208 Rn\u00d7n\n\u2329 11\u22a4, X \u232a subject to \u2329 A + I, X \u232a = 1,\nX \u2208 C\u2217n,\nwhere A is the adjacency matrix of the graph\u2019s complement [71]. The dual of (4.1) is the following copositive program:\n(4.2) minimize \u03bb \u2208 R \u03bb\nsubject to \u03bb(I + A)\u2212 11\u22a4 \u2208 Cn.\nThis copositive program only has one variable regardless of the graph\u2019s number of vertices or edges. However, the copositivity check\u2019s size is determined by the number of vertices, n, which impacts the complexity of computing the cuts from the certificates of non-copositivity. The number of edges can be used to upper-bound the size of the maximum clique, thus determining the size of the initial feasible region; however, its effect on the complexity of checking copositivity is unclear.\nTo study the scaling of the proposed approach, we considered random max-clique problems with 10, 30, . . . , 130 vertices. For each graph size, we generated 25 random Erdo\u030bs-Renyi instances with edge densities p \u2208 {0.25, 0.5, 0.75} and solved to global optimality using the proposed copositive cutting plane algorithm. All experiments were run on an AMD Ryzen 7 1800X Eight-Core Processor@3.6GHz with 64GB of RAM and 16 threads. All code needed to reproduce these experiments is available at https://github.com/StanfordASL/copositive-cutting-plane-max-clique.\nMany hybrid algorithms are designed by replacing subroutines of existing (fully classical) algorithms with a quantum(-inspired) counterpart. An oft-neglected consideration is whether the quantum(-inspired) computer is applied to a bottleneck in the original algorithm. We contend that for a hybrid algorithm to yield significant speed-ups, the quantized subroutine should constitute the bulk of the algorithm\u2019s complexity. In keeping with this supposition, we first evaluated whether the copositive cutting-plane algorithm shifts the complexity of the solution process onto the copositivity checks by profiling each component of the algorithm separately. The copositivity checks were conducted by solving Anstreicher\u2019s MILP characterization of copositivity [65] (which we found to be one of the most competitive classical formulations), using Gurobi version 9.0.3 [72]. Figure 3 plots the time the copositive cutting plane algorithm spent on the copositivity checks versus other operations (updating the outer approximation and computing test points). The time spent on the copositivity checks scales exponentially with the number of vertices in the graph, while the time spent on other operations grows modestly. This is because Problem (4.1) only has one constraint regardless of the graph\u2019s number of vertices or edges. In contrast, the size of the copositivity check is exactly equal to the number of vertices in the graph. Both the theoretical analysis and empirical results confirm that the proposed approach shifts the complexity of the copositive program onto the copositivity checks. This experiment shows that the proposed methodology is particularly effective for problems whose constraints remain constant or grow modestly with problem size.\nWhile undesirable for a fully classical implementation, the overwhelming complexity in the copositivity checks represents an opportunity for a quantum(-inspired) solver to beget significant speed-ups \u2013 they will result from being able to execute the copositivity checks faster than the classical implementation (i.e., Anstreicher\u2019s MILP formulation). To investigate potential speedups from using a stochastic Ising solver, we re-solved each copositivity check that yielded a certificate of non-copositivity using Simulated Annealing (SA) through the software Neal version 0.5.9, a SA sampler [73], i.e., a solver that returns samples on the solutions distribution generated by SA. Because SA is not guaranteed to find the global optima in a single annealing cycle, we define a probabilistic notion of time to target. In particular, we follow [74] and define the time to target with s confidence to be the number of repetitions to find the ground state at least once with probability s multiplied by the time for each annealing cycle, Tanneal, i.e.,\nTTTs = Tanneal log(1\u2212 s)\nlog(1\u2212 p\u0302succ) ,(4.3)\nwhere p\u0302succ is the expected value of the returned solution divided by the ground state/minimum. This results in a probability of success that interpolates between counting only solutions corresponding\nto the ground state and counting all certificates of non-copositivity as successes by considering the relative quality of each sample. We will also consider analogous scenarios where only ground state solutions are counted as success; we reserve the terminology \u201ctime to solution\u201d, TTSs = Tanneal log(1\u2212s)\nlog(1\u2212psucc) ,\nfor such cases to distinguish from the previously defined time to target. The values of p\u0302succ and psucc is evaluated empirically over 1000 samples/reads. The time per annealing cycle, Tanneal, was evaluated as the total wall-clock time (for all reads) divided by the number of reads. All other Neal parameters were left as their default values.\nFor each copositivity check solved, we considered discretizations corresponding to minz\u0302\u2208{0, 1}n z\u0302\n\u22a4Mz\u0302 (i.e., no additional problem discretization). We solved each copositivity check with 100 sweeps and 1000 reads3. Figure 4 plots the time to target with 99% confidence from Neal against the solution time from Gurobi4. We see that for all graph sizes, Neal can consistently find certificates of non-copositivity in orders of magnitude less time than Gurobi. Notably, Neal and Gurobi demonstrate similar scaling with respect to the number of vertices.\nUnlike SA, which operates without reference to rigorous optimality bounds, Gurobi\u2019s solution process tracks both upper and lower bounds on the objective value and terminates only when they reach user-specified stopping conditions. To evaluate whether the optimal objective is found early in the solution process and time is spent closing the upper bounds, we plotted Gurobi\u2019s lower and upper bounds progress against time together with TTT0.99 and TTT0.999 in Figure 5 for instances with density p = 0.25. Analogous plots for other densities are included in the Appendix. For each graph size, we plotted the instances where the ratio between Gurobi\u2019s solution time and TTT0.99 is the greatest (top row) and least (bottom row)\u2013all instances were run with 100 sweeps. For each instance, we plot Gurobi\u2019s upper bound (blue) and best objective found (orange), and Neal TTT0.99 (green), and TTT0.999 (purple). We found that in most instances, Neal reaches the time to target with 99.9% confidence before Gurobi even returns a callback (i.e., when the purple line does not intersect either of the blue or orange lines); this is likely due to an initial pre-processing step. We only found one instance where Gurobi was able to confirm optimality at the first callback even so, TTT0.999 is nearly an order of magnitude faster than Gurobi\u2019s solution time in this instance.\nNext, we compared the copositive cutting-plane algorithm with the SA implementation in Neal as the Ising solver against solving a mixed-integer linear program (MILP) formulation of maximum-clique directly with Gurobi. Gurobi\u2019s solution time was evaluated on the following MILP\n3While the performance of Neal depends on the number of sweeps, we found that optimizing the number of sweeps does not result in significant reductions in the time to target. We provide further discussion in the Appendix 6.3.\n4Note that Gurobi\u2019s solution time in Figure 4 is different from copositivity checks profiling in Figure 3. This is because only non-copositive instances were considered for this comparison, while all instances, including copositive ones, were included in the profiling comparison.\nformulation of maximum clique:\n(4.4)\nminimize x \u2208 {0, 1}n\n1\u22a4x\nsubject to xi + xj \u2264 1, \u2200(i, j) \u2208 E,\nwhere E is the edges in the complement graph. This is a MILP with n binary variables, where n is the number of vertices in the graph, and |E| constraints (i.e., the number of edges in the complement graph). The copositive cutting-plane algorithm was tested with different sweeps and reads, which were fixed throughout each run of the algorithm. The pink lines in Figure 6 plot the runtime of the copositive cutting-plane algorithm for a representative set of these parameters. Because Neal may fail to find a certificate for some non-copositive matrices, this method may incorrectly reduce the upper bound in the outer approximation; however, it cannot incorrectly update the lower bound. Consequently, the solution returned was determined by rounding the lower bound up to the nearest integer. The fraction of correct maximum clique solutions is indicated by the color of the markers. From the pink plots, we see that for a fixed parameter setting, the copositive cutting-plane algorithm exhibits polynomial scaling in the graph size. While it is tempting to extrapolate this scaling relationship to larger graph sizes, the failure of parameters that were successful on smaller graphs on larger graph sizes (denoted by the green and blue markers) indicate that it is unlikely that fixed parameter settings will continue to be effective ad infinitum. In particular, we found that while smaller and sparser instances are tolerant of fewer sweeps and reads (resulting in shorter calls to the Ising solver), larger instances required more sweeps and reads to be accurate. While the copositive cutting-plane algorithm is designed to benefit from speed-ups of state-of-the-art Ising solvers, the converse is also expected\u2013poor scaling of the Ising solver will make its way into the runtime as the time spent in each oracle call, TQ. On the other hand, we observe that the confidence intervals for Neal are significantly wider than those of Gurobi and the copositive cutting-plane algorithm \u2013 this is potentially due to the sensitivity of Neal to its penalty weight. While Neal can also produce lower bounds for the maximum clique, the bounds can only be updated when it returns solution corresponds to a clique. In contrast, the copositive cutting-plane algorithm can generate cuts from any certificate of non-copositivity, even those that do not correspond to a clique at all. This means that the copositive cutting-plane algorithm can make progress from a larger set of the solutions returned by the Ising solver. This suggests that the copositive cutting-plane algorithm may even be competitive against its underlying copositivity checker solving a direct formulation of the problem, particularly if its performance is highly sensitive to parameter settings. Finally, we note that Gurobi takes advantage of multi-threading while neither Neal nor the copositive cutting-plane algorithm do. This raises the important question of how much the copositive cutting-plane algorithm (and Neal) will benefit from similar decomposition and parallelization efforts.\nFinally, we investigated the effectiveness of directly converting the maximum clique problem to an\nIsing problem using a standard penalty formulation. To do so, we solved each of the maximum clique problem instances using the maximum clique formulator5 with Neal as the sampler and a range of penalty weights in {2\u22121, 20, . . . , 24}; the number of sweeps was left to its default value of 1000. This results in a QUBO with n variables and |E| quadratic terms. For each instance, we conducted 1000 reads and evaluated the average normalized sample size (the size of the returned solution divided by the ground truth maximum clique size) and the fraction of reads that resulted in a valid clique; a ground state solution is one that is both a valid clique and has a normalized sample size of 1. We computed the probability of success, psucc, as the fraction of reads that resulted in a ground state solution, which was subsequently used to derive the time to solution to 99.9% confidence. Figure 7 plots each of these metrics as a function of the penalty weights and graph size for edge density p = 0.25. Analogous plots for other densities are included in the Appendix. For penalty weights 0.5 and 1, the normalized sample size is often greater than 1, resulting in samples that do not represent a valid clique. For penalty weights 2, 4, 8, and 16, most samples were valid cliques; however, the normalized sample sizes were typically less than 1\u2013these represent non-maximum cliques. Generally, as the penalty weight is increased, the normalized sample size decreases, and the fraction of valid cliques increases. This aligns with the interpretation that the penalty weight represents a tradeoff between satisfying the constraints versus optimizing the objective. These empirical results also corroborate the analytical results of [75], which state that the minimum valid penalty weight for the stable set of a graph is 1. Given that maximum clique represents the maximum clique problem as finding the stable set of the graph built with the complement of the original edges, the bound on the penalty weight is valid. This experiment demonstrates that while the penalty formulation may be an effective heuristic, it typically requires carefully tuning the penalty weights to optimize the trade-off between satisfying the constraints and optimizing the objective. Figure 6 also plots the corresponding TTT0.999 from Neal applied directly to the maximum clique formulation with penalty weight 1 against the Gurobi solution time and the copositive cutting-plane solution time.\n5. Conclusions. In this paper, we advocate for the development of a theory of hybrid quantumclassical algorithms that analytically quantifies their performance. Metrics for comparing different hybrid algorithms may include the number of calls to the quantum computer, the complexity of the classical portion, and the requirements on the quantum computer. As a step in this direction, we demonstrate a class of hybrid algorithms for mixed-binary quadratic programming problems using Ising solvers and report the aforementioned metrics. Our framework relies on Burer\u2019s convex reformulation of such problems using completely positive programming\u2013our first contribution is to extend this result and show that under mild conditions, the dual copositive program exhibits strong duality.\n5https://docs.ocean.dwavesys.com/projects/dwave-networkx/en/latest/reference/algorithms/generated/ dwave networkx.maximum clique.html\n8 16\n32 64\n12 8\n25 6\n51 2\n1. 00 1. 25 1. 50 1. 75 2. 00 Normalized sample size Pe\nna lty\n= 0\n.5\n8 16\n32 64\n12 8\n25 6\n51 2\n1. 0 1. 2 1. 4\nPe na\nlty =\n1\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 7 0. 8 0. 9 1. 0\nPe na\nlty =\n2\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 8 0. 9 1. 0\nPe na\nlty =\n4\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 7 0. 8 0. 9\nPe na\nlty =\n8\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 6 0. 7 0. 8 0. 9\nPe na\nlty =\n1 6\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 00\n0\n0. 25\n0\n0. 50\n0\n0. 75\n0\n1. 00\n0\nValid clique fraction\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 40\n0\n0. 60\n0\n0. 80\n0\n1. 00\n0\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 99\n8\n0. 99\n8\n0. 99\n9\n0. 99\n9\n1. 00\n0\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 99\n9\n0. 99\n9\n1. 00\n0\n1. 00\n0\n1. 00\n0\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 95\n0\n0. 97\n5\n1. 00\n0\n1. 02\n5\n1. 05\n0\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 95\n0\n0. 97\n5\n1. 00\n0\n1. 02\n5\n1. 05\n0\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 00 0. 25 0. 50 0. 75 1. 00\nGround state fraction\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 00 0. 25 0. 50 0. 75 1. 00\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 00 0. 25 0. 50 0. 75 1. 00\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 00 0. 25 0. 50 0. 75 1. 00\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 00 0. 25 0. 50 0. 75\n8 16\n32 64\n12 8\n25 6\n51 2\n0. 0 0. 2 0. 4 0. 6 0. 8\n8 16\n32 64\n12 8\n25 6\n51 2\n10 2 10 1 10 4\nTTS0.999 (s)\n8 16\n32 64\n12 8\n25 6\n51 2\n10 4 10 2 10 0 10 2\n8 16\n32 64\n12 8\n25 6\n51 2\n10 3 10 0 10 3 10 6\n8 16\n32 64\n12 8\n25 6\n51 2\n10 2 10 0 10 2\n8 16\n32 64\n12 8\n25 6\n51 2\n10 1 10 2 10 5\n8 16\n32 64\n12 8\n25 6\n51 2\n10 1 10 2 10 5\n0. 0\n0. 2\n0. 4\n0. 6\n0. 8\n1. 0\nN um\nbe r o\nf V er\ntic es\n0. 0 0. 2 0. 4 0. 6 0. 8 1. 0\nF ig\n. 7:\nT h\nis fi\ngu re\np lo\nts th\ne n\nor m\nal iz\ned sa\nm p\nle si\nze (t\nh e\nsi ze\no f\nth e\nre tu\nrn ed\nso lu\nti o n\nd iv\nid ed\nb y\nth e\ng ro\nu n\nd tr\nu th\nm a x im\nu m\ncl iq\nu e\nsi ze\n) a n\nd th\ne fr\na ct\nio n\no f\nre a d s th at re su lt ed in a va li d cl iq u e fo r gr ap h d en si ty p = 0 .2 5. T h es e fi g u re s w er e u se d to co m p u te th e fr a ct io n o f re a d s re su lt in g in a g ro u n d st a te so lu ti o n a n d th e co rr es p on d in g T T T 0 .9 9 9 (a ls o p lo tt ed ). A s th e p en al ty w ei gh t is in cr ea se d , th e n o rm a li ze d sa m p le si ze d ec re a se s, a n d th e fr a ct io n o f va li d cl iq u es in cr ea se s. T h is h ig h li gh ts th e d el ic at e tr ad eoff b et w ee n co n st ra in ts an d th e o b je ct iv e in p en a lt y fo rm u la ti o n s.\nWe then propose a hybrid quantum-classic solution algorithm based on cutting-plane algorithms, where an Ising solver is used to construct the separation oracle. This approach partially mitigates the heuristic nature of many state-of-the-art Ising solvers. Moreover, the runtime of the components handled by the classical computer scales polynomially with the number of constraints in the original mixed-binary quadratic program. This suggests that if our approach is applied to a problem with exponential scaling, the complexity is shifted on the subroutine carried out by the hardware accelerator, e.g., the quantum computer. Our proposed approach is particularly appealing because it suggests that the proposed approach could take advantage of any speedup that exists even without an explicit characterization of what that speedup is.\nWhile the proposed framework seems like a promising way forward for utilizing quantum/quantuminspired Ising solvers, a crucial question remains regarding how the algorithm should proceed if the Ising solver fails to find a certificate of non-copositivity. Could one design an efficient algorithm that circumvents the ambiguity due to failure to find a certificate of non-copositivity (perhaps using a sum-of-squares-based inner approximations of the copositive cone)? Alternatively, is there a complexity barrier that prevents such a construction? More broadly, identifying fundamental limitations, such as this example, is important for understanding what requirements should be placed on new computing architectures. While the theory in this paper is framed in the context of understanding algorithms that interact with existing hardware, we believe its most potent impact is in informing the co-design of \u201chardware primitives\u201d and optimization algorithms.\nAcknowledgements. This work was supported by NSF CCF (grant #1918549), NASA Academic Mission Services (contract NNA16BD14C \u2013 funded under SAA2-403506). R.B. acknowledges support from the NASA/USRA Feynman Quantum Academy Internship program. The authors wish to thank Aaron Lott, Luis Zuluaga, and Juan Vera for helpful input and discussions during the development of these ideas."
        }
    ],
    "title": "A COPOSITIVE FRAMEWORK FOR ANALYSIS OF HYBRID ISING-CLASSICAL ALGORITHMS",
    "year": 2023
}