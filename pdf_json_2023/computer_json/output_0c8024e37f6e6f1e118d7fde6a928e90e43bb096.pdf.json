{
    "abstractText": "Co-evolution of epidemiology and artificial intelligence: challenges and opportunities Joohon Sung * and John L Hopper Genome and Health Data Laboratory and Department of Epidemiology, Graduate School of Public Health, Seoul National University, Seoul, Korea, Institute of Health and Environment, Seoul National University, Seoul, Korea and and Centre for Epidemiology and Biostatistics, School of Population and Global Health, University of Melbourne, Melbourne, VIC, Australia",
    "authors": [
        {
            "affiliations": [],
            "name": "Joohon Sung"
        },
        {
            "affiliations": [],
            "name": "John L Hopper"
        }
    ],
    "id": "SP:dc2856c7b4e4724651191468b6611ba2c81d8694",
    "references": [
        {
            "authors": [
                "F. Chollet"
            ],
            "title": "Deep Learning with Python",
            "venue": "edn. New York: Manning Publications,",
            "year": 2021
        },
        {
            "authors": [
                "P Wang",
                "TM Berzin",
                "JR Glissen Brown"
            ],
            "title": "Real-time automatic detection system increases colonoscopic polyp and adenoma detection rates: a prospective randomised controlled study",
            "venue": "Gut",
            "year": 2019
        },
        {
            "authors": [
                "DSW Ting",
                "CY Cheung",
                "G Lim"
            ],
            "title": "Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes",
            "venue": "JAMA",
            "year": 2017
        },
        {
            "authors": [
                "JR Giudicessi",
                "M Schram",
                "JM Bos"
            ],
            "title": "Artificial intelligenceenabled assessment of the heart rate corrected QT interval using a mobile electrocardiogram device. Circulation 2021;143:1274\u201386",
            "year": 2021
        },
        {
            "authors": [
                "A O\u2019Shea",
                "G Lightbody",
                "G Boylan",
                "A. Temko"
            ],
            "title": "Neonatal seizure detection from raw multi-channel EEG using a fully convolutional architecture",
            "venue": "Neural Netw 2020;123:12\u201325",
            "year": 2020
        },
        {
            "authors": [
                "VanderWeele TJ"
            ],
            "title": "On the distinction between interaction and effect modification",
            "venue": "Epidemiology",
            "year": 2009
        },
        {
            "authors": [
                "NJ Timpson",
                "DA Lawlor",
                "RM Harbord"
            ],
            "title": "C-reactive protein and its role in metabolic syndrome: mendelian randomisation study",
            "year": 2005
        },
        {
            "authors": [
                "JM Robins",
                "M\u00c1 Hern\u00e1n",
                "B. Brumback"
            ],
            "title": "Marginal structural models and causal inference in epidemiology",
            "venue": "Epidemiology",
            "year": 2000
        },
        {
            "authors": [
                "PWG Tennant",
                "EJ Murray",
                "KF Arnold"
            ],
            "title": "Use of directed acyclic graphs (DAGs) to identify confounders in applied health research: review and recommendations",
            "venue": "Int J Epidemiol",
            "year": 2021
        },
        {
            "authors": [
                "G Davey Smith",
                "S. Ebrahim"
            ],
            "title": "Mendelian randomization\u2019: can genetic epidemiology contribute to understanding environmental determinants of disease",
            "venue": "Int J Epidemiol",
            "year": 2003
        },
        {
            "authors": [
                "S Li",
                "M Bui",
                "JL. Hopper"
            ],
            "title": "Inference about causation from examination of familial confounding (ICE FALCON): a model for assessing causation analogous to Mendelian randomization",
            "venue": "Int J Epidemiol",
            "year": 2020
        },
        {
            "authors": [
                "JJ Titano",
                "M Badgeley",
                "J Schefflein"
            ],
            "title": "Automated deepneural-network surveillance of cranial images for acute neurologic events",
            "venue": "Nat Med",
            "year": 2018
        },
        {
            "authors": [
                "E Schroeder",
                "M Yang",
                "P Brocklehurst",
                "L Linsell",
                "O. Rivero-Arias"
            ],
            "title": "Economic evaluation of computerised interpretation of fetal heart rate during labour: a cost-consequence analysis alongside the INFANT study",
            "venue": "Arch Dis Child Fetal Neonatal Ed",
            "year": 2021
        },
        {
            "authors": [
                "GS Collins",
                "P Dhiman",
                "CL Andaur Navarro"
            ],
            "title": "Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence",
            "venue": "BMJ Open 2021;11:e048008",
            "year": 2021
        },
        {
            "authors": [
                "B Vasey",
                "M Nagendran",
                "B Campbell"
            ],
            "title": "DECIDE-AI Expert Group. Reporting guideline for the early-stage clinical evaluation of decision support systems driven by artificial intelligence: DECIDE-AI",
            "venue": "Nat Med",
            "year": 2022
        },
        {
            "authors": [
                "C Infante-Rivard",
                "A. Cusson"
            ],
            "title": "Reflection on modern methods: selection bias: a review of recent developments",
            "venue": "Int J Epidemiol",
            "year": 2018
        },
        {
            "authors": [
                "M. Porta"
            ],
            "title": "A Dictionary of Epidemiology",
            "year": 2016
        },
        {
            "authors": [
                "MM Glymour",
                "L Osypuk T",
                "DH. Rehkopf"
            ],
            "title": "Invited commentary: Off-roading with social epidemiology\u2013exploration, causation, translation",
            "venue": "Am J Epidemiol",
            "year": 2013
        },
        {
            "authors": [
                "Jorm LR"
            ],
            "title": "Commentary: Towards machine learning-enabled epidemiology",
            "venue": "Int J Epidemiol",
            "year": 2021
        },
        {
            "authors": [
                "S. Rose"
            ],
            "title": "Intersections of machine learning and epidemiological methods for health services research",
            "venue": "Int J Epidemiol",
            "year": 2024
        }
    ],
    "sections": [
        {
            "heading": "Editorial",
            "text": ""
        },
        {
            "heading": "Co-evolution of epidemiology and artificial",
            "text": "intelligence: challenges and opportunities"
        },
        {
            "heading": "Joohon Sung 1,2,* and John L Hopper3",
            "text": "1Genome and Health Data Laboratory and Department of Epidemiology, Graduate School of Public Health, Seoul National University, Seoul, Korea, 2Institute of Health and Environment, Seoul National University, Seoul, Korea and and 3Centre for Epidemiology and Biostatistics, School of Population and Global Health, University of Melbourne, Melbourne, VIC, Australia\n*Corresponding author. Genome and Health Data Laboratory and Department of Epidemiology, Graduate School of Public Health, Seoul National University, 1st Gwanak-ro, Gwanak-gu, Seoul 08826, Korea. E-mail: jsung@snu.ac.kr\nReceived 21 November 2022; Editorial decision 18 April 2023; Accepted 11 June 2023"
        },
        {
            "heading": "Legacy of epidemiology",
            "text": "Epidemiology, as suggested by its etymology, has been dedicated to discovering knowledge that can improve the health of populations. Epidemiology has evolved as a discipline that combines qualitative and quantitative designs and techniques to identify true and likely causal signals against a background of confounding and random errors. From the examples of tobacco smoking regulation to COVID-19 guidelines, epidemiological evidence has contributed to the identification of proper intervention targets, so as to have an impact on the population\u2019s health.\nThe big data era and a burgeoning of data science and artificial intelligence (AI)\nArtificial intelligence (AI), also often referred to as machine learning (ML) and deep learning (DL) (see Box 1 for clarification), is an automated process whereby information is extracted from a given dataset using computing techniques to create an algorithm for making predictions and/or classifications.1 The key difference between AI and classic epidemiology is that the latter builds models based on explicit assumptions about what matters and how, so that the results can be directly interpretable, whereas AI builds algorithms in essence for predictive models discovered from the data, without necessarily understanding why. The trend toward larger and more complex \u2018big\u2019\ndatasets (see Box 1) is inevitable and irreversible. Big data unfortunately suffer from major problems. For example, the shift in electronic health records (EHR) data over time which accompanies the evolution of clinical practice, the sparse density arising from ever-increasing data points, and the inclusion of unstructured data, are but a few of the challenges. Novel AI approaches are increasingly being required to properly process data silos into an analysis-ready format so as to handle the complexity and abundance of data.\nSuccessful examples and unintended consequences of AI in health\nWhen applied to health, AI has had numerous successes, including diagnostic support for image analysis2,3 and automated interpretation of echocardiography and electroencephalography.4,5 On the other hand, unintended consequences and unsatisfactory performances have also been reported. One primary problem lies in that AI-based methods will not work for \u2018minority\u2019 sub-groups, however defined, given they have been under-represented in the training data used for building AI algorithms.\nWe believe it is essential to take a balanced view of the success and limitations of AI in health, especially in these formative years, by understanding AI\u2019s fundamental (intrinsic) versus controllable (extrinsic) problems. We should\nVC The Author(s) 2023. Published by Oxford University Press on behalf of the International Epidemiological Association. 969 This is an Open Access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited."
        },
        {
            "heading": "IEA",
            "text": "International Epidemiological Association\nInternational Journal of Epidemiology, 2023, 969\u2013973\nhttps://doi.org/10.1093/ije/dyad089\nAdvance Access Publication Date: 22 June 2023\nEditorial\nD ow nloaded from https://academ ic.oup.com /ije/article/52/4/969/7205341 by Indian Institute of Technology Patna user on 10 January 2024\navoid making undue criticism of AI, because no methods are free from errors.\nIntrinsic versus extrinsic problems of AI in health\nAI algorithms derive accuracy metrics based on features extracted from a given dataset, regardless of their causal contributions; see Box 1 and Table 1 for the definition of terms related to AI modelling. The optimization process of AI is highly efficient, but overfitting is inevitable. Diagnostic performance is achieved at the cost of transparency and causality. AI also loses generalizability when the training dataset does not represent the characteristics of the population to which the results are applied (targets), which is the origin of \u2018unfairness\u2019 for minority groups. These issues are intrinsic to AI.\nExtrinsic problems of AI stem from the interactions between AI tools and humans. Health practice relies on multidisciplinary experts whose routine is structured into tight schedules where precise and efficient communication matters. In theory, extrinsic problems should be controllable,\nbut technical hurdles to humanizing the AI interface often precipitate real-world problems, impairing the anticipated effectiveness of AI.\nKey epidemiological principles to redress AI\u2019s intrinsic weaknesses in health\nEpidemiological discipline has evolved through confronting health problems and customizing practice using welldesigned studies, and should now use this experience in the application of AI. Epidemiology has led health research by being continually enriched by other disciplines, and we present ideas on how the same could apply when using AI.\nProviding causal insights\nAI is particularly powerful for diagnosis and prediction. However, features with good predictive power do not necessarily have causal relevance, as has been established by theoretical work6 and practical examples7; see Box 1 for more details about the concept of causality in AI and epidemiology. Application of AI to the recent quasi-experimental methods\nBox 1 Confusing terms and terms with different meaning in epidemiology, statistics and artificial intelligence\nArtificial intelligence (AI), machine learning (ML) and deep learning (DL):\nAI emulates human intelligence systems by using computers. ML is a subtype of AI that can improve prediction algorithms using data with \u2018ground truth\u2019 (answers). Note the differences with conventional programming, which uses \u2018pre-completed\u2019 algorithms (\u00bc rule-based methods) to get answers. DL is a specific type of ML that uses deep layers of neural networks inspired by human neurons. Although the majority of modern successes of AI are attributable to DL, AI is widely used as a lay term to mean both DL and ML with a long history. In this article, we use the term AI instead of DL."
        },
        {
            "heading": "Big data:",
            "text": "Big data refers to datasets that are too large (in amount) or complicated (in structure) to be dealt with by traditional data processing methods using well-defined database programs (e.g. sorting, merging and taking representative values). By \u2018big\u2019, the size of observations is generally more important, contrasting with so-called \u2018fat data\u2019 with fewer observations relative to the number of variables in datasets. From the epidemiology angle, big data is also characterized by lacking prior analytical plans but later utilized for research purposes; electronic health records (HER) from hospital administration and lifelogs from smartphone use are typical examples.\nBias:\nIn epidemiology, bias means systematic errors in statistical inference which arise from weaknesses in study designs and conduct. In statistical inference, bias is defined as a difference between the expected value of an estimate and its true value. Statistical analyses cannot correct biases due to faulty design. In AI, bias means the intercepts in unit models (i.e. bi of yi \u00bc ai * Xi \u00fe bi)."
        },
        {
            "heading": "Parameter, parametric and hyperparameter:",
            "text": "In statistics, a parameter refers to the characteristic of the population, such as the mean, variance or some other aspect of the probability distribution of one or more random variables. A parametric model is one in which the relationship between random variables is assumed to follow a particular equation. In AI, a parameter refers to the components that AI learns from model training. Hyperparameter in AI refers to values needed to be set using a priori insight or experience. Regularization terms or batch size are hyperparameters in DL.\nD ow nloaded from https://academ ic.oup.com /ije/article/52/4/969/7205341 by Indian Institute of Technology Patna user on 10 January 2024"
        },
        {
            "heading": "Cause, causality, and association",
            "text": "In epidemiology, cause and causality are reserved for associations verified at a biological level or by experimental studies. Otherwise, all potential causal relations are defined as associations, recognizing that these could be due to causation in one of both directions or by uncontrolled confounding. In statistical models, an association refers to the result with statistical significance rejecting the null hypothesis, although statistical parlance often refers to these associations as \u2018effects\u2019, which unfortunately implies association despite the caveats above. AI generally fails to distinguish between cause and association because it is mainly interested in prediction, irrespective of the reason why. In AI, features with high \u2018feature importance\u2019 are generally considered meaningful predictive factors. Causal or counterfactual models in AI usually denote generative adversarial networks (GAN) where the other label (\u00bc outcome in epidemiology) is replaced in training and comparing the results between the original and reversed models."
        },
        {
            "heading": "Model development and validation:",
            "text": "In epidemiology, after the development of an explanatory model, validation is conducted using an independent dataset; that is, there is a distinction between internal and external validation depending on the source of the validation dataset. In AI, model development is denoted as \u2018training\u2019, and for validation, mixing training and validation subsets from the same dataset commonly occur (e.g. iterated k-fold crossvalidation). Such validation is internal. For this reason, AI generally uses a third \u2018test\u2019 process with a strictly independent subset from the same dataset.\n\u2018Fairness\u2019, \u2018fairness of algorithm\u2019, and \u2018fairness of data\u2019\nIn ML, predictions made by an ML algorithm are considered unfair if the performance of the predictions depends on variables considered to be \u2018sensitive.\u2019 (such as race and sex) Unfair algorithms would result in both quality and equity problems. Data scientists attempt to assure algorithmic fairness based on \u2018correction algorithms\u2019. The \u2018metrics\u2019 of fairness are, in essence, the differences in the predictive performance (e.g. positive or negative predictive accuracy) between the groups divided by sensitive traits. The unfairness of data is, if not entirely, responsible for ML\u2019s algorithmic unfairness, given ML\u2019s overfitting abilities. This \u2018fairness\u2019 issue applies to all sub-populations, however they be defined, and would result in unsatisfactory performances of the resultant algorithms. The \u2018Dictionary of Epidemiology\u201922 lacks the term \u2018fairness\u2019. Semantically similar \u2018equity\u2019 is one of the major interests in epidemiology, if not a key concept of its discipline. However, fairness in ML is more about the equality of metrics than bioethics. From an epidemiology angle, thus fairness is more related to data representativeness without selection and information bias. Epidemiology has unique strengths and an established discipline to understand and handle those biases.\nMeasures assessed by a \u2018reference standard\u2019\n(previously \u2018gold standard\u2019) method\nGround truth or label Actual outcome measurements\nRisk factors (epi) or independent variables\n(stat)\nFeatures Potential predictor measurements\nModel fitting Model training Learning the association between predictors\nand outcome\nInternal validation Validation Testing the prediction using initial dataset External validation Test Testing the prediction using independent\ndataset\nPrediction Classification Performance of the model in terms of risk\ndiscrimination\nWinner\u2019s curse: (overfitting when\nextrapolating the results)\nOverfitting during training (an inevitable\nand necessary, intermediate phenomenon in AI)\nModel performance outside the learning\ndata is worse than within the dataset\nD ow nloaded from https://academ ic.oup.com /ije/article/52/4/969/7205341 by Indian Institute of Technology Patna user on 10 January 2024\nfor making causal inference could make these approaches more powerful.8 These methods include: (i) use of directed acyclic graphs (DAGs) when the analysis includes variables that might exert effects on both exposures and outcomes of interest (so-called \u2018collider\u2019), or confounding variables that require conditioning9; (ii) Mendelian randomization that in theory combines biological knowledge with statistical inference10; and (iii) Inference on Causation from Examination of FAmiliaL CONfounding (ICE FALCON) which learns by studying the changes in the regression coefficients before and after conditioning when applied to twin and sibling data.11\nAssuring the comparative effectiveness\nOne fundamental question is whether application of AI to health will improve outcomes and reduce costs. AI solutions need to be tested in the settings where they are to be applied, not just in the controlled settings of an intermediate process used to internally evaluate diagnostic performance.12,13 AI\u2019s intrinsic overfitting is problematic when applied to new data with unseen heterogeneity. Recently, expert groups have been gathering consensus on new reporting guidelines specific to different phases of clinical research involving AI, e.g. TRIPOD-AI for prediction model and development of diagnostics,14,15 DECIDE-AI for early-stage clinical studies,16 CONSORT-AI and SPIRIT-AI for clinical trials.17\nAssessing the fairness of AI\nAlgorithmic fairness, defined as the dependency of results or performance on \u2018sensitive variables\u2019 such as race or gender, is well-known in the data science society18; see Box 1 for clarification of the fairness and related concepts. Multiple software packages for \u2018fairness corrections\u2019, such as \u2018Fairlearn\u2019 (Microsoft)19 and \u2018ML-Fairness Gym\u2019 (Google),20 have been developed and generally assess the predictive performance metrics between \u2018sensitive variables\u2019 and try to reduce the imbalance within a given dataset. This attempt at mitigation invariably results in a mechanical balance of the metrics at the expense of destroying the concept of population inference from random samples.\nEpidemiology has long developed theories and remedies for biases that arise from differential selection/participation and heterogeneity.21 The fairness of the algorithms would be better evaluated if the differences in frequency between population and sample were estimated and used (e.g. using matching) rather than trying to produce one omnibus solution. Fairness of algorithms and data is another area where epidemiological thinking could contribute, but this has so far largely been neglected by epidemiologists.\nIJE efforts and editorial plans\nThis Editorial is a call for papers in the IJE on development and issues arising from the use of artificial intelligence (AI) in epidemiology, and vice versa. The big data era presents both challenges and opportunities for epidemiology. The IJE has a keen interest in this brisk change that epidemiology is confronting. A critical evaluation of AI in epidemiological practice, or the need for a new evolution, has already been published in IJE and other epidemiology journals.23\u201325 The authors are keen to consolidate the constructive discussions so far, and suggest topics toward which next discussions might converge. These include, but are not limited to:\n\u2022 study designs that maximize the informativity and credi-\nbility derived from big data;\n\u2022 causal analysis methods combined with AI analysis; \u2022 proper evaluation of AI solutions for diagnostics and ul-\ntimate outcomes;\n\u2022 roles of epidemiology in assuring fairness and equity of\ndata algorithms derived from big data;\n\u2022 regulatory or reporting guidelines for studies using AI.\nThese two planets are getting ever closer. Epidemiologists and AI researchers are beginning to work together, rather than against each other, and respect each other\u2019s disciplines. We envisage the IJE initiative to publish papers on this issue will facilitate the co-evolution of epidemiology and AI for the population\u2019s health to become the true beneficiary."
        },
        {
            "heading": "Author contributions",
            "text": "J.S. initiated the idea, J.S. and J.L.H. designed, reviewed, wrote and edited the paper."
        },
        {
            "heading": "Funding",
            "text": "This work was supported by an Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2020\u20130-00121) and a National Research Foundation of Korea (NRF) grant funded by the Korea Government (MSIT) (No. 2020R1A2C2101041). J.L.H. was supported by a NHMRC Senior Principal Research Fellowship (GNT1137349) and is a Dame Kate Campbell Fellow and Redmond Barry Distinguished Professor at the University of Melbourne, Australia."
        },
        {
            "heading": "Conflict of interest",
            "text": "None declared."
        }
    ],
    "title": "Co-evolution of epidemiology and artificial intelligence: challenges and opportunities",
    "year": 2023
}