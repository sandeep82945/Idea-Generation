{
    "abstractText": "This paper proposes a graph-based deep framework for detecting anomalous image regions in human monitoring. The most relevant previous methods, which adopt deep models to obtain salient regions with captions, focus on discovering anomalous single regions and anomalous region pairs. However, they cannot detect an anomaly involving more than two regions and have deficiencies in capturing interactions among humans and objects scattered in multiple regions. For instance, the region of a man making a phone call is normal when it is located close to a kitchen sink and a soap bottle, as they are in a resting area, but abnormal when close to a bookshelf and a notebook PC, as they are in a working area. To overcome this limitation, we propose a spatial and semantic attributed graph and develop a Spatial and Semantic Graph Auto-Encoder (SSGAE). Specifically, the proposed graph models the \u201ccontext\u201d of a region in an image by considering other regions with spatial relations, e.g., a man sitting on a chair is adjacent to a white desk, as well as other region captions with high semantic similarities, e.g., \u201ca man in a kitchen\u201d is semantically similar to \u201ca white chair in the kitchen\u201d. In this way, a region and its context are represented by a node and its neighbors, respectively, in the spatial and semantic attributed graph. Subsequently, SSGAE is devised to reconstruct the proposed graph to detect abnormal nodes. Extensive experimental results indicate that the AUC scores of SSGAE improve from 0.79 to 0.83, 0.83 to 0.87, and 0.91 to 0.93 compared with the best baselines on three real-world datasets.",
    "authors": [
        {
            "affiliations": [],
            "name": "Kang Zhang"
        },
        {
            "affiliations": [],
            "name": "Einoshin Suzuki"
        }
    ],
    "id": "SP:7baab6661afebf1074ef5aab7a3adadcfe63865a",
    "references": [
        {
            "authors": [
                "W. Sultani",
                "C. Chen",
                "M. Shah"
            ],
            "title": "Real-World Anomaly Detection in Surveillance Videos",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT,",
            "year": 2018
        },
        {
            "authors": [
                "W. Luo",
                "W. Liu",
                "D. Lian",
                "S. Gao"
            ],
            "title": "Future Frame Prediction Network for Video Anomaly Detection",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "year": 2021
        },
        {
            "authors": [
                "M. Yu",
                "G. Li",
                "D. Jiang",
                "G. Jiang",
                "B. Tao",
                "D. Chen"
            ],
            "title": "Hand Medical Monitoring System Based on Machine Learning and Optimal EMG Feature Set",
            "venue": "Pers. Ubiquitous Comput",
            "year": 2019
        },
        {
            "authors": [
                "P. Wu",
                "J. Liu",
                "Y. Shi",
                "Y. Sun",
                "F. Shao",
                "Z. Wu",
                "Z. Yang"
            ],
            "title": "Not Only Look, but Also Listen: Learning Multimodal Violence Detection under Weak Supervision",
            "venue": "In Proceedings of the European Conference on Computer Vision, Glasgow, UK,",
            "year": 2020
        },
        {
            "authors": [
                "Y. Deguchi",
                "D. Takayama",
                "S. Takano",
                "V.M. Scuturici",
                "J.M. Petit",
                "E. Suzuki"
            ],
            "title": "Skeleton Clustering by Multi-Robot Monitoring for Fall Risk Discovery",
            "venue": "J. Intell. Inf. Syst",
            "year": 2017
        },
        {
            "authors": [
                "Y. Hatae",
                "Q. Yang",
                "M.F. Fadjrimiratno",
                "Y. Li",
                "T. Matsukawa",
                "E. Suzuki"
            ],
            "title": "Detecting Anomalous Regions from an Image based on Deep Captioning",
            "venue": "In Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, Valletta, Malta,",
            "year": 2020
        },
        {
            "authors": [
                "M.F. Fadjrimiratno",
                "Y. Hatae",
                "T. Matsukawa",
                "E. Suzuki"
            ],
            "title": "Detecting Anomalies from Human Activities by an Autonomous Mobile Robot based on \u201cFast and Slow",
            "venue": "Thinking. In Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, Online Streaming,",
            "year": 2021
        },
        {
            "authors": [
                "N. Dong",
                "E. Suzuki"
            ],
            "title": "GIAD-ST: Detecting Anomalies in Human Monitoring Based on Generative Inpainting via Self-Supervised Multi-Task Learning",
            "venue": "J. Intell. Inf. Syst",
            "year": 2022
        },
        {
            "authors": [
                "J. Yi",
                "S. Yoon"
            ],
            "title": "Patch SVDD: Patch-level SVDD for Anomaly Detection and Segmentation",
            "venue": "In Proceedings of the Asian Conference on Computer Vision, Kyoto, Japan,",
            "year": 2020
        },
        {
            "authors": [
                "C.L. Li",
                "K. Sohn",
                "J. Yoon",
                "T. Pfister"
            ],
            "title": "CutPaste: Self-Supervised Learning for Anomaly Detection and Localization",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Kyoto, Japan,",
            "year": 2020
        },
        {
            "authors": [
                "K. Wu",
                "L. Zhu",
                "W. Shi",
                "W. Wang",
                "J. Wu"
            ],
            "title": "Self-Attention Memory-Augmented Wavelet-CNN for Anomaly Detection",
            "venue": "IEEE Trans. Circuits Syst. Video Technol",
            "year": 2022
        },
        {
            "authors": [
                "H. Mu",
                "R. Sun",
                "M. Wang",
                "Z. Chen"
            ],
            "title": "Spatio-Temporal Graph-Based CNNs for Anomaly Detection in Weakly-Labeled Videos",
            "venue": "Inf. Process. Manag",
            "year": 2022
        },
        {
            "authors": [
                "K. Zhang",
                "M.F. Fadjrimiratno",
                "E. Suzuki"
            ],
            "title": "Context-Based Anomaly Detection via Spatial Attributed Graphs in Human Monitoring",
            "venue": "In Proceedings of the International Conference on Neural Information Processing, Sanur, Bali, Indonesia,",
            "year": 2021
        },
        {
            "authors": [
                "M.J. Choi",
                "A. Torralba",
                "A.S. Willsky"
            ],
            "title": "Context Models and Out-of-Context Objects",
            "venue": "Pattern Recognit. Lett",
            "year": 2012
        },
        {
            "authors": [
                "A. Pasini",
                "E. Baralis"
            ],
            "title": "Detecting Anomalies in Image Classification by means of Semantic Relationships",
            "venue": "In Proceedings of the 2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE), Sardinia, Italy,",
            "year": 2019
        },
        {
            "authors": [
                "J. Johnson",
                "A. Karpathy",
                "L. Fei-Fei"
            ],
            "title": "DenseCap: Fully Convolutional Localization Networks for Dense Captioning",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV, USA,",
            "year": 2016
        },
        {
            "authors": [
                "T.N. Kipf",
                "M. Welling"
            ],
            "title": "Variational Graph Auto-Encoders",
            "venue": "arXiv 2016,",
            "year": 2016
        },
        {
            "authors": [
                "K. Ding",
                "J. Li",
                "R. Bhanushali",
                "H. Liu"
            ],
            "title": "Deep Anomaly Detection on Attributed Networks",
            "venue": "In Proceedings of the 2019 SIAM International Conference on Data Mining, Calgary, AB, Canada,",
            "year": 2019
        },
        {
            "authors": [
                "K. Xu",
                "W. Hu",
                "J. Leskovec",
                "S. Jegelka"
            ],
            "title": "How Powerful are Graph Neural Networks",
            "venue": "In Proceedings of the International Conference on Learning Representations,",
            "year": 2019
        },
        {
            "authors": [
                "R. Krishna",
                "Y. Zhu",
                "O. Groth",
                "J. Johnson",
                "K. Hata",
                "J. Kravitz",
                "S. Chen",
                "Y. Kalantidis",
                "L.J. Li",
                "D.A Shamma"
            ],
            "title": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations",
            "venue": "Int. J. Comput. Vis. 2017,",
            "year": 2023
        },
        {
            "authors": [
                "P. Bergmann",
                "M. Fauser",
                "D. Sattlegger",
                "C. Steger"
            ],
            "title": "MVTec AD\u2014A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA,",
            "year": 2019
        },
        {
            "authors": [
                "P. Seeb\u00f6ck",
                "S. Waldstein",
                "S. Klimscha",
                "B.S. Gerendas",
                "R. Donner",
                "T. Schlegl",
                "U. Schmidt-Erfurth",
                "G. Langs"
            ],
            "title": "Identifying and Categorizing Anomalies in Retinal Imaging Data",
            "venue": "arXiv 2016,",
            "year": 2016
        },
        {
            "authors": [
                "T. Schlegl",
                "P. Seeb\u00f6ck",
                "S.M. Waldstein",
                "U. Schmidt-Erfurth",
                "G. Langs"
            ],
            "title": "Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery",
            "venue": "In Proceedings of the International Conference on Information Processing in Medical Imaging,",
            "year": 2017
        },
        {
            "authors": [
                "S. Venkataramanan",
                "K.C. Peng",
                "R.V. Singh",
                "A. Mahalanobis"
            ],
            "title": "Attention Guided Anomaly Localization in Images",
            "venue": "In Proceedings of the European Conference on Computer Vision, Glasgow, UK,",
            "year": 2020
        },
        {
            "authors": [
                "D. Gong",
                "L. Liu",
                "V. Le",
                "B. Saha",
                "M.R. Mansour",
                "S. Venkatesh",
                "A.v.d. Hengel"
            ],
            "title": "Memorizing Normality to Detect Anomaly: Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision, Seoul, Republic of Korea,",
            "year": 2019
        },
        {
            "authors": [
                "C. Sun",
                "Y. Jia",
                "Y. Hu",
                "Y. Wu"
            ],
            "title": "Scene-Aware Context Reasoning for Unsupervised Abnormal Event Detection in Videos",
            "venue": "In Proceedings of the 28th ACM International Conference on Multimedia, Seattle, WA, USA,",
            "year": 2020
        },
        {
            "authors": [
                "M. Pourreza",
                "M. Salehi",
                "M. Sabokrou"
            ],
            "title": "Ano-Graph: Learning Normal Scene Contextual Graphs to Detect Video Anomalies",
            "venue": "arXiv 2021,",
            "year": 2021
        },
        {
            "authors": [
                "Z. Wu",
                "S. Pan",
                "F. Chen",
                "G. Long",
                "C. Zhang",
                "S.Y. Philip"
            ],
            "title": "A Comprehensive Survey on Graph Neural Networks",
            "venue": "IEEE Trans. Neural Netw. Learn. Syst",
            "year": 2020
        },
        {
            "authors": [
                "Y. Liu",
                "Z. Li",
                "S. Pan",
                "C. Gong",
                "C. Zhou",
                "G. Karypis"
            ],
            "title": "Anomaly Detection on Attributed Networks via Contrastive Self-Supervised Learning",
            "venue": "IEEE Trans. Neural Netw. Learn. Syst",
            "year": 2021
        },
        {
            "authors": [
                "Y. Zheng",
                "M. Jin",
                "Y. Liu",
                "L. Chi",
                "K.T. Phan",
                "Y.P.P. Chen"
            ],
            "title": "Generative and Contrastive Self-Supervised Learning for Graph Anomaly Detection",
            "venue": "IEEE Trans. Knowl. Data Eng",
            "year": 2021
        },
        {
            "authors": [
                "M. Jin",
                "Y. Liu",
                "Y. Zheng",
                "L. Chi",
                "Y.F. Li",
                "S. Pan"
            ],
            "title": "ANEMONE: Graph Anomaly Detection with Multi-Scale Contrastive Learning",
            "venue": "In Proceedings of the 30th ACM International Conference on Information & Knowledge Management, Queensland, Australia,",
            "year": 2021
        },
        {
            "authors": [
                "T.N. Kipf",
                "M. Welling"
            ],
            "title": "Semi-Supervised Classification with Graph Convolutional Networks",
            "venue": "arXiv 2016,",
            "year": 2016
        },
        {
            "authors": [
                "H. Fan",
                "F. Zhang",
                "Z. Li"
            ],
            "title": "AnomalyDAE: Dual Autoencoder for Anomaly Detection on Attributed Networks",
            "venue": "In Proceedings of the ICASSP 2020\u20142020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Barcelona, Spain,",
            "year": 2020
        },
        {
            "authors": [
                "A. Salehi",
                "H. Davulcu"
            ],
            "title": "Graph Attention Auto-Encoders",
            "venue": "In Proceedings of the IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI),",
            "year": 2020
        },
        {
            "authors": [
                "S. Akcay",
                "A. Atapour-Abarghouei",
                "T.P. Breckon"
            ],
            "title": "GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training",
            "venue": "In Proceedings of the Asian Conference on Computer Vision, Perth, Australia,",
            "year": 2018
        },
        {
            "authors": [
                "K. He",
                "X. Zhang",
                "S. Ren",
                "J. Sun"
            ],
            "title": "Deep Residual Learning for Image Recognition",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV, USA,",
            "year": 2016
        },
        {
            "authors": [
                "N. Reimers",
                "I. Gurevych"
            ],
            "title": "Sentence-Bert: Sentence Embeddings Using Siamese Bert-Networks",
            "venue": "arXiv 2019,",
            "year": 2019
        },
        {
            "authors": [
                "J. Devlin",
                "M.W. Chang",
                "K. Lee",
                "K. Toutanova"
            ],
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "venue": "arXiv 2018,",
            "year": 2018
        },
        {
            "authors": [
                "Y. Liu",
                "M. Ott",
                "N. Goyal",
                "J. Du",
                "M. Joshi",
                "D. Chen",
                "O. Levy",
                "M. Lewis",
                "L. Zettlemoyer",
                "V. Roberta Stoyanov"
            ],
            "title": "A robustly optimized bert pretraining approach",
            "venue": "arXiv 2019,",
            "year": 2019
        },
        {
            "authors": [
                "J. Deng",
                "W. Dong",
                "R. Socher",
                "L.J. Li",
                "K. Li",
                "L. Fei-Fei"
            ],
            "title": "ImageNet: A Large-Scale Hierarchical Image Database",
            "venue": "In Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition, Miami, FL, USA,",
            "year": 2009
        },
        {
            "authors": [
                "Y. Bengio",
                "P. Lamblin",
                "D. Popovici",
                "H. Larochelle"
            ],
            "title": "Greedy Layer-Wise Training of Deep Networks",
            "venue": "In Proceedings of the Advances in Neural Information Processing Systems,",
            "year": 2006
        },
        {
            "authors": [
                "G. Li",
                "J.J. Jung"
            ],
            "title": "Entropy-based dynamic graph embedding for anomaly detection on multiple climate time series",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Citation: Zhang, K.; Fadjrimiratno,\nM.F.; Suzuki, E. Region Anomaly\nDetection via Spatial and Semantic\nAttributed Graph in Human\nMonitoring. Sensors 2023, 23, 1307.\nhttps://doi.org/10.3390/s23031307\nAcademic Editors: Daniela\nGiordano and Simone Palazzo\nReceived: 21 December 2022\nRevised: 15 January 2023\nAccepted: 18 January 2023\nPublished: 23 January 2023\nCopyright: \u00a9 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: image region anomaly detection; human monitoring; graph modeling; graph neural networks; deep learning for multimodal data"
        },
        {
            "heading": "1. Introduction",
            "text": "Anomalies in human activities, e.g., irregular human behaviors and inappropriate interactions between humans and objects, pose a problem in many security-related and healthcare scenarios. They include abnormal events in video surveillance [1,2] and unusual signals in medical monitoring [3]. Therefore, anomaly detection in human monitoring, which concentrates on discovering unexpected human activities that deviate from those seen in normal instances, has attracted substantial interest from researchers. It has a wide range of real-world applications, such as violence detection [4], fall risk discovery [5], and trajectory outlier detection [6]. Among such works, image region anomaly detection [7\u201311] is a vital task of spotting abnormal areas from images in human monitoring. Traditional methods focus on discovering region-level anomalies that deviate from the patterns learned from normal image regions [7,10\u201313]. Such a region is defined as a single anomaly in human monitoring. For instance, a man holding a baseball bat in the laboratory [7] is a single anomaly, as such behavior is never observed in normal regions. However, in addition to the single anomalies,\nSensors 2023, 23, 1307. https://doi.org/10.3390/s23031307 https://www.mdpi.com/journal/sensors\nthere also exist contextual anomalies [8,9,14], which violate regular interactions among human and objects, as the context of a region is characterized by other regions in the same image. For instance, the region of a man making a phone call is normal when it is located close to a kitchen sink and a soap bottle, as they are in a resting area, while abnormal when close to a bookshelf and a notebook PC, as they are in a working area if the latter is not allowed. Therefore, capturing contextual information is crucial in a region anomaly detection task. Existing methods consider region contexts by exploring the relations among regions. They can be classified into an object-label-based method [15], a spatial-relation-based method [16], and deep-captioning-based methods [7,8]. Choi et al. [15] represent all the objects in an image with a tree-structured model to detect objects that do not conform to the scene. However, utilizing all object labels beforehand is impractical for anomaly detection. The spatial-relation-based method [16] considers the positions, such as above, below, and inside, of two objects to detect abnormal semantic relationships between a pair of image segmentations, while such spatial positions are limited in characterizing diverse region contexts that are essential for detecting the contextual anomalies. In addition to exploiting visual features of image regions, our previous methods [7,8] adopt deep-captioning models, such as DenseCap [17], to obtain region captions as the semantic information for the task. Since these methods also consider both the visual and semantic information of image regions on the same task, they are the most relevant works to our proposed method. They focus on detecting anomalous single regions and anomalous region pairs by considering the spatial relations between two regions and their captions. Nevertheless, they do not consider interactions among more than two regions and are thus limited in detecting contextual anomalies in human monitoring. In this paper, we propose a spatial and semantic attributed graph and a tailored framework, Spatial and Semantic Graph Auto-Encoder (SSGAE), to tackle the image region anomaly detection task. Specifically, by exploring the interactions among regions in the visual perspective and the similarities among their captions in the semantic perspective, our proposed graph models the contextual information of a region by other spatially adjacent regions and semantically similar regions in the same image. Thus, the region and its context in an image can be represented as a node and its neighbors in the graph, respectively, which naturally casts the region anomaly detection task into detecting abnormal nodes in the proposed graph. Figure 1 illustrates examples of constructing the spatial and semantic attributed graphs to model the normal and abnormal regions with their contexts in the images.\nAccordingly, SSGAE is devised for detecting abnormal nodes in the proposed graph. In particular, since the regions depicting similar objects, such as a desk, and similar human behaviors, such as a man sitting on a chair, frequently appear in human monitoring, the neighbors of a node usually contain similar features in the graph. The mean-pooling or max-pooling strategy focuses on capturing the proportions of the node attributes (node attributes and node features are utilized interchangeably in this paper) or the most representative node attribute to represent the node neighbors. Therefore, existing graph auto-encoders [18,19] equipped with these strategies are difficult to discriminate such node neighbors representing the regional contexts. Consequently, SSGAE adopts the sum aggregation strategy used in Graph Isomorphism Network (GIN) [20], which is superior in discriminating such node neighbors by capturing all their attributes, as we will give the details in Section 4.2.1.\nThe main contributions of this paper are summarized as follows.\n(1) We propose a spatial and semantic attributed graph to characterize the regions with their contexts by exploring their spatial and semantic relationships among regions co-occurring in an image. (2) We devise a novel graph auto-encoder-based framework, SSGAE, which adopts the sum aggregation strategy to discriminate the node neighbors containing similar node attributes, to tackle the region anomaly detection task by jointly reconstructing the node features and structures in the graph. (3) We construct three real-world datasets, including two human monitoring datasets collected by an autonomous mobile robot and one region anomaly dataset AnoVisualGenome from a large-scale visual dataset VisualGenome [21] to evaluate the performance of SSGAE. Extensive experimental results demonstrate that SSGAE outperforms other advanced anomaly detection methods on the region anomaly detection task.\nA part of the results in this paper was originally published in its conference version [14], which tackles the same task via the spatial attributed graph. However, this paper extends our preliminary work with several important modifications. (1) We consider the interactions of regions in the semantic level in addition to their spatial relations and thus propose a spatial and semantic attributed graph to model regions with their contexts in one image in Section 4.1. (2) We further construct a region anomaly dataset, AnoVisualGenome, and present more results to evaluate SSGAE in Sections 5.1 and 5.3. (3) Additional analytical results, including the sensitivity to the number of embedding dimensions and the effectiveness of the components in our method, are presented in Sections 5.4 and 5.5."
        },
        {
            "heading": "2. Related Work",
            "text": "In this section, we briefly introduce related works on two topics: (1) image and region anomaly detection and (2) graph anomaly detection."
        },
        {
            "heading": "2.1. Image and Region Anomaly Detection",
            "text": "Image-level and region-level anomaly detection has been active research areas for decades, which can be classified into two categories: those which implicitly consider and those which explicitly consider the relationships among images or regions. The former methods mainly focus on discovering pixel-wise or patch-level deviations by learning the regularities of normal instances, such as defect detection [11,22] and medical image analysis [23,24]. These works have shown their advantages in detecting anomalous regions via self-supervised learning [10,11,25,26], where the contextual information characterized by other regions is implicit in their tasks. Since these methods consider images or regions separately, they are unable to detect contextual anomalies in human monitoring. On the other hand, the latter methods explicitly combine the images or regions with their relationships as the contexts to understand and discover diverse image-level or regionlevel anomalies, such as video surveillance [1,2] and human monitoring [7\u20139]. Among such works, several approaches [9,15,16,27,28] consider the regions and their relations in the visual perspective for region anomaly detection, while our previous methods [7,8] addi-\ntionally adopt deep-captioning models, such as DenseCap [17], to obtain region captions as the semantic information for the task. Sun et al. [27] proposed a Spatio-Temporal Graph (STG) to represent spatio-temporal relations among objects to bridge the gap between an anomaly and its context. Similarly, Ano-Graph [28] detects video anomalies by modeling spatio-temporal interactions among objects via self-supervised learning. Moreover, Spatial-Temporal Graph-based Convolutional Neural Networks (STGCNs) [13] construct a spatial similarity graph and a temporal consistency graph with a self-attention mechanism to model the correlations of video clips for video anomaly detection. Choi et al. [15] discovered out-of-context objects, i.e., objects which do not conform to the scene, by modeling all the objects in the same image via a tree-based graphical model. These works have shown the effectiveness of utilizing graphical models to represent the relationships among video clips or objects for video or region anomaly detection. To detect anomalous images in human monitoring, Dong et al. [9] employed inpainting techniques to coarsen image regions and then generate the regions by utilizing the remaining part of the image. Moreover, Semantic Anomaly Detection (SAD) [16] models the relative positions and sizes of all object pairs to detect abnormal semantic relationships between a pair of image segmentations. These methods have proven their superiority in exploring the visual information of videos and images to detect abnormal instances. However, in addition to the visual features and relations of image regions considered by these methods, region captions provide semantic information regardless of intra-object variations, which can contribute to more accurate region anomaly detection [7,8]. Our previous methods [7,8] exploit both the visual features of regions and the semantic information of region captions for the target task. Nevertheless, they consider each region separately for the anomalous single regions [7] as well as the relations of two overlapped regions for anomalous region pairs [8]. Therefore, they cannot capture the relations among more than two regions that indicate the region context, leading to failures in detecting some of the contextual anomalies in our task."
        },
        {
            "heading": "2.2. Graph Anomaly Detection",
            "text": "Graph Neural Networks (GNNs), which are a family of deep learning models for graph or node embedding [29], have been widely explored for graph anomaly detection. Graph contrastive learning [30\u201332] designs node pairs from local subgraphs for graph anomaly detection. However, to achieve a satisfactory performance, elaborate handcrafted contrastive pretext tasks are mandatory for such kind of methods. On the other hand, several reconstruction-based graph auto-encoder frameworks with different neighborhood aggregation strategies are devised for the task. Deep Anomaly Detection on Attributed Networks (DOMINANT) [19] constructs a graph auto-encoder model equipped with Graph Convolutional Network (GCN) [33] layers to reconstruct the node attributes and structures for detecting abnormal nodes on large-scale graphs. Furthermore, Anomaly Dual AutoEncoders (AnomalyDAE) tackle the same problem via reconstruction by designing a dual auto-encoder with graph attention layers [34]. By adopting graph attention layers in both the encoder and the decoder, Graph Attention Auto-Encoder (GATE) [35] exhibits superior performance in learning node representations for node classification. The existing graph auto-encoders are effective for learning typical node representations for downstream tasks, such as graph anomaly detection [19,34] and node classification [35]. However, the learned representations do not explicitly consider all the features in node neighbors since they focus on capturing the proportions of the features or the most representative feature in node neighbors [20]. This limitation would cause failures in discriminating the representations of different node neighbors, which indicate the contextual information of regions, for detecting the anomalies in human monitoring."
        },
        {
            "heading": "3. Problem Formulation",
            "text": "In this paper, we utilize bold lowercase Roman letters (e.g., x), bold uppercase Roman letters (e.g., X), and uppercase calligraphic fonts (e.g., D) to denote vectors, matrices, and sets, respectively. All important notations are summarized in Table 1 for convenience.\nIn the target problem, the input dataset D is composed of a training set Dtrain = {Ik|k = 1, . . . , K} and a test setDtest = {Ik\u2032 |k\u2032 = 1, . . . , K\u2032}. In the training phase, each input image Ik contains n salient regions rki with captions c k i and region labels y k i as {(rki , cki , yki )|i = 1, . . . , n}. Due to the rareness and diversity of the anomalies in our task, the target problem is solved under a one-class anomaly detection scenario [7\u20139]. This indicates that Dtrain only contains normal regions during training, in which yki = 0 denotes the class label of the normal region. In the test phase, each image Ik \u2032 contains n salient regions with captions and region labels yk \u2032\ni \u2208 {0, 1} as {(rk \u2032 i , c k\u2032 i , y k\u2032 i )|i = 1, . . . , n}, where yk \u2032 i = 1 denotes the class\nlabel of the abnormal region. Our target is to output the degree of abnormality for each region in Ik \u2032 from Dtest.\nFollowing previous methods of anomaly detection [8,9,22,36], we adopt ROC-AUC as the evaluation metric to quantify the performance of our method. The ROC curve is plotted by the true positive rate (TPR) and the false positive rate (FPR) with a range of thresholds. AUC score stands for the value of the area under the ROC curve, which corresponds to the probability that a positive test sample is ranked higher than a negative test sample in terms of the estimated degree of abnormality."
        },
        {
            "heading": "4. Methodology",
            "text": "We present the proposed method in two steps. In Section 4.1, the spatial and semantic attributed graph is constructed to model the relations among regions in an image. In Section 4.2, a customized graph auto-encoder framework SSGAE is devised for the target task. To the best of our knowledge, this is the first work that constructs a graph model that bridges the gap between the interactions of visual and semantic information of image regions and devises a graph auto-encoder-based method to tackle the region anomaly detection task. The whole architecture of our method is illustrated in Figure 2."
        },
        {
            "heading": "4.1. Spatial and Semantic Attributed Graph",
            "text": "In both training and test phases, we obtain the regions with captions from images and extract their visual and semantic features through pre-trained deep models. Based on the acquired regions with their extracted features, we introduce the criteria for constructing the graph for each image to represent regions with their spatial and semantic relations, as shown in Figure 3.\n4.1.1. Localizing and Describing Regions in an Image\nFollowing our previous works [7,8], we apply a dense captioning model DenseCap [17], to simultaneously localize and describe regions in image Ik and select the top-n salient regions {rki |i = 1, . . . , n}with captions {cki |i = 1, . . . , n} from the generated region candidates. An example of an image containing the generated regions with captions is shown in the left part of Figure 3. Then, we utilize an image classification model, ResNet [37], and a sentence embedding model, SBERT [38], to extract visual features of regions {rki |i = 1, . . . , n} and semantic features of captions {cki |i = 1, . . . , n}.\n4.1.2. Construction of Spatial and Semantic Attributed Graph\nIn human monitoring, humans and objects often appear with specific spatial relations to one another in an image. For example, a human, a computer screen, and a desk typically appear in a regular arrangement [15]. In addition, the region captions indicate their relations at the semantic level. For example, the two region captions: \u201cman in a kitchen\u201d and \u201cwhite chair in the kitchen\u201d, are highly related to each other. Consequently, modeling such spatial and semantic relations among regions is promising to represent their contexts. We propose the spatial and semantic attributed graph Gk to model regions {rki |i = 1, . . . , n} with their relationships in image Ik. Following works on graph anomaly detection [19,30,32], we define an attributed graph as G = (V , E , X), where V = {v1, . . . , vn} represents the set of nodes (|V| = n) and E represents the set of edges (|E | = m). X \u2208 Rn\u00d7d represents the attribute matrix, where the vector xi \u2208 Rd in X in the ith row denotes the attribute of the ith node with the dimension d. The topology of G can be denoted by adjacency matrix A, where Aij = 1 represents that there exists an edge between nodes vi and vj; otherwise Aij = 0. The vector ai \u2208 Rn in A denotes the edge information, i.e., the structure, of the ith node. Therefore, the attributed graph can also be denoted as G = (A, X). In graph Gk, region rki , the concatenation Concat(rki , cki ) of its visual and semantic features rki and c k i , and its interactions with other regions in I\nk are represented as node vki , node attribute x k i , and node structure information a k i , respectively. Here Concat(\u00b7, \u00b7) denotes the concatenation operator. Consequently, training set Dtrain and test set Dtest can be represented as Gktrain = {Ak, Xk}Kk=1 and G k\u2032 test = {Ak \u2032 , Xk\n\u2032}K\u2032k\u2032=1. We assume that the spatially adjacent regions and the regions whose captions have\nhigh semantic similarities are informative to characterize the contextual information. Accordingly, we build spatial edges between nodes when their corresponding regions are spatially overlapped and semantic edges when their region captions have high semantic similarities. Following the works on semantic textual tasks [38\u201340], we utilize cosinesimilarity to compute the semantic similarity of captions.\nSim(cki , c k j ) = cki \u00b7 ckj \u2016cki \u2016\u2016ckj \u2016\n(1)\nIf Sim(cki , c k j ) > \u03b8sim, where \u03b8sim is a similarity threshold, two captions c k i and c k j are\njudged to have high semantic similarity, and thus, a semantic edge is built between nodes vki and v k j . Figure 3 shows an example of constructing a spatial and semantic attributed graph to model an image. The no. 1 region with its features is represented as node 1 with its attribute. The edges between nodes 1 and 0, as well as nodes 1 and 2, are built according to their spatially adjacent regions and the high semantic similarities of their captions, respectively."
        },
        {
            "heading": "4.2. Spatial and Semantic Graph Auto-Encoder",
            "text": "We first give an overview of the framework of SSGAE in our method. With a graph auto-encoder [18] as a backbone, SSGAE consists of three components: an attributed graph encoder, a graph structure decoder, and a graph attribute decoder. The whole architecture of SSGAE is illustrated in the right part of Figure 2. We present the overall procedure\nof SSGAE, including the training and test phases in Algorithm 1. Given the constructed graphs as input, SSGAE is devised to estimate the abnormality of each node in each graph by leveraging the node structure and the attribute reconstruction errors. In particular, we adopt the sum aggregation strategy from GIN [20] in SSGAE to discriminate the diverse node neighbors containing similar node features in the constructed graphs; we will explain the details in Section 4.2.1.\nAlgorithm 1 Overall procedure of SSGAE.\nInput: Graph Gktrain = {Ak, Xk}Kk=1, G k\u2032 test = {Ak \u2032 , Xk \u2032}K\u2032k\u2032=1; Learnable parameter \u0398; Hyper-parameter \u03b2; Number L of the hidden layers in SSGAE; Number T of the training epochs. Output: Anomaly score sk \u2032\ni for each node v k\u2032 i via function f (\u00b7).\n1: . Training Stage. 2: Randomly initialize \u0398 and the trainable parameters in MLPEnc, MLPStr\u2212Dec and\nMLPAtt\u2212Dec; 3: for t = 1, 2, \u00b7 \u00b7 \u00b7 , T do; 4: for k = 1, 2, \u00b7 \u00b7 \u00b7 , K do 5: for l = 1, 2, \u00b7 \u00b7 \u00b7 , L do 6: Calculate H(l) via Equation (3); 7: end for 8: Zk = H(L); 9: for l = 1, 2, \u00b7 \u00b7 \u00b7 , L do\n10: Calculate H\u0302(l) via Equation (6); 11: end for 12: X\u0302k = H\u0302(L); 13: Calculate A\u0302k via Equation (4); 14: Update \u0398 and the trainable parameters in MLPEnc, MLPStr\u2212Dec, and MLPAtt\u2212Dec via Equation (8) with the backpropagation algorithm. 15: end for 16: end for 17: . Test Stage. 18: for k\u2032 = 1, 2, \u00b7 \u00b7 \u00b7 , K\u2032 do 19: for l = 1, 2, \u00b7 \u00b7 \u00b7 , L do 20: Calculate H(l) via Equation (3); 21: end for 22: Zk \u2032 = H(L); 23: for l = 1, 2, \u00b7 \u00b7 \u00b7 , L do 24: Calculate H\u0302(l) via Equation (6); 25: end for 26: X\u0302k \u2032 = H\u0302(L); 27: Calculate A\u0302k \u2032\nvia Equation (4); 28: Calculate anomaly score sk\n\u2032 i of each node v k\u2032 i in Gk \u2032 test via Equation (9).\n29: end for\n4.2.1. Sum Neighborhood Aggregation Strategy\nDifferent from prevalent graph auto-encoder variants [18,19,34,35], SSGAE adopts the sum neighborhood aggregation strategy from GIN [20]. The mean-pooling or max-pooling aggregation strategies in graph auto-encoders [18,19,34,35] are capable of capturing the proportions of features or the representative feature in node neighbors, respectively. They have shown their advantages in graph anomaly detection on citation networks and social networks, in which the node features are diverse and rarely identical, as the proportions of features or the representative feature in node neighbors already provide strong signals for the task. However, in human monitoring, regions depicting similar objects, such as a desk, and similar human behaviors, such as a man sitting on a chair, frequently appear\nin images, which means that similar node features often exist in the node neighbors in the constructed graphs. In such a case, the sum neighborhood aggregation strategy [20] is capable of explicitly capturing all the features in node neighbors compared with meanpooling, max-pooling, and weighted average via attention (the weighted average via attention strategy may implicitly capture all the node features by learning different weights for node neighbors) [35] strategies. Figure 4 illustrates toy examples to show the advantage of the sum aggregation strategy in discriminating such node neighbors. The no. 0 regions in Ii and I j and their corresponding nodes are abnormal and normal in red and green colors, respectively. We assume the features of the regions in orange showing laboratory furniture are similar, and the features of the regions in blue showing the black pants are similar. We observe that the mean-pooling or max-pooling strategies aggregate the two kinds of node neighbors into approximately equivalent representations and thus cannot discriminate them well. In contrast, the sum strategy compresses the two kinds of node neighbors into discriminative representations. Consequently, we adopt the sum aggregation strategy in SSGAE since discriminating the representations of such node neighbors, which represent the context of regions, plays a critical role in the region anomaly detection task, as we will verify its effectiveness in Section 5.5.\n4.2.2. Attributed Graph Encoder\nTo learn discriminative embeddings from the node attributes and structures, the hidden layers in the attributed graph encoder are equipped with the sum aggregation strategy [20] to compress node representations in aggregation and transformation scheme. Formally, given the graph Gk = {Ak, Xk}Kk=1, the node representation h (l) i in the l\nth layer is iteratively updated as\nh(l)i = MLP (l) Enc (( 1 + \u0398(l)i ) h(l\u22121)i + \u2211vkj\u2208N (vki ) h (l\u22121) j ) , (2)\nwhere the multi-layer perceptron module MLP(l)Enc adopts the ReLU(\u00b7) activation function. We initialize h(0)i = x k i as the feature of node v k i . In the view of the whole matrix, the hidden representation matrix H(l) is formulated as\nH(l) = MLP(l)Enc (( Ak + ( 1 + \u0398(l) ) \u00b7 I ) \u00b7H(l\u22121) ) . (3)\nhere H(0) = Xk is the input node attribute matrix. After applying this procedure to L hidden layers, the final hidden embedding matrix is generated as H(L) = Zk, where Zk consists of embedding zki of each node v k i in Gk.\n4.2.3. Graph Structure Decoder\nThe node structure information, which is represented as the node and its connections to other nodes, indicates the consistency between a region and its context. Thus, reconstructing the node structure is essential to identify abnormal nodes in our task. We utilize the inner product operation, which has been widely employed by [18,19,34], with an additional MLP module MLPStr\u2212Dec to estimate the probability of edge A\u0302kij between nodes v k i and v k j as\nP ( A\u0302kij|zki , zkj ) = \u03c3 ( MLPStr\u2212Dec ( zki \u00b7 zkj T)) , (4)\nwhere \u03c3(\u00b7) denotes the sigmoid activation function and MLPStr\u2212Dec adopts the ReLU(\u00b7) activation function.\n4.2.4. Graph Attribute Decoder\nTo compare the mismatch of the nodes and their reconstructions in the attribute perspective, the graph attribute decoder is devised to decompress Zk for reconstructing the original node attributes. Similarly, we utilize the same hidden layers using the sum aggregation strategy from the attributed graph encoder. The node representation h\u0302(l)i in the lth layer is computed as\nh\u0302(l)i = MLP (l) Att\u2212Dec (( 1 + \u0398(l)i ) h\u0302(l\u22121)i + \u2211vkj\u2208N (vki ) h\u0302 (l\u22121) j ) . (5)\nThe multi-layer perceptron module MLP(l)Att\u2212Dec also adopts the ReLU(\u00b7) activation function, where the fully-connected layers are symmetric to the layers in MLP(l)Enc in terms of the number of their hidden units for reconstruction. Accordingly, total hidden representation matrix H\u0302(l) is computed as\nH\u0302(l) = MLP(l)Att\u2212Dec (( Ak + ( 1 + \u0398(l) ) \u00b7 I ) \u00b7 H\u0302(l\u22121) ) . (6)\nThe input for the graph attribute decoder is H\u0302(0) = Zk, and the output in the Lth layer is the reconstructed node attribute matrix H(L) = X\u0302k.\n4.2.5. Optimization and Anomaly Score\nAs suggested in common graph auto-encoders [19,34], the disparity between the attribute and the structure information of a node and its reconstruction is a strong signal to estimate the abnormality of the node. Following this assumption, we optimize our model by jointly minimizing the structure reconstruction error Lstr and the attribute reconstruction error Latt, which is formulated as\nL = (1\u2212 \u03b2)Lstr + \u03b2Latt (7)\n= 1 K \u2211 K k=1 ( (1\u2212 \u03b2)\u2016A\u0302k \u2212Ak\u20162F + \u03b2\u2016X\u0302k \u2212 Xk\u2016 2 F ) , (8)\nwhere \u03b2 is a hyper-parameter to balance Lstr and Latt. Trained on graphs that contain only normal nodes, SSGAE is capable of reconstructing the high-quality attributes and structures of the normal nodes [19] by optimizing the objective function. Therefore, in the test stage, SSGAE is supposed to output a high attribute reconstruction error and a high structure reconstruction error for an abnormal node in the test set. We define the anomaly score function f (\u00b7) for node vk\u2032i to estimate its degree of abnormality as\nsk \u2032 i = f (v k\u2032 i ) = (1\u2212 \u03b2)\u2016a\u0302k \u2032 i \u2212 ak \u2032 i \u2016 2 2 + \u03b2\u2016x\u0302 k\u2032 i \u2212 xk \u2032 i \u2016 2 2. (9)\nSince node vk \u2032 i in graph Gk \u2032 test corresponds to region r k\u2032 i in image I k\u2032 , we can rank the anomalous image regions through their computed anomaly scores."
        },
        {
            "heading": "5. Experiments",
            "text": "We first introduce three real-world datasets and conduct experiments to evaluate the performance of SSGAE and the baseline methods. Then the experimental results are illustrated, including a comparison of performance, a parameter study, and an investigation into the effectiveness of its components."
        },
        {
            "heading": "5.1. Datasets",
            "text": "We evaluate SSGAE on three real-world datasets: LabPatrolling, BehaviorMonitoring, and AnoVisualGenome. The first two datasets are constructed from the human monitoring video clips collected by our autonomous robot in a real laboratory environment, which have been adopted in our previous work [7\u20139,14]. We additionally construct a new dataset named AnoVisualGenome by randomly selecting a subset of human-related images, which includes human activities in various environments, from a large-scale region caption dataset Visual Genome (https://visualgenome.org/, accessed on 17 January 2022) [21]. These three datasets consist of diverse region anomalies, i.e., single and contextual anomalies, and thus pose a challenge to detection algorithms. The instructions for these datasets are given as follows.\n\u2022 LabPatrolling [14] is constructed from the video clips when the mobile robot patrols around the laboratory. It includes various single anomalies, such as a man holding a baseball bat and a man holding an umbrella in the room, as well as a small number of contextual anomalies, such as a man making a phone call in the working area. It contains 5146 normal images for training, as well as 373 normal images and 21 abnormal images for testing. \u2022 BehaviorMonitoring [14] is constructed from another large-scale human monitoring dataset of video clips (almost 100 h) when the mobile robot is navigated to designated locations by a program to monitor diverse human behaviors in the laboratory. It includes a wide range of contextual anomalies of many human behaviors, such as eating and sleeping in the working and resting areas, which are defined as normal and abnormal activities. It contains 5548 normal images for training, as well as 585 normal images and 106 abnormal images for testing. \u2022 AnoVisualGenome is constructed from Visual Genome [21], which provides dense annotations for regions on over 108K images. It includes several kinds of human activities in inappropriate environments as contextual anomalies, such as watching TV on the street and sitting on a couch on the beach. It contains 1427 normal images for training, as well as 218 normal images and 31 abnormal images for testing.\nFor our target task, after obtaining salient regions from images, we annotate regionlevel anomalies in the images, including anomalous human behaviors or irregular humanobject interactions. Several examples of images containing normal and abnormal regions are shown in Figure 5.\n5.2. Experimental Setup 5.2.1. Preprocessing\nIn the preprocessing stage, by utilizing advanced pre-trained deep models, we obtain regions with their captions in images and generate the visual and semantic features of regions to construct graphs. Specifically, we utilize a dense captioning model Densecap (https://github.com/ jcjohnson/densecap, accessed on 19 March 2020) [17] pre-trained on Visual Genome [21] in a standard implementation to generate region candidates for the first two datasets and select the top-n region candidates per image based on their confidence scores. By investigating the qualities of the generated regions with captions, n is set to 10 [7\u20139]. For AnoVisualGenome, as the number of regions with captions per image ranges from 10 to 60, we randomly select 10 regions for each image. Subsequently, ResNet101 (https://pytorch.org/vision/stable/models/resnet.html, accessed on 10 April 2021) is adopted to extract the visual feature of each region from the output in the penultimate layer with dimension 2048. An SBERT model named \u201call-mpnetbase-v2\u201d (https://huggingface.co/sentence-transformers/all-mpnet-base-v2, accessed on 15 January 2022) is adopted for transforming each region caption into an embedded vector with dimension 768. ResNet101 and SBERT are applied under their default settings and pre-trained on ImageNet [41] and 14 sentence datasets [38], respectively.\n5.2.2. Baseline Algorithms\nWe compare our method with several traditional and popular anomaly detection algorithms, including Auto-Encoders (AE) [42] and GANomaly (https://github.com/ samet-akcay/ganomaly, accessed on 16 January 2020) [36], our previous region anomaly detection methods, Anomalous Image Region Detection (AIRD) [7] and Fast-and-SlowThinking Anomaly Detection (FSTAD) [8], as well as three variants of graph auto-encoders, Variational Graph Auto-Encoders (https://github.com/DaehanKim/vgae_pytorch, accessed on 20 April 2021) (VGAE) [18], Deep Anomaly Detection on Attributed Networks (https://github.com/kaize0409/GCN_AnomalyDetection_pytorch, accessed on 18 March 2022) (DOMINANT) [19], and Graph Attention Auto-Encoders (GATE) [35].\n\u2022 AE [42] is a classical reconstruction-based method for anomaly detection. Both the encoder and the decoder are designed with fully-connected layers.\n\u2022 GANomaly [36] is a popular generative anomaly detection method. It adopts an encoder-decoder-encoder module as a generator and three loss functions to jointly reconstruct images and features in a latent space. \u2022 AIRD [7] is a one-class region anomaly detection method. It combines the visual, caption, and coordinate features of each region as its representation and employs an incremental clustering method to model normal regions. \u2022 FSTAD [8] employs AIRD as its fast module for detecting single anomalies and devises a slow module recording neighboring regions with their visual features for detecting anomalous region pairs. \u2022 VGAE [18] is the first model to extend the auto-encoder framework on graph data. It encodes node representations by GCN layers and utilizes an inner product decoder for reconstructing the adjacency matrix of graph data. \u2022 DOMINANT [19] is the state-of-the-art graph auto-encoder for detecting anomalous nodes in attributed graphs by devising GCN-based components and adopting reconstruction errors as the anomaly scores. \u2022 GATE [35] is a graph auto-encoder variant that stacks graph attention layers in its encoder and decoder for graph classification tasks.\n5.2.3. Implementation Details\nIn the spatial and semantic graph, the semantic similarity threshold \u03b8sim for building semantic edges is set to 0.5 in our experiments. The proposed method SSGAE is implemented in Pytorch (version 1.6.0) and optimized by Adam with a learning rate 0.004 and a weight decay 8\u00d7 10\u22125. The attributed graph encoder is equipped with L = 2 hidden layers along with their MLP modules, both of which contain two fully-connected layers with the hidden units (2816\u2212 256\u2212 256) and (256\u2212 256\u2212 128), respectively, with ReLU activation function. Accordingly, the graph attribute decoder also contains two hidden layers with their MLP modules, in which the fully-connected layers are symmetric to the layers in the encoder in terms of the number of their hidden units for reconstruction. In the graph structure decoder, the dimensions of the fully-connected layers in MLPstr\u2212dec are set to (128\u2212 256\u2212 256). The hidden layers of other graph auto-encoder models in the baselines are set to the same dimensions as SSGAE for a fair comparison. SSGAE and the other graph auto-encoder variants are trained for T = 400 epochs on the first two datasets and T = 200 epochs on AnoVisuaGenome. Hyper-parameter \u03b2 in SSGAE is set to 0.8, 0.8, and 0.9 for LabPatrolling, BehaviorMonitoring, and AnoVisuaGenome, respectively. When implementing other baseline methods, we retain the suggested settings in their original papers."
        },
        {
            "heading": "5.3. Experimental Results and Analysis",
            "text": "Figure 6 and Table 2 show the ROC curve and AUC score of SSGAE compared with the baselines on the three datasets, respectively. Moreover, Figure 7 illustrates the anomaly score distributions of all methods by boxplot, which displays the lower quartile, the median, and the upper quartile of the scores in a box and extends the box from the lowest to the highest scores by a line segment. We have the following findings based on the results.\n1. SSGAE outperforms all the baseline methods on the three datasets, which achieves 0.016\u2212 0.387, 0.038\u2212 0.315, and 0.043\u2212 0.345 improvements in terms of their AUC scores on LabPatrolling, BehaviorMonitoring, and AnoVisualGenome, respectively. This validates the superiority of our method for the region anomaly detection task. The main reason is that SSGAE is capable of discriminating node representations from the spatial and semantic graphs and thus generates separated reconstruction errors to measure the abnormalities of regions, as shown in the example in Figure 8. 2. The previous methods, which do not consider region contexts, i.e., AE, GANomaly, and AIRD, achieve competitive performance on LabPatrolling, where most of the anomalies are single anomalies. This fact proves their effectiveness in detecting single anomalies that are dissimilar to normal regions, e.g., normal and abnormal regions\nin the upper row in Figure 8. However, these methods do not perform well on BehaviorMonitoring and AnoVisual Genome, where there exist a large number of contextual anomalies. For instance, GANomaly achieves an AUC score of 0.911 on LabParolling, while it only achieves 0.794 and 0.687 on the other two datasets. The distributions of the anomaly scores on the two datasets shown in (b) and (c) in Figure 7 demonstrate that AE, GANomaly, and AIRD are unable to separate the normal and abnormal regions very well. We think the reason would be that without considering the region contexts, the contextual anomalies include similar human behaviors as normal regions, which are difficult to detecte with these methods. To confirm the reason, we investigate the anomaly scores of the examples, including a normal region and a contextual anomaly, i.e., the no. 0 regions in the upper and bottom images in the left part of Figure 8. Compared with SSGAE, which outputs the anomaly score of 0.565/0.814 on the normal/abnormal regions in Figure 8, AE, GANomaly, and AIRD output 0.425/0.462, 0.199/0.381, and 0.542/0.639, respectively. These findings indicate that the methods that do not consider region contexts have deficiencies in detecting contextual anomalies compared with SSGAE.\n3. Compared with other graph auto-encoder variants, SSGAE achieves significant performance gains with the improvements of 0.043, 0.055, and 0.043 on the three datasets in terms of AUC scores. Accordingly, the anomaly scores of normal and abnormal regions generated by SSGAE are better separated compared with these baseline methods, as shown in Figure 7. The main difference between SSGAE and other graph auto-encoders is the sum aggregation strategy, which plays a critical role in discriminating the representations of node neighbors. We verify the effectiveness of the sum aggregation strategy in SSGAE by substituting it with the aggregation strategies in other graph auto-encoders, as illustrated in Section 5.5. 4. We observe that VGAE performs worst on the target task, although its encoder is similar to the encoders in other graph auto-encoders. We notice that compared with DOMINANT, GATE, and SSGAE, the decoder in VGAE only aims at reconstructing the graph structure without considering the reconstruction of node attributes in the graph. This fact implies that both the structure and the attribute reconstructions are necessary for our method of the task.\nWe also show an example of detecting normal and anomalous regions by SSGAE in Figure 8. In the upper image, the no. 0 region of a man making a phone call (the green\nbox) in a resting area is normal, while the no. 0 region of the same behavior (the red box) in a working area in the bottom image is abnormal due to their different contexts. We visualize the original features of two regions and their embeddings generated by SSGAE with Principal Component Analysis (PCA) [43]. We see that although the two regions are closely located in the original feature space, trained on normal data, SSGAE can compress the two regions with their contextual information into well-separated embeddings and thus generate accurate anomaly scores in the right part of Figure 8. Considering the feasibility of applying our method to real-time region anomaly detection in human monitoring, we also evaluate the actual running time of the method in the test phase. For each test image, the proposed method outputs the anomaly scores of all regions with an average running time of 0.53 s. We believe this performance is sufficient as we target human monitoring. Here we assume that the preprocessing procedure, which includes extracting pre-trained features and constructing graphs, is conducted before the monitoring process. The computation time of the preprocessing procedure during testing is about 3 m 48 s, 7 m 58 s, and 2 m 16 s on LabPatrolling, BehaviorMonitoring, and AnoVisualGenome, respectively."
        },
        {
            "heading": "5.4. Parameter Sensitivity Study",
            "text": "To investigate the effects of embedding dimensions de of the final hidden embedding and hyper-parameter \u03b2 in the objective function on the performance of SSGAE, we conduct experiments by modifying their values. We first explore the sensitivity to dimension de of the final hidden embedding by setting the values of de from 4 to 256. We show the performance of SSGAE in Figure 9a. On BehavoringMonitoring and LabPatrolling, the performance steadily improves when de increases from 4 and reaches the peak value of 128, and then it drops slightly when de is 256. On AnoVisualGenome, the AUC score also steadily increases from de = 4 to de = 128. Then the performance gain becomes smaller when de = 256. These results show that de should be in an appropriate range, e.g., from 64 to 256, for the target task.\nWe then modify the value of \u03b2 in the range of {0.0, 0.1, 0.2, . . . , 1.0} and show the results in Figure 9b. According to the results, the AUC score rises when \u03b2 increases and reaches the peak value at 0.8, 0.8, and 0.9 on LabPatrolling, BehaviorMonitoring, and AnoVisualGenome, respectively. In particular, we can evaluate the performance of SSGAE only equipped with the structure decoder when \u03b2 = 0.0 and only equipped with the attribute decoder when \u03b2 = 1.0. We observe that our model achieves poor results when merely considering the structure reconstruction error, which indicates that attribute information is necessary for our task. On the contrary, by merely utilizing an attribute decoder in SSGAE, we cannot achieve the best results, which indicates the significance of jointly optimizing SSGAE by the structure reconstruction error and the attribute reconstruction error. These\nresults show that it is necessary to find a trade-off to balance the two kinds of reconstruction errors for our task."
        },
        {
            "heading": "5.5. Effectiveness of Components",
            "text": "We further investigate the effectiveness of components in our method, i.e., the impacts of jointly considering the spatial and semantic relations in the proposed graph and the sum aggregation strategy in SSGAE. We first conduct an ablation study by building two variants of the graph, i.e., the spatial attributed graph and the semantic attributed graph, which consider spatial relations only and semantic relations only among regions, respectively. Table 3 shows the results of SSGAE with these graphs. We observe that SSGAE on the spatial or semantic attributed graph achieves suboptimal performance, which implies the superiority of considering both the spatial and semantic relations in the graph. Figure 10 shows several normal (green color) and abnormal (red color) examples in (a)\u2013(e) with their anomaly scores in (f). These examples in (a)\u2013(e) include several human behaviors, such as a human sleeping, making a call, eating, and sitting on a couch, in different contexts. We observe that with the spatial attributed graph and the semantic attributed graph, the anomaly scores in (f) of the normal and abnormal regions are not well-separated compared to SSGAE with the spatial and semantic graphs. These results validate the effectiveness of the spatial and semantic graphs on the target task.\nWe then verify the effectiveness of the sum aggregation strategy by substituting it with the mean-pooling and the max-pooling strategies in SSGAE. Based on the results in Table 3, SSGAE adopting the mean-pooling or max-pooling aggregation strategy achieves competitive performance on LabPatrolling. The reason would be that most anomalous regions in LabPatrolling are single anomalies and, thus, are easy to be detected by any of the aggregation strategies. However, the diverse contextual anomalies in BehaviorMonitoring and AnovisualGenome need to be judged by combining the regions with their contexts. Figure 10 shows the anomaly scores of regions in (a)\u2013(e) with different strategies in (g). We observe that SSGAE adopting the sum aggregation strategy discriminates the normal and abnormal regions better than SSGAE adopting the other two strategies in terms of their anomaly scores. For instance, the normal and abnormal regions in Figure 10a show a human sleeping in the working and resting areas. SSGAE with the sum aggregation strategy generates the highest anomaly score for the abnormal region and a relatively low score for the normal region in (a) compared to SSGAE with the other two strategies. This implies the effectiveness of adopting the sum aggregation strategies in SSGAE for detecting contextual anomalies in our task."
        },
        {
            "heading": "6. Conclusions",
            "text": "This paper tackles the region anomaly detection task in human monitoring via constructing the spatial and semantic attributed graph and proposing the graph auto-encoder framework SSGAE. To characterize the anomalous region based on its content and context, we build the graph to model regions with their spatial and semantic relations in the image. Subsequently, SSGAE equipped with the sum aggregation strategy, which consists of one encoder and dual decoders, is introduced for our task. Due to the lack of rare and diverse anomalies in human monitoring, SSGAE is trained to reconstruct the node attributes and structures in the graph in a one-class anomaly detection manner. In the test stage, the structure and the attribute reconstruction errors are then jointly employed in the anomaly score to estimate the abnormality of nodes as well as their corresponding regions. We conducted extensive experiments and analyzed the results to evaluate the superiority of SSGAE on the target problem. In our method, generating accurate regions and captions from images is important to build spatial and semantic relations in the proposed graph, though we notice that a few regions and captions generated by Densecap [17] are insufficient in quality for human monitoring. Therefore, improving the quality of the regions and captions through, for instance, a specialized, elaborate fine-tuning of the pre-trained model would be one of our future works. Another future work is to explore a more informative graph model, e.g., weighted graphs, to represent the importance of relations among regions. Such a model would promote our future method toward more real-world applications in complex scenarios. In addition, we expect that extending the proposed method for anomaly detection in other domains opens promising research avenues. For instance, climate monitoring [44] and single-object anomaly detection [15] call for defining nodes dynamically, as these domains include vague objects, e.g., clouds, and ill-defined objects, e.g., a part of a building. The definition could be iterative, i.e., the construction of the attributed graph and the detection of anomalies should be repeated by accumulating useful clues. This paper, which targets anomaly detection in human monitoring, would serve as a fundamental step in such an avenue.\nAuthor Contributions: Conceptualization, K.Z.; methodology, K.Z.; software, K.Z.; validation, K.Z. and E.S.; data curation, K.Z. and M.F.F.; formal analysis, K.Z. and E.S.; writing\u2014original draft preparation, K.Z.; writing\u2014review and editing, K.Z. and E.S.; supervision, E.S.; project administration, K.Z. and E.S.; funding acquisition, E.S. All authors have read and agreed to the published version of the manuscript.\nFunding: This research was partially funded by the China Scholarship Council, Grant No. 201906330075.\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability Statement: The datasets generated during and/or analyzed during the current study are available from the corresponding author on reasonable request.\nAcknowledgments: We thank other laboratory members who contributed to collecting the human monitoring datasets.\nConflicts of Interest: The authors declare no conflict of interest.\nReferences 1. Sultani, W.; Chen, C.; Shah, M. Real-World Anomaly Detection in Surveillance Videos. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 6479\u20136488. [CrossRef] 2. Luo, W.; Liu, W.; Lian, D.; Gao, S. Future Frame Prediction Network for Video Anomaly Detection. IEEE Trans. Pattern Anal. Mach. Intell. 2021, 44, 7505\u20137520. [CrossRef] [PubMed] 3. Yu, M.; Li, G.; Jiang, D.; Jiang, G.; Tao, B.; Chen, D. Hand Medical Monitoring System Based on Machine Learning and Optimal EMG Feature Set. Pers. Ubiquitous Comput. 2019, 1\u201317. [CrossRef] 4. Wu, P.; Liu, J.; Shi, Y.; Sun, Y.; Shao, F.; Wu, Z.; Yang, Z. Not Only Look, but Also Listen: Learning Multimodal Violence Detection\nunder Weak Supervision. In Proceedings of the European Conference on Computer Vision, Glasgow, UK, 23\u201328 August 2020; pp. 322\u2013339. [CrossRef]\n5. Deguchi, Y.; Takayama, D.; Takano, S.; Scuturici, V.M.; Petit, J.M.; Suzuki, E. Skeleton Clustering by Multi-Robot Monitoring for Fall Risk Discovery. J. Intell. Inf. Syst. 2017, 48, 75\u2013115. [CrossRef] 6. Meng, F.; Yuan, G.; Lv, S.; Wang, Z.; Xia, S. An Overview on Trajectory Outlier Detection. Artif. Intell. Rev. 2019, 52, 2437\u20132456. [CrossRef] 7. Hatae, Y.; Yang, Q.; Fadjrimiratno, M.F.; Li, Y.; Matsukawa, T.; Suzuki, E. Detecting Anomalous Regions from an Image based on Deep Captioning. In Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, Valletta, Malta, 27\u201329 February 2020; Volume 5, pp. 326\u2013335. [CrossRef] 8. Fadjrimiratno, M.F.; Hatae, Y.; Matsukawa, T.; Suzuki, E. Detecting Anomalies from Human Activities by an Autonomous Mobile Robot based on \u201cFast and Slow\u201d Thinking. In Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, Online Streaming, 8\u201310 February 2021; Volume 5, pp. 943\u2013953. [CrossRef] 9. Dong, N.; Suzuki, E. GIAD-ST: Detecting Anomalies in Human Monitoring Based on Generative Inpainting via Self-Supervised Multi-Task Learning. J. Intell. Inf. Syst. 2022, 59, 733\u2013754. [CrossRef] 10. Yi, J.; Yoon, S. Patch SVDD: Patch-level SVDD for Anomaly Detection and Segmentation. In Proceedings of the Asian Conference on Computer Vision, Kyoto, Japan, 30 November\u20134 December 2020. [CrossRef] 11. Li, C.L.; Sohn, K.; Yoon, J.; Pfister, T. CutPaste: Self-Supervised Learning for Anomaly Detection and Localization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Kyoto, Japan, 30 November 2020; pp. 9664\u20139674. [CrossRef] 12. Wu, K.; Zhu, L.; Shi, W.; Wang, W.; Wu, J. Self-Attention Memory-Augmented Wavelet-CNN for Anomaly Detection. IEEE Trans. Circuits Syst. Video Technol. 2022, early access. [CrossRef] 13. Mu, H.; Sun, R.; Wang, M.; Chen, Z. Spatio-Temporal Graph-Based CNNs for Anomaly Detection in Weakly-Labeled Videos. Inf. Process. Manag. 2022, 59, 102983. [CrossRef] 14. Zhang, K.; Fadjrimiratno, M.F.; Suzuki, E. Context-Based Anomaly Detection via Spatial Attributed Graphs in Human Monitoring. In Proceedings of the International Conference on Neural Information Processing, Sanur, Bali, Indonesia, 8 December 2021; pp. 450\u2013463. [CrossRef] 15. Choi, M.J.; Torralba, A.; Willsky, A.S. Context Models and Out-of-Context Objects. Pattern Recognit. Lett. 2012, 33, 853\u2013862. [CrossRef] 16. Pasini, A.; Baralis, E. Detecting Anomalies in Image Classification by means of Semantic Relationships. In Proceedings of the 2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE), Sardinia, Italy, 3\u20135 June 2019; pp. 231\u2013238. [CrossRef] 17. Johnson, J.; Karpathy, A.; Fei-Fei, L. DenseCap: Fully Convolutional Localization Networks for Dense Captioning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV, USA, 27\u201330 June 2016; pp. 4565\u20134574. [CrossRef] 18. Kipf, T.N.; Welling, M. Variational Graph Auto-Encoders. arXiv 2016, arXiv:1611.07308. 19. Ding, K.; Li, J.; Bhanushali, R.; Liu, H. Deep Anomaly Detection on Attributed Networks. In Proceedings of the 2019 SIAM International Conference on Data Mining, Calgary, AB, Canada, 2\u20134 May 2019; pp. 594\u2013602. [CrossRef] 20. Xu, K.; Hu, W.; Leskovec, J.; Jegelka, S. How Powerful are Graph Neural Networks? In Proceedings of the International Conference on Learning Representations, New Orleans, LA, USA, 6\u20139 May 2019. 21. Krishna, R.; Zhu, Y.; Groth, O.; Johnson, J.; Hata, K.; Kravitz, J.; Chen, S.; Kalantidis, Y.; Li, L.J.; Shamma, D.A.; et al. Visual\nGenome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations. Int. J. Comput. Vis. 2017, 123, 32\u201373. [CrossRef]\n22. Bergmann, P.; Fauser, M.; Sattlegger, D.; Steger, C. MVTec AD\u2014A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 9592\u20139600. [CrossRef] 23. Seeb\u00f6ck, P.; Waldstein, S.; Klimscha, S.; Gerendas, B.S.; Donner, R.; Schlegl, T.; Schmidt-Erfurth, U.; Langs, G. Identifying and Categorizing Anomalies in Retinal Imaging Data. arXiv 2016, arXiv:1612.00686. 24. Schlegl, T.; Seeb\u00f6ck, P.; Waldstein, S.M.; Schmidt-Erfurth, U.; Langs, G. Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery. In Proceedings of the International Conference on Information Processing in Medical Imaging, Boone, NC, USA, 25\u201330 June 2017; pp. 146\u2013157. [CrossRef] 25. Venkataramanan, S.; Peng, K.C.; Singh, R.V.; Mahalanobis, A. Attention Guided Anomaly Localization in Images. In Proceedings of the European Conference on Computer Vision, Glasgow, UK, 23\u201328 August 2020; pp. 485\u2013503. [CrossRef] 26. Gong, D.; Liu, L.; Le, V.; Saha, B.; Mansour, M.R.; Venkatesh, S.; Hengel, A.v.d. Memorizing Normality to Detect Anomaly: Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision, Seoul, Republic of Korea, 27 October\u20132 November 2019; pp. 1705\u20131714. [CrossRef] 27. Sun, C.; Jia, Y.; Hu, Y.; Wu, Y. Scene-Aware Context Reasoning for Unsupervised Abnormal Event Detection in Videos. In Proceedings of the 28th ACM International Conference on Multimedia, Seattle, WA, USA, 12\u201316 October 2020; pp. 184\u2013192. [CrossRef] 28. Pourreza, M.; Salehi, M.; Sabokrou, M. Ano-Graph: Learning Normal Scene Contextual Graphs to Detect Video Anomalies. arXiv 2021, arXiv:2103.10502. 29. Wu, Z.; Pan, S.; Chen, F.; Long, G.; Zhang, C.; Philip, S.Y. A Comprehensive Survey on Graph Neural Networks. IEEE Trans. Neural Netw. Learn. Syst. 2020, 32, 4\u201324. [CrossRef] 30. Liu, Y.; Li, Z.; Pan, S.; Gong, C.; Zhou, C.; Karypis, G. Anomaly Detection on Attributed Networks via Contrastive Self-Supervised Learning. IEEE Trans. Neural Netw. Learn. Syst. 2021, 33, 2378\u20132392. [CrossRef] 31. Zheng, Y.; Jin, M.; Liu, Y.; Chi, L.; Phan, K.T.; Chen, Y.P.P. Generative and Contrastive Self-Supervised Learning for Graph Anomaly Detection. IEEE Trans. Knowl. Data Eng. 2021, early access. [CrossRef] 32. Jin, M.; Liu, Y.; Zheng, Y.; Chi, L.; Li, Y.F.; Pan, S. ANEMONE: Graph Anomaly Detection with Multi-Scale Contrastive Learning. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management, Queensland, Australia, 1\u20135 November 2021; pp. 3122\u20133126. [CrossRef] 33. Kipf, T.N.; Welling, M. Semi-Supervised Classification with Graph Convolutional Networks. arXiv 2016, arXiv:1609.02907. 34. Fan, H.; Zhang, F.; Li, Z. AnomalyDAE: Dual Autoencoder for Anomaly Detection on Attributed Networks. In Proceedings of\nthe ICASSP 2020\u20142020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Barcelona, Spain, 4\u20138 May 2020; pp. 5685\u20135689. [CrossRef]\n35. Salehi, A.; Davulcu, H. Graph Attention Auto-Encoders. In Proceedings of the IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI), Baltimore, MD, USA, 9\u201311 November 2020; pp. 989\u2013996. [CrossRef] 36. Akcay, S.; Atapour-Abarghouei, A.; Breckon, T.P. GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training. In Proceedings of the Asian Conference on Computer Vision, Perth, Australia, 2\u20136 December 2018; pp. 622\u2013637. [CrossRef] 37. He, K.; Zhang, X.; Ren, S.; Sun, J. Deep Residual Learning for Image Recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV, USA, 27\u201330 June 2016; pp. 770\u2013778. [CrossRef] 38. Reimers, N.; Gurevych, I. Sentence-Bert: Sentence Embeddings Using Siamese Bert-Networks. arXiv 2019, arXiv:1908.10084. 39. Devlin, J.; Chang, M.W.; Lee, K.; Toutanova, K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv 2018, arXiv:1810.04805. 40. Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.; Levy, O.; Lewis, M.; Zettlemoyer, L.; Stoyanov, V. Roberta: A robustly optimized bert pretraining approach. arXiv 2019, arXiv:1907.11692. 41. Deng, J.; Dong, W.; Socher, R.; Li, L.J.; Li, K.; Fei-Fei, L. ImageNet: A Large-Scale Hierarchical Image Database. In Proceedings\nof the 2009 IEEE Conference on Computer Vision and Pattern Recognition, Miami, FL, USA, 20\u201325 June 2009; pp. 248\u2013255. [CrossRef]\n42. Bengio, Y.; Lamblin, P.; Popovici, D.; Larochelle, H. Greedy Layer-Wise Training of Deep Networks. In Proceedings of the Advances in Neural Information Processing Systems, Vancouver, BC, Canada, 4\u20137 December 2006; pp. 153\u2013160. 43. Shlens, J. A Tutorial on Principal Component Analysis. arXiv 2014, arXiv:1404.1100. 44. Li, G.; Jung, J.J. Entropy-based dynamic graph embedding for anomaly detection on multiple climate time series. Sci. Rep. 2021,\n11, 13819. [CrossRef] [PubMed]\nDisclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."
        }
    ],
    "title": "Region Anomaly Detection via Spatial and Semantic Attributed Graph in Human Monitoring ",
    "year": 2023
}