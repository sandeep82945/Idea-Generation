{
    "abstractText": "Sign language (SL) has strong structural features. Various gestures and the complex trajectories of hand movements bring challenges to sign language recognition (SLR). Based on the inherent correlation between gesture and trajectory of SL action, SLR is organically divided into gesture-based recognition and gesture-related movement trajectory recognition. One hundred and twenty commonly used Chinese SL words involving 9 gestures and 8 movement trajectories, are selected as research and test objects. The method based on the amplitude state of surface electromyography (sEMG) signal and acceleration signal is used for vocabulary segmentation. The multi-sensor decision fusion method of coupled hidden Markov model is used to complete the recognition of SL vocabulary, and the average recognition rate is 90.41%. Experiments show that the method of sEMG signal and motion information fusion has good practicability in SLR.",
    "authors": [
        {
            "affiliations": [],
            "name": "Wenyu LiID"
        },
        {
            "affiliations": [],
            "name": "Zhizeng Luo"
        },
        {
            "affiliations": [],
            "name": "Wenguo Li"
        },
        {
            "affiliations": [],
            "name": "Xugang Xi"
        }
    ],
    "id": "SP:af20e6204201d09a2f68fa036351c636dd51d1b5",
    "references": [
        {
            "authors": [
                "K Bantupalli",
                "Y Xie",
                "editors"
            ],
            "title": "American sign language recognition using deep learning and computer vision",
            "venue": "IEEE International Conference on Big Data (Big",
            "year": 2018
        },
        {
            "authors": [
                "AR Asif",
                "A Waris",
                "SO Gilani",
                "M Jamil",
                "H Ashraf",
                "M Shafique"
            ],
            "title": "Performance evaluation of convolutional neural network for hand gesture recognition using EMG",
            "venue": "PMID:",
            "year": 2006
        },
        {
            "authors": [
                "A Mittal",
                "P Kumar",
                "PP Roy",
                "R Balasubramanian",
                "BBJISJ. Chaudhuri"
            ],
            "title": "A modified LSTM model for continuous sign language recognition using leap",
            "year": 2019
        },
        {
            "authors": [
                "P Kumar",
                "H Gauba",
                "PP Roy",
                "DPJN. Dogra"
            ],
            "title": "A multimodal framework for sensor based sign language recognition",
            "year": 2017
        },
        {
            "authors": [
                "C Savur",
                "F Sahin",
                "editors"
            ],
            "title": "American Sign Language Recognition system by using surface EMG signal. 2016",
            "venue": "IEEE International Conference on Systems,",
            "year": 2016
        },
        {
            "authors": [
                "B Lei",
                "L Zhizeng",
                "X Xugang",
                "L. Wenguo"
            ],
            "title": "Gesture Recognition Based on the Fusion of Surface Electromyography and Acceleration",
            "venue": "Chinese Journal of Sensors and Actuators",
            "year": 2019
        },
        {
            "authors": [
                "Wu J",
                "Sun L",
                "Jafari RJIjob",
                "informatics h"
            ],
            "title": "A wearable system for recognizing American sign language in real-time using IMU and surface EMG",
            "year": 2016
        },
        {
            "authors": [
                "X Yang",
                "X Chen",
                "X Cao",
                "S Wei",
                "XJIjob Zhang",
                "h. informatics"
            ],
            "title": "Chinese sign language recognition based on an optimized tree-structure framework",
            "year": 2016
        },
        {
            "authors": [
                "A Tigrini",
                "F Verdini",
                "M Scattolini",
                "F Barbarossa",
                "L Burattini",
                "M Morettini"
            ],
            "title": "Handwritten Digits Recognition from sEMG: Electrodes",
            "venue": "Location and Feature Selection",
            "year": 2023
        },
        {
            "authors": [
                "P Yang",
                "X Chen",
                "Y Li",
                "W Wang",
                "JJHYyYG. Yang"
            ],
            "title": "A sign language recognition method based on multisensor information",
            "year": 2012
        },
        {
            "authors": [
                "J Tian",
                "X Chen",
                "Y Li",
                "JJCJoBE. Yang"
            ],
            "title": "A Chinese Sign Language Recognition Approach Based on Multiple Sensor Information Fusion and Statistical Language Model",
            "year": 2011
        },
        {
            "authors": [
                "Wen-bin XJSJTU"
            ],
            "title": "Study on Coupled Hidden Markov Model Based Rolling Element Bearing Fault Diagnosis and Performance Degradation Assessment",
            "year": 2011
        },
        {
            "authors": [
                "H Jun",
                "Z Hua",
                "L. Jizhong"
            ],
            "title": "Multi-sensor asynchronous information fusion classification strategy based on coupled HMM",
            "venue": "Application Research of Computers",
            "year": 2009
        },
        {
            "authors": [
                "Q Ding",
                "A Xiong",
                "X Zhao",
                "JJAAS. Han"
            ],
            "title": "A review on researches and applications of sEMG-based motion intent recognition",
            "year": 2016
        },
        {
            "authors": [
                "JG Abreu",
                "JM Teixeira",
                "LS Figueiredo",
                "V Teichrieb",
                "editors"
            ],
            "title": "Evaluating sign language recognition using the myo armband. 2016 XVIII symposium on virtual and augmented reality (SVR); 2016",
            "year": 2016
        },
        {
            "authors": [
                "JG Beltr\u00e1n Hern\u00e1ndez",
                "J Ruiz Pinales",
                "P L\u00f3pez Rodr\u0131\u0301guez",
                "JL L\u00f3pez Ram\u0131\u0301rez",
                "JGJMB Avi\u00f1a Cervantes",
                "ENGINEERING"
            ],
            "title": "Multi-Stroke handwriting character recognition based on sEMG using convolutional-recurrent",
            "year": 2020
        },
        {
            "authors": [
                "XI X-g ZUO J",
                "LUO Z-zJAES"
            ],
            "title": "Weighted kernel FDA fall recognition of EMG fuzzy entropy",
            "year": 2016
        },
        {
            "authors": [
                "W Li",
                "Z Luo",
                "Y Jin",
                "XJS. Xi"
            ],
            "title": "Gesture recognition based on multiscale singular value entropy and deep belief network",
            "venue": "PMID:",
            "year": 2020
        },
        {
            "authors": [
                "W Li",
                "Z Luo",
                "XJE. Xi"
            ],
            "title": "Movement trajectory recognition of sign language based on optimized dynamic time warping",
            "year": 2020
        },
        {
            "authors": [
                "C Xiang",
                "S. Ruiliang"
            ],
            "title": "Optimized Strategy of fHMM for Real-time Multi-sensor Gesture Recognition",
            "venue": "Space Medicine & Medical Engineering",
            "year": 2015
        },
        {
            "authors": [
                "G Hao",
                "W Zhibo",
                "Z Lili",
                "Z. Chao"
            ],
            "title": "Research on Transformer Fault Diagnosis Based on coupled hidden Markov model",
            "venue": "Guangdong Electric Power",
            "year": 2015
        },
        {
            "authors": [
                "Wang JS",
                "Chuang FCJIToIE"
            ],
            "title": "An Accelerometer-Based Digital Pen With a Trajectory Recognition Algorithm for Handwritten Digit and Gesture Recognition",
            "year": 2012
        },
        {
            "authors": [
                "Y Zhuang",
                "B Lv",
                "X Sheng",
                "X Zhu",
                "editors"
            ],
            "title": "Towards Chinese sign language recognition using surface electromyography and accelerometers",
            "year": 2017
        },
        {
            "authors": [
                "Heickal H",
                "Zhang T",
                "Hasanuzzaman MJIJoI",
                "Graphics"
            ],
            "title": "Computer vision-based real-time 3D gesture recognition using depth",
            "year": 2015
        },
        {
            "authors": [
                "Y Zhou",
                "Z Cheng",
                "L Jing",
                "J Wang",
                "TJAi. Huang"
            ],
            "title": "Pre-classification based hidden Markov model for quick and accurate gesture recognition using a finger-worn device",
            "venue": "PLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December",
            "year": 2014
        }
    ],
    "sections": [
        {
            "text": "Sign language (SL) has strong structural features. Various gestures and the complex trajec-\ntories of hand movements bring challenges to sign language recognition (SLR). Based on\nthe inherent correlation between gesture and trajectory of SL action, SLR is organically\ndivided into gesture-based recognition and gesture-related movement trajectory recogni-\ntion. One hundred and twenty commonly used Chinese SL words involving 9 gestures and 8\nmovement trajectories, are selected as research and test objects. The method based on the\namplitude state of surface electromyography (sEMG) signal and acceleration signal is used\nfor vocabulary segmentation. The multi-sensor decision fusion method of coupled hidden\nMarkov model is used to complete the recognition of SL vocabulary, and the average recog-\nnition rate is 90.41%. Experiments show that the method of sEMG signal and motion infor-\nmation fusion has good practicability in SLR."
        },
        {
            "heading": "Introduction",
            "text": "Sign language (SL) is the main way for deaf/mute individuals to communicate, which enables them to improve their social participation. Sign language recognition (SLR) uses computers to convert the information expressed by SL actions into specific target application information, which has become one of the research hotspots in the field of rehabilitation medicine [1, 2].\nTraditional SLR technologies based on images and data gloves do not easily meet the\nrequirements of wearability and low cost [3, 4], and the recognition method based on the combination of surface electromyography (sEMG) and motion information is gradually favored [5\u20137]. Approximately 5600 types of Chinese sign language (CSL) vocabulary exist. At present, most research results only aim at the preset test words and lack the universality of the entire vocabulary. Therefore, it is essential to put forward systematic solutions for all CSL vocabulary recognition.\nBased on the structural characteristics of CSL, many scholars decompose it into pure struc-\ntural elements for analysis and research, such as hand shape, orientation, posture, and position. Yang et al. [8] used the hand shape, orientation, position and other elements of gesture action to classify the vocabulary step by step. Although this method has high recognition rate and\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 1 / 15\na1111111111 a1111111111\nOPEN ACCESS\nCitation: Li W, Luo Z, Li W, Xi X (2023) Chinese sign language recognition based on surface electromyography and motion information. PLoS ONE 18(12): e0295398. https://doi.org/10.1371/ journal.pone.0295398\nEditor: Andrea Tigrini, Polytechnic University of Marche: Universita Politecnica delle Marche, ITALY\nReceived: July 14, 2023\nAccepted: November 21, 2023\nPublished: December 7, 2023\nPeer Review History: PLOS recognizes the benefits of transparency in the peer review process; therefore, we enable the publication of all of the content of peer review and author responses alongside final, published articles. The editorial history of this article is available here: https://doi.org/10.1371/journal.pone.0295398\nCopyright: \u00a9 2023 Li et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\nData Availability Statement: All relevant data are within the paper and its Supporting Information files.\nFunding: This work was supported by the National Natural Science Foundation of China, the award\naccuracy, it has the disadvantages of a small number of recognized words and lack of systematization. Due to the large number of gesture movements in CSL, Tigrini et al. [9] have shown that placing the collection device on the forearm or wrist is helpful in recognizing complex gesture movements. As the CSL action process has the complex characteristics of spatio-temporal information change, many scholars use multi-sensor information fusion technology to improve the accuracy of SLR. Yang et al. [10] fused image, sEMG and acceleration (ACC) sensor information to achieve high recognition rate, but the system design is extremely complex. Tian et al. [11] used the data fusion of sEMG and ACC sensors and introduced statistical language model to recognize SL, with a recognition rate of 90%. However, these studies directly input ACC eigenvalues and sEMG into the classifier, and only take ACC as the auxiliary feature of gesture state, without considering the internal correlation and dependence between gesture and movement trajectory, nor considering the spatiotemporal attributes of gesture and trajectory in the formation process of CSL. This fusion method has great limitations in the vocabulary expansion of SLR. At present, there are thousands of words are included in CSL. Identifying them one by one will not only produce a great burden of training and calculation but also complicate the recognition system.\nCoupled hidden Markov model (cHMM) is a multi-stream Markov chain that describes the interaction of multiple random processes. It is highly suitable for the interactive fusion of multiple independent information streams [12]. CSL is a strong spatio-temporal action correlation process regarding gestures and trajectories. The strong timing coupling analysis ability of cHMM can effectively analyze the internal characteristics of gestures and trajectories before and after CSL. cHMM also has the advantage of analyzing the correlation and asynchronous characteristics of various source data streams [13]. When analyzing and processing the dual information flow of gesture based on sEMG and trajectory based on motion information, cHMM can not only ensure the independence of the implementation of the dual information flow algorithm, but also considers the correlation characteristics of gesture and movement trajectory at a certain SL action time. It is very suitable for the fusion of gesture and movement trajectory in SLR. On the basis of summarizing and analyzing the internal characteristics of CSL formation, this study aims to organically decompose CSL into standardized gestures and gesture-related movement trajectories, fully analyze the mode features and motion features of sEMG and motion information, output the gesture and movement trajectories related to CSL, and then integrate the two with cHMM. A systematic SLR method with more universal applicability and a richer vocabulary is proposed.\nThis study proposes a general method to decompose Chinese sign language into 37 standard-\nized gestures and 18 action trajectories, and uses the sEMG, ACC and AV signals of motion information to comprehensively study the recognition of sign language words. Successfully applied to 120 common vocabulary words. This study provides a relevant foundation for the development of high real-time, high reliability and wearable sign language recognition devices."
        },
        {
            "heading": "Materials and methods",
            "text": ""
        },
        {
            "heading": "Participants",
            "text": "We enrolled 8 participants (7 men and 1 women, age: 22.1 \u00b1 1.1 years (22\u201325 years)). All participants provided written informed consent, and the experimental procedures were approved by the local ethics committee of Hangzhou Dianzi University."
        },
        {
            "heading": "Experimental preparation",
            "text": "A total of 8 healthy volunteers (7 males and 1 female) aged 20\u201330 were recruited (All subjects were informed of the specific experimental procedures and potential risks, and signed\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 2 / 15\nnumber is 62171171. This work was supported by the Natural Science Foundation of Zhejiang Province, the award number is LZ23F030005.\nCompeting interests: The authors have declared that no competing interests exist.\ninformed consent forms). As shown in (Fig 1), each volunteer sat on a chair and performed 120 CSL vocabulary actions respectively. The experimental acquisition system in (Fig 2) was used to record the corresponding sEMG, ACC, and AV signals. Based on these signals, 960 groups of data were collected, of which 480 groups were training samples and the other 480 groups were test samples. In the experiment, each state corresponded to a CSL vocabulary, and the likelihood probability value of the corresponding state output of each model was calculated. The composite state with the largest probability value was the target vocabulary.\nThe number of channels for sEMG signal acquisition and analysis influences the recogni-\ntion performance, complexity and calculation of the recognition system. In general, the number of channels should be reduced as much as possible on the premise of good recognition rate, to reduce the system complexity and calculation. Therefore, according to the correlation between gestures and muscle groups, this study selects four muscle groups as signal acquisition objects: extensor carpi radialis (ECR), extensor digitorum (ED), flexor digitorum superficialis (FDS) and extensor pollicis brevis (EPB). The layout position of the four channel sEMG sensor is shown in (Fig 3).\nTrigno wireless sEMG acquisition is used to build an experimental acquisition system\nbased on sEMG and motion information. Each trigno sensor has built-in three-axis accelerometer, three-axis gyroscope and sEMG acquisition module, that can collect ACC, angular velocity (AV) signals and sEMG signals of the corresponding muscle groups in real time. The sampling frequency of the sensor is 1000Hz. The duration of a SL action is approximately 2s. During the experiment, the sensor recording sEMG signal was pasted on the surface of the corresponding muscle group of the forearm of the experimental object. The sensor recording ACC and AV signals is pasted near the wrist joint to facilitate more accurate detection of the spatial position and movement of the hand, as shown in (Fig 2).\nChinese sign language (CSL) decomposition\nCSL is developed on the basis of finger letter gesture [14], which is the research basis of CSL gesture. At present, CSL has evolved into a complex dynamic mode accompanied by limb\nhttps://doi.org/10.1371/journal.pone.0295398.g001\nhttps://doi.org/10.1371/journal.pone.0295398.g002\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 3 / 15\nmovement in the formation and change of various gestures. Therefore, the main research contents of CSL include various gestures and gesture-related movement trajectories. Therefore, this study proposes to decompose CSL into several standardized gestures and movement trajectories, organically divide a large number of CSL vocabulary recognition into gesture recognition and gesture-related movement trajectory recognition, and systematically propose an SLR scheme. Their recognition depends on sEMG and motion information of CSL action respectively. As sEMG and motion information signals have certain motion predictability [15], they are suitable for the recognition of various changing gestures and the tracking of movement trajectory. The organic combination of sEMG and motion information is also conducive to the study of the internal correlation and logic of CSL gesture and movement trajectory.\nIn Chinese, 30 finger letter gestures are used (Fig 4) [14, 16], of which three letter gestures\nare the same, with only differences in direction. The actual gestures are 27. In addition, 10 kinds of gestures (Fig 5) have been added to \u201cChinese Sign Language (Revised Edition)\u201d [14]. Therefore, a total of 37 kinds of standardized CSL gestures are examined in this study. After repeated research and induction of all CSL movement trajectories, 18 kinds of regular trajectories are obtained, as shown in (Fig 6). Then, there are 19 kinds of movement states in addition to the state of action rest. According to the types of gestures, CSL is mainly divided into single hand gesture vocabulary (SHGV), double hand gesture vocabulary (DHGV) and dynamic gesture vocabulary (DGV). SHGV refers to the vocabulary expressed only by the action of the main hand (usually the right hand). DHGV refers to the vocabulary expressed by the main and auxiliary hands, and the gesture actions of these hands are the same and different. In DGV, the gesture actions in a vocabulary expression cycle are not fixed but changeable. Therefore, through the organic combination of 37 gestures and 18 movement trajectories, the number of words that can be recognized in theory is 52022, which can cover all CSL vocabulary.\nhttps://doi.org/10.1371/journal.pone.0295398.g003\nhttps://doi.org/10.1371/journal.pone.0295398.g004\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 4 / 15\nAs the joint activities of more than 20 degrees of freedom of the hand are driven by specific\nmuscle groups [17, 18], and the muscles are interrelated and coordinated, all gestures can be recognized by appropriately increasing the number and position layout of sEMG sensors. Then, 18 movement trajectories can also be detected by various motion sensors. The CSL decomposition and recognition method based on standardized gesture and movement trajectory is shown in (Fig 7). First, CSL is decomposed into standardized gestures and movement trajectories. Then, gesture recognition and movement trajectory classification based on gesture formation process are carried out respectively. Finally, the recognized CSL target vocabulary is output through cHMM fusion algorithm.\nThe CSL vocabulary is extensive. The scheme shown in (Fig 6) is a systematic SLR solution that can systematically summarize the recognition of all CSL vocabulary words into the recognition of 37 gestures and 18 movement trajectories. However, as the CSL vocabulary involves many uncommon words, it is neither lengthy nor complicated, nor does it necessitate identification and analysis of all words. To facilitate the analysis, this study selects 120 words involving nine gestures and eight trajectories as an example to examine the problem of SLR based on gesture and movement trajectory decomposition. Specifically, the 120 target words are presented in Table 1."
        },
        {
            "heading": "Gesture recognition",
            "text": "By collecting the sEMG signals of specific muscle groups and analyzing the pattern information, nine corresponding gesture can be recognized from the sEMG signals of four muscle groups. The specific steps can be found in [19]. The definitions of the nine gestures and the corresponding CSL vocabulary are shown in (Fig 8). These nine gestures are repeated more frequently in the CSL vocabulary, which is more convenient to intuitively explain the combination form of gestures and gesture-related movement trajectories."
        },
        {
            "heading": "Movement trajectory recognition",
            "text": "ACC and AV signals capture the movement trajectory information executed by SL, build the trajectory completely through the algorithm, and use the trajectory classification method to distinguish the eight movement trajectories. The specific steps can be found in [20]. (Fig 9)\nhttps://doi.org/10.1371/journal.pone.0295398.g005\nhttps://doi.org/10.1371/journal.pone.0295398.g006\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 5 / 15\nlists the definitions and corresponding CSL vocabulary of the eight movement trajectories in detail.\nVocabulary segmentation based on sEMG and ACC dual-signal amplitude\nA complete SL vocabulary often involves several consecutive different gesture actions, which makes the gesture segmentation algorithm based entirely on sEMG signal amplitude unsuitable for the vocabulary segmentation. In [21], the amplitude change of the sEMG signal used as the judgment basis for the start and end points of gesture action. An sEMG signal can represent the level of muscle activity. When the gesture is switched from one action to another, the corresponding muscle will relax temporarily. Therefore, the amplitude change information of the sEMG signal can be used for data segmentation of SHGV and DHGV. However, for DGV with multiple gesture combinations, judging only the sEMG signal amplitude, such as the CSL vocabulary word \"clear\" is not enough. (Fig 10) shows the sEMG and ACC signal activity diagram in a vocabulary cycle. In the VCM(Vertical circular arc movement) trajectory, the process of changing from FFE(Five fingers extended) to ET(Extended thumb) gesture occurs. During the gesture-switching process, the muscles relax briefly. If only the change of sEMG amplitude is used as the basis for vocabulary segmentation, the word \"clear\" is easy to divide into two other independent words, resulting in false recognition. In fact, the dynamic gesture process is also accompanied by the violent fluctuation of the ACC signal. According to this information, combining the amplitude changes of sEMG and ACC signals can enable more effective judgment of the start and end points of CSL activities.\nhttps://doi.org/10.1371/journal.pone.0295398.g007"
        },
        {
            "heading": "Category CSL Vocabulary",
            "text": "https://doi.org/10.1371/journal.pone.0295398.t001\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 6 / 15\nIn this study, the absolute mean sliding window (AMSW) method is used to detect the start and end points of CSL activity for the synchronization of sEMG and ACC signals. The specific steps are as follows:\n\u2022 The time series of the sEMG signal with channel k length N is expressed as xk(i), i = 1,2,. . ., N. The absolute mean value of the signal sample is:\nMAVk \u00bc\nXN\ni\u00bc1 jxk\u00f0i\u00dej N\n\u00f01\u00de\nhttps://doi.org/10.1371/journal.pone.0295398.g008\nhttps://doi.org/10.1371/journal.pone.0295398.g009\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 7 / 15\n\u2022 The time series of the ACC signal with channel l length M is expressed as yl(j),j = 1,2,. . .,M. The absolute mean value of the signal sample is:\nMAVl \u00bc\nXM\nj\u00bc1 jyl\u00f0j\u00dej\nM \u00f02\u00de\n\u2022 The length of the moving window is K and the step is T. When K/3\ufffdT\ufffdK/2,better experimental results and computational efficiency are obtained. In the experiment, The moving\nwindow K = 50 and the step T = 25.\n\u2022 The activity thresholds of time series sEMG and ACC signals are set to TsEMG and TACC. When MAVk>TsEMG or MAVl>TACC, the amplitude state is set to 1, and the signal is in the active section of the gesture action. The values of activity thresholds TsEMG and TACC are obtained by combining the signal activity start and stop situations of 8 experimental volun-\nteers during sign language action training.\nThe CSL activity detection steps in (Fig 10) are shown in (Fig 11).\nhttps://doi.org/10.1371/journal.pone.0295398.g010\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 8 / 15\nDecision fusion of gesture and movement trajectory based on cHMM\ncHMM can be regarded as a multi-chain HMM structure, and coupling conditional probability is introduced between the state sequences of each HMM [22], as shown in (Fig 12). The model consists of two HMM chains named HMMa and HMMb, which contains a hidden state sequence and an observed value sequence respectively. The number of hidden states can be set according to the actual application. The Figure shows that a certain state of each HMM chain at any time only depends on two different channel states at the previous time. This singlechannel asynchronous cHMM structure retains Markov characteristics, and SLR processes the combined information of gesture and movement trajectory. The gesture and movement trajectory data are independent two channel information streams, and their modal information is also a time-dependent sequence with Markov characteristics. Therefore, the integration of SL gesture and movement trajectory using cHHM is in accordance with its internal law.\nThe parameters of a cHMM with two chains are described as follows [12]:\n\u2022 Q: State sequence of the model. The two chains are gesture and movement trajectory\nsequence. Therefore, the state of the model at any time is the state combination of the two chains, which is CSL vocabulary. Note that the number of states of the c-th chain is Nc, and the number of states of the model is Y2\nc\u00bc1 Nc, that is, the number of CSL words. Further-\nmore, the Nc of the c-th chain is Sc1; S c 2 ; \ufffd \ufffd \ufffd ; ScN , the state of the c-th chain at time t is q c t , and the state of the model at time t is qt \u00bc fq 1 t ; q 2 t g. Then the state sequence of the model is Q \u00bc fq1; q2; \ufffd \ufffd \ufffd ; qTg \u00bc f\u00f0q11; q 2 1 \u00de; \u00f0q1 2 ; q2 2 \u00de; \ufffd \ufffd \ufffd ; \u00f0q1T; q 2 T\u00deg.\n\u2022 O: Observed value sequence of the model. Similarly, the observation sequence of the model\nalso includes the observation sequence of two chains. Note that the state of the c-th chain at time t is ot \u00bc fo 1 t ; o 2 t g. Then the state sequence of the model is O \u00bc fo1; o2; \ufffd \ufffd \ufffd ; oTg \u00bc f\u00f0o11; o 2 1 \u00de; \u00f0o1 2 ; o2 2 \u00de; \ufffd \ufffd \ufffd ; \u00f0o1T; o 2 T\u00deg.\nhttps://doi.org/10.1371/journal.pone.0295398.g012\nhttps://doi.org/10.1371/journal.pone.0295398.g011\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 9 / 15\n\u2022 \u03c0: Initial state probability vector, \u03c0 = {\u03c0i}, where \u03c0i is the prior probability of Si \u00bc fS 1 i1; S 2 i2g at\ntime t = i, that is,\npi \u00bc Y2 c\u00bc1 pcic \u00bc Y2 c\u00bc1 P\u00f0qc 1 \u00bc Scic\u00de \u00f03\u00de\n\u2022 A: State transition probability matrix, A = {ai,j},where ai,j is the probability of model transfer from Si \u00bc fS 1 i1; S 2 i2g to Sj \u00bc fS 1 j1; S 2 j2g, that is,\nai;j \u00bc Y2 c\u00bc1 aci;jc \u00bc Y2 c\u00bc1 P\u00f0qct\u00fe1 \u00bc S c jcjqt \u00bc Si\u00de \u00f04\u00de\nWhere aci;jc represents the probability that the c-th chain is in state S c jc at the current time given that the model is in state Si \u00bc fS 1 i1; S 2 i2g at the previous time.\n\u2022 B: Probability distribution of observations, B = {bj(ot)},where bj(ot) is the probability of the observed value ot \u00bc fo1t ; o 2 t g when the model is in state Sj \u00bc fS 1 j1; S 2 j2g.\nbj\u00f0ot\u00de \u00bc Y2 c\u00bc1 bcjc\u00f0o c t\u00de \u00bc Y2 c\u00bc1 P\u00f0oct jq c t \u00bc S c jc\u00de \u00f05\u00de\nSimilarly, cHMM can be abbreviated as \u03bb = (\u03c0,A,B) is adjusted to maximize the probability of generating the observed value sequence. That is, a set of model parameters \ufffdl is found so that\n\ufffdl \u00bc arg max l P\u00f0Ojl\u00de \u00f06\u00de\nThe preceding equation is a maximum likelihood estimation problem with hidden variable\nQ, and the expected maximum algorithm can be used to iteratively obtain the local optimal solution. According to [11, 12], the estimated model parameter \ufffdl \u00bc \u00f0\ufffdp; \ufffdA; \ufffdB\u00de is obtained and satisfies P\u00f0Oj\ufffdl\u00de \ufffd P\u00f0Ojl\u00de. That is, the estimation formula always increases the probability P (O|\u03bb) until the local maximum is obtained. Taking the estimated model parameter \ufffdl \u00bc \u00f0\ufffdp; \ufffdA; \ufffdB\u00de as the new initial model parameter, we repeat the iterative steps of the expected maximum algorithm until the probability P\u00f0Oj\ufffdl\u00de converges. The final model parameter is the maximum likelihood estimation of the model, that is, the obtained cHMM model. The combination state corresponding to the maximum output likelihood probability (i.e. CSL vocabulary) is the target object."
        },
        {
            "heading": "Results and discussion",
            "text": ""
        },
        {
            "heading": "CSL decomposition status table",
            "text": "In the fusion experiment of the gesture and movement trajectory information of the CSL vocabulary using the cHMM method, first, two HMM chains and implicit states of cHMM structure were defined. Nine types of gesture recognition output were defined as hidden state \u00f0q1 1 ; q1 2 ; q1 3 ; q1 4 ; q1 5 ; q1 6 ; q1 7 ; q1 8 ; q1 9 \u00de of HMMa chain. Rest state, and eight types of movement trajectory recognition output were defined as hidden state \u00f0q2 1 ; q2 2 ; q2 3 ; q2 4 ; q2 5 ; q2 6 ; q2 7 ; q2 8 ; q2 9 \u00de of the HMMb chain. The cHMM composite hidden state are combination \u00f0q1 1 ; q1 2 ; q1 3 ; q1 4 ; q1 5 ; q1 6 ; q1 7 ; q1 8 ; q1 9 \u00de and \u00f0q2 1 ; q2 2 ; q2 3 ; q2 4 ; q2 5 ; q2 6 ; q2 7 ; q2 8 ; q2 9 \u00de, up to 81 types in theory.\nA total of 120 CSL words are in the test vocabulary, including 45 words of SHGV, 52 words\nof DHGV and 23 words of DGV. Three decomposition state tables are established for the three\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 10 / 15\ntypes of vocabulary. Each vocabulary word in the table is represented as a composite state of a combination of standardized gestures and movement trajectories. After the three types of vocabulary are mapped to the state table, the recognition of the CSL vocabulary is calculated as the likelihood probability value of the cHMM state output. Due to space limitations, this study includes only the representative vocabulary in the three status tables, which are explained together (Fig 13).\nDecision fusion experiment based on cHMM\nIn the decision fusion experiment, first, the signal activity segment of a complete CSL vocabulary is intercepted by the vocabulary segmentation method. In the signal activity segment, three types of SHGV, DHGV and DGV are judged by the sEMG signal activity amplitude. The decision fusion experiment is conducted on the three types of vocabulary by using cHMM.\nIn the experiment, each state corresponds to a CSL vocabulary, and the likelihood probabil-\nity value of the corresponding state output of each model is calculated. The composite state with the largest probability value is the target vocabulary. For example, in the DGV of \"clear (\u6e05)\", (Fig 14) is the output value of the \"clear (\u6e05)\" vocabulary word using the cHMM for decision fusion. (Fig 14A) shows the output value of the gesture in the first stage of the vocabulary, and (Fig 14B) presents the output value of the gesture in the second stage of the vocabulary. In (Fig 14A), Q(1,9), Q(1,8), Q(5,9), Q(5,8), Q(1,7), Q(1,6), Q(1,1), and Q(2,9) are \u00f0q1 1 ; q2 9 \u00de, \u00f0q1 1 ; q2 8 \u00de, \u00f0q1 5 ; q2 9 \u00de, \u00f0q1 5 ; q2 8 \u00de, \u00f0q1 1 ; q2 7 \u00de, \u00f0q1 1 ; q2 6 \u00de, \u00f0q1 1 ; q2 1 \u00de, and \u00f0q1 2 ; q2 9 \u00de. By looking up the decomposition status in (Fig 14), we know that the vocabulary corresponding to the output first stage gesture are \"clear (\u6e05)\" (first-stage gesture), \"kindergarten (\u5e7c\u513f\u56ed)\" (first-stage gesture), \"hear of (\u542c\u8bf4)\" (second-stage gesture), \"kindergarten (\u5e7c\u513f\u56ed)\" (second-stage gesture), \"PE (\u4f53\u68c0)\", \"handle (\u628a)\", \"hear of (\u542c\u8bf4)\" (first-stage gesture), and \"how (\u600e\u4e48)\".\nIn (Fig 14B), Q(3,9), Q(3,3), Q(5,9), Q(4,4), Q(5,8), Q(2,6), Q(1,7), and Q(3,2) are \u00f0q1 3 ; q2 9 \u00de,\n\u00f0q1 3 ; q2 3 \u00de, \u00f0q1 5 ; q2 9 \u00de, \u00f0q1 4 ; q2 4 \u00de, \u00f0q1 5 ; q2 8 \u00de, \u00f0q1 2 ; q2 6 \u00de, \u00f0q1 1 ; q2 7 \u00de, and \u00f0q1 3 ; q2 2 \u00de. By looking up the decomposition status in (Fig 13), we know that the vocabulary corresponding to the output second stage\nhttps://doi.org/10.1371/journal.pone.0295398.g013\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 11 / 15\ngesture are \"clear (\u6e05)\" (second-stage gesture), \"healthy (\u5065\u5eb7)\", \"hear of (\u542c\u8bf4)\", \"fishing (\u9493 \u9c7c)\", \"kindergarten (\u5e7c\u513f\u56ed)\" (second-stage gesture), \"handle (\u628a)\", \"PE (\u4f53\u68c0)\", and \"smooth (\u987a\u5229)\". The state with the largest likelihood probability value of gesture decision fusion output in the first stage and the second stage is \"clear (\u6e05)\", that is, \"clear (\u6e05)\" is the recognized target vocabulary.\nhttps://doi.org/10.1371/journal.pone.0295398.g014\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 12 / 15\nsummarizes the accuracy of the three types of vocabulary, which reach 92.22%, 90.38% and 86.95% respectively. The average accuracy reaches 90.41%.\nWang et al. [23] used a three-axis ACC for the recognition of 8 custom gestures, achieving a\nrecognition rate of 98.75%. Zhuang et al. [24] used signals from four forearm muscle groups and one palm muscle group to classify 18 Chinese Sign Language vocabulary words. The average recognition rate achieved 91.4%. The main work of [23, 24] is on gesture recognition, neglecting the action trajectories during the formation and transformation of gestures. This has resulted in a limited vocabulary for recognition. In this study, we integrate Chinese sign language gestures with action trajectory information, utilizing the cHMM multi-sensor information fusion approach to achieve the recognition of complex Chinese sign language vocabulary. The experimental results show that the decision fusion method of cHMM is effective for SL vocabulary recognition."
        },
        {
            "heading": "Discussion",
            "text": "The main purpose of this article is to study gesture recognition based on the fusion of gesture information and motion trajectory information. Using the amplitude states of synchronous sEMG signal and ACC signal to determine the starting and ending points of sign language activities, continuous sign language vocabulary is segmented. Then, utilizing the independent information flow of sign language gesture and action trajectory information, as well as the inherent sequence and logical correlation, the multi-sensor information fusion method of cHMM is used to complete the recognition of sign language vocabulary. By using gesture pattern types and action trajectory types as hidden states of the cHMM chains, the output probability values of each state observation value are fused using cHMM, solving the classification problem of large vocabulary sign language recognition systems.\nThe vocabulary of Chinese sign language is enormous, with a total of over 5600 words. If vocabulary is identified individually or decomposed according to structural elements, it will incur a huge training burden and make the recognition system complex. Kshitij et al [1] and Heickal et al. [25] used computer vision to recognize and analyze sign language, achieving a recognition rate of 91% for 150 American sign language vocabulary. Zhou et al. [26] designed a data acquisition and recognition system for wearing on fingers using three-axis ACC, achieving an average recognition rate of 80% in 16 gesture movements. Asif et al. [2] analyzed sign language recognition based on sEMG signals and ultimately achieved a recognition rate of 95% for 11 gestures. However, the above methods only have good recognition rates for single sign language actions, and often do not have high recognition rates for continuous sign language actions. Considering the inherent order and logicality of gesture and action trajectory information in continuous sign language, this study uses the method of sEMG signal and ACC signal amplitude state to perform vocabulary segmentation, fuses sign language gesture and action trajectory to output target vocabulary, which provides convenience for continuous sign language recognition and has a positive effect on improving recognition accuracy. This study\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 13 / 15\ncollected sEMG and ACC data of 120 Chinese sign language vocabulary from 8 volunteers. After cHMM decision fusion, the recognition rate of SHGV and DHGV vocabulary is as high as 92.22% and 90.38%, and the recognition rate of DGV vocabulary is 86.95%. This article provides a relevant foundation for the development of Chinese sign language recognition devices with high real-time, high reliability, and wearability.\nHowever this study also has many limitations in experiments and methods. At present, the method proposed in this study has only been tested on healthy individuals. In future work, we will cooperate with rehabilitation institutions for further experiments and research, and test this method on a group of deaf/mute patients receiving rehabilitation treatment. In addition, the target object of this article\u2019s research method is all Chinese sign language vocabulary. Currently, only 120 commonly used vocabulary libraries have been established and tested. Therefore, the expansion of the testing vocabulary library and the corresponding gesture and action trajectory decomposition table for the expanded vocabulary are also key challenges that need to be solved in the next step of research. The recognition rate of SHGV vocabulary is as high as 92.22%"
        },
        {
            "heading": "Conclusions",
            "text": "SLR is an important research direction in human-computer interaction. This study deeply discusses the SLR method based on sEMG and motion information fusion, and makes a beneficial attempt on the comprehensive and systematic recognition of CSL. First, according to the internal characteristics of CSL, it is divided into 37 standardized gestures and 18 movement trajectories, and all CSL vocabulary words are classified. Then, 120 commonly used target words, involving 9 gestures and 8 movement trajectories, are listed as research and test objects. Based on the acquisition system of sEMG and motion information as well as the vocabulary segmentation method of sEMG and ACC dual-signal amplitude state, the multi-sensor information decision fusion of cHMM is used to complete the recognition of CSL vocabulary. The average accuracy is 90.41%."
        },
        {
            "heading": "Supporting information",
            "text": "S1 File. Dataset. In the file, it is reported the dataset of the experiment for each participant. (XLSX)"
        },
        {
            "heading": "Author Contributions",
            "text": "Conceptualization: Zhizeng Luo, Wenguo Li.\nData curation: Wenyu Li.\nFunding acquisition: Wenyu Li.\nInvestigation: Wenyu Li.\nMethodology: Zhizeng Luo, Wenguo Li, Xugang Xi.\nVisualization: Wenyu Li.\nWriting \u2013 original draft: Wenyu Li, Wenguo Li.\nWriting \u2013 review & editing: Zhizeng Luo, Xugang Xi.\nPLOS ONE | https://doi.org/10.1371/journal.pone.0295398 December 7, 2023 14 / 15"
        }
    ],
    "title": "Chinese sign language recognition based on surface electromyography and motion information",
    "year": 2023
}