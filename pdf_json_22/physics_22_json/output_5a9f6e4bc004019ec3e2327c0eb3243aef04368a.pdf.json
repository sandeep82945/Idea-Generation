{
    "abstractText": "Learning the solution of partial differential equations (PDEs) with a neural network is an attractive alternative to traditional solvers due to its elegance, greater flexibility and the ease of incorporating observed data. However, training such physics-informed neural networks (PINNs) is notoriously difficult in practice since PINNs often converge to wrong solutions. In this paper, we address this problem by training an ensemble of PINNs. Our approach is motivated by the observation that individual PINN models find similar solutions in the vicinity of points with targets (e.g., observed data or initial conditions) while their solutions may substantially differ farther away from such points. Therefore, we propose to use the ensemble agreement as the criterion for gradual expansion of the solution interval, that is including new points for computing the loss derived from differential equations. Due to the flexibility of the domain expansion, our algorithm can easily incorporate measurements in arbitrary locations. In contrast to the existing PINN algorithms with time-adaptive strategies, the proposed algorithm does not need a pre-defined schedule of interval expansion and it treats time and space equally. We experimentally show that the proposed algorithm can stabilize PINN training and yield performance competitive to the recent variants of PINNs trained with time adaptation.",
    "authors": [
        {
            "affiliations": [],
            "name": "Katsiaryna Haitsiukevich"
        }
    ],
    "id": "SP:7619d69bfd20814f95e79b26ca655c1049103e04",
    "references": [
        {
            "authors": [
                "P. Bachman",
                "O. Alsharif",
                "D. Precup"
            ],
            "title": "Learning with pseudo-ensembles",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2014
        },
        {
            "authors": [
                "D. Berthelot",
                "N. Carlini",
                "I. Goodfellow",
                "N. Papernot",
                "A. Oliver",
                "C.A. Raffel"
            ],
            "title": "Mixmatch: A holistic approach to semi-supervised learning",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "J. Brandstetter",
                "D.E. Worrall",
                "M. Welling"
            ],
            "title": "Message passing neural PDE solvers",
            "venue": "International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "R.T.Q. Chen",
                "Y. Rubanova",
                "J. Bettencourt",
                "D.K. Duvenaud"
            ],
            "title": "Neural ordinary differential equations",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2018
        },
        {
            "authors": [
                "R. Courant",
                "D. Hilbert"
            ],
            "title": "Methods of mathematical physics: partial differential equations",
            "year": 1989
        },
        {
            "authors": [
                "A. Daw",
                "J. Bu",
                "S. Wang",
                "P. Perdikaris",
                "A. Karpatne"
            ],
            "title": "Rethinking the importance of sampling in physics-informed neural networks",
            "venue": "arXiv preprint arXiv:2207.02338,",
            "year": 2022
        },
        {
            "authors": [
                "S. Dong",
                "N. Ni"
            ],
            "title": "A method for representing periodic functions and enforcing exactly periodic boundary conditions with deep neural networks",
            "venue": "Journal of Computational Physics,",
            "year": 2021
        },
        {
            "authors": [
                "L.C. Evans"
            ],
            "title": "Partial Differential Equations, volume 19 of Graduate studies in mathematics",
            "venue": "American Mathematical Society,",
            "year": 1998
        },
        {
            "authors": [
                "O. Hennigh",
                "S. Narasimhan",
                "M.A. Nabian",
                "A. Subramaniam",
                "K. Tangsali",
                "Z. Fang",
                "M. Rietmann",
                "W. Byeon",
                "S. Choudhry"
            ],
            "title": "NVIDIA SimNet: An AI-accelerated multi-physics simulation framework",
            "venue": "In International Conference on Computational Science,",
            "year": 2021
        },
        {
            "authors": [
                "G.E. Hinton",
                "N. Srivastava",
                "A. Krizhevsky",
                "I. Sutskever",
                "R.R. Salakhutdinov"
            ],
            "title": "Improving neural networks by preventing co-adaptation of feature detectors",
            "venue": "arXiv preprint arXiv:1207.0580,",
            "year": 2012
        },
        {
            "authors": [
                "V. Iakovlev",
                "M. Heinonen",
                "H. L\u00e4hdesm\u00e4ki"
            ],
            "title": "Learning continuous-time PDEs from sparse data with graph neural networks",
            "venue": "International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "N. Jean",
                "S.M. Xie",
                "S. Ermon"
            ],
            "title": "Semi-supervised deep kernel learning: Regression with unlabeled data by minimizing predictive variance",
            "venue": "Neural Information Processing Systems,",
            "year": 2018
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv preprint arXiv:1412.6980,",
            "year": 2014
        },
        {
            "authors": [
                "A.S. Krishnapriyan",
                "A. Gholami",
                "S. Zhe",
                "R. Kirby",
                "M.W. Mahoney"
            ],
            "title": "Characterizing possible failure modes in physics-informed neural networks",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "I.E. Lagaris",
                "A. Likas",
                "D.I. Fotiadis"
            ],
            "title": "Artificial neural networks for solving ordinary and partial differential equations",
            "venue": "IEEE transactions on neural networks,",
            "year": 1998
        },
        {
            "authors": [
                "S. Laine",
                "T. Aila"
            ],
            "title": "Temporal ensembling for semi-supervised learning",
            "venue": "International Conference on Learning Representations,",
            "year": 2017
        },
        {
            "authors": [
                "D.-H. Lee"
            ],
            "title": "Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks",
            "venue": "In Workshop on challenges in representation learning, ICML,",
            "year": 2013
        },
        {
            "authors": [
                "Y.-F. Li",
                "H.-W. Zha",
                "Z.-H. Zhou"
            ],
            "title": "Learning safe prediction for semi-supervised regression",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2017
        },
        {
            "authors": [
                "D. Liu",
                "Y. Wang"
            ],
            "title": "A dual-dimer method for training physics-constrained neural networks with minimax architecture",
            "venue": "Neural Networks,",
            "year": 2021
        },
        {
            "authors": [
                "D.C. Liu",
                "J. Nocedal"
            ],
            "title": "On the limited memory BFGS method for large scale optimization",
            "venue": "Mathematical programming,",
            "year": 1989
        },
        {
            "authors": [
                "L. Lu",
                "X. Meng",
                "Z. Mao",
                "G.E. Karniadakis"
            ],
            "title": "DeepXDE: A deep learning library for solving differential equations",
            "venue": "SIAM Review,",
            "year": 2021
        },
        {
            "authors": [
                "L. Lu",
                "R. Pestourie",
                "W. Yao",
                "Z. Wang",
                "F. Verdugo",
                "S.G. Johnson"
            ],
            "title": "Physics-informed neural networks with hard constraints for inverse design",
            "venue": "SIAM Journal on Scientific Computing,",
            "year": 2021
        },
        {
            "authors": [
                "S. Markidis"
            ],
            "title": "The old and the new: Can physics-informed deep-learning replace traditional linear solvers",
            "venue": "Frontiers in big Data,",
            "year": 2021
        },
        {
            "authors": [
                "R. Mattey",
                "S. Ghosh"
            ],
            "title": "A novel sequential method to train physics informed neural networks for Allen-Cahn and Cahn-Hilliard equations",
            "venue": "Computer Methods in Applied Mechanics and Engineering,",
            "year": 2022
        },
        {
            "authors": [
                "L. McClenny",
                "U. Braga-Neto"
            ],
            "title": "Self-adaptive physics-informed neural networks using a soft attention mechanism",
            "venue": "arXiv preprint arXiv:2009.04544,",
            "year": 2020
        },
        {
            "authors": [
                "M. Raissi",
                "P. Perdikaris",
                "G.E. Karniadakis"
            ],
            "title": "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations",
            "venue": "Journal of Computational Physics,",
            "year": 2019
        },
        {
            "authors": [
                "F.M. Rohrhofer",
                "S. Posch",
                "C. G\u00f6\u00dfnitzer",
                "B.C. Geiger"
            ],
            "title": "Understanding the difficulty of training physics-informed neural networks on dynamical systems",
            "venue": "arXiv preprint arXiv:2203.13648,",
            "year": 2022
        },
        {
            "authors": [
                "Y. Rubanova",
                "R.T. Chen",
                "D.K. Duvenaud"
            ],
            "title": "Latent ordinary differential equations for irregularly-sampled time series",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "A. Sanchez-Gonzalez",
                "J. Godwin",
                "T. Pfaff",
                "R. Ying",
                "J. Leskovec",
                "P. Battaglia"
            ],
            "title": "Learning to simulate complex physics with graph networks",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "V. Sitzmann",
                "J. Martel",
                "A. Bergman",
                "D. Lindell",
                "G. Wetzstein"
            ],
            "title": "Implicit neural representations with periodic activation functions",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "K. Sohn",
                "D. Berthelot",
                "N. Carlini",
                "Z. Zhang",
                "H. Zhang",
                "C.A. Raffel",
                "E.D. Cubuk",
                "A. Kurakin",
                "C.-L. Li"
            ],
            "title": "Fixmatch: Simplifying semi-supervised learning with consistency and confidence",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "N. Sukumar",
                "A. Srivastava"
            ],
            "title": "Exact imposition of boundary conditions with distance functions in physics-informed deep neural networks",
            "venue": "Computer Methods in Applied Mechanics and Engineering,",
            "year": 2022
        },
        {
            "authors": [
                "M. Tancik",
                "P. Srinivasan",
                "B. Mildenhall",
                "S. Fridovich-Keil",
                "N. Raghavan",
                "U. Singhal",
                "R. Ramamoorthi",
                "J. Barron",
                "R. Ng"
            ],
            "title": "Fourier features let networks learn high frequency functions in low dimensional domains",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "S. Wang",
                "Y. Teng",
                "P. Perdikaris"
            ],
            "title": "Understanding and mitigating gradient flow pathologies in physics-informed neural networks",
            "venue": "SIAM Journal on Scientific Computing,",
            "year": 2021
        },
        {
            "authors": [
                "S. Wang",
                "H. Wang",
                "P. Perdikaris"
            ],
            "title": "On the eigenvector bias of fourier feature networks: From regression to solving multi-scale PDEs with physics-informed neural networks",
            "venue": "Computer Methods in Applied Mechanics and Engineering,",
            "year": 2021
        },
        {
            "authors": [
                "S. Wang",
                "X. Yu",
                "P. Perdikaris"
            ],
            "title": "When and why PINNs fail to train: A neural tangent kernel perspective",
            "venue": "Journal of Computational Physics,",
            "year": 2021
        },
        {
            "authors": [
                "S. Wang",
                "S. Sankaran",
                "P. Perdikaris"
            ],
            "title": "Respecting causality is all you need for training physics-informed neural networks",
            "venue": "arXiv preprint arXiv:2203.07404,",
            "year": 2022
        },
        {
            "authors": [
                "C.L. Wight",
                "J. Zhao"
            ],
            "title": "Solving Allen-Cahn and Cahn-Hilliard equations using the adaptive physics informed neural networks",
            "venue": "arXiv preprint arXiv:2007.04542,",
            "year": 2020
        },
        {
            "authors": [
                "J.C. Wong",
                "C. Ooi",
                "A. Gupta",
                "Y.-S. Ong"
            ],
            "title": "Learning in sinusoidal spaces with physics-informed neural networks",
            "venue": "IEEE Transactions on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "C. Wu",
                "M. Zhu",
                "Q. Tan",
                "Y. Kartha",
                "L. Lu"
            ],
            "title": "A comprehensive study of non-adaptive and residual-based adaptive sampling for physics-informed neural networks",
            "venue": "arXiv preprint arXiv:2207.10289,",
            "year": 2022
        },
        {
            "authors": [
                "K. Zubov",
                "Z. McCarthy",
                "Y. Ma",
                "F. Calisto",
                "V. Pagliarino",
                "S. Azeglio",
                "L. Bottero",
                "E. Luj\u00e1n",
                "V. Sulzer",
                "A. Bharambe"
            ],
            "title": "NeuralPDE: Automating physics-informed neural networks (PINNs) with error approximations",
            "venue": "arXiv preprint arXiv:2107.09443,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Keywords Label propagation \u00b7Model ensembles \u00b7 Partial differential equations \u00b7 Physics-informed neural networks"
        },
        {
            "heading": "1 Introduction",
            "text": "Partial differential equations (PDEs) are a powerful tool for modeling many real-world phenomena (Evans, 1998; Courant and Hilbert, 1989). When derived from the first principles, partial differential equations can serve as predictive models which do not require any data for tuning. When learned from data, they often outperform other models by incorporating the inductive bias of the continuity of the modeled domain (time or space) (Chen et al., 2018; Rubanova et al., 2019; Iakovlev et al., 2021). Inference in this type of models is done by solving partial differential equations, that is by finding a trajectory that satisfies the model equations and a set of initial and boundary conditions. Since analytic solutions exist only for a limited number of models (most likely derived from the first principles), inference is typically done by numerical solvers of differential equations.\nOne way of solving differential equations is to approximate the solution by a neural network which is trained to satisfy a given set of differential equations, initial and boundary conditions. This approach is known in the literature under the name of physics-informed neural networks (PINNs, Lagaris et al., 1998; Raissi et al., 2019) and it can be seen as a machine learning alternative to classical numerical solvers. Despite the conceptual simplicity and elegance of the method, training PINNs is notoriously difficult in practice (Wang et al., 2021a; Krishnapriyan et al., 2021). It requires balancing of multiple terms in the loss function (Wang et al., 2021a;c) and the commonly used neural network architectures and parameter initialization schemes may not work best for PINNs (Wang et al., 2021b; Sitzmann et al., 2020).\nar X\niv :2\n20 4.\n05 10\n8v 3\n[ cs\n.L G\n] 1\n1 Ja\nIt has been noted by many practitioners that training PINNs often results in convergence to bad solutions (see, e.g., Krishnapriyan et al., 2021; Sitzmann et al., 2020; Wang et al., 2022). Several recent works (Wight and Zhao, 2020; Krishnapriyan et al., 2021; Mattey and Ghosh, 2022) address this problem by splitting the time interval into sub-intervals and sequentially training PINNs on each sub-interval. This idea is often referred in the literature as time adaptation or time marching. The time-adaptive strategies make the training procedure of PINNs similar to classical numerical solvers which compute the solution gradually moving from the initial conditions towards the other end of the time interval. Similarly to classical solvers, many existing PINN algorithms are based on a pre-defined schedule of time adaptation.\nIn this work, we follow the idea of the gradual expansion of the solution interval when training PINNs. We propose to train an ensemble of PINNs and use the ensemble agreement (confidence) as the criterion for expanding the solution interval to new areas. Due to the flexibility of the domain expansion, in contrast to existing baselines, our algorithm can easily incorporate measurements in arbitrary locations: the algorithm will propagate the solution from all the locations where supervision targets are known (see Fig. 1 as an example). The proposed algorithm does not need a pre-defined schedule of interval expansion and it treats time and space equally. We experimentally show that the proposed algo-\nrithm can stabilize PINN training (see Fig. 2) and yield performance competitive to the recent variants of PINNs which use time adaptation."
        },
        {
            "heading": "2 Background",
            "text": ""
        },
        {
            "heading": "2.1 Physics-informed neural networks",
            "text": "Physics-informed neural networks are neural networks which are trained to approximate the solution of a partial differential equation\n\u2202u(x, t)\n\u2202t = f\n( \u22022u(x, t)\n\u2202x2 , \u2202u(x, t) \u2202x , x, t\n) (1)\non the interval x \u2208 [X1, X2], t \u2208 [T1, T2] with initial conditions u(x, T1) = u0(x), x \u2208 [X1, X2] (2)\nand boundary conditions g(u(x, t)) = 0, x \u2208 {X1, X2} . (3)\nFunctions f and u0 in Eqs. 1\u20132 are assumed to be known, function g in Eq. 3 is known as well and it can represent different types of boundary conditions (e.g., Neumann, Dirichlet, Robin or periodic boundary conditions). In the PINN\napproach, one approximates the solution with a neural network which takes inputs x and t and produces u(x, t) as the output. The network is trained by minimizing a sum of several terms:\nL = LS + LB + LPDE. (4) LS is the standard supervised learning loss which makes the neural network fit the initial conditions:\nLS = KS\u2211 i=1 wi (u(xi, ti)\u2212 ui)2 . (5)\nwhere wi are point-specific weights, ti = T1, ui = u0(xi) and xi are sampled from [X1, X2]. LB is the loss computed to satisfy the boundary conditions:\nLB = KB\u2211 j=1 wj ||g(u(xj , tj))||2 , (6)\nwhere wj are point-specific weights, xj \u2208 {X1, X2} and tj are sampled from [T1, T2]. LPDE is the loss derived from the PDE in 1:\nLPDE = KPDE\u2211 k=1 wk ( \u2202uk \u2202t \u2212 f ( \u22022uk \u2202x2 , \u2202uk \u2202x , xk, tk ))2 , (7)\nwhere wk are point-specific weights and the partial derivatives dukdt , \u22022uk \u2202x2 , \u2202uk \u2202x are computed at collocation points (xk, tk) sampled from the interval xk \u2208 [X1, X2], tk \u2208 [T1, T2]. Classical PINNs use shared weights wS = wi,\u2200i, wB = wj ,\u2200j, wPDE = wk,\u2200k. The values of the weights vary depending on the implementation and in the simplest case they are wS = 1/KS, wB = 1/KB, wPDE = 1/KPDE.\nThe method can easily be extended to fit a sequence of observations {((x\u2217i , t\u2217i ), u\u2217i )}Ni=1 by including the observed data to the supervision loss in Eq. 5. In this case, the method can be seen as fitting a neural network to the training data (containing the observations) while regularizing the solution using the PDE loss in Eq. 7. One advantage of the PINN method compared to traditional numerical solvers is the ability to work with ill-posed problems, for example, if the initial conditions are known only in a subset of points. More details on existing extensions of PINNs can be found in Appendix A.1."
        },
        {
            "heading": "2.2 PINNs with expansion of the time interval",
            "text": "Recently, several papers have proposed to solve the initial-boundary value problem by gradually expanding the interval from which points (xk, tk) in Eq. 7 are sampled. These versions of PINNs are closest to our approach.\nTime-adaptive strategies Wight and Zhao (2020) and Krishnapriyan et al. (2021) show the effectiveness of the time marching strategy: the time interval [T1, T2] is split into multiple sub-intervals and the equation is solved on each individual sub-interval sequentially by a separate PINN. The solution at the border of the previous sub-interval is used as the initial condition for the next one.\nA similar approach is based on progressive expansion of the time interval by gradually increasing the end point T2 during training (Wight and Zhao, 2020; Mattey and Ghosh, 2022). Backward compatible PINNs (bc-PINNs, Mattey and Ghosh, 2022) implement this idea such that the solution found during the previous interval extension is used as the PINN targets during training on a newly expanded interval to prevent catastrophic forgetting.\nAll these time adaptation strategies need a pre-defined schedule for the time interval expansion, which makes them similar to classical numerical solvers which use pre-defined discretization schemes.\nCausality training The idea of time adaptation is closely related to the adaptive weighting scheme that respects causality (Wang et al., 2022). The authors use adaptive weights for the individual terms in Eq. 7 such that the weights are computed using the cumulative PDE loss for the preceding points:\nwk = exp ( \u2212 \u2211\nk\u2032|tk\u2032<tk LPDE(tk\u2032)\n) , (8)\nwhere LPDE(tk\u2032) denotes an individual term in Eq. 7 that corresponds to time point tk\u2032 . The idea is to zero out the effect of the points that are far away from the initial conditions until the solution is approximated well on all the points before them. The method assumes that the boundary conditions are enforced as hard constraints and thus the total loss consists of LS and LPDE."
        },
        {
            "heading": "3 Ensembles of PINNs",
            "text": ""
        },
        {
            "heading": "3.1 Motivation",
            "text": "To motivate our approach, we demonstrate failure cases of PINNs using an example from (Krishnapriyan et al., 2021) on solving a convection equation. Fig. 3 shows the ground-truth solution of the equation (Fig. 3a) and two inaccurate solutions (Figs. 3b, c) found by PINNs trained with the same network architecture but different random seeds for weight initialization. The found PINN solutions can be seen as a combination of two solutions: the correct solution near the initial conditions (for small t) and a simpler solution farther away from the initial conditions (for large t). The second row in Fig. 3 illustrates that the second, simpler solution satisfies well the solved PDEs. This example illustrates that simple solutions can be attractive for PINNs, which can cause problems for the optimization procedure. Once a PINN finds a simple, locally consistent solution in some areas (for example, far away from the initial conditions), it may be very difficult to change it. This leads to a final solution which is a combination of the correct solution and a wrong one.\nThis example provides the following intuition: when points located far away from the initial conditions contribute to the PDE loss in Eq. 7, it may hurt the optimization procedure by pulling the solution towards a bad local optimum. On the other hand, including those points in the PDE loss at the beginning of training hardly brings any benefits: it makes little sense to regularize the solution using the loss in Eq. 7 before we know its approximate shape. The ability to escape from wrong solutions largely depends on the design choices made for the PINN training such as the optimizer type, the use of mini-batches, type of the sampling utilized for points in LPDE term in Eq. 7, normalization of the inputs, hard or soft encoding of the initial and boundary conditions and so on. While some of these tricks can be beneficial for the PINN accuracy on particular systems, it is quite difficult to select a common set of settings beneficial across a wider range of PDEs.\nThe illustrated problem is avoided by the classical numerical solvers because they usually \u201cpropagate\u201d the solution from the initial and boundary conditions to cover the entire interval using a schedule determined by the discretization scheme."
        },
        {
            "heading": "3.2 Method",
            "text": "In this paper, we propose to gradually expand the areas from which we sample collocation points (xk, tk) to compute loss LPDE. Our approach is based on training an ensemble of PINNs: a set of neural networks initialized with different weights but trained using the same loss function. Since PINN ensemble members typically converge to the same solution in the vicinity of observed data but may favor distinct wrong solutions farther away from the observations (Fig. 3b-c), we can use the ensemble agreement as the criterion for including new points for computing loss LPDE.\nOptionally, if all ensemble members agree on the solution in a particular point, we can create a pseudo-label (taken as the median of the ensemble predictions) for that point and make this point contribute to the supervision loss LS in Eq. 5.\nAlgorithm 1 Training PINNs with label propagation Hyperparameters: \u2206PDE, \u2206, \u03c32 and\n1: DL = {((xi, ti), ui)} . Points with targets (blue dots) 2: DPL = {} . Points with pseudo-labels (light blue dots) 3: IB = {(xj , tj)} . Sample candidate points for computing LB (empty red circles) 4: IPDE = {(xm, tm)} . Sample candidate points for computing LPDE (empty black circles) 5: while not converge do 6: D = DL \u222aDPL 7: I \u2032B = {(xj , tj) \u2208 IB | DISTANCE((xj , tj), D) < \u2206PDE} . red dots 8: I \u2032PDE = {(xm, tm) \u2208 IPDE | DISTANCE((xm, tm), D) < \u2206PDE} . black dots 9: Train L networks fl for N iterations using DL \u222aDPL (\u2019PL\u2019 version) or DL (\u2019Ens\u2019 version), I \u2032B, I \u2032PDE to compute LS, LB, LPDE, respectively. 10: for (xm, tm) \u2208 I \u2032PDE do 11: u\u0302l = fl(xm, tm), \u2200l \u2208 1, ..., L . Prediction of each ensemble network 12: vm = variance(u\u03021, . . . , u\u0302L) . Variance of predictions 13: u\u0304m = median(u\u03021, . . . , u\u0302L) . Median of predictions 14: if vm < \u03c32 & DISTANCE((xm, tm), D) < \u2206 then 15: DPL \u2190 DPL \u222a ((xm, tm), u\u0304m) . Add a point with a pseudo-label 16: end if 17: end for 18: end while 19: 20: function DISTANCE((x, t), D) 21: D\u2032 = {(xi, ti) \u2208 D | || 1L \u2211 l fl(xi, ti)\u2212 ui|| < } . Points with good fit to targets 22: return min(xi,ti)\u2208D\u2032 ||(xi, ti)\u2212 (x, t)|| 23: end function\nThe proposed algorithm is illustrated in Fig. 4. At the beginning of training, the supervision loss LS is computed using points sampled at the initial conditions (the blue dots in Fig. 4a) and losses LPDE and LB are computed using only points that are close enough to the initial conditions (the black and red dots in Fig. 4a respectively). The proximity is measured by thresholding the Euclidean distance to the closest point among the blue dots. After N training iterations, we compute\nthe median and the variance of the ensemble predictions (see Fig. 4b-c). If the variance in a particular location is small enough, we use the median of the ensemble predictions at that point as a pseudo-label and add that point to the data set which is used to compute the supervision loss LS (the light blue dots in Fig. 4b). Points for pseudo-labeling are selected among the collocation points (the black dots in Fig. 4a). Locations which are close enough to the data points with labels or pseudo-labels are added to the set which contributes to LPDE and LB (the black and red dots in Fig. 4b). Then, we train the ensemble of PINNs for a fixed number of iterations and again increase the sets of inputs which are used to compute the losses in a similar way (Fig. 4d-e). The iterations continue until all collocation points (which are pre-sampled at the beginning of the training procedure) are included in the loss computations.\nMore formally, the training procedure is presented in Algorithm 1. The dots and the circles in the algorithm refer to Fig. 4. In the experiments, we test two versions of the proposed algorithm:\n1. Pseudo-labels (PL): a version with pseudo-labels in which the points with a high degree of ensemble agreement are used to compute both LPDE and LS;\n2. PINN Ensemble (Ens): a version without pseudo-labels, in which the points with a high degree of ensemble agreement are used to compute LPDE but not LS.\nEach member of the ensemble is trained to minimize the loss in Eq. 4 with shared weightswB = 1/|IB|,wPDE = 1/|IPDE| and wS = 1/|D| for the PINN Ensemble version and wS = 1/|D \u222a IPDE| for the version with pseudo-labels. Other weighting strategies (e.g., Wight and Zhao, 2020; Wang et al., 2021a;c) could be combined with our approach as well."
        },
        {
            "heading": "3.3 Related work",
            "text": "PINNs and their extensions The proposed algorithm is built on the idea of the gradual expansion of the solution interval, which makes it similar to the time-adaptive techniques (Wight and Zhao, 2020; Krishnapriyan et al., 2021; Mattey and Ghosh, 2022) and the adaptive weighting method that respects causality (Wang et al., 2022). The advantage of the proposed algorithm is its greater flexibility in the way of expanding the area covered by collocation points: instead of expanding the time interval with a pre-defined (Wight and Zhao, 2020; Krishnapriyan et al., 2021; Mattey and Ghosh, 2022) or an automatic (Wang et al., 2022) schedule, our algorithm considers each collocation point individually during the expansion and it treats time and space equally. This feature allows the application of the algorithm to datasets with an arbitrary layout of the points with known targets. We illustrate this by solving the convection system (Eqs. 9\u2013 10) on the interval t \u2208 [0, 2] when the solution is known for t = 0 and t = 2. As illustrated in Fig. 1, the algorithm finds a reasonable schedule for expanding the area starting from both ends of the interval.\nLabel propagation and ensembles Training an ensemble of PINNs with pseudo-labeling is related to how label propagation is done in semi-supervised classification tasks (see, e.g, Lee et al., 2013; Sohn et al., 2020): when a classifier becomes confident in the predicted class of an unlabeled example, that example is added to the labeled set. Model ensembles (Laine and Aila, 2017) or prediction ensembles (Berthelot et al., 2019) are often used in those tasks to generate better targets. Since PINNs are trained on real-valued targets, one can view PINNs as regression models regularized by the loss in Eq. 7. Label propagation in regression tasks is less studied with only a few existing works on semi-supervised regression (Jean et al., 2018; Li et al., 2017). In our algorithm, we use the confidence of the ensemble predictions to decide whether the solution interval can be extended and which points can be assigned pseudo-labels."
        },
        {
            "heading": "4 Experiments",
            "text": "We test the proposed algorithm on finding the solutions of the following differential equations:\n\u2022 convection equation used to model transport phenomena\n\u2202u \u2202t =\u2212 \u03b2 \u2202u \u2202x , x \u2208 [0, 2\u03c0], t \u2208 [0, 1], \u03b2 = const (9)\nu(x, 0) = sin(x), u(0, t) = u(2\u03c0, t) (10)\n\u2022 reaction system for modelling chemical reactions\n\u2202u \u2202t =\u03c1u(1\u2212 u), x \u2208 [0, 2\u03c0], t \u2208 [0, 1], \u03c1 = const (11)\nu(x, 0) = exp ( \u22128(x\u2212 \u03c0)2/\u03c02 ) , u(0, t) = u(2\u03c0, t) (12)\n\u2022 reaction-diffusion equation that models reactions together with diffusion of substances\n\u2202u \u2202t =\u03bd\n\u22022u \u2202x2 + \u03c1u(1\u2212 u), x \u2208 [0, 2\u03c0], t \u2208 [0, 1], \u03bd, \u03c1 = const, (13)\nu(x, 0) = exp ( \u22128(x\u2212 \u03c0)2/\u03c02 ) , u(0, t) = u(2\u03c0, t), ux (0, t) = ux (2\u03c0, t) (14)\n\u2022 diffusion equation with periodic boundary conditions\n\u2202u \u2202t = 1 d2 \u22022u \u2202x2 , x \u2208 [0, 2\u03c0], t \u2208 [0, 1], d = const (15)\nu(x, 0) = sin(dx) u(0, t) = u(2\u03c0, t), ux (0, t) = ux (2\u03c0, t) (16)\n\u2022 diffusion equation in 15 with boundary conditions of the Dirichlet type:\nu(0, t) = u(2\u03c0, t) = 0 (17)\nIn all the experiments, we use a multi-layer perceptron with four hidden layers with 50 neurons and the tanh activation in each hidden layer as a backbone PINN. Our ensemble of PINNs contains five such networks. The two inputs x and t of the network are normalized to [\u22121, 1], which has a positive effect on the accuracy in our experiments. The models are trained either with the Adam optimizer (Kingma and Ba, 2014) with learning rate 0.001 or with Adam followed by fine-tuning with LBFGS (Liu and Nocedal, 1989). The LBFGS fine-tuning is done before each update of the collocation points which contribute to loss LPDE and at the very end of training. Illustrations of the training procedure for the considered systems can be found in Figs. 4 and 5. The plots show that the proposed algorithm finds accurate solutions for the considered systems.\nTo evaluate the accuracy of the proposed algorithm, we compute metrics used in the previous works (Krishnapriyan et al., 2021; Wang et al., 2022): we report the relative l2 error\nr = l2(u\u0302\u2212 u)/l2(u) , (18)\nwhere u is a vector of the ground-truth values in the test set, u\u0302 is the corresponding PINN predictions and l2() denotes l2 norm. Our test set consists of points on a regular 256\u00d7 100 grid. In Table 1, we compare the accuracy of the proposed method with several strong baselines proposed recently in the literature. We present the means and standard deviations of the solution errors obtained in 10 runs with different initializations. Since most of the considered methods benefit from longer training, we limit the number of network updates for all the comparison methods. We use the following comparison methods: (1) Vanilla PINN trained with the LBFGS optimizer, (2) Vanilla PINN trained with the Adam optimizer, (3) Causality (Wang et al., 2022), (4) SA-PINN (McClenny and Braga-Neto, 2020), (5) bc-PINN (Mattey and Ghosh, 2022). More details on the methods and the selection of hyperparameters can be found in Appendix A.2.\nThe results in Table 1 show that vanilla PINNs trained with LBFGS struggle to find accurate solutions for all the considered systems. Vanilla PINNs trained with Adam yield more accurate results but the results are unsatisfactory for the reaction and reaction-diffusion systems. The causality weighting scheme seems to require many more collocation\npoints to find satisfactory solutions. SA-PINN and bc-PINN work very well on the reaction and reaction-diffusion systems but do not find good solutions for the convection system. The proposed ensemble method provides stable training (see the summary of the results in Fig. 2) and shows competitive performance in all the considered systems. We can also observe that the LBFGS fine-tuning has positive effect on the accuracy when a good approximation is found during pre-training with Adam.\nIn Table 2, we compare the accuracy of the proposed algorithm on solving the diffusion system with the two types of boundary conditions: periodic (Eq. 16) and Dirichlet-type (Eq. 17) boundary conditions. In this comparison, we omit the causality-motivated baseline (Wang et al., 2022) because the periodic boundary conditions in the existing implementations are enforced as hard constraints. The results in Table 2 show that training ensembles of PINNs yields competitive performance in these settings as well.\nIn Appendix A.3, we study the sensitivity of the ensemble training of PINNs to its hyperparameters. The results show that the PINN Ensemble algorithm is generally stable at solving the considered systems with little sensitivity to the hyperparameter values. We note the importance of hyperparameter \u2206PDE which determines how far the points considered for inclusion can be from the points already included in the loss calculations. The performance of the algorithm drops when \u2206PDE is too large. This happens because ensemble members may be attracted by the same trivial solution in areas too far away from the initial conditions, the effect caused by commonly used network architectures and initialization schemes (see, e.g., Wong et al., 2022; Rohrhofer et al., 2022), which may negatively affect the ensemble diversity."
        },
        {
            "heading": "5 Discussion and future work",
            "text": "In this paper, we propose to stabilize training of PINNs by gradual expansion of the solution interval based on the agreement of an ensemble of PINNs. The obtained results suggest that the proposed approach can reduce the number of failure cases during PINN training. Another potential advantage of the proposed algorithm is that the PINN ensemble produces confidence intervals which can be viewed as uncertainty estimates of the found solution (see Fig. 4c, e). Although the proposed algorithm is more computationally expensive compared to vanilla PINNs, ensemble training can be effectively parallelized in which case the wall clock time of training does not grow significantly. The method shows good results for simple systems such as convection and reaction-diffusion.\nThis work can be extended in a number of ways. One potential direction is to use different ways of creating model ensembles, for example, by dropout (Hinton et al., 2012) or pseudo-ensembles (Bachman et al., 2014). It is interesting to investigate how the proposed algorithm can be combined with other tricks from the PINN literature, for example, adaptive balancing of the loss terms (Wang et al., 2021c). Another direction is to find alternative ways of the solution interval expansion (e.g., update sets I \u2032PDE, I \u2032B more frequently), which may increase the convergence speed. It should also be possible to improve the PINN architecture such that the knowledge of a found (local) solution in one area could be used in finding the solution in another area. Using neural networks with the right inductive bias (e.g., similar to the ones proposed by Sanchez-Gonzalez et al., 2020; Iakovlev et al., 2021; Brandstetter et al., 2022), might provide a solution for that."
        },
        {
            "heading": "Acknowledgment",
            "text": "We thank CSC (IT Center for Science, Finland) for computational resources and the Academy of Finland for the support within the Flagship programme: Finnish Center for Artificial Intelligence (FCAI)."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 PINN extensions\nDespite the elegance of the PINN approach, the method is known to be prone to failures, especially when the solution has a complex shape on the considered interval (see, e.g., Wang et al., 2021a; Krishnapriyan et al., 2021; Wang et al., 2021c;b; 2022; Wight and Zhao, 2020). The optimization problem solved while training PINNs is very hard and the accuracy of the found solution is very sensitive to the hyperparameters of PINNs (see, e.g., Markidis, 2021): the weights wS, wB, wPDE of the loss terms, the parameterization used in the neural network and the strategy for sampling the points in which the loss terms are computed.\nBalancing shared weights wS, wB, wPDE of the individual loss terms in Eqs. 5\u20137 is a popular way to improve the accuracy of the PINN solution. Wight and Zhao (2020) propose using larger weights wS relative to wB and wPDE because the initial conditions largely determine the shape of the solution. Several works propose different schemes for dynamically adapting wS, wB, wPDE during training such that the weights that correspond to problematic loss terms get higher values. Wang et al. (2021a;c) propose to adjust the weights either based on the magnitudes of the gradients of the corresponding loss terms or based on the eigenvalues of the limiting Neural Tangent Kernel. Liu and Wang (2021) propose to treat weights wS, wB, wPDE as trainable parameters and adjust them jointly with the PINN parameters solving a minimax optimization problem. Self-Adaptive PINNs (SA-PINNs, McClenny and Braga-Neto, 2020) increase point-wise weights wi, wj and wk of the loss terms in Eqs. 5\u20137 during training such that the changes of the weights are proportional to the corresponding loss terms.\nThe accuracy of PINNs can also be improved by using a different parameterization for the trained neural network instead of the most standard multilayer perceptron architecture. Several works (see, e.g., Lagaris et al., 1998; Dong and\nNi, 2021; Lu et al., 2021b; Sukumar and Srivastava, 2022) propose neural network parameterizations which guarantee that the initial or boundary conditions are satisfied exactly, thus eliminating terms LS and LB from Eq. 4. Wang et al. (2021b) propose to use Fourier features as the inputs of the neural network, which is motivated by the success of Fourier feature networks (Tancik et al., 2020) in preserving high-frequencies in the modeled solution. The method called SIREN (Sitzmann et al., 2020) proposes to use a multilayer perceptron with periodic activation functions and adjusts the weight initialization schemes to work better with such activation functions. This parameterization can also improve learning of high frequencies in the modeled solution. Wang et al. (2021a) propose to add multiplicative connections to the standard multilayer perceptron architecture to account for possible multiplicative interactions between different input dimensions.\nAnother popular way of improving the accuracy of PINNs is to use adaptive strategies for sampling collocation points (xk, tk) to compute LPDE in Eq. 7. Wight and Zhao (2020) propose to sample more collocation points in the areas with large values of LPDE, which helps to learn solutions with fast transitions. Daw et al. (2022) propose an evolutionary strategy for sampling the collocation points: the points with large contribution to LPDE are kept for the next iteration while the rest of the points are re-sampled uniformly from the domain. These approaches resemble the strategy of the classical solvers to reduce the discretization interval when the solution cannot be estimated accurately. More details on the sampling strategies for PINN and empirical comparison can be found in (Wu et al., 2022).\nMany of the improvements proposed to PINNs can be combined, which is supported by existing software libraries (Lu et al., 2021a; Zubov et al., 2021; Hennigh et al., 2021).\nA.2 Training details\nFor all comparison methods (similarly to Krishnapriyan et al. (2021)), we useKPDE = 1000 collocation points randomly sampled from a regular 256\u00d7 100 grid on the solution interval. We use KS = 256 points to fit the initial conditions, these points are selected from a regular grid on x \u2208 [0, 2\u03c0] with t = 0. We use KB = 100 for the boundary condition loss LBC. These points are selected form a regular grid on t \u2208 [0, 1]. For the proposed ensemble method, we use the following hyperparameters: \u03c32 = 0.0004, = 0.001, \u2206 = 0.05 and \u2206PDE = 0.1. We perform N = 1000 gradient updates before extending sets I \u2032PL, I \u2032 PDE, IB, except for the first set extension which is done after N1 = 5000 training steps. We also set weighting coefficient ws = 64/|D \u222a IPDE| for runs with pseudo-labels trained with Adam and LBFGS similar to the closest baseline.\nFor the baseline methods we adapted the authors\u2019 implementations with the following adjustments.\n\u2022 Causality (Wang et al., 2022): PINN with an adaptive weighting scheme that respects causality. We report results for the values of hyperparameter in Eq. 8 that worked best for the considered systems: = 0.01 for the convection system, = 100 for the reaction system and = 1 for the reaction-diffusion systems. We train the model until all the adapted weights become greater than 0.99 (the stopping criterion used by Wang et al. (2022)). As the existing implementation requires a regular grid, we use a grid of KPDE = 32\u00d7 32 = 1024 collocation points to compute loss LPDE. We also report results with a denser grid of KPDE = 256 \u00d7 100 = 25600 points for this algorithm. We do not add normalization for network inputs x and t to [\u22121, 1] and follow input encoding of the original implementation.\n\u2022 SA-PINN (McClenny and Braga-Neto, 2020) with trainable point-specific weights. We switch off finetuning with the LBFGS optimizer after Adam due to observed training instabilities. We also add normalization of network inputs to [\u22121, 1] similar to our method.\n\u2022 bc-PINN (Mattey and Ghosh, 2022): a technique of expanding the time interval with a pre-defined schedule. We expand the time interval four times and sample 250 collocation points on each interval to compute loss LPDE and 25 points per interval to compute LB. We report the results obtained with the Adam optimizer and with the Adam optimizer followed by LBFGS on each time interval.\nFor all of the methods, we train convection equation (Eqs. 9\u201310) with \u03b2 = 30 for 104000 gradient updates and with \u03b2 = 40 for 154000 updates, reaction (Eqs. 11\u201312) and reaction-diffusion (Eqs. 13\u201314) equations are trained for 64000 updates, diffusion (Eqs. 15\u201317) equation with d = 5 and d = 7 for 84000 updates and with d = 10 for 104000 (unless an automatic stopping criterion is used).\nA.3 Hyperparameter sensitivity\nIn Table 3, we test the sensitivity of the ensemble training of PINNs to its hyperparameters. In these experiments, we use the number of updates as described in Appendix A.2. We consider that a run has not converged if less than 95% of\nthe sampled points have been added to the set which is used to compute LPDE by the last update. Such runs are excluded from the statistics reported in Table 3. This step is done only in the hyperparameter sensitivity experiments.\nThe most important hyperparameters are the variance threshold \u03c32 and the distance parameters \u2206 and \u2206PDE which determine how quickly the algorithm expands the solution interval. When \u03c32 is small then the interval is expanded more slowly and the algorithm may require more iterations to converge. Too large values of \u03c32 can result in adding new regions in the training procedure too early. The distance hyperparameters \u2206 and \u2206PDE have a similar effect. However, for the considered systems, the model performance is stable with little sensitivity to the values of these hyperparameters as well as to the number KPDE of collocation points and the number of networks in the ensemble.\nA.4 More experimental results\nIn this section we report additional experimental results for reaction (Eqs. 11\u201312) with \u03c1 = 6 and reaction-diffusion (Eqs. 13\u201314) with \u03bd = 2."
        }
    ],
    "title": "IMPROVED TRAINING OF PHYSICS-INFORMED NEURAL NETWORKS WITH MODEL ENSEMBLES",
    "year": 2023
}