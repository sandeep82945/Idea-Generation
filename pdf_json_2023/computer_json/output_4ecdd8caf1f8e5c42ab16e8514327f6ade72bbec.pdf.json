{
    "abstractText": "Imbalanced distributions are ubiquitous in real-world data. They create constraints on Deep Neural Networks to represent the minority labels and avoid bias towards majority labels. The extensive body of imbalanced approaches address categorical label spaces but fail to effectively extend to regression problems where the label space is continuous. Local and global correlations among continuous labels provide valuable insights towards effectively modelling relationships in feature space. In this work, we propose ConR, a contrastive regularizer that models global and local label similarities in feature space and prevents the features of minority samples from being collapsed into their majority neighbours. ConR discerns the disagreements between the label space and feature space, and imposes a penalty on these disagreements. ConR addresses the continuous nature of label space with two main strategies in a contrastive manner: incorrect proximities are penalized proportionate to the label similarities and the correct ones are encouraged to model local similarities. ConR consolidates essential considerations into a generic, easy-to-integrate, and efficient method that effectively addresses deep imbalanced regression. Moreover, ConR is orthogonal to existing approaches and smoothly extends to uniand multi-dimensional label spaces. Our comprehensive experiments show that ConR significantly boosts the performance of all the stateof-the-art methods on four large-scale deep imbalanced regression benchmarks. Our code is publicly available in https://github.com/BorealisAI/ConR.",
    "authors": [
        {
            "affiliations": [],
            "name": "Mahsa Keramati"
        },
        {
            "affiliations": [],
            "name": "Lili Meng"
        },
        {
            "affiliations": [],
            "name": "R. David Evans"
        }
    ],
    "id": "SP:d827af9d1e87f08753d24a330872fa9750f24739",
    "references": [
        {
            "authors": [
                "Carlo Alberto Barbano",
                "Benoit Dufumier",
                "Edouard Duchesnay",
                "Marco Grangetto",
                "Pietro Gori"
            ],
            "title": "Contrastive learning for regression in multi-site brain age prediction",
            "venue": "IEEE 20th International Symposium on Biomedical Imaging (ISBI),",
            "year": 2023
        },
        {
            "authors": [
                "Mateusz Buda",
                "Atsuto Maki",
                "Maciej A Mazurowski"
            ],
            "title": "A systematic study of the class imbalance problem in convolutional neural networks",
            "venue": "Neural networks,",
            "year": 2018
        },
        {
            "authors": [
                "Jonathon Byrd",
                "Zachary Lipton"
            ],
            "title": "What is the effect of importance weighting in deep learning",
            "venue": "In International conference on machine learning,",
            "year": 2019
        },
        {
            "authors": [
                "Nitesh V Chawla",
                "Kevin W Bowyer",
                "Lawrence O Hall",
                "W Philip Kegelmeyer"
            ],
            "title": "Smote: synthetic minority over-sampling technique",
            "venue": "Journal of artificial intelligence research,",
            "year": 2002
        },
        {
            "authors": [
                "Ting Chen",
                "Simon Kornblith",
                "Mohammad Norouzi",
                "Geoffrey Hinton"
            ],
            "title": "A simple framework for contrastive learning of visual representations",
            "venue": "Proceedings of the 37th International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Xiaohua Chen",
                "Yucan Zhou",
                "Dayan Wu",
                "Wanqian Zhang",
                "Yu Zhou",
                "Bo Li",
                "Weiping Wang"
            ],
            "title": "Imagine by reasoning: A reasoning-based implicit semantic data augmentation for long-tailed classification",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Xinlei Chen",
                "Haoqi Fan",
                "Ross Girshick",
                "Kaiming He"
            ],
            "title": "Improved baselines with momentum contrastive learning",
            "venue": "arXiv preprint arXiv:2003.04297,",
            "year": 2020
        },
        {
            "authors": [
                "Peng Chu",
                "Xiao Bian",
                "Shaopeng Liu",
                "Haibin Ling"
            ],
            "title": "Feature space augmentation for long-tailed data",
            "venue": "In Computer Vision\u2013ECCV 2020: 16th European Conference,",
            "year": 2020
        },
        {
            "authors": [
                "Jiequan Cui",
                "Zhisheng Zhong",
                "Shu Liu",
                "Bei Yu",
                "Jiaya Jia"
            ],
            "title": "Parametric contrastive learning",
            "venue": "In Proceedings of the IEEE/CVF international conference on computer vision,",
            "year": 2021
        },
        {
            "authors": [
                "Yu Gong",
                "Greg Mori",
                "Frederick Tung"
            ],
            "title": "Ranksim: Ranking similarity regularization for deep imbalanced regression",
            "venue": "In ICML,",
            "year": 2022
        },
        {
            "authors": [
                "Hui Han",
                "Wen-Yuan Wang",
                "Bing-Huan Mao"
            ],
            "title": "Borderline-smote: a new over-sampling method in imbalanced data sets learning",
            "venue": "In Advances in Intelligent Computing: International Conference on Intelligent Computing,",
            "year": 2005
        },
        {
            "authors": [
                "Kaiming He",
                "Haoqi Fan",
                "Yuxin Wu",
                "Saining Xie",
                "Ross Girshick"
            ],
            "title": "Momentum contrast for unsupervised visual representation learning",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Junjie Hu",
                "Mete Ozay",
                "Yan Zhang",
                "Takayuki Okatani"
            ],
            "title": "Revisiting single image depth estimation: Toward higher resolution maps with accurate object boundaries",
            "venue": "IEEE winter conference on applications of computer vision (WACV),",
            "year": 2019
        },
        {
            "authors": [
                "Ziyu Jiang",
                "Tianlong Chen",
                "Ting Chen",
                "Zhangyang Wang"
            ],
            "title": "Improving contrastive learning on imbalanced data via open-world sampling",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Bingyi Kang",
                "Saining Xie",
                "Marcus Rohrbach",
                "Zhicheng Yan",
                "Albert Gordo",
                "Jiashi Feng",
                "Yannis Kalantidis"
            ],
            "title": "Decoupling representation and classifier for long-tailed recognition",
            "venue": "In International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Bingyi Kang",
                "Yu Li",
                "Sa Xie",
                "Zehuan Yuan",
                "Jiashi Feng"
            ],
            "title": "Exploring balanced feature spaces for representation learning",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Bingyi Kang",
                "Yu Li",
                "Sa Xie",
                "Zehuan Yuan",
                "Jiashi Feng"
            ],
            "title": "Exploring balanced feature spaces for representation learning",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Prannay Khosla",
                "Piotr Teterwak",
                "Chen Wang",
                "Aaron Sarna",
                "Yonglong Tian",
                "Phillip Isola",
                "Aaron Maschinot",
                "Ce Liu",
                "Dilip Krishnan"
            ],
            "title": "Supervised contrastive learning",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Prannay Khosla",
                "Piotr Teterwak",
                "Chen Wang",
                "Aaron Sarna",
                "Yonglong Tian",
                "Phillip Isola",
                "Aaron Maschinot",
                "Ce Liu",
                "Dilip Krishnan"
            ],
            "title": "Supervised contrastive learning",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Tianhong Li",
                "Peng Cao",
                "Yuan Yuan",
                "Lijie Fan",
                "Yuzhe Yang",
                "Rogerio S Feris",
                "Piotr Indyk",
                "Dina Katabi"
            ],
            "title": "Targeted supervised contrastive learning for long-tailed recognition",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Tsung-Yi Lin",
                "Priya Goyal",
                "Ross Girshick",
                "Kaiming He",
                "Piotr Doll\u00e1r"
            ],
            "title": "Focal loss for dense object detection",
            "venue": "IEEE International Conference on Computer Vision (ICCV),",
            "year": 2017
        },
        {
            "authors": [
                "Stylianos Moschoglou",
                "Athanasios Papaioannou",
                "Christos Sagonas",
                "Jiankang Deng",
                "Irene Kotsia",
                "Stefanos Zafeiriou"
            ],
            "title": "Agedb: the first manually collected, in-the-wild age database",
            "venue": "In proceedings of the IEEE conference on computer vision and pattern recognition workshops,",
            "year": 2017
        },
        {
            "authors": [
                "Aaron van den Oord",
                "Yazhe Li",
                "Oriol Vinyals"
            ],
            "title": "Representation learning with contrastive predictive coding",
            "venue": "arXiv preprint arXiv:1807.03748,",
            "year": 2018
        },
        {
            "authors": [
                "Jiawei Ren",
                "Mingyuan Zhang",
                "Cunjun Yu",
                "Ziwei Liu"
            ],
            "title": "Balanced mse for imbalanced visual regression",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Rasmus Rothe",
                "Radu Timofte",
                "Luc Van Gool"
            ],
            "title": "Deep expectation of real and apparent age from a single image without facial landmarks",
            "venue": "International Journal of Computer Vision,",
            "year": 2018
        },
        {
            "authors": [
                "Nyeong-Ho Shin",
                "Seon-Ho Lee",
                "Chang-Su Kim"
            ],
            "title": "Moving window regression: a novel approach to ordinal regression",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Nathan Silberman",
                "Derek Hoiem",
                "Pushmeet Kohli",
                "Rob Fergus"
            ],
            "title": "Indoor segmentation and support inference from rgbd images",
            "venue": "ECCV (5),",
            "year": 2012
        },
        {
            "authors": [
                "Michael Steininger",
                "Konstantin Kobs",
                "Padraig Davidson",
                "Anna Krause",
                "Andreas Hotho"
            ],
            "title": "Density-based weighting for imbalanced regression",
            "venue": "Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Junjiao Tian",
                "Yen-Cheng Liu",
                "Nathaniel Glaser",
                "Yen-Chang Hsu",
                "Zsolt Kira"
            ],
            "title": "Posterior recalibration for imbalanced datasets",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Vikas Verma",
                "Alex Lamb",
                "Christopher Beckham",
                "Amir Najafi",
                "Ioannis Mitliagkas",
                "David LopezPaz",
                "Yoshua Bengio"
            ],
            "title": "Manifold mixup: Better representations by interpolating hidden states",
            "venue": "In International conference on machine learning,",
            "year": 2019
        },
        {
            "authors": [
                "Peng Wang",
                "Kai Han",
                "Xiu-Shen Wei",
                "Lei Zhang",
                "Lei Wang"
            ],
            "title": "Contrastive learning based hybrid networks for long-tailed image classification",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Xudong Wang",
                "Long Lian",
                "Zhongqi Miao",
                "Ziwei Liu",
                "Stella Yu"
            ],
            "title": "Long-tailed recognition by routing diverse distribution-aware experts",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Yaoming Wang",
                "Yangzhou Jiang",
                "Jin Li",
                "Bingbing Ni",
                "Wenrui Dai",
                "Chenglin Li",
                "Hongkai Xiong",
                "Teng Li"
            ],
            "title": "Contrastive regression for domain adaptation on gaze estimation",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Yuzhe Yang",
                "Kaiwen Zha",
                "Yingcong Chen",
                "Hao Wang",
                "Dina Katabi"
            ],
            "title": "Delving into deep imbalanced regression",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Xi Yin",
                "Xiang Yu",
                "Kihyuk Sohn",
                "Xiaoming Liu",
                "Manmohan Chandraker"
            ],
            "title": "Feature transfer learning for face recognition with under-represented data",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Hongyi Zhang",
                "Moustapha Cisse",
                "Yann N Dauphin",
                "David Lopez-Paz"
            ],
            "title": "mixup: Beyond empirical risk minimization",
            "venue": "arXiv preprint arXiv:1710.09412,",
            "year": 2017
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Imbalanced data distributions, which are common in real-world contexts, introduce substantial challenges in generalizing conventional models due to variance across minority labels and bias to the majority ones (Wang et al., 2021b; Gong et al., 2022; Buda et al., 2018). Although there are numerous works on learning from imbalanced data (Chawla et al., 2002; Cui et al., 2021; Jiang et al., 2021), these studies mainly focus on categorical labels. Continuous labels are potentially infinite, high-dimensional and hard to bin semantically (Ren et al., 2022). These characteristics impede the performance of imbalanced classification approaches on Deep Imbalanced Regression (DIR) (Yang et al., 2021).\nContinuous labels result in underlying local and global correlations, which yields valuable perspectives towards effective representation learning of imbalanced data (Gong et al., 2022; Shin et al., 2022). For instance, regression training on imbalanced data fails to model appropriate relationships for minority labels in the feature space (Yang et al., 2021). Yang et al. (2021) established an empirical example of this phenomenon on the age estimation task where the learned features of under-represented samples collapse to majority features. Several approaches tackle this issue by encouraging local dependencies (Yang et al., 2021; Steininger et al., 2021). However, these methods fail to exploit global relationships and are biased toward only learning representative features for majority samples, especially when minority examples do not have majority neighbours. RankSim (Gong et al., 2022) leverages global and local dependencies by exploiting label similarity orders in feature space. Yet, RankSim does not generalize to all regression tasks, as not all continuous label spaces convey order relationships. For example, for depth-map estimation from scene\n\u2217Work done during an internship at Borealis AI.\nar X\niv :2\n30 9.\n06 65\n1v 2\n[ cs\n.L G\n] 4\nO ct\n2 02\n3\npictures, the complicated relationships in the high-dimensional label space are not trivially convertible to a linearly ordered feature space. Given the importance of the correspondence between the label space and feature space for imbalanced regression, can we effectively transfer inter-label relationships, regardless of their complexity, to the feature space?\nWe propose a method to enforce this correspondence: ConR is a novel Contrastive Regularizer which is based on infoNCE loss (Oord et al., 2018) but adapted for multi-positive pairs. While similar extensions are performed for classification tasks (Khosla et al., 2020a), ConR addresses continuous label space and penalizes minority sample features from collapsing into the majority ones. Contrastive approaches for imbalanced classification are mainly based on predefined anchors, decision boundary-based negative pair selection and imposing discriminative feature space (Cui et al., 2021; Wang et al., 2021a; Li et al., 2022). These are not feasibly extendible to continuous label spaces. ConR introduces continuity to contrastive learning for regression tasks. Fig 1 illustrates an intuitive example for ConR from the task of age estimation. There are images of individuals of varying ages, including 1, 21, 25, and 80 years. Age 1 and 80 are the minority examples, reflecting the lim-\nited number of images available for these age groups within the datasets. While 21 is a majority example, given the abundance of images around this age within the datasets. Without using ConR, similarities in the feature space are not aligned with the relationships in the label space. Thus, the minority samples\u2019 features collapse to the majority sample, leading to inaccurate predictions for minority ones that mimic the majority sample (Fig 1a). ConR regularizes the feature space by simultaneously encouraging locality via pulling together positive pairs and preserving global correlations by pushing negative pairs. The 21-year-old sample coexists within a region in the feature space alongside 1-year-old and 80-year-old samples. Thus, ConR 1) considers the 21-year-old sample as an anchor, and, 2) pushes negative pairs for minority anchors harder than majority examples to provide better separation in feature space. Furthermore, ConR 3) increases pushing power based on how heavily mislabelled an example is (Fig 1b.1 to Fig 1b.3). We demonstrate that ConR effectively translates label relationships to the feature space, and boosts the regression performance on minority samples (Fig 1c). Refer to A.1 for the empirical analysis on the motivation of ConR.\nConR implicitly models the local and global correlations in feature space by three main contributions to the contrastive objective: 1) Dynamic anchor selection: Throughout the training, considering the learned proximity correspondences, ConR selects samples with the most collapses on the feature manifold as anchors. 2) Negative Pairs selection: Negative pairs are sampled to quantify the deviation they introduce to the correspondence of similarities in feature and label space, thereby compensating for under-represented samples. 3) Relative pushing: Negative pairs are pushed away proportional to their label similarity and the density of the anchor\u2019s label.\nConR is orthogonal to other imbalanced learning techniques and performs seamlessly on highdimensional label spaces. Our comprehensive experiments on large-scale DIR benchmarks for facial age, depth and gaze estimation show that ConR strikes a balance between efficiency and performance, especially on depth estimation, which has a complicated and high-dimensional label space."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "Imbalanced classification. The main focus of existing imbalanced approaches is on the classification task, while imbalanced regression is under-explored. The imbalanced classification methods\nare either data-driven or model-driven. Resampling (Chawla et al., 2002; Chu et al., 2020; Byrd & Lipton, 2019; Han et al., 2005; Jiang et al., 2021) is a data-driven technique that balances the input data by either over-sampling (Chawla et al., 2002; Byrd & Lipton, 2019) the minority classes or under-sampling the majority ones (Han et al., 2005). Model-Aware K-center(MAK) (Jiang et al., 2021) over-samples tail classes using an external sampling pool. Another branch of data-driven approaches is augmentation-based methods. Mixup-based approaches linearly interpolate data either in input space (Zhang et al., 2017) or feature space (Verma et al., 2019) for vicinal risk minimization. RISDA (Chen et al., 2022) shares statistics between classes considering a confusion-based knowledge graph and implicitly augments minority classes. Model-driven methods such as focal loss (Lin et al., 2017) and logit-adjustment (Tian et al., 2020) are cost-sensitive approaches that regulate the loss functions regarding the class labels. To encourage learning an unbiased feature space, several training strategies including two-stage training (Kang et al., 2020), and transfer learning (Yin et al., 2019) are employed. As discussed further, though there has been much success in this area, there are many issues in converting imbalanced classification approaches to regression.\nImbalanced regression. Unlike classification tasks with the objective of learning discriminative representation, effective imbalanced learning in continuous label space is in lieu of modelling the label relationships in the feature space (Yang et al., 2021; Gong et al., 2022). Therefore, imbalanced classification approaches do not feasibly extend to the continuous label space. DenseLoss (Steininger et al., 2021) and LDS (Yang et al., 2021) encourage local similarities by applying kernel smoothing in label space. Feature distribution smoothing (FDS) (Yang et al., 2021) extends the idea of kernel smoothing to the feature space. Ranksim (Gong et al., 2022) proposes to exploit both local and global dependencies by encouraging a correspondence of similarity order between labels and features. Balanced MSE (Ren et al., 2022) prevents Mean Squared Error (MSE) from carrying imbalance to the prediction phase by restoring a balanced prediction distribution.\nContrastive learning. Contrastive Learning approaches are pairwise representation learning techniques that push away semantically divergent samples and pull together similar ones (He et al., 2020; Chen et al., 2020a; Khosla et al., 2020a; Kang et al., 2021a). Momentum Contrast (Moco) (He et al., 2020) is an unsupervised contrastive learning approach that provides a large set of negative samples via introducing a dynamic queue and a moving-averaged encoder; while SupCon (Khosla et al., 2020b) incorporates label information to the contrastive learning. Kang et al. (2021a) argue that in case of imbalanced data, SupCon is subject to learning a feature space biased to majority samples and proposed k-positive contrastive loss (KCL) to choose the same number of positive samples for each instance to alleviate this bias. Contrastive long-tailed classification methods train parametric learnable class centres (Cui et al., 2021; Wang et al., 2021a) or encourage learning a regular simplex (Li et al., 2022). However, these approaches cannot be used for regression tasks where handling label-wise prototypes is potentially complex. Contrastive Regression (CR) (Wang et al., 2022) adds a contrastive loss to Mean Squared Error (MAE) to improve domain adaptation for the gaze estimation task. CR assumes there is a correspondence between similarities in label space and the feature space. Regardless, when learning from the imbalanced data, the correspondence can\u2019t be assumed. Instead of the assumption of correspondence, ConR translates the relative similarities from the label space to the feature space. Barbano et al. (2023) proposed a relative pushing for the task of brain age prediction using MRI scans. This relative pushing doesn\u2019t consider imbalanced distribution, and the weights are learnable kernels that can introduce complexities to complex label spaces."
        },
        {
            "heading": "3 METHOD",
            "text": ""
        },
        {
            "heading": "3.1 PROBLEM DEFINITION",
            "text": "Consider a training dataset consisting N examples, which we denote as {(xi, yi)}Ni=0, where xi \u2208 Rd is an example input, and yi \u2208 Rd \u2032 is its corresponding label. d and d\u2032 are the dimensions of the input and label, respectively. We additionally enforce that the distribution of the labels Dy deviates significantly from a uniform distribution. Given a model that consists of a feature encoder E(\u00b7), and a regression function R(\u00b7), the objective is to train a regression model R(E(\u00b7)), such that the model output y\u0302i = R(E(xi)) is similar to the true label yi."
        },
        {
            "heading": "3.2 IMBALANCED CONTRASTIVE REGRESSION",
            "text": "In regression tasks, inter-label relationships unveil meaningful associations in feature space. However, learning from imbalanced data harms this correspondence since the features learned for minority samples share statistics with the majority samples, despite dissimilar labels (Yang et al., 2021). By incorporating label and prediction relationships into contrastive learning, ConR enforces appropriate feature-level similarities for modelling a balanced feature space.\nConR is a continuous variation of infoNCE. Initially, for creating diversity in examples, we perform problem-specific augmentations on each input xi to produce two augmented samples. We define the set of augmented examples from the input to be {(xaj , yj)}2Nj=0, where xaj is an augmented input. As illustrated in Fig. 2, ConR is a collaboration of pair selection and relative pushing. For each augmented sample, ConR first selects pairs. Next, in the case of at least one negative pairing, the sample is considered an anchor and contributes to the regularizing process of ConR by pulling together positive pairs and relatively repelling negative pairs. In the remainder of this section, we will elucidate ConR as presented in Fig. 2."
        },
        {
            "heading": "3.2.1 PAIR SELECTION",
            "text": "Given a pair of examples (xai , yi) and (x a j , yj) from the augmented inputs (labels and samples, Fig. 2-a), each example is passed to the feature encoder E(\u00b7) to produce feature vectors zi and zj , and then to the regression function R(\u00b7) for predictions y\u0302i and y\u0302j (sample through regression function, Fig. 2-a). The values of the predicted and actual labels are used to determine if the examples should be a positive pair, a negative pair, or unpaired (righthand side, Fig. 2-a).\nTo measure similarity between labels (or predictions) of augmented examples, ConR defines a similarity threshold \u03c9. Given a similarity function Sim(\u00b7, \u00b7) \u2208 R (e.g., inverse square error), we define two labels (or two predictions) yi and yj as similar if Sim(yi, yj) \u2265 \u03c9. We denote this as yi \u2243 yj . Iff two examples have similar labels yi \u2243 yj , then they are treated as a positive pair. The examples have dissimilar labels, but similar predictions y\u0302i \u2243 y\u0302j , then they are treated as a negative pair. Otherwise, examples are unpaired.\nAnchor selection. For each example j, (xaj , yj) We denote the sets of positive and negative pairs for this example, and their feature vectors as K+j = {(zp)} N+j p and K\u2212j = {(zq)} N\u2212j q , respectively, where N+j is the number of positive examples and N \u2212 j is the number of negative samples for example j. If N\u2212j > 0, (x a j , yj) is selected as an anchor and contributes to the regularization process of ConR."
        },
        {
            "heading": "3.2.2 CONTRASTIVE REGULARIZER",
            "text": "For each example j, ConR introduces a loss function LConRj . If example j is not selected as an anchor, LConRj = 0. Otherwise, LConRj pulls together positive pairs while pushing away negative pairs proportional to the similarity of their labels. As shown in Fig. 2-b, ConR pushes away negative samples with less label similarity to yj harder than negative samples with labels closer to the anchor yj :\nLConRj = \u2212 log \u2211\nzi\u2208K+j\nexp(zj \u00b7 zi/\u03c4)\u2211 zp\u2208K+j exp(zj \u00b7 zp/\u03c4) + \u2211 zq\u2208K\u2212j Sj,q exp(zj \u00b7 zq/\u03c4)\n(1)\nwhere \u03c4 is a temperature hyperparameter and Sj,n is a pushing weight for each negative pair:\nSj,q = fS(\u03b7j , Sim(yj , yq)), (2)\nand yq is the label of xq where zq = E(xq). \u03b7j is a pushing power for each sample (xaj , yj) that depends on label distribution Dy to boost the pushing power for minority samples (Fig. 2-b): \u03b7j \u221d wj , where wj is a density-based weight for input j derived from the empirical label distribution (e.g., inverse frequency). The function fS computes the Sj,q to be proportionate to \u03b7j and inversely related to Sim(yj , yq). Please refer to Appendix A.3 for the definition of fS .\nFinally, LConR is the ConR\u2019s regularizer value for the augmented example set:\nLConR = 1\n2N 2N\u2211 j=0 LConRj . (3)\nTo prevent the representations of minority labels from collapsing to the majority ones in deep imbalanced regression, Lsum is optimized. Lsum is weighed sum of LConR and a regression loss LR (e.g., mean absolute error) as below:\nLsum = \u03b1LR + \u03b2LConR (4)"
        },
        {
            "heading": "4 EXPERIMENTS",
            "text": "To evaluate the effectiveness of ConR, we assess its performance against recent methods on three public datasets for deep imbalanced regression. Additionally, for a more extensive evaluation, we derived a DIR benchmark from a public real-world dataset. In this section, we cover experimental setup, analysis of our results, and, finally, ablation studies to investigate the design of ConR."
        },
        {
            "heading": "4.1 MAIN RESULTS",
            "text": "Datasets. We use three datasets curated by Yang et al. (2021) for the deep imbalanced regression problem: AgeDB-DIR is a facial age estimation benchmark, created based on AgeDB (Moschoglou et al., 2017). IMDB-WIKI-DIR is an age estimation dataset originated from IMDB-WIKI (Rothe et al., 2018). NYUD2-DIR is created based on NYU Depth Dataset V2 (Silberman et al., 2012) to predict the depth maps from RGB indoor scenes. Moreover, we create MPIIGaze-DIR based on MPIIGaze, which is an appearance-based gaze estimation benchmark. Refer to Appendix A.2 and A.3 for more dataset and implementation details.\nBaselines. ConR is orthogonal to state-of-the-art imbalanced learning methods, thus we examine the improvement from ConR when added on top of existing methods, which we refer to as baselines for our technique: Label- and Feature-Distribution Smoothing (LDS and FDS) encourage local similarities in label and feature space (Yang et al., 2021). RankSim imposes a matching between the order of similarities in label space with these similarities in feature space (Gong et al., 2022). Balanced MSE encourages a balanced prediction distribution (Ren et al., 2022). To investigate the effect of contrastive learning on deep imbalanced regression, we also regularize using infoNCE (Oord et al., 2018) and contrastive architecture of MoCo (He et al., 2020), MoCo V2 (Chen et al., 2020b). Refer to Appendix A.5 for contrastive analysis. Results for RankSim on depth estimation and gaze estimation are omitted as RankSim is not suitable for these tasks.\nEvaluation process and metrics. Following the standard procedure for imbalanced learning (Yang et al., 2021; Gong et al., 2022), we report the results for four shots: All, few, median and many. The whole test data is denoted by All. Based on the number of samples in the training dataset, few, median and many that have less than 20, between 20 and 100, and more than 100 training samples per label, respectively.\nFor AgeDB-DIR and IMDB-WIKI-DIR, the metrics are Mean-Absolute-Error (MAE), and Geometric Mean (GM). For NYUD2-DIR we use Root Mean Squared Error (RMSE) and Threshold accuracy (\u03b41) as metrics as in (Yang et al., 2021; Ren et al., 2022). Threshold accuracy \u03b4i is the percentage of di that satisfies max(d1g1 , g1 d1 ) < 1.25, where for each pixel, g1 is the ground truth depth value and d1 is the predicted depth value. For MPIIGaze-DIR, we use Mean Angle Error (degrees). To calculate relative improvement of ConR, we compare the performance of each combination of methods including ConR, against the same combination without ConR. Each \u201dOurs vs. ...\u201d entry shows the average of these improvements (e.g. \u201dOurs vs. LDS\u201d is the average of the improvements of adding ConR to each combination of baselines that has LDS).\nMain results for age estimation. Table 1 and Table 2 show the results on AgeDB-DIR and IMDBWIKI-DIR benchmarks, respectively. We compare the performance of DIR methods: FDS, LDS and RankSim with their regularized version by ConR. All results are the averages of 5 random runs. We observe that the performances of all the baselines are considerably boosted when they are regularized with ConR. In addition, ConR results in the best performance across both metrics and all shots for the AgeDB-DIR benchmark with leading MAE results of 6.81 and 9.21 on the overall test set and few-shot region, respectively. For IMDB-WIKI-DIR, ConR achieves the highest performance on 7 out of 8 shot/metric combinations with the best MAE results of 7.29 and 21.32 on the overall test set and few-shot region, respectively.\nMain results for depth estimation. To assess the effectiveness of ConR in more challenging settings where the label space is high-dimensional with non-linear inter-label relationships, we compare its performance with baselines: LDS, FDS and Balanced MSE on NYUD2-DIR depth estimation benchmark. For this task, the label similarity is measured by the difference between the average depth value of two samples. As shown in table 3, ConR alleviates the bias of the baseline toward the majority samples. ConR significantly outperforms LDS, FDS and Balanced MSE across all shots and both metrics with leading RMSE results of 1.265 on the overall test set and 1.667 on the few-shot region. Notably, RankSim cannot be used on the depth estimation task; however, ConR can smoothly be extended to high-dimensional label space with high performance. The reason is that\norder relationships are not semantically meaningful for all regression tasks with high-dimensional label space, such as depth estimation.\nMain results for gaze estimation. Table 4 compares the performance of ConR with three baseline methods: LDS, FDS and Balanced MSE on the MPIIGaze-DIR benchmark. As shown in table 4, ConR consistently improve the performance of all baselines for all shots and achieves the best Mean angular error of 5.63 (degrees) on the overall test set and 5.21 (degrees) on the few-shot region.\nError reduction. In Fig. 3, we show the comparison between three strong baselines (LDS, FDS and Balanced MSE) and by adding ConR for NYUD2-DIR benchmark. It shows a consistent and notable error reduction effect by adding our ConR to the deep imbalanced learning. For more\nresults and analysis on other datasets (e.g. AgeDB-DIR and IMDB-WIKI-DIR, MPIIGaze-DIR), please refer to Appendix A.4.\nTime consumption Analysis. Table 5 provides the time consumption of ConR in comparison to other baselines and VANILLA for the age estimation and depth estimation tasks. VANILLA is a regression model with no technique for imbalanced learning. The reported time consumptions are expressed in seconds for AgeDB-DIR and in minutes for NYUD2-DIR, representing the average forward pass and training time, and were measured using four NVIDIA GeForce GTX 1080 Ti GPUs. Table 5\u2019s findings demonstrate that even with a high-dimensional label space, ConR\u2019s training time is considerably lower than FDS while remaining comparable to the time complexity of LDS, RankSim, and Balanced MSE. This indicates that ConR is an efficient alternative to FDS without compromising efficiency compared to other well-established methods. This result highlights ConR\u2019s ability to handle complex tasks without introducing significant computational overhead.\nFeature visualizations. We evaluate ConR by comparing its learned representations with VANILLA, FDS, and LDS. Using t-SNE visualization, we map ResNet-50\u2019s features to a 2D space for the AgeDB-DIR dataset. Fig. 4 demonstrates the feature-label semantic correspondence exploited by ConR, compared to VANILLA, FDS and LDS. VANILLA fails to effectively model the feature space regarding three key observations: a) high occurrences of collapses: features of minority samples are considerably collapsed to the majority ones. b) low relative spread: contradicting the linearity in the age estimation task\u2019s label space, the learned representation exhibits low feature variance across the label spread (across the colour spectrum) compared to the variance across a single label (same colour). c) Noticeable gaps within the feature space: contradicts the intended continuity in regression tasks. Compared to VANILLA, FDS and LDS slightly alleviate the semantic confusion in feature space. However, as shown in Fig. 4d, ConR learns a considerably more effective feature space with fewer collapses, higher relative spread and semantic continuity."
        },
        {
            "heading": "4.2 ABLATION STUDIES ON DESIGN MODULES",
            "text": "Negative sampling, pushing weight and pushing power analysis. Here we assess the significance of our method\u2019s contributions through the evaluation of several variations of ConR and investigating the impact of different choices of the hyperparameters in ConR. We define four versions of ConR: Contrastive-ConR: contrastive regularizer where negative peers are selected only based on label similarities. ConR-S: ConR with no pushing power assigned to the negative pairs. ConR-\n\u03b7: ConR with pushing powers that are not proportionate to the instance weights. ConR-Sim: ConR with pushing powers that are not proportionate to the label similarities. Table 6 describes the comparison between these three versions on the AgeDB-DIR benchmark and shows the crucial role of each component in deep imbalanced regression. Contrastive-ConR is the continuous version of SupCon (Khosla et al., 2020a) that is biased to majority samples (Kang et al., 2021b). Thus, Contrastive-ConR shows better results on many shot that is due to the higher performance for majority samples, while it degrades the performance for minority ones. However, ConR results in a more balanced performance with significant improvement for the minoirty shots.\nSimilarity threshold analysis. We investigate the choice of similarity threshold \u03c9 by exploring the learned features and model performance employing different values for the similarity threshold. Fig. 5a and Fig. 5b compare the feature space learnt with similarity threshold \u03c9 = 2 and \u03c9 = 1 for ConR on the AgeDB-DIR benchmark. ConR implicitly enforces feature smoothness and linearity in feature space. A high threshold (\u03c9 = 2) is prone to encouraging feature smoothing in a limited label range and bias towards majority samples. As illustrated in Fig. 5b, choosing a higher similarity threshold leads to smoother and more linear feature space. Fig. 5c demonstrates the ablation results for the similarity threshold on the Age-DB-DIR dataset. For AgeDB-DIR, \u03c9 = 1 produces the best performance. An intuitive explanation could be the higher thresholds will impose sharing feature statistics to an extent that is not in correspondence with the heterogeneous dynamics in the feature space. For example, in the task of facial age estimation, the ageing patterns of teenagers are different from people in their 20s. For more details on this study please refer to Appendix A.5."
        },
        {
            "heading": "5 CONCLUSION",
            "text": "In this work, we propose ConR, a novel regularizer that encapsulates desirable properties for deep imbalanced regression. ConR effectively incorporates continuity to contrastive learning and implicitly encourages preserving local and global semantic relations in the feature space without any explicit assumption about inter-label dependencies. The novel anchor selection proposed in this work\nconsistently derives a balanced training focus across the imbalanced training distribution. ConR is orthogonal to all regression models. Our extensive experiments on uni- and multi-dimensional DIR benchmarks show that regularizing a regression model with ConR considerably lifts its performance, especially for the under-represented samples and high-dimensional label spaces. ConR opens a new perspective to contrastive regression and is inspiring for further studies. Contrastive methods rely on rich data augmentations and the best performance of ConR on tasks with no well-defined data augmentations requires further work to define task-specific data augmentations. Our future study is to investigate the impact of task-agnostic data augmentations on imbalanced contrastive regression."
        },
        {
            "heading": "A EXPERIMENTS",
            "text": "A.1 EMPIRICAL ANALYSIS OF THE MOTIVATION\nThe key motivation of the design of ConR is that features of minority samples tend to collapse to their majority neighbours. ConR highlights these situations by defining a penalty based on the misalignments between prediction similarities and label similarities. Further, ConR regularizes a regression model by minimizing the defined penalty in a contrastive manner.\nHere we first define the penalty P (y) for each prediction value y \u2208 Dy . P (y) denotes the average of the regression errors of the samples with the similar prediction value of y: P (y) = 1 Ny \u2211Ny i=0 LR(xi, yi), where R(E(xi)) \u2243 y, yi \u0338\u2243 y and Ny is the number of the samples collapsed to the feature space of samples labelled with y.\nTo empirically confirm the motivation behind ConR, we investigate the importance of the penalty term in regression tasks. In addition, we show that regularizing a regression model with ConR consistently alleviate the penalty term defined by ConR and this optimization considerably contributes to imbalanced regression. Fig. 6a and Fig. 6b demonstrate the comparison between LDS and ConR in terms of the training loss curve and validation loss curve, respectively. Moreover, Fig. 6c shows the trend of the expected value of P (y) over the label space, throughout the training. Comparing Fig. 6c with Fig. 6a and Fig. 6b, P (y) follows the same decreasing pattern as training loss and validation loss. This observation show that penalizing the penalty term is highly coupled with the learning process. In addition, Fig. 6 shows that ConR outperform LDS with a considerable gap, particularly in terms of P (y); showing that ConR regularizer consistently alleviates the penalty and significantly contributes to the imbalanced regression.\nFig. 7a shows the training label distribution and Fig. 7b depicts the difference of P (y) across the label space between ConR and LDS. It empirically shows the considerable improvement of ConR over LDS in terms of the defined penalty. More improvement over the majority of samples is intuitive because due to the imbalanced distribution, most of the collapses in feature space happen in the majority areas and decreasing the penalty in these areas contributes the most to the imbalanced regression. Finally, Fig. 7c compares the regression error of ConR and LDS and we observe ConR results in a considerable improvement over LDS, especially for minority samples.\nA.2 DATASET DETAILS\nGaze estimation We used a subset of the MPIIGaze dataset comprising 45,000 training samples from 15 individuals, with 3,000 samples per person. The dataset is naturally imbalanced over the 2D training label distribution. To create a balanced test set, we sample shots corresponding to a 10x10 grid over the 2D label distribution, similar to the methods used in the FDS work.\nFollow the baselines (Gong et al., 2022), only the training data for these tasks is imbalanced; the test dataset is balanced.\nA.3 IMPLEMENTATION DETAILS\nWe use four NVIDIA GeForce GTX 1080 Ti GPU to train all models. For a fair comparison, we follow (Yang et al., 2021) for all standard train/val/test splits. The rest of this section provides the implementation details and choices of hyperparameters for all three datasets.\nAge estimation. For AgeDB-DIR benchmark and IMDB-WIKI-DIR benchmark, we use Resnet50 for encoder E(\u00b7) and a one-layer fully connected network for the regression module R(\u00b7). The batch size is 64 and the learning rate is 2.5 \u2217 10\u22124 and decreases by 10\u00d7 at epoch 60 and epoch 80. We use the Adam optimizer with a momentum of 0.9 and a weight decay of 1e-4. Following the baselines (Yang et al., 2021) the loss function for regression LR is Mean Absolute Error(MAE). All the models are trained for 90 epochs.\n\u03b7j = (0.01)wj and the similarity function Sim(\u00b7, \u00b7) is inverse Mean Absolute Error(MAE). To resolve divide by zero and infinite numbers, a pair of samples with MAE distance < 1\u03c9 are considered similar. Further, the pushing weight Sj,q is defined as: Sj,q = fS(\u03b7j , 1MAE(yj ,yq) ) = \u03b7jMAE(yj , yq). Finally, the similarity threshold \u03c9 is 1, \u03c4 = 0.2, \u03b1 = 1, and \u03b2 = 4.\nDepth estimation. For NYUD2-DIR benchmark, we use ResNet-50-based encoder-decoder architecture (Hu et al., 2019). The output size is 114 \u00d7 152. The batch size is 32 and the learning rate is 1 \u2217 10\u22124. All models are trained for 90 epochs with an Adam optimizer. The momentum of the optimizer is 0.9 and its weight decay is 1e\u2212 4. Following the baselines (Yang et al., 2021; Hu et al., 2019) the loss function for regression LR is root-mean-square(RMSE). To measure the similarity in label space, first, for each sample (zj , yj), we take the average value of the depth map, denoted as y\u0304j . Then, for each pair of samples, we use the root-mean-square(RMSE) to quantify the similarity of this pair in the label space. If the RMSE(y\u0304i, y\u0304j) is less than 1\u03c9 , sample i and sample j are considered similar and otherwise dissimilar. In addition, the pushing weight Sj,q is defined as: Sj,q = fS(\u03b7j , 1RMSE(yj ,yq) ) = \u03b7jRMSE(yj , yq). The similarity threshold \u03c9 is 5, \u03b2 = 0.2, \u03c4 = 0.7 and \u03b7j = (0.2)wj .\nGaze estimation. We reported our results on a balanced test set, containing 600 samples in total and 200 samples per each \u201dmany,\u201d \u201dmedian,\u201d and \u201dfew\u201d shots. Our results were averaged over five random runs to ensure statistical significance. Each run in the evaluation incorporated a leave-oneout scheme, where we performed 15 runs with a single individual as the designated test set. The final results are the Mean Angle Error (in degrees) for all the individuals. The backbone is LeNet, \u03b2 = 0.4, \u03b1 = 1, \u03c9 = 1 . \u03b7j = (0.01)wj and Sj,q = fS(\u03b7j , 1MAE(yj ,yq) ) = \u03b7jMAE(yj , yq). The batch size and the base learning rate are 32 and 0.01, respectively.\nA.4 PERFORMANCE ANALYSIS\nAll the experimental results are reported as the averages of 5 random runs.\nMore results for age estimation. For a more extensive empirical confrimation that ConR is orthogonal to DIR baselines, Table 7 shows the performance improvements when RRT Yang et al. (2021), Focal-R Yang et al. (2021) and Balanced MSE are regularized by ConR.\nError Reduction. Here we show the comparison of the Error reduction resulting from adding ConR to the deep imbalanced regression baselines (LDS, FDS and RankSim) for age estimation benchmarks(e.g. AgeDB-DIR and IMDB-WIKI-DIR) and (LDS, FDS and Balanced MSE) for gaze estimation benchmark. Fig. 8, Fig. 9 and Fig. 10 empirically confirm significant performance consistency ConR introduces to DIR for AgeDB-DIR, IMDB-WIKI-DIR and MPIIGaze-DIR benchmarks, respectively.\nA.5 ABLATION STUDY\nNegative Sampling, Pushing Weight and Power Analysis. Table 8, table 9 and table 10 show the significance of the main contributions of ConR for IMDB-WIKI-DIR, NYUD2-DIR and MPIIGazeDIR benchmarks, respectively.\nSimilarity Threshold Selection. Fig. 11 shows the ablation study on the similarity threshold for IMDB-WIKI-DIR and NYUD2-DIR benchmarks. \u03c9 = 1 and \u03c9 = 5 are the best similarity threshold choices for IMDB-WIKI-DIR and NYUD2-DIR benchmarks, respectively.\nHyperparameter selection. Here we present the selection process of hyperparameters \u03b1, \u03b2 and \u03b7 for all the benchmarks. Table 11, Table 12, Table 13 and Table 14 show the ablation study of ConR on \u03b1 and \u03b2 in Eq. 4 for AgeDB-DIR, IMDB-WIKI-DIR, NYUD2-DIR and MPIIGaze-DIR benchmarks, respectively. In these tables, hyperparameter \u03b7 is set to the values mentioned in ??. Additionally, Table 15, Table 16, Table 17 and Table 18 show the ablation study of ConR on \u03b7 in Eq. 2 for AgeDB-DIR, IMDB-WIKI-DIR, NYUD2-DIR and MPIIGaze-DIR benchmarks, respectively. In these tables, hyperparameter \u03b7 is set to the values mentioned in ??.\nContrastive Regression. To evaluate the impact of contrastive learning on deep imbalanced regression, we use two contrastive regularizers: MoCo: We regularize the baselines with infoNCE\nloss, using the architecture of with MoCo V1 (He et al., 2020), MoCo V2 (Chen et al., 2020b), and ConR. Here we regularized a regression model with both Moco v1 and MoCo v2. Our experiments shows that MoCo v2 degrades the regression performance in some cases. Table 19 compares the per-\nformance of a regression model on AgeDB-DIR, IMDB-WIKI-DIR and NYUD2-DIR benchmarks when it is regularized in a contrastive manner with MoCo V1, MoCo V2, and ConR. The results are reported in terms of MAE for AgeDB-DIR benchmark and IMDB-WIKI-DIR benchmark and in terms of RMSE for NYUD2-DIR dataset. Moco considerably boost the performance of VANILLA and shows that contrastive training significantly improves the regression performance, especially for minority samples. ConR incorporate unbiased supervision into the contrastive regression and significantly boost the performance on minority samples with no harm to the learning process for majority samples. As shown in Fig. 12, Moco and ConR provide more consistent performance compared to the baseline. In addition, Moco is consistently outperformed by ConR and empirically confirms ConR improves the self-supervised contrastive regularizer by incorporating supervision in an unbiased manner.\nTable 19: Results of contrastive learning analysis on AgeDB-DIR, IMDB-WIKI-DIR and NYUD2-DIR benchmarks. Results are reported for the whole test data (all) and three other shots: many, median, few. At the bottom of the table the improvements of ConR with respect to Moco are reported in green for each benchmark, shot and metric. In each column, the best result is in bold.\nBenchmark AgeDB-DIR IMDB-WIKI-DIR NYUD2-DIR Metric MAE\u2193 MAE\u2193 RMSE\u2193 Method Shot All Many Median Few All Many Median Few All Many Median Few VANILLA 7.35 6.56 8.23 12.37 8.06 7.23 15.12 26.33 1.477 0.591 0.952 2.123 + Moco V1 7.33 6.50 8.19 11.72 7.89 7.13 14.78 26.11 1.370 0.601 0.902 1.912 + Moco V2 7.47 6.21 8.75 12.75 8.12 6.99 15.02 26.01 1.404 0.632 0.978 2.207 + ConR 7.28 6.53 8.03 10.42 7.84 7.09 14.16 25.15 1.304 0.682 0.889 1.885 ConR vs. Moco 0.68% -0.46% 1.96% 11.10% 0.63% 0.56% 4.20% 3.68% 4.82% -1.63% 1.44% 4.41%\nVANILLA Moco ConR\n(a) AgeDB-DIR\nVANILLA Moco ConR\n(b) IMDB-WIKI-DIR\nR M SE\nVANILLA Moco ConR\n(c) NYUD2-DIR\nFigure 12: Comparison of the performance gain of regularizing VANILLA regression model with contrastive regularizers: Moco V1 and ConR on (a) AgeDB-DIR, (b) IMDB-WIKI-DIR anf (c) NYUD2-DIR benchmarks. It shows contrastive regularizer consistently lifts the performance of the baseline, particularly on minority samples."
        }
    ],
    "title": "CONR: CONTRASTIVE REGULARIZER",
    "year": 2023
}