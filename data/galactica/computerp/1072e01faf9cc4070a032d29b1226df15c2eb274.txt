Federated learning is an emerging privacy-preserving distributed machine learning that enables multiple parties to collaboratively learn a shared model while keeping each partyâ€™s data private. However, federated learning faces two main problems: semi-honest server privacy inference attacks and malicious client-side model theft. To address privacy inference attacks, parameter-based encrypted federated learning secure aggregation can be used. To address model theft, a watermark-based intellectual property protection scheme can verify model ownership. Although watermarkbased intellectual property protection schemes can help verify model ownership, they are not sufficient to address the issue of continuous model theft by uncaught malicious clients in federated learning. Existing IP protection schemes that have the ability to track traitors are also not compatible with federated learning security aggregation. Thus, in this paper, we propose Federated Client-side Intellectual Property Protection (FedCIP), which is compatible with federated learning security aggregation and has the ability to track traitors. To the best of our knowledge, this is the first IP protection scheme in federated learning that is compatible with secure aggregation and has tracking capabilities. 1 conclusions In this paper, we explore the challenges of protecting intellectual property rights in federated learning and review existing research on watermarking techniques from both the client and server sides. We identify the limitations of each approach and propose a new client-side watermarking approach called FedCIP that allows for traitor tracking while maintaining compatibility with federated learning security aggregation such as parameter encryption. We provide a detailed description of the design and implementation of FedCIP and evaluate its performance in terms of model accuracy and watermark detection accuracy using three different models and datasets. Our results demonstrate that FedCIP is effective in
protecting intellectual property in federated learning while also adding pressure on traitors to reduce the risk of IP theft.