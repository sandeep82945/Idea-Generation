{
    "abstractText": "Accelerating the bi-objective optimization of applications for performance and energy is crucial to achieving energy efficiency objectives and meeting quality-of-service requirements in modern high-performance computing platforms and cloud computing infrastructures. In this work, we highlight the crucial challenges to accelerate model-based methods proposed for the bi-objective optimization of data-parallel applications for performance and energy that employ workload distribution between the executing processors as the decision variable. The methods solve unconstrained bi-objective optimization problems and take input, the processors\u2019 performance and energy profiles in the form of discrete functions of workload size, and output Pareto-optimal solutions (workload distributions), minimizing the execution time and the total energy consumption of computations during the parallel execution of the application. One of the challenges is the fast computation of Pareto-optimal solutions. We then formulate the bi-objective optimization problem of data-parallel applications for performance and energy through workload distribution on a cluster of p identical hybrid nodes, each containing h heterogeneous processors. The state-of-the-art algorithm for solving the problem is sequential and takes exorbitant execution times to find Pareto-optimal solutions for even moderate numbers of processors. We propose two algorithms that address this shortcoming. The first algorithm is an exact sequential algorithm that is more efficient and amenable to parallelization and achieves a complexity reduction of O(m \u00d7 h) over the state-of-the-art sequential algorithm where m is the cardinality of the input discrete execution time and dynamic energy functions. The second algorithm is a parallel algorithm executed by q identical parallel processes that reduces the complexity of our proposed sequential algorithm by O(q) and therefore achieves a complexity reduction of O(m\u00d7h\u00d7q) over the state-of-the-art sequential algorithm. Finally, we experimentally analyze the practical efficacy of our proposed algorithms for two data-parallel applications, matrix multiplication and fast Fourier transform, on a heterogeneous hybrid node containing an Intel Haswell multicore CPU, an Nvidia k40c GPU, and an Nvidia P100 GPU and simulations of clusters of such hybrid nodes. The experiments demonstrate that our proposed algorithms provide tremendous speedups over state-of-the-art solutions. INDEX TERMS high-performance heterogeneous computing, energy-efficient computing, biobjective optimization, performance optimization, energy optimization, data-parallel applications, workload distribution",
    "authors": [
        {
            "affiliations": [],
            "name": "RAVI REDDY MANUMACHU"
        },
        {
            "affiliations": [],
            "name": "HAMIDREZA KHALEGHZADEH"
        }
    ],
    "id": "SP:e2cd709816ce1989989bda03a9420f1e0f57f7c4",
    "references": [
        {
            "authors": [
                "M. Mezmaz",
                "N. Melab",
                "Y. Kessaci",
                "Y. Lee",
                "E.-G. Talbi",
                "A. Zomaya",
                "D. Tuyttens"
            ],
            "title": "A parallel bi-objective hybrid metaheuristic for energy-aware scheduling for cloud computing systems",
            "venue": "Journal of Parallel and Distributed Computing, vol. 71, no. 11, pp. 1497\u20131508, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "J. Ko\u0142odziej",
                "S.U. Khan",
                "L. Wang",
                "A.Y. Zomaya"
            ],
            "title": "Energy efficient genetic-based schedulers in computational grids",
            "venue": "Concurrency and Computation: Practice and Experience, vol. 27, no. 4, pp. 809\u2013829, Mar. 2015.",
            "year": 2015
        },
        {
            "authors": [
                "R. Lucas"
            ],
            "title": "DOE advanced scientific computing advisory subcommittee (ASCAC) report: Top ten exascale research challenges",
            "venue": "2 2014. [Online]. Available: https: //www.osti.gov/biblio/1222713",
            "year": 2014
        },
        {
            "authors": [
                "F.D. Rossi",
                "M.G. Xavier",
                "C.A. De Rose",
                "R.N. Calheiros",
                "R. Buyya"
            ],
            "title": "E-eco: Performance-aware energy-efficient cloud data center orchestration",
            "venue": "Journal of Network and Computer Applications, vol. 78, pp. 83\u201396, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "Y. Kessaci",
                "N. Melab",
                "E.-G. Talbi"
            ],
            "title": "A pareto-based metaheuristic for scheduling HPC applications on a geographically distributed cloud federation",
            "venue": "Cluster Computing, vol. 16, no. 3, pp. 451\u2013468, Sep. 2013.",
            "year": 2013
        },
        {
            "authors": [
                "J.J. Durillo",
                "V. Nae",
                "R. Prodan"
            ],
            "title": "Multi-objective energyefficient workflow scheduling using list-based heuristics",
            "venue": "Future Generation Computer Systems, vol. 36, pp. 221\u2013236, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "L. Yu",
                "Z. Zhou",
                "S. Wallace",
                "M.E. Papka",
                "Z. Lan"
            ],
            "title": "Quantitative modeling of power performance tradeoffs on extreme scale systems",
            "venue": "Journal of Parallel and Distributed Computing, vol. 84, pp. 1\u201314, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "N. Gholkar",
                "F. Mueller",
                "B. Rountree"
            ],
            "title": "Power tuning HPC jobs on power-constrained systems",
            "venue": "Proceedings of the 2016 International Conference on Parallel Architectures and Compilation, ser. PACT \u201916. Association for Computing Machinery, 2016, p. 179\u2013191.",
            "year": 2016
        },
        {
            "authors": [
                "B. Rountree",
                "D.K. Lowenthal",
                "S. Funk",
                "V.W. Freeh",
                "B.R. de Supinski",
                "M. Schulz"
            ],
            "title": "Bounding energy consumption in large-scale MPI programs",
            "venue": "Proceedings of the 2007 ACM/IEEE Conference on Supercomputing, ser. SC \u201907. Association for Computing Machinery, 2007.",
            "year": 2007
        },
        {
            "authors": [
                "A. Lastovetsky",
                "L. Szustak",
                "R. Wyrzykowski"
            ],
            "title": "Modelbased optimization of EULAG kernel on Intel Xeon Phi through load imbalancing",
            "venue": "IEEE Transactions on Parallel and Distributed Systems, vol. 28, no. 3, pp. 787\u2013797, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "A. Lastovetsky",
                "R. Reddy"
            ],
            "title": "New model-based methods and algorithms for performance and energy optimization of data parallel applications on homogeneous multicore clusters",
            "venue": "IEEE Transactions on Parallel and Distributed Systems, vol. 28, no. 4, pp. 1119\u20131133, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "R. Reddy",
                "A. Lastovetsky"
            ],
            "title": "Bi-objective optimization of data-parallel applications on homogeneous multicore clusters for performance and energy",
            "venue": "IEEE Transactions on Computers, vol. 64, no. 2, pp. 160\u2013177, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "A. Chakrabarti",
                "S. Parthasarathy",
                "C. Stewart"
            ],
            "title": "A pareto framework for data analytics on heterogeneous systems: Implications for green energy usage and performance",
            "venue": "Parallel Processing (ICPP), 2017 46th International Conference on. IEEE, 2017, pp. 533\u2013542.",
            "year": 2017
        },
        {
            "authors": [
                "S. Khokhriakov",
                "R.R. Manumachu",
                "A. Lastovetsky"
            ],
            "title": "Multicore processor computing is not energy proportional: An opportunity for bi-objective optimization for energy and performance",
            "venue": "Applied Energy, vol. 268, p. 114957, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "H. Khaleghzadeh",
                "M. Fahad",
                "A. Shahid",
                "R.R. Manumachu",
                "A. Lastovetsky"
            ],
            "title": "Bi-objective optimization of data-parallel applications on heterogeneous HPC platforms for performance and energy through workload distribution",
            "venue": "IEEE Transactions on Parallel and Distributed Systems, vol. 32, no. 3, pp. 543\u2013560, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "R.R. Manumachu",
                "A.L. Lastovetsky"
            ],
            "title": "Parallel data partitioning algorithms for optimization of data-parallel applications on modern extreme-scale multicore platforms for performance and energy",
            "venue": "IEEE Access, vol. 6, pp. 69 075\u2013 69 106, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "M. Fahad",
                "A. Shahid",
                "R.R. Manumachu",
                "A. Lastovetsky"
            ],
            "title": "Accurate energy modelling of hybrid parallel applications on modern heterogeneous computing platforms using systemlevel measurements",
            "venue": "IEEE Access, vol. 8, pp. 93 793\u201393 829, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Z. Zhong",
                "V. Rychkov",
                "A. Lastovetsky"
            ],
            "title": "Data partitioning on multicore and multi-GPU platforms using functional performance models",
            "venue": "Computers, IEEE Transactions on, vol. 64, no. 9, pp. 2506\u20132518, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "M. Fahad",
                "A. Shahid",
                "R.R. Manumachu",
                "A. Lastovetsky"
            ],
            "title": "A comparative study of methods for measurement of energy of computing",
            "venue": "Energies, vol. 12, no. 11, p. 2204, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "A. Shahid",
                "M. Fahad",
                "R.R. Manumachu",
                "A.L. Lastovetsky"
            ],
            "title": "Energy predictive models of computing: Theory, practical implications and experimental analysis on multicore processors",
            "venue": "IEEE Access, vol. 9, pp. 63 149\u201363 172, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Shahid",
                "M. Fahad",
                "R.R. Manumachu",
                "A. Lastovetsky"
            ],
            "title": "Improving the accuracy of energy predictive models for multicore CPUs by combining utilization and performance events model variables",
            "venue": "Journal of Parallel and Distributed Computing, vol. 151, pp. 38\u201351, 05/2021 2021.",
            "year": 2021
        },
        {
            "authors": [
                "H. Khaleghzadeh",
                "Z. Zhong",
                "R. Reddy",
                "A. Lastovetsky"
            ],
            "title": "Out-of-core implementation for accelerator kernels on heterogeneous clouds",
            "venue": "The Journal of Supercomputing, vol. 74, no. 2, pp. 551\u2013568, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "V.W. Freeh",
                "D.K. Lowenthal",
                "F. Pan",
                "N. Kappiah",
                "R. Springer",
                "B.L. Rountree",
                "M.E. Femal"
            ],
            "title": "Analyzing the energy-time trade-off in high-performance computing applications",
            "venue": "IEEE Transactions on Parallel and Distributed Systems, vol. 18, no. 6, pp. 835\u2013848, 2007.",
            "year": 2007
        },
        {
            "authors": [
                "B. Rountree",
                "D.K. Lowenthal",
                "B.R. de Supinski",
                "M. Schulz",
                "V.W. Freeh",
                "T. Bletsch"
            ],
            "title": "Adagio: Making DVS practical for complex HPC applications",
            "venue": "Proceedings of the 23rd International Conference on Supercomputing, ser. ICS \u201909. Association for Computing Machinery, 2009, p. 460\u2013469.",
            "year": 2009
        },
        {
            "authors": [
                "Y.C. Lee",
                "A.Y. Zomaya"
            ],
            "title": "Energy conscious scheduling for distributed computing systems under different operating conditions",
            "venue": "IEEE Transactions on Parallel and Distributed Systems, vol. 22, no. 8, pp. 1374\u20131381, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "A. Beloglazov",
                "J. Abawajy",
                "R. Buyya"
            ],
            "title": "Energy-aware resource allocation heuristics for efficient management of data centers for cloud computing",
            "venue": "Future Generation Computer Systems, vol. 28, no. 5, pp. 755\u2013768, 2012, special Section: Energy efficiency in large-scale distributed systems.",
            "year": 2012
        },
        {
            "authors": [
                "J. Demmel",
                "A. Gearhart",
                "B. Lipshitz",
                "O. Schwartz"
            ],
            "title": "Perfect strong scaling using no additional energy",
            "venue": "2013 IEEE 27th International Symposium on Parallel and Distributed Processing, 2013, pp. 649\u2013660.",
            "year": 2013
        },
        {
            "authors": [
                "M. Drozdowski",
                "J.M. Marszalkowski",
                "J. Marszalkowski"
            ],
            "title": "Energy trade-offs analysis using equal-energy maps",
            "venue": "Future Generation Computer Systems, vol. 36, pp. 311\u2013321, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "J.M. Marsza\u0142kowski",
                "M. Drozdowski",
                "J. Marsza\u0142kowski"
            ],
            "title": "Time and energy performance of parallel systems with hierarchical memory",
            "venue": "Journal of Grid Computing, vol. 14, no. 1, pp. 153\u2013170, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "L.A. Barroso",
                "U. H\u00f6lzle"
            ],
            "title": "The case for energyproportional computing",
            "venue": "Computer, no. 12, pp. 33\u201337, 2007.",
            "year": 2007
        },
        {
            "authors": [
                "Y. Ogata",
                "T. Endo",
                "N. Maruyama",
                "S. Matsuoka"
            ],
            "title": "An efficient, model-based CPU-GPU heterogeneous FFT library",
            "venue": "Parallel and Distributed Processing, 2008. IPDPS 2008. IEEE International Symposium on. IEEE, 2008, pp. 1\u201310.",
            "year": 2008
        },
        {
            "authors": [
                "C. Yang",
                "F. Wang",
                "Y. Du",
                "J. Chen",
                "J. Liu",
                "H. Yi",
                "K. Lu"
            ],
            "title": "Adaptive optimization for petascale heterogeneous CPU/GPU computing",
            "venue": "Cluster Computing (CLUSTER), 2010 IEEE International Conference on. IEEE, 2010, pp. 19\u201328.",
            "year": 2010
        },
        {
            "authors": [
                "A. Lastovetsky",
                "R. Reddy"
            ],
            "title": "Data partitioning with a functional performance model of heterogeneous processors",
            "venue": "International Journal of High Performance Computing Applications, vol. 21, no. 1, pp. 76\u201390, 2007.",
            "year": 2007
        },
        {
            "authors": [
                "T. Gautier",
                "X. Besseron",
                "L. Pigeon"
            ],
            "title": "KAAPI: A thread scheduling runtime system for data flow computations on cluster of multi-processors",
            "venue": "ser. Proceedings of the 2007 International Workshop on Parallel Symbolic Computation. ACM, 2007, pp. 15\u201323.",
            "year": 2007
        },
        {
            "authors": [
                "C. Augonnet",
                "S. Thibault",
                "R. Namyst",
                "P.-A. Wacrenier"
            ],
            "title": "StarPU: A unified platform for task scheduling on heterogeneous multicore architectures",
            "venue": "Concurrency: Practice and Experience, vol. 23, no. 2, pp. 187\u2013198, Feb. 2011.",
            "year": 2011
        },
        {
            "authors": [
                "G. Bosilca",
                "A. Bouteiller",
                "A. Danalis",
                "T. Herault",
                "P. Lemarinier",
                "J. Dongarra"
            ],
            "title": "DAGuE: A generic distributed DAG engine for high performance computing",
            "venue": "ser. 2011 IEEE IPDPSW, May 2011, pp. 1151\u20131158.",
            "year": 2011
        },
        {
            "authors": [
                "M.D. Linderman",
                "J.D. Collins",
                "H. Wang",
                "T.H. Meng"
            ],
            "title": "Merge: a programming model for heterogeneous multi-core systems",
            "venue": "ser. ACM SIGOPS operating systems review, vol. 42, no. 2. ACM, 2008, pp. 287\u2013296.",
            "year": 2008
        },
        {
            "authors": [
                "G. Quintana-Ort\u00ed",
                "F.D. Igual",
                "E.S. Quintana-Ort\u00ed",
                "R.A. van de Geijn"
            ],
            "title": "Solving dense linear systems on platforms with multiple hardware accelerators",
            "venue": "SIGPLAN Notices, vol. 44, no. 4, pp. 121\u2013130, Feb. 2009.",
            "year": 2009
        },
        {
            "authors": [
                "C. Augonnet",
                "S. Thibault",
                "R. Namyst"
            ],
            "title": "Automatic Calibration of Performance Models on Heterogeneous Multicore Architectures",
            "venue": "ser. 3rd Workshop on Highly Parallel Processing on a Chip (HPPC 2009), Aug. 2009.",
            "year": 2009
        },
        {
            "authors": [
                "K. Schloegel",
                "G. Karypis",
                "V. Kumar"
            ],
            "title": "A unified algorithm for load-balancing adaptive scientific simulations",
            "venue": "ser. Supercomputing, ACM/IEEE 2000 Conference, Nov 2000, pp. 59\u201359.",
            "year": 2000
        },
        {
            "authors": [
                "U.V. Catalyurek",
                "E.G. Boman",
                "K.D. Devine",
                "D. Bozdag",
                "R. Heaphy",
                "L.A. Riesen"
            ],
            "title": "Hypergraph-based dynamic load balancing for adaptive scientific computations",
            "venue": "ser. IEEE International Parallel and Distributed Processing Symposium (IPDPS). IEEE, 2007, pp. 1\u201311.",
            "year": 2007
        },
        {
            "authors": [
                "D. Clarke",
                "A. Lastovetsky",
                "V. Rychkov"
            ],
            "title": "Dynamic load balancing of parallel computational iterative routines on highly heterogeneous HPC platforms",
            "venue": "Parallel Processing Letters, vol. 21, pp. 195\u2013217, 06/2011 2011.",
            "year": 2011
        },
        {
            "authors": [
                "R. Reddy Manumachu",
                "A.L. Lastovetsky"
            ],
            "title": "Design of self-adaptable data parallel applications on multicore clusters automatically optimized for performance and energy through load distribution",
            "venue": "Concurrency and Computation: Practice and Experience, vol. 31, no. 4, p. e4958, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "K.-H. Kim",
                "K. Kim",
                "Q.-H. Park"
            ],
            "title": "Performance analysis and optimization of three-dimensional FDTD on GPU using roofline model",
            "venue": "Computer Physics Communications, vol. 182, no. 6, pp. 1201\u20131207, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "J. Shen",
                "A.L. Varbanescu",
                "Y. Lu",
                "P. Zou",
                "H. Sips"
            ],
            "title": "Workload partitioning for accelerating applications on heterogeneous platforms",
            "venue": "IEEE Transactions on Parallel and Distributed Systems, vol. 27, no. 9, pp. 2766\u20132780, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "A. Kalinov",
                "A. Lastovetsky"
            ],
            "title": "Heterogeneous distribution of computations solving linear algebra problems on networks of heterogeneous computers",
            "venue": "Journal of Parallel and Distributed Computing, vol. 61, no. 4, pp. 520 \u2013 535, 2001.",
            "year": 2001
        },
        {
            "authors": [
                "O. Beaumont",
                "V. Boudet",
                "F. Rastello",
                "Y. Robert"
            ],
            "title": "Matrix multiplication on heterogeneous platforms",
            "venue": "IEEE Trans. Parallel Distrib. Syst., vol. 12, no. 10, Oct. 2001.",
            "year": 2001
        },
        {
            "authors": [
                "A. Lastovetsky",
                "R. Reddy"
            ],
            "title": "Data partitioning for multiprocessors with memory heterogeneity and memory constraints",
            "venue": "Scientific Programming, vol. 13, no. 2, pp. 93\u2013112, 2005.",
            "year": 2005
        },
        {
            "authors": [
                "T. Heath",
                "B. Diniz",
                "B. Horizonte",
                "E.V. Carrera",
                "R. Bianchini"
            ],
            "title": "Energy conservation in heterogeneous server clusters",
            "venue": "10th ACM SIGPLAN symposium on Principles and practice of parallel programming (PPoPP). ACM, 2005, pp. 186\u2013195.",
            "year": 2005
        },
        {
            "authors": [
                "D. Economou",
                "S. Rivoire",
                "C. Kozyrakis",
                "P. Ranganathan"
            ],
            "title": "Full-system power analysis and modeling for server environments",
            "venue": "In Proceedings of Workshop on Modeling, Benchmarking, and Simulation, 2006, pp. 70\u201377.",
            "year": 2006
        },
        {
            "authors": [
                "X. Fan",
                "W.-D. Weber",
                "L.A. Barroso"
            ],
            "title": "Power provisioning for a warehouse-sized computer",
            "venue": "34th Annual International Symposium on Computer architecture. ACM, 2007, pp. 13\u201323.",
            "year": 2007
        },
        {
            "authors": [
                "R. Bertran",
                "M. Gonzalez",
                "X. Martorell",
                "N. Navarro",
                "E. Ayguade"
            ],
            "title": "Decomposable and responsive power models for multicore processors using performance counters",
            "venue": "Proceedings of the 24th ACM International Conference on Supercomputing. ACM, 2010, pp. 147\u2013158.",
            "year": 2010
        },
        {
            "authors": [
                "R. Basmadjian",
                "N. Ali",
                "F. Niedermeier",
                "H. de Meer",
                "G. Giuliani"
            ],
            "title": "A methodology to predict the power consumption of servers in data centres",
            "venue": "2nd International Conference on Energy-Efficient Computing and Networking. ACM, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "S. Hong",
                "H. Kim"
            ],
            "title": "An integrated GPU power and performance model",
            "venue": "p. 280\u2013289, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "C. Isci",
                "M. Martonosi"
            ],
            "title": "Runtime power monitoring in high-end processors: Methodology and empirical data",
            "venue": "36th annual IEEE/ACM International Symposium on Microarchitecture. IEEE Computer Society, 2003, p. 93.",
            "year": 2003
        },
        {
            "authors": [
                "H. Nagasaka",
                "N. Maruyama",
                "A. Nukada",
                "T. Endo",
                "S. Matsuoka"
            ],
            "title": "Statistical power modeling of GPU kernels using performance counters",
            "venue": "International Green Computing Conference and Workshops (IGCC). IEEE, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "S. Song",
                "C. Su",
                "B. Rountree",
                "K.W. Cameron"
            ],
            "title": "A simplified and accurate model of power-performance efficiency on emergent GPU architectures",
            "venue": "27th IEEE International Parallel and Distributed Processing Symposium (IPDPS). IEEE Computer Society, 2013, pp. 673\u2013686.",
            "year": 2013
        },
        {
            "authors": [
                "Y.S. Shao",
                "D. Brooks"
            ],
            "title": "Energy characterization and instruction-level energy model of Intel\u2019s Xeon Phi processor",
            "venue": "Proceedings of the 2013 International Symposium on Low Power Electronics and Design, ser. ISLPED \u201913. IEEE Press, 2013.",
            "year": 2013
        }
    ],
    "sections": [
        {
            "text": "INDEX TERMS high-performance heterogeneous computing, energy-efficient computing, biobjective optimization, performance optimization, energy optimization, data-parallel applications, workload distribution\nI. INTRODUCTION\nPerformance and energy are the two most important objectives for optimization in modern high per-\nformance computing (HPC) platforms, computational grids, data centers, and cloud computing infrastructures ([1],[2],[3],[4]). Achieving the energy efficiency objectives\nVOLUME 10, 2022 1\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nand meeting the performance or response time qualityof-service (QoS) requirements is crucial to the commercial viability of data centers and cloud computing infrastructures. Therefore, fast solution methods for systemlevel and application-level bi-objective optimization for performance and energy are vital to addressing energy efficiency, environmental and commercial concerns in these computing settings.\nWe start with a brief review of system-level and application-level solution methods for bi-objective optimization on HPC platforms for performance and energy. Then, we present the state-of-the-art application-level solution methods for bi-objective optimization of dataparallel applications on modern HPC platforms for performance and energy, employing workload distribution as a decision variable. Finally, we summarize the challenges specific to the acceleration of the state-of-the-art application-level solution methods before presenting our solution addressing the challenges.\nSystem-level solution methods aim to optimize the performance and energy of the environment executing the applications [2],[5],[6],[7],[8],[9]. The methods employ application-agnostic models and hardware parameters as decision variables. Dynamic voltage and frequency scaling (DVFS) is a dominant decision variable in this category. The application-level solution methods [10],[11],[12],[13],[14],[15] utilize application-level decision variables and models. The decision variables include the number of threads, number of processors, loop tile size, and workload distribution.\nWe will now review the state-of-the-art applicationlevel solution methods for bi-objective optimization of data-parallel applications on modern HPC platforms for performance and energy, employing workload distribution as a decision variable. First, briefly, some terminology on energy consumption. The total energy consumption during an application execution is the sum of dynamic and static energy consumption. We define static energy consumption as the energy consumed by the platform without the application execution. Dynamic energy consumption is calculated by subtracting this static energy consumption from the total energy consumed by the platform during the application execution.\nLastovetsky and Reddy [11] propose data partitioning algorithms that solve single-objective optimization problems of data-parallel applications for performance or dynamic energy on homogeneous clusters of multicore CPUs. The algorithms take as input application-specific performance and dynamic energy profiles of the multicore CPU processor. The profiles are discrete functions of workload size with no shape assumptions that accurately and realistically account for resource contention and non-uniform memory access (NUMA) inherent in modern multicore CPU platforms. The algorithms output performance-optimal and energy-optimal workload\ndistributions. Furthermore, Reddy and Lastovetsky [12] propose an exact global optimization algorithm to solve the bi-objective optimization problem of data-parallel applications for performance and energy on homogeneous clusters of multicore CPUs. The algorithm takes discrete performance and dynamic energy functions against workload size as input and outputs the globally Pareto-optimal set of solutions.\nThe algorithms ([11], [12]) target homogeneous HPC platforms and exhibit time complexity of O(m2 \u00d7 p2) where m is the cardinality of the discrete sets representing the speed and energy functions, and p is the number of available processors. However, the algorithms are sequential and exhibit impractical runtime and memory costs for large values of p (several hundred). To address this problem, Reddy et al. [16] propose parallel versions of the sequential data partitioning algorithms presented in [11] that achieve a complexity reduction of O(p). However, the parallel algorithms return only the performance-optimal and energy-optimal workload distributions.\nKhaleghzadeh et al. [15] study the bi-objective optimization problem of data-parallel applications for performance and energy on heterogeneous processors. They propose a solution method (HEPOPTA) comprising an efficient and exact global optimization algorithm. The algorithm takes input performance and dynamic energy profiles of the processors as arbitrary discrete functions of workload size and returns the Pareto-optimal solutions (generally, load imbalanced). Furthermore, HEPOPTA employs a methodology [17] that accurately models the energy consumption by a hybrid data-parallel application executing on a heterogeneous HPC platform containing different computing devices using systemlevel power measurements provided by power meters, which is considered the ground-truth.\nWe now summarize the main steps in the applicationlevel method ([15]) to solve the bi-objective optimization problem of data-parallel applications for performance and energy on heterogeneous hybrid platforms.\nThe first step involves modelling a data-parallel application executing on a heterogeneous hybrid platform. Such a hybrid application consists of several kernels (generally speaking, multithreaded) running in parallel on different computing devices of the platform. Due to the inherent tight integration and severe resource contention, the load of one computational kernel in the application may significantly impact others\u2019 performance to the extent of preventing the ability to model the performance and energy consumption of each kernel in hybrid applications individually [18]. Therefore, configurations of the hybrid application with no more than one CPU kernel or accelerator kernel running on the corresponding device are only considered. Each group of cores executing an individual kernel of the application is modelled as an abstract processor to represent the"
        },
        {
            "heading": "2 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nexecuting platform as a set of heterogeneous abstract processors. Such a grouping ensures that the sharing of system resources is maximized within groups of computational cores representing the abstract processors and minimized between the groups. This way, the contention and mutual dependence between abstract processors are minimized.\nTherefore, a hybrid data-parallel application is represented by a set of computational kernels executing on groups of cores, which we term heterogeneous abstract processors. To give an example, consider the hybrid node employed in our experiments in this work and whose specification is shown in Table 1. It consists of a dualsocket Intel Haswell multicore CPU involving 24 physical cores with 64 GB main memory, which hosts two accelerators, an Nvidia K40c GPU and an Nvidia P100 GPU. So, we model a data-parallel application executing on this node by three heterogeneous abstract processors, CPU_1, GPU_1, and GPU_2. CPU_1 comprises 22 (out of a total of 24) CPU cores. GPU_1 symbolizes the Nvidia K40c GPU and a host CPU core connected to this GPU via a dedicated PCI-E link. The Nvidia P100 PCI-E GPU and a host CPU core connected to this GPU via a dedicated PCI-E link are denoted by GPU_2.\nSecond, the computational kernels\u2019 performance and dynamic energy profiles are built offline using a methodology based on processor clocks and systemlevel power measurements provided by external power meters (ground-truth method). In this work, when we say the performance and dynamic energy profiles of the heterogeneous processors, we mean the profiles of the three computational kernels executing on the three heterogeneous abstract processors.\nFinally, given the performance and dynamic energy profiles, a data-partitioning algorithm solves the biobjective optimization problem to determine the Pareto-\noptimal solutions (workload distributions), minimizing the execution time and the total energy consumption of computations during the parallel execution of the application. We term the bi-objective optimization problem HEPOPT that we formulate in the following section.\nHowever, there are two issues with the applicationlevel solution method [15]. First, the data-partitioning algorithm is sequential and takes exorbitant execution times for even moderate values of p. For example, consider its execution times for HEPOPTA [15] solving the bi-objective optimization problem for two scientific dataparallel applications, matrix multiplication (DGEMM) and 2D fast Fourier transform (2D-FFT), executed on a platform comprising two connected heterogeneous multiaccelerator NUMA nodes. For the DGEMM application, the data-partitioning algorithm\u2019s execution time ranges from 4 seconds to 6 hours for values of p varying from 12 to 192. For the 2D-FFT application, the execution time increases from 16 seconds to 16 hours for values of p, going from 12 to 192.\nSecond, the procedure to construct the performance and dynamic energy profiles employing system-level power measurements provided by external power meters (ground-truth method) is also sequential and expensive. The execution times of constructing the discrete performance and dynamic energy profiles comprising 210 and 256 workload sizes for the two applications, DGEMM and 2D-FFT, are 8 hours and 14 hours, respectively. Finally, the dynamic energy profiles are constructed offline using the ground-truth method. Briefly, while the ground-truth method exhibits the highest accuracy, it is also the most expensive [17]. In addition, it cannot be employed in dynamic environments (HPC platforms and data centers) containing nodes that are not equipped with power meters.\nTherefore, there are two crucial challenges to accelerating the bi-objective optimization of data-parallel applications for performance and energy on modern heterogeneous HPC platforms: (a) Fast computation of Pareto-optimal solutions optimizing the application for performance and energy, and (b) Fast construction of performance and dynamic energy profiles that are discrete functions of workload size by employing an energy measurement method that caters to environments where nodes are not equipped with power meters.\nIn this work, we propose algorithms that address the first challenge, the fast computation of Pareto-optimal solutions optimizing the application for performance and energy. The second challenge is an open problem. Therefore, we present just an overview of the issues involved.\nTo construct the performance and dynamic energy profiles of the heterogeneous processors (components), we need accurate and reliable methods for componentlevel measurement of the execution time and energy. Since all processing units are equipped with sufficiently\nVOLUME 10, 2022 3\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nprecise clocks, obtaining accurate performance profiles is achievable (even in the case of tightly coupled components). However, methods for component-level measurement of energy consumption present a real challenge.\nThere are three component-level energy measurement approaches. The first approach employs system-level physical measurements using external power meters, which is the most accurate but very expensive. In our experience, obtaining a single experimental point with sufficient statistical confidence can take hours and even days. Nevertheless, the measurements obtained this way are considered ground truth [19]. The second approach is to use on-chip power sensors such as Intel RAPL (Running Average Power Limit), Intel Xeon Phi SMC (System Management Controller), AMD APM (Application Power Management), Nvidia NVML (Nvidia Management Library). While cheap and very efficient, on-chip power sensors have been found very inaccurate and poorly documented [19]. Furthermore, extensive experiments with highly optimized scientific kernels on several mainstream CPUs and accelerators have shown that energy profiles constructed using state-of-the-art on-chip power sensors are qualitatively inaccurate [19].\nThe third approach uses software energy predictive models employing various measurable runtime performance-related predictor variables. This approach is the only realistic alternative to the ground-truth method. There has been good progress in energy modelling for multicore CPUs built on selection of model variables that satisfy basic laws of energy conservation [20]. For example, best models employing performance monitoring counters (PMCs) and utilization variables have 10-20% accuracy on popular scientific kernels [21]. However, accelerators are poorly instrumented for runtime energy modelling. As a result, runtime modeling of energy consumption by components running on accelerators is underdeveloped.\nWe first formulate the bi-objective optimization problem (HEPOPT) of data-parallel applications for performance and energy through workload distribution on a cluster of p identical hybrid nodes, each containing h heterogeneous processors. The inputs to HEPOPT are the workload size, n; the number of identical nodes, p; the number of heterogeneous processors in each node, h; the sets T and E containing the discrete functions of execution time and dynamic energy against the workload size for the h heterogeneous processors; the static power consumption of a node, Ps. Finally, the output is the Pareto-optimal solutions for performance and total energy.\nThe problem formulation has some additional contraints. The workload size is assumed to be a multiple of a basic computation unit that does not differ during the application execution. For example, a basic computation unit in matrix multiplication is a matrix update, a + b\u00d7 c, where a, b, and c are u\u00d7 u matrices\nof fixed size u. Therefore, the workload sizes are given in multiples of 2\u00d7u3, which is the number of arithmetic operations in the basic computation unit. The discrete sets representing the execution time and dynamic energy functions have cardinality m. The set of workload sizes in the functions is {1, \u00b7 \u00b7 \u00b7 ,m}. Therefore, the workload size n has an upper bound, p\u00d7m\u00d7 h.\nThe state-of-the-art sequential algorithm, HEPOPTA [15], solves HEPOPT with time complexity of O(m3 \u00d7 p3\u00d7h3\u00d7log2(m\u00d7p\u00d7h)) where m is the maximum cardinality of the discrete sets representing the performance and energy profiles of the h heterogeneous processors. Note, however, that HEPOPTA can handle input discrete sets of different cardinalities, and arbitrary sizes can separate the workload sizes in the sets. Furthermore, the workload sizes can be positive reals.\nWe propose a two-level hierarchical sequential algorithm called HEPOPTADP that is more efficient and amenable to parallelization. It uses the dynamic programming technique and employs HEPOPTA as the fundamental building block at the second level. The inputs to HEPOPTADP are the workload size, n; the number of identical nodes, p; the number of heterogeneous processors in each node, h; the sets T and E containing the discrete execution time and dynamic energy functions of the h heterogeneous processors; the static power consumption of a node, Ps. HEPOPTADP returns the Pareto-optimal solutions for performance and total energy. Each solution, generally not load balanced, is a workload distribution between the p\u00d7h processors where the workloads in the distribution can be different.\nThe time complexity of HEPOPTADP is O(n\u00d7 p2 \u00d7 m \u00d7 h \u00d7 log2(p \u00d7 m \u00d7 h)). Therefore, it achieves a complexity reduction of O(m\n2\u00d7h2\u00d7p n ) over HEPOPTA.\nTherefore, the speedup is constant for a constant amount of work per processor, np\u00d7h , keeping the other application input parameters (execution time and dynamic energy functions) the same. The reduction is due to the hierarchical design and memoization employed in dynamic programming technique. Since the workload size n has an upper bound, p \u00d7 m \u00d7 h, the lower bound on the complexity reduction will be O(m\u00d7 h).\nWe then propose a parallel version of HEPOPTADP called PARHEPOPTA executed by q identical parallel processes and time complexity O(n \u00d7 p 2\nq \u00d7 m \u00d7 h \u00d7 log2(p \u00d7 m \u00d7 h)). Therefore, it reduces the time complexity of HEPOPTADP by O(q) and HEPOPTA by O(m\n2\u00d7h2\u00d7p\u00d7q n )). Since n \u2264 p\u00d7m\u00d7h, the lower bound on the complexity reduction will be O(q\u00d7m\u00d7h). Therefore, the speedup increases with q for a constant np\u00d7h keeping the other application input parameters the same.\nWe developed two implementations of PARHEPOPTA. The first implementation employs q MPI processes. The second implementation uses hybrid parallelism and is executed by q MPI processes, each em-"
        },
        {
            "heading": "4 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nploying t threads. Experimentally, we find that the first implementation performs better. Therefore, we describe this implementation here. The implementation using hybrid parallelism is given in the supplemental.\nWe study the practical efficacy of HEPOPTADP and PARHEPOPTA for two data-parallel applications, matrix multiplication (DGEMM) and fast Fourier transform (2D-FFT), using the hybrid node (Table 1). The DGEMM application computes the matrix product of two square matrices of size N \u00d7 N. The 2D-FFT application computes the 2D discrete Fourier Transform of a complex signal matrix of size N\u00d7N.\nFirst, we present the speedups of PARHEPOPTA and HEPOPTADP over HEPOPTA. All three algorithms are executed on the hybrid node employing only the Intel multicore CPU since we do not have their GPU implementations. HEPOPTADP and HEPOPTA are serial algorithms and executed by one process. PARHEPOPTA is executed by q processes. Experimentally, the best value of q on the experimental compute node is 24, which is equal to the total number of CPU cores.\nOur experiments show that the proposed algorithms PARHEPOPTA and HEPOPTADP exhibit good speedups over HEPOPTA. For example, for DGEMM application with configuration (N = 70656, p = 256,h = 3,m = 211), the speedup of HEPOPTADP over HEPOPTA is 4.6, and the speedup of PARHEPOPTA over HEPOPTADP is 6.57. For 2D-FFT application with (N = 96000, p = 256, h = 3,m = 256), the speedups are 2.12 and 10, respectively. Thus, the total speedups of PARHEPOPTA over HEPOPTA are 30.25 and 21.05 for DGEMM and 2D-FFT, respectively.\nSecond, we provide examples of usage of PARHEPOPTA. Finally, we present scenarios where PARHEPOPTA can accelerate the development of energy-efficient parallel applications and long-running simulations like numerical weather prediction due to its tremendous speedups.\nIn summary, the main original contributions of this work are:\n\u2022 The formulation of the bi-objective optimization problem (HEPOPT) of data-parallel applications for performance and energy on a cluster of p identical hybrid nodes, each containing h heterogeneous processors; \u2022 A model-based dynamic programming data partitioning algorithm, HEPOPTADP, solving HEPOPT that is more efficient and more amenable to parallelization than the state-of-the-art algorithm. HEPOPTADP takes input discrete execution time and dynamic energy functions of cardinality m with any arbitrary shape and returns the Pareto front of load imbalanced solutions and best load balanced solutions. It achieves a complexity reduction over the state-of-the-art sequential algorithm that has the lower bound of O(m\u00d7 h);\n\u2022 A parallel version of HEPOPTADP executed by q identical parallel processes called PARHEPOPTA solving HEPOPT. It reduces the time complexity of HEPOPTADP by O(q). It achieves a complexity reduction over the state-of-the-art sequential algorithm that has the lower bound of O(m\u00d7 h\u00d7 q); \u2022 Two novel algorithms, which HEPOPTADP and PARHEPOPTA invoke. The first algorithm, PoP, combines k input Pareto fronts, each containing n points with a complexity of O(k \u00d7 n). The second algorithm, ConPar, determines the dominating Pareto front given k input Pareto fronts, each containing n points with a complexity of O(k\u00d7 n\u00d7 log2(k\u00d7 n)); \u2022 Experiments on a heteregeneous hybrid node and simulations of clusters of such hybrid nodes demonstrating that our proposed algorithms exhibit good speedups over the state-of-the-art solutions.\nThe rest of the paper is organized as follows. Section II contains the formulation of the bi-objective optimization problem for performance and energy on heterogeneous hybrid platforms. Our proposed sequential and parallel algorithms, HEPOPTADP and PARHEPOPTA, are described in Sections III and IV. Section V contains the experimental results. Section VI presents the related work. Finally, we conclude the paper in Section VII."
        },
        {
            "heading": "II. BI-OBJECTIVE OPTIMIZATION PROBLEM ON HYBRID NODES FOR PERFORMANCE AND TOTAL ENERGY: PROBLEM FORMULATION",
            "text": "This section formulates HEPOPT, the bi-objective optimization problem for data-parallel applications for performance and total energy on a heterogeneous platform of p identical hybrid nodes, each containing h heterogeneous processors. The problem employs workload distribution as the decision variable.\nConsider a workload size n executed using p identical nodes each containing h heterogeneous processors. Let the sets, T = {t1(x), . . . , th(x)} and E = {e1(x), . . . , eh(x)}, contain the discrete execution time and dynamic energy functions of the h heterogeneous processors. The function ei(x) represents the amount of dynamic energy consumed by Pi to execute the workload size x, and ti(x) is the execution time of the workload size on this processor.\nThe workload size n is assumed to be a multiple of a basic computation unit that does not differ during the application execution. The discrete sets representing the execution time and dynamic energy functions are assumed to have cardinality m. The set of workload sizes in the functions is {1, \u00b7 \u00b7 \u00b7 ,m}. Therefore, the maximum workload size n that can be solved is p\u00d7m\u00d7 h.\nHEPOPT is then formulated as follows:\nVOLUME 10, 2022 5\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nHEPOPT(n, p, h,T,E,Ps,D):\nfT(D) = p\nmax i=1 h max j=1 tj(dij)\nfE(D) = p\u2211\ni=1\n(Ps \u00d7 h\nmax j=1\ntj(dij) + h\u2211\nj=1\nej(dij))\nminimize D (fT(D), fE(D))\nsubject to: p\u2211\ni=1 h\u2211 j=1 dij = n,\n0 \u2264 dij \u2264 m, i \u2208 {1, \u00b7 \u00b7 \u00b7 ,p}, j \u2208 {1, \u00b7 \u00b7 \u00b7 , h}\n(1)\nThe two objective functions are fT(D) and fE(D). The objective function fT(D) gives the parallel execution time of the workload employing the workload distribution, D = [dij]p\u00d7h, i = 1, 2, . . . ,p, j = 1, 2, . . . ,h. The objective function fE(D) gives the total energy consumption during the execution of the workload. We use T\u00d7 E : Rk\u22650 \u00d7 Rk\u22650 to denote the objective space of this problem.\nHEPOPT returns Pareto-optimal solutions (workload distributions) minimizing the two objective functions. Our solution finds a set of triplets, P = {(fT(D), fE(D),D)}, such that D is a Pareto-optimal decision vector and the projection of P onto the objective space is the Pareto front.\nThe state-of-the-art sequential algorithm, HEPOPTA [15], solves HEPOPT with time complexity of O(m3 \u00d7 p3\u00d7h3\u00d7 log2(m\u00d7p\u00d7h)). We first propose an algorithm HEPOPTADP employing the dynamic programming approach to solve HEPOPT and that is more efficient and more amenable to parallelization. Then, we describe our parallel algorithm, PARHEPOPTA, based on HEPOPTADP.\nIII. HEPOPTADP: DYNAMIC PROGRAMMING BI-OBJECTIVE OPTIMIZATION ALGORITHM We propose an algorithm HEPOPTADP employing the dynamic programming approach to solve HEPOPT and that is more amenable to parallelization. HEPOPTADP is a two-level hierarchical algorithm employing HEPOPTA as the fundamental building block at the second level.\nThe state-of-the-art sequential algorithm, HEPOPTA [15], solves HEPOPT with time complexity of O(m3 \u00d7 p3 \u00d7 h3 \u00d7 log2(m \u00d7 p \u00d7 h)). HEPOPTA considers the cluster of p identical nodes, each containing h processors, as a 1D array of p \u00d7 h heterogeneous processors. HEPOPTA is a branch-and-bound algorithm that organizes workload distributions, (x1, \u00b7 \u00b7 \u00b7 , xp\u00d7h), efficiently as a tree while considering only distributions that sum to n to determine the Pareto front.\nFor example, let us consider HEPOPTA solving a workload size n = 8 on p = 2 identical nodes containing h = 2 processors each. The other inputs are two discrete\nexecution time and dynamic energy functions of the heterogeneous abstract processors. Let us assume the set of workload sizes in the functions is {1, \u00b7 \u00b7 \u00b7 , 4}. First, HEPOPTA converts the platform configuration (p,h) into a 1D array of 4 heterogeneous processors (P0,P1,P2,P3) with four corresponding discrete execution time and dynamic energy discrete functions. Then it organizes the workload distributions between the four processors as a tree containing four levels. The first level contains allocations to processor P0, the second level with allocations to processors P0 and P1, and the last level contains the workload distribution for all four processors. Therefore, the first level contains five branches with workload size allocations {0, 1, 2, 3, 4} to P0. The first branch is then extended to five other branches with workload size allocations {0, 0}, {0, 1}, {0, 2}, {0, 3}, {0, 4}} to P0 and P1 and so on. Then, it applies constraints to traverse only branches where the processor allocations sum to 8 and other optimizations to determine the Pareto front. HEPOPTA is detailed in the supplemental, Section 3.\nThe inputs to HEPOPTADP are the workload size, n; the number of identical nodes, p; the number of heterogeneous processors in each node, h; the sets T and E containing the discrete execution time and dynamic energy functions; the static power consumption of a node, Ps.\nThe output of HEPOPTADP is a Pareto front represented by a set of tuples, P = {(fE(D), fT(D),D)i}, i \u2208 [1 . . K], where D = [dij]p\u00d7h, i = 1, 2, . . . ,p, j = 1, 2, . . . ,h is the optimal workload distribution, fE(D) is the total energy, and fT(D) is the execution time corresponding to the optimal workload distribution. The solutions in the set P are output in an increasing order of total energy.\nHEPOPTADP has three core components: a). Recurrence relation, b). Tabular computation, and c). Traceback. HEPOPTADP uses the recurrence relations to compute the cells in the dynamic programming table, dpt, of size n \u00d7 p, as shown in the Figure 1(a). The parameter h is not shown in the figure since it is employed in the HEPOPTA invocations to obtain the Pareto fronts for the red and orange cells.\nHEPOPTADP divides the partitioning of workload size r between c processors into the following subproblems:\n\u2022 Allocating i to one processor and the remaining r\u2212i to c\u2212 1 processors. \u2022 Allocating r to i processors, i = 1, . . . , c \u2212 1. Since dpt(r, c\u2212 1) is composed from the solutions to subproblems, dpt(r, 1), . . . ,dpt(r, c \u2212 2), the only subprogram required to be solved is allocating r to c\u22121 processors."
        },
        {
            "heading": "6 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nVOLUME 10, 2022 7\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nThe recurrence relations are given below:\ndpt(1, c) = HEPOPTA(1, h,T,E,Ps), c = 1, . . . ,p dpt(r, 1) = HEPOPTA(r, h,T,E,Ps), r = 2, . . . ,min(n,m \u2217 h) dpt(r, 1) = \u03a6, r = min(n,m \u2217 h) + 1, . . . ,n dpt(r, c) = ConPar(\nPoP(dpt(1, 1), dpt(r\u2212 1, c\u2212 1)), . . . , PoP(dpt(rmax, 1), dpt(r\u2212 rmax, c\u2212 1)), dpt(r, c\u2212 1)\n),\nrmax = min(r\u2212 1,m\u00d7 h), r = 2, . . . ,n, c = 2, . . . ,p\nThe row and column dimensions are given by r and c. The cell, dpt(r, c), r = 1, 2, . . . ,n, c = 1, 2, . . . ,p, contains the Pareto front to solve the workload size r using c nodes. We denote the Pareto front by Prc. At the end of the execution of HEPOPTADP, the cell dpt(n,p) contains the Pareto front to solve the workload size n using the p identical nodes.\nThe top three recurrence relations (base conditions) represent the base initialization step, which computes the red cells in the first row and orange cells in the first column as shown in Figure 1(b). The cell, dpt(1, c), c = 1, . . . ,p, contains the Pareto front to solve the workload size one using c nodes. The workload distribution is trivial in this case, one node gets the workload, and the rest get zero. Since each node contains h heterogeneous processors, HEPOPTADP invokes HEPOPTA to determine the Pareto front, P1c, to solve the workload using the heterogeneous processors. The cell, dpt(r, 1), r = 1, . . . ,m \u2217 h, contains the Pareto front Pr1 to solve the workload size r using one node. HEPOPTADP invokes HEPOPTA to determine the Pareto front solving the workload using h heterogeneous processors. The cell, dpt(r, 1), r = m \u2217 h + 1, . . . ,n, will contain a null Pareto front since m\u2217h is the maximum workload size that can be solved using h heterogeneous processors.\nThe fourth recurrence relation represents the computation of the cells in an anti-diagonal, L = 3, . . . ,n+p\u22121. The size of an anti-diagonal L gives the number of cells in it. All the cells in an anti-diagonal are computed sequentially. The anti-diagonals L are visited serially in the order, 3, . . . ,n + p \u2212 1. The Pareto front for a table cell in an anti-diagonal L depends only on the Pareto fronts in the cells in the anti-diagonals preceding L as shown in Figure 1(c). Consider the anti-diagonal, L=5. It has five cells, {(5,1),(4,2),(3,3),(2,4),(1,5)}. The Pareto fronts for the cells, {(5,1),(1,5)}, are computed in the base initialization step. The values for the blue cells depend only on the Pareto fronts in the green cells in the anti-diagonals preceding L=5. For the cell (4,2), the possible workload distributions for the workload size 4 are {(1, 1), (3, 1), (0, p \u2212 2)}, {(2, 1), (2, 1), (0, p \u2212\n2)}, {(4, 1), (0, p \u2212 1)}. The first workload distribution allocates workload size one to one node, three to one node, and zero to the rest. The second workload distribution allocates workload size two to one node, two to one node, and zero to the rest. Finally, the last workload distribution allocates workload size four to one node, and zero to the rest. The computation of the Pareto front for the cell (4,2) will involve two invocations of the Pareto front combination routine, PoP. First, two Pareto fronts, P11 and P31, are combined using PoP to get a temporary Pareto front, Ptmp1. Then, two Pareto fronts, P21 and P21, are combined using PoP to get a temporary Pareto front, Ptmp2. The routine ConPar builds the optimal Pareto front, P42, for the cell (4,2), from the three input Pareto fronts, {Ptmp1, Ptmp2, P41}.\nThe routine PoP combining two or more Pareto fronts is described in the supplemental. The Figure 1(d) illustrates how PoP combines two Pareto fronts to compute the Pareto front for the cell, (7, 5). For the anti-diagonal L=6, there are six cells, {(6,1),(5,2),(4,3),(3,4),(2,5),(1,6)}. The cells {(6,1),(1,6)} are computed in the base initialization step. The Pareto front for the rest of the cells are determined as described above by invoking ConPar routine that takes as input the Pareto fronts in the cells in the antidiagonals preceding L=6.\nThe Figure 1(e) illustrates all the PoP invocations involved in determining the Pareto front for the cell, (r, c). The last recurrence relation illustrates how the Pareto front is computed for this cell using the routine, ConPar. There are rmax PoP invocations, PoP(P11,Pr\u22121 c\u22121), PoP(P21,Pr\u22122 c\u22121),. . . , PoP(Prmax 1,Pr\u2212rmax c\u22121) resulting in rmax Pareto fronts. These Pareto fronts along with the Pareto front, (Pr c\u22121), are input to the ConPar invocation.\nThe last anti-diagonal visited, L = n+p\u2212 1, contains the cell, dpt(n, p). The Pareto front for this cell is determined similarly using ConPar routine. The ConPar invocations takes as inputs, Pareto fronts resulting from rmax PoP invocations, PoP(P11,Pn\u22121 p\u22121), . . . , PoP(Prmax 1,Pn\u2212rmax p\u22121), and the Pareto front, (Pn p\u22121). The cell dpt(n, p) contains the output of HEPOPTADP, the Pareto front needed to solve the workload size n using the p identical nodes.\nHEPOPTADP provides not only the solution for (n, p) but also for any (I, J),\u2200I = 1, . . . ,n, J = 1, . . . ,p, through its dpt table. The time complexity of this algorithm isO(n\u00d7p2\u00d7m\u00d7h\u00d7log2(p\u00d7m\u00d7h)). Therefore, it achieves a complexity reduction of O(m\n2\u00d7h2\u00d7p n ) over\nHEPOPTA. Since n \u2264 p \u00d7 m \u00d7 h, the lower bound on the reduction in complexity will be O(m \u00d7 h). The reduction is due to the hierarchical design of HEPOPTADP and memoization in dynamic programming technique. The correctness and time complexity proofs of HEPOPTADP are given in the supplemental."
        },
        {
            "heading": "8 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nFIGURE 2: The main steps in the execution of PARHEPOPTA employing q processes (4, in this case) to determine the Pareto front solving the workload size n = 12 using p = 9 identical nodes, each containing h heterogeneous processors. (a). The columns (2, . . . ,p) in the dynamic programming table are divided evenly between the q processes. (b). In the first main step, the Pareto fronts in the red cells, {(1,1),(2,1),. . . ,(m \u2217 h,1)}, are computed in parallel and replicated at all the q processes since they will be needed at all the main steps of PARHEPOPTA. (c). PARHEPOPTA then visits the anti-diagonals L serially in the order, 3, . . . ,n + p \u2212 1. For each anti-diagonal L, the Pareto fronts in its cells are computed in parallel by the q processes. There are no dependencies between the cells in the anti-diagonal. (d). Consider the computations for the cell (6, 6) in the antidiagonal L = n + 1 = 11. The cell belongs to P3. To compute the Pareto front in this cell, P3 will need the Pareto fronts in the cells, {(1,1),...,(6,1),(6,2),. . . ,(6,4),(1,5),. . . ,(6,5)}. P3 contains locally the Pareto fronts in the cells, {(1,1),. . . ,(6,1)}. Note the cells in the first column {(1,1),. . . ,(6,1),. . . ,(m\u00d7 h,1)} are replicated at all the processes. P1 communicates the Pareto fronts in the cells, {(6,2),(6,3)}, to P3. P2 communicates the Pareto fronts in the cells, {(2,5),(3,5),(4,5),(5,5),(6,4),(6,5)}, to P3. Then, P3 performs local computations involving PoP invocations and a ConPar invocation to compute the Pareto front for cell, (6,6)."
        },
        {
            "heading": "IV. PARHEPOPTA: PARALLEL DYNAMIC PROGRAMMING BI-OBJECTIVE OPTIMIZATION ALGORITHM",
            "text": "We describe here the parallel version of HEPOPTADP called PARHEPOPTA executed by q identical parallel MPI processes.\nThe inputs to PARHEPOPTA are the workload size, n; the number of identical nodes, p; the number of heterogeneous processors in each node, h; the number of identical MPI processes executing PARHEPOPTA, q; the sets T and E containing the discrete execution time and dynamic energy functions; the static power consumption of a node, Ps. All the inputs and outputs are assumed to be available at process 0 only.\nThe output is a Pareto front represented by a set of tuples, P = {(fE(D), fT(D),D)i}, i \u2208 [1 . . K], where\nD = [dij]p\u00d7h, i = 1, 2, . . . ,p, j = 1, 2, . . . ,h is the optimal workload distribution, fE(D) is the total energy, and fT(D) is the execution time corresponding to the optimal workload distribution. The solutions in the set P are output in an increasing order of total energy.\nThe pseudocode of PARHEPOPTA is illustrated in the Algorithm 1.\nThe dynamic programming table dpt of dimensions n \u00d7 p is partitioned vertically between q processes. We assume p is divisible by q for aiding exposition. The first column is replicated at all the processes since its cell values are needed at each step of PARHEPOPTA. The rest of the columns (1, . . . ,p \u2212 1) are distributed evenly between the q processes.\nA vertical partitioning scheme is better for load bal-\nVOLUME 10, 2022 9\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nAlgorithm 1 Parallel algorithm solving the bi-objective optimization of workload size n for performance and energy employing q parallel processes.\n1: procedure PARHEPOPTA(n, p,h, q,T,E,m,Ps,P) Input:\nWorkload size, n Number of identical nodes, p Number of heterogeneous processors per node, h Number of identical MPI processes executing PARHEPOPTA, q Set of discrete execution time functions, T = {t1(x), . . . , th(x)} Set of discrete dynamic energy functions, E = {e1(x), . . . , eh(x)} The cardinality of the discrete sets, m Static power consumption of a node, Ps\nOutput: Pareto front, P = {(fE(D), fT(D),X)k}, k \u2208 [1 . . K]\nD = [dij]p\u00d7h, i \u2208 [1 . . p], j \u2208 [1 . . h]\n2: iam\u2190 MPI_Comm_rank(MPI_COMM_WORLD) 3: if p = 1 and q = 1 then 4: return HEPOPTA(n, h,T,E,Ps) 5: end if 6: for r\u2190 1, min(n,m\u2217h)q do 7: w\u2190 r + iam \u2217 min(n,m\u2217h)q 8: dpt(w, 1) \u2190 HEPOPTA(w, h,T,E,Ps) 9: end for\n10: for r\u2190 1, (min(n,m \u2217 h)) mod q do 11: if (iam = (r\u2212 1)) then 12: w\u2190 r + q \u2217 min(n,m\u2217h)q 13: dpt(w, 1) \u2190 HEPOPTA(w, h,T,E,Ps) 14: break 15: end if 16: end for 17: MPI_Allgatherv(dpt(\u2217, 1)) 18: for L\u2190 3, n + p\u2212 1 do 19: dpt \u2190 computeL(iam, n,m, p, h, q,L, dpt) 20: end for 21: if (iam = (q\u2212 1)) then 22: MPI_Send(dpt(n, pq ), . . . , 0, . . . ) 23: end if 24: if (iam = 0) then 25: MPI_Recv(Pnp, . . . , q\u2212 1, . . . ) 26: end if 27: return Pnp 28: end procedure\nAlgorithm 2 Routine where the processes compute in parallel all the cells in the anti-diagonal L.\n1: function computeL(iam,n,m, p, h, q,L, dpt) 2: ncells\u2190 getncells(L,n, p) 3: (myncells, ncellspre)\u2190 getmyncells( iam, ncells,L, n, q, aggDptPart) 4: myP\u2190 aggDptPart[iam+ 1]\u2212 aggDptPart[iam] 5: sRow\u2190 (L < n)?(L\u2212 1) : n 6: sCol\u2190 (L \u2264 n)?2 : (L\u2212 n + 1) 7: lCol\u2190 sCol + ncellsPre\u2212 2\u2212 aggDptPart[iam] 8: if (iam \u0338= 0) and (myncells! = 0) and (lCol = 0) then 9: lRow\u2190 sRow \u2212 ncellsPre\u2212 2\n10: MPI_Recv(dptL(lRow), . . . , iam\u2212 1, . . . ) 11: end if 12: if (iam \u0338= q\u2212 1) and (ncellsPre + myncells < ncells) then 13: lRow\u2190 sRow \u2212 (ncellsPre + myncells)\u2212 2 14: lCol\u2190 myP\u2212 1 15: MPI_Send(dptL(lRow, lCol), iam + 1) 16: end if 17: for v\u2190 1,myncells do 18: gRow\u2190 sRow \u2212 ncellsPre\u2212 v 19: gCol\u2190 sCol + ncellsPre + v 20: lRow\u2190 gRow \u2212 2 21: lCol\u2190 gCol\u2212 2\u2212 aggDptPart[iam] 22: dpt(lRow, lCol) \u2190 23: computecell(iam,m, gRow, gCol, lRow, lCol, dptL,dpt) 24: end for 25: return dpt 26: end function\nance than the horizontal partitioning scheme, where the n rows are divided equally between the q processes. Since the computation progresses diagonally in the dpt table, horizontal partitioning results in idling several processes and not doing any work. For example, q \u2212 1 processes (excluding process 0) will idle at the beginning of the computation and q\u22121 processes (excluding process q\u22121) will idle at the end of the computation.\nA process finds its rank, iam, on Line 2. Lines 3- 5 cover the simple case when only one process executes PARHEPOPTA, q = 1, to solve the workload n using one node (p = 1) with h heterogeneous processors. PARHEPOPTA invokes HEPOPTA to obtain the Pareto front solving the workload using h heterogeneous processors. Lines 6-16 execute the base conditions (the top three recurrence relations). The table cells, dpt(1, c), c = 1, . . . ,p, store the Pareto front, P11, to solve the workload size one using one node.\nThe table cell, dpt(r, 1), r \u2208 [2 . . m \u2217 h], is filled with the Pareto front, Pr1, to solve the workload size r using one node. PARHEPOPTA invokes HEPOPTA"
        },
        {
            "heading": "10 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nAlgorithm 3 Local routine computing dpt(r, c) in the anti-diagonal L.\n1: function computecell(iam,m, gRow, gCol, lRow, lCol, dptL,dpt) 2: for row\u2190 1, gRow \u2212 1 do 3: if (row > m) and (gCol = 2) then 4: break 5: end if 6: if (gRow \u2212 row) = 1 then 7: dpt(lRow, lCol) \u2190 PoP(dpt(row \u2212 1, 0), dpt(0, 0),dpt(lRow, lCol)) 8: else 9: dpt(lRow, lCol) \u2190 PoP(dpt(row \u2212 1, 0),\ndptL(gRow \u2212 row \u2212 1), dpt(lRow, lCol))\n10: end if 11: end for 12: if !((gRow > m) and (gCol = 2)) then 13: if !((lCol = 0) and (dptL \u0338= \u03d5)) then 14: dpttmp\u2190 dptL(gRow \u2212 2) 15: else 16: dpttmp\u2190 dpt(row \u2212 2, lCol\u2212 1) 17: end if 18: dpt(lRow, lCol) \u2190 ConPar(dpttmp, dpt(lRow, lCol)) 19: end if 20: return dpt(lRow, lCol) 21: end function\nto obtain this Pareto front solving the workload r using h heterogeneous processors. First, the Pareto fronts in the cells in the first column are determined in parallel by the q processes. Then, the column is replicated at all the processes using MPI_Allgatherv routine.\nThe core loop starts at Line 18. The loop variable, L = 3, . . . ,n+p\u22121, represents the anti-diagonal. All the cells in an anti-diagonal are computed using the routine, computeL.\nAlgorithm 2 illustrates the routine, computeL. All the q processes take part in this routine. Since the table cells in an anti-diagonal L = 3, . . . ,n+ p\u2212 1 depend only on the cells in the anti-diagonals preceding L and have no inter-dependencies, they can be computed in parallel. The anti-diagonals are, however, visited sequentially as shown in the Figure 2(c). The number of cells in an antidiagonal, ncells, is obtained using the routine, getncells (explained in the supplemental). There can only be a maximum of p cells in any anti-diagonal. The routine, getmyncells, returns myncells and ncellspre, which are the number of cells in an anti-diagonal owned by the process iam and the number of cells that precede the cells belonging to the process iam. Both getncells and getmyncells are local routines.\nLines 7-16 in Algorithm 2 present the communications in PARHEPOPTA illustrated in Figure 2(d). Only one\ncell value is communicated between neighbouring processes iam and iam + 1 in each iteration of L. If the process iam \u0338= 0 and if it is computing a cell in its first table column given by the condition (lCol = 0), then it needs the values of the cells in the column preceding it from the neighbouring process, iam\u22121. The buffer, dptL, stores these values with every increment of L. The neighbouring cell value is stored at the index, lRow. If the process iam \u0338= (q \u2212 1) is not the last process owning a cell in the anti-diagonal L given by the condition ((ncellspre + myncells) < ncells), then it sends the cell value, dpt(lRow, lCol), to the neighbouring process, iam + 1.\nAfter the communications are completed, the loop (Lines 17-24) contain the core computations. The local routine, computecell (Algorithm 3), computes the table cell value dpt(lRow, lCol), which depends only on the cells, {(row, 1), (gRow\u2212row, lCol\u22121)},\u2200I \u2208 [1 . . gRow\u2212 1] and (lRow, lCol\u2212 1), as shown in Figure 1(e).\nLines 2-11 in Algorithm 3 contain the invocation of PoP routine to combine the Pareto fronts in the cells, (row, 1) and (gRow \u2212 row, lCol \u2212 1), as shown in the Figure 2(c). Lines 12-19 invoke the ConPar routine to build the Pareto front, dpt(lRow, lCol), from the input Pareto fronts, {dpt(lRow, lCol\u2212 1), dpt(lRow, lCol)}.\nFinally, in the Lines 16-21 of the main algorithm 1, process q \u2212 1 sends the cell value, dpt(n, pq ), to process 0. It contains the Pareto front, Pnp, having the optimal performance-energy application configurations (workload distributions) to solve the workload size n using the p identical nodes. Pnp is the output of PARHEPOPTA.\nPARHEPOPTA, through its dpt table, provides not only the solution for (n, p) but also for any (I, J),\u2200I = 1, . . . ,n, J = 1, . . . ,p. It reduces the time complexity of HEPOPTADP by O(q). Therefore, it offers a potential speedup of O(m\n2\u00d7h2\u00d7p\u00d7q n ) over HEPOPTA. Since n \u2264\np\u00d7m\u00d7h, the lower bound for the reduction in complexity is m \u00d7 h \u00d7 q. The time and memory complexity proofs of PARHEPOPTA are given in the supplemental.\nIn the supplemental, we present the implementation of PARHEPOPTA employing hybrid parallelism employing q identical parallel MPI processes (q \u2264 p) each executing t threads. There is no change in the theoretical time complexity between the hybrid implementation and the multi-process implementation. However, we experimentally found that the multi-process implementation performs better."
        },
        {
            "heading": "V. EXPERIMENTAL RESULTS AND DISCUSSION",
            "text": "This section first presents the heterogeneous hybrid node and the data-parallel applications employed in the experiments. Then it describes the experimental methodology to construct the discrete execution time and the ground-truth dynamic energy profiles based on system-level physical power measurements using power meters for the processors involved in executing the two\nVOLUME 10, 2022 11\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\ndata-parallel applications. We then present the speedups of PARHEPOPTA and HEPOPTADP over HEPOPTA. Finally, we provide examples of usage of PARHEPOPTA and discuss scenarios where PARHEPOPTA can accelerate the development and runtime of energy-efficient parallel applications.\nTo ensure the reliability of our results, we follow a statistical methodology where a sample average for a response variable (energy, time, PMC, utilization variables) is obtained from multiple experimental runs. The sample average is calculated by executing the application repeatedly until it lies in the 95% confidence interval and a precision of 0.05 (5%) is achieved. For this purpose, Student\u2019s t-test is used, assuming that the individual observations are independent and their population follows the normal distribution. We verify the validity of these assumptions using Pearson\u2019s chisquared test. The methodology is described in the supplemental.\nA. HETEROGENEOUS HYBRID NODE AND DATA-PARALLEL APPLICATIONS The hybrid node is presented in the Introduction section and consists of a dual-socket Intel Haswell multicore CPU containing 24 physical cores with 64 GB main memory, which hosts two accelerators, an Nvidia K40c GPU and an Nvidia P100 GPU (specifications in Table 1). Each accelerator connects to a dedicated host core via a separate PCI-E link. The static power consumption of the node is 253 W (Ps).\nThe hybrid node has one WattsUp Pro power meter that sits between the wall A/C outlets and the node\u2019s input power sockets. The power meter captures the total power consumption of the node. It has a data cable connected to one USB port of the node. A Perl script collects the data from the power meter using the serial USB interface. The execution of these scripts is nonintrusive and consumes insignificant power.\nThe power meters are periodically calibrated using an ANSI C12.20 revenue-grade power meter, Yokogawa WT210. The maximum sampling speed of the power meters is one sample every second. The accuracy specified in the data sheets is \u00b13%. The minimum measurable power is 0.5 watts. The accuracy at 0.5 watts is \u00b10.3 watts.\nWe employ two popular and highly optimized scientific applications employing matrix multiplication (DGEMM) and 2D fast Fourier transform (2D-FFT) routines, respectively.\nThe DGEMM application computes C+ = A \u00d7 B, where A, B, and C are square matrices of size N \u00d7 N. The application employs Intel MKL DGEMM for the CPU, and ZZGEMMOOC out-of-card package [22] for Nvidia GPUs. ZZGEMMOOC packages reuse CUBLAS and MKL BLAS for in-card DGEMM calls. The Intel\nMKL and CUDA versions are 2017.0.2 and 9.2.148. The workload size is equal to 2\u00d7N3.\nThe 2D-FFT application computes 2D discrete Fourier Transform of a complex signal matrix of size N\u00d7N. It employs Intel MKL FFT routines for the CPU and CUFFT routines for Nvidia GPUs. For workload sizes that cannot be factored into primes less than or equal to 127, CUFFT gives failures. Therefore, we employ out-of-card computations for these workload sizes where the workload size is divided into small sizes that can be solved on the GPU. The workload size is 5\u00d7N2 \u00d7 log2 N.\nOnly the Intel multicore CPU is employed for executing PARHEPOPTA because we do not have an implementation of PARHEPOPTA for Nvidia GPUs. The MPI used is Open MPI version 4.0.1."
        },
        {
            "heading": "B. METHODOLOGY TO CONSTRUCT DISCRETE EXECUTION TIME AND GROUND-TRUTH DYNAMIC ENERGY PROFILES",
            "text": "This section describes the methodology to construct the discrete execution time and ground-truth dynamic energy profiles for the processors executing the two dataparallel applications.\nThe data-parallel application on the hybrid node is modeled by three heterogeneous abstract processors, CPU_1, GPU_1, and GPU_2. The details are presented in the Introduction section. The execution time profiles of the abstract processors are experimentally built separately using an automated build procedure using three OpenMP threads where one thread is mapped to one abstract processor. The execution times of all the abstract processors executing the same workload are measured simultaneously, thereby considering the influence of resource contention. The execution time for abstract processors involving the accelerators includes the time to transfer data between the host and the accelerator. For example, the execution time and dynamic energy of the execution of a workload on GPU_1 include the time and energy to transfer data from the host multicore CPU core to the accelerator and back and the computations on the accelerator.\nThe ground-truth dynamic energy profiles of the abstract processors are constructed using the additive approach [15]. In the additive approach, the dynamic energy profiles of the three processors are constructed serially. The combined profile where the individual dynamic energy consumptions are totalled for each data point is then obtained. Then, the dynamic energy profile employing all the processors in parallel is built. The difference between the parallel and combined dynamic energy profiles is observed. We find that the average difference between parallel and combined dynamic energy profiles is around 5% for both applications and within the statistical accuracy threshold set in our experiments. Both the parallel and combined profiles also follow the same pattern. Therefore, we conclude that"
        },
        {
            "heading": "12 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nthe processors in our experiments satisfy the additive hypothesis: the abstract processors are loosely coupled and therefore do not interfere with each other during the application. Thus, we conclude that the ground-truth dynamic energy profiles of the three processors can be constructed serially or in parallel for our experimental platform and applications.\nFigures 3a and 3b show the execution time and ground-truth dynamic energy profiles of the three processors for the DGEMM application obtained using the ground-truth method. The numbers of points (m) in the profiles for DGEMM and 2D-FFT applications are 210 and 256, respectively. Figures 3c and 3d display the execution time and ground-truth dynamic energy profiles of the three processors for the 2D-FFT application obtained using the ground-truth method.\nIn the figures, all the processors solve the same workload size for each data point in the discrete performance and energy profiles. For a given workload, PARHEPOPTA takes the discrete profiles as input and determines the optimal workload distribution to solve the workload. The workload distribution typically would contain different workload sizes assigned to the processors, but they are still members of the input discrete sets. The total execution time and energy of parallel execution of the workload is calculated to be the maximum of the execution times of the assigned workload sizes and summation of their respective energies. We can call them the model execution time and model energy. We confirm through exhaustive experimentation that the actual total execution time and total energy of parallel execution of the workload do not differ significantly from the model time and model energy."
        },
        {
            "heading": "1) Precautions to Prevent Noise in Measuring Energy Consumption",
            "text": "The server is fully reserved and dedicated to the experiments during their execution. We also ensure that there are no drastic fluctuations in the load due to abnormal events in the server by monitoring its load continuously for a week using the tool, sar. Insignificant variation in the load is observed during this monitoring period suggesting normal and clean behaviour of the server.\nSeveral precautions are taken in computing energy measurements to eliminate any potential interference of the computing elements that are not part of the given abstract processor running the application kernel. First, we group abstract processors so that a given abstract processor constitutes solely the computing elements involved in running a given application kernel. The application kernel will, in this way, only use the computing elements of the abstract processor executing it and not use any other component for its execution. Hence, the dynamic energy consumption will solely reflect the work done by the computing elements of the given abstract processor executing the application kernel.\n(a) Execution time profiles of the three processors employed in the DGEMM application.\n(b) Dynamic energy profiles of the three processors employed in the DGEMM application.\n(c) Execution time profiles of the three processors employed in the 2D FFT application.\n(d) Dynamic energy profiles of the three processors employed in the 2D FFT application.\nFIGURE 3: The execution time and ground-truth dynamic energy profiles of the three processors for the DGEMM and 2D-FFT applications.\nVOLUME 10, 2022 13\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nConsider DGEMM application kernel executing on the abstract processor CPU_1 (comprises of CPU and DRAM). The HCLWattsUp API function gives the server\u2019s total energy consumption during an application\u2019s execution. Energy consumption includes the contribution from all components, such as NIC, SSDs, and fans. Therefore, to rule out their contribution to dynamic energy consumption, we ensure all the components other than CPUs and DRAM are not used during the execution of an application. In this way, the dynamic energy consumption that we obtain using HCLWattsUp API reflects only the contribution of CPUs and DRAM. The following steps are employed for this purpose:\n\u2022 The disk consumption is monitored before and during the application run and ensure no I/O is performed by the application using tools such as sar and iotop. \u2022 The workload used in the execution of an application does not exceed the main memory, and that swapping (paging) does not occur. \u2022 The application does not use the network by monitoring using tools such as sar and atop. \u2022 The application kernel\u2019s CPU affinity mask is set using SCHED API\u2019s system call, SCHED_SETAFFINITY(). To bind the DGEMM application kernel, we set its CPU affinity mask to 11 physical CPU cores of Socket 1 and 11 physical CPU cores of Socket 2.\nFans are also a great contributor to energy consumption. On our platform, fans are controlled in zones: a) zone 0: CPU or System fans, b) zone 1: Peripheral zone fans. There are four levels to control the speed of fans:\n\u2022 Standard: BMC control of both fan zones, with the CPU zone based on CPU temp (target speed 50%) and Peripheral zone based on PCH temp (target speed 50%); \u2022 Optimal: BMC control of the CPU zone (target speed 30%), with Peripheral zone fixed at low speed (fixed 30%); \u2022 Heavy IO: BMC control of CPU zone (target speed 50%), Peripheral zone fixed at 75%; \u2022 Full: all fans running at 100%. To rule out fans\u2019 contribution to dynamic energy consumption, we set the fans at full speed before launching the experiments. The fans run consistently at \u223c13400 rpm when set at full speed. In this way, fans consume the same amount of power, which is included in the static power of the server. Furthermore, we monitor the server\u2019s temperatures and the fans\u2019 speeds with the help of Intelligent Platform Management Interface (IPMI) sensors, both with and without the application run. We find that there are no significant differences in temperature and the speeds of fans are the same in both scenarios.\nThus, we ensure that the dynamic energy consumption measured reflects the contribution solely by the ab-\nstract processor executing the given application kernel."
        },
        {
            "heading": "C. SPEEDUPS OF PARHEPOPTA AND HEPOPTADP OVER HEPOPTA",
            "text": "This section compares the speedup of PARHEPOPTA and HEPOPTADP over HEPOPTA. All three algorithms are executed only on the Intel multicore CPU since we do not have their implementations for Nvidia GPUs.\nHEPOPTADP and HEPOPTA are executed by only one process using one thread. PARHEPOPTA is executed by q MPI processes.\nFor DGEMM, the workload size n input to the algorithms is a multiple of the number of arithmetic operations in a basic computation unit, a matrix update, a + b \u00d7 c, where a, b, and c are u \u00d7 u matrices of fixed size u. Therefore, the workload size n is a multiple of 2\u00d7 u3. The value of u used in our experiments is 1536. For 2D FFT, the workload size n is a multiple of a basic computation unit, a 2D FFT of a signal matrix of size v \u00d7 v. The value of v used in our experiments is 512.\nThe input discrete dynamic energy profiles to all three algorithms are the ground-truth profiles constructed offline. The numbers of points (m) in the profiles for DGEMM and 2D-FFT applications are 210 and 256, respectively. The optimal workload distributions determined by all three algorithms contain workload sizes that are members of the input set X. Finally, we verify that the Pareto-optimal solutions returned by all algorithms match.\nThe speedup of PARHEPOPTA over HEPOPTA is calculated using the formula, thepoptatparhepopta , where thepopta and tparhepopta are the execution times of HEPOPTA and PARHEPOPTA solving the same problem. The speedup of HEPOPTADP over HEPOPTA is calculated using the formula, thepoptathepoptadp , where thepopta and thepoptadp are the execution times of HEPOPTA and HEPOPTADP solving the same problem.\nThe speedups for the DGEMM and 2D-FFT applications are shown in Tables 2 and 3, respectively. The upper bound on n that can be solved by the algorithms is equal to m\u00d7h\u00d7p. Therefore, the maximum np\u00d7h that can be solved is m, which is 211 and 256 for DGEMM and 2D-FFT applications, respectively.\nThe quantity, np\u00d7h , refers to the amount of work per processor or the granularity. The tables show that HEPOPTADP and PARHEPOPTA provide constant speedups over HEPOPTA keeping the granularity constant, thereby, confirming the theoretical results. The speedups of PARHEPOPTA over HEPOPTADP are about 7x and 10x for the two applications. The ideal speedup of 24x is unlikely owing to resource contention and (Non-uniform Memory Access) NUMA effects.\nTable 4 shows the increase in speedup of PARHEPOPTA over HEPOPTA as q is increased keeping"
        },
        {
            "heading": "14 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nall the other application parameters constant, thereby, confirming the theoretical result of O(q).\nD. APPLICATIONS OF PARHEPOPTA We examples of usage of PARHEPOPTA and how it can accelerate the development and runtime of energyefficient parallel applications."
        },
        {
            "heading": "1) Usage of PARHEPOPTA",
            "text": "For a given application, the user provides the application configuration parameters, n, p, h, the number of MPI processes (q) executing PARHEPOPTA, the discrete performance and dynamic energy profiles (T,E) of cardinality m, the static energy consumption, Ps, and a criterion for selecting a Pareto-optimal solution (workload distribution) to be employed during the application execution. Some example criteria are\nTABLE 4: Speedup of PARHEPOPTA over HEPOPTA for the DGEMM and 2D-FFT applications as q is varied from 1 to 24 while keeping all the application parameters constant.\nq DGEMM 2D-FFT 1 4.60 2.13 2 7.76 4.08 4 14.74 8.17 8 16.16 15.9 16 26.9 18.11 24 30.25 20.77\na). select the performance-optimal solution, b). select the energy-optimal solution, and c). select a solution whose performance degradation is not more than 5% and has the lowest total energy. During the application execution, PARHEPOPTA is invoked using the parameters (n, p, h, q,T,E,m,Ps) to determine the Pareto front (P). A Pareto-optimal solution is then selected from the Pareto front using the user-specified criterion and employed for the computations.\nWe illustrate two representative cases involving DGEMM and 2D-FFT applications. Consider, for example, the DGEMM application execution with input parameters, N = 33792,n = 10240, p = 96, h = 3,m = 211, q = 24,Ps = 253, and the discrete performance and dynamic energy profiles (Figures 3a and 3b built offline). Figure 4a shows the Pareto front output by PARHEPOPTA. The execution time of PARHEPOPTA using one hybrid node is 19 seconds. Assuming all the 96 hybrid nodes are employed to execute PARHEPOPTA, the estimated execution time is 0.2 seconds due to potential O(p) speedup.\nThe endpoints of a Pareto front represent the optimal solutions for single-objective optimization for performance and energy. A steep slope close to the timeoptimal endpoint means that allowing a slight degradation in performance can result in significant energy savings. Similarly, a steep slope close to the energyoptimal endpoint means that significant performance improvement is possible with a slight increase in energy consumption. In this case, a performance degradation of 0.34 seconds gives energy savings of 24918 J.\nDue to the steepness of the Pareto front slope, the user would specify criteria that explore points further from the time-optimal endpoint down the Pareto front since the energy savings are pretty significant. Supposing the user specifies the selection of the performance-optimal solution, then the workload distribution associated with the Pareto front point (1.44 [s], 75985 [J]) is employed to compute the DGEMM matrix multiplication. On the other hand, if the user wants a solution whose performance degradation is not more than 5% and has the lowest total energy, then the workload distribution associated with the Pareto front point (1.50 [s], 71890 [J]) is used to compute the DGEMM matrix multiplication. The selected point is the third point from the timeoptimal endpoint. Allowing 1% further performance degradation can provide 5180 J energy savings due to the steepness of the Pareto front slope.\nSimilarly, consider the 2D-FFT application execution with input parameters, N = 60416, n = 24576,p = 128, h = 3,m = 256, q = 24,Ps = 253, and the discrete performance and dynamic energy profiles (Figures 3c and 3d built offline). Figure 4b shows the Pareto front output by PARHEPOPTA. The execution time of PARHEPOPTA using one hybrid node is 61 seconds. Assuming all the 128 hybrid nodes are employed to\nVOLUME 10, 2022 15\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\n(a) Pareto front for the DGEMM application for (N = 33792, p = 96, h = 3,m = 211). (b) Pareto front for the 2D-FFT application for (N = 60416, p = 128, h = 3,m = 256).\nFIGURE 4: The Pareto fronts for the DGEMM and 2D-FFT applications output by PARHEPOPTA using the ground-truth dynamic energy profiles of cardinality m. The matrix sizes employed in the applications is N\u00d7N. For DGEMM, the workload size, n, input to PARHEPOPTA is a multiple of a basic computation unit, a matrix update of 1536\u00d7 1536 matrices and is equal to 10240. For 2D FFT, the workload size, n, input to PARHEPOPTA is 24576. The number of MPI processes (q) executing PARHEPOPTA is 24. The static power consumption Ps of the node is 253 W.\nexecute PARHEPOPTA, the estimated execution time is 0.47 seconds due to potential O(p) speedup.\nThe 2D-FFT Pareto front is less steep than the DGEMM Pareto front and more or less horizontal. While allowing a performance degradation of 0.34 seconds gives energy savings of 24918 J for DGEMM, the energy savings for the same performance degradation is 7286 J for 2D-FFT. Therefore, the user-specific criteria for 2D-FFT will differ from those for DGEMM.\nSince the 2D-FFT slope is almost horizontal, the user would specify criteria that focus on points closer to the time-optimal endpoint since venturing further down the Pareto front will not provide substantial energy savings. Supposing the user wants a solution whose performance degradation is not more than 8% and has the lowest total energy, then the workload distribution associated with the Pareto front point (2.17 [s], 76794 [J]) is used to compute the 2D fast Fourier transform. The selected point is the fifth point from the time-optimal endpoint. Allowing 6% further performance degradation can only yield 2685 J energy savings."
        },
        {
            "heading": "2) Acceleration of Development and Runtime of Energy-efficient Applications",
            "text": "The development of an energy-efficient parallel application is typically done on a small subset of nodes in a cluster before the application is deployed in production. Therefore, the critical building blocks of such applications, such as the data-partitioning algorithm, must not slow down the development effort.\nConsider, for example, the development of DGEMM and 2D-FFT applications described previously using two test configurations, (N = 33792, n = 10240, p =\n96, h = 3,m = 211,Ps = 253) for DGEMM and (N = 60416, n = 24576, p = 128, h = 3,m = 256,Ps = 253) for 2D-FFT. The discrete performance and dynamic energy profiles employed for DGEMM are shown in Figures 3a and 3b and for 2D-FFT in Figures 3c and 3d. For these application configurations, the execution times of HEPOPTA are 3077 seconds and 11616 seconds for DGEMM and 2D-FFT, respectively. Therefore, the long execution times of HEPOPTA make it unfit for developing such energy-efficient parallel applications. However, the good speedups offered by PARHEPOPTA render it practicable.\nPARHEPOPTA is ideal for accelerating long-running simulations like numerical weather prediction. For example, consider the real-life scientific application, Multidimensional Positive Definite Advection Transport Algorithm (MPDATA), which is a core component of the EULAG (Eulerian/semi-Lagrangian fluid solver) geophysical model developed for numerical weather prediction [10]. The simulation runs for over 16000 time steps for a 2-day prediction where each time step takes 0.125 seconds on an Intel Xeon Phi coprocessor. Therefore, the total simulation time is 2000 seconds.\nThe authors improve the performance of the simulation by 15% using a model-based data partitioning algorithm. In the improved version, the simulation comprises initialization and solution phases. In the initialization phase, the performance profiles are built and input to the data partitioning algorithm, which determines the performance-optimal heterogeneous workload distribution. The solution phase employs the same workload distribution in all the time steps to perform the simulation. The initialization phase takes less than 20 time steps."
        },
        {
            "heading": "16 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nSince MPDATA computation in each time step is similar to matrix multiplication, we consider accelerating such simulations on a moderate-sized cluster of hybrid nodes, for example, p = 96. Using HEPOPTA can be prohibitively expensive in this case since its execution time of 3077 [s] exceeds the simulation time. However, the overhead of PARHEPOPTA is less than two time steps, and its execution time of 0.2 [s] is only 0.01% of the simulation time.\nVI. RELATED WORK We divide our related literature study into five categories: a). System-level optimization methods, b). Application-level optimization methods, c). Static and dynamic optimization methods, d). Performance models of computation, and e). Energy models of computation.\nA. SYSTEM-LEVEL METHODS System-level methods aim to optimize the performance and energy of the environment where the applications are executed. The methods employ application-agnostic models and hardware parameters as decision variables. The dominant decision variable in this category is Dynamic Voltage and Frequency Scaling (DVFS). DVFS reduces the dynamic power consumed by a processor by throttling its clock frequency.\nFreeh et al. [23] analyse the performance-energy tradeoffs of serial and parallel applications on a cluster of DVFS-capable AMD nodes. The decision variable is the DVFS frequency. Rountree et al. [24] propose a runtime system that employs DVS during predicted slack periods to achieve signficant energy savings while incurring negligible performance degradation. Lee et al. [25] propose energy-conscious scheduling heuristics that employ DVS for bi-objective optimization of parallel applications on HPC platforms.\nMezmaz et al. [1] propose a parallel genetic algorithm for bi-objective optimization on cloud computing infrastructures for performance and energy. The decision variable is the supply voltage of the processor. Fard et al. [26] present a four-objective case study comprising performance, economic cost, energy consumption, and reliability for optimization of scientific workflows in heterogeneous computing environments. The decision variable is the task assignment or mapping. Beloglazov et al. [27] propose heuristics that consider twin objectives of energy efficiency and Quality of Service (QoS) for provisioning data center resources. The decision variables are the number of virtual machines and clock frequencies.\nKessaci et al. [5] present a multi-objective genetic algorithm that minimizes the energy consumption, CO2 emissions and maximizes the generated profit of a cloud computing infrastructure. The decision variable is the arrival rate of applications. Durillo et al. [6] propose a multi-objective workflow scheduling algorithm\nfor bi-objective optimization on heterogeneous highperformance parallel and distributed computing systems for performance and energy. They study the impact of several decision variables: number of tasks, number of machines, DVFS levels, static energy, and types of tasks. Kolodziej et al. [2] propose multi-objective genetic algorithms for bi-objective optimization on green grid clusters and clouds for performance and energy. The performance is modeled using computation speed of a processor. The decision variable is the DVFS level.\nSolution methods can also be differentiated based on whether they output a partial or a full Pareto front of performance-energy optimal solutions. Some solution methods optimize HPC platforms for performance under an energy budget or optimize for energy under an execution time constraint [7],[8],[9]. They determine a partial Pareto front by applying the power cap or an execution time constraint and then select the best configuration to fulfil a user-specific criterion. Some methods solve unconstrained bi-objective optimization for performance and energy (with no time or energy constraints) [5],[6],[2]. They build the full Pareto front. Research works [28], [29], [30] are analytical studies of bi-objective optimization for performance and energy."
        },
        {
            "heading": "B. APPLICATION-LEVEL METHODS",
            "text": "The second approach consists of solution methods that optimize applications rather than the operating environment. The methods use application-level decision variables and predictive models for the performance and energy consumption of applications. The dominant decision variables include the number of threads, loop tile size, and workload distribution. This approach is understudied compared to the mainstream system-level approach.\nLastovetsky and Reddy [11] propose data partitioning algorithms that solve single-objective optimization problems of data-parallel applications for performance or energy on homogeneous clusters of multicore CPUs. They take as an input discrete performance and dynamic energy functions with no shape assumptions that accurately and realistically account for resource contention and NUMA inherent in modern multicore CPU platforms. Reddy and Lastovetsky [12] propose a solution method to solve the bi-objective optimization problem of an application for performance and energy on homogeneous clusters of modern multicore CPUs. They demonstrate that the method gives a diverse set of Pareto-optimal solutions and can be combined with DVFS-based multi-objective optimization methods to give a better set of (Pareto-optimal) solutions. The methods target homogeneous high-performance computing (HPC) platforms.\nModern HPC platforms, cloud computing systems, and data centers are highly heterogeneous, comprising nodes where a multicore processor is tightly integrated\nVOLUME 10, 2022 17\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nwith one or more accelerators to address the twin critical concerns of performance and energy efficiency. A crucial requirement to determine the energy-optimal configuration of a parallel/hybrid application executing on such platforms is to determine component-level dynamic energy profiles of the application executing on multiple independent devices of the platform. Fahad et al. [17] present the first methodology to measure the component-level energy consumption of a hybrid application on a heterogeneous computing platform based on system-level power measurements using power meters. Chakraborti et al. [13] consider the effect of heterogeneous workload distribution on bi-objective optimization of data analytics applications by simulating heterogeneity on homogeneous clusters. A linear function of workload size represents the performance, and the energy is predicted using historical data tables. Khaleghzadeh et al. [15] propose a solution for solving the bi-objective optimization problem on heterogeneous processors comprising two principal components. The solution method employs the methodology [17] to determine the fine-grained component-level decomposition of an application\u2019s energy consumption.\nArchitects of modern multicore processors follow a key design goal called energy proportionality (EP) (Barroso and H\u00f6lzle [31]), which means designing microprocessors that consume energy proportional to the amount of work performed. Khokhriakhov et al. [14] demonstrate that EP does not hold for modern multicore processors using a novel application-level bi-objective optimization method for energy and performance on a single multicore processor. They experiment with four popular and highly optimized multithreaded data-parallel applications on four modern multicore processors. They show that optimizing for performance alone may result in a significant increase in dynamic energy consumption and optimizing for dynamic energy alone \u2013 in considerable performance degradation. Their optimization method determined a good number of Pareto-optimal solutions.\nC. STATIC AND DYNAMIC OPTIMIZATION METHODS Static optimization solution methods use a priori information about the application and platform. We will focus mainly on workload partitioning methods. The solution methods can afford to construct full and comprehensive performance and energy profiles offline, allowing them to explore a large space of solutions. They are typically used in applications where data locality is important because they do not require data redistribution. The methods [32],[33],[34] solve the singleobjective optimization problem for performance on heterogeneous platforms. The methods [11],[12],[15] solve the bi-objective optimization problem for performance and energy for homogeneous and heterogeneous platforms. They take input performance and energy profiles that are built offline. The energy profiles are constructed\nusing the system-level physical power measurements using external power meters. However, the methods are not suitable for two scenarios: a). Dynamic environments where the number of available processors and their performance and energy profiles can differ for different application runs, and b). Environments with no provision for node-level physical power measurements using external power meters, for example, supercomputing facilities, computational grids, and cloud computing infrastructures.\nDynamic optimization solution methods adapt at runtime to dynamic changes in the environment. Runtime schedulers such as KAAPI [35], StarPU [36], and DAGuE [37] schedule an application described as a Direct Acyclic Graph (DAG) or task graph onto parallel platforms. Task scheduling and work-stealing algorithms [38], [39], [40], balance the load by moving fine-grained tasks between processors during the execution. Dynamic load balancers based on graph partitioners are proposed by [41], [42] for adaptive scientific computations where two objectives, interprocessor communication and data migration costs, are considered. Lastovetsky et al. [43] propose a data partitioning algorithm for employment in self-adaptable applications due to its low runtime cost. The methods above solve the single-objective optimization problem for performance. Reddy et al. [44] propose a dynamic data partitioning algorithm which solves the bi-objective optimization problem for performance and energy on homogeneous clusters of multicore CPUs. The algorithm constructs partial performance and energy profiles at runtime and assumes that the nodes are equipped with power meters providing power measurements. Therefore, it is unsuitable for employment in dynamic environments where nodes lack power meters."
        },
        {
            "heading": "D. PERFORMANCE MODELS OF COMPUTATION",
            "text": "Performance models of computations can be classified into analytical and non-analytical categories.\nAnalytical models use techniques such as linear regression, analysing patterns of computation and memory accesses, and static code analysis to estimate performance for CPUs and accelerators [45], [46]. In the nonanalytical category, the most simple model is a constant performance model (CPM), where different notions such as normalized cycle time, normalized processor speed, average execution time, and task computation time. characterize the speed of an application [47], [48]. In CPMs, no dependence is assumed between the performance of a processor and the workload size.\nCPMs are too simplistic to accurately model the performance of data-parallel applications executing on modern heterogeneous platforms. The most advanced load balancing algorithms employ functional performance models (FPMs) that are application-specific and represent the speed of a processor by a continuous function of workload size [49], [34]. The FPMs capture"
        },
        {
            "heading": "18 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nrealistically and accurately the real-life behaviour of applications executing on nodes consisting of uniprocessors (single-core CPUs).\nThe complex nodal architecture of modern HPC systems, consisting of tightly integrated processors with inherent severe resource contention and NUMA, pose serious challenges to load balancing algorithms based on the FPMs. These inherent traits result in significant variations (drops) in the performance profiles of parallel applications executing on these platforms, thereby violating the assumptions on the shapes of the performance profiles considered by the FPM-based load balancing algorithms. In [10], [11], [12], [15], the performance model of computations is represented by a complex (nonsmooth and non-linear) function of workload size.\nE. ENERGY MODELS OF COMPUTATION A linear energy model based on the utilization of CPU, disk, and the network is proposed by Heath et al. [50]. A more complex power model propsoed in [51] employs utilization metrics of CPU, disk, and network components and hardware performance counters for memory as predictor variables. Fan et al. [52] propose a simple linear model that correlates the power consumption of a single-core processor with its utilization. Bertran et al. [53] present a power model that provides a percomponent power breakdown of a multicore CPU. Their model is based on activity factors obtained from PMCs for various components in a multicore CPU. Basmadjian et al. [54] construct a power model of a server using the summation of power models of its components: the processor (CPU), memory (RAM), fans, and disk (HDD). Lastovetsky et al. [11] propose a model representing the energy consumption of a multicore CPU by a non-linear function of workload size.\nHong et al. [55] present an energy model for an Nvidia GPU based on a PMC-based power prediction approach similar to [56]. Nagasaka et al. [57] propose a PMC-based statistical power consumption modelling technique for GPUs that run CUDA applications. Song et al. [58] present power and energy prediction models based on machine learning algorithms such as backpropagation in artificial neural networks (ANNs). Shao et al. [59] develop an instruction-level energy consumption model for a Xeon Phi processor.\nShahid et al. [20] propose a novel theory of energy predictive models of computing and unify its practical implications to increase the prediction accuracy of linear energy predictive models in a consistency test. The test contains a suite of properties that include determinism, reproducibility, and additivity to select model variables and constraints for model coefficients. By applying the consistency test, the authors improve the average prediction accuracy of state-of-the-art linear regression models from 31% to 18%. Shahid et al. [21] analyze the prediction accuracy of models employing\nutilization variables only, PMCs only, and combination of both utilization variables and PMCs, through the lens of the theory of energy predictive models of computing for modern multicore CPU platforms. They demonstrate that application-specific and platform-level models using both utilization variables and PMCs exhibit up to 3.6x and 2.6x better average prediction accuracy respectively when compared with models employing utilization variables only and highly additive PMCs only.\nKhokhriakhov et al. [14] propose a qualitative linear dynamic energy model employing CPU utilization and PMCs to explain the discovered energy nonproportionality on their multicore CPU platforms."
        },
        {
            "heading": "VII. CONCLUSION",
            "text": "Achieving energy efficiency objectives and satisfying quality-of-service requirements related to response time are critical concerns in modern high performance computing platforms, computational grids, and cloud computing infrastructures. Therefore, accelerating the biobjective optimization of applications for performance and energy on such platforms is necessary to address these concerns.\nIn this work, we presented an overview of the modelbased methods proposed recently for bi-objective optimization of data-parallel applications on modern HPC platforms for performance and energy. The methods use workload distribution as the decision variable. However, the methods are sequential and exhibit exorbitant execution times for even moderate input values of the number of available processors. Based on our overview, we highlighted two fundamental challenges to accelerating the methods: (a). Fast computation of Pareto-optimal solutions optimizing the application for performance and energy, and (b). Fast construction of performance and energy profiles that are discrete functions of workload size.\nWe then formulated the bi-objective optimization problem of data-parallel applications for performance and energy on a cluster of p identical hybrid nodes, each containing h heterogeneous processors. The problem employs workload distribution as the decision variable. We proposed two algorithms that address the first challenge, the fast computation of Pareto-optimal solutions. The first algorithm is an exact sequential algorithm that is more efficient and amenable to parallelization. It achieves a complexity reduction over the state-ofthe-art sequential algorithm that has the lower bound of O(m \u00d7 h) where m is the cardinality of the input discrete execution time and dynamic energy functions. It returns the Pareto-optimal set of workload distributions, minimizing the execution time and the total energy consumption of computations during the parallel execution of the application.\nThe second algorithm is a parallel algorithm executed by q identical parallel processs that reduces the com-\nVOLUME 10, 2022 19\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nplexity of our proposed sequential algorithm by O(q) and therefore achieves a complexity reduction that has the lower bound of O(m\u00d7h\u00d7q) over the state-of-the-art sequential algorithm.\nWe experimentally studied the practical efficacy of our algorithms for two data-parallel applications, matrix multiplication and fast Fourier transform, on a state-ofthe-art heterogeneous hybrid node containing an Intel Haswell multicore CPU, an Nvidia k40c GPU, and an Nvidia P100 GPU and simulations of clusters of such hybrid nodes. The experiments demonstrated that our proposed algorithms provide tremendous speedups over the state-of-the-art sequential algorithm.\nThe software implementations of the algorithms proposed in this paper can be downloaded from the URL [60].\nACKNOWLEDGMENT This publication has emanated from research conducted with the financial support of Sustainable Energy Authority of Ireland (SEAI) under Grant Number 21/RDD/664 and Science Foundation Ireland (SFI) under the SFI Frontiers for the Future Programme 20/FFP-P/8683.\nREFERENCES [1] M. Mezmaz, N. Melab, Y. Kessaci, Y. Lee, E.-G. Talbi,\nA. Zomaya, and D. Tuyttens, \u201cA parallel bi-objective hybrid metaheuristic for energy-aware scheduling for cloud computing systems,\u201d Journal of Parallel and Distributed Computing, vol. 71, no. 11, pp. 1497\u20131508, 2011. [2] J. Ko\u0142odziej, S. U. Khan, L. Wang, and A. Y. Zomaya, \u201cEnergy efficient genetic-based schedulers in computational grids,\u201d Concurrency and Computation: Practice and Experience, vol. 27, no. 4, pp. 809\u2013829, Mar. 2015. [3] R. Lucas and et al., \u201cDOE advanced scientific computing advisory subcommittee (ASCAC) report: Top ten exascale research challenges,\u201d 2 2014. [Online]. Available: https: //www.osti.gov/biblio/1222713 [4] F. D. Rossi, M. G. Xavier, C. A. De Rose, R. N. Calheiros, and R. Buyya, \u201cE-eco: Performance-aware energy-efficient cloud data center orchestration,\u201d Journal of Network and Computer Applications, vol. 78, pp. 83\u201396, 2017. [5] Y. Kessaci, N. Melab, and E.-G. Talbi, \u201cA pareto-based metaheuristic for scheduling HPC applications on a geographically distributed cloud federation,\u201d Cluster Computing, vol. 16, no. 3, pp. 451\u2013468, Sep. 2013. [6] J. J. Durillo, V. Nae, and R. Prodan, \u201cMulti-objective energyefficient workflow scheduling using list-based heuristics,\u201d Future Generation Computer Systems, vol. 36, pp. 221\u2013236, 2014. [7] L. Yu, Z. Zhou, S. Wallace, M. E. Papka, and Z. Lan, \u201cQuantitative modeling of power performance tradeoffs on extreme scale systems,\u201d Journal of Parallel and Distributed Computing, vol. 84, pp. 1\u201314, 2015. [8] N. Gholkar, F. Mueller, and B. Rountree, \u201cPower tuning HPC jobs on power-constrained systems,\u201d in Proceedings of the 2016 International Conference on Parallel Architectures and Compilation, ser. PACT \u201916. Association for Computing Machinery, 2016, p. 179\u2013191. [9] B. Rountree, D. K. Lowenthal, S. Funk, V. W. Freeh, B. R. de Supinski, and M. Schulz, \u201cBounding energy consumption in large-scale MPI programs,\u201d in Proceedings of the 2007 ACM/IEEE Conference on Supercomputing, ser. SC \u201907. Association for Computing Machinery, 2007.\n[10] A. Lastovetsky, L. Szustak, and R. Wyrzykowski, \u201cModelbased optimization of EULAG kernel on Intel Xeon Phi through load imbalancing,\u201d IEEE Transactions on Parallel and Distributed Systems, vol. 28, no. 3, pp. 787\u2013797, 2017. [11] A. Lastovetsky and R. Reddy, \u201cNew model-based methods and algorithms for performance and energy optimization of data parallel applications on homogeneous multicore clusters,\u201d IEEE Transactions on Parallel and Distributed Systems, vol. 28, no. 4, pp. 1119\u20131133, 2017. [12] R. Reddy and A. Lastovetsky, \u201cBi-objective optimization of data-parallel applications on homogeneous multicore clusters for performance and energy,\u201d IEEE Transactions on Computers, vol. 64, no. 2, pp. 160\u2013177, 2018. [13] A. Chakrabarti, S. Parthasarathy, and C. Stewart, \u201cA pareto framework for data analytics on heterogeneous systems: Implications for green energy usage and performance,\u201d in Parallel Processing (ICPP), 2017 46th International Conference on. IEEE, 2017, pp. 533\u2013542. [14] S. Khokhriakov, R. R. Manumachu, and A. Lastovetsky, \u201cMulticore processor computing is not energy proportional: An opportunity for bi-objective optimization for energy and performance,\u201d Applied Energy, vol. 268, p. 114957, 2020. [15] H. Khaleghzadeh, M. Fahad, A. Shahid, R. R. Manumachu, and A. Lastovetsky, \u201cBi-objective optimization of data-parallel applications on heterogeneous HPC platforms for performance and energy through workload distribution,\u201d IEEE Transactions on Parallel and Distributed Systems, vol. 32, no. 3, pp. 543\u2013560, 2021. [16] R. R. Manumachu and A. L. Lastovetsky, \u201cParallel data partitioning algorithms for optimization of data-parallel applications on modern extreme-scale multicore platforms for performance and energy,\u201d IEEE Access, vol. 6, pp. 69 075\u2013 69 106, 2018. [17] M. Fahad, A. Shahid, R. R. Manumachu, and A. Lastovetsky, \u201cAccurate energy modelling of hybrid parallel applications on modern heterogeneous computing platforms using systemlevel measurements,\u201d IEEE Access, vol. 8, pp. 93 793\u201393 829, 2020. [18] Z. Zhong, V. Rychkov, and A. Lastovetsky, \u201cData partitioning on multicore and multi-GPU platforms using functional performance models,\u201d Computers, IEEE Transactions on, vol. 64, no. 9, pp. 2506\u20132518, 2015. [19] M. Fahad, A. Shahid, R. R. Manumachu, and A. Lastovetsky, \u201cA comparative study of methods for measurement of energy of computing,\u201d Energies, vol. 12, no. 11, p. 2204, 2019. [20] A. Shahid, M. Fahad, R. R. Manumachu, and A. L. Lastovetsky, \u201cEnergy predictive models of computing: Theory, practical implications and experimental analysis on multicore processors,\u201d IEEE Access, vol. 9, pp. 63 149\u201363 172, 2021. [21] A. Shahid, M. Fahad, R. R. Manumachu, and A. Lastovetsky, \u201cImproving the accuracy of energy predictive models for multicore CPUs by combining utilization and performance events model variables,\u201d Journal of Parallel and Distributed Computing, vol. 151, pp. 38\u201351, 05/2021 2021. [22] H. Khaleghzadeh, Z. Zhong, R. Reddy, and A. Lastovetsky, \u201cOut-of-core implementation for accelerator kernels on heterogeneous clouds,\u201d The Journal of Supercomputing, vol. 74, no. 2, pp. 551\u2013568, 2018. [23] V. W. Freeh, D. K. Lowenthal, F. Pan, N. Kappiah, R. Springer, B. L. Rountree, and M. E. Femal, \u201cAnalyzing the energy-time trade-off in high-performance computing applications,\u201d IEEE Transactions on Parallel and Distributed Systems, vol. 18, no. 6, pp. 835\u2013848, 2007. [24] B. Rountree, D. K. Lowenthal, B. R. de Supinski, M. Schulz, V. W. Freeh, and T. Bletsch, \u201cAdagio: Making DVS practical for complex HPC applications,\u201d in Proceedings of the 23rd International Conference on Supercomputing, ser. ICS \u201909. Association for Computing Machinery, 2009, p. 460\u2013469. [25] Y. C. Lee and A. Y. Zomaya, \u201cEnergy conscious scheduling for distributed computing systems under different operating conditions,\u201d IEEE Transactions on Parallel and Distributed Systems, vol. 22, no. 8, pp. 1374\u20131381, 2011. [26] H. M. Fard, R. Prodan, J. J. D. Barrionuevo, and T. Fahringer, \u201cA multi-objective approach for workflow"
        },
        {
            "heading": "20 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nscheduling in heterogeneous environments,\u201d in 2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (ccgrid 2012), ser. CCGRID \u201912. IEEE Computer Society, 2012, pp. 300\u2013309. [27] A. Beloglazov, J. Abawajy, and R. Buyya, \u201cEnergy-aware resource allocation heuristics for efficient management of data centers for cloud computing,\u201d Future Generation Computer Systems, vol. 28, no. 5, pp. 755\u2013768, 2012, special Section: Energy efficiency in large-scale distributed systems. [28] J. Demmel, A. Gearhart, B. Lipshitz, and O. Schwartz, \u201cPerfect strong scaling using no additional energy,\u201d in 2013 IEEE 27th International Symposium on Parallel and Distributed Processing, 2013, pp. 649\u2013660. [29] M. Drozdowski, J. M. Marszalkowski, and J. Marszalkowski, \u201cEnergy trade-offs analysis using equal-energy maps,\u201d Future Generation Computer Systems, vol. 36, pp. 311\u2013321, 2014. [30] J. M. Marsza\u0142kowski, M. Drozdowski, and J. Marsza\u0142kowski, \u201cTime and energy performance of parallel systems with hierarchical memory,\u201d Journal of Grid Computing, vol. 14, no. 1, pp. 153\u2013170, 2016. [31] L. A. Barroso and U. H\u00f6lzle, \u201cThe case for energyproportional computing,\u201d Computer, no. 12, pp. 33\u201337, 2007. [32] Y. Ogata, T. Endo, N. Maruyama, and S. Matsuoka, \u201cAn efficient, model-based CPU-GPU heterogeneous FFT library,\u201d in Parallel and Distributed Processing, 2008. IPDPS 2008. IEEE International Symposium on. IEEE, 2008, pp. 1\u201310. [33] C. Yang, F. Wang, Y. Du, J. Chen, J. Liu, H. Yi, and K. Lu, \u201cAdaptive optimization for petascale heterogeneous CPU/GPU computing,\u201d in Cluster Computing (CLUSTER), 2010 IEEE International Conference on. IEEE, 2010, pp. 19\u201328. [34] A. Lastovetsky and R. Reddy, \u201cData partitioning with a functional performance model of heterogeneous processors,\u201d International Journal of High Performance Computing Applications, vol. 21, no. 1, pp. 76\u201390, 2007. [35] T. Gautier, X. Besseron, and L. Pigeon, \u201cKAAPI: A thread scheduling runtime system for data flow computations on cluster of multi-processors,\u201d ser. Proceedings of the 2007 International Workshop on Parallel Symbolic Computation. ACM, 2007, pp. 15\u201323. [36] C. Augonnet, S. Thibault, R. Namyst, and P.-A. Wacrenier, \u201cStarPU: A unified platform for task scheduling on heterogeneous multicore architectures,\u201d Concurrency: Practice and Experience, vol. 23, no. 2, pp. 187\u2013198, Feb. 2011. [37] G. Bosilca, A. Bouteiller, A. Danalis, T. Herault, P. Lemarinier, and J. Dongarra, \u201cDAGuE: A generic distributed DAG engine for high performance computing,\u201d ser. 2011 IEEE IPDPSW, May 2011, pp. 1151\u20131158. [38] M. D. Linderman, J. D. Collins, H. Wang, and T. H. Meng, \u201cMerge: a programming model for heterogeneous multi-core systems,\u201d ser. ACM SIGOPS operating systems review, vol. 42, no. 2. ACM, 2008, pp. 287\u2013296. [39] G. Quintana-Ort\u00ed, F. D. Igual, E. S. Quintana-Ort\u00ed, and R. A. van de Geijn, \u201cSolving dense linear systems on platforms with multiple hardware accelerators,\u201d SIGPLAN Notices, vol. 44, no. 4, pp. 121\u2013130, Feb. 2009. [40] C. Augonnet, S. Thibault, and R. Namyst, \u201cAutomatic Calibration of Performance Models on Heterogeneous Multicore Architectures,\u201d ser. 3rd Workshop on Highly Parallel Processing on a Chip (HPPC 2009), Aug. 2009. [41] K. Schloegel, G. Karypis, and V. Kumar, \u201cA unified algorithm for load-balancing adaptive scientific simulations,\u201d ser. Supercomputing, ACM/IEEE 2000 Conference, Nov 2000, pp. 59\u201359. [42] U. V. Catalyurek, E. G. Boman, K. D. Devine, D. Bozdag, R. Heaphy, and L. A. Riesen, \u201cHypergraph-based dynamic load balancing for adaptive scientific computations,\u201d ser. IEEE International Parallel and Distributed Processing Symposium (IPDPS). IEEE, 2007, pp. 1\u201311. [43] D. Clarke, A. Lastovetsky, and V. Rychkov, \u201cDynamic load balancing of parallel computational iterative routines on highly heterogeneous HPC platforms,\u201d Parallel Processing Letters, vol. 21, pp. 195\u2013217, 06/2011 2011.\n[44] R. Reddy Manumachu and A. L. Lastovetsky, \u201cDesign of self-adaptable data parallel applications on multicore clusters automatically optimized for performance and energy through load distribution,\u201d Concurrency and Computation: Practice and Experience, vol. 31, no. 4, p. e4958, 2019. [45] K.-H. Kim, K. Kim, and Q.-H. Park, \u201cPerformance analysis and optimization of three-dimensional FDTD on GPU using roofline model,\u201d Computer Physics Communications, vol. 182, no. 6, pp. 1201\u20131207, 2011. [46] J. Shen, A. L. Varbanescu, Y. Lu, P. Zou, and H. Sips, \u201cWorkload partitioning for accelerating applications on heterogeneous platforms,\u201d IEEE Transactions on Parallel and Distributed Systems, vol. 27, no. 9, pp. 2766\u20132780, 2016. [47] A. Kalinov and A. Lastovetsky, \u201cHeterogeneous distribution of computations solving linear algebra problems on networks of heterogeneous computers,\u201d Journal of Parallel and Distributed Computing, vol. 61, no. 4, pp. 520 \u2013 535, 2001. [48] O. Beaumont, V. Boudet, F. Rastello, and Y. Robert, \u201cMatrix multiplication on heterogeneous platforms,\u201d IEEE Trans. Parallel Distrib. Syst., vol. 12, no. 10, Oct. 2001. [49] A. Lastovetsky and R. Reddy, \u201cData partitioning for multiprocessors with memory heterogeneity and memory constraints,\u201d Scientific Programming, vol. 13, no. 2, pp. 93\u2013112, 2005. [50] T. Heath, B. Diniz, B. Horizonte, E. V. Carrera, and R. Bianchini, \u201cEnergy conservation in heterogeneous server clusters,\u201d in 10th ACM SIGPLAN symposium on Principles and practice of parallel programming (PPoPP). ACM, 2005, pp. 186\u2013195. [51] D. Economou, S. Rivoire, C. Kozyrakis, and P. Ranganathan, \u201cFull-system power analysis and modeling for server environments,\u201d in In Proceedings of Workshop on Modeling, Benchmarking, and Simulation, 2006, pp. 70\u201377. [52] X. Fan, W.-D. Weber, and L. A. Barroso, \u201cPower provisioning for a warehouse-sized computer,\u201d in 34th Annual International Symposium on Computer architecture. ACM, 2007, pp. 13\u201323. [53] R. Bertran, M. Gonzalez, X. Martorell, N. Navarro, and E. Ayguade, \u201cDecomposable and responsive power models for multicore processors using performance counters,\u201d in Proceedings of the 24th ACM International Conference on Supercomputing. ACM, 2010, pp. 147\u2013158. [54] R. Basmadjian, N. Ali, F. Niedermeier, H. de Meer, and G. Giuliani, \u201cA methodology to predict the power consumption of servers in data centres,\u201d in 2nd International Conference on Energy-Efficient Computing and Networking. ACM, 2011. [55] S. Hong and H. Kim, \u201cAn integrated GPU power and performance model,\u201d p. 280\u2013289, 2010. [56] C. Isci and M. Martonosi, \u201cRuntime power monitoring in high-end processors: Methodology and empirical data,\u201d in 36th annual IEEE/ACM International Symposium on Microarchitecture. IEEE Computer Society, 2003, p. 93. [57] H. Nagasaka, N. Maruyama, A. Nukada, T. Endo, and S. Matsuoka, \u201cStatistical power modeling of GPU kernels using performance counters,\u201d in International Green Computing Conference and Workshops (IGCC). IEEE, 2010. [58] S. Song, C. Su, B. Rountree, and K. W. Cameron, \u201cA simplified and accurate model of power-performance efficiency on emergent GPU architectures,\u201d in 27th IEEE International Parallel and Distributed Processing Symposium (IPDPS). IEEE Computer Society, 2013, pp. 673\u2013686. [59] Y. S. Shao and D. Brooks, \u201cEnergy characterization and instruction-level energy model of Intel\u2019s Xeon Phi processor,\u201d in Proceedings of the 2013 International Symposium on Low Power Electronics and Design, ser. ISLPED \u201913. IEEE Press, 2013. [60] R. R. Manumachu and A. Lastovetsky, \u201cPAREPOPT: Dynamic performance-energy optimization of dataparallel applications on hybrid nodes through workload distribution,\u201d 2022. [Online]. Available: https://csgitlab.ucd. ie/manumachu/parepopt\nVOLUME 10, 2022 21\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nReddy et al.: Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms\nRAVI REDDY MANUMACHU received a B.Tech degree from I.I.T, Madras in 1997 and a PhD degree from the School of Computer Science, University College Dublin in 2005. His main research interests include high performance heterogeneous computing and energy-efficient computing.\nHAMIDREZA KHALEGHZADEH received the B.Sc. and M.Sc. degrees in computer engineering (software) in 2007 and 2011, respectively, and the Ph.D from the School of Computer Science, University College Dublin, in 2019. His research interests include performance and energy consumption optimization in massively heterogeneous systems, high-performance heterogeneous systems, energy efficiency, and paral-\nlel/distributed computing.\nALEXEY LASTOVETSKY received a Ph.D. degree from the Moscow Aviation Institute in 1986, and a Doctor of Science degree from the Russian Academy of Sciences in 1997. His main research interests include high performance heterogeneous computing and energy-efficient computing. He is currently Associate Professor in the School of Computer Science at University College Dublin (UCD). At UCD, he is also the founding Di-\nrector of the Heterogeneous Computing Laboratory. He authored the monographs Parallel computing on heterogeneous networks (Wiley, 2003) and High performance heterogeneous computing (Wiley, 2009)."
        },
        {
            "heading": "22 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/"
        }
    ],
    "title": "Acceleration of Bi-objective Optimization of Data-parallel Applications for Performance and Energy on Heterogeneous Hybrid Platforms",
    "year": 2023
}