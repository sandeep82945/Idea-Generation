{
    "abstractText": "This paper proposes a class of basis functions for realizing the input-tostate stability verification of identified models obtained from the true system (assumed to be input-to-state stable) using the Koopman operator. The formulated input-to-state stability conditions are in the form of linear matrix inequalities. We also present extensions to relax the imposed restrictions on the basis functions. A numerical example is provided to demonstrate the efficacy of the proposed results.",
    "authors": [
        {
            "affiliations": [],
            "name": "Wenjie Mei"
        },
        {
            "affiliations": [],
            "name": "Yu Zhou"
        },
        {
            "affiliations": [],
            "name": "Ahmad Taha"
        },
        {
            "affiliations": [],
            "name": "Chengyan Zhao"
        }
    ],
    "id": "SP:83e1818bb29e06ea48aaaa2a3f1e5adf554bb96e",
    "references": [
        {
            "authors": [
                "B.O. Koopman"
            ],
            "title": "Hamiltonian systems and transformation in Hilbert space",
            "venue": "Proceedings of the National Academy of Sciences 17 (5) ",
            "year": 1931
        },
        {
            "authors": [
                "I. Mezi\u0107"
            ],
            "title": "Spectral properties of dynamical systems",
            "venue": "model reduction and decompositions, Nonlinear Dynamics 41 ",
            "year": 2005
        },
        {
            "authors": [
                "M. Korda",
                "I. Mezi\u0107"
            ],
            "title": "Linear predictors for nonlinear dynamical systems: Koopman operator meets model predictive control",
            "venue": "Automatica 93 ",
            "year": 2018
        },
        {
            "authors": [
                "A.S. Dogra",
                "W. Redman"
            ],
            "title": "Optimizing neural networks via Koopman operator theory",
            "venue": "Advances in Neural Information Processing Systems 33 ",
            "year": 2020
        },
        {
            "authors": [
                "L.A. Zadeh"
            ],
            "title": "From circuit theory to system theory",
            "venue": "Proceedings of the IRE 50 (5) ",
            "year": 1962
        },
        {
            "authors": [
                "D. Efimov",
                "A.Y. Aleksandrov"
            ],
            "title": "Robust stability analysis and implementation of Persidskii systems",
            "venue": "in: 2019 IEEE 58th Conference on Decision and Control (CDC), IEEE",
            "year": 2019
        },
        {
            "authors": [
                "M.O. Williams",
                "I.G. Kevrekidis",
                "C.W. Rowley"
            ],
            "title": "A Data-Driven Approximation of the Koopman Operator: Extending Dynamic Mode Decomposition",
            "venue": "Journal of Nonlinear Science 25 (6) ",
            "year": 2015
        },
        {
            "authors": [
                "A. Mauroy",
                "J. Goncalves"
            ],
            "title": "Linear identification of nonlinear systems: A lifting technique based on the Koopman operator",
            "venue": "in: 2016 IEEE 55th Conference on Decision and Control (CDC), IEEE",
            "year": 2016
        },
        {
            "authors": [
                "D. Bruder",
                "C.D. Remy",
                "R. Vasudevan"
            ],
            "title": "Nonlinear System Identification of Soft Robot Dynamics Using Koopman Operator Theory",
            "venue": "in: 2019 International Conference on Robotics and Automation (ICRA), IEEE",
            "year": 2019
        },
        {
            "authors": [
                "C. Zhang",
                "E. Zuazua"
            ],
            "title": "A quantitative analysis of Koopman operator methods for system identification and predictions",
            "venue": "Comptes Rendus. M\u00e9canique 351 (S1) ",
            "year": 2023
        },
        {
            "authors": [
                "S.L. Lacy",
                "D.S. Bernstein"
            ],
            "title": "Subspace identification with guaranteed stability using constrained optimization",
            "venue": "IEEE Transactions on automatic control 48 (7) ",
            "year": 2003
        },
        {
            "authors": [
                "M. Vidyasagar"
            ],
            "title": "Input-output analysis of large-scale interconnected systems",
            "venue": "Vol. 29 of Lecture Notes in Control and Information Sciences, Springer-Verlag, Berlin",
            "year": 1981
        },
        {
            "authors": [
                "E.D. Sontag",
                "Y. Wang"
            ],
            "title": "New characterizations of input-to-state stability",
            "venue": "IEEE transactions on automatic control 41 (9) ",
            "year": 1996
        },
        {
            "authors": [
                "E.D. Sontag",
                "Y. Wang"
            ],
            "title": "On characterizations of input-to-state stability with respect to compact sets",
            "venue": "IFAC Proceedings Volumes 28 ",
            "year": 1995
        },
        {
            "authors": [
                "W. Mei",
                "D. Efimov",
                "R. Ushirobira"
            ],
            "title": "On annular short-time stability conditions for generalized persidskii systems",
            "venue": "International Journal of Control (just-accepted) ",
            "year": 2023
        },
        {
            "authors": [
                "K. Hornik"
            ],
            "title": "Approximation capabilities of multilayer feedforward networks",
            "venue": "Neural networks 4 (2) ",
            "year": 1991
        },
        {
            "authors": [
                "J.A. Bullinaria"
            ],
            "title": "Recurrent neural networks",
            "venue": "Neural Computation: Lecture 12 ",
            "year": 2013
        },
        {
            "authors": [
                "W. Mei",
                "D. Efimov",
                "R. Ushirobira"
            ],
            "title": "On input-to-output stability and robust synchronization of generalized Persidskii systems",
            "venue": "IEEE Transactions on Automatic Control ",
            "year": 2021
        },
        {
            "authors": [
                "S.A. Nugroho",
                "A.F. Taha",
                "C.G. Claudel"
            ],
            "title": "A control-theoretic approach for scalable and robust traffic density estimation using convex optimization",
            "venue": "IEEE Transactions on Intelligent Transportation Systems 22 (1) ",
            "year": 2019
        },
        {
            "authors": [
                "M.J. Lighthill",
                "G.B. Whitham"
            ],
            "title": "On kinematic waves ii",
            "venue": "a theory of traffic flow on long crowded roads, Proceedings of the Royal Society of London. Series A. Mathematical and Physical Sciences 229 ",
            "year": 1955
        },
        {
            "authors": [
                "J.-P. Lebacque"
            ],
            "title": "The godunov scheme and what it means for first order traffic flow models",
            "venue": "in: Internaional Symposium on Transportation and Traffic Theory",
            "year": 1996
        },
        {
            "authors": [
                "A. Mauroy",
                "I. Mezi\u0107"
            ],
            "title": "Y",
            "venue": "Susuki (Eds.), The Koopman Operator in Systems and Control, Vol. 484 of Lecture Notes in Control and Information Sciences, Springer International Publishing, Cham",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "This paper proposes a class of basis functions for realizing the input-tostate stability verification of identified models obtained from the true system (assumed to be input-to-state stable) using the Koopman operator. The formulated input-to-state stability conditions are in the form of linear matrix inequalities. We also present extensions to relax the imposed restrictions on the basis functions. A numerical example is provided to demonstrate the efficacy of the proposed results.\nKeywords: Basis functions, input-to-state stability verification, Koopman operator"
        },
        {
            "heading": "1. Introduction",
            "text": "It has become more facile to collect or measure data from networks/dynamics in recent years, making data-driven methods popular tools in technical systems. For nonlinear control applications, the identification problems may become intractable and, indeed, complex for implementation, especially under significant noise or uncertainty. To that end, a theoretic framework called Koopman operator [1] has been exploited for lifting complicated nonlinear dynamical systems to linear models with higher dimensions, which can be utilized for prediction, control, and stability analysis.\nPreprint submitted to Journal of the Franklin Institute September 6, 2023\nar X\niv :2\n30 9.\n01 24\n2v 1\n[ ee\nss .S\nSuch a framework is frequently combined with data-driven methods. Specifically, the collected data from the system trajectory may be used to approximate the Koopman operator, making the application of the Koopman operator more viable. Various related investigations can be found in the directions of its spectral properties [2], linear predictors [3], and neural network training [4], to mention a few examples.\nIn this work, under the realized system identification (defined as the determination, based on the measured input/output data, of a system model within a specified class of dynamics [5]) of nonlinear systems (they can be well approximated by \u201cquasi generalized Persidskii systems\u201d [6]), we focus on the stability verification problem in the identified model derived by the Koopman operator theory and its conjunction with a useful data-driven method, namely the extended dynamic mode decomposition (EDMD) [7]. One can find that there are studies involved in system identification in the context of the Koopman operator in recent years, such as the adaption of Koopman operator theory to identification [8] and its application to soft robots [9]; the investigation on the convergence of a variant of the generator EDMD algorithm [10] for calculating a linear representation of the operator. Nevertheless, there still exist many gaps in the stability verification issue in identified models (the true system is assumed to be stable) under the employment of the Koopman operator theory.\nFor that purpose, this paper proposes a general scheme to examine if an identified system modeled via the Koopman operator technique is inputto-state stable. To the author\u2019s knowledge, rare studies have addressed the stability analysis problem of identified systems obtained by using the Koopman operator theory. That is, in practice, the true system is usually assumed to be input-to-state stable. However, due to many factors, such as noise and modeling errors, the input-to-state stability (ISS) of identified models can not be guaranteed. This motivated the works of stability guarantees presented in, for example, [11] and this paper.\nDue to the intricate forms and possibly highly dynamic nature of nonlinear systems, especially in the presence of external perturbations, the stability analyses may be difficult [12]. Among them, the most widely utilized framework is the ISS concept [13, 14]. As stated above, the stability analysis of an identified model could also be tricky since it can be a nonlinear system taking an unpredictable, thus probably complex form. However, the ISS of the true system is necessary for robustness and makes system identification practical [11]. These inspire us to tackle the target problem in this paper.\nThe main contributions of this work can be summarized as follows: i) If one selects basis functions for the identification as in complex forms, even if only one of them does, the ISS analysis of the resulting identified system (for example, with many nonlinearities) can still be laborious. To that end, we introduce a class of basis functions (they can be linear or nonlinear in generalized Persidskii dynamics) to facilitate the relevant stability analysis since it serves the adaptable number of nonlinearities under the preservation of the generality of the functions. ii) Since it is also beneficial to relax the imposed conditions on the basis function, we present two extensions from the considered kind of functions for enlarging the selection range. By doing this, the analyzable forms of the identified system can be further expanded. iii) Under a mild assumption (Assumption 1 in this note), we bridge the considered class of nonlinear systems with the actual system. This enables us to skip the obstruction in approximating the differentiation of the input but only focus on being involved in identifying the vector field of the true system.\nThe rest of this work is organized as follows. The lifting approach, the data-driven method for calculating Koopman operators, and the class of nonlinear systems under consideration are all provided in Section 2. Section 4 presents the ISS conditions of identified systems, followed by introducing two extending forms of the basis functions. In Section 5, we show an example to illustrate the efficiency of the proposed results. The notation is provided next:\nN, Z and R represent the sets of natural numbers, integers and real numbers, respectively, R+ = {s \u2208 R | s \u2265 0}; Rn and Rm\u00d7n denote the vector spaces of n-tuples of real numbers and m \u00d7 n real matrices, respectively. The symbol \u2225\u00b7\u2225 refers to the Euclidean norm on Rn (and the induced matrix norm \u2225A\u2225 (or the Frobenius norm \u2225A\u2225F ) for a matrix A \u2208 Rm\u00d7n). The set of n\u00d7 n diagonal matrices (with nonnegative diagonal elements) is denoted by Dn (Dn+). We let Op\u00d7n refer to the p \u00d7 n zero matrix. For p, n \u2208 N with p \u2264 n, the notation p, n is used to represent the set {p, p + 1, . . . , n}; p mod n is the remainder of the Euclidean division of p by n. vec(A) represents the vectorization of a matrix Am\u00d7n; for a vector \u2113 \u2208 Rmn, vec\u22121m\u00d7n(\u2113) = (vec(In)\n\u22a4\u2297Im)(In\u2297\u2113) \u2208 Rm\u00d7n, where In denotes the n\u00d7n identity matrix and \u2297 denotes the Kronecker product. Let \u230a\u00b7\u230b represent the floor function defined on R. C(U,R) denotes the space of continuous functions f : U \u2192 R, where U,R are metric spaces. For t1, t2 \u2208 R, with t1 < t2, we denote by C1n([t1, t2)) the Banach space of continuously differentiable functions \u03c8 : [t1, t2) \u2192 Rn\nwith the norm \u2225\u03c8\u2225[t1,t2) = supr\u2208[t1,t2) \u2225\u03c8(r)\u2225+ supr\u2208[t1,t2) \u2225 d\u03c8(r) dr \u2225 < +\u221e."
        },
        {
            "heading": "2. Preliminaries",
            "text": "This section introduces the lifting approach based on utilizing the Koopman operator, which can be represented as a matrix after projection. Based on that, the relationship between the Koopman operator and system identification is clarified. Then, the Extended Dynamic Mode Decomposition (EDMD) algorithm (see e.g., [7]) is shown for approximating the Koopman operator so that a system identification can be realized."
        },
        {
            "heading": "2.1. Koopman operator via a matrix",
            "text": "Following the definitions given in the Appendices, for brevity, consider rewriting system (.1) to the dynamics\n\u03c7\u0307(t) = F\u0303 (\u03c7(t)) :=\n[ F (x(t), u(t))\nu\u0307(t)\n] , t \u2208 R+ (1)\nwith an extended state \u03c7 = [ x\u22a4 u\u22a4 ]\u22a4 \u2208 Rn+m, which admits a unique solution \u03c7t(\u03c70) for any initial condition \u03c70 \u2208 Rn+m defined for t \u2208 [0, T\u03c70) with some T\u03c70 > 0. Then, the Koopman operator theory states that\nKtH\u0303 = H\u0303 \u25e6 \u03c7t,\nwhere H\u0303 : Rn \u00d7 Rm \u2192 R are observable functions in a space H\u0303 and Kt is the Koopman operator. In order to define a procedure for lifting the dimension of the model (1) for using the data-driven method that will be presented in the sequel, we need to introduce a finite-dimensional subspace of H\u0303: H\u0303NH := span {H1(\u03c7) . . . HNH (\u03c7)} spanned by NH linear independent scalar-valued functions H1, . . . , HNH , which are called lifting functions [9]. Then the projection of H\u0303 onto the space H\u0303NH (\u2282 H\u0303) can be expressed as:\nP H\u0303(\u03c7) = a\u22a4  H1(\u03c7)... HNH (\u03c7)  := a\u22a4P (\u03c7) \u2208 R, a \u2208 RNH , and\nP KtH\u0303(\u03c7) = b\u22a4P (\u03c7) \u2208 R, b \u2208 RNH , (2)\nwhere P (\u03c7) = [H1(\u03c7) . . . HNH (\u03c7)] \u22a4 and P : H\u0303 \u2192 H\u0303NH is a projection operator. Note that to get (2), we used a property of the operator P, i.e., Kt : H\u0303NH \u2192 H\u0303, such that Krepa = b, where the matrix Krep is a representation of Kt [8].\nIn short, the matrix Krep is a linear representation of the nonlinear dynamic system (1). It can be calculated numerically using data-driven approaches, such as the EDMD, which will be briefly introduced later. Notice that if one selects lifting functions under the restriction of Kt-invariance, i.e., Kt(H\u0303NH ) = H\u0303NH , then in (2) the projection operator P can be ignored."
        },
        {
            "heading": "2.2. Connecting Koopman operator and system identification",
            "text": "In this subsection, the relationship between the Koopman operator and system identification [8] is clarified, illustrating how to identify the vector field F\u0303 by applying the Koopman operator technique.\nFor system (1), assume that the function F\u0303i can be projected onto the space H\u0303NF (here H\u0303NF := span {G1(\u03c7) . . . GNF (\u03c7)} with the linear independent basis functions G1 . . . GNF ; note that NF is not necessarily equal to NH) as\nF\u0303i(\u03c7) = NF\u2211 j=1 \u03bbijGj(\u03c7), \u2200i \u2208 1, n+m, (3)\nwhere F\u0303i is the i-th element of the function F\u0303 defined in (1). By the Koopman operator theory, there is a Koopman infinitesimal generator L =\u2211n+m\ni=1 \u2211NF j=1 \u03bbijLij with the operators Lij = Gj \u00b7 \u2202 \u2202\u03c7i such that\nP\u0307 (\u03c7) = n+m\u2211 i=1 \u03c7\u0307i \u00b7 \u2202P (\u03c7) \u2202\u03c7i = n+m\u2211 i=1 F\u0303i \u00b7 \u2202P (\u03c7) \u2202\u03c7i\n= n+m\u2211 i=1 NF\u2211 j=1 (\u03bbijGj) \u00b7 \u2202P (\u03c7) \u2202\u03c7i = n+m\u2211 i=1 NF\u2211 j=1 \u03bbij ( Gj \u00b7 \u2202P (\u03c7) \u2202\u03c7i ) = LP (\u03c7),\nwhich is a linear system so that\nP (\u03c7(T + t)) = eLtP (\u03c7(T )) = KtP (\u03c7(T )). (4)\nUntil now, we have introduced the linear operator Kt and demonstrated the connections among the Koopman operator Kt, the generators Lij and\nthe identification of F\u0303 , for the implementation of the system identification procedures, the forms of Gj should be properly selected by a designer. The remaining part of this section provides a way to calculate the values of \u03bbij to actualize a system identification.\nNote that the operator L can also be represented as a matrix\nLrep = n+m\u2211 i=1 NF\u2211 j=1 \u03bbijLij, rep, (5)\nwhich usually can be computed by\nLrep = 1\nt ln(Krep), (6)\ndue to (4). In addition, by the relation (5), it can be deduced that \u0393 := [ \u03bb11 . . . \u03bb1NF . . . \u03bb(m+n)1 . . . \u03bb(m+n)NF ]\u22a4 (7)\n= [ vec(L11, rep) . . . vec(L1NF , rep) . . .\nvec(L(n+m)1, rep) . . . vec(L(n+m)NF , rep) ]\u2020 vec(Lrep).\nWe will describe how Krep, Lrep can be obtained by the EDMD algorithm in the next section. Thus, if one has the values of Lij, rep, then it is direct to get the parameters \u03bbij from (7).\nIt is worth mentioning here that, in practice preserving the Kt-invariance is challenging since each operator Lij generates terms that may increase the amount of linear independent lifting functions in the resulting space (see, e.g., in (2), the Koopman operator Kt : H\u0303NH \u2192 H\u0303 and H\u0303NH \u2282 H\u0303). Then the idea of this work is that by selecting Gj and the elements Pl of P satisfied the sector condition formulated in Assumption 3 of the Appendices, there always exists an operator Lij such that LijP = Gj \u00b7 \u2202P\u2202\u03c7i since the scalarvalued functions Gj, Pl are in the semigroup (F(R), \u00b7), where F(R) = {f \u2208 C(R,R) | f(0) = 0, \u03bdf(\u03bd) > 0, \u2200 \u03bd \u0338= 0}. This provides a possible scheme to ensure the Kt-invariance in theory, which demonstrates one of the strengths of the criterion of choosing Gj as functions satisfying Assumption 3, whose further merits will be interpreted at length in the sequel."
        },
        {
            "heading": "2.3. Approximating Koopman operator",
            "text": "This section presents a data-driven approach: the EDMD algorithm (see [7] for reference). It can calculate a matrix Krep to represent the Koopman operator.\nFor a given constant sampling time Tc > 0 and a series of the input values {uk}N+1k=1 of length N \u2208 N, collect pairs of the state xk and the output yk of the true system: {(xk, uk), (yk, uk+1)}Nk=1 with uk+1 = \u0398uk, where \u0398 is a left shift operator. Here yk is not necessarily equal to xk+1 = x\nTc(xk, u) due to the existence of measurement noises. In the case that there do not exist such noises, one can assume that yk = x\nTc(xk, u). The EDMD converts an approximation problem to a minimization one as\nfollows:\n(Krep) \u22a4 = argmin\n(Krep)\u22a4 N\u2211 k=1 \u2225\u2225P (yk, uk+1)\u2212 (Krep)\u22a4P (xk, uk)\u2225\u2225F . (8) Then, the corresponding least square solution of (8) can be calculated by\nKrep =  P (x1, u1) \u22a4\n... P (xN , uN) \u22a4\n \u2020  P (y1, u2) \u22a4\n... P (yN , uN+1) \u22a4  , (9) where the symbol \u2020 stands for the pseudoinverse.\nSo far, we have introduced the nonlinear system (.1) into account to give the general definitions of the lifting approach, the Koopman operator and its connection with identification, and the EDMD algorithm."
        },
        {
            "heading": "3. Problem statement",
            "text": "In this paper, we assume that the considered identified models take the form of (generalized) Persidskii dynamics, and the following assumption is imposed on the true system (.1) (see Appendices for the detailed definition of (.1)).\nAssumption 1. Assume that the true system (.1) is ISS and can be presented in the form\nx\u0307 = f(x) +Du, (10)\nwhere f : Rn \u2192 Rn is a vector field and D \u2208 Rn\u00d7m is a constant matrix.\nRemark 1. Note that in this work, we use generalized Persidskii systems to approximate the true system (10). Then, one can see that non-restrictive\n(since (10) is also a general nonlinear system) Assumption 1 makes the identification feasible since the continuous function f can be approximated (or identified) arbitrarily well by a neural network represented by the generalized Persidskii dynamics (see [15] for the details of representing recurrent neural networks by generalized Persidskii systems; also, see Universal Approximation Theorem [16, 17] for the illustration that a recurrent neural network can approximate the function f arbitrarily well).\nOn the other hand, at least the generalized Persidskii system is more adaptable for approximating the true system (10) than the linearization of (10) (locally or globally), considering, for example, x\u0307 = \u2212x tanh(x) + Du = \u2212x2 + x4\n3 \u2212 2x6 15 + \u00b7 \u00b7 \u00b7 + Du, and the latter is a particular case of the for-\nmer one.\nThe main goal of this work is to propose a generic scheme to verify if an identified model obtained by applying the Koopman operator theory is ISS, under the preliminary that the system (10) is ISS and its implicit form is known (i.e. Assumption 1 is verified)."
        },
        {
            "heading": "4. Main results: Basis functions for ISS analysis of identified models",
            "text": "In this section, we propose a novel type of basis functions (they belong to the nonlinearity classes in generalized Persidskii systems) helpful in analyzing the ISS property of an identified model associated with the system (10), which is also the main contribution of this study."
        },
        {
            "heading": "4.1. A class of basis functions",
            "text": "The considered kind of functions Gj (in (3)) is defined as follows.\nDefinition 1. The functions Gj satisfying Assumption 3 are called sector basis functions (SBFs).\nWe then show the usefulness of SBFs in system identification. Firstly, to suppress unnecessary computation of the given input u during the solution process of (8), we further impose that the basis functions take the form Gs(\u03c7) = \u03c6s(x) + \u03c8s(u), s \u2208 1, nM +m, where the functions \u03c6s : Rn \u2192 R and \u03c8s : U \u2192 R. Moreover, let \u03c8s(u) = 0 for s \u2208 1, nM and Gs\u2032(\u03c7) = us\u2032\u2212nM for s\u2032 \u2208 nM + 1, nM +m. We have\nG(\u03c7) := [ \u03c61(x) . . . \u03c6nM(x) u \u22a4]\u22a4 .\nHere NF = nM +m. Then, with conciseness we apply SBFs f\u03031, . . . , f\u0303nM to G(\u03c7) as:\nfj\u2032(x) = \u03c6(j\u2032\u22121)n+1(x)... \u03c6j\u2032n(x)  = f\u0303(j\u2032\u22121)n+1(x1)... f\u0303j\u2032n(xn)  \u2208 Rn for all j\u2032 \u2208 1,M , so\nG(\u03c7) = [ f1(x) . . . fM(x) u ]\u22a4 . (11)\nThe identification of u is not considered since it is given. Hence, without loss of generality and by (3), we deal solely with identifying the vector field F :\nF\u0303 (\u03c7) = [ F (x, u) u\u0307 ] = [ \u03931 ... \u0393M B ... ... ] G(\u03c7),\nleading to\nF (x, u) = M\u2211 j\u2032=1 \u0393j\u2032fj\u2032(x) +Bu,\nwhere\n\u0393j\u2032 = ( vec\u22121n\u00d7n ( Ej\u2032\u0393 ))\u22a4 , Ej\u2032 \u2208 Rn 2\u00d7((m+n)(nM+m)),\n[Ej\u2032 ]ab =  1, if b = \u230a an\u230b(nM +m) + (j \u2032 \u2212 1)n+ a mod n, a mod n \u0338= 0; 1, if b = (\u230a an\u230b \u2212 1)(nM +m) + j \u2032n, a mod n = 0;\n0, otherwise, B = ( vec\u22121m\u00d7n ( B\u0303\u0393 ))\u22a4 , B\u0303 \u2208 R(mn)\u00d7((m+n)(nM+m)),\n[B\u0303]cd =  1, if d = \u230a cm\u230b(nM +m) + nM + c mod m, c mod m \u0338= 0; 1, if d = \u230a cm\u230b(nM +m), c mod m = 0; 0, otherwise.\nHere we recall that the vector \u0393 is defined in (7) and emphasize that the matrices \u0393j\u2032 and B are essentially the extraction and reorganization of the elements (the parameters \u03bbij) in \u0393, i.e.\n\u0393j\u2032 = \u03bb1((j\u2032\u22121)n+1) . . . \u03bb1(j\u2032n)... . . . ... \u03bbn((j\u2032\u22121)n+1) . . . \u03bbn(j\u2032n) , B = \u03bb1(Mn+1) . . . \u03bb1(Mn+m)... . . . ... \u03bbn(Mn+1) . . . \u03bbn(Mn+m) .\nAlso, the matrices Ej\u2032 , B\u0303 are used for the extractions. Therefore, the identified system\nx\u0307 = M\u2211 j\u2032=1 \u0393j\u2032fj\u2032(x) +Bu (12)\nis in the form of generalized Persidskii systems (.3) (f1, . . . , fM are SBFs). The notable advantages of considering the generalized Persidskii system are that its stability properties have been well investigated in, for instance, [18, 6], and letting basis functions take the form of such a class of dynamics allows us to analyze the stability of the identified model (random selections may lead to complex stability analysis) and preserve the generality of basis functions to some extent. Apart from these, the theoretically infinite number of nonlinearities in the generalized Persidskii systems can be well-fitted into the possibly voluminous dimension of the lifting/basis function."
        },
        {
            "heading": "4.2. ISS property of the identified model",
            "text": "In this section, the ISS conditions of the identified system are formulated, based on the selection of SBFs, for verifying the ISS property of (12) under Assumption 1. The following theorem investigates the ISS of the identified model (12).\nTheorem 1. Let Assumption 3 be satisfied with \u03d5 \u2208 N\\{0}. If there exist 0 \u2264 P = P\u22a4 \u2208 Rn\u00d7n; { \u039bj = diag(\u039bj1, . . . ,\u039b j n) }M j=1 , { \u039ek }M k=1\n, {\u03a5s,z}0\u2264s<z\u2264M \u2282 Dn+; 0 < \u03a6 = \u03a6\u22a4 \u2208 Rn\u00d7n; \u03c1 \u2208 R such that\nP + \u03c1 \u00b5\u2211 j=1 \u039bj > 0, Q \u2264 0, \u03d5\u2211 k=1 \u039ek + 2 \u03d5\u2211 s=0 \u03d5\u2211 z=s+1 \u03a5s,z > 0, (13)\nwhere\nQ1,1 = On\u00d7n; Qj+1,j+1 = \u0393 \u22a4 j \u039b j + \u039bj\u0393j + \u039e j , j \u2208 1,M\nQ1,j+1 = P\u0393j +\u03a50,j , j \u2208 1,M ; Q1,M+2 = P,\nQs+1,z+1 = \u0393 \u22a4 s \u039b z + \u039bs\u0393z +\u03a5s,z , s \u2208 1,M \u2212 1, z \u2208 s+ 1,M,\nQj+1,M+2 = \u039b j , QM+2,M+2 = \u2212\u03a6,\nand \u03d5 is defined in the Appendices, then a forward complete system (12) is ISS.\nProof. A similar proof can be founded in [6, 18], where the ISS analysis of (12) can be performed using a Lyapunov function V (x) = x\u22a4Px + 2 \u2211 j\u22081,M \u2211 i\u22081,n \u039b j i \u222b x 0 f ij(\u03bd)d\u03bd, where f i j is the i-th element of fj, and 0 \u2264 P = P\u22a4 \u2208 Rn\u00d7n and \u039bj = diag(\u039bj1, ...,\u039bjn) \u2208 Dn+ are tuning matrices. They are selected in a way that ensures positive definiteness of V under Assumption 3 (see the first inequality of (13)), then there exist functions \u03b1P,\u039b 1,...,\u039bM\n1 , \u03b1 P,\u039b1,...,\u039bM 2 \u2208 K\u221e such that\n\u03b1P,\u039b 1,...,\u039bM 1 (\u2225x\u2225) \u2264 V (x) \u2264 \u03b1 P,\u039b1,...,\u039bM 2 (\u2225x\u2225)\nfor all x \u2208 Rn. For instance, the function \u03b1P,\u039b 1,...,\u039bM\n2 can always be taken as\n\u03b1P,\u039b 1,...,\u039bM\n2 (\u03c4) = \u03bbmax(P )\u03c4 2 + 2Mn max\nj\u22081,M,i\u22081,n\n{ \u039bji \u222b \u03c4 0 f ij(\u03bd) d\u03bd } .\nThese recover the first relation in (.2). Then consider the second condition in (.2): Take the time derivative V\u0307 = \u2207V (x)x\u0307, we have\nV\u0307 =  x f1(x) . .\n. fM (x) Bu\n \u22a4 Q  x f1(x) . .\n. fM (x) Bu\n\u2212 M\u2211 j=1 fj(x) \u22a4\u039ejfj(x)\u2212 2 M\u2211 j=1 x\u22a4\u03a50,jfj(x)\n\u2212 2 M\u22121\u2211 s=1 M\u2211 z=s+1 fs(x) \u22a4\u03a5s,zfz(x) + (Bu) \u22a4\u03a6Bu\n\u2264 \u2212 M\u2211 j=1 fj(x) \u22a4\u039ejfj(x)\u2212 2 M\u2211 j=1 x\u22a4\u03a50,jfj(x) \u2212 2 M\u22121\u2211 s=1 M\u2211 z=s+1 fs(x) \u22a4\u03a5s,zfz(x) + (Bu) \u22a4\u03a6Bu,\nfrom which we see that the function of x in the right-hand side of the last inequality is radially unbounded (this satisfies the second relation in (.2)) due to the last LMI of (13). Here only the nonlinearities f1, . . . , f\u03d5 are radially unbounded. By Theorem 2, the proof is complete.\nFrom Section 4.1 to Theorem 1, we have placed mild restrictions on a problem with great freedom to obtain an analyzable one (in terms of ISS analysis). In addition, the significance of stability verification of identified systems and the retention of the generality of basis functions indicate the acceptable price is worth it. These reflect the main novelty of this work."
        },
        {
            "heading": "4.3. Extensions of basis functions",
            "text": "This section demonstrates that extending the considered basis functions is possible to increase the selection range when one implements data-driven methods. Let us consider the first approach of relaxing the imposed form of basis functions:\n1) Translation of functions : We start by defining a vector-valued function G(\u03bd) = [ g1(\u03bd) . . . gn(\u03bd) ]\u22a4 = F (\u03bd) + \u2113 = [ f1(\u03bd) . . . fn(\u03bd) ]\u22a4 + \u2113 for all \u03bd \u2208 Rn, where f1, . . . , fn \u2208 F(R) and \u2113 \u2208 Rn. This formulation can also be expressed as: G(\u03bd)\u2212 \u2113 = F (\u03bd), where the functions fi are in the semigroup F(R). It is clear that gi do not satisfy Assumption 3 if the i-th element of \u2113 is not equal to zero. Afterwards, we can extend the system (.3) to x\u0307(t) = A0x(t) + \u2211M j\u2032=1Aj\u2032Gj\u2032(x(t)) + u(t), which is essentially equivalent to\nx\u0307(t) = A0x(t) + \u2211M j\u2032=1Aj\u2032Fj\u2032(x(t)) + u(t) + \u2211M\nj\u2032=1Aj\u2032lj\u2032 , where the constant vectors l1, . . . , lM \u2208 Rn. Therefore, one can see that the generality of the functions Gj\u2032 is greater than that of Fj\u2032 , which illustrates a possible direction of extensions. It is also worth mentioning that such a transformation does not affect the use of the lifting approach and the stability analysis introduced above.\n2) Change of independent variables of functions : We consider generalizing the variables of the functions Fj\u2032 , for which the linear operators Tj\u2032x := Rj\u2032x are taken into account, where Rj\u2032 \u2208 Rkj\u2032\u00d7n are constant matrices with appropriate dimensions (Tj\u2032 may be the identity operator, then the independent variables do not change). Thus, under the substitutions of x to Tj\u2032x in the nonlinearities of the system (.3), we can obtain the resulting system:\nx\u0307(t) = A0x(t) + M\u2211 j\u2032=1 Aj\u2032Fj\u2032(Rj\u2032x(t)) + u(t), (14)\nextending the model (.3). For such a generalization, we require a minor revision of Assumption 3, provided next.\nAssumption 2. Assume that for any i \u2208 1, kj\u2032 and j\u2032 \u2208 1,M , \u03bdf ij\u2032(\u03bd) > 0, for all \u03bd \u0338= 0.\nGiven this assumption1, we can now formulate the ISS conditions for the system (14) in the following corollary.\n1There exists an index \u03d5 \u2208 0,M such that for all s \u2208 1, \u03d5 and i \u2208 1, ks, lim \u03bd\u2192\u00b1\u221e f is(\u03bd) =\nCorollary 1. Let Assumption 2 be satisfied with \u03d5 \u2208 N\\{0}. If there exist 0 \u2264 P = P\u22a4 \u2208 Rn\u00d7n; \u039bj = diag(\u039bj1, . . . ,\u039b j kj ) \u2208 Dkj+ (j \u2208 1,M); \u039es \u2208 Dks+ (s \u2208 0,M), \u03a50,s \u2208 Dks+ (s \u2208 1,M); {\u03a5s,r}Mr=s+1 \u2282 Dn+ (s \u2208 1,M \u2212 1); \u03f1 \u2208 R and 0 < \u03a6 = \u03a6\u22a4 \u2208 Rn\u00d7n such that\nP + \u03f1 \u00b5\u2211 j=1 \u039bj > 0, Q = Q\u22a4 = (Qa, b) M+2 a, b=1 \u2264 0,\n\u03d5\u2211 s=0 \u039es + 2 \u03d5\u2211 s=0 \u03d5\u2211 r=s+1 \u03a5s,r > 0,\nwhere Q1,1 = A\u22a40 P + PA0 + \u039e0; Qj+1,j+1 = A\u22a4j R\u22a4j \u039bj + \u039bjRjAj + \u039ej , j \u2208 1,M ; Q1,j+1 = PAj + A\u22a40 R \u22a4 j \u039b j + R\u22a4j \u03a50,j , j \u2208 1,M ; Qs+1,r+1 = A\u22a4s R\u22a4r \u039br + \u039bsRsAr + R\u22a4s Rs\u03a5s,rR\u22a4r Rr, s \u2208 1,M \u2212 1, r \u2208 s+ 1,M ; Q1,M+2 = P, QM+2,M+2 = \u2212\u03a6, Qj+1,M+2 = \u039bjRj , j \u2208 1,M , then the system (14) is ISS.\nThe proof developments for Corollary 1 refer to the methodology used in the works [6] and are omitted from this paper due to the unobtrusive modifications."
        },
        {
            "heading": "5. Numerical Case Study",
            "text": "This section is involved in a generalized traffic system in [19] obtained from the Lighthill Whitham Richards (LWR) flow model [20] under an ODE approximation technique [21]. Such a model describes the evolution of traffic densities on prescribed highway segments and on/off-ramps. We dealt with its identification first, then verified the ISS property to illustrate the efficacy of the proposed result.\nThe considered model can be expressed as:\nx\u0307(t) = [ A1 A2 O A3 ] x(t) + g(x) +Buu(t) + d(t), (15)\nwhere x is the state vector; A1, A2, A3, Bu are constant matrices; each element of the function g is a quadratic polynomial with one or more variables\n\u00b1\u221e. Also, there exists \u00b5 \u2208 \u03d5,M such that for all s \u2208 1, \u00b5, i \u2208 1, ks, we have\nlim \u03bd\u2192\u00b1\u221e \u222b \u03bd 0 f is(r)dr = +\u221e.\ncontaining only quadratic terms, i.e., gi(x) = c1x 2 i + c2x 2 j + ... \u2208 R; u(t), d(t) are the input and the disturbance with the appropriate dimensions. We transformed the system (15) into its linearization, thus the functions gi satisfy Assumption 3. In the simulation, we let n = 2, m = 1, NF = 4, G(x) =[ x1 x2 x 3 1 x 3 2 ]\u22a4 , Tc = 0.01, N = 348, t \u2208 [0, 3.5], and obtained that it is possible to identify the model (15) with high precision in the case of no disturbance (d(t) = 0; see Fig. 1). And the ISS conditions in Theorem 1 are verified by solving the LMIs. However, under the disturbance (d(t) = 10\u22121 \u00d7 [ sin(t) tanh(t) ] ; appeared in the process of system identification), another simulation result shows that the ISS property has not been retained, illustrated by Fig. 2. In this case, one may reexamine the working environment and perform the system identification under a better situation or consider disturbance rejection."
        },
        {
            "heading": "6. Paper Summary and Future Work",
            "text": "This work proposed a beneficial class of functions named sector basis functions for identifying the vector field of the system. The identified system takes the form of a specific kind of nonlinear system whose input-to-state stability conditions were formulated as linear algebraic inequalities and, thus, can be constructively verified. Additionally, two directions of the extensions of the basis functions were introduced. Simulation on the macroscopic traffic dynamics was exploited for examining the proposed results. Future work topics include further applications to power system dynamics and extending the theory to descriptor systems.\nAppendices\nThis section gives the used preliminaries for the general continuous-time nonlinear dynamical system:\nx\u0307(t) = F (x(t), u(t)), t \u2208 R+, (.1)\nwhere x(t) \u2208 Rn is the state vector; u(t) \u2208 U \u2282 Rm is the given external input, u \u2208 C1m([0,\u221e)); and vector-valued nonlinearity is defined as F \u2208 C(Rn \u00d7U,Rn) being also locally Lipschitz continuous in x(t). For an initial state x0 \u2208 Rn, u \u2208 C1m([0,\u221e)) and t \u2208 R+, the corresponding solution of system (.1) is denoted by xt(x0, u) = x(t, x0, u). It is assumed that in (.1) such a solution is uniquely defined for any x0 \u2208 Rn, u \u2208 C1m([0,\u221e)) and all t \u2208 R+."
        },
        {
            "heading": "Appendix .1. Koopman operator",
            "text": "We present the definition of the Koopman operator [22] Kt : H \u2192 H (t \u2208 R+) associated with the system (.1) as\nKtH = H \u25e6 xt,\nwhere H : Rn \u2192 R is observable function (H belongs to a Banach space H of such functions) and \u25e6 denotes the composition operator. The Koopman operator is of interest since it can transform nonlinear dynamics into a linear representation of the theoretically infinite-dimensional system. Let\nK = {Kt}t\u22650 represent the C0-semigroup of Koopman operators Kt, then L := limt\u21920+ Kt\u2212I t\nstands for the infinitesimal generator of K, where I is the identity operator on the space H. Note that theoretically, H can be infinite-dimensional, and Kt is a linear operator for each t \u2208 R+."
        },
        {
            "heading": "Appendix .2. Input-to-state stability properties",
            "text": "Definition 2. [13, 14] A forward complete system (.1) is said to be inputto-state stable (ISS) if there exist \u03b2 \u2208 K L , \u03b3 \u2208 K such that \u2225xt(x0, u)\u2225 \u2264 \u03b2 (\u2225x0\u2225, t)+\u03b3(\u2225u\u2225\u221e), \u2200t \u2208 R+ for any x0 \u2208 Rn and u \u2208 C1m([0,\u221e)). For the system (.1), a smooth function V : Rn \u2192 R+ is an ISS-Lyapunov function if there exist \u03b11, \u03b12, \u03b13 \u2208 K\u221e and \u03c7 \u2208 K such that\n\u03b11(\u2225x\u2225) \u2264 V (x) \u2264 \u03b12(\u2225x\u2225), (.2) \u2225x\u2225 \u2265 \u03c7(\u2225u\u2225) \u21d2 \u2207V (x)F (x, u) \u2264 \u2212\u03b13(\u2225x\u2225)\nfor all x \u2208 Rn and u \u2208 U.\nTheorem 2. [13, 14] The system (.1) is ISS if and only if it admits an ISS-Lyapunov function."
        },
        {
            "heading": "Appendix .3. Generalized Persidskii systems",
            "text": "We then introduce generalized Persidskii dynamics [6]:\nx\u0307(t) = A0x(t) + M\u2211 j\u2032=1 Aj\u2032Fj\u2032(x(t)) + u(t), t \u2208 R+, (.3)\nwhere x = [x1, . . . , xn] \u22a4 \u2208 Rn is the state, x(0) = x0; As \u2208 Rn\u00d7n, s \u2208 0,M are constant matrices; the input u = [u1, . . . , un] \u22a4 \u2208 L n\u221e, and the functions Fj\u2032 \u2208 C(Rn,Rn), Fj\u2032(x) = [ f 1j\u2032(x1) . . . fnj\u2032(xn) ]\u22a4, \u2200j\u2032 \u2208 1,M. The nonlinearity Fj\u2032 has a diagonal structure: each element of Fj\u2032 (i.e., each function f i j\u2032) depends only on the respective coordinate xi, i \u2208 1, n. We also impose a sector boundedness or a passivity condition on f ij\u2032 :\nAssumption 3. For system (.3), assume that for any i \u2208 1, n and j\u2032 \u2208 1,M , we have \u03bdf ij\u2032(\u03bd) > 0 for all \u03bd \u0338= 0.\nUnder Assumption 3, with a reordering of nonlinearities and their decomposition, there exists an index \u03d5 \u2208 0,M such that for all a \u2208 1, \u03d5, i \u2208 1, n: lim\u03bd\u2192\u00b1\u221e f i a(\u03bd) = \u00b1\u221e, and that there exists \u00b5 \u2208 \u03d5,M such that for all\nb \u2208 1, \u00b5, i \u2208 1, n: lim\u03bd\u2192\u00b1\u221e \u222b \u03bd 0 f ib(\u03c4)d\u03c4 = +\u221e.\nAssumption 3 is not restrictive, considering, for instance, the identity rectified linear unit (ReLU), tanh, and sigmoid functions are some representative examples fulfilling Assumption 3."
        }
    ],
    "title": "On input-to-state stability verification of identified models obtained by Koopman operator",
    "year": 2023
}