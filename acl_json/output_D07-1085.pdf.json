{
    "abstractText": "Speech recognition transcripts are far from perfect; they are not of sufficient quality to be useful on their own for spoken document retrieval. This is especially the case for conversational speech. Recent efforts have tried to overcome this issue by using statistics from speech lattices instead of only the 1best transcripts; however, these efforts have invariably used the classical vector space retrieval model. This paper presents a novel approach to lattice-based spoken document retrieval using statistical language models: a statistical model is estimated for each document, and probabilities derived from the document models are directly used to measure relevance. Experimental results show that the lattice-based language modeling method outperforms both the language modeling retrieval method using only the 1-best transcripts, as well as a recently proposed lattice-based vector space retrieval method.",
    "authors": [
        {
            "affiliations": [],
            "name": "Tee Kiah Chia"
        },
        {
            "affiliations": [],
            "name": "Haizhou Li"
        },
        {
            "affiliations": [],
            "name": "Hwee Tou Ng"
        }
    ],
    "id": "SP:40fcf63948b52677570ac2dcac3012c8cdc1c38e",
    "references": [
        {
            "authors": [
                "Dave Abberley",
                "David Kirby",
                "Steve Renals",
                "Tony Robinson."
            ],
            "title": "The THISL broadcast news retrieval system",
            "venue": "InProceedings of ESCA ETRW Workshop on Accessing Information in Spoken Audio, pages 14\u201319.",
            "year": 1999
        },
        {
            "authors": [
                "Adam Berger",
                "John Lafferty."
            ],
            "title": "Information retrieval as statistical translation",
            "venue": "In",
            "year": 1999
        },
        {
            "authors": [
                "David Carmel",
                "Einat Amitay",
                "Miki Herscovici",
                "Yoelle Maarek",
                "Yael Petruschka",
                "Aya Soffer."
            ],
            "title": "Juru at TREC 10 \u2013 Experiments with index pruning",
            "venue": "Proceedings of the Tenth Text Retrieval Conference (TREC-10), pages 228\u2013236.",
            "year": 2001
        },
        {
            "authors": [
                "Ciprian Chelba",
                "Alex Acero."
            ],
            "title": "Position specific posterior lattices for indexing speech",
            "venue": "In",
            "year": 2005
        },
        {
            "authors": [
                "Berlin Chen",
                "Hsin-min Wang",
                "Lin-shan Lee"
            ],
            "title": "A discriminative HMM/n-gram-based retrieval approach for Mandarin spoken documents",
            "venue": "Proceedings of ACL",
            "year": 2005
        },
        {
            "authors": [
                "Andrew O. Hatch",
                "Barbara Peskin",
                "Andreas Stolcke."
            ],
            "title": "Improved phonetic speaker recognition using lattice decoding",
            "venue": "InProceedings of IEEE ICASSP 2005, 1:169\u2013172.",
            "year": 2005
        },
        {
            "authors": [
                "Hsiao-Wuen Hon",
                "Baosheng Yuan",
                "Yen-Lu Chow",
                "S. Narayan",
                "Kai-Fu Lee."
            ],
            "title": "Towards large vocabulary Mandarin Chinese speech recognition",
            "venue": "In",
            "year": 1994
        },
        {
            "authors": [
                "David Anthony James",
                "Steve J. Young."
            ],
            "title": "A fast lattice-based approach to vocabulary independent wordspotting",
            "venue": "InProceedings of ICASSP 1994, 1:377\u2013 380.",
            "year": 1994
        },
        {
            "authors": [
                "Frederick Jelinek",
                "Robert L. Mercer."
            ],
            "title": "Interpolated estimation of Markov source parameters from sparse data",
            "venue": "InProceedings of the Workshop on Pattern Recognition in Practice, pages 381\u2013397.",
            "year": 1980
        },
        {
            "authors": [
                "Gareth J.F. Jones",
                "Jonathan T. Foote",
                "Karen Sp\u00e4rck Jones",
                "Steve J. Young."
            ],
            "title": "Retrieving spoken documents by combining multiple index sources",
            "venue": "Proceedings of SIGIR 1996, pages 30\u201338.",
            "year": 1996
        },
        {
            "authors": [
                "Jin Kiat Low",
                "Hwee Tou Ng",
                "Wenyuan Guo."
            ],
            "title": "A maximum entropy approach to Chinese word segmentation",
            "venue": "Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing, pages 161\u2013 164.",
            "year": 2005
        },
        {
            "authors": [
                "David J.C. MacKay",
                "Linda C. Bauman Peto"
            ],
            "title": "A hierarchical Dirichlet language model",
            "year": 1994
        },
        {
            "authors": [
                "Jonathan Mamou",
                "David Carmel",
                "Ron Hoory."
            ],
            "title": "Spoken document retrieval from call-center conversations",
            "venue": "InProceedings of SIGIR 2006, pages 51\u201358.",
            "year": 2006
        },
        {
            "authors": [
                "Lidia Mangu",
                "Eric Brill",
                "Andreas Stolcke."
            ],
            "title": "Finding consensus in speech recognition: word error minimization and other applications of confusion networks",
            "venue": "Computer Speech and Language, 14(4):373\u2013 400.",
            "year": 2000
        },
        {
            "authors": [
                "Mehryar Mohri",
                "Fernando C.N. Pereira",
                "Michael Riley"
            ],
            "title": "A rational design for a weighted finite-state transducer library",
            "year": 1998
        },
        {
            "authors": [
                "National Institute of Standards",
                "Technology."
            ],
            "title": "TREC-9 SDR Track web site",
            "venue": "www.nist.gov/speech/tests/sdr/sdr2000/sdr2000.htm.",
            "year": 2000
        },
        {
            "authors": [
                "The Use of Context in Large Vocabulary Speech Recognition. Ph. D. thesis",
                "Cambridge University Engineering Department. Jay M. Ponte",
                "W. Bruce Croft."
            ],
            "title": "A language modeling approach to information retrieval",
            "venue": "In",
            "year": 1998
        },
        {
            "authors": [
                "Murat Saraclar",
                "Richard Sproat."
            ],
            "title": "Lattice-based search for spoken utterance retrieval",
            "venue": "In",
            "year": 2004
        },
        {
            "authors": [
                "Matthew A. Siegler"
            ],
            "title": "1999.Integration of Continuous Speech Recognition and Information Retrieval for Mutually Optimal Performance",
            "venue": "Ph. D. thesis,",
            "year": 1999
        },
        {
            "authors": [
                "Fei Song",
                "W. Bruce Croft."
            ],
            "title": "A general language model for information retrieval",
            "venue": "In",
            "year": 1999
        },
        {
            "authors": [
                "Andreas Stolcke."
            ],
            "title": "SRILM \u2013 An extensible language modeling toolkit",
            "venue": "Proceedings of ICSLP, 2:901\u2013 904.",
            "year": 2002
        },
        {
            "authors": [
                "Andy Tuerk",
                "Sue E. Johnson",
                "Pierre Jourlin",
                "Karen Sp\u00e4rck Jones",
                "Philip C. Woodland"
            ],
            "title": "The Cambridge University multimedia document retrieval demo system",
            "year": 2001
        },
        {
            "authors": [
                "Peng Yu",
                "Kaijiang Chen",
                "Lie Lu",
                "Frank Seide."
            ],
            "title": "Searching the audio notebook: keyword search in recorded conversations",
            "venue": "In",
            "year": 2005
        },
        {
            "authors": [
                "Chengxiang Zhai",
                "John Lafferty"
            ],
            "title": "A study of smoothing methods for language models applied to information",
            "venue": "Proceedings of HLT/EMNLP",
            "year": 2005
        }
    ],
    "sections": [
        {
            "text": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pp. 810\u2013818, Prague, June 2007. c\u00a92007 Association for Computational Linguistics\nSpeech recognition transcripts are far from perfect; they are not of sufficient quality to be useful on their own for spoken document retrieval. This is especially the case for conversational speech. Recent efforts have tried to overcome this issue by using statistics from speech lattices instead of only the 1- best transcripts; however, these efforts have invariably used the classical vector space retrieval model. This paper presents a novel approach to lattice-based spoken document retrieval using statistical language models: a statistical model is estimated for each document, and probabilities derived from the document models are directly used to measure relevance. Experimental results show that the lattice-based language modeling method outperforms both the language modeling retrieval method using only the 1-best transcripts, as well as a recently proposed lattice-based vector space retrieval method."
        },
        {
            "heading": "1 Introduction",
            "text": "Information retrieval (IR) is the task of ranking a collection of documents according to an estimate of their relevance to a query. With the recent growth in the amount of speech recordings in the form of voice mails, news broadcasts, and so forth, the task of spoken document retrieval (SDR) \u2013 information retrieval in which the document collection is in the form of speech recordings \u2013 is becoming increasingly important.\nSDR on broadcast news corpora has been \u201cdeemed to be a solved problem\u201d, due to the fact that the performance of retrieval engines working on 1- best automatic speech recognition (ASR) transcripts was found to be \u201cvirtually the same as their performance on the human reference transcripts\u201d (NIST, 2000). However, this is still not the case for SDR on data which are more challenging, such as conversational speech in noisy environments, as the 1-best transcripts of these data contain too many recognition errors to be useful for retrieval. One way to ameliorate this problem is to work with not just one ASR hypothesis for each utterance, but multiple hypotheses presented in alattice data structure. A lattice is a connected directed acyclic graph in which each edge is labeled with a term hypothesis and a likelihood value (James, 1995); each path through a lattice gives a hypothesis of the sequence of terms spoken in the utterance.\nEach lattice can be viewed as a statistical model of the possible transcripts of an utterance (given the speech recognizer\u2019s state of knowledge); thus, an IR model based on statistical inference will seem to be a more natural and more principled approach to lattice-based SDR. This paper thus proposes a lattice-based SDR method based on the statistical language modeling approach of Song and Croft (1999). In this method, thexpected word count \u2013 the mean number of occurrences of a word given a lattice\u2019s statistical model \u2013 is computed for each word in each lattice. Using these expected counts, a statistical language model is estimated for each spoken document, and a document\u2019s relevance to a query is computed as a probability under this model.\n810\nThe rest of this paper is organized as follows. In Section 2 we review related work in the areas of speech processing and IR. Section 3 describes our proposed method as well as the baseline methods. Details of the experimental setup are given in Section 4, and experimental results are in Section 5. Finally, Section 6 concludes our discussions and outlines our future work."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Lattices for Spoken Document Retrieval",
            "text": "James and Young (1994) first introduced the lattice as a representation for indexing spoken documents, as part of a method for vocabulary-independent keyword spotting. The lattice representation was later applied to the task of spoken document retrieval by James (1995): James counted how many times each query word occurred in each phone lattice with a sufficiently high normalized log likelihood, and these counts were then used in retrieval under a vector space model withtf \u00b7 idf weighting. Jones et al. (1996) combined retrieval from phone lattices using variations of James\u2019 method with retrieval from 1- best word transcripts to achieve better results.\nSince then, a number of different methods for SDR using lattices have been proposed. For instance, Siegler (1999) used word lattices instead of phone lattices as the basis of retrieval, and generalized thetf \u00b7 idf formalism to allow uncertainty in word counts. Chelba and Acero (2005) preprocessed lattices into more compact Position Specific Posterior Lattices (PSPL), and computed an aggregate score for each document based on the posterior probability of edges and the proximity of search terms in the document. Mamou et al. (2006) converted each lattice into a word confusion network (Mangu et al., 2000), and estimated the inverse document frequency (idf ) of each wordt as the ratio of the total number of words in the document collection to the total number of occurrences oft.\nDespite the differences in the details, the above lattice-based SDR methods have all been based on the classical vector space retrieval model withtf \u00b7idf weighting."
        },
        {
            "heading": "2.2 Expected Counts from Lattices",
            "text": "A speech recognizer generates a 1-best transcript of a spoken document by considering possible transcripts of the document, and then selecting the transcript with the highest probability. However, unlike a text document, such a 1-best transcript is likely to be inexact due to speech recognition errors. To represent the uncertainty in speech recognition, and to incorporate information from multiple transcription hypotheses rather than only the 1-best, it is desirable to use expected word counts from lattices output by a speech recognizer.\nIn the context of spoken document search, Siegler (1999) described expected word counts and formulated a way to estimate expected word counts from lattices based on the relative ranks of word hypothesis probabilities; Chelba and Acero (2005) used a more explicit formula for computing word counts based on summing edge posterior probabilities in lattices; Saraclar and Sproat (2004) performed word-spotting in speech lattices by looking for word occurrences whose expected counts were above a certain threshold; and Yu et al. (2005) searched for phrases in spoken documents using a similar measure, the expected word relevance.\nExpected counts have also been used to summarize the phonotactics of a speech recording repesented in a lattice: Hatch et al. (2005) performed speaker recognition by computing the expected counts of phone bigrams in a phone lattice, and estimating an unsmoothed probability distribution of phone bigrams.\nAlthough many uses of expected counts have been studied, the use of statistical language models built from expected word counts has not been well explored."
        },
        {
            "heading": "2.3 Retrieval via Statistical Language Modeling",
            "text": "Finally, the statistical language modeling approach to retrieval was used by Ponte and Croft (1998) for IR with text documents, and it was shown to outperform thetf \u00b7 idf approach for this task; this method was further improved on in Song and Croft (1999). Chen et al. (2004) applied Song and Croft\u2019s method to Mandarin spoken document retrieval using 1-best ASR transcripts. In this task, it was also shown to\noutperformtf \u00b7 idf . Thus, the statistical language modeling approach to retrieval has been shown to be superior to the vector space approach for both these IR tasks."
        },
        {
            "heading": "2.4 Contributions of Our Work",
            "text": "The main contributions of our work include\n\u2022 extending the language modeling IR approach from text-based retrieval to lattice-based spoken document retrieval; and\n\u2022 formulating a method for building a statistical language model based on expected word counts derived from lattices.\nOur method is motivated by the success of the statistical retrieval framework over the vector space approach withtf \u00b7 idf for text-based IR, as well as for spoken document retrieval via 1-best transcripts. Our use of expected counts differs from Saraclar and Sproat (2004) in that we estimate probability models from the expected counts. Conceptually, our method is close to that of Hatch et al. (2005), as both methods build a language model to summarize the content of a spoken document represented in a lattice. In practice, our method differs from Hatch et al. (2005)\u2019s in many ways: first, we derive word statistics for representing semantics, instead of phone bigram statistics for representing phonotactics; second, we introduce a smoothing mechanism (Zhai and Lafferty, 2004) to the language model that is specific for information retrieval."
        },
        {
            "heading": "3 Methods",
            "text": "We now describe the formulation of three different SDR methods: a baseline statistical retrieval method which works on 1-best transcripts, our proposed statistical lattice-based SDR method, as well as a previously published vector space lattice-based SDR method."
        },
        {
            "heading": "3.1 Baseline Statistical Retrieval Method",
            "text": "Our baseline retrieval method is motivated by Song and Croft (1999), and uses the language model smoothing methods of Zhai and Lafferty (2004). This method is used to perform retrieval on the documents\u2019 1-best ASR transcripts and reference human transcripts.\nLet C be the collection of documents to retrieve from. For each documentd contained inC, and each queryq, the relevance ofd to q can be defined as Pr(d | q). This probability cannot be computed directly, but under the assumption that the priorPr(d) is uniform over all documents inC, we see that\nPr(d | q) = Pr(q | d) Pr(d)\nPr(q) \u221d Pr(q | d);\nThis means that ranking documents byPr(d | q) is equivalent to ranking them byPr(q | d), and thus Pr(q | d) can be used to measure relevance (Berger and Lafferty, 1999).\nNow expressq as a series of words drawn from vocabularyV = {w1, w2, \u00b7 \u00b7 \u00b7wV }; that is,q =\nq1q2 \u00b7 \u00b7 \u00b7 qK , whereK is the number of words in the query, andqi \u2208 V for 1 \u2264 i \u2264 K. Then given a unigram model derived fromd which assigns a probability Pr(w | d) to each wordw in V, we can computePr(q | d) as follows:\nPr(q | d) = Pr(q1q2 \u00b7 \u00b7 \u00b7 qK | d)\n= K \u220f\ni=1\nPr(qi | d)\n= \u220f\nw\u2208V , C(w|q)>0\nPr(w|d)C(w|q) (1)\nwhereC(w | q) is the word count ofw in q. Before using Equation 1, we must estimate a unigram model fromd: that is, an assignment of probabilities Pr(w | d) for all w \u2208 V. One way to do this is to use a maximum likelihood estimate (MLE) \u2013 an assignment ofPr(w | d) for all w which maximizes the probability of generatingd. The MLE is given by the equation\nPr mle(w | d) = C(w | d)\n|d|\nwhereC(w | d) is the number of occurrences of w in d, and |d| is the total number of words ind. However, using this formula means we will get a value of zero forPr(q | d) if even a single query wordqi is not found ind. To overcome this problem, we smooth the model by assigning some probability mass to such unseen words. Specifically, we adopt\na two-stage smoothing method (Zhai and Lafferty, 2004):\nPr(w | d) = (1 \u2212 \u03bb) C(w | d) + \u00b5 Pr(w | C)\n|d| + \u00b5\n+\u03bbPr(w | U) (2)\nHere,U denotes a background language model, and \u00b5 > 0 and\u03bb \u2208 (0, 1) are parameters to the smoothing procedure. This is a combination of Bayesian smoothing using Dirichlet priors (MacKay and Peto, 1984) and Jelinek-Mercer smoothing (Jelinek and Mercer, 1980).\nThe parameter\u03bb can be set empirically according to the nature of the queries. For the parameter\u00b5, we adopt the estimation procedure of Zhai and Lafferty (2004): we maximize the leave-one-out log likelihood of the document collection, namely\n\u2113\u22121(\u00b5 | C) = \u2211\nd\u2208C\n\u2211\nw\u2208V\nC(w | d)\nlog\n(\nC(w | d) \u2212 1 + \u00b5 Pr(w | C)\n|d| \u2212 1 + \u00b5\n)\n(3)\nby using Newton\u2019s method to solve the equation\n\u2113\u2032\u22121(\u00b5 | C) = 0"
        },
        {
            "heading": "3.2 Our Proposed Statistical Lattice-Based Retrieval Method",
            "text": "We now propose our lattice-based retrieval method. In contrast to the above baseline method, our proposed method works on the lattice representation of spoken documents, as generated by a speech recognizer.\nFirst, each spoken document is divided intoM short speech segments. A speech recognizer then generates a lattice for each speech segment. As previously stated, a lattice is a connected directed acyclic graph with edges labeled with word hypotheses and likelihoods. Thus, each path through the lattice contains a hypothesis of the series of words spoken in this speech segment,t = t1t2 \u00b7 \u00b7 \u00b7 tN , along with acoustic probabilitiesPr(o1 | t1), Pr(o2 | t2), \u00b7 \u00b7 \u00b7 Pr(oN | tN ), where oi denotes the acoustic observations for the time interval of the wordti hypothesized by the speech recognizer. Leto = o1o2 \u00b7 \u00b7 \u00b7 oN denote the acoustic observations for the\nentire speech segment; then\nPr(o | t) =\nN \u220f\ni=1\nPr(oi | ti)\nWe then rescore each lattice with ann-gram language model. Effectively, this means multiplying the acoustic probabilities withn-gram probabilities:\nPr(t,o) = Pr(o | t) Pr(t)\n=\nN \u220f\ni=1\nPr(oi | ti) Pr(ti | ti\u2212n+1 \u00b7 \u00b7 \u00b7 ti\u22121)\nThis produces an expanded lattice in which paths (hypotheses) are weighted by their posterior probabilities rather than their acoustic likelihoods: specifically, by Pr(t,o) \u221d Pr(t | o) rather thanPr(o | t) (Odell, 1995). The lattice is then pruned, by removing those paths in the lattice whose log posterior probabilities \u2013 to be precise, whose\u03b3 ln Pr(t | o) \u2013 are not within a threshold\u0398 of the best path\u2019s log posterior probability (in our implementation,\u03b3 = 10000.5).\nNext, we compute the expected count of each word in each document. For each wordw and each documentd comprised ofM speech segments represented byM acoustic observationso(1), o(2), \u00b7 \u00b7 \u00b7 o(M), the expected count ofw in d is\nE[C(w | d)] =\nM \u2211\nj=1\n\u2211\nt\nC(w | t) Pr(t | o(j))\nwhereC(w | t) is the word count ofw in the hypothesized transcript. We can also analogously compute the expected document length:\nE[|d|] = M \u2211\nj=1\n\u2211\nt\n|t|Pr(t | o(j))\nwhere|t| denotes the number of words int. We now replaceC(w | d) and |d| in Equation 2 with E[C(w | d)] andE[|d|]; thus\nPr(w | d) = (1 \u2212 \u03bb) E[C(w | d)] + \u00b5 Pr(w | C)\nE[|d|] + \u00b5\n+\u03bbPr(w | U) (4)\nIn addition, we also modify the procedure for stimating \u00b5, by replacing C(w | d) and\n|d| in Equation 3 with \u230a E[C(w | d)] + 12 \u230b and \u2211\nw\u2208V\n\u230a E[C(w | d)] + 12 \u230b\nrespectively. The probability estimates from Equation 4 can then be substituted into Equation 1 to yield relevance scores.\n3.3 Baseline tf \u00b7 idf Lattice-Based Retrieval Method\nAs a further comparison, we also implemented Mamou et al. (2006)\u2019s vector space retrieval method (without query refinement via lexical affinities). In this method, each documentd is represented as a word confusion network (WCN) (Mangu et al., 2000) \u2013 a simplified lattice which can be viewed as a sequence of confusion setsc1, c2, c3, \u00b7 \u00b7 \u00b7 . Eachci corresponds approximately to a time interval in the spoken document and contains a group of word hypotheses, and each wordw in this group of hypotheses is labeled with the probabilityPr(w | ci,d) \u2013 the probability thatw was spoken in the time interval of ci. A confusion set may also give a probability for Pr(\u01eb | ci,d), the probability that no word was spoken in the time ofci. Figure 1 gives an example of a WCN.\nMamou et al.\u2019s retrieval method proceeds as follows. First, the documents are divided into speech segments, lattices are generated from the speech segments, and the lattices are pruned according to the path probability threshold\u0398, as described in Section 3.2. The lattice for each speech segment is then converted into a WCN according to the algorithm of Mangu et al. (2000). The WCNs for the speech segments in each document are then concatenated to form a single WCN per document.\nNow, to retrieve documents in response to a query q, the method computes, for each documentd \u2208 C and each wordw \u2208 V,\n\u2022 the \u201cdocument length\u201d|d|, computed as the number of confusion sets in the WCN ofd;\n\u2022 the \u201caverage document length\u201davdl, computed\nas\navdl = 1\n|C|\n\u2211\nd\u2032\u2208C\n\u2223 \u2223d\u2032 \u2223 \u2223 ;\n\u2022 the \u201cdocument term frequency\u201dC\u2217(w | d), computed as\nC\u2217(w|d) = \u2211\nc\u2208occ(w,d)\n(brank(w|c,d)\u00b7Pr(w|c,d))\nwhere occ(w,d) is the set of confusion sets in d\u2019s WCN which containw as a hypothesis, rank(w | c,d) is the rank ofw in terms of probability within the confusion setc, and (b1, b2, b3, \u00b7 \u00b7 \u00b7 ) = (10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 0, 0, \u00b7 \u00b7 \u00b7 ) is a boosting vector which serves to discard all but the top 10 hypotheses, and gives more weight to higher-ranked word hypotheses;\n\u2022 the query term frequencyC(w | q), which is simply the word count ofw in q; and\n\u2022 the \u201cinverse document frequency\u201didf(w), computed as\nidf(w) = log O\nOw\nwhere\nOw = \u2211\nd\u2208C\n\u2211\nc\u2208occ(w,d)\nPr(w | c,d)\nO = \u2211\nw\u2032\u2208V\nOw\u2032\nWith these, the relevance ofd to q is computed as (Carmel et al., 2001)\nrel(d,q) =\nP\nw\u2208V C\u2217(w | d) \u00b7 C(w | q) \u00b7 idf(w) p\n0.8 \u00b7 avdl + 0.2 \u00b7 |d|"
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Document Collection",
            "text": "To evaluate our proposed retrieval method, we performed experiments using the Hub5 Mandarin training corpus released by the Linguistic Data Consortium (LDC98T26). This is a conversational telephone speech corpus which is 17 hours long, and\ncontains recordings of 42 telephone calls corresponding to approximately 600Kb of transcribed Mandarin text. Each conversation has been broken up into speech segments of less than 8 seconds each.\nAs the telephone calls in LDC98T26 have not been divided neatly into \u201cdocuments\u201d, we had to choose a suitable unit of retrieval which could serve as a \u201cdocument\u201d. An entire conversation would be too long for such a purpose, while a speech segment or speaker turn would be too short. We decided to use12 -minute time windows with 50% overlap as retrieval units, following Abberley et al. (1999) and Tuerk et al. (2001). The 42 telephone conversations were thus divided into 4,312 retrieval units (\u201cdocuments\u201d). Each document comprises multiple consecutive speech segments."
        },
        {
            "heading": "4.2 Queries and Ground Truth Relevance Judgements",
            "text": "We then formulated 18 queries (14 test queries, 4 development queries) to issue on the document collection. Each query was comprised of one or more written Chinese keywords. We then obtained ground truth relevance judgements by manually examining each of the 4,312 documents to see if it is relevant to the topic of each query. The number of retrieval units relevant to each query was found to range from 4 to 990. The complete list of queries and the number of documents relevant to each query are given in Table 1."
        },
        {
            "heading": "4.3 Preprocessing of Documents and Queries",
            "text": "Next, we processed the document collection with a speech recognizer. For this task we used the Abacus system (Hon et al., 1994), a large vocabulary continuous speech recognizer which contains a triphonebased acoustic system and a frame-synchronized search algorithm for effective word decoding. Each Mandarin syllable was modeled by one to four triphone models. Acoustic models were trained from a corpus of 200 hours of telephony speech from 500 speakers sampled at 8kHz. For each speech frame, we extracted a 39-dimensional feature vector consisting of 12 MFCCs and normalized energy, and their first and second order derivatives. Sentence-based cepstral mean subtraction was applied for acoustic normalization both in the training and testing. Each triphone was modeled by a left-\nTest queries\nTopic Keywords # relevant\ndocuments\nContact information ,Rh,\u01d1 ,\u00c9\u00f8,v 103 Chicago z \u00b8 15 The weather \u00ed,\u00a5,y,FZ,Z,\u00d8O,\u00a5,8\u00ae, 117 ,\u00ac ,\u00ed ,\u00a7\u00dd Housing matters 2 , ,\u00d4,2 , \u00e4,\u00c2,\u00f32, 354\u00b9?,y ,2\u00c0,\u00d3 Studies, academia \u00c6 , \u00a0, A, ,\u00d6,Wt,'V, 9901, I, , D,3 Litigation F,F ,K ,\u00e5\u00aa 31 Raising children B/,/ , \u00b8,\u00c6 , \u00c6\u00c9,m, 334m\u00e4,E\u00c6 Christian churches s\u00cc, ,\u00cc,\u00b2\u00be,s\u00ec,\u00d9\u00c4, \u00b2, 78L\u00ea Floods vy,\u00cc, ,y 4 Clothing q, , ,F ,\u00b0:g,g , 28: F,\u00dcq, Eating out \u00cf,j ,iq,\u00a5j,>0,,\u00a1 57 Playing sports KE,\u00d9\u00c4, |E,\\E 24 Dealings with banks Uq,| , , ,TQ 54 Computers and , \u00ae\u00e5, G 175 software\nDevelopment queries\nTopic Keywords # relevant\ndocuments\nPassport and visa \u01d1L,\u00fcy, \u00b8,C ,I ,#\u00cc 143 matters Washington D. C. \u00ee 15 Working life \u00d9\u00c6, ,K\u00d3,{,\u00d3*, \u00c6,\u00f1 , 509\u00da ,l,\u00d3\u00fd,\u00de ,3/, , 1996 Olympics \u00a3\u00e4\u00cc,\u00c6 }L 8\nTable 1: List of test and development queries\nto-right 3-state hidden Markov model (HMM), each state having 16 Gaussian mixture components. In total, we built 1,923 untied within-syllable triphone models for 43 Mandarin phonemes, as well as 3 silence models. The search algorithm was supported by a loop grammar of over 80,000 words.\nWe processed the speech segments in our collection corpus, to generate lattices incorporating acoustic likelihoods but notn-gram model probabilities. We then rescored the lattices using a backoff tri-\ngram language model interpolated in equal proportions from two trigram models:\n\u2022 a model built from the TDT-2, TDT-3, and TDT-4 Mandarin news broadcast transcripts (about 58Mb of text)\n\u2022 a model built from corpora of transcripts of conversations, comprised of a 320Kb subset of the Callhome Mandarin corpus (LDC96T16) and the CSTSC-Flight corpus from the Chinese Corpus Consortium (950Kb)\nThe unigram counts from this model were also used as the background language modelU in Equations 2 and 4.\nThe reference transcripts, queries, and trigram model training data were all segmented into words using Low et al. (2005)\u2019s Chinese word segmenter, trained on the Microsoft Research (MSR) corpus, with the speech recognizer\u2019s vocabulary used as an external dictionary. The 1-best ASR transcripts were decoded from the rescored lattices.\nLattice rescoring, trigram model building, WCN generation, and computation of expected word counts were done using the SRILM toolkit (Stolcke, 2002), while lattice pruning was done with the help of the AT&T FSM Library (Mohri et al., 1998).\nWe also computed the character error rate (CER) and syllable error rate (SER) of the 1-best transcripts, and the lattice oracle CER, for one of the telephone conversations in the speech corpus (ma_4160). The CER was found to be 69%, the SER 63%, and the oracle CER 29%."
        },
        {
            "heading": "4.4 Retrieval and Evaluation",
            "text": "We then performed retrieval on the document collection using the algorithms in Section 3, using the reference transcripts, the 1-best ASR transcripts, lattices, and WCNs. We set\u03bb = 0.1, which was suggested by Zhai and Lafferty (2004) to give good retrieval performance for keyword queries.\nThe results of retrieval were checked against the ground truth relevance judgements, and evaluated in terms of the non-interpolated mean average precision (MAP):\nMAP = 1\nL\nL \u2211\ni=1\n\n\n1\nRi\nRi \u2211\nj=1\nj\nri,j\n\n\nwhereL denotes the total number of queries,Ri the total number of documents relevant to theith query, and ri,j the position of thejth relevant document in the ranked list output by the retrieval method for queryi.\nFor the lattice-based retrieval methods, we performed retrieval with the development queries using several values of\u0398 between 0 and 100,000, and then used the value of\u0398 with the best MAP to do retrieval with the test queries."
        },
        {
            "heading": "5 Experimental Results",
            "text": "The results of our experiments are summarized in Table 2; the MAP of the two lattice-based retrieval methods, Mamou et al. (2006)\u2019s vector space method and our proposed statistical retrieval method, are shown in Figure 2 and Figure 3 respectively.\nThe results show that, for the vector space retrieval method, the MAP of the development queries is highest at\u0398 = 27, 500, at which point the MAP for the test queries is 0.1599; and for our proposed method, the MAP for the development queries is highest at\u0398 = 65, 000, and at this point the MAP for the test queries reaches 0.2154.\nAs can be seen, the performance of our statistical lattice-based method shows a marked improvement over the MAP of 0.1364 achieved using only the 1- best ASR transcripts, and indeed a one-tailed Student\u2019st-test shows that this improvement is statistically significant at the 99.5% confidence level. The statistical method also yields better performance than Mamou et al.\u2019s vector space method \u2013 at-test\nshows the performance difference to be statistically significant at the 97.5% confidence level."
        },
        {
            "heading": "6 Conclusions and Future Work",
            "text": "We have presented a method for performing spoken document retrieval using lattices which is based on a statistical language modeling retrieval framework. Results show that our new method can significantly improve the retrieval MAP compared to using only the 1-best ASR transcripts. Also, our proposed retrieval method has been shown to outperform Mamou et al. (2006)\u2019s vector space latticebased retrieval method.\nBesides the better empirical performance, our method also has other advantages over Mamou et al.\u2019s vector space method. For one, our method computes expected word counts directly from rescored lattices, and does not require an additional step to\nconvert lattices lossily to WCNs. Furthermore, our method uses all the hypotheses in each lattice, rather than just the top 10 word hypotheses at each time interval. Most importantly, our method provides a more natural and more principled approach to lattice-based spoken document retrieval based on a sound statistical foundation, by harnessing the fact that lattices are themselves statistical models; the statistical approach also means that our method can be more easily augmented with additional statistical knowledge sources in a principled way.\nFor future work, we plan to test our proposed method on English speech corpora, and with largerscale retrieval tasks involving more queries and more documents. We would like to extend our method to other speech processing tasks, such as spoken document classification and example-based spoken document retrieval as well."
        }
    ],
    "title": "A Statistical Language Modeling Approach to Lattice-Based Spoken Document Retrieval",
    "year": 2007
}