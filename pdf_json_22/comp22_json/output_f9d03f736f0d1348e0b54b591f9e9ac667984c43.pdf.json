{
    "abstractText": "COPYRIGHT \u00a9 2022 Wirtshafter and Wilson. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms. Artificial intelligence insights into hippocampal processing",
    "authors": [
        {
            "affiliations": [],
            "name": "Jiyoung Kang"
        },
        {
            "affiliations": [],
            "name": "Matthew A. Wilson"
        }
    ],
    "id": "SP:d17bfc15b88598ef48679257e010b8860732462f",
    "references": [
        {
            "authors": [
                "D. Abel",
                "D. Arumugam",
                "L. Lehnert",
                "M. Littman"
            ],
            "title": "State abstractions for lifelong reinforcement learning, International Conference on Machine Learning",
            "venue": "PMLR 80, 10\u201319.",
            "year": 2018
        },
        {
            "authors": [
                "A. Banino",
                "C. Barry",
                "B. Uria",
                "C. Blundell",
                "T. Lillicrap",
                "P Mirowski"
            ],
            "title": "Vector-based navigation using grid-like representations in artificial agents",
            "venue": "Nature 557,",
            "year": 2018
        },
        {
            "authors": [
                "E. Bermudez-Contreras",
                "B.J. Clark",
                "A. Wilber"
            ],
            "title": "The Neuroscience of Spatial Navigation and the Relationship to Artificial Intelligence",
            "venue": "Front. Comput. Neurosci. 14:63. doi: 10.3389/fncom.2020.00063",
            "year": 2020
        },
        {
            "authors": [
                "C.N. Boccara",
                "M. Nardin",
                "F. Stella",
                "J. O\u2019Neill",
                "J. Csicsvari"
            ],
            "title": "The entorhinal cognitive map is attracted to goals",
            "venue": "Science 363,",
            "year": 2019
        },
        {
            "authors": [
                "R.M. Cichy",
                "A. Khosla",
                "D. Pantazis",
                "A. Torralba",
                "A. Oliva"
            ],
            "title": "Comparison of deep neural networks to spatio-temporal cortical dynamics of human visual object recognition reveals hierarchical correspondence",
            "venue": "Sci. Rep. 6:27755. doi: 10.1038/srep27755",
            "year": 2016
        },
        {
            "authors": [
                "L.L. Colgin",
                "E.I. Moser",
                "M.B. Moser"
            ],
            "title": "Understanding memory through hippocampal remapping",
            "venue": "Cell 31, 469\u2013477. doi: 10.1016/j.tins.2008.0",
            "year": 2008
        },
        {
            "authors": [
                "A.G.E. Collins",
                "M.J. Frank"
            ],
            "title": "Neural signature of hierarchically structured expectations predicts clustering and transfer of rule sets in reinforcement learning",
            "venue": "Cognition 152, 160\u2013169. doi: 10.1016/j.cognition.2016.04. 002",
            "year": 2016
        },
        {
            "authors": [
                "W. Dabney",
                "Z. Kurth-Nelson",
                "N. Uchida",
                "C.K. Starkweather",
                "D. Hassabis",
                "R Munos"
            ],
            "title": "A distributional code for value in dopamine-based reinforcement learning",
            "venue": "Nature 577,",
            "year": 2020
        },
        {
            "authors": [
                "K. Diba",
                "G. Buzsaki"
            ],
            "title": "Forward and reverse hippocampal place-cell sequences during ripples",
            "venue": "Nat. Neurosci. 10, 1241\u20131242. doi: 10.1038/nn1961",
            "year": 2007
        },
        {
            "authors": [
                "I. Djonlagic",
                "A. Rosenfeld",
                "D. Shohamy",
                "C. Myers",
                "M. Gluck",
                "R. Stickgold"
            ],
            "title": "Sleep enhances category learning",
            "venue": "Learn. Mem. 16, 751\u2013755. doi: 10.1101/ lm.1634509",
            "year": 2009
        },
        {
            "authors": [
                "D.J. Foster",
                "M.A. Wilson"
            ],
            "title": "Hippocampal theta sequences",
            "venue": "Hippocampus 17, 1093\u20131099. doi: 10.1002/hipo.20345",
            "year": 2007
        },
        {
            "authors": [
                "M. Fyhn",
                "T. Hafting",
                "A. Treves",
                "M.B. Moser",
                "E.I. Moser"
            ],
            "title": "Hippocampal remapping and grid realignment in entorhinal cortex",
            "venue": "Nature 446, 190\u2013194. doi: 10.1038/nature05601",
            "year": 2007
        },
        {
            "authors": [
                "S.J. Gershman"
            ],
            "title": "The Successor Representation: Its Computational Logic and Neural Substrates",
            "venue": "J. Neurosci. 38, 7193\u20137200. doi: 10.1523/JNEUROSCI. 0151-18.2018",
            "year": 2018
        },
        {
            "authors": [
                "A.S. Gupta",
                "M.A. van der Meer",
                "D.S. Touretzky",
                "A.D. Redish"
            ],
            "title": "Hippocampal replay is not a simple function of experience",
            "venue": "Neuron",
            "year": 2010
        },
        {
            "authors": [
                "T. Hafting",
                "M. Fyhn",
                "S. Molden",
                "M.B. Moser",
                "E.I. Moser"
            ],
            "title": "Microstructure of a spatial map in the entorhinal cortex",
            "venue": "Nature 436, 801\u2013806. doi: 10.1038/nature03721",
            "year": 2005
        },
        {
            "authors": [
                "E. Hoel"
            ],
            "title": "The overfitted brain: Dreams evolved to assist generalization",
            "venue": "Patterns 2:100244. doi: 10.1016/j.patter.2021.100244",
            "year": 2021
        },
        {
            "authors": [
                "S.A. Hollup",
                "S. Molden",
                "J.G. Donnett",
                "M.B. Moser",
                "E.I. Moser"
            ],
            "title": "Accumulation of hippocampal place fields at the goal location in an annular watermaze task",
            "venue": "J. Neurosci. 21, 1635\u20131644. doi: 10.1523/JNEUROSCI.21-0501635.2001",
            "year": 2001
        },
        {
            "authors": [
                "K.M. Igarashi",
                "L. Lu",
                "L.L. Colgin",
                "M.B. Moser",
                "E.I. Moser"
            ],
            "title": "Coordination of entorhinal-hippocampal ensemble activity during associative learning",
            "venue": "Nature 510, 143\u2013147. doi: 10.1038/nature13162",
            "year": 2014
        },
        {
            "authors": [
                "R.L. Jackson",
                "T.T. Rogers",
                "M.A. Lambon Ralph"
            ],
            "title": "Reverseengineering the cortical architecture for controlled semantic cognition",
            "venue": "Nat. Hum. Behav. 5, 774\u2013786. doi: 10.1038/s41562-020-01034-z",
            "year": 2021
        },
        {
            "authors": [
                "K.J. Jeffery",
                "A. Gilbert",
                "S. Burton",
                "A. Strudwick"
            ],
            "title": "Preserved performance in a hippocampal-dependent spatial task despite complete place cell remapping",
            "venue": "Hippocampus 13, 175\u2013189. doi: 10.1002/hipo.10047",
            "year": 2003
        },
        {
            "authors": [
                "A.J.E. Kell",
                "D.L.K. Yamins",
                "E.N. Shook",
                "S.V. Norman-Haignere",
                "J.H. McDermott"
            ],
            "title": "A Task-Optimized Neural Network Replicates Human Auditory Behavior, Predicts Brain Responses, and Reveals a Cortical Processing Hierarchy",
            "venue": "Neuron 98, 630\u2013644e16. doi: 10.1016/j.neuron.2018.0",
            "year": 2018
        },
        {
            "authors": [
                "A. Krizhevsky",
                "I. Sutskever",
                "E. Hinton"
            ],
            "title": "Imagenet classification with deep convolutional neural networks",
            "venue": "Adv. Neural Inf. Process. Syst. 25, 1097\u20131105.",
            "year": 2012
        },
        {
            "authors": [
                "I. Lee",
                "A.L. Griffin",
                "E.A. Zilli",
                "H. Eichenbaum",
                "M.E. Hasselmo"
            ],
            "title": "Gradual translocation of spatial correlates of neuronal firing in the hippocampus toward prospective reward locations",
            "venue": "Neuron 51, 639\u2013650. doi: 10.1016/j.neuron. 2006.06.033",
            "year": 2006
        },
        {
            "authors": [
                "L. Lehnert",
                "M.L. Littman",
                "M.J. Frank"
            ],
            "title": "Reward-predictive representations generalize across tasks in reinforcement learning",
            "venue": "PLoS Comput. Biol. 16:e1008317. doi: 10.1371/journal.pcbi.1008317",
            "year": 2020
        },
        {
            "authors": [
                "J. Lesting",
                "T. Daldrup",
                "V. Narayanan",
                "C. Himpe",
                "T. Seidenbecher",
                "Pape",
                "H. C"
            ],
            "title": "Directional theta coherence in prefrontal cortical to amygdalohippocampal pathways signals fear extinction",
            "venue": "PLoS One 8:e77707",
            "year": 2013
        },
        {
            "authors": [
                "J.K. Leutgeb",
                "S. Leutgeb",
                "A. Treves",
                "R. Meyer",
                "C.A. Barnes",
                "McNaughton",
                "B. L"
            ],
            "title": "Progressive transformation of hippocampal neuronal representations in \"morphed\" environments",
            "venue": "Neuron 48,",
            "year": 2005
        },
        {
            "authors": [
                "Y. Lian",
                "A.N. Burkitt"
            ],
            "title": "Learning an efficient hippocampal place map from entorhinal inputs using non-negative sparse coding",
            "venue": "eNeuro 8, ENEURO.557\u2013ENEURO.520. doi: 10.1523/ENEURO.0557-20.2021",
            "year": 2021
        },
        {
            "authors": [
                "M.D. McEchron",
                "J.F. Disterhoft"
            ],
            "title": "Hippocampal encoding of nonspatial trace conditioning",
            "venue": "Hippocampus 9, 385\u2013396. doi: 10.1002/(SICI)10981063(1999)9:4<385::AID-HIPO5>3.0.CO;2-K",
            "year": 1999
        },
        {
            "authors": [
                "F. Michon",
                "J.J. Sun",
                "C.Y. Kim",
                "D. Ciliberti",
                "F. Kloosterman"
            ],
            "title": "Postlearning Hippocampal Replay Selectively Reinforces Spatial Memory for Highly Rewarded Locations",
            "venue": "Curr. Biol. 29, 1436\u20131444e5. doi: 10.1016/j.cub.2019.0",
            "year": 2019
        },
        {
            "authors": [
                "E.I. Moser",
                "E. Kropff",
                "M.B. Moser"
            ],
            "title": "Place cells, grid cells, and the brain\u2019s spatial representation system",
            "venue": "Annu. Rev. Neurosci. 31, 69\u201389. doi:",
            "year": 2008
        },
        {
            "authors": [
                "J. O\u2019Keefe"
            ],
            "title": "Place units in the hippocampus of the freely moving rat",
            "venue": "Exp. Neurol",
            "year": 1976
        },
        {
            "authors": [
                "H.F. Olafsdottir",
                "C. Barry",
                "A.B. Saleem",
                "D. Hassabis",
                "H.J. Spiers"
            ],
            "title": "Hippocampal place cells construct reward related sequences through unexplored space",
            "venue": "eLife 4:e06063. doi: 10.7554/eLife.06063",
            "year": 2015
        },
        {
            "authors": [
                "J. O\u2019Neill",
                "B. Pleydell-Bouverie",
                "D. Dupret",
                "J. Csicsvari"
            ],
            "title": "Play it again: Reactivation of waking experience and memory",
            "venue": "Trends Neurosci",
            "year": 2010
        },
        {
            "authors": [
                "H. Penagos",
                "C. Varela",
                "M.A. Wilson"
            ],
            "title": "Oscillations, neural computations and learning during wake and sleep",
            "venue": "Curr. Opin. Neurobiol. 44, 193\u2013201. doi: 10.1016/j.conb.2017.05.009",
            "year": 2017
        },
        {
            "authors": [
                "S. Penick",
                "P.R. Solomon"
            ],
            "title": "Hippocampus, context, and conditioning",
            "venue": "Behav. Neurosci. 105, 611\u2013617. doi: 10.1037/0735-7044.105.5.611",
            "year": 1991
        },
        {
            "authors": [
                "B.E. Pfeiffer",
                "D.J. Foster"
            ],
            "title": "Hippocampal place-cell sequences depict future paths to remembered goals",
            "venue": "Nature 497, 74\u201379. doi: 10.1038/nature1 2112",
            "year": 2013
        },
        {
            "authors": [
                "M.H. Plitt",
                "L.M. Giocomo"
            ],
            "title": "Experience-dependent contextual codes in the hippocampus",
            "venue": "Nat. Neurosci. 24, 705\u2013714. doi: 10.1038/s41593-021-00816-",
            "year": 2021
        },
        {
            "authors": [
                "B.A. Richards",
                "T.P. Lillicrap",
                "P. Beaudoin",
                "Y. Bengio",
                "R. Bogacz",
                "A Christensen"
            ],
            "title": "A deep learning framework for neuroscience",
            "venue": "Nat. Neurosci",
            "year": 2019
        },
        {
            "authors": [
                "H. Sanders",
                "M.A. Wilson",
                "S.J. Gershman"
            ],
            "title": "Hippocampal remapping as hidden state inference",
            "venue": "eLife 9:e51140. doi: 10.7554/eLife.51140",
            "year": 2020
        },
        {
            "authors": [
                "J. Schrittwieser",
                "I. Antonoglou",
                "T. Hubert",
                "K. Simonyan",
                "L. Sifre",
                "S Schmitt"
            ],
            "title": "Mastering Atari, Go, chess and shogi by planning with a learned model",
            "venue": "Nature 588,",
            "year": 2020
        },
        {
            "authors": [
                "T. Sigurdsson",
                "K. Stark",
                "M. Karayiorgou",
                "J.A. Gogos",
                "A. Gordon"
            ],
            "title": "Impaired hippocampal-prefrontal synchrony in a genetic mouse model of schizophrenia",
            "venue": "Nature 464, 763\u2013767. doi: 10.1038/nature08855",
            "year": 2010
        },
        {
            "authors": [
                "D. Silver",
                "A. Huang",
                "C. Maddison",
                "A. Guez",
                "L. Sifre",
                "G van den Driessche"
            ],
            "title": "Mastering the game of Go with deep neural networks and tree",
            "year": 2016
        },
        {
            "authors": [
                "A.C. Singer",
                "M.F. Carr",
                "M.P. Karlsson",
                "L.M. Frank"
            ],
            "title": "Hippocampal SWR activity predicts correct decisions during the initial learning of an alternation task",
            "venue": "Neuron 77, 1163\u20131173. doi: 10.1016/j.neuron.2013.01.027",
            "year": 2013
        },
        {
            "authors": [
                "K.L. Stachenfeld",
                "M.M. Botvinick",
                "S.J. Gershman"
            ],
            "title": "The hippocampus as a predictive map",
            "venue": "Nat. Neurosci. 20, 1643\u20131653. doi: 10.1038/nn. 4650",
            "year": 2017
        },
        {
            "authors": [
                "G.P. Urcelay",
                "R.R. Miller"
            ],
            "title": "The functions of contexts in associative learning",
            "venue": "Behav. Process. 104, 2\u201312. doi: 10.1016/j.beproc.2014.02.008",
            "year": 2014
        },
        {
            "authors": [
                "E. V\u00e9rtes",
                "M. Sahani"
            ],
            "title": "A neurally plausible model learns successor representations in partially observable environments",
            "venue": "Adv. Neural Inf. Process. Syst. 32, 13714\u201313724.",
            "year": 2019
        },
        {
            "authors": [
                "J.X. Wang",
                "Z. Kurth-Nelson",
                "D. Kumaran",
                "D. Tirumala",
                "H. Soyer",
                "Leibo",
                "J. Z"
            ],
            "title": "Prefrontal cortex as a meta-reinforcement learning system",
            "venue": "Nat. Neurosci",
            "year": 2018
        },
        {
            "authors": [
                "J.C.R. Whittington",
                "T.H. Muller",
                "S. Mark",
                "G. Chen",
                "C. Barry",
                "N Burgess"
            ],
            "title": "The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation",
            "venue": "Cell 183,",
            "year": 2020
        },
        {
            "authors": [
                "A.M. Wikenheiser",
                "A.D. Redish"
            ],
            "title": "Decoding the cognitive map: Ensemble hippocampal sequences and decision making",
            "venue": "Curr. Opin. Neurobiol. 32, 8\u201315. doi: 10.1016/j.conb.2014.10.002",
            "year": 2015
        },
        {
            "authors": [
                "A.M. Wikenheiser",
                "A.D. Redish"
            ],
            "title": "Hippocampal theta sequences reflect current goals",
            "venue": "Nat. Neurosci. 18, 289\u2013294. doi: 10.1038/nn. 3909",
            "year": 2015
        },
        {
            "authors": [
                "M.A. Wilson",
                "B.L. McNaughton"
            ],
            "title": "Reactivation of hippocampal ensemble memories during sleep",
            "venue": "Science 265, 676\u2013679. doi: 10.1126/science. 8036517",
            "year": 1994
        },
        {
            "authors": [
                "H.S. Wirtshafter",
                "M.A. Wilson"
            ],
            "title": "Locomotor and Hippocampal Processing Converge in the Lateral Septum",
            "venue": "Curr. Biol. 29, 3177\u20133192. doi: 10. 1016/j.cub.2019.07.089",
            "year": 2019
        },
        {
            "authors": [
                "H.S. Wirtshafter",
                "M.A. Wilson"
            ],
            "title": "Differences in reward biased spatial representations in the lateral septum and hippocampus",
            "venue": "eLife 9:e55252. doi: 10.7554/eLife.55252",
            "year": 2020
        },
        {
            "authors": [
                "H.S. Wirtshafter",
                "M.A. Wilson"
            ],
            "title": "Lateral septum as a nexus for mood, motivation, and movement",
            "venue": "Neurosci. Biobehav. Rev. 126, 544\u2013559. doi:",
            "year": 2021
        },
        {
            "authors": [
                "A.M. Zador"
            ],
            "title": "A critique of pure learning and what artificial neural networks can learn from animal brains",
            "venue": "Nat. Commun. 10:3770. doi: 10.1038/ s41467-019-11786-6",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "TYPE Perspective PUBLISHED 07 November 2022 DOI 10.3389/fncom.2022.1044659"
        },
        {
            "heading": "OPEN ACCESS",
            "text": ""
        },
        {
            "heading": "EDITED BY",
            "text": "Jiyoung Kang, Pukyong National University, South Korea"
        },
        {
            "heading": "REVIEWED BY",
            "text": "Sebastien Royer, Korea Institute of Science and Technology, South Korea\n*CORRESPONDENCE Hannah S. Wirtshafter hsw@mit.edu\nRECEIVED 14 September 2022 ACCEPTED 21 October 2022 PUBLISHED 07 November 2022"
        },
        {
            "heading": "CITATION",
            "text": "Wirtshafter HS and Wilson MA (2022) Artificial intelligence insights into hippocampal processing. Front. Comput. Neurosci. 16:1044659. doi: 10.3389/fncom.2022.1044659"
        },
        {
            "heading": "COPYRIGHT",
            "text": "\u00a9 2022 Wirtshafter and Wilson. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.\nArtificial intelligence insights into hippocampal processing Hannah S. Wirtshafter1,2,3* and Matthew A. Wilson1,2,3,4\n1Department of Biology, Massachusetts Institute of Technology, Cambridge, MA, United States, 2Picower Institute for Learning and Memory, Cambridge, MA, United States, 3Massachusetts Institute of Technology, Cambridge, MA, United States, 4Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA, United States\nAdvances in artificial intelligence, machine learning, and deep neural networks\nhave led to new discoveries in human and animal learning and intelligence.\nA recent artificial intelligence agent in the DeepMind family, muZero, can\ncomplete a variety of tasks with limited information about the world in\nwhich it is operating and with high uncertainty about features of current\nand future space. To perform, muZero uses only three functions that are\ngeneral yet specific enough to allow learning across a variety of tasks\nwithout overgeneralization across different contexts. Similarly, humans and\nanimals are able to learn and improve in complex environments while\ntransferring learning from other contexts and without overgeneralizing. In\nparticular, the mammalian extrahippocampal system (eHPCS) can guide\nspatial decision making while simultaneously encoding and processing spatial\nand contextual information. Like muZero, the eHPCS is also able to adjust\ncontextual representations depending on the degree and significance of\nenvironmental changes and environmental cues. In this opinion, we will argue\nthat the muZero functions parallel those of the hippocampal system. We\nwill show that the different components of the muZero model provide a\nframework for thinking about generalizable learning in the eHPCS, and that\nthe evaluation of how transitions in cell representations occur between similar\nand distinct contexts can be informed by advances in artificial intelligence\nagents such as muZero. We additionally explain how advances in AI agents\nwill provide frameworks and predictions by which to investigate the expected\nlink between state changes and neuronal firing. Specifically, we will discuss\ntestable predictions about the eHPCS, including the functions of replay\nand remapping, informed by the mechanisms behind muZero learning. We\nconclude with additional ways in which agents such as muZero can aid in\nilluminating prospective questions about neural functioning, as well as how\nthese agents may shed light on potential expected answers.\nKEYWORDS\nhippocampus, replay, navigation, learning, context, DeepMind, muZero, modelbased learning\nFrontiers in Computational Neuroscience 01 frontiersin.org"
        },
        {
            "heading": "Introduction",
            "text": "A goal of artificial intelligence research is to design programs that can solve problems as well as, or better than humans. Algorithms such as AlphaGo and MuZero can compete with and beat the best trained humans at tasks such as Chess, Go, and Atari (Silver et al., 2016; Schrittwieser et al., 2020). Other artificial intelligence programs can do image classification at accuracy on par with and speeds surpassing humans (Krizhevsky et al., 2012). Ideally, advances in artificial intelligence and machine learning would transfer to understanding human intelligence. However, this often fails to be the case as machines and humans use different mechanisms to learn. For instance, while a supervised image classifier can only distinguish between an elephant and a dog after being presented with 1,000s of images, a child can distinguish between these animals after only a few stimulus exposures (Krizhevsky et al., 2012; Zador, 2019).\nHowever, advances in artificial intelligence, machine learning, and deep neural networks have also led to new discoveries in human and animal learning and intelligence (Richards et al., 2019). Notably, artificial intelligence research has proposed cellular and systems level mechanisms of reinforcement learning (Wang et al., 2018; Dabney et al., 2020), auditory processing (Kell et al., 2018; Jackson et al., 2021), object recognition (Cichy et al., 2016), and spatial navigation (Banino et al., 2018; Bermudez-Contreras et al., 2020; Lian and Burkitt, 2021). In several of these studies, artificial intelligence showed that specific inputs or parameters, such as grid cell coding, were sufficient to create a representation of the environment in which performance on a task closely resembles or surpasses human ability (Banino et al., 2018; Kell et al., 2018).\nA recent artificial intelligence agent in the DeepMind family, muZero, can complete a variety of tasks with limited information about the world in which it is operating and with high uncertainty about features of current and future space (Schrittwieser et al., 2020). For instance, unlike in chess, where each move results in a predictable board layout, Atari games (as well as real-world scenarios) involve complex environments with unknown action consequences. MuZero can perform impressively in these environments using only three functions. These functions first encode the environment, then compute potential actions and rewards, and then finally predict an estimation of the future environment. These three functions are both general and specific enough to allow learning across a variety of tasks without overgeneralization across different contexts.\nLike muZero, humans and animals can learn context dependent and independent task schema. Decisions by humans and animals are also made in complex spaces and result in unknown consequences, and, like muZero, humans and animals are still able to learn and improve in these environments. In particular, the mammalian extrahippocampal system (eHPCS)\ncan guide spatial decision making while simultaneously encoding and processing spatial and contextual information (O\u2019Keefe, 1976; Penick and Solomon, 1991; Hafting et al., 2005; Moser et al., 2008; Wirtshafter and Wilson, 2021). The eHPCS is also able to adjust contextual representations depending on the degree and significance of environmental changes and the significance of environmental cues (Hollup et al., 2001; Leutgeb et al., 2005; Lee et al., 2006; Fyhn et al., 2007; Wikenheiser and Redish, 2015b; Boccara et al., 2019; Wirtshafter and Wilson, 2020). In this opinion, we will argue that the muZero functions parallel those of the hippocampal system. We will show that the different components of the muZero model provide a framework for thinking about generalizable learning in the eHPCs.\nParallels in muZero with hippocampal function can help explain mechanisms of context independent learning\nThe ability to generalize learning to unknown contexts is a key component of human and animal intelligence. For instance, a driver is able to generalize that a red light means stop, regardless of the location of the intersection, the car being driven, or the time of day. While the neural mechanisms behind generalization remain largely unknown, most artificial intelligence models generalize using either modelfree or model-based learning. Model-free systems, which learn through experience, are inflexible, fast to run but slow to adapt to change, and estimate the best action based on cached values. Conversely, model-based systems, which aim to learn a model of the environment, are flexible but inefficient, highly sensitive to details of task representations, and easily adaptive to environmental changes (Stachenfeld et al., 2017; Gershman, 2018; V\u00e9rtes and Sahani, 2019). Although model-based, muZero improves on many shortcomings of model-based and modelfree systems by modeling only the elements of the environment important for decision making: the value (the strength of the correct position), the policy (the best action to take), and the reward (the benefit of the previous action). It models these three components using a representation function, a dynamics function, and a predictions function (Schrittwieser et al., 2020). Below, we argue these functions parallel functions found in the hippocampal system, and can be used to provide further insight into and build on current theories of hippocampal function during learning generalization."
        },
        {
            "heading": "The representation function",
            "text": "The first step of muZero processing is to encode the actual environment to a hidden state using a representation function\nFrontiers in Computational Neuroscience 02 frontiersin.org\n(Schrittwieser et al., 2020). This hidden state is a rendition of the environment that contains crucial information for performing the task. Similarly, several structures in the eHPCS flexibly represent environmental cues, with some regions placing emphasis on cues and locations of significance. Specifically, the entorhinal cortex (EC), CA regions of the hippocampus (HPC), and the lateral septum (LS) all contain cells whose firing rate is modulated by the location of the animal (termed grid cells, place cells, and \u201cplace-like\u201d cells, respectively) (O\u2019Keefe, 1976; Hafting et al., 2005; Moser et al., 2008; Wirtshafter and Wilson, 2019). Spatial representations in all three regions can be restructured by the presence of reward or cues/landmarks of interest, in which cells show a bias for coding for these significant locations (Hollup et al., 2001; Lee et al., 2006; Boccara et al., 2019; Wirtshafter and Wilson, 2020). When there are large changes to the environment, HPC and EC cell populations change representations and are said to \u201cremap\u201d (Fyhn et al., 2007; Colgin et al., 2008). It is likely that this phenomenon also occurs in the LS but it has not been studied.\nSelectively coding and over-representing causal features of the environment is important for generalization of learning across contexts (Collins and Frank, 2016; Lehnert et al., 2020). The refinement of this coding allows the inference of critical salient environmental features that may allow or preclude generalization to other contexts\u2014if the salient features are shared among two contexts, learning may be generalizable between the contexts (Collins and Frank, 2016; Abel et al., 2018; Lehnert et al., 2020). This muZero processing parallels the theory that the hippocampus can generalize across different contexts during learning by treating states that have equivalent actions or rewards as equivalent states. By compressing environmental representations into lower dimensionality abstractions, learning can be sped up and more easily transferred between environments with shared features (Lehnert et al., 2020). As such, the representation function provides a means by which learning can be generalized through contextual learning (Figure 1).\nThe dynamics and prediction functions and the Monte Carlo tree search algorithm\nIn muZero, a simulation always begins with the representation of the current state (environment), as created using the representation function. From this initial state, a number of hypothetical new states and their corresponding potential actions and rewards are derived using the dynamics and prediction functions, which both rely on the use of a Monte Carlo tree search (MCTS) algorithm.\nA MCTS allows a guided search of possible future actions. In brief, at a certain stage of the environment (such as a position in a game), subsequent possible actions and the resulting rewards are evaluated. Using these potential actions and rewards, a new\nhypothetical internal state is created and evaluated. Potential future states of this states are then considered and evaluated. This process occurs iteratively, forming expansive nodes off of the actual initial state, to allow for deeper search to evaluate more distant outcomes of potential actions. After expansion, the computed rewards are back-propagated up the tree to the current state and the mean value of an expansion is computed. Only then does the agent choose the optimal move or action and progress to the next state.\nUnlike AlphaGo, in which the rules of the game are known, MuZero learns the mechanics of the game and environment, and can relatively reliably only expand nodes that will likely result in rewarding actions. This expansion is first done using the dynamics function, progressive states are mapped, in a reoccurring process, based on different possible action choices. At each hypothetical state, the function computes a reward and a potential new internal hidden state (the future environment). Both the reward and the new state are computed based on the previous hidden state (Schrittwieser et al., 2020).\nFollowing the creation of each new state in muZero, a prediction function computes potential actions (a policy) and rewards (value) (Schrittwieser et al., 2020). The policy represents how the agent might act in this hidden state, while the value is an estimate of future rewards based on the current state. The value function is updated at each iteration of the dynamics function, as discussed.\nThis iterative process, of predicting and evaluating future actions in an environment has multiple corollaries in hippocampal processing: predictive place cell coding (the \u201csuccessor representation\u201d), theta sequences, and replay (Figure 1).\nPlace cells and the successor representation\nIn an animal model, it is possible that place cell coding plays a predictive role in cognition: in the \u201csuccessor representation\u201d (SR) view of place cells, place cells encode features of the environment in relation to their predictive relationship with other features, including the potential presence of reward or potential future trajectories (Stachenfeld et al., 2017; Gershman, 2018). The SR view of place and grid cells explain the aforementioned bias toward significant features in coding. This view would also explain why cells in the HPC and EC maintain stable environmental representations in environments that vary in small ways that do not change the predictive value of contextual clues. In noisy or partially observable environments, models of SR place cells function better than pure cognitive map place cell models. Additionally, in the SR model, state relationships can be learned latently, while reward values are learned locally, allowing for fast updating of changes in reward structure in different contexts (Stachenfeld et al., 2017; Gershman, 2018; V\u00e9rtes and Sahani, 2019).\nFrontiers in Computational Neuroscience 03 frontiersin.org\nFIGURE 1 MuZero mirrors hippocampus processing. (Left) Functions of muZero. (Right) Analogous/similar hippocampal functions. (Left top) In muZero, the representation functions maps the initial state, such as the position on a checker board, to an internal hidden state that emphasizes important features of the environment. (Right top) A similar processing in the extrahippocampal system (EHPCs) represents the environment in a cognitive map as a serious of cell positions encoded by grid and place cells. Place cells tend to have fields clustered around the location of a reward, such as the destination of a candy shop. (Left center) From the hidden state, a prediction function computes potential actions (policies) and rewards (values) of the location in the current state. (Right center) In the EHPCs, place cells encode features of the environment in relation to their predictive relationship with other features, such as the potential presence of reward. Additionally, state prediction in HPC (via theta sequences) can be coupled through theta coordination coherence to other areas of the brain that process action and reward. (Bottom left) In muZero, the dynamics function calculates reward (such as a captured checkers piece) and computes a new hidden state. (Bottom right) In the EHPCs, offline replay, which occurs during periods of sleep, emphasizes locations of previous reward. During replay, events can be selectively sampled from visited event space, with priority given to representations or locations that correspond with reward. Reward-predictive representations can then be compressed into a lower dimensional space. Replay can be comprised of novel state configurations that have not been experienced, such as a novel route to the reward location."
        },
        {
            "heading": "Theta sequences",
            "text": "The HPC also has an additional \u201clookahead\u201d mechanism to evaluate future trajectory choices after an animal has experienced an environment and formulated a \u201cmap\u201d with place cells. This hippocampal phenomenon, termed theta sequences, is a time-compressed and sequential firing of HPC place cells as if the animal were traversing a trajectory (Foster and Wilson, 2007). Because theta sequences can represent future possible trajectories, they are believed to play a role in planning (Wikenheiser and Redish, 2015a,b). Consistent with this idea, theta sequences incorporate information about future goal locations, and can use phase coupling of these rhythms to coordinate processing with other brain areas, much like the prediction function in muZero (Wikenheiser and Redish, 2015b; Penagos et al., 2017) (Figure 1).\nIn addition, the eHPC work in coordination with other structures to link present and future states with potential future actions. For instance, state prediction in HPC (via theta sequences) can be coupled through theta coordination\ncoherence to other areas of the brain that process action and reward, including executive systems such as the prefrontal cortex (policy function) and dopaminergic areas like the VTA (reward function). Disruption of this coherence may, therefore, interrupt functions that require accurate predictions and may thus impact learning (Sigurdsson et al., 2010; Lesting et al., 2013; Igarashi et al., 2014)."
        },
        {
            "heading": "Replay",
            "text": "In muZero, sampling of future states occurs without the performance of an action and is most analogous to hippocampal offline processing that occurs during non-REM sleep and quiet wake. During these periods, cells in the hippocampus engage in replay: highly compressed (100s of ms) place cell sequences that form a trajectory (Wilson and McNaughton, 1994; Diba and Buzsaki, 2007). It is believed that hippocampal replay plays a fundamental role in memory consolidation and may also be important for planning (Gupta et al., 2010; O\u2019Neill et al., 2010; Pfeiffer and Foster, 2013; Singer et al., 2013).\nFrontiers in Computational Neuroscience 04 frontiersin.org\nIn one theory of hippocampal function, hippocampal replay also plays an important role in generalization by aiding in the offline construction of compressed environmental representations (V\u00e9rtes and Sahani, 2019). During replay, events can be selectively sampled from visited event space, with priority given to representations that are reward predictive (Pfeiffer and Foster, 2013; Olafsdottir et al., 2015; Michon et al., 2019). Reward-predictive representations can then be compressed into a lower dimensional space that can be reused to plan future novel trajectories (Penagos et al., 2017). Replay may then use saved states to construct novel trajectories without the need for additional sampling or experience. Consistent with this idea, HPC replay selectively reinforces rewarded and significant locations, and it is possible that the shifting of place fields toward rewarded locations (a modification of representation) is dependent on replay. Additionally, replay can be comprised of novel sequences that have not been experienced, suggesting an environmental map can be generalized beyond prior experience (Gupta et al., 2010; Olafsdottir et al., 2015).\nQuestions for context dependent learning\nThe means by which the HPC is involved in the differential encoding of separate spatial environments is well studied. This process, known as \u201cremapping,\u201d occurs when place cells change spatial representations in new environments (Colgin et al., 2008). In addition to the remapping that occurs when moving between starkly different environments, when exposed to continuous environmental change, place cells will gradually morph to remap to the new environment (Leutgeb et al., 2005). Although modeling experiments have shown that no threshold for remapping exists (Sanders et al., 2020), it is still unknown, experimentally if there is a threshold level of difference required to induce remapping between environments.\nImportantly, learning also does not appear to be fully transferred between different environments where remapping is presumed to occur. For example, learning in both classical and operant conditioning tasks is nearly always context dependent, although the conditioned or operant response can be \u201cre\u201dlearned more quickly in the second environment (Urcelay and Miller, 2014). However, environmental changes may not affect the performance of navigational tasks to the same extent (Jeffery et al., 2003). Although cells in the HPC can encode conditioned and operant stimuli (as well as spatial location) (McEchron and Disterhoft, 1999; Wirtshafter and Wilson, 2019), it is not yet known whether any representation of the learned stimuli exists between remapped environments. Interestingly, however, animals with hippocampal lesions will transfer associative conditioning tasks across different environments (Penick and Solomon, 1991). It is similarly unknown whether this \u201cfailure\u201d of context-dependent learning is due to an inappropriate\npreservation of stimuli encoding, or a remapping failure in which the representation of the first environmental interferes with the representation of the second.\nAlthough muZero doesn\u2019t explicitly perform context discrimination, using the model it has built of the environment, muZero must infer, probabilistically, whether enough contextual elements have changed to require a new map and, potentially, new learning. Studying how probabilistic inference gives rise to context independent learning in muZero may provide insight into human and animal learning and generalization. Establishing what rules muZero uses to determine when a new map is needed and when learning is context dependent may shed light on the mechanisms behind contextual learning in animals.\nConceptual equivalence can result in predictions about hippocampal function\nHow might the advances made by muZero direct brain research? The evaluation of how transitions in cell representations occur between similar and distinct contexts is an under-researched topic in hippocampal systems neuroscience, and can be informed by advances in artificial intelligence agents such as muZero.\nAs previously explained, we believe AI can shed important light on the processes involved in contextual generalization. In muZero, there is a representational bias toward significant cues, and then this biased representation is compressed into a lower dimensionality. Representational bias allows for dimensionality reduction by beginning the selection of the most significant contextual elements (Lehnert et al., 2020). This reduction enables generalization by allowing learning inferences between environments with similarly compressed maps; i.e., in muZero, carry over of biased compressed representations allows for generalization (Lehnert et al., 2020).\nIn muZero, compression, which occurs during the dynamics function, plays an essential role in the generalization of learning. As previously explained, compression in the hippocampus may occur during hippocampal replay during sleep (Figure 1) (Penagos et al., 2017), and, like in muZero, this compression may be an important component of learning generalization (V\u00e9rtes and Sahani, 2019). We might expect, therefore, for disruptions in sleep replay to cause deficits in task generalization (Hoel, 2021), and for increased replay (such as sleep sessions between tasks) to enhance learning generalization (Djonlagic et al., 2009). If replay plays an important role in generalization, we also might expect replay sequences and structure to be similar between two environments with the same task rules. Specifically, replay may be structured around task organization and reward-contingent actions, resulting in a clustering of replay around shared action states between two environments.\nFrontiers in Computational Neuroscience 05 frontiersin.org\nThe compression of salient cues informs the creation of new hidden states, which may explain mechanisms of remapping between environments (Sanders et al., 2020). muZero\u2019s dynamics function does more than calculate a new hidden state based solely on known context; it also makes inferences based on policy (action) and value (reward) mapping. In other words, a state representation not only reflects the environment, but also the actions that lead to environmental consequences. If the hippocampus follows a similar mechanism, it is likely that \u201cknowing\u201d when to remap requires more than a simple evaluation of environmental cues (there may be similar contexts that require different actions) but also necessitates identifying differences in potential policies and rewards, especially during periods of uncertainty (such as when experiencing novelty) (Penagos et al., 2017; Sanders et al., 2020; Whittington et al., 2020). Because a portion of this evaluation of state similarity and difference happens offline, sleep replay may be an essential mechanism for remapping. In this context, remapping may result in the generating or updating of hidden states when there is uncertainty due to change in inputs.\nThe speed and type (partial or complete) of remapping that occurs may therefore depend on how past experience is evaluated offline during replay (Plitt and Giocomo, 2021). We might also, therefore, expect disrupting replay to change the speed at which remapping occurs, or whether it occurs at all. Failures in remapping would likely also impact the ability to distinguish different environments during learning, thereby causing inability to learn skills in a new environment, conflation of skills learned in different environments, and/or perseverance of skills in the incorrect environment.\nThe majority of current hippocampal research focuses on representational correspondence between neural activity and context, such as how the brain represents the spatial correlates of an environment through neuronal firing patterns. Absent from much of this research is a larger focus on questions of algorithmic correspondence between neuron activity and context, such as determining the required difference between two environments to induce remapping. We believe advances in AI agents will assist in shifting research toward the investigation of algorithmic correspondence, via providing frameworks and predictions (such the necessity for replay in contextual generalization), by which to investigate the expected link between state changes and neuronal firing. Agents such as\nmuZero can aid in illuminating these prospective questions, as well as shedding light on potential expected answers."
        },
        {
            "heading": "Data availability statement",
            "text": "The original contributions presented in this study are included in the article/supplementary material, further inquiries can be directed to the corresponding author."
        },
        {
            "heading": "Author contributions",
            "text": "HW and MW: study conception and design and manuscript editing. HW: draft manuscript preparation. Both authors reviewed the results and approved the final version of the manuscript."
        },
        {
            "heading": "Funding",
            "text": "HW was supported by the Department of Defense (DoD) through the National Defense Science and Engineering Graduate Fellowship (NDSEG) Program. The funders had no role in study design, data collection, and interpretation or the decision to submit the work for publication."
        },
        {
            "heading": "Conflict of interest",
            "text": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest."
        },
        {
            "heading": "Publisher\u2019s note",
            "text": "All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher."
        }
    ],
    "title": "Artificial intelligence insights into hippocampal processing",
    "year": 2022
}