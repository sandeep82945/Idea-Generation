{
    "abstractText": "Photoacoustic tomography (PAT) is a newly emerged imaging modality which enables both high optical contrast and acoustic depth of penetration. Reconstructing images of photoacoustic tomography from limited amount of senser data is among one of the major challenges in photoacoustic imaging. Previous works based on deep learning were trained in supervised fashion, which directly map the input partially known sensor data to the ground truth reconstructed from full field of view. Recently, score-based generative models played an increasingly significant role in generative modeling. Leveraging this probabilistic model, we proposed Rotation Consistency Constrained Score-based Generative Model (RCC-SGM), which recovers the PAT images by iterative sampling between Langevin dynamics and a constraint term utilizing the rotation consistency between the images and the measurements. Our proposed method can generalize to different measurement processes (32.29 PSNR with 16 measurements under random sampling, whereas 28.50 for supervised counterpart), while supervised methods need to train on specific inverse mappings.",
    "authors": [
        {
            "affiliations": [],
            "name": "Shangqing Tong"
        },
        {
            "affiliations": [],
            "name": "Hengrong Lan"
        },
        {
            "affiliations": [],
            "name": "Liming Nie"
        },
        {
            "affiliations": [],
            "name": "Jianwen Luo"
        },
        {
            "affiliations": [],
            "name": "Fei Gao"
        }
    ],
    "id": "SP:c4e2038d4602c986a9558a0c827e99a948ad25f0",
    "references": [
        {
            "authors": [
                "M. Abadi",
                "A. Agarwal",
                "P. Barham",
                "E. Brevdo",
                "Z. Chen",
                "C. Citro",
                "G.S. Corrado",
                "A. Davis",
                "J. Dean",
                "M. Devin",
                "S. Ghemawat",
                "I.J. Goodfellow",
                "A. Harp",
                "G. Irving",
                "M. Isard",
                "Y. Jia",
                "R. J\u00f3zefowicz",
                "L. Kaiser",
                "M. Kudlur",
                "J. Levenberg",
                "D. Man\u00e9",
                "R. Monga",
                "S. Moore",
                "D.G. Murray",
                "C. Olah",
                "M. Schuster",
                "J. Shlens",
                "B. Steiner",
                "I. Sutskever",
                "K. Talwar",
                "P.A. Tucker",
                "V. Vanhoucke",
                "V. Vasudevan",
                "F.B. Vi\u00e9gas",
                "O. Vinyals",
                "P. Warden",
                "M. Wattenberg",
                "M. Wicke",
                "Y. Yu",
                "X. Zheng"
            ],
            "title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems",
            "venue": "ArXiv abs/1603.04467",
            "year": 2016
        },
        {
            "authors": [
                "J. Bradbury",
                "R. Frostig",
                "P. Hawkins",
                "M.J. Johnson",
                "C. Leary",
                "D. Maclaurin",
                "G. Necula",
                "A. Paszke",
                "J. VanderPlas",
                "S. Wanderman-Milne",
                "Q. Zhang"
            ],
            "title": "JAX: composable transformations of Python+NumPy programs",
            "year": 2018
        },
        {
            "authors": [
                "A. Chambolle"
            ],
            "title": "An algorithm for total variation minimization and applications",
            "venue": "Journal of Mathematical Imaging and Vision 20, 89\u201397",
            "year": 2004
        },
        {
            "authors": [
                "S.G. Chang",
                "B. Yu",
                "M. Vetterli"
            ],
            "title": "Adaptive wavelet thresholding for image denoising and compression",
            "venue": "IEEE transactions on image processing : a publication of the IEEE Signal Processing Society 9 9, 1532\u201346",
            "year": 2000
        },
        {
            "authors": [
                "H. Chung",
                "B. Sim",
                "D. Ryu",
                "J.C. Ye"
            ],
            "title": "Improving diffusion models for inverse problems using manifold constraints",
            "venue": "ArXiv abs/2206.00941",
            "year": 2022
        },
        {
            "authors": [
                "H. Chung",
                "B. Sim",
                "J.C. Ye"
            ],
            "title": "Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction",
            "venue": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) pp. 12403\u201312412",
            "year": 2021
        },
        {
            "authors": [
                "H. Chung",
                "J.C. Ye"
            ],
            "title": "Score-based diffusion models for accelerated mri",
            "venue": "Medical image analysis 80, 102479",
            "year": 2021
        },
        {
            "authors": [
                "N. Davoudi",
                "X.L. De\u00e1n-Ben",
                "D. Razansky"
            ],
            "title": "Deep learning optoacoustic tomography with sparse data",
            "venue": "Nature Machine Intelligence pp. 1\u20138",
            "year": 2019
        },
        {
            "authors": [
                "S. Guan",
                "A.A. Khan",
                "S. Sikdar",
                "P.V. Chitnis"
            ],
            "title": "Limited-view and sparse photoacoustic tomography for neuroimaging with deep learning",
            "venue": "Scientific Reports 10",
            "year": 2019
        },
        {
            "authors": [
                "A. Hauptmann",
                "F. Lucka",
                "M.M. Betcke",
                "N. Huynh",
                "J. Adler",
                "B.T. Cox",
                "P.C. Beard",
                "S. Ourselin",
                "S.R. Arridge"
            ],
            "title": "Model-based learning for accelerated, limitedview 3-d photoacoustic tomography",
            "venue": "IEEE transactions on medical imaging 37, 1382 \u2013 1393",
            "year": 2017
        },
        {
            "authors": [
                "A. Jalal",
                "M. Arvinte",
                "G. Daras",
                "E. Price",
                "A.G. Dimakis",
                "J. Tamir"
            ],
            "title": "Robust compressed sensing mri with deep generative priors",
            "venue": "Advances in Neural Information Processing Systems 34, 14938\u201314954",
            "year": 2021
        },
        {
            "authors": [
                "H. Lan",
                "D. Jiang",
                "C. Yang",
                "F. Gao",
                "F. Gao"
            ],
            "title": "Y-net: Hybrid deep learning image reconstruction for photoacoustic tomography in vivo",
            "venue": "Photoacoustics 20",
            "year": 2020
        },
        {
            "authors": [
                "H. Lan",
                "K. Zhou",
                "C. Yang",
                "J. Cheng",
                "J. Liu",
                "S. Gao",
                "F. Gao"
            ],
            "title": "Ki-gan: Knowledge infusion generative adversarial network for photoacoustic image reconstruction in vivo",
            "venue": "International Conference on Medical Image Computing and ComputerAssisted Intervention",
            "year": 2019
        },
        {
            "authors": [
                "H. Liu",
                "K. Wang",
                "D. Peng",
                "H. Li",
                "Y. Zhu",
                "S. Zhang",
                "M. Liu",
                "J. Tian"
            ],
            "title": "Curvedriven-based acoustic inversion for photoacoustic tomography",
            "venue": "IEEE Transactions on Medical Imaging 35, 2546\u20132557",
            "year": 2016
        },
        {
            "authors": [
                "I. Loshchilov",
                "F. Hutter"
            ],
            "title": "Decoupled weight decay regularization",
            "venue": "International Conference on Learning Representations",
            "year": 2017
        },
        {
            "authors": [
                "X. Meng",
                "Y. Gu",
                "Y. Pan",
                "N. zhuan Wang",
                "P. Xue",
                "M. Lu",
                "X. He",
                "Y. Zhan",
                "D. Shen"
            ],
            "title": "A novel unified conditional score-based generative framework for multimodal medical image completion",
            "venue": "ArXiv abs/2207.03430",
            "year": 2022
        },
        {
            "authors": [
                "O. Ronneberger",
                "P. Fischer",
                "T. Brox"
            ],
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "venue": "Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18. pp. 234\u2013241. Springer",
            "year": 2015
        },
        {
            "authors": [
                "Y. Song",
                "S. Ermon"
            ],
            "title": "Generative modeling by estimating gradients of the data distribution",
            "venue": "Advances in neural information processing systems 32",
            "year": 2019
        },
        {
            "authors": [
                "Y. Song",
                "S. Ermon"
            ],
            "title": "Improved techniques for training score-based generative models",
            "venue": "Advances in neural information processing systems 33, 12438\u201312448",
            "year": 2020
        },
        {
            "authors": [
                "P. Vincent"
            ],
            "title": "A connection between score matching and denoising autoencoders",
            "venue": "Neural Computation 23, 1661\u20131674",
            "year": 2011
        },
        {
            "authors": [
                "M. Xu",
                "L.V. Wang"
            ],
            "title": "Universal back-projection algorithm for photoacoustic computed tomography",
            "venue": "SPIE BiOS",
            "year": 2005
        },
        {
            "authors": [
                "M. Xu",
                "L.V. Wang"
            ],
            "title": "Photoacoustic imaging in biomedicine",
            "venue": "Review of Scientific Instruments 77, 041101",
            "year": 2006
        }
    ],
    "sections": [
        {
            "text": "Keywords: Score-based Generative Model \u00b7 PAT Reconstruction \u00b7 Inverse Problem"
        },
        {
            "heading": "1 Introduction",
            "text": "Photoacoustic tomography (PAT) [25], which enables high optical absorption contrast and penetration depth, is a newly emerged imaging modality based on photoacoustic effect. When biological tissues are exposed to non-ionizing laser radiation, the tissues absorb the energy of the laser and convert the energy to heat, which leads to local transient thermoelastic expansion. During this procedure, wide band ultrasound signals are emitted, carrying knowledge about the \u22c6 The first two authors have contributed equally to this paper.\nar X\niv :2\n30 6.\n13 84\n3v 1\n[ cs\n.C V\n] 2\nstructural and functional information of the tissues. The ultrasound signals, so called photoacoustic signals, are then captured with ultrasound transducers, and will be further analysed to produce images with reconstruction algorithms.\nTraditional reconstruction algorithms of PAT include back projection (BP) algorithm [24] and delay-and-sum (DAS) algorithm. However, these approaches are vulnerable to the detection angles and numbers of measurements. Besides, several model-based iterative methods, such as total variation [3] and wavelet [4], are also used for undersampled PAT image enhancement.\nWith the in-depth development of deep learning theory, it has been widely used to perform undersampled reconstructions. To our best knowledge, previous studies with deep learning methods are mostly in an end-to-end supervised fashion, which directly trained a well-designed deep neural network with a pregenerated paired dataset. Ref. [8,13,9,12] utilized deep learning methods to reconstruct images, while Ref. [10] combined deep learning with model-based approaches. Ref. [17] also utilized diffusion model for multi-modal medical image completion. However, paired datasets either are expensive to obtain, or do not exist under some particular circumstances. Though supervised solutions provide high quality images, it hinders the generalization capacity, leading to some counterintuitive problems such as worse reconstruction results with even more measurements.\nWith the emergence of score-based generative models (SGM) [19,22], a wide range of methods based on SGM have been proposed to solve inverse problems in medical imaging in recent years. Ref. [11] first proposed a Langevin solver to produce MRI images by adding gradients of likelihood. After that, several works had been proposed to improve the performance of diffusion models for inverse problems in medical imaging [7,5,6]. Yang Song et al. proposed the first sampler to solve inverse problems in CT [21]. These methods are mostly proposed to\nsolve inverse problems in MRI and CT. To the best of our knowledge, there are no existing unsupervised methods for PAT reconstruction.\nIn this work, we propose the Rotation Consistency Constrained Score-based Generative Model (RCC-SGM) for PAT reconstruction. Our work, which utilized the SGM to solve inverse problem, is the first fully unsupervised method that has witnessed success on in vivo PAT data. We have shown that by imposing the rotation consistency between the measurements and images, an unsupervised SGM can achieve competitive results of reconstructing photoacoustic images to supervised ones. Specifically, using a trained generative prior, we proposed a solver to inject measurement information into the process of solving the reverse stochastic differential equation (SDE). Experiment results are evaluated both quantitatively and qualitatively. We achieved higher PSNR than the supervised UNet baselines. The evaluation showed that with random sampling of 16 measurements, we obtained 32.29 PSNR, while UNet obtained 28.50 PSNR; with limited view of 64 measurements, our method obtained 37.21 PSNR and 0.975 SSIM, while UNet obtained 31.31 PSNR and 0.970 SSIM."
        },
        {
            "heading": "2 Background",
            "text": ""
        },
        {
            "heading": "2.1 Photoacoustic Tomography",
            "text": "Photoacoustic imaging is an imaging modality based on photoacoustic effect [25]. Given a heat source H(r, t), the pressure p(r, t) in an acoustically homogeneous inviscid medium is given by\n\u22072p(r, t)\u2212 1 v2s\n\u22022\n\u2202t2 p(r, t) = \u2212 \u03b2\nCp\n\u2202 \u2202t H(r, t), (1)\nwhere \u03b2 is the isobaric volumn expansion coefficient, vs is the speed of sound in the medium, and Cp is the specific heat. The forward solution of Equation (1) in time domain can be achieved via Green\u2019s function,\np(r, t) = \u03b2\n4\u03c0Cp\n\u222b\u222b\u222b dr\u2032\n|r \u2212 r\u2032| \u2202H(r\u2032, t\u2032) \u2202t\u2032 \u2223\u2223\u2223\u2223 t\u2032=t\u2212|r\u2212r\u2032|/vs . (2)\nThe magnitude of the received photoacoustic signal is proportional to the local energy deposition, which illustrates the physiological optical absorption contrast."
        },
        {
            "heading": "2.2 Score-based Generative Modeling",
            "text": "Yang Song, et al. proposed SGMs [19,22], which produce samples via Langevin dynamics using gradients of the logarithmic data distribution estimated by score matching. In general, an SGM perturbs the training data with Gaussian noise during the forward (perturbation) process following the forward stochastic differential equation (SDE),\ndxt = f(t)xtdt+ g(t)dwt, (3)\nwhere wt is a standard Wiener process, t \u2208 [0, 1], f(t) : [0, 1] \u2192 R is called the drift coefficient of x and g(t) : [0, 1]\u2192 R is called the diffusion coefficient. A noise conditional score network is trained to capture the gradient of the logarithmic data distribution (i.e. score function, \u2207x log p(x)) solving the denoising score matching objective function [23]. In particular, the Variance Exploding (VE) SDE [22] is defined as\ndxt =\n\u221a d [\u03c32(t)]\ndt dwt, (4)\nwhich provides a stochastic process with exploding variance with t\u2192 +\u221e. Other SDEs include the Variance Preserving (VP) SDE [22] and sub-VP SDE [22].\nThe reverse process traces back from drawing a sample from the prior distribution and recover the deserved samples step by step via gradually removing noise using the estimated score. Theoretically, the corresponding reverse process of Equation (3) is\ndxt = [ f(t)xt \u2212 g2(t)\u2207xt log pt(xt) ] dt+ g(t)dw\u0304t, (5)\nwhere w\u0304t is a standard Wiener process in reverse direction, and dt is an infinitesimal negative time step, t \u2208 [0, 1]. The term \u2207xt log pt(xt) is called the score function of pt(xt). By solving the reverse time SDE, we can obtain samples with only the score of a distribution. There are various methods to solve SDEs. Yang Song, et al. proposed annealed Langevin dynamics (ALD) [19] to approximate samples from a distribution by gradually removing noise from a noisy image extracted from a prior distribution (i.e. normal distribution) with several times of noisy gradient ascent in a decreasing order of noise."
        },
        {
            "heading": "3 Methodology",
            "text": ""
        },
        {
            "heading": "3.1 Problem Overview",
            "text": "The basic inverse model of PAT imaging is the DAS algorithm. We used the model matrix, which is calculated following the curve-driven-based method [14], denoted by A \u2208 Rm\u00d7n and A\u2020 \u2208 Rn\u00d7m respectively, to approximate the forward and inverse operators. An image, denoted by x \u2208 Rn, is passed through the forward process. Measurements y \u2208 Rm are obtained, but only a subset of the measurements which consists of n\u0303 < m known photoacoustic signals are accessible for reconstruction. The measurement process can be modeled through a linear equation,\ny = Ax+ \u03b7 (6)\nwhere \u03b7 is the noise in the measurement process."
        },
        {
            "heading": "3.2 Controllable Generation with Score-based Generative Models",
            "text": "In this work, a noise conditional score network (NCSN) is trained to capture the scores of the distribution perturbed with L different noise scales ranging\nfrom \u03c3min to \u03c3max, denoted by s\u03b8(x, \u03c3i) for i = 1, 2, . . . , L. During the annealed Langevin dynamics (ALD) algorithm, the gradient ascent step is performed T times for a single noise scale. The outputs of ALD under various noise scales, denoted by {xi}Li=1, can be seen as an estimation of the sample perturbed with a sequence of noise. The last sample, x0, produced with the ALD under noise scale \u03c3min can be treated as an certain approximation of reconstruction.\nHowever, the reconstruction from limited number of measurements can be treated as sampling from a conditioned distribution p(x | y). To sidestep this intractable item, we can refer to the Bayes\u2019 rule, i.e.\n\u2207x log p(x | y) = \u2207x log p(x) +\u2207x log p(y | x), (7)\nwhere \u2207x log p(x) can be replaced by the NCSN we trained, and the gradient of likelihood \u2207x log p(y | x) is relatively easy to obtain [11]. We iterate the ALD from \u03c3max to \u03c3min by updating\nx (t+1) i \u2190 x (t) i + \u03f5\u2207x(t)i log p(x (t) i | y) +\n\u221a 2\u03f5z(t), (8)\nfor t = 0, 1, . . . , T \u22121 at the i-th noise scale. By plugging in Equation (7), we can inject the mapping between the regions to the sampling process, thus produce reconstructions."
        },
        {
            "heading": "3.3 Rotation Consistency Constraints",
            "text": "The main purpose of our idea is to modify the sampling algorithm of the SGM to gain better reconstruction results for PAT, which is achieved by regularizing the ALD with rotation consistency constraints between PAT measurements and images.\nGiven a signal set X \u2286 Rn, a group of transformations {Tg}|G|g=1, notated by G, is equivariant to the signal set if \u2200x \u2208 X , Tgx \u2208 X for all transformations in the transformation group, i.e.\nATg(x) = Tg(Ax). (9)\nLet R be the group of rotations by the angle between two adjacent sensors (360\u25e6/m degree) where |R| = m. Considering the symmetry of measurements and images, Tr is the rotation operator on images and T\u0303r is the shift operator for the sensor data, where r \u2208 R. For the full-sampled processes, the rotation transformation group should be equivariant to the model matrix, i.e.\nT\u0303r (Ax) = ATr (x) . (10)\nIn ideal, full-sampled cases, there exists the consistency. However, the equivariance may not hold in each approximation xi the ALD has produced, thus this error may accumulate gradually as the iteration proceeds. To correct this deviation in every noise scale in ALD, we do\nx (T ) i \u2190 x (T ) i + \u03b1A \u2020 [ T\u0303r ( Ax (T ) i ) \u2212ATr ( x (T ) i )] (11)\nright after the T steps of ALD update at the i-th noise scale described in Equation (8), where \u03b1 \u2208 [\u22121, 1] is a hyperparameter to be tuned."
        },
        {
            "heading": "4 Experiments",
            "text": "Setup Our experiments have assessed different sampling patterns, including uniform sampling, random sampling and limited view. Uniform sampling performs a uniform downsampling of PA signals. Random sampling stochastically chooses a deserved number of known measurements. Limited view chooses to leave a portion of the adjacent signals as known measurements while ignores the rest. In addition, reconstructions with different numbers of measurements ranging from 16 to 64 were also evaluated.\nDataset The dataset we used is a collection of in vivo PAT scans of mice. The scans were performed with a panoramic PAT system (SIP-PACT512, Uion Photoacoustic Technologies Co., Ltd., Wuhan, China). We used a 1064 nm laser to irradiate the mice, and the PA signals were then collected by a 360\u25e6 annular transducer array with 512 channels at 5 MHz center frequency. The sampling frequency was 40 MHz. Four healthy nude mice (8 weeks old, SPF Biotechnology Co., Ltd., Beijing, China) were involved in our experiment. Immersed in a homothermal water tank, these mice were scanned by moving the animal holder using a positioner to image the entire body in 0.02 mm steps. The experiments were approved by the Institutional Animal Care and Use Committee in Guangdong Provincial People\u2019s Hospital. The dataset contains 3382 scans, with 382 slices reserved for evaluation and the remaining 3000 samples used for training.\nStandard techniques for PAT reconstruction We included learning-free denoising methods for comparison. One of them is the linear reconstruction with no regularizations. The observations were recontructed using undersampled measurements by simply calculating A\u2020y. The other is the total variation method.\nWe chose \u03bb = 2000, tolerance \u03f5 = 2\u00d7 10\u22124 for the denoising. The iteration was performed up to 200 times.\nSupervised learning baselines UNet [18] is a simple baseline for undersampled PAT image denoising. The input undersampled signals are first converted to noisy images, and the UNets were trained to map the images to ground truths respectively for different measurement processes, optimized by AdamW optimizer [16]. The UNets were trained for 25000 iterations with batch size 16. The learning rate followed a cosine annealing schedule [15] from 1\u00d710\u22124 to 1\u00d710\u22127.\nScore-related baseline and our implementation We implemented a simple sampling method with only ALD without our constraint term, which was named Langevin. The score network we used was an implementation of NCSN++ [22] trained on 4\u00d7NVIDIA Titan RTX GPUs with a total batch size of 64 for 150000 iterations. The learning rate also followed a cosine annealing schedule, which started from 2.5\u00d7 10\u22125 and ended at 2.5\u00d7 10\u22127. A warm-up of 4000 steps was adopted, where the learning rate rose from 0 to 2.5 \u00d7 10\u22125 linearly. Gradient clipping was also used in training. The NCSN++ was optimized by AdamW optimizer. Exponential moving average (EMA) was applied to the parameters of NCSN++ with momentum m = 0.999, and the final parameters produced by EMA were used for evaluation. We used 500 noise scales varying from \u03c3min = 0.01 to \u03c3max = 100, following the studies in [20]. All the sampling hyperparameters were tuned on the training dataset for 250 steps of Bayesian optimization via ax-platform. The results of each method were generated with the optimal parameters. The Langevin approach and our method shared the same score model. All the methods were implemented in Google\u2019s JAX [2] and TensorFlow [1]."
        },
        {
            "heading": "5 Results and Discussions",
            "text": "Since our method is fully unsupervised, it is not restricted to any specific measurement process. We have tried different sampling patterns and different num-\nbers of measurements, and all the results are shown in Figure 3 and Table 1. Note that the supervised counterparts were trained and evaluated on different sampling patterns and different numbers of measurements respectively. As shown in Figure 3 and Table 1, we significantly outperformed the Langevin method in all measurement processes. In particular, the results of the Langevin approach showed significant distortion at 16 and 32 measurements. We achieved the highest PSNRs among all experiments with more than 40 measurements, while SSIMs still comparable. We could obtain competitive results to well-designed and trained supervised neural networks, while utilizing the same score model.\nWe have reported PSNR and SSIM values for they are basic metrics for estimating image reconstruction quality. Though the generalization capability is promising, the sampling time is relatively long due to high computation cost caused by excessive number of noise scales. The slow speed of reconstruction hinders the efficiency, which cannot meet the real-time scanning requirements of clinical needs. More in-depth studies are needed to modify the sampling algorithm for fast reconstruction."
        },
        {
            "heading": "6 Conclusion",
            "text": "Collectively, we proposed the first fully unsupervised framework named RCCSGM for solving inverse problems in PAT via SGM and ALD with rotation consistency constraints. Evaluation results demonstrated that our method surpassed vanilla Langevin method in all kinds of measurement processes, even beat supervised counterparts under some particular circumstances. Besides, as a fully unsupervised method, we achieved higher generalization capability to new measurement processes than other approaches. If modifying the number of measurements and sampling patterns, we can use the same generative prior to generate high quality samples with a single score model."
        }
    ],
    "title": "Score-based Generative Models for Photoacoustic Image Reconstruction with Rotation Consistency Constraints",
    "year": 2023
}