{
    "abstractText": "Artificial intelligence generated content (AIGC) has emerged as a promising technology to improve the efficiency, quality, diversity and flexibility of the content creation process by adopting a variety of generative AI models. Deploying AIGC services in wireless networks has been expected to enhance the user experience. However, the existing AIGC service provision suffers from several limitations, e.g., the centralized training in the pre-training, fine-tuning and inference processes, especially their implementations in wireless networks with privacy preservation. Federated learning (FL), as a collaborative learning framework where the model training is distributed to cooperative data owners without the need for data sharing, can be leveraged to simultaneously improve learning efficiency and achieve privacy protection for AIGC. To this end, we present FL-based techniques for empowering AIGC, and aim to enable users to generate diverse, personalized, and high-quality content. Furthermore, we conduct a case study of FL-aided AIGC fine-tuning by using the state-of-the-art AIGC model, i.e., stable diffusion model. Numerical results show that our scheme achieves advantages in effectively reducing the communication cost and training latency and privacy protection. Finally, we highlight several major research directions and open issues for the convergence of FL and AIGC.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xumin Huang"
        },
        {
            "affiliations": [],
            "name": "Peichun Li"
        },
        {
            "affiliations": [],
            "name": "Hongyang Du"
        },
        {
            "affiliations": [],
            "name": "Jiawen Kang"
        }
    ],
    "id": "SP:3c6f7ff2a85b4defcca7a2cbd9bb55a1b3a05ea7",
    "references": [
        {
            "authors": [
                "H. Du",
                "Z. Li",
                "D. Niyato",
                "J. Kang",
                "Z. Xiong",
                "D.I. Kim"
            ],
            "title": "Enabling ai-generated content (aigc) services in wireless edge networks",
            "venue": "arXiv preprint arXiv:2301.03220, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "I. Goodfellow",
                "J. Pouget-Abadie",
                "M. Mirza",
                "B. Xu",
                "D. Warde-Farley",
                "S. Ozair",
                "A. Courville",
                "Y. Bengio"
            ],
            "title": "Generative adversarial networks",
            "venue": "Communications of the ACM, vol. 63, no. 11, pp. 139\u2013144, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "D.P. Kingma",
                "M. Welling"
            ],
            "title": "An introduction to variational autoencoders",
            "venue": "Foundations and Trends\u00ae in Machine Learning, vol. 12, no. 4, pp. 307\u2013392, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J. Sohl-Dickstein",
                "E. Weiss",
                "N. Maheswaranathan",
                "S. Ganguli"
            ],
            "title": "Deep unsupervised learning using nonequilibrium thermodynamics",
            "venue": "International Conference on Machine Learning, pp. 2256\u20132265, PMLR, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "A. Vaswani",
                "N. Shazeer",
                "N. Parmar",
                "J. Uszkoreit",
                "L. Jones",
                "A.N. Gomez",
                "\u0141. Kaiser",
                "I. Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems, vol. 30, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "M. Zhang",
                "Y. He"
            ],
            "title": "Accelerating training of transformer-based language models with progressive layer dropping",
            "venue": "Advances in Neural Information Processing Systems, vol. 33, pp. 14011\u201314023, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Tian",
                "Y. Wan",
                "L. Lyu",
                "D. Yao",
                "H. Jin",
                "L. Sun"
            ],
            "title": "Fedbert: when federated learning meets pre-training",
            "venue": "ACM Transactions on Intelligent Systems and Technology (TIST), vol. 13, no. 4, pp. 1\u201326, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "R. Yan",
                "L. Qu",
                "Q. Wei",
                "S.-C. Huang",
                "L. Shen",
                "D. Rubin",
                "L. Xing",
                "Y. Zhou"
            ],
            "title": "Label-efficient self-supervised federated learning for tackling data heterogeneity in medical imaging",
            "venue": "IEEE Transactions on Medical Imaging, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "E.J. Hu",
                "Y. Shen",
                "P. Wallis",
                "Z. Allen-Zhu",
                "Y. Li",
                "S. Wang",
                "L. Wang",
                "W. Chen"
            ],
            "title": "Lora: Low-rank adaptation of large language models",
            "venue": "arXiv preprint arXiv:2106.09685, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "N. Ruiz",
                "Y. Li",
                "V. Jampani",
                "Y. Pritch",
                "M. Rubinstein",
                "K. Aberman"
            ],
            "title": "Dreambooth: Fine tuning text-to-image diffusion models for subjectdriven generation",
            "venue": "arXiv preprint arXiv:2208.12242, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "R. Gal",
                "Y. Alaluf",
                "Y. Atzmon",
                "O. Patashnik",
                "A.H. Bermano",
                "G. Chechik",
                "D. Cohen-Or"
            ],
            "title": "An image is worth one word: Personalizing text-to-image generation using textual inversion",
            "venue": "arXiv preprint arXiv:2208.01618, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "L. Zhang",
                "M. Agrawala"
            ],
            "title": "Adding conditional control to text-to-image diffusion models",
            "venue": "arXiv preprint arXiv:2302.05543, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "Y. Liu",
                "H. Du",
                "D. Niyato",
                "J. Kang",
                "Z. Xiong",
                "D.I. Kim",
                "A. Jamalipour"
            ],
            "title": "Deep generative model and its applications in efficient wireless network management: A tutorial and case study",
            "venue": "arXiv preprint arXiv:2303.17114, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "S. Hosseinalipour",
                "S.S. Azam",
                "C.G. Brinton",
                "N. Michelusi",
                "V. Aggarwal",
                "D.J. Love",
                "H. Dai"
            ],
            "title": "Multi-stage hybrid federated learning over large-scale d2d-enabled fog networks",
            "venue": "IEEE/ACM Transactions on Networking, vol. 30, no. 4, pp. 1569\u20131584, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "R. Rombach",
                "A. Blattmann",
                "D. Lorenz",
                "P. Esser",
                "B. Ommer"
            ],
            "title": "Highresolution image synthesis with latent diffusion models",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10684\u201310695, 2022. 8",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n30 7.\n07 14\n6v 1\n[ cs\n.D C\n] 1\n4 Ju\nl 2 02\n3\nFederated Learning-Empowered AI-Generated\nContent in Wireless Networks Xumin Huang, Peichun Li, Hongyang Du, Jiawen Kang, Member, IEEE\nDusit Niyato, Fellow, IEEE, Dong In Kim, Fellow, IEEE, and Yuan Wu, Senior Member, IEEE\nAbstract\u2014Artificial intelligence generated content (AIGC) has emerged as a promising technology to improve the efficiency, quality, diversity and flexibility of the content creation process by adopting a variety of generative AI models. Deploying AIGC services in wireless networks has been expected to enhance the user experience. However, the existing AIGC service provision suffers from several limitations, e.g., the centralized training in the pre-training, fine-tuning and inference processes, especially their implementations in wireless networks with privacy preservation. Federated learning (FL), as a collaborative learning framework where the model training is distributed to cooperative data owners without the need for data sharing, can be leveraged to simultaneously improve learning efficiency and achieve privacy protection for AIGC. To this end, we present FL-based techniques for empowering AIGC, and aim to enable users to generate diverse, personalized, and high-quality content. Furthermore, we conduct a case study of FL-aided AIGC fine-tuning by using the state-of-the-art AIGC model, i.e., stable diffusion model. Numerical results show that our scheme achieves advantages in effectively reducing the communication cost and training latency and privacy protection. Finally, we highlight several major research directions and open issues for the convergence of FL and AIGC.\nIndex Terms\u2014Federated learning, AIGC, wireless networks, deep learning, stable diffusion.\nI. INTRODUCTION\nTo generate a vast amount of high-quality digital content for Web 3.0 applications such as Metaverse, artificial intelligence generated content (AIGC) has emerged as a promising technology to adopt a variety of generative AI models for producing, handling and modifying diverse data, e.g., text, image and audio. Due to the outstanding capability of content generation, AIGC achieves great potential in changing the lifestyle of humans and making tremendous progress in different domains. Furthermore, deploying AIGC services in wireless networks has been envisioned to enable users to have a real-time interactive environment, context awareness support, personalized and engaging experience [1]. However,\nX. Huang and P. Li are with State Key Laboratory of Internet of Things for Smart City, University of Macau, Taipa, Macau, China (e-mail: huangxu min@163.com; peichunli@um.edu.mo). H. Du, and D. Niyato are with the School of Computer Science and Engineering, Nanyang Technological University, Singapore (e-mail: hongyang001@e.ntu.edu.sg; dniyato@ntu.edu.sg). J. Kang is with School of Automation, Guangdong University of Technology, Guangzhou 510006, China (e-mail: kavinkang@gdut.edu.cn). D. I. Kim is with the Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon 16419, South Korea (e-mail: dikim@skku.ac.kr). Y. Wu is with State Key Laboratory of Internet of Things for Smart City, University of Macau, Taipa, Macau, China, and also with Department of Computer and Information Science, University of Macau, Taipa, Macau, China (e-mail: yuanwu@um.edu.mo).\nAIGC service provision is still facing several challenging issues. On one hand, both model size and dataset size of a large-scale AIGC models are extremely large and cause critical difficulties to pre-train, fine-tune and infer the AIGC model among resource-constrained devices. For example, Chat Generative Pre-trained Transformer (ChatGPT) is one of the latest large language models trained on a huge amount of text data, i.e., 300 billion words (570 GB) and with over 175 billion parameters. On the other hand, data privacy has become a growing concern for users in the open wireless distributed computing environment when they join AIGC services by using their local data.\nDespite its great benefits and advantages, there have been several vital challenges in the AIGC processes, including pretraining, fine-tuning, and inference as follows.\n\u2022 Since AIGC pre-training necessitates enormous comput-\ning power and time, most of the devices with the limited resource capacity and power supply are difficult to join this process. Their data cannot be fully utilized. \u2022 AIGC fine-tuning transfers a pre-trained model to a wide\nrange of downstream tasks. Fine-tuning aims to apply the pre-trained model\u2019s knowledge to new problems, i.e., downstream tasks. But the traditional fine-tuning process relies on continuous data collection from the users, which violates individual data privacy of users. \u2022 Optimizations for AIGC inference suffer from imperfect\ninformation and uncertainties of network environment, where deep reinforcement learning (DRL) can provide a promising solution. For example, DRL was adopted in [1] to orchestrate the multi-user AIGC inference. We further consider a cooperative multi-agent learning environment without centralizing the training data of all agents.\nFacing the above challenges, federated learning (FL), as a most prevalent distributed training and collaborative learning framework, provides an effective approach to empower AIGC. FL enables distributed users/clients to collaboratively train a shared model while keeping all training data on the local storage. In particular, FL provides a promising scheme for enabling the AIGC pre-training and fine-tuning in a distributed manner. Compared with the centralized AIGC via cloud, distributive AIGC via FL promotes collaboration among multiple clients and has advantages in improving resource utilization efficiency, collecting fresh data for model training, reducing notable AIGC service delay and mitigating certain security and privacy threats. Thanks to FL, both efficiency and privacy of AIGC can be effectively improved. More specifically,\n\u2022 FL can be leveraged for AIGC pre-training by delegating\na proper training task to a number of clients. Clients can join the pre-training process and contribute their data. \u2022 FL can facilitate AIGC fine-tuning such that the clients\ncan distributively fine-tune a pre-trained AIGC model in a privacy-preserving manner. \u2022 Federated reinforcement learning enables each agent to\nonly share the learning experience with other agents and accelerate the training process, which is helpful to save the time and energy consumption for solving the multiuser AIGC inference problem.\nHowever, the integration of FL and AIGC is not straightforward and poses several challenging issues. Accounting for the huge scale of an AIGC model with billions of parameters, it is prohibitive for a conventional client to perform the pre-training of an entire AIGC mode or fine-tuning all model parameters. In addition, multiple iterations of local training and global aggregation in FL cause high resource consumption to AIGC services, which further aggravates challenges of deploying AIGC services in wireless networks. In federated pre-training, each client is suitable to train a small part of the AIGC model. In federated fine-tuning, we should limit the number of parameters which are fine-tuned by each client such that we can reduce the data communication of interacting with the parameter server. In federated fine-tuning and federated reinforcement learning for inference, proper FL designs can be discussed to accelerate the training convergence. The challenges motivate us to investigate how to exploit FL and its variants for empowering AIGC in different processes.\nIn this article, we focus on leveraging FL for AIGC, and study how to decentralize the model training procedures regarding AIGC pre-training, fine-tuning and inference. We discuss the challenges of the existing AIGC, and propose instrumental FL-based techniques to empower AIGC and implement the FL procedure in different approaches, i.e., parallel, split and sequential, according to different application conditions. We compare the techniques and reveal the remarkable benefits of FL to AIGC. Besides, we present a case study of FL-aided AIGC fine-tuning, where we consider the stable diffusion model, one of the state-of-the-art AIGC models, and study how to fine-tune the stable diffusion model on a neural style transfer task under the FL setting. Finally, we provide extensive discussions about opportunities and challenges of FL-empowered AIGC.\nThe main contributions of this article can be summarized\nas follows.\n\u2022 We propose a FL-empowered approach to introduce the\nFL-based techniques for the AIGC processes. To the best of our knowledge, this is the first work that considers the integration of FL and AIGC in wireless environment. \u2022 We present a case study to show the potential of FL for\nfine-tuning the stable diffusion model. This case study can be straightforwardly extended to other AIGC finetuning scenarios. Compared with a traditional scheme, our scheme reduces both the communication cost and training latency while achieving the identical convergence performance to it.\n\u2022 We outline research challenges and present potential\nsolutions to the FL-empowered AIGC. We discuss open directions on how economic theories and emerging technologies such as semantic communication, blockchain and edge intelligence can be leveraged for the convergence of FL and AIGC."
        },
        {
            "heading": "II. DEEP GENERATIVE MODELS AND AIGC PROCESSES",
            "text": "In this section, we present a short overview of FLempowered AIGC, as shown in Fig. 1. We introduce the deep generative models and AIGC processes. The up-to-date research works of applying FL for the AIGC processes are also discussed."
        },
        {
            "heading": "A. Fundamentals of Deep Generative Models",
            "text": "As a key enabling technology for AIGC, deep generative model learns to generate predictions in the identical modality as the input data with one modality. The rapid development of deep generative models has witnessed several promising techniques and we pay attention to Generative Adversarial Network (GAN), Variational Autoencode (VAE), diffusion model and Transformer. We summarize technique details of the deep generative models and their comparisons in Table I.\n\u2022 GAN: As a unsupervised machine learning algorithm,\nGAN aims to generate new data from the same space of the original data [2]. GAN consists of two neural networks named by generator and discriminator, which are trained together in an adversarial manner. However, GAN cannot support multi-modal generation. \u2022 VAE: As a probabilistic generative model, VAE aims to\nmaximize the probability of the generated output with respect to the input data [3]. VAE is an adaptation from a standard autoencoder, transforms the data from a higher-dimensional to a lower-dimensional space and further tackles the critical problem of non-regularized latent space in the traditional autoencoder. Both GAN and VAE are two popular approaches that have been widely commonly used for generative modeling. Compared with GAN, VAE learns from labeled data and is easier to train. \u2022 Diffusion model: Also known as diffusion probabilistic\nmodel, diffusion model is inspired by non-equilibrium thermodynamics proposed by Sohl-Dickstein et al. [4]. Diffusion model destructs training data by gradually adding Gaussian noise in the forward process, then reverses this process to generate the desired data from the noise. Compared with VAE and GAN, diffusion model can achieve a better learning performance but requires more training data, computational cost and time. \u2022 Transformer: Following an encoder-decoder structure,\nTransformer relies on the adaption of self-attention layers in both the encoder and decoder [5]. By capturing the relations among elements of the sequential data, Transformer is suited to process sequence-to-sequence prediction tasks, and enables parallel training for both the data and model. Compared with the above generative models, Transformer achieves an advantage in performing the large-scale training.\nTo enable the convenient use of AIGC, pre-trained large models, i.e., foundation models, are trained on large, unlabeled datasets and developed to adapt to a wide range of downstream tasks. In recent years, leading AI industries have presented a variety of pre-trained large models for AIGC, including the models for natural language processing such as BERT by Google and GPT by OpenAI, the models for computer vision such as Florence by Microsoft, the models for multimodal training such as Dall-E 2 by OpenAI, Imagen by Google, and stable diffusion by Stability AI. We provide more details of GPT and stable diffusion as follows.\nMany foundation models in the natural language processing domain rely on the Transformer-based architecture for training, due to the remarkable learning ability and parallelism of Transformer. In this regard, GPT refers to a series of generative pre-Trained Transformer models released by OpenAI and has evolved from the first version GPT-1 in 2018 to the latest model GPT-4 in 2023. GPT 3.5 is an intermediate version between GPT-3 and GPT-4. As a popular AI chatbot based on GPT-3.5, ChatGPT is developed as a variant of GPT with\nchatbot functionality, and is fine-tuned by jointly utilizing supervised learning and reinforcement learning to improve the conversational abilities of the chatbot1. Due to the fastrising popularity, ChatGPT reportedly has over 100 million active users globally. In addition, diffusion model provides a cutting-edge approach for text-conditioned image generation and stable diffusion as one of the well-known foundation models have attracted extensive attention. Stable diffusion is an open-source visual generative foundation model released by Stability AI in 2022, and has been commonly used for generating high-quality images in massive applications. Stable diffusion is one of the most flexible AI image generators to create AI-generated images and modify the images on demand, e.g., inpainting and super-resolution, according to the text prompts2. Besides, running a stable diffusion model also requires relatively lower memory, e.g., 16 GB of DDR4 or DDR5 RAM, and GPU usage, e.g, 10 GB VRAM.\n1https://openai.com/blog/chatgpt 2https://stability.ai/blog/stable-diffusion-v2-release"
        },
        {
            "heading": "B. AIGC Processes",
            "text": "In the following, we discuss the challenging issues and current solutions of AIGC processes, including pre-training, fine-tuning and inference. 1) Pre-training: AIGC depends on large-scale pre-trained models with several billions of parameters. Existing pretraining methods require an available large-scale dataset and a huge investment in hardware (e.g., thousands of GPUs) and time (e.g., several days). For example, training a GPT-3 model with over 175 billion parameters requires more than 4 months with 1,000 GPUs and the training cost is estimated from 4.6 to 12 million US dollars for a single training run. The big companies like Google and OpenAI can afford but individuals and small companies are difficult to help pre-train a large model although they have available training data. Effective collaboration among different parties should be explored to facilitate the pre-training process and improve the diversity of pre-training data.\nTo improve the pre-training performance, effective schemes are provided to alleviate the unbearablel computational time and expense. Take the Transformer-based foundation models as an example. Proper pre-training designs are introduced to make well use of the inherent parallelism in Transformers. Model architecture change by applying the switchable transformer blocks to drop some Transformer layers for each minibatch [6] is proposed to train the models at a faster rate. FL has been leveraged to enhance the pre-training processes of BERT and ImageNet. The authors in [7] combine FL with split learning to prevent collecting the tremendous training data and permit resource-constrained clients to join the BERT pre-training. Split learning enables each client to train a computation-lightweight part of the model as a client-side model and FL further enables all clients to collaboratively train the shared client-side model in a privacy-preserving manner. Federated self-supervised learning is integrated with the existing masked image modeling methods to facilitate the ImageNet pre-training [8]. 2) Fine-tuning: Before the practical use of a pre-trained AIGC model, fine-tuning is performed to properly enhance\nthe model\u2019s performance on a downstream task and adjust the model\u2019s parameters to suit the new data, e.g., in a new domain.\nWe specifically consider the diffusion-based text-to-image generative model and introduce baseline methods for AIGC fine-tuning. The traditional fine-tuning method is to directly fine-tune the full or partial weights of a pre-trained model. Many advanced fine-tuning methods have been presented to overcome the limitations of the traditional method. Lowrank adaptation (LoRA) fine-tuning is proposed by Microsoft to explore low-rank adaptation to facilitate the fine-tuning process in a storage and computation efficient manner [9]. In Section IV, we apply this method to fine-tune a stable diffusion model on a customized dataset. DreamBooth fine-tuning [10] is proposed by Google to bind a unique identifier with an interesting subject in a few (typically 3-5) input images, and embed the subject within the pre-trained diffusion model\u2019s output domain to generate new images of the subject. Textual inversion fine-tuning [11] is proposed by NVIDIA to find new pseudo-words that capture high-level semantic information and fine-grained visual details in the textual embedding space of a frozen latent diffusion model. ControlNet [12] adds an adapter model to a frozen pre-trained diffusion model, and train the adapter model to let the diffusion model support additional input conditions. We have a brief introduction of the above fine-tuning methods and compare their gradient and training data sizes in the first three columns of Table II.\n3) Inference: A fine-tuned AIGC model is deployed in wireless networks to provide AIGC inference services for users. Several works have been presented to improve the inference efficiency and provide considerable payments for the inference services. To incentivize AIGC service providers, a diffusion-based contract theory is employed to tackle the problem on how a user designs proper contracts for different AIGC service providers with different types [13]. Deep reinforcement learning is adopted to tackle the inference service matching problem under incomplete information [1]. Reinforcement learning algorithms show great potential to overcome the incomplete information condition when the inference services have insufficient prior knowledge. Furthermore, we need to\nprevent each agent from directly sharing any private information in the cooperative multi-agent learning environment.\nAccording to the overview of AIGC, we realize that FL has begun to be applied for decentralizing the model training procedures regrading the AIGC processes. However, the integration of FL and AIGC is not straightforward. We take finetuning an AIGC model in a federated manner as an example. For the privacy protection, the federated fine-tuning methods are motivated but technical challenges remain unresolved. For example, the combination of FL and LoRA is helpful to exploit the decomposition matrices for achieving the communication and data-efficient fine-tuning while this may deteriorate the diversity of the generated content. We summarize the pros and cons of combining the fine-tuning methods with FL for AIGC in the last two columns of Table II."
        },
        {
            "heading": "III. FEDERATED LEARNING-AIDED AIGC",
            "text": "In this section, we introduce features, technique details and\ndiscussions of FL-aided AIGC."
        },
        {
            "heading": "A. Features of Federated Learning Designs for AIGC",
            "text": "We discuss the necessitated features of the FL designs for AIGC fine-tuning when both the FL and AIGC are deployed in wireless networks.\n\u2022 Data-efficient: For local model training of each client,\nthe amount of downstream data is properly decided to overcome the overfitting problem and restrict the number of local training iterations. \u2022 Hardware-friendly: Fine-tuning methods are selected and\nadjusted to reduce the GPU VRAM usage and make GPU-based computation more efficient. \u2022 Parameter-efficient: Parameter-efficient fine-tuning tech-\nniques aim to train a small portion of the model parameters while keeping the rest frozen to cut down the computation workloads, time and communication cost."
        },
        {
            "heading": "B. Federated Learning-Based Techniques for AIGC",
            "text": "We propose FL and the variants to empower AIGC, as shown in Fig. 2. In the conventional FL, all clients train an entire learning model in a parallel approach. This may hinder the participation willingness of lightweight clients that are difficult to train the computation-intensive model, and degrade the convergence rate when a large number of clients with heterogeneous data sizes and computing capability participate in FL. Thus, we propose to implement FL in other approaches, i.e., split and sequential, according to the specific application scenarios. We aim to extend the adoption of FL in the AIGC processes, and make FL designs better suited for different application purposes. We provide more details as follows.\n1) FL in a parallel approach: : The implementation of the conventional FL is shown in Fig. 2(a). In each global round (i.e., communication round), Steps 2-5 are performed and the steps repeat until the global model converges.\n2) FL in a split approach: : The implementation depends on the joint utilization of FL and split learning. The entire AIGC model is split into two sub-models: client-side model C and server-side model S. The split approach provides an opportunity for general clients to collaboratively train a large AIGC model since the client-side model is computationlightweight and acceptable for the general clients with limited computing capability. In a global round of FL, each client receives the initialized weights of the client-side model and trains it by using the local data. The parameter server has dual responsibilities: i) helps each client update its clientside model and updates its server-side model by using split learning, ii) aggregates all client-side models by using the FedAvg algorithm, which assigns higher weights to the clients with more local data. Here, output of the last layer of a clientside model is named by smash data D. We provide more details of the global round in Fig. 2(b).\n3) FL in a sequential approach: : The implementation depends on device-to-device (D2D) based model propagation [14] among all clients. All local model training tasks are performed among the clients one by one. A client takes a turn to play as a relay training node, which receives a local model from its previous client, train the local model by using the local data, and pass the updated local model to the next client. The model propagation between any two adjacent clients is quickly performed by using D2D communications to improve spectral and energy efficiency of cellular networks. We provide more details of the global round in Fig. 2(c)."
        },
        {
            "heading": "C. Discussions on Federated Learning-Empowered AIGC",
            "text": "FL can be performed in different approaches to empower AIGC. The parallel approach is easily applied and can resist a certain proportion of security threats such as model poisoning attacks through the gradient averaging operation. However, it presents a relatively higher computational requirement for the participating clients since each client needs to train the entire AIGC model. The convergence performance of the original FL cannot be guaranteed with the increasing number of the clients. The split approach prevents the clients from undertaking the heavy computation workloads, and enables the resource-constrained clients to join the FL procedure by letting them only train a computational-lightweight part of the model. The split approach is suitable for training the models with Transformer-based architectures since the models are conveniently split into two parts with different computation workloads. However, the split approach may be inapplicable for training some special AIGC models since the parameter server could simultaneously require the input data and label data of each client to perform the backward propagation for updating the client-side model. For example, FL in a split approach is not compatible with the training of a conventional denoising diffusion probabilistic model, which necessitates the original image data of the clients for each training iteration. At this time, sharing the local data of the clients with the parameter server will violate the original privacy-preserving rule of FL. The sequential approach is convinced to greatly improve the convergence rate of FL. However, the sequential\napproach could aggravate some security threats to the FL procedure. Due to the model propagation among the clients, the sequential approach makes the FL procedure more susceptible to model poisoning attacks and gradient leakage attacks.\nThe proposed FL-based techniques are helpful to facilitate the development and deployment of the AIGC models with more data utilization for pre-training, less communication cost for fine-tuning and higher-level optimizations for inference. We summarize the benefits of FL to AIGC as follows.\n\u2022 Data diversity for AIGC pre-training: The diversity of\npre-training data increases after FL enables the clients to help pre-train a large AIGC model. \u2022 Communication saving for AIGC fine-tuning: FL and the\nparameter-efficient fine-tuning methods work together to improve the communication efficiency in the AIGC finetuning. \u2022 Knowledge transferring for AIGC inference: Federated\nreinforcement learning encourages the agents to use the knowledge of other agents, which is beneficial to accelerate the training process of the multi-agent learning."
        },
        {
            "heading": "IV. CASE STUDY: FEDERATED FINE-TUNING FOR A STABLE DIFFUSION MODEL",
            "text": "In this section, we present a detailed case study of federated fine-tuning for a stable diffusion model. We perform the FL procedure in a sequential approach for fine-tuning the stable diffusion model in [15]. We aim to generate traditional Chinese ink paintings by leveraging the LoRA-based neural style transfer technique. We design a federated fine-tuning framework where multiple clients collaboratively customize the general image synthesis model for creating a unique artistic style and D2D based model propagation is utilized to accelerate the training convergence for them.\nWe consider a training scenario with a set of clients and a parameter server. Let w denote the weight of the foundation stable diffusion model, and v denote the weight of the additional bypass introduced by LoRA. During the fine-tuning process, we fix the base weight w and only train the additional weight v. The training procedure of the federated fine-tuning with the D2D communications is described as follows.\n\u2022 Step 1: The parameter server initializes an index set S\nthat equalizes the original set of the clients, and randomly selects a client i \u2208 S. In the global round t, the parameter server transmits the bypass weights vt to client i. \u2022 Step 2: The selected client i performs a local model\ntraining task with local training samples and produces the new weights for the bypass model vt,i. After that, client i is split from the index set, S = S \u2212 i. \u2022 Step 3: The current global round terminates if S = \u2205 and\ngo to the next global round t = t+1. Otherwise, client i selects a new client i\u2032 \u2208 S as the next relay training node. When the local weights vt,i is transmitted from client i to client i\u2032, we assign i = i\u2032 and jump to Step 2. \u2022 Step 4: The above steps 1-3 are repeated T global rounds\nwhen t > T . Then the weights of the base model w and additional bypass vT are merged together to form the weights of the fine-tuned personalized model w\u2032, which is utilized to generate the customized content. Note that the inference cost of w\u2032 is identical to that of w.\nTo evaluate the performance of our proposed federated finetuning scheme, we collected 20 pieces of ancient Chinese ink paintings by different masters and cropped them to a resolution of 512\u00d7512 pixels. For simplicity, the total number of clients is 5 and each client has 4 training samples. For the hyperparameter setting, we use a number of low-rank dimensions of 8 and let the total number of global rounds T = 100. We compare the performance between our scheme and a traditional fine-tuning scheme, which trains all parameters of the U-Net in the stable diffusion model. To reduce the training cost, we apply the half-precision floating-point for the parameter representation. Specifically, the required data sizes for D2D parameter transmission of the proposed and traditional schemes are 9.1 and 1,720 megabytes, respectively.\nFigure 3(a) shows the training loss over the global round\nbetween these two schemes. We observe that the traditional scheme converges faster than the our scheme in the first 60 rounds and our scheme achieves comparable training loss to the traditional scheme after 100 global rounds. During the training, we periodically sample and record the output image of the generator every 20 rounds with the same prompt. The traditional scheme acquires the ability to generate Chinese inkstyle images after approximately 20 global rounds while our scheme requires about 40 rounds to attain the same proficiency.\nHowever, our scheme achieves a remarkable advantage in reducing the system cost in terms of the communication cost and time consumption for the model convergence, as shown in Fig. 3(b). To achieve an identical training loss of 0.02, the traditional and our schemes consume about 189 gigabytes and 1.3 gigabytes of data traffic, respectively. To achieve a training loss of 0.08, the traditional and our schemes take about 131 minutes and 2.9 minutes, respectively. Compared with the traditional scheme, our scheme can reduce both the communication costs and training latency by up to two orders of magnitude. Fig. 3(c) shows the image samples generated by different fine-tuned models on the client side. The results show that our scheme successfully enables a client to obtain the ability to generate Chinese ink-style paintings."
        },
        {
            "heading": "V. FUTURE RESEARCH DIRECTIONS",
            "text": "To achieve the benefits of FL-empowered AIGC, there still\nexist several open and challenging issues.\nA. Incentive Mechanism Design for Federated Learning\nIncentive mechanisms are necessitated to provide effective incentives for clients, which are willing to join the federatedlearning-empowered AIGC. Mathematical tools of economic\ntheory such as game theory, auction theory, and contract theory can be adopted. Furthermore, the incentive mechanism design should coordinate with other FL designs to achieve a centralized objective. For example, the incentive mechanism design for the clients and split point selection of an AIGC model are jointly optimized to enhance the FL in a split approach. Facing the FL in a sequential approach, the decision-maker considers a joint optimization scheme to design proper incentives to the clients while assigning their processing orders."
        },
        {
            "heading": "B. Blockchain Assisted Decentralized AIGC Services",
            "text": "As a decentralized ledger, blockchain has been envisioned as the underlying technology to provide data security and transparent management for FL-aided AIGC.\nOn one hand, blockchain supports decentralized and secure model storage for reliable FL by maintaining immutable records of all submitted local model updates and making them tamper-proof. Blockchain-based incentive mechanisms have been designed to stimulate honest clients to contribute data and join the FL procedure. On the other hand, blockchain provides a valuable solution to protection of sensitive data of users and effective management of AIGC products. Blockchain can prevent the leakage of the information such as chat records of ChatGPT. Blockchain also establishes a decentralized platform for the users to freely distribute, authentic the ownership, and trade their content in the totally trustless environment."
        },
        {
            "heading": "C. Green AIGC Enabled By Semantic Communication",
            "text": "AIGC has been applied to generate digital content to render graphics for Metaverse. A Metaverse service provider collects sensing data of a user and performs an AIGC inference based rendering task for the user. Semantic communication is further exploited to extract available semantic information from the raw data and only transmit the semantic information with a small data size, thereby saving the data transmission time and communication overheads in the system. In particular, FL can be leveraged to decentralize the semantic encoder/decoder model training while improving the accuracy of the semantic information extraction by using more training data."
        },
        {
            "heading": "D. Personalized AIGC Based on Edge Intelligence",
            "text": "Edge intelligence relies on exploiting the AI based decisionmaking capability for promoting the convergence of caching, computing and communication at the network edge and serves different users in the AIGC inference services.\nMany research efforts have been conducted to apply the edge intelligence to tackle the tradeoff between the model performance and resource consumption when multiple clients join the FL procedure. When a part of AIGC models are cached, the multi-user inference service delivery aims to improve the overall user satisfaction while reducing the inference latency and resource consumption. The existing optimization schemes for FL can be modified to take into account the personalized requirements for the quality of the AIGC inference services. However, it is rather difficult to quantitatively evaluate the impacts of the above optimization decisions on the performance\nmetrics of the AIGC inference services, e.g., quality of the generated content, latency and reliability of content delivery and model hit ratio."
        },
        {
            "heading": "VI. CONCLUSION",
            "text": "The centralized training in the AIGC processes raises a challenging issue for deploying AIGC services in wireless networks. To address this issue, we proposed FL to decentralize the model training procedures regarding AIGC, which can improve learning efficiency and achieve privacy protection for AIGC. We analyzed the issues remained on the integration of FL and AIGC, and then proposed instrumental FL-based techniques to implement the FL procedure including the parallel, split and sequential approaches. As a case study, we adopted FL in a sequential approach to perform the federated finetuning for a stable diffusion model. Numerical results verified the superiority of the proposed scheme. Finally, we outlined the open research issues of FL-empowered AIGC."
        }
    ],
    "title": "Federated Learning-Empowered AI-Generated Content in Wireless Networks",
    "year": 2023
}