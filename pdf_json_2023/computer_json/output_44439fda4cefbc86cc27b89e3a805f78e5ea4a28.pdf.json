{
    "abstractText": "Accurate detection and parameter estimation of frequency hopping (FH) signals remain challenging in FH signal-based transmission systems. This study proposes a scheme combining time-frequency analysis (TFA) and deep learning (DL)-based image processing algorithms to alleviate the degradation of detection accuracy and estimation performance caused by complex electromagnetic interference (EMI). A short-time Fourier transform (STFT) was used to obtain the signal spectrogram, which reflects the signal energy in a concentration-dependent manner. Then, a CenterNet-based deep network was employed to identify each FH hop\u2019s shape and position, reducing the computational burden via a lightweight neural network while maintaining high recognition accuracy. Inverse mapping from the coordinates to the spectrogram was used to perform parameter estimation in the time-frequency (TF) domain. The estimation error was reduced by precisely locating the centroid of the signal energy using CenterNet. The simulation results demonstrate that the proposed scheme can accurately estimate the FH signal at a low signal-to-noise ratio (SNR) with complex EMI. Furthermore, appropriately determining the optimal parameters of CenterNet to ensure the estimator performance provides a novel approach for integrating DL into signal detection and estimation in complex EMI environments. INDEX TERMS FH signal, TFA, CenterNet, complex EMI, image detection.",
    "authors": [
        {
            "affiliations": [],
            "name": "ZIYI CHEN"
        },
        {
            "affiliations": [],
            "name": "YAOWU SHI"
        },
        {
            "affiliations": [],
            "name": "YINGWEI WANG"
        },
        {
            "affiliations": [],
            "name": "XINBO LI"
        }
    ],
    "id": "SP:8705396a20ce8cf5999fea056b689724f3f5f596",
    "references": [
        {
            "authors": [
                "A. Ephremides",
                "J.E. Wieselthier",
                "D.J. Baker"
            ],
            "title": "A design concept for reliable mobile radio networks with frequency hopping signaling",
            "venue": "Proc. IEEE, vol. 75, no. 1, pp. 56\u201373, Jan. 1987, doi: 10.1109/PROC.1987.13705.",
            "year": 1987
        },
        {
            "authors": [
                "Q. Chen",
                "E.S. Sousa",
                "S. Pasupathy"
            ],
            "title": "Multicarrier CDMA with adaptive frequency hopping for mobile radio systems",
            "venue": "IEEE J. Sel. Areas Commun., vol. 14, no. 9, pp. 1852\u20131858, Dec. 1996, doi: 10.1109/49.545707.",
            "year": 1852
        },
        {
            "authors": [
                "S. Barbarossa",
                "A. Scaglione"
            ],
            "title": "Parameter estimation of spread spectrum frequency-hopping signals using time-frequency distributions",
            "venue": "Proc. 1st IEEE Signal Process. Workshop Signal Process. Adv. Wireless Commun., Apr. 1997, pp. 213\u2013216, doi: 10.1109/SPAWC.1997.630288.",
            "year": 1997
        },
        {
            "authors": [
                "D.J. Torrieri"
            ],
            "title": "Mobile frequency-hopping CDMA systems",
            "venue": "IEEE Trans. Commun., vol. 48, no. 8, pp. 1318\u20131327, Aug. 2000, doi: 10.1109/26.864169.",
            "year": 2000
        },
        {
            "authors": [
                "S. Srinivasa",
                "S. Jafar"
            ],
            "title": "Cognitive radios for dynamic spectrum access\u2014The throughput potential of cognitive radio: A theoretical perspective",
            "venue": "IEEE Commun. Mag., vol. 45, no. 5, pp. 73\u201379, May 2007, doi: 10.1109/MCOM.2007.358852. 46012 VOLUME 11, 2023 Z. Chen et al.: Unlocking Signal Processing With Image Detection",
            "year": 2007
        },
        {
            "authors": [
                "Y. Yuan",
                "Z. Huang",
                "X. Wang"
            ],
            "title": "Detection of frequency-hopping radio frequency-switch transients",
            "venue": "Electron. Lett., vol. 50, no. 13, pp. 956\u2013957, Jun. 2014.",
            "year": 2014
        },
        {
            "authors": [
                "Y.-A. Jung",
                "D. Shin",
                "Y.-H. You"
            ],
            "title": "Efficient estimation algorithm of carrier frequency offset for LTE machine-type communication using frequency hopping",
            "venue": "IEEE Access, vol. 7, pp. 177274\u2013177283, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J. Ma",
                "Y. Yang",
                "H. Li",
                "J. Li"
            ],
            "title": "FH-BOC: Generalized low-ambiguity anti-interference spread spectrummodulation based on frequency-hopping binary offset carrier",
            "venue": "GPS Solutions, vol. 24, no. 3, p. 70, Jul. 2020, doi: 10.1007/s10291-020-00982-3.",
            "year": 2020
        },
        {
            "authors": [
                "C. Li",
                "P. Qi",
                "D. Wang",
                "Z. Li"
            ],
            "title": "On the anti-interference tolerance of cognitive frequency hopping communication systems",
            "venue": "IEEE Trans. Rel., vol. 69, no. 4, pp. 1453\u20131464, Dec. 2020, doi: 10.1109/TR.2020.3002105.",
            "year": 2020
        },
        {
            "authors": [
                "J. Ye",
                "J. Zou",
                "J. Gao",
                "G. Zhang",
                "M. Kong",
                "Z. Pei",
                "K. Cui"
            ],
            "title": "A new frequency hopping signal detection of civil UAV based on improved Kmeans clustering algorithm",
            "venue": "IEEE Access, vol. 9, pp. 53190\u201353204, 2021, doi: 10.1109/ACCESS.2021.3070491.",
            "year": 2021
        },
        {
            "authors": [
                "K. Wu",
                "J. Andrew Zhang",
                "X. Huang",
                "Y. Jay Guo",
                "R.W. Heath Jr."
            ],
            "title": "Waveform design and accurate channel estimation for frequency-hopping MIMO radar-based communications",
            "venue": "IEEE Trans. Commun., vol. 69, no. 2, pp. 1244\u20131258, Oct. 2020, doi: 10.1109/TCOMM.2020.3034357.",
            "year": 2020
        },
        {
            "authors": [
                "H. Chougrani",
                "S. Kisseleff",
                "S. Chatzinotas"
            ],
            "title": "Efficient preamble detection and time-of-arrival estimation for single-tone frequency hopping random access in NB-IoT",
            "venue": "IEEE Internet Things J., vol. 8, no. 9, pp. 7437\u20137449, May 2021, doi: 10.1109/JIOT.2020.3039004.",
            "year": 2021
        },
        {
            "authors": [
                "F. Liu",
                "M.W. Marcellin",
                "N.A. Goodman",
                "A. Bilgin"
            ],
            "title": "Compressive sampling for detection of frequency-hopping spread spectrum signals",
            "venue": "IEEE Commun. Lett., vol. 64, no. 21, pp. 5513\u20135524, Nov. 2016, doi: 10.1109/TSP.2016.2597122.",
            "year": 2016
        },
        {
            "authors": [
                "S. Liu",
                "Y.D. Zhang",
                "T. Shan",
                "R. Tao"
            ],
            "title": "Structure-aware Bayesian compressive sensing for frequency-hopping spectrum estimation with missing observations",
            "venue": "IEEE Trans. Signal Process., vol. 66, no. 8, pp. 2153\u20132166, Apr. 2018, doi: 10.1109/TSP.2018.2806351.",
            "year": 2018
        },
        {
            "authors": [
                "S. Ghanem"
            ],
            "title": "Decoding and measurement of frequency-hopping spread spectrum signals using an adaptive algorithm-based compressive sensing",
            "venue": "Int. J. Commun. Syst., vol. 34, no. 3, p. e4675, Feb. 2021, doi: 10.1002/dac.4675.",
            "year": 2021
        },
        {
            "authors": [
                "B.F. Lo",
                "S. Torborg",
                "C.K.A. Yeung"
            ],
            "title": "HopSAC: Frequency hopping parameter estimation based on random sample consensus for counter-unmanned aircraft systems",
            "venue": "Proc. IEEE Mil. Commun. Conf. (MILCOM), Nov. 2019, pp. 355\u2013360, doi: 10.1109/MIL- COM47813.2019.9020841.",
            "year": 2019
        },
        {
            "authors": [
                "J.L. Loof",
                "T.G. Pratt"
            ],
            "title": "Frequency-hopped signal source identification in frequency-selective channels",
            "venue": "IEEE Trans. Aerosp. Electron. Syst., vol. 55, no. 6, pp. 3316\u20133329, Dec. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "A. Kanaa",
                "A.Z. Sha\u2019Ameri"
            ],
            "title": "A robust parameter estimation of FHSS signals using time\u2013frequency analysis in a non-cooperative environment",
            "venue": "Phys. Commun., vol. 26, pp. 9\u201320, Feb. 2018, doi: 10.1016/j.phycom.2017.10.013.",
            "year": 2018
        },
        {
            "authors": [
                "L. Zhi",
                "Z. Jianhua",
                "C. Hao",
                "G. Xu",
                "L. Jian"
            ],
            "title": "Parameter estimation of frequency hopping signals based on analogue information converter",
            "venue": "IET Commun., vol. 13, no. 13, pp. 1886\u20131892, Aug. 2019, doi: 10.1049/ietcom.2019.0057.",
            "year": 1886
        },
        {
            "authors": [
                "J. Wan",
                "D. Zhang",
                "W. Xu",
                "Q. Guo"
            ],
            "title": "Parameter estimation of multi frequency hopping signals based on space-time-frequency distribution",
            "venue": "Symmetry, vol. 11, no. 5, p. 648, May 2019. [Online]. Available: https://www.mdpi.com/2073-8994/11/5/648",
            "year": 2019
        },
        {
            "authors": [
                "J. Wu",
                "F. Guo"
            ],
            "title": "Time-frequency parameter estimation method of frequency hopping signal based on morphology method under low SNR",
            "venue": "Proc. IEEE 6th Int. Conf. Signal Image Process. (ICSIP), Oct. 2021, pp. 734\u2013738, doi: 10.1109/ICSIP52628.2021.9688633.",
            "year": 2021
        },
        {
            "authors": [
                "H. Wang",
                "B. Zhang",
                "H. Wang",
                "B. Wu",
                "D. Guo"
            ],
            "title": "Hopping time estimation of frequency-hopping signals based on HMM-enhanced Bayesian compressive sensing with missing observations",
            "venue": "IEEE Commun. Lett., vol. 26, no. 9, pp. 2180\u20132184, Sep. 2022, doi: 10.1109/LCOMM.2022.3184173.",
            "year": 2022
        },
        {
            "authors": [
                "Z. Jiang",
                "S. Wang",
                "Y. Chen",
                "P. Wang",
                "L. Gao"
            ],
            "title": "Frequency hopping signal parameter estimation algorithm based on time-frequency point correlation",
            "venue": "Proc. IEEE 10th Joint Int. Inf. Technol. Artif. Intell. Conf. (ITAIC), Jun. 2022, pp. 740\u2013744, doi: 10.1109/ITAIC54216.2022.9836485.",
            "year": 2022
        },
        {
            "authors": [
                "B. Hinman",
                "J. Bernstein",
                "D. Staelin"
            ],
            "title": "Short-space Fourier transform image processing",
            "venue": "Proc. IEEE Int. Conf. Acoust., Speech, Signal Process., Mar. 1984, pp. 166\u2013169, doi: 10.1109/ICASSP.1984.1172374.",
            "year": 1984
        },
        {
            "authors": [
                "L. Tong",
                "T. Yinhui",
                "L. Jun"
            ],
            "title": "Parameter estimation of FH signals based on STFT and music algorithm",
            "venue": "Proc. Int. Conf. Comput. Appl. Syst. Model. (ICCASM), Oct. 2010, pp. 22\u201324, doi: 10.1109/ICCASM.2010.5619186.",
            "year": 2010
        },
        {
            "authors": [
                "T. Feng",
                "C.W. Yuan"
            ],
            "title": "Blind parameter estimation of frequencyhopping signals based on the time-frequency distribution maxima",
            "venue": "Acta Electronica Sinica, vol. 39, no. 12, pp. 2921\u20132925, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "W. Fu",
                "X. Li",
                "N. Liu",
                "Y. Hei",
                "J. Wei"
            ],
            "title": "Parameter blind estimation of frequency-hopping signal based on time\u2013frequency diagram modification",
            "venue": "Wireless Pers. Commun., vol. 97, no. 3, pp. 3979\u20133992, Dec. 2017, doi: 10.1007/s11277-017-4710-5.",
            "year": 2017
        },
        {
            "authors": [
                "B. Kaplan",
                "I. Kahraman",
                "A. Gorcin",
                "H.A. Cirpan",
                "A.R. Ekti"
            ],
            "title": "Measurement based FHSS\u2013type drone controller detection at 2.4 GHz: An STFT approach",
            "venue": "inProc. IEEE 91st Veh. Technol. Conf. (VTC-Spring), May 2020, pp. 1\u20136, doi: 10.1109/VTC2020-Spring48590.2020.9129525.",
            "year": 2020
        },
        {
            "authors": [
                "S. Kumawat",
                "M. Verma",
                "Y. Nakashima",
                "S. Raman"
            ],
            "title": "Depthwise spatio-temporal STFT convolutional neural networks for human action recognition",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 44, no. 9, pp. 4839\u20134851, Apr. 2022, doi: 10.1109/TPAMI.2021.3076522.",
            "year": 2022
        },
        {
            "authors": [
                "T. Feng",
                "C.W.Yuan"
            ],
            "title": "Combination ofWigner\u2013Ville distribution and its application to blind parameter estimation of frequency-hopping signals",
            "venue": "J. Xidian Univ., vol. 37, no. 6, pp. 1137\u20131142, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "T.-C. Chen"
            ],
            "title": "Joint signal parameter estimation of frequency-hopping communications",
            "venue": "IET Commun., vol. 6, no. 4, pp. 381\u2013389, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "Z. Leyuan",
                "L. Chuanhui",
                "L. Bihui",
                "L. Faping",
                "K. Jiafang"
            ],
            "title": "Research on time-frequency energy distribution characteristics of PSWFs signals based on WVD",
            "venue": "Proc. 4th Int. Conf. Inf. Commun. Signal Process. (ICICSP), Sep. 2021, pp. 134\u2013138, doi: 10.1109/ICICSP54369.2021.9611851.",
            "year": 2021
        },
        {
            "authors": [
                "Z. Li",
                "X. Zhang",
                "Q. Yang",
                "Y. Xiao",
                "H. An",
                "H. Yang",
                "J. Wu",
                "J. Yang"
            ],
            "title": "Hybrid SAR-ISAR image formation via joint FrFT-WVD processing for BFSAR ship target high-resolution imaging",
            "venue": "IEEE Trans. Geosci. Remote Sens., vol. 60, 2022, Art. no. 5215713, doi: 10.1109/TGRS.2021.3117280.",
            "year": 2022
        },
        {
            "authors": [
                "P. Flandrin"
            ],
            "title": "Some features of time-frequency representations of multicomponent signals",
            "venue": "Proc. IEEE Int. Conf. Acoust., Speech, Signal Process., Mar. 1984, pp. 266\u2013269, doi: 10.1109/ICASSP.1984.1172741.",
            "year": 1984
        },
        {
            "authors": [
                "Z. Wang",
                "Y. Li",
                "W. Xu"
            ],
            "title": "A blind parameter estimation method of frequency hopping signal with low SNR",
            "venue": "Int. J. Circuits, Syst. Signal Process., vol. 15, pp. 248\u2013253, Apr. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S.K. Khare",
                "V. Bajaj",
                "U.R. Acharya"
            ],
            "title": "SPWVD-CNN for automated detection of schizophrenia patients using EEG signals",
            "venue": "IEEE Trans. Instrum. Meas., vol. 70, pp. 1\u20139, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Kamble",
                "P.H. Ghare",
                "V. Kumar"
            ],
            "title": "Deep-learning-based BCI for automatic imagined speech recognition using SPWVD",
            "venue": "IEEE Trans. Instrum. Meas., vol. 72, pp. 1\u201310, 2023, doi: 10.1109/TIM.2022.3216673.",
            "year": 2023
        },
        {
            "authors": [
                "R. Girshick",
                "J. Donahue",
                "T. Darrell",
                "J. Malik"
            ],
            "title": "Rich feature hierarchies for accurate object detection and semantic segmentation",
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2014, pp. 580\u2013587, doi: 10.1109/CVPR.2014.81.",
            "year": 2014
        },
        {
            "authors": [
                "R. Girshick"
            ],
            "title": "Fast R-CNN",
            "venue": "Proc. IEEE Int. Conf. Comput. Vis. (ICCV), Dec. 2015, pp. 1440\u20131448.",
            "year": 2015
        },
        {
            "authors": [
                "J. Redmon",
                "S. Divvala",
                "R. Girshick",
                "A. Farhadi"
            ],
            "title": "You only look once: Unified, real-time object detection",
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 779\u2013788, doi: 10.1109/CVPR.2016.91.",
            "year": 2016
        },
        {
            "authors": [
                "S. Ren",
                "K. He",
                "R. Girshick",
                "J. Sun"
            ],
            "title": "Faster R-CNN: Towards realtime object detection with region proposal networks",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 39, no. 6, pp. 1137\u20131149, Jun. 2017, doi: 10.1109/TPAMI.2016.2577031.",
            "year": 2017
        },
        {
            "authors": [
                "K. He",
                "G. Gkioxari",
                "P. Dollar",
                "R. Girshick"
            ],
            "title": "Mask R-CNN",
            "venue": "Proc. IEEE Int. Conf. Comput. Vis. (ICCV), Oct. 2017, pp. 2980\u20132988, doi: 10.1109/ICCV.2017.322.",
            "year": 2017
        },
        {
            "authors": [
                "J. Redmon",
                "A. Farhadi"
            ],
            "title": "YOLOv3: An incremental improvement",
            "venue": "2018, arXiv:1804.02767.",
            "year": 2018
        },
        {
            "authors": [
                "Z. Tian",
                "C. Shen",
                "H. Chen",
                "T. He"
            ],
            "title": "FCOS: Fully convolutional onestage object detection",
            "venue": "inProc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), Oct. 2019, pp. 9626\u20139635, doi: 10.1109/ICCV.2019.00972.",
            "year": 2019
        },
        {
            "authors": [
                "I. Oksuz",
                "J.R. Clough",
                "B. Ruijsink",
                "E.P. Anton",
                "A. Bustin",
                "G. Cruz",
                "C. Prieto",
                "A.P. King",
                "J.A. Schnabel"
            ],
            "title": "Deep learning-based detection and correction of cardiac MR motion artefacts during reconstruction for high-quality segmentation",
            "venue": "IEEE Trans. Med. Imag., vol. 39, no. 12, pp. 4001\u20134010, Dec. 2020, doi: 10.1109/TMI.2020.3008930.",
            "year": 2020
        },
        {
            "authors": [
                "Z. Ge",
                "S. Liu",
                "F. Wang",
                "Z. Li",
                "J. Sun"
            ],
            "title": "YOLOX: Exceeding YOLO series in 2021",
            "venue": "2021, arXiv:2107.08430. VOLUME 11, 2023 46013 Z. Chen et al.: Unlocking Signal Processing With Image Detection",
            "year": 2021
        },
        {
            "authors": [
                "C.-Y. Wang",
                "A. Bochkovskiy",
                "H.-Y. Mark Liao"
            ],
            "title": "YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors",
            "venue": "2022, arXiv:2207.02696.",
            "year": 2022
        },
        {
            "authors": [
                "X. Zhou",
                "D. Wang",
                "P. Kr\u00e4henb\u00fchl"
            ],
            "title": "Objects as points",
            "venue": "arXiv:1904.07850, 2019.",
            "year": 1904
        },
        {
            "authors": [
                "Y. Sun",
                "Z. Li",
                "L. Wang",
                "J. Zuo",
                "L. Xu",
                "M. Li"
            ],
            "title": "Automatic detection of vehicle targets based on CenterNet model",
            "venue": "Proc. IEEE Int. Conf. Consum. Electron. Comput. Eng. (ICCECE), Jan. 2021, pp. 375\u2013378.",
            "year": 2021
        },
        {
            "authors": [
                "Z. Dai",
                "J. Yi",
                "L. Jiang",
                "S. Yang",
                "X. Huang"
            ],
            "title": "Cascade CenterNet: Robust object detection for power line surveillance",
            "venue": "IEEE Access, vol. 9, pp. 60244\u201360257, 2021, doi: 10.1109/ACCESS.2021.3072901.",
            "year": 2021
        },
        {
            "authors": [
                "H. Zheng",
                "Y. Cui",
                "W. Yang",
                "J. Li",
                "L. Ji",
                "Y. Ping",
                "S. Hu",
                "X. Chen"
            ],
            "title": "An infrared image detection method of substation equipment combining iresgroup structure and CenterNet",
            "venue": "IEEE Trans. Power Del., vol. 37, no. 6, pp. 4757\u20134765, Dec. 2022, doi: 10.1109/TPWRD.2022.3158818.",
            "year": 2022
        },
        {
            "authors": [
                "Y.-J. Zhang",
                "R.-Y. Liu",
                "H.-J. Song"
            ],
            "title": "A method of the detection of frequency-hopping signal based on channelized receiver in the complicated electromagnetic environment",
            "venue": "Proc. Int. Conf. Intell. Inf. Hiding Multimedia Signal Process. (IIH-MSP), Sep. 2015, pp. 294\u2013297, doi: 10.1109/IIH-MSP.2015.65.",
            "year": 2015
        },
        {
            "authors": [
                "K. He",
                "X. Zhang",
                "S. Ren",
                "J. Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 770\u2013778, doi: 10.1109/CVPR.2016.90.",
            "year": 2016
        },
        {
            "authors": [
                "B. Xiao",
                "H. Wu",
                "Y. Wei"
            ],
            "title": "Simple baselines for human pose estimation and tracking",
            "venue": "2018, arXiv:1804.06208.",
            "year": 2018
        },
        {
            "authors": [
                "H. Law",
                "J. Deng"
            ],
            "title": "CornerNet: Detecting objects as paired keypoints",
            "venue": "Proc. Eur. Conf. Comput. Vis., 2018, pp. 734\u2013750.",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "INDEX TERMS FH signal, TFA, CenterNet, complex EMI, image detection.\nI. INTRODUCTION Frequency hopping (FH) signals have been increasingly utilized in civilian and military communications. Since their invention, the robust anti-interference capability, low interception probability, and excellent anti-fading effect have made it possible to diversify the human use of electromagnetic waves [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12]. For instance, Code Division Multiple Accessbased 3G cellular communications significantly enhance the channel capacity; however, the multipath effect may distort the frequency identification of FH carriers, leading to an elevated Bit Error Rate. While military FH communications\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Wen Chen .\nrequire less channel capacity and spectrum utilization, the adversary\u2019s intense Electromagnetic Interference (EMI) usually focuses on covering the hopping bands, resulting in false detection or even communication disruption at the receiver. Thus, the precise detection and estimation of the received FH signals are essential for effective information transmission. To address this issue, an adaptive kernel was utilized in [13] to maximize the mutual information between the input signal and the measurement, thus improving the detection performance after compressive sampling of the full FH spectrum. In [14], a spectrum estimation algorithm for FH signals underlying compressive sensing was introduced, which reconstructed FH signals with missing observations by exploiting the inherent structure of the signal. A compressionaware measurement was presented in [15] to decode FH\n46004 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 11, 2023\nsignals without prior knowledge and pseudo-random code, and an adaptive kernel was designed for compression and decoding. After the immediate exclusion of gross errors, [16] proposed a low-complexity multiple-target detection method for FH signals, based on a small set of random samples. In [17], FH signals were assumed to be blindly separated by exploiting the polarized frequency correlation, and the estimation accuracy was improved by descrambling reconstruction.\nThe solutions above consider only the case of FH signals under the assumption that no other EMI exists. However, in realistic environments, there are interferences from the nature, numerous electronic devices around the link, and deliberately released disturbances. Furthermore, the FH signal is time-varying, making it difficult to describe its changing patterns visually and to identify FH signals from interferences using traditional time-domain or frequencydomain analysis, especially in complex EMI environment. Fortunately, approaches based on time-frequency analysis (TFA) enable the visualization of signal characteristics in the time-frequency (TF) domain, providing an effective solution for this problem [18], [19], [20], [21], [22], [23].\nAmong the various TFA methods, the widely used ones include the short-time Fourier transform (STFT) [24], [25], [26], [27], [28], [29], the Wigner-Ville distribution (WVD) [30], [31], [32], [33], and its modified solution, known as the smooth pseudo Wigner-Ville distribution (SPWVD) [3], [34], [35], [36], [37]. However, although the WVD has the highest resolution, its sizeable cross-term interference requires numerous computationally intensive matrix operations. On the other hand, the SPWVD can handle cross-term interference but has limited noise tolerance. In contrast, the STFT is a computationally simple process that does not correlate the signal and prevents cross-term interference. Additionally, because STFT is a windowed transform, apparent edges in the spectrogram with high resolution can be achieved with a smaller window, thus making it easier to analyze the signal features using image processing algorithms. However, in complex EMI environments, interfering signals often contaminate the TF representation (TFR) of the STFT, causing a noticeable drop in detection accuracy. Consequently, accurately identifying FH signals from generated images has become a pressing concern.\nWith the advent of deep learning (DL) and rapid development of hardware capabilities, image-processing algorithms based onDL have emerged. Various networks focusing on target detection have been proposed in the literature [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], using convolutional kernels to extract image features and improve recognition accuracy by increasing the network depth and innovating structural design. However, these algorithms require abundant network parameters, resulting in a high computational burden. Moreover, these algorithms focus on the entire image and pay insufficient attention to the energy concentration of FH signals in spectrograms. In contrast, CenterNet [48], [49], [50], [51] is a lightweight network with a target centroid as\nthe primary measurement criterion for recognition, ensuring a high recognition accuracy and speed.\nBased on the above analysis, this study proposes an FH signal estimation scenario using STFT and CenterNet, which can accurately estimate FH signals after detecting them in complex EMI. The scenario first transforms the signal into a spectrogram using STFT to show energy aggregation, and then uses CenterNet to detect the FH signals from other interferences by labeling the aggregation area of each hop in the spectrogram. Finally, mapping the pixel coordinates to the TF grid provides an accurate parameter estimation of the FH hops. The contributions of this study are as follows:\n1) Making a more intuitive distinction, the scenario converts statistical features of both signals and interferences into image features; 2) By introducing DL-based image detection methods into signal processing, the fast iterative properties of DL algorithms can rapidly improve the accuracy and anti-interference capability of signal estimation; 3) This scenario enriches the toolbox of signal detection and parameter estimation by taking advantage of specific parameters from image detection, such as intersection over union (IoU) analysis; 4) CenterNet boosts the computing speed by leveraging parallel computing for machine learning.\nThe remainder of this paper is organized as follows: Section II establishes an FH signal model with complex EMI. Section III describes TFA for the FH signal, target detection, and parameter estimation. Section IV presents the simulation setup and results evaluation, and Section V provides concluding remarks.\nII. SIGNALS AND ENVIRONMENT MODELING This section analyses the EMI environment and creates a signal model in the TF domain.\nA. COMPLEX EMI ENVIRONMENT Interfering signals and noise always coexist with FH signals in an EMI environment. These interferences typically consist of three categories: fixed-frequency, linear-frequency modulation (LFM), and burst signals. Fixed-frequency signals such as voice broadcasts and TV signals typically have a permanent frequency and usually last for seconds. LFM signals, also known as chirp signals, are signals whose frequency varies linearly with time andwhose appearance is typically periodic, such as radar signals. In contrast, burst signals are random and irregular with fixed frequencies and short durations. These interferences and background noise constitute themain obstacles to identifying FH signals [52].\nB. MODELING Assume that there is a mixed-signal r(t) consisting of M FH signals cm(t),H chirp signals fh(t), L fixed-frequency signals gl(t), Q burst signals jq(t), and v(t) at the receiver during the\nVOLUME 11, 2023 46005\nobservation time T0, denoted as\nr(t) = M\u2211 m=1 cm(t) + H\u2211 h=1 fh(t) + L\u2211 l=1 gl(t) + Q\u2211 q=1 jq(t) + v(t)\n(1)\nwhere v(t) represents the additional Gaussian white noise (AWGN) with zero mean and variance of \u03c3 2.\nGiven that the mth FH signal has a hopping period of Tm, there are B hops in the observation time T0. The carrier frequency corresponding to the bth hop is denoted as fmb . Because the start time of the first hop cannot be determined and the hop may not be complete, the duration is generally considered to be \u03b1Tm with 0 < \u03b1 < 1. Then, cm(t) can be expressed as\ncm(t) = am B\u2211 b=1 ej(2\u03c0 fmb t \u2032 +\u03c6mb )rect( t \u2032 Tm ) (2)\nwhere t \u2032 = t \u2212 (b \u2212 1)Tm \u2212 \u03b1Tm. am is the amplitude of cm(t) and \u03c6mb is the initial phase of the bth hop with b \u2208 {1, 2, \u00b7 \u00b7 \u00b7 ,B}. rect(\u2022) is a unit of rectangular pulse function. From (1), it can be seen that there are no correlations between the FH signals and others; thus, signals other than FH can be unified as additive interference n(t) to be represented as\nn(t) = H\u2211 h=1 fh(t) + L\u2211 l=1 gl(t) + Q\u2211 q=1 jq(t) + v(t). (3)\nFrom (1) and (3), we have\nr(t) = M\u2211 m=1 cm(t) + n(t). (4)\nIII. METHOD This section provides an overview of FH signal detection, covering spectrogram generation, deep network image detection, and parameter estimation using the detection outputs.\nA. SCHEME OVERVIEW The structure of the proposed scheme is illustrated in Fig. 1. The time-domain input signal is converted into a spectrogram via the STFT. The spectrogram is then fed into the CenterNet as an image for detection, yielding the center point position and bounding box (Bbox) of the FH signal. Finally, the frequencies and hopping period of the FH signal are estimated through inverse mapping based on the coordinates from the image.\nB. STFT-BASED SPECTROGRAM GENERATION STFT is a Fourier transform with added windowing, where a time-domain signal is processed separately by a sliding window and then switched into the TF domain as stacked\nspectra. The STFT of the signal r(t) is defined as\nR(t, f ) = STFT(r(t))\n=\n\u222b \u221e\n\u2212\u221e\nr(t)h(\u03c4 \u2212 t)e\u2212j2\u03c0 f \u03c4d\u03c4 (5)\nwhere h(t) denotes a window function. Performing the STFT on both ends of (4) simultaneously yields\nR(t, f ) = \u222b \u221e\n\u2212\u221e ( M\u2211 m=1 cm(t) + n(t))h(\u03c4 \u2212 t)e\u2212j2\u03c0 f \u03c4d\u03c4\n=\n\u222b \u221e\n\u2212\u221e M\u2211 m=1 cm(t)h(\u03c4 \u2212 t)e\u2212j2\u03c0 f \u03c4d\u03c4\n+\n\u222b \u221e\n\u2212\u221e\nn(t)h(\u03c4 \u2212 t)e\u2212j2\u03c0 f \u03c4d\u03c4\n= STFT( M\u2211 m=1 cm(t)) + STFT(n(t))\n= Cm(t, f ) + N (t, f ). (6)\nTo facilitate 2-D image processing, we denote the TF values using the following notation:\n|R(t, f )| = |Cm(t, f )| + |N (t, f )| . (7)\nThis representation makes it easier to detect the FH signal in a spectrogram, which is the process of detecting |Cm(t, f )| from |R(t, f )|. After converting the time-domain signal into a spectrogram using the STFT, different signals can be easily distinguished from various interferences. As shown in Fig. 2, the FH signal appears as a short horizontal line of consistent length in the spectrogram, whereas the fixed-frequency signal appears as a long horizontal line. The chirp signal appears as diagonal segments with the same slope, frequency band, and period, whereas the burst signal appears as a short horizontal line of random length. The random noise signal covers the entire spectrogram as irregular dots, and the lower the signal-tonoise ratio (SNR), the higher the energy and brightness of the dots in the spectrogram. According to the above analysis, detecting FH signals in a spectrogram is transformed into an image detection problem. The objective is to detect regular short horizontal lines from other shapes in the image. Current transmitters usually select a relatively clean band to avoid overlapping interference. Therefore, we assume that the FH signal does not overlap with the interfering signals in the spectrogram, which allows for the accurate detection and parameter estimation of the FH signal using the proposed scheme.\nC. NETWORK ARCHITECTURE The architecture of the CenterNet used in this study is illustrated in Fig. 3, which comprises two main components: a convolution-based backbone network and an upsampling network. The backbone network extracts features from the image, and the upsampling network merges these features\n46006 VOLUME 11, 2023\ninto feature maps. The feature maps are then fed into three different convolutional heads to produce the detection results of the FH signal. These three heads are responsible for the following:\n1) Extracting the heat map of the features for classification; 2) Determining the height and width of the target Bbox; 3) Recording the offset between the center point and the\ntarget\u2019s actual position.\nOne advantage of CenterNet over traditional CNN-based networks (such as R-CNN and Faster R-CNN) is its insensitivity to the initial size and stretching of the image. Instead of traversing the image using numerous alternate anchors, CenterNet focuses solely on the center point position and anchor size, making the network design straightforward. In this study, the input image was preprocessed from 900 \u00d7 1200 to 512 \u00d7 512 pixels in the RGB format, which contains three channels.\nThe backbone network is typically selected from ResNet, DLA, and Hourglass [48]. In this study, we selected ResNet-50 as the backbone network, which improves processing speed while ensuring learning accuracy and avoids gradient disappearance and explosion caused by network deepening [53]. After feature extraction using the backbone network, the dimensions of the feature maps were 16 \u00d7 16 with 2048 channels. Subsequently, deconvolution of the feature maps was used as an upsampling tool to obtain heat maps, acquiring feature maps at a dimension of 128 \u00d7 128 pixels with 64 channels [42], [54].\nThe obtained featuremaps are duplicated into three parallel heads to output parameters. First, the convolution depth is equal to the number of desired classifications. As the FH signal is the unique class in this study, the convolution depth of the head was 1. Second, because the Bbox is determined\nby the width and height, the convolution depth was 2. Finally, to compensate for the offset during feature extraction, a finetuning of the centroid position is performed with a convolution depth of 2. The specific architecture of the detection network is presented in Table 1."
        },
        {
            "heading": "D. TRAINING AND PREDICTION OF THE SPECTROGRAMS",
            "text": ""
        },
        {
            "heading": "1) POSITION PREDICTION OF THE FH SIGNAL",
            "text": "The keypoint prediction of the FH signal was referenced from [55]. Given a particular FH signal c in the input image I \u2208 \u211cW\u00d7H\u00d73 with width W and height H , the keypoint of the ground truth is Y \u2208 [0, 1] W S \u00d7 H S \u00d7C with the position of p \u2208 \u211c2, which is scaled by the same ratio as the position of p\u0303 = \u230a p S \u230b and is dispersed by the Gaussian kernel in (8) on the heat map. The output scaling stride S was set to 4 according to the network structure, and the number of classes C was set to 1 in this study. The variance \u03c3 2p of the heat map is calculated from the radius r , which is determined using IoU settings.\nYxyc = e \u2212\n(x\u2212p\u0303x )2+(y\u2212p\u0303y)2\n2\u03c32p (8)\nLet the corresponding keypoint Y\u0302 \u2208 [0, 1] W S \u00d7 H S \u00d7C be given by the network prediction, whose position is p\u0302 \u2208 \u211c2. We use Y\u0302xyc = 1 to denote that the keypoint is acquired, whereas Y\u0302xyc = 0 denotes the background. Moreover, we use the focal loss for logistic regression, and the loss function can be expressed as\nLpt = \u2212 1 M \u2211 xyc  (1 \u2212 Y\u0302xyc) \u03b1 log(Y\u0302xyc), Yxyc = 1 (1 \u2212 Yxyc)\u03b2 (Y\u0302xyc)\u03b1\nlog(1 \u2212 Y\u0302xyc), otherwise\n(9)\nwhere \u03b1 and \u03b2 are the hyperparameters of focal loss. In this study, we take \u03b1 = 2 and \u03b2 = 4, respectively. M is the number of keypoints in an image when normalizing the focal loss.\nIn addition, for the head used for offset prediction, let O\u0302 \u2208 \u211c W S \u00d7 H S \u00d72 be the offset prediction shared by all classes with offset coordinates (\u03b4x\u0302, \u03b4y\u0302). When using L1 loss to participate in the training, we have\nLoff = 1 M \u2211 p \u2223\u2223\u2223O\u0302p\u0303 \u2212 ( pS \u2212 p\u0303) \u2223\u2223\u2223. (10)"
        },
        {
            "heading": "2) SIZE PREDICTION OF THE FH SIGNAL",
            "text": "For the mth FH hop cm with Bbox coordinates (x(m)1 , y (m) 1 , x (m) 2 , y (m) 2 ), the center point position pm and the\nVOLUME 11, 2023 46007\nsize of the Bbox sm(w(m), h(m)) are\npm =\n( x(m)1 + x (m) 2\n2 , y(m)1 + y (m) 2 2\n) (11)\nand\nsm = ( x(m)2 \u2212 x (m) 1 , y (m) 2 \u2212 y (m) 1 ) , (12)\nrespectively. Let the size prediction be S\u0302 \u2208 \u211c W R \u00d7 H R \u00d72, and use L1 loss again to participate in the training. Then we have\nLsize = 1 M M\u2211 m=1 \u2223\u2223\u2223S\u0302pm \u2212 sm\u2223\u2223\u2223. (13) Overall, the loss for the entire training can be expressed as\nLtrain = Lpt + \u03bbsizeLsize + Loff (14)\nwhere the coordinates use the pixel positions in the original image. The weights assigned to each part of the loss were\ndefined by \u03bbsize = 0.1. Finally, the Bbox predicted by the network can be expressed as\n(x\u0302 + \u03b4x\u0302 \u2212 w\u0302 2 , y\u0302+ \u03b4y\u0302\u2212 h\u0302 2 , x\u0302 + \u03b4x\u0302 + w\u0302 2 , y\u0302+ \u03b4y\u0302+ h\u0302 2 ). (15)\nwhere w\u0302 and h\u0302 denote the width and height of the Bbox, respectively.\nE. PARAMETER ESTIMATION OF THE FH SIGNAL The FH signal cm is obtained from network prediction, and the frequency limit of its image representation is displayed between the upper limitFmax and the lower limitFmin, respectively. The inverse mapping from the image to the signal is calculated as\nTm w\u0302 = T0 W\n(16)\nand Fmax \u2212 Fmin\nH = fmb \u2212 Fmin y\u0302+ \u03b4y\u0302 . (17)\n46008 VOLUME 11, 2023\nThe hopping period Tm and carrier frequency fmb of cm can be converted to\nTm = w\u0302 W T0 (18)\nand\nfmb = y\u0302+ \u03b4y\u0302 H (Fmax \u2212 Fmin) + Fmin. (19)\nWhen there is only one FH signal in the environment, the hop duration for theM hop FH signal in a single observation window can be estimated as\nT\u0304 = 1 M M\u2211 m=1 Tm. (20)\nIV. NUMERAL EXPERIMENTS AND ANALYSIS In this section, numerical results are used to demonstrate the effectiveness of the proposed scheme.\nA. EXPERIMENT SETTINGS In this study, the carrier signal operates within the very-low frequency (VLF) band of the International Radio Consultative Committee (CCIR) and the long-wave (LW) band of the International Special Committee on Radio Interference CISPR-25. This band is well suited for air-sea integrated communications and navigation because of the electromagnetic waves transmitted over longer distances, allowing for communication over several kilometers. Furthermore, the band is highly stable, providing robustness against day and night, weather, climate, cosmic rays, and other interferences. Additionally, the band is more penetrative underwater, with less attenuation up to 100 m.\nHowever, the VLF band still faces complex EMI issues, particularly in FH communication. Chirp signals are commonly used in maritime radar systems that may interfere with VLF band communication, as well as the fixed-frequency radiation emitted by electrical devices such as motors and engine blades on aircraft, ships, and offshore platforms. Furthermore, the burst emissions of maritime lightning and ionospheric fluctuations can also affect VLF band communication. Therefore, identifying FH signals in such complex EMI is of great significance.\nThis study focused on baseband signal processing to simplify the analysis. The SNR of AWGN ranged from -10 dB to 10 dB, with an observation time of 0.08 s and a 128-point Hamming window for the STFT. The parameters of the FH, fixed-frequency, chirp, and burst signals presented in the complex EMI are listed in Table 2. In addition, to guarantee the statistical convenience and accuracy of the experimental results, Monte Carlo samples considering the algorithm\u2019s robustness are usually selected by discrete SNR with a step of 1 dB. However, to better understand the prediction results between selected SNRs, it is crucial to conduct sufficient Monte Carlo samples at each SNR. Therefore, this study generated 500 Monte Carlo samples per dB per step for a hopping period of the FH signal between 0.01 s and 0.02 s\nwith a step of 0.002 s, which contained a total dataset of 63,000 spectrograms.\nFor the CenterNet parameters, the training, validation, and test sets were segmented at 50%, 25%, and 25%, respectively. The model was pre-trained on MS COCO [56] for weight initialization, and the Adam algorithm with 0.94 momenta and 0.0001 weight decay was used for training. We used a learning rate segmentation strategy to avoid misconvergence. The learning rate was initially set to 1 \u00d7 10\u22124 with a batch size of 64, and then decayed to 1 \u00d7 10\u22125 after 50 epochs with a batch size of 16, and the training terminus was set to 100 epochs.\nB. RESULTS EVALUATION"
        },
        {
            "heading": "1) STFT PERFORMANCE VERIFICATION",
            "text": "Fig. 4 compares the spectrograms and contour plots of STFT with WVD and SPWVD for the same mixed signal at an SNR of 0 dB. Comparing Fig. 4(a) and 4(b) with Fig. 4(c) and 4(d) reveals that the WVD extensively aggregated the signal representation, as evidenced by the slim and bright outlines, and the noise was effectively suppressed. However, owing to the presence of cross terms, the WVD of signal and interference were represented as non-independent, causing a severe TF overlap. Furthermore, bacause WVD is the Fourier transform of the autocorrelation function, the values lose linearity over time, resulting in a more confusing TFR, making it challenging to achieve signal detection using image processing algorithms. Comparing Fig. 4(c) and 4(d) with Fig. 4(e) and 4(f), we can see that the SPWVD reduced the TF aggregation and overlap. Nevertheless, as the cross terms remain, the TF overlap generated substantial interference and few correct outlines, which differs from the STFT. The results confirm the incomparable advantage of the STFT in this scheme."
        },
        {
            "heading": "2) RESULTS OBSERVATION OF THE PROPOSED SCHEME",
            "text": "To illustrate the procedure of the proposed scheme more intuitively, we showcase the detection outputs of the FH signal in a mixed signal with AWGN at an SNR of 5 dB, as shown in Fig. 5. The mixed signal in the time domain is shown in Fig. 5(a). The 3-D mesh in the TF domain after applying STFT highlights the concentration of the signal energy, as shown in Fig. 5(b). After 2-D processing to obtain Fig. 5(c), the FH signal can be visually identified from other interferences with the energy distribution. Finally, the Bbox coordinates of the FH hops are revealed in the image through CenterNet, as shown in Fig. 5(d). After the screening, an inverse mapping is performed to derive the frequency and hopping period estimations of the FH signal."
        },
        {
            "heading": "3) NETWORK TRAINING PERFORMANCE",
            "text": "In Fig. 6, we present the trend of the total loss and validation loss with respect to the epoch of our DL architecture, observing that both losses decreased smoothly as the number of training epochs increased. The result indicates\nVOLUME 11, 2023 46009\nFIGURE 4. Comparison of the TFA algorithms (SNR = 0 dB). (a) STFT spectrogram. (b) STFT contour. (c) WVD spectrogram. (d) WVD contour. (e) SPWVD spectrogram. (f) SPWVD contour.\nFIGURE 5. A proceeding example of proposed scheme (SNR = 5 dB). (a) Original time-domain signal. (b) 3-D mesh after the STFT. (c) Spectrogram after 2-D Processing. (d) Image with Bbox after CenterNet Detection.\nthat the architecture parameters were well selected without overfitting. Moreover, the losses reduced steadily when the epoch was between 30 and 50 and decreased sharply again when the learning rate was adjusted to 1 \u00d7 10\u22125 at the 50th epoch, demonstrating an appropriate setting. Finally, the losses became smooth again after 90 epochs andwere reduced to the magnitude of 10\u22121, indicating quick convergence and appropriate fitting of the architecture."
        },
        {
            "heading": "4) PERFORMANCE COMPARISON OF THE DL ARCHITECTURES",
            "text": "In this part, we conducted two experiments to compare the performance of CenterNet with YOLOv7 [47] and YOLOX [46]. The results of the mean average precision (mAP), APtest50 , and AP test 75 obtained from training and testing these three DL architectures on the dataset generated in Section IV-A are summarized in Table 3. As can be seen, the average precision (AP) performance of all architectures is significantly higher than that of MS COCO [56], with APs exceeding 90%. This result originates from the\ncontinued training for the dedicated application in this study based on the pre-trained model, which improves the generalization capability of the network parameters for FH signal detection. In addition, CenterNet obtained 99.25% mAP, 99.91% APtest50 , and 99.75% AP test 75 , outperforming YOLOv7 and YOLOX by 6.31%, 0.01%, 0.03% and 8.39%, 0.03%, 1.21%, respectively. This is because YOLOv7 and YOLOX are both anchor-based architectures that require different aspect ratios of anchors to traverse the image. In contrast, CenterNet is an anchor-free architecture that uses a heat map of the features to represent the probability of the center point location, thus obtaining a better representation of the features of the object. On the other hand, YOLOv7 and YOLOX primarily concentrate on optimization for smalltarget detection, and the improvement in performance for regular-target detection is comparatively limited. For the application in this study, the FH signal will not appear as a small target in the spectrogram as long as the TF scale is set appropriately; thus, the performance is generally satisfactory.\n46010 VOLUME 11, 2023\nTABLE 3. AP comparison of the DL architectures.\nFIGURE 7. mAP comparison of the DL architectures by SNR.\nFurthermore, we compared the mAPs of the three DL architectures under different SNRs, as shown in Fig. 7. As can be seen, the mAP of all architectures gradually increased as the SNR increased. The mAP of CenterNet exceeded 90% when the SNR reached -1 dB, whereas the mAPs of both YOLOv7 and YOLOX exceeded 88% when the SNR reached 3 dB. Subsequently, the mAPs of all the architectures converged. It was also evident that the mAPs of YOLOv7 and YOLOX were closer under all SNRs, whereas the mAP of CenterNet was consistently higher by at least 2%. Thus, we can conclude that CenterNet outperforms YOLOv7 and YOLOX in terms of the prediction performance under all SNRs."
        },
        {
            "heading": "5) PERFORMANCE IMPACT OF THE IOU",
            "text": "The key to detecting a signal using image detection is correctly identifying the target representation from the image. Therefore, the next step is to verify the detection accuracy of the proposed method. Here, we chose IoU as the criterion and usedmiss probability as an index of recognition accuracy. The miss probability Pmiss is the quantity ratio of detected FH hops Ndetect to total FH hops Ntotal.\nPmiss = 1 \u2212 Ndetect Ntotal\n(21)\nThe SNR-miss probability graph for different IoU thresholds is shown in Fig. 8. We observed that if the IoU was too large, the miss probability also became significant. When the IoU decreased gradually, the miss probability also decreased and stabilized until it almost stopped changing when the IoU was less than 0.6. These results can be explained by the fact that, although the Bbox of the detected FH hop is close to the ground truth, there may still be some errors in the exact position. Thus, setting the IoU between 0.3 and 0.6 will ensure the reliability of the detection results to avoid discarding of approximate predictions, which would decrease detection accuracy by having a high threshold value.\nIn addition, considering IoU = 0.5, as an example, the miss probability decreased as the SNR increased. When the SNR exceeded -7 dB, the miss probability dropped to 0, demonstrating that 100% of the FH hops were detected. Furthermore, the miss probability reduced to within 2%when the\nVOLUME 11, 2023 46011\nSNR reached -10 dB, indicating that the proposed scheme can accurately detect FH signals in complex EMI environments with a low SNR.\nFurthermore, we evaluate the estimator using the root mean squared error (RMSE) metric and present the results in Fig. 9. Fig. 9(a) and 9(b) illustrate that the estimation of the frequency and hopping period reached the magnitudes of 10\u22123 and 10\u22124, respectively. The RMSE of the frequency tended to stabilize after a slight decrease as the SNR increased, converging after the SNR reached \u22121 dB. On the other hand, the RMSE of the hopping period decreased as the SNR increased and converged after the SNR reached \u22129 dB, indicating that the proposed scheme achieves desirable estimation accuracy. Furthermore, increasing the IoU decreases the RMSE because a higher IoU implies a stricter screening of the prediction results, which selects a Bbox closer to the\nground truth and lowers the RMSE. However, combined with the analysis of Fig. 8, the reduction in estimation error comes at the cost of recognition accuracy, verifying that an IoU between 0.3 and 0.6 is the optimal choice for performance compromise."
        },
        {
            "heading": "6) PERFORMANCE IMPACT OF THE HOPPING PERIOD",
            "text": "In this part, we compare the miss probability and the RMSE of the proposed scheme at different hopping periods. The results with hopping periods of 0.01 s, 0.016 s, and 0.02 s at IoU of 0.5 are shown in Fig. 10. As can be seen from Fig. 10, the three curves overlapped with each other with an irregular trend, indicating that the hopping period change does not affect the experimental results. It is worth noting that the statistics of other hopping periods still obey the same conclusion. Therefore, Fig. 10 does not present the statistical results for all hopping periods simultaneously to maintain conciseness and to facilitate comparison.\nV. CONCLUSION This paper presents a novel scheme for estimating FH signals in complex EMI environments by combining STFT analysis and CenterNet image detection. The optimal parameters of CenterNet were obtained to ensure the detection accuracy and estimation precision. Simulations showed promising results in detecting and estimating the FH signal in complex EMI at a low SNR, providing a reference for designing and optimizing other DL-based image detection algorithms for detecting and estimating FH signals. Future work will focus on exploring the effects of STFT window size, discovering other TFA algorithms, fingerprinting multiple FH transmitters, detecting interfering signals, analyzing the minimum size of the dataset for model training, and designing adaptive spectrum switching or FH code schemes to mitigate the effects of active or passive interference. The performance of the proposed scheme under more complex background noise requires further exploration. Moreover, the current performance evaluation focuses mainly on the accuracy of the offline scheme, and we will develop an online version in the future to comprehensively evaluate its real-time performance.\nREFERENCES [1] A. Ephremides, J. E. Wieselthier, and D. J. Baker, \u2018\u2018A design con-\ncept for reliable mobile radio networks with frequency hopping signaling,\u2019\u2019 Proc. IEEE, vol. 75, no. 1, pp. 56\u201373, Jan. 1987, doi: 10.1109/PROC.1987.13705. [2] Q. Chen, E. S. Sousa, and S. Pasupathy, \u2018\u2018Multicarrier CDMA with adaptive frequency hopping for mobile radio systems,\u2019\u2019 IEEE J. Sel. Areas Commun., vol. 14, no. 9, pp. 1852\u20131858, Dec. 1996, doi: 10.1109/49.545707. [3] S. Barbarossa and A. Scaglione, \u2018\u2018Parameter estimation of spread spectrum frequency-hopping signals using time-frequency distributions,\u2019\u2019 in Proc. 1st IEEE Signal Process. Workshop Signal Process. Adv. Wireless Commun., Apr. 1997, pp. 213\u2013216, doi: 10.1109/SPAWC.1997.630288. [4] D. J. Torrieri, \u2018\u2018Mobile frequency-hopping CDMA systems,\u2019\u2019 IEEE Trans. Commun., vol. 48, no. 8, pp. 1318\u20131327, Aug. 2000, doi: 10.1109/26.864169. [5] S. Srinivasa and S. Jafar, \u2018\u2018Cognitive radios for dynamic spectrum access\u2014The throughput potential of cognitive radio: A theoretical perspective,\u2019\u2019 IEEE Commun. Mag., vol. 45, no. 5, pp. 73\u201379, May 2007, doi: 10.1109/MCOM.2007.358852.\n46012 VOLUME 11, 2023\n[6] Y. Yuan, Z. Huang, and X. Wang, \u2018\u2018Detection of frequency-hopping radio frequency-switch transients,\u2019\u2019 Electron. Lett., vol. 50, no. 13, pp. 956\u2013957, Jun. 2014. [7] Y.-A. Jung, D. Shin, and Y.-H. You, \u2018\u2018Efficient estimation algorithm of carrier frequency offset for LTE machine-type communication using frequency hopping,\u2019\u2019 IEEE Access, vol. 7, pp. 177274\u2013177283, 2019. [8] J. Ma, Y. Yang, H. Li, and J. Li, \u2018\u2018FH-BOC: Generalized low-ambiguity anti-interference spread spectrummodulation based on frequency-hopping binary offset carrier,\u2019\u2019 GPS Solutions, vol. 24, no. 3, p. 70, Jul. 2020, doi: 10.1007/s10291-020-00982-3. [9] C. Li, P. Qi, D. Wang, and Z. Li, \u2018\u2018On the anti-interference tolerance of cognitive frequency hopping communication systems,\u2019\u2019 IEEE Trans. Rel., vol. 69, no. 4, pp. 1453\u20131464, Dec. 2020, doi: 10.1109/TR.2020.3002105. [10] J. Ye, J. Zou, J. Gao, G. Zhang, M. Kong, Z. Pei, and K. Cui, \u2018\u2018A new frequency hopping signal detection of civil UAV based on improved Kmeans clustering algorithm,\u2019\u2019 IEEE Access, vol. 9, pp. 53190\u201353204, 2021, doi: 10.1109/ACCESS.2021.3070491. [11] K. Wu, J. Andrew Zhang, X. Huang, Y. Jay Guo, and R. W. Heath Jr., \u2018\u2018Waveform design and accurate channel estimation for frequency-hopping MIMO radar-based communications,\u2019\u2019 IEEE Trans. Commun., vol. 69, no. 2, pp. 1244\u20131258, Oct. 2020, doi: 10.1109/TCOMM.2020.3034357. [12] H. Chougrani, S. Kisseleff, and S. Chatzinotas, \u2018\u2018Efficient preamble detection and time-of-arrival estimation for single-tone frequency hopping random access in NB-IoT,\u2019\u2019 IEEE Internet Things J., vol. 8, no. 9, pp. 7437\u20137449, May 2021, doi: 10.1109/JIOT.2020.3039004. [13] F. Liu, M. W. Marcellin, N. A. Goodman, and A. Bilgin, \u2018\u2018Compressive sampling for detection of frequency-hopping spread spectrum signals,\u2019\u2019 IEEE Commun. Lett., vol. 64, no. 21, pp. 5513\u20135524, Nov. 2016, doi: 10.1109/TSP.2016.2597122. [14] S. Liu, Y. D. Zhang, T. Shan, and R. Tao, \u2018\u2018Structure-aware Bayesian compressive sensing for frequency-hopping spectrum estimation with missing observations,\u2019\u2019 IEEE Trans. Signal Process., vol. 66, no. 8, pp. 2153\u20132166, Apr. 2018, doi: 10.1109/TSP.2018.2806351. [15] S. Ghanem, \u2018\u2018Decoding and measurement of frequency-hopping spread spectrum signals using an adaptive algorithm-based compressive sensing,\u2019\u2019 Int. J. Commun. Syst., vol. 34, no. 3, p. e4675, Feb. 2021, doi: 10.1002/dac.4675. [16] B. F. Lo, S. Torborg, and C. K. A. Yeung, \u2018\u2018HopSAC: Frequency hopping parameter estimation based on random sample consensus for counter-unmanned aircraft systems,\u2019\u2019 in Proc. IEEE Mil. Commun. Conf. (MILCOM), Nov. 2019, pp. 355\u2013360, doi: 10.1109/MILCOM47813.2019.9020841. [17] J. L. Loof and T. G. Pratt, \u2018\u2018Frequency-hopped signal source identification in frequency-selective channels,\u2019\u2019 IEEE Trans. Aerosp. Electron. Syst., vol. 55, no. 6, pp. 3316\u20133329, Dec. 2019. [18] A. Kanaa and A. Z. Sha\u2019Ameri, \u2018\u2018A robust parameter estimation of FHSS signals using time\u2013frequency analysis in a non-cooperative environment,\u2019\u2019 Phys. Commun., vol. 26, pp. 9\u201320, Feb. 2018, doi: 10.1016/j.phycom.2017.10.013. [19] L. Zhi, Z. Jianhua, C. Hao, G. Xu, and L. Jian, \u2018\u2018Parameter estimation of frequency hopping signals based on analogue information converter,\u2019\u2019 IET Commun., vol. 13, no. 13, pp. 1886\u20131892, Aug. 2019, doi: 10.1049/ietcom.2019.0057. [20] J. Wan, D. Zhang, W. Xu, and Q. Guo, \u2018\u2018Parameter estimation of multi frequency hopping signals based on space-time-frequency distribution,\u2019\u2019 Symmetry, vol. 11, no. 5, p. 648, May 2019. [Online]. Available: https://www.mdpi.com/2073-8994/11/5/648 [21] J. Wu and F. Guo, \u2018\u2018Time-frequency parameter estimation method of frequency hopping signal based on morphology method under low SNR,\u2019\u2019 in Proc. IEEE 6th Int. Conf. Signal Image Process. (ICSIP), Oct. 2021, pp. 734\u2013738, doi: 10.1109/ICSIP52628.2021.9688633. [22] H. Wang, B. Zhang, H. Wang, B. Wu, and D. Guo, \u2018\u2018Hopping time estimation of frequency-hopping signals based on HMM-enhanced Bayesian compressive sensing with missing observations,\u2019\u2019 IEEE Commun. Lett., vol. 26, no. 9, pp. 2180\u20132184, Sep. 2022, doi: 10.1109/LCOMM.2022.3184173. [23] Z. Jiang, S. Wang, Y. Chen, P. Wang, and L. Gao, \u2018\u2018Frequency hopping signal parameter estimation algorithm based on time-frequency point correlation,\u2019\u2019 in Proc. IEEE 10th Joint Int. Inf. Technol. Artif. Intell. Conf. (ITAIC), Jun. 2022, pp. 740\u2013744, doi: 10.1109/ITAIC54216.2022.9836485. [24] B. Hinman, J. Bernstein, and D. Staelin, \u2018\u2018Short-space Fourier transform image processing,\u2019\u2019 in Proc. IEEE Int. Conf. Acoust., Speech, Signal Process., Mar. 1984, pp. 166\u2013169, doi: 10.1109/ICASSP.1984.1172374.\n[25] L. Tong, T. Yinhui, and L. Jun, \u2018\u2018Parameter estimation of FH signals based on STFT and music algorithm,\u2019\u2019 in Proc. Int. Conf. Comput. Appl. Syst. Model. (ICCASM), Oct. 2010, pp. 22\u201324, doi: 10.1109/ICCASM.2010.5619186. [26] T. Feng and C. W. Yuan, \u2018\u2018Blind parameter estimation of frequencyhopping signals based on the time-frequency distribution maxima,\u2019\u2019 Acta Electronica Sinica, vol. 39, no. 12, pp. 2921\u20132925, 2011. [27] W. Fu, X. Li, N. Liu, Y. Hei, and J. Wei, \u2018\u2018Parameter blind estimation of frequency-hopping signal based on time\u2013frequency diagram modification,\u2019\u2019 Wireless Pers. Commun., vol. 97, no. 3, pp. 3979\u20133992, Dec. 2017, doi: 10.1007/s11277-017-4710-5. [28] B. Kaplan, I. Kahraman, A. Gorcin, H. A. Cirpan, and A. R. Ekti, \u2018\u2018Measurement based FHSS\u2013type drone controller detection at 2.4 GHz: An STFT approach,\u2019\u2019 inProc. IEEE 91st Veh. Technol. Conf. (VTC-Spring), May 2020, pp. 1\u20136, doi: 10.1109/VTC2020-Spring48590.2020.9129525. [29] S. Kumawat, M. Verma, Y. Nakashima, and S. Raman, \u2018\u2018Depthwise spatio-temporal STFT convolutional neural networks for human action recognition,\u2019\u2019 IEEE Trans. Pattern Anal. Mach. Intell., vol. 44, no. 9, pp. 4839\u20134851, Apr. 2022, doi: 10.1109/TPAMI.2021.3076522. [30] T. Feng and C.W.Yuan, \u2018\u2018Combination ofWigner\u2013Ville distribution and its application to blind parameter estimation of frequency-hopping signals,\u2019\u2019 J. Xidian Univ., vol. 37, no. 6, pp. 1137\u20131142, 2010. [31] T.-C. Chen, \u2018\u2018Joint signal parameter estimation of frequency-hopping communications,\u2019\u2019 IET Commun., vol. 6, no. 4, pp. 381\u2013389, 2012. [32] Z. Leyuan, L. Chuanhui, L. Bihui, L. Faping, and K. Jiafang, \u2018\u2018Research on time-frequency energy distribution characteristics of PSWFs signals based on WVD,\u2019\u2019 in Proc. 4th Int. Conf. Inf. Commun. Signal Process. (ICICSP), Sep. 2021, pp. 134\u2013138, doi: 10.1109/ICICSP54369.2021.9611851. [33] Z. Li, X. Zhang, Q. Yang, Y. Xiao, H. An, H. Yang, J. Wu, and J. Yang, \u2018\u2018Hybrid SAR-ISAR image formation via joint FrFT-WVD processing for BFSAR ship target high-resolution imaging,\u2019\u2019 IEEE Trans. Geosci. Remote Sens., vol. 60, 2022, Art. no. 5215713, doi: 10.1109/TGRS.2021.3117280. [34] P. Flandrin, \u2018\u2018Some features of time-frequency representations of multicomponent signals,\u2019\u2019 in Proc. IEEE Int. Conf. Acoust., Speech, Signal Process., Mar. 1984, pp. 266\u2013269, doi: 10.1109/ICASSP.1984.1172741. [35] Z. Wang, Y. Li, and W. Xu, \u2018\u2018A blind parameter estimation method of frequency hopping signal with low SNR,\u2019\u2019 Int. J. Circuits, Syst. Signal Process., vol. 15, pp. 248\u2013253, Apr. 2021. [36] S. K. Khare, V. Bajaj, and U. R. Acharya, \u2018\u2018SPWVD-CNN for automated detection of schizophrenia patients using EEG signals,\u2019\u2019 IEEE Trans. Instrum. Meas., vol. 70, pp. 1\u20139, 2021. [37] A. Kamble, P. H. Ghare, and V. Kumar, \u2018\u2018Deep-learning-based BCI for automatic imagined speech recognition using SPWVD,\u2019\u2019 IEEE Trans. Instrum. Meas., vol. 72, pp. 1\u201310, 2023, doi: 10.1109/TIM.2022.3216673. [38] R. Girshick, J. Donahue, T. Darrell, and J. Malik, \u2018\u2018Rich feature hierarchies for accurate object detection and semantic segmentation,\u2019\u2019 in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2014, pp. 580\u2013587, doi: 10.1109/CVPR.2014.81. [39] R. Girshick, \u2018\u2018Fast R-CNN,\u2019\u2019 in Proc. IEEE Int. Conf. Comput. Vis. (ICCV), Dec. 2015, pp. 1440\u20131448. [40] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, \u2018\u2018You only look once: Unified, real-time object detection,\u2019\u2019 in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 779\u2013788, doi: 10.1109/CVPR.2016.91. [41] S. Ren, K. He, R. Girshick, and J. Sun, \u2018\u2018Faster R-CNN: Towards realtime object detection with region proposal networks,\u2019\u2019 IEEE Trans. Pattern Anal. Mach. Intell., vol. 39, no. 6, pp. 1137\u20131149, Jun. 2017, doi: 10.1109/TPAMI.2016.2577031. [42] K. He, G. Gkioxari, P. Dollar, and R. Girshick, \u2018\u2018Mask R-CNN,\u2019\u2019 in Proc. IEEE Int. Conf. Comput. Vis. (ICCV), Oct. 2017, pp. 2980\u20132988, doi: 10.1109/ICCV.2017.322. [43] J. Redmon and A. Farhadi, \u2018\u2018YOLOv3: An incremental improvement,\u2019\u2019 2018, arXiv:1804.02767. [44] Z. Tian, C. Shen, H. Chen, and T. He, \u2018\u2018FCOS: Fully convolutional onestage object detection,\u2019\u2019 inProc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), Oct. 2019, pp. 9626\u20139635, doi: 10.1109/ICCV.2019.00972. [45] I. Oksuz, J. R. Clough, B. Ruijsink, E. P. Anton, A. Bustin, G. Cruz, C. Prieto, A. P. King, and J. A. Schnabel, \u2018\u2018Deep learning-based detection and correction of cardiac MR motion artefacts during reconstruction for high-quality segmentation,\u2019\u2019 IEEE Trans. Med. Imag., vol. 39, no. 12, pp. 4001\u20134010, Dec. 2020, doi: 10.1109/TMI.2020.3008930. [46] Z. Ge, S. Liu, F. Wang, Z. Li, and J. Sun, \u2018\u2018YOLOX: Exceeding YOLO series in 2021,\u2019\u2019 2021, arXiv:2107.08430.\nVOLUME 11, 2023 46013\n[47] C.-Y. Wang, A. Bochkovskiy, and H.-Y. Mark Liao, \u2018\u2018YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors,\u2019\u2019 2022, arXiv:2207.02696. [48] X. Zhou, D. Wang, and P. Kr\u00e4henb\u00fchl, \u2018\u2018Objects as points,\u2019\u2019 arXiv:1904.07850, 2019. [49] Y. Sun, Z. Li, L. Wang, J. Zuo, L. Xu, and M. Li, \u2018\u2018Automatic detection of vehicle targets based on CenterNet model,\u2019\u2019 in Proc. IEEE Int. Conf. Consum. Electron. Comput. Eng. (ICCECE), Jan. 2021, pp. 375\u2013378. [50] Z. Dai, J. Yi, L. Jiang, S. Yang, and X. Huang, \u2018\u2018Cascade CenterNet: Robust object detection for power line surveillance,\u2019\u2019 IEEE Access, vol. 9, pp. 60244\u201360257, 2021, doi: 10.1109/ACCESS.2021.3072901. [51] H. Zheng, Y. Cui, W. Yang, J. Li, L. Ji, Y. Ping, S. Hu, and X. Chen, \u2018\u2018An infrared image detection method of substation equipment combining iresgroup structure and CenterNet,\u2019\u2019 IEEE Trans. Power Del., vol. 37, no. 6, pp. 4757\u20134765, Dec. 2022, doi: 10.1109/TPWRD.2022.3158818. [52] Y.-J. Zhang, R.-Y. Liu, and H.-J. Song, \u2018\u2018A method of the detection of frequency-hopping signal based on channelized receiver in the complicated electromagnetic environment,\u2019\u2019 in Proc. Int. Conf. Intell. Inf. Hiding Multimedia Signal Process. (IIH-MSP), Sep. 2015, pp. 294\u2013297, doi: 10.1109/IIH-MSP.2015.65. [53] K. He, X. Zhang, S. Ren, and J. Sun, \u2018\u2018Deep residual learning for image recognition,\u2019\u2019 in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 770\u2013778, doi: 10.1109/CVPR.2016.90. [54] B. Xiao, H. Wu, and Y. Wei, \u2018\u2018Simple baselines for human pose estimation and tracking,\u2019\u2019 2018, arXiv:1804.06208. [55] H. Law and J. Deng, \u2018\u2018CornerNet: Detecting objects as paired keypoints,\u2019\u2019 in Proc. Eur. Conf. Comput. Vis., 2018, pp. 734\u2013750. [56] T.-Y. Lin,M.Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Doll\u00e1r, and C. L. Zitnick, \u2018\u2018Microsoft COCO: Common objects in context,\u2019\u2019 in Proc. ECCV, 2014, pp. 740\u2013755.\nZIYI CHEN (Student Member, IEEE) received the B.Eng. degree in automation from Jilin University, Changchun, China, in 2012, where he is currently the Ph.D. degree in control theory and control engineering with the College of Communication Engineering.\nFrom September 2017 to September 2019, he was a Visiting Ph.D. Student with the School of Electrical and Computer Engineering, Georgia Institute of Technology (GATech), Atlanta, GA,\nUSA. His currently research interests include frequency hopping signal processing, time frequency analysis, and image processing using machine learning.\nMr. Chen has been a Student Member of the China Institute of Communication (CIC), China, since 2013.\nYAOWU SHI received the B.Eng., M.Sc., and Ph.D. degrees in control theory and control engineering from the Jilin University of Technology, Changchun, China, in 1982, 1985, and 1994, respectively.\nFrom 1986 to 1994, he was a Lecturer with the Jilin University of Technology, where he was promoted to an Associate Professor, in 1994. In 1998, he was a Professor with Jilin University. He is the author or coauthor of one book and several book\nchapters, and more than 200 articles. His current research interests include modern cross-spectrum analysis, system identification, DOA estimation, harmonic parameter estimation, and chaotic signal processing.\nYINGWEI WANG received the B.Eng. degree in mechatronic engineering from the Shenyang Institute of Engineering, Shenyang, China, in 2016, and the M.Sc. degree in control engineering from Jilin University, Changchun, China, in 2019, where he is currently pursuing the Ph.D. degree in control science and engineering with the College of Communication Engineering.\nHis research interests include deep learning and control technology of acoustic levitation.\nXINBO LI received the B.Eng. degree in automation and the M.Sc. and Ph.D. degrees in control theory and control engineering from Jilin University, Changchun, China, in 2002, 2005, and 2009, respectively.\nFrom October 2007 to October 2008, he was a Visiting Ph.D. Student with the School of Electrical and Electronic Engineering, Nanyang Technological University (NTU), Singapore. He is currently a Professor with Jilin University. His\nresearch interests include piezoelectric drive control technology, array signal processing, and time frequency analysis.\nXIAOHUI YU received the B.Eng. degree in automation and the M.Sc. and Ph.D. degrees in control theory and control engineering from Jilin University, Changchun, China, in 2001, 2004, and 2007, respectively.\nShe is currently a Lecturer with Jilin University. Her research interests include control theory, parameter estimation, and array signal processing.\nYIRAN SHI (Member, IEEE) received the B.Eng. degree in control engineering from the Changchun University of Science and Technology, Changchun, China, in 2007, the M.Sc. degree in control engineering from the Lanzhou University of Technology, Lanzhou, China, in 2010, and the Ph.D. degree in control engineering from Jilin University, Changchun, in 2014.\nHe is currently a Professor with Jilin University. He is the author or coauthor of more than\n30 articles. His current research interests include signal processing andmodel predictive control.\n46014 VOLUME 11, 2023"
        }
    ],
    "title": "Unlocking Signal Processing With Image Detection: A Frequency Hopping Detection Scheme for Complex EMI Environments Using STFT and CenterNet",
    "year": 2023
}