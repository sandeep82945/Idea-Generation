{
    "abstractText": "We extend the methodology in Yang et al. [SIAM J. Appl. Dyn. Syst. 22, 269\u2013310 (2023)] to learn autonomous continuous-time dynamical systems from invariant measures. The highlight of our approach is to reformulate the inverse problem of learning ODEs or SDEs from data as a PDE-constrained optimization problem. This shift in perspective allows us to learn from slowly sampled inference trajectories and perform uncertainty quantification for the forecasted dynamics. Our approach also yields a forward model with better stability than direct trajectory simulation in certain situations. We present numerical results for the Van der Pol oscillator and the Lorenz-63 system, together with real-world applications to Hall-effect thruster dynamics and temperature prediction, to demonstrate the effectiveness of the proposed approach. Published by AIP Publishing. https://doi.org/10.1063/5.0149673 Data-driven models have proven to be instrumental across numerous scientific disciplines for their ability to predict and control the behavior of complex physical systems. Popular approaches for modeling dynamical trajectories typically adopt a Lagrangian perspective and seek pointwise matching with either the observed data or its approximate state derivatives. When the observed data have a poor temporal resolution and the state derivatives are difficult to approximate, these approaches may struggle. Such difficulties are further exaggerated when measurements are contaminated with noise, and the system in question exhibits sensitive dependence on initial conditions. In this paper, we propose an alternative approach that can circumvent some of these challenges by treating global statistics of the observed dynamics as the inference data.",
    "authors": [
        {
            "affiliations": [],
            "name": "Yunan Yang"
        },
        {
            "affiliations": [],
            "name": "Jonah Botvinick-Greenhouse"
        },
        {
            "affiliations": [],
            "name": "Robert Martin"
        }
    ],
    "id": "SP:1d344b28364c9e1723ea8f158da7697f76b2ec55",
    "references": [
        {
            "authors": [
                "2014). 37W. Huang",
                "M. Ji",
                "Z. Liu",
                "Y. Yi"
            ],
            "title": "Steady states of Fokker\u2013Planck equations",
            "year": 2014
        }
    ],
    "sections": [
        {
            "text": "We extend the methodology in Yang et al. [SIAM J. Appl. Dyn. Syst. 22, 269\u2013310 (2023)] to learn autonomous continuous-time dynamical systems from invariant measures. The highlight of our approach is to reformulate the inverse problem of learning ODEs or SDEs from data as a PDE-constrained optimization problem. This shift in perspective allows us to learn from slowly sampled inference trajectories and perform uncertainty quantification for the forecasted dynamics. Our approach also yields a forward model with better stability than direct trajectory simulation in certain situations. We present numerical results for the Van der Pol oscillator and the Lorenz-63 system, together with real-world applications to Hall-effect thruster dynamics and temperature prediction, to demonstrate the effectiveness of the proposed approach.\nPublished by AIP Publishing. https://doi.org/10.1063/5.0149673\nData-driven models have proven to be instrumental across numerous scientific disciplines for their ability to predict and control the behavior of complex physical systems.1 Popular approaches for modeling dynamical trajectories typically adopt a Lagrangian perspective and seek pointwise matching with either the observed data or its approximate state derivatives. When the observed data have a poor temporal resolution and the state derivatives are difficult to approximate, these approaches may struggle. Such difficulties are further exaggerated when measurements are contaminated with noise, and the system in question exhibits sensitive dependence on initial conditions. In this paper, we propose an alternative approach that can circumvent some of these challenges by treating global statistics of the observed dynamics as the inference data.\nI. INTRODUCTION\nDifferential equations are typically used to model trajectory data originating from physical systems. Common techniques for fitting differential equations to trajectory data include the shooting methods,2,3 neural differential equations,4\u20136 and SINDy.7,8 Methods based on the Kalman filter are effective in data assimilation and\nin estimating unknown states and parameters of a system as it evolves in time.9\u201314 When used to identify model parameters, these approaches fall under the broad category of system identification.\nThese approaches all adopt a Lagrangian perspective and directly fit the modeled trajectories or their state derivatives to the observed measurements. While these techniques have seen great success in modeling complex dynamics, their application is generally limited to inference trajectories sampled at a relatively high frequency. When the inference trajectory is sampled slowly or in the worst-case scenario when measurement times are unknown, these approaches may not be applicable. For example, see Fig. 1 in which we investigate the use of SINDy7 and a neural ODE4 for modeling the dynamics of a slowly sampled limit cycle.\nThere are at least three sources of instabilities when directly using the trajectory data to perform velocity reconstruction. First, for certain chaotic dynamical systems, a small perturbation in the initial condition can lead to a large deviation in the trajectory at a later time, which cannot be differentiated from inaccurate dynamics by looking at the data alone. Second, the estimation of the particle velocity suffers from slowly sampled trajectory data, which directly affects the reconstruction of the dynamics, as shown in Fig. 1. Third, the measurement (extrinsic) noise and the model intrinsic noise both change the state location. The small noise pollution can be\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-1\nPublished by AIP Publishing\n10 January 2024 13:03:41\namplified more in the velocity estimation using the divided difference with a small time step. All three factors share the nature that a small perturbation in the trajectory data leads to a large deviation in the estimated velocity/learned dynamics.\nIn contrast with the Lagrangian approach to modeling dynamics, our method builds on an Eulerian perspective17,18 in which velocity models are constructed to yield the same asymptotic statistics as the observed measurements. This approach converts what is traditionally regarded as an ordinary differential equation (ODE) or a stochastic differential equation (SDE) modeling problem into a partial differential equation (PDE)-constrained optimization problem. The motivation of our method is that, in certain situations, the PDE forward model yields better stability in solving the inverse problem than direct trajectory forward simulation based upon an ODE or SDE. Importantly, our method does not rely on prior knowledge of sampling times and can, thus, be used to learn the dynamics from slowly sampled trajectories.\nThere are two important differences between the line of work using Kalman filters and our proposed method. First, a Kalman filter is a particular case of the Bayes filter using the Bayes theorem, while our reconstruction follows a deterministic inverse problem (PDEconstrained optimization). Second, time is a crucial element in designing a Kalman filter, while in our approach, we use the invariant measure and a time-independent PDE surrogate model. Once the flow has been inferred, we can also perform uncertainty quantification for the forecasted dynamics, building toward extending gridbased Bayesian estimation of nonlinear low-dimensional systems19 to slowly sampled unknown systems with nontrivial invariant measures.\nMore specifically, instead of directly treating the noisy observations {x\u0303(ti)}ni=1 from one single trajectory of an autonomous flow x\u0307 = v\u2217(x) as inference data, we consider the occupation measure \u03c1\u2217 generated by a single trajectory, where for each measurable set B,\n\u03c1\u2217(B) := 1 n\nn\u2211 i=1 \u03c7B (x\u0303(ti)), \u03c7B(x) = { 1, x \u2208 B, 0, x 6\u2208 B. (1)\nWhen the occupation measures generated by a nontrivial (see Sec. II A) set of initial conditions all weakly converge to the same invariant measure, the limiting measure is said to be physical.20 In this work, we consider the class of autonomous systems for which the occupation measure of Lebesgue-almost all initial conditions converges to a unique physical measure. Notably, this encompasses chaotic attractors, such as the Lorenz-63 system.21,22 This assumption guarantees the uniqueness of the invariant measure for the dynamical system under study. If we relax it and allow the existence of multiple invariant measures, further treatment of the PDE forward model is needed; for instance, the fact that different invariant measures are mutually singular as well as information on the initial condition, among other considerations, is necessary to guarantee that the steady-state solution picked up by the PDE model matches the observed invariant measure. We remark that the definition of a physical measure demonstrates its robustness to perturbations with respect to initial conditions.\nGoing forward, we write v = v(\u03b8) = v(x; \u03b8) to denote the dependence of the reconstructed velocity fields on a set of parameters \u03b8 \u2208 2 where 2 \u2282 Rm is the admissible set of all parameter values. The concrete form of \u03b8 depends on the hypothesis space of v, which will be discussed in Sec. IV B. The task is now to find the best-parameterized model v(x; \u03b8) approximating the true velocity v\u2217 through the optimization\ninf \u03b8\u22082\nJ (\u03b8), J (\u03b8) := D(\u03c1\u03b5(v(\u03b8)), \u03c1\u2217). (2)\nThe formulation (2) represents an inverse data-matching problem, in which D denotes a metric or divergence on the space of probability measures and \u03c1\u03b5(v(\u03b8)) is a regularized approximation to the physical measure of the dynamical system, given some regularization parameter \u03b5 > 0 and the current velocity v(\u03b8); that is, v(\u03b8) 7\u2192 \u03c1\u03b5(v(\u03b8)) is our new forward model.\nAlthough one could approximate \u03c1(v(\u03b8)) by numerically integrating a trajectory and binning the observed states to a histogram,17 this approach does not permit simple differentiation of the resulting measure with respect to the parameters \u03b8 . When the size of \u03b8 , i.e., m, is large, it is practical to use gradient-based optimization methods for solving the optimization problem (2), and one has to compute\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-2\nPublished by AIP Publishing\n10 January 2024 13:03:41\nthe essential gradient \u2202\u03b8J . In Ref. 18, this was handled by viewing \u03c1\u03b5(v(\u03b8)) as the dominant eigenvector of a regularized Markov matrix originating from an upwind finite-volume discretization of the continuity equation. The derivative \u2202\u03b8J was then seamlessly computed via the adjoint-state method.18 The computation time of the adjoint-state method is independent of the size of \u03b8 , making the framework presented in Ref. 18 well-suited for large-scale computational inverse problems.\nIn this work, we build upon the framework proposed in Ref. 18 and study invariant measure-based velocity learning with a largescale parameter space applied to real data. There are three essential new contributions:\n1. We consider the Fokker\u2013Planck equation as the partial differential equation (PDE) forward model for \u03c1\u03b5(v(\u03b8)), rather than the continuity equation. This is motivated by the Fokker\u2013Planck equation\u2019s greater modeling capacity. Indeed, the Fokker\u2013Planck equation reduces to the continuity equation when its diffusion term is zero, and it can fit intrinsic noise present in trajectories, which reduces over-fitting the parameterized velocity v(\u03b8). Moreover, the Fokker\u2013Planck equation can be seen as an alternative to the teleportation regularization used for the continuity equation in Ref. 18 in order to guarantee the uniqueness of the computed stationary solution \u03c1\u03b5(v(\u03b8)). 2. In contrast to only learning three coefficients as done in Ref. 18, we parameterize the velocity v(\u03b8) using piecewise polynomial, global polynomial, and neural network discretizations, which can all yield large parameter spaces with thousands of dimensions. We compare the reconstructed velocity in each case and further discuss how the choice of parameterization affects the inverse problem\u2019s well-posedness and the reconstructed velocity\u2019s regularity. We also consider various metrics/divergences as the choice of the objective function. 3. We investigate velocity learning in time-delay coordinates, which can characterize the full dynamics from partial state measurements alone.23 After performing the optimization (2), we evolve the learned Fokker\u2013Planck equation forward in time to quantify the uncertainty in predictions of future dynamics. Based on this framework, we demonstrate that forecasts incur larger uncertainties when the embedding dimension is not sufficiently high. It is worth noting that there is no analytic form for the velocity in time-delay coordinates, even for well-studied dynamical systems. We also stress that our proposed approach permits larger-scale modeling of time-delayed dynamics than the approach considered in Ref. 17 due to the use of the adjoint-state method when solving the PDE-constrained optimization.\nThe rest of the paper is organized as follows. In Sec. II, we review essential background on dynamical systems, invariant measures, the Fokker\u2013Planck equation, and time-delay coordinates. In Sec. III, we introduce the forward surrogate model \u03c1\u03b5(v(\u03b8)) and analyze its modeling errors. In Sec. IV, we present an efficient gradient calculation for the objective function J (\u03b8) by treating (2) as a PDE-constrained optimization problem and utilizing the adjointstate method. We then adapt the gradient calculation to various velocity parameterizations, including neural network discretizations\nin which the gradient is computed along with the backpropagation technique.24\nFinally, in Sec. V, we present velocity reconstructions for the Van der Pol oscillator and the Lorenz-63 system. We also model dynamics in time-delay coordinates based on real-world data from a Hall-effect thruster and actual temperature recordings. We perform uncertainty quantification on the last two real-data examples. Conclusions follow in Sec. VI."
        },
        {
            "heading": "II. BACKGROUND",
            "text": "This section reviews the essential background on invariant measures, stochastic dynamics, the Fokker\u2013Planck equation, and time-delay coordinates. We also review the Eulerian approach for parameter identification proposed in Refs. 17 and 18, as well as past work on the discrete inverse Frobenius\u2013Perron problem.25"
        },
        {
            "heading": "A. Physical measures",
            "text": "Physical measures characterize the long-term statistical behavior of a significant collection of dynamical trajectories. When a dynamical system is chaotic and exhibits sensitive dependence on initial conditions, the existence of a physical measure unifies the statistical properties of trajectories that are pointwise dissimilar. While ergodic measures also describe the long-term statistical behavior of dynamical trajectories, they may have very small support or even be singular. On the other hand, when a dynamical system admits a physical measure, it holds that the trajectories corresponding to a positive Lebesgue measure subset of initial conditions will all share the same statistical behavior. We will now formalize these ideas in the language of ergodic theory. For a more thorough treatment of the topic, we refer to Refs. 20, 26, 27, and 28.\nWhile we will review the theory of physical measures in the context of discrete-time dynamical systems, our applications will consider dynamics given by a time-1t flow map for some 1t > 0. Following Ref. 20, we assume that M is a compact Riemannian manifold and that T : M \u2192 M is a diffeomorphism. A probability measure \u00b5 is said to be invariant with respect to the map T if \u00b5(T\u22121(B)) = \u00b5(B) for all B \u2208 B, where B denotes the Borel \u03c3 -algebra (see Ref. 29, Definition 2.1). Hereafter, we will assume that \u00b5 is an invariant measure. A point x \u2208 M is said to be generic (see Ref. 20, Sec. 2.2) if for all g \u2208 C(M), it holds that\nlim N\u2192\u221e\n1\nN\nN\u22121\u2211 k=0 g(Tk(x)) =\n\u222b\nM\ng d\u00b5. (3)\nThe left-hand side of (3) is known as the time-average of a function g \u2208 C(M), whereas the right-hand side of (3) is known as the space average. It follows from Birkhoff\u2019s pointwise ergodic theorem (see Theorem 2.30 in Ref. 29) that the time-average of any g \u2208 C(M) necessarily exists on a set of full \u00b5-measure. To formally discuss the statistical properties of dynamical trajectories, we now define the Nstep occupation measure given the initial condition x \u2208 M as\n\u00b5x,N(B) := 1\nN\nN\u22121\u2211 k=0 \u03c7B(T k(x)), \u2200B \u2208 B. (4)\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-3\nPublished by AIP Publishing\n10 January 2024 13:03:41\nThe condition that a point x \u2208 M is generic is equivalent to the condition\nlim N\u2192\u221e\n\u00b5x,N = \u00b5 , (5)\nwhere convergence takes place in the weak-* topology (see Ref. 29, Definition 4.19). Since the quantity \u00b5x,N(B) approximates the average amount of time for which the orbit {Tk(x)}\u221ek=0 initiated at x \u2208 M resides in a measurable set B \u2208 B, this convergence indicates that the collection of generic points all share the same asymptotic statistical behavior. When the measure \u00b5 is ergodic (see Ref. 29, Definition 4.19), it holds that \u00b5-almost every x \u2208 M is a generic point (see Ref. 29, Corollary 4.20). However, if \u00b5 is an ergodic measure that is singular with respect to the Lebesgue measure, the resulting collection of generic points may be physically insignificant and difficult to observe computationally. Motivated by this perspective, an invariant measure \u00b5 is said to be physical if there exists a collection of generic points with a positive Lebesgue measure (see Ref. 20, Definition 2.3).\nWe will next discuss the ways in which a physical invariant measure \u00b5 can be computationally approximated. If one collects the measurements {Tk(x)}Nk=1, the weak-* convergence in (5) suggests that the physical measure \u00b5 will describe the statistics of our measurements provided that N is sufficiently large. Motivated by this perspective, we can discretize the domain M and directly compute the occupation measure (4) for each cell in the discretization to approximate the physical measure. This procedure has been previously used to approximate physical measures.17,18,30 Other approaches have been proposed to compute the invariant measure as the stationary vector of the finite-dimensional approximation of the continuous Frobenius\u2013Perron operator,31 including Ulam\u2019s27 and Galerkin-type methods.32,33 More precisely, these discretizations are used to construct a Markov matrix that represents a random dynamical system approximating the deterministic map T : M \u2192 M. An invariant measure for the discrete approximation is then recovered as a stationary vector of the resulting Markov matrix. As the discretization is refined, certain assumptions guarantee that the desired physical measure will be recovered in the weak-* limit (see Ref. 32, Theorem 4.14)."
        },
        {
            "heading": "B. Stochastic dynamics and the Fokker\u2013Planck equation",
            "text": "Consider an It\u00f4 stochastic differential equation (SDE) of the form dXt = v(Xt)dt + \u03c3(Xt)dWt, X0 = x. (6) Above, Wt is a Brownian motion, v is the velocity, and \u03c3 determines the diffusion matrix 6(x) = 1\n2 \u03c3(x)\u03c3 (x)>. For simplicity, we will\nconsider the case of constant diffusion. Similar to the deterministic setting, there are analogous notions of invariant measures, ergodicity, and physical measures in the stochastic setting.34,35 One may use the Euler\u2013Maruyama method to obtain the numerical solution to (6) on the time interval [0, T], which assigns\nXj+1 = Xj + v(Xj)1t + \u03c3(Xj)\u03bej \u221a 1t,\nwhere {\u03bej} are independently and identically distributed (i.i.d.) from N (0, I), the standard normal distribution on Rd, 1t := T/N, and j \u2208 {0, . . . , N \u2212 1}.\nThe Fokker\u2013Planck equation provides a PDE description of the probability density \u03c1(x, t) of the random variable Xt. The density evolves as (see Ref. 36, p. 88)\n\u2202\u03c1(x, t)\n\u2202t = \u2212\u2207 \u00b7 (\u03c1(x, t)v(x))+ \u2207 \u00b7\n( \u2207 \u00b7 (6(x)\u03c1(x, t)) ) . (7)\nBy assuming a constant diffusion, we may write6(x) = DI, where I denotes the identity and D > 0 is a constant representing the scale of the diffusion. Equation (7) can then be simplified to read\n\u2202\u03c1(x, t)\n\u2202t = \u2212\u2207 \u00b7 (\u03c1(x, t)v(x))+ D\u22072\u03c1(x, t). (8)\nWe leave the study of a non-constant or anisotropic diffusion for later work. We remark that if D = 0, (8) reduces to the so-called continuity equation, which instead models the probability flow of the ODE given by x\u0307 = v(x). Under certain conditions,37 the steadystate solution \u03c1(x) of (8) exists and satisfies\n\u2207 \u00b7 (\u03c1(x)v(x)) = D\u22072\u03c1(x). (9)\nSince (9) describes a limiting distribution limt\u2192\u221e \u03c1(x, t), it has been previously used to provide approximations of invariant measures for stochastically forced dynamical systems.30 In Ref. 38, an SDE learning problem was studied using (7) as the modeling equation with different data assumptions."
        },
        {
            "heading": "C. Delay coordinates and Takens\u2019 theorem",
            "text": "The technique of time-delay embedding is a popular approach for reconstructing chaotic dynamical systems from limited observations.17,39\u201341 The procedure involves embedding time-series measurements \u03c8(t) = \u03c8(x(t)) of the state x(t) into d-dimensional Euclidean space by considering the vector of time-lagged observations,\n9d,\u03c4 (t) = (\u03c8(t),\u03c8(t \u2212 \u03c4), . . . ,\u03c8(t \u2212 (d \u2212 1)\u03c4 )),\nfor some \u03c4 > 0. Takens\u2019 theorem23 provides suitable assumptions under which9d,\u03c4 (t) and x(t) are related via diffeomorphism, implying that the time-lagged vector of partial observations 9d,\u03c4 (t) is sufficient for reconstructing the full state x(t). Notably, the embedding dimension provided in Ref. 23 is d = 2m + 1, where m is the dimension of a compact manifold M on which the flow map ft for the original dynamics is defined. In cases when trajectories are attracted to a compact subset A with a box-counting dimension (see Ref. 42, p. 586) dA strictly less than m, it turns out that lower-dimensional embeddings can be obtained.\nWhen a time-series projection \u03c8(t) of an unknown system x\u0307 = v(x) is observed, one can try to numerically determine a suitable embedding dimension d and time delay \u03c4 ; see, for example, Refs. 43\u201346. Choosing a proper embedding dimension and time delay is important for obtaining a reliable surrogate model of the original dynamics in time-delayed coordinates. Notably, in Sec. V B, we demonstrate that models for the velocity in time-delayed coordinates can incur excess uncertainties when the embedding dimension is not sufficiently large.\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-4\nPublished by AIP Publishing\n10 January 2024 13:03:41"
        },
        {
            "heading": "D. Prior work on learning dynamics from invariant measures",
            "text": "For chaotic systems, trajectories are sensitive to initial conditions and estimation parameters. Sometimes, the approximate reference velocity field {v\u0302(x(ti))} cannot be accurately estimated from a trajectory {x(ti)} due to the lack of observational data, slow sampling, discontinuous or inconsistent time trajectories, and noisy measurements. To tackle such difficulties, instead of working with the Lagrangian trajectories, Refs. 17 and 18 propose an Eulerian approach by treating the occupation measure (4) as the data. When enough samples are available, the occupation measure can be treated as an approximation to the invariant measure; see Sec. II A. Finding the optimal parameter \u03b8 is then translated into the optimization problem (2). The reference measure \u03c1\u2217 is the occupation measure converted from the observed trajectories {x\u0302(ti)}; see (4). In Ref. 17, the approximated synthetic \u03c1\u03b5(v(\u03b8)) is generated by first simulating the synthetic trajectories {x(ti; \u03b8)} based on the dynamical system and then computing its histogram following (4). Since this approach requires lengthy trajectory simulation, each evaluation of \u03c1\u03b5(v(\u03b8)) for a given \u03b8 is relatively costly. Moreover, it is difficult to compute the derivative of \u03c1\u03b5(v(\u03b8))with respect to \u03b8 due to the histogram approximation of nonlinear trajectories. As an improvement to the original idea in Ref. 17, Ref. 18 proposes a surrogate model to approximate \u03c1\u03b5(v(\u03b8)) that is differentiable in \u03b8 and sometimes faster to compute. The key idea is to solve for \u03c1\u03b5(v(\u03b8)) as the distributional steady-state solution to the continuity equation [i.e., (9) with D = 0] using a finite-volume upwind scheme together with the teleportation regularization. The gradient of the objective function J in (2) with respect to the parameter \u03b8 can be efficiently computed based on the adjoint-state method (see Sec. 5 in Ref. 18). The problem of learning an SDE from an invariant measure is also studied in Ref. 47, which uses a deep learning framework to invert the drift and diffusion terms.\nThe task of learning a dynamical system from an invariant measure has also been studied in the discrete-time setting under the inverse Frobenius\u2013Perron problem.25,48\u201350 The Frobenius\u2013Perron operator, also known as the transfer operator, characterizes the time evolution of an initial measure \u00b50 according to some prespecified dynamical system. Given a probability measure\u00b5, the inverse Frobenius\u2013Perron problem seeks to construct a dynamical system for which\u00b5 is a fixed point of the associated transfer operator. The most widely studied case involves recovering an ergodic map T on [0, 1] for which a prescribed absolutely continuous measure is the unique fixed point of the discrete transfer operator. In this particular setting, various approaches, such as topological conjugation51 and matrix methods,52 have been introduced to solve the inverse problem. The multivariate inverse Frobenius\u2013Perron problem was also studied in Ref. 53, where ergodic maps were constructed to adhere to the statistics of two-dimensional densities. Moreover, due to inherent non-uniqueness in the inverse problem, recent approaches further restrict the solution space of the discrete ergodic maps to those with a prescribed power spectrum.54 To the best of our knowledge, Refs. 17, 18, and 47, and our contributions here are the first works that numerically solve the inverse Frobenius\u2013Perron problem in the continuous-time setting. Notably, we do not assume that \u00b5 is absolutely continuous, as we use a finite-volume discretization to approximate the Frobenius\u2013Perron operator."
        },
        {
            "heading": "III. THE FORWARD MODEL AND MODELING ERRORS",
            "text": "A central contribution of this work is to consider a different regularized forward model than the one in Ref. 18, especially for trajectory measurements containing intrinsic noise, which can be interpreted as sample paths of stochastic dynamical systems (6). In those cases, the Fokker\u2013Planck equation (7) is a better candidate as the PDE surrogate model, as it contains a diffusion term that can fit noise present in the data. Based on the relationship between (6) and (7), one can learn both the velocity field v(x) and the diffusion tensor 6(x) in the optimization framework (2). For simplicity, we only consider a fixed diffusion constant and leave the investigation of multi-parameter inversion to future work.\nWe will use (9) as the forward model to fit invariant measures generated by trajectories with intrinsic noise. While the diffusion term allows the model to fit the intrinsic noise and prevent over-fitting the noise into the target velocity component, it also controls the scaling of the reconstructed velocity v(x; \u03b8). Indeed, when D = 0 and v\u0303(x) = a v(x), we have \u2207 \u00b7 (\u03c1(x)v\u0303(x)) = 0 as long as \u2207 \u00b7 (\u03c1(x)v(x)) = 0 for any a > 0. However, for most cases, v\u0303 and v will not solve the stationary Fokker\u2013Planck equation (9) for D > 0."
        },
        {
            "heading": "A. Finite-volume discretization",
            "text": "We assume that our system evolves on the d-dimensional rectangular state space,\n= [a1, b1] \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 [ad, bd] \u2282 Rd,\nwith a spatially dependent velocity v : \u2192 Rd. We define ni \u2208 Z+, 1 \u2264 i \u2264 d, to be the number of equally spaced points along the ith spatial dimension at which we wish to approximate the solution of (8), as well as the mesh spacing\n1xi := bi \u2212 ai ni \u2212 1 .\nWe are, thus, interested in obtaining a solution to the forward problem at points of the form\nxk1 ,...,kd := (a1 + k11x1, . . . , ad + kd1xd),\nwhere ki \u2208 {1, . . . , ni}. We will index our coordinates using columnmajor order and write xk1 ,...,kd = xj where\nj = k1 + d\u2211\ni=2 (ki \u2212 1)Si, Si :=\ni\u22121\u220f j=1 nj. (10)\nWe will regard xj as the center of the cell Cj where\nCj = d\u220f\ni=1\n[ ai + ( ki \u2212 1\n2\n) 1xi, ai + ( ki + 1\n2\n) 1xi ) .\nFollowing the approach in Ref. 19, we implement a first-order upwind finite-volume discretization of the continuity equation, adding a diffusion term using the central difference scheme and enforcing a zero-flux boundary condition.55 This allows us to obtain an explicit time evolution of the probability vector \u03c1 = [ \u03c11 \u03c12 . . . \u03c1N ]> \u2208 RN, where N = \u220fdi=1 ni. While \u03c1 is\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-5\nPublished by AIP Publishing\n10 January 2024 13:03:41\na discrete probability measure over the cells Cj, it also corresponds to a piecewise-constant probability density function on .\nWith an abuse of notation, we will refer to both the piecewiseconstant density and the discrete probability measure as \u03c1. We discretize the time domain with a step size 1t. Based on (8), the\nprobability vector at the lth time step evolves as\n\u03c1(l+1) = \u03c1(l) + K\u03c1(l), K = d\u2211\ni=1\n1t 1x Ki,\nwhere each Ki is a tridiagonal matrix of the form\nKi :=\n. . .\n\u2212vi,\u2212j\u22121 + D\n1xi . . . ...\nvi,\u2212j\u22121 \u2212 wi,+j\u22121 \u2212 2D 1xi \u2212vi,\u2212j + D\n1xi . . . ... ...\nwi,+j\u22121 + D 1xi vi,\u2212j \u2212 wi,+j \u2212 2D 1xi \u2212vi,\u2212j+1 + D\n1xi ... ... . . .\nwi,+j + D 1xi vi,\u2212j+1 \u2212 wi,+j+1 \u2212 2 D\n1xi ... . . .\nwi,+j+1 + D\n1xi . . .\n \n  Si \u2208 RN\u00d7N.\nAbove, we have defined for each j \u2208 {1, . . . , N} the upwind velocities\nvi,\u2212j := min { 0, vij } , vi,+j := max { 0, vij } , wi,\u2212j := min { 0, wij } , wi,+j := max { 0, wij } ,\nwhere vij := v ( xj \u2212 ei1xi/2 ) \u00b7 ei and wij := v ( xj + ei1xi/2 ) \u00b7 ei denote the ith components of the velocity field at the center of cell faces, and {ei} is the standard basis in Rd. We remark that if xj is away from \u2202 , then wi,\u00b1j = vi,\u00b1j+1. To enforce the zero-flux boundary condition, we set both the velocity v and diffusion D to be zero on \u2202 . As a result, the columns of K each sum to zero, and the total probability\n\u03c1(l) \u00b7 1 = 1, 1 := [ 1 . . . 1 ]> \u2208 RN\nis conserved under time evolution. Since numerical artifacts cause the flux accumulation along the boundary, we also enforce \u03c1 = 0 on \u2202 . When the boundary \u2202 is sufficiently far from the trajectory data, this artifact is insignificant. Hereafter, we assume the uniform spatial discretization1xi = 1x for all i = 1, . . . , d. Here, we used an explicit time stepping scheme. The Courant\u2013Friedrichs\u2013Lewy (CFL) stability condition enforces 1t = O(1x2) to ensure the stability of\nthe scheme. To be more specific, we choose\n1t < 1\n2d\n1x2\nD +1x\u2016v\u2016\u221e ,\nwhere \u2016v\u2016\u221e = maxi \u2016v(x) \u00b7 ei\u2016\u221e. In this way, we can enforce that all entries of I + K are non-negative with columns summed to one, which implies that I + K is a Markov matrix.\nFor a complete description of the finite-volume scheme, we refer to Ref. 55. We remark that there are many higher-order structure-preserving schemes to solve (8), which also yield a Markov matrix; see Ref. 56 for example. A more accurate numerical scheme can further reduce the forward modeling error, which is left for future work."
        },
        {
            "heading": "B. Teleportation and diffusion regularization",
            "text": "We use the finite-volume discretization of the Fokker\u2013Planck equation in Sec. III A to approximate its steady-state solution. After discretization, finding such stationary distributions to (9) is equivalent to solving the linear system,\n(I + K)\u03c1 = \u03c1.\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-6\nPublished by AIP Publishing\n10 January 2024 13:03:41\nSince the columns of K sum to zero, we have that M := I + K is a column-stochastic Markov matrix. When D 6= 0, M is a transition matrix for an ergodic Markov chain, which has a unique equilibrium. When D = 0, to guarantee the uniqueness of the equilibrium, Ref. 18 applies the so-called teleportation regularization57 and considers\nM\u03b5 := (1 \u2212 \u03b5)M + \u03b5U, U = N\u2212111> \u2208 RN\u00d7N. There is now a unique solution to the linear system\nM\u03b5\u03c1 = \u03c1, \u03c1 \u00b7 1 = 1, \u03c1 > 0. (11) From a computational aspect, it is useful to take advantage of the fact that M \u2212 I is sparse where I \u2208 RN\u00d7N is the identity matrix and to instead solve\n(1 \u2212 \u03b5)(M \u2212 I)\u03c1 = \u2212N\u22121\u03b51, where we have simply rearranged terms in (11) and used the fact that \u03c1 \u00b7 1 = 1.\nSince U is also a column stochastic Markov matrix with the uniform probability of visiting any point of the mesh, using M\u03b5 amounts to stopping the dynamics based on M at a random time and restarting it from a uniformly randomly chosen initial point. The size of \u03b5 represents the restarting frequency\u2014the smaller \u03b5, the rarer we restart.18\nOn the other hand, adding the diffusion component D to the tridiagonal matrix K can be seen as another way of regularizing the noise-free Markov matrix by adding scaled Brownian motion after each discrete evolution of the deterministic dynamics. For deterministic dynamics with D = 0, the solution to (9) might not be unique if there is more than one attractor. The use of teleportation connects all attractors through the \u201crandom restart,\u201d and the solution \u03c1\u03b5 to the linear system (11) has support that connects all the disjoint attractors. Similarly, when D 6= 0, the Brownian motion connects all disjoint attractors of the deterministic dynamics, giving a unique steady-state solution. In this scenario, the use of teleportation for the diffusive case is simply a numerical treatment to improve the conditioning of matrix M rather than to guarantee the uniqueness of \u03c1.\nIt is worth noting that both the teleportation regularization and an incorrect diffusion coefficient could be sources of modeling error when we perform parameter identification. Although these regularizations enable faster evaluation of \u03c1\u03b5(v(\u03b8)) and better posedness of the forward problem, they may reduce the accuracy of the inverse problem solution."
        },
        {
            "heading": "C. Numerical diffusion",
            "text": "In Fig. 2, we illustrate \u03c1\u03b5 computed as the steady-state solution to the Fokker\u2013Planck equation in the top row and the approximation to physical invariant measures of the corresponding SDE in the bottom row. From Fig. 2, we see that on a coarse mesh, the first-order finite-volume scheme incurs significant numerical error, which gives a computed solution with an artificial diffusion effect and, thus, is often referred to as the numerical diffusion.19 The amount of numerical diffusion is reduced as the mesh is refined since it is incurred by the first-order scheme. In particular, it is expected to decay as O(maxi1xi) in the L \u221e norm as we refine the\nmesh.55 Besides the teleportation and the modeling diffusion D, the presence of numerical diffusion is another modeling error incurred from solving the forward problem."
        },
        {
            "heading": "IV. GRADIENT CALCULATION AND VELOCITY PARAMETERIZATION",
            "text": "Another main contribution of this paper is to reconstruct the velocity field v(x) using large-scale parameterizations v(x; \u03b8), which turns an infinite-dimensional problem of searching for v(x) in a function space to a finite-dimensional optimization problem of finding \u03b8 \u2208 2 \u2282 Rm. Here, we introduce parameterizations based on piecewise-constant, neural network, and global polynomial functions. We also investigate various data-fitting objective functions J that compare the mismatch between the observed and simulated invariant measures, \u03c1\u2217 and \u03c1\u03b5(v(\u03b8)). We compute the gradient of such functions with respect to the coefficients \u03b8 in the parameterized velocity model v(x; \u03b8) based on the adjoint-state method for the PDE-constrained part and the backpropagation technique24 for the neural network part. Thanks to these techniques, we can then efficiently evaluate the gradients of J with respect to \u03b8 and, thus, conveniently use gradient-based optimization algorithms to iteratively update \u03b8 , e.g., steepest descent, L-BFGS, conjugate gradient descent methods as well as stochastic methods such as Adam.58 For notational simplicity, we will write \u03c1(v(\u03b8)) = \u03c1\u03b5(v(\u03b8)) throughout this section."
        },
        {
            "heading": "A. Gradient calculation through the adjoint-state method",
            "text": "Recall the finite-volume scheme in Sec. III A for solving (9). The forward model yields a discrete measure \u03c1(v(\u03b8)) = \u03c1(\u03b8) = [\u03c11(\u03b8) . . . \u03c1j(\u03b8) . . . \u03c1N(\u03b8)]> over the cells {Cj}, which converges to the solution to (9) in the weak sense as we refine the discretization parameters. For the explicit form of \u03c1(v(\u03b8)), we refer to Eq. (5.1) in Ref. 18. Note that we have highlighted the dependence of our approximate steady-state distributional solution to the Fokker\u2013Planck equation (9) on the velocity v(x; \u03b8). Our goal is to solve the optimization problem (2),\ninf \u03b8\u22082\nJ (\u03c1(v(\u03b8)), \u03c1\u2217),\nby using gradient-based methods, where J is the cost function and \u03c1\u2217 represents our inference data. The adjoint-state method is an efficient technique by which we can evaluate the derivative \u2202\u03b8J , as the computation time is largely independent of the size of \u03b8 . One can derive the adjoint-state method for gradient computations by differentiating the discrete constraint,59 which in our case is the eigenvector problem,\ng(\u03c1(\u03b8), \u03b8) = M\u03b5(\u03b8)\u03c1(\u03b8)\u2212 \u03c1(\u03b8) = 0, where \u03c1(\u03b8) \u00b7 1 = 1. Specifically, we compute \u2202\u03b8J = \u03bb>\u2202\u03b8g where \u03bb solves (\u2202\u03c1g)\n>\u03bb = \u2212(\u2202\u03c1J )>. In our case, this linear system is the adjoint equation [see Ref. 18, Eq. (5.8)]\n(M>\u03b5 \u2212 I)\u03bb = \u2212 ( \u2202\u03c1J )> + ( \u2202\u03c1J )> \u03c1 1, (12)\nand the derivative\n\u2202\u03b8J = \u03bb> ( \u2202\u03b8M\u03b5 ) \u03c1. (13)\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-7\nPublished by AIP Publishing\n10 January 2024 13:03:41\nAs a result, we only need to compute the derivatives \u2202\u03c1J and \u2202\u03b8M\u03b5 to determine the gradient \u2207\u03b8J = (\u2202\u03b8J )>. The former depends on the choice of the objective function, while the latter is based on a specific parameterization of the velocity field v(x; \u03b8) determined by its hypothesis space."
        },
        {
            "heading": "1. The computation of \u2202\u03c1J",
            "text": "For the objective function J , we consider the quadratic Wasserstein distance, the squared L2 norm, the Kullback\u2013Leibler (KL) divergence, and the Jensen\u2013Shannon (JS) divergence.\na. Quadratic Wasserstein distance. For probability measures \u03c1 and \u03c1\u2217 on , with finite second-order moments, the squared quadratic Wasserstein distance is defined by\nW22(\u03c1, \u03c1 \u2217) := inf\nT\u03c1,\u03c1\u2217 \u2208T\n\u222b\n|x \u2212 T\u03c1,\u03c1\u2217(x)|2d\u03c1(x),\nwhere\nT := {T : \u2192 : \u03c1(T\u22121(B)) = \u03c1\u2217(B), B \u2208 B} is the set of maps that push \u03c1 forward into \u03c1\u2217.60 With an abuse of notation, we also use \u03c1(x) and \u03c1\u2217(x) to denote the densities of \u03c1 and \u03c1\u2217, respectively. For efficient computation of the W2 distance, we utilize the back-and-forth method,61 which instead uses the dual Kantorovich formulation,60\nW22(\u03c1, \u03c1 \u2217) = sup\n\u03c61 ,\u03c62\n(\u222b\n\u03c61(x)\u03c1 \u2217(x)dx +\n\u222b\n\u03c62(x)\u03c1(x)dx\n) ,\nwhere \u03c61 \u2208 L1\u03c1\u2217( ) and \u03c62 \u2208 L1\u03c1( ) are required to satisfy \u03c61(x)+ \u03c62(y) \u2264 |x \u2212 y|2. In this case, the Fr\u00e9chet derivative of J = W22(\u03c1, \u03c1\u2217) with respect to \u03c1 is given by\n\u2202J \u2202\u03c1 = \u03c62.\nb. Squared L2 norm. The squared L2 distance as the objective function and its Fr\u00e9chet derivative are given by\nJ = 1 2\n\u222b\n|\u03c1(x)\u2212 \u03c1\u2217(x)|2dx,\n\u2202J \u2202\u03c1 = \u03c1 \u2212 \u03c1\u2217.\nc. KL divergence. The KL divergence and its Fr\u00e9chet derivative are given by\nJ = DKL(\u03c1, \u03c1\u2217) := \u222b \u03c1\u2217(x) log ( \u03c1\u2217(x)\n\u03c1(x)\n) dx,\n\u2202DKL \u2202\u03c1 = \u2212\u03c1\n\u2217(x)\n\u03c1(x) .\nWe remark that our definition of the KL divergence differs from many applications in which it is commonly computed as J = DKL(\u03c1\u2217, \u03c1).\nFIG. 2. As the mesh size of the forward model discretization is refined, we visually observe the convergence of the computed steady-state solution (a) to the approximate physical measure (b). The Van der Pol oscillator (19) with c = 1 and D = 0.001 is used in this example, and the histograms indicate mass per cell. (a) The computed\nsteady-state solution to (9) for decreasing values of 1x. (b) The approximate physical measure obtained by binning a time trajectory based on the SDE (6) for decreasing values of1x.\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-8\nPublished by AIP Publishing\n10 January 2024 13:03:41\nd. JS divergence. Defining \u03c1 \u2032 := (\u03c1 + \u03c1\u2217)/2, the JS divergence and its Fr\u00e9chet derivative are given by\nJ = DJS(\u03c1, \u03c1\u2217) = 1\n2 DKL(\u03c1, \u03c1 \u2032)+ 1 2 DKL(\u03c1 \u2217, \u03c1 \u2032),\n\u2202DJS \u2202\u03c1 = 1 2 log\n( 2\u03c1 \u03c1 + \u03c1\u2217 ) .\nBased on definitions of the KL and JS divergence, it is clear that we may encounter numerical instability issues if either \u03c1 or \u03c1\u2217 is not supported on the entire domain . Thus, we remark that for the computation of both the KL and JS divergences, we restrict the domain to regions where both \u03c1 and \u03c1\u2217 are strictly positive. This is equivalent to the definition of the KL and JS divergence based upon the so-called Csiszar divergence [see Ref. 62, Eq. (1)]."
        },
        {
            "heading": "2. The computation of \u2202\u03b8J",
            "text": "We have presented a few cases of \u2202\u03c1J for different choices\nof J . Next, we show how to obtain \u2202\u03b8M\u03b5 , which is the other necessary component in the adjoint-state method for gradient calculation; see (12) and (13). To begin with, we consider \u03b8 = {vij} for all i = 1, . . . , d and j = 1, . . . , N, which corresponds to one variant of piecewise-constant velocity parameterization.\nSince we are only interested in computing the gradient away from \u2202 , we can utilize the property that wi,\u00b1j = vi,\u00b1j+1. First, observe that\n\u2202M\u03b5\n\u2202vij = (1 \u2212 \u03b5)\nd\u2211\n`=1\n1t\n1x\n\u2202K` \u2202vij = (1 \u2212 \u03b5) 1t 1x \u2202Ki \u2202vij ,\nas well as\n\u2202Ki \u2202vij =\n. . . 0\n. . . ...\n\u2212H(vij) \u2212(1 \u2212 H(vij)) . . . ... ...\nH(vij) (1 \u2212 H(vij)) 0 ... ... . . .\n0 0\n... . . . 0\n. . .\n \n  Si\nH(x) :=    1, x > 0\n0, x \u2264 0 . (14)\nIn (14), H(\u00b7) is the Heaviside function. We remark that \u2202vij Ki can only be nonzero in the (j, j), (j, j \u2212 Si), (j \u2212 Si, j), and (j \u2212 Si, j \u2212 Si)th entries where Si is defined in (10). After solving (12) for \u03bb and applying (13), we deduce that\n\u2202J \u2202vij = \u03bb \u00b7 \u2202M\u03b5 \u2202vij \u03c1 = (1 \u2212 \u03b5) 1t 1x\n( \u03bb \u00b7 \u2202Ki\n\u2202vij \u03c1\n)\n= (1 \u2212 \u03b5) 1t 1x\n( H(vij)\u03c1j\u2212Si\u03bbj + (1 \u2212 H(vij))\u03c1j\u03bbj\n\u2212 H(vij)\u03c1j\u2212Si\u03bbj\u2212Si \u2212 (1 \u2212 H(vij))\u03c1j\u03bbj\u2212Si )\n= (1 \u2212 \u03b5) 1t 1x\n( \u03bbj \u2212 \u03bbj\u2212Si ) ( H(vij)\u03c1j\u2212Si + (1 \u2212 H(vij))\u03c1j ) .\n(15)\nEquation (15) provides an efficient way for computing the gradient of the objective function with respect to the piecewise-constant velocity based on cells {Cj} from our finite-volume discretization.\nAlternatively, if the velocity v = v(x; \u03b8) is smoothly parameterized by the vector \u03b8 = [\u03b81, . . . , \u03b8k, . . . , \u03b8m]> \u2208 Rm, for each \u03b8k, we can then evaluate\n\u2202J \u2202\u03b8k =\nN\u2211\nj=1\nd\u2211\ni=1\n\u2202J \u2202vij\n\u2202vij \u2202\u03b8k (16)\n\u2202vij \u2202\u03b8k = ei \u00b7 \u2202v \u2202\u03b8k \u2223\u2223\u2223\u2223 (xj\u2212ei1xi/2;\u03b8)\nto determine the derivative \u2202\u03b8J . By using a similar indexing convention to Sec. III A, we can collect the terms \u2202vij J and \u2202\u03b8kv i j into the vectors \u2202vJ and \u2202\u03b8kv, respectively. Therefore, the double summation in (16) is achieved by the inner-product \u2202vJ \u00b7 \u2202\u03b8kv. Note that\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-9\nPublished by AIP Publishing\n10 January 2024 13:03:41\nfor different \u03b8k, we only need to change \u2202\u03b8kv as \u2202vJ does not depend on \u03b8k.\nB. Velocity parameterization\nWe now apply Eqs. (15) and (16) to evaluate the gradients of several parameterized velocity models. Specifically, we consider piecewise constant, global polynomial, and neural network parameterizations of the velocity."
        },
        {
            "heading": "1. Piecewise-constant parameterization",
            "text": "In the case of the piecewise-constant parameterization, we model the velocity as\nv(x; \u03b8) = d\u2211\ni=1\nN\u2211\ni=j vij \u03c7Cj(x) ei, \u03b8 = {vij}. (17)\nHere, we again use the column-major ordering from Sec. III A to accumulate vectors of cells Cj with centers xj and velocity components\nvij = v(xj \u2212 ei1xi/2) \u00b7 ei\nalong the ith direction of the cell face located at xj \u2212 ei1x/2. The parameter space of the model presented in (17) is given by {vij}, which has size N \u00b7 d, and the gradient of the parameters {vij} can be directly evaluated by (15).\nWe remark that (17) is only one variant of piecewise-constant parameterization since the parameterization mesh is the same as the discretization mesh in the finite-volume method; see Sec. III A. These two meshes do not have to be coupled together. To reduce the numerical error from the first-order scheme, it is preferable to reduce the spacing {1xi}, but we can keep the parameterization mesh fixed so that the size of the optimization problem does not change. In this case, we need to apply the chain rule (16) to obtain the final gradient after evaluating (15).\nThe model defined by (17) can be learned by gradient-based optimization methods. The regularity of the piecewise-constant model defined by (17) can be improved to a C0 function by interpolating between the values vij using either piecewise linear or higher-order piecewise polynomial functions, as in Ref. 63."
        },
        {
            "heading": "2. Global polynomial parameterization",
            "text": "Though the regularity of the piecewise-constant model given by (17) can be improved by interpolation, the inverted velocity v(x; \u03b8) may still be highly oscillatory if the mesh size1x is small. Modeling approaches, such as SINDy,7 learn the velocity fields of dynamical systems from a polynomial basis together with sparse regression. Here, we show how the gradient derivation in (16) can be adapted to such polynomial basis parameterizations of the velocity field:\nv(x; \u03b8) = [v1(x; \u03b8), . . . , vd(x; \u03b8)]> = d\u2211\ni=1 vi(x; \u03b8) ei.\nThe ith component of the velocity field vi(x; \u03b8) parameterized by a linear combination of the monomial basis of degree at most K can\nbe written as\nvi(x; \u03b8) = M\u2211\n`=1 ai`(x\n>e1) 1ki ` . . . (x>ed) dki ` ,\nM = (\nd + K K\n) , (18)\nwhere the powers are represented by multi-indices\nki` = (1ki`, . . . , dki`), with 1 \u2264 ` \u2264 M, |ki`| \u2264 K, and \u03b8 = {ai`}. The size of \u03b8 in this case is d \u00b7 M. To learn the model parameterized by (18), we can use (16) to compute the gradient \u2202J /\u2202ai`. Without loss of generality, we assume 1xi = 1x for all 1 \u2264 i \u2264 d. The only term in (16) that explicitly depends on the velocity parameterization is\n\u2202vij \u2202ai` = ( (xj \u2212 ei1x/2)>e1 )1ki ` . . . ( (xj \u2212 ei1x/2)>ed )dki ` ,\nwhere i, j, ai` and the multi-index k i ` are fixed. Note that \u2202ai ` vi\n\u2032 j\n= 0 if i\u2032 6= i. Thus, we can again use gradient-based methods to infer proper polynomial coefficients {ai`}.\nAlthough a global polynomial parameterization guarantees ideal C\u221e regularity of the parameterized velocity v(x; \u03b8), the Runge phenomenon could be a potential downside of this approach. Specifically, as we increase the maximum degree K of the polynomial basis, we may encounter substantial interpolation errors near the boundary \u2202 ."
        },
        {
            "heading": "3. Neural network parameterization",
            "text": "Motivated by the universal approximation theory of neural networks,64 we may also choose to model each component of the velocity vi(x; \u03b8) as a feed-forward neural network, where the tunable parameters \u03b8 make up the network\u2019s weights and biases. We follow Ref. 65 to combine the adjoint-state method for the PDE constraints and the backpropagation technique to update the weights and biases of the neural network.\nThe term \u2202vij J in the gradient calculation (16) can be computed by first evaluating the neural network on the mesh of cell face centers oriented in the direction of ei to obtain {vij}, which is then plugged into (15) to obtain \u2202vij J . The remaining term \u2202\u03b8v in (16) is then computed via the backpropagation technique.24\nFor simplicity, we restrict ourselves to single-layer feedforward networks. Moreover, by using a smooth activation function, such as the hyperbolic tangent or the sigmoid function, we can guarantee C\u221e regularity of the reconstructed velocity v(x; \u03b8) on the domain . To enforce the zero-flux boundary condition, we manually set v = 0 on \u2202 . Consequently, the neural network parameterization may lack regularity near \u2202 . However, if the domain is sufficiently large, the support of the physical measure will be very far from \u2202 , in which case, we will not observe any discontinuities originating from the boundary condition while simulating the trajectories based on (6). As we increase the number of nodes in the hidden layer of the neural network, both the approximation power and the potential difficulty of training the neural network are expected to increase.\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-10\nPublished by AIP Publishing\n10 January 2024 13:03:41"
        },
        {
            "heading": "V. NUMERICAL RESULTS",
            "text": "In this section, we present several numerical examples to demonstrate the utility of the proposed approach for learning dynamical systems from invariant measures with intrinsic noise. [We include a publicly available code (https://github.com/ jrbotvinick/Learning-Dynamics-on-Invariant-Measures), which contains an example demonstrating the velocity inversion for the Van der Pol oscillator (19) based on a global polynomial parameterization. It can also be used to reproduce the comparison in Fig. 1 and Table II.] In Sec. V A, we study the inverse problem for the Van der Pol oscillator with piecewise constant, global polynomial, and neural network parameterizations of the velocity. In Sec. V B, we time-delay embed a signal sampled from a Hall-effect thruster and proceed to model the dynamics in delay-coordinates based upon the time-delayed invariant measure. We then illustrate that a lowdimensional embedding may increase the uncertainty of the learned model and that the choice of parameterization largely affects the regularity of the reconstructed velocity. In Sec. V C, we study rolling averages of a temperature data set and perform uncertainty quantification using the learned Fokker\u2013Planck PDE in time-delayed coordinates. We conclude in Sec. V D by inverting a component of the Lorenz-63 system\u2019s velocity using a neural network parameterization. All experiments are conducted using an Intel i7-1165G7 CPU.\nA. Van der Pol oscillator\nWe begin by considering the autonomous Van der Pol oscillator,66 given by\n{ x\u0307 = y, y\u0307 = c(1 \u2212 x2)y \u2212 x. (19)\nOur results for learning a dynamical system with prescribed statistical properties given by the stochastically forced Van der Pol oscillator are shown in Fig. 3. In the top row, the first panel features the velocity of (19) for the choice of c = 0.5, the second panel shows the approximate occupation measure [see (4)] obtained from the simulation of a single SDE trajectory [see (6)], the third panel shows the SDE trajectory used to approximate the invariant measure, and the fourth panel shows the dynamics of the oscillator without stochastic forcing. Throughout, we color the SDE trajectories by their histogrammed density to illustrate the connection between the Lagrangian and Eulerian perspectives. We also stress that the experiment in Fig. 3 assumes the diffusion coefficient to be known a priori, but that Sec. V B relaxes this assumption.\nIn the following rows of Fig. 3, we use neural network, piecewise constant, and global polynomial parameterizations of the velocity to solve the inverse problem using the optimization framework from Secs. III A and IV. For the case of the neural network parameterization, we compare each objective function studied in Sec. IV A 1, while we only focus on the L2 objective for the remaining two parameterizations. Across all tests, the reconstructed velocity is shown to vary significantly from the true velocity shown in the first row of Fig. 3. This is mainly due to the lack of data away from the main attracting limit cycle. In regions of the state space with no available data, we can only expect that the modeled velocity v(x; \u03b8)\nwill direct trajectories toward the attracting limit cycle on which the invariant measure is supported. Indeed, this is what we observe.\nMoreover, while the learned PDE model (9) matches the observed occupation measure (4) across all tests, we find that the SDE and ODE trajectories generated using the learned velocity vector fields may vary depending on the parameterization. Table I provides a comparison of the accuracy of the learned models, as well as the required computation times. While the piecewise constant velocity is by construction discontinuous and, thus, does not naturally guarantee the existence and uniqueness of the corresponding ODE solution, the neural network parameterization based on the hyperbolic tangent activation function yields a C\u221e velocity. Moreover, while the global polynomial parameterization is also C\u221e, it may suffer from the Runge phenomena and grow rapidly near the boundary of the domain. Thus, we mainly consider neural network parameterizations of the velocity for the remainder of the numerical tests.\nTo reduce the computational cost of the inversion in the final row of Fig. 3, we compute J = W22 on a coarsened mesh. Among the four objective functions in Fig. 3, it is worth noting that the W2 metric does not compare the two densities pointwisely and is welldefined for comparing singular measures. The distance reflects both the local intensity differences and the global geometry mismatches.67 It has also been shown that the Wasserstein metric is robust to noise.68,69 Thanks to the geometric nature of the optimal transportation problem, the Wasserstein metric is primarily sensitive to global changes, such as translation and dilation, and is robust to small local perturbations, such as noisy measurements of \u03c1\u2217. The better stability also brings a downside as the optimization landscape can be relatively flat around the ground truth, which may lead to compromised accuracy in the velocity inversion.\nThe different velocities shown in the second column of Fig. 3 reveal that there is nonuniqueness if we only use the invariant measure as the reference data. The current modeling assumption yields dynamics reproducing the same invariant measure but does not necessarily recover the same velocity field. Depending on the concrete application, one can add regularization, time information, or focus on velocities in a particular parameterized subspace to avoid nonuniqueness. The large error for the reconstructed velocity near the origin is due to the fact that the method aims to learn the flow on or (in the case of stochastically forced dynamics) near the invariant measure. It is, therefore, unsurprising that the learned velocity does not match the ground truth where there are no data.\nIn Fig. 4, we show how the inversion accuracy and computation time depend on the chosen value of 1x; that is, as 1x decreases, we can learn velocities that can reproduce the statistics of the observed occupation measure more accurately, with the cost of longer computation time.\nNext, we provide experimental details on the comparison of our approach with SINDy7 and the neural ODE4 frameworks in Fig. 1. This test uses the Van der Pol oscillator with c = 2. Since the SINDy and neural ODE methods are designed for modeling ODEs, the experiments in Fig. 1 use the diffusion coefficient D = 0. While we only plot the first eight points of the slowly sampled trajectory in Fig. 1, the full trajectory used for inference contains 2.5 \u00d7 103 observations. The quickly sampled trajectory also consists of 2.5 \u00d7 103 observations. The three approaches considered for comparison have\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-11\nPublished by AIP Publishing\n10 January 2024 13:03:41\nFIG. 3. Learning velocity fields to reproduce the statistics of the stochastically forced Van der Pol oscillator. The ground truth occupation measure, velocity, and dynamics are shown in (a). The results for inverting the velocity based on the occupationmeasure from (a) using piecewise constant, global polynomial, and neural network parameterizations are shown in (b)\u2013(g). The first column shows the objective function, the second column shows the learned velocity vector field, the third column shows the final PDE forward model evaluation based on the learned velocity, the fourth column shows the simulation of a diffuse trajectory, and the final column shows the simulation of a trajectory without diffusion. Specifically, the \u201cdiffuse trajectories\u201d are simulated according to the Euler\u2013Maruyama method using the assumed diffusion coefficient D = 0.02, while the \u201cnon-diffuse\u201d trajectories assume D = 0. The coloring of each diffuse trajectory is given by the occupation measure it generates; see (4). Across all tests, the objective\nfunction is minimized to 0.25%\u20130.35% of its initial value. For (b)\u2013(c), the L-BFGS-B algorithm is used for optimization. In (d)\u2013(g), the neural network architecture consists of a single hidden layer with the hyperbolic tangent activation function, trained by the Adam optimizer with a learning rate of 10\u22121. (a) Ground truth velocity, occupation measure, diffuse trajectory, and non-diffuse trajectory for the Van der Pol oscillator with c = 0.5 and D = 0.02. (b) Piecewise constant parameterization (see Sec. IV B 1) with the squared L2 objective function. (c) Degree five global polynomial parameterization (see Sec. IV B 2) with the squared L2 objective function. (d) Neural network parameterization (see Sec. IV B 3) with the squared L2 objective function. (e) Neural network parameterization with the KL divergence objective function. (f) Neural network parameterization with the JS divergence objective function. (g) Neural network parameterization with the squaredW2 objective function.\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-12\nPublished by AIP Publishing\n10 January 2024 13:03:41\nvarious hyperparameters, which can be tuned. For SINDy, we learn the models from the monomial basis up to degree three and use the sequentially thresholded least squares optimizer with a threshold of 0.025 to enforce a sparsity condition on the learned coefficients; see Ref. 7. For the neural ODE framework, the velocity is parameterized by a single-layer fully connected neural network with 100 nodes and a hyperbolic tangent activation function. The neural ODE is trained using a multiple shooting approach with the mean-squared error objective function. More specifically, rather than treating the simulation of a single long time trajectory as the forward model, we integrate N \u2212 1 trajectories initiated at the observed data points {x(ti)}N\u22121i=1 for a time of 1t = ti+1 \u2212 ti. This approach results in greater success while modeling slowly sampled dynamics. The Adam optimizer with a learning rate of 10\u22123 is used, and the tolerance for both relative and absolute errors of the ODE solver is set as 10\u22125.\nTo ensure a fair comparison with the neural ODE framework, we consider our approach based on a neural network parameterization of the velocity using the same architecture, optimizer, and learning rate. For our approach, we use the KL-divergence objective function (see Sec. IV A 1), apply additional Gaussian filtering to the occupation measure [see (4)] to simplify the resulting optimization, assume a diffusion coefficient of D = 10\u22123 during training, and set 1x = 0.1. Thus, the only differences between the setup for our approach and the neural ODE framework are the forward model and the objective function.\nAs shown in Fig. 1, all three frameworks can learn from the quickly sampled trajectory. However, SINDy and the neural ODE frameworks are less robust to changes in the sampling frequency of the inference data than our approach. This is further demonstrated in Table II, where we quantify the error in the simulated occupation measure based on the learned velocity. We report the average error over ten trials with different random training seeds to compare our method and the neural ODE framework. When the data are sampled at a sufficiently high frequency, Table II also shows that methods, such as SINDy or the neural ODE, are preferable in terms of both computational cost and accuracy."
        },
        {
            "heading": "B. Hall-effect thruster",
            "text": "We now turn to the more realistic setting of experimentally sampled time-series data. Specifically, we study the cathode-Pearson\nsignal sampled from a Hall-effect thruster (HET) in its breathing mode. Hall-effect thrusters are in-space propulsion devices that exhibit dynamics resembling stable limit cycles while in a breathing mode. For details about the experimental setup used to collect the data, the reader is encouraged to consult Refs. 70 and 71. In Sec. V B 1, we utilize Takens\u2019 theorem23 to reformulate the largescale optimization framework presented in Secs. III and IV to be compatible with scalar time-series observations, and in Sec. V B 2, we demonstrate numerical results based upon this reformulation."
        },
        {
            "heading": "1. Methods",
            "text": "Intrinsic physical fluctuations present in the cathode-Pearson signal indicate that the HET\u2019s dynamics may be modeled well by a Fokker\u2013Planck equation. Motivated by this insight, we first timedelay embed the cathode-Pearson signal C(t) in d-dimensions to form the trajectory Cd,\u03c4 (t) := (C(t), C(t \u2212 \u03c4) . . . , C(t \u2212 (d \u2212 1)\u03c4 )).\nTABLE II. Comparison with the SINDy and neural ODE frameworks for learning from trajectories sampled at different frequencies (Hz). The wall-clock computation time is reported, and the error is quantified by W 22 (\u03c1\u0302, \u03c1 \u2217), where \u03c1\u0302 is the simulated occupation measure from the learned velocity field and \u03c1\u2217 is the observed occupation measure.\nMethod Sampling freq. Wall-clock time (s) Error\nSINDy 10.00 2 \u00d7 10\u22122 5.6 \u00d7 10\u22123 Neural ODE 10.00 5 \u00d7 102 5.32 \u00d7 10\u22123 Ours 10.00 5 \u00d7 102 1.14 \u00d7 10\u22121 SINDy 0.25 10\u22122 3.52 Neural ODE 0.25 5 \u00d7 102 1.81 Ours 0.25 5 \u00d7 102 6.79 \u00d7 10\u22122\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-13\nPublished by AIP Publishing\n10 January 2024 13:03:41\nWe then use a histogram approximation to compute the occupation measure \u03c1\u2217 of Cd,\u03c4 (t); see (4). By viewing each dimension of the coordinate system on which the measure \u03c1\u2217 is supported as the independent variables C\u2212k\u03c4 (t) := C(t \u2212 k\u03c4) where 0 \u2264 k \u2264 d \u2212 1, we then seek a solution to the optimization problem (2) for a velocity v = v(Cd,\u03c4 ; \u03b8). Such a velocity can then provide us with a model of the asymptotic statistics of the embedded trajectory Cd,\u03c4 (t), provided that a suitable diffusion coefficient can be found.\nWe note that forming the time-delay coordinates Cd,\u03c4 (t) does require a knowledge of measurements at uniform increments in time. However, the available data may still be sampled slowly enough such that it is impractical to seek a direct approximation of the Lagrangian velocity through the standard approaches described in Sec. I. This perspective motivates our use of the approach developed in Secs. III and IV to learn dynamical systems from invariant measures in time-delay coordinates.\nThere are a few additional considerations that arise when adapting the modeling framework presented in Secs. III and IV to real-world data; namely, we do not know the proper diffusion coefficient a priori (as was the case in Sec. V A). Moreover, the invariant measure that the model is based on does not contain any information about the time scale at which the system evolves. Toward this, we utilize the following three-step procedure as a computationally efficient means to mitigate these difficulties.\n1. Bin the trajectory Cd,\u03c4 (t) onto a d-dimensional mesh with spacing 1x along each axis to form the occupation measure \u03c1\u2217, assume a constant diffusion coefficient D > 0, and learn the velocity v = v(Cd,\u03c4 ; \u03b8), using the framework from Secs. III and IV. 2. Bin the trajectory Cd,\u03c4 (t) onto another d-dimensional mesh with spacing 1x\u0302 \u2264 1x to create a new occupation measure \u03c1\u0302\u2217 and adjust the diffusion coefficient by solving the optimization\nproblem\nD\u0303 = arg min D\u0302\u2208R J (\u03c1\u03b5(v; D\u0302), \u03c1\u0302 \u2217), (20)\nwhere the term \u03c1\u03b5(v; D\u0302) in (20) denotes the forward model evaluation with the diffusion coefficient D\u0302. 3. Rescale both the velocity and diffusion by solving the optimization problem\na\u0303 = arg min a\u2208R\nN\u2211\ni=1\n\u2225\u2225\u2225C\u0302(ti; a)\u2212 Cd,\u03c4 (ti) \u2225\u2225\u2225 2\n2 , (21)\nwhere C\u0302(ti; a) denotes the time-ti solution of the ODE initial value problem with velocity av(\u00b7; \u03b8) and initial condition Cd,\u03c4 (t0). The final velocity and diffusion are then given by a\u0303v(\u00b7; \u03b8) and a\u0303D\u0303, respectively. The three-step approach makes repeated use of the fact that \u03c1\u03b5(v; D) = \u03c1\u03b5(av; aD) for any scalar multiple a > 0. Indeed, if the true diffusion coefficient D\u2217 > 0 is unknown a priori, but we instead seek a solution v(\u00b7, \u03b8) with a different diffusion D > 0, it is guaranteed that the velocity v = (D/D\u2217)v\u2217 will still provide a solution to the inverse problem. This observation motivates step one, in which an arbitrary diffusion coefficient is used to find a solution v(\u00b7; \u03b8) to the inverse problem. As the dimensionality d is increased, solving the large-scale optimization problem in step 1 on a fine mesh becomes infeasible. As such, step one is typically performed on a coarse mesh where additional Gaussian filtering is applied to the inference measure \u03c1\u2217 to make the large-scale optimization more feasible.\nThe diffusion coefficient is then adjusted in step two on a finer mesh via (20) to mitigate the errors due to the Gaussian filtering, numerical diffusion, and histogram errors incurred during step one (see Fig. 2). Finally, in step three, the scale of both the velocity and diffusion is adjusted via (21) such that the time evolution of simulated trajectories is consistent with the inference trajectory Cd,\u03c4 (t) in\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-14\nPublished by AIP Publishing\n10 January 2024 13:03:41\nFIG. 6. Comparing the model accuracy and uncertainty for the embedded cathode-Pearson signal with 2D and 3D time delays. The time evolution of the 2D and 3D models is compared to a collection {Cd,\u03c4 (ti)}ni=1 of samples (plotted in black) from the time-delayed cathode-Pearson signal. The plots (a) and (b) feature a qualitative comparison, whereas (c) shows a quantitative comparison of the uncertainties. Throughout, the time units are normalized to the inverse of a HET breathing mode frequency (16.6 kHz).\nBoth the 2D and 3D models utilized neural network velocity parameterization with 500 nodes in a single hidden layer and reduced the KL divergence objective function to 0.1% of its initial value during training. As in Fig. 5, the three-step procedure in Sec. V B 1 is used to learn the models, and in step one, additional Gaussian filtering is applied to the occupation measure \u03c1\u2217 to simplify the resulting optimization. The 3D visualization was plotted using Ref. 72. (a) Using the 2D model to predict the evolution of the samples C2,\u03c4 . (b) Using the 3D model to predict the evolution of the samples C3,\u03c4 . (c) Uncertainty comparison for the 2D and 3D model predictions.\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-15\nPublished by AIP Publishing\n10 January 2024 13:03:41\ndelay coordinates. Since diffusion plays a relatively small role over short time scales for the quasiperiodic HET data, we use the zerodiffusion trajectory to calibrate reasonable time scaling between our model and the available data. However, as the magnitude of the\ndiffusion increases, the least squares fit in (21) will become less reliable, and it may be preferable to instead minimize a transport cost between a collection of model samples and a collection of data samples at each time step. While this final optimization is similar in spirit to various Lagrangian approaches for learning dynamics (see\nSec. I), we remark that the parameter space in (21) has only one dimension."
        },
        {
            "heading": "2. Results",
            "text": "The results of the three-step procedure in Sec.V B 1 for learning the HET dynamics are shown in Fig. 5 for an embedding dimension of d = 3 and time-delay of \u03c4 = 1.4 \u00d7 10\u22125 sec or rather \u03c4 = .23 when normalizing the time scale to the HET breathing mode frequency (16.6 kHz). The modeled trajectory accurately reconstructs the shape of the embedded cathode-Pearson signal but cannot capture the variable diffusion present throughout the time-delayed signal. We do not expect to capture such details, as we assume a constant diffusion coefficient in our model. Nevertheless, we regard the reconstruction of the 3D globally\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-16\nPublished by AIP Publishing\n10 January 2024 13:03:41\nFIG. 8. Performing prediction and uncertainty quantification for Ithaca, NY\u2019s temperature in 2019. (a) The ground truth occupation measure accumulated from 13 years of weekly rolling averaged temperature observations, normalized by an affine transformation to [\u22121, 1]. (b) The learned velocity vector field. (c) The corresponding forward\nmodel output. In (d), the PDEmodel with a uniform initialization in the box from (c) is evolved in time and used to quantify the uncertainty in the measurements of C0. Observed trajectories of the temperature in delay coordinates with initial conditions displayed in the top left plot are also shown to demonstrate the effectiveness of the learned model. A time delay of \u03c4 = 280 days is used, and the model is trained using a neural network parameterization and the KL-divergence objective function.\nattracting limit cycle as a success and leave extending the model to account for the case of a non-constant diffusion tensor to future work.\nThe dimensionality of the original HET dynamics is unknown, and as such, a sufficient embedding dimension for the cathodePearson signal is unclear, though likely very high. Interestingly, we can compare the model learned in Fig. 5 with a 2D analog to demonstrate that when the number of time delays is not sufficiently large, there is more uncertainty in modeling the time-delayed dynamics. This phenomenon is most evident when inspecting regions of the delayed cathode-Pearson signal for which the 2D embedding lacks structure readily observed in 3D.\nSpecifically, consider a collection of nearby samples {C3,\u03c4 (ti)}ni=1 in the 3D time-delay coordinate system (C0, C\u2212\u03c4 , C\u22122\u03c4 ). The corresponding 2D samples {C2,\u03c4 (ti)}ni=1 will also be nearby one another in the 2D time-delay coordinate system (C0, C\u2212\u03c4 ). In Fig. 6, we initiate uniform distributions centered about these samples in both 2D and 3D time-delay coordinate systems. We then evolve both the samples and initial uniform distributions forward in time. The evolution of the ground truth samples is simply determined by the time-delayed cathode-Pearson signal Cd,\u03c4 (t), and the evolution of the uniform distributions is given by Fokker\u2013Planck\nmodels constructed from the time-delayed cathode-Pearson signal\u2019s invariant measure. As the modeled probability densities and ground truth samples evolve in time, we observe in Fig. 6 that the mean of the 3D model matches the true sample mean more closely than the 2D model and that it has less uncertainty.\nIn Fig. 7, we study the three parameterizations from Sec. IV B for learning the time-delayed cathode-Pearson signal\u2019s velocity, now with an embedding dimension of two to allow for clearer visualizations. It can be seen that the density associated with each velocity parameterization indeed matches the ground truth density in Fig. 7, but that the velocity fields differ significantly from one another. The piecewise-constant velocity in Fig. 7 suffers from poor regularity with discontinuities on the attracting limit cycle. As a result, we lose the connection between the Eulerian and Lagrangian dynamics and cannot reconstruct zero-diffusion trajectories that form a stable limit cycle. On the other hand, the velocities parameterized by the global polynomial and the neural network are both C\u221e. The differences among these three can clearly be seen via the zoomed-in velocity plots in the second row of Fig. 7. The global polynomial and neural network discretizations are both global parameterizations of the velocity, and as such, their values near the domain\u2019s boundary are dictated by the available data in the center of\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-17\nPublished by AIP Publishing\n10 January 2024 13:03:41\nFIG. 9. Neural network parameterization of x\u0307 using the Lorenz system\u2019s stochastically perturbed invariant measure with D = 10 and 1x = 2. For visualization of the\noccupation measure used to learn the model displayed in the top row, we refer to Ref. 18. (a) Learned velocity vector field (left), a simulated trajectory with diffusion (middle), and a simulated trajectory without diffusion (right). (b) True velocity (left), a ground truth SDE trajectory (middle), and a ground true ODE trajectory (right).\nthe domain. This causes the polynomial velocity to rapidly increase near the boundary, and a similar effect can also be seen for the neural network.\nIt is worth noting that the initial condition for the optimization in Fig. 7 can play a large role in the reconstructed velocity, which is related to the optimization landscape of the nonconvex optimization problem (2) we tackle. In the case of the piecewise-constant discretization, we initialize all velocities to be significantly less than the diffusion coefficient D = 0.1. Thus, diffusion initially dominates in the finite-volume solver, and all non-boundary cells will contain nonzero mass, which allows for accurate gradient updates everywhere. This phenomenon can also help neural network training, though it is not always necessary due to the global nature of parameterization. Moreover, we initialize our polynomial basis to form the velocity\n(x\u0307, y\u0307) = ( \u2212y + x(0.1 \u2212 x2 \u2212 y2), x + y(0.1 \u2212 x2 \u2212 y2) ) ,\nwhich describes a globally attracting limit cycle. To converge to the ground truth limit cycle of the time-delayed cathode-Pearson signal, this initial velocity only needs to be translated and deformed."
        },
        {
            "heading": "C. Temperature uncertainty quantification",
            "text": "We now study 2D time-delay embedded data of weekly rolling averages of the temperature in Ithaca, NY, between 2006 and 2020.73 We view temperature fluctuations over short time scales as an intrinsic diffusion process and the approximately periodic oscillation of seasonal temperatures driven by some nonzero velocity. Thus, we model the 2D data in delay coordinates as a diffuse limit cycle. We again follow the procedure in Sec. V B 1 to learn a velocity v(x; \u03b8) and diffusion coefficient D, which closely matches the occupation measure.\nAs in Sec. V B, we can use the trained model v(x; \u03b8) to quantify measurement uncertainties through the Fokker\u2013Planck equation (9), whose solution is a probability density in the timedelay coordinates (C0, C\u2212\u03c4 ). Specifically, if we know some initial probability distribution that captures the current state of the temperature system well, we can consider the time evolution of the distribution using our trained model to quantify the uncertainty of future temperature measurements. The process of evolving both the Fokker\u2013Planck PDE from a uniform distribution and the ground truth sample paths from past temperature measurements is shown in Fig. 8. The uncertainty bounds from the model accurately capture fluctuations in the training data used to form the occupation\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-18\nPublished by AIP Publishing\n10 January 2024 13:03:41\nFIG. 10. Neural network parameterization of x\u0307 using the arctan Lorenz system\u2019s stochastically perturbed invariant measure with D = 10 and1x = 2. The neural network used to learn the velocity contains a single layer of 100 nodes with the sigmoid activation function, and the L2 objective function is used to train the model. (a) Learned\nvelocity vector field (left), a simulated trajectory with diffusion (middle), and a simulated trajectory without diffusion (right). (b) True velocity (left), a ground truth SDE trajectory (middle), and a ground true ODE trajectory (right).\nmeasure (plotted in black), as well as a testing sample path previously unseen by the model (plotted in red).\nIt is also worth noting that the confidence intervals we construct may be larger than the actual range due to several factors, including additional extrinsic noise from filtering the data, modeling errors accumulated from the hypothesis space, numerical diffusion in the forward model, and a sub-optimal embedding dimension. Reducing such errors may result in tighter confidence intervals, and considering time delays in higher dimensions could yield better predictions of the temperature\u2019s transient behaviors."
        },
        {
            "heading": "D. Lorenz-63 system",
            "text": "We conclude this section by studying the Lorenz-63 system,21\ndefined by\n   x\u0307 = c1(y \u2212 x), y\u0307 = x(c2 \u2212 z)\u2212 y, z\u0307 = xy \u2212 c3z,\n(22)\nwhere we consider (c1, c2, c3) = (10, 28, 8/3). For these choices of parameters, the Lorenz-63 system exhibits chaotic behavior and admits a unique physical measure.22 In Fig. 9, we assume that the quantities y\u0307 and z\u0307 are known, and we learn a model for the velocity in the x-direction, using the stochastically forced Lorenz-63 system\u2019s occupation measure. We emphasize that the data used to approximate the Lorenz system\u2019s occupation measure can be sampled slowly or even randomly in time (see Fig. 7 in Ref. 18). From the approximate occupation measure, we are able to successfully invert the first component x\u0307 of the Lorenz-63 system\u2019s velocity via neural network parameterization.\nWe remark that when x\u0307, y\u0307, and z\u0307 are all simultaneously inverted, the optimization is unsuccessful at reconstructing the true velocity (22). While we may be able to learn a velocity that approximately recovers the stationary state of the Lorenz-63 system in the sense of (9), the physical property (3) does not hold. Whether the difficulties of inverting all velocity components of the Lorenz-63 system are due to inherent non-uniqueness in the inverse problem or simply inconvenient local minima during training is worth further investigation in future work. To demonstrate the applicability of our approach to non-rational velocities, we also consider the arctan Lorenz-63\nChaos 33, 063152 (2023); doi: 10.1063/5.0149673 33, 063152-19\nPublished by AIP Publishing\n10 January 2024 13:03:41\nsystem,18 given by\n   x\u0307 = 50 arctan(c1(y \u2212 x)/50), y\u0307 = 50 arctan(x(c2 \u2212 z)/50 \u2212 y/50), z\u0307 = 50 arctan(xy/50 \u2212 c3z/50),\n(23)\nwhere again, (c1, c2, c3) = (10, 28, 8/3). The results for inverting x\u0307 from the occupation measure generated by (23) with additional stochastic forcing are shown in Fig. 10, assuming that the quantities y\u0307 and z\u0307 are known."
        },
        {
            "heading": "VI. CONCLUSION",
            "text": "In this paper, we introduced a PDE-constrained optimization approach to modeling trajectory data originating from stochastic dynamical systems. We first adapted the invariant measure surrogate model in Ref. 18 based upon the continuity equation to the Fokker\u2013Planck equation. This increased our modeling capacity and prevented overfitting the reconstructed velocity while modeling intrinsically noisy trajectories. We next extended the threecoefficient learning performed in Ref. 18 to thousands of coefficients by modeling the velocity via global polynomials, piecewise polynomials, and fully connected neural networks. The efficient gradient computation presented in Sec. IV made these large-scale parameterizations of the velocity computationally tractable. We finally studied velocity inversion for invariant measures of time-delay embedded observables. The method of time-delay embedding is useful for analyzing real-world data, where in many cases, only limited observations of complex systems are available. As such, we proceeded to learn the velocity in time-delay coordinates for a Hall-effect thruster system and rolling weekly averages of temperature measurements. Using these models, we predicted future states of the systems and quantified uncertainty in forecasts by evolving the learned Fokker\u2013Planck equation forward in time."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "This paper was supported in part by a fellowship award under Contract No. FA9550-21-F-0003 through the National Defense Science and Engineering Graduate (NDSEG) Fellowship Program, sponsored by the Air Force Research Laboratory (AFRL), the Office of Naval Research (ONR) and the Army Research Office (ARO). R. Martin was partially supported by AFOSR Grants FA955020RQCOR098 (PO: Leve) and FA9550-20RQCOR100 (PO: Fahroo). This work was done in part while Y. Yang was visiting the Simons Institute for the Theory of Computing in Fall 2021. Y. Yang acknowledges support from Dr. Max R\u00f6ssler, the Walter Haefner Foundation, and the ETH Z\u00fcrich Foundation. This material is based upon work supported by the National Science Foundation under Award Number DMS-1913129.\nWe thank Dr. Chen Li for his helpful suggestions and generosity in sharing the code for the approach of Sec. IV B 3.\nWe would like to thank the referees for carefully reading our manuscript and giving many constructive comments that helped improve the paper.\nAUTHOR DECLARATIONS\nConflict of Interest\nThe authors have no conflicts to disclose.\nAuthor Contributions\nJonah Botvinick-Greenhouse: Formal analysis (lead); Software (lead); Writing \u2013 original draft (equal); Writing \u2013 review & editing (equal). Robert Martin: Conceptualization (equal); Writing \u2013 review & editing (equal). Yunan Yang: Conceptualization (equal); Formal analysis (supporting); Supervision (lead); Writing \u2013 original draft (equal); Writing \u2013 review & editing (equal).\nDATA AVAILABILITY\nThe data used in Secs. V A, V B, and V D are available from the corresponding author upon reasonable request. The data used in Sec. V B were obtained from the EPTEMPEST experimental program funded by the AFSOR grant FA9550-17QCOR497 (Program Officer: Dr. Brett Pokines). The data used in Sec. V C are openly available via Ref. 73."
        }
    ],
    "title": "Learning dynamics on invariant measures using PDE-constrained optimization",
    "year": 2024
}