{
    "abstractText": "We present a first-order method for solving constrained optimization problems. The method is derived from our previous work [28], a modified search direction method inspired by singular value decomposition. In this work, we simplify its computational framework to a \u201cgradient descent akin\u201d method (GDAM), i.e., the search direction is computed using a linear combination of the negative and normalized objective and constraint gradient. We give fundamental theoretical guarantees on the global convergence of the method. This work focuses on the algorithms and applications of GDAM. We present computational algorithms that adapt common strategies for the gradient descent method. We demonstrate the potential of the method using two engineering applications, shape optimization and sensor network localization. When practically implemented, GDAM is robust and very competitive in solving the considered large and challenging optimization problems.",
    "authors": [
        {
            "affiliations": [],
            "name": "Long Chena"
        },
        {
            "affiliations": [],
            "name": "Kai-Uwe Bletzingerb"
        },
        {
            "affiliations": [],
            "name": "Nicolas R. Gaugera"
        },
        {
            "affiliations": [],
            "name": "Yinyu Yec"
        }
    ],
    "id": "SP:51220a21af321502ee62b2559d80eb06d8298d80",
    "references": [
        {
            "authors": [
                "I.F. Akyildiz",
                "W. Su",
                "Y. Sankarasubramaniam",
                "E. Cayirci"
            ],
            "title": "Wireless sensor networks: a survey",
            "venue": "Computer networks 38 ",
            "year": 2002
        },
        {
            "authors": [
                "T.A. Albring",
                "M. Sagebaum",
                "N.R. Gauger"
            ],
            "title": "Efficient aerodynamic design using the discrete adjoint method in SU2, in 17th AIAA/ISSMO multidisciplinary analysis and optimization conference",
            "year": 2016
        },
        {
            "authors": [
                "M.M. Ali",
                "T.L. Oliphant"
            ],
            "title": "A trajectory-based method for constrained nonlinear optimization problems",
            "venue": "Journal of Optimization Theory and Applications 177 ",
            "year": 2018
        },
        {
            "authors": [
                "G. Allaire"
            ],
            "title": "Shape optimization by the homogenization method",
            "venue": "Vol. 146, Springer Science & Business Media",
            "year": 2012
        },
        {
            "authors": [
                "G. Allaire",
                "F. Jouve",
                "A.M. Toader"
            ],
            "title": "Structural optimization using sensitivity analysis and a level-set method",
            "venue": "Journal of computational physics 194 ",
            "year": 2004
        },
        {
            "authors": [
                "X. Allamigeon",
                "P. Benchimol",
                "S. Gaubert",
                "M. Joswig"
            ],
            "title": "Log-barrier interior point methods are not strongly polynomial",
            "venue": "SIAM Journal on Applied Algebra and Geometry 2 ",
            "year": 2018
        },
        {
            "authors": [
                "E.D. Andersen",
                "K.D. Andersen"
            ],
            "title": "The MOSEK interior point optimizer for linear programming: an implementation of the homogeneous algorithm",
            "venue": "High performance optimization, Springer",
            "year": 2000
        },
        {
            "authors": [
                "H. Antil",
                "R.H. Hoppe",
                "C. Linsenmann"
            ],
            "title": "Path-following primal-dual interior-point methods for shape optimization of stationary flow problems",
            "venue": "Journal of Numerical Mathematics 15 ",
            "year": 2007
        },
        {
            "authors": [
                "J.S. Arora"
            ],
            "title": "Introduction to optimum design",
            "venue": "3rd ed., Elsevier",
            "year": 2011
        },
        {
            "authors": [
                "S. Arora",
                "N. Cohen",
                "E. Hazan"
            ],
            "title": "On the optimization of deep networks: Implicit acceleration by overparameterization",
            "venue": "35th International Conference on Machine Learning, ICML 2018. International Machine Learning Society (IMLS)",
            "year": 2018
        },
        {
            "authors": [
                "H. Attouch",
                "X. Goudou",
                "P. Redont"
            ],
            "title": "The heavy ball with friction method",
            "venue": "i. the continuous dynamical system: global exploration of the local minima of a real-valued 42 function by asymptotic analysis of a dissipative dynamical system, Communications in Contemporary Mathematics 2 ",
            "year": 2000
        },
        {
            "authors": [
                "D.A. Bayer",
                "J.C. Lagarias"
            ],
            "title": "The nonlinear geometry of linear programming",
            "venue": "i. affine and projective scaling trajectories, Transactions of the American Mathematical Society 314 ",
            "year": 1989
        },
        {
            "authors": [
                "W. Behrman"
            ],
            "title": "An efficient gradient flow method for unconstrained optimization",
            "venue": "stanford university PhD thesis",
            "year": 1998
        },
        {
            "authors": [
                "M.P. Bendsoe",
                "O. Sigmund"
            ],
            "title": "Topology optimization: theory",
            "venue": "methods, and applications, Springer Science & Business Media",
            "year": 2013
        },
        {
            "authors": [
                "S.J. Benson",
                "Y. Ye"
            ],
            "title": "Algorithm 875: DSDP5\u2014software for semidefinite programming",
            "venue": "ACM Transactions on Mathematical Software (TOMS) 34 ",
            "year": 2008
        },
        {
            "authors": [
                "D. Bertsekas"
            ],
            "title": "Convex optimization algorithms",
            "venue": "Athena Scientific",
            "year": 2015
        },
        {
            "authors": [
                "P. Biswas",
                "T.C. Lian",
                "T.C. Wang",
                "Y. Ye"
            ],
            "title": "Semidefinite programming based algorithms for sensor network localization",
            "venue": "ACM Transactions on Sensor Networks (TOSN) 2 ",
            "year": 2006
        },
        {
            "authors": [
                "P. Biswas",
                "Y. Ye"
            ],
            "title": "Semidefinite programming for ad hoc wireless sensor network localization",
            "venue": "Proceedings of the 3rd international symposium on Information processing in sensor networks",
            "year": 2004
        },
        {
            "authors": [
                "P. Biswas",
                "Y. Ye"
            ],
            "title": "A distributed method for solving semidefinite programs arising from ad hoc wireless sensor network localization",
            "venue": "Multiscale optimization methods and applications, Springer",
            "year": 2006
        },
        {
            "authors": [
                "K.U. Bletzinger"
            ],
            "title": "Free shape optimal design of structures",
            "venue": "Computational Design Modelling, Springer",
            "year": 2011
        },
        {
            "authors": [
                "R.I. Bo\u0163",
                "E.R. Csetnek",
                "S.C. L\u00e1szl\u00f3"
            ],
            "title": "A primal-dual dynamical approach to structured convex minimization problems",
            "venue": "Journal of Differential Equations 269 ",
            "year": 2020
        },
        {
            "authors": [
                "C.A. Botsaris"
            ],
            "title": "Differential gradient methods",
            "venue": "Journal of Mathematical Analysis and Applications 63 ",
            "year": 1978
        },
        {
            "authors": [
                "S. Boyd",
                "N. Parikh",
                "E. Chu",
                "B. Peleato"
            ],
            "title": "J",
            "venue": "Eckstein, et al., Distributed optimization and statistical learning via the alternating direction method of multipliers, Foundations and Trends\u00ae in Machine learning 3 ",
            "year": 2011
        },
        {
            "authors": [
                "S. Boyd",
                "L. Vandenberghe"
            ],
            "title": "Convex optimization",
            "venue": "Cambridge university press",
            "year": 2004
        },
        {
            "authors": [
                "J.J. Brust",
                "R.F. Marcia",
                "C.G. Petra",
                "M.A. Saunders"
            ],
            "title": "Large-scale optimization with linear equality constraints using reduced compact representation",
            "venue": "SIAM Journal on Scientific Computing 44 ",
            "year": 2022
        },
        {
            "authors": [
                "R.M. Buehrer",
                "H. Wymeersch",
                "R.M. Vaghefi"
            ],
            "title": "Collaborative sensor network localization: Algorithms and practical issues",
            "venue": "Proceedings of the IEEE 106 ",
            "year": 2018
        },
        {
            "authors": [
                "R.H. Byrd",
                "J.C. Gilbert",
                "J. Nocedal"
            ],
            "title": "A trust region method based on interior point techniques for nonlinear programming",
            "venue": "Mathematical programming 89 ",
            "year": 2000
        },
        {
            "authors": [
                "L. Chen",
                "K. Bletzinger",
                "A. Geiser",
                "R. W\u00fcchner"
            ],
            "title": "A modified search direction method for inequality constrained optimization problems using the singular-value decomposition of normalized response gradients",
            "venue": "Structural and Multidisciplinary Optimization 60 ",
            "year": 2019
        },
        {
            "authors": [
                "X. Chen",
                "M.M. Kostreva"
            ],
            "title": "Methods of feasible directions: A review",
            "venue": "Progress in Optimization, Springer",
            "year": 2000
        },
        {
            "authors": [
                "L. Chizat",
                "F. Bach"
            ],
            "title": "On the global convergence of gradient descent for overparameterized models using optimal transport, in Advances in neural information processing",
            "year": 2018
        },
        {
            "authors": [
                "T.J. Chowdhury",
                "C. Elkin",
                "V. Devabhaktuni",
                "D.B. Rawat",
                "J. Oluoch"
            ],
            "title": "Advances on localization techniques for wireless sensor networks: A survey",
            "venue": "Computer Networks 110 ",
            "year": 2016
        },
        {
            "authors": [
                "J. Cortes"
            ],
            "title": "Finite-time convergent gradient flows with applications to network consensus",
            "venue": "Automatica 42 ",
            "year": 2006
        },
        {
            "authors": [
                "E. De Klerk"
            ],
            "title": "J",
            "venue": "Snyman, S.O.R. Group, et al., A feasible descent cone method for linearly constrained minimization problems, Computers & Mathematics with Applications 28 ",
            "year": 1994
        },
        {
            "authors": [
                "A. Dener",
                "G.K. Kenway",
                "J.E. Hicken",
                "J. Martins"
            ],
            "title": "Comparison of inexact-and quasinewton algorithms for aerodynamic shape optimization, in 53rd AIAA Aerospace Sciences Meeting",
            "year": 2015
        },
        {
            "authors": [
                "I. Diener"
            ],
            "title": "Trajectory methods in global optimization",
            "venue": "Handbook of Global optimization, Springer",
            "year": 1995
        },
        {
            "authors": [
                "J.S. Dokken",
                "S.K. Mitusch",
                "S.W. Funke"
            ],
            "title": "Automatic shape derivatives for transient PDEs in FEniCS and Firedrake",
            "venue": "arXiv preprint arXiv:2001.10058 ",
            "year": 2020
        },
        {
            "authors": [
                "F. Feppon",
                "G. Allaire",
                "C. Dapogny"
            ],
            "title": "Null space gradient flows for constrained optimization with applications to shape optimization",
            "venue": "ESAIM: Control, Optimisation and Calculus of Variations ",
            "year": 2020
        },
        {
            "authors": [
                "A.V. Fiacco",
                "G.P. McCormick"
            ],
            "title": "Nonlinear programming: sequential unconstrained minimization techniques",
            "venue": "Vol. 4, Siam",
            "year": 1990
        },
        {
            "authors": [
                "R. Fletcher",
                "S. Leyffer"
            ],
            "title": "Nonlinear programming without a penalty function",
            "venue": "Mathematical programming 91 ",
            "year": 2002
        },
        {
            "authors": [
                "A. Forsgren",
                "P.E. Gill",
                "M.H. Wright"
            ],
            "title": "Interior methods for nonlinear optimization",
            "venue": "SIAM review 44 ",
            "year": 2002
        },
        {
            "authors": [
                "B. Fr\u00f6hlich",
                "J. Gade",
                "F. Geiger",
                "M. Bischoff",
                "P. Eberhard"
            ],
            "title": "Geometric element parameterization and parametric model order reduction in finite element based shape optimization",
            "venue": "Computational Mechanics 63 ",
            "year": 2019
        },
        {
            "authors": [
                "M.X. Goemans",
                "D.P. Williamson"
            ],
            "title": "Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming",
            "venue": "Journal of the ACM (JACM) 42 ",
            "year": 1995
        },
        {
            "authors": [
                "J. Gondzio"
            ],
            "title": "Interior point methods 25 years later",
            "venue": "European Journal of Operational Research 218 ",
            "year": 2012
        },
        {
            "authors": [
                "A. Griewank",
                "A. Walther"
            ],
            "title": "Evaluating derivatives: principles and techniques of algorithmic differentiation",
            "venue": "SIAM",
            "year": 2008
        },
        {
            "authors": [
                "A.O. Griewank"
            ],
            "title": "Generalized descent for global optimization",
            "venue": "Journal of optimization theory and applications 34 ",
            "year": 1981
        },
        {
            "authors": [
                "R.T. Haftka",
                "J. Sobieszczanski-Sobieski",
                "S.L. Padula"
            ],
            "title": "On options for interdisciplinary analysis and design optimization",
            "venue": "Structural optimization 4 ",
            "year": 1992
        },
        {
            "authors": [
                "J. Haslinger",
                "R.A. M\u00e4kinen"
            ],
            "title": "Introduction to shape optimization: theory",
            "venue": "approximation, and computation, SIAM",
            "year": 2003
        },
        {
            "authors": [
                "U. Helmke",
                "J.B. Moore"
            ],
            "title": "Optimization and dynamical systems",
            "venue": "Springer Science & Business Media",
            "year": 1996
        },
        {
            "authors": [
                "J. Herskovits",
                "G. Dias",
                "G. Santos",
                "C.M. Soares"
            ],
            "title": "Shape structural optimization with an interior point nonlinear programming algorithm",
            "venue": "Structural and Multidisciplinary Optimization 20 ",
            "year": 2000
        },
        {
            "authors": [
                "J.E. Hicken",
                "D.W. Zingg"
            ],
            "title": "Aerodynamic optimization algorithm with integrated geometry parameterization and mesh movement",
            "venue": "AIAA journal 48 ",
            "year": 2010
        },
        {
            "authors": [
                "M. Hojjat",
                "E. Stavropoulou",
                "K.U. Bletzinger"
            ],
            "title": "The vertex morphing method for nodebased shape optimization",
            "venue": "Computer Methods in Applied Mechanics and Engineering 268 ",
            "year": 2014
        },
        {
            "authors": [
                "R.H. Hoppe",
                "C. Linsenmann",
                "H. Antil"
            ],
            "title": "Adaptive path following primal dual interior point methods for shape optimization of linear and nonlinear Stokes flow problems",
            "venue": "International Conference on Large-Scale Scientific Computing. Springer",
            "year": 2007
        },
        {
            "authors": [
                "J.T. Hwang"
            ],
            "title": "A modular approach to large-scale design optimization of aerospace systems",
            "venue": "PhDT ",
            "year": 2015
        },
        {
            "authors": [
                "F. Jarre",
                "M. Kocvara",
                "J. Zowe"
            ],
            "title": "Optimal truss design by interior-point methods",
            "venue": "SIAM Journal on Optimization 8 ",
            "year": 1998
        },
        {
            "authors": [
                "M.I. Jordan"
            ],
            "title": "Dynamical",
            "venue": "symplectic and stochastic perspectives on gradient-based optimization, in Proceedings of the International Congress of Mathematicians, Vol. 1. World Scientific",
            "year": 2018
        },
        {
            "authors": [
                "D. Kandris",
                "C. Nakas",
                "D. Vomvas",
                "G. Koulouras"
            ],
            "title": "Applications of wireless sensor networks: an up-to-date survey",
            "venue": "Applied System Innovation 3 ",
            "year": 2020
        },
        {
            "authors": [
                "G. Kennedy"
            ],
            "title": "Large-scale multi-material topology optimization for additive manufacturing, in 56th AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference",
            "year": 2015
        },
        {
            "authors": [
                "G.K. Kenway",
                "G.J. Kennedy",
                "J.R. Martins"
            ],
            "title": "Scalable parallel approach for high-fidelity steady-state aeroelastic analysis and adjoint derivative computations",
            "venue": "AIAA journal 52 ",
            "year": 2014
        },
        {
            "authors": [
                "S. Kim",
                "M. Kojima",
                "H. Waki"
            ],
            "title": "Exploiting sparsity in sdp relaxation for sensor network localization",
            "venue": "SIAM Journal on Optimization 20 ",
            "year": 2009
        },
        {
            "authors": [
                "M. Kocvara",
                "S. Mohammed"
            ],
            "title": "Primal-dual interior point multigrid method for topology optimization",
            "venue": "SIAM Journal on Scientific Computing 38 ",
            "year": 2016
        },
        {
            "authors": [
                "M. Ko\u010dvara",
                "M. Stingl"
            ],
            "title": "PENNON: A code for convex nonlinear and semidefinite programming",
            "venue": "Optimization methods and software 18 ",
            "year": 2003
        },
        {
            "authors": [
                "J. Korelc"
            ],
            "title": "Automation of primal and sensitivity analysis of transient coupled problems",
            "venue": "Computational mechanics 44 ",
            "year": 2009
        },
        {
            "authors": [
                "C. Lemar\u00e9chal"
            ],
            "title": "Cauchy and the gradient method",
            "venue": "Doc Math Extra 251 ",
            "year": 2012
        },
        {
            "authors": [
                "N.E. Leonard",
                "D.A. Paley",
                "F. Lekien",
                "R. Sepulchre",
                "D.M. Fratantoni",
                "R.E. Davis"
            ],
            "title": "Collective motion",
            "venue": "sensor networks, and ocean sampling, Proceedings of the IEEE 95 ",
            "year": 2007
        },
        {
            "authors": [
                "J. Liang",
                "T.P. Runarsson",
                "E. Mezura-Montes",
                "M. Clerc",
                "P.N. Suganthan",
                "C.C. Coello",
                "K. Deb"
            ],
            "title": "Problem definitions and evaluation criteria for the cec 2006 special session on constrained real-parameter optimization",
            "venue": "Journal of Applied Mechanics 41 ",
            "year": 2006
        },
        {
            "authors": [
                "J. Liedmann",
                "S. Gerke",
                "F.J. Barthold",
                "M. Br\u00fcnig"
            ],
            "title": "Shape optimization of the x0specimen: theory",
            "venue": "numerical simulation and experimental verification, Computational Mechanics ",
            "year": 2020
        },
        {
            "authors": [
                "K. Linkwitz",
                "H.J. Schek"
            ],
            "title": "Einige Bemerkungen zur Berechnung von vorgespannten Seilnetzkonstruktionen",
            "venue": "Ingenieur-Archiv 40 ",
            "year": 1971
        },
        {
            "authors": [
                "J. Lofberg"
            ],
            "title": "YALMIP: A toolbox for modeling and optimization in MATLAB",
            "venue": "2004 IEEE international conference on robotics and automation (IEEE Cat. No. 04CH37508). IEEE",
            "year": 2004
        },
        {
            "authors": [
                "D.G. Luenberger",
                "Y. Ye"
            ],
            "title": "Linear and nonlinear programming",
            "venue": "5th ed., Springer",
            "year": 2021
        },
        {
            "authors": [
                "D. Luft",
                "V.H. Schulz",
                "K. Welker"
            ],
            "title": "Efficient techniques for shape optimization with variational inequalities using adjoints",
            "venue": "SIAM Journal on Optimization 30 ",
            "year": 2020
        },
        {
            "authors": [
                "Z.Q. Luo",
                "W.K. Ma",
                "A.M.C. So",
                "Y. Ye",
                "S. Zhang"
            ],
            "title": "Semidefinite relaxation of quadratic optimization problems",
            "venue": "IEEE Signal Processing Magazine 27 ",
            "year": 2010
        },
        {
            "authors": [
                "B. Maar",
                "V. Schulz"
            ],
            "title": "Interior point multigrid methods for topology optimization",
            "venue": "Structural and Multidisciplinary Optimization 19 ",
            "year": 2000
        },
        {
            "authors": [
                "A. Majumdar",
                "G. Hall",
                "A.A. Ahmadi"
            ],
            "title": "Recent scalability improvements for semidefinite programming with applications in machine learning",
            "venue": "control, and robotics, Annual Review of Control, Robotics, and Autonomous Systems 3 ",
            "year": 2020
        },
        {
            "authors": [
                "I. Maros",
                "C. Meszaros"
            ],
            "title": "The Maros and Meszaros Convex QP Test Problem Set (2022)",
            "year": 2022
        },
        {
            "authors": [
                "J.R. Martins",
                "A.B. Lambe"
            ],
            "title": "Multidisciplinary design optimization: a survey of architectures",
            "venue": "AIAA journal 51 ",
            "year": 2013
        },
        {
            "authors": [
                "K. Mihi\u0107",
                "M. Zhu"
            ],
            "title": "and Y",
            "venue": "Ye, RACQP ",
            "year": 2019
        },
        {
            "authors": [
                "K. Mihi\u0107",
                "M. Zhu",
                "Y. Ye"
            ],
            "title": "Managing randomization in the multi-block alternating direction method of multipliers for quadratic optimization",
            "venue": "Mathematical Programming 45 Computation 13 ",
            "year": 2021
        },
        {
            "authors": [
                "R. Najian Asl",
                "I. Antonau",
                "A. Ghantasala",
                "W.G. Dettmer",
                "R. W\u00fcchner",
                "K.U. Bletzinger"
            ],
            "title": "A partitioned scheme for adjoint shape sensitivity analysis of fluid\u2013structure interactions involving non-matching meshes",
            "venue": "Optimization Methods and Software ",
            "year": 2020
        },
        {
            "authors": [
                "Y. Nesterov",
                "H. Wolkowicz",
                "Y. Ye"
            ],
            "title": "Semidefinite programming relaxations of nonconvex quadratic optimization",
            "venue": "Handbook of semidefinite programming, Springer",
            "year": 2000
        },
        {
            "authors": [
                "Y.E. Nesterov"
            ],
            "title": "A method for solving the convex programming problem with convergence rate O (1/k\u02c6",
            "venue": "Dokl. akad. nauk Sssr,",
            "year": 1983
        },
        {
            "authors": [
                "B. O\u2019Donoghue"
            ],
            "title": "Operator splitting for a homogeneous embedding of the linear complementarity problem",
            "venue": "SIAM Journal on Optimization",
            "year": 2021
        },
        {
            "authors": [
                "R.E. Perez",
                "P.W. Jansen",
                "J.R.R.A. Martins"
            ],
            "title": "pyOpt: A Python-based object-oriented framework for nonlinear constrained optimization",
            "venue": "Structures and Multidisciplinary Optimization 45 ",
            "year": 2012
        },
        {
            "authors": [
                "L. Perko"
            ],
            "title": "Differential Equations and Dynamical Systems",
            "venue": "Vol. 7, Springer Science & Business Media",
            "year": 2008
        },
        {
            "authors": [
                "I. Polik",
                "T. Terlaky",
                "Y. Zinchenko"
            ],
            "title": "SeDuMi: a package for conic optimization",
            "venue": "IMA workshop on Optimization and Control, Univ. Minnesota, Minneapolis. Citeseer",
            "year": 2007
        },
        {
            "authors": [
                "F.A. Potra",
                "S.J. Wright"
            ],
            "title": "Interior-point methods",
            "venue": "Journal of Computational and Applied Mathematics 124 ",
            "year": 2000
        },
        {
            "authors": [
                "D. Puccinelli",
                "M. Haenggi"
            ],
            "title": "Wireless sensor networks: applications and challenges of ubiquitous sensing",
            "venue": "IEEE Circuits and systems magazine 5 ",
            "year": 2005
        },
        {
            "authors": [
                "R. Rao"
            ],
            "title": "Jaya: A simple and new optimization algorithm for solving constrained and unconstrained optimization problems",
            "venue": "International Journal of Industrial Engineering Computations 7 ",
            "year": 2016
        },
        {
            "authors": [
                "T.D. R\u00e4ty"
            ],
            "title": "Survey on contemporary remote surveillance systems for public safety",
            "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews) 40 ",
            "year": 2010
        },
        {
            "authors": [
                "J.B. Rosen"
            ],
            "title": "The gradient projection method for nonlinear programming",
            "venue": "part i. linear constraints, Journal of the society for industrial and applied mathematics 8 ",
            "year": 1960
        },
        {
            "authors": [
                "C. Schillings",
                "S. Schmidt",
                "V. Schulz"
            ],
            "title": "Efficient shape optimization for certain and uncertain aerodynamic design",
            "venue": "Computers & Fluids 46 ",
            "year": 2011
        },
        {
            "authors": [
                "S. Schmidt",
                "C. Ilic",
                "V. Schulz",
                "N.R. Gauger"
            ],
            "title": "Three-dimensional large-scale aerodynamic shape optimization based on shape calculus",
            "venue": "AIAA journal 51 ",
            "year": 2013
        },
        {
            "authors": [
                "V.H. Schulz",
                "M. Siebenborn",
                "K. Welker"
            ],
            "title": "Towards a Lagrange\u2013Newton approach for PDE constrained shape optimization",
            "venue": "New Trends in Shape Optimization, Springer",
            "year": 2015
        },
        {
            "authors": [
                "J.A. Sethian"
            ],
            "title": "Level set methods and fast marching methods: evolving interfaces in computational geometry",
            "venue": "fluid mechanics, computer vision, and materials science, Vol. 3, Cambridge university press",
            "year": 1999
        },
        {
            "authors": [
                "J. Snyman",
                "L. Fatti"
            ],
            "title": "A multi-start global minimization algorithm with dynamic search trajectories",
            "venue": "Journal of Optimization Theory and Applications 54 ",
            "year": 1987
        },
        {
            "authors": [
                "A.M.C. So",
                "Y. Ye"
            ],
            "title": "Theory of semidefinite programming for sensor network localization",
            "venue": "Mathematical Programming 109 ",
            "year": 2007
        },
        {
            "authors": [
                "J. Sokolowski",
                "J.P. Zol\u00e9sio"
            ],
            "title": "Introduction to shape optimization",
            "venue": "Introduction to Shape Optimization, Springer",
            "year": 1992
        },
        {
            "authors": [
                "N. Stander",
                "J. Snyman"
            ],
            "title": "A new first-order interior feasible direction method for structural optimization",
            "venue": "International journal for numerical methods in engineering 36 ",
            "year": 1993
        },
        {
            "authors": [
                "N. Stander",
                "J. Snyman",
                "J. Coster"
            ],
            "title": "On the robustness and efficiency of the sam algorithm for structural optimization",
            "venue": "International Journal for Numerical Methods in Engineering 38 ",
            "year": 1995
        },
        {
            "authors": [
                "B. Stellato",
                "G. Banjac",
                "P. Goulart",
                "A. Bemporad",
                "S. Boyd"
            ],
            "title": "OSQP: An operator splitting solver for quadratic programs",
            "venue": "Mathematical Programming Computation 12 ",
            "year": 2020
        },
        {
            "authors": [
                "W. Su",
                "S. Boyd"
            ],
            "title": "Candes, A differential equation for modeling Nesterov\u2019s accelerated gradient method: Theory and insights, in Advances in Neural Information",
            "venue": "Processing Systems",
            "year": 2014
        },
        {
            "authors": [
                "D. Sun",
                "K.C. Toh"
            ],
            "title": "Y",
            "venue": "Yuan, and X.Y. Zhao, SDPNAL+: A Matlab software for semidefinite programming with bound constraints (version 1.0), Optimization Methods and Software 35 ",
            "year": 2020
        },
        {
            "authors": [
                "T. Sun",
                "L.J. Chen",
                "C.C. Han",
                "M. Gerla"
            ],
            "title": "Reliable sensor networks for planet exploration",
            "venue": "Proceedings. 2005 IEEE Networking, Sensing and Control, 2005. IEEE",
            "year": 2005
        },
        {
            "authors": [
                "K. Svanberg"
            ],
            "title": "The method of moving asymptotes\u2014a new method for structural optimization",
            "venue": "International journal for numerical methods in engineering 24 ",
            "year": 1987
        },
        {
            "authors": [
                "K.C. Toh",
                "M.J. Todd",
                "R.H. T\u00fct\u00fcnc\u00fc"
            ],
            "title": "On the implementation and usage of SDPT3\u2013 a Matlab software package for semidefinite-quadratic-linear programming",
            "venue": "version 4.0, in Handbook on semidefinite, conic and polynomial optimization, Springer",
            "year": 2012
        },
        {
            "authors": [
                "M. Towara",
                "U. Naumann"
            ],
            "title": "A discrete adjoint model for OpenFOAM",
            "venue": "Procedia Computer Science 18 ",
            "year": 2013
        },
        {
            "authors": [
                "S. Wang",
                "X. Yang",
                "K.L. Teo"
            ],
            "title": "A unified gradient flow approach to constrained nonlinear optimization problems",
            "venue": "Computational Optimization and Applications 25 ",
            "year": 2003
        },
        {
            "authors": [
                "Z. Wang",
                "S. Zheng",
                "Y. Ye",
                "S. Boyd"
            ],
            "title": "Further relaxations of the semidefinite programming approach to sensor network localization",
            "venue": "SIAM Journal on Optimization 19 ",
            "year": 2008
        },
        {
            "authors": [
                "A.C. Wilson",
                "B. Recht",
                "M.I. Jordan"
            ],
            "title": "A lyapunov analysis of accelerated methods in optimization",
            "venue": "Journal of Machine Learning Research 22 ",
            "year": 2021
        },
        {
            "authors": [
                "M. Yamashita",
                "K. Fujisawa",
                "M. Fukuda",
                "K. Kobayashi",
                "K. Nakata",
                "M. Nakata"
            ],
            "title": "Latest developments in the SDPA family for solving large-scale SDPs",
            "venue": "Handbook on semidefinite, conic and polynomial optimization, Springer",
            "year": 2012
        },
        {
            "authors": [
                "Y. Ye"
            ],
            "title": "Interior point algorithms: theory and analysis",
            "venue": "Vol. 44, John Wiley & Sons",
            "year": 2011
        },
        {
            "authors": [
                "Y. Zheng",
                "G. Fantuzzi",
                "A. Papachristodoulou"
            ],
            "title": "Chordal and factor-width decompositions for scalable semidefinite and polynomial optimization",
            "venue": "Annual Reviews in Control 52 ",
            "year": 2021
        },
        {
            "authors": [
                "O.C. Zienkiewicz",
                "R.L. Taylor",
                "P. Nithiarasu",
                "J. Zhu"
            ],
            "title": "The finite element method",
            "venue": "Vol. 3, McGraw-hill London",
            "year": 1977
        },
        {
            "authors": [
                "G. Zoutendijk"
            ],
            "title": "Methods of feasible directions: a study in linear and non-linear programming",
            "venue": "Elsevier",
            "year": 1960
        }
    ],
    "sections": [
        {
            "text": "KEYWORDS Negative and normalized gradients; inequality constrained optimization; gradient descent; interior-point method; shape optimization; sensor network localization\nAMS CLASSIFICATION 65K05; 90C22; 90C30; 90C51; 90C90"
        },
        {
            "heading": "1. Introduction",
            "text": "In this paper, we propose a first-order method for solving inequality constrained optimization problems. The problem of interest is\nminimize f(x), subject to gi(x) \u2264 0, i = 1, ...,m, (COP)\nL. Chen. Email: long.chen@scicomp.uni-kl.de K.-U. Bletzinger. Email: kub@tum.de N. R. Gauger. Email: nicolas.gauger@scicomp.uni-kl.de Y. Ye. Email: yyye@stanford.edu\nar X\niv :2\n30 2.\n11 89\n8v 1\n[ m\nat h.\nO C\n] 2\nwhere f, g1, ..., gm : Rn \u2192 R are twice differentiable. We propose a gradient descent akin method (GDAM) for (COP) with a single inequality constraint g(x),\nxk+1 = xk + \u03b1ks\u03b6(xk), s\u03b6(xk) = \u2212 \u2207f(xk) |\u2207f(xk)| \u2212 \u03b6 \u2207g(xk) |\u2207g(xk)| , \u03b6 \u2208 [0, 1), (GDAM)\nwhere \u03b1k denotes the step size, \u201c| \u00b7 |\u201d denotes the Euclidean norm, and \u03b6 is a parameter. \u2207f(x) and \u2207g(x) are the gradient column vectors of the objective function and constraint function, respectively.\nProvided the well-known logarithmic barrier function\n\u03a6(x) = \u2212 m\u2211 i=1 log(\u2212gi(x)), i = 1, ...,m, (1)\nwhere log(\u00b7) denotes the natural logarithm, we propose a generalization of (GDAM) for multiple constrained problems with \u03b6 \u2208 [0, 1) as\ns\u03b6(xk) = \u2212 \u2207f(xk) |\u2207f(xk)| \u2212 \u03b6 \u2207\u03a6(xk) |\u2207\u03a6(xk)| , if \u2207\u03a6(xk) 6= 0;\n\u2212\u2207f(xk), if \u2207\u03a6(xk) = 0. (2)"
        },
        {
            "heading": "1.1. Main contributions",
            "text": "Theory, computational algorithms, and applications are the three pillars of an optimization method. Just as the title suggests, this manuscript mainly focuses on the algorithms and applications of GDAM. We also give essential theoretical guarantees on the global convergence of the method for a complete presentation.\nWe summarize the main contributions of this work:\n1. We present (GDAM), which is derived from our previous work [28], whereby the equivalence of the two methods is not obvious. 2. We give fundamental theoretical guarantees to the method using a continuoustime dynamical systems approach. 3. We present two computational algorithms based on (GDAM), a vanilla and an accelerated implementation. 4. We apply the developed algorithms to two engineering applications, node-based shape optimization and sensor network localization, which demonstrate the practical usefulness of GDAM in solving large-scale and difficult optimization problems."
        },
        {
            "heading": "1.2. Organization of paper",
            "text": "In section 2, we first review related works focusing on algorithm and application aspects. In section 3, we derive the method for single inequality constrained problems. Illustrative examples are presented in section 4 for an informal but intuitive presentation of the method. We give fundamental theoretical guarantees of the method in 5\nand show its generalization to multiple constraints in section 6. We present computational algorithms of GDAM in section 7 and show preliminary numerical experiments. Two engineering applications, shape optimization and sensor network localization, are presented in sections 8 and 9. We conclude the work with a discussion in section 10."
        },
        {
            "heading": "2. Related works and applications",
            "text": ""
        },
        {
            "heading": "2.1. Gradient descent method",
            "text": "The gradient descent method, originally proposed by Cauchy, is a first-order method for unconstrained optimization that uses the negative gradient of the objective function for the variable update [64]. In a canonical form, it writes\nxk+1 = xk \u2212 \u03b1k\u2207f(xk), (3)\nThe direction of the gradient descent is the steepest descent direction in Euclidean norm. To see this, we write the first-order Taylor expansion at the current iterate xk of the objective function,\nf(xk + d) \u2248 f(xk) + \u3008\u2207f(xk), d\u3009.\nwhere \u201c\u3008 , \u3009\u201d denotes the inner product in Euclidean space. The steepest descent direction d is found by the optimization problem\nminimize \u3008\u2207f(xk), d\u3009 subject to |d| = 1.\nFrom the Cauchy-Schwarz inequality, we obtain\nd(xk) = \u2212 \u2207f(xk) |\u2207f(xk)| , (4)\nwhich is the negative and normalized objective gradient. Comparing (4) and (GDAM),\ns\u03b6(xk) = \u2212 \u2207f(xk) |\u2207f(xk)| \u2212 \u03b6 \u2207g(xk) |\u2207g(xk)| , \u03b6 \u2208 [0, 1),\nwhich linearly combines the negative and normalized objective and constraint gradient, we consider the present method: a gradient descent akin method for inequality constrained optimization problems. The present method can be explained intuitively: For an inequality constrained problem, we use the objective gradient descent direction to minimize f(x), and use the constraint gradient descent direction to minimize g(x) (so as to maintain feasibility by moving away from the constraint boundary). Since the gradient directions are normalized to 1, a parameter 0 \u2264 \u03b6 < 1 ensures that the computed direction is a descent direction of the objective function."
        },
        {
            "heading": "2.2. Interior-point methods",
            "text": "Interior-point methods (IPMs), which are mostly based on the Newton method, are among the most competitive methods for constrained optimization problems. The signature of IPM is the existence of continuously parameterized families of approximate solutions that converge to the exact solution asymptotically [40]. IPMs find a wide variety of applications of convex and nonconvex optimizations in broad fields. There are a vast amount of excellent works that have been devoted to IPM. A comprehensive review of this class of methods is certainly beyond the scope of the present paper, however we refer the interested reader to [40][87][112], more recently, in [43], and many other excellent optimization books.\nThe present method results in trajectories that asymptotically converge to the central path for a particular IPM, the logarithmic barrier method [38]. We introduce its connections/differences to the present method in the next. Consider a convex optimization problem of the form (COP), we start with its approximated unconstrained subproblem using the logarithmic barrier function \u03a6(x),\nminimize f(x) + \u03b7\u03a6(x), (5)\nwhere the barrier parameter \u03b7 is a positive parameter. As \u03b7 \u2192 0, the solution of the approximated problem converges to the original one. The central path is characterized by the set of points that satisfy the necessary and sufficient conditions [24]:\n0 = \u2207f(x?) + \u03b7\u2207\u03a6(x?), x? \u2208 \u2126\u2212, (6)\nwhere \u2126\u2212 = {x : gi(x) < 0, i = 1, ...,m}. The conditions (6) are interpreted as a modified KKT system in the literature [24][27][40]. The barrier method finds an approximated solution for the original problem by 1) iteratively decreasing the barrier parameter \u03b7, and 2) in each iteration, solving the subproblem (the modified KKT system) defined by (6) using the Newton method. Therefore, the barrier parameter \u03b7 can be considered a central path parameter.\nIn the present method, we do not parameterize the central path. Instead, we normalize the objective and constraint gradients. For optimization problems with a single inequality constraint, we propose the normalized central path condition as\n\u2207f(x) |\u2207f(x)| + \u2207g(x) |\u2207g(x)| = 0. (7)\nThe condition (7) is used in section 5 for the analysis. A generalization of the normalized central path condition from single inequality to multiple inequalities is introduced by the use of the logarithmic barrier function (see section 6) as\n\u2207f(x) |\u2207f(x)| + \u2207\u03a6(x) |\u2207\u03a6(x)| = 0. (8)\nCompared with the barrier method, the path parameter \u03b7 has vanished. The condition (8) characterizes the central path, which differs from (6), which instead characterizes a point on the central path.\nTo see the connections between GDAM and the interior-point method, we first write\nthe gradient descent direction d\u03a6,\u03b7 for a barrier \u03b7-subproblem (5),\nd\u03a6,\u03b7 = \u2212\u2207f(x)\u2212 \u03b7\u03a6(x). (9)\nA straightforward way to design a first-order method is to follow the double-loop structure of the second-order IPM: 1) iteratively decrease the barrier parameter \u03b7 in the outer loop, and 2) solve the subproblem (5) by the gradient descent (9) in the inner loop. Unfortunately, this approach has long been known to be computationally impractical, see, e.g., the discussions in [70, p. 469]. Roughly speaking, when \u03b7 is very small, d\u03a6,\u03b7 tends to result in an optimization trajectory that travels alongside the boundary of the constraints and suffers severely from poor conditioning.\nNext, we scale the GDAM search direction s\u03b6 with |\u2207f(xk)|,\n|\u2207f(xk)|s\u03b6 = \u2212\u2207f(xk)\u2212 \u03b6 |\u2207f(xk)| |\u2207\u03a6(xk)| \u2207\u03a6(xk). (10)\nComparing (10) with (9), it is then clear that the (scaled) GDAM suggests a dynamic computation of the barrier parameter at each step k,\n\u03b7(xk) = \u03b6 |\u2207f(xk)| |\u2207\u03a6(xk)| . (11)\nGDAM results in an optimization trajectory that travels alongside the central path (within a neighborhood relative to the parameter \u03b6) \u2014a typical behavior of a pathfollowing method. Therefore, we consider GDAM as a first-order interior-point method. As one of the main contributions of this work, we will show that GDAM, in contrast to the sequential application of gradient descent to the barrier subproblems, is a computationally practical optimization method."
        },
        {
            "heading": "2.3. Dynamical systems approaches",
            "text": "Dynamical systems approaches have been used to study optimization methods in many works, and our literature review could not be exhaustive. Extensive studies on the connections between interior-point flows with linear programming methods can be found in [49, Chapter 4] and the references therein. Nonlinear dissipative dynamical systems are studied in [11] in view of unconstrained optimization. [102] studies the celebrated Nesterov\u2019s accelerated gradient method using a dynamical system as the analysis tool. Recently, dynamical systems have been used to study optimization algorithms for solving problems arising from machine learning applications, see, e.g., [10][30][56][110]. In some literature, optimization methods that use dynamical systems are called trajectory methods. These methods construct optimization paths in a way so that one or all solutions to the optimization problem are a priori known to lie on these paths [35]. Typically, these optimization paths are solution trajectories to ODE of first or second-order. Trajectory methods are mainly studied for unconstrained optimizations for finding local solutions [13][22], and global solutions [45][96]. Studies for constrained optimization are, however, very limited, see [3][21][108] and the references therein. In this work, we give basic theoretical guarantees of the present method using a dynamical system\u2019s perspective \u2014we show that the method is globally convergent to first-order stationarities."
        },
        {
            "heading": "2.4. Feasible direction methods",
            "text": "The method of feasible directions (MFD) dates back to the 1960\u2019s by the work of Zoutendijk [115] and has enjoyed fruitful developments for decades. MFDs have been especially popular in the engineering community because of the importance of ending up with a design that satisfies the hard specifications expressed by a set of inequalities [29]. The general idea behind the MFD is to move from one feasible design to an improved feasible design iteratively so that a local solution can be found [9]. In the present method, the search direction must not be a feasible direction. The idea behind the method design is to find a search direction that approaches the central path while maintaining a descent direction of the objective function. Due to this major difference, we do not categorize our method as a method of feasible directions.\nIn the present method, we compute a search direction that uses normalized gradients. In [99], the authors also present a feasible direction method that applies normalized gradients. Their work is then continued and further developed in [33] and [100]. In these works, the active-set strategy is used. The common idea is to formulate a linear system under given input criteria on a chosen working set of (active) constraints, and a feasible descent search direction is obtained by solving the linear system. In the present method, we use a barrier function based formulation to treat multiple inequality constraints. The search direction is computed as a linear combination of the negative and normalized objective and barrier gradient."
        },
        {
            "heading": "2.5. Shape optimization",
            "text": "As a subset of design optimization, shape optimization is characterized by a very large or even infinite number of design variables that describe the varying boundary in the optimization process. Introductions to shape optimization are given in [48][98]. Shape optimization is distinct from another well-known problem in design optimization: topology optimization [14] (sometimes referred to as the homogenization method [4]). The main difference is that the topology optimization method removes smoothness and topological constraints in shape optimization, which results in different optimization formulations. Many topology optimization problems can be formulated in an (equivalent) convex optimization problem, while shape optimizations are typically nonlinear, and often nonconvex [53]. This difference partially contributes to the fact that there are successful implementations of IPM for large-scale1 topology optimization problems [55][58][61][73], but only a few works have presented a shape optimization that uses an IPM as the optimizer [8][50]. In the latter works, the size of the shape optimization problem is only moderate so that the power of IPM is not fully exploited. One of the most successful methods for nonlinear topology optimization is the method of moving asymptotes (MMA) that was introduced by Svanberg in 1987 [105]. In each iteration, MMA generates and solves an approximated convex problem related to the original one. For shape optimization, however, there is as yet no literature that discusses a large-scale problem using MMA.\nShape optimization is a subject frequently considered in multidisciplinary design optimization (MDO) [47]. To design complex engineering systems, MDO considers multiple disciplines and their interactions. For shape optimization, ongoing efforts are devoted to the computation of the shape gradient for coupled disciplines, for example, for steady-state coupled problems [59][79] and for transient coupled problems [63].\n1In this work, we refer large-scale optimizations to problems that have a high-dimensional variable space.\nWhile the development for the coupled-gradient is challenging, the reward is accurate derivatives and massive reductions in computational cost, which are essential for large-scale optimizations [76]. In many practical circumstances, the shape geometry is reparameterized with finitely many parameters. A shape reparameterization is typically needed if there are producibility restrictions [67] or if the initial geometric variable is not differentiable [54]. Well-parameterized shape geometry often allows the application of standard optimization approaches [41][51][84] or Newton-Krylov type methods [34]. On the other hand, the achievable shape is limited and dependent on the chosen parameterization. High-fidelity shape optimizations, which are directly based on finite element meshes [68][114] or level-set methods [5][95], exploit the largest shape space possible for real-life problems but lead to challenging optimization problems [37][71].\nManually deriving and implementing shape derivatives can be a laborious and errorprone task. A prominent approach to tackle this challenge is Algorithmic Differentiation (AD) [44], which computes derivatives of a function given as a computer program. In the context of shape optimization, AD has been successfully implemented in open-source solvers, such as OpenFOAM[107], SU2[2], and FEniCS[36], enabling shape design optimization practice on increasingly complex problems. Another ongoing research is the computation of shape Hessians, which are complex objects even for moderate problems. Recently, several works compute approximated shape Hessians and use a Newton-based method for the design optimization [92][93]. In general, largescale shape optimization is mainly performed using gradient descent type methods so far [94]. In engineering practice, a large number of constraints may be considered. The lack of literature in this regard has motivated our development of MSDM in [28]. In the present work, we simplify its computational framework to a gradient descent akin method. As an important result, the implementation effort and computational cost are reduced significantly. It opens the possibility of shape optimization to a wider range of applications."
        },
        {
            "heading": "2.6. Sensor network localization via semidefinite programming relaxation",
            "text": "Wireless sensor networks (WSNs), which consist of low-cost, low-energy, and multifunctional sensors that can communicate over short distances, provide many opportunities for monitoring and controlling the physical environment when the sensors are wireless linked and deployed in large numbers [1]. WSNs find a wide range of applications in environmental, industrial, urban, health, and other sectors, and we refer to comprehensive surveys in [57][88]. For many applications, awareness of the sensor locations is crucial for a meaningful interpretation of the gathered sensing data, see, e.g., [26][65][90][104]. Sensor network localization (SNL), which estimates sensor locations based on pairwise distance, is therefore considered one of the key enabling technologies for WSN applications.\nSNL is a challenging optimization problem, as it is a nonconvex problem and is generally intractable to find the global solution. Among various solution methods, convex relaxation based on semidefinite programming (originally introduced in Biswas-Ye [18]) is regarded as one of the most prominent approaches for global localization [31]. In theory, the semidefinite programming (SDP) relaxation provides the exact solution to an SNL problem if the problem is uniquely localizable [97]. The challenge that has hindered the practical application of SDP relaxation to large-scale SNL problems\nis primarily computational2. Well-established SDP solvers that are based on secondorder interior-point methods ([7][15][86][106][111]) can solve SNL problems with up to a few hundreds of sensors to arbitrary high accuracy, but they are unable to solve larger problems efficiently. This has motivated the development of advanced modelling approaches to alleviate the computational difficulty, see, e.g., [19][60][109]. Meanwhile, in the last two decades, a number of scalable SDP solvers were successfully developed. For example, the packages PENNON [62] and SDPNAL+ [103] are based on the Augmented Lagrangian method, and SCS [82] is based on the Alternating Direction of Multipliers method (ADMM). A comprehensive review of the latest advancements in the scalability of SDP solvers is given in [74]. In this work, we apply GDAM to solve the Biswas-Ye SDP relaxation of SNL problems. We use the classical logarithmic barrier function approach for the semidefinite cone constraint, and thus our method to solve SDP problems is general. Our computational experiments show that GDAM, when practically implemented, is very competitive in finding moderate accurate solutions to SNL problems of moderate size and is capable of solving very large problems (over 5000 sensors) that are intractable for comparing solvers."
        },
        {
            "heading": "3. Deriving the search direction for single inequality constrained optimizations",
            "text": "In this section, we show the consistent derivation of (GDAM) from our previous work [28] considering a single inequality constraint. First, we review the basic ideas of the modified search direction method and then show the derivation. For the remainder of the paper, we use \u2207f and \u2207g instead of \u2207f(x) and \u2207g(x) to lighten the notation when it is clear from the context.\nIn MSDM, at each iterate x, we construct a sensitivity matrix that contains the normalized objective and constraint gradient,\nm(x) = [\u2207fT |\u2207f | \u2207gT |\u2207g| ] . (12)\nThe total differential of the objective and constraint function at x are\ndf = \u2207fTdx, dg = \u2207gTdx.\n(13)\nA perspective from the input-output system established by the matrix m(x) gives( df |\u2207f | dg |\u2207g| ) = m(x)dx. (14)\nApplying SVD to the matrix m(x), we obtain\nm(x) = U\u03a3VT = min(2,n)\u2211 i=1 \u03c3iuiv T i . (15)\n2Indeed, scalability is a major challenge to the successful application of semidefinite programming to many\nlarge-size practical problems.\nThus, an orthonormal bases set vi, i = 1, 2,vi \u2208 Rn is obtained. Each vi can be used as a base search direction for the variable update, and v1 and v2 are defined as follows:\n- v1: by taking \u03b4v1 as the variable update, we obtain a change in objective as well as in constraint function [ df|\u2207f | , dg |\u2207g| ] T = \u03c31\u03b4u1, which is a decrease in the\nobjective function and an increase in the constraint function. - v2: by taking \u03b4v2 as the variable update, we obtain a change in the objective as\nwell as in the constraint function [ df|\u2207f | , dg |\u2207g| ] T = \u03c32\u03b4u2, which is a decrease in the objective function and a decrease in the constraint function.\nIt is worth mentioning that the update step \u03b4v1 provides a similar result as the filter approach presented in [39], which tries to minimize the so-called bi-objective optimization problem with two goals of minimizing the objective function f and the constraint violation |g|.\nWith v1 and v2, we can then rewrite the normalized steepest descent direction \u2212 \u2207f|\u2207f | as\n\u2212 \u2207f |\u2207f | = cos\u03b11v1 + cos\u03b12v2, (16)\nwhere \u03b11 is the angle between v1 and \u2212 \u2207f|\u2207f | , and \u03b12 is the angle between v2 and \u2212 \u2207f|\u2207f | . The modified search direction reads\nsc = cos\u03b11v1 + c \u00b7 cos\u03b12v2, (17)\nwhere c \u2265 1 is introduced to enlarge the contribution of v2 for the variable update. In the following, we show the derivation of (GDAM) from (17). By (15), we have\nmmT = U\u03a3\u03a3TUT , (18)\nwhich is a diagonalization of the symmetric matrix mmT . We have\nmmT = (\u2207fT |\u2207f | \u2207gT |\u2207g| )( \u2207f |\u2207f | \u2207g |\u2207g| ) = ( 1 cos \u03b8 cos \u03b8 1 ) , (19)\nwhere \u03b8 is the angle between \u2207f and \u2207g. The eigenvalues of mmT are\n\u03bb1 = 1\u2212 cos \u03b8, \u03bb2 = 1 + cos \u03b8.\n(20)\nBy the definition of v1 and v2 in MSDM, the eigenvectors of mm T can be factorized,\nu1 = ( \u2212 \u221a\n2 2 ,\n\u221a 2\n2\n)T ,\nu2 = ( \u2212 \u221a\n2 2 , \u2212\n\u221a 2\n2\n)T .\n(21)\nThe respective singular values are\n\u03c31 = \u221a\n1\u2212 cos \u03b8, \u03c32 = \u221a 1 + cos \u03b8.\n(22)\nBy the definition of SVD,(\u2207fT |\u2207f | \u2207gT |\u2207g| ) = ( \u2212 \u221a 2 2 \u2212 \u221a 2 2\u221a 2 2 \u2212 \u221a 2 2 )(\u221a 1\u2212 cos \u03b8 0 0 \u221a 1 + cos \u03b8 )( vT1 vT2 ) . (23)\nTherefore, we obtain\nv1 = 1\u221a\n2\u2212 2 cos \u03b8 ( \u2212 \u2207f |\u2207f | + \u2207g |\u2207g| ) ,\nv2 = 1\u221a\n2 + 2 cos \u03b8 ( \u2212 \u2207f |\u2207f | \u2212 \u2207g |\u2207g| ) ,\n(24)\nwhere \u03b8 is the angle between the objective function gradient \u2207f and the constraint function gradient \u2207g (full details in Appendix A). With \u03b8 we also have\ncos\u03b11 = \u2212\u3008 \u2207f |\u2207f |\n,v1\u3009 = \u221a\n1\u2212 cos \u03b8\u221a 2 ,\ncos\u03b12 = \u2212\u3008 \u2207f |\u2207f |\n,v2\u3009 = \u221a\n1 + cos \u03b8\u221a 2 .\n(25)\nInserting (24), (25) into (17) we have\nsc = \u2212 \u2207f |\u2207f | \u2212 (c\u2212 1) 2 ( \u2207f |\u2207f | + \u2207g |\u2207g| ) . (26)\nAs we are mainly interested in the direction of the vector field sc, we can rewrite it as\ns\u03b6 = \u2212 \u2207f |\u2207f | \u2212 \u03b6 \u2207g |\u2207g| , (27)\nwith \u03b6 = c\u22121c+1 . With c \u2208 [1,+\u221e) we have \u03b6 \u2208 [0, 1) and thus we get the present search direction (GDAM)."
        },
        {
            "heading": "4. Illustrative examples and intuition",
            "text": "In this section, we demonstrate GDAM with two illustrative examples and provide intuitive explanations for its optimization behavior."
        },
        {
            "heading": "4.1. The behavior of the method with a fixed \u03b6",
            "text": "We consider a quadratically constrained nonconvex optimization problem,\nminimize f(x1, x2) = 1.5x 2 1 + x 2 2 \u2212 2x1x2 + 2x31 + 0.5x41, subject to g(x1, x2) = x 2 1 \u2212 x2 \u2212 2.2 \u2264 0.\n(28)\nThe problem has multiple local solutions due to nonconvexity. Figure 1 shows that there are two local solutions to the considered problem in the depicted variable space:\n1. A critical point of f(x), illustrated as a star, lies inside the feasible set. 2. A KKT solution, illustrated as a dot, is located at the boundary of the constraint.\nIt can be observed that the optimization trajectories all converge to the critical points (shown as stars). Moreover, the intersection points of the two left trajectories and the constraint boundary are approximate KKT points. While the former case is a common behavior of gradient flow approaches, the latter case is unique to the present method."
        },
        {
            "heading": "4.2. The behavior of the method in terms of \u03b6",
            "text": "We show the behavior of the method in terms of different \u03b6 by solving a 2D optimization problem analytically. The optimization problem reads,\nminimize f(x1, x2) = 1\n2 (x21 + x 2 2),\nsubject to g(x1, x2) = \u2212x2 + 10 \u2264 0. (29)\nThe present search direction field s\u03b6 reads\ns\u03b6 = \u22121\u221a x21 + x 2 2\n{ x1, x2 \u2212 \u03b6 \u221a x21 + x 2 2 }T . (30)\nWe define an initialization as (x01, x 0 2). Let x\u03042 = 1 2 ( x02 + \u221a (x01) 2 + (x02) 2 ) , then, the trajectory \u0393\u03b6 of the present search direction field s\u03b6 is\nx2 + \u221a x21 + x 2 2 = 2x\u03042 \u2223\u2223\u2223\u2223x1x01 \u2223\u2223\u2223\u22231\u2212\u03b6 . (\u0393\u03b6)\nLet (x1,\u03b6 , x2,\u03b6) be a point on the trajectory \u0393 \u03b6 with a maximal x2 component, then\nwe have\n(x2,\u03b6) \u03b6 =\n2\u03b6\n1 + \u03b6 x\u03042 |x01|1\u2212\u03b6 (\u221a 1\u2212 \u03b62 \u03b6 )1\u2212\u03b6 , (31)\nand\n|x1,\u03b6 | = x\u03042 \u03b6\n\u221a 1\u2212 \u03b62. (32)\nLet \u03b6 \u2192 1\u2212, then, x1,\u03b6 \u2192 0, x2,\u03b6 \u2192 x\u03042, the trajectory \u0393\u03b6 will converge to the curve \u0393 that is a union of the parabola\nx21 = 4x\u0304 2 2 \u2212 4x2x\u03042, x1 \u2208 (0, x01)( or(x01, 0), ) (33)\nand the interval (0, x\u03042) on x2-axis as is shown in figure 2 (full derivation details in Appendix A).\nWe now give an estimation of the intersection point x]\u03b6 of the trajectory (\u0393 \u03b6) with\nthe constraint boundary, x]\u03b6,2 + \u221a (x]\u03b6,1) 2 + (x]\u03b6,2) 2 = 2x\u03042 \u2223\u2223\u2223\u2223\u2223x ] \u03b6,1 x01 \u2223\u2223\u2223\u2223\u2223 1\u2212\u03b6 ,\nx]\u03b6,2 = 10;\n(34)\nFor a simple presentation, we first assume that x01 > 0. By\ndx1 dt = \u2212x1\u221a x21 + x 2 2 ,\nthe optimization trajectory is monotonically decreasing as x1 > 0, and thus x ] \u03b6,1 < x1,\u03b6 . Furthermore, dx1dt |x1=0 = 0 ensures that x1(t) \u2265 0 holds for any t. Combining both arguments, we obtain an estimate for the intersection point x]\u03b6 ,0 \u2264 x ] \u03b6,1 \u2264 x\u03042 \u03b6 \u221a 1\u2212 \u03b62,\nx]\u03b6,2 = 10.\n(35)\nObviously, x01 < 0 allows a similar study. Thus we obtain\n|x]\u03b6 \u2212 x ?| \u2264 x\u03042\n\u03b6\n\u221a 1\u2212 \u03b62, (36)\nwhere x? = (0, 10) is the KKT solution. We note that the error bound (36) is derived specifically for the problem (29) and is a very rough estimation that is based on a special point (x1,\u03b6 , x2,\u03b6). In the following section, we will give a general result regarding such an error bound, as well as other fundamental theoretical guarantees."
        },
        {
            "heading": "5. Global convergence",
            "text": "In this section, we give fundamental theoretical guarantees of the method regarding global convergence. We shall first analyze the single constraint optimization problem (SCOP), whose results can then be easily generalized to multiple constraints via the logarithmic barrier function (see next section).\nFor now, let\u2019s consider\nminimize f(x), subject to g(x) \u2264 0. (SCOP)\nRecall the iterative update formula of (GDAM),\nxk+1 = xk + \u03b1ks\u03b6(xk), s\u03b6(xk) = \u2212 \u2207f(xk) |\u2207f(xk)| \u2212 \u03b6 \u2207g(xk) |\u2207g(xk)| , \u03b6 \u2208 [0, 1). (GDAM)\nWe make use of the following dynamical system to study the convergence of the method,\ndx dt = \u2212 \u2207f(x) |\u2207f(x)| \u2212 \u03b6 \u2207g(x) |\u2207g(x)| , \u03b6 \u2208 [0, 1). (DS)\nIn addition to the theoretical convergence guarantee, we report results on the global behavior of the continuous-time trajectory of the method, which can be useful for the design of practical algorithms."
        },
        {
            "heading": "5.1. Assumptions and basic results",
            "text": "For the analysis of the system (DS), we make the following assumptions:\n(A1) Coercive condition for the objective function f(x),\nlim x\u2192\u221e\nf(x) = +\u221e;\n(A2) \u2207f(x) 6= 0 in the feasible set \u2126 = {x : g(x) \u2264 0}; (A3) \u2207g(x) 6= 0 in the feasible set \u2126; (A4) f and g are twice continuously differentiable functions.\nIf the function f(x) is coercive and continuous, then it has a global minimizer. The assumptions (A2) and (A3) are introduced due to our continuous-time analysis, as we need system (DS) to be well-defined. We will discuss the case where (A2) is excluded in subsection 5.2. In practice, (A3) may not always be satisfied. To escape the critical points of constraint functions, we suggest using the gradient descent search direction (see also section 6).\nLet x(t; \u03b6, x0) be the solution of the system:\n dx dt = s\u03b6(x),\nx|t=0 = x0. (37)\nwith x0 as the initial design in the feasible set and T\u03b6,x0 as the maximal existence interval of x(t; \u03b6, x0) in the set E \u2282 Rn,\nE := {x : |\u2207f(x)| 6= 0, |\u2207g(x)| 6= 0, x \u2208 Rn}.\nWe refer to [85] for a formal definition of the maximal interval of existence. In the following, we show some basic properties of the trajectory x(t; \u03b6, x0).\n5.1.1. Time derivative of f(x(t, \u03b6, x0)) and g(x(t, \u03b6, x0))\nWe first observe the changes of the objective function f(x) and constraint function g(x) along the solution trajectory x(t, \u03b6, x0). This is done by taking the time derivatives of f(x(t, \u03b6, x0)) and g(x(t, \u03b6, x0)),\nd dt (f(x(t; \u03b6, x0))) = df(x) dx \u00b7 dx(t; \u03b6, x0) dt\n= \u2207f(x)T ( \u2212 \u2207f(x) |\u2207f(x)| \u2212 \u03b6 \u2207g(x) |\u2207g(x)| ) = \u2212|\u2207f(x)| ( \u2207f(x)T\u2207f(x) |\u2207f(x)||\u2207f(x)| + \u03b6 \u2207f(x)T\u2207g(x) |\u2207f(x)||\u2207g(x)|\n) = \u2212|\u2207f(x)| (1 + \u03b6 cos \u03b8(x)) ,\n(38)\nsimilarly,\nd dt (g(x(t; \u03b6, x0))) = \u2212|\u2207g(x)|(cos \u03b8(x) + \u03b6), (39)\nwhere\ncos \u03b8(x) = \u2207f(x)T\u2207g(x) |\u2207f(x)||\u2207g(x)| . (40)\nObviously, (38), (39), and (40) hold under Assumptions (A1)\u2212 (A4) and as x \u2208 \u2126. In the following, we derive basic theoretical results based on the above three equations.\n5.1.2. Boundedness of the solution x(t; \u03b6, x0)\nFirst, it is easy to observe from (38) that f(x) decreases along x(t; \u03b6, x0) with a fixed \u03b6 \u2208 [0, 1). Furthermore, there exists a global lower bound for the objective function f(x) by the coercive Assumption (1). We can show that the solution trajectory x(t; \u03b6, x0) always stays in a bounded set that is dependent on the initialization x0. The result is formalized as follows.\nFirst, we define the bounded set in relation to a feasible initialization x0.\nDefinition 5.1 (Bounded set Bf(x0)). Given a feasible initialization x0,\nx0 \u2208 \u2126 = {x : g(x) \u2264 0}.\nThe bounded set Bf(x0) is defined by\nBf(x0) := {x : f(x) \u2264 f(x0)}. (41)\nLemma 5.2 (Boundedness). Suppose that assumptions (A1) - (A4) hold, and let \u03b6 \u2208 [0, 1), x0 \u2208 \u2126. Then the trajectory x(t; \u03b6, x0) always stays within the bounded set Bf(x0) associated with the feasible initialization x0.\nProof. Based on the deformation of the objective function f(x) along the trajectory x(t; \u03b6, x0) shown in (38), and with \u03b6 \u2208 [0, 1), cos \u03b8(x) \u2208 [\u22121, 1], we have\n1 + \u03b6 cos \u03b8(x) > 0. (42)\nTherefore,\ndf(x(t; \u03b6, x0))\ndt \u2264 0. (43)\nThus, the proof is complete.\nRemark 1. Lemma 5.2 is a basic result that implies that the integral of (38) is always bounded under our assumptions, i.e.,\u222b T\u03b6,x0\n0 |\u2207f(x(t; \u03b6, x0))|(1 + \u03b6 cos \u03b8(x))dt = f(x0)\u2212 f(x(T\u03b6,x0 ; \u03b6, x0)) <\u221e. (44)\n5.1.3. Lipschitz continuity of the vector field s\u03b6\nThe intersection of the feasible set \u2126 and the bounded set Bf(x0) defines the bounded feasible set.\nDefinition 5.3 (Bounded feasible set \u2126f(x0)). Given a feasible initialization x0,\nx0 \u2208 \u2126 = {x : g(x) \u2264 0}.\nThe bounded feasible set \u2126f(x0) is defined by\n\u2126f(x0) := {x : f(x) \u2264 f(x0), x \u2208 \u2126}. (45)\nIn the bounded feasible set \u2126f(x0), we show Lipschitz continuity of the present vector field s\u03b6 .\nLemma 5.4. Suppose that assumptions (A1)-(A4) hold and let the bounded feasible set \u2126f(x0) be non-empty. Then, the vector field s\u03b6(x), \u03b6 \u2208 [0, 1] is Lipschitz continuous for x \u2208 \u2126f(x0), i.e.,\n|s\u03b6(x)\u2212 s\u03b6(y)| \u2264 L|x\u2212 y|, (46)\nwhere L is a positive constant.\nProof. By assumption (A4), the second derivatives of f and g are bounded in \u2126f(x0). Therefore, \u2207f and \u2207g are Lipschitz continuous in \u2126x0 . By assumption (A2) and (A3), we have\n|\u2207f(x)| \u2265 a, |\u2207g(x)| \u2265 b, \u2200x \u2208 \u2126x0 ,\nfor some positive numbers a, b. Therefore, \u2207f(x)|\u2207f(x)| and \u2207g(x) |\u2207g(x)| are Lipschitz continuous. Thus, we have a Lipschitz continuity for s\u03b6(x) = \u2212 \u2207f(x)|\u2207f(x)|\u2212\u03b6 \u2207g(x) |\u2207g(x)| with x \u2208 \u2126f(x0).\n5.1.4. A cosine measure for the central path neighborhood\nFor the studies of inequality constrained optimizations, the central path is recognized as \u201ca fundamental mathematical object\u201d [12]. For example, its total curvature is used in the study of the existence of strongly polynomial algorithms for linear programs in the context of IPMs [6]. The equation (40) inspired us to give a cosine measure for the central path and its neighborhood.\nRecall the normalized central path condition (7),\n\u2207f(x) |\u2207f(x)| + \u2207g(x) |\u2207g(x)| = 0,\nwhich can be formulated as the angular relation between \u2207f(x) and \u2207g(x)\ncos \u03b8(x) = \u3008\u2207f(x),\u2207g(x)\u3009 |\u2207f(x)||\u2207g(x)| = \u22121. (47)\nUnder our assumptions (A1)-(A4), cos \u03b8(x) is a continuously differentiable function of x in \u2126f(x0). Additionally, we note that cos \u03b8(x) reaches its own minimum when x is at the central path. Combining both arguments allows us to conveniently define a neighborhood of the central path using the level set of cos \u03b8(x).\nDefinition 5.5 (\u00b5\u2212neighborhood). The \u00b5\u2212neighborhood of a central path is defined as\n\u0398\u00b5 = {x : cos \u03b8(x) < \u2212\u00b5, x \u2208 \u2126f(x0)}, \u00b5 \u2208 [0, 1].\nIntuitively, \u0398\u00b5 is a cone-like neighborhood around the central path. Obviously, \u0398\u00b5 shrinks to the central path as \u00b5\u2192 1\u2212. With the definition of the \u00b5\u2212neighborhood, we can show the following behavior of the optimization trajectory related to the constraint function g(x).\nLemma 5.6. Suppose that assumptions (A1)-(A4) hold, \u03b6 \u2208 [0, 1) is fixed, and x0 \u2208 \u2126, then the constraint function g(x) decreases along the trajectory x(t; \u03b6, x0) out of the neighborhood \u0398\u03b6 , and increases in \u0398\u03b6 , with \u0398\u03b6 defined as\n\u0398\u03b6 = {x : cos \u03b8(x) < \u2212\u03b6, x \u2208 \u2126f(x0)}. (48)\nProof. Based on the deformation of the constraint function g along the trajectory x(t; \u03b6, x0) shown in (39),\nd dt g(x(t; \u03b6, x0)) = \u2212|\u2207g|(\u03b6 + cos \u03b8(x)),\nwe get a proof directly.\nRemark 2. Lemma 5.6 hints that the optimization progresses faster when an iterate x(tk) \u2208 \u0398\u03b6 than vice versa. This result is useful in designing practical algorithms where mechanisms/heuristics can be developed to adjust the stepsize and/or the parameter \u03b6 so to achieve a faster convergence.\n5.2. Global convergence to critical points of f(x)\nWe show that, as long as \u03b6 \u2208 [0, 1), the present optimization trajectory always converges to a critical point of the objective function.\nTheorem 5.7. Suppose that assumptions (A1),(A3), (A4) hold and |\u2207g| 6= 0 in the whole Rn. The trajectory x(t; \u03b6, x0) converges to a connected subset of critical points of the objective function by \u03b6 \u2208 [0, 1). Especially, if the critical points of the objective function are isolated, then\nlim t\u2192T\u2212\u03b6,x0\nx(t; \u03b6, x0) = xc, \u2200\u03b6 \u2208 [0, 1), (49)\nwhere xc is a critical point of f .\nProof. First, notice that the present flow may be finite-time convergent3. The analytical example in section 4.2 shows that the present system can be finite-time convergent: 1) the analytical trajectory has a finite length, and 2) that the speed of the flow has a minimum norm of 1 \u2212 \u03b6 by the definition of the present system. To overcome this difficulty, we introduce a time-reparameterized Y\u2212system: dy d\u03c4 = |\u2207f(y)|s\u03b6(y),\ny|\u03c4=0 = x0. (50)\nThe system (50) has the same orbit as (37) in the subset E \u2282 Rn. Under our assumptions, the Y-system is uniformly Lipschitz continuous and continuous in \u03c4 . By Picard\u2019s existence theorem, it has a unique solution y(\u03c4 ; \u03b6, x0) with an infinite existence interval.\nFor \u03b6 \u2208 [0, 1), consider an integral along y(\u03c4 ; \u03b6, x0),\nf(y(T ; \u03b6, x0)) = f(x0)\u2212 \u222b T\n0 |\u2207f |2(1 + \u03b6 cos \u03b8)(y(\u03c4 ; \u03b6, x0))d\u03c4.\n3If \u03b6 = 0, the present system reduces to the normalized gradient flow for unconstrained minimization, which is shown to be finite-time convergent using nontrivial nonsmooth stability analysis [32, Theorem 8].\nLemma 5.2 ensures\u222b T 0 |\u2207f |2(1 + \u03b6 cos \u03b8)(y(\u03c4 ; \u03b6, x0))d\u03c4 = f(x0)\u2212 f(y(T ; \u03b6, x0)) \u2264M (51)\nwith some positive number M independent of T . Hence\u222b \u221e 0 |\u2207f |2(y(\u03c4 ; \u03b6, x0))d\u03c4 \u2264 M 1\u2212 \u03b6 < +\u221e. (52)\nNotice that\nd\nd\u03c4 |\u2207f(y(\u03c4 ; \u03b6, x0))| =\nd\nd\u03c4  n\u2211 j=1 ( \u2202f \u2202yj )2 12\n= 1\n2  n\u2211 j=1 ( \u2202f \u2202yj )2\u2212 12 n\u2211 j=1 d d\u03c4 ( \u2202f \u2202yj )2\n= 1\n|\u2207f | n\u2211 j=1 \u2202f \u2202yj n\u2211 k=1 \u2202 \u2202yk ( \u2202f \u2202yj ) dyk d\u03c4\n= 1\n|\u2207f | n\u2211 j=1,k=1 \u2202f \u2202yj \u22022f \u2202yjyk dyk d\u03c4\n= \u2212 1 |\u2207f | n\u2211 j=1,k=1 \u2202f \u2202yj \u22022f \u2202yj\u2202yk |\u2207f | ( 1 |\u2207f | \u2202f \u2202yk + \u03b6 |\u2207g| \u2202g \u2202yk ) .\nNotice that \u03b6 \u2208 [0, 1), we have\u2223\u2223\u2223\u2223 dd\u03c4 |\u2207f(y(\u03c4 ; \u03b6, x0))| \u2223\u2223\u2223\u2223 \u2264 n\u2211\nk=1,j=1\n\u2223\u2223\u2223\u2223 \u2202f\u2202yj \u2223\u2223\u2223\u2223 \u2223\u2223\u2223\u2223 \u22022f\u2202yk\u2202yj \u2223\u2223\u2223\u2223 ( 1|\u2207f | \u2223\u2223\u2223\u2223 \u2202f\u2202yk \u2223\u2223\u2223\u2223+ 1|\u2207g| \u2223\u2223\u2223\u2223 \u2202g\u2202yk \u2223\u2223\u2223\u2223) . By Cauchy-Schwarz inequality, we have\n\u2223\u2223\u2223\u2223 dd\u03c4 |\u2207f(y(\u03c4 ; \u03b6, x0))| \u2223\u2223\u2223\u2223 \u2264 |\u2207f | \u221a\u221a\u221a\u221a n\u2211 k=1,j=1 \u2223\u2223\u2223\u2223 \u22022f\u2202yk\u2202yj \u2223\u2223\u2223\u22232 \u221a\u221a\u221a\u221a n\u2211 k=1 ( 1 |\u2207f | \u2223\u2223\u2223\u2223 \u2202f\u2202yk \u2223\u2223\u2223\u2223+ 1|\u2207g| \u2223\u2223\u2223\u2223 \u2202g\u2202yk \u2223\u2223\u2223\u2223)2.\nFurther, we have n\u2211 k=1 ( 1 |\u2207f | \u2223\u2223\u2223\u2223 \u2202f\u2202yk \u2223\u2223\u2223\u2223+ 1|\u2207g| \u2223\u2223\u2223\u2223 \u2202g\u2202yk \u2223\u2223\u2223\u2223)2 = n\u2211 k=1 ( 1 |\u2207f |2 \u2223\u2223\u2223\u2223 \u2202f\u2202yk \u2223\u2223\u2223\u22232 + 2 1|\u2207f ||\u2207g| \u2223\u2223\u2223\u2223 \u2202f\u2202yk \u2202g\u2202yk \u2223\u2223\u2223\u2223+ 1|\u2207g|2 \u2223\u2223\u2223\u2223 \u2202g\u2202yk \u2223\u2223\u2223\u22232 )\n\u2264 n\u2211 k=1 2\n( 1\n|\u2207f |2 \u2223\u2223\u2223\u2223 \u2202f\u2202yk \u2223\u2223\u2223\u22232 + 1|\u2207g|2 \u2223\u2223\u2223\u2223 \u2202g\u2202yk \u2223\u2223\u2223\u22232 ) = 4.\nTherefore,\n\u2223\u2223\u2223\u2223 dd\u03c4 |\u2207f(y(\u03c4 ; \u03b6, x0))| \u2223\u2223\u2223\u2223 \u2264 2|\u2207f | \u221a\u221a\u221a\u221a n\u2211 k=1,j=1 \u2223\u2223\u2223\u2223 \u22022f\u2202yk\u2202yj \u2223\u2223\u2223\u22232. (53)\nBy assumption (A4) and Lemma 5.2, the right-hand side of above equation is bounded. There is a constant l so that\u2223\u2223\u2223\u2223 dd\u03c4 |\u2207f(y(\u03c4 ; \u03b6, x0))|\n\u2223\u2223\u2223\u2223 \u2264 l, \u2200\u03c4. Hence, we have a Lipschitz continuity for |\u2207f(y(\u03c4 ; \u03b6, x0))|:\u2223\u2223|\u2207f(y(\u03c4 \u2032; \u03b6, x0))| \u2212 |\u2207f(y(\u03c4 \u2032\u2032; \u03b6, x0))|\u2223\u2223 \u2264 l|\u03c4 \u2032 \u2212 \u03c4 \u2032\u2032|, \u2200\u03c4 \u2032, \u03c4 \u2032\u2032. (54) Now, we claim\nlim \u03c4\u2192+\u221e\n|\u2207f(y(\u03c4 ; \u03b6, x0))| = 0. (55)\nOtherwise, there is a sequence of \u03c4j \u2192 +\u221e and a positive constant b so that\n|\u2207f(y(\u03c4j ; \u03b6, x0))| \u2265 b > 0.\nChoosing \u03b4 = b2l , then\n|\u2207f(y(\u03c4 ; \u03b6, x0))| \u2265 |\u2207f(y(\u03c4j ; \u03b6, x0))| \u2212 ||\u2207f(y(\u03c4j ; \u03b6, x0))| \u2212 |\u2207f(y(\u03c4 ; \u03b6, x0))||\n\u2265 |\u2207f(y(\u03c4j ; \u03b6, x0))| \u2212 l|\u03c4j \u2212 \u03c4 | \u2265 b\u2212 \u03b4l = b\n2\nfor any |\u03c4j \u2212 \u03c4 | \u2264 \u03b4. Therefore,\u222b \u221e 0 |\u2207f(y(\u03c4 ; \u03b6, x0))|2d\u03c4 \u2265 \u221e\u2211 j=1 \u222b \u03c4j+\u03b4 \u03c4j\u2212\u03b4 |\u2207f(y(\u03c4 ; \u03b6, x0))|2d\u03c4\n\u2265 \u221e\u2211 j=1 \u222b \u03c4j+\u03b4 \u03c4j\u2212\u03b4 b2 4 d\u03c4 = \u221e\u2211 j=1 b3 4l = +\u221e.\nThis is a contradiction to (52). Hence\nlim \u03c4\u2192+\u221e\n|\u2207f(y(\u03c4 ; \u03b6, x0))| = 0. (56)\nThis means that y(\u03c4, \u03b6, x0) approaches the connected subset of the critical points. An isolated condition makes sure that\nlim \u03c4\u2192+\u221e y(\u03c4 ; \u03b6, x0) = xc, (57)\nfor some critical point xc of the objective function. Recall that the system (50) and (37) are orbit equivalent in E, therefore\nlim t\u2192T\u2212\u03b6,x0\nx(t; \u03b6, x0) = xc, \u2200\u03b6 \u2208 [0, 1). (58)\nRemark 3. The global behavior of the system (37) looks like a gradient flow. Obviously, as \u03b6 = 0, the system reduces to the normalized gradient flow of the objective function. Specifically, when converging to the same critical point, the present trajectory is homotopic with the gradient descent trajectory for \u03b6 \u2208 (0, 1) by the continuous dependence of the solutions to differential equations on parameters.\nRemark 4. The analytical trajectory may find a critical point of constraint g without condition (A3). In practical implementations, we suggest using the gradient descent \u2212\u2207f(x) to escape these critical points.\nRemark 5. We note that the assumption (A2) is excluded in Theorem 5.7. If there exists some critical point xc of f(x) in the feasible set \u2126, the optimization trajectory may converge to it (also compare to Lemma 5.9 where the assumption (A2) is included for the analysis). In such a case, obviously, a first-order solution is found for the considered constrained optimization problem. An example is illustrated in figure 1 for a 2D problem."
        },
        {
            "heading": "5.3. Global convergence to KKT solutions at the constraint boundary",
            "text": "In the previous subsection, we have shown that the continuous optimization trajectory converges to a critical point xc of the objective function f(x), regardless if xc lies in the feasible set \u2126 or not. For cases that xc \u2208 \u2126, this implies that we are able to use the present optimization trajectory to obtain a (first-order) optimal solution. What remains is the question of whether the present method can find a (near-optimal) solution at the constraint boundary, i.e., the second case presented in section 4.1. In the following, we give an affirmative answer to this question. To give a rigorous presentation, we shall first define what we meant by the wording \u201cfind\u201d, based on which we establish an error bound of the solution to a KKT point.\n5.3.1. A solution is found at the intersection point of the optimization trajectory and the constraint boundary\nAs illustrated in figure 2 of the second preliminary example, the optimization trajectories x(t; \u03b6, x0), with different \u03b6 values, converge to the critical point of the objective function while intersecting the constraint boundary at some time t. The larger the \u03b6 chosen, the closer the intersection point is to the KKT solution. We consider these intersection points as the solutions found by the present method to a single constrained problem. A formal definition is given as follows.\nDefinition 5.8. (Solution point x]\u03b6) Let \u03b6 \u2208 [0, 1) and x0 \u2208 \u2126, and suppose that the optimization trajectory x(t; \u03b6, x0) intersects the constraint boundary at a point x ] \u03b6 = x(t]; \u03b6, x0), where t ] \u03b6 is the minimum time for the trajectory to reach the constraint\nboundary. We say the intersection point x]\u03b6 is a solution point obtained by the system (DS) for the problem (SCOP). We have{ g(x(t]; \u03b6, x0)) = 0,\ng(x(t; \u03b6, x0)) < 0, t < t ].\n(59)\nNext, we argue that under the assumption (A1)\u2212 (A4), the optimization trajectory x(t; \u03b6, x0), with \u03b6 \u2208 [0, 1) and x0 \u2208 \u2126, always intersects the constraint boundary. Although this statement can readily be made by following Theorem 5.7, we give an independent and simple proof for clarity.\nLemma 5.9. Suppose that assumptions (A1) - (A4) hold, and let \u03b6 \u2208 [0, 1), x0 \u2208 \u2126. Then the trajectory x(t; \u03b6, x0) must go out of the feasible set. Hence, a solution point x]\u03b6 must exist.\nProof. We prove the lemma by contradiction. Suppose that x(t; \u03b6, x0) stays in the feasible set \u2126 for any t < T\u03b6,x0 , then the vector field s\u03b6 keeps C\n1 continuous in a neighborhood of trajectory x(t; \u03b6, x0)|[0,T\u03b6,x0 ), since there is no critical point of f(x) and g(x) in \u2126. Lemma 5.2 ensures that\n|\u2207f(x(t; \u03b6, x0))| \u2265 A, |f(x(t; \u03b6, x0)| \u2264 B, \u2200t < T\u03b6,x0 , (60)\nwith some positive numbers A and B. On the other hand, s\u03b6(x(t)) is uniformly Lipschitz continuous in x(t) by Lemma 5.4. Picard\u2019s existence theorem implies that T\u03b6,x0 = +\u221e. The integral of (38) shows (see also Remark 1)\u222b T\u03b6,x0\n0 |\u2207f(x(t; \u03b6, x0))|(1 + \u03b6 cos \u03b8)dt = f(x0)\u2212 f(x(T\u03b6,x0 ; \u03b6, x0)) <\u221e.\nFor any \u03b6 \u2208 [0, 1), 1 + \u03b6 cos \u03b8 > 0 holds, therefore\u222b \u221e 0 |\u2207f(x(t; \u03b6, x0))|dt <\u221e. (61)\n(61) is a contradiction to (60). This completes the proof.\n5.3.2. An upper bound of the solution time t] relative to \u03b6\nWe estimate the solution time t] that is equivalent for the trajectory x(t; \u03b6, x0) to reach the constraint boundary. An upper bound for t] is given as follows.\nLemma 5.10. Suppose that the assumptions (A1)- (A4) hold, and let \u03b6 \u2208 [0, 1), x0 \u2208 \u2126, the time in which the optimization trajectory x(t; \u03b6, x0) reaches the boundary of the feasible set is at most C1\u2212\u03b6 with C independent of \u03b6.\nProof. By Lemma 5.9, the trajectory x(t; \u03b6, x0) must go out of the feasible set. Let T ]\u03b6,x0 be the time in which the trajectory first reaches the boundary of the feasible set,\nthen (60) holds for 0 < t < T ]\u03b6,x0 . By (38),\u222b T ]\u03b6,x0 0 |\u2207f |(1 + \u03b6 cos \u03b8)dt = f(x0)\u2212 f(x(T ]\u03b6,x0 ; \u03b6, x0)) \u2264 2B. (62)\nHence\nT ]\u03b6,x0A(1\u2212 \u03b6) \u2264 2B, (63)\nwhich implies\nT ]\u03b6,x0 \u2264 2B\nA(1\u2212 \u03b6) , (64)\nso that T ]\u03b6,x0 \u2264 C 1\u2212\u03b6 holds. This ends the proof.\nLemma 5.10 implies that the system (DS) finds a solution x]\u03b6 in t ] \u2264 O( 11\u2212\u03b6 ).\n5.3.3. An upper bound of the solution error relative to \u03b6\nLastly, we shall give an error measure of a solution (intersection) point x]\u03b6 to a KKT solution x?. The KKT conditions for the problem (SCOP) write\n\u2207f(x?) + \u03bb?\u2207g(x?) = 0, (65a)\n\u03bb? = |\u2207f(x?)| |\u2207g(x?)| \u2265 0, (65b)\ng(x?) = 0. (65c)\nIt is obvious that the conditions (65a) and (65b) are equivalent to the normalized centrality condition (7), repeated as the follows for convenience,\n\u2207f(x) |\u2207f(x)| + \u2207g(x) |\u2207g(x)| = 0,\nIn addition, (65c) is satisfied with (59). Following the normalized central path condition (7), a proper residual for an intersection point x]\u03b6 can be defined using the L2-norm,\nrL2(x ] \u03b6) = \u2223\u2223\u2223\u2223\u2223 \u2207f(x ] \u03b6) |\u2207f(x]\u03b6)| + \u2207g(x]\u03b6) |\u2207g(x]\u03b6)| \u2223\u2223\u2223\u2223\u2223 . (66) Based on (66), we give a formal definition for an error measure .\nDefinition 5.11 (Solution error). An error measure for a solution point x]\u03b6 is defined as the L2-norm of the residual (66),\n(x]) = rL2(x ]). (67)\nIn the following, we show that the error of the method is upper bounded relative to the parameter \u03b6.\nTheorem 5.12. Suppose that assumptions (A1)-(A4) hold, and let \u03b6 \u2208 [0, 1), x0 \u2208 \u2126. Then, the solution error of x]\u03b6 is upper bounded in relative to the parameter \u03b6,\n(x]\u03b6) \u2264 \u221a 2(1\u2212 \u03b6). (68)\nProof. By Lemma 5.9, the optimization trajectory x(t; \u03b6, x0) must intersect the constraint boundary when initialized in the feasible set \u2126. By (59), we have at the intersection point x(t]; \u03b6, x0),\nd dt g(x]\u03b6) \u2265 0. (69)\nBy (39),\n|\u2207g(x]\u03b6)|(\u03b6 + cos \u03b8(x ] \u03b6)) \u2264 0. (70)\nThus,\ncos \u03b8(x]\u03b6) \u2264 \u2212\u03b6. (71)\nBy Definition 5.11, we have\n2(x]\u03b6) = 2(1 + cos \u03b8(x ] \u03b6)). (72)\nTherefore,\n(x]\u03b6) \u2264 \u221a 2(1\u2212 \u03b6).\nOur proof is thus complete.\nRemark 6. By Lemma 5.10 and Theorem 5.12, we can conclude that the time complexity for the optimization trajectory to achieve an approximate solution is\n|x]\u03b6 \u2212 x ?| \u2264 O( 1\u221a\nt ). (73)\nThe result matches the ergodic convergence rate of first-order methods for general optimization problems."
        },
        {
            "heading": "6. The method for multiple constraints: a formulation based on the logarithmic barrier function",
            "text": "Recall the logarithmic barrier function for the problem (COP),\n\u03a6(x) = \u2212 m\u2211 i=1 log(\u2212gi(x)), i = 1, ...,m.\nWe first notice that the barrier function grows without bound if gi(x)\u2192 0\u2212 and it is not differentiable at the boundary of the feasible set. To overcome this difficulty, we consider a subset of the feasible set,\n\u2126M = {x : \u03a6(x) \u2264M}, (74)\nwhere M is a sufficiently large positive number so that \u2126M approximates the original feasible set \u2126. The barrier function is twice continuously differentiable in \u2126M and thus fulfills the assumption (A4).\nSet\nGM (x) = \u03a6(x)\u2212M, x \u2208 \u2126M .\nThe original problem (COP) can be approximately reformulated as\nminimize f(x), subject to GM (x) \u2264 0, (75)\nso that the present system (DS) may be applied. Notice that the global behavior shown in section 5 is based on the assumption that \u2207g 6= 0 in the feasible set \u2126. In general, this may not always be the case for the function GM (x),\u2200x \u2208 \u2126M . To escape the points where \u2207\u03a6(x) = 0, we suggest using the gradient descent \u2212\u2207f(x). Thus we get a dynamical system for solving the approximate problem (75),\ndx dt = \u2212 \u2207f(x) |\u2207f(x)| \u2212 \u03b6 \u2207\u03a6(x) |\u2207\u03a6(x)| , if \u2207\u03a6(x) 6= 0;\n\u2212\u2207f(x) if \u2207\u03a6(x) = 0. (DSM)\nNote that in computational practice, \u2207\u03a6 = 0 rarely occurs. The second ODE of the above system serves as a safeguard for the present method.\nCorollary 6.1. Suppose that the assumptions (A1) (A2) and (A4) hold, and \u2207gi(x) 6= 0, i = 1, ...,m in the feasible subset \u2126M . Let x ] \u03b6 be the solution point of the system (DSM) for the approximate problem (75), then\nx]\u03b6 \u2208 {x : \u03a6(x) = M, cos \u03b8(x) \u2264 \u2212\u03b6}. (76)\nAnd the solution error to a KKT solution of the problem (75) is\n\u2264 O( \u221a 1\u2212 \u03b6).\nProof. A similar method as used in Theorem 5.12 gives the proof.\nTo conclude, using the barrier function formulation for problem (COP), the resulting trajectory achieves an approximated local solution that locates on the boundary of the subset \u2126M . Notice, too, that the system (DSM) does not depend on the choice of M , and \u2126M exhaust \u2126, i.e., \u2126 = \u222aM>0\u2126M . This means that the resulting trajectory keeps approaching the boundary of the original feasible set \u2126 by crossing the boundary of any subset \u2126M dependent on M . Therefore, it eases the practical implementation of the method since no extra parameter M needs to be defined for the stopping criterion, but rather, a check for each constraint violation would be sufficient."
        },
        {
            "heading": "7. Algorithms and preliminary computational experiments",
            "text": "We present two computational implementations of GDAM and show their preliminary computational tests on common benchmarks for both convex and nonconvex constrained optimizations."
        },
        {
            "heading": "7.1. Computational algorithms",
            "text": "When implementing the present method for the problem (COP), the canonical firstorder optimization procedure is given as below,\nxk+1 = xk + \u03b1ks\u03b6(xk), (77)\nwith\ns\u03b6(xk) = \u2212 \u2207f(xk) |\u2207f(xk)| \u2212 \u03b6 \u2207\u03a6(xk) |\u2207\u03a6(xk)| , if \u2207\u03a6(xk) 6= 0;\n\u2212\u2207f(xk) if \u2207\u03a6(xk) = 0.\nIn this work, we design computational algorithms for problems whose minimizers are non-trivially located at the constraint boundary, as is the case for our targeted applications, shape optimization and sensor network localization.\n7.1.1. Fix-length stepsize\nObviously, the choice of \u03b1k is essential to the computational performance of the method, and, certainly, there are many ways that can satisfy the purpose of the convergence. In this work, we propose a fixed-length step size rule for the method, i.e.,\n\u03b1k = \u03b2\n|s\u03b6(xk)| , (78)\nwhere \u03b2 is some positive parameter. As a result,\n|xk\u22121 \u2212 xk| = \u03b2. (79)\nThe step size rule can be considered aggressive, since at a central point xc, as \u03b6 \u2192 1\u2212, |s\u03b6(xc)| \u2192 0. A fixed-length step size (78) aggressively re-scales the step size using\nthe reciprocal of |s\u03b6(x)|, resulting in a finite variable update. A fix-length stepsize is also used in subgradient methods to deal with nonsmoothness at the solution by dynamically adjusting \u03b2 towards zero, see, e.g., [16, Proposition 3.2.7]. For constrained problems, when more than one inequality constraints are active at a solution, the solution vertex itself can be nonsmooth and contributes to the ill-conditioning of the logarithmic barrier function at its close neighborhood. A fix-length stepsize bounds the range of an update and can thus be considered a trust-region-like approach that stabilizes the iterative process. Finally, various line search methods can be added to dynamically adjust the parameter \u03b2.\n7.1.2. Vanilla implementation\nA vanilla implementation based on the fixed-length stepsize approach is summarized in the pseudocode in Algorithm 1. For constant parameter \u03b2, we terminate the optimization whenever a constraint is violated.\nAlgorithm 1 Vanilla GDAM\n1: Initialization: x0, \u03b6, \u03b2, \u03b2min, k = 0 2: while Stopping criteria is not met do 3: if \u2207\u03a6(xk) 6= 0 then\ns\u03b6(xk)\u2190 \u2212 \u2207f(xk)|\u2207f(xk)| \u2212 \u03b6 \u2207\u03a6(xk) |\u2207\u03a6(xk)|\n4: else s\u03b6(xk)\u2190 \u2212\u2207f(xk) 5: end if 6: Update: \u03b1k \u2190 \u03b1|s\u03b6(yk)| , xk+1 \u2190 xk + \u03b1ks\u03b6(xk), k \u2190 k + 1 7: (Line search to update \u03b2) 8: end while\nWhen an additional line search is equipped, the stopping criteria is set as to simultaneously fulfill the following two conditions:\n1. Any constraint is violated; 2. \u03b2 < \u03b2min.\nFor example, the algorithm can be equipped with a simple backtracking line search to improve the performance, i.e., we reduce the stepsize \u03b2 by a scaling factor \u03c4 whenever a constraint is violated until \u03b2 < \u03b2min.\n7.1.3. Accelerated implementation\nA prominent approach to improve the convergence rate of the gradient descent method is Nesterov\u2019s Accelerated Gradient (NAG) method [81]. We apply NAG to the present method by replacing the gradient descent update step with a GDAM update step. We summarize the pseudocode in Algorithm 2. Notice that compared to the vanilla implementation, a momentum parameter m and a sequence of auxiliary variables {yk} are added.\nThe following shows preliminary computational experiments of the proposed vanilla and accelerated GDAM algorithms on common benchmark tests. Computational results show that the present implementations are robust in finding near-optimal solutions, which can be desirable in practical engineering applications.\nAlgorithm 2 Accelerated GDAM\n1: Initialization: y0, \u03b2, \u03b2min, m, k = 0 2: Compute: \u03b10 =\n\u03b1 |s\u03b6(y0)| , x0 \u2190 y0 + \u03b10s\u03b6(y0), y1 \u2190 x0, k = 1\n3: while Stopping criteria is not met do 4: if \u2207\u03a6(xk) 6= 0 then\ns\u03b6(yk)\u2190 \u2212 \u2207f(yk)|\u2207f(yk)| \u2212 \u03b6 \u2207\u03a6(yk) |\u2207\u03a6(yk)|\n5: else s\u03b6(yk)\u2190 \u2212\u2207f(yk) 6: end if 7: Update: \u03b1k \u2190 \u03b2|s\u03b6(yk)| , xk \u2190 yk+\u03b1ks\u03b6(yk), yk+1 \u2190 xk+m(xk\u2212xk\u22121), k \u2190 k+1 8: (Line search to update \u03b2) 9: end while"
        },
        {
            "heading": "7.2. Experiments on IEEE CEC 2006 tests with the vanilla implementation",
            "text": "We first show numerical experiments for the inequality constrained problems presented at the EA competition at the 2006 IEEE Congress on Evolutionary Computation [66]. These benchmark tests are widely used in the community of evolutionary algorithms. We choose them as test examples for three reasons. First, they are well defined constrained optimization problems and have different characteristics [89]. Second, they are nontrivial to solve with first-order methods. Third, the relatively simple formulation of the optimization problems allows us to gain deeper insight into the numerical behavior of the present method. We choose the inequality constrained optimization problems for the experimentation. The problem G12 is excluded because it has a feasible set consisting of 93 disjointed spheres. For the problem G24, which has a feasible set consisting of two disconnected sub-regions, we choose initial designs in the sub-region that contains the reported optimal solution.\nWe conduct numerical experiments for the vanilla implementation (Algorithm 1) with \u03b6 = 0.98 and tuned fixed-length stepsize parameter \u03b2. All bound constraints are treated as inequalities. Random initializations that are away from the reported optimal solution are selected in the feasible sets. We evaluate the error in the objective function value by\nerr = |f(x?)\u2212 f(x\u03b6)|\n1 + |f(x?)| , (80)\nwhere x? is the reported global optimum. As shown in table 1, apart from the problem G19, vanilla GDAM finds solutions with objective function value errors less than 2e-2 compared to the reported global optima. This is somewhat surprising because GDAM is a local search algorithm. More accurate results can be obtained when we choose shorter step sizes and larger parameters \u03b6. For the problem G19, the reported optimal solution x? = (1.6699e-17, 3.9637e-16, 3.9459, 1.060e-16, 3.2831, 9.9999, 1.1283e17, 1.2026e-17, 2.5071e-15, 2.2462e-15, 0.3708, 0.2785, 0.5238, 0.3886, 0.2982) is not achievable with the present fixed-length stepsize rule with a reasonable constant parameter \u03b2. For the problems G01, G04, G06, G07, G08, G24, we find sub-optimal solutions that are close to the reported optimal designs. For the problems G09, G10, G18, G19, sub-optimal solutions close to local minima are found."
        },
        {
            "heading": "7.3. Experiments on Maros and Meszaros QPs with the accelerated implementation",
            "text": "The Maros and Meszaros test set [75] is a collection of hard convex quadratic programming problems from a variety of sources. The problems included are of the following form\nmin x\n1 2 xTHx+ cTx+ c0,\ns.t. Ax = b,\nl \u2264 x \u2264 u,\n(81)\nwhere x \u2208 Rn, H \u2208 Rn\u00d7n is a symmetric positive definite matrix, A \u2208 Rm\u00d7n is a sparse matrix, c, c0 \u2208 Rn, b \u2208 Rm, and l, u \u2208 Rn. Note that components of l and u may be infinite, and |c0| < +\u221e.\nThe algorithms 1 and 2 can easily be extended to handle linear equality constraints by the gradient projection method. Suppose that A is nondegenerate, following Rosen\u2019s method [91], the projection matrix for the subspace spanned by the linear equalities Ax = b writes\nPA = In \u2212AT (AAT )\u22121A. (82)\nThe projected vector vp of any vector v \u2208 Rn reads\nvp = PAv. (83)\nThen, the projected GDAM search direction writes,\ns\u03b6,P (xk) = \u2212 PA\u2207f(xk) |PA\u2207f(xk)| \u2212 \u03b6 PA\u2207\u03a6(xk) |PA\u2207\u03a6(xk)| . (84)\nPractically, we can precompute and store the projection matrix PA. For large-scale and sparse problems (n and m are large, and A is sparse), we may make use of Cholesky\nfactorization for AAT for more efficient computation. More advanced methods for treating linear equalities, such as [25], may be applied to the present method.\nWe use a subset of the Maros and Meszaros instances for the experiments. These instances were carefully chosen to cover a variety of problem models for performance comparisons among dedicated QP solvers [78]. We evaluate the error in the objective function value by\nerr = |objbest \u2212 obj| 1 + |objbest| , (85)\nwhere objbest is the smallest objective function value of the solvers. In table 2, we show the results of the present method and compare it with well-established solvers Matlab quadprog, Gurobi [46], and OSQP [101]. Both Matlab quadprog and Gurobi implement state-of-the-art second-order solvers for convex QPs, and OSQP is a firstorder convex QP solver based on the alternating direction method of multipliers [23]. For Matlab quadprog and Gurobi, we use the default settings. For OSQP, we set the absolute and relative tolerance to 1e\u2212 4 for more accurate solutions (default settings are both 1e\u2212 3). For GDAM, \u03b6 = 0.999 and a backtracking line search with reduction parameter \u03c4 = 0.3 are chosen. We set the maximum number of iterations to 10000 for both OSQP and GDAM. All experiments are run on a Linux workstation with a 2.70 GHz 6-core AMD Ryzen 5 5600U processor and 16 GB RAM.\nAs shown in table 2, accelerated GDAM finds near-optimal solutions for all instances except UBH1, which demonstrates its robustness. Gurobi is the fastest and the most robust solver in general. GDAM is more efficient in solving the instances CVXQP*. By setting smaller tolerances and a larger number of maximum iterations, OSQP finds more accurate solutions for the instances BOYD1, CONT*, and DTOC3. We note that\nno presolve and preconditioning strategies have been implemented for GDAM, unlike other mature QP solvers, since the goal here is to show the robustness of the present algorithm. On the other hand, it leaves room for improvements in computational efficiency."
        },
        {
            "heading": "8. Application to Shape Optimization",
            "text": "We show applications of vanilla GDAM (Algorithm 1) to shape optimization problems arising in Computational Mechanics. We begin by briefly introducing the shape optimization framework used in this work and then show the optimization results using GDAM."
        },
        {
            "heading": "8.1. Vertex Morphing",
            "text": "The shape optimization problems we aim to solve are almost always ill-posed due to the very large discrete design space based on the finite element mesh. To tackle the problem, we use the Vertex Morphing method (VM) introduced in [52].\nThe idea of the Vertex Morphing is to control the discrete surface coordinates x = [x1, x2, ..., xn] T with design controls p = [p1, p2, ..., pn] T , filtered by a filter function. The explicit filtering used in VM is the convolution of the coordinate field x with a kernel. In the discretized system, it is a matrix-vector multiplication that is the summation of nodal contributions that are weighted with the kernel function. VM distinguishes itself with standard explicit filtering, in which it applies the filtering process twice.\nFirst, the so-called forward mapping step that uses the linear filtering matrix R is defined as follows:\nxi = Rijpj . (86)\nSimilarly, the change of the control \u03b4p is mapped onto the change of the design configuration \u03b4x\n\u03b4xi = Rij\u03b4pj . (87)\nThe design controls are the control variables of the gradient-based optimization. The number of variables is equivalent to the number of surface coordinates. Following the chain rule of differentiation, the sensitivities of a response function \u03a8 with respect to the discretized geometry x are backward mapped to the design control using the adjoint or backward mapping matrix R\u2217, with R\u2217 = RT for regular grids,\nd\u03a8 dpi = d\u03a8 dxj dxj dpi = Rji d\u03a8 dxj . (88)\nEquations (87) and (88) can be used in a gradient descent framework, ensuring smooth shape updates in each iteration."
        },
        {
            "heading": "8.2. Academic example",
            "text": "First, we show an academic convex problem. The objective is to maximize the volume of a small sphere. This small sphere is located inside a bigger sphere that acts as the geometric constraint. The shape of both spheres are represented with finite element meshes [114]. The optimization problem writes\nminimize \u2212 V (x), subject to gi(x) \u2264 0, i = 1, ...,m,\n(89)\nwhere V (x) is the volume function, gi(x) is a point-wise defined geometric constraint for the i-th design node, m is the number of nodes of the design mesh, and x \u2208 R3m is the field of nodal coordinates of the design sphere mesh. The number of nodes of the small sphere (design sphere) is 19897. Thus, the total number of design variables is 59691 and the total number of constraints is 19897. We use the logarithmic barrier function for multiple constraints and choose the parameter \u03b6 = 0.95. In figure 3, the shape variation process with depicted iterations is shown. Initially, the design sphere is located close to the boundary of the constraint sphere. During the shape variation process, it moves towards the center of the constraint sphere while adapting its shape at each iteration. One could recognize easily that the central path of this optimization problem is being approached and followed until the solution is found when constraints become active."
        },
        {
            "heading": "8.3. Real-world example",
            "text": "We consider a real-world application to shape optimization. The present method is implemented in ShapeModule, which is a flexible solver-agnostic optimization platform and provides optimization algorithms as well as shape control methods, such as Vertex Morphing [52]. The optimization problem is to minimize the mass of a frame structure under load-displacement constraint (i.e., the displacement of every surface node is bounded). The optimization problem writes\nminimize M(x), subject to gi(x, u) \u2264 0, i = 1, ...,m, (90)\nwhere M(x) is the function for the mass, gi(x, u) is a point-wise formulated displacement constraint for the i-th node, m is the number of nodes of the design surface mesh, x \u2208 R3m is the field of nodal coordinates of the design surface mesh, and u \u2208 R3m is the nodal displacement field. The number of design variables is 144423, and the number of constraints is 48141. Note that for multiple constraints, we can use the logarithmic barrier function formulation as in the previous test examples. Each single displacement constraint gradient can be efficiently computed using the adjoint sensitivity analysis. In this application, we use the load-displacement sensitivity provided by the software OptiStruct to conform with a standard industrial design chain. We choose the parameter \u03b6 = 0.95. We note that there is a rather large gap between our theoretical analysis and the large-scale implementation of the method, as our results are asymptotic and the oracle is a black-box. Nevertheless, we were able to obtain results that are qualitatively in agreement with our theory.\nIn figure 4 we show the initial frame design and the optimized shape design after 194 iterations. The mass of the structure is reduced by 41% as shown in figure 5a. In figure 5b, we show a plot of maximum constraint value g = max{gi} of each iteration. In figure 6, we show that the optimization is able to approach and follow a central path within the \u03b6-neighborhood.\nRemark 7. By following a central path, an intermediate design improves not only the objective function but also the constraint function. Take the design of iteration 80 as an example: the mass is reduced by 20.5%, and the displacement is reduced by 12.1%. These designs may enrich the design options if the original problem is reformulated as a bi-objective optimization problem, in which both mass and the maximum displacement are set as objectives. The resulting intermediate designs alongside a central path are approximated Pareto solutions.\nRemark 8. This section focuses on the vanilla implementation of GDAM and demonstrates its robustness in solving node-based shape optimization problems, as robustness is considered a key to practical success for real-world shape design applications [20]. Accelerated GDAM can be applied to further reduce the number of iterations. However, both accelerated GDAM and Vertex Morphing introduce their own auxiliary variables into the optimization process: {yk} in the Algorithm 2 for GDAM and the control variables p in Vertex Morphing, respectively. Moreover, the forward and backward mapping between the control space and variable space in VM makes an application of accelerated GDAM even more delicate. The most efficient and robust way to combine both methods is worthy of further investigation. And this is of independent interest than this manuscript, which we leave to future work."
        },
        {
            "heading": "9. Application to Sensor Network Localization via Semidefinite Programming",
            "text": "In this section, we apply the present method to solve sensor network localization (SNL) problems via the semidefinite programming (SDP) formulation [18]. First, we briefly introduce the basics of SDP-based SNL, after which we show computational experiments and comparisons with state-of-the-art first- and second-order SDP solvers."
        },
        {
            "heading": "9.1. Sensor Network Localization via Semidefinite Relaxation",
            "text": "Sensor Network Localization (SNL) aims to recover unknown sensor locations with (partially) given distance information between them, and thus can be considered an inverse problem. Consider a nonlinear least square (NLS) formulation for SNL problems with n sensors and m anchors in 2d:\nmin x1,...,xn\u2208R2 \u2211 (i,j)\u2208M ( |xi \u2212 xj |2 \u2212 d2ij )2 + \u2211 (k,j)\u2208M\u0304 ( |ak \u2212 xj |2 \u2212 d2kj )2 , (NLS)\nwhere the location of each sensor xi \u2208 Rd, i = 1, ..., n, is to be determined, and the location of each anchor ak \u2208 R2, k = 1, ...,m is known. The distance {dij : (i, j) \u2208M} and {dkj : (k, j) \u2208 M\u0304} are known observations between sensor-sensor pairs and sensoranchor pairs, respectively. Often, the distances are detected in a given radius r.\nWe can formulate SNL as a constrained optimization problem,\nmin x1,...,xn\u2208R2 0,\ns.t. |xi \u2212 xj |2 = d2ij , (i, j) \u2208M |ak \u2212 xj |2 = d2kj , (k, j) \u2208 M\u0304\n(91)\nSNL is a typical nonconvex quadratic optimization problem [72][80] for which one is not content with finding a local solution but the global optimum, so that the true sensor locations can be recovered. Following the work [18], we relax the NP-hard nonconvex problem (91) using SDP. First, we rewrite the distances of sensor-sensor pairs,\n|xi \u2212 xj |2 = (ei \u2212 ej)TXTX(ei \u2212 ej) = \u3008Eij , XTX\u3009, (92)\nwhere ei \u2208 Rn is the i-th unit vector, X is a 2\u00d7n matrix whose i-th column is xi, and Eij = (ei \u2212 ej)(ei \u2212 ej)T \u2208 Sn. Similarly, we have\n|ak \u2212 xj |2 = [ aTk ,\u2212eTj ] [ I2 X XT XTX ] [ ak \u2212ej ] = \u3008M\u0304kj , Z\u3009, (93)\nwhere\nM\u0304kj = [ ak \u2212ej ] [ aTk ,\u2212eTj ] ,\nand\nZ = [ I2 X XT XTX ] . (94)\nFurthermore, let\nMij = [ 0 0 0 Eij ] . (95)\nBy lifting the variables, we obtain an equivalent formulation in the variable Z \u2208 Sn+2 for (91),\nmin 0,\ns.t. \u3008Mij , Z\u3009 = d2ij , (i, j) \u2208M \u3008M\u0304kj , Z\u3009 = d2kj , (k, j) \u2208 M\u0304 Z1:2,1:2 = I2, Z 0, rank(Z) = 2.\n(96)\nThe problem (96) is, still, a very challenging nonconvex optimization problem. However, by lifting the variable, the nonconvexity is now only allocated at the rank constraint\nrank(Z) = 2.\nThe semidefinite relaxation is to drop out this rank constraint, and thus a convex optimization problem is obtained,\nmin 0,\ns.t. \u3008Mij , Z\u3009 = d2ij , (i, j) \u2208M \u3008M\u0304kj , Z\u3009 = d2kj , (k, j) \u2208 M\u0304 Z1:2,1:2 = I2, Z 0.\n(SNLP)\nThe dual of (SNLP) writes,\nmax V,y\n\u3008I2, V \u3009+ \u2211\n(i,j)\u2208M\nyijd 2 ij + \u2211 (k,j)\u2208M\u0304 ykjd 2 kj\ns.t. [ V 0 0 0 ] + \u2211 (i,j)\u2208M yijMij + \u2211 (k,j)\u2208M\u0304 ykjM\u0304kj + S = 0,\nS 0.\n(SNLD)\nThe semidefinite relaxation is mathematically elegant, and many applications show that, indeed, SDRs result in tight approximations to the original NP-hard problems, see, e.g., the seminal work on the maximum cut problem [42]. In the case of SNL, the work [97] shows that SDR provides the exact solution to the original problem if the sensors are uniquely localizable with provided distance information. On the other\nside, the cost of SDR is the much-increased problem dimensions and the introduced nontrivial PSD cone constraint, which are computationally challenging for large-scale applications.\nNotice that the SDR formulation (SNLP) of an SNL problem is a feasibility program \u2014any feasible solution solves the optimization problem. The present method is not directly applicable since the optimization iterates in the feasible set. On the other hand, the dual formulation (SNLD) is an inequality constrained problem and is, therefore, a well-suited optimization formulation for the present method. We implement the accelerated GDAM (Algorithm 2) in MATLAB R2022a to solve the dual problem (SNLD). Further details on implementation are reported in Appendix B."
        },
        {
            "heading": "9.2. Sensor Network Localization examples",
            "text": "We randomly generate a set of examples with n nodes representing the true sensor locations [\u22120.5, 0.5]2, with n ranging from 100 to 10000. Additional four anchor nodes are generated whose positions are known a priori. A total of m pairs of distances information are measured within a radio detection range r. To measure the estimation accuracy, we use the root-mean-square-distance (RMSD), which has been widely used on SNL to test the performance and is defined as\nRMSD =\n( 1\nn n\u2211 i=1 |xi \u2212 xtruei |2 )1/2 , (97)\nwhere xi is the estimated position and x true i is the true position of sensor i, respectively. All experiments are run on a Linux workstation with a 2.70 GHz 6-core AMD Ryzen 5 5600U processor and 16 GB RAM.\n9.2.1. GDAM results\nWe report the runtimes and RMSDs of the present method in table 3. It can be seen that the obtained solutions are of moderate accuracy in terms of the RMSD. The eigenvalues of the solution matrices Z show that they are near rank 2 matrices. Thus, the present method not only solves the SDR problem (SNLP) approximately, but also solves the rank-constrained SDP problem (96) to moderate accuracy. As (96) is equivalent to the original feasibility problem (91), we can hope that the present method provides near-optimal solutions to the original NP-hard SNL problems. Indeed, as we observed in our extensive numerical experiments, using the obtained SDR solutions as initializations, we can accurately recover all the true sensor locations by applying local search methods such as gradient descent for (NLS). We show some of the graphical results in figure 7 and 8. The left figures show the results obtained by applying accelerated GDAM for the SDR (SNLD); the right figures show refinements of the GDAM solutions by applying gradient descent to the original and low-dimensional problem (NLS).\n9.2.2. Comparisons\nWe compare results in terms of runtime and RMSD with three well-established solvers: DSDP v5.8 [15], a generic SDP solver based on a second-order dual interior-point method, SCS (Splitting Conic Solver) version 3.1.0 [82], a generic large-scale conic solver based on ADMM, and SDPNAL+ version 1.0 [103], a large-scale SDP solver based on a semismooth Newton-CG augmented Lagrangian method. We run the same examples listed in table 3.\nDSDP: We use the default settings of DSDP, where the tolerance for the optimality gap is set to be 1e\u22126. DSDP is an efficient second-order solver for SNL problems that exploits the problem feature which leads to reduced storage and increased efficiency. Table 4 shows that DSDP can solve problems to very high accuracy. For problems with size n \u2265 1500, the workstation is running out of memory. While DSDP achieves high accuracy for the SNL problems, GDAM requires a much less time in finding an approximate solution. To recover the true sensor locations, we run GD for the lowdimensional nonlinear least squares problem (NLS), a well-established approach for SNL problems [17] that belongs to the general two-phase strategy for solving SDP\nrelaxation problems, where a SDP solutions is used as an initialization for nonlinear programming methods to locally solve the original NP-hard problem [72].\nSCS: We use \u2018sparse-indirect\u2019 for the linear solve setting and choose convergence tolerances between tol. = 1e\u22122 and tol. = 1e\u22124, and set the maximum runtime to be 24 hours. We observe that SCS encounters numerical difficulties if the objective is set to be empty, as is the case of our feasibility formulation (SNLP). Therefore, We add an objective \u00b1trace(Z) to the model. We find that the runtime is quite sensible with the choice of the sign. Therefore, we tuned the sign \u00b1 and report results with better performance. We use Yalmip (Version 31-March-2021) [69] for the problem modeling and the interface to SCS.\nWe report the results of SCS in table 5. For problems with n \u2264 1500, a tolerance with 1e\u22123 yields comparably accurate results as GDAM. For the problem with n = 3000, a smaller tolerance 1e\u22124 is needed to obtain a good estimation as initialization for local refinement, as shown in figure 9. For all the instances, GDAM is more competitive in the runtime. For example, for the problem with n = 3000, GDAM takes about 12 minutes to find a moderate accurate solution with RMSD = 5.38e\u2212 3, and SCS finds an inferior solution after five and a half hours.\nSDPNAL+: SDPNAL+ v1.0 is a two-phase solver in which an ADMM algorithm is used in phase I to provide an initial point for the phase II algorithm, which is a semismooth Newton-CG augmented Lagrangian method. We use the default settings of SDPNAL+ and set the tolerances to 1e\u22122 and 1e\u22123, and set the maximum runtime to be 24 hours. We solve the test examples shown in section 9.2.1 and report results in table 6. Comparing table 6 and table 5, we see that the performance of SDPNAL+ and SCS are fairly close. In about the same runtime, SDPNAL+ finds more accurate solutions for problems with n \u2264 1500, while SCS finds a more accurate solution for the problem with n = 3000 (see SDPNAL+ result in figure 10). A comparison of table 6 and table 3 shows that GDAM is more efficient than SDPNAL+ in finding moderate accurate solutions in terms of RMSD for the considered SNL problems.\nRemark 9. Large-scale semidefinite programs arising from the relaxation of SNL problems are challenging convex optimization problems. Even advanced large-scale SDP solvers, such as SCS and SDPNAL+, need to make a compromise between the computational time and the accuracy of a solution. A practical difficulty lies in how\nto choose such a tolerance a priori. Take the example of n = 3000, SCS requires tol. = 1e \u2212 4 to obtain a moderate accurate localization solution, which is an order of magnitude smaller than that required for problems with n \u2264 1500. For the same problem n = 3000, a practical tolerance for SDPNAL+ may lie between 1e \u2212 2 and 1e\u2212 3, whereas the difference in the runtime of the two tolerances is about 18 hours. On the other hand, without the knowledge of the true sensor locations, it may not be straightforward to design a practical stopping criterion. In this regard, GDAM shows its practical advantage by only using a single fixed parameter \u03b6 = 0.9999 (universally for different numbers of sensors, radius, and anchor locations). In theory, \u03b6 is related to solution accuracy (see Theorem 5.12), but its practical implications for large-scale SDP problems may be more profound, which is worth further investigation.\nRemark 10. Compared to SCS and SDPNAL+, the number of iterations needed for GDAM increases only slowly as the dimension of the problem grows. Indeed, GDAM is the only method we are aware of that is capable of solving the SDP model (SNLP) (or (SNLD)) to 10000 sensors on a laptop workstation. This clearly shows the potential of GDAM as a practical optimization method for some of the large-scale and difficult constrained optimization problems."
        },
        {
            "heading": "10. Discussion",
            "text": "This paper proposes a gradient descent akin method for solving constrained optimization problems. GDAM may be considered a gradient descent method for constrained optimization and a first-order interior-point method. We give essential theoretical guarantees on the global convergence of the method to first-order solutions. We present computational algorithms based on GDAM and show their applications to two engineering problems, shape optimization and sensor network localization. Computational experiments demonstrate that GDAM is robust and very competitive in finding moderate accurate solutions and scales well to very large problems. Given the rather big difference in the characteristics of the two applications, we believe that GDAM could be suitable for other large-scale constrained optimization problems by providing inexact but useful solutions."
        },
        {
            "heading": "Acknowledgements",
            "text": "The author LC thanks the financial support of the German National High Performance Computing (NHR) Alliance. We are grateful to the ShapeModule team at the BMW Group for providing a real-world model and their shape optimization framework."
        },
        {
            "heading": "Appendix B. Implementation detail of GDAM for SNL",
            "text": "We report more implementation details in addition to the section 7.1 for solving the SNL problems.\nB.1. Logarithmic barrier function for the positive semidefinite cone constraint\nIn the following, we briefly show how the PSD constraint can be tackled using the standard logarithmic barrier function. For the primal SDP formulation (SNLP), the PSD cone constraint of the matrix variable Z 0 can be expressed as Z only has non-negative eigenvalues, i.e.,\n\u03bbi \u2265 0, i = 1, ..., n, (B1)\nwhere we assume Z \u2208 Sn for a general presentation. Using the logarithmic barrier function for (B1), we have\n\u03a6(Z) = n\u2211 i=1 \u2212 log \u03bbi = \u2212 log (\u03a0ni=1\u03bbi) = \u2212 log (det(Z)) . (B2)\nThe gradient of \u03a6(Z) with respect to the matrix variable Z writes\n\u2202\n\u2202Zij (\u2212 log detZ) = \u2212\n( Z\u22121 ) ji . (B3)\nFor the dual SDP formulation (SNLD), the PSD cone constraint can be formulated similarly. Notice now that the variable is the dual variable y, and so we have\n\u03a6(y) = \u2212 log [det(S(y))] . (B4)\nThe gradient of \u03a6(y) writes\n\u2202\n\u2202yi\n( \u2212 log [det(S)] ) = \u3008S\u22121,Ai\u3009Sn , (B5)\nwhere A = {Mij , M\u0304kl, (i, j) \u2208 M, (k, l) \u2208 M\u0304}. From (B3) and (B5), we see that in order to use a gradient-based method with the logarithmic barrier framework, a matrix inversion needs to be done for a matrix in Sn for both the primal and dual formulation.\nB.2. Presolve\nPresolve is an important part of the practical implementation of optimization algorithms that transforms the input problem into an easier one. For SNL problems, we use a simple presolve strategy that rescales the network geometry to the range [\u22125, 5]2. Numerically, it can be regarded as a preconditioning of the formulated dual SDP problem (SNLD). Compared to the canonical sensor range [\u22120.5, 0.5]2, which is often presented the literature, the dual IPM solver DSDP justifies the efficacy of our presolve strategy with a reduced number of iterations. We note that general purpose presolve/preconditioning strategies (see, e.g., [113]) will probably further improve the performance of the method, which we leave for future work.\nB.3. Strictly feasible initialization\nDifferent initialization strategies are available for IPMs in solving SDPs. In this work, we use the Phase I-then-Phase II method, i.e., we first try to find a feasible point (and in our case one for the dual problem), and then start the main solve routine. Notice that the dual problem (SNLD) is feasible when V = 0 and yij = 0 for all (i, j) \u2208M and ykj = 0 for all (i, j) \u2208 M\u0304, and we denote this zero initialization as y0 for convenience. The point y0 is, however, not an interior point in the feasible set for which we can start GDAM. To overcome this, we propose to run a few steps of gradient descent,\nstarting from y0, for the following auxiliary logarithmic barrier problem,\nmin \u2212 log det ( \u03bbIn+2 \u2212 [ V 0 0 0 ] \u2212 \u2211 (i,j)\u2208M yijMij \u2212 \u2211 (k,j)\u2208M\u0304 ykjM\u0304kj ) , (B6)\nwhere \u03bb is a positive number, which we choose to be 10.0 in our implementation. After a few steps of GD, an feasible interior initialization for the dual problem (SNLD) can be readily obtained.\nB.4. Main solve\nAfter a strictly feasible initialization is found, the main solution phase starts that applies the accelerated Algorithm 2 for the dual problem (SNLD). To further improve the practical performance, we developed adaptive stepsize and restart strategies, whose heuristics were tuned for the SNL problems. We implement a backtracking-like stepsize rule for the iterate to remain in the feasible set, i.e., the stepsize is reduced by a scaling factor whenever a constraint is violated. We choose the initial stepsize to be \u03b10 = 1.618e1 and set the minimum stepsize to be \u03b1min = 1e\u22128. The restart strategy is motivated by the work [83]. Specifically, we restart the optimization algorithm when the objective function value increases or the objective reduction is heavily slowed down4. For efficiency, we do not reset the stepsize to \u03b10, but to a multiple of the stepsize prior to the restart, i.e., \u03b1r+1 = \u03ba\u03b1r, where \u03ba is a constant and r is the index of each restart. It should be noted that the implemented heuristic strategies are still basic, and more sophisticated methods can be used to further enhance the practical performance. Nonetheless, we found the present implementation is robust and scales well to large-scale problems.\nB.5. Postsolve\nAfter solving the dual SDR problem (SNLD), an additional step is needed to recover the primal solution Z that contains the actual sensor locations. Denote the feasible sets of (SNLP) and (SNLD) by Fp and Fd, respectively. Denote F = Fp\u00d7Fd, and the interior of F by o F . Assume that o F 6= \u2205, the central path of a SDP can be expressed as\nC = {(Z, y, S) \u2208 o F : ZS = \u03b7I, 0 < \u03b7 <\u221e}, (B7)\nwhere \u03b7 is the barrier parameter (compare (5)), I is the identity matrix. The primal solution Z can be recovered from the dual solution S by\nZ = \u03b7S\u22121, (B8)\n4In our practical implementation, the objective function values are monitored in a fixed frequency.\nwhere \u03b7 is the barrier parameter, and, within the computational framework of GDAM, it can be approximated by (11),\n\u03b7(x]\u03b6) = \u03b6 |\u2207f(x]\u03b6)|\n|\u2207\u03a6(x]\u03b6)| ,\nwhere x]\u03b6 is a solution found by the parameter \u03b6. To achieve higher accuracy, we run GDAM with \u03b6 = 1.0 by taking the optimizer of the main solve as the initialization. In our implementation, we set \u03b1min = 1e \u2212 10 for the postsolve. Note that smaller \u03b1min (for both the main solve and the postsolve) leads to more accurate solutions. However, too small step sizes result in (almost) singular matrices for S, and numerical instabilities occur when inverting them."
        }
    ],
    "title": "A gradient descent akin method for constrained optimization: algorithms and applications",
    "year": 2023
}