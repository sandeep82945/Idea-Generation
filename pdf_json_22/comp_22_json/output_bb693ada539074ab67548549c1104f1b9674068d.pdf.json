{
    "abstractText": "The disco v ery potential from astronomical and other data is limited by their noise. We introduce a no v el non-parametric noise reduction technique based on Bayesian inference techniques, fully adaptive Bayesian algorithm for data analysis ( FABADA ) that automatically impro v es the signal-to-noise ratio of oneand two-dimensional data, such as astronomical images and spectra. The algorithm iteratively evaluates possible smoothed versions of the data, the smooth models, estimating the underlying signal that is statistically compatible with the noisy measurements. Iterations stop based on the evidence and the \u03c72 statistic of the last smooth model. We then compute the expected value of the signal as a weighted average of the whole set of smooth models. We explain the mathematical formalism and numerical implementation of the algorithm, and e v aluate its performance in terms of the peak signal-to-noise ratio, the structural similarity index, and the time payload, using a battery of real astronomical observations. Our FABADA yields results that, without any parameter tuning, are comparable with standard image processing algorithms whose parameters have been optimized based on the true signal to be reco v ered, something that is impossible in a real application. On the other hand, state-of-the-art non-parametric methods, such as block-matching and three-dimensional filtering, offer slightly better performance at high signal-to-noise ratio, while our algorithm is significantly more accurate for extremely noisy data, a situation usually encountered in astronomy.",
    "authors": [
        {
            "affiliations": [],
            "name": "Pablo M. S \u0301anchez-Alarc \u0301on"
        }
    ],
    "id": "SP:af254b643ea5b6a50d9aa95b7239fe6ab4a97d75",
    "references": [],
    "sections": [
        {
            "text": "RASTAI 2, 129\u2013141 (2023) https://doi.org/10.1093/rasti/rzad006 Advance Access publication 2023 March 16\nFully adapti v e Bay esian algorithm for data analysis: FABADA\nPablo M. S \u0301anchez-Alarc \u0301on 1 , 2 \u2039 and Yago Ascasibar 3 1 Instituto de Astrof \u0301\u0131sica de Canarias, c/ V \u0301\u0131a L \u0301actea s/n E-38205, La Laguna, Tenerife, Spain 2 Departamento de Astrof \u0301\u0131sica, Universidad de La Laguna, E-38206, La Laguna, Tenerife, Spain 3 Departamento de F \u0301\u0131sica Te \u0301orica, Universidad Aut \u0301onoma de Madrid, E-28049 Madrid, Spain\nAccepted 2023 January 30. Received 2023 January 20; in original form 2022 August 24\nA B S T R A C T The disco v ery potential from astronomical and other data is limited by their noise. We introduce a no v el non-parametric noise reduction technique based on Bayesian inference techniques, fully adaptive Bayesian algorithm for data analysis ( FABADA ) that automatically impro v es the signal-to-noise ratio of one- and two-dimensional data, such as astronomical images and spectra. The algorithm iteratively evaluates possible smoothed versions of the data, the smooth models, estimating the underlying signal that is statistically compatible with the noisy measurements. Iterations stop based on the evidence and the \u03c72 statistic of the last smooth model. We then compute the expected value of the signal as a weighted average of the whole set of smooth models. We explain the mathematical formalism and numerical implementation of the algorithm, and e v aluate its performance in terms of the peak signal-to-noise ratio, the structural similarity index, and the time payload, using a battery of real astronomical observations. Our FABADA yields results that, without any parameter tuning, are comparable with standard image processing algorithms whose parameters have been optimized based on the true signal to be reco v ered, something that is impossible in a real application. On the other hand, state-of-the-art non-parametric methods, such as block-matching and three-dimensional filtering, offer slightly better performance at high signal-to-noise ratio, while our algorithm is significantly more accurate for extremely noisy data, a situation usually encountered in astronomy.\nKey words: methods: data analysis \u2013 methods: statistical \u2013 techniques: image processing \u2013 techniques: spectroscopic.\n1\nT s a T o a e o r l i s r\no o n i t m fi\nd n ( Z r f c a 2\nt d a B m t s a t a d t h\n\u00a9 P C p\nD ow nloaded from https://academ ic.oup.com /rasti/article/2/1/129/7079157 by Indian Institute of Technology Patna user on 25 January 2024 . I N T RO D U C T I O N he acquisition of any kind of experimental data is affected by everal sources of statistical error, which ultimately translate into random noise component in the measurements to be recorded. here are different types of noise depending on their physical rigin, both related to electronic (thermal noise and fluctuations) nd mechanical (non-perfect lenses, antennas, etc.) devices. For xample, in astronomy, errors can be produced in the acquisition f the images due to defects in the optics of the telescopes and in the ead-out process of the detector (typically a CCD) transforming the ight captured by the telescope into an electrical signal. The noise ntroduced can sometimes be comparable to or even larger than the ignal, and different image processing algorithms may be used to eco v er the information that is buried deep in the data.\nSmoothing, where measurements are weighted at nearby spatial r temporal points (using different schemes to assign weights), is ne of the most popular techniques to mitigate the effects of random oise (Savitzky & Golay 1964 ; Cle veland 1979 ). No wadays there s a large number of smoothing algorithms based on many different echniques (e.g. see Goyal et al. 2020 , for a re vie w), such as central\no ving av erage, data grouping/se gmentation (Dabo v et al. 2007 ), tting smooth functions, different types of statistical analysis, partial\nE-mail: pmsa.astro@gmail.com\na s a\n2023 The Author(s) ublished by Oxford University Press on behalf of Royal Astronomical Society. Th ommons Attribution License ( http://cr eativecommons.or g/licenses/by/4.0/), whic rovided the original work is properly cited.\nifferential equations, wavelength transformation filters, linear and on-linear filtering, sparse models, non-local self-similarity models Gu et al. 2014 ), and more recently artificial neural networks (see hang et al. 2017 ; Ilesanmi & Ilesanmi 2021 ). Rest of these methods ely on some explicit or implicit assumptions about the true (noiseree) signal in order to separate it properly from the random noise. A ommon assumption is that the signal being retrieved varies gradually nd that the data can be fit by a smooth function (see Katkovnik et al. 006 ). Many techniques analyse the probability that the data correspond o a random Gaussian realization of the model that attempts to escribe the underlying signal plus random fluctuations of known mplitude (El Helou & Susstrunk 2020 ). In this work, we use ayesian inference to e v aluate and combine different candidate odels that iteratively attempt to impro v e the quality of the fit to he data. This new Bayesian technique incorporates an automatic election criterion based on the statistical properties of the residuals, nd therefore it yields a fully non-parametric method. Although he moti v ation of our scheme is the application in the field of stronomy, our new algorithm, fully adaptive Bayesian algorithm for ata analysis ( FABADA ) is focused in a general way, and it is possible o generate a smooth model for any type of data. Several algorithms av e been dev eloped o v er the years for denoising data, and their bility to reco v er the underlying signal from an experimental data et with its corresponding errors has been e v aluated and compared ccording to different standard metrics. Our method is fully described\nis is an Open Access article distributed under the terms of the Creative h permits unrestricted reuse, distribution, and reproduction in any medium,\nR\nTable 1. List of all symbols used to describe the FABADA algorithm in Section 2 .\nSymbol Definition\nDimensions x \u2208 X Coordinates of the data set (either 1D or 2D coordinates) i Iteration number { 1, 2,.., N i }\nInputs I = { z , e } Set of inputs of the algorithm z = z ( x ) Observational measurements e = e ( x ) Errors associated to the measurements\nModels m i = m i ( x ) Set of all possible models with shape ( N X , N i ) \u03bci = \u03bci ( x ) Expectation value of the element x of the model m i v i = v i ( x ) Associate variance of the expectation value L ( z| m i , e) Likelihood of the model m i E( m i ) Evidence of the model m i\nPriors p ( m i ) Prior probability distribution of the model m i \u02dc \u03bci Central moving mean of \u03bci along N avg neighbours\nPosteriors P( m i | z, e) Posterior probability distribution of the model m i Output \u02c6 y = \u02c6 y( x) Estimation of the underlying signal\ni w p i S\n2\nT s d I r e f o m\ni t p m n m d b i i c e (\ng m t y o p p t a\n2\nF o a d s b i o t G\no\np\nu a d r fi p\nP\ni\nP\nc m d o\na\n\u03bc\nt N\nD ow nloaded from https://academ ic.oup.com /rasti/article/2/1/129/7079157 by Indian Institute of Technology Patna user on 25 January 2024 n Section 2 , and we use a set of synthetic tests to compare it ith other prescriptions in the literature. Details of the comparison rocedure are provided in Section 3 , and results are discussed n Section 4 . Our main conclusions are briefly summarized in ection 5 . . FA BA DA he goal of our algorithm, FABADA is to estimate an unknown ignal y = y ( x ) at N X different locations x \u2208 X specified by a oneimensional (1D) or 2D coordinate that belongs to the data domain. ts input are N X -independent measurements, contaminated with andom Gaussian white noise \u03b7( x) \u223c N (0 , e( x)), and the associated rrors e = e ( x ). The noisy observational data, z : X \u2192 R , have the orm z ( x ) = y ( x ) + \u03b7( x ), and FABADA returns an estimation \u02c6 y = \u02c6 y( x) f the original signal y ( x ) that is statistically compatible with the easurements z ( x ). The approximation that different measurements (pixels in an mage or wavelengths in a spectrum) are independent is crucial o our method: It is assumed that the noise values are fully indeendent random variables, and any correlation between adjacent easurements can only be attributed to the signal. This is not ecessarily true in realistic astronomical observations, since both the easurement process and the arithmetic operations carried out by the ata reduction pipeline may introduce a certain degree of correlation etween adjacent errors. Although we think our assumption of fully ndependent noise is a good approximation in most cases of practical nterest, it is worth noting that other approaches to account for spatial orrelation and denoising, such as COmpressed Sensing (Farrens t al. 2020 ), and Integrated Nested Laplace Approximation, INLA Gonz \u0301alez-Gait \u0301an et al. 2019 ), can be found in the literature.\nIn our method, we apply Bayes\u2019 theorem in an iteratively way to enerate smooth models of the noisy measurements. Therefore, we ust define a suitable likelihood function to e v aluate these models o be tested, and specify a prior probability distribution for the signal to initiate the process. Our likelihood is based on the statistics f a Gaussian process, and we start from an improper, constant rior. Then, we e v aluate dif ferent smooth versions of the posterior robabilities until a certain condition is reached, and we combine all he smooth models to produce the final estimation \u02c6 y( x), taking into ccount both their Bayesian evidence and the \u03c72 of the residuals.\nASTAI 2, 129\u2013141 (2023)\n.1 Iterati v e models\nABADA , as the name suggests, is a fully automatic algorithm that nly takes the data set z = z ( x ) and its associated errors e = e ( x ) s input, I = { z , e } , where the domain X may have one or two imensions. Within the field of astrophysics, y may be, e.g. the pectral energy distribution as a function of wavelength x , or a broadand photometric image of an arbitrary region of the sky. This is ndeed the kind of data that we will use to illustrate the performance f the algorithm, but the results can be easily generalized to any other ype of empirical measurement in one or two dimensions affected by aussian random errors. Under this assumption, the likelihood function L for a model m ( x ) f the underlying signal y is given by\n( z| m, e) = L ( z| m, e) = \u220f x\u2208 X e \u2212 [ z( x ) \u2212m ( x )] 2 2 \u00b7e( x) 2 \u221a 2 \u03c0 \u00b7 e( x) . (1)\nsing the notation described in Table 1 . Since we do not assume ny pre vious kno wledge about the signal, the prior probability istribution for our initial model m 0 will be homogeneous in the ange of all possible values, i.e. p ( m 0 ( x )) = 1 for all x , during the rst iteration of the algorithm. According to Bayes\u2019 theorem, the osterior probability distribution\n( m | z, e) = p( m ) \u00b7 L ( z| m, e) E (2) s in this case the straightforward multi v ariate Gaussian\n( m 0 | z, e) = \u220f x\u2208 X e \u2212 [ z( x ) \u2212m 0 ( x )] 2 2 \u00b7e( x) 2 \u221a 2 \u03c0 \u00b7 e( x) (3)\nentred on the empirical measurements z . The expected value of 0 ( x ) is thus \u03bc0 ( x ) \u2261 \u3008 m 0 ( x ) \u3009 = z ( x ), its variance v 0 ( x ) = e 2 ( x ) is etermined by the corresponding errors, and the Bayesian evidence f the model E = \u222b p( m ) L ( z| m, e) d m reduces to unity. To create smoothed versions of this first model, we iteratively pply a central moving average filter\n\u02dc i ( x ) = \u2211 x\u2208 avg \u03bci ( x )\nN avg (4)\no the expected values \u03bci ( x ) of the last iteration. We simply adopt avg = 3 in 1D (including the two adjacent measurements) and\nN t r p\np\nb t v\np f p\nP\nw\n\u03bc\na\na\nE\na f t t\n2\nO\n\u3008\na \u3008 s i d c t t\no\n\u03c7\na a i f\nt\ns v\n2\nO m y\ny\nw a\nt O a e d i p\nt e r a o \u03c7 t w \u03c7 I m f W\nw\na\nt u E o\nE\nw m a\nw\n3\nW d a d o ( a\nD ow nloaded from https://academ ic.oup.com /rasti/article/2/1/129/7079157 by Indian Institute of Technology Patna user on 25 January 2024\navg = 9 (a 3 \u00d7 3 square) in 2D. The basis of our method is o use information from neighbouring points to update our priors egarding the correct value of m ( x ). For every iteration i > 0, the rior probability distribution\n( m i ( x )) = e \u2212 [ \u0303 \u03bci\u22121 ( x ) \u2212m i ( x )] 2\n2 \u00b7v i\u22121 ( x) \u221a 2 \u03c0 \u00b7 v i\u22121 ( x )\n(5)\necomes a Gaussian centred on the smoothed expectation ( 4 ) of he posterior distribution from the previous iteration, using its local ariance v i ( x ) as a measure of our uncertainty.\nWe stress that we are forsaking the strict Bayesian philosophy (the rior distribution should be, as its name indicates, totally independent rom the data) on purely practical grounds. Once we accept this remise, one may compute the posterior probability distribution\n( m i | z, e ) = e \u2212 [ \u03bci ( x) \u2212m i ( x)] 2\n2 v i ( x) \u221a 2 \u03c0v i ( x) , (6)\nhere i ( x) = v i ( x) \u00b7 [\n\u02dc \u03bci\u22121 ( x) v i\u22121 ( x) + z( x) e 2 ( x)\n] (7)\nnd\n1 v i ( x) = 1 e 2 ( x) + 1 v i\u22121 ( x) , (8)\ns well as the evidence\ni ( x ) = e \u2212 [ \u0303 \u03bci\u22121 ( x ) \u2212z( x )] 2\n2[ e 2 ( x ) + v i \u22121 ( x )] \u221a 2 \u03c0 [ e 2 ( x ) + v i\u22121 ( x)] . (9)\nAs long as the model remains relatively close to the data (within n environment of the order of \u221a e 2 ( x) + v i ( x) ), the evidence in its a v our will be high, but if it departs significantly, the exponential erm will indicate that we have reached the maximum smoothing hat is statistically compatible with the data.\n.2 Stopping criteria\nn the one hand, we e v aluate the average evidence of model m i as\nE i \u3009 = 1 N X \u2211 x\u2208 X E i ( x) (10) nd we ensure that we iterate until it reaches a maximum; \u3008 E i \u3009 < E i\u22121 \u3009 . Since our priors are based on the data themselves, it is not urprising that the evidence increases rapidly during the first few terations of the algorithm. Ho we ver, our model uncertainties v i ( x ) ecrease monotonically, and the smooth models quickly become less ompatible with the data than the first (self-tuned) estimates. Thus, he average evidence reaches its maximum at a very early stage, and hen it slowly declines as the number of iterations increase.\nIn order to o v ercome the bias arising from the lack of independence f the priors (i.e. o v erfitting), we made use of the chi-square statistics\n2 i = \u2211 x\u2208 X [ \u03bci ( x) \u2212 z( x)] 2 e 2 ( x)\n(11)\nnd iterate until \u03c72 i > N X \u2212 2 (the absolute maximum of the ssociated probability density function). Note that this condition s achieved when, on average, the model has departed by about 1 \u03c3 rom the observational measurements.\nWe al w ays impose both criteria, so that the algorithm stops on he largest number of iterations. Usually this is set by the chi-square\ntatistics, although the evidence-based condition may dominate at ery high signal-to-noise ratio (SNR).\n.3 Model selection\nnce the algorithm stops, after N i iterations, we combine all the odels m i ( x ) to generate our final estimation \u02c6 y( x) of the real signal ( x ) as a weighted sum o v er the expected values\n\u02c6 ( x ) = \u2211 N i\ni= 0 w i ( x ) \u03bci ( x ) \u2211 N i i= 0 w i ( x )\n(12)\nhere the adopted weights w i ( x ) are important ingredients of our lgorithm.\nWe explored several phenomenological prescriptions in an attempt o optimize the performance, stability, and reliability of the results. n the one hand, our tests show the convenience of taking into ccount the local evidence E i ( x) calculated at each iteration for very location x . This quantity adapts to the local structure of the ata, giving more weight to the smoother models (larger number of iterations) in areas where the data are indeed smooth, while reserving the information when sharp edges are present. On the other hand, we use the o v erall \u03c72 i statistic of each model m i o gauge its compatibility with the measurements z , given the errors . The probability density function of the \u03c72 of a large number of andom variables can be approximated as a narrow Gaussian centred round N X \u2212 2. Since our priors are biased because they are based n the data themselves, the maximum evidence occurs at values of 2 that are typically much lower than this value (i.e. they overfit he measurements). Using the probability density function directly ould give minimal weight to any model that is not extremely close, 2 N X \u2212 2, which we find tends to yield o v erly smoothed models. n order to a v oid this problem, we use the actual value of \u03c72 to give ore weight to the smoother models, but not so much that the models a v oured by the Bayesian evidence are almost completely ignored. e thus adopt\ni ( x) = E i ( x) \u03c72 i , (13) s our final prescription for i > 0.\nOf course, this expression is not valid for i = 0, since \u03c72 0 = 0 and he initial evidence is E 0 ( x) = 1 for every point. Note that, due to the se of an improper prior, this value is in general very different from 1 ( x). To a v oid these problems, we a posteriori set \u03c72 0 = \u03c72 1 based n the first iteration (i.e. the lowest of all smooth models) and use\n0 ( x) = e \u2212 1 2 \u221a 2 \u03c0e , (14)\nhich is merely a reformulation of ( 9 ), assuming that our initial odel based on the measurements should be, on average, about 1 \u03c3\nway from the true signal. Thus,\n0 ( x) = \u03c7 2 1 e \u2212 1 2 \u221a 2 \u03c0e . (15)\n. SYNTHETI C TESTS\ne develop a battery of synthetic tests based on real astronomical ata to assess the performance of the algorithm. More precisely, we pply FABADA to a set of astronomical spectra and images, with if ferent le vels of Gaussian random noise, and compare the quality f the reconstructed signal [in terms of the peak signal-to-noise ratio PSNR) and the structure similarity index measure (SSIM)], as well s the e x ecution time, with other methods available in the literature.\nRASTAI 2, 129\u2013141 (2023)\nR\nTable 2. List of all noise reduction methods used to be compared with FABADA alongwith their parameters and space implementations, one or two dimensions. The first six methods are standard parametric algorithms, while the last four are representative of state-of-the-art non-parametric methods.\nMethod Parameters 1D 2D\nMedian Window size ( w ) SGF Window ( w ) and order ( o ) LOWESS Fraction window ( f ) - GF Radius ( R 0 ) Wiener Low frequency ( k ) TV Denoised weight d w\nWavelet \u2013 BM3D \u2013 - PySAP \u2013 - FABADA \u2013\n3\nO d d p o c k & t p m v s s u\ni s\n3\nO o o w u e t o c t s a d\n3\nA s s m s\ni\ny\nf m d \u2265 o w\n3\nA w t p t i t w a h a w i\n3\nA t ( e O o h\nG\nw n t m e\n3\nT i s k S o\ny\nw a t f\nD ow nloaded from https://academ ic.oup.com /rasti/article/2/1/129/7079157 by Indian Institute of Technology Patna user on 25 January 2024 .1 Other algorithms ver the last decades, lots of efforts have been placed into the evelopment of several applications that help in the analysis of igital images in different fields. Noise reduction is one of the basic roblems in this context, and we attempt to provide a fair comparison f our algorithm with other methods that are representative of the urrent state of the art. Leaving aside the techniques based on some ind of training, such as neural networks (Zhang et al. 2017 ; El Helou Susstrunk 2020 ; Ilesanmi & Ilesanmi 2021 ), we focus on a more raditional, statistical approach, closer in philosophy to the formalism ropose here. It is important to stress that many of these standard ethods involve a number of free parameters, and we optimize their alues according to the metrics used to compare. Note that, of course, uch optimization is only possible in a synthetic test, since the true ignal in a real problem is unknown. Thus, our results represent an pper limit to the performance of parametric methods. We now briefly describe the main principles and free parameters, f any, of all the techniques that we have considered. A succinct ummary is provided in Table 2 . .1.1 Median filter ne of the classical non-linear digital filtering techniques, it is still ften used to remo v e noise from an image or signal. The main idea f the median filter is to run through the data, replacing each point ith the median of neighbouring entries. The number of neighbours sed in the median is called the \u2018window\u2019, which slides, entry by ntry, o v er the entire signal. For each data point z ( x ), the region used o compute the median contains, for 1D data, ( w \u2212 1)/2 neighbours n each side, whereas for 2D it corresponds to a square of size w entred in z ( x ). The optimization procedure consisted on computing he estimation \u02c6 yw M ( x) for different values of w , starting with the mallest value of the window length, w 0 = 3, and increasing it ccording to w i + 1 = w i + 2(1 + w i //5), where // denotes the integer ivision.\n.1.2 Savitzki\u2013Golay filter\ns first noted by Savitzky and Golay in (Savitzky & Golay 1964 ), a moothed version of the data may be obtained by fitting successive ubsets of adjacent points with a low-degree polynomial using the ethod of least squares. When the data are equally spaced, the olution of the least squares (i.e. the coefficients of the polynomials)\nASTAI 2, 129\u2013141 (2023)\ns analytical and independent of the data to be smoothed. Thus,\n\u02c6 w,o SG ( x) = w\u22121 2 \u2211 i= 1 \u2212w 2 C o i ( w, o) z( x + i) (16)\nor w\u22121 2 \u2264 x \u2264 N X \u2212 w\u22121 2 , where the two free parameters of the ethod are the window length w of the data region, i.e. the number of ata points to be fitted, and the order o of the polynomial. C o i are the w o Savitzky\u2013Golay coefficients, and \u02c6 yw,o SG ( x) is the smoothed result f the filter at position x . We vary the window length according to i + 1 = w i + 2(1 + w i //5) and o \u2264 10 for the order of the polynomial.\n.1.3 Locally weighted scatterplot smoothing\npopular variant of the Savitzky\u2013Golay method is the locally eighted scatterplot smoothing (LOWESS; Cleveland 1979 ), where he regions to be fitted are not evenly spaced and the least-squares rocedure takes into account weighted values of the data, according o their distance from the point to be e v aluated. This scheme nvolves computing the coefficients of the fitted polynomial each ime, producing a less-efficient algorithm. To compare with FABADA , e use the implementation explained in Cleveland ( 1979 ), which uses linear fit and can only be used for 1D data. This implementation as only one parameter, which is the fraction f of data points used to ccomplish the linear regression at each point. For the optimization e begin with the smallest fraction possible ( f = 2/ N X ) and then it is ncremented it by a factor of 1.5 until the best reco v ery is found.\n.1.4 Gaussian filter\nnother classical technique of noise reduction consists in filtering he high frequency components of the data using a Gaussian filter GF). The fast Fourier transform (FFT) is the most computationally fficient way to convert the data z ( x ) to the frequency domain \u02dc z( w). nce we have the spectrum of the image, defined as the amplitude f the FFT of the data, we can apply a low-pass GF to discard the ighest modes:\nF ( \u0303 z( w) , W 0 ) = e \u2212| \u0303 z( w) | 2 / 2 W 2 0 (17) here | \u0303 z( w) | is the distance from the centre (zero-frequency compoent) in Fourier space, and W 0 is the radius of the filter, equi v alent o W 0 = 2 \u03c0 / R 0 in configuration space. This is again a one-parameter ethod, in which we select the radius R 0 of the low-pass GF by v aluating in 20 logarithmic steps between R 0 = 1 and R 0 = 630.\n.1.5 Wiener filter\nhe Wiener filter minimizes the mean-square error (MSE) taking nto account that the measurements are a random process where the tatistical properties (in particular, the spectrum) of the noise are nown. In this work, we have used the implementation in the Scipy ignal Tools library (Lim 1990 ; Virtanen et al. 2020 ), where the utput of the filter given the signal z ( x ) is given by \u02c6 W ( x) = { \u03c3 2 \u03c3 2 z m z + ( 1 \u2212 \u03c3 2 \u03c3 2 z ) z \u03c3 2 z \u2265 \u03c3 2\nm z \u03c3 2 z < \u03c3\n2 (18)\nhere m z and \u03c3 2 z are local estimates of the mean and variance within window of size w , and \u03c3 2 = \u3008 \u03c3 2 z ( x) \u3009 is the average variance across he data. We increment w starting from 3 until the best reco v ery is ound.\nFigure 1 Example spectra used to compare the performance of the different algorithms: a Kurucz stellar atmosphere model (left-hand panel), supernova remnant N132D in the Large Magellanic Cloud (centre panel), and interacting galaxy Arp 256 (right-hand panel).\n3\nT d t e o w o t f\n3\nT s e m 2 ( n\n3\nW e a 2 i ( s s t u b t a p n\n3\nF r\np r v c t r i S i s n\n3\nA s a G\no l d i s t s p l p f T c d ( 2 c a s D d d f d n\nD ow nloaded from https://academ ic.oup.com /rasti/article/2/1/129/7079157 by Indian Institute of Technology Patna user on 25 January 2024\n.1.6 Total variation filter he total variation (TV) filter is a well-known algorithm, first escribed by Rudin, Osher & Fatemi ( 1992 ), that aims to minimize he image\u2019s TV norm, defined as the square sum of the gradients of ach pixel, in both directions. In this work, we use the implementation f Chambolle ( 2004 ) in the scikit-ima g e library of Python that orks either in one or two dimensions. This implementation has ne parameter, the denoised weight d w , and we increase it from 10 \u22122 o 10 3 in logarithmically spaced steps until the maximum PSNR is ound. .1.7 Wavelet denoising filter he wavelet denoising filter is an adaptive approach to wavelet oft thresholding where a unique threshold is estimated for ach wavelet sub-band. In this work, we used the impleentation in the scikit-image library (van der Walt et al. 014 ), while the method is described in Chang, Yu & Vetterli 2000 ). This algorithm is non-parametric, and no optimization is ecessary. .1.8 Block-matching and 3D filtering\ne also include the block-matching and 3D filtering (BM3D; Dabov t al. 2007 ) algorithm, which arguably represents the state of the rt in the research field of image analysis (El Helou & Susstrunk 020 ). A detailed account of this method, where image denoising s implemented as two-step process, can be found in Dabov et al. 2007 ). For the first step, the noisy image is divided into equalize square blocks. For each block, a 3D group is formed with imilar regions (block-matching), and noise is attenuated by hardhresholding the coefficients of a 3D transform. The filtered image is sed to estimate the energy spectrum of the signal, and the process can e repeated a second time using a Wiener filtering instead of hardhresholding. The final smoothed result of the image is generated s a weighted average of the denoised blocks in their original ositions. This is a non-parametric method, and no optimization is ecessary.\n.1.9 Python Sparse Data Analysis Package\ninally, the Python Sparse Data Analysis Package (PySAP; Farens et al. 2020 ) is an open-source image processing software\nackage developed for the COmpressed Sensing for Magnetic esonance Imaging and Cosmology project. This package proides a set of flexible tools that can be applied to a variety of ompressed sensing and image reconstruction problems. In paricular, PySAP offers a denoising non-parametric automatic algoithm that is used in this work. The denoising algorithm uses the sotropic undecimated wavelet transform from the C ++ package, parse2D, to decompose the noisy image, and a soft threshold s then applied with weights learned from the noisy image itelf. This is a non-parametric method, and no optimization is ecessary.\n.2 Data sample\nll the methods explained in the previous section are applied to a et of test data in one and two dimensions (astrophysical spectra nd monochromatic images, respectively) with different levels of aussian random noise. An important aspect in the reco v ery of spectra is the conservation f their features, such as the Balmer break or emission and absorption ines, after noise reduction. For this purpose, we consider three ifferent spectra (represented in Fig. 1 ) that show these characteristics n different degrees. The first spectrum (left-hand panel) is a Kurucz tellar atmosphere model (Castelli & Kurucz 2003 ) with an ef fecti ve emperature T eff = 11 500 K, metal abundance log Z = 0.1 and urface gravity log g = 5.0, typical of an O/B-type star, with a rominent Balmer break at \u223c400 nm and several strong absorption ines. The spectrum of a supernova remnant, plotted on the middle anel, is a composite of five different observations (Blair et al. 2000 ) rom the Faint Object Spectrograph instrument of the Hubble Space elescope (HST). This high-resolution spectrum (0.9 \u00c5 per pixel) is haracterized by very prominent emission lines, useful for inferring ifferent physical properties of these objects. The last spectrum right-hand panel) is taken from the TRDS Brown Atlas (Brown et al. 014 ) which consist on a pair of interacting galaxies, Arp 256, in the onstellation of Cetus, and it contains a combination of emission and bsorption lines with a stellar continuum. The Kurucz and Arp 256 pectra can be found in the Synthetic Photometry SYNPHOT (Lim, iaz & Laidler 2015 ) Python package that simulates photometric ata and spectra, observed or otherwise. The aim of using these ifferent spectra is to obtain a good representation of the possible eatures that can appear in 1D astrophysical data and see how the ifferent algorithms perform in digging up spectral features out of a oisy signal.\nRASTAI 2, 129\u2013141 (2023)\nR\nFigure 2 Battery of images used for the comparison procedure. From left to right, top to bottom, the objects shown in this figure are the Bubble nebula (NGC 7635), a galaxy cluster (Abell S1063), the Crab nebula (M 1), the Eagle nebula (M 16), a spiral galaxy pair (NGC 4302 and 4298), the Ghost nebula (IC 63), Saturn, and a globular star cluster (NGC 1466). Labels on the bottom-left corner are used to identify each object throughout this work.\nd f s b t t a B s n T i a a H I m s a s f\n3\nW c\nz\nw m a d\ns a\nc o e t ( f\na t\nr\nM\na\nP\nw f o\nt s\nw \u03c3 c w\nD ow nloaded from https://academ ic.oup.com /rasti/article/2/1/129/7079157 by Indian Institute of Technology Patna user on 25 January 2024\nFor astronomical images, we consider eight different targets, isplayed in Fig. 2 , that are intended to sample the wide range of eatures that may be encountered in the field, including planets, tars, diffuse nebulae, and galaxies, either alone or in potentially lended groups. Saturn is arguably the target that is most similar to he ordinary test images (e.g. natural landscapes, and human subjects) hat are often used in the context of digital image processing. In ddition, our sample includes two examples of nebulae (Crab and ubble) dominated by the gaseous component, two with a more ignificant contribution of the stellar population (Eagle and Ghost eb ulae), and a glob ular cluster full of stars with different brightness. here is also an image with a galaxy pair (NGC 4302 and NGC 4298) n which we can see two different orientations of the galaxies, s well as a galaxy cluster with a wide variety of morphologies nd apparent sizes. All of these images have been taken from the ST gallery produced by NASA and the Space Telescope Science nstitute. All of them have been compressed to 8-bit values, with a aximal dynamical range of 0\u2013255 counts and 512 \u00d7 512 pixels ize to lighten up the computational load. For simplicity, we have lso normalized the astronomical spectra to 255 in order to have the ame dynamical range and represent the noise in terms of this value or both dimensions. .3 Test statistics\ne apply different levels of Gaussian random noise \u03b7( x ) with onstant variance \u03c3 2 to the real signal y ( x ):\n( x) = y( x) + \u03b7( x) (19) here \u03b7( x) = N (0 , \u03c3 ), the element x \u2208 X denotes independent easurements (spectrum wavelengths or image pixels), and we ssume that statistical errors are correctly characterized in the input ata. Once z ( x ) is computed, a softened estimation \u02c6 y( x) of the real\nASTAI 2, 129\u2013141 (2023)\nignal y ( x ) is carried out using the different algorithms explained bo v e.\nIn one dimension, noise levels vary from \u03c3 = 5 counts to \u03c3 = 95 ounts, out of the 255 maximal value that sets the dynamical range f our data (i.e. of the order of \u2248 2 \u221240 per cent relative errors). We xtend the values of \u03c3 to even higher values in 2D data, specifically o 1024 counts (400 per cent ) to illustrate the challenging situation not so seldom encountered in astronomy) that the signal is actually ainter than the background noise.\nWe e v aluate the quality of the reconstruction in terms of the PSNR nd the SSIM of the estimators \u02c6 y( x), following common practice in he signal processing literature.\nBy definition, the PSNR (usually expressed in decibels, dB) is elated to the MSE\nSE ( \u0302 y) = 1 N X \u2211 x\u2208 X ( \u0302 y( x) \u2212 y( x) ) 2 (20)\ns SNR ( \u0302 y) = 10 \u00b7 log 10 ( 255 2\nMSE\n) , (21)\nhere 255 is the dynamical range in our data. In principle, a more aithful reco v ery of the underlying signal should yield smaller values f the MSE and higher values of the PSNR. The SSIM is another typical metric used in image restoration hat takes into account properties such as luminance, contrast, and tructure. It is defined by the expression (Wang et al. 2004 )\nSSIM ( x , y ) = ( 2 \u03bcx \u03bcy + C 1 ) ( 2 \u03c3xy + C 2 )( \u03bc2 x + \u03bc2 y + C 1 ) ( \u03c3 2 x + \u03c3 2 y + C 2\n) (22) here x and y denote the two images being compared, \u03bc and 2 are their mean and variance, and \u03c3 xy their covariance. The onstants C 1 and C 2 are two variables to stabilize the division hen the denominator approaches zero, and they are usually set\nFigure 3 Results obtained for the Arp 256 spectrum (see Fig. 1 ) by all the models explained in Section 3.1 (rows) for three different noise levels (from left to right columns). The real signal y ( x ), the noisy input data z ( x ), and the estimation \u02c6 y( x) are represented as red, grey, and black lines, respectively. Numbers on each panel quote the PSNR and SSIM obtained by each method, to be compared with the noisy data (column headers).\nt o l\nt C n g o t\n4\nW s t l o A u u\n4\nF d G a i\no c\n4\nW r s w\n0 a P a ( t r c A p l i i t a\ni G a\nD ow nloaded from https://academ ic.oup.com /rasti/article/2/1/129/7079157 by Indian Institute of Technology Patna user on 25 January 2024\no C 1 = (0 . 01 L ) 2 and C 2 = (0 . 03 L ) 2 , where L is the dynamic range f the images. The SSIM metric can adopt values from 0 (absolute ack of correlation) to 1 (high structural similarity). Another metric that we consider is the CPU time used to generate he estimation of the real data on a 2.40 GHz Intel i9-9980HK PU along with 16Gb DDR4 2400 MHz RAM memory. Please ote that this time corresponds to the final e x ecution time for the iven noise level in the Python implementation of the algorithms, nce the optimal parameters have been found, but it does not include he time invested in the optimization, which is considerably larger. . RESULTS e now assess the ability of our algorithm to reco v er the underlying ignal for the synthetic test cases described in Section 3.2 . In order o facilitate the comparison with previous results reported in the iterature, we use the PSNR defined in ( 21 ), which is just a measure f the MSE, expressed in dB, as well as the SSIM defined in ( 22 ). ll the results shown from the parametric methods are optimized sing the PSNR metric (similar results are obtained if SSIM was sed instead).\n.1 Reco v ery examples\nigs 3 and 4 show two examples of the results obtained by the ifferent algorithms explained in Section 3.1 : the median, Savitzky\u2013 olay filter (SGF), GF, W iener filter , and LOWESS for 1D spectra, nd the median, SGF, GF, Wiener filter, and BM3D filters for the mages. Each row of both figures provides the reco v ered estimations\nf the signal \u02c6 y( x) for different noise levels, represented in each olumn.\n.1.1 Spectra example\ne represent in Fig. 3 the reco v eries obtained for three random ealizations with high, low, and extremely low SNRs of the Arp 256 pectrum (see Fig. 1 ). The PSNR achieved by each method is quoted ithin the corresponding panel along with the SSIM index. At high SNR ( \u03c3 = 10, original PSNR = 28.13 dB, SSIM = .52), all algorithms display not only a similar performance, but ctually converge to very similar solutions. The highest value of SNR/SSIM is obtained by the optimized TV filter (33.69 dB/0.84), little better than the Wiener filter (33.52 dB/0.82), and FABADA 33.15 dB/0.82). The difference is lower than the difference between hese three reco v eries and an y of the others. The impro v ement with espect to the originally high-quality data is necessarily modest in all ases, of the order of \u22483 dB, i.e. an increase of \u223c 50 per cent in MSE. ll algorithms are able to correctly trace the presence of the most rominent emission lines, as well as the strong Lyman- \u03b1 absorption ine near the peak at the left end of the spectrum. Nevertheless, it is mportant to note that, while the TV filter provides the best reco v ery n terms of o v erall noise reduction, FABADA tends to preserve the rue intensity of these features slightly better than any of the other lgorithms.\nThis trend becomes more significant as the noise increases, and t is more difficult to discriminate significant spectral features from aussian random fluctuations. In the middle panels, where \u03c3 = 35, ll models are able to reproduce the o v erall shape of the continuum.\nRASTAI 2, 129\u2013141 (2023)\nR\nASTAI 2, 129\u2013141 (2023)\nH e s O t a T t ( m t a\no n a F L W s n t i t F a s t l v d a r h m l q f\n4\nS F w d T p c t f o t o S 3 r ( fi c w (\na o c t r s s a\n= b ( h r f a t i\na o r P O S i a r t i r h w y i s\na l i G h n F a a t n m\nt F l h a e w t f T s h\nD ow nloaded from https://academ ic.oup.com /rasti/article/2/1/129/7079157 by Indian Institute of Technology Patna user on 25 January 2024\no we v er, the y fail to reco v er ev en the strongest absorption and mission lines, although hints of the brightest emission lines are till present in the wavelet, LOWESS, W iener , GF, and TV filters. nly our prescription is able to provide a good description of hese prominent features with this level of noise in the input data, lbeit weaker absorption and emission lines are completely lost. his reflects on the values of the metrics, where FABADA and he wavelet filter obtain the highest values (27.93 dB/0.77) and 27.95 dB/0.76), respectively; a difference of 10.68 dB, which is ore than an order of magnitude of noise reduction with respect to he original measurements. Ho we v er, the wav elet filter seems to have decreased resolution since it merges similar regions in wider bins.\nIf we now turn to the reco v ery of the noisiest spectrum ( \u03c3 = 95, n the right column), we see this behaviour of the wavelet filter more oticeable. Despite obtaining the highest values of the metrics, almost ll the information enclosed in the spectrum is gone. In comparison, ABADA obtains the second highest value of PSNR, while GF and OWESS obtain higher values of SSIM and close values of PSNR. hile the results of FABADA and GF are actually similar, all the pectral information in LOWESS is gone. At these high levels of oise, the MSE and the SSIM metrics are rather inadequate to assess he quality of the reconstructed emission line spectra, because they ncur in minimal penalty for failing to reproduce a handful of peaks hat are barely statistically significant. The criteria implemented in ABADA are more conserv ati ve, and a lot of random fluctuations re kept (hence the slightly lower SSIM) together with the most ignificant remains of the actual signal. It is somewhat remarkable hat FABADA manages to reco v er the brightest line even at this noise e vel, at v ariance with the other methods, while still obtaining high alues of the noise reduction metrics. We stress once again that this oes not necessarily imply a failure of the methods, but of the MSE s a goodness-of-fit indicator. On the other hand, it does highlight the obustness of FABADA in this respect, although the results reported ere suggest that perhaps the MSE and SSIM is not the optimal etric to gauge the quality of the reco v ered solution or, more ikely, that it should be complemented with another test statistic that uantifies information loss and/or gives more weight to informative eatures.\n.1.2 Ima g e example\nimilar trends are observed in the results obtained for the 2D data. ig. 4 shows the reco v ery of the Bubble nebula image for the hole set of different algorithms, represented in each row, with four ifferent noise levels ( \u03c3 = 10, 45, 95, and 255) along the columns. he PSNR and SSIM values obtained for each are also shown in each anel, and a close-up of some structures is provided in the last four olumns to illustrate whether the smoothing methods can reproduce heir shape and edges. All models yield fairly similar reconstructions or the highest SNR case ( \u03c3 = 10). The best reconstruction in terms f the MSE and SSIM is provided by the TV method, which improves he PSNR from 28.15 to 36.98 dB, more than one order of magnitude f noise reduction in terms of the MSE, and from 0.5 to 0.91 for the SIM index. The state-of-the-art BM3D obtains similar results with 6.94 dB and SSIM of 0.91. This is around 15 per cent more than the eco v ery with FABADA (35.85 dB) in terms of PSNR and 10 per cent 0.87) in terms of SSIM. Similar results are obtained with the Wiener lter (36.02 dB/0.89) and with PySAP (35.84 dB/0.89). The other lassical filters (median, SGF, and GF) obtain comparable results hen their parameters are tuned to minimize the MSE, about \u22481 dB \u223c 25 per cent ) below FABADA \u2019s solution. Regardless of the MSE\nnd SSIM statistics, the Wiener filter and PySAP virtually miss some f the filaments in the shape of the zoomed structure, while the other lassical filters reco v er some of the shapes, although in a blurrier way han FABADA , TV, and BM3D. Visually, the TV filter and BM3D eproduce the shape of the zoomed structure better, both in terms of harpness and smoothness. In particular, several edges in FABADA eem to be a little bit more blurry compared to BM3D, together with clearly visible salt and pepper noise component.\nSimilar behaviour is found when we increase the noise to \u03c3 45. FABADA yields results (30.82 dB/0.78) comparable to the est solutions obtained by BM3D (31.66 dB/0.82) and PySAP 31.03 dB/0.8). Despite its lower PSNR (30.81 dB), the GF obtains a igher value of SSIM (0.82) than FABADA . If we inspect the zoomed egion, we see that PySAP is able to ef fecti vely filter the highrequency noise with the cost of not reco v ering well the gradients nd the structure. In contrast, BM3D is able to reco v er fairly well he gradients of the image, while FABADA and GF reco v er a blurrier mage.\nOnce again, the advantages of our algorithm become more evident s the noise increases. In the middle range, with a noise level f \u03c3 = 95, one may see that FABADA \u2019s difference in MSE with espect to BM3D decrease to 0.37 dB, and it becomes better than ySAP by 0.7 dB, achieving higher values of SSIM in both cases. n the other hand, the GF reaches the highest values of MSE and SIM, whereas the W iener , TV, SGF, and median methods display ncreasingly lower values than the other methods. Most of them are ble to bring up large-scale gradients and structures, but they fail to eco v er the smallest filaments (as shown by the zoomed panels) due o the high level of noise. The most significant problem of FABADA s still the salt and pepper noise. The PySAP denoising filter, in turn, eturns a composition of smoothed and high-contrast regions that ardly reproduces the true underlying gradients in the signal. The avelet filter again seems to merge regions with similar intensity, ielding a lower effective resolution in the final reco v ery . Finally , it s remarkable how the state-of-the-art BM3D method starts to add ome artificial edges to the reco v ered image.\nIf we push the noise even further, as is often the case in practical strophysical applications, the signal itself is comparable to or even ower than the statistical uncertainties. In our last test, the noise level s \u03c3 = 255, equal to the dynamic range of the original data. The F obtains again the highest values of MSE (26.23 dB, 0.08 dB igher than FABADA \u2019s solution), almost an order of magnitude of oise reduction, and an SSIM value of 0.74, 0.02 point higher than ABADA . Despite the artificial lower resolution, the wavelet filter is ble to reco v er high values of the metrics (25.26 dB/ 0.7), which gain gives us a hint that the MSE and SSIM metrics may not be he optimal way to quantify the reco v ery of this type of image. It is oteworthy to see that these three solutions are far abo v e the rest, by ore than \u22483 dB in PSNR and \u22480.3 in SSIM. Upon visual inspection of the different reconstructions, including he zoomed region, one can see that almost every algorithm, except ABADA and GF, produces some artefacts in the images either at arge or small scales. The GF, ho we v er, is v ery efficient at filtering igh-frequency noise, but, by construction, highlights graininess t the characteristic scale of the filter. A similar effect is more vident in the PySAP, TV, SGF, and median filters. Although the avelet filter is able to recover the large-scale structure of the image, he decrease of resolution is even more noticeable, and spurious utures associated with the wavelet basis appear in the reconstruction. he Wiener filter still mixes regions with very different levels of moothing, while BM3D is extremely successful in eliminating the igh-frequency \u2018grain\u2019, albeit the smooth areas of the real image are\nRASTAI 2, 129\u2013141 (2023)\nR\nWavelet 15 0.598 4 0.065 Wavelet 17 1 .776 17 0.653 15 0 .102 15 0 .07 LOWESS 0 1.205 2 0.071 BM3D 60 1 .436 10 2.858 54 0 .112 8 0 .216 Savitzky\u2013Golay 4 1.377 9 0.083 Savitzky\u2013Golay 0 4 .439 0 5.361 3 0 .19 3 0 .219 Gaussian 9 0.885 23 0.033 Gaussian 23 1 .54 22 0.598 25 0 .117 22 0 .081 Median 0 1.866 0 0.112 Median 1 3 .17 1 2.337 4 0 .191 4 0 .199 Wiener 18 0.615 13 0.129 Wiener 0 5 .421 0 7.864 2 0 .192 2 0 .257 TV 1 2.613 1 0.243 TV 5 4 .247 0 7.168 3 0 .204 0 0 .322 \u2013 \u2013 \u2013 \u2013 \u2013 PySAP 0 3 .897 0 4.848 2 0 .162 1 0 .22\nt i s p m c M i p\n4\nW s 1 a d\n4\nI o o m ( fi P i r ( fi c o s a a 0 t t\ns t o h d\ni l l H p s t S a 0\na c t t w i L h p o\n4\nF 6 n t fi t fi a o d l\nF i d o a\nn t\nD ow nloaded from https://academ ic.oup.com /rasti/article/2/1/129/7079157 by Indian Institute of Technology Patna user on 25 January 2024 ransformed into more staggered gradients. This feature might be nherent to the block-matching algorithm, whose aim is to classify imilar square sections of the image into groups, thus resulting in atches with similar gradients and/or edges. The fully automatic ethod developed in this work, FABADA , seems to offer a reasonable ompromise solution. At high levels of noise, it is able to reduce the SE and increase the SSIM at the cost of significantly blurring the mage, but the introduction of spurious patterns, apart from salt and epper noise, is not as severe as in the other methods. .2 Entire data base results e have computed the PSNR, SSIM, and CPU time for all data amples, noise levels, and methods as a function of \u03c3 , averaged over 0 different random realizations. The number of cases that a specific lgorithm has reco v ered the best solution as well as the average ifference with respect to the optimal choice is quoted in Table 3 . .2.1 One dimension - spectra n one dimension (Fig. 5 ), FABADA behaves very similarly to the ptimized Wiener and the wavelet filters, particularly in terms f PSNR (top panel). In general, the best results regarding this etric are achieved with the latter methods; 18 out of the 57 32 per cent ) test cases by the W iener filter , followed by the wavelet lter with 15 (26 per cent ) and FABADA , who obtained the best SNR for 10 (18 per cent ) estimations, being especially successful\nn the low-SNR regime. Then, the optimized GF obtained the best econstruction in nine (16 per cent ) cases, and the remaining five 10 per cent ) correspond to the optimized SGF (four) and the TV lter (one). Neither LOWESS nor the median filter obtained in any ase the best values for PSNR. Just taking into account these results, ne can see how FABADA performs as well as the best possible olutions of the standard methods typically used in astronomy. The verage difference with respect to the highest PSNR achieved by any lgorithm is only 0.575 dB, a little closer than the wavelet method .598 dB. This supports the idea that FABADA automatically achieves he limit of the standard methods when their parameters are tuned to he (unknown) optimal values.\nIn terms of the SSIM metric (middle panels), our algorithm obtains lightly worse results, being the best option only in five (9 per cent ) est cases, with an average distance with respect to the highest SSIM f 0.118. The optimized GF filter obtained 23 (40 per cent ) of the ighest values and an average difference of 0.034. This result is ue in part to the SN 132 D spectra, where most of the information\nASTAI 2, 129\u2013141 (2023)\ns concentrated in the emission lines. At high values of the noise evel, almost all standard methods converge towards a horizontal ine, where all the information is lost (see e.g. LOWESS in Fig. 3 ). o we ver, the SSIM (and, to some extent, PSNR) do not strongly enalize the misfitting of the emission lines when their statistical ignificance becomes low, which hints the limitations of these metrics o quantify the reco v ery of rele v ant information. Discarding the N132D spectra, FABADA is seldom the optimal choice, but the verage distance decreases to 0.048 in terms of SSIM, compared to .022 for the GF, and 0.056\u20130.085 for the other algorithms. As regards to the CPU time, it is easy to see that FABADA has\nstrong dependence on the level of noise, at variance with most lassical methods, due to the increasing number of iterations required o fulfil our \u03c72 stopping condition. This behaviour is also seen in he median, due to a similar increase in the optimal window size, hether other methods are less sensitive to the noise level. FABADA s, in general, significantly slower than the other algorithms (except OWESS, at high SNRs), although it must be borne in mind that we ave not taken into account the time consumed by the optimization rocess of the standard algorithms, only the e x ecution time once the ptimal parameters have been found.\n.2.2 Two dimensions - ima g es\nor the 2D images (Fig. 6 ), BM3D reaches the highest PSNR for 0 out of our 112 (54 per cent ) test cases with different target and oise le vels, follo wed by the optimized GF with 23 (21 per cent ), he wavelet filter 17 (15 per cent ), FABADA with six (5 per cent ), TV lter with five (4 per cent ), and one (1 per cent ) that correspond to he optimized median filter. Neither SGF, PySAP, nor the Wiener lter ever obtained the highest v alues. Ne vertheless, BM3D is on verage 1.44-dB below the optimal choice, comparable to the 1.43 dB f FABADA , 1.50 dB of GF, and 1.77 dB of the wavelet filter ue to the significantly different trends observed at different noise evels.\nIn general, BM3D stands o v er the other methods, including ABADA , at high SNR ( \u03c3 95 dB), in particular for the Saturn\nmage. Its collaborative filter is particularly well suited for periodic ata, or images with repetitive patterns, which are virtually absent in ther test cases. The stars image would be a paradigmatic example, nd the difference in this test is insignificant.\nOn the other hand, FABADA , the wavelet filter, and GF predomiate in the low-SNR regime ( \u03c3 95 dB), where BM3D only achieves he best reconstruction in 10 out of the 56 (18 per cent ) test cases.\nFigure 5 PSNR, SSIM, and CPU times obtained for all the 1D spectra samples and noise ranges considered in the comparison procedure. In the top set of figures is shown the PSNR in dB, in the middle is represented the SSIM, and in the bottom one the CPU time in seconds. Each figure of both groups is labelled with the reference name given at the top of the column. The dashed yellow line represents the PSNR and SSIM of the noisy data. Solid lines with filled symbols refer to the non-parametric methods. In 1D data, we used two automatic methods, the one presented in this work, FABADA , which is represented with a red solid square, and the wavelet filter, with light green x. Dotted lines with unfilled symbols refer to the optimized methods. The LOWESS algorithm is represented with the blue diamond, the Wiener filter with the orange circle, the median filter with the green triangle, SGF with the brown hexagon, the GF with the purple cross, and the TV filter with the grey pentagon.\nT w a a w E a B fi l t\nr b d n a a s ( A\nF S s S a\nC a s s w p b w 0 w a 8 o o q\nD ow nloaded from https://academ ic.oup.com /rasti/article/2/1/129/7079157 by Indian Institute of Technology Patna user on 25 January 2024\nhe remaining 46 are achieved by GF with 22 (39 per cent ), the avelet filter with 17 (30 per cent ), FABADA with six (12 per cent ), nd the median filter with one (1 per cent ). Furthermore, BM3D is on verage 2.86-dB below the highest value, while FABADA , GF, and the avelet filter are only 0.57-, 0.59-, and 0.65-dB lo wer, respecti vely. ssentially, FABADA , the wavelet filter, and the optimized GF chieve remarkably similar results, and they perform better than M3D at low SNRs. Despite the high values obtained by the wavelet lter, we see in our examples that small-scale details in the image are ost, and they become replaced by artificial structures arising from he wavelet basis. This is not seen either in FABADA or BM3D.\nThis behaviour is also seen in the middle panels, where the SSIM is epresented. From the 54 (48 per cent ) of the highest values achieved y BM3D, only eight (19 per cent ) are abo v e \u03c3 > 95 counts, and the ifference with respect to the highest value of SSIM increases with oise level from 0.1 to 0.2. Although in this metric FABADA only chieves the best recovery in four (5 per cent ) cases, one (7 per cent ) t high noise levels, it is only 0.1 apart, on average, from the best olution. The optimized GF obtains the highest solution for 23 15 per cent ) cases and 25 (13 per cent ) in the low-SNR regime. dditionally, the wavelet filter produces better estimations than\nABADA in 17 (15 per cent ) cases, and 15 (13 per cent ) in the lowNR regime. Despite this difference, GF and the wavelet filter are till 0.11 and 0.12 below the best solution (0.07 and 0.081 at low NR), respectively, again very close to the results obtained by our lgorithm.\nThis change in the trend of the best solution is at the cost of PU time. While FABADA seems to converge to its solution in n efficient way in the high-SNR regime (consistently below the econd), for high noise levels (low SNR) the time rises up to 30 s, as hown in the bottom panels. Once again, for the optimized models e only take into account the e x ecution time with the fine-tuned arameters already known. The results are similar to the 1D case, ut the time-scale increases with the problem\u2019s dimensionality. The avelet filter is the fastest algorithm, obtaining an average time of .02 s, while the PySAP denoising filter seems to be the slowest, ith 18.24 s. FABADA also features a high e x ecution time (8.08 s on verage), whereas BM3D, GF, TV, the Wiener filter, and SGF yield .7, 0.87, 0.05, and 0.04 s, respecti vely. Ho we ver, the performance f FABADA and the median filter vary significantly as a function f SNR. Combining these results with the abo v e metrics for the uality of the reconstruction, we argue that our method provides a\nRASTAI 2, 129\u2013141 (2023)\nR\nASTAI 2, 129\u2013141 (2023)\nc l f w l\n5\nI a i s a /\no p P O a p t c b q i s t l r g t v d a\ne t i u S\nA\nP R e o 1 I t w fi\nS K t f ( A\nD\nT p i g ( K\nR\nB B C\nC C C D\nE F G\nG\nG\nI K\nL\nL\nR\nS v V W\nZ\nT\nD ow nloaded from https://academ ic.oup.com /rasti/article/2/1/129/7079157 by Indian Institute of Technology Patna user on 25 January 2024\nompetiti ve alternati ve both at high SNR, where it achieves slightly ess reliable results than the state-of-the-art algorithm BM3D at a raction of the computational cost, as well as in the low-SNR regime, here it provides a more faithful reconstruction after a significantly arger e x ecution time.\n. C O N C L U S I O N S\nn this work, we present the theory and implementation of a no v el utomatic algorithm for noise reduction: the FABADA . Our method terati vely e v aluates progressi vely smoother models of the underlying ignal and then combines them according to their Bayesian evidence nd \u03c72 statistic. The source code is publicly available at: https: / github.com/PabloMSanAla/ fabada .\nWe compare FABADA with other methods that are representative f the current state of the art in image analysis and digital signal rocessing. For this comparison, we used the most typical metrics, the SNR, which is a measure of the MSE, the SSIM, and the CPU time. ne important advantage of our method, shared by BM3D, PySAP, nd the wavelet filter, over classical algorithms is the absence of free arameters to be tuned by the user. Our results suggest that FABADA , he wavelet filter, and BM3D achie ve v alues of PSNR or SSIM omparable to or better than the best possible solution attainable y the classical methods. Beyond the precise values of the global uantitative metrics, both FABADA and BM3D are quite successful n adapting to the structures present in the input data. Perhaps the most ignificant difference between them is that FABADA \u2019s priors assume hat the signal is smooth, whereas BM3D uses block-matching to ook for repetitive patterns. This might be rele v ant when one must eco v er the height and shape of the spectral features in 1D or the radients and boundaries in 2D. We argue that FABADA appears o offer a trade-off among noise reductions, increasing the metric alues significantly, in a way that is statistically compatible with the ata, keeping significant features without introducing considerable rtefacts.\nRe garding e x ecution time, non-parametric methods are more xpensiv e than the classical alternatives once the optimal values of heir parameters are known , something that is of course impossible n practice. FABADA is faster than BM3D at high SNR, although it sually yields a poorer reconstruction, and the trend reverses for low NR.\nC K N OW L E D G E M E N T S\nMSA acknowledges financial support from the Spanish State esearch Agency (AEI-MICINN) of the Spanish Ministry of Scince and Innovation under the grant \u2018The structure and evolution f galaxies and their central regions\u2019 with reference PID201905602GB-I00/10.13039/501100011033, from the ACIISI, Canary slands Department of Economy, Knowledge and Employment, and he European Regional Development Fund (ERDF) under grant ith reference PROID2021010044, and from IAC project P/300724, nanced by the Ministry of Science and Innovation, through the\ntate Budget and by the Canary Islands Department of Economy, nowledge and Employment, through the Regional Budget of\nhe Autonomous Community. YA acknowledges financial support rom grant \u2018Starbursts throughout the evolution of the Universe\u2019 PID2019-107408GB-C42/AEI/10.13039/501100011033) from the EI-MICINN, Spain.\nATA AVAI LABI LI TY\nhe Python implementation of the method developed in this work is ublicly available at: https:// github.com/PabloMSanAla/ fabada . The mages used in this work were taken from the Hubble Space Telescope allery produced by NASA and the Space Telescope Science Institute STScI). The spectra used in this work were taken from Castelli & urucz ( 2003 ), Blair et al. ( 2000 ), and Brown et al. ( 2014 ).\nEFERENCES\nlair W. P. et al., 2000, ApJ , 537, 667 rown M. J. I. et al., 2014, ApJS , 212, 18 astelli F., Kurucz R. L., 2003, Proc. IAU Symp. 210, Modelling of Stellar\nAtmospheres. Astron. Soc. Pac., San Francisco, p. A20 hambolle A., 2004, J. Math. Imag. Vis. , 20, 89 hang S., Yu B., Vetterli M., 2000, IEEE Trans. Image Process. , 9, 1532 leveland W. S., 1979, J. Am. Stat. Assoc. , 74, 829 abo v K., F oi A., Katko vnik V., Egiazarian K., 2007, IEEE Trans. Image\nProcess. , 16, 2080 l Helou M., Susstrunk S., 2020, IEEE Trans. Image Process. , 29, 4885 arrens S. et al., 2020, Astron. Comput. , 32, 100402 onz \u0301alez-Gait \u0301an S., de Souza R. S., Krone-Martins A., Cameron E., Coelho\nP., Galbany L., Ishida E. E. O., COIN Collaboration, 2019, MNRAS , 482, 3880 oyal B., Dogra A., Agrawal S., Sohi B., Sharma A., 2020, Inf. Fusion , 55, 220 u S., Zhang L., Zuo W., Feng X., 2014, Proc. 2014 IEEE Conf. Comput. Vis. Pattern Recognit., Weighted Nuclear Norm Minimization with Application to Image Denoising. IEEE, USA, p. 2862 lesanmi A. E., Ilesanmi T. O., 2021, Complex & Intelligent Systems , 7, 2179 atk ovnik V., Katk ovnik V., Egiazarian K., Astola J., 2006, Local Approxima-\ntion Techniques in Signal and Image Processing. SPIE Press, Bellingham im J. S., 1990, Two-dimensional Signal and Image Processing. Prentice\nHall, NJ, USA im P. L., Diaz R. I., Laidler V., 2015, Pysynphot User\u2019s Guide. StSci, MD,\nUSA udin L. I., Osher S., Fatemi E., 1992, Physica D: Nonlinear Phenom. , 60,\n259 avitzky A., Golay M. J. E., 1964, Anal. Chem. , 36, 1627 an der Walt S. et al., 2014, PeerJ , 2, e453 irtanen P. et al., 2020, Nature Methods , 17, 261 ang Z., Bovik A., Sheikh H., Simoncelli E., 2004, IEEE Trans. Image\nProcess. , 13, 600 hang K., Zuo W., Chen Y., Meng D., Zhang L., 2017, IEEE Trans. Image\nProcess. , 26, 3142\nhis paper has been typeset from a T E X/L A T E X file prepared by the author.\nRASTAI 2, 129\u2013141 (2023)"
        }
    ],
    "title": "Fully adaptive Bayesian algorithm for data analysis: FABADA",
    "year": 2023
}