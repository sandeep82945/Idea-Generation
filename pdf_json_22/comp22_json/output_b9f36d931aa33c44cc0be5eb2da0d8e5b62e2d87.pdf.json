{
    "abstractText": "An important issue in model-based control design is that an accurate dynamic model of the system is generally nonlinear, complex, and costly to obtain. This limits achievable control performance in practice. Gaussian process (GP) based estimation of system models is an effective tool to learn unknown dynamics directly from input/output data. However, conventional GPbased control methods often ignore the computational cost associated with accumulating data during the operation of the system and how to handle forgetting in continuous adaption. In this paper, we present a novel Dual Gaussian Process (DGP) based model predictive control (MPC) strategy that enables efficient use of online learning based predictive control without the danger of catastrophic forgetting. The bio-inspired DGP structure is a combination of a long-term GP and a short-term GP, where the long-term GP is used to keep the learned knowledge in memory and the short-term GP is employed to rapidly compensate unknown dynamics during online operation. Furthermore, a novel recursive online update strategy for the shortterm GP is proposed to successively improve the learnt model during online operation. Effectiveness of the proposed strategy is demonstrated via numerical simulations.",
    "authors": [
        {
            "affiliations": [],
            "name": "Yuhan Liu"
        },
        {
            "affiliations": [],
            "name": "Pengyu Wang"
        },
        {
            "affiliations": [],
            "name": "Roland T\u00f3th"
        }
    ],
    "id": "SP:29887c1a5b4713d0ab8065b3ccabba78e2a63a37",
    "references": [
        {
            "authors": [
                "S Joe Qin",
                "Thomas A Badgwell"
            ],
            "title": "A survey of industrial model predictive control technology",
            "venue": "Control engineering practice,",
            "year": 2003
        },
        {
            "authors": [
                "Anil Aswani",
                "Humberto Gonzalez",
                "S Shankar Sastry",
                "Claire Tomlin"
            ],
            "title": "Provably safe and robust learning-based model predictive control",
            "year": 2013
        },
        {
            "authors": [
                "Ezzat Elokda",
                "Jeremy Coulson",
                "Paul N Beuchat",
                "John Lygeros",
                "Florian D\u00f6rfler"
            ],
            "title": "Data-enabled predictive control for quadcopters",
            "venue": "International Journal of Robust and Nonlinear Control,",
            "year": 2021
        },
        {
            "authors": [
                "Yanran Ding",
                "Abhishek Pandala",
                "Hae-Won Park"
            ],
            "title": "Realtime model predictive control for versatile dynamic motions in quadrupedal robots",
            "venue": "In 2019 International Conference on Robotics and Automation (ICRA),",
            "year": 2019
        },
        {
            "authors": [
                "Carl Edward Rasmussen"
            ],
            "title": "Gaussian processes in machine learning",
            "venue": "In Summer School on Machine Learning,",
            "year": 2003
        },
        {
            "authors": [
                "Xuemei Ren",
                "Frank L Lewis",
                "Jingliang Zhang"
            ],
            "title": "Neural network compensation control for mechanical systems with disturbances",
            "year": 2009
        },
        {
            "authors": [
                "Vincent Laurain",
                "Roland T\u00f3th",
                "Dario Piga",
                "Wei Xing Zheng"
            ],
            "title": "An instrumental least squares support vector machine for nonlinear system identification",
            "year": 2015
        },
        {
            "authors": [
                "Thomas Beckers",
                "Dana Kuli\u0107",
                "Sandra Hirche"
            ],
            "title": "Stable Gaussian process based tracking control of Euler\u2013Lagrange",
            "venue": "systems. Automatica,",
            "year": 2019
        },
        {
            "authors": [
                "Jonas Umlauft",
                "Thomas Beckers",
                "Melanie Kimmel",
                "Sandra Hirche"
            ],
            "title": "Feedback linearization using Gaussian processes",
            "venue": "In Proc. of the IEEE 56th Conf. on Decision and Control,",
            "year": 2017
        },
        {
            "authors": [
                "Mohamed K Helwa",
                "Adam Heins",
                "Angela P Schoellig"
            ],
            "title": "Provably robust learning-based approach for high-accuracy tracking control of lagrangian systems",
            "venue": "IEEE Robotics and Automation Letters,",
            "year": 2019
        },
        {
            "authors": [
                "Aditya Gahlawat",
                "Pan Zhao",
                "Andrew Patterson",
                "Naira Hovakimyan",
                "Evangelos Theodorou"
            ],
            "title": "L1-gp: L1 adaptive control with bayesian learning",
            "venue": "In Learning for Dynamics and Control,",
            "year": 2020
        },
        {
            "authors": [
                "Torsten Koller",
                "Felix Berkenkamp",
                "Matteo Turchetta",
                "Andreas Krause"
            ],
            "title": "Learning-based model predictive control for safe exploration",
            "venue": "IEEE conference on decision and control (CDC),",
            "year": 2018
        },
        {
            "authors": [
                "Lukas Hewing",
                "Juraj Kabzan",
                "Melanie N Zeilinger"
            ],
            "title": "Cautious model predictive control using Gaussian process 12 regression",
            "venue": "IEEE Transactions on Control Systems Technology,",
            "year": 2019
        },
        {
            "authors": [
                "Angelo D Bonzanini",
                "David B Graves",
                "Ali Mesbah"
            ],
            "title": "Learning-based smpc for reference tracking under statedependent uncertainty: An application to atmospheric pressure plasma jets for plasma medicine",
            "venue": "IEEE Transactions on Control Systems Technology,",
            "year": 2021
        },
        {
            "authors": [
                "Ali Mesbah",
                "Kim P Wabersich",
                "Angela P Schoellig",
                "Melanie N Zeilinger",
                "Sergio Lucia",
                "Thomas A Badgwell",
                "Joel A Paulson"
            ],
            "title": "Fusion of machine learning and mpc under uncertainty: What advances are on the horizon",
            "venue": "American Control Conference (ACC),",
            "year": 2022
        },
        {
            "authors": [
                "Lukas Hewing",
                "Kim P Wabersich",
                "Marcel Menner",
                "Melanie N Zeilinger"
            ],
            "title": "Learning-based model predictive control: Toward safe learning in control",
            "venue": "Annual Review of Control, Robotics, and Autonomous Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Neil Lawrence",
                "Matthias Seeger",
                "Ralf Herbrich"
            ],
            "title": "Fast sparse Gaussian process methods: The informative vector machine",
            "venue": "In Proc. of the Conf. on Neural Information Processing Systems,",
            "year": 2003
        },
        {
            "authors": [
                "Christopher Williams",
                "Matthias Seeger"
            ],
            "title": "Using the nystr\u00f6m method to speed up kernel machines",
            "venue": "In Proc. of the 14th Conf. on Neural Information Processing Systems,",
            "year": 2001
        },
        {
            "authors": [
                "Lehel Csat\u00f3"
            ],
            "title": "Gaussian processes: iterative sparse approximations",
            "venue": "PhD thesis,",
            "year": 2002
        },
        {
            "authors": [
                "Matthias Seeger"
            ],
            "title": "Bayesian Gaussian process models: PAC-Bayesian generalisation error bounds and sparse approximations",
            "venue": "Technical report, University of Edinburgh,",
            "year": 2003
        },
        {
            "authors": [
                "Volker Tresp"
            ],
            "title": "The generalized bayesian committee machine",
            "venue": "In Proc. of the 6th ACM Int. Conf. on Knowledge Discovery and Data Mining,",
            "year": 2000
        },
        {
            "authors": [
                "Edward Snelson",
                "Zoubin Ghahramani"
            ],
            "title": "Sparse Gaussian processes using pseudo-inputs",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2005
        },
        {
            "authors": [
                "Haitao Liu",
                "Yew-Soon Ong",
                "Xiaobo Shen",
                "Jianfei Cai"
            ],
            "title": "When gaussian process meets big data: A review of scalable gps",
            "venue": "IEEE transactions on neural networks and learning systems,",
            "year": 2020
        },
        {
            "authors": [
                "Juraj Kabzan",
                "Lukas Hewing",
                "Alexander Liniger",
                "Melanie N Zeilinger"
            ],
            "title": "Learning-based model predictive control for autonomous racing",
            "venue": "IEEE Robotics and Automation Letters,",
            "year": 2019
        },
        {
            "authors": [
                "Andrea Carron",
                "Elena Arcari",
                "Martin Wermelinger",
                "Lukas Hewing",
                "Marco Hutter",
                "Melanie N Zeilinger"
            ],
            "title": "Data-driven model predictive control for trajectory tracking with a robotic arm",
            "venue": "IEEE Robotics and Automation Letters,",
            "year": 2019
        },
        {
            "authors": [
                "Gang Cao",
                "Edmund MK Lai",
                "Fakhrul Alam"
            ],
            "title": "Gaussian process based model predictive control for linear time varying systems",
            "venue": "In Proc. of the 14th IEEE Int. Workshop on Advanced Motion Control,",
            "year": 2016
        },
        {
            "authors": [
                "Yuhan Liu",
                "Roland T\u00f3th"
            ],
            "title": "Learning based model predictive control for quadcopters with dual gaussian process",
            "venue": "In 2021 60th IEEE Conference on Decision and Control (CDC),",
            "year": 2021
        },
        {
            "authors": [
                "Michalis Titsias"
            ],
            "title": "Variational learning of inducing variables in sparse gaussian processes",
            "venue": "In Artificial Int. and Satistics,",
            "year": 2009
        },
        {
            "authors": [
                "James Hensman",
                "Nicolo Fusi",
                "Neil D Lawrence"
            ],
            "title": "Gaussian processes for big data",
            "venue": "arXiv preprint arXiv:1309.6835,",
            "year": 2013
        },
        {
            "authors": [
                "James Hensman",
                "Alexander Matthews",
                "Zoubin Ghahramani"
            ],
            "title": "Scalable variational gaussian process classification",
            "venue": "In Artificial Intelligence and Statistics,",
            "year": 2015
        },
        {
            "authors": [
                "Karl Friston",
                "J\u00e9r\u00e9mie Mattout",
                "Nelson Trujillo-Barreto",
                "John Ashburner",
                "Will Penny"
            ],
            "title": "Variational free energy and the laplace approximation",
            "year": 2007
        },
        {
            "authors": [
                "Lehel Csat\u00f3",
                "Manfred Opper"
            ],
            "title": "Sparse on-line gaussian processes",
            "venue": "Neural computation,",
            "year": 2002
        },
        {
            "authors": [
                "Dejan Petelin",
                "Ju\u0161 Kocijan"
            ],
            "title": "Control system with evolving gaussian process models",
            "venue": "IEEE Workshop on Evolving and Adaptive Intelligent Systems (EAIS),",
            "year": 2011
        },
        {
            "authors": [
                "Ju\u0161 Kocijan"
            ],
            "title": "Modelling and control of dynamic systems using Gaussian process models",
            "year": 2016
        },
        {
            "authors": [
                "Joaquin Quinonero-Candela",
                "Agathe Girard",
                "Carl Edward Rasmussen"
            ],
            "title": "Prediction at an uncertain input for Gaussian processes and relevance vector machinesapplication to multiple-step ahead time-series forecasting",
            "venue": "Technical report,",
            "year": 2003
        },
        {
            "authors": [
                "Marc Peter Deisenroth"
            ],
            "title": "Efficient reinforcement learning using Gaussian processes, volume 9",
            "venue": "KIT Scientific Publishing,",
            "year": 2010
        },
        {
            "authors": [
                "Simon Muntwiler",
                "Kim P Wabersich",
                "Lukas Hewing",
                "Melanie N Zeilinger"
            ],
            "title": "Data-driven distributed stochastic model predictive control with closed-loop chance constraint satisfaction",
            "venue": "European Control Conference (ECC),",
            "year": 2021
        },
        {
            "authors": [
                "Johannes K\u00f6hler",
                "Melanie N Zeilinger"
            ],
            "title": "Recursively feasible stochastic predictive control using an interpolating initial state constraint",
            "venue": "IEEE Control Systems Letters,",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "An important issue in model-based control design is that an accurate dynamic model of the system is generally nonlinear, complex, and costly to obtain. This limits achievable control performance in practice. Gaussian process (GP) based estimation of system models is an effective tool to learn unknown dynamics directly from input/output data. However, conventional GPbased control methods often ignore the computational cost associated with accumulating data during the operation of the system and how to handle forgetting in continuous adaption. In this paper, we present a novel Dual Gaussian Process (DGP) based model predictive control (MPC) strategy that enables efficient use of online learning based predictive control without the danger of catastrophic forgetting. The bio-inspired DGP structure is a combination of a long-term GP and a short-term GP, where the long-term GP is used to keep the learned knowledge in memory and the short-term GP is employed to rapidly compensate unknown dynamics during online operation. Furthermore, a novel recursive online update strategy for the shortterm GP is proposed to successively improve the learnt model during online operation. Effectiveness of the proposed strategy is demonstrated via numerical simulations.\nKey words: Learning-based control; Data-driven model; Dual Gaussian process; Model predictive control; Machine learning"
        },
        {
            "heading": "1 Introduction",
            "text": "Model predictive control (MPC) has attracted considerable attention in recent decades due to its capability of dealing with control problems under operational constraints. MPC has been applied in a wide range of applications, including process control [1], flight control of quadrotors [2, 3], and motion control of robots [4], etc. The performance of model predictive control is highly dependent on the accurate description of the system dynamics. Generally, the system dynamics can be modeled by first principle laws such as the Newton-Euler approach. However, systems in real applications are usually affected by nonlinear couplings, time-varying distur-\n? This research was supported by the European Union within the framework of the National Laboratory for Autonomous Systems (RRF-2.3.1-21-2022-00002).\nEmail addresses: y.liu11@tue.nl (Yuhan Liu), wangpy@kaist.ac.kr (Pengyu Wang), r.toth@tue.nl (Roland To\u0301th).\nbances, and unmodeled dynamics, that may have a significant impact on the achievable control performance. For example, aerodynamic effects such as complex interactions of rotor airflows with the ground and objects such as walls, air friction, and flapping dynamics of the rotor blades are hard to model and specific for each individual quadrotor, but they can seriously affect highspeed maneuvering. As a result, a comprehensive and precise model for high performance operations is often costly to obtain.\nRecently, various data-driven learning-based control methods have shown potential to capture unmodeled dynamics and achieve superior performance in compensatory control over physical model-based control. Collected input-output data from the system can be used to directly construct an accurate data-driven model by these methods. Especially, Gaussian Process regression [5], which is a Bayesian nonparametric data-driven modeling method, is promising to automatically extract important features of the unknown dynamics from\nPreprint submitted to Automatica 8 November 2022\nar X\niv :2\n21 1.\n03 69\n9v 1\n[ ee\nss .S\nY ]\n7 N\nmeasurement data. Compared to other model learning methods based on Artificial Neural Networks (ANNs) [6] and Support Vector Machines (SVMs) [7], the main advantage of GP regression is that it does not only provide a single function estimate, but also a variance, i.e. confidence interval, which indicates the accuracy of the model estimate. Substantial results have been achieved in GP-based learning control. In [8], a GP-based datadriven dynamic model was identified for reducing the uncertainty of a given model and adapting the feedback gain by taking into account the model confidence. Furthermore, feedback linearization-based control had been also achieved by learning a control affine GP model [9]. In [10], the GP was employed to estimate the error between the desired and actual accelerations, then a robust controller with uncertainty upper bound was proposed to guarantee the closed-loop stability. A L1 adaptive control with GP was presented in [11], where the unknown model was learnt by a GP to achieve the safe control objective without sacrificing robustness.\nPowerful results have also been achieved for GP-MPC, where the unknown part of the system dynamics is captured by a learnt probabilistic GP model [12\u201315]. While this provides flexibility to represent the unknown dynamics with their uncertainty bounds it also introduces a stochastic term into the state propagation, which in turn necessitates the use of approximations to make the control problem tractable [16]. Another challenge is the high computational load during the receding horizon optimization, especially when the GP is employed to predict the function value based on a large data set. In general, GP is not suitable for large training sets because the computational cost to train a GP is cubic in terms of the number of data points. To solve this issue, various scalable GP methods have been developed to reduce the computational load, but preserve the prediction accuracy. The simplest way is to choose a subset of data (SoD) of size M N randomly to represent the full training set. However, this strategy can lead to serious underfitting as the probability of discarding crucial information included in the full training set grows with the reduction rate. In [17], instead of choosing a subset randomly, an information vector machine based method is proposed to select the subset more efficiently. Besides the SoD method, many advanced techniques have been explored, including the Nystro\u0308m method [18], deterministic training conditional approximation (DTC) [19,20], partially independent training conditional approximation (PITC) [21], and fully independent training conditional approximation (FITC) [22]. A unifying framework of the mentioned algorithms was discussed in [23]. Several studies for GP-MPC were carried out with the applications of race cars [13, 24], robot arms [25], and quadrotors [26]. However, most GP-based control methods do not perform online updating to avoid the issue of data bloating. Although, this would allow online adaptation with GP-based control during the system operation. By using data approximation techniques to counteract data\nbloating in online updating, the GP can gradually lose its knowledge learned during the training phase, and morph into a purely online adaptive regressor. Thus, designing a \u201dmemory\u201d-based GP structure with online learning ability is highly attractive.\nMotivated by these facts and inspired by the biological concept of \u201dlong/short term memory\u201d of human beings, we propose a novel dual Gaussian process (DGP) based model predictive control strategy in this paper, as an extension of our preliminary work in the topic and presented in [27]. The DGP structure consists of two parts: a short-term GP which has the capability of online updating and is used for time-varying uncertainty compensation, and a long-term GP that is employed to learn the time-independent uncertainties and store the collected experience. The main contributions of this paper are summarized below.\n1) By the authors\u2019 knowledge, the proposed DGP structure is the first framework that emphasizes both \u201dmemory\u201d and \u201dlearning\u201d ability by a combination of long/short-term GPs. As we show, such a method is capable of preventing forgetting relevant process information without the need of periodic reinforcement, but at the same time ensures exploration and adaptation to uncertain or varying aspects of the dynamics. A longterm GP is utilized for the former while a short-term GP is used for the latter objectives.\n2) A novel recursive online updating strategy for the short-term GP is presented to continuously learn the unknown time-varying uncertainties during control operation. The proposed recursive online sparse GP has the ability of efficiently updating both the posterior mean and variance simultaneously, which especially benefits the MPC settings.\n3) We show that the proposed DGP structure can be employed in an MPC scheme, which enables the conventional MPC to have additional bio-inspired advantages of online learning and remembering. Also, rigorous results of DGP prediction at an uncertain input are provided in detail to permit the uncertainty propagation in GP-MPC scheme.\nThe remainder of this paper is organized as follows. Section 2 formalizes the model predictive control problem and introduces the preliminaries on GPs. The proposed recursive online sparse GP regression together with the novel dual GP structure are detailed in Section 3. Then, a learning based predictive control strategy based on the proposed dual GP structure is presented in Section 4. To demonstrate the capabilities of the proposed adaptive predictive control scheme, simulation examples of adaptive flight control of a quadrotor are given in Section 5. Finally, conclusions on the achieved results are drawn in Section 6."
        },
        {
            "heading": "2 Preliminaries and Problem Formulation",
            "text": ""
        },
        {
            "heading": "2.1 The Data-generating System",
            "text": "In this paper, we consider discrete-time nonlinear systems that can be represented in the form of\nx(k + 1) = f(x(k),u(k)) + g(x(k),u(k)) + v(k), (1)\nwhere k \u2208 Z is the discrete time, x(k) \u2208 Rnx , u(k) \u2208 Rnu , and v(k) \u2208 Rnx are the state, control inputs, and noisy signals, respectively, while f : Rnx\u00d7nu \u2192 Rnx and g : Rnx\u00d7nu \u2192 Rnx are bounded deterministic vector functions. The function f constitutes the physically well interpretable and a priori know dynamics of the system, i.e., its nominal model, whereas, g represents the unknown, i.e., unmodeled dynamics together with the external disturbances of the system. The noisy signal v is assumed to be an independent and identically distributed (i.i.d.) white noise process v \u223c N (0,\u03a3 ) where \u03a3 = diag(\u03c3\n2 ,1, . . . , \u03c3 2 ,nx). We moreover assume that\nthe full state vector is available for measurement.\nLet us consider f to be linear allowing to write (1) as\nx(k+ 1) = Ax(k) +Bu(k) +g(x(k),u(k)) +v(k) (2)\nwhere A and B are the known system matrices derived from the linearization of the idealistic dynamics, hence g(x(k),u(k)) captures the approximation error of the applied linearization and discretization or effects that cannot be captured reliably by the idealistic model (1) (i.e., both nonlinear effects and external disturbances)."
        },
        {
            "heading": "2.2 The Predictive Control Problem",
            "text": "In this paper, we consider a constrained finite-horizon optimal control problem for (2). Given the current time instant k \u2208 Z, time horizon H \u2208 N, the state and input constraints X \u2286 Rnx and U \u2286 Rnu , respectively, the goal is to find the sequence of admissible control inputs Uk = {u0|k, ...,ui|k} that satisfy xi|k \u2208 Rnx and ui|k \u2208 Rnu for all i \u2208 IH0 = {i \u2208 Z | 0 \u2264 i \u2264 H}, that is, solving the following receding horizon optimization problem:\nmin Uk J(x(k),Uk) =\n( lf(xH|k) +\nH\u22121\u2211 i=0 l(xi|k,ui|k) ) s.t. x0|k = x(k), u0|k = u(k),\nxi+1|k = Axi|k +Bui|k + g(xi|k,ui|k), xi|k \u2208 X , ui|k \u2208 U .\n(3)\nwhere l(\u00b7) : Rnx \u00d7 Rnu \u2192 R and lf(\u00b7) : Rnx \u2192 R are the stage and terminal cost functions, which are defined in a quadratic form with weight matrices Q, Qf and R,\ni.e., l(x,u) = x>Qx+u>Ru. Furthermore, we consider polytopic constraints for the state and control input:\nX = {x(k)|Cxx(k) \u2264 cx} (4a) U = {u(k)|Cuu(k) \u2264 cu} (4b)\nwhere Cx \u2208 Rnc\u00d7nx , cx \u2208 Rnc , nc is the number of half-space constraints. The considered predictive control problem (3) can only be solved if g is known or if an approximate description of it is efficiently from data."
        },
        {
            "heading": "2.3 Learning with Gaussian Processes",
            "text": "To guarantee the aforementioned state and control input constraints, a model \u2206(x(k),u(k)) of g should be identified reliably. Our goal is to construct a probabilistic model \u2206(x(k),u(k)) from the system measurement data, and to improve accuracy gradually as more data are collected. We model \u2206(x(k),u(k)) as a GP where the state-input pairs z(k) , (x>(k) u>(k))> \u2208 Rnx+nu and y(k) , x(k + 1)\u2212Ax(k)\u2212Bu(k) are denoted as training inputs and outputs, respectively. In terms of definition, a vectorial Gaussian Process GP : Rnz \u2192 Rnx assigns to every point z \u2208 Rnz a random variable GP(z) taking values in Rnx such that, for any finite set {z(\u03c4)}N\u03c4=1 \u2282 Rnz , the joint probability distribution of GP (z(1)) , . . . ,GP (z(N)) is multidimensional Gaussian. This constitutes a distribution over functions. GPs are fully determined by\n\u00b5(z) = E[\u2206(z)], \u03ba(z, z\u2032) = E[(\u2206(z)\u2212 \u00b5(z))(\u2206(z\u2032)\u2212 \u00b5(z\u2032))>], (5)\nwhere \u00b5(z) is the mean function and \u03ba(z, z\u2032) , cov(\u2206(z),\u2206(z\u2032)) is the positive semi-definite covariance function which denotes a measure for the correlation (or similarity) of any two data points (z, z\u2032). Then we assume that:\n\u2206(z) \u223c GP(\u00b5(z),\u03ba(z, z\u2032)), (6)\nwhich describes our prior belief over the uncertain dynamics. The prior mean function is usually set to zero as all prior knowledge of the dynamics is assumed to be given in f . Furthermore, GP regression is often implemented for each element of the GP-output variable separately, i.e, in terms of scalar-valued \u2206i \u223c GP(\u00b5i, \u03bai) with i \u2208 Inx1 , constituting to \u2206 = vec(\u22061, . . . ,\u2206nx). While this approach greatly simplifies the estimation problem, it inherently results in the choice of \u03ba = diag(\u03ba1, . . . , \u03banx). Regarding \u03bai, there is a wide selection of covariance functions, such as sinusoidal and Mate\u0301rn kernels, and in this paper we use the squared exponential function with automatic relevance determi-\nnation (SEARD):\n\u03bai (z, z \u2032) = \u03c32f,i exp\n( \u22121\n2 (z \u2212 z\u2032)>\u039b\u22121i (z \u2212 z\u2032)\n) (7)\nas a prior due to its universal approximation capability, where \u03c32f,i \u2208 R\u22650 and \u039bi = diag(\u03bb2i,1, ..., \u03bb2i,nz) are signal variance and length-scale hyperparameters, respectively.\nConsider the training set DN = {(y(k), z(k))}Nk=1 with N noisy output y(k) = \u2206(z(k)) + v(k). Let Z = vec(z(1), . . . ,z(N)) and Yi = vec(yi(1), . . . ,yi(N)) for i \u2208 Inx1 . The Gaussian prior distribution for the function \u2206 and the model likelihood of the training set DN are given by:\nP (\u2206i) = N (\u2206i|0,KN,i) (8a) P (Yi|\u2206i) = N (Yi|\u2206i, \u03c32 ,iIN ) (8b)\nrespectively, where KN,i \u2208 RN\u00d7N denotes the kernel matrix with elements [KN ]n,m = \u03bai(z(n), z(m)), n,m \u2208 IN1 and \u2206i = vec(\u2206i(z(1)), . . . ,\u2206i(z(N)) for i \u2208 Inx1 . Thus, according to Bayes\u2019 rule, one can obtain the posterior distribution by maximum a posterior (MAP) estimation\nP (\u2206|Y ) \u221d P (Y |\u2206)P (\u2206) \u221d vec ( N (\u2206i|KN,i(KN,i + \u03c32 ,iIN )\u22121Yi,\n(K\u22121N,i + \u03c3 \u22122 ,i IN ) \u22121) (9) Since the prior mean has been assumed to be zero, one has the joint distribution over \u2206i and \u2206\n\u2217 i :(\n\u2206i | Z \u2206\u2217i | z\u2217\n) \u223c N ( \u2206i\n\u2206\u2217i\n\u2223\u2223\u2223\u2223 0 , [ KN,i KN\u2217,i\nK\u2217N,i k\u2217\u2217,i\n]) (10)\nwhere [KN\u2217,i]j = \u03bai(z(j), z\u2217), K\u2217N,i = K>N\u2217,i and k\u2217\u2217,i = \u03bai(z\u2217, z\u2217).\nThen, the associated posterior distribution of the function value \u2206(z\u2217) at a new test point z\u2217 can be derived by merging (9) and (10) together into:\nP (\u2206\u2217|DN , z\u2217) = \u222b P (\u2206\u2217|Z,\u2206, z\u2217)P (\u2206|Y )d\u2206\n= N (\u00b5\u2206(z\u2217),\u03a3\u2206(z\u2217)) (11)\nwhere\u00b5\u2206(z \u2217) = vec(\u00b5\u2206,1(z\u2217), ..., \u00b5\u2206,nz(z \u2217)), \u03a3\u2206(z\u2217) = diag(\u03c32\u2206,1(z \u2217), ..., \u03c32\u2206,nz(z \u2217)) with the predictive mean and variance for each dimension i:\n\u00b5\u2206,i(z \u2217) = K\u2217N,i(KN,i + \u03c3 2 ,iIN ) \u22121Yi (12a) \u03c32\u2206,i(z \u2217) = k\u2217\u2217,i\u2212K\u2217N,i(KN,i+\u03c32 ,iIN )\u22121KN\u2217,i\n(12b)\nFurthermore, given the marginal likelihood P (Yi) = N (0,KN,i + \u03c3 ,i2IN ) and the hyperparameters set \u03b8i = vec(\u03c3 2 ,i, \u03c3 2 f,i, \u03bbi,1, ..., \u03bbi,nz), the probabilistic GP model (6) can be trained by maximizing the likelihood of each individual predictive output distribution separately, i.e.,\nlogP (Yi) =\u2212 N\n2 log 2\u03c0 \u2212 log |KN,i + \u03c3 ,i2IN |\n\u2212 1 2 Y >i (KN,i + \u03c3 ,i 2IN ) \u22121Yi\n(13)\nto find the optimal \u03b8\u0302i \u2208 arg max\u03b8i logP (Yi) by means of conjugate gradient-based algorithm [5], which has a computational load of O(N3) per iteration."
        },
        {
            "heading": "3 Recursive Online Sparse Gaussian Regression with Dual Structure",
            "text": ""
        },
        {
            "heading": "3.1 Sparse Variational Gaussian Process",
            "text": "As we could see, due to the diagonal assumption of the prior covariance matrix \u03ba, the predictive distribution for each \u2206i can be independently formulated and trained. Hence, to avoid complexity of the notation, in this section we will drop the indexing for the output dimension of the GP as the derived results in this section can be used channel vise in the same manner as we have seen it in Section 2.3.\nThe computational load per test case for the full GP in (12a) and (12b) is O(N) and O(N2) in terms of mean and variance, respectively. In this paper, we focus on the generalization of sparse variational GP regression (SVGP), which has been first introduced in [28] and further extended to mini-batch training [29] and nonGaussian likelihood [30] problems.\nThe goal of sparse GP is to find a set of pseudo inputs Zu = vec(zu,1, ...,zu,M ) corresponding to pseudo outputs \u2206u = vec(\u2206u,1, ...,\u2206u,M ) of size M N . In SVGP, the true posterior distribution P (\u2206|DN ) is approximated by a Gaussian distribution q(\u2206,\u2206u) = P (\u2206|\u2206u)q(\u2206u) by means of variational inference, where a tractable variational distribution q (\u2206u) = N (\u2206u|mu,Su) is used, corresponding to the maximization of the evidence lower bound (ELBO) of logP (Y ):\nL(q) , \u222b q (\u2206,\u2206u) log P (Y ,\u2206,\u2206u)\nq (\u2206,\u2206u) d\u2206d\u2206u\n= F (q)\u2212KL(q (\u2206u) ||P (\u2206u)), (14)\nwhere L(q) is also known as the Variational Free Energy (VFE) in variational learning and is used as an approximation of the log evidence for model selection [31],\nF (q) = \u222b q (\u2206u)P (\u2206|\u2206u) logP (Y |\u2206)d\u2206d\u2206u, and KL(\u00b7||\u00b7) represents the Kullback-Leibler divergence which quantifies the similarity between two distributions. Then the optimal q\u2217 (\u2206u) in terms of maximum of (14) with mean mu and variance Su is:\nmu = \u03c3 \u22122 SuK \u22121 M KMNY (15a)\nSu = KM ( KM + \u03c3 \u22122 KMNKNM )\u22121 KM (15b)\nwhere [KMN ]i,j = \u03ba(zu,i, z(j)) denotes the covariance matrix between pseudo inputs Zu and training inputs Z, KMN = K > MN , KM is the covariance matrix of the pseudo inputs. See Appendix A for details of the derivation of the optimal variational parameters. Merging the optimal distribution q\u2217 (\u2206u) into L(q), we get:\nL(q)=logN (Y |0,QN +\u03c32 IN )\u2212 1\n2\u03c32 tr(KN\u2212QN ) (16)\nwhere QN = KNMK \u22121 M KMN . The pseudo inputs Zu and hyperparameters \u03b8 can be optimized by maximizing (16), which results in a computational load of O(NM2 +M3).\nWith the approximated posterior q(\u2206,\u2206u), the marginal distribution of \u2206 is:\nq(\u2206) = \u222b P (\u2206|\u2206u) q (\u2206u) d\u2206u\n= N (\u00b5\u2206(z), \u03c32\u2206(z)), (17)\nThus, the predictive mean and variance at the test point z\u2217 are\n\u00b5\u2206(z \u2217) = K\u2217MK \u22121 M mu (18a) \u03c32\u2206(z \u2217) = k\u2217\u2217\u2212K\u2217M ( K\u22121M \u2212K\u22121M SuK\u22121M ) KM\u2217\n(18b)\nwhere [K\u2217M ]j = \u03ba(z\u2217, zu,j).\nIt is worth mentioning that, the hyperparameters and pseudo points are fixed after the ELBO maximization, and the GP is used to predict the mean and variance at a new data point during the operation. However, due to the fact that the external environment for real physical systems can be complicated and time-varying, the offline pre-trained GP model is required to be successively improved to ensure continuous betterment/adaptation."
        },
        {
            "heading": "3.2 Recursive Online Sparse Gaussian Process",
            "text": "Next a novel online update strategy for sparse Gaussian processes is proposed. The proposed method updates the posterior mean and variance of q (\u2206u) recursively based on the regression error at the current time step k.\nOn the basis of recursive Bayesian regression, and given a new online measurement output\ny(k) = \u2206(z(k)) + v(k), (19)\nthe posterior mean and variance (15) at the kth-step qk(\u2206u) = N (\u2206u|mku,Sku) can be rewritten in terms of the posterior q1:k\u22121(\u2206u) = N (\u2206u|mk\u22121u ,Sk\u22121u ) with\nmku = S k u(S k\u22121 u m k u + \u03c3 \u22122 \u03a6 > k y(k)) (20a) Sku = (S k\u22121 u + \u03c3 \u22122 \u03a6 > k \u03a6k) \u22121 (20b)\nwith kernel \u03a6k = KzMK \u22121 M |z=z(k) and [\u03a6(z(k))]j = \u03c6(z(k), zu(j)). Then (18a) can be seen as a linear combination of M kernel functions, each one corresponding to a pseudo input:\n\u00b5\u2206(z) = M\u2211 j=1 mu,j\u03c6(z, zu,j) = \u03a6(z)mu (21)\nNote that (21) can be interpreted as a weight-space representation of (18a). Thus, recursive least squares can be efficiently used to update (18a) and (18b) online under an incoming data stream of measurement points. Given a new data point {z(k), y(k)}, the posterior mean and variance can be updated by: mku = m k\u22121 u +Lkrk rk = y(k)\u2212\u03a6kmk\u22121u Lk = S k\u22121 u \u03a6 > kG \u22121 k Gk = \u03bb+ \u03a6kS k\u22121 u \u03a6 > k\nSku = \u03bb \u22121(Sk\u22121u \u2212LkGkL>k )\n(22)\nwhere 0 < \u03bb \u2264 1 is the forgetting factor. The recursion starts fromm0u and S 0 u, which can be seen as the prior of the GP. This recursive online sparse GP, which is one of the main contributions of this paper, can be embedded into the predictor of an MPC scheme, and is capable of dealing with varying disturbances and sudden changes in the dynamics.\nRemark 1. (Initial guess for m0u and S 0 u.) In (22), the online update routine starts from m0u, which can be provided by an offline trained GP. The initial posterior variance S0u is a user-defined parameter matrix and usually selected as S0u = \u03b2\n\u22121IM with 0 < \u03b2 \u2264 1. According to the authors\u2019 experience, if the function space to be learnt is far away from the training data set DN , one should choose a smaller \u03b2 indicating a smaller confidence level for the trained GP; Conversely, one chooses \u03b2 \u2248 1.\nRemark 2. Comparing with the existing online GP methods, such as the (sparse online GP, SOGP) in [32], and the evolving GP in [33, 34], the proposed recursive online sparse Gaussian process is equivalent to directly updating the posterior distribution q(\u2206u) with no need\nto re-optimize the hyperparameters or update the \u201ddictionary\u201d at every time step. Furthermore, both the posterior mean mu and variance Su will be updated simultaneously, which benefits the uncertainty propagation within the prediction horizon in an MPC strategy."
        },
        {
            "heading": "3.3 Dual Gaussian Process Structure",
            "text": "Despite the adapting capability of the recursive online sparse GP, the learned dynamics obtained during the offline training phase, will be forgotten during the online learning phase. This means that, if the current evidence during the online control phase does not support the dynamics seen, they will gradually disappear via the forgetting factor \u03bb according to (22). For example, the \u201dknowledge\u201d for the uncertainties with large state bias will fade in case the state reaches equilibrium for a while. Inspired by the biological concept of \u201dlong/short term memory\u201d, we present a novel structure named Dual Gaussian Process (see Fig. 1), which allows to store collected experience and able to prevent knowledge forgetting.\nThe DGP structure mainly consists of two GPs: The first GP corresponds to the long-term GP, which is employed to learn all the time-independent uncertainties and disturbances. The hyperparameters and the pseudo points of the long-term GP are kept fixed during the online learning phase, and will be batch updated after each mission. This makes the long-term GP to have the ability to keep the accumulated experience preserved in terms of a long-term memory, but still evolve from mission to mission. On the other hand, the short-term GP is utilized to adapt to online time-varying disturbances and (sudden) changes in system dynamics. It is worth mentioning that, the short-term GP learns around the predicted mean value of the long-term GP, and the posterior is recursively updated during the online learning phase. Hence, a single dimension of the unknown dynamics \u2206(z) can be rewritten as a sum of two GPs:\n\u2206(z) = \u2206l(z) + \u2206s(z) (23a)\n\u2206l(z) \u223c GP(\u00b5l(z), \u03ba(z, z\u2032)), (23b) \u2206s(z) \u223c GP(0, \u03bd(z, z\u2032)) (23c)\nwhere the subscript l and s represent \u201dlong-term\u201d and\n\u201dshort-term\u201d, respectively. \u03bd(z, z\u2032) denotes the covariance function for the short-term GP. For the simplicity of notation, the prior mean function is set as zero in the following derivation. Furthermore, the mean function \u00b5l(z) for the long-term GP is obtained from the offline training phase.\nAssumption 1. The long-term GP \u2206l and the shortterm GP \u2206s are independent with each other.\nNote that Assumption 1 is mild because the sum of two functions, which are drawn from two arbitrary Gaussian processes, is also a Gaussian process. Furthermore, the short-term GP is set to learn around the mean value of the long-term GP, and the long-term GP is kept fixed during the online update of the short-term GP.\nThen, considering the training set DN , the prior distribution for \u2206l and \u2206s are given by:\nP (\u2206l) = N (\u2206l | \u00b5l,KN ), (24a) P (\u2206s) = N (\u2206s | 0,VN ), (24b)\nwith \u2206l = vec(\u2206l(z(1)), . . . ,\u2206l(z(N)) and \u2206s = vec(\u2206s(z(1)), . . . ,\u2206s(z(N)) respectively. Moreover, the model likelihood is denoted as P (Y |\u2206l,\u2206s) = N (Y |\u2206l + \u2206s, \u03c32 IN ) where VN represents the Gram matrix with [V ]i,j = \u03bd(z(i), z(j)) for the short-term GP.\nTo deal with large data sets, we introduce two sets of pseudo points for the DGP, i.e., ul,i = \u2206l(zu,l,i) and us,i = \u2206s(zu,s,i) where z(\u00b7),i denote the M number of pseudo inputs for the long/short-term GP, respectively. The graphical model for DGP is shown in Fig. 2.\nSubsequently, one can obtain the following conditional distributions:\nP (\u2206l|ul) = N (\u2206l|KNMK\u22121M ul,KN \u2212QN ) (25a) P (\u2206s|us) = N (\u2206s|VNMV \u22121M us,VN \u2212ON ) (25b)\nwhere ON = VNMV \u22121 M VMN . Also, the marginal likeli-\nhood of DGP gives as:\nlogP (Y ) = log \u222b P (Y |\u2206l,\u2206s)P (\u2206l|ul)P (\u2206s|us) P (ul)P (us)d\u2206ld\u2206sduldus (26)\nNext, two variational distributions q(ul) = N (ul|mu,l,Su,l) and q(us) = N (us|mu,s,Su,s) are introduced to approximate the true posterior:\nP (\u2206l,\u2206s,ul,us|Y ) \u2248 P (\u2206l|ul)P (\u2206s|us)q(ul)q(us). (27)\nThen, the marginalized distributions of \u2206l and \u2206s\nq(\u2206l) = \u222b P (\u2206l|ul)q(ul)dul (28a)\nq(\u2206s) = \u222b P (\u2206s|us)q(us)dus (28b)\ncan be simply computed as\nq(\u2206l) = N ( ml\ufe37 \ufe38\ufe38 \ufe37 KNMK \u22121 M mu,l, Sl\ufe37 \ufe38\ufe38 \ufe37 KN + Q\u0302N ) (29a) q(\u2206s) = N (VNMV \u22121M mu,s\ufe38 \ufe37\ufe37 \ufe38 ms ,VN + O\u0302N\ufe38 \ufe37\ufe37 \ufe38 Ss ) (29b)\nwhere Q\u0302N = KNMK \u22121 M (Su,l \u2212 KM )K\u22121M KMN , and O\u0302N = VNMV \u22121 M (Su,s \u2212 VM )V \u22121M VMN .\nIt is worth mentioning that the posterior for long-term GP q(ul) is obtained after the offline training phase and it is fixed during the inference. Furthermore, the posterior q(us) for the short-term GP is updated with (24). Then we can obtain the lower bound of logP (Y ) for DGP as follows:\nL(q) , \u222b q (\u2206l,\u2206s,ul,us) log P (Y ,\u2206l,\u2206s,ul,us)\nq (\u2206l,\u2206s,ul,us)\nd\u2206ld\u2206sduldus\n= \u222b q(ul) \u222b P (\u2206s|us)q(us) \u222b P (\u2206l|ul)\nlogP (Y |\u2206l,\u2206s)d\u2206ld\u2206sdusdul \u2212KL(q (ul) ||P (ul))\u2212KL(q (us) ||P (us)) (30)\nDue to the fact that the posterior of the long-term GP is fixed during the online learning phase, we can equate the variational parameters of q(ul) to (15): mu,l = mu and Su,l = Su. Next we will compute the analytic form of (30) to get the optimal variational parameters for q(us). The inner integral for the first term of (30) can\nbe solved as:\u222b P (\u2206l|ul) logP (Y |\u2206l,\u2206s)d\u2206l\n= \u222b N (\u2206l|KNMK\u22121M ul,KN \u2212QN ) logP (Y |\u2206l,\u2206s)d\u2206l\n= logN (Y |KNMK\u22121M ul + \u2206s, \u03c32 IN )\u2212 1\n2\u03c32 tr(KN \u2212QN )\n(31) By merging the inner integral into the second integral\nin (32):\u222b P (\u2206s|us)q(us) \u222b P (\u2206l|ul) logP (Y |\u2206l,\u2206s)d\u2206sdus\n= \u222b q(\u2206s) logN (Y |KNMK\u22121M ul + \u2206s, \u03c32 IN )d\u2206s\n\u2212 1 2\u03c32 tr(KN \u2212QN )\n= logN (Y |KNMK\u22121M ul +ms, \u03c32 IN )\n\u2212 1 2\u03c32 tr(KN \u2212QN )\u2212 1 2\u03c32 tr(Ss). (32)\nSubstituting (32) back to (30), one has: L(q) = \u222b q(ul) logN (Y |KNMK\u22121M ul +ms, \u03c32 IN )dul\n\u2212KL(q (ul) ||P (ul))\u2212KL(q (us) ||P (us)) \u2212 1 2\u03c32 tr(KN \u2212QN )\u2212 1 2\u03c32 tr(Ss) (33)\n\u2264 log \u222b N (Y |KNMK\u22121M ul +ms, \u03c32 IN )P (ul) dul\n\u2212KL(q (us) ||P (us))\u2212 1\n2\u03c32 tr(KN \u2212QN )\u2212\n1\n2\u03c32 tr(Ss)\nUsing Gaussian identities, the integral in the long-term expression can be further simplified as:\u222b\nN (Y |KNMK\u22121M ul +ms, \u03c32 IN )P (ul) dul =\nN (Y |ms,QN + \u03c32 IN ). (34)\nFurthermore, the KL-divergence between two Gaussians is analytical, that is:\nKL(q (us) ||P (us)) = 1\n2 log |VM |+\n1 2 m>u,sV \u22121 M mu,s\n+ 1\n2 tr(Su,sV\n\u22121 M )\u2212\n1 2 M \u2212 1 2 log |Su,s| (35)\nConsequently, one gets the analytical form of L(q):\nL(q) = logN (Y |ms,QN +\u03c32 IN )\u2212 1\n2\u03c32 tr(KN\u2212QN )\n\u2212 1 2\u03c32 tr(Ss)\u2212 1 2 log |VM | \u2212 1 2 m>u,sV \u22121 M mu,s\n\u2212 1 2 tr(Su,sV \u22121 M ) + 1 2 M + 1 2 log |Su,s|. (36)\nTaking the derivative of L(q) with respect to the varia-\ntional parameters of q(us) and setting them as zeros, we can obtain the optimal q\u2217(us) with mean and variance:\nmu,s =VM (VM+VMNQ\u0303 \u22121 N VNM ) \u22121VMNQ\u0303 \u22121 N Y (37a)\nSu,s = VM ( VM + \u03c3 \u22122 VMNVNM )\u22121 VM (37b)\nwhere Q\u0303N = QN + \u03c3 2 IN . Combining (28) with the learned variational parameters, one can derive the predictive distribution of both of the GPs:\nq(\u2206\u2217l ) = \u222b P (\u2206\u2217l |ul)q\u2217(ul)du\u2217l , N (\u00b5\u2217l , \u03c32\u2217l ) (38a)\nq(\u2206\u2217s ) = \u222b P (\u2206\u2217s |us)q\u2217(us)du\u2217s , N (\u00b5\u2217s , \u03c32\u2217s ) (38b)\nwith \u00b5\u2217l = K\u2217MK \u22121 M mu,l, \u00b5 \u2217 s = V\u2217MV \u22121 M mu,s, \u03c32\u2217l = k\u2217\u2217 \u2212K\u2217MK\u22121M KM\u2217 +K\u2217MK\u22121M Su,lK\u22121M KM\u2217, and \u03c32\u2217s = v\u2217\u2217\u2212V\u2217MV \u22121M VM\u2217+V\u2217MV \u22121M Su,sV \u22121M VM\u2217.\nFinally, the predictive distribution of the latent function \u2206 at a new test point z\u2217 is given by\nq(\u2206\u2217) = \u222b P (\u2206\u2217|\u2206\u2217l ,\u2206\u2217s )q(\u2206\u2217l )q(\u2206\u2217s )d\u2206\u2217l d\u2206\u2217s (39)\nwhich leads to the following predictive mean and variance of the DGP:\n\u00b5\u2206(z \u2217) = K\u2217MK \u22121 M mu,l + V\u2217MV \u22121 M mu,s (40) \u03c32\u2206(z \u2217) = k\u2217\u2217 + v\u2217\u2217 \u2212K\u2217MK\u22121M KM\u2217 \u2212 V\u2217MV \u22121M VM\u2217\n+K\u2217MK \u22121 M Su,lK \u22121 M KM\u2217 + V\u2217MV \u22121 M Su,sV \u22121 M VM\u2217\nNote that obtaining these analytic formulas are one of the main contributions of the paper, as the predictive distribution q(\u2206\u2217) of the latent function \u2206 can be used for multi-step prediction over a given horizon as it is done in the MPC scheme in the next section. Furthermore, to update the predictive mean and variance of the shortterm GP, one can first recursively update the posterior distribution q(us) with (24) using online data points, then marginalize the posterior on us as in (28), leading to q(\u2206\u2217)."
        },
        {
            "heading": "4 DGP-MPC Scheme",
            "text": "In this section, we reformulate the MPC problem (3) by embedding into the prediction the proposed dual GP structure based model, i.e., the predictive posterior distribution. Due to the stochastic property of the dual Gaussian process, there is an uncertainty \u2206(\u00b7) associated with the prediction which can be inferred by the DGP structure. This directly leads to the random variable xi|k within the prediction model. Thus, the GP input z becomes a random variable during the state propagation, and the posterior of \u2206. Under the assumption\nthat\nzi|k = (x > i|k,u > i|k) \u223c N (\u00b5zi ,\u03a3zi ) = N ([ \u00b5xi\nui|k\n] , [ \u03a3xi 0\n0 0\n]) , (41)\nthe contribution of the GP model to the statepropagation is\nP (\u2206i|k|\u00b5zi ,\u03a3zi ) = \u222b P (\u2206i|k|zi|k)P (zi|k|\u00b5zi ,\u03a3zi )dzi|k\n(42) One can observe that the posterior P (\u2206i|k|\u00b5zi ,\u03a3zi ) is a non-Gaussian distribution and intractable to be computed analytically. In this paper, we further extend the exact moment matching approach [35, 36] into the proposed DGP structure to fit the posterior optimally with the first and second moments of the posterior distribution, that is: P (\u2206i|k|\u00b5zi ,\u03a3zi ) \u2248 N (\u00b5i\u2206,\u03a3i\u2206). See Appendix B to find the details about the derivation of this Gaussian approximation.\nThen the prediction model in (3) can be rewritten as xi+1|k \u223c N (\u00b5i+1x ,\u03a3i+1x ) with mean and variance:\n\u00b5i+1x = A\u00b5 i x +Bui|k + \u00b5 i \u2206, (43a) \u03a3i+1x = A\u03a3 i xA > + \u03a3i\u2206 + \u03a3\u03b5, (43b)\nwhere \u03a3 = diag(\u03c3 2 ,1, . . . , \u03c3 2 ,nx). On the other hand, the stochastic state also results in a probabilistic cost function J . Generally one chooses the expected value to represent the stochastic cost, that is: E[J(x(k),Uk)]. Recalling the prediction model (43), the stochastic cost function can be expressed as a deterministic form:\nE[J(x(k),Uk)] = H\u22121\u2211 i=0 [ l(\u00b5ix,ui|k) + tr(Q\u03a3 i x) ] +\nlf(\u00b5 H x ) + tr(Qf\u03a3 H x ) (44)\nNext, we discuss the satisfaction of the constraints on the state and the control input. As xi|k is a random variable with mean \u00b5ix and variance \u03a3 i x, we intend to satisfy the polytopic constraints in a probabilistic sense, i.e., by the chance constraint [13,37,38]:\nP (xi|k \u2208 X ) , P (Cx\u00b5ix \u2264 cx) \u2265 \u03b3, (45)\nwhere \u03b3 is a chosen probability level of the credibility sets. We utilize the quantile function$(\u03b3) to convert the above given chance constraints into deterministic ones. Denoting ej = Cx,jxi \u2212 cx,j with j = 1, ..., nc, then we have:\nej \u223c N (Cx,j\u00b5ix \u2212 cx,j ,Cx,j\u03a3ixC>x,j). (46)\nThus, the chance constraint (45) is equivalent to$(\u03b3) \u2264 0 and finally leads to:\nCx,j\u00b5 i x \u2264 cx,j \u2212$(\u03b3) \u221a Cx,j\u03a3ixC > x,j , j \u2208 Inc1 . (47)\nFinally, the DGP-MPC problem in this paper is transformed into a deterministic formulation:\nmin Uk (44)\ns.t. (4b), (43), (47)\nx0|k = x(k),u0|k = u(k).\n(48)\nBecause the stochastic cost has been transformed into a deterministic form, most nonlinear optimization algorithms can be utilized to solve the problem. The specific implementation steps are summarized in Algorithm 1.\nAlgorithm 1 Learning based model predictive control strategy with Dual Gaussian process\nInitialization: Constraints X , U , step size Ts, k = 0, m0u,s = 0, S 0 u,s = \u03b2\n\u22121IM , \u03bb, max. number of iterations \u03c4max.\n1: for \u03c4 = 1, ..., \u03c4max do Offline Phase: 2: Generate the initial training set D0 3: Train the long-term GP to obtain q (ul)\nOnline Phase: 4: for each time instant k = 1, 2, ..., do 5: Obtain current state x(k); 6: Compute measurement output y(k) by (19); 7: Update mku,s and S k u,s using (22); 8: for i = 0, ...,H do 9: State propagation\n10: xi+1|k \u223c N (\u00b5i+1x ,\u03a3i+1x ) 11: with (B.4), (B.10) 12: end for 13: Solve (48) for Uk; 14: Apply u(k)\u2190 u0|k on the system (2); 15: Record data Dk \u2190 Dk\u22121 \u222a {x(k), u(k)}. 16: end for 17: Set D0 \u2190 Dk and go back to offline phase. 18: end for"
        },
        {
            "heading": "5 Illustrative Examples",
            "text": "In this section, we present the results and insights gained by applying DGP-MPC Algorithm 1 described in Section 4 for trajectory tracking of a quadrotor to illustrate its effectiveness."
        },
        {
            "heading": "5.1 Quadrotor dynamics",
            "text": "The quadrotor is modeled as a rigid body with four rotors. Let I denote the inertial frame and B denote the body fixed frame which is attached to the center of mass\n(COM) of the quadrotor and oriented according to I. Define p \u2208 R3 and v \u2208 R3 as the position and velocity of the COM. Denoting \u03b6 = [ \u03c6 \u03b8 \u03c8 ]> as the Euler angles\nof the quadrotor, then from the Newton-Euler formulation, one can obtain a motion model for the quadrotor:\np\u0307 = v, mv\u0307 = mge3 \u2212 TRe3 + F\u2206, \u03b6\u0307 = \u0398\u03c9, J\u03c9\u0307 = \u2212\u03c9\u00d7J\u03c9 + \u03c4 + \u03c4\u2206\n(49)\nwhere R is the rotation matrix from B to I with Z-Y-X sequence, \u03c9 \u2208 R3 denotes the angular velocity of B with respect to I, and\n\u0398 =\n[ c\u03b8 0 \u2212s\u03b8c\u03d5\n0 1 s\u03d5\ns\u03b8 0 c\u03b8c\u03d5\n]\u22121 ,\nwith s and c being short hands for sine and cosine, respectively. m = 1.9kg is the total mass of the quadrotor, e3 = [0 0 1]\n> denotes the unit vector aligning with the gravity g in I, (\u00b7)\u00d7 : R3 \u2192 R3\u00d73 denotes the crossproduct operator, J = diag(5.9, 5.9, 10.7)\u00b710\u22123kg \u00b7m2 is the inertia matrix, T \u2208 R+ is the thrust force generated by the four rotors, and \u03c4 \u2208 R3 represents the control torque expressed in B. The terms F\u2206 and \u03c4\u2206 represent unknown force and torque affecting the quadrotor due to time-varying uncertainties and unmodeled dynamics, such as external wind, complex interactions of rotor airflows affected by the ground and walls, friction and flapping dynamics of the rotor blades. Further details about the rest of the system parameters and the derivation of the terms F\u2206 and \u03c4\u2206 can be found in [39].\nBy denoting x = [p> v> \u03b6> \u03c9>]> \u2208 (R12)R and u = [T \u03c4>]> \u2208 (R4)R, the continuous-time model (49) can be linearized and discretized resulting in the dynamics given by (2). The challenges posed by this application are:\n(1) The ideal dynamics described by the first principles cannot capture all the unknown internal nonlinearities and external disturbances accurately, especially when there exist time-varying disturbances such as aerodynamic effects and varying winds. This is addressed by the recursive online sparse GP method in Section 3.2.\n(2) It is not clear how the quadrotor can memorize and exploit historical data when the system experiences a similar environment while performing a repetitive task. This is addressed by the dual GP structure in Section 3.3.\n(3) For the sake of safety, the robust satisfaction of state and input constraints should be guaranteed. Here the state constraints refer to a limited safe space where the quadrotor can fly and the input constraints correspond to the maximal thrust force and torque that the quadrotor could provide. This is addressed by the dual GPMPC strategy in Section 4."
        },
        {
            "heading": "5.2 Data Collection",
            "text": "Based on our considerations and according to the disturbance model given in [39], the GP inputs are designed as z = [\u03b6> v> T ]> \u2208 (R7)R. Then, to generate the training data set, the quadrotor is enabled to track a random reference trajectory and explore the space. The pseudo-random trajectory is designed as xr(t) = 1.5 sin(t) + 1.5 sin(0.33t), yr(t) = sin(1.1t + \u03c0/2) + sin(0.11t), and zr(t) = sin(0.33t+ \u03c0/2) + sin(0.76t) + 3. It is worth mentioning that the training data can also be collected by flying the quadrotor manually. We use the linear MPC to approximately follow the reference by the quadrotor for 50s, and collect the data with 20Hz, resulting in a training\ndata set with size N = 1000. Furthermore, we employ a constant wind with speed (1 3 \u2212 2)> m/s in frame I which occurs as a heading-dependent uncertainty in the dynamics (49) during the offline training phase. After the data collection phase, the long-term GP is trained with pseudo points with size M = 20, resulting in the posterior q(ul). Furthermore, the posterior of short-term GP is initialized as mu,s = 0, Su,s = 10 2I."
        },
        {
            "heading": "5.3 Simulation Analysis",
            "text": "The quadrotor is forced to track a helix trajectory in 3D space, which is described by: xd(t) = 2 sin(t), yd(t) = 2 cos(t), and zd(t) = 2t/T + 2 for a total operation time T = 20s. The sampling time Ts is 0.05s. Furthermore, to validate the effectiveness of the proposed strategy, the constant wind turns into a time-varying wind at 10s. The discrete-time nonlinear system dynamics of the quadrotor are linearized and decomposed into two LTI systems, i.e., the outer-loop translational subsystem and the inner-loop rotational subsystem. To simplify the controller design and speed up the simulation, we adopt a PD controller for the rotational subsystem and use the MPC for the translational subsystem. It is worth mentioning that, despite the linearizing effect of feedback control in the rotational subsystem driven by PD controller, the nonlinearities and additional dynamics experienced there affect the translational system, which interprets the necessity of a GP compensation. For the MPC scheme, the prediction horizon is chosen as H = 5, and the weight matrices in the cost function are Q = diag(1, 1, 20, 1, 1, 20), and R = diag(1, 1, 1).\nThe 3D trajectory of the quadrotor controlled by the proposed DGP-MPC for the 2nd iteration is intuitively depicted in Fig. 3. The mission of trajectory tracking is achieved and the tracking performance is adequate though the constant wind from 0s - 10s, which suddenly turns into the time-varying wind at 10s. The learned unknown function \u2206 is depicted in Fig. 4. It is clear that after the 2nd iteration, i.e., with two-task experience, the predictive mean of the DGP structure evaluated at the true state values at time t can track the true function in real-time with a fast convergence process because the memory of the trained function is kept in the long-term GP.\nTo show the advantage of the proposed DGP-MPC strategy, the following methods are compared with the DGP solution:\n(1) Baseline MPC: MPC strategy using the baseline linear model without any GP augmentation;\n(2) Long-term only GP-MPC (LGP-MPC): MPC strategy with offline trained GP;\n(3) Online GP-MPC (OGP-MPC): MPC strategy with\noffline trained GP which is recursively update online with (22).\nTo compare the tracking results with these MPC schemes, Fig. 5 qualitatively shows the quadrotor trajectories by the controllers projected to the X-Y plane, where the color of the trajectory indicates the current time. One can easily notice that, in Fig. 5(a) and Fig. 5(b), both the baseline MPC and LGP-MPC have poor dynamic responses during the whole online phase due to their inaccurate prediction model; in Fig. 5(c), owing to the recursive online capability of our algorithm, the OGP-MPC shows a relatively better performance than baseline and LGP-MPC even during the effect of the unknown time-varying wind. Comparing with Fig. 5(c), the results of the DGP-MPC given in Fig. 5(d) show the best control performance during the entire task. The reason is that the proposed dual GP\nstructure enables the real-time accurate compensation of both the system uncertainties and time-varying disturbances. Furthermore, the DGP-MPC preserves the historical data of the repetitive task, which leads to a more precise estimation of the unknown dynamics especially in the first half of the task.\nThe ability of having long-term memory together with active learning with the proposed DGP could also be validated in Figs. 6-7, which depicts the absolute value of GP estimation error |\u00b5\u2206,i \u2212 \u2206i| of the LGP, OGP, and DGP in a repetitive task and visualizes the comparison of the mean squared error (MSE) of the predictive mean and true function value for DGP and OGP within the same simulation scenario through the different task phases. One can easily deduce that the DGP is capable of estimating the unknown function \u2206 more accurately within the first 10s of the execution while the LGP results in a dramatic estimation error after \u2206 be-\ngins to vary with time. On the other hand, the OGP needs to re-learn \u2206 at the beginning since it inevitably forgets the previously learned parts of function during the recursive update process. Then, after 10s, when fast adaptation is required to cope with the time-varying effects both OGP and DGP perform equally well. In this case OGP shows a slightly better performance as DGP is more cautious in the adaptation by trying to exploit its long-term memory.\nFurthermore, the quantitative evaluation of the proposed DGP-MPC approach in comparison with the baseline controllers is provided in Table. 1. One can see that the performance of the proposed DGP-MPC approach in executing the same trajectory dramatically improves through multiple experiences and after only one attempt it shows much better performance compared to the other control methods.\nRemark 3. It is worth pointing out that for a nonrepetitive task, the proposed DGP-MPC and OGPMPC have similar control performance due to their abilities of online updating according to (22). However, in terms of the implementation, the posterior qk(\u2206) of OGP-MPC with a single GP structure will continuously update with online streaming data, while the initial posterior q0(\u2206) obtained from the offline training phase will gradually vanish during the online phase. In contrast, the DGP-MPC proposed in this paper has a dual GP structure with long-term GP and short-term GP. As a part of the overall posterior distribution, the longterm GP posterior with offline trained historical data remains fixed and only the short-term GP posterior is updated with the online data to cope with complex timevarying conditions. Therefore, the proposed DGP-MPC approach has a clear advantage for repetitive tasks."
        },
        {
            "heading": "6 Conclusions",
            "text": "A novel Gaussian Process based online learning approach for uncertain systems together with an adaptive model predictive control scheme have been proposed in this paper. Specifically, a dual Gaussian process structure has been designed to learn the system uncertainties with both long-term remembering and rapid\nonline learning capabilities. The knowledge of reoccurring dynamics are learned and preserved by a long-term GP while the short-term GP performs recursive online adaption to compensate unlearned or time-varying uncertainties during the control operation. The features and effectiveness of our approach have been illustrated by numerical simulations and compared with multiple MPC schemes. The proposed DGP structure is not only limited to MPC, but also can be extended to any GPbased controller which requires both \u201dmemory\u201d and \u201dlearning\u201d. Future work will consider the generalization of the DGP structure to other control approaches."
        },
        {
            "heading": "A Derivation of variational parameters",
            "text": "According to the definition of ELBO, one has:\nL(q) = \u222b q(\u2206,\u2206u) log P (Y ,\u2206,\u2206u)\nq(\u2206,\u2206u) d\u2206d\u2206u\n= \u222b P (\u2206 |\u2206u)q(\u2206u)\nlog P (Y |\u2206) P (\u2206|\u2206u)P (\u2206u)\nP (\u2206|\u2206u)q(\u2206u)\nd\u2206d\u2206u\n= F (q) + \u222b q(\u2206u) log P (\u2206u)\nq(\u2206u) d\u2206u (A.1)\nwhere the first term F (q) can be derived as:\nF (q) = \u222b q (\u2206u) \u222b P (\u2206|\u2206u) logP (Y |\u2206)d\u2206d\u2206u\n(A.2)\nThe term inside the integral in (A.2) can be computed as\u222b\nP (\u2206 |\u2206u) logP (Y |\u2206)d\u2206 = \u2212 |N | 2 log 2\u03c0\u2212 1 2 log |\u03c32 IN | \u2212 1 2\u03c32 (Y \u2212KNMK\u22121M \u2206u)>(Y \u2212KNMK\u22121M \u2206u)\n\u2212 1 2\u03c32 tr (KN \u2212QN ) (A.3)\nwhere QN = KNMK \u22121 M KMN . By benoting q (\u2206u) = N (\u2206u|mu,Su), we have the analytical form of F (q) as follows:\nF (q) = \u2212|N | 2 log 2\u03c0 \u2212 1 2 log |\u03c32 IN | \u2212 1 2\u03c32 Y >Y\n+ 1 \u03c32 m>uK \u22121 M KMNY \u2212 1 2\u03c32 m>uK \u22121 M KMNKNMK \u22121 M mu\n\u2212 1 2\u03c32 tr(K\u22121M KMNKNMK \u22121 M Su)\u2212 1 2\u03c32 tr (KN \u2212QN )\n(A.4)\nFurthermore, the second term in ELBO (A.1) represents the KL divergence between q (\u2206u) and P (\u2206u):\u222b\nq(\u2206u) log P (\u2206u)\nq(\u2206u) d\u2206u\n= Eq[logP (\u2206u)]\u2212 Eq[log q(\u2206u)] = \u22121 2 log |KM | \u2212 1 2 m>uK \u22121 M \u2212 1 2 tr ( SuK \u22121 M ) + |M |\n2 +\n1 2 log |Su| (A.5)\nBased on these derivations, one can readily get the analytical form of the ELBO for the variational distribution q(\u2206,\u2206u):\nL(q) = \u2212|N | 2 log 2\u03c0 \u2212 1 2 log |\u03c32 IN | \u2212 1 2\u03c32 Y >Y\n+ 1 \u03c32 m>uK \u22121 M KMNY \u2212 1 2\u03c32 m>uK \u22121 M KMNKNMK \u22121 M mu\n\u2212 1 2\u03c32 tr(K\u22121M KMNKNMK \u22121 M Su)\u2212 1 2\u03c32 tr(KN \u2212QN )\n\u2212 1 2 log |KM | \u2212 1 2 m>uK \u22121 M \u2212 1 2 tr ( SuK \u22121 M ) + |M |\n2 +\n1 2 log |Su| (A.6)\nTaking the partial derivatives of (A.6) w.r.tmu and Su respectively and set them as zeros, one can finally get the optimal q\u2217(\u2206u) as in (15)."
        },
        {
            "heading": "B Uncertainty propagation for DGP",
            "text": "In this section we will derive the mathematical equations necessary for multiple-step ahead prediction with the DGP structure described in Section 3.3.\nDuring the state propagation procedure given in (43), the GP input becomes a stochastic variable P (z\u2217|\u00b5\u0303, \u03a3\u0303) = N (\u00b5\u0303, \u03a3\u0303). This leads to the following predictive distribution:\nP (\u2206\u2217|\u00b5\u0303, \u03a3\u0303,DN )= \u222b P (\u2206\u2217|z\u2217,D)P (z\u2217|\u00b5\u0303, \u03a3\u0303)dz\u2217 (B.1)\nSince P (\u2206\u2217|z\u2217,DN ) is a nonlinear function of z\u2217, the predictive distribution (B.1) is not Gaussian. So it is intractable to obtain the analytical form of the integral (B.1). In this paper, we use exact moment matching to make Gaussian approximations to (B.1).\nFirst, we rewrite the predictive mean of the DGP as:\n\u00b5\u2206(z \u2217) = K\u2217M\u03b2l + V\u2217M\u03b2s (B.2)\nwhere \u03b2l = K \u22121 M mu,l, \u03b2s = V \u22121 M mu,s. Then, for predicting at uncertain input z\u2217 \u223c N (\u00b5\u0303, \u03a3\u0303), we need to compute the first moment mean\nm\u0304(\u00b5\u0303, \u03a3\u0303) = Ez\u2217 [\u00b5\u2206(z\u2217)] (B.3)\naccording to the law of iterated expectations. For the convenience of notation, we denote the Gaussian kernel (7) as \u03ba (z, z\u2032) = cN (z|z\u2032,\u039b) where c = \u03c32f (2\u03c0)\nD/2|\u039b|1/2 and D = nx + nu. Thus, using the product of two Gaussian identities, one has:\nm\u0304(\u00b5\u0303, \u03a3\u0303) = \u222b (K\u2217M\u03b2l + V\u2217M\u03b2s)P (z \u2217|\u00b5\u0303, \u03a3\u0303)dz\u2217\n= M\u2211 j=1 \u03b2l,jLl,j + M\u2211 j=1 \u03b2s,jLs,j = \u03b2>l L (1) l + \u03b2 > s L (1) s\n(B.4)\nwhere the elements of vector L (1) l and L (1) s are\nLl,j = clN (\u00b5\u0303|z(j)u,l ,\u039bl + \u03a3\u0303) (B.5a)\nLs,j = csN (\u00b5\u0303|z(j)u,s ,\u039bs + \u03a3\u0303) (B.5b)\nNext, we compute the variance of the predictive distribution. Similarly, rewriting the variance of the DGP in a concise form, one has:\n\u03c32\u2206(z \u2217) = k\u2217\u2217+v\u2217\u2217\u2212K\u2217MBlKM\u2217\u2212V\u2217MBsVM\u2217 (B.6)\nwhere Bl = K \u22121 M \u2212 K\u22121M Su,lK\u22121M and Bs = V \u22121M \u2212 V \u22121M Su,sV \u22121 M are the terms independent of test point z \u2217.\nAccording to the law of iterated conditional variances, the variance v\u0304(\u00b5\u0303, \u03a3\u0303) can be derived as:\nv\u0304(\u00b5\u0303, \u03a3\u0303) = Ez\u2217 [\u03c32\u2206(z\u2217)] + Ez\u2217 [\u00b5\u2206(z\u2217)2]\u2212 E2z\u2217 [\u00b5\u2206(z\u2217)] (B.7)\nwhere:\nEz\u2217 [\u03c32\u2206(z\u2217)] = \u03c32fl + \u03c32fs \u2212 \u2211 i\u2208IN1 \u2211 j\u2208IN1 Bi,jl L i,j l \u2212Bi,js Li,js\nEz\u2217 [\u00b5\u2206(z\u2217)2] = \u2211 i\u2208IN1 \u2211 j\u2208IN1 \u03b2l,i\u03b2l,jL i,j l + \u03b2s,i\u03b2s,jL i,j s\n+ 2\u03b2l,i\u03b2s,jL\u0304 i,j ,\nE2z\u2217 [\u00b5\u2206(z\u2217)] = m\u0304(\u00b5\u0303, \u03a3\u0303)2.\nTherefore,\nLi,j(\u00b7) = c 2 (\u00b7)N (ziu(\u00b7)|zju(\u00b7), 2\u039b(\u00b7))N (\u00b5\u0303|zd(\u00b7), \u03a3\u0303 +\n1 2 \u039b(\u00b7)),\n(B.8)\nL\u0304i,j = c2l c 2 sN (ziu,l|zju,s,\u039bl + \u039bs)N (\u00b5\u0303|\u03bei,j ,\u039e). (B.9)\nwhere zd(\u00b7) = (ziu(\u00b7)+z j u(\u00b7))/2, \u03bei,j = \u039bs(\u039bl+\u039bs) \u22121ziu,l+ \u039bl(\u039bl +\u039bs) \u22121zju,s, \u039e = (\u039b \u22121 l +\u039b \u22121 s ) \u22121 + \u03a3\u0303. This leads to the solution for the predictive variance of:\nv\u0304(\u00b5\u0303, \u03a3\u0303) = \u03c32fl + \u03c3 2 fs \u2212 tr((Bl \u2212 \u03b2l\u03b2>l )L(2)l )\n\u2212 tr((Bs \u2212 \u03b2s\u03b2>s )L(2)s ) + 2tr(\u03b2l\u03b2>s L\u0304) \u2212 m\u0304(\u00b5\u0303, \u03a3\u0303)2. (B.10)\nIt is worth mentioning that, if the GP input is deterministic without any uncertainty, i.e., \u03a3\u0303 = 0, then m\u0304(\u00b5\u0303,0) tends to \u00b5\u2206(z \u2217) and v\u0304(\u00b5\u0303,0) collapses to \u03c32\u2206(z \u2217) as we expect."
        }
    ],
    "title": "LearningForPredictiveControl: ADualGaussianProcessApproach",
    "year": 2022
}