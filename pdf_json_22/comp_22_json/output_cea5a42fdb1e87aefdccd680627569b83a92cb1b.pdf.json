{
    "authors": [
        {
            "affiliations": [],
            "name": "Claudia Peersman"
        },
        {
            "affiliations": [],
            "name": "Matthew Edwards"
        },
        {
            "affiliations": [],
            "name": "Emma Williams"
        },
        {
            "affiliations": [],
            "name": "Awais Rashid"
        }
    ],
    "id": "SP:c1ec0b11d7bea1dda0785785b3f2bdd82924086c",
    "references": [
        {
            "authors": [
                "P. Jeney"
            ],
            "title": "Combatting child sexual abuse online",
            "venue": "http://www.europarl. europa.eu/RegData/etudes/STUD/2015/536481/IPOL_STU",
            "year": 2015
        },
        {
            "authors": [
                "C. Troncoso"
            ],
            "title": "Privacy & online rights knowledge area (2019)",
            "year": 2019
        },
        {
            "authors": [
                "R. Dingledine",
                "N. Mathewson",
                "P. Syverson"
            ],
            "title": "Tor: The second-generation onion router",
            "venue": "Technical Report, Naval Research Lab Washington DC",
            "year": 2004
        },
        {
            "authors": [
                "M.G. Reed",
                "P.F. Syverson",
                "D.M. Goldschlag"
            ],
            "title": "Anonymous connections and onion routing",
            "venue": "IEEE Journal on Selected areas in Communications 16 ",
            "year": 1998
        },
        {
            "authors": [
                "A. Rocha",
                "W.J. Scheirer",
                "C.W. Forstall",
                "T. Cavalcante",
                "A. Theophilo",
                "B. Shen",
                "A.R. Carvalho",
                "E. Stamatatos"
            ],
            "title": "Authorship attribution for social media forensics",
            "venue": "IEEE Transactions on Information Forensics and Security 12 ",
            "year": 2017
        },
        {
            "authors": [
                "M. Koppel",
                "J. Schler",
                "S. Argamon"
            ],
            "title": "Authorship attribution in the wild",
            "venue": "Language Resources and Evaluation 45 ",
            "year": 2011
        },
        {
            "authors": [
                "R.H. G\u00e1lvez",
                "A. Gravano"
            ],
            "title": "Assessing the usefulness of online message board mining in automatic stock prediction systems",
            "venue": "Journal of Computational Science 19 ",
            "year": 2017
        },
        {
            "authors": [
                "H. Van Halteren",
                "H. Baayen",
                "F. Tweedie",
                "M. Haverkort",
                "A. Neijt"
            ],
            "title": "New machine learning methods demonstrate the existence of a human stylome",
            "venue": "Journal of Quantitative Linguistics 12 ",
            "year": 2005
        },
        {
            "authors": [
                "M. Dobson"
            ],
            "title": "The Making of the National Poet: Shakespeare",
            "venue": "Adaptation and Authorship, 1660-1769: Shakespeare, Adaptation and Authorship, 1660-1769, Clarendon Press",
            "year": 1992
        },
        {
            "authors": [
                "F. Mosteller",
                "D. Wallace"
            ],
            "title": "Inference and disputed authorship: The Federalist",
            "venue": "Addison-Wesley",
            "year": 1964
        },
        {
            "authors": [
                "P. Juola"
            ],
            "title": "Authorship attribution",
            "venue": "Foundations and Trends\u00ae in Information Retrieval 1 ",
            "year": 2008
        },
        {
            "authors": [
                "A. Mukherjee",
                "B. Liu"
            ],
            "title": "Improving gender classification of blog authors",
            "venue": "in: Proceedings of the 2010 conference on Empirical Methods in natural Language Processing, Association for Computational Linguistics,",
            "year": 2010
        },
        {
            "authors": [
                "C. Zhang",
                "P. Zhang"
            ],
            "title": "Predicting gender from blog posts",
            "venue": "University of Massachussetts Amherst, USA ",
            "year": 2010
        },
        {
            "authors": [
                "S. Argamon",
                "M. Koppel",
                "J.W. Pennebaker",
                "J. Schler"
            ],
            "title": "Automatically profiling the author of an anonymous text",
            "venue": "Communications of the ACM 52 ",
            "year": 2009
        },
        {
            "authors": [
                "M. Koppel",
                "S. Argamon",
                "A.R. Shimoni"
            ],
            "title": "Automatically categorizing written texts by author gender",
            "venue": "Literary and Linguistic Computing 17 ",
            "year": 2002
        },
        {
            "authors": [
                "J.R. McMillan",
                "A.K. Clifton",
                "D. McGrath",
                "W.S. Gale"
            ],
            "title": "Women\u2019s language: Uncertainty or interpersonal sensitivity and emotionality",
            "venue": "Sex Roles 3 ",
            "year": 1977
        },
        {
            "authors": [
                "D. Biber",
                "S. Conrad",
                "R. Reppen"
            ],
            "title": "Corpus linguistics: Investigating language structure and use",
            "venue": "Cambridge University Press",
            "year": 1998
        },
        {
            "authors": [
                "A. Mulac",
                "D.R. Seibold",
                "J.L. Farris"
            ],
            "title": "Female and male managers\u2019 and professionals\u2019 criticism giving: Differences in language use and effects",
            "venue": "Journal of Language and Social Psychology 19 ",
            "year": 2000
        },
        {
            "authors": [
                "M.R. Mehl"
            ],
            "title": "J",
            "venue": "W. Pennebaker, The sounds of social life: a psychometric analysis of students\u2019 daily social environments and natural conversations., Journal of personality and social psychology 84 ",
            "year": 2003
        },
        {
            "authors": [
                "M.L. Newman",
                "C.J. Groom",
                "L.D. Handelman"
            ],
            "title": "J",
            "venue": "W. Pennebaker, Gender differences in language use: An analysis of 14,000 text samples, Discourse Processes 45 ",
            "year": 2008
        },
        {
            "authors": [
                "K. Keune"
            ],
            "title": "Explaining register and sociolinguistic variation in the lexicon: Corpus studies on Dutch",
            "venue": "Ph.D. thesis, Radboud Universiteit Nijmegen",
            "year": 2012
        },
        {
            "authors": [
                "M. Koppel",
                "J. Schler",
                "S. Argamon"
            ],
            "title": "Computational methods in authorship attribution",
            "venue": "Journal of the Association for Information Science and Technology 60 ",
            "year": 2009
        },
        {
            "authors": [
                "F. Al Zamal",
                "W. Liu"
            ],
            "title": "D",
            "venue": "Ruths, Homophily and latent attribute inference: Inferring latent attributes of twitter users from neighbors., ICWSM 270 ",
            "year": 2012
        },
        {
            "authors": [
                "D. Bamman",
                "J. Eisenstein",
                "T. Schnoebelen"
            ],
            "title": "Gender in Twitter: Styles",
            "venue": "stances, and social networks, CoRR abs/1210.4567 ",
            "year": 2012
        },
        {
            "authors": [
                "F. Rangel",
                "P. Rosso",
                "M. Koppel",
                "E. Stamatatos",
                "G. Inches"
            ],
            "title": "Overview of the author profiling task at PAN 2013, in: CLEF Conference on Multilingual and Multimodal Information Access Evaluation, CELCT",
            "year": 2013
        },
        {
            "authors": [
                "F. Rangel",
                "P. Rosso",
                "I. Chugur",
                "M. Potthast",
                "M. Trenkmann",
                "B. Stein",
                "B. Verhoeven",
                "W. Daelemans"
            ],
            "title": "Overview of the 2nd author profiling task at PAN 2014",
            "venue": "in: CLEF 2014 Evaluation Labs and Workshop Working Notes Papers, Sheffield, UK",
            "year": 2014
        },
        {
            "authors": [
                "F. Rangel",
                "P. Rosso",
                "M. Potthast",
                "B. Stein",
                "W. Daelemans"
            ],
            "title": "Overview of the 3rd author profiling task at PAN 2015, in: CLEF",
            "year": 2015
        },
        {
            "authors": [
                "K. Filippova"
            ],
            "title": "User demographics and language in an implicit social network",
            "venue": "in: Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,",
            "year": 2012
        },
        {
            "authors": [
                "A. Rashid",
                "A. Baron",
                "P. Rayson",
                "C. May-Chahal",
                "P. Greenwood",
                "J. Walkerdine"
            ],
            "title": "Who am I? Analyzing digital personas in cybercrime investigations",
            "venue": "Computer 46 ",
            "year": 2013
        },
        {
            "authors": [
                "C. Peersman"
            ],
            "title": "Detecting deceptive behaviour in the wild: text mining for online child protection in the presence of noisy and adversarial social media communications",
            "venue": "Ph.D. thesis, Lancaster University",
            "year": 2018
        },
        {
            "authors": [
                "M. Koppel",
                "J. Schler",
                "E. Bonchek-Dokow"
            ],
            "title": "Measuring differentiability: Unmasking pseudonymous authors",
            "venue": "Journal of Machine Learning Research 8 ",
            "year": 2007
        },
        {
            "authors": [
                "M. Kestemont",
                "K. Luyckx",
                "W. Daelemans",
                "T. Crombez"
            ],
            "title": "Cross-genre authorship verification using unmasking",
            "venue": "English Studies 93 ",
            "year": 2012
        },
        {
            "authors": [
                "S. Afroz",
                "M. Brennan",
                "R. Greenstadt"
            ],
            "title": "Detecting hoaxes, frauds, and deception in writing style online",
            "venue": "in: Security and Privacy (SP),",
            "year": 2012
        },
        {
            "authors": [
                "P. Juola",
                "D. Vescovi"
            ],
            "title": "Analyzing stylometric approaches to author obfuscation",
            "venue": "Advances in Digital Forensics VII ",
            "year": 2011
        },
        {
            "authors": [
                "D. Crystal"
            ],
            "title": "Language and the Internet",
            "venue": "Cambridge, CUP ",
            "year": 2001
        },
        {
            "authors": [
                "S. Tagliamonte"
            ],
            "title": "Variationist sociolinguistics: Change",
            "venue": "observation, interpretation, volume 40, John Wiley & Sons",
            "year": 2012
        },
        {
            "authors": [
                "W.A. Wolfram"
            ],
            "title": "A Sociolinguistic Description of Detroit Negro Speech",
            "venue": "Urban Language Series, No. 5., ERIC",
            "year": 1969
        },
        {
            "authors": [
                "W. Labov"
            ],
            "title": "Sociolinguistic patterns",
            "venue": "4, University of Pennsylvania Press",
            "year": 1972
        },
        {
            "authors": [
                "P. Trudgill"
            ],
            "title": "On dialect: Social and geographical perspectives",
            "venue": "Wiley- Blackwell",
            "year": 1983
        },
        {
            "authors": [
                "J. Milroy",
                "L. Milroy",
                "S. Hartley",
                "D. Walshaw"
            ],
            "title": "Glottal stops and tyneside glottalization: Competing patterns of variation and change in British English",
            "venue": "Language Variation and Change 6 ",
            "year": 1994
        },
        {
            "authors": [
                "J. Cheshire"
            ],
            "title": "Sex and gender in variationist research",
            "venue": "The handbook of language variation and change ",
            "year": 2002
        },
        {
            "authors": [
                "W. Labov"
            ],
            "title": "The intersection of sex and social class in the course of linguistic change",
            "venue": "Language variation and change 2 ",
            "year": 1990
        },
        {
            "authors": [
                "W. Labov"
            ],
            "title": "Principles of linguistic change Volume 1: Internal Factors",
            "venue": "Blackwell",
            "year": 1994
        },
        {
            "authors": [
                "W. Labov"
            ],
            "title": "Principles of linguistic change Volume 2: Social Factors",
            "venue": "Blackwell",
            "year": 2001
        },
        {
            "authors": [
                "W. Downes"
            ],
            "title": "Language and society",
            "venue": "Cambridge University Press",
            "year": 1998
        },
        {
            "authors": [
                "R. Wardhaugh"
            ],
            "title": "An introduction to sociolinguistics",
            "venue": "John Wiley & Sons",
            "year": 2010
        },
        {
            "authors": [
                "J. Holmes"
            ],
            "title": "An introduction to sociolinguistics",
            "venue": "Routledge",
            "year": 2013
        },
        {
            "authors": [
                "J.K. Chambers",
                "N. Schilling"
            ],
            "title": "The handbook of language variation and change",
            "venue": "volume 129, John Wiley & Sons",
            "year": 2013
        },
        {
            "authors": [
                "B. Heap",
                "M. Bain",
                "W. Wobcke",
                "A. Krzywicki",
                "S. Schmeidl"
            ],
            "title": "Word vector enrichment of low frequency words in the bag-of-words model for short text multi-class classification problems",
            "venue": "arXiv preprint arXiv:1709.05778 ",
            "year": 2017
        },
        {
            "authors": [
                "S. Nunn"
            ],
            "title": "wanna still nine hard?\u2019: Exploring mechanisms of police bias in the translation and interpretation of wiretap conversations",
            "venue": "Surveillance & Society 8 ",
            "year": 2010
        },
        {
            "authors": [
                "G. Branwen",
                "N. Christin",
                "D. D\u00e9cary-H\u00e9tu",
                "R.M. Andersen"
            ],
            "title": "StExo",
            "venue": "E. Presidente, Anonymous, D. Lau, Sohhlz, D. Kratunov, V. Cakic, V. Buskirk, Whom, M. McKenna, S. Goode, Dark net market archives, 2011-2015, https://www.gwern.net/DNM-archives",
            "year": 2015
        },
        {
            "authors": [
                "M. Fatima",
                "S. Anwar",
                "A. Naveed",
                "W. Arshad",
                "R.M.A. Nawab",
                "M. Iqbal",
                "A. Masood"
            ],
            "title": "Multilingual sms-based author profiling: Data and methods",
            "venue": "Natural Language Engineering 24 ",
            "year": 2018
        },
        {
            "authors": [
                "C.C. Aggarwal",
                "C. Zhai"
            ],
            "title": "A survey of text clustering algorithms",
            "venue": "in: Mining text data, Springer",
            "year": 2012
        },
        {
            "authors": [
                "A.K. Jain"
            ],
            "title": "Data clustering: 50 years beyond k-means",
            "venue": "Pattern recognition letters 31 ",
            "year": 2010
        },
        {
            "authors": [
                "D.M. Blei",
                "A.Y. Ng",
                "M.I. Jordan"
            ],
            "title": "Latent dirichlet allocation",
            "venue": "Journal of machine Learning research 3 ",
            "year": 2003
        },
        {
            "authors": [
                "T. Mikolov",
                "K. Chen",
                "G. Corrado",
                "J. Dean"
            ],
            "title": "Efficient estimation of word representations in vector space",
            "venue": "arXiv preprint arXiv:1301.3781 ",
            "year": 2013
        },
        {
            "authors": [
                "J.H. Ward Jr"
            ],
            "title": "Hierarchical grouping to optimize an objective function",
            "venue": "Journal of the American statistical association 58 ",
            "year": 1963
        },
        {
            "authors": [
                "F. Pedregosa",
                "G. Varoquaux",
                "A. Gramfort",
                "V. Michel",
                "B. Thirion",
                "O. Grisel",
                "M. Blondel",
                "P. Prettenhofer",
                "R. Weiss"
            ],
            "title": "V",
            "venue": "Dubourg, et al., Scikit-learn: Machine learning in python journal of machine learning research ",
            "year": 2011
        },
        {
            "authors": [
                "D.E. Rumelhart",
                "G.E. Hinton",
                "R.J. Williams"
            ],
            "title": "Learning internal representations by error propagation",
            "venue": "Technical Report, California Univ San Diego La Jolla Inst for Cognitive Science",
            "year": 1985
        },
        {
            "authors": [
                "P. Elzinga"
            ],
            "title": "Formalizing the concepts of crimes and criminals",
            "venue": "Ph.D. thesis, University of Amsterdam",
            "year": 2011
        },
        {
            "authors": [
                "M. Motoyama",
                "D. McCoy",
                "K. Levchenko",
                "S. Savage",
                "G.M. Voelker"
            ],
            "title": "An analysis of underground forums",
            "venue": "in: Proceedings of the 2011 ACM SIG- COMM Internet Measurement Conference,",
            "year": 2011
        },
        {
            "authors": [
                "T.J. Holt"
            ],
            "title": "Examining the forces shaping cybercrime markets online",
            "venue": "Social Science Computer Review 31 ",
            "year": 2013
        },
        {
            "authors": [
                "D. D\u00e9cary-H\u00e9tu",
                "B. Dupont"
            ],
            "title": "Reputation in a dark network of online criminals",
            "venue": "Global Crime 14 ",
            "year": 2013
        }
    ],
    "sections": [
        {
            "text": "A Survey of Relevant Text Mining Technology\nClaudia Peersman Matthew Edwards Emma Williams Awais Rashid\nNovember 30, 2022\nar X\niv :2\n21 1.\n15 78\n4v 1\n[ cs\n.C R\n] 2\n8 N\nov 2\n02 2\nA Survey of Relevant Text Mining Technology"
        },
        {
            "heading": "1 Introduction",
            "text": "In recent years, Darknets and other environments offering anonymity are becoming increasingly popular among cybercriminals with a high degree of computer literacy and forensic awareness. Additionally, the emergence of online cybercriminal communities are enhancing the \u201cnormalisation\u201d of cybercrime, providing offenders with technical and security support [1]. Although none of the existing anonymisation techniques (e.g., the ToR service (there are many legitimate and ethical uses of anonimisation techniques such as ToR, which we do not debate here (see [2, 3, 4]) is entirely bulletproof, they can easily complicate or even block current cybercrime investigations. In such cases, the communications produced on social media platforms (both regular and cybercriminal fora) can be one of few clues to an offender\u2019s identity [5]. Additionally, investigating such social interactions can contribute to a better understanding of the dynamics leading to initial engagement in cybercrime, continued careers and (potentially) retirement.\nRecent advances in text mining and natural language processing technology have enabled researchers to detect an author\u2019s identity or demographic characteristics, such as age and gender, in several text genres by automatically analysing the variation of linguistic characteristics. However, applying such techniques \u201cin the wild\u201d [6], i.e., in both cybercriminal and regular online social media, differs from more general applications in that its defining characteristics are both domain and process dependent. This gives rise to a number of challenges of which contemporary research has only scratched the surface. More specifically, a text mining approach applied on social media communications typically has no control over the dataset size \u2013 the number of available communications will vary across users. Hence, the system has to be robust towards limited data availability. Additionally, the quality of the data cannot be guaranteed. As a result, the approach needs to be tolerant to a certain degree of linguistic noise (for example, abbreviations, non-standard language use, spelling variations and errors). Finally, in the context of cybercriminal fora, it has to be robust towards deceptive or adversarial behaviour, i.e. offenders who attempt to hide their criminal intentions (obfuscation) or who assume a false digital persona (imitation) [7], potentially using coded language.\nIn this work we present a comprehensive survey that discusses the problems that have already been addressed in current literature and review potential solutions. Additionally, we highlight which areas need to be given more attention. In the next section, we briefly introduce the fields of text mining and computational stylometry. Section 3 provides an overview of related work in these fields. In section 4, we discuss outstanding challenges and present the project\u2019s research agenda. Finally, we conclude this survey in Section 5.\nA Survey of Relevant Text Mining Technology"
        },
        {
            "heading": "2 Background",
            "text": ""
        },
        {
            "heading": "Text Mining",
            "text": "With the increasing availability of large amounts of computer-mediated communications, text mining has become a popular area of research for automatically detecting patterns and trends in a \u201cBig Data\u201d set-up. Typically designed within a Natural Language Processing (NLP) framework as a level of information extraction from text, the main objective of a text mining approach is to build an intelligent tool, that has the capability of analysing large amounts of natural language texts (e.g., newspaper articles, books or emails) and extracting useful information in a timely manner. Hence, it is a step forward from the information retrieval task, in which the best matches in a database are calculated based on a user query, to a level of exploring the various types of high quality knowledge that can be extracted from text. Although this is a relatively new research area, the technology is already being used in a wide variety of applications, such as biomedical applications (e.g., GoPubMed1, a knowledge-based search engine for biomedical texts), business and marketing applications (e.g., stock return prediction [8]), security applications (e.g., automatic monitoring of Internet news, blogs and social media [9]) and academic applications (e.g., academic publishers making their papers available for text mining purposes).\nA text mining approach typically involves the following six steps:\n1. A dataset of text documents relevant to the task at hand is collected.\n2. Each document is pre-processed. More specifically, the data is converted to the desired format, is split up into individual words and punctuation marks (i.e., tokenised) and processed for removing content undesirable for the task in question (e.g., hyperlinks, non-standard word forms, redundancies and stop words).\n3. The documents are transformed from the full text version to a vector space model that represents the different sets of linguistic features present in each document (e.g., words, characters, Parts-of-Speech and semantic roles).\n4. Statistical techniques are applied to determine which features are most informative for the task at hand. Usually, non-discriminative features are discarded by the system to reduce the dimensionality of the dataset.\n1http://www.gopubmed.com/web/gopubmed/\nA Survey of Relevant Text Mining Technology\n5. The resulting structured database is analysed using either automatic classification or clustering techniques that are also used in data mining. In most cases, analysis happens using machine learning or statistical algorithms.\n6. The output of the previous step is evaluated and can be stored or used in a series of following text mining experiments.\nFigure 1 shows a standard text mining process flow. The next section introduces the emerging research field of computational stylometry, in which the relation between natural language and its users is typically studied by adopting such a text mining framework."
        },
        {
            "heading": "Computational Stylometry",
            "text": "Language is a social phenomenon and language variation is, as a consequence, innate to its social nature. By selecting between a range of potential variations of language use, people construct a social identity, which can be employed to achieve certain social goals. In other words, language users can make use of specific language varieties to represent themselves in a certain way. This freedom of choice, which is shaped by a series of both consciously and unconsciously made linguistic decisions, is often referred to as speaker agency. Such variation can be manifested at various levels of language use, for example, the choice between different words, phonological variants or grammatical alternatives, and is typically influenced by a speaker\u2019s (intended) audience, demographic variables\nA Survey of Relevant Text Mining Technology\n(such as age group, gender or background) and objectives (e.g., knowledge transfer, persuasion or likeability). Stylometry studies are mainly based on the hypothesis that the combination of these (un)conscious linguistic decisions is unique for each individual \u2014 like a fingerprint or a DNA profile [10, 11] \u2014 and that language users (i.e., both speakers and authors) can be identified by analysing the specific properties of their linguistic choices. The idea of such a human stylome [10] can be dated as far back as the mediaeval scholastics.\nIn modern times, the approach of analysing a text on different linguistic levels to determine its authorship was adopted within research fields such as stylistics and literary criticism, one of the most prominent examples being the investigations into the literary works attributed to Shakespeare [12]. This type of research is commonly referred to as traditional authorship attribution and typically involves in-depth reading by human experts. However, in the late 19th century, a new line of research demonstrated that an author\u2019s writing style could be quantified. A study by [13], for example, showed that the authorship of the Federalist Papers could be settled by comparing the distribution of stop words (or function words) in the disputed texts to other texts written by the three candidate authors2.\nThe arrival of modern computational methods and the emergence of the Internet have instigated a new research area, combining insights from the fields of stylometry to techniques commonly used in computer science. Based on the assumption that authors can be distinguished by their stylome, non-traditional authorship attribution typically focuses on developing a computational model that can automatically identify the author of a given text. The dominant approach in these studies is typically based on text mining methods, which are used to automatically attribute one or more predefined thematic categories \u2014 such as authors\u2014 to a set of natural language texts (e.g., books, papers or emails)3. Recently, a significant part of the field has shifted focus from attributing texts to specific authors to investigating whether certain aspects in an author\u2019s writing style can be generalised for larger author groups belonging to, for example, the same age or gender group or showing similar personality traits (e.g., outgoing or withdrawn). Together with non-traditional authorship attribution, such author profiling studies constitute the rapidly developing field of computational stylometry.\n2Alexander Hamilton, James Madison and John Jay. 3The history and background of authorship attribution studies can be found in [14].\nA Survey of Relevant Text Mining Technology"
        },
        {
            "heading": "3 Related Work",
            "text": ""
        },
        {
            "heading": "Automatic User Profiling",
            "text": "A large body of work already exists on detecting a user\u2019s age and gender based on computer-mediated communications. At first, most studies that involved a computational stylometry approach to automatically predict users\u2019 demographics were based on large collections of blogs (e.g., [15, 16, 17, 18, 19, 20, 21, 22]. The main advantage of using blog corpora is that blog sites are publicly available and they usually contain information about the blogger\u2019s profile. In one such study, Schler et al. [23] applied a text mining approach to predict gender in a corpus of over 71,000 English blogs. Based on stylistic features (non-dictionary words, parts-of-speech, function words and hyper-links) and content features (content words4 with the highest Information Gain), they found that, despite the strong stereotypical differences in content between male and female bloggers, stylistic differences proved to be more discriminative than content differences [23]. However, combining both feature types, they were able to obtain an accuracy of 80.1% when distinguishing between male and female bloggers.\nWith regard to age (group) identification, content words showed to be slightly more useful than the style-based features, but again combining them rendered the best results [23]: 10s (13\u201317) were distinguishable from 30s (33\u2013 42) with accuracy above 96% and differentiating between 10s and 20s (23\u201327) was achieved with an accuracy of 87.3%. However, many 30s were wrongly classified as 20s, which rendered an overall accuracy of 76.2%. This resulted in an F-score of 0.86 for the 10s, 0.75 for the 20s and 0.52 for the 30s category5. Yan and Yan [22] were the first to include \u201cnon-traditional\u201d features in their experiments, such as background colour, word fonts and cases, punctuation marks and emoticons. When combining these non-traditional features with bag-of-word features, their system achieved an F-score of 0.68 based on a corpus of 75,000 English blog entries authored by 3,000 individual bloggers. Interesting to see was that removing stop words actually decreased the performance of their system to 0.64, which is consistent with previous sociolinguistic studies that attested gender differences in the use of highly frequent word classes such as pronouns, articles and prepositions (e.g., [24, 25, 26, 27, 28, 29]). Similar results were found for age: based on the same corpus as was described in [23], Koppel et al. [30] showed that language usage in blogs correlates with age:\n4Content words carry the primary communicative message of an utterance (e.g., nouns, adjectives, verbs and adverbs).\n5These scores were calculated based on the confusion matrix in the paper.\nA Survey of Relevant Text Mining Technology\npronouns and the use of both assent and negation become scarcer with age, while prepositions and determiners become more frequent. Their system yielded an accuracy of 76.1% for the three-way classification problem of attributing blogs to one of three age groups: 13\u201317, 23\u201327 or 33\u201347 (majority baseline = 42.7%) by combining style- and content-based features and 80.5% for predicting gender. Goswami et al. [18] further expanded the research of [23] by adding non-dictionary words and the average sentence length as features. Furthermore, the stylistic difference in usage of non-dictionary words combined with content words allowed to predict the age group (10s, 20s, 30s or higher) with an accuracy of 80.3% and gender with an accuracy of 89.2%. The average sentence length, however, did not correlate significantly with age or gender. Additionally, [31] found that female authors were more likely to use emoticons, ellipses, character flooding, repeated exclamation marks, puzzled punctuation (i.e., combinations of \u201c?\u201d and \u201c!\u201d), the abbreviation \u201comg\u201d (oh my god), and transcriptions of back-channels like \u201cah\u201d, \u201chmm\u201d, \u201cugh\u201d, and \u201cgrr\u201d. Affirmations like \u201cyeah\u201d and \u201cyea\u201d were the only preferences that were attributed to males. These latter features are called \u2014 not quite accurately \u2014 \u201csociolinguistic features\u201d in e.g., [31]. Finally, a number of other, non-textual features have been suggested for age and gender prediction, such as the number of friends and followers [31, 32] and posted images [22].\nMore recently, a number of studies were based on a corpus of Twitter (e.g., [33, 34, 35, 36, 32, 31]) and other social network data (see e.g., the author profiling tasks at PAN 2013, 2014 and 2015 [37, 38, 39]). Although the amount of available data on Twitter is expanding massively, profile data is often absent, which requires additional techniques to acquire such meta-data. Contrary to blogs, tweets are typically very short, containing a maximum of 140 characters. However, most studies tend to combine multiple messages per user and show very similar results to previous studies on weblog data. The best results for gender prediction were achieved by Bamman et al. [36], whose system achieved an accuracy score of 88.0% based on over 600 tweets per user. When predicting age on a corpus of 200 Dutch tweets per user, [33] were able to reach a 0.76 F-score when distinguishing between users younger than 20, between 20 and 40 years old and older than 40. Binary age prediction (adults versus adolescents), as examined in this chapter, was first performed by Filippova [40], who investigated the performance of shallow textual features (e.g., character counts), language models and non-textual information (e.g., number of friends) when identifying bloggers under and over 18. However, their classifiers only yielded slightly better results than their majority baseline. Finally, Rashid et al. [41] presented a set of tools for predicting age and gender in a forensic context. By including POS, semantic and BOW features in a hierarchic classification system, their hierarchical, binary age prediction model yields probabilities that a user belongs to a\nA Survey of Relevant Text Mining Technology\nspecific age band (11\u201318 or over 18, followed by a breakdown of the probabilities for 11\u201314; 15\u201318; 19\u201349; 50+; etc.), resulting in a 72.15% recall and 72.24% precision for distinguishing between children and adults.\nAside from investigating which feature types are most effective for predicting profile information, Zhang and Zhang [17] contributed to the field by comparing different data representation methods, feature selection methods and machine learning algorithms for gender prediction in 3,226 blogs (52% female), which contained about 400 words on average. They also included 20 semantic labels (e.g., \u201cconversation\u201d, \u201cfamily\u201d) as features in their instances, which were based on lists of words appearing in a similar context (e.g., \u201ctell\u201d, \u201ctalk\u201d, \u201cask\u201d belonged to the \u201cconversation\u201d label). Together with these word factor analysis features, they included word unigrams, POS tags and average word and sentence length in their experiments, but did not compare the results of these feature types individually. Their best prediction accuracy of 72.1% was achieved by using Information Gain as feature selection criterion, and Support Vector Machines (linear kernel) as machine learning algorithm. Based on a corpus of 3,100 English blogs with an average post length of 250 words for men and 330 words for women, [16] investigated which feature selection methods were most suitable for their type of data. Their ensemble feature selection method (EFS) improved the accuracy scores on gender attribution significantly compared to single selection metrics, such as Information Gain and Chi Square, by about 6-10%, resulting in a best accuracy score of 88.6%. Although this EFS method showed promising results, its application in age and/or gender attribution remains limited to [16]. The reason for this could be that building a new classifier for each subset remains very time-consuming when working with a large number of features.\nContrary to research on age and gender prediction, studies on automatically detecting a user\u2019s region of origin in social media communications are far less prominent in the field. Rao et al. [31] experimented with token n-grams and the same set of sociolinguistic features that was mentioned above and were able to distinguish between English-writing Twitter users located in either Northern or Southern India with an accuracy score of 77.1%.\nAlthough some of the previously mentioned studies show promising results for user profiling in social media communications, all of these works included text fragments ranging from 250 to several thousands of words on average per user. However, when looking at recent studies by [42, 43], these results are subject to scalability issues when the models are applied on shorter text fragments: Burger et al. [43] reported a significant decrease in the performance to 66.5% when predicting gender using only a single tweet per user. Additionally, the work of [42] specifically investigated the effect of different aspects of experimental\nA Survey of Relevant Text Mining Technology\ndesign, such as feature types, feature selection, document representation and machine learning algorithms, when performing user profiling based on only one social media posting per user in the context of designing online child protection technology. The developed techniques will be evaluated for their efficiency when analysing cyber offenders\u2019 online messages in the project."
        },
        {
            "heading": "Adversarial Stylometry",
            "text": "Stylometry is based on the assumption that every individual has a unique writing style and, as a result, an author can be distinguished from other authors by measuring specific properties of his or her writings. However, most stylometric research is also based on the assumption that authors do not attempt to disguise their linguistic writing style. The author of [14] discusses the importance of determining the robustness of an authorship attribution system when it is confronted with deception. However, so far, research into this issue has been limited. Kacmarcik and Gamon [44] were the first to explore the possibility to computationally obfuscate the (most likely) author of the disputed Federalist Papers (see e.g., [45]). They attempted to hide the author\u2019s identity by neutralising 14 of the most informative words per thousand words in the texts. Yet, the obfuscation was successfully detected by a technique called unmasking, which was proposed by [46]: using a series of SVM classifiers to iteratively remove the features that received the highest weight from the SVM\u2019s during training, they found that, when comparing two texts that were written by two different authors, the accuracy score slowly declined during the iterations. However, when comparing two texts that were written by the same author of which one was computationally modified, as in [44], they attested a steep drop of the accuracy. This drop is explained by the fact that when comparing between texts that are written by the same author, the number of highly discriminative features is limited. Hence, when building a degradation curve, iteratively removing these features typically results in sudden drops in accuracy. However, when comparing texts that are written by different authors, the number of discriminative features is larger, resulting in a more steadily declining accuracy when iteratively removing subsets of these features (see also [47]).\nContrary to these studies, however, initial work by Brennan and Greenstadt [7] showed that including obfuscation passages written by humans resulted in a devastating effect on the robustness of most state-of-the-art authorship attribution methods. Moreover, in an extended study on the English BrennanGreenstadt corpus, which included original writings, obfuscated, and imitation passages of 45 different authors, the work of [48] stated that including obfusca-\nA Survey of Relevant Text Mining Technology\ntion passages resulted in a decrease of the precision for authorship attribution from over 80% to less than 10% when training on data from forty different authors. With regard to detecting imitations of literary writings (or pastiches), Dinu and Nisioi [49] reported that using frequency rankings of stop words as features showed promising results when trying to distinguish between the Romanian novelist Caragiale\u2019s writings and authors that had attempted to imitate his writing style after his death. However, research by [48] reported a precision of less than 5% when including imitation passages from the English BrennanGreenstadt corpus.\nAlthough the work of [50, 51] confirmed the fact that identifying the author of such deceptively written texts is extremely difficult, both Afroz et al. [48] and Juola [52] found that the authors\u2019 intent to deceive or hide their identity is detectable. On the one hand, Afroz et al. [48] reported that, in imitated passages, the usage of personal pronouns and particles increased, while the usage of adjectives decreased. They also noticed an increased use of existential \u201cthere\u201d, adverbs, particles and personal pronouns in obfuscated passages, but a decrease in the usage of nouns and wh-pronouns. Finally, they noticed that authors tend to \u201cdumb down\u201d their writing style by using shorter sentences, simpler words with less syllables, lower readability scores and higher readability ease and that changing function words seemed to be an important way to obfuscate a text. On the other hand, using the Java Graphical Authorship Attribution Program (JGAAP) software package, [52] was able to identify five of six \u201cdeceptive\u201d documents (83%) and 22 out of 28 \u201chonest\u201d writings (79%) in the Brennan-Greenstadt corpus. He concluded that the attempts of people to write \u201cdifferently\u201d could be fit into a recognisable and distinctive stylistic pattern.\nYet, the research described above still shows a number of limitations in the context of analysing cybercriminal social media communications: (a) some of the mentioned studies were performed on computationally modified data instead of on deceptive texts written by (untrained) human beings; (b) all studies were performed on a minimum of 500 words per author; and (c) they only included formal text genres.\nA Survey of Relevant Text Mining Technology"
        },
        {
            "heading": "4 Towards Automatic User Profiling in",
            "text": "Cybercriminal Communities"
        },
        {
            "heading": "Challenges",
            "text": "Three aspects are essential for designing a real-life computational stylometry application that can be used to support digital forensic investigations pertaining to cybercrime, namely: (i) dealing with linguistically noisy texts, (ii) sparse, skewed \u201cbig data\u201d analysis and (iii) detecting adversarial text samples.\nNoisy data. The increased level of immediacy in computer-mediated communication (CMC) has led to the rise of a new glocal language variety, displaying characteristics from a global Internet language leading to a wild proliferation of new language varieties (e.g., Internet abbreviations, acronyms, character flooding, concatenations and emoticons) [53, 54]. The presence of such linguistic noise is said to provide a significant challenge for text mining research, because many off-the-shelf NLP tools fail to correctly analyse this anomalous input. Previous work on age and gender detection in CMC discards all non-standard language varieties (e.g., [23, 22, 21]) or normalises them to improve feature extraction procedures (e.g., [55]). However, previous work in spoken discourse studies has observed strong correlations between the use of non-standard language and sociological variables such as age and gender (e.g., [56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68]). Additionally, linguistic noise can also be used as an adversarial tactic by cybercriminals to avoid detection [42].\nSparse, skewed Big Data. Most documents only contain a small percentage of the total number of features present in the dataset. Because of their limited length, they provide great challenges for standard text mining approaches that rely on word frequencies, word co-occurrences or shared context to determine the similarity between documents. Additionally, in many cases the focus lies on detecting the minority class and, hence, the number of useful instances is limited. Standard practice in a wider text mining context is to increase the data in each sample by, e.g., grouping multiple text fragments written by the same author ([23, 17, 33]) or by incorporating additional word level concept information obtained from external sources, such as pre-trained word embeddings, WordNet, concept annotations or snippets produced by public search engines (e.g., [69, 70, 71]). However, for a real-life application, it is essential that a cyber offender profiling and detection approach is able to achieve a reliable performance, even when confronted with limited data availability. Furthermore, in\nA Survey of Relevant Text Mining Technology\na digital forensics context, it would be inconceivable to combine evidence with external content that was not produced by the person under investigation.\nAdversaries. Contemporary computational stylometry research typically focuses on two aspects: identifying and extracting linguistic features that are potentially discriminative for an author\u2019s writing print (or stylome [10]) and developing an efficient computational model that includes these features to automatically determine an author\u2019s identity or demographics. Although a range of feature types and computational methods have been suggested for the task, the field is dominated by studies that evaluate their computational stylometry approaches on non-deceptive datasets. However, a key issue when designing a computational stylometry approach to be used in cybercrime investigations is whether it will remain useful when it is confronted with adversarial behaviour. Cyber criminals may try to hide behind multiple digital personas or a group of offenders can share a single online identity. Additionally, they might attempt to hide their true identity or imitate other (non-criminal) users and use specialised vocabulary or coded language to conceal the nature of their activities 6."
        },
        {
            "heading": "Research Agenda",
            "text": "In this section, we discuss the advances needed to study cybercriminal careers at scale. We focus on two key dimensions: (1) datasets that provide an empiricallygrounded basis for uncovering identifying characteristics of cyber offenders; (2) technological advances for designing a text mining approach to automatically detect cybercriminal demographics and assessing such approaches for their robustness when applied in the wild and in adversarial settings of cybercriminal fora."
        },
        {
            "heading": "Datasets",
            "text": "To support any text mining methodology, large and diverse datasets (Big Data) are required in order to study cybercriminal careers at scale. To our knowledge, the only significant longitudinal coverage of many cybercriminal communities is the dataset collected by [73]. This dataset consists of longitudinal observations of some 89 darknet marketplaces (crypto-markets using Bitcoin and other cryptocurrencies in escrow systems accessible as hidden services within the Tor network) and 37 forums over a period covering roughly 2013 to 2015, dependent\n6For example, illegal drug traffickers have been reported to use a widely varied terminology for selling their products [72].\nA Survey of Relevant Text Mining Technology\non the marketplace accessibility. This large dataset, over 1.5TB of web pages and associated resources, contains within it a wealth of business and social interactions between criminals, covering several adverse events which had impact on the community, along with market listings, reputation indicators and other activity information and identity markers which are valuable for understanding the characteristics of offenders and their motivations. However, there are a number of limitations to this dataset, largely related to the incompleteness or partial inconsistency of particular crawling results. For example, pages may be missing from a given snapshot of a market on a particular date, due to scraper errors or connectivity issues with the market itself. These limitations can be partially addressed through the redundancy inherent in the longitudinal nature of the scraping process, inferring the approximate extent of missing data for a given site snapshot from prior and future observations of the same site, and translating this into imputed adjustments of the impact assessment measures. Other limitations include the comparatively smaller populations using darknet marketplaces for cyber-dependent crime as opposed to, e.g., illegal drug trade. There are, of course, other issues with the trustworthiness of observations from within the scrapes (e.g., vendors using shills, counterintelligence efforts, scams) and hold implications for any analysis. Finally, no (gold standard) information is available about the demographics of the users who are represented in the dataset.\nFor the purposes of the approach presented in the project, a new dataset with a broad coverage, which is being established by building a list of target criminal communities and collecting both archive and current data covering online communications between cyber criminals and adjacent participants, over as broad a period as possible in each case. Web-crawling technology is being deployed to unobtrusively collect online forum history, while conventional textlogging systems are used to monitor chat channels over a defined interval. This data will provide up-to-date information on the online language use of different types of cyber offenders, fuelling both the project\u2019s qualitative research objectives and text mining analyses and tool development. However, while this approach to corpus development would generate material suitable for unsupervised learning approaches (see below), it does not provide \u201cground truth\u201d for the testing of user profiling models developed by the research team.\nTherefore, performance is being (partially) established through first establishing a baseline in similar non-criminal data for which ground-truth demographics are available:\n\u2022 The SMS-AP-18 corpus. This corpus was used for the first shared task on Multilingual Author Profiling on SMS (English/Urdu) [74]. It consists of 810 user profiles together with their age metadata (15\u201319, 20\u201324, 25\u2013xx)\nA Survey of Relevant Text Mining Technology\nand gender.\n\u2022 The PAN corpus (2012 \u2013 2017). This dataset contains different corpora collected from the author profiling tasks at PAN 2013, 2014 and 2015 [37, 38, 39] and covers three online media genres (blogs, Twitter feeds and unspecified social media postings). All corpora used contain metadata about gender and age group (13\u201317, 23\u201327 and 33\u201347).\nThis will be followed by transfer learning and evaluation on smaller validated datasets established from criminal prosecutions or doxxing events, in which (anonymous) users are linked to their actual offline identity, drawn from criminal platforms themselves. We expect that such datasets will be too limited for training our systems, but will be valuable for evaluating the robustness of our approach when applied in the wild."
        },
        {
            "heading": "Technological Advances",
            "text": "Computational Stylometry. Our approach to this computational stylometry task is based on text categorisation, and involves the creation of document representations based on a selected set of (patterns) of linguistic features, feature selection using statistical techniques, and classification using machine learning algorithms (see Section 2). Contrary to previous research that mainly focused on predicting authors\u2019 demographics based on large, formal text samples, we will perform a systematic study of different aspects of methodological design incorporated in a state-of-the-art user profiling approach to assess its robustness to highly sparse, skewed and noisy text data, i.e., performing user profiling \u201cin the wild\u201d.\nBased on the results of this systematic study, we will investigate different strategies to boost the performance for automatic user profiling using only a single message per user. Because, in the context of a cybercrime investigation, a conjunction of evidence with external content, which was not produced by the suspect7 would be out of the question, the following strategies will be explored:\n1. a systematic study of different aspects of methodological design incorporated in a state-of-the-art user profiling approach to assess its robustness to highly sparse, skewed, noisy and adversarial text data, i.e., performing user profiling in the wild;\n7For example, by including information from Wikipedia, Wordnet or Internet search engines as is typically done in semantic and semi-supervised classification approaches.\nA Survey of Relevant Text Mining Technology\n2. novel feature engineering methods in which different feature types are extracted in parallel and the resulting vectors are concatenated into larger vectors to create complex models; and\n3. a cross-task classification approach in which the meta-data for gender or location is included in the experiments in order to investigate their effect on age prediction and vice versa.\nAdditionally, we aim to investigate whether a message-based approach, in which predictions are made on the level of the individual post and aggregated to the user level in post-processing, enables the system to identify different offender characteristics more accurately than the traditional user-based approach that renders predictions directly on the user level. We will apply both approaches (a) in the context of automatically detecting people trying to imitate the writing style of another demographic group and (b) on the text genre of short, online social media communications. So far, both these applications have remained unexplored in the field.\nFinally, the research project will also include a qualitative analysis of the features that make the user profiling model. Providing such a qualitative analysis of the most discriminative linguistic features enables an evaluation of the scalability of the approach for other researches and allows for methodological reflection towards well established sociolinguistic principles. Moreover, a qualitative analysis is typically absent in most text mining studies, as they tend to focus solely on the performance of their user profiling models.\nTopic Detection. Aside from author profiling techniques, the project will focus on developing advanced unsupervised topic detection modules, which will be required for automatically analysing (underground) forums and marketplaces, allowing for automatically categorising and prioritising potential cyber threats and offences. Contrary to most text mining approaches, in which the training data available is pre-labelled with the required information to perform a categorisation task (i.e., the \u201cground truth\u201d), detecting topic in adversarial communications will require an unsupervised learning approach, because no information on the presence or absence of guarded language will be available when analysing currently existing or newly collected datasets. As a result, methodologies will be investigated that can reveal hidden structures, patterns or features from unlabelled data. Potential machine learning techniques used in unsupervised learning that could contribute to this task include clustering techniques, Neural Networks and Formal Concept Analysis.\nClustering. In the baseline clustering approach, the similarity between different objects is measured by using one or more similarity functions. With re-\nA Survey of Relevant Text Mining Technology\ngard to textual data in which the objects can be of different granularities (e.g., documents, paragraphs, sentences or words), clustering methods have shown promising results for e.g., browsing or organising documents and summarising large text corpora [75]. Standard practice for vector data is to use the K-means algorithm or Latent Dirichlet Allocation (LDA). The first technique divides a set of text samples into k disjoint clusters, each described by the centroid of the text samples in the cluster. The algorithm then attempts to select centroids that minimise the within-cluster sum-of-squares (or inertia) [76]. LDA, from its part, is a Bayesian probabilistic model, which also assumes a collection of k clusters. The latter algorithm could be especially useful when applied to social media communications, because it assumes that each document instance is a mixture of a small number of topics and that each word can be clustered into one of these topics [77]. Recent work on topic modelling over short text samples suggested incorporating word embeddings generated by Word2Vec [78]. More specifically, short texts are aggregated into long pseudo-texts by incorporating the semantic knowledge from the word embeddings to boost the performance of clustering algorithms [79]. A second challenge is that most clustering techniques depend on a predefined (k) number of clusters. Therefore, agglomerative clustering algorithms will be investigated to determine the hierarchy of all topic clusters present in the dataset. More specifically, by using a bottom-up approach, in which each instance initiates its own cluster and clusters are merged together using a linkage criteria (for example, Ward\u2019s algorithm [80] hierarchical clustering can be achieved and represented in a tree structure or dendrogram for further analysis of the number of different topics present in the data.\nNeural Networks. Artificial neural networks can mainly be distinguished from other methods by its inclusion of one or more non-linear (or hidden) layers between the input and the output layer during the analysis. The input layer consists of a set of neurons, which represent the features of each instance. Next, each neuron in the hidden layer transforms the values from the previous layer with a weighted linear summation followed by a non-linear activation function. The output layer then analyses the values from the last hidden layer and produces a decision. In most cases, a supervised learning technique called Backpropagation is used during training, which runs a \u201cforward pass\u201d to compute all the activations throughout the neural network and determine the degree in which each node in each layer contributes to any errors in the output of the system [81, 82]. In recent work by [83], neural topic models have been presented that show similar sparse topic distributions as found with traditional Dirichlet-Multinomial models on larger text samples, such as song lyrics or news articles. The advantage of recurrent neural networks, specifically, with regard to the task at hand is their ability to model sequences of unbounded length and, when combined with variational inference methods, they allow the number of topics to dynamically\nA Survey of Relevant Text Mining Technology\nincrease [83].\nFormal Concept Analysis. FCA provides a well-founded mathematical framework for organising a set of objects based on their shared features without including any knowledge about the objects. In the context of automatic topic modelling in social media communications, the technique can be used to create thematically-based and cohesive clusters. The key advantage of FCA is that no prior knowledge of the data is required for its computation, which enables researchers to overcome typical topic detection problems, such as unknown topic distribution and the appearance of new topics. The technique has already been successfully applied on police data for detecting radicalisation and child sex offender grooming [84]."
        },
        {
            "heading": "5 Conclusions",
            "text": "Online interactions between cybercriminals are a valuable lens into the underlying nature of offenders, which in turn is necessary grounding for any preventative or disruptive intervention. Prior work has demonstrated some of the insight that studies of cybercriminal communities might have to offer [85, 86, 87]. In this review, we described the related work, open challenges and requirements regarding computational assessment of cyber offenders, their identifying characteristics and their behaviours. These challenges and requirements underpin our research on analysing cybercriminal careers at scale. Within our on-going work in the project, we are focusing on developing a novel text mining approach for automatic user profiling and topic detection under the complex conditions of linguistically noisy, highly sparse, adversarial datasets and evaluate their forensic readiness when applied in the wild. Aside from addressing policy-guiding research questions, these new methodologies can be refined according to guidelines and feedback from law enforcement, leading to software tools that can support their investigations into cybercrime."
        }
    ],
    "title": "A Survey of Relevant Text Mining Technology",
    "year": 2022
}