{
    "abstractText": "I modify the canonical statistical discrimination model of Coate and Loury (1993) by assuming the firm\u2019s belief about an individual\u2019s unobserved class is machine learning-generated and, therefore, contractible. This expands the toolkit of a regulator beyond belief-free regulations like affirmative action. Contractible beliefs make it feasible to require the firm to select a decision policy that equalizes true positive rates across groups \u2013 what the algorithmic fairness literature calls equal opportunity. While affirmative action does not necessarily end statistical discrimination, I show that imposing equal opportunity does. JEL Codes: C53, D86, J71, L51",
    "authors": [
        {
            "affiliations": [],
            "name": "JOHN Y. ZHU"
        }
    ],
    "id": "SP:b257e7327e7220f205b3706352dc9b6ca3a6a3ad",
    "references": [
        {
            "authors": [
                "Blattner",
                "Laura",
                "Scott Nelson",
                "Jann Spiess"
            ],
            "title": "Unpacking the black box: Regulating algorithmic decisions,",
            "venue": "arXiv preprint arXiv:2110.03443",
            "year": 2021
        },
        {
            "authors": [
                "Chiappa",
                "Silvia"
            ],
            "title": "Path-specific counterfactual fairness,",
            "venue": "Proceedings of the AAAI conference on artificial intelligence,",
            "year": 2019
        },
        {
            "authors": [
                "Chouldechova",
                "Alexandra"
            ],
            "title": "Fair prediction with disparate impact: A study of bias in recidivism prediction instruments,",
            "venue": "Big data,",
            "year": 2017
        },
        {
            "authors": [
                "Coate",
                "Stephen",
                "Glenn C"
            ],
            "title": "Will affirmative-action policies eliminate negative stereotypes?",
            "venue": "Loury",
            "year": 1993
        },
        {
            "authors": [
                "Corbett-Davies",
                "Sam",
                "J Gaebler",
                "Hamed Nilforoshan",
                "Ravi Shroff",
                "Sharad Goel"
            ],
            "title": "The measure and mismeasure of fairness,",
            "venue": "J. Mach. Learn. Res",
            "year": 2023
        },
        {
            "authors": [
                "Corbett-Davies",
                "Sam",
                "Emma Pierson",
                "Avi Feller",
                "Sharad Goel",
                "Aziz Huq"
            ],
            "title": "Algorithmic decision making and the cost of fairness,",
            "venue": "Proceedings of the 23rd acm sigkdd international conference on knowledge discovery and data mining,",
            "year": 2017
        },
        {
            "authors": [
                "Dwork",
                "Cynthia",
                "Moritz Hardt",
                "Toniann Pitassi",
                "Omer Reingold",
                "Richard Zemel"
            ],
            "title": "Fairness through awareness,",
            "venue": "Proceedings of the 3rd innovations in theoretical computer science conference,",
            "year": 2012
        },
        {
            "authors": [
                "Eliaz",
                "Kfir",
                "Ran Spiegler"
            ],
            "title": "The model selection curse,",
            "venue": "American Economic Review: Insights,",
            "year": 2019
        },
        {
            "authors": [
                "Fang",
                "Hanming",
                "Andrea Moro"
            ],
            "title": "Theories of statistical discrimination and affirmative action: A survey,",
            "venue": "Handbook of social economics,",
            "year": 2011
        },
        {
            "authors": [
                "Feldman",
                "Michael",
                "Sorelle A Friedler",
                "John Moeller",
                "Carlos Scheidegger",
                "Suresh Venkatasubramanian"
            ],
            "title": "Certifying and removing disparate impact,",
            "venue": "in proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining,",
            "year": 2015
        },
        {
            "authors": [
                "Frankel",
                "Alex",
                "Navin Kartik"
            ],
            "title": "Improving information from manipulable data,",
            "venue": "Journal of the European Economic Association,",
            "year": 2022
        },
        {
            "authors": [
                "Hardt",
                "Moritz",
                "Eric Price",
                "Nati Srebro"
            ],
            "title": "Equality of opportunity in supervised learning,",
            "venue": "Advances in neural information processing systems,",
            "year": 2016
        },
        {
            "authors": [
                "Heidari",
                "Hoda",
                "Claudio Ferrari",
                "Krishna Gummadi",
                "Andreas Krause"
            ],
            "title": "Fairness behind a veil of ignorance: A welfare analysis for automated decision making,",
            "venue": "Advances in neural information processing systems,",
            "year": 2018
        },
        {
            "authors": [
                "Hu",
                "Lily",
                "Yiling Chen"
            ],
            "title": "A short-term intervention for long-term fairness in the labor market,",
            "venue": "Proceedings of the 2018 World Wide Web Conference,",
            "year": 2018
        },
        {
            "authors": [
                "Kleinberg",
                "Jon",
                "Himabindu Lakkaraju",
                "Jure Leskovec",
                "Jens Ludwig",
                "Sendhil"
            ],
            "title": "Mullainathan (2018a) \u201cHuman decisions and machine predictions,",
            "venue": "The Quarterly Journal of Economics,",
            "year": 2018
        },
        {
            "authors": [
                "Kleinberg",
                "Jon",
                "Jens Ludwig",
                "Sendhil Mullainathan",
                "Cass R"
            ],
            "title": "Sunstein (2018b) \u201cDiscrimination in the Age of Algorithms,",
            "venue": "Journal of Legal Analysis,",
            "year": 2020
        },
        {
            "authors": [
                "Kleinberg",
                "Jon",
                "Sendhil Mullainathan",
                "Manish Raghavan"
            ],
            "title": "Inherent tradeoffs in the fair determination of risk scores,",
            "venue": "arXiv preprint arXiv:1609.05807",
            "year": 2016
        },
        {
            "authors": [
                "Kleinberg",
                "Jon",
                "Manish Raghavan"
            ],
            "title": "How do classifiers induce agents to invest effort strategically?",
            "venue": "ACM Transactions on Economics and Computation (TEAC),",
            "year": 2020
        },
        {
            "authors": [
                "Kusner",
                "Matt J",
                "Joshua Loftus",
                "Chris Russell",
                "Ricardo Silva"
            ],
            "title": "Counterfactual fairness,",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Liu",
                "Lydia T",
                "Sarah Dean",
                "Esther Rolf",
                "Max Simchowitz",
                "Moritz Hardt"
            ],
            "title": "Accuracy Frontier,",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "(1993) by assuming the firm\u2019s belief about an individual\u2019s unobserved class is machine learning-generated and, therefore, contractible. This expands the toolkit of a regulator beyond belief-free regulations like affirmative action. Contractible beliefs make it feasible to require the firm to select a decision policy that equalizes true positive rates across groups \u2013 what the algorithmic fairness literature calls equal opportunity. While affirmative action does not necessarily end statistical discrimination, I show that imposing equal opportunity does.\nJEL Codes: C53, D86, J71, L51 Keywords: statistical discrimination, algorithmic fairness, equal opportunity\n1University of Kansas, johnzhuyiran@ku.edu.\nar X\niv :2\n31 0.\n04 58\n5v 1\n[ ec\non .T\nH ]\n6 O\nct 2"
        },
        {
            "heading": "1 Introduction",
            "text": "In traditional economic models, beliefs exist in the minds of humans and are, therefore, not contractible. In contrast, beliefs generated by machine learning algorithms in the form of predictions are, in principle, contractible. In this paper, I show how belief-contingent regulation can be used to end equilibrium statistical discrimination in the canonical model of Coate and Loury (1993) \u2013 referred to as CL from now on.\nRecall, in that model, applicants belonging to two ex-ante identical groups, i \u2208 {w, b}, individually decide if they want to become qualified at iid cost. There is a firm that does not observe qualification status, but does observe each applicant\u2019s group identity i, and some signals, x, that are informative of qualification status and/or group identity. The observed (i, x) is the features vector of an applicant, and the unobserved qualification status is an applicant\u2019s class y \u2208 {q, u}. Given an (i, x) applicant, the firm forms a belief, f(i, x), about the conditional probability that y = q. The firm then makes a binary accept-reject decision on the applicant. All applicants prefer accept, while the firm prefers accept if and only if y = q.\nDespite being ex-ante identical, the two groups of applicants can end up in a discriminatory equilibrium. Relative to the favored group, the discriminated group faces higher acceptance standards, which leads to fewer applicants from the discriminated group becoming qualified, which in turn rationalizes the higher standards they face.\nCL then impose an affirmative action control on the firm. A control is a regulation that limits the kinds of acceptance policies the firm can use. The affirmative action control requires the firm to accept applicants from different groups at equal rates. In any discriminatory equilibrium, affirmative action brings gains to the discriminated group by inducing the firm to shrink the acceptance rate gap. However, in the long run, these gains need not lead to a non-discriminatory equilibrium, that would allow the control to be harmlessly lifted. Indeed, under affirmative action, there exist steady states where the previously discriminated group is now patronized with lower acceptance standards. Without affirmative action, such a state is not in equilibrium. If the control is lifted, the patronizing lower standards revert to higher standards, and the original discriminatory equilibrium can re-emerge. This begs a natural question:\nIs there an ideal control that brings gains to the discriminated group in any discriminatory equilibrium and whose steady states coincide with the set of non-discriminatory equilibria?\nI show ideal controls exist if the firm\u2019s belief, f , is contractible.\nIn the traditional setting of CL, where one imagines the belief, f , as existing in the mind of a human, it makes sense to assume f is not contractible and focus on belief-free controls like affirmative action. However, when the firm uses a machine learning algorithm to compute f , a control ought to be able to depend on it. This introduces a new world of algorithmic controls that regulate the decisions of the firm based on its beliefs.\nIn particular, consider what the algorithmic fairness literature calls the equal opportunity control: Given a decision policy d, the distribution of features \u00b5, and belief f , the true positive rate of a group i is\u2211 x d(i, x)\u00b5(i, x)f(i, x)\u2211\nx \u00b5(i, x)f(i, x) ,\nwhere d(i, x) is the probability an (i, x) applicant is accepted. The equal opportunity control requires the firm to choose a decision policy that equalizes true positive rates across groups. In contrast, the non-algorithmic affirmative action control requires the firm to choose a decision policy that equalizes acceptance rates,\u2211 x d(i, x)\u00b5(i, x)\u2211\nx \u00b5(i, x) ,\nacross groups.\nIn any discriminatory equilibrium, when either control is imposed, utility maximization drives the firm to lower the acceptance rate of the favored group and to raise the acceptance rate of the discriminated group. This, by definition, brings gains to the discriminated group.\nIn addition, as the firm starts raising the acceptance rate of the discriminated group, its incentive to invest in becoming qualified starts increasing, bringing it closer to that of the favored group. Under the equal opportunity control, the firm\u2019s utility is maximized precisely when incentives are equalized across groups. This ensures that any steady state under equal opportunity is non-discriminatory. In contrast, affirmative action\u2019s requirement to equalize acceptance rates causes the firm to push past the equal incentives point. The acceptance rate of the discriminated group can become so high that the incentive it faces starts declining \u2013 possibly dropping below that of the favored group again. This leads to the existence of discriminatory steady states under affirmative action where one group is patronized relative to the other.\nIn practice, a regulator seeking to end statistical discrimination likely knows much\nless about market conditions than the firm it is regulating. Moreover, political and legal considerations may constrain the regulator to act in a transparent way. The one thing a regulator has going for it is its authority to audit the firm\u2019s machine learning-generated belief. The equal opportunity control is ideally adapted to this situation. Implementing it requires no knowledge of model parameter values \u2013 only the firm\u2019s belief and the distribution of features are needed. Moreover, how this information is used in regulating the firm is easily interpretable. The equal opportunity control demonstrates how, in a world where beliefs are contractible, a regulator can use belief-contingent regulation to end equilibrium statistical discrimination in a robust and transparent way.\nRelated Literature. So far, I have shown how ideas from the field of algorithmic fairness, such as algorithmic audits and equal opportunity, can be used to tackle problems of statistical discrimination. Conversely, my work on statistical discrimination can be viewed as a contribution to the field of algorithmic fairness.\nTo begin, let us first review the basics of algorithmic decision-making, using the language of the statistical discrimination model sketched out in the introduction. There is a vector of random variables, (i, x, y), representing the distribution of observed group identity, observed other features, and unobserved class of a population of individuals. In addition, there is a set of available decisions D. Let \u2206(D) denote the set of all probability distributions on D. The goal is to find a decision policy d : (i, x) \u2192 \u2206(D) that minimizes the expectation of some given loss function, \u2113(y, d(i, x)).\nGiven the distribution, \u00b5, of features, computing Ei,x,y\u2113(y, d(i, x)) requires estimating the conditional distribution of y given (i, x). This is what a supervised machine learning algorithm does. Once the algorithm generates an estimate, f , an expected loss-minimizing d can be selected.\nToday, algorithmic decision-making is ubiquitous. See Agrawal et al. (2018). Kleinberg et al. (2018a) demonstrate how algorithmic decision-making can substantially outperform human decision-making in a high stakes setting. Nevertheless, there is concern that algorithmic decision-making can be unfair, reinforcing pre-existing discriminatory behavior. For example, in a study on household credit markets, Fuster et al. (2022) show how certain minority groups are adversely affected by the introduction of machine learning algorithms for predicting creditworthiness.\nThe field of algorithmic fairness emerged in response to such concerns. It deals\nwith the disparate treatment of or impact to individuals with different group identities under algorithmic decision-making. See Barocas et al. (2019) for a textbook treatment. The literature can be roughly classified into two areas depending on the focus \u2013 removing disparate treatment or removing disparate impact.\nRemoving Disparate Treatment. Papers in this area aim to ensure that decisions do not \u201cfactor in\u201d group identity. The most direct way to achieve that aim is to require that d not depend on group identity. However, such color-blind decisions can still factor in group identity indirectly through proxies. To mitigate proxy effects, Pope and Sydnor (2011) propose averaging out group identity by requiring that d depend on x only up to Eif(i, x). Similarly, Yang and Dobbie (2020) propose fixing a group identity \u2013 say, w \u2013 and requiring that d depend on x only up to f(w, x). Kusner et al. (2017) take as given a directed acyclic graph (DAG) modeling the causal relationships between i, x, and y, and then require that d not depend on any causal descendants of group identity. Dwork et al. (2012) take as given two similarity metrics, one on I\u00d7X and another on D, and then require that similar individuals receive similar decisions.\nRemoving Disparate Impact. Papers in this area aim to ensure that the distributions of decisions experienced by different groups are \u201cfair\u201d in some statistical sense. Removing disparate impact often requires that decision policies factor in group identity. Common notions of fairness include statistical parity, equal opportunity, equal odds, group calibration, positive and negative class balance, predictive parity, and error rate balance. Zemel et al. (2013), Feldman et al. (2015), and Hardt et al. (2016b) introduce ways of regulating algorithmic decision-making to guarantee that the selected decision policy satisfies statistical parity, equal opportunity, or equal odds.\nRecently, there have been calls to bring an economic perspective to the study of algorithmic fairness, as a complement to the purely statistical approaches surveyed above. See, for example, Cowgill and Tucker (2020). Such a reaction is driven in part by some issues of the purely statistical approaches:\n1. Pareto-Inferiority. Corbett-Davies et al. (2023) show that, for a given applica-\ntion, if the loss function, \u2113, already encodes the fairness concerns appropriate for that application, then imposing additional purely statistical fairness constraints like the ones described above can lead to all groups being made worse off. See also Hu and Chen (2020) for a similar finding. Moreover, even if \u2113 represents a\npurely utilitarian social welfare function, imposing common algorithmic fairness regulations can not only reduce welfare but also reduce fairness as measured in an application-appropriate way. Corbett-Davies et al. (2017) show that such welfare losses can be large in real-life applications.\n2. Agency Problems. In most applications, the agent engaged in algorithmic\ndecision-making and the regulator with fairness concerns are different entities. Moreover, the regulator often has limited ability to control the agent\u2019s selection of a decision policy \u2013 either because of information asymmetries or limited regulatory tools. Such agency problems are often ignored.\n3. Endogenous Data. Regulations of algorithmic decision-making meant to en-\nhance fairness are often derived under the assumption that the joint distribution of (i, x, y) is exogenous. Ideally, the design of such regulations should anticipate how a regulation will affect the endogenous relationships between i, x, and y. Liu et al. (2018) introduce a reduced-form model of how the chosen decision policy affects (i, x, y), and show that imposing fairness constraints meant to improve welfare under the current distribution of (i, x, y) can lead to long-term changes in the distribution of (i, x, y) that make the protected group worse off.\n(a) Manipulable Data. A distinct but related issue concerns the fact that, in\npractice, data collected about (i, x, y) may be strategically manipulated by the population of individuals. Thus, the choice of a decision policy should take into account how that policy will affect the way (i, x, y) is manipulated.\n4. Inconsistency. Without an economic model to discipline the choice of how to\nmeasure fairness, the literature on disparate impact has introduced a plethora of model-free statistical fairness conditions. Kleinberg et al. (2016) and Chouldechova (2017) show that many of these fairness conditions are generically impossible to satisfy simultaneously.\n5. Parameter-Dependency. In contrast, some of the methods for removing dis-\nparate treatment depend quite strongly on the regulator having detailed knowledge of an underlying model. To ensure counterfactual fairness and path-specific counterfactual fairness, Kusner et al. (2017) and Chiappa (2019) require the regulator to know the causal DAG governing (i, x, y). Achieving fairness through awareness, as in Dwork et al. (2012), requires the regulator to know what it\nmeans for different individuals and decisions to be similar, which depends on the application.\nNew research in algorithmic fairness has begun to address these issues. Heidari et al. (2018) introduce a benefit function b(y, d(i, x)) meant to capture relevant welfare considerations, and argues for constraining the expected loss-minimization problem by requiring the expected benefit to be above some lower bound. Liang et al. (2023) introduce a limited-tools agency problem where the regulator can only use coarsifications of data to align the incentives of the agent. Blattner et al. (2021) introduce an information asymmetry agency problem where the regulator is unable to perfectly monitor the machine learning-generated f . Rambachan et al. (2020) introduce a regulator with a non-discriminatory social welfare function, while giving some agents taste-based preferences for discrimination, and then show how, by auditing the agents\u2019 machine learning-generated f , the regulator can achieve their first-best payoff. Perdomo et al. (2020) create an equilibrium predictions framework and study how retraining can converge to equilibria. Kleinberg and Raghavan (2020) consider a model where data is both manipulable and endogenous. Hu and Chen (2018) show how fairness-enhancing interventions in a short-term labor market can lead to fairness in a long-term market without intervention. Penn and Patty (2023) endow individuals of the population with preferences and the ability to choose their class, and then analyze the equilibrium distribution of (i, x, y). Hardt et al. (2016a), Eliaz and Spiegler (2019), and Frankel and Kartik (2022) model individuals strategically manipulating their data in response to how that data is used in algorithmic decision-making.\nMy paper is based on the observation that Arrovian models of statistical discrimination \u2013 in which any differences in the conditional distribution of y across groups are derived in equilibrium \u2013 are ideal vessels through which to think about algorithmic fairness in a coherent way that addresses the issues brought up above. See Arrow (1971). Fang and Moro (2011) provide an excellent survey of statistical discrimination models. Patty and Penn (2023) also draw connections between statistical discrimination and algorithmic fairness.\nConsider the Arrovian statistical discrimination model of CL described in the introduction. Algorithmic bias emerges endogenously, in the form of discriminatory equilibria that feature both disparate treatment and disparate impact.\nIndividuals of the population are endowed with preferences over decisions that yield a natural fairness goal for the regulator: To bring gains to the discriminated group in any discriminatory equilibrium. This goal addresses issue 1 by properly\norienting the regulator and ensuring that they do not unintentionally shoot for policies that end up making all groups worse off. In contrast, the agent firm simply wants to maximize its own utility. The regulator, unlike the firm, does not know the parameter values of the model, such as the utilities of various decisions and the distribution of qualification costs. This limits the regulator\u2019s ability to control the agent\u2019s algorithmic decision-making in a fine-tuned way, yielding a natural agency problem that addresses issue 2. In the model, individuals are not exogenously assigned classes. Instead, each individual chooses their class, taking into account the firm\u2019s decision policy. Thus, a natural way for the regulator to show awareness of the long-term impact on fairness from imposing a new regulation is by seeking to design controls under which steady states are non-discriminatory equilibria. This addresses issue 3, while introducing a second fairness goal.\nWith two fairness goals to satisfy now, it is, a priori, not clear that a regulator can achieve both. This brings up issue 4. Indeed, CL\u2019s result, about how affirmative action achieves the first but not the second fairness goal, can be interpreted as suggesting the two fairness goals might be incompatible. By recasting CL\u2019s traditional human decision-making model as a modern model of algorithmic decision-making, I am able to leverage the insights of Kleinberg et al. (2018b, 2020), who argue that a fundamental difference between regulating human decision-making and regulating algorithmic decision-making is that in the latter case, algorithms can be audited \u2013 in particular, beliefs are contractible. This allows me to conceive of algorithmic controls as feasible regulations of the firm, eventually leading me to the discovery that the equal opportunity control achieves both fairness goals and, therefore, addresses issue 4. Finally, since the regulator does not know the parameter values of the model, any feasible control that achieves the regulator\u2019s fairness goals is necessarily nonparametric. Thus, ideal controls like the equal opportunity control address issue 5."
        },
        {
            "heading": "2 An Economic Model with Machine Learning",
            "text": "I take the statistical discrimination model of CL and make one essential change: I replace the rational expectations firm with one that uses a machine learning algorithm to compute a prediction to serve as its contractible belief.\nThere is a firm and a unit mass of applicants. Each applicant possesses a vector of publicly observable features (i, x) and an unobservable binary class y \u2208 Y := {q, u}. Here, i \u2208 I := {w, b} is the group identity (can generalize to more than two), and\nx \u2208 X := X1 \u00d7X2 \u00d7 . . .\u00d7XN are the other features. Assume X is finite. The distribution of applicants over I\u00d7X\u00d7Y is the result of actions taken by the applicants. Initially, each applicant independently draws a group identity i and a cost c \u2208 (\u2212\u221e,\u221e). Let \u03bbw and \u03bbb = 1\u2212\u03bbw be the positive probabilities of drawing w and b, respectively, and let G and g denote the CDF and PDF of c, respectively. After an applicant draws (i, c), they choose to join a class. Joining class q costs c, while joining class u costs 0. Assume g has full support. The assumption is not essential, but it does simplify the analysis by ensuring that, in equilibrium, there are applicants in both classes. Once an applicant joins a class, their other features, x, are realized according to the following statistical model:\nAssumption 1. There exists a nonempty Y \u2282 {1, 2, . . . N}, such that\np(x|i, y) = p(xY |y)p(x\u2212Y |i, xY) > 0 \u2200(i, x, y) \u2208 I \u00d7X \u00d7 Y.\nAssumption 1 allows features to serve as proxies for group identity. CL considers the special case, Y = {1, 2, . . . N}, where there are no proxies for group identity. At this point, the distribution of applicants over I \u00d7X \u00d7 Y is determined. Given that features are public, I assume the firm observes the distribution of applicants over I \u00d7X. In addition, the firm forms a contractible belief f : I \u00d7X \u2192 (0, 1) about the conditional probability that an applicant is of class q.\nThe firm then makes a binary 1-0 decision (e.g., accept-reject, lend-deny, assign to high-low skill job) on each applicant, by choosing a decision policy, defined to be a map d : I\u00d7X \u2192 [0, 1]. Given an (i, x) applicant, d selects decision 1 with probability d(i, x). If the selected decision is 1, the firm\u2019s payoff depends on the applicant\u2019s class, vq > 0 or \u2212vu < 0, while the applicant\u2019s payoff is \u03c9 > 0. If the selected decision is 0, both parties\u2019 payoffs are 0."
        },
        {
            "heading": "2.1 The Formal Game",
            "text": "Clearly, if an i-applicant with cost c is weakly better off joining class q, then any i-applicant with strictly lower cost is strictly better off joining class q. Thus, for each group i, I imagine a representative i-applicant choosing a cost threshold c(i) so that an i-applicant with cost c joins class q if and only if c \u2264 c(i). This allows us to treat the model as a simultaneous-move game, (X,\u03bbw, p, G, vq, vu, \u03c9), between three players: A pair of representative applicants choose a pair of cost thresholds c = (c(w), c(b)) and the firm chooses a decision policy d.\nGiven c, the true distribution, \u00b5RE, of applicant features is\n\u00b5RE(i, x|c(i)) := \u03bbi [G(c(i))p(x|i, q) + (1\u2212G(c(i)))p(x|i, u)] \u2200(i, x) \u2208 I \u00d7X.\nGiven c and d, the utility of the representative i-applicant, for each group i, is\nUi(c(i), d(i)) = \u03c9 \u2211 x\u2208X \u00b5RE(i, x|c(i)) \u03bbi d(i, x)\u2212 \u222b c(i) \u2212\u221e cg(c)dc,\nwhere d(i) is d restricted to i\u00d7X. To ensure Ui is well-defined, assume \u222b\u221e \u2212\u221e |c|g(c)dc < \u221e. The utility of the firm depends on its observed distribution, \u00b5, of applicant features and its machine learning-generated belief, f ,\nUF (d, \u00b5, f) = \u2211\n(i,x)\u2208I\u00d7X\nd(i, x)\u00b5(i, x) [f(i, x)vq \u2212 (1\u2212 f(i, x))vu] .\nFor now, let us assume the observed distribution is the true one, \u00b5 = \u00b5RE, and machine learning is perfectly rational (i.e. calibrated):\nf(i, x) = fRE(i, x|c(i)) := G(c(i))p(x|q, i)\nG(c(i))p(x|q, i) + (1\u2212G(c(i)))p(x|u, i)\n= G(c(i))p(xY |q)\nG(c(i))p(xY |q) + (1\u2212G(c(i)))p(xY |u) \u2200(i, x) \u2208 I \u00d7X.\nIn Section 5, we will consider (\u00b5, f) within some small \u03b5 > 0 of (\u00b5RE, fRE).\nA word on notation: When working with a cost threshold pair, c\u03b1, that is indexed with some subscript \u03b1, we will write \u00b5RE,\u03b1 and fRE,\u03b1 to refer to \u00b5RE and fRE given c\u03b1. The same convention applies for superscripts."
        },
        {
            "heading": "2.2 Controls",
            "text": "Given a set of other features X, let \u2206o(I \u00d7 X) denote the set of all full-support probability distributions over I \u00d7X.\nDefinition. A control k specifies, for each X and (\u00b5, f) \u2208 \u2206o(I \u00d7X)\u00d7 (0, 1)|I\u00d7X|, a nonempty compact set, k(X,\u00b5, f) \u2282 [0, 1]|I\u00d7X|, of decision policies.\nA control is a contract that limits the set of decision policies available to the firm based on what a hypothetical regulator is assumed to be able to observe: (X,\u00b5, f).\nCL, on the other hand, implicitly assume that controls only depend on (X,\u00b5) because f is thought of as existing in the mind of a human rather than the output of a machine learning algorithm. In either case, controls do not depend on the preference parameters of the game, (G, vq, vu, \u03c9), which are assumed to be unknown to a regulator. If controls could depend on all parameters of the game, then eliminating statistical discrimination would be a trivial task.\nExample. The un control specifies, for each X and (\u00b5, f) \u2208 \u2206o(I \u00d7X)\u00d7 (0, 1)|I\u00d7X|, the set of all decision policies.\nExample. A decision policy, d, is color-blind if d(w, x) = d(b, x) \u2200x \u2208 X. The colorblind control specifies, for each X and (\u00b5, f) \u2208 \u2206o(I \u00d7X)\u00d7 (0, 1)|I\u00d7X|, the set of all color-blind decision policies.\nExample. The affirmative action control specifies, for each X and (\u00b5, f) \u2208 \u2206o(I \u00d7 X)\u00d7 (0, 1)|I\u00d7X|,\nk(X,\u00b5, f) = { d \u2208 [0, 1]|I\u00d7X| \u2223\u2223\u2223\u2223 AR(w, d, \u00b5) = AR(b, d, \u00b5)} , where AR(i, d, \u00b5) := \u2211 x\u2208X d(i,x)\u00b5(i,x)\u2211\nx\u2208X \u00b5(i,x) is the acceptance rate of group i.\nUnlike the three controls described above, the following algorithmic control de-\npends on the firm\u2019s machine learning-generated belief:\nExample. The equal opportunity control specifies, for each X and (\u00b5, f) \u2208 \u2206o(I \u00d7 X)\u00d7 (0, 1)|I\u00d7X|,\nk(X,\u00b5, f) = { d \u2208 [0, 1]|I\u00d7X| \u2223\u2223\u2223\u2223 TP (w, d, \u00b5, f) = TP (b, d, \u00b5, f)} , where TP (i, d, \u00b5, f) := \u2211 x\u2208X d(i,x)\u00b5(i,x)f(i,x)\u2211\nx\u2208X \u00b5(i,x)f(i,x) is the true positive rate of group i.\nDefinition. Given a control k and a game (X,\u03bbw, p, G, vq, vu, \u03c9), a strategy profile (ck, dk) is a k-controlled equilibrium if\n1. ck(i) = argmaxc(i)\u2208R Ui(c(i), dk(i)) for all groups i,\n2. dk \u2208 argmaxd\u2208k(X,\u00b5RE,k,fRE,k) UF (d, \u00b5RE,k, fRE,k).\nFrom now on, the term \u201cequilibrium\u201d will refer to an un-controlled equilibrium."
        },
        {
            "heading": "2.3 Characterizing Equilibria",
            "text": "This part reviews CL Section I. Results are stated without proof.\nFix a game (X,\u03bbw, p, G, vq, vu, \u03c9) and let (c \u2217, d\u2217) be an equilibrium. (c\u2217, d\u2217) can be decomposed into a pair of within-group equilibria, {(c\u2217(i), d\u2217(i)) | i \u2208 I}. Let us characterize within-group equilibria.\nDefine the likelihood function\nl(x) := p(xY |q) p(xY |u) \u2200x \u2208 X.\nSince p(xY |y) > 0 for all (x, y) \u2208 X \u00d7 Y , l is a well-defined positive function taking finitely many values, 0 < l1 < l2 < . . . < ln for some n.\nFix a group i. Given a within-group decision policy d(i), and a likelihood value\nlm, define d(i|lm) := \u2211\nx\u2208X,l(x)=lm(G(c(i))p(x|i, q) + (1\u2212G(c(i)))p(x|i, u))d(i, x)\u2211 x\u2208X,l(x)=lm G(c(i))p(x|i, q) + (1\u2212G(c(i)))p(x|i, u) .\nd(i|lm) is the probability an i-applicant receives decision 1 under d(i) conditional on having a vector of other features with likelihood value lm. Note, d(i|lm) is independent of c(i) because all applicants in this subgroup, by definition, have vectors of other features with the same likelihood value:\nd(i|lm) = \u2211\nx\u2208X,l(x)=lm p(x|i, q)d(i, x)\u2211 x\u2208X,l(x)=lm p(x|i, q) =\n\u2211 x\u2208X,l(x)=lm p(x|i, u)d(i, x)\u2211\nx\u2208X,l(x)=lm p(x|i, u) .\nIntroduce the auxiliary likelihood value l0 = 0. For each likelihood value lm,\nm \u2208 {0, 1, 2, . . . n}, define\nWW (lm) := \u03c9 \u2211\nxY\u2208XY , p(xY|q) p(xY|u) >lm\n(p(xY |q)\u2212 p(xY |u)) \u2208 [0, \u03c9).\nWW (lm) = 0 if and only if m \u2208 {0, n}. Create the piecewise-linear functionWW : [0, ln] \u2192 [0, \u03c9) that connects the points {(lm,WW (lm)) | m = 0, 1, . . . n}. Figure 1a depicts an example WW with n = 3. WW is independent of group identity.\nRefer to any l \u2208 [0, ln] as a likelihood mixture. For each likelihood mixture l, define \u2308l\u2309 to be the smallest likelihood value \u2265 l and \u2308l\u2309\u2212 denote the next smallest\nlikelihood value, if it exists. Associate to l the set of all within-group decision policies d(i) satisfying\nd(i|lm) =  1 if lm > \u2308l\u2309 \u2308l\u2309\u2212l \u2308l\u2309\u2212\u2308l\u2309\u2212 if lm = \u2308l\u2309\n0 if lm < \u2308l\u2309,\nfor each m \u2208 {1, 2, . . . n}. Given l \u2208 [0, ln], a d(i) associated with l has a threshold form, selecting decision 1/0 for i-applicants with likelihood value above/below \u2308l\u2309. WW (l) is the best-response of the representative i-applicant.\nDefinition. A decision policy is fair if both of its within-group decision policies are associated with the same likelihood mixture.\nNext, for each likelihood value lm, m \u2208 {1, 2, . . . n}, define cost EE(lm) to satisfy\nG(EE(lm)) = 1\nvq vu\n\u00b7 lm + 1 .\nIf the representative i-applicant chooses c(i) = EE(lm), then the firm is indifferent\nbetween making decision 1 and 0 for any i-applicant with likelihood value lm. Since G is strictly increasing and continuous with range (0, 1), EE(lm) exists and is unique for each m \u2208 {1, 2, . . . n}. Moreover, EE(l1) > EE(l2) > . . . > EE(ln). Create the correspondence EE : [0, ln] \u2282 R as follows:\nEE(l) =  [EE(l1),\u221e) if l = 0 [EE(lm+1), EE(lm)] if l = lm for some m \u2208 {1, 2, . . . n\u2212 1} EE(lm) if l \u2208 (lm\u22121, lm) for some m \u2208 {1, 2, . . . n}\n(\u2212\u221e, EE(ln)] if l = ln.\nLike WW , EE is also independent of group identity. Figure 1b depicts an EE superimposed on aWW . Each intersection, (l\u2217,WW (l\u2217)), of EE andWW is associated with a set of within-group equilibria,\n{(c\u2217(i) = WW (l\u2217), d\u2217(i))},\nwhere d\u2217(i) is any within-group decision policy associated with the likelihood mixture l\u2217. Conversely, each within-group equilibrium is an element of one such set.\nThe set of equilibria is the set of pairs of within-group equilibria, one for each group. Since EE and WW intersect, the set of equilibria is nonempty. Call two equilibria equivalent if they are associated with the same pair of intersections of EE and WW . This partitions the set of equilibria into equivalence classes.\nAssumption 2. WW is single-peaked.\nAssuming WW is single-peaked is equivalent to assuming that 1 is not a likelihood value, which is a generic property of games. The assumption ensures that there does not exist equilibria (c\u2217, d\u2217), where c\u2217(w) = c\u2217(b) but d\u2217 is unfair and acceptance rates differ across groups. The assumption is not crucial, but it does simplify the statements of some definitions and results, such as the following:\nLemma 1. Given an equilibrium (c\u2217, d\u2217), the following are equivalent:\n1. c\u2217(w) = c\u2217(b),\n2. d\u2217 is fair,\n3. AR(w, d\u2217, \u00b5\u2217RE) = AR(b, d \u2217, \u00b5\u2217RE).\nAn equilibrium satisfying these equivalent conditions is called non-discriminatory."
        },
        {
            "heading": "3 Ideal Controls",
            "text": "Definition. A control k is ideal if, for any game (X,\u03bbw, p, G, vq, vu, \u03c9), the following two properties are satisfied:\n1. (Gains to the Discriminated Group in Any Discriminatory Equilibrium.) If\n(c\u2217, d\u2217) is a discriminatory equilibrium, then\n\u2200d\u0302 \u2208 argmax d\u2208k(X,\u00b5\u2217RE ,f \u2217 RE) UF (d, \u00b5 \u2217 RE, f \u2217 RE),[\nmin i\u2208I AR(i, d\u0302, \u00b5\u2217RE),max i\u2208I AR(i, d\u0302, \u00b5\u2217RE)\n] \u228a [ min i\u2208I AR(i, d\u2217, \u00b5\u2217RE),max i\u2208I AR(i, d\u2217, \u00b5\u2217RE) ] .\n2. (Steady States Coincide with the Set of Non-Discriminatory Equilibria.) The\nset of k-controlled equilibria is the set of non-discriminatory equilibria.\nThe definition of an ideal control is motivated by CL, who write,\nA key question concerning affirmative action is whether the labor-market gains it brings to minorities can continue without it becoming a permanent fixture in the labor market.\nEssentially, CL are asking is the affirmative action control ideal? The control does bring gains to the discriminated group in any discriminatory equilibrium. However, CL construct affirmative action-controlled equilibria that are not non-discriminatory equilibria. In these equilibria, the previously discriminated group remains less qualified and permanently requires the support of affirmative action in order to not fall behind the previously favored group. Thus, the affirmative action control is not ideal.\nIn contrast, an ideal control not only brings gains to the discriminated group in any discriminatory equilibrium, it also ensures that when the market reaches a steady state, that steady state will be a non-discriminatory equilibrium that renders obsolete the control that brought the market there.\nTheorem 1. The equal opportunity control is ideal.\nLet k be the equal opportunity control and fix a game (X,\u03bbw, p, G, vq, vu, \u03c9) with\nlikelihood values 0 = l0 < l1 < l2 < . . . < ln for some n.\nGiven an arbitrary c, define\nSk(\u00b5RE, fRE) := argmax d\u2208k(X,\u00b5RE ,fRE) UF (d, \u00b5RE, fRE),\nand let d\u0302 \u2208 Sk(\u00b5RE, fRE). Let TP (d\u0302) be the true positive rate shared by both groups under (d\u0302, \u00b5RE, fRE). Then, for each group i, {d\u0302(i, x)}x\u2208X is a solution to the following linear programming problem,\nargmax {dx\u2208[0,1]}x\u2208X s.t. \u2211 x\u2208X dx\u00b5RE(i,x)fRE(i,x)\u2211 x\u2208X \u00b5RE(i,x)fRE(i,x) =TP (d\u0302) \u2211 x\u2208X dx\u00b5RE(i, x) [fRE(i, x)vq \u2212 (1\u2212 fRE(i, x))vu] .\nIt can be shown that the first-order conditions that characterize the solution imply that, for each group i, d\u0302(i) is associated with some likelihood mixture. Equality of true positive rates then implies that d\u0302 is fair. Under a fair decision policy, d, the incentive to invest to be come qualified,\n\u03c9 \u2211 x\u2208X d(i, x)(p(x|i, q)\u2212 p(x|i, u)),\nis equalized across groups. Thus, the equal opportunity control induces a utilitymaximizing firm to equalize incentives \u2013 this is the crucial property of the equal opportunity control.\nConversely, any fair decision policy equalizes true positive rates and is, therefore, allowed under the equal opportunity control. These observations can be summarized as follows:\nLemma 2. Let k be the equal opportunity control. Given any cost threshold pair, c, Sk(\u00b5RE, fRE) \u2282 F \u2282 k(X,\u00b5RE, fRE).\nProof. See appendix.\nWe are now in a position to prove Theorem 1. First, consider a discriminatory equilibrium (c\u2217, d\u2217). Let l\u2217i be the likelihood mixture associated with d \u2217(i). Without loss of generality, assume l\u2217w < l \u2217 b . Let d\u0302 \u2208 Sk(\u00b5\u2217RE, f \u2217RE). By Lemma 2, d\u0302 is fair, and so both within-group decision policies are associated with the same likelihood mixture \u2013 call it l\u0302.\nThere exist integers mw \u2208 {0, 1, . . . n \u2212 1} and mb \u2208 {1, 2, . . . n} such that l\u2217w \u2208 [lmw , lmw+1) and l \u2217 b \u2208 (lmb\u22121, lmb ]. If l\u0302 > lmb , then the firm is strictly better off deviating to the fair decision policy associated with lmb . By Lemma 2, this deviation is feasible under the equal opportunity control. It makes the firm strictly better off because the additional w-applicants that receive decision 1 give the firm positive expected utility and the additional b-applicants that receive decision 1 give the firm nonnegative expected utility. Thus, l\u0302 \u2264 lmb .\nIf l\u2217b < lmb , then l \u2217 w \u2264 lmb\u22121. In this case, if l\u0302 \u2208 (lmb\u22121, lmb ], then the firm is strictly better off deviating to the fair decision policy where both within-group decision policies are associated with lmb\u22121. Under this deviation, the additional wapplicants that receive decision 1 give the firm positive expected utility and the additional b-applicants that receive decision 1 give the firm zero expected utility. Thus, l\u0302 \u2264 l\u2217b and AR(b, d\u0302, \u00b5\u2217RE) \u2265 AR(b, d\u2217, \u00b5\u2217RE). By a symmetric argument l\u0302 \u2265 l\u2217w and AR(w, d\u0302, \u00b5\u2217RE) \u2264 AR(w, d\u2217, \u00b5\u2217RE). Since l\u2217w < l\u2217b , so c \u2217(w) > c\u2217(b). And now, since d\u0302 is fair, we have AR(b, d\u0302, \u00b5\u2217RE) < AR(w, d\u0302, \u00b5 \u2217 RE). Finally, since l\u2217w < l \u2217 b , it must be the case that l\u0302 < l \u2217 b \u2013 in which case, AR(b, d\u0302, \u00b5 \u2217 RE) > AR(b, d\u2217, \u00b5\u2217RE), or l\u0302 > l \u2217 w \u2013 in which case, AR(w, d\u0302, \u00b5 \u2217 RE) < AR(w, d \u2217, \u00b5\u2217RE). This proves that the equal opportunity control brings gains to the discriminated group in any discriminatory equilibrium.\nNext, let (ck, dk) be an equal opportunity-controlled equilibrium. By Lemma 2,\ndk is fair, and so ck(w) = ck(b). Since ck(w) = ck(b), the set\nS(\u00b5RE,k, fRE,k) := argmax d\u2208[0,1]|I\u00d7X| UF (d, \u00b5RE,k, fRE,k)\nconsists of a single fair decision policy, or it contains fair decision policies. Let d\u2217k \u2208 S(\u00b5RE,k, fRE,k) \u2229 F . By Lemma 2, d\u2217k \u2208 k(X,\u00b5RE,k, fRE,k). This implies UF (dk, \u00b5RE,k, fRE,k) \u2265 UF (d\u2217k, \u00b5RE,k, fRE,k), which implies dk \u2208 S(\u00b5RE,k, fRE,k). So, (ck, dk) is a non-discriminatory equilibrium. Clearly, all non-discriminatory equilibria are equal opportunity-controlled equilibria. This establishes that the set of equal opportunity-controlled equilibria is the set of non-discriminatory equilibria.\nLet k\u2032 be any control with the property that, for each X and (\u00b5, f) \u2208 \u2206o(I\u00d7X)\u00d7 (0, 1)|I\u00d7X|, F \u2282 k\u2032(X,\u00b5, f) \u2282 k(X,\u00b5, f). Lemma 2 and the proof of Theorem 1 imply that k\u2032 is also ideal. For example, the equal odds control, that equalizes both true and false positive rates, is ideal. Such controls are, by definition, more restrictive than the equal opportunity control. An interesting question is whether there exist ideal controls that are meaningfully less restrictive than the equal opportunity control.\nOne family of controls that comes close is the following:\nExample. In a mistaken identity control, there exists a reference identity, i\u2217, such that, for each X and (\u00b5, f) \u2208 \u2206o(I \u00d7X)\u00d7 (0, 1)|I\u00d7X|,\nk(X,\u00b5, f) = { d \u2208 [0, 1]|I\u00d7X| \u2223\u2223\u2223\u2223 d is a threshold function of f(i\u2217, x)}.\nA decision policy d is a threshold function of f(i\u2217, x) if d depends on (i, x) only up to f(i\u2217, x) \u2013 in particular, d is color-blind \u2013 and there exists an f \u2208 (0, 1) such that f(i\u2217, x) > f (< f) \u21d2 d(w, x) = d(b, x) = 1 (= 0).\nRoughly speaking, mistaken identity controls force the firm to act as if it thinks all groups have the same identity. They are similar to the minority-as-whites proposal of Yang and Dobbie (2020) and are also related to the proposal studied by Pope and Sydnor (2011). An attractive property of mistaken identity controls is that, unlike the equal opportunity control, they do not depend on \u00b5. Mistaken identity controls are almost ideal in the sense that they satisfy the first property of being ideal and a slightly relaxed version of the second property where the requirement that every non-discriminatory equilibrium be a k-controlled equilibrium is changed to every equivalence class of non-discriminatory equilibria contains a k-controlled equilibrium.\nIn Section 5, I will introduce another control that does not depend on \u00b5 and is also almost ideal. However, we will see that issues can arise with both of these controls when the firm\u2019s machine learning algorithm is not perfectly rational."
        },
        {
            "heading": "4 Not Ideal Controls",
            "text": "CL showed that the affirmative action control is not ideal by constructing affirmative action-controlled equilibria that are not non-discriminatory equilibria. In this section and the next, I consider other controls that are not ideal, in order to provide additional context for ideal controls.\nLet us begin by constructing a useful family of games. Fix a cost distribution with\nG and g satisfying G(0) = 1\u2212G(2 3 ) = 1 6 and g(c) = 1 for all c \u2208 [0, 2 3 ], and consider the following family of games parameterized by constants \u03b3 \u2208 (0, 1 6 ) and \u03b4 \u2208 (0, 1):\n\u2022 X = X1 \u00d7X2 = {L,H\u2212, H+} \u00d7 {W,B},\n\u2022 \u03bbw = 12 ,\n\u2022 p(x|i, y) = p(x1|y)p(x2|i) where\n\u2013 p(x1|q) = 13 for all x1 \u2208 X1, \u2013 p(L|u) = 2 3 , p(H\u2212|u) = 16 + \u03b3, p(H+|u) = 1 6 \u2212 \u03b3, \u2013 p(W |w) = p(B|b) = 1\u2212 \u03b4,\n\u2022 vq = vu = \u03c9 = 1.\nFor any game in this family, EE and WW intersect five times as in Figure 2. To begin, consider the limit \u201cgame\u201d where \u03b3 = \u03b4 = 0. Technically speaking, this is not a game because \u03b4 = 0 implies the full support condition of Assumption 1 is violated.\nLet c\u2217(w) = 1 3 and c\u2217(b) = 0. The tables for (\u00b5\u2217RE(i, x), f \u2217 RE(i, x)) for (i, x) \u2208\nw \u00d7X1 \u00d7W \u222a b\u00d7X1 \u00d7B are:\nw W H+ 1/8 2/3 H\u2212 1/8 2/3 L 1/4 1/3\nb B H+ 7/72 2/7 H\u2212 7/72 2/7 L 22/72 1/11\nDefinition. Given a game (X,\u03bbw, p, G, vq, vu, \u03c9) and a pair of cost thresholds c =\n(c(w), c(b)), the color-blind true distribution, \u00b5cb,RE, of applicant features is\n\u00b5cb,RE(x|c) := \u00b5RE(w, x|c(w)) + \u00b5RE(b, x|c(b)) \u2200x \u2208 X,\nand the color-blind true conditional probability, fcb,RE, is\nfcb,RE(x|c) := \u00b5RE(w, x|c(w))fRE(w, x|c(w)) + \u00b5RE(b, x|c(b))fRE(b, x|c(b))\n\u00b5cb,RE(x|c) \u2200x \u2208 X.\nThe tables for (\u00b5\u2217RE(i, x), f \u2217 RE(i, x)) yield the table for (\u00b5 \u2217 cb,RE, f \u2217 cb,RE):\nW B\nH+ 1/8 2/3 7/72 2/7 H\u2212 1/8 2/3 7/72 2/7 L 1/4 1/3 22/72 1/11\nIn particular, f \u2217cb,RE(x) > vu vq+vu = 1 2 for x \u2208 {(H+,W ), (H\u2212,W )} and f \u2217cb,RE(x) < 12 otherwise.\nDefine the color-blind decision policy d\u2217 where d\u2217(i, x) = 1 if x \u2208 {(H+,W ), (H\u2212,W )} and d\u2217(i, x) = 0 otherwise. Continuity now implies, for all sufficiently small \u03b3, \u03b4 > 0, the best-response c\u2217\u03b3,\u03b4 to d \u2217 in the (\u03b3, \u03b4)-game is sufficiently close to c\u2217 so that f \u2217cb,RE,\u03b3,\u03b4(x) > 1 2 for x \u2208 {(H+,W ), (H\u2212,W )} and f \u2217cb,RE,\u03b3,\u03b4(x) < 12 otherwise. This implies that in these (\u03b3, \u03b4)-games, (c\u2217\u03b3,\u03b4, d \u2217) is a color-blind-controlled equilibrium.\nClearly, (c\u2217\u03b3,\u03b4, d \u2217) is not a non-discriminatory equilibrium. In fact, holding \u03b3 fixed, as \u03b4 goes to zero, (c\u2217\u03b3,\u03b4, d \u2217) converges in payoff to one of the two most discriminatory equilibria, where the within-group equilibrium of w is associated with Eq1 and the within-group equilibrium of b is associated with Eq5. Thus, we have proved\nProposition 1. The color-blind control is not ideal."
        },
        {
            "heading": "4.1 Color-Blind Data",
            "text": "Attempts to remove disparate treatment often begin with making data color-blind. In this section, I argue that regulating machine learning by making data color-blind is counterproductive. I extend the definition of an ideal control to when data is color-blind and then prove that no such control exists.\nGiven a game (X,\u03bbw, p, G, vq, vu, \u03c9), let us extend the definitions of a number of\npreviously introduced concepts to when data is color-blind.\nWhen data is color-blind, a distribution of features \u00b5cb is an element of \u2206 o(X), a\nbelief fcb is an element of (0, 1) |X|, and a decision policy dcb is an element of [0, 1] |X|. In the rest of this section, I will not add the qualifier \u201cwhen data is color-blind\u201d when discussing concepts for when data is color-blind. The only exception is in formal definitions and results, where I will continue to add the qualifier. When referring to the originally defined versions of concepts, I will add the qualifier \u201cwhen data is not color-blind.\u201d\nA strategy profile is a pair (c, dcb). Each dcb can be identified with the color-blind decision policy d = (d(w), d(b)) = (dcb, dcb) in the original setting when data is not color-blind. This allows us to identify (c, dcb) with a strategy profile when data is not color-blind. Given c, dcb, and fcb, define Ucb,i(c(i), dcb) := Ui(c(i), dcb) for each i \u2208 I, and define Ucb,F (dcb, \u00b5cb, fcb) in the obvious way. A control specifies, for each X and (\u00b5cb, fcb) \u2208 \u2206o(X) \u00d7 (0, 1)|X|, a nonempty compact set, kcb(X,\u00b5cb, fcb) \u2282 [0, 1]|X|, of decision policies. Define a kcb-controlled equilibrium (ccb,k, dcb,k) in the obvious way. An equilibrium is non-discriminatory if, when viewed as a strategy profile when data is not color-blind, it is a non-discriminatory equilibrium.\nDefinition. When data is color-blind, a control kcb is ideal if, for any game (X,\u03bbw, p, G, vq, vu, \u03c9), the following two properties are satisfied:\n1. (Gains to the Discriminated Group in Any Discriminatory Equilibrium.) If\n(c\u2217, d\u2217cb) is a discriminatory equilibrium, then\n\u2200d\u0302cb \u2208 argmax dcb\u2208k(X,\u00b5\u2217cb,RE ,f \u2217 cb,RE) UF (dcb, \u00b5 \u2217 cb,RE, f \u2217 cb,RE),[\nmin i\u2208I\nAR(i, (d\u0302cb, d\u0302cb), \u00b5 \u2217 RE),max\ni\u2208I AR(i, (d\u0302cb, d\u0302cb), \u00b5\n\u2217 RE) ] \u228a [ min i\u2208I AR(i, (d\u2217cb, d \u2217 cb), \u00b5 \u2217 RE),max i\u2208I AR(i, (d\u2217cb, d \u2217 cb), \u00b5 \u2217 RE) ] .\n2. (Steady States Coincide with the Set of Non-Discriminatory Equilibria.) The\nset of k-controlled equilibria is the set of non-discriminatory equilibria.\nTheorem 2. When data is color-blind, there does not exist an ideal control.\nTo prove Theorem 2, it suffices to find two different games such that a discriminatory equilibrium of one game and a non-discriminatory equilibrium of the other game share the same (X, d\u2217cb, \u00b5 \u2217 cb,RE, f \u2217 cb,RE). This puts the two properties of being\nideal in conflict with each other: Let kcb be ideal. Since (X, d \u2217 cb, \u00b5 \u2217 cb,RE, f \u2217 cb,RE) arises from a discriminatory equilibrium, both properties imply d\u2217cb /\u2208 kcb(X,\u00b5\u2217cb,RE, f \u2217cb,RE). Since (X, d\u2217cb, \u00b5 \u2217 cb,RE, f \u2217 cb,RE) arises from a non-discriminatory equilibrium, the second property implies d\u2217cb \u2208 kcb(X,\u00b5\u2217cb,RE, f \u2217cb,RE). Contradiction. We now construct two such games. The shared X is the one shared by the family of (\u03b3, \u03b4)-games considered earlier, X1 \u00d7X2 = {L,H\u2212, H+} \u00d7 {W,B}. Recall, in the analysis of that family of games, we introduced the decision policy d\u2217, when data is not color-blind, where d\u2217(i, x) = 1 if x \u2208 {(H+,W ), (H\u2212,W )} and d\u2217(i, x) = 0 otherwise, and its best-response cost threshold pair, c\u2217\u03b3,\u03b4. One game is a (\u03b3, \u03b4)-game, with \u03b3 and \u03b4 sufficiently close to zero so that f \u2217cb,RE,\u03b3,\u03b4(x) > 1 2 for x \u2208 {(H+,W ), (H\u2212,W )} and f \u2217cb,RE,\u03b3,\u03b4(x) < 1 2 otherwise. This yields the discriminatory equilibrium (c\u2217\u03b3,\u03b4, d \u2217 cb), where d\u2217cb := d \u2217(w) = d\u2217(b). Notice, d\u2217cb is a threshold function of f \u2217 cb,RE,\u03b3,\u03b4 in the sense that, there exists a threshold (1 2 , for example), such that d\u2217cb takes value 1/0 when f \u2217cb,RE,\u03b3,\u03b4 is above/below that threshold, respectively. Once Lemma 3 below is proved, the existence of a game with the same X featuring a non-discriminatory equilibrium with the same firm decision policy, true distribution of applicant features, and true conditional probability is guaranteed, and Theorem 2 is proved.\nLemma 3. Given an X and a (dcb, \u00b5cb, fcb) \u2208 [0, 1]|X|\u00d7\u2206o(X)\u00d7(0, 1)|X|, where dcb is a threshold function of fcb, there exists a game (X,\u03bbw, p, G, vq, vu, \u03c9) with the property that, when data is color-blind, (\u00b5cb, fcb) is the true distribution of applicant features and true conditional probability of a non-discriminatory equilibrium with decision policy dcb.\nThe proof of Lemma 3 is constructive. FixX and (dcb, \u00b5cb, fcb) \u2208 [0, 1]|X|\u00d7\u2206o(X)\u00d7 (0, 1)|X|, where dcb is a threshold function of fcb with some threshold f .\nLet {G}\u222a{(qx, ux)}x\u2208X be a collection of variables satisfying the following system of equations:\n\u2022 \u00b5cb(x) = Gqx + (1\u2212 G)ux for all x \u2208 X,\n\u2022 fcb(x) = GqxGqx+(1\u2212G)ux for all x \u2208 X,\n\u2022 \u2211 x\u2208X qx = \u2211 x\u2208X ux = 1.\nThere exists a unique solution:\n\u2022 G = \u2211\nx\u2208X \u00b5cb(x)fcb(x) \u2208 (0, 1),\n\u2013 which implies 1\u2212 G = \u2211 x\u2208X \u00b5cb(x)(1\u2212 fcb(x)) since \u2211 x\u2208X \u00b5cb(x) = 1,\n\u2022 qx = \u00b5cb(x)fcb(x)G \u2208 (0, 1) for all x \u2208 X,\n\u2022 ux = \u00b5cb(x)(1\u2212fcb(x))1\u2212G \u2208 (0, 1) for all x \u2208 X.\nDefine the following game:\n\u2022 \u03bbw can be any value,\n\u2022 G satisfies G(c(w)) = G(c(b)) = G,\n\u2013 where c(w) = c(b) = \u2211\nx\u2208X dcb(x)(qx \u2212 ux),\n\u2022 p(x|i, q) = qx and p(x|i, u) = ux for all (i, x) \u2208 I \u00d7X,\n\u2022 vq, vu satisfy f = vuvq+vu ,\n\u2022 \u03c9 = 1.\nIt is straightforward to check that (c, dcb) is a non-discriminatory equilibrium with true distribution of applicant features, \u00b5cb, and true conditional probability, fcb."
        },
        {
            "heading": "5 Beyond Perfect Rationality",
            "text": "Given a set of other features X and a belief f defined over I \u00d7X, a subset, Y\u0302 , of the other features indices has the property that f depends on I \u00d7X only up to I \u00d7XY\u0302 if\nxY\u0302 = x \u2032 Y\u0302 \u21d2 f(i, x) = f(i, x \u2032) \u2200x, x\u2032 \u2208 X, i \u2208 I.\nLet Y\u03021 and Y\u03022 be two such subsets, then Y\u03021 \u2229 Y\u03022 also has the property: Let x, x\u2032 satisfy xY\u03021\u2229Y\u03022 = x \u2032 Y\u03021\u2229Y\u03022 . Let x\u2032\u2032 satisfy x\u2032\u2032Y\u03021 = xY\u03021 and x \u2032\u2032 Y\u03022 = x\u2032Y\u03022 . Then f(i, x) = f(i, x\u2032\u2032) = f(i, x\u2032). Thus, there exists a unique, possibly empty, minimal subset, Y\u0302(f), with the property.\nExample. The no proxies control k specifies, for each X and (\u00b5, f) \u2208 \u2206o(I \u00d7X)\u00d7 (0, 1)|I\u00d7X|,\nk(X,\u00b5, f) = { d \u2208 [0, 1]|I\u00d7X| \u2223\u2223 d depends on I \u00d7X only up to XY\u0302(f)} .\nWhen machine learning is perfectly rational, the no proxies control excludes all features that are proxies for group identity. It is similar to the counterfactual fairness proposal of Kusner et al. (2017). Like the mistaken identity controls, it depends only on f and is almost ideal.\nHowever, it is clear that arbitrarily small deviations from perfect rationality can cause the no proxies control to fail to exclude any features for being a group identity proxy. This suggests that the ideal-ness of the no proxies control is fragile. One may try to remedy this fragility by strengthening the definition of Y\u0302(f) to exclude any features along which f is \u201calmost constant,\u201d rather than just \u201cconstant.\u201d The problem with such an approach is that, without knowing the parameters of the model, it is impossible to know what constitutes almost constant.\nI now make precise in what sense the no proxies control is fragile. I then show\nthat, in contrast, the equal opportunity control is not fragile.\nDefinition. Given a control k, a game (X,\u03bbw, p, G, vq, vu, \u03c9), and an \u03b5 > 0, a strategy profile (ck,\u03b5, dk,\u03b5) is a k-controlled \u03b5-equilibrium if there exists a (\u00b5k,\u03b5, fk,\u03b5) satisfying\n\u2225(\u00b5k,\u03b5, fk,\u03b5)\u2212 (\u00b5RE,k,\u03b5, fRE,k,\u03b5)\u22252 \u2264 \u03b5,\nsuch that\n1. ck,\u03b5(i) = argmaxc(i)\u2208R Ui(c(i), dk,\u03b5(i)) for all i \u2208 I,\n2. dk,\u03b5 \u2208 argmaxd\u2208k(X,\u00b5k,\u03b5,fk,\u03b5) UF (d, \u00b5k,\u03b5, fk,\u03b5).\nDefinition. A control k is not fragile if, for any game (X,\u03bbw, p, G, vq, vu, \u03c9) and any \u03b4 > 0, there exists an \u03b5 > 0 such that the following two properties are satisfied:\n1. If (c\u2217, d\u2217) is a discriminatory equilibrium and \u2225(\u00b5\u2217, f \u2217)\u2212(\u00b5\u2217RE, f \u2217RE)\u22252 \u2264 \u03b5, then for every d\u0302 \u2208 Sk(\u00b5\u2217, f \u2217), there exists a d\u0302\u2217 \u2208 Sk(\u00b5\u2217RE, f \u2217RE) such that \u2225d\u0302\u2212 d\u0302\u2217\u22252 \u2264 \u03b4.\n2. If (ck,\u03b5, dk,\u03b5) is a k-controlled \u03b5-equilibrium, then there exists a k-controlled equi-\nlibrium (ck, dk), such that \u2225(ck,\u03b5, dk,\u03b5)\u2212 (ck, dk)\u22252 \u2264 \u03b4.\nLet k be the no proxies control and let us reconsider the (\u03b3, \u03b4)-games introduced in the previous section. Again, assume \u03b3, \u03b4 > 0 are sufficiently small so that f \u2217cb,RE,\u03b3,\u03b4(x) > 1 2 for x \u2208 {(H+,W ), (H\u2212,W )} and f \u2217cb,RE,\u03b3,\u03b4(x) < 12 otherwise. Recall, this implies (c\u2217\u03b3,\u03b4, d \u2217) is a color-blind-controlled equilibrium. Note, (c\u2217\u03b3,\u03b4, d \u2217) is not a\nno proxies-controlled equilibrium because when machine learning is perfectly rational, d\u2217 /\u2208 k(X,\u00b5\u2217RE,\u03b3,\u03b4, f \u2217RE,\u03b3,\u03b4), since d\u2217 depends on the excluded feature X2. However, for any \u03b5 > 0, it is possible to perturb the perfectly rational belief f \u2217RE,\u03b3,\u03b4 to some f \u2217\u03b3,\u03b4 so that\n1. \u2225(\u00b5\u2217RE,\u03b3,\u03b4, f \u2217\u03b3,\u03b4)\u2212 (\u00b5\u2217RE,\u03b3,\u03b4, f \u2217RE,\u03b3,\u03b4)\u22252 \u2264 \u03b5,\n2. d\u2217 remains the best-response color-blind decision policy,\n3. f \u2217\u03b3,\u03b4 is injective.\nf \u2217\u03b3,\u03b4 injective implies no feature except group identity is excluded, in which case k(X,\u00b5\u2217RE,\u03b3,\u03b4, f \u2217 \u03b3,\u03b4) is the set of color-blind decision policies and d\n\u2217 \u2208 k(X,\u00b5\u2217RE,\u03b3,\u03b4, f \u2217\u03b3,\u03b4). This implies that (c\u2217\u03b3,\u03b4, d \u2217) is a no proxies-controlled \u03b5-equilibrium and implies,\nProposition 2. The no proxies control is fragile.\nUnlike the no proxies control, the equal opportunity control is continuous \u2013 it is both an upper hemicontinuous and a lower hemicontinuous correspondence. The Maximum Theorem implies that small deviations from perfect rationality do not significantly compromise the ideal-ness of continuous controls.\nTheorem 3. Any continuous control is not fragile.\nProof. See appendix.\nAnd what about the mistaken identity controls? It turns out they are fragile as well \u2013 but not as fragile as the no proxies control. Take the definition of being not fragile, remove \u201cand any \u03b4 > 0,\u201d replace \u2018\u2018\u2225d\u0302 \u2212 d\u0302\u2217\u22252 \u2264 \u03b4\u201d with \u201cd\u0302\u2217(i|lm) = 0 (= 1) \u21d2 d\u0302(i|lm) = 0 (= 1) for all groups i and likelihood values lm,\u201d and replace \u201c\u2225(ck,\u03b5, dk,\u03b5) \u2212 (ck, dk)\u22252 \u2264 \u03b4\u201d with \u201cdk(i|lm) = 0 (= 1) \u21d2 dk,\u03b5(i|lm) = 0 (= 1) for all groups i and likelihood values lm.\u201d This yields a definition for being almost not fragile that, depending on the application, could be quite reasonable. For example, when d\u0302\u2217(i) and dk(i) are associated with likelihood mixtures \u2013 as will be the case when k is a mistaken identity control, the above conditions imply that, at worst, d\u0302(i) differs from d\u0302\u2217(i) and dk,\u03b5(i) differs from dk(i) on i-applicants associated with a single likelihood value. It can be shown that mistaken identity controls are almost not fragile. The reason is that mistaken identity controls are, in an intuitive sense, almost continuous."
        },
        {
            "heading": "6 Conclusion",
            "text": "This paper recasts the Arrovian statistical discrimination model of CL as a model of algorithmic decision-making. The model\u2019s discriminatory and non-discriminatory equilibria serve as the basis for two natural algorithmic fairness goals: Bring gains to the discriminated group in any discriminatory equilibrium and ensure that the steady states under regulation are the non-discriminatory equilibria. I then search for a control that achieves both fairness goals.\nCL showed that the affirmative action control achieves the first but not the second fairness goal. I discover that the equal opportunity control, that requires the firm to equalize true positive rates across groups, achieves both fairness goals. A crucial step leading to that discovery is the realization that, with algorithmic decision-making, beliefs are contractible. This expands the set of feasible regulations of the firm to include algorithmic controls \u2013 like the equal opportunity control \u2013 that regulate the firm\u2019s decisions based on its machine learning-generated belief. I also find that a common method of regulating machine learning \u2013 making data color-blind \u2013 can make it impossible to achieve both fairness goals.\nThe equal opportunity control has attractive robustness properties. It only depends on the distribution of features and the firm\u2019s machine learning-generated belief, and not on the model\u2019s parameter values. Also, its ability to achieve both fairness goals can withstand deviations from perfect rationality. Finally, I evaluate a number of other controls in terms of their ability to achieve both fairness goals and their robustness properties. I find the mistaken identity controls to be promising."
        },
        {
            "heading": "7 Appendix",
            "text": "Proof of Lemma 2. It is obvious F \u2282 k(X,\u00b5RE, fRE). I now prove Sk(\u00b5RE, fRE) \u2282 F . Let d\u0302 \u2208 Sk(\u00b5RE, fRE). Define\nTP (d\u0302) := \u2211 x\u2208X d\u0302(w, x)\u00b5RE(w, x)fRE(w, x)\u2211\nx\u2208X \u00b5RE(w, x)fRE(w, x) =\n\u2211 x\u2208X d\u0302(b, x)\u00b5RE(b, x)fRE(b, x)\u2211\nx\u2208X \u00b5RE(b, x)fRE(b, x) .\nThat d\u0302 \u2208 Sk(\u00b5RE, fRE) means that the firm cannot be made strictly better off by swapping out d\u0302(i) with a different d(i) with the same true positive rate. Thus, for\neach i \u2208 I, {d\u0302(i, x)}x\u2208X is an element of\nargmax {dx}x\u2208X s.t. \u2211 x\u2208X dx\u00b5RE(i,x)fRE(i,x)\u2211 x\u2208X \u00b5RE(i,x)fRE(i,x) =TP (d\u0302) \u2211 x\u2208X dx\u00b5RE(i, x) [fRE(i, x)vq \u2212 (1\u2212 fRE(i, x))vu]\ns.t. dx \u2265 0 \u2200x \u2208 X dx \u2264 1 \u2200x \u2208 X.\nThe Kuhn-Tucker conditions imply there exists a \u03bb\u2217i \u2265 0 such that, for each x \u2208 X,\nd\u0302(i, x) =  0 if \u00b5RE(i,x)[fRE(i,x)vq\u2212(1\u2212fRE(i,x))vu]\u00b5RE(i,x)fRE(i,x)\u2211 x\u2032\u2208X \u00b5RE(i,x \u2032)fRE(i,x\u2032) < \u03bb\u2217i\n1 if \u00b5RE(i,x)[fRE(i,x)vq\u2212(1\u2212fRE(i,x))vu]\u00b5RE(i,x)fRE(i,x)\u2211 x\u2032\u2208X \u00b5RE(i,x \u2032)fRE(i,x\u2032) > \u03bb\u2217i .\nSimplifying the fraction appearing in the first order condition yields\n\u00b5RE(i, x) [fRE(i, x)vq \u2212 (1\u2212 fRE(i, x))vu] \u00b5RE(i,x)fRE(i,x)\u2211\nx\u2032\u2208X \u00b5RE(i,x \u2032)fRE(i,x\u2032) = \u2211 x\u2032\u2208X \u00b5RE(i, x \u2032)fRE(i, x \u2032) [ vq \u2212 1\u2212 fRE(i, x) fRE(i, x) vu ] =\n\u2211 x\u2032\u2208X \u00b5RE(i, x \u2032)fRE(i, x \u2032) [ vq \u2212 (1\u2212G(c(i))) G(c(i))l(x) vu ] .\nThis means there exists a likelihood value lmi , mi \u2208 {1, 2, . . . n}, such that\nd\u0302(i, x) = 0 if l(x) < lmi1 if l(x) > lmi . This implies that d\u0302(i) is a within-group decision policy associated with the likelihood mixture d\u0302(i|lmi)lmi\u22121 + (1 \u2212 d\u0302(i|lmi))lmi . With this characterization of d\u0302(i), we can express the shared true positive rate as\nTP (d\u0302) = \u2211 x\u2208X d\u0302(i, x)\u00b5RE(i, x)fRE(i, x)\u2211\nx\u2208X \u00b5RE(i, x)fRE(i, x)\n=\n\u2211 x\u2208X,l(x)=lmi\nd\u0302(i, x)\u00b5RE(i, x)fRE(i, x)\u2211 x\u2208X \u00b5RE(i, x)fRE(i, x) +\n\u2211 x\u2208X,l(x)>lmi\n\u00b5RE(i, x)fRE(i, x)\u2211 x\u2208X \u00b5RE(i, x)fRE(i, x)\n= \u2211\nx\u2208X,l(x)=lmi\nd\u0302(i, x)p(x|i, q) + \u2211\nx\u2208X,l(x)>lmi\np(x|i, q)\n= d\u0302(i|lmi) \u2211\nx\u2208X,l(x)=lmi\np(x|i, q) + \u2211\nm\u2208{mi+1,mi+2,...n} \u2211 x\u2208X,l(x)=lm p(x|i, q)\n= d\u0302(i|lmi) \u2211\nx\u2208X, p(xY|q) p(xY|u) =lmi\np(xY |q)p(x\u2212Y |i, xY)+\n\u2211 m\u2208{mi+1,mi+2,...n} \u2211 x\u2208X, p(xY|q)\np(xY|u) =lm\np(xY |q)p(x\u2212Y |i, xY)\n= d\u0302(i|lmi) \u2211\nxY\u2208XY , p(xY|q) p(xY|u) =lmi\n\u2211 x\u2212Y\u2208X\u2212Y p(xY |q)p(x\u2212Y |i, xY)+\n\u2211 m\u2208{mi+1,mi+2,...n} \u2211 xY\u2208XY ,\np(xY|q) p(xY|u) =lm\n\u2211 x\u2212Y\u2208X\u2212Y p(xY |q)p(x\u2212Y |i, xY)\n= d\u0302(i|lmi) \u2211\nxY\u2208XY , p(xY|q) p(xY|u) =lmi\np(xY |q) + \u2211\nm\u2208{mi+1,mi+2,...n} \u2211 xY\u2208XY ,\np(xY|q) p(xY|u) =lm\np(xY |q).\nIf mw \u2277 mb, then clearly the true positive rate of group b \u2277 the true positive rate of group w. So mw = mb. Now equality of true positive rates implies\nd\u0302(w|lmw) \u2211\nxY\u2208XY , p(xY|q) p(xY|u) =lmw\np(xY |q) = d\u0302(b|lmb) \u2211\nxY\u2208XY , p(xY|q) p(xY|u) =lmb\np(xY |q),\nwhich implies d\u0302(w|lmw) = d\u0302(b|lmb), which implies d\u0302 \u2208 F .\nProof of Theorem 3. Let k be a continuous control. Fix a game (X,\u03bbw, p, G, vq, vu, \u03c9).\nLet (c\u2217, d\u2217) be a discriminatory equilibrium. Suppose there exists a \u03b4 > 0 and a sequence ( d\u0302t, (\u00b5 \u2217 t , f \u2217 t ), \u03b5t > 0 ) t\u2208Z+ such that limt\u2192\u221e \u03b5t = 0 and, for all t, d\u0302t \u2208 Sk(\u00b5\u2217t , f \u2217t ), \u2225d\u0302t \u2212 d\u0302\u2217\u2225 \u2265 \u03b4 for all d\u0302\u2217 \u2208 Sk(\u00b5\u2217RE, f \u2217RE), and \u2225(\u00b5\u2217t , f \u2217t )\u2212 (\u00b5\u2217RE, f \u2217RE)\u2225 \u2264 \u03b5t. Since [0, 1]|I\u00d7X| is compact, (d\u0302t)t\u2208Z+ has a convergent subsequence. By picking such a subsequence and relabelling, it is without loss of generality to assume there exists a decision policy d\u0302 such that limt\u2192\u221e d\u0302t = d\u0302. Since \u2225d\u0302\u2212d\u0302\u2217\u2225 \u2265 \u03b4 for all d\u0302\u2217 \u2208 Sk(\u00b5\u2217RE, f \u2217RE), so d\u0302 /\u2208 Sk(\u00b5\u2217RE, f \u2217RE).\nSince UF (d, \u00b5, f) is continuous and k(X,\u00b5, f) is compact-valued and continuous in (\u00b5, f), by the Maximum Theorem, Sk(\u00b5, f) is upper hemicontinuous. So d\u0302 \u2208 Sk(\u00b5\u2217RE, f \u2217RE). Contradiction. This implies, for every \u03b4 > 0, there exists an\n\u03b5 > 0 such that, if \u2225(\u00b5\u2217, f \u2217)\u2212 (\u00b5\u2217RE, f \u2217RE)\u22252 \u2264 \u03b5, then for every d\u0302 \u2208 Sk(\u00b5\u2217, f \u2217), there exists a d\u0302\u2217 \u2208 Sk(\u00b5\u2217RE, f \u2217RE) such that \u2225d\u0302 \u2212 d\u0302\u2217\u2225 \u2264 \u03b4. Right now, the \u03b5 depends on (c\u2217, d\u2217). However, since the number of equivalence classes of equilibria is finite, \u03b5 can be chosen independently of (c\u2217, d\u2217). This proves that k satisfies the first property of not being fragile.\nClaim. Define cmax := maxx\u2208X WW (l(x)). If c \u2217(i) = argmaxc(i)\u2208R Ui(c(i), d \u2217(i)) for some d\u2217(i), then c\u2217(i) \u2208 [\u2212cmax, cmax]. Proof of Claim. By definition, c\u2217(i) = \u03c9 \u2211\n(i,x)\u2208I\u00d7X [p(x|i, q) \u2212 p(x|i, u)]d\u2217(i, x). The right hand side of the equation achieves its highest value, cmax, when d(i, x) = 1 (= 0) if l(x) > 1 (< 1), respectively. Likewise, it is achieves its lowest value, \u2212cmax, when d(i, x) = 0 (= 1) if l(x) > 1 (< 1), respectively.\nNow, suppose there exists a \u03b4 > 0 and a sequence ((ck,\u03b5t , dk,\u03b5t), (\u00b5k,\u03b5t , fk,\u03b5t), \u03b5t > 0)t\u2208Z+ such that limt\u2192\u221e \u03b5t = 0 and, for all t, (ck,\u03b5t , dk,\u03b5t) is a k-controlled \u03b5t-equilibrium supported by (\u00b5k,\u03b5t , fk,\u03b5t) and \u2225(ck,\u03b5t , dk,\u03b5t) \u2212 (c\u2217, d\u2217)\u2225 \u2265 \u03b4 for all k-controlled equilibria (c\u2217, d\u2217). By the claim, ck,\u03b5t \u2208 [\u2212cmax, cmax]2 for all t. So, just like before, ((ck,\u03b5t , dk,\u03b5t), (\u00b5k,\u03b5t , fk,\u03b5t))t\u2208Z+ has a convergent subsequence, and it is without loss of generality to assume there exists a (ck, dk) such that limt\u2192\u221e ((ck,\u03b5t , dk,\u03b5t), (\u00b5k,\u03b5t , fk,\u03b5t)) = ((ck, dk), (\u00b5RE,k, fRE,k)). Since \u2225(ck, dk) \u2212 (c\u2217, d\u2217)\u2225 \u2265 \u03b4 for all k-controlled equilibria (c\u2217, d\u2217), so (ck, dk) is not a k-controlled equilibrium. The Maximum Theorem now implies dk \u2208 Sk(\u00b5RE,k, fRE,k) and ck is a best response to dk. Thus, (ck, dk) is a k-controlled equilibrium. Contradiction. This proves that k satisfies the second property of not being fragile."
        }
    ],
    "title": "THE IMPACT OF EQUAL OPPORTUNITY ON STATISTICAL DISCRIMINATION",
    "year": 2023
}