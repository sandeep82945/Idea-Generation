{
    "abstractText": "In the last few years, we have witnessed the emergence of several knowledge graphs that explicitly describe research knowledge with the aim of enabling intelligent systems for supporting and accelerating the scientific process. These resources typically characterize a set of entities in this space (e.g., tasks, methods, evaluation techniques, proteins, chemicals), their relations, and the relevant actors (e.g., researchers, organizations) and documents (e.g., articles, books). However, they are usually very partial representations of the actual research knowledge and may miss several relevant facts. In this paper, we introduce SciCheck, a new triple classification approach for completing scientific statements in knowledge graphs. SciCheck was evaluated against nine alternative approaches on seven benchmarks, yielding excellent results. Finally, we provide a real-world use case and applied SciCheck to the Artificial Intelligence Knowledge Graph (AI-KG), a large-scale automatically-generated open knowledge graph including 1.2M statements extracted from the 333K most cited articles in the field of Artificial Intelligence, and generated a new version of this knowledge graph with 300K additional triples. INDEX TERMS Knowledge Graphs, Science of Science, Knowledge Graph Completion, Triple classification, Machine Learning, Semantic Web",
    "authors": [
        {
            "affiliations": [],
            "name": "AGUST\u00cdN BORREGO"
        },
        {
            "affiliations": [],
            "name": "DANILO DESS\u00cc"
        },
        {
            "affiliations": [],
            "name": "INMA HERN\u00c1NDEZ"
        },
        {
            "affiliations": [],
            "name": "FRANCESCO OSBORNE"
        },
        {
            "affiliations": [],
            "name": "DIEGO REFORGIATO RECUPERO"
        },
        {
            "affiliations": [],
            "name": "DAVID RUIZ"
        },
        {
            "affiliations": [],
            "name": "DAVIDE BUSCALDI"
        },
        {
            "affiliations": [],
            "name": "ENRICO MOTTA"
        }
    ],
    "id": "SP:b59fa42889b595f8a6bd8da89263eacd2dfbce9d",
    "references": [
        {
            "authors": [
                "H. Kitano"
            ],
            "title": "Artificial intelligence to win the nobel prize and beyond: Creating the engine for scientific discovery",
            "venue": "AI magazine, vol. 37, no. 1, pp. 39\u201349, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "D. Dess\u00ec",
                "F. Osborne",
                "D.R. Recupero",
                "D. Buscaldi",
                "E. Motta",
                "H. Sack"
            ],
            "title": "AI-KG: an automatically generated knowledge graph of artificial intelligence",
            "venue": "ISWC 2020, vol. 12507. Springer, 2020, pp. 127\u2013143. [Online]. Available: https://doi.org/10.1007/978-3-030-62466-8_9",
            "year": 2020
        },
        {
            "authors": [
                "R. d. Haan",
                "I. Tiddi",
                "W. Beek"
            ],
            "title": "Discovering research hypotheses in social science using knowledge graph embeddings",
            "venue": "European Semantic Web Conference. Springer, 2021, pp. 477\u2013494.",
            "year": 2021
        },
        {
            "authors": [
                "M.Y. Jaradeh",
                "A. Oelen",
                "K.E. Farfar",
                "M. Prinz",
                "J. D\u2019Souza",
                "G. Kismih\u00f3k",
                "M. Stocker",
                "S. Auer"
            ],
            "title": "Open research knowledge graph: Next generation infrastructure for semantic scholarly knowledge",
            "venue": "Proceedings of the 10th International Conference on Knowledge Capture, 2019, pp. 243\u2013 246.",
            "year": 2019
        },
        {
            "authors": [
                "A.G. Nuzzolese",
                "A.L. Gentile",
                "V. Presutti",
                "A. Gangemi"
            ],
            "title": "Semantic web conference ontology-a refactoring solution",
            "venue": "European Semantic Web Conference. Springer, 2016, pp. 84\u201387.",
            "year": 2016
        },
        {
            "authors": [
                "D. Ayala",
                "A. Borrego",
                "I. Hern\u00e1ndez",
                "D. Ruiz"
            ],
            "title": "A neural network for semantic labelling of structured information",
            "venue": "Expert Syst. Appl., vol. 143, 2020. [Online]. Available: https://doi.org/10.1016/j.eswa.2019.113053",
            "year": 2020
        },
        {
            "authors": [
                "F. Hoppe",
                "D. Dess\u00ec",
                "H. Sack"
            ],
            "title": "Deep learning meets knowledge graphs for scholarly data classification",
            "venue": "Companion proceedings of the web conference 2021, 2021, pp. 417\u2013421.",
            "year": 2021
        },
        {
            "authors": [
                "F. Belleau",
                "M.-A. Nolin",
                "N. Tourigny",
                "P. Rigault",
                "J. Morissette"
            ],
            "title": "Bio2rdf: towards a mashup to build bioinformatics knowledge systems",
            "venue": "Journal of biomedical informatics, vol. 41, no. 5, pp. 706\u2013716, 2008.",
            "year": 2008
        },
        {
            "authors": [
                "D. Shotton"
            ],
            "title": "Semantic publishing: the coming revolution in scientific journal publishing",
            "venue": "Learned Publishing, vol. 22, no. 2, pp. 85\u201394, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "A. Kelley",
                "D. Garijo"
            ],
            "title": "A framework for creating knowledge graphs of scientific software metadata",
            "venue": "Quantitative Science Studies, pp. 1\u201337, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "K. Wolstencroft",
                "R. Haines",
                "D. Fellows",
                "A. Williams",
                "D. Withers",
                "S. Owen",
                "S. Soiland-Reyes",
                "I. Dunlop",
                "A. Nenadic",
                "P. Fisher"
            ],
            "title": "The taverna workflow suite: designing and executing workflows of web services on the desktop, web or in the cloud",
            "venue": "Nucleic acids research, vol. 41, no. W1, pp. W557\u2013W561, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "P. Groth",
                "A. Gibson",
                "J. Velterop"
            ],
            "title": "The anatomy of a nanopublication",
            "venue": "Information Services & Use, vol. 30, no. 1-2, pp. 51\u201356, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "T. Kuhn",
                "C. Chichester",
                "M. Krauthammer",
                "N. Queralt-Rosinach",
                "R. Verborgh",
                "G. Giannakopoulos",
                "A.-C.N. Ngomo",
                "R. Viglianti",
                "M. Dumontier"
            ],
            "title": "Decentralized provenance-aware publishing with nanopublications",
            "venue": "PeerJ Computer Science, vol. 2, p. e78, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "J. Schneider",
                "P. Ciccarese",
                "T. Clark",
                "R.D. Boyce"
            ],
            "title": "Using the micropublications ontology and the open annotation data model to represent evidence within a drug-drug interaction knowledge base",
            "venue": "LISC@ISWC, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "A.A. Salatino",
                "T. Thanapalasingam",
                "A. Mannocci",
                "F. Osborne",
                "E. Motta"
            ],
            "title": "The computer science ontology: a large-scale taxonomy of research areas",
            "venue": "International Semantic Web Conference. Springer, 2018, pp. 187\u2013205.",
            "year": 2018
        },
        {
            "authors": [
                "S. Peroni",
                "D. Shotton"
            ],
            "title": "The spar ontologies",
            "venue": "International Semantic Web Conference. Springer, 2018, pp. 119\u2013136.",
            "year": 2018
        },
        {
            "authors": [
                "A. Hogan",
                "E. Blomqvist",
                "M. Cochez",
                "C. d\u2019Amato",
                "G.D. Melo",
                "C. Gutierrez",
                "S. Kirrane",
                "J.E.L. Gayo",
                "R. Navigli",
                "S. Neumaier"
            ],
            "title": "Knowledge graphs",
            "venue": "ACM Computing Surveys (CSUR), vol. 54, no. 4, pp. 1\u201337, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S. Vahdati",
                "N. Arndt",
                "S. Auer",
                "C. Lange"
            ],
            "title": "Openresearch: collaborative management of scholarly communication metadata",
            "venue": "European Knowledge Acquisition Workshop. Springer, 2016, pp. 778\u2013793.",
            "year": 2016
        },
        {
            "authors": [
                "O. Bodenreider"
            ],
            "title": "The unified medical language system (umls): integrating biomedical terminology",
            "venue": "Nucleic acids research, vol. 32, no. suppl_1, pp. D267\u2013D270, 2004.",
            "year": 2004
        },
        {
            "authors": [
                "A. Salatino",
                "F. Osborne",
                "E. Motta"
            ],
            "title": "Researchflow: Understanding the knowledge flow between academia and industry",
            "venue": "Knowledge Engineering and Knowledge Management \u2013 22nd International Conference, EKAW 2020, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A. Rossanez",
                "J.C. dos Reis",
                "R. da Silva Torres"
            ],
            "title": "Representing scientific literature evolution via temporal knowledge graphs.",
            "venue": "in MEPDaW@ ISWC,",
            "year": 2020
        },
        {
            "authors": [
                "D. Ayala",
                "A. Borrego",
                "I. Hern\u00e1ndez",
                "C.R. Rivero",
                "D. Ruiz"
            ],
            "title": "AYNEC: all you need for evaluating completion techniques in knowledge graphs",
            "venue": "ESWC 2019, vol. 11503. Springer, 2019, pp. 397\u2013411. [Online]. Available: https://doi.org/10.1007/978-3-030-21348-0_26",
            "year": 2019
        },
        {
            "authors": [
                "Y. Dai",
                "S. Wang",
                "N.N. Xiong",
                "W. Guo"
            ],
            "title": "A survey on knowledge graph embedding: Approaches, applications and benchmarks",
            "venue": "Electronics, vol. 9, no. 5, p. 750, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A. Bordes",
                "N. Usunier",
                "A. Garc\u00eda-Dur\u00e1n",
                "J. Weston",
                "O. Yakhnenko"
            ],
            "title": "Translating embeddings for modeling multi-relational data",
            "venue": "NIPS, 2013, pp. 2787\u20132795.",
            "year": 2013
        },
        {
            "authors": [
                "Z. Sun",
                "Z.-H. Deng",
                "J.-Y. Nie",
                "J. Tang"
            ],
            "title": "Factorizing yago: scalable machine learning for linked data",
            "venue": "ICLR, 2019, pp. 271\u2013280.",
            "year": 2019
        },
        {
            "authors": [
                "T. Trouillon",
                "J. Welbl",
                "S. Riedel",
                "\u00c9. Gaussier",
                "G. Bouchard"
            ],
            "title": "Complex embeddings for simple link prediction",
            "venue": "ICML, vol. 48, 2016, pp. 2071\u2013 2080.",
            "year": 2016
        },
        {
            "authors": [
                "A. Borrego",
                "D. Ayala",
                "I. Hern\u00e1ndez",
                "C.R. Rivero",
                "D. Ruiz"
            ],
            "title": "CAFE: Knowledge graph completion using neighborhood-aware features",
            "venue": "Engineering Applications of Artificial Intelligence, vol. 103, p. 104302, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Shen",
                "D. Wen",
                "Y. Li",
                "N. Du",
                "H.-t. Zheng",
                "M. Yang"
            ],
            "title": "Pathbased attribute-aware representation learning for relation prediction",
            "venue": "Proceedings of the 2019 SIAM International Conference on Data Mining. SIAM, 2019, pp. 639\u2013647.",
            "year": 2019
        },
        {
            "authors": [
                "J. Zhou",
                "G. Cui",
                "Z. Zhang",
                "C. Yang",
                "Z. Liu",
                "L. Wang",
                "C. Li",
                "M. Sun"
            ],
            "title": "Graph neural networks: A review of methods and applications",
            "venue": "CoRR, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Q. Wang",
                "Z. Mao",
                "B. Wang",
                "L. Guo"
            ],
            "title": "Knowledge graph embedding: A survey of approaches and applications",
            "venue": "IEEE TKDE, vol. 29, no. 12, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "S.M. Kazemi",
                "D. Poole"
            ],
            "title": "Simple embedding for link prediction in knowledge graphs",
            "venue": "Advances in Neural Information Processing Systems, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Y. Lin",
                "Z. Liu",
                "M. Sun",
                "Y. Liu",
                "X. Zhu"
            ],
            "title": "Learning entity and relation embeddings for knowledge graph completion.",
            "venue": "in AAAI,",
            "year": 2015
        },
        {
            "authors": [
                "H. Liu",
                "Y. Wu",
                "Y. Yang"
            ],
            "title": "Analogical inference for multi-relational embeddings",
            "venue": "ICML-Volume 70, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "R. Socher",
                "D. Chen",
                "C.D. Manning",
                "A. Ng"
            ],
            "title": "Reasoning with neural tensor networks for knowledge base completion",
            "venue": "Advances in NIPS, 2013, pp. 926\u2013934.",
            "year": 2013
        },
        {
            "authors": [
                "T. Mitchell",
                "W. Cohen",
                "E. Hruschka",
                "P. Talukdar",
                "B. Yang",
                "J. Betteridge",
                "A. Carlson",
                "B. Dalvi",
                "M. Gardner",
                "B. Kisiel",
                "J. Krishnamurthy",
                "N. Lao",
                "K. Mazaitis",
                "T. Mohamed",
                "N. Nakashole",
                "E. Platanios",
                "A. Ritter",
                "M. Samadi",
                "B. Settles",
                "R. Wang",
                "D. Wijaya",
                "A. Gupta",
                "X. Chen",
                "A. Saparov",
                "M. Greaves",
                "J. Welling"
            ],
            "title": "Never-ending learning",
            "venue": "Commun. ACM, vol. 61, no. 5, pp. 103\u2013115, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "T. Mikolov",
                "I. Sutskever",
                "K. Chen",
                "G. Corrado",
                "J. Dean"
            ],
            "title": "Distributed representations of words and phrases and their compositionality",
            "venue": "Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2, ser. NIPS\u201913, 2013, pp. 3111\u20133119. [Online]. Available: http://dl.acm.org/citation.cfm?id=2999792.2999959",
            "year": 2013
        },
        {
            "authors": [
                "Y. Liu",
                "M. Ott",
                "N. Goyal",
                "J. Du",
                "M. Joshi",
                "D. Chen",
                "O. Levy",
                "M. Lewis",
                "L. Zettlemoyer",
                "V. Stoyanov"
            ],
            "title": "Roberta: A robustly optimized BERT pretraining approach",
            "venue": "CoRR, vol. abs/1907.11692, 2019. [Online]. Available: http://arxiv.org/abs/1907.11692",
            "year": 1907
        },
        {
            "authors": [
                "N. Lao",
                "W.W. Cohen"
            ],
            "title": "Relational retrieval using a combination of path-constrained random walks",
            "venue": "Machine learning, vol. 81, no. 1, pp. 53\u2013 67, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "M. Gardner",
                "T. Mitchell"
            ],
            "title": "Efficient and expressive knowledge base completion using subgraph feature extraction",
            "venue": "EMNLP. The Association for Computational Linguistics, 2015, pp. 1488\u20131498.",
            "year": 2015
        },
        {
            "authors": [
                "S. Mazumder",
                "B. Liu"
            ],
            "title": "Context-aware path ranking for knowledge base completion",
            "venue": "IJCAI. AAAI Press, 2017, pp. 1195\u20131201.",
            "year": 2017
        },
        {
            "authors": [
                "W. Xiong",
                "T. Hoang",
                "W.Y. Wang"
            ],
            "title": "Deeppath: A reinforcement learning method for knowledge graph reasoning",
            "venue": "EMNLP, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "T. Hamaguchi",
                "H. Oiwa",
                "M. Shimbo",
                "Y. Matsumoto"
            ],
            "title": "Knowledge transfer for out-of-knowledge-base entities : A graph neural network approach",
            "venue": "Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17, 2017, pp. 1802\u20131808. [Online]. Available: https://doi.org/10.24963/ijcai.2017/250",
            "year": 2017
        },
        {
            "authors": [
                "C. Shang",
                "Y. Tang",
                "J. Huang",
                "J. Bi",
                "X. He",
                "B. Zhou"
            ],
            "title": "Endto-end structure-aware convolutional networks for knowledge base completion",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, 2019, pp. 3060\u20133067. [Online]. Available: https://ojs.aaai.org/index.php/AAAI/article/view/4164",
            "year": 2019
        },
        {
            "authors": [
                "P. Veli\u010dkovi\u0107",
                "G. Cucurull",
                "A. Casanova",
                "A. Romero",
                "P. Li\u00f2",
                "Y. Bengio"
            ],
            "title": "Graph attention networks",
            "venue": "International Conference on Learning Representations, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Z. Wang",
                "Z. Ren",
                "C. He",
                "P. Zhang",
                "Y. Hu"
            ],
            "title": "Robust embedding with multi-level structures for link prediction.",
            "venue": "in IJCAI,",
            "year": 2019
        },
        {
            "authors": [
                "M.Y. Jaradeh",
                "K. Singh",
                "M. Stocker",
                "S. Auer"
            ],
            "title": "Triple classification for scholarly knowledge graph completion",
            "venue": "Proceedings of the 11th on Knowledge Capture Conference, ser. K-CAP \u201921, New York, NY, USA, 2021, p. 225\u2013232. [Online]. Available: https://doi.org/10.1145/3460210. 3493582",
            "year": 2021
        },
        {
            "authors": [
                "M. Nayyeri",
                "G.M. Cil",
                "S. Vahdati",
                "F. Osborne",
                "M. Rahman",
                "S. Angioni",
                "A. Salatino",
                "D.R. Recupero",
                "N. Vassilyeva",
                "E. Motta",
                "J. Lehmann"
            ],
            "title": "Trans4e: Link prediction on scholarly knowledge graphs",
            "venue": "Neurocomputing, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "M. Nayyeri",
                "S. Vahdati",
                "X. Zhou",
                "H.S. Yazdi",
                "J. Lehmann"
            ],
            "title": "Embedding-based recommendations on scholarly knowledge graphs",
            "venue": "European Semantic Web Conference. Springer, 2020, pp. 255\u2013270.",
            "year": 2020
        },
        {
            "authors": [
                "M. Nayyeri",
                "G.M. Cil",
                "S. Vahdati",
                "F. Osborne",
                "A. Kravchenko",
                "S. Angioni",
                "A. Salatino",
                "D.R. Recupero",
                "E. Motta",
                "J. Lehmann"
            ],
            "title": "Link prediction of weighted triples for knowledge graph completion within the scholarly domain",
            "venue": "IEEE Access, vol. 9, pp. 116 002\u2013116 014, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "K. Bollacker",
                "C. Evans",
                "P. Paritosh",
                "T. Sturge",
                "J. Taylor"
            ],
            "title": "Freebase: a collaboratively created graph database for structuring human knowledge",
            "venue": "Proceedings of the 2008 ACM SIGMOD international conference on Management of data. AcM, 2008, pp. 1247\u20131250.",
            "year": 2008
        },
        {
            "authors": [
                "N. Heist",
                "P. Haase"
            ],
            "title": "Flexible and extensible competency management with knowledge graphs",
            "venue": "ISWC (Posters/Demos/Industry), vol. 2980. CEUR-WS.org, 2021. [Online]. Available: http://ceur-ws.org/Vol-2980/ paper412.pdf",
            "year": 2021
        },
        {
            "authors": [
                "G. Ji",
                "S. He",
                "L. Xu",
                "K. Liu",
                "J. Zhao"
            ],
            "title": "Knowledge graph embedding via dynamic mapping matrix",
            "venue": "ACL (1). The Association for Computer Linguistics, 2015, pp. 687\u2013696.",
            "year": 2015
        },
        {
            "authors": [
                "I. Bansal",
                "S. Tiwari",
                "C.R. Rivero"
            ],
            "title": "The impact of negative triple generation strategies and anomalies on knowledge graph completion",
            "venue": "CIKM \u201920: The 29th ACM International Conference on Information and Knowledge Management. ACM, 2020, pp. 45\u201354.",
            "year": 2020
        },
        {
            "authors": [
                "T. Alahakoon",
                "R. Tripathi",
                "N. Kourtellis",
                "R. Simha",
                "A. Iamnitchi"
            ],
            "title": "Kpath centrality: A new centrality measure in social networks",
            "venue": "Proceedings of the 4th Workshop on Social Network Systems, SNS\u201911, 04 2011.",
            "year": 2011
        },
        {
            "authors": [
                "L.A. Adamic",
                "E. Adar"
            ],
            "title": "Friends and neighbors on the web",
            "venue": "Soc. Networks, vol. 25, no. 3, pp. 211\u2013230, 2003.",
            "year": 2003
        },
        {
            "authors": [
                "D. Dess\u00ec",
                "D.R. Recupero",
                "H. Sack"
            ],
            "title": "An assessment of deep learning models and word embeddings for toxicity detection within online textual comments",
            "venue": "Electronics, vol. 10, no. 7, p. 779, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Z. Wang",
                "J. Zhang",
                "J. Feng",
                "Z. Chen"
            ],
            "title": "Knowledge graph embedding by translating on hyperplanes.",
            "venue": "in AAAI,",
            "year": 2014
        },
        {
            "authors": [
                "X. Han",
                "S. Cao",
                "X. Lv",
                "Y. Lin",
                "Z. Liu",
                "M. Sun",
                "J. Li"
            ],
            "title": "Openke: An open toolkit for knowledge embedding",
            "venue": "EMNLP, 2018, pp. 139\u2013144.",
            "year": 2018
        },
        {
            "authors": [
                "A. Borrego",
                "D. Ayala",
                "I. Hern\u00e1ndez",
                "C.R. Rivero",
                "D. Ruiz"
            ],
            "title": "Generating rules to filter candidate triples for their correctness checking by knowledge graph completion techniques",
            "venue": "K-CAP, 2019, pp. 115\u2013122.",
            "year": 2019
        },
        {
            "authors": [
                "A.A. Salatino",
                "T. Thanapalasingam",
                "A. Mannocci",
                "A. Birukou",
                "F. Osborne",
                "E. Motta"
            ],
            "title": "The computer science ontology: A comprehensive automatically-generated taxonomy of research areas",
            "venue": "Data Intell., vol. 2, no. 3, pp. 379\u2013416, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A. Bordes",
                "X. Glorot",
                "J. Weston",
                "Y. Bengio"
            ],
            "title": "A semantic matching energy function for learning with multi-relational data - application to word-sense disambiguation",
            "venue": "Machine Learning, vol. 94, no. 2, pp. 233\u2013 259, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "T. Dettmers",
                "P. Minervini",
                "P. Stenetorp",
                "S. Riedel"
            ],
            "title": "Convolutional 2D knowledge graph embeddings",
            "venue": "AAAI, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "P. Pezeshkpour",
                "Y. Tian",
                "S. Singh"
            ],
            "title": "Revisiting evaluation of knowledge base completion models",
            "venue": "AKBC, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "M. Speranskaya",
                "M. Schmitt",
                "B. Roth"
            ],
            "title": "Ranking vs. classifying: Measuring knowledge base completion quality",
            "venue": "AKBC, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "E.R. DeLong",
                "D.M. DeLong",
                "D.L. Clarke-Pearson"
            ],
            "title": "Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach",
            "venue": "Biometrics, pp. 837\u2013845, 1988.",
            "year": 1988
        },
        {
            "authors": [
                "X. Li",
                "M. Daoutis"
            ],
            "title": "Unsupervised key-phrase extraction and clustering for classification scheme in scientific publications",
            "venue": "arXiv preprint arXiv:2101.09990, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "F. Hoppe",
                "D. Dess\u00ec",
                "H. Sack"
            ],
            "title": "Understanding class representations: An intrinsic evaluation of zero-shot text classification",
            "venue": "Workshop on Deep Learning for Knowledge Graphs (DL4KG@ ISWC2021), ser. CEUR Workshop Proceedings, vol. 3034, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "D. Dess\u00ec",
                "F. Osborne",
                "D.R. Recupero",
                "D. Buscaldi",
                "E. Motta"
            ],
            "title": "Generating knowledge graphs by employing natural language processing and machine learning techniques within the scholarly domain",
            "venue": "Future Generation Computer Systems, vol. 116, pp. 253\u2013264, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "D. Wadden",
                "U. Wennberg",
                "Y. Luan",
                "H. Hajishirzi"
            ],
            "title": "Entity, relation, and event extraction with contextualized span representations",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019, 2019, pp. 5783\u20135788. [Online]. Available: https://doi.org/10.18653/v1/D19-1585",
            "year": 2019
        },
        {
            "authors": [
                "A.A. Salatino",
                "F. Osborne",
                "T. Thanapalasingam",
                "E. Motta"
            ],
            "title": "The CSO classifier: Ontology-driven detection of research topics in scholarly articles",
            "venue": "Digital Libraries for Open Knowledge, A. Doucet, A. Isaac, K. Golub, T. Aalberg, and A. Jatowt, Eds. Cham: Springer International Publishing, 2019, pp. 296\u2013311.",
            "year": 2019
        },
        {
            "authors": [
                "G. Angeli",
                "M.J.J. Premkumar",
                "C.D. Manning"
            ],
            "title": "Leveraging linguistic structure for open domain information extraction",
            "venue": "Proceedings of the 53rd Annual Meeting of the ACL and the 7th IJCNLP, vol. 1, 2015, pp. 344\u2013354.",
            "year": 2015
        },
        {
            "authors": [
                "K. Toutanova",
                "D. Klein",
                "C.D. Manning",
                "Y. Singer"
            ],
            "title": "Feature-rich partof-speech tagging with a cyclic dependency network",
            "venue": "Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, 2003, pp. 252\u2013 259.",
            "year": 2003
        }
    ],
    "sections": [
        {
            "text": "INDEX TERMS Knowledge Graphs, Science of Science, Knowledge Graph Completion, Triple classification, Machine Learning, Semantic Web\nI. INTRODUCTION THE rise of Open Science and the steady growth of thenumber of research publications, datasets, and other materials on the web is changing the way research outcomes are shared and explored, and is posing new challenges and opportunities. This large mass of open research outcomes has the potential of supporting a new generation of intelligent systems for actively supporting, automatizing, and accelerating the scientific effort [1].\nOne of the main challenges in this space is to generate a semantically rich, interlinked, and machine readable description of the research knowledge that could support more sophisticated services for analysing the scientific literature, forecasting research dynamics, generating scientific hypothesis, identifying key insights, informing funding decision, confirming claims in news, automatically running experi-\nments, and so on [2, 3, 4]. The Semantic Web community has been working for several years on semantically rich representations of research outcomes by creating bibliographic repositories in the Linked Data Cloud [5], annotating existing knowledge bases [6, 7], generating knowledge bases of biological data [8], advocating the Semantic Publishing paradigm [9], formalising research workflows [10, 11], implementing systems for managing nano-publications [12, 13], micropublications [14] and developing ontologies to describe scholarly data, e.g., BIBO1, CSO [15], or SPAR [16]2.\nIn the last few years, we saw the emergence of several knowledge graphs (KGs) explicitly representing research\n1BIBO - http://bibliontology.com 2SPAR - http://www.sparontologies.net/\nVOLUME 4, 2022 1\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nA. Borrego et al.: Completing Scientific Facts in Knowledge Graphs of Research Concepts\nknowledge. These resources typically describe a set of entities in this space (e.g., tasks, methods, evaluation techniques, datasets, proteins, chemicals), their relations, and the relevant actors (e.g., authors, organizations) and documents (e.g., articles, books) [17, 18]. Some of these solutions are crowdsourced (e.g., ORKG [4], UMLS [19], Nanopublications [13]), while others are automatically generated from the text and metadata of research articles (e.g., AI-KG [2], CSO [20], TKG [21]).\nAs many other KGs, those that describe research concepts suffer from incompleteness. They are typically very partial representations of the actual research knowledge and may lack several relevant facts, that were not identified by information extraction approaches or human experts. The issue of incompleteness in knowledge graphs is usually addressed by means of link prediction or triple classification techniques [22, 23], which have proved to yield good results in several domains [17].\nThese methods typically use KG Embedding models (e.g. TransE [24], RotatE [25], ComplEx [26]), path-based features [27, 28], or Graph Neural Networks [29].\nHowever, typical methods for knowledge graph completion under-perform on KGs of research concepts, as detailed in Section IV. In particular, they suffer from low precision, which is not acceptable in the scientific domain.\nTo address the above issue, in this paper, we introduce SciCheck, a new approach for completing scientific facts in knowledge graphs of research concepts. SciCheck is built on top of the CAFE approach [27] and introduces several new features and heuristics for the scholarly domain.\nWe evaluated SciCheck on two new benchmarks extracted from AI-KG (AIKG-1M and AIKG-500) and five wellknown general benchmarks for triple classification (FB13, WN11, WN18, WN18RR, and NELL). The evaluation shows that SciCheck significantly outperforms nine alternative approaches in terms of precision, which we consider key for reliably extending knowledge graphs of research concepts, while still obtaining good values of recall. All the resources used for evaluation are available online3.\nAs use case, we used SciCheck for enriching the Artificial Intelligence Knowledge Graph (AI-KG)4 [2], a largescale automatically-generated open KG including 14M RDF triples and 1.2M reified statements extracted from the 333K most cited articles in the field of AI. We also made available to the scientific community a new version of AI-KG (version 1.2) with 300K additional triples5 that we obtained thanks to SciCheck.\nIn summary, the main contributions of our work are the following:\n\u2022 We propose SciCheck, a new triple classification technique that uses a variety of features to complete KGs of research concepts with a high precision.\n3Evaluation data - https://zenodo.org/record/5764114 4AI-KG - http://w3id.org/aikg 5AI-KG 1.2 - https://zenodo.org/record/5769957\n\u2022 We compare SciCheck with nine alternative KG completion methods on AIKG-1M, AIKG-500, FB13, WN11, WN18, WN18RR, and NELL, showing that it obtains excellent results. \u2022 We release two new datasets for KG completion: AIKG1M, including 1M triples from AI-KG, and AIKG-500, including 500 manually annotated statements. \u2022 We provide a real-world use case and apply SciCheck on AI-KG and use it to generate a new version of AI-KG containing 300K additional triples.\nThe remainder of this paper is organized as follows. Section II describes the related work. Section III describes SciCheck in detail, and Section IV discusses the evaluation results. Section V describes AI-KG and how SciCheck was applied to it in order to extend it. Finally, Section VI concludes the paper and presents future directions of research."
        },
        {
            "heading": "II. RELATED WORK",
            "text": "The majority of related proposals in this field are nowadays based on embedding models, i.e., producing a translation from the entities and relations in the graph into vectors that preserve their semantics. In this area, experts usually distinguish between knowledge graph embeddings, and language models.\nKG embeddings [23, 30] learn embedded representations of KGs entities and relations, performing different transformations in an embedding space [24, 25, 26, 31, 32, 33, 34]. The resulting embedding space is subsequently used to evaluate the likelihood of a candidate triple to be correct or incorrect, since entities that are supposed to be related by means of a certain relation are expected to be closer to each other in the embedding space. They have also been recently used for assessing research hypotheses, yielding promising results [3].\nWhile they provide good results in general, all of the former proposals suffer from a performance drawback: due to the way in which the embedded representations are obtained, they need to be recomputed whenever new triples are added to the KG, which is a relatively frequent event [35]. Language models are based on word embeddings (such as Word2Vec [36] or BERT [37]), that represent the semantic information encoded in the text of nodes and relations, and are therefore less affected by the introduction of new triples. These models are able to deal with text ambiguity and produce contextualized embeddings.\nEmbedding-based approaches are able to exploit features from both the entities and relations in the graph, but they usually explore the immediate neighborhood of entities, disregarding longer paths in the graph that could also provide some interesting features. Therefore, other approaches are proposed to leverage these longer paths: path-based, and graph neural network-based approaches.\nPath-based techniques exploit the highly relational nature of KGs to learn how to predict new relations between entities. Regarding this approach, Lao and Cohen [38] introduced the Path Ranking Algorithm (PRA), a two-step process to find"
        },
        {
            "heading": "2 VOLUME 4, 2022",
            "text": "This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nA. Borrego et al.: Completing Scientific Facts in Knowledge Graphs of Research Concepts\nwhich paths may be useful to predict a certain relation. An evolution of PRA named Subgraph Feature Extraction (SFE) by Gardner and Mitchell [39] achieves better performance than PRA and produces more expressive results. Mazumder et al. [40] propose a random walk-based approach using neighborhood-guided path finding, where semantic similarities between entities are computed by applying a Word2Vecbased embedding model on the names of the entities. Reinforcement learning has also been used to find valuable paths that can help to successfully complete a KG [41]. Shen et al. [28] propose combining the benefits of embeddings and path-based approaches, by computing embeddings of the entities and relations, and then combining these embeddings in the forms of paths. Unfortunately, due to the non-deterministic way in which these paths are computed, they may miss relevant information by mere chance. More recently, Borrego et al. [27] proposed CAFE, a deterministic approach to exploit the highly connected nature of KGs that does not rely on random paths.\nThere are also a number of proposals that leverage the use of Graph Neural Networks (GNNs) to exploit not just a limited set of paths, but the entire structure of the graph. Some of them are based on traditional embedding models [42, 43]. The most recent proposals are based on Graph Attention Networks [44, 45, 46]. An extended survey on GNNs and their applications has been carried out by Zhou et al. [29]. The main drawback of this approach is the amount of computational resources it requires, making them unappealing to deal with real-world KGs, such as those about research concepts, which are our focus.\nThe particularities of research concepts make the former proposals generally unable to complete these KGs with a high precision. They usually contain a large number of ambiguous and synonym terms, due to a lack of standardization in the vocabulary used in different research works [47]. Also, they often contain highly categorical relations [48], i.e., relations in which the number of possible head entities is significantly higher than the number of possible tail entities. Therefore, some language models have been proposed based on different types of KG embeddings to deal specifically with this type of graphs [48, 49, 50]. Some recent techniques, such as exBERT [47] exploit contextualized language models rather than KG embeddings.\nDifferently from the previous proposals, our approach is not based solely on KG embeddings, language models, or random paths, but on a combination of features that leverages the strengths of embeddings and deterministic path features, and does not suffer from the high hardware requirements of GNNs.\nSpecifically, SciCheck makes use of deterministic pathbased and embedding-based features to solve the problem of triple classification in general-domain knowledge graphs, and more specifically, in scholarly KGs. In addition, according to our experimental results, SciCheck is also able to outperform the other proposals in terms of precision, which is essential to complete KGs of research concepts, while still achieving a\nfair recall."
        },
        {
            "heading": "III. SciCheck",
            "text": "SciCheck6 is a novel approach for triple classification designed to complete scientific statements in a knowledge graph. It is built on top of the CAFE approach [27] by incorporting a new set of features and heuristics tailored to capture scientific knowledge. SciCheck takes an entire KG in the form of triples as input, and produces one neuralbased classifier for each relation in the KG as output. Specifically, given a relationship r, SciCheck generates a model fr : (h, r, t) \u2192 s, that assigns a confidence score s in the range [0, 1] to any arbitrary triple < h, r, t > to solve a binary classification task (\u201cis the triple correct or not?\u201d). To feed the model, triples are converted into a numerical vector representation using ad-hoc features and contextual embedding representations. SciCheck can operate on any KG and focuses on optimizing precision, to ensure that the knowledge deemed correct is trustworthy.\nIn the following subsections, we describe all the relevant steps for the workflow of SciCheck. Fig. 1 displays a small KG that will be used to provide specific examples for some steps.\nLOADING THE KG The first step of SciCheck takes as an input a set of triples from the target KG. Triples are transformed into a graph structure. Due to the generally large number of entities that comprise a KG and the high volume of read operations that are used in the following steps, the KG is stored in the form of adjacency hashmaps, which also preserve the types of the different relations.\nGENERATING NEGATIVE EXAMPLES Knowledge Graphs only contain positive knowledge, i.e., triples for which their heads and tails are known to be related by means of a relationship. However, in order to train a classifier, negative triples are also needed. To do this, SciCheck follows the same approach as many other related techniques [27, 28, 38, 51, 52, 53] and generates negative triples by corrupting a positive triple < h, r, t > and replacing t with t\u2032, in such a way that < h, r, t\u2032 > is not part of the original graph.\nIn order to produce more realistic negative triples, we randomly pick t\u2032 such that its type is in the range of the\n6https://github.com/agu-borrego/SciCheck\nVOLUME 4, 2022 3\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nA. Borrego et al.: Completing Scientific Facts in Knowledge Graphs of Research Concepts\nrelation r [54]. This can either be done automatically by using entities which appear as tail of that relation in the set of positive triples, or by using ontological information if it is available.\nCONVERTING TRIPLES INTO FEATURE VECTORS After both positive and negative examples are included in the graph, all triples are converted into labeled feature vectors that are provided to the neural classifier for both training and testing. For this purpose, SciCheck uses an extensible set of neighbourhood-aware features specifically tailored to scholarly information, which represent the neighbourhoods of the two entities of a triple in a variety of ways. The neighbourhood of an entity is considered to be the set of all other entities that can be reached from it using a certain number of hops in the KG. This number of hops is called the neighbourhood\u2019s \u201cradius\u201d. Fig. 1 shows a KG that will be used as an example in the discussion of the features.\nEach triple is evaluated by all features. The values associated to the triple for each feature form the triple feature vector.\nEach feature can also depend on a number of parameters, such as a maximum neighbourhood radius. These features, and their rationales, are as follows:\n\u2022 f1: Number of entities in the neighbourhood of radius r of the head and the tail of a triple. For example, in Fig. 1, three entities can be reached in total using up to two hops from link_prediction, namely, neural_network, dbpedia, and triple_classification. \u2022 f2: Index of N-path centrality [55] of the head and tail of a triple. This feature assesses how well-connected an entity is to the rest of the graph in relative terms. It is defined as follows: for every vertex v of a graph G = (V,E), the n-path centrality Ck(v) is defined as the sum, over all possible source nodes s, of the probability that a message originating from s goes through v, assuming that the message traversals are only going along random simple paths of at most k edges. \u2022 f3: Cardinality of the intersection of the neighbourhoods of radius r of the head and tail of the triple. This feature measures the raw amount of common entities in the vicinities of the two entities in a triple. For example, using a radius r = 1 in the example shown in Fig. 1, the entities rdf_graph and neural_network have the common entity dbpedia in their neighbourhoods. \u2022 f4: Jaccard index of the neighbourhoods of radius r of the head and tail of the triple. This feature provides a similar assessment as the previous one, but normalized in the interval [0, 1]. The Jaccard index is defined as:\nJ(A,B) = |A \u2229B| |A \u222aB|\n\u2022 f5: Adamic/Adar index [56] between the head and tail. This index gives higher scores to entities whose neighbourhoods are smaller. It complements the previous two\nfeatures, since a higher number of shared nearby entities is likely to be less significant if head and tail have a very large amount of connections. It is defined as the sum of the inverse logarithmic degree centrality of the neighbors shared by the two nodes:\nA(x, y) = \u2211\nu\u2208N(x)\u2229N(y)\n1\nlog|N(u)|\nwhere N(u) is the set of nodes adjacent to u. \u2022 f6: Paths of length r between the head and tail. For\nexample, in Fig. 1, the entities link_prediction and dbpedia are connected by a path of length 2, by means of the triples <link_prediction, usesMethod, neural_network> and <neural_network, usesMaterial, dbpedia>. Additionally, the relations that are present in those paths are also encoded using a r-hot vector. \u2022 f7: Cosine similarity of the word embeddings of the head and tail. This feature measures the semantic similarity of the two entities in a triple, using any entity embeddings. If we consider A and B to be the embeddings of the head and tail entities of the triple respectively, it is defined as:\ncos(A,B) = \u2211n i=1 AiBi\u221a\u2211n\ni=1 (Ai) 2 \u221a\u2211n i=1 (Bi) 2\n\u2022 f8: Dot product of the word embeddings of the head and tail entities. This feature complements the previous one by also taking into account the magnitudes of the embeddings of the entities. If we consider A and B to be the embeddings of the head and tail entities of the triple respectively, it is defined as:\nA \u00b7B = n\u2211\ni=1\nAiBi\n\u2022 f9: Types of the head and tail entities according to the ontology of the KG. This feature encodes the known types of the entities according to the available ontology as two one-hot vectors.\nRegarding the rationales of the features, f1 and f2 leverage the fact that large neighbourhoods are more prone to contain unrelated information, while smaller ones are usually more specific. This is especially true in the scholarly domain, since, as an example, the entity neural_network may be mentioned in a large amount of papers and proposals that are not directly related to each other.\nThe features that measure the similarities of two neighborhoods (f3, f4, and f5) follow the intuition that correct triples have a higher amount of shared entities in their respective neighbourhoods than incorrect ones, as shown by previous research efforts [18, 27, 57].\nFeature f6 measures the number of paths between two entities because a correct triple will typically have a larger number of unique paths of a given maximum length between"
        },
        {
            "heading": "4 VOLUME 4, 2022",
            "text": "This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nA. Borrego et al.: Completing Scientific Facts in Knowledge Graphs of Research Concepts\nhead and tail than an incorrect one. Furthermore, the information about which relations are comprised by those paths can be useful since the semantic meaning of a path changes depending on the relevant relations.\nFeatures f7 and f8 incorporate information from the word embeddings of the two entities, which had been shown to be advantageous for triple classification [25, 31]. SciCheck uses by default the RoBERTa model [37] to generate the word embeddings, since is able to capture and represent semantic similarities across a wide range of domains.\nFinally, feature f9 leverages the ontological schema of the KG. This allows SciCheck to include information regarding the types of the two entities in a triple into the feature vector for that triple. Furthermore, SciCheck can automatically classify a triple as incorrect if the triple does not respect the domains and ranges of the relation as defined in the ontological schema. For example, in the KG shown in Fig. 1, the triple <accuracy, evaluatesTask, rdf_graph> would be considered incorrect without further evaluation, because the range of the relation evaluatesTask is Task, while rdf_graph is a Material.\nSciCheck makes use of a much more comprehensive set of features than the original CAFE, which in turn allows a better characterization of entities and predicates. In particular, the features based on word embeddings enable SciCheck to exploit the implicit contextual information from the training papers that may not be encoded in the KG. Additionally, the inclusion of ontology-based features allows SciCheck to take advantage of the available high-level knowledge about any specific domain. These improvements are particularly crucial for assessing scientific claims, which tend to use a specific jargon and to rely on a well defined epistemological framework.\nFurthermore, different types of relations in the graph may carry specific insight that should be captured separately. For this reason, SciCheck first computes all features in the input KG as-is, and then it computes them again in different versions of the KG where only relations of a single type are present. This is done for all the different relations in the KG. Additionally, in features that use the neighbourhoods of the head and tail entities such as f1 or f3, these two neighborhoods are calculated using all possible combinations of relations. Finally, SciCheck concatenates all the resulting features in the final feature vector.\nThe features which involve computing entity neighbourhoods or paths (from f1 to f6) use a maximum number of hops for their computations. Following the findings in [27], by default SciCheck computes them for a maximum number of hops numhops of 1, 2, and 3. The resulting set of features using different radii are eventually all added to the final feature vector. Considering all the possible combinations with the number of different relations in the graph, which also affects the size of the feature vector as described previously, the number of total features is numhops \u00d7 6 \u00d7 #rels2 + 3 \u00d7 #rels, where #rels is the number of distinct relations in the KG.\nGROUPING FEATURE VECTORS SciCheck creates one classifier per each relation, under the assumption that the specific information needed to correctly classify triples may vary depending on the specific relation. After all triples have been converted into feature vectors in the previous step, they are grouped by the relation present in the triple, and passed on to the relevant classifier.\nTRAINING AND EVALUATING THE MODELS Finally, SciCheck trains a neural network-based classifier model for each relation using the resulting feature vectors. We generate multiple models, so that each classifier has a high specialization in addressing the target relation.\nIt is also advantageous to consider different neighbourhood radii that might carry information of different nature. For this reason, each of these classifiers is composed of several sub-models that consider only the features computed using a specific radius value on the sub-graph of a specific relation as in [27]. They are combined into a single classifier model by using an additional layer with a single neuron, which receives the outputs of all sub-models and combines them into a single output.\nThis step involves the use of a flexible neural classifier, which can be fine-tuned for the KG in question. The hyperparameters used in the evaluation are discussed in Section IV-A."
        },
        {
            "heading": "IV. EVALUATION",
            "text": "This section reports and discusses the evaluation of SciCheck. It also describes the evaluation data, including the new benchmarks that we created from the AI-KG Knowledge Graph (AIKG-1M and AIKG-500, available at https: //zenodo.org/record/5764114)."
        },
        {
            "heading": "A. EVALUATION PROTOCOL",
            "text": "We evaluated the performance of SciCheck on seven benchmarks against nine alternative approaches. Five of the baselines are well-known embedding-based KG completion approaches: TransE [24], TransD [53], TransH [58], SimplE [31], and ComplEx [26]. To provide a common ground to train and test these techniques, we used the OpenKE [59] tool.\nIn order to assess the contributions of the different components of SciCheck, we also considered five alternative versions of our approach:\n\u2022 CAFE Baseline, which uses solely the context-aware features for KG completion such as neighbourhood size, shared entities, connectivity, and so on from the original implementation [27]. \u2022 CAFE+RoBERTa, which extends CAFE by considering features based on the similarity of the embeddings of head and tail, using the RoBERTa model. \u2022 CAFE+SciBERT, which extends CAFE by considering features based on the similarity of the embeddings of head and tail, using SciBERT, an alternative BERT-\nVOLUME 4, 2022 5\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nA. Borrego et al.: Completing Scientific Facts in Knowledge Graphs of Research Concepts\nbased text embedding model7 specifically tailored to scientific documents. \u2022 CAFE+Ontology, which extends CAFE by considering features that identify the types of head and tail according to the domain ontology (e.g., AI-KG ontology) and also filters triples whose entities are not consistent with the domain and range restrictions of the relation. \u2022 SciCheck, the full version of our approach, which incorporates both features based on word embeddings (RoBERTa in the current implementation) and features based on the ontology, as described in Section III.\nThese methods were evaluated on the following benchmarks, whose characteristics are summarized in Table 1:\n\u2022 AIKG-1M, a new dataset that we created from AI-KG. We used a de-reified version of AI-KG, in order to consider only triples which involve tasks, methods, materials, metrics, and other scientific entities. As a result, 1,075,652 triples were directly generated from scientific literature, without considering facts that were materialized using the domain semantics defined in the AIKG ontology (e.g., transitivity). Triples were split into a training and a testing set with a split ratio of 80%-20%, respectively. To generate negative triples in the testing split, each positive triple was corrupted once by randomly replacing the tail entity with another one within the domain of the relation in the triple, i.e., if the range of the tail entity is a Task, then it is substituted by another entity whose type is Task. We also make sure that the randomly generated negative triple is not already present in the KG, to prevent creating false negatives whenever possible. As an example, the triple <dbpedia, usesOtherEntity, sparql_query> is correct, while the corrupted version <dbpedia, usesOtherEntity, cost_function> is considered incorrect, where sparql_query and cost_function are both of type OtherEntity. However, negative examples were not generated for the training split, as specific KG completion techniques usually have a preferred way to generate them automatically [60]. In total, the training split comprised 860,512 positive triples and the testing split includes 430,280 triples (50% positive and 50% negative). \u2022 AIKG-500, a new dataset that we constructed by manually annotating triples in AI-KG about the Semantic Web. To construct it, we randomly selected 250 triples which had as their head one of the 24 sub-topics of the Semantic Web according to the CSO ontology [61] and were considered to be correct by at least 2 methods among TransE, TransD, TransH, SimplE, ComplEx, and SciCheck. Another 250 triples were randomly selected out of those deemed incorrect by at least 2 techniques. The resulting 500 triples were manually annotated by five domain experts, with an inter-reviewer agreement\n7https://huggingface.co/sentence-transformers/ paraphrase-distilroberta-base-v2\nKG Training triples Test triples Entities Relations\nAIKG-1M 860,512 430,280 820,708 20 AIKG-500 860,512 500 228 7\nFB13 228,172 105,509 74,998 13 WN11 77,948 36,042 38,195 9 WN18 71,984 33,282 40,943 11 WN18RR 86,835 3,134 40,943 11 NELL 86,971 40,104 53,934 148\nIt is well-known [63] that these traditional benchmarks suffer from information leakage between the training and test sets, due to the presence of reciprocal relations. For this reason, we removed all reciprocal relations in all datasets except WN18, since we also include its previously discussed sanitized version, WN18RR.\nTo predict the correctness of a triple, we used feed-forward neural networks with 3 intermediate layers containing 128, 64 and 32 neurons, respectively. The output neuron uses a sigmoid function, returning a confidence score in the interval [0, 1]. The classifier was trained throughout 100 epochs, using a binary cross-entropy loss function.\nSince SciCheck is a triple classifier, we evaluated its effectiveness by comparing the labels it predicted for the triples in the testing set against the ground truth. The results are thus reported in terms of precision and recall, which have been recently become standard metrics to evaluate KG completion, since they can be more informative than MRR and Hits@N in many practical settings [64, 65]. In this paper, we specifically focus on precision, since we have the concrete objective of extending AI-KG and this can only be reliably done using a method with a high precision."
        },
        {
            "heading": "6 VOLUME 4, 2022",
            "text": "This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nA. Borrego et al.: Completing Scientific Facts in Knowledge Graphs of Research Concepts\nB. RESULTS AND DISCUSSION\nTable 2 and Table 3 report the precision and recall of the KG completion techniques on AIKG-1M. To determine whether a triple was correct or incorrect, we used a confidence threshold of 0.5 for SciCheck, as suggested in [27]. The thresholds of the other state-of-the-art techniques under evaluation and their results were obtained using the OpenKE [59] tool, allowing it to choose the optimal value for each one.\nAll CAFE variants outperform embedding-based techniques in precision, achieving notably higher values. Including features from the text embeddings provides also an important improvement over the base version of CAFE. Both SciCheck and the variants that improve the baseline using embedding-based features rank consistently among those with the highest precision for all relations, with the differences between them being very narrow. Interestingly, using text embeddings trained specifically on academic abstracts yields a slightly worse performance than using the generic RoBERTa model. This may suggest that more general embeddings may sometimes produce better performance on KGs of research concepts, but this needs to be investigated further.\nThe Ontology variation, which includes one-hot type vectors and domain/range checking for the relation, only slightly improves the baseline. This is most likely due to the typeconstrained way in which the negative triples were generated, since it already guarantees that the domain and range types of the relation are preserved.\nThe recall of SciCheck is naturally lower than that of the embedding-based approaches, in a typical precision-recall trade-off. However, this is acceptable since the main goal is to expand scientific KG with correct triples, hence, a high precision is necessary. SciCheck has also a generally higher recall than all other CAFE variants. Consequently, the results suggest that SciCheck is the best performing technique for the task of reliably completing scientific KGs.\nIt is noteworthy that different relations can lead to very different performance. For instance, relations such as narrower, supportsTask and supportsMethod yield very good performance. Conversely, the methods did not perform as well on relations such as evaluatesTask and evaluatesOtherEntity. This may depend on the number of relevant examples or the fact that some relations are inherently harder to predict. The role of different relations in the context of completing scientific KG requires further analysis.\nIn order to study the performance of the different techniques for all possible threshold values, we also report their corresponding ROC curves in Fig. 2. This analysis confirms the previous findings: 1) SciCheck outperforms all the other methods, 2) text embedding features significantly improve the baseline, and 3) the ontological features slightly improve the baseline. In addition, Fig. 2(b) confirm that SciCheck outperforms the standard state-of-the art methods regardless of the threshold.\nTo check whether the differences between the methods were statistically significant, we used DeLong\u2019s test [66] to compare the areas under two curves. The p-values obtained when comparing the ROC curve of SciCheck with the alternative methods in Fig. 2(a) and Fig. 2(b) were all < 0.0001. This very high statistical confidence is due to the large number of observations, since the testing set of AIKG-1M includes more than 400,000 triples.\nTable 4 shows the performance of the methods on AIKG500, which are consistent with the previous findings. For the sake of brevity, here we do not report the results of all CAFE variants, which are in line with those obtained on AIKG-1M. Even in a smaller, manually annotated benchmark, SciCheck achieves a high precision, which confirms that it is suitable for completing scientific KGs.\nTable 5 reports the performance of all the techniques on five standard benchmarks for triple classification. The results show that SciCheck is able to outperform other techniques in almost all cases, thus being an effective triple classification tool for KGs of many different natures. They also confirm that completing scientific KGs is indeed a challenging task that requires specialized techniques, as the general purpose embedding-based approaches yield worse results on benchmarks extracted from AI-KG in comparison to generic ones.\nIn order to assess the scalability of our solution, Table 6 reports the seconds used by SciCheck to process the previously discussed datasets. To ensure statistical significance, we measured the runtime for each benchmark 10 times, and we report the average and the standard distribution for each one. The runtime ranges from a few seconds to over two hours according to the dataset.\nThese differences are caused by mainly two factors. First, the amount of distinct entities corresponds directly to the number of RoBERTa embeddings that have to be computed, which are typically quite time-consuming. Hence, a larger number of entities has a negative impact on runtime. Second, and most importantly, the specific topology of every KG affects the size of the neighborhoods of the entities, and thus also affects the time it takes to compute features on them. The case of FB13 is particularly noteworthy since, in contrast with the other datasets, it contains many entities with a very high cardinality. This causes the sizes of the entity neighborhoods to grow exponentially in size, resulting in longer runtimes. However, even in this worst-case scenario, SciCheck took less than 3 hours, which we consider reasonable for its application to most KGs."
        },
        {
            "heading": "V. USE CASE: AI-KG",
            "text": "A real-world use case for SciCheck involves the development and extension of AI-KG [2], a large scale knowledge graph about research entities from the AI domain. AI-KG was released in late 2020 and it includes about 14M RDF triples and 1.2M reified statements about 800K entities extracted from 333K articles in the field of AI. It describes 5 types of entities (tasks, methods, materials, metrics, others) linked by 27 relations (e.g., usesMaterial, evaluatesMethod, sup-\nVOLUME 4, 2022 7\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nA. Borrego et al.: Completing Scientific Facts in Knowledge Graphs of Research Concepts"
        },
        {
            "heading": "8 VOLUME 4, 2022",
            "text": "This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nA. Borrego et al.: Completing Scientific Facts in Knowledge Graphs of Research Concepts\nportsTask). AI-KG statements characterize the relationships between two entities according to their description in a\nset of scientific articles, e.g., <sentiment_analysis, usesMaterial, twitter_data>.\nIt is important to note that, in AI-KG, a triple associated with a set of papers is considered true if the papers actually contain that claim. To analyze the general truth value of each claim is not currently possible. Therefore, triples in AI-KG are devised to be a means for representing specific claims by researchers.\nFor example, the entity sentiment_analysis only represents the concept or idea of sentiment analysis as it is described in the original corpus of papers, but it is not aimed to represent or include all available prototypes and implementations to\nVOLUME 4, 2022 9\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nA. Borrego et al.: Completing Scientific Facts in Knowledge Graphs of Research Concepts\npredict sentiments and emotions available today. In fact, such a modeling would require to promote research entities from concepts to classes to describe specific ontological knowledge (e.g., by defining an ontology to describe how sentiment analysis prototypes can use datasets and machine learning approaches) which is out of the scope of AI-KG.\nFor instance, a triple <deep_model_cnn, usedByTask, toxicity_detection> from the paper [57] should be interpreted in the context of the same paper [57] i.e., deep model cnn is used for toxicity detection in [57] and, more broadly, some deep model cnn can be used for toxicity detection. Neither an interpretation like all deep model cnn are used for toxicity detection nor deep model cnn must be used for toxicity detection are correct according to the design and use of the current implementation of AI-KG.\nAI-KG is adopted by several organizations for characterizing the AI domain and it has been used for supporting several research efforts, e.g., for extracting entities from scientific publications [67], describing competencies [52], and classifying scholarly articles [68]. AI-KG was generated by using Natural Language Processing (NLP) and Machine Learning (ML) methods for extracting entities and their relationships [69]. More specifically, AI-KG adopts a pipeline process that is applied on natural language scientific texts to (i) detect entities using a domain-specific extractor based on transformers [70] and a topic classifier developed on top of the CSO ontology [71]; (ii) identify relationships between entities by using open- and domain-specific ML and NLP tools [70, 72, 73], and (iii) define which facts make sense according to an ontology representing the domain semantics. In addition, to determine whether a fact makes sense, the authors adopted a support score defined as the number of research papers where the fact was extracted from.\nThe reader can find more details about this methodology in [2, 69]. The current version of AI-KG consists of research entities belonging to one of the following classes:\n\u2022 Task: A research challenge or a certain work to perform. \u2022 Method: A research proposal or approach whose aim is to perform a certain task. \u2022 Material: Resources that are employed for a certain research task, e.g., a dataset, an image, a text corpus. \u2022 Metric: Entities that can be quantified and are used to measure the quality of a certain method. \u2022 OtherEntity: A class used to group entities that cannot be classified in any of the previous ones.\nThe relations were created by clustering frequent verbs and asking human experts to define domain and range restrictions as well as transitiveness.\nSome examples of object properties are evaluatesMethod, includesMaterial, or usesMethod. The ontology of AI-KG is available at https://scholkg.kmi.open. ac.uk/aikg/ontology.\nAlthough the extracted facts compose a large-scale KG, the mining of such knowledge from natural language is an error-prone and challenging task and, therefore, it tends\nto have low coverage, i.e. well-known facts might not be materialized within the KG. As a result, AI-KG is sparse and incomplete. For example, the well-known fact <neural_network, usesMaterial, rdf_graph> cannot be found in the current AI-KG resource despite the fact that RDF graphs are the input of most of the existing neural network-based link prediction and triple classification algorithms.\nFor this reason, scientific KGs are calling for specific approaches for their completion [47]. However, state-of-the-art methods developed for general-domain KGs such as TransE, TransR, RotatE, and so on fail to predict triples with a good accuracy on AI-KG.\nAs reported in Section IV, these methods yield decent F1measures, but suffer from a low precision (typically around 45-60%). Their adoption would thus introduce too many incorrect facts in the graph. The poor results of the existing techniques motivated this use case.\nWe applied SciCheck to AI-KG and, using a confidence threshold of 0.7, materialized 303, 760 additional facts. Specifically, we used SciCheck to connect the most frequent 500 entities according to the relations defined in the AI-KG ontology8. These include many significant facts there were missed by the information extraction pipeline, such as <search_engine, includesMaterial, knowledge_base>, <f_measure, evaluatesMethod, neural_network>, <neural_network, usesMaterial, rdf_graph>, or <recommender_system, usesMethod, predictive_model>.\nThe new version of AI-KG is available online at https:// zenodo.org/record/5769957."
        },
        {
            "heading": "VI. CONCLUSION",
            "text": "In this paper, we introduced SciCheck, a new approach for completing scientific facts in knowledge graphs of research concepts.\nWe evaluated SciCheck on two new benchmarks extracted from the Artificial Intelligence Knowledge Graph (AI-KG) [2], a large-scale KG of research concepts, (AIKG1M and AIKG-500) and five well-known general benchmarks for link prediction (FB13, WN11, WN18, WN18RR, and NELL). The experiments show that SciCheck significantly outperforms nine alternative approaches. Furthermore, we have shown a real-world use case and used SciCheck to complete AI-KG, producing a new version of it including more than 300K additional statements (a 28% increase).\nAs future work, we plan to study the application of KG completion techniques to hypothesis generation and extend SciCheck in this space. We also plan to consider weighted triples [50, 74] that could formalize the degree of certainty in specific statements. Finally, we look forward to applying our methodology to other scientific KGs, such as Open Research Knowledge Graph [4] and Nanopublications [13].\n8http://scholkg.kmi.open.ac.uk/aikg/ontology"
        },
        {
            "heading": "10 VOLUME 4, 2022",
            "text": "This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nA. Borrego et al.: Completing Scientific Facts in Knowledge Graphs of Research Concepts\nREFERENCES [1] H. Kitano, \u201cArtificial intelligence to win the nobel prize and beyond:\nCreating the engine for scientific discovery,\u201d AI magazine, vol. 37, no. 1, pp. 39\u201349, 2016. [2] D. Dess\u00ec, F. Osborne, D. R. Recupero, D. Buscaldi, E. Motta, and H. Sack, \u201cAI-KG: an automatically generated knowledge graph of artificial intelligence,\u201d in ISWC 2020, vol. 12507. Springer, 2020, pp. 127\u2013143. [Online]. Available: https://doi.org/10.1007/978-3-030-62466-8_9 [3] R. d. Haan, I. Tiddi, and W. Beek, \u201cDiscovering research hypotheses in social science using knowledge graph embeddings,\u201d in European Semantic Web Conference. Springer, 2021, pp. 477\u2013494. [4] M. Y. Jaradeh, A. Oelen, K. E. Farfar, M. Prinz, J. D\u2019Souza, G. Kismih\u00f3k, M. Stocker, and S. Auer, \u201cOpen research knowledge graph: Next generation infrastructure for semantic scholarly knowledge,\u201d in Proceedings of the 10th International Conference on Knowledge Capture, 2019, pp. 243\u2013 246. [5] A. G. Nuzzolese, A. L. Gentile, V. Presutti, and A. Gangemi, \u201cSemantic web conference ontology-a refactoring solution,\u201d in European Semantic Web Conference. Springer, 2016, pp. 84\u201387. [6] D. Ayala, A. Borrego, I. Hern\u00e1ndez, and D. Ruiz, \u201cA neural network for semantic labelling of structured information,\u201d Expert Syst. Appl., vol. 143, 2020. [Online]. Available: https://doi.org/10.1016/j.eswa.2019.113053 [7] F. Hoppe, D. Dess\u00ec, and H. Sack, \u201cDeep learning meets knowledge graphs for scholarly data classification,\u201d in Companion proceedings of the web conference 2021, 2021, pp. 417\u2013421. [8] F. Belleau, M.-A. Nolin, N. Tourigny, P. Rigault, and J. Morissette, \u201cBio2rdf: towards a mashup to build bioinformatics knowledge systems,\u201d Journal of biomedical informatics, vol. 41, no. 5, pp. 706\u2013716, 2008. [9] D. Shotton, \u201cSemantic publishing: the coming revolution in scientific journal publishing,\u201d Learned Publishing, vol. 22, no. 2, pp. 85\u201394, 2009. [10] A. Kelley and D. Garijo, \u201cA framework for creating knowledge graphs of scientific software metadata,\u201d Quantitative Science Studies, pp. 1\u201337, 2021. [11] K. Wolstencroft, R. Haines, D. Fellows, A. Williams, D. Withers, S. Owen, S. Soiland-Reyes, I. Dunlop, A. Nenadic, P. Fisher et al., \u201cThe taverna workflow suite: designing and executing workflows of web services on the desktop, web or in the cloud,\u201d Nucleic acids research, vol. 41, no. W1, pp. W557\u2013W561, 2013. [12] P. Groth, A. Gibson, and J. Velterop, \u201cThe anatomy of a nanopublication,\u201d Information Services & Use, vol. 30, no. 1-2, pp. 51\u201356, 2010. [13] T. Kuhn, C. Chichester, M. Krauthammer, N. Queralt-Rosinach, R. Verborgh, G. Giannakopoulos, A.-C. N. Ngomo, R. Viglianti, and M. Dumontier, \u201cDecentralized provenance-aware publishing with nanopublications,\u201d PeerJ Computer Science, vol. 2, p. e78, 2016. [14] J. Schneider, P. Ciccarese, T. Clark, and R. D. Boyce, \u201cUsing the micropublications ontology and the open annotation data model to represent evidence within a drug-drug interaction knowledge base,\u201d in LISC@ISWC, 2014. [15] A. A. Salatino, T. Thanapalasingam, A. Mannocci, F. Osborne, and E. Motta, \u201cThe computer science ontology: a large-scale taxonomy of research areas,\u201d in International Semantic Web Conference. Springer, 2018, pp. 187\u2013205. [16] S. Peroni and D. Shotton, \u201cThe spar ontologies,\u201d in International Semantic Web Conference. Springer, 2018, pp. 119\u2013136. [17] A. Hogan, E. Blomqvist, M. Cochez, C. d\u2019Amato, G. D. Melo, C. Gutierrez, S. Kirrane, J. E. L. Gayo, R. Navigli, S. Neumaier et al., \u201cKnowledge graphs,\u201d ACM Computing Surveys (CSUR), vol. 54, no. 4, pp. 1\u201337, 2021. [18] S. Vahdati, N. Arndt, S. Auer, and C. Lange, \u201cOpenresearch: collaborative management of scholarly communication metadata,\u201d in European Knowledge Acquisition Workshop. Springer, 2016, pp. 778\u2013793. [19] O. Bodenreider, \u201cThe unified medical language system (umls): integrating biomedical terminology,\u201d Nucleic acids research, vol. 32, no. suppl_1, pp. D267\u2013D270, 2004. [20] A. Salatino, F. Osborne, and E. Motta, \u201cResearchflow: Understanding the knowledge flow between academia and industry,\u201d in Knowledge Engineering and Knowledge Management \u2013 22nd International Conference, EKAW 2020, 2020. [21] A. Rossanez, J. C. dos Reis, and R. da Silva Torres, \u201cRepresenting scientific literature evolution via temporal knowledge graphs.\u201d in MEPDaW@ ISWC, 2020, pp. 33\u201342. [22] D. Ayala, A. Borrego, I. Hern\u00e1ndez, C. R. Rivero, and D. Ruiz, \u201cAYNEC: all you need for evaluating completion techniques in knowledge graphs,\u201d in ESWC 2019, vol. 11503. Springer, 2019, pp. 397\u2013411. [Online]. Available: https://doi.org/10.1007/978-3-030-21348-0_26\n[23] Y. Dai, S. Wang, N. N. Xiong, and W. Guo, \u201cA survey on knowledge graph embedding: Approaches, applications and benchmarks,\u201d Electronics, vol. 9, no. 5, p. 750, 2020. [24] A. Bordes, N. Usunier, A. Garc\u00eda-Dur\u00e1n, J. Weston, and O. Yakhnenko, \u201cTranslating embeddings for modeling multi-relational data,\u201d in NIPS, 2013, pp. 2787\u20132795. [25] Z. Sun, Z.-H. Deng, J.-Y. Nie, and J. Tang, \u201cFactorizing yago: scalable machine learning for linked data,\u201d in ICLR, 2019, pp. 271\u2013280. [26] T. Trouillon, J. Welbl, S. Riedel, \u00c9. Gaussier, and G. Bouchard, \u201cComplex embeddings for simple link prediction,\u201d in ICML, vol. 48, 2016, pp. 2071\u2013 2080. [27] A. Borrego, D. Ayala, I. Hern\u00e1ndez, C. R. Rivero, and D. Ruiz, \u201cCAFE: Knowledge graph completion using neighborhood-aware features,\u201d Engineering Applications of Artificial Intelligence, vol. 103, p. 104302, 2021. [28] Y. Shen, D. Wen, Y. Li, N. Du, H.-t. Zheng, and M. Yang, \u201cPathbased attribute-aware representation learning for relation prediction,\u201d in Proceedings of the 2019 SIAM International Conference on Data Mining. SIAM, 2019, pp. 639\u2013647. [29] J. Zhou, G. Cui, Z. Zhang, C. Yang, Z. Liu, L. Wang, C. Li, and M. Sun, \u201cGraph neural networks: A review of methods and applications,\u201d in CoRR, 2018. [30] Q. Wang, Z. Mao, B. Wang, and L. Guo, \u201cKnowledge graph embedding: A survey of approaches and applications,\u201d IEEE TKDE, vol. 29, no. 12, 2017. [31] S. M. Kazemi and D. Poole, \u201cSimple embedding for link prediction in knowledge graphs,\u201d in Advances in Neural Information Processing Systems, 2018. [32] Y. Lin, Z. Liu, M. Sun, Y. Liu, and X. Zhu, \u201cLearning entity and relation embeddings for knowledge graph completion.\u201d in AAAI, vol. 15, 2015. [33] H. Liu, Y. Wu, and Y. Yang, \u201cAnalogical inference for multi-relational embeddings,\u201d in ICML-Volume 70, 2017. [34] R. Socher, D. Chen, C. D. Manning, and A. Ng, \u201cReasoning with neural tensor networks for knowledge base completion,\u201d in Advances in NIPS, 2013, pp. 926\u2013934. [35] T. Mitchell, W. Cohen, E. Hruschka, P. Talukdar, B. Yang, J. Betteridge, A. Carlson, B. Dalvi, M. Gardner, B. Kisiel, J. Krishnamurthy, N. Lao, K. Mazaitis, T. Mohamed, N. Nakashole, E. Platanios, A. Ritter, M. Samadi, B. Settles, R. Wang, D. Wijaya, A. Gupta, X. Chen, A. Saparov, M. Greaves, and J. Welling, \u201cNever-ending learning,\u201d Commun. ACM, vol. 61, no. 5, pp. 103\u2013115, 2018. [36] T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean, \u201cDistributed representations of words and phrases and their compositionality,\u201d in Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2, ser. NIPS\u201913, 2013, pp. 3111\u20133119. [Online]. Available: http://dl.acm.org/citation.cfm?id=2999792.2999959 [37] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, \u201cRoberta: A robustly optimized BERT pretraining approach,\u201d CoRR, vol. abs/1907.11692, 2019. [Online]. Available: http://arxiv.org/abs/1907.11692 [38] N. Lao and W. W. Cohen, \u201cRelational retrieval using a combination of path-constrained random walks,\u201d Machine learning, vol. 81, no. 1, pp. 53\u2013 67, 2010. [39] M. Gardner and T. Mitchell, \u201cEfficient and expressive knowledge base completion using subgraph feature extraction,\u201d in EMNLP. The Association for Computational Linguistics, 2015, pp. 1488\u20131498. [40] S. Mazumder and B. Liu, \u201cContext-aware path ranking for knowledge base completion,\u201d in IJCAI. AAAI Press, 2017, pp. 1195\u20131201. [41] W. Xiong, T. Hoang, and W. Y. Wang, \u201cDeeppath: A reinforcement learning method for knowledge graph reasoning,\u201d in EMNLP, 2017. [42] T. Hamaguchi, H. Oiwa, M. Shimbo, and Y. Matsumoto, \u201cKnowledge transfer for out-of-knowledge-base entities : A graph neural network approach,\u201d in Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17, 2017, pp. 1802\u20131808. [Online]. Available: https://doi.org/10.24963/ijcai.2017/250 [43] C. Shang, Y. Tang, J. Huang, J. Bi, X. He, and B. Zhou, \u201cEndto-end structure-aware convolutional networks for knowledge base completion,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, 2019, pp. 3060\u20133067. [Online]. Available: https://ojs.aaai.org/index.php/AAAI/article/view/4164 [44] D. Nathani, J. Chauhan, C. Sharma, and M. Kaul, \u201cLearning attentionbased embeddings for relation prediction in knowledge graphs,\u201d in Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, 2019, pp. 4710\u20134723.\nVOLUME 4, 2022 11\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nA. Borrego et al.: Completing Scientific Facts in Knowledge Graphs of Research Concepts\n[45] P. Velic\u030ckovic\u0301, G. Cucurull, A. Casanova, A. Romero, P. Li\u00f2, and Y. Bengio, \u201cGraph attention networks,\u201d in International Conference on Learning Representations, 2018. [46] Z. Wang, Z. Ren, C. He, P. Zhang, and Y. Hu, \u201cRobust embedding with multi-level structures for link prediction.\u201d in IJCAI, 2019, pp. 5240\u20135246. [47] M. Y. Jaradeh, K. Singh, M. Stocker, and S. Auer, \u201cTriple classification for scholarly knowledge graph completion,\u201d in Proceedings of the 11th on Knowledge Capture Conference, ser. K-CAP \u201921, New York, NY, USA, 2021, p. 225\u2013232. [Online]. Available: https://doi.org/10.1145/3460210. 3493582 [48] M. Nayyeri, G. M. Cil, S. Vahdati, F. Osborne, M. Rahman, S. Angioni, A. Salatino, D. R. Recupero, N. Vassilyeva, E. Motta, and J. Lehmann, \u201cTrans4e: Link prediction on scholarly knowledge graphs,\u201d Neurocomputing, 2021. [49] M. Nayyeri, S. Vahdati, X. Zhou, H. S. Yazdi, and J. Lehmann, \u201cEmbedding-based recommendations on scholarly knowledge graphs,\u201d in European Semantic Web Conference. Springer, 2020, pp. 255\u2013270. [50] M. Nayyeri, G. M. Cil, S. Vahdati, F. Osborne, A. Kravchenko, S. Angioni, A. Salatino, D. R. Recupero, E. Motta, and J. Lehmann, \u201cLink prediction of weighted triples for knowledge graph completion within the scholarly domain,\u201d IEEE Access, vol. 9, pp. 116 002\u2013116 014, 2021. [51] K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor, \u201cFreebase: a collaboratively created graph database for structuring human knowledge,\u201d in Proceedings of the 2008 ACM SIGMOD international conference on Management of data. AcM, 2008, pp. 1247\u20131250. [52] N. Heist and P. Haase, \u201cFlexible and extensible competency management with knowledge graphs,\u201d in ISWC (Posters/Demos/Industry), vol. 2980. CEUR-WS.org, 2021. [Online]. Available: http://ceur-ws.org/Vol-2980/ paper412.pdf [53] G. Ji, S. He, L. Xu, K. Liu, and J. Zhao, \u201cKnowledge graph embedding via dynamic mapping matrix,\u201d in ACL (1). The Association for Computer Linguistics, 2015, pp. 687\u2013696. [54] I. Bansal, S. Tiwari, and C. R. Rivero, \u201cThe impact of negative triple generation strategies and anomalies on knowledge graph completion,\u201d in CIKM \u201920: The 29th ACM International Conference on Information and Knowledge Management. ACM, 2020, pp. 45\u201354. [55] T. Alahakoon, R. Tripathi, N. Kourtellis, R. Simha, and A. Iamnitchi, \u201cKpath centrality: A new centrality measure in social networks,\u201d Proceedings of the 4th Workshop on Social Network Systems, SNS\u201911, 04 2011. [56] L. A. Adamic and E. Adar, \u201cFriends and neighbors on the web,\u201d Soc. Networks, vol. 25, no. 3, pp. 211\u2013230, 2003. [57] D. Dess\u00ec, D. R. Recupero, and H. Sack, \u201cAn assessment of deep learning models and word embeddings for toxicity detection within online textual comments,\u201d Electronics, vol. 10, no. 7, p. 779, 2021. [58] Z. Wang, J. Zhang, J. Feng, and Z. Chen, \u201cKnowledge graph embedding by translating on hyperplanes.\u201d in AAAI, vol. 14, 2014. [59] X. Han, S. Cao, X. Lv, Y. Lin, Z. Liu, M. Sun, and J. Li, \u201cOpenke: An open toolkit for knowledge embedding,\u201d in EMNLP, 2018, pp. 139\u2013144. [60] A. Borrego, D. Ayala, I. Hern\u00e1ndez, C. R. Rivero, and D. Ruiz, \u201cGenerating rules to filter candidate triples for their correctness checking by knowledge graph completion techniques,\u201d in K-CAP, 2019, pp. 115\u2013122. [61] A. A. Salatino, T. Thanapalasingam, A. Mannocci, A. Birukou, F. Osborne, and E. Motta, \u201cThe computer science ontology: A comprehensive automatically-generated taxonomy of research areas,\u201d Data Intell., vol. 2, no. 3, pp. 379\u2013416, 2020. [62] A. Bordes, X. Glorot, J. Weston, and Y. Bengio, \u201cA semantic matching energy function for learning with multi-relational data - application to word-sense disambiguation,\u201d Machine Learning, vol. 94, no. 2, pp. 233\u2013 259, 2014. [63] T. Dettmers, P. Minervini, P. Stenetorp, and S. Riedel, \u201cConvolutional 2D knowledge graph embeddings,\u201d in AAAI, 2018. [64] P. Pezeshkpour, Y. Tian, and S. Singh, \u201cRevisiting evaluation of knowledge base completion models,\u201d in AKBC, 2020. [65] M. Speranskaya, M. Schmitt, and B. Roth, \u201cRanking vs. classifying: Measuring knowledge base completion quality,\u201d in AKBC, 2020. [66] E. R. DeLong, D. M. DeLong, and D. L. Clarke-Pearson, \u201cComparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach,\u201d Biometrics, pp. 837\u2013845, 1988. [67] X. Li and M. Daoutis, \u201cUnsupervised key-phrase extraction and clustering for classification scheme in scientific publications,\u201d arXiv preprint arXiv:2101.09990, 2021. [68] F. Hoppe, D. Dess\u00ec, and H. Sack, \u201cUnderstanding class representations: An intrinsic evaluation of zero-shot text classification,\u201d in Workshop on\nDeep Learning for Knowledge Graphs (DL4KG@ ISWC2021), ser. CEUR Workshop Proceedings, vol. 3034, 2021. [69] D. Dess\u00ec, F. Osborne, D. R. Recupero, D. Buscaldi, and E. Motta, \u201cGenerating knowledge graphs by employing natural language processing and machine learning techniques within the scholarly domain,\u201d Future Generation Computer Systems, vol. 116, pp. 253\u2013264, 2021. [70] D. Wadden, U. Wennberg, Y. Luan, and H. Hajishirzi, \u201cEntity, relation, and event extraction with contextualized span representations,\u201d in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019, 2019, pp. 5783\u20135788. [Online]. Available: https://doi.org/10.18653/v1/D19-1585 [71] A. A. Salatino, F. Osborne, T. Thanapalasingam, and E. Motta, \u201cThe CSO classifier: Ontology-driven detection of research topics in scholarly articles,\u201d in Digital Libraries for Open Knowledge, A. Doucet, A. Isaac, K. Golub, T. Aalberg, and A. Jatowt, Eds. Cham: Springer International Publishing, 2019, pp. 296\u2013311. [72] G. Angeli, M. J. J. Premkumar, and C. D. Manning, \u201cLeveraging linguistic structure for open domain information extraction,\u201d in Proceedings of the 53rd Annual Meeting of the ACL and the 7th IJCNLP, vol. 1, 2015, pp. 344\u2013354. [73] K. Toutanova, D. Klein, C. D. Manning, and Y. Singer, \u201cFeature-rich partof-speech tagging with a cyclic dependency network,\u201d in Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, 2003, pp. 252\u2013 259. [74] X. Chen, M. Chen, W. Shi, Y. Sun, and C. Zaniolo, \u201cEmbedding uncertain knowledge graphs,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, 2019, pp. 3363\u20133370.\nAGUST\u00cdN BORREGO is currently pursuing his Ph.D. degree at the University of Seville. From 2018 to 2019, he was a Research Assistant at the DEAL research group in the University of Seville. From 2019, he has been a PhD student at USE and a visiting student to the Open University, UK. His current research interests involve Knowledge Graphs, including their completion and refinement.\nDR. DANILO DESS\u00cc has been a Researcher at the University of Cagliari, Italy (UNICA) since August 2021. Previously, he was a Post-Doctoral Researcher/Senior Researcher at FIZ Karlsruhe \u2013 Leibniz Institute for Information Infrastructure and Karlsruhe Institute of Technology (KIT), Institute of Applied Informatics and Formal Description Methods (AIFB) with Prof. Dr. Harald Sack. He holds a Master\u2019s degree and a Doctoral degree from UNICA. His PhD thesis was supervised by\nProf. Diego Reforgiato Recupero. He has been visiting researchers in the following centers all around the world: Philips Research (Eindhoven, 2016), Center for Data Science NYU (New York City, 2017), Knowledge Media Institute \u2013 The Open University (Milton Keynes, 2018), and Laboratoire d\u2019informatique de Paris Nord \u2013 University of Paris 13 (Paris, 2019). He is a member of the laboratory of Human-Robot Interaction HRI Lab@UNICA at the University of Cagliari (in collaboration with R2M Solution s.r.l.) whose research and development activities are dedicated to the understanding, designing, and evaluating of several robotic platforms which employ different research technologies (e.g. Sentiment Analysis, Semantic Web, Deep Learning, Natural Language Processing, etc.) when interacting with humans."
        },
        {
            "heading": "12 VOLUME 4, 2022",
            "text": "This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nA. Borrego et al.: Completing Scientific Facts in Knowledge Graphs of Research Concepts\nDR. INMA HERN\u00c1NDEZ is an Associate Professor at the University of Seville, and a founding member of the Data Enginnering Applications Lab. Her current research involves Data Engineering and Knowledge Graphs.\nShe has authored many peer-reviewed publications on these topics in top conferences and journals, and she is a very active reviewer and a member of several program committees in major conferences. She is currently Principal Investiga-\ntor on a number of projects funded by the Spanish national R&D program. Since 2020, she is the coordinator of the Master on Software Engineering: Cloud, Data and IT Management at the Postgraduate School of the University of Sevilla.\nDR. FRANCESCO OSBORNE is a Research Fellow at the Knowledge Media Institute of the Open University in UK, where he leads the Scholarly Data Mining team. He is also Assistant Professor at the University of Milano Bicocca. His research covers Artificial Intelligence, Information Extraction, Knowledge Graphs, Science of Science, and Semantic Web. He has authored more than a hundred peer-reviewed publications in top journals and conferences of these fields. He col-\nlaborates with major publishers, universities, and companies in the space of innovation for producing a variety of innovative services for supporting researchers, editors, and research polities makers. He has released many well-adopted resources such as the Computer Science Ontology and the Artificial Intelligence Knowledge Graph.\nPROF. DIEGO REFORGIATO RECUPERO has been Full Professor at the Department of Mathematics and Computer Science of the University of Cagliari, Italy, since February 2022. He received the Ph.D. degree in computer science from the University of Naples Federico II, Italy, in 2004. From 2005 to 2008 he was a Postdoctoral Researcher at the University of Maryland College Park, USA. He won different awards in his career (such as Marie Curie International Reintegration\nGrant, Marie Curie Innovative Training Network, Best Researcher Award from the University of Catania, Computer World Horizon Award, Telecom Working Capital, Startup Weekend, best paper award). He co-founded 6 companies within the ICT sector and is actively involved in European projects and research (with one of his companies he won more than 40 FP7 and H2020 projects). His current research interests include sentiment analysis, semantic web, natural language processing, human robot interaction, financial technology, and smart grid. He is author of more than 190 conference and journal papers in these research fields, with more than 2400 citations.\nPROF. DAVID RUIZ is Full Professor of Software Engineering at the University of Seville. He leads the Data Engineering Applications Lab at the University of Seville, focusing his research on Data Engineering, Knowledge Graphs, and Data Integration. He has recently started two new related lines of research, focused on the application of machine learning techniques for the automated retrieval and processing of aviation data, and for the genomic analysis of multi-resistant bacteria.\nSince 2014, he is Deputy Director of the School of Computer Science at the University of Seville, where he has contributed to the creation of a Dual Bachelor\u2019s Degree in Computer Science and Mathematics, and two new postgraduate Master\u2019s courses.\nDR. DAVIDE BUSCALDI is Associate Professor at LIPN, Sorbonne Paris North University and part-time Assistant Professor at the Ecole Polytechnique, where he is teaching Machine Learning and Data Science courses, principally. His main research interests are Natural Language Processing and Text Mining, in particular the application of modern NLP techniques to text annotation and relation extraction. He has directed or co-directed 2 PhD theses and is currently directing 3 more\ntheses in NLP and Machine Learning. He collaborates in various national and European projects, and he is author of more than 110 peer-reviewed conference and journal papers.\nPROF. ENRICO MOTTA is Professor in Knowledge Technologies and Former Director (2000 - 2007) of the Knowledge Media Institute (KMi) at the Open University in UK. Prof. Motta has a Laurea in Computer Science from the University of Pisa in Italy and a PhD in Artificial Intelligence from the Open University. His research spans a variety of aspects at the intersection of largescale data integration and modelling, semantic and language technologies, intelligent systems, and\nhuman-computer interaction. Over the years, Prof. Motta has led KMi\u2019s contribution to numerous high-profile projects, receiving over \u00a310.4M in external funding since 2000 from a variety of institutional funding bodies and commercial organizations.\nVOLUME 4, 2022 13\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/"
        }
    ],
    "title": "Completing Scientific Facts in Knowledge Graphs of Research Concepts",
    "year": 2022
}