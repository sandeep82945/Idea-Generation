{
    "abstractText": "Entity typing aims to classify semantic types of an entity mention in a specific context. Most existing models obtain training data using distant supervision, and inevitably suffer from the problem of noisy labels. To address this issue, we propose entity typing with language model enhancement. It utilizes a language model to measure the compatibility between context sentences and labels, and thereby automatically focuses more on context-dependent labels. Experiments on benchmark datasets demonstrate that our method is capable of enhancing the entity typing model with information from the language model, and significantly outperforms the stateof-the-art baseline. Code and data for this paper can be found from https://github. com/thunlp/LME.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ji Xin"
        },
        {
            "affiliations": [],
            "name": "Hao Zhu"
        },
        {
            "affiliations": [],
            "name": "Xu Han"
        },
        {
            "affiliations": [],
            "name": "Zhiyuan Liu"
        },
        {
            "affiliations": [],
            "name": "Maosong Sun"
        }
    ],
    "id": "SP:e4bb134b2c02e88d963b6b7f9af70273a43d019f",
    "references": [
        {
            "authors": [
                "Yoshua Bengio",
                "R\u00e9jean Ducharme",
                "Pascal Vincent",
                "Christian Jauvin."
            ],
            "title": "A neural probabilistic language model",
            "venue": "JMLR.",
            "year": 2003
        },
        {
            "authors": [
                "Mohamed Chabchoub",
                "Michel Gagnon",
                "Amal Zouaq."
            ],
            "title": "Collective disambiguation and semantic annotation for entity linking and typing",
            "venue": "Proceedings of SWEC.",
            "year": 2016
        },
        {
            "authors": [
                "Luciano Del Corro",
                "Abdalghani Abujabal",
                "Rainer Gemulla",
                "Gerhard Weikum."
            ],
            "title": "Finet: Context-aware fine-grained named entity typing",
            "venue": "Proceedings of EMNLP.",
            "year": 2015
        },
        {
            "authors": [
                "Li Dong",
                "Furu Wei",
                "Hong Sun",
                "Ming Zhou",
                "Ke Xu."
            ],
            "title": "A hybrid neural model for type classification of entity mentions",
            "venue": "Proceedings of IJCAI.",
            "year": 2015
        },
        {
            "authors": [
                "Dan Gillick",
                "Nevena Lazic",
                "Kuzman Ganchev",
                "Jesse Kirchner",
                "David Huynh."
            ],
            "title": "Contextdependent fine-grained entity type tagging",
            "venue": "arXiv preprint arXiv:1412.1820.",
            "year": 2014
        },
        {
            "authors": [
                "Sepp Hochreiter",
                "J\u00fcrgen Schmidhuber."
            ],
            "title": "Long short-term memory",
            "venue": "Neural computation.",
            "year": 1997
        },
        {
            "authors": [
                "Sanjeev Karn",
                "Ulli Waltinger",
                "Hinrich Sch\u00fctze."
            ],
            "title": "End-to-end trainable attentive decoder for hierarchical entity classification",
            "venue": "Proceedings of EACL.",
            "year": 2017
        },
        {
            "authors": [
                "Yankai Lin",
                "Shiqi Shen",
                "Zhiyuan Liu",
                "Huanbo Luan",
                "Maosong Sun."
            ],
            "title": "Neural relation extraction with selective attention over instances",
            "venue": "Proceedings of ACL.",
            "year": 2016
        },
        {
            "authors": [
                "Xiao Ling",
                "Daniel S Weld."
            ],
            "title": "Fine-grained entity recognition",
            "venue": "Proceedings of AAAI.",
            "year": 2012
        },
        {
            "authors": [
                "Tom\u00e1\u0161 Mikolov",
                "Martin Karafi\u00e1t",
                "Luk\u00e1\u0161 Burget",
                "Jan \u010cernock\u1ef3",
                "Sanjeev Khudanpur."
            ],
            "title": "Recurrent neural network based language model",
            "venue": "Proceedings of INTERSPEECH.",
            "year": 2010
        },
        {
            "authors": [
                "Mike Mintz",
                "Steven Bills",
                "Rion Snow",
                "Dan Jurafsky."
            ],
            "title": "Distant supervision for relation extraction without labeled data",
            "venue": "Proceedings of ACL.",
            "year": 2009
        },
        {
            "authors": [
                "Makoto Miwa",
                "Yutaka Sasaki."
            ],
            "title": "Modeling joint entity and relation extraction with table representation",
            "venue": "Proceedings of EMNLP.",
            "year": 2014
        },
        {
            "authors": [
                "Arvind Neelakantan",
                "Ming-Wei Chang."
            ],
            "title": "Inferring missing entity type instances for knowledge base completion: New dataset and methods",
            "venue": "Proceedings of NAACL.",
            "year": 2015
        },
        {
            "authors": [
                "Jeffrey Pennington",
                "Richard Socher",
                "Christopher Manning."
            ],
            "title": "Glove: Global vectors for word representation",
            "venue": "Proceedings of EMNLP.",
            "year": 2014
        },
        {
            "authors": [
                "Xiang Ren",
                "Wenqi He",
                "Meng Qu",
                "Lifu Huang",
                "Heng Ji",
                "Jiawei Han."
            ],
            "title": "Afet: Automatic finegrained entity typing by hierarchical partial-label embedding",
            "venue": "Proceedings of EMNLP.",
            "year": 2016
        },
        {
            "authors": [
                "Xiang Ren",
                "Wenqi He",
                "Meng Qu",
                "Clare R Voss",
                "Heng Ji",
                "Jiawei Han."
            ],
            "title": "Label noise reduction in entity typing by heterogeneous partial-label embedding",
            "venue": "Proceedings of KDD.",
            "year": 2016
        },
        {
            "authors": [
                "Alan Ritter",
                "Mausam",
                "Luke Zettlemoyer",
                "Oren Etzioni."
            ],
            "title": "Modeling missing data in distant supervision for information extraction",
            "venue": "TACL.",
            "year": 2013
        },
        {
            "authors": [
                "Mike Schuster",
                "Kuldip K Paliwal."
            ],
            "title": "Bidirectional recurrent neural networks",
            "venue": "IEEE Transactions on Signal Processing.",
            "year": 1997
        },
        {
            "authors": [
                "Sonse Shimaoka",
                "Pontus Stenetorp",
                "Kentaro Inui",
                "Sebastian Riedel."
            ],
            "title": "Neural architectures for fine-grained entity type classification",
            "venue": "Proceedings of EACL.",
            "year": 2017
        },
        {
            "authors": [
                "Martin Sundermeyer",
                "Ralf Schl\u00fcter",
                "Hermann Ney."
            ],
            "title": "Lstm neural networks for language modeling",
            "venue": "Proceedings of INTERSPEECH.",
            "year": 2012
        },
        {
            "authors": [
                "Shingo Takamatsu",
                "Issei Sato",
                "Hiroshi Nakagawa."
            ],
            "title": "Reducing wrong labels in distant supervision for relation extraction",
            "venue": "Proceedings of ACL.",
            "year": 2012
        },
        {
            "authors": [
                "Ji Xin",
                "Yankai Lin",
                "Zhiyuan Liu",
                "Maosong Sun."
            ],
            "title": "Improving neural fine-grained entity typing with knowledge attention",
            "venue": "Proceedings of AAAI.",
            "year": 2018
        },
        {
            "authors": [
                "Peng Xu",
                "Denilson Barbosa."
            ],
            "title": "Neural finegrained entity type classification with hierarchyaware loss",
            "venue": "Proceedings of NAACL.",
            "year": 2018
        },
        {
            "authors": [
                "Yadollah Yaghoobzadeh",
                "Hinrich Sch\u00fctze."
            ],
            "title": "Corpus-level fine-grained entity typing using contextual information",
            "venue": "Proceedings of EMNLP.",
            "year": 2015
        },
        {
            "authors": [
                "Mohamed Yahya",
                "Klaus Berberich",
                "Shady Elbassuoni",
                "Gerhard Weikum."
            ],
            "title": "Robust question answering over the web of linked data",
            "venue": "Proceedings of CIKM.",
            "year": 2013
        },
        {
            "authors": [
                "Limin Yao",
                "Sebastian Riedel",
                "Andrew McCallum."
            ],
            "title": "Universal schema for entity type prediction",
            "venue": "Proceedings of Workshop on AKBC.",
            "year": 2013
        },
        {
            "authors": [
                "Dani Yogatama",
                "Daniel Gillick",
                "Nevena Lazic."
            ],
            "title": "Embedding methods for fine grained entity type classification",
            "venue": "Proceedings of ACL.",
            "year": 2015
        },
        {
            "authors": [
                "Mohamed Amir Yosef",
                "Sandro Bauer",
                "Johannes Hoffart",
                "Marc Spaniol",
                "Gerhard Weikum."
            ],
            "title": "HYENA: Hierarchical type classification for entity names",
            "venue": "Proceedings of COLING.",
            "year": 2012
        },
        {
            "authors": [
                "Zheng Yuan",
                "Doug Downey."
            ],
            "title": "Otyper: A neural architecture for open named entity typing",
            "venue": "Proceedings of AAAI.",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 993\u2013998 Brussels, Belgium, October 31 - November 4, 2018. c\u00a92018 Association for Computational Linguistics\n993"
        },
        {
            "heading": "1 Introduction",
            "text": "Entity typing classifies semantic types of an entity mention in a context sentence, and can be beneficial for a large number of natural language processing tasks (Neelakantan and Chang, 2015), such as entity linking (Chabchoub et al., 2016), relation extraction (Miwa and Sasaki, 2014), and question answering (Yahya et al., 2013). Finegrained entity typing (FET) (Ling and Weld, 2012; Yosef et al., 2012; Yao et al., 2013; Gillick et al., 2014; Del Corro et al., 2015; Yogatama et al., 2015; Yaghoobzadeh and Schu\u0308tze, 2015; Ren et al., 2016a; Yuan and Downey, 2018) is based on a large set of fine-grained types and is therefore more challenging. So far, neural models (Dong et al., 2015; Shimaoka et al., 2017; Xin et al., 2018) have achieved state-of-the-art results on FET.\nAll current FET models rely on distant supervision (DS) (Mintz et al., 2009) to obtain training\n\u2217 Corresponding author: Zhiyuan Liu.\ndata, due to the lack of large-scale human-labeled data. Such reliance on DS has been a significant problem for entity typing. In DS, an entity mention in the context sentence is first linked to a named entity in the knowledge base (KB). The entity has type labels1 stored in the KB, and all labels will be assigned to this entity mention. In other words, these are noisy global labels without considering the specific context of the entity mention. On the other hand, entity typing aims to predict context-dependent types of the entity mention, and test datasets are all human-labeled. The difference between DS and human annotation leads to a huge gap in performances between training/development and test dataset.2\nTo address this problem, we propose Entity Typing with Language Model Enhancement (LME). It is able to measure the compatibility between the context sentence and each distantly supervised label, in an unsupervised manner using meaning of the label.\nIn previous works, the hierarchical structure of labels has been considered (Ren et al., 2016b; Karn et al., 2017; Xu and Barbosa, 2018). However, to the best of our knowledge, precious\n1 Since entities are classified into labels of types, type and label have the same meaning in this paper.\n2 In the WIKI dataset, strict accuracies and macro-F1 scores are respectively 72.3%/89.2% on the development set and 59.7%/79.0% on the test set, using the model NFGEC from (Shimaoka et al., 2017).\ninformation inside names of labels has never been used. For example, whether the label is /person/actor or /foo/bar makes no difference. We argue that, the meaning of entity mention words can also be expressed by the name of its context-dependent type, to some extent. Based on this argument, replacements with contextdependent types make more sense than those with global-but-context-irrelevant ones. We provide an example in Table 1. The entity Schwarzenegger has types /actor and /politician, and we can see that replacements with context-dependent types produce better sentences.\nThe natural way to evaluate the soundness of sentences is language modeling (Bengio et al., 2003; Mikolov et al., 2010). Our method employs a language model to evaluate the soundness of each synthetic sentence generated by replacing the entity mention with its type\u2019s name. It is able to focus more on context-dependent types.\nWe conduct experiments to compare our model with the state-of-the-art baseline on two widely used datasets. The results demonstrate that LME is capable of improving entity typing systems by considering the meaning of labels, and alleviating the problem of noise in distantly-supervised entity typing."
        },
        {
            "heading": "2 Model",
            "text": "Our model (Figure 1) consists of two parts: an entity typing (ET) module, and a language model enhancement (LME) module.\nET predicts a probability distribution vector y for an entity mention, where each entry yi represents the predicted probability for each type label.\nIn the training phase, LME optimizes a language model whose input includes y, and also back-propagates gradients through y to parameters inside ET. In the testing phase, LME is not involved and y is directly used for inference: if yi is greater than a threshold 0.5, the ith type is considered true; if all entries are below the threshold, the type with the greatest entry is considered true."
        },
        {
            "heading": "2.1 Entity Typing Module",
            "text": "Entity typing is defined on an ontology T (the set of all labels). Given an entity mention e and its context sentence s = {l1, l2, ..., e, r1, r2, ...} (li and ri are left and right context words), the typing model predicts a vector y indicating the probabil-\nity distribution over all labels in the ontology:\ny = \u03c3(Wy [vM ;vC ;vF ]), (1)\nwhere \u03c3 is the sigmoid function, Wy is a parameter matrix, and [; ; ] denotes concatenation. Three vectors: Mention, Context and Feature, are built from e and s as follows:\nEntity mention vector There may be multiple words e1, e2, ... in the entity mention, and vM is the average of word embeddings of these words.\nContext vector Two bi-directional LSTMs (Hochreiter and Schmidhuber, 1997; Schuster and Paliwal, 1997) are used for left and right context words. The outputs of BiLSTMs further go through a self-attention layer. vC is the concatenation of the attention-layer outputs.\nHand-crafted feature vector A sparse feature vector f is built from the entity mention e. The features are adopted from those used by Gillick et al. (2014) and Yogatama et al. (2015). vF is a dense projection of f :\nvF = Wf f , (2)\nwhere Wf is the projection matrix. After y is calculated, DS provides a label vector y\u2217 \u2208 {0, 1}|T |, where |T | is the number of labels. The loss function for typing is the cross-entropy\nbetween y and y\u2217:\nJtype = H(y \u2217,y) = \u2212 \u2211\ni y \u2217 i log(yi) + (1\u2212 y\u2217i ) log(1\u2212 yi),\n(3)"
        },
        {
            "heading": "2.2 Language Model Enhancement Module",
            "text": "The core part of the LME module is an LSTM language model (Sundermeyer et al., 2012). The language model takes a sentence {w1, w2, ..., wn} as input, and assigns a probability to this sentence. Concretely, at step i, the LSTM reads the word sub-sequence {w1, ..., wi}, and predicts the probability of wi+1 succeeding the sub-sequence. A well trained language model predicts high probability for a reasonable sentence.\nBefore applying the LME module to enhance the ET module, the language model is pre-trained with sentences from the training set. The loss function for s in the pre-train phase is:\nJpre = LM({l1, l2, ..., e, r1, r2, ...}), (4)\nwhere bold face letters are word embeddings for corresponding words. LM(\u00b7) is the language model loss function: accumulative step-wise logprobability of each word of the input sequence. A well-trained language model calculates smaller loss for a more reasonable sentence.\nAfter pre-training the language model, the LME module is combined with the ET module. Concretely, we assign an embedding vector Li for each label, and take the sum of label embeddings weighted by y. The sum h replaces e in the input sequence of the language model:\nh = \u2211T\ni=1 yiLi, (5)\nJlm = LM({l1, l2, ...,h, r1, r2, ...}), (6)\nwhere L is the matrix of all label embeddings, and Jlm is loss function of the language model used in the training phase. In order to ensure that label embeddings are in the same semantic space with word embeddings, L is initialized with word embeddings of the labels\u2019 names.\nIn the training phase, parameters of the ET module are updated w.r.t.\nJtrain = Jtype + \u03bbJlm, (7)\nwhere \u03bb is the weight to balance the loss. The ET module has a much smaller parameter space than the language model. In order to\nmake full use of the gradients, we only update parameters of the ET module and fix the language model in the training phase. Now that the language model is fixed, when Jlm is being minimized, it adjusts the probability distribution in y. If a label i is compatible with the context sentence, its corresponding entry yi is expected to have a high value. Gradients are back-propagated through y and update parameters of the ET module. In this way, y can learn to be more contextdependent."
        },
        {
            "heading": "3 Experiments",
            "text": ""
        },
        {
            "heading": "3.1 Dataset",
            "text": "We employ two well-established and widely-used dataset for evaluating our model: WIKI (Ling and Weld, 2012) and ONTONOTES (Gillick et al., 2014).\nTraining parts of both datasets are labeled with DS, and testing parts are annotated by human. Therefore they are suitable for evaluating how our model can narrow the gap between DS and ground-truth context-dependent labels. Statistics of the two datasets are provided in Table 2."
        },
        {
            "heading": "3.2 Experiment Settings",
            "text": "The baseline for comparison is the hybrid model NFGEC proposed by Shimaoka et al. (2017). It is described as the ET module of our model. Our own model is referred to as NFGEC+LME.\nWe implement our model based on the source code of NFGEC.3 For a fair comparison, the ET module is unchanged, including all hyperparameters and methods of parameter random initialization. Word embeddings are initialized with pretrained embeddings provided by Pennington et al. (2014).\nThere are a few additional hyperparameters in our model. The most important one is \u03bb, the weight between two parts of the loss function. Other ones include the learning rate r for pretraining the language model and the hidden size h of LSTM used in the language model. We perform\n3https://github.com/shimaokasonse/ NFGEC\na grid-search based on performances on the development set, and set r = 0.005 and h = 500. Details of \u03bb will be discussed in Section 3.4."
        },
        {
            "heading": "3.3 Overall Results",
            "text": "We compare vanilla NFGEC and NFGEC+LME in Table 3. The results of NFGEC come from the paper by Shimaoka et al. (2017). For running NFGEC+LME, \u03bb is set to 0.005 in WIKI and 0.001 in ONTONOTES.\nEvaluation metrics include strict accuracy, macro-F1 score and micro-F1 score (Ling and Weld, 2012).\nFrom the results we see that: (1) In both datasets, LME consistently helps NFGEC to better classify entity mentions into their context-dependent types. We can see improvements in all metrics. This is because LME is capable of evaluating the appropriateness of each label and distinguishing context-dependent ones from global-but-context-irrelevant ones. Therefore LME helps the system to focus on more reasonable types.\n(2) Among all metrics, the improvement on strict accuracy is the most significant. Strict accuracy is the proportion of entity mentions whose predicted types are completely identical with human annotation. It is therefore the most important metric for evaluating how robust the system is against noisy labels. The ability of LME alleviating noises from DS contributes to improving strict accuracy most."
        },
        {
            "heading": "3.4 Analysis of \u03bb",
            "text": "We choose the optimal \u03bb values for results in Table 3 according to their performances on the development set. After they are chosen, we compare the results on the test set under different values of \u03bb in Figure 2.\nConclusions from the previous subsection can be seen again: when \u03bb is set to a proper value, our model can consistently outperform the baseline over all metrics; strict accuracy is the metric with the most significant improvements.\nAlso, we notice that the performances deteriorate when \u03bb grows too large, and may even be worse than the baseline. The reason is that LME is a kind of regularization: its role is only in the training phase, exchanging the performance on training set with that on test set. So \u03bb, as a regularization coefficient, must be carefully chosen."
        },
        {
            "heading": "3.5 Qualitative Analysis",
            "text": "In order to have an intuitive feeling of the model, we provide an example of LME\u2019s effect.\nIn the following sentence (from the test set of WIKI), both models try to predict the type of Lake Placid which, in this very context, is a town in New York. We show all labels with at least one score over the threshold 0.5, or is annotated true by human in Table 4.\nNFGEC predicts a high score for /person and a low score for /location, probably because both words of the entity mention are firstletter capitalized and thus look like a person\u2019s name. LME, however, may consider the sentence structure person of location to be more reasonable than person of person, and makes the\ncorrect judgment between these two labels. As for /location/city, LME also shows higher confidence than NFGEC, but it is still regretfully below the threshold. This also demonstrates a weakness of LME: limited by the performance of the ET module. Addressing this limitation can be considered as a future direction for improvement."
        },
        {
            "heading": "4 Conclusion",
            "text": "In this paper, we propose a novel architecture LME to improve entity typing systems. It utilizes a language model and a set of label embeddings to judge the compatibility between labels and context sentences, and reduces noises introduced by DS. Experiments demonstrate that LME is capable of helping NFGEC, a state-of-the-art entity typing model, to alleviate the problem of noisy labels, and reaching a new state-of-the-art performance. Since the LME module does not depend on the ET module, we are confident that LME can be adapted to other entity typing systems as well.\nFuture Work Utilizing meaning of labels to alleviate the problem of noises from DS is an interesting direction. We make the first attempt in this paper, and we believe the direction is worth further exploring. For example, (1) how to train a language model that is sensitive with incorrect labels; (2) how to combine meaning of labels with the hierarchical structure of types; (3) how to find the optimal \u03bb easily for a new dataset. LME may also be extended to other tasks that also suffer from noises and incompleteness of DS, such as relation extraction (Takamatsu et al., 2012; Ritter et al., 2013; Lin et al., 2016). However, since a relation does not have a specific location in the sentence, it needs more effort than a simple replacement."
        },
        {
            "heading": "Acknowledgment",
            "text": "This work is supported by the 973 Program (No. 2014CB340501), the National Natural Science Foundation of China (NSFC No. 61572273, 61661146007) and Tsinghua University Initiative Scientific Research Program (20151080406). This work is also funded by China Association for Science and Technology (2016QNRC001). We also thank anonymous reviewers for their insightful suggestions."
        }
    ],
    "title": "Put It Back: Entity Typing with Language Model Enhancement",
    "year": 2018
}