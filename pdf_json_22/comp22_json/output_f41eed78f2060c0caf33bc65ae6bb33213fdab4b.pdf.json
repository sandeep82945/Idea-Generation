{
    "abstractText": "Research on the similarity of a graph to being a tree\u2014called the treewidth of the graph\u2014has seen an enormous rise within the last decade, but a practically fast algorithm for this task has been discovered only recently by Tamaki (ESA 2017). It is based on dynamic programming and makes use of the fact that the number of positive subinstances is typically substantially smaller than the number of all subinstances. Algorithms producing only such subinstances are called positive-instance driven (PID). The parameter treedepth has a similar story. It was popularized through the graph sparsity project and is theoretically well understood\u2014but the first practical algorithm was discovered only recently by Trimble (IPEC 2020) and is based on the same paradigm. We give an alternative and unifying view on such algorithms from the perspective of the corresponding configuration graphs in certain two-player games. This results in a single algorithm that can compute a wide range of important graph parameters such as treewidth, pathwidth, and treedepth. We complement this algorithm with a novel randomized data structure that accelerates the enumeration of subproblems in positive-instance driven algorithms.",
    "authors": [
        {
            "affiliations": [],
            "name": "Max Bannach"
        },
        {
            "affiliations": [],
            "name": "Sebastian Berndt"
        }
    ],
    "id": "SP:778f7fede9733c1a62843f0ec80124c0bccbf43c",
    "references": [
        {
            "authors": [
                "S. Kreutzer"
            ],
            "title": "Algorithmic Meta-Theorems",
            "venue": "Electron. Colloq. Comput. Complex. (ECCC) 2009,",
            "year": 2009
        },
        {
            "authors": [
                "J. Berg",
                "M. J\u00e4rvisalo",
                "B. Malone"
            ],
            "title": "Learning optimal bounded treewidth Bayesian networks via maximum satisfiability",
            "venue": "In Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics, Reykjavik, Iceland,",
            "year": 2014
        },
        {
            "authors": [
                "A. Darwiche"
            ],
            "title": "A differential approach to inference in Bayesian networks",
            "venue": "J. ACM (JACM)",
            "year": 2003
        },
        {
            "authors": [
                "G. Elidan",
                "S. Gould"
            ],
            "title": "Learning bounded treewidth Bayesian networks",
            "venue": "J. Mach. Learn. Res. 2008,",
            "year": 2008
        },
        {
            "authors": [
                "J. Kneis",
                "A. Langer",
                "P. Rossmanith"
            ],
            "title": "Courcelle\u2019s theorem\u2014A game-theoretic approach",
            "venue": "Discret. Optim. 2011,",
            "year": 2011
        },
        {
            "authors": [
                "M. Bannach",
                "S. Berndt"
            ],
            "title": "Practical Access to Dynamic Programming on Tree Decompositions",
            "venue": "Algorithms 2019,",
            "year": 2022
        },
        {
            "authors": [
                "P. Bjesse",
                "J.H. Kukula",
                "R.F. Damiano",
                "T. Stanion",
                "Y. Zhu"
            ],
            "title": "Guiding SAT Diagnosis with Tree Decompositions",
            "venue": "In Proceedings of the International Conference on Theory and Applications of Satisfiability Testing",
            "year": 2003
        },
        {
            "authors": [
                "J.K. Fichte",
                "M. Hecher",
                "S. Woltran",
                "M. Zisser"
            ],
            "title": "Weighted Model Counting on the GPU by Exploiting Small Treewidth",
            "venue": "In Proceedings of the 26th Annual European Symposium on Algorithms (ESA 2018),",
            "year": 2018
        },
        {
            "authors": [
                "D. Habet",
                "L. Paris",
                "C. Terrioux"
            ],
            "title": "A Tree Decomposition Based Approach to Solve Structured SAT Instances",
            "venue": "In Proceedings of the 2009 21st IEEE International Conference on Tools with Artificial Intelligence,",
            "year": 2009
        },
        {
            "authors": [
                "G. Charwat",
                "S. Woltran"
            ],
            "title": "Dynamic Programming-based QBF Solving",
            "venue": "In Proceedings of the QBF 2016, Bordeaux, France,",
            "year": 2016
        },
        {
            "authors": [
                "S. Karakashian",
                "R.J. Woodward",
                "B.Y. Choueiry"
            ],
            "title": "Improving the Performance of Consistency Algorithms by Localizing and Bolstering Propagation in a Tree Decomposition",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2013
        },
        {
            "authors": [
                "A.M.C.A. Koster",
                "S.P.M. van Hoesel",
                "A.W.J. Kolen"
            ],
            "title": "Solving partial constraint satisfaction problems with tree decomposition. Networks",
            "year": 2002
        },
        {
            "authors": [
                "F. Eisenbrand",
                "C. Hunkenschr\u00f6der",
                "K. Klein"
            ],
            "title": "Faster Algorithms for Integer Programs with Block Structure",
            "venue": "In Proceedings of the 45th International Colloquium on Automata, Languages, and Programming (ICALP 2018), Prague, Czech Republic,",
            "year": 2018
        },
        {
            "authors": [
                "R. Ganian",
                "S. Ordyniak",
                "M.S. Ramanujan"
            ],
            "title": "Going Beyond Primal Treewidth for (M)ILP",
            "venue": "In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence,",
            "year": 2017
        },
        {
            "authors": [
                "R. Ganian",
                "S. Ordyniak"
            ],
            "title": "The complexity landscape of decompositional parameters for ILP",
            "venue": "Artif. Intell",
            "year": 2018
        },
        {
            "authors": [
                "M. Kouteck\u00fd",
                "A. Levin",
                "S. Onn"
            ],
            "title": "A Parameterized Strongly Polynomial Algorithm for Block Structured Integer Programs",
            "venue": "In Proceedings of the 45th International Colloquium on Automata, Languages, and Programming (ICALP 2018), Prague, Czech Republic,",
            "year": 2018
        },
        {
            "authors": [
                "S. Szeider"
            ],
            "title": "On Fixed-Parameter Tractable Parameterizations of SAT",
            "venue": "In Proceedings of the Theory and Applications of Satisfiability Testing",
            "year": 2003
        },
        {
            "authors": [
                "M. Bannach",
                "S. Berndt",
                "T. Ehlers"
            ],
            "title": "Jdrasil: A Modular Library for Computing Tree Decompositions",
            "venue": "In Proceedings of the 16th International Symposium on Experimental Algorithms (SEA 2017),",
            "year": 2017
        },
        {
            "authors": [
                "A. Bonifati",
                "W. Martens",
                "T. Timm"
            ],
            "title": "An analytical study of large SPARQL query logs",
            "venue": "VLDB J. 2020,",
            "year": 2020
        },
        {
            "authors": [
                "J.M. Dudek",
                "V.H.N. Phan",
                "M.Y. Vardi"
            ],
            "title": "DPMC: Weighted Model Counting by Dynamic Programming on Project-Join Trees",
            "venue": "In Proceedings of the Principles and Practice of Constraint Programming\u201426th International Conference,",
            "year": 2020
        },
        {
            "authors": [
                "J.M. Dudek",
                "V.H.N. Phan",
                "M.Y. Vardi"
            ],
            "title": "ProCount: Weighted Projected Model Counting with Graded Project-Join Trees",
            "venue": "In Proceedings of the Theory and Applications of Satisfiability Testing\u2014SAT 2021\u201424th International Conference,",
            "year": 2021
        },
        {
            "authors": [
                "T. Korhonen",
                "M. J\u00e4rvisalo"
            ],
            "title": "Integrating Tree Decompositions into Decision Heuristics of Propositional Model Counters (Short Paper)",
            "venue": "In Proceedings of the 27th International Conference on Principles and Practice of Constraint Programming,",
            "year": 2021
        },
        {
            "authors": [
                "S. Maniu",
                "P. Senellart",
                "S. Jog"
            ],
            "title": "An Experimental Study of the Treewidth of Real-World Graph Data",
            "venue": "In Proceedings of the 22nd International Conference on Database Theory, ICDT 2019,",
            "year": 2019
        },
        {
            "authors": [
                "G.Z. Gutin",
                "M. Jones",
                "M. Wahlstr\u00f6m"
            ],
            "title": "Structural Parameterizations of the Mixed Chinese Postman Problem",
            "venue": "In Proceedings of the Algorithms\u2014ESA 2015\u201423rd Annual European Symposium, Patras, Greece,",
            "year": 2015
        },
        {
            "authors": [
                "Y. Iwata",
                "T. Ogasawara",
                "N. Ohsaka"
            ],
            "title": "On the Power of Tree-Depth for Fully Polynomial FPT Algorithms",
            "venue": "In Proceedings of the 35th Symposium on Theoretical Aspects of Computer Science,",
            "year": 2018
        },
        {
            "authors": [
                "C. Brand",
                "M. Kouteck\u00fd",
                "S. Ordyniak"
            ],
            "title": "Parameterized Algorithms for MILPs with Small Treedepth",
            "venue": "In Proceedings of the Thirty-Fifth AAAI Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "T. Bl\u00e4sius",
                "P. Fischbeck",
                "T. Friedrich",
                "M. Katzmann"
            ],
            "title": "Solving Vertex Cover in Polynomial Time on Hyperbolic Random Graphs",
            "venue": "In Proceedings of the 37th International Symposium on Theoretical Aspects of Computer Science,",
            "year": 2020
        },
        {
            "authors": [
                "F.V. Fomin",
                "A.C. Giannopoulou",
                "M. Pilipczuk"
            ],
            "title": "Computing Tree-Depth Faster Than 2n",
            "venue": "Algorithmica 2015,",
            "year": 2022
        },
        {
            "authors": [
                "F. Reidl",
                "P. Rossmanith",
                "F.S. Villaamil",
                "S. Sikdar"
            ],
            "title": "A Faster Parameterized Algorithm for Treedepth",
            "venue": "In Proceedings of the Automata, Languages, and Programming\u201441st International Colloquium,",
            "year": 2014
        },
        {
            "authors": [
                "H.L. Bodlaender"
            ],
            "title": "A Linear-Time Algorithm for Finding Tree-Decompositions of Small Treewidth",
            "venue": "SIAM J. Comput",
            "year": 1996
        },
        {
            "authors": [
                "H. R\u00f6hrig"
            ],
            "title": "Tree Decomposition: A Feasibility Study",
            "venue": "Master\u2019s Thesis, Max-Planck-Institut fu\u0308r Informatik in Saarbru\u0308cken, Saarbru\u0308cken, Germany,",
            "year": 1998
        },
        {
            "authors": [
                "V. Gogate",
                "R. Dechter"
            ],
            "title": "A Complete Anytime Algorithm for Treewidth",
            "venue": "In Proceedings of the UAI\u201904, 20th Conference in Uncertainty in Artificial Intelligence, Banff, AB, Canada,",
            "year": 2004
        },
        {
            "authors": [
                "D. Coudert",
                "D. Mazauric",
                "N. Nisse"
            ],
            "title": "Experimental Evaluation of a Branch-and-Bound Algorithm for Computing Pathwidth and Directed Pathwidth",
            "venue": "ACM J. Exp. Algorithmics 2016,",
            "year": 2016
        },
        {
            "authors": [
                "J. Trimble"
            ],
            "title": "An Algorithm for the Exact Treedepth Problem",
            "venue": "In Proceedings of the 18th International Symposium on Experimental Algorithms,",
            "year": 2020
        },
        {
            "authors": [
                "M. Hamann",
                "B. Strasser"
            ],
            "title": "Graph Bisection with Pareto Optimization",
            "venue": "ACM J. Exp. Algorithmics",
            "year": 2018
        },
        {
            "authors": [
                "H.L. Bodlaender",
                "A.M.C.A. Koster"
            ],
            "title": "Treewidth computations I",
            "venue": "Upper bounds. Inf. Comput",
            "year": 2010
        },
        {
            "authors": [
                "H. Tamaki"
            ],
            "title": "Computing Treewidth via Exact and Heuristic Lists of Minimal Separators",
            "venue": "In Proceedings of the Analysis of Experimental Algorithms\u2014Special Event,",
            "year": 2019
        },
        {
            "authors": [
                "Y. Kobayashi",
                "K. Komuro",
                "H. Tamaki"
            ],
            "title": "Search Space Reduction through Commitments in Pathwidth Computation: An Experimental Study",
            "venue": "In Proceedings of the Experimental Algorithms\u201413th International Symposium, SEA 2014, Copenhagen, Denmark,",
            "year": 2014
        },
        {
            "authors": [
                "Fernando S\u00e1nchez Villaamil"
            ],
            "title": "About Treedepth and Related Notions",
            "venue": "Ph.D. Thesis, RWTH Aachen University, Aachen,",
            "year": 2017
        },
        {
            "authors": [
                "K. Kask",
                "A. Gelfand",
                "L. Otten",
                "R. Dechter"
            ],
            "title": "Pushing the Power of Stochastic Greedy Ordering Schemes for Inference in Graphical Models",
            "venue": "In Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence,",
            "year": 2011
        },
        {
            "authors": [
                "H. Dell",
                "T. Husfeldt",
                "B. Jansen",
                "P. Kaski",
                "C. Komusiewicz",
                "F. Rosamond"
            ],
            "title": "The First Parameterized Algorithms and Computational Experiments Challenge",
            "venue": "In Proceedings of the 11th International Symposium on Parameterized and Exact Computation (IPEC 2016),",
            "year": 2016
        },
        {
            "authors": [
                "H. Dell",
                "C. Komusiewicz",
                "N. Talmon",
                "M. Weller"
            ],
            "title": "The PACE 2017 Parameterized Algorithms and Computational Experiments Challenge: The Second Iteration",
            "venue": "In Proceedings of the 12th International Symposium on Parameterized and Exact Computation (IPEC 2017), Vienna, Austria,",
            "year": 2017
        },
        {
            "authors": [
                "L. Kowalik",
                "M. Mucha",
                "W. Nadara",
                "M. Pilipczuk",
                "M. Sorge",
                "P. Wygocki"
            ],
            "title": "The PACE 2020 Parameterized Algorithms and Computational Experiments Challenge: Treedepth",
            "venue": "In Proceedings of the 15th International Symposium on Parameterized and Exact Computation,",
            "year": 2020
        },
        {
            "authors": [
                "Tamaki",
                "H. Treewidth-Exact"
            ],
            "title": "Available online: github.com/TCS-Meiji/treewidth-exact (accessed on 2 August 2017)",
            "year": 2016
        },
        {
            "authors": [
                "L. Larisch",
                "F. Salfelder"
            ],
            "title": "Available online: https://github.com/freetdi/p17 (accessed on 2 August 2017)",
            "year": 2017
        },
        {
            "authors": [
                "J. Trimble"
            ],
            "title": "PACE Solver Description: Bute-Plus: A Bottom-Up Exact Solver for Treedepth",
            "venue": "In Proceedings of the 15th International Symposium on Parameterized and Exact Computation, IPEC 2020 (Virtual Conference), Hong Kong, China,",
            "year": 2020
        },
        {
            "authors": [
                "M. Bannach",
                "S. Berndt",
                "M. Schuster"
            ],
            "title": "Wien\u00f6bst, M. PACE Solver Description: PID",
            "venue": "In Proceedings of the 15th International Symposium on Parameterized and Exact Computation, IPEC 2020 (Virtual Conference), Hong Kong, China,",
            "year": 2020
        },
        {
            "authors": [
                "S. Arnborg",
                "D.G. Corneil",
                "A. Proskurowski"
            ],
            "title": "Complexity of finding embeddings in ak-tree",
            "venue": "SIAM J. Algebr. Discret. Methods",
            "year": 1987
        },
        {
            "authors": [
                "V. Bouchitt\u00e9",
                "I. Todinca"
            ],
            "title": "Listing all potential maximal cliques of a graph",
            "venue": "Theor. Comput. Sci",
            "year": 2002
        },
        {
            "authors": [
                "H. Tamaki"
            ],
            "title": "Positive-instance driven dynamic programming for treewidth",
            "venue": "J. Comb. Optim",
            "year": 2019
        },
        {
            "authors": [
                "E. Althaus",
                "D. Schnurbusch",
                "J. W\u00fcschner",
                "S. Ziegler"
            ],
            "title": "On Tamaki\u2019s Algorithm to Compute Treewidths",
            "venue": "In Proceedings of the 19th International Symposium on Experimental Algorithms, SEA 2021,",
            "year": 2021
        },
        {
            "authors": [
                "F.V. Fomin",
                "D. Kratsch"
            ],
            "title": "Exact Exponential Algorithms; Texts in Theoretical Computer Science, An EATCS Series",
            "year": 2010
        },
        {
            "authors": [
                "R. Halin"
            ],
            "title": "S-functions for graphs",
            "venue": "J. Geom. 1976,",
            "year": 1976
        },
        {
            "authors": [
                "N. Robertson",
                "P.D. Seymour"
            ],
            "title": "Graph minors. I. Excluding a forest",
            "venue": "JCT J. Comb. Theory",
            "year": 1983
        },
        {
            "authors": [
                "N. Robertson",
                "P.D. Seymour"
            ],
            "title": "Graph Minors. II. Algorithmic Aspects of Tree-Width",
            "venue": "Algorithms",
            "year": 1986
        },
        {
            "authors": [
                "P. Seymour",
                "R. Thomas"
            ],
            "title": "Graph Searching and a Min-Max Theorem for Tree-Width",
            "venue": "JCT J. Comb. Theory",
            "year": 1993
        },
        {
            "authors": [
                "L. Kirousis",
                "C. Papadimitriou"
            ],
            "title": "Searching and Pebbling",
            "venue": "TCS Theor. Comput. Sci",
            "year": 1986
        },
        {
            "authors": [
                "A. Giannopoulou",
                "P. Hunter",
                "D. Thilikos"
            ],
            "title": "LIFO-search: A min-max theorem and a searching game for cycle-rank and tree-depth",
            "venue": "Discret. Appl. Math. 2012,",
            "year": 2022
        },
        {
            "authors": [
                "F. Fomin",
                "P. Fraigniaud",
                "N. Nisse"
            ],
            "title": "Nondeterministic Graph Searching: From Pathwidth to Treewidth",
            "year": 2009
        },
        {
            "authors": [
                "H. Tamaki"
            ],
            "title": "Experimental Analysis of Treewidth. In Treewidth, Kernels, and Algorithms\u2014Essays Dedicated to Hans L",
            "venue": "Bodlaender on the Occasion of His 60th Birthday; Springer: Berlin/Heidelberg, Germany,",
            "year": 2020
        },
        {
            "authors": [
                "T. Korhonen"
            ],
            "title": "PACE Solver Description: SMS",
            "venue": "In Proceedings of the 15th International Symposium on Parameterized and Exact Computation, IPEC 2020 (Virtual Conference), Hong Kong, China,",
            "year": 2020
        },
        {
            "authors": [
                "R. Brokkelkamp",
                "R. van Veneti\u00eb",
                "M.J. de Vries",
                "J. Westerdiep"
            ],
            "title": "PACE Solver Description: TdULL",
            "venue": "In Proceedings of the 15th International Symposium on Parameterized and Exact Computation, IPEC 2020 (Virtual Conference), Hong Kong, China,",
            "year": 2020
        },
        {
            "authors": [
                "N. Lodha",
                "S. Ordyniak",
                "S. Szeider"
            ],
            "title": "A SAT Approach to Branchwidth",
            "venue": "ACM Trans. Comput. Log",
            "year": 2019
        },
        {
            "authors": [
                "V.P. Ramaswamy",
                "S. Szeider"
            ],
            "title": "MaxSAT-Based Postprocessing for Treedepth",
            "venue": "In Proceedings of the Principles and Practice of Constraint Programming\u201426th International Conference,",
            "year": 2020
        },
        {
            "authors": [
                "R. Ganian",
                "N. Lodha",
                "S. Ordyniak",
                "S. Szeider"
            ],
            "title": "SAT-Encodings for Treecut Width and Treedepth",
            "venue": "In Proceedings of the TwentyFirst Workshop on Algorithm Engineering and Experiments,",
            "year": 2019
        },
        {
            "authors": [
                "N. Lodha",
                "S. Ordyniak",
                "S. Szeider"
            ],
            "title": "SAT-Encodings for Special Treewidth and Pathwidth",
            "venue": "In Proceedings of the Theory and Applications of Satisfiability Testing\u2014SAT 2017\u201420th International Conference, Melbourne, Australia,",
            "year": 2017
        },
        {
            "authors": [
                "M. Samer",
                "H. Veith"
            ],
            "title": "Encoding Treewidth into SAT",
            "venue": "In Proceedings of the Theory and Applications of Satisfiability Testing\u2014SAT",
            "year": 2009
        },
        {
            "authors": [
                "J. Berg",
                "M. J\u00e4rvisalo"
            ],
            "title": "SAT-Based Approaches to Treewidth Computation: An Evaluation",
            "venue": "In Proceedings of the 26th IEEE International Conference on Tools with Artificial Intelligence, Limassol, Cyprus,",
            "year": 2014
        },
        {
            "authors": [
                "M. Bannach",
                "S. Berndt"
            ],
            "title": "Positive-Instance Driven Dynamic Programming for Graph Searching",
            "venue": "In Proceedings of the Algorithms and Data Structures\u201416th International Symposium,",
            "year": 2019
        },
        {
            "authors": [
                "M. Safari"
            ],
            "title": "D-Width: A More Natural Measure for Directed Tree Width",
            "venue": "In Proceedings of the Mathematical Foundations of Computer Science",
            "year": 2005
        },
        {
            "authors": [
                "D. Bienstock"
            ],
            "title": "Graph Searching, Path-Width, Tree-Width and Related Problems (A Survey)",
            "venue": "In Proceedings of the Reliability of Computer and Communication Networks, Proceedings of a DIMACS Workshop,",
            "year": 1989
        },
        {
            "authors": [
                "H. Gruber",
                "M. Holzer"
            ],
            "title": "Finite Automata, Digraph Connectivity, and Regular Expression Size",
            "venue": "In Proceedings of the International Colloquium on Automata, Languages, and Programming, Reykjavik, Iceland,",
            "year": 2008
        },
        {
            "authors": [
                "D. Bienstock",
                "P.D. Seymour"
            ],
            "title": "Monotonicity in Graph Searching",
            "venue": "J. Algorithms",
            "year": 1991
        },
        {
            "authors": [
                "A. LaPaugh"
            ],
            "title": "Recontamination Does Not Help to Search a Graph",
            "year": 1993
        },
        {
            "authors": [
                "F. Mazoit",
                "N. Nisse"
            ],
            "title": "Monotonicity of non-deterministic graph searching",
            "venue": "TCS Theor. Comput. Sci",
            "year": 2008
        },
        {
            "authors": [
                "A.B. Kahn"
            ],
            "title": "Topological sorting of large networks",
            "venue": "Commun. ACM 1962,",
            "year": 1962
        },
        {
            "authors": [
                "W. Evans",
                "P. Hunter",
                "M. Safari"
            ],
            "title": "D-Width and Cops and Robbers",
            "venue": "Technical Report,",
            "year": 2007
        },
        {
            "authors": [
                "I. Savnik"
            ],
            "title": "Index Data Structure for Fast Subset and Superset Queries",
            "venue": "In Proceedings of the 5th International Cross-Domain Conference on Vailability, Reliability, and Security in Information Systems and HCI, Regensburg, Germany,",
            "year": 2013
        },
        {
            "authors": [
                "J. Flum",
                "M. Grohe"
            ],
            "title": "Parameterized Complexity Theory; Texts in Theoretical Computer Science, An EATCS Series",
            "year": 2006
        },
        {
            "authors": [
                "A.M.C.A. Koster",
                "H.L. Bodlaender",
                "S.P.M. van Hoesel"
            ],
            "title": "Treewidth: Computational Experiments",
            "venue": "Electron. Notes Discret. Math. 2001,",
            "year": 2001
        },
        {
            "authors": [
                "L. Gugelmann",
                "K. Panagiotou",
                "U. Peter"
            ],
            "title": "Random Hyperbolic Graphs: Degree Sequence and Clustering\u2014(Extended Abstract)",
            "venue": "In Proceedings of the Automata, Languages, and Programming\u201439th International Colloquium,",
            "year": 2012
        },
        {
            "authors": [
                "T. Bl\u00e4sius",
                "T. Friedrich",
                "A. Krohmer"
            ],
            "title": "Hyperbolic Random Graphs: Separators and Treewidth",
            "venue": "In Proceedings of the 24th Annual European Symposium on Algorithms, Aarhus, Denmark,",
            "year": 2016
        },
        {
            "authors": [
                "R. Aldecoa",
                "C. Orsini",
                "D.V. Krioukov"
            ],
            "title": "Hyperbolic graph generator",
            "venue": "Comput. Phys. Commun",
            "year": 2015
        },
        {
            "authors": [
                "B. Courcelle"
            ],
            "title": "On the model-checking of monadic second-order formulas with edge set quantifications",
            "venue": "Discret. Appl. Math",
            "year": 2012
        },
        {
            "authors": [
                "H.L. Bodlaender",
                "S. Kratsch",
                "V.J.C. Kreuzen",
                "O. Kwon",
                "S. Ok"
            ],
            "title": "Characterizing width two for variants of treewidth",
            "venue": "Discret. Appl. Math",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "Citation: Bannach, M.; Berndt, S.\nRecent Advances in Positive-Instance\nDriven Graph Searching. Algorithms\n2022, 15, 42. https://doi.org/\n10.3390/a15020042\nAcademic Editors: Frank Werner and\nCarla Piazza\nReceived: 15 November 2021\nAccepted: 24 January 2022\nPublished: 27 January 2022\nPublisher\u2019s Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished maps and institutional affil-\niations.\nCopyright: \u00a9 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: treewidth; pathwidth; treedepth; graph searching; positive-instance driven; color coding"
        },
        {
            "heading": "1. Introduction",
            "text": "Graph decompositions are an important tool in modern algorithmic graph theory that provide a structured representation of a graph. A graph decomposition comes along with a width measure that indicates how well a graph can be decomposed. Many problems that presumably cannot be solved in polynomial time on general graphs can be solved efficiently on graphs that admit a certain decomposition of small width [1]. The most prominent example of a width measure is treewidth, which (on an intuitive level) measures the similarity of a graph to a tree. This parameter is a cornerstone of parameterized algorithms [2] and its success has led to its integration into many different fields. For instance, treewidth has been studied in the context of machine learning [3\u20135], modelchecking [6,7], SAT-solving [8\u201310], QBF-solving [11,12], CSP-solving [13,14], or ILPS [15\u201319]. Tools such as Jdrasil [20] that compute tree decompositions of minimum width or that try to find good heuristic solutions are actively used, for instance, in the analysis of large SPARQL query logs [21] or in propositional model counting [22\u201324]. A large-scale experimental study that classifies real-world data sets according to their treewidth was recently performed by Maniu, Senellart, and Jog [25]. However, treewidth is often too general and we require more restrictive width measures in order to obtain an algorithmic advantage [26,27]. Close relatives of treewidth are the width measures pathwidth and treedepth, which (again on an intuitive level) measure the similarity of the graph to a path or a star, respectively. These graph parameters can be naturally ordered in the sense that some of them are more restrictive than others, that is, a graph of bounded treedepth has bounded pathwidth as well, and a graph of bounded pathwidth has also bounded treewidth. Tools that compute treedepth decompositions of\nAlgorithms 2022, 15, 42. https://doi.org/10.3390/a15020042 https://www.mdpi.com/journal/algorithms\nAlgorithms 2022, 15, 42 2 of 33\nsmall width can be used to efficiently solve the mixed Chinese postman problem [26] or to design algorithms for mixed integer linear programs [28]. Pathwidth was recently used as structural parameter to prove that the well-known vertex cover problem can be solved in polynomial time with high probability on hyperbolic random graphs (which are frequently used to model real-world networks) [29]. No matter which of these width measures we wish to utilize for a task at hand, we have to be able to compute it quickly. More crucially, most algorithms also need a witness in the form of a decomposition. A lot of theoretical research has been performed in this direction [30,31] and width measures such as treewidth can even be computed in linear fpt-time by Bodlaender\u2019s famous algorithm [32]. Unfortunately, it is known that this algorithm does not work in practice due to huge constants [33] (the same holds for similar algorithms for the other width measures). When it comes to implementations, small progress has been made with classical exact exponential time algorithms, which are only able to solve graphs with about 50\u2013100 vertices. See, for instance, the QuickBB algorithm for treewidth [34], the algorithm by Coudert, Mazauric, and Nisse for pathwidth [35], or a recent branch-and-bound algorithm for treedepth [36]. More progress was made with heuristics, see, for instance, [37\u201339] for treewidth, the algorithm by Kobayashi et al. for pathwidth [40], and Section 24 in [41] for treedepth. We may argue that, indeed, a heuristic is sufficient, as the attached solver will work correctly independently of the width of the provided decomposition\u2014and the heuristic may produce a decomposition of \u201csmall enough\u201d width. However, even a small error, something as \u201coff by 5\u201d, may put the parameter to a computationally intractable range, as the dependency on the width is usually at least exponential. For instance, it was observed that small changes (even by just one or two) in the width of a tree decomposition can have a huge impact on the inference time in probabilistic networks [42]. A similar effect was observed in recent advances of implementing a lightweight model checker for a fragment of MSO [7], where it turned out to be beneficial to invest additional time in order to obtain an optimal tree decomposition rather than relying on faster heuristics. It is therefore a natural and important task to build practical fast algorithms to determine parameters such as the treewidth, pathwidth, or treedepth of a graph exactly. To tackle this issue, the fpt-community came up with a contest, the Parameterized Algorithms and Computational Experiments (PACE) challenge [43\u201345], with the goal of finding new exact algorithms to determine the exact treewidth or treedepth of a graph. Besides many, one important result of the challenge was a new combinatorial algorithm due to Tamaki, which computes the treewidth of an input graph exactly and astonishingly fast on a wide range of instances. An implementation of this algorithm by Tamaki himself [46] won the corresponding track in the PACE challenge in 2016 [43] and an alternative implementation due to Larisch and Salfelder [47] won in 2017 [44]. In 2020, many participants adapted the original algorithm to treedepth [45,48,49]. Tamaki\u2019s original algorithm is based on a dynamic program by Arnborg, Corneil, and Proskurowski [50] for computing tree decompositions. This algorithm has a game theoretic characterization that can be used to generalize the algorithm to other width measures such as treedepth. Tamaki has improved his algorithm for the second iteration of the PACE by applying his framework to the algorithm by Bouchitt\u00e9 and Todinca [51,52], see, for instance, [53] for a recent evaluation of this version of the algorithm. While Bouchitt\u00e9 and Todinca\u2019s algorithm has a game theoretic characterization as well [54], it is still unclear how it can be generalized to other width measures. We focus on Tamaki\u2019s first algorithm and characterize it in a unifying way that allows us to compute not just the treewidth of a graph but, with the same algorithm, the pathwidth, treedepth, q-branched treewidth, and dependency treewidth as well. Perhaps even more importantly, our description of the algorithm in a game theoretic framework is simple and intuitive and can be implemented quite directly. In fact, our treewidth and treedepth solvers Jdrasil and PID? are based on this characterization [20,49]. The detailed contributions of this paper are the following:\nAlgorithms 2022, 15, 42 3 of 33\nContribution I: A Simple Description of Tamaki\u2019s First Algorithm. We describe Tamaki\u2019s algorithm as a well-known graph searching game. This provides a link to known theory and allows us to analyze the algorithm in depth. Contribution II. Extending Tamaki\u2019s Algorithm to Other Parameters The game theoretic point of view allows us to extend the algorithm naturally to various other parameters\u2014including pathwidth and treedepth. Contribution III: A Novel Randomized Data Structure. The bottleneck in positive-instance driven algorithms is the enumeration of already computed solutions. We present a lazily constructed randomized data structure that, in contrast to existing data structures for this task, provides a guarantee that certain useless solutions are not enumerated with high probability."
        },
        {
            "heading": "1.1. Related Work",
            "text": "The concepts of pathwidth and treewidth were rediscovered several times in the literature [55\u201357]. Treedepth was discovered and analyzed by Ne\u0161etr\u030cil and de Mendez in their study of sparsity [58]. The game theoretic characterization of treewidth goes back to Seymour and Thomas [59]. Kirousis and Papadimitriou have studied a similar game for pathwidth [60], and Giannopoulou, Hunter and Thilikos have studied game theoretic approaches for treedepth [61]. The generalized version of this game, which we will use in this paper, was introduced by Fomin, Fraigniaud, and Nisse [62]. The potential success of positive-instance driven algorithms was demonstrated by Tamaki, who implemented a positive-instance driven version of Arnborg, Corneil, and Proskurowski\u2019s treewidth algorithm for the PACE 2016 [46]. This algorithm outperformed all other submissions (including one by the authors) by far [43]. The winning algorithm of the PACE 2017 also \u201cis basically Hisao Tamakis implementation\u201d [44,47]. Tamaki later adapted his algorithm to the algorithm by Bouchitt\u00e9 and Todinca in his pioneering work introducing positive-instance driven dynamic programming [52]. Ongoing research constantly improves the performance of this version of the algorithm [39,53,63]. Positive-instance driven dynamic programming also played a key role in many submissions for the PACE 2020, where the goal was to compute the treedepth of a graph rather than the treewidth [45], for instance, in the winning submission by Trimble [48]. However, it should be noted that in contrast to treewidth, the dominance of positive-instance driven algorithms compared to other strategies (such as enumerating minimal separators [64,65]) was less dramatic for the computation of treedepth [45]. Besides the development of dedicated algorithms for these graph parameters, there is also ongoing research in implementing a unifying way of computing all these parameters using SAT or MAXSAT solvers. See, for instance, [20,66\u201371]."
        },
        {
            "heading": "1.2. Organization of This Paper",
            "text": "We provide some preliminaries about graphs and their decompositions in Section 2. We then invite the reader, in Section 3, to a gentle introduction to positive-instance driven graph searching with the example of computing the treedepth of a graph\u2014while not directly necessary for the remaining paper, this section should make it easier to follow the more general approach presented later on. Section 4 lifts the game theoretic approach to a unifying algorithm that allows us to compute not just the treewidth or treedepth of a given graph but also its pathwidth and dependency treewidth. The somewhat technical proof of Theorem 2 is only sketched within the main text and we dedicate Appendix A to fill in the details. After the main part of the paper, in Section 5 we identify a bottleneck of the positiveinstance driven graph searching approach that was observed experimentally in various solvers. We extend a known data structure used by such algorithms, called block sieve, with a randomized component based on the well-known color coding technique. We illustrate the gained performance exemplarily in our treedepth solver PID? in Section 6.\nWe conclude our findings and discuss further research directions in Section 7.\nAlgorithms 2022, 15, 42 4 of 33"
        },
        {
            "heading": "1.3. Difference to the Conference Paper",
            "text": "This paper is an extended version of our paper Positive-Instance Driven Dynamic Programming for Graph Searching presented at WADS 2019 [72]. In the conference version, we already presented the unifying approach now discussed in Section 4. Because of this, the structure and content of this section have barely changed. In the present work, we improve the presentation of the algorithm and extend the approach further to directed treewidth (Section 4.6). A new contribution, compared to [72], is the gentle introduction to positive-instance driven graph searching in Section 3. It is based on insights we gained during the development of our treedepth solver PID? [49] and its aim is to help the reader in following the more general algorithm presented later. A new technical contribution is the lazily constructed randomized data structure (dubbed color coding sieve) presented in Section 5. The most expensive part of a positiveinstance driven algorithm (be it for treewidth, treedepth, or any other width measure) is the enumeration of already computed positive subproblems that are compatible with each other [20,48,49,52,63]. Previous solvers use a data structure called block sieves to accelerate this process, which are basically set tries that store the positive subproblems and that can prune some non-compatible elements during the enumeration process. However, set tries are cumbersome and do not provide any guarantees on the number of non-compatible elements that actually get pruned. Our color coding sieves, in contrast, are (i) much more compact, as they are lazily constructed, (ii) use randomization to provide a guarantee that non-compatible elements are pruned with high probability, and (iii) allow a trade-off between the time spend in the data structure and the amount of elements that will be pruned. We extend this theoretical analysis by an implementation of the data structure in our treedepth solver PID? and an experimental evaluation (Sections 6)."
        },
        {
            "heading": "2. Preliminaries: Graphs and Their Decompositions",
            "text": "A digraph G = (V(G), E(G)) is a tuple containing a set V(G) of vertices and a binary edge relation E(G) \u2286 { (v, w) | v 6= w \u2227 v, w \u2208 V }. The neighborhood of a vertex v \u2208 V(G) is defined as NG(v) = {w | (v, w) \u2208 E(G) } and we define NG[v] = NG(v) \u222a {v}. For a set X \u2286 V, we write NG(X) = \u222ax\u2208X N(x) and G \\ X = (V(G) \\ X, E(G) \\ { e \u2208 E(G) | X \u2229 e 6= \u2205 }) for the graph obtained by deleting the vertices in X from G. The subgraph induced by X is defined as G[X] = G \\ (V(G) \\ X). If G is clear from the context, we may simply refer to V(G) and E(G) as V and E, respectively, and we may drop the subscript \u201cG\u201d in the other definitions. A graph is undirected if its edge relation is symmetric and we may write abbreviations like {u, v} \u2208 E instead of (u, v), (v, u) \u2208 E for such graphs.\nGraph Decompositions\nLet G = (V, E) be an undirected graph. A tree decomposition (T, \u03b9) of G is a tree T and a mapping \u03b9 from the nodes of T to subsets of V (which we call bags) such that (i) for every v \u2208 V, the set { x | v \u2208 \u03b9(x) } is non-empty and connected in T, and (ii) for every edge {v, w} \u2208 E there is a node y in T with {v, w} \u2286 \u03b9(y). The width of a tree decomposition is the maximum size of one of its bags minus one. The treewidth tw(G) is the minimum width over all tree decompositions of G and its pathwidth pw(G) is the minimum width over all tree decompositions of G in which T is a path. Furthermore, its treedepth td(G) is the minimum width over all tree decompositions in which T can be rooted in such a way that for all nodes x, y of T we have \u03b9(x) ( \u03b9(y) if y is a descendant of x. Finally, its q-branched treewidth twq(G) is the minimum width over all tree decompositions of G that can be rooted such that there are at most q vertices with more than one descendant on any root-leaf path. Intuitively, the treewidth of a graph measures how similar the graph is \u201cto being a tree\u201d, in the same sense pathwidth measures the similarity to a path and treedepth the similarity to a star. The q-branched treewidth allows to study the phase transition between the pathwidth and the treewidth of a graph. Loosely speaking, we can study the trade-off between the width of a decomposition and its \u201ccomplexity\u201d. A path decomposition has the\nAlgorithms 2022, 15, 42 5 of 33\nhighest width, but it is not \u201ccomplex\u201d. In contrast, a tree decomposition has the smallest width but may be arbitrary \u201ccomplex\u201d, as it may contain a large number of nodes of high degree. It is well known that we have tw(G) \u2264 pw(G) \u2264 td(G) \u2264 tw(G) \u00b7 log2 n [58] and, by definition, we have tw(G) = tw\u221e(G) and pw(G) = tw0(G). Figure 1 shows an example graph with multiple tree decompositions that minimize the various invariants defined above. Another important variant of these parameters is dependency treewidth, which is used primarily in the context of quantified Boolean formulas [12]. Intuitively, this notion captures the idea that vertices in the graph are dependent on each other and thus need to be processed in a certain order. More formally, for a graph G = (V, E) and a partial order l of V, the dependency treewidth dtw(G) is the minimum width of any tree decomposition (T, \u03b9) with the following property: Consider the natural partial order \u2264T that T induces on its nodes, where the root is the smallest elements and the leaves form the maximal elements; define for any v \u2208 V the node Fv(T) that is the \u2264T-minimal node t with v \u2208 \u03b9(t) (which is well defined); then define a partial order <T on V such that u <T v if, and only if, Fu(T) \u2264T Fv(T); finally, for all u, v \u2208 V, it must hold that Fu(T) <T Fv(T) implies that u l v does not hold. There are multiple generalizations of treewidth for digraphs. We will use the so-called D-width, which was introduced by Safari [73] and is based on D-decompositions. Such a decomposition is a tuple (T, \u03b9) as above, but with the conditions that (i) for every strongly connected subset S \u2286 V there is at least one x in T with \u03b9(x) \u2229 S 6= \u2205, and (ii) the subgraph of T induced by { {x, y} | \u03b9(x) \u2229 \u03b9(y) \u2229 S 6= \u2205 } is connected. The D-width of a digraph G, denoted by tw (G), is the minimal width of any D-decomposition of G."
        },
        {
            "heading": "3. A Gentle Introduction to Positive-Instance Driven Graph Searching",
            "text": "Before we describe a unifying algorithm that can compute all the graph decompositions shown in Figure 1, we will illustrate the positive-instance driven graph searching technique in a simpler example. Our goal in this section is to describe a game theoretic positiveinstance driven algorithm for the width measure treedepth alone. For that end, let us use the following equivalent definition of this parameter: the treedepth of a graph G = (V, E) is the minimum height of a rooted forest F such that G is a subgraph of the closure of F. This forest is called a treedepth decomposition of G. Since the treedepth of a graph is the maximum treedepth of its connected components, we can restrict ourselves to connected graphs. In this case, a treedepth decomposition of G is an elimination tree.\nAlgorithms 2022, 15, 42 6 of 33"
        },
        {
            "heading": "3.1. Graph Searching",
            "text": "Many graph decompositions have game theoretic characterizations in the form of vertex pursuit-evasion games [74]. Such games, which are also known as graph searching or cops and robber, are played by two players on an undirected graph G = (V, E). In the game for treedepth, the first player places a team of k searchers iteratively on the vertices of G, while the second player controls a single fugitive that hides in a connected component. The game is played in rounds as follows [61,75]: Initially, the fugitive hides in the vertex set C = V (which we assume to be connected). The vertices in C are said to be contaminated. In each round, both players perform one action:\n1. The searchers pick a vertex v \u2208 C on which they want to place the next searcher. We say they clean the vertex v. 2. The fugitive responds by picking a component C\u2032 of G[C \\ {v}]. The contaminated area is reduced to C\u2032 and the game proceeds only on this subgraph.\nThe game ends when the contaminated area shrinks to the empty set or if the searchers have placed all k members of their team and C is still non-empty. In the first case, the graph was cleaned and the fugitive was caught; in the second case, the fugitive escaped. The searchers win if they catch the fugitive, otherwise the fugitive wins. Note that in this version of the game, the searchers are not allowed to remove an already placed searcher from the graph. The game is therefore monotone and always ends after, at most, k rounds. Further observe that the fugitive is visible in the sense that the searchers know in which connected component she hides\u2014in contrast, an invisible fugitive could hide in subgraphs that are not connected (which notably complicates the arguments). The game is illustrated in Figure 2 on a small graph with eight vertices.\nVersion December 12, 2021 submitted to Algorithms 6 of 30\nGraph Searching. Many graph decompositions have game theoretic characteriza-231 tions in the form of vertex pursuit-evasion games [75]. Such games, which are also known232 as graph searching or cops and robber, re played by two players on an undirected graph233 G = (V, E). In t e gam for treedepth, the first player places a team of k se chers itera-234 tively on the vertices of G, while the second player controls a single fugitive that hides in235 a connected component. The game is played in rounds as follows [62,76]: Initially, the236 fugitive ides in t vertex set C = V (which we assume to be connected). The vertices237 in C are said to be contaminat d. In each round, both players perform one action:238\n1. The searchers pick a vertex v 2 C on which they want to place the next searcher.239 We s y they clean the vertex v.240 2. The fugitive responds by picking a component C0 of G[C \\ {v}]. The contaminated241 area is reduced to C0 and the game proceeds only on this subgraph.242\nThe game ends when the contaminated area shrinks to the empty set, or if the searchers243 have placed all k members of their team and C is still non-empty. In the first case the244 graph was cleaned and the fugitive was caught, in the second case the fugitive escaped.245 The earchers win if they catch the fugitive, otherwise the fugitive wins. Note that in246 this version of t e game, the searc rs are not all wed to remove an already placed247 searcher from the graph. The game is therefore monotone and always ends after at most248 k rounds. Further observe that the fugitive is visible in the sense that the searchers know249 in which connected component she hides \u2013 in contrast, an invisible fugitive could hide250 in subgraphs that are not connected (which notably complicates the arguments). The251 game is illustrated in Figure 2 on a small graph with 8 vertices.252\nFigure 2. An illustration of the graph searching game for treedepth on the 8 vertex graph shown at the very top. Vertices that contain a green dot are currently contaminated. The searchers will place a searcher on the vertex with a red circle in the next round. The cleaned vertices (on which a searcher stands) are filled with blue. The arrows indicate the various choices of the fugitive. The diagram proves that 4 searchers have a winning strategy on this specific graph.\nWe call the configurations of this game blocks, which are tuple (C, r) with r 2 N253 and C \u2713 V being a connected subgraph with |N(C)| + r  k. Informally, C is the254 contaminated area (which is connected), and r is the number of remaining searchers.255 We require |N(C)| + r  k as the neighborhood of C has to be cleaned in order to have256\nigure 2. An illustration of the gr p searching game for treedepth on the 8 vertex graph shown at\nthe very top. Vertices that contain a green dot are currently contaminated. The searchers will place a\nsearcher on the vertex with a red circle in the next round. The cleaned vertices (on which a searcher\nstands) are filled with blue. The arrows indicate the various choices of the fugitive. The diagram\nproves that 4 searchers have a winning strategy on this specific graph.\nThe configurations of this game are blocks, which are tuple (C, \u03c1) with \u03c1 \u2208 N and C \u2286 V being a connected subgraph with |N(C)|+ \u03c1 \u2264 k. Informally, C is the (connected) contaminated area, and \u03c1 is the number of remaining searchers. We require |N(C)|+ \u03c1 \u2264 k as the neighborhood of C has to be cleaned in order to have C as contaminated area. We denote the set of blocks of the game played on a graph G with k searchers by B(G, k). Two\nAlgorithms 2022, 15, 42 7 of 33\nblocks (C1, \u03c11) and (C2, \u03c12) intersect if C1 \u2229 C2 6= \u2205, NG(C1) \u2229 C2 6= \u2205 or C1 \u2229 NG(C2) 6= \u2205. The start configuration of the game is (V, k) and the winning configurations for the searchers are (\u2205, \u03c1 \u2265 0). We say the searchers have a winning strategy on a block (C, \u03c1) if, starting with configuration (C, \u03c1), they can ensure to reach a winning configuration no matter how the fugitive acts. The set of blocks that guarantee such a strategy is the winning region, which we denote byR(G, k) \u2286 B(G, k)\u2014the elements in this region are said to be positive. The connection between the game and the width measure treedepth is established by the following fact:\nFact 1 ([61]). Let G = (V, E) be a graph and k \u2208 N. Then (V, k) \u2208 R(G, k)\u21d0\u21d2 td(G) \u2264 k."
        },
        {
            "heading": "3.2. Simple Positive-Instance Driven Graph Searching",
            "text": "By Fact 1, it is sufficient to compute the set R(G, k) in order to test whether the treedepth of G is at most k. One way of doing so would be to first compute B(G, k), then build an auxiliary graph on top of this set, and finally compute R(G, k) by solving reachability queries on this auxiliary graph. We can estimate the number of configurations with | B(G, k)| \u2264 (k + 1) \u00b7 nk+1, as there are nk possible ways of placing k searchers on an n-vertex graph\u2014at most n connected components adjacent to a separator\u2014and we have \u03c1 \u2208 {0, . . . , k}. Therefore, the sketched algorithm achieves a run time of nO(k), which is not feasible in practice for even moderate values of k. To make the game theoretic approach feasible, we present an output-sensitive algorithm that computes just R(G, k)\u2014 without \u201ctouching\u201d the rest of B(G, k). Figure 3 illustrates why we may hope thatR(G, k) is smaller than B(G, k). In the remainder of this section, we will develop some intuition about how to compute the setR(G, k). The formal details are postponed to the unifying version of the algorithm in the next section.\nVersion November 12, 2021 submitted to Algorithms 6 of 27\nthis version of the game, the searchers are not allowed to remove an already placed213 searcher from the graph. The game is therefore monotone and always ends after at most214 k rounds. Further observe that the fugitive is visible in the sense that the searchers know215 in which connected component she hides \u2013 in contrast, an invisible fugitive could hide216 in subgraphs that are not connected (which notably complicates the arguments).217 We call the configurations of this game blocks, which are tuple (C, r) with r 2 N218 and C \u2713 V being a connected subgraph with |N(C)| + r  k. Informally, C is the219 contaminated area (which is connected), and r is the number of remaining searchers. We220 require |N(C)| + r  k as the neighborhood of C has to be cleaned in order to have C221 as contaminated area. Let us denote the set of all blocks of the game played on a graph222 G with a eam of k searchers by B(G, k). Two blocks (C1, r1) and (C2, r2) intersect if223 C1 \\ C2 6= \u2206, NG(C1) \\ C2 6= \u2206, or C1 \\ N (C2) 6= \u2206. The start configuration of the game224 is the block (V, k) and the winning configurations for the searchers are (\u2206, r 0). We225 say the searchers have a winning strategy on a block (C, r) if, starting with configuration226 (C, r), they can ensure to reach a winning configuration no matter how the fugitive acts.227 The set of blocks that guarantee such a strategy is the winning region, which we denote228 by R(G, k) \u2713 B(G, k) \u2013 the elements in this region are said to b positive.229 It is known that a graph has treedepth k if, and only if, k searchers have a winning230 strategy in the game defined above. In our notation we can express this fact as follows:231\nFact 1 ([55]). Let G = (V, E) be a graph and k 2 N. Then (V, k) 2 , k) () td(G)  k.232\n3.1. Simple Positive-Instance Driven Graph Searching233 By Fact 1 it is sufficient to compute the set R(G, k) in order to test whether the234 treedepth of G is at most k. One way of doing so would be to first compute B(G, k), then235 build an auxiliary graph on top of this set, and finally com ute R(G, k) by solving reach-236 ability queries on this auxiliary graph. We can estimate the number of configurations237 with | B(G, k)|  (k + 1) \u00b7 nk+1, as there are nk possible ways of placing k searchers on an238 n-vertex graph; at most n connected components adjacent to a separator; and we have239 r 2 {0, . . . , k}. Therefore, the sketched algorithm achieves a run time of nO(k), which is240 not feasible in practice for even moderate values of k.241 In order to make the game theoretic approach feasible, we present an output-sensitive242 algorithm th t com utes just R( , k) \u2013 without \u201ctouching\u201d the rest of B(G, k). Figure 3243 illustrates why we may hope that R(G, k) is smaller than B(G, k). In the remainder of244 this section we will develop some intuition about how to compute the set R(G, k). The245 formal details are postponed to the unifying version of the algorithm in the next section.246\nSurely, we can not start at some block, say (V, k), and just simulate the game in a247 top-down fashion \u2013 we could touch a lot of blocks in B(G, k) \\ R(G, k) without even248 noticing it (in Figure 3 that would mean starting a graph traversal from s, which could249 explore any leg of the spider). After all, we do not know whether (V, k) 2 R(G, k). We250\nSurely, we cannot start at some block, say (V, k), and just simulate the game in a topdown fashion\u2014we could touch a lot of blocks in B(G, k) \\ R(G, k) without even noticing it (in Figure 3, that would mean starting a graph traversal from s, which could explore any leg of the spider). After all, we do not know whether (V, k) \u2208 R(G, k). We do know, however, that (\u2205, 0) is a winning configuration (vertex t in Figure 3). So, let us start with the set R = { (\u2205, 0) } and then try to grow it toR(G, k) in a bottom-up fashion. We can first ask which configurations of the game lead to (\u2205, 0), i. e., what are configurations in which the searchers immediately win in the next round? These are the configurations ({v}, 1) with |N(v)| < k, as in these the searchers can surround the fugitive and have a searcher left to place it on top of her (in Figure 3, this corresponds to the predecessor of t). Now, assume that we have currently a setR \u2286 R(G, k) that had already grown a little. What does a configuration (C, \u03c1) \u2208 R(G, k) \\ R that is \u201cclose to\u201d R look like (that is, we wish to traverse the s-t-path of Figure 3 in reverse direction)? The set C is connected by definition and, since the searchers have a winning strategy from (C, \u03c1), there is a vertex v \u2208 C such that G[C \\ {v}] has connected components C1, . . . , Cq (q = 1 is possible) with (Ci, \u03c1 \u2212 1) \u2208 R for all i \u2208 {1, . . . , q}. To find (C, \u03c1), we first guess the vertex v, scan\nAlgorithms 2022, 15, 42 8 of 33\nthe sets of pairwise non-intersecting blocks X \u2286 { (C\u2032, \u03c1\u2032) \u2208 R | v \u2208 NG(C\u2032) \u2227 \u03c1\u2032 < \u03c1 }, and generate the new blocks (\u22c3 (C\u2032 ,\u03c1\u2032)\u2208X C\u2032 \u222a {v}, 1 + max(C\u2032 ,\u03c1\u2032)\u2208X \u03c1\u2032 ) . Note that we can\nprune a set X if \u2223\u2223(NG(\u22c3(C\u2032 ,\u03c1\u2032)\u2208X C\u2032)\u2223\u2223 > k\u2212max(C\u2032 ,\u03c1\u2032)\u2208X \u03c1\u2032, as this neighborhood has to be\ncleaned by the searchers before they clean one of the components C\u2032. This will be utilized by the randomized data structure that we develop later in Section 5. Figure 4 illustrates this step of the algorithm, which we call a glue operation. We refer the reader who is interested in the details of implementing this algorithm for treedepth efficiently to the description of our solver PID? [49]. In the next section, we present a formal and more general version of the sketched strategy\u2014which does not just work for treedepth, but for treewidth, pathwidth and many other width measures, too.23:6 Engineering an Exact Algorithm for Treedepth\nFigure 2 The glue operation of a positive-instance driven algorithm. We currently handle the block (C, fl) and have guessed a neighbor v \u0153 N(C) and the set X = { (C1, fl1), (C2, fl2) } with fli \u00c6 fl. Note that all blocks are adjacent to v and are pairwise non-intersecting, e. g., N [C] fl C1 = \u00ff. The combined neighborhood is highlighted. This area is not allowed to be larger than k \u2260 fl, as the searchers must clean it before they can proceed the search on one of the blocks. From this situation, we generate the block (C fiC1 fiC2 fi {v}, fl + 1), if the neighborhood of this set is at most k\u2260 fl \u2260 1.\nIn order to e ciently implement the algorithm, we manage a priority queue of newly174 discovered blocks. We process the blocks in increasing order of fl \u2013 that is, we handle175 subgraphs of smaller treedepth first. The complete algorithm is presented in Listing 1 and176 its correctness is proven in Theorem 4.177\nListing 1 The core positive-instance driven algorithm tailored towards treedepth. It obtains as input a graph G and a number k, and outputs the set R(G, k). We assume that the set R\u00d5, the priority queue, and some data structure to mark already explored subgraphs C (for instance a hash set) are available in global memory.\n178 1INPUT: graph G = (V,E) and number k \u0153 N179 2OUTPUT: a set R = R(G, k)180 3181 4// in global memory182 5R\u00d5 \u03a9 empty set of blocks183 6queue \u03a9 priority queue of blocks (C, fl) ordered by fl184 7185 8function pid()186 9// configurations leading to (\u00ff, 0)187 10for v in V do188 11if |N(v)| < k then189 12insert ({v}, 1) into queue190 13end191 14end192 15193 16// compute the set R\u00d5 \u2122 R(G, k)194 17while queue is not empty extract a block (C, fl) and do195 18if C was already visited then continue end196 19mark C as visited197 20198 21// compute predecessor configurations199 22for v in N(C) do200 23for X \u2122 { (C\u00d5, fl\u00d5) \u0153 R\u00d5 | v \u0153 N(C\u00d5) \u00b7N [C] fl C\u00d5 = \u00ff \u00b7 fl\u00d5 \u00c6 fl } do201 24// assert: blocks in X are pairwise non -intersecting202 25if |N(C fi t (C\u00d5,fl\u00d5)\u0153X C\n\u00d5 fi {v})| \u00c6 k \u2260 fl \u2260 1 then203 26insert (C fi t (C\u00d5,fl\u00d5)\u0153X C\n\u00d5 fi {v}, fl + 1) into queue204 27end205"
        },
        {
            "heading": "3.3. Alternative Characterization",
            "text": "Let us briefly sketch an i rpretation of the algorithm without the game theoretic point of view. One can think of it as a procedure that, given a connected graph G = (V, E), list ever growing ree epth decomposi ion of subgraphs of G. In detail, a collection Td of trees of depth at most d for some d \u2265 1 is managed\u2014starting with the trivial trees of depth 1 (i. e., single vertices) we have T1 \u2286 V. Then, for ever larger d, the set Td is computed by picking a new root r \u2208 V and a collection of previously computed trees S \u2286 \u22c3d\u22121i=1 Ti, and by arranging the trees of S to a new tree by connecting their roots to r. Of course, in order to obtain a valid treedepth decomposition, the elements of S must be pairwise disjoint and non-adjacent. The selection of the set S is what was the glue operation and what will be a universal step in the algorithm presented in the next section, and the value d corresponds to k \u2212 \u03c1 and will be the distance that we will compute. Let us stress out that, in this characterization, the trees in S are, indeed, trees and thus connected. This is an invariant that the following algorithm cannot guarantee for all parameters but which improves the performance of the algorithm if met."
        },
        {
            "heading": "3.4. Execution Modes",
            "text": "It is worth noting that positive-instance driven algorithms only solve the problem for a fixed k. Hence, to obtain an optimal treedepth decomposition (or any other decomposition), one has to run the algorithm for various values of k. The order in which these values are tested is called the execution mode of the algorithm. Positive-instance driven algorithms differ from other strat gies with respect to values that are \u201ceasy\u201d. For instance, branch-andbound algorithms usually solve the problem quickly if k overestimates the optimal value. However, overestimating k means more positive subproblems, making these instances hard for positive-instance driven algorithms. On the other hand, underestimating the optimal value yields instances that are usually hard but that are solved quickly by positive-instance driven algorithms as there are only few positive instances. Positive-instance driven graph searching is, thus, especially suited to compute lower bounds [63]. Therefore, the typical execution mode is to start with k = 1 and to increase this lower bound until either an optimal solution was found or a heuristically obtained upper bound is met [48,49].\nAlgorithms 2022, 15, 42 9 of 33"
        },
        {
            "heading": "4. A Unifying Take on Positive-Instance Driven Graph Searching",
            "text": "Our goal is to generalize the algorithm that we just sketched in Section 3.2 to other graph measures such as treewidth and pathwidth. When we generalize from treedepth to other parameters, there are two main obstacles that we have to face. First, the sketched algorithm for treedepth \u201cguessed\u201d a root vertex in every iteration and glued already computed blocks to it. In more flexible graph decompositions such as tree decompositions, the root no longer is a single vertex but a set of up to k vertices. Clearly, we cannot guess such a set and, hence, have to compute it implicitly. Second, the treedepth algorithm explicitly carried the number of remaining searchers \u03c1 around (they were part of the blocks). In more flexible graph measures, we may remove and reuse already placed searchers and, thus, have to encode this information in a different way. We will handle this issue by splitting the computation into two phases, where the first phase mainly computes a configuration graph (intuitively, this graph contains blocks for various values of \u03c1) and where the second phase then computes distances in this configuration graph (hence, computes best possible \u03c1-values for the blocks). However, let us postpone the fiddling with distance queries to Section 4.5 and focus solely on the more general search game in the first part of this section. We study graph searching in a setting proposed by Fomin, Fraigniaud, and Nisse [62]. The input is again an undirected graph G = (V, E) and a number k \u2208 N, and the question is whether a team of k searchers can catch an invisible fugitive on G by the following set of rules: At the beginning, the fugitive picks a connected component C of G in which she hides\u2014since the fugitive is invisible, in contrast to Section 3.2, the game is continued on G and not on G[C] and we say that the set V is contaminated. In each round, the player now follows a similar procedure as in the previous game, but the searchers have a larger set of possible moves:\n1. The searchers perform one of the following:\n\u2022 Place a searcher on a contaminated vertex; \u2022 Remove a searcher from a vertex; \u2022 Reveal the current position of the fugitive.\n2. The fugitive responds as follows:\n\u2022 If the searchers place or remove a searcher, the fugitive adapts her connected component by adding or removing the vertex, respectively. (This may join multiple components or disconnect the current component, in which case the fugitive selects one of the resulting connected components). \u2022 If the searchers perform a reveal, the fugitive responds by uncovering her current connected component C. The contaminated area is reduced to C.\nWe follow the same terminology as before, i. e, we say a contaminated vertex becomes clean if a searcher is placed on it. In contrast to the previous game, a vertex v may now become recontaminated if a searcher is removed from it and there is a contaminated vertex adjacent to v. The searchers win the game if they manage to clean all vertices, i. e., if they catch the fugitive; the fugitive wins if, at any point, a recontamination occurs or if she can escape infinitely long. Note that this implies that the searchers have to catch the fugitive in a monotone way. A priori, one could assume that the later condition gives the fugitive an advantage (recontamination could be necessary for the cleaning strategy); however, a crucial result in graph searching is that \u201crecontamination does not help\u201d in all variants of the game that we consider [59,61,76\u201378]."
        },
        {
            "heading": "4.1. Entering the Arena and the Colosseum",
            "text": "Our primary goal is to determine whether the searchers have a winning strategy. A folklore algorithm for this task is to construct an alternating graph called the arena: arena(G, k) = ((Vs \u222a Vf ), Earena) that contains for each position of the searchers (S \u2286 V with |S| \u2264 k) and each position of the fugitive ( f \u2208 V) two copies of the vertex (S, f ), one in Vs and one in Vf (see, for instance, Section 7.4 in [2]). Vertices in Vs correspond to a configuration in which the searchers perform the next move (they are existential)\nAlgorithms 2022, 15, 42 10 of 33\nand vertices in Vf correspond to fugitive moves (they are universal). The edges Earena are constructed according to all possible moves. The question is now whether there is an alternating path from a start configuration to some configuration in which the fugitive is caught. Since alternating paths can be computed in linear time ([79], Section 3.4), we immediately obtain an O(nk+1) algorithm. Modeling a configuration of the game as tuple (S, f ) comes, however, with a major drawback: The size of the arena does directly depend on n and k and does not depend on some further structure of the input. For instance, the arena of a path of length n and any other graph on n vertices will have the same size for any fixed value k. As the major goal of parameterized complexity is to gain insight into structural parameters beyond the input size n, such a fixed-size approach is not what we are looking for. A bit counter intuitive, we will tackle this problem by, firstly, defining an alternating graph that is larger than the arena: the colosseum. As it befits for any good colosseum, it is not only larger but, in particular, \u201cprettier\u201d than the arena (which here means that it adapts to the input structure of the graph). Once we can capture the structure in the colosseum, we will introduce yet another alternating graph that, finally, is actually small. This graph, which will be a subset of the colosseum, is called the pit\u2014where only true champions can survive!"
        },
        {
            "heading": "4.2. Simplifying the Game",
            "text": "Before we define all the locations of potential gladiator fights in graph theoretic terms, let us start with some simplifications of the game. We restrict the fugitive as follows: Since she is invisible, there is no need for her to take regular actions. Instead, the only moment when she is actually active is when the searchers perform a reveal. If C is the set of contaminated vertices, consisting of the induced components C1, . . . , C`, a reveal will uncover the component in which the fugitive hides and, as a result, reduce C to Ci for some 1 \u2264 i \u2264 `. The only task of the fugitive is to answer a reveal with such a number i. The complete process of the searcher performing a reveal, the fugitive answering it, and finally of reducing C to Ci is called a reveal-move. We also restrict the searchers by the concept of implicit searcher removal. Let S \u2286 V(G) be the set of vertices currently occupied by the searchers, and let C \u2286 V(G) be the set of contaminated vertices. We call a vertex v \u2208 S covered if every path between v and C contains a vertex w \u2208 S with w 6= v.\nLemma 1. A covered searcher can be removed safely.\nProof. As we have N(v)\u2229 C = \u2205, the removal of v will not increase the contaminated area. Furthermore, v cannot be recontaminated at a later point, unless a neighbor of v becomes recontaminated as well (in which case the game would already be over).\nLemma 2. Only covered searchers can be removed safely.\nProof. Since for any other vertex w \u2208 S we have N(w) \u2229 C 6= \u2205, the removal of w would recontaminate w and, hence, would result in a defeat of the searchers.\nBoth lemmas together imply that the searchers never have to decide to remove a searcher but rather can do it implicitly. We restrict the possible moves of the searchers to a combined move of placing a searcher and immediately removing searchers from all covered vertices. This is called a fly-move. Observe that the sequence of original moves mimicked by a fly-move does not contain a reveal and, thus, may be performed independently of any action of the fugitive."
        },
        {
            "heading": "4.3. Building the Colosseum",
            "text": "We are now ready to define the colosseum. As for the arena, we could define it as an alternating graph. However, as only the searchers perform actions in the simplified game,\nAlgorithms 2022, 15, 42 11 of 33\nwe find it more natural to express this game as an edge-alternating graph\u2014a generalization of alternating graphs. An edge-alternating graph is a triple H = (V, E, A) consisting of a vertex set V, an existential edge relation E \u2286 V\u00d7V, and a universal edge relation A \u2286 V\u00d7V. The neighborhoods of a vertex v are the existential neighborhood N\u2203(v) = {w | (v, w) \u2208 E }, the universal neighborhood N\u2200(v) = {w | (v, w) \u2208 A }, and the complete neighborhood NH(v) = N\u2203(v) \u222a N\u2200(v). An edge-alternating s-t-path is a set P \u2286 V such that (i) s, t \u2208 P and (ii) for all v \u2208 P with v 6= t we have either N\u2203(v) \u2229 P 6= \u2205 or \u2205 6= N\u2200(v) \u2286 P or both. We write s \u227a t if such a path exists and define R(Q) = { v | v \u2208 Q \u2228 (\u2203w \u2208 Q : v \u227a w) } for Q \u2286 V as the set of vertices on edge-alternating paths leading to Q. We say that an edge-alternating s-t-path P is q-branched if (i) H is acyclic and (ii) every (classical) directed path \u03c0 from s to t in H with \u03c0 \u2286 P uses at most q universal edges.\nFor G = ( V(G), E(G) ) and k \u2208 N, the colosseum(G, k) is the edge-alternating graph\nH with V(H) = {C | \u2205 6= C \u2286 V(G) and |NG(C)| \u2264 k } and the following edge sets: for all pairs C, C\u2032 \u2208 V(H) there is an existential edge e = (C, C\u2032) \u2208 E(H) if, and only if, C \\ {v} = C\u2032 for some v \u2208 C and |NG(C)| < k; furthermore, for all C \u2208 V(H) with at least two components C1, . . . , C` we have universal edges (C, Ci) \u2208 A(H). The nodes of the colosseum are called blocks and, thinking of Section 3.2, we have V(H) = B(G, k) (but note that the definition of \u201cblock\u201d has slightly changed). The start configuration of the game is the block C = V(G), i. e., all vertices are contaminated. We define Q = { {v} \u2286 V(G) : |NG({v})| < k } to be the set of winning configurations, as at least one searcher is available to catch the fugitive. Therefore, the searchers have a winning strategy if, and only if, V(G) \u2208 R(Q) and we will therefore refer to R(Q) = R(G, k) as the winning region (we did so similarly in Section 3.2, but we did not have the notation of edge-alternating graphs then). Observe that the colosseum is acyclic (that is, the digraph (V(H), E(H) \u222a A(H)) is acyclic) as we have for every edge (C, C\u2032) that |C| > |C\u2032|, and observe that Q is a subset of the sinks of this graph. Hence, we can test if V(G) \u2208 R(Q) in time O(| colosseum(G, k))|). Finally, note that the size of colosseum(G, k) may be of order 2n rather than nk+1, giving us a slightly worse overall runtime. This larger structure is required to encode that the fugitive is invisible."
        },
        {
            "heading": "4.4. Fighting in the Pit",
            "text": "The sketched algorithms have running time proportional to the size of the arena and the colosseum. Both of these auxiliary graphs might be large, as the arena has fixed size of order O(nk+1) while the colosseum may even have size O(2n). Additionally, both graphs can contain unnecessary configurations, that is, configurations not part of the winning region. In the light of dynamic programming, this is the same as listing all possible configurations, and in the light of positive-instance driven dynamic programming, we would like to list only the positive instances\u2014which is exactly the winning regionR(Q). The pit pit(G, k) inside the colosseum is now formally defined as the subgraph of colosseum(G, k) induced by R(Q), that is, as the induced subgraph on the winning region. The key insight is that |pit(G, k)| may be smaller than | colosseum(G, k)| or even | arena(G, k)| on various graph classes. Our primary goal for this section will therefore be the development of an algorithm that computes the pit in time depending only on the size of the pit (rather the size of the arena or the colosseum). The algorithm traverses the colosseum \u201cbackwards\u201d starting from the winning configurations Q and uncovering R(Q) layer by layer. In order to achieve this, we need to compute the predecessors of a block C. This is easy if C was reached by a fly-move as we can simply enumerate the n possible predecessors. Reversing a reveal-move, that is, finding the universal predecessors, is significantly more involved. A simple approach is to test for every subset of already explored configurations if we can \u201cglue\u201d them together\u2014as we did in the sketched algorithm in Section 3.2. However, this results in an even worse runtime of 2|pit(G,k)|. To avoid this exponential blow-up, we require the following structural property of the colosseum.\nAlgorithms 2022, 15, 42 12 of 33\nDefinition 1 (Universal Consistent). We say that an edge-alternating graph H = (V, E, A) is universal consistent with respect to a set Q \u2286 V if for all v \u2208 V \\ Q with v \u2208 R(Q) and N\u2200(v) = {w1, . . . , wr} we have (1) N\u2200(v) \u2286 R(Q) and (2) for every I \u2286 {w1, . . . , wr} with |I| \u2265 2 there is a vertex v\u2032 \u2208 V with N\u2200(v\u2032) = I and v\u2032 \u2208 R(Q).\nIntuitively, Definition 1 implies that for every vertex with high universal-degree, there is a set of vertices that can be arranged in a tree-like fashion to realize the same adjacency relation. This allows us to glue only two configurations at a time and, thus, removes the exponential dependency. The definition is illustrated in Example 1.\nExample 1. Consider the following three edge-alternating graphs, where black edges are existential and the blue edges are universal. The set Q contains a single vertex that is highlighted. From left to right: the first graph is universal consistent, the second and third one are not. The second graph conflicts the condition that v \u2208 R(Q) implies N\u2200(v) \u2286 R(Q), as the vertex on the very left is contained inR(Q) by the top path, while its universal neighbor on the bottom path is not contained inR(Q). The third graph conflicts the condition that N\u2200(v) = {w1, . . . , wr} implies that for every I \u2286 {w1, . . . , wr} with |I| \u2265 2 there is a vertex v\u2032 \u2208 V with N\u2200(v\u2032) = I and v\u2032 \u2208 R(Q) as witnessed by the vertex with three outgoing universal edges.\nVersion November 12, 2021 submitted to Algorithms 11 of 27 4.4. Fighting in the Pit436 The sketched algorithms have running time proportional to size of the arena and the437 colosseum. Both of these auxiliary graphs might be large, as the arena has fixed size of438 order O(nk+1) while the colosseum may even have size O(2n). Additionally, both graphs439 can contain unnecessary configurations, that is, configurations not part of the winning440 region. In the light of dynamic programming, this is the same as listing all possible441 configurations; and in the light of positive-instance driven dynamic programming, we442 would like to list only the positive instances \u2013 which is exactly the winning region R(Q).443 The pit pit(G, k) inside the colosseum is now formally defined as the subgraph of444 colosseum(G, k) induced by R(Q), that is, as the induced subgraph on the winning445 region. The key-insight is that | pit(G, k)| may be smaller than | colosseum(G, k)| or even446 | arena(G, k)| on various graph classes. Our primary goal for this section will therefore447 be the development of an algorithm that computes the pit in time depending only on the448 size of the pit (rather the size of the arena or the colosseum).449\nThe algorithm traverses the colosseum \u201cbackwards\u201d starting from the winning450 configurations Q and uncovering R(Q) layer by layer. In order to achieve this, we need451 to compute the predecessors of a block C. This is easy if C was reached by a fly-move as452 we can simply enumerate the n possible predecessors. Reversing a reveal-move, that is,453 finding the universal predecessors, is significantly more involved. A simple approach454 is to test for every subset of already explored configurations if we can \u201cglue\u201d them455 together \u2013 as we did in the sketched algorithm in Section 3.1. However, this results in456 an even worse runtime of 2| pit(G,k)|. To avoid this exponential blow-up we require the457 following structural property of the colosseum.458\nDefinition 1 (Universal Consistent). We say that an edge-alternating graph H = (V, E, A)459 is universal consistent with respect to a set Q \u2713 V if for all v 2 V \\ Q with v 2 R(Q) and460 N8(v) = {w1, . . . , wr} we have (1) N8(v) \u2713 R(Q) and (2) for every I \u2713 {w1, . . . , wr} with461 |I| 2 there is a vertex v0 2 V with N8(v0) = I and v0 2 R(Q).462\nIntuitively, this definition implies that for every vertex with high universal-degree463 there is a set of vertices that can be arranged in a tree-like fashion to realize the same464 adjacency relation. This allows us to glue only two configurations at a time and, thus,465 removes the exponential dependency. The definition is illustrated in Example 1.466\nExample 1. Consider the following three edge-alternating graphs, where black edges are existen-467 tial and the blue edges are universal. The set Q contains a single vertex that is highlighted. From468 left to right: the first graph is universal consistent; the second and third one are not. The second469 graph conflicts the condition that v 2 R(Q) implies N8(v) \u2713 R(Q), as the vertex on the very470 left is contained in R(Q) by the top path, while its universal neighbor on the bottom path is not471 contained in R(Q). The third graph conflicts the condition that N8(v) = {w1, . . . , wr} implies472 that for every I \u2713 {w1, . . . , wr} with |I| 2 there is a vertex v0 2 V with N8(v0) = I and473 v0 2 R(Q) as witnessed by the vertex with three outgoing universal edges.474\n475\nLemma 3. For every graph G and number k, the edge-alternating graph colosseum(G, k) is universal consistent.\nProof. For the first property, observe that \u201creveals do not harm\u201d: Searchers that can catch the fugitive without knowing where she hides, certainly can do so if they know. For the second property, consider any configuration C \u2208 V(H) that has universal edges to C1, . . . , C`. By definition, we have |NG(C)| \u2264 k and NG(Ci) \u2286 NG(C) for all 1 \u2264 i \u2264 `. Therefore, we have for every I \u2286 {1, . . . , `} and C\u2032 = \u222ai\u2208ICi that NG(C\u2032) \u2286 NG(C) and |NG(C\u2032)| \u2264 k and, thus, C\u2032 \u2208 V(H).\nThe algorithm for computing the pit, see Figures 5 and 6, runs in three phases: it first computes the set Q of winning configurations; then the winning regionR(Q) (the vertices of pit(G, k)); and finally, it computes the edges of pit(G, k). Theorem 1. The algorithm discover(G,k) finishes in at most O ( | R(Q)|2 \u00b7 |V|2 ) steps and correctly outputs pit(G, k).\nProof. The algorithm computes Q in phase I, the winning regionR(Q) in phase II, and the edges of colosseum(G, k)[R(Q)] in phase III. First observe that Q is correctly computed in phase I by the definition of Q. For the correctness of the second phase, we show that the computed set V(pit(G, k)) equalsR(Q). Let us refer to the set V(pit(G, k)) during the computation as K and observe that this is exactly the set of vertices inserted into the queue. We first show K \u2286 R(Q) by induction over the ith inserted vertex. The first vertex C1 is in R(Q) as C1 \u2208 Q. Now, consider a Ci \u2208 K. It was either added in Line 18 or Line 24. In the first case, there was a vertex C\u0303i \u2208 K such that Ci = C\u0303i \u222a {v} for some v \u2208 N(C\u0303i). By the induction hypothesis we have C\u0303i \u2208 R(Q) and by the definition of the colosseum we have (Ci, C\u0303i) \u2208 E(H) and, thus, Ci \u2208 R(Q). In the second case, there were vertices C\u0303i, C\u0302i \u2208 K with Ci = C\u0303i \u222a C\u0302i.\nAlgorithms 2022, 15, 42 13 of 33\nBy the induction hypothesis, we have again C\u0303i, C\u0302i \u2208 R(Q). Let t1, . . . , t` be the connected components of C\u0303i and C\u0302i. Since the colosseum is universal consistent with respect to Q by Lemma 3, we have t1, . . . , t` \u2208 R(Q). By the definition of the colosseum, we have N\u2200(Ci) = t1, . . . , t` and, thus, Ci \u2208 R(Q). To see R(Q) \u2286 K, consider for a contradiction the vertices of R(Q) in reversed topological order (recall that the colosseum is acyclic) and let C be the first vertex in this order with C \u2208 R(Q) and C 6\u2208 K. If C \u2208 Q, we have C \u2208 K by phase I and are complete, so assume otherwise. Since C \u2208 R(Q), we have either N\u2203(C) \u2229R(Q) 6= \u2205 or \u2205 6= N\u2200(C) \u2286 R(Q). In the first case, there is a block C\u0303 \u2208 R(Q) with (C, C\u0303) \u2208 E(H). Block C\u0303, thus, precedes C in the reversed topological order and, by the choice of C, we have C\u0303 \u2208 K. Therefore, at some point, C\u0303 is extracted from the queue and, in Line 18, C would be added to K, a contradiction. In the second case, there are vertices t1, . . . , t` \u2208 R(Q) with N\u2200(C) = {t1, . . . , t`}. By the choice of C, we have again t1, . . . , t` \u2208 K. Since H is universal consistent with respect to Q, we have for every I \u2286 {1, . . . , `} that \u22c3i\u2208I ti is contained in R(Q). In particular, the vertices t1 \u222a t2, t3 \u222a t4, . . . , t`\u22121 \u222a t` are contained in R(Q), and these elements are added to K whenever the ti are processed (for simplicity, assume here that ` is a power of 2). Once these elements are processed, Line 24 will also add their union, that is, vertices of the form (t1 \u222a t2) \u222a (t3 \u222a t4). In this way, the process will add vertices that correspond to increasing subgraphs of G to K, resulting ultimately in adding \u22c3` i=1 ti = C into K, which is the contradiction we have been looking for. OnceR(Q) is known, it is easy to compute the subgraph colosseum(G, k)[R(Q)], that is, to compute the edges of the subgraph induced by R(Q). Phase III essentially iterates over all vertices and adds edges according to the definition of the colosseum. For the runtime, observe that the queue will contain exactly the setR(Q) and, for every element extracted, we search through the current K\u2032 \u2286 R(Q), which leads to the quadratic timebound of | R(Q)|2. Furthermore, we have to compute the neighborhood of every extracted element, and we have to test whether two such configurations intersect\u2014both can easily be achieved in time O(|V|2). Finally, in phase III, we have to compute connected components of the elements inR(Q), but since this is possible in linear time per element, it is clearly possible in time O ( | R(Q)| \u00b7 |V|2 ) for the whole graph."
        },
        {
            "heading": "4.5. Distance Queries in Edge-Alternating Graphs",
            "text": "We have just discussed how to compute the pit for a given graph and k \u2208 N. The computation of graph measures such as treewidth now boils down to simple distance queries to this pit. To obtain an intuition of \u201cdistance\u201d in edge-alternating graphs, think about such a graph as in our game and consider some vertex v. There is always one active player that may decide to take one existential edge (a fly-move in our game) or the player may decide to ask the opponent to make a move and, thus, has to handle all universal edges (a reveal-move in our game). From the point of view of the active player, the distance is thus the minimum over the minimum of the distances of the existential edges and the maximum of the universal edges.\nAlgorithms 2022, 15, 42 14 of 33\n1 procedure discover ( G , k ) 2 V(pit(G, k)) := \u2205 3 E(pit(G, k)) := \u2205 4 A(pit(G, k)) := \u2205 5 i n i t i a l i z e empty~queue 6 7 / / Phase I : compute Q 8 f o r v \u2208 V(G) do 9 o f f e r ({v} , k\u2212 1 )\n10 end 11 12 / / Phase I I : compute R(Q) = V(pit(G, k)) 13 while queue not empty do 14 e x t r a c t C from~queue 15 16 / / r e v e r s e f l y \u2212moves 17 f o r v \u2208 N(C) do 18 o f f e r ( C \u222a {v} , k\u2212 1 ) 19 end 20 21 / / r e v e r s e r e v e a l \u2212moves 22 f o r C\u2032 \u2208 V(pit(G, k)) do 23 i f not i n t e r s e c t ( C , C\u2032 ) then 24 o f f e r ( C \u222a C\u2032 , k ) 25 end 26 end 27 end 28 29 / / Phase I I I : compute E and A 30 discoverEdges ( V(pit(G, k)) , E(pit(G, k)) , A(pit(G, k)) ) 31 32 re turn ( V(pit(G, k)), E(pit(G, k)), A(pit(G, k))\n) 33 end\nFigure 5. The discover algorithm computes, given a graph G = (V, E) and an integer k \u2208 N, the auxiliary graph pit(G, k). Using the positive-instance driven paradigm, only the elements of the pit are explored during this process. The executed subprocedures can be found in Figure 6.\n1 procedure o f f e r ( C , t ) 2 i f C \u2208 V(pit(G, k)) then 3 re turn 4 end 5 i f |NG(C)| \u2264 t then 6 add C to V(pit(G, k)) 7 i n s e r t C i n t o queue 8 end 9 end\n1 procedure i n t e r s e c t ( C , C\u2032 ) 2 i f C \u2229 C\u2032 6= \u2205 then 3 re turn true 4 end 5 i f NG(C) \u2229 C\u2032 6= \u2205 then 6 re turn true 7 end 8 i f C \u2229 NG(C\u2032) 6= \u2205 then 9 re turn true\n10 end 11 re turn f a l s e 12 end\n1procedure discoverEdges ( V , E , A ) 2f o r C \u2208 V do 3 4/ / add f l y \u2212move e d g e s 5f o r v \u2208 C do 6i f C \\ {v} \u2208 V then 7add (C, C \\ {v}) to E 8end 9end 10 11/ / add r e v e a l \u2212move e d g e s 12l e t C1, . . . , C` be the 13components of G[C] 14i f C1, . . . , C` \u2208 K then 15f o r i = 1 to ` do 16add (C, Ci) to A 17end 18end 19end 20end\nFigure 6. Subprocedures used by the discover algorithm. The offer procedure adds a block to the queue if t is not too large. The intersect procedure simply checks if two blocks are compatible (i. e., that they can be glued together), and the discoverEdges procedure identifies the edges of the pit.\nAlgorithms 2022, 15, 42 15 of 33\nDefinition 2 (Edge-Alternating Distance). Let H = (V, E, A) be an edge-alternating graph with v \u2208 V and Q \u2286 V, let further c0 \u2208 N be a constant, and \u03c9E : E \u2192 N and \u03c9A : A \u2192 N be weight functions. The distance d(v, Q) from v to Q is inductively defined as d(v, Q) = c0 for v \u2208 Q and otherwise:\nd(v, Q) = min (\nmin w\u2208N\u2203(v) (d(w, Q) + \u03c9E(v, w)), max w\u2208N\u2200(v)\n(d(w, Q) + \u03c9A(v, w)) ) .\nLemma 4. Given an acyclic edge-alternating graph H = (V, E, A), two weight functions \u03c9E : E\u2192 N and \u03c9A : A\u2192 N, a source vertex s \u2208 V, a subset of the sinks Q, and a constant c0 \u2208 N. The value d(s, Q) can be computed in time O(|V|+ |E|+ |A|) and a corresponding edge-alternating path can be output in the same time.\nProof of Lemma 4. Since H is acyclic, we can compute a topological order of (V, E \u222a A) using the algorithm from [80]. We iterate over the vertices v in reversed order and compute the distance as follows. If v is a sink, we set:\nd(v, Q) = { c0 if v \u2208 Q; \u221e otherwise.\nIf v is not a sink, we have already computed d(w, Q) for all w \u2208 N(v) and, hence, can compute d(v, Q) by the formula of the definition. Since this algorithm has to consider every edge once, the whole algorithm runs in time O(|V|+ |E|+ |A|). A path from s to Q of length d(s, Q) can be found by backtracking the labels starting at s.\nBeing able to answer distance queries in the pit yields an easy way of computing graph measures that have game theoretic characterizations [61,62,76]. For instance, if we wish to compute a tree decomposition (there is no bound on the number of branches nor on the depth), we seek a winning strategy that may use an unbounded number of reveals and fly-moves\u2014hence, we just can look for any path from the start configuration to Q. If we, instead, look for a path decomposition, we seek a tree decomposition without branches\u2014hence, we need a winning strategy that does not use reveals and we can find one by introducing heavy weights on the universal edges. The following theorem collects graph measures that can be computed with similar arguments. We provide a sketch that illustrates how the weights have to be chosen within the main text; the interested reader finds the full (unfortunately somewhat technical) proof in Appendix A.\nTheorem 2. Given a graph G and an integer k, we can decide in time O(|pit(G, k + 1)|2 \u00b7 |V|2) whether G has { treewidth, pathwidth, treedepth, q-branched treewidth, dependency treewidth } at most k.\nProof. All five problems have game theoretic characterizations in terms of the same search game with the same configuration set [61,62,76]. More precisely, they condense to various distance questions within the colosseum by assigning appropriate weights to the edges.\ntreewidth: To solve treewidth, it is sufficient to find any edge-alternating path from the vertex Cs = V(G) to a vertex in Q. We can find a path by choosing \u03c9E and \u03c9A as (x, y) 7\u2192 0, and by setting c0 = 0. pathwidth: In the pathwidth game, the searchers are not allowed to perform any reveal [76]. Hence, universal edges cannot be used and we set \u03c9A to (x, y) 7\u2192 \u221e. By setting \u03c9E to (x, y) 7\u2192 0 and c0 = 0, we again only need to find some path from V(G) to Q with weight less than \u221e. treedepth: In the game for treedepth, the searchers are not allowed to remove a placed searcher again [61]. Hence, the searchers can only use k existential edges. Choosing \u03c9E as (x, y) 7\u2192 1, \u03c9A as (x, y) 7\u2192 0, and c0 = 1 is sufficient. We have to search a path of weight at most k.\nAlgorithms 2022, 15, 42 16 of 33\nq-branched treewidth: For q-branched treewidth, we wish to use at most q reveals [62]. By choosing \u03c9E as (x, y) 7\u2192 0, \u03c9A as (x, y) 7\u2192 1, and c0 = 0, we have to search for a path of weight at most q. dependency treewidth: This parameter is, in essence, defined via graph searching game that is equal to the game we study with some fly- and reveal-moves forbidden. Forbidding a move can be achieved by setting the weight of the corresponding edge to \u221e and by searching for an edge-alternating path of weight less than \u221e."
        },
        {
            "heading": "4.6. Extending the Algorithm to Directed Treewidth",
            "text": "D-width has a game theoretic characterization based on the following version of the game: The searchers and the fugitive now play on a digraph G, the searchers have unlimited reveals (q = \u221e), and the fugitive is restricted to move inside strongly connected components (i. e., she can only reach vertices from which there is path back to her current position). Let D-search(G) be the minimal number of searchers required to catch the fugitive in a monotone way. In contrast to the games we have considered previously, the number of required searchers may be reduced if we allow non-monotone strategies [81]. However, this is not relevant for the D-width, as we have:\nFact 2 ([81]). D-search(G) = tw (G) + 1.\nSimilar to the undirected games, we can construct a colosseum H, where each vertex C \u2208 V(H) corresponds to a configuration of the game. We put an existential edge from C1 to C2 when we can transform C1 to C2 by placing a searcher in C1 and by removing all covered searchers (i. e., all searchers that stand on vertices v with v 6\u2208 NG(C2)). A universal edge is put from C to all its strongly connected components C1, . . . , Cr.\nObservation 1. Apart from G now being directed, not much changes for the colosseum. In particular, it is easy to see that it is still an acyclic edge-alternating graph. Thus, we can compute the pit in it using Theorem 1.\nCorollary 1. Given a digraph G = (V, E) and an integer k, we can test whether or not we have tw (G) \u2264 k in time O(|pit(G, k)|2 \u00b7 |V|2).\nProof. Compute the pit for the directed graph using Theorem 1; weight the edges with \u03c9E and \u03c9A as (x, y) 7\u2192 0, and set c0 = 0 (as for undirected treewidth in Theorem 2). Find a shortest edge-alternating path from V to the sinks of the pit using Lemma 4."
        },
        {
            "heading": "5. Color Coding Sieves",
            "text": "The bottleneck in practical implementations of the presented algorithm is the enumeration of compatible blocks that can be glued (Line 22 and 23 in Figure 5). The same problem was observed in the positive-instance driven algorithms for treewidth [52] and treedepth [48]. Both used so called block sieves to tackle this problem. These sieves are data structures based on set tries [82] allowing for an efficient enumeration over blocks that are possible candidates. More precisely, if K is the set of already computed blocks and the algorithm from Figure 5 reaches Line 22 with a block C, a block sieve shall efficiently enumerate a set K\u2032 \u2286 K such that all C\u2032 \u2208 K for which the algorithm reaches Line 24 are contained in K\u2032 while |K \\ K\u2032| is maximized. Trivially, one could store K as list and just test for every element whether it is compatible (this is exactly what Figure 5 does). A block sieve improves this naive idea by storing the sets in a tree that represents intersections. Hence, while enumerating the output, one can prune some parts of the tree (of K) and, thus, has to consider only a subset of K\u2032 \u2286 K. Tamaki presented this idea for the first time [52] and a more involved version was used by Trimble [48]. However, both implementations came with the drawback that they do not provide any guarantee on how well they sieve. We provide a randomized data structure for which we can provide tight bounds for the probability that certain unnecessary blocks are pruned. Furthermore, we\nAlgorithms 2022, 15, 42 17 of 33\nshow how to derandomize this data structure using the well-known color coding technique and obtain an implementation of the block sieve data structure that correctly prunes all of these blocks. Another disadvantage of set tries is the overhead introduced by managing a tree structure of sets compared to, say, storing the blocks in a simple list or array. During the development of our treedepth solver PID? for PACE 2020, we actually observed that block sieves can negatively impact the performance of positive-instance driven solvers on instances of medium size [49]. In this section, we develop a randomized data structure that gives us the performance advantage of block sieves, reduces the overhead introduced by the set tries, and provides provable guarantees on the sieve quality. Color coding sieves apply different filter strategies successively to divide the set of all blocks into smaller and smaller sets. These sets often become small enough to be stored in simple lists. Only if these lists become too large, we divide them into multiple lists via a random choice. If such a separation happens frequently, the data structure converges into a classical set trie. We assume a total order < on V, that is, V = {1, 2, . . . , n}. Furthermore, we denote the smallest vertex in a set C \u2286 V by min(C). Observe that < implies a partial order l on subgraphs where C1 l C2 if, and only if, min(C1) < min(C2). The color coding sieve will be used to store the setR(Q) = V(pit(G, k)), which, as before, consists of blocks C. The first operation supported by our data structure is the insertion operation that inserts a block C to the set represented by the data structure and is denoted by insert(C). The second operation is used to speed up Line 22 in Listing 5. For a fixed block C, we have to enumerate all blocks C\u2032 that (i) do not intersect C (procedure intersect(C, C\u2032) in Figure 6) and that (ii) satisfy |NG(C \u222a C\u2032)| \u2264 k (procedure offer(C, t) in Figure 6). Recall that two blocks intersect if C \u2229 C\u2032 6= \u2205, NG(C) \u2229 C\u2032 6= \u2205 or C \u2229 NG(C\u2032) 6= \u2205.\nDefinition 3. A block C\u2032 is compatible with respect to a block C if all of the following holds: 1. C l C\u2032; 2. |NG(C \u222a C\u2032)| \u2264 k; 3. C \u2229 C\u2032 = \u2205, NG(C) \u2229 C\u2032 = \u2205, and C \u2229 NG(C\u2032) = \u2205.\nThe set of all blocks that are compatible to C is denoted by comp(C).\nIn light of this definition, query operation query(C) should return a super set of comp(C). To support efficient implementation of such queries, a color coding sieve stores a set of blocks in three levels. Each level filters the blocks by making use of one of the three items of Definition 3. The level-1 sieve partitions the blocks into sets Si = {C \u2208 R | 2i \u2264 min(C) < 2i+1 } for i \u2208 {0, . . . , log n\u2212 1} to make use of the partial ordering l. We choose this partition because there are in general many more blocks with min(C) = 1 than with min(C) = n. Each set Si is stored as a level-2 sieve of depth \u03b3. These sieves are the eponym for the data structure and partition Si by making use of \u03b3 colorings color1, . . . , color\u03b3. Each coloring assigns two colors, say blue and orange, to the vertices of G. Let orangej and bluej be the set of orange and blue vertices according to colorj, respectively. The set Si is partitioned into sets Si[`], where ` = (`1, . . . , `\u03b3) \u2208 {0, . . . , k}\u03b3. A block C belongs to Si[`] if, and only if, the number of orange neighbors w. r. t. colorj is exactly `j, that is,\nSi[`] = {C \u2208 Si : |NG(C) \u2229 orangej | = `j for all j \u2208 {1 . . . , \u03b3} }.\nThe idea is that whenever we query a block C with [r1, r2, . . . , r\u03b3] blue neighbors, we only have to search for compatible blocks in those sets Si[`1, . . . , `\u03b3] with `j + rj \u2264 k. Finally, the sets Si[`] are stored as level-3 sieves, which are lazily built random set tries. Initially, we store the set Si[`] as a list. If the size of the list grows too large, i. e., |Si[`]| > \u0398 for a threshold \u0398, we pick a random vertex x \u2208 V and divide Si[`] into {C \u2208 Si[`] | x \u2208 C } and {C \u2208 Si[`] | x 6\u2208 C }. These sets are then recursively managed by new level-3 sieves.\nAlgorithms 2022, 15, 42 18 of 33\nObserve that a level-3 sieve degenerates into a set trie with random order after n splits. However, because of the other sieve levels, we hope for far fewer recursive steps in the level-3 sieves."
        },
        {
            "heading": "5.1. Insert a Block to the Color Coding Sieve",
            "text": "Inserting a block C is straight forward: Every sieve adds it to the corresponding sieves of the next level. In detail, the level-1 sieve would add C to the sieve Si with 2i \u2264 min(C) < 2i+1. The level-2 sieve, on the other hand, counts, for j = 1, . . . , \u03b3, the number `j of orange neighbors of C and adds the block to Si[`]. Finally, this level-3 sieve follows a path from the root in the trie to a leaf by checking for vertices on that path whether they are in C. Then C is added to the list stored at the leaf, which eventually is split if it grows too large."
        },
        {
            "heading": "5.2. Query the Color Coding Sieve",
            "text": "To answer query(C), we need to iterate through the sieves. For the level-1 sieve, let q be such that 2q \u2264 min(C) < 2q+1. As we only need to find blocks C\u2032 with C l C\u2032, we can focus our search on the sets Si with i \u2265 q. In order to sieve out elements on level 2, let C have rj blue neighbors (w. r. t. colorj). We only need to consider sets Si[`1, . . . , `\u03b3] with `j + rj \u2264 k for all j \u2208 {1, . . . , \u03b3}. Finally, for level-3 sieves, if Si[`] is a list, we simply output that list. If Si[`] is split into X = {C\u2032 \u2208 Si[`] | x \u2208 C } and X = {C\u2032 \u2208 Si[`] | x 6\u2208 C } for a vertex x \u2208 V, we have to investigate these sets recursively. If x \u2208 C, we only have to recur in X, as we seek blocks that are disjoint from C. Otherwise, we have to search in both sets. The data structure is illustrated in Figure 7 together with the steps corresponding to an insert and a query. The following lemma states that the color coding sieve is, in fact, a block sieve: the output of query(C) contains all blocks that are compatible to C.\nLemma 5. After a sequence of insertions has inserted a set K of blocks to a color coding sieve that corresponds to a graph G = (V, E) and k \u2208 N, we have comp(C) \u2286 query(C) for all possible blocks C.\nProof. All three levels of the color coding sieve manage a partition of the set of blocks they contain and, thus, of K. We argue that any C\u2032 \u2208 comp(C) is output on query(C). The proof is by contradiction, so assume C\u2032 is pruned by one of the sieves. If C\u2032 is pruned on level 1, it must have been in a set Si with 2i \u2264 min(C\u2032) \u2264 2i+1 and i < q for 2q \u2264 min(C) \u2264 2q+1. Thus, C\u2032 l C and, hence, C\u2032 is not compatible with respect to C by property 1 of being compatible. Now, assume C\u2032 was pruned by the level-2 sieve. Then C\u2032 was stored in a set Si[`1, . . . , `\u03b3] that was not explored. Hence, there must be an index j \u2208 {1, . . . , \u03b3} and a number rj \u2265 0 with `j + rj > k such that NG(C \u222a C\u2032) contains at least `j orange and rj blue vertices with respect to colorj. This is a witness for |NG(C \u222a C\u2032)| > k and, thus, a contradiction to property 2 of being compatible. Finally, if C\u2032 was pruned by the level-3 sieve, then clearly the sieve contains multiple layers (otherwise the whole list is output). The only way the sieve prunes is that it had split its list with a vertex x \u2208 V and x \u2208 C. Since C\u2032 was pruned, we have x \u2208 C\u2032 and, hence, C \u2229 C\u2032 6= \u2205\u2014a contradiction to property 3 of being compatible.\nAlgorithms 2022, 15, 42 19 of 33 Version November 12, 2021 submitted to Algorithms 18 of 27\nLevel Data Structure Insert {2, 8} to Query ({3, 4, 5}) from\n1 S0 S1 S2 S3\n2 S1[0] S1[1] S1[2] S1[3]\n3 S1[2] = { {2, 3}, {2, 3, 4}, {2, 8, 9} } 8 2 C 8 62 C\n{2, 8} {2, 8, 9} {2, 3} {2, 3, 4}random split at 8\nS1\nS1[2]\nS1, S2, S3\nS1[0], S1[1], S1[2]\nWe have to query both branches of the trie, as 8 62 {3, 4, 5}. 1 2 3 4 5\n7\n9\n8 6\nFigure 7. A color coding sieve for the nine vertex graph shown on the bottom left with k = 4 and g = 1. The three levels are illustrated as gray boxes and show the contained sieves of the next level \u2013 green pointers indicate which level-i sieve is shown, i. e., the level-2 sieve is S1 and the level-3 sieve is S1[2] (all the other sieves are not shown). In the center, an insert of {2, 8} is illustrated: the first sieve inserts it to S1, the level-2 sieve S1 inserts it to the level-3 sieve S1[2] (other branches are not shown). The level-2 sieve uses the random partition shown on the graph, that is, {2, 8} has two orange neighbors. The level-3 sieve S1[2] is an ordinary list before the insert and becomes a trie after the insert, as a random split at vertex 8 occurs. On the right side of the figure we see all sieves that we have to search through in order to answer the query ({3, 4, 5}).\nLemma 5. After a sequence of insertions has inserted a set K of blocks to a color coding sieve692 that corresponds to a graph G = (V, E) and k 2 N, we have Compat(C) \u2713 query(C) for all693 possible blocks C.694\nProof. All three levels of the color coding sieve manage a partition of the set of blocks695 they manage and, thus, of K. We argue that any C0 2 Compat(C) is output on query(C).696 The proof is by contradiction, so assume C0 is pruned by one of the sieves.697 If C0 is pruned on level 1, it must have been in a set Si with 2i  min(C0)  2i+1698 and i < q for 2q  min(C)  2q+1. Thus C0 l C and, hence, C0 is not compatible with699 respect to C by property 1 of being compatible.700 Now assume C0 was pruned by the level-2 sieve. Then C0 was stored in a set701 Si[`1, . . . , `g] that was not explored. Hence, there must be an index j 2 {1, . . . , g} and a702 number rj 0 with `j + rj > k such that NG(C [ C0) contains at least `j orange and rj703 blue vertices with respect to colorj. This is a witness for |NG(C [ C0)| > k and, thus, a704 contradiction to property 2 of being compatible.705 Finally, if C0 was pruned by the level-3 sieve, then clearly the sieve contains multiple706 layers (otherwise the whole list is output). The only way the sieve prunes is that it had707 splitted its list with a vertex x 2 V and x 2 C. Since C0 was pruned, we have x 2 C0 and,708 hence, C \\ C0 6= \u2206 \u2013 a contradiction to property 3 of being compatible.709\nOptimizing Level-2 Sieves. We have not yet specified the colorings used in level 2.710 In the following, we first consider randomized colorings and then make use of color711 coding for derandomization. Using the guarantees provide by this technique, we obtain712 a provable running time bound for the level-2 sieve. We are interested in the probability713 that a block C0 with |NG(C [ C0)| > k is part of the output if we use random colorings.714\nLemma 6. Let g = 1 and fix some blocks C and C0 with |NG(C [ C0)| > k. If color1 is chosen randomly, the probability that C0 is output by query(C) is at most\n1 k + 1 2k+1 .\nFigure 7. A color coding sieve for the nine vertex graph shown on the bottom left with k = 4 and \u03b3 = 1. The three levels are illustrated as gray boxes and show the contained sieves of the next level\u2014green pointe indicat which lev -i sieve is shown, . e., the l vel-2 sieve is S1 and the level-3 sieve is S1[2] (all the other sieves are not shown). In the center, an insert of {2, 8} is illustrated: the first sieve inserts it to S1, the level-2 sieve S1 inserts it to the level-3 sieve S1[2] (other branches are not shown). The level-2 sieve uses the random partition shown on the graph, that is, {2, 8} has two orange neighbors. The level-3 sieve S1[2] is an ordinary list before the insert and becomes a trie after the insert, as a random split at vertex 8 occurs. On the right side of the figure, we see all sieves that we have to search through in order to answer the query ({3, 4, 5})."
        },
        {
            "heading": "5.3. Optimizing Level-2 Sieves",
            "text": "We have not yet specified the colorings used in level 2. In the following, we first consider randomized colorings and then make use of color coding for derandomization. Using the guarantees provided by this technique, we obtain a provable running time bound for the level-2 sieve. We are intereste in the probability that a block C\u2032 with |NG(C \u222a C\u2032)| > k is part of the output if we use random colorings.\nLemma 6. Let \u03b3 = 1 and fix some blocks C and C\u2032 with |NG(C \u222a C\u2032)| > k. If color1 is chosen randomly, the probability that C\u2032 is output by query(C) is at most\n1\u2212 k + 1 2k+1 .\nProof of Lemma 6. Let k\u0302 = |NG(C \u222a C\u2032)| \u2208 {k + 1, . . . , 2k} and let color1 be a randomly sampled coloring. Note that C\u2032 is output by query(C) if, and only if, \u03b2(C) + \u03c9(C\u2032) \u2264 k, where we define \u03b2(C) := |{ v \u2208 NG(C) | c lor(v) = blue } as the numb of blue neigh ors and \u03c9(C) equivalently as the number of orange neighbors. A coloring is called good if \u03b2(C) + \u03c9(C\u2032) > k as it allows to discard C\u2032. A vertex v \u2208 NG(C \u222a C\u2032) is good if either color(v) = blue and v \u2208 NG(C) or color(v) = orange and v \u2208 NG(C\u2032). Hence, a coloring is good if at least k + 1 vertices are good. Note that all vertices in NG(C) \u2229 NG(C\u2032) are good (as each vertex is colored). In the following, we thus assume that NG(C) \u2229 NG(C\u2032) = \u2205, which is the worst case. As each coloring occurs with probability 2\u2212k\u0302, the probability to hit a good coloring is then exactly\n( 2k\u0302 )\u22121 k\u0302\u2211\ni=k+1\n( k\u0302 i ) .\nHence, the probability of hitting a non-good coloring (and outputting C\u2032) is at most\n1\u2212 \u2211 k\u0302 i=k+1 ( k\u0302 i)\n2k\u0302 =\n\u2211ki=0 ( k\u0302 i)\n2k\u0302 .\nAlgorithms 2022, 15, 42 20 of 33\nThis term is maximized for k\u0302 = k + 1, as the denominator grows faster than the nominator. Hence, the probability to output C\u2032 is at most\n\u2211ki=0 ( k\u0302 i)\n2k\u0302 \u2264 \u2211\nk i=0 ( k+1 i )\n2k+1 = 1\u2212 k + 1 2k+1 .\nIf we choose all \u03b3 colorings randomly and independent, we obtain:\nCorollary 2. Fix some blocks C and C\u2032 with |NG(C \u222a C\u2032)| > k. If color1, color2, . . . , color\u03b3 are chosen randomly and independent, the probability that C\u2032 is output by query(C) is at most\n(1\u2212 k + 1 2k+1 )\u03b3.\nWe can now increase \u03b3 until the term (1\u2212 k+1 2k+1 )\u03b3 is below a tolerable threshold. If we add sufficiently many colorings, we may obtain the same result with deterministic colors that are produced by hash functions (that is, the level-2 sieve can be derandomized).\nDefinition 4. For two natural numbers n and k, an (n, k, 2)-universal coloring family is a set \u039b of functions \u03bb : {1, . . . , n} \u2192 {orange, blue} such that for every subset S \u2286 {1, . . . , n} of size |S| = k and for every mapping \u00b5 : S\u2192 {orange, blue}, there is at least one function \u03bb \u2208 \u039b with \u00b5(s) = \u03bb(s) for all s \u2208 S.\nIt is well-known that such families can be constructed via hash functions.\nTheorem 3 (Theorem 13.41 in [83]). For all natural numbers n and k, an (n, k, 2)-universal coloring family \u039b of size |\u039b| \u2264 2O(k) \u00b7 log2(n) can be found in time 2O(k) \u00b7 n \u00b7 log2(n).\nLet \u039b be (n, k, 2)-universal coloring family and assume that we operate the level-2 sieve with \u03b3 = |\u039b| colorings such that each of the colorings is produced by one of the hash functions in \u039b. Now assume we perform query(C) and fixate any block C\u2032 with |NG(C \u222a C\u2032)| > k. By the properties of (n, k, 2)-universal coloring families, there is at least one coloring in \u039b that colors the vertices in C \u222a C\u2032 in such a way that N(C) contains at least ` orange vertices, N(C\u2032) contains at least r blue vertices, and `+ r > k. Hence, the level-2 sieve prunes C\u2032 and, therefore, prunes all blocks that are incompatible to C by property 2 of being compatible. We collect this finding in form of the following theorem:\nTheorem 4. There is a computable function f : N \u2192 N such that for any graph G on n vertices and any k \u2208 N, the level-2 sieve can be implemented deterministically with \u03b3 = f (k) \u00b7 poly(n) colors. When a block C is queried, this sieve prunes all stored blocks C\u2032 with |NG(C \u222a C\u2032)| > k."
        },
        {
            "heading": "5.4. Pruning Queries in Level-3 Sieves",
            "text": "If the level-3 sieve degenerates into a set trie, we can use the structure of the trie to prune queries. Consider a node p of the trie and observe that the path from p to the root defines two sets Rp and Fp of required and forbidden vertices, respectively. Each block C\u2032 stored in the subtrie rooted at p fulfills Rp \u2286 C\u2032 and Fp \u2229 C\u2032 = \u2205. Hence, if min(Rp) \u2264 min(C), we do not have to explore p or its children. Define a pin to be a vertex v \u2208 V with v \u2208 Fp and NG(v) \u2229 Rp 6= \u2205, and let Pp be the set of pins at p. Note that all blocks stored in the subtrie rooted at p are adjacent to v and, thus, we can prune the search if v \u2208 C as all blocks then intersect with C. Pins become neighbors of glued blocks and, hence, we can also prune if |NG(C) \u222a Pp| > k."
        },
        {
            "heading": "6. Experimental Evaluation of Color Coding Sieves",
            "text": "In this section, we experimentally evaluate the performance gain of a positive-instance driven algorithm when equipping it with a color coding sieve. We exemplarily do so\nAlgorithms 2022, 15, 42 21 of 33\nby adding the color coding sieve (with \u03b3 = 1 and randomly generated coloring) to our treedepth solver PID? that is built on the algorithms developed within this paper [49]. A comparison of PID? with other state-of-the-art treedepth solvers was recently performed in the light of PACE 2020 and can be found in [45]. We perform the experiments on a computer equipped with 64 GB of RAM and an AMD Ryzen Threadripper 3970X with 32 cores of 3.7 Ghz each and with 144 MB of combined cache. The system runs on Ubuntu 18.04.5 LTS, 64bit. We let the solver run on two benchmark sets: the well-known DIMACS graph coloring instances (see [34,84] for an overview of these instances in light of treewidth), and the instances that were used in the exact track of the treedepth challenge PACE 2020 [45]. Both solvers (without and with color coding sieves) were run for 10 min on each instance. The results of the experiment are illustrated as scatter plots in Figure 8 (the left one corresponds with the DIMACS instances, the right one to the PACE 2020 instances).\nVersion November 12, 2021 submitted to Algorithms 20 of 27 Theorem 7. There is a computable function f : N ! N such that for any graph G on n vertices738 and any k 2 N the level-2 sieve can be implemented deterministically with g = f (k) \u00b7 poly(n)739 colors. When a block C is queried, this sieve prunes all blocks C0 with |NG(C [ C0)| > k.740\nPruning Queries in Level-3 Sieves. If the level-3 sieve degenerates into a set trie,741 we can use the structure of the trie to prune queries. Consider a node p of the trie742 and observe that the path from p to the root defines two sets Rp and Fp of required and743 forbidden vertices, respectively. Each block C0 stored in the subtrie rooted at p fulfills744 Rp \u2713 C0 and Fp \\ C0 = \u2206. Hence, if min(Rp)  min(C), we do not have to explore p745 or its children. Define a pin to be a vertex v 2 V with v 2 Fp and NG(v) \\ Rp 6= \u2206, and746 let Pp be the set of pins at p. Note that all blocks stored in the subtrie rooted at p are747 adjacent to v and, thus, we can prune the search if v 2 C as all blocks then intersect748 with C. Furthermore, all pins become neighbors of glued blocks and, hence, we can also749 prune if |NG(C) [ Pp| > k.750\n5.1. Experimental Evaluation of Color Coding Sieves751\nIn this section we experimentally evaluate the performance gain of a positive-752 instance driven algorithm when equipping it with a color coding sieve. We exemplarily753 do so by a i the sieve to our treed pth solver PID? th t is buil n the algorithms754 developed within this paper [42]. A comparison of PID? with other state-of-the-art755 treedepth solvers was recently done in the light of PACE 2020 and can be found in [38].756 We perform the experiments on a computer equipped with 64 GB of RAM and757 an AMD Ryzen Threadripper 3970X with 32 cores of 3.7 Ghz each and with 144MB of758 combined cache. The system runs on Ubuntu 18.04.5 LTS, 64bit. We let the solver run759 on two benchmark sets: the well-known DIMACS graph coloring instances (see [26,77]760 for an overview of these instances in light of treewidth); and the instances that where761 used in the ex ct track of the treedepth challenge PACE 2020 [38]. Fi ure 8 provides762 the results of our experiments i the form of a scatt r plo (the left one corresponds the763 DIMACS instances, the right one to the PACE 2020 instances).764\n1 2 4 6 8 10\n1 2\n4\n6\n8\n10\nPID?-ccs\nPID?\ntimeout\n1 2 4 6 8 10\n1 2\n4\n6\n8\n10\nPID?-ccs\nPID?\ntimeout\nFigure 8. Scatter plots that show the performance of PID? without color coding sieves compared to\nthe performance of the solver with them enabled (\u03b3 = 1 and a randomly generated coloring is used).\nThe left plot contains the DIMACS graph coloring instances, the right plot the PACE 2020 test set.\nEach point corresponds to an instance; the x-axis is the time needed by the solver using color coding\nsieves and the y-axis without using this feature. The color of the dot indicates which version was\nbetter; it is gray if they are equal. If a solver needed more than 10 min for an instance, the coordinate is set to the red dotted line.\nAs one can observe, the color coding sieve generally improves the performance of the solver. Just on a few outlier instances, the solver cannot utilize this data structure, which is probably due to many non-compatible blocks that have a small neighborhood and, thus, are not pruned by the level-2 sieve. We can also observe that the obtained speedup is larger on the PACE 2020 instances than on the DIMACS instances. The PACE instances were generally harder to solve for PID? and contained more blocks. Hence, the solver can utilize the color coding sieve better on this benchmark set."
        },
        {
            "heading": "6.1. Color Coding Sieves on Hyperbolic Random Graphs",
            "text": "In this section, we investigate the potential performance boost obtained by using coloring coding sieves on hyperbolic random graphs. We use the same experimental setup as in the last section and, again, equip our treedepth solver PID? [49] with the color coding sieve data structure. In contrast to the last section, we will now:\n1. Vary the used layers and the number of colorings \u03b3; 2. Run the solver on random graphs rather than predefined benchmark sets.\nFor this experiment, we use hyperbolic random graphs, which are known to replicate many structural properties of real-world networks [85,86]. Loosely speaking, these graphs are generated by sampling points randomly in a disk (these are the vertices) and by connecting points by an edge if their hyperbolic distance is smaller than some predefined threshold.\nAlgorithms 2022, 15, 42 22 of 33\nWe generated a set of 210 hyperbolic random graphs using the Hyperbolic Graph Generator [87]. The generator expects six parameters that we set as shown in Table 1. The solver PID? was used with the four configurations explained in Table 2, whereby the level-2 sieves always use uniformly sampled random colorings.\nAll configuration of the solver were run on all instances for at most 30 min. The results of the experiment are illustrated in a cumulative distribution function plot in Figure 9. Various interesting findings are contained in the plot: First, we can observe that the core solver without any sieve layer (-wo) cannot fully utilize the provided 30 min time window. All instances solved by this configuration are solved within 20 min and, indeed, afterwards the amount of blocks becomes too large to be enumerated naively. Second, we see the small (and expected) disadvantage of solvers with color coding sieves (-trie and -color-1) compared to the core algorithm (-wo) on \u201ceasy\u201d instances (that can be solved in a minute or less). Of course, using involved data structures comes with an overhead and, if there are simply not enough blocks, we may not overcome this disadvantage with the improvements provided by the data structure. However, we can also observe that the performance of the solver with lazily built tries (-trie) and with the full color coding sieve (-color-1) quickly outperforms the core solver on the remaining instances. For the same reason as mentioned above, the lazily built set trie alone is better than the whole sieve on \u201cmedium hard\u201d instance (solvable in about five minutes). Then, on even harder instances with more blocks, the additional layers can be utilized and the full color coding sieve provides the overall best performance. Third, we can observe that, on this test set, choosing \u03b3 > 1 (-color-2) has no positive effect compared to using \u03b3 = 1 (-color-1). Adding more colorings increases the overhead of the data structure and, thus, a negative effect is expected if a layer cannot be fully utilized. Here, we conclude that on instances that are currently tractable for the solver, there are not enough blocks such that a second random partition sufficiently improves the enumeration of compatible blocks. However, we can also observe that the trend is positive, i. e., the overhead of a second coloring is reduced more and more on harder instances. We thus conjecture that, if the solver can be tuned to solve larger instances, the positive effect of \u03b3 > 1 colorings, theoretically provided by Corollary 2, will also have a positive impact in practical implementations.\nAlgorithms 2022, 15, 42 23 of 33\nVersion December 9, 2021 submitted to Algorithms 22 of 30 Table 1. Parameters of the used hyperbolic graph generator [88]. We set the number of vertices to a range in which the instances are tractable but challenging for the solver. The expected average degree is k1 for n 2 {100, 110, 120}, k2 for n 2 {130, 140}, k3 for n 2 {150, 160}, and k4 for n 2 {170, 180, 190, 200}. For each combination of n and the corresponding ki, we generated six instances with random seed s 2 {1, . . . , 6} \u2013 yielding 210 instances. The remaining parameters of the generator are set to their default value. number of nodes n 2 {100, 110, 120, . . . , 200} expected average degree k1 2 {10, 20, 30}, k2 2 k1 [ {40}, k3 = k2 [ {50}, k4 2 {3, 5} expected power-law exponent 2 (default) square root of curvature 1 (default) temperature 0 (default) seed i 2 {1, 2, . . . , 6} Table 2. Seven configurations of PID? used in the experiment. All modes either do not use the color coding sieve at all, or use the lazy set trie and a subset of the remaining sieves (that is, we either extend the solver by block sieves or we do not). Configuration Meaning\n-wo Color coding sieves is not used. -trie Only the lazy set tries are used.\n-level-1 The level-1 and level-3 sieves are used. -color-1 All three sieves are used and g = 1. -color-2 All three sieves are used and g = 2. -color-3 All three sieves are used and g = 3. -color-4 All three sieves are used and g = 4.\n-wo (69 %)\n-trie (73 %) -color-1 (74 %) -color-2 (71 %)\n1 5 10 15 20 25 30\n60 65 70 75 80 85 90 95\n100 105 110 115 120 125 130 135 140 145\nTime in Minutes\nNumber of Solved Instances\nFigure 9. tba\n6. Conclusion and Outlook822\nTreewidth is one of the most useful graph parameters that is successfully used in823\nmany different areas. The positive-instance driven dynamic programming paradigm824 has led to the first practically relevant algorithm for this parameter, as well as for its825 close relative treedepth. We formalized such algorithms in the general setting of graph826 searching, which has allowed us to provide a clean and simple formulation and to extend827 the algorithm to many natural graph parameters.828\nFigure 9. A cumulative distribution function plot that shows the performance of PID? without color coding sieves (-wo), with just the lazily built set trie (-trie), with the full color coding sieve and \u03b3 = 1 (-color-1), and with the full color coding sieve and \u03b3 = 2 (-color-2). The experiments are performed on the set of 210 hyperbolic random graphs described in Table 1."
        },
        {
            "heading": "6.2. Sieve-Quality of th Individual Layers",
            "text": "So far, we measured the performance boost obtained by adding a color coding sieve to PID? with respect to the overall time the solver needs to solve an instance. In this section, we rather focus on the quality of the individual layers of the sieve. That is, we do not measure the time used to solve an instance but measure the amount of blocks that a sieve filtered. In more detail, we measure the total number of blocks generated by PID? (that is, the total number of blocks inserted into the sieve) and the number of compatible blocks that were filtered from the output of the sieve (over the complete run of the solver). We compare this number with the number of loaded blocks, which is the number of blocks returned by the sieve. Of course, all compatible blocks are loaded, but (if the sieve works poorly) many other blocks may be loaded, too. We measure the performance of the sieve as the fraction of falsely loaded blocks over all non-compatible blocks. See Table 3 for the exact terminology.\nObserve that, in the light of Corollary 2 and Theorem 4, the performance of a color coding sieve converges to 1 if \u03b3, the number of colorings, converges to infinity. See Figure 10 for an illustrative example.\nAlgorithms 2022, 15, 42 24 of 33Version January 16, 2022 submitted to Algorithms 24 of 32\nthe following procedure: start with a star with n leaves, then replace every edge by a873 path with d vertices, and finally replace every vertex by a clique on c vertices that is874 fully-connected to the vertices of adjacent cliques1. The corresponding experiment is875 summarized in Table 5. Finally, we performed the experiment on a set of instances from876 the PACE 2020 benchmark set [46] (see Section 5.1). The results are presented in Table 6.877\nTable 4. Overview of the performance of PID? if a single layer of the color coding sieve is used. The columns n, m, and td describe the number of vertices and edges, as well as the tree depth of the corresponding graph. The columns labeled \u201cLevel-i\u201d indicate that a level-i sieve is used (and non of the other layers). In this case, the level-2 sieve is used with g = 1 and the level-3 sieve in its plain version (without any improvements). Columns labeled with g = c indicate that a level-2 sieve with c colorings was used (the \u201crandom\u201d colorings were generated with a seeded pseudo-random generator, that is, the first coloring of the g = 3 sieve is the same as the coloring of the g = 1 sieve and the first three colorings of the g = 6 sieve are the ones of the g = 3 sieve), and the column \u201cimp. Level-3\u201d corresponds to a level-3 sieve with the improvements discussed after Theorem 7. In each row the sieve with the best performance on this instance is highlighted.\na of . . . Graph n m td Level-1 Level-2 g = 3 g = 6 Leve-3 imp. Level-3\ngrid_4 \u21e5 4 16 24 7 0.00 0.22 0.41 0.63 0.25 0.34 grid_5 \u21e5 5 25 40 9 0.00 0.20 0.49 0.66 0.46 0.65 grid_6 \u21e5 6 36 60 11 0.02 0.26 0.52 0.70 0.62 0.81 grid_7 \u21e5 7 49 84 13 0.07 0.29 0.59 0.78 0.69 0.92 grid_8 \u21e5 8 649 112 15 0.12 0.31 0.62 0.81 0.72 0.96\nTable 5. Same as Table 4, but on spider-graphs rather than grids.\na of . . . Graph n m td Level-1 Level-2 g = 3 g = 6 Leve-3 imp. Level-3\nspider_(10, 5, 5) 255 1760 20 0.00 0.23 0.38 0.51 0.04 0.13 spider_(10, 10, 5) 505 3510 25 0.03 0.18 0.35 0.49 0.05 0.22 spider_(10, 10, 6) 606 5115 30 0.03 0.16 0.34 0.44 0.05 0.19\nspider_(20, 10, 3) 606 2403 15 0.11 0.16 0.38 0.57 0.03 0.33\nspider_(30, 10, 5) 1505 10510 25 0.15 0.14 0.31 0.42 0.02 0.34\nFrom the experimental data shown in Table 4, 5, and 6 we conclude three observa-878 tions: First, the level-1 sieve alone does not much. This was expected, as this sieve has879 semantically the least function. It is intended as fast preprocessing for the other sieves.880 Secondly, the level-2 and level-3 sieve (a single random partition and a normal set trie)881 are relatively equivalent. While the former is better on spider graphs, the later is better882\n1 Intuitively, a star is a worst-case instance for the positive instance driven approach, as initially only the leaves are positive subproblems and, by trying to glue them together, the solver has to explore all 2n subsets of the leaves. By stretching and thickening the edges, we enforce that is behaviour remains the same and is not overcome by heuristics internally used by the solver.\nFor the following experiments, we only use a single layer of the color coding sieve and make all measurements with respect to a complete run of the solver for a given instance (i. e., summed over a ious values of the target width k). Since w aim to obtain a good estimation of the actual performance of the various siev s via exp rimental mean , we co sider rather difficult instances in this section. First, in Table 4, we consider n\u00d7 n-grid graphs, which are well-known to be difficult for various graph decomposition algorithms. Secondly, we hand-crafted a set of instances that are particularly difficult for the positive-instance driven\napproach. Let a (n, d, c)-spider be the graph obtained by the following procedure: start with\na star with n leaves, then replace every edge by a path with d vertices, and finally replace\nevery vertex by a clique on c vertices that is fully-connected to the vertices of adjacent\ncliques. (Intuitively, a star is a worst-case instance for the positive-instance driven approach,\nas initially only the leaves are positive subproblems and, by trying to glue them together,\nthe solver has to explore all 2n s bsets of the l av s. By stretching and thickening the edges,\nwe enforce that is behaviour stays the same and circumvent heuristics internally used by\nthe solver.) The corresponding experiment is summarized in Table 5. Finally, we performed\nthe experiment on a set of instances from the PACE 2020 benchmark set [45] (see Section 6).\nThe results are presented in Table 6.\n\u03b1 of . . .\nGraph n m td Level-1 Level-2 \u03b3 = 3 \u03b3 = 6 Level-3 imp. Level-3\ngrid_4\u00d7 4 16 24 7 0.00 0.22 0.41 0.63 0.25 0.34 grid_5\u00d7 5 25 40 9 0.00 0.20 0.49 0.66 0.46 0.65 grid_6\u00d7 6 36 60 11 0.02 0.26 0.52 0.70 0.62 0.81 grid_7\u00d7 7 49 84 13 0.07 0.29 0.59 0.78 0.69 0.92 grid_8\u00d7 8 649 112 15 0.12 0.31 0.62 0.81 0.72 0.96\nTable 5. Same as Table 4, but on spider-graphs rather than grids.\n\u03b1 of . . . Graph n m td Level-1 Level-2 \u03b3 = 3 \u03b3 = 6 Level-3 imp. Level-3\nspider_(10, 5, 5) 255 1760 20 0.00 0.23 0.38 0.51 0.04 0.13 spider_(10, 10, 5) 505 3510 25 0.03 0.18 0.35 0.49 0.05 0.22 spider_(10, 10, 6) 606 5115 30 0.03 0.16 0.34 0.44 0.05 0.19 spider_(20, 10, 3) 606 2403 15 0.11 0.16 0.38 0.57 0.03 0.33 spider_(30, 10, 5) 1505 10510 25 0.15 0.14 0.31 0.42 0.02 0.34\nAlgorithms 2022, 15, 42 25 of 33\nFrom the experimental data shown in Tables 4\u20136, we conclude three observations: First, the level-1 sieve alone does not much. This was expected, as this sieve has semantically the least function. It is intended as fast preprocessing for the other sieves. Secondly, the level-2 and level-3 sieve (a single random partition and a normal set trie) are relatively equivalent. While the former is better on spider graphs, the latter is better on instances from the PACE benchmark set. Our final observation is that both sieves greatly improve their performance if the extensions are added (more colorings for the level-2 sieve or the improvements discussed after Theorem 4 for the trie, respectively). Comparing the level-2 sieve with \u03b3 = 6 to the improved trie leads again to a mixed picture in which both of the sieves are better than the other on some of the instances. We conclude that taking a random partitioning is a valuable alternative to a set trie. The level-2 sieve has two advantages over the set trie: (i) it is comparatively easy to implement and comes with low constants and (ii) we can easily improve its performance by adding more colorings. On the downside, adding more colorings slows this sieve down. Hence, if we need a large \u03b3, a set trie becomes the better choice."
        },
        {
            "heading": "7. Conclusions and Outlook",
            "text": "Treewidth is one of the most useful graph parameters that is successfully used in many different areas. The positive-instance driven dynamic programming paradigm has led to the first practically relevant algorithm for this parameter, as well as for its close relative treedepth. We formalized such algorithms in the general setting of graph searching, which has allowed us to provide a clean and simple formulation and to extend the algorithm to many natural graph parameters. With a few modifications of the colosseum, our approach can also be used for the notion of special treewidth [88]. We assume that a similar modification may also be possible for other parameters such as spaghetti treewidth [89]. We also extended the block sieve data structure to a randomized multi-level sieve that is constructed lazily and that utilizes the well-known color coding technique. By modifying the number of colorings used, we can change the probability that a non-compatible block is pruned by the sieve. Hence, introducing more and more colors makes it unlikely that noncompatible blocks are output by the sieve. On the theoretical side, we may derandomize the data structure and obtain a guarantee that certain non-compatible blocks are filtered. Experiments have revealed that the color coding sieve in general increases the performance of our treedepth solver PID?. For the instances that are currently tractable by the solver, a single random coloring provides the best overall performance, but we expect that on harder instances the theoretical guarantees of using more colorings will result in a positive practical impact. An interesting next step would be to implement the color coding sieve in state-of-the-art treewidth solvers such as [20,53,63], which currently perform slightly better than the state-of-the-art treedepth solvers [44,45].\nAuthor Contributions: The authors have contributed equally. All authors have read and agreed to the published version of the manuscript.\nFunding: This research received no external funding.\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nAlgorithms 2022, 15, 42 26 of 33\nData Availability Statement: The DIMACS graph coloring instances and the PACE 2020 instances are publicly available [45,84]. The hyperbolic random graphs can be generated with the publicly available hyperbolic graph generator [87] and the parameters stated within the main text. The tools Jdrasil and PID? are also publicly available [20,49].\nConflicts of Interest: The authors declare no conflict of interest."
        },
        {
            "heading": "Appendix A. Proof of Theorem 2",
            "text": "We dedicate this section to the missing proof of Theorem 2. The theorem states that we can compute various graph parameters in polynomial time width respect to the size of the pit, the formal statement was: Recall the sketched proof idea from Section 4.5: We wanted to use the fact that all five problems have game theoretic characterizations that can be encoded in the colosseum [61,62,76]; then we argued that, by setting the weights in the pit correctly, we would obtain all parameters by simply computing shortest edge-alternating paths. We further claimed that the required weights are the following:\ntreewidth: Choose \u03c9E and \u03c9A as (x, y) 7\u2192 0, and set c0 = 0. pathwidth: Set \u03c9A to (x, y) 7\u2192 \u221e, \u03c9E to (x, y) 7\u2192 0, and c0 = 0. treedepth: Choosing \u03c9E as (x, y) 7\u2192 1, \u03c9A as (x, y) 7\u2192 0, and c0 = 1. q-branched treewidth: Set \u03c9E to (x, y) 7\u2192 0, \u03c9A to (x, y) 7\u2192 1, and c0 = 0. dependency treewidth As for treewidth, but we have to set the weight of some forbidden edges to infinity.\nLet us first observe that, by the definition of the colosseum, k searchers in the search game have a winning strategy if, and only if, the start configuration V(G) is contained in R(Q). With other words, if there is an edge-alternating path from V(G) to some winning configuration in Q. Note that such a path directly corresponds to the strategy by the searchers in the sense that the used edges directly correspond to possible actions of the searchers. Since for any graph G = (V, E) and any number k \u2208 N the edge-alternating graph colosseum(G, k) is universal consistent by Lemma 3, all vertices of an edge-alternating path corresponding to a winning strategy are contained in R(Q) as well. In fact, every edge-alternating path from V(G) to Q (and, thus, any winning strategy) is completely contained in R(Q). Therefore, it will always be sufficient to search such paths within pit(G, k). By Lemma 4, we can find such a path in time O(|pit(G, k)|2). In fact, we can even define two weight functions wE : E \u2192 N and wA : A \u2192 N and search a shortest path from V(G) to Q."
        },
        {
            "heading": "Appendix A.1. Computing Branched Tree Decompositions",
            "text": "To compute the invariants of G as stated in the theorem, we make the following claim:\nClaim A1. Let G = (V, E) be a graph and k \u2208 N. Define wE as (x, y) 7\u2192 0 and wA as (x, y) 7\u2192 1, and set c0 = 0. Then we have d(V(G), Q) \u2264 q in pit(G, k) if, and only if, twq(G) \u2264 k\u2212 1.\nProof. We follow the proof of Theorem 1 in [62] and use the following fact that follows from the observation that in a tree decomposition (T, \u03b9), for each three different nodes i1, i2, i3 \u2208 T, we have \u03b9(i1) \u2229 \u03b9(i3) \u2286 \u03b9(i2) if i2 is on the unique path from i1 to i3 in T.\nFact A1. Let (T, \u03b9) be a tree decomposition of G = (V, E) rooted arbitrarily at some node r \u2208 T. Let i \u2208 T be a node and j \u2208 T be a child of i in T. Then, the set \u03b9(i) \u2229 \u03b9(j) is a separator between C = [\u22c3 d\u2208desc(j) \u03b9(d) ] \\ ( \u03b9(i) \u2229 \u03b9(j) ) and ( V \\ C ) \\ ( \u03b9(i) \u2229 \u03b9(j) ) , where desc(x) denotes the set of descendants of x including x. Hence, every path from some node u \u2208 C to some node v \u2208 V \\ C contains a vertex of \u03b9(i) \u2229 \u03b9(j).\nAlgorithms 2022, 15, 42 27 of 33\nAppendix A.1.1. From Tree Decompositions to Edge-Alternating Paths\nLet (T, \u03b9) be a q-branched tree decomposition of G = (V, E) of width k. Without loss of generality, we can assume that G is connected. We will show how to construct an edgealternating path from the start configuration V of cost at most q in colosseum(G, k + 1). As described above, this is also an edge-alternating path with the same costs in pit(G, k + 1). The first existential edge from V leads to the configuration V \\ \u03b9(r), where r is the root of T. Observe that we clearly have N(V \\ \u03b9(r)) \u2286 \u03b9(r). Suppose a configuration C was reached with N(C) \u2286 \u03b9(i) \u2208 V(colosseum(G, k + 1)) for some node i \u2208 T and we have:\nC \u2286 [ \u22c3 j\u2208desc(i) \u03b9(j) ] \\ \u03b9(i).\nClearly, for i = r, this assumption holds trivially. If i is a leaf in T, there are no more descendants and thus C = \u2205. Hence, we have reached a winning configuration in colosseum(G, k + 1). Now, suppose that i is a non-leaf node. We distinguish two cases:\n\u2022 If i has exactly one child j, we can find a path P1 of existential edges leading from C to a configuration C1 with N(C1) \u2286 \u03b9(i) \u2229 \u03b9(j). Moreover, we can also find a path P2 of existential edges from C1 to a configuration C2 with N(C2) \u2286 \u03b9(j). The path P1 will be constructed by iteratively removing all vertices v \u2208 C with N(v) \u2229 [\u03b9(i) \\ \u03b9(j)] 6= \u2205. For the remaining vertices C1, we have N(C1) \u2286 \u03b9(i) \u2229 \u03b9(j). If all configurations that we aim to visit on P1 exist, the corresponding edges also exist by definition. Assume that we are in some configuration C\u2032 with N(C\u2032)\u2229 [\u03b9(i) \\ \u03b9(j)] 6= \u2205 and want to remove a vertex v \u2208 C\u2032 with N(v) \u2229 [\u03b9(i) \\ \u03b9(j)] 6= \u2205, but C\u2032 \\ {v} 6\u2208 V(colosseum(G, k + 1)). By definition of colosseum(G, k + 1), this means that |N(C\u2032 \\ {v})| \u2265 k + 2. As we wanted to remove v, we have N(v) \u2229 \u03b9(i) 6= \u2205. As N(C\u2032 \\ {v}) \u2286 N(C\u2032) \u222a {v} and |N(C\u2032 \\ {v})| \u2265 k + 2, we know that there is some u \u2208 C\u2032 with v \u2208 N(u). Fact A1 implies that v \u2208 \u03b9(i) \u2229 \u03b9(j), a contradiction and, hence, all configurations in P1 exist. Similarly, we construct P2 by iteratively removing all vertices in \u03b9(j) from C1. It is easy to see that the neighborhood of the visited configurations will always be a subset of \u03b9(j) and, hence, all configurations on this path exist. We have arrived at a configuration C2 with N(C2) \u2286 \u03b9(j) and due to Fact A1:\nC2 \u2286 [ \u22c3\nj\u2032\u2208desc(j) \u03b9(j\u2032)\n] \\ \u03b9(j).\n\u2022 If node i has a set of children J with |J| \u2265 2, we will use universal edges. Let C be the connected components of G[ \u22c3 j\u2208desc(i) \u03b9(j) \\ \u03b9(i)]. We claim that for each component\n\u0393 \u2208 C there is a unique index j(\u0393) \u2208 J such that \u0393 \u2229 \u03b9(j(\u0393)) 6= \u2205. If no such index exists, we have \u03b9(j) = \u03b9(i). We can iteratively remove such bags \u03b9(j) until this cannot happen anymore. If two indices j1, j2 \u2208 J exist with \u03b9(j1) \u2229 \u0393 6= \u2205 and \u03b9(j2) \u2229 \u0393 6= \u2205, the connectivity property implies that \u03b9(i) \u2229 \u0393 6= \u2205, a contradiction to our assumption. Hence, for each component \u0393, we follow the universal edge to \u0393 and then proceed as above: first, we find a path P1 of existential edges from \u0393 to a configuration \u03931 with N(\u03931) \u2286 \u03b9(i)\u2229 \u03b9(j(\u0393)) and then a path P2 of existential edges from \u03931 to a configuration \u03932 with N(\u03932) \u2286 \u03b9(j(\u0393)). The same arguments as above imply that all configurations on these paths exist and that we arrive at a configuration \u03932 with N(\u03932) \u2286 \u03b9(j(\u0393)) and:\n\u03932 \u2286 [ \u22c3\nj\u2032\u2208desc(j(\u0393)) \u03b9(j\u2032)\n] \\ \u03b9(j(\u0393)).\nThis shows that we will eventually reach the leaves of the tree decomposition and, thus, some wining configuration. This is an edge-alternating path in colosseum(G, k + 1) and pit(G, k + 1). Furthermore, as each path from the root of T to some leaf of T contains\nAlgorithms 2022, 15, 42 28 of 33\nat most q nodes with more than one children, this path is q-branched, as we use at most q universal edges from the initial configuration V to any used winning configuration for every induced directed path. Hence, we have found an edge-alternating path in pit(G, k + 1) of cost at most q.\nAppendix A.1.2. From Edge-Alternating Paths to Tree Decompositions\nLet P \u2286 V(pit(G, k + 1)) be an edge-alternating q-branched path from the initial configuration V to a final configuration {v\u2217} in pit(G, k + 1) with |N({v\u2217})| \u2264 k. We argue inductively on q.\n\u2022 If q = 0, the path P does not use any universal edges. Let \u03c0 = \u03c01, . . . , \u03c0s be any classical directed path from the initial configuration V to some winning configuration {v\u2217} in pit(G, k + 1) that only uses vertices from P. As the initial configuration is \u03c01 = V, the winning configuration is \u03c0s = {v\u2217}, and there are only existential edges (C, C\u2032) with |C\u2032| = |C| \u2212 1 in pit(G, k + 1), we know that |\u03c0i| = |V| \u2212 i + 1, and thus s = |V|. We say that vertex v \u2208 V is removed at time i, if v \u2208 \u22c2ij=1 \u03c0j and v 6\u2208 \u22c3|V|j=i+1 \u03c0j. We also say that v\u2217 was removed at time |V|. For i = 1, . . . , |V|, let vi be the vertex removed at time i. We will now construct a 0-branched tree decomposition (T, \u03b9), i. e., a path decomposition. As T is a path, let t1, . . . , t|V| be the vertices on the path in their respective ordering with root t1. We set \u03b9(ti) = N(\u03c0i) \u222a {vi}. For i = 1, . . . , |V| \u2212 1, there is an existential edge leading from \u03c0i to \u03c0i+1 and thus |N(\u03c0i)| \u2264 k. As \u03c0|V| = {v|V|} is a winning configuration, we also have |N(\u03c0|V|)| \u2264 k. Hence, the resulting decomposition T has width at most k. As T is a path, it is also 0-branched. We now need to verify that (T, \u03b9) is indeed a valid tree decomposition. As every vertex v is removed at some time i, we have v = vi and thus v \u2208 \u03b9(ti). Hence, every vertex is in some bag. Let {vi, vi\u2032} be any edge with i < i\u2032. As vi\u2032 \u2208 \u03c0i\u2032 and vi 6\u2208 \u03c0i\u2032 , we have vi \u2208 N(\u03c0i\u2032) and thus {vi, vi\u2032} \u2286 N(\u03c0i\u2032) \u222a {vi\u2032} = \u03b9(ti\u2032). Hence, every edge is in some bag. Finally, let vi \u2208 V. Clearly, as vi \u2208 \u03c01, vi \u2208 \u03c02,. . . , vi \u2208 \u03c0i\u22121, the first bag where vi might appear is \u03b9(ti). Let vi\u2032 \u2208 N(vi) be the neighbor of vi that is removed at the latest time. If i\u2032 < i, we have N(vi) \u2229 \u22c3|V| j=i+1 \u03c0j = \u2205 and vi thus only appears in \u03b9(ti).\nIf i < i\u2032, then vi \u2208 \u22c2i\u2032 j=i+1 N(\u03c0j) and hence vi \u2208 \u22c2i\u2032\nj=i+1 \u03b9(tj). \u2022 Now, assume that q \u2265 1 and that we can construct for every q\u2032 < q a q\u2032-branched tree\ndecomposition of width at most k from any q\u2032-branched edge-alternating path P in pit(G, k + 1). Consider the directed acyclic subgraph H in pit(G, k + 1) induced by P. A configuration C \u2208 V(H) is called a universal configuration, if NA(C) \u2286 V(H) and a top-level universal configuration with respect to some directed path \u03c0 if C is the first universal configuration on \u03c0. Note that we can reduce P in such a way that all directed paths \u03c0 from the initial configuration V to some winning configuration {v\u2217} in H have the same top-level universal configuration, call it C\u2217. Let V = \u03c01, . . . , \u03c0i = C\u2217 be the shared existential path from V to C\u2217 in H and let NA(C\u2217) = {C1, . . . , C`} be the universal children of C\u2217. Note that {C1, . . . , C`} \u2286 P due to the definition of an edge-alternating path. For each child Cj, the edge-alternating path P contains a directed path \u03c0(j) from Cj to some final configuration in pit(G, k + 1). Furthermore, each \u03c0(j) contains at most q\u2032 \u2264 q \u2212 1 universal edges (otherwise, P would not be q-branched). Hence, by induction hypothesis, we can construct a q\u2032-branched tree decomposition (T(j),\u03b9 (j) ) for the subgraph induced by the vertices contained in the path \u03c0(j) with root r(j). Now, we use the same construction as above to construct a path (T\u2032 = (t\u20321, . . . , t \u2032 i), \u03b9 \u2032) from \u03c01, . . . , \u03c0i and for each path \u03c0(j) we add the root r(j) of the q\u2032-branched tree decomposition (T(j), \u03b9(j)) as a child of bag ti to obtain our final tree decomposition (T, \u03b9). As there is a universal edge from C\u2217 to Cj, we know that Cj is a component of\nAlgorithms 2022, 15, 42 29 of 33\nC\u2217. As all (T(j), \u03b9(j)) are valid q\u2212 1-branched tree decompositions of width at most k, we can thus conclude that (T, \u03b9) is a valid q-branched tree decomposition of width k.\nThis concludes the proof of the claim.\nCombining the above claim with Theorem 1 for computing the pit, we conclude that we can check whether a graph G has q-branched-treewidth k in time O(|pit(G, k + 1)|2 \u00b7 |V|2). We note that the algorithm is fully constructive, as the obtained path (and, hence, the winning strategy of the searchers) directly corresponds to the desired decomposition. Since we have tw(G) = tw\u221e(G) and pw(G) = tw0(G), the above results immediately imply the same statement for treewidth and pathwidth by checking d(V(G), k) < \u221e or d(V(G), k) = 0, respectively."
        },
        {
            "heading": "Appendix A.2. Computing Treedepth Decompositions",
            "text": "In order to show the statement for treedepth, we will require another claim for different weight functions. The proof idea is, however, very similar.\nClaim A2. Let G = (V, E) be a graph and k \u2208 N. Define wE as (x, y) 7\u2192 1 and wA as (x, y) 7\u2192 0, and c0 = 1. Then we have d(V(G), Q) \u2264 k in pit(G, k) if, and only if, td(G) \u2264 k.\nProof. To prove the claim, we use an alternative representation of treedepth [58]. Let G = (V, E) be a graph with connected components C1, . . . , C`, then:\ntd(G) =  1 if |V| = 1; max`i=1 td(G[Ci]) if ` \u2265 2; minv\u2208V td(G[V \\ {v}]) + 1 otherwise.\nLet us reformulate this definition a bit. Let C \u2286 V be a subset of the vertices and let C1, . . . , C` be the connected components of G[C]. Define:\ntd\u2217(C) =  1 if |C| = 1; max`i=1 td\n\u2217(Ci) if ` \u2265 2; minv\u2208C td \u2217(C \\ {v}) + 1 otherwise.\nObviously, td(G) = td\u2217(V). We proof that for any C \u2286 V we have d(C, Q) = td\u2217(C) in pit(G, k) for every k \u2265 td(G) and d(C, Q) \u2265 td\u2217(C) for all k < td(G). For the first part, we consider the vertices of pit(G, k) in inverse topological order and prove the claim by induction. The first vertex C0 is in Q and thus d(C0, Q) = c0 = 1. Since the vertices in Q represent sets of cardinality 1, we have d(C0, Q) = td\u2217(C0). For the inductive step, consider Ci and first assume it is not connected in G. Then\nd(Ci, Q) = max Cj\u2208N\u2200(Ci)\n( d(Cj, Q) + wA(Ci, Cj) ) = max\nCj\u2208N\u2200(Ci) d(Cj, Q)\n= max Cj is a component in G[Ci ]\ntd\u2217(Cj)\n= td\u2217(Ci).\nNote that there could, of course, also be existential edges leaving Ci. However, since the universal edges are \u201cfor free\u201d, for every shortest path that uses an existential edge at Ci, there is also one that first uses the universal edges.\nAlgorithms 2022, 15, 42 30 of 33\nFor the second case, that is Ci is connected, observe that Ci is not incident to any universal edge. Therefore, we obtain:\nd(Ci, Q) = min v\u2208Ci\n( d(Ci \\ {v}, Q) + wE(Ci, Ci \\ {v}) ) = min\nv\u2208Ci\n( d(Ci \\ {v}, Q) + 1 ) = min\nv\u2208Ci\n( td\u2217(Ci \\ {v}) + 1 ) = td\u2217(Ci).\nThis completes the part of the proof that shows d(C, Q) = td\u2217(C) for k \u2265 td(G). We are left with the task to argue that d(C, Q) \u2265 td\u2217(C) for all k < td(G). This follows by the fact that for every k\u2032 < k we have that pit(G, k\u2032) is an induced subgraph of pit(G, k). Therefore, the distance can only increase in the pit for a smaller k\u2014in fact, the distance can even become infinity if k < td(G).\nAgain, combining the claim with Theorem 1 yields the statement of the theorem for treedepth."
        },
        {
            "heading": "Appendix A.3. Computing Dependency Treewidth",
            "text": "This parameter can be characterized by an adaption of the graph searching game [12]: In addition to the graph G and the parameter k, one is also given a partial ordering l on the vertices of G. For a vertex set V\u2032, let \u00b5l(V\u2032) = { v \u2208 V\u2032 | \u2200w \u2208 V\u2032 \\ {v} : (w, v) 6\u2208 l } be the minimal elements of V\u2032 with regard to l. If C \u2286 V(G) is the contaminated area, we are only allowed to put a searcher on \u00b5l(C), rather than on all of C. The dependency-treewidth dtwl(G) is the minimal number of searchers required to catch the fugitive in this version of the game. Therefore, we just need a way to permit only existential edges (C, C\u2032) with C \\ C\u2032 \u2286 \u00b5l(C). We show the following stronger claim:\nClaim A3. Consider a variant of the search game in which at some configurations Ci some fly-moves are forbidden, and in which, furthermore, at some configurations Cj no reveals are allowed. Whether k searcher have a winning strategy in this game can be decided in time O(|pit(G, k)|2 \u00b7 |V|2).\nProof. First observe that, if the k searcher has a winning strategy S, this strategy corresponds to a path in pit(G, k). The reason is that searchers that are allowed to use all flyand reveal-moves (and for which all winning strategies correspond to paths in pit(G, k)) can, of course, use S as well. We compute the pit with Theorem 1. Now, to find the restricted winning strategy, we initially set wE and wA to (x, y) 7\u2192 0. Then, for any existential edge (Ci, Cj) that we wish to forbid, we set wE(Ci, Cj) = \u221e. Furthermore, for any node C at which we would like to forbid universal edges, we set wE(Ci, Cj) = \u221e for all Cj \u2208 N\u2200(Ci). Finally, we search a path from V(G) to Q of weight less than \u221e using Lemma 4.\nThis completes the proof of Theorem 2.\nReferences 1. Kreutzer, S. Algorithmic Meta-Theorems. Electron. Colloq. Comput. Complex. (ECCC) 2009, 16, 147. 2. Cygan, M.; Fomin, F.; Kowalik, L.; Lokshtanov, D.; Marx, D.; Pilipczuk, M.; Pilipczuk, M.; Saurabh, S. Parameterized Algorithms; Springer: Berlin/Heidelberg, Germany, 2015. 3. Berg, J.; J\u00e4rvisalo, M.; Malone, B. Learning optimal bounded treewidth Bayesian networks via maximum satisfiability. In\nProceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics, Reykjavik, Iceland, 22\u201325 April 2014; pp. 86\u201395.\n4. Darwiche, A. A differential approach to inference in Bayesian networks. J. ACM (JACM) 2003, 50, 280\u2013305. [CrossRef] 5. Elidan, G.; Gould, S. Learning bounded treewidth Bayesian networks. J. Mach. Learn. Res. 2008, 9, 2699\u20132731. 6. Kneis, J.; Langer, A.; Rossmanith, P. Courcelle\u2019s theorem\u2014A game-theoretic approach. Discret. Optim. 2011, 8, 568\u2013594. [CrossRef] 7. Bannach, M.; Berndt, S. Practical Access to Dynamic Programming on Tree Decompositions. Algorithms 2019, 12, 172. [CrossRef]\nAlgorithms 2022, 15, 42 31 of 33\n8. Bjesse, P.; Kukula, J.H.; Damiano, R.F.; Stanion, T.; Zhu, Y. Guiding SAT Diagnosis with Tree Decompositions. In Proceedings of the International Conference on Theory and Applications of Satisfiability Testing 2003, Santa Margherita Ligure, Italy, 5\u20138 May 2003; pp. 315\u2013329. 9. Fichte, J.K.; Hecher, M.; Woltran, S.; Zisser, M. Weighted Model Counting on the GPU by Exploiting Small Treewidth. In Proceedings of the 26th Annual European Symposium on Algorithms (ESA 2018), Helsinki, Finland, 20\u201322 August 2018; pp. 28:1\u201328:16. 10. Habet, D.; Paris, L.; Terrioux, C. A Tree Decomposition Based Approach to Solve Structured SAT Instances. In Proceedings of the 2009 21st IEEE International Conference on Tools with Artificial Intelligence, Newark, NJ, USA , 2\u20134 November 2009; pp. 115\u2013122. 11. Charwat, G.; Woltran, S. Dynamic Programming-based QBF Solving. In Proceedings of the QBF 2016, Bordeaux, France, 4 July 2016; pp. 27\u201340. 12. Eiben, E.; Ganian, R.; Ordyniak, S. Small Resolution Proofs for QBF using Dependency Treewidth. In Proceedings of the 35th Symposium on Theoretical Aspects of Computer Science (STACS 2018), Caen, France, 28 February\u20133 March 2018; Volume 96, pp. 28:1\u201328:15. 13. Karakashian, S.; Woodward, R.J.; Choueiry, B.Y. Improving the Performance of Consistency Algorithms by Localizing and Bolstering Propagation in a Tree Decomposition. In Proceedings of the AAAI Conference on Artificial Intelligence, Bellevue, WA, USA, 14\u201318 July 2013. 14. Koster, A.M.C.A.; van Hoesel, S.P.M.; Kolen, A.W.J. Solving partial constraint satisfaction problems with tree decomposition. Networks 2002, 40, 170\u2013180. [CrossRef] 15. Eisenbrand, F.; Hunkenschr\u00f6der, C.; Klein, K. Faster Algorithms for Integer Programs with Block Structure. In Proceedings of the 45th International Colloquium on Automata, Languages, and Programming (ICALP 2018), Prague, Czech Republic, 9\u201313 July 2018; Volume 107, pp. 49:1\u201349:13. 16. Ganian, R.; Ordyniak, S.; Ramanujan, M.S. Going Beyond Primal Treewidth for (M)ILP. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, San Francisco, CA, USA, 4\u20139 February 2017; pp. 815\u2013821. 17. Ganian, R.; Ordyniak, S. The complexity landscape of decompositional parameters for ILP. Artif. Intell. 2018, 257, 61\u201371. [CrossRef] 18. Kouteck\u00fd, M.; Levin, A.; Onn, S. A Parameterized Strongly Polynomial Algorithm for Block Structured Integer Programs. In Proceedings of the 45th International Colloquium on Automata, Languages, and Programming (ICALP 2018), Prague, Czech Republic, 9\u201313 July 2018; Volume 107, pp. 85:1\u201385:14. 19. Szeider, S. On Fixed-Parameter Tractable Parameterizations of SAT. In Proceedings of the Theory and Applications of Satisfiability Testing 2003, Santa Margherita Ligure, Italy, 5\u20138 May 2003; pp. 188\u2013202. 20. Bannach, M.; Berndt, S.; Ehlers, T. Jdrasil: A Modular Library for Computing Tree Decompositions. In Proceedings of the 16th International Symposium on Experimental Algorithms (SEA 2017), London, UK, 21\u201323 June 2017; pp. 28:1\u201328:21. 21. Bonifati, A.; Martens, W.; Timm, T. An analytical study of large SPARQL query logs. VLDB J. 2020, 29, 655\u2013679. [CrossRef] 22. Dudek, J.M.; Phan, V.H.N.; Vardi, M.Y. DPMC: Weighted Model Counting by Dynamic Programming on Project-Join Trees. In\nProceedings of the Principles and Practice of Constraint Programming\u201426th International Conference, CP 2020, Louvain-laNeuve, Belgium, 7\u201311 September 2020; pp. 211\u2013230. [CrossRef]\n23. Dudek, J.M.; Phan, V.H.N.; Vardi, M.Y. ProCount: Weighted Projected Model Counting with Graded Project-Join Trees. In Proceedings of the Theory and Applications of Satisfiability Testing\u2014SAT 2021\u201424th International Conference, Barcelona, Spain, 5\u20139 July 2021; pp. 152\u2013170. [CrossRef] 24. Korhonen, T.; J\u00e4rvisalo, M. Integrating Tree Decompositions into Decision Heuristics of Propositional Model Counters (Short Paper). In Proceedings of the 27th International Conference on Principles and Practice of Constraint Programming, CP 2021, (Virtual Conference), Montpellier, France, 25-29 October 2021; pp. 8:1\u20138:11. [CrossRef] 25. Maniu, S.; Senellart, P.; Jog, S. An Experimental Study of the Treewidth of Real-World Graph Data. In Proceedings of the 22nd International Conference on Database Theory, ICDT 2019, Lisbon, Portugal, 26-28 March 2019; pp. 12:1\u201312:18. [CrossRef] 26. Gutin, G.Z.; Jones, M.; Wahlstr\u00f6m, M. Structural Parameterizations of the Mixed Chinese Postman Problem. In Proceedings of the Algorithms\u2014ESA 2015\u201423rd Annual European Symposium, Patras, Greece, 14\u201316 September 2015; pp. 668\u2013679. [CrossRef] 27. Iwata, Y.; Ogasawara, T.; Ohsaka, N. On the Power of Tree-Depth for Fully Polynomial FPT Algorithms. In Proceedings of the 35th Symposium on Theoretical Aspects of Computer Science, STACS 2018, Caen, France, 28 February\u20133 March 2018; pp. 41:1\u201341:14. [CrossRef] 28. Brand, C.; Kouteck\u00fd, M.; Ordyniak, S. Parameterized Algorithms for MILPs with Small Treedepth. In Proceedings of the Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, 2\u20139 February 2021; pp. 12249\u201312257. 29. Bl\u00e4sius, T.; Fischbeck, P.; Friedrich, T.; Katzmann, M. Solving Vertex Cover in Polynomial Time on Hyperbolic Random Graphs. In Proceedings of the 37th International Symposium on Theoretical Aspects of Computer Science, STACS 2020, Montpellier, France, 10\u201313 March 2020; pp. 25:1\u201325:14. [CrossRef] 30. Fomin, F.V.; Giannopoulou, A.C.; Pilipczuk, M. Computing Tree-Depth Faster Than 2n. Algorithmica 2015, 73, 202\u2013216. [CrossRef]\nAlgorithms 2022, 15, 42 32 of 33\n31. Reidl, F.; Rossmanith, P.; Villaamil, F.S.; Sikdar, S. A Faster Parameterized Algorithm for Treedepth. In Proceedings of the Automata, Languages, and Programming\u201441st International Colloquium, ICALP 2014, Copenhagen, Denmark, 8\u201311 July 2014; pp. 931\u2013942. [CrossRef] 32. Bodlaender, H.L. A Linear-Time Algorithm for Finding Tree-Decompositions of Small Treewidth. SIAM J. Comput. 1996, 25, 1305\u20131317. [CrossRef] 33. R\u00f6hrig, H. Tree Decomposition: A Feasibility Study. Master\u2019s Thesis, Max-Planck-Institut f\u00fcr Informatik in Saarbr\u00fccken, Saarbr\u00fccken, Germany, 1998. 34. Gogate, V.; Dechter, R. A Complete Anytime Algorithm for Treewidth. In Proceedings of the UAI\u201904, 20th Conference in Uncertainty in Artificial Intelligence, Banff, AB, Canada, 7\u201311 July 2004; pp. 201\u2013208. 35. Coudert, D.; Mazauric, D.; Nisse, N. Experimental Evaluation of a Branch-and-Bound Algorithm for Computing Pathwidth and Directed Pathwidth. ACM J. Exp. Algorithmics 2016, 21, 1.3:1\u20131.3:23. [CrossRef] 36. Trimble, J. An Algorithm for the Exact Treedepth Problem. In Proceedings of the 18th International Symposium on Experimental Algorithms, SEA 2020, Catania, Italy, 16\u201318 June 2020; pp. 19:1\u201319:14. [CrossRef] 37. Hamann, M.; Strasser, B. Graph Bisection with Pareto Optimization. ACM J. Exp. Algorithmics 2018, 23, 1\u201334. [CrossRef] 38. Bodlaender, H.L.; Koster, A.M.C.A. Treewidth computations I. Upper bounds. Inf. Comput. 2010, 208, 259\u2013275. [CrossRef] 39. Tamaki, H. Computing Treewidth via Exact and Heuristic Lists of Minimal Separators. In Proceedings of the Analysis of Experimental Algorithms\u2014Special Event, SEA2 2019, Kalamata, Greece, 24\u201329 June 2019; pp. 219\u2013236. [CrossRef] 40. Kobayashi, Y.; Komuro, K.; Tamaki, H. Search Space Reduction through Commitments in Pathwidth Computation: An Experi-\nmental Study. In Proceedings of the Experimental Algorithms\u201413th International Symposium, SEA 2014, Copenhagen, Denmark, 29 June\u20131 July 2014; pp. 388\u2013399. [CrossRef]\n41. Fernando S\u00e1nchez Villaamil. About Treedepth and Related Notions. Ph.D. Thesis, RWTH Aachen University, Aachen, Germany, 2017. 42. Kask, K.; Gelfand, A.; Otten, L.; Dechter, R. Pushing the Power of Stochastic Greedy Ordering Schemes for Inference in Graphical Models. In Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2011, San Francisco, CA, USA, 7\u201311 August 2011. 43. Dell, H.; Husfeldt, T.; Jansen, B.; Kaski, P.; Komusiewicz, C.; Rosamond, F. The First Parameterized Algorithms and Computational Experiments Challenge. In Proceedings of the 11th International Symposium on Parameterized and Exact Computation (IPEC 2016), Aarhus, Denmark, 24\u201326 August 2016; pp. 30:1\u201330:9. 44. Dell, H.; Komusiewicz, C.; Talmon, N.; Weller, M. The PACE 2017 Parameterized Algorithms and Computational Experiments Challenge: The Second Iteration. In Proceedings of the 12th International Symposium on Parameterized and Exact Computation (IPEC 2017), Vienna, Austria, 6\u20138 September 2017. 45. Kowalik, L.; Mucha, M.; Nadara, W.; Pilipczuk, M.; Sorge, M.; Wygocki, P. The PACE 2020 Parameterized Algorithms and Computational Experiments Challenge: Treedepth. In Proceedings of the 15th International Symposium on Parameterized and Exact Computation, IPEC 2020 (Virtual Conference), Hong Kong, China, 14\u201318 December 2020; pp. 37:1\u201337:18. [CrossRef] 46. Tamaki, H. Treewidth-Exact. 2016. Available online: github.com/TCS-Meiji/treewidth-exact (accessed on 2 August 2017). 47. Larisch, L.; Salfelder, F. p17. 2017. Available online: https://github.com/freetdi/p17 (accessed on 2 August 2017). 48. Trimble, J. PACE Solver Description: Bute-Plus: A Bottom-Up Exact Solver for Treedepth. In Proceedings of the 15th International\nSymposium on Parameterized and Exact Computation, IPEC 2020 (Virtual Conference), Hong Kong, China, 14\u201318 December 2020; pp. 34:1\u201334:4. [CrossRef]\n49. Bannach, M.; Berndt, S.; Schuster, M.; Wien\u00f6bst, M. PACE Solver Description: PID?. In Proceedings of the 15th International Symposium on Parameterized and Exact Computation, IPEC 2020 (Virtual Conference), Hong Kong, China, 14\u201318 December 2020; pp. 28:1\u201328:4. [CrossRef] 50. Arnborg, S.; Corneil, D.G.; Proskurowski, A. Complexity of finding embeddings in ak-tree. SIAM J. Algebr. Discret. Methods 1987, 8, 277\u2013284. [CrossRef] 51. Bouchitt\u00e9, V.; Todinca, I. Listing all potential maximal cliques of a graph. Theor. Comput. Sci. 2002, 276, 17\u201332. [CrossRef] 52. Tamaki, H. Positive-instance driven dynamic programming for treewidth. J. Comb. Optim. 2019, 37, 1283\u20131311. [CrossRef] 53. Althaus, E.; Schnurbusch, D.; W\u00fcschner, J.; Ziegler, S. On Tamaki\u2019s Algorithm to Compute Treewidths. In Proceedings of the 19th International Symposium on Experimental Algorithms, SEA 2021, Nice, France, 7\u20139 June 2021; pp. 9:1\u20139:18. [CrossRef] 54. Fomin, F.V.; Kratsch, D. Exact Exponential Algorithms; Texts in Theoretical Computer Science, An EATCS Series; Springer: Berlin/Heidelberg, Germany, 2010. 55. Halin, R. S-functions for graphs. J. Geom. 1976, 8, 171\u2013186. [CrossRef] 56. Robertson, N.; Seymour, P.D. Graph minors. I. Excluding a forest. JCT J. Comb. Theory 1983, 35, 39\u201361. [CrossRef] 57. Robertson, N.; Seymour, P.D. Graph Minors. II. Algorithmic Aspects of Tree-Width. Algorithms 1986, 7, 309\u2013322. [CrossRef] 58. Nesetril, J.; de Mendez, P.O. Sparsity; Springer: Berlin/Heidelberg, Germany, 2012. 59. Seymour, P.; Thomas, R. Graph Searching and a Min-Max Theorem for Tree-Width. JCT J. Comb. Theory 1993, 58, 22\u201333. [CrossRef] 60. Kirousis, L.; Papadimitriou, C. Searching and Pebbling. TCS Theor. Comput. Sci. 1986, 47, 205\u2013218. [CrossRef] 61. Giannopoulou, A.; Hunter, P.; Thilikos, D. LIFO-search: A min-max theorem and a searching game for cycle-rank and tree-depth.\nDiscret. Appl. Math. 2012, 160, 2089\u20132097. [CrossRef]\nAlgorithms 2022, 15, 42 33 of 33\n62. Fomin, F.; Fraigniaud, P.; Nisse, N. Nondeterministic Graph Searching: From Pathwidth to Treewidth. Algorithmica 2009, 53, 358\u2013373. [CrossRef] 63. Tamaki, H. Experimental Analysis of Treewidth. In Treewidth, Kernels, and Algorithms\u2014Essays Dedicated to Hans L. Bodlaender on the Occasion of His 60th Birthday; Springer: Berlin/Heidelberg, Germany, 2020, pp. 214\u2013221._15. [CrossRef] 64. Korhonen, T. PACE Solver Description: SMS. In Proceedings of the 15th International Symposium on Parameterized and Exact Computation, IPEC 2020 (Virtual Conference), Hong Kong, China, 14\u201318 December 2020; pp. 30:1\u201330:4. [CrossRef] 65. Brokkelkamp, R.; van Veneti\u00eb, R.; de Vries, M.J.; Westerdiep, J. PACE Solver Description: TdULL. In Proceedings of the 15th International Symposium on Parameterized and Exact Computation, IPEC 2020 (Virtual Conference), Hong Kong, China, 14\u201318 December 2020; pp. 29:1\u201329:4. [CrossRef] 66. Lodha, N.; Ordyniak, S.; Szeider, S. A SAT Approach to Branchwidth. ACM Trans. Comput. Log. 2019, 20, 15:1\u201315:24. [CrossRef] 67. Ramaswamy, V.P.; Szeider, S. MaxSAT-Based Postprocessing for Treedepth. In Proceedings of the Principles and Practice of\nConstraint Programming\u201426th International Conference, CP 2020, Louvain-la-Neuve, Belgium, 7\u201311 September 2020; pp. 478\u2013495. [CrossRef]\n68. Ganian, R.; Lodha, N.; Ordyniak, S.; Szeider, S. SAT-Encodings for Treecut Width and Treedepth. In Proceedings of the TwentyFirst Workshop on Algorithm Engineering and Experiments, ALENEX 2019, San Diego, CA, USA, 7\u20138 January 2019; pp. 117\u2013129. [CrossRef] 69. Lodha, N.; Ordyniak, S.; Szeider, S. SAT-Encodings for Special Treewidth and Pathwidth. In Proceedings of the Theory and Applications of Satisfiability Testing\u2014SAT 2017\u201420th International Conference, Melbourne, Australia, 28 August 28\u20131 September 2017; pp. 429\u2013445. [CrossRef] 70. Samer, M.; Veith, H. Encoding Treewidth into SAT. In Proceedings of the Theory and Applications of Satisfiability Testing\u2014SAT 2009, 12th International Conference, SAT 2009, Swansea, UK, 30 June\u20133 July 2009; pp. 45\u201350. [CrossRef] 71. Berg, J.; J\u00e4rvisalo, M. SAT-Based Approaches to Treewidth Computation: An Evaluation. In Proceedings of the 26th IEEE International Conference on Tools with Artificial Intelligence, Limassol, Cyprus, 10\u201312 November 2014; pp. 328\u2013335. [CrossRef] 72. Bannach, M.; Berndt, S. Positive-Instance Driven Dynamic Programming for Graph Searching. In Proceedings of the Algorithms and Data Structures\u201416th International Symposium, WADS 2019, Edmonton, AB, Canada, 5\u20137 August 2019; pp. 43\u201356. [CrossRef] 73. Safari, M. D-Width: A More Natural Measure for Directed Tree Width. In Proceedings of the Mathematical Foundations of Computer Science 2005, Gdansk, Poland, 29 August\u20132 September 2005; pp. 745\u2013756. 74. Bienstock, D. Graph Searching, Path-Width, Tree-Width and Related Problems (A Survey). In Proceedings of the Reliability of Computer and Communication Networks, Proceedings of a DIMACS Workshop, New Brunswick, NJ, USA, 2\u20134 December 1989; pp. 33\u201350. [CrossRef] 75. Gruber, H.; Holzer, M. Finite Automata, Digraph Connectivity, and Regular Expression Size. In Proceedings of the International Colloquium on Automata, Languages, and Programming, Reykjavik, Iceland, 7\u201311 July 2008; pp. 39\u201350. [CrossRef] 76. Bienstock, D.; Seymour, P.D. Monotonicity in Graph Searching. J. Algorithms 1991, 12, 239\u2013245. [CrossRef] 77. LaPaugh, A. Recontamination Does Not Help to Search a Graph. ACM 1993, 40, 224\u2013245. [CrossRef] 78. Mazoit, F.; Nisse, N. Monotonicity of non-deterministic graph searching. TCS Theor. Comput. Sci. 2008, 399, 169\u2013178. [CrossRef] 79. Immerman, N. Descriptive Complexity; Springer: Berlin/Heidelberg, Germany, 1999. 80. Kahn, A.B. Topological sorting of large networks. Commun. ACM 1962, 5, 558\u2013562. [CrossRef] 81. Evans, W.; Hunter, P.; Safari, M. D-Width and Cops and Robbers; Technical Report, 2007; unpublished. 82. Savnik, I. Index Data Structure for Fast Subset and Superset Queries. In Proceedings of the 5th International Cross-Domain\nConference on Vailability, Reliability, and Security in Information Systems and HCI, Regensburg, Germany, 2\u20136 September 2013; pp. 134\u2013148. [CrossRef]\n83. Flum, J.; Grohe, M. Parameterized Complexity Theory; Texts in Theoretical Computer Science, An EATCS Series; Springer: Berlin/Heidelberg, Germany, 2006. 84. Koster, A.M.C.A.; Bodlaender, H.L.; van Hoesel, S.P.M. Treewidth: Computational Experiments. Electron. Notes Discret. Math. 2001, 8, 54\u201357. [CrossRef] 85. Gugelmann, L.; Panagiotou, K.; Peter, U. Random Hyperbolic Graphs: Degree Sequence and Clustering\u2014(Extended Abstract). In Proceedings of the Automata, Languages, and Programming\u201439th International Colloquium, ICALP 2012, Warwick, UK, 9\u201313 July 2012; pp. 573\u2013585. [CrossRef] 86. Bl\u00e4sius, T.; Friedrich, T.; Krohmer, A. Hyperbolic Random Graphs: Separators and Treewidth. In Proceedings of the 24th Annual European Symposium on Algorithms, Aarhus, Denmark, 22\u201324 August 2016; pp. 15:1\u201315:16. [CrossRef] 87. Aldecoa, R.; Orsini, C.; Krioukov, D.V. Hyperbolic graph generator. Comput. Phys. Commun. 2015, 196, 492\u2013496. [CrossRef] 88. Courcelle, B. On the model-checking of monadic second-order formulas with edge set quantifications. Discret. Appl. Math. 2012, 160, 866\u2013887. [CrossRef] 89. Bodlaender, H.L.; Kratsch, S.; Kreuzen, V.J.C.; Kwon, O.; Ok, S. Characterizing width two for variants of treewidth. Discret. Appl.\nMath. 2017, 216, 29\u201346. [CrossRef]"
        }
    ],
    "title": "Recent Advances in Positive-Instance Driven Graph Searching ",
    "year": 2022
}