{
    "abstractText": "The respiratory rate (RR) is a significant indicator to evaluate a patient\u2019s prognosis and status; however, it requires specific instrumentation or estimates from other monitored signals. A photoplethysmogram (PPG) is extensively used in clinical environments as well as in intensive care units (ICUs) to primarily monitor peripheral circulation while capturing indirect information about intrathoracic pressure changes. This study aims to apply and evaluate several deep learning models using a PPG for the continuous and accurate estimation of the RRs of patients. The dataset was collected twice for 2 min each in 100 patients aged 18 years and older from the surgical intensive care unit of a tertiary referral hospital. The BIDMC and CapnoBase public datasets were also analyzed. The collected dataset was preprocessed and split according to the 5-fold cross-validation. We used seven deep learning models, including our own Dilated Residual Neural Network, to check how accurately the RR estimates match the ground truth using the mean absolute error (MAE). As a result, when validated using the collected dataset, our model showed the best results with a 1.2628 \u00b1 0.2697 MAE on BIDMC and RespNet and with a 3.1268 \u00b1 0.6363 MAE on our dataset, respectively. In conclusion, RR estimation using PPG-derived models is still challenging and has many limitations. However, if there is an equal amount of data from various breathing groups to train, we expect that various models, including our Dilated ResNet model, which showed good results, can achieve better results than the current ones.",
    "authors": [
        {
            "affiliations": [],
            "name": "Chi Shin Hwang"
        },
        {
            "affiliations": [],
            "name": "Yong Hwan Kim"
        },
        {
            "affiliations": [],
            "name": "Jung Kyun Hyun"
        },
        {
            "affiliations": [],
            "name": "Joon Hwang Kim"
        },
        {
            "affiliations": [],
            "name": "Seo Rak Lee"
        },
        {
            "affiliations": [],
            "name": "Choong Min Kim"
        },
        {
            "affiliations": [],
            "name": "Jung Woo Nam"
        },
        {
            "affiliations": [],
            "name": "Eun Young Kim"
        }
    ],
    "id": "SP:62f9b3db17df2619397fe5e80df871c2cc0d0a5e",
    "references": [
        {
            "authors": [
                "W. Lim",
                "M. Van der Eerden",
                "R. Laing",
                "W. Boersma",
                "N. Karalus",
                "G. Town",
                "S. Lewis",
                "J. Macfarlane"
            ],
            "title": "Defining community acquired pneumonia severity on presentation to hospital: An international derivation and validation study",
            "venue": "Thorax",
            "year": 2003
        },
        {
            "authors": [
                "F. Shann",
                "K. Hart",
                "D. Thomas"
            ],
            "title": "Acute lower respiratory tract infections in children: Possible criteria for selection of patients for antibiotic therapy and hospital admission",
            "venue": "Bull. World Health Organ. 1984,",
            "year": 1984
        },
        {
            "authors": [
                "W.A. Knaus",
                "E.A. Draper",
                "D.P. Wagner",
                "J.E. Zimmerman"
            ],
            "title": "APACHE II: A severity of disease classification system",
            "venue": "Crit. Care Med",
            "year": 1985
        },
        {
            "authors": [
                "M. Singer",
                "C.S. Deutschman",
                "C.W. Seymour",
                "M. Shankar-Hari",
                "D. Annane",
                "M. Bauer",
                "R. Bellomo",
                "G.R. Bernard",
                "J.D. Chiche",
                "C.M Coopersmith"
            ],
            "title": "The Third International Consensus Definitions for Sepsis and Septic Shock (Sepsis-3)",
            "venue": "JAMA",
            "year": 2016
        },
        {
            "authors": [
                "D.R. Goldhill"
            ],
            "title": "The critically ill: Following your MEWS",
            "venue": "QJM Int. J. Med",
            "year": 2001
        },
        {
            "authors": [
                "J. Hogan"
            ],
            "title": "Why don\u2019t nurses monitor the respiratory rates of patients",
            "venue": "Br. J. Nurs",
            "year": 2006
        },
        {
            "authors": [
                "P.H. Charlton",
                "D.A. Birrenkott",
                "T. Bonnici",
                "M.A.F. Pimentel",
                "A.E.W. Johnson",
                "J. Alastruey",
                "L. Tarassenko",
                "P.J. Watkinson",
                "R. Beale",
                "D.A. Clifton"
            ],
            "title": "Breathing Rate Estimation From the Electrocardiogram and Photoplethysmogram: A Review",
            "venue": "IEEE Rev. Biomed. Eng",
            "year": 2018
        },
        {
            "authors": [
                "A.K. Gupta"
            ],
            "title": "Respiration Rate Measurement Based on Impedance Pneumography; Texas Instruments: Dallas",
            "venue": "TX, USA,",
            "year": 2011
        },
        {
            "authors": [
                "J. Allen"
            ],
            "title": "Photoplethysmography and its application in clinical physiological measurement",
            "venue": "Physiol. Meas",
            "year": 2007
        },
        {
            "authors": [
                "R. Sahni"
            ],
            "title": "Noninvasive monitoring by photoplethysmography",
            "venue": "Clin. Perinatol",
            "year": 2012
        },
        {
            "authors": [
                "S. Albawi",
                "T.A. Mohammed",
                "S. Al-Zawi"
            ],
            "title": "Understanding of a convolutional neural network",
            "venue": "In Proceedings of the 2017 International Conference on Engineering and Technology (ICET), Antalya, Turkey,",
            "year": 2017
        },
        {
            "authors": [
                "A.L. Goldberger",
                "L.A. Amaral",
                "L. Glass",
                "J.M. Hausdorff",
                "P.C. Ivanov",
                "R.G. Mark",
                "J.E. Mietus",
                "G.B. Moody",
                "C.-K. Peng",
                "H.E. Stanley"
            ],
            "title": "PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation",
            "year": 2000
        },
        {
            "authors": [
                "M.A. Pimentel",
                "A.E. Johnson",
                "P.H. Charlton",
                "D. Birrenkott",
                "P.J. Watkinson",
                "L. Tarassenko",
                "D.A. Clifton"
            ],
            "title": "Toward a robust estimation of respiratory rate from pulse oximeters",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2016
        },
        {
            "authors": [
                "W. Karlen",
                "S. Raman",
                "J.M. Ansermino",
                "G.A. Dumont"
            ],
            "title": "Multiparameter respiratory rate estimation from the photoplethysmogram",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2013
        },
        {
            "authors": [
                "B.A. Shenoi"
            ],
            "title": "Finite Impulse Response Filters. In Introduction to Digital Signal Processing and Filter Design",
            "year": 2005
        },
        {
            "authors": [
                "J. Park",
                "H.S. Seok",
                "S.-S. Kim",
                "H. Shin"
            ],
            "title": "Photoplethysmogram Analysis and Applications: An Integrative Review",
            "venue": "Front. Physiol. 2022,",
            "year": 2022
        },
        {
            "authors": [
                "T. Iqbal",
                "A. Elahi",
                "S. Ganly",
                "W. Wijns",
                "A. Shahzad"
            ],
            "title": "Photoplethysmography-Based Respiratory Rate Estimation Algorithm for Health Monitoring Applications",
            "venue": "J. Med. Biol. Eng",
            "year": 2022
        },
        {
            "authors": [
                "F.J. Harris"
            ],
            "title": "On the use of windows for harmonic analysis with the discrete Fourier transform",
            "venue": "Proc. IEEE",
            "year": 1978
        },
        {
            "authors": [
                "L.M. Nilsson"
            ],
            "title": "Respiration signals from photoplethysmography",
            "venue": "Anesth. Analg",
            "year": 2013
        },
        {
            "authors": [
                "S. Khreis",
                "D. Ge",
                "H.A. Rahman",
                "G. Carrault"
            ],
            "title": "Breathing Rate Estimation Using Kalman Smoother with Electrocardiogram and Photoplethysmogram",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2020
        },
        {
            "authors": [
                "J.F. Steffensen"
            ],
            "title": "Interpolation; Courier Corporation: North Chelmsford",
            "venue": "MA, USA,",
            "year": 2006
        },
        {
            "authors": [
                "D. Bian",
                "P. Mehta",
                "N. Selvaraj"
            ],
            "title": "Respiratory rate estimation using PPG: A deep learning approach",
            "venue": "In Proceedings of the 2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), Montreal, QC, Canada,",
            "year": 2020
        },
        {
            "authors": [
                "V. Ravichandran",
                "B. Murugesan",
                "V. Balakarthikeyan",
                "K. Ram",
                "S. Preejith",
                "J. Joseph",
                "M. Sivaprakasam"
            ],
            "title": "RespNet: A deep learning model for extraction of respiration from photoplethysmogram",
            "venue": "In Proceedings of the 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Berlin,",
            "year": 2019
        },
        {
            "authors": [
                "A.K. Kumar",
                "M. Ritam",
                "L. Han",
                "S. Guo",
                "R. Chandra"
            ],
            "title": "Deep learning for predicting respiratory rate from biosignals",
            "venue": "Comput. Biol. Med",
            "year": 2022
        },
        {
            "authors": [
                "K. He",
                "X. Zhang",
                "S. Ren",
                "J. Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV, USA,",
            "year": 2016
        },
        {
            "authors": [
                "O. Ronneberger",
                "P. Fischer",
                "T. Brox"
            ],
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "venue": "In Proceedings of the Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI 2015: 18th International Conference, Munich, Germany,",
            "year": 2015
        },
        {
            "authors": [
                "S. Hochreiter",
                "J. Schmidhuber"
            ],
            "title": "Long Short-Term Memory",
            "venue": "Neural Comput",
            "year": 1997
        },
        {
            "authors": [
                "X. Shi",
                "Z. Chen",
                "H. Wang",
                "D.-Y. Yeung",
                "W.-K. Wong",
                "W.-C. Woo"
            ],
            "title": "Convolutional LSTM network: A machine learning approach for precipitation nowcasting",
            "venue": "In Advances in Neural Information Processing Systems 28, Proceedings of the 29th Annual Conference on Neural Information Processing Systems",
            "year": 2015
        },
        {
            "authors": [
                "M. Schuster",
                "K.K. Paliwal"
            ],
            "title": "Bidirectional recurrent neural networks",
            "venue": "IEEE Trans. Signal Process",
            "year": 1997
        },
        {
            "authors": [
                "A. Vaswani",
                "N. Shazeer",
                "N. Parmar",
                "J. Uszkoreit",
                "L. Jones",
                "A.N. Gomez",
                "\u0141. Kaiser",
                "I. Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "arXiv 2017,",
            "year": 2017
        },
        {
            "authors": [
                "D. Bahdanau",
                "K. Cho",
                "Y. Bengio"
            ],
            "title": "Neural machine translation by jointly learning to align and translate",
            "venue": "arXiv 2014,",
            "year": 2014
        },
        {
            "authors": [
                "G. Li",
                "L. Zhu",
                "P. Liu",
                "Y. Yang"
            ],
            "title": "Entangled transformer for image captioning",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision, Seoul, Republic of Korea,",
            "year": 2019
        },
        {
            "authors": [
                "X. Niu",
                "Y. Hou",
                "P. Wang"
            ],
            "title": "Bi-directional LSTM with quantum attention mechanism for sentence modeling",
            "venue": "In Proceedings of the Neural Information Processing: 24th International Conference,",
            "year": 2017
        },
        {
            "authors": [
                "F. Yu",
                "V. Koltun"
            ],
            "title": "Multi-scale context aggregation by dilated convolutions",
            "venue": "arXiv 2015,",
            "year": 2015
        },
        {
            "authors": [
                "R. Gao"
            ],
            "title": "Rethinking Dilated Convolution for Real-Time Semantic Segmentation",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2023
        },
        {
            "authors": [
                "T. Yu",
                "H. Zhu"
            ],
            "title": "Hyper-parameter optimization: A review of algorithms and applications",
            "venue": "arXiv 2020,",
            "year": 2020
        },
        {
            "authors": [
                "J. Lee",
                "M. Kim",
                "H.-K. Park",
                "I.Y. Kim"
            ],
            "title": "Motion Artifact Reduction in Wearable Photoplethysmography Based on Multi-Channel Sensors with Multiple Wavelengths",
            "venue": "Sensors",
            "year": 2020
        },
        {
            "authors": [
                "E. Hassan",
                "M.Y. Shams",
                "N.A. Hikal",
                "S. Elmougy"
            ],
            "title": "The effect of choosing optimizer algorithms to improve computer vision tasks: A comparative study",
            "venue": "Multimed. Tools Appl",
            "year": 2023
        },
        {
            "authors": [
                "A. Sapra",
                "A. Malik",
                "P. Bhandari"
            ],
            "title": "Vital Sign Assessment; StatPearls Publishing: Treasure Island, FL, USA, 2022",
            "year": 2022
        },
        {
            "authors": [
                "C.R. Harris",
                "K.J. Millman",
                "S.J. van der Walt",
                "R. Gommers",
                "P. Virtanen",
                "D. Cournapeau",
                "E. Wieser",
                "J. Taylor",
                "S. Berg",
                "N.J Smith"
            ],
            "title": "Array programming with NumPy",
            "venue": "Nature",
            "year": 2020
        },
        {
            "authors": [
                "P. Virtanen",
                "R. Gommers",
                "T.E. Oliphant",
                "M. Haberland",
                "T. Reddy",
                "D. Cournapeau",
                "E. Burovski",
                "P. Peterson",
                "W. Weckesser",
                "J Bright"
            ],
            "title": "SciPy 1.0: Fundamental algorithms for scientific computing in Python",
            "venue": "Nat. Methods",
            "year": 2020
        },
        {
            "authors": [
                "J.D. Hunter"
            ],
            "title": "Matplotlib: A 2D Graphics Environment",
            "venue": "Comput. Sci. Eng",
            "year": 2007
        },
        {
            "authors": [
                "J.M. Bland",
                "D.G. Altman"
            ],
            "title": "Statistical methods for assessing agreement between two methods of clinical measurement",
            "venue": "Lancet 1986,",
            "year": 1986
        },
        {
            "authors": [
                "M.H. Chowdhury",
                "M.N.I. Shuzan",
                "M.E.H. Chowdhury",
                "Z.B. Mahbub",
                "M.M. Uddin",
                "A. Khandakar",
                "M.B.I. Reaz"
            ],
            "title": "Estimating Blood Pressure from the Photoplethysmogram Signal and Demographic Features Using Machine Learning Techniques",
            "venue": "Sensors",
            "year": 2020
        },
        {
            "authors": [
                "S.C. Douglas"
            ],
            "title": "Introduction to adaptive filters",
            "venue": "In Digital Signal Processing Fundamentals; CRC Press: Boca Raton, FL,",
            "year": 2017
        },
        {
            "authors": [
                "R. Dwivedi",
                "D. Dave",
                "H. Naik",
                "S. Singhal",
                "R. Omer",
                "P. Patel",
                "B. Qian",
                "Z. Wen",
                "T. Shah",
                "G Morgan"
            ],
            "title": "Explainable AI (XAI): Core Ideas, Techniques, and Solutions",
            "venue": "ACM Comput. Surv",
            "year": 2023
        },
        {
            "authors": [
                "A. Chaddad",
                "J. Peng",
                "J. Xu",
                "A. Bouridane"
            ],
            "title": "Survey of Explainable AI Techniques in Healthcare",
            "venue": "Sensors 2023,",
            "year": 2023
        },
        {
            "authors": [
                "X. Ying"
            ],
            "title": "An overview of overfitting and its solutions",
            "venue": "J. Phys. Conf. Ser",
            "year": 2019
        },
        {
            "authors": [
                "C. Orphanidou",
                "T. Bonnici",
                "P. Charlton",
                "D. Clifton",
                "D. Vallance",
                "L. Tarassenko"
            ],
            "title": "Signal-quality indices for the electrocardiogram and photoplethysmogram: Derivation and applications to wireless monitoring",
            "venue": "IEEE J. Biomed. Health Inform",
            "year": 2015
        },
        {
            "authors": [
                "Y. Liang",
                "M. Elgendi",
                "Z. Chen",
                "R. Ward"
            ],
            "title": "An optimal filter for short photoplethysmogram",
            "venue": "signals. Sci. Data 2018,",
            "year": 2018
        },
        {
            "authors": [
                "G.D. Lucaf\u00f3",
                "P. Freitas",
                "R. Lima",
                "G. da Luz",
                "R. Bispo",
                "P. Rodrigues",
                "F. Cabello",
                "O. Penatti"
            ],
            "title": "Signal quality assessment of photoplethysmogram signals using hybrid rule-and learning-based models",
            "venue": "J. Health Inform",
            "year": 2023
        },
        {
            "authors": [
                "Q. Li",
                "G.D. Clifford"
            ],
            "title": "Dynamic time warping and machine learning for signal quality assessment of pulsatile signals",
            "venue": "Physiol. Meas",
            "year": 2012
        }
    ],
    "sections": [
        {
            "text": "Citation: Hwang, C.S.; Kim, Y.H.;\nHyun, J.K.; Kim, J.H.; Lee, S.R.; Kim,\nC.M.; Nam, J.W.; Kim, E.Y. Evaluation\nof the Photoplethysmogram-Based\nDeep Learning Model for Continuous\nRespiratory Rate Estimation in\nSurgical Intensive Care Unit.\nBioengineering 2023, 10, 1222.\nhttps://doi.org/10.3390/\nbioengineering10101222\nAcademic Editor: Giuseppe Baselli\nReceived: 21 August 2023\nRevised: 16 October 2023\nAccepted: 17 October 2023\nPublished: 19 October 2023\nCopyright: \u00a9 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: photoplethysmogram; respiratory rate; intensive care unit; surgery; signal; prediction; deep learning; convolutional neural network; residual neural network"
        },
        {
            "heading": "1. Introduction",
            "text": "The respiratory rate (RR) can be useful for critically ill patients as a significant indicator to evaluate a patient\u2019s prognosis and status, as it not only represents a clinical status change in a patient\u2019s respiratory system function but also participates in the respiratory compensation mechanism for tissue hypoperfusion and systemic circulation dysfunction such as shock [1,2]. The importance of the RR can also be seen in the various scoring systems such as the Acute Physiology And Chronic Health Evaluation (APACHE) [3], which assesses the prognosis of a patient\u2019s disease in the intensive care unit (ICU); the Sequential Organ Failure Assessment (SOFA, qSOFA) [4], which conventionally assesses the level of organ failure and infection; and the Modified Early Warning Score (MEWS) [5], which is used for the continuous surveillance of the patient\u2019s condition. However, the general RR measuring method that is currently conducted in clinical practice is a manual counting method measured by nursing staff, which does not fit for continuous all-time surveillance [6]. Although various RR estimation methods using physiological signals\nBioengineering 2023, 10, 1222. https://doi.org/10.3390/bioengineering10101222 https://www.mdpi.com/journal/bioengineering\nBioengineering 2023, 10, 1222 2 of 17\n(etCO2, ECG, Impedance Pneumography signal, and Oral\u2013Nasal Pressure) have been developed to compensate for this shortcoming [7\u20139], a requirement of additional equipment such as an impedance meter, ECG leads, the restriction of movement due to such equipment, and the difficulty of always-on measurement come as its limitations. Eventually, this limits the applicability of these methods as standard methods for continuous real-time RR surveillance in critically ill patients. A photoplethysmogram (PPG) is a physiological signal that implies the information of blood volume changes in the microvascular bed of tissue detected using the pulse oximeter. It is normally acquired from a subject\u2019s peripheral site such as a fingertip, with a lightemitting diode that illuminates a red or a near-infrared wavelength and detects its reflections through the photodetector. At this point, the most affecting factor of the signal is the blood volume, especially in the arteries, as the blood vessel constantly changes in response to cardiac contraction, breathing, and the autonomic nervous system [10,11]. Therefore, the morphological characteristics and time-dependent attributes of the PPG signal contain various and significant clinical information that indirectly indicates a subject\u2019s heart rate, blood pressure, oxygen saturation, and respiratory rate [11,12]. Deep learning (DL), an Artificial Intelligence algorithm that is widely utilized in image detection, time forecasting, natural language processing, etc., according to the architectural design, can be trained to extract various features effectively from the physiological signal (e.g., PPG) using a feature extractor [13] and to estimate another signal (e.g., RR). Herein, we collected real-time PPG and RR data from patients admitted to the surgical intensive care unit (SICU) of a tertiary referral hospital in Korea, and they were used in several previously studied DL models for RR estimation. Moreover, we implemented a novel DL model and compared its performance with others to verify the significance of a PPG-derived DL model\u2019s RR estimation."
        },
        {
            "heading": "2. Materials and Methods",
            "text": ""
        },
        {
            "heading": "2.1. PPG Measurement and Dataset Collection",
            "text": "Our dataset in the current study consisted of 100 patients aged 18 years and older. Experiments were conducted in the SICU of our institution, which has been operated as a closed ICU system by two critical care specialists who take care of all patients admitted to the SICU. The diagnosis of a patient was made through a consultation with the specialists, and the decision was made by considering the patient\u2019s blood test, physical examination, imaging test, and history. The dataset contained demographic information, PPG signals, and exhalation timestamps for each de-identified subject. Two-minute PPGs were collected for each subject twice, sampled at 125 Hz. A unique ID was generated for each collected two-minute PPG. This ID served as an identifier for individual data and as a de-identifier for the subject at the same time. Table 1 shows the participants\u2019 characteristics and the details extracted from our dataset.\n* SD = Standard Deviation.\nBioengineering 2023, 10, 1222 3 of 17\nThe PPG signal collector is a respiratory counter web application, and its signal collecting process is represented in Figure 1. A router was linked with a laptop to connect the network between the browser and the patient monitor. In this study, for our research, data were collected from patients through a pulse oximeter connected to the patient\u2019s monitor. All patient measurements were taken while they were lying in the supine position. The subject\u2019s demographic information must be entered into the PPG signal collector to acquire the data. When the collection started, the PPG signal was continuously recorded during the time limit, and the RR was recorded manually by medical staff pressing the spacebar at the exhalation time. To ensure the collection of 2 min of data, the measurement time was set to 2 min and 10 s. When the time ended, the data were recorded and stored in the database. Medical staff supported our data collection using the PPG signal collector.\nBioengineering\u00a02023,\u00a010,\u00a0x\u00a0FOR\u00a0PEER\u00a0REVIEW\u00a0 3\u00a0 of\u00a0 18\u00a0 \u00a0\nDiagnosis,\u00a0n\u00a0(%)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Malignancy\u00a0 54\u00a0(54)\u00a0 30\u00a0(53.6)\u00a0 24\u00a0(54.5)\u00a0 1.000\u00a0\nNon-cancerous\u00a0lesion\u00a0 28\u00a0(28)\u00a0 16\u00a0(28.6)\u00a0 12\u00a0(27.3)\u00a0 1.000\u00a0 Trauma\u00a0 10\u00a0(10)\u00a0 5\u00a0(8.9)\u00a0 5\u00a0(11.4)\u00a0 0.798\u00a0\nMiscellaneous\u00a0 8\u00a0(8)\u00a0 5\u00a0(8.9)\u00a0 3\u00a0(6.8)\u00a0 0.891\u00a0 *\u00a0SD\u00a0=\u00a0Standard\u00a0Deviation.\u00a0\nThe\u00a0PPG\u00a0signal\u00a0collector\u00a0is\u00a0a\u00a0respiratory\u00a0counter\u00a0web\u00a0application,\u00a0and\u00a0its\u00a0signal\u00a0collecting\u00a0process\u00a0is\u00a0represented\u00a0in\u00a0Figure\u00a01.\u00a0A\u00a0 outer\u00a0was\u00a0linked\u00a0with\u00a0a\u00a0laptop\u00a0to\u00a0connect\u00a0the\u00a0 network\u00a0between\u00a0the\u00a0browser\u00a0and\u00a0the\u00a0patient\u00a0monitor.\u00a0In\u00a0this\u00a0study,\u00a0for\u00a0our\u00a0research,\u00a0data\u00a0 were\u00a0collected\u00a0from\u00a0patients\u00a0through\u00a0a\u00a0pulse\u00a0oximeter\u00a0connected\u00a0to\u00a0the\u00a0patient\u2019s\u00a0monitor.\u00a0 All\u00a0patient\u00a0measurements\u00a0were\u00a0taken\u00a0while\u00a0they\u00a0were\u00a0lying\u00a0in\u00a0the\u00a0supine\u00a0position.\u00a0The\u00a0 subject\u2019s\u00a0demographic\u00a0 information\u00a0must\u00a0be\u00a0entered\u00a0into\u00a0the\u00a0PPG\u00a0signal\u00a0collector\u00a0to\u00a0acquire\u00a0 the\u00a0data.\u00a0When\u00a0 the\u00a0collection\u00a0started,\u00a0 the\u00a0PPG\u00a0signal\u00a0was\u00a0continuously\u00a0recorded\u00a0 during\u00a0the\u00a0time\u00a0limit,\u00a0and\u00a0the\u00a0RR\u00a0 as\u00a0recorded\u00a0manually\u00a0by\u00a0medical\u00a0staff\u00a0pressing\u00a0the\u00a0 spacebar\u00a0at\u00a0the\u00a0 xhalatio \u00a0ti .\u00a0 \u00a0ensure\u00a0the\u00a0collection\u00a0of\u00a02\u00a0min\u00a0of\u00a0data,\u00a0the\u00a0measurement\u00a0 time\u00a0was\u00a0 et\u00a0 o\u00a02\u00a0 i \u00a0 \u00a010\u00a0s.\u00a0When\u00a0the\u00a0time\u00a0ended,\u00a0the\u00a0data\u00a0were\u00a0recor ed\u00a0and\u00a0stored\u00a0 in\u00a0t e\u00a0 atabase.\u00a0 edical\u00a0staff\u00a0supported\u00a0our\u00a0data\u00a0collectio \u00a0using\u00a0the\u00a0PPG\u00a0signal\u00a0collector.\u00a0 \u00a0\n\u00a0\nFigure\u00a01.\u00a0Picture\u00a0of\u00a0PPG\u00a0collecting\u00a0process.\u00a0\nThe\u00a0details\u00a0of\u00a0the\u00a0collection\u00a0procedure\u00a0are\u00a0as\u00a0follows:\u00a0 1. Move\u00a0into\u00a0the\u00a0local\u00a0monitoring\u00a0page\u00a0through\u00a0the\u00a0browser\u00a0installed\u00a0on\u00a0the\u00a0laptop.\u00a0 2. Set\u00a0up\u00a0the\u00a0measuring\u00a0time.\u00a0 3. Register\u00a0the\u00a0subject\u2019s\u00a0demographic\u00a0information\u00a0including\u00a0gender,\u00a0age,\u00a0and\u00a0diagnosis\u00a0 to\u00a0start\u00a0recording.\u00a0 4. When\u00a0a\u00a0window\u00a0pops\u00a0up,\u00a0click\u00a0the\u00a0start\u00a0button\u00a0to\u00a0record\u00a0the\u00a0PPG.\u00a0 5. Press\u00a0the\u00a0spacebar\u00a0when\u00a0the\u00a0subject\u00a0exhales.\u00a0 6. When\u00a0the\u00a0time\u00a0is\u00a0up,\u00a0the\u00a0window\u00a0will\u00a0close,\u00a0and\u00a0the\u00a0data\u00a0will\u00a0be\u00a0stored\u00a0automatically.\u00a0\nThe\u00a0PPG\u00a0signal\u00a0collector\u00a0receives\u00a0medical\u00a0data\u00a0from\u00a0the\u00a0Philips\u00a0IntelliVue\u00a0MX450,\u00a0 referring\u00a0to\u00a0the\u00a0interlocking\u00a0specification\u00a0provided\u00a0by\u00a0Philips\u00a0[14].\u00a0We\u00a0used\u00a0a\u00a0MacOS\u00a0Big\u00a0 Sur\u00a0v11.4\u00a0laptop\u00a0with\u00a0a\u00a01.3\u00a0GHz\u00a0dual-core\u00a0Intel\u00a0Core\u00a07\u00a0processor\u00a0CPU\u00a0and\u00a08\u00a0GB\u00a01600\u00a0MHz\u00a0 DDR3\u00a0memory\u00a0for\u00a0our\u00a0research\u00a0and\u00a0used\u00a0Safari\u00a0v14.11\u00a0for\u00a0the\u00a0browser.\u00a0The\u00a0application\u00a0 was\u00a0developed\u00a0in\u00a0NestJS\u00a0v8.0.0\u00a0and\u00a0Vue\u00a0v3.2.31\u00a0based\u00a0on\u00a0Javascript\u00a02017\u00a0(ES8),\u00a0and\u00a0the\u00a0 database\u00a0was\u00a0configured\u00a0with\u00a0MongoDB\u00a0v5.0.9.\u00a0The\u00a0overall\u00a0structure\u00a0of\u00a0the\u00a0PPG\u00a0signal\u00a0 collector\u00a0is\u00a0shown\u00a0in\u00a0Figure\u00a02.\u00a0All\u00a0research\u00a0protocols\u00a0followed\u00a0were\u00a0in\u00a0accordance\u00a0with\u00a0 the\u00a0ethical\u00a0standards\u00a0of\u00a0the\u00a0responsible\u00a0committee\u00a0on\u00a0human\u00a0experimentation\u00a0and\u00a0with\u00a0 the\u00a0Helsinki\u00a0Declaration\u00a0of\u00a01975,\u00a0as\u00a0revised\u00a0in\u00a02000.\u00a0All\u00a0data\u00a0used\u00a0in\u00a0this\u00a0study\u00a0were\u00a0anonymized,\u00a0deidentified,\u00a0 and\u00a0 aggregated\u00a0before\u00a0 analysis.\u00a0 Informed\u00a0 consent\u00a0was\u00a0obtained\u00a0\nFigure 1. Picture of PPG collecting process.\nThe details of th collection procedur are as f llows:\n1. Move into the local monitoring page through the browser installed on the laptop. 2. Set up the measuring time. 3. Register the subject\u2019s demographic information including gender, age, and diagnosis to start recording. 4. When a window pops up, click the start button to record the PPG. 5. Press the spacebar when the subject exhales. 6. When the time is up, the window will close, and the data will be stored automatically.\nThe PPG signal collector receives medical data from the Philips IntelliVue MX450, referring to the i terlocking specification provided by Philips [14]. We used a MacOS Big Sur v11.4 laptop with a 1.3 GHz dual-core Intel Core 7 processor CPU and 8 GB 1600 MHz DDR3 memory for our research and used Safari v14.11 for the browser. The application was developed in NestJS v8.0.0 and Vue v3.2.31 based on Javascript 2017 (ES8), and the database was configured with MongoDB v5.0.9. The overall structure of the PPG signal collector is shown in Figure 2. All research protocols followed were in accordance with the ethical standards of the responsible committee on human experimentation and with the Hel inki Declaration of 1975, as revised in 2000. All data used in this study wer anonymized, deidentified, and aggregat d before analysis. Informed consent was obtaine from all participants r caregivers. This study was approved by the I stitutional Review Board of the Ethics Committee of Seoul St. Mary\u2019s Hospital (IRB No. KC21ONSI0839).\nBioengineering 2023, 10, 1222 4 of 17\nBioengineering\u00a02023,\u00a010,\u00a0x\u00a0FOR\u00a0PEER\u00a0REVIEW\u00a0 4\u00a0 of\u00a0 18\u00a0 \u00a0\nfrom\u00a0all\u00a0participants\u00a0or\u00a0caregivers.\u00a0This\u00a0study\u00a0was\u00a0approved\u00a0by\u00a0the\u00a0Institutional\u00a0Review\u00a0 Board\u00a0of\u00a0the\u00a0Ethics\u00a0Committee\u00a0of\u00a0Seoul\u00a0St.\u00a0Mary\u2019s\u00a0Hospital\u00a0(IRB\u00a0No.\u00a0KC21ONSI0839).\u00a0\n\u00a0 Figure\u00a02.\u00a0Signal\u00a0collector\u00a0architecture.\u00a0\n2.2.\u00a0Additional\u00a0Dataset\u00a0 In\u00a0addition\u00a0to\u00a0the\u00a0above\u00a0datasets,\u00a0we\u00a0used\u00a0additional\u00a0datasets\u00a0for\u00a0the\u00a0training\u00a0and\u00a0 validation\u00a0of\u00a0DL\u00a0models.\u00a0The\u00a0datasets\u00a0are\u00a0described\u00a0below.\u00a0\n2.2.1.\u00a0BIDMC\u00a0 BIDMC\u00a0[15,16]\u00a0 is\u00a053\u00a0samples\u00a0of\u00a08\u00a0min\u00a0duration\u00a0signals\u00a0collected\u00a0from\u00a0ICU\u00a0of\u00a0Beth\u00a0 Israel\u00a0Deaconess\u00a0Medical\u00a0Center.\u00a0Two\u00a0annotators\u00a0labeled\u00a0the\u00a0RR\u00a0using\u00a0each\u00a0subject\u2019s\u00a0impedance\u00a0respiratory\u00a0signal.\u00a0However,\u00a0we\u00a0excluded\u00a0samples\u00a0with\u00a0IDs\u00a013,\u00a015,\u00a0and\u00a019,\u00a0which\u00a0 had\u00a0missing\u00a0values\u00a0for\u00a0RR,\u00a0so\u00a0a\u00a0total\u00a0of\u00a050\u00a0samples\u00a0were\u00a0used\u00a0in\u00a0the\u00a0study.\u00a0The\u00a0dataset\u00a0 consists\u00a0of\u00a0impedance\u00a0respiratory,\u00a0electrocardiogram,\u00a0and\u00a0PPG\u00a0sampled\u00a0in\u00a0125\u00a0Hz.\u00a0It\u00a0also\u00a0 includes\u00a0demographics\u00a0and\u00a01\u00a0Hz\u00a0signals\u00a0such\u00a0as\u00a0heart\u00a0rate,\u00a0respiratory\u00a0rate,\u00a0O2\u00a0saturation,\u00a0 and\u00a0pulse.\u00a0This\u00a0dataset\u00a0provides\u00a0various\u00a0 formats,\u00a0 including\u00a0csv,\u00a0 for\u00a0countless\u00a0research\u00a0 and\u00a0benchmark\u00a0tests,\u00a0and\u00a0it\u00a0is\u00a0a\u00a0public\u00a0dataset.\u00a0In\u00a0this\u00a0study,\u00a0we\u00a0used\u00a0the\u00a0PPG\u00a0signal\u00a0and\u00a0 RR\u00a0provided\u00a0by\u00a0the\u00a0dataset\u00a0to\u00a0validate\u00a0the\u00a0model.\u00a0\n2.2.2.\u00a0CapnoBase\u00a0 The\u00a0IEEE\u00a0TBME\u00a0Respiratory\u00a0Rate\u00a0Benchmark\u00a0dataset\u00a0[17]\u00a0is\u00a0a\u00a0dataset\u00a0designed\u00a0for\u00a0 developing\u00a0and\u00a0testing\u00a0RR\u00a0estimation.\u00a0The\u00a0dataset\u00a0contains\u00a08\u00a0min\u00a0electrocardiogram,\u00a0capnography,\u00a0and\u00a0PPG\u00a0signals\u00a0acquired\u00a0from\u00a042\u00a0patients\u00a0during\u00a0elective\u00a0surgery\u00a0and\u00a0routine\u00a0 anesthesia.\u00a0Labels\u00a0from\u00a0an\u00a0annotator\u00a0are\u00a0available\u00a0for\u00a0peaks\u00a0from\u00a0PPG\u00a0and\u00a0breaths\u00a0from\u00a0 CO2.\u00a0The\u00a0data\u00a0were\u00a0obtained\u00a0from\u00a029\u00a0children\u00a0and\u00a013\u00a0adults.\u00a0The\u00a0dataset\u00a0was\u00a0used\u00a0for\u00a0 validation\u00a0purposes,\u00a0and\u00a0only\u00a013\u00a0adult\u00a0patients\u00a0were\u00a0used\u00a0 in\u00a0this\u00a0study,\u00a0given\u00a0that\u00a0the\u00a0 study\u00a0was\u00a0conducted\u00a0on\u00a0adult\u00a0patients.\u00a0\n2.3.\u00a0Preprocessing\u00a0 When\u00a0measuring\u00a0the\u00a0PPG\u00a0signal\u00a0using\u00a0a\u00a0pulse\u00a0oximeter,\u00a0various\u00a0low-\u00a0and\u00a0high-frequency\u00a0noises\u00a0that\u00a0become\u00a0biases\u00a0in\u00a0model\u00a0training\u00a0are\u00a0generated\u00a0because\u00a0of\u00a0motion\u00a0arti-\ni r . l ll t it ct re."
        },
        {
            "heading": "2.2. Additional Dataset",
            "text": "In addition to the above datasets, we used additional datasets for the training and validation of DL models. The datasets are described below."
        },
        {
            "heading": "2.2.1. BIDMC",
            "text": "BIDMC [15,16] is 53 samples of 8 min duration signals collected from ICU of Beth Israel Deaconess Medical Center. Two annotators labeled the RR using each subject\u2019s impedance respiratory signal. However, we excluded samples with IDs 13, 15, and 19, which had missing values for RR, so a total of 50 samples were used in the study. The dataset consists of impedance respiratory, electrocardiogram, and PPG sampled in 125 Hz. It also includes demographics and 1 Hz signals such as heart rate, respiratory rate, O2 saturation, and pulse. This dataset provides various formats, including csv, for countless research and benchmark tests, and it is a public dataset. In this study, we used the PPG signal and RR provided by the dataset to validate the model.\n2.2.2. CapnoBase\nThe IEEE TBME Respiratory Rate Benchmark dataset [17] is a dataset designed for developing and testing RR estimation. The dataset contains 8 min electrocardiogram, capnography, and PPG signals cquired from 42 patient during elective surgery and routine anesthesia. Labels from an annotator are available for peaks from PPG breaths from CO2. The data were obtained f om 29 childr n and 13 adults. The dataset wa used for validation purposes, nd only 13 adult patients were used in t is study, given that the study was conducted o adult patients."
        },
        {
            "heading": "2.3. Preprocessing",
            "text": "When measuring the PPG signal using a pulse oximeter, various low- and highfrequency noises that become biases in model training are generated because of motion artifacts, probe\u2013tissue interface disturbance, powerline interference due to the instrumentation amplifiers, and changes in physiological parameters such as cardiac impulse [11]. Therefore, removing such noises lurking in the signal using signal filtering is a mandatory process, and it can improve the estimation accuracy of DL models effectively. We filtered the signal using a Hamming window and applied Finite Impulse Response (FIR) band-pass\nBioengineering 2023, 10, 1222 5 of 17\nfilter (BPF) with a cut-off frequency ranging from 0.1 to 0.4 Hz [18\u201321]. This is a frequency band that corresponds to respiration, and several studies have suggested an arbitrary cut-off between 0.05 and 0.4 Hz for estimating the RR [16,20,22,23]. Then, the filtered signal, in turn, was sliced into data samples of constant intervals for a fitted size to train the DL model. An interval of 60 s with 1 s shifting was set to slice the signal, as the RR, which we were trying to estimate, is conventionally counted per minute. Through the process above, we generated 6508, 21,050, and 5473 samples of 1 min PPG and RR values (brpm) from our self-collected dataset, BIDMC, and CapnoBase, respectively. Additionally, to enhance the efficiency of model calculation, a signal of 125 Hz was resampled into 30 Hz using linear interpolation [24,25]. The described preprocessing method applies to all of the datasets introduced above."
        },
        {
            "heading": "2.4. Deep Learning Models",
            "text": "For the next step, our patient\u2019s preprocessed dataset was exploited to train the DL models, which we introduce below: Residual Neural Network, U-Net, Long Short-Term Memory, and Dilated Residual Neural Network. Each model has been utilized in many studies, using PPG to estimate the RR or its reference signal [25\u201327]. Except for the Dilated Residual Neural Network we are proposing, the remaining six models were implemented directly by referring to the architecture and parameters of each of the introduced papers, and the related code can be found at the following link: https://github.com/Noritheyellow/ Project-RRpo-2ndStudy (accessed on 12 October 2023.).\n2.4.1. Residual Neural Network (ResNet)\nResNet, as a DL model introduced to overcome the vanishing gradient problem that occurs as the layers of backpropagation-based models become substantially deeper, takes the idea of summing the input and output values of the layer [28]. This is because the gradient, which has an important effect on the learning of weights in error propagationbased models, converges to zero as the layer becomes deeper, resulting in sluggish learning. To overcome this problem, ResNet simply sums the input and output values of an arbitrary layer. With ResNet, you can prevent learning by gradually losing the original shape and features of the PPGs due to the feature extraction process of data using PPGs and the pooling process that reduces the size of the data. As in the case of Bian [25], we implemented a ResNet block that reduces the size of the PPG using a convolutional layer and extracts features by accumulating them, and we implemented the model by applying it five times and used it to predict the RR value. CapnoBase, BIDMC, and synthetic datasets were used as the datasets, and the MAE was about 3.8 \u00b1 0.5 when only real-world data were trained, and the result was about 2.5 \u00b1 0.6 when synthetic data were mixed. In this paper, we implemented the model according to its description, and used a CapnoBase, BIDMC, and tertiary referral hospital data with it.\n2.4.2. U-Net\nU-Net is a DL model designed to solve the pixel-wise labeling of images in biomedical image segmentation [29]. To prevent the loss of characteristics in the whole image context, the model extracts the features from each downsampling step and concatenates them to other extracted features, i.e., upsampled features. U-Net performs the above process through a set of layers called the contracting path. At this time, the features of each stage extracted from the contracting path are concatenated with the feature map of the symmetrical expanding path. The features are then upsampled using convolution to convert them to a higher resolution and then propagated to the next layer so that they can be combined with the features of the contracting path. The architecture of this overall model is U-shaped, hence the name. Ravinchandran [26] proposed a model called RespNet, which is based on U-Net and uses a Dilated Residual Inception Block internally. The model trains the PPG to predict RR reference signals such as Capnometry, Impedance Pneumography, and the Oral\u2013Nasal\nBioengineering 2023, 10, 1222 6 of 17\nPressure signal of a subject and uses Capnobase and Vortal datasets for this purpose. The prediction performance of the model is 0.262, and there is a 0.145 MSE for each dataset, as shown in the paper, but the cost burden and difficulty in securing patients may be a limitation because respiratory signals rather than RRs must be collected as a reference. Note that it is the RR value, and not the RR reference signal, that we wanted to estimate in this study, so we used a dense layer to change its output for that purpose.\n2.4.3. Long Short-Term Memory (LSTM)\nLSTM, as a DL model designed to address the problem of forgetting the extracted features from the sequential data, i.e., the vanishing gradient problem that traditional recurrent neural network (RNN) models challenge, involves a computational process that selectively keeps only the necessary features over time [30]. Because of these properties, LSTMs are often used as linguistic models, but they have also shown significant results for one-dimensional data such as signals. Since such a feature of LSTM is useful for sequential data estimation, various models were implemented upon it. Convolutional-LSTM [31] combines an LSTM that extracts temporal features from the incoming sequence data with a convolutional layer that extracts spatial features to provide a more holistic view of the data. Bidirectional LSTM [32] introduces an additional LSTM that trains in the backward direction and uses sequence data is the input, as opposed to the traditional LSTM that trains only in the forward direction. This approach is expected to yield better results because it obtains information from both the forward and backward flows of time and uses it for prediction. Attention [33], which mimics the cognitive action of attending to specific features, has been shown to significantly improve the prediction performance of sequential data, such as linguistic sentences, and is often used for signals that are also sequential data. Models that use attention mechanisms identify their own contextual relationships and utilize them for prediction. In addition to the most basic dot product attention, Bahdanau attention, entangled attention, and quantum attention [34\u201336] are used to measure the similarity between these data. Kumar [27] tried to predict the RR by training vital signs from Capnobase, BIDMC, and sEMG datasets with various LSTM models such as LSTM, bidirectional LSTM (Bi-LSTM), Attention-based Bi-LSTM, CNN-LSTM, etc. However, the paper had limitations in terms of practicality because it used signals such as ECG and sEMG to predict the RR instead of using PPG alone. In this study, we implemented all models from the bottom and set parameters according to the paper described. The units of the models, specifically Vanilla LSTM, CNN LSTM, Bi-LSTM, and Attention-based Bi-LSTM, were modified into 256, 256, 128, and 64.\n2.4.4. Dilated Residual Neural Network (Our Proposed Model)\nIn this study, we did not only estimate the RR using the PPG-derived DL models that we introduced above, but we also used the model that we implemented, a Dilated Residual Neural Network (Dilated ResNet). The implemented model was layered using a dilated convolutional layer [37,38] additionally, and the inputs and outputs of each layer group were summed to overcome the vanishing gradient problem. First, the input PPG signal was passed through each of the 3 horizontally organized dilated convolutional layers. This allowed the model to characterize the signal\u2019s relationships between data that are not only adjacent but also temporally spaced apart, facilitating the capture of the morphological features of the overall PPG. In addition, we tried to extract more characteristic information from the existing signal by adding another vertically identical layer. At this point, all features extracted from the layer group and feature-wise average values of input data were summed and used as the output. This process works inside a single unit block, the RespBlock, where the feature extraction of the RespBlock is followed by downsampling on its result. This process of the DL model that we considered compresses the existing extracted features densely and reduces the required computational resources for learning, so it continuously repeats the feature extraction and compression. Our study processed\nBioengineering 2023, 10, 1222 7 of 17\nfeature extraction and compression three times for each sample and doubled the output feature size for each iteration. Then, we applied the average pooling layer and fully connected layer on the output to estimate the final RR value. For the proposed DL model to show good results, it is important to find the optimal hyperparameters. In the Dilated ResNet model, the hyperparameters are the number of RespBlocks (Nblk), kernel size of the convolutional layer inside the RespBlock (kernelblk), dilation rate of the convolutional layer inside the RespBlock (Dblk), kernel_size of 1D convolutional layer for downsample (kerneldwn), number of filters multiplied by the power of two ( f iltersc), stride size of average pooling (Sc), and units of first dense layer (nden), and we tried to estimate the RR accurately by adjusting these parameters. To select the optimal hyperparameters, we used the Bayesian optimization algorithm [39], which has been used in studies of various models. Table 2 summarizes each of these hyperparameters and their experimental values, and the final selected parameters and model structure can be seen in Figure 3.\nTable 2. Hyperparameters for Bayesian optimization.\nHyperparameters Range of Values Selected Value\nNumber of RespBlocks (Nblk) 1~5 4 Kernel size of conv layer inside the RespBlock (kernelblk) 2~5 2 Dilation rate of conv layer inside the RespBlock (Dblk) 1~5 3 Kernel size of conv layer for downsample (kerneldwn) 2~4 3 Number of filters multiplied by power of two ( f iltersc) 4~10 8 Stride size of average pooling (Sc) 2~4 2\nUnits of first dense layer (nden) 20~100 86 Bioengineering\u00a02023,\u00a010,\u00a0x\u00a0FOR\u00a0PEER\u00a0REVIEW\u00a0 8\u00a0 of\u00a0 18\u00a0 \u00a0\n\u00a0\nFigure\u00a03.\u00a0Dilated\u00a0ResNet\u00a0architecture.\u00a0\n2.5.\u00a0Experiments\u00a0 In\u00a0this\u00a0study,\u00a0we\u00a0trained\u00a0and\u00a0validated\u00a0the\u00a0models\u00a0using\u00a0only\u00a0our\u00a0datasets\u00a0to\u00a0understand\u00a0the\u00a0performance\u00a0of\u00a0each\u00a0model\u00a0introduced\u00a0above\u00a0when\u00a0trained\u00a0on\u00a0datasets\u00a0collected\u00a0 from\u00a0real-world\u00a0clinics.\u00a0To\u00a0evaluate\u00a0the\u00a0generalization\u00a0performance\u00a0of\u00a0the\u00a0trained\u00a0models,\u00a0 we\u00a0extracted\u00a0some\u00a0unseen\u00a0data\u00a0from\u00a0the\u00a0self-collected\u00a0datasets\u00a0and\u00a0added\u00a0the\u00a0BIDMC\u00a0and\u00a0 CapnoBase\u00a0datasets\u00a0to\u00a0form\u00a0a\u00a0test\u00a0dataset.\u00a0Additionally,\u00a0BIDMC\u00a0was\u00a0utilized\u00a0as\u00a0a\u00a0training\u00a0 and\u00a0validation\u00a0dataset\u00a0to\u00a0compare\u00a0the\u00a0RR\u00a0estimation\u00a0performance\u00a0of\u00a0various\u00a0models,\u00a0including\u00a0the\u00a0model\u00a0proposed\u00a0in\u00a0this\u00a0study.\u00a0All\u00a0trained\u00a0models\u00a0were\u00a0evaluated\u00a0using\u00a0the\u00a0 authors\u2019\u00a0dataset,\u00a0CapnoBase,\u00a0and\u00a0BIDMC\u00a0pre-segmented\u00a0test\u00a0datasets.\u00a0Lastly,\u00a0since\u00a0the\u00a0 purpose\u00a0of\u00a0this\u00a0study\u00a0was\u00a0to\u00a0estimate\u00a0the\u00a0RRs\u00a0of\u00a0critically\u00a0ill\u00a0patients,\u00a0we\u00a0further\u00a0tested\u00a0 and\u00a0evaluated\u00a0 the\u00a0robustness\u00a0of\u00a0 the\u00a0model\u00a0 to\u00a0motion\u00a0artifacts.\u00a0Therefore,\u00a0we\u00a0extracted\u00a0 signals\u00a0from\u00a0random\u00a0patients\u00a0from\u00a0the\u00a0BIDMC\u00a0test\u00a0dataset\u00a0and\u00a0added\u00a0artificial\u00a0baseline\u00a0 wanderings\u00a0created\u00a0by\u00a0varying\u00a0the\u00a0amplitude\u00a0and\u00a0frequency\u00a0to\u00a0those\u00a0signals\u00a0to\u00a0produce\u00a0 signals\u00a0with\u00a0signal-to-noise\u00a0ratios\u00a0(SNRs)\u00a0of\u00a020\u00a0db,\u00a015\u00a0db,\u00a0and\u00a010\u00a0db,\u00a0respectively.\u00a0These\u00a0 signals\u00a0were\u00a0 intended\u00a0 to\u00a0 reflect\u00a0motion\u00a0 artifacts,\u00a0 such\u00a0 as\u00a0 high-intensity\u00a0 accelerations,\u00a0 which\u00a0affect\u00a0PPG\u00a0signals\u00a0[40].\u00a0\n2.5.1.\u00a0Training\u00a0and\u00a0Validation\u00a0method\u00a0 Two\u00a0datasets\u00a0were\u00a0used\u00a0to\u00a0train\u00a0and\u00a0validate\u00a0the\u00a0model:\u00a0the\u00a0authors\u2019\u00a0own\u00a0dataset\u00a0and\u00a0 BIDMC.\u00a0In\u00a0order\u00a0to\u00a0perform\u00a0independent\u00a0training\u00a0and\u00a0validation\u00a0of\u00a0the\u00a0model,\u00a0we\u00a0tried\u00a0 to\u00a0completely\u00a0distinguish\u00a0the\u00a0training\u00a0and\u00a0validation\u00a0datasets\u00a0according\u00a0to\u00a0the\u00a0patient\u00a0ID,\u00a0 so\u00a0we\u00a0performed\u00a0randomly\u00a0shuffled\u00a05-fold\u00a0cross-validation\u00a0based\u00a0on\u00a0patient\u00a0ID.\u00a0All\u00a0PPG\u00a0 signals\u00a0and\u00a0ground\u00a0truth\u00a0RR\u00a0values\u00a0were\u00a0configured\u00a0with\u00a0a\u00a0batch\u00a0size\u00a0of\u00a0256.\u00a0The\u00a0starting\u00a0 learning\u00a0rate\u00a0was\u00a0set\u00a0to\u00a00.001\u00a0and\u00a0optimized\u00a0using\u00a0Adam\u00a0optimization\u00a0[41].\u00a0Training\u00a0was\u00a0 performed\u00a0over\u00a01000\u00a0epochs.\u00a0In\u00a0addition,\u00a0if\u00a0the\u00a0loss\u00a0value\u00a0for\u00a0the\u00a0validation\u00a0dataset\u00a0formed\u00a0 a\u00a0plateau\u00a0with\u00a0no\u00a0change\u00a0for\u00a0a\u00a0certain\u00a0number\u00a0of\u00a0epochs\u00a0when\u00a0the\u00a0model\u00a0was\u00a0learning,\u00a0\nFigure 3. Dilated ResNet architecture.\nBioengineering 2023, 10, 1222 8 of 17"
        },
        {
            "heading": "2.5. Experiments",
            "text": "In this study, we trained and validated the models using only our datasets to understand the performance of each model introduced above when trained on datasets collected from real-world clinics. To evaluate the generalization performance of the trained models, we extracted some unseen data from the self-collected datasets and added the BIDMC and CapnoBase datasets to form a test dataset. Additionally, BIDMC was utilized as a training and validation dataset to compare the RR estimation performance of various models, including the model proposed in this study. All trained models were evaluated using the authors\u2019 dataset, CapnoBase, and BIDMC pre-segmented test datasets. Lastly, since the purpose of this study was to estimate the RRs of critically ill patients, we further tested and evaluated the robustness of the model to motion artifacts. Therefore, we extracted signals from random patients from the BIDMC test dataset and added artificial baseline wanderings created by varying the amplitude and frequency to those signals to produce signals with signal-to-noise ratios (SNRs) of 20 db, 15 db, and 10 db, respectively. These signals were intended to reflect motion artifacts, such as high-intensity accelerations, which affect PPG signals [40].\n2.5.1. Training and Validation method\nTwo datasets were used to train and validate the model: the authors\u2019 own dataset and BIDMC. In order to perform independent training and validation of the model, we tried to completely distinguish the training and validation datasets according to the patient ID, so we performed randomly shuffled 5-fold cross-validation based on patient ID. All PPG signals and ground truth RR values were configured with a batch size of 256. The starting learning rate was set to 0.001 and optimized using Adam optimization [41]. Training was performed over 1000 epochs. In addition, if the loss value for the validation dataset formed a plateau with no change for a certain number of epochs when the model was learning, the learning rate was increased by a factor of 0.1 for more precise learning, and an early stopping technique was applied at the learning stage to prevent overfitting. All the models introduced here were implemented with Tensorflow version 2.0.\n2.5.2. Evaluation Method\nTo evaluate the models for each experiment, the test datasets were organized into four different groups: slow breathing group (<12 rpm), normal breathing group (12 to 20 rpm), rapid breathing group (>20 rpm), and all. The reason for this classification is that the RR is a significant vital sign that is associated with various diseases, and the PPG signal can vary accordingly (Figure 4), affecting the performance of models that estimate RR [42]. The performance of the model was evaluated using the mean absolute error (MAE), which calculates the error between the true and estimated values, for training, validation, and testing across all experiments conducted for each dataset.\nMAE = 1 N\nN\n\u2211 i=1 \u2223\u2223\u2223RRitrue \u2212 RRiest\u2223\u2223\u2223 (1) In the above formula, RRitrue and RR i est represent the i-th actual RR and its correspond-\ning estimated RR. n represents the size of the dataset. To evaluate and compare each result, we applied Min\u2013Max normalization to all data, which replaces all values with values between 0 and 1.\nBioengineering 2023, 10, 1222 9 of 17\nBioengineering\u00a02023,\u00a010,\u00a0x\u00a0FOR\u00a0PEER\u00a0REVIEW\u00a0 9\u00a0 of\u00a0 18\u00a0 \u00a0 the\u00a0learning\u00a0rate\u00a0was\u00a0increased\u00a0by\u00a0a\u00a0factor\u00a0of\u00a00.1\u00a0for\u00a0more\u00a0precise\u00a0learning,\u00a0and\u00a0an\u00a0early\u00a0 stopping\u00a0technique\u00a0was\u00a0applied\u00a0at\u00a0the\u00a0learning\u00a0stage\u00a0to\u00a0prevent\u00a0overfitting.\u00a0All\u00a0the\u00a0models\u00a0 introduced\u00a0here\u00a0were\u00a0implemented\u00a0with\u00a0Tensorflow\u00a0version\u00a02.0.\u00a0 2.5.2.\u00a0Evaluation\u00a0Method\u00a0 To\u00a0evaluate\u00a0 the\u00a0models\u00a0 for\u00a0each\u00a0experiment,\u00a0 the\u00a0 test\u00a0datasets\u00a0were\u00a0organized\u00a0 into\u00a0 four\u00a0different\u00a0groups:\u00a0slow\u00a0breathing\u00a0group\u00a0(<12\u00a0rpm),\u00a0normal\u00a0breathing\u00a0group\u00a0(12\u00a0to\u00a020\u00a0 rpm),\u00a0rapid\u00a0breathing\u00a0group\u00a0(>20\u00a0rpm),\u00a0and\u00a0all.\u00a0The\u00a0reason\u00a0for\u00a0this\u00a0classification\u00a0is\u00a0that\u00a0 the\u00a0RR\u00a0is\u00a0a\u00a0significant\u00a0vital\u00a0sign\u00a0that\u00a0is\u00a0associated\u00a0with\u00a0various\u00a0diseases,\u00a0and\u00a0the\u00a0PPG\u00a0signal\u00a0can\u00a0vary\u00a0accordingly\u00a0(Figure\u00a04),\u00a0affecting\u00a0the\u00a0performance\u00a0of\u00a0models\u00a0that\u00a0estimate\u00a0RR\u00a0 [42].\u00a0The\u00a0performance\u00a0of\u00a0the\u00a0model\u00a0was\u00a0evaluated\u00a0using\u00a0the\u00a0mean\u00a0absolute\u00a0error\u00a0(MAE),\u00a0 which\u00a0calculates\u00a0the\u00a0error\u00a0between\u00a0the\u00a0true\u00a0and\u00a0estimated\u00a0values,\u00a0for\u00a0training,\u00a0validation,\u00a0 and\u00a0testing\u00a0across\u00a0all\u00a0experiments\u00a0conducted\u00a0for\u00a0each\u00a0dataset.\u00a0\n\ud835\udc40\ud835\udc34\ud835\udc38 1\ud835\udc41 \ud835\udc45\ud835\udc45 \ud835\udc45\ud835\udc45 \u00a0 (1)\nIn\u00a0the\u00a0above\u00a0formula,\u00a0 \ud835\udc45\ud835\udc45 \u00a0 and\u00a0 \ud835\udc45\ud835\udc45 \u00a0 represent\u00a0the\u00a0 i-th\u00a0actual\u00a0RR\u00a0and\u00a0its\u00a0corresponding\u00a0estimated\u00a0RR.\u00a0n\u00a0represents\u00a0the\u00a0size\u00a0of\u00a0the\u00a0dataset.\u00a0To\u00a0evaluate\u00a0and\u00a0compare\u00a0each\u00a0 result,\u00a0we\u00a0applied\u00a0Min\u2013Max\u00a0normalization\u00a0to\u00a0all\u00a0data,\u00a0which\u00a0replaces\u00a0all\u00a0values\u00a0with\u00a0values\u00a0between\u00a00\u00a0and\u00a01.\u00a0\n\u00a0\nFigure\u00a04.\u00a0Examples\u00a0of\u00a0BIDMC\u00a0patients\u2019\u00a01\u00a0min\u00a0PPG\u00a0signals\u00a0according\u00a0to\u00a0the\u00a0breathing\u00a0group.\u00a0(A)\u00a0\nRapid\u00a0breathing\u00a0(>20\u00a0rpm),\u00a0(B)\u00a0normal\u00a0breathing\u00a0(12\u00a0to\u00a020\u00a0rpm),\u00a0(C)\u00a0slow\u00a0breathing\u00a0(<12\u00a0rpm).\u00a0Each\u00a0\nexample\u2019s\u00a0baseline\u00a0wandering,\u00a0amplitude\u00a0modulation,\u00a0and\u00a0 frequency\u00a0modulation\u00a0are\u00a0 related\u00a0 to\u00a0\ntheir\u00a0RRs.\u00a0Thus,\u00a0while\u00a0subject\u00a0(A)\u00a0shows\u00a0a\u00a0dynamic\u00a0signal\u00a0movement,\u00a0(B,C)\u00a0show\u00a0relatively\u00a0constant\u00a0\nmovement.\u00a0\n2.6.\u00a0Statistical\u00a0Analysis\u00a0 All\u00a0statistical\u00a0analyses\u00a0were\u00a0performed\u00a0using\u00a0 the\u00a0Numpy\u00a0and\u00a0Scipy\u00a0 libraries\u00a0supported\u00a0by\u00a0Python\u00a0and\u00a0visualized\u00a0using\u00a0Matplotlib\u00a0[43\u201345].\u00a0Before\u00a0proceeding\u00a0with\u00a0preprocessing\u00a0and\u00a0model\u00a0training\u00a0using\u00a0in-hospital\u00a0data,\u00a0we\u00a0statistically\u00a0tested\u00a0whether\u00a0the\u00a0 collected\u00a0PPG\u00a0data\u00a0had\u00a0any\u00a0differences\u00a0according\u00a0to\u00a0gender\u00a0and\u00a0existence\u00a0of\u00a0the\u00a0disease,\u00a0 and\u00a0finally\u00a0set\u00a0the\u00a0data\u00a0that\u00a0were\u00a0suitable\u00a0for\u00a0model\u00a0training.\u00a0To\u00a0test\u00a0whether\u00a0the\u00a0collected\u00a0 signal\u00a0data\u00a0grouped\u00a0by\u00a0gender\u00a0were\u00a0equal\u00a0to\u00a0its\u00a0variances\u00a0and\u00a0averages,\u00a0the\u00a0Bartlett\u00a0test\u00a0 and\u00a0independent\u00a0two-sample\u00a0t-test\u00a0were\u00a0performed.\u00a0After\u00a0the\u00a0models\u00a0were\u00a0trained,\u00a0each\u00a0 of\u00a0 them\u00a0derived\u00a0estimated\u00a0RRs\u00a0corresponding\u00a0 to\u00a0 the\u00a0actual\u00a0RRs\u00a0using\u00a0a\u00a0PPG\u00a0 from\u00a0 the\u00a0 validation\u00a0dataset.\u00a0Using\u00a0a\u00a0difference\u00a0between\u00a0these\u00a0two\u00a0values,\u00a0our\u00a0study\u00a0evaluated\u00a0its\u00a0 error\u00a0and\u00a0standard\u00a0deviation,\u00a0and\u00a0then\u00a0expressed\u00a0it\u00a0as\u00a0MAE\u00a0\u00b1\u00a0SD\u00a0(brpm)\u00a0to\u00a0compare\u00a0their\u00a0\nFigure 4. Examples of BIDMC patients\u2019 1 min PPG signals according to the breathing group. (A) Rapid breathing (>20 rpm), (B) normal breathing (12 to 20 rpm), (C) slow breathing (<12 rpm). Each example\u2019s baseline wandering, amplitude modulation, and frequency modulation are related to their RRs. Thus, while subject (A) shows a dynamic signal movement, (B,C) show relatively constant movement."
        },
        {
            "heading": "2.6. Statistical Analysis",
            "text": "All statistical analyses were performed using the Numpy and Scipy libraries supported by Python and visualized using Matplotlib [43\u201345]. Before proceeding with preprocessing and model training using in-hospital data, we statistically tested whether the collected PPG data had any differences according to gender and existence of the disease, and finally set the ata that were suitable for model training. To test whether the collected signal data grouped by gender wer q al to its variances a d averages, t Bartlett test an independent two-sample t-test ere performed. After the mod ls were trained, each of them deriv d estimated RRs corresponding to the actual RRs using a PPG from the validation dataset. Using a differenc between these two v lues, o r study evaluated its error nd standard deviation, and then expressed it as MAE \u00b1 SD (brpm) to compare their pe formances. A box plot was use o evaluat each model\u2019s estimation tendency, estimat d RR distribution, and the number of outliers. Furthermore, linear regression analysis was applied to assess each model\u2019s correlation between the actual and estimated values, and to be more specific, Pearson\u2019s correlation coefficient (R) was also utilized to indicate the quantitative correlation between both observations. In addition, a Bland\u2013Altman plot [46] analysis was exploited to confirm the agreement between them. Our study considered a level of significance for comparative analysis and testing as p < 0.05."
        },
        {
            "heading": "3. Results",
            "text": "From June 2022 to July 2022, a total of 100 patients admitted to the SICU of our institution were subjected to PPG and RR data collection and outcome analysis, including 56 males and 44 females. The mean age was 67.5 years, and the mean SOFA score on the day of admission to the SICU was 2.5 (range 0\u20136). A respiratory history of COPD or asthma was observed in seven patients (7%), and the most common diagnosis at admission was malignancy (54 patients; 54%), followed by non-cancerous lesions including ulcer perforation, pan-peritonitis, and bowel obstruction (28 patients; 28%). There were no differences in the baseline characteristics and disease profiles between the genders. (Table 1) As a result of the comparative analysis of the PPG data by gender, it was determined that the signal data of the two groups showed equal variance and consistency in the model training as the data did not show significant differences. The data used in the study were first split into training data and testing data. The testing data were extracted in proportion to the three breathing groups, which were slow breathing (five subjects), normal breathing (five subjects), and rapid breathing (five subjects)\nBioengineering 2023, 10, 1222 10 of 17\nfor our own dataset, and one subject, three subjects, and three subjects for BIDMC, respectively. The reason why only one slow breathing subject was selected as the testing data in BIDMC was that there were only two slow breathing subjects in the entire BIDMC data, so we wanted to use the data of at least one subject for training. The training data were then split into a training dataset and validation dataset according to the 5-fold cross-validation method. Table 3 summarizes the number of samples for each dataset.\nBased on the above data, we ran the experiments described in the Experiments subsection and obtained the following results. Figure 5 shows the RR of the BIDMC validation dataset subject (bidmc_17), which was estimated using the Dilated ResNet model.\nBioengineering\u00a02023,\u00a010,\u00a0x\u00a0FOR\u00a0PEER\u00a0REVIEW\u00a0 10\u00a0 of\u00a0 18\u00a0 \u00a0 performances.\u00a0A\u00a0box\u00a0plot\u00a0was\u00a0used\u00a0to\u00a0evaluate\u00a0each\u00a0model\u2019s\u00a0estimation\u00a0tendency,\u00a0estimated\u00a0RR\u00a0distribution,\u00a0and\u00a0the\u00a0number\u00a0of\u00a0outliers.\u00a0Furthermore,\u00a0linear\u00a0regression\u00a0analysis\u00a0was\u00a0applied\u00a0to\u00a0assess\u00a0each\u00a0model\u2019s\u00a0correlation\u00a0between\u00a0the\u00a0actual\u00a0and\u00a0estimated\u00a0values,\u00a0and\u00a0to\u00a0be\u00a0more\u00a0specific,\u00a0Pearson\u2019s\u00a0correlation\u00a0coefficient\u00a0(R)\u00a0was\u00a0also\u00a0utilized\u00a0to\u00a0indicate\u00a0the\u00a0quantitative\u00a0correlation\u00a0between\u00a0both\u00a0observations.\u00a0In\u00a0addition,\u00a0a\u00a0Bland\u2013Altman\u00a0 plot\u00a0[46]\u00a0analysis\u00a0was\u00a0exploited\u00a0to\u00a0confirm\u00a0the\u00a0agreement\u00a0between\u00a0them.\u00a0Our\u00a0study\u00a0considered\u00a0a\u00a0level\u00a0of\u00a0significance\u00a0for\u00a0comparative\u00a0analysis\u00a0and\u00a0testing\u00a0as\u00a0p\u00a0<\u00a00.05.\u00a0 3.\u00a0Results\u00a0 From\u00a0June\u00a02022\u00a0to\u00a0July\u00a02022,\u00a0a\u00a0total\u00a0of\u00a0100\u00a0patients\u00a0admitted\u00a0to\u00a0the\u00a0SICU\u00a0of\u00a0our\u00a0insti-\ntution\u00a0were\u00a0subjected\u00a0to\u00a0PPG\u00a0and\u00a0RR\u00a0data\u00a0collection\u00a0and\u00a0outcome\u00a0analysis,\u00a0including\u00a056\u00a0 males\u00a0and\u00a044\u00a0females.\u00a0The\u00a0mean\u00a0age\u00a0was\u00a067.5\u00a0years,\u00a0and\u00a0the\u00a0mean\u00a0SOFA\u00a0score\u00a0on\u00a0the\u00a0day\u00a0 of\u00a0admission\u00a0to\u00a0the\u00a0SICU\u00a0was\u00a02.5\u00a0(range\u00a00\u20136).\u00a0A\u00a0respiratory\u00a0history\u00a0of\u00a0COPD\u00a0or\u00a0asthma\u00a0 was\u00a0observed\u00a0in\u00a0seven\u00a0patients\u00a0(7%),\u00a0and\u00a0the\u00a0most\u00a0common\u00a0diagnosis\u00a0at\u00a0admission\u00a0was\u00a0 malignancy\u00a0(54\u00a0patients;\u00a054%),\u00a0followed\u00a0by\u00a0non-cancerous\u00a0lesions\u00a0including\u00a0ulcer\u00a0perforation,\u00a0pan-peritonitis,\u00a0and\u00a0bowel\u00a0obstruction\u00a0 (28\u00a0patients;\u00a028%).\u00a0There\u00a0were\u00a0no\u00a0differences\u00a0in\u00a0the\u00a0baseline\u00a0characteristics\u00a0and\u00a0disease\u00a0profiles\u00a0between\u00a0the\u00a0genders.\u00a0(Table\u00a01)\u00a0As\u00a0 a\u00a0result\u00a0of\u00a0the\u00a0comparative\u00a0analysis\u00a0of\u00a0the\u00a0PPG\u00a0data\u00a0by\u00a0gender,\u00a0it\u00a0was\u00a0determined\u00a0that\u00a0the\u00a0 signal\u00a0data\u00a0of\u00a0the\u00a0two\u00a0groups\u00a0showed\u00a0equal\u00a0variance\u00a0and\u00a0consistency\u00a0in\u00a0the\u00a0model\u00a0training\u00a0as\u00a0the\u00a0data\u00a0did\u00a0not\u00a0show\u00a0significant\u00a0differences.\u00a0 The\u00a0data\u00a0used\u00a0 in\u00a0the\u00a0study\u00a0were\u00a0first\u00a0split\u00a0into\u00a0training\u00a0data\u00a0and\u00a0testing\u00a0data.\u00a0The\u00a0 testing\u00a0data\u00a0were\u00a0extracted\u00a0in\u00a0proportion\u00a0to\u00a0the\u00a0three\u00a0breathing\u00a0groups,\u00a0which\u00a0were\u00a0slow\u00a0 breathing\u00a0(five\u00a0subjects),\u00a0normal\u00a0breathing\u00a0(fiv \u00a0subjects),\u00a0and\u00a0rapid\u00a0breathing\u00a0(fiv \u00a0sub jects)\u00a0for\u00a0our\u00a0ow \u00a0dataset,\u00a0and\u00a0one\u00a0su j c ,\u00a0three\u00a0subjects,\u00a0and\u00a0three\u00a0subj cts\u00a0for\u00a0BIDMC,\u00a0 respectively.\u00a0The\u00a0r ason\u00a0why\u00a0only\u00a0 ne\u00a0slow\u00a0breathing\u00a0subject\u00a0was\u00a0selected\u00a0as\u00a0the\u00a0testing\u00a0 data\u00a0in\u00a0BIDMC\u00a0was\u00a0that\u00a0there\u00a0w re\u00a0only\u00a0two\u00a0slow\u00a0bre thi \u00a0subjects\u00a0in\u00a0the\u00a0entire\u00a0BIDMC\u00a0 data,\u00a0so\u00a0we\u00a0wanted\u00a0to\u00a0use\u00a0the\u00a0d ta\u00a0of\u00a0at\u00a0least\u00a0one\u00a0subject\u00a0for\u00a0training.\u00a0The\u00a0training\u00a0data\u00a0 were\u00a0then\u00a0split\u00a0into\u00a0a\u00a0training\u00a0dataset\u00a0and\u00a0validation\u00a0dataset\u00a0according\u00a0to\u00a0the\u00a05-fold\u00a0crossvalidation\u00a0method.\u00a0Table\u00a03\u00a0summarizes\u00a0the\u00a0number\u00a0of\u00a0samples\u00a0for\u00a0each\u00a0dataset.\u00a0\nBased\u00a0on\u00a0the\u00a0above\u00a0data,\u00a0we\u00a0ran\u00a0the\u00a0experiments\u00a0described\u00a0in\u00a0the\u00a0Experiments\u00a0subsection\u00a0and\u00a0obtained\u00a0the\u00a0following\u00a0results.\u00a0Figure\u00a05\u00a0shows\u00a0the\u00a0 R\u00a0of\u00a0the\u00a0BID C\u00a0vali ation\u00a0 ataset\u00a0s ject\u00a0( i c_17),\u00a0 ic \u00a0 as\u00a0esti ate \u00a0 si \u00a0t e\u00a0 ilate \u00a0 es et\u00a0 o el.\u00a0"
        },
        {
            "heading": "3.1. Training Model Using Self-Collected Dataset",
            "text": "All seven models introduced above were trained on our dataset, and the performances of the trained models were evaluated using the validation dataset. Table 4 summarizes these results. Next, an unseen dataset of each respiratory group was input to each model, and the results are shown in Table 5.\n* MAE = Mean Absolute Error; ** SD = Standard Deviation.\nBioengineering 2023, 10, 1222 11 of 17\nThe results of evaluating the performance of the model trained with the self-collected dataset and the validation dataset are shown in Table 4. In Table 5, which shows the evaluation of RespNet\u2019s unseen data, we can see that RespNet has the best performance on the same dataset as the trained data (in bold). We can also see that overall, most of the models have the best estimation performance for the normal breathing group within the dataset (in bold). The difference in the MAE between our dataset and CapnoBase within the same model is a maximum of 10.5005 and a minimum of 2.5712."
        },
        {
            "heading": "3.2. Training Model Using BIDMC Dataset",
            "text": "The performances of the seven models trained on BIDMC were evaluated on the validation dataset and are shown in Table 4. The models were also trained on the unseen dataset of each breathing group, and the results are shown in Table 6. The performance evaluation on the BIDMC validation dataset in Table 4 shows that Bian\u2019s ResNet, Ravichandran\u2019s RespNet, and our proposed Dilated ResNet model perform well compared to the LSTM-based models. The MAE of these three models is around 1.27, while the MAE of the LSTM-based models is around 1.68. This behavior is also evident in Table 6, which shows the respiration rate estimation results of the models using the unseen dataset from various datasets. In this table, we again see that the three models perform best in alternating groups of datasets (in bold). We also see that when we drill down into each dataset by group, the best performing group is generally the normal breathing group. This is true across all seven models. We wanted to check the results of the three most prominent models using the BIDMC validation dataset and the boxplot in Figure 6. The y-axis of the figure shows the absolute error (rpm), and the lowest error among the three models is obtained by RespNet, which is close to zero. The model with the lowest median is BianResNet, with a value of 0.5843. On the other hand, the model with the highest median is Dilated ResNet, with a value of 0.6503. Among the three models, Dilated ResNet has the fewest outliers for respiration rate estimation, with 454 outliers (13.48%) out of 3368 total data samples. Conversely, the model with the most outliers is BianResNet, with 531 outliers (15.77%). Furthermore, this paper calculated the Pearson correlation coefficient (PCC) between the estimated RR and the actual RR of each of the three models using the BIDMC validation dataset. As a result, BianResNet does not show a correlation between the estimated RR and actual RR at \u22120.0519 (p < 0.01). For RespNet, there is a weak negative correlation between the estimated and actual values at \u22120.3211 (p < 0.01). On the other hand, for Dilated ResNet, there is a weak positive correlation between the estimated and actual values at 0.5069 (p < 0.01).\nBioengineering 2023, 10, 1222 12 of 17Bioengineering\u00a02023,\u00a010,\u00a0x\u00a0FOR\u00a0PEER\u00a0REVIEW\u00a0 3\u00a0 f\u00a0 18\u00a0 \u00a0\nFigure\u00a06.\u00a0Comparison\u00a0of\u00a0the\u00a0absolute\u00a0error\u00a0between\u00a0two\u00a0models.\u00a0The\u00a0box\u00a0plot\u00a0shows\u00a0five\u00a0values:\u00a0 minimum,\u00a0lower\u00a0quartile\u00a0(25%),\u00a0median\u00a0(50%),\u00a0upper\u00a0quartile\u00a0(75%),\u00a0and\u00a0maximum.\u00a0Bian\u00a0ResNet\u00a0 model\u00a0(left)\u00a0approximately\u00a0shows\u00a00.0004,\u00a00.2362,\u00a00.5843,\u00a01.1879,\u00a0and\u00a02.6125\u00a0for\u00a0each.\u00a0RespNet\u00a0(center)\u00a0approximately\u00a0shows\u00a00,\u00a00.2770,\u00a00.865,\u00a00.6393,\u00a01.2240,\u00a0and\u00a02.6418\u00a0for\u00a0each.\u00a0Dilated\u00a0ResNet\u00a0(right)\u00a0 approximately\u00a0shows\u00a00.0009,\u00a00.2823,\u00a00.6503,\u00a01.6312,\u00a0and\u00a03.6290\u00a0for\u00a0each.\u00a0\n3.3.\u00a0Testing\u00a0Model\u2019s\u00a0Robustness\u00a0in\u00a0Different\u00a0SNRs\u00a0\nTo\u00a0test\u00a0the\u00a0robustness\u00a0of\u00a0the\u00a0three\u00a0models\u00a0 in\u00a0the\u00a0above\u00a0experiments,\u00a0we\u00a0 input\u00a0the\u00a0 signals\u00a0of\u00a0different\u00a0SNRs\u00a0to\u00a0compare\u00a0and\u00a0evaluate\u00a0the\u00a0results\u00a0(Table\u00a07).\u00a0\nTable\u00a07.\u00a0Test\u00a0result\u00a0of\u00a0models\u00a0in\u00a0different\u00a0SNRs.\u00a0\nModels\u00a0 Original\u00a0 20\u00a0db\u00a0 15\u00a0db\u00a0 10\u00a0db\u00a0 ResNet\u00a0[25]\u00a0 0.7203\u00a0\u00b1\u00a00.2655\u00a0 0.7304\u00a0\u00b1\u00a00.2729\u00a0 1.4932\u00a0\u00b1\u00a00.4728\u00a0 2.2513\u00a0\u00b1\u00a00.4843\u00a0 RespNet\u00a0[26]\u00a0 0.7122\u00a0\u00b1\u00a00.3290\u00a0 0.7265\u00a0\u00b1\u00a00.3328\u00a0 2.0491\u00a0\u00b1\u00a00.4456\u00a0 2.5544\u00a0\u00b1\u00a00.3368\u00a0 Dilated\u00a0ResNet\u00a0 \u00a0 (Proposed)\u00a0 0.6303\u00a0\u00b1\u00a00.3197\u00a0 0.6417\u00a0\u00b1\u00a00.3258\u00a0 0.8123\u00a0\u00b1\u00a00.3744\u00a0 4.1142\u00a0\u00b1\u00a00.4804\u00a0\nAccording\u00a0 to\u00a0 the\u00a0 result,\u00a0when\u00a0 the\u00a0SNR\u00a0 is\u00a010\u00a0db,\u00a0BianResNet\u00a0has\u00a0 the\u00a0 lowest\u00a0error\u00a0 among\u00a0 the\u00a0 three\u00a0models\u00a0with\u00a0 an\u00a0MAE\u00a0of\u00a0 2.2513,\u00a0while\u00a0our\u00a0proposed\u00a0Dilated\u00a0ResNet\u00a0 model\u00a0has\u00a0the\u00a0highest\u00a0error\u00a0with\u00a0an\u00a0MAE\u00a0of\u00a04.1142.\u00a0However,\u00a0in\u00a0all\u00a0other\u00a0cases,\u00a0we\u00a0can\u00a0 see\u00a0that\u00a0our\u00a0proposed\u00a0model\u00a0performs\u00a0the\u00a0best\u00a0as\u00a0it\u00a0obtained\u00a0values\u00a0of\u00a00.6303,\u00a00.6417,\u00a0and\u00a0 0.8123\u00a0(in\u00a0bold).\u00a0However,\u00a0the\u00a0overall\u00a0RR\u00a0estimation\u00a0error\u00a0consistently\u00a0increased\u00a0as\u00a0the\u00a0 SNR\u00a0decreased\u00a0in\u00a0our\u00a0experiment.\u00a0\n4.\u00a0Discussion\u00a0\nIn\u00a0our\u00a0study,\u00a0we\u00a0can\u00a0see\u00a0that\u00a0RespNet\u00a0and\u00a0CNNLSTM\u00a0perform\u00a0better\u00a0than\u00a0the\u00a0other\u00a0 models\u00a0in\u00a0Table\u00a05,\u00a0and\u00a0BianResNet,\u00a0RespNet,\u00a0and\u00a0Dilated\u00a0ResNet\u00a0perform\u00a0better\u00a0in\u00a0Table\u00a0 6.\u00a0We\u00a0believe\u00a0this\u00a0is\u00a0because\u00a0these\u00a0models\u00a0extract\u00a0the\u00a0spatial\u2013spectral\u00a0feature\u00a0of\u00a0the\u00a0signal,\u00a0 which\u00a0is\u00a0often\u00a0used\u00a0in\u00a0various\u00a0PPG\u00a0analysis\u00a0studies\u00a0[19,47].\u00a0Models\u00a0that\u00a0focus\u00a0on\u00a0temporal\u00a0 feature\u00a0extraction,\u00a0such\u00a0as\u00a0BiLSTM,\u00a0also\u00a0occasionally\u00a0perform\u00a0well\u00a0using\u00a0the\u00a0temporal\u00a0features\u00a0of\u00a0the\u00a0signal,\u00a0but\u00a0more\u00a0consistently\u00a0perform\u00a0well\u00a0when\u00a0using\u00a0convolution\u00a0and\u00a0taking\u00a0 the\u00a0shapes\u00a0of\u00a0previous\u00a0signals\u00a0and\u00a0adding\u00a0them\u00a0together,\u00a0such\u00a0as\u00a0ResNet.\u00a0\nTable 6. Test results of models trained using BIDMC dataset.\nModels Our Dataset BIDMC CapnoBase\nSlow Normal Rapid Total Slow Normal Rapid Total Slow Normal Rapid Total\nResNet [25] 6.7551 \u00b11.4659 2.3388 \u00b1 1.5861 10.2008 \u00b1 3.7638 5.2620 \u00b1 4.3497 5.1753 \u00b1 0.9849 1.9299 \u00b1 1.7501 8.1591 \u00b1 1.3136 2.3000 \u00b1 1.4898 3.9111 \u00b1 1.4059 2.8848 \u00b1 2.1277 9.2696 \u00b1 2.0520 3.3907 \u00b1 3.2020\nRespNet [26]\n7.3596 \u00b1 1.5644 1.9156 \u00b1 1.4486 8.7616 \u00b1 3.6743 4.4259 \u00b1 3.7224 7.1553 \u00b1 1.2752 2.1594 \u00b1 1.1806 6.3923 \u00b1 0.8528 3.0716 \u00b1 1.8902 6.4438 \u00b1 1.4510 2.1066 \u00b1 1.2562 9.6627 \u00b1 1.9590 5.2284 \u00b1 2.9006\nLSTM [27] 8.3830 \u00b11.4564 2.5204 \u00b1 1.7610 6.7114 \u00b1 3.2051 4.5045 \u00b1 3.2727 7.6302 \u00b1 0.7488 2.4339 \u00b1 1.6054 3.4213 \u00b1 0.6928 3.0237 \u00b1 2.0134 8.6937 \u00b1 1.3914 3.2512 \u00b1 2.0568 9.1971 \u00b1 2.2106 6.7515 \u00b1\n3.1394 CNNLSTM\n[27] 8.3352 \u00b1 1.4555 2.5152 \u00b1 1.7407 6.8162 \u00b1 3.2058 4.5053 \u00b1 3.2677 7.5736 \u00b1 0.7489 2.4258 \u00b1 1.5640 3.5066 \u00b1 0.6838 3.0262 \u00b1 1.9795 8.6084 \u00b1 1.3961 3.2184 \u00b1 2.0228 9.2106 \u00b1 2.1942 6.7124 \u00b1\n3.1280 BiLSTM\n[27] 8.3728 \u00b1 1.4567 2.5197 \u00b1 1.7594 6.7144 \u00b1 3.2055 4.5045 \u00b1 3.2725 7.6295 \u00b1 0.7460 2.4334 \u00b1 1.6034 3.4170 \u00b1 0.6934 3.0237 \u00b1 2.0119 8.6904 \u00b1 1.3916 3.2534 \u00b1 2.0568 9.2453 \u00b1 2.2108 6.7539 \u00b1\n3.1393 Attention-\nbased BiLSTM\n[27]\n8.5053 \u00b1 1.4586 2.5759 \u00b1 1.8162 6.5746 \u00b1 3.2057 4.5154 \u00b1 3.2677 7.7224 \u00b1 0.7387 2.4917 \u00b1 1.6578 3.2839 \u00b1 0.7083 3.0555 \u00b1 2.0589 8.8453 \u00b1 1.3939 3.4019 \u00b1 2.0630 9.1195 \u00b1 2.2234 6.8935 \u00b1 3.1338\nDilated ResNet\n(Proposed) 7.5543 \u00b1 1.9206 1.9894 \u00b1 1.2824 5.3631 \u00b1 3.2921 4.3177 \u00b1 3.3040 5.8661 \u00b1 0.8277 2.3702 \u00b1 2.1687 2.5696 \u00b1 1.3980 2.6526 \u00b1 2.2229 9.7006 \u00b1 1.4092 4.1819 \u00b1 2.1613 8.3740 \u00b1 2.4213 7.6322 \u00b1 3.1464"
        },
        {
            "heading": "3.3. Testing Model\u2019s Robustness in Different SNRs",
            "text": "To test the robustness of the three models in the above experiments, w input the signals of diff rent SNRs to co pare and evaluate the results (Table 7).\nTable 7. Test result of models in different SNRs.\nModels Original 20 db 15 db 10 db\nResNet [25] 0.7203 \u00b1 0.2655 0.7304 \u00b1 0.2729 1.4932 \u00b1 0.4728 2.2513 \u00b1 0.4843 RespNet [26] 0.7122 \u00b1 0.3290 0.7265 \u00b1 0.3328 2.0491 \u00b1 0.4456 2.5544 \u00b1 0.3368 Dilated ResNet (Proposed) 0.6303 \u00b1 0.3197 0.6417 \u00b1 0.3258 0.8123 \u00b1 0.3744 4.1142 \u00b1 0.4804\nBioengineering 2023, 10, 1222 13 of 17\nAccording to the result, when the SNR is 10 db, BianResNet has the lowest error among the three models with an MAE of 2.2513, while our proposed Dilated ResNet model has the highest error with an MAE of 4.1142. However, in all other cases, we can see that our proposed model performs the best as it obtained values of 0.6303, 0.6417, and 0.8123 (in bold). However, the overall RR estimation error consistently increased as the SNR decreased in our experiment."
        },
        {
            "heading": "4. Discussion",
            "text": "In our study, we can see that RespNet and CNNLSTM perform better than the other models in Table 5, and BianResNet, RespNet, and Dilated ResNet perform better in Table 6. We believe this is because these models extract the spatial\u2013spectral feature of the signal, which is often used in various PPG analysis studies [19,47]. Models that focus on temporal feature extraction, such as BiLSTM, also occasionally perform well using the temporal features of the signal, but more consistently perform well when using convolution and taking the shapes of previous signals and adding them together, such as ResNet. In Tables 5 and 6, we can confirm that the normal breathing group has the best results for all models in most cases. This is because of the group\u2019s imbalance in the dataset that we used to train the model. This also can be seen in Table 3, which shows that both datasets have most of the data in the normal breathing group and have the least data in the slow breathing group. In the case of BIDMC, about 85% of the dataset consisted of data from the normal breathing group, which is a larger number than the other groups. The slow breathing group data, on the other hand, is only 3% of the dataset. Understanding this explains why the normal breathing group performs well in most cases. The reason for the better performance of the model trained on the BIDMC dataset compared to our dataset in Table 4 can be understood by expanding on the following: there are much more normal breathing data to train on, and the validation data are dominated by data from the same breathing class. Using the BIDMC validation dataset, we compared each model\u2019s estimates of RRs to the actual RRs to see if they were correlated. If the models overestimated the normal RR, i.e., if they had less error in estimating the actual RR, their estimates were positively correlated with the actual RR. However, BianResNet and RespNet produced either a negative correlation or no correlation of \u22120.0519 (p < 0.01) and \u22120.3211 (p < 0.01), respectively. This is likely due to the imbalance in the respiratory data, as discussed above. A negative correlation means that the straight-line output based on the actual and estimated values descends downward, and since BIDMC is almost dominated by normal breathing data, a negative slope may occur when the model estimates data belonging to the slow breathing group with higher estimated values than the actual values. On the other hand, in the case of Dilated ResNet, we confirmed a weak positive correlation of 0.5069 (p < 0.01). This means that the RR estimates, using the current signal data, are not highly correlated with the actual values, which points to the limitations of the current preprocessing. To further consider that motion artifacts from patients in clinical practice can affect PPG-based RR estimation, we also confirmed the robustness of the three best-performing models to input signals of different SNRs, as shown in Table 7. The results show that Dilated ResNet has the highest estimation error at 10 db and the lowest errors are seen in the rest of the models. However, while the other models illustrate a gradual increase in error as the SNR decreases (i.e., as the shape of the input signal becomes more distorted), our model shows a sharp increase in error. This suggests that our model is more sensitive to noise that affects morphological features, as mentioned above. To improve this in future work, we would like to introduce regularization techniques to prevent our model from overfitting with the existing features. We would also like to use filters that are flexible to changes in the signal, such as adaptive filters [48], in preprocessing to increase the robustness of the overall model to various noises. To estimate the RR, we filtered out only the 0.1\u20130.4 frequency band signals from the PPG that are likely to be associated with it. Also, it was processed to obtain a low-frequency\nBioengineering 2023, 10, 1222 14 of 17\nsignal from the PPG that contains information about movement due to respiration. At the same time, it was an attempt to exclude information such as the heartbeat. Many studies suggested various frequency bands [16,20,22,23]. In addition, in this paper, we resampled the input signal to reduce the computation of the model, in the same way as Bian [25]. Although this preprocessing allowed us to better focus on the data that we wanted to study, it caused a loss of information and the deformation of a signal in the original data. Such limitation has the potential of degrading the model\u2019s performance and weakening correlations. In our future research, we should be aware of these points to improve the accuracy of RR estimation and more thoroughly investigate the appropriate frequency bands to remove unnecessary noise and capture more information for the estimation. Alternatively, it would be interesting to see and discuss the results of inputting such data without any information-losing preprocessing, taking advantage of the DL model\u2019s ability to analyze the signal. This may be one way to improve the accuracy of RR estimation by applying preprocessing layers of noise filtering and signal detrending to PPG to overcome the existing manual de-modulation method, as an advantage of deep learning models is that they can convolve various filters and signals into PPG, which is difficult for humans to process. However, improving the reliability of these results remains a challenge. Although there are various attempts at Explainable AI [49,50], this is also an area for future research to improve the reliability of respiration rate estimation using PPG. It is possible to provide some evidence for the reliability of the result if the convolution filters, frequency filters, or detrending functions initialized in the DL process are adjusted to be more specific to RR estimation and placed in layers. The variety of factors that are present in a patient is another limitation that weakens the model\u2019s performance. In our study, such components\u2014diseases (e.g., hypertension, atrial fibrillation, etc.), interventions (e.g., vasopressor, ventilation, etc.), and other external influences\u2014that modulate the PPG signal were not considered. Thus, in future work, we would like to study these characteristics, categorize patients, and confirm the model\u2019s RR estimation performance for each factor. Checking the box plot in Figure 6, we confirmed that Dilated ResNet has the highest standard deviation and median in errors among the three models. This suggests that our proposed model may be affected by various hyperparameters, as shown in Table 2, by applying a convolutional layer. Thus, future research will not only reduce the error of the proposed model but also clarify and study the causes of such deviations. To improve our model, it is necessary to generalize the model by applying regularization techniques such as L2 regularization, Dropout [51], replacing the RespBlock inner layer of the Dilated ResNet model to reduce RR estimation bias, and collecting additional data to provide the model with numerous signal patterns. A signal quality index (SQI) algorithm should also be added to reduce RR estimation error. The SQI algorithm is a technique that is intended to assess the signal and exclude signals with noise, which affect the training of the DL model in the preprocessing stage. Various algorithms, such as the skewness-based method, F1-score-based method, entropy-based method, machine learning-based method, etc., have been proposed to assess the quality of the PPG [16,52\u201355]. If we improve the quality of the PPG signal using an appropriate SQI algorithm that fits the PPG-derived DL model that we implemented for RR estimation in the follow-up study, we expect to estimate a more precise RR. In Tables 5 and 6, the difference in RR estimation resulting from the breathing rate group in the testing dataset is an obvious limitation that needs to be improved. To overcome this, in future research, we will fully utilize public datasets, but at the same time, try to configure our dataset to evenly test patients with different breathing rates and develop it into a public dataset. To carry this out, we are planning to carefully organize the database schema and data collection environment subject to a large data collection group and to collect the data over a long period, including the subject\u2019s demographic information (e.g., age, gender, weight, etc.), medical record (e.g., whether they underwent surgery, infusion drug time, diagnosis, etc.), and various physiological signals (e.g., ECG, etCO2, etc.). Furthermore, by improving the methodology of this study, which collected data using only\nBioengineering 2023, 10, 1222 15 of 17\nfingertips, we will collect PPG data from various body sites such as the earlobe or foot of a patient, analyze the measurements to compare the accuracy of the RR estimation between sites, and analyze the validity and association of PPG-derived RR estimation AI models according to the patient\u2019s underlying disease and functional level. We expect to propose detailed guidance that is capable of sophisticated application according to the patient\u2019s clinical status and measurement environment for the PPG-derived RR estimation AI model."
        },
        {
            "heading": "5. Conclusions",
            "text": "In conclusion, RR estimation using PPG-derived DL models is still challenging and has many limitations. Larger datasets, a model structure design, and preprocessing specialized in spatial\u2013temporal feature extraction for the estimation are required. However, as the validation results in Table 4 show, if there are equal amounts of data from various breathing groups to train, we expect that the DL models, including our Dilated ResNet model, can achieve better results than the current ones.\nAuthor Contributions: Conceptualization, E.Y.K.; methodology, C.S.H. and E.Y.K.; software, C.S.H., Y.H.K., J.K.H. and S.R.L.; validation, Y.H.K., J.K.H. and J.H.K.; formal analysis, C.S.H., J.K.H. and C.M.K.; investigation, J.H.K., S.R.L., C.M.K., J.W.N. and E.Y.K.; resources, Y.H.K., J.K.H., J.H.K., C.M.K. and J.W.N.; data curation, C.S.H., Y.H.K., J.K.H., J.H.K., S.R.L., C.M.K. and J.W.N.; writing\u2014original draft preparation, C.S.H.; writing\u2014review and editing, E.Y.K.; visualization, S.R.L. and J.W.N.; supervision, E.Y.K. All authors have read and agreed to the published version of the manuscript.\nFunding: This research received no external funding.\nInstitutional Review Board Statement: This study was conducted in accordance with the Declaration of Helsinki and approved by the Institutional Review Board (or Ethics Committee) of Seoul St. Mary\u2019s Hospital (IRB no. KC21ONSI0839, 26 October 2021).\nInformed Consent Statement: Informed consent was obtained from all subjects involved in the study.\nData Availability Statement: The datasets used and analyzed during the current study are available from the corresponding authors upon reasonable request.\nAcknowledgments: Not applicable.\nConflicts of Interest: The authors declare no conflict of interest.\nAbbreviations The following abbreviations are used in this manuscript. AI Artificial Intelligence APACHE Acute Physiology And Chronical Health Evaluation DL Deep Learning ECG Electrocardiogram ICU Intensive Care Unit MAE Mean Absolute Error MEWS Modified Early Warning Score PPG Photoplethysmogram RR Respiratory Rate SD Standard Deviation SICU Surgical Intensive Care Unit SOFA Sequential Organ Failure Assessment SQI Signal Quality Index"
        }
    ],
    "title": "Evaluation of the Photoplethysmogram-Based Deep Learning Model for Continuous Respiratory Rate Estimation in Surgical Intensive Care Unit",
    "year": 2023
}