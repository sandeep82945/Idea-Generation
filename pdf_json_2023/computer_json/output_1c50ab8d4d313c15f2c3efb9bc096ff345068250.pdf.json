{
    "abstractText": "We introduce a principled study on establishing Gaussian processes (GPs) with inputs on the product of directional manifolds. A circular kernel is first presented according to the von Mises distribution. Based thereon, the so-called hypertoroidal von Mises (HvM) kernel is proposed to establish GPs on hypertori with consideration of correlational circular components. The proposed HvM kernel is demonstrated with multi-output GP regression for learning vector-valued functions defined on hypertori using the intrinsic coregionalization model. Analytical derivatives in hyperparameter optimization are provided for runtime-critical applications. For evaluation, we synthesize a ranging-based sensor network and employ the HvMbased GPs for data-driven recursive localization. The numerical results show that the HvM-based GP achieves superior tracking accuracy compared to parametric model and GPs based on conventional kernel designs.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ziyu Cao"
        },
        {
            "affiliations": [],
            "name": "Kailai Li"
        }
    ],
    "id": "SP:e04b7ba5eb2282d45c7096d836992195ff8b00f1",
    "references": [
        {
            "authors": [
                "N. Ito",
                "S. Araki",
                "T. Nakatani"
            ],
            "title": "Complex angular central Gaussian mixture model for directional statistics in mask-based microphone array signal processing",
            "venue": "European Signal Processing Conference, Aug. 2016, pp. 1153\u20131157.",
            "year": 2016
        },
        {
            "authors": [
                "J. Glover",
                "L.P. Kaelbling"
            ],
            "title": "Tracking the spin on a ping pong ball with the quaternion Bingham filter",
            "venue": "IEEE International Conference on Robotics and Automation, June 2014, pp. 4133\u20134140.",
            "year": 2014
        },
        {
            "authors": [
                "X. Zhe",
                "S. Chen",
                "H. Yan"
            ],
            "title": "Directional statistics-based deep metric learning for image classification and retrieval",
            "venue": "Pattern Recognition, vol. 93, pp. 113\u2013123, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "H. M\u00f6ls",
                "K. Li",
                "U.D. Hanebeck"
            ],
            "title": "Highly parallelizable plane extraction for organized point clouds using spherical convex hulls",
            "venue": "IEEE International Conference on Robotics and Automation, May 2020.",
            "year": 2020
        },
        {
            "authors": [
                "K. Li",
                "F. Pfaff",
                "U.D. Hanebeck"
            ],
            "title": "Grid-based quaternion filter for SO(3) estimation",
            "venue": "European Control Conference, May 2020.",
            "year": 2020
        },
        {
            "authors": [
                "\u2014\u2014"
            ],
            "title": "Circular discrete reapproximation",
            "venue": "International Conference on Information Fusion, July 2022.",
            "year": 2022
        },
        {
            "authors": [
                "C.E. Rasmussen",
                "C.K.I. Williams"
            ],
            "title": "Gaussian Processes for Machine Learning",
            "year": 2006
        },
        {
            "authors": [
                "D. Duvenaud"
            ],
            "title": "Automatic model construction with Gaussian processes",
            "venue": "Ph.D. dissertation, University of Cambridge, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "F. Lindgren",
                "H. Rue",
                "J. Lindst"
            ],
            "title": "An explicit link between Gaussian fields and Gaussian Markov random fields: The stochastic partial differential equation approach",
            "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology), vol. 73, no. 4, pp. 423\u2013498, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "V. Borovitskiy",
                "A. Terenin",
                "P. Mostowsky"
            ],
            "title": "Mat\u00e9rn Gaussian processes on Riemannian manifolds",
            "venue": "Advances in Neural Information Processing Systems, vol. 33, pp. 12 426\u201312 437, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "M. Hutchinson",
                "A. Terenin",
                "V. Borovitskiy",
                "S. Takao",
                "Y. Teh",
                "M. Deisenroth"
            ],
            "title": "Vector-valued Gaussian processes on Riemannian manifolds via gauge independent projected kernels",
            "venue": "Advances in Neural Information Processing Systems, vol. 34, pp. 17 160\u201317 169, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Feragen",
                "F. Lauze",
                "S. Hauberg"
            ],
            "title": "Geodesic exponential kernels: When curvature and linearity conflict",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition, June 2015, pp. 3032\u20133042.",
            "year": 2015
        },
        {
            "authors": [
                "A. Majumdar"
            ],
            "title": "Gaussian processes on the support of cylindrical surfaces, with application to periodic spatio-temporal data",
            "venue": "Journal of Statistical Planning and Inference, vol. 153, pp. 27\u201341, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "M. Lang",
                "O. Dunkley",
                "S. Hirche"
            ],
            "title": "Gaussian process kernels for rotations and 6D rigid body motions",
            "venue": "IEEE International Conference on Robotics and Automation, June 2014, pp. 5165\u20135170.",
            "year": 2014
        },
        {
            "authors": [
                "R. Fisher"
            ],
            "title": "Dispersion on a sphere",
            "venue": "Proceedings of the Royal Society of London. Series A, Mathematical and Physical Sciences, vol. 217, no. 1130, pp. 295\u2013305, 1953.",
            "year": 1953
        },
        {
            "authors": [
                "K. Li",
                "F. Pfaff",
                "U.D. Hanebeck"
            ],
            "title": "Progressive von Mises\u2013Fisher filtering using isotropic sample sets for nonlinear hyperspherical estimation",
            "venue": "Sensors, vol. 21, no. 9, p. 2991, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "\u2014\u2014"
            ],
            "title": "Nonlinear von Mises\u2013Fisher filtering based on isotropic deterministic sampling",
            "venue": "IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems, Sep. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "I. Gilitschenski",
                "R. Sahoo",
                "W. Schwarting",
                "A. Amini",
                "S. Karaman",
                "D. Rus"
            ],
            "title": "Deep orientation uncertainty learning based on a Bingham loss",
            "venue": "International Conference on Learning Representations, Apr. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "K. Li",
                "D. Frisch",
                "B. Noack",
                "U.D. Hanebeck"
            ],
            "title": "Geometry-driven deterministic sampling for nonlinear Bingham filtering",
            "venue": "European Control Conference, Jun. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "K. Li"
            ],
            "title": "On-manifold recursive Bayesian estimation for directional domains",
            "venue": "Ph.D. dissertation, Karlsruhe Institute of Technology, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "K. Li",
                "F. Pfaff",
                "U.D. Hanebeck"
            ],
            "title": "Dual quaternion sample reduction for SE(2) estimation",
            "venue": "International Conference on Information Fusion, Jul. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "G. Kurz",
                "U.D. Hanebeck"
            ],
            "title": "Toroidal information fusion based on the bivariate von Mises distribution",
            "venue": "IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems, Sep. 2015, pp. 309\u2013315.",
            "year": 2015
        },
        {
            "authors": [
                "S. Bultmann",
                "K. Li",
                "U.D. Hanebeck"
            ],
            "title": "Stereo visual SLAM based on unscented dual quaternion filtering",
            "venue": "International Conference on Information Fusion, Jul. 2019, pp. 1\u20138.",
            "year": 2019
        },
        {
            "authors": [
                "K. Li",
                "F. Pfaff",
                "U.D. Hanebeck"
            ],
            "title": "Unscented dual quaternion particle filter for SE(3) estimation",
            "venue": "IEEE Control Systems Letters, vol. 5, no. 2, pp. 647\u2013652, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "\u2014\u2014"
            ],
            "title": "Geometry-driven stochastic modeling of SE(3) states based on dual quaternion representation",
            "venue": "IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems, May 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M.A. Alvarez",
                "L. Rosasco",
                "N.D. Lawrence"
            ],
            "title": "Kernels for vectorvalued functions: A review",
            "venue": "Foundations and Trends in Machine Learning, vol. 4, no. 3, pp. 195\u2013266, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "N. Boumal",
                "B. Mishra",
                "P.-A. Absil",
                "R. Sepulchre"
            ],
            "title": "Manopt, a Matlab toolbox for optimization on manifolds",
            "venue": "Journal of Machine Learning Research, vol. 15, no. 42, pp. 1455\u20131459, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "M. Kok",
                "J.D. Hol",
                "T.B. Sch\u00f6n"
            ],
            "title": "Indoor positioning using ultrawideband and inertial measurements",
            "venue": "IEEE Transactions on Vehicular Technology, vol. 64, no. 4, pp. 1293\u20131303, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "Y. Oshman",
                "P. Davidson"
            ],
            "title": "Optimization of observer trajectories for bearings-only target localization",
            "venue": "IEEE Transactions on Aerospace and Electronic Systems, vol. 35, no. 3, pp. 892\u2013902, 1999.",
            "year": 1999
        },
        {
            "authors": [
                "F. Gustafsson",
                "F. Gunnarsson",
                "N. Bergman",
                "U. Forssell",
                "J. Jansson",
                "R. Karlsson",
                "P.-J. Nordlund"
            ],
            "title": "Particle filters for positioning, navigation, and tracking",
            "venue": "IEEE Transactions on Signal Processing, vol. 50, no. 2, pp. 425\u2013437, 2002.",
            "year": 2002
        },
        {
            "authors": [
                "M. Titsias"
            ],
            "title": "Variational learning of inducing variables in sparse Gaussian processes",
            "venue": "International Conference on Artificial Intelligence and Statistics, Apr. 2009, pp. 567\u2013574.",
            "year": 2009
        },
        {
            "authors": [
                "M. Cai",
                "M. Hasanbeig",
                "S. Xiao",
                "A. Abate",
                "Z. Kan"
            ],
            "title": "Modular deep reinforcement learning for continuous motion planning with temporal logic",
            "venue": "IEEE Robotics and Automation Letters, vol. 6, no. 4, pp. 7973\u20137980, 2021.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "I. INTRODUCTION\nDirectional variables appear in ubiquitous control-related scenarios including signal processing, object tracking, and computer vision, among others [1]\u2013[6]. Typical examples of directional manifolds include the unit circle S1 \u2282 R2 and hyperspheres Sd\u22121 \u2282 Rd, which are by nature nonlinear and periodic. Many real-world applications, such as ground/aerial locomotion, robotic manipulation, and angle-of-arrival-based tracking, involve stochastic systems composing multiple directional inputs. Gaussian processes (GPs) have emerged as a powerful statistical tool for inferential modeling of uncertain dynamical systems [7], where dependence between system outputs is captured by the similarity across the input domain quantified by the kernel. This paper focuses on the study of a representative case, namely GP modeling of vector-valued functions defined on the hypertorus T3 := S1\u00d7S1\u00d7S1 \u2282 R6 (\u2018\u00d7\u2019 denotes the Cartesian product).\nThe key challenge in addressing the considered problem is to design a suitable kernel quantifying the similarity between hypertoroidal data points adaptively to the underlying manifold structure. The investigation can be decomposed into two sub-problems. First, each circular component is inherently periodic and nonlinear, which cannot be simply handled by conventional kernels defined based on Euclidean distances. Second, it is essential to properly interpret the correlations among the circular components for informative similarity quantification. The former challenge can be overcome by\nThis work is partially supported by the German Research Foundation (DFG) under grant HA 3789/25-1 and the Swedish Research Council under grant Scalable Kalman Filters.\nZiyu Cao was with the Intelligent Sensor-Actuator-Systems Laboratory (ISAS), Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology (KIT), Germany. Kailai Li is with the Division of Automatic Control, Department of Electrical Engineering, Linko\u0308ping University, Sweden. E-Mails: ziyu.cao@outlook.com, kailai.li@liu.se\ntransforming common periodic kernels w.r.t. the unit circle S1 [7]. The latter refers to constructing kernels on a manifold composing multiple domains through the Cartesian product. In this regard, most existing solutions employ a straightforward strategy of multiplying the kernels belonging to each domain component, which overlooks the correlational interpretation between them and may result in information loss for inferential modeling [8].\nThe major contribution of the presented work is a principled study on establishing Gaussian processes on the product of directional manifolds. The so-called hypertoroidal von Mises (HvM) kernel is proposed for handling input data on hypertori with consideration of correlational circular components in a manifold-adaptive manner. Closed-form derivatives are provided for efficient hyperparameter optimization. Further, we synthesize an evaluation scenario for recursive tracking in sensor networks, where an unknown range sensing model is learned using angle-of-arrival data. Compared with parametric and GP modeling using common kernel designs, the proposed HvM-based GP enables superior tracking accuracy and robustness.\nThe remainder of the paper is organized as follows. We summarize related works in Sec. II. Preliminaries on GP modeling are introduced in Sec. III, after which the HvM kernel is proposed in Sec. IV. We elaborate the evaluation in Sec. V, and the work is concluded in Sec. VI."
        },
        {
            "heading": "II. RELATED WORKS",
            "text": "GPs on Riemannian Manifolds: In [9], GP kernels have been derived on Riemannian manifolds (RMs) implicitly by solving stochastic partial differential equations incorporating the Laplace\u2013Beltrami operator. An improvement on scalability has been proposed in [10] via spectral theory for Mate\u0301rn GPs on RMs. The approach was further adopted in [11] for modeling tangential vector fields defined on RMs through projective geometry. These implicit strategies are generally applicable for developing RM-adaptive kernels, however, suffer from high theoretical complexity and computational expense, such as the eigendecomposition of Laplace-Beltrami operators, leading to a considerable gap for their usage in engineering practices. Alternatively, manifold-adaptive kernels can be explicitly designed w.r.t. the underlying manifold structure. This can lead to a conciser procedure of establishing GPs. However, simply replacing the distance metric with the geodesic to generalize Gaussian kernels on RMs for nonEuclidean inputs does not guarantee positive definiteness. In this regard, Laplacian kernels are eligible if and only if the distance metric is conditionally negative definite [12]. For GP modeling on domains with complex but known ar X iv :2\n30 3.\n06 79\n9v 2\n[ cs\n.L G\n] 1\n1 Ju\nn 20\n23\nstructures, basic kernels of each domain component are typically combined through summation or multiplication [8]. In [13], GPs have been established on cylindrical surface (S1\u00d7R) for spatiotemporal modeling of meteorological fields, where the kernel is obtained by multiplying a sinusoidal and a Laplacian kernel of l1-norm. In [14], various GP kernels have been investigated on manifolds of unit quaternions and unit dual quaternions based on hyperspherical geometry on S3 for spatial orientation/pose inferences.\nDirectional Statistics: Distributions from directional statistics have provided valuable references for quantifying similarities between directional data points [15]. Popular choices include the wrapped normal and the von Mises distributions on the unit circle, and the von Mises\u2013Fisher distribution on hyperspheres [16]\u2013[18]. For modeling directional quantities of antipodal symmetry, e.g., unit quaternions on S3 \u2282 R4, the Bingham distribution is commonly used and has been widely exploited in reasoning uncertain spatial orientations [19], [20]. As for distributions on composite directional domains, one important aspect is to interpret correlation across manifold components [21], [22]. Former works were shown on the torus S1 \u00d7 S1 for temporal modeling of correlated wind directions [23] and on the manifold of unit dual quaternions for modeling uncertain spatial poses [24]\u2013[26]."
        },
        {
            "heading": "III. GAUSSIAN PROCESS REGRESSION AND INFERENCE",
            "text": "A. Gaussian Process Modeling\nA Gaussian process is a collection of random variables on a certain domain. Any finite set of these random variables follows a multivariate Gaussian distribution. For instance, a GP of scalar output is denoted as r(x) \u223c GP(m(x),k(x, x\u2032)), with m(x) and k(x, x\u2032) being the mean and covariance functions of r(x), respectively [7]. Suppose there is an arbitrary function that is observed under uncertainty following z = r(x) + \u03f5 with noise \u03f5 \u223c N (0, \u03c32r). Given a set of n input locations and corresponding observations corrupted by noise, {(x\u2022,i, zi)}ni=1, a GP yields a posterior of the function value at test locations {x\u25e6,i}mi=1 in the form of a multivariate Gaussian distribution\nr\u25e6|{(x\u2022,i, zi)}ni=1, {x\u25e6,i}mi=1 \u223c N (r\u0302\u25e6,C\u25e6) ,\nwith the mean and covariance given by\nr\u0302\u25e6 = K\u25e6\u2022K \u22121z and C\u25e6 = K\u25e6\u25e6 \u2212K\u25e6\u2022K\u22121K\u2022\u25e6 , (1)\nrespectively [7], where K = K\u2022\u2022 + \u03c32rIn. Element in matrix K\u2022\u25e6 \u2208 Rn\u00d7m at entry (i, j) is the covariance given by the kernel evaluated at training and test locations (x\u2022,i, x\u25e6,j). Matrices K\u2022\u2022 \u2208 Rn\u00d7n, K\u25e6\u2022 \u2208 Rm\u00d7n can be obtained analogously. Vector z = [z1, \u00b7 \u00b7 \u00b7 , zn]\u22a4 collects all observations, and In \u2208 Rn\u00d7n is an identity matrix. Further, the set of predicted observations at test locations follows the distribution N (r\u0302\u25e6,C\u25e6 + \u03c32rIm).\nB. Multi-Output Gaussian Processes\nFor modeling vector-valued functions expressed as z = r(x) + \u03f5 \u2208 Rd, where \u03f5 \u223c N (0d,R) is the noise term and R = diag(\u03c32r,1, \u00b7 \u00b7 \u00b7 , \u03c32r,d) its associated covariances, the\nmulti-output Gaussian process can be exploited. It takes the form r(x) \u223c GP(m(x),K(x, x\u2032)), with m(x) \u2208 Rd being a vector-valued function collecting the mean of each dimension and K(x, x\u2032) the matrix-valued covariance function. To obtain a valid K(x, x\u2032), one popular method is the intrinsic coregionalization model. This leads to\nK(x, x\u2032) = k(x, x\u2032)B , with B \u2208 Rd\u00d7d (2)\nbeing a coregionalization matrix that is positive semidefinite [27]. Given uncertain observations {zi}ni=1 collected at training locations {x\u2022,i}ni=1, the posterior at a test location x\u25e6 follows\nr\u25e6|{(x\u2022,i, zi)}ni=1, x\u25e6 \u223c N (r\u0302\u25e6,C\u25e6) .\nHere, the mean and covariance are calculated according to the general form in (1), with components newly defined as K\u25e6\u2022 = B\u2297 k\u25e6\u2022, K\u25e6\u25e6 = k(x\u25e6, x\u25e6)B and K = B\u2297K\u2022\u2022 +R\u2297 In. Note that K\u2022\u2022 still denotes the kernel matrix at training locations as given in (1). Furthermore, vector z is obtained through the vectorization z = vec([ z1, \u00b7 \u00b7 \u00b7 , zn ]\u22a4) \u2208 Rnd, and vector k\u25e6\u2022 = [k(x\u25e6, x\u2022,1), \u00b7 \u00b7 \u00b7 ,k(x\u25e6, x\u2022,n)]. Similarly to the scalar case, the predictive distribution of the observation at x\u25e6 is obtained as z\u25e6 \u223c N (r\u0302\u25e6,C\u25e6 +R)."
        },
        {
            "heading": "IV. GAUSSIAN PROCESSES ON THE HYPERTORUS",
            "text": "A. A Circular Kernel Based on the von Mises Distribution\nWe now consider a scalar-valued function r(x) with inputs defined on the unit circle, namely, r : S1 \u2192 R for GP modeling. In order to quantify the similarity between two circular inputs u, v \u2208 S1, we formulate a kernel kvM(u, v) = \u03c92 exp(\u03bbu\u22a4v) based on the von Mises distribution, with \u03c9 controlling signal variance and \u03bb > 0 the concentration. Note that this kernel can be referred to as a reformulation of the periodic kernel with angular inputs [7, Eq. 4.31]. To showcase its functionality within the GP framework compared with kernels on Euclidean domains, we demonstrate the following case study.\nCase Study 1 We synthesize a function on the unit circle by mixing three von Mises distributions and one Bingham distribution, with each component configured with individual parameters. The function is observed via z = 1 3 \u22113 i=1 f i vM(x)+ fB(x)+ \u03f5, with \u03f5 \u223c N (0, 0.0025) being an additive noise. We embed the squared exponential (SE) kernel (distance metric d = \u03b8 \u2212 \u03b8\u2032, with \u03b8 and \u03b8\u2032 denoting the angular positions of u and v, respectively) and the proposed von Mises (vM) kernel into the same GP regression scheme as introduced in Sec. III-A. Shown in Fig. 1-(A), the SE kernel produces discontinuous curves due to the aperiodic distance metric of Euclidean geometry. In contrast, the proposed vM kernel quantifies periodic similarity adaptively to circular geometry, inducing identical posteriors with period of 2\u03c0 as plotted in Fig. 1-(B).\nB. The Hypertoroidal von Mises Kernel\nWe now aim to establish GPs on the hypertorus T3 \u2282 R6. For constructing kernels on the Cartesian product of multiple unit circles, a common strategy is to multiply kernels on each circular component [8]. However, this only considers the similarity within each unit circle and neglects any potential correlations in between. To achieve informative GP modeling on hypertori, it is crucial to design a manifold-adaptive kernel with consideration of correlational circular components. For that, we propose the so-called hypertoroidal von Mises (HvM) kernel defined as\nkHvM(u, v) = \u03c9 2exp(\u03bb\u22a4d(u, v) +d(u, v)\u22a4\u039bd(u, v)) , (3)\nwith u, v \u2208 S1 \u00d7 S1 \u00d7 S1 being a pair of hypertoroidal inputs. We express them component-wise w.r.t. each circle as u= [ (u1)\u22a4, (u2)\u22a4, (u3)\u22a4 ]\u22a4 and v= [ (v1)\u22a4, (v2)\u22a4, (v3)\u22a4 ]\u22a4. The metric d is defined as\nd(u, v) = [ (u1)\u22a4v1, (u2)\u22a4v2, (u3)\u22a4v3 ]\u22a4 ,\nwhich measures distances between data points via inner products on each circular component. This analogizes the von Mises kernel given in Sec. IV-A, and inherently guarantees the symmetry of function (3) and the periodic nature of the hypertoroidal manifold.\nThe proposed HvM kernel incorporates three hyperparameters, i.e., the \u03c9 \u2208 R, \u03bb \u2208 R3, and \u039b \u2208 R3\u00d73. Similar to the von Mises kernel in Sec. IV-A, \u03c9 controls signal variance. The exponent of the kernel consists of a linear term and a quadratic term w.r.t. the distance metric d. In the linear term, \u03bb = [\u03bb1, \u03bb2, \u03bb3 ]\u22a4 is a nonnegative vector and interprets concentrations on each circular component. In the second term, \u039b serves as a weighting matrix in the quadratic formulation and is defined as\n\u039b =  0 a1 a3a1 0 a2 a3 a2 0  , with all elements being nonnegative. It is specifically designed to capture the correlations between the three pairs of circular components through the quadratic term. It allows for more informative similarity quantification of hypertoroidal data\ncompared to simple products of circular kernels. To showcase this efficacy, we provide the following case study.\nCase Study 2 We configure the proposed kernel in (3) w.r.t. the torus S1 \u00d7 S1 \u2282 R4 based on four sets of parameters {(\u03c9i, \u03bbi,\u039bi)}4i=1. These follow\n\u2022 \u03c91 = \u03c92 = \u03c93 = \u03c94 = 1 , \u2022 \u03bb1 = \u03bb2 = [ 0.3, 0.3 ] \u22a4, \u03bb3 = \u03bb4 = [ 1, 1 ] \u22a4 , and \u2022 \u039b1 = \u039b3 = 02\u00d72, \u039b2 = \u00ef 0 0.3 0.3 0 \u00f2 , \u039b4 = \u00ef 0 1 1 0 \u00f2 .\nWe evaluate the proposed kernel with one input fixed at u = [ 1, 0, 1, 0 ]\u22a4, which corresponds to zero angular positions on each circle, and the other one given by\nv = [ cos(\u03b1), sin(\u03b1), cos(\u03b2), sin(\u03b2) ]\u22a4\nw.r.t. angles (\u03b1, \u03b2). Shown in Fig. 2-(A) to (D), the resulted kernels are plotted corresponding to the parameter sets 1 to 4. In all cases, the kernel indicates the highest similarity at (\u03b1, \u03b2) = (0, 0), namely, u = v . When \u039b = 02\u00d72, as illustrated by Fig. 2-(A) and (C), the proposed hypertoroidal kernel degenerates to a simple multiplication of von Mises kernels, which disregards the correlation between the two circular components. In contrast, the nonzero off-diagonal elements in \u039b2 and \u039b4 enable correlation interpretation between circles, leading to more distinguishable similarity quantification of function values as plotted in Fig. 2-(B) and (D), respectively.\nC. Hyperparameter Optimization\nVarying the free parameters, e.g., those in the kernels, has a considerable impact on the performance of GP regression and inference. In general, these hyperparameters \u03b8 can be obtained via maximum likelihood estimation following \u03b8\u2217 = argmax\u03b8 F(\u03b8). The objective is derived in the form of log\nmarginal likelihood F(\u03b8) = 2 log p ( z|{x\u2022,i}ni=1, \u03b8 ) = \u2212z\u22a4K\u22121z\u2212 log |K| \u2212 n log(2\u03c0) ,\n(4)\nwith K and z specified according to Sec. III. In practice, the nonlinear optimization problem above is solved numerically with the kernel matrix evaluated in each iteration. The gradient of the objective w.r.t. the i-th element in \u03b8 takes the following general form\n\u2202F(\u03b8)\n\u2202\u03b8i = z\u22a4K\u22121\n\u2202K \u2202\u03b8i K\u22121z\u2212 tr\n( K\u22121 \u2202K\n\u2202\u03b8i\n) , (5)\nwith tr denoting the trace of a matrix. As for multi-output GPs using the proposed hypertoroidal von Mises kernel, the hyperparameters can be collected into\n\u03b8 = [\u03c9, \u03bb\u22a4, a\u22a4, b\u22a4, \u03c3\u22a4r ] \u22a4 .\nThe first three components, \u03c9, \u03bb, and a = [ a1, a2, a3 ]\u22a4 are free parameters in (3). b = vec(B) denotes the vectorized coregionalization matrix in (2). And \u03c3r = [\u03c3r,1, \u00b7 \u00b7 \u00b7 , \u03c3r,d ]\u22a4 indicates observation noise variance on each output dimension according to Sec. III-B.\nComputing (5) boils down to deriving the derivative of K(\u03b8) w.r.t. hyperparameters in \u03b8, which we express elementwise now for clear explanation. The derivative of the kernel matrix w.r.t. the signal deviation \u03c9 follows\n\u2202K \u2202\u03c9 = B\u2297 \u2202K\u2022\u2022 \u2202\u03c9 = 2 \u03c9 B\u2297K\u2022\u2022 ,\nwhere K\u2022\u2022 denotes the kernel matrix evaluated at training sets as introduced in Sec. III-B. Further, the derivative of K w.r.t. each element in the concentration vector \u03bb follows\n\u2202K \u2202\u03bbs = B\u2297 \u2202K\u2022\u2022 \u2202\u03bbs = B\u2297 (K\u2022\u2022 \u2299Ds\u2022\u2022) ,\nwith s \u2208 {1, 2, 3} being the index of the s-th circular component of the hypertorus. Correspondingly, elements in Ds\u2022\u2022 \u2208 Rn\u00d7n follow (Ds\u2022\u2022)ij := (xs\u2022,i)\u22a4xs\u2022,j , which interprets distance between training inputs on each circle,\nand \u2299 denotes the Hadamard product. As for differentiation on the nonzero elements in matrix \u039b, we have \u2202K\n\u2202as = B\u2297 \u2202K\u2022\u2022 \u2202as = 2B\u2297\n( K\u2022\u2022 \u2299Ds\u2022\u2022 \u2299Ds mod 3+1\u2022\u2022 ) ,\nwith s \u2208 {1, 2, 3}. The derivative of K w.r.t. the s-th element in the vectorized coregionalization matrix takes the form\n\u2202K \u2202bs = \u2202(B\u2297K\u2022\u2022) \u2202bs = \u2202B \u2202bs \u2297K\u2022\u2022 = Eij \u2297K\u2022\u2022 ,\nwith Eij \u2208 Rd\u00d7d denoting a matrix unit. Here, bs = (B)ij , with s = d (j \u2212 1) + i \u2208 {1, \u00b7 \u00b7 \u00b7 , d2}. The derivative of K w.r.t. observation deviation \u03c3r,s of each output domain s \u2208 {1, \u00b7 \u00b7 \u00b7 , d} can be derived in a similar fashion. It follows\n\u2202K\n\u2202\u03c3r,s = \u2202(R\u2297 In) \u2202\u03c3r,s = 2\u03c3r,sEss \u2297 In ,\nwhere Ess \u2208 Rd\u00d7d is a matrix unit. In practice, we exploit the trust-regions method from Manopt [28] for maximizing the objective in (4)."
        },
        {
            "heading": "V. EVALUATION",
            "text": "We now evaluate the proposed HvM-based GPs within particle filtering for data-driven recursive tracking in sensor networks. Here, an unknown range sensing model is learned on the hypertorus, which consists of multiple angle-of-arrival data as input.\nA. Scenario Setup\nWe set up a two-dimensional area of 30\u00d7 30 m2, where a mobile agent is tracked while moving along different trajectories. We have the following system dynamics according to a random walk\nxt+1 = xt +wt , (6)\nwith xt, xt+1 \u2208 R2 denoting positions and wt \u2208 R2 the process noise following wt \u223c N (02,Qt). A range sensor, e.g., of ultrasonic or ultra-wideband modalities, is equipped onboard the platform observing distances to three reference points of coordinates {\u03b9rs}3s=1 \u2282 R2 under uncertainty. This can be formulated as\nzt = h(xt) + \u03b4t + vt , (7)\nwhere zt \u2208 R3 and vt \u2208 R3 denote the range measurement and corresponding noise, respectively, and vt \u223c N (03,Rt). The observation function is given by\nh(xt) := [\u2225\u03b9r1 \u2212 xt\u2225, \u2225\u03b9r2 \u2212 xt\u2225, \u2225\u03b9r3 \u2212 xt\u2225]\u22a4 ,\nwhich generates noise-free range readings of position state xt w.r.t. the three reference points. Moreover, a time-varying offset \u03b4t \u2208 R3 is added to the range signal to include possible interference in sensor networks, such as clock drift or signal reflection [29]. For the sake of demonstration, we assume that it is proportional to the range, namely, \u03b4t = c \u00b7 h(xt), where the ratio c = 0.05.\nB. Multi-Output GPs on Hypertorus\nSuppose that the offset and uncertainty in range observations are unknown. However, we are able to obtain accurate angle-of-arrival (AoA) readings from each reference point w.r.t. 24\u00d710 grid points {xi}n=240i=1 that are uniformly spaced on the xy-plane. Meanwhile, range measurements given by the onboard sensor are collected, inducing a training set of {(\u03b1i, zi)}ni=1, where the range zi \u2208 R3. The input \u03b1i = [ (\u03b1 1 i ) \u22a4, (\u03b12i ) \u22a4, (\u03b13i )\n\u22a4]\u22a4 \u2208 T3 \u2282 R6 incorporates the AoA signal of each reference point w.r.t. grid point xi, which can be obtained via\n\u03b1si = [ (\u03b9 r s \u2212 xi)x, (\u03b9rs \u2212 xi)y]\u22a4/\u2225\u03b9rs \u2212 xi\u2225 \u2208 S1 , (8)\nwith s \u2208 {1, 2, 3}. Such a scenario occurs commonly when there exists no positioning system (e.g., camera networks) covering the whole tracking space, whereas certain portable devices such as total stations can be easily deployed to provide accurate relative angles between two locations [30]. Based on the training set, we exploit the proposed HvM-based vectorvalued GPs to learn the unknown range sensing model as introduced in Sec. IV. According to Sec. III-B, we reformulate the measurement model in (7) into zt = r(\u03b1t)+vt, with \u03b1t \u2208 T3 incorporating the AoA inputs and vt the uncertainty in the output. Given the scenario setup in Sec. V-A, the noise-free range observation follows r(\u03b1t) = h(xt)+\u03b4t = (1+c)h(xt).\nC. GP-Based Particle Filtering\nWe apply particle filtering to track the mobile agent set up in Sec. V-A [31]. Given a particle x\u0302t|t\u22121 drawn at timestamp t from the prior estimate (particle index is omitted for brevity), we first compute the corresponding hypertoroidal state \u03b1\u0302t|t\u22121 \u2208 T3 following (8). Here, each circular component is given by\n\u03b1\u0302st|t\u22121 = [ (\u03b9 r s \u2212 x\u0302t|t\u22121)x, (\u03b9rs \u2212 x\u0302t|t\u22121)y]\u22a4/\u2225\u03b9rs \u2212 x\u0302t|t\u22121\u2225\nw.r.t. each reference point indexed by s \u2208 {1, 2, 3}. We further inquire the pre-trained GPs (using training data {(\u03b1i, zi)}ni=1) at \u03b1\u0302t|t\u22121 to predict corresponding range measurement distribution, i.e.,\nzt|{(\u03b1i, zi)}ni=1, \u03b1\u0302t|t\u22121 \u223c N (r\u0302t|t\u22121,Ct|t\u22121 +R) ,\nwhere r\u0302t|t\u22121 and (Ct|t\u22121 + R) are posterior mean and covariance given by the GP regression in Sec. III-B, respectively. Based thereon, the likelihood function is directly\nobtained for reweighting the prior particle x\u0302t|t\u22121 given current measurement zt. Afterward, particles are updated via resampling.\nD. Evaluation and Results\nWe equip the GP-based particle filter in Sec. V-C with the proposed HvM kernel. For comparison, we instrument the product of squared exponential kernels (PSE), the product of periodic kernels (PPRD), and the product of von Mises kernels (PvM) on the hypertorus through multiplication of the corresponding circular kernels [8]. GPs based on different kernels are trained using the same data set collected as introduced in Sec. V-B. Furthermore, we approximate range measurement noise with a three-dimensional Gaussian distribution using the same training data to provide likelihood functions for a parametric form. We set the process noise in (6) with covariance Qt = diag(0.16, 0.16) and the measurement noise in (7) with covariance Rt = \u03be2I3, where \u03be \u2208 {0.01, 0.03, 0.05} controls the level of uncertainty. We deploy 100 particles to all particle filters for 1000 time steps and perform evaluation based on 100 Monte Carlo runs for each trajectory and noise level.\nShown in Fig. 3, we collect evaluation results given by the particle filters configured above on multiple sequences with varying trajectories (as plotted in T1-T3 in Fig. 4) and measurement noise levels (S1-S3 w.r.t. \u03be). The proposed HvM kernel delivers superior tracking accuracy of particle filtering via GP-based reweighting over the PPRD, PvM, PSE kernels, and the parametric modeling method. Exemplary runs of HvM-GP-based particle filtering on these three trajectories are shown in Fig. 4 under the noise level of \u03be = 0.01. Almost identical accuracies are achieved by the PPRD and PvM kernels, which suggests that the von Mises kernel can be interpreted as a reformulation of the common periodic kernel. Moreover, results from these two kernels show better accuracy compared with the parametric method, whereas the PSE kernel fails tracking on most sequences due to disregard of periodic nature of hypertori.\nTo bring more insights to the functionality of the proposed HvM kernel on particle reweighting, we demonstrate in Fig. 5 range measurement distributions predicted by GPs using HvM, PvM, and PSE kernels over time. The proposed HvM-GP predicts more data-adaptive range distributions than PvM-GP,\nand the PSE kernel induces discontinuity when periodicity in inputs takes effect. The parametric method fails at modeling the time-varying noise pattern, which can be interpreted in a straightforward way (thus not plotted)."
        },
        {
            "heading": "VI. CONCLUSIONS",
            "text": "We provide a novel study on establishing GPs on the product of directional manifolds. Based on the circular kernel following the form of the von Mises distribution, a novel hypertoroidal von Mises (HvM) kernel has been proposed on the hypertorus S1 \u00d7 S1 \u00d7 S1 \u2282 R6 in a manifold-adaptive manner. It captures information not only within each circular component but also in the correlated region, leading to a more distinct similarity quantification of hypertoroidal data compared to conventional strategies such as kernel multiplication. In consideration of potential usage in runtime-critical scenarios, derivatives of the marginal likelihood w.r.t. the hyperparameters have been provided to facilitate efficient GP modeling. The proposed HvM-based GP has been evaluated for data-driven recursive localization in ranging-based sensor networks. Simulations have shown that it delivers superior tracking performance over the parametric model and GPs based on kernel multiplications.\nFor future work, the efficiency of the proposed method can be improved by reducing the computational complexity, e.g., via sparse Gaussian processes [32]. In addition, the proposed HvM-GP is to be exploited in real-world applications for datadriven modeling of complex stochastic systems with multiple angular inputs [33]. Also, the HvM kernel can be extended to higher-dimensional spaces, enabling its application in more extensive scenarios."
        }
    ],
    "title": "Gaussian Process on the Product of Directional Manifolds",
    "year": 2023
}