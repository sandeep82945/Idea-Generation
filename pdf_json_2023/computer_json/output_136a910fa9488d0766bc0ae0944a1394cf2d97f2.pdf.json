{
    "abstractText": "Mass-casualty incidents with a large number of injured persons caused by human-made or by natural disasters are increasing globally. In such situations, medical first responders (MFRs) need to perform diagnosis, basic life support, or other first aid to help stabilize victims and keep them alive to wait for the arrival of further support. Situational awareness and effective coping with acute stressors are essential [5] to enable first responders to take appropriate action that saves lives. Such tasks are particularly challenging for first responders, that lack the special training to act optimally in these situations. Increasingly severe consequences of natural disasters and terrorist threats will expand the occurrence probability of such stressful and demanding situations and require the development and deployment of innovative technological solutions adapted to the (cross-sectoral) needs of first responders. In that context, the adage \u201cpractice makes perfect\u201d is well-fitting to situational training. Lectures, books, videos, etc. are no substitute for hands-on experiences, and humans often learn more from their mistakes than from their successes. Unfortunately, it is difficult to provide such training for large-scale emergency medicine or in dangerous conditions. Current training of medical first responders often happens through live exercises: medics practice stabilisation and wound care via moulage, a training exercise where live persons are given highly realistic \u201cfake\u201d wounds. The drawback of such training is the large effort needed to create such live training exercises (a large number of \u2018victim actors\u2019 needed, availability of infrastructure, etc.) and the lack of realistic treatments. Hence, such training or exercises are not executed very often and sometimes also fail to create \u201creal\u201d stressful and demanding environments. Virtual Reality (VR) has already been demonstrated in several domains to be a serious alternative, and in some areas also a significant improvement to conventional learning and training. Especially for the challenges in the training of MFRs, it can be highly useful for practising and learning domains where the context of the training is not easily available. VR training offers controlled, easy-to-create environments that can be created and trained repeatedly under the same conditions. This repetitionmakes it possible tomaster a new skill or process. Like in real-life training, trainees are transformed into active users who need to be physically and mentally engaged to evaluate the situation, take appropriate measures and act accordingly. There are two types of VR medical training systems realised up to date. Systems centred on teaching direct physical skills and procedures e.g. surgery (e.g. [7], [10], [14], [12]). Those usually employ highly sophisticated hardware user interfaces providing realistic haptic feedback or/and mimicking real devices. On the other end of the spectrum, there are VR systems helping the trainee to develop psychological skills required in real-world scenarios (e.g. [15], [11]) and in particular decision training. However, these approaches are currently rather disjunct and do not allow to train decision-making under stress together with physical skill scenarios. Also, other medical tasks or preclinical routines in patient care and treatment are not yet covered by haptic solutions. Training medical skills are about vision and haptics for tangible interaction, and if a simulation has only one of those two, it will provide only half of the experience.",
    "authors": [],
    "id": "SP:b62310c8e196d8da12f47a574263344d15b1f4fa",
    "references": [
        {
            "authors": [
                "Andrea F Abate",
                "Mariano Guida",
                "Paolo Leoncini",
                "Michele Nappi",
                "Stefano Ricciardi"
            ],
            "title": "A haptic-based approach to virtual training for aerospace industry",
            "venue": "Journal of Visual Languages & Computing 20,",
            "year": 2009
        },
        {
            "authors": [
                "Cyril Bossard",
                "Gilles Kermarrec",
                "C\u00e9dric Buche",
                "Jacques Tisseau"
            ],
            "title": "Transfer of learning in virtual environments: a new challenge",
            "venue": "Virtual Reality 12,",
            "year": 2008
        },
        {
            "authors": [
                "Meredith Carroll",
                "Mitchell Ruble",
                "MarkDranias",
                "Summer Rebensky",
                "Maria Chaparro",
                "Joanna Chiang",
                "BrentWinslow"
            ],
            "title": "Automatic detection of learner engagement using machine learning and wearable sensors",
            "venue": "Journal of Behavioral and Brain Science 10,",
            "year": 2020
        },
        {
            "authors": [
                "Jonathan Currie",
                "Raymond R Bond",
                "Paul McCullagh",
                "Pauline Black",
                "Dewar D Finlay",
                "Stephen Gallagher",
                "Peter Kearney",
                "Aaron Peace",
                "Danail Stoyanov",
                "Colin D Bicknell"
            ],
            "title": "Wearable technology-based metrics for predicting operator performance during cardiac catheterisation. International journal of computer assisted radiology and surgery",
            "year": 2019
        },
        {
            "authors": [
                "Marie Ottilie Frenkel",
                "Laura Giessing",
                "Sebastian Egger-Lampl",
                "Vana Hutter",
                "Raoul RD Oudejans",
                "Lisanne Kleygrewe",
                "Emma Jaspaert",
                "Henning Plessner"
            ],
            "title": "The impact of the COVID-19 pandemic on European police officers: Stress, demands, and coping resources",
            "venue": "Journal of Criminal justice",
            "year": 2021
        },
        {
            "authors": [
                "Andrzej Grabowski",
                "Jaros\u0142aw Jankowski"
            ],
            "title": "Virtual reality-based pilot training for underground coal miners",
            "venue": "Safety science",
            "year": 2015
        },
        {
            "authors": [
                "Cuan M Harrington",
                "Dara O Kavanagh",
                "John F Quinlan",
                "Donncha Ryan",
                "Patrick Dicker",
                "Dara O\u2019Keeffe",
                "Oscar Traynor",
                "Sean Tierney"
            ],
            "title": "Development and evaluation of a trauma decision-making simulator in Oculus virtual reality",
            "venue": "The American Journal of Surgery 215,",
            "year": 2018
        },
        {
            "authors": [
                "Hsiu-Mei Huang",
                "Ulrich Rauch",
                "Shu-Sheng Liaw"
            ],
            "title": "Investigating learners\u2019 attitudes toward virtual reality learning environments: Based on a constructivist approach",
            "venue": "Computers & Education 55,",
            "year": 2010
        },
        {
            "authors": [
                "Filip Jaskiewicz",
                "Krystyna Frydrysiak",
                "Katarzyna Starosta-G\u0142owinska",
                "Dariusz Timler"
            ],
            "title": "The applicability of virtual reality in cardiopulmonary resuscitation training \u2013 opinion of medical professionals and students",
            "venue": "Emergency Medical Service",
            "year": 2019
        },
        {
            "authors": [
                "Joshua Benjamin Kaplan",
                "Aaron L Bergman",
                "Michael Christopher",
                "Sarah Bowen",
                "Matthew Hunsinger"
            ],
            "title": "Role of resilience in mindfulness training for first responders",
            "venue": "Mindfulness 8,",
            "year": 2017
        },
        {
            "authors": [
                "Hannes G\u00f6tz Kenngott",
                "Anas Amin Preukschas",
                "MartinWagner",
                "Felix Nickel",
                "MichaelM\u00fcller",
                "Nadine Bellemann",
                "Christian Stock",
                "Markus Fangerau",
                "Boris Radeleff",
                "Hans-Ulrich Kauczor"
            ],
            "title": "Mobile, real-time, and point-of-care augmented reality is robust, accurate, and feasible: a prospective pilot study",
            "venue": "Surgical endoscopy 32,",
            "year": 2018
        },
        {
            "authors": [
                "Paul Milgram",
                "Haruo Takemura",
                "Akira Utsumi",
                "Fumio Kishino"
            ],
            "title": "Augmented reality: A class of displays on the reality-virtuality continuum",
            "venue": "In Telemanipulator and telepresence technologies,",
            "year": 1995
        },
        {
            "authors": [
                "Felix Nickel",
                "Julia A Brzoska",
                "Matthias Gondan",
                "Henriette M Rangnick",
                "Jackson Chu",
                "Hannes G Kenngott",
                "Georg R Linke",
                "Martina Kadmon",
                "Lars Fischer",
                "Beat P M\u00fcller-Stich"
            ],
            "title": "Virtual reality training versus blended learning of laparoscopic cholecystectomy: a randomized controlled trial with laparoscopic novices",
            "venue": "Medicine 94,",
            "year": 2015
        },
        {
            "authors": [
                "Federica Pallavicini",
                "Luca Argenton",
                "Nicola Toniazzi",
                "Luciana Aceti",
                "Fabrizia Mantovani"
            ],
            "title": "Virtual reality applications for stress management training in the military",
            "venue": "Aerospace medicine and human performance 87,",
            "year": 2016
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n30 1.\n13 12\n4v 1\n[ cs\n.C Y\n] 3\n0 Ja\nn 20\n23\nMED1stMR: Mixed Reality to Enhance the Training of Medical First\nResponders for Challenging Contexts\nHELMUT SCHROM-FEIERTAG, GEORG REGAL, and MARKUS MURTINGER, AIT Austrian Insti-\ntute of Technology, Vienna"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Mass-casualty incidents with a large number of injured persons caused by human-made or by natural disasters are increasing globally. In such situations, medical first responders (MFRs) need to perform diagnosis, basic life support, or other first aid to help stabilize victims and keep them alive to wait for the arrival of further support. Situational awareness and effective coping with acute stressors are essential [5] to enable first responders to take appropriate action that saves lives. Such tasks are particularly challenging for first responders, that lack the special training to act optimally in these situations. Increasingly severe consequences of natural disasters and terrorist threats will expand the occurrence probability of such stressful and demanding situations and require the development and deployment of innovative technological solutions adapted to the (cross-sectoral) needs of first responders.\nIn that context, the adage \u201cpractice makes perfect\u201d is well-fitting to situational training. Lectures, books, videos, etc. are no substitute for hands-on experiences, and humans often learn more from their mistakes than from their successes. Unfortunately, it is difficult to provide such training for large-scale emergency medicine or in dangerous conditions. Current training of medical first responders often happens through live exercises: medics practice stabilisation and wound care via moulage, a training exercise where live persons are given highly realistic \u201cfake\u201d wounds. The drawback of such training is the large effort needed to create such live training exercises (a large number of \u2018victim actors\u2019 needed, availability of infrastructure, etc.) and the lack of realistic treatments. Hence, such training or exercises are not executed very often and sometimes also fail to create \u201creal\u201d stressful and demanding environments.\nVirtual Reality (VR) has already been demonstrated in several domains to be a serious alternative, and in some areas also a significant improvement to conventional learning and training. Especially for the challenges in the training of MFRs, it can be highly useful for practising and learning domains where the context of the training is not easily available. VR training offers controlled, easy-to-create environments that can be created and trained repeatedly under the same conditions. This repetitionmakes it possible tomaster a new skill or process. Like in real-life training, trainees are transformed into active users who need to be physically and mentally engaged to evaluate the situation, take appropriate measures and act accordingly.\nThere are two types of VR medical training systems realised up to date. Systems centred on teaching direct physical skills and procedures e.g. surgery (e.g. [7], [10], [14], [12]). Those usually employ highly sophisticated hardware user interfaces providing realistic haptic feedback or/and mimicking real devices. On the other end of the spectrum, there are VR systems helping the trainee to develop psychological skills required in real-world scenarios (e.g. [15], [11]) and in particular decision training.\nHowever, these approaches are currently rather disjunct and do not allow to train decision-making under stress together with physical skill scenarios. Also, other medical tasks or preclinical routines in patient care and treatment are not yet covered by haptic solutions. Training medical skills are about vision and haptics for tangible interaction, and if a simulation has only one of those two, it will provide only half of the experience.\nAs an advanced alternative to VR, Mixed Reality (MR) environments have the potential to augment current VR training by providing a dynamic simulation of an environment and hands-on practice on injured victims.\nThere are several interpretations of MR, one is that the real environment is augmented by digital objects, another is that physical objects are integrated into the VR. In our vision, MR is to be considered as the latter interpretation with a fully digital environment, where the user sees a fully digital environment without looking at the real world, but this digital environment is connected to real physical objects. This VR-based mixed reality is also called augmented virtuality (AV) according to [13].\nBuilding on this interpretation of MR, the main aim of MED1stMR is to develop a new generation of MR training\nwith haptic feedback for enhanced realism. To this end, we will pursue the following pioneering concepts:"
        },
        {
            "heading": "2.1 Integration of high-fidelity patient simulation manikins for enhanced realism",
            "text": "Evidence shows that the use of VR is useful when the training domain is complex and difficult to master (cf. [9], [2]) and when the audio-visual features assisted by haptic feedback of the training environment are crucial to the overall training success (cf. [1]). This makes virtual environments the solution for practising and learning domains where the context of the training is not easily available or replicable due to security and safety issues (e.g. [6]). It allows creating easily a diverse range of training scenarios tailored to the training goals and needs (single user vs. teams, from single to many people injured in large incidents, influence of psychological and contextual factors).\nThrough the integration of high-fidelity patient simulationmanikins andmedical equipment into theMR experience, MED1stMR offers a much richer sensory experience. This MR training environment allows trainees to immerse into virtual scenarios and be able to feel and perceive actual movements of the limbs, head, and face through tactile and visual interaction as they are actuated. Furthermore, it enables systematic manipulation of a large set of potential influence factors in order to optimise training effects. This will bring virtual training closer to reality and enable both scenario training and medical training in the same MR training environment."
        },
        {
            "heading": "2.2 Biosignal feedback loop and smart scenario control to enhance effectiveness of MR training",
            "text": "The wireless integration of wearables in MR training environments is emerging (e.g., [8]) and particularly in the training of highly demanding skills such as piloting/aviation, medical surgeries (e.g., [4]) or first responders (e.g., [3]).\nIn order to better support, assist and personalise MFRs training, we will integrate wearable technology for monitoring trainees\u2019 physiological data. Smart electronic devices can detect and transmit information regarding biosignals, informing on trainees\u2019 physiological status. Monitoring these signals will provide the detection of physical and psychological strain and stress during training.\nThis will provide information for the debriefing sessions and can be used for real-time scenario control through the trainer (manual control) or automatically by the training system through artificial intelligence-based adaptive smart scenarios. The data on trainee state and behaviour can then be used to constitute a feedback loop for personalising and adapting training to the trainees\u2019 needs. Such a system can automatically adjust the scenarios according to the stress level of the trainee, for example, low stress increases the difficulty of the scenario and allows longer and more complex scenarios to be trained without the intervention of a trainer.\nThe development of such a training system for MFRs requires research, expertise, and knowledge in the areas of medical research, biosensors, and wearable technologies, human factors research, psychology, physiological research, technology experience, user research, VR/MR, andmedical training simulation development to answer all the questions that arise in order to develop an optimal training system for MFRs:\n\u2022 How can haptic feedback for training medical skills on victims be provided for MFRs? \u2022 Which scenarios and use cases are most suitable for MR training and deliver the greatest benefits? \u2022 How can effective MR training scenarios be developed? \u2022 How effective are such training approaches, how good is the learning progress and how does it compare to\nreal-world training?\n\u2022 How should a MR training curriculum be designed and merged with existing training curricula? \u2022 What about the costs for the training system and does the benefit justify the effort?"
        },
        {
            "heading": "4 OUR CONTRIBUTION TO THEWORKSHOP",
            "text": "MED1stMR develop a MR training system based on a combination of VR environment and the integration of VRenabled manikins. With this new training environment, MED1stMRdelivers a training platform for collaborativemultiuser training to train themedical skills ofMFRs aswell the decision-making abilities in disaster situations. In the project, the training is designed for teams of up to four people to enable emergency teams to train together. The technological basis is the Refense trainings platform (www.refense.com) that allows up to 10 users on an area of 11 x 20 meters to immerse themselves into a realistic common shared scenario, see each other in real time with full-body VR tracking. A trainer can also be included as an invisible observer in the training. Every movement and voice spoken are recorded for debriefing of team collaboration and actions taken. The inclusion of manikins as tangible objects as learning support provides a more realistic experience and enables novel possibilities for hands-on tasks. The basis will build the ADAMX manikin (https://medical-x.com/product/adam-x/) and will be advanced to a fully functional touch-enabled human manikin designed for practising skills in trauma emergency situation.\nThe goal of the MED1stMR training solution is to train the situation awareness and the procedure in the first and second triage. The realisation of a biosignal feedback loop with body sensors allows to monitor trainee (stress, anxiety, etc.) states and behaviours of MFRs during training and will make this data available for scenario control. For this purpose, heart rate variability is measured as one of the most reliable indicators of stress. The trainer can adapt training to the personal needs of trainees and provides a new way of interaction between trainer and trainee and requires an appropriate user interface for support.\nA key point in MED1stMR is to examine the effectiveness of training for the different roles. To increase the effectiveness of the training, the simple repetition of the training scenarios as well as the recording of all movements, activities and communication during the training for the debriefing play an important role. The presentation of our project is intended to provide an insight into our approach and to open up an exchange of experiences with other people, projects, research, and developments and also to get an impression of how the topics are received, what others are doing in this field and where further and interesting research topics lie in this area.\nWe can contribute existing knowledge to the workshop and discuss with the other participants\u2019 challenges and help\nto set up a future research agenda for collaborative multi-user VR training.\nThe project MED1stMR has received funding from the European Union\u2019s Horizon 2020 Research and Innovation Programme under grant agreement No 101021775. The content reflects only the MED1stMR consortium\u2019s view. Research Executive Agency and European Commission is not liable for any use that may be made of the information contained herein."
        }
    ],
    "year": 2023
}