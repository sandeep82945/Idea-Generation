{
    "abstractText": "1. National Institute for Health and Care Excellence (NICE), UK; 2. Zorginstituut Nederland (National 10 Health Care Institute), The Netherlands; 3. Syreon Research Institute, Hungary; 4. University of 11 Oulu, Finland; 5. The London School of Economics and Political Science, UK; 6. University of 12 Birmingham, UK; 7. EURORDIS \u2013 Rare Diseases Europe, Belgium; 8. Tandv\u00e5rds-och 13 l\u00e4kemedelsf rm\u00e5nsverket (The Dental and Pharmaceutical Benefits Agency), Sweden; 9. University 14 College London, UK; 10. Utrecht University, Netherlands; 11. University of Oxford, UK; 12. Cairo 15 University, Egypt. 16",
    "authors": [
        {
            "affiliations": [],
            "name": "Claire Hawksworth"
        },
        {
            "affiliations": [],
            "name": "Jamie Elvidge"
        },
        {
            "affiliations": [],
            "name": "Saskia Knies"
        },
        {
            "affiliations": [],
            "name": "Antal Zemplenyi"
        },
        {
            "affiliations": [],
            "name": "Zsuzsanna Petyk\u00f3"
        },
        {
            "affiliations": [],
            "name": "Gunjan Chandra"
        },
        {
            "affiliations": [],
            "name": "Divya Srivastava"
        },
        {
            "affiliations": [],
            "name": "Alastair Denniston"
        },
        {
            "affiliations": [],
            "name": "Anastasia Chalkidou"
        },
        {
            "affiliations": [],
            "name": "Petros Nousios"
        },
        {
            "affiliations": [],
            "name": "Manuel Gomes"
        },
        {
            "affiliations": [],
            "name": "Tuba Saygin Avsar"
        },
        {
            "affiliations": [],
            "name": "Junfeng Wang"
        },
        {
            "affiliations": [],
            "name": "Stavros Petrou"
        },
        {
            "affiliations": [],
            "name": "Dalia Dawoud"
        }
    ],
    "id": "SP:3148e795282d5a9c2652a9bb1a5827806d73f3a1",
    "references": [
        {
            "authors": [
                "M. Miller"
            ],
            "title": "FDA Publishes Approved List of AI/ML-enabled Medical Devices [Internet",
            "venue": "IQVIA 276 Blog",
            "year": 2021
        },
        {
            "authors": [
                "J Vamathevan",
                "D Clark",
                "P Czodrowski",
                "I Dunham",
                "E Ferran",
                "G Lee"
            ],
            "title": "Applications of 280 machine learning in drug discovery and development",
            "year": 2019
        },
        {
            "authors": [
                "X Liu",
                "S Cruz Rivera",
                "D Moher",
                "M Calvert",
                "AK Denniston",
                "T Spirit-ai"
            ],
            "title": "Reporting 282 guidelines for clinical trial reports for interventions involving artificial intelligence: the 283 CONSORT-AI extension",
            "venue": "Nat Med",
            "year": 2020
        },
        {
            "authors": [
                "SC Rivera",
                "X Liu",
                "AW Chan",
                "AK Denniston",
                "MJ. Calvert"
            ],
            "title": "Guidelines for clinical trial protocols 285 for interventions involving artificial intelligence: The SPIRIT-AI Extension",
            "venue": "BMJ. 2020;370:1\u2013",
            "year": 2020
        },
        {
            "authors": [
                "H Unsworth",
                "B Dillon",
                "L Collinson",
                "H Powell",
                "M Salmon",
                "T Oladapo"
            ],
            "title": "The NICE Evidence 288 Standards Framework for digital health and care technologies \u2013 Developing and maintaining 289 an innovative evidence framework with global impact",
            "venue": "Digit Heal. 2021;7:1\u201320",
            "year": 2021
        },
        {
            "authors": [
                "H C. Excellence NI for"
            ],
            "title": "Evidence standards framework (ESF) for digital health 291 technologies [Internet",
            "venue": "National Institute for Health and Care Excellence",
            "year": 2022
        },
        {
            "authors": [
                "D Husereau",
                "M Drummond",
                "S Petrou",
                "C Carswell",
                "D Moher",
                "D Greenberg"
            ],
            "title": "Consolidated 294 Health Economic Evaluation Reporting Standards (CHEERS) statement. BMJ",
            "year": 2013
        },
        {
            "authors": [
                "D Husereau",
                "M Drummond",
                "F Augustovski",
                "E De Bekker-Grob",
                "AH Briggs",
                "C Carswell"
            ],
            "title": "Consolidated Health Economic Evaluation Reporting Standards 2022 (CHEERS 2022) 298 statement: Updated reporting guidance for health economic evaluations. BMJ",
            "year": 2022
        },
        {
            "authors": [
                "C Hawksworth",
                "J Elvidge",
                "D. Dawoud"
            ],
            "title": "CHEERS-AI \u2013 Consolidated Health",
            "venue": "EQUATOR",
            "year": 2023
        },
        {
            "authors": [
                "AM Manyara",
                "P Davies",
                "D Stewart",
                "CJ Weir",
                "A Young",
                "NJ Butcher"
            ],
            "title": "Protocol for the 309 development of SPIRIT and CONSORT extensions for randomised controlled trials with 310 surrogate primary endpoints: SPIRIT-SURROGATE and CONSORT-SURROGATE",
            "venue": "BMJ",
            "year": 2022
        },
        {
            "authors": [
                "MM Voets",
                "J Veltman",
                "CH Slump",
                "S Siesling",
                "H. Koffijberg"
            ],
            "title": "Systematic Review of Health 313 Economic Evaluations Focused on Artificial Intelligence in Healthcare: The Tortoise and the 314 Cheetah",
            "venue": "Value Heal",
            "year": 2022
        },
        {
            "authors": [
                "D Barrett",
                "R. Heale"
            ],
            "title": "What are Delphi studies",
            "venue": "Evid Based Nurs",
            "year": 2020
        },
        {
            "authors": [
                "S. Chuenjitwongsa"
            ],
            "title": "How to conduct a Delphi study",
            "venue": "Wales deanary [Internet]",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "1 of 13\nProtocol for the development of an artificial intelligence 1 extension to the Consolidated Health Economic Evaluation 2 Reporting Standards (CHEERS) 2022 3\n1. Manuscript details 4\n1.1. Authors 5\nClaire Hawksworth1, Jamie Elvidge1, Saskia Knies2, Antal Zemplenyi3, Zsuzsanna Petyk\u00f33, Pekka 6 Siirtola4, Gunjan Chandra4, Divya Srivastava5, Alastair Denniston6, Anastasia Chalkidou1, Julien 7 Delaye7, Petros Nousios8, Manuel Gomes9, Tuba Saygin Avsar1, Junfeng Wang10, Stavros Petrou11, 8 Dalia Dawoud1,12 9\n1. National Institute for Health and Care Excellence (NICE), UK; 2. Zorginstituut Nederland (National 10 Health Care Institute), The Netherlands; 3. Syreon Research Institute, Hungary; 4. University of 11 Oulu, Finland; 5. The London School of Economics and Political Science, UK; 6. University of 12 Birmingham, UK; 7. EURORDIS \u2013 Rare Diseases Europe, Belgium; 8. Tandv\u00e5rds-och 13 l\u00e4kemedelsf rm\u00e5nsverket (The Dental and Pharmaceutical Benefits Agency), Sweden; 9. University 14 College London, UK; 10. Utrecht University, Netherlands; 11. University of Oxford, UK; 12. Cairo 15 University, Egypt. 16"
        },
        {
            "heading": "1.2. Abstract 17",
            "text": "Introduction: AI interventions for health care are on the rise. Decisions about coverage and 18 reimbursement are often informed by Health Technology Assessment (HTA) bodies, who rely on 19 Health Economic Evaluations (HEEs) to estimate the value for money (cost effectiveness) of 20 interventions. Transparent reporting of HEEs ensures they can be used for decision making. 21 Reporting guidance exists to support this, such as the Consolidated Health Economic Reporting 22 Standards (CHEERS) checklist. We aim to identify consensus about specific items should be 23 reported by HEEs that evaluate AI interventions and, if such items are identified, to develop them 24 into an extension to CHEERS: \u201cCHEERS-AI\u201d. 25\nMethods and analysis: The project will have 4 phases: 26\n\u2022 Phase 1 is a literature review to help identify potential AI-related reporting items. 27\n\u2022 Phase 2 commences a Delphi process, with a series of surveys to elicit the importance of the 28 potential AI-related reporting items. 29\n\u2022 Phase 3 is a consensus-generation meeting to agree on the final extension items. 30\nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n2 of 13\n\u2022 Phase 4 is dissemination of the project\u2019s outputs. 31\nEthics and dissemination: This study has received ethical approval from Newcastle University 32 Ethics Committee (reference: 28568/2022). The findings will be available in as an open access 33 article and disseminated through blogs, newsletters, and presentations. 34"
        },
        {
            "heading": "1.3. Funding statement 35",
            "text": "This study is supported by the Next Generation Health Technology Assessment (HTx) project. The 36 HTx project has received funding from the European Union\u2019s Horizon 2020 research and innovation 37 programme under grant agreement N\u00ba 825162. This dissemination reflects only the views of the 38 authors and the Commission is not responsible for any use that may be made of the information it 39 contains. 40\n3 of 13"
        },
        {
            "heading": "2. Introduction 41",
            "text": "In recent times there has been a rapid increase in the development of technologies with an artificial 42 intelligence (AI) component for health care interventions. This is evidenced in the number of 43 approvals given by regulatory bodies. Between 1997 and 2021, the Food and Drug Administration in 44 the United States approved 350 AI technologies with 91% of them approved since 2015 (1). In 45 2021, the European Medicines Agency (EMA) led a report on behalf of the International Coalition of 46 Medicines Regulatory Authorities documenting a horizon scanning exercise in AI and highlighting 47 regulatory challenges (2). This was in response to these new technologies increasingly challenging 48 regulatory frameworks and a need for recommendations on how to adapt them. 49\nAI is a broad term to encompass iterative, \u2018learning\u2019 algorithms that use data and high computing 50 power to make interpretations, predictions or decisions (2). Some AI technologies are fixed, and 51 others are adaptive. Various subsets of AI, such as machine learning (ML), are being used 52 throughout the drug discovery process for target validation, identification of biomarkers, and 53 analysis of clinical trial data (3). As well as assisting with the drug development process, AI is also 54 featuring in the end product, and it is these health technologies that are the focus of this paper. 55 Examples of AI health interventions include systems for screening and triage, diagnosis, prognosis, 56 decision support, and treatment recommendation (4,5). 57\nTo ensure their appropriate use in healthcare pathways, we need to understand what benefits new 58 AI technologies bring, and at what cost. There are established methods to do this for 59 pharmacological and diagnostic interventions, but AI algorithms may be distinct from more 60 traditional interventions in numerous challenging ways. Firstly, they have the potential to learn over 61 time, meaning the relationship between intervention and outcome may not be fixed. This has 62 implications when considering future benefits, such as choosing a suitable method or assumption 63 for long-term treatment outcomes. We often see an assumption that the treatment effect of a 64 medicine wanes over time, but how might healthcare decision makers appropriately value on an AI 65 intervention that might get more effective over time? Secondly, the user is most often a health care 66 professional rather than a patient, and the degree to which the clinician employs the results of the AI 67 intervention may vary, particularly when its purpose is a decision-support tool. Thirdly, trial data 68 normally underpin a health technology assessment (HTA) and reimbursement decisions. However, 69 to date, AI technologies have not typically been subjected to interventional trials, meaning various 70 data sources or assumptions will be required to inform a value assessment. Although randomised 71 controlled trials (RCTs) are increasingly being conducted to evaluate the clinical efficacy of 72 interventions with an AI component, there are concerns relating to their design and reporting. To try 73 to address these concerns, AI extensions to reporting checklists have been developed; for example, 74 for protocols (SPIRIT-AI) (5) and trials (CONSORT-AI) (4). 75\n4 of 13\nIn addition, the ways in which AI-based intervention are developed arguably create an extra, 76 inherent layer of uncertainty. Their function and attainment depend on the data sets used to train 77 and validate their underlying algorithms. This development, or learning, step precedes any study of 78 efficacy relative to the standard of care, which tends to be the primary source of potential 79 uncertainty for more traditional interventions. 80\nHealth economic evaluations (HEEs) assessing the cost effectiveness of health interventions are 81 often used by HTA bodies to make their reimbursement recommendations. HTA bodies will 82 increasingly be expected to assess the value of health technologies that use AI. For example, the 83 National Institute of Health and Care Excellence (NICE) in the UK recently updated their Evidence 84 Standards Framework to reflect and include adaptive AI and data-driven technologies (6,7). The 85 usefulness of a published HEE to decision makers depends on how well it is conducted and 86 reported. Reporting guidelines can improve their transparency and completeness. A prominent HEE 87 reporting checklist is the Consolidated Health Economic Evaluation Reporting Standards (CHEERS) 88 statement. It was originally published in 2013 to help authors accurately report details of the HEE, 89 including the health intervention, what was being compared and in what context, how the evaluation 90 was undertaken, and what the findings were (8). This checklist outlined minimum reporting 91 standards and the increased transparency allows decision-makers such as HTA bodies and payers 92 to judge the quality and appropriateness of the HEE for their decision problem, facilitating trust in 93 the results. The CHEERS statement was updated in 2022 (9) and now comprises a 28-item 94 checklist including methodological approach, data identification, model inputs, assumptions, 95 uncertainty analysis, and conflicts of interest. 96\nCHEERS 2022 does not include any reporting items that are specific to potential AI components of 97 an intervention, but the authors of CHEERS 2022 explicitly \u201cencourage those who see opportunities 98 to expand CHEERS 2022 items or create additional reporting guidance that provides clarification in 99 specific areas to work with members of the CHEERS Task Force to develop CHEERS extensions in 100 these areas\u201d. As noted above, extensions for AI health interventions have already been developed 101 for other checklists, demonstrating a system wide need and motivation for improving best practice 102 around data collection and transparency. Including AI-specific items in the reporting of HEEs is a 103 logical step to contribute to this standard setting for AI interventions. It will help to ensures that all 104 relevant information required for decision-making is available to decision-makers. 105\n5 of 13\n3. Methods 106\nOur research approach was guided by the EQUATOR (Enhancing the QUAlity and Transparency Of 107 health Research) Network\u2019s recommended steps for developing a health research reporting 108 guideline (10) and methods used to develop other related extensions (CHEERS 2022, CONSORT-109 AI and SPIRIT-AI). The guideline extension is registered on the EQUATOR Network website (11). 110 The structure and writing of this protocol were guided by the recently published protocol for the 111 SPIRIT-SURROGATE and CONSORT-SURROGATE extensions (12). 112\nA project management group led by NICE is organising and conducting the project with oversight 113 from a Steering Group. The Steering Group is a multi-disciplinary and international group with 114 representation from University of Oulu, Finland; Zorginstituut Nederland (National Health Care 115 Institute) and Utrecht University, the Netherlands; Syreon Research Institute, Hungary; Tandv\u00e5rds-116 och l\u00e4kemedelsf rm\u00e5nsverket (The Dental and Pharmaceutical Benefits Agency), Sweden; and 117 The London School of Economics and Political Science, the University of Birmingham, University 118 College London and University of Oxford, UK. The Steering Group includes a representative from 119 the CHEERS Task Force to provide expert input. The Steering Group was formed in December 120 2022. 121\nThis study has been supported by Next Generation Health Technology Assessment (HTx), which is 122 a Horizon 2020 project supported by the European Union, lasting for 5 years from January 2019. Its 123 main aim is to create a framework for the next generation of HTA to support patient-centred, 124 societally oriented, real-time decision making on access to and reimbursement for health 125 technologies throughout Europe. 126\n5.1. Phase 1: Systematic literature review 127\nWe conducted a systematic literature review in the summer of 2022 to assess the methodological 128 and reporting quality of HEEs of AI-based technologies. This updated a previously published review 129 by Voets et al (13). Our search was performed on 17th June 2022 and found 21 HEE studies 130 published in the preceding 15 months. This review was used to identify potential AI-extension items. 131 Members of the Steering Group were also able to contribute potential AI-extension items, based on 132 their knowledge and experience of AI, HEE, and reporting guideline development. This led to a 133 \u2018long-list\u2019 of potential items for an AI extension to CHEERS 2022. The review and Steering Group 134 also helped to identify subject matter experts who could participate in the Delphi study. This group 135 are referred to as the Expert Panel (EP). 136\n6 of 13\n5.2. Phase 2: Consensus-generation surveys (Delphi process) 137\nThis phase will involve participants rating long-list candidate items generated in phase 1 and 138 suggesting additional items not included in the long-list. There will also be the opportunity to revise 139 wording for the items. Proposed timelines are to open the first survey round in May 2023 to coincide 140 with the ISPOR 2023 conference in Boston, US. The consensus process will dictate the number of 141 necessary survey rounds, but it is anticipated that the whole project will complete in during 2023. 142\n5.2.1. Survey design and setting 143\nThis methodology follows that used for the development of CHEERS 2022 (9). CHEERS 2022 144 employed a modified Delphi process. Delphi is a widely recognised and used method for 145 consensus-building and revolves around the following key steps: identification of factors, 146 anonymous surveys among subject matter experts to elicit importance, integration and controlled 147 feedback and presentation of aggregated data at consensus meetings (14). The survey will be 148 developed in Snap Surveys software. 149\nWe will conduct a minimum of 2 survey rounds and will consider additional rounds if necessary. This 150 approach has been taken for other guideline extensions (4,5,9,12). 151\n5.2.2. Sample size, recruitment, and inclusion criteria 152\nWe will recruit an EP representing the following key stakeholder groups: health economists, AI 153 methodologists and academics, industry, policy makers, HTA experts, ethicists, patient 154 representatives, journal editors, healthcare professionals, payers, and research funders. This is 155 consistent with the EQUATOR Network\u2019s guidance (10) and groups who participated in related 156 extension. We anticipate inviting over 100 EP members. 157\nOur approach to recruit EP members involves a multi-faceted approach. The Steering Group will 158 identify participants. This purposive sampling will utilise a snowball sampling method where invited 159 participants will be allowed to invite additional participants, meaning the total number of survey 160 recipients should far exceed the those identified by the Steering Group. The survey will elicit the 161 profession of the recipient to ensure that all respondents are part of one or more of the key 162 stakeholder groups. We will also approach relevant professional groups such as the ISPOR 163 Machine Learning Task Force. We will utilise authors identified in the phase 1 as another source of 164 potential participants and will coordinate completions of the survey with the ISPOR conference, 165 taking place in May 2023 in Boston, US. All EP members will be sent an introductory email and 166 participant information sheet. 167\n7 of 13\nWe will collect descriptive demographic data at the start of the survey, including stakeholder group, 168 country of work and years of relevant experience to indicate understanding of AI in healthcare and 169 HEE. Inclusion criteria are the key stakeholder groups previously specified. There are no exclusion 170 criteria, but this targeted recruitment should result in identification of suitable EP members. 171\nThere is guidance on the minimum number of survey responses to allow statistical rigour, with 30 172 commonly cited (15). By identifying and inviting over 100 experts to participate, we will allow 173 sufficient headroom for non-response and attrition between survey rounds. 174\n5.2.3. Data collection, analysis, and consensus definition 175\nThe survey will be developed in consultation with the Steering Group, including a pilot prior to the 176 launch to ensure usability. All participants will be sent a link to the survey which will start with study 177 information and a tick box for consent. The first survey will be open for a 3-week window, 178 commencing May 2023. The second survey will be sent approximately 4 weeks after closure of the 179 first. Response rates will be monitored during the survey window and email reminders sent to 180 participants to increase response rates. Records will be kept of the number approached, and non-181 responses. 182\nThe EP will be asked to vote on the relevance of candidate items when reporting a HEE of an AI-183 based intervention. They will be asked to use a 9-point Likert rating scale, consistent with CHEERS 184 2022 and other reporting extensions. A \u2018don\u2019t know\u2019 option will also be available for each item, in 185 case a participant feels unable to provide a rating. Potential items will be grouped according to 186 standard sections of HEEs (e.g., title, abstract, methods, discussion), and each item will have an 187 accompanying definition and rationale for inclusion. We will employ the consensus definition used 188 for CHEERS 2022 (see Figure 1). After survey round 1, any items that were scored lower than 7 by 189 at least 70% of respondents will be excluded; that is, we will conclude that consensus has been 190 reached that those items are not relevant reporting standards for HEEs of AI interventions. Those 191 items will be \u2018rejected\u2019 and will not proceed to survey round 2 in their original form. Participants will 192 have the opportunity to comment on the wording and propose new items. If suitable revised wording 193 of original items has been proposed, then revised items may be included in survey round 2. 194\n8 of 13\n195\nResults from survey round 1 will be analysed in MS Excel to identify the mean scores and measure 196 of agreement (proportion of scores 7 or higher). After excluding those meeting the exclusion 197 threshold, the remaining items will be included in survey round 2. They will be presented in order of 198 mean score and the measure of agreement will also be shown. Respondents will have the 199 opportunity to consider their round 1 answers in light of the aggregate results and justify any 200 revisions. Any new items that were suggested by respondents in survey one will also be voted on in 201 the second survey round, along with proposed changes such a new wording or merging of items 202 from free-text responses. 203\nAfter survey round 2, results will be analysed in MS Excel, and items with a mean score of 4 or less 204 will be categorised as \u2018rejected\u2019 (consensus reached). Items with mean scores of 7 or higher will be 205 grouped as \u2018included\u2019 (consensus reached). Items with mean scores above 4 but less than 7 will be 206 grouped as \u2018possible\u2019 (consensus not reached). Any such items will proceed to survey round 3, 207 presented in order of importance (mean score), alongside a measure of agreement (proportion of 208 scores 7 or higher). After this final survey round, items with a mean score of 5 or less will be 209 \u2018rejected\u2019 (consensus reached). Items with a mean score above 5 will be \u2018included\u2019 (consensus 210 reached). Therefore, consensus will be achieved for all items after survey round 3, unless 211\n9 of 13\nparticipants provide substantial and conflicting free-text responses about the wording, or additional 212 items. Any such items will proceed to a consensus meeting for resolution. 213\n5.3. Phase 3: Consensus-generation meeting (Delphi process) 214\nA consensus meeting will be held virtually, with the aim of concluding the final extension list. We will 215 invite a purposive sample representative of the EP who completed every survey round. The 216 EQUATOR Network has guidance on conducting face to face consensus meetings (10). 217\n5.3.1. Structure and participants 218\nThe COVID-19 pandemic has normalised virtual working and we propose to hold the meeting 219 virtually. This is also advantageous in terms of maximising engagement and attendance from a 220 range of geographical locations. The meeting length will be agreed after survey round 3, at which 221 point the number of items that still haven\u2019t achieved consensus (and therefore require extensive 222 discussion) will be known. However, the meeting time will be sufficient to allow discussion time for 223 all items. Other extensions have used meetings over two days (4,5,12). 224\nAt the end of survey round 2, participants will be invited to register their interest in attending the 225 consensus meeting. The Steering Group will purposively select members from this pool considering 226 the need to have an international multidisciplinary group of participants. 227\n5.3.2. Consensus procedure 228\nAttendees at the meeting will ratify all items about which consensus was reached during the first 2 229 survey rounds. Items that proceeded to survey round 3 will be discussed more comprehensively at 230 the meeting. Minor modifications to wording can be included by a simple 50% majority vote during 231 the meeting. 232\nThe richest discussion will be for any items where consensus has not yet been reached by the end 233 of the survey round 3. These will be any new items that were proposed in free-text responses during 234 survey round 3, and any items that received extensive requests for modification in free-text 235 responses (e.g., merging items), such that a simple 50% majority vote at the meeting would not be 236 appropriate to support inclusion. For these significant modifications, a 70% majority vote during the 237 meeting will be required to include the modified or new items. 238\nItems that do not reach consensus (e.g., due to a large proportion of \u2018don\u2019t know\u2019 or abstained 239 votes) will be discussed further and voted on again, if appropriate, until consensus is reached or 240 time runs out. The Steering Group will make final decisions soon after the consensus meeting on 241 any outstanding items without consensus. 242\n10 of 13\nThe consensus meeting will be recorded to ensure accurate recall, and minutes will be taken. 243\n5.4. Phase 4: Knowledge translation 244\nThis phase includes all activities aiming to publish and publicise the extension. This objective will be 245 integrated and considered throughout all stages of the project. 246\n5.4.1. Pilot testing and revision of final checklist 247\nAfter the meeting we will conduct a pilot of the finalised extension with invited researchers to check 248 clarity of wording and identify any challenges. These will be people whom we invited but were 249 unable to join our Steering Group or who expressed an interest to join after survey round 1 had 250 started. This exercise will inform writing of the explanation and elaboration documents. 251\n5.4.2. Publications 252\nWe aim to publish the CHEERS-AI extension in a high impact open access journal to maximise 253 dissemination. We will also utilise the ISPOR CHEERS Task Force to help publicise the extension. 254 We will seek the endorsement of the extension from journals and editorial groups. 255\n5.4.3. Partner and stakeholder engagement 256\nThe project is registered on the EQUATOR website. We aim to have the final extension published 257 on the CHEERS website. The CHEERS statement is endorsed by ISPOR. 258\n5.4.4. Patient and public involvement 259\nWe have patient advocacy on the Steering Group led by EURORDIS (Rare Diseases Europe). They 260 will ensure views and perspectives of patients and the public are represented at all stages. Patients 261 and the public are also one of our key stakeholder groups to be represented on the Expert Panel 262 and therefore will be involved in consensus building for the final checklist. EURORDIS and the NICE 263 lead for patient and public involvement will be requested to advise on dissemination activities. 264\n5.4.5. Ethics and dissemination 265\nAn ethics application was submitted via the NICE ethical approval process. Ethics approval was 266 received from Newcastle University Ethics Committee who are the awarding body (reference: 267 28568/2022). 268\nExpert Panel members will be provided with a participant information sheet and will be asked to 269 provide consent before completing the first survey. We will also obtain electronic written consent 270 before the consensus meeting for participation and recording of the meeting. Participants will have a 271 right to withdraw at any stage of the project. All data will be securely stored although we anticipate 272\n11 of 13\nthat it will not be highly sensitive. We will ask participants if they prefer to opt out of 273 acknowledgement in any publications. 274\n12 of 13\n4. References 275\n1. Miller M. FDA Publishes Approved List of AI/ML-enabled Medical Devices [Internet]. IQVIA 276 Blog. 2021 [cited 2023 May 9]. Available from: https://www.iqvia.com/locations/united-277 states/blogs/2021/10/fda-publishes-approved-list-of-ai-ml-enabled-medical-devices 278\n2. ICMRA. Horizon Scanning Assessment Report - Artificial Intelligence. 2021. 1\u201337 p. 279\n3. Vamathevan J, Clark D, Czodrowski P, Dunham I, Ferran E, Lee G, et al. Applications of 280 machine learning in drug discovery and development. Vol. 18. 2019. 463\u2013477 p. 281\n4. Liu X, Cruz Rivera S, Moher D, Calvert M, Denniston AK, Spirit-ai T, et al. Reporting 282 guidelines for clinical trial reports for interventions involving artificial intelligence: the 283 CONSORT-AI extension. Nat Med. 2020;26(September):1364\u201374. 284\n5. Rivera SC, Liu X, Chan AW, Denniston AK, Calvert MJ. Guidelines for clinical trial protocols 285 for interventions involving artificial intelligence: The SPIRIT-AI Extension. BMJ. 2020;370:1\u2013286 14. 287\n6. Unsworth H, Dillon B, Collinson L, Powell H, Salmon M, Oladapo T, et al. The NICE Evidence 288 Standards Framework for digital health and care technologies \u2013 Developing and maintaining 289 an innovative evidence framework with global impact. Digit Heal. 2021;7:1\u201320. 290\n7. Excellence NI for H and C. Evidence standards framework (ESF) for digital health 291 technologies [Internet]. National Institute for Health and Care Excellence. 2022 [cited 2023 292 May 9]. Available from: https://www.nice.org.uk/corporate/ecd7 293\n8. Husereau D, Drummond M, Petrou S, Carswell C, Moher D, Greenberg D, et al. Consolidated 294 Health Economic Evaluation Reporting Standards (CHEERS) statement. BMJ. 295 2013;346(March):1\u20136. 296\n9. Husereau D, Drummond M, Augustovski F, De Bekker-Grob E, Briggs AH, Carswell C, et al. 297 Consolidated Health Economic Evaluation Reporting Standards 2022 (CHEERS 2022) 298 statement: Updated reporting guidance for health economic evaluations. BMJ. 299 2022;376(Cheers):1\u20137. 300\n10. Medicine U of OC for S in. EQUATOR Network toolkit for developing a reporting guideline 301 [Internet]. EQUATOR Network. 2018. Available from: https://www.equator-302 network.org/toolkits/developing-a-reporting-guideline/ 303\n11. Hawksworth C, Elvidge J, Dawoud D. CHEERS-AI \u2013 Consolidated Health Economic 304\n13 of 13\nEvaluation Reporting Standards Artificial Intelligence Extension [Internet]. EQUATOR 305 Network. 2023. Available from: https://www.equator-network.org/library/reporting-guidelines-306 under-development/reporting-guidelines-under-development-for-other-study-307 designs/#CHEERS-AI 308\n12. Manyara AM, Davies P, Stewart D, Weir CJ, Young A, Butcher NJ, et al. Protocol for the 309 development of SPIRIT and CONSORT extensions for randomised controlled trials with 310 surrogate primary endpoints: SPIRIT-SURROGATE and CONSORT-SURROGATE. BMJ 311 Open. 2022;12(10):1\u20138. 312\n13. Voets MM, Veltman J, Slump CH, Siesling S, Koffijberg H. Systematic Review of Health 313 Economic Evaluations Focused on Artificial Intelligence in Healthcare: The Tortoise and the 314 Cheetah. Value Heal. 2022;25(3):340\u20139. 315\n14. Barrett D, Heale R. What are Delphi studies? Evid Based Nurs. 2020;23(3):68\u20139. 316\n15. Chuenjitwongsa S. How to conduct a Delphi study. Wales deanary [Internet]. 317 2017;27(1173):639\u201343. Available from: 318 https://meded.walesdeanery.org/sites/default/files/how_to_conduct_a_delphistudy.pdf 319"
        }
    ],
    "title": "Protocol for the development of an artificial intelligence extension to the Consolidated Health Economic Evaluation Reporting Standards (CHEERS) 2022",
    "year": 2023
}