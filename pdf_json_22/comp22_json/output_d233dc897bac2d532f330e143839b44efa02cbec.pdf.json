{
    "abstractText": "In unsupervised domain adaptation (UDA), directly adapting from the source to the target domain usually suffers significant discrepancies and leads to insufficient alignment. Thus, many UDA works attempt to vanish the domain gap gradually and softly via various intermediate spaces, dubbed domain bridging (DB). However, for dense prediction tasks such as domain adaptive semantic segmentation (DASS), existing solutions have mostly relied on rough style transfer and how to elegantly bridge domains is still under-explored. In this work, we resort to data mixing to establish a deliberated domain bridging (DDB) for DASS, through which the joint distributions of source and target domains are aligned and interacted with each in the intermediate space. At the heart of DDB lies a dual-path domain bridging step for generating two intermediate domains using the coarse-wise and the fine-wise data mixing techniques, alongside a cross-path knowledge distillation step for taking two complementary models trained on generated intermediate samples as \u2018teachers\u2019 to develop a superior \u2018student\u2019 in a multi-teacher distillation manner. These two optimization steps work in an alternating way and reinforce each other to give rise to DDB with strong adaptation power. Extensive experiments on adaptive segmentation tasks with different settings demonstrate that our DDB significantly outperforms state-of-the-art methods. Code is available at https: //github.com/xiaoachen98/DDB.git.",
    "authors": [
        {
            "affiliations": [],
            "name": "Lin Chen"
        },
        {
            "affiliations": [],
            "name": "Zhixiang Wei"
        },
        {
            "affiliations": [],
            "name": "Xin Jin"
        },
        {
            "affiliations": [],
            "name": "Huaian Chen"
        },
        {
            "affiliations": [],
            "name": "Miao Zheng"
        },
        {
            "affiliations": [],
            "name": "Kai Chen"
        },
        {
            "affiliations": [],
            "name": "Yi Jin"
        }
    ],
    "id": "SP:b7e5bf614b1c62ad11de47c427c77e8bee11e040",
    "references": [
        {
            "authors": [
                "N. Araslanov",
                "S. Roth"
            ],
            "title": "Self-supervised augmentation consistency for adapting semantic segmentation",
            "venue": "CVPR, pages 15384\u201315394",
            "year": 2021
        },
        {
            "authors": [
                "S. Ben-David",
                "J. Blitzer",
                "K. Crammer",
                "F. Pereira"
            ],
            "title": "Analysis of representations for domain adaptation",
            "venue": "NeurIPS, 19",
            "year": 2006
        },
        {
            "authors": [
                "L. Chen",
                "H. Chen",
                "Z. Wei",
                "X. Jin",
                "X. Tan",
                "Y. Jin",
                "E. Chen"
            ],
            "title": "Reusing the task-specific classifier as a discriminator: Discriminator-free adversarial domain adaptation",
            "venue": "CVPR, pages 7181\u20137190",
            "year": 2022
        },
        {
            "authors": [
                "L.-C. Chen",
                "G. Papandreou",
                "I. Kokkinos",
                "K. Murphy",
                "A.L. Yuille"
            ],
            "title": "Deeplab: Semantic image segmentation with deep convolutional nets",
            "venue": "atrous convolution, and fully connected crfs. TPAMI, 40(4):834\u2013 848",
            "year": 2017
        },
        {
            "authors": [
                "S. Chen",
                "X. Jia",
                "J. He",
                "Y. Shi",
                "J. Liu"
            ],
            "title": "Semi-supervised domain adaptation based on dual-level domain mixing for semantic segmentation",
            "venue": "CVPR, pages 11018\u201311027",
            "year": 2021
        },
        {
            "authors": [
                "Y.-C. Chen",
                "Y.-Y. Lin",
                "M.-H. Yang",
                "J.-B. Huang"
            ],
            "title": "Crdoco: Pixel-level domain transfer with cross-domain consistency",
            "venue": "CVPR, pages 1791\u20131800",
            "year": 2019
        },
        {
            "authors": [
                "J. Choi",
                "T. Kim",
                "C. Kim"
            ],
            "title": "Self-ensembling with gan-based data augmentation for domain adaptation in semantic segmentation",
            "venue": "ICCV, pages 6830\u20136840",
            "year": 2019
        },
        {
            "authors": [
                "M. Contributors"
            ],
            "title": "MMSegmentation: Openmmlab semantic segmentation toolbox and benchmark",
            "venue": "https: //github.com/open-mmlab/mmsegmentation",
            "year": 2020
        },
        {
            "authors": [
                "M. Cordts",
                "M. Omran",
                "S. Ramos",
                "T. Rehfeld",
                "M. Enzweiler",
                "R. Benenson",
                "U. Franke",
                "S. Roth",
                "B. Schiele"
            ],
            "title": "The cityscapes dataset for semantic urban scene understanding",
            "venue": "CVPR, pages 3213\u20133223",
            "year": 2016
        },
        {
            "authors": [
                "S. Cui",
                "S. Wang",
                "J. Zhuo",
                "L. Li",
                "Q. Huang",
                "Q. Tian"
            ],
            "title": "Towards discriminability and diversity: Batch nuclear-norm maximization under label insufficient situations",
            "venue": "CVPR, pages 3941\u20133950",
            "year": 2020
        },
        {
            "authors": [
                "S. Cui",
                "S. Wang",
                "J. Zhuo",
                "C. Su",
                "Q. Huang",
                "Q. Tian"
            ],
            "title": "Gradually vanishing bridge for adversarial domain adaptation",
            "venue": "CVPR, pages 12455\u201312464",
            "year": 2020
        },
        {
            "authors": [
                "Y. Dai",
                "J. Liu",
                "Y. Sun",
                "Z. Tong",
                "C. Zhang",
                "L.-Y. Duan"
            ],
            "title": "Idm: An intermediate domain module for domain adaptive person re-id",
            "venue": "ICCV, pages 11864\u201311874",
            "year": 2021
        },
        {
            "authors": [
                "J. Deng",
                "W. Dong",
                "R. Socher",
                "L.-J. Li",
                "K. Li",
                "L. Fei-Fei"
            ],
            "title": "Imagenet: A large-scale hierarchical image database",
            "venue": "CVPR, pages 248\u2013255",
            "year": 2009
        },
        {
            "authors": [
                "G. French",
                "A. Oliver",
                "T. Salimans"
            ],
            "title": "Milking cowmask for semi-supervised image classification",
            "venue": "arXiv",
            "year": 2020
        },
        {
            "authors": [
                "Y. Ganin",
                "E. Ustinova",
                "H. Ajakan",
                "P. Germain",
                "H. Larochelle",
                "F. Laviolette",
                "M. Marchand",
                "V. Lempitsky"
            ],
            "title": "Domain-adversarial training of neural networks",
            "venue": "JMLR, pages 2096\u20132030",
            "year": 2016
        },
        {
            "authors": [
                "R. Gong",
                "W. Li",
                "Y. Chen",
                "L.V. Gool"
            ],
            "title": "Dlow: Domain flow for adaptation and generalization",
            "venue": "CVPR, pages 2477\u20132486",
            "year": 2019
        },
        {
            "authors": [
                "J. Gou",
                "B. Yu",
                "S.J. Maybank",
                "D. Tao"
            ],
            "title": "Knowledge distillation: A survey",
            "venue": "IJCV, 129(6):1789\u20131819",
            "year": 2021
        },
        {
            "authors": [
                "E. Harris",
                "A. Marcu",
                "M. Painter",
                "M. Niranjan",
                "A. Pr\u00fcgel-Bennett",
                "J. Hare"
            ],
            "title": "Fmix: Enhancing mixed sample data augmentation",
            "venue": "ICLR",
            "year": 2021
        },
        {
            "authors": [
                "J. He",
                "X. Jia",
                "S. Chen",
                "J. Liu"
            ],
            "title": "Multi-source domain adaptation with collaborative learning for semantic segmentation",
            "venue": "CVPR, pages 11008\u201311017",
            "year": 2021
        },
        {
            "authors": [
                "K. He",
                "X. Zhang",
                "S. Ren",
                "J. Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "CVPR, pages 770\u2013778",
            "year": 2016
        },
        {
            "authors": [
                "G. Hinton",
                "O. Vinyals",
                "J. Dean"
            ],
            "title": "et al",
            "venue": "Distilling the knowledge in a neural network. arXiv, 2(7)",
            "year": 2015
        },
        {
            "authors": [
                "J. Hoffman",
                "E. Tzeng",
                "T. Park",
                "J.-Y. Zhu",
                "P. Isola",
                "K. Saenko",
                "A. Efros",
                "T. Darrell"
            ],
            "title": "Cycada: Cycleconsistent adversarial domain adaptation",
            "venue": "ICML, pages 1989\u20131998",
            "year": 2018
        },
        {
            "authors": [
                "J. Hoffman",
                "D. Wang",
                "F. Yu",
                "T. Darrell"
            ],
            "title": "Fcns in the wild: Pixel-level adversarial and constraint-based adaptation",
            "venue": "arXiv",
            "year": 2016
        },
        {
            "authors": [
                "L. Hoyer",
                "D. Dai",
                "L. Van Gool"
            ],
            "title": "Daformer: Improving network architectures and training strategies for domain-adaptive semantic segmentation",
            "venue": "CVPR",
            "year": 2022
        },
        {
            "authors": [
                "T. Isobe",
                "X. Jia",
                "S. Chen",
                "J. He",
                "Y. Shi",
                "J. Liu",
                "H. Lu",
                "S. Wang"
            ],
            "title": "Multi-target domain adaptation with collaborative consistency learning",
            "venue": "CVPR, pages 8187\u20138196",
            "year": 2021
        },
        {
            "authors": [
                "S. Lee",
                "W. Choi",
                "C. Kim",
                "M. Choi",
                "S. Im"
            ],
            "title": "Adas: A direct adaptation strategy for multi-target domain adaptive semantic segmentation",
            "venue": "CVPR",
            "year": 2022
        },
        {
            "authors": [
                "M. Li",
                "Y.-M. Zhai",
                "Y.-W. Luo",
                "P.-F. Ge",
                "C.-X. Ren"
            ],
            "title": "Enhanced transport distance for unsupervised domain adaptation",
            "venue": "CVPR, pages 13936\u201313944",
            "year": 2020
        },
        {
            "authors": [
                "R. Li",
                "S. Li",
                "C. He",
                "Y. Zhang",
                "X. Jia",
                "L. Zhang"
            ],
            "title": "Class-balanced pixel-level self-labeling for domain adaptive semantic segmentation",
            "venue": "CVPR",
            "year": 2022
        },
        {
            "authors": [
                "S. Li",
                "C.H. Liu",
                "Q. Lin",
                "Q. Wen",
                "L. Su",
                "G. Huang",
                "Z. Ding"
            ],
            "title": "Deep residual correction network for partial domain adaptation",
            "venue": "TPAMI, 43(7):2329\u20132344",
            "year": 2020
        },
        {
            "authors": [
                "S. Li",
                "F. Lv",
                "B. Xie",
                "C.H. Liu",
                "J. Liang",
                "C. Qin"
            ],
            "title": "Bi-classifier determinacy maximization for unsupervised domain adaptation",
            "venue": "AAAI",
            "year": 2021
        },
        {
            "authors": [
                "Y. Li",
                "L. Yuan",
                "N. Vasconcelos"
            ],
            "title": "Bidirectional learning for domain adaptation of semantic segmentation",
            "venue": "CVPR, pages 6936\u20136945",
            "year": 2019
        },
        {
            "authors": [
                "Y. Liu",
                "J. Deng",
                "J. Tao",
                "T. Chu",
                "L. Duan",
                "W. Li"
            ],
            "title": "Undoing the damage of label shift for cross-domain semantic segmentation",
            "venue": "CVPR",
            "year": 2022
        },
        {
            "authors": [
                "M. Long",
                "Y. Cao",
                "J. Wang",
                "M. Jordan"
            ],
            "title": "Learning transferable features with deep adaptation networks",
            "venue": "ICML, pages 97\u2013105",
            "year": 2015
        },
        {
            "authors": [
                "M. Long",
                "Z. Cao",
                "J. Wang",
                "M.I. Jordan"
            ],
            "title": "Conditional adversarial domain adaptation",
            "venue": "NeurIPS, volume 31",
            "year": 2018
        },
        {
            "authors": [
                "M. Long",
                "H. Zhu",
                "J. Wang",
                "M.I. Jordan"
            ],
            "title": "Deep transfer learning with joint adaptation networks",
            "venue": "ICML, pages 2208\u20132217. PMLR",
            "year": 2017
        },
        {
            "authors": [
                "I. Loshchilov",
                "F. Hutter"
            ],
            "title": "Decoupled weight decay regularization",
            "venue": "arXiv",
            "year": 2017
        },
        {
            "authors": [
                "Y. Luo",
                "L. Zheng",
                "T. Guan",
                "J. Yu",
                "Y. Yang"
            ],
            "title": "Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation",
            "venue": "CVPR, pages 2507\u20132516",
            "year": 2019
        },
        {
            "authors": [
                "H. Ma",
                "X. Lin",
                "Z. Wu",
                "Y. Yu"
            ],
            "title": "Coarse-to-fine domain adaptive semantic segmentation with photometric alignment and category-center regularization",
            "venue": "CVPR, pages 4051\u20134060",
            "year": 2021
        },
        {
            "authors": [
                "L. McInnes",
                "J. Healy",
                "J. Melville"
            ],
            "title": "Umap: Uniform manifold approximation and projection for dimension reduction",
            "venue": "arXiv",
            "year": 2018
        },
        {
            "authors": [
                "K. Mei",
                "C. Zhu",
                "J. Zou",
                "S. Zhang"
            ],
            "title": "Instance adaptive self-training for unsupervised domain adaptation",
            "venue": "ECCV, pages 415\u2013430",
            "year": 2020
        },
        {
            "authors": [
                "J. Na",
                "H. Jung",
                "H.J. Chang",
                "W. Hwang"
            ],
            "title": "Fixbi: Bridging domain spaces for unsupervised domain adaptation",
            "venue": "CVPR, pages 1094\u20131103",
            "year": 2021
        },
        {
            "authors": [
                "G. Neuhold",
                "T. Ollmann",
                "S. Rota Bulo",
                "P. Kontschieder"
            ],
            "title": "The mapillary vistas dataset for semantic understanding of street scenes",
            "venue": "ICCV, pages 4990\u20134999",
            "year": 2017
        },
        {
            "authors": [
                "V. Olsson",
                "W. Tranheden",
                "J. Pinto",
                "L. Svensson"
            ],
            "title": "Classmix: Segmentation-based data augmentation for semi-supervised learning",
            "venue": "WACV, pages 1369\u20131378",
            "year": 2021
        },
        {
            "authors": [
                "S.J. Pan",
                "I.W. Tsang",
                "J.T. Kwok",
                "Q. Yang"
            ],
            "title": "Domain adaptation via transfer component analysis",
            "venue": "TNNLS, 22(2):199\u2013210",
            "year": 2010
        },
        {
            "authors": [
                "S.J. Pan",
                "Q. Yang"
            ],
            "title": "A survey on transfer learning",
            "venue": "TNNLS, 22(10):1345\u20131359",
            "year": 2009
        },
        {
            "authors": [
                "Y. Pan",
                "T. Yao",
                "Y. Li",
                "Y. Wang",
                "C.-W. Ngo",
                "T. Mei"
            ],
            "title": "Transferrable prototypical networks for unsupervised domain adaptation",
            "venue": "CVPR, pages 2239\u20132247",
            "year": 2019
        },
        {
            "authors": [
                "E. Reinhard",
                "M. Adhikhmin",
                "B. Gooch",
                "P. Shirley"
            ],
            "title": "Color transfer between images",
            "venue": "IEEE Computer graphics and applications, 21(5):34\u201341",
            "year": 2001
        },
        {
            "authors": [
                "S.R. Richter",
                "V. Vineet",
                "S. Roth",
                "V. Koltun"
            ],
            "title": "Playing for data: Ground truth from computer games",
            "venue": "ECCV, pages 102\u2013118",
            "year": 2016
        },
        {
            "authors": [
                "K. Saito",
                "K. Watanabe",
                "Y. Ushiku",
                "T. Harada"
            ],
            "title": "Maximum classifier discrepancy for unsupervised domain adaptation",
            "venue": "CVPR, pages 3723\u20133732",
            "year": 2018
        },
        {
            "authors": [
                "W. Tranheden",
                "V. Olsson",
                "J. Pinto",
                "L. Svensson"
            ],
            "title": "Dacs: Domain adaptation via cross-domain mixed sampling",
            "venue": "WACV, pages 1379\u20131389",
            "year": 2021
        },
        {
            "authors": [
                "Y.-H. Tsai",
                "W.-C. Hung",
                "S. Schulter",
                "K. Sohn",
                "M.-H. Yang",
                "M. Chandraker"
            ],
            "title": "Learning to adapt structured output space for semantic segmentation",
            "venue": "CVPR, pages 7472\u20137481",
            "year": 2018
        },
        {
            "authors": [
                "T.-H. Vu",
                "H. Jain",
                "M. Bucher",
                "M. Cord",
                "P. P\u00e9rez"
            ],
            "title": "Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation",
            "venue": "CVPR, pages 2517\u20132526",
            "year": 2019
        },
        {
            "authors": [
                "H. Wang",
                "T. Shen",
                "W. Zhang",
                "L.-Y. Duan",
                "T. Mei"
            ],
            "title": "Classes matter: A fine-grained adversarial approach to cross-domain semantic segmentation",
            "venue": "ECCV, pages 642\u2013659",
            "year": 2020
        },
        {
            "authors": [
                "G. Wei",
                "C. Lan",
                "W. Zeng",
                "Z. Chen"
            ],
            "title": "Metaalign: Coordinating domain alignment and classification for unsupervised domain adaptation",
            "venue": "CVPR, pages 16643\u201316653",
            "year": 2021
        },
        {
            "authors": [
                "G. Wilson",
                "D.J. Cook"
            ],
            "title": "A survey of unsupervised deep domain adaptation",
            "venue": "ACM Transactions on Intelligent Systems and Technology (TIST), 11(5):1\u201346",
            "year": 2020
        },
        {
            "authors": [
                "M. Wrenninge",
                "J. Unger"
            ],
            "title": "Synscapes: A photorealistic synthetic dataset for street scene parsing",
            "venue": "arXiv",
            "year": 2018
        },
        {
            "authors": [
                "Y. Wu",
                "D. Inkpen",
                "A. El-Roby"
            ],
            "title": "Dual mixup regularized learning for adversarial domain adaptation",
            "venue": "ECCV, pages 540\u2013555",
            "year": 2020
        },
        {
            "authors": [
                "N. Xiao",
                "L. Zhang"
            ],
            "title": "Dynamic weighted learning for unsupervised domain adaptation",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15242\u201315251",
            "year": 2021
        },
        {
            "authors": [
                "E. Xie",
                "W. Wang",
                "Z. Yu",
                "A. Anandkumar",
                "J.M. Alvarez",
                "P. Luo"
            ],
            "title": "Segformer: Simple and efficient design for semantic segmentation with transformers",
            "venue": "NeurIPS, 34",
            "year": 2021
        },
        {
            "authors": [
                "M. Xu",
                "J. Zhang",
                "B. Ni",
                "T. Li",
                "C. Wang",
                "Q. Tian",
                "W. Zhang"
            ],
            "title": "Adversarial domain adaptation with domain mixup",
            "venue": "AAAI, volume 34, pages 6502\u20136509",
            "year": 2020
        },
        {
            "authors": [
                "Y. Yang",
                "S. Soatto"
            ],
            "title": "Fda: Fourier domain adaptation for semantic segmentation",
            "venue": "CVPR, pages 4085\u20134095",
            "year": 2020
        },
        {
            "authors": [
                "S. Yun",
                "D. Han",
                "S.J. Oh",
                "S. Chun",
                "J. Choe",
                "Y. Yoo"
            ],
            "title": "Cutmix: Regularization strategy to train strong classifiers with localizable features",
            "venue": "ICCV, pages 6023\u20136032",
            "year": 2019
        },
        {
            "authors": [
                "H. Zhang",
                "M. Cisse",
                "Y.N. Dauphin",
                "D. Lopez-Paz"
            ],
            "title": "mixup: Beyond empirical risk minimization",
            "venue": "ICLR",
            "year": 2018
        },
        {
            "authors": [
                "P. Zhang",
                "B. Zhang",
                "T. Zhang",
                "D. Chen",
                "Y. Wang",
                "F. Wen"
            ],
            "title": "Prototypical pseudo label denoising and target structure learning for domain adaptive semantic segmentation",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12414\u201312424",
            "year": 2021
        },
        {
            "authors": [
                "Q. Zhang",
                "J. Zhang",
                "W. Liu",
                "D. Tao"
            ],
            "title": "Category anchor-guided unsupervised domain adaptation for semantic segmentation",
            "venue": "NeurIPS, 32",
            "year": 2019
        },
        {
            "authors": [
                "Y. Zhang",
                "T. Liu",
                "M. Long",
                "M. Jordan"
            ],
            "title": "Bridging theory and algorithm for domain adaptation",
            "venue": "ICML, pages 7404\u20137413. PMLR",
            "year": 2019
        },
        {
            "authors": [
                "H. Zhao",
                "S. Zhang",
                "G. Wu",
                "J.M. Moura",
                "J.P. Costeira",
                "G.J. Gordon"
            ],
            "title": "Adversarial multiple source domain adaptation",
            "venue": "NeurIPS, 31",
            "year": 2018
        },
        {
            "authors": [
                "S. Zhao",
                "B. Li",
                "X. Yue",
                "Y. Gu",
                "P. Xu",
                "R. Hu",
                "H. Chai",
                "K. Keutzer"
            ],
            "title": "Multi-source domain adaptation for semantic segmentation",
            "venue": "NeurIPS, 32",
            "year": 2019
        },
        {
            "authors": [
                "S. Zhao",
                "X. Yue",
                "S. Zhang",
                "B. Li",
                "H. Zhao",
                "B. Wu",
                "R. Krishna",
                "J.E. Gonzalez",
                "A.L. Sangiovanni- Vincentelli",
                "S.A. Seshia"
            ],
            "title": "et al",
            "venue": "A review of single-source deep unsupervised visual domain adaptation. TNNLS",
            "year": 2020
        },
        {
            "authors": [
                "Z. Zheng",
                "Y. Yang"
            ],
            "title": "Rectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation",
            "venue": "IJCV, pages 1106\u20131120",
            "year": 2021
        },
        {
            "authors": [
                "Q. Zhou",
                "Z. Feng",
                "Q. Gu",
                "J. Pang",
                "G. Cheng",
                "X. Lu",
                "J. Shi",
                "L. Ma"
            ],
            "title": "Context-aware mixup for domain adaptive semantic segmentation",
            "venue": "arXiv",
            "year": 2021
        },
        {
            "authors": [
                "J.-Y. Zhu",
                "T. Park",
                "P. Isola",
                "A.A. Efros"
            ],
            "title": "Unpaired image-to-image translation using cycle-consistent adversarial networks",
            "venue": "ICCV, pages 2223\u20132232",
            "year": 2017
        },
        {
            "authors": [
                "Y. Zou",
                "Z. Yu",
                "X. Liu",
                "B. Kumar",
                "J. Wang"
            ],
            "title": "Confidence regularized self-training",
            "venue": "ICCV, pages 5982\u20135991",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "When training deep models on one domain but applying it to other unseen domains, its performance typically drops seriously due to the domain shift/discrepancy issue [45, 44, 69, 55]. Since annotating data in the new scenario to re-train model to mitigate performance degradation is too expensive and time consuming, extensive researches have resorted to unsupervised domain adaptation (UDA) [41, 15, 34, 3], which aims to transfer knowledge from labeled source domain to unlabeled target domain.\nGenerally, existing UDA methods typically reduce the domain discrepancy by leveraging information statistics metrics [10, 27, 29, 33, 35, 46, 66] or adversarial training [15, 30, 34, 49, 54, 58, 3]. Both of these branches directly adapt the knowledge learned from the source domain to the target domain. However, excessive/continuous domain discrepancies tend to limit the efficiency of these methods for knowledge transfer, causing non-optimal performance, especially on dense prediction tasks such as semantic segmentation.\n\u2217Equal contribution. \u2020Correspoding author.\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\nar X\niv :2\n20 9.\n07 69\n5v 3\n[ cs\n.C V\n] 1\n1 O\nct 2\nTo address this issue, some recent approaches tend to mitigate the excessive domain discrepancies by gradually transferring knowledge across domains by constructing intermediate domains in the input space [41, 60, 61], feature space [11, 12], or output space (self-training based) [64, 65]. Such mechanism of constructing intermediate domain is usually termed as domain bridging (DB). Despite unprecedented advances achieved in UDA classification task, the most common DB approaches, such as CycleGAN [72] and ColorTransfer [47] that based on style transfer, are inapplicable and cannot achieve satisfactory adaptation performance for the domain adaptive semantic segmentation (DASS). These style transfer-based DB approaches are prone to generate unexpected artifacts in the global input space and also ignore to bridge in the label space, which makes the optimization constraints insufficient for the dense prediction tasks such as DASS [16, 22, 67, 68, 71]. Therefore, such dilemma drives an urgent demand to investigate a new DB method for the densely predicted DASS area.\nIn this paper, to consistently construct intermediate representations in the input space as well as the label space for domain bridging in DASS, we resort to the mix-based data augmentation techniques[63, 62, 18, 14, 43]. First, we study the existing data mix methods and group them into two categories according to their working way: global interpolation [63] and local replacement [62, 18, 14, 43, 71]. As shown in Fig. 1, the global interpolation based data mix may cause the pixel-wise ambiguity issue, but the local replacement based mix methods can better preserve the semantic integrity/consistency of objects for segmentation. Next, to fully exploit the local replacement based data mix for domain bridging, we further deeply explore it from two complementary perspectives: the coarse region-level mix (e.g., CutMix [62], FMix [18]) and the fine class-level mix (e.g., ClassMix [43]). We can also see from Fig. 1 that the coarse region-level domain bridging helps the model to exploit contextual information, reducing semantics confusion (e.g., category confusion between objects such as \u2018truck, bus, and train\u2019). Complementarily, the fine class-level domain bridging enables the model to fully exploit the inherent properties of each category, making each object distinguishable. However, these two groups of DB methods tend to drive the model to be overly dependent on contextual information or inherent properties, causing class bias and confusion in the target domain separately.\nIn this work, we propose a powerful DASS method called Deliberated Domain Bridging (DDB) to carefully take advantage of data mixing techniques and gradually transfer knowledge from the source domain to the target domain. As an optimization strategy, DDB consists of two alternating steps, i.e., Dual-Path Domain Bridging (DPDB) and Cross-path Knowledge Distillation (CKD). In the first step, DPDB independently leverages the coarse region-level data mix and fine class-level data mix to construct two complementary bridging paths to train two expert teacher models, achieving dual-granularity domain bridging. In the second step, CKD uses two complementary teacher models to guide one identical student model on the target domain, achieving adaptive segmentation. These two optimization steps work in an alternating way, which allows the powerful teacher and student models to reinforce each other progressively based on the joint distributions of source and target domains. The main contributions of this paper are summarized as follows:\n\u2022 To the best of our knowledge, this is the first work that provides a comprehensive analysis w.r.t the recent domain bridging techniques when directly applied to the task of domain-adaptive semantic segmentation (DASS).\n\u2022 Based on the analysis, we propose an effective DASS method called Deliberated Domain Bridging (DDB), which consists of two alternating steps \u2013 Dual-path Domain Bridging (DPDB) and Cross-path Knowledge Distillation (CKD). These two optimization steps promote each other and progressively encourage two complementary teacher models and a superior student model (used for inference), achieving a win-win effect. \u2022 We experimentally validate the superiority of our DDB not only in the single-source domain setting but also in the multi-source and multi-target domain settings and conclude that DDB outperforms previous methods tailored for each setting by a large margin."
        },
        {
            "heading": "2 Related Work",
            "text": "Domain Adaptive Semantic Segmentation (DASS). This task aims to improve the adaptation performance for the semantic segmentation model to avoid laborious pixel-wise annotation in new target scenarios. The recent DASS works can be mainly grouped into two categories: adversarial training based methods [23, 51\u201353, 37] and self-training based methods [24, 73, 70, 64, 65]. For the first branch, most works tend to learn domain-invariant representations based on a min-max adversarial optimization game, where a feature extractor is trained to fool a domain discriminator and thus helps to obtain aligned feature distributions [51\u201353, 37]. The second branch focuses on how to generate highly reliable pseudo labels for the target domain data for further model optimization, which drives many classic related techniques, such as confidence regularized pseudo label generation [73, 70] and category-aware pseudo label rectification [64, 65]. These two branches of the DASS task both directly adapt the knowledge learned from the source domain to the target domain. However, the large continuous domain discrepancies in DASS make such direct discrepancy minimization paradigms difficult, due to the fine-grained pixel-wise gap among different domains.\nDomain Bridging (DB). Instead of directly transferring knowledge from the source domain to the target domain, some UDA works in the tasks of classification and person re-identification tend to gradually transfer knowledge by building a bridge between source and target domains, i.e., constructing an intermediate domain on the image level [57, 41], on the feature level [11, 12], or on the output level [64, 65]. Representatively, GVB [11] designs a gradually vanishing bridge and inserts it into the task-specific classifier and the domain discriminator to construct intermediate domaininvariant representations, reducing the knowledge transfer difficulty. Along this road, some works [57, 60, 41, 12, 5, 50] resort to style transfer techniques [6, 22, 7, 16] and data mix techniques [63, 62, 43] for constructing various intermediate domains. However, the existing DB approaches have not yet been extensively investigated in DASS. In this paper, we first perform a comprehensive analysis w.r.t the recent DB techniques and find the complementarity between the coarse region-level DB and the fine class-level DB methods, then deliberately/carefully apply these two DB methods to help the task of DASS."
        },
        {
            "heading": "3 Deliberated Domain Bridging",
            "text": ""
        },
        {
            "heading": "3.1 Recap of Preliminary Knowledge",
            "text": "For domain adaptive semantic segmentation (DASS), we denote the source domain as Ds = {(x(i)s , y(i)s )}N s i=1 with N s samples drawn from the source domain S, where x(i)s \u2208 Xs is an image, y(i)s \u2208 Ys is the corresponding pixel-wise one-hot label covering K classes. Similarly, the unlabeled target domain set is denoted as Dt = {x(i)t }N t i=1 with N t samples drawn from the target domain T . Note that the source and target domains share the same label space. This work aims to learn a segmentation model for effectively transferring knowledge from the source domain to the target domain, finally achieving reliable pixel-wise predictions on the target data. Following previous works [64, 65], this segmentation model M consists of a feature extractor that maps the image to the feature space and a classifier that generates corresponding pixel-wise predictions."
        },
        {
            "heading": "3.2 Exploring Domain Bridging for DASS",
            "text": "Revisiting Existing DB Methods. As mentioned in Sec. 2, the previous DB methods are mainly based on style transfer [72, 47], global interpolation based mix [63], and local replacement based mix [62, 18, 14, 43, 71]. Formally, the image-level style transfer-based DB methods can be formulated\nas, xs\u2192t = h (xs) , xt\u2192s = h\n\u2032 (xt) , (1) where h (\u00b7) and h\u2032 (\u00b7) represent the S \u2192 T translation function and T \u2192 S translation function, respectively. Such style transfer-based DB approaches tend to generate unexpected artifacts at the image level and also ignore the influence of pixel-wise label correspondence.\nIn addition, we formalize the global interpolation mix based DB methods as,\nxnew = \u03bb \u00b7 xs + (1\u2212 \u03bb) \u00b7 xt ynew = \u03bb \u00b7 ys + (1\u2212 \u03bb) \u00b7 yt, (2)\nwhere \u03bb denotes the mixing ratio sampled from a beta distribution. Furthermore, the local replacement mix based DB methods are formulated as,\nxnew = M xs + (1\u2212M) xt ynew = M ys + (1\u2212M) yt, (3)\nwhere M denotes a binary mask indicating which pixel needs to be copied from the source domain and pasted to the target domain, 1 is a mask filled with ones, and represents the element-wise multiplication operation. yt represents the pseudo label for target domain. In particular, this local replacement DB contains two types of coarse region-level mix and fine class-level mix. As shown in Fig. 1(b), the binary mask M of the former is the cut patch [62, 18, 14] while M of the latter is obtained from the pixel-wise annotations in source domain [43].\nAnalyzing DB Methods with Toy Game. From the above formalization, we can see that the global interpolation-based and local replacement-based DB methods both build bridges across the crossdomain joint distributions of input data, which can benefit the densely predicted DASS task. To verify this, we perform a toy game with a simple self-training based DASS pipeline following [50, 24] to evaluate the performance w.r.t semantic segmentation of different DB methods. As illustrated in Tab. 1 (a) and (b), although style transfer based and global interpolation based DB methods both outperform baseline (i.e., the source only scheme), they are pronouncedly inferior to their local replacement-based counterparts. This implies that for the DASS task, (1) it not only needs to construct an intermediate domain on the input space, but also the label space; (2) the local replacement based DB methods are more suitable for segmentation because they can better preserve the semantic integrity/consistency for pixels belonging to the same object.\nIn addition, Tab. 1 (b) shows that the performance of coarse region-level CutMix [62] and fine class-level ClassMix [43] are comparable. Thus, we further conduct a group of tests by combining different DB methods for a deeper study. The results are shown in Tab. 1 (c), we can observe that (1) due to the unexpected artifacts, the segmentation performance is degraded when region-level DB methods are combined with style transfer ones; (2) we surprisingly notice that the coarse region-level and fine class-level domain bridging methods can mutually reinforce/promote each other.\nAnalyzing the Local Replacement Based DB Methods with Visualization. For the coarse regionlevel data mix methods (e.g., CutMix [62]), those pixels (i.e., a patch) pasted to the target domain\nusually have a rich contextual information. For example, the pixel beneath a \u2018person\u2019 must belong to the \u2018sidewalk\u2019. However, the area beneath a \u2019person\u2019 is more likely to be \u2019road\u2019 in the target domain. Thus, such excessive hard reliance on context may introduce the issue of class bias from the source domain to the target domain, e.g., \u2018road\u2019 and \u2018sidewalk\u2019 in Fig. 2 (c). In contrast, the fine class-level bridging method (e.g., ClassMix [43]) only pastes a set of pixels belonging to the same class to the target domain image, avoiding class bias issue, which also drives the model to discriminate different objects solely based on their inherent properties, leading to a more compact feature distribution in Fig. 2 (d). But, the scheme that only relies on the characteristics of each category may be confused by the classes that can easily be distinguished by the context, e.g., \u2018train\u2019 and \u2018bus\u2019 in Fig. 2 (d). All in all, both coarse-grained and fine-grained DB methods have their own advantages and drawbacks, and thus there is an urgent need to find a appropriate way to combine them to achieve a win-win effect."
        },
        {
            "heading": "3.3 Progressively learning from Dual-grained Domain Bridging",
            "text": "Instead of directly combining individual DB methods as did in the bottom of Tab. 1(c), we propose an alternating optimization strategy to progressively transfer knowledge from the source domain to the target domain, which consists of two steps, i.e., Dual-Path Domain Bridging (DPDB) and Cross-path Knowledge Distillation (CKD). These two steps are conducted iteratively, and the ending of each round will serve as the beginning for the next round (see detailed algorithm in supplemental material).\nDual-Path Domain Bridging (DPDB). To better preserve and exploit the advantages of the coarse region-level and fine class-level DB methods, we create bridging paths for them independently rather than simply fusing them. Based on previous analysis and experiments, we utilize the cross-domain CutMix [62] and ClassMix [43] techniques to construct the coarse region-path (CRP) and fine classpath (FCP) domain bridging, respectively. The self-training pipeline then proceeds in the following manner along each path (here we take the coarse region-path (CRP) as an example for illustration):\nFollowing [2], to minimize the empirical risk on the unlabeled target domain, we simultaneously minimize the empirical risk on the source domain and mitigate the domain discrepancy. The first item is achieved with a pixel-wise cross-entropy (CE) loss,\nLCsrc = \u2212 H\u00d7W\u2211 i=1 K\u2211 j=1 y(i,j)s logMC(xs) (i,j) , (4)\nwhere MC is the model training on the coarse region-path and H,W denote the sample height and width, respectively. To mitigate the domain discrepancy, we minimize the CE loss on the constructed bridging path instead of adversarial training or minimize the predefined discrepancy metric. Considering the fact that the unlabeled target domain images are involved in the bridging path construction, an additional teacher network M \u2032C is employed to generate a denoised pixel-wise pseudo-label y\u0302t for xt through the exponential moving average (EMA) based on the weights of MC after each training step t,\n\u03b8t+1M \u2032C \u2190 \u03b1\u03b8tM \u2032C + (1\u2212 \u03b1) \u03b8 t MC , (5)\nwhere \u03b1 denotes the momentum and is set to 0.99. Based on Eqn. 3, we can generate the bridging image xcrp and label y\u0302crp on the coarse region-path. In line with [50, 43], a confidence-based weight\nmap mcrp will be generated to regularize the target domain during the training process as follows,\nmcrp = M 1 + (1\u2212M) mt, (6)\nwhere mt = \u2211H\u00d7W i=1 [maxj\u2032M \u2032 C(xt) (i,j\u2032)>\u03c4 ]\nH\u00b7W denotes the ratio of pixels that exceed a threshold \u03c4 on the maximum softmax probability and [\u00b7] represents the Iverson bracket. Then, we minimize the CE loss on the region-path bridging,\nLCbrg = \u2212 H\u00d7W\u2211 i=1 K\u2211 j=1 m(i,j)crp y\u0302 (i,j) crp logMC(xcrp) (i,j) . (7)\nFurthermore, the overall objective function of the self-training pipeline on the region-path bridging is summarized as,\nLC = LCsrc + LCbrg = Lce (MC (xs) , ys) + Lce (MC (xcrp) ,mcrp y\u0302crp) . (8)\nSimilarly, we can obtain the overall objective function LF on the fine class-path (FCP) bridging. By minimizing LC and LF separately for the coarse region-path and fine class-path, we can obtain two complementary models. The next problem that needs to be addressed is how to appropriately integrate these two kinds of complementary knowledge in an elegant manner.\nCross-path Knowledge Distillation (CKD). Inspired by previous works [17, 21], knowledge can be transferred from a teacher network to a student network by knowledge distillation in the output space. Here, we reform it to extract knowledge from two complementary teachers and adaptively transfer the integrated knowledge to a student. Note that we only integrate and transfer the complementary knowledge in the unlabeled target domain. Specifically, the outputs of two teachers have been adaptively weighted and ensembled as guidance to drive the student model to learn segmentation in the unlabeled target domain. Furthermore, we experimentally choose the \u2018hard\u2019 distillation, i.e., ensembling the predicted softmax logits to generate a one-hot vector and utilizing the CE loss for supervising the student model MS . The detailed distillation loss can be written as,\nLdistill = Lce (MS (xaugt ) , y\u0304t) , (9)\nwhere xaugt represents the target images augmented by color jitter and gaussian blur, and y\u0304t is obtained by weighted ensembling on the teachers\u2019 softmax logits of the target image xt. Intuitively, different samples, even different pixels in one sample, require different contributions from the two teacher models for ensembling. We adaptively generate a pixel-wise weight map w(i,j) in the target domain by calculating the distance pixel-by-pixel between feature response f (i) before the classification layer and the centroid \u03b7(j) of each category. At each location, the closer the feature response is far from one centroid of certain category, the more likely it belongs to that category and thus should contribute more to the ensemble effect. Therefore, taking the coarse region-path (CRP) as an example, we first utilize the trained MC to calculate the centroid \u03b7 (j) C of each category in the target domain,\n\u03b7 (j) C =\n\u2211 xt\u2208Xt \u2211 i f (i) C \u2217 1(y\u0302\n(i,j) t == 1)\u2211 xt\u2208Xt \u2211 i 1(y\u0302 (i,j) t == 1) . (10)\nThen, we define the adaptive ensemble weights w(i,j)C of MC as the softmax over feature distances to the centroids\nw (i,j) C = exp(\u2212\u2016f (i)C \u2212 \u03b7 (j) C \u2016)\u2211\nj\u2032 exp(\u2212\u2016f (i) C \u2212 \u03b7 (j\u2032) C \u2016)\n. (11)\nSimilarly, we can also obtain the ensembling weight of the other path w(i,j)F of MF . Furthermore, we can obtain the pseudo-label y\u0304t, following the weighted ensembling,\ny\u0304t = arg max( wC \u00b7 \u03c3(MC(xt)) + wF \u00b7 \u03c3(MF (xt))\n2 ), (12)\nwhere \u03c3 denotes the softmax function. In addition, the student model is also supervised by the labeled source data to generate discriminative features\nLSsrc = Lce(MS(xs), ys). (13)\nThe overall loss function of constraining the student model MS can be written as,\nLS = LSsrc + Ldistill = Lce(MS(xs), ys) + Lce(MS(x aug t ), y\u0304t). (14)\nIn the end, a superior student model is well trained by adaptively integrating the knowledge from two complementary teacher models covering different granularities.\nAlternating Optimization Strategy. By integrating the complementary knowledge from two expert teacher models, we can obtain a superior student model. In turn, this student model can be used to initialize the teacher models in the next new round, resulting in two stronger teacher models. They promote each other, achieving a win-win effect. Ultimately, we can obtain the most powerful student model after the final round."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Experimental Settings",
            "text": "Datasets: We use four publicly available semantic segmentation benchmarks for validation, including two synthetic scenes and two real-world scenes. Each scene has a unique structure and visual appearance. In detail, GTA5 [48] is a synthetic dataset of 24,966 labeled images obtained from a video game. Synscapes [56] is also a synthetic dataset of 25,000 images created by photo-realistic rendering techniques, and its style is closer to real-world driving scenes than GTA5. Cityscapes [9] is a real-world urban dataset collected from European cities, with 2,975 images for training and 500 images for validation. Mapillary Vista [42] is a large-scale dataset collected by various imaging devices worldwide and includes 18,000 images for training and 2,000 images for validation.\nImplementation details: We use the mmsegmentation [8] codebase and train models on RTX 3090Ti GPUs. Following previous works [64, 65, 24, 59], we use the advanced DeepLab-v2 [4] model with ResNet101 [20] pre-trained on ImageNet-1k [13] as backbone, and train the model with AdamW [36]. We set the learning rate as 6e-5 for the backbone and 6e-4 for the decoder head, use a weight decay of 0.01 and a linear learning rate warmup followed by 1.5k iterations linear decay. All experiments are trained on a batch of 512x512 random cropped images for 40k iterations. We set the batch size to 2 for analysis and experiments in Tab. 1 and Tab. 6, and set batch size to 4 for other results. Following [50], we use the same augmentation parameters and set \u03c4 = 0.968. For CutMix [62], the ratio of the selected region for cross-domain pasting is experimentally set to 0.3. For ClassMix [43], half of categories in the source domain are selected for cross-domain pasting."
        },
        {
            "heading": "4.2 Comparison with State-of-the-arts under Multiple Settings",
            "text": "GTA5 \u2192 Cityscapes (single-source). Tab. 2 reports results on the validation set of Cityscapes. Note that the comparable ProDA [64], UndoDA [32], and CPSL [28] have been improved with a warmup stage following existing DASS methods [51, 53]. Additionally, they also need to complete numerous rounds of self-distillation for the student model initialized by self-supervised pre-training. Compared to these methods that require redundant optimization processes, the proposed DDB method requires only two alternating optimization steps of DPDB and CKD. Despite simplicity, our method achieves a SOTA mIoU score of 62.7, outperforming existing methods significantly, which also achieves the best IoU score in 7 out of 19 categories. Particularly, thanks to combining the complementary teacher\nTable 7: Performance comparison (mIoU) of the student model obtained from CKD during various rounds in the whole training process on three benchmarks. The best score is indicated in underlined bold.\n0 1 2 3\nG\u2192 C 32.1 61.2 62.7 62.7 G + S\u2192 C 50.9 68.6 69.0 68.8 G\u2192 C + M 32.8 57.4 58.6 58.2\nmodels devoted to exploiting the context and inherent properties by the coarse region-path and fine class-path, the student model performs surprisingly well in those categories that are susceptible to the class bias issue, e.g., \u2018sidewalk\u2019 and \u2018bike.\u2019 Additionally, the final student model also performs well in those categories suffering from semantic confusion, e.g., \u2018person, rider\u2019 and \u2018truck, bus, train.\u2019\nGTA5 + Synscapes \u2192 Cityscapes (multi-source). We also perform experiments under the multisource domain setting. As shown in Tab. 3, our method obtains an impressive performance of 69.0 in mIoU, outperforming the previous SOTA methods over 10.0, achieving the best performance in all classes, especially those suffering class bias issue, e.g., \u2018sidewalk\u2019 and \u2018bike.\u2019 Although the proposed DDB is not tailored for multi-source DASS, our method still benefits this task by constructing intermediate domains between target and multiple source domains to facilitate knowledge transfer.\nGTA5 \u2192 Cityscapes + Mapillary (multi-target). Tab. 4 displays the performance of the proposed method in a multi-target domain setting. Although the multi-target DASS is more challenging due to unknown distributions, our method can still achieve an impressive performance of 58.6 in mIoU on average for multiple target domains, outperforming the existing SOTA methods by a significant margin. Moreover, the proposed DDB outperforms ADAS [26] by 31.2 in averaged mIoU on the \u2018sidewalk,\u2019 by 14.1 in averaged mIoU on the \u2018bus, train,\u2019 which indicates our method avoids the class bias and confusion issues. Such substantial performance gains comes from the DPDB-driven complementary teacher networks and the CKD-driven knowledge integration."
        },
        {
            "heading": "4.3 Ablation Study and Detailed Discussion",
            "text": "Complementarity Verification. To verify the complementarity of two teacher models trained on different bridging paths, we conduct an ablation where we train each path twice separately to obtain four different models. After ensembling these models pair-by-pair, the segmentation results are presented in Tab. 6. Unsurprisingly, the ensembled models across paths consistently perform better results than those only from a single view.\nStudy on Dual-path Domain Bridging. In Tab. 5, the source-only model achieves 32.1 in mIoU on the target domain. Combining the self-training pipeline with the coarse region-level and fine class-level domain bridging, we can obtain two complementary teacher models, and they achieve 56.5 and 58.2 in mIoU, respectively. As shown in Fig. 3, the coarse region-path tends to promote the model to utilize contextual information for prediction, whereas the fine class-path enables the model to focus more on exploiting inherent properties. Detailed results for the two teacher models in each category are provided in the supplemental materials.\nStudy on Cross-path Knowledge Distillation. Since CKD is performed on the unlabeled target domain, as shown in Tab. 5, we use the more stable hard distillation, which performs 0.9 mIoU higher than the soft distillation using the Kullback-Leibler divergence. Furthermore, our proposed adaptive ensemble scheme further improves the performance by 2.1 and 1.3 in mIoU in the case of soft and hard distillation, respectively. After applying CKD equipped with the hard distillation and adaptive\nensemble schemes, we can consistently obtain a superior student model. Fig. 3 illustrates how the student model performs after integrating the knowledge from two complementary teacher models and alleviates the class bias and confusion issues in various domain settings.\nInfluence of Alternating Optimization Strategy. As shown in Tab. 5, the alternation of DPDB and CKD allows the complementary teacher and student models to promote each other and gradually transfer knowledge across domains. We also test different alternating rounds on all three benchmarks, and report the performance of the student models after each round in Tab. 7 (more results are provided in the supplemental materials). The student model performs best across all three domain settings in the second round. On the other hand, the student model shows a slight performance degradation after the third round of alternate training in the multi-source and multi-target domain settings. We analyse the degradation is because the non-negligible domain conflict in these two settings."
        },
        {
            "heading": "5 Conclusions",
            "text": "In this paper, we study how the domain bridging techniques should be applied to domain adaptive semantic segmentation. To ensure that the segmentation model takes full advantage of domain bridging while avoiding side effects, we propose an effective Deliberated Domain Bridging (DDB) method. We build dual-path domain bridging (DPDB) with the coarse region-level data mix and fine class-level data mix to construct two complementary teacher models. Then, a superior student model can be generated from cross-path distillation (CKD) based on such two teacher models. By alternating steps of DPDB and CKD, teacher models and student model would promote each other and progressively transfer knowledge from the source domain to the target domain. Extensive ablation studies demonstrate the effectiveness of our method, and the experimental results on three benchmarks in the different settings further show its versatility and robustness."
        },
        {
            "heading": "6 Acknowledgement",
            "text": "This work was supported in part by the National Natural Science Foundation of China under Grant 61727809, in part by the Special Fund for Key Program of Science and Technology of Anhui Province under Grant 201903c08020002, and in part by the National Key Research and Development Program of China under Grant 2019YFC0117800."
        },
        {
            "heading": "Checklist",
            "text": "1. For all authors... (a) Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s\ncontributions and scope? [Yes] (b) Did you describe the limitations of your work? [Yes] See supplementary materials. (c) Did you discuss any potential negative societal impacts of your work? [No] (d) Have you read the ethics review guidelines and ensured that your paper conforms to\nthem? [Yes] 2. If you are including theoretical results...\n(a) Did you state the full set of assumptions of all theoretical results? [N/A] (b) Did you include complete proofs of all theoretical results? [N/A]\n3. If you ran experiments... (a) Did you include the code, data, and instructions needed to reproduce the main experi-\nmental results (either in the supplemental material or as a URL)? [Yes] (b) Did you specify all the training details (e.g., data splits, hyperparameters, how they\nwere chosen)? [Yes] (c) Did you report error bars (e.g., with respect to the random seed after running experi-\nments multiple times)? [Yes] (d) Did you include the total amount of compute and the type of resources used (e.g., type\nof GPUs, internal cluster, or cloud provider)? [Yes] 4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\n(a) If your work uses existing assets, did you cite the creators? [Yes] (b) Did you mention the license of the assets? [No] (c) Did you include any new assets either in the supplemental material or as a URL? [Yes] (d) Did you discuss whether and how consent was obtained from people whose data you\u2019re\nusing/curating? [No] (e) Did you discuss whether the data you are using/curating contains personally identifiable\ninformation or offensive content? [No] 5. If you used crowdsourcing or conducted research with human subjects...\n(a) Did you include the full text of instructions given to participants and screenshots, if applicable? [N/A]\n(b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [N/A]\n(c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [N/A]"
        },
        {
            "heading": "A Appendix",
            "text": "In the supplementary material, we provide more experimental results and summary them as follows:\n\u2022 In Sec. A.1, we utilize UMAP [39] to generate more visualization results for a comprehensive analysis of the feature space learned by different models.\n\u2022 In Sec. A.2, we provide a comprehensive training procedure of our proposed method.\n\u2022 In Sec. A.3, we provide detailed ablation studies on the key components of our proposed method w.r.t single-source, multi-source, and multi-target benchmarks.\n\u2022 In Sec. A.4, we compare our proposed method with previous state-of-the-art methods by qualitative results on the GTA5\u2192 Cityscapes benchmark.\n\u2022 In Sec. A.5, we provide a detailed comparison of the training efficiency with previous state-of-the-art methods on the GTA5\u2192 Cityscapes benchmark.\n\u2022 In Sec. A.6, we further discuss the limitations and potential negative impacts of our proposed method.\nTo reproduce our main experimental results, we release the code in a zip file named \u2018code.zip\u2019 and provide the checkpoints as anonymous links in the README file.\nA.1 Visualization of Feature Space\nTo better understand the intuitions behind the proposed method, we utilize UMAP [39] to visualize the target feature representations before the final classification layer on the GTA5 \u2192 Cityscapes benchmark. As shown in Fig. 4, the feature representation of the model trained on the source domain is not compact enough within each class, and the inter-class distance of each class pair is also relatively small. While models trained on the coarse region-path (CRP) and fine class-path (FCP) have comparable performance, their feature distributions are quite different. In FCP, due to more attention paid to the object\u2019s inherent properties, the feature representation within each class is more compact than in CRP. However, the representations of \u2018bus\u2019 and \u2018train\u2019 in FCP are seriously overlapping. The model trained on CRP tends to exploit the contextual information to discriminate the confused classes, which drives to more separable representations of \u2018bus\u2019 and \u2018train.\u2019\nAs depicted in the bottom row of Fig. 4, the student models integrating knowledge from two complementary teacher models not only have more compact feature representations than the teacher model in FCP but also mitigate the overlapping issue of the confused \u2018bus\u2019 and \u2018train\u2019 classes. Furthermore, the alternating optimization strategy can consistently further enhance such properties of the student model."
        },
        {
            "heading": "A.2 Algorithm",
            "text": "The training procedure of our DDB is summarized in Algorithm 1, which is composed of multiple rounds of alternating dual-path domain bridging (DPDB) and cross-path knowledge distillation (CKD) steps. For detailed equations and loss functions, please refer to the main paper.\nAlgorithm 1: Training process of DDB Input: training dataset: (Xs, Ys, Xt); batch data: (xs, ys, xt); teacher models: M1C ,M1F and student\nmodel: M1S ; EMA teacher models: M \u2032r C ,M \u2032r F ; EMA momentum: \u03b1; alternating rounds: R.\nOutput: final student model: MRS . 1 for r \u2190 1 to R do 2 # Dual-path Domain Bridging 3 EMA models initialization: \u03b8M\u2032r\nC \u2190 \u03b8Mr C , \u03b8M\u2032r F \u2190 \u03b8Mr F ;\n4 for k \u2190 1 to max_iterations do 5 Get source images xs, target images xt; 6 7 Get CRP bridging images xcrp, labels y\u0302crp by Eqn. 3 8 Get pseudo-label weight maps mcrp by Eqn. 6; 9 Optimize MrC by Eqn. 8;\n10 Update EMA model: \u03b8k+1M\u2032r C \u2190 \u03b1\u03b8kM\u2032r C + (1\u2212 \u03b1) \u03b8kMC ; 11 12 Get FCP bridging images xfcp, labels y\u0302fcp by Eqn. 3 13 Get pseudo-label weight maps mfcp by Eqn. 6; 14 Optimize MrF by Eqn. 8; 15 Update EMA model: \u03b8k+1M\u2032r\nF \u2190 \u03b1\u03b8kM\u2032r F + (1\u2212 \u03b1) \u03b8kMF ;\n16 17 # Cross-path Knowledge Distillation 18 Calculate the prototypes \u03b7rC , \u03b7 r F on Xt by Eqn. 10; 19 for k \u2190 1 to max_iterations do 20 Get source images xs; 21 Get clean and augmented target images xt, xaugt ; 22 Utilize prototypes to get adaptive weight maps wC , wF by Eqn. 11; 23 Get ensembled pseudo-label y\u0304t; 24 Optimize MrS by Eqn. 14;\n25 if r 6= R then 26 Teacher models initialization for next round: \u03b8\nMr+1 C \u2190 \u03b8Mr S , \u03b8 Mr+1 F \u2190 \u03b8Mr S ;"
        },
        {
            "heading": "A.3 Detailed Ablation Studies",
            "text": "Study on Baseline. As mentioned in Sec.3.2 of the main paper, we follow [50, 24] to construct a simple self-training pipeline (pseudo labeling) to validate the effectiveness of various DB methods in the DASS task and treat it as our baseline. As shown in Tab. 10, Tab. 11, and Tab. 12, the model trained on baseline tends to give over confidences to some easily discriminated categories, resulting in performance converging to 0 in other categories. Specifically, due to more labeled data in the source domain, the model under the multi-source setting has a extremely over-confidence w.r.t the easily discriminated categories, resulting in a performance decrease of 8.5 in mIoU.\nStudy on Dual-path Domain Bridging. As shown in Tab. 10, Tab. 11, and Tab. 12, the source-only and baseline models all perform poorly on three benchmarks. Benefited from the proposed dual-path domain bridging scheme, the adapted model on each path can obtain gains at least 24.4, 15.3, and 19.7 in mIoU separately. Although the CRP and FCP models achieve comparable performance, they have pretty different behaviors in each class. For example, on the GTA5\u2192 Cityscapes (single-source) benchmark, the CRP model achieves 39.5 in the \u2018train\u2019 class while the FCP model only achieves 0.0. This is because the CRP model tends to exploit contextual information to mitigate the class confusion issue. Due to the lack of contextual information, the FCP model pays more attentions on the inherent object properties, mitigating the class bias, such as \u2018sidewalk\u2019 and \u2018terrain\u2019 classes. Moreover, as shown in Tab. 8, we further conducted ablation experiments on \u03b1, and found that \u03b1 = 0.99 will lead to better and more stable results.\nStudy on Cross-path Knowledge Distillation. As illustrated in Tab. 10 and Tab. 11, the hard distillation is more effective than the soft manner in the single-source and multi-source domain settings. Especially in the multi-source setting (see Tab. 11), the hard distillation can improve model by 2.1 in mIoU than the soft one. Furthermore, the proposed adaptive ensemble can consistently improve the performance of both soft and hard distillation schemes in all three settings. By leveraging CKD that equipped with the hard distillation and adaptive ensemble schemes, we can consistently obtain a more superior student model than its teachers in all three benchmarks. Especially in the multi-target setting (see Tab. 12), the student model gets gains of 3.6 and 4.4 in mIoU than the CRP and FCP teacher models, separately. Moreover, we further conducted ablation experiments about the augmentation strategies. As shown in Tab. 9, combining the Gaussian blur and color jitter augmentation techniques leads to the best performance.\nInfluence of Alternating Optimization Strategy. As illustrated in Tab. 10, Tab. 11, and Tab. 12, after integrating knowledge from two complementary teacher models, the student model performs better than each teacher model. Once a superior student is obtained, we further conduct next DPDB step and utilize the weights of the student model to initialize the teacher models in DPDB to obtain two more powerful teachers. The student model performs best across all three domain settings in the second round. However, the student model shows a slight performance degradation after the third round of alternate training in the multi-source and multi-target domain settings. We analyse the degradation is because the non-negligible domain conflict in these two settings."
        },
        {
            "heading": "A.4 Comparison of Qualitative Results",
            "text": ""
        },
        {
            "heading": "A.5 Comparison of Training Efficiency",
            "text": "As illustrated in Tab. 13, our method achieved better performance after one round of training with smaller input size, fewer GPUs, fewer iterations, and fewer post-processing steps than other SOTA methods. Furthermore, our method could still achieve gains of 1.5 mIoU with one more training round, while still being more efficient than other SOTA methods."
        },
        {
            "heading": "A.6 Limitations",
            "text": "Although our proposed approach achieves impressive performance on the single-source, multi-source, and multi-target domain settings, it still requires multiple training rounds to conduct alternating optimization processes of the proposed dual-path domain bridging and cross-path knowledge distillation steps. We will explore an end-to-end optimization approach in future work. Moreover, the proposed method might be used in undesirable applications like surveillance or military UAVs for the purpose of domain adaptive semantic segmentation. Legal limitations on the applications of semantic segmentation algorithms could be a potential defense."
        }
    ],
    "title": "Deliberated Domain Bridging for Domain Adaptive Semantic Segmentation",
    "year": 2022
}