{
    "abstractText": "The CONGEST and CONGEST-CLIQUE models have been carefully studied to represent situations where the communication bandwidth between processors in a network is severely limited. Messages of only O(log(n)) bits of information each may be sent between processors in each round. The quantum versions of these models allow the processors instead to communicate and compute with quantum bits under the same bandwidth limitations. This leads to the following natural research question: What problems can be solved more efficiently in these quantum models than in the classical ones? Building on existing work, we contribute to this question in two ways. Firstly, we present two algorithms in the Quantum CONGEST-CLIQUE model of distributed computation that succeed with high probability; one for producing an approximately optimal Steiner Tree, and one for producing an exact directed minimum spanning tree, each of which uses \u00d5(n) rounds of communication and \u00d5(n) messages, where n is the number of nodes in the network. The algorithms thus achieve a lower asymptotic round and message complexity than any known algorithms in the classical CONGEST-CLIQUE model. At a high level, we achieve these results by combining classical algorithmic frameworks with quantum subroutines. An existing framework for using a distributed version of Grover\u2019s search algorithm to accelerate triangle finding lies at the core of the asymptotic speedup. Secondly, we carefully characterize the constants and logarithmic factors involved in our algorithms as well as related algorithms, otherwise commonly obscured by \u00d5 notation. The analysis shows that some improvements are needed to render both our and existing related quantum and classical algorithms practical, as their asymptotic speedups only help for very large values of n. Keywords\u2014 Quantum Computing, Distributed Computing, Steiner Tree, Directed Minimum Spanning Tree",
    "authors": [
        {
            "affiliations": [],
            "name": "Phillip A. Kerger"
        },
        {
            "affiliations": [],
            "name": "David E. Bernal Neira"
        },
        {
            "affiliations": [],
            "name": "Zoe Gonzalez Izquierdo"
        },
        {
            "affiliations": [],
            "name": "Eleanor G. Rieffel"
        }
    ],
    "id": "SP:c8ad5055c561a27bec44e3c155d651126aedc693",
    "references": [
        {
            "authors": [
                "K. Censor-Hillel",
                "O. Fischer",
                "F. Le Gall",
                "D. Leitersdorf",
                "R. Oshman"
            ],
            "title": "Quantum Distributed Algorithms for Detection of Cliques",
            "venue": "arXiv. Retrieved from https://arxiv.org/abs/2201.03000 doi: doi:10.48550/ARXIV.2201.03000",
            "year": 2022
        },
        {
            "authors": [
                "K. Censor-Hillel",
                "P. Kaski",
                "J.H. Korhonen",
                "C. Lenzen",
                "A. Paz",
                "J. Suomela"
            ],
            "title": "mar). Algebraic methods in the congested clique",
            "venue": "Distributed Computing,",
            "year": 2016
        },
        {
            "authors": [
                "M. Dinitz",
                "M.M. Halldorsson",
                "T. Izumi",
                "C. Newport"
            ],
            "title": "Distributed Minimum Degree Spanning Trees",
            "venue": "In Proceedings of the 2019 acm symposium on podc (p. 511\u2013520)",
            "year": 2019
        },
        {
            "authors": [
                "D. Dolev",
                "C. Lenzen",
                "S. Peled"
            ],
            "title": "Tri, Tri Again\u201d: Finding Triangles and Small Subgraphs in a Distributed Setting - (Extended Abstract)",
            "year": 2012
        },
        {
            "authors": [
                "J Edmonds"
            ],
            "title": "Optimum branchings",
            "venue": "Journal of Research of the national Bureau of Standards B ,",
            "year": 1967
        },
        {
            "authors": [
                "M. Elkin",
                "H. Klauck",
                "D. Nanongkai",
                "G. Pandurangan"
            ],
            "title": "Can Quantum Communication Speed Up Distributed Computation? arXiv. Retrieved from https://arxiv.org/abs/1207.5211 doi: doi:10.48550/ARXIV.1207.5211",
            "year": 2012
        },
        {
            "authors": [
                "O. Fischer",
                "R. Oshman"
            ],
            "title": "A distributed algorithm for directed minimum-weight spanning tree",
            "venue": "Distributed Computing,",
            "year": 2021
        },
        {
            "authors": [
                "M. Ghaffari"
            ],
            "title": "Distributed Graph Algorithms (Lecture Notes)",
            "year": 2020
        },
        {
            "authors": [
                "V. Giovannetti",
                "S. Lloyd",
                "L. Maccone"
            ],
            "title": "apr). Quantum random access memory",
            "venue": "Physical Review Letters ,",
            "year": 2008
        },
        {
            "authors": [
                "T. Izumi",
                "F.L. Gall"
            ],
            "title": "jul). Quantum Distributed Algorithm for the All-Pairs Shortest Path Problem in the CONGEST-CLIQUE Model",
            "venue": "In Proceedings of the 2019 ACM symposium on podc. ACM. Retrieved from https://arxiv.org/abs/1906.02456 doi: doi:10.1145/3293611.3331628",
            "year": 2019
        },
        {
            "authors": [
                "T. Izumi",
                "F. Le Gall",
                "F. Magniez"
            ],
            "title": "Quantum Distributed Algorithm for Triangle Finding in the CONGEST Model. Schloss Dagstuhl - Leibniz-Zentrum f\u00fcr Informatik. Retrieved from https://drops.dagstuhl.de/opus/volltexte/2020/11884/ doi: doi:10.4230/LIPICS.STACS.2020.23",
            "year": 2020
        },
        {
            "authors": [
                "J.H. Korhonen",
                "J. Suomela"
            ],
            "title": "Towards a complexity theory for the congested clique. arXiv. Retrieved from https://arxiv.org/abs/1705.03284 doi: doi:10.48550/ARXIV.1705.03284",
            "year": 2017
        },
        {
            "authors": [
                "L.T. Kou",
                "G. Markowsky",
                "L. Berman"
            ],
            "title": "A fast algorithm for Steiner trees",
            "venue": "Acta Informatica,",
            "year": 1981
        },
        {
            "authors": [
                "F. Le Gall",
                "F. Magniez"
            ],
            "title": "jul). Sublinear-Time Quantum Computation of the Diameter in CONGEST Networks",
            "venue": "In Proceedings of the 2018 ACM symposium on podc. ACM. Retrieved",
            "year": 2018
        },
        {
            "authors": [
                "C. Lenzen"
            ],
            "title": "Optimal Deterministic Routing and Sorting on the Congested Clique",
            "venue": "arXiv. doi: doi:10.48550/ARXIV.1207.1852",
            "year": 2012
        },
        {
            "authors": [
                "L. Lovasz"
            ],
            "title": "Computing ears and branchings in parallel",
            "venue": "In 26th annual symposium on foundations of computer science (sfcs",
            "year": 1985
        },
        {
            "authors": [
                "K. Nowicki"
            ],
            "title": "A Deterministic Algorithm for the MST Problem in Constant Rounds of Congested Clique",
            "year": 2019
        },
        {
            "authors": [
                "E. Rieffel",
                "W. Polak"
            ],
            "title": "Quantum Computing: A Gentle Introduction (1st ed.)",
            "year": 2011
        },
        {
            "authors": [
                "P. Saikia",
                "S. Karmakar"
            ],
            "title": "Distributed Approximation Algorithms for Steiner Tree in the CONGESTED CLIQUE",
            "venue": "arXiv. Retrieved from https://arxiv.org/abs/1907.12011 doi: doi:10.48550/ARXIV.1907.12011",
            "year": 2019
        },
        {
            "authors": [
                "J. van Apeldoorn",
                "T. de Vos"
            ],
            "title": "A Framework for Distributed Quantum Queries in the CONGEST Model. arXiv. Retrieved from https://arxiv.org/abs/2202.10969 doi: doi:10.48550/ARXIV.2202.10969",
            "year": 2022
        },
        {
            "authors": [
                "U. Zwick"
            ],
            "title": "All Pairs Shortest Paths using Bridging Sets and Rectangular Matrix Multiplication",
            "year": 2000
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n30 4.\n02 82\n5v 6\n[ qu\nan t-\nKeywords\u2014 Quantum Computing, Distributed Computing, Steiner Tree, Directed Minimum Spanning Tree"
        },
        {
            "heading": "1 Introduction",
            "text": "The classical CONGEST-CLIQUE Model (cCCM henceforth) in distributed computing has been carefully studied as a model central to the field, e.g., (Korhonen & Suomela, 2017; Saikia & Karmakar, 2019; Fischer & Oshman, 2021; Lenzen, 2012; Dolev, Lenzen, & Peled, 2012; Nowicki, 2019). In this model, processors in a network solve a problem whose input is distributed across the nodes under significant communication limitations, described in detail in \u00a72. For example, a network of aircraft or spacecraft, satellites, and control stations, all with large distances between them, may have severely limited communication bandwidth to be modeled in such a way. The quantum version of this model, in which quantum bits can be sent between processors, the quantum CONGEST-CLIQUE Model (qCCM), as well as the quantum CONGEST model, have been the subject of recent research (Izumi & Gall, 2019; CensorHillel, Fischer, Le Gall, Leitersdorf, & Oshman, 2022; van Apeldoorn & de Vos, 2022; Elkin, Klauck, Nanongkai, &\nPandurangan, 2012) in an effort to understand how quantum communication may help in these distributed computing frameworks. For the quantum CONGEST Model, however, (Elkin et al., 2012) showed that many problems cannot be solved more quickly than in the classical model. These include shortest paths, minimum spanning trees, Steiner trees, min-cut, and more; the computational advantages of quantum communication are thus severely limited in the CONGEST setting, though a notable positive result is sub-linear diameter computation in (Le Gall & Magniez, 2018). No comparable negative results exist for the qCCM, and in fact, (Izumi & Gall, 2019) provides an asymptotic quantum speedup for computing all-pairs shortest path (APSP henceforth) distances. Hence, it is apparent that the negative results of (Elkin et al., 2012) cannot transfer over to the qCCM, so investigating these problems in the qCCM presents an opportunity for contribution to the understanding of how quantum communication may help in these distributed computing frameworks. In this paper, we contribute to this understanding by formulating algorithms in the qCCM for finding approximately optimal Steiner trees and exact directed minimum spanning trees using O\u0303(n1/4) rounds \u2013 asymptotically fewer rounds than any known classical algorithms. This is done by augmenting the APSP algorithm of (Izumi & Gall, 2019) with an efficient routing table scheme, which is necessary to make use of the shortest paths information instead of only the APSP distances, and using the resulting subroutine with existing classical algorithmic frameworks. Beyond asymptotics, we also characterize the complexity of our algorithms as well as those of (Izumi & Gall, 2019; Censor-Hillel et al., 2016; Saikia & Karmakar, 2019; Fischer & Oshman, 2021) to include the logarithmic and constant factors involved to estimate the scales at which they would be practical, which was not included in the previous work. It should be noted that, like APSP, these problems cannot see quantum speedups in the CONGEST (non-clique) setting as shown in (Elkin et al., 2012). Our Steiner tree algorithm is approximate and based on a classical polynomial-time centralized algorithm of (Kou, Markowsky, & Berman, 1981). Our directed minimum spanning tree problem algorithm follows an approach similar to (Fischer & Oshman, 2021), which effectively has its centralized roots in (Lovasz, 1985)."
        },
        {
            "heading": "2 Background and Setting",
            "text": "This section provides the necessary background for our algorithms\u2019 settings and the problems they solve."
        },
        {
            "heading": "2.1 The CONGEST and CONGEST-CLIQUE Models of Distributed Computing",
            "text": "In the standard CONGEST model, we consider a graph of n processor nodes whose edges represent communication channels. Initially, each node knows only its neighbors in the graph and associated edge weights. In rounds, each processor node executes computation locally and then communicates with its neighbors before executing further local computation. The congestion limitation restricts this communication, with each node able to send only one message of O(log(n)) classical bits in each round to its neighbors, though the messages to each neighbor may differ. Since there are n nodes, assigning them ID labels 1, ..., n means the binary encoding size of a label is \u2308log(n)\u2309 bits \u2013 i.e., each message in CONGEST of O(log n) bits can contain roughly the amount of information to represent one node ID. In the cCCM, we separate the communication graph from the problem input graph by allowing all nodes to communicate with each other, though the same O(log(n)) bits-per-message congestion limitation remains. Hence, a processor node could send n\u22121 different messages to the other n\u22121 nodes in the graph, with a single node distributing up to O(n \u00b7 log(n)) bits of information in a single round. Taking advantage of this way of dispersing information to the network is paramount in many efficient CONGEST-CLIQUE algorithms. The efficiency of algorithms in these distributed models is commonly measured in terms of the round complexity, the number of rounds of communication used in an algorithm to solve the problem in question. A good overview of these distributed models can be found in (Ghaffari, 2020)."
        },
        {
            "heading": "2.2 Quantum Versions of CONGEST and CONGEST-CLIQUE",
            "text": "The quantum models we work in are obtained via the following modification: Instead of restricting to messages of O(log(n)) classical bits, we allow messages to consist of O(log(n)) quantum bits, qubits. For background on qubits and the fundamentals of quantum computing, we refer the reader to (Rieffel & Polak, 2011). We formally define the qCCM, the setting for our algorithms, as follows:\nDefinition 2.1 (Quantum CONGEST-CLIQUE). The Quantum CONGEST-CLIQUE Model (qCCM) is a distributed computation model in which an input graph G = (V,E,W ) is distributed over a network of n processors,\nwhere each processor is represented by a node in V . Each node is assigned a unique ID number in [n]. Time passes in rounds, each of which consists of the following:\n1. Each node may execute unlimited local computation.\n2. Each node may send a message consisting of either a register of O(log n) qubits or a string of O(log n) classical bits to each other node in the network. Each of those messages may be distinct.\n3. Each node receives and saves the messages the other nodes send it.\nThe input graph G is distributed across the nodes as follows: Each node knows its own ID number, the ID numbers of its neighbors in G, the number of nodes n in G, and the weights corresponding to the edges it is incident upon. The output solution to a problem must be given by having each node v \u2208 V return the restriction of the global output to NG(u) := {v : uv \u2208 E}, its neighborhood in G. No entanglement is shared across nodes initially.\nThis is an analog of the cCCM, except that quantum bits may be sent in place of classical bits. To clarify the output requirement, in the Steiner tree problem, we require node u to output the edges of the solution tree that are incident upon u. Since many messages in our algorithms need not be sent as qubits, we define the qCCM slightly unconventionally, allowing either quantum or classical bits to be sent. We specify those that may be sent classically. However, even without this modification, the quantum versions of CONGEST and cCCM are at least as powerful as their classical counterparts. This is because any n-bit classical message can be instead sent as an n-qubit message of unentangled qubits; for a classical bit reading 0 or 1, we can send a qubit in the state |0\u3009 or |1\u3009 respectively, and then take measurements with respect to the {|0\u3009 , |1\u3009} basis to read the same message the classical bits would have communicated. Hence, one can also freely make use of existing classical algorithms in the qCCM. Further, the assumption that IDs are in [n], with n known, is not necessary but is convenient; without this assumption, we could have all nodes broadcast their IDs to the entire network and then assign a new label in [n] to each node according to an ordering of the original IDs, resulting in our assumed situation.\nRemark 2.2. Definition 2.1 does not account for how the information needs to be stored. In this paper, it suffices for all information regarding the input graph to be stored classically as long as there is quantum access to that data. We provide some details on this in \u00a78.4 of the appendix.\nRemark 2.3. No entanglement being shared across nodes initially in definition 2.1 results in quantum teleportation not being a trivial way to solve problems in the qCCM.\nExample 2.4. To provide some intuition on how allowing communication through qubits in this distributed setting can be helpful, we now describe and give an example of distributed Grover search, first described in (Le Gall & Magniez, 2018). The high-level intuition for why quantum computing gives an advantage for search is that quantum operations use quantum interference effects to have canceling effects among non-solutions. Grover search has a generalization called \u201camplitude amplification\u201d we will use; see (Rieffel & Polak, 2011) for details on these algorithms. Now, for a processor node u in the network and a Boolean function g : X \u2192 {0, 1}, suppose there exists a classical procedure C in the cCCM that allows u to compute g(x), for any x \u2208 X in r rounds. The quantum speedup will come from computing C in a quantum superposition, which enables g to be evaluated with inputs in superposition so that amplitude amplification can be used for inputs to g. Let Ai : {x \u2208 X : g(x) = i}, for i = 0, 1, and suppose that 0 < |A1| \u2264 |X|/2. Then classically, node u can find an x \u2208 A1 in \u0398(r|X|) rounds by checking each element of X. Using the quantum distributed Grover search of (Le Gall & Magniez, 2018) enables u to find such an x with high probability in only O\u0303(r \u221a\n|X|) rounds by evaluating the result of computing g on a superposition of inputs. We illustrate this procedure in an example case where a node u wants to inquire whether one of its edges uv is part of a triangle in G. We first describe a classical procedure for this, followed by the corresponding quantumdistributed search version. For v \u2208 NG(u), denote by Iv : V \u2192 {0, 1} the indicator function of NG(v), and by guv : NG(u) \u2192 {0, 1} its restriction to inputs in NG(u). Classically, node u can evaluate guv(w) in two rounds for any w \u2208 NG(u) by sending the ID of w (of length log n) to v, and having v send back the answer Iv(w). Then u can check guv(w) for each w \u2208 NG(u) one at a time to determine whether uv is part of a triangle in G or not in 2 \u00b7 |NG(u)| rounds.\nFor the distributed quantum implementation, u can instead initialize a register of log n qubits as |\u03c8\u30090 := 1\u221a\n|NG(u)|\n\u2211\nx\u2208NG(u) |x\u3009, all the inputs for guv in equal superposition. To do a Grover search, u needs to be able to evaluate guv with inputs |\u03c8\u3009 in superposition. For the quantum implementation of C, u sends a quantum register in state |\u03c8\u3009|0\u3009 to node v, and has node v evaluate a quantum implementation of Iv, which we will consider as a call to an oracle mapping |x\u3009|0\u3009 to |x\u3009|Iv(x)\u3009 for all x \u2208 V . Node v sends back the resulting qubit register, and node u has evaluated guv(|\u03c8\u3009) in 2 rounds. Now, since u can evaluate guv in superposition, node u may proceed using standard\namplitude amplification, using 2 rounds of communication for each evaluation of guv, so that u can find an element w \u2208 NG(u) satisfying guv(w) = 1 with high probability in O\u0303(r \u221a\n|NG(u)|) rounds if one exists. We note that in this example, v cannot execute this procedure by itself since it does not know NG(u) (and sending this information to v would take |NG(u)| rounds), though it is able to evaluate Iv in superposition for any w \u2208 NG(u). For any classical procedure C evaluating a different function from this specific g (that can be implemented efficiently classically and, therefore, translated to an efficient quantum implementation), the same idea results in the square-root advantage to find a desired element such that g evaluates to 1."
        },
        {
            "heading": "2.3 Notation and Problem Definitions",
            "text": "For an integer-weighted graph G = (V,E,W ), we will denote n := |V |, m := |E|, and We the weight of an edge e \u2208 E throughout the paper. Let \u03b4(v) \u2282 V be the set of edges incident on node v, and NG(u) := {v : uv \u2208 E} the neighborhood of u \u2208 G. Denote by dG(u, v) the shortest-path distance in G from u to v. For a graph G = (V,E,W ) two sets of nodes U and U \u2032, let PG(U,U \u2032) := {uv \u2208 E : u \u2208 U,w \u2208 U \u2032} be the set of edges connecting U to U \u2032. Let P(U) := P(U,U) as shorthand. All logarithms will be taken with respect to base 2, unless otherwise stated.\nDefinition 2.5 (Steiner Tree Problem). Given a weighted, undirected graph G = (V,E,W ), and a set of nodes Z \u2282 V , referred to as Steiner Terminals, output the minimum weight tree in G that contains Z.\nDefinition 2.6 (Approximate Steiner Tree). For a Steiner Tree Problem with terminals Z and solution SOPT with edge set ESOPT , a tree T in G containing Z with edge set ET such that\n\u2211\nuv\u2208ET\nWuv \u2264 r \u00b7 \u2211\nuv\u2208ESOPT\nWuv\nis called an approximate Steiner Tree with approximation factor r.\nDefinition 2.7 (Directed Minimum Spanning Tree Problem (DMST)). Given a directed, weighted graph G = (V,E,W ) and a root node r \u2208 V , output the minimum weight directed tree T \u2217 in G such that there exists a directed path in T \u2217 from r to any other node of G. This is also known as the minimum weight arborescence problem."
        },
        {
            "heading": "3 Contributions",
            "text": "We provide an algorithm for the qCCM that produces an approximate Steiner Tree with high probability (w.h.p.) in O\u0303(n1/4) rounds and an algorithm that produces an exact Directed Minimum Spanning Tree w.h.p. in O\u0303(n1/4) rounds. To do this, we enhance the quantum APSP algorithm of (Izumi & Gall, 2019) in an efficient way to compute not only APSP distances but also the corresponding routing tables (described in \u00a74) that our algorithms rely on. Further, in addition to these O\u0303 results, in sections 4.7, 5.4, and 6.3, we characterize the constants and logarithmic factors involved in our algorithms as well as related classical algorithms to contribute to the community\u2019s understanding of their implementability. This reveals that the factors commonly obscured by O\u0303 notation in related literature, especially the logarithms, have a severe impact on practicality.\nWe summarize the algorithmic results in the following two theorems:\nTheorem 3.1. There exists an algorithm in the QuantumCONGEST-CLIQUEmodel that, given an integer-weighted input graph G = (V,E,W ), outputs a 2(1 \u2212 1/l) approximate Steiner Tree with probability of at least 1 \u2212 1\npoly(n) ,\nand uses O\u0303(n1/4) rounds of computation, where l denotes the number of terminal leaf nodes in the optimal Steiner Tree.\nTheorem 3.2. There exists an algorithm in the Quantum CONGEST-CLIQUE model that, given a directed and integer-weighted input graph G = (V,E,W ), produces an exact Directed Minimum Spanning Tree with high probability, of at least 1\u2212 1\npoly(n) , and uses O\u0303(n1/4) rounds of computation."
        },
        {
            "heading": "4 APSP and Routing Tables",
            "text": "We first describe an algorithm for the APSP problem with routing tables in the qCCM, for which we combine an algorithm of (Izumi & Gall, 2019) with a routing table computation from (Zwick, 2000). For this, we reduce APSP with routing tables to triangle finding via distance products as in (Censor-Hillel et al., 2016)."
        },
        {
            "heading": "4.1 Distance Products and Routing Tables",
            "text": "Definition 4.1. A routing table for a node v is a function Rv : V \u2192 V mapping a vertex u to the first node visited in the shortest path going from v to u other than v itself.\nDefinition 4.2. The distance product between two n\u00d7 n matrices A and B is defined as the n\u00d7 n matrix A \u22c6 B with entries:\n(A \u22c6 B)ij = min k {Aik +Bkj}. (4.1)\nThe distance product is also sometimes called the min-plus or tropical product. For shortest paths, we will repeatedly square the graph adjacency matrix with respect to the distance product. For an n \u00d7 n matrix W and an integer k, let us denote W k,\u22c6 := W \u22c6 (W \u22c6 (. . . (W \u22c6 W )) . . . ) as the kth power of the distance product. For a graph G = (V,E,W ) with weighted adjacency matrix W (assigning Wuv = \u221e if uv /\u2208 E), W k,\u22c6uv is the length of the shortest path from v to u in G using at most k hops. Hence, for any N \u2265 n, WN,\u22c6 contains all the shortest path distances between nodes in G. As these distance products obey standard exponent rules, we may take N = 2\u2308log n\u2309 to recursively compute the APSP distances via taking \u2308log n\u2309 distance product squares:\nW 2,\u22c6 =W \u22c6W, W 4,\u22c6 = ( W 2,\u22c6 )2,\u22c6 , . . . , W 2 \u2308log n\u2309,\u22c6 =\n(\nW 2 \u2308log n\u2309\u22121,\u22c6\n)2,\u22c6\n. (4.2)\nThis procedure reduces computing APSP distances to computing \u2308log n\u2309 distance products. In the context of the CONGEST-CLIQUE model, each node needs to learn the row of W n that represents it. As we also require nodes to learn their routing tables, we provide a scheme in \u00a74.3 that is well-suited for our setting to extend (Izumi & Gall, 2019) to also compute routing tables."
        },
        {
            "heading": "4.2 Distance Products via Triangle Finding",
            "text": "Having established reductions to distance products, we turn to their efficient computation. The main idea is that we can reduce distance products to a binary search in which each step in the search finds negative triangles. This procedure corresponds to (Izumi, Le Gall, & Magniez, 2020, Proposition 2), which we describe here, restricting to finding the distance product square needed for Eq. (4.2).\nA negative triangle in a weighted graph is a set of edges \u2206\u2212 = (uv, vw,wu) \u2282 E3 such that \u2211e\u2208\u2206\u2212 We < 0. Let us denote the set of all negative triangles in a graph G as \u2206\u2212G. Specifically, we will be interested in each node v being able to output edges vu \u2208 \u03b4(v) such that vu is involved in at least one negative triangle in G. Let us call this problem FindEdges, and define it formally as:\nFindEdges\nInput: An integer-weighted (directed or undirected) graph G = (V,E,W ) distributed among the nodes, with each node v knowing NG(v), as well as the weights Wvu for each u \u2208 NG(v). Output: For each node v, its output is all the edges vu \u2208 E that are involved in at least one negative triangle in G.\nProposition 4.3. If FindEdges on an n-node integer-weighted graph G = (V,E,W ) can be solved in T (n) rounds, then the distance product A \u22c6 B of two n \u00d7 n matrices A and B with entries in [M ] can be computed in T (3n) \u00b7 \u2308log2(2M)\u2309 rounds.\nProof. Let A and B be arbitrary n \u00d7 n integer-valued matrices, and D be an n \u00d7 n matrix initialized to 0. Let each u \u2208 V simulate three copies of itself,u1, u2, u3, writing V1, V2, V3 as the sets of copies of nodes in V . Consider the graph G\u2032 = (V1 \u222a V2 \u222a V3, E\u2032,W \u2032), by letting uivj \u2208 E\u2032 for ui \u2208 Vi, vj \u2208 Vj , i 6= j, taking W \u2032u1v2 = Auv for u1 \u2208 V1, v2 \u2208 V2, W \u2032u2v3 = Buv for u2 \u2208 V2, v3 \u2208 V3, and W \u2032u3v1 = Duv for u3 \u2208 V3, v1 \u2208 V1. An edge zv is part of a negative triangle in G\u2032 exactly whenever\nmin u\u2208V {Avu +Buz} < \u2212Dzv.\nAssuming we can compute FindEdges for a k-node graph in T (n) rounds, with a non-positive matrix D = 0 initialized we can apply simultaneous binary searches on Dzv, with values between {\u22122M, 0}, updating it for each node v after each run of FindEdges to find minu\u2208V {Avu +Buz} for every other node z in T (3n) \u00b7 \u2308log(maxv,z\u2208V {minu\u2208V {Avu +Buz}})\u2309 rounds, since G\u2032 is a tripartite graph with 3n nodes.\nRemark 4.4. This procedure can be realized in a single n-node distributed graph by letting each node represent the three copies of itself since G\u2032 is tripartite. The T (3n) stems from each processor node possibly needing to send one message for each node it is simulating in each round of FindEdges. If bandwidth per message is large enough (3 times the bandwidth needed for solving FindEdges in T (n) rounds), then this can be done in T (n) rounds.\nSo for this binary search, each node v initializes and locally stores Dvz = 0 for each other z \u2208 V , after which we solve FindEdges on G\u2032. The node then updates each Dvz according to whether or not the edge copies of vz were part of a negative triangle in G\u2032, after which FindEdges is computed with the updated values for D. This is repeated until all the minu\u2208V {Avu +Buz} have been determined."
        },
        {
            "heading": "4.3 Routing Tables via Efficient Computation of Witness Matrices",
            "text": "For the routing table entries, we also need each node v to know the intermediate node u that is being used to attain minu\u2208V {Wvu +Wuz}.\nDefinition 4.5. For a distance product A \u22c6 B of two n \u00d7 n matrices A,B, a witness matrix C is an n \u00d7 n matrix such that\nCij \u2208 argmink\u2208[n]{Aik +Bkj}\nPut simply, a witness matrix contains the intermediate entries used to attain the values in the resulting distance product. We present here a simple way of computing witness matrices along with the distance product by modifying the matrix entries appropriately, first considered by (Zwick, 2000). The approach is well-suited for our algorithm, as we only incur O(log n) additional calls to FindEdges for a distance product computation with a witness matrix.\nFor an n\u00d7n integer matrix W , obtain matrices W \u2032 and W \u2032\u2032 by taking W \u2032ij = nWij + j\u2212 1 and W \u2032\u2032ji = nWji. Set K =W \u2032 \u22c6 W \u2032\u2032.\nClaim 1. With W,W \u2032,W \u2032\u2032, and K as defined immediately above,\n(i)\n\u230a\nK\nn\n\u230b\n=W 2,\u22c6\n(ii) (K mod n) + 1 is a witness matrix for W 2,\u22c6.\nThe claim follows from routine calculations of the quantities involved and can be found in the Appendix, \u00a78.1. Hence, we can obtain witness matrices by simply changing the entries of our matrices by no more than a multiplicative factor of n and an addition of n. Since the complexity of our method depends on the magnitude of the entries of W logarithmically, we only need logarithmically many more calls to FindEdges to obtain witness matrices along with the distance products, making this simple method well-suited for our approach. More precisely, we can compute W 2,\u22c6 with a witness matrix using \u2308 log (\n2n \u00b7maxi,j{W 2,\u22c6ij <\u221e} )\u2309\n. calls to FindEdges. We obtain the following corollary to proposition 4.3 to characterize the exact number of rounds needed:\nCorollary 4.6. If FindEdges on an n-node integer-weighted graph G = (V,E,W ) can be solved in T (n) rounds, then the distance product square W 2,\u22c6, along with a witness matrix H , can be computed in T (3n) \u00b7 \u2308log2(n \u00b7 maxv,z\u2208V {minu\u2208V {Wvu +Wuz}}+ n)\u2309 rounds.\nProof. This follows from claim 1 and proposition 4.3 upon observing that maxv,z\u2208V {minu\u2208V {W \u2032vu +W \u2032\u2032uz)}} \u2264 n \u00b7maxv,z\u2208V {minu\u2208V {Wvu +Wuz}}+ n.\nOnce we obtain witness matrices along with the distance product computations, constructing the routing tables for each node along the way of computing APSP is straightforward. In each squaring of W in Eq. (4.2), each node updates its routing table entries according to the corresponding witness matrix entry observed. It is worth noting that these routing table entries need only be stored and accessed classically so that we avoid using unnecessary quantum data storage."
        },
        {
            "heading": "4.4 Triangle Finding",
            "text": "Given the results from sections 4.3 and 4.2, we have reduced finding both the routing tables and distance product to having each edge learn the edges involved in a negative triangle in the graph. This section will thus describe the procedure to solve the FindEdges subroutine. We state here a central result from (Izumi & Gall, 2019):\nProposition 4.7. There exists an algorithm in the quantum CONGEST-CLIQUE model that solves the FindEdges subroutine in O\u0303(n1/4) rounds.\nWe will proceed to describe each step of the algorithm to describe the precise round complexity beyond the O\u0303(n1/4) to characterize the constants involved in the interest of assessing the future implementability of our algorithms.\nAs a preliminary, we give a message routing lemma of (Dolev et al., 2012) for the congested clique, which will be used repeatedly:\nLemma 4.8. Suppose each node in G is the source and destination for at most n messages of size O(log n) and that the sources and destinations of each message are known in advance to all nodes. Then all messages can be routed to their destinations in 2 rounds.\nWe introduce the subproblem FindEdgesWithPromise (FEWP henceforth). Let \u0393(u, v) denote the number of nodes w \u2208 V such that (u, v, w) forms a negative triangle in G.\nFEWP\nInput: An integer-weighted graph G = (V,E,W ) distributed among the nodes and a set S \u2282 P(V ), with each node v knowing NG(v) and S. Promise: For each uv \u2208 S,\u0393(u, v) \u2264 90 log n. Output: For each node v, its output is the edges vu \u2208 S that satisfy \u0393(u, v) > 0.\nWe give here a description of the procedure of (Izumi & Gall, 2019) to solve FindEdges given an algorithm A to solve FEWP. Let \u03b5A be the failure probability of the algorithm A for an instance of FEWP.\nFindEdgesViaFEWP\n1: S := P ;M := \u2205; i := 0. 2: WHILE 60 \u00b7 2i log n \u2264 n:\na): Each node samples each of its edges with probability \u221a\n60\u00b72i logn n , so that we obtain a distributed\nsubgraph G\u2032 of G consisting of the sampled edges\nb): Run A on (G\u2032, S). Denote the output by S\u2032. c): S \u2190 S \\ S\u2032;M \u2190M \u222a S; i\u2190 i+ 1.\n3: Run A on (G,S), and call S\u2032\u2032 the output. 4: Output M \u222a S.\nFrom step 2 of this above algorithm, it is straightforward to check that this requires a maximum of cn := \u2308log ( n60 log n )\u2309 + 1 calls to the A subroutine to solve FEWP. Further, it succeeds with probability at least 1 \u2212 cn/n3 \u2212 cn/n28\u2212 (cn + 1)\u03b5A. We refer the reader to (Izumi & Gall, 2019, \u00a73) for the proof of correctness. We now turn toward constructing an efficient algorithm for FEWP.\nTo solve this subroutine, we must first introduce an additional labeling scheme over the nodes that will determine how the search for negative triangles will be split up to avoid communication congestion in the network. Assume for simplicity that n1/4, \u221a n, n3/4 are integers. LetM = [n1/4]\u00d7 [n1/4]\u00d7 [\u221an]. Clearly, |M| = n, andM admits a total ordering lexicographically. Since we assume each node vi \u2208 V is labeled with unique integer ID i \u2208 [n], vi can select the element in M that has place i in the lexicographic ordering of M without communication occurring. Hence, each node v \u2208 V is associated with a unique triple (i, j, k) \u2208 M. We will refer to the unique node associated with (i, j, k) \u2208 M as node v(i,j,k). The next ingredient is a partitioning scheme of the space of possible triangles. Let U be a partition of V into n1/4\nsubsets containing n3/4 nodes each, by taking Ui := {vj : j \u2208 {(i \u2212 1) \u00b7 n3/4, . . . , i \u00b7 n3/4}} for i = 1, . . . , n1/4, and U := {U1, . . . , Un14 }. Apply the same idea to create a partition U \u2032 of \u221a n sets of size \u221a n, by taking U \u2032i := {vj : j \u2208\n{(i \u2212 1) \u00b7 \u221an, . . . , i \u00b7 \u221an}} for i = 1, . . . ,\u221an, and U := {U1, . . . , U\u221an}. Let V = U \u00d7 U \u00d7 U \u2032. Each node v(i,j,k) can then locally determine its association with the element (Ui, Uj , U \u2032 k) \u2208 V since |V| = n. Further, if we use one round to have all nodes broadcast their IDs to all other nodes, each node v(i,j,k) can locally compute the (Ui, Uj , U \u2032 k) it is assigned to, so this assignment can be done in one round. We present here the algorithm ComputePairs used to solve the FEWP subroutine.\nComputePairs\nInput: An integer-weighted graph G = (V,E,W ) distributed among the nodes, a partition of V \u00d7 V \u00d7 V of (Ui, Uj , U \u2032 k) associated with each node as above, and a set S \u2282 P(V ) such that for uv \u2208 S,\u0393(u, v) \u2264 90 log n. Output: For each node v, its output is the edges vu \u2208 S that satisfy \u0393(u, v) > 0. 1: Every node v(i,j,k) receives the weights Wuv, Wvw for all uv \u2208 P(Ui, Uj) and vw \u2208 P(Uj , U \u2032k). 2: Every node v(i,j,k) constructs the set \u039bk(Ui, Uj) \u2282 P(Ui, Uj) by selecting every uv \u2208 P(Ui, Uj) with\nprobability 10 \u00b7 log n\u221a n . If |{v \u2208 U1 : uv \u2208 \u039bk(Ui, Uj)}| > 100n1/4 log n for some u \u2208 Uj , abort the algorithm and report failure. Otherwise, v(i,j,k) keeps all pairs uv \u2208 \u039bk(Ui, Uj) \u2229 S and receives the weights Wuv for all of those pairs. Denote those elements of \u039bk(Ui, Uj) \u2229 S as uk1vk1 , . . . , ukmvkm. 3: Every node v(i,j,k) checks for each l \u2208 [m] whether there is some U \u2208 U \u2032 that contains a node w such that (ukl , v k l , w) forms a negative triangle, and outputs all pairs u k l v k l for which a negative triangle was found.\nWith probability at least 1 \u2212 2/n, the algorithm ComputePairs does not terminate at step 2 and every pair (u, v) \u2208 S appears in at least one \u039bk(Ui, Uj). The details for this result can be found in (Izumi & Gall, 2019, Lemma 2).\nStep 1 requires 2n1/4\u2308 logW log n \u2309 rounds and can be implemented fully classically without any qubit communication. Step 2 requires at most 200 log n\u2308 logW log n \u2309 rounds and can also be implemented classically. Step 3 can be implemented in O\u0303(n1/4) rounds quantumly taking advantage of distributed Grover search but would take O(\u221an) steps to implement classically. The remainder of this section is devoted to illustrating how this step can be done in O\u0303(n1/4) rounds.\nDefine the following quantity:\nDefinition 4.9. For node v(i,j,k), let\n\u2206(i, j, k) := {(u, v) \u2208 P(Ui, Uj) \u2229 S : \u2203w \u2208 U \u2032k with (u, v, w) forming a negative triangle in G}\nFor simultaneous quantum searches, we divide the nodes into different classes based on the number of negative triangles they are a part of with the following routine:\nIdentifyClass\nInput: An integer-weighted graph G = (V,E,W ) distributed among the nodes, and a set S \u2282 E as in FEWP. Output: For each node v, a class \u03b1 the node belongs to.\n1: Every node u(i,j,k) \u2208 V samples each node in {v \u2208 V : (u(i,j,k), v) \u2208 S} with probability 10 log nn , creating a set \u039b(u) of sampled vertices. If maxu |\u039b(u)| > 20 log n, abort the algorithm and report a failure. Otherwise, have each node broadcast \u039b(u) to all other nodes, and take R := \u222au\u2208V {uv|v \u2208 \u039b(u)}. 2: Each v(i,j,k) \u2208 V computes di,j,k := |{uv \u2208 P(i, j) \u2229 R : \u2203w \u2208 U \u2032k such that {u, v, w} forms a negative triangle in G}|, then determines its class \u03b1 to be min{c \u2208 N : di,j,k < 10 \u00b7 2c log n}.\nThis uses at most 20 log n rounds (each node sends at most that many IDs to every other node) and can be implemented by having all exchanged messages consist only of classical bits. Using Chernoff\u2019s bound, one can show that the procedure succeeds with probability of at least 1\u2212 1/n as seen in (Izumi et al., 2020, Proposition 5).\nLet us make the convenient assumption that \u03b1 = 0 for all vi,j,k, which avoids some technicalities around congestion in the forthcoming triangle search. Note that \u03b1 \u2264 1\n2 log n, so we can run successive searches for each \u03b1 for nodes\nin with class \u03b1 in the general case. The general case is discussed in \u00a78.2 of the appendix and can also be found in (Izumi & Gall, 2019), but this case is sufficient to convey the central ideas.\nWe have all the necessary ingredients to describe the implementation of step 3 of the ComputePairs procedure.\n3.1: Each node executes the IdentifyClass procedure.\n3.2: For each \u03b1, for every l \u2208 [m], every node v(i,j,k) in class \u03b1 executes a quantum search to find whether there is a U \u2032k \u2208 U \u2032 with some w \u2208 U \u2032k forming a negative triangle (ukl , vkl , w) in G, and then reports all the pairs ukl v k l for which such a U \u2032 k was found.\nThis provides the basis of the triangle-searching strategy. To summarize the intuition of the asymptotic speedup in this paper: Since the U \u2032k have size \u221a n (recall that |U \u2032| = \u221an), if each node using a quantum search can search through its assigned U \u2032k in O\u0303(n1/4) rounds, simultaneously, we will obtain our desired complexity. We will complete this argument in \u00a74.6 and first describe the quantum searches used therein in the following subsection."
        },
        {
            "heading": "4.5 Distributed Quantum Searches",
            "text": "With this intuition in mind, we now state two useful theorems of (Izumi & Gall, 2019) for the distributed quantum searches. Let X denote a finite set throughout this subsection.\nTheorem 4.10. Let g : X \u2192 {0, 1}, if a node u can compute g(x) in r rounds in the CONGEST-CLIQUE model for any x \u2208 X, then there exists an algorithm in the Quantum CONGEST-CLIQUE that has u output some x \u2208 X with g(x) = 1 with high probability using O\u0303(r \u221a |X|) rounds.\nThis basic theorem concerns only single searches, but we need a framework that can perform multiple simultaneous searches. Let g1, . . . , gm : X \u2192 {0, 1} and\nA0i := {x \u2208 X : gi(x) = 0}, A1i := {x \u2208 X : gi(x) = 1}, \u2200i \u2208 [m].\nAssume there exists an r-round classical distributed algorithm Cm that allows a node u upon an input \u03c7 = (x1, . . . , xm) \u2208 Xm to determine and output (g1(x1), . . . , gm(xm)). In our use of distributed searches, X will consist of nodes in the network, and searches will need to communicate with those nodes for which the functions gi are evaluated. To avoid congestion, we will have to consider those \u03c7 \u2208 Xm that have many repeated entries carefully. We introduce some notation for this first. Define the quantity\n\u03b1(\u03c7) := max I\u2282[m]\n|{\u03c7i = \u03c7j \u2200i, j \u2208 I}|,\nthe maximum number of entries in \u03c7 that are all identical. Next, given some \u03b2 \u2208 N, assume that in place of Cm we now have a classical algorithm C\u0303m,\u03b2 such that upon input \u03c7 = (x1, . . . , xm) \u2208 Xm, a node u outputs g1(x1), . . . , gm(xm) if \u03b1(\u03c7) \u2264 \u03b2 and an arbitrary output otherwise. The following theorem summarizes that such a C\u0303m,\u03b2 with sufficiently large \u03b2 is enough to maintain a quantum speedup as seen in the previous theorem:\nTheorem 4.11. For a set X with |X| < m/(36 logm), suppose there exists such an evaluation algorithm Cm,\u03b2 for some \u03b2 > 8m/|X| and that \u03b1(\u03c7) \u2264 \u03b2 for all \u03c7 \u2208 A11\u00d7 \u00b7 \u00b7 \u00b7\u00d7A1m. Then there is a O\u0303(r \u221a\n|X|)-round quantum algorithm that outputs an element of A11 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7A1m with probability at least 1\u2212 2/m2.\nThe proof can be found in (Izumi & Gall, 2019, Theorem 3)."
        },
        {
            "heading": "4.6 Final Steps of the Triangle Finding",
            "text": "We continue here to complete the step 3.2 of the ComputePairs procedure, armed with Theorem 4.11. We need simultaneous searches to be executed by each node v(i,j,k) to determine the triangles in Ui \u00d7 Uj \u00d7 U \u2032k. We provide a short lemma first that ensures the conditions for the quantum searches:\nLemma 4.12. The following statements hold with probability at least 1\u2212 2/n2: (i): |\u2206(i, j, k)| \u2264 2n (ii): |\u039bk(Ui, Uj) \u2229\u2206(i, j, k)| \u2264 100 \u00b7 \u221a n log n for i, j \u2208 [n1/4].\nThe proofs of these statements are technical but straightforward, making use of Chernoff\u2019s bound and union bounds; hence we skip them here. To invoke Theorem 4.11, we describe a classical procedure first, beginning with an evaluation step, EvaluationA implementable in O\u0303(1) rounds.\nEvaluationA Input: Every node v(i,j,k) receives m elements (u i,j,k 1 , . . . , u i,j,k m ) of U \u2032\nPromise: For every node vi,j,k and every w \u2208 U \u2032, |Li,j,kw | \u2264 800 \u221a n log n. Output: Each node outputs a list of exactly those ui,j,kl such that there is a negative triangle in Ui\u00d7Uj \u00d7ui,j,kl . 1. Every node v(i,j,k), for each r \u2208 \u221a n routes the list Li,j,t w to node v(i,j,t).\n2. Every node v(i,j,k), for each vu it received in step 1, sends the truth value of the inequality\nmin w\u2208U\u2032\nk\n{Wuw +Wwv} \u2264Wvu (4.3)\nto the node that sent vu.\nEach node is the source and destination of up to 800n log n messages in step 1, meaning that this step can be implemented in 1600 log n rounds. The same goes for step 2, noting that the number of messages is the same, but they need only be single-bit messages (the truth values of the inequalities). Hence, the evaluations for Theorem 4.11 can be implemented in 3200 log n rounds. Now, applying the theorem with X = U \u2032, \u03b2 = 800\u221an log n, noting that then the assumptions of the theorem hold with probability at least 1 \u2212 2/n2 due to Lemma 4.12, implies that step 3.2 is implementable in O\u0303(n1/4) rounds, with a success probability of at least 1\u2212 2/m2.\nFor the general case in which we do not assume \u03b1 = 0 for all i, j, k in IdentifyClass, covered in the appendix, one needs to modify the EvaluationA procedure in order to implement load balancing and information duplication to avoid congestion in the simultaneous searches. These details can be found in the appendix, where a new labeling scheme and different evaluation procedure EvaluationB, are described for this, or in (Izumi & Gall, 2019)."
        },
        {
            "heading": "4.7 Complexity",
            "text": "As noted previously and in (Izumi & Gall, 2019), this APSP scheme uses O\u0303(n1/4) rounds. Let us characterize the constants and logarithmic factors involved to assess this algorithm\u2019s practical utility. Suppose that in each round, 2 \u00b7 log n qubits can be sent in each message (so that we can send two IDs or one edge with each message), where n is the number of nodes. For simplicity, let\u2019s assume that for the edge weights W \u226a n and drop W .\n1. APSP with routing tables needs log(n) distance products with witness matrices.\n2. Computing the ith distance product square for Eq. (4.2) with a witness matrix needs up to log ( 2i )\n= i calls to FindEdges, since the entries of the matrix being squared may double each iteration. Then APSP and distance products together make\n\u2211\u2308logn\u2309 i=1 i = \u2308log(n)\u2309(\u2308log(n)\u2309+1) 2 calls to FindEdges.\n3. Solving FindEdges needs log (\nn 60 log n\n)\ncalls to FEWP, using FindEdgesViaFEWP.\n4. Step 1 of ComputePairs needs up to 2 \u00b7 n1/4 rounds and step 2 takes up to 200 log n rounds. 5. Step 1 of IdentifyClass needs up to 20 log n rounds.\n6. In step 2 of IdentifyClass, the cuvw are up to 1 2 log n large, and hence \u03b1 may range up to 1 2 log n. 7. Step 0 of the EvaluationB procedure needs n1/4 rounds. Steps 1 and 2 of the EvaluationB (or EvaluationA, in the \u03b1 = 0 case) procedure use a total of 3200 log n rounds.\n8. EvaluationB (or EvaluationA) procedure is called up to log(n)n1/4 times for each value of \u03b1 in step 3.2 of ComputePairs.\nWithout any improvements, we get the following complexity, using 3n in place of n for the terms of steps 3-8 due to corollary 4.6:\n\u2308log(n)\u2309(\u2308log(n)\u2309+ 1) 2 log\n(\n3n\n60 log 3n\n)\n(\n2(3n)1/4 + 220 log 3n+ 2(3n)1/4+\n1 2 log 3n \u00b7 log 3n \u00b7 (3n)1/43200(log 3n) ) , (4.4)\nwhich we will call f(n), so that f(n) = O(n1/4 log6(n)), with the largest term being about 800 log6(n)n1/4, and we have droppedW to just consider the case W \u226a n. We can solve the problem trivially in the (quantum or classical) CONGEST-CLIQUE within n log(W ) rounds by having each node broadcast its neighbors and the weight on the\nedge. Let us again drop W for the case W \u226a n so that in order for the quantum algorithm to give a real speedup, we will need\nf(n) < n,\nwhich requires n > 1018 (even with the simpler under-approximation 800 log6(n)n1/4 in place of f). Hence, even with some potential improvements, the algorithm is impractical for a large regime of values of n even when compared to the trivial CONGEST-CLIQUE n-round strategy. For the algorithm of (Izumi & Gall, 2019) computing only APSP distances, the first term in 4.4 becomes simply \u2308log n\u2309, so that when computing only APSP distances the advantage over the trivial strategy begins at roughly n \u2248 1016.\nRemark 4.13. In light of logarithmic factors commonly being obscured by O\u0303 notation, we point out that even an improved algorithm needing only log4(n)n1/4 would not be practical unless n > 107, for the same reasons. Recall that n is the number of processors in the distributed network \u2013 tens of millions would be needed to make this algorithm worth implementing instead of the trivial strategy. Practitioners should mind the O\u0303 if applications are of interest, since even relatively few logarithmic factors can severely limit practicality of algorithms, and researchers should be encouraged to fully write out the exact complexities of their algorithms for the same reason."
        },
        {
            "heading": "4.7.1 Memory Requirements",
            "text": "Although in definition 2.1 we make no assumption on the memory capacities of each node, the trivial n-round strategy uses at least 2 log(n)|E|2 \u00b7 log(W ) memory at the leader node that solves the problem. For the APSP problem in question, using the Floyd-Warshall algorithm results in memory requirements of 2n2 log(n) \u00b7 log(nW ) at the leader node. Hence, we may ask whether the quantum APSP algorithm leads to lower memory requirements. The memory requirement is largely characterized by up to 720n7/4 log(n) log(nW ) needed in step 0 of the EvaluationB procedure, which can be found in the appendix. This results in a memory advantage for quantum APSP over the trivial strategy beginning in the regime of n > 1.6 \u00b7 1010."
        },
        {
            "heading": "4.7.2 Complexity of the Classical Analogue",
            "text": "For completeness, we provide here a characterization of the complexity of a closely related classical algorithm for APSP with routing tables in the CONGEST-CLIQUE as proposed in (Censor-Hillel et al., 2016) that has complexity O\u0303(n1/3). In their framework, the approach to finding witness matrices requires O(log(n)3) calls to the distance product (Censor-Hillel et al., 2016, \u00a73.4), and similarly to our approach log(n) distance products are required. Their classical algorithm computes distance products in O(n1/3) rounds, or under 2 log n message bandwidth in up to\n20n1/3 log(n)4 =: g(n) (4.5)\nrounds, the details of which can be found in the appendix, \u00a78.2.1. Then g(n) > n up until about n \u2248 2.6 \u00b7 1011. As with the quantum APSP, though this algorithm gives the best known asymptotic complexity of O\u0303(n1/3) in the classical CONGEST-CLIQUE, it also fails to give any real improvement over the trivial strategy across a very large regime of values of n. Consequently, algorithms making use of this APSP algorithm, such as (Saikia & Karmakar, 2019) or (Fischer & Oshman, 2021), suffer from the same problem of impracticality. However, the algorithm only requires within 4n4/3 log(n) log(nW ) + n log(n) log(nW ) memory per node, which is less than required for the trivial strategy even for n \u2265 4."
        },
        {
            "heading": "5 Approximately Optimal Steiner Tree Algorithm",
            "text": ""
        },
        {
            "heading": "5.1 Algorithm Overview",
            "text": "We present a high-level overview of the proposed algorithm to produce approximately optimal Steiner Trees, divided into four steps.\nStep 1 - APSP and Routing Tables: Solve the APSP problem as in (Izumi & Gall, 2019) and add an efficient routing table scheme via triangle finding in O\u0303(n1/4) rounds, with success probability (1\u2212 1/poly(n)) (this step determines the algorithm\u2019s overall success probability).\nStep 2 - Shortest-path Forest: Construct a shortest-path forest (SPF), where each tree consists of exactly one source terminal and the shortest paths to the vertices whose closest terminal is that source terminal. This step can be completed in one round and n messages, per (Saikia & Karmakar, 2019, \u00a73.1). The messages can be in classical bits.\nStep 3 - Weight Modifications: Modify the edge weights depending on whether they belong to a tree (set to 0), connect nodes in the same tree (set to \u221e), or connect nodes from different trees (set to the shortest path distance between root terminals of the trees that use the edge). This uses one round and n messages.\nStep 4 - Minimum Spanning Tree: Construct a minimum spanning tree (MST) on the modified graph in O(1) rounds as in (Nowicki, 2019), and prune leaves of the MST that do not connect terminal nodes since these are not needed for the Steiner Tree.\nThe correctness of the algorithm follows from the correctness of each step together with the analysis of the classical results of (Kou et al., 1981), which uses the same algorithmic steps of constructing a shortest path forest and building it into an approximately optimal Steiner Tree."
        },
        {
            "heading": "5.2 Shortest Path Forest",
            "text": "After the APSP distances and routing tables have been found, we construct a Shortest Path Forest (SPF) based on the terminals of the Steiner Tree.\nDefinition 5.1. (Shortest Path Forest): For a weighted, undirected graph G = (V,E,W ) together with a given set of terminal nodes Z = {z1, . . . , zk}, a subgraph F = (V,EF ,W ) of G is called a shortest path forest if it consists of |Z| disjoint trees Tz = (Vz, Ez,W ) satisfying\ni) zi \u2208 Tzj if and only if i = j, for i, j \u2208 [k]. ii) For each v \u2208 Zi, dG(v, zi) = minz\u2208Z dG(v, z), and a shortest path connecting v to zi in G is contained in Tzi iii) The Vzi form a partition of V , and Ez1 \u222aEz2 \u00b7 \u00b7 \u00b7 \u222a Ezk = EF \u2282 E\nIn other words, an SPF is a forest obtained by gathering, for each node, a shortest path in G connecting it to the closest Steiner terminal node.\nFor a node v in a tree, we will let par(v) denote the parent node of v in that tree, s(v) the Steiner Terminal in the tree that v will be in, and ID(v) \u2208 [n] the ID of node v \u2208 V . Let Q(v) := {z : dG(v, z) = minz\u2208Z dG(v, z)} be the set of Steiner Terminals closest to node v. We make use of the following procedure for the SPF:\nDistributedSPF\nInput: For each node v \u2208 G, APSP distances and the corresponding routing table Rv . Output: An SPF distributed among the nodes.\n1: Each node v sets s(v) := argminz\u2208Q(v)ID(z) using the APSP information.\n2: Each node v sets par(v) := Rv(s(v)), Rv being the routing table of v, and sends a message to par(v) to indicate this choice. If v receives such a message from another node u, it registers u as its child in the SPF.\nStep 1 in DistributedSPF requires no communication since each node already knows the shortest path distances to all other nodes, including the Steiner Terminals, meaning it can be executed locally. Each node v choosing par(v) in step 2 can also be done locally using routing table information, and thus step 2 requires 1 round of communication of n\u2212 |Z| classical messages, since all non-Steiner nodes send one message.\nClaim 2. After executing the DistributedSPF procedure, the trees Tzk = (Vzk , Ezk ,W ) with Vzk := {v \u2208 V : s(v) = zk} and Ezk := {v, par(v)} : v \u2208 Vzk} form an SPF.\nProof. i) holds since each Steiner Terminal is closest to itself. iii) is immediate. To see that ii) holds, note that for v \u2208 Vzk , par(v) \u2208 Vzk and {v, par(v)} \u2208 Ezk as well. Then par(par(. . . par(v) . . . )) = zk and the entire path to zk lies in Tzk .\nHence, after this procedure, we have a distributed SPF across our graph, where each node knows its label, parent, and children of the tree it is in."
        },
        {
            "heading": "5.3 Weight Modified MST and Pruning",
            "text": "Finally, we introduce a modification of the edge weights before constructing an MST on that new graph that will be pruned into an approximate Steiner Tree. These remaining steps stem from a centralized algorithm first proposed by (Kou et al., 1981) whose steps can be implemented efficiently in the distributed setting, as in (Saikia & Karmakar, 2019). We first modify the edge weights as follows:\nPartition the edges E into three sets \u2013 tree edges EF as in 5.1 that are part of the edge set of the SPF, intra-tree edges EIT that are incident on two nodes in the same tree Ti of the SPF, and inter-tree edges EXT that are incident on two nodes in different trees of the SPF. Having each node know which of these its edges belong to can be done in one round by having each node send its neighbors the ID of the terminal it chose as the root of the tree in the SPF that is a part of. Then the edge weights are modified as follows, denoting the modified weights as W \u2032:\n(i): For e = (u, v) \u2208 ET ,W \u2032(u, v) := 0 (ii): For e = (u, v) \u2208 EIT ,W \u2032(u, v) :=\u221e (iii): For e = (u, v) \u2208 EXT ,W \u2032(u, v) := d(u,Zu) +W (u, v) + d(v,Zv), noting that dG(u, s(u)) is the shortest-path distance in G from u to its closest Steiner Terminal.\nNext, we find a minimum spanning tree on the graph G\u2032 = (V,E,W \u2032), for which we may implement the classical O(1) round algorithm proposed by (Nowicki, 2019). On a high level, this constant-round complexity is achieved by sparsification techniques, reducing MST instances to sparse ones, and then solving those efficiently. We skip the details here and refer the interested reader to (Nowicki, 2019). After this step, each node knows which of its edges are part of this weight-modified MST, as well as the parent-child relationships in the tree for those edges.\nFinally, we prune this MST by removing non-terminal leaf nodes and the corresponding edges. This is done by each node v sending the ID of its parent in the MST to every other node in the graph. As a result, each node can locally compute the entire MST and then decide whether or not it connects two Steiner Terminals. If it does, it decides it is part of the Steiner Tree; otherwise, it broadcasts that it is to be pruned. Each node that has not been pruned then registers the edges connecting it to non-pruned neighbors as part of the Steiner Tree. This pruning step takes 2 rounds and up to n2 + n classical messages."
        },
        {
            "heading": "5.4 Overall Complexity and Correctness",
            "text": "In algorithm 5.1, after step 1, steps 2, and 3 can each be done within 2 rounds. Walking through (Nowicki, 2019) reveals that the MST for step 4 can be found in 54 rounds, with an additional 2 rounds sufficing for the pruning. Hence, the overall complexity remains dominated by Eq. (4.4). Hence, the round complexity is O\u0303(n1/4), which is faster than any known classical CONGEST-CLIQUE algorithm to produce an approximate Steiner tree of the same approximation ratio. However, as a consequence of the full complexity obtained in \u00a74.7, the regime of n in which this algorithm beats the trivial strategy of sending all information to a single node is also n > 1018. For the same reason, the classical algorithm provided in (Saikia & Karmakar, 2019) making use of the APSP subroutine from (Censor-Hillel et al., 2016) discussed in \u00a74.7.2 has its complexity mostly characterized by Eq. (4.5), so that the regime in which it provides an advantage over the trivial strategy lies in n > 1011. Our algorithm\u2019s correctness follows from the correctness of each step together with the correctness of the algorithm by (Kou et al., 1981) that implements these steps in a classical, centralized manner."
        },
        {
            "heading": "6 Directed Minimum Spanning Tree Algorithm",
            "text": "This section will be concerned with establishing Theorem 3.2 for the Directed Minimum Spanning Tree (DMST) problem, in definition 2.7. Like (Fischer & Oshman, 2021), we follow the algorithmic ideas first proposed by (Lovasz, 1985), implementing them in the quantum CONGEST-CLIQUE. Specifically, we will use log n calls to the APSP and routing tables scheme described in \u00a74, so that in our case, we retrieve complexity O\u0303(n1/4) and success probability (1\u2212 1\npoly(n) )log n = 1\u2212 1 poly(n) .\nBefore describing the algorithm, we need to establish some preliminaries and terminology for the procedures executed during the algorithm, especially the ideas of shrinking vertices into super-vertices and tracking a set H of specific edges as first described in (Edmonds et al., 1967). We use the following language to discuss super-vertices and related objects.\nDefinition 6.1. A super-vertex set V\u2217 := {V \u22171 , . . . , V \u2217t } for a graph G = (V,E,W ) is a partition of V , and each V \u2217i is called a super-vertex. We will call a super-vertex simple if V \u2217 is a singleton. The corresponding minor\nG\u2217 := (V\u2217, E\u2217,W \u2217) is the graph obtained by creating edges (V \u2217i , V \u2217 j ) with weight W \u2217(V \u2217i , V \u2217 j ) := min{W (vi, vj) : vi \u2208 V \u2217i , vj \u2208 V \u2217j }.\nNotably, we continue to follow the convention of an edge of weight \u221e being equivalent to not having an edge. We will refer to creating a super-vertex V \u2217 as contracting the vertices in V \u2217 into a super-vertex."
        },
        {
            "heading": "6.1 Edmonds\u2019 Centralized DMST Algorithm",
            "text": "We provide a brief overview of the algorithm proposed in (Edmonds et al., 1967), which presents the core ideas of the super-vertex-based approach. The following algorithm produces a DMST for G:\nEdmonds DMST Algorithm\nInput: An integer-weighted digraph and a root node r.\nOutput: A DMST for G rooted at r.\n1. Initialize a subgraph H with the same vertex set as G by subtracting for each node the minimum incoming edge weight from all its incoming edges, and selecting exactly one incoming zero-weight edge for each nonroot node of G. Set G0 = G,H0 = H, t = 0.\n2. WHILE Ht is not a tree:\n(a) For each cycle of H , contract the nodes on that cycle into a super-vertex. Consider all non-contracted nodes as simple super-vertices, and obtain a new graph Gt+1 as the resulting minor.\n(b) If there is a non-root node of Gt+1 with no incoming edges, report a failure. Otherwise, obtain a subgraph Ht+1 by, for each non-root node of Gt+1, subtracting the minimum incoming edge weight from all its incoming edges, and selecting exactly one incoming zero-weight edge for each non-root, updating t\u2190 t+ 1.\n3. Let Bt = Ht. FOR k \u2208 (t, t\u2212 1, . . . , 1): (a) Obtain B\u2032k\u22121 by expanding the non-simple super-vertices of Bk and selecting all but one of the edges\nfor each of the previously contracted cycles of Hk to add to Bk\u22121.\n4. Return B0.\nNote that the edge weight modifications modify the weight of all directed spanning trees equally, so optimality is unaffected. In step 2., if Ht is a tree, it is an optimal DMST for the current graph Gt. Otherwise, it contains at least one directed cycle, so that indeed step 2. is valid. Hence, at the beginning of step 3., Bt is a DMST for Gt. Then the first iteration produces Bt\u22121 a DMST for Gt\u22121 since only edges of zero weight were added, and Bt\u22121 will have no cycles. The same holds for Bt\u22122, Bt\u22123, . . . , B0, for which B0 corresponds to the DMST for the original graph G. If the algorithm reports a failure at some point, no spanning tree rooted at r exists for the graph, since a failure is reported only when there is an isolated non-root connected component in Gt+1.\nNote that in iteration t of step 2., H has one cycle for each of its connected components that does not contain the root node. Hence, the drawback of this algorithm is that we may apply up to O(n) steps of shrinking cycles. This shortcoming is remedied by a more efficient method of selecting how to shrink nodes into super-vertices in (Lovasz, 1985), such that only log n shrinking cycle steps take place."
        },
        {
            "heading": "6.2 Lovasz\u2019 Shrinking Iterations",
            "text": "We devote this subsection to discuss the shrinking step of (Lovasz, 1985) that will be repeated log n times in place of step 2. of Edmonds\u2019 algorithm to obtain Lovasz\u2019 DMST algorithm.\nLovasz\u2019 Shrinking Iteration LSI Input: A directed, weighted graph G = (V,E,W ) and a root node r \u2208 V . Output: Either a new graph G\u2217, or a success flag and a DMST H of G.\n1. If there is a non-root node of G with no incoming edges, report a failure. Otherwise, for each non-root node of G, subtract the minimum incoming edge weight from all its incoming edges. Select exactly one incoming zero-weight edge for each non-root node to create a subgraph H of G with those edges.\n2 Find all cycles of H , and denote them H1, . . . , HC . If H has no cycles, abort the iteration and return (SUCCESS, H). For j = 1, . . . , C, find the set Vj of nodes that dipaths in H from Hj can reach.\n3. Compute the All-Pairs-Shortest-Path distances in G.\n4. For each node v \u2208 V , denote dj(v) := min{d(v, u) : u \u2208 Hj}. For each j = 1, . . . , C, set \u03b2j := min{dj(v) : v \u2208 V (G) \\ Vj} and Uj := {u \u2208 Vj : dj(u) \u2264 \u03b2j}. 5. Create a minor G\u2217 by contracting each Uj into a super-vertex U\u2217j , considering all other vertices of G as simple super-vertices V \u22171 , . . . , V \u2217 k . For each vertex N \u2217 of G\u2217, let the edge weights in G\u2217 be:\nW \u2217N\u2217U\u2217 j = min{Wvu : v \u2208 N\u2217, u \u2208 U\u2217j } \u2212 \u03b2j +min{dj(u) : u \u2208 U\u2217j } for all j = 1, . . . , C, and W \u2217N\u2217V \u2217 = min{WvV \u2217 : v \u2208 N\u2217} for all the simple super-vertices V \u2217 of G\u2217.\n6. Return G\u2217.\nTo summarize these iterations: The minimum-weight incoming edge of each node is selected. That weight is subtracted from the weights of every incoming edge to that node, and one of those edges with new weight 0 is selected for each node to create a subgraph H . If H is a tree, we are done. Otherwise, we find all cycles of the resulting directed subgraph, then compute APSP and determine the Vj , Uj , and \u03b2j , which we use to define a new graph with some nodes of the original G contracted into super-vertices.\nThe main result for the DMST problem in (Lovasz, 1985) is that replacing (a) and (b) of step 2. in the Edmonds DMST Algorithm, taking the new H obtained at each iteration to be Ht+1 and the G\n\u2217 to be Gt+1, leads to no more than \u2308log n\u2309 such shrinking iterations needed before a success is reported."
        },
        {
            "heading": "6.2.1 Quantum Distributed Implementation",
            "text": "Our goal is to implement the Lovasz iterations in the quantum distributed setting in O\u0303(n1/4) rounds by making use of quantum APSP of \u00a74. In the distributed setting, processor nodes cannot directly be shrunk into super-vertices. As in (Fischer & Oshman, 2021), we reconcile this issue by representing the super-vertex contractions within the nodes through soft contractions.\nFirst, note that a convenient way to track what nodes we want to consider merging into a super-vertex is to keep a mapping sID : V \u2192 S, where S is a set of super-vertex IDs, which we can just take to be the IDs of the original nodes. We will refer to a pair of (G, sID) as an annotated graph. An annotated graph naturally corresponds to some minor of G, namely, the minor obtained by contracting all vertices sharing a super-vertex ID into a super-vertex.\nDefinition 6.2 (Soft Contractions). For an annotated graph (G, sID), a set of active edges H , and active component Hi with corresponding weight modifiers \u03b2i, and a subset A \u2282 S of super-vertices, the soft contraction of Hi in G is the annotated graph (GHi , sID\u2032) obtained by taking GHi = (V,E,W \u2032) with\n\u2022 W \u2032uv = 0 if sID(u) = sID(v) \u2022 W \u2032uv =Wuv + distG(A)(v, C(Hi))\u2212 \u03b2i if u \u2208 V \\A and v \u2208 A \u2022 W \u2032uv =Wuv otherwise\nand updating the mapping sID to sID\u2032 defined by sID\u2032(v) = sID(v),\u2200v /\u2208 A, sID\u2032(v) = min{sID(u) : u \u2208 A}."
        },
        {
            "heading": "6.2.2 Quantum Distributed Lovasz\u2019 Iteration",
            "text": "We provide here a quantum distributed implementation of Lovasz\u2019 iteration that we will form the core of our DMST algorithm.\nQuantum Distributed Lovasz\u2019 Iteration QDLSI Input: A directed, weighted, graph G = (V,E,W ) with annotations sID and a subgraph H . Output: A new graph G\u2217 with annotations sID\u2032, or a success flag and a DMST H of G.\n1: Have all nodes learn all edges of H , as well as the current super-vertices.\n2: For each connected component Hi \u2282 H , denote by C(Hi) the cycle of Hi. Let c(Hi) be the node with maximal ID in C(Hi), which each node can locally compute.\n3: Run the quantum algorithm for APSP and routing tables described in \u00a74 on this graph, or report a failure if it fails.\n4: For each i, determine an edge viui, vi /\u2208 Hi, ui \u2208 Hi minimizing \u03b2i :=Wviui+dG(ui, c(Hi)), and broadcast both to all nodes in Hi.\n5: Each node vi in each Hi applies the following updates locally:\n\u2013 Soft-contract Hi at level \u03b2i to soft-contract all super-vertices with distance \u03b2i to C(Hi) into one super-vertex, with each contracted node updating its super-vertex ID to c(Hi)\n\u2013 add edge viui to H , effectively merging Hi with another active component of H\nWe can follow exactly the steps of Lovasz\u2019s DMST algorithm, distributedly by replacing steps 2-5 of the LSI with this quantum-distributed version. The following ensues:\nLemma 6.3. If none of the APSP and routing table subroutines fail, within \u2308log n\u2309 iterations of the QDLSI, H is a single connected component.\nLemma 6.4. With probability (1\u2212 1 poly(n) )logn, all the APSP and routing table subroutines in step 3 succeed.\nLemmas 6.3 and 6.4 then together imply Theorem 3.2. Within \u2308log n\u2309 iterations, only one active component remains: the root component. This active component can then be expanded to a full DMST on G within \u2308log n\u2309 rounds, as detailed in (Fischer & Oshman, 2021, \u00a77) or the Unpacking procedure in \u00a78.3 of the appendix. All messages in the algorithm other than those for computing the APSP in QDLSI may be classical. We provide here the full algorithm for completeness:\nQuantum DMST Algorithm\nInput: An integer-weighted digraph and a root node r.\nOutput: A DMST for G rooted at r.\n1. Initialize a subgraph H with the same vertex set as G by subtracting for each node the minimum incoming edge weight from all its incoming edges, and selecting exactly one incoming zero-weight edge for each nonroot node of G. Set t = 0, H0 = H , and G0 = G with annotations sID0 to be the identity mapping.\n2. WHILE: Ht is not a single component\n(a) Run QDLSI with inputs Ht, (Gt, sIDt) to obtain Ht+1, (Gt+1, sIDt+ 1) as outputs. Increment t\u2190 t+ 1.\n3. Let Tt := Ht. For k = t, . . . , 1: For each super-vertex of the k th iteration of QDLSI applied, simultaneously\nrun the Unpacking procedure with input tree Tk to obtain Tk\u22121.\n4. Return T0 as the distributed minimum spanning tree."
        },
        {
            "heading": "6.3 Complexity",
            "text": "In the QDLSI, all steps other than the APSP step 3 of the quantum Lovasz iteration can be implemented within 2 rounds. In particular, to have all nodes know some tree on G for which each node knows its parent, every node can simply broadcast its parent edge and weight. Since this iteration is used up to \u2308log(n)\u2309 times and expanding the DMST at the end of the algorithm also takes logarithmically many rounds, we obtain a complexity dominated by the APSP computation of O\u0303(n1/4), a better asymptotic rate than any known classical CONGEST-CLIQUE algorithm. However, beyond the O\u0303, the complexity is largely characterized by log(n) \u00b7 f(n), with f(n) as in Eq. (4.4). In order to have log(n)f(n) < n to improve upon the trivial strategy of having a single node solve the problem, we then need n > 1021. Using the classical APSP from (Censor-Hillel et al., 2016) in place of the quantum APSP of \u00a74 as done in\n(Fischer & Oshman, 2021) to attain the O\u0303(n1/3) complexity in the cCCM, one would need log(n) \u00b7 g(n) < n to beat the trivial strategy, with g as in Eq. (4.5), or more than n > 1014."
        },
        {
            "heading": "7 Discussion and Future Work",
            "text": "We have provided algorithms in the Quantum CONGEST-CLIQUE model for computing approximately optimal Steiner Trees and exact Directed Minimum Spanning trees that use asymptotically fewer rounds than their classical known counterparts. As Steiner Tree and Minimum Spanning Trees cannot benefit from quantum communication in the CONGEST (non-clique) model, the algorithms reveal how quantum communication can be exploited thanks to the CONGEST-CLIQUE setting. A few open questions remain as well. In particular, there exist many generalizations of the Steiner Tree problem, so these may be a natural starting point to attempt to generalize the results. A helpful overview of Steiner-type problems can be found in (Hauptmann & Karpinski, 2015). Regarding the DMST, it may be difficult to generalize a similar approach to closely related problems. Since the standard MST can be solved in a (relatively small) constant number of rounds in the classical CONGEST-CLIQUE, no significant quantum speedup is possible. Other interesting MST-type problems are the bounded-degree and minimum-degree spanning tree problems. However, even the bounded-degree decision problem on an unweighted graph, \u201cdoes G have a spanning tree of degree at most k?\u201d is NP-complete, unlike the DMST, so we suspect that other techniques would need to be employed. (Dinitz, Halldorsson, Izumi, & Newport, 2019) provides a classical distributed approximation algorithm for the problem. Additionally, we have traced many constants and log factors throughout our description of the above algorithms, which, as shown, would need to be significantly improved for these and related algorithms to be practical. Hence, a natural avenue for future work is to work towards such practical improvements. Beyond the scope of the particular algorithms involved, we hope to help the community recognize the severity with which the practicality of algorithms is affected by logarithmic factors that may be obscured by O\u0303 notation, and thus encourage fellow researchers to present the full complexity of their algorithms beyond asymptotics. Particularly in a model like CONGEST-CLIQUE, where problems can always be solved trivially in n rounds, these logarithmic factors should clearly not be taken lightly. Further, a question of potential practical interest would be to ask the following: What algorithms solving the discussed problems are the most efficient with respect to rounds needed in the CONGESTCLIQUE in the regimes of n in which the discussed algorithms are impractical?"
        },
        {
            "heading": "Acknowledgements",
            "text": "We are grateful for support from the NASA Ames Research Center, from the NASA SCaN program, and from DARPA under IAA 8839, Annex 130. PK and DB acknowledge support from the NASA Academic Mission Services (contract NNA16BD14C). The authors thank Ojas Parekh for helpful input and discussions regarding the arborescence problem, Shon Grabbe for ongoing useful discussions, and Filip Maciejewskifor for helpful feedback on the work."
        },
        {
            "heading": "8 Appendix",
            "text": ""
        },
        {
            "heading": "8.1 Proof of claim 1",
            "text": "For an n\u00d7 n integer matrix W , obtain matrices W \u2032 and W \u2032\u2032 by taking W \u2032ij = nWij + j \u2212 1 and W \u2032\u2032ji = nWji. Set D =W \u2032 \u22c6 W \u2032\u2032. We aim to show that \u230a D\nn\n\u230b\n=W 2,\u22c6 and (D mod n) + 1 is a witness matrix for W 2,\u22c6.\nProof.\n(i) We have\n\u230a\nD\nn\n\u230b\nij\n=\n\u230a\nmin k\u2208[n]\n{nWik + k \u2212 1 + nWkj} /n \u230b = \u230a\nmin k\u2208[n]\n{\nWik +Wkj + k \u2212 1 n\n}\u230b\n=W 2ij +\n\u230a\nmin k\u2208[n]\n{\nk \u2212 1 n :Wik +Wkj =W 2 ij\n}\u230b\n=W 2ij .\n(ii) Next,\nDij = nW 2 ij +\n\u230a\nmin k\u2208[n]\n{ k \u2212 1 :Wik +Wkj =W 2ij }\n\u230b\ngives us\n(D mod n) + 1 =\n\u230a\nmin k\u2208[n]\n{ k \u2212 1 :Wik +Wkj =W 2ij }\n\u230b\n+ 1 = min k\u2208[n]\n{\nk :Wik +Wkj = W 2 ij\n}\n,\nwhich proves the claim."
        },
        {
            "heading": "8.2 The \u03b1 \u00bf 0 case",
            "text": "The strategy will be to assign each v(i,j,k) \u2208 V into classes in accordance with approximately how many negative triangles are in Ui \u00d7 Uj \u00d7 U \u2032k before starting the search.\nTo assign each node to a class, we use the routine IdentifyClass of (Izumi & Gall, 2019), also described in the main text.\nThe main body of this paper discussed the special case assuming \u03b1 = 0. Hence we now consider the \u03b1 > 0 case. For each \u03b1 \u2208 N, let us denote ci,j,k the smallest nonnegative integer satisfying di,j,k < 10 \u00b7 2c log n, and\nV\u03b1 := {v(i,j,k) : ci,j,k = \u03b1} (8.1) V\u03b1[i, j] := {U \u2032k \u2208 U \u2032 : v(i,j,k) \u2208 V\u03b1} (8.2)\nfor any i, j \u2208 [n1/4]. Notably, P(i, j) contains at most \u221an edges, so that di,j,k \u2264 \u221a n as well. Hence, c = 1\n2 log n\nprovides an upper bound for the minimum in step 2. The important immediate consequence is that we only need to consider V\u03b1 up to at most \u03b1 =\n1 2 log n.\nLemma 8.1. The IdentifyClass algorithm and the resulting V\u03b1 satisfy the following statements with probability at least 1\u2212 2/n: (i): The algorithm does not abort\n(ii): |\u2206(i, j, k)| \u2264 2n (iii): For \u03b1 > 0, v(i,j,k) \u2208 V\u03b1, we have 2\u03b1\u22123n \u2264 |\u2206(i, j, k)| \u2264 2\u03b1+1n. (iv): |\u039bx(i, j) \u2229\u2206(i, j, k)| \u2264 100 \u00b7 2\u03b1 \u221a n log n for i, j \u2208 [n1/4] and \u03b1 \u2208 N.\nThis provides an adapted version of lemma 4.12 for the \u03b1 > 0 case. The following lemma provides a tool that will allow for \u201dduplication\u201d of information to avoid message congestion\nin the network in the EvaluationB procedure.\nLemma 8.2. For all \u03b1 \u2265 0 and i, j \u2208 [n1/4],\n|V\u03b1[i, j]| \u2264 720 \u221a n log n\n2\u03b1 (8.3)\nProof. The \u03b1 = 0 case is immediate since |U \u2032| = \u221an, so consider \u03b1 \u2265 1. The \u201cpromise\u201d in the FEWP subroutine we are in guarantees that for all (u, v) \u2208 S,\u0393(u, v) \u2264 90 log n, so that for any i, j \u2208 [n1/4], each edge in P(Ui, Uj)\u2229S has at most 90 log n other nodes forming a negative triangle with it, leading to the inequality\n\u2211\nk:v(i,j,k)\u2208V\u03b1 |\u2206(i, j, k)| \u2264 90n3/2 log n.\nUsing |\u2206(i, j, k)| \u2265 2\u03b1\u22123n from part (i) of lemma 8.1, the conclusion follows.\nWe now describe the implementation of step 3 of the ComputePairs procedure for the \u03b1 > 0 case.\n3.1: Each node executes the IdentifyClass procedure.\n3.2: For each \u03b1: For every l \u2208 [m], every node v(i,j,k) executes a quantum search to find whether there is a U \u2032k \u2208 V\u03b1[Ui, Uj ] with some w \u2208 U \u2032k forming a negative triangle (ukl , vkl , w) in G, and then reports all the pairs ukl vkl for which such a U \u2032k was found.\nThe \u03b1 = 0 case was described in the main text. We proceed to describe the classical procedure for invoking theorem 4.11 to obtain the speedup for the general \u03b1 case, as in (Izumi & Gall, 2019, \u00a75.3.2). Some technical precautions must be taken to avoid congestion of messages between nodes. This crucially relies on information duplication to effectively increase bandwidth between nodes. Lemma 8.2 provides a strong bound for the size of each V\u03b1. For this duplication of the information stored by the relevant nodes, a new labeling scheme is convenient. Suppose for simplicity that C\u03b1 := 2\n\u03b1/(720 log n) is an integer, and assign each node a label (u,v,w, y) \u2208 V\u03b1 \u00d7 [C\u03b1], which is possible due to the bound of lemma 8.2. The following EvaluationB implementable in O(log n) rounds (using a slightly sharper complexity analysis than (Izumi & Gall, 2019)) can then be used for invoking theorem 4.11:\nEvaluationB Input: A list (wk1 , . . . ,w k m) of elements of V\u03b1[u,v] assigned to each node k = (u,v, x).\nPromise: |Lk w | \u2264 800 \u00b7 2\u03b1\u221an log n for each node k and all |w \u2208 V\u03b1[u,v]. Output: Every node k = (u,v, x) outputs for each \u2113 \u2208 [m] whether some w \u2208 wkl forms a negative triangle {uk\u2113 , vk\u2113 , w}.\n0. Every node (u,v,w) \u2208 V\u03b1 broadcasts the edge information loaded in step 1 of ComputePairs to (u,v,w, y) for each y \u2208 [C\u03b1].\n1. Every node (u,v, x) splits each Lk w into smaller sublists Lk w,1, . . . , L k w,C\u03b1 for each w, with each sublist\ncontaining up to \u2308|Lk w |/C\u03b1\u2309 = \u2308800\u00b7720 \u221a n log2 n\u2309 elements,and sends each Lk\nw,y to node (u,v,w, y) along with the relevant edge weights.\n2. Every (u,v,w, y) node returns the truth value\nmin w\u2208w {Wuw +Wwv} \u2264Wvu\nto node k for each uv \u2208 Lk w,y received in step 1.\nFor each value of \u03b1, we separately solve step 3.2 of the ComputePairs procedure. Since lemma 8.2 tells us that there are C\u03b1 times more nodes not in V\u03b1 than there are in V\u03b1, every node in V\u03b1 can use C\u03b1 of those nodes not in V\u03b1 to relay messages and effectively increase its message bandwidth, which is exactly what EvaluationB takes advantage of. Steps 1 and 2 of the procedure take up to 2 \u00b7 \u2308|Lk w |\u2309/n \u2264 1600 \u00b7 log n rounds, since lists of size \u2308|Lk w |/C\u03b1\u2309 are sent to C\u03b1 nodes, and the bound on \u03b1 gives \u2308|Lkw|\u2309 \u2264 800n log(n)."
        },
        {
            "heading": "8.2.1 Complexity of the Classical Analogue",
            "text": "This subsection of the appendix serves to provide some supplemental information to \u00a74.7.2 discussing the complexity of an algorithm for APSP with routing tables in the CONGEST-CLIQUE as proposed in (Censor-Hillel et al., 2016) that has complexity O\u0303(n1/3). Note that (Censor-Hillel et al., 2016, corollary 6) applied to APSP distance computations only, whereas the routing table computations are discussed in (Censor-Hillel et al., 2016, \u00a73.4). As shown there, O(log3) distance products (without witnesses) are needed to compute one distance product with a witness matrix. More precisely:\n1. Obtaining a witness matrix when witnesses are unique requires log(n) distance products.\n2. The procedure for finding witnesses in the general case calls the procedure to find witnesses in the unique witness case O(log2 n) times, or 2 \u00b7 log2 n times if c = 2 is deemed as sufficient for the success probability.\n3. log n such distance products with witnesses are needed for the APSP algorithm with routing tables.\nThen 2 log4 n distance products are computed in total for one distance product with witnesses. The distance product via the semi-ring matrix multiplication algorithm of (Censor-Hillel et al., 2016, \u00a72.1) uses 10n1/3 rounds (4n1/3 for its steps 1 and 2, and 2n1/3 for step 3) using lemma 4.8, and hence one obtains the full round complexity of\n10n1/3 \u00b7 2 log(n)4 = g(n). (8.4)"
        },
        {
            "heading": "8.3 Expanding the DMST in the Distributed Setting",
            "text": "We handle the expansion of the DMST in the same way as in (Fischer & Oshman, 2021, \u00a77), borrowing much of their discussion for our description here. However, as we have computed APSP distances along the way in place of SSSP, \u2018unpacking\u2019 the DMST becomes a bit simpler in our case. Consider a component Hi in one of the iterations of QDLSI, with input graph for the iteration being Gi. For each contraction in QDLSI, we determined edges viui, vi /\u2208 Hi, ui \u2208 Hi minimizing \u03b2i := Wviui + dG(ui, c(Hi)) to contract nodes. Recall that what happens in the iteration is that the cycle c(Hi) and all nodes that have distance \u03b2i to c(Hi) are contracted into one super-vertex. Denote that super-vertex by V \u2217Hi,\u03b2i . Let Gi+1 denote the graph obtained after this contraction. Then our goal, given a DMST Ti+1 for Gi+1, is to recover Gi along with a DMST Ti for Gi. We make use of the following Unpacking operation of (Fischer & Oshman, 2021, \u00a77):\nUnpacking\nInput: A digraph Gi+1 with a DMST Ti+1 with root r, a set of edges Hi as in Quantum DMST Algorithm, a node V \u2217Hi,\u03b2i of GI+1 marked as a super-vertex, a set c(Hi) of the nodes contracted into it, and Gi the graph before contracting c(Hi).\nOutput: A DMST Ti for Gi rooted at r.\n1: For any v1, v2 /\u2208 V \u2217Hi,\u03b2i , let edge v1v2 \u2208 Ti iff v1v2 \u2208 Ti+1. 2: For uV \u2217Hi,\u03b2i \u2208 Ti+1, which exists since Ti+1 is a DMST for Gi+1, denote the edge\nuv\u2217 := argminuv:v\u2208V \u2217 Hi,\u03b2i ,u:\u2203uv\u2208Gi+1Wvu + dG(u, c(Hi)). Add uv \u2217 and the shortest path \u03b6 connecting v\u2217 to c(Hi) to Ti.\n3: For any edge V \u2217Hi,\u03b2iu \u2208 Ti+1 outgoing from the contracted super-vertex, add the edge argminvu:v\u2208V \u2217\nHi,\u03b2i WGivu to Ti.\n4: Add all edges Hi \\ \u03b4in(\u03b6) to Ti, where \u03b4in(\u03b6) denotes all edges incoming on \u03b6.\nAt the end of this procedure, Ti is a DMST for Gi (Fischer & Oshman, 2021, lemma 8). We now describe how it can be implemented distributedly, needing only classical messages and information. For every contracted super-vertex, the following steps can be implemented at the same time, as will become clear in how the steps are executed for the nodes of each contracted super-vertex. Let us focus on unpacking one super-vertex V \u2217Hi,\u03b2i . Each node knows its neighbors in Gi, and every node\u2019s super-vertex ID in Gi and Gi+1, since each node stores this information before the initial contraction to Gi+1 in QDLSI happens. Hence, step 1 can be done locally at each node without any communication. Step 2 can be done by first having each node v \u2208 V \u2217Hi,\u03b2i send \u03b2(u, v) to the other nodes in V \u2217Hi,\u03b2i , in one round, and then having each node of V \u2217Hi,\u03b2i send to v\n\u2217 the routing table entry corresponding to its shortest path to c(Hi) in Gi, also in one round (the nodes have already computed this information in QDLSI. Then v\u2217 notifies the nodes that are\npart of \u03b6, which can then add the appropriate edge to Ti, needing yet another round, so that step 2 can be done in three rounds of classical communication only. Step 3 is handled similarly. For the outgoing edge, each node in V \u2217Hi,\u03b2i sends WGivu to the other nodes in V \u2217 Hi,\u03b2i\nso that the appropriate edge to add to Ti can be determined (in case of a tie, the node with smaller ID can be the one to add the edge), so this can be done in one round. For step 4, every node in \u03b6 notifies its neighbors that it is in \u03b6, after which every node can determine which edges to add to Ti. For the unpacking of V \u2217Hi,\u03b2i , the information and communication for implementing its unpacking is contained in the nodes of V \u2217Hi,\u03b2i , so we can indeed unpack all vertices synchronously to obtain Gi even when multiple super-vertices were contracted to get Gi+1. Hence, one layer of unpacking using this procedure can be implemented in 5 rounds (making use of the APSP and routing table information computed earlier before the contractions in QDLSI). Since there are at most \u2308log n\u2309 contraction steps, the unpacking procedure can be implemented in 5 \u00b7 \u2308log n\u2309 rounds."
        },
        {
            "heading": "8.4 Information access",
            "text": "In remark 2.2, we mention that it suffices for all information regarding the input graph to be stored classically, with quantum access to it. Here, we expand on what we mean by that and refer the interested reader to (Booth, O'Gorman, Marshall, Hadfield, & Rieffel, 2021) for further details.\nWhile our algorithms use quantum subroutines, the problem instances and their solutions are encoded as classical information. The required quantum access refers to the ability to access the classical data so that computation in superposition of this data is possible. For instance, in the standard (non-distributed) Grover search algorithm, with a problem instance described by a function g : X \u2192 0, 1, we need the ability to apply the unitary Uw|x\u3009 = (\u22121)g(x)|x\u3009 to an N-qubit superposition state |s\u3009 = 1\u221a\nN\n\u2211N\u22121 x=0 |x\u3009. This unitary is also referred to as the \u201coracle\u201d, and a call\nto it as a \u201cquery\u201d. If we wish to use the distributed Grover search in example 2.4, in which the node u leading the search tries to determine whether each edge uv incident on it is part of a triangle in graph G, the unitary that node v must be able to evaluate is the indicator function of its neighborhood, and u must be able to apply the Grover diffusion unitary restricted to its neighborhood. Then after initializing the N-qubit equal superposition, nodes u and v can send a register of qubits back and forth between each other, with v evaluating the unitary corresponding to the indicator of its neighborhood and u applying the Grover diffusion operator restricted to its neighborhood.The same ideas transfer over to a distributed quantum implementation of the EvaluationA (or EvaluationB) procedure. There, instead of evaluating unitaries corresponding to indicators, in step 2, each node v(i,j,k) evaluates the unitary corresponding to the truth values of inequality 4.3 for the evaluation steps. That information is then returned to the node that sent it, which can then apply the appropriate Grover diffusion operator.\nIn general, quantum random access memory (QRAM) is the data structure that allows queries to the oracle. We can use circuit QRAM in our protocols or could make use of special-purpose hardware QRAM if it were to be realized. This choice does not affect the number of rounds of communication but would affect the efficiency of computation at each node. A main component of the distributed algorithms discussed in this work is quantum query access for each node to its list of edges and their weights in some graph G. This information is stored in memory, and the QRAM implementing the query to retrieve it can be called in time O(log n), resulting in a limited overhead for our algorithms. This retrieval of information takes place locally at each node; hence, this overhead does not add to the round complexity of our algorithms in the CONGEST-CLIQUE setting. We refer to (Giovannetti, Lloyd, & Maccone, 2008) for more details on QRAM."
        }
    ],
    "year": 2023
}