{
    "abstractText": "It is not uncommon for malicious sellers to collude with fake reviewers (also called spammers) to write fake reviews for multiple products to either demote competitors or promote their products\u2019 reputations, forming a gray industry chain. To detect spammer groups in a heterogeneous network with rich semantic information from both buyers and sellers, researchers have conducted extensive research using Frequent Item Mining-based and graph-based methods. However, these methods cannot detect spammer groups with cross-product attacks and do not jointly consider structural and attribute features, and structure-attribute correlation, resulting in poorer detection performance. Therefore, we propose a collaborative training-based spammer group detection algorithm by constructing a heterogeneous induced sub-network based on the target product set to detect cross-product attack spammer groups. To jointly consider all available features, we use the collaborative training method to learn the feature representations of nodes. In addition, we use the DBSCAN clustering method to generate candidate groups, exclude innocent ones, and rank them to obtain spammer groups. The experimental results on real-world datasets indicate that the overall detection performance of the proposed method is better than that of the baseline methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "Qi Zhang"
        },
        {
            "affiliations": [],
            "name": "Zhixiang Liang"
        },
        {
            "affiliations": [],
            "name": "Shujuan Ji"
        },
        {
            "affiliations": [],
            "name": "Benyong Xing"
        },
        {
            "affiliations": [],
            "name": "Dickson K. W. Chiu"
        }
    ],
    "id": "SP:a30d9aa2ca80b4756cd97a6a84430fc2304d60e7",
    "references": [
        {
            "authors": [
                "L Akoglu",
                "R Chandy",
                "C Faloutsos"
            ],
            "title": "Opinion fraud detection in online reviews by network effects",
            "venue": "Proceedings of the international AAAI conference on web and social media,",
            "year": 2013
        },
        {
            "authors": [
                "N Cao",
                "S Ji",
                "DK Chiu",
                "M He",
                "X Sun"
            ],
            "title": "A deceptive review detection framework: combination of coarse and fine-grained features",
            "venue": "Expert Syst Appl",
            "year": 2020
        },
        {
            "authors": [
                "N Cao",
                "S Ji",
                "DK Chiu",
                "M Gong"
            ],
            "title": "A deceptive reviews detection model: separated training of multi-feature learning and classification",
            "venue": "Expert Syst Appl",
            "year": 2022
        },
        {
            "authors": [
                "J Chao",
                "C Zhao",
                "F Zhang"
            ],
            "title": "Network embedding-based approach for detecting collusive spamming groups on E-commerce platforms. In: Security and communication networks, pp",
            "year": 2022
        },
        {
            "authors": [
                "M Ester",
                "HP Kriegel",
                "J Sander",
                "X Xu"
            ],
            "title": "A density-based algorithm for discovering clusters in large spatial databases with noise",
            "venue": "In: KDD,",
            "year": 1996
        },
        {
            "authors": [
                "X Glorot",
                "Y Bengio"
            ],
            "title": "Understanding the difficulty of training deep feedforward neural networks",
            "venue": "In: Proceedings of the thirteenth international conference on artificial intelligence and statistics. JMLR Workshop and Conference Proceedings, pp 249\u2013256",
            "year": 2010
        },
        {
            "authors": [
                "Y Hu"
            ],
            "title": "Unsupervised learning for spammer group detection based on network representation",
            "year": 2021
        },
        {
            "authors": [
                "W Huang",
                "Y Li",
                "Y Fang",
                "J Fan",
                "H Yang"
            ],
            "title": "BiANE: Bipartite attributed network embedding",
            "venue": "Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval",
            "year": 2020
        },
        {
            "authors": [
                "SJ Ji",
                "Q Zhang",
                "J Li",
                "DK Chiu",
                "S Xu",
                "L Yi",
                "M Gong"
            ],
            "title": "A burst-based unsupervised method for detecting review spammer groups",
            "year": 2020
        },
        {
            "authors": [
                "N Jindal",
                "B Liu"
            ],
            "title": "Opinion spam and analysis",
            "venue": "Proceedings of the 2008 International Conference on Web Search and Data Mining",
            "year": 2008
        },
        {
            "authors": [
                "DP Kingma",
                "J Ba"
            ],
            "title": "Adam: a method for stochastic optimization",
            "year": 2014
        },
        {
            "authors": [
                "FH Li",
                "M Huang",
                "Y Yang",
                "X Zhu"
            ],
            "title": "Learning to identify review spam. In: Twenty-second international joint conference on artificial intelligence",
            "year": 2011
        },
        {
            "authors": [
                "H Li",
                "G Fei",
                "S Wang",
                "B Liu",
                "W Shao",
                "A Mukherjee",
                "J Shao"
            ],
            "title": "Bimodal distribution and co-bursting in review spam detection",
            "venue": "Proceedings of the 26th international conference on World Wide Web",
            "year": 2017
        },
        {
            "authors": [
                "S Liu",
                "B Hooi",
                "C Faloutsos"
            ],
            "title": "A contrast metric for fraud detection in rich graphs",
            "venue": "IEEE Trans Knowl Data Eng",
            "year": 2018
        },
        {
            "authors": [
                "M Luca"
            ],
            "title": "2016) Reviews, reputation, and revenue: the case of Yelp",
            "venue": "Com. (March",
            "year": 2016
        },
        {
            "authors": [
                "A Mukherjee",
                "B Liu",
                "N Glance"
            ],
            "title": "Spotting fake reviewer groups in consumer reviews",
            "venue": "In: Proceedings of the 21st International Conference on World Wide Web. pp 191\u2013200",
            "year": 2012
        },
        {
            "authors": [
                "A Mukherjee",
                "A Kumar",
                "B Liu",
                "J Wang",
                "M Hsu",
                "M Castellanos",
                "R Ghosh"
            ],
            "title": "Spotting opinion spammers using behavioral footprints",
            "venue": "Proceedings of the 19th ACM SIGKDD international conference on knowledge discovery and data mining",
            "year": 2013
        },
        {
            "authors": [
                "M Ott",
                "Y Choi",
                "C Cardie",
                "JT Hancock"
            ],
            "title": "Finding deceptive opinion spam by any stretch of the imagination",
            "year": 2011
        },
        {
            "authors": [
                "S Rayana",
                "L Akoglu"
            ],
            "title": "Collective opinion spam detection: Bridging review networks and metadata",
            "venue": "Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining",
            "year": 2015
        },
        {
            "authors": [
                "S Shehnepoor",
                "R Togneri",
                "W Liu",
                "M Bennamoun"
            ],
            "title": "HIN-RNN: a graph representation learning neural network for fraudster group detection with no handcrafted features. In: IEEE transactions on neural networks and learning systems",
            "year": 2021
        },
        {
            "authors": [
                "S Shehnepoor",
                "R Togneri",
                "W Liu",
                "M Bennamoun"
            ],
            "title": "Spatio-temporal graph representation learning for fraudster group detection. In: IEEE transactions on neural networks and learning systems",
            "year": 2022
        },
        {
            "authors": [
                "G Wang",
                "S Xie",
                "B Liu",
                "PS Yu"
            ],
            "title": "Identify online store review spammers via social review",
            "venue": "graph. ACM Trans Intell Syst Technol",
            "year": 2012
        },
        {
            "authors": [
                "Z Wang",
                "T Hou",
                "D Song",
                "Z Li",
                "T Kong"
            ],
            "title": "Detecting review spammer groups via bipartite graph projection",
            "venue": "Comput J",
            "year": 2016
        },
        {
            "authors": [
                "Z Wang",
                "S Gu",
                "X Zhao",
                "X Xu"
            ],
            "title": "Graph-based review spammer group detection",
            "venue": "Knowl Inf Syst",
            "year": 2018
        },
        {
            "authors": [
                "J Wang",
                "Y Guo",
                "X Wen",
                "Z Wang",
                "Z Li",
                "M Tang"
            ],
            "title": "Improving graph-based label propagation algorithm with group partition for fraud detection",
            "year": 2020
        },
        {
            "authors": [
                "X Wang",
                "N Liu",
                "H Han",
                "C Shi"
            ],
            "title": "2021a) Self-supervised heterogeneous graph neural network with co-contrastive learning",
            "venue": "Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining",
            "year": 2021
        },
        {
            "authors": [
                "Y Wang",
                "J Zhang",
                "S Guo",
                "H Yin",
                "C Li",
                "H Chen"
            ],
            "title": "Decoupling representation learning and classification for GNN-based anomaly detection",
            "venue": "Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval",
            "year": 2021
        },
        {
            "authors": [
                "X Wang",
                "D Bo",
                "C Shi",
                "S Fan",
                "Y Ye",
                "SY Philip"
            ],
            "title": "A survey on heterogeneous graph embedding: methods, techniques, applications and sources",
            "venue": "IEEE Trans Big Data",
            "year": 2022
        },
        {
            "authors": [
                "C Xu",
                "J Zhang",
                "K Chang",
                "C Long"
            ],
            "title": "Uncovering collusive spammers in Chinese review websites",
            "venue": "Proceedings of the 22nd ACM international conference on information & knowledge management",
            "year": 2013
        },
        {
            "authors": [
                "K Xu",
                "W Hu",
                "J Leskovec",
                "S Jegelka"
            ],
            "title": "How powerful are graph neural networks",
            "year": 2018
        },
        {
            "authors": [
                "J Ye",
                "L Akoglu"
            ],
            "title": "Discovering opinion spammer groups by network footprints. In: Machine learning and knowledge discovery in databases: European conference",
            "venue": "ECML PKDD 2015,",
            "year": 2015
        },
        {
            "authors": [
                "F Zhang",
                "X Hao",
                "J Chao",
                "S Yuan"
            ],
            "title": "2020a) Label propagation-based approach for detecting review spammer groups on e-commerce websites",
            "venue": "KnowlBased Syst",
            "year": 2020
        },
        {
            "authors": [
                "Y Zhang",
                "Y Li",
                "X Gu",
                "S Ji"
            ],
            "title": "A group spam detection algorithm combining behavior and structural feature reasoning",
            "year": 2021
        },
        {
            "authors": [
                "Q Zhang",
                "S Ji",
                "W Zhang"
            ],
            "title": "2022a) Group spam detection algorithm considering structure and behavior characteristics",
            "venue": "Appl Res",
            "year": 2022
        },
        {
            "authors": [
                "F Zhang",
                "S Yuan",
                "J Wu",
                "P Zhang",
                "J Chao"
            ],
            "title": "Detecting collusive spammers on e-commerce websites based on reinforcement learning and adversarial autoencoder",
            "venue": "Expert Syst Appl",
            "year": 2022
        },
        {
            "authors": [
                "S Zhang",
                "H Yin",
                "T Chen",
                "QVN Hung",
                "Z Huang",
                "L Cui"
            ],
            "title": "2020b) GCN-based user representation learning for unifying robust recommendation and fraudster detection",
            "venue": "Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval",
            "year": 2020
        },
        {
            "authors": [
                "M Zheng",
                "C Zhou",
                "J Wu",
                "S Pan",
                "J Shi",
                "L Guo"
            ],
            "title": "FraudNE: a joint embedding approach for fraud detection. In: 2018 international joint conference on neural networks (IJCNN)",
            "year": 2018
        },
        {
            "authors": [
                "C Zhu",
                "W Zhao",
                "Q Li",
                "P Li",
                "Q Da"
            ],
            "title": "Network embedding-based anomalous density searching for multi-group collaborative fraudsters detection in social media",
            "venue": "Comput Mater Continua",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "\u00a9 The Author(s) 2023. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nKeywords Spammer group, Heterogeneous network, Collaborative training, DBSCAN"
        },
        {
            "heading": "Introduction",
            "text": "The convenience of e-commerce has made online shopping increasingly common. As the information in e-commerce is asymmetry and the lack of quality control centers, consumers tend to browse reviews related to products or services before purchasing them online. This makes online reviews an essential reference for consumers to make purchasing decisions. According to a Harvard University study, every 1-star increase in a product\u2019s rating on Yelp creates a 5\u20139% increase in revenue for that product (Luca 2016). Motivated by potential financial gain, some malicious sellers tend to collude with spammers, aiming to either demote competitors or promote their businesses by posting many fake reviews. The proliferation of fake reviews makes it impossible for consumers to judge the actual quality of products based on the review information. This seriously affects consumers\u2019 shopping experience and destroys the fair competition environment among merchants. It also has an extremely negative impact on the development of the e-commerce industry.\nSpammers are constantly changing their spam strategies to escape the detection of the spammer identification model. Spammers often work in groups to camouflage their behavior and improve attack efficiency. A spammer *Correspondence: Shujuan Ji jsjsuzie@sina.com 1 Shandong Provincial Key Laboratory of Wisdom Mine Information Technology, Shandong University of Science and Technology, Qingdao 266590, Shandong, China 2 Zhejiang University-University of Illinois at Urbana-Champaign Institute, Haining 314499, Zhejiang, China 3 School of Civil Engineering, Beijing Jiaotong University, Beijing 100044, China 4 Faculty of Education, The University of Hong Kong, Pok Fu Lam, Hong Kong, China\ngroup is a group of reviewers who write fake reviews for one or several products in an organized and coordinated manner (Mukherjee et\u00a0 al. 2012). The spammer group is more covert, destructive, and influential than individual spammers. This is because spammer groups can evade the platform\u2019s detection by avoiding certain relationships with other group members or developing multiple relationships with genuine reviewers (Shehnepoor et\u00a0 al. 2022). In addition, they can mislead consumers by imitating the behavior and language of genuine reviewers and writing fake reviews about target products in a short period. Therefore, how to effectively identify spammer groups on e-commerce platforms and ensure the credibility of product reviews has become an urgent issue of network information security.\nSince the pioneering work of Jindal and Liu (2008), most efforts have been aimed at detecting fake reviews (Jindal and Liu 2008; Ott et\u00a0 al. 2011; Li et\u00a0 al. 2011; Cao et\u00a0 al. 2020, 2022) or individual spammers (Wang et\u00a0 al. 2012, 2020; Mukherjee et\u00a0 al. 2013). In recent years, several researchers (Mukherjee et\u00a0 al. 2012; Shehnepoor et\u00a0 al. 2022, 2021; Ji et\u00a0 al. 2020; Xu et\u00a0 al. 2013; Zhang et\u00a0 al. 2021, 2022a, 2020a, 2022b; Wang et\u00a0al. 2016, 2018; Li et\u00a0al. 2017; Hu 2021; Akoglu et\u00a0al. 2013; Ye and Akoglu 2015; Zheng et\u00a0al. 2018; Zhu et\u00a0al. 2019; Chao et\u00a0al. 2022) have attempted to detect spammers with collusive fraudulent behaviors at the group level. The existing work for detecting spammer groups can be roughly divided into two categories, i.e., FIMbased and graph-based methods. FIM-based methods (Mukherjee et\u00a0 al. 2012; Shehnepoor et\u00a0 al. 2022, 2021; Xu et\u00a0 al. 2013; Zhang et\u00a0 al. 2021) typically identify candidate groups based on the co-review hypothesis, and graph-based methods (Wang et\u00a0 al. 2016, 2018; Li et\u00a0al. 2017; Zhang et\u00a0al. 2022a, 2020a, 2022b; Hu 2021; Akoglu et\u00a0 al. 2013; Ye and Akoglu 2015; Zheng et\u00a0 al. 2018; Zhu et\u00a0al. 2019; Chao et\u00a0al. 2022), such as graph partition or clustering on the constructed reviewer relationship network, to discover candidate groups. Both these two categories of methods utilize a set of spam indicators to measure the spamming behavior of each candidate group and from which to identify spammer groups. Though most existing methods have shown excellent performance, they have two major limitations. First, existing methods only detect spammer groups from the viewpoint of reviewers or singleproduct, ignoring the characteristic that spammer groups will implement cross-product (i.e., for multiple target products) attacks for camouflage to evade detectors. Secondly, most existing methods focus only on structural features of the review network or attribute\nfeatures of nodes (e.g., features about the behavior of reviewers or products) when detecting spammer groups, without jointly considering structural and attribute features as well as the structure-attribute correlation. It is necessary to design a method that comprehensively discover all the available information to learn the feature representation of nodes.\nTherefore, we propose a spammer group detection algorithm based on collaborative training for heterogeneous networks named SGDCTH. In particular, we first calculate the suspiciousness of each product based on the Network Footprint Score (NFS) metric to filter target products and then construct a heterogeneous induced sub-network based on all target products, in which we can detect spammer groups that commit cross-product attacks. Subsequently, we use a collaborative training method to model both the intra-partition and inter-partition proximity of a heterogeneous induced sub-network. In this process, we consider each node\u2019s structural and attribute information and the structure-attribute correlation to learn the feature representation of nodes effectively. Furthermore, we use the DBSCAN clustering method to generate candidate groups in the embedding space of reviewers. Finally, we obtain spammer groups by the group purification and ranking method. The contributions of this paper are summarized as follows:\n(1) Unlike most existing methods that detect spammer groups based on the viewpoint of reviewers (Mukherjee et\u00a0 al. 2012; Shehnepoor et\u00a0 al. 2022, 2021; Xu et\u00a0 al. 2013; Zhang et\u00a0 al. 2021, 2022a, 2020a, 2022b; Wang et\u00a0 al. 2016, 2018; Li et\u00a0 al. 2017; Hu 2021; Akoglu et\u00a0 al. 2013; Ye and Akoglu 2015; Zheng et\u00a0al. 2018; Zhu et\u00a0al. 2019; Chao et\u00a0al. 2022) or single-product (Ji et\u00a0al. 2020), we propose a new\u00a0 heterogeneous network-based\u00a0 method for identifying spammer groups from the viewpoint of cross-product. We first filter target products, then construct a heterogeneous network based on the target product\u00a0 set,\u00a0 and\u00a0 finally discover spammer groups by learning feature representations of nodes in the heterogeneous network. This enables our method to detect groups that attack multiple target products more accurately. (2) Unlike most existing methods that focus only on structural features of the review network (Shehnepoor et\u00a0 al. 2022; Ye and Akoglu 2015; Zheng et\u00a0al. 2018; Zhu et\u00a0al. 2019; Zhang et\u00a0al. 2022b) or attribute features of nodes (Mukherjee et\u00a0 al. 2012; Ji et\u00a0al. 2020; Xu et\u00a0al. 2013; Li et\u00a0al. 2017; Hu 2021;\nZhang et\u00a0 al. 2020a), we jointly consider structural and attribute features as well as the structure-attribute correlation to detect spammer groups. We first extract the raw structural and attribute features of nodes, then use the collaborative training method to model both the intra-partition and inter-partition proximity of a heterogeneous network. In the training process, we take all available information into account to capture suspicious spammer groups in terms of structure and attributes. (3) We conduct experiments on real-world review datasets and make a comparison with four baseline methods. The experimental results indicate that our method can accurately and efficiently detect active spammer groups on e-commerce websites.\nThe rest of the paper is organized as follows. Section \u201cRelated work\u201d reviews the related work on spammer group detection. Section \u201cThe spammer group detection algorithm based on collaborative training for heterogeneous networks\u201d details our SGDCTH method. Section \u201cExperiments\u201d describes the experimental results. Finally, we summarize this paper in section \u201cConclusion\u201d."
        },
        {
            "heading": "Related work",
            "text": "According to different classification criteria, we can divide the existing work on spammer group detection into four dimensions. First, depending on the strategy used to generate candidate spammer groups, the existing work can be divided into two categories, i.e., FIMbased and graph-based methods. Secondly, according to the different features considered in group mining, the existing work can be divided into three categories, i.e., the methods based on group behavior and content analysis (B&C), the methods based on group structure analysis (S), and the methods combining group behavior and structure analysis (B&C+S). Thirdly, according to the different coupling degrees of the discovered group members, the existing work can be divided into two categories, i.e., tightly coupled and loosely coupled methods. Fourthly, according to the different concentrations of the attacked target products, the existing work can be divided into two categories, i.e., single-product and cross-product methods. It is worth noting that tightly coupled and loosely coupled methods are designed based on reviewers\u2019 viewpoints, and existing works are almost entirely from the viewpoint of reviewers to detect spammer groups. However, single-product and cross-product methods are designed based on products\u2019 viewpoints. To the best of our knowledge, Ji et\u00a0al. (2020) were the first to propose detecting spammer groups from the viewpoint of products. The following subsections review existing\nwork according to the strategy used to generate candidate spammer groups."
        },
        {
            "heading": "FIM\u2011based methods",
            "text": "FIM-based methods first use the FIM method to generate candidate groups based on the co-review hypothesis and then rank or classify them to obtain spammer groups. Mukherjee et\u00a0al. (2012) were the first to study the problem of spammer group detection. They use the FIM method to treat reviewers who co-review the same set of products as a candidate group and propose a relationship-based model to detect spammer groups. Later, Xu et\u00a0 al. (2013) proposed a KNN-based and a graph-based classification method to predict whether a candidate group\u2019s members are suspicious. Zhang et\u00a0al. (2021) first use the FIM method to discover candidate groups and then propose a method that fuses behavioral and structural feature reasoning to detect spammer groups. After obtaining the candidate groups based on the concept of FIM, Shehnepoor et\u00a0 al. (2022, 2021) use deep learning methods to gradually refine the reviewers\u2019 representation and remove abnormal members from candidate groups based on the refined representation, and finally classify candidate groups. However, the FIM method may incorrectly classify some genuine reviewers who accidentally post reviews into the spammer groups in the process of mining groups. In addition, the method is very sensitive to the setting of support thresholds. Therefore, FIM methods are suitable for detecting tightly coupled groups (i.e., group members need to review all target products) but not for detecting loosely coupled groups (i.e., group members do not need to review every target product to conceal the group\u2019s spamming behavior) (Wang et\u00a0 al. 2016, 2018; Zhang et\u00a0al. 2022b)."
        },
        {
            "heading": "Graph\u2011based methods",
            "text": "Graph-based methods use graph partition, clustering, community detection, and other methods to generate candidate groups on the review network and then rank or classify them to obtain spammer groups. Different graph construction methods can be further divided into homogeneous and heterogeneous graph-based methods."
        },
        {
            "heading": "Homogeneous graph\u2011based methods",
            "text": "Among homogeneous graph-based methods, researchers generally detect spammer groups in the reviewer relationship network constructed based on the similarity between reviewers. Wang et\u00a0 al. (2016) adopt the divide-and-conquer idea to detect loosely coupled spammer groups on the reviewer projection network. On this basis, Wang et\u00a0al. (2018) propose a top-down framework\nGSBC, which uses the min-cut method to discover spammer groups on a bi-connected reviewer network. Li et\u00a0 al. (2017) use the graph clustering method to obtain spammer groups on the co-burst network. Zhang et\u00a0 al. (2022a) detect spammer groups in three steps. First, they construct a reviewer relationship network and use an improved label propagation method to discover candidate groups. Secondly, they adopt a combination of subjective and objective indicator weighting strategies to evaluate the spamicities of each candidate group. Finally, they rank the candidate groups according to spamicity scores to obtain spammer groups. Hu (2021) uses a community mining method based on network representation learning on the constructed reviewer similarity network to detect tightly connected groups and from which to identify true spammer groups. Zhang et\u00a0al. (2020a) use an improved label propagation method to obtain candidate groups and propose a new ranking method to find collusive spammers. However, homogeneous graph-based methods do not deeply examine the implicit relationships among reviewers when constructing the reviewer relationship network, which fails to discover spammers with collusive fraudulent behaviors. Moreover, these methods cannot capture the highly non-linear relationship between nodes in the network (Zheng et\u00a0al. 2018)."
        },
        {
            "heading": "Heterogeneous graph\u2011based methods",
            "text": "Among heterogeneous graph-based methods, researchers detect spammer groups in a reviewer-object heterogeneous network constructed from the reviewer\u2019s review behavior. Akoglu et\u00a0 al. (2013) obtain spammer groups by the graph clustering method on an induced sub-graph containing highly suspicious reviewers and corresponding products. Ye et\u00a0al. (2015) propose a two-step method to discover review spammer groups. They first identify target products vulnerable to spammer attacks and then use the agglomerative hierarchical clustering method to detect spammer groups on an induced sub-graph. Zheng et\u00a0al. (2018) first utilize the deep network embedding method to jointly learn the feature representation of nodes in a bipartite review network and then use the DBSCAN clustering method to detect dense blocks in the latent space. Zhu et\u00a0 al. (2019) first embed explicit and implicit relations in a bipartite network to obtain the representation of reviewers and then use a k-dimensional tree-based fast-density sub-graph mining method to obtain multiple collaborative groups. Chao et\u00a0 al. (2022) first construct a heterogeneous network based on the idea of metagraph and use the improved DeepWalk method to learn the feature representation of nodes. Then, they utilize the Canopy and K-means clustering method to generate candidate groups and treat the top k most suspicious groups as spammer groups. Zhang et\u00a0 al. (2022b) first construct a reviewer-product bipartite network as the agent\u2019s interactive\nenvironment and use an improved reinforcement learning method to generate candidate groups. Next, they exploit the Doc2Vec model to obtain the embedding vector of each candidate group and devise an adversarial autoencoderbased one-class classification model for detecting collusive spammers. The above heterogeneous graph-based methods neglected to exclude innocent individuals in candidate groups. Furthermore, these methods only utilize structural or attribute information when detecting spammer groups, which do not jointly consider structural and attribute information as well as the structure-attribute correlation."
        },
        {
            "heading": "Summary",
            "text": "Table\u00a01 summarizes the existing work in these four dimensions. Although most existing FIM-based or graph-based methods for detecting spammer groups are generally effective, they have some limitations. Specifically, FIM-based methods are prone to misjudging genuine reviewers as spammers in the process of mining groups. Furthermore, the FIM methods are suitable for detecting tightly coupled spammer groups. For homogeneous graph-based and heterogeneous graph-based methods, the former does not take full advantage of the implicit relationships between reviewers when constructing the reviewer relationship network, while the latter ignores the step of group purification. Moreover, existing heterogeneous graph-based methods do not jointly consider the structural features of the review network and the attribute features of nodes as well as the structure-attribute correlation.\nThe spammer group detection algorithm based on\u00a0collaborative training for\u00a0heterogeneous networks Aiming at the limitations of existing research methods, we propose a new unsupervised spammer group detection algorithm, SGDCTH, as shown in Algorithm\u00a0 1. Figure\u00a01 shows the overall framework of our method. In detail, our method consists of four steps. First, we filter target products based on the NFS metric and then construct a heterogeneous induced sub-network based on the set of target products (see Algorithms 2 and 3 for details). Secondly, we use a collaborative training method to model the intra-partition and inter-partition proximity of the heterogeneous induced sub-network to obtain low-dimensional vector representations of nodes (see Algorithm\u00a0 4 for details). Thirdly, the candidate spammer groups are generated based on the DBSCAN clustering method (see Algorithm\u00a0 5 for details). Fourthly, innocent reviewers are excluded from the candidate group and ranked to obtain spammer groups (see Algorithm\u00a0 6 for details). An algorithm implements each step. We describe the preliminary in subsection \u201cPreliminary\u201d, and the subsequent subsections describe the implementation details of each step.\nTa bl\ne 1\nA s\num m\nar y\nof e\nxi st\nin g\nw or\nk on\ns pa\nm m\ner g\nro up\nd et\nec tio\nn\nM et\nho d\nCl as\nsi fic\nat io\nn di\nm en\nsi on\nTh e\nst ra\nte gy\nu se\nd to\ng en\ner at\ne ca\nnd id\nat e\ngr ou\nps Co\nns id\ner ed\nfe at\nur es\nTh e\nco up\nlin g\nde gr\nee s\nof\ngr ou\np m\nem be\nrs Th\ne co\nnc en\ntr at\nio ns\no f t\nhe a\ntt ac\nke d\nta rg\net p\nro du\nct s\nFI M\n\u2011b as\ned G\nra ph\n\u2011b as\ned B&\nC S\nB& C+\nS Ti\ngh tly \u2011 co up le\nd Lo\nos el y\u2011 co up le\nd Si\nng le\n\u2011p ro\ndu ct\nCr os\ns\u2011 pr\nod uc\nt\nH om\nog en\neo us\nH et\ner og\nen eo\nus\nM uk\nhe rje\ne et\na l.\n(2 01\n2) \u221a\nSh eh\nne po\nor e\nt a l.\n(2 02\n2) \u221a\n\u221a \u221a\nJi et\na l.\n(2 02\n0) \u221a\n\u221a\nXu e\nt a l.\n(2 01\n3) \u221a\n\u221a \u221a\nZh an\ng et\na l.\n(2 02\n1) \u221a\n\u221a \u221a\nSh eh\nne po\nor e\nt a l.\n(2 02\n1) \u221a\n\u221a \u221a\nW an\ng et\na l.\n(2 01\n6) \u221a\n\u221a \u221a\nW an\ng et\na l.\n(2 01\n8) \u221a\n\u221a \u221a\nLi e\nt a l.\n(2 01\n7) \u221a\n\u221a \u221a\nZh an\ng et\na l.\n(2 02\n2a )\n\u221a \u221a\n\u221a\nH u\n(2 02\n1) \u221a\n\u221a\nZh an\ng et\na l.\n(2 02\n0a )\n\u221a \u221a\n\u221a\nA ko\ngl u\net a\nl. (2\n01 3)\n\u221a \u221a\n\u221a\nYe e\nt a l.\n(2 01\n5) \u221a\n\u221a \u221a\nZh en\ng et\na l.\n(2 01\n8) \u221a\n\u221a \u221a\nZh u\net a\nl. (2\n01 9)\n\u221a \u221a\nC ha\no et\na l.\n(2 02\n2) \u221a\n\u221a \u221a\nZh an\ng et\na l.\n(2 02\n2b )\n\u221a \u221a\n\u221a\nSG D\nC TH\n(O ur\ns) \u221a\n\u221a \u221a\n\u221a"
        },
        {
            "heading": "Preliminary",
            "text": "This subsection defines several important concepts that are relevant to our work.\nDefinition 1 Heterogeneous Information Network (Wang et\u00a0al. 2022). Heterogeneous Information Network (HIN) is defined as a network G = (V , E) , where V and E denotes the set of nodes and the set of edges, respectively, and each node v \u2208 V and each edge e \u2208 E is associated with their node type mapping function \u03c6(v) : V \u2192 A and edge type mapping function \u03d5(e) : E \u2192 R , where\nA and R denotes the set of node types and edge types respectively, |A+R| > 2.\nDefinition 2 Meta-path (Wang et\u00a0 al. 2021a). A meta-path P is defined as a path in the form of A1 R1 \u2212\u2192A2 R2 \u2212\u2192\u00b7 \u00b7 \u00b7 Rl \u2212\u2192Al+1(abbreviated as A1A2 \u00b7 \u00b7 \u00b7 Al+1 ), which describes a composite relation R = R1 \u25e6 R2 \u25e6 \u00b7 \u00b7 \u00b7 \u25e6 Rl between node types A1 and Al+1 , where \u25e6 denotes the composition operator on relations.\nThe target product filtration method and\u00a0the\u00a0heterogeneous induced sub\u2011network construction method"
        },
        {
            "heading": "The target product filtration method",
            "text": "Inspired by Ji et\u00a0al. (2020), who detect spammer groups based on review bursts from the products\u2019 viewpoints, we cite the NFS metric (Ye and Akoglu 2015) to quantify the likelihood of a product being attacked. NFS leverages two key observations relevant to real-world networks, i.e., neighbor diversity and self-similarity. The former means the local diversity of node importance within the neighborhood of a node, and the latter means the distributional similarity between node importance at the local and global levels. In this work, we use degree and PageRank centrality (Ye and Akoglu 2015) to measure node importance in a network.\n(1) Neighbor diversity of nodes\nIn order to measure the diversity of neighborhood centralities of a given product p\u0303 \u2208 V with degree deg(p\u0303) , we mainly divide it into three steps. First, a list of buckets f = {0, 1, ...} is created so that the bucket boundary values grow exponentially as a \u00b7 bf . Then, the reviewers are placed in F buckets, and the reviewers in each bucket are counted and normalized to obtain a discrete probability distribution S(i) with value [s(i)1 , ..., s (i) F ] . Finally, by calculating the Shannon entropy of S(i) , the product p\u0303 obtains two neighbor diversity scores Hdeg ( p\u0303 ) and Hpr ( p\u0303 ) for\ndegree and PageRank, respectively. The lower these scores are, the more suspicious the product is.\n(2) Self-similarity in real-world network\nTo calculate the self-similarity for a given product p\u0303 , the histogram density S(i) = [s(i)1 , ..., s (i) F ] of the centrality of the reviewers and the KL-divergence between all reviewers in the network denoted by T is defined. T is calculated in the same way as S , except that T divides the centrality values of all reviewers in a network into buckets. Finally, the product p\u0303 obtains two separate scores KLdeg ( p\u0303 ) and\nKLpr ( p\u0303 ) from the difference in self-similarity. The higher these scores are, the more suspicious the product is.\n(3) NFS metric\nFinally, each product receives four suspiciousness scores, where two based on neighbor diversity, i.e., Hdeg and Hpr , and two based on self-similarity, i.e., KLdeg and KLpr . We use the Cumulative Distribution Function (CDF) to unify them into a standard scale score. Let H = {H(1),H(2), ...} as a list of entropy values calculated for a set of products (based on degree or PageRank centrality). To quantify the extremes of H ( p\u0303 ) , an empirical CDF is used on H and the probability that the set H = {H(1),H(2), ...} is less than or equal to H ( p\u0303 ) is counted and calculated as follows (Ye and Akoglu 2015).\nOn the other hand, for the KL-divergence, the statistical probability that the set KL = {KL(1), KL(2), ...} is greater than KL ( p\u0303 ) is calculated as follows (Ye and Akoglu 2015).\nOur ultimate goal is to take the low value in H ( p\u0303 ) and the high value in KL ( p\u0303 ) , and obtain the NFS value of a product p\u0303 by combining them. A higher value of NFS ( p\u0303 ) \u2208 [0, 1] indicates that a product is more suspicious, calculated as follows (Ye and Akoglu 2015).\nThe heterogeneous induced sub\u2011network construction method Based on the HIN and the set of target products, we first give the definition of the heterogeneous induced sub-network.\nDefinition 3 Heterogeneous Induced Sub-network. The heterogeneous induced sub-network (HISN) is defined as a network SG = (VSG , ESG) , where VSG and EV denotes the set of nodes and edges, respectively. The sub-network consists of target product set P\u0303 , all reviewers R who reviewed target products in P\u0303 , and all products P \u2287 P reviewed by these reviewers. In other words, this sub-network is an induced sub-network of the network G at nodes within two hops of target products in P\u0303.\n(1)f ( H ( p\u0303 )) = P ( H \u2264 H ( p\u0303 ))\n(2)f ( KL ( p\u0303 )) = 1\u2212 P ( KL \u2264 KL ( p\u0303 ))\n(3) NFS ( p\u0303 ) = 1\u2212\n\u221a f ( Hdeg ( p\u0303 ))2 + f ( Hpr ( p\u0303 ))2 + f ( KLdeg ( p\u0303 ))2 + f ( KLpr ( p\u0303 ))2\n4\nBased on the above description, we design a method for filtering target products in Algorithm\u00a0 2. For each product in the review network, its NFS value is calculated. If the NFS value exceeds a given threshold \u03b4p\u0303 , and then it is added to the target product set P\u0303 . In addition, we design a method for constructing HISN in Algorithm\u00a03. In Algorithm\u00a03, we construct the HISN using all of the target products. The collaborative training\u2011based feature representation learning method In real life, a spammer often has a close relationship with a series of manipulated target products, i.e., a reviewerproduct relationship. To increase the concealment of a group, its members often collaborate to co-review multiple target products, i.e., a reviewer-reviewer relationship. The target products under attack will have overlapped\nspammers, i.e., a product-product relationship. To capture these relationships, we first use a collaborative training method to model both the intra-partition proximity and inter-partition proximity of HISN. Then, we model the structure-attribute correlation using a latent correlation training strategy to learn the feature representation of nodes."
        },
        {
            "heading": "Intra\u2011partition proximity modeling",
            "text": "The intra-partition proximity captures the relationships between nodes within the same partition in terms of both structure and attributes (i.e., implicit relationships, including reviewer-reviewer relationship and productproduct relationship). On the one hand, the nodes with similar \u201cinteraction\u201d behaviors with nodes in the other partition should have high proximity (i.e., structural proximity). On the other hand, nodes sharing similar attributes tend to exhibit similar behaviors in the network (i.e., attribute proximity) (Huang et\u00a0al. 2020). Specifically, we first extract the raw structural features and attribute features of nodes in HISN. Subsequently, we partition HISN and input the structural and attribute features of nodes within the same partition into two independent autoencoders to learn their compact representations. Finally, we jointly model the structural and attribute proximity to preserve the first-order proximity of nodes."
        },
        {
            "heading": "The raw feature extraction method",
            "text": "(1) The raw structural feature extraction method\nThe NFS measures how unusually suspiciously similar reviewers target a product, and such groups of highly similar reviewers are likely to work together in spam campaigns (Ye and Akoglu 2015). Therefore, the behavior of reviewers within each sub-graph (i.e., a bipartite sub-graph consisting of a target product and its corresponding reviewer) is highly consistent. However, Wang et\u00a0 al. (2021b) found an inconsistency between a node\u2019s behavior and its label semantics. Inspired by Wang et\u00a0al. (2021b), we propose to adopt the contrast between node representation and sub-graph representation to reduce the impact of inconsistency caused by different behaviors across sub-graphs.\nWe first perform feature decomposition for the normalized adjacency matrix to obtain the initial feature vector X , where xi \u2208 Rd0 represents the d0-dimensional initial feature vector of a node vi . Then, it is fed into GNN to learn the structural features of nodes. In our work, we adopt GIN (Xu et\u00a0 al. 2018) in Eq.\u00a0 (4), a state-of-the-art graph neural network, to learn the structural features of each node by means of a sum-like neighborhood aggregation function.\nwhere x(l)i \u2208 R d is the embedding of node vi at l-th layer, and x(0)i =xi . N (vi) is the set of neighbors of node vi . MLP denotes a multi-layer perceptron. (l) is either a learnable parameter or a fixed scalar. We stack L layers to obtain the higher-order structural features x(L)i of each node in HISN.\nFor each sub-graph Ck , we compute a sub-graph level representation sk to summarize most nodes\u2019 behavior.\nwhere nk denotes the number of nodes in Ck. The sub-graph level representation is encoded as the node representation by optimizing the loss function LkStru , and the final loss function LStru is the average of K sub-graph losses.\nwhere D is a discriminator that outputs the affinity score for each node-sub-graph pair. A sub-graph C\u0303k is generated by a row-wise shuffling of the initial feature matrix of Ck , providing that node representation x\u0303 (L) i can be paired with sub-graph representation sk as a negative sample.\n(2) The raw attribute feature extraction method\nEach node in HISN is associated with a set of attributes. In this paper, we extract 23 behavioral features from the literature (Zhang et\u00a0al. 2020b) as the raw attribute features of a reviewer. In addition, we extract 6 behavioral features from the literature (Rayana and Akoglu 2015) and the proportion of each rating level of a product, a total of 11 behavioral features as the raw attribute features of a product. In particular, the numerical attributes are normalized, the categorical attributes are coded using one-hot, and they are all concatenated as the raw attribute features of a node.\n(4)x(l)i = MLP (l)\n  \ufffd 1+ (l) \ufffd \u00b7 x\n(l\u22121) i +\n\ufffd\nvj\u2208N (vi)\nx (l\u22121) j\n \n(5)sk = \u03c3   1 nk \ufffd\nvi\u2208Ck\nx (L) i\n \n(6) Lk Stru\n=\u2212 1\n2nk\n\u2211\nvi\u2208Vk\n( ECk logD ( x (L) i , sk )\n+E C\u0303k\nlog ( 1\u2212D ( x\u0303 (L) i , sk )))\n(7)LStru = 1\nK\nK\u2211\nk=1\nLkStru\nPartitioning and\u00a0 compact representation learning method After obtaining the raw structural features x and attribute features z , we divide HISN into reviewer partition and product partition based on the meta-path \u201cR-P-R\u201d and \u201cP-R-P\u201d, where two nodes connected within a partition are each other\u2019s intra-partition neighbors. The same applies to product partition as to reviewer partition.\nWe feed the features x and z into two independent autoencoders to obtain encodings x\u2032 and z\u2032 as well as the reconstructed vectors x\u0302 and z\u0302 . We capture the attribute information and structural information of a reviewer vi by minimizing the following reconstruction loss function.\nJoint modeling To bring two nodes with similar review behavior closer together in the embedding space, after obtaining the encodings x\u2032 and z\u2032 , we perform a joint model of attribute encoding and structure encoding to preserve the first-order proximity between nodes by optimizing the following loss function.\nwhere amn denotes the adjacency matrix elements of the synthesized intra-partition network, \ufffdn(v) denotes the negative sampling distribution.\nFinally, x\u2032 and z\u2032 are concatenated to obtain the final embedding h , which is used for inter-partition proximity modeling."
        },
        {
            "heading": "Inter\u2011partition proximity modeling",
            "text": "Inter-partition proximity captures the relationship between reviewers and products (i.e., the explicit relationship). For edges ESGmn between rm and pn , consider the joint probability as the inter-partition proximity between them.\nwhere \u03c3 denotes the sigmoid function. hm and hn denotes the final embedding of rm and pn , respectively.\nThe likelihood function of the joint probability is maximized by minimizing the following loss function.\n(8)L1 = \u2211\ni\n\u2225\u2225x\u0302i \u2212 xi \u2225\u22252 + \u2211\ni\n\u2225\u2225z\u0302i \u2212 zi \u2225\u22252\n(9)\nL2 = \u2211\namn>0\nlog \u03c3 ( x \u2032T m \u00b7 x \u2032 n ) \u2212 \u2211\nn\u2032=1\nEvn\u2032\u00b7\ufffdn(v) log \u03c3 ( \u2212x\u2032Tm \u00b7 x\u2032n\u2032 )\n\u2212 \u2211\namn>0\nlog \u03c3 ( z \u2032T m \u00b7 z \u2032 n ) \u2212 \u2211\nn\u2032=1\nEvn\u2032\u00b7\ufffdn(v) log \u03c3 ( \u2212z\u2032Tm \u00b7 z\u2032n\u2032 )\n(10)p(m, n) = \u03c3 ( h T m \u00b7 hn )\nwhere \ufffdn(v) denotes the negative sampling distribution.\nLatent correlation training strategy Since structural information and attribute information are two different modalities, they provide complementary information. Moreover, they both describe the same network, implying that they have potential consistency. Therefore, we comprehensively consider their complementarity and consistency, which is called structureattribute correlation (Huang et\u00a0al. 2020).\nTo effectively preserve attribute-structure correlation, two auxiliary space transformation kernels are used to transform encodings to a new latent space and project it to obtain the latent representations x\u0303 and z\u0303 (Huang et\u00a0al. 2020). The attribute-structure correlation of any two nodes is defined as the joint probability of their latent representations.\nThe likelihood function of the joint probability is maximized by minimizing the following loss function.\nwhere p\u0303(m, n) denote the dynamic positive sampling distribution.\nUltimately, we combine all the optimization functions as a final objective function to optimize the embedding vector jointly.\nWe summarize the process of collaborative training in Algorithm\u00a04. Lines 1\u201319 model the intra-partition proximity. In particular, lines 1\u20139 extract the raw structural and attribute features of nodes. Line 10 divides HISN into two partitions based on meta-path. Lines 13\u201314 perform compact feature learning. Line 15 performs a joint model to preserve the first-order proximity between nodes within the same partition. Lines 16\u201319 model the correlation between attribute and structural information. Lines 20\u201321 model the inter-partition proximity.\n(11)\nL3 = \u2212 \u2211\n\u03b5SGmn\u2208E\nlog \u03c3 ( h T m \u00b7 hn ) \u2212 \u2211\nn\u2032=1\nEvn\u2032 \u00b7\ufffdn(v) log \u03c3 ( \u2212hTm \u00b7 hn\u2032 )\n(12)p\u0303(m, n) = \u03c3 ( x\u0303 T m \u00b7 z\u0303n )\n(13)\nL4 =\u2212 \u2211\nm=n or rm,rn\u223cp\u0303(m,n)\nlog \u03c3 ( x\u0303 T m \u00b7 z\u0303n )\n\u2212 \u2211\nn\u2032=1\nEvn\u2032\u223c\ufffdn(v) log \u03c3 ( \u2212x\u0303Tm \u00b7 z\u0303n\u2032 )\n(14)L = L1 + L2 + L3 + L4\nThe DBSCAN\u2011based candidate group generation method After obtaining the feature representation of nodes, we utilize the DBSCAN clustering method to find candidate spammer groups in the reviewers\u2019 embedding space. The reasons for choosing the DBSCAN clustering method are that: (1) it can generate groups adaptively without the need for an artificially predefined number of groups; (2) it can discover groups of arbitrary shapes; and (3) it can find abnormal points in the process of mining groups (Ester et\u00a0 al. 1996). Algorithm\u00a05 describes the specific process of the method."
        },
        {
            "heading": "The group purification and\u00a0ranking method",
            "text": "As some genuine reviewers who coincidently post reviews may be mixed in the detected candidate groups and are misjudged as spammers, we should filter out these innocent individuals. Therefore, we use the group purification method adopted by Zhang et\u00a0 al. (2022a) that can be used for HIN. The basic steps of the method are as follows. First, we calculate the contrast suspiciousness metric. Specifically, we extract the reviewerproduct bipartite graph of each candidate group from the original review dataset. Based on the heterogeneous structure graph of candidate groups, we calculate the contrast suspiciousness metric in terms of structural characteristics of groups, rating time characteristics, and rating distribution characteristics. Secondly, we purify and rank the candidate groups. In particular, we define the spamicity (degree of spam) of an individual reviewer and the spamicity of a group according to the contrast suspiciousness metric. And we rank the candidate groups according to their spamicities to obtain spammer groups.\nContrast suspiciousness metric calculation method Based on the generated candidate groups, we first construct a heterogeneous structure graph of candidate groups, which is defined as follows.\nDefinition 4 Heterogeneous structure graph of candidate groups.\nThe heterogeneous structure graph of candidate groups is defined as BiG = (U ,V ,E) , where U denotes\nall members of the candidate groups and V denotes the set of products reviewed by these members from the original review dataset. Notably, if a member writes multiple reviews on a product, there are multiple edges between them, each of which is associated with a rating and a timestamp.\nIn real life, to reduce the cost of attacks (e.g., time), a group of suspicious reviewers A \u2282 U tends to collectively and actively write reviews on a set of products B \u2282 V in a short period. Therefore, the density score D(A,B) can be used to measure the extent to which A collective reviews the set of products B reviewed (Liu et\u00a0al. 2018).\nwhere fA(vi) denotes the total edge frequency from A to a product vi in B , \u03c3ji denotes the global suspiciousness of an edge, eji refers to the number of edges between (uj , vi).\n(15)    D(A,B) = \ufffd vi\u2208B fA(vi) |A|+|B| fA(vi) = \ufffd\n(uj ,vi)\u2208E\u2227uj\u2208A\n\u03c3jieji\nTo maximize D(A,B) , A and B are mutually dependent. As a result, we introduce the definition of contrast suspiciousness.\nDefinition 5 Contrast suspiciousness (Liu et\u00a0al. 2018).\nThe contrast suspiciousness denoted as P(vi|A) is defined as the conditional probability of a node vi that belongs to B , given A . The values of contrast suspiciousness are proportional to q(\u03b1i) , q(\u03b2i) and q(\u03b3i) . These values are calculated as follows.\n(1) Topology\nA product is suspicious if it is only reviewed by members in A and rarely by other members (Liu et\u00a0al. 2018). From the topology perspective, the contrast suspiciousness satisfies Eq.\u00a0(16).\nwhere \u03b1i \u2208 [0, 1] is the involvement ratio of members in A in the spam activity of a product vi , fU (vi) is the weighted indegree of vi similar to fA(vi) , the edges are weighted by global suspiciousness and q(\u00b7) is a scale function chosen in the exponential form q(x) = bx\u22121 , where b = 32.\n(2) Temporal bursts and drops\nLet the time series of a product vi as T = {(t0, c0), (t1, c1), ..., (te, ce)} , where ci is the number of timestamps in the time box [ti \u2212\ufffdt/2, ti +\ufffdt/2) and t is the box size. The point with the maximum value cm is set as the bursting point, i.e., (tm, cm) . The awakening point of the burst is defined as the point along the time series T , to which the distance from l (the auxiliary straight line from the start point to the bursting point) is greatest. This paper uses the MultiBurst method (Liu et\u00a0 al. 2018) to find the sub-burst points and associated awakening points of multiple bursts. From the perspective of rating time, the contrast suspiciousness satisfies Eq.\u00a0(17).\nwhere \u03b2i \u2208 [0, 1] is the involvement ratio of members in A in multiple bursts, TA is the collection of timestamp from members in A to vi , TU is the collection of timestamps\n(16)\n{ P(vi|A) \u221d q(\u03b1i)\n\u03b1i = fA(vi) fU (vi)\n(17)    P(vi|A) \u221d q(\u03b2i) \u03b2i = \ufffd(TA) \ufffd(TU ) \ufffd(T ) = \ufffd\n(ta,tm)\n\ufffdcamsam \ufffd t\u2208T I(t \u2208 [ta, tm])\nfrom all members to vi , cam is the height difference of burst-awakening point pair, and sam is the slope of burstawakening point pair.\nTo capture the sudden drop pattern after attacking, we draw another auxiliary straight line from the highest point (tm, cm) to the last point (te, ce) . The point of death (td , cd) (i.e., the end of the drop) is found by maximizing the distance to this straight line. We use the MaxDrop method (Liu et\u00a0al. 2018) to find the maximum drop and slope. A product of the maximum drop and slope is used in Eq.\u00a0(15) to measure the global suspiciousness of an edge.\nwhere cbd is the fall of maximum drop, and sbd is the slope of the maximum drop.\n(3) Rating deviation and aggregation\nFor each product, we use the KL-divergence from the distribution between members in A and other members in U\\A to calculate the rating deviation and weight it by a balancing factor. From the perspective of rating distribution, the contrast suspiciousness satisfies Eq.\u00a0(19).\nwhere k denotes the rating category, Fk(vi) denotes the frequency with which members in A rated product vi with category k scores, and F \u2032k(vi) denotes the frequency with which other members U\\A rated product vi with category k scores.\nUltimately, we use joint probability to aggregate the three signals above to obtain the contrast suspiciousness metric."
        },
        {
            "heading": "The candidate group purification and\u00a0ranking method",
            "text": "Based on the contrast suspiciousness metric, the spamicity for a reviewer can be calculated according to Eq.\u00a0(21).\n(18)\u03c3 = \ufffdcbd \u00b7 sbd\n(19)    P(vi|A) \u221d q(\u03b3i) \u03b3i = \ufffd k\u2264K Fk(vi) log Fk (vi) F \u2032 k (vi)\n\u03b3i = min \ufffd\nfA(vi) fU\\A(vi)\n, (vi) \ufffd \u00b7 \u03b3i\n(20)P(vi|A) = q(\u03b1i)q(\u03b2i)q(\u03b3i) = b\u03b1i+\u03b2i+\u03b3i\u22123\n(21)S(uj \u2208 A)= \u2211\nvi:(uj ,vi)\u2208E\n\u03c3jiejiP(vi|A)\nwhere \u03c3ji is the global suspiciousness on an edge, eji is the number of edges between (uj , vi) , and P(vi|A) is the contrast suspiciousness.\nTo increase the association of a candidate group A with a set of products reviewed B , we use the expectation of the density score D(A,B) over the probability P(vi|A) as the spamicity of a group. The objective function is defined according to Eq.\u00a0(22).\nWe describe the specific steps for group purification and ranking in Algorithm\u00a0 6. The algorithm takes one candidate group A in Candidate_Group at a time as the input, and uses a priority tree to efficiently find the reviewer with the lowest spamicity in A and remove it. Then, the contrast suspiciousness changes, and the reviewer\u2019s spamicities are updated. The algorithm decreases A until A is empty, obtaining A\u2217 that maximizes the value of the objective function. The A\u2217 with a group size greater than or equal to 2 is placed into Spammer_Group . Based on spamicities, we rank the groups in Spammer_Group . Finally, the algorithm returns the top 300 most suspicious spammer groups.\n(22)\nmax A Obj(A) =E[D(A,B)]\n= 1\n|A|+ \u2211 k\u2208V P(vk |A)\n\u2211\ni\u2208V\nfA(vi)P(vi|A)"
        },
        {
            "heading": "Experiments",
            "text": ""
        },
        {
            "heading": "Dataset and\u00a0human labeling",
            "text": "As there is no ground truth for spammer groups in the e-commerce field, we need to label the datasets to compare the performance of the spammer group detection methods. In this subsection, we first introduce the dataset used in the experiments and then detail the method for manually labeling the dataset."
        },
        {
            "heading": "Dataset",
            "text": "In our experiments, we use the unlabeled AmazonBooks review dataset. AmazonBooks is a dataset of book reviews from 1993 to 2014, which includes 22,507,155 reviews, 8,026,324 reviewers, and 2,330,066 products. Due to the large amount of review data, we only extracted data in 2013 for experiments according to the GSDB method (Ji et\u00a0 al. 2020). Finally, we got 6,990,316 reviews, 2,998,380 reviewers, and 1,079,741 products. Table\u00a02 shows the statistics of the dataset."
        },
        {
            "heading": "Human labeling",
            "text": "The problem of spammer group detection is very challenging because of no available standard datasets with group labels for model building or method evaluation. Although our SGDCTH method is completely unsupervised and does not require any labels in its\nimplementation, we need to obtain labels for the final groups to analyze the impact of parameter values on group detection performance and to achieve performance comparisons with baseline methods. Therefore, we hired three graduate student experts in the e-commerce environment to manually label the resulting top 300 spammer groups that are generated by each detection method and take these labels as ground truth.\nSpecifically, we use five individual spam indicators used by Ji et\u00a0al. (2020) to label groups output by Algorithm\u00a05, including Rating deviation (RD), Ratio of Extreme Rating (EXR), The Most Reviews One-day (MRO), Account Duration (AD), and Active time interval reviews (ATR). The human labeling method is divided into three steps. First, each group member is assigned 1 point for each spam judgment, 0.5 points for each borderline judgment, and 0 for non-spam judgment. Secondly, we calculate each group\u2019s total spamicity and average spamicity score according to the labels of its members. Thirdly, if the average spamicity score of a group is greater than or equal to 2/3, then the group will be labeled as a spammer group.\nBaselines, evaluation metrics, and\u00a0experimental setting"
        },
        {
            "heading": "Baselines",
            "text": "To evaluate the performance of our method, we compare it with four classical unsupervised spammer group detection methods.\n(1) GSDB (Ji et\u00a0al. 2020). A review burst-based spammer group detection method. From the viewpoint of single-product, GSDB uses the Kernel Density Estimation (KDE) method to generate candidate groups from the review bursts of target products and further purify and classify the candidate groups to obtain spammer groups. The similarity between SGDCTH and GSDB is that both detect spammer groups from the viewpoint of products. The difference is that the SGDCTH method detects spammer groups for cross-product attacks and considers the structural-attribute correlation.\n(2) GSBC (Wang et\u00a0 al. 2018). A graph-based spammer group detection method that introduces a topdown computational framework to identify spammer groups using the topology of a reviewer graph. The similarity between SGDCTH and GSBC is that both are graph-based methods. The difference is that the SGDCTH method takes products as the entry point and constructs a heterogeneous network to detect spammer groups. (3) GroupStrainer (Ye and Akoglu 2015). A two-step method for discovering target products and spammer groups in a heterogeneous network. The similarity between SGDCTH and GroupStrainer is that both detect spammer groups in heterogeneous networks. The difference is that the SGDCTH method considers the structure-attribute correlation and uses the group purification method to further improve the performance of the spammer group detection method. (4) HoloScope (Liu et\u00a0al. 2018). A method that uses the Singular Value Decomposition (SVD) method in a heterogeneous network to detect dense subgraphs. The similarity between SGDCTH and HoloScope is that both detect spammer groups in heterogeneous networks. The difference is that the SGDCTH method is from the viewpoint of products and considers the structure-attribute correlation."
        },
        {
            "heading": "Evaluation metrics",
            "text": "As in previous work (Ji et\u00a0 al. 2020; Zhang et\u00a0 al. 2021, 2022a; Wang et\u00a0al. 2016, 2018), we use precision, recall, and F1 values as evaluation criteria, which are defined according to Eqs.\u00a0(23), (24), and (25).\nwhere TP(True Positive) represents the number of spammer groups that are correctly detected, FP (False Positive) represents the number of true groups that are misjudged as a spammer group, and FN (False Negative) represents the number of spammer groups that are not accurately identified.\n(23)Precision = TP\nTP + FP\n(24)Recall = TP\nTP + FN\n(25)F1 = 2 \u00b7 Precision \u00b7 Receall\nPrecision+ Recall\nPrecision reflects the number of correctly detected spammer groups as a percentage of the total number of groups predicted to be spammer groups, with larger values indicating better detection precision. Recall indicates the number of correctly detected spammer groups as a proportion of the total number of spammer groups in practice, with larger values indicating better detection performance. The F1 value reconciles and averages the test precision and recall, reflecting the overall performance of the spammer group detection algorithm."
        },
        {
            "heading": "Experimental settings",
            "text": "We designed three sets of experiments based on the AmazonBooks dataset in 2013. The first set of experiments aims to analyze the impact of parameter values on the group detection performance of our method. The second set of experiments aims to evaluate the performance of our method by comparison with baseline methods, including two analyses. Specifically, the first analysis is the analysis of the precision, recall, and F1 values for group detection methods, and the second is a comparative analysis of the time complexity of SGDCTH with baseline methods, which aims to verify the effectiveness and efficiency of our method. In the third set of experiments, we designed four variants of SGDCTH to verify the necessity of considering all available information and the step of group purification.\nThe SGDCTH method involves three parameters that need to be verified, i.e., the target product filtration threshold, the neighborhood radius threshold, and the minimum number of sample points threshold. The target product filtration threshold \u03b4p\u0303 is between 0.5 and 0.7. To generate a suitable number of candidate groups, we select the neighborhood radius threshold \u03f5 is {0.4, 0.5, 0.6, 0.7, 0.8} and the minimum number of sample points threshold \u03c6 is {2, 3, 4} for experimental verification. In addition, we randomly initialize model parameters with a standard Xavier normal distribution (Glorot and Bengio 2010) and optimize the model with Adam (Kingma and Ba 2014). The number of GNN layers L is 2, the learning rate lr is 0.01, is set as 0 in Eq.\u00a0(4), and the dimension of the raw structural features x is set as 128. We list the parameters for structural autoencoder and attribute autoencoder for two partitions in Table\u00a0 3. The transformation kernel is set as 64\u201316. The number of epochs t is set as 50. The\nnumber of dynamic samples is set as 5. The dimension of the final embedding vector d is set as 128.\nFor the GSDB method, we set the target product filtration threshold \u03b4p as 0.1, the individual spamicity threshold \u03b4I as 0.43, and the group spamicity threshold \u03b4G as 0.57 to obtain a total of 320 groups. For the GSBC method, we set the co-review time window size \u03c4 as 30, the edge weight threshold \u03b4 as 0.1, the user-specified parameter MP as 1000, and the group spamicity threshold \u03b4G as 0.53 to obtain a total of 325 groups. For the GroupStrainer method, the target product filtration threshold \u03b4p is set as 0.75 to filter out target products with high suspicion. For the HoloScope method, the scaling base b is set to 32. In summary, we detail the parameter settings for each method in Table\u00a04."
        },
        {
            "heading": "Results and\u00a0analysis of\u00a0parameter selection",
            "text": "Based on the parameter settings listed in Table\u00a04, we perform the first set of experiments for parameter selection. In this section, we mainly explore the impacts of the target product filtration threshold, the neighborhood radius threshold, and the minimum number of sample points threshold on the detection performance of our method. Notably, when discussing one parameter, other parameters will be set to their best value."
        },
        {
            "heading": "Results and\u00a0analysis of\u00a0the\u00a0target product filtration threshold",
            "text": "We draw a histogram of the NFS value distribution of products, as shown in Fig.\u00a02. The frequencies of products with different NFS values show a skewed distribution, with most products having a concentrated distribution of NFS values between about 0.5 and 0.7. Since the Amazon dataset is relatively dense with reviews, too small a target product filtration threshold \u03b4p\u0303 will increase the time complexity of our method, and too large a value will discard some reviewers in the process of constructing the graph, which negatively affects the algorithm\u2019s detection performance. In our experiments, we obtain through interpolation analysis that when the target product\u2019s filtration threshold \u03b4p\u0303 > 0.65 , the product is vulnerable to attack. Therefore, we will set it as 0.65 and finally obtain 7027 target products."
        },
        {
            "heading": "Results and\u00a0analysis of\u00a0the\u00a0neighborhood radius threshold",
            "text": "Our experiments found that the number of detected spammer groups decreases gradually as the value of \u03f5 increases. To generate a comparable number of groups as the baseline methods, the neighborhood radius threshold \u03f5 is set as {0.4, 0.5, 0.6, 0.7, 0.8}. The impact of \u03f5 on the detection performance of our method will be further explored.\nFigure\u00a0 3 shows the precision and F1 values of our method are gradually improving as the value of \u03f5\nincreases. When the neighborhood radius \u03f5 is set to 0.6, the precision and F1 values of the SGDCTH method are the highest for the top 300 groups, and the recall curve changes more gently. Following that, the precision of our method gradually decreases, as does the number of groups generated. When the neighborhood radius \u03f5 is set to 0.8, only 232 spammer groups are generated.\nResults and\u00a0analysis of\u00a0the\u00a0minimum number of\u00a0sample points threshold Consistent with the neighborhood radius threshold \u03f5, the larger the value of the minimum number of sample\npoints threshold, the smaller the number of discovering groups. Therefore, we set the minimum number of sample point thresholds \u03c6 as {2, 3, 4} to further explore the impact of parameter \u03c6 on the detection performance of our method.\nFigure\u00a0 4 shows the precision of SGDCTH gradually decreases as the value of \u03c6 increases. The precision of SGDCTH is lowest when \u03c6 is set as 4, and only 215 spammer groups are obtained. Although the F1 value is lower for approximately the top 160 groups, after that, the F1 value is higher than when \u03c6 is set as 3 or 4. On the whole, the detection performance of our method for the top 300 groups is better when the minimum number of sample points threshold \u03c6 is set as 2.\nResults and\u00a0comparison analysis for\u00a0the\u00a0group detection method We implemented a second set of experiments to compare the performance of our method with baseline methods. The analysis is mainly carried out in two aspects, i.e., the comparative analysis of the precision, recall, and F1 values and the time complexity.\nResults and\u00a0comparison analysis of\u00a0the\u00a0precision, recall, and\u00a0F1 values Based on the manual labeling of the top 300 groups detected by the GSDB, GSBC, GroupStrainer, HoloScope, and SGDCTH methods, we analyze the precision, recall, and F1 values for SGDCTH with baseline methods, as shown in Fig.\u00a05.\nTable 4 Parameter settings"
        },
        {
            "heading": "Method Parameter Description Value",
            "text": "SGDCTH (Ours) \u03b4p\u0303 Target product filtration threshold 0.5\u20130.7\n\u03f5 Neighborhood radius threshold 0.4\u20130.8 \u03c6 Minimum number of sample points threshold 2, 3, 4\nL Number of GNN layers 2\nlr Learning rate 0.01\nLearnable parameter or fixed scalar 0\nt Number of epochs 50\nd Embedding dimension of nodes 128\nGSDB \u03b4p Target product filtration threshold 0.1\n\u03b4I Individual spamicity threshold 0.43\n\u03b4G Group spamicity threshold 0.57\nGSBC \u03c4 Co-review time window size 30\n\u03b4 Edge weight threshold 0.1\nMP User-specified parameter 1000\n\u03b4G Group spamicity threshold 0.53\nGroupStrainer \u03b4p Target product filtration threshold 0.75\nHoloScope b Scaling base 32\nFigure\u00a0 5a shows the precision curves of SGDCTH, GroupStrainer, and HoloScope consistently outperform the GSBC method, indicating that the heterogeneous graph-based method is capable of digging deeper into the implicit relationships among reviewers than the homogeneous graph-based method to capture spam groups with suspected collusion. Moreover, the precision curve of SGDCTH consistently outperformed that of GroupStrainer and HoloScope, indicating the effectiveness of comprehensively considering structural and attribute features of nodes. The precision curves of SGDCTH and GSDB cross at about the 185th group, before which GSDB outperforms SGDCTH, but after which SGDCTH outperforms GSDB. This is because GSDB only detects spammer groups in review bursts of a single target product, while SGDCTH can detect spammer groups that attack across multiple products, which is closer to the attack method of spammer groups in real life. As can be seen in Fig.\u00a05b, for about the top 130 groups, the recall curve of SGDCTH is slightly lower than that of GroupStrainer, which may be because our method did\nnot detect some spam groups that evaded detection for the purpose of camouflage. However, after that, the recall curve of SGDCTH is better than that of GroupStrainer, HoloScope. Overall, the SGDCTH method seems to have the smoothest recall curve fluctuations.\nFigure\u00a0 5c shows the F1 value obtained by combining precision and recall. Also, the F1 value curve of each method maintains a monotonically increasing state. After about the 120th group, the F1 value of SGDCTH is better than that of the GSBC, GroupStrainer, and HoloScope methods. Finally, it surpasses the GSDB method, which\nillustrates the superiority of cross-product detection and collaborative training methods.\nFrom this, we can draw two conclusions. (1) The SGDCTH, GroupStrainer, and HoloScope methods based on the heterogeneous network are better than the GSBC method based on the homogeneous network. (2) The SGDCTH method for detecting spammer groups in cross-product attacks is more consistent with real-life attacks on spammer groups than the GSDB method for detecting spammer groups from the review bursts of a single product."
        },
        {
            "heading": "Comparison analysis of\u00a0the\u00a0time complexity",
            "text": "We compare and analyze the time complexity of the GSDB, GSBC, GroupStrainer, HoloScope, and SGDCTH methods, as shown in Table\u00a05.\nThe GSDB method uses the KDE method to generate candidate groups in the review bursts of single-product with time complexity O(n2) . The time complexity of the target product filtration and the group purification and classification are both O(n) , resulting in the total time complexity O(n2) . The GSBC method uses three loop levels to construct a reviewer relationship graph with time complexity O(n3) . The group generation and detection stage uses the min-cut method in one level of loops with a time complexity of O(n3) , so the total time complexity is O(n3) . The GroupStrainer method consists of two stages, i.e., target product detection and spammer group generation. Each stage has a time complexity O(n2) , so the total time complexity is O(n2) . For the HoloScope method, the time complexity of constructing the heterogeneous graph is O(n2) , and the time complexity of detecting dense blocks using SVD is O(n log n) , so the total time complexity is O(n2) . For the SGDCTH method, the time complexity of the target product filtration is O(n2) , the time complexity of constructing heterogeneous graph is O(n2) ,\nthe time complexity of node feature representation learning is O(n log n) , the time complexity of candidate groups generation is O(n2) , and the time complexity of the group purification and ranking stage is O(n) , so the total time complexity is O(n2).\nOverall, the total time complexity of GSBC is O(n3) , while the total time complexity of the GSDB, GroupStrainer, HoloScope, and SGDCTH methods are all O(n2) . In addition, since the SGDCTH method first filters target products vulnerable to attack by spammers, it makes SGDCTH focus on the review data closely related to target products, which greatly improves the algorithm\u2019s efficiency."
        },
        {
            "heading": "Analysis of\u00a0ablation",
            "text": "We conduct an ablation analysis to evaluate our method and configure SGDCTH to the following settings.\n(1) SGDCTH_TP. A variant of our method, which utilizes the behavioral metric combining the abnormal distributions of product rating and product average rating used by Ji et\u00a0al. (2020) in filtering target products. (2) SGDCTH_Stru. A variant of our method that only utilizes structural features, but ignores attribute and structure-attribute correlation features. (3) SGDCTH_Attr. A variant of our method that only utilizes attribute features, but ignores structural and structure-attribute correlation features. (4) SGDCTH_Stru+Attr. A variant of our method that utilizes structural and attribute features, but ignores structure-attribute correlation features. (5) SGDCTH_DPC. A variant of our method that utilizes the Density Peaks Clustering (DPC) method to discover candidate groups in the vector space of reviewers. (6) SGDCTH_K-Means. A variant of our method that utilizes the K-Means clustering method to discover candidate groups in the vector space of reviewers. (7) SGDCTH_No purification. A variant of our method that ignores the step of group purification.\nWe analyze the precision, recall, and F1 values for SGDCTH with seven variants, as shown in Fig.\u00a0 6. The precision curve in Fig.\u00a06a shows that SGDCTH achieves the best performance. This is because it comprehensively considers structure, attribute, and structure-attribute correlation features when detecting spammer groups. Furthermore, it uses a more robust NFS metric to filter target products and a group purification method to filter innocent members of candidate groups generated by the DBSCAN method, which further improves the performance of SGDCTH. SGDCTH_TP shows inferior performance to SGDCTH, indicating the NFS metric is more robust to evasion than behavioral metrics (Ye and Akoglu 2015). In the precision curve between the 115th and 240th groups, SGDCTH_Stru and SGDCTH_Attr show inferior performance to SGDCTH_Stru+Attr, which indicates the necessity of considering structure and attribute features comprehensively. The performance of SGDCTH_Stru+Attr is inferior to that of SGDCTH, indicating the importance of considering the structureattribute correlation features. The detection performance of SGDCTH_DPC and SGDCTH_K-Means is inferior to that of SGDCTH, which indicates that DBSCAN is better than DPC and K-Means at discovering spammer groups that attack target products separately. In addition, SGDCTH_No purification shows inferior performance to SGDCTH, indicating the necessity of group purification.\nThe recall curve in Fig.\u00a0 6b shows that SGDCTH_Attr and SGDCTH_Stru+Attr have a higher recall, while SGDCTH_Stru has a lower recall. This indicates that the attribute features of nodes are somewhat adversarial. Spammers are prone to disguising their relationship with other members of groups (i.e., structural features) to evade the detector.\nThe F1 curve in Fig.\u00a0 6c shows that SGDCTH_Attr, SGDCTH_Stru, and SGDCTH_K-Means have the worst performance, indicating that all available information and a better clustering method should be considered when designing the detector to enhance its robustness.\nTable 5 The time complexity of SGDCTH with baseline methods\nMethod Target product filtration Construct graph Feature representation learning\nCandidate groups generation Group purification and ranking (or classification) Total of time complexity\nGSDB O (n) \u00d7 \u00d7 O (n2) O (n) O (n2) GSBC \u00d7 O (n3) \u00d7 O (n3) O (n) O (n3) GroupStrainer O (n2) O (n2) \u00d7 O (n2) \u00d7 O (n2) HoloScope \u00d7 O (n2) \u00d7 O (n log n) \u00d7 O (n2) SGDCTH O (n2) O (n2) O (n log n) O (n2) O (n) O (n2)"
        },
        {
            "heading": "Conclusion",
            "text": "Online fake reviews have increasingly become a real threat to e-commerce evaluation and reputation systems, and detecting spammer groups is key to ensuring the credibility of review information on e-commerce websites. This paper proposes a collaborative trainingbased algorithm for detecting spammer groups in a heterogeneous network called SGDCTH. It greatly reduces the algorithm\u2019s time complexity by filtering target products vulnerable to spammer attacks from the products\u2019 viewpoint. To effectively learn low-dimensional vector representations of nodes, the SGDCTH method uses a collaborative training method to model the intra-partition and inter-partition proximity of a heterogeneous network, which considers the structure-attribute correlation. This makes our method detect suspicious spammer groups in e-commerce in terms of structure and attributes. Since genuine reviewers are easily mixed into the detected candidate groups and misjudged by the detector as spammers, SGDCTH utilizes the group purification method to filter the innocent individuals in candidate groups. This further improves the performance of our SGDCTH method.\nAlthough our SGDCTH method achieves good performance, there is still room for improvement. For example, we use the DBSCAN clustering method to generate candidate groups, but we need to manually set two thresholds. We will explore a method to automatically learn these two thresholds to generate higher-quality groups. Future work also includes designing methods to learn node features more efficiently in heterogeneous networks, as well as simulating the attack patterns of spammer groups to write fake reviews and injecting these data into real datasets to evaluate the performance of the detection method.\nAbbreviations FIM Frequent item mining NFS Network footprint score B&C Group behavior and content S Group structure B&C+S Group behavior and structure HIN Heterogeneous information network HISN Heterogeneous induced sub-network KDE Kernel density estimation SVD Singular value decomposition RD Rating deviation EXR Ratio of extreme rating MRO Most reviews one-day AD Account duration ATR Active time interval reviews\nAcknowledgements The authors would like to thank the editor and anonymous referees for their constructive comments.\nAuthor contributions QZ completed the writing and experiments for the manuscript, ZL and BX examined and validated experiments, and SJ and DKWC provided guidance and suggestions for revision. All authors read and approved the final manuscript.\nFunding This paper is supported in part by the Natural Science Foundation of China (No. 71772107, 62072288), Shandong Nature Science Foundation of China [Grant No. ZR2019MF003, ZR2020MF044].\nAvailability of data and materials When certain data sharing requirements are met, the data is available upon request. Such requests should be sent to the first author of this paper."
        },
        {
            "heading": "Declarations",
            "text": "Competing interests The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\nReceived: 22 February 2023 Accepted: 13 April 2023\nReferences Akoglu L, Chandy R, Faloutsos C (2013) Opinion fraud detection in online\nreviews by network effects. In: Proceedings of the international AAAI conference on web and social media, vol 7, 1st edn. pp 2\u201311\nCao N, Ji S, Chiu DK, He M, Sun X (2020) A deceptive review detection framework: combination of coarse and fine-grained features. Expert Syst Appl 156:113465 Cao N, Ji S, Chiu DK, Gong M (2022) A deceptive reviews detection model: separated training of multi-feature learning and classification. Expert Syst Appl 187:115977 Chao J, Zhao C, Zhang F (2022) Network embedding-based approach for detecting collusive spamming groups on E-commerce platforms. In: Security and communication networks, pp 1\u201313 Ester M, Kriegel HP, Sander J, Xu X (1996) A density-based algorithm for discovering clusters in large spatial databases with noise. In: KDD, vol 96, 34th edn. pp 226\u2013231 Glorot X, Bengio Y (2010). Understanding the difficulty of training deep feedforward neural networks. In: Proceedings of the thirteenth international conference on artificial intelligence and statistics. JMLR Workshop and Conference Proceedings, pp 249\u2013256 Hu Y (2021) Unsupervised learning for spammer group detection based on network representation. Univ Electron Sci Technol China. https:// doi. org/ 10. 27005/d. cnki. gdzku. 2021. 000829 Huang W, Li Y, Fang Y, Fan J, Yang H (2020) BiANE: Bipartite attributed network embedding. In: Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval. pp 149\u2013158 Ji SJ, Zhang Q, Li J, Chiu DK, Xu S, Yi L, Gong M (2020) A burst-based unsupervised method for detecting review spammer groups. Inf Sci 536:454\u2013469 Jindal N, Liu B (2008) Opinion spam and analysis. In: Proceedings of the 2008 International Conference on Web Search and Data Mining. pp 219\u2013230 Kingma DP, Ba J (2014) Adam: a method for stochastic optimization. arXiv preprint arXiv: 1412. 6980 Li FH, Huang M, Yang Y, Zhu X (2011) Learning to identify review spam. In: Twenty-second international joint conference on artificial intelligence Li H, Fei G, Wang S, Liu B, Shao W, Mukherjee A, Shao J (2017) Bimodal distribution and co-bursting in review spam detection. In: Proceedings of the 26th international conference on World Wide Web. pp 1063\u20131072 Liu S, Hooi B, Faloutsos C (2018) A contrast metric for fraud detection in rich graphs. IEEE Trans Knowl Data Eng 31(12):2235\u20132248 Luca M (2016) Reviews, reputation, and revenue: the case of Yelp. Com. (March 15, 2016). Harvard Business School NOM Unit Working Paper, (12-016) Mukherjee A, Liu B, Glance N (2012). Spotting fake reviewer groups in consumer reviews. In: Proceedings of the 21st International Conference on World Wide Web. pp 191\u2013200 Mukherjee A, Kumar A, Liu B, Wang J, Hsu M, Castellanos M, Ghosh R (2013) Spotting opinion spammers using behavioral footprints. In: Proceedings of the 19th ACM SIGKDD international conference on knowledge discovery and data mining. pp 632\u2013640 Ott M, Choi Y, Cardie C, Hancock JT (2011) Finding deceptive opinion spam by any stretch of the imagination. arXiv preprint arXiv: 1107. 4557 Rayana S, Akoglu L (2015) Collective opinion spam detection: Bridging review networks and metadata. In: Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining. pp 985\u2013994 Shehnepoor S, Togneri R, Liu W, Bennamoun M (2021) HIN-RNN: a graph representation learning neural network for fraudster group detection with no handcrafted features. In: IEEE transactions on neural networks and learning systems. pp 1\u201314 Shehnepoor S, Togneri R, Liu W, Bennamoun M (2022) Spatio-temporal graph representation learning for fraudster group detection. In: IEEE transactions on neural networks and learning systems. pp 1\u201315 Wang G, Xie S, Liu B, Yu PS (2012) Identify online store review spammers via social review graph. ACM Trans Intell Syst Technol (TIST) 3(4):1\u201321 Wang Z, Hou T, Song D, Li Z, Kong T (2016) Detecting review spammer groups via bipartite graph projection. Comput J 59(6):861\u2013874 Wang Z, Gu S, Zhao X, Xu X (2018) Graph-based review spammer group detection. Knowl Inf Syst 55(3):571\u2013597 Wang J, Guo Y, Wen X, Wang Z, Li Z, Tang M (2020) Improving graph-based label propagation algorithm with group partition for fraud detection. Appl Intell 50(10):3291\u20133300 Wang X, Liu N, Han H, Shi C (2021a) Self-supervised heterogeneous graph neural network with co-contrastive learning. In: Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining. pp 1726\u20131736\nWang Y, Zhang J, Guo S, Yin H, Li C, Chen H (2021b) Decoupling representation learning and classification for GNN-based anomaly detection. In: Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval. pp 1239\u20131248 Wang X, Bo D, Shi C, Fan S, Ye Y, Philip SY (2022) A survey on heterogeneous graph embedding: methods, techniques, applications and sources. IEEE Trans Big Data 9(2):415\u2013436 Xu C, Zhang J, Chang K, Long C (2013) Uncovering collusive spammers in Chinese review websites. In: Proceedings of the 22nd ACM international conference on information & knowledge management. pp 979\u2013988 Xu K, Hu W, Leskovec J, Jegelka S (2018) How powerful are graph neural networks? arXiv preprint arXiv: 1810. 00826 Ye J, Akoglu L (2015) Discovering opinion spammer groups by network footprints. In: Machine learning and knowledge discovery in databases: European conference, ECML PKDD 2015, Porto, Portugal, September 7\u201311, 2015, Proceedings, Part I 15. pp 267\u2013282 Zhang F, Hao X, Chao J, Yuan S (2020a) Label propagation-based approach for detecting review spammer groups on e-commerce websites. KnowlBased Syst 193:105520 Zhang Y, Li Y, Gu X, Ji S (2021) A group spam detection algorithm combining behavior and structural feature reasoning. Comput Eng Sci 43(05):926\u2013935 Zhang Q, Ji S, Zhang W et al (2022a) Group spam detection algorithm considering structure and behavior characteristics. Appl Res Comput 39(05):1374\u20131379 Zhang F, Yuan S, Wu J, Zhang P, Chao J (2022b) Detecting collusive spammers on e-commerce websites based on reinforcement learning and adversarial autoencoder. Expert Syst Appl 203:117482 Zhang S, Yin H, Chen T, Hung QVN, Huang Z, Cui L (2020b) GCN-based user representation learning for unifying robust recommendation and fraudster detection. In: Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval. pp 689\u2013698 Zheng M, Zhou C, Wu J, Pan S, Shi J, Guo L (2018) FraudNE: a joint embedding approach for fraud detection. In: 2018 international joint conference on neural networks (IJCNN). IEEE, pp 1\u20138 Zhu C, Zhao W, Li Q, Li P, Da Q (2019) Network embedding-based anomalous density searching for multi-group collaborative fraudsters detection in social media. Comput Mater Continua 60(1):317\u2013333"
        },
        {
            "heading": "Publisher\u2019s Note",
            "text": "Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations."
        }
    ],
    "title": "Detecting fake reviewers in heterogeneous networks of buyers and sellers: a collaborative training-based spammer group algorithm",
    "year": 2023
}