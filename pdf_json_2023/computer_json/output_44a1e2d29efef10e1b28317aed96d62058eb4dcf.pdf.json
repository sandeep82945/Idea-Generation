{
    "abstractText": "Recently, multi-expert methods have led to significant improvements in long-tail recognition (LTR). We summarize two aspects that need further enhancement to contribute to LTR boosting: (1) More diverse experts; (2) Lower model variance. However, the previous methods didn\u2019t handle them well. To this end, we propose More Diverse experts with Consistency Self-distillation (MDCS) to bridge the gap left by earlier methods. Our MDCS approach consists of two core components: Diversity Loss (DL) and Consistency Self-distillation (CS). In detail, DL promotes diversity among experts by controlling their focus on different categories. To reduce the model variance, we employ KL divergence to distill the richer knowledge of weakly augmented instances for the experts\u2019 self-distillation. In particular, we design Confident Instance Sampling (CIS) to select the correctly classified instances for CS to avoid biased/noisy knowledge. In the analysis and ablation study, we demonstrate that our method compared with previous work can effectively increase the diversity of experts, significantly reduce the variance of the model, and improve recognition accuracy. Moreover, the roles of our DL and CS are mutually reinforcing and coupled: the diversity of experts benefits from the CS, and the CS cannot achieve remarkable results without the DL. Experiments show our MDCS outperforms the state-of-the-art by 1% \u223c 2% on five popular long-tailed benchmarks.",
    "authors": [
        {
            "affiliations": [],
            "name": "Qihao Zhao"
        },
        {
            "affiliations": [],
            "name": "Chen Jiang"
        },
        {
            "affiliations": [],
            "name": "Wei Hu"
        },
        {
            "affiliations": [],
            "name": "Fan Zhang"
        },
        {
            "affiliations": [],
            "name": "Jun Liu"
        }
    ],
    "id": "SP:8b38df7a3e372bde31b05abaad107d5e99757eb7",
    "references": [
        {
            "authors": [
                "Philip Bachman",
                "Ouais Alsharif",
                "Doina Precup"
            ],
            "title": "Learning with pseudo-ensembles",
            "venue": "Advances in neural information processing systems,",
            "year": 2014
        },
        {
            "authors": [
                "Cristian Bucilu\u01ce",
                "Rich Caruana",
                "Alexandru Niculescu"
            ],
            "title": "Mizil. Model compression",
            "venue": "In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,",
            "year": 2006
        },
        {
            "authors": [
                "Mateusz Buda",
                "Atsuto Maki",
                "Maciej A Mazurowski"
            ],
            "title": "A systematic study of the class imbalance problem in convolutional neural networks",
            "venue": "Neural Networks,",
            "year": 2018
        },
        {
            "authors": [
                "Jonathon Byrd",
                "Zachary Lipton"
            ],
            "title": "What is the effect of importance weighting in deep learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "Jiarui Cai",
                "Yizhou Wang",
                "Jenq-Neng Hwang"
            ],
            "title": "Ace: Ally complementary experts for solving long-tailed recognition in one-shot",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Kaidi Cao",
                "Colin Wei",
                "Adrien Gaidon",
                "Nikos Arechiga",
                "Tengyu Ma"
            ],
            "title": "Learning imbalanced datasets with label-distribution-aware margin loss",
            "year": 1906
        },
        {
            "authors": [
                "Defang Chen",
                "Jian-Ping Mei",
                "Can Wang",
                "Yan Feng",
                "Chun Chen"
            ],
            "title": "Online knowledge distillation with diverse peers",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Ekin D Cubuk",
                "Barret Zoph",
                "Jonathon Shlens",
                "Quoc V Le"
            ],
            "title": "Randaugment: Practical automated data augmentation with a reduced search space",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops,",
            "year": 2020
        },
        {
            "authors": [
                "Jiequan Cui",
                "Shu Liu",
                "Zhuotao Tian",
                "Zhisheng Zhong",
                "Jiaya Jia"
            ],
            "title": "Reslt: Residual learning for long-tailed recognition",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Jiequan Cui",
                "Zhisheng Zhong",
                "Shu Liu",
                "Bei Yu",
                "Jiaya Jia"
            ],
            "title": "Parametric contrastive learning",
            "venue": "In Proceedings of the IEEE/CVF international conference on computer vision,",
            "year": 2021
        },
        {
            "authors": [
                "Yin Cui",
                "Menglin Jia",
                "Tsung-Yi Lin",
                "Yang Song",
                "Serge Belongie"
            ],
            "title": "Class-balanced loss based on effective number of samples",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Xiyang Dai",
                "Yinpeng Chen",
                "Jianwei Yang",
                "Pengchuan Zhang",
                "Lu Yuan",
                "Lei Zhang"
            ],
            "title": "Dynamic detr: End-toend object detection with dynamic attention",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Jia Deng",
                "Wei Dong",
                "Richard Socher",
                "Li-Jia Li",
                "Kai Li",
                "Li Fei-Fei"
            ],
            "title": "Imagenet: A large-scale hierarchical image database",
            "venue": "IEEE conference on computer vision and pattern recognition,",
            "year": 2009
        },
        {
            "authors": [
                "Alexey Dosovitskiy",
                "Lucas Beyer",
                "Alexander Kolesnikov",
                "Dirk Weissenborn",
                "Xiaohua Zhai",
                "Thomas Unterthiner",
                "Mostafa Dehghani",
                "Matthias Minderer",
                "Georg Heigold",
                "Sylvain Gelly"
            ],
            "title": "An image is worth 16x16 words: Transformers for image recognition at scale",
            "venue": "arXiv preprint arXiv:2010.11929,",
            "year": 2020
        },
        {
            "authors": [
                "Qiushan Guo",
                "Xinjiang Wang",
                "Yichao Wu",
                "Zhipeng Yu",
                "Ding Liang",
                "Xiaolin Hu",
                "Ping Luo"
            ],
            "title": "Online knowledge distillation via collaborative learning",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Haibo He",
                "Edwardo A Garcia"
            ],
            "title": "Learning from imbalanced data",
            "venue": "IEEE Transactions on knowledge and data engineering,",
            "year": 2009
        },
        {
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2016
        },
        {
            "authors": [
                "Geoffrey Hinton",
                "Oriol Vinyals",
                "Jeff Dean"
            ],
            "title": "Distilling the knowledge in a neural network",
            "venue": "arXiv preprint arXiv:1503.02531,",
            "year": 2015
        },
        {
            "authors": [
                "Youngkyu Hong",
                "Seungju Han",
                "Kwanghee Choi",
                "Seokjun Seo",
                "Beomsu Kim",
                "Buru Chang"
            ],
            "title": "Disentangling label distribution for long-tailed visual recognition",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Grant Van Horn",
                "Oisin Mac Aodha",
                "Yang Song",
                "Alexander Shepard",
                "Hartwig Adam",
                "Pietro Perona",
                "Serge J. Belongie"
            ],
            "title": "The inaturalist challenge",
            "venue": "dataset. CoRR,",
            "year": 2017
        },
        {
            "authors": [
                "Nathalie Japkowicz",
                "Shaju Stephen"
            ],
            "title": "The class imbalance problem: A systematic study",
            "venue": "Intelligent data analysis,",
            "year": 2002
        },
        {
            "authors": [
                "Bingyi Kang",
                "Yu Li",
                "Sa Xie",
                "Zehuan Yuan",
                "Jiashi Feng"
            ],
            "title": "Exploring balanced feature spaces for representation learning",
            "venue": "In International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Bingyi Kang",
                "Saining Xie",
                "Marcus Rohrbach",
                "Zhicheng Yan",
                "Albert Gordo",
                "Jiashi Feng",
                "Yannis Kalantidis"
            ],
            "title": "Decoupling representation and classifier for long-tailed recognition",
            "year": 1910
        },
        {
            "authors": [
                "Salman H Khan",
                "Munawar Hayat",
                "Mohammed Bennamoun",
                "Ferdous A Sohel",
                "Roberto Togneri"
            ],
            "title": "Cost-sensitive learning of deep feature representations from imbalanced data",
            "venue": "IEEE transactions on neural networks and learning systems,",
            "year": 2017
        },
        {
            "authors": [
                "Alex Krizhevsky",
                "Geoffrey Hinton"
            ],
            "title": "Learning multiple layers of features from tiny images",
            "year": 2009
        },
        {
            "authors": [
                "Samuli Laine",
                "Timo Aila"
            ],
            "title": "Temporal ensembling for semisupervised learning",
            "venue": "arXiv preprint arXiv:1610.02242,",
            "year": 2016
        },
        {
            "authors": [
                "Jun Li",
                "Zichang Tan",
                "Jun Wan",
                "Zhen Lei",
                "Guodong Guo"
            ],
            "title": "Nested collaborative learning for long-tailed visual recognition",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Tianhong Li",
                "Peng Cao",
                "Yuan Yuan",
                "Lijie Fan",
                "Yuzhe Yang",
                "Rogerio S Feris",
                "Piotr Indyk",
                "Dina Katabi"
            ],
            "title": "Targeted supervised contrastive learning for long-tailed recognition",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Tsung-Yi Lin",
                "Priyal Goyal",
                "Ross Girshick",
                "Kaiming He",
                "Piotr Doll\u00e1r"
            ],
            "title": "Focal loss for dense object detection",
            "venue": "IEEE transactions on pattern analysis and machine intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Ze Liu",
                "Yutong Lin",
                "Yue Cao",
                "Han Hu",
                "Yixuan Wei",
                "Zheng Zhang",
                "Stephen Lin",
                "Baining Guo"
            ],
            "title": "Swin transformer: Hierarchical vision transformer using shifted windows",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Ziwei Liu",
                "Zhongqi Miao",
                "Xiaohang Zhan",
                "Jiayun Wang",
                "Boqing Gong",
                "Stella X Yu"
            ],
            "title": "Large-scale long-tailed recognition in an open world",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Alexander Long",
                "Wei Yin",
                "Thalaiyasingam Ajanthan",
                "Vu Nguyen",
                "Pulak Purkait",
                "Ravi Garg",
                "Alan Blair",
                "Chunhua Shen",
                "Anton van den Hengel"
            ],
            "title": "Retrieval augmented classification for long-tail visual recognition",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2022
        },
        {
            "authors": [
                "Eran Malach",
                "Shai Shalev-Shwartz"
            ],
            "title": "Decoupling \u201dwhen to update\u201d from \u201dhow to update",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "S\u00e9bastien Marcel",
                "Yann Rodriguez"
            ],
            "title": "Torchvision the machine-vision package of torch",
            "venue": "In Proceedings of the 18th ACM international conference on Multimedia,",
            "year": 2010
        },
        {
            "authors": [
                "Aditya Krishna Menon",
                "Sadeep Jayasumana",
                "Ankit Singh Rawat",
                "Himanshu Jain",
                "Andreas Veit",
                "Sanjiv Kumar"
            ],
            "title": "Long-tail learning via logit adjustment",
            "venue": "arXiv preprint arXiv:2007.07314,",
            "year": 2020
        },
        {
            "authors": [
                "Takeru Miyato",
                "Shin-ichi Maeda",
                "Masanori Koyama",
                "Shin Ishii"
            ],
            "title": "Virtual adversarial training: a regularization method for supervised and semi-supervised learning",
            "venue": "IEEE transactions on pattern analysis and machine intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Rafael M\u00fcller",
                "Simon Kornblith",
                "Geoffrey E Hinton"
            ],
            "title": "When does label smoothing help",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "Seulki Park",
                "Youngkyu Hong",
                "Byeongho Heo",
                "Sangdoo Yun",
                "Jin Young Choi"
            ],
            "title": "The majority can help the minority: Context-rich minority oversampling for long-tailed classification",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2022
        },
        {
            "authors": [
                "Nikolaos Passalis",
                "Anastasios Tefas"
            ],
            "title": "Learning deep representations with probabilistic knowledge transfer",
            "venue": "In Proceedings of the European Conference on Computer Vision (ECCV),",
            "year": 2018
        },
        {
            "authors": [
                "Baoyun Peng",
                "Xiao Jin",
                "Jiaheng Liu",
                "Dongsheng Li",
                "Yichao Wu",
                "Yu Liu",
                "Shunfeng Zhou",
                "Zhaoning Zhang"
            ],
            "title": "Correlation congruence for knowledge distillation",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2019
        },
        {
            "authors": [
                "Jiawei Ren",
                "Cunjun Yu",
                "Shunan Sheng",
                "Xiao Ma",
                "Haiyu Zhao",
                "Shuai Yi",
                "Hongsheng Li"
            ],
            "title": "Balanced metasoftmax for long-tailed visual recognition",
            "venue": "arXiv preprint arXiv:2007.10740,",
            "year": 2020
        },
        {
            "authors": [
                "Jiawei Ren",
                "Cunjun Yu",
                "Shunan Sheng",
                "Xiao Ma",
                "Haiyu Zhao",
                "Shuai Yi",
                "Hongsheng Li"
            ],
            "title": "Balanced metasoftmax for long-tailed visual recognition",
            "venue": "arXiv preprint arXiv:2007.10740,",
            "year": 2020
        },
        {
            "authors": [
                "Mehdi Sajjadi",
                "Mehran Javanmardi",
                "Tolga Tasdizen"
            ],
            "title": "Regularization with stochastic transformations and perturbations for deep semi-supervised learning",
            "venue": "Advances in neural information processing systems,",
            "year": 2016
        },
        {
            "authors": [
                "Kihyuk Sohn",
                "David Berthelot",
                "Nicholas Carlini",
                "Zizhao Zhang",
                "Han Zhang",
                "Colin A Raffel",
                "Ekin Dogus Cubuk",
                "Alexey Kurakin",
                "Chun-Liang Li"
            ],
            "title": "Fixmatch: Simplifying semi-supervised learning with consistency and confidence",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Peize Sun",
                "Rufeng Zhang",
                "Yi Jiang",
                "Tao Kong",
                "Chenfeng Xu",
                "Wei Zhan",
                "Masayoshi Tomizuka",
                "Lei Li",
                "Zehuan Yuan",
                "Changhu Wang"
            ],
            "title": "Sparse r-cnn: End-to-end object detection with learnable proposals",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Zehua Sun",
                "Qiuhong Ke",
                "Hossein Rahmani",
                "Mohammed Bennamoun",
                "Gang Wang",
                "Jun Liu"
            ],
            "title": "Human action recognition from various data modalities: A review",
            "venue": "IEEE transactions on pattern analysis and machine intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Christian Szegedy",
                "Vincent Vanhoucke",
                "Sergey Ioffe",
                "Jon Shlens",
                "Zbigniew Wojna"
            ],
            "title": "Rethinking the inception architecture for computer vision",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2016
        },
        {
            "authors": [
                "Antti Tarvainen",
                "Harri Valpola"
            ],
            "title": "Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Peng Wang",
                "Kai Han",
                "Xiu-Shen Wei",
                "Lei Zhang",
                "Lei Wang"
            ],
            "title": "Contrastive learning based hybrid networks for longtailed image classification",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Peng Wang",
                "Kai Han",
                "Xiu-Shen Wei",
                "Lei Zhang",
                "Lei Wang"
            ],
            "title": "Contrastive learning based hybrid networks for longtailed image classification",
            "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2021
        },
        {
            "authors": [
                "Xudong Wang",
                "Long Lian",
                "Zhongqi Miao",
                "Ziwei Liu",
                "Stella X Yu"
            ],
            "title": "Long-tailed recognition by routing diverse distribution-aware experts",
            "venue": "arXiv preprint arXiv:2010.01809,",
            "year": 2020
        },
        {
            "authors": [
                "Xiu-Shen Wei",
                "Peng Wang",
                "Lingqiao Liu",
                "Chunhua Shen",
                "Jianxin Wu"
            ],
            "title": "Piecewise classifier mappings: Learning fine-grained learners for novel categories with few examples",
            "venue": "IEEE Transactions on Image Processing,",
            "year": 2019
        },
        {
            "authors": [
                "Liuyu Xiang",
                "Guiguang Ding",
                "Jungong Han"
            ],
            "title": "Learning from multiple experts: Self-paced knowledge distillation for long-tailed classification",
            "venue": "In European Conference on Computer Vision,",
            "year": 2020
        },
        {
            "authors": [
                "Cihang Xie",
                "Alan Yuille"
            ],
            "title": "Intriguing properties of adversarial training at scale",
            "venue": "arXiv preprint arXiv:1906.03787,",
            "year": 2019
        },
        {
            "authors": [
                "Yue Xu",
                "Yong-Lu Li",
                "Jiefeng Li",
                "Cewu Lu"
            ],
            "title": "Constructing balance from imbalance for long-tailed image recognition",
            "venue": "In European Conference on Computer Vision,",
            "year": 2022
        },
        {
            "authors": [
                "Yuzhe Yang",
                "Zhi Xu"
            ],
            "title": "Rethinking the value of labels for improving class-imbalanced learning",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Linfeng Zhang",
                "Jiebo Song",
                "Anni Gao",
                "Jingwei Chen",
                "Chenglong Bao",
                "Kaisheng Ma"
            ],
            "title": "Be your own teacher: Improve the performance of convolutional neural networks via self distillation",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2019
        },
        {
            "authors": [
                "Yifan Zhang",
                "Bryan Hooi",
                "Lanqing Hong",
                "Jiashi Feng"
            ],
            "title": "Test-agnostic long-tailed recognition by test-time aggregating diverse experts with self-supervision",
            "venue": "arXiv preprint arXiv:2107.09249,",
            "year": 2021
        },
        {
            "authors": [
                "Yifan Zhang",
                "Bryan Hooi",
                "Lanqing Hong",
                "Jiashi Feng"
            ],
            "title": "Self-supervised aggregation of diverse experts for testagnostic long-tailed recognition",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Yifan Zhang",
                "Bingyi Kang",
                "Bryan Hooi",
                "Shuicheng Yan",
                "Jiashi Feng"
            ],
            "title": "Deep long-tailed learning: A survey",
            "venue": "arXiv preprint arXiv:2110.04596,",
            "year": 2021
        },
        {
            "authors": [
                "Yongshun Zhang",
                "Xiu-Shen Wei",
                "Boyan Zhou",
                "Jianxin Wu"
            ],
            "title": "Bag of tricks for long-tailed visual recognition with deep convolutional neural networks",
            "venue": "In Proceedings of the AAAI conference on artificial intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Ying Zhang",
                "Tao Xiang",
                "Timothy M Hospedales",
                "Huchuan Lu"
            ],
            "title": "Deep mutual learning",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2018
        },
        {
            "authors": [
                "QiHao Zhao",
                "Wei Hu",
                "Yangyu Huang",
                "Fan Zhang"
            ],
            "title": "Pdiff+: Improving learning classifier with noisy labels by noisy negative learning loss",
            "venue": "Neural Networks,",
            "year": 2021
        },
        {
            "authors": [
                "Qihao Zhao",
                "Yangyu Huang",
                "Wei Hu",
                "Fan Zhang",
                "Jun Liu"
            ],
            "title": "Mixpro: Data augmentation with maskmix and progressive attention labeling for vision transformer",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Zhisheng Zhong",
                "Jiequan Cui",
                "Shu Liu",
                "Jiaya Jia"
            ],
            "title": "Improving calibration for long-tailed recognition",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2021
        },
        {
            "authors": [
                "Boyan Zhou",
                "Quan Cui",
                "Xiu-Shen Wei",
                "Zhao-Min Chen"
            ],
            "title": "Bbn: Bilateral-branch network with cumulative learning for long-tailed visual recognition",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Bolei Zhou",
                "Agata Lapedriza",
                "Aditya Khosla",
                "Aude Oliva",
                "Antonio Torralba"
            ],
            "title": "Places: A 10 million image database for scene recognition",
            "venue": "IEEE transactions on pattern analysis and machine intelligence,",
            "year": 2017
        },
        {
            "authors": [
                "Jianggang Zhu",
                "Zheng Wang",
                "Jingjing Chen",
                "Yi-Ping Phoebe Chen",
                "Yu-Gang Jiang"
            ],
            "title": "Balanced contrastive learning for long-tailed visual recognition",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1. Introduction",
            "text": "Deep learning has achieved remarkable progress in a range of computer vision (CV) tasks, such as image recognition [17, 14, 64, 30, 63], object detection [45, 12], and\n*Equal contribution. \u2020The Corresponding author is with the College of Information Science and Technology and the Interdisciplinary Research Center for Artificial Intelligence, Beijing University of Chemical Technology, China\naction recognition [46]. Despite advances in deep technologies and computational capability, great success is also highly dependent on well-designed large datasets such as ImageNet [13] and Places [67], where each category has sufficient and roughly balanced training samples. However,\nar X\niv :2\n30 8.\n09 92\n2v 2\n[ cs\n.C V\n] 3\n0 N\nov 2\nreal-world data tends to be long-tailed over semantic categories [60]: a few categories contain many instances (called head categories), while most categories contain only a few instances (called tail categories). Long-tailed recognition (LTR) is challenging because it needs to deal not only with the numerous small data learning problems of the tail categories but also with the extremely unbalanced classification of all categories. Deep models trained with such long-tailed data are usually biased toward head categories on balanced testing data and perform poorly on tail categories.\nTo address this challenge, many approaches have explored long-tail recognition in order to learn wellperforming models from long-tailed data, such as class rebalancing/re-weighting [3, 4, 24, 29, 11, 6, 54, 35], decoupling learning [23] and contrastive learning [56, 22, 49, 68, 10]. Recently, long-tailed recognition methods employing multi-expert ensemble learning [53, 51, 5, 59, 27] have achieved state-of-the-art (SOTA) performance. We summarize two key aspects of these approaches that need further improvement for boosting LTR. (1) Diverse experts experts focus on different aspects, maximizing the expertise of each [5, 51]. More diversity can support experts in improving LTR. (2) There is a heavy model variance in the prediction of the model, especially for the tail category. So, reducing model variance is essential for LTR. Previous multi-expert methods [53, 51, 5, 59, 27] focused on the above two aspects but did not handle them well. RIDE [51] utilizes a loss to moderate diversity, yet individual experts focus primarily on head categories. ACE and SADE [5, 51, 59] focus on the diverse experts, which learn classification knowledge from sub-categories or dominant categories. However, The \u201dtail category experts\u201d of these methods can greatly suppress head category performance while focusing on the tail categories. Furthermore, these multi-expert methods all employ an ensemble method to reduce the final variance while ignoring the variance of each expert. Among them, NCL [27] introduces strong data augmentation [8] that provides a better generalization of the model. However, there is still a high risk of model variance in its one-hot label supervision for strongly augmented instances. To this end, we design a novel method, namely More Diverse experts with Consistency Self-distillation (MDCS), for long-tailed recognition.\nOur proposed MDCS contains two key components, Diversity Loss (DL) and Consistency Self-distillation (CS). Our DL contains an adjustable distribution weight, to cater to the diversity of each expert. By adjusting the distribution weight, each expert tends to recognize different categories, such as Many-shot categories, Medium-shot categories, and Few-shot categories. It is a simple yet effective method for increasing diversity and significantly improving recognition accuracy over previous methods (discussed in Sec. 4). To reduce the model variance and avoid model over-\nfitting instances, we look forward to providing each expert with a richer form of supervision when learning strongly augmented samples. The label-smoothing regularization [47, 37] is a straightforward way, and further MiSLAS [65] proposes label-aware smoothing for long-tailed recognition. However, the proportion of label-smoothing assignments of these methods is still instance-agnostic, and more reasonable label assignment principles remain to be explored. To this end, we design CS for each expert, which distills richer instance knowledge from predictions of weakly augmented data to regularize strongly augmented instances. Especially for a mini-batch instance, we propose Confident Instance Sampling (CIS) to select the correctly classified instances for consistency self-distillation. In this way, our proposed CIS can prevent CS from introducing biased/noisy knowledge. As illustrated in Fig. 1, the model trained with strong augmentation method [8] could reduce the model variance [51] compared with the model trained with weakly augmented instances (e.g., flipped, cropped). However, our CS trains the model on strongly augmented instances and is supervised by \u201dsoft labels\u201d from the predictions of weakly augmented instances, leading to lower model variance and higher recognition accuracy. These \u201dsoft labels\u201d, produced by prediction on weakly augmented representation, contain more knowledge than their one-hot labels. In addition, the roles of our DL and CS are mutually reinforcing and coupled: (1) Our CS is designed for each expert, which increases the diversity and recognition accuracy of a single expert, and ultimately benefits the ensemble model. (2) Without the DL, the CS cannot achieve remarkable results as the model is biased towards head categories (discussed in Sec. 6).\nIn the experiments, our proposed MDCS model outperforms state-of-the-art (SOTA) methods by a significant margin on five commonly used benchmark datasets. For instance, on CIFAR-100-LT with an imbalance factor of 100, our approach achieves an accuracy of 56.1%. Similarly, on ImageNet-LT with ResNeXt-50, our model achieves an accuracy of 61.8%, while on iNaturalist 2018 with ResNet-50, we achieve an accuracy of 75.6%."
        },
        {
            "heading": "2. Related Work",
            "text": "Long-tailed Visual Recognition. Conventional methods to alleviate the long-tailed problem are to design re-balancing paradigms that consist of re-sampling and reweighting. Re-sampling methods, which over-sample tail classes or under-sample head classes, aim to achieve a more balanced data distribution. Re-sampling by simply oversampling minority classes [3, 4, 38] and under-sampling by abandoning data for dominant classes [21, 16, 3]. However, over-sampling duplicated tailed samples might lead to the over-fitting of minority classes [3]. Under-sampling potentially loses head class information and certainly impairs the\ngeneralization ability of the DNNs. Re-weighting methods [24, 29, 11, 6, 54, 35, 42, 55] assign weights to different classes by loss modification or logits adjustment. However, some researchers observed that re-balancing methods will hurt representation learning, and decoupling representation with classifiers will lead to better features. Therefore, twostage learning was proposed which first trains the model with original data and then fine-tunes the classifier with class-balanced data [33]. Transfer learning is another way to tackle the long-tailed problem, aiming to transfer knowledge learned from majority classes to minority classes. But knowledge transfer methods often need carefully designed structures such as memory bank [31, 50, 32]. More recently, many works try to improve the performance of long-tailed visual recognition by using contrastive learning (CL) strategy [56, 22, 49, 68, 10, 28]. For example, PaCo [10] introduces a set of class-wise learnable center to overcome bias on high-frequency classes of basic supervised contrastive learning (SCL).\nEnsemble-based methods, which use multiple experts with aggregation methods, are receiving more and more attention due to their effectiveness on long-tailed recognition. LFME [53] trains different experts with different parts of the dataset and distills the knowledge from these experts to a student model. RIDE [51] optimizes experts jointly with distribution-aware diversity loss and trains a router to handle hard samples. SADE [58] proposed test-time experts aggregating method to handle unknown test class distributions. Recently proposed NCL [27] uses mutual distillation allowing every expert to learn knowledge from others. They still have shortcomings in terms of expert diversity and model variance.\nKnowledge Distillation. Knowledge distillation(KD) [2, 18, 39] was proposed for the purpose of model compression by transferring knowledge learned from a powerful teacher model to a student model. KD is performed by supervising the student model with soft labels generated by the teacher model, which also provides better generalization to the student model. KD has gradually evolved from an offline process [40, 18, 39], where the teacher model has trained ahead of time, to an online process [7, 15, 62], where teacher model and student model are trained simultaneously. Unlike offline or online KD, self-distillation [57] assumes that one model can be its own teacher, where the teacher model and student model are identical.\nConsistency regularization. Consistency regularization has played a very important role in semi-supervised learning, which was first proposed by Bachman [1] and popularized by Sajjadi [43] and Laine [26]. Consistency regularization utilizes unlabeled data by assuming the model should output the same result when the inputs are similar. Specifically, given two different formations of perturbation of a training sample, the gap in the output is treated as a\nloss to train the model. There are various ways to generate perturbed input [36, 48]. A common method is employing two different formations of data augmentation on the same image [44]. FixMatch [44] computes an artificial label for each unlabeled sample by computing the model\u2019s predicted class distribution given a weakly-augmented version. Unlike the above methods, our proposed consistency selfdistillation first designs without extra hyper-parameters, combines consistency mechanisms that transfer the richer knowledge of weakly augmented instances to provide more supervision, and employs confidence instance sampling to remove biased/noisy knowledge. Benefiting from these well-designed components, our method effectively reduces the model variance and improves generalization ability."
        },
        {
            "heading": "3. Method",
            "text": "The proposed MDCS consists of two parts, Diversity Loss(DL) and Consistency Self-distillation(CS), aiming to improve the diversity of experts and reduce model variance, respectively. In the following part, we first introduce the preliminaries of long-tailed recognition. Then, we elaborate on our proposed DL and CS. Finally, we show the overall loss of the training process."
        },
        {
            "heading": "3.1. Preliminaries",
            "text": "Long-tail identification attempts to learn a wellrepresented classification model from a training dataset with a long-tailed class distribution. Formally, let Ds = {(xi, yi)|1 \u2264 i \u2264 ns} be a training set, which xi is the i-th training sample and yi \u2208 {0, 1}C is its corresponding onehot label over C classes. The test set Dt = {(xi, yi)|1 \u2264 i \u2264 nt} is defined in the similar way. Let nj denote the number of training samples for class j, and let N = \u2211C j=1 nj be the total number of training samples. Without loss of generality, we assume that the classes are decreasingly ordered, i.e., if i<j, then ni \u2265 nj . Additionally, an imbalanced dataset has significant differences in the class instance numbers, ni \u226b nj ."
        },
        {
            "heading": "3.2. Diversity Loss",
            "text": "For training diversity experts, one intuitive approach is to train different experts to focus on different sub-categories. We propose our Diversity Softmax defined as:\np(x; \u03b8) = n\u03bbkexp(v k)\u2211C c=1 n \u03bb c exp(v c) , \u03bb \u2208 (\u2212\u221e,\u221e), (1)\nwhere vk is the class-k output of the model f(xi; \u03b8) with parameter \u03b8, and nk is the number of training samples for category k. The diversity softmax function maps a model\u2019s class-k output vk to the probability p(x; \u03b8). More importantly, the introduced \u03bb acts as a weight distribution parameter for logit adjustment. Fortunately, in our experiments,\nwe discover that it has the effect of generating a reversed weight of long-tailed distribution when \u03bb > 1. Then, we can employ it to train an expert to improve the accuracy of minority categories with original long-tailed data distribution. Similarly, when \u03bb < 0, it has the effect of aggravating the imbalance of original long-tailed data, which makes the expert pay more attention to the head categories. When the \u03bb is set to (0, 1), it can weaken the influence of longtailed distribution [41, 35]. Notably, the aggravation is sensible because our intention is to improve the diversity of all experts in all categories. The experiments in Sec. 6 also demonstrate the effect of \u03bb for simulating weight distribution.\nWith diversity softmax, we propose our Diversity Loss (DL) for diversity experts learning. The DL is defined as:\nLDL = 1 \u2225D\u2225 \u2211 xi\u2208D \u2212yi log \u03c3(f(xi; \u03b8) + w), (2)\nwhere the \u03c3(\u00b7) is the standard softmax function and w is:\nw = \u03bb logNC , (3)\nwhere NC is a list consisting of the number of training samples for each category. In the default setting, we employ DL for training three experts, namely E1, E2, and E3, focusing on Many-shot classes, Medium-shot classes, and Few-shot classes respectively. Visually, Fig. 2 illustrates a multiexpert model with a shared backbone f\u03b8 and three experts trained with DL. The only difference between the Diverse Loss for different experts is the distribution weight w, such as whead for E1, wbalance for E2, and wtail for E3. In general, the structure of our diversity experts learning can have\nany number of experts E\u00b5(\u00b5 = 1, 2, 3, ...). The effect of the number of experts is shown in the later section 6."
        },
        {
            "heading": "3.3. Consistency Self-distillation",
            "text": "Overall view. In this section, we propose an elegant Consistency Self-distillation (CS) approach to tackle the model variance problem. Our CS method distills richer knowledge from a normal image to a distorted version of the same image. As demonstrated in the left part of Fig. 2, we first construct an original image xi to two different views denoted as xi and x\u0303i by a weak augmentation (e.g. crop, flip) and a strong argumentation (e.g. RandAug [8]). For different Expert E\u00b5, we employ diversity softmax to conduct probabilities p(xi; \u03b8) and p\u0303(xi; \u03b8) for given (xi, x\u0303i):\np(xi; \u03b8) = n\u03bbkexp(v k i /T )\u2211C\nc=1 n \u03bb c exp(v c i/T )\n, (4)\np\u0303(x; \u03b8) = n\u03bbkexp(v\u0303 k i /T )\u2211C\nc=1 n \u03bb c exp(v\u0303 c i /T )\n, (5)\nwhere T is a temperature (a higher T produces a softer probability distribution over categories[18]). Then, our proposed CS employs the Kullback-Leibler(KL) divergence to perform self-distillation for an instance, which can be formulated as:\nLCS = KL(p(xi; \u03b8)||p(x\u0303i; \u03b8)). (6)\nConfident Instance Sampling As our diversity experts specialize in certain categories and may perform poorly in\nother categories. To prevent CS distills from all instances introducing biased knowledge, we only distill the instances which are correctly classified. Thus, we define Confident Instance set contain all correctly classified instances as:\nDCI = {xi \u2208 D|argmax(p(xi; \u03b8)) == yi}, (7)\nwhere yi is the ground-truth label of instance xi. Furthermore, we re-formulate the loss of CS with CIS as:\nLCS = 1 \u2225DCI\u2225 \u2211 xi\u2208DCI KL(p(xi; \u03b8)||p(x\u0303i; \u03b8)) (8)"
        },
        {
            "heading": "3.4. Model Training",
            "text": "The overall loss in our proposed MDCS consists of two parts, the Loss LDL of diversity loss and the Loss LCS of consistency self-distillation with CIS. Finally, we denote the set of Expert as E and formulate the overall loss as:\nLall = \u2211\nE\u00b5\u2208E (LDL\u00b5 + \u03b1LCS\u00b5 ) (9)\nwhere \u03b1 is a hyperparameter to adjust the weight of Consistency Self-distillation. In addition, we conduct the effect of parameter \u03b1 in Sec. 6."
        },
        {
            "heading": "4. Method Analysis",
            "text": ""
        },
        {
            "heading": "4.1. More Diverse Experts",
            "text": "Definition of diversity. According to our empirical analysis, more diverse experts could contribute to the improvement of long-tailed recognition. However, the previous works [59, 51] don\u2019t present a measure of diversity. Here, we propose a measure called the diversity factor (\u03c3), defined for a model containing M experts as:\n\u03c3 = M\u22c3 \u00b5=1 S\u00b5 (10)\nwhere S\u00b5 is all the correctly classified samples in the test set by Expert Eu. The S\u00b5 can define as:\nS\u00b5 = {argmax(p(xi; \u03b8\u00b5)) == yi, (xi, yi) \u2208 Dt} (11)\nThe bigger \u03c3 represents greater diversity for the ensemble model.\nComparison with SOTA methods. The recognition accuracy and diversity factor results are shown in Table 1, where we compare our result with the prior art, such as RIDE and SADE. The RIDE [51] aims to improve diversity through KL-divergence between experts. However, simply maximizing the KL divergence between experts cannot lead to good diversity and accuracy. SADE is limited\nRIDE [51]\nImageNet-LT CIFAR100-LTModel\nMany Med. Few All Many Med. Few All\nE1 Acc 64.3 49.0 31.9 52.6 63.5 44.8 20.3 44.0\nE2 Acc 64.7 49.4 31.2 52.8 63.1 44.7 20.2 43.8\nto only generating different inversely long-tailed data distributions by adjusting the hyper-parameter in the inverse softmax loss [59] and the accuracy and diversity of Manyor Medium-shot is severely inhibited for the \u201dtail category expert,\u201d E3. The results show a significant advantage of our method in terms of both diversity and accuracy. The E1 trained with our DL shows significant improvement in diversity and accuracy in Many-shot categories and similar results in medium-shot categories and Few-shot categories. The E2 and E3 in MDCS also show great strengths in all three shots, which demonstrates the effectiveness of our DL.\nThe effect of \u03bb for diversity. Table 2 shows different \u03bb used in diversity loss to increase the model diversity. With\n\u03bb all set to 0, the experts focus on head or tail categories, which gives the model poor diversity. With \u03bb set to {1, 1, 1}, experts focus on average different categories, the model could get better diversity. With \u03bb set to {0, 1, 2} and {-0.5, 1, 2.5}, experts focus on different categories, the model gets best diversity."
        },
        {
            "heading": "4.2. Lower Model Variance",
            "text": "Model variance is the degree of variation in the predictions produced by the same model on different training datasets. With high model variance, the model may perform very differently on different training data, which may indicate that the model overfitted the training data and thus performs poorly in generalizing to unseen data. For n random data sets B(1),..., B(m), the k-th models trained on B(k) will predict y(k) for instance x. The mean predicted value of these models is y, which is denote:\ny = 1\nm m\u2211 k=1 y(k), (12)\nand the model variance denotes:\nVar(x, f) = 1\nm m\u2211 k=1 (y(k) \u2212 y)2. (13)\nTo establish a benchmark for model variance, we compare our approach against three baseline methods: cRT [23], RIDE [51] and RIDE with label smoothing (LS) [47]. These metrics are evaluated using twenty independently trained models, trained on CIFAR100-LT with 300 samples for class 0 (IF = 100) [51]. In Table 3, compare with cRT, RIDE and RIDE with LS, our model has better accuracy performance as well as lower model variance. It also suggests that our approach has better generalization than using ensemble model and label smoothing regularization to reduce model variance.\nWe also conduct experiments to show the effect of our proposed method on the model variance. Table 4 shows that\nthe model with our consistency self-distillation (CS) effect reduces the model variance of each expert for the Many-, Medium-, and Few-shot subsets."
        },
        {
            "heading": "5. Experiments",
            "text": "In this section, we perform experiments on five widely used datasets in long-tailed recognition, including CIFAR100/10-LT [25], ImageNet-LT [31], Places-LT [31], and iNaturalist 2018 [20]. After that, we conduct ablation experiments on the CIFAR100-LT and ImageNet-LT datasets to gain further insights."
        },
        {
            "heading": "5.1. Dataset",
            "text": "CIFAR100/10-LT. CIFAR100/10-LT is the long-tailed version of CIFAR100/10 [25]. CIFAR-100/10 contains 50,000 images for training and 10,000 images for the validation of size 32 \u00d7 32 with 100/10 classes. Following [51, 58], we use the same long-tailed version for a fair comparison. The imbalanced factor (IF) \u03b2 is defined by \u03b2 = Nmax/Nmin, and this reflects the degree of imbalance in the data. The imbalance factors used in the experiment are set to 100 and 50.\nImageNet-LT and Places-LT. ImageNet-LT and PlacesLT are the long-tailed versions of the dataset ImageNet2012 [13] and the large-scale scene classification dataset Places [67] proposed by Liu [31]. We follow their work by conducting the same dataset by sampling subsets following the Pareto distribution with the power value \u03b3 = 6. Overall, ImageNet-LT has 115.8K images from one thousand categories with an imbalanced factor \u03b2 = 1280/5. Places-LT contains 184.5K images from 365 categories with imbalanced factor \u03b2 = 4980/5.\niNaturalist 2018. iNaturalist [20] is a large-scale realworld dataset for long-tailed recognition, which suffers from extremely imbalanced distribution. It contains 437.5K training images and 24.4K validation images from 8142 categories. In addition, the fine-grained problem makes it more\nchallenging [52]. Moreover, we follow the works [27, 59] to divide classes into Many-shot(with more than 100 images), Medium-shot (with 20 - 100 images), and Few-shot (with less than 20 images) parts and report the results on each part."
        },
        {
            "heading": "5.2. Implementation Details",
            "text": "Ensemble method. The final ensemble is average across the experts.\nArchitecture and settings. We use the same setup for all the baselines and our method. Specifically, following previous work [51, 27, 58], we employ ResNet-32 for CIFAR100/10-LT, ResNeXt-50/ResNet-50 for ImageNetLT, ResNet-152 for Places-LT and ResNet-50 for iNaturalist 2018 as backbones, respectively. Moreover, we adopt the cosine classifier for prediction on all datasets. If not specified, we use the SGD optimizer with a momentum of 0.9 and set the initial learning rate as 0.1 with linear decay. We set \u03bb = {-0.5, 1, 2.5} and \u03b1 = 0.6 in our method for all benchmarks. The results of our comparison method are taken from their original paper and our results are averaged over three experiments. More implementation details about epochs we have marked in the comparison table and the hyper-parameter statistics are reported in Appendix.\nAugmentation. Our purposed CS utilizes weaklyaugmented view and strongly-augmented view to conduct self-distillation. On the CIFAR10/100-LT dataset, the weak augmentation includes crop, horizontal flip, and rotation. The strong augmentation uses CIFAR10Policy besides the basic augmentation. For ImageNet-LT, Places-LT, and iNaturalist, we use cropping, horizontal flipping, rotation, and ColorJitter as weak augmentation. For a fair comparison, we utilize RandAug [8] as strong augmentation for ImageNet-LT and iNaturalist 2018. We add RandomGrayscale and Gaussian Blur to the basic data augmentation composing strong augmentation for Places-LT following previous work [27]."
        },
        {
            "heading": "5.3. Comparisons with SOTA on Benchmarks",
            "text": "Long-Tailed CIFAR-100 and CIFAR-10. The comparison results between MDCS and other methods on longtailed CIFAR datasets are shown in Table 5. We conduct experiments on CIFAR100-LT and CIFAR10-LT with imbalance factors of 100 and 50. Additionally, for fairness, we compare results for 200 epochs and 400 epochs respectively. Our MDCS significantly outperforms the previous method on all groups, including 56.1% on the CIFAR100LT dataset with an IF of 100 when trained for 400 epochs.\nImageNet-LT, Places-LT, and iNaturalist 2018. Table 6, 7, and 12 list the Top-1 accuracy of SOTA methods utilizing different backbones on ImageNet-LT, Places-LT, and iNaturalist 2018, respectively. We report the overall Top1 accuracy as well as the Top-1 accuracy on Many-shot,\nMedium-shot, and Few-shot groups for Place-LT, and iNaturalist 2018. For fair comparisons, we report the accuracy results at different epochs and these results are from their origin papers. Compared with prior arts, such as PaCo, BCL, NCL, and SADE, our proposed MDCS achieves SOTA performance in the same setting."
        },
        {
            "heading": "6. Ablation Study and Further Analysis",
            "text": "Simulating weight distributions by \u03bb. To enrich the diversity of each expert, the Diversity Loss employs the hyper-parameter \u03bb to simulate different weight distributions for each expert\u2019s training. Fig. 3 indicates how different \u03bb can affect the accuracy of Many-shot, medium-shot, and few-shot categories and overall accuracy. When \u03bb increases, the accuracy of Many-shot categories decreases while the accuracy of few-shot categories increases, which demonstrates the ability to simulate different weight distributions. Besides, when \u03bb gets high enough, the accuracy of few-shot classes will decrease. This is due to the few-shot group having 30 categories on CIFAR100-LT, this categorization is not fine-grained enough to cater to the effect of the extremely inversely long-tailed distribution generated.\nInfluence of data augmentations. The RandAug [8] is widely employed as its strong generalization for long-tailed recognition [27, 68, 10]. In this subsection, we conduct dif-\nferent augmentations on training samples to evaluate the effectiveness of weak-strong consistency self-distillation. The results are shown in Table 9, where we compare weakstrong distillation with weak-weak distillation and strongstrong distillation. The results of weak-strong consistency self-distillation are better than strong-strong distillation, which demonstrates that the excellence of our structure does not depend entirely on RandAugment.\nImpact of a different number of experts. Our proposed MDCS is a multi-expert framework. The number of experts can be easily extended by adjusting \u03bb for different experts. We conduct experiments to demonstrate the power of multiple experts. As shown in Fig. 4 (a), the performance of MDCS tends to get better when the number of experts increases. The \u03bb for the one-expert model is {1}, for the two-expert model is {\u22120.5, 2.5}, for the three-expert model is {\u22120.5, 1, 2.5},\nfor the four-expert model is {\u22120.5, 0, 1, 2.5}, for the five-expert model is {\u22120.5, 0, 1, 2, 2.5}, for the six-expert model is {\u22121,\u22120.5, 0, 2, 2.5, 3}, and for the seven-expert model is {\u22121,\u22120.5, 0, 1, 2, 2.5, 3}.\nThe rule for setting \u03bb. The ensemble models are not sensitive to the hyper-parameter \u03bb within a reasonable range, so we can easily choose \u03bb just to spread across this range. When the number of branches of experts\nincreases, we first average divide experts into the three groups to set \u03bb. For the head group, the \u03bb \u2208 [-1, 0.5], for the balanced group, the \u03bb \u2208 (0.5, 1.5), for the tail group, the \u03bb \u2208 [1.5, 3]. when the values of \u03bb for different experts fell within the above three ranges, the multiexpert model exhibits effective performance improvements. For example, we set {\u22120.5, 1, 2.5} for three experts and {\u22121,\u22120.5, 0, 1, 2, 2.5, 3} for seven experts.\nInfluence of loss weight \u03b1. The \u03b1 is an adjusted loss weight of Consistency Self-distillation to control the contribution of the CS part in total loss. To find an appropriate for \u03b1, A series of values experimented on the CIFAR100LT dataset. As shown in Fig. 4 (b), the best performance is achieved when \u03b1 = 0.6. The best result means a balance of supervised learning and self-distillation.\nAblation studies on all components. In this subsection, we conduct detailed ablation studies on the CIFAR100LT dataset to analyze every component of our MDCS. As shown in Table 10, we evaluate the proposed components including Diverse Loss (DL), weak-strong augmentation(w/RandAug), Consistency Self-distillation (CS), respectively. The %in DL means we use normal Softmax to conduct experiments and the %in w/RandAug means we employ weak-weak augmentation. As shown in Table, our proposed Diversity Loss improves the performance by 2.9%. It is a core component because, without our DL, the other components are less effective at improving perfor-\nmance. MDCS Employing weak-strong augmentation can improve performance from 50.7% to 54.1%, which proves the strength of RandAug [8, 27]. Eventually, when conducting our proposed CS, the performance is significantly further improved, from 54.6% to 56.1%."
        },
        {
            "heading": "7. Conclusion",
            "text": "In this paper, we propose a novel method, MDCS, to cater to the diversity and variance of multi-expert, leading to improved long-tailed recognition accuracy. Our MDCS contains two core components: (1) diversity loss (DL), which can effectively enhance the diversity of experts. (2) consistency self-distillation (CS), which is a novel selfdistillation method for reducing the model variance. Furthermore, we propose confident instance sampling in CS to ensure unbiased knowledge. In analyses and ablation studies, we analyze the effectiveness of our proposed core components through experimental results. Moreover, the roles of our DL and CS are mutually reinforcing and coupled. Experimental evidence shows that our MDCS achieves significant performance over the SOTA methods on five popular benchmarks, including 56.1% (+1.9%) accuracy on CIFAR100-LT with an IF 100, 61.8% (+1.3%) accuracy on ImageNet-LT with ResNeXt-50, and 75.6% (+0.7%) accuracy on iNaturalist 2018 with ResNet-50."
        },
        {
            "heading": "Acknowledgement",
            "text": "This work was supported in part by the National Natural Science Foundation of China under Grant No.62271034, and in part by the Fundamental Research Funds for the Central Universities under Grant XK2020-03.\nAppendix 1. The Efficiency of Consistency Self-distillation As illustrated in Fig. 5, previous methods [51, 5, 59] reduced the model variance only by using an ensemble of multiple experts. In contrast, our approach not only reduces the variance by ensemble but also reduces the model variance by CS for each expert. The effect of CS is not\nonly to reduce the model variance. Each expert gets richer constraint information through weakly augmented images, which enhances the expert\u2019s own recognition ability. As shown in Table 11, experts with stronger recognition abilities also produce more diverse ensemble models.\n2. More Details Settings We implement our method with PyTorch. Following [59, 27], we use ResNeXt-50/ResNet-50 for ImageNet-LT, ResNet-32 for CIFAR100/10-LT, ResNet-152 for Places-LT and ResNet-50 for iNaturalist 2018 as backbones, respectively. Moreover, we adopt the cosine classifier for prediction on all datasets. The details settings for our method are shown in table 12."
        }
    ],
    "title": "MDCS: More Diverse Experts with Consistency Self-distillation for Long-tailed Recognition",
    "year": 2023
}