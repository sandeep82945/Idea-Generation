{
    "abstractText": "Lifted planning \u2013 finding plans directly on the PDDL input model \u2013 has attracted renewed attention during the last years. This avoids the process of grounding, which can become computationally prohibitive very easily. However, the main focus of recent research in this area has been on satisficing, i.e., (potentially) suboptimal planning. We present a novel heuristic for optimal lifted planning. Our basic idea is inspired by the LM-cut heuristic, which has been very successful in grounded optimal planning. Like LM-cut, we generate cut-based landmarks via back-chaining from the goal, generating cuts of partially grounded actions. However, exactly mimicking the ground formulation is not feasible, this includes computing the h heuristic several times for one computation of the LM-cut heuristic (which is already NP-hard to compute). We show that our heuristic is admissible and evaluate it in a cost optimal setting.",
    "authors": [
        {
            "affiliations": [],
            "name": "Julia Wichlacza"
        },
        {
            "affiliations": [],
            "name": "Daniel H\u00f6llera"
        },
        {
            "affiliations": [],
            "name": "Daniel Fi\u0161era"
        },
        {
            "affiliations": [],
            "name": "J\u00f6rg Hoffmanna"
        }
    ],
    "id": "SP:931cbad10fad18d5a96b6d3fa2af50845298b6d6",
    "references": [
        {
            "authors": [
                "Blai Bonet",
                "H\u00e9ctor Geffner"
            ],
            "title": "Planning as heuristic search",
            "venue": "Artificial Intelligence,",
            "year": 2001
        },
        {
            "authors": [
                "Blai Bonet",
                "Malte Helmert"
            ],
            "title": "Strengthening landmark heuristics via hitting sets",
            "venue": "Proceedings of the 19th European Conference on Artificial Intelligence",
            "year": 2010
        },
        {
            "authors": [
                "Samuel R. Buss"
            ],
            "title": "An introduction to proof theory\u2019, in Handbook of Proof Theory, volume 137 of Studies in Logic and the Foundations of Mathematics, chapter I",
            "year": 1998
        },
        {
            "authors": [
                "Patrik Haslum"
            ],
            "title": "Computing genome edit distances using domainindependent planning",
            "venue": "Proceedings of the SPARK Workshop,",
            "year": 2011
        },
        {
            "authors": [
                "Malte Helmert"
            ],
            "title": "The Fast Downward planning system",
            "venue": "Journal of Artificial Intelligence Research,",
            "year": 2006
        },
        {
            "authors": [
                "Malte Helmert",
                "Carmel Domshlak"
            ],
            "title": "Landmarks, critical paths and abstractions: What\u2019s the difference anyway?",
            "venue": "Proceedings of the 19th International Conference on Automated Planning and Scheduling",
            "year": 2009
        },
        {
            "authors": [
                "J\u00f6rg Hoffmann",
                "Bernhard Nebel"
            ],
            "title": "The FF planning system: Fast plan generation through heuristic search",
            "venue": "Journal of Artificial Intelligence Research,",
            "year": 2001
        },
        {
            "authors": [
                "Daniel H\u00f6ller",
                "Gregor Behnke"
            ],
            "title": "Encoding lifted classical planning in propositional logic",
            "venue": "Proceedings of the 32nd International Conference on Automated Planning and Scheduling",
            "year": 2022
        },
        {
            "authors": [
                "Rostislav Hor\u010d\u00edk",
                "Daniel Fi\u0161er",
                "\u00c1lvaro Torralba"
            ],
            "title": "Homomorphisms of lifted planning tasks: The case for delete-free relaxation heuristics",
            "venue": "Proceedings of the 36th AAAI Conference on Artificial Intelligence",
            "year": 2022
        },
        {
            "authors": [
                "Erez Karpas",
                "Carmel Domshlak"
            ],
            "title": "Cost-optimal planning with landmarks",
            "venue": "Proceedings of the 21st International Joint Conference on Artificial Intelligence",
            "year": 2009
        },
        {
            "authors": [
                "Alexander Koller",
                "J\u00f6rg Hoffmann"
            ],
            "title": "Waking up a sleeping rabbit: On natural-language sentence generation with FF",
            "venue": "Proceedings of the 20th International Conference on Automated Planning and Scheduling",
            "year": 2010
        },
        {
            "authors": [
                "Alexander Koller",
                "Ronald Petrick"
            ],
            "title": "Experiences with planning for natural language generation",
            "venue": "Computational Intelligence,",
            "year": 2011
        },
        {
            "authors": [
                "Pascal Lauer",
                "\u00c1lvaro Torralba",
                "Daniel Fi\u0161er",
                "Daniel H\u00f6ller",
                "Julia Wichlacz",
                "J\u00f6rg Hoffmann"
            ],
            "title": "Polynomial-time in PDDL input size: Making the delete relaxation feasible for lifted planning",
            "venue": "Proceedings of the 30th International Joint Conference on Artificial Intelligence (IJ-",
            "year": 2021
        },
        {
            "authors": [
                "Rami Matloob",
                "Mikhail Soutchanski"
            ],
            "title": "Exploring organic synthesis with state-of-the-art planning techniques",
            "venue": "Proceedings of the SPARK Workshop,",
            "year": 2016
        },
        {
            "authors": [
                "J. Scott Penberthy",
                "Daniel S. Weld"
            ],
            "title": "UCPOP: A sound, complete, partial order planner for ADL\u2019, in Principles of Knowledge Representation and Reasoning",
            "venue": "Proceedings of the 3rd International Conference",
            "year": 1992
        },
        {
            "authors": [
                "Silvia Richter",
                "Malte Helmert",
                "Matthias Westphal"
            ],
            "title": "Landmarks revisited\u2019, in Proceedings of the 23rd National Conference of the American Association for Artificial Intelligence (AAAI\u201908)",
            "year": 2008
        },
        {
            "authors": [
                "Silvia Richter",
                "Matthias Westphal"
            ],
            "title": "The LAMA planner: Guiding cost-based anytime planning with landmarks",
            "venue": "Journal of Artificial Intelligence Research,",
            "year": 2010
        },
        {
            "authors": [
                "Bram Ridder",
                "Maria Fox"
            ],
            "title": "Heuristic evaluation based on lifted relaxed planning graphs",
            "venue": "Proceedings of the 24th International Conference on Automated Planning and Scheduling",
            "year": 2014
        },
        {
            "authors": [
                "Jendrik Seipp"
            ],
            "title": "Pattern selection for optimal classical planning with saturated cost partitioning",
            "venue": "Proceedings of the 28th International Joint Conference on Artificial Intelligence (IJCAI\u201919),",
            "year": 2019
        },
        {
            "authors": [
                "Julia Wichlacz",
                "Daniel H\u00f6ller",
                "J\u00f6rg Hoffmann"
            ],
            "title": "Landmark heuristics for lifted planning",
            "venue": "Proceedings of the 31st International Joint Conference on Artificial Intelligence",
            "year": 2022
        },
        {
            "authors": [
                "H\u00e5kan L.S. Younes",
                "Reid G. Simmons"
            ],
            "title": "VHPOP: versatile heuristic partial order planner",
            "venue": "Journal of Artificial Intelligence Research,",
            "year": 2003
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Heuristic search has been extremely successful in AI planning (e. g. [2, 12, 10, 22, 25]). But this research has almost exclusively been based on grounded (propositional) task representations, in contrast to the lifted PDDL input models, that employ variables ranging over a finite universe of objects. The grounded representation has \u2013 in worst-case \u2013 size exponential in the arity (number of arguments) of the PDDL predicates and action schemas. Hence, planning techniques at the grounded level are limited to planning tasks where that blow-up is not prohibitive. It has been frequently observed that this excludes a variety of applications (e. g. [11, 16, 17, 8, 19]).\nLifted planning methods do not require grounding as a preprocess. They have been considered throughout the history of AI planning (e. g. [20, 24, 27], but heuristic search planning has begun to develop lifted methods only recently. Research so far devised an effective lifted forward search mechanism [5], lifted delete relaxation [23, 6, 18, 7] and landmark (LM) heuristics [26]. However, most methods focused on satisficing planning, where no guarantee on plan quality is given and hence inadmissible heuristics can be used. The only heuristic for lifted optimal search is hmax [7], but there are two other systems for lifted optimal planning: hlmchom guides a (lifted) search with ground heuristics computed on a reduced model [14]; and LiSAT translates lifted planning problems into a propositional SAT problem [13]. The latter can \u2013 however \u2013 only do length-optimal and not cost-optimal planning.\nA successful heuristic for grounded optimal planning is the LMcut heuristic [10], which generates a set of disjunctive action LMs via back-chaining from the goal definition. It comes with interesting theoretical guarantees and has also been highly successful in empirical\n\u2217 Corresponding Author. Email: wichlacz@cs.uni-saarland.de.\nevaluations. However, it does not directly transfer to lifted planning. The problem is that \u2013 in the grounded setting \u2013 it relies on information from the hmax heuristic [2]. hmax needs to be computed repeatedly for one computation of the LM-cut heuristic, which is expensive (NP-hard) in the lifted setting. The information from hmax is needed in the precondition choice function, which is both important to determine good cuts (i.e., LMs), but also to show theoretical properties.\nHere we present a novel heuristic for lifted optimal planning, which is inspired by the grounded LM-cut heuristic, generating disjunctive action LMs via back-chaining from the goal. In order to circumvent the problem described above, we present alternative precondition choice functions. While this means that we cannot show dominance of hmax (like in the grounded setting), we show that (1) our cuts form partially grounded disjunctive action LMs, and that (2) the resulting heuristic values are admissible.\nWe run experiments on recent benchmarks for lifted planning [18] which we extend with domain variants featuring non-unit action costs. We compare our methods to the competitors given above: lifted hmax, hlmchom, and LiSAT. LiSAT turns out to be dominant in length optimal planning, while cost optimal planning has more mixed results."
        },
        {
            "heading": "2 Preliminaries",
            "text": "We consider normalized PDDL tasks without conditional effects and negative preconditions, and with all formulas being conjunctions of atoms (represented as sets of atoms). To simplify the presentation, we also, w.l.o.g., assume that the initial state as well as the goal consists of a single ground atom. Every planning task can be transformed to this form simply by adding two new auxiliary (ground) actions.\nA normalized PDDL task is a tuple P = \u3008B, T ,V,P,AS , c, \u03c8I , \u03c8G\u3009 where B is a non-empty set of objects, T is a non-empty set of types containing a default type denoted by t0 \u2208 T , objects and types are associated by a total function D : T \u2192 2B such that D(t0) = B and for every pair of types ti, tj \u2208 T it holds that D(ti) \u2286 D(tj) or D(ti) \u2287 D(tj) or D(ti) \u2229 D(tj) = \u2205. V is a denumerable set of variable symbols, each variable v \u2208 V has a type \u03c4var(v) \u2208 T . P is a set of predicate symbols, each predicate p \u2208 P has arity ar(p) \u2208 N and an associated type \u03c4pred(p, i) \u2208 T for every i \u2208 {1, ..., ar(p)}. An atom is of the form p(s1, . . . , sn), where p \u2208 P is a predicate symbol, n = ar(p) is the arity of p, and each si is either an object o \u2208 D(\u03c4pred(p, i)), or a variable v \u2208 V with D(\u03c4var(v)) \u2286 D(\u03c4pred(p, i)). For a given atom \u03b1 = p(s1, . . . , sn), V[\u03b1] \u2282 V denotes a set of variables appearing in the atom, i.e., V[\u03b1] = {s1, . . . , sn} \u2229 V , and P[\u03b1] = p denotes the predicate of \u03b1. Given a set of atoms X , we define V[X] = \u22c3 x\u2208X V[x]\nand P[X] = \u22c3\nx\u2208X P[x]. A ground atom is an atom \u03b1 such that V[\u03b1] = \u2205.\nAS denotes a set of action schemas, each action schema a \u2208 AS is a tuple a = \u3008pre(a), add(a), del(a)\u3009 where pre(a), add(a) and del(a) are sets of atoms, called preconditions, add effects, and delete effects, respectively. We, w.l.o.g., assume non-empty preconditions. By V[a] = V[pre(a) \u222a add(a) \u222a del(a)] we denote a set of variables appearing in the action. The cost function c : AS \u2192 R+0 maps each action schema to a non-negative number.\n\u03c8I and \u03c8G are ground atoms, \u03c8I is called the initial-state atom, and \u03c8G is called the goal atom. A function \u03c3 : V \u222a B \u2192 V \u222a B is called a substitution if \u03c3(o) = o for every object o \u2208 B, and for every variable v \u2208 V it holds that either (i) \u03c3(v) \u2208 D(\u03c4var(v)), or (ii) \u03c3(v) \u2208 V and D(\u03c4var(\u03c3(v))) \u2286 D(\u03c4var(v)). We write \u03c3x to denote \u03c3(x). A set of all substitutions is denoted by S.\nWe extend \u03c3 element-wise to sets and tuples, i.e., if X = {x1, . . . , xn}, then \u03c3X = {\u03c3x1, . . . , \u03c3xn}, and if X = \u3008x1, . . . , xn\u3009, then \u03c3X = \u3008\u03c3x1, . . . , \u03c3xn\u3009.\nGiven a set of substitutions \u03a3 = {\u03c31, . . . , \u03c3n} \u2286 S and an element X (a set X), \u03a3(X) denotes the set {\u03c3x | x \u2208 X} ( \u22c3\n\u03c3\u2208\u03a3 \u03c3(X)). A substitution \u03b3 is called grounding if \u03b3(v) \u2208 B for every v \u2208 V . A set of all groundings is denoted by G. A = S(AS) denotes the set of all possible actions, and we assume that for every two distinct action schemas a \u2208 AS and a\u2032 \u2208 AS it holds that S(a)\u2229S(a\u2032) = \u2205. We also extend the cost function c over the set of actions A by setting c(a) = c(aS) whenever a \u2208 S(aS) for some aS \u2208 AS . A ground action is an action a such that V[a] = \u2205, i.e., G(AS) = G(A) \u2286 A is the set of all ground actions. A state is a set of ground atoms. An initial state is the state {\u03c8I} and every state sG such that \u03c8G \u2208 sG is a goal state. A ground action a is applicable in a state s if pre(a) \u2286 s. The resulting state of applying an applicable ground action a in a state s is the state a[s] = (s \\ del(a)) \u222a add(a). A sequence of ground actions \u03c0 = \u3008a1, . . . , an\u3009 is applicable in a state s0 if there are states s1, . . . , sn such that ai is applicable in si\u22121 and si = a[si\u22121] for every i \u2208 \u30081, . . . , n\u3009. The resulting state of this application is \u03c0[s0] = sn. The cost of the sequence \u03c0 is defined as c(\u03c0) = \u2211n i=1 c(ai). A sequence of ground actions \u03c0 = \u3008a1, . . . , an\u3009 is called plan if it is applicable in the initial state, and \u03c0[{\u03c8I}] \u03c8G is a goal state. To simplify the notation, we use [n] for a natural number n \u2265 1 to denote {1, . . . , n}."
        },
        {
            "heading": "3 Lifted Disjunctive Action Landmarks",
            "text": "On the ground level, a disjunctive action landmark is a set of ground actions out of which at least one must be part of every plan [21, 15]. Given a disjunctive action landmarkL, we can immediately infer that the minimum cost over ground actions from L, which we denote as c(L) = mina\u2208L c(a), is a lower bound on the cost of optimal plans, i.e., it is an admissible estimate from the initial state. Similarly, if we have two disjoint landmarks L and L\u2032, then c(L) + c(L\u2032) is a lower bound as every plan has to contain at least one ground action from L and another one from L\u2032. This clearly generalizes to an arbitrary set of (pairwise disjoint) landmarks, but we can compute a lower bound on the cost of optimal plans also from a set of disjunctive action landmarks sharing some actions using cost partitioning.\nGiven a set of disjunctive action landmarks L1, . . . , Ln, we can associate cost functions c1, . . . , cn mapping ground actions to numbers with L1, . . . , Ln, respectively, and define ci(Li) =\nmina\u2208L ci(a) for every i \u2208 [n]. Then \u2211n\ni=1 ci(Li) is a lower bound on the cost of optimal plans, if the cost functions c1, . . . , cn are constructed in such a way that for every ground action a \u2208 \u22c3 i\u2208[n] Li it holds that \u2211\ni\u2208[n],a\u2208Li ci(a) \u2264 c(a). In other words, the sum over ci(Li) is an admissible estimate as long as we spread the original cost c(a) of each action a appearing in landmarks across the cost functions ci. One particular heuristic function utilizing this principle is the LM-\ncut heuristic [10]. It repeatedly builds the so-called justification graph and then extracts a landmark and the corresponding cost function from it by finding a cut in the graph separating the initial state and goal. The justification graph utilized in LM-cut is a labeled directed multi-graph having facts (ground atoms) as vertices and, for each ground action a, there is a set of edges labeled with a that connect a single selected precondition with all its add effects. Preconditions are selected using the so-called precondition choice function (pcf) mapping ground actions to facts, which selects the precondition with the highest hmax value (breaking ties arbitrarily).\nHere, we build on the aforementioned LM-cut heuristic designed for ground planning. First, we generalize the notion of disjunction action landmarks to the lifted level. Second, we define justification graphs on the lifted level and we generalize the notion by showing it can be built much more freely than it was originally used without loosing its property that any cut separating the initial state and goal corresponds to a landmark. In particular, we show that we can choose preconditions arbitrarily. This is not an entirely new finding as Bonet and Helmert [3] already pointed out that an arbitrary pcf can be used. We expand on this by showing that we do not even need a pcf (as a function mapping (ground) actions to (ground) atoms), but for each add effect of each action, we can choose any precondition freely. Note, however, that choosing freely does not preserve the dominance of the original LM-cut over the hmax heuristic anymore. Third, we show how to extract a sequence of landmarks and the corresponding cost functions from the lifted justification graph in a similar manner as it is done in the ground LM-cut heuristic leading to a new admissible landmark-cut heuristic for lifted planning.\nWe start by introducing the notion of lifted disjunctive action landmark as a set of actions (ground or lifted, i.e., with or without variables) such that its grounding is a ground disjunctive action landmark. That is, L \u2286 A is a lifted disjunctive action landmark if every plan contains at least one ground action from G(L).\nDefinition 1. A set of actions L = {l1, . . . , lm} is called a lifted disjunctive action landmark (or a landmark for short) if for every plan \u03c0 = \u3008a1, . . . , an\u3009 there exist i \u2208 \u30081, . . . , n\u3009, and j \u2208 \u30081, . . . ,m\u3009 such that ai \u2208 G(lj).\nNext, we define a lifted justification graph as a labeled directed multi-graph where vertices are atoms (ground or lifted) and edges are labeled with actions (also ground or lifted). Following the construction of the justification graph from [10], the edges connect actions\u2019 preconditions with their add effects and the graph contains the initial-state and goal facts. In contrast to [10], we do not require a pcf. So, we require that (C1) the initial-state and goal atoms have corresponding vertices in the graph; (C2) every edge is labeled with an action and leads from one of its preconditions to one of its add effects, i.e., we do not require that all edges labeled with the same action start in the same precondition; and (C3) we require that for every non-initial-state atom u there are incoming edges whose labels cover all possible ground actions leading to any ground atom in G(u), i.e., the lifted justification graph must be constructed so that it includes all possible actions leading to an atom appearing in the\ngraph. An s-t-path is then defined as a sequence of edges leading from the vertex (atom) s to the vertex (atom) t, and an s-t-cut is a set of edges separating s and t.\nDefinition 2. A labeled directed multi-graph is a tuple K = \u3008U,E,L\u3009 where U denotes a set of vertices, L denotes a set of labels, and E denotes a set of labeled edges \u3008u, u\u2032, l\u3009, also denoted by u l\u2212\u2192 u\u2032, where u \u2208 U and u\u2032 \u2208 U are start and end vertices, respectively, such that u = u\u2032, and l \u2208 L is a label.\nA sequence of edges \u03c0 = \u3008s1 l1\u2212\u2192 t1, . . . , sn ln\u2212\u2192 tn\u3009 is called an s1-tn-path if for every i \u2208 [n\u2212 1] it holds that ti = si+1. Given two distinct vertices s \u2208 U and t \u2208 U , a set of edges C \u2286 E is called an s-t-cut if every s-t-path contains at least one edge from C.\nDefinition 3. Given a normalized PDDL task P = \u3008B, T ,V,P,A, \u03c8I , \u03c8G\u3009, a labeled directed multi-graph K = \u3008U,E,L\u3009 is called a lifted justification graph for P if all of the following hold:\n(C1) U is a set of atoms, and \u03c8I \u2208 U and \u03c8G \u2208 U , and (C2) for every s l\u2212\u2192 t \u2208 E it holds that l is an action and s \u2208 pre(l) and t \u2208 add(l), and (C3) for every u \u2208 U such that \u03c8I \u2208 G(u), and every grounding\n\u03b3 \u2208 G, and every ground action ag such that \u03b3u \u2208 add(ag), there exists an edge u\u2032 l\u2212\u2192 u \u2208 E such that ag \u2208 G(l).\nNote that any atom can be represented by at most one vertex in a lifted justification graph (cf. condition (C1)). Before we show that every \u03c8I -\u03c8G-cut of any lifted justification graph correspond to a lifted disjunctive action landmark, we prove two auxiliary lemmas. In Lemma 4, we show that every edge u\u2032 l\u2212\u2192 u \u2208 E of a lifted justification graph has its grounded counterparts a \u2208 G(l) and p\u2032 \u2208 pre(a) such that p\u2032 \u2208 G(u\u2032) (and therefore also p\u2032 \u2208 G(pre(l))). In Lemma 5, we show that every plan has its corresponding \u03c8I - \u03c8G-path in every lifted justification graph. The correspondence is such that for every plan \u3008a1, . . . , an\u3009 there is a sequence of labels (actions) \u3008l1, . . . , lm\u3009 induced by some \u03c8I -\u03c8G-path such that for every li there is some aj \u2208 G(li), and the labels have the same ordering as plans\u2019 actions, i.e., given li corresponding to aj and li\u2032 corresponding to aj\u2032 , if i > i\u2032 then j > j\u2032. For the rest of this section, let P = \u3008B, T ,V,P,A, \u03c8I , \u03c8G\u3009 denote a normalized PDDL task.\nLemma 4. Let a denote a ground action, let p \u2208 add(a) denote one of its add effects, and let K = \u3008U,E,L\u3009 denote a lifted justification graph for P. If there exists u \u2208 U such that p \u2208 G(u), then there exists u\u2032 l\u2212\u2192 u \u2208 E such that a \u2208 G(l) and p\u2032 \u2208 G(u\u2032) for some p\u2032 \u2208 pre(a).\nProof. From (C3) it follows that there exists u\u2032 l\u2212\u2192 u \u2208 E such that a \u2208 G(l), and from (C2) we have that u\u2032 \u2208 pre(l) and therefore there exists p\u2032 \u2208 pre(a) such that p\u2032 \u2208 G(u\u2032).\nLemma 5. Let \u03c0 = \u3008a1, . . . , an\u3009 denote a plan, and let K = \u3008U,E,L\u3009 denote a lifted justification graph for P. Then there exists a \u03c8I -\u03c8G-path p = \u3008u0\nl1\u2212\u2192 u1, . . . , um\u22121 lm\u2212\u2212\u2192 um\u3009 with u0 = \u03c8I and um = \u03c8G and an increasing function f : [m] \u2192 [n] such that for every i \u2208 [m] it holds that af(i) \u2208 G(li).\nProof. (By induction) First, we show that there exists um\u22121 lm\u2212\u2212\u2192 um = \u03c8G and ai \u2208 {a1, . . . , an} s.t. ai \u2208 G(lm). Since \u03c0 is a plan,\nwe have that \u03c8G \u2208 \u03c0[\u03c8I ], and from (C1) we have \u03c8G \u2208 U . Let i \u2208 [n] denote an arbitrary number such that \u03c8G \u2208 add(ai). From Lemma 4, we have u l\u2212\u2192 \u03c8G \u2208 E such that ai \u2208 G(l) and p \u2208 G(u) for some p \u2208 pre(a).\nNext, we show that if there exists ux\u22121 lx\u2212\u2192 ux for some x \u2208 [m] and ai \u2208 {a1, . . . , an} s.t. ai \u2208 G(lx), then either (i) ux\u22121 = \u03c8I (and therefore u0 = ux\u22121), or (ii) there exists ux\u22122\nlx\u22121\u2212\u2212\u2212\u2192 ux\u22121 and aj \u2208 {a1, . . . , ai\u22121} s.t. aj \u2208 G(lx\u22121), i.e., j < i and aj precedes ai in \u03c0. Since we assume non-empty preconditions and a singleton initial state, {\u03c8I} = pre(a1) so (i) eventually holds. So, assuming ux\u22121 = \u03c8I , the precondition p \u2208 pre(ai) s.t. p \u2208 G(ux\u22121) (C3) must be achieved by some action preceding ai in \u03c0, therefore there exists aj \u2208 {a1, . . . , ai\u22121} with p \u2208 add(aj) s.t. p \u2208 G(ux\u22121). Therefore (ii) follows from Lemma 4.\nSo, there exists a \u03c8I -\u03c8G-path p = \u3008u0 l1\u2212\u2192 u1, . . . , um\u22121 lm\u2212\u2212\u2192 um\u3009 with each li \u2208 {l1, . . . , lm} corresponding to a different aj \u2208 {a1, . . . , an} in such a way that if li corresponds to aj and li\u2032 corresponds to aj\u2032 , then i > i\u2032 implies j > j\u2032.\nNow we can finally prove that \u03c8I -\u03c8G-cut induces a lifted disjunctive action landmark. The reason is simple: As we know from Lemma 5, every plan \u03c0 has its corresponding \u03c8I -\u03c8G-path p. Therefore, every \u03c8I -\u03c8G-cut contains at least one edge e from every such p, and the edge e in turn corresponds to some action in \u03c0. So, every \u03c8I -\u03c8G-cut goes over at least one action of every plan.\nTheorem 6. Let K = \u3008U,E,L\u3009 denote a lifted justification graph for P, and let C denote an \u03c8I -\u03c8G-cut, and let CL = {l | s l\u2212\u2192 t \u2208 C}. Then CL is a lifted disjunctive action landmark.\nProof. If there is no plan, then any set of actions is a lifted disjunctive action landmark, so let us assume there are some plans. From Lemma 5 it follows that for every plan \u03c0 = \u3008a1, . . . , an\u3009 there exists an \u03c8I -\u03c8G-path p = \u3008u0\nl1\u2212\u2192 u1, . . . , um\u22121 lm\u2212\u2212\u2192 um\u3009 and a function mapping each li to some aj in such a way that aj \u2208 G(li). Furthermore, since C is an \u03c8I -\u03c8G-cut, C contains at least one edge ux\u22121\nlx\u2212\u2192 ux from every such p. Therefore, we have that lx \u2208 CL and we also have some ay \u2208 G(lx) for some y \u2208 [n], which concludes the proof.\nTheorem 6 shows how to extract landmarks from a lifted justification graph, but it does not tell us how to sum them up admissibly. Note that getting an admissible estimate from a set of lifted landmarks is more involved than doing the same from a set of ground landmarks. The reason is that lifted landmarks can contain lifted actions so instead of looking for intersections between landmarks, we need to deal with intersections between groundings of landmarks. For example, let us assume we have two lifted landmarks L1 and L2 and we would like to extract a lower bound on the cost of optimal plans from it. When can we take the summina\u2208L1 c(a) +mina\u2208L2 c(a)? Clearly, just checking the intersection between L1 and L2 is not enough as the actions in L1 and L2 can be lifted. Instead, we need to check the intersection G(L1) \u2229 G(L2). If it is empty, we can use the aforementioned sum. If it is not empty, we need to apply some kind of cost partitioning.\nIt is easy to see that G(L1) \u2229 G(L2) = \u2205 holds if and only if there exist a \u2208 L1 and a\u2032 \u2208 L2 such that G(a) \u2229 G(a\u2032) = \u2205. In other words, we can apply cost partitioning over (lifted) actions by considering non-empty intersections G(a) \u2229 G(a\u2032). That is, we can construct the cost function c1 for L1 and c2 for L2 so that for every\na \u2208 L1 and a\u2032 \u2208 L2 such that G(a) \u2229 G(a\u2032) = \u2205 it holds that c1(a) + c2(a\n\u2032) \u2264 min{c(a), c(a\u2032)} (and ci(a) = c(a) for all other actions). Then the sum mina\u2208L1 c1(a) + mina\u2208L2 c2(a) is a lower bound on the cost of optimal plans.\nTo generalize this approach over larger sets of landmarks, we introduce the notion of an action-cost database. It is defined as a set of pairs relating an action to its cost in such a way that every ground action is covered by some entry, and for every pair \u3008a, ca\u3009 of the action a \u2208 A and its cost ca \u2208 R+0 in the database it holds that ca \u2264 c(a).\nDefinition 7. A set D \u2286 A\u00d7R+0 is called an action-cost database if, for every action a \u2208 A, there exists \u3008b, cb\u3009 \u2208 D such that G(a) \u2229 G(b) = \u2205 and cb \u2264 c(a).\nGiven an action-cost database D and an action a \u2208 A, we define D(a) = min{ca | \u3008a\u2032, ca\u3009 \u2208 D,G(a) \u2229 G(a\u2032) = \u2205}. Given an action-cost database D and a set of actions A \u2286 A, we define D(A) = mina\u2208A D(a).\nWe use action-cost databases instead of cost functions. Given an action-cost database D and an action a \u2208 A, we define D(a) as the minimum cost over all entries matching a. Such a definition allows us to update action-cost databases by simply adding more actioncost pairs. On one hand, this is guaranteed to only decrease D(a) values. On the other hand, if we update the database with the residual costs of (lifted) actions already encountered in previously considered landmarks, then the database will provide costs of actions that can be used for further landmarks admissibly.\nConsider the following example: Let L1 and L2 denote two lifted landmarks and let D1 denote an action-cost database. Furthermore, let us assume that there is exactly one a1 \u2208 L1 and exactly one a2 \u2208 L2 such that G(a1) \u2229 G(a2) = \u2205. Clearly, both D1(L1) and D1(L2) are (each individually) admissible estimates, but D1(L1) + D1(L2) is not guaranteed to be an admissible estimate. Nevertheless, we could use a\u2019s cost up to D1(L1) and leave the residual cost D1(a) \u2212 D1(L1) for a\u2032 in L2. In other words, we can construct another action-cost database D2 = D1 \u222a {\u3008a,D1(a)\u2212D1(L1)\u3009} and then the sumD1(L1)+D2(L2)must be an admissible estimate. This is because adding \u3008a,D1(a) \u2212 D1(L1)\u3009 to D2 makes sure that every action a\u2032 such that G(a) \u2229 G(a\u2032) = \u2205 gets the cost of at most D1(a) \u2212 D1(L1), which induces a cost partitioning over actions in L1 and L2 \u2013 it is the same as creating cost functions c1 and c2 such that ci(a) = min{Di(a),Di(Li)} for every a \u2208 Li, and therefore c2(a\n\u2032) \u2264 c1(a)\u2212mina\u2032\u2032\u2208L1 c1(a\u2032\u2032). In the following theorem, we prove this principle formally for any\nsequence of lifted disjunctive action landmarks as long as the first action-cost database in the sequence starts with the original costs of actions.\nTheorem 8. Let L1, . . . , Ln denote a sequence of disjunctive action landmarks, let D1, . . . ,Dn denote a sequence of action-cost databases such that D1 = {\u3008a, c(a)\u3009 | a \u2208 AS} and, for every i \u2208 {2, . . . , n}, Di = Di\u22121 \u222a {\u3008a,Di\u22121(a) \u2212 Di\u22121(Li\u22121)\u3009 | a \u2208 Li\u22121}, and let c denote the cost of an optimal plan. Then\u2211n\ni=1 Di(Li) \u2264 c .\nProof. Before we get to the main claim, we need to verify that, for every i \u2208 [n], Di is a well-defined action-cost database. For that, it is enough to show that for every i \u2208 [n], and every a \u2208 Li, it holds that 0 \u2264 Di(a) \u2212 Di(Li) \u2264 c(a). This trivially holds for i = 1 as D1(a) = c(a). For i \u2265 2, it easy to see that Di(a) \u2265 Di(Li) \u2265 0 by Definition 7, therefore Di(a)\u2212Di(Li) is non-negative, and also Di(a) \u2264 Dj(a) for any j \u2208 [i \u2212 1] because D1(a) = c(a) and any\nconsecutive Di(a) can only decrease, concluding the first part of the proof.\nLet Ki = G(Li) for every i \u2208 [n], and let AK = \u22c3\ni\u2208[n] Ki. Next, we prove that \u2211n i=1 Di(Ki) = \u2211n i=1 Di(Li). From Definition 7, it easily follows that D(a) = minag\u2208G(a) D(ag) for any action a \u2208 A and any action-cost database D. Therefore, for any action-cost database D and any set of actions L \u2286 A we have that D(L) = mina\u2208L D(a) = mina\u2208L minag\u2208G(a) D(ag) = mina\u2032g\u2208G(L) D(a \u2032 g) = D(G(L)). Therefore, we have that Di(Li) = Di(Ki) for every i \u2208 [n]. Finally, we prove that \u2211n i=1 Di(Ki) \u2264 c\n. Since every Li is a landmark, then also every Ki is a landmark (Definition 1). Therefore, it is enough to show that for every a \u2208 AK it holds that\u2211\ni\u2208[n],a\u2208Ki Di(Ki) \u2264 c(a). Keeping in mind that Di(a) \u2265 Di(Ki) for every Ki s.t. a \u2208 Ki, we prove an even stronger claim: For every a \u2208 AK and every i \u2208 [n] such that a \u2208 Ki it holds that\n\u2211 j\u2208[i\u22121],a\u2208Kj Dj(Kj) + Di(a) \u2264 c(a). Since c(a) =\nD1(a) \u2265 Dk(a) \u2265 Dl(a) for every 1 \u2264 k \u2264 l \u2264 n, it is easy to see that the claim holds for the smallest possible i. Now, we assume it holds for some i \u2208 [n], and we prove that it also holds for the smallest possible k \u2208 {i + 1, . . . , n}, i.e., we assume a \u2208 Ki for some i \u2208 [n] and it holds that \u2211 j\u2208[i\u22121],a\u2208Kj Dj(Kj)+ Di(a) \u2264 c(a), and we prove that \u2211\nj\u2208[k\u22121],a\u2208Kj Dj(Kj) + Dk(a) \u2264 c(a) for k = min{x \u2208 {i + 1, . . . , n} | a \u2208 Kx}. Since k > i and for every x \u2208 {i + 1, . . . , k \u2212 1} it holds that a \u2208 Kx, it follows that that Dk(a) \u2264 Di(a) \u2212 Di(Ki) holds by construction (as we already know that Di(Li) = Di(Ki)). Moreover, we have that \u2211 j\u2208[k\u22121],a\u2208Kj Dj(Kj) + Dk(a) = \u2211\nj\u2208[i\u22121],a\u2208Kj Dj(Kj) + Di(Ki) + Dk(a). So, everything put together, we have that\n\u2211 j\u2208[i\u22121],a\u2208Kj Dj(Kj)+Di(Ki)+\nDk(a) \u2264 \u2211\nj\u2208[i\u22121],a\u2208Kj Dj(Kj) +Di(Ki) +Di(a)\u2212Di(Ki) =\u2211 j\u2208[i\u22121],a\u2208Kj Dj(Kj)+Di(a) \u2264 c(a)which concludes the proof."
        },
        {
            "heading": "4 Computing Lifted Landmark-Cuts",
            "text": "Moving from theory to practice, here we introduce a novel algorithm utilizing the ideas from the previous section. We start with the definition of (most general) unifiers as substitutions under which sets of atoms or actions become singletons.\nDefinition 9. Given a set of atoms or actions X , a substitution \u03c3 is called unifier for X if |\u03c3X| = 1, and \u03c3v = v for every variable v \u2208 V[X].\nA unifier \u03c3 for X is called a most general unifier (MGU) for X if, for every unifier \u03c4 for X , there exists another unifier \u03c1 such that \u03c4 = \u03c1\u03c3.\nTo simplify the formalization, we tacitly assume than, unless explicitly specified otherwise, every unifier \u03c3 for X maps every variable v \u2208 V[X] either to itself or to a fresh variable not used anywhere else, i.e., it never \u201crecycles\u201d any variable already used in any atom or other substitution.\nIt is well-known, that if there exists a unifier, then there also exists a most general unifier and it is unique up to renaming of variables [4]. It is also easy to see that G(a) \u2229 G(a\u2032) = \u2205, for a pair of atoms or actions a and a\u2032, if and only if there exist an MGU for {a, a\u2032}. Moreover, note that we assume unifiers are the identity mapping outside the considered set of atoms or actions. For example, given an action a, its add effect p \u2208 add(a), some atom q, and a unifier \u03c3 for {p, q},\n\u03c3 can re-map only the variables appearing in p and q, i.e., applying \u03c3 on a preserves the variables V[a] \\ V[p].\nThe proposed algorithm, encapsulated in Algorithm 1, follows the schema laid out in Theorem 8 by looking for lifted landmarks one by one while maintaining the updated action-cost database. In each cycle, a lifted landmark with non-zero cost (according to the current action-cost database) is extracted as an \u03c8I -\u03c8G-cut of a lifted justification graph (Theorem 6). The algorithm terminates once it fails to find a non-zero lifted landmark which happens when there exists a zero-cost \u03c8I -\u03c8G-path.\nThe most noticeable difference to the theory is that we do not construct the full lifted justification graph. Instead, we iteratively build the smallest portion of the lifted justification graph connected to the goal vertex \u03c8G containing a single non-zero \u03c8I -\u03c8G-cut. More precisely, we start with \u03c8G and enumerate all possible actions having \u03c8G in their add effects. For every such action a we select one of its preconditions p \u2208 pre(a) (using some function SelectPre) and repeat this process for p as long as the explored actions have cost zero according to the current action-cost database (or \u03c8I is reached). The non-zero actions encountered during this process then form a (non-zero) lifted disjunctive action landmark because we enumerate all possible actions achieving each explored atom (cf. Achievers and (C3)) and therefore we obtain a cut separating \u03c8I and \u03c8G. Looking at Algorithm 1 in more detail, the algorithmmaintains the\nresulting heuristic value h initialized on line 1 to zero and increased with each non-zero landmark (line 6). It also maintains the actioncost database D initialized at line 2 and updated on line 7 in the way as described in Theorem 8. For completeness, we also include the function Cost(D,a) implementing D(a) as per Definition 7. The main part of the algorithm on lines 3 to 8 extracts landmarks using the function FindCut (line 3 and 8) one by one while updating the heuristic value h (line 5 and 6) and the action-cost databaseD (line 7) with the cost of the current landmark.\nThe function FindCut uses the function ExploreGoalZone, wich iteratively builds a portion of the lifted justification graph, extracts all atoms P0 from which the goal vertex \u03c8G is reachable with zero-cost paths, and a non-zero \u03c8I -\u03c8G-cut A+ which consists of all actions having their add effects in P0. Moreover, ExploreGoalZone returns empty sets (which eventually leads to the termination of the algorithm) whenever it connects \u03c8I and \u03c8G with a zero-cost path. Note that ExploreGoalZone can use an arbitrary function SelectPre for selecting one of the preconditions of the given action. It does not even have to be a function in a mathematical sense as it can have an internal memory and return a different precondition for the same action when called multiple times. Lastly, FindCut tries to reduce A+ by removing actions whose selected precondition lies in the P0 set. Since we are allowed to choose any precondition when constructing the lifted justification graph, we can reduce the cut A+ by removing (non-zero cost) actions connecting vertices within P0 because they are not necessary for separating \u03c8I from \u03c8G. Next, we sketch a proof showing that Algorithm 1 returns an admissible estimate for any function SelectPre.\nTheorem 10. Let c denote the cost of optimal plans. Then Algorithm 1 with any SelectPre function returns h \u2264 c .\nProof Sketch. Assuming FindCut eventually returns the empty set, the algorithm terminates. Assuming FindCut returns either the empty set or a valid \u03c8I -\u03c8G-cut, it follows from Theorem 8 that the main procedure on lines 1 to 8 results in an admissible estimate h. Furthermore, assuming ExploreGoalZone returns either empty sets or a \u03c8I -\u03c8G-cut A+ and a set of all vertices P0 from which \u03c8G\nAlgorithm 1: Lifted Landmark-Cut Heuristic Input: Set of action schemasAS , initial-state atom \u03c8I , goal atom\n\u03c8G Output: Heuristic value h\n1 h\u2190 0; 2 D \u2190 {\u3008a, c(a)\u3009 | a \u2208 AS}; 3 C \u2190 FindCut(D); 4 while |C| > 0 do 5 k \u2190 mina\u2208C Cost(D,a); 6 h\u2190 h+ k; 7 D \u2190 D \u222a {\u3008a,Cost(D,a)\u2212 k\u3009 | a \u2208 C}; 8 C \u2190 FindCut(D); 9 function FindCut(D) 10 A+, P0 \u2190 ExploreGoalZone (D); 11 C \u2190 \u2205; 12 foreach a \u2208 A+ do 13 q \u2190 SelectPre(a); 14 if q is not unifiable with any p \u2208 P0 then 15 C \u2190 C \u222a {a}; 16 return C 17 function ExploreGoalZone(D) 18 Q\u2190 {\u03c8G}; 19 P0 \u2190 {\u03c8G}; 20 A+ \u2190 {}; 21 while |Q| \u2265 0 do 22 p\u2190 Pop(Q); 23 foreach a \u2208 Achievers(AS , p) do 24 if Cost(D,a) = 0 then 25 q \u2190 SelectPre(a); 26 if there exists an MGU for {q, \u03c8I} then 27 return \u2205, \u2205; 28 Q\u2190 Q \u222a {q}; 29 P0 \u2190 P0 \u222a {q}; 30 else 31 A+ \u2190 A+ \u222a {a};\n32 return A+, P0; 33 function Achievers(AS , p) 34 A\u2190 \u2205; 35 foreach a \u2208 AS do 36 foreach q \u2208 add(a) do 37 \u03c3 \u2190 Find MGU for {p, q}; 38 if \u03c3 exists then 39 A\u2190 A \u222a {\u03c3a};"
        },
        {
            "heading": "40 return A;",
            "text": "41 function Cost(D, a) 42 k \u2190 c(a); 43 foreach \u3008b, cb\u3009 \u2208 D do 44 if cb < k and there exists an MGU for {b, a} then 45 k \u2190 cb;"
        },
        {
            "heading": "46 return k;",
            "text": "is reachable with a zero-cost path, the procedure on lines 11 to 16 clearly disregards only the actions fromA+ that are not necessary for separating \u03c8I and \u03c8G, therefore FindCut returns either the empty set or an \u03c8I -\u03c8G-cut.\nTherefore, we need to prove that (1) ExploreGoalZone eventually returns empty sets, and (2) if A+ and P0 returned by ExploreGoalZone are non-empty, then (2a) A+ is a \u03c8I -\u03c8G-cut and (2b) P0 contains all vertices from the lifted justification graph from which the vertex \u03c8G is reachable with zero-cost paths.\nThe main observations here are that ExploreGoalZone builds the portion of the lifted justfication graph starting from the \u03c8G vertex and backchaining via actions add effects to their precondition which means that conditions (C1) and (C2) from Definition 3 hold for the explored portion of the graph. Anothoer crucial observa-\ntion is that the function Achievers always enumerates all possible actions having the given atom p in their add effects. Therefore, ExploreGoalZone either reaches \u03c8I with a zero-cost path, or the condition (C3) holds for all vertices (atoms) in P0. Therefore, it immediatelly follows that (2b) holds, and (2a) holds because it also means that all non-zero actions having atoms from P0 in their add effects are added to A+. As for (1), it is easy to see that since we are iterativelly reducing costs of actions in the action-cost database and since we are not skipping any action during the building of the justification graph, it must eventually happen that we connect \u03c8I with \u03c8G by a zero-cost path.\nAs given before, SelectPre can be any function selecting a precondition of an action. Here, we evaluate the following functions:\n\u2022 LMC-random selects a precondition randomly, i.e., it can select a different precondition every time it is called on the same action. \u2022 LMC-most-gr selects the precondition having least variables, ties are broken arbitrarily. Fully lifted atoms are more likely unifiable with \u03c8I , so avoiding those leads to a larger graph and potentially more cuts. \u2022 LMC-least selects the precondition whose predicate was picked as a supporter least often so far, ties are broken arbitrarily. Picking predicates we have not seen in the graph so far is more likely to lead to new action schemas in the graph. \u2022 LMC-hLmax selects the precondition with the highest hmax value breaking ties arbitrarily. This is the variant closest to the original LM-cut heuristic. For this purpose, we adapted the already existing hLmax heuristic [6] computing hmax values using a Datalog program on the lifted level."
        },
        {
            "heading": "5 Experimental Evaluation",
            "text": "We implemented1 our approach on top of the Powerlifted (PWL) system [6]. We evaluate four configurations LMC-random, LMC-mostgr, LMC-least, and LMC-hLmax, described in the previous section. We compare our system against several systems from the literature. We use two grounded configurations of Fast Downward [9]:\n\u2022 hmax: ground A\u2217 search combined with the hmax heuristic [2]. \u2022 hlmc: ground A\u2217 search combined with the LM-cut heuristic [10].\nThen we compare against several lifted systems:\n\u2022 hLmax: lifted PWL A\u2217 search with the hmax heuristic [6]. \u2022 hlmchom: lifted A\u2217 with LM-cut computed on the task reduced with\nPDDL homomorphisms that was subsequently grounded [14], we use the best performing variant, as reported in [14], that preserves goal objects and reduces the planning task by 95% of objects. \u2022 LiSAT: translation of the lifted problem into a propositional SAT problem [13]. We use the non-incremental, length-optimal configuration with the Kissat [1] solver.\nBe aware that neither hlmchom nor LiSAT uses a heuristic computed on the lifted model, making hLmax the system closest to ours.\nWe evaluate our system on a benchmark set that has been introduced specifically for lifted planning [6, 18] and has been used in recent papers (see also [6, 18, 13, 26]).\nHowever, the benchmarks have been introduced for satisficing planning and therefore most domains come with unit costs. So to make the cost-optimal planning evaluation more meaningful, we adapted the domains by adding cost values1 in the following way:\n1 The code can be found at: https://github.com/minecraft-saar/powerlifted\n\u2022 GED \u2013 already came with action costs. \u2022 Organic Synthesis \u2013 since the costs represent the \u201ceffort\u201d of a\nreaction, we assigned an action its number of effects as cost value. \u2022 Pipesworld \u2013 here we distinguish unary/non-unary pipes; opera-\ntions on unary pipes come with cost 1, those on non-unary cost 3. \u2022 VisitAll \u2013 the version of visitAll that we build on comes with more\nthan two dimensions; inspired by some kind of high bay warehouse, we gave moving on the first two dimensions cost 1, the third dimension cost 5 (since some kind of lift needs to be used), and further increased costs the higher the dimensions get. \u2022 Childsnack \u2013 here we tried to reflect the temporal effort of the different actions in their costs and assigned costs 5 to making the sandwich, 1 to putting it on the tray, and 3 to serving it. \u2022 BlocksWorld \u2013 here we tried to reflect the control effort (putting a block on some other block being more difficult than putting it on the table) and energy consumption (putting a block down being less effort than lifting it) in the costs and assigned 5, 3, 5 and 10 to pickup, putdown, stack and unstack, respectively. \u2022 Logistics \u2013 operations of planes cost more than those of trucks, moving costs more than loading and unloading. \u2022 Rovers \u2013 here we assigned costs based on the temporal effort and energy consumption of the actions (e.g., taking an image costing less than taking a rock sample).\nWe conduct two separate evaluations, one for the length-optimal and one for the cost-optimal setting. Since the SAT-based solver can only generate length-optimal solutions, we only use it in this setting. The other systems can plan both length- and cost-optimal.\nFigure 1 shows our coverage results for the unit-cost setting. It can be seen that in this setting, no search-based approach reaches the performance of the SAT-based approach on the given benchmark set. From the search-based systems, hlmchom has the hightest coverage, followed by hLmax and our configurations. As we expected LMC-hLmax falls behind on overall coverage. The overall coverage of LMC-random, LMC-most-gr, and LMC-least are close, but they perform very different across the domain set. The greatest difference is in the Blocks World domain, where the best of our configurations (LMC-most-gr) solves 37 out of 40 instances, while LMCleast solves only a single instance. Notably, this is the one of two domains where a search-based configuration reaches a performance close to the SAT-based system. The other is Organic Synthesis (\u201calk\u201d and \u201cmit\u201d), but here several search-based systems are close together.\nAnother domain with large differences between our configurations is Organic Synthesis (alk), where LMC-least and LMC-hLmax perform better then the others. In GED, LMC-most-gr does not perform well.\nCompared to the other search-based systems, our configurations perform worse mainly in two domains: VisitAll and Logistics. However, the latter seems to be difficult for all PWL-based configurations, the only search-based system performing well is hlmchom. Let us next have a look at the cost-optimal setting (Table 2). When\nwe first compare our configurations, we see that there are \u2013 again \u2013 differences in the performance among the domains: LMC-least performs well in GED and Organic Synthesis, LMC-random in VisitAll and both LMC-random and LMC-most-gr in Blocks World. We also see the expected drop in overall coverage by LMC-hLmax.\nComparing all systems, hlmchom performs best. Using ground heuristics on the transformed model seems to work well on the given benchmark set. Compared to the other lifted heuristic (LMC-hLmax), our configurations perform worse especially in visitAll and Logistics. We will discuss the latter domain in more detail in the next section. Our system shows especially good results in the Blocks World. Here it even beats hlmchom."
        },
        {
            "heading": "6 Discussion and Conclusion",
            "text": "In this paper, we presented a lifted version of the admissible LM-cut heuristic. We also showed that the justification graph used in LM-cut for the extraction of landmarks can be built much more freely than previously used. Moreover, we introduced an algorithm that does not need to construct the whole justification graph to infer a landmark, but it constructs just the minimal part of the graph connecting a nonzero cost landmark to the goal.\nA main question is how to come up with an informative pcf that can be computed on the lifted model. As we expected, using LMChLmax seems to be too costly and resulted in the worst overall coverage of our pcfs. Further, there is also not a single domain where it outperformed the other pcfs. The other pcfs perform similar when looking at overall coverage, but there are large differences between the domains. While this is not good for the comparison with other systems as done in the evaluation, it opens several directions for future work. The most elegant solution would be to find a different pcf combining the advantages of the ones presented here. But from a practical perspective, there are also other ways to combine the advantages. One would be to compute several landmark sets and do a\ncost partitioning or hitting set approach based on them. Computationally, this might be no problem, since the different steps like successor generation or heuristic computation are more costly in lifted planning than in the grounded setting. If it is too costly, it might be an option to select the best pcf for a given planning instance based on the initial heuristic value. Since the heuristics are admissible, a simple criterion might be to pick the one with highest value on the initial node.\nOne detail in the evaluation made us especially interested: we did not expect the poor result in the Logistics domain, both in terms of absolute performance (coverage of 0 across all pcfs), nor in comparison to hLmax (the latter is different e.g. in Childsnack). A look in the data revealed that all 6 instances solved by hLmax in the cost-optimal setting have a single goal, resulting in very informed hLmax values. While this is an extreme example, it seems that the benchmark set\nhas been constructed in a way to get large, but simple problems, resulting in problems with very few goals. Another example is VisitAll, which comes with 1 to 3 goals.\nBased on this insight, we want to get an impression about scaling behavior of the heuristics across goals and are especially interested in the comparison to hLmax, since these are the only lifted heuristics in the evaluation (hlmchom uses grounded heuristics on a reduced model).\nWe created a small Logistics problem with a single city, a single truck, and an increasing number of packages, all of which are placed at a single position and need to be brought to the same goal position. Since hLmax and our configurations are admissible, we can meaningfully compare the initial heuristic values and we know that a larger value is always better. Figure 1 shows the number of packages on the x axis and the initial heuristic value on the y axis. In this example, we observe the behavior that we expected when comparing hLmax with other heuristics: while hLmax cannot incorporate costs of more than one sub-goal (resulting in a constant heuristic value shown at the bottom), our heuristics accumulate costs over all sub-goals, resulting in a heuristic value scaling with the number of goals. Be further aware that not only one, but all our different pcf functions scale reasonably well with the packages. In this example, LMC-most-gr returns the best heuristic values.\nWhile this discussion points towards a problem that might be present in the benchmark set, we want to underline that we do not have a good solution for it: the lifted systems are \u2013 yet \u2013 not as powerful as the grounded ones. So instances in the benchmark set need to be relatively simple to solve. At the same time, they shall be large enough to break the systems needing a grounded model. This results in a set like the one used in recent work (and here)."
        },
        {
            "heading": "Acknowledgments",
            "text": "\u201eGef\u00f6rdert durch die Deutsche Forschungsgemeinschaft (DFG) \u2013 Projektnummer 232722074 \u2013 SFB 1102 / Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) \u2013 Project-ID 232722074 \u2013 SFB 1102\u201c"
        }
    ],
    "title": "A Landmark-Cut Heuristic for Lifted Optimal Planning",
    "year": 2023
}