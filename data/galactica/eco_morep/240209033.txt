Platform businesses operate on a digital core and their decision making requires high-dimensional accurate forecast streams at different levels of cross-sectional (e.g., geographical regions) and temporal aggregation (e.g., minutes to days). It also necessitates coherent forecasts across all levels of the hierarchy to ensure aligned decision making across different planning units such as pricing, product, controlling and strategy. Given that platform data streams feature complex characteristics and interdependencies, we introduce a non-linear hierarchical forecast reconciliation method that produces cross-temporal reconciled forecasts in a direct and automated way through the use of popular machine learning methods. The method is sufficiently fast to allow forecast-based high-frequency decision making that platforms require. We empirically test our framework on a unique, large-scale streaming dataset from a leading on-demand delivery platform in Europe. 1 conclusion Forecast reconciliation based on linear methods has been shown to be very useful and successful in a wide variety of applications. Recently, ML-based forecast reconciliation methods are proposed for cross-sectional time series hierarchies. We extend the latter approach to cross-temporal hierarchies. We provide a general description of the methodology and an application to a unique platform dataset from an on-demand logistics company. In particular, the data consists of demand streams that constitute a rich hierarchy in spatial and time dimensions, with bottom level time series defined as delivery areas at 30-minute frequency. Our key empirical finding is that ML-based forecast reconciliation for our platform data can result in substantial forecast accuracy improvements compared to existing linear recon-
ciliation methods. However, unless one can face the huge computational cost of hyperparameter tuning, ML-based reconciliation is not uniformly superior to linear methods. Another key finding is that, as platform data streams are potentially impacted by data shifts, our approach is able to react swiftly to such instability when compared with linear approaches. Several extensions should be considered. First, applications to other datasets consisting of different cross-temporal hierarchies. Second, our ML algorithms in the platform application consist of tree-based methods only, though our approach can be used with any ML algorithm. Taking into account computing time, it would be interesting to test alternative neural network based methods using our approach. Third, we currently retrain the ML algorithms at every iteration of the rolling window, it would be interesting to investigate if online ML methods that incrementally update the forecast function as new data becomes available can lead to further computational efficiencies. appendix b design of the forecast study B.1 Rolling-Window Set-Up
iteration r
B.2 Base Forecasts
We consider four base forecast models: (i) Naive, (ii) SARIMA, (iii) ETS and a (iv)
forecast combination of the former three. Naive. The first base forecast model for temporal aggregation level k of a specific crosssectional time series is simply x [k] j = x [k] j−7m/k + ε [k] j , which we call “Naive” since it simply implies that the forecast of a specific time slot (30-min, hourly or daily) is the value observed in the same time slot and day of the previous week. This way of forecasting is popular in the industry since it is ultra fast, i.e. it does not require parameter estimation, and it works well in the case of strong seasonality patterns as observed in platform data. SARIMA. Secondly, we consider ARIMA models, as implemented in the forecast package (Hyndman et al., 2023; Hyndman and Khandakar, 2008) in R. For the daily time series, we search for each series the optimal model in the space of seasonal ARIMA models, thereby allowing for weekly seasonality (seasonal period equal to 7 for daily data) and a maximal MA order q = 3, and maximal AR order of p = 3. For the seasonal components we set the maximal MA order to Q = 1 and maximal AR order to P = 1. We restrict the maximum number of non-seasonal differences to d = 1. All other arguments are kept at their default values. For the hourly and 30-min time series, we need to additionally account for the strong intra-day seasonal patterns in the platform data. Since the seasonal period is long in both cases (m1 = 34 for 30-min data and m2 = 17 for hourly data), we follow the common practice based on Fourier series to capture the seasonality. Specifically, for the 30-min time series yt, we consider the regression model
yt = µ+ S∑
s=1
[αssin(2πst/m1) + βscos(2πst/m1)] + εt, (B.1)
where εt is subsequently modeled as an ARIMA process. Analogously for the hourly data thereby taking the seasonal period m2 = 17. We select the optimal value of S via the Bayesian Information Criterion. ETS. Thirdly, we consider exponential smoothing (ETS; Hyndman et al., 2002) as another popular model to produce the base forecasts. To this end, we use the ets function (with default arguments) as implemented in the forecast package. As above, for the 30-min and hourly series we first estimate the intra-day seasonality through the Fourier series approach and subsequently model the error term in equation (B.1) using ETS. Forecast Combination. Our final base forecast model consists of a simple forecast combination of the previous three base forecast models. Forecast combination approaches have shown to perform well as base forecast methods in the hierarchical forecasting literature, thereby oftentimes providing an effective practice for improving forecast accuracy; see for instance Rostami-Tabar and Hyndman (2024) for an application on emergency medical services data. We opt for equal weights in the forecast combination, mainly because of its simplicity, ease in implementation and its established track-record of good performance in the forecast combination literature (e.g., Elliott and Timmermann, 2016, Chapter 14). B.3 Machine Learning Methods
We consider three machine learning methods: (i) random forest, (ii) XGBoost and (iii)
LightGBM. Random Forest. Random forests, proposed by Breiman (2001), produce forecasts by combining regression trees. A regression tree is a nonparametric method that partitions the feature space to compute local averages as forecasts, see Efron and Hastie (2016) for a textbook treatment. The tuning parameters are the number of trees that are used in the forecast combination, the number of features to randomly select when constructing each regression tree split, and the minimum number of observations in each terminal node to compute the local forecasts. We use the standard implementation of the randomForest package (Liaw and Wiener, 2002) in R with default settings for the hyperparamters (i.e. number of trees: ntree = 500, number of variables sampled at each split: mtry = # of features/3, minimum size of terminal nodes: nodesize = 5) when reporting our main results. In Section 5.3, we also investigate the performance of the random forest based forecast reconciliation method when the hyperparameters are tuned. To this end, we follow Spiliotis
et al. (2021) and use the package mlr in R (Bischl et al., 2016) which implements a random grid search with cross-validation to find the optimal hyperparameters. In the cross-validation procedure, we leave each of the four subsequent weeks in the validation set once out as test sample and use the root mean squared error as cross-validation score to compute the optimal hyperparameters. Note that we tune the hyperparameters only once every four iterations (i.e. once every month) in the outer rolling window (so in 8 out of the 31 outer rolling windows) to keep the computational burden low; in between we use the optimal hyperparameters from the previous tuning round as fixed values. The lower and upper bounds for the hyperparameters are set to (2, 50) for mtry and (5, 50) for nodesize. We set the bounds for ntree between 50 and 500 on interval steps of 10. XGBoost. Gradient boosting, proposed by Friedman (2001), constructs forecasts by sequentially fitting small regression trees, i.e. weak learners, to the residuals by the ensemble of the previous trees. This procedure results in a one final tree, constructed as a sum of trees, used for forecasting. Extreme gradient boosting (XGBoost), introduced by Chen and Guestrin (2016), optimizes the implementation of the gradient boosting framework in terms of speed and flexibility. We use the xgboost package (Chen et al., 2023) in R with fixed choices of the tuning parameters when reporting our main results. We fix the hyperparameters to the default values as follows: 100 boosting iterations (nrounds), 6 as max tree depth (max depth), 0.3 as learning rate (eta), 1 as subsample ratio (subsample), 1 as subsample ratio of columns (colsample bytree), 1 as minimum sum of instance weight (hessian) (min child weight) and 0 as minimum loss reduction (gamma). Subsequently, to tune the hyperparameters, we use the same procedure as discussed for random forest but this time use Bayesian optimization to tune the hyperparameters since grid search is computationally very expensive in this case. To this end, we use the
rBayesianOptimization (Yan, 2021) in R and consider the following intervals with lower and upperbounds for each hyperparameter, in line with Spiliotis et al. (2021): we set the values of max depth between (2, 10), the learning rate (eta) between (0.01, 0.05), subsample values between (0.3, 1), colsample bytree values between (0.3, 1), min child weight between (0, 10) and gamma between (0, 5). The values for the maximum number of boosting iterations (nrounds) are over the range of 50 and 200. LightGBM. LightGBM, put forward by Microsoft in 2016, is a gradient boosting framework that uses tree-based learning algorithms like XGBoost but as the name suggests has computational advantages with respect to training speed, memory usage and parallelization. The implementation of gradient-based one-side sampling and exclusive feature bundling techniques allows handling large training datasets. We use the lightgbm package (Shi et al., 2023) in R with fixed, default hyperparameters when reporting our main results: 100 boosting iterations (nrounds), 31 as maximum number of leaves (num leaves), 0.1 as learning rate (eta), 1 as subsample ratio (subsample), 1 as subsample ratio of columns (colsample bytree), 0.001 as minimum sum of instance weight (hessian) (min child weight) and 0 as ℓ1-regularization (lambda l1) and no limit to the max depth (max depth) for the tree model. Finally, to tune the hyperparameters, we also use Bayesian optimization with the following similar prior values for the hyperparameters as with XGBoost. The maximum number of leaves (num leaves) fixed to the range of 5 and 31. The learning rate (eta) is set between (0.01, 0.05), subsample values between (0.3, 1), colsample bytree values are set between (0.3, 1), min child weight between (0, 10), max depth between (2, 10) and lambda l1 between (0, 5). The values for the maximum number of boosting iterations (nrounds) are over the range of 50 and 200. appendix c platform application: additional results This Appendix contains the forecast accuracy results on the London data for two additional forecast error metrics, namely the symmetric mean absolute percentage error (SMAPE) and the root mean squared scaled error (RMSSE), see Hyndman and Koehler (2006) for an overview. The two forecast error metrics, for temporal factor k and cross-sectional time series
i = 1, . . . , n, are defined as
SMAPE [k] i =
1
Ttest/k Ttest/k∑ j=1 |A[k]i,j − F [k] i,j | |A[k]i,j |+ |F [k] i,j | ,
and
RMSSE [k] i,r = √√√√√  1 mkH mk(N+H)∑ j=mkN+1 (A [k] i,j − F [k] i,j ) 2  /[ 1 mk(N − 7) mkN∑ j=7mk+1 (A [k] i,j − A [k] i,j−7mk) 2 ] ,
for outer rolling window r = 1, . . . , 31, and RMSSE [k] i = 1 31 ∑31 r=1RMSSE [k] i,r given the 31 outer rolling windows in our forecast set-up. Table C.1 presents the results for the SMAPE, Table C.2 for the RMSSE.