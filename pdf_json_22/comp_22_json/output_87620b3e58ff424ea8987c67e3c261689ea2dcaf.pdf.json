{
    "abstractText": "This paper considers optimal design problems for the Weibull distribution, which can be used to model symmetrical or asymmetrical data, in the presence of progressive interval censoring in life-testing experiments. Two robust approaches, Bayesian and minimax, are proposed to deal with the dependence of the D-optimality and c-optimality on the unknown model parameters. Meanwhile, the compound design method is applied to ensure a compromise between the precision of estimation of the model parameters and the precision of estimation of the quantiles. Furthermore, to make the design become more practical, the cost constraints are taken into account in constructing the optimal designs. Two algorithms are provided for finding the robust optimal solutions. A simulated example and a real life example are given to illustrate the proposed methods. The sensitivity analysis is also studied. These new design methods can help the engineers to obtain robust optimal designs for the censored life-testing experiments.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xiaodong Zhou"
        },
        {
            "affiliations": [],
            "name": "Yunjuan Wang"
        },
        {
            "affiliations": [],
            "name": "Rongxian Yue"
        }
    ],
    "id": "SP:366936608a8c2b71120b08e57bc4c58226646128",
    "references": [
        {
            "authors": [
                "N. Balakrishnan",
                "R. Aggarwala"
            ],
            "title": "Progressive Censoring: Theory, Methods, and Applications",
            "venue": "Birkhauser: Basel, Switzerland,",
            "year": 2000
        },
        {
            "authors": [
                "N. Balakrishnan",
                "E. Cramer"
            ],
            "title": "The Art of Progressive Censoring; Birkhauser",
            "year": 2014
        },
        {
            "authors": [
                "N. Balakrishnan"
            ],
            "title": "Progressive censoring methodology: An appraisal",
            "venue": "Test 2007,",
            "year": 2007
        },
        {
            "authors": [
                "R. Aggarwala"
            ],
            "title": "Progressive interval censoring: Some mathematical results with applications to inference",
            "venue": "Commun. Stat. Theory Methods",
            "year": 2001
        },
        {
            "authors": [
                "L. Xiang",
                "S.K. Tse"
            ],
            "title": "Maximum likelihood estimation in survival studies under progressive interval censoring with random removals",
            "venue": "Biopharm. Stat",
            "year": 2005
        },
        {
            "authors": [
                "H.K.T. Ng",
                "Z. Wang"
            ],
            "title": "Statistical estimation for the parameters of Weibull distribution based on progressively type I interval censored sample",
            "venue": "J. Stat. Comput. Simul",
            "year": 2009
        },
        {
            "authors": [
                "D.G. Chen",
                "Y.L. Lio"
            ],
            "title": "Parameter estimations for generalized exponential distribution under progressive type I interval censoring",
            "venue": "Comput. Stat. Data. Anal",
            "year": 2010
        },
        {
            "authors": [
                "Y.J. Lin",
                "Y.L. Lio"
            ],
            "title": "Bayesian inference under progressive type I interval censoring",
            "venue": "J. Appl. Stat",
            "year": 2012
        },
        {
            "authors": [
                "C. Lodhi",
                "Y.M. Tripathi"
            ],
            "title": "Inference on a progressive type I interval-censored truncated normal distribution",
            "venue": "J. Appl. Stat",
            "year": 2020
        },
        {
            "authors": [
                "S. Budhiraja",
                "B. Pradhan"
            ],
            "title": "Point and interval estimation under progressive type-I interval censoring with random removal",
            "year": 2020
        },
        {
            "authors": [
                "S.F. Wu",
                "W.T. Chang"
            ],
            "title": "The evaluation on the process capability index CL for exponentiated Frech\u2014Et lifetime product under progressive type I interval censoring",
            "venue": "Symmetry",
            "year": 2021
        },
        {
            "authors": [
                "R. Alotaibi",
                "H. Rezk",
                "S. Dey",
                "H. Okasha"
            ],
            "title": "Bayesian estimation for Dagum distribution based on progressive type I interval censoring",
            "venue": "PLoS ONE 2021,",
            "year": 2021
        },
        {
            "authors": [
                "S.J. Wu",
                "C.T. Chang",
                "K.J. Liao",
                "S.R. Huang"
            ],
            "title": "Planning of progressive group-censoring life tests with cost considerations",
            "venue": "J. Appl. Stat",
            "year": 2008
        },
        {
            "authors": [
                "C.T. Lin",
                "S.J. Wu",
                "N. Balakrishnan"
            ],
            "title": "Planning life tests with progressively type-I interval censored data from the lognormal distribution",
            "venue": "J. Stat. Plan. Infer",
            "year": 2009
        },
        {
            "authors": [
                "C.T. Lin",
                "N. Balakrishnan",
                "S.J. Wu"
            ],
            "title": "Planning life tests based on progressively type-I grouped censored data from the Weibull distribution",
            "venue": "Comm. Statist. Simul. Comput",
            "year": 2011
        },
        {
            "authors": [
                "S. Roy",
                "B. Pradhan"
            ],
            "title": "Bayesian optimum life testing plans under progressive type I interval censoring scheme",
            "venue": "Quality Reliab. Eng. Int",
            "year": 2017
        },
        {
            "authors": [
                "S. Budhiraja",
                "B. Pradhan"
            ],
            "title": "Optimum reliability acceptance sampling plans under progressive type-I interval censoring with random removal using a cost model",
            "venue": "J. Appl. Stat",
            "year": 2019
        },
        {
            "authors": [
                "S. Roy",
                "B. Pradhan"
            ],
            "title": "Bayesian C-optimal life testing plans under progressive type-I interval censoring",
            "venue": "scheme. Appl. Math. Model",
            "year": 2019
        },
        {
            "authors": [
                "S.F. Wu",
                "T.H. Liu",
                "Y.H. Lai",
                "W.T. Chang"
            ],
            "title": "A study on the experimental design for the lifetime performance index of rayleigh lifetime distribution under progressive type I interval censoring",
            "year": 2022
        },
        {
            "authors": [
                "K. Chaloner",
                "I. Verdinelli"
            ],
            "title": "Bayesian experimental design: A review",
            "venue": "Statist. Sci",
            "year": 1995
        },
        {
            "authors": [
                "A.C. Atkinson",
                "A.N. Donev",
                "R.D. Tobias"
            ],
            "title": "Optimum Experimental Designs with SAS",
            "year": 2007
        },
        {
            "authors": [
                "R.X. Yue",
                "X.D. Zhou"
            ],
            "title": "Robust integer-valued designs for linear random intercept models",
            "venue": "Commun. Stat. Theory Methods",
            "year": 2018
        },
        {
            "authors": [
                "R. Pan",
                "T. Yang"
            ],
            "title": "Design and evaluation of accelerated life testing plans with dual objectives",
            "venue": "J. Stat. Comput. Simul",
            "year": 2014
        },
        {
            "authors": [
                "R. Bhattacharya",
                "B.N. Saha",
                "G.G. Far\u00edas",
                "N. Balakrishnan"
            ],
            "title": "Multi-criteria-based optimal life-testing plans under hybrid censoring",
            "year": 2020
        },
        {
            "authors": [
                "D. Kundu"
            ],
            "title": "Bayesian inference and life testing plan for the Weibull distribution in presence of progressive censoring",
            "year": 2008
        },
        {
            "authors": [
                "H. Chernoff"
            ],
            "title": "Locally optimum designs for estimating parameters",
            "venue": "Ann. Math. Statist",
            "year": 1953
        },
        {
            "authors": [
                "R.D. Cook",
                "W.K. Wong"
            ],
            "title": "On the equivalence of constrained and compound designs",
            "venue": "J. Am. Statist. Assoc",
            "year": 1994
        },
        {
            "authors": [
                "L.K. Foo",
                "S. Duffull"
            ],
            "title": "Methods of robust design of nonlinear models with an application to pharmacokinetics",
            "venue": "J. Biopharm. Stat",
            "year": 2010
        },
        {
            "authors": [
                "R. Eberhart",
                "J. Kennedy"
            ],
            "title": "New optimizer using particle swarm theory",
            "venue": "In Proceedings of the Sixth International Symposium on Micro Machine and Human Science, Nagoya, Japan,",
            "year": 1995
        },
        {
            "authors": [
                "R. Poli",
                "J. Kennedy",
                "T. Blackwell"
            ],
            "title": "Particle swarm optimization an overview",
            "venue": "Swarm. Intell. 2007,",
            "year": 2007
        },
        {
            "authors": [
                "S. Ruidas",
                "M.R. Seikh",
                "P.K. Nayak"
            ],
            "title": "A production inventory model with interval-valued carbon emission parameters under price-sensitive demand",
            "venue": "Comput. Ind. Eng",
            "year": 2021
        },
        {
            "authors": [
                "S. Ruidas",
                "M.R. Seikh",
                "P.K. Nayak"
            ],
            "title": "Application of particle swarm optimization technique in an interval-valued EPQ model. In Meta-Heuristic Optimization Techniques: Applications",
            "venue": "Eds.; De Gruyter: Berlin,",
            "year": 2022
        },
        {
            "authors": [
                "R.B. Chen",
                "P.Y. Chen",
                "W.K. Wong"
            ],
            "title": "Standardized maximin D optimal designs for pharmacological models via particle swarm optimization techniques",
            "venue": "Chemom. Intell. Lab. Syst",
            "year": 2018
        },
        {
            "authors": [
                "X.D. Zhou",
                "Y.J. Wang",
                "R.X. Yue"
            ],
            "title": "Robust population designs for longitudinal linear regression model with a random intercept",
            "year": 2018
        },
        {
            "authors": [
                "X. Liu",
                "R.X. Yue",
                "Z.Z. Zhang",
                "K.W. Wong"
            ],
            "title": "G-optimal designs for hierarchical linear models: An equivalence theorem and a nature-inspired meta-heuristic algorithm",
            "venue": "Soft Comput",
            "year": 2021
        },
        {
            "authors": [
                "P.P. Carbone",
                "L.E. Kellerhouse",
                "E.A. Gehan"
            ],
            "title": "Plasmacytic myeloma: A study of the relationship of survival to various clinical manifestations and anomalous protein type in 112 patients",
            "venue": "Am. J. Med",
            "year": 1967
        },
        {
            "authors": [
                "P. Chen",
                "Z.S. Ye"
            ],
            "title": "Approximate Statistical Limits for a Gamma Distribution",
            "venue": "J. Qual. Technol",
            "year": 2017
        },
        {
            "authors": [
                "P. Chen",
                "Z.S. Ye"
            ],
            "title": "Estimation of Field Reliability Based on Aggregate Lifetime Data",
            "venue": "Technometrics",
            "year": 2017
        },
        {
            "authors": [
                "A. Xu",
                "S. Zhou",
                "Y. Tang"
            ],
            "title": "A unified model for system reliability evaluation under dynamic operating conditions",
            "venue": "IEEE Trans. Reliab",
            "year": 2020
        },
        {
            "authors": [
                "L. J\u00e4ntschi"
            ],
            "title": "A test detecting the outliers for continuous distributions based on the cumulative distribution function of the data being tested",
            "venue": "Symmetry 2019,",
            "year": 2019
        },
        {
            "authors": [
                "X.J. Zhao",
                "R. Pan",
                "E. del Castillo",
                "M. Xie"
            ],
            "title": "An adaptive two-stage Bayesian model averaging approach to planning and analyzing accelerated life tests under model uncertainty",
            "venue": "J. Qual. Technol",
            "year": 2019
        },
        {
            "authors": [
                "S.J. Wu",
                "S.R. Huang"
            ],
            "title": "Optimal progressive interval censoring plan under accelerated life test with limited budget",
            "venue": "J. Stat. Comput. Simul",
            "year": 2019
        },
        {
            "authors": [
                "J. Hu",
                "P. Chen"
            ],
            "title": "Predictive maintenance of systems subject to hard failure based on proportional hazards model",
            "venue": "Reliab. Eng. Syst. Saf",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Citation: Zhou, X.; Wang, Y.; Yue, R.\nRobust Optimum Life-Testing Plans\nunder Progressive Type-I Interval\nCensoring Schemes with Cost\nConstraint. Symmetry 2022, 14, 1047.\nhttps://doi.org/10.3390/\nsym14051047\nAcademic Editor: Piao Chen\nReceived: 12 April 2022\nAccepted: 17 May 2022\nPublished: 19 May 2022\nPublisher\u2019s Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished maps and institutional affil-\niations.\nCopyright: \u00a9 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: Weibull distribution; progressive interval censoring; Bayesian design; minimax design; particle swarm optimization"
        },
        {
            "heading": "1. Introduction",
            "text": "Progressive censoring is frequently employed in life-testing experiments because it permits removing the test units at the points other than the final termination point, which can save experiment time and/or cost. Recently, the research on progressive censoring has grown very fast. For the relevant research progress one may refer to two important monographs (Balakrishnan et al. [1]; Balakrishnan and Cramer [2]) and the review article (Balakrishnan [3]). In applications, progressive type-I and type-II censoring are two important types of progressive censoring schemes. They are usually required to continuously observe the testing process under a given censoring scheme. However, due to the high cost and/or possible danger, it is sometimes infeasible to carry out continuous inspection in monitoring the test. Alternatively, an interval inspection scheme can be used, where only the number of failures between two consecutive inspections is recorded. Combining the concepts of the progressive censoring and the interval censoring, Aggarwala [4] developed a progressive type-I interval censoring (PIC-I) scheme. Since Aggarwala [4], many scholars have studied the statistical inference for PIC-I data under various life distributions by the maximum likelihood method and/or Bayesian method. Some of them are Xiang and Tse [5], Ng and Wang [6], Chen and Lio [7], Lin and Lio [8], Singh and Tripathi [9], Lodhi and Tripathi [10], Budhiraja and Pradhan [11], Wu and Chang [12], and Alotaibi et al. [13]. In addition to statistical inference, many researchers have been focused on optimally obtaining PIC-I test plans. For more information on this direction one can refer to, e.g., Wu et al. [14], Lin et al. [15], Lin et al. [16], Singh and\nSymmetry 2022, 14, 1047. https://doi.org/10.3390/sym14051047 https://www.mdpi.com/journal/symmetry\nTripathi [9], Roy and Pradhan [17], Budhiraja and Pradhan [18], Roy and Pradhan [19], and Wu et al. [20]. In most of the aforementioned studies on designing PIC-I test schemes, the model parameters that appear in the design criteria are assumed to be known, usually gained from previous studies. Designs obtained under these planning values are called locally optimal designs. If these values are uncertain, which is usually the case, or are incorrectly specified, then these designs may not be optimal. Therefore, it would be helpful for researchers to obtain the optimal designs, which are robust against misspecifications of the values of the model parameters. For the PIC-I life tests, Roy and Pradhan [17,19] proposed to employ proper prior distributions over the entire parameter space to describe the knowledge about the parameters. Then the designs obtained were called Bayesian optimal designs. Unfortunately, we sometimes do not have enough information to construct such prior distributions. In this case, the minimax method can be used to obtain robust designs. The resulting design is often referred to as the minimax optimal design. In fact, in the literature of experimental design, the Bayesian and minimax strategies have been widely used to overcome the dependency of the optimal design on the unknown parameters (see, e.g., Chaloner and Verdinelli [21], Atkinson, et al. [22], and Yue and Zhou [23]). However, in our knowledge, these problems have not been properly addressed when designing the reliability test. Previous reviewed studies mainly focused on single design objective, such as estimation of model parameters (e.g., Wu et al. [14]) or the qth quantile of the life distribution or minimization of the total cost of life testing (e.g., Roy and Pradhan [19]). However, sometimes researchers prefer to achieve a design that meets multiple objectives at the same time. This design is called a multiple-objective design, which is robust with respect to the design objectives. In the accelerated life test (ALT), Pan and Yang [24] proposed a compound design criterion to obtain a dual-objective optimal design, which could make a trade-off between the model parameter estimation and the model-based prediction. Bhattacharya et al. [25] gave a new design method based on multi-criteria, taking variance and cost factors into account in the context of the hybrid censored life-testing experiment. Though there are some studies on robust designs in reliability life tests for multiple design objectives, robust optimum designs for PIC-I tests have received little attention in the literature so far. In this paper, we study robust optimum designs for PIC-I life tests by using the Bayesian and minimax strategies to deal with the model parameters dependency problem and the compound design method to fulfill multiple design objectives. Two robust optimum design criteria and two algorithms are provided to calculate robust optimum designs when the experimental cost is taken into account. Our methods can help practitioners have easier access to robust optimum designs when the model parameters are uncertain and there are more than one design objective, and can be easily extended to obtain robust designs for other test schemes. The rest of this paper is organized as follows. Section 2 introduces the PIC-I test plan and derives the Fisher information matrix (FIM). Section 3 provides definitions of the Bayesian compound and the minimax compound optimality criteria for the PIC-I test plans based on both D-optimality and c-optimality, termed BcD-optimality and McD-optimality, respectively. Section 4 presents two optimization algorithms, i.e., mixed-integer nonlinear optimization (MNO) and Particle swarm optimization (PSO), to derive optimal equal spaced PIC-I test plans and general PIC-I test plans, respectively. Numerical results are given in Sections 5 and 6 to illustrate the proposed methods. Conclusions and discussions are made in Section 7."
        },
        {
            "heading": "2. Preliminaries",
            "text": "Suppose that the lifetime T of a test product follows the Weibull distribution with the probability density function (pdf)\nf (t; \u03b7, \u03bd) = \u03bd \u03b7\u03bd t\u03bd\u22121 exp\n{ \u2212 (\nt \u03b7\n)\u03bd} , t > 0, \u03b7, \u03bd > 0, (1)\nand the cumulative distribution function (cdf)\nF(t; \u03b7, \u03bd) = 1\u2212 exp { \u2212 (\nt \u03b7\n)\u03bd} . (2)\nLet Y = log(T). We can convert the Weibull distribution to the extreme value (Gumbel) distribution given by\nf (y; \u00b5, \u03c3) = 1 \u03c3\nexp {\ny\u2212 \u00b5 \u03c3 \u2212 exp\n( y\u2212 \u00b5\n\u03c3\n)} ,\u2212\u221e < \u00b5 < \u221e, \u03c3 > 0, (3)\nwhere \u00b5 = log \u03b7 is the location parameter and \u03c3 = 1/\u03bd is the scale parameter. The corresponding cdf can be written as\nG(y; \u00b5, \u03c3) = 1\u2212 exp { \u2212 exp ( y\u2212 \u00b5\n\u03c3\n)} . (4)\nAssume that a PIC-I scheme is employed, where all N units are simultaneously placed on a life test at the beginning of the experiment, and interval inspections are conducted at time points t1, t2, . . . , tk. At the jth inspection time tj, nj failed units are observed and rj surviving units are randomly removed from the experiment. Let qj denote the probability that a unit fails in the jth time interval given that the failure has not occurred in an earlier time interval, i.e.,\nqj = P(yj\u22121 \u2264 Y \u2264 yj | Y \u2265 yj) = G(yj)\u2212 G(yj\u22121)\n1\u2212 G(yj\u22121) = 1\u2212 exp(hj \u2212 hj\u22121), (5)\nwhere h0 = 0, hj = \u2212 exp(zj), j = 2, . . . , k with zj = (yj \u2212 \u00b5)/\u03c3 and yj = log(tj). Under the PIC-I test plan, the distribution of the number of failed units nj is binomial, i.e., nj | nj\u22121, . . . , n1, rj\u22121, . . . , r1 \u223c binomial(mj, qj), (6)\nwhere m1 = N and mj = N \u2212\u2211 j\u22121 s=1 ns \u2212\u2211 j\u22121 s=1 rs, j = 2, . . . , k is the number of non-removed surviving units at the beginning of the jth inspection. Note that the number of removal units rj is a random variable due to the randomness of the variable nj, and its value can be computed through the predetermined percentages of the remaining survived units pj (with pk = 1). That is, rj = (mj \u2212 nj)pj. All data collected from the PIC-I test plan are denoted by D = {nj, rj, j = 1, . . . , k}. Let \u03b8 = (\u00b5, \u03c3)T be the vector of the model parameters. Based on the data D and the cdf given in Equation (4), the likelihood function of \u03b8 can be written as\nL(\u03b8) = k\n\u220f j=1 ( mj nj )[ 1\u2212 exp(hj \u2212 hj\u22121) ]nj[exp(hj \u2212 hj\u22121)]mj\u2212nj . Then, the corresponding log-likelihood function is\n`(\u03b8) = k\n\u2211 j=1\n{ log (\nmj nj\n) + nj log [ 1\u2212 exp(hj \u2212 hj\u22121) ] + (mj \u2212 nj)(hj \u2212 hj\u22121) } . (7)\nTherefore, the maximum likelihood estimates (MLEs) of the parameters \u00b5 and \u03c3 can be obtained by solving the following likelihood equations:\n\u2202`(\u03b8)\n\u2202\u00b5 =\n\u2202`(\u03b8)\n\u2202\u03c3 = 0.\nFurthermore, the FIM of the parameters \u03b8 can be written as\nI(\u03b8) = ( I\u00b52 I\u00b5\u03c3 I\u00b5\u03c3 I\u03c32 ) , (8)\nwhere\nI\u00b52 = 1 \u03c32\nk\n\u2211 j=1\nE(mj) (hj \u2212 hj\u22121)2\n1\u2212 exp(hj \u2212 hj\u22121) exp(hj \u2212 hj\u22121),\nI\u03c32 = 1 \u03c32\nk\n\u2211 j=1\nE(mj) (zjhj \u2212 zj\u22121hj\u22121)2\n1\u2212 exp(hj \u2212 hj\u22121) exp(hj \u2212 hj\u22121),\nI\u00b5\u03c3 = 1 \u03c32\nk\n\u2211 j=1\nE(mj) (hj \u2212 hj\u22121)(zjhj \u2212 zj\u22121hj\u22121)\n1\u2212 exp(hj \u2212 hj\u22121) exp(hj \u2212 hj\u22121)\nand E(mj) = NSj\u22121, j = 2, . . . , k. Here, S1 = 1, and Sj\u22121 = \u220f j\u22121 s=1(1\u2212 qs)(1\u2212 ps) is the survival probability of the test unit until the time point tj\u22121. Under some mild regularity conditions, the FIM is approximate to the inverse of the variance-covariance matrix of the MLE of \u03b8."
        },
        {
            "heading": "3. Robust PIC-I Test Plan",
            "text": ""
        },
        {
            "heading": "3.1. PIC-I Test Plan",
            "text": "In this section, we investigate the optimal PIC-I test plan with limited cost constraint. Generally, the PIC-I test plan consists of the total number of test units N, the number of inspections k, the inspection time points tj, j = 1, . . . , k and the proportions of the removals at each time point pj, j = 1, . . . , k\u2212 1. For convenience, we denote the PIC-I test plan as \u03be, i.e.,\n\u03be = { N, tj, pj, j = 1, . . . , k, pk = 1 } .\nFrom the expression of the FIM given in (8), it can be easily concluded that if there is no limit on the removal proportions pj and if the other conditions are fixed, the optimal choices of pj(j = 1, . . . , k\u2212 1) are zeros. Some evidences can be found in the work by Roy and Pradhan [17,19]. However, this is not consistent with the topic discussed in this paper. To investigate the influence of the removal proportions pj(j = 1, . . . , k) on the optimal PIC-I test plan, we assume that the scheme of removals at each points is predetermined. Then, the PIC-I test plan can be re-expressed as\n\u03be = { N, tj; pj, j = 1, . . . , k, pk = 1, N \u2208 N+, tj \u2208 R+, pj \u2208 P } , (9)\nwhere N+ is the set of positive integers,R+ is the set of positive natural number, P is the set of possible values of pj and will be predetermined by the experimenter. For practical convenience, many studies assume that the inspection time intervals have equal lengths, say \u03c4. Then, the inspection time points can be re-expressed as tj = j\u03c4, j = 1, . . . , k, k \u2208 K,K = {1, 2, . . . , k } where k is the maximum number of inspections. In addition, the removal proportions at each inspection times can be assumed constant, i.e., p1 = p2 = . . . = pk\u22121 = p \u2208 P . Therefore, the design (9) can be reduced to\n\u03be = { N, k, \u03c4; p, N \u2208 N+, k \u2208 K, \u03c4 \u2208 R+, p \u2208 P } . (10)\nSince the FIM I(\u03b8) given in (8) depends not only on the parameter vector \u03b8, but also the design \u03be, we denote I(\u03b8) by I(\u03be; \u03b8) in what follows."
        },
        {
            "heading": "3.2. D- and c-Optimal Design Criteria",
            "text": "The first design criterion we considered is the D-optimality for estimating the model parameter vector \u03b8 as efficiently as possible. The D-optimal criterion is defined as follows:\n\u03a8D(\u03be; \u03b8) = \u2212 1 2 log | I(\u03be; \u03b8) |= \u22121 2 log(I\u00b52I\u03c32 \u2212 I2\u00b5\u03c3), (11)\nwhere I\u00b52 , I\u03c32 , I\u00b5\u03c3 are given in Equation (8). Let \u039e be the set consisting of all possible designs \u03be in the form of (9) or (10). The design \u03be\u2217D, which satisfies \u03be \u2217 D = min\u03be\u2208\u039e \u03a8D(\u03be; \u03b8) for given \u03b8 is called a D-optimal design. The rationality of taking use of this design criterion can be found in Atkinson et al. [22] and has been discussed by many authors (e.g., Wu et al. [14], and Roy and Pradhan [17]). In addition to the estimation of the model parameters \u00b5 and \u03c3, an experimenter may also be interested in estimating the qth quantile lifetime of the units (Roy and Pradhan [19]). Let yq be the logarithm of the qth quantile lifetime of the units, and cq = (1, cq)T = (1, log(\u2212 log(1\u2212 q)))T . Under the distribution (4), then yq can be written as yq = cTq \u03b8. By the invariance property of the MLE and the delta method, the distribution of the estimator y\u0302q is approximately normal with mean yq and variance cTq I\u22121(\u03be; \u03b8)cq. To efficiently estimate yq, the following c-optimality criterion is usually adopted:\n\u03a8c(\u03be; \u03b8) = log [ cTq I\u22121(\u03be; \u03b8)cq ] = log [ (I\u00b52 \u2212 2cqI\u00b5\u03c3 + c2qI\u03c32)/(I\u00b52I\u03c32 \u2212 I2\u00b5\u03c3) ] . (12)\nA design \u03be\u2217c which minimizes \u03a8c(\u03be; \u03b8) for given \u03b8 and q over the design space \u039e is called a c-optimal design.\nRemark 1. The design criterion given in Equation (12) depends on the setting of q, which will be determined based on some practical consideration. To overcome the dependence, a nonnegative weight function W(q) satisfying \u222b 1 0 W(q)dq = 1 can be used following the idea of Kundu [26]. Then, the design criterion will be\n\u03a8c(\u03be; \u03b8) = log [\u222b 1\n0 (I\u00b52 \u2212 2cqI\u00b5\u03c3 + c2qI\u03c32)/(I\u00b52I\u03c32 \u2212 I2\u00b5\u03c3)W(q)dq\n] .\nTo compare the optimal PIC-I test plan \u03be\u2217L with another arbitrary test plan \u03be under a given L-optimality criterion (L \u2208 {D, c}), we define the following efficiency function\nEffL(\u03beL; \u00b7) = exp(\u03a8L(\u03be\u2217L; \u00b7)\u2212\u03a8L(\u03be; \u00b7)). (13)"
        },
        {
            "heading": "3.3. Bayesian Compound Design Criterion",
            "text": "Note that the design criteria \u03a8D(\u03be; \u03b8) and \u03a8c(\u03be; \u03b8) depend not only on the design \u03be, but also on the the parameters \u03b8. Optimal designs obtained under a perfect guess (planning) values \u03b8t are called locally optimal designs (Chernoff [27]). Numerical results given in Wu et al. [14] indicate that D-optimal test plans depend on the setting of the parameters \u00b5 and \u03c3. To reduce the risks caused by misspecifying the planning values \u03b8t, many approaches, such as the Bayesian, minimax, adaptive, or sequential approaches have been proposed in the literature of optimal experimental designs, see Atkinson et al. [22] for details. However, planning robust test schemes has rarely been found in a reliability study. Therefore, in the following part of this subsection, we apply robust design techniques to obtain robust PIC-I test plans. To be consistent with most experiments in practical applications, we confine ourselves on the static robust design methods, including the Bayesian and the minimax approaches to obtain robust test plans against the uncertainty of the parameters \u03b8.\nIn addition, even when all parameters in the D-optimality and c-optimality criteria have the same settings, the D-optimal design \u03be\u2217D and the c-optimal design \u03be \u2217 c are not necessarily identical, see the numerical results listed in Table 1. To get a good test plan that satisfies many design objectives, the compound design criterion (Cook and Wong [28]) should be a good choice. It can ensure that the optimal design has good performances for different design purposes (Pan and Yang [24]). Therefore, considering the uncertainty of the parameters in the model and two possible design objectives, we propose the Bayesian compound optimality criterion (termed BcD-optimality), which is given as follows:\n\u03a8BcD(\u03be; \u03ba) = \u03ba \u222b\n\u0398 \u03a8D(\u03be; \u03b8)p(\u03b8)d\u03b8+ (1\u2212 \u03ba) \u222b \u0398 \u03a8c(\u03be; \u03b8)p(\u03b8)d\u03b8, (14)\nwhere p(\u03b8) is the prior over the set \u0398, which will be specified later, and \u03ba is the weight parameter reflecting the relative importance between the D-optimality and the c-optimality. A design, \u03be\u2217BcD, which minimizes \u03a8BcD(\u03be; \u03ba) over the design space \u039e is called a BcD-optimal design. In this paper, we assume that the prior of \u00b5 is a censored normal distribution over the interval [a, b], and its pdf is\n\u03c0(\u00b5; \u00b50, \u03c320 ) = f (\u00b5; \u00b50, \u03c320 )\n\u03a6(b; \u00b50, \u03c320 )\u2212\u03a6(a; \u00b50, \u03c320 ) , a \u2264 \u00b5 \u2264 b, \u03c30 > 0, (15)\nwhere f (\u00b5; \u00b50, \u03c320 ) and \u03a6(\u00b7; \u00b50, \u03c30) are the pdf and cdf of the normal distribution N(\u00b50, \u03c320 ) and \u00b50, \u03c320 are the hyperparameters predetermined by the experimenter. The prior of the scale parameter \u03c3 is assumed to be a censored inverse \u0393(\u03bd0, \u03b30) over the interval [c, d] with the pdf\n\u03c0(\u03c3; \u03bd0, \u03b30) = f (\u03c3; \u03bd0, \u03b30)\n\u0393\u22121(d; \u03bd0, \u03b30)\u2212 \u0393\u22121(c; \u03bd0, \u03b30) ,\nf (\u03c3; \u03bd0, \u03b30) = \u0393(\u03bd0) \u03b3\u03bd00\n\u03c3\u2212(\u03bd0+1) exp ( \u2212\u03b30\n\u03c3\n) , \u03bd0, \u03b30 > 0,\nwhere f (\u00b7; \u03bd0, \u03b30) and \u0393\u22121(\u00b7; \u03bd0, \u03b30) are the pdf and cdf of the inverse Gamma distribution \u0393\u22121(\u03bd0, \u03b30), respectively, and \u03bd0, \u03b30 are the hyperparameters predetermined by the experimenter. Under the assumption of the priors of \u00b5 and \u03c3 being independent, the joint prior density of \u00b5 and \u03c3 is given as\n\u03c0(\u00b5, \u03c3) = \u03c0(\u00b5; \u00b50, \u03c320 ) \u00b7 \u03c0(\u03c3; \u03bd0, \u03b30), (\u00b5, \u03c3) \u2208 \u0398 = [a, b]\u00d7 [c, d].\nIn addition, when the weight \u03ba equals 0 (or 1), then the BcD-optimal design \u03be\u2217BcD will reduce to Bayesian c (or D)-optimal design and be denoted as \u03be\u2217Bc (or \u03be \u2217 BD). In the special case that the prior has only one support point \u03b8t, the BcD-optimal design becomes the locally cD-optimal design, which can be denoted as \u03be\u2217cD and the corresponding design criterion is\n\u03a8cD(\u03be; \u03ba, \u03b8t) = \u03ba\u03a8D(\u03be; \u03b8t) + (1\u2212 \u03ba)\u03a8c(\u03be; \u03b8t). (16)\nTo deal with the integration in the Bayesian optimality criterion, we can draw Q samples \u03b8l from the joint prior distribution \u03c0(\u00b5, \u03c3) and use the MCMC method to obtain the approximation of the Bayesian optimality criterion (14) (Roy and Pradhan [17,19]), i.e.,\n\u03a8BcD(\u03be; \u03ba) = 1 Q\nQ\n\u2211 l=1\n{ \u2212\u03ba\n2 log | I(\u03be; \u03b8l) | +(1\u2212 \u03ba) log\n[ cTq I\u22121(\u03be; \u03b8l)cq ]} .\nHowever, the computational burden for this approximation will increase rapidly with the sample size Q. To reduce computational burden, Foo and Duffull [29] proposed a hypercube D-optimality criterion to optimize the logarithm of the product of the normalized determinants of FIM over the set of their model parameters, which consists of the\ncombinations of the 2.5th and 97.5th percentiles of the priors distributions. In this paper, we utilize a similar idea to alleviate the computational burden, but more percentiles of the prior parameter distribution are used to ensure the accuracy of approximation. We denote the set of all combinations of these percentiles by \u0398Q. Then\n\u03a8BcD(\u03be; \u03ba) = 1 Q \u2211\n\u03b8l\u2208\u0398Q\n{ \u2212\u03ba\n2 log | I(\u03be; \u03b8l) | +(1\u2212 \u03ba) log\n[ cTq I\u22121(\u03be; \u03b8l)cq ]} . (17)"
        },
        {
            "heading": "3.4. Minimax Compound PIC-I Test Plan",
            "text": "Another popular robust design approach is the minimax method, which aims at finding the design that minimizes the maximum values of the compound optimality criterion over the parameters space \u0398Q. Similar to the Bayesian optimality criterion, the minimax optimality criterion (termed McD-optimality) is defined as follows:\n\u03a8McD(\u03be; \u03c9) = \u03c9 max \u03b8\u2208\u0398Q \u03a8D(\u03be; \u03b8) + (1\u2212\u03c9) max \u03b8\u2208\u0398Q \u03a8c(\u03be; \u03b8), (18)\nwhere \u03c9 is the weight parameter similar as \u03ba. The design \u03be\u2217McD minimizing \u03a8McD(\u03be; \u03c9) over the design space \u039e is called a McD-optimal design. In addition, when the weight \u03c9 equals 0 (or 1), then the McD-optimal design \u03be\u2217McD will reduce to the minimax c-optimal design and be denoted as \u03be\u2217Mc (or \u03be \u2217 MD)."
        },
        {
            "heading": "3.5. Cost Constraint",
            "text": "To make the test plan be more practical for experimenters, we take the budget of the experiment into account at the planning stage. For the general design \u03be defined in Equation (9), we assume that there is a restriction on the total cost\nC1(\u03be) = NCs + kCi + tkCo \u2264 C, (19)\nwhere Cs is the cost of one test unit, Ci is the cost of one inspection, Co is the operation cost of one unit time, and C is the total cost. For more details one can refer to Wu et al. [14]. Furthermore, for the special test plan \u03be defined in (10), the cost constraint is defined as follows:\nC2(\u03be) = NCs + kCi + k\u03c4Co \u2264 C. (20)"
        },
        {
            "heading": "4. Algorithms",
            "text": ""
        },
        {
            "heading": "4.1. Mixed-Integer Nonlinear Optimization Algorithm",
            "text": "In this subsection, we give an algorithm inspired by Wu et al. [14] to search for the robust PIC-I test plan with equal inspection intervals of length \u03c4 and the constant removal proportion p, except at the end of the experiment. The design is given in (10) and the cost constraint is presented in (20). For clarity, we rewrite the robust design criteria \u03a8BcD(\u03be; \u03ba) and \u03a8McD(\u03be; \u03c9) by \u03a8BcD(N, k, \u03c4; \u03ba) and \u03a8McD(N, k, \u03c4; \u03c9), respectively. Then, the optimization problem can be expressed as\nmin \u03a8BcD(N, k, \u03c4; \u03ba) or \u03a8McD(N, k, \u03c4; \u03c9) s.t. C2(\u03be) = NCs + kCi + k\u03c4Co \u2264 C, (21) N \u2208 N+, \u03c4 \u2208 R+, k \u2208 K.\nSince C2(\u03be) \u2264 C, we have N \u2264 (C\u2212 (kCi + k\u03c4Co))/Cs \u2264 (C\u2212 Ci)/Cs. Thus, the upper bound of N is obtained. Because the D-optimality and c-optimality are decreasing functions of N, we substitute N by its upper bound (C\u2212 (kCi + k\u03c4Co))/Cs in the design criteria. Furthermore, for a given value of N, we have k \u2264 (C\u2212 NCs)/Ci \u2264 (C\u2212 Cs)/Ci. Then the upper bound of k is min{(C \u2212 Cs)/Ci, k }. Similarly, we can obtain the upper bound of \u03c4, \u03c4 \u2264 (C\u2212 Cs \u2212 kCi)/(kCo) for a given k. Therefore, the algorithm to solve the optimization problem (21) is given in Algorithm 1.\nAlgorithm 1 MNO Algorithm.\n1: Set the values of the cost parameters Cs, Ci, Co, C; the maximum number of inspection k ; the removal proportion p; the region of the model related parameters \u0398; the hyperparamters in the priors for Bayesian optimality criterion; the weight parameter \u03ba or \u03c9. 2: Compute the upper bound of the number of inspections\nk\u0303 = min {[\nC\u2212 Cs Ci\n] , k } ,\nwhere [y] denotes the greatest integer less than or equal to y. 3: Set k = 2. 4: Calculate the upper bound of the length of inspection interval\n\u03c4k = C\u2212 Cs \u2212 kCi\nkCo .\n5: For a given k, by the optimization method, such as the PSO algorithm or the grid method, if the minimum length of the inspection interval is to be considered due to practical constraints, find the solution \u03c4\u2217k to the problem\n\u03c4\u2217k = arg min \u03c4\u2208[0,\u03c4k ] \u03a8BcD(N(k, \u03c4), k, \u03c4; \u03ba) or \u03a8McD(N(k, \u03c4), k, \u03c4; \u03c9),\nwhere N(k, \u03c4) = (C\u2212 (kCi + k\u03c4Co))/Cs. 6: Set k = k + 1. If k \u2264 k\u0303 go to Step 4, else go to Step 7. 7: Find the optimal design \u03be\u2217 = {N\u2217, k\u2217, \u03c4\u2217} such that\n\u03a8BcD(N\u2217, k\u2217, \u03c4\u2217; \u03ba) = min 1\u2264k\u2264k\u0303 \u03a8BcD(N(k, \u03c4\u2217k ), k, \u03c4 \u2217 k ; \u03ba) or \u03a8McD(\u03be\u2217) = min 1\u2264k\u2264k\u0303 \u03a8McD(N(k, \u03c4\u2217k ), k, \u03c4 \u2217 k ; \u03c9).\n8: Output the optimal test plan \u03be\u2217 = {N\u2217, k\u2217, \u03c4\u2217}."
        },
        {
            "heading": "4.2. Particle Swarm Optimization Algorithm",
            "text": "In Section 4.1, we have considered a special case of the PIC-I test plan and give an algorithm to obtain the robust test plan. However, the procedure depends on the cost function and the assumption of equal length of inspection interval and the same removal proportion. In this subsection, we give an algorithm to solve the general design problem defined as follows:\nmin \u03a8BcD(\u03be; \u03ba) or \u03a8McD(\u03be; \u03c9) s.t. C1(\u03be) \u2264 C, (22) N \u2208 N+, pi \u2208 P , 0 \u2264 t1 \u2264 t2 \u2264 . . . \u2264 tk, ti \u2208 (0, tmax).\nThe concrete form of the design \u03be has been given in (9). From the definition of the cost function C1(\u03be) in (19), we have N \u2264 (C\u2212 kCi \u2212 tkCo)/Cs. The information given in (8) implies that more test units will provide more information. Therefore, we substitute N in (8) by the supreme value (C\u2212 kCi \u2212 tkCo)/Cs to solve the optimization problem (22). Then, the optimality criterion \u03a8BcD(\u03be) or \u03a8McD(\u03be) is a function of pi, ti, which are all continuous variables. To solve this continuous optimization problem with constraints, we use the PSO algorithm, which is a population based stochastic optimization method inspired by the social behavior of birds flocking or fish schooling. It was introduced by Eberhart and Kennedy [30], improved by many authors to deal with all kinds of optimization problems. It has shown high efficiency in finding optimal points in various disciplines\n(Poli et al. [31], Ruidas et al. [32,33]). The PSO algorithm is derivative-free. There are few tuning parameters required of the algorithm and the knowledge of good solutions is retained by all particles, and particles in the swarm share information between, which makes the algorithm easily escape from local minima and converge at a fast rate. Recently, different versions of PSO have been used to solve all kinds of optimal design problems (see Chen et al. [34], Zhou et al. [35], and Liu et al. [36]). In the following we give a summary of the PSO algorithm for completeness. For the sake of brevity and clarity, we vectorize the design \u03be and denote it by X = [t1, t2, . . . , tk], and by f (X) denote the optimality criterion function \u03a8BcD(\u03be; \u03ba) or \u03a8McD(\u03be, \u03c9). The optimization problem (22) is rewritten as\nmin f (X)\ns.t. C2(X)\u2212 C \u2264 0, 0 \u2264 t1 \u2264 t2 \u2264 . . . \u2264 tk, ti \u2208 (0, tmax), 0 < k < k . (23)\nHere, ui, i = 1, 2 are real random numbers between 0 and 1, Pi is the best candidate solution found for the ith particle, Pg is the best candidate solution for the entire population particles, and \u03b1, \u03b1i, i = 1, 2 are the user defined coefficients which respectively control the inertia, the exploitive, and the explorative attributes of the particle motion."
        },
        {
            "heading": "5. Numerical Example",
            "text": "In this section, we present a numerical example to illustrate the applications of the proposed robust design methods. As in the study by Wu et al. [14], we use the algorithm given by Aggarwala [4] to generate data with n = 20, k = 5, \u03c4 = 2, \u03b7 = 5, \u03bd = 2 and the predetermined removed proportions (p1, . . . , p5) = (0, 0.2, 0.3, 0.4, 1). Then the corresponding parameters in model (4) become \u00b5 = log 5, \u03c3 = 1/2. The generated data are presented in Table 2. Based on the data, we easily obtain the MLEs of \u00b5 and \u03c3, \u00b5\u0302 = 1.8454 and \u03c3\u0302 = 0.5091, and their standard errors s\u00b5\u0302 = 0.1329 and s\u03c3\u0302 = 0.1157, respectively. To use the Bayesian or minimiax design criteria, we assume that the range of the values of \u00b5 and \u03c3 are [a, b] = [\u00b5\u0302\u2212 s\u00b5\u0302, \u00b5\u0302 + s\u00b5\u0302] and [c, d] = [\u03c3\u0302 \u2212 s\u03c3\u0302, \u03c3\u0302 + s\u03c3\u0302], respectively. The hyperparameters in the censored normal distribution N(\u00b50, \u03c320 ) are \u00b50 = 1.8 and \u03c30 = 0.2, respectively. Similarly, the hyperparameters in the censored inverse distribution \u0393\u22121(\u03bd0, \u03b30) are assumed to be \u03bd0 = 27 and \u03b30 = 13, respectively, which implies that the mean of \u0393\u22121(\u03bd0, \u03b30) is 0.5 and the variance is 0.01. The cost parameters are assumed as follows: Cs = $80/unit, Ci = $3, Co = $2.5/10 h, and C = $6000. In our numerical results, the set \u0398Q = {(\u00b5ith, \u03c3jth), i, j = 0, 1, . . . , 10}, where \u00b5ith is the ith quantile of \u03c0(\u00b5; \u00b50, \u03c320 ) and \u03c3jth is the jth quantile of \u03c0(\u03c3; \u03bd0, \u03b30), which are used to obtain the approximation of the BcD-optimality criterion in (14) or to calculate the McD-optimality criterion in (18). We set q = 0.1 in the BcD- and McD-optimal design criteria. Since the McD-optimal PIC-I test plans are very similar to their corresponding BcD-optimal ones, then we do not show the numerical McD-optimal PIC-I test plans in what follows to save space. We will give some concluding remarks in Section 6. The R codes, written to obtain the results in this paper, can be obtained from the authors upon request."
        },
        {
            "heading": "5.1. Locally Optimal PIC-I Test Plans",
            "text": "By Algorithm 1, we first compute the locally D- and c-optimal equal spaced (ES) PIC-I test plans (denoted as \u03be\u2217D and \u03be \u2217 c , respectively) at the planning values \u00b5 = log 5 and \u03c3 = 1/2 when the removal proportions are p = 0.1 and p = 0.3, respectively.\np = 0.1 : \u03be\u2217D : N = 74, k = 7, \u03c4 = 1.9261, \u03a8D = \u22125.6620, EffD(\u03be\u2217BD) = 0.9834, EffD(\u03be \u2217 MD) = 0.9735,\n\u03be\u2217c : N = 74, k = 5, \u03c4 = 1.7235, \u03a8c = \u22123.5486, Effc(\u03be\u2217Bc) = 0.9872, Effc(\u03be \u2217 Mc) = 0.9911. (24)\np = 0.3 : \u03be\u2217D : N = 74, k = 5, \u03c4 = 2.7647, \u03a8D = \u22125.3891, EffD(\u03be\u2217BD) = 0.9609, EffD(\u03be \u2217 MD) = 0.9485,\n\u03be\u2217c : N = 74, k = 3, \u03c4 = 2.6525, \u03a8c = \u22123.4414, Effc(\u03be\u2217Bc) = 0.9622, Effc(\u03be \u2217 Mc) = 0.9824. (25)\nIn Equations (24) and (25), we also present the efficiencies of the Bayesian and minimax D- and c-optimal test plans with \u0398 = \u03981, which will be defined later. These efficiencies indicate that these robust designs perform well. To assess the influence of the settings of the parameters \u00b5 and \u03c3 and the design criteria, the optimal PIC-I test plans under different parameters settings and removal proportions for different design criteria are computed, which are shown in Table 1. Comparing with the optimal test plans presented in Equations (24) and (25), we find that the settings of the planning values will have a great impact on the final designs, especially when the uncertainty of \u00b5 and \u03c3 encountered in the design stage becomes great\u2014so do the removal proportions and design criteria. The efficiencies of the c- and D-optimal designs relative to the D- and c-optimal designs are also shown in Table 1. These efficiencies imply that the design purposes will have an effect on the finial designs. In addition, for some planning values, the c-optimal test plans can be very inefficient, whereas the D-optimal test plans perform well under the c-optimality in all cases considered here."
        },
        {
            "heading": "5.2. Bayesian Optimal PIC-I Test Plans",
            "text": "To obtain optimal PIC-I test plans that fulfill multiple design purposes, we compute cD-optimal compound designs for different weights \u03ba, planning values \u03b8, and removal\nproportions p. Some of the results are given in Table 3. The designs with \u03ba = 0 and \u03ba = 1 correspond to locally c- and D-optimal designs, respectively. From the table, we find that the optimal number of units remains constant, which is determined by the cost parameters, as we will discuss later. The results in Table 3 show us that cD-optimal designs depend on the planning values of \u03b8, the weight \u03ba, and the removal proportion p. With the increase of the removal proportion p, the number of inspections will decrease, but the length of the inspection interval will increase. The duration of the experiment will increase when the weight approaches 1. In addition, efficiencies of the cD-optimal designs with different \u03ba to the locally D- and c-optimal designs imply that the cD-optimal designs can perform very well in most cases. However, in some special cases, such as p = 0.3 and \u00b5 = \u00b5\u0302 \u2212 2s\u00b5\u0302, \u03c3 = \u03c3\u0302 \u2212 2s\u03c3\u0302, the cD-optimal compound designs are very sensitive to the change of the weight parameter \u03ba. Furthermore, with the increase of \u03ba, the optimal number of inspections will increase or remain constant, and the duration for the design with \u03ba = 1 is always larger than that of the design with \u03ba = 0. To choose a proper value of the weight \u03ba, we suggest using the efficiency lines plot. Figure 1 gives an illustrating example where efficiencies of the cD-optimal compound designs for different \u03ba to the locally D- and c-optimal designs are calculated and presented in a triangle or circle. Then, the horizontal coordinate of the intersection point of these two lines may be the best choice of \u03ba.\nIn Table 4, we show BcD-optimal PIC-I test plans for different weights and removal proportions when the sets of the planning values are \u03981 = [\u00b5\u0302\u2212 s\u00b5\u0302, \u00b5\u0302 + s\u00b5\u0302]\u00d7 [\u03c3\u0302\u2212 s\u03c3\u0302, \u03c3\u0302 + s\u03c3\u0302] and \u03982 = [\u00b5\u0302\u2212 2s\u00b5\u0302, \u00b5\u0302 + 2s\u00b5\u0302]\u00d7 [\u03c3\u0302\u2212 2s\u03c3\u0302, \u03c3\u0302 + 2s\u03c3\u0302], respectively. Comparing the designs with p = 0.1 and p = 0.3, we find that when the removal proportion increases, the number of inspections will decrease and the lengths of the inspection time intervals will increase. Designs with \u0398 = \u03981 and \u0398 = \u03982 indicate that when the uncertainty of the planning values increase, the numbers of inspections tend to increase or remain constant, the lengths of the inspection intervals tend to decrease, and the durations of the optimal designs will become longer for most cases. Furthermore, we also compute the efficiencies of the BcD-optimal designs relative to the BD-optimal designs (\u03ba = 1) and to the Bc-optimal\ndesigns (\u03ba = 0) by the formula given in (13), in which BD- and Bc-optimality criteria are considered, respectively and then presented them in columns 8 (or 15) and 9 (or 16), respectively. By these efficiencies, the robust weights can be determined by the plot of efficiency lines, similar as we have shown in the cD-optimal compound designs."
        },
        {
            "heading": "5.3. Influence of the Cost Parameters",
            "text": "In order to investigate the influence of the cost parameters on the final robust optimal PIC-I test plans, we change the cost parameters over the sets Cr \u2208 {4000, 6000, 8000}, Cs \u2208 {70, 80, 90}, Ci \u2208 {2, 3, 5}, Co \u2208 {1, 2.5, 4} and compute the optimal test plans using Algorithm 1. The results for BcD-optimal designs with p = 0.3 are presented in Table 5. The ranges of the planning values are \u0398 = \u03981. It is observed from Table 5 that the number of units will increase with an increase of the budget C, but decrease with the increase of the cost of one test unit Cs. The test plans are insensitive to the values of the cost parameter of\none inspection Ci. However, the number of inspections or the duration of the experiment will decrease or remain constant with the increase of the cost operation Co. Under different cost parameters, we also list the efficiencies of the BcD-optimal designs to the locally optimal design with the planning values \u00b5 = log 5 and \u03c3 = 0.5. These efficiencies indicate that the performances of the robust BcD-optimal designs are actually quite insensitive to the cost parameters."
        },
        {
            "heading": "5.4. Optimal General PIC-I Test Plans",
            "text": "In this subsection, we consider the solution to the general problem given in (22). The model and values of the model parameters are the same as those described in the previous subsections. We use the PSO algorithm (Algorithm 2) to compute all general PIC-I test plans. Noting from the results in the previous tables that lengths of the inspection intervals are no more than 5, we then limit the lengths of the inspection intervals to the range of 0 to 10 in the PSO algorithm. The optimal PIC-I test plans are calculated for different design criteria and removal proportions. During the computation, we start Algorithm 2 by first setting k = 2, calculate the k-point optimal inspection time points ti and then the optimal size of test units N, and increase k by 1 until the optimality criterion function does not decrease or arrives at the maximum inspection time kmax, see Algorithm 2 for details. We use the solutions obtained using the L-BFGS-B method as the initial values of the PSO algorithm. During the computation, we find that the design criterion is a convex function of k. See Figure 2 for an illustration. For the sake of saving space, we provide only the results with p = 0.3. Table 6 shows the locally D- and c-optimal PIC-I test plans for different number of inspections k and the values of their corresponding design criteria. Table 7 shows the BcD-optimal PIC-I test plans with different \u03ba when the regions of parameters are \u0398 = \u03981 and \u0398 = \u03982, respectively. In Tables 6 and 7, the optimal test plans are shown in\nbold. Looking at these tables we can see that the number of time points of every optimal PICI test plan does not exceed 10, which is very similar to its corresponding equispaced design. In Table 7, the efficiencies of k points BcD-optimal designs relative to their corresponding locally ones given in Table 6 are also given in the last two columns. The results indicate that the BcD-optimal test plans can perform very well in most situations, especially when the planning values are in the prior regions. Finally, to investigate the influence of the cost parameters on the optimal test plans, the BcD-optimal designs are also calculated under different combinations of the cost parameters, and the results for p = 0.3 are presented in Table 8. Similar conclusions to their corresponding ES designs can be drawn from the table.\nAlgorithm 2 PSO Algorithm.\n\u0398 \u03ba k N Inspection Times \u03a8BcD EffD(\u03be\u2217BcD) Effc(\u03be \u2217 BcD) \u03981 0 2 74 (3.911, 7.256) \u22123.4467 0.8388 0.8882 3 74 (3.700, 6.219, 8.875) \u22123.4764 0.8693 0.9238 4 74 (3.658, 6.020, 8.051, 10.269) \u22123.4811 0.8791 0.9314 5 74 (3.650, 5.983, 7.900, 9.628, 11.190) \u22123.4813 0.8818 0.9329 6 74 (3.650, 5.982, 7.892, 9.595, 11.047, 11.312) \u22123.4808 0.8816 0.9329\n0.5 2 74 (3.811, 9.328) \u22124.3429 0.8983 0.8882 3 74 (3.540, 7.755, 11.515) \u22124.4152 0.9313 0.9088 4 74 (3.453, 7.255, 10.413, 13.462) \u22124.4335 0.9383 0.9218 5 74 (3.430, 7.122, 10.123, 12.563, 15.151) \u22124.4376 0.9407 0.9256 6 74 (3.424, 7.090, 10.053, 12.353, 14.409, 16.276) \u22124.4378 0.9414 0.9263 7 74 (3.423, 7.087, 10.046, 12.334, 14.342, 16.028, 16.511) \u22124.4373 0.9415 0.9263\n1 2 74 (3.304, 9.810) \u22125.3200 0.8949 0.8700 3 74 (3.227, 8.798, 12.277) \u22125.4196 0.9254 0.8763 4 74 (3.193, 8.480, 11.343, 14.299) \u22125.4422 0.9367 0.8813 5 74 (3.183, 8.389, 11.098, 13.437, 16.036) \u22125.4472 0.9405 0.8829 6 74 (3.180, 8.366, 11.037, 13.234, 15.279, 17.240) \u22125.4476 0.9414 0.8831 7 74 (3.180, 8.363, 11.030, 13.209, 15.188, 16.899, 17.583) \u22125.4472 0.9415 0.8831\n\u03982 0 2 74 (3.835, 7.571) \u22123.4431 0.8794 0.8994 3 74 (3.590, 6.233, 9.451) \u22123.4909 0.8914 0.9388 4 74 (3.538, 5.963, 8.319, 11.210) \u22123.4998 0.8963 0.9472 5 74 (3.527, 5.902, 8.074, 10.268, 12.605) \u22123.5010 0.8986 0.9490 6 74 (3.525, 5.892, 8.035, 10.126, 12.055, 13.172) \u22123.5006 0.8993 0.9492\n0.5 2 74 (3.713, 8.514) \u22124.3305 0.9316 0.9037 3 74 (3.469, 7.312, 11.248) \u22124.4273 0.9320 0.9233 4 74 (3.389, 6.910, 10.013, 13.540) \u22124.4508 0.9390 0.9341 5 74 (3.364, 6.784, 9.666, 12.385, 15.614) \u22124.4566 0.9424 0.9377 6 74 (3.357, 6.750, 9.572, 12.096, 14.599, 17.120) \u22124.4573 0.9435 0.9384 7 74 (3.356, 6.745, 9.559, 12.055, 14.459, 16.629, 17.601) \u22124.4569 0.9436 0.9384"
        },
        {
            "heading": "6. A Real Life Example",
            "text": "In this section we consider a real data example, which contains 112 patients with plasma cell myeloma treated at the National Cancer Institute (Carbone et al. [37]) to illustrate our method. For easy reference, we reproduce this data set in Table 9. Note that this data set has been reanalysed by many authors (see Ng and Wang [6] and Lin and lio [8]) via different distributions and estimating methods (Balakrishnan and Cramer [2], Ch. 18). To be consistent with the topic we investigated in this paper, we fit the data by the Weibull distribution (1), similar as Ng and Wang [6], and the parameters are estimated by the maximum likelihood method. The resulted estimates are given as follows: \u00b5\u0302 = 3.1391, \u03c3\u0302 = 0.8132 and s\u00b5\u0302 = 0.0841, s\u03c3\u0302 = 0.0724. Similar in the simulation example, we assume that the range of the values of \u00b5 and \u03c3 are [a, b] = [\u00b5\u0302 \u2212 s\u00b5\u0302, \u00b5\u0302 + s\u00b5\u0302] and [c, d] = [\u03c3\u0302 \u2212 s\u03c3\u0302, \u03c3\u0302 + s\u03c3\u0302], respectively. Furthermore, we assume that the hyperparameters in the prior distributions N(\u00b50, \u03c320 ) and \u0393\n\u22121(\u03bd0, \u03b30) are \u00b50 = \u00b5\u0302, \u03c30 = \u03c3\u0302, \u03bd0 = \u03c3\u03022/s2\u03c3\u0302 + 2 = 128.1588, \u03b30 = \u03c3\u0302(\u03c3\u03022/s2\u03c3\u0302 + 1) = 103.4055. Since we have no any cost information for the original experiment, we then assume that Cs = $60/unit, Ci = $30, Co = $25/m. Therefore, the total cost is C = 121Cs + 9Ci + 60.5C0 = $9042.5. In BcD- or McD-optimal design criteria, we set q = 0.5, which means that the median lifetime of survivors is of interest. In order to compare with the original inspection scheme \u03beorg, we first calculate the optimal\nES and the general PIC-I test plans, respectively, assuming that the number of inspection times and the removal scheme are the same as in \u03beorg. The results for different design criteria are shown in Tables 10 and 11, respectively. Efficiencies of \u03beorg under different design criteria are also given in the last column of these tables. These results indicate that the original inspection scheme \u03beorg has good robustness under different design criteria, except general D- and c-optimal design criteria. In addition, the optimal general PIC-I test plan has better performance than the corresponding ES test plan. Furthermore, considering different removal proportions, p = 0 and p = 0.3, we redesign the Plasma cell myeloma inspection scheme. Optimal robust ES and general inspection schemes for different design criteria are shown in Tables 12 and 13, respectively. The efficiencies of the original scheme \u03beorg are also listed in the last columns of these tables. These numerical results suggest that it is important to consider the removal proportions (or dropouts) at the design stage. The structures of robust PIC-I test schemes obtained under different design criteria may differ substantially."
        },
        {
            "heading": "7. Conclusions and Discussions",
            "text": "This paper considers robust optimal life testing plans under the PIC-I scheme. Based on the D-optimality and c-optimality, both the Bayesian and the minimax compound optimality criteria are proposed to obtain robust designs against the uncertainty of the model parameters and the design objectives. To make the designs more practical, the cost of the experiment at the design stage is taken into account. Two algorithms, including the MNO algorithm and the PSO algorithm, are proposed to solve the optimization problems. A numerical example and a real data example are provided to validate the feasibility and effectiveness of our methods. It is easy to see that the inspection times, the length of the inspection interval, and the experimental duration in the c- (Bc- or Mc-) optimal ES PIC-I test plan are less than the corresponding D- (BD- or MD-) optimal PIC-I test plan. Those in the cD- (BcD- or McD-) optimal PIC-I test plan are somewhere in between. Increasing the removal proportion will reduce the number of the inspections and lengthen the inspection interval. With the increase of the uncertainty of the model parameters, the number of the inspections and the duration of the optimal PIC-I test plan tend to increase. The MCD-optimal PIC-I test plan (not shown in the simulation example) tends to have more inspection times and longer duration of the experimental than its corresponding BcD-optimal test plan. Similar conclusions can be drawn for the general optimal test plan. In addition, we should point out that the optimal PIC-I test plans depend on the budget of the experiment. We need to carefully set the larger coefficients in the cost function,\nbecause they will have a big impact on the experiment. Overall, our numerical results indicate that the proposed approaches can obtain better designs with improved robustness for conducting PIC-I life tests to estimate the model parameters and the qth quantile of the lifetime distribution efficiently. They also provide a coherent way to efficiently use one\u2019s resources. Our approaches are intuitive and can be useful to engineers. In this paper, to approximate the Bayesian and minimax design criteria, we choose finite percentiles of the prior parameter distributions. To improve the accuracy of these approximations, some Monte Carlo sampling methods and advanced optimization methods (Ruidas et al. [33]) need to be applied. This may be a topic worth studying in the future. This paper mainly focuses on obtaining robust designs under PIC-I test schemes when the model parameters are unknown and there are more than one design objective. However, there are still other uncertainties that need to be considered in the design stage. For example, many studies on designing PIC-I test plans assume that the lifetime data follow some symmetrical or asymmetrical distribution, such as Weibull (Wu et al. [14]), lognormal (Roy and Pradhan [17,19]), truncated normal (Lodhi and Tripathi [10]), and Exponentiated Frech\u2019et (Wu and Chang [12]). In fact, many symmetric and asymmetric distributions have recently been proposed to fit lifetime data and evaluate the reliability of system (see [38\u201341]). When life time data is available, many methods of hypothesis testing have been provided to check the fitness of a given distribution (J\u00e4ntschi [42]). However, we need to point out that the life data is not available at the design stage, so the latent lifetime distribution may be uncertain. Therefore, it is an interesting topic to find robust designs against possible departures from underlying model assumptions (Zhao et al. [43]). In addition, our methods proposed in this paper can be extended to the situations of accelerated life test (Wu and Huang [44]) or degradation life test [45].\nAuthor Contributions: Methodology, X.Z. and Y.W.; funding acquisition, R.Y.; software, X.Z. and Y.W.; writing, X.Z., Y.W. and R.Y. All authors have read and agreed to the published version of the manuscript.\nFunding: This work was supported by the National Natural Science Foundation of China under Grants (11971318, 11871143) and Shanghai Rising-Star Program (No. 20QA1407500).\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability Statement: The authors confirm that the data supporting the findings of this study are available within the article.\nAcknowledgments: We express our sincere thanks to the editors and four reviewers for their insightful comments that have greatly improved this article.\nConflicts of Interest: The authors declare no conflict of interest.\nReferences 1. Balakrishnan, N.; Aggarwala, R. Progressive Censoring: Theory, Methods, and Applications; Birkhauser: Basel, Switzerland, 2000. 2. Balakrishnan, N.; Cramer, E. The Art of Progressive Censoring; Birkhauser: New York, NY, USA, 2014. 3. Balakrishnan, N. Progressive censoring methodology: An appraisal. Test 2007, 16, 211\u2013259. [CrossRef] 4. Aggarwala, R. Progressive interval censoring: Some mathematical results with applications to inference. Commun. Stat. Theory Methods 2001, 30, 1921\u20131935. [CrossRef] 5. Xiang, L.; Tse, S.K. Maximum likelihood estimation in survival studies under progressive interval censoring with random removals. Biopharm. Stat. 2005, 15, 981\u2013991. [CrossRef] [PubMed] 6. Ng, H.K.T.; Wang, Z. Statistical estimation for the parameters of Weibull distribution based on progressively type I interval censored sample. J. Stat. Comput. Simul. 2009, 79, 145\u2013159. [CrossRef] 7. Chen, D.G.; Lio, Y.L. Parameter estimations for generalized exponential distribution under progressive type I interval censoring. Comput. Stat. Data. Anal. 2010, 54, 1581\u20131591. [CrossRef] 8. Lin, Y.J.; Lio, Y.L. Bayesian inference under progressive type I interval censoring. J. Appl. Stat. 2012, 39, 1811\u20131824. [CrossRef] 9. Singh, S.; Tripathi, Y.M. Estimating the parameters of an inverse Weibull distribution under progressive type I interval censoring.\nStat. Pap. 2016, 59, 21\u201356. [CrossRef]\n10. Lodhi, C.; Tripathi, Y.M. Inference on a progressive type I interval-censored truncated normal distribution. J. Appl. Stat. 2020, 47, 1402\u20131422. [CrossRef] 11. Budhiraja, S.; Pradhan, B. Point and interval estimation under progressive type-I interval censoring with random removal. Stat. Pap. 2020, 61, 445\u2013477. [CrossRef] 12. Wu, S.F.; Chang, W.T. The evaluation on the process capability index CL for exponentiated Frech\u2014Et lifetime product under progressive type I interval censoring. Symmetry 2021, 13, 1032. [CrossRef] 13. Alotaibi, R.; Rezk, H.; Dey, S.; Okasha, H. Bayesian estimation for Dagum distribution based on progressive type I interval censoring. PLoS ONE 2021, 16, e0252556. [CrossRef] [PubMed] 14. Wu, S.J.; Chang, C.T.; Liao, K.J.; Huang, S.R. Planning of progressive group-censoring life tests with cost considerations. J. Appl. Stat. 2008, 35, 1293\u20131304. [CrossRef] 15. Lin, C.T.; Wu, S.J.; Balakrishnan, N. Planning life tests with progressively type-I interval censored data from the lognormal distribution. J. Stat. Plan. Infer. 2009, 139, 54\u201361. [CrossRef] 16. Lin, C.T.; Balakrishnan, N.; Wu, S.J. Planning life tests based on progressively type-I grouped censored data from the Weibull distribution. Comm. Statist. Simul. Comput. 2011, 40, 574\u2013595 [CrossRef] 17. Roy, S.; Pradhan, B. Bayesian optimum life testing plans under progressive type I interval censoring scheme. Quality Reliab. Eng. Int. 2017, 33, 2727\u20132737. [CrossRef] 18. Budhiraja, S.; Pradhan, B. Optimum reliability acceptance sampling plans under progressive type-I interval censoring with random removal using a cost model. J. Appl. Stat. 2019, 46, 1492\u20131517. [CrossRef] 19. Roy, S.; Pradhan, B. Bayesian C-optimal life testing plans under progressive type-I interval censoring scheme. Appl. Math. Model 2019, 70, 299\u2013314. [CrossRef] 20. Wu, S.F.; Liu, T.H.; Lai, Y.H.; Chang, W.T. A study on the experimental design for the lifetime performance index of rayleigh lifetime distribution under progressive type I interval censoring. Mathematics 2022, 10, 517. [CrossRef] 21. Chaloner, K.; Verdinelli, I. Bayesian experimental design: A review. Statist. Sci. 1995, 10, 273\u2013304. [CrossRef] 22. Atkinson, A.C.; Donev, A.N.; Tobias, R.D. Optimum Experimental Designs with SAS; Oxford University Press: Oxford, UK, 2007. 23. Yue, R.X.; Zhou, X.D. Robust integer-valued designs for linear random intercept models. Commun. Stat. Theory Methods 2018, 47, 4338\u20134354. [CrossRef] 24. Pan, R.; Yang, T. Design and evaluation of accelerated life testing plans with dual objectives. J. Stat. Comput. Simul. 2014, 46, 114\u2013126. [CrossRef] 25. Bhattacharya, R.; Saha, B.N.; Far\u00edas, G.G.; Balakrishnan, N. Multi-criteria-based optimal life-testing plans under hybrid censoring scheme. TEST 2020, 29, 430\u2013453. [CrossRef] 26. Kundu, D. Bayesian inference and life testing plan for the Weibull distribution in presence of progressive censoring. Technometrics 2008, 50, 144\u2013154. [CrossRef] 27. Chernoff, H. Locally optimum designs for estimating parameters. Ann. Math. Statist. 1953, 24, 586\u2013602. [CrossRef] 28. Cook, R.D.; Wong, W.K. On the equivalence of constrained and compound designs. J. Am. Statist. Assoc. 1994, 89, 687\u2013692. [CrossRef] 29. Foo, L.K.; Duffull, S. Methods of robust design of nonlinear models with an application to pharmacokinetics. J. Biopharm. Stat. 2010, 20, 886\u2013902. [CrossRef] 30. Eberhart, R.; Kennedy, J. New optimizer using particle swarm theory. In Proceedings of the Sixth International Symposium on Micro Machine and Human Science, Nagoya, Japan, 4\u20136 October 1995; pp. 39\u201343. 31. Poli, R.; Kennedy, J.; Blackwell, T. Particle swarm optimization an overview. Swarm. Intell. 2007, 1, 33\u201357. [CrossRef] 32. Ruidas, S.; Seikh, M.R.; Nayak, P.K. A production inventory model with interval-valued carbon emission parameters under price-sensitive demand. Comput. Ind. Eng. 2021, 154, 107154. [CrossRef] 33. Ruidas, S.; Seikh, M.R.; Nayak, P.K. Application of particle swarm optimization technique in an interval-valued EPQ model. In\nMeta-Heuristic Optimization Techniques: Applications in Engineering; Kumar, A., Pant, S., Ram, M., Yadav, O., Eds.; De Gruyter: Berlin, Germany; Boston, MA, USA, 2022; pp. 51\u201378.\n34. Chen, R.B.; Chen, P.Y.; Wong, W.K. Standardized maximin D optimal designs for pharmacological models via particle swarm optimization techniques. Chemom. Intell. Lab. Syst. 2018, 169, 79\u201386. [CrossRef] 35. Zhou, X.D.; Wang, Y.J.; Yue, R.X. Robust population designs for longitudinal linear regression model with a random intercept. Comput. Stat. 2018, 33, 903\u2013931. [CrossRef] 36. Liu, X.; Yue, R.X.; Zhang, Z.Z.; Wong, K.W. G-optimal designs for hierarchical linear models: An equivalence theorem and a nature-inspired meta-heuristic algorithm. Soft Comput. 2021, 25, 13549\u201313565. [CrossRef] [PubMed] 37. Carbone, P.P.; Kellerhouse, L.E.; Gehan, E.A. Plasmacytic myeloma: A study of the relationship of survival to various clinical manifestations and anomalous protein type in 112 patients. Am. J. Med. 1967, 42, 937\u2013948. [CrossRef] 38. Chen, P.; Ye, Z.S. Approximate Statistical Limits for a Gamma Distribution. J. Qual. Technol. 2017, 49, 64\u201377. [CrossRef] 39. Chen, P.; Ye, Z.S. Estimation of Field Reliability Based on Aggregate Lifetime Data. Technometrics 2017, 59, 115\u2013125. [CrossRef] 40. Xu, A.; Zhou, S.; Tang, Y. A unified model for system reliability evaluation under dynamic operating conditions. IEEE Trans. Reliab. 2020, 70, 65\u201372. [CrossRef] 41. Luo, C.; Shen, L.; Xu, A. Modelling and estimation of system reliability under dynamic operating environments and lifetime\nordering constraints. Reliab. Eng. Syst. Saf. 2022, 218, 108136. [CrossRef]\n42. J\u00e4ntschi, L. A test detecting the outliers for continuous distributions based on the cumulative distribution function of the data being tested. Symmetry 2019, 11, 835. [CrossRef] 43. Zhao, X.J.; Pan, R.; del Castillo, E.; Xie, M. An adaptive two-stage Bayesian model averaging approach to planning and analyzing accelerated life tests under model uncertainty. J. Qual. Technol. 2019, 51, 181\u2013197. [CrossRef] 44. Wu, S.J.; Huang, S.R. Optimal progressive interval censoring plan under accelerated life test with limited budget. J. Stat. Comput. Simul. 2019, 89, 3241\u20133257. [CrossRef] 45. Hu, J.; Chen, P. Predictive maintenance of systems subject to hard failure based on proportional hazards model. Reliab. Eng. Syst. Saf. 2020, 196, 106707. [CrossRef]"
        }
    ],
    "title": "Robust Optimum Life-Testing Plans under Progressive Type-I Interval Censoring Schemes with Cost Constraint",
    "year": 2022
}