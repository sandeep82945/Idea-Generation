Due to the prevalence of scale variance in nature images, we propose to use image scale as a self-supervised signal for Masked Image Modeling (MIM). Our method involves selecting random patches from the input image and downsampling them to a low-resolution format. Our framework utilizes the latest advances in superresolution (SR) to design the prediction head, which reconstructs the input from low-resolution clues and other patches. After 400 epochs of pre-training, our Super Resolution Masked Autoencoders (SRMAE) get an accuracy of 82.1% on the ImageNet-1K task. Image scale signal also allows our SRMAE to capture scale invariance representation. For the very low resolution (VLR) recognition task, our model achieves the best performance, surpassing DeriveNet by 1.3%. Our method also achieves an accuracy of 74.84% on the task of recognizing low-resolution facial expressions, surpassing the current state-of-the-art FMD by 9.48%. LR facial expression classification on CK+ dataset: In the experimental setup, we discovered that the CK+ dataset had limited data. Thus, training the model using CK+ dataset alone may not produce sophisticated results. We employed the model that was pre-trained for 400 epochs on the ImageNet-1K[13] dataset and fine-tuned it on the CK+ dataset. According to the results presented in 3, our model attained a top-1 accuracy of 94.21% on this dataset, which is within 1.4% of the state-of-the-art performance. We conducted an unfair comparison with MAE, due to the difference in the pre-training process. MAE employed a ViT-B model that was pre-trained for 1600 epochs and fine-tuned it for the downstream task, resulting in a top-1 accuracy of 95.04%. LR Facial Expression Classification on RAF-DB dataset: The size of the RAF-DB dataset is still relatively small. We also use the model that was pre-trained for 400 epochs on the ImageNet-1K dataset. We fine-tuned it on the RAF-DB dataset. According to the results presented in 3, the model’s performance on the RAF-DB dataset was found to be 5% lower than that of the state-of-the-art models. We also conducted an unfair comparison with MAE dut to MAE employed a model that was pre-trained for 1600 epochs. The results in 3 demonstrated that MAE yielded good results on the RAF-DB dataset. Therefore, we attribute our relatively lower performance to the inadequate pre-training of our model. If more comprehensive pre-training is undertaken, we anticipate that our results may significantly improve. LR Facial Expression Classification on ExpW dataset: The ExpW dataset is one of the largest databases consisting of facial expressions. Hence, we forewent the use of supplementary datasets [13] and exclusively employed the ExpW dataset for pre-training, followed by fine-tuning during downstream tasks. Our model yielded a top-1 classification accuracy of 74.84%, as per the results presented in 3. This accuracy is 9.48% higher than that of the previous state-of-the-art model, indicative of a significant improvement in our methodology. Additionally, we conducted a fair comparison with MAE on this dataset, without using any extra pre-training datasets. Our experimental results revealed that our model achieved a top-1 accuracy of 74.53% on this dataset, which is marginally below that of SRMAE by 0.3%. SRMAE exhibits strong robustness in low-resolution tasks, particularly in larger datasets where the advantages of self-supervised learning can be fully utilized, leading to excellent performance. Moreover, SRMAE improves the MIM model’s learning of low-resolution image features under similar experimental conditions by using scale as the self-supervisory signal, which renders it more suitable for low-resolution tasks compared to MAE. 5 conclusion and discussion We present a robust and effective MIM framework, named SRMAE, that is capable of learning scale-invariant deep representation and apply it to visual tasks of different scales. TOur method leverages scale as a self-supervised signal to facilitate resolution restoration, which replaces image reconstruction and adapts easily to scale-varied tasks. We have achieved extensive results in tasks such as high-resolution image classification and low-resolution object recognition. To the best of our knowledge, this is the first model that achieves close to SOTA results for high-resolution image classification and low-resolution object recognition.