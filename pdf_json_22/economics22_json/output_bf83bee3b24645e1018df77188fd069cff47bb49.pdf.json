{
    "abstractText": "Problem definition: We consider the problem of dynamic pricing of a product in the presence of featuredependent price sensitivity. Developing practical algorithms that can estimate price elasticities robustly, especially when information about no purchases (losses) is not available, to drive such automated pricing systems is a challenge faced by many industries. Methodology: Based on the Poisson semi-parametric approach, we construct a flexible yet interpretable demand model where the price related part is parametric while the remaining (nuisance) part of the model is non-parametric and can be modeled via sophisticated machine learning (ML) techniques. The estimation of price-sensitivity parameters of this model via direct onestage regression techniques may lead to biased estimates due to regularization. To address this concern, we propose a two-stage estimation methodology which makes the estimation of the price-sensitivity parameters robust to biases in the estimators of the nuisance parameters of the model. In the first-stage we construct estimators of observed purchases and prices given the feature vector using sophisticated ML estimators such as deep neural networks. Utilizing the estimators from the first-stage, in the second-stage we leverage a Bayesian dynamic generalized linear model to estimate the price-sensitivity parameters. Results: We test the performance of the proposed estimation schemes on simulated and real sales transaction data from the Airline industry. Our numerical studies demonstrate that our proposed two-stage approach reduces the estimation error in price-sensitivity parameters from 25% to 4% in realistic simulation settings. Managerial implications: The two-stage estimation techniques proposed in this work allows practitioners to leverage modern ML techniques to robustly estimate price-sensitivities while still maintaining interpretability and allowing ease of validation of its various constituent parts.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ravi Kumar"
        },
        {
            "affiliations": [],
            "name": "Shahin Boluki"
        },
        {
            "affiliations": [],
            "name": "Karl Isler"
        },
        {
            "affiliations": [],
            "name": "Jonas Rauch"
        },
        {
            "affiliations": [],
            "name": "Darius Walczak"
        }
    ],
    "id": "SP:a3fe8350f6a3d39f51e213735ae51698d520193b",
    "references": [
        {
            "authors": [
                "J. Hua",
                "L. Yan",
                "H. Xu"
            ],
            "title": "and C",
            "venue": "Yang, \u201cMarkdowns in e-commerce fresh retail: A counterfactual prediction and multi-period optimization approach,\u201d in Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, ser. KDD \u201921. New York, NY, USA: Association for Computing Machinery",
            "year": 2021
        },
        {
            "authors": [
                "P. Ye",
                "J. Qian",
                "J. Chen",
                "C. hung Wu",
                "Y. Zhou",
                "S.D. Mars",
                "F. Yang",
                "L. Zhang"
            ],
            "title": "Customized regression model for airbnb dynamic pricing,",
            "venue": "Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, ser. KDD \u201918",
            "year": 2018
        },
        {
            "authors": [
                "H. Zou",
                "P. Cui",
                "B. Li",
                "Z. Shen",
                "J. Ma",
                "H. Yang"
            ],
            "title": "and Y",
            "venue": "He, \u201cCounterfactual prediction for bundle treatment,\u201d Advances in Neural Information Processing Systems, vol. 33",
            "year": 2020
        },
        {
            "authors": [
                "U. Shalit",
                "F.D. Johansson"
            ],
            "title": "and D",
            "venue": "Sontag, \u201cEstimating individual treatment effect: generalization bounds and algorithms,\u201d in International Conference on Machine Learning. PMLR",
            "year": 2017
        },
        {
            "authors": [
                "G.W.S. Athey"
            ],
            "title": "Imbens, \u201cMachine learning methods that economists should know about,",
            "venue": "Annual Review of Economics,",
            "year": 2019
        },
        {
            "authors": [
                "B. Vinod"
            ],
            "title": "The Evolution of Yield Management in the Airline Industry",
            "venue": "Springer",
            "year": 2021
        },
        {
            "authors": [
                "J.D. Angrist",
                "J.-S. Pischke"
            ],
            "title": "Mostly harmless econometrics",
            "venue": "Princeton, NJ: Princeton Univ. Press",
            "year": 2009
        },
        {
            "authors": [
                "A.V. den Boer"
            ],
            "title": "Dynamic pricing and learning: Historical origins, current research, and new directions,",
            "venue": "Surveys in Operations Research and Management Science,",
            "year": 2015
        },
        {
            "authors": [
                "M.C. Cohen",
                "I. Lobel"
            ],
            "title": "and R",
            "venue": "P. Leme, \u201cFeature-based dynamic pricing,\u201d in Proceedings of the 2016 ACM Conference on Economics and Computation, EC \u201916, Maastricht, The Netherlands, July 24-28, 2016, V. Conitzer, D. Bergemann, and Y. Chen, Eds. ACM",
            "year": 2016
        },
        {
            "authors": [
                "S. Qiang",
                "M. Bayati"
            ],
            "title": "Dynamic pricing with demand covariates,",
            "venue": "arXiv e-prints, p",
            "year": 2016
        },
        {
            "authors": [
                "A. Javanmard",
                "H. Nazerzadeh"
            ],
            "title": "Dynamic pricing in high-dimensions,",
            "venue": "Journal of Machine Learning Research (JMLR),",
            "year": 2019
        },
        {
            "authors": [
                "G.-Y. Ban",
                "N.B. Keskin"
            ],
            "title": "Personalized Dynamic Pricing with Machine Learning: High-Dimensional Features and Heterogeneous Elasticity,",
            "venue": "Management Science,",
            "year": 2021
        },
        {
            "authors": [
                "A.N. Elmachtoub",
                "V. Gupta"
            ],
            "title": "and M",
            "venue": "L. Hamilton, \u201cThe value of personalized pricing,\u201d Management Science, vol. 67, no. 10, pp. 6055\u20136070",
            "year": 2021
        },
        {
            "authors": [
                "O. Besbes",
                "A.J. Zeevi"
            ],
            "title": "Dynamic pricing without knowing the demand function: Risk bounds and near-optimal algorithms,",
            "venue": "Operations Research,",
            "year": 2009
        },
        {
            "authors": [
                "O. Besbes",
                "A. Zeevi"
            ],
            "title": "On the (surprising) sufficiency of linear models for dynamic pricing with demand learning,",
            "year": 2015
        },
        {
            "authors": [
                "G. Perakis",
                "D. Singhvi"
            ],
            "title": "Dynamic pricing with unknown non-parametric demand and limited price changes,",
            "venue": "Available at SSRN: https://ssrn.com/abstract=3336949 or http://dx.doi.org/10.2139/ssrn.3336949,",
            "year": 2019
        },
        {
            "authors": [
                "P.M. Robinson"
            ],
            "title": "Root-n-consistent semiparametric regression,",
            "venue": "p. 931,",
            "year": 1988
        },
        {
            "authors": [
                "W.K. Newey",
                "F. Hsieh"
            ],
            "title": "and J",
            "venue": "M. Robins, \u201cTwicing kernels and a small bias property of semiparametric estimators,\u201d [Wechselnde Verlagsorte], pp. 947\u2013962",
            "year": 2004
        },
        {
            "authors": [
                "V. Chernozhukov",
                "D. Chetverikov",
                "M. Demirer",
                "E. Duflo",
                "C. Hansen",
                "W. Newey"
            ],
            "title": "and J",
            "venue": "Robins, \u201cDouble/debiased machine learning for treatment and structural parameters,\u201d The Econometrics Journal, vol. 21, no. 1, pp. C1\u2013C68",
            "year": 2018
        },
        {
            "authors": [
                "J. Pearl"
            ],
            "title": "Causality",
            "venue": "Cambridge university press",
            "year": 2009
        },
        {
            "authors": [
                "W.K. Newey",
                "J.L. Powell"
            ],
            "title": "Instrumental variable estimation of nonparametric models,",
            "venue": "Econometrica, vol. 71,",
            "year": 2003
        },
        {
            "authors": [
                "J. Hartford",
                "G. Lewis",
                "K. Leyton-Brown"
            ],
            "title": "and M",
            "venue": "Taddy, \u201cDeep iv: A flexible approach for counterfactual prediction,\u201d in International Conference on Machine Learning. PMLR",
            "year": 2017
        },
        {
            "authors": [
                "J. Kmenta"
            ],
            "title": "Mostly harmless econometrics: An empiricist\u2019s companion,",
            "year": 2010
        },
        {
            "authors": [
                "J.D. Angrist",
                "G.W. Imbens"
            ],
            "title": "and D",
            "venue": "B. Rubin, \u201cIdentification of causal effects using instrumental variables,\u201d Journal of the American statistical Association, vol. 91, no. 434, pp. 444\u2013455",
            "year": 1996
        },
        {
            "authors": [
                "S. Darolles",
                "Y. Fan",
                "J.-P. Florens"
            ],
            "title": "and E",
            "venue": "Renault, \u201cNonparametric instrumental regression,\u201d Econometrica, vol. 79, no. 5, pp. 1541\u20131565",
            "year": 2011
        },
        {
            "authors": [
                "D.X. Chen"
            ],
            "title": "Pouzo, \u201cEstimation of nonparametric conditional moment models with possibly nonsmooth generalized residuals,",
            "venue": "Econometrica, vol. 80,",
            "year": 2012
        },
        {
            "authors": [
                "V. Semenova",
                "M. Goldman",
                "V. Chernozhukov"
            ],
            "title": "and M",
            "venue": "Taddy, \u201cEstimation and inference on heterogeneous treatment effects in high-dimensional dynamic panels,\u201d arXiv preprint arXiv:1712.09988",
            "year": 2017
        },
        {
            "authors": [
                "L. Mackey",
                "V. Syrgkanis"
            ],
            "title": "and I",
            "venue": "Zadik, \u201cOrthogonal machine learning: Power and limitations,\u201d in International Conference on Machine Learning. PMLR",
            "year": 2018
        },
        {
            "authors": [
                "M. Oprescu",
                "V. Syrgkanis"
            ],
            "title": "and Z",
            "venue": "S. Wu, \u201cOrthogonal random forest for causal inference,\u201d in International Conference on Machine Learning. PMLR",
            "year": 2019
        },
        {
            "authors": [
                "D. Nekipelov",
                "V. Semenova"
            ],
            "title": "and V",
            "venue": "Syrgkanis, \u201cRegularised orthogonal machine learning for nonlinear semiparametric models,\u201d The Econometrics Journal, vol. 25, no. 1, pp. 233\u2013255",
            "year": 2022
        },
        {
            "authors": [
                "S. Athey",
                "J. Tibshirani"
            ],
            "title": "and S",
            "venue": "Wager, \u201cGeneralized random forests,\u201d The Annals of Statistics, vol. 47, no. 2, pp. 1148\u20131178",
            "year": 2019
        },
        {
            "authors": [
                "S. Wager",
                "S. Athey"
            ],
            "title": "Estimation and inference of heterogeneous treatment effects using random forests,",
            "venue": "Journal of the American Statistical Association,",
            "year": 2018
        },
        {
            "authors": [
                "D.P. Kingma",
                "M. Welling"
            ],
            "title": "Auto-encoding variational bayes,",
            "venue": "arXiv preprint arXiv:1312.6114,",
            "year": 2013
        },
        {
            "authors": [
                "D.J. Rezende",
                "S. Mohamed"
            ],
            "title": "and D",
            "venue": "Wierstra, \u201cStochastic backpropagation and approximate inference in deep generative models,\u201d in International conference on machine learning. PMLR",
            "year": 2014
        },
        {
            "authors": [
                "C. Louizos",
                "U. Shalit",
                "J. Mooij",
                "D. Sontag",
                "R. Zemel"
            ],
            "title": "and M",
            "venue": "Welling, \u201cCausal effect inference with deep latent-variable models,\u201d in Proceedings of the 31st International Conference on Neural Information Processing Systems",
            "year": 2017
        },
        {
            "authors": [
                "R.S. Sutton",
                "A.G. Barto"
            ],
            "title": "Reinforcement learning",
            "venue": "An introduction. Cambridge, MA: MIT Press",
            "year": 2018
        },
        {
            "authors": [
                "H.-T. Cheng",
                "L. Koc",
                "J. Harmsen",
                "T. Shaked",
                "T. Chandra",
                "H. Aradhye",
                "G. Anderson",
                "G. Corrado",
                "W. Chai",
                "M. Ispir",
                "R. Anil",
                "Z. Haque",
                "L. Hong",
                "V. Jain",
                "X. Liu"
            ],
            "title": "and H",
            "venue": "Shah, \u201cWide & deep learning for recommender systems,\u201d in Proceedings of the First Workshop on Deep Learning for Recommender Systems",
            "year": 2016
        },
        {
            "authors": [
                "J. Neyman"
            ],
            "title": "C (\u03b1) tests and their use,",
            "venue": "Sankhya\u0304: The Indian Journal of Statistics, Series A, pp",
            "year": 1979
        },
        {
            "authors": [
                "M. West",
                "J. Harrison"
            ],
            "title": "Bayesian forecasting and dynamic models",
            "venue": "Springer Science & Business Media",
            "year": 2006
        },
        {
            "authors": [
                "L.R. Berry",
                "M. West"
            ],
            "title": "Bayesian forecasting of many count-valued time series,",
            "venue": "Journal of Business & Economic Statistics,",
            "year": 2020
        },
        {
            "authors": [
                "M. Goldstein",
                "D. Wooff"
            ],
            "title": "Bayes linear statistics: Theory and methods",
            "venue": "John Wiley & Sons",
            "year": 2007
        },
        {
            "authors": [
                "L.R. Berry"
            ],
            "title": "Bayesian dynamic modeling and forecasting of count time series,",
            "venue": "Ph.D. dissertation, Duke University,",
            "year": 2019
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization,",
            "venue": "ICLR,",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "Keywords: Dynamic Pricing, Price Elasticity, Causal Inference, Machine Learning"
        },
        {
            "heading": "1 Introduction",
            "text": ""
        },
        {
            "heading": "1.1 Background and Overview",
            "text": "Many sellers are interested in improving their pricing decisions by dynamically adjusting prices of their products based on unique product features and other relevant information available at the time of request e.g., competing product prices, market indices etc. Automated dynamic pricing systems that can enable such functionality typically require estimates of customers\u2019 price-sensitivity at this granular level using historical sales transaction data. Although modern IT systems have made it possible to collect and use rich request-specific information from a shopping session, the estimation of price-sensitivity from such feature-rich historical observational data still remains a challenging task in many industries [1, 2]. This is especially true when the firm is only able to observe the total quantity sold for a product at a certain price in given time period but is unable to observe customer requests that did not result in a sale. Data about unsuccessful sale events at an individual request level is commonly referred to as loss or no-purchase information and if available can be utilized to estimate price-sensitivity by directly modeling purchase probabilities as a function of price and other relevant features via methods like parameterized logistic regression. Situations where loss information is not available are common in industries like Airlines, Car Rentals, and Hotels where a large fraction of sales occur via third-party websites or Online Travel Agents (OTA) such as Expedia, KAYAK, Google, Orbitz etc. Typically, a firm selling its products via these OTAs does not have direct visibility into\n\u2217corresponding author \u2020authors contributed equally\n1\nar X\niv :2\n20 5.\n01 87\n5v 2\n[ st\nat .M\nL ]\n1 9\nD ec\nloss information corresponding to a large fraction of individual requests on these platforms. In the absence of such loss information, one may estimate price-sensitivity by learning price-demand relationship (demand response modeling) using total sales for a product in given time period e.g., daily sales.\nIn this work we focus on learning such price-demand relationship given historical observations. This is akin to an observational study setup where the purchases are observed under the historical pricing policy deployed by the firm. A na\u0308\u0131ve approach can be to fit a supervised model with desired features (including price-related) and demand as the response variable. But this approach has several shortcomings. One of the shortcomings is related to the choice of the model. On one hand, parametric models that are popular in the literature provide an explainable and easy to use model with interpretability of their parameters, but are limited in terms of their flexibility and have strong assumptions about the generating process. On the other hand, modern machine learning (ML) approaches such as neural networks and gradient boosting, despite their high predictive power, do not easily lend themselves to constructing an interpretable framework for the inference task related to the price sensitivity estimation.\nAnother issue of directly fitting a supervised model is the presence of confounders, which are features that affect both demand and price. It is well known that omission of such features from the regression model may lead to biased estimates of price sensitivity parameters when estimated from observational data. In addition, although our main goal in this paper is not demand prediction, it is worth mentioning that a complex predictive model directly fitted on demand using price and additional features cannot generally make reasonable demand predictions for prices outside the range of observed values or prices different from the pricing policy underlying the observed data, as those regions are out of the training data distribution [3, 4]. Explainable and simpler parametric models based on micro-economic theory and domain specific knowledge may be less susceptible to this challenge compared with more complex approaches such as deep neural networks.\nOur approach for demand response modeling is thus based on a hybrid framework where we utilize modern ML-based non-parametric techniques such as deep neural networks to make an observational baseline prediction of both price and demand, and then combine it with a parametric approach to estimate the causal relationship between deviations of price and demand from this baseline. To this end, we build upon recent advances in the area of causal inference and semi-parametric regression in econometrics [5] and employ related ideas to construct robust price-sensitivity estimators using Poisson semi-parametric modeling. Moreover, by utilizing variational Bayesian approach for updating the model parameters in an online fashion, this approach is compute and storage efficient from a practical implementation perspective."
        },
        {
            "heading": "1.2 Pricing in Airline Industry and Challenges",
            "text": "In the airline dynamic pricing application motivating this work, a product being priced is typically an itinerary defined by specific route (Origin, Destination and Path), trip type (round trip, one way, multi-city etc), date and time of departure. Moreover, airlines typically differentiate products by compartment (economy, economy-premier, business, first etc.) and associated privileges and restriction e.g., change-related fees, upgrade eligibility, baggage allowance etc. Additional trip-related features are also used to differentiate customer price-sensitivity, these may include duration of stay at the destination, advance purchase restrictions, departure day of week, and number of layovers.\nAirline demand is significantly impacted by yearly seasonal patterns; for example often there is more demand in summer months due to school holidays. Moreover, special events (HSE) such as conferences in the origin or destination city also have a major impact on demand. Demand patterns also vary over the booking horizon of an itinerary. Most airlines allow the booking process to start around one year before the departure date. The pattern of demand over this booking horizon can show significant variation due to the fact that leisure customers, who represent a large fraction of demand, are highly price-sensitive, and book their trips early while business travelers with higher willingness-to-pay (WTP) may book their trip much later. Therefore, causal inference of price-sensitivity parameters via price-demand relationships requires inclusion of features to control for yearly seasonality, booking days prior and HSEs in the model.\nThe competitive landscape that the airline is operating in also plays an important role in determining its demand. On most routes there are multiple airlines offering services. The set of competing products that may impact an itinerary\u2019s demand are not only the similar (and relevant) itineraries offered by a competing airline but also other products for the same origin-destination pair offered by airline itself. Moreover, quality indicators such as on-time performance or rating of in-flight services could also be correlated to price-sensitivity.\nUnlike many scenarios related to e-commerce setting where the inventory costs for the product being sold are minimal due to supply being relatively elastic, airlines have to deal with fixed supply of seat inventory on flights in their network. Any seat not sold by the departure date brings no revenue and gets wasted i.e., the inventory is perishable. To deal with the fixed and perishable inventory, airlines employ sophisticated\nRevenue Management (RM) systems. Prices generated by an airline for an itinerary are the product of complex interactions between the RM system output and further refinements done via pricing rules, also known as fare rules in the airline industry. Airline RM systems work at a higher (aggregated) level than the level at which an itinerary is priced. For example, regardless of whether an RM system performs optimization at the leg or the origin-destination (OD) level, round-trip related dimensions e.g., duration of stay, are not explicitly considered in the RM system optimization process. RM systems determine the expected marginal opportunity costs involved in fulfilling the itinerary request by considering product prices at an aggregated level (fare classes), forecasts of future demand, remaining seat inventories and time until departure. These marginal opportunity costs, also known as bid prices in the airline industry, are used to determine availability of fare classes at the OD level. Further refinement to get to the level of itinerary price is handled via a complex set of fare rules tied to these fare classes [6]. Often these fare rules are not fully data-driven based on an empirical understanding of customers\u2019 price-sensitivities, but rely to a large extent on experience of analysts and managers in the airline\u2019s pricing departments.\nIn this work, we focus on developing more data-driven approaches to refine prices given the aggregate level marginal opportunity costs (bid prices) computed by the RM system. In particular, we assume that the firm has an RM system to perform finite-horizon network level optimization at an aggregate level and therefore it can compute the marginal opportunity costs, cit, associated with fulfilling an itinerary request i that it receives at time t. Given this cost and an m-dimensional feature-vector, Xit, associated with this itinerary request, the firm is interested in further refining the price to charge for this request. Features associated with the itinerary can include information about origin, destination, number of stops, point of sale, departure time, day of week, holiday indicators etc.\nTo enable such dynamic pricing policies, we develop robust methods for estimating the price-sensitivity of customer population for such featurized itineraries via demand response modeling. Note that this system for further price refinement is separate from the RM system and only takes as input marginal opportunity costs generated by the RM system i.e., the problem of interest in this work is to find an optimal price for the itinerary given that the marginal opportunity cost has already been computed by the RM system. The RM and pricing systems are implicitly connected as the bookings generated and prices associated with sales transactions are fed back into the RM system forecaster at an aggregate level to forecast class level demands and fares used for network optimization. We assume that the firm takes into consideration some consistency requirements between the two systems while generating inputs for the RM system e.g., by appropriately mapping booking and price transactions to aggregated level products (classes) used in the RM system, prorating fares from round-trip to half-return level etc. This interaction between the RM and Pricing systems although important are beyond the scope of this work and here we solely focus on the price sensitivity estimation problem.\nGiven the complex RM system and pricing methods used by the airline, the price offered for an itinerary is correlated with many of the features we have discussed earlier in this section. What makes estimating price-sensitivity parameters via demand response modeling challenging is that the demand for an itinerary is also correlated with many of the same features that impact its price. For example, higher demand in summer months leads to higher prices due to the opportunity costs (or bid prices) for that time period being higher. Such features that affect both the price (treatment variable) and sales (outcome variable) are known in econometrics literature as confounders. If the confounders are not identified and included in the model i.e., they are not controlled for, a na\u0308\u0131ve estimation of price-sensitivity coefficients will be biased due to the so-called \u201comitted variable bias\u201d [7]. This bias problem cannot be solved just by using more sophisticated ML based estimators. Instead, one would need to rely on Instrumental Variable (IV) techniques or conduct randomized pricing experiments by assigning randomly chosen prices to itinerary requests [7].\nRandomized pricing-based studies to estimate customers\u2019 price-sensitivity in the airline industry may also not be possible. The main reason is that such experiments could be perceived to be quite costly in the short-term because of using \u201cnon-optimal\u201d pricing policy and fear of losing revenue. Besides, if two booking requests with the same features are offered randomly different prices, the passengers may try to get around the randomization by trying several times to get a lower price. Even worse, the randomization approach can be perceived as unfair and dishonest.\nGiven these challenges, industries like airlines have found it difficult to implement a robust framework for automated dynamic pricing. The current state of affairs has necessitated the use of complex rules-based pricing systems as the de facto solution to dynamic pricing in this industry. In our view, sophisticated ML techniques by themselves cannot solve this problem. However, combining these techniques with the recent advances in the area of causal inference allows for a more data-driven solution to this problem."
        },
        {
            "heading": "1.3 Related Work",
            "text": "This work is related to the literature on dynamic pricing in the presence of contextual features, and the literature on causal inference in the presence of treatment heterogeneity with applications to price elasticity estimation.\nConstructing price-demand relationships for goods has a long history in economics, specifically in macroeconomic theories related to the study of supply and demand. The use of demand response modeling in the more applied area of dynamic pricing via maximizing profit or revenue functions is relatively more recent but has already lead to a substantial amount of literature. The survey paper by [8] provides an extensive overview of the dynamic pricing and learning literature. The majority of the work in this area focuses on parametric models, where the functional form of the demand function is assumed to be known. This includes more recent works on dynamic pricing in the presence of contextual features [9, 10, 11, 12, 13]. There is also some work in the area of non-parametric models which do not assume a known functional form for the demand model, see for example [14, 15] and [16]. However, most of these works have not focused on robust estimators for price-sensitivity from the causal inference perspective in the presence of many confounding variables, a situation common in industries like Airlines. There has also been work on semi-parametric models especially in the econometrics literature [17, 18]. These models assume a parametric (often linear) structure for treatment effect and a non-parametric structure for the remaining part of the model. However, most of this line of work has focused on additive noise structure for the model of interest and results for demand models using discrete distributions like Poisson or Negative Binomial has been largely lacking. Moreover, there are new challenges related to regularization induced bias in the estimation of parameters of interest if the non-parametric part is modeled using modern ML techniques [19].\nFor estimating treatment effects e.g., price sensitivities, Instrumental Variable (IV) based two-stage estimation schemes are often used in the causal inference literature to reduce estimation bias [20, 21, 22, 23]. An IV is a variable that directly affects the treatment (e.g., price) but not the outcome (e.g., bookings), i.e., its effect on the outcome is only through the treatment. IVs help in estimating the causal relationship from regression models in the presence of endogenous regressors, for example due to omitted confounders. Two-stage least squares (2SLS) estimation [24] is one of the most widely known IV techniques which has a linear and homogeneous treatment effect assumption. In the first stage of 2SLS, the endogenous variable is regressed on the IVs to create a new latent variable, and in the second stage the endogenous variable is replaced by the new variable (prediction from the first stage model) in the main linear regression model of the outcome. Non-parametric IV frameworks have been developed for more general settings than the linear model [21, 25, 26, 22]. In [22], the authors train deep neural networks to model the distribution of treatment given the IVs and other features in the first stage and the outcome prediction model in the second stage. Although IV based frameworks are promising, identifying IVs itself is a challenging problem which limits their application.\nWith firms having access to richer data, it is possible to include most of the important confounders into the regression model. However, this results in a high-dimensional setting and may also require a more sophisticated regression model. For such settings, Double or Orthogonal machine learning (DML) is another line of causal inference methods that use a two-stage estimation process [19]. This approach assumes a partially linear model where the treatment effect is linear but other features are either high-dimensional (with respect to number of samples) and/or their effect on treatment and outcome is non-parametric. It combines sophisticated machine learning techniques for constructing estimators for the non-parametric part in the first-stage with a second stage estimation of the treatment effect based on Neyman-orthogonal moment equations for robust estimation of treatment effects. DML procedure can achieve a \u221a n-consistent estimator of the treatment effect under very weak conditions. [27] extend DML to a panel data setting with a highdimensional treatment effect and unobserved unit heterogeneity, but limit the relationship between features and treatment/outcome to be linear. Other extensions and variations of the DML framework are also available in the literature [28, 29]. Nevertheless, DML methods and its variants have practically been mostly applicable to partially linear regression models or setups with binary treatment. [30] is a recent work that proposes an Orthogonal ML approach for nonlinear semi-parametric models and is applicable to our problem setup.\nMachine learning methods such as random forests and neural networks have recently been used to build methods for estimating treatment effects and counterfactual prediction. Some recent works have proposed methods for estimating non-parametric heterogeneous treatment effects based on random forests [31, 32]. Other works have employed neural networks for learning treatment invariant representation of confounders to adjust the observational distribution [4], and variational autoencoders (VAE) [33, 34] for inferring unobserved confounders with proxies [35] or inferring latent factors of treatment and decorrelating them with confounders [3]. However, all of these works focus mainly on binary (or vector of binary) treatments. In contrast, our focus in this work is on a continuous treatment variable such as price with the response being modeled using discrete distributions such as Poisson with a non-linear demand-response function to model the price-demand relationship."
        },
        {
            "heading": "1.4 Overview of the Paper and Main Contributions",
            "text": "In this article, we consider a setting in which a firm can measure relevant confounders for estimating pricesensitivity. However, because the firm is dealing with a large number of features with complex interactions, fully parametric models for constructing demand response functions may not suffice. To address this situation, we formulate a Poisson semi-parametric demand response model with feature-dependent pricesensitivity. This model allows us to leverage the flexibility provided by modern ML techniques, while keeping the specification of the effect of price on demand interpretable. Pricing methodologies can have a large impact on the firm\u2019s revenue and for such critical tasks, interpretability vis-a-vis price sensitivity parameters is important as it allows a firm to qualitatively validate the inferred parameters easily by considering the individual effect of each feature. For example, parameters associated with day of week can be used to analyze relative impact of each day on price-sensitivity to see if weekdays have higher willingness-to-pay as compared to weekends on markets with predominant business traffic. Similarly, parameters associated with time of day can be checked to see if morning and evening flights have relatively higher willingness-to-pay as compared to afternoon flights on weekdays etc. We propose two approaches to construct estimators of price sensitivity parameters associated with this demand model.\nThe modeling and estimation aspects related to the Poisson semi-parametric model are not straightforward. To address that, we first develop a direct approach to implement this model using deep neural networks. The estimates for price-sensitivities can be directly obtained from the weights of one of the layers of the trained neural network. While this methodology is relatively easy to implement, it may be challenging to validate, thereby making it less feasible from a practical application perspective. Moreover, the estimates of price-sensitivities may be susceptible to bias since we simultaneously estimate the price-sensitivity parameters with other unknown parameters of the model and use regularization techniques to prevent overfitting.\nTo address some of the issues of the direct estimation approach described above, our main contribution involves development of a robust two-stage approach for estimating price-sensitivities by extending the ideas related to Double or Orthogonal machine learning [19] to a Poisson semi-parametric setting. In the first stage of the method, we leverage the predictive power of modern machine learning methodologies to build predictive models for price and demand conditional on other features. In the second stage, we utilize interpretable parametric models and employ dynamic Bayesian models with an efficient sequential learning scheme based on variational Bayes ideas and Laplace approximation. The Bayesian model is naturally equipped with uncertainty estimation, allows for encoding prior information, and exhibits robustness in our experiments. In addition, it is suitable for streaming data and works well in the presence of time-variation of parameters that may exist in practice.\nWe also discuss the related price optimization problem and how the uncertainty estimates related to pricesensitivities can be used for evaluating policies for price experimentation based on Reinforcement Learning (RL) techniques such as Upper Confidence Bound (UCB) etc. [36].\nTo compare the performance of the proposed methodologies, we conduct a simulation study and show that the two-stage construction leads to robust and more accurate estimators of price-sensitivity parameters when compared to the direct one-stage approach. We also conduct a numerical study using real data to qualitatively compare the performance of the two estimation approaches."
        },
        {
            "heading": "2 Modeling Perspective and Framework",
            "text": ""
        },
        {
            "heading": "2.1 Poisson Semi-parametric Model for Demand Response",
            "text": "In this section, we formally define the problem set-up in the dynamic pricing setting under consideration. Consider a selling horizon of T time periods, where for each t = 1, 2, . . . , T , the seller offers an itinerary i at price Pit. Assuming that customers arrive according to a Poisson process and considering an exponential form for the demand response model, the demand and observed prices are modeled as\nYit|Xit, Pit \u223c Pois(\u03bb(Pit;Xit,\u03b8, \u03c6)), log(\u03bb(Pit;Xit,\u03b8, \u03c6)) = Pit\u03b8TWit + \u03c6(Xit), (1) Pit|Xit = g(Xit) + it, E[ it|Xit] = 0. (2)\nHere we denote the number of observed purchases for this itinerary in time period t by Yit. The vector of controls, denoted by Xit \u2208 Rm, includes exogenous features like data related to the specific itinerary derived features or pre-specified transformations of this data (e.g., time seasonality basis functions, constant term etc.), and may also contain lags of Yit and Pit. Wit \u2208 Rd is the feature set related to the heterogeneity associated with the price-elasticity. Wit is based on a sub-vector of the observed data vector Xit; it includes an intercept term and any pre-specified transformation of raw features. \u03b8 \u2208 Rd is a vector of parameters associated with price-sensitivity. \u03c6(\u00b7) is a function associated with the total demand volume. To illustrate its role, note that if we set Pit = 0 in (1), the purchases will occur according to a Poisson process with\nmean exp(\u03c6(Xit))). As discussed earlier, the overall demand for a product could be influenced by a variety of factors, therefore \u03c6(\u00b7) could be non-linear, complex and high-dimensional. Given this model, our main objective is to estimate the price-sensitivity parameters \u03b8.\nIn (2), we have specified the dependence of price on the set of features Xit. Typically, with the RM and Pricing systems employed by the firm, the prices are based on marginal opportunity costs (bid prices) computed by solving a finite horizon optimization problem considering demand forecasts, capacities etc., and further refinement based on pricing rules employed by the firm. Therefore, the function g(\u00b7) in most practical scenarios will be complex and high-dimensional. Although (2) is not the main equation of interest, it is useful in elucidating the causal dependence between variables in the model and will also help us later in developing a robust two-stage estimation approach. While our main concern is to estimate the price sensitivity parameters \u03b8, we still need to estimate the additional unknown parameters of the model, ((\u03c6(\u00b7), g(\u00b7)), known in the econometrics parlance as the nuisance parameters. As compared to a fully parametric model such as the Poisson generalized linear model, which itself may lead to biased estimates of \u03b8 if the nuisance (volume) parameter is mis-specified due to linearity restriction, the semi-parametric model in (1) with a more flexible structure allows one to mitigate this problem while still being interpretable and amenable to efficient estimation approaches for the parameters of interest [17]."
        },
        {
            "heading": "3 Estimating Price-Sensitivity Parameters",
            "text": "Estimating the parameters of the Poisson semi-parametric model described in (1) can in practice be challenging. Ideally, one wants Xit to incorporate all the possible features and confounders (to control for them), including possible interactions and transformations. To alleviate the challenges related to complex feature engineering, it is beneficial to utilize sophisticated non-parametric ML models in constructing the estimators for the nuisance parameters, ((\u03c6(\u00b7), g(\u00b7)). We next propose two approaches based on these ideas for estimating the parameters of interest."
        },
        {
            "heading": "3.1 Direct Estimation using Wide and Deep Neural Networks",
            "text": "In the first approach, we model (1) using a deep neural network and directly estimate the parameters, \u03b8 and \u03c6(\u00b7), by training it on the historical sales transaction data. We would like to leverage the advantages of complex feature representations learned via the deep neural network for estimating the nuisance parameter \u03c6(\u00b7). However, since the dependency of price sensitivity on the features is log-linear, we need to consider a specific neural network architecture for this purpose. The Wide & Deep neural network architecture proposed by [37] provides a way to accomplish this by jointly training a wide linear part and a deep neural network. Although this architecture was originally proposed for recommender systems, we adapt it for the price-sensitivity estimation problem. Figure 1 shows this architecture for the Poisson semi-parametric model in (1).\nIn this architecture, the wide component is used to model the linear part of the form Pit\u03b8 TWit and the deep part is used to model the nuisance parameter \u03c6(Xit). These parts are combined to construct the log rate parameter and fed to a Probabilistic Poisson layer with Poisson negative log likelihood loss for joint training. The estimated parameters of interest, \u03b8\u0302, can be obtained from the weights of the layer constructing the log-rate parameter.\nThis method provides a direct way to construct an estimator for the Poisson semi-parametric model and can be implemented relatively easily using packages such as tensorflow or PyTorch. However, in a practical implementation, this approach can be challenging to work with since the output of the deep part is the nuisance parameter, \u03c6(\u00b7), which is not directly observable. Therefore, we cannot validate how well the deep part is learning this parameter. Moreover, to control for overfitting, a regularization approach (e.g., L1/L2 norm penalization of model parameters, early stopping, drop-out or batch normalization) is often necessary while training the neural network. But regularization may also introduce bias in the estimate of the nuisance parameter. In the absence of properties that make the estimation of price sensitivity parameters robust to errors in the nuisance parameter, any bias in learning the nuisance parameter will lead to bias in the estimate of price-sensitivity parameters \u03b8.\nAn alternative approach to the Wide & Deep architecture proposed above is to directly use a sophisticated ML estimator (e.g., deep neural networks or gradient boosted trees) for constructing the estimator for \u03c6(\u00b7) in (1) and estimate the price sensitivity parameters by an iterative scheme that alternates between estimating the parametric and non-parametric parts. We can start by initializing the estimator of \u03c6(\u00b7) to \u03c6\u03020(\u00b7) e.g., by randomly initializing the weights of a neural network. Given the initial estimate of \u03c6\u03020(\u00b7), we can estimate the price-sensitivity parameters, \u03b8\u03020, by maximum likelihood estimation. Given the estimated \u03b8\u03020 we can then create an updated estimate of \u03c6(\u00b7), \u03c6\u03021(\u00b7). This process continues until some convergence criteria is met for the price-sensitivity parameter. However, this approach not only suffers from the regularization related issue described above but due to its iterative nature can also become prohibitively computationally expensive for practical implementation."
        },
        {
            "heading": "3.2 Two-stage Estimation Approach",
            "text": "To address deficiencies of the estimation approaches discussed so far, we present a two-stage approach in this section. Given the data D = (Y,X, P ), the log-likelihood function for our original model in (1) can be written as\n`(D;\u03b8, \u03c6) = Y (P\u03b8TW + \u03c6(X))\u2212 exp(P\u03b8TW + \u03c6(X))\u2212 log(Y !). (3) Let \u0398 \u2282 Rd be the convex feasible space for price-sensitivity parameters and \u03a6 be the set of functions of\nX with finite mean squared error. The true values of the parameters of (1) are,\n(\u03b80, \u03c60) = arg max \u03b8\u2208\u0398,\u03c6\u2208\u03a6\nE[`(D;\u03b8, \u03c6)],\nwhere the expectation is taken w.r.t. the probability law governing the data D = (Y,X, P ). Since the log-likelihood function is concave, it satisfies the first order optimality condition given the true parameters (\u03b80, \u03c60)\n\u2202\n\u2202\u03b8 E[`(D;\u03b8, \u03c6)] \u2223\u2223\u2223 \u03b80,\u03c60 = 0.\nThe score function, \u03c8(D;\u03b8, \u03c6) = \u2202 \u2202\u03b8 E[`(D;\u03b8, \u03c6)], for estimating \u03b80 satisfies the Neyman orthogonality condition if the Gateaux derivative of the score function with respect to the the nuisance parameter \u03c6 at \u03c60 is 0 [19, 38] i.e.,\n\u2202\n\u2202r \u03c8(\u03b80, \u03c60 + r(\u03c6\u2212 \u03c60)) \u2223\u2223\u2223 r=0 = 0. (4)\nThe condition in 4 intuitively means that the score function for estimating the parameter of interest, \u03b8, is locally insensitive to small perturbations in the nuisance parameter around \u03c60. However, the score function, \u03c8(D;\u03b8, \u03c6), corresponding to our original Poisson semi-parametric model in (1) doesn\u2019t satisfy this orthogonality condition. Thus, we next describe a two-stage estimation method which leads to a reduced form model with score function that is indeed Neyman orthogonal."
        },
        {
            "heading": "3.2.1 Constructing Neyman Orthogonal Score Functions.",
            "text": "In [19] the authors proposed a two-stage estimation approach where in the first stage the nuisance parameters are estimated using sophisticated ML estimators and in the second stage the parameters of interest e.g., the price-sensitivity parameters in our case, are estimated. The second stage score function is constructed so that it satisfies the Neyman orthogonality condition (4). Most of the works on Neyman orthogonal\nscores e.g., [19, 27], consider linear or log-linear models with additive noise. For the Poisson model in our case with non-linear demand response, we construct the Neyman orthogonal scores approximately via the Concentrating-out approach proposed in [19]. This approach works on the principle that maximizing the expected maximum likelihood function with respect to the nuisance parameter, \u03c6, plugging that maximizer back in, and differentiating it with respect to the parameter of interest \u03b8 produces an orthogonal moment condition.\nFor this let \u03c6\u03b8 = arg max\n\u03c6\u2208\u03a6 E[`(D;\u03b8, \u03c6)],\nbe the \u201cconcentrated-out\u201d non-parametric part of the model. Note that there is a \u03c6\u03b8 for any \u03b8 \u2208 \u0398. For our model, this can be derived based on first order conditions as\n\u03c6\u03b8(X) = log(E[Y |X])\u2212 log(E[exp(P\u03b8TW )|X]) \u2248 log(E[Y |X])\u2212 \u03b8TWE[P |X],\u03b8 \u2208 \u0398, (5) where the approximation is based on a first order Taylor series expansion of the exponential function around E[P |X] (details in Section A.1 of the Online Appendix). For the price-sensitivity estimation task we are interested in, this approximation works reasonably well in practice where the term (\u03b8TW\u03c3 it)\n2 is small. Based on the approximate \u201cconcentrated-out\u201d non-parametric part, we can construct an alternate score\nfunction for estimating \u03b8 which is Neyman orthogonal [19] as\n\u03c8\u0304(D;\u03b8, \u03c6) = d`(D;\u03b8, \u03c6\u03b8) d\u03b8 . (6)\nFor the Poisson semi-parameteric model, based on (5) and (6), the Neyman orthogonal score is given by \u03c8\u0304(D;\u03b8, \u03c6\u03b8) = YW (P \u2212 E[P |X])\u2212 exp ( \u03b8TW (P \u2212 E[P |X]) + log(E[Y |X]) ) W (P \u2212 E[P |X]). (7)\nNote that the Neyman orthogonal score function for estimating \u03b8 in (7) corresponds to the reduced form model\nYit|Xit, Pit \u223c Pois ( exp((Pit \u2212 E[Pit|Xit])\u03b8TWit + log(E[Yit|Xit])) ) . (8)\nTherefore, instead of the original model, we can estimate the price-sensitivity parameters based on the reduced form equation (8). The subtraction of E[Pit|Xit] from Pit in (8) changes the price-related variable to have a \u201clocal\u201d interpretation, in which the parametric part locally governs changes in demand w.r.t. changes in price around the expected value for price given Xit."
        },
        {
            "heading": "3.2.2 Advantages of the Reduced Form Model.",
            "text": "Working with the reduced form version of the demand response model is advantageous for several reasons. Firstly, instead of the nuisance parameters \u03c6(\u00b7) and g(\u00b7) in (1), the nuisance parameters in (8) are expected purchases E[Yit|Xit] and expected price E[Pit|Xit]. These are directly observable quantities so we can deploy sophisticated ML techniques for constructing estimators Y\u0302it and P\u0302it for E[Yit|Xit] and E[Pit|Xit]; validation of their goodness of fit becomes much easier, enabling us to use standard techniques for model selection and hyperparameter tuning. Furthermore, learning P\u0302it is akin to learning the firm\u2019s historical pricing policy which can be useful in constructing reasonable price bounds for an automated dynamic pricing system in a practical deployment. Secondly, given estimates P\u0302it and Y\u0302it, the model in (8) is now a fully parametric Poisson generalized linear model, therefore it is easy to use batch or online estimators for estimating the price sensitivity parameters \u03b8. Finally, and most importantly, by approximately orthogonalizing the price with respect to X and removing the effect of confounding by subtracting P\u0302it from Pit in (8), the reduced form model provides robustness in the subsequent estimation of parameters \u03b8 against biases in the estimators for nuisance parameters [19]."
        },
        {
            "heading": "3.2.3 Two-stage Approach based on the Reduced Form.",
            "text": "Our overall scheme for constructing the estimator of price-sensitivity parameters \u03b8 based on the reduced form (8) comprises of two stages. In the first-stage, we create two estimators, P\u0302it and Y\u0302it, for g(Xit) = E[Pit|Xit] and E[Yit|Xit], respectively, using machine learning methods. For P\u0302it the response variable is the observed price and for Y\u0302it the response variable is the observed bookings. Given the estimates from the first stage, in the second stage we estimate parameters of a Poisson generalized linear model. The use of non-parametric ML-based methods for the estimators of P\u0302it and Y\u0302it allows us to bring more complex representation of the feature space Xit into the model while still being able to perform the second-stage estimation via a tractable and interpretable Poisson generalized linear model form.\nIn this work, we use neural networks for constructing the first-stage estimators and Bayesian dynamic generalized linear models (DGLM) for the second stage estimation as will be discussed in the following sections. The use of Bayesian methods in the second stage is mainly done to get online estimators of \u03b8 which are convenient for practical applications. Any concern regarding the regularization bias due to implicit regularization in Bayesian methods can be mitigated by considering prior distributions with high variance. Furthermore, the Bayesian approach also provides a principled way to quantify uncertainty on the estimate of price-sensitivity parameters which is not only useful for validating the model but can also drive reinforcement learning-based approaches for price optimization. Similar to [19, 27, 31], and [28], we use cross-fitting approach in our two-stage scheme to prevent overfitting, where the data is split into K-folds and for each fold the first stage predictions used in the second stage estimation are from first-stage models trained on other folds. As shown in [19] prevention of over-fitting in the construction of first stage estimators for E[Yit|Xit] and E[Pit|Xit] plays a key role in getting \u221a n-consistent two-stage estimators for \u03b8.\nIn (1), we assume a parametric form for treatment heterogeneity because of its interpretability. In practice, a domain expert may choose Wit considering the trade-off between flexibility and estimation precision. Wit can, for example, be a vector of binary variables encoding categorical features and other continuous features such as basis functions to capture seasonality etc. In our simulation experiments, we empirically see that our method provides elasticity estimates that are robust to minor misspecification in Wit when compared to simpler approaches. We will refer to this two-stage estimation approach as Two-stage-CO in the rest of this article."
        },
        {
            "heading": "3.2.4 Neural-networks based First Stage Prediction of Price and Bookings.",
            "text": "For real-world applications, we use neural networks to construct the estimator for E[Pit|Xit] in the first stage with the mean-squared error loss. Although in principle we can use other function approximators such as gradient boosting, neural networks can provide advantages beyond just the prediction task. One such advantage is the ability to encode categorical variables in our feature set via learnable embedding vectors. We can cluster categorical variables based on the closeness (euclidean norm) of embedding vectors e.g., derive groups or segments related to Origin-Destination pairs, Days of Weeks etc., with similar pricing behavior. Such inferred closeness of categories contains information about expert knowledge encoded in the pricing system, which then can be used to inform the choice of the structure of W and/or segmentation to help with data sparsity.\nWhen learning the first stage model for price, we leverage all the available data from different markets (Origin-Destination pairs) and add categorical variables representing each market to the feature set. This also requires careful scaling of the prices in different markets to a similar range so that they have a balanced influence on the training. By pooling all the data, we increase the sample size and also effectively add an implicit regularization to learn a more accurate model compared with training on each market separately. In addition, we embed the categorical features in a low-dimensional continuous space, where the embedding is learned jointly with other parameters of the neural network.\nWe also estimate E[Yit|Xit] using neural networks in the first stage. However, as the generating process for purchases is assumed be a count process, we train the model with a Poisson log-likelihood loss. Note that the choice of this loss function is still an approximation as although Yit|Xit, Pit has a Poisson distribution, the distribution of Yit|Xit is not Poisson. This approximation is mainly driven by the ease of implementing neural networks using standard packages such as Pytorch and tensorflow. Our numerical results in Sections 5 and 6 show that despite this approximation, the two-stage estimation approach performs well."
        },
        {
            "heading": "3.2.5 Bayesian Dynamic Generalized Linear Model for Second Stage Estimation of Price Sensitivity Parameters.",
            "text": "Given the predictions of the first-stage models, in the second stage, we adopt a Bayesian dynamic generalized linear model (DGLM) [39, 40] for estimating the price-sensitivity parameter \u03b8 in (5). DGLMs are based on the Bayesian state-space models with a sequential and efficient update procedure, which makes them suitable for applications with streaming data. Additionally, the Bayesian framework provides a principled way for quantifying uncertainty of parameter estimates, which is helpful for making more informed pricing decisions and utilizing RL techniques. Based on the estimates from the first stage, the Bayesian model for the second stage for (5) is:\nYit \u223c Pois(\u03bbit), log(\u03bbit) = (Pit \u2212 P\u0302it)\u03b8TWit + log(Y\u0302it) \u03b8 \u223c \u03c0(\u03b8). (9)\nHere, Y\u0302it is the cross-fitted prediction of purchases for the specific itinerary i from the first stage model and \u03c0(\u03b8) is the prior distribution over the parameters. The inference in the second stage is done independently\nfor each market on all itineraries belonging to that market. The inference procedure of the second stage can be completely parallelized for efficiency, which is extremely relevant for an implementation in a real-life system. For each market, W it is concatenation of an intercept, continuous features (e.g., Fourier basis for departure date seasonality, Splines related to days before departure, departure time etc) and one-hot encoded categorical variables (e.g., Day of Week, Point of Sale, Number of Connections etc.) as shown in (10).\nW it = [1, 0.5, 0.1, \u00b7 \u00b7 \u00b7 , 0.7\ufe38 \ufe37\ufe37 \ufe38 Cont. Vars. , 0, 0, \u00b7 \u00b7 \u00b7 , 1\ufe38 \ufe37\ufe37 \ufe38 Cat. Var. 1 , 0, \u00b7 \u00b7 \u00b7 , 1, 0\ufe38 \ufe37\ufe37 \ufe38 Cat. Var. 2 , \u00b7 \u00b7 \u00b7 , 0, 1, 0, \u00b7 \u00b7 \u00b7\ufe38 \ufe37\ufe37 \ufe38 Cat. Var. v ]T . (10)\nThus, by modeling heterogeneous price-sensitivity through an additive structure, the parameter \u03b8 in (9) is estimated for each market (origin-destination pair) using data for all its departure dates present in the historical transactions.\nThe update procedure in DGLMs is sequential and can be performed immediately after each new observation (daily bookings and price recorded for a market). The overall procedure is based on the combination of linear Bayes\u2019 theory [41] and a variational Bayes approach. We describe the inference procedure in detail in Section A.2 of the Online Appendix, where we also introduce a Laplace approximation based approach to further speed up the procedures of [42] and [39]. Through this inference procedure, we are able to update the posterior means and covariances of the parameters without requiring any assumptions on their exact distribution.\nA desirable property of the dynamic regression model is that it can be incrementally updated in an efficient manner in between the complete retraining of the first and second stage models. In our application, the updating schedule of the first stage and second stage models are different. Since the airlines pricing policies and the underlying model of latent variables are expected to be more stable, we update the first stage models, which have higher computational cost, with lower frequency compared with the second stage model. The second stage model is incrementally updated after each observation to have the most updated belief on \u03b8."
        },
        {
            "heading": "3.2.6 Alternative Approach to Neyman Orthogonal Scores via Partialling-out.",
            "text": "An alternative approach to construct Neyman orthogonal scores for semi-parametric generalized linear models has recently been proposed in [30]. In this approach, the authors first partial out [17] the effect of controls (X) from treatment (P ) inside the link function\u2019s argument of the GLM. Specifically, for the case of Poisson semi-parametric model (1), in this approach one starts with the following partialled-out form for the original model (1):\nYit|Xit, Pit \u223c Pois ( exp((Pit \u2212 E[Pit|Xit])\u03b8TWit + q(Xit)) ) . (11)\nwhere q(Xit) := E[Pit|Xit]\u03b8T0Wit + \u03c60(Xit) = E[log(E[Yit|Xit, Pit])|Xit]. The Neyman orthogonal score for the Poisson semi-parametric model based on [30] is:\n\u03c8\u0303(D;\u03b8, q) = YW (P \u2212 E[P |X])\u2212 exp\n( \u03b8TW (P \u2212 E[P |X]) + q(X) ) W (P \u2212 E[P |X])\nE[Y |X, P ] , (12)\nwhich corresponds to a weighted maximum likelihood based score function for (11) with the weights being 1 E[Y |X,P ] .\nTo utilize this score function, we first need to construct (ML) estimators for E[Pit|Xit] and E[Yit|Xit, Pit]. The predictions from the initial estimator for E[Yit|Xit, Pit], are used as weights and also as response variables to form an estimator for q(Xit), i.e. an estimator for E[log(E[Yit|Xit, Pit])|Xit]. After constructing these estimators, the parameter of interest, \u03b8, is found based on the score function in (12). Given the first-stage estimators, the solution to (12) can be easily found by fitting a regular weighted Poisson generalized linear model. We will refer to this partialled-out approach as Two-stage-PO and the concentrated-out approach in Section 3.2.1 as Two-stage-CO. It is worth noting that the partialling-out approach involves building (ML) estimators for E[Pit|Xit], E[Yit|Xit, Pit], and q(Xit), while the Two-stage-CO approach only needs (ML) estimators for E[Pit|Xit] and E[Yit|Xit]. Thus, the Two-stage-CO method can be significantly better in terms of computation time. Moreover, the inclusion of an additional estimator adds to the complexity of the process and requires increased effort in validating the goodness of fit of these estimators. We will compare the estimation performance of Two-stage-CO and Two-stage-PO via Simulation studies in Section 5."
        },
        {
            "heading": "4 Price Optimization",
            "text": "In this section we describe how to compute dynamic pricing policy given the estimates of the price-sensitivity parameters. The objective of the firm is to maximize the expected margin contribution given the associated\nper unit cost c from selling the product to a request during a shopping session. As noted earlier, for the airline pricing problem, the cost is the marginal opportunity cost or bid price associated with the seat inventory requested in the itinerary. Here we assume that the applicable marginal opportunity cost has already been computed by the airline\u2019s RM system by solving a separate finite horizon optimization problem and is available at the time of the request.\nLet \u00b5\u03b8 and \u03a3\u03b8 be the current estimate of mean and covariance associated with the price-sensitivity parameters \u03b8 at the time of request, and Pit := plbit \u2264 p \u2264 pubit be the feasible space of prices for the request. Let Rit(p; c,Xit,\u00b5\u03b8,\u03a3\u03b8) denote the expected margin contribution from an itinerary/product i requested at time t with associated feature vector Xit and cost c. The optimal price for the request is given by\nP \u2217it = arg max p\u2208Pit Rit(p; c,Xit,\u00b5\u03b8,\u03a3\u03b8). (13)\nIn Section 4.1 we discuss how we compute the dynamic prices in our experiments."
        },
        {
            "heading": "4.1 Computing Dynamic Prices",
            "text": "Given the posterior distribution of price sensitivity parameter, \u03c0\u2217(\u03b8), the expected margin contribution for the Poisson demand response model in (1) is:\nRit(p; c,Xit,\u00b5\u03b8,\u03a3\u03b8) = E\u03c0\u2217(\u03b8)[exp(p\u03b8 TW it)(p\u2212 c)]. (14)\nFinding the price based on maximizing the above expected margin contribution is akin to using a greedy policy for pricing. Since the Bayesian DGLM-based update procedure in 3.2.5 does not make distributional assumptions on \u03c0\u2217(\u03b8) and only yields the posterior mean and covariance of \u03b8, a closed-form expression of (14) is not available, and one can either resort to a plug-in approach using point estimates of the parameters or an approximation of the expectation. We discuss the plug-in approach that we use in our experiments in the following and two more approaches to approximate (14) in Section A.3.1 of the Online Appendix.\nUsing the posterior mean of the parameters, which is the optimal mean-squared error estimator, we can form a plug-in estimator of (14), where the corresponding margin contribution function is\nRit(p; c,Xit,\u00b5\u03b8) = exp(p\u00b5 T \u03b8W it)(p\u2212 c). (15)\nThe utility function in (15) results in a convex optimization problem that in fact has a closed-form solution\nP \u2217it = min{max{plbit, c\u2212 1\n\u00b5T\u03b8W it }, pubit }. (16)\nNote that if we employ frequentist methods for estimating \u03b8 e.g., the direct estimation approach in Section 3.1, we can use the same formula in (16) to compute the optimal price which maximizes the margin contribution by replacing \u00b5\u03b8 with the frequentist estimate \u03b8\u0302.\nSome other methods for constructing pricing policies such as Bayes greedy and Reinforcement Learning are discussed further in Section A.3 of the Online Appendix."
        },
        {
            "heading": "5 Simulation Experiments",
            "text": "In this section we present results from computational experiments on randomly generated data where we know the true ground demand model, i.e., we know the underlying price-demand relationship. The goal of this study is to analyze and compare the accuracy of the proposed estimators of price-sensitivity parameters based on simulated data."
        },
        {
            "heading": "5.1 Simple Example",
            "text": "We first perform a comparison on a simple setup with randomly generated data where we set the ground truth of the parameters. By comparing the estimates with the true parameters, we can evaluate the performance of our proposed estimation methods. For this simulation, the exogenous features, X \u2208 R10, are normally distributed, Xi \u223c N (0,\u03a3(\u03c1)), where \u03a3jk(\u03c1) = \u03c1|j\u2212k| and \u03c1 is set to 0.5. The dependence of price on the features is assumed to be linear and the demand data are generated according to a Poisson model:\nYi|Xi, Pi \u223c Pois ( exp(Pi(\u03b80 + 4\u2211 j=1 \u03b8jXij) + \u03c4 + \u03b7 T [XTi , X 2 i1, Xi2Xi3, Xi3Xi4, Xi4Xi5] T ) )\nPi = 50 + \u03b3 TXi + i, i \u223c N (0, \u03c3 = 9).\nHere, \u03c4 = 1.2, \u03b7 \u2208 R14 with all elements equal to 0.1, and \u03b3 \u2208 R10 with all elements equal to 3. As can be seen, the nuisance \u03c6(Xi) is a simple polynomial of degree 2. The vector of parameters of interest, \u03b8T = [\u03b80, \u03b81, \u03b82, \u03b83, \u03b84], is set as [-0.02,-0.005,-0.005,-0.005,-0.005].\nWe compare the performance of the direct estimation approach based on Wide and Deep architecture presented in Section 3.1, and the two-stage estimation approaches discussed in Section 3. For this example, the deep part of the Wide and Deep consists of one hidden layer with 50 units and ReLU activation followed by a layer with a single unit representing the nuisance parameter. Additionally, we use L2 regularization on hidden layer weights of the deep part, and in each run, we do early stopping and restore the best performing model state on a validation set, formed by randomly setting aside 20% of training data. These are all techniques commonly used when training neural networks on real data which can introduce some level of bias in parameter estimates. The model is trained using the Adam optimizer [43].\nFor the proposed two-stage methods, the reduced form model corresponding to the Two-stage-CO approach in Section 3.2.1 is:\nlog(E[Yi|Xi, Pi]) = (Pi \u2212 E[Pi|Xi])(\u03b80 + 4\u2211 j=1 \u03b8jXij) + log(E[Yi|Xi]).\nWe use ridge regression for estimating E[Pi|Xi] in the first stage. The first stage estimator for E[Yi|Xi] is constructed using a random forest regressor with mean-squared-error loss. All first stage model training and predictions are carried out by 5-fold cross-fitting. In this toy example, to isolate the effect of the reduced form model on estimation accuracy, we employ a frequentist Maximum Likelihood Estimation (MLE) approach for the Poisson GLM in the second stage estimation of the parameter of interest, \u03b8.\nFor the alternative Two-stage-PO estimation approach discussed in Section 3.2.6, in the first stage, we first fit E[Yi|Xi, Pi] with a random forest regressor with Poisson deviance loss, and then construct an estimator for E[log(E[Yi|Xi, Pi])|Xi] by training a random forest regressor with mean-squared-error loss on log of predictions of the previous random forest. Note that these steps are performed with 5-fold cross-fitting. To estimate the parameter of interest, in the second stage we use a frequentist weighted MLE approach for the Poisson GLM where samples are given weights inversely proportional to their first stage prediction of E[Yi|Xi, Pi].\nWe generate 10,000 samples from the assumed data generation model in each simulation run, and test the estimation accuracy of different methods on the generated data. The procedure of data generation and model testing is repeated ten times and the average results are shown in Table 1.\nThe two-stage methods result in significant improvement over the direct estimation procedure. Moreover, Two-stage-CO and Two-stage-PO show very close performance and the difference between them is not statistically significant."
        },
        {
            "heading": "5.2 Simulation in Airline Setting",
            "text": "To generate the sales transactions mimicking the complexities involved in real-life airline pricing, we model the interactions between RM and pricing with finite seat capacity. We set-up the simulation experiment considering a single-leg with a seat capacity of 100. The booking horizon for each departure date consists of 365 days grouped into 10 contiguous time periods called time frames (TF), such that the demand arrival rate within each TF is constant but varies across TFs. TF 0 is the furthest away from departure of a flight and TF 9 is closest to departure. The demand arrival is Poisson distributed with a rate that varies by week of year (WOY), booking period (TF), days of week (DOW) and point of sale (POS). Moreover, customer willingness-to-pay is exponentially distributed (WTP|\u03b8 \u223c exp(\u2212 1\n\u03b8 )) and the price-sensitivity parameters for\ncustomers (\u03b8) vary by POS and TF. With this setup, the ground demand response model governing demand on day t of the booking horizon for departure date i is\nYit|Xit = (WOY, DOW, POS, TF), Pit \u223c Pois ( exp((Pit \u2211 POS,TF \u03b8POS,TF1POS,TF + \u03c6(Xit) ) .\nThe true price-sensitivity parameters are shown in Table 2. Note that as discussed previously, for the exponential demand response function, the optimal price given price sensitivity parameter \u03b8 and cost c is\ngiven by\np\u2217|\u03b8, c = arg max{exp(p\u03b8)(p\u2212 c)} = c\u2212 1 \u03b8 .\nFor a given POS, TF combination, \u03b1 = \u2212 1 \u03b8\ndenotes the mean willingness-to-pay, which is also the optimal price when the cost is zero. These provide a more intuitive explanation of the price sensitivity parameters and therefore we have included them in the Table 2.\nThe RM system computes the marginal opportunity cost of seats (bid prices) considering the known demand arrival rates and price-sensitivity parameters using dynamic programming and the pricing system computes the final prices based on the relevant bid price and true price-sensitivity parameters i.e., the optimal pricing policy. To mimic idiosyncratic noise in prices observed in real life, we add normally distributed noise to final prices with mean zero and standard deviation of 20. These prices are then offered to a stream of arriving customers and the customer accepts or rejects the price based on their sampled willingness-to-pay (WTP|\u03b8 \u223c exp(\u2212 1\n\u03b8 )). The number of customers arriving in any time unit and their WTP are sampled according\nto the encoded ground truth price-demand model. This process creates the historical sales transaction data which includes daily bookings, daily average price and additional features useful for estimation namely, WOY, DOW, POS, TF. Given this scheme, the price generation process in the simulation is:\nPit|Xit = (WOY, DOW, POS, TF) = vit(sit;Xit)\u2212 1\n\u03b8POS,TF + it, it|Xit \u223c N (0, 20),\nwhere vit(x) denotes the optimal opportunity cost (bid price) computed via dynamic programming based optimization for the departure date i on day t given that we have sit seats remaining. Given the complex dependence of price on bid price, reservation process and price elasticity, the data generation process for bookings and prices resembles the model described in (1) and (2).\nUsing this simulation setup, we generate data corresponding to two years worth of daily flight departures (730 individual flights). Further analysis on the data generated under this simulation set-up can be found in the Online Appendix, Section A.4."
        },
        {
            "heading": "5.2.1 Price Sensitivity Parameter Estimation.",
            "text": "For the purpose of estimating the price-sensitivity parameters, we consider the following model for the log-rate of the Poisson demand response model\nlog(E[Yit|Xit, Pit]) = Pit(\u03b80 + #POS\u22121\u2211 pos=1 \u03b8pos1{POS=pos} + #TF\u22121\u2211 tf=1 \u03b8tf1{TF=tf}) + \u03c6(Xit). (17)\nNote that the ground demand response model used for the data generating process has a weak interaction in the price sensitivity parameters between POS and TF. Given some of the sparser entities, estimation benefits from a simpler linearly additive specification of price effects across POS and TF as shown in (17). Moreover, minor misspecifications of this type are common in practice, so the model in (17) will allow us to validate the robustness of the estimation method better. We use the direct neural network based technique and the two-stage approach to estimate the parameters of interest, \u03b8, for the above model next."
        },
        {
            "heading": "5.2.2 Direct Approach based on Wide and Deep Neural Network.",
            "text": "We first perform the direct estimation method proposed in Section 3.1. The features used in the model, Xit, include one-hot encoded categorical variables for POS, TF, and DOW, and four continuous features representing the yearly seasonality, which are Fourier series based on WOY with the first two frequencies and 52 weeks period. The deep part consists of a hidden layer with 50 units and ReLU activation followed by a layer with a single unit. The layer constructing the Poisson log rate forms Pit(\n\u2211#POS\u22121 pos=1 \u03b8pos1{POS=pos} +\u2211#TF\ntf=0 \u03b8tf1{TF=tf}) + \u03c6(Xit). In each run, we randomly set aside 15% of flights as validation set and train the model using the Adam optimizer [43] with early stopping."
        },
        {
            "heading": "5.2.3 Two-stage Approach.",
            "text": "As detailed in Section 3, we construct two-stage estimators for the price sensitivity parameters \u03b8 using both Two-stage-CO and Two-stage-PO methods.\nFor the Two-stage-CO approach detailed in Section 3.2.1, we use the following reduced form model based on (8) log(E[Yit|Xit, Pit]) = (Pit\u2212E[Pit|Xit])(\u03b80+ #POS\u22121\u2211 pos=1 \u03b8pos1{POS=pos}+ #TF\u22121\u2211 tf=1 \u03b8tf1{TF=tf})+log(E[Yit|Xit]).\n(18)\nThe first-stage estimators for E[Pit|Xit] and E[Yit|Xit] are constructed using a random forest regressor where the number of decision trees to be ensembled are fixed to 100 and use a mean squared error loss function. The features are the same as the ones used in the direct method explained in the previous Section. Moreover, to avoid overfitting, we use a cross-fitting approach and split the data into 5-folds with random shuffling. When estimating the second-stage model on each fold, we use the predictions from the first-stage models trained on other folds.\nFor the second-stage estimator we use the Bayesian Dynamic Generalized Linear Model approach described in Section 3.2.5. For the model parameters, \u03b8, we set the prior mean vector, \u00b5\u03b8 = 0, and a diagonal covariance matrix with all variance values set to 10 and the discount factors \u03b4\u03b8 = 1.0.\nThe alternative Two-stage-PO approach detailed in Section 3.2.6 we require three first-stage estimators. For the estimator of E[Yi|Xi, Pi] we utilize a random forest regressor with Poisson deviance loss, and then construct an estimator for E[log(E[Yi|Xi, Pi])|Xi] by training another random forest regressor with meansquared-error loss on log of predictions of the previous random forest. In addition the estimator for E[Pit|Xit] is constructed in a similar manner to that in the Two-stage-PO approach. In all the random forest regressors, the number of decision trees to be ensembled are fixed to 100. The second-stage estimation for the pricesensitivity parameters in the Two-stage-PO approach is performed using a frequentist maximum-likelihood estimation. We use a frequentist approach here since for the score function in (12) we need to perform a weighted maximum likelihood estimation using the estimates of 1E[Yi|Xi,Pi] as weights. Therefore, this weighting scheme cannot be implemented in a meaningful way via Bayesian modeling."
        },
        {
            "heading": "5.2.4 Comparison of Estimation Performance.",
            "text": "The final values of estimated price sensitivity parameters \u03b1\u0302 = \u2212 1 \u03b8\u0302\nafter updating over 104 week\u2019s worth of data for both direct and two-stage methods are shown in Table 2. The mean absolute percentage errors (MAPE) between the estimated and true price sensitivity parameters are also shown in Table 2. We also compute the weighted MAPE (wMAPE) metric where the weights are normalized to 1 based on relative bookings received for various POS/TF combinations i.e., we give higher weight to POS/TF combinations with more bookings. Since the direct approach\u2019s performance may change based on the train-validation split and different random initialization of the model, we perform 10 runs and for each run calculate the MAPE and wMAPE and report the means in Table 2. Note that the individual numbers for the direct approach estimates in Table 2 are from one run that had performance close to the mean (MAPE=23.814% and wMAPE=0.786%) and are used as a representative for illustration purposes.\nWe see that both the direct approach via wide and deep neural network and the two-stage approaches are able to estimate price-sensitivity parameters in a reasonable range and capture general trends like willingnessto-pay increasing as we get closer to departure and that for a given TF, WTP for POS 1 are higher than that for POS 0. However, the two-stage approaches have lower MAPE errors of 4.16% and 17.36% for Two-stage-CO and Two-stage-PO respectively, as compared to the Wide and Deep approach with an average MAPE error of 24.876%. From the wMAPE metric perspective, the Two-stage-CO approach is substantially better than the Two-stage-PO and the Direct approach which have very similar wMAPE error. These results also show the robustness of the two-stage approach to the minor mis-specification in the linear treatment effect model.\nWe note that the Two-stage-CO method provides substantial improvement in the estimates of price sensitivity parameters as compared to other approaches. The estimation for the Two-stage-CO was performed using Bayesian method while that for Two-stage-PO was done via frequentist approach. To rule out the possibility of difference in second stage estimation methodology leading to difference in performance of these two methods, we also performed the estimation for the Two-stage-CO via the same frequentist Poisson GLM approach. We can see from Table 3 provided in Section A.4 of the Online Appendix that the performance of Bayesian and frequentist estimates for the Two-stage-CO is very close. Therefore, the difference in the performance of these methods cannot be attributed just to the Bayesian approach utilized for the second stage.\nAlthough the Two-stage-CO and Two-stage-PO approaches performed similarly in simpler simulation setting, in more complex settings the added estimation required in the first-stage for the Two-stage-PO may compound errors and lead to deterioration of estimation performance. These results indicate that the Two-stage-CO is not only computationally efficient but also leads to excellent estimation performance in both simple and complex simulation settings. Therefore, for the numerical study in the next section we choose to perform analysis only on the Direct and the Two-stage-CO approach.\nThe Bayesian DGLM model in the Two-stage-CO approach updates the parameter estimates in an online fashion, Figure 2 shows the evolution of the posterior means of price sensitivity parameters (\u03b1\u0302 = 1\n\u00b5\u0302\u03b8 ) for\nvarious (POS, TF) combinations. We see that most of the parameters converge to a value close to true parameter value within 20 weeks worth of data. The sparser (POS, TF) combinations e.g., TF 8 take a\nlonger time to converge."
        },
        {
            "heading": "6 Numerical Study with Real Data",
            "text": "In this section, we present results of the proposed methodologies on an anonymized data set comprising of airline sales transactions using an offline estimation study. For real data, since the true price-sensitivity parameters are unknown, it is difficult to validate the quality of the estimators in a manner similar to the simulation study. Instead, we perform a qualitative study to determine the reasonability of the recommended optimal price based on the estimated price-sensitivity parameters by comparing these to the historical prices in the sales transaction data. We also discuss reasonability of trends and patterns observed in the pricesensitivity parameters vis-a-vis expected trends."
        },
        {
            "heading": "6.1 Data Description",
            "text": "The data comprises of historical transactions for a period of 100 weeks for four markets (Origin-Destination pair). The transaction data is for economy compartment and includes daily bookings and daily average price for each departure date for a 180 day booking horizon."
        },
        {
            "heading": "6.2 Estimation of Price Sensitivity Parameters",
            "text": ""
        },
        {
            "heading": "6.2.1 Features used for Demand Response Modeling.",
            "text": "In building the model for price sensitivity estimation, we considered several features including origin and destination, departure time, travel time. Furthermore, departure date related features like yearly seasonality via Fourier series representations based on departure day of year, departure day of week, holidays/special events and booking date related features like seasonality via Fourier series representations based on days before departure were also included. For estimating price sensitivity on the real data, we consider price\nsensitivity to be differentiated by POS, DOW, and Days before Departure (DBD) for each Origin-Destination pair. We use continuous basis functions for representing price sensitivity variation over DBDs."
        },
        {
            "heading": "6.2.2 Direct Wide and Deep Approach.",
            "text": "For direct estimation by the wide and deep method, we use a three layer architecture for the deep part. The features used in the model include the categorical features, and continuous features representing seasonality mentioned above. The wide and deep architecture is trained for each Origin-Destination separately."
        },
        {
            "heading": "6.2.3 Two-stage Approach.",
            "text": "We use neural networks with five layers for the first-stage prediction of price (P\u0302it) and demand (Y\u0302it). The models are trained via a cross-fitting approach, where the flights are split into 10-folds. We observed that by pooling data from other origin-destinations to learn a model for the conditional expected price, the prediction accuracy was improved by 5% for the four origin-destinations of interest, compared to using data only from one origin-destination.\nFor the second-stage estimator we use the Bayesian Dynamic Generalized Linear Model approach described in Section 3.2.5. For the model parameters, \u03b8, we set the prior mean vector, \u00b5\u03b8 = 0, and a diagonal covariance matrix with all variance values set to 2 and the discount factors \u03b4\u03b8 = 0.9995."
        },
        {
            "heading": "6.3 Results",
            "text": "Unlike the simulation setting, in the real data setting, we cannot compare the estimated price sensitivity parameters to some ground truth. Nevertheless, we can still make some qualitative statements by comparing the price recommended under various estimation schemes and the historical prices. Figure 3 shows the recommended price under Direct and Two-stage estimation approach in solid lines and historical prices in dashed lines over the booking horizon (days before departure) for four airline markets.\nThe historical and recommended prices are averaged over other dimensions like departure dates. Note that, if the estimate of the price sensitivity parameter is \u03b1\u0302 = \u2212 1\n\u00b5\u0302T \u03b8\nW , then the optimal price given cost\nc is c + \u03b1\u0302. The appropriate cost to use in our setting is the marginal opportunity cost or the bid price computed by the RM system for the inventory position at the time of the booking request. We use the historical marginal opportunity costs stamped in the booking transactions for computing the recommended\nprice corresponding to the price sensitivities estimated with Direct Wide and Deep Neural Network and the Two-stage-CO methods.\nThe left panel in Figure 3 shows the evolution of price recommendations based on price-sensitivities estimated using direct estimation approach. We see from these figures, that the recommended prices from the direct approach increase as we go closer to departure on all markets. However, we observe that the recommended prices are much higher than the historical prices for all the markets. Although we do not expect the prices in the historical transactions to be optimal, if a method generates prices considerably higher or lower than historical prices, it is very likely that the price sensitivity estimates are biased.\nThe right panel in Figure 3 shows the price recommendations based on price-sensitivities estimated using the two-stage-CO approach. We see that similar to the direct estimation approach, the recommended prices are increasing as we go closer to departure. However, unlike the direct estimation approach, the aggressiveness of this increase is much lower and more in line with historical prices. We also see that the price trend across different days of the week (DOW) is similar to that seen in the historical prices.\nFigure 4 shows the distribution of the difference between the recommended and historical prices (positive values indicate that the recommended price is higher than the historical price) for the Direct and Two-stage-CO approach. The distributions are plotted differently corresponding to transactions with positive bookings and those with zero bookings. The prices recommended by the Direct estimation method tend to be much higher than the historical prices (mode occurs at more positive value) for both booking and non-booking related transactions. The prices recommended by the Two-stage-CO approach tend to be closer to historical prices (mode is closer to zero). As with the Direct approach, for most of the markets, the mode of the empirical distribution for the Two-stage-CO method also occurs at slightly positive values indicating that the willingness-to-pay may be higher than that used during the historical period. Although qualitative in nature, these results do provide some evidence that the over-estimation of price-sensitivity parameters observed in the direct estimation approach has been corrected to a large extent by the two-stage estimation approach.\nAs discussed earlier, one of the motivations for keeping the specification of price sensitivity parameters\ninterpretable is that we can easily visualize how these parameters vary across various factors such as departure time, weak of year, days to departure etc. Figure 5 shows this analysis for Market 1. We can observe the following behaviors for this market:\n\u2022 Willingness-to-pay is higher for the morning and evening flight and lower for the flights with departure time during middle of the day. This behavior may indicate significant presence of business travellers.\n\u2022 Willingness-to-pay is higher for departure dates in April-May and also from September-October period while it is lowest for the December-February period.\n\u2022 For a given departure date, willingness-to-pay increases as we get closer to departure. This is the typical behavior observed in all the markets since leisure customers with higher willingness-to-pay book early and business travelers book later.\nThese observations are aligned with typical behavior on this market and generates further confidence in the estimates of price-sensitivity parameters from the Two-stage-CO methodology."
        },
        {
            "heading": "7 Conclusion and Future Research",
            "text": "In this paper, we introduced a Poisson semi-parametric demand response model with feature-dependent pricesensitivity to enable automated dynamic pricing. This model allows one to construct a more flexible model than a fully parametric one. In particular, we allow for the nuisance part to use modern ML techniques while keeping a log-linear specification for the effect of price on demand. After first proposing a direct modeling and estimation approach for this model via a deep neural network architecture, we then propose a two-stage estimation approach for price-sensitivity estimation based on ideas related to double/debiased ML approach and Neyman orthogonalization of score functions. This approach is advantageous not only from the perspective of practical implementation but also endows robustness to the estimates of price-sensitivity from biases in the estimation of the nuisance part. The second-stage inference of parameters driven by a variational Bayes approach leads to a computationally efficient sequential learning scheme and also enables the implementation of policies for smart price-experimentation based on RL techniques. The numerical studies performed based on simulated data as well a real data demonstrate the superior performance of the two-stage estimation approach as compared to the direct estimation approach.\nAlthough this work was applied to the setting of Airline pricing, we believe that the model and associated estimation techniques discussed in this paper are relevant for retail pricing problem in many industries. Furthermore, the general philosophy of combining traditional fully parametric models with more sophisticated ML techniques e.g., via semi-parametric models, to construct powerful frameworks for decision problems will be helpful beyond the pricing setting discussed in this work. In contrast, for thosesettings where interpretability is not an important concern, extension of the two-stage estimation techniques to fully non-parametric models for dynamic pricing is a promising direction for future research."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 Approximation Used for Neyman Orthogonalization\nHere we discuss the approximation used to derive (5) in 3.2.1 of the main text. Approximating exp(Pit\u03b8 TWit) via Taylor series around P\u0302it := E[Pit|Xit] we have,\nEPit|Xit [exp(Pit\u03b8 TWit)] = EPit|Xit [exp(P\u0302it\u03b8 TWit) + \u03b8 TWitexp(P\u0302it\u03b8 TWit)(Pit \u2212 P\u0302it) +O(Pit \u2212 P\u0302it)2]\n\u2248 exp(P\u0302it\u03b8TWit),\nwhere the approximation is derived by ignoring the second order term if (\u03b8TW\u03c3 it) 2, is small.\nA.2 Details of the Inference in the Second Stage Estimation of Price Sensitivity Parameters\nNoting that for airline booking data, time unit t is relative to the departure date/time of itinerary i, the same time units of different itineraries may not be concurrent. For example, t = 0 for itinerary i corresponds to the time unit farthest from departure and t = T corresponds to the time unit closest to departure. Let the data be sorted by the actual observation time based on i, t indices and the new observation time index be denoted by j. The order within the set of i, t indices with the same observation time unit, i.e., the order within concurrent observations from different itineraries, is assigned randomly. For the ease of exposition, in this section we replace i, t with j, and define Hj = (Pit \u2212 P\u0302it)Wit. Also, let Dj\u22121 represent the collection of all observations and features up to and including observation time j \u2212 1. The dynamic regression model is then defined as:\nlog(\u03bbj) = \u03b8 T j Hj + log(Y\u0302j),\nwhere \u03b8j = \u03b8j\u22121 + \u03c5j . (19)\nThe evolution noise \u03c5j has known mean E[\u03c5j |Dj\u22121] = 0 and covariance matrix Cov[\u03c5j |Dj\u22121] = \u03a5j , which is independent from \u03b8j\u22121 given Dj\u22121. Due to the sequential nature of the dynamic regression model, the posterior and estimate of the parameters \u03b8 are updated in an online fashion.\nGiven the posterior moments E[\u03b8|Dj ] = \u00b5j and Cov[\u03b8j |Dj ] = \u03a3j , the prior moments of \u03b8j+1 are induced by (19) which in turn leads to prior moments on log(\u03bbj+1), ej+1 := E[log(\u03bbj+1)|Dj ] = HTj+1\u00b5j + log(Y\u0302j+1) and lj+1 := Var[log(\u03bbj+1)|Dj ] = HTj+1(\u03a3j + \u03a5j+1)Hj+1. At this stage, a version of variational Bayes concept is applied to update the belief on \u03bbj+1. The prior distribution for \u03bbj+1 is assumed to be a Gamma distribution, Gamma(aj+1, bj+1), which is the conjugate prior for Poisson. The parameters of the prior are determined either based on moment matching [39] or minimizing forward or backward KL divergence [42] (for KL one needs to make an additional distributional assumption) via an iterative numerical solver. The posterior for \u03bbj+1 can then simply be computed as Gamma(aj+1 + Yj+1, bj+1 + 1). The moments of the posterior of log(\u03bbj+1) can be computed as qj+1 := E[log(\u03bbj+1)|Dj+1] = \u03c8(aj+1 + Yj+1) \u2212 log(bj+1 + 1) and \u03bdj+1 := Var[log(\u03bbj+1)|Dj+1] = \u03c8\u2032(aj+1 + Yj+1), where \u03c8(\u00b7) and \u03c8\u2032(\u00b7) are the digamma and trigamma functions, respectively. Using linear Bayes updating, the posterior moments E[\u03b8j+1|Dj+1] = \u00b5j+1 and Cov[\u03b8j+1|Dj+1] = \u03a3j+1 are given by\n\u00b5j+1 = \u00b5j + (\u03a3j + \u03a5j+1)Hj+1(qj+1 \u2212 ej+1)/lj+1, \u03a3j+1 = (\u03a3j + \u03a5j+1)\u2212 (\u03a3j + \u03a5j+1)(Hj+1HTj+1)(\u03a3j + \u03a5j+1)T (1\u2212 \u03bdj+1/lj+1)/lj+1.\nWe specify \u03a5j+1 based on the parsimonious component discounting [39], where \u03a5j+1 = \u03a3j(1\u2212 \u03b4)/\u03b4 and \u03b4 is typically in [0.9,1.0].\nAlthough the above procedure is efficient, the variational step to find the conjugate distributions\u2019s parameters still requires an iterative numerical computation. To circumvent the need to use an iterative solver we propose to take a Laplace approximation instead and derive a closed-form update using the principal branch of Lambert W function (inverse of \u03c9 7\u2192 \u03c9exp(\u03c9)). Having ej+1 and lj+1 and assuming a normal distribution for P (log(\u03bbj+1))|Dj) \u223c N (ej+1, lj+1), qj+1 = argmax\u03c9 log ( Pois(Yj+1; exp(\u03c9))N (\u03c9; ej+1, lj+1) ) and \u03bdj+1 is the inverse of the curvature of negative log-posterior at qj+1:\nqj+1 = log ( LambertW ( lj+1exp(Yj+1lj+1 + ej+1) ) /lj+1 ) ,\n\u03bdj+1 = lj+1/(1 + lj+1exp(qj+1)).\nA.3 Constructing Bayes Greedy and RL-based Pricing Policies\nA.3.1 Bayes Greedy Policy\nAs a second option to compute (14) of the main text, we can approximate the expectation in (14) without any specific distributional assumption by a second order Taylor expansion of the exponential term around the mean of parameters:\nE\u03c0\u2217(\u03b8)[exp(p\u03b8TW it)(p\u2212 c)] \u2248\n(p\u2212 c)E\u03c0\u2217(\u03b8)[exp(p\u00b5T\u03b8W it) + exp(p\u00b5 T \u03b8W it)(\u03b8 \u2212 \u00b5\u03b8) T (pW it) + 1\n2 (\u03b8 \u2212 \u00b5\u03b8) T (pW it)(pW it) T (\u03b8 \u2212 \u00b5\u03b8)] = (p\u2212 c)exp(p\u00b5T\u03b8W it) ( 1 + 1\n2 p2W Tit\u03a3\u03b8W it\n) .\n(20)\nAssuming \u03c0\u2217(\u03b8) is a multivariate normal distribution leads us to a third approach to approximate (14). Under this assumption and considering the random variable p\u03b8TW it should lie within (\u2212\u221e, 0), we can derive a closed-form for (14) and calculate the expectation in (14) as follows:\nE\u03c0\u2217(\u03b8)[exp(p\u03b8TW it)(p\u2212 c)] = (p\u2212 c) \u222b 0 \u2212\u221e\nexp(z)\nZ\n( \u2212p\u00b5T\n\u03b8 W it\np \u221a WTit\u03a3\u03b8W it\n) \u03b6 ( z\u2212p\u00b5T\u03b8W it p \u221a WTit\u03a3\u03b8W it ) p \u221a W Tit\u03a3\u03b8W it =\n(p\u2212 c)exp ( p\u00b5T\u03b8W it +\np2W Tit\u03a3\u03b8W it 2\n) Z (\u2212\u00b5T\u03b8W it\u2212pWTit\u03a3\u03b8W it\u221a WTit\u03a3\u03b8W it ) Z\n( \u2212\u00b5\u03b8TW it\u221a WTit\u03a3\u03b8W it\n) , (21)\nwhere \u03b6(\u00b7) and Z(\u00b7) denote the standard normal PDF and CDF, respectively. In contrast to the plug-in estimator in (15), both (21) and (20) depend on \u03a3\u03b8 in addition to the estimated mean of \u03b8. For real-time pricing by using the utility in (21) or (20), we can discretize [plbit, p ub it ] and query the approximated utility to find the price maximizing the expected margin contribution.\nA.3.2 Pricing with Learning\nThe estimation of price sensitivities via the Bayesian DGLM approach allows one to leverage ideas from Reinforcement Learning for developing dynamic price experimentation policies based on methods such as Upper Confidence Bound (UCB) or Thompson sampling (TS) [36]. Such policies incorporate the knowledge about current uncertainty in the price sensitivity parameters to judiciously randomize prices and typically converge to the optimal price faster than the Bayes greedy policies. For TS, the policy is to draw samples from the posterior so as to select a price with probability equal to the posterior probability that the price results in the highest margin contribution. With the normal distributional assumption for the posterior of the parameters, implementing TS is rather straightforward, where a sample (\u03b8\u0304) from the posterior of the parameters is taken (with rejection if \u03b8\u0304 T W it \u2264 0) and the price that maximizes exp(p\u03b8\u0304TW it)(p \u2212 c) is selected. The offered price under TS is min{max{plbit, c \u2212 1/\u03b8\u0304 T W it}, pubit }, which is similar to (16) in the main text with \u00b5\u03b8 replaced by the parameter sample. For UCB, the policy is to select the price that maximizes a desired quantile of the margin contribution (the choice of quantile can be time dependent). Since the Bayesian DGLM approach doesn\u2019t enforce a distributional assumption for \u03c0\u2217(\u03b8), we will assume a normal distributional approximation to develop the pricing policy under UCB. The UCB in this case is approximated by E[exp(p\u03b8TW it)(p\u2212c)]+\u03beStd[exp(p\u03b8TW it)(p\u2212c)], where Std[\u00b7] represents standard deviation, \u03be = \u221a 2erf\u22121(2\u03b1 \u2212 1), and \u03b1 denotes the desired quantile. By first-order Taylor expansion we can approximate the UCB as\nUCB(\u03b1) \u2248 E[exp(p\u03b8TW it)(p\u2212 c)] + \u03beStd[exp(p\u03b8TW it)(p\u2212 c)]\n\u2248 (p\u2212 c)exp(p\u00b5T\u03b8W it) + \u03be(p\u2212 c)exp(p\u00b5 T \u03b8W it)p \u221a W Tit\u03a3\u03b8W it.\n(22)\nSince the approximated UCB in (22) is differentiable and log-concave for plbit > c, the price maximizing (22) is either the root of its gradient (root of a quadratic polynomial which can be easily calculated) or one of the price boundaries, plbit or p ub it .\nBy further assuming that the posterior distribution of the parameters is multivariate normal, we can derive a closed-form for UCB. Specifically, we can compute the desired quantile of the margin contribution based on standard normal quantile (inverse CDF) function. Under this assumption and considering that p\u03b8TW it lies within (\u2212\u221e, 0), the quantile function of the margin contribution is equal to\nUCB(\u03b1) = exp ( p\u00b5T\u03b8W it + p \u221a W Tit\u03a3\u03b8W itZ \u22121 ( \u03b1Z ( \u2212\u00b5T\u03b8W it\u221a W Tit\u03a3\u03b8W it ))) (p\u2212 c). (23)\nThen the optimal price with respect to the UCB utility function in (23) has the following closed-form solution\nP \u2217it = min { max { plbit, c\u2212 1/ ( \u00b5T\u03b8W it + \u221a W Tit\u03a3\u03b8W itZ \u22121 ( \u03b1Z ( \u2212\u00b5T\u03b8W it\u221a W Tit\u03a3\u03b8W it )))} , pubit } . (24)\nA.4 Additional Details about the Simulation Setup Used in the Airline Setting\nFigure 6 shows the trend of bookings over the two year simulated history, where we can observe the yearly seasonality marked by a peak and low season. Moreover, for POS 0, we observe more bookings in the middle TFs while for POS 1 we observe higher share of bookings for the later TFs. For both the POSs, the early TFs receive a relatively lower number of bookings.\nFigure 7 shows the distribution of prices over the two year history. We observe that since the willingnessto-pay (\u03b1) is increasing as we get closer to the departure (higher TFs), the offered prices also show this increasing trend over TFs. Moreover, the average price for any TF is higher for POS 1 as compared to POS 0 again as the willingness-to-pay for POS 1 is higher than that for POS 0.\nA.5 Additional results for the simulation in airline setting"
        }
    ],
    "title": "Machine Learning based Framework for Robust Price-Sensitivity Estimation with Application to Airline Pricing",
    "year": 2022
}