 Here are 5 possible future research ideas after reading this paper:

1. Evaluate the rule-based method on a larger dataset of student-generated questions across more subject areas. This could reveal new insights into how well it generalizes and which flaws are most prevalent in different domains.

2. Refine the rule-based method by adjusting the thresholds and logic for certain criteria to improve performance on flaws it currently struggles with. This could lead to even higher accuracy compared to human evaluation.

3. Develop new rule-based methods for other educational question types beyond multiple choice, such as short answer or fill in the blank questions. This would expand the applicability of automatic evaluation. 

4. Compare the rule-based method to other machine learning techniques, like SVM or neural networks trained on the human annotated data. This could reveal the strengths and weaknesses of the different approaches.

5. Build a hybrid system that leverages both rule-based logic and machine learning to get the best of both worlds - interpretability from rules and pattern recognition from ML. The system could use rules to filter out obvious flaws and then use ML on the more nuanced criteria.