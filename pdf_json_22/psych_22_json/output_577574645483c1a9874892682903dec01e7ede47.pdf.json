{
    "abstractText": "In this study, we aim to detect in social media texts written in Hebrew girls who are suspected of being anorexic. We constructed a dataset containing 100 blog posts written by females who are probably anorexic, and 100 blog posts written by females who are likely to be non-anorexic. The construction of this dataset was supervised and approved by an international expert on anorexia. We tested several text classification (TC) methods, using various feature sets (content-based and style-based), five machine learning (ML) methods, three RNN models, four BERT models, three basic preprocessing methods, three feature filtering methods, and parameter tuning. Several insights were found as follows. A set of 50-word n-grams (mostly word unigrams) given by an expert was found as a good basic detector. A heuristic process based on the random forest ML method has overcome a combinatorial explosion and led to significant improvement over a baseline result at a level of P= .01. Application of an iterative process that tests combinations of \u2018\u2018k out of n\u2019\u2019 where n< n (n is the number of feature sets) lead to a result of 90.63%, using a combination of 300 features from ten feature sets. INDEX TERMS Mental disorders, natural language processing, supervised machine learning, text analysis, text classification, text processing.",
    "authors": [
        {
            "affiliations": [],
            "name": "YAAKOV HACOHEN-KERNER"
        },
        {
            "affiliations": [],
            "name": "NATAN MANOR"
        },
        {
            "affiliations": [],
            "name": "MICHAEL GOLDMEIER"
        },
        {
            "affiliations": [],
            "name": "EYTAN BACHAR"
        }
    ],
    "id": "SP:5613251df1006f611238e16d12e349248334d1df",
    "references": [
        {
            "authors": [
                "G. Szmukler",
                "D. Bolton"
            ],
            "title": "What is Mental Disorder? An Essay in Philosophy, Science, and Values",
            "year": 2008
        },
        {
            "authors": [
                "S.L. James"
            ],
            "title": "Global, regional, and national incidence, prevalence, and years lived with disability for 354 diseases and injuries for 195 countries and territories, 1990\u20132017: A systematic analysis for the global burden of disease study 2017",
            "venue": "Lancet, vol. 392, pp. 1789\u20131858, Nov. 2018.",
            "year": 1858
        },
        {
            "authors": [
                "P.S. Wang",
                "S. Aguilar-Gaxiola",
                "J. Alonso",
                "M.C. Angermeyer",
                "G. Borges",
                "E.J. Bromet",
                "R. Bruffaerts",
                "G. De Girolamo",
                "R. De Graaf",
                "O. Gureje",
                "J.M. Haro"
            ],
            "title": "Use of mental health services for anxiety, mood, and substance disorders in 17 countries in the WHO world mental health surveys",
            "venue": "Lancet, vol. 370, no. 9590, pp. 841\u2013850, Sep. 2007.",
            "year": 2007
        },
        {
            "authors": [
                "G. Coppersmith",
                "C. Harman",
                "M. Dredze"
            ],
            "title": "Measuring post traumatic stress disorder in Twitter",
            "venue": "Proc. 8th Int. AAAI Conf. Weblogs Social Media, 2014, pp. 1\u20134.",
            "year": 2014
        },
        {
            "authors": [
                "R.L. Frost",
                "D.J. Rickwood"
            ],
            "title": "A systematic review of the mental health outcomes associated with Facebook use",
            "venue": "Comput. Hum. Behav., vol. 76, pp. 576\u2013600, Nov. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "I. Pirina",
                "\u00c7. \u00c7\u00f6ltekin"
            ],
            "title": "Identifying depression on reddit: The effect of training data",
            "venue": "Proc. EMNLP Workshop SMM4H, 3rd Social Media Mining Health Appl. Workshop Shared Task, 2018, pp. 9\u201312.",
            "year": 2018
        },
        {
            "authors": [
                "G. Coppersmith",
                "M. Dredze",
                "C. Harman",
                "K. Hollingshead"
            ],
            "title": "From ADHD to SAD: Analyzing the language of mental health on Twitter through self-reported diagnoses",
            "venue": "inProc. 2ndWorkshop Comput. Linguistics Clin. Psychol., From Linguistic Signal Clin. Reality, 2015, pp. 1\u201310.",
            "year": 2015
        },
        {
            "authors": [
                "A. Trifan",
                "R. Antunes",
                "S.Matos",
                "J.L. Oliveira"
            ],
            "title": "Understanding depression from psycholinguistic patterns in social media texts",
            "venue": "Advances in Information Retrieval, vol. 12036. Cham, Switzerland: Springer, 2020, pp. 402\u2013409.",
            "year": 2020
        },
        {
            "authors": [
                "M.M. Tadesse",
                "H. Lin",
                "B. Xu",
                "L. Yang"
            ],
            "title": "Detection of suicide ideation in social media forums using deep learning",
            "venue": "Algorithms, vol. 13, no. 1, p. 7, Dec. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J.H. Shen",
                "F. Rudzicz"
            ],
            "title": "Detecting anxiety through reddit",
            "venue": "Proc. 4th Workshop Comput. Linguistics Clin. Psychol. From Linguistic Signal Clin. Reality, 2017, pp. 58\u201365.",
            "year": 2017
        },
        {
            "authors": [
                "M.L. Birnbaum",
                "S.K. Ernala",
                "A.F. Rizvi",
                "M. De Choudhury",
                "J.M. Kane"
            ],
            "title": "A collaborative approach to identifying social media markers of schizophrenia by employing machine learning and clinical appraisals",
            "venue": "J. Med. Internet Res., vol. 19, no. 8, p. e289, Aug. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "I. Sekuli\u0107",
                "M. Gjurkovi\u0107",
                "J. \u0160najder"
            ],
            "title": "Not just depressed: Bipolar disorder prediction on reddit",
            "venue": "2018, arXiv:1811.04655.",
            "year": 2018
        },
        {
            "authors": [
                "A. Honey andC. Halse"
            ],
            "title": "The specifics of coping: Parents of daughters with anorexia nervosa",
            "venue": "Qualitative Health Res., vol. 16, no. 5, pp. 611\u2013629, May 2006.",
            "year": 2006
        },
        {
            "authors": [
                "D.E. Pawluck",
                "K.M. Gorey"
            ],
            "title": "Secular trends in the incidence of anorexia nervosa: Integrative review of population-based studies",
            "venue": "Int. J. Eating Disorders, vol. 23, no. 4, pp. 347\u2013352, May 1998.",
            "year": 1998
        },
        {
            "authors": [
                "R.L. Palmer"
            ],
            "title": "Death in anorexia nervosa",
            "venue": "Lancet, vol. 361, no. 9368, p. 1490, May 2003.",
            "year": 2003
        },
        {
            "authors": [
                "E. Bachar",
                "Y. Latzer",
                "S. Kreitler",
                "E.M. Berry"
            ],
            "title": "Empirical comparison of two psychological therapies: Self psychology and cognitive orientation in the treatment of anorexia and bulimia",
            "venue": "J. Psychotherapy Pract. Res., vol. 8, no. 2, p. 115, 1999.",
            "year": 1999
        },
        {
            "authors": [
                "H. Bruch"
            ],
            "title": "Four decades of eating disorders",
            "venue": "inHandbook of Psychotherapy for Anorexia Nervosa and Bulimia. NewYork, NY, USA: The Guilford Press, 1985, pp. 7\u201318.",
            "year": 1985
        },
        {
            "authors": [
                "E. Bachar",
                "A. Verbin"
            ],
            "title": "Psychodynamic Self Psychology in the Treatment of Anorexia and Bulimia",
            "year": 2020
        },
        {
            "authors": [
                "P.C. H\u00e9bert",
                "M.A. Weingarten"
            ],
            "title": "The ethics of forced feeding in anorexia nervosa",
            "venue": "Can. Med. Assoc. J., vol. 144, p. 141, Jan. 1991.",
            "year": 1991
        },
        {
            "authors": [
                "S. Giordano"
            ],
            "title": "Risk and supervised exercise: The example of anorexia to illustrate a new ethical issue in the traditional debates of medical ethics",
            "venue": "J. Med. Ethics, vol. 31, no. 1, pp. 15\u201320, Jan. 2005.",
            "year": 2005
        },
        {
            "authors": [
                "H. Maslen",
                "J. Pugh",
                "J. Savulescu"
            ],
            "title": "The ethics of deep brain stimulation for the treatment of anorexia nervosa",
            "venue": "Neuroethics, vol. 8, no. 3, pp. 215\u2013230, Dec. 2015.",
            "year": 2015
        },
        {
            "authors": [
                "D.E. Losada",
                "F. Crestani"
            ],
            "title": "A test collection for research on depression and language use",
            "venue": "Proc. Int. Conf. Cross-Lang. Eval. Forum Eur. Lang., 2016, pp. 28\u201339.",
            "year": 2016
        },
        {
            "authors": [
                "D.E. Losada",
                "F. Crestani",
                "J. Parapar"
            ],
            "title": "Overview of eRisk: Early risk prediction on the internet",
            "venue": "Proc. Int. Conf. Cross-Lang. Eval. Forum Eur. Lang., 2018, pp. 343\u2013361.",
            "year": 2018
        },
        {
            "authors": [
                "M. Trotzek",
                "S. Koitka",
                "C.M. Friedrich"
            ],
            "title": "Word embeddings and linguistic metadata at the CLEF 2018 tasks for early detection of depression and anorexia",
            "venue": "Proc. CLEF, Working Notes, 2018, pp. 1\u201315.",
            "year": 2018
        },
        {
            "authors": [
                "D.G. Funez",
                "M.J.G. Ucelay",
                "M.P. Villegas",
                "S. Burdisso",
                "L.C. Cagnina",
                "M. Montes-y-G\u00f3mez",
                "M. Errecalde"
            ],
            "title": "UNSL\u2019s participation at eRisk 2018 lab",
            "venue": "Proc. CLEF, Working Notes, 2018, pp. 1\u201311.",
            "year": 2018
        },
        {
            "authors": [
                "M.E. Aragon",
                "A.P. Lopez-Monroy",
                "L.-C.-G. Gonzalez-Gurrola",
                "M. Montes"
            ],
            "title": "Detecting mental disorders in social media through emotional patterns\u2014The case of anorexia and depression",
            "venue": "IEEE Trans. Affect. Comput., early access, Apr. 27, 2021, doi: 10.1109/TAFFC.2021.3075638.",
            "year": 2021
        },
        {
            "authors": [
                "S.M. Mohammad",
                "P.D. Turney"
            ],
            "title": "Crowdsourcing a word\u2013emotion association lexicon",
            "venue": "Comput. Intell., vol. 29, no. 3, pp. 436\u2013465, Aug. 2013.",
            "year": 2013
        },
        {
            "authors": [
                "D.E. Losada",
                "F. Crestani",
                "J. Parapar"
            ],
            "title": "Overview of eRisk 2019 early risk prediction on the internet",
            "venue": "Proc. Int. Conf. Cross-Lang. Eval. Forum Eur. Lang., 2019, pp. 340\u2013357.",
            "year": 2019
        },
        {
            "authors": [
                "E. Mohammadi",
                "H. Amini",
                "L. Kosseim"
            ],
            "title": "Quick and (maybe not so) easy detection of anorexia in social media posts",
            "venue": "Proc. CLEF (Working Notes), 2019, pp. 1\u201314.",
            "year": 2019
        },
        {
            "authors": [
                "W. Ragheb",
                "J. Az\u00e9",
                "S. Bringay",
                "M. Servajean"
            ],
            "title": "Attentive multi-stage learning for early risk detection of signs of anorexia and self-harm on social media",
            "venue": "Proc. CLEF (Working Notes), 2019, pp. 1\u201315.",
            "year": 2019
        },
        {
            "authors": [
                "A.S. Uban",
                "B. Chulvi",
                "P. Rosso"
            ],
            "title": "Understanding patterns of anorexia manifestations in social media data with deep learning",
            "venue": "Proc. 7th Workshop Comput. Linguistics Clin. Psychol., Improving Access, 2021, pp. 224\u2013236.",
            "year": 2021
        },
        {
            "authors": [
                "S. Tsugawa",
                "Y. Kikuchi",
                "F. Kishino",
                "K. Nakajima",
                "Y. Itoh",
                "H. Ohsaki"
            ],
            "title": "Recognizing depression from Twitter activity",
            "venue": "Proc. 33rd Annu. ACM Conf. Hum. Factors Comput. Syst., Apr. 2015, pp. 3187\u20133196.",
            "year": 2015
        },
        {
            "authors": [
                "D.M. Blei",
                "A.Y. Ng",
                "M.I. Jordan"
            ],
            "title": "Latent Dirichlet allocation",
            "venue": "J. Mach. Learn. Res., vol. 3, pp. 993\u20131022, Mar. 2003.",
            "year": 2003
        },
        {
            "authors": [
                "T. Wang",
                "M. Brede",
                "A. Ianni",
                "E. Mentzakis"
            ],
            "title": "Detecting and characterizing eating-disorder communities on social media",
            "venue": "Proc. 10th ACM Int. Conf. Web Search Data Mining, Feb. 2017, pp. 91\u2013100.",
            "year": 2017
        },
        {
            "authors": [
                "Y.R. Tausczik",
                "J.W. Pennebaker"
            ],
            "title": "The psychological meaning of words: LIWC and computerized text analysis methods",
            "venue": "J. Lang. Social Psychol., vol. 29, no. 1, pp. 24\u201354, Mar. 2010.",
            "year": 2010
        },
        {
            "authors": [
                "E. Fast",
                "B. Chen",
                "M.S. Bernstein"
            ],
            "title": "Empath: Understanding topic signals in large-scale text",
            "venue": "Proc. CHI Conf. Hum. Factors Comput. Syst., May 2016, pp. 4647\u20134657.",
            "year": 2016
        },
        {
            "authors": [
                "S. Bird",
                "E. Klein",
                "E. Loper",
                "Natural"
            ],
            "title": "Language ProcessingWith Python: Analyzing Text With the Natural Language Toolkit",
            "year": 2009
        },
        {
            "authors": [
                "D. Ram\u00edrez-Cifuentes",
                "M. Mayans",
                "A. Freire"
            ],
            "title": "Early risk detection of anorexia on social media",
            "venue": "Proc. Int. Conf. Internet Sci., 2018, pp. 3\u201314.",
            "year": 2018
        },
        {
            "authors": [
                "J.W. Pennebaker",
                "R.L. Boyd",
                "K. Jordan",
                "K. Blackburn"
            ],
            "title": "The development and psychometric properties of LIWC2015",
            "venue": "Dept. Psychol., Univ. Texas Austin, Austin, TX, USA, Tech. Rep., 2015.",
            "year": 2015
        },
        {
            "authors": [
                "T. Zhou",
                "G. Hu",
                "L. Wang"
            ],
            "title": "Psychological disorder identifying method based on emotion perception over social networks",
            "venue": "Int. J. Environ. Res. Public Health, vol. 16, no. 6, p. 953, Mar. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M.M. Tadesse",
                "H. Lin",
                "B. Xu",
                "L. Yang"
            ],
            "title": "Detection of depressionrelated posts in reddit social media forum",
            "venue": "IEEE Access, vol. 7, pp. 44883\u201344893, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M.E. Arag\u00f3n",
                "A.P. L\u00f3pez-Monroy",
                "L.C. Gonz\u00e1lez-Gurrola",
                "M. Montes-y-G\u00f3mez"
            ],
            "title": "Detecting depression in social media using finegrained emotions",
            "venue": "Proc. Conf. North Amer. Chapter Assoc. Comput. Linguistics, Hum. Lang. Technol., vol. 1, 2019, pp. 1481\u20131486.",
            "year": 2019
        },
        {
            "authors": [
                "H. Alhuzali",
                "T. Zhang",
                "S. Ananiadou"
            ],
            "title": "Predicting sign of depression via using frozen pre-trained models and random forest classifier",
            "venue": "Proc. Working Notes CLEF, 2021, pp. 21\u201324.",
            "year": 2021
        },
        {
            "authors": [
                "S.C. Guntuku",
                "D.B. Yaden",
                "M.L. Kern",
                "L.H. Ungar",
                "J.C. Eichstaedt"
            ],
            "title": "Detecting depression and mental illness on social media: An integrative review",
            "venue": "Current Opinion Behav. Sci., vol. 18, pp. 43\u201349, Dec. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "A.Wongkoblap",
                "M.A. Vadillo",
                "V. Curcin"
            ],
            "title": "Researching mental health disorders in the era of social media: Systematic review",
            "venue": "J. Med. Internet Res., vol. 19, no. 6, p. e228, Jun. 2017. VOLUME 10, 2022 34813 Y. HaCohen-kerner et al.: Detection of Anorexic Girls-In Blog Posts Written in Hebrew",
            "year": 2017
        },
        {
            "authors": [
                "L. Canetti",
                "E. Bachar",
                "E.M. Berry"
            ],
            "title": "Food and emotion",
            "venue": "Behav. Process., vol. 60, no. 2, pp. 157\u2013164, 2002.",
            "year": 2002
        },
        {
            "authors": [
                "Y. Latzer",
                "Z. Hochdorf",
                "E. Bachar",
                "L. Canetti"
            ],
            "title": "Attachment style and family functioning as discriminating factors in eating disorders,\u2019\u2019Contemp",
            "venue": "Family Therapy,",
            "year": 2002
        },
        {
            "authors": [
                "U. Pinus",
                "L. Canetti",
                "O. Bonne",
                "E. Bachar"
            ],
            "title": "Selflessness as a predictor of remission from an eating disorder: 1\u20134 year outcomes from an adolescent day-care unit",
            "venue": "Eating Weight Disorders Stud. Anorexia, Bulimia Obesity, vol. 24, no. 4, pp. 777\u2013786, Aug. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "Z. Jianqiang",
                "G. Xiaolin"
            ],
            "title": "Comparison research on text preprocessing methods on Twitter sentiment analysis",
            "venue": "IEEE Access, vol. 5, pp. 2870\u20132879, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "Y. HaCohen-Kerner",
                "Y. Yigal",
                "D.Miller"
            ],
            "title": "The impact of preprocessing on classification ofmental disorders",
            "venue": "inProc. 19th Ind. Conf. DataMining (ICDM), New York, NY, USA, 2019, pp. 52\u201366.",
            "year": 2019
        },
        {
            "authors": [
                "Y. HaCohen-Kerner",
                "D. Miller",
                "Y. Yigal"
            ],
            "title": "The influence of preprocessing on text classification using a bag-of-words representation",
            "venue": "PLoS ONE, vol. 15, no. 5, May 2020, Art. no. e0232525.",
            "year": 2020
        },
        {
            "authors": [
                "C. Cortes",
                "V. Vapnik"
            ],
            "title": "Support-vector networks",
            "venue": "Mach. Learn., vol. 20, pp. 273\u2013297, Sep. 1995.",
            "year": 1995
        },
        {
            "authors": [
                "C.C. Chang",
                "C.J. Lin"
            ],
            "title": "LIBSVM: A library for support vector machines",
            "venue": "ACM Trans. Intell. Syst. Technol., vol. 2, no. 3, pp. 1\u201327, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "L. Breiman"
            ],
            "title": "Random forests",
            "venue": "Mach. Learn., vol. 45, no. 1, pp. 5\u201332, 2001.",
            "year": 2001
        },
        {
            "authors": [
                "F. Murtagh"
            ],
            "title": "Multilayer perceptrons for classification and regression",
            "venue": "Neurocomputing, vol. 2, nos. 5\u20136, pp. 183\u2013197, Jul. 1991.",
            "year": 1991
        },
        {
            "authors": [
                "D.R. Cox"
            ],
            "title": "The regression analysis of binary sequences",
            "venue": "J. Roy. Stat. Soc. B, Methodol., vol. 20, no. 2, pp. 215\u2013232, 1958.",
            "year": 1958
        },
        {
            "authors": [
                "M. Kibriya",
                "E. Frank",
                "B. Pfahringer",
                "G. Holmes"
            ],
            "title": "Multinomial Naive Bayes for text categorization revisited",
            "venue": "Proc. Australas. Joint Conf. Artif. Intell., Berlin, Germany, 2004, pp. 488\u2013499.",
            "year": 2004
        },
        {
            "authors": [
                "E. Frank",
                "R.R. Bouckaert"
            ],
            "title": "Naive Bayes for text classification with unbalanced classes",
            "venue": "Proc. Eur. Conf. Princ. Data Mining Knowl. Discovery, 2006, pp. 503\u2013510.",
            "year": 2006
        },
        {
            "authors": [
                "T. Kanamori"
            ],
            "title": "Deformation of log-likelihood loss function for multiclass boosting",
            "venue": "Neural Netw., vol. 23, no. 7, pp. 843\u2013864, Sep. 2010.",
            "year": 2010
        },
        {
            "authors": [
                "M. Sabzevari",
                "G. Mart\u00ednez-Mu\u00f1oz",
                "A. Su\u00e1rez"
            ],
            "title": "Vote-boosting ensembles",
            "venue": "Pattern Recognit., vol. 83, pp. 119\u2013133, Dec. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "C. Nadeau",
                "Y. Bengio"
            ],
            "title": "Inference for the generalization error",
            "venue": "Proc. Adv. Neural Inf. Process. Syst., vol. 12, 2000, pp. 307\u2013313.",
            "year": 2000
        },
        {
            "authors": [
                "C. Nadeau",
                "Y. Bengio"
            ],
            "title": "Inference for the generalization error,\u2019\u2019Mach",
            "venue": "Learn., vol. 52,",
            "year": 2003
        },
        {
            "authors": [
                "Y. HaCohen-Kerner",
                "E. Malin",
                "I. Chasson"
            ],
            "title": "Summarization of Jewish law articles in Hebrew",
            "venue": "Proc. CAINE, 2003, pp. 172\u2013177.",
            "year": 2003
        },
        {
            "authors": [
                "Y. HaCohen-Kerner",
                "S.Y. Blitz"
            ],
            "title": "Initial experiments with extraction of stopwords in Hebrew",
            "venue": "Proc. KDIR, 2010, pp. 449\u2013453.",
            "year": 2010
        },
        {
            "authors": [
                "Y. HaCohen-Kerner",
                "R. Dilmon",
                "M. Hone",
                "M.A. Ben-Basan"
            ],
            "title": "Automatic classification of complaint letters according to service provider categories",
            "venue": "Inf. Process. Manage., vol. 56, no. 6, Nov. 2019, Art. no. 102102.",
            "year": 2019
        },
        {
            "authors": [
                "S. Baluja"
            ],
            "title": "An empirical comparison of seven iterative and evolutionary function optimization heuristics",
            "venue": "Dept. Comput. Sci., Carnegie-Mellon Univ., Pittsburgh, PA, USA, Tech. Rep. NASA-CR-201901, 1995.",
            "year": 2019
        },
        {
            "authors": [
                "Y. HaCohen-Kerner",
                "H. Beck",
                "E. Yehudai",
                "M. Rosenstein",
                "D. Mughaz"
            ],
            "title": "Cuisine: Classification using stylistic feature sets and/or name-based feature sets",
            "venue": "J. Amer. Soc. Inf. Sci. Technol., vol. 61, pp. 1644\u20131657, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "S. Hochreiter",
                "J. Schmidhuber"
            ],
            "title": "LSTM can solve hard long time lag problems",
            "venue": "Proc. Adv. Neural Inf. Process. Syst., 1997, pp. 473\u2013479.",
            "year": 1997
        },
        {
            "authors": [
                "J. Chung",
                "C. Gulcehre",
                "K. Cho",
                "Y. Bengio"
            ],
            "title": "Empirical evaluation of gated recurrent neural networks on sequence modeling",
            "venue": "2014, arXiv:1412.3555.",
            "year": 2014
        },
        {
            "authors": [
                "A. Seker",
                "E. Bandel",
                "D. Bareket",
                "I. Brusilovsky",
                "R. Shaked Greenfeld",
                "R. Tsarfaty"
            ],
            "title": "AlephBERT: A Hebrew large pre-trained language model to start-off your Hebrew NLP application with",
            "venue": "2021, arXiv:2104.04052.",
            "year": 2021
        },
        {
            "authors": [
                "A. Chriqui",
                "I. Yahav"
            ],
            "title": "HeBERT & HebEMO: A Hebrew BERT model and a tool for polarity analysis and emotion recognition",
            "venue": "2021, arXiv:2102.01909.",
            "year": 2021
        },
        {
            "authors": [
                "S. Pyysalo",
                "J. Kanerva",
                "A. Virtanen",
                "F. Ginter"
            ],
            "title": "WikiBERT models: Deep transfer learning for many languages",
            "venue": "2020, arXiv:2006.01538.",
            "year": 2020
        },
        {
            "authors": [
                "J. Devlin",
                "M.-W. Chang",
                "K. Lee",
                "K. Toutanova"
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "2018, arXiv:1810.04805.",
            "year": 2018
        },
        {
            "authors": [
                "Y. Ko",
                "J. Seo"
            ],
            "title": "Text classification from unlabeled documents with bootstrapping and feature projection techniques",
            "venue": "Inf. Process. Manage., vol. 45, no. 1, pp. 70\u201383, Jan. 2009.",
            "year": 2009
        },
        {
            "authors": [
                "D.M. Blei",
                "A.Y. Ng",
                "M.I. Jordan"
            ],
            "title": "Latent Dirichlet allocation",
            "venue": "J. Mach. Learn. Res., vol. 3, pp. 993\u20131022, Jan. 2003.",
            "year": 2003
        },
        {
            "authors": [
                "G.E. Hinton"
            ],
            "title": "A practical guide to training restricted Boltzmann machines",
            "venue": "Neural Networks: Tricks of the Trade. Berlin, Germany: Springer, 2012, pp. 599\u2013619.",
            "year": 2012
        },
        {
            "authors": [
                "I. Goodfellow",
                "J. Pouget-Abadie",
                "M. Mirza",
                "B. Xu",
                "D. Warde-Farley",
                "S. Ozair",
                "A. Courville",
                "Y. Bengio"
            ],
            "title": "Generative adversarial nets",
            "venue": "Proc. Adv. Neural Inf. Process. Syst., vol. 27, 2014, pp. 1\u20139.",
            "year": 2014
        },
        {
            "authors": [
                "Y. Li",
                "Q. Pan",
                "S. Wang",
                "T. Yang",
                "E. Cambria"
            ],
            "title": "A generative model for category text generation",
            "venue": "Inf. Sci., vol. 450, pp. 301\u2013315, Jun. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "S. Gupta",
                "S.K. Gupta"
            ],
            "title": "Abstractive summarization: An overview of the state of the art",
            "venue": "Expert Syst. Appl., vol. 121, pp. 49\u201365, May 2019.",
            "year": 2019
        },
        {
            "authors": [
                "G. Brauwers",
                "F. Frasincar"
            ],
            "title": "A survey on aspect-based sentiment classification",
            "venue": "ACM Comput. Surv., Dec. 2021, p. 35.",
            "year": 2021
        },
        {
            "authors": [
                "A.Montesinos-L\u00f3pez",
                "O.A.Montesinos-L\u00f3pez",
                "D. Gianola",
                "J. Crossa",
                "C.M. Hern\u00e1ndez-Su\u00e1rez"
            ],
            "title": "Multi-environment genomic prediction of plant traits using deep learners with dense architecture",
            "venue": "G3, Genes, Genomes, Genetics, vol. 8, no. 12, pp. 3813\u20133828, Dec. 2018.",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "INDEX TERMS Mental disorders, natural language processing, supervised machine learning, text analysis, text classification, text processing.\nI. INTRODUCTION Amental disorder is a behavioral ormental pattern that causes significant distress or impairment of personal functionality. Szmukler [1] and James et al. [2] estimated that there are approximately 971 million people worldwide who suffer from variousmental disorders, e.g.,\u223c 284million suffer from anxiety, \u223c 264 million suffer from depressive disorders, and \u223c 50million suffer from dementia. Furthermore, according to Wang et al. [3], between 76% and 85% of people with mental disorders receive no treatment.\nA mental disorder can be diagnosed only by a mental health professional. In our opinion, plausible suspicion of many mental disorders can be generated by an intelligent supervised machine learning (ML) system based on social texts, such as Twitter messages and blog posts. Such a system will be able to detect various suspected mental disorders\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Marco Martalo .\namong people participating in social networks. The output of such a system can be presented to professional experts, to whom the individuals can be referred.\nOnline social networks, such as Facebook, Twitter, and blog forums, are extremely popular, with hundreds of millions of users, and many people express their mental state and feelings on social media. Therefore, social media enable the construction of datasets that can serve as excellent testbeds for the detection of various mental disorders.\nIn recent years, an increasing amount of research on mental health has focused on social media, e.g., Twitter [4], Facebook [5], and Reddit Reddit1 (news and social website dedicated to thousands of communities) [6]. Coppersmith et al. [7] showed that several mental disorders (e.g., anxiety, eating disorders, and schizophrenia) can be detected in Twitter messages by using character n-gram language models (CLMs). Previous mental health studies have\n1https://www.redditinc.com/\n34800 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 10, 2022\nlargely focused on several specific mental disorders, such as depression [8], post-traumatic stress disorder (PTSD) [4], suicide [9], anxiety [10], schizophrenia [11], and bipolar disorder [12].\nAnorexia nervosa (AN) is an eating disorder (ED) that is defined by the Diagnostic and Statistical Manual of Mental Disorders [Edition, 2013, pages 338-339] as follows:\n\u2018\u2018Anorexia Nervosa. Diagnostic Criteria A. Restriction of energy intake relative to requirements leading to significantly low body weight in the context of age, sex, developmental trajectory, and physical health. Significantly low weight is defined as a weight that is less than minimally normal or, for children and adolescents, less than that minimally expected. B. Intense fear of gaining weight or becoming fat, or persistent behavior that interferes with weight gain, even though at a significantly lowweight. C. Disturbance in theway inwhich one\u2019s body weight or shape is experienced, undue influence of body weight or shape on self-evaluation, or persistent lack of recognition of the seriousness of the current low body weight.\u2019\u2019\nBriefly, AN is an ED that is characterized as the maintenance of extremely low body weight, an intense fear of putting on weight despite being severely underweight and having amenorrhea and a distorted body image [13]. Adolescents and young adults are at particularly high risk. The peak onset for AN occurs during the teenage years and early twenties, with a preponderance in girls and women [6], [14], [15]. Therefore, the target population of the current study is adolescent and young adult females. According to James et al. [2], there are approximately 3.36 million people worldwide who suffer from anorexia.\nAN is a disabling, deadly, and costly mental disorder that considerably impairs physical health and disrupts the psychosocial functioning of the individual. AN has one of the highest death rates of any psychiatric disorder [15] and is considered the most dangerous among the cluster of eating disorders [16]. The physical complications of AN, which are the results of extreme starvation and subsequent thinness, are enormous. Various possible complications of AN are amenorrhea, i.e., the cessation of menstruation in menstruation-aged women [17], constipation, severe abdominal pain, slowness, low body temperature, and a failure to thrive to the body\u2019s full potential. If normal eating restoration is not gradual, severe edema may appear. Bone density may also significantly decrease [18], [19].\nVarious interesting ethical issues are involved in anorexiarelated studies. For example, forced feeding of people with anorexia [20], participation of people with anorexia in fitness classes Giordano [21], and the use of deep brain stimulation to treat patients with anorexia [22].\nIn our study as well, there are some relevant ethical issues, e.g. (1) Whether and how can we present posts authored by girls suspected as being anorexic? (2) How can we ensure that people will not take advantage of vulnerable people?; (3) If there is any intention to contact the girls identified as being anorexic, how can we help them?; and (4)\nWhether and how can we persuade them to be involved in the research?\nWe hypothesize that the application of ML method(s) using heuristic combinations of suitable content-based and style-based feature sets on supervised social datasets related to anorexia can successfully identify, from their text data, females that are likely to be anorexic.\nThe key contributions and innovations of this research are as follows: A labeled anorexia-related dataset of social media posts written in Hebrew was constructed, approved by an international expert in the domain of anorexia, and made available to the public for reproducibility or benchmarking. A set of 50-word n-grams (mostly word unigrams) provided by an expert was found as a good basic detector. In addition, two heuristic methods lead to significant improvements over a baseline result at a level of P= .01: (a) a hill-climbing process that leads to a result of 89.07%using a combination of 372 features from nine feature sets and (b) an iterative process that tests combinations of \u2018\u2018k out of n\u2032\u2019\u2019 where n\u2032< n (the total number of feature sets) for different values of k and n\u2032 lead to the best result of 90.63%, using a combination of 300 features from ten feature sets.\nThe rest of this paper is organized as follows: Section II introduces previous anorexia detection systems related to eRisk tasks. Section III introduces previous mental disorder detection systems. Section IV presents previous datasets alongwith the dataset constructed for this research. Section V introduces the preprocessing methods, ML methods, and the experimental setup. Section VI presents the experimental results and an analysis of the main results. In Section VII, we discuss the implications that this study has and suggest future research. Finally, Section VIII summarizes and concludes this study."
        },
        {
            "heading": "II. PREVIOUS ANOREXIA DETECTION SYSTEMS RELATED",
            "text": ""
        },
        {
            "heading": "TO ERISK TASKS",
            "text": "Since 2017, the eRisk (Early risk prediction on the Internet) lab2 (under the platform of CLEF3 \u2013 Conference and Labs of the Evaluation Forum) organized tasks related to early detection of various mental disorders such as depression and self-harm or anorexia. In 2018 and 2019, eRisk organized tasks related to the early detection of anorexia. The datasets are collections of hundreds of Reddit users labeled as anorexic or non-anorexic along with hundreds of posts and comments (for each user on average) written in English that were recorded chronologically. The positive set is composed of users who explicitly mentioned that they were diagnosed with anorexia, while the negative set is mainly composed of random users from the same social media platform (including users who have close relatives suffering from anorexia).\nThese datasets and the evaluation methodology were constructed using the same methodology and sources as the datasets described in Losada and Crestani [23].\n2https://early.irlab.org/ 3http://www.clef-initiative.eu/\nVOLUME 10, 2022 34801\nThe evaluation of the tasks involves standard measures, such as F1, Recall, and Precision. These measures are time-unaware and do not penalize late decisions. Therefore, Losada et al. [23] defined ERDE (Early Risk Detection Error), an error measure for early risk detection for which the fewer posts and alerts required to raise an alert, the better. Otherwise, there is a penalty for late decisions.\nAn overview of the early risk detection tasks (anorexia and depression) in eRisk 2018 is given in Losada et al. [24]. The dataset of the anorexia task is imbalanced. The organizers received 35 submissions from 9 different teams (each team could submit up to 5 variants or runs). The highest F1 score 0.85 was achieved by the FHDO-BCSGE model [25], which consists of a simple late fusion ensemble approach that has been calculated as the unweighted mean of the outputs obtained from three bags-of-words, including metadata models and two CNN models. The highest precision, recall, and the lowest ERDE scores (0.91, 0.88, 11.4%, respectively) were achieved by various runs of the UNSL models of Funez et al. [26], which were based on a model that uses a semantic representation of documents and a model that carries out an incremental estimation of the association of each user to each class.\nAbout 80%\u2013100%of the non-anorexia users were correctly identified by most of the systems (nearly all non-anorexia users fall in the rangemeaning that at least 80%of the systems labeled them as non-anorexic). In contrast, the distribution of anorexia users is flatter and, in many cases, they are only identified by less than half of the systems. An interesting result is that all anorexia users were identified by at least 10% of the systems. Most of the teams ignored penalties for late decisions and mostly focused on classification accuracy.\nAragon et al. [27] showed that early detection of signs of depression and anorexia of social media authors could be based on the presence of the emotions expressed by the authors. Their study was based on the eRisk-2018 anorexia dataset, which contains posts and comments written by 472 users where only 12.9% of themwere categorized as positive. Aragon et al. [27] created groups of sub-emotions using the EmoLEX lexicon [28] and some word-embedding algorithms. The highest baseline result (F1= 0.82) was obtained by a support vector machine (SVM) using BoSE unigrams (Bag of Sub-Emotions). Using the late fusion method, they improved to F1= 0.84. The performance of deep learning (DL) models (word2vec and Glove) was also tested and was very low.\nLosada et al. [29], in their overview paper, provided an overview of eRisk 2019, related to early risk detection of three tasks related to health and safety: anorexia, depression, and self-harm. The anorexia dataset of eRisk 2019 is also highly imbalanced. The organizers received submissions from 13 teams. Nine teams processed the entire thread of messages (around 2,000 iterations).\nThe highest F1 score (0.71) in eRisk 2019 was achieved by an ensemble approach developed by the ClaC team [30]. Their method employed several attention-based neural\nsub-models that extracted features and predicted class probabilities. These features served as input features to an SVM model. The highest precision score (0.77) and a relatively high F1 score (0.68) were achieved by the LIRMM team [31], which applied a deep mood module that activates several attention-based DL models.\nThe datasets provided in 2018 and 2019 by eRisk, which are highly imbalanced are composed of posts and comments written in English by Reddit users labeled as anorexic or nonanorexic, along with hundreds of posts and comments (for each user in average) that were recorded chronologically. In 2020 and 2021, eRisk did not suggest any task or dataset relevant to Anorexia.\nUban et al. (2021) proposed a DL model to detect signs of people suffering from anorexia in social media. They also tried to explain the behavior of their model. They trained a hierarchical attentionmodel and used its internal encodings to discover different clusters of anorexia symptoms. They interpreted the identified patterns from emotional expressions, personality traits, and psycho-linguistic features. They found patterns of word usage in some users with anorexia, which show that they feel less as being part of a group compared to control cases, as well as that they have abandoned explanatory activity as a result of a greater feeling of helplessness and fear.\nIn contrast, in our study, we worked with a balanced dataset we constructed, which is composed of posts written in Hebrew in Israeli blog forums (or sub-forums) that are located in various public-domain Israeli websites. This dataset was supervised and approved by an international expert in the domain of anorexia (more details in Section IV part B).\nIII. OTHER PREVIOUS MENTAL DISORDER DETECTION SYSTEMS Tsugawa et al. [33] presented a model based on the results of a web-based questionnaire answered by 209 Twitter users regarding their social media activities, to measure their degree of depression. Their best result (accuracy of 0.66 and F-measure of 0.46) was obtained using an SVM based on 17 features: 10 topics extracted using the latent Dirichlet allocation (LDA) model [34], a ratio of positive-affect words contained in tweets, a ratio of negative-affect words contained in tweets, number of tweets per day, overall retweet rate, a ratio of tweets containing a URL, number of followers, and number of users followed.\nWang et al. [35] developed a method that automatically gathers individuals who self-identify as ED in their profile descriptions, as well as in their social network connections with others on Twitter. They also built predictive models to classify users with and without an ED. They explored three different MLmethods: naive Bayes (NB), an SVMwith various kernels, and k-nearest neighbors. The best accuracy result (above 97%) was obtained using a linear SVM with default settings. In their best model, each user is represented as a vector of 97 features composed of 6 social-status features, 11 behavioral features, and 80 psychometric features that\n34802 VOLUME 10, 2022\nmatch each of the 80 psychologically-relevant categories in the Linguistic Inquiry and Word Count (LIWC) lexicon [36].\nShen and Rudzicz [10] presented models that detect anxiety in posts submitted in Reddit. They collected 22,808 posts over three months, 9,971 of them were anxiety-related posts (\u2018\u2018anxiety\u2019\u2019) and 12,837 were general posts (\u2018\u2018control\u2019\u2019). They applied n-gram language modeling, vector embeddings, topic analysis, and emotional norms to generate features that accurately classify posts related to binary levels of anxiety. They obtained an accuracy of 98% in two models: word2vec embeddings combinedwith LIWC features, and n-gram probabilities combined with LIWC.\nBirnbaum et al. [11] introduced models that distinguish between Twitter messages written by 146 users with self-disclosed diagnoses of schizophrenia and 146 users from a control group. The performance was evaluated using a 10-fold cross-validation method (70% training and 30% validation). Their models used the TF-IDF values of the top-500 n-grams and 50 LIWC categories. Then, feature filtering using the ANOVA F-test reduced the feature space from 550 to 350 features. They applied four supervised ML methods: Gaussian na\u00efve Bayes, random forest (RF), logistic regression (LR), and SVM. The best results (accuracy of 0.81 and F-measure of 0.80) were obtained by RF.\nSekuli\u0107 et al. [12] presented a study on the prediction of bipolar disorder from user comments. on Reddit posts written by 3,488 users with self-disclosed diagnoses of bipolar disorder and 3,931 users that were sampled from the general Reddit community. For each user, they extracted three types of features: (1) psycholinguistic features composed of syntactic features (e.g., pronouns and articles), topical features (e.g., work and friends), and psychological features (e.g., emotions and social context) based on LIWC categories, and words using similarities based on neural embeddings found through Empath [37]; (2) lexical features composed of TF-IDF weighted bag-of-words, stemmed using the Porter stemmer from NLTK [38]; (3) and several Reddit user features that attempt to model the user\u2019s interaction patterns. They applied three classifiers: SVM, LR, and RF. The best results (an accuracy of 0.869 and an F1-score of 0.863) were obtained by RF.\nRam\u00edrez-Cifuentes et al. [39] proposed several models for the early detection of anorexia on a collection composed of writings (posts or comments) from a set of Reddit users. Their model used 5,093 features composed of 64 frequencies of words belonging to the categories of the LIWC dictionary [40], 9 anorexia-related categories (anorexia, body image, food and meals, eating, caloric restriction, binging, compensatory behavior, and exercise), 4,303 word unigrams, 665 word bigrams, and 50 topics using LDA. The best results (0.85 for all three measures: F1, precision, and recall) were obtained using an SVM with 50 LDA topics, TFIDF values, 64 LIWC features, and the text length threshold (TLT) feature.\nZhou et al. [41] proposed amental disorder aided diagnosis model that detects people with high probabilities of suffering\nfrom five common adult mental disorders: anxiety disorder, bipolar disorder, depressive disorder, obsessive-compulsive disorder, and panic disorder. The tested documents were tweets collected using relevant mental disorder-related hashtags and timestamp information. The supervised dataset contained 396 users with 5,323 tweets who were considered to have one of the five mental disorders and 400 users with 6,683 tweets whowere considered to have nomental disorder. Using the stochastic gradient descent method they obtained precision, recall, and F1-measure scores of 0.77, 0.92, and 0.84, respectively.\nTadesse et al. [42] proposed several models that distinguish between depressed and non-depressed users in Reddit. The experiments were conducted on a dataset built by Pirina and \u00c7\u00f6ltekin [6]. The dataset contains 1,293 depression-indicative posts and 548 standard posts. The depression-indicative posts were collected from Reddit forums devoted to depression, in which the depressed users asked for support. Standard posts written by non-depressed users were collected from Reddit forums related to family or friends. The authors applied five supervised ML methods (SVM, LR, RF, AdaBoost, and MLP). The best results (accuracy of 0.9 and F1-score of 0.93) were obtained byMLP using word bigrams, LIWC, and LDA features.\nArag\u00f3n et al. [43] proposed a method called a Bag of SubEmotions (BoSE) that represents social media documents. This set of fine-grained emotions is automatically generated using a lexical resource of emotions and subword embeddings from Fast-Text. Using this representation capture topics and emotions that are used for depression detection. The usage of their simple and interpretable method improved the results compared to proposed baselines and a representation based on the core emotions and obtained competitive results in comparison to the state of the art approaches (i.e., related eRisk task winners) that are much more complex and difficult to interpret (most of the participants used plenty of different features and a vast range of models, including deep).\nAlhuzali et al. [44] described a method that detects a sign of depression from users\u2019 posts. Their method applied pretrained models that extract features for all user\u2019s posts and then feed them into an RF classifier, achieving an average hit rate of 32.86% in sub-task 3 of the CLEF 2021 e-risk shared task. Their method achieved reasonable performance. The evaluation showed that different SpanEmo-encoder layers produced different results. The choice of which layer to choose depends on the metric of interest. They also reported some negative results, and hope that it will inspire the community to investigate the correlations/associations between different aspects.\nIV. CONSTRUCTED SUPERVISED DATASETS In this section, we describe, on the one hand, the construction of previous datasets based on social media and on the other hand, the construction of our supervised dataset.\nVOLUME 10, 2022 34803"
        },
        {
            "heading": "A. CONSTRUCTION OF PREVIOUS SUPERVISED DATASETS BASED ON ONLINE SOCIAL MEDIA FROM STUDIES",
            "text": "Several studies have been conducted on the detection of users considered to have a mental illness based on online forums, without being identified as such through a clinical diagnosis. Guntuku et al. [45] introduced 12 studies on automatically detecting mental disorders without relying on diagnoses made by clinicians. The datasets from five studies were based on posts from Twitter, Facebook, and other web forums, written by users who have been self-declared as having a certain mental illness, as well as posts, are written by control users. Most of the described datasets are balanced or relatively balanced.\nWongkoblap et al. [46] presented a review of 48 studies dealing with, among other things, the prediction of various mental health disorders based on data from social media. The datasets in these studies were obtained using two main approaches: (1) directly collecting data from the participants with their consent, using surveys and electronic data collection instruments, and (2) indirectly collecting public posts from social network platforms, based on regular expressions used to search for relevant posts, e.g., \u2018\u2018I was diagnosed with [condition].\u2019\u2019 The authors did not provide details about the balance degree of the studies\u2019 datasets they reviewed.\nThe construction of the eRisk datasets was described in Section II. As mentioned at the end of Section II, in our study, we constructed a dataset that is composed of posts written in Hebrew by Israeli web-users in blog forums (or subforums) that are located in various public-domain Israeli websites. Our dataset is composed of balanced positive and negative sets and was supervised and approved by an international expert on anorexia (see next sub-section). This is in contrast to the previous usually imbalanced datasets, whose positive cases are of users who explicitly mentioned that they were diagnosed with anorexia.\nB. CONSTRUCTION OF OUR SUPERVISED DATASET In this study, we constructed a dataset containing 100 blog posts written in Hebrew that are likely to have been written by girls with anorexia, and 100 blog posts that are likely to have been written by girls without anorexia. The blog posts written by girls probably with anorexia were collected from blog forums (or sub-forums) dedicated to anorexic girls that are located in the following public-domain Israeli websites: http://israblog.org/, https://www.tapuz. co.il/, https://saloona.co.il/, and https://www.fxp.co.il/. In these forums, only posts that were most likely written by girls with anorexia were labeled as \u2018\u2018positive posts.\u2019\u2019 No other posts (e.g., posts written by family members or medical doctors) were selected. \u2018\u2018Negative posts\u2019\u2019 were collected from forums, which are not connected to mental disorders. The construction of this dataset was supervised and approved by Professor Eytan Bachar, an international expert in the field of anorexia [16], [19], [47]\u2013[49]. Professor Bachar approved every post that was labeled as \u2018\u2018positive.\u2019\u2019 We did not approve\neven posts that are likely to have been written by girls with bulimia, which is a related ED, but less dangerous than anorexia in respect to the chances of dying. The constructed dataset will bemade available to the public for reproducibility or benchmarking.\nTable 1 provides general details about the dataset. Most of the posts in the dataset (both positive and negative) were written by teenage girls or young women in their twenties. This is because almost all anorexic females are within these age groups.\nIn addition, 25% of the posts that were labeled as \u2018\u2018negative\u2019\u2019 are likely to have been authored by athletic girls or girls who want to diet. These posts were chosen according to the following simple heuristic rule: posts containing at least one of 50 keywords (e.g., body, sports, athlete, calories, breast, binge, weight loss, starvation, menu, dietitian, food, diet, lean, slim, flat, bones, excess, and weight) that are used by anorexic girls according to an international expert. This was applied to achieve a more challenging dataset in terms of classification because many anorexic girls write about sports and dieting.\nV. PREPROCESSING METHODS, ML METHODS, MODEL, AND EXPERIMENTAL SETUP In this section, we introduce the preprocessing methods, ML methods, and the experimental setup of our study.\nA. PREPROCESSING METHODS In many cases, preprocessing the datasets can \u2018\u2018clean\u2019\u2019 the datasets and improve their quality. There are basic types of preprocessing methods e.g., conversion of uppercase letters into lowercase letters, HTML tag removal, punctuation mark removal, stop-word removal, and word stemming, as well as advanced preprocessing methods such as correction of misspelled words, expansion of abbreviations, and word lemmatization.\n34804 VOLUME 10, 2022\nJianqiang and Xiaolin [50] tested six types of preprocessing methods (expanding acronyms, removing numbers, removing stop words, removing URL links, replacing negative mentions, and reverting words that contain repeated letters into their original English form) on five sentiment datasets. The best preprocessing method in their experiments was the replacement of negative mentions in the n-grams model. This method leads to a significant improvement in almost all classifiers on all datasets.\nHaCohen-Kerner et al. [51] investigated the impact of all possible combinations of six preprocessingmethods (spelling correction, HTML tag removal, converting uppercase letters into lowercase letters, punctuation mark removal, reduction of repeated characters, and stopword removal) on TC in three benchmark mental disorder datasets. In one dataset, the best result showed a significant improvement of approximately 28% over the baseline result using all six preprocessing methods. In the other two datasets, several combinations of preprocessing methods showed minimal improvements over the baseline results.\nIn another study, HaCohen-Kerner et al. [52] explored the influence of various combinations of the same six basic preprocessing methods mentioned in the previous paragraph on TC in four benchmark text corpora using a bag-of-words representation. The general conclusion was that it is always advisable to perform an extensive and systematic variety of preprocessing methods, combined with TC experiments because this contributes to improving TC accuracy.\nB. ML METHODS A wide variety of supervised ML methods are applied in TC tasks. Various classical supervised ML methods were implemented, such as support vector classifier (SVC), RF, and LR. During the last decade, DL methods (e.g., RNN and CNN) and then word embeddings (e.g., Word2vec, GloVe, ELMo, and BERT) become popular in TC.\nIn this research, at the first stage, we applied five classical supervised ML methods: SVC, RF, MLP, LR, and multinomial na\u00efve Bayes (MNB).\nAn SVC is a variant of an SVM [53] implemented in Scikit-Learn. An SVC uses LibSVM [54], which is a rapid implementation of the SVMmethod. An SVM is a supervised ML method that classifies vectors in a feature space into one of two sets, given the training data. It operates by constructing an optimal hyperplane that divides the two sets, either in the original feature space or in higher dimensional kernel space.\nAn RF is an ensemble learning method for classification and regression [55], which constructs a multitude of decision trees. Each tree in the ensemble is generated by randomly selecting the attributes to split at each node, and these features on the training set are used to estimate the best split.\nAn MLP is an artificial neural network [56] based on a network of computational units (perceptrons) interconnected in a feed-forward manner. Typically, perceptrons apply a sigmoid function to the input they obtain and feed the next\nlayer with the output of the function. This model is useful, particularly when the data are not linearly separable.\nAn LR [57], [58] is a linear classification model in which the output value is represented as a linear combination of the input values. A sigmoid function is used to model the probability of \u2018\u2018success.\u2019\u2019\nAn MNB [59], a version of naive Bayes, is a probabilistic generative ML method. MNB is based on Bayes\u2019 theorem with the \u2018\u2018naive\u2019\u2019 assumption of conditional independence between every pair of features, given the value of the class variable. In MNB, each document is viewed as a collection of words whose order is considered irrelevant.\nC. EXPERIMENTAL SETUP We used the accuracy measure to assess the usefulness of the various models. Accuracy is a suitable measure because our dataset is balanced (100 posts of anorexic girls and 100 posts of non-anorexic girls). To indicate which results are statistically significant compared to the baseline results, we ran 20 times 5-fold cross-validation experiments on the dataset to generate 100 performance estimates for Scheme A (any baseline experiment) and 100 estimates for Scheme B (any other experiment). These estimates can be paired because they are generated on the same splits of the dataset. Because the 100 estimates for each of the schemes are not statistically independent, having been generated from different subsets of the same dataset, many researchers (e.g., [60]\u2013[62]) have applied the corrected resampled paired t-test developed by Nadeau and Bengio [63], [64], which has been found to be reliable (providing a false positive rate at the significance level when evaluated on synthetic data).\nVI. EXPERIMENTAL RESULTS In this section, we present the experimental results and an analysis of the main results\nA. BASELINE WORD N-GRAM RESULTS To select the word unigrams for use by the baseline models, we decided to work only with words that appear in at least three blog posts in the training set. An examination of the five pairings of the training and test sets showed that 2,245 is the minimal number of different words that appear. To achieve a reasonable accuracy baseline, based on the number of different words mentioned above, we decided to perform classification experiments on 100, 500, 1,000, 1,500, and 2,000 word unigrams according to both their TF and TF-IDF values, using five different common ML methods. Additionally, we examined the classification according to a list of 50 key expressions (46 word unigrams and 4 word bigrams), provided by an expert on anorexia, that characterize anorexic girls. The rationale behind the experiment was to define reasonable baselines for the discussed task. Table 2 lists the baseline accuracy results when using the above-mentioned features and ML methods.\nAnalysis of the results in Table 2 shows the following: The best baseline result (79.75%) was achieved by RF when\nVOLUME 10, 2022 34805\nusing only the top-500 word unigrams (according to their TF-IDF values). In addition, the TF-IDF results are higher than the TF results for all tested ML methods for almost all tested numbers of word unigrams (except for one out of the 20 cases). Therefore, from now on, in principle, the following experiments will use only the TF-IDF values instead of the TF values. Another noteworthy finding was the relatively high result of 75.70% obtained by MLP using 50 keywords of the expert, which was better than all results achieved using 100 word unigrams by all tested ML methods. That is, the 50 keywords of the expert are better for a basic classification than 100 words with the highest TF-IDF values. A plausible explanation is that expertise is an important asset when we want to apply classification using a relatively low number of word unigrams; it can reduce the number of word unigrams and yet improve the results.\nIn comparison with English, in Hebrew, there are fewer available NLP tools in general, and fewer available preprocessing methods in particular. In this research, we applied only three preprocessing methods: L - conversion of uppercase letters into Lowercase letters only for words in English; A - removal of \u2018.\u2019 from Acronyms, e.g., I.B.M. into IBM; and H - removal of stop words using a basic list of 47 stop words in Hebrew [65]\u2013[67].\nThe tools, libraries, and lists that we used in this study include Python (https://www.python.org/); Scikit-learn (https://scikit-learn.org/stable), a library for ML methods in Python; and NLTK (https://www.nltk.org/), a library that produces various n-gram features and a corpus of synonyms.\nWe conducted classification experiments with all possible combinations of preprocessing methods using the TF-IDF values of the top\u2212100,\u2212500,\u22121000,\u22121500, and\u22122000 frequent words. The best result (80.22%) was obtained by RF with 500 words using the H, A, and L preprocessing methods. This result shows a small and insignificant improvement of 0.47% in comparison with the best baseline result. Both the A and H preprocessing methods substantially change some of the texts in the dataset and prevent the ability to extract various features, e.g., spelling and function words. In contrast, the L preprocessing method, which converts uppercase letters in English into lowercase letters (for all the English letters in our dataset, which is written mainly in Hebrew), is a relatively\nsmall change in the texts in which there are no deletions or insertions of any letters. The application of L leads to a result of 80.0% (a small and insignificant improvement of 0.25% relative to the baseline). Although this improvement is insignificant, we implemented the L preprocessing method in the following experiments because this method is simple to implement easily and quickly and it leads to an improvement.\nB. FEATURE SETS AND A HILL-CLIMBING MODEL 28 feature sets were defined semi-automatically. After reading many of the post blogs, we manually defined 28 feature sets where each set contains a basic list of features. Most of the feature sets are content-based, e.g., food and drink, hunger, vomiting and fasting, ana, calories and weight, anorexia, fat, sickness/illness, weakness and pain, sleep, and sports. Some of the feature sets are style-based, e.g., quantitative and average values, orthographic, limiters, intensifiers, repetition of words and letters, and language richness. Some of the feature sets are sentiment-based, e.g., positive and negative words. Typically, a set contains 5\u2013112 word unigrams and their declensions that are relevant to the set. For instance, the \u2018\u2018ana\u2019\u2019 set contains a few symbolic words describing anorexic girls, e.g., (\u2018\u2018ana\u2019\u2019), (\u2018\u2018to ana\u2019\u2019),\n(\u2018\u2018the ana\u2019\u2019), and (\u2018\u2018pro-ana\u2019\u2019). Table 3 presents the general details of these feature sets. The Hebrew declensions were generated using regular expressions. The resulting words were checked and the illegal ones were filtered out.\nTo determine the best combination of feature sets for a TC task, all possible combinations of the feature sets should be attempted. However, for n = 28 (the number of feature sets), there are 228 (134,217,728) possibilities. To overcome this combinatorial explosion for non-small values of n, several variants of hill-climbing have been proposed, (e.g., [68]). An application of TC to hill-climbing using feature sets was successfully demonstrated in HaCohen-Kerner et al. [69].\nIn this research, we apply the following hill-climbing process. In the first step, TC is applied to each feature set alone. The best feature set is selected from among n feature sets. In the second step, all possible combinations of two feature sets (where one of them is the set chosen in the first stage) are tested, that is, (n\u22121) possible pairs of feature sets are verified in the second step. If the best combination of two sets achieves\n34806 VOLUME 10, 2022\nTABLE 3. Single feature sets.\na better accuracy result than the best single feature set, then the process continues. This process proceeds step by step until no further improvement occurs. Such a hill-climbing model tests amaximal number of n+(n\u22121)+. . .+1 combinations of feature sets. That is, the complexity of this heuristic model is O(n2) instead of O(2n). The rationale behind this experiment was to heuristically find an ML method and a combination of feature sets that achieves an improved classification result using a polynomial run time algorithm.\nIt should be noted that although the method should be discontinued when there is no improvement from one stage to the next, we ran the process to the end even though the result was not always improved because the order of magnitude remained the same and in some cases, the application of the \u2018\u2018extended\u2019\u2019 version improved the result.\nTable 4 presents the accuracy results for the hill-climbing process for feature sets using a 5-fold cross-validation process 20 times. Some of the results are marked with a \u2018\u2018V\u2019\u2019 or \u2018\u2018\u2217,\u2019\u2019 which indicate that a specific result is statistically better or worse than the best baseline result, respectively. To compare the different results, we conducted statistical tests using a\ncorrected paired two-sided t-test with a confidence level of 95%. In cases where the result is statistically better than the best baseline result with a confidence level of 99%, the result\nVOLUME 10, 2022 34807\nwill be marked with \u2018\u2018W\u2019\u2019. The highest accuracy for a single set is 76.47%, which was obtained using LR applied to the FDF (food and drink) set that contains 112 words. This result is lower (but not significantly lower, at a significance level of P= .05) than the baseline result of 79.75%, which was obtained using RF applied to the top-500 words according to their TF-IDF values.\nThe highest accuracy that was obtained during the hillclimbing process was 89.07%W (an improvement of 9.32% over the baseline result, which is statistically significant at a level of P= .01) with the RF using the following nine sets: ACF, AOF, CAF, E50TH, FDF, FRC, HUF, MEF, and VOF, containing 372 features. These sets are composed of seven content-based sets (four of them from the five sets that enabled the best results as single sets) and two style-based sets (ACF (quantitative and average values) and FRC (orthographic features)). The addition of a 10th set reduced the result to 88.8%.\nFigure I shows the best results for each of the 10 steps of the hill-climbing process described in Table 4. We see a high growth rate until the end of the fourth step. After the fourth step, we see the first result (86.17%V), which was significantly better than the best baseline result a level of P= .05. In the next five steps (5\u20139), we see a slight growth rate. After the sixth step, we see the first result (87.5%W), which was significantly better than the best baseline result at a level of P= .01. The best result (89.07%W) was obtained after the ninth step. In the tenth step, the accuracy decreased and the hill-climbing process stopped."
        },
        {
            "heading": "1) CLASSIFICATION USING RNN MODELS",
            "text": "In this stage, we focused on the application of recurrent neural networks (RNNs), which are a class of neural networks that is suitable for modeling sequence data e.g., natural language processing or time series. We applied three common types of RNN models that have tools for sequence analysis, which are implemented by Keras application programming\ninterface (API): SimpleRNN,4 Long Short Term Memory (LSTM) [70], and Gated Recurrent Unit (GRU) [71].\nEach RNN model contained five hidden layers (with 64 nodes in each such layer): encoder layer, embedding layer, a bidirectional layer that contains the RNN layer type (SimpleRNN/LSTM/GRU), and two dense layers. Default parameter values have been used. We ran 20 times 5-fold cross-validation experiments on the dataset and their results are presented in Table 5. The run time on our server of each model was around 2 days. The rationale behind this experiment was to determine whether the use of an RNN method can improve the best classification result.\nAll the results were significantly lower than the baseline result. The best RNN result (67.48%) was obtained using the LSTM model with the text vectorization embedding mode."
        },
        {
            "heading": "2) CLASSIFICATION USING BERT MODELS",
            "text": "We also applied classification using different BERT models based on theHugging Face\u2019s BERTmode5 (BertTokenizer for tokenizing and BertForSequenceClassification for classification) with several pre-trained models. The BertTokenize6 is a class that builds an instance based on some pre-trainedmodel. This class has a function named encode_plus that receives a sequence of words (a string) and returns the corresponding tokens of the sequence and the attention mask. The rationale behind this experiment was to determine whether the use of various models of BERT (the state-of-the-art DLmethod) can improve the best classification result."
        },
        {
            "heading": "3) THE APPLIED BERT MODELS ON THE DATASET",
            "text": "For our dataset, we used 4 different pre-trained models. Two of them were trained especially for Hebrew (AlephBERT and HeBERT) and two of themwere trained for several languages, including Hebrew (WikiBERT and BERT multilingual base). Details about these BERT models are presented below.\n1. AlephBERT: A large pre-trained model for Modern Hebrew introduced by Seker et al. [72] at Bar-Ilan University. This model was trained on 98.7M sentences from 3 different Hebrew text sources: the Hebrew portion of the OSCAR database, tweets in Hebrew collected from Twitter between 2014 - 2018, and the texts of the Hebrew Wikipedia.\n4https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN 5https://huggingface.co/ 6https://huggingface.co/transformers/model_doc/bert.html#berttokenizer\n34808 VOLUME 10, 2022\n2. HeBERT: A Hebrew pre-trained language model introduced by Chriqui and Yahav [73]. This model was trained on over 24.6M sentences from three different Hebrew text sources: the Hebrew portion of the OSCAR, Hebrew dump of Wikipedia, and comments collected between January 2020 to August 2020 from Israeli news websites (Ynet, Israel Hayom, and Be-Hadre Haredim).\n3. WikiBERT: A collection of BERT models for several languages built from Wikipedia texts that was introduced by Pyysalo et al. [74]. We applied the Hebrew version, which was trained on 166M tokens from Hebrew Wikipedia.\n4. BERT multilingual base (cased): a pre-trained model on the top 104 languages with the most extensive Wikipedia that was introduced by Devlin et al. [75]. During the training, the entire Wikipedia was dumped into the model for each one of those 104 languages.\nThe results of these BERTmodels (all of them with 12 hidden layers and a hidden size of 768) on the dataset are presented in Table 6. It is important to note that the run time of each model was around two hours and that the results are relatively low. Therefore, we decided to run thesemodels only one time of 5-fold cross-validation, instead of 20 times 5-fold cross-validation.\nAs expected, the two pre-trained models for Hebrew (HeBERT and AlephBERT) obtained significantly better results than the results of the two multilingual BERT models. Even though the \u2018\u2018Vocab size\u2019\u2019 of the AlephBERT model is higher than the \u2018\u2018Vocab size\u2019\u2019 of the HeBERT model, the result of the HeBERT model was better. A similar phenomenon was found for the two multilingual BERT models. Even though the \u2018\u2018Vocab size\u2019\u2019 of the BERT multilingual base (cased) model is much higher than the \u2018\u2018Vocab size\u2019\u2019 of theWikiBERTmodel, the result of theWikiBERTmodel was better.\nC. THE HEURISTIC METHOD Before presenting the heuristic experiments, we will mention that the best result that has been achieved so far (89.07%W), was obtained using the hill-climbing method. This result using the hill-climbing method was by applying RF using a combination of 9 sets. One of the disadvantages of the hill-climbing method is the risk of falling into the local optimum and not finding the global optimum. On the other hand, as mentioned above, the brute force method that tests all possible combinations of feature sets; the number of such\ncombinations is 2n where n is the number of features sets (28 in our case), and this is unpractical.\nTherefore, we decided to apply a heuristic algorithm that will test only combinations of \u2018\u2018k out of n\u2032\u2019\u2019 items, where n\u2032< n (n is the number of feature sets) and k <= n\u2032. In addition, we must remember that there is a non-negligible run time for each combination (depending on the number of feature sets in the combination, the number of features in each feature set, the applied ML method(s), the time needed to generate the model(s) in the training subset, and the time to activate the constructed model(s) in the test subset). A set composed of hundreds or thousands of combinations might take from a few hours to a few days on our available server (a virtual machine with the following specifications: Intel Xeon Platinum 8168 processor, 8 virtual cores (and later 16 cores), RAM of 32GB, and SSD of 127GB). For instance, the run time of a set of 8,008 combinations while applying only one ML method (RF) was 3 full days, one hour, and one minute.\nThe rationale behind the various experiment of the heuristic methodwas to apply an iterative heuristic process that tests much more combinations than the O(n2) combinations that were tested by the hill-climbing process to achieve a better classification result. Table 7 presents details about various combinations of \u2018\u2018k out of n\u2032\u2019\u2019 (n\u2032< n; n is the number of feature sets) best feature sets and their results. After the application of various experiments, we analyzed all combinations that obtained an accuracy result of at least 88% using the RF ML method (including combinations from the hill-climbing process). We saw that the best combinations contained sets that were not always the best feature sets. We concluded that we should perform experiments of heuristic sets composed of 15 sets, but not the top 15 sets that achieved the best results on their own, but rather the 15 sets with the highest number of occurrences in combinations that achieved 88% and above. These are the new 15 selected feature sets: acf, fdf, frc, vof, aof, e50th, mef, caf, huf, anf, pw, nw, pnf, agf, and wef. It is important to point out that, as expected, many of the selected feature sets, are anorexia (directly- or indirectly-) related sets, e.g., FDF (food and drinks), AOF (anorexia phrases), CAF (calories and weight), ANF (phrases with inflections of \u2018\u2018Anna\u2019\u2019), HUF (hunger), AGF (anger), and E50TH (expert\u2019s 50 terms inHebrew). Another important finding is that among these 15 selected sets, three sets do not appear in the top 15 feature sets that achieved the best results on their own as follows: (1) PNF obtained 53.98\u2217 alone using LR, 21st place; (2) AGF obtained 53.08\u2217 alone using RF, 22nd place; and (3) WEF obtained 52.23\u2217 alone using MNB, 25th place.\nWe run RF on all possible combinations of 9 and 10 sets out of these 15 sets (5,005 and 3,003 combinations, respectively). Table 7 presents the accuracy results (\u2265 89.35%) of set combinations in descending order using the RF ML method.\nThe first combination {vof, huf, aof, pnf, anf, agf, frc, mef, acf, fdf} obtained the best accuracy result (89.62W).\nAt this point, we decided to try two additional well-known directions for further improvements: feature filtering and parameter tuning. The rationale behind these experiments\nVOLUME 10, 2022 34809\nwas to test common improvement methods to improve the best classification result."
        },
        {
            "heading": "1) FEATURE FILTERING",
            "text": "In this stage, using three types of feature filtering methods (Chi^2, ANOVA, and Mutual Information), we performed various experiments to improve the accuracy results achieved by the four combinations that obtained results \u2265 89.3%. The total run time of these experiments was 47 minutes.\nThe use of the Mutual Information feature filtering method on the 1st, 3rd, and 4th combinations and the application of RF on the resulting features led to higher results compared to the results without the filtering. The highest accuracy result (89.8%) was obtained using RF and 300 features after applying the \u2018\u2018Mutual Information\u2019\u2019 feature filtering method on the 1st combination {vof, huf, aof, pnf, anf, agf, frc, mef, acf, fdf}. That is, a tiny improvement of 0.18% was obtained compared to the accuracy result (89.62%) achieved by the 1st combination, which consists of 10 feature sets containing 501 features without any feature filtering and/or parameter tuning."
        },
        {
            "heading": "2) PARAMETER TUNING",
            "text": "We applied parameter tuning on the combination {vof, huf, aof, pnf, anf, agf, frc, mef, acf, fdf} that achieved the highest result without any feature filtering as follows. Using the RandomizedSearchCV class of Sikict-Leran, we tried 150 random combinations of parameters. The best result (90.38W) was obtained by the following combination of parameters: n_estimators= 1900, max_features= sqrt, max_depth= 105, min_samples_split= 5, min_samples_ leaf= 3, and bootstrap = True. Using the same feature set combination, we performed an extended experiment for various parameter combinations (a slightly larger range than the previous range). Although in this stage we tried 625 combinations of various parameters, we did not obtain any improvement."
        },
        {
            "heading": "3) FEATURE FILTERING AND PARAMETER TUNING",
            "text": "In this stage, first we applied feature filtering using Mutual Information on the discussed set combination {vof, huf, aof, pnf, anf, agf, frc, mef, acf, fdf} resulting in 300 features. Then we applied parameter tuning on these 300 features using 150 random combinations of parameters. The total run time for these 150 parameter combinations was 12 minutes. The best result 90.63W was obtained by the following combination of parameters:\nn_estimators=1200, max_features= sqrt, max_depth= 71, min_samples_split= 3, min_samples_leaf= 3, and bootstrap=True."
        },
        {
            "heading": "4) CONCLUSION OF FEATURE FILTERING AND/OR PARAMETER TUNING EXPERIMENTS",
            "text": "Using the best combination {vof, huf, aof, pnf, anf, agf, frc, mef, acf, fdf} that obtained an accuracy result of 89.62W, we applied thousands of feature filtering and/or parameter tuning experiments. The best results are presented in Table 8.\nThe contribution of parameter tuning was higher than the contribution of feature filtering. The application of only feature filtering led to 89.8W (a slight improvement of 0.18) while the application of only parameter tuning led to 90.38W (an improvement of 0.76). The best result 90.63W was achieved using both parameter tuning and feature filtering.\nOur best result (an accuracy of 0.9063) is statistically better than the best baseline result with a confidence level of 99%. This result is competitive in comparison to the state-of \u2013theart results achieved in previous early detection of anorexia tasks (eRisk 2018 and eRisk 2019). The highest F1 score (0.85) in eRisk 2018 was achieved by the FHDO-BCSGE model [25], which consists of a simple late fusion ensemble approach and CNN models. The highest F1 score (0.71) in eRisk 2019was achieved by an ensemble approach developed by the ClaC team [30].\nThe eRisk datasets and our dataset are composed of blog posts. However, there aremany differences, e.g., (1) Our posts are written in Hebrew while the posts in the eRisk are written in English; (2) The eRisk datasets are also composed of comments to the posts while our dataset contains only posts; (3) Each eRisk dataset contains hundreds of Reddit users with hundreds of posts and comments (for each user on average), while our dataset contains only 200 posts; (4) Our dataset is balanced (therefore, the selected measure is accuracy) while the eRisk datasets are imbalanced (therefore, the selected measure is F1); and (5) In the eRisk datasets, the positive posts are of users who explicitly mentioned that they were diagnosed with anorexia, while in our dataset, the positive\n34810 VOLUME 10, 2022\nposts were probably written by anorexic girls and approved by our international expert.\nVII. DISCUSSION AND FUTURE RESEARCH There have been a few systems that dealt with the detection of anorexic girls. Current studies have various limitations (some of them are detailed below).\nVOLUME 10, 2022 34811\nLack of datasets: There is a great lack of datasets on anorexics in general and in the Hebrew language in particular. Current studies mainly apply supervised ML methods that require manual annotation. However, there are not enough (both in number and size) annotated datasets, especially in social datasets. There is also a lack of standards for dataset construction.\nAnnotated constructed datasets are not clinical ground truth: The annotated constructed datasets are not clinical ground truth. That is to say, the blog posts that were labeled as \u2018\u2018positive\u2019\u2019 were probably (and not certainly) written by anorexic girls. These posts were collected from blog forums (or sub forums) dedicated to anorexic girls. Professor Eytan Bachar guided us to collect them as positive posts. He said that the cases of cheaters are negligible and we do not need to worry about them.\nBalanced data vs. imbalanced data: Posts written by anorexic girls are a tiny proportion of social posts (even relative to other mental disorders such as depression and anxiety). However, many datasets related to mental disorders are either balanced or relatively balanced datasets rather than ill-balanced datasets as it is in reality.\nThere is no complete successful detection of anorexic girls: The current ML methods failed to completely detect posts written by anorexic girls. The success of these methods is partial. Nonetheless, there are several learned various statistical clues.\nThere are various challenges for future work. Some of them are presented below.\nApplication of non-classical ML methods: DL methods in general and word embedding vectors such as BERT and other models have boosted research in many domains. Extensive research is expected to also use these methods to detect various mental disorders including anorexia.\nExtend the number and the size of relevant datasets using automatic generation of labeled data: New labeled data can be automatically generated without manual annotation in various methods, e.g., by collecting ground reference data, by using unsupervised or semi-supervised learning, and by using advanced simulators or generative models.\nFor example, Ko and Seo [76] suggest a TC method based on unsupervised or semi-supervised learning. Their method launches TC tasks with unlabeled documents and the title word of each category for learning, and then it automatically learns text classifier by using bootstrapping and feature projection techniques. Labeled data can be generated by generative models from a small amount of labeled data, which can be used for training the classifiers. Examples of such generative models are latent Dirichlet distribution (Blei et al. [77]), restricted Boltzmann Hinton [78], generative adversarial networks (Goodfellow et al. [79]), and a combination of reinforcement learning, generative adversarial networks, and recurrent neural networks (Li et al. [80]). Extend the social text dataset(s) with clinical notes: The addition of clinical notes about the discussed users (in cases\nwhere it is possible) can strengthen the predictive ability and reliability of the classification models.\nAnother interesting future direction is to identify and analyze changes over the temporal information of users participating in social networks. Modeling the temporal track of users\u2019 posts can effectively monitor the change of mental status and it is essential for predicting early signs of anorexia that can be presented to professional experts, to whom the individuals can be referred.\nA better understanding of anorexia: Many factors are relevant to anorexia. A better understanding of this mental disorder can lead to guidelines for better detection ability such as definition and use of more suitable feature sets.\nVIII. SUMMARY AND CONCLUSION In this study, we conducted an extensive and systematic set of experiments for several TC models (e.g., the half-interval search method and the hill-climbing method) on a dataset of post blogs written in Hebrew that we constructed for this study. We defined 28 feature sets and used them with five ML methods, preprocessing methods, three feature filtering methods (Chi^2, ANOVA, and Mutual Information), and parameter tuning.\nTable 9 presents the main accuracy results that were obtained along the stages of this study, as explained above.\nFigure II presents these results graphically. An interesting finding that repeats itself in most systems that are described in Sections II and III and also in our system (Table 9) is that classicalMLmethods (e.g.; SVM andRF) are currently better than DL methods.\nPossible explanations for this finding are: (1) the classical ML methods have been explored and tried much more than the DL methods over the years and on the various datasets; (2) DL methods require large amounts of data to train (Gupta and Gupta [81]; Brauwers and Frasincar [82]), which is not the case in most of the above-mentioned datasets; (3) DL methods are computationally intensive and therefore need advanced computational resources (Montesinos-L\u00f3pez et al. [83]; Ayoub et al. [84]); and (4) Optimization of DL methods requires extensive experiments using different combinations of number of layers, number of units, and number of epochs as well as other parameters [83].\nThemain contributions of this study are a labeled anorexiarelated dataset of social media posts written in Hebrew, which was constructed and approved by an international expert in the domain of anorexia. This dataset was made available to the public for reproducibility or benchmarking. In addition, three insights and novelties were found: A set of 50-word n-grams supplied by an expert was found as a good basic detector. A heuristic process based on the RF ML method, feature filtering, and parameter tuning overcame a combinatorial explosion and lead to significant improvements over a baseline result at a level of P= .01. This process iteratively tested various combinations of \u2018\u2018k out of n\u2032\u2019\u2019 where n\u2032< n (the total number of feature sets) for different values of k and n\u2019\n34812 VOLUME 10, 2022\nlead to the best result of 90.63% using a combination of 300 features from ten feature sets.\nREFERENCES [1] G. Szmukler and D. Bolton, What is Mental Disorder? An Essay in\nPhilosophy, Science, and Values. London, U.K.: Oxford Univ. Press, 2008, p. 321. [2] S. L. James et al., \u2018\u2018Global, regional, and national incidence, prevalence, and years lived with disability for 354 diseases and injuries for 195 countries and territories, 1990\u20132017: A systematic analysis for the global burden of disease study 2017,\u2019\u2019 Lancet, vol. 392, pp. 1789\u20131858, Nov. 2018. [3] P. S. Wang, S. Aguilar-Gaxiola, J. Alonso, M. C. Angermeyer, G. Borges, E. J. Bromet, R. Bruffaerts, G. De Girolamo, R. De Graaf, O. Gureje, and J. M. Haro, \u2018\u2018Use of mental health services for anxiety, mood, and substance disorders in 17 countries in the WHO world mental health surveys,\u2019\u2019 Lancet, vol. 370, no. 9590, pp. 841\u2013850, Sep. 2007. [4] G. Coppersmith, C. Harman, and M. Dredze, \u2018\u2018Measuring post traumatic stress disorder in Twitter,\u2019\u2019 in Proc. 8th Int. AAAI Conf. Weblogs Social Media, 2014, pp. 1\u20134. [5] R. L. Frost and D. J. Rickwood, \u2018\u2018A systematic review of the mental health outcomes associated with Facebook use,\u2019\u2019 Comput. Hum. Behav., vol. 76, pp. 576\u2013600, Nov. 2017. [6] I. Pirina and \u00c7. \u00c7\u00f6ltekin, \u2018\u2018Identifying depression on reddit: The effect of training data,\u2019\u2019 in Proc. EMNLP Workshop SMM4H, 3rd Social Media Mining Health Appl. Workshop Shared Task, 2018, pp. 9\u201312. [7] G. Coppersmith, M. Dredze, C. Harman, and K. Hollingshead, \u2018\u2018From ADHD to SAD: Analyzing the language of mental health on Twitter through self-reported diagnoses,\u2019\u2019 inProc. 2ndWorkshop Comput. Linguistics Clin. Psychol., From Linguistic Signal Clin. Reality, 2015, pp. 1\u201310. [8] A. Trifan, R. Antunes, S.Matos, and J. L. Oliveira, \u2018\u2018Understanding depression from psycholinguistic patterns in social media texts,\u2019\u2019 in Advances in Information Retrieval, vol. 12036. Cham, Switzerland: Springer, 2020, pp. 402\u2013409. [9] M. M. Tadesse, H. Lin, B. Xu, and L. Yang, \u2018\u2018Detection of suicide ideation in social media forums using deep learning,\u2019\u2019 Algorithms, vol. 13, no. 1, p. 7, Dec. 2019. [10] J. H. Shen and F. Rudzicz, \u2018\u2018Detecting anxiety through reddit,\u2019\u2019 in Proc. 4th Workshop Comput. Linguistics Clin. Psychol. From Linguistic Signal Clin. Reality, 2017, pp. 58\u201365. [11] M. L. Birnbaum, S. K. Ernala, A. F. Rizvi, M. De Choudhury, and J. M. Kane, \u2018\u2018A collaborative approach to identifying social media markers of schizophrenia by employing machine learning and clinical appraisals,\u2019\u2019 J. Med. Internet Res., vol. 19, no. 8, p. e289, Aug. 2017. [12] I. Sekuli\u0107, M. Gjurkovi\u0107, and J. \u0160najder, \u2018\u2018Not just depressed: Bipolar disorder prediction on reddit,\u2019\u2019 2018, arXiv:1811.04655. [13] A. Honey andC. Halse, \u2018\u2018The specifics of coping: Parents of daughters with anorexia nervosa,\u2019\u2019 Qualitative Health Res., vol. 16, no. 5, pp. 611\u2013629, May 2006. [14] D. E. Pawluck and K. M. Gorey, \u2018\u2018Secular trends in the incidence of anorexia nervosa: Integrative review of population-based studies,\u2019\u2019 Int. J. Eating Disorders, vol. 23, no. 4, pp. 347\u2013352, May 1998. [15] R. L. Palmer, \u2018\u2018Death in anorexia nervosa,\u2019\u2019 Lancet, vol. 361, no. 9368, p. 1490, May 2003. [16] E. Bachar, Y. Latzer, S. Kreitler, and E. M. Berry, \u2018\u2018Empirical comparison of two psychological therapies: Self psychology and cognitive orientation in the treatment of anorexia and bulimia,\u2019\u2019 J. Psychotherapy Pract. Res., vol. 8, no. 2, p. 115, 1999. [17] Diagnostic and Statistical Manual of Mental Disorders, 5th ed., Amer. Psychiatric Assoc., Washington, DC, USA, 2013, vol. 21. [18] H. Bruch, \u2018\u2018Four decades of eating disorders,\u2019\u2019 inHandbook of Psychotherapy for Anorexia Nervosa and Bulimia. NewYork, NY, USA: The Guilford Press, 1985, pp. 7\u201318. [19] E. Bachar and A. Verbin, Psychodynamic Self Psychology in the Treatment of Anorexia and Bulimia. London, U.K.: Routledge, 2020. [20] P. C. H\u00e9bert and M. A. Weingarten, \u2018\u2018The ethics of forced feeding in anorexia nervosa,\u2019\u2019 Can. Med. Assoc. J., vol. 144, p. 141, Jan. 1991. [21] S. Giordano, \u2018\u2018Risk and supervised exercise: The example of anorexia to illustrate a new ethical issue in the traditional debates of medical ethics,\u2019\u2019 J. Med. Ethics, vol. 31, no. 1, pp. 15\u201320, Jan. 2005. [22] H. Maslen, J. Pugh, and J. Savulescu, \u2018\u2018The ethics of deep brain stimulation for the treatment of anorexia nervosa,\u2019\u2019 Neuroethics, vol. 8, no. 3, pp. 215\u2013230, Dec. 2015.\n[23] D. E. Losada and F. Crestani, \u2018\u2018A test collection for research on depression and language use,\u2019\u2019 in Proc. Int. Conf. Cross-Lang. Eval. Forum Eur. Lang., 2016, pp. 28\u201339. [24] D. E. Losada, F. Crestani, and J. Parapar, \u2018\u2018Overview of eRisk: Early risk prediction on the internet,\u2019\u2019 in Proc. Int. Conf. Cross-Lang. Eval. Forum Eur. Lang., 2018, pp. 343\u2013361. [25] M. Trotzek, S. Koitka, and C. M. Friedrich, \u2018\u2018Word embeddings and linguistic metadata at the CLEF 2018 tasks for early detection of depression and anorexia,\u2019\u2019 in Proc. CLEF, Working Notes, 2018, pp. 1\u201315. [26] D. G. Funez, M. J. G. Ucelay, M. P. Villegas, S. Burdisso, L. C. Cagnina, M. Montes-y-G\u00f3mez, and M. Errecalde, \u2018\u2018UNSL\u2019s participation at eRisk 2018 lab,\u2019\u2019 in Proc. CLEF, Working Notes, 2018, pp. 1\u201311. [27] M. E. Aragon, A. P. Lopez-Monroy, L.-C.-G. Gonzalez-Gurrola, and M. Montes, \u2018\u2018Detecting mental disorders in social media through emotional patterns\u2014The case of anorexia and depression,\u2019\u2019 IEEE Trans. Affect. Comput., early access, Apr. 27, 2021, doi: 10.1109/TAFFC.2021.3075638. [28] S. M. Mohammad and P. D. Turney, \u2018\u2018Crowdsourcing a word\u2013emotion association lexicon,\u2019\u2019 Comput. Intell., vol. 29, no. 3, pp. 436\u2013465, Aug. 2013. [29] D. E. Losada, F. Crestani, and J. Parapar, \u2018\u2018Overview of eRisk 2019 early risk prediction on the internet,\u2019\u2019 in Proc. Int. Conf. Cross-Lang. Eval. Forum Eur. Lang., 2019, pp. 340\u2013357. [30] E. Mohammadi, H. Amini, and L. Kosseim, \u2018\u2018Quick and (maybe not so) easy detection of anorexia in social media posts,\u2019\u2019 in Proc. CLEF (Working Notes), 2019, pp. 1\u201314. [31] W. Ragheb, J. Az\u00e9, S. Bringay, and M. Servajean, \u2018\u2018Attentive multi-stage learning for early risk detection of signs of anorexia and self-harm on social media,\u2019\u2019 in Proc. CLEF (Working Notes), 2019, pp. 1\u201315. [32] A. S. Uban, B. Chulvi, and P. Rosso, \u2018\u2018Understanding patterns of anorexia manifestations in social media data with deep learning,\u2019\u2019 in Proc. 7th Workshop Comput. Linguistics Clin. Psychol., Improving Access, 2021, pp. 224\u2013236. [33] S. Tsugawa, Y. Kikuchi, F. Kishino, K. Nakajima, Y. Itoh, and H. Ohsaki, \u2018\u2018Recognizing depression from Twitter activity,\u2019\u2019 in Proc. 33rd Annu. ACM Conf. Hum. Factors Comput. Syst., Apr. 2015, pp. 3187\u20133196. [34] D. M. Blei, A. Y. Ng, and M. I. Jordan, \u2018\u2018Latent Dirichlet allocation,\u2019\u2019 J. Mach. Learn. Res., vol. 3, pp. 993\u20131022, Mar. 2003. [35] T. Wang, M. Brede, A. Ianni, and E. Mentzakis, \u2018\u2018Detecting and characterizing eating-disorder communities on social media,\u2019\u2019 in Proc. 10th ACM Int. Conf. Web Search Data Mining, Feb. 2017, pp. 91\u2013100. [36] Y. R. Tausczik and J. W. Pennebaker, \u2018\u2018The psychological meaning of words: LIWC and computerized text analysis methods,\u2019\u2019 J. Lang. Social Psychol., vol. 29, no. 1, pp. 24\u201354, Mar. 2010. [37] E. Fast, B. Chen, and M. S. Bernstein, \u2018\u2018Empath: Understanding topic signals in large-scale text,\u2019\u2019 in Proc. CHI Conf. Hum. Factors Comput. Syst., May 2016, pp. 4647\u20134657. [38] S. Bird, E. Klein, and E. Loper,Natural Language ProcessingWith Python: Analyzing Text With the Natural Language Toolkit. Sebastopol, CA, USA: O\u2019Reilly Media, 2009. [39] D. Ram\u00edrez-Cifuentes, M. Mayans, and A. Freire, \u2018\u2018Early risk detection of anorexia on social media,\u2019\u2019 in Proc. Int. Conf. Internet Sci., 2018, pp. 3\u201314. [40] J. W. Pennebaker, R. L. Boyd, K. Jordan, and K. Blackburn, \u2018\u2018The development and psychometric properties of LIWC2015,\u2019\u2019 Dept. Psychol., Univ. Texas Austin, Austin, TX, USA, Tech. Rep., 2015. [41] T. Zhou, G. Hu, and L. Wang, \u2018\u2018Psychological disorder identifying method based on emotion perception over social networks,\u2019\u2019 Int. J. Environ. Res. Public Health, vol. 16, no. 6, p. 953, Mar. 2019. [42] M. M. Tadesse, H. Lin, B. Xu, and L. Yang, \u2018\u2018Detection of depressionrelated posts in reddit social media forum,\u2019\u2019 IEEE Access, vol. 7, pp. 44883\u201344893, 2019. [43] M. E. Arag\u00f3n, A. P. L\u00f3pez-Monroy, L. C. Gonz\u00e1lez-Gurrola, and M. Montes-y-G\u00f3mez, \u2018\u2018Detecting depression in social media using finegrained emotions,\u2019\u2019 in Proc. Conf. North Amer. Chapter Assoc. Comput. Linguistics, Hum. Lang. Technol., vol. 1, 2019, pp. 1481\u20131486. [44] H. Alhuzali, T. Zhang, and S. Ananiadou, \u2018\u2018Predicting sign of depression via using frozen pre-trained models and random forest classifier,\u2019\u2019 in Proc. Working Notes CLEF, 2021, pp. 21\u201324. [45] S. C. Guntuku, D. B. Yaden, M. L. Kern, L. H. Ungar, and J. C. Eichstaedt, \u2018\u2018Detecting depression and mental illness on social media: An integrative review,\u2019\u2019 Current Opinion Behav. Sci., vol. 18, pp. 43\u201349, Dec. 2017. [46] A.Wongkoblap, M. A. Vadillo, and V. Curcin, \u2018\u2018Researching mental health disorders in the era of social media: Systematic review,\u2019\u2019 J. Med. Internet Res., vol. 19, no. 6, p. e228, Jun. 2017.\nVOLUME 10, 2022 34813\n[47] L. Canetti, E. Bachar, and E. M. Berry, \u2018\u2018Food and emotion,\u2019\u2019 Behav. Process., vol. 60, no. 2, pp. 157\u2013164, 2002. [48] Y. Latzer, Z. Hochdorf, E. Bachar, and L. Canetti, \u2018\u2018Attachment style and family functioning as discriminating factors in eating disorders,\u2019\u2019Contemp. Family Therapy, vol. 24, pp. 581\u2013599, Dec. 2002. [49] U. Pinus, L. Canetti, O. Bonne, and E. Bachar, \u2018\u2018Selflessness as a predictor of remission from an eating disorder: 1\u20134 year outcomes from an adolescent day-care unit,\u2019\u2019 Eating Weight Disorders Stud. Anorexia, Bulimia Obesity, vol. 24, no. 4, pp. 777\u2013786, Aug. 2019. [50] Z. Jianqiang and G. Xiaolin, \u2018\u2018Comparison research on text preprocessing methods on Twitter sentiment analysis,\u2019\u2019 IEEE Access, vol. 5, pp. 2870\u20132879, 2017. [51] Y. HaCohen-Kerner, Y. Yigal, and D.Miller, \u2018\u2018The impact of preprocessing on classification ofmental disorders,\u2019\u2019 inProc. 19th Ind. Conf. DataMining (ICDM), New York, NY, USA, 2019, pp. 52\u201366. [52] Y. HaCohen-Kerner, D. Miller, and Y. Yigal, \u2018\u2018The influence of preprocessing on text classification using a bag-of-words representation,\u2019\u2019 PLoS ONE, vol. 15, no. 5, May 2020, Art. no. e0232525. [53] C. Cortes and V. Vapnik, \u2018\u2018Support-vector networks,\u2019\u2019 Mach. Learn., vol. 20, pp. 273\u2013297, Sep. 1995. [54] C. C. Chang and C. J. Lin, \u2018\u2018LIBSVM: A library for support vector machines,\u2019\u2019 ACM Trans. Intell. Syst. Technol., vol. 2, no. 3, pp. 1\u201327, 2011. [55] L. Breiman, \u2018\u2018Random forests,\u2019\u2019 Mach. Learn., vol. 45, no. 1, pp. 5\u201332, 2001. [56] F. Murtagh, \u2018\u2018Multilayer perceptrons for classification and regression,\u2019\u2019 Neurocomputing, vol. 2, nos. 5\u20136, pp. 183\u2013197, Jul. 1991. [57] D. R. Cox, \u2018\u2018The regression analysis of binary sequences,\u2019\u2019 J. Roy. Stat. Soc. B, Methodol., vol. 20, no. 2, pp. 215\u2013232, 1958. [58] D. W. Hosmer, Jr., S. Lemeshow, and R. X. Sturdivant, Applied Logistic Regression, vol. 398. Hoboken, NJ, USA: Wiley, 2013. [59] M. Kibriya, E. Frank, B. Pfahringer, and G. Holmes, \u2018\u2018Multinomial Naive Bayes for text categorization revisited,\u2019\u2019 in Proc. Australas. Joint Conf. Artif. Intell., Berlin, Germany, 2004, pp. 488\u2013499. [60] E. Frank and R. R. Bouckaert, \u2018\u2018Naive Bayes for text classification with unbalanced classes,\u2019\u2019 in Proc. Eur. Conf. Princ. Data Mining Knowl. Discovery, 2006, pp. 503\u2013510. [61] T. Kanamori, \u2018\u2018Deformation of log-likelihood loss function for multiclass boosting,\u2019\u2019 Neural Netw., vol. 23, no. 7, pp. 843\u2013864, Sep. 2010. [62] M. Sabzevari, G. Mart\u00ednez-Mu\u00f1oz, and A. Su\u00e1rez, \u2018\u2018Vote-boosting ensembles,\u2019\u2019 Pattern Recognit., vol. 83, pp. 119\u2013133, Dec. 2018. [63] C. Nadeau and Y. Bengio, \u2018\u2018Inference for the generalization error,\u2019\u2019 in Proc. Adv. Neural Inf. Process. Syst., vol. 12, 2000, pp. 307\u2013313. [64] C. Nadeau and Y. Bengio, \u2018\u2018Inference for the generalization error,\u2019\u2019Mach. Learn., vol. 52, no. 3, pp. 239\u2013281, Sep. 2003. [65] Y. HaCohen-Kerner, E. Malin, and I. Chasson, \u2018\u2018Summarization of Jewish law articles in Hebrew,\u2019\u2019 in Proc. CAINE, 2003, pp. 172\u2013177. [66] Y. HaCohen-Kerner and S. Y. Blitz, \u2018\u2018Initial experiments with extraction of stopwords in Hebrew,\u2019\u2019 in Proc. KDIR, 2010, pp. 449\u2013453. [67] Y. HaCohen-Kerner, R. Dilmon, M. Hone, and M. A. Ben-Basan, \u2018\u2018Automatic classification of complaint letters according to service provider categories,\u2019\u2019 Inf. Process. Manage., vol. 56, no. 6, Nov. 2019, Art. no. 102102. [68] S. Baluja, \u2018\u2018An empirical comparison of seven iterative and evolutionary function optimization heuristics,\u2019\u2019 Dept. Comput. Sci., Carnegie-Mellon Univ., Pittsburgh, PA, USA, Tech. Rep. NASA-CR-201901, 1995. [69] Y. HaCohen-Kerner, H. Beck, E. Yehudai, M. Rosenstein, and D. Mughaz, \u2018\u2018Cuisine: Classification using stylistic feature sets and/or name-based feature sets,\u2019\u2019 J. Amer. Soc. Inf. Sci. Technol., vol. 61, pp. 1644\u20131657, 2010. [70] S. Hochreiter and J. Schmidhuber, \u2018\u2018LSTM can solve hard long time lag problems,\u2019\u2019 in Proc. Adv. Neural Inf. Process. Syst., 1997, pp. 473\u2013479. [71] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, \u2018\u2018Empirical evaluation of gated recurrent neural networks on sequence modeling,\u2019\u2019 2014, arXiv:1412.3555. [72] A. Seker, E. Bandel, D. Bareket, I. Brusilovsky, R. Shaked Greenfeld, and R. Tsarfaty, \u2018\u2018AlephBERT: A Hebrew large pre-trained language model to start-off your Hebrew NLP application with,\u2019\u2019 2021, arXiv:2104.04052. [73] A. Chriqui and I. Yahav, \u2018\u2018HeBERT & HebEMO: A Hebrew BERT model and a tool for polarity analysis and emotion recognition,\u2019\u2019 2021, arXiv:2102.01909. [74] S. Pyysalo, J. Kanerva, A. Virtanen, and F. Ginter, \u2018\u2018WikiBERT models: Deep transfer learning for many languages,\u2019\u2019 2020, arXiv:2006.01538. [75] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, \u2018\u2018BERT: Pre-training of deep bidirectional transformers for language understanding,\u2019\u2019 2018, arXiv:1810.04805.\n[76] Y. Ko and J. Seo, \u2018\u2018Text classification from unlabeled documents with bootstrapping and feature projection techniques,\u2019\u2019 Inf. Process. Manage., vol. 45, no. 1, pp. 70\u201383, Jan. 2009. [77] D. M. Blei, A. Y. Ng, and M. I. Jordan, \u2018\u2018Latent Dirichlet allocation,\u2019\u2019 J. Mach. Learn. Res., vol. 3, pp. 993\u20131022, Jan. 2003. [78] G. E. Hinton, \u2018\u2018A practical guide to training restricted Boltzmann machines,\u2019\u2019 in Neural Networks: Tricks of the Trade. Berlin, Germany: Springer, 2012, pp. 599\u2013619. [79] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, \u2018\u2018Generative adversarial nets,\u2019\u2019 in Proc. Adv. Neural Inf. Process. Syst., vol. 27, 2014, pp. 1\u20139. [80] Y. Li, Q. Pan, S. Wang, T. Yang, and E. Cambria, \u2018\u2018A generative model for category text generation,\u2019\u2019 Inf. Sci., vol. 450, pp. 301\u2013315, Jun. 2018. [81] S. Gupta and S. K. Gupta, \u2018\u2018Abstractive summarization: An overview of the state of the art,\u2019\u2019 Expert Syst. Appl., vol. 121, pp. 49\u201365, May 2019. [82] G. Brauwers and F. Frasincar, \u2018\u2018A survey on aspect-based sentiment classification,\u2019\u2019 ACM Comput. Surv., Dec. 2021, p. 35. [83] A.Montesinos-L\u00f3pez, O. A.Montesinos-L\u00f3pez, D. Gianola, J. Crossa, and C.M. Hern\u00e1ndez-Su\u00e1rez, \u2018\u2018Multi-environment genomic prediction of plant traits using deep learners with dense architecture,\u2019\u2019 G3, Genes, Genomes, Genetics, vol. 8, no. 12, pp. 3813\u20133828, Dec. 2018. [84] J. Ayoub, X. J. Yang, and F. Zhou, \u2018\u2018Combat COVID-19 infodemic using explainable natural language processing models,\u2019\u2019 Inf. Process. Manage., vol. 58, no. 4, Jul. 2021, Art. no. 102569.\nYAAKOV HACOHEN-KERNER received the Ph.D. degree in computer science from Bar-Ilan University, Ramat-Gan, Israel. He is the Dean of the Faculty of Engineering and Computer Science, JerusalemCollege of Technology (JCT). He is also with the CSDepartment, JCT. He has authored and coauthored 104 papers. His current research interests include text classification, sentiment analysis, author profiling, word completion and prediction, key-phrase extraction, citation extraction and anal-\nysis, plagiarism detection, and composition of chess problems.\nNATAN MANOR received the bachelor\u2019s degree in software engineering from the Jerusalem College of Technology (JCT). Together with his partner Michael Goldmeier, they finished their final graduation project under the guidance of Yaakov Hacohen-Kerner. He is a coauthor of two previous articles in the text classification domain together with Yaakov Hacohen-Kerner.\nMICHAEL GOLDMEIER received the bachelor\u2019s degree in software engineering from the Jerusalem College of Technology (JCT). Together with his partner Natan Manor, they finished their final graduation project under the guidance of Yaakov Hacohen-Kerner. He is a coauthor of a previous article in the text classification domain together with his partner and Yaakov Hacohen-Kerner.\nEYTAN BACHAR received the Ph.D. degree in psychology from The Hebrew University of Jerusalem, Jerusalem, Israel. He is the Head Psychologist of theHadassahUniversityMedical Center, Jerusalem, an Associate Professor with the Hebrew University of Jerusalem, and a Former Chair of the Israeli Association of Eating Disorders. He is a highly experienced Expert in eating disorders and post-traumatic stress disorders (PTSD). His research interests include psychologi-\ncal factors contributing to the onset, maintenance and treatment of twomental disorders: eating disorders and post-traumatic stress disorders.\n34814 VOLUME 10, 2022"
        }
    ],
    "title": "Detection of Anorexic Girls-In Blog Posts Written in Hebrew Using a Combined Heuristic AI and NLP Method",
    "year": 2022
}