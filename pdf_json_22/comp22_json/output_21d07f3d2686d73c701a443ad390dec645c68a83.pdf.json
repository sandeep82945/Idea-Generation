{
    "abstractText": "A hardware-based control flow monitoring technique enables the detection of errors in both the control flow and the instruction stream executed on a processor. However, as shown in recent publications, these techniques fail to detect malicious carefully-tuned manipulations of the instruction stream in a basic block. This paper presents a non-linear encoder and checker that can cope with this weakness. It is a MAC based control flow checker that has the advantage of working with basic blocks of variable length, can detect every error, and performs the computation in real-time. The architecture can easily be modified to support different signature size and error masking probabilities. Keywords\u2014 Embedded Security, Control Flow Checking, NonLinear Codes, Signature, Countermeasures",
    "authors": [
        {
            "affiliations": [],
            "name": "G. Dar"
        },
        {
            "affiliations": [],
            "name": "Giorgio Di Natale"
        },
        {
            "affiliations": [],
            "name": "Gilad Dar"
        },
        {
            "affiliations": [],
            "name": "Osnat Keren"
        }
    ],
    "id": "SP:dbf9d0602159644dee1014b198d5b59237d9d70f",
    "references": [
        {
            "authors": [
                "A. Shrivastava",
                "A. Rhisheekesan",
                "R. Jeyapaul",
                "C.-J. Wu"
            ],
            "title": "Quantitative analysis of control flow checking mechanisms for soft errors",
            "venue": "Proceedings of the 51st Annual Design Automation Conference, DAC \u201914, (New York, NY, USA), pp. 13:1\u201313:6, ACM, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "A. Benso",
                "S. Di Carlo",
                "G. Di Natale",
                "P. Prinetto"
            ],
            "title": "A watchdog processor to detect data and control flow errors",
            "venue": "9th IEEE On- Line Testing Symposium, 2003. IOLTS 2003., pp. 144\u2013148, July 2003.",
            "year": 2003
        },
        {
            "authors": [
                "A. Chaudhari",
                "J. Park",
                "J. Abraham"
            ],
            "title": "A framework for low overhead hardware based runtime control flow error detection and recovery",
            "venue": "IEEE 31st VLSI Test Symposium (VTS), Berkeley, CA, pp. 1\u20135, IEEE, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "J. Abraham",
                "R. Vemu"
            ],
            "title": "Control flow deviation detection for software security",
            "venue": "Mar. 11 2010. WO Patent App. PCT/US2009/047,390.",
            "year": 2010
        },
        {
            "authors": [
                "R. de Clercq",
                "I. Verbauwhede"
            ],
            "title": "A survey of hardware-based control flow integrity (CFI)",
            "venue": "CoRR, vol. abs/1706.07257, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "R. d. Clercq",
                "R.D. Keulenaer",
                "B. Coppens",
                "B. Yang",
                "P. Maene",
                "K. d. Bosschere",
                "B. Preneel",
                "B. d. Sutter",
                "I. Verbauwhede"
            ],
            "title": "Sofia: Software and control flow integrity architecture",
            "venue": "2016 Design, Automation Test in Europe Conference Exhibition (DATE), pp. 1172\u20131177, March 2016.",
            "year": 2016
        },
        {
            "authors": [
                "D. Arora",
                "S. Ravi",
                "A. Raghunathan",
                "N.K. Jha"
            ],
            "title": "Hardwareassisted run-time monitoring for secure program execution on embedded processors",
            "venue": "IEEE Transactions on Very Large Scale Integration (VLSI) Systems, vol. 14, pp. 1295\u20131308, Dec 2006.",
            "year": 2006
        },
        {
            "authors": [
                "M. Werner",
                "R. Schilling",
                "T. Unterluggauer",
                "S. Mangard"
            ],
            "title": "Protecting risc-v processors against physical attacks",
            "venue": "2019 Design, Automation Test in Europe Conference Exhibition (DATE), pp. 1136\u20131141, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "A. Mahmood",
                "E.J. McCluskey"
            ],
            "title": "Concurrent error detection using watchdog processors-a survey",
            "venue": "IEEE Transactions on Computers, vol. 37, pp. 160\u2013174, Feb 1988.",
            "year": 1988
        },
        {
            "authors": [
                "K. Wilken",
                "J.P. Shen"
            ],
            "title": "Continuous signature monitoring: efficient concurrent-detection of processor control errors",
            "venue": "International Test Conference New Frontiers in Testing, pp. 914\u2013 925, Sep. 1988.",
            "year": 1988
        },
        {
            "authors": [
                "M. Werner",
                "E. Wenger",
                "S. Mangard"
            ],
            "title": "Protecting the control flow of embedded processors against fault attacks",
            "venue": "Smart Card Research and Advanced Applications (N. Homma and M. Medwed, eds.), (Cham), pp. 161\u2013176, Springer International Publishing, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "Y. Xie",
                "X. Xue",
                "J. Yang",
                "Y. Lin",
                "Q. Zou",
                "R. Huang",
                "J. Wu"
            ],
            "title": "A logic resistive memory chip for embedded key storage with physical security",
            "venue": "IEEE Transactions on Circuits and Systems II: Express Briefs, vol. 63, pp. 336\u2013340, April 2016.",
            "year": 2016
        },
        {
            "authors": [
                "L. Cojocar",
                "K. Razavi",
                "C. Giuffrida",
                "H. Bos"
            ],
            "title": "Exploiting correcting codes: On the effectiveness of ecc memory against rowhammer attacks",
            "venue": "2019 IEEE Symposium on Security and Privacy (SP), pp. 55\u201371, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "N/A (requires an AES cipher) [18] N/A (requires an RSA cipher) [24] 3500 2nd International Verification",
                "Security Workshop (IVSW)",
                "Thessaloniki",
                "pp. 51\u201356",
                "IEEE",
                "2017. [15] Z. Wang",
                "M. Karpovsky",
                "\u201cAlgebraic manipulation detection codes",
                "their applications for design of secure cryptographic devices",
                "\u201d in On-Line Testing Symposium (IOLTS)",
                "2011 IEEE 17th International",
                "pp. 234\u2013239",
                "IEEE",
                "2011. [16] A.M. Fiskiran",
                "R.B. Lee"
            ],
            "title": "Runtime execution monitoring (rem) to detect and prevent malicious code execution",
            "venue": "IEEE International Conference on Computer Design: VLSI in Computers and Processors, 2004. ICCD 2004. Proceedings., pp. 452\u2013 457, Oct 2004.",
            "year": 2004
        },
        {
            "authors": [
                "A.T. Abdalsatir",
                "A.J. Abboud"
            ],
            "title": "Integrity checking of several program codes",
            "venue": "Journal of Engineering and Applied Sciences, 01 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J. Danger",
                "A. Facon",
                "S. Guilley",
                "K. Heydemann",
                "U. K\u00fchne",
                "A. Si Merabet",
                "M. Timbert"
            ],
            "title": "Ccfi-cache: A transparent and flexible hardware protection for code and control-flow integrity",
            "venue": "2018 21st Euromicro Conference on Digital System Design (DSD), pp. 529\u2013536, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "C. Bresch",
                "D. H\u00e9ly",
                "R. Lysecky",
                "S. Chollet",
                "I. Parissis"
            ],
            "title": "Trustflow-x: A practical framework for fine-grained controlflow integrity in critical systems",
            "venue": "ACM Trans. Embed. Comput. Syst., vol. 19, Sept. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "P. Delsarte",
                "J. Goethals",
                "F.M. Williams"
            ],
            "title": "On generalized reedmuller codes and their relatives",
            "venue": "Information and Control, vol. 16, no. 5, pp. 403 \u2013 442, 1970.",
            "year": 1970
        },
        {
            "authors": [
                "G.D. Natale",
                "O. Keren"
            ],
            "title": "Nonlinear codes for control flow checking",
            "venue": "2020 IEEE European Test Symposium (ETS), pp. 1\u2013 6, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "N. Rangarajan",
                "S. Patnaik",
                "J. Knechtel",
                "O. Sinanoglu",
                "S. Rakheja"
            ],
            "title": "Smart: A secure magnetoelectric antiferromagnetbased tamper-proof non-volatile memory",
            "venue": "IEEE Access, vol. 8, p. 76130\u201376142, 2020.",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Keywords\u2014 Embedded Security, Control Flow Checking, NonLinear Codes, Signature, Countermeasures\nI. INTRODUCTION\nDependability is an important characteristic of modern computing systems. The hardware components of a system can be affected by faults deriving from different root causes such as environmental perturbations (e.g., radiation, electromagnetic interference) or malicious attacks (e.g., fault attacks, software modification or replacement).\nMany techniques have been proposed to cope with transient, permanent and malicious fault. These techniques for reliability improvement and fault tolerance target both the hardware and the software, and rely on different forms of redundancy. Among them, Control Flow Checking (CFC) makes it possible to cover faults affecting storing elements containing the executable program, as well as all the hardware components handling the program itself and its flow [1, 2]. It can also cope with the effects of a malicious attacker who tries either to bypass security checks or retrieves secret information by fault injection [3, 4].\nSoftware based CFC solutions that modify the program rely on the assumption that the binary code stored in memory is not being maliciously tampered. Thus, these solutions cannot provide security against fault injection attacks [5]. In contrast, hardware-based CFC solutions, such as [6] can detect malicious code and data tampering at run-time.\nThere are two types of hardware-based CFC policies: fine grained and coarse grained [5]. A fine grained CFC policy allows control flow along the valid edges of the Control Flow Graph (CFG), whereas a coarse grain policy relaxes this restriction. A CFG makes it possible to model the normal program behavior of a code that is not selfmodifying or generated on the fly as a walk on a static graph. The nodes in this graph are sequences of non-branching instructions (also called basic blocks) with a single entry point at the first instruction and a single exit point at the last instruction. The edges of the graph represent jumps, branches and returns. In [7] the authors distinguished between two levels of fine granularity: instruction integrity checking which aims to detect attacks which may not result in control flow\nThis research was supported by the ISRAEL SCIENCE FOUNDATION (grant No. 1266/20) and by the IRS project CROCHET funded by the IDEX UGA\n*Institute of Engineering Univ. Grenoble Alpes\nviolations, and instruction flow checking for detecting forward-edge and backward-edge flow violations between basic blocks.\nIn [8] the authors suggested encrypting the instructions to detect changes in it. The instructions are decrypted by adding a stage to the pipeline, immediately before the instruction\u2019s decode stage, which required architectural modifications. The additional stage of the pipeline introduced an \u2248 9.1% total execution time overhead. At this point, it is important to note that tampering the flow of the program (i.e., its branches, jumps, calls and returns) can affect its behaviour tremendously. For that reason, the authenticity of the last instruction in a basic block must be verified as close as possible to its execution time, as the Signature Modeling approach suggests.\nSignature Modeling is a fine-grained technique [9, 10, 11]. In Signature Modeling, basic blocks are accompanied by a signature, such as a Cyclic Redundancy Check (CRC) checksum or Hamming code, that are generated at run-time and then compared against a pre-computed signature which is stored in a tamper-resistant memory (e.g., the tamper-resistant RAM presented in [12]). In the case of modification of any bit belonging to that portion of the code, the detection code deviates from the expected signature and reveals the fault. The two signatures can be compared during the execution of each instruction [10, 11] or when a basic block ends [7, 3]. In [11] a CRC-based signature monitor was integrated into the instruction fetch state to prevent the processing of instructions whose pre-calculated and current signatures do not match. However, a CRC-based signature monitor has a major drawback, it can be bypassed by a sophisticated attacker [13]. The authors in [14] proposed a technique to map one malicious software into another (protected by a control flow checking mechanism), without violating the structure of the latter; i.e., without being detected by a control flow monitoring technique. The basic principle involved the fine-tuning of the instructions in each basic block so that the generated signature corresponded to the one for the original program. In this paper we close this gap, we propose a finegrained MAC-based CFC which utilizes non-linear codes to protect against malicious modifications of the executed program. We assume the attacker knows the protected architecture details and its machine language, as well as the program and its control flow graph. The attacker can execute malicious physical manipulations on the device by injecting precise faults at run-time into the machine code stored in memory. We assume that the signature is stored in a tamper-resistant memory that cannot be tampered with.\nThe contribution of this paper is: \u2022 A non-linear code based on a weakened version of the\nKarpovsky-Wang Algebraic Manipulation Detection (AMD) code with multiple random variables [15]. \u2022 A signature calculation method that works in parallel to the processor pipeline and does not require processor changes, nor code changes. \u2022 We introduce an upper bound on the probability that an error will not be detected. This bound applies to every basic block and hence obviates the need for simulations/experiments. \u2022 The area overhead of the signature calculation is relatively small (compared to methods preventing malicious attacks) and there is no need to partition the program into basic blocks of equal length as required in [7].\nThis paper is organized as follows: Section II presents an overview\nof existing CFC solutions, and details the architecture in which the proposed signature calculation can be used. Section III provides formal definitions and formulates the security metric we use to evaluate the effectiveness of the construction. Section IV presents the theoretical construction of the non-linear code and Section V describes its hardware implementation. Finally, we draw some conclusions in section VI."
        },
        {
            "heading": "II. CONTEXT",
            "text": "Historically, error-detection codes primarily targeted natural faults which are likely to cause a small number of bit-flips, randomly distributed. These codes are usually linear and hence have a small overall impact on the target system in terms of area overhead and the additional delays introduced for their calculation. However, they cannot cope with malicious attacks. For example, [11], the so-called \u201dderived signature\u201d enables a checksum computation with zero latency. However, it utilizes systematic encoders of linear cyclic codes defined by generator polynomials over a finite field. Due to the linearity of the codes, the corresponding CFCs can only detect a (relatively) small number of errors, and they cannot detect attacks launched by sophisticated precise attackers.\nMalicious attacks are handled better by non-linear methods; e.g., methods based on Message Authentication Codes (MAC). In MAC, the signature is calculated by resorting to secret information which also guarantees the authenticity of the data. MAC techniques that are based on a statically computed cryptographic hash of the instruction sequence in the basic block [16] generally have high latency, because the monitor has to buffer the instruction stream corresponding to a basic block and only start to compute the hash when the block ends. In some hash algorithms the input is processed through several rounds and additional latency is accumulated. A few MAC based checkers ([6]) can compute the signature together with the execution of the program itself. Nevertheless, these solutions have certain limitations. In [6] a Cipher Block Chaining-Message Authentication Code (CBCMAC) algorithm with a 64-bit MAC length is used. Since CBC-MAC is only secure for messages of a fixed length, two block lengths of 5 and 6 instructions are supported only. In addition, its implementation has a critical path which is longer than the one of the processor, leading to a cycle overhead of 13.7% and a total execution time overhead of 110%. In [17] the authors use public-key cryptography to protect their code. The strength of the used cipher guarantees the security of the solution, however its cost (in hardware and timing overhead) is extremely high. In [18] the authors implemented CCFI-cache; a dedicated tamper-resistant signature memory with the same properties as the instruction cache. Each signature consists of the hash value of the instructions and the meta-data of the basic block along with the meta-data itself (The number of instructions in the basic block and the address of the next basic blocks).Since the signature may occupied several entries in the CCFI-cache, in the case where the basic block is very short, it must be padded with nop instructions, so its size match the size of the signature. Similarly, short signatures must be padded with empty entries in the case of a long basic block. This lead to a program overhead of up to 30%.\nHere, we introduce a MAC scheme that can be applied to every architecture where the CFC (or watchdog) is a standalone module that works in parallel with the main processor\u2019s pipeline (see the generic architecture in Fig. 1). The CFC is a co-processor that calculates the signatures of the basic blocks by fetching the instructions to be executed from the main bus, and then comparing the obtained signature with a predefined one. It does not modify the pipeline stages, does not add latency, and does not interfere with the program flow. The CFC communicates with the processor via the existing signals at its interface or within the pipeline. Namely, the current address and instruction on buses used by the processor during the Instruction Fetch (IF) phase, and the calculated address of the next instruction. For instance, the proposed approach can be easily integrated in recent solutions, such as [19], where the checker is an independent module as the one shown in Fig. 2. The generic architecture we consider consists of four main blocks: a compact processing unit, a comparator,\na control unit, and a tamper-resistant memory array. The tamperresistant memory is more expensive, but is only used for storing a small amount of information, not the whole program. The size of the tamper-resistant memory and its width depends on the number of basic blocks, their maximal size and the required security level.\nIn this paper we focus on the design of the computation module. We assume that:\n\u2022 The control unit generates all the control signals for the computation module. This includes the generation of a reset signal that goes to the computation module at the beginning of a basic block and an indication that the basic block ends (due to a branch instruction or because it has reached its maximal size). \u2022 The control unit delivers the signature from the tamper-resistant memory to the computation module.\nWe also assume that:\n\u2022 The profiling process as well as the program can be trusted. \u2022 The content of the tamper-resistant memory is pre-computed\nfrom the control flow graph (see the process flow diagram in Fig. 1). The pre-computation of the signatures (i.e., the encoding of the basic blocks by using random vectors) can be trusted. \u2022 The process of loading the signatures into the tamper-resistant memory can be trusted. \u2022 To reduce the cost of the product, the main memory has no dedicated security protection whereas the CFC itself, including its tamper-resistant memory in which the signatures are stored, is not accessible to the attacker. \u2022 The attacker knows the original code, its profiling and its location in the main memory. \u2022 The attacker is able to tamper with the content of the main memory and is able to inject arbitrary or precise errors before the execution or at run-time; i.e., when the code is being fetched from the memory."
        },
        {
            "heading": "III. DEFINITIONS AND SECURITY METRIC",
            "text": "A. Basic blocks\nA basic block is a piece of code made of one or several consecutive instructions without any jumps between them. A basic block starts when its address is the target of a jump instruction of another basic block, and ends with a jump to another basic block (or a return), or if the successor instruction is a target of a jump instruction. For example,\nExample 1. The following code consists of 3 basic blocks:\n. . .\nDEC R1 BNZ R1, L1 //end of BB1 INC R1 //end of BB2\nL1: ADD R2, 2 //beginning of BB3 . . .\nThe first basic block ends because of jump instruction and the second due to the fact that \u2018ADD R2, 2\u2019 is a target of a jump instruction.\nThe size of the BB is defined as the number of bytes occupied by all the instructions in that basic block. Its size can range from 32 (for a 32-bit architecture) to 8N bits (N bytes). If the original basic block is larger than N bytes, it should be divided into several basic blocks by inserting a branch instruction which jumps to the successor instruction.\nThe content of a basic block can be referred to as a binary string, or, as is common in coding theory, as a q-ary vector over an alphabet of size q = 2r . When algebraic codes are used for signature computation, the symbols of the vectors are treated as elements in the finite field Fq = GF (q). The size of the alphabet determines both the effectiveness of the code and the implementation complexity. In general, a small r lowers the implementation cost of the multipliers over that field, whereas a large r increases the fault detection probability.\nB. Signature structure\nThe signature S is a q-ary vector of length t + 1 symbols (i.e., (t + 1) \u00b7 r bits). It has two parts: a \u201dkey\u201d X and a tag f ; that is, S = (X, f(X,Y )). In this paper, the \u201dkey\u201d is a non-zero vector, X = (xt, ...x1) \u2208 X \u2286 Ftq chosen at random by the manufacturer. Y is the content of a basic block\nY = (yk, ...y1) \u2208 Fkq ,\nand f = f(X,Y ) \u2208 Fq is a single q-ary symbol that represents the tag. The effectiveness of the CFC is determined by the choice of the tag function.\nThe triplets (Y,X, f(X,Y )) form a block code. In our case, the encoder works off-line and thus can be implemented in software, whereas the decoder works on-line and thus must to be implemented in hardware.\nTypically, block codes consist of codewords of fixed length. Systematic block codes are codes whose codewords have two parts: a fixed length information portion Y \u2208 Fkq and a fixed length redundant portion S. Our case is different; since Y represents a basic block its length depends on the number of instructions within a basic block and is not fixed. It is possible to work around this problem by adding jumps and NOPs to the program, but this in turn adds latency and increases the tamper-resistant memory size. In order to minimize the cost, the tag function f must be able to handle (in run-time) a q-ary vector Y of arbitrary length k,\nk \u2264 kmax = d 8 \u00b7N r e,\nwithout knowing its length beforehand.\nC. Security metric Recall that Y is stored in a regular memory. Thus, the attacker can alter it at will and even change its length. By contrast, the signature is not observable to the attacker and hence cannot be altered. Formally, denote by Y\u0302 = (y\u0302k\u0302, ...y\u03021) the (possibly erroneous) sequence as read by the control flow checker. Note that the length of this sequence is k\u0302, 1 \u2264 k\u0302 \u2264 kmax. k\u0302 may be smaller, equal to, or greater than k. Consequently, the checker \u201dsees\u201d the tuple (Y\u0302 , X, f(X,Y )) and has to decide whether this tuple is a codeword. Specifically, it computes f(X, Y\u0302 ) and raises a flag if the computed value differs from the one stored in the tamper-resistant memory; that is, if f(X, Y\u0302 ) 6= f(X,Y ). Therefore, we assess the effectiveness of this type of CFC as the probability Q that a precise attack will pass unnoticed. That is,\nDefinition 1 (Security metric.). Let X be a uniformly distributed random vector over a subset X \u2286 Ftq , then the error masking probability is\nQ\u0304 = max Y,Y\u0302\nProb ( f(X,Y ) = f(X, Y\u0302 ) | Y, Y\u0302 ) .\nThe function f(X,Y ) must be a nonlinear function in X and Y . Otherwise, if f can be written as f(X,Y ) = f1(Y ) + f2(X), an attacker who knows Y and can choose which bits to flip in order to replace it by Y\u0302 will choose a Y\u0302 for which f1(Y ) = f1(Y\u0302 ); such an attack will never be detected. The following example clarifies this statement:\nExample 2. Let q = 2 and let Y be the basic block to be protected and denote by Y0 the vector Y padded with kmax \u2212 k zeros, Y0 = (0kmax\u2212k, Y ).\nLet C be a linear code of length kmax + t+ rb bits and dimension kb = kmax + t defined by a (systematic) generator matrix\nG = ( Ikmax\u00d7kmax 0kmax\u00d7t Akmax\u00d7rb 0t\u00d7kmax It\u00d7t Bt\u00d7rb ) .\nA codeword in C is a triplet (Y0, X, f(X,Y0)) = (Y0, X)G. The signature associated with Y is then S = (X, f(X,Y )) where the tag f(X,Y ) is (Y0, X) \u00b7 (A,B)T .\nIt is reasonable to assume that the tag length is smaller than the maximal basic block length; i.e., kmax > rb \u2265 rank(A). Therefore, for every Y there exists at least one vector Y\u0302 for which Y0A = Y\u03020A. (Y\u0302 and Y may be of different lengths). Since for every X , we have S\u0302 = (X, Y\u03020A + XB) = S an attacker can replace Y by this Y\u0302 without being detected.\nNumerical examples of attacks that can never be detected by linear codes are presented in the Appendix (Examples 12,13)."
        },
        {
            "heading": "IV. CONSTRUCTION",
            "text": "A. Formal description of the tag function We use a tag function f based on weakened version of the Karpovsky-Wang Algebraic Manipulation Detection (AMD) codes [15]. The computational complexity of f is smaller than KarpovskyWang\u2019s code since it makes use of the fact that the signature cannot be tampered with. This fact enable us to construct a variable length code whose checker can work in parallel to the execution of the basic block; the computed signature is ready before the last instruction of the current basic block leaves the pipeline. This makes this CFC an add-on module because it does not change the throughput or latency of the system. It also enables a simple and smooth transition between basic blocks.\nOne of the AMD codes presented in [15] relies on the Generalized Reed-Muller (GRM) codes. A GRM code is a non-systematic fixedlength code; it is defined by three parameters, r, t and b [20]: r - defines the size of the finite field (q = 2r) t - is the number of random q-ary symbols b - is the order of the code, b \u2264 t(q \u2212 1)\nb is the smallest integer for which the coding scheme can protect a sequence of maximal length kmax; i.e., b is the smallest integer for which kmax \u2264 \u03bb(t, b)\u2212 1 where\n\u03bb(t, b) = t\u2211 j=0\n(\u22121)j ( t\nj )( t+ b\u2212 jq b\u2212 jq ) .\nIn a GRM code, an information word Y of length kmax determines the coefficients of a polynomial of order \u2264 b. The corresponding GRM codeword is then a q-ary vector of length qt whose symbols are the values that this polynomial takes.\nOur code is built on the GRM code in the sense that we use a specific subset of the GRM codewords, and define f(X,Y ) as the value of the X\u2019th symbol in the GRM codeword associated with the information word Y0 = (0kmax\u2212k, Y ). In what follows we define the mapping we use between Y and the polynomial. We start with several definitions.\nLet Zq be the set of integers {0, 1, ..., q\u22121}. Let w = (wt, ...w1) \u2208 Ztq be a q-ary vector of length t that represents the number N(w) =\u2211t\nj=1 wjq j\u22121 in radix q. When it is clear from the context, we refer to a vector w by its value N(w). Define \u2126b to be an ordered set of size kmax of vectors whose sum is smaller or equal to b. That is,\n\u2126b = {wi = (wi,t, ...wi,1) \u2208 Ztq : 0 < t\u2211\nj=1\nwi,j \u2264 b}kmaxi=1 .\nIn addition, we require that the numbers associated with the vectors in \u2126b be the smallest numbers that have this property. In other words, N(w1) = 1, N(wi) < N(wi+1) and there is no other vector, say w\u0302 /\u2208 \u2126b such that N(wi) < N(w\u0302) < N(wi+1).\nExample 3. Let t = 3, r = 8. The values \u03bb(3, b) are given in Table I. For b = 8 the set \u2126b consists of 164 vectors,  \u2212 (0, 0, 1) (0, 0, 2) (0, 0, 3) . . . (0, 0, 7) (0, 0, 8) (0, 1, 0) (0, 1, 1) (0, 1, 2) (0, 1, 3) . . . (0, 1, 7) \u2212 (0, 2, 0) (0, 2, 1) (0, 2, 2) (0, 2, 3) . . . \u2212 \u2212 ... ... ... ... . . . ... ... (6, 2, 0) \u2212 \u2212 \u2212 . . . \u2212 \u2212 (7, 0, 0) (7, 0, 1) \u2212 \u2212 . . . \u2212 \u2212 (7, 1, 0) \u2212 \u2212 \u2212 . . . \u2212 \u2212 (8, 0, 0) \u2212 \u2212 \u2212 . . . \u2212 \u2212  For example, w56 = (1, 1, 3) and N(w56) = 1 \u00b7 (28)2 + 1 \u00b7 (28)1 + 3 \u00b7 (28)0 = 65795.\nConstruction 1 (The tag function f ). Let Y be a q-ary vector of length k \u2264 kmax. Denote by Xw the product term\nXw = xwtt \u00b7 \u00b7 \u00b7x w2 2 \u00b7 x w1 1 ,\nwhere computations are performed over Fq . A polynomial based nonlinear signature of Y is a binary vector of size (t+1)\u00b7r bits isomorphic to the vector S = (X, f(X,Y )) \u2208 Ft+1q where\nf(X,Y ) = k\u2211 i=1 yiX wi , (1)\nand wi \u2208 \u2126b Note that f(X,Y ) = f(X,Y0) is the X\u2019th symbol in a GRM codeword\nc = (f(0, Y0), f(1, Y0), . . . , f(q t \u2212 1, Y0))\nassociated with the information symbol Y0 = (0kmax\u2212k, Y ).\nExample 4. Let the maximal length of a sequence be N = 161 bytes. Assume we want to design a control flow checker whose signature is a binary vector of length 32 = (3 + 1) \u00b7 8; that is, r = 8 and t = 3. Then we have kmax = d 8\u00b71618 e = 161, and b = 8 is the smallest integer for which (\n3 + b\nb\n) \u2212 1 = 164 \u2265 kmax.\nA signature is a binary vector of length 32 of the form S = (X = (x1, x2, x3), f(X,Y )) where x1, x2, x3 and f are 8 bit vectors that represent elements from the finite field F28 . The function f for k = 3 is\nf(X,Y ) = y1X (0,0,1) + y1X (0,0,2) + y1X (0,0,3)\n= y1x1 + y1x 2 1 + y1x 3 1,\nwhereas for k = kmax it is\nf(X,Y ) = y1X (0,0,1) + y2X (0,0,2) + ...y8X (0,0,8) +\ny9X (0,1,0) + y10X (0,1,1) + ...y16X (0,1,7) +\n... y159X (6,0,1) + y160X (6,1,0) + y161X (7,0,0)\n= y1x1 + y2x 2 1 + ...y8x 8 1 +\ny9x2 + y10x2x1 + ...y16x2x 7 1 + ... y159x 6 3x1 + y160x 6 3x2 + y161x 7 3.\nB. The effectiveness of the CFC\nIt is important to note that the triplet (Y,X, f(X,Y )) is a codeword in an error detecting code; it has no error correction capabilities. Thus, the decoder has no error-recovery mechanism. This serves to avoid scenarios in which an attacker can manipulate the system and make the decoder conceal the attack by \u201dcorrecting\u201d an erroneous basic block into a legal but different basic block. Example 13 in the Appendix shows how simple it is to manipulate a system when the error correction mechanism is activated.\nThe following theorem provides an upper bound on the probability that the CFC will not detect a tampered-with basic block. The bound applies to all basic blocks regardless of their length and content and therefore obviates the need for experiments/simulations.\nTheorem 1. Let X be a random vector that is uniformly distributed over X \u2286 Ftq . The probability that a GRM based signature will not detect a tampered sequence is\nQ\u0304 \u2264 bq t\u22121\n|X | .\nProof. Let Y be a q-ary vector of length k that represents the correct sequence, and denote by Y\u0302 the q-ary vector of length k\u0302 that represents the tampered sequence. The two sequences may be of different lengths, i.e., k 6= k\u0302. Notice that the expansion of Y and Y\u0302 into q-ary vectors of length kmax does not change the signature since f(X,Y ) = f(X, (0kmax\u2212k, Y )) and f(X, Y\u0302 ) = f(X, (0kmax\u2212k\u0302, Y\u0302 )). Thus, without loss of generality, we assume that both vectors are of size kmax. This enables us to represent Y\u0302 as\nY\u0302 = Y + E\nwhere Y, Y\u0302 and E are vectors in Fkmaxq . E is defined as the difference between the two sequences and hence can be treated as an additive error vector. The error masking probability is then\nQ\u0304 = max E\u2208Fkmaxq \\{0} Q(E).\nThe error E is detected if the computed signature of Y\u0302 differs from the signature of Y . In other words, the attack is undetected if f(Y,X) = f(Y + E,X). Define,\ngE(X) = f(Y,X)\u2212 f(Y + E,X) =\n= k\u2211 i=1 yiX wi \u2212 k\u2211 i=1 (yi + ei)X wi = k\u2211 i=1 eiX wi . (2)\nThen, a nonzero E is undetected if X is a root of the polynomial gE . This polynomial is associated with a q-ary codeword c of length qt in the generalized Reed-Muller (GRM) code. That is,\nc = (gE(0), gE(1), ..., gE(q t \u2212 1)) 6= 0qt .\nSince the GRM is a linear code of minimum distance d = (q\u2212b)qt\u22121, every nonzero codeword c has a minimal weight d. That is, gE has at most qt \u2212 d roots. Hence, for a uniformly chosen non-zero vector X \u2208 X , the probability that tampering will go undetected is\nQ(E) \u2264 q t \u2212 d |X | = bqt\u22121 |X | .\nExample 5. Consider the code in Example 4. The code has t = 3, b = 8 and r = 8, hence for |X | = (2r)t = 224, the probability that an attack will be masked is approximately 2\u22125.\nNote that another way to construct a control flow checker for N = 161 bytes is by taking a larger r; i.e., r = 16, t = 1 and b = dN/2e = 81. In this case, the signature is a binary vector of length (1+1)\u00b716 bits, and f is a polynomial of a single variable, f(X,Y ) = y1x + y2x\n2 + \u00b7 \u00b7 \u00b7 + y81x81. Here, the computation is performed in the (larger) field F216 ; hence, the implementation cost is larger, but the probability that an attack will be masked becomes significantly smaller ( \u2248 2\u22129).\nTable II shows several constructions for different block and signature sizes. The first column lists the length of the maximal sequence (in bytes), the probability Q that an attack will be masked with\nX1 = {X = (xt, . . . , x1) : xi 6= 0 \u2200i} \u2282 Ftq\nand with X2 = Ftq , in the second and third columns, respectively. The signature size (in bits) is appears in the fourth column, and the GRM parameters, r, t and b are given in columns 5-7.\nThe analysis of the error masking probability Q\u0304 is a worst case analysis. The error masking probability can be smaller when the gE is of low degree. The following example illustrates this statement:\nExample 6. Assume X = (x3, x2, x1) \u2208 X , and let\ngE = e1x1 + e2x 2 1 + e3x 3 1x2.\nFor a given (x3, x2 6= 0) pair, gE is a polynomial of degree 3, and for pairs (x3, x2 = 0) it is of degree 2. Hence, gE has at most (3q(q \u2212 1) + 2q) roots. The probability that this error is masked is:\nQ(E) \u2264 q(3q \u2212 1)|X | < 8q2 |X | ."
        },
        {
            "heading": "V. CFC DESIGN FOR A 32-BIT SINGLE-PIPELINE PROCESSOR WITH A 32-BIT SIGNATURE",
            "text": "In this section we detail the design of a CFC protecting a singlepipeline processor with a 32 bit ISA from malicious attacks. We\nassume that the pre-computed signatures are stored in a tamperresistant memory. We start by describing the considerations that underlie the choice of design parameters, then describe the architecture of the computational module and elaborate on the structure of each of its blocks, with a focus on the correctness of the implementation rather than its efficiency. Finally, we describe the architectural changes needed to make it an effective real-time CFC.\nA. Design parameters All the code parameters are linked: as we saw in the previous section, the triplet t, b and r affects N , the code\u2019s error masking probability Q\u0304, and the signature size. In what follows, we describe the design considerations that led to the choice of N and r, which in turn determine parameters b and t for the selected processor and the 32-bit signature.\n1) The maximal basic block length N : The parameter N represents the maximal basic block length (in bytes) that can be protected by the code. Since any basic block can be split into several basic blocks of smaller length, it is assumed that the encoder and the checker \u201dsee\u201d basic blocks of length smaller or equal to N .\nNote that splitting a basic block larger than N -bytes into smaller basic blocks requires additional rows in the signature memory; hence, the maximal basic block size cannot be too small. On the other hand, a large N may increase the time between the execution of a tampered instruction and its detection. Therefore, N cannot be too large either.\nThe basic block size, along with the execution of a jump instruction, indicates the end of a basic block. To cope with a case where a basic block ends with a label (see Example 1), we can keep the size of the basic block in the tamper-resistant memory, as part of the signature, or insert an unconditional jump to the next (labeled) instruction at the end of this basic block. Figure 3, taken from [21], shows the distribution of BB sizes for some real Linux-based applications (ghostscript, head, hexdump, sort, tail) running on a x86 architecture. As can be seen, the vast majority of BBs have a number of bytes that is smaller than"
        },
        {
            "heading": "8 164 0.0316 32 3 8",
            "text": ""
        },
        {
            "heading": "8 209 0.0238 40 4 6",
            "text": ""
        },
        {
            "heading": "9 133 0.0138 36 3 7",
            "text": ""
        },
        {
            "heading": "10 130 0.0127 30 2 13",
            "text": ""
        },
        {
            "heading": "10 148 0.0069 40 3 7",
            "text": ""
        },
        {
            "heading": "11 143 0.0064 33 2 13",
            "text": ""
        },
        {
            "heading": "12 135 0.0029 36 2 12",
            "text": "N = 164, thus confirming that the choice of these parameters is reasonable.\n2) The tag size r: For simplicity, we work with bytes (r = 8). That is, both the y\u2019s and the x\u2019s are elements of F2r (that is, isomorphic to Fr2). Table III shows several constructions for r = 8 (q = 28). The columns from left to right are the maximal basic block length (N ), the probability Q that an attack will be masked, the signature size in bits, and the GRM parameters, t and b.\nIn fact, r can take larger values (i.e., r > 8). In this case the x\u2019s should take a nonzero value from F2r and the eight bits of the y\u2019s should be padded with r \u2212 8 zeros. This may lead to constructions with a smaller error masking probability with a similar implementation cost. Table IV shows the error masking probability for several r values and for different (maximal) lengths of basic blocks. Note that the size of the signature, which is a function of r and t, takes values from 27 to 40. It is clear from the table that by adding a single bit to the signature, one can implement a checker with r = 11 and obtain a smaller error masking probability of 0.0064 instead of 0.0316.\nGuided by these design considerations, we implemented a CFC with the following parameters (marked in bold in Table IV):\n\u2022 Serial implementation (Section V-B)\nr = 8, t = 3, b = 8, N = 164, bytes q = 256,\nand error masking probability Q\u0304 = 8 \u00b7 q2/(q3 \u2212 1) = 3.13%. \u2022 Parallel implementation (Section V-F)\nr = 8, t = 3, b = 9, N = 144, bytes q = 256,\nand error masking probability Q\u0304 = 9 \u00b7 q2/(q3 \u2212 1) = 3.5%.\nB. Generic architecture of the Computation Module (CM) A simplified block diagram of the Computation Module (CM) is shown in Fig. 4. It receives the random portion X of the current basic blockfrom the tamper-resistant memory and the content of the basic block as fetched from the instruction cache. The CM has its own clock, whose frequency depends on the number of y symbols processed each clock period. For simplicity, we first describe the operation of the CM when it receives one byte per clock and in Section V-F we show how to use this simplified design to process four bytes per clock. In the latter case, the system\u2019s clock is used as the CM\u2019s clock.\nThe CM consists of three modules: \u2022 A (t, b) counter. These counters are used for generating the t-\ndigit vectors in \u2126b. The inputs to this block are the CM clock and the global reset signals from the control unit. The current state of the counters w \u2208 \u2126b is used to compute internal control signals (incj and resetj , j = 1, . . . t) that determine its next state. The t-bit control signal inc = (inct, ..., inc1) is also used as input to the product term computation block (described next). \u2022 A product term generator. This block computes Xw. The inputs to this block are the CM clock, the global reset signals from the control unit, the secret key - X , and the control signals from the counter block. The block consists of t r-bit registers dubbed R1, . . . Rt and a single finite field multiplier. Given these registers and the fact that the \u2126b is an ordered set, Xw can be computed without using w. That is, w is an internal variable of the counter/s. Thus, only t wires connect the counter and this block (instead of t \u00b7 log2(b)).\n\u2022 A polynomial evaluator. This block computes f(Y,X). In what follows we elaborate on each module.\nC. The (t, b) Counter module The (t, b) counter is a state-machine; it produces the vectors \u2126b in an ordered manner. At time slot i the counter generates the vector\nwi = (wi,t, . . . , wi,2, wi,1) \u2208 \u2126b.\nA schematic block diagram of the (t, b) counters is depicted in Fig. 5 and its formal description is given in Alg. 1.\nThe counter can be viewed as a radix q = 2r ripple counter. For example, for t = 3, r = 8, b = 8, if the current vector w is (w3 = 5, w2 = 0, w1 = 1), the next vector will be (5, 0, 2). However, it differs from a conventional t-digit counter in that a conventional counter has a global reset/preset signal that initializes (simultaneously) all the digits to a predefined value, whereas in our case the counter has t local reset and increment signals, resetj and incj ( Alg.1, Line 11). Thus it can increment its upper part, e.g., (wt, . . . , wj+1), and reset its lower part (wj , . . . , w1), see Alg.1, Lines 7-10. For example, (4, 2, 2) will be followed by\nwi+1 = (4, 3, 0), wi+2 = (4, 3, 1) wi+3 = (4, 4, 0).\nAlgorithm 1 (t, b) Counter for b < q 1: (Initialization step) Set i = 1. 2: (Initialization step) Set wi = (0, 0, . . . , 0, 1). 3: while the basic block has not ended, do 4: inc1 := ( \u2211t j=1 wi,j < b)\n5: reset1 := \u00acinc1 6: for j = 1 : t do 7: Update the value of the j\u2019th digit wi+1,j : 8: if (resetj == 1) then wi+1,j := 0, 9: if (resetj == 0)\u2227 (incj == 0) then wi+1,j :=\nwi,j , 10: if (resetj == 0)\u2227 (incj == 1) then wi+1,j := wi,j + 1, 11: Generate the reset and increment signals for the (j +\n1)\u2019th digit: 12: resetj+1 := (resetj == 1) \u2227 (wi,j == 0), 13: incj+1 := (resetj == 1) \u2227 (wi,j > 0). 14: end for 15: i = i+ 1 // Virtual counter to simplify the analysis 16: end while\nNote that N(4, 2, 2) < N(4, 3, 0) < N(4, 3, 1). Fig. 5-top shows a (t, b) composed of t sub-counters that work in parallel. Each sub-counter produces r bit vectors, dubbed \u2019digit\u2019. Each sub-counter has its own reset and increment signals that are generated by the preceding sub-counter (Alg.1, Lines 11-13). The first sub-counter is controlled by the b comparator (Alg.1, Lines 4-5). The bottom figure shows a detailed scheme of a sub-counter. At each cycle, if the increment signal is raised, the sub-counter increments its value by 1 (Alg.1, Line 10). The first sub-counter, cnt1, is set to 1 on a global reset (Alg.1, Line 2). All the other sub-counters can be set to zero by either external reset (Line 2) or by a reset from the preceding sub-counter (Line 12).\nTheorem 2. For b < q, Alg. 1 generates all the vectors in \u2126b in increasing order.\nThe proof of this theorem is given in the Appendix.\nD. Product term computation module This block computes the product term Pi = Xwi . The schematics of this module are shown in Fig 6. Alg. 2 explains how it operates and the associated theorem proves its correctness.\nThe block consists of one finite field multiplier and t \u201dshadow\u201d registers, where each register Rj holds a different product. Recall that the product term computation module does not \u201dsee\u201d the value of wi, and thus has to figure out how to compute the current product Pi by analyzing the t bits of the inc vector. Denote by j+ the largest index for which incj = 1 (Alg.2, Line 3); the i\u2019th product term is computed by multiplying the value stored in the (j+)\u2019th shadow register by xj+ (Alg.2, Line 4). Then, the value of the first shadow registers, R1, . . . Rj+ is updated with the new product Pi (Line 5).\nTheorem 3. Algorithm 2 correctly computes Pi = Xwi from the signals inc1, . . . inct.\nThe proof of this theorem is given in the Appendix.\nAlgorithm 2 Compute Product Term 1: (Initialization step) Set Rj = 1 for all 1 \u2264 j \u2264 t. 2: while the basic block has not ended, do 3: Find the largest index j+ for which incj+ == 1. 4: Compute Pi := Rj+ \u00b7 xj+ . 5: for j = 1 : j+ do 6: Update the register with the current product term:\nRj := Pi, loadj := 1. 7: end for 8: i = i+ 1 // Virtual counter to simplify the analysis 9: end while\nExample 7. Consider the CFC in Example 4. Table V shows the content of the shadow registers over time.\nE. Polynomial Evaluation module The polynomial f(Y,X) can evaluated at the same time as the generation of the vectors in \u2126b. As described at Fig. 7, it consists of a multiplier and an adder. The computed Pi is multiplied by the corresponding yi and the result is added to the content of the register that holds the sum of the products computed so far.\nF. Concurrent CFC implementation A schematic block diagram of the checker is depicted in Fig 8. Every clock cycle, 32 bits are read from the memory; therefore, at every clock cycle, 4 = 32/r q-ary symbols, yi, yi+1, . . . yi+3, enter the checker. As shown in the figure, there are four different (t, b) counters: the j\u2019th counter has tj digits with design parameter bj . Each counter can have its own initialization value (or values).\nThe output of the j\u2019th counter at time i, wi,j , enters a product term computation module that generates the product Pi,j where Pi,j = X\nwi,j j (X \\Xj) vj . Here, Xj \u2286 X is the predefined tj q-ary random variables allocated to the j\u2019th counter, (X \\ Xj) are the remaining variables, and vj \u2208 Zt\u2212tj is a predefined integer vector whose L1 norm is equal to or smaller than b\u2212 bj . The polynomial evaluation module in Fig. 8 computes the sum\u22114 j=1 yi+j\u22121Pi,j and adds it to the sum accumulated so far.\nFour disjoint sets of w\u2019s are generated by the counters. Denote the sets as \u2126(0)9 ,\u2126 (1) 9 ,\u2126 (2) 9 and \u2126 (3) 9 . These sets satisfy \u2126 (j) 9 \u2229 \u2126 (l) 9 = \u03a6 for j 6= l, and | \u222aj \u2126(j)9 | \u2265 N . The signature value is then\nf(X,Y ) = k/4\u2211 i=1 3\u2211 j=0 y4i+j,jX wi,j , (3)\nwhere y4i+j,j is the j\u2019th byte of the i\u2019th instruction in a basic block that has k bytes, and wi,j is the i\u2019th vector in the ordered set \u2126 (j) 9 .\nThere are several ways to split \u21269 into four disjoint sets. One example is the following:\n\u2126 (0) 9 = {w : w \u2208 \u21269 and w3 = 0} \u2126 (1) 9 = {w : w \u2208 \u21269 and w3 = 1} \u2126 (2) 9 = {w : w \u2208 \u21269 and w3 = 2} \u2126 (3) 9 = {w : w \u2208 \u21269 and w3 \u2265 3}. (4)\nNote that the sets are of different sizes |\u2126(0)9 | = 54, |\u2126 (1) 9 | = 45, |\u2126(2)9 | = 36, |\u2126 (3) 9 | > 40. This implies that the maximal Basic Block must be smaller or equal to 4 \u00b7 36 = 144 bytes. This number is smaller than 164 which is the maximal basic block size that can be supported by an 8-bit architecture.\nRecall that the four sets are generated by four counters that work in parallel. Table VI presents the parameters of these counters. For each counter, the table specifies the parameter vector (ti, bi), the maximal number of w\u2019s that it can generate and the form of the corresponding product. Table VII shows the operation of the four counters and the control signal they generate at different time slots. Note that the first counter starts from 1 whereas the other three start from zero.\nSince N is determined by the size of the smallest counter (in our case \u2126(2)9 ), we can use its saturation signal; i.e., its inc2 signal, to notify the control unit that the current basic block has ended.\nIt is important to note that the product terms that correspond to elements in \u2126(0)9 are of the form x 0 3X\u0302\nw\u0302 where X\u0302 = x2x1 and w\u0302 are the vectors associated with a smaller code with parameters r = 8, t = 2 and b = 9. Similarly, the product terms corresponding to elements in \u2126(2)9 are of the form x 2 3X\u0302\nw\u0302 where the w\u0302\u2019s are associated with code with parameters r = 8, t = 2, b = 7. Overall, a checker for this code will consist of four different encoders of smaller codes and will have to multiply each partial product X\u0302w\u0302 by a different power of x3 (see Fig. 8). Specifically, additional finite field multipliers are required to compute, for example, x33.\nG. Operation Consistent with Theorem 1, every error will be detected with a probability of at least (1 \u2212 Q\u0304) = 96.87%. In fact, for a given pair consisting of a basic block and a tampered-with block the exact probability that the CFC will not detect the error can be calculated, following the proof of the theorem.\nIn the Appendix we provide four examples that illustrating how the CFC works and how it detects an error: \u2022 Example 8 shows how the CFC works when the tag is calculated\nin an error-free scenario. \u2022 Example 9 shows a case where two instructions are erroneous. \u2022 Examples 10 and 11 show the tag calculation when the attacker\nchanges the size of a basic block.\nH. Implementation cost The coding scheme presented in this section was implemented for the chosen parameters. We synthesized the circuit by using a 28nm CMOS technology. The results of the synthesis led to an area occupancy of about 1700 Gate Equivalents (GEs). In order to compare our solution to existing ones, we calculated (when possible) the area of the other solutions in GEs. The values we obtained are sensitive to errors since not all the technological details are provided (nor units in some cases). For instance, in [6], the sizes are not explicitly calculated. However, they declare a 30% area overhead w.r.t. Leon3. Leon3 implementations range from 300K to 450K GE, thus leading to a rough approximation of at least 90K GEs for their implementation. Table VIII presents the comparison to the other works discussed in this paper. As can been seen, our solution has the smallest overhead while guaranteeing a high level of security. Concerning the impact in terms of speed, the circuit can work at more than 1 GHz when working at 1.3V, thus confirming the possibility to run in parallel with modern processors without incurring in additional delay. It is important to note that we did not considered the impact of the tamper-resistant memory in this analysis. We have assumed that such a memory is available and can be easily integrated into the system. Example of existing tamper-resistant non-volatile memories are proposed in [22] and [23]."
        },
        {
            "heading": "VI. CONCLUSION",
            "text": "This paper presents a non-linear encoder and checker that can be used in every Control Flow Checking mechanism. It suggests a way to design an add-on, low overhead, fine-grained checker with no need for architectural changes. Similar to other code-based solutions, it has the advantages of not introducing additional latency, has low overhead and is able to protect basic blocks of variable length. However, in contrast to existing code-based solutions, it employs non-linear\ncodes. In this sense, it guarantees the high level of security of the MAC-based system, without introducing high area penalties. As in every MAC-based solution, the code integrates a secret part that must be stored (together with the pre-calculated signatures) in a tamperresistant memory."
        },
        {
            "heading": "VII. APPENDIX",
            "text": "A. Proof of Theorem 2\nFirst we show that each generated vector is a member of \u2126b. The proof is by induction. Clearly, w1 \u2208 \u2126b. Assume that wi \u2208 \u2126b. If the sum of the digits of wi is smaller than b (Alg. 1 line 4), the value of the least significant digit wi+1,1 will be incremented by one (line 10). Consequently, the reset2 and inc2 signals of the second digit will be set to zero (line 12-13) and hence the second digit will keep its value (line 9). The same applies to all the other digits, and hence wi+1,j = wi,j for all j > 1, and therefore, \u2211t j=1 wi+1,j = \u2211t j=1 wi,j +1 \u2264 b.\nOn the other hand, if the sum of the digits of wi equals b then inc1 = 0 and reset1 = 1. Denote by j\u2217 the index of the first digit that carries a nonzero value. That is, wi,j = 0 for all 1 \u2264 j < j\u2217 and wi,j\u2217 \u2265 1. From line 12, all the first j\u2217 \u2212 1 digits that carry a zero have resetj = 1 and hence will remain zero (line 8). In addition, wi+1,j\u2217 will be set to zero since resetj\u2217 = 1, and the following digit that will have resetj\u2217+1 = 0 and incj\u2217+1 = 1 will be incremented by one (line 10). Therefore we have\nwi+1,j\u2217 + wi+1,j\u2217+1 = 0 + (1 + wi,j\u2217+1) \u2264 wi,j\u2217 + wi,j\u2217+1.\nSince resetj\u2217+1 = 0 all the following digits, j > j \u2217 +1, will have resetj = incj = 0. Hence, they will keep their value (line 9). Therefore,\nt\u2211 j=1 wi+1,j = 0 + wi+1,j\u2217 + wi+1,j\u2217+1 + t\u2211 j=j\u2217+2 wi+1,j\n\u2264 t\u2211\nj=j\u2217\nwi,j \u2264 t\u2211\nj=1\nwi,j = b (5)\nand thus wi+1 \u2208 \u2126b. Next, we show that all the elements of \u2126b are generated. For this, it is sufficient to show that\nN(wi) < N(wi+1) (6)\nand that there is no legal vector, say w\u0302, in \u2126b such that N(wi) < N(w\u0302) < N(wi+1).\nNote that if the sum of the digits of wi is smaller than b, then N(wi+1) = N(wi) + 1 and Eq. 6 is fulfilled. Otherwise,\nN(wi+1)\u2212N(wi) = qj \u2217 ((wi+1,j\u2217 + qwi+1,j\u2217+1))\n\u2212qj \u2217 ((wi,j\u2217 + qwi,j\u2217+1))\n= qj \u2217 (q \u2212 wi,j\u2217) > 0. (7)\nAssume now that there exists a legal vector w\u0302 in between wi+1 and wi. Then, w\u0302j\u2217+1 \u2208 {wi,j\u2217+1, wi+1,j\u2217+1}. If w\u0302j\u2217+1 = wi,j\u2217+1 then \u2211t j=1 w\u0302j > \u2211t j=1 wi,j = b is hence a contradiction (since w\u0302\ncannot be a member of \u2126b). If w\u0302j\u2217+1 = wi+1,j\u2217+1 then \u2211j\u2217\nj=1 w\u0302j <\u2211j\u2217 j=1 wi+1,j = 0 and this again is a contradiction since the sum of the first j\u2217 digits of w\u0302 cannot be negative.\nB. Proof of Theorem 3\nAt the first time slot the registers Rj+ are initialized to carry the value 1. (In Section V-F, there are four sets of registers, where each set is initialized with a different predefined value.)\nConsider the i\u2019th time slot, i > 1. Assume that the last time slot Rj+ was updated was at time p, p < i. At that time slot, the increment occurred at position j+p \u2265 j+i and wp carried the value\nwp =  (wp,t, . . . , wp,j+p , 0, . . . 0, 0,\ufe38\ufe37\ufe37\ufe38 j+i 0, . . . 0) for j+p > j + i ,\n(wp,t, . . . , wp,j+p , 0, 0, . . . 0) for j + p = ji+\n.\nThat is, at time slot i the register R j+i holds Xwp . In the time slots between p and i, the value of the w vectors were in the range\nN(wp) < N(\u2126) < N(wp) + q j+i\nbecause the counter generates an increasing series of numbers; namely, all the registers with indices smaller than j+i were changed, and the registers with indices greater or equal than j+i remained untouched. In other words, at time slot i, the wi vector is of the form\nwi = (wi\u22121,t, . . . , wi\u22121,j+i +1 , w i\u22121,j+i + 1, 0, . . . 0)\n= wp + (0, . . . , 0, 1, 0 . . . 0). (8)\nHence, Pi = x w j + i Xwp = Xwi and the block outputs the correct value.\nC. Examples In the following examples the computations were run over the finite field F82. We used the primitive polynomial \u03c0(x) = x8 + x4 + x3 + x2 + 1 to construct the field.\nExample 8 (The error-free case). Consider the following consecutive basic block complied for an ARM architecture.\nadd.w r2, r7, #16 subs r2, #8 bl 558 //end of BB1\nmovs r1, #1 bl 0 //end of BB2\nThe binary of BB1 is the following (3\u00d7 32)-bit vector\nY = (y12, . . . , y1) = ( 0xEB, 0x00, 0x00, 0x87, 0xE2, 0x52, 0x20, 0x08, 0xE2, 0x87, 0x20, 0x10 ).\nAssume that the randomly chosen part attached to Y is\nX = (x3, x2, x1) = (0x87, 0x37, 0x1C),\nthen the pre-computed tag is f(X,Y ) = 0x3C. In an error-free scenario, the checker recomputes the tag and sees that it equals the tag stored in the tamper-resistant memory. In this case, the checker works as follows:\nWhen the previous basic block ends and BB1 begins the counters and registers are initialized to:\n(2, 9)-cnt(0) = (0, 1), R(0)1 = 1, R (0) 2 = 1, (2, 8)-cnt(1) = (0, 0), R(1)1 = x3, R (1) 2 = x3, (2, 7)-cnt(2) = (0, 0), R(2)1 = x 2 3, R (2) 2 = x 2 3, (2, 6)-cnt(3) = (0, 0), R(3)1 = x 3 3, R (3) 2 = x 3 3.\nThe first fetched instruction (0xE2, 0x87, 0x20, 0x10) is bought to the checker, and the four bytes are split between the four parallel units. The values at the output of the Polynomial Evaluation module are\nf1,0(X,Y ) = y1x1 = x 4 \u00b7 (x4 + x3 + x2) mod \u03c0(x) = 0xDD\nf1,1(X,Y ) = y2x3 = 0x5A\nf1,2(X,Y ) = y3y 2 3 = 0x35 f1,3(X,Y ) = y4x 3 3 = 0xDA\nf1(X,Y ) = 3\u2295 i=0 f1,i = 0x68\nThe tag value at the end of the first cycle is 0x68.\nAt the beginning of the second cycle the values of the counters and registers are\n(2, 9)-cnt(0) = (0, 2), R(0)1 = x1, R (0) 2 = 1, (2, 8)-cnt(1) = (0, 1), R(1)1 = x3, R (1) 2 = x3, (2, 7)-cnt(2) = (0, 1), R(2)1 = x 2 3, R (2) 2 = x 2 3, (2, 6)-cnt(3) = (0, 1), R(3)1 = x 3 3, R (3) 2 = x 3 3.\nIn this cycle, the second instruction, (0xE2, 0x52, 0x20, 0x08), is fetched and the checker computes\nf2,0(X,Y ) = f1,0 \u2295 y5x21 = 0x8F f2,1(X,Y ) = f1,1 \u2295 y6x3x1 = 0x71 f2,2(X,Y ) = f1,2 \u2295 y7x23x1 = 0xA6 f2,3(X,Y ) = f1,3 \u2295 y8x33x1 = 0x2A\nf2(X,Y ) = 3\u2295 i=0 f2,i = 0x72.\nThat is, the value of the tag at the end of the second cycle; i.e., the tag accumulated so far, is 0x72.\nFinally, in the third cycle, the last instruction of the basic block, (0xEB, 0x00, 0x00, 0x87) is bought to the checker;\nthe values of the counters and registers are\n(2, 9)-cnt(0) = (0, 3), R(0)1 = x 2 1, R (0) 2 = 1, (2, 8)-cnt(1) = (0, 2), R(1)1 = x3x1, R (1) 2 = x3, (2, 7)-cnt(2) = (0, 2), R(2)1 = x 2 3x1, R (2) 2 = x 2 3, (2, 6)-cnt(3) = (0, 2), R(3)1 = x 3 3x1, R (3) 2 = x 3 3.\nThe checker computes\nf3,0(X,Y ) = f2,0 \u2295 y9x31 = 0x07 f3,1(X,Y ) = f2,1 \u2295 y10x3x21 = 0x71 f3,2(X,Y ) = f2,2 \u2295 y11x23x21 = 0xA6 f3,3(X,Y ) = f2,3 \u2295 y12x33x21 = 0xEC f3(X,Y ) = 0x3C\nAfter the third cycle the block ends; as expected, the computed tag 0x3C equals the pre-computed one.\nExample 9 (An adversary tampering with the content of a basic block). Assume that the BB1 from Example 8 has been altered by an adversary that has injected bit-flips to obtain the following code (the tamperedwith parts are written in bold):\nadd.w r2, r1, #16 add.w r3, r4, #1 bl 558 //end of BB1\nmovs r1, #1 bl 0 //end of BB2\nThe corresponding binary vector is\nY\u0302 = (Y\u030212, . . . , Y\u03021) = ( 0xEB, 0x00, 0x00, 0x87, 0xE2, 0x84, 0x30, 0x01, 0xE2, 0x81, 0x20, 0x10 )\n(the differences between Y and Y\u0302 are marked in bold). The tag computation process is similar to the computation in Example 8. After the third instruction the computed tag which equals f(X, Y\u0302 ) = 0xB2 is compared with the tag stored in memory (0x3C). Since the tags differ, the checker signals that an error has been detected.\nIt is important to note that in this case the actual error masking\nprobability Q(E) is smaller than the error masking probability of the code Q\u0304 = 8 \u00b7 2562/(2563 \u2212 1); since\nmax{deg(f(X,Y ),deg(f(X, Y\u0302 )} = 3,\nat least 2562(256 \u2212 3) X\u2019s out of 2563 are able to detect this code manipulation. In other words, the error masking probability for this specific error vector,\nE = ( 0x00, 0x00, 0x00, 0x00, 0x00, 0xD6, 0x10, 0x09, 0x00, 0x06, 0x00, 0x00 ) ,\nis Q(E) \u2264 3 256\u22121 < Q\u0304.\nExample 10 (An adversary shortening a basic block). Consider BB1 from Example 8. By injecting bit-flips it is possible to change the second instruction (subs) into a branch instruction. This way the adversary shortens the basic block by one instruction:\nadd.w r2, r7, #16 bl 100 //end the modified BB1\nbl 558 //end the original BB1\nmovs r1, #1 bl 0 //end of BB2\nNow the checker will \u201dsee\u201d a shorter vector\nY\u0302 = (y\u03028, . . . , y\u03021) = ( 0xEB, 0x00, 0x00, 0x16, 0xE2, 0x87, 0x20, 0x10 )\nand will check the signature at the end of the second cycle. The computed signature is\nf1(X, Y\u0302 ) = y\u03021x1 \u2295 y\u03022x3 \u2295 y3x23 \u2295 y4x33 = 0x68\nf2(X, Y\u0302 ) = f1(X, Y\u0302 )\u2295 y\u03025x21\u2295 y\u03026x3x1\u2295 y\u03027x23x1\u2295 y\u03028x33x1 = 0x7D\nHence, f(X, Y\u0302 ) = 0x7D 6= f(X,Y ), and the error is detected.\nSimilar to Example 9, max{deg(f(X,Y ), deg(f(X, Y\u0302 )} = 3. Consequently, at least 2562(256\u22123)X\u2019s out of 2563 are able to detect this code manipulation. In other words, the error masking probability for this specific error vector,\nE = ( 0xEB, 0x00, 0x00, 0x87, 0x00, 0x52, 0x20, 0x1E, 0x00, 0x00, 0x00, 0x00 ) ,\nis Q(E) \u2264 3 256\u22121 < Q\u0304.\nExample 11 (An adversary lengthening a basic block). Consider BB1 from Example 8. Assume that an adversary has lengthened this basic block by changing the branch instruction into a non-branch instruction. For example, assume that the tampered-with code becomes\nadd.w r2, r7, #16 subs r2, #8 add.w r1, r1, #2 //end of the original BB1\nbl 100 //end of the modified BB1\nbl 0 //end of BB2\nThe checker will \u201dsee\u201d the vector\nY\u0302 = (y\u030216, . . . , y\u03021) = ( 0xEB, 0x00, 0x00, 0x14, 0xE2, 0x81, 0x10, 0x02, 0xE2, 0x52, 0x20, 0x08, 0xE2, 0x87, 0x20, 0x10 ).\nThe checker will compare the computed tag value after the fourth cycle. Since the first two instructions were not changed, the computed tag value in the first and second cycles are identical to the first two tags in Example 8. In other words, we have,\nf1(X, Y\u0302 ) = y\u03021x1 \u2295 y\u03022x3 \u2295 y\u03023x23 \u2295 y\u03024x 3 3 = 0x68\nf2(X, Y\u0302 ) = f1(X, Y\u0302 ) \u2295 y\u03025x21 \u2295 y\u03026x3x1 \u2295 y\u03027x 2 3x1 \u2295 y\u03028x 3 3x1 = 0x72\nf3(X, Y\u0302 ) = f2(X, Y\u0302 ) \u2295 y\u03029x31 \u2295 y\u030210x3x 2 1 \u2295 y\u030211x 2 3x 2 1 \u2295 y\u030212x 3 3x 2 1 = 0xBA\nf4(X, Y\u0302 ) = f3(X, Y\u0302 ) \u2295 y\u030213x41 \u2295 y\u030214x3x 3 1 \u2295 y\u030215x 2 3x 3 1 \u2295 y\u030216x 3 3x 3 1 = 0x3B\nSince the computed tag f(X, Y\u0302 ) = f4(X, Y\u0302 ) = 0x3B differs from the tag read from the tamper-resistant memory, the error will be detected.\nNote that in this case 2563 \u2212 4 \u00b7 2562 X\u2019s out of 2563 are able to detect this code manipulation. In other words, the error masking probability for this error\nE = ( 0xEB, 0x00, 0x00, 0x14, 0x09, 0x81, 0x10, 0x85, 0x00, 0x00, 0x00, 0x00 0x00, 0x00, 0x00, 0x00 ).\nis Q(E) \u2264 4 256 < Q\u0304.\nExample 12 (The weakness of linear codes). This example shows that a linear code; e.g., the code in [11], will always have an error masking probability Q\u0304 = 1. Furthermore, even the use of a random vector X for masking the signature cannot solve the problem.\nAssume that a basic block is protected by a CRC32 code with the generator polynomial g(z) whose coefficients are G = 0x82F63B78 and a random mask X . Formally, let RY be the coefficients of the reminder polynomial\nrY (z) = Y (z)z 32 mod g(z),\nthen the tag function is f(Y ) = RY \u2295X. Consider the basic block from Example 8, and let the (secret) random mask be X = 0xFFFFFFFF. The corresponding tag, f(Y ) = 0x47718DEF \u2295 X = 0xB88E7210 , is stored in a tamper-resistant memory. Assume that an adversary with the ability to inject precise errors injects the error vector\nE = ( 0x00, 0x00, 0x00, 0x07, 0xB7, 0x1B, 0xD0, 0x50, 0x00, 0x00, 0x00, 0x00 ). .\nThen, the corresponding tampered code will be\nadd.w r2, r1, #16 strbpl pc, [sb, #-0x58] bl 528 //end of BB1\nmovs r1, #1 bl 0 //end of BB2\nFor this error vector we have rY (z) = rY\u0302 (z) for every random mask E. Since the calculated tag of the modified basic block, f(Y\u0302 ), is identical to one stored in the memory, the error will never be detected ( Q(E) = 1). In fact, any error vector E which is a multiple of the generator polynomial, will be masked.\nExample 13 (Error-recovery mechanism can help the adversary). Throughout this paper, we assumed that the adversary has the ability\nto choose the error. In practice, it is hard to inject precise errors, and thus, a fault can yield a non-valid opcode . As we show next, a decoder with error correction capabilities that attempts to recover from this error and correct the opcode may cause security issues.\nConsider the basic block, Y , and the corresponding CRC32 tag, f(Y ), from Example 12. Assume that the adversary failed to inject the intended error E, and instead flipped the bits such that the actual error is\nE\u2032 = ( 0x00, 0x00, 0x00, 0x07, 0xB1, 0x1B, 0xD0, 0x50, 0x00, 0x00, 0x00, 0x00 ). .\n(the differences between E and E\u2032 are marked in bold). In this case, the decoder finds out that the second instruction in the erroneous basic block, Y\u0302 , yields an invalid opcode. Consequently, the tuple c\u0302 = (Y + E\u2032, f(Y )) is not a valid codeword and the decoder activates the error correction mechanism. It decodes the erroneous word c\u0302 into a codeword c\u2032 \u2208 C for which the Hamming distance d(c\u2032, c\u0302) is minimal. From the properties of the CRC32 code it follows that c\u2032 is the codeword (Y + E, f(Y )) from Example 12. In other words, rather than correcting the basic block, the decoder helped the attacker to conduct a successful attack."
        }
    ],
    "title": "Nonlinear Code-based Low-Overhead Fine-Grained Control Flow Checking",
    "year": 2024
}