Natural language generation (NLG) is one of the most impactful fields in NLP, and recent years have witnessed its evolution brought about by large language models (LLMs). As the key instrument for writing assistance applications, they are generally prone to replicating or extending offensive content provided in the input. In low-resource data regime, they can also lead to repetitive outputs [1]. Usually, offensive content and repetitions are mitigated with post-hoc methods, including n-gram level blocklists, top-k and nucleus sampling. In this paper, we apply non-exact repetition suppression using token and sequence level unlikelihood loss, and further explore the framework of unlikelihood training objective in order to jointly endow the model with abilities to avoid generating offensive words and phrases from the beginning. Finally, with comprehensive experiments, we demonstrate that our proposed methods work exceptionally in controlling the repetition and content quality of LLM outputs. 1. conclusions & future work In this paper, we explored a joint effort of non-exact repetition suppression and content moderation to address the limitations of LLMs in generating repetitive and offensive content. We first set up SentenceBERT as a baseline of repetition detection & post-processing methods. Then, we utilized multiple levels of unlikelihood training objectives to suppress repetition at the step of generation. Finally, we exploited and further generalized the unlikelihood training objective and brought it into the field of content moderation. We demonstrated that our proposed methods work exceptionally well in controlling the repetition and content quality of LLM outputs. The results showed that multi-level
unlikelihood training objectives and our novel block loss greatly reduce token repetition, repetitive n-grams and offensive content while maintaining minimum impact on model performance.