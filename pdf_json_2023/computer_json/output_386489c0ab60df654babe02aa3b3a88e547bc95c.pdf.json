{
    "abstractText": "In this paper, we propose a noise-robust pulse wave estimation method from near-infrared face video images. Pulse wave estimation in a near-infrared environment is expected to be applied to non-contact monitoring in dark areas. The conventional method cannot consider noise when performing estimation. As a result, the accuracy of pulse wave estimation in noisy environments is not very high. This may adversely affect the accuracy of heart rate data and other data obtained from pulse wave signals. Therefore, the objective of this study is to perform pulse wave estimation robust to noise. The Wiener estimation method, which is a simple linear computation that can consider noise, was used in this study. Experimental results showed that the combination of the proposed method and signal processing (detrending and bandpass filtering) increased the SNR (signal to noise ratio) by more than 2.5 dB compared to the conventional method and signal processing. The correlation coefficient between the pulse wave signal measured using a pulse wave meter and the estimated pulse wave signal was 0.30 larger on average for the proposed method. Furthermore, the AER (absolute error rate) between the heart rate measured with the pulse wave meter was 0.82% on average for the proposed method, which was lower than the value of the conventional method (12.53% on average). These results show that the proposed method is more robust to noise than the conventional method for pulse wave estimation.",
    "authors": [
        {
            "affiliations": [],
            "name": "Yuta Hino"
        },
        {
            "affiliations": [],
            "name": "Koichi Ashida"
        },
        {
            "affiliations": [],
            "name": "Keiko Ogawa-Ochiai"
        },
        {
            "affiliations": [],
            "name": "Norimichi Tsumura"
        }
    ],
    "id": "SP:cb2d60fe74b36452a0573250bd2391637b58f58b",
    "references": [
        {
            "authors": [
                "Y. Hino",
                "K. Ashida",
                "N. Tsumura"
            ],
            "title": "A noise-robust pulse wave estimation from NIR video using Wiener estimation method",
            "venue": "In Proceedings of the Color and Imaging Conference,",
            "year": 2022
        },
        {
            "authors": [
                "M.V. Gastel",
                "S. Stuijk",
                "S. Overeem",
                "J.P.V. Dijk",
                "M.M.V. Gilst",
                "G.D. Haan"
            ],
            "title": "Camera-based vital signs monitoring during sleep-A proof of concept study",
            "venue": "IEEE J. Biomed. Health Inform",
            "year": 2020
        },
        {
            "authors": [
                "L.A.M. Aarts",
                "V. Jeanne",
                "J.P. Cleary",
                "J.S. Nelson",
                "S.B. Oetomo",
                "W. Verkruysse"
            ],
            "title": "Non-contact heart rate monitoring utilizing camera photoplethysmography in the neonatal intensive care unit\u2014A pilot study",
            "venue": "Early Hum. Dev",
            "year": 2013
        },
        {
            "authors": [
                "L. Iozzia",
                "L. Cerina",
                "L.T. Mainardi"
            ],
            "title": "Assessment of beat-to-beat heart rate detection method using a camera as contactless sensor",
            "venue": "In Proceedings of the 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,",
            "year": 2016
        },
        {
            "authors": [
                "Y. Sun",
                "N. Thakor"
            ],
            "title": "Photoplethysmography Revisited: From Contact to Noncontact, From Point to Imaging",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2016
        },
        {
            "authors": [
                "W. Verkruysse",
                "L.O. Svaasand",
                "J.S. Nelson"
            ],
            "title": "Remote plethysmographic imaging using ambient light",
            "venue": "Opt Express",
            "year": 2008
        },
        {
            "authors": [
                "K. Kurita",
                "T. Yonezawa",
                "M. Kuroshima",
                "N. Tsumura"
            ],
            "title": "Non-contact Video Based Estimation for Heart Rate Variability Spectrogram using Ambient Light by Extracting Hemoglobin Information",
            "venue": "In Proceedings of the Color and Imaging Conference,",
            "year": 2015
        },
        {
            "authors": [
                "M. Garbey",
                "N. Sun",
                "A. Merla",
                "I. Pavlidis"
            ],
            "title": "Contact-Free Measurement of Cardiac Pulse Based on the Analysis of Thermal Imagery",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2007
        },
        {
            "authors": [
                "W. Zeng",
                "Q. Zhang",
                "Y. Zhou",
                "G. Xu",
                "G. Liang"
            ],
            "title": "Infrared Video based Non-invasive Heart Rate Measurement",
            "venue": "In Proceedings of the IEEE Conference on Robotics and Biomimetics, Zhuhai, China,",
            "year": 2015
        },
        {
            "authors": [
                "R. Mitsuhashi",
                "G. Okada",
                "K. Kurita",
                "S. Kawahito",
                "C. Koopipat",
                "N. Tsumura"
            ],
            "title": "Noncontact pulse wave detection by two-band infrared video-based measurement on face without visible lighting",
            "venue": "Artif. Life Robot",
            "year": 2018
        },
        {
            "authors": [
                "D.M. Mancini",
                "L. Bolinger",
                "H. Li",
                "K. Kendrick",
                "B. Chance",
                "J.R. Wilson"
            ],
            "title": "Validation of near-infrared spectroscopy in humans",
            "venue": "J. Appl. Physiol",
            "year": 1994
        },
        {
            "authors": [
                "D. McDuff"
            ],
            "title": "Camera Measurement of Physiological Vital Signs",
            "venue": "ACM Comput. Surv",
            "year": 2023
        },
        {
            "authors": [
                "B. Lokendra",
                "G. Puneet"
            ],
            "title": "AND-rPPG: A novel denoising-rPPG network for improving remote heart rate estimation",
            "venue": "Comput. Biol. Med",
            "year": 2021
        },
        {
            "authors": [
                "J.S. Lee",
                "G. Hwang",
                "M. Ryu",
                "S.J. Lee"
            ],
            "title": "LSTC-rPPG: Long Short-Term Convolutional Network for Remote Photoplethysmography",
            "venue": "In Proceedings of the 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops,",
            "year": 2023
        },
        {
            "authors": [
                "C. Ash",
                "M. Dubec",
                "K. Donne",
                "T. Bashford"
            ],
            "title": "Effect of wavelength and beam width on penetration in light-tissue interaction using computational methods",
            "venue": "Lasers Med. Sci. 2017,",
            "year": 1909
        },
        {
            "authors": [
                "R.R. Anderson",
                "J.A. Parrish"
            ],
            "title": "The optics of human skin",
            "venue": "J. Invest. Dermatol",
            "year": 1981
        },
        {
            "authors": [
                "J. Liu",
                "B.P. Yan",
                "W.X. Dai",
                "X.R. Ding",
                "Y.T. Zhang",
                "N. Zhao"
            ],
            "title": "Multi-wavelength photoplethysmography method for skin arterial pulse extraction",
            "venue": "Biomed. Opt. Express",
            "year": 2016
        },
        {
            "authors": [
                "N. Tsumura",
                "H. Haneishi",
                "Y. Miyake"
            ],
            "title": "Estimation of Spectral Reflectances from Multi-Band Images by Multiple Regression Analysis",
            "venue": "Jpn. J. Opt",
            "year": 1998
        },
        {
            "authors": [
                "M. Kumar",
                "A. Veeraraghavan",
                "A. Sabharwal"
            ],
            "title": "DistancePPG: Robust non-contact vital signs monitoring using a camera",
            "venue": "Biomed. Opt. Express 2015,",
            "year": 2015
        },
        {
            "authors": [
                "S. Kwon",
                "J. Kim",
                "D. Lee",
                "K. Park"
            ],
            "title": "ROI analysis for remote photoplethysmography on facial video",
            "venue": "In Proceedings of the 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, Milan, Italy,",
            "year": 2015
        },
        {
            "authors": [
                "M.P. Tarvainen",
                "P.O. Ranta-Aho",
                "P.A. Karjalainen"
            ],
            "title": "An advanced detrending method with application to HRV analysis",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2002
        },
        {
            "authors": [
                "M.Z. Poh",
                "D.J. McDuff",
                "R.W. Picard"
            ],
            "title": "Non-contact, automated cardiac pulse measurements using video imaging and blind source separation",
            "venue": "Opt. Express",
            "year": 2010
        },
        {
            "authors": [
                "W. Wang",
                "A.C.D. Brinker",
                "G.D. Haan"
            ],
            "title": "Discriminative signatures for Remote-PPG",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2020
        },
        {
            "authors": [
                "T. Yamakoshi",
                "J. Lee",
                "K. Matsumura",
                "Y. Yamakoshi",
                "P. Rolfe",
                "D. Kiyohara",
                "K. Yamakoshi"
            ],
            "title": "Integrating Sphere FingerPhotoplethysmography: Preliminary Investigation towards Practical Non-Invasive Measurement of Blood Constituents",
            "venue": "PLoS ONE 2015,",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "Citation: Hino, Y.; Ashida, K.;\nOgawa-Ochiai, K.; Tsumura, N.\nNoise-Robust Pulse Wave Estimation\nfrom Near-Infrared Face Video\nImages Using the Wiener Estimation Method \u2020. J. Imaging 2023, 9, 202.\nhttps://doi.org/10.3390/\njimaging9100202\nAcademic Editors: Silvia Liberata\nUllo and Raimondo Schettini\nReceived: 24 August 2023\nRevised: 26 September 2023\nAccepted: 27 September 2023\nPublished: 28 September 2023\nCopyright: \u00a9 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: near-infrared; Wiener estimation method; pulse wave estimation"
        },
        {
            "heading": "1. Introduction",
            "text": "It is noted that a part of research was presented Color and Imaging Conference 2022 [1]. Recently, there has been growing demand for monitoring technology in dark areas. Examples of applications of monitoring technology in dark areas include vital signs monitoring during sleep [2]. One method to achieve this is to attach contact-type measurement devices. However, the prolonged use of contact-type devices may cause discomfort to users. In addition, some people have difficulty in attaching contact-type devices; for example, newborns and people with burns [3,4]. Because of these disadvantages of contact-type devices, non-contact measurement methods are being proposed. One non-contact measurement technique is the estimation of a pulse wave from face video images. By capturing subtle changes in the light reflected from the skin with a camera, pulse waves can be estimated [5,6]. From the estimated pulse wave, it is possible to obtain biometric information such as heart rate. Kurita et al. proposed a method for pulse wave estimation by separating RGB video images into melanin, hemoglobin, and shade components for analysis [7]. However, RGB cameras have problems in capturing video images and pulse wave estimations in low-light conditions. Near-infrared cameras have the advantage of being able to capture video images in low-light conditions. Garbey\nJ. Imaging 2023, 9, 202. https://doi.org/10.3390/jimaging9100202 https://www.mdpi.com/journal/jimaging\nJ. Imaging 2023, 9, 202 2 of 14\net al. proposed a method to measure pulse waves using a single-band medium wavelength infrared camera [8]. Zeng et al. proposed a method to estimate the pulse rate using a single-band near-infrared camera [9]. However, a single-band camera has the problem that the pulse wave estimation is affected by illumination in an environment with illumination fluctuation. Mitsuhashi et al. proposed a pulse wave estimation method that can be used in dark areas by using two-band near-infrared video images [10]. This method used two-band near-infrared video images to separate hemoglobin and shade components. By separating the components, the effect of illumination was removed and the pulse wave signal was estimated. However, this method does not consider noise for pulse wave estimation; thus, there is the issue with acquiring a distorted waveform when estimating the pulse wave signal. A distorted waveform may adversely affect the accuracy of physiological information obtained from pulse wave signals. In addition, hemoglobin absorption is weak in the near-infrared environment and estimated pulse wave signals are highly affected by noise [11,12]. There are some methods for denoising during pulse wave estimation [13,14]. However, these methods are deep-learning-based methods which can be complex in processing and difficult to implement. In addition, there are only a few types of large-scale datasets that include human biological information. In this paper, therefore, we propose a method for estimating pulse waves in dark areas while considering the effect of noise. Our proposed method is a modified version of Mitsuhashi et al.\u2019s method [10]. The Wiener estimation method was used for pulse wave estimation to consider noise. This estimation method can consider noise added to the video images by a linear operation. Therefore, it does not require complex processing techniques such as deep learning. Noise in images can be caused by thermal noise, illumination fluctuation or body motion. In this paper, we focus only on noise caused by thermal noise."
        },
        {
            "heading": "2. Skin Model in the Near-Infrared Environment",
            "text": "Light is classified into three categories: ultraviolet light, visible light and infrared light. Infrared light has a long wavelength range and is classified into near-infrared rays, mid-infrared rays and far-infrared rays according to its wavelength range. In this study, pulse wave estimation was performed using near-infrared video images in the wavelength range of approximately 780 nm to 1000 nm. Human skin is a multilayered structure that can be divided into three main parts: the epidermis, dermis and subcutaneous tissue. The skin contains various pigments such as melanin, hemoglobin and bilirubin. Among these pigments, changes in melanin and hemoglobin have a significant effect on skin coloration. Melanin is found in the epidermis, whereas hemoglobin is found in the dermis, where capillaries are located. Kurita et al. [7] used a two-layer skin model composed of the epidermis and dermis. They simplified the skin model by assuming that the epidermis is a layer containing only melanin and the dermis is a layer containing only hemoglobin. This allows us to assume that the layer containing only melanin and the layer containing only hemoglobin are spatially independent. Therefore, under visible light illumination, human skin can be treated as a two-layer skin model consisting of a melanin layer and a hemoglobin layer, as shown in Figure 1a. In Kurita et al. [7], melanin and hemoglobin components were estimated using independent component analysis after removing shading components from the observed signal in the density space. In order to separate the melanin, hemoglobin and shade components in a visible light environment, a three-band image such as RGB image is required. Kurita et al. [7] used an RGB camera; images obtained from an RGB camera contain only information obtained from visible light. On the other hand, near-infrared light has a longer wavelength than visible light. Therefore, it has a deeper penetration depth into the inside of a living body and is considered to be able to measure blood vessels deep inside the body, called microvessels, which exist even deeper than capillaries [15\u201317]. Therefore, it can be assumed that when light in the near-infrared environment enters the skin, reflection\nJ. Imaging 2023, 9, 202 3 of 14\noccurs only in the dermis, as shown in Figure 1b [9]. In this environment, no diffuse reflection occurs in the dermis. In order to separate the hemoglobin and shade components in the near-infrared environment, a two-band image is required. Therefore, the influence of the melanin component in the epidermis can be ignored in the near-infrared environment, whereas the melanin component is important in the visible light environment.\nJ. Imaging 2023, 9, x 3 of 14\ncomponents in the near-infrared environment, a two-band image is required. Therefore, the influence of the melanin component in the epidermis can be ignored in the near-infrared environment, whereas the melanin component is important in the visible light environment.\n(a) (b)\nFigure 1. Skin model at different light wavelengths. (a) Visible light; (b) infrared light.\n3. Hemoglobin and Shade Component Separation 3.1. Conventional Method\nThe pixel value \ud835\udc63 when captured by the camera is expressed by the following equation: \ud835\udc63 = \ud835\udc61 (\ud835\udf06)\ud835\udc38(\ud835\udf06)\ud835\udc46(\ud835\udf06)\ud835\udc5f(\ud835\udc65, \ud835\udc66, \ud835\udf06)\ud835\udc51\ud835\udf06, \ud835\udc56 = 1, \u2026 , \ud835\udc5a, (1) where \ud835\udc61 (\ud835\udf06) is the spectral transmittance of the ith filter, \ud835\udc38(\ud835\udf06) is the spectral radiance of the illumination, \ud835\udc46(\ud835\udf06) is the spectral sensitivity of the sensor and \ud835\udc5f(\ud835\udc65, \ud835\udc66, \ud835\udf06) is the spectral reflectance of the object at coordinates (\ud835\udc65, \ud835\udc66). Equation (1) can be represented graphically as in Figure 2.\nFigure 2. Process flow of Equation (1).\nExpressing Equation (1) in matrix form, it can be expressed as follows: \ud835\udc63 = \ud835\udc39\ud835\udc5f, (2) where \ud835\udc63 is a vector of pixel values, \ud835\udc39 is a matrix summarizing spectral transmittance, spectral radiance and spectral sensitivity and \ud835\udc5f is a vector of object reflectance. This equation is also valid when replacing \ud835\udc63 with a vector of the negative logarithm of the pixel\nFigure 1. Skin model at different light wavelengths. (a) Visible light; (b) infrared li t."
        },
        {
            "heading": "3. Hemoglobin and Shade Component Separation",
            "text": ""
        },
        {
            "heading": "3.1. Conventional Method",
            "text": "The pixel value vi when captured by the camera is expressed by the following equation:\nvi = \u222b ti(\u03bb)E(\u03bb)S(\u03bb)r(x, y, \u03bb)d\u03bb, i = 1, . . . , m, (1)\nwhere ti(\u03bb) is the spectral transmittance of the ith filter, E(\u03bb) is the spectral radiance of the illumination, S(\u03bb) is the spectral sensitivity of the sensor and r(x, y, \u03bb) is the spectral reflectance of the object at coordinates (x, y). Equation (1) can be represented graphically as in Figure 2.\nJ. Imaging 2023, 9, x 3 of 14\ncomponents in the near-infrared environment, a two-band image is required. Therefore, the influence of the melanin component in the epidermis can be ignored in the near-infrared environment, whereas the melanin component is important in the visible light environment.\n(a) (b)\nFigure 1. Skin model at different light wavelengths. (a) Visible light; (b) infrared light.\n3. Hemoglobin and Shade Component Separation .1. Conventio l Met o\nThe pixel value \ud835\udc63 when captured by the camera is expressed by the following equation: \ud835\udc63 = \ud835\udc61 (\ud835\udf06)\ud835\udc38(\ud835\udf06)\ud835\udc46(\ud835\udf06)\ud835\udc5f(\ud835\udc65, \ud835\udc66, \ud835\udf06)\ud835\udc51\ud835\udf06, \ud835\udc56 = 1, \u2026 , \ud835\udc5a, (1) where \ud835\udc61 (\ud835\udf06) is the spectral transmittance of the ith filter, \ud835\udc38(\ud835\udf06) is the spectral radiance of the illumination, \ud835\udc46(\ud835\udf06) is the spectral sensi ivity of the sensor and \ud835\udc5f(\ud835\udc65, \ud835\udc66, \ud835\udf06) is the spectral reflectance of the object at coordinat s (\ud835\udc65, \ud835\udc66). Equatio (1) can be represented graphically as in Figure 2.\nFigure 2. Process flow of Equation (1).\nExpressing Equation (1) in matrix form, it can be expressed as follows: \ud835\udc63 = \ud835\udc39\ud835\udc5f, (2) where \ud835\udc63 is a vector of pixel values, \ud835\udc39 is a matrix summarizing spectral transmittance, spectral radiance and spectral sensitivity and \ud835\udc5f is a vector of object reflectance. This equation is also valid when replacing \ud835\udc63 with a vector of the negative logarithm of the pixel\nFigure 2. Process flow of Equation (1).\nExpres ing Equation (1) in matrix form, it can be expressed as follows:\nv = Fr, (2)\nwhere v is a vector of pixel values, F is a matrix summarizing spectral transmittance, spectral radiance and spectral sensitivity and r is a vector of object reflectance. This equation is also\nJ. Imaging 2023, 9, 202 4 of 14\nvalid when replacing v with a vector of the negative logarithm of the pixel values and r with a vector of hemoglobin and shade components [9]. In the following sections, we will use the above replacement. Equation (2) is the equation for the case where no noise is added. However, noise is added to the image during actual image capture due to thermal noise and other causes. Therefore, when noise is added, Equation (2) can be expressed as follows:\nv = Fr + n, (3)\nwhere n denotes noise. When estimating r from v, the following equation is used for estimation:\nr = F\u22121v. (4)\nIt is noted that this estimation made by using simple inverse matrix (Equation (4)) is used as the conventional method in this paper. However, Equation (4) does not consider the noise added in Equation (3). Therefore, the estimated pigment components may differ significantly from the original ones."
        },
        {
            "heading": "3.2. Proposed Method",
            "text": "To estimate r from v after considering noise, the following matrix G can be used:\nr\u0303 = Gv, (5)\nwhere r\u0303 is the pigment component estimated using the Wiener estimation method. It is desirable to minimize the error between the correct value r and the estimated value r\u0303. For this purpose, the mean squared error between r and r\u0303 is first calculated. The mean square error can be expressed as follows:\nMSE = \u3008(r\u2212 r\u0303)T(r\u2212 r\u0303)\u3009, (6)\nwhere \u3008\u3009 denotes the ensemble mean for the pigment component vector. The estimation matrix that minimizes the mean squared error shown in Equation (6) is then expressed in Equation (7).\nG = RrvR\u22121vv , (7)\nwhere Rrv denotes the cross-correlation matrix of r and v, and Rvv denotes the autocorrelation matrix of v.\nRrv = \u3008rvT\u3009, (8)\nRvv = \u3008vvT\u3009, (9)\nThe autocorrelation matrix of r is expressed as in Equation (10).\nRrr = \u3008rrT\u3009, (10)\nUsing this, Equation (7) can also be expressed as in Equation (11).\nG = RrrFT ( FRrrFT )\u22121 . (11)\nIn this case, we assume that noise is added to the images, as shown in Equation (3). As a result, the estimation matrix is given by following equation:\nG = RrrFT ( FRrrFT + Rnn )\u22121 , (12)\nJ. Imaging 2023, 9, 202 5 of 14\nwhere Rnn denotes the autocorrelation matrix of the noise.\nRnn = \u3008nnT\u3009, (13)\nAs described above, the Wiener estimation method gives the estimation matrix that minimizes the mean-square error between the correct and estimated values using a simple linear operation when the signal and noise statics are known [18]."
        },
        {
            "heading": "4. Experimental Setup and Methods",
            "text": ""
        },
        {
            "heading": "4.1. Experimental Setup",
            "text": "We performed the experiments on a lab test bench setup. The experimental setup is shown in Figure 3. Three male subjects in their 20 s participated in this experiment. In a darkroom, the subject was illuminated with infrared LED lights (SA6-IR, EnergyPower, Hong Kong, China). The wavelength of this light is 850 nm. Face video images were captured for 30 s using a multi-band near-infrared camera (Spectral Devices, MSC2-BIO-1A) at 66.5 frames per second. Imaging was performed once for each subject. Each video image was saved as a still image, frame by frame to avoid the effects of compression. A total of 1995 frames of images were obtained for each subject. This camera had four wavelength bands centered at 735 nm, 800 nm, 865 nm and 930 nm. The resolution of each image was 512 \u00d7 512 pixels. The artificial skin patch was captured at the same time. The artificial skin patch was used to obtain the autocorrelation matrix Rnn of the noise added to the captured video images. Simultaneously with the imaging, a pulse wave signal was measured by attaching a photoelectric pulse wave meter (Procomp Infiniti, Thought Technology, Montreal, Canada) to the tip of the index finger of the subject\u2019s left hand. The subjects were instructed to place their chin on a chin rest, which minimized the subject\u2019s head motion as much as possible. In addition, the subjects were instructed to move their head and finger as little as possible during imaging.\nJ. Imaging 2023, 9, x 5 of 14"
        },
        {
            "heading": "4. Experimental Setup and Methods",
            "text": ""
        },
        {
            "heading": "4.1. Experimental Setup",
            "text": "We performed the experiments on a lab test bench setup. The experimental setup is shown in Figure 3. Three male subjects in their 20 s participated in this experiment. In a darkroom, the subject was illuminated with infrared LED lights (SA6-IR, EnergyPower, Hong Kong, China). The wavelength of this light is 850 nm. Face video images were captured for 30 s using a multi-band near-infrared camera (Spectral Devices, MSC2-BIO-1-A) at 66.5 frames per second. Imaging was performed once for each subject. Each video image was saved as a still image, frame by frame to avoid the effects of compression. A total of"
        },
        {
            "heading": "1995 frame of image were obtained for e ch subject. This camera had four wavelength bands centered t 735 nm, 800 nm, 865 nm and 930 nm. The resolution of e ch image was",
            "text": "512 \u00d7 512 pixels. The artificial skin patch was captured at the same time. The artificial skin patch was used to obtain the autocorrelation matrix \ud835\udc45 of the noise added to the captured video images. Simultaneously with the imaging, a pulse wave signal was measured by attaching a photoelectric pulse wave meter (Procomp Infiniti, Thought Technology, Montreal, Canada) to the tip of the index finger of the subject\u2019s left hand. The subjects were instructed to place their chin on a chin rest, which minimized the subject\u2019s head motion as much as possible. In addition, the subjects were instructed to move their head and finger as littl as possible during imaging.\nFigure 3. Experimental setup for capturing face video images."
        },
        {
            "heading": "4.2. Calculation Autocorrelation Matrixes",
            "text": "As described in Section 3, the noise autocorrelation matrix \ud835\udc45 is required when using the Wiener estimation method. To obtain the noise autocorrelation matrix, it is necessary to obtain the noise added to the captured video images. In this study, the noise added to the video images was obtained by simultaneously capturing an artificial skin patch with the subject\u2019s face. Ideally, the pixel values of artificial skin patch do not change because the surface condition of the artificial skin patch does not change over time. However, the pixel values of the artificial skin patch changed due to the influence of noise. This change in pixel value was used to determine the magnitude of the noise. The ROI (region of interest) was set for the image of the artificial skin patch, as shown in Figure 4, and the temporal variation of the averaged pixel value was calculated within the ROI. The standard deviation was also calculated on the temporal variation of the averaged pixel value. The above process was performed on the two bands used for imaging and the larger standard deviation was used in subsequent procedures. Then, Gaussian noise was generated by setting the mean value to 0 and the standard deviation to the obtained value. Finally, the autocorrelation matrix of the noise \ud835\udc45 was obtained using this generated noise.\nFigure 3. Experimental setup for capturing face video images."
        },
        {
            "heading": "4.2. Calculation Autocorrelation Matrixes",
            "text": "As described in Section 3, the noise autocorrelation matrix Rnn is required when using the Wiener estimatio meth d. To obtain the noise autocorrelation matrix, t is necessary to obtain th noise added to the captured video images. In this study, the noise dded to the video images was obtained by simultaneously capturing an artificial skin patch with the subject\u2019s face. Ideally, the pixel values of artificial skin patch do not change because the surface condition of the artificial skin patch does not change over time. However, the pixel values of the artificial skin patch changed due to the influence of noise. This change in pixel value was used to determine the magnitude of the noise. The ROI (region of interest) was set for the image of the artificial skin patch, as shown i Figure 4, and the temporal variation of the averaged pixel value was calculated within the\nJ. Imaging 2023, 9, 202 6 of 14\nROI. The standard deviation was also calculated on the temporal variation of the averaged pixel value. The above process was performed on the two bands used for imaging and the larger standard deviation was used in subsequent procedures. Then, Gaussian noise was generated by setting the mean value to 0 and the standard deviation to the obtained value. Finally, the autocorrelation matrix of the noise Rnn was obtained using this generated noise. J. Imaging 2023, 9, x 6 of 14\n(a) (b)\nFigure 4. Near-infrared video images of artificial skin patch. (a) Video images of artificial skin patch; (b) averaged pixel values of (a). The autocorrelation matrix of the skin pigment \ud835\udc45 is also required when using the Wiener estimation method. To calculate \ud835\udc45 , a value of \ud835\udc5f is required. In this study, the value of \ud835\udc5f obtained using the conventional method (Equation (4)) was used. The pigment component \ud835\udc5f consists of a hemoglobin component and a shade component, and both the hemoglobin and shade component were calculated as the average of the values obtained from each of the three subjects. When calculating \ud835\udc45 , the hemoglobin component values varied within the range of values obtained from three subjects, while the shade component values were fixed. This reflects the fact that the hemoglobin component fluctuated with time because of the blood, while the shade component did not. With the above settings of \ud835\udc5f, \ud835\udc45 was calculated. 4.3. Acquisition of the Original Pulse Wave Signal and Signal Processing\nThe temporal variation in the averaged pixel values in the ROI was analyzed by selecting two bands from the multi-band near-infrared face video images taken under the imaging environment described in Section 4.1 and setting the ROI as shown in Figure 5. The nose and cheeks were selected as the ROI [18]. In a vertical direction, the ROI was set in the range shown in Figure 5 to avoid the eye blink and lip motion. The ROI size was set as large as possible within the above range because a larger ROI size reduces noise [19]. In the current study, two-band images were used: one with a central wavelength of 800 nm and the other with a central wavelength of 930 nm. These two wavelengths were selected based on a previous study [9]. By using the temporal variation in the acquired average pixel values in Equations (4) and (5), respectively, the estimation results of the original pulse wave signal by the conventional and proposed methods could be obtained.\nFigure 5. Near-infrared face video images and ROI setting.\nDetrending [20] was performed on the original pulse wave signal. A bandpass filter was then applied. The frequency range transmitted by the bandpass filter was set to [0.75, 4.0] Hz [21,22]. The upper peak points were detected by finding the local maximum values for each waveform in the bandpass-filtered pulse wave signal. The peak points are used to estimate the heart rate. The heart rate can be calculated by using the interval between\nFigure 4. Near-infrared video images of artificial skin patch. (a) Video images of artificial skin patch; (b) averaged pixel values of (a).\nThe autocorrel tion matrix of the ski pigment Rrr is also required when using the Wiener estimation method. To calculate Rrr, a value of r is required. In this study, t value of r obtained using the conventional method (Equation (4)) was used. The pigment component r consists of a hemoglobin component and a shade component, and both the hemoglobin and shade compon nt were calculated as the v rage of the valu s obtained from each of the three subjects. Wh n calculating Rrr, the hemoglobin component values varied within the range of values obtained from three subjects, w ile the shade component values were fixed. This r fl cts the fact that the hemoglobin component fluctuated with time because of t e blood, while the shade component did not. With th above set ings of r, Rrr was calculated."
        },
        {
            "heading": "4.3. Acquisition of the Original Pulse Wave Signal and Signal Processing",
            "text": "The emporal variation in the veraged pixel values in the ROI was analyzed by selecting two bands from the multi-band near-infrared face video images taken under the imaging environment described in Section 4.1 and setting the ROI as shown in Figure 5. The nose and cheeks were selected as the ROI [19]. In a vertical direction, the ROI was set in the range shown in Figure 5 to avoid the eye blink and lip motion. The ROI size was set as large as possible within the above range because a larger ROI size reduces noise [20]. In the current study, two-band images were used: one with a central wavelength of 800 nm and the other with a central wavelength of 930 nm. These two wavelengths were selected based on a previous study [10]. By using the temporal variation in the acquired average pixel values in Equations (4) and (5), respectively, the estimation results of the original pulse wave signal by the conventional and proposed methods could be obtained.\nJ. Imaging 2023, 9, x 6 of 14\n(a) (b)\nFigure 4. Near-infrared video images of artificial skin patch. (a) Video images of artificial skin patch; (b) averaged pixel values of (a).\nThe autocorrelation matrix of the skin pigment \ud835\udc45 is also required when using the Wiener estimation method. To calculate \ud835\udc45 , a value of \ud835\udc5f is required. In this study, the value of \ud835\udc5f obtained using the conventional method (Equation (4)) was used. The pigment component \ud835\udc5f consists of a hemoglobin component and a shade component, and both the hemoglobin and shade component were calculated as the average of the values obtained from each f the hree subjects. When calculating \ud835\udc45 , the hemoglobi component values vari d within the range of valu s obtained rom three subjects, while the shade component values were fixed. This reflects the fact that the hemoglobin component fluctuated with time because of the blood, while the shade component did not. With the above settings of \ud835\udc5f, \ud835\udc45 was calculated. 4.3. Acquisition of the Ori inal Pulse Wave Signal and Signal Processing\nThe temporal variation in the averaged pixel values in the ROI was analyzed by selecting tw bands from the multi-band ear-infrar d face video images taken under the imaging nv onment descr bed in ection 4.1 and setting the ROI as shown in Figure 5. The nose and cheeks were selected as the ROI [18]. In a vertical direction, the ROI was set in the range shown in Figure 5 to avoid the eye blink and lip motion. The ROI size was set as large as possible within the above range because a larger ROI size reduces noise [19]. In the current study, wo- and images were used: one with a central wavelength of 800 nm and the other with a central wavelength of 930 nm. These two wavelengths were selected based n previous study [9]. By using the temporal variation in the acquired average pixel values in Equations (4) and (5), respectively, the estimation results of the original puls wave signal by the conventional and prop se methods could be obtained.\nFigure 5. Near-infrared face video images and ROI setting.\nDetrending [20] was performed on the original pulse wave signal. A bandpass filter was then a lied. The frequency range transmitted by the bandpass filter was set to [0.75, 4.0] Hz [21,22]. The upper peak points were detected by finding the local maximum values for each waveform in the bandpass-filtered pulse wave signal. The peak points are used to estimate the heart rate. The heart rate can be calculated by using the interval between\nFigure 5. Near-infrared face video images and ROI setting.\nJ. Imaging 2023, 9, 202 7 of 14\nDetrending [21] was performed on the original pulse wave signal. A bandpass filter was then applied. The frequency range transmitted by the bandpass filter was set to [0.75, 4.0] Hz [22,23]. The upper peak points were detected by finding the local maximum values for each waveform in the bandpass-filtered pulse wave signal. The peak points are used to estimate the heart rate. The heart rate can be calculated by using the interval between adjacent peak points, called the RR interval. The heart rate can be calculated by dividing 60 by RRinterval (the average of RR interval in the signal), as shown in Equation (14).\nHR = 60\nRRinterval (14)"
        },
        {
            "heading": "4.4. Evaluation Metrics",
            "text": "In this paper, the correlation coefficient, SNR (signal to noise ratio) and AER (absolute error rate) were used as evaluation metrics for pulse wave estimation. To calculate SNR, the pulse wave signals were Fourier-transformed to obtain the \u201cSignal\u201d component (0.5\u201315 Hz) and the \u201cNoise\u201d component (frequencies after 15 Hz) [24]. The \u201cSignal\u201d and \u201cNoise\u201d components were used to calculate the SNR from Equation (15).\nSNR = 20log10 ( Signal Noise ) [dB]. (15)\nThe AER between the estimated heart rate and the heart rate obtained using a pulse wave meter was determined [10]. AER is expressed by the following equation:\nAER = |HRGT \u2212 HREV |\nHRGT \u00d7 100. (16)\nwhere HRGT is the ground truth of the heart rate obtained using a pulse meter and HREV is the estimated heart rate obtained from the pulse wave estimated by the conventional or proposed method."
        },
        {
            "heading": "5. Results",
            "text": ""
        },
        {
            "heading": "5.1. Original Pulse Wave Signals",
            "text": "Figure 6 shows the original pulse wave signals obtained by applying the conventional and proposed methods to two-band near-infrared images and pulse wave signals obtained using a pulse wave meter. The correlation coefficient was calculated between the estimated pulse wave signals and the pulse wave signal obtained using a pulse wave meter. SNR was calculated from the pulse wave signals. Based on the results of the correlation coefficient and SNR (Table 1), the proposed method provides a stronger correlation than the conventional method. The results on SNR show that the proposed method can estimate pulse wave signals robustly regarding noise.\nJ. Imaging 2023, 9, 202 8 of 14J. Imaging 2023, 9, x 8 of 14\n(a) (b) (c)\n(d) (e) (f)\n(g) (h) (i)\nFigure 6. Original pulse wave signals. (a) Pulse wave meter (subject 1); (b) conventional method (subject 1); (c) proposed method (subject 1); (d) pulse wave meter (subject 2); (e) conventional method (subject 2); (f) proposed method (subject 2); (g) pulse wave meter (subject 3); (h) conventional method (subject 3); and (i) proposed method (subject 3).\nTable 1. Comparison of conventional and proposed methods (original pulse wave signals).\nSubjects Methods Correlation Coefficient\nSNR [dB]\nSubject 1 Conventional \u22120.004 \u22128.1\nProposed \u22120.027 \u22124.8\nSubject 2 Conventional \u22120.020 \u22128.4\nProposed \u22120.078 \u22124.6\nSubject 3 Conventional \u22120.004 \u22128.2\nProposed 0.059 \u22123.0\n5.2. After Signal Processing Detrending was performed on the original pulse wave signal and the results are shown in Figure 7. A bandpass filter was applied. Figure 8 shows the results of applying the bandpass filter.\nFigure 6. Original pulse wave signals. (a) Pulse wave meter (subject 1); (b) conventional method (subject 1); (c) proposed method (subject 1); (d) pulse wave meter (subject 2); (e) conventional method (subject 2); (f) proposed method (subject 2); (g) pulse wave meter (subject 3); (h) conventional method (subject 3); and (i) proposed method (subject 3)."
        },
        {
            "heading": "5.2. After Signal Processing",
            "text": "Detrending was performed on the original pulse wave signal and the results are shown in Figure 7. A bandpass filter was applied. Figure 8 shows the results of applying the bandpass filter. Correlation coefficients were calculated between each pulse wave signal and the pulse wave signal obtained using a pulse wave meter. SNR was calculated from each estimated pulse wave signal. Furthermore, the heart rate was estimated from each bandpass-filtered pulse wave signal, and AER was calculated between the estimated heart rate and the heart rate obtained from the pulse wave meter. The heart rate was estimated only from the bandpassfiltered pulse wave signals because the waveform after bandpass filtering had clearer peak points. Table 2 shows the results for the correlation coefficient, SNR and AER after each signal processing; the combined use of detrend and bandpass filtering makes the pulse wave signal robust to noise and improves the accuracy of heart rate estimation using the pulse wave signal. The pulse ve signal estimated using the proposed method showed a stronger correlation coefficient with the pulse wav signal obtained from a pulse wave met r. Furthermore, for the SNR and AER the results showed that the proposed method can achieve noise-robust pulse wave estimation and highly accurate heart rate estimation.\nJ. Imaging 2023, 9, 202 9 of 14J. Imaging 2023, 9, x 9 of 14\n(a) (b)\n(c) (d)\n(e) (f)\nFigure 7. Pulse wave signals after detrending. (a) Conventional method (subject 1); (b) proposed method (subject 1); (c) conventional method (subject 2); (d) proposed method (subject 2); (e) conventional method (subject 3); (f) proposed method (subject 3).\nFigure 7. Puls wave signals after detre ding. (a) Conventional method (subject 1); ( ) roposed method (subject 1); (c) conve tional method (subject 2); (d) r sed method (subject 2); (e) conve - tional method (subject 3); (f) propose etho (subject 3).\nJ. Imaging 2023, 9, 202 10 of 14\nJ. Imaging 2023, 9, x 9 of 14 (a) (b) (c) (d)\n(e) (f)\nFigure 7. Pulse wave signals after detrending. (a) Conventional method (subject 1); (b) proposed method (subject 1); (c) conventional method (subject 2); (d) proposed method (subject 2); (e) con-\nventional method (subject 3); (f) proposed method (subject 3).\n(a) (b)\n(c) (d)\nJ. Imaging 2023, 9, x 10 of 14\n(e) (f)\nFigure 8. Pulse wave signals after bandpass filtering. (a) Conventional method (subject 1); (b) proposed method (subject 1); (c) conventional method (subject 2); (d) proposed method (subject 2); (e) conventional method (subject 3); (f) proposed method (subject 3).\nCorrelation coefficients were calculated between each pulse wave signal and the pulse wave signal obtained using a pulse wave meter. SNR was calculated from each estimated pulse wave signal. Furthermore, the heart rate was estimated from each bandpass-filtered pulse wave signal, and AER was calculated between the estimated heart rate and the heart rate obtained from the pulse wave meter. The heart rate was estimated only from the bandpass-filtered pulse wave signals because the waveform after bandpass filtering had clearer peak points. Table 2 shows the results for the correlation coefficient, SNR and AER after each signal processing; the combined use of detrend and bandpass filtering makes the pulse wave signal robust to noise and improves the accuracy of heart rate estimation using the pulse wave signal. The pulse wave signal estimated using the proposed method showed a stronger correlation coefficient with the pulse wave signal obtained from a pulse wave meter. Furthermore, for the SNR and AER the results showed that the proposed method can achieve noise-robust pulse wave estimation and highly accurate heart rate estimation.\nTable 2. Correlation coefficient, SNR and AER results after each signal processing.\nSubjects Methods Signal Processing Correlation Coefficient SNR [dB] AER [%]\nSubject 1\nConventional Detrend 0.027 \u22128.8 -\nDetrend and bandpass filter\n0.109 \u22125.5 20.6\nProposed Detrend 0.342 0.3 -\nDetrend and bandpass filter 0.506 3.3 0.90\nSubject 2\nConventional Detrend 0.096 \u22128.8 -\nDetrend and bandpass filter 0.187 2.1 7.68\nProposed Detrend 0.353 \u22124.8 -\nDetrend and bandpass filter\n0.411 5.6 0.06\nSubject 3\nConventional Detrend 0.090 \u22122.9 -\nDetrend and bandpass filter\n0.246 2.1 9.31\nProposed Detrend 0.332 \u22125.1 -\nDetrend an bandpass filter 0.517 4.7 1.50\nFigure 8. Pulse wave signals after bandpass filtering. (a) Conventional method (subject 1); (b) proposed method (subject 1); (c) conventional method (subject 2); (d) proposed method (subject 2); (e) conventional method (subject 3); (f) proposed method (subject 3)."
        },
        {
            "heading": "6. Discussion",
            "text": "The advantage of the proposed method is that it shows robustness to noise at the point of the original pulse wave signal, as shown in Figure 6. This akes it possible to estimate the pulse wave using the proposed method even when the pulse wave is buried in noise using only a bandpass filter, as shown in Figure 8a. The accuracy of heart rate estimation differ d among subjects (Tables 1 nd 2). This may be du to slight differences in skin thickness [25] and the position of blood vessels among th subjects, which affects the accuracy of pulse wave estimation. In this pa er, the sample size wa small (three subjects). In order to provide sufficient discussion with a smal numb r of data, we de cribe below discussion of the relationship between the calcula ion meth d of he autocorr lation matrix Rrr used in the Wiener estimation method and the es lts. As described in Section 4.2, when calculating the autocorrelation matrix Rrr for the pigment components, the h moglobin and shade component values wer the verage values for all subjects obtained using the conventional method (Equation (4)). Here, we show the results obtained when calculating Rrr by utilizing the\nvalues of hem globi and sha e components for each individual subject. Figure 9 shows\nthe original pulse wave signal and the pulse wave signal after signal processing (detrend and bandpass filter) under the above co dition settings. Table 3 shows the correlation coefficient with the pulse wave signal obtained from the pulse wave meter, the SNR of each estimated pulse wave signal and the AER between the estimated heart rate and the heart rate obtained from the pulse wave meter. Comparing Figure 9 with Figures 6\u20138,\nJ. Imaging 2023, 9, 202 11 of 14\nalthough a change in the values of the vertical axis occurred in the original pulse wave signals, there was almost no effect on the approximate shape of the original pulse wave signals. Comparing Table 3 with Tables 1 and 2, the SNR was lowest in the case of subject 1, regardless of the method used to set the value of Rrr. The correlation coefficient, SNR and AER did not change significantly. These results indicate that the method of setting the Rrr value does not significantly influence the pulse wave estimation results. This may be due to the similarity between the values of hemoglobin and shade components obtained from each subject and the average of the component values for all subjects. However, since the subjects in this experiment had a narrow range of age, race, gender and sex, the method used to set the Rrr value is not considered to have a significant effect on the results. Further experiments will be performed with subjects of various ages, races and genders to further examine the individual differences in the accuracy of pulse wave estimation and the effect of the Rrr value setting method on accuracy in the future.\nJ. Imaging 2023, 9, x 11 of 14 6. Discussion The advantage of the proposed method is that it shows robustness to noise at the point of the original pulse wave signal, as shown in Figure 6. This makes it possible to estimate the pulse wave using the proposed method even when the pulse wave is buried in noise using only a bandpass filter, as shown in Figure 8a. The accuracy of heart rate estimation differed among subjects (Tables 1 and 2). This may be due to slight differences in skin thickness [24] and the position of blood vessels among the subjects, which affects the accuracy of pulse wave estimation.\nIn this paper, the sample size was small (three subjects). In order to provide sufficient discussion with a small number of data, we describe below a discussion of the relationship between the calculation method of the autocorrelation matrix R_rr used in the Wiener estimation method and the results. As described in Section 4.2, when calculating the autocorrelation matrix \ud835\udc45 for the pigment components, the hemoglobin and shade component values were the average values for all subjects obtained using the conventional method (Equation (4)). Here, we show the results obtained when calculating \ud835\udc45 by utilizing the values of hemoglobin and shade components for each individual subject. Figure 9 shows the original pulse wave signal and the pulse wave signal after signal processing (detrend and bandpass filter) under the above condition settings. Table 3 shows the correlation coefficient with the pulse wave signal obtained from the pulse wave meter, the SNR of each estimated pulse wave signal and the AER between the estimated heart rate and the heart rate obtained from the pulse wave meter. Comparing Figure 9 with Figures 6\u20138, although a change in the values of the vertical axis occurred in the original pulse wave signals, t ere was almost no effect on th appro mate shape of the or ginal pulse wave signals. Comparing Table 3 with Tables 1 and 2, the SNR was lowest in the case of subject 1, reg rdless of the method used to set the value of \ud835\udc45 . The correlation coefficient, SNR and AER did not change significantly. These results indicate that the method of setting the \ud835\udc45 value does not significantly influence the pulse wave estimation results. This may be due to the similarity between the values of hemoglobin and shade components obtained from each subject and the average of the component values for all subjects. However, since the subjects in this experiment had a narrow range of age, race, gender and sex, the method used to set the \ud835\udc45 value is not considered to have a significant effect on the results. Further experiments will be performed with subjects of various ages, races and genders to further examine the individual differences in the accuracy of pulse wave estimation and the effect of the \ud835\udc45 value setting method on accuracy in the future.\n(a) (b) (c)\n(d) (e) (f)\nJ. Imaging 2023, 9, x 12 of 14\n(g) (h) (i)\nTable 3. Correlation coefficient, SNR and AER results after changing \ud835\udc45 configuration.\nFigure 9. Pulse wave signals when changing the configuration of the pigment component values used for Rrr. (a) Original pulse wave signal (subject 1); (b) pulse wave signal after detrending (subject 1); (c) pulse wave signal after applying bandpass filtering (subject 1); (d) original pulse wave signal (subject 2); (e) pulse wave signal after detrending (subject 2); (f) pulse wave signal after applying bandpass filtering (subject 2); (g) original pulse wave signal (subject 3); (h) pulse wave signal after detrending (subject 3); and (i) pulse wave signal after applying bandpass filtering (subject 3).\nJ. Imaging 2023, 9, 202 12 of 14"
        },
        {
            "heading": "7. Conclusion and Future Works",
            "text": "In this study, we proposed a noise-robust pulse wave estimation method for nearinfrared face video images using the Wiener estimation method. We compared the proposed method with a conventional method in a near infrared environment. For pulse wave estimation in the near-infrared environment, pulse waves can be obtained by separating hemoglobin and shade components in two-band face video images. While the conventional method uses the inverse matrix of the pigment components (hemoglobin and shade component) vectors, the Wiener estimation method approximates the inverse matrix used in the conventional method by using the autocorrelation matrix of the pigment components and the autocorrelation matrix of the noise added to video images. Therefore, the estimation matrix obtained by the Wiener estimation method can consider noise, whereas the conventional method does not have any information about noise in the matrix used for component separation. The Wiener estimation method is a linear operation and can consider noise without the need for complex processing methods such as deep learning. The pulse wave signal was estimated using the proposed method and was compared with the one estimated using the conventional method. As evaluation metrics, we used the correlation coefficient between the pulse wave signal obtained from a pulse wave meter and the estimated pulse wave signal, the SNR of each estimated pulse wave signal and the AER between the estimated heart rate (only the estimated pulse wave signals that had been detrended and bandpass filtered) and the heart rate obtained from the pulse wave meter. In the comparison, experimental results showed that the combination of the proposed method and signal processing (detrending and bandpass filtering) increased the SNR by more than 2.5 dB compared to the conventional method and signal processing. The correlation coefficient between the pulse wave signal measured using the pulse wave meter and the estimated pulse wave signal was 0.48 on average for the proposed method and 0.18 on average for the conventional method, indicating a stronger correlation with the proposed method. Furthermore, the AER with the heart rate measured using the pulse wave meter averaged 0.82% for the proposed method and 12.53% for the conventional method, indicating that the pulse wave estimated using the proposed method can be used to estimate the heart rate with high accuracy. Although the results in the near-infrared environment were better than those obtained with the conventional method, it is necessary to verify the use of this method in environments other than the near-infrared environment, such as in RGB photography. It is also necessary to verify the method when the noise is larger than the noise added in this experiment. In this paper, only the noise caused by thermal noise was considered. However, for practical use, it will be necessary to consider other types of noise in the future.\nJ. Imaging 2023, 9, 202 13 of 14\nAuthor Contributions: Conceptualization, Y.H. and N.T.; methodology, Y.H.; software, Y.H; formal analysis, Y.H; investigation, Y.H.; data curation, Y.H.; writing\u2014original draft preparation, Y.H.; supervision, K.A. and N.T.; project administration, K.O.-O. and N.T. All authors have read and agreed to the published version of the manuscript.\nFunding: This research received no external funding.\nInstitutional Review Board Statement: This study was approved by the Ethics Review Committee for Epidemiological Research, Hiroshima University Hospital (E2021-2489). All participants agreed to the publication of the results obtained from the study. All results have been decoded. Individual results cannot be tracked.\nInformed Consent Statement: Informed consent was obtained from all subjects involved in the study.\nData Availability Statement: The data presented in this study are available on request from the corresponding author. These data are not publicly available due to ethical restrictions.\nConflicts of Interest: The authors declare no conflict of interest.\nReferences 1. Hino, Y.; Ashida, K.; Tsumura, N. A noise-robust pulse wave estimation from NIR video using Wiener estimation method. In Proceedings of the Color and Imaging Conference, Scottsdale, AR, USA, 13\u201317 November 2022. 2. Gastel, M.V.; Stuijk, S.; Overeem, S.; Dijk, J.P.V.; Gilst, M.M.V.; Haan, G.D. Camera-based vital signs monitoring during sleep-A proof of concept study. IEEE J. Biomed. Health Inform. 2020, 25, 1409\u20131418. [CrossRef] [PubMed] 3. Aarts, L.A.M.; Jeanne, V.; Cleary, J.P.; Nelson, J.S.; Oetomo, S.B.; Verkruysse, W. Non-contact heart rate monitoring utilizing\ncamera photoplethysmography in the neonatal intensive care unit\u2014A pilot study. Early Hum. Dev. 2013, 89, 943\u2013948. [CrossRef] [PubMed]\n4. Iozzia, L.; Cerina, L.; Mainardi, L.T. Assessment of beat-to-beat heart rate detection method using a camera as contactless sensor. In Proceedings of the 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, Orlando, FL, USA, 16\u201320 August 2016. 5. Sun, Y.; Thakor, N. Photoplethysmography Revisited: From Contact to Noncontact, From Point to Imaging. IEEE Trans. Biomed. Eng. 2016, 63, 463\u2013477. [CrossRef] [PubMed] 6. Verkruysse, W.; Svaasand, L.O.; Nelson, J.S. Remote plethysmographic imaging using ambient light. Opt Express. 2008, 16, 21434\u201321445. [CrossRef] [PubMed] 7. Kurita, K.; Yonezawa, T.; Kuroshima, M.; Tsumura, N. Non-contact Video Based Estimation for Heart Rate Variability Spectrogram using Ambient Light by Extracting Hemoglobin Information. In Proceedings of the Color and Imaging Conference, Darmstadt, Germany, 19\u201323 October 2015. 8. Garbey, M.; Sun, N.; Merla, A.; Pavlidis, I. Contact-Free Measurement of Cardiac Pulse Based on the Analysis of Thermal Imagery. IEEE Trans. Biomed. Eng. 2007, 54, 1418\u20131426. [CrossRef] [PubMed] 9. Zeng, W.; Zhang, Q.; Zhou, Y.; Xu, G.; Liang, G. Infrared Video based Non-invasive Heart Rate Measurement. In Proceedings of the IEEE Conference on Robotics and Biomimetics, Zhuhai, China, 6\u20139 December 2015. 10. Mitsuhashi, R.; Okada, G.; Kurita, K.; Kawahito, S.; Koopipat, C.; Tsumura, N. Noncontact pulse wave detection by two-band infrared video-based measurement on face without visible lighting. Artif. Life Robot. 2018, 23, 345\u2013352. [CrossRef] 11. Mancini, D.M.; Bolinger, L.; Li, H.; Kendrick, K.; Chance, B.; Wilson, J.R. Validation of near-infrared spectroscopy in humans. J. Appl. Physiol. 1994, 77, 2740\u20132747. [CrossRef] [PubMed] 12. McDuff, D. Camera Measurement of Physiological Vital Signs. ACM Comput. Surv. 2023, 55, 1\u201340. [CrossRef] 13. Lokendra, B.; Puneet, G. AND-rPPG: A novel denoising-rPPG network for improving remote heart rate estimation. Comput. Biol. Med. 2021, 141, 105146. [CrossRef] [PubMed] 14. Lee, J.S.; Hwang, G.; Ryu, M.; Lee, S.J. LSTC-rPPG: Long Short-Term Convolutional Network for Remote Photoplethysmography.\nIn Proceedings of the 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, Vancouver, BC, Canada, 17\u201324 June 2023.\n15. Ash, C.; Dubec, M.; Donne, K.; Bashford, T. Effect of wavelength and beam width on penetration in light-tissue interaction using computational methods. Lasers Med. Sci. 2017, 32, 1909\u20131918. [CrossRef] [PubMed] 16. Anderson, R.R.; Parrish, J.A. The optics of human skin. J. Invest. Dermatol. 1981, 77, 13\u201319. [CrossRef] [PubMed] 17. Liu, J.; Yan, B.P.; Dai, W.X.; Ding, X.R.; Zhang, Y.T.; Zhao, N. Multi-wavelength photoplethysmography method for skin arterial pulse extraction. Biomed. Opt. Express. 2016, 7, 4313\u20134326. [CrossRef] [PubMed] 18. Tsumura, N.; Haneishi, H.; Miyake, Y. Estimation of Spectral Reflectances from Multi-Band Images by Multiple Regression Analysis. Jpn. J. Opt. 1998, 27, 384\u2013391. 19. Kumar, M.; Veeraraghavan, A.; Sabharwal, A. DistancePPG: Robust non-contact vital signs monitoring using a camera. Biomed.\nOpt. Express 2015, 6, 1565\u20131588. [CrossRef] [PubMed]\nJ. Imaging 2023, 9, 202 14 of 14\n20. Kwon, S.; Kim, J.; Lee, D.; Park, K. ROI analysis for remote photoplethysmography on facial video. In Proceedings of the 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, Milan, Italy, 25\u201329 August 2015. 21. Tarvainen, M.P.; Ranta-Aho, P.O.; Karjalainen, P.A. An advanced detrending method with application to HRV analysis. IEEE Trans. Biomed. Eng. 2002, 49, 172\u2013175. [CrossRef] [PubMed] 22. Poh, M.Z.; McDuff, D.J.; Picard, R.W. Non-contact, automated cardiac pulse measurements using video imaging and blind source separation. Opt. Express 2010, 18, 10762\u201310774. [CrossRef] [PubMed] 23. Wang, W.; Brinker, A.C.D.; Haan, G.D. Discriminative signatures for Remote-PPG. IEEE Trans. Biomed. Eng. 2020, 67, 1462\u20131473. [CrossRef] [PubMed] 24. Yamakoshi, T.; Lee, J.; Matsumura, K.; Yamakoshi, Y.; Rolfe, P.; Kiyohara, D.; Yamakoshi, K. Integrating Sphere FingerPhotoplethysmography: Preliminary Investigation towards Practical Non-Invasive Measurement of Blood Constituents. PLoS ONE 2015, 10, e0143506. [CrossRef] [PubMed] 25. Moco, A.V.; Stuijk, S.; Haan, G.D. New insights into the origin of remote PPG signals in visible light and infrared. Sci. Rep. 2018, 8, 8501. [CrossRef] [PubMed]\nDisclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."
        }
    ],
    "title": "Noise-Robust Pulse Wave Estimation from Near-Infrared Face Video Images Using the Wiener Estimation Method \u2020",
    "year": 2023
}