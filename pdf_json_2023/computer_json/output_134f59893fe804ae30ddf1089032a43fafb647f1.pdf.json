{
    "abstractText": "This paper focuses on the optimal output synchronization control problem of heterogeneous multiagent systems (HMASs) subject to nonidentical communication delays by a reinforcement learning method. Compared with existing studies assuming that the precise model of the leader is globally or distributively accessible to all or some of the followers, the leader\u2019s precise dynamical model is entirely inaccessible to all the followers in this paper. A data-based learning algorithm is first proposed to reconstruct the leader\u2019s unknown system matrix online. A distributed predictor subject to communication delays is further devised to estimate the leader\u2019s state, where interaction delays are allowed to be nonidentical. Then, a learning-based local controller, together with a discounted performance function, is projected to reach the optimal output synchronization. Bellman equations and game algebraic Riccati equations are constructed to learn the optimal solution by developing a model-based reinforcement learning (RL) algorithm online without solving regulator equations, which is followed by a model-free off-policy RL algorithm to relax the requirement of all agents\u2019 dynamics faced by the model-based RL algorithm. The optimal tracking control of HMASs subject to unknown leader dynamics and communication delays is shown to be solvable under the proposed RL algorithms. Finally, the effectiveness of theoretical analysis is verified by numerical simulations.",
    "authors": [
        {
            "affiliations": [],
            "name": "Yong XU"
        },
        {
            "affiliations": [],
            "name": "Zheng-Guang WU"
        },
        {
            "affiliations": [],
            "name": "Wei-Wei CHE"
        },
        {
            "affiliations": [],
            "name": "Deyuan MENG"
        }
    ],
    "id": "SP:e294f78e799c5109b7c972a7119c6a98bb7129f6",
    "references": [
        {
            "authors": [
                "F Liu T",
                "Z Qin",
                "P. Jiang Z"
            ],
            "title": "A new look at distributed optimal output agreement of multi-agent systems",
            "year": 2022
        },
        {
            "authors": [
                "F Su Y",
                "J. Huang"
            ],
            "title": "Cooperative output regulation of linear multi-agent systems",
            "venue": "IEEE Trans Automat Contr,",
            "year": 2012
        },
        {
            "authors": [
                "H Cai",
                "J. Huang"
            ],
            "title": "Output based adaptive distributed output observer for leader-follower multiagent systems",
            "venue": "Automatica, 2021,",
            "year": 2021
        },
        {
            "authors": [
                "S Sutton R",
                "G. Barto A"
            ],
            "title": "Introduction to Reinforcement Learning",
            "year": 1998
        },
        {
            "authors": [
                "H Modares",
                "P Nageshrao S",
                "D Lopes G A"
            ],
            "title": "Optimal model-free output synchronization of heterogeneous systems using off-policy reinforcement learning",
            "year": 2016
        },
        {
            "authors": [
                "Y Yang",
                "H Modares",
                "C Wunsch D"
            ],
            "title": "Leader-follower output synchronization of linear heterogeneous systems with active leader using reinforcement learning",
            "venue": "IEEE Trans Neural Netw Learn Syst,",
            "year": 2018
        },
        {
            "authors": [
                "C Mu",
                "Q Zhao",
                "C. Sun"
            ],
            "title": "Optimal tracking control of heterogeneous MASs using event-driven adaptive observer and reinforcement learning",
            "venue": "IEEE Trans Neural Netw Learn Syst,",
            "year": 2022
        },
        {
            "authors": [
                "Y Xu",
                "G. Wu Z"
            ],
            "title": "Data-efficient off-policy learning for distributed optimal tracking control of HMAS with unidentified exosystem dynamics",
            "venue": "IEEE Trans Neural Netw Learn Syst,",
            "year": 2022
        },
        {
            "authors": [
                "Q Li",
                "L Xia",
                "R. Song"
            ],
            "title": "Leader-follower bipartite output synchronization on signed digraphs under adversarial factors via databased reinforcement learning",
            "venue": "IEEE Trans Neural Netw Learn Syst,",
            "year": 2020
        },
        {
            "authors": [
                "R Olfati-Saber",
                "M. Murray R"
            ],
            "title": "Consensus problems in networks of agents with switching topology and time-delays",
            "venue": "IEEE Trans Automat Contr,",
            "year": 2004
        },
        {
            "authors": [
                "B Zhou",
                "Z. Lin"
            ],
            "title": "Consensus of high-order multi-agent systems with large input and communication",
            "venue": "delays. Automatica,",
            "year": 2014
        },
        {
            "authors": [
                "X Yang",
                "B. Zhou"
            ],
            "title": "Consensus of discrete-time multiagent systems with input delays by truncated pseudo-predictor feedback",
            "venue": "IEEE Trans Cybern,",
            "year": 2017
        },
        {
            "authors": [
                "X Ge",
                "L Han Q",
                "M. Zhang X"
            ],
            "title": "Achieving cluster formation of multi-agent systems under aperiodic sampling and communication delays",
            "venue": "IEEE Trans Ind Electron,",
            "year": 2017
        },
        {
            "authors": [
                "M Lu",
                "L. Liu"
            ],
            "title": "Consensus of linear multi-agent systems subject to communication delays and switching networks",
            "venue": "Int J Robust Nonlinear Control,",
            "year": 2017
        },
        {
            "authors": [
                "M Lu",
                "L. Liu"
            ],
            "title": "Distributed feedforward approach to cooperative output regulation subject to communication delays and switching networks",
            "venue": "IEEE Trans Automat Contr,",
            "year": 2017
        },
        {
            "authors": [
                "J Yu",
                "L. Wang"
            ],
            "title": "Group consensus in multi-agent systems with switching topologies and communication delays",
            "venue": "Syst Control Lett,",
            "year": 2010
        },
        {
            "authors": [
                "Y Jiang",
                "P. Jiang Z"
            ],
            "title": "Robust adaptive dynamic programming for large-scale systems with an application to multimachine power systems",
            "venue": "IEEE Trans Circuits Syst II,",
            "year": 2012
        },
        {
            "authors": [
                "X Wang",
                "J Sun",
                "G Wang"
            ],
            "title": "Data-driven control of distributed event-triggered network systems",
            "venue": "IEEE CAA J Autom Sin, 2023,",
            "year": 2023
        },
        {
            "authors": [
                "L. Moreau"
            ],
            "title": "Stability of continuous-time distributed consensus algorithms",
            "venue": "Proceedings of the 43rd IEEE Conference on Decision and Control (CDC),",
            "year": 2004
        },
        {
            "authors": [
                "H Modares",
                "L Lewis F",
                "P. Jiang Z"
            ],
            "title": "H\u221e tracking control of completely unknown continuous-time systems via off-policy reinforcement learning",
            "venue": "IEEE Trans Neural Netw Learn Syst,",
            "year": 2015
        },
        {
            "authors": [
                "G Vamvoudakis K",
                "L Lewis F",
                "R. Hudas G"
            ],
            "title": "Multi-agent differential graphical games: online adaptive learning solution for synchronization with optimality",
            "year": 2012
        },
        {
            "authors": [
                "W Liu",
                "J Sun",
                "G Wang"
            ],
            "title": "Data-driven resilient predictive control under denial-of-service",
            "venue": "IEEE Trans Automat Contr,",
            "year": 2022
        },
        {
            "authors": [
                "Y Xu",
                "J Sun",
                "J Pan Y"
            ],
            "title": "Dynamic deadband event-triggered strategy for distributed adaptive consensus control with applications to circuit systems",
            "venue": "IEEE Trans Circuits Syst I,",
            "year": 2022
        },
        {
            "authors": [
                "P Zhang",
                "F Liu T",
                "P. Jiang Z"
            ],
            "title": "Event-triggered stabilization of a class of nonlinear time-delay systems",
            "venue": "IEEE Trans Automat Contr,",
            "year": 2021
        },
        {
            "authors": [
                "Y. Xu"
            ],
            "title": "Resilient secure control of networked systems over unreliable communication networks",
            "venue": "IEEE Trans Ind Inf,",
            "year": 2022
        },
        {
            "authors": [
                "Y Tao Y",
                "G. Wu Z"
            ],
            "title": "Asynchronous control of two-dimensional Markov jump Roesser systems: an event-triggering strategy",
            "venue": "IEEE Trans Netw Sci Eng, 2022,",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "c\u00a9 Science China Press 2023 info.scichina.com link.springer.com\ntiagent systems (HMASs) subject to nonidentical communication delays by a reinforcement learning method. Compared with existing studies assuming that the precise model of the leader is globally or distributively accessible to all or some of the followers, the leader\u2019s precise dynamical model is entirely inaccessible to all the followers in this paper. A data-based learning algorithm is first proposed to reconstruct the leader\u2019s unknown system matrix online. A distributed predictor subject to communication delays is further devised to estimate the leader\u2019s state, where interaction delays are allowed to be nonidentical. Then, a learning-based local controller, together with a discounted performance function, is projected to reach the optimal output synchronization. Bellman equations and game algebraic Riccati equations are constructed to learn the optimal solution by developing a model-based reinforcement learning (RL) algorithm online without solving regulator equations, which is followed by a model-free off-policy RL algorithm to relax the requirement of all agents\u2019 dynamics faced by the model-based RL algorithm. The optimal tracking control of HMASs subject to unknown leader dynamics and communication delays is shown to be solvable under the proposed RL algorithms. Finally, the effectiveness of theoretical analysis is verified by numerical simulations.\nKeywords heterogeneous multiagent systems, HMAS, reinforcement learning, RL, optimal output synchronization, communication delays\nCitation Xu Y, Wu Z-G, Che W-W, et al. Reinforcement learning-based unknown reference tracking control of HMASs with nonidentical communication delays. Sci China Inf Sci, 2023, 66(7): 170203, https://doi.org/10.1007/ s11432-022-3729-7"
        },
        {
            "heading": "1 Introduction",
            "text": "Considerable attention from different domains has been focused on the cooperative tracking control of multiagent systems (MASs), and its control purpose at urging the reference trajectory generated by the leader can be tracked by a group of following agents by exploiting different distributed control protocols. Many tracking control algorithms are broadly reported in [1\u20135]."
        },
        {
            "heading": "1.1 Related work",
            "text": "Existing results for similar leader-follower synchronization control of MASs with homogeneous dynamics have been widely investigated with different control algorithms. Unfortunately, these developed algorithms are useless for heterogeneous systems. In terms of the output synchronization control of heterogeneous multiagent systems (HMASs), a two-layer framework was first proposed in [6]. Afterward, different cooperative control algorithms were designed. For example, Ref. [7] designed a relative output-based dynamic compensator for the output tracking of HMASs under a distributed controller comprising the\n*Corresponding author (email: nashwzhg@zju.edu.cn)\ndynamic compensator\u2019s state and the local agent. Ref. [8] proposed an adaptive fault-tolerant controller for the output tracking control problem of HMASs. Ref. [9] put forward an adaptive control protocol for a robust tracking consensus of HMASs with disturbance and actuator faults. Ref. [10] discussed the output consensus problem of HMASs subject to nonlinear dynamics using a distributed dynamic compensator. The output tracking control subject to self-tuning parameters through an event-triggered control mechanism was addressed in [11]. Ref. [12] developed a distributed adaptive observer approach for the leader-follower consensus control of MASs, where the function of the adaptive observer is used to estimate the prior knowledge of the exosystem, and the adaptive observer using the relative output information is considered with a similar method in [13]. However, these abovementioned communication protocols among agents are not configurated optimally because the proposed control policy requires obtaining an accurate model in advance. Fortunately, reinforcement learning (RL) [14] is an effective tool for providing a tight link with optimal control, and many optimal consensus results have been reported. The optimal output synchronization of HMASs was considered using the RL algorithm in [15]. An RLbased containment control protocol for MASs with an active leader was discussed in [16]. The optimal leader-follower tracking consensus controller design of MASs with switching topologies using the RL algorithm was investigated in [17]. The RL-based optimal output trajectory following control of HMASs with an unknown exosystem was discussed in [18]. A data-based RL-based optimal output synchronization scheme was proposed for HMASs with event-triggered communication in [19], and so on. Importantly, the abovementioned RL-based studies assume that the leader\u2019s system matrix is completely accessible to some or all of the followers in a completely unrestricted communication environment. Moreover, a communication delay is neglected in the abovementioned RL-based optimal tracking control of HMASs.\nCommunication latency is inevitable in the process of agent information exchange in practical communication environments. The occurrence of communication delay brings great difficulty to coordination control and even causes catastrophic damage to a system\u2019s stability. The consensus studies related to communication delays and input delays have been conducted using various techniques, including the frequency domain method in [20] and the Lyapunov method related to Lyapunov-Krasovskii theorem or Razumikhin theorem in [21\u201323]. The distributed consensus subject to state and input delays has been discussed in [24], which is further addressed to consider unknown transmission delays in [25]. Although different algorithms were proposed in the abovementioned studies, challenging issues remain, such as (1) the precise model of the leader is assumed to be known by some or all followers in the literature. Nevertheless, it seems to be difficult to enable all agents to know the leader\u2019s information in practical applications. (2) Existing results consider uniform communication delays for each agent and its neighbors with a single or double integrator [20\u201323,26], while nonuniform and time-varying communication delays are considered for the general linear MASs in this article. The existing algorithms cannot be extended to solve the nonuniform (or nonidentical) communication delays. This difficulty is due to the fact that the closed-loop system subject to nonidentical communication delays cannot be written in a tractable compact form. (3) In [6\u201310, 12\u201314], the output tracking consensus results mostly rely on solvable regulator equations that require prior knowledge of the leader\u2019s system matrix. If the regulator equations are unsolvable because each agent does not know the leader, then output tracking is difficult to achieve. (4) The developed consensus protocols subject to communication delays are not formed in an optimal control fashion. Thus, the integration of the RL-based algorithm and nonidentical communication delays to solve the optimal output tracking control problem is rarely reported and motivates us to conduct this study."
        },
        {
            "heading": "1.2 Main contributions",
            "text": "Based on the abovementioned challenges, this paper employs a learning method to achieve the output state trajectory tracking of HMASs with an unknown leader\u2019s model and uncertain but bounded timevarying communication delays. The contributions of this paper are summarized as follows.\n\u2022 Contrary to most existing results where some or all followers know the leader\u2019s prior information, an accurate dynamical model of the reference system is entirely unknown to those tracking agents in this paper. A data-based learning algorithm is proposed to reconstruct the leader\u2019s parameter matrix.\n\u2022 Compared with existing studies [21, 26] in which the communication delays imposed by each agent itself and its neighbors are uniform, the time-varying interaction delays only influencing information about each agent\u2019s neighbors are considered for the general HMASs, where the communication delays may be nonidentical for different neighbor agents, which makes the problem more practical and challenging.\n\u2022 Model-based and model-free learning algorithms are given to guarantee output synchronization without directly solving the regulation equations. Moreover, the model-free case does not rely on the agents\u2019 dynamics that are required by the model-based RL algorithm.\nThe outline of the remainder of this paper is as follows: Preliminaries and a problem statement are presented in Section 2, and Section 3 gives the main results. A numerical example is provided in Section 4, and the conclusion is drawn in Section 5.\nNotations. Rn and Rn\u00d7m denote the set of the real vectors of dimension n and the set of real matrices of dimensions n\u00d7m, respectively. Z+ denotes the set of positive integers. diag{\u2217} is a diagonal matrix with nondiagonal elements being zero. I\u030ci is a square matrix. I\u0302i is the i-th row of I\u030ci, and all other rows of I\u0302i are zero row vectors. For a matrix A, \u03bb [A] i denotes its eigenvalue, and rank(A) denotes its rank. Define x|ab = x(a)\u2212 x(b)."
        },
        {
            "heading": "2 Preliminaries and the problem statement",
            "text": "Consider a group of N agents with the dynamics of the i-th agent expressed as\nr\u0307i(t) = Airi(t) +Biui(t), yi(t) = Ciri(t), (1)\nwhere ri(t) is the state, ui(t) is the control input, and yi(t) is the output, respectively. Matrices Ai, Bi, and Ci with different dimensions are known.\nTo track a reference trajectory (called the leader), its dynamical model is as follows:\nr\u03070(t) = A0r0(t), y0(t) = Fr0(t), (2)\nwhere r0(t) \u2208 R m is the state of the leader, and A0 is completely inaccessible to all followers.\nFor the leader-follower systems in (1) and (2), a directed graph G = (A ,V , E ) comprises the adjacent matrix A = [aij ] \u2208 R\nn\u00d7m, the node set V = {v1, . . . , vN}, and an edge set E \u2286 V \u00d7V , respectively. The adjacent matrix\u2019s element aij > 0 if (vi, vj) \u2208 E ; otherwise, aij = 0. For two distinct nodes vi and vj , if vi can obtain the information of vj , and there is a communication link. Then define L = [Lij ] \u2208 R n\u00d7m as the Laplacian matrix, and its elements satisfies Lij = \u2212aij , i 6= j and Lii = \u2211N j=1,j 6=i aij . If there exists a pinning node v0, the new communication topology graph G\u0304 is described by G\u0304 = G \u222a v0, and its element ai0 > 0 if vi can directly receive the leader\u2019s information, and otherwise ai0 = 0, and the overall relationship between vi and v0 can be described by a diagonal matrix D = diag{ai0}. In terms of v0, if v0 and any distinct nodes have an information flow (path), the graph is considered to have a spanning tree in G . The link between L and D can be given as H = L + D , and the characteristic roots of H are monotonically increasing, namely, 0 < \u03bb [H ] 1 < \u03bb [H ] 2 < \u00b7 \u00b7 \u00b7 < \u03bb [H ] N .\nProblem statement: For the HMAS in (1) and (2), develop a learning-based distributed controller ui(t) subject to obeying heterogeneous time-varying communication delays.\n(1) The matrix A0 in (2) can be reconstructed with system data by all followers; (2) The output trajectory of each tracking agent tracks the reference system output trajectory by\ndeveloping the distributed controller in an optimal way, satisfying\nlim t\u2192\u221e \u2016ei(t)\u2016 = lim t\u2192\u221e \u2016yi(t)\u2212 y0(t)\u2016 = 0, i = 1, . . . , N. (3)\nTo achieve the output tracking control, some assumptions in [6, 7] are used as follows.\nAssumption 1. The communication topology graph is called to have a spanning tree if the leader at least has a path to all tracking followers.\nAssumption 2. The pair (Ai, Bi) is stabilizable.\nAssumption 3. All characteristic roots of the matrix A0 lie in imaginary axis or have no positive parts."
        },
        {
            "heading": "3 Main results",
            "text": "In this section, a data-based learning algorithm is given to reconstruct the matrix A0 for each follower. Then, a stability analysis of the prediction error between the predictor and the leader subject to nonidentical communication delays is discussed."
        },
        {
            "heading": "3.1 Identification of A0 using a data-based learning algorithm",
            "text": "According to the dynamic of the leader, Eq. (2) can be rewritten in the following form by integrating from t = t+ (\u03c3 \u2212 1)t to t+ \u03c3t with \u03c3 > 0 being the sampling period as\nr0| t+\u03c3t t+(\u03c3\u22121)t = A0\n\u222b t+\u03c3t\nt+(\u03c3\u22121)t\nrT0 (\u03c4)d\u03c4, (4)\nwhere the system data of (2) are stored at the initial instant with \u03c3 = 1 by introducing the following two vectors denoted by \u0393\u03c3 and G\u03c3 to collect system data as follows:\n\u0393\u03c3 = col ( r0| t+\u03c3t t+(\u03c3\u22121)t ) , G\u03c3 = Im \u2297 col\n(\n\u222b t+\u03c3t\nt\u2212(\u03c3\u22121)t\nrT0 (\u03c4)d\u03c4\n)\n, \u03c3 = 1, 2, . . . . (5)\nThe use of the Kronecker product to combine (4) and (5) yields\n\u0393\u03c3 = G\u03c3 \u00b7 vec(A0), (6)\nwhere vec(A0) = [A [1] 0 , A [2] 0 , . . . , A [m] 0 ] T. Theorem 1. In an HMAS under Assumption 3, assume that the prior knowledge of the leader (2) is unknown to each follower. The leader\u2019s matrix A0 can be identified and reconstructed by satisfying the following conditions. (1) The matrix A0 can be identified provided that rank[G\u03c3] = m\n2; and (2) each follower can compute the identifiable matrix A0 obeying\nA0 = [ (G\u22121\u03c3 \u0393\u03c3)\u03c3\u2192m \u00b7 \u00b7 \u00b7 (G \u22121 \u03c3 \u0393\u03c3)(m2\u2212m)\u2192m2 ] , (7)\nwhere (G\u22121\u03c3 \u0393\u03c3)\u03c3\u2192m can be obtained by using the 1th to mth element of (G \u22121 \u03c3 \u0393\u03c3). Proof. If Assumption 3 holds, then confirmation that the matrix G\u03c3 exists as a full rank satisfying rank[G\u03c3] = m\n2 is not difficult to obtain. Inspired by the idea of the data-driven methods in [27, 28], the matrix A0 can be identified only when the rank condition is met. Thus, the first part is completed. In contrast, if the rank condition holds, one can conclude that the inverse matrix (\u0393\u03c3)\n\u22121 exists, implying that the constructed matrix A0 can be derived by computing (7).\nRemark 1. Similar results suppose that the leader\u2019s prior knowledge is accessible to some or all of the followers. In terms of some followers having no prior knowledge of the leader, a combination of the adaptive control and the observer approach is employed in [12,13] to estimate the leader\u2019s system model, respectively. Unlike existing results for similar problems, the most obvious difference is that the leader\u2019s prior knowledge is totally unknown to those tracking followers in this article. To address this thorny problem, a data-based learning algorithm and a data-driven control are used to identify and reconstruct A0 in (7)."
        },
        {
            "heading": "3.2 Technical lemmas on nonidentical communication delays",
            "text": "Considering that the occurrence of data transmission among agents is subject to nonidentical communication delays, some technical lemmas are given below to facilitate the stability of prediction error systems.\nDefinition 1 ([29]). A matrix is called a Metzler matrix if its off-diagonal elements are positive or zero.\nDefinition 2 (\u03b4-digraph [29]). Given a Metzler matrix, the \u03b4-digraph (\u03b4 > 0) associated with a Metzler matrix is the digraph related to both the node set and an arc when and only when the entry of a Metzler matrix is greater than \u03b4.\nLemma 1 ([29]). For the following linear time-delay system:\nx\u0307(t) = diag(L (t))x(t) + L\u0304 (t)x(t\u2212 \u01eb), (8)\nwhere L\u0304 (t) = L (t) \u2212 diag(L (t)) denotes the off-diagonal elements of L (t). Suppose that the system matrix L (t) is a bounded and piecewise continuous function of time. If the system matrix L (t) is Metzler with zero row sums. Under Assumption 1, if the equilibrium set of consensus states is uniformly exponentially stable. All components of any solution of (8) converge to a common value as t \u2192 \u221e.\nNote that Lemma 1 only considers the leaderless consensus subject to communication delays for a single system. In this paper, the general case, including the existence of the leader, and multiple neighboring agents, is considered under heterogeneous communication delays. The extension of Lemma 1 is given in the following Lemma 2 under fixed topology.\nLemma 2. Consider the time-delay systems with the leader described by\nx\u0307 = \u2212\u03b1(diag(H )\u2297 In)x\u2212 \u03b1\nN \u2211\ni=1\n((I\u030ciH\u0304 )\u2297 In)((Fi \u2297 In)x), (9)\nwhere x = [xT1 , . . . , x T N ] T is the tracking error of the time-delay systems, Fi = diag{fij} with fiix(t) = x(t) and fijx(t) = x(t\u2212 \u01ebij(t)) for i 6= j for some piecewise continuous \u01ebij(t) and 0 6 \u01ebij(t) 6 \u01eb for some positive constants \u01eb. H\u0304 = H \u2212 diag(H ) with H = L + D defined in graph theory, and \u03b1 > 0 is a constant. Then, the initial point of (9) is exponentially stable.\nProof. According to (9) for a single system, the dynamics of an MAS in the presence of heterogeneous delays, as an extension of (9), is expressed as\nx\u0307i(t) = \u2212\u03b1 N \u2211\nj=1\naij(xj(t\u2212 \u01ebij(t))\u2212 xi(t)) or x\u0307(t) = \u2212\u03b1diag(L (t))x(t) \u2212 \u03b1 N \u2211\ni=1\nI\u030ciL\u0304 (t)(Fix(t)).\n(10)\nThe compact form of multiple time-delay systems (10) is given as follows:\nx\u0307 = \u2212\u03b1(diag(L )\u2297 In)x\u2212 \u03b1\nN \u2211\ni=0\n((I\u030ci+1L\u0304 )\u2297 In)[Fi \u2297 In]x, (11)\nwhere x = [xT0 , x T 1 , . . . , x T N ] T, and \u03b1 > 0 is a constant number. L\u0304 = L \u2212 diag(L ) with L being the Laplacian matrix of L by removing the link (0, i) i = 1, . . . , N . Because the interaction topology is fixed, the \u03b4-graph has the property that every agent i = 1, . . . , N , is reachable from the agent 0 based on Definition 2. Similar to [6, 25], according to Definition 1, \u03b1diag(L ) is a Metzler matrix with zero row sums. Then, limt\u2192\u221e xi(t) = x0(0), i = 1, . . . , N is easy to conclude based on Lemma 1. Because H = L + D with the diagonal matrix D , the exponential stability of (9) is easily inferred."
        },
        {
            "heading": "3.3 Predictor design subject to communication delays",
            "text": "The distributed predictor with communication delays is designed to estimate the reference system\u2019s state as follows:\n\u03b7\u0307i(t) = A0\u03b7i(t) + c N \u2211\nj=0\naij [e A0\u01ebij(t)\u03b7j(t\u2212 \u01ebij(t))\u2212 \u03b7i(t)]\n= A0\u03b8i(t) + c\nN \u2211\nj=1\naij [e A0\u01ebij(t)\u03b7j(t\u2212 \u01ebij(t))\u2212 \u03b7i(t)] + cai0[e A0\u01ebi0(t)\u03b70(t\u2212 \u01ebi0(t))\u2212 \u03b7i(t)], (12)\nwhere eA0\u01ebi0(t)\u03b70(t\u2212\u01ebi0(t)) = r0(t) based on (2). The last term of (12) is associated with the heterogeneous delay between the leader and its neighboring agent.\nRemark 2. Existing results consider the simple network structure with one single coupling subject to one single communication delay in [29], while different communication links among agents corresponding to nonidentical delays are considered with multiple network structures and multiple couplings in this paper. Moreover, most existing studies in [20\u201323,26] consider that states of adjacent agents are afflicted by uniform communication delays. In our paper, the time-varying interaction delays only influencing information about each agent\u2019s neighbors are considered, which are allowed to be nonidentical. Therefore, a consensus analysis with nonidentical communication delays is made more challenging. The difficulty emerges because the nonidentical communication delays for the closed-loop systems cannot be written in a tractable compact form.\nTheorem 2. Consider the HMAS in (1) and (2) with a directed communication graph. Under Assumptions 1\u20133, a predictor based on the learning-based algorithm can predict the state of a leader satisfying \u03b7i(t) \u2192 r0(t) as t \u2192 \u221e. Proof. Define the prediction error as \u03b8i(t) = \u03b7i(t)\u2212 r0(t). The time derivative of \u03b8i satisfies\n\u03b8\u0307i(t) = A0\u03b8i(t) + c N \u2211\nj=1\naij [e A0\u01ebij(t)\u03b7j(t\u2212 \u01ebij(t))\u2212 \u03b7i(t)] + cai0[e A0\u01ebi0(t)\u03b70(t\u2212 \u01ebi0(t))\u2212 \u03b7i(t)]\n= A0\u03b8i(t) + c\nN \u2211\nj=0\naij\n[\neA0\u01ebij(t) [ \u03b8j(t\u2212 \u01ebij(t)) + r0(t\u2212 \u01ebij(t))\u2212 (\u03b8j(t) + r0(t)) ]\n]\n= A0\u03b8i(t) + c N \u2211\nj=0\naij\n[\neA0\u01ebij(t)\u03b8j(t\u2212 \u01ebij(t)) \u2212 \u03b8j(t)\n]\n. (13)\nLetting \u03b8\u0303i(t) = e \u2212A0t\u03b8i(t), it follows that\n\u02d9\u0303 \u03b8i(t) = \u2212A0e \u2212Ait\u03b8i(t) + e \u2212A0t\n[\nA0\u03b8i(t) + c\nN \u2211\nj=0\naij\n[ eA0\u01ebij(t)\u03b8j(t\u2212 \u01ebij(t))\u2212 \u03b8i(t) ]\n]\n= c\nN \u2211\nj=0\naij [e \u2212A0(t\u2212\u01ebij(t))\u03b8j(t\u2212 \u01ebij(t)) \u2212 e \u2212A0t\u03b8i(t)]\n= c N \u2211\nj=0\naij [\u03b8\u0303j(t\u2212 \u01ebij(t))\u2212 \u03b8\u0303i(t)]. (14)\nThe above equation can be rewritten in a compact form as\n\u02d9\u0303 \u03b8(t) = \u2212c\n[\ndiag(H )\u2297 In\n]\n\u03b8\u0303(t)\u2212 c\nN \u2211\ni=1\n[\n(H \u2212 diag(H ))\u2297 In\n]\n[(Fi \u2297 In)\u03b8\u0303(t)], (15)\nwhere \u03b8\u0303 = [\u03b8\u0303T1 , . . . , \u03b8\u0303 T N ] T. Therefore, it frankly knows that \u03b8\u0303(t) \u2192 0 as t \u2192 \u221e based on Lemma 2.\nSince \u03b8\u0303i(t) = e \u2212Ait\u03b8i(t), there exist positive constants \u03b31 and \u03b32 satisfying\nlim t\u2192\u221e \u2016\u03b8(t)\u2016 6 lim t\u2192\u221e\n\u2016(In \u2297 e \u2212A0t)\u03b8\u0303(t)\u2016 6 lim\nt\u2192\u221e \u2016In \u2297 e\nA0t\u2016\u2016\u03b8\u0303(t)\u2016\n6 lim t\u2192\u221e\n\u2016In \u2297 e A0t\u2016\n\u2225 \u2225 \u2225 \u03b31e\n\u03b32t sup \u2212\u01eb6\u033a60\n\u03b8\u0303(\u033a) \u2225 \u2225\n\u2225\n6 lim t\u2192\u221e\n\u03b31e \u03b32t\u2016In \u2297 e A0t\u2016 6 lim t\u2192\u221e \u03b31e \u03b32tP (t) = 0, (16)\nwhere \u2016In \u2297 e A0t\u2016 6 P (t) exists because all characteristic roots of the matrix A0 have no real parts, and there exists a polynominal P (t). Thus, the proof is completed.\nRemark 3. Different approaches, such as the frequency domain method and the Lyapunov-Krasovskii theorem or the Razumikhin theorem approach, have been reported to solve uniform time-delay issues for first- or second-order MASs, while the nonuniform and time-varying communication delays are considered for the general linear HMASs in this article. Obviously, the existing methods cannot be directly applied to solve this paper. To solve the time-varying communication delay case, Lemma 2 is introduced and established, which is not only simpler but also less computationally complex compared with constructing multiple Lyapunov functions related to uniform communication delays."
        },
        {
            "heading": "3.4 RL-based optimal output tracking consensus",
            "text": "For agent i, we consider the state feedback controller as follows:\nui = Q1iri +Q2ir0, i = 1, 2, . . . , N, (17)\nwhere ui = [Q1i, Q2i]Zi = QiZi, and Q1i, Q2i are gain matrices to be determined later.\nLet Zi = [r T i , r T 0 ] T. Integrating (1), (2), and (17) yields the following augmented systems:\nZ\u0307i =\n[\nAi 0\n0 A0\n]\nZi +\n[\nBi\n0\n]\nui = A\u0304iZi + B\u0304iui,\nei = Ciri \u2212 Fir0 = [Ci,\u2212F ]Zi = C\u0304iZi. (18)\nFor (18), the value function corresponding to the performance function Ji(Zi, ui) is considered as\nVi(Zi, ui) =\n\u222b \u221e\nt\ne\u2212\u03c7i(s\u2212t) [\nZTi C\u0304i\u039eiC\u0304 T i Z T i + u T i \u0398iui\n]\nds = ZTi WiZi, (19)\nwhere \u039ei > 0 and \u0398i > 0 are weighting matrices, \u03c7i > 0 is a constant number to be designed later, and its function of introducing the parameter \u03c7i is to ensure the tracking control while satisfying the predefined performance (19). To analyze the stability, define Vi(Zi) = Z T i WiZi, where the matrix Wi > 0.\nThe control objective is to determine\nV \u2217i (ui) = minui Ji(Zi, ui) = min ui\n\u222b \u221e\nt\ne\u2212\u03c7i(s\u2212t) [\nZTi C\u0304i\u039eiC\u0304 T i Z T i + u T i \u0398iui\n]\nds. (20)\nAccording to (19), the Bellman equation is easy to conclude as follows:\nH(Zi, ui) = Z T i C\u0304i\u039eiC\u0304 T i Z T i + u T i \u0398iui + 2Z T i Wi[A\u0304iZi + B\u0304iui]\u2212 \u03c7iVi = 0. (21)\nBased on the stationary condition \u2202H(Zi,ui)\u2202ui = 0, the optimal control policy is as follows:\nu\u2217i = QiZi = \u2212\u0398 \u22121 i B\u0304 T i WiZi, (22)\nwhere Wi = W T i = [\nW11i W 12 i W21i W 22 i ] satisfies the following equation:\nA\u0304Ti Wi +WiA\u0304i \u2212 \u03c7iWi + C\u0304 T i \u039eiC\u0304i \u2212WiB\u0304i\u0398 \u22121 i B\u0304 T i Wi = 0. (23)\nNote that the solution Wi of (23) will be learned based on Bellman equations (18), and the detailed learning process is given in Algorithm 1.\nAlgorithm 1 Model-based RL algorithm 1. Start with a stabilizing control policy u [k] i with k = 0 for i; 2. Solve the following Bellman equation for V [k+1] i :\nZTi C\u0304i\u039eiC\u0304 T i Z T i + (u [k])Ti \u0398iu [k] i +\n(\u2202Vi(Zi, ui)\n\u2202Zi\n)[k+1] [A\u0304iZi + B\u0304iu [k] i ] \u2212 \u03c7iVi = 0, (24)\nwhere \u2202Vi(Zi, ui)/\u2202Zi = 2WiZi; 3. Find improved control policies using ui and the optimal controller gain Qi,\nu [k+1] i = \u2212\u0398 \u22121 i B\u0304 T i W [k] i Zi, Q [k+1] i = \u2212\u0398 \u22121 i B\u0304 T i W [k] i ; (25)\n4. Stop when \u2016Q (k+1) i \u2212 Q (k) i \u2016 6 \u03c6, where \u03c6 is a small constant; otherwise, k = k + 1 and return to Step 2 until the convergence criterion is satisfied.\nTheorem 3. Consider an HMAS composed of (1) and (2) under Assumptions 1\u20133, developing the RL-based local controller ui in (1) with Qi = \u2212\u0398 \u22121 i B\u0304 T i Wi. Then, Ai+BiQ1i is Hurwitz, and the optimal output tracking consensus of the HMASs can be obtained if \u03c7i = \u03c7 \u2217 i 6 2\u2016(C T i \u039eiCiBi\u0398 \u22121 i B T i ) 1 2 \u2016. Proof. According to (23), substituting Wi into (23) yields\nATi W 11 i +W 11 i Ai \u2212 \u03c7iW 11 i + C T i \u039eiCi \u2212W 11 i Bi\u0398 \u22121 i B T i W 11 i = 0, (26)\nwhich can be rewritten as\n(Ai +BiQ1i) + (Ai +BiQ1i)\u2212 \u03c7iIn = \u2212C T i \u039eiCi(W 11 i ) \u22121 \u2212W 11i Bi\u0398 \u22121 i B T i\n= \u2212 \u2225 \u2225\n\u2225 (CTi ) 1 2\u039e\n1 2 i C 1 2 i (W 11 i ) \u2212 12\n\u2225 \u2225 \u2225 2 \u2212 \u2225 \u2225 \u2225 (W 11i ) 1 2B 1 2 i \u0398 \u2212 12 i (B T i ) 1 2 \u2225 \u2225 \u2225 2\n6 \u22122 \u2225 \u2225\n\u2225 (CTi \u039eiCiBi\u0398 \u22121 i B T i )\n1 2\n\u2225 \u2225 \u2225 < 0, (27)\nwhere the eigenvalues of the matrix (Ai + BiQ1i) + (Ai + BiQ1i) \u2212 \u03c7iIn can be described by 2\u03bb(Ai + BiQ1i)\u2212\u03c7i. Thus, 2\u03bb(Ai +BiQ1i)\u2212\u03c7i 6 \u22122\u2016(C T i \u039eiCiBi\u0398 \u22121 i B T i ) 1 2 \u2016. Note that if the discounted factor satisfies \u03c7i 6 2\u2016(C T i \u039eiCiBi\u0398iB T i ) 1 2 \u2016, it concludes \u03bb(Ai +BiQ1i) < 0, and then Ai +BiQ1i is Hurwitz.\nOn the other hand, multiplying the left-and right-hand sides of (23) by ZTi and Zi, we have\n2ZTi A\u0304 T i WiZi \u2212 \u03c7iZ T i WiZi + Z T i C\u0304 T i \u039eiC\u0304iZi \u2212 (Z T i Wi)B\u0304i\u0398 \u22121 i B\u0304 T i (WiZ T i ) = 0. (28)\nIt can be observed from (28) that if WiZi = 0, then Z T i C\u0304 T i \u039eiC\u0304iZi = 0. Thus, (yi \u2212 y0) T\u039ei(yi \u2212 y0) = ZTi C\u0304 T i \u039eiC\u0304iZi = 0 is easily confirmed, and the output tracking consensus ei = 0. If WiZi 6= 0, one has V\u0307 (Zi, ui) = 2Z T i Wi(A\u0304i + B\u0304iQi)Zi = Z T i (WiA\u0303i + A\u0303iWi)Zi, where A\u0303i = [ Ai + BiQ1i BiQ2i 0 A0 ] is Hurwitz because Ai + BiQ1i is Hurwitz and all eigenvalues of A0 satisfy Assumption 3. Thus, a matrix S > 0 satisfying WiA\u0303i + A\u0303iWi + S 6 0 must exist. Then, one has V\u0307 (Zi, ui) = \u2212Z T i SZi 6 0. According to LaSalle\u2019s invariance principle, Zi synchronizes to the largest invariant subspace where V\u0307 (Zi, ui) = 0. Then, it is easy to check that V\u0307 (Zi, ui) = 0 when WiZi = 0. The optimal output tracking control problem of HMASs is solved by using a policy iteration algorithm as shown in Algorithm 1.\nRemark 4. It is worth noting that Theorem 2 is a model-based control algorithm because the obtained optimal control policy relies on the accurate matrix B\u0304i in (22). If the dynamical model is unknown, the model-based control algorithm is useless. To relax this condition, inspired by [30], we will develop a model-free learning algorithm.\nThe augmented systems (18) is rewritten as\nZ\u0307i = (A\u0304i + B\u0304iQ [k] i )Zi + B\u0304i(ui \u2212Q [k] i Zi). (29)\nBased on Algorithm 1, V\u0307i(Zi) satisfies\nV\u0307i = ( dVi dZi )[ (A\u0304i + B\u0304iQ [k] i )Zi ] + (dVi dZi )[ B\u0304i(ui \u2212Q [l] i Zi) ]\n= \u03c7iVi \u2212 Z T i\n[\nC\u0304Ti \u039eiC\u0304i + ( Q [k] i\n)T\n\u0398iQ [k] i\n]\nZi \u2212 2 ( ui \u2212Q [k] i Zi ) \u0398iQ [k+1] i Zi. (30)\nFor the interval [t, t + T ], the following IRL Bellman equation can be derived by imposing e\u2212\u03c7it on both sides of (30) as\ne\u2212\u03c7iT \u2032 V [k+1] i (Zi(t+ T \u2032))\u2212 V [k+1] i (Zi(t)) = \u2212\n\u222b t+T \u2032\nt\ne\u2212\u03c7i(s\u2212t)ZTi\n[ C\u0304Ti \u039eiC\u0304i + ( Q [k] i\n)T\n\u0398iQ [k] i\n]\nZids\n\u2212 2\n\u222b t+T \u2032\nt\ne\u2212\u03c7i(s\u2212t) (\nui \u2212Q [k] i Zi\n)T\n\u0398iQ [k+1] i Zids. (31)\nNote that for (31), C\u0304Ti \u039eiC\u0304i is associated with the matrices Ci and F in (31), which means that Algorithm 2 is a model-free algorithm. In fact, the prior knowledge related to Ci and F is not required in Algorithm 2 mainly because we can use the relative output information (yi\u2212 y0)\nT\u039ei(yi\u2212 y0) to relax the requirement of C\u0304Ti \u039eiC\u0304i in (31). That is, it is a model-free algorithm without any prior knowledge. The model-free RL algorithm as shown in Algorithm 2 is given to achieve the optimal output synchronization without relying on system dynamics.\nRemark 5. Note that Algorithm 1 has the same solution as Algorithm 2, and the convergence of Algorithm 1 can be ensured considering [31]. That is, the convergence of Algorithm 2 is guaranteed.\nRemark 6. The controller gains of existing results [16\u201318] are derived by resolving a series of linear matrix inequalities (LMIs), and the analytical solution of multiple LMIs is difficult to ensure. However, in this paper, the optimal control gains of (17) can be obtained by simultaneously using an RL algorithm.\nAlgorithm 2 Model-free off-policy IRL algorithm 1. Begin with a stabilizing control policy u [k] i with k = 0 for i; 2. Solve the integral Bellman equation (31) for V [k+1] i and u [k+1] i simultaneously; 3. Stop when \u2016V [k+1] i \u2212 V [k] i \u2016 6 \u03c6 where \u03c6 is a small constant; otherwise, k = k + 1 and return to Step 2 until the convergence criterion is satisfied."
        },
        {
            "heading": "4 Numerical simulations",
            "text": "Consider an HMAS comprising a leader and four tracking agents with the following system parameters:\nA0 =\n[\n0 \u22121\n1 0\n]\n, F =\n[\n2\n0\n]T\n, Ai =\n[\n0 \u2212i\ni 0\n]\n, Bi =\n[\ni\n0\n]\n, Ci =\n[\n0\ni\n]T\n, i = 1, . . . , 4.\nThe communication topology structure among five agents is shown in Figure 1, and Assumptions 1\u20133 hold. The initial values of the leader and predictors are selected as r0(0) = [\u22122, 3] T, \u03b71(0) = [2,\u22121] T, \u03b72(0) = [1,\u22122] T, \u03b73(0) = [\u22122.5, 5] T, and \u03b74(0) = [\u22125,\u22126] T. Meanwhile, suppose that the time-varying communication delays are described by \u01ebij(t) = 1\n3t+is, i = 1, 2, 3, 4 for different neighboring agents. Using the predictor in (11), the state synchronization between predictors and the leader converges to a common state value, as shown in Figure 2, and the curves of corresponding prediction errors are depicted in Figure 3. That is, the predictor can estimate the leader\u2019s state although the different communication delays are imposed on different links. When the communication delays \u01ebij(t) = 1 3ts for different links are the same case, the evolutions of state trajectories and the prediction errors are as presented in Figures 4 and 5. Now, we implement the RL algorithm for output tracking consensus, and the parameters \u03c7i = 2, \u039ei = 2, \u0398i = 10 are considered in discounted performance function (19). Based on the given system matrices, solving the algebraic Riccati equation (23) derives the optimal controller gains for four followers\nas follows:\nQ\u22171 = [ \u22120.0736 \u22120.1006 \u22120.2012 \u22120.1471 ] , Q\u22172 = [ \u22120.5822 \u22120.6301 \u22120.8378 \u22120.3176 ] ,\nQ\u22173 = [ \u22120.9889 \u22121.3077 \u22121.0912 \u22120.2287 ] , Q\u22174 = [ \u22121.3021 \u22122.0211 \u22121.2019 \u22120.1658 ] .\nBased on the optimal controller gains in (17), the output tracking consensus can be achieved, and the evolution of the tracking errors ei(t), i = 1, 2, 3, 4 is illustrated in Figure 6."
        },
        {
            "heading": "5 Conclusion",
            "text": "The optimal output synchronization control of HMASs subject to heterogeneous delays and an unknown reference model was studied in this paper. A data-based learning algorithm is proposed to learn the leader\u2019s model for each follower. The leader state predictor subject to nonidentical communication delays is further given to estimate the leader\u2019s state for each follower. Then, the optimal controller-based RL algorithm is developed to ensure the control objective, which is extended to the model-free RL algorithm that does not depend on system dynamics. Finally, a simulation example is provided to verify the effectiveness of the theoretical analysis. Note that because the obtained results ignore the existence of limited bandwidth, different resilient event-triggered strategies [32\u201336] will be exploited for the optimal secure control of nonlinear HMASs in our future work. Furthermore, the proposed algorithms begin with an admissible initial control policy, which is associated with the system dynamics matrix, and how to remove this assumption also merits consideration in our future study.\nAcknowledgements This work was supported by National Natural Science Foundation of China (Grant Nos. 62103047, U1966202), Beijing Institute of Technology Research Fund Program for Young Scholars, and Young Elite Scientists Sponsorship Program by BAST (Grant No. BYESS2023365)\nReferences\n1 Ni W, Cheng D. Leader-following consensus of multi-agent systems under fixed and switching topologies. Syst Control Lett,\n2010, 59: 209\u2013217\n2 Yu W W, Wang H, Hong H F, et al. Distributed cooperative anti-disturbance control of multi-agent systems: an overview.\nSci China Inf Sci, 2017, 60: 110202\n3 Liu T F, Qi J, Jiang Z P. Distributed containment control of multi-agent systems with velocity and acceleration saturations.\nAutomatica, 2020, 117: 108992\n4 Xu Y, Fang M, Shi P, et al. Multileader multiagent systems containment control with event-triggering. IEEE Trans Syst Man\nCybern Syst, 2021, 51: 1642\u20131651\n5 Liu T F, Qin Z, Jiang Z P. A new look at distributed optimal output agreement of multi-agent systems. Automatica, 2022,\n136: 110053\n6 Su Y F, Huang J. Cooperative output regulation of linear multi-agent systems. IEEE Trans Automat Contr, 2012, 57:\n1062\u20131066\n7 Lu M, Liu L. Cooperative output regulation of linear multi-agent systems by a novel distributed dynamic compensator. IEEE\nTrans Automat Contr, 2017, 62: 6481\u20136488\n8 Deng C, Yang G H. Distributed adaptive fault-tolerant control approach to cooperative output regulation for linear multi-agent\nsystems. Automatica, 2019, 103: 62\u201368\n9 Dong S L, Chen G R, Liu M Q, et al. Cooperative neural-adaptive fault-tolerant output regulation for heterogeneous nonlinear\nuncertain multiagent systems with disturbance. Sci China Inf Sci, 2021, 64: 172212\n10 Li G Q, Wang L. Adaptive output consensus of heterogeneous nonlinear multiagent systems: a distributed dynamic compen-\nsator approach. IEEE Trans Automat Contr, 2023, 68: 2483\u20132489\n11 Xu Y, Wu Z G. Distributed adaptive event-triggered fault-tolerant synchronization for multiagent systems. IEEE Trans Ind\nElectron, 2021, 68: 1537\u20131547\n12 Cai H, Lewis F L, Hu G, et al. The adaptive distributed observer approach to the cooperative output regulation of linear\nmulti-agent systems. Automatica, 2017, 75: 299\u2013305\n13 Cai H, Huang J. Output based adaptive distributed output observer for leader-follower multiagent systems. Automatica, 2021,\n125: 109413\n14 Sutton R S, Barto A G. Introduction to Reinforcement Learning. Cambridge: MIT Press, 1998 15 Modares H, Nageshrao S P, Lopes G A D, et al. Optimal model-free output synchronization of heterogeneous systems using\noff-policy reinforcement learning. Automatica, 2016, 71: 334\u2013341\n16 Yang Y, Modares H, Wunsch D C, et al. Leader-follower output synchronization of linear heterogeneous systems with active\nleader using reinforcement learning. IEEE Trans Neural Netw Learn Syst, 2018, 29: 2139\u20132153\n17 Mu C, Zhao Q, Sun C. Optimal tracking control of heterogeneous MASs using event-driven adaptive observer and reinforcement\nlearning. IEEE Trans Neural Netw Learn Syst, 2022. doi: 10.1109/TNNLS.2022.3208237\n18 Xu Y, Wu Z G. Data-efficient off-policy learning for distributed optimal tracking control of HMAS with unidentified exosystem\ndynamics. IEEE Trans Neural Netw Learn Syst, 2022. doi: 10.1109/TNNLS.2022.3172130\n19 Li Q, Xia L, Song R. Leader-follower bipartite output synchronization on signed digraphs under adversarial factors via data-\nbased reinforcement learning. IEEE Trans Neural Netw Learn Syst, 2020, 31: 4185\u20134195\n20 Olfati-Saber R, Murray R M. Consensus problems in networks of agents with switching topology and time-delays. IEEE Trans\nAutomat Contr, 2004, 49: 1520\u20131533\n21 Zhou B, Lin Z. Consensus of high-order multi-agent systems with large input and communication delays. Automatica, 2014,\n50: 452\u2013464\n22 Yang X, Zhou B. Consensus of discrete-time multiagent systems with input delays by truncated pseudo-predictor feedback.\nIEEE Trans Cybern, 2017, 49: 505\u2013516\n23 Ge X, Han Q L, Zhang X M. Achieving cluster formation of multi-agent systems under aperiodic sampling and communication\ndelays. IEEE Trans Ind Electron, 2017, 65: 3417\u20133426\n24 Lu M, Liu L. Consensus of linear multi-agent systems subject to communication delays and switching networks. Int J Robust\nNonlinear Control, 2017, 27: 1379\u20131396\n25 Lu M, Liu L. Distributed feedforward approach to cooperative output regulation subject to communication delays and switching\nnetworks. IEEE Trans Automat Contr, 2017, 62: 1999\u20132005\n26 Yu J, Wang L. Group consensus in multi-agent systems with switching topologies and communication delays. Syst Control\nLett, 2010, 59: 340\u2013348\n27 Jiang Y, Jiang Z P. Robust adaptive dynamic programming for large-scale systems with an application to multimachine power\nsystems. IEEE Trans Circuits Syst II, 2012, 59: 693\u2013697\n28 Wang X, Sun J, Wang G, et al. Data-driven control of distributed event-triggered network systems. IEEE CAA J Autom Sin,\n2023, 10: 351\u2013364\n29 Moreau L. Stability of continuous-time distributed consensus algorithms. In: Proceedings of the 43rd IEEE Conference on\nDecision and Control (CDC), 2004. 4: 3998\u20134003\n30 Modares H, Lewis F L, Jiang Z P. H\u221e tracking control of completely unknown continuous-time systems via off-policy rein-\nforcement learning. IEEE Trans Neural Netw Learn Syst, 2015, 26: 2550\u20132562\n31 Vamvoudakis K G, Lewis F L, Hudas G R. Multi-agent differential graphical games: online adaptive learning solution for\nsynchronization with optimality. Automatica, 2012, 48: 1598\u20131611\n32 Liu W, Sun J, Wang G, et al. Data-driven resilient predictive control under denial-of-service. IEEE Trans Automat Contr,\n2022. doi: 10.1109/TAC.2022.3209399\n33 Xu Y, Sun J, Pan Y J, et al. Dynamic deadband event-triggered strategy for distributed adaptive consensus control with\napplications to circuit systems. IEEE Trans Circuits Syst I, 2022, 69: 4663\u20134673\n34 Zhang P, Liu T F, Jiang Z P. Event-triggered stabilization of a class of nonlinear time-delay systems. IEEE Trans Automat\nContr, 2021, 66: 421\u2013428\n35 Xu Y. Resilient secure control of networked systems over unreliable communication networks. IEEE Trans Ind Inf, 2022, 18:\n4069\u20134077\n36 Tao Y Y, Wu Z G. Asynchronous control of two-dimensional Markov jump Roesser systems: an event-triggering strategy.\nIEEE Trans Netw Sci Eng, 2022, 9: 2278\u20132289"
        }
    ],
    "title": "Reinforcement learning-based unknown reference tracking control of HMASs with nonidentical communication delays",
    "year": 2023
}