{
    "abstractText": "A map of the environment is an essential component for robotic navigation. In the majority of cases, a map of the static part of the world is the basis for localization, planning, and navigation. However, dynamic objects that are presented in the scenes during mapping leave undesirable traces in the map, which can impede mobile robots from achieving successful robotic navigation. To remove the artifacts caused by dynamic objects in the map, we propose a novel instance-aware map building method. Our approach rejects dynamic points at an instance-level while preserving most static points by exploiting instance segmentation estimates. Furthermore, we propose effective ways to consider the erroneous estimates of instance segmentation, enabling our proposed method to be robust even under imprecise instance segmentation. As demonstrated in our experimental evaluation, our approach shows substantial performance increases in terms of both, the preservation of static points and rejection of dynamic points. Our code is available at https://github.com/url-kaist/ERASOR2.",
    "authors": [
        {
            "affiliations": [],
            "name": "Hyungtae Lim"
        },
        {
            "affiliations": [],
            "name": "Lucas Nunes"
        },
        {
            "affiliations": [],
            "name": "Benedikt Mersch"
        },
        {
            "affiliations": [],
            "name": "Xieyunali Chen"
        },
        {
            "affiliations": [],
            "name": "Jens Behley"
        },
        {
            "affiliations": [],
            "name": "Hyun Myung"
        },
        {
            "affiliations": [],
            "name": "Cyrill Stachniss"
        }
    ],
    "id": "SP:b0c5fdf3bbf9b669d2a17c9af2b8cd5af11ab973",
    "references": [
        {
            "authors": [
                "M. Arora",
                "L. Wiesmann",
                "X. Chen",
                "C. Stachniss"
            ],
            "title": "Mapping the static parts of dynamic scenes from 3D LiDAR point clouds exploiting ground segmentation",
            "venue": "Proc. of the Europ. Conf. on Mobile Robotics (ECMR), pages 1\u20136",
            "year": 2021
        },
        {
            "authors": [
                "M. Arora",
                "L. Wiesmann",
                "X. Chen",
                "C. Stachniss"
            ],
            "title": "Static map generation from 3D LiDAR point clouds exploiting ground segmentation",
            "venue": "Journal on Robotics and Autonomous Systems (RAS), 159:104287\u2013 104294",
            "year": 2023
        },
        {
            "authors": [
                "J. Behley",
                "M. Garbade",
                "A. Milioto",
                "J. Quenzel",
                "S. Behnke",
                "C. Stachniss",
                "J. Gall"
            ],
            "title": "SemanticKITTI: A dataset for semantic scene understanding of LiDAR sequences",
            "venue": "Proc. of the IEEE/CVF Intl. Conf. on Computer Vision (ICCV), pages 9297\u20139307",
            "year": 2019
        },
        {
            "authors": [
                "J. Behley",
                "C. Stachniss"
            ],
            "title": "Efficient surfel-based SLAM using 3D laser range data in urban environments",
            "venue": "Proc. of Robotics: Science and Systems (RSS), pages 59\u201368",
            "year": 2018
        },
        {
            "authors": [
                "J. Behley",
                "V. Steinhage",
                "A.B. Cremers"
            ],
            "title": "Efficient radius neighbor search in three-dimensional point clouds",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 3625\u20133630",
            "year": 2015
        },
        {
            "authors": [
                "M. Bennewitz",
                "W. Burgard",
                "G. Cielniak",
                "S. Thrun"
            ],
            "title": "Learning motion patterns of people for compliant robot motion",
            "venue": "Intl. Journal of Robotics Research (IJRR), 24(1):31\u201348",
            "year": 2005
        },
        {
            "authors": [
                "M. Bennewitz",
                "W. Burgard",
                "S. Thrun"
            ],
            "title": "Adapting navigation strategies using motions patterns of people",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 2000\u20132005",
            "year": 2003
        },
        {
            "authors": [
                "F. Blochliger",
                "M. Fehr",
                "M. Dymczyk",
                "T. Schneider",
                "R. Siegwart"
            ],
            "title": "Topomap: Topological mapping and navigation based on visual SLAM maps",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 3818\u20133825",
            "year": 2018
        },
        {
            "authors": [
                "H. Caesar",
                "V. Bankiti",
                "A.H. Lang",
                "S. Vora",
                "V.E. Liong",
                "Q. Xu",
                "A. Krishnan",
                "Y. Pan",
                "G. Baldan",
                "O. Beijbom"
            ],
            "title": "nuScenes: A multimodal dataset for autonomous driving",
            "venue": "Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR), pages 11621\u201311631",
            "year": 2020
        },
        {
            "authors": [
                "R.J. Campello",
                "D. Moulavi",
                "J. Sander"
            ],
            "title": "Density-based clustering based on hierarchical density estimates",
            "venue": "Proc. of Pacific- Asia. Conf. on Knowledge Discovery and Data Mining, pages 160\u2013 172",
            "year": 2013
        },
        {
            "authors": [
                "X. Chen",
                "S. Li",
                "B. Mersch",
                "L. Wiesmann",
                "J. Gall",
                "J. Behley",
                "C. Stachniss"
            ],
            "title": "Moving object segmentation in 3D LiDAR data: A learning-based approach exploiting sequential data",
            "venue": "IEEE Robotics and Automation Letters (RA-L), 6:6529\u20136536",
            "year": 2021
        },
        {
            "authors": [
                "X. Chen",
                "B. Mersch",
                "L. Nunes",
                "R. Marcuzzi",
                "I. Vizzo",
                "J. Behley",
                "C. Stachniss"
            ],
            "title": "Automatic labeling to generate training data for online LiDAR-based moving object segmentation",
            "venue": "IEEE Robotics and Automation Letters (RA-L), 7(3):6107\u20136114",
            "year": 2022
        },
        {
            "authors": [
                "A. Dewan",
                "T. Caselitz",
                "G.D. Tipaldi",
                "W. Burgard"
            ],
            "title": "Motion-based detection and tracking in 3D LiDAR scans",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 4508\u20134513",
            "year": 2016
        },
        {
            "authors": [
                "A. Elfes"
            ],
            "title": "Using occupancy grids for mobile robot perception and navigation",
            "venue": "Computer, 22(6):46\u201357",
            "year": 1989
        },
        {
            "authors": [
                "T. Fan",
                "B. Shen",
                "H. Chen",
                "W. Zhang",
                "J. Pan"
            ],
            "title": "DynamicFilter: An online dynamic objects removal framework for highly dynamic environments",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 7988\u20137994",
            "year": 2022
        },
        {
            "authors": [
                "M. Fehr",
                "F. Furrer",
                "I. Dryanovski",
                "J. Sturm",
                "I. Gilitschenski",
                "R. Siegwart",
                "C. Cadena"
            ],
            "title": "TSDF-based change detection for consistent long-term dense reconstruction and dynamic object discovery",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 5237\u20135244",
            "year": 2017
        },
        {
            "authors": [
                "H. Fu",
                "H. Xue",
                "G. Xie"
            ],
            "title": "MapCleaner: Efficiently removing moving objects from point cloud maps in autonomous driving scenarios",
            "venue": "Remote Sensing, 14(18):4496",
            "year": 2022
        },
        {
            "authors": [
                "A. Geiger",
                "P. Lenz",
                "R. Urtasun"
            ],
            "title": "Are we ready for autonomous driving? the KITTI vision benchmark suite",
            "venue": "Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR), pages 3354\u20133361",
            "year": 2012
        },
        {
            "authors": [
                "D. Hahnel",
                "D. Schulz",
                "W. Burgard"
            ],
            "title": "Map building with mobile robots in populated environments",
            "venue": "Proc. of the IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS), pages 496\u2013501",
            "year": 2002
        },
        {
            "authors": [
                "M. Henein",
                "G. Kennedy",
                "V. Ila",
                "R. Mahony"
            ],
            "title": "Simultaneous localization and mapping with dynamic rigid objects",
            "venue": "arXiv preprint, arXiv:1805.03800",
            "year": 2018
        },
        {
            "authors": [
                "A. Hornung",
                "K.M. Wurm",
                "M. Bennewitz",
                "C. Stachniss",
                "W. Burgard"
            ],
            "title": "OctoMap: An efficient probabilistic 3D mapping framework based on Octrees",
            "venue": "Autonomous Robots, 34:189\u2013206",
            "year": 2013
        },
        {
            "authors": [
                "C. Jiang",
                "D.P. Paudel",
                "Y. Fougerolle",
                "D. Fofi",
                "C. Demonceaux"
            ],
            "title": "Static-map and dynamic object reconstruction in outdoor scenes using 3-D motion segmentation",
            "venue": "IEEE Robotics and Automation Letters (RA-L), 1(1):324\u2013331",
            "year": 2016
        },
        {
            "authors": [
                "G. Kim",
                "A. Kim"
            ],
            "title": "Remove",
            "venue": "then revert: Static point cloud map construction using multiresolution range images. In Proc. of the IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS), pages 10758\u201310765",
            "year": 2020
        },
        {
            "authors": [
                "G. Kim",
                "B. Park",
                "A. Kim"
            ],
            "title": "1-day learning",
            "venue": "1-year localization: Long-term LiDAR localization using scan context image. IEEE Robotics and Automation Letters (RA-L), 4(2):1948\u20131955",
            "year": 2019
        },
        {
            "authors": [
                "J. Kim",
                "J. Woo",
                "S. Im"
            ],
            "title": "RVMOS: Range-view moving object segmentation leveraged by semantic and motion features",
            "venue": "IEEE Robotics and Automation Letters (RA-L), 7(3):8044\u20138051",
            "year": 2022
        },
        {
            "authors": [
                "J. Kim",
                "W. Chung"
            ],
            "title": "Robust localization of mobile robots considering reliability of LiDAR measurements",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 6491\u20136496",
            "year": 2018
        },
        {
            "authors": [
                "T. K\u00fchner",
                "J. K\u00fcmmerle"
            ],
            "title": "Large-scale volumetric scene reconstruction using LiDAR",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 6261\u20136267",
            "year": 2020
        },
        {
            "authors": [
                "H. Lim",
                "S. Hwang",
                "H. Myung"
            ],
            "title": "ERASOR: Egocentric ratio of pseudo occupancy-based dynamic object removal for static 3D point cloud map building",
            "venue": "IEEE Robotics and Automation Letters (RA-L), 6(2):2272\u20132279",
            "year": 2021
        },
        {
            "authors": [
                "H. Lim",
                "M. Oh",
                "H. Myung"
            ],
            "title": "Patchwork: Concentric zone-based region-wise ground segmentation with ground likelihood estimation using a 3D LiDAR sensor",
            "venue": "IEEE Robotics and Automation Letters (RA-L), 6(4):6458\u20136465",
            "year": 2021
        },
        {
            "authors": [
                "D.G. Lowe"
            ],
            "title": "Distinctive image features from scale-invariant keypoints",
            "venue": "Intl. Journal of Computer Vision (IJCV), 60(2):91\u2013110",
            "year": 2004
        },
        {
            "authors": [
                "M. Luber",
                "J.A. Stork",
                "G.D. Tipaldi",
                "K.O. Arras"
            ],
            "title": "People tracking with human motion predictions from social forces",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 464\u2013469",
            "year": 2010
        },
        {
            "authors": [
                "B. Mersch",
                "X. Chen",
                "I. Vizzo",
                "L. Nunes",
                "J. Behley",
                "C. Stachniss"
            ],
            "title": "Receding moving object segmentation in 3D LiDAR data using sparse 4D convolutions",
            "venue": "IEEE Robotics and Automation Letters (RA-L), 7(3):7503\u20137510",
            "year": 2022
        },
        {
            "authors": [
                "A. Millane",
                "Z. Taylor",
                "H. Oleynikova",
                "J. Nieto",
                "R. Siegwart",
                "C. Cadena"
            ],
            "title": "C-blox: A scalable and consistent TSDF-based dense mapping approach",
            "venue": "Proc. of the IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS), pages 995\u20131002",
            "year": 2018
        },
        {
            "authors": [
                "L. Nunes",
                "X. Chen",
                "R. Marcuzzi",
                "A. Osep",
                "L. Leal-Taix\u00e9",
                "C. Stachniss",
                "J. Behley"
            ],
            "title": "Unsupervised class-agnostic instance segmentation of 3D LiDAR data for autonomous vehicles",
            "venue": "IEEE Robotics and Automation Letters (RA-L), 7(4):8713\u20138720",
            "year": 2022
        },
        {
            "authors": [
                "M. Oh",
                "E. Jung",
                "H. Lim",
                "W. Song",
                "S. Hu",
                "E.M. Lee",
                "J. Park",
                "J. Kim",
                "J. Lee",
                "H. Myung"
            ],
            "title": "TRAVEL: Traversable ground and aboveground object segmentation using graph representation of 3D LiDAR scans",
            "venue": "IEEE Robotics and Automation Letters (RA-L), pages 7255\u2013 7262",
            "year": 2022
        },
        {
            "authors": [
                "S. Pagad",
                "D. Agarwal",
                "S. Narayanan",
                "K. Rangan",
                "H. Kim",
                "G. Yalla"
            ],
            "title": "Robust method for removing dynamic objects from point clouds",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 10765\u201310771",
            "year": 2020
        },
        {
            "authors": [
                "E. Palazzolo",
                "J. Behley",
                "P. Lottes",
                "P. Giguere",
                "C. Stachniss"
            ],
            "title": "ReFusion: 3D reconstruction in dynamic environments for RGB-D cameras exploiting residuals",
            "venue": "Proc. of the IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS)",
            "year": 2019
        },
        {
            "authors": [
                "J. Park",
                "Y. Cho",
                "Y.S. Shin"
            ],
            "title": "Nonparametric background modelbased LiDAR SLAM in highly dynamic urban environments",
            "venue": "IEEE Trans. on Intelligent Transportation Systems (ITS), 23(12):24190\u2013 24205",
            "year": 2022
        },
        {
            "authors": [
                "P. Pfreundschuh",
                "H.F. Hendrikx",
                "V. Reijgwart",
                "R. Dub\u00e9",
                "R. Siegwart",
                "A. Cramariuc"
            ],
            "title": "Dynamic object aware LiDAR SLAM based on automatic generation of training data",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 11641\u201311647",
            "year": 2021
        },
        {
            "authors": [
                "F. Pomerleau",
                "P. Kr\u00fcsi",
                "F. Colas",
                "P. Furgale",
                "R. Siegwart"
            ],
            "title": "Longterm 3D map maintenance in dynamic environments",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 3712\u20133719",
            "year": 2014
        },
        {
            "authors": [
                "C. Qian",
                "Z. Xiang",
                "Z. Wu",
                "H. Sun"
            ],
            "title": "RF-LIO: Removal-first tightlycoupled LiDAR inertial odometry in high dynamic environments",
            "venue": "Proc. of the IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS), pages 4421\u20134428",
            "year": 2021
        },
        {
            "authors": [
                "P. Ruchti",
                "W. Burgard"
            ],
            "title": "Mapping with dynamic-object probabilities calculated from single 3D range scans",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 6331\u20136336",
            "year": 2018
        },
        {
            "authors": [
                "P.E. Sarlin",
                "C. Cadena",
                "R. Siegwart",
                "M. Dymczyk"
            ],
            "title": "From coarse to fine: Robust hierarchical localization at large scale",
            "venue": "Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR), pages 12716\u201312725",
            "year": 2019
        },
        {
            "authors": [
                "J. Schauer",
                "A. N\u00fcchter"
            ],
            "title": "The Peopleremover\u2014Removing dynamic objects from 3D point cloud data by traversing a voxel occupancy grid",
            "venue": "IEEE Robotics and Automation Letters (RA-L), 3(3):1679\u20131686",
            "year": 2018
        },
        {
            "authors": [
                "S. Song",
                "H. Lim",
                "A.J. Lee",
                "H. Myung"
            ],
            "title": "DynaVINS: A visualinertial SLAM for dynamic environments",
            "venue": "IEEE Robotics and Automation Letters (RA-L), 7(4):11523\u201311530",
            "year": 2022
        },
        {
            "authors": [
                "C. Stachniss"
            ],
            "title": "Robotic Mapping and Exploration, volume",
            "year": 2009
        },
        {
            "authors": [
                "C. Stachniss",
                "W. Burgard"
            ],
            "title": "Mobile robot mapping and localization in non-static environments",
            "venue": "Proc. of the National Conference on Artificial Intelligence (AAAI), pages 1324\u20131329",
            "year": 2005
        },
        {
            "authors": [
                "J. Sun",
                "Y. Dai",
                "X. Zhang",
                "J. Xu",
                "R. Ai",
                "W. Gu",
                "X. Chen"
            ],
            "title": "Efficient spatial-temporal information fusion for LiDAR-based 3D moving object segmentation",
            "venue": "Proc. of the IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS), pages 11456\u201311463",
            "year": 2022
        },
        {
            "authors": [
                "C. Sung",
                "S. Jeon",
                "H. Lim",
                "H. Myung"
            ],
            "title": "What if there was no revisit? Large-scale graph-based SLAM with traffic sign detection in an HD map using LiDAR inertial odometry",
            "venue": "Intelligent Service Robotics (ISR), 15(2):161\u2013170",
            "year": 2022
        },
        {
            "authors": [
                "V. Vineet",
                "O. Miksik",
                "M. Lidegaard",
                "M. Nie\u00dfner",
                "S. Golodetz",
                "V.A. Prisacariu",
                "O. K\u00e4hler",
                "D.W. Murray",
                "S. Izadi",
                "P. P\u00e9rez"
            ],
            "title": "et al",
            "venue": "Incremental dense semantic stereo fusion for large-scale semantic scene reconstruction. In Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 75\u201382",
            "year": 2015
        },
        {
            "authors": [
                "I. Vizzo",
                "X. Chen",
                "N. Chebrolu",
                "J. Behley",
                "C. Stachniss"
            ],
            "title": "Poisson surface reconstruction for LiDAR odometry and mapping",
            "venue": "Proc. of the IEEE Intl. Conf. on Robotics & Automation (ICRA), pages 5624\u2013 5630",
            "year": 2021
        },
        {
            "authors": [
                "I. Vizzo",
                "T. Guadagnino",
                "J. Behley",
                "C. Stachniss"
            ],
            "title": "VDBFusion: Flexible and efficient TSDF integration of range sensor data",
            "venue": "Sensors, 22(3):1296\u20131320",
            "year": 2022
        },
        {
            "authors": [
                "X. Weng",
                "J. Wang",
                "D. Held",
                "K. Kitani"
            ],
            "title": "3D multi-object tracking: A baseline and new evaluation metrics",
            "venue": "Proc. of the IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS), pages 10359\u2013 10366",
            "year": 2020
        },
        {
            "authors": [
                "M. Yguel",
                "O. Aycard",
                "C. Laugier"
            ],
            "title": "Update policy of dense maps: Efficient algorithms and sparse representation",
            "venue": "Proc. of the Intl. Conf. on Field and Service Robotics (FSR), pages 23\u201333",
            "year": 2008
        },
        {
            "authors": [
                "M. Yokozuka",
                "K. Koide",
                "S. Oishi",
                "A. Banno"
            ],
            "title": "LiTAMIN: LiDAR-based tracking and mapping by stabilized ICP for geometry approximation with normal distributions",
            "venue": "Proc. of the IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS), pages 5143\u2013 5150",
            "year": 2020
        },
        {
            "authors": [
                "D. Yoon",
                "T. Tang",
                "T. Barfoot"
            ],
            "title": "Mapless online detection of dynamic objects in 3D LiDAR",
            "venue": "Proc. of the Intl. Conf. on 3D Vision ",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "1\nI. INTRODUCTION\nA static map is an essential component for many mobile robot platforms to achieve robot navigation [28], [46], [47], [49]. Static landmarks provide geometrical features that are repeatably observed, thus a robot can utilize a map of the static world to localize itself reliably. These maps can be represented in various forms, such as occupancy grid maps [21], feature maps [43], topological maps [8], or structural-variance-robust place representations [24]. In this paper, we focus on 3D point cloud maps [23], [28], which are an output of the accumulation of laser scans from a 3D LiDAR sensor. Thus, we aim for the mapping of the static 3D points.\nLaser scanner data captured in urban environments often include dynamic objects. If integrated into a map, this information can degrade the performance of localization and navigation of a mobile robot [28]. Dynamic instances such as\n\u2021Corresponding author: Hyun Myung Cyrill Stachniss is additionally with the Department of Engineering Science at the University of Oxford, UK, and with the Lamarr Institute for Machine Learning and Artificial Intelligence, Germany.\nThis work was supported by Korea Evaluation Institute of Industrial Technology (KEIT) funded by the Korea Government (MOTIE) under Grant No.20018216, Development of mobile intelligence SW for autonomous navigation of legged robots in dynamic and atypical environments for real application, BK21 FOUR, and the European Union\u2019s Horizon Europe research and innovation programme under grant agreement No 101070405 (DigiForest).\nbuses, cars, and pedestrians, take up space only temporarily. This causes misrecognitions about space occupancy in the map [11], [12], [26]. Therefore, static map building, which rejects dynamic points caused by moving objects, is the key and necessary to reduce these negative effects.\nTo tackle the problem of mapping in dynamic environments, numerous researchers have proposed static map building methods exploiting geometrical discrepancies between each scan and a map cloud [2], [17], [23], [36], [44], [56]. In practice, three limitations still exist in most systems. First, once the poses from scan registration or pose graph optimization become imprecise, the geometric correlation between the current scan and map cloud also becomes inaccurate, resulting in the loss of many static points (red points in Fig. 1). Second, existing methods often do not consider any instance-level information, so some points from moving objects could remain in the map cloud (blue points in Fig. 1(a)). Third, some methods use the segmentation information, but the way to deal with noisy or erroneous instance segmentation is still less examined.\nIn sum, the aim is to bring the number of false positive and false negative dynamic points toward zero even though\nrealistic and thus imprecise poses and instance segmentation estimates are provided. Several researchers have proposed learning-based moving object segmentation (MOS) methods [11], [12], [32], which segment dynamic and static points for each scan. Although these methods show precise segmentation, the performance can decrease when used in environments that differ significantly from the ones used for training or when using different sensor setups. For these reasons, we believe map-centric management is still required for achieving high-quality maps.\nThe main contribution of this paper is a novel instanceaware static map building approach, called ERASOR2. It shares some of the philosophy of ERASOR [28], a technique that rejects dynamic points in a region-wise manner using so-called pseudo occupancy. Our new approach overcomes the shortcomings of existing static map building methods by leveraging instance-level information reducing both, false positives and false negatives, as illustrated in Fig. 1(b). In particular, our new method is not limited to specific instance segmentation algorithms, such that the pipeline easily works with other instance segmentation methods and in various environments. Furthermore, we propose some effective ways to deal with the noise of instance segmentation estimates, i.e. under- and over-segmentation [35], and unlabeled points, enabling our proposed method to be robust against imprecise instance segmentation.\nIn sum, we make the following three key claims. Our approach (i) precisely rejects dynamic points at an instancelevel while preserving static points compared with the state-of-the-art methods, (ii) is robust against the imprecise instance segmentation estimates, and (iii) shows superior performance even in highly crowded environments, demonstrating the robustness of our proposed method and necessity of map-level management by comparing our proposed method to a recent state-of-the-art egocentric learning-based approach. These claims are backed up by the following sections and our experimental evaluation."
        },
        {
            "heading": "II. RELATED WORK",
            "text": "In general, there are three ways of building a map of the static environment depending on the purpose of dynamic point removal. The first one is to reduce wrong data association within the simultaneous localization and mapping (SLAM) process, so dynamic points are simultaneously rejected when poses are estimated [20], [38], [39], [41], [45], [50]. The second one is to segment moving objects in the surroundings for each scan, which focuses more on an egocentric perception [11]\u2013[14], [25], [32], [56]. The last one is to build a static map as a post-processing of SLAM before the localization or navigation step [16], [22], [23], [28], [40], [42]. In this study, we place more emphasis on the last case. This last group of approaches can be further classified into three subgroups: a) ray tracing-based, b) visibility-based, and c) traversability-based methods.\nOccupancy grids [14], [19], OctoMap [5], [21], and TSDFbased methods [27], [33], [51], [52] are typical methods that use ray tracing, which updates the state of some space,\nsuch as grid cells or voxels, by checking whether a ray runs through that some space or not. By utilizing the ray tracing concept, Schauer and Nu\u0308chter [44] proposed removing dynamic points by traversing a voxel occupancy grid and Pagad et al. [36] suggested a combination of object detection and OctoMap. However, these methods are often affected by the quality of estimated poses. If imprecise poses are provided, many static points are removed because the decision on whether the points are static or dynamic becomes challenging (see Section IV.B). In addition, ray tracing-based methods are computationally expensive because large parts of the scene are taken into account for each traced ray.\nTo increase computational efficiency, visibility-based methods [23], [37], [40] have been proposed, which usually detect dynamic points by using the geometrical discrepancies between a query range image and a map range image. That is, if the range value of the pixel on a query image is larger than that on the map image, these visibility-based methods estimate that occlusion occurs at that location corresponding to the pixel of a map range image. Thus, the points projected onto those pixels are considered as dynamic points.\nHowever, owing to the uneven distribution of the 3D point cloud captured by a mechanically spinning LiDAR sensor, the incidence angle, which is an angle between a ray and the normal direction of the ground, becomes more ambiguous [29]. Thus, neighboring ground points far from the sensor frame are projected to the same pixels, resulting in many false positives. To tackle the limitation of the range image, Pomerleau et al. [40] exploited the normal vector as another cue to resolve the incidence angle ambiguity. Kim and Kim [23] proposed a window-based pixel comparison and multi-resolution methods. However, from the pixel-wise removal, dynamic points remained scattered in the map, which led to the introduction of traversability-based methods.\nRecently, traversability-based methods have been proposed to reject dynamic points based on the fact that dynamic objects in urban environments usually move on the ground [1], [2], [17], [28]. Lim et al. [28] proposed an efficient concept to estimate temporarily occupied regions by comparing the min-max height of a query and map, called pseudo occupancy. Fu et al. [17] proposed robust drivable region proposals to extract ground points. Arora et al. [2] suggested offline ground segmentation on the image plane, and then dynamic and static points are discerned. Despite substantial progress being made, two potential limitations still exist. First, the aforementioned works firmly consider the estimated ground points as static points. Yet, the researchers did not propose methods to deal with cases where dynamic points are misclassified as ground points. Second, the proposed methods do not consider instance information, potentially leading to partial false positives, as presented in Fig. 1(a).\nMeanwhile, deep learning-based MOS approaches have led to significant improvement [11], [25], [32], [48]. One might think that a static map can be simply built by accumulating the estimated static points by MOS methods. However, these methods still rely on the supervised labels and it is empirically demonstrated that a static map by the estimates\nof MOS methods has many undesirable false negatives (see Section IV.D). Therefore, map-centric dynamic points management is still necessary to leverage temporal information.\nIn this paper, we propose a novel instance-aware approach to mapping the static world. Unlike previous static map building approaches that only exploit geometrical discrepancies, our proposed method blends the best of the philosophy of traversability-based methods and instance-aware dynamic point removal, resulting in cleaner static maps with less false positive and false negative points."
        },
        {
            "heading": "III. OUR APPROACH TO INSTANCE-AWARE MAPPING OF THE STATIC WORLD",
            "text": "The schematic diagram of our instance-aware static map building method is presented in Fig. 2. It mainly consists of four parts: pseudo occupancy grid map update, dynamic instance proposal, under-segmentation check, and volumetric outlier removal. Our proposed method aims for dynamic points removal at an instance-level."
        },
        {
            "heading": "A. Notations and Problem Definition",
            "text": "We begin by explaining the notations of inputs. Let us define a 3D point cloud as P = {p1,p2, \u00b7 \u00b7 \u00b7 ,pN} where N denotes the size of point cloud and each point, p, consists of an x, y, and z value, i.e., p = [x, y, z]\u1d40, in Cartesian coordinates. In this study, we divide P into two categories: ground points and non-ground points. Those will be further classified into multiple instance segments by the following procedure.\nFirst, P is taken as an input of a ground segmentation approach [29], so it is divided into ground points, G, and nonground points, P \u2032, which satisfy G \u2229 P \u2032 = \u2205 and G \u222a P \u2032 = P . Next, a clustering method is utilized to separate P \u2032 into unlabeled points, S0, and K instances, I+ = {S1, \u00b7 \u00b7 \u00b7 ,SK}, such that I = {S0} \u222a I+, each of which follows Sa \u2229 Sb = \u2205 if a 6= b. Unlabeled points S0 are a set of unclustered points, which is an output of most instance segmentation methods due to the failure of clustering caused by the sparse distribution of the cloud points.\nNote that G and I are estimates, so segments could be partially under- or over-segmented. In particular, the actual dynamic points are sometimes classified into S0, as shown in Fig. 3. Thus, it is necessary to consider the potential failure of instance segmentation. Therefore, we propose robust dynamic points rejection methods to account for the noises and errors of instance segmentation (see Section III.D and Section III.E).\nIn general, static map building methods assume that corrected poses are given [23]. Let Twt be the transformation matrix of the t-th body frame with respect to world frame w, the map cloud M can be defined as:\nM = \u03bd ( \u22c3 t\u2208\u3008T \u3009 \u03bd ({ Twt p | p \u2208 Pt })) , (1)\nwhere \u03bd(\u00b7) denotes a voxelization; T is the total time step; \u3008T \u3009 is equal to {1, 2, . . . , T}; Pt denotes the point cloud whose origin is the t-th body frame; Twt p means that a point expressed in the t-th body frame is transformed into world frame w. Consequently,M is an accumulated map, so it still contains all measured dynamic points.\nFollowing Lim et al. [28], the problem definition can be expressed as follows:\nM\u0302 =M\u2212 \u22c3 t\u2208\u3008T \u3009 M\u0302dynt , (2)\nwhere M\u0302 denotes the estimated static map cloud and M\u0302dynt denotes the dynamic points to be rejected from M at time step t.\nThere are two challenges in (2): a) once the direct subtraction of M\u0302dynt from M wrongly rejects static points, there is no way to revert these static points and b) M\u0302dynt is decided without any instance-level information, so points of moving objects could remain in M\u0302 while only a portion of the objects would be rejected.\nTo tackle these two problems, we redefine the problem for the work presented here as:\nM\u0302 = \u03bd ( \u22c3 t\u2208\u3008T \u3009 \u03bd ({ Twt p | p \u2208 Pt \u2212 U\u0302t \u2212 \u22c3 S\u2208I\u0302t S })) , (3) where I\u0302t denotes the estimated dynamic instances set, which is a subset of the predictions from the instance segmentation at t, It, i.e. I\u0302t \u2282 It. S denotes the moving instance included in I\u0302t, and U\u0302t denotes the additionally estimated dynamic points to overcome the erroneous predictions of instance segmentation (see Section III.E).\nBy doing so, (3) has advantages over (2) for the following two reasons. First, the false positives of our proposed method affect the quality of a map less directly. This is because static instances are usually observed multiple times, so false positives at t can be naturally compensated if the corresponding static points are preserved in other viewpoints. In contrast, once false positives occur, the direct subtraction in (2) triggers some empty holes in the map by rejecting static points, which Lim et al. [28] has an issue with. Second, by rejecting dynamic points in an instance-aware manner, the aforementioned partial removal issue can be resolved, as shown in Fig. 1(b).\nThus, the following sections explain how to estimate I\u0302t and U\u0302t in (3), overcoming the erroneous estimates of instance segmentation."
        },
        {
            "heading": "B. Pseudo Occupancy Grid Map Update",
            "text": "It is not easy to distinguish moving objects by only using a single scan captured at t. Thus, we utilize the temporal information of all scans and fuse the information from the map-centric perspective, as shown in Fig. 2(a). A map cloud is the accumulation of all scans transformed into the reference frame, which includes traces of moving objects over time. Whereas each scan is a snapshot of the surroundings, and traversable regions may only be temporarily occupied by moving objects. Accordingly, we check the geometrical discrepancies due to the moving objects by comparing the t-th point cloud transformed into the map frame and map cloud. In doing so, we can estimate the regions that contain the traces of dynamic objects in the map. Finally, we can consider the non-ground points in those regions as moving objects.\nBased on these observations, we propose to build a pseudo occupancy grid map. Unlike generic occupancy grid maps,\nwhich model whether space is occupied or not, our proposed grid map models whether the regions are likely to be temporally occupied by dynamic objects in a probabilistic manner [6], [7], [31]. By estimating the probabilities of which cells could contain moving objects, non-ground points in the grid cells with high probabilities are highly likely to be from dynamic instances.\nTo this end, we update the probability of each grid cell based on a binary Bayes filter to fuse all the predictions from each scan. In this way, the information is aggregated from the map-centric perspective and can be used to improve decision making about static and dynamic 3D points. Formally, the pseudo occupancy grid map is initialized with a prior probability, p0. Then, the pseudo occupancy grid map is updated, whose joint distribution of the binary state, m, is expressed as follows:\np (m | z1:t) = \u220f i p (mi | z1:t) , (4)\nwhere mi denotes the binary state of whether the i-th1 grid cell could be temporarily occupied or not and z1:t denotes the observed measurements during whole time steps, each of which is the geometrical discrepancy between the t-th scan and the map cloud, which will be explained in the following paragraphs.\nThen, by using Bayes\u2019 rule and log-odds notation, l(x) = logit(p(x)) = log p(x)1\u2212p(x) , (4) is paraphrased as follows:\nl (mi | z1:t) = l (mi | z1:t\u22121) + l (mi | zt)\u2212 l (mi) , (5)\nwhere l (mi | z1:t\u22121), l (mi | zt), and l (mi) represent a recursive term, update term, and prior term, respectively; l (mi) is equal to log-odds of prior probability, i.e. logit(p0).\nNext, we model the geometrical discrepancy zt. There are typically three possible occasions for each grid cell as described below: \u2022 Case A: an object occupies the grid cell of map cloud\nwhile the corresponding region is free in that of the t-th cloud (red bins in Fig. 4). \u2022 Case B: an object occupies both grid cell of the map and the t-th cloud (emerald bins in Fig. 4). \u2022 Case C: neither an object occupies the cell of the map nor the t-th cloud, i.e. both are unoccupied (white bins in Fig. 4).\nTherefore, our objective is to find some regions where case A occurs and then increase the probabilities of these grid cells.\nTo this end, we use pseudo occupancy, which is introduced by Lim et al. [28], to efficiently check the discrepancies between the transformed t-th scan and map cloud for each grid cell. The pseudo occupancy is described by the minmax z difference \u2206h. Then, if there is a large difference of pseudo occupancy between the scan and map cloud, we can determine that the corresponding cell is occupied at another\n1Strictly speaking, the index i should be expressed as (u, v), where u and v are the indices of the 2D grid map, yet (u, v) is simplified to i for brevity.\ntime step t\u2032, where t\u2032 6= t, which is highlighted as red bins in Fig. 4.\nFormally, we first extract the physically significant space where dynamic objects are likely to be located, called volume of interest (VOI), Vt, for each t-th point cloud as:\nVt = {pl \u2208 Pt | hmin < zl < hmax} , (6)\nwhere hmin and hmax denote the minimum and maximum heights of VOI, respectively. Then, the pseudo occupancy of each cell is described using the VOI. By extracting the VOI in advance, we can preserve the purpose of the pseudo occupancy that we intended, i.e. description of being occupied at an instance-level, even in some cases where a roof exists.\nNext, the local map, Mlocal, to be compared with the transformed Vt is defined as:\nMlocal = \u03bd ( \u22c3 t\u2208\u3008T \u3009 \u03bd ({ Twt p | p \u2208 Vt })) , (7)\nwhere w is the coordinate frame of the local map. By using the local coordinate, our method is available in cases where some pitch angles or z-values of poses are large with respect to the world frame.\nLet VQt = { Twt p | p \u2208 Vt } be the transformed cloud into the w frame and VMt \u2282 Mlocal be the corresponding map VOI, which is the overlapped region with VQt as illustrated in Fig. 5(a). Finally, the pseudo occupancy for the i-th cell\nexpressed in the reference frame \u2206hi,t is defined as: \u2206hi,t = H ( Vi,t ) = max { Zi,t } \u2212 z\u0304loweri,t , (8)\nwhere Zi,t = {zl | pl = [xl, yl, zl]\u1d40 \u2208 Vi,t} and Vi,t is the subset of VOI corresponding to the region of i-th grid cell; let the subsets of the map and transformed scan be VMi,t \u2282 VMt and VQi,t \u2282 V Q t , respectively, then z\u0304 lower i,t = min (z\u0304 Q i,t, z\u0304 M i,t), where z\u0304Qi,t and z\u0304 M i,t denote the mean z values of ground points within VQi,t and VMi,t . Thus, by using (8), the pseudo occupancies corresponding to VQi,t and VMi,t are set as \u2206h Q i,t = H(VQi,t) and \u2206hMi,t = H(VMi,t ), respectively. \u2206hQi,t and \u2206h M i,t are used to check the case of our interest, i.e. case A. As illustrated in Fig. 4, large difference between \u2206hQi,t and \u2206h M i,t indicates that the i-th grid cell is occupied at another time step t\u2032 but is not occupied at t resulting in \u2206hQi,t ' 0. To robustly check the difference, we use the ratio test [30] as \u2206hQi,t/\u2206h M i,t < \u03c4\u2206h where \u03c4\u2206h denotes the ratio threshold. In addition, we check two conditions to judge if sufficient points are observed and if the cell is not in case C. To this end, first, we check if the number of points in VQi,t and that in VMi,t are larger than Nmin, where Nmin denotes the minimum number of points for each grid cell. Second, we check if \u2206hMi,t > \u2206hmin, where \u2206hmin denotes the minimum pseudo occupancy. If all three conditions are satisfied, we consider that case A occurs, which is highlighted as orange rectangles in Fig. 5(a).\nHowever, even though any conditions are not satisfied, if most points in VQi,t are ground points, which means that the cell is currently free, then the i-th cell can be considered as an area potentially occupied by a moving object. This is\nbecause the ground regions can be potentially traversable by moving objects. Therefore, the update term is adaptively set based on these observations as follows:\nl (mi | zt) =  \u03bainc \u00b7 logit(pinc), if case A occurs logit(pinc), if |GQi,t| |VQi,t| > \u03c4ground\nlogit(p0), otherwise.\n(9)\nwhere \u03bainc > 1 is the incremental gain, pinc > p0 is the update probability, | \u00b7 | denotes the cardinality of a set, GQi,t denotes the ground points within VQi,t, and \u03c4ground denotes the ratio threshold that is close to 1. p0 is prior probability, which makes l (mi | zt) = l(mi) in (5), so update does not happen, i.e. l (mi | z1:t) = l (mi | z1:t\u22121), which is represented as white regions in Fig. 5(b)."
        },
        {
            "heading": "C. Dynamic Instance Proposal",
            "text": "After updating the pseudo occupancy grid map, we consider the instances corresponding to the non-ground points in the grid cells with high probabilities as initial dynamic instances I\u0302 initt . Formally, we define the indices set of grid cells which correspond to the high probabilities as R:\nR = {i | p(mi | z1:t) > prp} , (10)\nwhere prp is a region proposal threshold. R is expressed as white regions in Fig. 6(b).\nLet f : p 7\u2192 i be the function that returns an index of the grid cell where a point, p, is located, I\u0302 initt is defined as follows:\nI\u0302 initt = { Sk,t \u2208 I+t | \u2203f(p) \u2208 R, p \u2208 Sk,t } , (11)\nwhere I+t is a provided instance set at t, except by the unlabeled points S0,t. Meanwhile, unlabeled points that are located in the region proposals are handled separately as\nU\u0302 initt = {p \u2208 S0,t | f(p) \u2208 R} , (12)\nwhere S0,t denotes all the unlabeled points at t. By doing so, the noisy points, which are highlighted in Fig. 3, are filtered out.\nHowever, I\u0302 initt also includes some undesirable static instances, which should not be rejected, because a portion of static instances is located in R, as shown in Fig. 6(c). Therefore, to check whether most parts of the objects are located on grid cells with high probabilities, we propose a novel metric called dynamic instance score dyn(\u00b7), which is defined as:\ndyn(Sk,t) = 1 |Sk,t| \u2211\np\u2208Sk,t\nlogit(g(p)), (13)\nwhere g(\u00b7) denotes a function that adaptively returns a probability of the grid cell corresponding to p depending on whether the grid cell is updated or not as:\ng (p) = { p(mi | z1:t), if p(mi | z1:t) > p0 pneg, otherwise\n(14)\nwhere pneg < 0.5 is a constant parameter. The objective of g(\u00b7) is to reduce dyn(Sk,t) if an instance is static. The cells fully occupied by static instances do not satisfy the aforementioned conditions in Section III.B. so these cells are not updated, preserving p(mi | z1:t) as p0. Thus, even if small portions of static objects are in R so that these instances are wrongly considered as initial dynamic instances, their dynamic instance scores are much lower than those of the actual dynamic instances due to logit(pneg) < 0, which makes dyn(Sk,t) be negative.\nTherefore, the final dynamic instances, I\u0302t, are selected as follows:\nI\u0302t = { Sk,t \u2208 I\u0302 initt | logit\u22121(dyn(Sk,t)) > p(p\u0304k,t) } , (15)\nwhere p(p\u0304k,t) is an adaptive probability threshold depending on the distance between the origin of the body frame and the centroid of the k-th segment, p\u0304k,t. That is, p(p\u0304k,t) returns psoft to make the threshold less conservative if an instance is located far from the body frame, and phard, otherwise, where psoft < phard. By doing so, wrongly rejected static instances are successfully reverted, as shown in Fig. 6(d). This adaptive thresholding slightly increases undesirable false positives, but substantially increases the rejection rate of moving objects (see Section IV.C)."
        },
        {
            "heading": "D. Under-Segmentation Check",
            "text": "The approach presented so far works well, but we occasionally observe that under-segmentation, which means that at least one static and one dynamic object are segmented together, occasionally triggers false negatives. This phenomenon is illustrated in Figs. 7(a) and 7(b). For instance, once an actual static object with a large size and an actual dynamic object are clustered together, the large static instance makes dyn(Sk,t) smaller because the most static points located in the non-updated cells return minus values of log-odds in (13). Consequently, dyn(Sk,t) becomes\nsmaller than the adaptive threshold of (15), so the undersegmented clusters with dynamic points are considered to be static, resulting in false negatives.\nTo resolve this problem, we partially reject the points in the grid cells with definitely high probabilities from the abnormally large instances. Formally, if the following three conditions are satisfied: a) the total area where a potential static instance is occupied is larger than AUSC, b) the ratio of the non-updated grids is larger than \u03c4USC, where \u03c4USC is the ratio threshold, and c) other grid cells with definitely high probabilities exist, we segment the partial points located in the grids with high probabilities as a new dynamic instance. By doing so, false negatives caused by under-segmentation can be successfully rejected, as shown in Fig. 7(c). The estimated dynamic points are added to I\u0302t.\nE. Volumetric Outlier Removal Finally, VOR is proposed to reject partially remaining dynamic points caused by the erroneous estimates of the instance and ground segmentation, by leveraging spatiotemporal information. As presented in Figs. 8(a) and 8(b), even though most dynamic instances are rejected by the dynamic instance proposal, some noisy points still remain in the map. Even, some lower parts of dynamic instances are misclassified as ground points in some cases. Therefore, it is necessary to additionally reject dynamic points at the final stage.\nThe basic idea of VOR is to reject points of the estimated static points neighboring to the estimated dynamic points because the adjacent volumes of dynamic instances are also likely to be occupiable; thus, our VOR works like volumetric erosion. To this end, first, let the estimated dynamic points be Qt (green points in Fig. 8(a)) and the estimated static points be Tt, which is the complement of Qt. Then, the neighboring search, N (\u00b7), to obtain neighboring noisy points is defined as:\nN (Qt, Tt, r) = {p \u2208 Tt | min \u2016p\u2212 q\u2016 < r}, (16)\nwhere q \u2208 Qt and r denotes a search radius. Qt is set by utilizing dynamic instances on adjacent frames as well as those estimated at time t. For each time step, there are two elements: a) the selected dynamic segments PQt , which is expressed as:\nPQt = \u22c3\nSk,t\u2208I\u0302t\nSk,t[logit\u22121(dyn(Sk,t)) > pv], (17)\nwhere [\u00b7] denotes the Iverson bracket, which is an indicator function returning 1 if the statement inside the bracket is true, and 0, otherwise; psoft < pv < phard is a probability threshold to select more reliable dynamic segments, and b) the unlabeled points included in (12) and close to PQt , which is defined as UQt = N (PQt , U\u0302 initt , rv), where rv is defined as \u03bav \u00b7 \u03be; \u03bav > 1 denotes the volumetric gain and \u03be denotes the voxel size. Finally, let t\u2032 \u2208 W be the window indices set, e.g. if |W | = 3, W = {t\u2212 1, t, t+ 1}, then Qt is set as:\nQt = \u22c3 t\u2032\u2208W { (Tw\u2032t ) \u22121Tw\u2032t\u2032 \u00b7 p | p \u2208 PQt\u2032 \u22c3 UQt\u2032 } . (18)\nNext, the estimated static points, Tt, is defined as: Tt = \u22c3\nSk,t\u2208(I+t \u2212I\u0302t)\nSk,t + S0,t \u2212 U\u0302 initt , (19)\nwhich is the complement of the estimated dynamic points, i.e. cloud points from I\u0302t and U\u0302 initt . Consequently, the rejected points, P\u0302vt , are defined as P\u0302vt = N (Qt, Tt, rv).\nFinally, U\u0302t in (3) is set to U\u0302t = P\u0302vt \u22c3 U\u0302 initt . As a result, some remaining dynamic points in the map are successfully rejected, as shown in Fig. 8(c)."
        },
        {
            "heading": "IV. EXPERIMENTAL EVALUATION",
            "text": "The main focus of this work is a robust map building approach for the static 3D points that rejects the dynamic points at an instance-level while preserving static points, overcoming the potentially erroneous estimates of instance segmentation.\nWe present our experiments to show the capabilities of our method. The results of our experiments also support our key claims, which are: our approach (i) precisely rejects dynamic points by using instance segmentation information, (ii) has effective ways that suppress the effect of erroneous estimates of instance segmentation, and (iii) shows superior robustness in a more crowded environment compared to state-of-the-art learning-based methods. Our experimental evaluation backs up these claims."
        },
        {
            "heading": "A. Experimental Setup",
            "text": "To perform our analysis, we exploit static map building benchmark, proposed by Lim et al. [28]. The benchmark uses the SemanticKITTI dataset [3], [18], which provides point-wise annotations of moving instances. This benchmark consists of five sequences with a large number of dynamic points as follows: Seq. 00 (4,390 - 4,530), Seq. 01 (150 - 250), Seq. 02 (860 - 950), Seq. 05 (2,350 - 2,670), and Seq. 07 (630 - 820), where the numbers in parentheses indicate the start and end frames. These subsequences are the five sequences with the largest number of dynamic objects, so the capability of static map building methods can be effectively evaluated. Note that this benchmark uses the estimated poses by SuMa [4], not ground truth poses, to check the robustness using realistically uncertain poses [23].\nThe datasets that have point-wise labels [9] have only a few dynamic points, so the phenomenon that different dynamic objects occupy the same space does not frequently occur. Therefore, we manually labeled Seq. 19 of the KITTI object tracking dataset, which contains more moving objects per scan. By doing so, we evaluate the performance of baseline methods and our method in a crowded environment.\nFor all experiments, we use Preservation Rate (PR), Rejection Rate (RR), and F1 score [28] defined as: \u2022 PR: # of preserved static voxels# of total static voxels on the naively accumulated map , \u2022 RR: 1\u2212 # of remaining dynamic voxels# of total dynamic voxels on the naively accumulated map , \u2022 F1: 2PR \u00b7 RR/(PR + RR).\nSee Lim et al. [28] for more details on these metrics. In addition, we summarize the parameters of our approach in Table I. Experiments on parameter tuning are provided in the appendix."
        },
        {
            "heading": "B. Static Map Building Performance",
            "text": "The first experiment evaluates the performance of our proposed method and baseline methods, supporting the claim that our approach precisely rejects dynamic points while preserving static points as many as possible by leveraging instance segmentation information. For our comparison, we used the following baseline methods: OctoMap [21] that employs a clamping technique [54] with voxel size 0.05 and 0.2;\nPeopleremover [44], Removert [23], where RM3 denotes the results after three Removal stages with resolutions of 0.4\u25e6, 0.45\u25e6, and 0.5\u25e6 when projecting points into the range images. RM3-RV1 refers to the result of RM3 followed by a Revert stage with the resolution of 0.55\u25e6; DynamicFilter [15], AutoMOS [12], ERASOR [28], and Park et al. [38]. We use the results or default parameters provided by the authors.\nThe comparison of such baseline to our method is shown in Table II and Fig. 9. The state-of-the-art methods provided an accurate static map, filtering out over 90 % of dynamic points. Our proposed method exhibits noticeable improvements in both PR and RR, showing the highest F1 scores. In particular, our proposed method even rejected the lower part of the dynamic instances more clearly (the 2nd row, Fig. 9) while losing fewer static points compared to ERASOR.\nOctoMap and Removert lost many static points while leaving dynamic points on the top part of the bus (the 4th row, Fig. 9). This is because, from the query coordinate, behind the upper part of the large object is free space, so there is no point to check hit or miss along the ray or range discrepancy between the query and map cloud. In addition, Auto-MOS, which is a tracking-based MOS method, also failed because tracking algorithms are highly sensitive to the parameters setting [53], [55], so tracking usually fails to track when too large or too small moving objects were detected. For these reasons, it was demonstrated that our proposed method showed better performance compared with ray tracing methods, visibility-based methods, and MOSbased methods.\nThe cause of lower RR in Seq. 01 and Seq. 07 compared with ERASOR is because the probability values of the\npseudo occupancy grid behind the median barriers and end parts of a map were less observed, so these values were not sufficiently updated. However, additional sensor measurements from the opposite lanes would easily overcome this limitation.\nWe conclude that our instance-aware dynamic object removal is effective for accurate static map building compared with existing methods."
        },
        {
            "heading": "C. Robustness Against Noise in Instance Segmentation",
            "text": "The second experiment evaluates the ability of our method to deal with noisy instance segmentation. As shown in Table III, the performance of our approach does not degrade significantly even if noisy instance segmentation is used. According to Nunes et al. [34], it was shown that the instance segmentation of the approach [34] for known objects is\nsubstantially better than HDBSCAN [10]. Nevertheless, note that no matter what instance segmentation method was used, our proposed method showed similar performance.\nFrom Seq. 01, we also notice how our instance-aware approach helps not only on removing dynamic objects but also on preserving static points. Because Seq. 01 is recorded in a highway scene, lots of bushy vegetation are represented as noisy points. When considering the more precise instance predictions from Nunes et al. [34], the PR is increased because more complete instance information is provided. Therefore, the noisy points from static bushes can be correctly preserved.\nTo further support our claim and examine the effectiveness of each module more closely, we conduct an ablation study, as shown in Table IV. There was a trade-off between PR and RR, yet our proposed modules showed a greater improvement in the RR than a decrease in the PR. In particular, our USC and VOR significantly increased RR for the following reasons: USC enables rejection of a portion of dynamic points clustered with large static instances and VOR rejects some false negative points neighboring to the estimated dynamic points, as presented in Figs. 7 and 8.\nTherefore, these results support our claim that robust modules, USC and VOR, against erroneous instance segmentation estimates allow the performance of our approach to be less variant to the quality of instance segmentation."
        },
        {
            "heading": "D. Static Map Building Performance in Highly Crowded Environments",
            "text": "This subsection backs up our third claim that the proposed method is more robust than existing methods, also in crowded environments. As shown in Table V and Fig. 10, our proposed method showed promising performance compared with other state-of-the-art methods. In particular, Removert did not remove the traces of pedestrians successfully and lost static points all over the region (Fig. 10(a)). ERASOR showed better dynamic object removal performance, yet ERASOR created some holes in the map, i.e., some ground points and a portion of walls are also removed (Fig. 10(b)). In contrast, our proposed method successfully rejected dynamic points by fusing all the predictions about moving objects to the pseudo occupancy grid map, while losing fewer static points than Removert and ERASOR (Fig. 10(d)).\nWe also compare our proposed method with the state-ofthe-art learning-based MOS method, 4DMOS [32]. That is, we generate the map by only using the estimated static points by 4DMOS. One interesting thing is that the MOS methods care more about precision, thus being too conservative and leading to more false negatives. For this reason, 4DMOS showed the highest PR, but its RR is substantially lower than existing static map building methods, as shown in Table V. In particular, naively accumulating the results of MOS cannot cover some false negatives at t. Thus, these false negatives directly degrade the quality of the estimated static map, as shown in Fig. 10(c)."
        },
        {
            "heading": "E. Runtime of Our Approach",
            "text": "Finally, we investigate the runtime of our approach. The runtime per scan of the static map building methods was analyzed in Seq. 01, which is the largest scale, so the speed difference becomes more noticeable depending on how map cloud is handled and geometrical discrepancies are estimated.\nAs presented in Table VI, our approach runs fast at around 0.2 s per scan. More specifically, pseudo occupancy grid map update, dynamic instance proposal, and the other refinement stages take 6.6 ms, 52.6 ms, and 144.2 ms, respectively. It takes some time to perform VOR because we use a K-d tree for searching neighboring points as in (16). Nevertheless, static map building is often used as a post-processing before the localization or navigation, which is an offline process, so the runtime is not very important. Nevertheless, the sufficiently fast speed implies that our proposed method efficiently builds static maps."
        },
        {
            "heading": "V. CONCLUSION",
            "text": "In this paper, we proposed a novel instance-aware static map building method, called ERASOR2. By exploiting instance segmentation estimates, our proposed method can precisely reject more dynamic points at an instance-level while preserving most static points. In particular, we proposed pseudo occupancy grid map update to estimate the regions that contain the traces of moving objects in the map. Furthermore, we present novel ways to deal with noisy instance segmentation estimates, which allow us to provide high performance, overcoming somewhat imprecise instance segmentation. Consequently, our proposed method shows promising performance compared with existing conventional and deep learning-based methods. Finally, all claims made in the paper have been experimentally supported."
        },
        {
            "heading": "APPENDIX A PERFORMANCE CHANGES WITH DIFFERENT PARAMETERS",
            "text": "Among the parameters in Table I, we stress that \u03bainc and pinc should be set appropriately. As shown in Fig. A1, there is a trade-off between PR and RR, so two parameters directly affect the performance. For instance, if both parameters are too large, too many region proposals occur, so false positives increase, resulting in a lower preservation rate and a high rejection rate. In contrast, if both parameters are too small, i.e. when \u03bainc = 1.0 and logit(pinc) = 0.05, the probabilities of the grids are not allowed to be over prp, leading to more false negatives. As a result, dynamic points are not successfully filtered out, showing low rejection rate as 32.93 %. Except in that case, our method successfully preserves static points (> 98%) and rejects dynamic points (> 90%) even though parameters are changed."
        },
        {
            "heading": "APPENDIX B PERFORMANCE CHANGES WITH DIFFERENT WINDOW SIZES",
            "text": "Next, we present performance changes with different window sizes. If the window size W (see Section III.E) becomes large, more points are likely to be wrongly rejected, so the preservation rate slightly decreases and rejection rate increases, and vice versa. In Seqs. 00, 02, 05, and 07, dynamic points from moving objects are already successfully rejected (> 98%), so the performance change with different window sizes is insignificant. But in more crowded environments, i.e. Seqs. 01 and 19, the performance change\nPreservation rate [%]\nIncremental gain, \u03bainc\nU pd\nat ed\nlo g-\nod ds\n,l og\nit( p\nin c)\nRejection rate [%]\nIncremental gain, \u03bainc\nU pd\nat ed\nlo g-\nod ds\n,l og\nit( p\nin c)\nFig. A1. Preservation and rejection rates for Seq. 07 on the SemanticKITTI dataset depending on \u03bainc and logit(pinc). If both parameters are too small, dynamic points are not successfully filtered out, showing low rejection rate, e.g. when \u03bainc = 1.0 and logit(pinc) = 0.05, rejection rate is 32.93 % (best viewed in color).\nof rejection rate becomes significant because moving objects frequently re-occupy the spaces that were occupied by another moving object just before. However, if W is set to be too large, the performance of the preservation rate becomes worse because the number of points to be preserved is wrongly rejected. Based on these observations, we set W = 3 as a moderate value.\nFig. A2. Preservation and rejection rates on the SemanticKITTI dataset depending on window size W ."
        }
    ],
    "title": "ERASOR2: Instance-Aware Robust 3D Mapping of the Static World in Dynamic Scenes"
}