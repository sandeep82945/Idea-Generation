{
    "abstractText": "Unmanned aerial vehicles (UAVs) have been actively studied as moving cloudlets to provide application offloading opportunities and to enhance the security level of user equipments (UEs). In this correspondence, we propose a hybrid UAV-aided secure offloading system in which a UAV serves as a helper by switching the mode between jamming and relaying to maximize the secrecy sum-rate of UEs. This work aims to optimize (i) the trajectory of the helper UAV, (ii) the mode selection strategy and (iii) the UEs\u2019 offloading decisions under the constraints of offloading accomplishment and the UAV\u2019s operational limitations. The solution is provided via a deep deterministic policy gradient (DDPG)-based method, whose superior performance is verified via a numerical simulation and compared to those of traditional approaches.",
    "authors": [
        {
            "affiliations": [],
            "name": "Seonghoon Yoo"
        },
        {
            "affiliations": [],
            "name": "Seongah Jeong"
        },
        {
            "affiliations": [],
            "name": "Joonhyuk Kang"
        }
    ],
    "id": "SP:0fd778908cde9e7604449dfa46664e7a308ba7f5",
    "references": [
        {
            "authors": [
                "Q. Hu",
                "Y. Cai",
                "G. Yu",
                "Z. Qin",
                "M. Zhao",
                "G.Y. Li"
            ],
            "title": "Joint offloading and trajectory design for UAV-enabled mobile edge computing systems",
            "venue": "IEEE Internet Things J., vol. 6, no. 2, pp. 1879\u20131892, Apr. 2019.",
            "year": 1879
        },
        {
            "authors": [
                "S. Jeong",
                "O. Simeone",
                "J. Kang"
            ],
            "title": "Mobile edge computing via a UAV- Mounted cloudlet: Optimization of bit allocation and path planning",
            "venue": "IEEE Trans. Veh. Technol., vol. 67, no. 3, pp. 2049\u20132063, Mar. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Y. Zhou"
            ],
            "title": "Secure communications for UAV-enabled mobile edge computing systems",
            "venue": "IEEE Trans. Commun., vol. 68, no. 1, pp. 376\u2013388, Jan. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "T. Bai",
                "J. Wang",
                "Y. Ren",
                "L. Hanzo"
            ],
            "title": "Energy-efficient computation offloading for secure UAV-edge-computing systems",
            "venue": "IEEE Trans. Veh. Technol., vol. 68, no. 6, pp. 6074\u20136087, Jun. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "W. Lu",
                "Y. Mo",
                "Y. Feng",
                "Y. Gao",
                "N. Zhao",
                "Y. Wu",
                "A. Nallanathan"
            ],
            "title": "Secure transmission for multi-UAV-assisted mobile edge computing based on reinforcement learning",
            "venue": "IEEE Transactions on Network Science and Engineering, pp. 1\u201312, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "C. Wen",
                "Y. Fang",
                "L. Qiu"
            ],
            "title": "Securing UAV communication based on multi-agent deep reinforcement learning in the presence of smart UAV eavesdropper",
            "venue": "2022 IEEE Wireless Communications and Networking Conference (WCNC), 2022, pp. 1164\u20131169.",
            "year": 2022
        },
        {
            "authors": [
                "S. Yin",
                "Z. Qu",
                "L. Li"
            ],
            "title": "Uplink resource allocation in cellular networks with energy-constrained UAV relay",
            "venue": "Proc. IEEE 87th Veh. Technol. Conf. (VTC Spring), Porto, Portugal, Jun. 2018, pp. 1\u20135.",
            "year": 2018
        },
        {
            "authors": [
                "D.W. Matolak",
                "R. Sun"
            ],
            "title": "Air\u2013ground channel characterization for unmanned aircraft systems-part III: The suburban and near-urban environments",
            "venue": "IEEE Trans. Veh. Technol., vol. 66, no. 8, pp. 6607\u2013 6618, Aug. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "C. You",
                "R. Zhang"
            ],
            "title": "3D trajectory optimization in rician fading for UAV-enabled data harvesting",
            "venue": "IEEE Trans. Wireless Commun., vol. 18, no. 6, pp. 3192\u20133207, Jun. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M. Al-Jarrah",
                "A. Al-Dweik",
                "E. Alsusa",
                "Y. Iraqi",
                "M.-S. Alouini"
            ],
            "title": "On the performance of IRS-assisted multi-layer UAV communications with imperfect phase compensation",
            "venue": "IEEE Trans. Commun., vol. 69, no. 12, pp. 8551\u20138568, Dec. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "T.P. Lillicrap"
            ],
            "title": "Continuous control with deep reinforcement learning",
            "venue": "2015. [Online]. Available: arXiv:1509.02971",
            "year": 2015
        },
        {
            "authors": [
                "L. Wang",
                "K. Wang",
                "C. Pan",
                "W. Xu",
                "N. Aslam",
                "L. Hanzo"
            ],
            "title": "Multiagent deep reinforcement learning-based trajectory planning for multi- UAV assisted mobile edge computing",
            "venue": "IEEE Trans. Cogn. Commun. Netw., vol. 7, no. 1, pp. 73\u201384, Mar. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Luo",
                "W. Ding",
                "B. Zhang"
            ],
            "title": "Optimization of task scheduling and dynamic service strategy for multi-UAV-enabled mobile-edge computing system",
            "venue": "IEEE Trans. Cogn. Commun. Netw., vol. 7, no. 3, pp. 970\u2013984, Sep. 2021.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n20 8.\n07 55\n0v 1\n[ ee\nss .S\nP] 1\n6 A\nug 2\n02 2\nIndex Terms\u2014Unmanned aerial vehicle (UAV), offloading, physical-layer security, deep reinforcement learning.\nI. INTRODUCTION\nRecently, unmanned aerial vehicles (UAVs) have begun to play an important role as moving cloudlets for edge computing thanks to their high flexibility and mobility. In particular, UAVs are employed to provide task offloading opportunities beyond 5G and 6G services with high-complexity and lowlatency requirements [1], [2]. The joint design of offloading resource allocation and the UAV trajectory is proposed in [2] to minimize energy consumption.\nWith the frequent appearance of the line-of-sight (LoS) paths in the offloading systems via UAV-mounted cloudlets, maintaining privacy and security is challenging. To resolve this issue, physical-layer security technologies have been explored [3], [4]. In [3], a full-duplex legitimate UAV acting as an edge server is developed with the optimal design of jamming and user association. The authors in [4] propose an energy-efficient offloading procedure for a UAV-assisted secure edge computing system with the aim of minimizing the energy consumption of the UAV\u2019s data processing. Both [3] and [4] provide conventional mathematical solutions, which require adaptive updating according to the time-variant offloading environment, e.g., the channel condition, and therefore encounter the computational complexity issue with an increase in the number of users. To address the complexity of the mathematical approaches, deep reinforcement learning (DRL) has emerged as a promising solution. DRL-based secure transmission in UAV-assisted mobile edge computing is developed in [5] to maximize the system utility function. Other authors [6] propose the optimal design of the legitimate UAV trajectory, the user\u2019s transmit power\nSeonghoon Yoo is with the Department of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon 34141, South Korea (e-mail: shyoo902@kaist.ac.kr).\nSeongah Jeong is with the School of Electronics Engineering, Kyungpook National University, Daegu 14566, Korea (e-mail: seongah@knu.ac.kr).\nJoonhyuk Kang is with the Department of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon 34141, South Korea (e-mail: jhkang@ee.kaist.ac.kr).\nand scheduling for secure communication by adopting a deep deterministic policy gradient (DDPG)-based method, a type of DRL method that can be used to solve continuous control problems. The existing DRL-based methods [5], [6] for secure offloading focus on the deployment or trajectory design of the legitimate UAV, in the former case of which the operation mode defaults to a single role, such as relaying or jamming.\nIn this correspondence, we propose a hybrid UAV-aided secure offloading scheme in which a UAV is employed as a helper, switching the mode between jamming and relaying in order to maximize the secrecy sum-rate of user equipments (UEs). The objective of this work is to optimize (i) the trajectory of the helper UAV, (ii) mode selection strategy, and (iii) the UEs\u2019 offloading decisions under the constraints of offloading accomplishment and the UAV\u2019s operational limitations. To this end, we formulate the problem based on a Markov decision process (MDP), whose solution is provided via a DDPG-based method. Via numerical results, the superior performance of the proposed algorithm is verified and compared to those of conventional approaches."
        },
        {
            "heading": "II. SYSTEM MODEL",
            "text": "We consider a hybrid UAV-enabled secure offloading system in which one legitimate UAV is employed as an edge server for ground UEs, while a helper UAV is adopted as a hybrid node to switch roles between relaying and jamming against a single eavesdropper UAV, as shown in Fig. 1. For simplicity and tractability, we assume a pair consisting of a legitimate UAV and a helper UAV in a single cell and focus on the uplink scenario. The helper UAV in relay mode assists with communication from the UE to the legitimate UAV by forwarding the offloaded data, in which the decode-and-forward (DF) method [7] is considered. In jamming mode, the helper UAV generates artificial noise against the eavesdropper UAV. Here, mode selection at the helper UAV is assumed to be optimized for each time slot (TS). According to the helper UAV\u2019s role, the legitimate UAV receives the offloaded data from both the helper UAV and UEs in relay mode or from UEs in jamming mode and executes the computation of the received offloaded data. To provide stability during offloading procedure, we assume that the legitimate UAV is hovering with a fixed altitude to serve all UEs within its coverage.\nIn the following, we denote the legitimate UAV as L, the helper UAV as H , and the eavesdropper UAV as E. A pair\n2\nconsisting of the legitimate UAV and the helper UAV hovers at an altitude h, and the eavesdropper UAV hovers at a higher altitude he. The U UEs transmit the data to the legitimate UAV for offloading with the orthogonal multiple access. The time horizon N is divided into T TSs, each of which has \u2206 seconds, i.e., N = T\u2206. For the orthogonal access of multiple UEs, each \u2206 is divided equally for the number U of UEs, i.e., \u2206/U seconds of each slot is allocated to each UE. In TS t, the mode of the helper UAV is denoted as\nk(t) =\n{\n1, if the helper UAV is in relay mode 0, if the helper UAV is in jamming mode. (1)\nAlso, we define the offloading decision variable zu(t) of the UE u as\nzu(t) =\n{\n1, if the UE u performs offloading 0, if the UE u performs local execution , \u2200u \u2208 U ,\n(2)\nwhere the set of UEs is denoted as U , {1, 2, ..., U}. In TS t, the helper UAV flies at a constant velocity in terms of the horizontal velocity vx(t) and the vertical velocity vy(t), yielding the set of the helper UAV\u2019s velocity variables, defined as vH(t) = {vx(t), vy(t)}. Accordingly, the horizontal coordinates of the helper UAV can be expressed as (xH(vH(t)), yH(vH(t))) while satisfying xH(vH(t)) = xH(0) + \u2211t t\u2032=1 vx(t \u2032)\u2206 and yH(vH(t)) = yH(0)+ \u2211t t\u2032=1 vy(t \u2032)\u2206, both of which are limited by its maximum velocity vmax. The legitimate UAV, the eavesdropper UAV and the UE u are assumed to be located on the xy-plane at (xL, yL), (xE , yE) and (xu, yu), respectively.\nBy following [8], Rician fading is adopted for the groundto-air (G2A) channel, and therefore the channel power gain between UE u and UAV i in TS t can be written as\ngu,i(vH(t)) = \u03b20\n(hu,i)2 + ( Du,i )2 \u03b3\nG2A(t), (3)\nfor \u2200u \u2208 U and i \u2208 {H,L,E}, where Du,i represents the Euclidean horizontal distance between UE u and UAV\ni on the xy-plane as Du,i=\n\u221a\n( xu \u2212 xi )2 + ( yu \u2212 yi )2\n, hu,i represents the altitude of UAV i and is defined as h and he when i\u2208{H,L} and i=E, respectively, and \u03b20 denotes the received power at the reference distance d0 = 1 m of the G2A link. Also, \u03b3G2A(t) is a small scale fading component in the G2A environment with the KG2A factor defined as \u03b3G2A(t) = \u221a KG2A/(KG2A + 1)\u03b3 + \u221a\n1/(KG2A + 1)\u03b3\u0303 [8], [9], where \u03b3 denotes the deterministic LOS component with |\u03b3| = 1 and \u03b3\u0303 is a circularly symmetric complex Gaussian (CSCG) random variable. Note that in (3), we explicitly express the dependency of the distance on the UAV\u2019s velocity when i = H as Du,i(vH(t)). For the air-to-air (A2A) channel\ngain between the helper UAV and UAV i \u2208 {L,E}, we define gH,i(vH(t)) as\ngH,i(vH(t)) = \u03b21 (\nhH,i )2 + ( DH,i(vH(t)) )2 \u03b3\nA2A(t), (4)\nfor i \u2208 {L,E}, where DH,i(vH(t)) is the horizontal distance between helper UAV H and the legitimate or eavesdropper UAV, hH,i represents the altitude difference, and is defined as 0 if i = L or as h \u2212 he if i = E, \u03b21 denotes the reference channel power gain of the A2A link, and \u03b3A2A(t) is small scale fading component with the KA2A factor [10]. Since the UE u can offload the data to the legitimate UAV or can be supported by the helper UAV within their coverage area in TS t, we have\nzu(t) ( k(t)Du,i + (1\u2212 k(t))Du,L ) \u2264 Dmax, (5)\nfor \u2200u \u2208 U and i \u2208 {H,L}, where Dmax denotes the radius of the coverage area for both the legitimate and helper UAVs."
        },
        {
            "heading": "A. Communication Model",
            "text": "In this section, we provide the communication model required for the secure offloading procedure between the legitimate UAV and UEs. For the relay operation of the helper UAV, we adopt a the time division manner due to the half-duplex limitation [7]. In particular, the time fraction \u2206/U allocated to each UE is divided into two parts, the first of which is used for each UE to transmit the data to both the legitimate and helper UAV, while the remainder is adopted for the helper UAV to relay the received data to the legitimate UAV. In jamming mode, the entire \u2206/U is consumed for transmission from each UE to the legitimate UAV while the helper UAV generates the jamming signal. Depending on the helper UAV\u2019s operation mode, the achievable data rates Rdu ( k(t),vH(t) ) and Reu ( k(t),vH(t) ) at the legitimate UAV and eavesdropper UAV are calculated as in Table I. In Table I, pu is the transmit power of UE u, \u03c32 is the noise power, and pH(k(t)) is the transmit power of the helper UAV, where pH(k(t)) = pR in relay mode, otherwise pH(k(t)) = pJ . For a further performance gain, the optimal power allocation for a different TS can be considered, which is left as our future work. Note that the achievable data rate at the legitimate UAV in relay mode is expressed as the minimum data rate obtained in two time fractions of the DF protocol, while the eavesdropper UAV can overhear the data via both the UE-legitimate UAV link and the helper UAV-legitimate UAV link. In jamming mode, the artificial interference at the eavesdropper UAV caused by the friendly jamming of the helper UAV is factored into the data rate. Consequently, the secrecy sum-rate of the wiretap channel is written as\n3 C ( k(t), z(t),vH (t) )\n= \u2211\nu\u2208U\nzu(t) [ Rdu ( k(t),vH(t) ) \u2212Reu ( k(t),vH(t) )]+ , (6)\nwhere [x]+ , max(x, 0), z(t) = {zu(t)}u\u2208U ."
        },
        {
            "heading": "B. Computing Model",
            "text": "We define the computational task of UE u in TS t as {Su(t), Fu(t)}, where Su(t) denotes the data size of the task, and Fu(t) denotes the number of CPU cycles for computing one bit. When the UE does the local execution, the task is computed within \u2206, and hence the CPU frequency fu(t) of the UE u is determined as fu(t) = Su(t)Fu(t)/\u2206. At the legitimate UAV, the total data received at the previous TS t \u2212 1 is assumed to be computed in TS t, and the CPU frequency of the legitimate UAV, fL(z(t)), is calculated as fL(z(t)) = \u2211\nu\u2208U\nzu(t\u2212 1)Su(t\u2212 1)Fu(t\u2212 1)/\u2206."
        },
        {
            "heading": "C. Energy Model",
            "text": "Here, since all network components have limited battery capabilities, their energy consumption needs to be addressed in the system design phase. The computation energy ECi (z(t)) required for execution at i \u2208 {1, ..., U, L} is given by [3]\nECi (z(t)) = \u03ba(fi) 3\u2206, (7)\nwhere \u03ba denotes the power consumption coefficient, and the CPU frequency fi is substituted with fu(t) and fL(z(t)) when i \u2208 U and i = L, respectively. The energy consumption at the helper UAV results from the signal transmission and the flying operation. The transmission energy consumption is derived as ETrH (k(t), z(t)) = k(t) \u2211\nu\u2208U zu(t)pR\u2206/(2U) + (1\u2212 k(t))pJ\u2206, while the flying energy consumption is given via EFH(vH(t)) = 0.5M\u2206 ( (vx(t)) 2+(vy(t)) 2 )\n[2], where M is the mass of the UAV, including its payload."
        },
        {
            "heading": "III. PROPOSED DDPG-BASED METHOD",
            "text": "This work aims to maximize the secrecy sum-rate by jointly optimizing the helper UAV\u2019s mode k(t), the UE\u2019s offloading choice z(t) and the helper UAV\u2019s velocity vH(t) for all t. To this end, we formulate the optimization problem as follows:\nmax k(t),z(t),vH(t) C(k(t), z(t),vH (t)) (8a)\ns.t. k(t) = {0, 1}, zu(t) = {0, 1}, \u2200u \u2208 U , (8b)\n\u2212lmax/2 \u2264 xH(vH(t)), yH(vH(t)) \u2264 lmax/2, (8c) zu(t) ( k(t)Du,i + (1 \u2212 k(t))Du,L ) \u2264 Dmax,\ni\u2208 {H,L}, \u2200u \u2208 U , (8d)\nzu(t)pu ( k(t) \u2206\n2U +(1\u2212 k(t))\n\u2206\nU\n)\n+(1\u2212 zu(t))E C u (t) \u2264 Eu, \u2200u \u2208 U ,\n(8e)\nECL (zt) \u2264 EL, (8f) EFH(vH(t))+E Tr H (k(t), z(t)) \u2264 EH , (8g)\nwhere (8b) is a binary variable constraint pertaining to the helper UAV\u2019s mode and offloading decision, (8c) ensures that the helper UAV travels within a lmax-side-length square, (8d)\nrestricts the legitimate and helper UAVs to hover within their coverage area, and (8e)-(8g) represent the energy constraints of UEs, the legitimate UAV and the helper UAV, respectively.\nTo solve problem (8), we employ the DRL framework to find the optimal policy for {k(t), z(t),vH(t)}\u2200t in every TS. Since a real-time mathematical approach for UAV trajectory design has complexity issues, we adopt the DDPG method among DRL-based approaches, which is appropriate for controlling a continuous action space [11]. In the MDP, the agent has state st in the environment during discrete TS, and it takes action at every TS. As the agent proceeds with various interactions in the environment, the agent obtains a reward rt and next state st+1. The policy (\u03c0) is designed to maximize the accumulated reward Rt = \u2211T i=t \u03b3 (i\u2212t)ri, where \u03b3 \u2208 [0, 1] is the discount factor. The critic network learns the actionvalue function Q(st, at) = Eai>t\u223c\u03c0[Rt|st, at] using Bellman\u2019s equation in Q-learning and proceeds to minimize the loss function L(\u00b7), which is defined as\nL(\u03b8Q) = E [( Q ( st, at|\u03b8 Q ) \u2212 yt )2] , (9)\nwhere \u03b8Q is the weight of the critic network and yt = rt + \u03b3Q\u2032 ( st+1, \u00b5 \u2032(st+1|\u03b8\u00b5 \u2032 )|\u03b8Q \u2032 ) . The actor network updates with the policy gradient method to maximize the expected reward J = Eai\u223c\u03c0[R1] and uses a policy function approximator, which follows\n\u2207\u03b8\u00b5J \u2248 E [ \u2207aQ(s, a|\u03b8 Q)|s=st,a=\u00b5(st)\u2207\u03b8\u00b5\u00b5(s|\u03b8 \u00b5)|st ] , (10)\nwhere \u03b8\u00b5 is the weight factor of the actor network. Additionally, the DDPG algorithm improves the update stability by using the target networks \u03b8Q \u2032 and \u03b8\u00b5 \u2032 , which are identical to those of the critic network and the actor network, and these target networks are updated by a soft update method.\nTo optimize the helper UAV\u2019s trajectory modeled as an MDP, we define the state, action and reward function in TS t as follows:\nState: Let S denote the system state space as S = {st|st = {xH(vH(t)), yH(vH(t)), k(t), {DH,i(vH(t))}i\u2208U\u222a{L,E}}, t \u2208 {1, 2, ..., T }}, whose components are the coordinates and the mode of the helper UAV, and the horizontal distance between the helper UAV and other nodes, respectively.\nAction: Let A denote the system action space as A = {at|at = {vx(t), vy(t)}, t \u2208 {1, 2, ..., T }}, whose components are the horizontal and vertical velocity of the helper UAV.\nReward: We define rt = C(k(t), z(t),vH (t))\u2212 rom as a reward function focusing on maximization of the secrecy sumrate, where rom is the penalty value for cases in which the helper UAV goes off of the given map. Note that the helper UAV returns to the previous location if it goes off of the map.\nWith the optimized helper UAV\u2019s trajectory, we develop a relaxation method to optimize the offloading decision variable z(t) and the helper UAV\u2019s operation mode k(t). The offloading decision variable z(t) is designed as\nzu(t) =\n\n \n \n1, if Rdu\n( k(t),vH(t) ) \u2212Reu ( k(t),vH(t) ) >\u03b5,\n\u2200u \u2208 U and (5) are satisfied\n0, otherwise, (11)\nso that a secrecy sum-rate greater than the minimum limit \u03b5 is guaranteed, and (5) is satisfied after action at is performed.\n4\nAlgorithm 1 DDPG-based method for a hybrid UAV-enabled secure offloading system\nInput: Structures of the actor, critic and target network. 1: Initialize: Actor \u00b5, critic Q and target network \u00b5\u2032, Q\u2032\nwith weights \u03b8\u00b5, \u03b8Q and \u03b8\u00b5 \u2032 \u2190 \u03b8\u00b5, \u03b8Q \u2032 \u2190 \u03b8Q and replay buffer B;\n2: for TS in T do 3: Set {zu(t) = 0}\u2200u\u2208U , and C0 = C1 = 0; 4: Calculate st as in \u201cState\u201d step of MDP; 5: Execute action at = \u00b5(st|\u03b8\n\u00b5) +N ; 6: for i \u2208 {0, 1} do 7: k(t) = i; 8: Obtain the offloading decision z(t) by (11); 9: Calculate Ci = C(k(t), z(t),vH(t))\n10: end for 11: Obtain reward rt= max i\u2208{0,1} Ci\u2212rom and next state st+1; 12: Store transition ( st, at, rt, st+1 )\nin B; 13: Sample a random mini-batch of K transitions (\nsi, ai, ri, si+1 )\nfrom B; 14: Update critic, actor network according to (9), (10); 15: Update target networks:\n\u03b8Q \u2190 \u03c4\u03b8Q + (1 \u2212 \u03c4)\u03b8Q \u2032 , \u03b8\u00b5 \u2032 \u2190 \u03c4\u03b8\u00b5 + (1\u2212 \u03c4)\u03b8\u00b5 \u2032 ;\n16: end for\nOutput: Actor network \u00b5(st|\u03b8\u00b5).\nAccording to the offloading decision, the helper UAV\u2019s mode for providing a higher secrecy sum-rate is selected by k(t) = argmaxi\u2208{0,1}Ci, and the reward rt is defined as rt = maxi\u2208{0,1}Ci \u2212 rom.\nBased on the entire process mentioned above, we propose the DDPG-based method, as given in Algorithm 1. In order to increase the convergence speed of Algorithm 1, the initial weights are set experimentally based on the previous steps, where a higher reward is achieved. For the helper UAV, action at is generated by the actor network \u00b5, and a noise process N is added for exploration. Then, we obtain the reward rt and next state st+1, while the helper UAV stores the transition into its finite-sized buffer B. From Line 14 to 15, networks are updated by pulling K samples from the buffer."
        },
        {
            "heading": "IV. SIMULATION RESULTS",
            "text": "In this section, we present the numerical results to evaluate the performance of the proposed algorithm compared to the reference methods. For simulations, we consider the parameter settings shown in Table II by following [3], [12]. For the energy budget of each node, we set Eu = 0.025J, EL = 24J, and EH is set to 3.9KJ [13]. In addition, we set 1000 episodes in the training stage. The capacity of the replay buffer is 8000, and the mini-batch size is 70. The noise process N follows a normal distribution with a zero mean and variance of 0.6. Noise decays at a rate of 0.999. The actor and critic networks have three fully-connected hidden layers with [300,100,100] neurons, and are trained at a learning rate of 10\u22124. The activation function is used as tanh function, and the network is updated using the AdamOptimizer. For references, the following benchmark methods are considered:\nFig. 2 shows the accumulated reward of the proposed algorithm as a function of training episodes. It is observed that the proposed method converges after 600 episodes. In addition, the proposed method achieved a higher accumulated reward than the Re-OT and Ja-OT schemes by further optimizing the offloading decision and the operation mode of the helper UAV. Fig. 3 shows the optimal trajectory obtained by the proposed method. In Fig. 3(a), we consider the case in which the UEs are randomly distributed around the legitimate UAV. It is observed that the optimized helper UAV tends to move around the UEs in Re-OT to increase the relay performance, while it moves towards the eavesdropper UAV in Ja-OT to maximize the jamming effect. In the proposed method, the helper UAV initially operates in relay mode (with yellow-solid line) and thus moves toward the UE cluster, similar to Re-OT. From 5\n5 -100 -75 -50 -25 0 25 50 75 100 x (m) -100 -75 -50 -25 0 25 50 75 100 y (m ) Starting point Legitimate UAV Eavesdropper UAV Re-OT Ja-OT Proposed method (relaying) Proposed method (jamming)\n(a)\n-100 -75 -50 -25 0 25 50 75 100 x (m)\n-100\n-75\n-50\n-25\n0\n25\n50\n75\n100\ny (m\n)\nStarting point\nRe-OT Ja-OT Proposed method (relaying) Proposed method (jamming)\n(b)\nFig. 3: The trajectory of the helper UAV according to the mode during 20 TS. (a) UEs are randomly distributed around the legitimate UAV. (b) Two UE clusters are spatially separated around the legitimate UAV.\nTS (5s), the helper UAV switches to jamming mode (with the yellow-dashed line), and moves toward the eavesdropper UAV, as in Ja-OT. In the case of 3(b), we consider two spatially separated UE groups around the legitimate UAV. Compared to 3(a), in Re-OT, the helper UAV moves toward the largescale cluster with 7 UEs, which can provide a higher secrecy sum-rate. In Ja-OT, the helper UAV goes to the eavesdropper UAV while maintaining its distance from the legitimate UAV. In the proposed method, both movement tendencies in Re-OT and Ja-OT are shown according to the corresponding mode change.\nIn Fig. 4, the secrecy sum-rate of the proposed method is shown as a function of the different time horizon N in a setting identical to that in Fig. 3(b). It can be seen that for all schemes, the secrecy sum-rate increases as the mission time increases. Note that the proposed method achieves the best secrecy sum-rate via joint optimization. Moreover, it is obvious that the DDPG-based trajectory design of the helper UAV provides additional secrecy improvements in comparison with Re-OT and Re-LT, or Ja-OT and Ja-LT."
        },
        {
            "heading": "V. CONCLUSIONS",
            "text": "In this correspondence, we have proposed a hybrid UAVenabled secure offloading algorithm to maximize the secrecy sum-rate of ground users, where a hybrid helper UAV is\n0 4 8 12 16 20\nTime horizon (s)\n0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\n4\nSe cr\nec y\nsu m\n-r at\ne (b\nps /H\nz)\nRe-LT Ja-LT Re-OT Ja-OT Proposed method\nFig. 4: The secrecy sum-rate of each schemes versus the time horizon.\nadopted to switch roles between relaying and jamming. We jointly optimize the helper UAV\u2019s mode selection and trajectory as well as users\u2019 offloading decisions based on the the DDPG method. Via simulations, the superior performance of the proposed method is verified compared to those of conventional methods. A scenario with multiple helpers and eavesdroppers can also be studied with the non-orthogonal multiple access in future work."
        }
    ],
    "title": "Hybrid UAV-enabled Secure Offloading via Deep Reinforcement Learning",
    "year": 2022
}