{
    "abstractText": "Background: Evidence-based practices (EBPs) are frequently adapted in response to the dynamic contexts in which they are implemented. Adaptation is defined as the degree to which an EBP is altered to fit the setting or to improve fit to local context and can be planned or unplanned. Although adaptations are common and necessary to maximizing the marginal impact of EBPs, little attention has been given to the economic consequences and how adaptations affect marginal costs. Discussion: In assessing the economic consequences of adaptation, one should consider its impact on core components, the planned adaptive periphery, and the unplanned adaptive periphery. Guided by implementation science frameworks, we examine how various economic evaluation approaches accommodate the influence of adaptations and discuss the pros and cons of these approaches. Using the Framework for Reporting Adaptations and Modifications to Evidence-based interventions (FRAME), mixed methods can elucidate the economic reasons driving the adaptations. Micro-costing approaches are applied in research that integrates the adaptation of EBPs at the planning stage using innovative, adaptive study designs. In contrast, evaluation of unplanned adaptation is subject to confounding and requires sensitivity analysis to address unobservable measures and other uncertainties. A case study is presented using the RE-AIM framework to illustrate the costing of adaptations. In addition to empirical approaches to evaluating adaptation, simulation modeling approaches can be used to overcome limited follow-up in implementation studies. Conclusions: As implementation science evolves to improve our understanding of the mechanisms and implications of adaptations, it is increasingly important to understand the economic implications of such adaptations, in addition to their impact on clinical effectiveness. Therefore, explicit consideration is warranted of how costs can be evaluated as outcomes of adaptations to the delivery of EBPs.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ramzi G. Salloum"
        },
        {
            "affiliations": [],
            "name": "Todd H. Wagner"
        },
        {
            "affiliations": [],
            "name": "Amanda M. Midboe"
        },
        {
            "affiliations": [],
            "name": "Sarah I. Daniels"
        },
        {
            "affiliations": [],
            "name": "Andrew Quanbeck"
        },
        {
            "affiliations": [],
            "name": "David A. Chambers"
        }
    ],
    "id": "SP:b9004c3079481b5b1183be3754d52af3ab7cdddd",
    "references": [
        {
            "authors": [
                "DK Owens",
                "A Qaseem",
                "R Chou",
                "P. Shekelle"
            ],
            "title": "Clinical Guidelines Committee of the American College of P: High-value, cost-conscious health care: concepts for clinicians to evaluate the benefits, harms, and costs of medical interventions",
            "venue": "Ann Intern Med",
            "year": 2011
        },
        {
            "authors": [
                "SLE Roberts",
                "A Healey",
                "N. Sevdalis"
            ],
            "title": "Use of health economic evaluation in the implementation and improvement science fields-a systematic literature review",
            "venue": "Implement Sci",
            "year": 2019
        },
        {
            "authors": [
                "HT Gold",
                "C McDermott",
                "T Hoomans",
                "TH. Wagner"
            ],
            "title": "Cost data in implementation science: categories and approaches to costing",
            "venue": "Implement Sci",
            "year": 2022
        },
        {
            "authors": [
                "RE Glasgow",
                "C Battaglia",
                "M McCreight",
                "RA Ayele",
                "rapid Rabin BA. Making implementation science more"
            ],
            "title": "use of the RE-AIM framework for mid-course adaptations across five health services research projects in the Veterans Health Administration",
            "venue": "Front Public Health. 2020;8:194. Page 13 of 13 Salloum et al. Implementation Science Communications",
            "year": 2022
        },
        {
            "authors": [
                "DA Chambers",
                "RE Glasgow",
                "KC. Stange"
            ],
            "title": "The dynamic sustainability framework: addressing the paradox of sustainment amid ongoing change",
            "venue": "Implement Sci",
            "year": 2013
        },
        {
            "authors": [
                "SW Stirman",
                "CJ Miller",
                "K Toder",
                "A. Calloway"
            ],
            "title": "Development of a framework and coding system for modifications and adaptations of evidence-based interventions",
            "year": 2013
        },
        {
            "authors": [
                "C Escoffery",
                "E Lebow-Skelley",
                "R Haardoerfer",
                "E Boing",
                "H Udelson",
                "R Wood"
            ],
            "title": "A systematic review of adaptations of evidence-based public health interventions globally",
            "venue": "Implement Sci",
            "year": 2018
        },
        {
            "authors": [
                "GA Aarons",
                "AE Green",
                "LA Palinkas",
                "S Self-Brown",
                "DJ Whitaker",
                "JR Lutzker"
            ],
            "title": "Dynamic adaptation process to implement an evidence-based child maltreatment intervention",
            "year": 2012
        },
        {
            "authors": [
                "E. Rogers"
            ],
            "title": "Diffusion of innovations fifth",
            "venue": "New York: edition Free Press;",
            "year": 2003
        },
        {
            "authors": [
                "Charters WW",
                "Pellegrin RJ"
            ],
            "title": "Barriers to the innovative process: Four case studies of differentiated staffing",
            "venue": "Educ Admin Q",
            "year": 1973
        },
        {
            "authors": [
                "L Leviton",
                "B. Henry"
            ],
            "title": "Better information for generalizable knowledge: systematic study of local adaptation. In: American Public Health Association 139th Annual Meeting and Exposition",
            "year": 2011
        },
        {
            "authors": [
                "Chambers DA",
                "Norton WE"
            ],
            "title": "The adaptome: advancing the science of intervention adaptation",
            "venue": "Am J Prev Med",
            "year": 2016
        },
        {
            "authors": [
                "M. Sculpher"
            ],
            "title": "Evaluating the cost-effectiveness of interventions designed to increase the utilization of evidence-based guidelines",
            "venue": "Fam Pract. 2000;17(Suppl 1):S26\u201331",
            "year": 2000
        },
        {
            "authors": [
                "J Mason",
                "N Freemantle",
                "I Nazareth",
                "M Eccles",
                "A Haines",
                "M. Drummond"
            ],
            "title": "When is it cost-effective to change the behavior of health professionals? JAMA",
            "year": 2001
        },
        {
            "authors": [
                "S Whyte",
                "S Dixon",
                "R Faria",
                "S Walker",
                "S Palmer",
                "M Sculpher"
            ],
            "title": "Estimating the cost-effectiveness of implementation: is sufficient evidence available",
            "venue": "Value Health",
            "year": 2016
        },
        {
            "authors": [
                "JC Mewes",
                "IJ Steuten LMG. C",
                "IJ MJ",
                "WH van Harten"
            ],
            "title": "Value of implementation of strategies to increase the adherence of health professionals and cancer survivors to guideline-based physical exercise",
            "venue": "Value Health",
            "year": 2017
        },
        {
            "authors": [
                "S Wiltsey Stirman",
                "AA Baumann",
                "CJ. Miller"
            ],
            "title": "The FRAME: an expanded framework for reporting adaptations and modifications to evidencebased interventions",
            "venue": "Implement Sci",
            "year": 2019
        },
        {
            "authors": [
                "Scheirer MA"
            ],
            "title": "Linking sustainability research to intervention",
            "venue": "types. Am J Public Health",
            "year": 2013
        },
        {
            "authors": [
                "G Moore",
                "M Campbell",
                "L Copeland",
                "P Craig",
                "A Movsisyan",
                "P Hoddinott"
            ],
            "title": "Adapting interventions to new contexts-the ADAPT guidance",
            "venue": "BMJ. 2021;374:n1679",
            "year": 2021
        },
        {
            "authors": [
                "AR Dopp",
                "P Mundey",
                "LO Beasley",
                "JF Silovsky",
                "D. Eisenberg"
            ],
            "title": "Mixed-method approaches to strengthen economic evaluations in implementation research",
            "year": 2019
        },
        {
            "authors": [
                "AB Eisman",
                "DW Hutton",
                "LA Prosser",
                "SN Smith",
                "AM. Kilbourne"
            ],
            "title": "Costeffectiveness of the Adaptive Implementation of Effective Programs Trial (ADEPT): approaches to adopting implementation strategies",
            "venue": "Implement Sci",
            "year": 2020
        },
        {
            "authors": [
                "S Wiltsey Stirman",
                "CA Gutner",
                "P Crits-Christoph",
                "J Edmunds",
                "AC Evans",
                "RS. Beidas"
            ],
            "title": "Relationships between clinician-level attributes and fidelityconsistent and fidelity-inconsistent modifications to an evidence-based psychotherapy",
            "year": 2015
        },
        {
            "authors": [
                "JA Mauskopf",
                "SD Sullivan",
                "L Annemans",
                "J Caro",
                "CD Mullins",
                "M Nuijten"
            ],
            "title": "Principles of good practice for budget impact analysis: report of the ISPOR Task Force on good research practices--budget impact analysis",
            "venue": "Value Health",
            "year": 2007
        },
        {
            "authors": [
                "WC Jones Rhodes",
                "DP Ritzwoller",
                "RE. Glasgow"
            ],
            "title": "Stakeholder perspectives on costs and resource expenditures: tools for addressing economic issues most relevant to patients, providers, and clinics",
            "venue": "Transl Behav Med",
            "year": 2018
        },
        {
            "authors": [
                "Z Philips",
                "K Claxton",
                "S. Palmer"
            ],
            "title": "The half-life of truth: what are appropriate time horizons for research decisions",
            "venue": "Med Decis Making",
            "year": 2008
        },
        {
            "authors": [
                "WC Becker",
                "SN Edmond",
                "DJ Cervone",
                "A Manhapra",
                "JJ Sellinger",
                "BA Moore"
            ],
            "title": "Evaluation of an integrated, multidisciplinary program to address unsafe use of opioids prescribed for pain",
            "venue": "Pain Med",
            "year": 2018
        },
        {
            "authors": [
                "RE Glasgow",
                "TM Vogt",
                "SM. Boles"
            ],
            "title": "Evaluating the public health impact of health promotion interventions: the RE-AIM framework",
            "venue": "Am J Public Health",
            "year": 1999
        },
        {
            "authors": [
                "LM Collins",
                "SA Murphy",
                "V. Strecher"
            ],
            "title": "The multiphase optimization strategy (MOST) and the sequential multiple assignment randomized trial (SMART): new methods for more potent eHealth interventions",
            "venue": "Am J Prev Med",
            "year": 2007
        },
        {
            "authors": [
                "LM Collins",
                "TB Baker",
                "RJ Mermelstein",
                "ME Piper",
                "DE Jorenby",
                "SS Smith"
            ],
            "title": "The multiphase optimization strategy for engineering effective tobacco use interventions",
            "venue": "Ann Behav Med",
            "year": 2011
        },
        {
            "authors": [
                "AM Kilbourne",
                "D Almirall",
                "D Eisenberg",
                "J Waxmonsky",
                "DE Goodrich",
                "JC Fortney"
            ],
            "title": "Protocol: Adaptive Implementation of Effective Programs Trial (ADEPT): cluster randomized SMART trial comparing a standard versus enhanced implementation strategy to improve outcomes of a mood disorders program",
            "year": 2014
        },
        {
            "authors": [
                "A Quanbeck",
                "D Almirall",
                "N Jacobson",
                "RT Brown",
                "JK Landeck",
                "L Madden"
            ],
            "title": "The Balanced Opioid Initiative: protocol for a clustered, sequential, multiple-assignment randomized trial to construct an adaptive implementation strategy to improve guideline-concordant opioid prescribing in primary care",
            "venue": "Implement Sci",
            "year": 2020
        },
        {
            "authors": [
                "Wagner TH"
            ],
            "title": "Rethinking how we measure costs in implementation research",
            "venue": "J Gen Intern Med",
            "year": 2020
        },
        {
            "authors": [
                "J Lipscomb",
                "KR Yabroff",
                "ML Brown",
                "W Lawrence",
                "PG. Barnett"
            ],
            "title": "Health care costing: data, methods, current applications",
            "venue": "Med Care",
            "year": 2009
        },
        {
            "authors": [
                "R Faria",
                "M Gomes",
                "D Epstein",
                "IR. White"
            ],
            "title": "A guide to handling missing data in cost-effectiveness analysis conducted within randomised controlled trials",
            "venue": "Pharmacoeconomics",
            "year": 2014
        },
        {
            "authors": [
                "RE Glasgow",
                "L Fisher",
                "LA Strycker",
                "D Hessler",
                "DJ Toobert",
                "DK King"
            ],
            "title": "Minimal intervention needed for change: definition, use, and value for improving health and health research",
            "venue": "Transl Behav Med",
            "year": 2014
        },
        {
            "authors": [
                "DA Marshall",
                "IJ Burgos-Liz L. MJ",
                "ND Osgood",
                "WV Padula",
                "MK Higashi",
                "PK Wong",
                "KS Pasupathy",
                "W Crown"
            ],
            "title": "Applying dynamic simulation modeling methods in health care delivery research-the SIMULATE checklist: report of the ISPOR simulation modeling emerging good practices task force",
            "venue": "Value Health",
            "year": 2015
        },
        {
            "authors": [
                "Hovmand PS"
            ],
            "title": "Group model building and community-based system dynamics process. In: Community based system dynamics",
            "year": 2014
        },
        {
            "authors": [
                "S Gerritsen",
                "S Harre",
                "D Rees",
                "A Renker-Darby",
                "AE Bartos",
                "WE Waterlander"
            ],
            "title": "Community group model building as a method for engaging participants and mobilising action in public health",
            "venue": "Int J Environ Res Public Health",
            "year": 2020
        },
        {
            "authors": [
                "J Mullahy",
                "A Venkataramani",
                "DL Millimet",
                "CF. Manski"
            ],
            "title": "Embracing uncertainty: the value of partial identification in public health and clinical research",
            "venue": "Am J Prev Med",
            "year": 2021
        },
        {
            "authors": [
                "RG Whitaker",
                "N Sperber",
                "M Baumgartner",
                "A Thiem",
                "D Cragun",
                "L Damschroder"
            ],
            "title": "Coincidence analysis: a new method for causal inference in implementation science",
            "venue": "Implement Sci",
            "year": 2020
        },
        {
            "authors": [
                "SD Sullivan",
                "JA Mauskopf",
                "F Augustovski",
                "J Jaime Caro",
                "KM Lee",
                "M Minchin"
            ],
            "title": "Budget impact analysis-principles of good practice: report of the ISPOR 2012 Budget Impact Analysis Good Practice II Task Force",
            "venue": "Value Health",
            "year": 2014
        },
        {
            "authors": [
                "M Drummond",
                "M. Sculpher"
            ],
            "title": "Common methodological flaws in economic evaluations",
            "venue": "Med Care",
            "year": 2005
        },
        {
            "authors": [
                "CJ Miller",
                "ML Barnett",
                "AA Baumann",
                "CA Gutner",
                "S. Wiltsey-Stirman"
            ],
            "title": "The FRAME-IS: a framework for documenting modifications to implementation strategies in healthcare",
            "venue": "Implement Sci",
            "year": 2021
        },
        {
            "authors": [
                "L Olsen",
                "D Aisner",
                "JM. McGinnis"
            ],
            "title": "Institute of Medicine (US). Roundtable on Evidence-Based Medicine. The learning healthcare system: workshop summary",
            "venue": "Washington National Academies Pr",
            "year": 2007
        }
    ],
    "sections": [
        {
            "text": "Discussion: In assessing the economic consequences of adaptation, one should consider its impact on core components, the planned adaptive periphery, and the unplanned adaptive periphery. Guided by implementation science frameworks, we examine how various economic evaluation approaches accommodate the influence of adaptations and discuss the pros and cons of these approaches. Using the Framework for Reporting Adaptations and Modifications to Evidence-based interventions (FRAME), mixed methods can elucidate the economic reasons driving the adaptations. Micro-costing approaches are applied in research that integrates the adaptation of EBPs at the planning stage using innovative, adaptive study designs. In contrast, evaluation of unplanned adaptation is subject to confounding and requires sensitivity analysis to address unobservable measures and other uncertainties. A case study is presented using the RE-AIM framework to illustrate the costing of adaptations. In addition to empirical approaches to evaluating adaptation, simulation modeling approaches can be used to overcome limited follow-up in implementation studies.\nConclusions: As implementation science evolves to improve our understanding of the mechanisms and implications of adaptations, it is increasingly important to understand the economic implications of such adaptations, in addition to their impact on clinical effectiveness. Therefore, explicit consideration is warranted of how costs can be evaluated as outcomes of adaptations to the delivery of EBPs.\nKeywords: Adaptation, Adaptive, Economics, Cost, Economic evaluation\n\u00a9 The Author(s) 2022. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/. The Creative Commons Public Domain Dedication waiver (http:// creat iveco mmons. org/ publi cdoma in/ zero/1. 0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\n*Correspondence: rsalloum@ufl.edu\n1 Department of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, 2004 Mowry Road, Room 2243, Gainesville, FL 32610, USA Full list of author information is available at the end of the article\nContributions to\u00a0the\u00a0literature\n\u2022 Adaptations are a reality of implementing evidencebased practices and have economic implications \u2022 Economic implications should be considered in decisions to adapt evidence-based practices \u2022 Current frameworks to describe adaptations and specify the conditions under which adaptations are made can be helpful in identifying their resource implications \u2022 Economic evaluation tools can guide how and when to assess the economic impact of adaptations"
        },
        {
            "heading": "Introduction",
            "text": "Allocating resources to the implementation of interventions requires an understanding of the relationship between resources expended and health outcomes achieved by the program or intervention. Economic evaluation methods that have traditionally been applied to measure value and compare the costs and consequences of health interventions [1] can also inform whether strategies designed to improve the quality of health care delivery and the uptake of evidence-based practices (EBPs) represent a cost-effective use of limited resources. An increasing number of health economic evaluations are nested within implementation and improvement research studies [2]. These studies estimate the costs of delivering EBPs (intervention costs), the costs of the implementation strategies to enhance their delivery (implementation costs), and the downstream health care costs subsequent to the implemented EBP (downstream costs) [3].\nDespite the growing use of economic evaluation in implementation science, little attention has been given to economic issues and to the methodological challenges of evaluating the marginal costs of implementation attributable to adaptations that often occur to EBPs during the implementation process [4]. This article offers a unique perspective on the economics of adaptation, an evolving area of the field, by discussing practical approaches to evaluate the economic consequences of adaptation (i.e., what is planned at baseline vs. what gets delivered). This topic is of increased importance to public health and health care delivery with the introduction of new approaches that integrate adaptive, contextually sensitive continuous quality improvement, particularly within learning health care systems [5]. Previous research suggests that adaptations are widespread [6, 7], underscoring the importance of understanding the effectiveness and economic implications of various adaptations to public health and health care delivery systems."
        },
        {
            "heading": "Background",
            "text": ""
        },
        {
            "heading": "Defining adaptation",
            "text": "There is an ongoing debate regarding what is meant by the term adaptation [8], and we use a definition that is broad but specific enough to advance the discussion of how to measure the economic impact of adaptations. Adaptation of EBPs has been defined as the process of \u201cthoughtful and deliberate alteration to the design or delivery of an intervention,\u201d with the goal of improving its fit or effectiveness in a new context [9]. The origins of adaptation can be traced to its roots in the Diffusion of Innovations theory [10], originally defined as \u201cre-invention\u201d and discussed as early as 1972 by Charters and Pellegrin [11]. Originally thought to be unambiguously negative, re-invention has increasingly been recognized as a fundamental part of the adoption and implementation process. The most common reasons for adaptation have included the need for a culturally appropriate program, a new target population, a new community or clinical setting, the desire to improve ease and feasibility of implementation, attempting to make the program more widely accessible, and condensing the original intervention [7]. Although adaptations can be made to the implementation strategy used to deliver EBPs into a new setting, this paper focuses on adaptations to EBPs which can occur even in the absence of implementation strategies."
        },
        {
            "heading": "The role of\u00a0economics in\u00a0the\u00a0science of\u00a0adaptation",
            "text": "There is growing recognition that adaptation is a necessary step in optimizing EBP implementation and that it is essential to the uptake and sustainment of EBPs. There are common steps involved in adaptation processes, each of which may have economic implications. These steps typically include conducting an organizational assessment, determining the level of change, and consulting stakeholders or experts before adapting the intervention, preparing new materials, training staff members, implementing the adapted intervention, evaluating the adapted intervention, and determining needed changes based on action step assessments [7].\nGiven the adaptations may have resource implications, there is a need to advance the science at the intersection between adaptation and economic evaluation. Despite their widespread prevalence, adaptations are understudied, with knowledge gaps surrounding their context, the adaptation decision itself, the positive and negative outcomes associated with various levels of adaptation, and the robustness of adaptations across different contexts and types of interventions [6]. Early efforts have been directed at studying the impact of adaptation on individuals and organizations,\nincluding an initiative by the Robert Wood Johnson Foundation to systematically investigate the local adaptation of evidence-based practices [12]. Advancing our economic understanding of adaptation is consistent with calls to develop strategies to improve the science of adaptation in the context of implementation that would more comprehensively describe the needed fit between EBPs and their settings, and embrace opportunities for ongoing learning about optimal EBP delivery over time [13]."
        },
        {
            "heading": "Progression of\u00a0economic evaluation in\u00a0implementation research",
            "text": "Economic modelling can inform those planning to scale up EBPs. In this respect, various approaches to the economic evaluation for implementation of EBPs can be applied to study adaptations. When evaluating EBPs, estimates of the expected benefit for each patient can be summed up to estimate the net effect for a group of patients, which can be used to estimate the net effect for a health care system. Sculpher first proposed the evaluation of implementation strategies by estimating their cost-effectiveness ratio in 2000 [14]. This model assumes that the strategies under evaluation can achieve perfect implementation conditions with patterns of clinical practice remaining static. In 2001, Mason and colleagues suggested a framework for economic evaluation that examines the cost-effectiveness of implementation strategies that help to achieve the adoption of treatments in addition to the costeffectiveness of the treatments [15]. This framework recognized that interventions do not achieve perfect implementation in the real world, and therefore, it is important to value the actual uptake of the intervention. However, costs on this framework are estimated at the patient level, which is less useful to decisionmaking that occurs at the program level. Additionally, while this framework acknowledges implementation gaps as a problem in economic modeling, it does not directly address adaptations and their consequences with respect to economic evaluation. Over the past two decades, analytic methods have been proposed to measure the expected value of the improved implementation of health care interventions at the patient level [16, 17]. However, the literature is scarce on approaches to directly address adaptation as a necessary step in optimizing implementation. In response, this paper discusses available frameworks and methods that can be applied to economic evaluation of adaptations, as well as the needed for new methods and approaches to advance the science of adaptation from an economic evaluation lens."
        },
        {
            "heading": "Methodology",
            "text": "Framework for\u00a0characterizing the\u00a0economic drivers and\u00a0consequences of\u00a0adaptations Stirman et\u00a0 al. developed the Framework for Reporting Adaptations and Modifications to Evidence-based interventions (FRAME) for describing and measuring adaptations that organizations make to fit an evidence-based intervention to their setting [6]. The framework was based on a systematic review of adaptations to evidencebased interventions. The latest iteration of this framework [18] includes eight domains: (1) when and how in the implementation process the adaptation was made, (2) whether the adaptation was planned/proactive or unplanned/reactive, (3) who determined that the adaptation should be made, (4) what is adapted, (5) at what level of delivery the adaptation is made, (6) type or nature of context or content-level adaptations, (7) the extent to which the adaptation is fidelity-consistent, and (8) the reasons for the adaptation, including the intent or goal of the adaptation (e.g., improve fit, adapt to a different culture, reduce costs).\nAcross all domains of the framework, there are economic drivers and implications that should be considered. Costs can vary according to (1) the timing of the adaptation; (2) whether they are planned; (3) the decision-maker responsible for the adaptation; (4) whether the adaptation is to the EBP or implementation strategy; (5) whether the EBP is delivered at the patient, practice, or organizational level and the nature of the adaptation; (6) the nature of the content adaptation; (7) whether the adaptation preserves fidelity to the core components of the EBP; and (8) the reason or motivation for the adaptation. In some cases, economic factors might be driving the adaptation, and researchers may seek to understand the mechanisms by which costs motivate adaptations to a program and the role they play in influencing the likelihood of sustainability over time. Table\u00a0 1 presents examples within each domain of the FRAME, along with its cost relevance, considerations for cost measurement, and comparisons of its implications according to whether the adaptation was planned or unplanned. For example, adaptation can focus on either the EBP or the implementation strategy. Delineating adaptation costs of the implementation strategy compared with the EBP is crucial for scaleup efforts. Variation in adaptation costs may be related to the complexity of the intervention to be implemented [19]. Potential strategies to reduce the cost of adaptations may include starting with smaller adaptations and building upon successful experiences and sharing learnings from adaptations early and often through \u201ctrain-the-trainer\u201d or communities of practice approaches.\nTa bl\ne 1\nA da\npt at\nio n\nim pl\nic at\nio ns\na nd\nc on\nsi de\nra tio\nns fo\nr c os\nt m ea\nsu re\nm en\nt, or\nga ni\nze d\nby th\ne Fr\nam ew\nor k\nfo r R\nep or\ntin g\nA da\npt at\nio ns\na nd\nM od\nifi ca\ntio ns\n(F RA\nM E)\n[6 ]\nD om\nai n/\nco ns\ntr uc\nt Ex\nam pl\ne Co\nst re\nle va\nnc e/\nim pl\nic at\nio ns\nCo ns\nid er\nat io\nns fo\nr c os t m ea su re m en t\nPl an\nne d\nvs . u\nnp la\nnn ed\n1. T\nim in\ng A\nda pt\nat io\nn oc\ncu rs\nin th\ne pr\neim\npl e-\nm en\nta tio\nn or\np la\nnn in\ng ph\nas e\nvs .\nim pl\nem en\nta tio\nn ph\nas e\nEa rly\n-p ha\nse a\nda pt\nat io\nns , e\nsp ec\nia lly\npr\nio r t\no im\npl em\nen ta\ntio n,\nm ay\nb e\nle ss\nco\nst ly\nth an\nla te\n-p ha\nse a\nda pt\nat io\nns\nTi m\ne of\nin iti\nat io\nn, fr\neq ue\nnc y,\na nd\nd ur atio n pe rio d of a da pt at io n. T he se m ay va ry a cr os s si te s du e to c ap ac ity\nM or\ne di\nffi cu\nlt to\nc ap\ntu re\nti m\ne va\nria bl\nes in\nun\npl an\nne d\nad ap\nta tio\nns\n2. P\nla nn\nin g\nle ve\nl U\nnp la\nnn ed\n/r ea\nct iv\ne vs\n. p la\nnn ed\n/p ro\nac -\ntiv e\nU np\nla nn\ned a\nda pt\nat io\nns m\nay re\nqu ire\nad\ndi tio\nna l r\nes ou\nrc es\nn ot\no rig\nin al\nly\nbu dg\net ed\nfo r.\nA lte\nrn at\niv el\ny, u\nnp la\nnn ed\nad\nap ta\ntio ns\nm ay\nre du\nce c\nos ts\nw he n th ey a re a im ed a t i m pr ov in g effi ci en\ncy\ndu rin\ng th\ne im\npl em\nen ta\ntio n\npr oc\nes s\nA pp\nro pr\nia te\nd at\na ca\npt ur\ne st\nra te\ngy\nis im\npe ra\ntiv e\nfo r a\nss es\nsi ng\nc on\ntin ua l ite ra tio n on th e ad ap ta tio n to m ea\nsu re\nin\ncr em\nen ta\nl c os\nt o n\nth e\nm ar\ngi n\n(re ac - tiv el y or p ro ac tiv el y)\nRe po\nrt in\ng sy\nst em\nis a\nlre ad\ny in\np la\nce fo r m ea su rin g pl an ne d ad ap ta tio ns ; r ep or tin g sy st em fo r u np la nn ed a da pt at io n m ay b e cr ea te d im pr om pt u\n3. D\nec is\nio n-\nm ak\ner Fu\nnd er\no r p\nay er\nv s.\not he\nr s ta\nke ho\nld er s (e .g ., po lit ic al le ad er , c lin ic ia n, in te rv en - tio n re ci pi en t)\nA fu\nnd er\n/p ay\ner in\nvo lv\ned in\nth e\nde ci\nsi on\nto\na da\npt m\nay b\ne m\nor e\nco st\n-c on\nsc io\nus\nth an\na no\nth er\ns ta\nke ho\nld er\nw ho\nis le\nss\naff ec\nte d\nby c\nos ts\nEs tim\nat ed\nc os\nt i m\npa ct\no f a\nda pt atio n m ay b e co nt ra ry to w ha t w as an tic ip at ed\nPr oj\nec te\nd ch\nan ge\ns in\nc os\nt d ue\nto\npl an\nne d\nad ap\nta tio\nns c\nou ld\nb e\nes tim\nat ed\nin\nB IA\na p\nrio ri\nfo r f\nun de\nr b uy\n-in to\nk ee p/ ch an ge d ec is io n\n4. A\nda pt\nat io\nn fo\ncu s\nA da\npt at\nio n\nto th\ne EB\nP vs\n. i m\npl em\nen ta - tio n st ra te gy A\nda pt\nin g\nco m\npl ex\nim pl\nem en\nta tio n st ra te gi es m ay b e m or e co st ly th an ad ap tin g le ss -c om pl ex s tr at eg ie s\nD el\nin ea\ntin g\nad ap\nta tio\nn co\nst s\nof im\npl e-\nm en\nta tio\nn vs\n. E BP\nis c\nru ci\nal fo\nr e xt\nra po - la tio n/ sc al in g. V ar ia tio n in a da pt at io n co st s m ay b e re la te d to th e co m pl ex ity of th e in te rv en tio n\nPr oj\nec te\nd ch\nan ge\ns in\nc os\nt d ue\nto\npl an\nne d\nad ap\nta tio\nns to\nim pl\nem en\nta tio n vs . E BP c ou ld b e es tim at ed a p rio ri fo r bu dg et in g pu rp os es\n5. D\nel iv\ner y\nle ve\nl In\ndi vi\ndu al\np at\nie nt\n/p ar\ntic ip\nan t v\ns. cl\nin ic / un it le ve l v s. or ga ni za tio n/ he al th sy st em\nA da\npt at\nio ns\na t t\nhe in\ndi vi\ndu al\np at\nie nt\nle\nve l m\nay h\nav e\na lo\nw u\nni t c\nos t b\nut le\nad\nto h\nig h\nto ta\nl c os\nt w he\nn ex\nte nd\nto a\npa\ntie nt\np op\nul at\nio n,\nw he\nre as\nh ig\nhe r\nle ve\nl a da\npt at\nio ns\nm ay\nin vo\nlv e\nco st\nly\nad ap\nta tio\nns to\nin fra\nst ru\nct ur\ne\nD ep\nen di\nng o\nn th\ne de\nliv er\ny le\nve l;\nne w\nda\nta c\nol le\nct io\nn on\nd ire\nct , b\not h\nfix ed\nan\nd va\nria bl\ne, a\nnd in\ndi re\nct c\nos ts\nm ay\nbe\nn ee\nde d\nto a\nss es\ns ad\nap ta\ntio n\nco st s. Eff ec ts o n un it co st m ay b e m or e di ffic ul t t o in te rp re t a t h ig he r l ev el s\nPr oj\nec te\nd ch\nan ge\ns in\nc os\nt d ue\nto\npl an\nne d\nad ap\nta tio\nns in\nd el\niv er\ny le\nve l\nco ul\nd be\ne st\nim at\ned a\np rio\nri fo\nr b ud\nge t-\nin g\n6. N\nat ur\ne of\nc on\nte nt\na da\npt at\nio n\nTa ilo\nrin g\nor re\nfin in\ng, a\ndd in\ng or\nre m\nov -\nin g\nel em\nen ts\n, s ho\nrt en\nin g\nor le\nng th\nen -\nin g\nEx te\nnd in\ng th\ne in\nte rv\nen tio\nn or\nim pl em en ta tio n st ra te gy m ay re su lt in h ig\nhe r\nco st\nw he\nre as\nc on\nde ns\nin g\nit m\nay re\nsu lt\nin lo\nw er\nc os\nt\nM ay\nre qu\nire m\nix ed\nm et\nho ds\nto c\nol le\nct\nal l d\nat a\nne ce\nss ar\ny fo\nr a cc\nur at\nel y\ndi s-\nce rn\nin g\nth e\nna tu\nre o\nf t he\na da\npt at\nio n\nN ee\nd fo\nr b ot\nh qu\nan tit\nat iv\ne an\nd qu\nal ita - tiv e da ta m ay b e pa rt ic ul ar ly a cu te fo r un pl an ne d ad ap ta tio ns w he re c on te\nxt is\nno\nt w el\nl-k no\nw n\n7. R\nel at\nio ns\nhi p\nto fi\nde lit\ny A\nda pt\nat io\nn th\nat p\nre se\nrv es\nc or\ne el em en ts v s. on e th at fa ils to d o so\nD ep\nar tu\nre fr\nom c\nor e\nel em\nen ts\nm ay\nin\ncr ea\nse c\nos t i\nf a dd\niti on\nal e\nle m\nen t(\ns)\nar e\nne ed\ned o\nr r ed\nuc e\nco st\nif c\ner ta\nin\nel em\nen t(\ns) a\nre n\no lo\nng er\nn ee\nde d\nw he n im pl em en tin g in a n ew c on te xt\nM ay\nre qu\nire m\nix ed\nm et\nho ds\nto c\nol le\nct\nal l d\nat a\nne ce\nss ar\ny fo\nr a cc\nur at\nel y\ndi s-\nce rn\nin g\nth e\nna tu\nre o\nf t he\na da\npt at\nio n\nM ay\nn ee\nd to\nc on\nsi de\nr l os\ns of\nm or e si te s, pr ov id er s, an d/ or p at ie nt s w\nith\nun pl\nan ne\nd ad\nap ta\ntio n\n8. R\nea so\nn or\nm ot\niv at\nio n\nIn cr\nea se\nre ac\nh or\ne ng\nag em\nen t,\nim pr\nov e\nfit , r\ned uc\ne co\nst M\not iv\nat io\nns fo\nr t he\na da\npt at\nio n\n(i. e. , in cr ea si ng p os iti ve o ut co m es ) m ay al so in cr ea se c os t. D et er m in in g w he\nn,\nw hy\n, a nd\nh ow\nre du\nce d\nco st\ns al\nig n\nw ith\not\nhe r m\not iv\nat io\nns s\nho ul\nd be\na dd\nre ss\ned\nat th\ne ou\nts et\nEs tim\nat ed\nc os\nt i m\npa ct\no f a\nda pt atio n m ay b e co nt ra ry to w ha t w as an tic ip at ed\nPr oj\nec te\nd ch\nan ge\ns in\nc os\nt d ue\nto\npl an\nne d\nad ap\nta tio\nns c\nou ld\nb e\nes tim\nat ed\na\npr io\nri to\ns up\npo rt\no r r\nef ut\ne re\nas on\nin g\nfo r\nad ap\nta tio\nn\nMixed methods economic evaluation Guided by the FRAME and other tools [20], mixed methods approaches can be highly useful to elucidate the economic reasons driving the adaptations to improve the generalizability of findings, as well as their economic consequences [21]. Mixed methods can also inform sensitivity analysis that is often a critical component to test the assumptions made in economic evaluation [22], by further identifying and explaining variations in cost at different levels (e.g., provider, practice) and for various stakeholders. For implementation planning purposes, it is useful to understand the dimensions upon which planned adaptations may be warranted and to establish a range in costs associated with planned adaptations that are likely to occur. Whereas estimating the cost implications of adaptations can be useful, more nuanced economic evaluation than simply measuring costs should be carried out in early phases of implementation and improvement program planning."
        },
        {
            "heading": "Addressing the\u00a0economic consequences of\u00a0adaptation",
            "text": "Figure\u00a0 1 conceptualizes adaptations to an EBP and its implementation that warrant economic evaluation. In the cases of the EBP, there are core components to consider, in addition to planned adaptive periphery, as well as unplanned adaptive periphery. This relationship is illustrated for both the trial components (i.e., EBP) and the trial costs (i.e., intervention costs, implementation costs, and downstream costs). Studies can be designed to monitor the impact of adaptations within the planned adaptive periphery. Economic evaluation can estimate the marginal costs for a particular implementation strategy, the marginal estimates of incremental costs of the EBP within the confines of the costs of a particular implementation\nstrategy, and the marginal costs in downstream estimates of the implemented intervention. However, tracking downstream effects may be subject to confounding because it may not be clear what caused the effect.\nEconomic methods can also be used to estimate the marginal cost in the case of unplanned or reactive adaptation. Unplanned adaptation is the change to the content or strategy of EBP delivery that is not specified in the standard treatment protocol [23]. From an evaluation perspective, unplanned adaptations could be in response to unexpected contextual changes (e.g., changing the structure of a treatment protocol due to the onset of COVID-19) or could reflect a deficit of implementation fidelity (e.g., drifting from the protocol) and create noise that could limit the interpretation or reduce the statistical power of estimating the consequences of these adaptations. The economic consequences of unplanned adaptation decisions may be difficult to address comprehensively using standard evaluation methods. One issue is the problem of endogeneity that confounds all unplanned adaptations. Endogeneity means that the choice to adapt was based on internal decisions, as opposed to being randomly assigned. This prevents causal estimates because the adaptation is correlated with unobserved confounders. When estimating EBP costs, unplanned adaptive peripheral costs are the marginal estimates of unexpected incremental costs. For downstream costs, these are the marginal estimates of unexpected incremental costs downstream of implementation. In all cases, these estimates may be outside the perceived bounds of the initial EBP costs and confounding is possible.\nFor a given EBP, estimates may exist from the original trial on the cost or cost-effectiveness of implementing the intervention. However, because an adapted EBP will rely on different local resources across various delivery settings, costs could differ substantially between contexts. When the EBP is implemented in a new setting, one scenario could involve implementing the EBP without adaptation. Although some costs might be lower in the new\nsetting \u2014 for example, if the original trial required more developmental work for an implementation infrastructure \u2014 it is possible that the EBP will achieve suboptimal outcomes due to the limited fit between the EBP and the new delivery setting. Therefore, an alternative scenario involves adaption to improve the fit of the EBP in the new setting. In this scenario, there is an incremental cost to implementing the EBP beyond the costs involved in the original setting, and there is an incremental change in implementation outcomes beyond the scenario that does not include adaptation. This rationale for studying the economics of adaptation is applicable to both cost-effectiveness analysis and budget impact analysis and depends on whether a standard has been established by one or more trials evaluating the EBP. The model structure diagram for a budget impact analysis [24] of implementation with an adaptation scenario is provided in Fig.\u00a02 for illustrative purposes, although a similar logic can be followed for addressing adaptations in a cost-effectiveness analysis. If the implementation of an EBP in a new setting without adaptation results in a loss in net benefits from the intervention, these models can examine the extent to which the adaptation restores these benefits."
        },
        {
            "heading": "Important considerations for\u00a0the\u00a0economics of\u00a0adaptation",
            "text": "The analysis of implementation studies includes costs that accrue to or are paid by the decision-maker and other costs relevant to stakeholders [25]. Implementation stakeholders are often faced with the decision of whether the adaptation should be made, based on prior knowledge and future projections of the value of EBPs. Stakeholders include those who are making the adaptation decision (whether top-down or bottom-up), but also those who will receive the results of the economic evaluation, including internal and external stakeholders. Therefore, specifying the appropriate economic perspective helps in identifying how and why certain adaptations should be costed and is essential for the effective replication of EBP implementation or in planning for potential\nadaptation. Given that implementation stakeholders are often interested in short-term rather than longer term outcomes, we focus the discussion on the evaluation of the economic impact of adaptation on intervention and implementation costs at the expense of downstream costs, especially when adaptations are involved. This discussion is applicable to both cost-effectiveness analysis which evaluates whether an EBP provides value relative to an existing intervention and budget impact analysis which estimates the financial consequences of adopting a new EBP.\nAnother important consideration in the economic evaluation of implementation within the context of adaptation is to specify the time period of interest. In traditional economic evaluation, the time horizon is any period over which economic value could be expected to differ across the comparators. The traditional approach of selecting a fixed value time horizon may be inappropriate. Philips et\u00a0 al. discussed alternative approaches to the selection of time horizons for valuing implementation alternatives and the benefits of explicitly modeling future changes and advocate for the selection of a common time horizon after accounting for the effects of anticipated changes in short-term adaptations [26]. Timing of the adaptation may influence cost, and it is plausible to observe diminishing returns in cost-savings for introducing an adaptation later in the implementation process. Given the complexity of adaptation decisions, implementation science frameworks are needed to evaluate costs of adaptations.\nCase study: costing adaptations in\u00a0implementation of\u00a0opioid reassessment clinics Implementation science frameworks can also clarify how adaptations could simultaneously affect primary target outcomes of an implementation study as well as its economic evaluation. Clarifying this a priori helps in planning for how to measure and report adaptations and make more appropriate cost estimates related to outcomes of interest. Table\u00a0 2 illustrates a case study of adaptations in opioid reassessment clinic (ORC) [27] implementation, organized by the domains of the Reach, Effectiveness, Adoption, Implementation, and Maintenance (RE-AIM) framework [28]. For each REAIM outcome, we present an adaptation example, along with its cost relevance, considerations for cost analysis, and a comparison of the implications of planned and unplanned adaptation. In the case study, effectiveness is measured as the number of patients on high-risk long-term opioid therapy who are transitioned to safer regimens. A new initiative at the clinical site requires regular monitoring of patients transferred to safer regimens. Costing this adaptation involves measuring the\ntime and resources required for monitoring patients after the initiative is launched. One method to consider here is interrupted time series that could examine the cost of adaptation on the effectiveness of the outcome per unit of time. However, in the case of unplanned adaptation, a causal inference may not be achieved due to endogeneity. One of the implementation outcome measures in the case study is the number of patients successfully completing treatment with the opioid reassessment clinic. The adaptation in this case involves hiring a new addiction specialist on site with specialty in tapering. Implications of the adaptation involve added salary for the new specialist, in addition to more time consulting and coordinating care with more patients. The additional implementation costs could be assessed in relevance to the increased rate of outcome per unit time. If this adaptation is planned, a causal inference may be achieved with random assignment of the adaptation."
        },
        {
            "heading": "Economic approaches to\u00a0costing adaptations",
            "text": "Adaptations occur across a continuum of implementation study designs, ranging from trials testing adapted versions of the EBP to studies that allow for local adaptations during the implementation process, with the potential for an infinite number of versions of the original EBP. Herein, we discuss various economic approaches to costing adaptations, namely micro-costing, time-based activity costing, minimal intervention needed for change, and simulation modeling."
        },
        {
            "heading": "Micro\u2011costing approaches",
            "text": "At one end of this continuum, micro-costing approaches have been applied in research that integrates adaptation of EBPs and implementation strategies at the planning stage using innovative study designs, such as the multiphase optimization strategy trial (MOST) design [29]. An adaptive implementation strategy can consist of several discrete strategies delivered in sequence and in different combinations. In adaptive implementation strategies, the type and dose of implementation strategy delivered to a site may be tailored in direct response to levels of adoption of EBPs observed among specific sites. Tailoring of implementation strategies could be based on circumstances that may not be observable at baseline. In one example, Collins and colleagues evaluated multiple intervention components for a smoking cessation trial with a MOST design [30]. The study used a phase-based approach to guide the choice of intervention components and outcome measures through randomized experimentation, while using the MOST framework to ensure that the intervention was not only effective, but also efficient and scalable. Matching implementation strategies to clinical context can be viewed as an optimization problem,\nTa bl\ne 2\nEx am\npl e\nof c\nos tin\ng ad\nap ta\ntio ns\no rg\nan iz\ned b\ny th\ne RE\n-A IM\nfr am\new or\nk\nO RC\no pi\noi d\nre as\nse ss\nm en\nt c lin\nic , L\nTO T\nlo ng\n-t er\nm o\npi oi\nd tr\nea tm\nen t\nRE -A\nIM d\nom ai\nn O\nut co\nm e\nA da\npt at\nio n\nCo st\nre le\nva nc\ne im\npl ic\nat io\nns o f ad ap ta tio n\nCo ns\nid er\nat io\nns fo\nr c os\nt a na\nly si\ns Pl\nan ne\nd vs\n. u np\nla nn\ned\nRe ac\nh N\num be\nr o f p\nat ie\nnt s\nw ith\na t l\nea st\non\ne O\nRC a\npp oi\nnt m\nen t\nEx pa\nnd in\ng el\nig ib\nili ty\nc rit\ner ia\nfo r\nO RC\ns er\nvi ce\ns Ti\nm e/\nre so\nur ce\ns re\nqu ire\nd fo\nr s er vin g ad di tio na l p at ie nt s\nIn te\nrr up\nte d\ntim e\nse rie\ns co\nul d\nex am\nin e\nco st\no f n\new p\nol ic\ny on\npa\ntie nt\nre ac\nh\nU np\nla nn\ned . C\nau sa\nl i nf\ner en\nce m\nay\nno t b\ne ac\nhi ev\ned d\nue to\ne nd\nog en eity\nEff ec\ntiv en\nes s\nN um\nbe r o\nf p at\nie nt\ns on\nh ig hris k LT O T tr an si tio ne d to s af er re gi m en s\nN ew\nin iti\nat iv\ne at\ns ite\nre qu\nire s\nre gu\nla r m\non ito\nrin g\nof p\nat ie\nnt s\ntr an\nsf er\nre d\nto s\naf er\nre gi\nm en\ns\nTi m\ne/ re\nso ur\nce s\nre qu\nire d\nfo r\nm on\nito rin\ng pa\ntie nt\ns po\nst la\nun ch\nof\nth e\nin iti\nat iv\ne\nIn te\nrr up\nte d\ntim e\nse rie\ns co\nul d\nex am\nin e\nco st\no f a\nda pt\nat io\nn on\neff\nec tiv\nen es\ns pe\nr t im\ne un\nit\nU np\nla nn\ned . C\nau sa\nl i nf\ner en\nce m\nay\nno t b\ne ac\nhi ev\ned d\nue to\ne nd\nog en eity\nA do\npt io\nn N\num be\nr o f p\nro vi\nde rs\nre fe\nrr in g pa tie nt s fo r o pi oi d re as se ss\nm en\nt N\new d\nas hb\noa rd\nfo r P\nC Ps\nto\nde te\nrm in\ne pa\ntie nt\ns pr\nere\nqu is\nite s\nfo r O\nRC\nSt ar\ntup\nc os\nts fo\nr d as\nhb oa\nrd\nde ve\nlo pm\nen t a\nlo ng\nw /\ntr ai\nni ng\nin\nth e\nus e\nof d\nas hb\noa rd\nTh e\nad di\ntio na\nl i m\npl em\nen ta\ntio n\nco st\ns co\nul d\nbe a\nss es\nse d\nin re lev an ce to o ut co m e of in te re st\nU np\nla nn\ned . C\nau sa\nl i nf\ner en\nce m\nay\nno t b\ne ac\nhi ev\ned d\nue to\ne nd\nog en eity\nIm pl\nem en\nta tio\nn N\num be\nr o f p\nat ie\nnt s\nse en\nb y\nO RC\nTe le\n-O RC\nte st\ned a\nt r an\ndo m\ns ite s du e to C O VI D\nSt ar\ntup\nc os\nts fo\nr t ra\nin in\ng on\nT el eO RC a nd c oo rd in at io n. C ha ng es in pa tie nt h ea lth c ar e ut ili za tio n du e to te le -h ea lth d el iv er y\nSe ns\niti vi\nty a\nna ly\nsi s\nco ul\nd sh\now\nco st\nd iff\ner en\ntia ls\nin th\nes e\nde liv\ner y\nm et\nho ds\nPl an\nne d.\nC au\nsa l i\nnf er\nen ce\nm ay\nb e\nac hi\nev ed\nw ith\nra nd\nom a\nss ig\nnm en\nt\nN um\nbe r o\nf p at\nie nt\ns su\ncc es\nsf ul\nly\nco m\npl et\nin g\ntr ea\ntm en\nt w ith\nO RC\nN ew\na dd\nic tio\nn sp\nec ia\nlis t h\nire d\non\nsi te\nw /\nsp ec\nia lty\nin ta\npe rin\ng Sa\nla ry\na dd\niti on\nfo r n\new s\npe ci\nal -\nis t o\nn th\ne im\npl em\nen ta\ntio n\nte am . M or e tim e co ns ul tin g/ co or di na tin g ca re w / m or e pa tie nt s\nTh e\nad di\ntio na\nl i m\npl em\nen ta - tio n co st s co ul d be a ss es se\nd in\nre\nle va\nnc e\nto in\ncr ea\nse d\nra te\no f\nou tc\nom e\npe r u\nni t t\nim e\nU np\nla nn\ned . C\nau sa\nl i nf\ner en\nce m\nay\nno t b\ne ac\nhi ev\ned d\nue to\ne nd\nog en eity\nM ai\nnt en\nan ce\nN um\nbe r o\nf p ro\nvi de\nrs re\nfe rr\nin g\npa tie\nnt s\nfo r o\npi oi\nd re\nas se\nss m\nen t\nan d\nco m\npl et\ned c\non su\nlts , a\nnd\nnu m\nbe r o\nf p at\nie nt\ns se\nen\nTe le\n-O RC\nm ai\nnt ai\nne d\ndu e\nto\nCO VI\nD a\nnd e\nxp an\nde d\nin a\ns te pw ed ge d fa sh io n to o th er s ite s\nA dd\niti on\nal s\nta rt\n-u p\nco st\ns fo\nr t ra\nin -\nin g\non T\nel e-\nO RC\na nd\nc oo\nrd in\nat io\nn.\nPa tie\nnt h\nea lth\nc ar\ne ut\nili za\ntio n\nco nt\nin ue\ns to\nd iff\ner d\nue to\nte le - he al th d el iv er y\nSe ns\niti vi\nty a\nna ly\nsi s\nco ul\nd sh\now\nco st\nd iff\ner en\ntia ls\nin th\nes e\nde liv\ner y\nm et\nho ds\nPl an\nne d.\nC au\nsa l i\nnf er\nen ce\nm ay\nb e\nac hi\nev ed\nd ue\nto ra\nnd om\na ss\nig n-\nm en\nt\nwhereby the objective is to determine the most costeffective approach to achieve the desired health outcome.\nThe sequential multiple assignment randomized trial One type of MOST used in optimizing decision rules of a time-varying adaptive intervention is the sequential multiple assignment randomized trial (SMART). A cluster randomized trial of community-based clinics with a SMART design evaluated a standard versus enhanced implementation strategy to improve outcomes of an EBP to treat mood disorders [31]. The trial evaluated implementation strategies of varying intensity, with a lowintensity strategy that includes EBP packaging, training, and technical assistance, followed by a medium-intensity strategy involving facilitation by external experts, and a high-intensity strategy involving internal facilitation with protected time for internal staff to support EBP implementation. Implementation strategies were evaluated for their cost-effectiveness through random assignment in three stages, whereby sites not responding to the implementation strategy in the previous stage were further randomized to receive a supplemental implementation strategy in the subsequent stage [22]. Findings suggested that the most cost-effective implementation support starts with a less intensive, less costly implementation strategy and increases as needed to enhance EBP uptake [22]. A SMART design is also being applied to the implementation of clinical guidelines for opioid prescribing in primary care settings, in which clinics are randomized to receive a sequence of implementation strategies that address implementation concerns at the health system, clinic, and provider levels [32]. This ongoing study aims to identify the most cost-effective sequence and combination of implementation strategies [32]."
        },
        {
            "heading": "Activity\u2011based costing approaches",
            "text": "Calculation of the expected value of specific implementation strategies and their adaptations requires determining the change in implementation levels and estimating the value of those changes. Comparing the value of such changes against their costs allows for the estimation of the expected value of the implementation strategies and adaptations. Empirical studies using micro-costing methods such as activity-based costing can inform decisionmakers about the opportunity costs of alternative health care interventions or strategies and how they change over time [33]. This involves tracking the inputs used to produce the EBP and multiplying the quantity of inputs by their input costs. The underlying assumption behind these methods is that the adaptation to improve implementation of the intervention results in a net health benefit from the intervention being tested. Such a gain\nin net health benefit is then compared with the cost of the implementation strategy to quantify whether it is an appropriate use of health care resources by estimating the value of implementation for a defined patient population and health care budget. Although relying on routinely generated data sources for analysis, such as electronic health record data, is preferrable due to its low burden, primary data collection may be necessary for measures that are not typically captured in existing data sources.\nThe example provided in Fig.\u00a0 3 outlines one method of measuring costs (while considering adaptations) with activity-based costing, but there are other types of microand macro-costing methods (e.g., cost-adjusted charges or total reimbursement, and gross-costing) that are discussed elsewhere [34]. Figure\u00a0 3 illustrates an approach for the measurement of input labor costs with the purpose of understanding the impact of adaptation on such costs. Although not included in this example for simplicity, other input costs (e.g., supplies, technology) may be considered as well. This hypothetical example considers the case of a planned adaptation within the context of a SMART design, whereby participants in one of the trial arms underwent a planned adaptation. Considering an activity-based costing dataset that is derived from a cost survey or log (panel A), the information is then summarized into an intermediate dataset with computed costs (panel B). In this stage, decision-makers will need to address potentially missing data from the activity logs. For example, the analysis should be informed by a plausible assumption for the mechanism behind the missing data (i.e., whether the likelihood that the data are missing is independent of or dependent upon the observed or unobserved values) [35]. The intermediate dataset is then transformed into a final analytic dataset for analysis, in which the costs attributable to the adaptation are derived as a distinct category based on the relevant activities (panel C). The variable costs in the adapted approach can be used to estimate the impact of the adaptation on health or system outcomes in determining the marginal benefit (or harm) based on the adaptation. In line with the concept of unplanned adaptations, this approach could also capture unplanned adaptations, by continuing to monitor input costs as local modifications arise. This approach could also be applied to retrospective studies, subject to the availability of input data. With retrospective data, it may be very difficult to use micro-costing if it is unclear when the adaptation took place and the effort that was expended before and after the adaptation. However, if retrospective micro-costing data already exist for an adaptation at a given site, these data may be invaluable when estimating costs to expand an adaptation to new sites and can be used as a tactic when approaching decision-makers.\nMinimal intervention needed for\u00a0change (MINC) approach One approach that has been recently introduced to optimize the delivery of EBPs is the concept of \u201cminimal intervention needed for change\u201d or MINC [36]. The goal of MINC is to provide a minimum standard for comparing low- vs. high-intensity EBPs to evaluate the relative improvements based on their relative costs. One question is as follows: how much more (or less) will the EBP cost with the adaptations and how do these changes influence the cost of EBP delivery or the implementation strategy? Not all adaptations are costly. Some adaptations involve recurring expenditures as opposed to new expenditures. Defining the core elements vs. the adaptable components of an EBP or implementation strategy is critical for the downstream economic evaluation of EBP delivery under different adaptation scenarios. Although MINC is a promising approach, its premise relies on introducing another comparison condition (i.e., the less intensive, less costly condition) that may or may not align with the required adaptation."
        },
        {
            "heading": "Simulation modeling approaches",
            "text": "In addition to economic evaluation based on empirical evidence, simulation modeling can be used to overcome limited follow-up in implementation studies. Common dynamic simulation modeling methods to inform the\nimplementation of EBPs in health care systems include system dynamics, discrete event simulation, and agentbased modeling [37]. These approaches to dynamic systems allow for considering the complexity of the system by modeling the upstream and downstream economic consequences of adaptations in complex health care systems. Simulation modeling enables decision-makers to evaluate scenarios outside of the observed norm, extend the time of observation, and strengthen and relax assumptions, which is typically not feasible in the real world. While it is inherently challenging to simulate downstream cost estimates over the long-term, overlaying simulations with probabilistic models of plausible health care disruptions (e.g., varying degrees of pandemic-related impacts) may provide more confidence in the standard error around the estimate.\nAlthough there are distinct advantages of simulation modeling over other economic evaluation models, these approaches can introduce challenges with respect to both analysis and interpretation. For instance, simulation models require extensive data that may not be available in the detail required by the model, especially when considering unintended economic consequences of an adaptation. However, although simulation models might require detailed or unavailable data, they are also able to account for this limitation in a way that other\nFig. 3 Measuring input costs to understand the effect of adaptation\nmodeling approaches are unable to. Simulation modeling can also present challenges for decision-makers \u2014 i.e., end users of such models. Given the additional complexity of such models, decision-makers may find them more difficult to comprehend, assess their validity, and interpret their findings. Although simulation modeling can be intimidating for some decision-makers, there is a strong evidence base to make such methods more accessible \u2014 e.g., through group model building and community-based system dynamics [38, 39]. These dynamic approaches allow for the costs and effects of the implementation strategy to improve implementation of an EBP across multiple time periods, whereas the traditional static approach assumes that the impact occurs entirely in a single time period. Varying marginal costs and benefits can be integrated into this approach by allowing for varying costs and benefits for the value of the EBP and of implementation strategies. Finally, even if simulations are not able to generate a precise point estimate, the simulations can generate a range of costs, and the bounds may provide sufficient information for decision-makers [40]."
        },
        {
            "heading": "Coincidence analysis as\u00a0an\u00a0alternative to\u00a0simulation modeling",
            "text": "One alternative method that has recently emerged to address the real-world complexity of dynamic implementation is coincidence analysis [41]. In coincidence analysis, researchers can apply an algorithm specifically designed for causal inference across entire datasets to identify specific combinations of components and conditions that consistently lead to improved outcomes, regardless of sample size [41]. However, one challenge with using coincidence analysis is that it requires the measures to be temporally aligned with the outcome, whereas downstream costs, by definition, are not temporally connected. Therefore, coincidence analysis may be useful to measure the costs of implementation strategies when the method used has sufficient precision to do so.\nAddressing uncertainty and\u00a0other considerations for\u00a0costing adaptations The results of any economic analysis contain inherent uncertainty due to the estimated nature of current inputs, other assumptions (e.g., the same observed benefits extend beyond the observation period), and predictions about the future. This uncertainty in economic modeling is exacerbated in the case of adaptation. Therefore, it is important for economic analysis of adaptation to include both scenario and sensitivity analyses [42]. The first source of uncertainty is related to the measures and assumptions that vary from the setting of the\noriginal trial as the intervention is implemented within a new site. Examples of measures that vary by setting include population characteristics, health system treatment patterns, and the disease prevalence within the health system. Scenario analysis is useful for this source of uncertainty. Local information should be used to inform alternative plausible scenarios by varying the value of these input measures. However, caution should be exercised to avoid the excessive use of assumptions rather than data and the inadequate characterization of uncertainty [43]. The second source of uncertainty is for the measures and other assumptions that are estimated with uncertainty regardless of the setting. This uncertainty could be due to changes in measures over the analysis time horizon and unpredictable future events. Sensitivity analysis is useful for this source of uncertainty. To the extent possible, the ranges of alternative values used for the sensitivity analysis should be based on observed variability in each measure, and information should be provided on how these ranges were derived. For example, the ranges used for effectiveness could be the 95% confidence limits from the original trial. For uncertain variables that lack observed data, expert opinion on likely ranges may be needed. When presenting results of the economic analysis, the base-case analysis results using single or default values for both the inputs known and unaffected by the adaptation and those for which there is uncertainty. Then, the alternative sets of results should be presented by changing the uncertain input measure one at a time or by changing a group of parameter values."
        },
        {
            "heading": "New estimation approaches are needed",
            "text": "One area where improved methods are needed is in estimating the economic consequences of the adaptation, compared with no adaptation, based on individual components of the EBP or implementation strategy. Using current micro-costing approaches, one would start with an estimate of the current EBP components without the adaptation under the original setting. However, producing projections of change in the effectiveness of various components once the adaptation is introduced would be based on assumptions or bestguess estimates. An additional assumption that is often made is that implementation capacity is equal across sites. Some adopting sites that have greater implementation capacity may be able to adapt more quickly or achieve superior outcomes. Guidance for methods to estimate the effect of adaptation on EBP or implementation strategy components would be useful. In addition to FRAME, FRAME-IS is a recent extension of the tool that can be used for documenting adaptations to implementation strategies [44]."
        },
        {
            "heading": "Conclusions",
            "text": "Economic evaluation of adaptations to EBP delivery is complex due to the multifaceted interactions involved, including various stakeholders, health care organizations, implementation processes, and technological innovations. Considering these challenges, researchers should strive to engage stakeholders in understanding the circumstances leading to the adaptation and its implications. As with any economic evaluation, clearly defining the problem and considering the appropriate perspective and time horizon are critical to guiding the purpose and scope of the evaluation. Mixed methods research guided by implementation science frameworks is important to establish the circumstances surrounding the adaptions and data availability. Next, researchers should consider the appropriateness of simulation modeling over traditional models for economic evaluation. Recently, the Professional Society for Health Economics and Outcomes Research (lSPOR) proposed a checklist to assist researchers and decision-makers in deciding whether simulation methods are appropriate to address specific health system problems [37]. The checklist can be used by health care delivery and implementation researchers, as well as decision-makers, in planning system interventions that address complex challenges in delivering effective and efficient care. Recent developments in implementation science and data science present opportunities to broaden and deepen our scientific understanding of the economics of adaptation. Beyond simulation modeling, additional checklists and reporting templates are available from ISPOR and other international standards organizations for applications in health economics and outcomes research to inform health care decision-making [45, 46].\nThe National Academy of Medicine has prioritized a paradigm shift towards a learning health care system, characterized by continuous learning and quality improvement with continuity in clinical data collection informing faster and more iterative adaptations [47]. This dynamic approach to evidence development and application integrates adaptative, contextually sensitive continuous quality improvement with the challenge of EBP sustainment [5]. Although a significant gap remains in achieving the goals of a learning health care system, progress will only be made if health systems can adapt to their evolving environments and the economic case for such adaptations can be demonstrated. Specifically, it is crucial to understand the differences between costing at baseline and real-world delivery. Further research on the economic implications of adaptations during the implementation process is necessary to improve EBP scaleup and sustainability.\nAbbreviations EBP: Evidence-based practice; FRAME: Framework for Reporting Adaptations and Modifications to Evidence-based interventions; MINC: Minimal intervention needed for change; MOST: Multiphase optimization strategy trial; SMART : Sequential multiple assignment randomized trial.\nAcknowledgements We would like to acknowledge the Economics and Implementation Science Workgroup for their formative input and internal review process. We especially thank Drs. Andria Eisman, Ties Hoomans, Heather Taffet Gold, and Gila Neta for their detailed, helpful comments on previous drafts. The views expressed in this article are those of the authors and do not represent the official positions of the National Cancer Institute or the Veterans Health Administration.\nAuthors\u2019 contributions RGS, THW, AMM, SID, AQ, and DAC conceived the paper, completed its drafting, and read and approved the final manuscript.\nFunding RGS was funded in part by the National Center for Advancing Translational Sciences (award number UL1TR001427).\nAvailability of data and materials This paper does not involve the use of specific data or materials."
        },
        {
            "heading": "Declarations",
            "text": "Ethics approval and consent to participate Not applicable.\nConsent for publication Not applicable.\nCompeting interests The authors declare that they have no competing interests.\nAuthor details 1 Department of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, 2004 Mowry Road, Room 2243, Gainesville, FL 32610, USA. 2 Palo Alto Health Economics Research Center, Department of Veterans Affairs, Menlo Park, CA, USA. 3 Department of Surgery, School of Medicine, Stanford University, Stanford, CA, USA. 4 Center for Innovation to Implementation, Palo Alto Health Care System, Department of Veterans Affairs, Menlo Park, CA, USA. 5 Department of Family Medicine and Community Health, School of Medicine, University of Wisconsin, Madison, WI, USA. 6 Division of Cancer Control and Population Sciences, National Cancer Institute, Rockville, MD, USA.\nReceived: 7 April 2022 Accepted: 15 September 2022\nReferences 1. Owens DK, Qaseem A, Chou R, Shekelle P. Clinical Guidelines Commit-\ntee of the American College of P: High-value, cost-conscious health care: concepts for clinicians to evaluate the benefits, harms, and costs of medical interventions. Ann Intern Med. 2011;154(3):174\u201380.\n2. Roberts SLE, Healey A, Sevdalis N. Use of health economic evaluation in the implementation and improvement science fields-a systematic literature review. Implement Sci. 2019;14(1):72. 3. Gold HT, McDermott C, Hoomans T, Wagner TH. Cost data in implementation science: categories and approaches to costing. Implement Sci. 2022;17(1):11. 4. Glasgow RE, Battaglia C, McCreight M, Ayele RA, Rabin BA. Making implementation science more rapid: use of the RE-AIM framework for mid-course adaptations across five health services research projects in the Veterans Health Administration. Front Public Health. 2020;8:194.\n5. Chambers DA, Glasgow RE, Stange KC. The dynamic sustainability framework: addressing the paradox of sustainment amid ongoing change. Implement Sci. 2013;8:117. 6. Stirman SW, Miller CJ, Toder K, Calloway A. Development of a framework and coding system for modifications and adaptations of evidence-based interventions. Implement Sci. 2013;8:65. 7. Escoffery C, Lebow-Skelley E, Haardoerfer R, Boing E, Udelson H, Wood R, et al. A systematic review of adaptations of evidence-based public health interventions globally. Implement Sci. 2018;13(1):125. 8. Evans RE, Moore G, Movsisyan A, Rehfuess E, Panel A. Arnold APcoL: How can we adapt complex population health interventions for new contexts? Progressing debates and research priorities. J Epidemiol Community Health. 2021;75(1):40\u20135. 9. Aarons GA, Green AE, Palinkas LA, Self-Brown S, Whitaker DJ, Lutzker JR, et al. Dynamic adaptation process to implement an evidence-based child maltreatment intervention. Implement Sci. 2012;7:32. 10. Rogers E. Diffusion of innovations fifth. New York: edition Free Press; 2003. 11. Charters WW, Pellegrin RJ. Barriers to the innovative process: Four case\nstudies of differentiated staffing. Educ Admin Q. 1973;9(1). 12. Leviton L, Henry B. Better information for generalizable knowledge: sys-\ntematic study of local adaptation. In: American Public Health Association 139th Annual Meeting and Exposition; 2011. p. 2011.\n13. Chambers DA, Norton WE. The adaptome: advancing the science of intervention adaptation. Am J Prev Med. 2016;51(4 Suppl 2):S124\u201331. 14. Sculpher M. Evaluating the cost-effectiveness of interventions designed to increase the utilization of evidence-based guidelines. Fam Pract. 2000;17(Suppl 1):S26\u201331. 15. Mason J, Freemantle N, Nazareth I, Eccles M, Haines A, Drummond M. When is it cost-effective to change the behavior of health professionals? JAMA. 2001;286(23):2988\u201392. 16. Whyte S, Dixon S, Faria R, Walker S, Palmer S, Sculpher M, et al. Estimating the cost-effectiveness of implementation: is sufficient evidence available? Value Health. 2016;19(2):138\u201344. 17. Mewes JC, Steuten LMG. C IJ, MJ IJ, van Harten WH: Value of implementation of strategies to increase the adherence of health professionals and cancer survivors to guideline-based physical exercise. Value Health. 2017;20(10):1336\u201344. 18. Wiltsey Stirman S, Baumann AA, Miller CJ. The FRAME: an expanded framework for reporting adaptations and modifications to evidencebased interventions. Implement Sci. 2019;14(1):58. 19. Scheirer MA. Linking sustainability research to intervention types. Am J Public Health. 2013;103(4):e73\u201380. 20. Moore G, Campbell M, Copeland L, Craig P, Movsisyan A, Hoddinott P, et al. Adapting interventions to new contexts-the ADAPT guidance. BMJ. 2021;374:n1679. 21. Dopp AR, Mundey P, Beasley LO, Silovsky JF, Eisenberg D. Mixed-method approaches to strengthen economic evaluations in implementation research. Implement Sci. 2019:14. 22. Eisman AB, Hutton DW, Prosser LA, Smith SN, Kilbourne AM. Costeffectiveness of the Adaptive Implementation of Effective Programs Trial (ADEPT): approaches to adopting implementation strategies. Implement Sci. 2020;15(1):109. 23. Wiltsey Stirman S, Gutner CA, Crits-Christoph P, Edmunds J, Evans AC, Beidas RS. Relationships between clinician-level attributes and fidelityconsistent and fidelity-inconsistent modifications to an evidence-based psychotherapy. Implement Sci. 2015;10:115. 24. Mauskopf JA, Sullivan SD, Annemans L, Caro J, Mullins CD, Nuijten M, et al. Principles of good practice for budget impact analysis: report of the ISPOR Task Force on good research practices--budget impact analysis. Value Health. 2007;10(5):336\u201347. 25. Jones Rhodes WC, Ritzwoller DP, Glasgow RE. Stakeholder perspectives on costs and resource expenditures: tools for addressing economic issues most relevant to patients, providers, and clinics. Transl Behav Med. 2018;8(5):675\u201382. 26. Philips Z, Claxton K, Palmer S. The half-life of truth: what are appropriate time horizons for research decisions? Med Decis Making. 2008;28(3):287\u201399. 27. Becker WC, Edmond SN, Cervone DJ, Manhapra A, Sellinger JJ, Moore BA, et al. Evaluation of an integrated, multidisciplinary program to address unsafe use of opioids prescribed for pain. Pain Med. 2018;19(7):1419\u201324.\n28. Glasgow RE, Vogt TM, Boles SM. Evaluating the public health impact of health promotion interventions: the RE-AIM framework. Am J Public Health. 1999;89(9):1322\u20137. 29. Collins LM, Murphy SA, Strecher V. The multiphase optimization strategy (MOST) and the sequential multiple assignment randomized trial (SMART): new methods for more potent eHealth interventions. Am J Prev Med. 2007;32(5):S112\u20138. 30. Collins LM, Baker TB, Mermelstein RJ, Piper ME, Jorenby DE, Smith SS, et al. The multiphase optimization strategy for engineering effective tobacco use interventions. Ann Behav Med. 2011;41(2):208\u201326. 31. Kilbourne AM, Almirall D, Eisenberg D, Waxmonsky J, Goodrich DE, Fortney JC, et al. Protocol: Adaptive Implementation of Effective Programs Trial (ADEPT): cluster randomized SMART trial comparing a standard versus enhanced implementation strategy to improve outcomes of a mood disorders program. Implement Sci. 2014;9:132. 32. Quanbeck A, Almirall D, Jacobson N, Brown RT, Landeck JK, Madden L, et al. The Balanced Opioid Initiative: protocol for a clustered, sequential, multiple-assignment randomized trial to construct an adaptive implementation strategy to improve guideline-concordant opioid prescribing in primary care. Implement Sci. 2020;15(1):26. 33. Wagner TH. Rethinking how we measure costs in implementation research. J Gen Intern Med. 2020;35(Suppl 2):870\u20134. 34. Lipscomb J, Yabroff KR, Brown ML, Lawrence W, Barnett PG. Health care costing: data, methods, current applications. Med Care. 2009;47(7 Suppl 1):S1\u20136. 35. Faria R, Gomes M, Epstein D, White IR. A guide to handling missing data in cost-effectiveness analysis conducted within randomised controlled trials. Pharmacoeconomics. 2014;32(12):1157\u201370. 36. Glasgow RE, Fisher L, Strycker LA, Hessler D, Toobert DJ, King DK, et al. Minimal intervention needed for change: definition, use, and value for improving health and health research. Transl Behav Med. 2014;4(1):26\u201333. 37. Marshall DA, Burgos-Liz L. MJ IJ, Osgood ND, Padula WV, Higashi MK, Wong PK, Pasupathy KS, Crown W: Applying dynamic simulation modeling methods in health care delivery research-the SIMULATE checklist: report of the ISPOR simulation modeling emerging good practices task force. Value Health. 2015;18(1):5\u201316. 38. Hovmand PS. Group model building and community-based system dynamics process. In: Community based system dynamics: Springer; 2014. p. 17\u201330. 39. Gerritsen S, Harre S, Rees D, Renker-Darby A, Bartos AE, Waterlander WE, et al. Community group model building as a method for engaging participants and mobilising action in public health. Int J Environ Res Public Health. 2020;17(10). 40. Mullahy J, Venkataramani A, Millimet DL, Manski CF. Embracing uncertainty: the value of partial identification in public health and clinical research. Am J Prev Med. 2021;61(2):e103\u20138. 41. Whitaker RG, Sperber N, Baumgartner M, Thiem A, Cragun D, Damschroder L, et al. Coincidence analysis: a new method for causal inference in implementation science. Implement Sci. 2020;15(1):108. 42. Sullivan SD, Mauskopf JA, Augustovski F, Jaime Caro J, Lee KM, Minchin M, et al. Budget impact analysis-principles of good practice: report of the ISPOR 2012 Budget Impact Analysis Good Practice II Task Force. Value Health. 2014;17(1):5\u201314. 43. Drummond M, Sculpher M. Common methodological flaws in economic evaluations. Med Care. 2005;43(7 Suppl):5\u201314. 44. Miller CJ, Barnett ML, Baumann AA, Gutner CA, Wiltsey-Stirman S. The FRAME-IS: a framework for documenting modifications to implementation strategies in healthcare. Implement Sci. 2021;16(1):36. 45. Society for Medical Decision Making. Modeling Good Research Practices Task Force [https:// smdm. org/ hub/ page/ model ing- good- resea rch- pract ices- task- force/ publi catio ns] 46. ISPOR. Good practices reports & more [https:// www. ispor. org/ heor- resou rces/ good- pract ices] 47. Olsen L, Aisner D, McGinnis JM. Institute of Medicine (US). Roundtable on Evidence-Based Medicine. The learning healthcare system: workshop summary. Washington National Academies Pr. 2007."
        },
        {
            "heading": "Publisher\u2019s Note",
            "text": "Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations."
        }
    ],
    "title": "The economics of adaptations to evidence-based practices",
    "year": 2022
}