{
    "abstractText": "The Artemis program requires robotic and crewed lunar rovers for resource prospecting and exploitation, construction and maintenance of facilities, and human exploration. These rovers must support navigation for 10s of kilometers (km) from base camps. A lunar science rover mission concept (\u201cEndurance-A\u201d) has been recommended by the new Decadal Survey as the highest priority medium-class mission of the Lunar Discovery and Exploration Program, and would be required to traverse approximately 2000 km in the South PoleAitkin (SPA) Basin, with individual drives of several kilometers between stops for downlink. These rover mission scenarios require functionality that provides onboard, autonomous, global position knowledge (\u201cabsolute localization\u201d). However, planetary rovers have no onboard global localization capability to date; they have only used relative localization, by integrating combinations of wheel odometry, visual odometry, and inertial measurements during each drive to track position relative to the start of each drive. At the end of each drive, a \u201cground-inthe-loop\u201d (GITL) interaction is used to get an absolute position update from human operators in a more global reference frame. As a result, autonomous rover drives are limited in distance so that accumulated relative navigation error does not risk the possibility of the rover driving into a \u201ckeep-out zone\u201d; in practice, drive limits of a few hundred meters are to be expected. In this work, we summarize recent developments from the LunarNav project, where we have developed algorithms and software to enable lunar rovers to estimate their global position and heading on the Moon with a goal performance of position error less than 5 meters (m) and heading error less than 3\u25e6, 3\u03c3, in sunlit areas. This new capability will eliminate the need for GITL interactions with human operators for lunar rover global position estimation, which will substantially increase operational productivity of lunar rovers and will reduce operations costs. This will be achieved autonomously onboard by detecting craters in the vicinity of the rover and matching them to a database of known craters mapped from orbit. The overall technical framework consists of three main elements: 1) crater detection, 2) crater matching, and 3) state estimation. In previous work, we developed crater detection algorithms for three different sensing modalities. This paper builds on that work, and focuses on the crater matching and state estimation aspects of the problem. In particular, we developed two algorithms for crater-based localization, and demonstrated them on datasets of both real and simulated lunar data, in representative environments. Our results suggest that rover localization with an error less than 5 m is highly probable during daytime operations. 978-1-6654-9032-0/23/$31.00 \u00a92023 IEEE TABLE OF CONTENTS",
    "authors": [
        {
            "affiliations": [],
            "name": "Shreyansh Daftry"
        },
        {
            "affiliations": [],
            "name": "Zhanlin Chen"
        },
        {
            "affiliations": [],
            "name": "Yang Cheng"
        },
        {
            "affiliations": [],
            "name": "Scott Tepsuporn"
        },
        {
            "affiliations": [],
            "name": "Shehryar Khattak"
        },
        {
            "affiliations": [],
            "name": "Brian Coltin"
        },
        {
            "affiliations": [],
            "name": "Ussama Naal"
        },
        {
            "affiliations": [],
            "name": "Lanssie Mingyue Ma"
        }
    ],
    "id": "SP:8a7fb48cc572a3e0f676da041fcfa7b5b5b15c69",
    "references": [
        {
            "authors": [
                "J.O. Elliott",
                "M. Robinson"
            ],
            "title": "Intrepid planetary mission concept overview",
            "venue": "2020.",
            "year": 2020
        },
        {
            "authors": [
                "J. Heldman"
            ],
            "title": "Inspire: a mission concept study from the decadal survey for planetary science and astrobiology: 2022-2023",
            "venue": "Lunar Exploration Analysis Group meeting, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "J.T. Keane"
            ],
            "title": "Endurance: lunar south pole-aitken basin traverse and sample return rover",
            "venue": "Lunar Exploration Analysis Group meeting, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "L. Matthies",
                "S. Daftry",
                "S. Tepsuporn",
                "Y. Cheng",
                "D. Atha",
                "R.M. Swan",
                "S. Ravichandar",
                "M. Ono"
            ],
            "title": "Lunar rover localization using craters as landmarks",
            "venue": "arXiv preprint arXiv:2203.10073, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "M. Robinson",
                "S. Team"
            ],
            "title": "Shadowcam: Seeing in the shadows",
            "venue": "Lunar Polar Volatiles, vol. 2087, p. 5028, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "A. Cauligi",
                "R.M. Swan",
                "M. Ono",
                "S. Daftry",
                "J. Elliott",
                "L. Matthies",
                "D. Atha"
            ],
            "title": "Shadownav: Crater-based localization for nighttime and permanently shadowed region lunar navigation",
            "venue": "IEEE Aerospace Conference, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "T. Parker",
                "M. Golombek",
                "M. Powell"
            ],
            "title": "Geomorphic/geologic mapping, localization, and traverse planning at the opportunity landing site, mars",
            "venue": "Lunar and Planetary Science Conference, no. 1533, 2010, p. 2638.",
            "year": 2010
        },
        {
            "authors": [
                "D. Gaines",
                "G. Doran",
                "M. Paton",
                "B. Rothrock",
                "J. Russino",
                "R. Mackey",
                "R. Anderson",
                "R. Francis",
                "C. Joswig",
                "H. Justice"
            ],
            "title": "Self-reliant rovers for increased mission productivity",
            "venue": "Journal of Field Robotics, vol. 37, no. 7, pp. 1171\u20131196, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Chiodini",
                "M. Pertile",
                "S. Debei",
                "L. Bramante",
                "E. Ferrentino",
                "A.G. Villa",
                "I. Musso",
                "M. Barrera"
            ],
            "title": "Mars rovers localization by matching local horizon to surface digital elevation models",
            "venue": "2017 IEEE International Workshop on Metrology for AeroSpace (MetroAeroSpace). IEEE, 2017, pp. 374\u2013379.",
            "year": 2017
        },
        {
            "authors": [
                "P. Yang",
                "L. Xie",
                "J. Liu"
            ],
            "title": "Simultaneous celestial positioning and orientation for the lunar rover",
            "venue": "Aerospace Science and Technology, vol. 34, pp. 45\u201354, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "D.T. Chelmins",
                "B.W. Welch",
                "O.S. Sands",
                "B.V. Nguyen"
            ],
            "title": "A kalman approach to lunar surface navigation using radiometric and inertial measurements",
            "venue": "2009.",
            "year": 2009
        },
        {
            "authors": [
                "C. Yang",
                "H. Zhao",
                "L. Bruzzone",
                "J.A. Benediktsson",
                "Y. Liang",
                "B. Liu",
                "X. Zeng",
                "R. Guan",
                "C. Li",
                "Z. Ouyang"
            ],
            "title": "Lunar impact crater identification and age estimation with chang\u2019e data by deep and transfer learning",
            "venue": "Nature Communications, vol. 11, no. 1, pp. 1\u201315, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Cheng",
                "A.E. Johnson",
                "L.H. Matthies",
                "C.F. Olson"
            ],
            "title": "Optical landmark detection for spacecraft navigation",
            "venue": "2003.",
            "year": 2003
        },
        {
            "authors": [
                "S. Thrun"
            ],
            "title": "Probabilistic robotics",
            "venue": "Communications of the ACM, vol. 45, no. 3, pp. 52\u201357, 2002.",
            "year": 2002
        },
        {
            "authors": [
                "M.A. Cornejo-Lupa",
                "R.P. Ticona-Herrera",
                "Y. Cardinale",
                "D. Barrios-Aranibar"
            ],
            "title": "A survey of ontologies for simultaneous localization and mapping in mobile robots",
            "venue": "ACM Computing Surveys (CSUR), vol. 53, no. 5, pp. 1\u201326, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "D.A. Minton",
                "C.I. Fassett",
                "M. Hirabayashi",
                "B.A. Howl",
                "J.E. Richardson"
            ],
            "title": "The equilibrium size-frequency distribution of small craters reveals the effects of distal ejecta on lunar landscape morphology",
            "venue": "Icarus, vol. 326, pp. 63\u201387, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "A. Rankin",
                "M. Maimone",
                "J. Biesiadecki",
                "N. Patel",
                "D. Levine",
                "O. Toupet"
            ],
            "title": "Mars curiosity rover mobility trends during the first 7 years",
            "venue": "Journal of Field Robotics, vol. 38, no. 5, pp. 759\u2013800, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "M. Allan",
                "U. Wong",
                "P.M. Furlong",
                "A. Rogg",
                "S. McMichael",
                "T. Welsh",
                "I. Chen",
                "S. Peters",
                "B. Gerkey",
                "M. Quigley"
            ],
            "title": "Planetary rover simulation for lunar exploration missions",
            "venue": "2019 IEEE Aerospace Conference. IEEE, 2019, pp. 1\u201319.",
            "year": 2019
        },
        {
            "authors": [
                "C. Aiazzi",
                "A. Jain",
                "A. Gaut",
                "A. Young",
                "A. Elmquist"
            ],
            "title": "Iris: High-fidelity perception sensor modeling for closed-loop planetary simulations",
            "venue": "AIAA SCITECH 2022 Forum, 2022, p. 1433.",
            "year": 2022
        },
        {
            "authors": [
                "B.W. Hapke"
            ],
            "title": "A theoretical photometric function for the lunar surface",
            "venue": "Journal of Geophysical Research, vol. 68, no. 15, pp. 4571\u20134586, 1963.",
            "year": 1963
        },
        {
            "authors": [
                "B. Hapke"
            ],
            "title": "Bidirectional reflectance spectroscopy: 1. theory",
            "venue": "Journal of Geophysical Research: Solid Earth, vol. 86, no. B4, pp. 3039\u20133054, 1981.",
            "year": 1981
        },
        {
            "authors": [
                "B.W. Hapke",
                "R.M. Nelson",
                "W.D. Smythe"
            ],
            "title": "The opposition effect of the moon: the contribution of coherent backscatter",
            "venue": "Science, vol. 260, no. 5107, pp. 509\u2013 511, 1993.",
            "year": 1993
        },
        {
            "authors": [
                "A. Colaprete",
                "D. Andrews",
                "W. Bluethmann",
                "R.C. Elphic",
                "B. Bussey",
                "J. Trimble",
                "K. Zacny",
                "J.E. Captain"
            ],
            "title": "An overview of the volatiles investigating polar exploration rover (viper) mission",
            "venue": "AGU Fall Meeting Abstracts, vol. 2019, 2019, pp. P34B\u201303.",
            "year": 2019
        },
        {
            "authors": [
                "C. Li",
                "J. Liu",
                "X. Ren",
                "W. Zuo",
                "X. Tan",
                "W. Wen",
                "H. Li",
                "L. Mu",
                "Y. Su",
                "H. Zhang"
            ],
            "title": "The chang\u2019e 3 mission overview",
            "venue": "Space Science Reviews, vol. 190, no. 1, pp. 85\u2013101, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "C. Li",
                "W. Zuo",
                "W. Wen",
                "X. Zeng",
                "X. Gao",
                "Y. Liu",
                "Q. Fu",
                "Z. Zhang",
                "Y. Su",
                "X. Ren"
            ],
            "title": "Overview of the chang\u2019e-4 mission: Opening the frontier of scientific exploration of the lunar far side",
            "venue": "Space Science Reviews, vol. 217, no. 2, pp. 1\u201332, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S.B. Goldberg",
                "M.W. Maimone",
                "L. Matthies"
            ],
            "title": "Stereo vision and rover navigation software for planetary exploration",
            "venue": "Proceedings, IEEE aerospace conference, vol. 5. IEEE, 2002, pp. 5\u20135.",
            "year": 2002
        },
        {
            "authors": [
                "S. Thrun"
            ],
            "title": "Particle filters in robotics.",
            "venue": "UAI, vol. 2. Citeseer,",
            "year": 2002
        },
        {
            "authors": [
                "D. Fox",
                "S. Thrun",
                "W. Burgard",
                "F. Dellaert"
            ],
            "title": "Particle filters for mobile robot localization",
            "venue": "Sequential Monte Carlo methods in practice. Springer, 2001, pp. 401\u2013428.",
            "year": 2001
        },
        {
            "authors": [
                "H. Rezatofighi",
                "N. Tsoi",
                "J. Gwak",
                "A. Sadeghian",
                "I. Reid",
                "S. Savarese"
            ],
            "title": "Generalized intersection over union: A metric and a loss for bounding box regression",
            "venue": "Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2019, pp. 658\u2013666.",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "In this work, we summarize recent developments from the LunarNav project, where we have developed algorithms and software to enable lunar rovers to estimate their global position and heading on the Moon with a goal performance of position error less than 5 meters (m) and heading error less than 3\u25e6, 3\u03c3, in sunlit areas. This new capability will eliminate the need for GITL interactions with human operators for lunar rover global position estimation, which will substantially increase operational productivity of lunar rovers and will reduce operations costs. This will be achieved autonomously onboard by detecting craters in the vicinity of the rover and matching them to a database of known craters mapped from orbit. The overall technical framework consists of three main elements: 1) crater detection, 2) crater matching, and 3) state estimation. In previous work, we developed crater detection algorithms for three different sensing modalities. This paper builds on that work, and focuses on the crater matching and state estimation aspects of the problem. In particular, we developed two algorithms for crater-based localization, and demonstrated them on datasets of both real and simulated lunar data, in representative environments. Our results suggest that rover localization with an error less than 5 m is highly probable during daytime operations.\n978-1-6654-9032-0/23/$31.00 \u00a92023 IEEE\nTABLE OF CONTENTS"
        },
        {
            "heading": "1. INTRODUCTION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1",
            "text": ""
        },
        {
            "heading": "2. RELATED WORK . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2",
            "text": ""
        },
        {
            "heading": "3. SYSTEM OVERVIEW . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2",
            "text": ""
        },
        {
            "heading": "4. REAL AND SIMULATED DATASETS . . . . . . . . . . . . . . . 4",
            "text": ""
        },
        {
            "heading": "5. TECHNICAL APPROACH . . . . . . . . . . . . . . . . . . . . . . . . . . 8",
            "text": ""
        },
        {
            "heading": "6. PERFORMANCE EVALUATION . . . . . . . . . . . . . . . . . . . . 10",
            "text": ""
        },
        {
            "heading": "7. DISCUSSION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10",
            "text": "ACKNOWLEDGMENTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 REFERENCES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 BIOGRAPHY . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15"
        },
        {
            "heading": "1. INTRODUCTION",
            "text": "Long-range, autonomous lunar rover mobility is expected to be part of human exploration and robotic science missions to the Moon in the next decade and beyond. Multiple whitepapers and mission concept studies [1], [2], [3], [4], [5] that addressed science that could be done with robotic lunar rovers were submitted to the recent Planetary Science and Astrobiology Decadal Survey (PSADS). The final report from PSADS [6] recommended a long-range lunar rover mission concept called \u201cEndurance-A\u201d as the highest priority medium-class mission for the Moon in the next decade. This mission concept would traverse \u223c2000 km in the South Pole Aitken (SPA) basin to collect \u223c100 kg of samples, which would be returned to Earth by astronauts. NASA\u2019s Artemis program for returning astronauts to the Moon includes a concept for a Lunar Terrain Vehicle (LTV) that would transport astronauts over distances of up to 20 km without having to stop to recharge batteries and would be capable of operation remotely when astronauts are not present [7]. These rover concepts would drive quickly compared to prior rovers: up to 30 cm/s for robotic science rovers and probably much faster for an LTV. They would also cover several kilometers (km) per autonomous rover drive, compared to at most a few hundred meters per drive for prior robotic science rovers.\nAll of these lunar rover mission concepts would require knowledge of the rover\u2019s position in a global reference frame. Since they would operate far beyond line-of-sight from a lander, they would need to obtain position knowledge independently from the lander need to obtain position knowledge from means other than navigation aiding from a lander. The accuracy needed for rover global position knowledge is debatable, but on the order of 10 m is desirable for confidence\nar X\niv :2\n30 1.\n01 35\n0v 1\n[ cs\n.R O\n] 3\nJ an\n2 02\nthat a rover will not stray into known hazards during long periods of autonomous driving with no contact with human operators.\nPlanetary rovers to date have all used onboard dead reckoning for position estimation relative to the start of each day\u2019s drive, with global position updates obtained with the aid of humans using rover images transmitted to Earth. This would not support these lunar rover mission concepts, because of unacceptably high requirements for communication with Earth and for support from human operators on Earth. Several methods of onboard position estimation have been studied, as reviewed in [8]: recognizing horizon landmarks, registering local elevation maps created onboard with elevation maps created from orbit, radio frequency navigation aiding from one or more orbiters, and celestial navigation using measured vectors to the Sun, the Earth, and the Moon\u2019s core. These methods have a variety of limitations, including position error often on the order of 100 m or more, limited availability of sufficiently high-resolution elevation maps from orbit, and relatively long periods when orbiter(s) are not overhead to provide RF navigation aiding.\nAn alternative approach is to use craters as landmarks, with the rover automatically detecting craters in its vicinity and matching them to known craters in a landmark database created from orbital imagery. This approach has the advantage that almost all sunlit areas of the Moon have been imaged from orbit with enough resolution (\u223c 0.5 m/pixel) to enable mapping crater landmarks as small as 5 to 10 m in diameter; moreover, the ShadowCam camera [9] on the Korean Pathfinder Lunar Orbiter is expected to map permanently shadowed regions with a resolution of \u223c 1.7 m/pixel, which could enable mapping crater landmarks with diameters of 10 to 20 m. This approach to lunar rover localization was introduced in [8], which described and evaluated algorithms for detecting craters in the vicinity of a rover with point cloud data from onboard lidar or stereo cameras, and/or with neural net-based pattern recognition in monocular images. Here, we build on that work by presenting methods to match such onboard crater detections to craters in the landmark database and to update rover global position estimates with a sequence of such detections as the rover moves. A related paper focuses on crater-based localization in the dark and for permanently shadowed regions [10]\nThe rest of the paper is organized as follows: Section 2 discusses related work. Section 3 describes LunarNav\u2019s overall crater-based localization system concept. Section 4 describes data sets of real and synthetic images obtained for this work. Section 5 describes the technical approach and two algorithms developed for the crater-based localization. Results of quantitative performance evaluation for both algorithms using multiple sensing modalities are shown in Section 6. These results show this approach to be very promising for achieving the goal of rover localization on the lunar surface, with an error less than 5m during daytime operations. Section 7 summarizes the results and outlines planned future work."
        },
        {
            "heading": "2. RELATED WORK",
            "text": "Methods for lunar rover localization were surveyed in [8]; here we give a brief recap of prior and an update on recent related work. As noted in [8], applicable methods fall into several classes:\n\u2022 Registering onboard image or local map data to orbital images or maps\n\u2022 Using horizon features as landmarks \u2022 Celestial measurements, potentially combined with other\nmeasurements, such as accurate gravity vector measurements\n\u2022 Radiometric ranging from lunar orbit or Earth tracking stations\nTransferring rover images to Earth for human operators to register them to orbital images has been the standard approach for Mars rover localization of Mars rovers [11]; this can achieve accuracy on the scale of the resolution of the orbital images, which is sub-meter scale for Mars and the Moon. This is more difficult to do when the sun angle varies as much as it would in lunar rover missions, especially given the high-contrast shadows on the Moon. This motivates using craters as landmarks, because these can be detected reliability independently of sun angle. Algorithms to register local elevation maps created onboard to elevation maps created with orbital imagery are described in [12]. A limitation of this approach for the Moon is that it requires high resolution stereo imaging from orbit of the entire rover traverse, which is not currently available.\nThe accuracy of localization methods based on horizon features depends on the terrain relief, distance to the horizon features, and resolution of the associated elevation map; in favorable situations this can give errors < 50 m [13], but this is not always available. Simulations of celestial navigation methods show 1\u03c3 errors on the order of 100 m [14]. In principle, radio ranging between the rover and either a lunar orbiter or Earth tracking stations can give meter-scale position knowledge [15]; however, the orbiter infrastructure needed for this is not in place and this would not provide instant position updates or continuous service.\nAutomatic crater detection in orbital images has been done to determine crater statistics for scientific purposes [16] and to estimate the position of landers during descent to highly craters asteroids [17]. Crater detection for lunar rover localization was introduced in [8]. Using landmarks like this for localization over long distances requires methods to reliably correspond craters detected onboard with craters in the landmark databased, despite errors in both onboard crater detection and the orbital landmark map. The large literature on \u201cSimultaneous Localization and Mapping\u201d (SLAM) is applicable to this problem, and includes methods such as particle filters and incremental batch optimization with crater detection [18], [19]. These methods currently appear to be the most promising approach to achieving lunar rover global localization with the required accuracy and update frequency."
        },
        {
            "heading": "3. SYSTEM OVERVIEW",
            "text": "System Concept\nThe LunarNav system concept requires creating a database of crater landmarks from orbital images, as shown in Figure 1. This database would contain the position, diameter, and estimated depth of each crater. Craters with diameters > 5 meters are mappable with LRO-NAC imagery, under most orbital imaging conditions. Even in the youngest terrain on the Moon, such craters occur with a frequency > 103 per km2, or on average about 30 meters apart, and they occur\nmore frequently in older terrain [20], [21]. This would provide frequent landmarks that should be detectable at distances of roughly 10 to 20 meters from the rover.\nRobotic lunar rovers will carry a sensor suite for relative localization and obstacle detection that includes wheel odometry, an IMU, either stereo cameras or a lidar, and either a sun sensor or a star camera for absolute heading measurement. Assuming the availability of a star camera, which is applicable for driving in sunlight and in shadow, gives 3-axis attitude knowledge to a small fraction of a degree. With this, the relative navigation sensor suite enables dead-reckoning with position error that typically can be < 2% of distance traveled. This provides a prior estimate of position that at all times strongly constrains which crater(s) from the landmark database are expected to be near the rover. Craters can then be detected near the rover with a combination of 3D point cloud data from stereo cameras or a lidar, image data from a camera, or reflectance image data from a lidar. This enables detecting craters with diameters roughly between 5 to 20 meters whose near rims are roughly less than 20 meters from the rover.\nOverall, these methods should enable reliable absolute localization; given typical resolution characteristics of cameras, stereo vision, and lidar, we estimate that it should be possible to maintain a rover absolute position estimate with 3\u03c3 error< 5 meters at all times. Furthermore, in terms of computational feasibility, crater-based localization is less expensive than\nobstacle detection and needs to be done much less frequently than obstacle detection, so any onboard computing system that can do obstacle detection would also be able to do craterbased localization.\nKey Performance Parameters\nThorough performance evaluation of the LunarNav framework was a function of many parameters, and depended fundamentally on the ability to detect and localize individual craters and to estimate their positions and diameters. This depends on (1) crater size and distance from the rover, (2) rover camera/lidar sensor parameters, including angular resolution, range resolution, field of view, and sensor height above the ground, (3) lighting conditions, and (4) other characteristics of terrain geometry, like slope. We distilled key performance parameters (KPPs) in terms of the crater distribution, as defined in Table 1 and anticipated that craters with diameters > 5 meters will be readily detectable from distances of at least 15 meters, in many but not necessarily all lighting conditions. For example, detection probability (Pd) of 0.5 for 5 m craters at 15 m range should be a conservative estimate. With a notional stereo camera system with angular resolution of 1 milliradian/pixel and binocular camera baseline of 30 cm, 3 \u03c3 errors in estimating the position and diameter of such craters should be < 2 m each.\nUpdates to rover position and heading will be obtained every\ntime an onboard crater map is registered to the orbital map. The precision of these rover position and heading estimates will be a function of the precision of crater positions and diameters in the onboard map, as well as detection and false alarm probabilities (Pd and Pf ) for onboard crater recognition. Quality of the onboard map will also depend on accuracy and precision of heading estimation and dead reckoning between crater detections. Past experience suggests that dead reckoned position error can be better than 2% of distance traveled with visual odometry (2 m per 100 m) [22]. Rover heading error should be bounded by about 5\u25e6 by a sun sensor, < 1\u25e6 per 100 m using visual odometry, or< 0.01\u25e6 at all times using a star camera. A star camera is the preferred heading estimation solution for performance, but a sun sensor may offer a lower cost solution with adequate performance for predominantly sunlit scenarios. Combining this with errors in crater center positions relative to the rover and crater position errors of < 2 m in the orbital map should enable rover position and heading estimation error to be conservatively bounded by about 10 m and 5\u25e6 at all times. Erroneous crater detections (false alarms) will be filtered out through a combination of several techniques applied at different stages of the estimation pipeline. Since the effect of false detections is ultimately captured in rover position estimation error, a separate key performance parameter is not specified for false alarms. Performance modeling and evaluation throughout the course of the project characterized how performance varies as a function of these sensor parameters (See Section 6)."
        },
        {
            "heading": "4. REAL AND SIMULATED DATASETS",
            "text": "We used both real and simulated sensor data to develop and evaluate the performance of lunar rover navigation with crater landmarks. Simulated data allowed testing with larger data sets and over wider ranges of illumination conditions than are practical with real data. For generating synthetic lunar surface images, three different simulation tools were initially considered: (1) RSIM - a simulator implemented in the Gazebo environment at NASA Ames [23], (2) a lunar surface simulation environment under development in JPL\u2019s DARTS lab to support the STMD/GCD \u201cCADRE\u201d task and other applications [24], and (3) an open-source Blender based computer graphics rendering engine [8]. RSIM had very low sun elevation angles rendered into terrain maps for use in\nsimulating polar missions, and required changes to generalize the functionality to arbitrary sun elevation angles was beyond the scope of LunarNav timeline requirements. Similarly, the DARTS-based simulator was not scheduled for completion in the timeframe needed for LunarNav. Therefore, Blender was used to create synthetic images. Synthetic lidar images were generated similarly, by rendering 3D point clouds instead of images; sun angle was considered irrelevant for lidar, so that variable was ignored and we were able to use the higher fidelity RSIM. It is to be noted that both the Gazebo-based and DARTS-based simulators have more general capability, including simulating rover behavior, so this trade should be re-evaluated for end-to-end simulation needs in future years.\nBlender-based Lunar Scene Simulator\nThe Blender-based image scene simulation takes a lunar digital elevation map (DEM), applies a custom texture map to it, and creates a world model with a simulated sun as a light source; within this model, a stereo camera pair is added and the simulation generates locations for the cameras and the sun. For each camera and sun location, Blender\u2019s render engine produces a synthetic image. This image is rendered using a custom implementation of the Hapke radiometric model [25], [26], [27] incorporated into the Blender\u2019s path tracing algorithm to simulate accurate lighting across the surface. The simulation has multiple parameters that can be controlled, including sun position, camera extrinsic and intrinsic parameters, image size, and a few others. Images were were generated for craters with diameters ranging from 5 to 20 meters, with four different approach angles for each crater. For each crater and approach angle, the stereo camera was positioned at distances between 5 and 20 meters from the crater near rim, at 1 meter spacing; for each location, an image was rendered with a varied set of sun angles from 0\u25e6 to 80\u25e6 from nadir. The final dataset consisted of 1,792 stereo pairs.\n2.5D Simulation Environment for Long-range Traverse\nTo facilitate development of algorithms for crater matching based localization, we constructed a 2.5D simulation environment that allows for independent unit testing of the different localization algorithms. This allowed us to quickly iterate through different versions of the localization algorithms and validate their effectiveness with offline Monte Carlo\nsimulations. In the simulated environment, the localization algorithm receives two sets of craters as input: the known craters detected from orbit and the ones observed by the rover from the ground. The orbital craters are parameterized by their size and location (x, y, diameter). Their craters sizes are drawn from a truncated power-law distribution (\u03b1 = 1, diameter < 20), whereas their locations are drawn from a uniform distribution. The craters observed on the surface by the rover are generated by perturbing the known orbital craters according to a similar distribution of noise from crater detection, with a zero-centered gaussian (\u03c3 = 3m) error in the crater location and zero-centered gaussian (\u03c3 = 1m) error in the crater size. Further, we also added the capability to mask a percentage of either orbital or ground craters to simulate false positives and false negatives in crater detection. Figure 3 shows an illustration of the simulated environment that was\nused. Assuming the motion model with 2% noise, the rover traverses within this simulated environment and observes craters within a field of view range (< 40m). The localization algorithms then match the observed ground craters to the orbital craters for localization. Then, the estimated route is compared against the ground truth route for evaluation. The simulated environment can be extended to long-range traversals and can be used to validate the effectiveness in overcoming the baseline 2% of motion model noise.\nLong-range LiDAR simulation using RSIM\nTo further simulate long-range traverses from real Lunar terrain, we added a LiDAR simulation capability in RSIM [23], a ROS2 and Gazebo based high-fidelity simulation environment developed at NASA Ames to support the development of the VIPER Rover [28]. RSIM models the VIPER lunar rover structure, with the full CAD including rover kinematics, dynamics, and 3D model. RSIM also contains a lunar terrain model of the Nobile landing site, with 8k resolution. The terrain includes rocks and crater distributions, shadowing, and sun lighting. The LiDAR sensor (also referred to as\nthe Velodyne Simulator), is forked from the Toyota Research Institute Velodyne Simulator. This package contains a URDF description and Gazebo plugins to simulate the Velodyne laser scanners (our model is the HDL-32E). This Gazebo plugin is based on the gazebo plugins ROS block laser, which publishes PointCloud2 messages with the same structure (x, y, z, intensity, ring) and simulates Gaussian noise. To capture the point clouds from the LiDAR sensor, we created a package that provides a ROS2 node that can subscribe to the Velodyne lidar sensor mounted on the VIPER rover and saves a snapshot to the desk. In addition to capturing the point cloud, this node also outputs the position and orientation of the rover with respect to the world origin. It also contains scripts to visualize the point cloud and export it to other formats. The final datasets used were two discrete drives of the VIPER rover in RSIM with LiDAR on the Nobile landing site; both drives started the rover at the bottom-left corner of\nthe map (320m x 320m) and traversed diagonally along the hypotenuse to the upper-right corner, took approximately 30- 32 steps of 10m each, with a change in orientation chosen randomly between (-5 to 5 degrees) at each step. Due to the orientation change, the rover could not complete all the steps as it would fall off the map since it was not driving in a purely straight path with step-length: 10m, total steps: 35 and orientation change: 5 degrees at every waypoint. Figure 4 shows an illustration of an instance the LiDAR simulation from RSIM.\nReal Lunar data from Chang\u2019e missions\nFor real sensor data, the original plan for to acquire a largescale dataset of LIDAR and stereo image data from an analog site at the Cinder Lake crater field near Flagstaff, Arizona. This had to be postponed due to covid travel restrictions and\nforest fires; in lieu of this data, we decided to use real lunar stereo images that were available from the \u201cpanoramic\u201d cameras (PCAM) on the Chang\u2019e 3 [29] and Chang\u2019e 4 [30] lunar rover missions. Since this is actual lunar data, in important\nways it is better than the analogue stereo images that were originally planned. The Chang\u2019e missions\u2019 rover data has been publicly released 2. The cameras for both missions\n2https://moon.bao.ac.cn/\nare identical; their FOV is 19.7\u25e6x14.5\u25e6, resolution are 2352 x 1728 pixels (color) and 1176 x 864 pixels (monochrome) and stereo baseline length is 27 cm. A total of 168 pairs of Chang\u2019e 3 and 1174 pairs of Chang\u2019e 4 PCAM images were processed. A stereo camera self-calibration applied to this data yielded good camera models for both data sets. Stereo depth maps were computed from these images with good results, as shown in Figures 5.\nGround truth labeling of craters in this imagery and registration of this imagery against orbital imagery was done to prepare a dataset that was used for performance evaluations. Towards this end, we studied the usefulness of the Chang\u2019e lander camera (LCAM) to obtain a high resolution and high precision crater database. The LCAM image sequences (5000 images) were downloaded, and the Chang\u2019e EDL flight trajectory was recovered between 1000m and 100m above ground, using terrain relative navigation (TRN) and structure from motion algorithms. Figure 6 shows visualization of the recovered LCAM trajectory. Then, the LCAM images were ortho-rectified to a coarser resolution LRO-NAC image map (1 m/pixel) to obtain an ortho-image with higher resolution of up to 20 cm/pixel around the lander. This process was used to improve the resolution for a 100m x 100m region around the Chang\u2019e 4 lander as shown in Figure 7. The craters were detected from this high-resolution map and their geographic locations, diameters, depths were extracted into a crater database, as shown in Figure 8. This database was used for rover localization algorithm development"
        },
        {
            "heading": "5. TECHNICAL APPROACH",
            "text": "LunarNav\u2019s technical approach consists of three main elements: 1) crater detection, 2) crater matching, and 3) state estimation. In previous work, we developed crater detection algorithms for three different sensing modalities [8]. This paper builds on that work, and focuses on the crater-based localization (i.e. crater matching and state estimation) aspect of the problem. We will start with a brief review of how we do crater detection, and then introduce two crater-matching based localization algorithms that we developed: parametric and non-parametric methods.\nEach approach has both advantages and disadvantages; nonparametric approaches like the particle filter make no assumptions about the probability distribution for rover location and are robust in a wide variety of scenarios. However, the runtime may be slow due to the large number of particles it uses to represent the possible states of the rover. In contrast, parametric approaches are faster and more computationally efficient because rover position uncertainty is represented by closed-form mathematical expressions. Because the parametric approach makes certain assumptions about the distribution of errors, it may be less robust compared to non-parametric approaches.\nReview of Crater Detection\nPlanetary rovers to date have all used stereo cameras for terrain imaging and 3D perception [31]. Future rovers (to Moon and Mars) might have LIDAR, either by itself or in addition to one or more cameras. Thus, any combination of these sensors could be used for crater detection. To cover this set of options and to create a foundation for identifying the best approach in the future, crater detection algorithms were developed for three classes of technical approach: (1) Using 3D point clouds from LIDAR, (2) Using 3D point clouds\nfrom stereo vision, and (3) Using deep-learning based pattern recognition with monocular images.\nThe original plan was to treat crater detection as a process done independently from any knowledge of the crater landmark map and rover position; however, work last year showed that more reliable crater detection results was achieved by assuming approximate prior knowledge of rover position, which is realistic in practice, and using that to allow the crater detection process to invoke 3D models of craters expected to be around the rover based on this prior knowledge. Such approximate prior knowledge was used for the LIDAR- based approach developed, but has not yet been carried over to the other approaches. Geometric analysis methods was appointed to the point clouds from LIDAR and stereo vision; machine learning with neural nets was used for monocular images.\nResults of quantitative performance evaluation with geometric analysis applied to simulated 3D point clouds from LIDAR show high reliability for detecting craters with a leading edge within about 15 m from the rover. The results also suggested that rover localization with an error less than 5 m is highly probable. Somewhat simpler geometric analysis methods were applied to simulated 3D point clouds from stereo vision, which are noisier than LIDAR-based point clouds. Stereo-based detection degraded at shorter range than for LIDAR and obtained significantly higher crater position estimation error; nevertheless, rover localization with error in the 5 m range still appears to be possible. Monocular appearance-based detection was done with a CNN-based machine learning algorithm; this produced detection results in image space, but did not produce 3D crater position and size estimates. Detection performance exceeded the other two methods, making this a very promising approach for future crater-based localization systems. See [8] for details on the algorithms and performance characterization of crater detection.\nCrater-based Localization using Particle Filters\nFor non-parametric methods, we implemented a crater-based localization algorithm based on Particle Filters [32], [33],\nwhere each particle represents a hypothesis for the rover location, and the strength of the hypothesis is represented by a measurement probability. Figure 9 illustrates a generalized overview of the particle filter\u2019s cycle in which we have, in the first layer, some particles represented by ellipsis of various sizes. The size denotes the weight of a particle. The second layer illustrates the result of the sampling process which can lead to repeated particles. Upon sampling, the weights of the particles lose their meaning and new measurements are necessary as the third layer shows. In this layer, the particles\u2019 weights are adjusted according to the used motion model and a noise model applied to the sorted particles. Upon adjustments, we have an estimation for the next frame in the sequence. The fourth layer shows the function representing the updated particles. In this function, the height denotes the weight of the measurement at a given point. The fifth layer shows the a posteriori probability function as the result\nof the measurement step. In this step, the particles are properly weighted and prepared for the next iteration of the localization cycle.\nIn our implementation, a large number of particles can be used to approximate the distribution of the rover location as the rover moves and detects the craters. To estimate the location, the particles are moved according to the motion model, then the measurement probabilities are updated by comparing the ground craters with the orbital craters. Lastly, the particles are re-sampled according to their measurement probabilities to represent the new location distribution after motion.\nThere are many possible formulations on how to update the measurement probability given certain observations; we reasoned that the geometric relationship between a set of\ncrater observations can be used to improve the accuracy of localization, instead of modeling each crater as an independent observation. Therefore, we constructed a spatial formulation where the measurement probability of each particle is represented by the average area Intersection Over Union (IoU) distance [34] between the orbital and ground craters:\nTo account for missed detections, we adjust for the probability of new crater detection by using prior probability of detection from previous data.\nCrater-based based Localization using Parametric Matching\nFor parametric method-based localization, we assumed that each crater is represented by a gaussian distribution, with the location of the crater as the mean and the half of the radius as the standard deviation. For orbital craters, the set of craters can then be expressed using a gaussian mixture; and this can also be independently formulated for ground craters. Parametric matching based localization is formulated as the problem of finding the translation between the two gaussian mixtures that best matches these two distributions as shown in 10. The KL-divergence [35] measures the distance between two distributions and can be used as the loss function. We minimize the loss function with gradient-descent based methods to find the best translation, which represents the location (as illustrated in Figure 11). Further, the Hessian around the optimal solution can be used to estimate the standard error, since KL-divergence is equivalent to the negative loglikelihood."
        },
        {
            "heading": "6. PERFORMANCE EVALUATION",
            "text": "LIDAR-based Localization on Simulation Environment:\nWe evaluated the particle filter and parametric localization algorithms on a 400m x 400m simulated environment with 100 craters. An example of the traversal and localization results are shown below in Figures 12-14. Over a large number of simulated scenarios (n=50), both localization methods were able to perform better than the relative localization baseline of 2% noise motion model, with the particle filter performing slightly better. Further, the particle filter converged at around 2m of error over long ranges, suggesting that crater landmarks are valid features for accurate localization.\nLIDAR-based Localization from Apollo 2 Landing Site:\nWe performed preliminarily tests of the particle filter and parametric localization on craters detected from simulated LIDAR point clouds. Here, we used the elevation map from the Apollo 2 landing site to simulate a traversal of 20 steps (with 1m/step) for crater detection. In this scenario, two craters (with diameter 6.20m and 14.76m) were manually labeled as orbital craters. The crater detection algorithm matches observed candidate craters on the ground with the two orbital craters, and the localization algorithm used the location of the observed craters for localization, as shown in Figure 15.\nLIDAR-based Localization from Rumker Dome Landing Site:\nFurther, we evaluated the particle filter and parametric localization on LIDAR crater detected from a traverse through the Rumker Dome region. This is a more complex scenario compared to the Apollo 2 landing site, with 4 manually labeled craters (with diameter 21.94m, 5.60m, 6.98m, 8.58m) and 50 traversal steps (1m/step). According to the 2% motion model baseline, our model is estimated to deviate 1m from the ground truth. Our results (Figure 16) indicate an average distance of 0.75m throughout the traverse, indicating that crater landmarks are a reliable feature for more accurate localization.\nStereo-based Localization on Chang\u2019e 4 Landing Site\nWe integrated the particle-filter-based localization algorithm with the stereo-based crater detection from FY21, and tested it with the Chang\u2019e rover stereo data. The stereo crater detection algorithm succeeds in detecting craters on the real data when the assumptions of the algorithm [8] hold true; for example, as shown in Figure 17 which demonstrated a successful case of stereo-based crater detection on real Lunar data.\nHowever, the original crater detection makes two critical assumptions which regularly do not hold in the Chang\u2019e 4 dataset. It first assumes that the entire crater is visible in the image. Due to the small field of view of the PCAM, this is often not the case in the Chang\u2019E imagery. The second assumption is that the crater composes a relatively small section of the image, since otherwise the ground plane will not be detected correctly. This is also not the case with nearby craters, in part due once again to the small camera field of view.\nFigure 18 shows three example images where crater detection currently fails. In the leftmost image, the algorithm successfully detects the as a crater candidate in the penultimate step of the algorithm. However, it is filtered out as not a crater because the entire crater is not visible in the image, violating an assumption behind the algorithm. In the middle image, the crater is not entirely within the image. This case fails in step three of the algorithm, earlier than the previous case, since the critical near rim edge is not visible. Furthermore, since the crater takes up almost the entirety of the image, the back wall of the crater is detected as the ground plane. In the rightmost image, the crater takes up a large section of the image, and the crater\u2019s back wall is detected as the ground plane, leading the algorithm to fail. Additionally, the left and right edges of the crater are not visible so this would likely fail in a later step as well. Thus, the performance of the crater detection did not generalize to the current dataset of craters visible in Chang\u2019e imagery. As a result, we were unable to benchmark the performance of the particle filter on stereo modality."
        },
        {
            "heading": "7. DISCUSSION",
            "text": "The LunarNav project made the following accomplishments and contributions to crater-based localization:\n\u2022 Developed high-fidelity simulation environments and generated multiple datasets to support the development and performance evaluation of lunar rover navigation with crater landmarks\n\u2022 Generated a high-resolution crater database of real Lunar data from the Chang\u2019e 4 landing site.\n\u2022 Raised the TRL of onboard crater detection capability from 2 to 4 by successfully demonstrating crater detection algorithms on both simulated and real Lunar data.\n\u2022 Raised the TRL of onboard, global (\u201cabsolute\u201d) localization capability from 2 to 4 by successfully demonstrating crater-based localization algorithms on both simulated and real Lunar data\n\u2022 Completed software and dataset documentation (to accompany final publication of this manuscript) to enable seamless re-distribution and open-source release, for future funded efforts and wide-spread use by the community.\nRemaining Gaps, Risks and Challenges to Flight Infusion\nAs mentioned in Section 1, the capability developed in this project is intended for use in lunar rovers. No such missions are currently in development, but robotic lunar science rover mission concepts were strongly recommended by the PSADS report; in particular, the Endurance-A robotic lunar science rover mission concept was recommended as the highest priority medium-sized mission for the Moon. This concept involves traverse of roughly 2,000 km in several Earth years, which requires onboard absolute position estimation; LunarNav capability would be enabling for this mission. The Lunar Terrain Vehicle (LTV) envisioned for transporting astronauts may also benefit from having an option for autonomous position estimation as developed by LunarNav. Some of the potential challenges to flight infusion falls into the following main categories:\n\u2022 The state of maturity of the LunarNav algorithms is at intermediate TRLs; more maturation is required before it is fully ready for infusion. In particular, the performance of stereo-based crater localization needs to be improved by adding robustness to a wide-range of operational scenarios (partial crater visibility, variable crater shapes)\n\u2022 LunarNav requires stereo cameras and/or a lidar onboard the rover. For night operation, either headlights for the stereo cameras or a lidar is required. These sensors are not fully developed at present. Furthermore, the majority of the work done in LunarNav focused on daytime driving; further work needs to be done to extend this capability to night-time and operations in permanently shadowed regions.\n\u2022 The computing load associated with crater-based localization is expected to be less than that required for rover\nobstacle avoidance. Since any autonomous lunar rover would need obstacle avoidance, it is expected that the necessary computing capability for LunarNav would be available. Nevertheless, this aspect of system architecture must be verified as being sufficient.\n\u2022 Validation and verification (V&V) of crater-based localization requires datasets with craters, either from lunar analog terrain on Earth or from high fidelity lunar terrain simulators. There is a very limited amount of suitable analog terrain available. The Cinder Lake Crater Field planned for use in the LunarNav project is the only location of any reasonable size in the U.S.; it is nevertheless fairly small for this purpose, it has not been maintained (i.e. it is partly overgrowth with vegetation), and access to it is limited to spring and fall seasons, due to snow in the winter, heat in the summer, and the possibility of nearby forest fires in the summer through early fall."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "The research was carried out at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration (80NM0018D0004)."
        }
    ],
    "title": "LunarNav: Crater-based Localization for Long-range Autonomous Lunar Rover Navigation",
    "year": 2023
}