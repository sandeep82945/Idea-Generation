{
    "abstractText": "We study the problem of online dynamic pricing with two types of fairness constraints: a procedural fairness which requires the proposed prices to be equal in expectation among different groups, and a substantive fairness which requires the accepted prices to be equal in expectation among different groups. A policy that is simultaneously procedural and substantive fair is referred to as doubly fair. We show that a doubly fair policy must be random to have higher revenue than the best trivial policy that assigns the same price to different groups. In a two-group setting, we propose an online learning algorithm for the 2-group pricing problems that achieves \u00d5( \u221a T ) regret, zero procedural unfairness and \u00d5( \u221a T ) substantive unfairness over T rounds of learning. We also prove two lower bounds showing that these results on regret and unfairness are both information-theoretically optimal up to iterated logarithmic factors. To the best of our knowledge, this is the first dynamic pricing algorithm that learns to price while satisfying two fairness constraints at the same time.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jianyu Xu"
        },
        {
            "affiliations": [],
            "name": "Yu-Xiang Wang"
        }
    ],
    "id": "SP:1cc05850f01fba212b359f0384730d8b750bb5be",
    "references": [
        {
            "authors": [
                "A. Agarwal",
                "A. Beygelzimer",
                "M. Dud\u00edk",
                "J. Langford",
                "H. Wallach"
            ],
            "title": "A reductions approach to fair classification",
            "venue": "International Conference on Machine Learning, pages 60\u201369. PMLR.",
            "year": 2018
        },
        {
            "authors": [
                "P. Auer",
                "N. Cesa-Bianchi",
                "P. Fischer"
            ],
            "title": "Finite-time analysis of the multiarmed bandit problem",
            "venue": "Machine learning, 47(2):235\u2013256.",
            "year": 2002
        },
        {
            "authors": [
                "P. Auer",
                "N. Cesa-Bianchi",
                "Y. Freund",
                "R.E. Schapire"
            ],
            "title": "The nonstochastic multiarmed bandit problem",
            "venue": "SIAM Journal on Computing, 32(1):48\u201377.",
            "year": 2002
        },
        {
            "authors": [
                "S. Barocas",
                "M. Hardt",
                "A. Narayanan"
            ],
            "title": "Fairness in machine learning",
            "venue": "Nips tutorial, 1:2.",
            "year": 2017
        },
        {
            "authors": [
                "Y. Bechavod",
                "C. Jung",
                "S.Z. Wu"
            ],
            "title": "Metric-free individual fairness in online learning",
            "venue": "Advances in neural information processing systems, 33:11214\u201311225.",
            "year": 2020
        },
        {
            "authors": [
                "O. Besbes",
                "A. Zeevi"
            ],
            "title": "Dynamic pricing without knowing the demand function: Risk bounds and near-optimal algorithms",
            "venue": "Operations Research, 57(6):1407\u20131420.",
            "year": 2009
        },
        {
            "authors": [
                "O. Besbes",
                "A. Zeevi"
            ],
            "title": "On the (surprising) sufficiency of linear models for dynamic pricing with demand learning",
            "venue": "Management Science, 61(4):723\u2013739.",
            "year": 2015
        },
        {
            "authors": [
                "J. Broder",
                "P. Rusmevichientong"
            ],
            "title": "Dynamic pricing under a general parametric choice model",
            "venue": "Operations Research,",
            "year": 2012
        },
        {
            "authors": [
                "N. Cesa-Bianchi",
                "O. Dekel",
                "O. Shamir"
            ],
            "title": "Online learning with switching costs and other adaptive adversaries",
            "venue": "Advances in Neural Information Processing Systems, 26.",
            "year": 2013
        },
        {
            "authors": [
                "J.M. Chapuis"
            ],
            "title": "Price fairness versus pricing fairness",
            "venue": "Revenue & Yield Management eJournal, page 12.",
            "year": 2012
        },
        {
            "authors": [
                "Q. Chen",
                "S. Jasin",
                "I. Duenyas"
            ],
            "title": "Nonparametric self-adjusting control for joint learning and optimization of multiproduct pricing with finite resource capacity",
            "venue": "Mathematics of Operations Research, 44(2):601\u2013631.",
            "year": 2019
        },
        {
            "authors": [
                "X. Chen",
                "X. Zhang",
                "Y. Zhou"
            ],
            "title": "Fairness-aware online price discrimination with nonparametric demand models",
            "venue": "arXiv preprint arXiv:2111.08221.",
            "year": 2021
        },
        {
            "authors": [
                "M.C. Cohen",
                "A.N. Elmachtoub",
                "X. Lei"
            ],
            "title": "Price discrimination with fairness constraints",
            "venue": "Management Science.",
            "year": 2022
        },
        {
            "authors": [
                "M.C. Cohen",
                "I. Lobel",
                "R. Paes Leme"
            ],
            "title": "Feature-based dynamic pricing",
            "venue": "Management Science, 66(11):4921\u20134943.",
            "year": 2020
        },
        {
            "authors": [
                "M.C. Cohen",
                "S. Miao",
                "Y. Wang"
            ],
            "title": "Dynamic pricing with fairness constraints",
            "venue": "Available at SSRN 3930622.",
            "year": 2021
        },
        {
            "authors": [
                "A.A. Cournot"
            ],
            "title": "Researches into the Mathematical Principles of the Theory of Wealth",
            "venue": "Macmillan.",
            "year": 1897
        },
        {
            "authors": [
                "C. Dwork",
                "M. Hardt",
                "T. Pitassi",
                "O. Reingold",
                "R. Zemel"
            ],
            "title": "Fairness through awareness",
            "venue": "Proceedings of the 3rd innovations in theoretical computer science conference, pages 214\u2013226.",
            "year": 2012
        },
        {
            "authors": [
                "R. Elfin"
            ],
            "title": "The future use of unconscionability and impracticability as contract doctrines",
            "venue": "Mercer L. Rev., 40:937.",
            "year": 1988
        },
        {
            "authors": [
                "E. Eyster",
                "K. Madar\u00e1sz",
                "P. Michaillat"
            ],
            "title": "Pricing under fairness concerns",
            "venue": "Journal of the European Economic Association, 19(3):1853\u20131898.",
            "year": 2021
        },
        {
            "authors": [
                "J. Fan",
                "Y. Guo",
                "M. Yu"
            ],
            "title": "Policy optimization using semiparametric models for dynamic pricing",
            "venue": "arXiv preprint arXiv:2109.06368.",
            "year": 2021
        },
        {
            "authors": [
                "B.S. Frey",
                "W.W. Pommerehne"
            ],
            "title": "On the fairness of pricing\u2014an empirical survey among the general population",
            "venue": "Journal of Economic Behavior & Organization, 20(3):295\u2013307.",
            "year": 1993
        },
        {
            "authors": [
                "S. Gupta",
                "V. Kamble"
            ],
            "title": "Individual fairness in hindsight",
            "venue": "J. Mach. Learn. Res., 22(144):1\u201335.",
            "year": 2021
        },
        {
            "authors": [
                "M. Hardt",
                "E. Price",
                "N. Srebro"
            ],
            "title": "Equality of opportunity in supervised learning",
            "venue": "Advances in neural information processing systems,",
            "year": 2016
        },
        {
            "authors": [
                "A. Javanmard",
                "H. Nazerzadeh"
            ],
            "title": "Dynamic pricing in high-dimensions",
            "venue": "The Journal of Machine Learning Research, 20(1):315\u2013363.",
            "year": 2019
        },
        {
            "authors": [
                "M. Joseph",
                "M. Kearns",
                "J.H. Morgenstern",
                "A. Roth"
            ],
            "title": "Fairness in learning: Classic and contextual bandits",
            "venue": "Advances in neural information processing systems, 29.",
            "year": 2016
        },
        {
            "authors": [
                "P.J. Kaufmann",
                "G. Ortmeyer",
                "N.C. Smith"
            ],
            "title": "Fairness in consumer pricing",
            "venue": "Journal of Consumer Policy, 14(2):117\u2013140.",
            "year": 1991
        },
        {
            "authors": [
                "R. Kleinberg",
                "T. Leighton"
            ],
            "title": "The value of knowing a demand curve: Bounds on regret for online posted-price auctions",
            "venue": "IEEE Symposium on Foundations of Computer Science (FOCS-03), pages 594\u2013605. IEEE.",
            "year": 2003
        },
        {
            "authors": [
                "T.L. Lai",
                "H. Robbins"
            ],
            "title": "Asymptotically efficient adaptive allocation rules",
            "venue": "Advances in applied mathematics, 6(1):4\u201322.",
            "year": 1985
        },
        {
            "authors": [
                "R.P. Leme",
                "J. Schneider"
            ],
            "title": "Contextual search via intrinsic volumes",
            "venue": "2018 IEEE 59th Annual Symposium on Foundations of Computer Science (FOCS-18), pages 268\u2013282. IEEE.",
            "year": 2018
        },
        {
            "authors": [
                "A. Liu",
                "R.P. Leme",
                "J. Schneider"
            ],
            "title": "Optimal contextual pricing and extensions",
            "venue": "Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms (SODA-21), pages 1059\u20131078. SIAM.",
            "year": 2021
        },
        {
            "authors": [
                "R. Maestre",
                "J. Duque",
                "A. Rubio",
                "J. Ar\u00e9valo"
            ],
            "title": "Reinforcement learning for fair dynamic pricing",
            "venue": "Proceedings of SAI Intelligent Systems Conference, pages 120\u2013135. Springer.",
            "year": 2018
        },
        {
            "authors": [
                "A. Priester",
                "T. Robbert",
                "S. Roth"
            ],
            "title": "A special price just for you: Effects of personalized dynamic pricing on consumer fairness perceptions",
            "venue": "Journal of Revenue and Pricing Management, 19(2):99\u2013112.",
            "year": 2020
        },
        {
            "authors": [
                "D. Qiao",
                "M. Yin",
                "M. Min",
                "Wang",
                "Y.-X."
            ],
            "title": "Sample-efficient reinforcement learning with loglog (T) switching cost",
            "venue": "arXiv preprint arXiv:2202.06385.",
            "year": 2022
        },
        {
            "authors": [
                "T.J. Richards",
                "J. Liaukonyte",
                "N.A. Streletskaya"
            ],
            "title": "Personalized pricing and price fairness",
            "venue": "International Journal of Industrial Organization, 44:138\u2013153.",
            "year": 2016
        },
        {
            "authors": [
                "Y. Wang",
                "B. Chen",
                "D. Simchi-Levi"
            ],
            "title": "Multimodal dynamic pricing",
            "venue": "Management Science.",
            "year": 2021
        },
        {
            "authors": [
                "Z. Wang",
                "S. Deng",
                "Y. Ye"
            ],
            "title": "Close the gaps: A learning-while-doing algorithm for single-product revenue management problems",
            "venue": "Operations Research, 62(2):318\u2013331.",
            "year": 2014
        },
        {
            "authors": [
                "J. Xu",
                "Wang",
                "Y.-X"
            ],
            "title": "Logarithmic regret in feature-based dynamic pricing",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "J. Xu",
                "Wang",
                "Y.-X."
            ],
            "title": "Towards agnostic feature-based dynamic pricing: Linear policies vs linear valuation with unknown noise",
            "venue": "International Conference on Artificial Intelligence and Statistics (AISTATS).",
            "year": 2022
        },
        {
            "authors": [
                "Z. Yang",
                "X. Fu",
                "P. Gao",
                "Chen",
                "Y.-J."
            ],
            "title": "Fairness regulation of prices in competitive markets",
            "venue": "Available at SSRN.",
            "year": 2022
        },
        {
            "authors": [
                "H. Yu",
                "M. Neely",
                "X. Wei"
            ],
            "title": "Online convex optimization with stochastic constraints",
            "venue": "Advances in Neural Information Processing Systems, 30.",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "\u221a T ) regret, zero\nprocedural unfairness and O\u0303( \u221a T ) substantive unfairness over T rounds of learning. We also prove two lower bounds showing that these results on regret and unfairness are both information-theoretically optimal up to iterated logarithmic factors. To the best of our knowledge, this is the first dynamic pricing algorithm that learns to price while satisfying two fairness constraints at the same time."
        },
        {
            "heading": "1 Introduction",
            "text": "Pricing problems have been studied since Cournot [1897]. In a classical pricing problem setting such as Kleinberg and Leighton [2003], Broder and Rusmevichientong [2012], Besbes and Zeevi [2015], the seller (referred as \u201cwe\u201d) sells identical products in the following scheme. Online pricing. For t = 1, 2, . . . , T : 1. The customer valuates the product as yt. 2. The seller proposes a price vt concurrently without knowing yt. 3. The customer makes a decision 1t = 1(vt \u2264 yt). 4. The seller receives a reward (revenue) rt = vt \u00b7 1t.\nar X\niv :2\n20 9.\n11 83\n7v 1\n[ cs\n.L G\n] 2\n3 Se\nHere T is the time horizon known to the seller in advance1, and yt\u2019s are drawn from a fixed distribution independently. The goal is to approach an optimal price that maximizes the expected revenue-price function. In order to make this, we should learn gradually from the binary feedback and improve our knowledge on customers\u2019 valuation distribution (or so-called \u201cdemands\u201d [Kleinberg and Leighton, 2003]).\nIn recent years, with the development of price discrimination and personalized pricing strategies, fairness issues on pricing arose social and academic concerns [Kaufmann et al., 1991, Chapuis, 2012, Richards et al., 2016, Eyster et al., 2021]. Customers are usually not satisfied with price discrimination, which would in turn undermine both their willing to purchase and the sellers\u2019 reputation. In the online pricing problem defined above, when we are selling identical items to customers from different groups (e.g., divided by gender, race, age, etc.), it can be unfair if we propose a specific optimal price for each group: These optimal prices in different groups are not necessarily the same, and unfairness occurs if different customers are provided or buying the same item with different prices. Inspired by the concept of procedural and substantive unconscionability[Elfin, 1988], we define a procedural unfairness measuring the difference of proposed prices between the two groups, and a substantive unfairness measuring that of accepted prices between the two groups. Given these notions, our goal is to approach the optimal pricing policy that maximizes the expected total revenue with no procedural and substantive unfairness.\nThe concept of procedural fairness has been well established in Cohen et al. [2022] as \u201cprice fairness\u201d, while the concept of the substantive fairness is new to this paper. In fact, both procedural and substantive fairness have significant impacts on customers\u2019 experience and social justice. For instance, these notions help prevent the following two scenarios:\n\u2022 Perspective buyers who are women found that they are offered consistently higher average price than men for the same product.\n\u2022 Women who have bought the product found that they paid a higher average price than men who have bought the product.\nTherefore, a good pricing strategy has to satisfy both procedural and substantive fairness.\nHowever, these constraints are very hard to satisfy even with full knowledge on customers\u2019 demands. If we want to fulfill those two sorts of fairness perfectly by proposing deterministic prices for different groups, the only thing we can do is to trivially set the same price in all groups and to maximize the weighted average revenue function by adjusting this uniformly fixed price with existing methods such as Kleinberg and Leighton [2003]. Consider the following example:\n1Here we assume T known for simplicity of notations. In fact, if T is unknown, then we may apply a \u201cdoubling epoch\u201d trick as Javanmard and Nazerzadeh [2019] and the regret bounds are the same.\nExample 1. Customers form two disjoint groups, where 30% customers are in Group 1 and the rest 70% are in Group 2.\nFor each price in {$0.625, $0.7, $1}, customers in two groups have different acceptance rates:\nAcceptance Rate $0.625 $0.7 $1 G1 (30%) 3/5 1/2 1/2 G2 (70%) 4/5 4/5 1/2\nThe right figure shows the expected revenue functions of prices in each group, where the red dashed line is their weighted average by population.\nPrice\nExpected Revenue\n$0.625 $0.7 $1\n$0.5\nk=4/5\nk=3/5\nk=1/2\nGroup 1\nGroup 2\nWeighted Average\nIn Example 1, the only way to guarantee both fairness constraints is to propose the same price for both groups, and the optimal price is $1 whose expected revenue is $0 .5 as is shown in the figure.\nHowever, if we instead propose a random price distribution to each group and inspect those fairness notions in expectation, then there may exist price distributions that satisfy both fairness constraints and achieve higher expected revenue than any fixed-price strategy. Here a price distribution is the distribution over the prices for customers, and the exact price for each customer is sampled from this distribution independently. This random price sampling process can be implemented by marketing campaigns such as random discounts or randomly-distributed coupons. Again, we consider Example 1 and the following random policy:\n\u2022 For customers from G1, propose $0.625 with probability 2029 and $1 with probability 9 29 .\n\u2022 For customers from G2, propose $0.7 with probability 2529 and $1 with probability 4 29 .\nUnder this policy, the expected proposed price and the expected accepted price in both groups are $4358 and $ 8 11 respectively. Furthermore, the expected revenue is $ 74 145 > $0 .5 , which means that this random policy performs better than the best fixed-price policy. It is worth mentioning that this is exactly the optimal random policy in this specific setting, but the proof of its optimality is highly non-trivial (and we put it in Appendix B.3 as part of the proof of Theorem 9 ).\nIn this work, we consider a two-group setting and we denote a policy as the tuple of two price distributions over the two groups respectively. Therefore, we can formally define the optimal policy as follows:\n\u03c0\u2217 = argmax \u03c0=(\u03c01,\u03c02) q \u00b7 E v1t\u223c\u03c01,y1t\u223cD1 [v1t \u00b7 1(v1t \u2264 y1t )] + (1\u2212 q) \u00b7 E v2t\u223c\u03c02,y2t\u223cD2 [v2t \u00b7 1(v2t \u2264 y2t )]\ns.t. E\u03c01 [v1t ] = E\u03c02 [v2t ] E\u03c01,D1 [v1t |1(v1t \u2264 y1t ) = 1] = E\u03c02,D2 [v2t |1(v2t \u2264 y2t ) = 1]\n(1)\nHere \u03c01, v1t , y1t ,D1 and \u03c02, v2t , y2t ,D2 are the proposed price distributions, proposed prices, customer\u2019s valuations and valuation distributions of Group 1 and Group 2 respectively, and q is the proportion of Group 1 among all customers. From (1), the optimal policy under the in-expectation fairness constraints should be random in general2. However, even we know the exact D1 and D2, it is still a very hard problem to get \u03c0\u2217: Both sides of the second constraint in (1) are conditional expectations (i.e., fractions of expected revenue over expected acceptance rate) and is thus not convex ( and also not quasiconvex). To make it harder, the seller actually has no direct access to customers\u2019 demands D1 and D2 at the beginning. Therefore, in this work we consider a T -round online learning and pricing setting, where we could learn these demands from those Boolean-censored feedback (i.e., customers\u2019 decisions) and improve our pricing policy to approach \u03c0\u2217 in (1).\nIn order to measure the performance of a specific policy, we define a regret metric that equals the expected revenue difference between this policy and the optimal policy. We also quantify the procedural and substantive unfairness that equals the absolute difference of expected proposed/accepted prices in two groups. We will establish a more detailed problem setting in Section 3.\nSummary of Results Our contributions are threefold:\n\u2022 We design an algorithm, FPA, that achieves an O( \u221a Td 3 2 log d log T ) cumulative regret\nwith 0 procedural unfairness and O( \u221a Td 3 2 log d log T ) substantive unfairness, with probability at least (1\u2212 ). Here d is the total number of prices allowed to be chosen from. These results indicate that our FPA is asymptotically no-regret and fair as T gets large. \u2022 We show that the regret of FPA is optimal with respect to T , as it matches \u2126( \u221a T )\nregret lower bound up to log log T factors.\n\u2022 We show that the unfairness of FPA is also optimal with respect to T up to log log T factors, as it has no procedural unfairness and its substantive unfairness matches the \u2126( \u221a T ) lower bound for any algorithm achieving an optimal O( \u221a T ) regret.\nTo the best of our knowledge, we are the first to study a pricing problem with multiple fairness constraints, where the optimal pricing policy is necessary to be random. We also\n2Notice that a fixed-price policy can also be considered as \u201crandom\u201d.\ndevelop an algorithm that is able to approach the best random pricing policy with high probability and at the least cost of revenue and fairness.\nTechnical Novelty. Our algorithm is a \u201cconservative policy-elimination\u201d-based strategy that runs in epochs with doubling batch sizes as in Auer et al. [2002a]. We cannot directly apply the action-elimination algorithm for multi-armed bandits as in Cesa-Bianchi et al. [2013], because the policy space is an infinite set and we cannot afford to try each one out. The fairness constraints further complicate things. Our solution is to work out just a few representative policies that are \u201cgood-and-exploratory\u201d, which can be used to evaluate the revenue and fairness of all other policies, then eliminate those that are unfair or have suboptimal revenue. Since we do not have direct access to the demand function, the estimated fairness constraints are changing over epochs due to estimation error, it is non-trivial to keep the target optimal policy inside our \u201cgood policy set\u201d during iterations. We settle this issue by setting the criteria of a \u201cgood policy\u201d conservatively.\nOur lower bound is new too and it involves techniques that could be of independent interest to the machine learning theory community. Notice that it is possible to have a perfectly fair algorithm by trivially proposing the same fixed price for both groups. It is highly non-trivial to show the unfairness lower bound within the family of regret-optimal algorithms. We present our result in Section 5.3 by establishing two similar problem settings that any algorithm cannot distinguish them efficiently and showing that a mismatch would cause a compatible amount of regret and substantive unfairness."
        },
        {
            "heading": "2 Related Works",
            "text": "Here we discuss some literature that are closely related to this work. For a broader discussion, please refer to Appendix A.\nDynamic Pricing Single product dynamic pricing problem has been well-studied through Kleinberg and Leighton [2003], Besbes and Zeevi [2009], Wang et al. [2014], Chen et al. [2019], Wang et al. [2021]. The crux is to learn and approach the optimal of a revenue curve from Boolean-censored feedback. In specific, Kleinberg and Leighton [2003] proves \u0398(log log T ), \u0398( \u221a T ) and \u0398(T 23 ) minimax regret bounds under noise-free, infinitely smooth and stochastic/adversarial valuation assumptions, sequentially. Wang et al. [2021] further shows a \u0398(T K+1 2K+1 ) minimax regret bound for Kth-smooth revenue functions. In all these works, the decision space is continuous. In our problem setting, we fix the proposed prices to be chosen in a fixed set of d prices, and show a bandit-style \u2126( \u221a dT ) regret lower bound with a similar method to Auer et al. [2002b].\nFairness in Machine Learning Fairness is a long-existing topic that has been extensively studied. In the machine learning community, fairness is defined from mainly two perspectives: the group fairness and the individual fairness. In a classification problem, for instance, [Dwork et al., 2012] defines these two notions as follows: (1) A group fairness requires different groups to have identical result distributions in statistics, which further includes the concepts of \u201cdemographic parity\u201d (predictions independent to group attributes) and \u201cequalized odds\u201d (predictions independent to group attributes conditioning on the true labels). In Agarwal et al. [2018], these group fairness are reduced to linear constraints. The two fairness definitions we make in this work, the procedural fairness and the substantive fairness, belong to group fairness. (2) An individual fairness [Hardt et al., 2016] requires the difference of predictions on two individuals to be upper bounded by a distance metric of their intrinsic features. The notion \u201ctime fairness\u201d is often considered as individual fairness as well. We provide a more detailed discussion on the line of work that address fairness concerns or stochastic constraints with online learning techniques in Appendix A.\nFairness in Pricing Recently there are many works contributing to pricing fairness problems [Kaufmann et al., 1991, Frey and Pommerehne, 1993, Chapuis, 2012, Richards et al., 2016, Priester et al., 2020, Eyster et al., 2021, Yang et al., 2022]. As is stated in Cohen et al. [2022], in a pricing problem with fairness concerns, the concept of fairness in existing works is modeled either as a utility or budget that trades-off the revenue or as a hard constraint that prevent us from taking the best action directly.Cohen et al. [2022] chooses the second model and defines four different types of fairness in pricing: price fairness, demand fairness, surplus fairness and no-purchase valuation fairness, each of which indicates the difference of prices, the acceptance rate, the surplus (i.e., (valuation \u2212 price) if bought and 0 otherwise) and the average valuation of not-purchasing customers in two groups is bounded, sequentially. They show that it is impossible to achieve any pair of different fairness notions simultaneously (with deterministic prices). In fact, this can be satisfied if they allow random pricing policies. Maestre et al. [2018] indeed builds their fairness definition upon random prices by introducing a \u201cJain\u2019s Index\u201d, which indicates the homogeneity of price distributions among different groups (i.e., our procedural fairness notion). They develop a reinforcement-learning-based algorithm to provide homogeneous prices, with no theoretic guarantees.\nCohen et al. [2021] and Chen et al. [2021] study the online-learning-fashion pricing problem as we do. Cohen et al. [2021] considers both group (price) fairness and individual (time) fairness, and their algorithm FaPU solves this problem with sublinear regret while guaranteeing fairness. They further study the pricing problem with demand fairness that are unknown and needs learning. In this setting, they propose another FaPD algorithm that achieves the optimal O\u0303( \u221a T ) regret and guarantees the demand fairness \u201calmost surely\u201d, i.e., upper bounded by \u03b4 \u00b7 T as a budget. Chen et al. [2021] considers two different sorts of fairness constraints: (1) Price fairness constraints (as in Cohen et al. [2022]) are enforced; (2)Price\nfairness constraints are generally defined (and maybe not accessible), where they adopt \u201csoft fairness constraints\u201d by adding the fairness violation to the regret with certain weights. In both cases, they achieve O\u0303(T 45 ) regrets. These learning-based fairness requirements are quite similar to our problem setting, but in our setting the fairness constraints are non-convex (while theirs are linear) and are also optimized to corresponding information-theoretic lower bounds without undermining the optimal regret."
        },
        {
            "heading": "3 Problem Setup",
            "text": "In this section, we describe the problem setting of online pricing, introduce new fairness definitions and set the goal of our algorithm design.\nProblem Description. We start with the online pricing process. The whole selling session involves customers from two groups (G1 and G2) and lasts for T rounds. Prices are only allowed to be chosen from a known and fixed set of d prices: V = {v1, v2, . . . , vd}, where 0 < v1 < v2 < . . . < vd \u2264 1. Denote \u2206d = {x \u2208 Rd+, \u2016x\u20161 = 1} as the probabilistic simplex. At each time t = 1, 2, . . . , T , we propose a pricing policy \u03c0 = (\u03c01, \u03c02) consisting of two probabilistic distributions \u03c01, \u03c02 \u2208 \u2206d over all d prices. A customer then arrives with an observable group attribution Ge (e \u2208 {1, 2}), and we propose a price by sampling a vet from V according to distribution \u03c0e. At the same time, the customer generates a valuation yet in secret, where yet is sampled independently and identically from some fixed unknown distribution De. Afterward, we observe a feedback 1et = 1(vet \u2264 yet ) and receive a reward(revenue) ret = 1et \u00b7 vet .\nKey Quantities. Here we define a few quantities and functions that is necessary to formulate the problem. Denote v := [v1, v2, . . . , vd]>, [d] := {1, 2, . . . , d} and 1 := [1, 1, . . . , 1]> \u2208 Rd for simplicity. Denote Fe(i) := PrDe [yet \u2265 vi], e = 1, 2, i \u2208 [d] as the probability of price vi being accepted in Ge, and we know that Fe(1) \u2265 Fe(2) \u2265 . . . \u2265 Fe(d). Notice that all Fe(i)\u2019s are unknown to us. Define a matrix Fe := diag(Fe(1), Fe(2), . . . , Fe(d)).\nAs a result, for a customer from Ge (e \u2208 {1, 2}), we know that\n\u2022 The expected proposed price is v>\u03c0e.\n\u2022 The expected reward(revenue) is v>Fe\u03c0e.\n\u2022 The expected acceptance rate is 1>Fe\u03c0e.\n\u2022 The expected accepted price is v>Fe\u03c0e 1>Fe\u03c0e .\nDenote the proportion of G1 in all potential customers as q (0 < q < 1) which is fixed and known to us, and we assume that every customer is chosen from all potential customers\nuniformly at random. As a consequence, we can define the expected revenue of a policy \u03c0.\nDefinition 2 (Expected Revenue). For any pricing policy \u03c0 = (\u03c01, \u03c02) \u2208 \u03a0, define its expected revenue (given F1 and F2) as the weighted average of the expected rewards of G1 and G2.\nR(\u03c0;F1, F2) := Pr[Customer is from G1] \u00b7 E[r1t ] + Pr[Customer is from G2] \u00b7 E[r2t ] =q \u00b7 v>F1\u03c01 + (1\u2212 q) \u00b7 v>F2\u03c02 (2)\nAlso, we can define the two different unfairness notions based on these results above.\nDefinition 3 (Procedural Unfairness). For any pricing policy \u03c0 \u2208 \u03a0, define its procedural unfairness as the absolute difference between the expected proposed prices of two groups.\nU(\u03c0) := |v>\u03c01 \u2212 v>\u03c02| = |v>(\u03c01 \u2212 \u03c02)|. (3)\nProcedural unfairness is totally tractable as we have full access to v> and \u03c0. Therefore, we can define a policy family \u03a0 := {\u03c0 = (\u03c01, \u03c02), U(\u03c0) = 0} that contains all policies with no procedural unfairness. Now we define a substantive unfairness as another metric.\nDefinition 4 (Substantive Unfairness). For any pricing policy \u03c0 \u2208 \u03a0, define its substantive unfairness as the difference between the expected accepted prices of two groups.\nS(\u03c0;F1, F2) := \u2223\u2223\u2223E[v1|v1 \u223c \u03c01, v1 being accepted ]\u2212 E[v2|v2 \u223c \u03c02, v2 being accepted ]\u2223\u2223\u2223\n= \u2223\u2223\u2223\u2223\u2223v>F1\u03c011>F1\u03c01 \u2212 v >F2\u03c0 2 1>F2\u03c02 \u2223\u2223\u2223\u2223\u2223 . (4)\nSubstantive unfairness is not as tractable as procedural unfairness, as we have no direct access to the true F1 and F2. Ideally, the optimal policy that we would like to achieve is:\n\u03c0\u2217 = argmax \u03c0=(\u03c01,\u03c02)\u2208\u03a0 R(\u03c0;F1, F2)\ns.t. U(\u03c0) = 0, S(\u03c0;F1, F2) = 0. (5)\nThe feasibility of this problem is trivial: policies such as \u03c01 = \u03c02 = [0, . . . , 0, 1, 0, . . . , 0]> (i.e., proposing the same fixed price despite the customer\u2019s group attribution) are always feasible. However, this problem is in general highly non-convex and non-quasi-convex. Finally, we define a (cumulative) regret that measure the performance of any policy \u03c0:\nDefinition 5 (Regret). For any algorithm A, define its cumulative regret as follows:\nRegT (A) := T\u2211 t=1 Reg(\u03c0t;F1, F2) := T\u2211 t=1 R(\u03c0\u2217;F1, F2)\u2212R(\u03c0t;F1, F2). (6)\nHere \u03c0t is the policy proposed by A at time t.\nNotice that we define the per-round regret by comparing the performance of \u03c0t with the optimal policy \u03c0\u2217 under constraints. Therefore, Reg(\u03c0t;F1, F2) is possible to be negative if \u03c0 \u2208 \u03a0 but U(\u03c0t) > 0 or S(\u03c0t;F1, F2) > 0. Similarly, we define a cumulative substantive unfairness as ST (A) := \u2211T t=1 S(\u03c0;F1, F2).\nGoal of Algorithm Design Our ultimate goal is to approach \u03c0\u2217 in the performance. In the online pricing problem setting we adopt, however, we cannot guarantee S(\u03c0t;F1, F2) = 0 for all \u03c0t we propose at time t = 1, 2, . . . , T since we do not know F1 and F2 in advance. Instead, we may suffer a gradually vanishing unfairness as we learn F1 and F2 better. Therefore, our goal in this work is to design an algorithm that guarantees an optimal regret while suffering 0 cumulative procedural unfairness and the least cumulative substantive unfairness.\nTechnical Assumptions. Here we make some mild assumptions that help our analysis.\nAssumption 1 (Least Probability of Acceptance). There exists a fixed constant Fmin > 0 such that Fe(d) \u2265 Fmin, e = 1, 2.\nAssumption 1 not only ensures the definition of expected accepted price to be sound (by ruling out these unacceptable prices), but also implies S(\u03c0, F1, F2) to be Lipschitz. Besides, we can always achieve this by reducing vd. We will provide a detailed discussion in Section 6.\nAssumption 2 (Number of Possible Prices). We treat d, the number of prices, as an amount independent from T . Also, we assume d = O(T 13 ). Assumption 2 is a necessary condition of applying \u2126( \u221a dT ) regret lower bound, and here we make it to show the optimality of our algorithm w.r.t. T ."
        },
        {
            "heading": "4 Algorithm",
            "text": "In this section, we propose our Fairly Pricing Algorithm (FPA) in Algorithm 1 and then discuss the techniques we develop and apply to achieve the \u201cno-regret\u201d and \u201cno-unfairness\u201d goal.\nAlgorithm 1 Fairly Pricing Algorithm (FPA) 1: Input: Time horizon T , prices set V, error probability , universal constant L, propor-\ntion q. 2: Before Epochs: Keep proposing the highest price vd for \u03c40 = 2 log T log 16 rounds.\nEstimate the average rate of acceptance in two groups as F\u0304d(1) and F\u0304d(2). Take F\u0302min = min{F\u0304d(1),F\u0304d(2)}2 .\n3: Initialization: Parameters Cq, ct. Epoch length \u03c4k = O(d \u221a T \u00b72k), reward uncertainty\n\u03b4k,r and unfairness uncertainty \u03b4k,s for k = 1, 2, . . . , O(log T ). (To be specified in Appendix B.1 ) Candidate policy set \u03a01 = \u03a0 := {\u03c0 = (\u03c01, \u03c02), U(\u03c0) = 0} and price index set I10 = I20 = [d].\n4: for Epoch k = 1, 2, . . . do 5: Set Ak = \u2205, I1k = I1k\u22121 and I2k = I2k\u22121. 6: for Group e = 1, 2 and for price index i \u2208 Iek\u22121, do 7: {Pick up policy maximizing each probability:} 8: Get \u03c0\u0303k,i,e = argmax\u03c0\u2208\u03a0k \u03c0\ne(i). 9: If \u03c0\u0303ek,i,e(i) \u2265 1\u221aT , let Ak = Ak \u222a {\u03c0\u0303k,i,e}. Otherwise, remove i from I e k.\n10: end for 11: Set Mk,e(i) = Nk,e(i) = 0, \u2200i \u2208 [d], e = 1, 2. 12: for each policy \u03c0 \u2208 Ak, do 13: {Sample random prices at t = 1, 2, . . . , \u03c4k|Ak| repeatedly:} 14: Run \u03c0 for a batch of \u03c4k|Ak| rounds. 15: For each time a price vi is proposed in Ge, set Mk,e(i)+ = 1. 16: For each time a price vi is accepted in Ge, set Nk,e(i)+ = 1. 17: end for 18: For e = 1, 2, set F\u0304k,e(i) = max{Nk,e(i)Mk,e(i) , F\u0302min} for i \u2208 I e k, and F\u0304k,e(i) = F\u0302min otherwise.\n19: Let F\u0302k,e = diag(F\u0304k,e(1), F\u0304k,e(2), . . . , F\u0304k,e(d)), e = 1, 2. 20: Solve the following optimization problem and get the empirical optimal policy \u03c0\u0302k,\u2217.\n\u03c0\u0302k,\u2217 = argmax \u03c0\u2208\u03a0k R(\u03c0, F\u0302k,1, F\u0302k,2), s.t. S(\u03c0, F\u0302k,1, F\u0302k,2) \u2264 \u03b4k,s. (7)\n21: To eliminate largely suboptimal or unfair policies, construct\n\u03a0k+1 = {\u03c0 : \u03c0 \u2208 \u03a0k, S(\u03c0, F\u03021, F\u03022) \u2264 \u03b4k,s, R(\u03c0, F\u03021, F\u03022) \u2265 R(\u03c0\u0302k,\u2217, F\u03021, F\u03022)\u2212 \u03b4k,r\u2212L \u00b7 \u03b4k,s}. (8)\n22: end for"
        },
        {
            "heading": "4.1 Algorithm Components",
            "text": "Algorithm 1 takes the following inputs: time horizon T , price set V, error probability , a universal constant L as the coefficient of the performance-fairness tradeoff on constraint relaxations (see Lemma 14), and q as the proportion that G1 takes. In the \u201cbefore epochs\u201d stage, we keep proposing the highest price vd for \u03c40 = O(log T ) rounds to estimate(lowerbound) the least acceptance rate Fmin. We also adopt the following techniques that serve as components of FPA and contribute to its no-regret and no-unfairness performance.\nDoubling Epochs Despite the \u201cbefore epochs\u201d stage, we divide the whole time space into epochs k = 1, 2, . . ., where each epoch k has a length \u03c4k = O( \u221a T \u00b7 2k) that doubles that of epoch (k\u2212 1). Within each epoch k, we run a set of \u201cgood-and-exploratory policies\u201d (to be introduced in Section 4.1) with equal shares of \u03c4k. At the end of each epoch k, we update the estimates of F1 and F2, eliminate the sub-optimal policies and update the set of \u201cgood-and-exploratory policies\u201d for the next epoch. Since the estimates of parameters get better as k increases, a doubling-epoch trick would ensure that we run better policies in longer epochs and therefore save the regret.\nPolicy Eliminations At the end of each epoch k, we update the candidate policy set by eliminating those substantially sub-optimal policies: Firstly, we select an empirical optimal policy \u03c0\u0302k,\u2217 that maximizes R(\u03c0, F\u0302k,1, F\u0302k,2) while guaranteeing S(\u03c0, F\u0302k,1, F\u0302k,2) \u2264 \u03b4k,s. After that, we eliminate those policies that satisfy one of the following two criteria:\n\u2022 Large unfairness: S(\u03c0, F\u0302k,1, F\u0302k,2) > \u03b4k,s, or\n\u2022 Large regret: R(\u03c0, F\u0302k,1, F\u0302K,2) < R(\u03c0\u0302k,\u2217, F\u0302k,1, F\u0302k,2)\u2212 \u03b4k,r \u2212 L \u00b7 \u03b4k,s.\nHere we adopt two subtractors on the regret criteria: \u03b4k,r for the estimation error in R(\u03c0) caused by F\u0302k,e, and L\u00b7\u03b4k,s for the possible increase of optimal reward by allowing S(\u03c0) \u2264 \u03b4k,s instead of S(\u03c0) = 0. In this way, we can always ensure the optimal policy \u03c0\u2217 (i.e., the solution of (5)) to remain and also guarantee the other remaining policies perform similarly to \u03c0\u2217.\nGood-and-Exploratory Policies Although all remaining policies perform good, not all of them are suitable of running in consideration of exploration. It is important to update the estimates of all F1(i) and F2(i) as they are required in the policy elimination. We solve this issue by keeping a set of good-and-exploratory policies: After eliminating sub-optimal policies at the end of previous epoch, for each price vi in group Ge we find out a policy in the remaining policies that maximizes the probability of proposing vi in Ge at the beginning of current epoch. The larger this probability is, the more times vi can be chosen in Ge, which would lead to a better estimate of Fe(i). Here we give up to estimate the acceptance\nprobability of those vi with \u2264 1\u221aT to be chosen by the optimal policy \u03c0\u2217, as it would not affect the elimination process and the performance substantially."
        },
        {
            "heading": "4.2 Computational Cost",
            "text": "Our FPA algorithm is oracle-efficient due to the doubling-epoch design, as we only run each oracle and update each parameter for O(log T ) times. However, the implementation of these oracles could be time-consuming: On the one hand, each set \u03a0k contains infinite policies, and a discretization would lead to exponential computational cost w.r.t. d. On the other hand, both (7) and (8) are highly non-convex on the constraints and are hard to solve with off-the-shelf methods."
        },
        {
            "heading": "5 Regret and Unfairness Analysis",
            "text": "In this section, we analyze the regret and unfairness of our FPA algorithm. We first present an O\u0303( \u221a Td 3 2 ) regret upper bound along with an O\u0303( \u221a Td 3 2 ) unfairness upper bound. Then we show both of them are optimal (w.r.t. T ) up to log log T factors by presenting matching lower bounds."
        },
        {
            "heading": "5.1 Regret Upper Bound",
            "text": "First of all, we propose the following theorem as the main results for our Algorithm 1 (FPA). Theorem 6 (Regret and Unfairness). FPA guarantees an O( \u221a Td 3 2 log d log T ) regret with no procedural unfairness and an O( \u221a Td 3 2 log d log T ) substantive unfairness with probability 1\u2212 .\nProof sketch. We prove this theorem by induction w.r.t. epoch index k. Firstly, we assume that \u03c0\u2217 \u2208 \u03a0k, which naturally holds as k = 1. Meanwhile, we show a high-probability bound on the estimation error of each Fe(i) for epoch k, according to concentration inequalities. Given this, we derive the estimation error bound of R(\u03c0, F1, F2) and S(\u03c0, F1, F2) for each policy \u03c0 \u2208 \u03a0k in epoch k. After that, we bound the regret and unfairness of each policy remaining in \u03a0k+1, and therefore bound the regret and unfairness of epoch (k + 1) with high probability. Finally, we show that optimal fair policy \u03c0\u2217 (defined in (5)) is also in \u03a0k+1, which matches the induction assumption for Epoch (k + 1). By adding up these performance over epochs, we get the cumulative regret and unfairness respectively. Please refer to Appendix B.1 for a detailed proof.\nRemark 7. Our algorithm guarantees O( \u221a T log log T ) regret and unfairness simultaneously, whose average-over-time match the generic estimation error of O( 1\u221a T ). It implies that these\nfairness constraints do not bring informational obstacles to the learning process. In fact, these upper bounds are tight up to O(log log T ) factors, which are shown in Theorem 8 and Theorem 9."
        },
        {
            "heading": "5.2 Regret Lower Bound",
            "text": "Here we show the regret lower bound of this pricing problem.\nTheorem 8 (Regret lower bound). Assume d \u2264 T 13 . Given the online two-group fair pricing problem and the regret definition as (6), any algorithm would at least suffer an \u2126( \u221a dT ) regret.\nWe may prove Theorem 8 by a reduction to online pricing problem with no fairness constraints: Given a problem setting where the two groups are identical, i.e. F1(i) = F2(i), \u2200i \u2208 [d], and let q = 0.5. Notice that any policy satisfying \u03c01 = \u03c02 is fair, and the optimal policy is to always propose the best fixed price. Therefore, this can be reduced to an online identical-product pricing problem, and we present a bandit-style lower bound proof in Appendix B.2 inspired by Auer et al. [2002b]."
        },
        {
            "heading": "5.3 Unfairness Lower Bound with Optimal Revenue",
            "text": "Here we show that any optimal algorithm has to suffer an \u2126( \u221a T ) substantive unfairness.\nTheorem 9 (Substantive Unfairness Lower Bound). For any constant Cx, there exists constants Cu > 0 such that any algorithm with an Cx \u00b7 T 1 2 cumulative regret and zero procedural unfairness has to suffer an Cu \u00b7 T 1 2 substantive unfairness.\nIt is worth mentioning that this result is different from ordinary lower bounds on the regret, as it also requires the algorithm to be optimal. In general, we propose 2 different problem settings, and we show the following four facts:\n\u2022 No algorithm can perform well in both settings.\n\u2022 Any algorithm cannot distinguish between the two settings very efficiently.\n\u2022 Not trying to distinguish between them would suffer either a very large regret or a very large substantive unfairness, and therefore we cannot do this very often.\n\u2022 Having tried but failed in distinguishing between them would definitely lead to a large substantive unfairness.\nIn order to prove this, we make use of Example 1 presented in Section 1. One of the settings is exactly Example 1, and the other one is identical to it except these 0.5 probabilities are now (0.5\u2212 \u03b6) in both groups. We get close-form solutions to both problem settings and\nshow that they are indistinguishable in information theory. Please refer to Appendix B.3 for more details."
        },
        {
            "heading": "6 Discussion",
            "text": "Here we discuss some open issues and potential extensions of this work. For more discussions on settings, techniques and social impacts, please refer to Appendix C.\nImprovement on Technical Assumptions. In this work, we assumed the existence of a lower bound Fmin > 0 of the acceptance rate of all prices for both groups. This assumption is stronger than our expectation, as the seller would not know the highest price that customers would accept. We assume this for two reasons: (1) Without assuming Fe(i) > 0, the substantive unfairness function might be undefined. For instance, if a pricing policy is completely unacceptable in G1 (with no accepted prices) but is acceptable in G2, then is it a fair policy? (2) With a constantly large probability of acceptance, we can estimate every Fe(i) and bound it away from 0 and therefore leads to the Lipschitzness of S(\u03c0, F\u03021, F\u03022). However, there might exist an algorithm that works for Fe(i) > 0 generally and maintains these optimalities as well, which is an open problem to the future.\nFeelings of Fairness in FPA. In our FPA algorithm, notice that we run each \u03c0\u0303 \u2208 Ak for a continuous batch of \u03c4k|Ak| = \u2126( \u221a T \u00b7 2k), which is long enough for customers to experience the fairness by comparing their proposed prices and accepted prices with customers from the other group.\nRelaxation on Substantive Fairness. In this work, our algorithm approached the optimal policy as the solution of (5) through an online learning framework. This ensures an asymptotic fairness as T \u2192 +\u221e, but we still cannot guarantee an any-time fair algorithm precisely. Therefore, it is more practical to consider the following inequality-constraint optimization problem:\n\u03c0\u03b4,\u2217 = argmax \u03c0=(\u03c01,\u03c02)\u2208\u03a0 R(\u03c0;F1, F2) s.t. U(\u03c0) = 0, S(\u03c0;F1, F2) \u2264 \u03b4. (9)\nComparing (5) with (9), we know that R(\u03c0\u2217) \u2264 R(\u03c0\u03b4,\u2217). According to Lemma 14, we further know that R(\u03c0\u2217) \u2265 R(\u03c0\u03b4,\u2217)\u2212 L \u00b7 \u03b4. Naturally, the substantive unfairness definition is now max{0, S(\u03c0;F1, F2)\u2212 \u03b4}. If we still consider this problem under the framework of online learning, then two questions arose naturally: What are the optimal regret rate and (substantive) unfairness rate like? And how can we achieve them simultaneously? From our results in this work, we only know that (1) If \u03b4 = 0, then both rates are \u0398( \u221a T ), and (2) if \u03b4 \u2265 1, then the optimal regret is \u0398( \u221a T ) and the optimal unfairness is 0 (as it is reduced\nto the unconstrained pricing problem). In fact, for \u03b4 = O( \u221a 1/T ), we may still achieve\nO( \u221a T ) regret and unfairness, but it is not clear if they are always optimal. For \u03b4 > \u221a 1/T , we conjecture that the optimal regret is still \u0398( \u221a T ) and the optimal unfairness could be \u0398(1/( \u221a T\u03b4)).\nOptimal Policy on the Continuous Space. In this work, we restrict our price choices in a fixed price set V = {v1, v2, . . . , vd} and aims at the optimal distributions on these vi\u2019s. However, if we are allowed to propose any price within [0, 1], then the optimal policy could be a tuple of two continuous distributions that outperforms any policy restricted on V. Even if we know that customers\u2019 valuations are all from V, the optimal policy is not necessarily located inside V due to the fairness constraints. This optimization problem is even harder than (5), and the online-learning scheme further increases its hardness. Existing methods such as continuous distribution discretization [Xu and Wang, 2022] might work, but would definitely lead to an exponential time complexity."
        },
        {
            "heading": "7 Conclusion",
            "text": "In this work, we studied the online pricing problem with fairness constraints. We introduced two fairness notions, a procedural fairness and a substantive fairness indicating the equality of proposed and accepted prices between two different groups respectively. In order to fulfill these two constraints simultaneously, we adopted random pricing policies and established the objective function and rewards in expectation. To solve this problem with unknown demands, we designed a policy-elimination-based algorithm, FPA, that achieves an O\u0303( \u221a T ) regret within an O\u0303( \u221a T ) unfairness. We showed that our algorithm is optimal up to log log T factors by proving an \u2126( \u221a T ) regret lower bound and an \u2126( \u221a T ) unfairness lower bound for any optimal algorithm with an O( \u221a T ) regret.\nAPPENDIX"
        },
        {
            "heading": "A More Related Works",
            "text": "This part serves as a complement to Section 2.\nDynamic Pricing Single product dynamic pricing problem has been well-studied through Kleinberg and Leighton [2003], Besbes and Zeevi [2009], Wang et al. [2014], Chen et al. [2019], Wang et al. [2021]. The crux is to learn and approach the optimal of a revenue curve (in continuous price space) from Boolean-censored feedback. Kleinberg and Leighton [2003] studies this problem under three settings: noise-free, infinitely smooth and stochastic/adversarial valuation assumptions, and proves \u0398(log log T ), \u0398( \u221a T ) and \u0398(T 23 ) minimax regret bounds, sequentially. Wang et al. [2021] further proves a \u0398(T K+1\n2K+1 ) minimax regret bound for Kth-smooth revenue functions. The key to these problem is to parametrize the revenue curve and estimate these parameters to bound the error. Therefore, a smoothness assumption would reduce the number of local parameters necessary for trading-off the information loss caused by randomness.\nThere are recently a variety of works on feature-based dynamic pricing problems [Cohen et al., 2020, Leme and Schneider, 2018, Javanmard and Nazerzadeh, 2019, Xu and Wang, 2021, Liu et al., 2021, Fan et al., 2021, Xu and Wang, 2022] where the sellers are asked to sell different products and set prices according to each of their features. All of these literatures listed above adopt a linear feature, i.e., customer\u2019s (expected) valuations are linearly dependent on the feature with fixed parameters. In specific, there are a few different problem settings:\n1. When customer\u2019s valuations are deterministic, Cohen et al. [2020] proposes a binarysearch-based algorithm and achieves a O(log T ) regret, which is later improved by Leme and Schneider [2018] with a better O(d log log T ) regret that matches the information-theoretic lower bound even for the single product pricing problem.\n2. When customers\u2019 valuations are linear and noisy. For the setting where the noise distribution is known to the seller, Javanmard and Nazerzadeh [2019] and Xu and Wang [2021] achieves the optimal O(d log T ) regret in stochastic and adversarial settings respectively. Javanmard and Nazerzadeh [2019] further achieves O( \u221a dT )\nregret for unknown but parametric noise distributions, which is also optimal according to Xu and Wang [2021]. For totally unknown noise, Xu and Wang [2022] shows a O(T 34 ) regret in the non-continuous case while Fan et al. [2021] proves a O(T 2K+1 4K\u22121 ) for Kth-smooth noises, and both of them are not likely to be optimal (where the current lower bounds are \u2126(T 23 ) and \u2126(T K+1 2K+1 ) respectively).\nFairness in Machine Learning Fairness is a long-existing topic that has been extensively studied. In machine learning society, fairness is defined from different perspectives. On the one hand, the concept of group fairness requires different groups to receive identical treatment in statistics. In a classification problem, for instance, there are mainly two different types of group fairness: (1) A \u201cdemographic parity\u201d [Dwork et al., 2012] that requires the outcome of a classifier to be statistically independent to the group information, and (2) an \u201cequalized odds\u201d (including \u201cequal opportunity\u201d as a relaxation) [Hardt et al., 2016] that requires the prediction of a classifier to be conditionally independent to the group information given the true label. In Agarwal et al. [2018], these probabilistic constraints are further modified as linear constraints, and therefore the fair classification problem is reduced to a cost-sensitive classification problem. It is worth mentioning that Agarwal et al. [2018] allows an k-unfairness due to the learning error and assumes k = O(n\u2212\u03b1) with some \u03b1 \u2264 12 , while we quantify the learning-caused unfairness and upper and lower bound the cumulative unfairness without pre-assuming its scale.\nOn the other hand, [Dwork et al., 2012] also proposes the concept of \u201cindividual fairness\u201d (or \u201cLipschitz property\u201d) where the difference of treatments toward two individuals should be upper bounded by a distance metric of their intrinsic features, i.e., D(\u00b5x, \u00b5y) \u2264 d(x, y) where x, y are features and \u00b5x, \u00b5y are the distributions of actions onto x and y respectively. The notion \u201ctime fairness\u201d is often considered as individual fairness as well. For a more inclusive review on different definitions of fairness in machine learning, please refer to Barocas et al. [2017].\nFairness in Online Learning Besides existing works on general machine learning fairness, there are some works that study online-learning or bandit problems. This is similar to our setting as we adopt an online pricing process. Among these works, Joseph et al. [2016] studies multi-armed and contextual bandits with fairness constraints. Their non-contextual setting is related to our works as our pricing problem can also be treated as a bandit. Their definition of \u03b4-fairness is defined as comparisons among probabilities of taking actions, which is similar to our definition on procedural fairness. However, their fairness definitions are defined from the perspective of arms (i.e. actions): better actions worth larger probability to take. In comparison, our fairness definitions are more on the results: different groups share the same expected prices. Bechavod et al. [2020] studies an online learning (in specific, an online classification) problem with unknown and non-parametric constraints on individual fairness at each round. They develop an adaptive algorithm that guarantees an O( \u221a T ) regret as well as an O( \u221a T ) cumulative fairness loss. However, their problem settings are quite different from ours. Primarily, they assume individual fairness as a constraint, while our fairness definitions are indeed group fairness. Also, their online classification problem is different from our online pricing problem as they have full access to the regret function while we even do not have full-information reward (i.e., which is Boolean-censored). Similarly, their fairness loss is accessible although the unfair pairs of (\u03c41, \u03c42) are not fully\naccessible, while in our settings we do not know the S(\u03c0;F1, F2) function at all. Besides, we have to satisfy two constraints at one time and one of them (the substantive fairness) is highly non-convex. Gupta and Kamble [2021] studies an online learning problem with two different sorts of individual fairness constraints over time: a \"fairness-across-time\" (FT) and a \"fairness-in-hindsight\" (FH). They show that it is necessary to have a linear regret under FT constraints, and they also propose a CAFE algorithm that achieves an optimal regret under FH constraints.\nDespite the specific properties of fairness constraints, we may also consider the framework of constraint online learning. Yu et al. [2017] studies an online convex optimization (OCO) problem with stochastic constraints, which might be applicable to online fair learning. However, their problem settings and methodologies are largely different from ours: Firstly, their constraints are assumed convex while our substantive fairness constraint (i.e., the S(\u03c0;F1, F2) function) is highly non-convex. Also, they have a direct access to the realized objective function f t(xt) at each time while our pricing problem only has a Boolean-censored feedback. More importantly, Yu et al. [2017] assumes the availability of unbiased samples on constraint-related variables. In specific, their constraints are roughly gk(x) < 0, and by the end of each period t they receive an unbiased sample of gk(xt) for the xt they have taken. On the contrary, we do not have any unbiased sample of S(\u03c0, F1, F2) at each time, since there is only one customer from one of the two groups. Therefore, we cannot make use of their results in our problem setting.\nFairness in Pricing There are some works also studying the fairness problem in dynamic pricing besides of the works we discuss in Section 2. For example, Richards et al. [2016] discusses some fairness issues regarding personalized pricing from the perspective of econometrics. Eyster et al. [2021] studies a phenomenon where customers would mistakenly attribute the cost increases to a time unfairness, and they propose methods to release customer\u2019s feeling of such unfairness by adjusting prices correspondingly. Chapuis [2012] looked into two fairness concerns called price fairness and pricing fairness, which indicates the distributional and procedural fairness of the pricing process respectively, from the seller\u2019s perspective. In fact, their price fairness is more likely to be our procedural fairness definition although it is not in their paper. This is because that we are considering the fairness from customers\u2019 perspective, where their observations on prices serve as a procedure of their decision process and their decision on whether or not to buy is actually indicating the fairness of results. There are more interesting works as is listed in Section 2, and we refer the readers to Chen et al. [2021] where there is a more comprehensive review on pricing and fairness."
        },
        {
            "heading": "B Proof Details",
            "text": "B.1 Proof of Theorem 6\nProof. First of all, we specify the parameters initialized in Algorithm 1: Let Cq = 3 max{1q , 1 1\u2212q} and ct = max{3,\n\u221a 3\nF\u0302min }. For k = 1, 2, . . ., let \u03c4k = 28Cq3 \u00b7 d\n\u221a T log(16d log T ) \u00b7\n2k, \u03b4k,r = 4ct log 16d log T d 3 2 \u221a Cq \u03c4k , \u03b4k,s = 32ct(F\u0302min)2 log 16d log T d 3 2 \u221a Cq \u03c4k . Now we prove that F\u0302min \u2264 Fmin with high probability. Recall than Cq = 3 max{1q , 1\n1\u2212q}. Recall that \u03c40 = 2 log T log 16 . According to Hoeffding\u2019s Inequality, we have:\nPr[|F\u03041(d)\u2212 F1(d)| \u2265 F1(d) 2 ] \u22642 exp{\u22122( F1(d) 2 ) 2 \u00b7 1 Cq \u03c40} \u21d4 Pr[F1(d)2 \u2264 3F1(d) 2 ] \u22651\u2212 2 exp{\u2212(F1(d)) 2 1 Cq log T log 16 }\n\u22651\u2212 8 .\n(10)\nHere the last inequality comes from Assumption 1 that F1(d) \u2265 Fmin > 0 and therefore we have (Fmin)2 1Cq log T \u2265 1 with large T . Therefore, we have F1(d) 2 F\u03041(d) \u2264 3F1(d) 2 with probability at least 1\u2212 8 . Similarly, we have F2(d) 2 F\u03042(d) \u2264 3F2(d)\n2 with probability at least 1\u2212 8 . Therefore, with Pr \u2265 1\u2212 4 , we have F\u0302min = 1 2 min{F\u03041(d), F\u03042(d)} \u2264 min{ 3F1(d) 4 , 3F2(d) 4 } = 3 4Fmin < Fmin.\nWe define some notations that are helpful to our proof. In epoch k, recall that we have:\n\u03c0\u0303k,i,e = argmax \u03c0\u2208\u03a0k \u03c0e(i). (11)\nFor simplicity, for every i \u2208 Iek, denote \u03c1k,e(i) := \u03c0\u0303ek,i,e(i) that is the largest probability of choosing price vi in Ge among all policies in \u03a0k. For those i /\u2208 Iek, we find out the largest k\u2032 such that i \u2208 Iek\u2032 and let \u03c1k,e(i) := \u03c0\u0303ek\u2032,i,e(i). According to the fact that \u03a0 = \u03a01 \u2283 \u03a02 \u2283 . . . \u2283 \u03a0k \u2283 \u03a0k+1 \u2283 . . ., we have\n\u03c0e(i) \u2264 \u03c1k,e(i), \u2200\u03c0 \u2208 \u03a0k; e = 1, 2; i \u2208 [d]. (12)\nNext, we prove the following lemmas together by induction over epoch index k = 1, 2, . . .. We firstly state that\nLemma 10. Recall the optimal policy \u03c0\u2217 defined in (5). Before Epoch k, we have \u03c0\u2217 \u2208 \u03a0k with high probability (the failure probability will be totally bounded at the end of this proof).\nwhich is natural at k = 1 as \u03a01 = \u03a0. Now, suppose Lemma 10 holds for \u2264 k, then we have:\nLemma 11 (Number of Choosing vi in Ge). For Mk,e(i) and Nk,e(i) defined in Algorithm 1, for any e = 1, 2; i \u2208 Iek, with Pr \u2265 1\u2212 2 log T we have:\n\u03c1k,e(i) \u00b7 \u03c4k 4d \u00b7 Cq \u2264Mk,e(i),\n|Nk,e(i)\u2212Mk,e(i) \u00b7 Fe(i)| \u2264ct \u00b7 \u221a Fe(i) \u00b7Mk,e(i) \u00b7 log 16d log T .\n(13)\nHere ct = max{3, \u221a\n3 F\u0302min }.\nProof of Lemma 11. For any i \u2208 Iek, there exists a policy \u03c0\u0303k,i,e running in Epoch k for at least \u03c4k |Ak| rounds, and. Therefore, we have E[Mk,e(i)] \u2265 \u03c1k,e(i)\u00b7 \u03c4k |Ak| \u00b7min{q, 1\u2212q} \u2265 \u03c1k,e(i)\u00b7 \u03c4k |Ak|\u00b7Cq . According to Bernstein\u2019s Inequality, for any e = 1, 2; i \u2208 Iek we have:\nPr[|Mk,e(i)\u2212 E[Mk,e(i)]| \u2264 E[Mk,e(i)]\n2 ]\n\u22651\u2212 2 exp{\u2212 1 2( E[Mk,e(i)] 2 )2\u2211 \u03c4k|Ak|\nt=1 \u03c1k,e(i) \u00b7 1Cq (1\u2212 \u03c1k,e(i) \u00b7 1 Cq ) + 13 \u00b7 1 \u00b7 E[Mk,e(i)] 2\n}\n\u22651\u2212 2 exp{\u2212 1 8(E[Mk,e(i)])2\n\u03c1k,e(i) \u00b7 \u03c4k|Ak|Cq + 1 6 \u00b7 E[Mk,e(i)]\n}\n\u22651\u2212 2 exp{\u2212 1 8(E[Mk,e(i)])2\nE[Mk,e(i)] + 16 \u00b7 E[Mk,e(i)] }\n=1\u2212 2 exp{\u2212 1 8 \u00b7 76 E[Mk,e(i)]} \u22651\u2212 2 exp{\u2212 328\u03c1k,e(i) \u00b7 \u03c4k |Ak| \u00b7 Cq } =1\u2212 2 exp{\u2212 328\u03c1k,e(i) \u00b7 28 3 \u00b7 d \u221a T log(16d log T ) \u00b7 2k 2d \u00b7 Cq } =1\u2212 2 exp{\u2212\u03c1k,e(i) \u221a T \u00b7 log(16d log T ) \u00b7 d \u00b7 2 k\n2d }\n\u22651\u2212 2 exp{\u2212 log(16d log T )}\n=1\u2212 2 \u00b7 16d log T =1\u2212 8d log T .\n(14)\nHere the second line is because that \u03c4k\u2211 t=1 E[(1(choosing vi at time t))2] \u2264 \u03c4k |Ak|\u2211 t=1 E[(1( running \u03c0\u0303k,i,e and choosing vi at time t))]\n, the third line is for 1\u2212 \u03c1k,e(i) \u00b7 1Cq \u2264 1, the fourth and sixth line are from E[Mk,e(i)] \u2265 \u03c1k,e(i)\u00b7\u03c4k |Ak|\u00b7Cq , the seventh line is by plugging in \u03c4k = 28Cq 3 \u00b7 d \u221a T log(16d log T ) \u00b7 2k, the eighth line is equivalent transformation and the ninth line is for \u03c1k,e(i) \u2265 1\u221aT according to Line 9 of Algorithm 1. As a result, with probability at least 1\u2212 8d log T , we have\nMk,e(i) \u2265 E[Mk,e(i)] 2 \u2265 \u03c1k,e(i) \u00b7 \u03c4k |Ak| \u00b7 Cq \u2265 \u03c1k,e(i) \u00b7 \u03c4k4dCq . (15)\nNow, we analyze Nk,e(i) for i \u2208 Iek. Again, from Line 15 of Algorithm 1 we know that Nk,e(i) = \u2211Mk,e(i) t=1 1(vt is accepted in Ge). Therefore, we apply Bernstein\u2019s Inequality and get:\nPr[|Nk,e(i)\u2212Mk,e(i) \u00b7 Fe(i)| \u2265 ct \u00b7 \u221a Mk,e(i) \u00b7 Fe(i) log 16d log T ]\n\u22642 exp{\u2212 1 2c 2 t \u00b7Mk,e(i)Fe(i)(log 16d log T )2\nMk,e(i)Fe(i) log 16d log T (1\u2212 Fe(i)) + 1 3 \u00b7 (ct \u00b7 \u221a Mk,e(i) \u00b7 Fe(i) log 16d log T ) }\n\u22642 exp{\u2212 1 2c 2 t log 16d log T\n1 + ct3 }\n\u2264 8 log T .\nHere the last line is by ct = max{3, \u221a\n3 F\u0302min } \u2265 3 and therefore\n1 2 c 2 t\n1+ ct3 \u2265 1. As a result, for\ne = 1, 2; i \u2208 Iek, with Pr \u2265 1\u2212 8 log T we have\n|Nk,e(i)\u2212Mk,e(i) \u00b7 Fe(i)| \u2264 ct \u00b7 \u221a Mk,e(i)Fe(i) log 16d log T .\nThat is to say,\n|F\u0304k,e(i)\u2212 Fe(i)| = |max{ Nk,e(i) Mk,e(i) , F\u0302min} \u2212 Fe(i)|\n\u2264 |Nk,e(i) Mk,e(i) |\n\u2264 ct \u00b7 \u221a\nFe(i) Mk,e(i) log 16d log T\n\u2264 ct log 16d log T \u221a Fe(i) \u00b7 \u221a 4dCq\n\u03c1k,e(i)\u03c4k .\nHere the first line is by definition of F\u0304k,e, the second line is because F\u0302min \u2264 Fmin \u2264 Fe(i), the third line is by the inequality above and the last line is by (15). Therefore, with Pr \u2265 1\u2212 2 log T , (13) holds for e = 1, 2 and for \u2200i \u2208 Iek.\nGiven Lemma 11, we have the following corollary directly:\nCorollary 12 (Estimation Error of F\u0304k,e(i)). Assume that Lemma 11 holds. For F\u0304k,e(i) = max{Nk,e(i)Mk,e(i) , F\u0302min} defined in Algorithm 1, for any e = 1, 2; i \u2208 I e k, we have:\n|F\u0304k,e(i)\u2212 Fe(i)| \u2264 ct \u00b7 log 16d log T \u221a 4dFe(i)Cq \u03c1k,e(i)\u03c4k . (16)\nFor simplicity, denoteR(\u03c0) := R(\u03c0, F1, F2), S(\u03c0) := S(\u03c0, F1, F2), R\u0302k(\u03c0) := R(\u03c0, F\u0304k,1, F\u0304k,2) and S\u0302k(\u03c0) := S(\u03c0, F\u0304k,1, F\u0304k,2). Based on Corollary 12, we can bound the estimation error of R\u0302k(\u03c0) and S\u0302k(\u03c0) by the following lemma:\nLemma 13 (Estimation Error of R and S Functions). Given Lemma 11, we have:\n|R(\u03c0)\u2212 R\u0302k(\u03c0)| \u2264 \u03b4k,r 2 ,\n|S(\u03c0)\u2212 S\u0302k(\u03c0)| \u2264 \u03b4k,s 2 .\n(17)\nHere \u03b4k,r = 4ct log 16d log T d 3 2 \u221a Cq \u03c4k and \u03b4k,s = 32ctF\u0302 2min log 16d log T d 3 2 \u221a 1 \u03c4k\nas is defined in Theorem 6.\nProof of Lemma 13. First of all, we show that for any e = 1, 2; i = 1, 2, . . . , d and for any \u03c0 \u2208 \u03a0k,\n|F\u0304k,e(i)\u2212 Fe(i)| \u00b7 \u03c0e(i) \u2264 ct \u00b7 log 16d log T \u221a 4dCq \u03c4k . (18)\nIn fact, when i \u2208 Iek, according to Lemma 11 we have\n|F\u0304k,e(i)\u2212 Fe(i)| \u00b7 \u03c0e(i) \u2264|F\u0304k,e(i)\u2212 Fe(i)| \u00b7 \u03c1k,e(i)\n\u2264ct \u00b7 log 16d log T \u221a 4dFe(i)Cq \u03c1k,e(i)\u03c4k \u00b7 \u03c1k,e(i)\n\u2264ct \u00b7 log 16d log T\n\u221a 4dCq \u00b7 (\u03c1k,e(i))\n\u03c4k\n\u2264ct \u00b7 log 16d log T \u221a 4dCq \u03c4k .\n(19)\nWhen i /\u2208 Iek, we know that \u03c1k,e(i) \u2264 1\u221aT and thus \u03c0 e(i) \u2264 1\u221a T , \u2200\u03c0 \u2208 \u03a0k according to (12). Also, since \u03c0\u2217 \u2208 \u03a0k by induction, we know that \u03c0e\u2217 \u2264 \u03c1k,e(i) \u2264 1\u221aT . Therefore, we have\n|F\u0304k,e(i)\u2212 Fe(i)| \u00b7 \u03c0e(i) \u2264|F\u0304k,e(i)\u2212 Fe(i)| \u00b7 \u03c1k,e(i)\n\u2264|F\u0304k,e(i)\u03c0e(i)\u2212 Fe(i)| \u00b7 1\u221a T \u22641 \u00b7 1\u221a T\n\u2264ct \u00b7 log 16d log T \u221a 4dCq \u03c4k .\n(20)\nHere we assume that log 16d log T > 1 without losing of generality (i.e., T is sufficiently large and can be arbitrarily close to zero), and the last inequality comes from ct \u2265 3 > 1 and 4d \u2265 1 and \u03c4k \u2264 T . Combining (19) and (20), we know that (18) holds for all e = 1, 2; i \u2208 [d]. Remember that R(\u03c0) = q \u00b7\u2211di=1 F1(i)\u03c01(i) + (1\u2212 q) \u00b7\u2211dj=1 F2(j)\u03c02(j) and that R\u0302k(\u03c0) = q \u00b7 \u2211d i=1 F\u0304k,1(i)\u03c01(i) + (1\u2212 q) \u00b7 \u2211d j=1 F\u0302k,2(j)\u03c02(j). Therefore, we may bound the error between R\u0302k(\u03c0) and R(\u03c0). For \u2200\u03c0 \u2208 \u03a0k, we have\n|R\u0302k(\u03c0)\u2212R(\u03c0)| \u2264 q \u00b7 d\u2211 i=1 |F\u0304k,1(i)\u2212 F1(i)| \u00b7 \u03c01(i) + (1\u2212 q) \u00b7 d\u2211 j=1 |F\u0304k,2(j)\u2212 F2(j)| \u00b7 \u03c02(i)\n\u2264 q \u00b7 d\u2211 i=1 ct \u00b7 log 16d log T \u221a 4dCq \u03c4k + (1\u2212 q) \u00b7 d\u2211 j=1 ct \u00b7 log 16d log T \u221a 4dCq \u03c4k\n= ct \u00b7 log 16d log T \u221a 4dCq \u03c4k \u00b7 d\n= \u03b4k,r2 . (21)\nSimilarly, for the error between S\u0302k(\u03c0) and S(\u03c0) as \u03c0 \u2208 \u03a0k, we have:\n|S\u0302k(\u03c0)\u2212 S(\u03c0)| =|| v>F\u0302k,1\u03c01 1>F\u0302k,1\u03c01 \u2212 v >F\u0302k,2\u03c0 2 1>F\u0302k,2\u03c02 | \u2212 |v >F1\u03c0 1 1>F1\u03c01 \u2212 v >F2\u03c0 2 1>F2\u03c02 ||\n\u2264|v >F\u0302k,1\u03c0 1 1>F\u0302k,1\u03c01 \u2212 v >F\u0302k,2\u03c0 2 1>F\u0302k,2\u03c02 \u2212 (v >F1\u03c0 1 1>F1\u03c01 \u2212 v >F2\u03c0 2 1>F2\u03c02 )|\n\u2264|v >F\u0302k,1\u03c0 1 1>F\u0302k,1\u03c01 \u2212 v >F1\u03c0 1 1>F1\u03c01 |+ |v >F\u0302k,2\u03c0 2 1>F\u0302k,2\u03c02 \u2212 v >F2\u03c0 2 1>F2\u03c02 | = 2\u2211 e=1 |v >F\u0302k,e\u03c0 e 1>F\u0302k,e\u03c0e \u2212 v >Fe\u03c0 e 1>Fe\u03c0e |\n= 2\u2211 e=1 |(v >F\u0302k,e\u03c0 e)(1>Fe\u03c0e)\u2212 (v>Fe\u03c0e)(1>F\u0302k,e\u03c0e) (1>F\u0302k,e\u03c0e)(1>Fe\u03c0e) |\n= 2\u2211 e=1 |(\u03c0e)>(F\u0302k,e \u2212 Fe)v \u00b7 (1>Fe\u03c0e) + (v>Fe\u03c0e)1>(Fe \u2212 F\u0302k,e)\u03c0e| |(1>F\u0302k,e\u03c0e)| \u00b7 |(1>Fe\u03c0e)|\n\u2264 2\u2211 e=1\n(1>Fe\u03c0e) \u00b7 \u2211d i=1 \u03c0 e(i)(F\u0304k,e(i)\u2212 Fe(i))vi + (v>Fe\u03c0e) \u00b7 \u2211d j=1 1 \u00b7 (Fe(j)\u2212 F\u0302k,e(j)) \u00b7 \u03c0e(j)\n|F\u0302min| \u00b7 |F\u0302min|\n\u2264 2\u2211 e=1 1 \u00b7\u2211di=1 \u03c0e(i)|F\u0304k,e(i)\u2212 Fe(i)| \u00b7 1 + 1 \u00b7\u2211dj=1 1 \u00b7 |Fe(j)\u2212 F\u0302k,e(j)|\u03c0e(j) (F\u0302min)2\n\u2264 1 (F\u0302min)2 2\u2211 e=1 ( d\u2211 i=1 ct \u00b7 log 16d log T \u221a 4dCq \u03c4k + d\u2211 j=1 ct \u00b7 log 16d log T \u221a 4dCq \u03c4k )\n= 1 (F\u0302min)2 \u00b7 2d \u00b7 ct \u00b7 log 16d log T \u221a 4dCq \u03c4k\n\u2264\u03b4k,s2 . (22)\nSince we have S\u0302k(\u03c0) \u2264 \u03b4k,s,\u2200\u03c0 \u2208 \u03a0k+1 by definition in Algorithm 1, we know that for any policy \u03c0 \u2208 \u03a0k+1,\nS(\u03c0) =S\u0302k(\u03c0) + (S(\u03c0)\u2212 S\u0302k(\u03c0)) \u2264S\u0302k(\u03c0) + |S(\u03c0)\u2212 S\u0302k(\u03c0)|\n\u2264\u03b4k,s + \u03b4k,s 2 \u22642\u03b4k,s.\n(23)\nTherefore, any policy remaining in \u03a0k+1 suffers at most 2\u03b4k,s unfairness. Now let us bound the regret of any policy in \u03a0k+1. Here we firstly propose a lemma.\nLemma 14 (Small Relaxation Gain). Recall that \u03c0\u2217 is the solution to (5). Define a \u03c0\u03b4,\u2217 as follows.\n\u03c0\u03b4,\u2217 = argmax \u03c0\u2208\u03a0 R(\u03c0)\ns.t. S(\u03c0) \u2264 \u03b4. (24)\nThen there exists a constant L \u2208 R+ such that R(\u03c0\u03b4,\u2217)\u2212R(\u03c0\u2217) \u2264 L2 \u00b7 \u03b4.\nWe leave the proof of Lemma 14 to the end of this section. Given Lemma 14 and the previous Lemma 13, we have:\nR\u0302(\u03c0\u0302k,\u2217)\u2212 R\u0302(\u03c0\u2217) =R\u0302(\u03c0\u0302k,\u2217)\u2212R(\u03c0\u0302k,\u2217) +R(\u03c0\u0302k,\u2217)\u2212R(\u03c02\u03b4k,s,\u2217) +R(\u03c02\u03b4k,s , \u2217)\u2212R(\u03c0\u2217) +R(\u03c0\u2217)\u2212 R\u0302(\u03c0\u2217) \u2264|R\u0302(\u03c0\u0302k,\u2217)\u2212R(\u03c0\u0302k,\u2217)|+ (R(\u03c0\u0302k,\u2217)\u2212R(\u03c02\u03b4k,s,\u2217)) + (R(\u03c02\u03b4k,s , \u2217)\u2212R(\u03c0\u2217)) + |R(\u03c0\u2217)\u2212 R\u0302(\u03c0\u2217)|\n\u2264\u03b4k,r2 + 0 + L 2 \u00b7 2\u03b4k,s + \u03b4k,r 2 =\u03b4k,r + L \u00b7 \u03b4k,s (25)\nBy definition of \u03a0k+1 at (8), we know that \u03c0\u2217 \u2208 \u03a0k+1, which holds Lemma 10 at k+ 1 and therefore completes the induction. As a result, all Lemma 10, Lemma 11, Lemma 13 and Lemma 14 holds for all k = 1, 2, . . .. As a result, we may calculate the total regret and substantive unfairness as follows.\nFor the regret, we may divide the whole time horizon T into three stages:\n1. Stage 0: Before epochs where we propose vd for \u03c40 = 2 log T log 16 rounds in either G1 or G2. The regret for this stage is O(log T log 1 ).\n2. Stage 1: Epoch 1 where we try every price for 2 \u00b7 \u03c412d rounds in either G1 or G2. The regret for this stage is O(\u03c41) = O(d \u221a T log log T ).\n3. Stage 2: Epoch k = 2, 3, . . .. In each epoch k, every policy \u03c0 we run satisfies \u03c0 \u2208 \u03a0k. Therefore, for any \u03c0 running in Epoch k = 2, 3, . . ., we have\nR(\u03c0\u2217)\u2212R(\u03c0) =(R(\u03c0\u2217)\u2212 R\u0302k\u22121(\u03c0\u2217)) + (R\u0302k\u22121(\u03c0\u2217)\u2212 R\u0302k\u22121(\u03c0)) + (R\u0302k\u22121(\u03c0)\u2212R(\u03c0))\n\u2264\u03b4k\u22121,r2 + (\u03b4k\u22121,r + L \u00b7 \u03b4k\u22121,s) + \u03b4k\u22121,r\n2 =2\u03b4k\u22121,r + L \u00b7 \u03b4k\u22121,s.\n(26)\nThe second line is by definition of \u03a0k for k \u2265 2 and by Lemma 13. Suppose there are K epochs in total, and then we know that:\nT \u2265 K\u2211 k=1 \u03c4k = 28Cq 3 \u00b7 d \u221a T \u00b7 log 16d log T \u00b7 K\u2211 k=1 2k.\nSolve the equaltion above and we get K = O(log \u221a T\nd log d logT ) and K \u2264 12 log T . Therefore, the total regret of Stage 2 is\nReg = O( K\u2211 k=2 \u03c4k \u00b7 (2\u03b4k\u22121,r + L \u00b7 \u03b4k\u22121,s)) = O( \u221a T \u00b7 d 3 2 log d log T ) (27)\nAdd the regret of all three stages above, we get that the total regret is O( \u221a T \u00b7 d 3 2 log d log T ).\nFor the unfairness, we derive it similarly in three stages:\n1. Stage 0: Before epochs where we propose vd for \u03c40 = 2 log T log 16 rounds in either G1 or G2. The unfairness for this stage is 0 as we always propose the same price to both groups.\n2. Stage 1: Epoch 1 where we try every price for 2 \u00b7 \u03c412d rounds in either G1 or G2. The regret for this stage is 0 as well.\n3. Stage 2: Epoch k = 2, 3, . . .. In each epoch k, every policy \u03c0 we run satisfies \u03c0 \u2208 \u03a0k. Therefore, for any \u03c0 running in Epoch k = 2, 3, . . ., we have\nS(\u03c0) =S\u0302k\u22121(\u03c0) + (S(\u03c0)\u2212 S\u0302k\u22121(\u03c0))\n\u2264\u03b4k\u22121,s + \u03b4k\u22121,s 2 \u22643\u03b4k\u22121,s2 .\n(28)\nHere the last line is by definition of \u03a0k for k \u2265 2 and by Lemma 13. Therefore, the total unfairness of Stage 2 is\nUnf \u2264 K\u2211 k=2 \u03c4k \u00b7 3\u03b4k\u22121,s 2 = O( \u221a T \u00b7 d 3 2 log d log T ). (29)\nTherefore, the total substantive unfairness of all three stages is O( \u221a T \u00b7 d 3 2 log d log T ) as well.\nFinally, we count the probability of failure of all stages. For Stage 0, the failure probability is Pr0 \u2264 4 . For each epoch, the failure probability is Prk \u2264 2 log T . Since there are K \u2264 log T 2 epochs, the total failure probability is Prfailure \u2264 Pr0 +K \u00b7 Prk \u2264 4 + K \u00b7 2 log T \u2264 2 < . That is to say, Theorem 6 holds with probability at least Pr \u2265 1\u2212 .\nAt the end of this subsection, we prove Lemma 14 as we promised above.\nProof of Lemma 14. Denote any policy \u03c0 \u2208 \u03a0 as \u03c0 = (\u03c01, \u03c02). For the simplicity of notation, we denote the following functions:\n(a) Define R1(\u03c01) = v>F1\u03c01;\n(b) Define R2(\u03c02) = v>F2\u03c02;\n(c) Define S1(\u03c01) = v >F1\u03c01\n1>F1\u03c01 ;\n(d) Define S2(\u03c02)\u2212 v >F2\u03c02\n1>F2\u03c02 .\nFor \u03c0\u03b4,\u2217 defined in (9), denote Vs := S1(\u03c01\u03b4,\u2217) and z = S2(\u03c02\u03b4,\u2217) \u2212 Vs. Therefore, we know that Vs \u2208 [v1, 1] (recalling that v1 > 0) and z \u2208 [\u2212\u03b4, \u03b4]. According to the optimality of \u03c0\u03b4,\u2217, we have:\n\u03c0\u03b4,\u2217 = argmax \u03c0\u2208\u03a0,Vs\u2208[v1,1],z\u2208[\u2212\u03b4,\u03b4] qR1(\u03c01) + (1\u2212 q)R2(\u03c02) s.t. S1(\u03c01) = Vs S2(\u03c02) = Vs + z\n(30)\n. Consider the constraint S2(\u03c02)\u2212 Vs \u2208 [\u2212\u03b4, \u03b4], we can derive the following relaxation:\nS2(\u03c02)\u2212 Vs \u2208 [\u2212\u03b4, \u03b4]\n\u21d4 \u2212\u03b4 \u2264 v >F2\u03c0 2\n1>F2\u03c02 \u2212 Vs \u2264 \u03b4\n\u21d2 \u2212\u03b4(1>F2\u03c02) \u2264 v>F2\u03c02 \u2212 Vs \u00b7 1>F2\u03c02 \u2264 \u03b4(1>F2\u03c02) \u21d2 \u2212\u03b4 \u2264 v>F2\u03c02 \u2212 Vs \u00b7 1>F2\u03c02 \u2264 \u03b4.\n(31)\nThis is because 1>F2\u03c02 \u2208 [Fmin, 1] \u2282 (0, 1]. Therefore, we may define \u03b8\u03b4 = (\u03b81\u03b4 , \u03b82\u03b4) \u2208 \u03a0 such that\n\u03b8\u03b4 := argmax \u03b8\u2208\u03a0,r,w\u2208[v1\u00b7Fmin,1] qR1(\u03b81) + (1\u2212 q)R2(\u03b82)\ns.t. v>F1\u03b81 =w\n\u00b71>F1\u03b81 = w\nVs\nv>F2\u03b82 =r\n\u2212\u03b4 \u2264 v1 \u00b7 1>F2\u03b82 \u2212 r \u00b7 v1 Vs \u2264\u03b4,\n(32)\nfor any \u03b8 \u2265 0. Here we make use of the fact that Vs \u2208 [v1, 1]. Notice that [v1 \u00b7 Fmin, 1] contains all possible r\u2019s due to the fact that Fe(i) > Fmin and vi \u2265 v1 for any i \u2208 [d] and\ne \u2208 {1, 2}, then we have R2(\u03b82\u03b4 ) \u2265 R2(\u03c02\u03b4,\u2217) as a relaxation of conditions, which means that R(\u03b8\u03b4) \u2265 R(\u03c0\u03b4,\u2217). Consider another policy \u03c0start:\n\u03c0start := argmax \u03c0\u2208\u03a0 qR1(\u03c01) + (1\u2212 q)R2(\u03c02)\ns.t. S1(\u03c01) =Vs S2(\u03c02) =Vs.\n(33)\nTherefore, we know that when \u03b4 = 0, we have \u03b80 = \u03c0start exactly. Also, since \u03c0\u2217 can also be defined as follows:\n\u03c0\u2217 = argmax \u03c0\u2208\u03a0,vs\u2208[v1,1] qR1(\u03c01)+(1\u2212 q)R2(\u03c02)\ns.t. S1(\u03c01) =vs S2(\u03c02) =vs.\n(34)\nAccording to the optimality of \u03c0\u2217 over all vs \u2208 [v1, 1] while \u03c0start is restricted on a specific Vs, we have R(\u03c0\u2217) \u2265 R(\u03c0start) = R(\u03b80). Recall that we also have R(\u03b8\u03b4) \u2265 R(\u03c0\u03b4,\u2217). Therefore, as long as we show that there exists a constant L such that R(\u03b8\u03b4)\u2212R(\u03b80) \u2264 L2 \u00b7 \u03b4, then it is sufficient to show that R(\u03c0\u03b4,\u2217)\u2212R(\u03c0\u2217) \u2264 L2 \u00b7 \u03b4.\nDenote \u03b8\u0303\u03b4 = [(\u03b81\u03b4 )>, w,\nw \u00b7 V1 Vs , (\u03b82\u03b4 )>, r, r \u00b7 v1 Vs ]> \u2208 R2d+4. (35)\nOf course \u2016\u03b8\u0303\u03b4\u20161 \u2264 1 + w + wVs + 1 + r + r Vs \u2264 4 + 2 2v1 . Denote the domain of \u03b8\u0303\u03b4 as D(\u03b4). Therefore, we know that for any \u03b8 \u2208 D(\u03b4), we have\n\u03b8 0 [1>d , 0, 0, . . . , 0]\u03b8 = 1\n[0, . . . , 0, 0, 0,1>d , 0, 0]\u03b8 = 1 [0, . . . , 0, 1, 0, . . . , 0]\u03b8 \u2264 1 (for 1 in the (d+ 1)th place) [0, . . . , 0, 1, 0, . . . , 0]\u03b8 \u2264 1 (for 1 in the (d+ 2)th place)\n[0, . . . , 0, 1, 0]\u03b8 \u2264 1 [0, . . . , 0, 0, 1]\u03b8 \u2264 1\n(36)\nDenote D\u0303(\u03b4) as the space of all \u03b8 satisfying (36), and we know that D\u0303(\u03b4) \u2287 D(\u03b4) and D\u0303(\u03b4) is a bounded, close and convex set with only linear boundaries. Also, denote the following\nfixed parameters:\na := [q \u00b7 (v>F1), 0, 0, (1\u2212 q) \u00b7 (v>F2), 0, 0] \u2208 R2d+4\nb1 := [v>F1,\u22121, 0, 0, . . . , 0] \u2208 R2d+4\nb2 := [v11>F1, 0,\u22121, 0, 0, . . . , 0] \u2208 R2d+4\ng := [0, . . . , 0, 0, 0,v>F2,\u22121, 0] \u2208 R2d+4\nd := [0, . . . , 0, 0, 0, v1 \u00b7 1>F2, 0,\u22121] \u2208 R2d+4.\n(37)\nAgain, these parameters are all constants under the same problem setting. Given these parameters, for the definition of \u03b8\u03b4 in (32), we may transform that definition into the following one equivalently:\n\u03b8\u0303\u03b4 := argmax \u03b8\u2208D\u0303(\u03b4)\na>\u03b8\ns.t. b>1 \u03b8 =0 b>2 \u03b8 =0 g>\u03b8 =0 d>\u03b8 \u2208[\u2212\u03b4, \u03b4].\n(38)\nSince D\u0303(\u03b4) \u2287 D(\u03b4), we know that a>\u03b8\u0303\u03b4 \u2265 R(\u03b8\u03b4). Denote\nD\u0303abg(\u03b4) := {\u03b8|\u03b8 \u2208 D\u0303(\u03b4),b>1 \u03b8 = 0,b>2 \u03b8 = 0,g>\u03b8 = 0},\nand we know that D\u0303abg(\u03b4) is also a bounded close and convex set with only linear boundaries. Therefore, (38) is equivalent to the following definition:\n\u03b8\u0303\u03b4 := argmax \u03b8\u2208D\u0303abg(\u03b4)\na>\u03b8\ns.t. d>\u03b8 \u2208 [\u2212\u03b4, \u03b4]. (39)\nNow we present the following lemma.\nLemma 15 (Bounded Shifting). Given any space Q \u2282 Rn that is bounded, close and convex with only linear boundaries, consider the following subset Q0 := {x \u2208 Q, d>x = 0} 6= \u2205. Then there exists a constant CL such that for any z \u2208 R, Qz := {x \u2208 Q, d>x = z} and any \u03b8z \u2208 Qz, there always exists a \u03b80 \u2208 Q0 such that \u2016\u03b8z \u2212 \u03b80\u20162 \u2264 CL \u00b7 |z|.\nProof of Lemma 15. Without loss of generality, we assume that z > 0. Denote Q+ = Q \u2229 {x : d>x \u2265 0}. Because Q is bounded, close and convex with only linear boundaries, the number of vertex of Q+ must be finite. The vertex set of Q+ can be decomposed as V = V0 + V1, where V0 denotes the vertex such that d>x = 0 while V1 denotes the vertex\nsuch that d>x > 0. In addition, Q0 = Q+ \u2229 {x : d>x = 0} is the cross section while we define B = {x : d>x = 0}.\nFor each point x \u2208 Q0, we define \u03b2x to be min{The intersection angle between B and \u2212\u2192xv, v \u2208 V1}. Due to the fact that \u03b2x is continuous upon x, \u03b2x > 0 and the domain Q0 is bounded and close, there exists a \u03b2min > 0 such that \u03b2x \u2265 \u03b2min, \u2200x \u2208 Q0. Then we construct a corresponding cone Conex for each x \u2208 Q0 such that Conex = {v : d>v \u2265 0, and the intersection angle between B and \u2212\u2192xv \u2265 \u03b2min}.\nSince Q+ is bounded, close and convex with only linear boundaries, for any point \u03b8z \u2208 Qz, there exits v1, v2, \u00b7 \u00b7 \u00b7 , vk and a1, a2, \u00b7 \u00b7 \u00b7 , ak such that vi \u2208 V, ai \u2265 0,\u2200i \u2208 [k] and \u2211k i=1 ai = 1\nand it holds that \u03b8z = \u2211k i=1 aivi. Then according to our construction of the cones, for each selected vertex vi, there exists a cone Coneti such that ti \u2208 Q0 and vi \u2208 Coneti . We claim that Cone\u2211k\ni=1 aiti = {\u2211ki=1 aifi : fi \u2208 Coneti}. Therefore, it holds that \u03b8z = \u2211ki=1 aivi \u2208\nCone\u2211k i=1 aiti . Consider this \u03b80 = \u2211k i=1 aiti, because Q0 is convex, we have \u03b80 \u2208 Q0. In addition, \u2016\u03b80 \u2212 \u03b8z\u20162 \u2264 |z|\u2016d\u20162\u00b7sin(\u03b2min) , which means by choosing CL = 1\n\u2016d\u20162\u00b7sin(\u03b2min) , the proof is complete.\nDenote z\u03b4 := \u03b8\u0303\u03b4 and we know that |z\u03b4| \u2264 \u03b4. In order to apply Lemma 15, we have to ensure that D\u0303abg(0) 6= \u2205. In fact, notice that \u03b8\u03030 \u2208 D\u0303abg \u2229 {d> = 0}. With Lemma 15, there exists a \u03b8\u03020 \u2208 D\u0303abg(0) such that \u2016\u03b8\u0303\u03b4 \u2212 \u03b8\u03020\u20162 \u2264 L2 |z| \u2264 L 2 \u03b4. As a result, we have:\na>\u03b8\u0303\u03b4 \u2212 a>\u03b8\u03020 \u2264 \u2016a\u20162 \u00b7 \u2016\u03b8\u0303\u03b4 \u2212 \u03b8\u03020\u20162 \u2264 \u2016a\u20161 \u00b7 CL \u00b7 \u03b4 \u2264 (q \u00b7 v>F11 + (1\u2212 q) \u00b7 v>F21) \u00b7 CL \u00b7 \u03b4 := Ca \u00b7 CL \u00b7 \u03b4.\n(40)\nBy definition of \u03b8\u0303\u03b4, we know that \u03b8\u03030 maximizes a>\u03b8 in D\u0303abg(0), which means that a>\u03b8\u03030 \u2265 a>\u03b8\u03020. As a result, we have:\nR(\u03b8\u03b4)\u2212R(\u03b80) =a>\u03b8\u0303\u03b4 \u2212 a>\u03b8\u03030 \u2264a>\u03b8\u0303\u03b4 \u2212 a>\u03b8\u03020 \u2264Ca \u00b7 CL \u00b7 \u03b4.\n(41)\nTherefore, we have R(\u03c0\u03b4,\u2217)\u2212R(\u03c0\u2217) \u2264 R(\u03b8\u03b4)\u2212R(\u03c0start) = R(\u03b8\u03b4)\u2212R(\u03b80) \u2264 Ca \u00b7 CL \u00b7 \u03b4. Let L := 2 \u00b7 Ca \u00b7 CL and this holds the lemma.\nB.2 Proof of Theorem 8\nAs is stated in Section 5.2, we may reduce this fair pricing problem to an ordinary online pricing problem with no fairness constraints. Therefore, we only need to prove the following\ntheorem.\nTheorem 16 (Regret Lower Bound). Consider the online pricing problem with T rounds and d fixed prices in [0, c] for 3 \u2264 d \u2264 T 1/3 and some constant c > 0. Then any algorithm has to suffer at least \u2126( \u221a dT ) regret.\nHere we mainly adopt the proof roadmap of Kleinberg and Leighton [2003]. Proof. We let c = 12 without losing generality. Let = \u221a\nd T , l = 1, a0 = 4l, ai = (1 + l )i \u00b7\na0, i = 1, 2, . . . , d, then we have: 4l = a0 < a1 < a2 < . . . < ad\u22121 < ad < 12l.\nDefine some distributions on the prices {ai}di=1:\n\u2022 P0, with acceptance rates of each price: P0 = [ la1 , l a2 , . . . , lad\u22121 , l ad ]T , where P0(i) = Pr[y \u2265 ai] = Pr[y > ai\u22121] = lai < 1 4 .\n\u2022 Pj , with acceptance rates of each price: Pj = [ la1 , l a2 , . . . , laj\u22121 , l+ aj , laj+1 , . . . , l ad\u22121 , lad ] T ,\nwhere Pj(i) = lai + ai \u00b7 1(i = j) \u2264 14 .\nIn the following part, we propose and prove the following lemma:\nLemma 17. For any algorithm S, \u2203j \u2208 {1, 2, . . . , d}, such that RegPj (S) = \u2126( \u221a Td).\nProof. Suppose f is a function: {0, 1}T \u2192 [0,M ]. Denote r = [11,12, . . . ,1T ]> as a vector containing the customer\u2019s decisions in sequence. Then for any j = 1, 2, . . . , d we have:\nEPj [f(r)]\u2212 EP0 [f(r)] = \u2211\nr f(r) \u00b7 (Pj [r]\u2212 P0[r])\n\u2264 \u2211\nr:Pj [r]\u2265P0[r] f(r)(Pj [r]\u2212 P0[r])\n\u2264M \u00b7 \u2211\nr:Pj [r]\u2265P0[r] f(r)(Pj [r]\u2212 P0[r])\n=M2 \u2016Pj \u2212 P0\u20161.\n(42)\nHere we cite a lemma from Cover and Thomas, Elements of Information theory, Lemma 11.6.1.\nLemma 18. KL(P1||P2) \u2265\n1 2 ln 2\u2016P1 \u2212 P2\u2016 2 1.\nSince\nKL(P0(r)||Pj(r))\n= T\u2211 t=1 KL(P0[rt|rt\u22121]||Pj [rt|rt\u22121])\n= t\u2211 t=1 P0(it 6= j) \u00b7 0 + P0(it = j) \u00b7KL( l aj || l aj + aj ).\n(43)\nThe first equality comes from the chain rule of decomposing a KL-divergence, and the second equality is because 1t satisfies a Bernoulli distribution B(1, lait + ait \u00b7 1(it = j)). Now we propose another lemma:\nLemma 19. If 112 \u2264 p \u2264 1 4 , then we have: KL(p, p+ ) \u2264 12 2 for sufficiently small .\nAccording to this Lemma 19, we have:\nKL(P0(r)||Pj(r)) \u2264 T\u2211 t=1 P0(it = j) \u00b7 12 2\n\u2264 T\u2211 t=1 P0(it = j) \u00b7 12 16l2 2.\n(44)\nTherefore, we have: EPj [f(r)]\u2212 EP0 [f(r)]\n\u2264M2 2 ln 2 \u00b7\n\u221a KL(P0(r)||Pj(r))\n\u2264 \u221a\n6 ln 2M 4 \u00b7 ( \u221a\u221a\u221a\u221a T\u2211 t=1 P0(it = j)) \u00b7 .\n(45)\nDenote Nj := \u2211T t=1 1(it = j), and hence:\nEPj [f(r)]\u2212 EPj [f(r)] \u2264 \u221a\n6 ln 2 4 M(\n\u221a EP0 [Nj ]) \u00b7 . (46)\nNow let f(r) = Nj , i.e., let function f simulate the algorithm which make choices of it\u2019s from historical results of {11,12, . . . , \u222b t\u22121} (It is straightforward that {i1, i2, . . . , it\u22121} are also historical results crucial for deciding it. However, for a deterministic algorithm, it can generate i1, i2, . . . , it\u22121 directly from \u2205, {11}, {11,12}, . . . , {11,12, . . . ,1t\u22122}.) Now,\n0 \u2264 f(r) \u2264 T , which indicates that M = T .. Then it turns out that\nEPj [Nj ]\u2212 EP0 [Nj ] \u2264 \u221a\n6 ln 2 4 \u00b7 T \u00b7 \u00b7\n\u221a EP0 [Nj ]\n\u21d2 1 d d\u2211 j=1 EPj [Nj ] \u2264 1 d d\u2211 j=1 (EP0 [Nj ] + \u221a 6 ln 2 4 \u00b7 T \u00b7 \u00b7 \u221a EP0 [Nj ])\n= T d\n+ \u221a\n6 ln 2 4 \u00b7 T d \u00b7 \u00b7 d\u2211 j=1 \u221a EP) [Nj ]\n\u2264 T d\n+ \u221a\n6 ln 2 4 \u00b7 \u00b7 T d \u00b7 \u221a Td\n= T d\n+ \u221a\n6 ln 2 4 \u00b7\n\u221a d\nT \u00b7 T d \u00b7 \u221a Td\n\u2264 T3 + 0.525 \u00b7 T \u2264 0.9T\n(47)\nHere the second line is an average over all j = 1, 2, . . . , d of the first line, the third line uses the fact that \u2211dj=1 E[Nj ] = T , the fourth line applies a Cauchy-Schwarz Inequality that Td = (\u2211dj=1 EP0 [Nj ])(d \u00b7 1) \u2265 (\u2211dj=1\u221aEP0 [Nj ])2, the fifth line plugs in the values that = \u221a d T , the sixth line uses the fact that ln 2 < 0.7, and the last line holds for sufficient large T .\nFrom Equation 47, we know that \u2203j \u2208 {1, 2, . . . , d} such that EPj [Nj ] \u2264 0.9T . As a result, we have:\nRegPj (S) \u2265(1\u2212 0.9)T ( l + aj \u00b7 aj \u2212 l ait \u00b7 ait), \u2200it 6= j\n=0.1T (l + \u2212 l) =0.1T =0.1 \u221a Td.\n(48)\nTherefore, the \u2126( \u221a Td) regret bound holds.\nB.3 Proof of Theorem 9\nProof. Prior to our technical analysis, we briefly introduce the roadmap of proving the unfairness lower bound.\n(i) We construct two different but very similar problem settings: one is exactly Example 1, the other is identical to Example 1 except all probabilities of 0.5 are now changed into (0.5\u2212 \u03b6), where \u03b6 = C \u00b7 T\u2212 12 +\u03b7 for some super small constant C \u2265 0 and some small \u03b7 \u2265 0. In the following, we may call them the \u201cProblem 0\u201d (or P0) and the \u201cProblem \u03b6\u201d (or P\u03b6) sequentially.\n(ii) We derive the close-form solutions to both Problem 0 and Problem \u03b6, where we also parameterize the reward function with the expected proposed price Vr and the proposed accepted price Vs. Of course Problem \u03b6 is more general and we may get the solutions to Problem 0 by simply let \u03b6 = 0.\n(iii) We show that there does not exist any policy \u03c0 that satisfies both of the following conditions simultaneously:\n\u2022 \u03c0 is within C0 \u00b7 T\u2212 1 2 +\u03b7-suboptimal (w.r.t. regret) and within C0 \u00b7 T\u2212 1 2 +\u03b7-unfair\n(w.r.t. fairness) in P0.\n\u2022 \u03c0 is within C0 \u00b7 T\u2212 1 2 +\u03b7-suboptimal (w.r.t. regret) and within C0 \u00b7 T\u2212 1 2 +\u03b7-unfair\n(w.r.t. fairness) in P\u03b6.\n(iv) We show that any algorithm have to distinguish P0 According to the roadmap above, we firstly construct the following example as the problem setting for lower bound proof.\nExample 20. Customers form 2 disjoint groups: Group 1 takes 30% proportion of customers, and Group 2 takes the rest 70%. In specific,\n\u2022 In Group 1, 40% customers valuate the item as $0, (10% + \u03b6) valuate customers it as $0.625, and (50%\u2212 \u03b6) customers valuate it as $1.\n\u2022 In Group 2, 20% customers valuate it as $0, (30% + \u03b6) customers valuate it as $0.7, and (50%\u2212 \u03b6) customers valuate it as $1.\nHere \u03b6 = C \u00b7 T\u2212 12 +\u03b7 is a small amount, where 0 \u2264 C \u2264 10\u221210. In other words, we have v> = [58 , 7 10 , 1], F1 = diag{0.6, 0.5\u2212 \u03b6, 0.5\u2212 \u03b6}, F2 = diag{0.8, 0.8, 0.5\u2212 \u03b6} and our policy \u03c0 = (\u03c01, \u03c02) where \u03c01, \u03c02 \u2208 \u22063. Our goal is to approach the following optimal policy\n\u03c0\u03b6,\u2217 = argmax \u03c0=(\u03c01,\u03c02)\u2208\u03a0 R(\u03c0;F1, F2)\ns.t. U(\u03c0) = 0 S(\u03c0;F1, F2) = 0.\n(49)\nFor any policy \u03c0 feasible to the constraints in (50), denote its expected accepted price as Vs (identical in both groups) and its expected proposed price as Vr (identical in both\ngroups as well). Notice that Vr \u2265 Vs \u2265 58 , we define \u03b1 = Vr \u2212 Vs as their difference, and therefore we know that \u03b1 \u2265 0. Again, we denote R(\u03c0, F1, F2) as R(\u03c0) without causing misunderstandings. Here we propose the following lemma regarding Example 20.\nLemma 21 (Close-form solution to Example 20). For the problem setting defined in Example 20, we have:\n\u03c01\u03b6,\u2217 =[ 20\u2212 40\u03b6 29\u2212 10\u03b6 , 0, 9 + 30\u03b6 29\u2212 10\u03b6 ] >, \u03c02\u03b6,\u2217 =[0, 25\u2212 50\u03b6 29\u2212 10\u03b6 , 4 + 40\u03b6 29\u2212 10\u03b6 ] >, \u2200\u03b6 \u2208 [0, 10\u221210]. (50)\nBesides, for any feasible policy \u03c0 and its corresponding Vs and \u03b1, we have:\nR(\u03c0) = 71\u2212 30\u03b6100 \u00b7 Vs + (100\u2212 60\u03b6)\u2212 (142\u2212 60\u03b6)Vs (8Vs \u2212 5)(1\u2212 Vs)25 \u00b7 Vs \u00b7 \u03b1. (51)\nProof of Lemma 21. For any feasible policy \u03c0 = (\u03c01, \u03c02), it has to satisfy the following equations for e = 1, 2:  1>\u03c0e = 1 v>\u03c0e = Vs + \u03b1 v>Fe\u03c0e\n1>Fe\u03c0e = Vs.\nThis is equivalent to the following linear equations system 1>\u03c0e = 1 v>\u03c0e = Vs + \u03b1 (v\u2212 Vs \u00b7 1)>Fe\u03c0e = 0.\n(52)\nThis is further equivalent to A1\u03c01 = [1, Vs + \u03b1, 0]> and A2\u03c02 = [1, Vs + \u03b1, 0]> where\nA1(Vs, \u03b6) =  1 1 158 710 1 (58 \u2212 Vs) \u00b7 3 5 ( 7 10 \u2212 Vs) \u00b7 ( 1 2 \u2212 \u03b6) (1\u2212 Vs) \u00b7 ( 1 2 \u2212 \u03b6)  . (53) and\nA2(Vs, \u03b6) =  1 1 158 710 1 (58 \u2212 Vs) \u00b7 4 5 ( 7 10 \u2212 Vs) \u00b7 4 5 (1\u2212 Vs) \u00b7 ( 1 2 \u2212 \u03b6)  . (54)\nHere we may omit the parameters (Vs, \u03b6) without misunderstanding. For Vs = 58 , the only possible policy is to propose the lowest price 58 for both groups, and the expected reward is 0.3\u00d7 58 \u00d7 3 5 + 0.7\u00d7 5 8 \u00d7 4 5 = 0.4625 < 0.5\u2212 \u03b6. Therefore, it is suboptimal as its expected reward is less than that of a deterministic policy keep proposing 1 as a price (whose reward is 0.5 \u2212 \u03b6). In the following, we only consider the case when Vs > 58 . Solve these linear equation systems and get\n\u03c01 =A\u221211 [1, Vs + \u03b1, 0]>\n= 13(8Vs \u2212 5)(1 + 10\u03b6) 120\u03b1(1\u2212 2\u03b6)\u2212((1 + 10\u03b6)8Vs + 10(1\u2212 8\u03b6)) \u00b7 \u03b1\u2212 (8(1 + 10\u03b6)V 2s \u2212 13(1 + 10\u03b6)Vs + (1 + 10\u03b6)5) 10(8(1 + 10\u03b6)Vs \u2212 2(1 + 28\u03b6)) \u00b7 \u03b1+ (1 + 10\u03b6)(8Vs \u2212 5)(10Vs \u2212 7)  (55)\nand \u03c02 =A\u221212 [1, Vs + \u03b1, 0]>\n= 13(1\u2212 Vs)(3 + 10\u03b6)4(((3 + 10\u03b6)10Vs \u2212 (6 + 100\u03b6))\u03b1\u2212 (3 + 10\u03b6)(10Vs \u2212 7)(Vs \u2212 1))(\u22125) \u00b7 (((3 + 10\u03b6)8Vs \u2212 80\u03b6)\u03b1+ (3 + 10\u03b6)(8Vs \u2212 5)(Vs \u2212 1)) 24\u03b1  . (56)\nOn the one hand, we can get the explicit form of R(\u03c0) w.r.t. Vs and \u03b1:\nR(\u03c0) =q \u00b7 v>F1\u03c01 + (1\u2212 q) \u00b7 v>F2\u03c02\n=71\u2212 30\u03b6100 Vs + (100\u2212 60\u03b6)\u2212 (142\u2212 60\u03b6)Vs (8Vs \u2212 5)(1\u2212 Vs)25 \u00b7 Vs\u03b1.\n(57)\nOn the other hand, we have a few constraints to be applied. Since \u03c0 is a probabilistic distribution, we have \u03c0e(i) \u2265 0, e = 1, 2; i = 1, 2, 3, which lead to 120\u03b1(1\u2212 2\u03b6) \u2265 0 \u2212 ((1 + 10\u03b6)8Vs + 10(1\u2212 8\u03b6)) \u00b7 \u03b1\u2212 (8(1 + 10\u03b6)V 2s \u2212 13(1 + 10\u03b6)Vs + (1 + 10\u03b6)5) \u2265 0 10(8(1 + 10\u03b6)Vs \u2212 2(1 + 28\u03b6)) \u00b7 \u03b1+ (1 + 10\u03b6)(8Vs \u2212 5)(10Vs \u2212 7) \u2265 0 4(((3 + 10\u03b6)10Vs \u2212 (6 + 100\u03b6))\u03b1\u2212 (3 + 10\u03b6)(10Vs \u2212 7)(Vs \u2212 1)) \u2265 0 (\u22125) \u00b7 (((3 + 10\u03b6)8Vs \u2212 80\u03b6)\u03b1+ (3 + 10\u03b6)(8Vs \u2212 5)(Vs \u2212 1)) \u2265 0 24\u03b1 \u2265 0. (58) From (58), we may derive the following upper and lower bounds for \u03b1.\n(a) The first line and the last line of (58) is naturally satisfied.\n(b) From the second line, we have\n\u03b1 \u2264 (1 + 10\u03b6)(8Vs \u2212 5)(1\u2212 Vs)(1 + 10\u03b6)8Vs + 10(1\u2212 8\u03b6) := B1. (59)\n(c) From the third line, we have\n\u03b1 \u2265 (1 + 10\u03b6)(8 \u00b7 Vs \u2212 5)(7\u2212 10Vs)(1 + 10\u03b6)8 \u00b7 Vs \u2212 2(1 + 28\u03b6) \u00b7 110 := B2. (60)\n(d) From the fourth line, we have\n\u03b1 \u2265 (3 + 10\u03b6)(10Vs \u2212 7)(1\u2212 Vs)(3 + 10\u03b6)10Vs \u2212 (6 + 100\u03b6) := B3. (61)\n(e) From the fifth line, we have\n\u03b1 \u2264 (3 + 10\u03b6)(8Vs \u2212 5)(1\u2212 Vs)(3 + 10\u03b6)8 \u00b7 Vs \u2212 80\u03b6 := B4. (62)\nWe get four constraints on \u03b1 as above, where (59) and (62) are upper bounds, and (60) and (61) are lower bounds. Compare B1 with B4, we notice that\nB1 B4\n= 80\u03b6 3+10\u03b6\n8Vs + 10 \u00b7 1\u22128\u03b61+10\u03b6 \u2264 1. (63)\nTherefore, (59) is tighter than (62). For the comparison between B2 and B3, we notice that B2 < 0 < B3 when Vs > 710 and B2 \u2265 0 \u2265 B3 when Vs \u2264 7 10 .\nIn the following part, we derive the optimal policy by cases.\n(a) When 58 < Vs \u2264 50\u221230\u03b6 71\u221230\u03b6 , we have\nR(\u03c0) =71\u2212 30\u03b6100 Vs + (100\u2212 60\u03b6)\u2212 (142\u2212 60\u03b6)Vs (8Vs \u2212 5)(1\u2212 Vs)25 \u00b7 Vs\u03b1\n\u226471\u2212 30\u03b6100 Vs + (100\u2212 60\u03b6)\u2212 (142\u2212 60\u03b6)Vs (8Vs \u2212 5)(1\u2212 Vs)25 \u00b7 Vs \u00b7B1 =71\u2212 30\u03b6100 Vs + (100\u2212 60\u03b6)\u2212 (142\u2212 60\u03b6)Vs (8Vs \u2212 5)(1\u2212 Vs)25 \u00b7 Vs \u00b7 (1 + 10\u03b6)(8Vs \u2212 5)(1\u2212 Vs) (1 + 10\u03b6)8Vs + 10(1\u2212 8\u03b6) =71\u2212 30\u03b6100 VS + 100\u2212 142Vs \u2212 60\u03b6(1\u2212 Vs)\n25(8Vs + 10 \u00b7 1\u22128\u03b61+10\u03b6 ) \u00b7 Vs\n=71\u2212 30\u03b6100 VS + 100\u2212 142Vs \u2212 60\u03b6(1\u2212 Vs)\n25(8Vs + 10)\u2212 450\u03b61+10\u03b6 \u00b7 Vs\n< 71\u2212 30\u03b6 100 VS + 100\u2212 142Vs \u2212 60\u03b6(1\u2212 Vs) + 450\u03b61+10\u03b6 25(8Vs + 10) \u00b7 Vs < 71 100Vs + 100.1\u2212 142Vs 25(8Vs + 10) \u00b7 Vs =71(8 \u00b7 Vs + 10) + (100.1\u2212 142 \u00b7 Vs) \u00b7 4100(8 \u00b7 Vs + 10) \u00b7 Vs = 11104 \u00b7 Vs1000(8 \u00b7 Vs + 10) \u2264111048000 \u2212 5 4 \u00d7 11104\n1000(8\u00d7 5071 + 10) \u22640.50019\n(64) Here the first inequality (line 2) is by (100\u2212 60\u03b6)\u2212 (142\u2212 60\u03b6)Vs \u2265 0 as Vs \u2264 50\u221230\u03b671\u221230\u03b6 and by \u03b1 \u2264 B1, the second inequality (line 6) is by the fact that Vs\u2019s coefficient is within (0, 1), the third inequality (line 7) is by \u03b6 \u2264 10\u221210 < 14500 , the fourth inequality (line 10) is by Vs \u2264 5071 and the last inequality (line 11) is by numerical computations. We will later show that 0.50019 is not optimal.\n(b) When Vs > 50\u221230\u03b671\u221230\u03b6 , we know that Vs > 7 10 as \u03b6 < 1 30 . Therefore, we know B2 < 0 < B3\nand we have \u03b1 \u2265 B3 =\n(3 + 10\u03b6)(10Vs \u2212 7)(1\u2212 Vs) (3 + 10\u03b6)10Vs \u2212 (6 + 100\u03b6) .\nAs a result, we have\nR(\u03c0) = 71\u2212 30\u03b6100 Vs \u2212 (142\u2212 60\u03b6)Vs \u2212 (100\u2212 60\u03b6) (8Vs \u2212 5)(1\u2212 Vs)25 \u00b7 Vs\u03b1\n\u2264 71\u2212 30\u03b6100 Vs \u2212 (142\u2212 60\u03b6)Vs \u2212 (100\u2212 60\u03b6) (8Vs \u2212 5)(1\u2212 Vs)25 \u00b7 Vs \u00b7B3 \u2264 71\u2212 30\u03b6100 Vs \u2212 (142\u2212 60\u03b6)Vs \u2212 (100\u2212 60\u03b6) (8Vs \u2212 5)(1\u2212 Vs)25 \u00b7 Vs \u00b7 (3 + 10\u03b6)(10Vs \u2212 7)(1\u2212 Vs) (3 + 10\u03b6)10Vs \u2212 (6 + 100\u03b6)\n(65) Also, we can derive an upper bound for Vs as B3 \u2264 \u03b1 \u2264 B1.\n(3 + 10\u03b6)(10Vs \u2212 7)(1\u2212 Vs) (3 + 10\u03b6)10Vs \u2212 (6 + 100) \u2264(1 + 10\u03b6)(8 \u00b7 Vs \u2212 5)(1\u2212 Vs)(1 + 10\u03b6)8 \u00b7 Vs + 10(1\u2212 8\u03b6)\n\u21d4 Vs \u2264 8 + 10\u03b6 11 + 10\u03b6 .\n(66)\nTherefore, we may solve the maximal of R(\u03c0) on 50\u221230\u03b671\u221230\u03b6 \u2264 Vs \u2264 8+10\u03b6 11+10\u03b6 by combining (65).\n\u2202R(\u03c0) \u2202Vs = 3(\u22123135 + 9870Vs \u2212 7491V 2 s ) + 3\u03b6(\u221246430 + 145660Vs \u2212 114638V 2s ) 20(\u22125 + 8Vs)2(\u22123\u2212 50\u03b6 + 15Vs + 50\u03b6Vs)2\n+ +3\u03b6 2(97900\u2212 315800Vs + 251740V 2s ) + 3\u03b63(15000\u2212 30000Vs + 15000V 2s )\n20(\u22125 + 8Vs)2(\u22123\u2212 50\u03b6 + 15Vs + 50\u03b6Vs)2\n= \u221222473(Vs \u2212 1645\u22126\n\u221a 2685\n2497 )(Vs \u2212 1645+6\n\u221a 2685\n2497 ) + 3(\u221246430 + 145660Vs \u2212 114638V 2s )\u03b6 + o(\u03b62) 20(\u22125 + 8Vs)2(\u22123\u2212 50\u03b6 + 15Vs + 50\u03b6Vs)2\n& \u221222473(Vs \u2212 0.5343)(vs \u2212 0.7833)\n20(\u22125 + 8Vs)2(\u22123\u2212 50\u03b6 + 15Vs + 50\u03b6Vs)2\n> 0. (67)\nHere the \u201c&\u201d inequality is because the coefficient of \u03b6 in any monomial above is within \u00b1106, which indicates that any monomial containing \u03b6 is within \u00b10.0001 . The last line is because 710 \u2264 50\u221230\u03b6 71\u221230\u03b6 \u2264 Vs \u2264 8+10\u03b6 11+10\u03b6 \u2264 3 4 and therefore (Vs\u22120.5343)(vs\u22120.7833) < 0. As a result, we know that R(\u03c0) is monotonically increasing as Vs increases within the range above. Therefore, we have:\nR(\u03c0) \u2264 R(\u03c0)|\u03b1=B3 \u2264 R(\u03c0)|\u03b1=B3 and Vs= 8+10\u03b611+10\u03b6 = 37(1\u2212 2\u03b6)(4 + 5\u03b6) 10(29\u2212 10\u03b6) (68)\nBy plugging in Vs = 8+10\u03b611+10\u03b6 into \u03b1 = B3 and the close-form feasible solutions of \u03c01\nand \u03c02 (i.e., (55) and (56) ), we may get:\n\u03b1 = B3 = 3(1 + 10\u03b6)(3 + 10\u03b6)\n2(29\u2212 10\u03b6)(11 + 10\u03b6)\n\u03c01 = [20\u2212 40\u03b629\u2212 10\u03b6 , 0, 9 + 30\u03b6 29\u2212 10\u03b6 ] > \u03c02 = [0, 25\u2212 50\u03b629\u2212 10\u03b6 , 4 + 40\u03b6 29\u2212 10\u03b6 ] >.\n(69)\nPushing back (69) to (49), we verify that R(\u03c0)max = 37(1\u22122\u03b6)(4+5\u03b6)10(29\u221210\u03b6) and therefore all inequalities in (68) hold as equalities.\nNotice that 37(1\u22122\u03b6)(4+5\u03b6)10(29\u221210\u03b6) > 0.50019, and therefore the optimal policy \u03c0\u03b6,\u2217 is what we derive in (69). This holds the lemma.\nWith Lemma 21, we know that \u03c01\u03b6,\u2217 = [ 20\u221240\u03b6 29\u221210\u03b6 , 0, 9+30\u03b6 29\u221210\u03b6 ]> and \u03c02\u03b6,\u2217 = [0, 25\u221250\u03b6 29\u221210\u03b6 , 4+40\u03b6 29\u221210\u03b6 ]>. We denote V \u2217s,\u03b6 := 8+10\u03b6 3+10\u03b6 and \u03b1\u2217\u03b6 = 3(1+10\u03b6)(3+10\u03b6) 2(29\u221210\u03b6)(11+10\u03b6) for future use. We also know that the optimal policy for Example 1 (i.e., \u03b6 = 0) is exactly what we proposed, i.e., \u03c01\u2217 = [2029 , 0, 9 29 ]> and \u03c02\u2217 = [0, 2529 , 4 29 ]>.\nLet us go back to the two problems: P0 defined in Example 1 and P\u03b6 defined in Example 20, where we consider the following four conditions:\n\u2022 \u03c0 is within C0 \u00b7 T\u2212 1 2 +\u03b7-suboptimal (w.r.t. regret) in P0 (denoted as Condition A).\n\u2022 \u03c0 is within C0 \u00b7 T\u2212 1 2 +\u03b7-suboptimal (w.r.t. regret) in P\u03b6 (denoted as Condition B).\n\u2022 \u03c0 is within C0 \u00b7 T\u2212 1 2 +\u03b7-unfair (w.r.t. fairness) in P0 (denoted as Condition C).\n\u2022 \u03c0 is within C0 \u00b7 T\u2212 1 2 +\u03b7-unfair (w.r.t. fairness) in P\u03b6 (denoted as Condition D).\nAccording to our proof roadmap, we then prove the following lemma:\nLemma 22 (No policy fitting in P0 and P\u03b6). There exist constants C0 > 0 such that there does not exist any policy \u03c0 \u2208 \u03a0 that satisfies all of Condition ABCD (denoting"
        },
        {
            "heading": "A \u2227B \u2227 C \u2227D) simultaneously.",
            "text": "Corollary 23. The space of \u03a0 can be divided as the following 3 subspaces:\n1. Policies satisfying Condition AC (denoted as Space AC).\n2. Policies satisfying Condition BD (denoted as Space BD).\n3. Policies satisfying Condition (denoted as Outer Spaces) A\u0304B\u0304 \u2228 C\u0304D\u0304 \u2228 A\u0304D\u0304 \u2228 B\u0304C\u0304. and these three subspaces are pairwise disjoint.\nProof of Lemma 22. Let C1 = CW and C2 = C W \u00b7L where L > 0 is a constant from Lemma 14 and W \u2265 10 to be specified later. Let C0 = min{C1, C2}, and we prove the lemma by contradiction. Suppose there exists a policy \u03c0 satisfies the four conditions above, and then we denote the expected accepted prices in G1 and G2 in Problem \u03b6 are Vs,\u03b6 and Vs,\u03b6 + \u03b2\u03b6 sequentially, where \u03b2\u03b6 \u2208 [0, C2T\u2212 1 2 +\u03b7]. Here we assume \u03b2 \u2265 0 without losing generality as we will not use the specific property of G1 versus G2. Also, we denote \u03b1\u03b6 as the difference between the expected proposed price in both groups (denoted as Vr,\u03b6) and Vs,\u03b6 .\nNow, consider a corresponding policy:\n\u03c0\u030c := { G1 : E[accepted price] = Vs,\u03b6 ,E[proposed price] = Vs,\u03b6 + \u03b1\u03b6 G2 : E[accepted price] = Vs,\u03b6 ,E[proposed price] = Vs,\u03b6 + \u03b1\u03b6\n(70)\nAccording to (66), we know that 58 \u2264 Vs,\u03b6 \u2264 V \u2217s,\u03b6 = 8+10\u03b6 11+10\u03b6 and R(\u03c0\u030c) \u2264 R(\u03c0\u03b6,\u2217). Therefore, we have: R(\u03c0) \u2264 R(\u03c0\u030c) + L \u00b7 \u03b2\u03b6\n\u2264 R(\u03c0\u03b6,\u2217)\u2212 min Vs\u2208[ 58 , 8+10\u03b6 11+10\u03b6 ] \u2202R(\u03c0) \u2202Vs \u00b7 (V \u2217s,\u03b6 \u2212 Vs,\u03b6) + L \u00b7 \u03b2\u03b6 \u2264 R(\u03c0\u03b6,\u2217)\u2212 1 4 \u00b7 (V \u2217 s,\u03b6 \u2212 Vs,\u03b6) + L \u00b7 \u03b2\u03b6 .\n(71)\nHere the first line comes from Lemma 14, the second line comes from the fact that f(x1)\u2212 f(x2) \u2265 minx(f \u2032(x))(x1 \u2212 x2) for x1 \u2265 x2 and f \u2032(x) > 0, and the third line comes from the fact that \u2202R(\u03c0)\u2202Vs \u2265 1 4 for Vs \u2208 [0.625, 0.728] as 0.728 > 8+10\u03b6 11+10\u03b6 for \u03b6 \u2264 10\u221210. Also, since \u03c0 satisfies a low-regret condition, we have\nR(\u03c0\u03b6,\u2217)\u2212R(\u03c0) \u2264 C1 \u00b7 T\u2212 1 2 +\u03b7.\nCombining with (71), we have\n1 4(V \u2217 s,\u03b6 \u2212 Vs,\u03b6)\u2212 L \u00b7 \u03b2\u03b6 \u2264 C1T\u2212 1 2 +\u03b7\n\u21d2 (V \u2217s,\u03b6 \u2212 Vs,\u03b6) \u2264 C1T\u2212 1 2 +\u03b7 + L \u00b7 \u03b2\u03b6\n\u2264 (C1 + LC2)T\u2212 1 2 +\u03b7.\n(72)\nNotice that this is suitable for any \u03b6 \u2208 [0, 10\u221210], we may have the same result for both \u03b6 = CT\u2212 12 +\u03b7 and for \u03b6 = 0. We denote \u03b60 = 0 and \u03b61 = CT\u2212 1 2 +\u03b7 where C = 10\u221210. Therefore, we have: (V \u2217s,\u03b60 \u2212 Vs,\u03b60) \u2264(C1 + LC2)T \u2212 12 +\u03b7,\n(V \u2217s,\u03b61 \u2212 Vs,\u03b61) \u2264(C1 + LC2)T \u2212 12 +\u03b7.\n(73)\nNow let us bound (\u03b1\u2217\u03b6 \u2212 \u03b1\u03b6) for both \u03b60 and \u03b61. From (59) and (61), we have\nB3|Vs=Vs,\u03b6 \u2264 \u03b1\u03b6 \u2264 B1|Vs=Vs,\u03b6 B3|Vs=V \u2217s,\u03b6 = \u03b1 \u2217 \u03b6 = B1|Vs=V \u2217s,\u03b6\n\u21d2 min Vs\u2208[0.7,0.75] {\u2202B3 \u2202Vs , \u2202B1 \u2202Vs } \u00b7 (V \u2217s,\u03b6 \u2212 Vs,\u03b6) \u2264 (\u03b1\u2217\u03b6 \u2212 \u03b1\u03b6) \u2264 max VS\u2208[0.7,0.75] {\u2202B3 \u2202Vs , \u2202B1 \u2202Vs }(V \u2217s,\u03b6 \u2212 Vs,\u03b6)\n\u21d2 0 \u2264 0.05(V \u2217s,\u03b6 \u2212 Vs,\u03b6) \u2264 (\u03b1\u2217\u03b6 \u2212 \u03b1\u03b6) \u2264 0.6(V \u2217s,\u03b6 \u2212 Vs,\u03b6). (74)\nTherefore, we have:\n0 \u2264 V \u2217r,\u03b6 \u2212 Vr,\u03b6 = V \u2217s,\u03b6 + \u03b1\u2217\u03b6 \u2212 (Vs,\u03b6 + \u03b1\u03b6) \u2264 (1 + 0.6)(V \u2217s,\u03b6 \u2212 Vs,\u03b6) \u2264 8 5 \u00b7 (C1 + LC2)T \u2212 12 +\u03b7.\nTherefore, we know that\nV \u2217r,\u03b60 \u2265Vr,\u03b60 \u2265 V \u2217 r,\u03b60 \u2212 8 5 \u00b7 (C1 + LC2)T \u2212 12 +\u03b7,\nV \u2217r,\u03b61 \u2265Vr,\u03b61 \u2265 V \u2217 r,\u03b61 \u2212 8 5 \u00b7 (C1 + LC2)T \u2212 12 +\u03b7. \u21d2 |Vr,\u03b61 \u2212 Vr,\u03b60 | \u2265 |V \u2217r,\u03b60 \u2212 V \u2217 r,\u03b61 | \u2212 (C1 + LC2)T \u2212 12 +\u03b7.\n(75)\nHOWEVER, we have Vr,\u03b61 = Vr,\u03b60 since they are the expected proposed price of the same pricing policy \u03c0 in P0 and P\u03b6 where the prices sets are all the same! Therefore, we have |V \u2217r,\u03b60 \u2212 V \u2217 r,\u03b61 | \u2212 (C1 + LC2)T\u2212 1 2 +\u03b7 \u2264 0. Since V \u2217r,\u03b60 = 43 58 and Vr,\u03b61 = 43+10\u03b61 58\u221220\u03b61 , we have |V \u2217r,\u03b60\u2212V \u2217 r,\u03b61 | = 360\u03b629(29\u221210\u03b6) \u2265 C 3 \u00b7T \u2212 12 +\u03b7. Since C1 = CW \u2264 10\u221211 and C2 = C W \u00b7L \u2264 1 L \u00d710\u221211, we know that |V \u2217r,\u03b60 \u2212 V \u2217 r,\u03b61 | > (C1 + LC2)T\u2212 1 2 +\u03b7, which contradicts to the inequality we derived. Therefore, the lemma is proved by contradiction.\nIn the following, we set \u03b6 = \u03b61 = CT\u2212 1 2 +\u03b7 where C = 10\u221210 as is defined in the proof of Lemma 22. Now let us go back to the main stream of proving Theorem 9. We also make it by contradiction. For any given Cx, without loss of generality, we may assume that Cu \u2264 Cx to be specified later. Define x = Cxlog T , and therefore CxT 1 2 = T 12\u2212x. We will make use of Example 1 and Example 20, and let \u03b7 > x to be specified later. Therefore, we have Cu \u00b7 T 1 2 \u2264 Cx \u00b7 T 1 2 = T 12\u2212x, which means that the contradiction is a sufficient condition to the following result: Suppose there exists an x > 0 and an algorithm such that it can always achieve O(T 12 +x) regret with zero procedural unfairness and O(T 12\u2212x) substantive unfairness. According to Corollary 23, we know that any policy \u03c0 \u2208 \u03a0 are in exact one of those three spaces. In our problem setting, denote the policy we take at time t = 1, 2, . . . , T as \u03c0t. Now we show that: among all policies {\u03c0t}Tt=1 we have taken, there are at most O(T 1\u2212\u03b7+x) policies in all T policies having been played belonging to the Outer Space defined in Corollary 23. In fact, for any policy \u03c0 in the Outer Space, we have:\n(i) When \u03c0 \u2208 A\u0304B\u0304, the policy \u03c0 will definitely suffer a regret C0 \u00b7T\u2212 1 2 +\u03b7, no matter which\nthe problem setting is (i.e., P0 or P\u03b6). In order to guarantee O(T 1 2 +x) regret, there are at most N1 = O(T 1\u2212\u03b7+x) = o(T ) rounds to play a policy in A\u0304B\u0304.\n(ii) When \u03c0 \u2208 C\u0304D\u0304, the policy \u03c0 will definitely suffer a substantive unfairness C0 \u00b7 T\u2212 1 2 +\u03b7,\nno matter which the problem setting is (i.e., P0 or P\u03b6). In order to guarantee O(T 1 2\u2212x) regret, there are at most N2 = O(T 1\u2212\u03b7\u2212x) = o(T ) rounds to play a policy in C\u0304D\u0304.\n(iii) When \u03c0 \u2208 A\u0304D\u0304 \u2228 B\u0304C\u0304, in either P0 or P\u03b6 it suffers something (that could be either C0 \u00b7 T\u2212 1 2 +\u03b7 regret or C0 \u00b7 T\u2212 1 2 +\u03b7 unfairness). As we have to guarantee\nO(T 12 +x) regret and O(T 12\u2212x) substantive unfairness, there are still at most N3 = O(max{T 1\u2212\u03b7+x, T 1\u2212\u03b7\u2212x}) = O(T 1\u2212\u03b7+x) = o(T ).\nTherefore, the number of rounds when we select and play a policy from Space AC or Space BD is at least T \u2212 o(T ) \u2265 T2 . Notice that if a policy in AC, then it performs well in P0 but not necessarily in P\u03b6 . Similarly, if a policy in BD, then it performs well in P\u03b6 but not necessarily in P0. Therefore, two questions emerges:\n\u2022 How do policies in AC perform in P\u03b6? and How do policies in BD perform in P0? Specifically, we only care about the substantive fairness.\n\u2022 How can we distinguish between P\u03b6 and P0?\nFor distinguishablity, denote F1(\u03b6) = diag{0.6, 0.5\u2212\u03b6, 0.5\u2212\u03b6} and F2(\u03b6) = diag{0.8, 0.8, 0.5\u2212 \u03b6}. Denote S0(\u03c0) := S(\u03c0, F1(0), F2(0))|\u03b6=0 and S\u03b6(\u03c0) := S(\u03c0, F1(\u03b6), F2(\u03b6)). In the following, we propose two lemmas that help us prove. The first lemma, Lemma 24, shows that failing to distinguish would lead to large substantive unfairness, which answers the first question above.\nLemma 24. There exists a constant Cac such that: for any policy \u03c0 \u2208 AC, we have S\u03b6(\u03c0) > Cac \u00b7 T\u2212 1 2 +\u03b7. There also exists a constant Cbd such that: for any policy \u03c0 \u2208 BD, we have S0(\u03c0) > Cbd \u00b7 T\u2212 1 2 +\u03b7.\nProof of Lemma 24 . We firstly prove the first half of this lemma, and then demonstrate the second half (which can be proved in exact the same way.)\nFirst of all, we have the close-form solution to both P0 and P\u03b6 in (50). Therefore, we have\nS\u03b6(\u03c00,\u2217) = 12\u03b6(1\u2212 2\u03b6)\n(11\u2212 6\u03b6)(11\u2212 10\u03b6) . (76)\nNow, consider any policy \u03c0 \u2208 AC. Similar to the Proof of Lemma 22, we define its accepted prices in G1 and G2 are Vs,0 and Vs,0 + \u03b2 where \u03b2 \u2208 [0, C2T\u2212frac12+\u03b7]. We also denote the\nexpected proposed price in both group as Vr,0 = Vs,0 + \u03b10. Also, define a corresponding policy \u03c0\u030c:\n\u03c0\u030c := { G1 : E[accepted price] = Vs,0,E[proposed price] = Vs,0 + \u03b10 G2 : E[accepted price] = Vs,0,E[proposed price] = Vs,0 + \u03b10.\n(77)\nNotice that \u03c01 = (A1(Vs,0, 0))\u22121[1, Vr,0, 0]> and \u03c02 = (A2(Vs,0, 0))\u22121[1, Vr,0, \u03b2 \u00b7 1>F2\u03c02]>. In comparison, we have \u03c0\u030c1 = (A1(Vs,0, 0))\u22121[1, Vr,0, 0]> and \u03c0\u030c2 = (A2(Vs,0, 0))\u22121[1, Vr,0, 0]>. Therefore, we have:\n\u03c01 = \u03c0\u030c1\n\u2016\u03c02 \u2212 \u03c0\u030c2\u20161 = \u2016(A2(Vs,0, 0))\u22121([1, Vr,0, \u03b2 \u00b7 1>F2\u03c02]> \u2212 [1, Vr,0, 0]>)\u20161 \u2264 \u2016(A2(Vs,0, 0))\u22121[0, 0, \u03b2]\u20161 = \u2016(A2(Vs,0, 0))\u22121[:,3]\u20161 \u00b7 \u03b2\n\u2264 100\u03b29(7Vs \u2212 5) .\n(78)\nAlso, since Fmin \u2264 1>F2\u03c02 \u2264 1 and \u2016v>F2\u20161 \u2264 d always hold, we know that \u2016\u2202S\u03b6(\u03c0)\u2202\u03c02 \u2016 \u2264 d\nFmin \u00b7 \u2016\u03c02\u20161 = dFmin . Since V \u2217 s,0 \u2248 811 and all Vs,0 we consider are around it (According to\n(73)), we may assume that (7Vs \u2212 5) > 12 \u00b7 ( 8 11 \u2212 5 7) > 1 200 Therefore, we have:\n|S\u03b6(\u03c0\u030c)\u2212 S\u03b6(\u03c0)| \u2264 d Fmin \u2016\u03c0\u030c2 \u2212 \u03c02\u20162\n\u2264 100d\u03b29(7 \u00b7 Vs \u2212 5)Fmin \u2264 100dC29(7 \u00b7 Vs \u2212 5)Fmin \u00b7 T\u2212 1 2 +\u03b7 \u2264 3000dC2 Fmin \u00b7 T\u2212 1 2 +\u03b7.\n(79)\nAlso, according to the proof of Lemma 22, we know that |Vs,0 \u2212 V \u2217s,0| \u2264 (C1 + LC2)T\u2212 1 2 +\u03b7 and |\u03b1\u22170 \u2212 \u03b10| \u2264 0.6(C1 + LC2)T\u2212 1 2 +\u03b7 (as \u03b6 = 0). Plugging in (55) and (56), we have:\n\u2016\u03c010,\u2217 \u2212 \u03c0\u030c1\u20161 \u226450 \u00b7 ((120 + 8 + 10 + 10\u00d7 (8 + 2))|\u03b1\u22170 \u2212 \u03b10|+ (13 + 106)|Vs,0 \u2212 V \u2217s,0|)\n\u22641309(C1 + LC2)T\u2212 1 2 +\u03b7\n\u2016\u03c020,\u2217 \u2212 \u03c0\u030c2\u20161 \u2264 1\n3\u00d7 0.2\u00d7 3((4\u00d7 36 + 120 + 24)|\u03b1 \u2217 0 \u2212 \u03b10|+ (120 + 51 + 120 + 39)|Vs,0 \u2212 V \u2217s,0|)\n\u2264350(C1 + LC2)T\u2212 1 2 +\u03b7\n(80)\nTherefore, we have:\n|S\u03b6(\u03c00,\u2217)\u2212 S\u03b6(\u03c0\u030c) \u2264 d\nFmin \u2016\u03c00,\u2217 \u2212 \u03c0\u030c\u20162\n= d Fmin (\u2016\u03c010,\u2217 \u2212 \u03c0\u030c1\u20162 + \u2016\u03c020,\u2217 \u2212 \u03c0\u030c2\u20162) \u2264 d Fmin (\u2016\u03c010,\u2217 \u2212 \u03c0\u030c1\u20161 + \u2016\u03c020,\u2217 \u2212 \u03c0\u030c2\u20161) \u2264 d Fmin \u00b7 (1309(C1 + LC2)T\u2212 1 2 +\u03b7 + 350(C1 + LC2)T\u2212 1 2 +\u03b7) \u2264 d Fmin 2000(C1 + LC2)T\u2212 1 2 +\u03b7.\n(81)\nRecall that C1 = CW and C2 = C W...L . Now, we let W = 106 d Fmin . Therefore, we have:\nS\u03b6(\u03c0) =S\u03b6(\u03c0)\u2212 S\u03b6(\u03c0\u030c) + S\u03b6(\u03c0\u030c)\u2212 S\u03b6(\u03c00,\u2217) + S\u03b6(\u03c00,\u2217) \u2265S\u03b6(\u03c00,\u2217)\u2212 |S\u03b6(\u03c0)\u2212 S\u03b6(\u03c0\u030c)| \u2212 |S\u03b6(\u03c0\u030c)\u2212 S\u03b6(\u03c00,\u2217)|\n\u2265 12\u03b6(1\u2212 2\u03b6)(11\u2212 2\u03b6)(11\u2212 6\u03b6) \u2212 3000dC2 Fmin \u00b7 T\u2212 1 2 +\u03b7 \u2212 d Fmin 2000(C1 + LC2)T\u2212 1 2 +\u03b7 \u2265 120\u03b6 \u2212 5000d(C1 + LC2) Fmin \u00b7 T\u2212 1 2 +\u03b7 = 120C \u00b7 T \u2212 12 +\u03b7 \u2212 5000dC Fmin \u00b7W \u00b7 T\u2212 1 2 +\u03b7 \u2265 120C \u00b7 T \u2212 12 +\u03b7 \u2212 1200C \u00b7 T \u2212 12 +\u03b7 \u2265 130C \u00b7 T \u2212 12 +\u03b7.\n(82)\nLet Cac = 130 \u00b7 C and this lemma holds.\nDefine PP0 and PP\u03b6 as the probabilistic distribution of customer\u2019s feedback at each round. In order to increase the information for distinguishing between two problem settings, we assume that a customer would always tell us whether or not she accept the price $1, at each time t = 1, 2, . . . , T . Therefore, both PP0 and PP\u03b6 are binomial distributions B(T, 0.5) and B(T, 0.5\u2212 \u03b6). Here we present another lemma, the Lemma 25, that indicates the hardness of distinguishing the two settings.\nLemma 25. Consider the N \u2265 T2 rounds when we play a policy in AC \u2228 BD. For any algorithm \u03c6, denote \u03c6t = 1 if \u03c0t \u2208 AC and \u03c6t = 0 if \u03c0t \u2208 BD. Then we have:\nmax{EP0 [ N\u2211 t=1 \u03c6t],EP\u03b6 [ N\u2211 t=1 (1\u2212 \u03c6t)]} \u2265 1 8T \u00b7 exp(\u2212T 2\u03b7). (83)\nProof of Lemma 25 . In fact, we have:\nmax{EP0 [ N\u2211 t=1 \u03c6t],EP\u03b6 [ N\u2211 t=1 (1\u2212 \u03c6t)]} \u2265 EP0 [\n\u2211N t=1 \u03c6t] + EP\u03b6 [ \u2211N t=1(1\u2212 \u03c6t)]\n2\n= N \u00b7 PP0 [\u03c6t == 1] + PP\u03b6 [\u03c6t == 0] 2 \u2265 T4 \u00b7 (PP0 [\u03c6t == 1] + PP\u03b6 [\u03c6t == 0]) \u2265 T8 \u00b7 exp(\u2212N \u00b7KL(PP0 ||PP\u03b6 )) \u2265 T8 \u00b7 exp(\u2212N \u00b7KL(Ber(0.5)||Ber(0.5\u2212 \u03b6))) \u2265 T8 \u00b7 exp(\u2212N \u00b7 12\u03b6 2) = T8 \u00b7 exp(\u2212N \u00b7 12(C \u00b7 T \u2212 12 +\u03b7)2) \u2265 T8 \u00b7 exp(\u221212C 2T 2\u03b7) \u2265 T8 \u00b7 exp(\u2212T 2\u03b7). (84)\nHere the first line is for max \u2265 average, the second is by definition of \u03c6t, the third line is for N \u2265 T2 , the fourth line is from Fano\u2019s Inequality that P0[\u03c6 == 1] + P1[\u03c6 == 0] \u2265 1 2 \u00b7 exp{\u2212N \u00b7KL(P0||P1)} for any distributions P0 and P1, the fifth line is by definition of P0 and P\u03b6 that they are only different in the customers\u2019 feedback satisfying Ber(0.5) and Pr = 0.5\u2212 \u03b6 for some actions, respectively, the sixth line is from Lemma 19, the seventh line is for \u03b6 = C \u00b7 T\u2212 12 +\u03b7, the eighth line is for N \u2264 T , and the last line is for 12C2 \u2264 1.\nWith the two lemma above, we know that\n\u2022 For any algorithm \u03c6, we either run at least T8 \u00b7 exp(\u2212T 2\u03b7) rounds with some \u03c0t \u2208 AC when the problem setting is P\u03b6 , or run at least T8 \u00b7 exp(\u2212T 2\u03b7) rounds with some \u03c0t \u2208 BD when the problem setting is P0, according to Lemma 25.\n\u2022 For each round we mismatching the problem setting, we will suffer a min{Cac, Cbd} \u00b7 T\u2212 1 2 +\u03b7 unfairness, according to Lemma 24.\nGiven these two facts, denote Cmin := 18 min{Cac, Cbd} and we at least have CminT \u00b7 exp(\u2212T 2\u03b7) \u00b7 T\u2212 12 +\u03b7 unfairness. For x = Cxlog T with any constant Cx, we let \u03b7 = 3x 2 = 3Cx 2 log T\nand therefore \u03b7 > x. As a result, we have\nCminT \u00b7 exp(\u2212T 2\u03b7) \u00b7 T\u2212 1 2 +\u03b7 = Cmin exp(\u2212T 2\u03b7 + \u03b7 log T )T 1 2\n= Cmin exp(\u2212T 2\u00b7 Cx logT + 3Cx2 log T \u00b7 log T )T 1 2\n= Cmin exp(\u2212 exp(2 \u00b7 Cx log T \u00b7 log T ) + 3Cx 2 )T 1 2 = Cmin exp(\u2212 exp(2Cx) + 3Cx\n2 )T 1 2\n(85)\nLet Cu = Cmin exp(\u2212 exp(2Cx)+ 3Cx2 )\n2 , and then the result of the equation above contradicts with the suppose that the unfairness does not exceed Cu \u00b7 T 1 2 . Therefore, we have proved the theorem."
        },
        {
            "heading": "C More Discussion",
            "text": "Here we discuss more on the problem settings we assumed, the techniques we used and the social impacts our algorithm might have, as a complement to Section 6.\nC.1 Potential Generalizations of Current Problem Setting.\nCurrently we make a few technical assumptions that qualify the applications of our algorithm. In fact, these assumptions are mild and can be released by some tricks: On the one hand, we can always meet the requirement of Assumption 1 by reducing vd. By running a binarysearch algorithm for the highest acceptable price (with constant acceptance probability), we can find the feasible vd within O(log T log T ) rounds (where log T for binary search and another log T for the concentration of a constant-expectation random variable, as we did in estimating Fmin). Since O(log T log T ) is much smaller than O( \u221a T ) as the optimal regret and unfairness, this would not harm the regret and unfairness substantially. On the other hand, we assume the prices to be chosen from a fixed and finite price set V, which not only restricted our action but might lead to suboptimality from the perspective of a larger scope. In fact, if we allow the prices to be selected in the whole [0, 1] range, a pricing policy can be a tuple of two continuous distributions over [0, 1]. To solve this problem, we may parametrize the distribution and learn the best parameters. We may also discretize the price space into small grids, i.e. prices are V = {\u03b3, 2\u03b3, . . . , (d\u2212 1)\u03b3, d\u03b3 = 1}, where \u03b3 = T\u2212\u03b1 with some constant \u03b1 and d= T\u03b1 as a consequence. It is intrinsically a specific way of parametrization. According to the \u201chalf-Lipschitz\u201d nature of pricing problem as well as our Lemma 14 along with the Lipschiness of S(\u03c0;F1, F2), we know that the per-round discretization error would be upper bounded by O(T\u2212\u03b1). Let the cumulative\ndiscretization error O(T 1 \u2212\u03b1) balances the cumulative regret (or substantive unfairness), i.e., O(d 32 \u221a T ) = 0(T 12 + 3\u03b12 ), we can achieve an upper bound on both the regret at O(T 45 ) by letting \u03b1 = T 15 . However, this is not optimal as we only match the upper and lower bounds w.r.t. T but not to d. Therefore, it would also be an interesting problem to see the minimax regret/unfairness dependent w.r.t. d.\nBesides of the assumptions we have made, there are other notions regarding our problem setup that can be generalized. Firstly, we may generalize our problem setting from two groups to multiple G \u2265 3 groups. Again, the feasible set is not empty as we can always propose the same fixed price to all groups. However, there is not a directly generalization of the fairness definition, which we defined as the difference of the expectation of certain amount between two groups. We might defined it as \u201cpairwise unfairness\u201d by comparing the same difference among each pair of groups and adding them up, but this is not rational: Consider the case when the expected proposed/accepted prices in (G\u2212 1) groups are very high and the last one is very low, and compare this case with another case when the expected proposed/accepted prices in 1 groups are very high and the other (G\u2212 1) groups has a very low expected prices. The unfairness in these two cases should be definitely different, as the first seems more acceptable (i.e., being kind to only the minority versus being kind to only the majority). However, their \u201cpairwise unfairness\u201d are exactly the same in these two cases. Therefore, a better notion of procedural/substantive unfairness should be established for multiple G \u2265 3 groups.\nSecondly, we may generalize the modeling on customers from i.i.d. to strategic. For example, what if a customer tries multiple times until getting the lowest price of the distribution for this group. This is an adaptive adversary and therefore very hard to deal with even in the simplest decision-making process such as bandits.\nThirdly, we may also include more fairness concern. Currently we are considering the two types of fairness, but we define the cumulative fairness based as the summation of expected per-round unfairness. This definition does not take into consideration the changing of policies. For example, if we propose a fair policy at each round, but the policies over time changes drastically, then it is hard for the customers to feel or experience such a fairness. In our algorithm design of FPA, we always play the same policy for at least \u03c4k2d = \u2126( \u221a T ) rounds as a batch until the policy changes. This is a long enough time period for customers to experience fairness since at least a Omega( \u221a T ) number of customers from both groups would come and buy items under the same policy according to the Law of Large Numbers. However, this would still cause a feeling of unfairness for the two customers who are arriving almost simultaneously but the policy is just changed after the first customer buy or decide not to buy. Therefore, there exists necessity for us to consider the time/individual fairness under this online pricing problem scheme.\nC.2 Potential Generalization of Techniques\nHere we discuss a little bit more on the probable extension of the techniques we developed in our algorithm design and analysis.\nFrom Two Groups to Multi Groups Our problem setting assumes that there are two groups of customers in total. We choose to study a two-group setting to simplify the presentation. In practice, however, it is very common that customers are coming from a number of groups with different valuations even on the same product. In fact, we believe it straightforward to extend our methodologies and results to multi-group settings, as long as we determine a metric of multi-group unfairness. For instance, if we choose to define the multi-group unfairness as the summation of pairwise unfairness of all pairs of groups, we may adjust our algorithm by lengthening each epoch by G/2 times and keeping everything the same as in this paper. In this way, the upper regret bound would be O\u0303(G2 \u221a Td2/3), which is O(G2) times as we have shown in this paper. Therefore, it is still optimal w.r.t. T up to iterative-log factors.\nA Good-and-exploratory Policy Set Our algorithm FPA maintains and updates a \u201cgood-and-exploratory\u201d policy Ak in each epoch. Each policy in this set performs close to the optimal policy in both regret and unfairness reductions. A similar idea in reinforcement learning related research exists in Qiao et al. [2022] where they select policies that visit each (horizon, state, action) tuple most sufficiently while ensuring that the policy is low in regret. In fact, if we imagine an \u201cexploratory\u201d policy as the one that would elevate the most \u201cinformation\u201d (i.e., that would reduce the most uncertainty), then the \u201cgood-and-exploratory\u201d policy-selection process is equivalent to an \u201cUpper Confidence Bound\u201d method Lai and Robbins [1985] where we always pull the arm with the highest upper confidence bound in a multi-armed bandit. The only difference is that: for traditional exploration-and-exploitation balancing algorithm, we only need to improve our estimation on the parameters of these optimal or near-optimal policies. However, in our problem setting, we have to guarantee a uniform error bound, i.e., we have to improve our estimation on all parameters instead of only those optimal-related ones. This is because that we have to improve the estimation on constraints as well as on the revenue function. In our algorithm design, we handle this problem by keeping eliminating a feasible policy set, which in turn releases the algorithm from estimating those unnecessary parameters. In a nutshell, our methods can be applied broadly in online-decision-making problems.\nUnfairness Lower Bound Proof on Optimal Algorithms The main idea of our proof of the \u2126( \u221a T ) unfairness lower bound on any algorithm with O( \u221a T ) optimal regret is to construct a trade-off on unfairness and regret between two adjacent problem settings. We first bound the \u201cbad policies\u201d away from each problem setting, to avoid those policies that are super fair in both setting but performs poor in both setting as well. Then we show\nthat policies with small-enough regret and unfairness on one setting should suffer a large regret on the other. Finally we end the proof by showing that we will definitely make \u0398\u0303(T ) times of mistakes in expectation, according to information theory. We believe that this scheme can be used in proving a variety of trading-off lower bounds.\nC.3 Social Impacts\nIn this work, we develop methods to prompt the procedural and substantive fairness of customers from all groups. We believe that our techniques and results would enhance the unity of people with different gender, race, age, cultural backgrounds, and so on. However, it is definitely correct that we have to treat differently to different group of people. In order to ensure the fairness from customers\u2019 perspective, the seller is required to behave unfairly. Of course we could partly get rid of this issue by leaving the generating process of a random price to the nature, i.e., we let each customer draw a coupon from a box randomly. However, this only means that the seller\u2019s pricing process is fair but not leads to a fair result, as customers\u2019 coupon varies a lot from person to person. This turn out to be the exact issue named as \u201cpricing and price fairness\u201d proposed in Chapuis [2012] regarding the fairness of a seller\u2019s behavior. Maybe in the future we could develop an algorithm that is not only profitable but also ensures the fairness from both the seller and the customers\u2019 perspective, which could be a truly \u201cdoubly fair\u201d dynamic pricing."
        }
    ],
    "title": "Doubly Fair Dynamic Pricing",
    "year": 2022
}