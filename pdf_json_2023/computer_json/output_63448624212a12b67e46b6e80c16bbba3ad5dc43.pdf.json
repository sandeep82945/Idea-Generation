{
    "abstractText": "This work addresses the employment of Machine Learning (ML) and Domain Adaptation (DA) in the framework of Brain-Computer Interfaces (BCIs) based on Steady-State Visually Evoked Potentials (SSVEPs). Currently, all the state-of-the-art classification strategies do not consider the high non-stationarity typical of brain signals. This can lead to poor performance, expecially when short-time signals have to be considered to allow real-time human-environment interaction. In this regard, ML and DA techniques can represent a suitable strategy to enhance the performance of SSVEPs classification pipelines. In particular, the employment of a two-step DA technique is proposed: first, the standardization of the data per subject is performed by exploiting a part of unlabeled test data during the training stage; second, a similarity measure between subjects is considered in the selection of the validation sets. The proposal was applied to three classifiers to verify the statistical significance of the improvements over the standard approaches. These classifiers were validated and comparatively tested on a well-known public benchmark dataset. An appropriate validation method was used in order to simulate real-world usage. The experimental results show that the proposed approach significantly improves the classification accuracy of SSVEPs. In fact, up to 62.27 % accuracy was achieved also in the case of short-time signals (i.e., 1.0 s). This represents a further confirmation of the suitability of advanced ML to improve the performance of BCIs for daily-life applications. INDEX TERMS Brain-Computer Interface, Domain Adaptation, EEG, EEGNet, Health 4.0, Instrumentation, Machine Learning, Neural Engineering, Neural Networks, SSVEP, Real-Time Systems.",
    "authors": [
        {
            "affiliations": [],
            "name": "ANDREA APICELLA"
        },
        {
            "affiliations": [],
            "name": "PASQUALE ARPAIA"
        },
        {
            "affiliations": [],
            "name": "EGIDIO DE BENEDETTO"
        },
        {
            "affiliations": [],
            "name": "LUIGI DURACCIO"
        },
        {
            "affiliations": [],
            "name": "SALVATORE GIUGLIANO"
        },
        {
            "affiliations": [],
            "name": "ROBERTO PREVETE"
        }
    ],
    "id": "SP:d9edf4e9d171c7153af9823d8bd7879c57e72c9e",
    "references": [
        {
            "authors": [
                "P. Arpaia",
                "L. Duraccio",
                "N. Moccaldi",
                "S. Rossi"
            ],
            "title": "Wearable brain\u2013computer interface instrumentation for robot-based rehabilitation by augmented reality",
            "venue": "IEEE Transactions on Instrumentation and Measurement, vol. 69, no. 9, pp. 6362\u2013 6371, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "J.R. Wolpaw",
                "N. Birbaumer",
                "D.J. McFarland",
                "G. Pfurtscheller",
                "T.M. Vaughan"
            ],
            "title": "Brain\u2013computer interfaces for communication and control",
            "venue": "Clinical neurophysiology, vol. 113, no. 6, pp. 767\u2013791, 2002.",
            "year": 2002
        },
        {
            "authors": [
                "D.J. McFarland",
                "J.R. Wolpaw"
            ],
            "title": "Brain-computer interfaces for communication and control",
            "venue": "Communications of the ACM, vol. 54, no. 5, pp. 60\u201366, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "R.A. Ramadan",
                "A.V. Vasilakos"
            ],
            "title": "Brain computer interface: control signals review",
            "venue": "Neurocomputing, vol. 223, pp. 26\u201344, 2017. VOLUME 10, 2022 9 This article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3266306 This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/",
            "year": 2017
        },
        {
            "authors": [
                "R. Fazel-Rezai",
                "B.Z. Allison",
                "C. Guger",
                "E.W. Sellers",
                "S.C. Kleih",
                "A. K\u00fcbler"
            ],
            "title": "P300 brain computer interface: current challenges and emerging trends",
            "venue": "Frontiers in neuroengineering, p. 14, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "J. Jiang",
                "C. Wang",
                "J. Wu",
                "W. Qin",
                "M. Xu",
                "E. Yin"
            ],
            "title": "Temporal combination pattern optimization based on feature selection method for motor imagery bcis",
            "venue": "Frontiers in Human Neuroscience, vol. 14, p. 231, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Pei",
                "Z. Luo",
                "Y. Yan",
                "H. Yan",
                "J. Jiang",
                "W. Li",
                "L. Xie",
                "E. Yin"
            ],
            "title": "Data augmentation: using channel-level recombination to improve classification performance for motor imagery eeg",
            "venue": "Frontiers in Human Neuroscience, vol. 15, p. 645952, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Pei",
                "T. Sheng",
                "Z. Luo",
                "L. Xie",
                "W. Li",
                "Y. Yan",
                "E. Yin"
            ],
            "title": "A tensor-based frequency features combination method for brain\u2013computer interfaces",
            "venue": "Cognitive Systems and Information Processing: 6th International Conference, ICCSIP 2021, Suzhou, China, November 20\u201321, 2021, Revised Selected Papers 6, pp. 511\u2013526, Springer, 2022.",
            "year": 2021
        },
        {
            "authors": [
                "P. Arpaia",
                "A. Esposito",
                "A. Natalizio",
                "M. Parvis"
            ],
            "title": "How to successfully classify eeg in motor imagery bci: a metrological analysis of the state of the art",
            "venue": "Journal of Neural Engineering, vol. 19, no. 3, p. 031002, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "P. Arpaia",
                "D. Coyle",
                "F. Donnarumma",
                "A. Esposito",
                "A. Natalizio",
                "M. Parvis"
            ],
            "title": "Visual and haptic feedback in detecting motor imagery within a wearable brain\u2013computer interface",
            "venue": "Measurement, vol. 206, p. 112304, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "P. Arpaia",
                "C. Bravaccio",
                "G. Corrado",
                "L. Duraccio",
                "N. Moccaldi",
                "S. Rossi"
            ],
            "title": "Robotic autism rehabilitation by wearable brain-computer interface and augmented reality",
            "venue": "2020 IEEE International Symposium on Medical Measurements and Applications (MeMeA), pp. 1\u20136, IEEE, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "P. Arpaia",
                "E. De Benedetto",
                "N. Donato",
                "L. Duraccio",
                "N. Moccaldi"
            ],
            "title": "A wearable ssvep bci for ar-based, real-time monitoring applications",
            "venue": "2021 IEEE International Symposium on Medical Measurements and Applications (MeMeA), pp. 1\u20136, IEEE, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "C.-M. Wu",
                "Y.-J. Chen",
                "I.A. Zaeni",
                "S.-C. Chen"
            ],
            "title": "A new SSVEP based BCI application on the mobile robot in a maze game",
            "venue": "2016 International Conference on Advanced Materials for Science and Engineering (ICAMSE), pp. 550\u2013 553, IEEE, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "Y. Li",
                "T. Kesavadas"
            ],
            "title": "SSVEP-based brain-computer interface for part-picking robotic co-worker",
            "venue": "Journal of Computing and Information Science in Engineering, vol. 22, no. 2, p. 021001, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "L. Chen",
                "P. Chen",
                "S. Zhao",
                "Z. Luo",
                "W. Chen",
                "Y. Pei",
                "H. Zhao",
                "J. Jiang",
                "M. Xu",
                "Y. Yan"
            ],
            "title": "Adaptive asynchronous control system of robotic arm based on augmented realityassisted brain\u2013computer interface",
            "venue": "Journal of Neural Engineering, vol. 18, no. 6, p. 066005, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "B. Liu",
                "X. Huang",
                "Y. Wang",
                "X. Chen",
                "X. Gao"
            ],
            "title": "Beta: A large benchmark database toward ssvep-bci application",
            "venue": "Frontiers in neuroscience, vol. 14, p. 627, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Q. Wei",
                "M. Xiao",
                "Z. Lu"
            ],
            "title": "A comparative study of canonical correlation analysis and power spectral density analysis for ssvep detection",
            "venue": "2011 Third International Conference on Intelligent Human-Machine Systems and Cybernetics, vol. 2, pp. 7\u201310, IEEE, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "S. Zhang",
                "X. Gao",
                "X. Chen"
            ],
            "title": "Humanoid robot walking in maze controlled by ssvep-bci based on augmented reality stimulus",
            "venue": "Frontiers in Human Neuroscience, vol. 16, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Y. Ke",
                "P. Liu",
                "X. An",
                "X. Song",
                "D. Ming"
            ],
            "title": "An online SSVEP-BCI system in an optical see-through augmented reality environment",
            "venue": "Journal of neural engineering, vol. 17, no. 1, p. 016066, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "M. Azeem",
                "A. Haleem",
                "M. Javaid"
            ],
            "title": "Symbiotic relationship between machine learning and industry 4.0: A review",
            "venue": "Journal of Industrial Integration and Management, p. 2130002, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "K.-R. M\u00fcller",
                "M. Krauledat",
                "G. Dornhege",
                "G. Curio",
                "B. Blankertz"
            ],
            "title": "Machine learning techniques for braincomputer interfaces",
            "venue": "Biomed. Tech, vol. 49, no. 1, pp. 11\u201322, 2004.",
            "year": 2004
        },
        {
            "authors": [
                "R. Singla",
                "B. Haseena"
            ],
            "title": "Comparison of ssvep signal classification techniques using svm and ann models for BCI applications",
            "venue": "International Journal of Information and Electronics Engineering, vol. 4, no. 1, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "M. Farooq",
                "O. Dehzangi"
            ],
            "title": "High accuracy wearable SSVEP detection using feature profiling and dimensionality reduction",
            "venue": "2017 IEEE 14th International Conference on Wearable and Implantable Body Sensor Networks (BSN), pp. 161\u2013 164, IEEE, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "I.A. Ansari",
                "R. Singla",
                "M. Singh"
            ],
            "title": "SSVEP and ANN based optimal speller design for brain computer interface",
            "venue": "Computational Science and Techniques, vol. 2, no. 2, pp. 338\u2013 349, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "T.-H. Nguyen",
                "W.-Y. Chung"
            ],
            "title": "A single-channel SSVEPbased BCI speller using deep learning",
            "venue": "IEEE Access, vol. 7, pp. 1752\u20131763, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "J.J. Podmore",
                "T.P. Breckon",
                "N.K. Aznan",
                "J.D. Connolly"
            ],
            "title": "On the relative contribution of deep convolutional neural networks for ssvep-based bio-signal decoding in BCI speller applications",
            "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering, vol. 27, no. 4, pp. 611\u2013618, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "X. Chen",
                "Y. Wang",
                "S. Gao",
                "T.-P. Jung",
                "X. Gao"
            ],
            "title": "Filter bank canonical correlation analysis for implementing a high-speed ssvep-based brain\u2013computer interface",
            "venue": "Journal of neural engineering, vol. 12, no. 4, p. 046008, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "D. Huang",
                "S. Zhou",
                "D. Jiang"
            ],
            "title": "Generator-based domain adaptation method with knowledge free for cross-subject eeg emotion recognition",
            "venue": "Cognitive Computation, pp. 1\u201312, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "D. Ibanez-Soria",
                "A. Soria-Frisch",
                "J. Garcia-Ojalvo",
                "G. Ruffini"
            ],
            "title": "Characterization of the non-stationary nature of steady-state visual evoked potentials using echo state networks",
            "venue": "PloS one, vol. 14, no. 7, p. e0218771, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "D. Kapgate",
                "D. Kalbande",
                "U. Shrawankar"
            ],
            "title": "Adaptive classification to reduce non-stationarity in visual evoked potential brain-computer interfaces",
            "venue": "Bio-Algorithms and Med- Systems, vol. 15, no. 2, p. 20190020, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J. Quinonero-Candela",
                "M. Sugiyama",
                "A. Schwaighofer",
                "N.D. Lawrence"
            ],
            "title": "Dataset shift in machine learning",
            "year": 2008
        },
        {
            "authors": [
                "J.L. Hagad",
                "T. Kimura",
                "K.-i. Fukui",
                "M. Numao"
            ],
            "title": "Learning subject-generalized topographical eeg embeddings using deep variational autoencoders and domain-adversarial regularization",
            "venue": "Sensors, vol. 21, no. 5, p. 1792, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Wang",
                "X. Chen",
                "X. Gao",
                "S. Gao"
            ],
            "title": "A benchmark dataset for SSVEP-based brain\u2013computer interfaces",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 25, no. 10, pp. 1746\u2013 1752, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "R.T. Schirrmeister",
                "J.T. Springenberg",
                "L.D.J. Fiederer",
                "M. Glasstetter",
                "K. Eggensperger",
                "M. Tangermann",
                "F. Hutter",
                "W. Burgard",
                "T. Ball"
            ],
            "title": "Deep learning with convolutional neural networks for eeg decoding and visualization",
            "venue": "Human brain mapping, vol. 38, no. 11, pp. 5391\u20135420, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "V.J. Lawhern",
                "A.J. Solon",
                "N.R. Waytowich",
                "S.M. Gordon",
                "C.P. Hung",
                "B.J. Lance"
            ],
            "title": "Eegnet: a compact convolutional neural network for eeg-based brain\u2013computer interfaces",
            "venue": "Journal of neural engineering, vol. 15, no. 5, p. 056013, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "W. Zhou",
                "A. Liu",
                "X. Chen"
            ],
            "title": "Compact cnn with dynamic window for ssvep-based bcis",
            "venue": "2022 41st Chinese Control Conference (CCC), pp. 3097\u20133101, IEEE, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "N. Waytowich",
                "V.J. Lawhern",
                "J.O. Garcia",
                "J. Cummings",
                "J. Faller",
                "P. Sajda",
                "J.M. Vettel"
            ],
            "title": "Compact convolutional neural networks for classification of asynchronous steadystate visual evoked potentials",
            "venue": "Journal of neural engineering, vol. 15, no. 6, p. 066031, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "L. Carreti\u00e9"
            ],
            "title": "Exogenous (automatic) attention to emotional stimuli: a review",
            "venue": "Cognitive, Affective, & Behavioral Neuroscience, vol. 14, no. 4, pp. 1228\u20131258, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "C. Jia",
                "X. Gao",
                "B. Hong",
                "S. Gao"
            ],
            "title": "Frequency and phase mixed coding in SSVEP-based brain\u2013computer interface",
            "venue": "IEEE Transactions on Biomedical Engineering, vol. 58, no. 1, pp. 200\u2013206, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "G.R. M\u00fcller-Putz",
                "R. Scherer",
                "C. Brauneis",
                "G. Pfurtscheller"
            ],
            "title": "Steady-state visual evoked potential (SSVEP)-based communication: impact of harmonic frequency components",
            "venue": "Journal of neural engineering, vol. 2, no. 4, p. 123, 2005.",
            "year": 2005
        },
        {
            "authors": [
                "G. Hakvoort",
                "B. Reuderink",
                "M. Obbink"
            ],
            "title": "Comparison of psda and cca detection methods in a SSVEP-based BCIsystem",
            "venue": "Centre for Telematics & Information Technology University of Twente, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "X. Chen",
                "Y. Wang",
                "M. Nakanishi",
                "X. Gao",
                "T.-P. Jung",
                "S. Gao"
            ],
            "title": "High-speed spelling with a noninvasive brain\u2013 computer interface",
            "venue": "Proceedings of the national academy of sciences, vol. 112, no. 44, pp. E6058\u2013E6067, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "Z. Lin",
                "C. Zhang",
                "W. Wu",
                "X. Gao"
            ],
            "title": "Frequency recognition based on canonical correlation analysis for ssvep-based BCIs",
            "venue": "IEEE transactions on biomedical engineering, vol. 53, no. 12, pp. 2610\u20132614, 2006.",
            "year": 2006
        },
        {
            "authors": [
                "P. Arpaia",
                "E. De Benedetto",
                "L. De Paolis",
                "G. D\u2019Errico",
                "N. Donato",
                "L. Duraccio"
            ],
            "title": "Performance enhancement of wearable instrumentation for ar-based ssvep bci",
            "venue": "Measurement, vol. 196, p. 111188, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "P. Arpaia",
                "E. De Benedetto",
                "L. De Paolis",
                "G. D\u2019Errico",
                "N. Donato",
                "L. Duraccio"
            ],
            "title": "Highly wearable ssvep-based bci: Performance comparison of augmented reality solutions for the flickering stimuli rendering",
            "venue": "Measurement: Sensors, vol. 18, p. 100305, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Chen",
                "C. Yang",
                "X. Chen",
                "Y. Wang",
                "X. Gao"
            ],
            "title": "A novel training-free recognition method for SSVEP-based BCIs using dynamic window strategy",
            "venue": "Journal of neural engineering, vol. 18, no. 3, p. 036007, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Apicella",
                "P. Arpaia",
                "E. De Benedetto",
                "N. Donato",
                "L. Duraccio",
                "S. Giugliano",
                "R. Prevete"
            ],
            "title": "Enhancement of ssveps classification in bci-based wearable instrumentation through machine learning techniques",
            "venue": "IEEE Sensors Journal, vol. 22, no. 9, pp. 9087\u20139094, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "X. Glorot",
                "Y. Bengio"
            ],
            "title": "Understanding the difficulty of training deep feedforward neural networks",
            "venue": "Proceedings of the thirteenth international conference on artificial intelligence and statistics, pp. 249\u2013256, JMLR Workshop and Conference Proceedings, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv preprint arXiv:1412.6980, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "D.-A. Clevert",
                "T. Unterthiner",
                "S. Hochreiter"
            ],
            "title": "Fast and accurate deep network learning by exponential linear units (elus)",
            "venue": "arXiv preprint arXiv:1511.07289, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "S. Kullback",
                "R.A. Leibler"
            ],
            "title": "On Information and Sufficiency",
            "venue": "The Annals of Mathematical Statistics, vol. 22, no. 1, pp. 79 \u2013 86, 1951.",
            "year": 1951
        },
        {
            "authors": [
                "L. Angrisani",
                "P. Arpaia",
                "A. Esposito",
                "N. Moccaldi"
            ],
            "title": "A wearable brain\u2013computer interface instrument for augmented reality-based inspection in industry 4.0",
            "venue": "IEEE Transactions on Instrumentation and Measurement, vol. 69, no. 4, pp. 1530\u20131539, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "X. Zhao",
                "Y. Du",
                "R. Zhang"
            ],
            "title": "A cnn-based multi-target fast classification method for ar-ssvep",
            "venue": "Computers in biology and medicine, vol. 141, p. 105042, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "S. Patro",
                "K.K. Sahu"
            ],
            "title": "Normalization: A preprocessing stage",
            "venue": "arXiv preprint arXiv:1503.06462, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "J. Bergstra",
                "Y. Bengio"
            ],
            "title": "Random search for hyperparameter optimization",
            "venue": "Journal of machine learning research, vol. 13, no. 2, 2012.",
            "year": 2012
        }
    ],
    "sections": [
        {
            "text": "INDEX TERMS Brain-Computer Interface, Domain Adaptation, EEG, EEGNet, Health 4.0, Instrumentation, Machine Learning, Neural Engineering, Neural Networks, SSVEP, Real-Time Systems.\nI. INTRODUCTION\nIN recent years, human-machine interaction has beensignificantly improved by the widespread diffusion of Brain-Computer Interfaces (BCIs) [1]. BCIs are an emerging technology integrating hardware and software to create a direct communication pathway between the human brain and external devices [2]. Among the different ways of decoding brain activity, Electroencephalography (EEG) is receiving a strong interest by the scientific community since it is non-invasive, cheap, and is endowed with high temporal resolution to allow real-time operation [3], [4]. In fact, different EEG-based\nBCI paradigms, such as P300 [5] and Motor Imagery [6]\u2013[10] have already been successfully employed in several contexts but, in particular, Steady-State Visually Evoked Potentials (SSVEPs) have gained outstanding relevance for the development of applications in healthcare, [11], [12] entertainment [13], and industry [14], [15] owing to quick response, easy detection, high signalto-noise ratio (SNR) [16]. As a matter of fact, the classification of SSVEPs can be performed with good results even with simple, trainingless algorithms, such as Power Spectral Density Analysis (PSDA) or Canonical Correlation Analysis (CCA) [17]. Nevertheless, there\nVOLUME 10, 2022 1\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nis much room for improvements aimed at employing SSVEP-based BCIs in challenging contexts, where the requirements are very demanding [18], [19].\nTo this aim, the widespread adoption of 4 .0 enabling technologies such as Artificial Intelligence (AI) and, in particular, Machine Learning (ML) [20], has raised the question of whether this family of technologies can improve the performance of such systems [21]. Among the ML paradigms, supervised ML models learn to predict outputs on the basis of given examples of relationships between input data and outputs (the training data). In this regard, several related works have already addressed the use of ML classifiers in SSVEPs classification, such as (i) Support Vector Machine (SVM) [22], (ii) kNearest Neighbors (k-NN) [23], and (iii) Artificial Neural Networks (ANNs) [24], by showing that ML represents a very promising strategy to boost the performance of their SSVEP-based BCIs. It has also been empirically shown that increasing the model complexity can lead to further enhancements in classification accuracy in several cases. For the sake of example, in [25], [26], the realized Convolutional Neural Networks (CNNs) allowed to achieve, under specific conditions, higher performance than Filter Bank Canonical Correlation Analysis (FBCCA) [27], which is currently considered the state of the art about SSVEPs classification [26].\nHowever, when short-time input signals are taken into account (i.e., lower than 1.5 s), the classification of SSVEPs can still be strongly improved as a means to allow real-time human-environment interaction. Currently, in fact, most of the literature considers SSVEPs only as a steady-state response given by purely oscillatory components synchronized in phase with the stimulation source, thus not considering the intrinsic non-stationarity of EEG signals [28], resulting in strong differences across the EEGs acquired from different subjects or at different time intervals (sessions). This can represent a limitation in SSVEPs classification and, in our knowledge, it is currently taken into account only in few studies [29], [30].\nA. THE DATASET SHIFT PROBLEM From a ML point of view, this issue can be viewed as an instance of the Dataset Shift problem [31]. In a nutshell, a Dataset Shift arises when the distribution of the data used to train the ML model differs from the data distribution used outside of the training stage. This violates one of the main assumption of ML approaches, stating that all the data, no matter if involved in training or not, come from the same probability distribution. As a consequence, the trained model won\u2019t work as expected on data acquired from different subjects or at different sessions with respect to the ones used during the training stage. This problem is usually mitigated by training specific models for each subject (called intra \u2212 subject models). However, an intra-\nsubject model can be used only on data acquired from the subject providing training data. Moreover, also in this case the Dataset Shift problem can arise insofar as data are collected from substantially different sessions.\nFor these reasons, newer studies tried to overcome the Dataset Shift problem in EEG-based BCIs [32]. In particular, Domain Adaptation (DA) strategies try to construct models able to generalize on unseen data exploiting knowledge given by available unlabelled data. These strategies rely on the assumption that a small initial part (even unlabeled) of the new user\u2019s data is already available before the actual classification. Although time-consuming, acquiring unlabeled data from a new user/session is still easier than getting labeled data, leading a BCI system to be more comfortable than one trained only on user/session-specific labeled data."
        },
        {
            "heading": "B. PROPOSAL",
            "text": "Starting from these considerations, in this work, a DA technique is proposed in the framework of the SSVEPs classification. More specifically, a two-step DA method is validated on a public dataset described in [33] and composed of 35 subjects and 40 simultaneous flickering stimuli. The remarkable number of subjects and flickering stimuli allows considering this dataset a challenging benchmark to significantly test SSVEPs classification algorithms. Following [26], a suitable validation method was adopted to simulate real-world usage in a statistically significant way.\nThe proposed DA technique is composed of two main steps, the former consisting in a per-subject z-score normalization (instead of the classical z-score applied on all the data without regard to the belonging domain), and the latter consisting in a simple change in the classical neural network training procedure. More in detail, in the classical neural network training stage a subset of the training data (named validation set) is used to prevent the network to overfit on the training data. Then, the performance of the network on the validation data are computed at the end of each training iteration, and the training stage is stopped when the validation performance starts to degrade rather than improve [34]. However, the validation set is usually selected randomly from the training data, without any regards about the original distribution of the data. In cases where several distribution are involved, such as in EEG data acquired from several subjects, this could not be the better choice, since data too dissimilar from the test data could be chosen, not leading the network to generalize toward unseen domains. Instead, if also a small part of unlabelled data coming from the target subject are available during the training time, this can be used to choose the validation set in a smarter way respect to the random choice. In this study, 20 % of the test data was considered as calibration data, therefore available at the training data without any label. These"
        },
        {
            "heading": "2 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\ndata can be used both to standardize the data and to compute a similarity measure between subjects to select the validation sets.\nThe statistical significance of the improvements made by the proposed DA technique over the standard approaches was validated on three different neural network classifiers: ShallowConvNet , DeepConvNet , and EEGNet . ShallowConvNet and DeepConvNet are two CNNs developed in [35] and used in Motory Imagerybased BCIs. Instead, EEGNet is a compact CNN successfully employed in several tasks involving different types of EEG signals, such as P300 visual-evoked potentials, Error-Related Negativity Response (ERN), Movement-Related Cortical Potentials (MRCP), and Sensory Motor Rhythms (SMR), showing comparably high performance with respect to the reference algorithms [36]. More recently, it has gained interest also in SSVEP-based BCIs [37]. In particular, promising results in terms of classification accuracy are reported in literature [38]. In our knowledge, however, this is the first time that EEGNet is tested to the benchmark dataset considered.\nThe paper is organized as follows. Sec. II provides a background on the SSVEPs classification problem, reporting some of the most widely adopted processing strategies over the years. Then, Sec. III describes, in brief, the classifiers chosen, along with the validation method and the DA technique considered. Therefore, Sec. IV reports the experimental setup, and Sec. V provides a comparative analysis between the results obtained by the proposed approach and those achieved with traditional, state-of-the-art strategies. Finally, conclusions are drawn.\nII. BACKGROUND AND RELATED WORKS This Section provides a background on the SSVEPs classification problem. In addition, an overview on some of the most widely adopted processing strategies is given.\nA. THE SSVEPS CLASSIFICATION PROBLEM SSVEPs are exogenous brain potentials [39], elicited in the primary visual cortex when a flickering stimulus is observed by the user. Stimulation frequency bands of the visual stimuli usually range from 6 Hz to 30 Hz, although the best Signal to Noise Ratio (SNR) is achieved in the range 8\u00f715 Hz [40]. The physiological SSVEP brain response is typically inducted after a latency ranging from 80 to 160 ms [41]. It is a sinusoidal-like waveform, composed of a fundamental frequency equal to that of the gazed stimulus, and often higher harmonics [42], as shown in Fig. 1. In practical applications, stimuli at different frequencies are simultaneously displayed to the user. Each stimulus is associated to a specific command: the user, by looking at the desired flickering stimulus, is able to send the related command to the target application.\nA representative architecture of SSVEP-based BCIs is shown in Fig. 2. A Stimuli Source (typically, a LCD monitor, or an eXtended Reality headset [15], [19]) is used to display N concurrent flickering stimuli . Each stimulus flickers at a different frequency from the others and is associated to a specific command to send to the BCIapplication. An EEG headset captures the user\u2019s brain signals, which are digitized and processed by means of a SSVEP classification algorithm. The aim of this algorithm is to deduce which stimulus has been observed by the user. Therefore, the recognition of N stimuli at different frequencies can be viewed as a N-class classification problem. Once the classification has been made, an output command is sent to the BCI Application, which provides a feedback to the user regarding the selection performed. Clearly, if the classification is successful, the output command corresponds\nVOLUME 10, 2022 3\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nto the choice desired by the user.\nB. PROCESSING STRATEGIES FOR CLASSIFYING SSVEPS\nAn overview of some of the typical processing strategies for classifying SSVEPs is given as follows. In particular, a distinction between non-ML, hybrid, and ML methods is made. For the sake of simplicity, but without loss of generality, a single-channel EEG signal is considered."
        },
        {
            "heading": "1) Non-ML Methods",
            "text": "\u2022 PSDA: Since SSVEPs are characterized by fre-\nquency peaks consistent with the observed flickering stimuli, the most intuitive approach used to detect and classify the elicited SSVEPs is based on a Power Spectral Density Analysis (PSDA) [40]. This method is composed by three steps: first, a Fast Fourier Transform (FFT) is applied to the user EEG; then, a PSD is performed in the neighborhood of each of the N frequencies rendered on the display, and eventually its multiple m harmonics, according to (1).\nP(fn) = 1\n2mk + 1  m\u2211 j=1 jkn+k\u2211 i=jkn\u2212k c(j) A2(i)  (1)\nWhere: P(fn) is the PSD coefficient for the given frequency fn (n = 1, 2, ...,N), kn is the corresponding bin in frequency domain, k is the number of nearest bins to be considered, m is the number of chosen harmonics, A is the signal amplitude, and c is a weight assigned to each harmonics. Finally, the classification is usually performed based on the hypothesis that the observed stimulus is very likely to be the one with the highest PSD [43]. The main drawback of PSDA is that it requires a minimum time window Tmin of the acquired EEG in order to correctly discriminate the harmonics, since an appropriate frequency resolution \u2206f = 1Tmin is needed [44]. \u2022 CCA: An alternative way to process SSVEPs is the Canonical Correlation Analysis (CCA) in time domain [15]. It is a multivariate statistical method of correlating linear relationships between two sets of data [45]. CCA is performed between the EEG data D and a set of sine waves yn(t) having the same frequencies of the N stimuli rendered on the display, and eventually their multiple harmonics. Given a frequency fn and the number of harmonics m to consider, the set of sinewaves yn(t) (n = 1, 2, ...,N)\ncan be obtained according to (2).\nyn(t) =  sin(2\u03c0 fn t) cos(2\u03c0 fn t) sin(4\u03c0 fn t) cos(4\u03c0 fn t) ...\nsin(m\u03c0 fn t) cos(m\u03c0 fn t)\n (2)\nFor each stimulus frequency fn, a correlation coefficient \u03c1n is extracted by means of the CCA between D and yn(t). Therefore, these coefficients are used for SSVEP classification. For the sake of example, in [45] the output of the classification was associated to the frequency with the highest correlation coefficient extracted. Alternatively, in [1], [46], [47] the maximum value among the correlation coefficients \u03c1n was compared with given threshold values: the signal was marked as classified only if the chosen correlation coefficient exceeded the thresholds. The classification performance achieved with the use of CCA are typically better than PSDA [43]. However, a band pass filtering for the EEG can be often necessary during the pre-processing phase, due to the effect of spontaneous EEG activities not involved in SSVEP events. \u2022 FBCCA: The FBCCA method is an enhancement of CCA [27] and consists of three major procedures: (i) filter bank analysis; (ii) CCA between SSVEP sub-band components and sinusoidal reference signals; and (iii) signal classification. First, sub-band decompositions are performed by the filter bank analysis by means of multiple filters with different pass-bands. In this way, the sub-band components XSBj (j = 1, 2, ..., s) from the original EEG X are obtained. After the filter bank analysis, the standard CCA is applied to each of the sub-band components separately. This results in correlation values between the sub-band components and the sinusoidal reference signals corresponding to the stimulation frequencies (n = 1, 2, ...,N). A correlation value \u03c1nj is obtained for each frequency n and each sub-band j according to (3).\n\u03c1n = [ \u03c1n1 , \u03c1 n 2 , ..., \u03c1 n j , ..., \u03c1 n s ] (3)\nA weighted sum of squares of the correlation values corresponding to all sub-band components is calculated as the feature for signal classification.\n\u03c1\u0303n = s\u2211 j=1 w(j) \u00b7 (\u03c1nj )2 (4)\nwhere j is the index of the sub-band. As the SNR of SSVEP harmonics decreases as the response"
        },
        {
            "heading": "4 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nFIGURE 3. Main blocks of the three classifiers chosen: ShallowConvNet (left), DeepConvNet (center), and EEGNet (right)\nfrequency increases, the weights for the sub-band components are defined as follows:\nw(j) = j\u2212a + b (5)\nwhere a and b are constants that maximize the classification performance. Therefore, N features \u03c1\u0303n are obtained (one for each frequency). Finally, the signal classification is performed on the basis that the observed frequency fz (z \u2208 1, ...,N) is that corresponding to the feature \u03c1\u0303z with the maximum value. Typically, the number of filters s, the number of harmonics m, and the values of a and b are determined using a grid search method in an offline analysis. A widely adopted practice is to vary s from 1 to 10, m from 1 to 6, a from 0 to 2, and b from 0 to 1."
        },
        {
            "heading": "2) Hybrid Methods",
            "text": "At the state of the art, CCA-based algorithms provide the best performance in terms of classification accuracy [33], [48]. However, recent works [49] showed that, for low-channels and low-stimuli setups, the adoption of hybrid approaches, based on a pre-processing of the EEG signal in time and frequency domains, and a MLbased classification, allows to outperform the results obtained by CCA. In particular, the algorithm developed in [49] (named Features Reduction) is constituted by (i) a pre-processing step, based both on Power Spectral Density Analysis (PSDA) and Canonical Correlation Analysis (CCA), to extract significant features from the digitized EEG signal, and (ii) a classification step which employs ML classifiers such as SVM, K-NN, and shallow NN to classify the extracted features into an output z (z \u2208 1, ...,N), where N is the number of stimulation frequencies."
        },
        {
            "heading": "3) ML Methods",
            "text": "PodNet is a CNN developed by Podmore et Al. [26]. It is constituted by several blocks (Pods), each one made up of a Convolutional layer, a Drop-out layer, a Batch Normalization layer, a Rectifier Linear Unit (ReLU) layer, and a Max Pooling layer. The final Pod\ncontains a dense layer which outputs to a Softmax operation to classify the EEG into one of the possible z (z \u2208 1, ...,N) classes, where N is the number of stimulation frequencies. All network weights are initialized using the Xavier method [50] and updated following the Adam optimization algorithm [51]. In [26], it has been shown that PodNet manages to outperform FBCCA, even if only under specific conditions (i.e., low-volume EEG electrode arrangements). Nevertheless, there is still much room for improvements when short-time input signals are taken into account, which are critical for facilitating real-time human-environment interaction."
        },
        {
            "heading": "III. MATERIALS AND METHODS",
            "text": "This Section describes the classifiers chosen, along with the validation method and DA technique proposed."
        },
        {
            "heading": "A. CLASSIFIERS CHOSEN",
            "text": "The three classifiers employed in this work were ShallowConvNet, DeepConvNet, and EEGNet, as shown in Fig. 3.\n1) ShallowConvNet is a Convolutional Neural Network developed in [35] and characterized by a single block, where two convolutional layers, which perform a temporal convolution and a spatial filter, are followed by a Batch Normalization layer with ELU activation function, an Average Pooling layer, a Dropout layer, and, finally, a Dense Softmax classification layer. 2) DeepConvNet is a Convolutional Neural Network developed in [35] and composed of four blocks:\n\u2022 The first block consists of two convolutional layers which perform a temporal convolution and a spatial filter. Then, Batch Normalization is applied, followed by Exponential Linear Unit (ELU) [52] activation function. Finally, a Max Pooling layer and Dropout layer are used. \u2022 The other three blocks are classic convolutional blocks, in which only one convolutional layer is followed by the same layers of the first block: Batch Normalization, Activation, Max Pooling, and Dropout.\nVOLUME 10, 2022 5\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n3) EEGNet is a Convolutional Neural Network originally designed to be applied to a wide variety of BCI paradigms (for further details, please refer to [36]). A brief description of the main blocks is provided as follows:\n\u2022 In the first block, a classical convolutional layer is applied to the input EEG signal, followed by a Depthwise Convolution layer [36]. Then, Batch Normalization is applied followed by ELU. Finally, an Average Pooling layer of size (1, 4) is used to reduce the sampling rate of the signal followed by a Dropout layer. \u2022 In the second block, a Separable Convolution [36] is used. After a Batch Normalization followed by the ELU activation function, a final Average Pooling layer followed by a Dropout layer is applied. \u2022 Final classification is made using applying a Softmax function directly, avoiding the use of a prior dense layer for feature aggregation to reduce the number of free parameters in the model.\nB. VALIDATION METHOD EEGNet was validated on the benchmark dataset with a repeated Hold-Out validation: following [26], this work included 25 subjects in the training set, 5 in the validation set, and the remaining 5 in the test set. In addition, 10 runs were made for each combination of the model\u2019s hyperparameters to make the reported results more statistically significant. Only novel BCI subjects were included in the test set to simulate real-world usage, as proposed in [26].\nC. DOMAIN ADAPTATION TECHNIQUE A two-step Domain Adaptation technique was applied during the training of the three analyzed models (ShallowConvNet, DeepConvNet, and EEGNet) on the benchmark dataset:\n1) DA-based Standardization: The relying hypothesis is that each subject data can be considered as belonging to a different Domain. Therefore, instead of the classical z-score normalization on the whole training data, a z-score standardization of the data subject-by-subject was made. In particular, for each subject Si belonging to the training and validation sets, all the related data were used to extract the subject mean value \u00b5i and the subject standard deviation \u03c3i. Therefore, a subject-wise z-score normalization was performed. Instead, for each subject St belonging to the test set, 20 % of the data was considered as unlabelled calibration data available during the training. The mean \u00b5t and the standard deviation \u03c3t was computed on the calibration data and used to perform a z-score normalization on the whole subject data.\n2) Similarity between Subjects: The similarity between subjects was considered in the selection of the validation sets. In general, a validation set is used to control the overfit of the network during the training. More in detail, the performance on the validation set are computed during the training stage and if it tends to get worse, the training is stopped. Differently from classical neural networks\u2019 learning strategies, where the validation set is selected from the training data randomly, in this study the validation sets were composed of the subjects closest to those who provided calibration data. Our starting hypothesis is that a proper validation set selected on the basis of the calibration data provided by test subjects can lead to learn a model able to better classify the data coming from the target distribution. In this study, Kullback-Leibler (KL) divergence [53] was used to measure the similarity between training and calibration data. More in detail, for each pair of subjects, their similarity is computed as follows:\nsim(Si,Sj) = 1\nK K\u2211 k=1 KL(Ski , S k j ), \u22001 \u2264 i, j \u2264 N\nWhere: S1, S2, . . . ,SN are the N subjects and K is the number of EEG channels."
        },
        {
            "heading": "IV. EXPERIMENTAL SETUP",
            "text": "This section provides an overview on the benchmark dataset considered [33]. Moreover, the pre-processing strategies and the model selection criteria are described."
        },
        {
            "heading": "A. DATA DESCRIPTION",
            "text": "The benchmark dataset has the following features:\n\u2022 Subjects: 35 healthy subjects (17 females and 18 males, aged 17\u201334 years, mean age: 22 years), having normal or corrected-to-normal vision, participated in this study. 8 subjects had previous experience in SSVEP-based BCI. \u2022 Stimulus Presentation: An offline BCI experiment using a 40-target BCI speller was designed. The 5 \u00d7 8 stimulus matrix was presented on a 23.6-in LCD monitor (Acer GD245 HQ, response time: 2 ms) with a resolution of 1920 \u00d7 1080 pixels, and a refresh rate of 60 Hz. The viewing distance to the screen was 70 cm. The sizes of stimulus and character were 140 \u00d7 140 and 32 \u00d7 32 pixels square, respectively. The size of the whole matrix area was 1510 \u00d7 1037 pixels. Both the vertical and horizontal distances between two neighboring stimuli were 50 pixels. The stimulus program was developed under MATLAB using the Psychophysics Toolbox Ver. 3. The 40 characters were coded using a joint frequency and phase modulation (JFPM) approach."
        },
        {
            "heading": "6 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nIn particular, the chosen frequencies were in the range [8.0-15.8] Hz with a 0.2 Hz step, while the phase values had a 0.5 \u03c0 step. A sampled sinusoidal stimulation method was applied to present visual flickers on the LCD monitor. Given a frequency f and a phase \u03b8, the stimulus sequence s(f, \u03b8, i) was generated by modulating the luminance of the screen according to 6 [33]:\ns(f, \u03b8, i) = 1\n2 {1 + sin[2\u03c0 f (i/RR) + \u03b8]} (6)\nwhere sin(\u00b7) generates a sine wave, and i indicates the frame index in the sequence. The refresh rate of the LCD monitor is indicated with RR. In the obtained stimulus sequence, 0 and 1 represent darkest and highest luminance, respectively. \u2022 Data acquisition: A Synamps2 EEG acquisition unit (Neuroscan, Inc.) was used to record EEG data at a sampling rate of 1 kSa/s. 64 electrodes, used to record whole-head EEG. The reference electrode was placed at the vertex of the user scalp (Cz). The electrode impedances were kept below 10 k \u2126 during the recording phase. A notch filter at 50 Hz was applied to remove the power-line noise. For each subject, the experiment included six blocks. Each block was composed of 40 trials, corresponding to all 40 squares. Each trial started with a 0.5-s target cue. Subjects were asked to shift their gaze to the indicated target as soon as possible. After the cue, all stimuli started to flicker on the screen concurrently for 5 s. Then, the screen became blank for 0.5 s, before the start of the next trial. Subjects were asked to avoid eye blinks during the 5-s stimulation duration. A rest for several minutes between two consecutive blocks was foreseen.\nB. PRE-PROCESSING Ten channels from the occipital and parietal areas were selected for the experiments, namely PO8 , PO7 , PO6 , PO5 , PO4 , PO3 , POz , O2 , O1 , and Oz , according to the International 10-20 System [33], as conducted in [26]. The time windows considered were 0.5, 1.0, and 1.5 s as they are typically considered the most challenging in view of using BCIs for real-time applications [55]. Therefore, the analysis at 5.0 s was excluded, also because the user would too long be obliged to gaze at the desired flickering stimulus, resulting in ocular discomfort. In all cases, the time duration of the target cue was discarded. The data extracted are then filtered by means of a band-pass Finite Impulsive Response (FIR) filter [49] with linear phase response, which avoids distortions on the original data and preserves the information contribution of the alpha and beta bands. Therefore, the\nstandardization of the data was performed in two ways: (i) canonical z-score normalization [56], and ii) according to the proposed DA technique mentioned in Sec. III-C."
        },
        {
            "heading": "C. SELECTION OF THE BEST MODEL",
            "text": "A random search strategy [57] was adopted to select the hyperparameters values of ShallowConvNet, DeepConvNet, and EEGNet. The hyperparameters spaces of each model are reported respectively in Tables 1, 2 and 3. In particular, on the three models, the Temporal Kernel Length hyperparameter is related to the signal sample rate and the time window input; with regards to EEGNet, the 2D convolutional layers of the first and second blocks, share the same number of filters. Furthermore, during the learning phase, a stop criterion was used by means of a patience of 10 epochs. The hyperparameters values leading the model toward the best performance in terms of mean classification accuracy (defined as the percentage of signals correctly classified) were selected.\nHyperparameter Range Temporal Kernel Length {250, 500, \u230a250 \u2217 seconds\u230b} 2D Convolutional Filters Block1 {20, 40, 80} Pool Size {10, 35} Stride {2, 7} Dropout Type Dropout Learning Rate 0.001 Optimizer Adam [58] Batch Size 32 Dropout Rate 0.5"
        },
        {
            "heading": "V. EXPERIMENTAL RESULTS",
            "text": "In this Section, the results achieved by the proposed approach on the benchmark dataset [33] are reported. A\nVOLUME 10, 2022 7\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\ncomparison with the performance obtained by several well-known strategies proposed in literature, that are PodNet [26], CCA, and FBCCA [27], was made. More in detail, Tab. 4 provides the classification accuracy and standard deviations for several time windows T, namely T = {0.5 s, 1.0 s, 1.5 s}. To validate the proposed approach, also a standard ML approach consisting in standard z-score normalization parameters computed on the whole training data and classical validation set composed of random data extracted from the training data was considered as baseline. In other words, the following two experiments were made:\n\u2022 DA experiment: in this case, the two-step DA technique proposed in Sec. III (DA-based standardization and similarity between subjects) is employed. \u2022 Standard experiments: in this case, a standard ML approach (canonical z-score normalization and random validation sets) is adopted.\nAs specified in Sec. III, the validation method used was an Hold-Out with a 25-5-5 split repeated 10 times. This setup allows to compare the proposal with the results achieved by PodNet reported in [26]. Moreover, the same validation method was also applied to CCA and FBCCA, implemented as described in [27]. However, several details needed for experimental repeatability, such as the precise validation procedure, are missing\nin the original study, therefore the FBCCA results obtained in this work are different from those reported in [27]. As stated in Sec. III, the 10 test sets were created randomly, with the only condition of excluding BCI-experienced subjects to simulate real-world usage. Preliminary experiments , in fact, showed that the performance of the expert participants were significantly higher than those obtained by naive ones. For the sake of example, given a 1.0-s time window, the mean accuracy obtained by EEGNet - DA on the eight experienced subjects was greater than 75 %, while that on the novel ones was only about 61 %. A similar condition happened with FBCCA: in that case, the mean accuracy obtained on the expert subjects was about 54 %, while that on the naive ones was only 40 %. Therefore, the proposed experiments including only BCI-novels subjects were considered more suitable to validate the usage of BCIs in real-world scenarios.\nWith regard to the findings reported in Tab. 4, the mean classification accuracy achieved by EEGNet, DeepConvNet, and ShallowConvNet when the two-step DA technique is applied results greater than the baseline in all the analyzed cases. For the sake of example, EEGNet - DA achieves about 62 % accuracy at 1.0 s, while EEGNet - Standard is limited to about 57 %, and FBCCA reaches only 39 %. Therefore, the adoption of the proposed DA method leads to an improvement of the performance with respect to the baseline.\nFig. 4 illustrates the boxplot of the accuracy achieved by all the aforementioned processing strategies, as a function of the time window T. The length of the whiskers is set to 1.5 times the Interquartile Range (IQR). The statistical significance of the results was tested by means of the Paired T \u2212 Test .\n\u2022 First, it was verified that the proposed DA technique significantly outperforms traditional ML strategies. To this aim, the chosen null hypothesis H0 was that the classifiers DA and Standard belonged to the same population. \u2022 Second, it was verified that the classifiers employed with the DA technique significantly outperform FBCCA, which is the gold standard in terms of SSVEPs classification. Therefore, the chosen null hypothesis H0 was that the classifiers DA and FBCCA belonged to the same population.\nIn Tab. 5, the details of the tests performed are shown in terms of P-Value, that is the probability of failing to reject the null hypothesis H0. The obtained P-Values can be considered acceptable to confirm that the adoption of DA techniques leads to relevant improvements in classification accuracy with respect both to traditional ML approaches and to FBCCA strategy, which is currently the state of the art in the field of SSVEPs classification. These improvements are more evident when the time windows are equal to 0.5 s and 1.0 s. In fact, in these"
        },
        {
            "heading": "8 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nFIGURE 4. Boxplot of the obtained results as a function of the time window\nTABLE 5. Details about the p-values obtained from the t-tests conducted\nT\u2212Test(H0 = same distribution) T = 0.5s T = 1.0s T = 1.5s ShallowConvNet (DA vs Standard) <0.05 <0.05 <0.50 DeepConvNet (DA vs Standard) <0.50 <0.10 <0.50 EEGNet (DA vs Standard) <0.05 <0.05 <0.05 ShallowConvNet - DA vs FBCCA <0.01 <0.01 <0.01 DeepConvNet - DA vs FBCCA <0.01 <0.01 <0.50 EEGNet - DA vs FBCCA <0.01 <0.01 <0.50\ncases, the obtained P-Values considerably decrease with respect to those obtained at 1.5 s.\nVI. CONCLUSIONS In this work, the employment of Machine Learning (ML) and Domain Adaptation (DA) in the framework of Brain-Computer Interfaces (BCIs) based on SteadyState Visually Evoked Potentials (SSVEPs) was addressed. Three well-known classifiers were employed to validate the proposed method, namely ShallowConvNet, DeepConvNet, and EEGNet. For each classifier, a twostep DA technique was applied: i) a percentage of the test data was considered available as a calibration set during the training stage, in order to standardize data per subject, and ii) a similarity measure between subjects was considered in the creation of the validation sets. This was made with the aim to reduce the high nonstationarity typical of the brain signals, leading to improved classification accuracy. The experimental results were obtained by testing the proposal on a benchmark dataset, composed of 35 subjects and 40 simultaneous flickering stimuli. A 10-run Hold-Out Validation was used to simulate real-world usage in a statistically significant way. The experimental results show that the proposed DA approach significantly helps to improve classification accuracy both over standard ML strategies and FBCCA, which is currently considered the gold\nstandard in terms of SSVEPs classification [26]. In fact, the low p-values obtained suggest that, for short-time signals, a Dataset Shift problem may arise due to the non-stationarity of EEG signals. Performance of 62.27 % accuracy was achieved by EEGNet - DA with a time window of only 1.0 s, while EEGNet - Standard and FBCCA reached 56.82 % and 39.34 %, respectively. This allows easier development of SSVEP-based BCIs in contexts where short-time signals are required for real-time human-environment interactions. Future work will be dedicated to further enhance the classification performance in order to achieve satisfactory results even with time windows equal to or lower than 1.0 s."
        },
        {
            "heading": "10 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nneural systems and rehabilitation engineering, vol. 14, no. 2, pp. 234\u2013240, 2006. [41] C. Jia, X. Gao, B. Hong, and S. Gao, \u201cFrequency and phase mixed coding in SSVEP-based brain\u2013computer interface,\u201d IEEE Transactions on Biomedical Engineering, vol. 58, no. 1, pp. 200\u2013206, 2010. [42] G. R. M\u00fcller-Putz, R. Scherer, C. Brauneis, and G. Pfurtscheller, \u201cSteady-state visual evoked potential (SSVEP)-based communication: impact of harmonic frequency components,\u201d Journal of neural engineering, vol. 2, no. 4, p. 123, 2005. [43] G. Hakvoort, B. Reuderink, and M. Obbink, \u201cComparison of psda and cca detection methods in a SSVEP-based BCIsystem,\u201d Centre for Telematics & Information Technology University of Twente, 2011. [44] X. Chen, Y. Wang, M. Nakanishi, X. Gao, T.-P. Jung, and S. Gao, \u201cHigh-speed spelling with a noninvasive brain\u2013 computer interface,\u201d Proceedings of the national academy of sciences, vol. 112, no. 44, pp. E6058\u2013E6067, 2015. [45] Z. Lin, C. Zhang, W. Wu, and X. Gao, \u201cFrequency recognition based on canonical correlation analysis for ssvep-based BCIs,\u201d IEEE transactions on biomedical engineering, vol. 53, no. 12, pp. 2610\u20132614, 2006. [46] P. Arpaia, E. De Benedetto, L. De Paolis, G. D\u2019Errico, N. Donato, and L. Duraccio, \u201cPerformance enhancement of wearable instrumentation for ar-based ssvep bci,\u201d Measurement, vol. 196, p. 111188, 2022. [47] P. Arpaia, E. De Benedetto, L. De Paolis, G. D\u2019Errico, N. Donato, and L. Duraccio, \u201cHighly wearable ssvep-based bci: Performance comparison of augmented reality solutions for the flickering stimuli rendering,\u201d Measurement: Sensors, vol. 18, p. 100305, 2021. [48] Y. Chen, C. Yang, X. Chen, Y. Wang, and X. Gao, \u201cA novel training-free recognition method for SSVEP-based BCIs using dynamic window strategy,\u201d Journal of neural engineering, vol. 18, no. 3, p. 036007, 2021. [49] A. Apicella, P. Arpaia, E. De Benedetto, N. Donato, L. Duraccio, S. Giugliano, and R. Prevete, \u201cEnhancement of ssveps classification in bci-based wearable instrumentation through machine learning techniques,\u201d IEEE Sensors Journal, vol. 22, no. 9, pp. 9087\u20139094, 2022. [50] X. Glorot and Y. Bengio, \u201cUnderstanding the difficulty of training deep feedforward neural networks,\u201d in Proceedings of the thirteenth international conference on artificial intelligence and statistics, pp. 249\u2013256, JMLR Workshop and Conference Proceedings, 2010. [51] D. P. Kingma and J. Ba, \u201cAdam: A method for stochastic optimization,\u201d arXiv preprint arXiv:1412.6980, 2014. [52] D.-A. Clevert, T. Unterthiner, and S. Hochreiter, \u201cFast and accurate deep network learning by exponential linear units (elus),\u201d arXiv preprint arXiv:1511.07289, 2015. [53] S. Kullback and R. A. Leibler, \u201cOn Information and Sufficiency,\u201d The Annals of Mathematical Statistics, vol. 22, no. 1, pp. 79 \u2013 86, 1951. [54] L. Angrisani, P. Arpaia, A. Esposito, and N. Moccaldi, \u201cA wearable brain\u2013computer interface instrument for augmented reality-based inspection in industry 4.0,\u201d IEEE Transactions on Instrumentation and Measurement, vol. 69, no. 4, pp. 1530\u20131539, 2019. [55] X. Zhao, Y. Du, and R. Zhang, \u201cA cnn-based multi-target fast classification method for ar-ssvep,\u201d Computers in biology and medicine, vol. 141, p. 105042, 2022. [56] S. Patro and K. K. Sahu, \u201cNormalization: A preprocessing stage,\u201d arXiv preprint arXiv:1503.06462, 2015. [57] J. Bergstra and Y. Bengio, \u201cRandom search for hyperparameter optimization.,\u201d Journal of machine learning research, vol. 13, no. 2, 2012. [58] D. Kingma and J. Ba, \u201cAdam: A method for stochastic optimization,\u201d International Conference on Learning Representations, 12 2014.\nANDREA APICELLA received the M.S. degree in Computer Science and the Ph.D. degree in Mathematics and Computer Science from the University of Naples Federico II, Italy, in 2014 and 2019, respectively. He is currently a Researcher with the Department of Information Technology and Electrical Engineering of University of Naples Federico II. His current research interests include Artificial Intelligence methods and eXplainable Artificial Intelligence (XAI) approaches for explaining the AI system\u2019s decisions.\nPASQUALE ARPAIA (SM\u201914) received the M.S. and Ph.D. degrees in electrical engineering from the University of Naples Federico II, Naples, Italy, in 1987 and 1992, respectively. He was an Associate Professor with the University of Sannio, Benevento, Italy. He is currently a Full Professor of instrumentation and measurements with the University of Naples Federico II, and a Team Leader with CERN, Geneva, Switzerland. Prof. Arpaia is also the Head of the Interdepartmental Research Centre in Health Management and Innovation in Healthcare of the University of Naples Federico II. His current research interests include augmented reality, brain computer interfaces, cyber-security, digital instrumentation and measurement techniques, evolutionary diagnostics, and distributed measurement systems.\nEGIDIO DE BENEDETTO (M\u201914, SM\u201916) received the M.S. degree in materials engineering and the Ph.D. degree in information engineering from the University of Salento, Lecce, Italy, in 2006 and 2010, respectively. He was with the Institute of Microelectronics and Microsystems, National Research Council, Lecce, Italy, from 2010 to 2012. From 2012 through 2019, he was a Research Fellow with the University of Salento (Lecce, Italy). Since 2019, Egidio De Benedetto is an Associate Professor with the Department of Electrical Engineering and Information Technology of the University of Naples Federico II (Italy).\nNICOLA DONATO (SM) received the M.S. degree in electronic engineering from the University of Messina, Messina, Italy, and the Ph.D. degree from the University of Palermo, Palermo, Italy. He is currently an Associate Professor of Electrical and Electronic Measurements and the Head of the Laboratories of \u201cElectronics for Sensors and for Systems of Transduction\u201d and \u201cElectrical and Electronic Measurements\u201d with the University of Messina. His current research interests include sensor characterization and modeling, development of measurement systems for sensors, and characterization of electronic devices up to microwave range and down to cryogenic temperatures.\nLUIGI DURACCIO received the M.S. degree (cum laude) in electronic engineering from the University of Naples Federico II in 2018. He developed his master thesis at CERN, Geneva, Switzerland, in the field of radiation measurement for electronics. His current research interests include biomedical instrumentation and measurement, electroencephalographic data acquisition and processing, augmented reality, and brain\u2013computer interfaces.\nVOLUME 10, 2022 11\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nSALVATORE GIUGLIANO received the M.S. degree (cum laude) in computer science in 2019. He developed his master thesis in neural networks. His current research interests include analysis and interpretation of EEG signals with machine learning techniques, transfer learning on EEG data and eXplainable Artificial Intelligence. He currently collaborates as a consultant and researcher at the Villa delle Ginestre clinic in Volla, Italy.\nROBERTO PREVETE received the M.Sc. degree in physics and the Ph.D. degree in mathematics and computer science from the Department of Electrical Engineering and Information Technologies (DIETI), University of Naples Federico II, Naples, Italy. He is currently an Assistant Professor of computer science with the DIETI, University of Naples Federico II. His current research interests include computational models of brain mechanisms, machine learning, and artificial neural networks and their applications. His research has been published in international journals, such as Biological Cybernetics, Experimental Brain Research, Neurocomputing, Neural Networks, and Behavioral and Brain Sciences."
        },
        {
            "heading": "12 VOLUME 10, 2022",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/"
        }
    ],
    "title": "Employment of Domain Adaptation techniques in SSVEP-based Brain-Computer Interfaces",
    "year": 2023
}