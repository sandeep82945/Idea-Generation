{
    "abstractText": "In the application recommendation field, collaborative filtering (CF) method is often considered to be one of the most effective methods. As the basis of CF-based recommendation methods, representation learning needs to learn two types of factors: attribute factors revealed by independent individuals (e.g., user attributes, application types) and interaction factors contained in collaborative signals (e.g., interactions influenced by others). However, existing CF-based methods fail to learn these two factors separately; therefore, it is difficult to understand the deeper motivation behind user behaviors, resulting in suboptimal performance. From this point of view, we propose a multi-granularity coupled graph neural network recommendation method based on implicit relationships (IMGC-GNN). Specifically, we introduce contextual information (time and space) into userapplication interactions and construct a three-layer coupled graph. Then, the graph neural network approach is used to learn the attribute and interaction factors separately. For attribute representation learning, we decompose the coupled graph into three homogeneous graphs with users, applications, and contexts as nodes. Next, we use multilayer aggregation operations to learn features between users, between contexts, and between applications. For interaction representation learning, we construct a homogeneous graph with user-context-application interactions as nodes. Next, we use node similarity and structural similarity to learn the deep interaction features. Finally, according to the learned representations, IMGC-GNN makes accurate application recommendations to users in different contexts. To verify the validity of the proposed method, we conduct experiments on real-world interaction data from three cities and compare our model with seven baseline methods. The experimental results show that our method has the best performance in the top-k recommendation.",
    "authors": [
        {
            "affiliations": [],
            "name": "Qingbo Hao"
        },
        {
            "affiliations": [],
            "name": "Yingyuan Xiao"
        },
        {
            "affiliations": [],
            "name": "\u00b7Hao Lin"
        },
        {
            "affiliations": [],
            "name": "Chundong Wang"
        }
    ],
    "id": "SP:c8b8dde17b4339d7b85adf410c6bbd7988d397a6",
    "references": [
        {
            "authors": [
                "T Liang",
                "L Zheng",
                "L Chen"
            ],
            "title": "Multi-view factorization machines for mobile app recommendation based on hierarchical attention",
            "venue": "Knowl Based Syst",
            "year": 2020
        },
        {
            "authors": [
                "C Lei",
                "H Dai",
                "Z Yu"
            ],
            "title": "A service recommendation algorithm with the transfer learning based matrix factorization to improve cloud security",
            "year": 2020
        },
        {
            "authors": [
                "F Xue",
                "X He",
                "X Wang"
            ],
            "title": "Deep item-based collaborative filtering for top-n recommendation",
            "venue": "ACM Trans Inf Syst (TOIS)",
            "year": 2019
        },
        {
            "authors": [
                "Y Liu",
                "S Yang",
                "Y Xu"
            ],
            "title": "Contextualized graph attention network for recommendation with item knowledge graph. IEEE Transactions on knowledge and data engineering",
            "year": 2021
        },
        {
            "authors": [
                "W Fan",
                "Y Ma",
                "Q Li"
            ],
            "title": "Graph neural networks for social recommendation",
            "venue": "The world wide web conference,",
            "year": 2019
        },
        {
            "authors": [
                "S Harada",
                "K Taniguchi",
                "M Yamada"
            ],
            "title": "Contextregularized neural collaborative filtering for game app recommendation",
            "venue": "RecSys (late-breaking results),",
            "year": 2019
        },
        {
            "authors": [
                "Q Hao",
                "K Zhu",
                "C Wang"
            ],
            "title": "Cfdil: a context-aware feature deep interaction learning for app recommendation",
            "year": 2022
        },
        {
            "authors": [
                "T Ebesu",
                "B Shen",
                "Y Fang"
            ],
            "title": "Collaborative memory network for recommendation systems",
            "venue": "The 41st international ACM SIGIR conference on research & development in informationretrieval,",
            "year": 2018
        },
        {
            "authors": [
                "AK Yengikand",
                "M Meghdadi",
                "S Ahmadian"
            ],
            "title": "Deep representation learning using multilayer perceptron and stacked autoencoder for recommendation systems",
            "venue": "IEEE International Conference on Systems, Man, and Cybernetics (SMC),",
            "year": 2021
        },
        {
            "authors": [
                "M Ahmadian",
                "M Ahmadi",
                "S Ahmadian"
            ],
            "title": "Integration of deep sparse autoencoder and particle swarm optimization to develop a recommender system",
            "venue": "IEEE International conference on systems, man, and cybernetics (SMC),",
            "year": 2021
        },
        {
            "authors": [
                "KP Lin",
                "YW Chang",
                "CY Shen"
            ],
            "title": "Leveraging online word of mouth for personalized app recommendation",
            "venue": "IEEE Trans Comput Soc Syst",
            "year": 2018
        },
        {
            "authors": [
                "Z Liu",
                "X Xia",
                "D Lo"
            ],
            "title": "Automatic, highly accurate app permission recommendation",
            "venue": "Autom Softw Eng",
            "year": 2019
        },
        {
            "authors": [
                "X Xu",
                "K Dutta",
                "A Datta"
            ],
            "title": "Identifying functional aspects from user reviews for functionality-based mobile app recommendation",
            "venue": "J Assoc Inf Sci Technol",
            "year": 2018
        },
        {
            "authors": [
                "J Sun",
                "Y Zhang",
                "W Guo"
            ],
            "title": "Neighbor interaction aware graph convolution networks for recommendation",
            "venue": "Proceedings of the 43rd International ACM SIGIR conference on research and development in information retrieval,",
            "year": 2020
        },
        {
            "authors": [
                "L Huang",
                "ZL Zhao",
                "CD Wang"
            ],
            "title": "Lscd: Low-rank and sparse cross-domain recommendation",
            "venue": "Neurocomputing 366:86\u2013",
            "year": 2019
        },
        {
            "authors": [
                "J Sun",
                "Y Zhang",
                "C Ma"
            ],
            "title": "Multi-graph convolution collaborative filtering",
            "venue": "IEEE International conference on data mining (ICDM),",
            "year": 2019
        },
        {
            "authors": [
                "I Kumar",
                "Y Hu",
                "Y Zhang"
            ],
            "title": "Eflec: Efficient feature-leakage correction in gnn based recommendation systems",
            "venue": "Proceedings of the 45th International ACM SIGIR conference on research and development in information retrieval,",
            "year": 2022
        },
        {
            "authors": [
                "Z Duan",
                "Y Wang",
                "W Ye"
            ],
            "title": "Connecting latent relationships over heterogeneous attributed network for recommendation",
            "venue": "Applied Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "M Ahmadian",
                "M Ahmadi",
                "S Ahmadian"
            ],
            "title": "A reliable deep representation learning to improve trust-aware recommendation systems",
            "venue": "Expert Syst Appl",
            "year": 2022
        },
        {
            "authors": [
                "C Wei",
                "B Bai",
                "K Bai"
            ],
            "title": "Gsl4rec: Session-based recommendations with collective graph structure learning and next interaction prediction",
            "venue": "Proceedings of the ACM web conference,",
            "year": 2022
        },
        {
            "authors": [
                "R Ying",
                "R He",
                "K Chen"
            ],
            "title": "Graph convolutional neural networks for web-scale recommender systems",
            "venue": "Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining,",
            "year": 2018
        },
        {
            "authors": [
                "X Wang",
                "X He",
                "M Wang"
            ],
            "title": "Neural graph collaborative filtering",
            "venue": "Proceedings of the 42nd international ACM SIGIR conference on research and development in information retrieval,",
            "year": 2019
        },
        {
            "authors": [
                "A Li",
                "B Yang",
                "H Huo"
            ],
            "title": "Leveraging implicit relations for recommender systems",
            "venue": "Inf Sci",
            "year": 2021
        },
        {
            "authors": [
                "H Gao",
                "J Xiao",
                "Y Yin"
            ],
            "title": "A mutually supervised graph attention network for few-shot segmentation: The perspective of fully utilizing limited samples. IEEE Transactions on neural networks and learning systems",
            "year": 2022
        },
        {
            "authors": [
                "H Gao",
                "B Qiu",
                "RJD Barroso"
            ],
            "title": "Tsmae: a novel anomaly detection approach for internet of things time series data using memory-augmented autoencoder",
            "venue": "IEEE Transactions on network science and engineering",
            "year": 2022
        },
        {
            "authors": [
                "J Guo",
                "Y Zhou",
                "P Zhang"
            ],
            "title": "Trust-aware recommendation based on heterogeneous multi-relational graphs fusion",
            "venue": "Inf Fusion",
            "year": 2021
        },
        {
            "authors": [
                "S Ahmadian",
                "M Ahmadian",
                "M Jalili"
            ],
            "title": "A deep learning based trust-and tag-aware recommender system",
            "year": 2022
        },
        {
            "authors": [
                "L Xia",
                "Y Xu",
                "C Huang"
            ],
            "title": "Graph meta network for multi-behavior recommendation",
            "venue": "Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval,",
            "year": 2021
        },
        {
            "authors": [
                "BJ Fogg"
            ],
            "title": "Tiny habits: The small changes that change everything",
            "venue": "Eamon Dolan Books",
            "year": 2019
        },
        {
            "authors": [
                "R Huskey",
                "S Wilcox",
                "R Weber"
            ],
            "title": "Network neuroscience reveals distinct neuromarkers of flow during media use",
            "venue": "J Commun",
            "year": 2018
        },
        {
            "authors": [
                "R Derfler-Rozin",
                "M Pitesa"
            ],
            "title": "Motivation purity bias: Expression of extrinsic motivation undermines perceived intrinsic motivation and engenders bias in selection decisions",
            "venue": "Acad Manag J",
            "year": 2020
        },
        {
            "authors": [
                "BK Iwana",
                "V Frinken",
                "S Uchida"
            ],
            "title": "Dtw-nn: a novel neural network for time series recognition using dynamic alignment between inputs and weights",
            "venue": "Knowl Based Syst",
            "year": 2020
        },
        {
            "authors": [
                "S Zhang",
                "L Yao",
                "A Sun"
            ],
            "title": "Deep learning based recommender system: a survey and new perspectives",
            "venue": "ACM Computing Surveys",
            "year": 2019
        },
        {
            "authors": [
                "X Jiang",
                "B Hu",
                "Y Fang"
            ],
            "title": "Multiplex memory network for collaborative filtering",
            "venue": "Proceedings of the 2020 SIAM international conference on data mining,",
            "year": 2020
        },
        {
            "authors": [
                "Z Tian",
                "Y Liu",
                "J Sun"
            ],
            "title": "Exploiting group information for personalized recommendation with graph neural networks",
            "venue": "ACM Trans Inf Syst (TOIS)",
            "year": 2021
        },
        {
            "authors": [
                "Z Guo",
                "K Yu",
                "Y Li"
            ],
            "title": "Deep learning-embedded social internet of things for ambiguity-aware social recommendations",
            "venue": "IEEE Transactions on network science and engineering",
            "year": 2021
        },
        {
            "authors": [
                "J Yu",
                "H Yin",
                "J Li"
            ],
            "title": "Enhance social recommendation with adversarial graph convolutional networks. IEEE Transactions on knowledge and data engineering",
            "year": 2020
        },
        {
            "authors": [
                "Y Ma",
                "B Narayanaswamy",
                "H Lin"
            ],
            "title": "Temporal-contextual recommendation in real-time",
            "venue": "Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining,",
            "year": 2020
        },
        {
            "authors": [
                "J Herce-Zelaya",
                "C Porcel",
                "J Bernab\u00e9-Moreno"
            ],
            "title": "New technique to alleviate the cold start problem in recommender systems using information from social media and random decision forests",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Keywords Application recommendation \u00b7 Graph neural network \u00b7 Context information \u00b7 Attribute representation \u00b7 Interaction representation\nChundong Wang michael3769@163.com\nQingbo Hao haoqingbo4546@163.com\n1 School of Computer Science and Engineering, Tianjin University of Technology, Binshui West Road, Tianjin, 300191, Tianjin, China\n2 Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Ministry of Education, Binshui West Road, Tianjin, 300191, Tianjin, China\n3 Engineering Research Center of Learning-Based Intelligent System, Ministry of Education, Binshui West Road, Tianjin, 300191, Tianjin, China"
        },
        {
            "heading": "1 Introduction",
            "text": "People\u2019s reliance on the mobile internet has promoted the rapid development of applications (apps). According to statistics1, as of 2021, the number of apps on Google Play and App Store had reached over 3.3 million and 2.1 million, respectively. In addition, a large number of lightweight applications, such as WeChat mini-programs, are active on the mobile internet. However, the massive number of mobile apps has caused the problem of information overload while satisfying the needs of human production\n1https://www.statista.com/statistics/276623/ number-of-apps-available-in-leading-app-stores/\nIMGC-GNN: A multi-granularity coupled graph neural network recommendation method based on implicit...\nand life [1\u20133]. Therefore, it is meaningful to make accurate recommendations for users.\nAs the most effective recommendation method, collaborative filtering (CF) based method first constructs user and item representations. Then, it predicts user preferences by using historical interaction information (e.g., interaction frequency, ratings), and gives the recommendation results. Therefore, representation learning is the basis of CF-based recommendation methods.\nHowever, the motivation for user-app interaction is usually obscure and complex in the real world. The motivation may come from user or app attribute factors (e.g., app type, user\u2019s gender or age). For example, young people like to play shooting games. The user\u2019s age and the category of the app are the motivations for this interaction. In addition, motivation may also arise from interaction factors in collaboration. For example, authors often check their email, which is driven by the fact that editors use email to communicate with other authors. To better capture user preferences (interaction motivation), the learned representations should reflect both attribute and interaction factors.\nIn recommender systems, most of the information inherently has graph structures, and graph neural network (GNN) has excellent performance on graph-structured data. Therefore, GNN has received considerable attention in recommendation field in recent years [4]. According to the kinds of relationships used in the recommendation models, GNN-based recommendation models can be divided into single-relationship and multi-relationship recommendation models. For single-relationship recommendation models, the mainstream approach is to embed the user or app attributes into the corresponding nodes. Then, the model aggregates the information according to the edges (interactions) in the graph. This modeling, which draws directly on historical interaction data, is coarse-grained. For multirelationship recommendation methods, the mainstream idea is to add additional information by introducing other relationships. For example, Fan et al. [5] fused user-app interaction graph with social relationships, and the additional information contained in social relationships is used to improve the recommendation performance. However, both approaches neglect to perform representation learning in terms of both user/item attribute factors and interaction factors, respectively. Henceforth, it is difficult to determine whether the motivation comes from attribute factors or interaction factors, resulting in a suboptimal solution for the recommendation.\nConsidering the limitations of existing methods, we propose a multi-granularity coupled graph neural network\nrecommendation method, IMGC-GNN. IMGC-GNN introduces contextual information into user-app interactions to construct a three-layer heterogeneous graph. Then, IMGCGNN uses a two-tower network structure to perform representation learning from the perspective of attribute and interaction factors. Specifically, (1) for attribute representation learning, IMGC-GNN constructs homogeneous graphs with users, contexts or apps as nodes by iteratively computating implicit relationships. Then, the model uses aggregation operations to learn representations between users, between contexts or between apps. (2) For interaction representation learning, IMGC-GNN constructs interaction graphs with user-context-app interactions as nodes using node similarity. Then, the model uses multi-layer aggregation to mine interaction representations. (3) Finally, according to the learned representations of attributes and interaction, IMGC-GNN makes preference predictions for users in different contexts and then completes app recommendations. In summary, the main contributions of this paper are as follows.\n1. IMGC-GNN constructs a three-layer heterogeneous graph (user-context-app) using historical interaction information. The introduction of contextual information adds a learning dimension to user-app interactions and provides a strong support for exploring user preferences in different contexts. 2. In attribute representation learning, IMGC-GNN constructs three homogeneous graphs, including a user graph, a context graph and an app graph, with the help of implicit relationships. By defining the iterative calculation of implicit relationships, our model not only effectively filters negative effects between nodes, but alleviates data sparsity and cold start problems. 3. In interaction representation learning, IMGC-GNN constructs an interaction graph taking user-contextapp interactions as nodes. By combining interaction similarity and structural similarity, our model can learn deep-level interaction features. 4. We apply IMGC-GNN to real-world datasets of three cities and conduct a series of experiments. The results show that our method outperforms other methods.\nThe remainder of this paper is structured as follows. We provide a brief overview of the related work in Section 2. In Section 3, we describe the motivation. Section 4 shows the framework of the proposed method and then presents our model in detail. Section 5 demonstrates the experimental results, and finally, the conclusions and future work are presented in Section 6.\n14669\nQ. Hao et al."
        },
        {
            "heading": "2 Related work",
            "text": ""
        },
        {
            "heading": "2.1 CF-based app recommendationmethods",
            "text": "App recommendation is an important branch of the recommendation field, and the most commonly used method is collaborative filtering [6, 7]. Since CF-based methods are classical similarity-oriented recommendation methods, the accuracy of similarity calculation is the key to its performance. CF-based methods can be divided into two categories: nearest neighbor-based collaborative filtering and model-based collaborative filtering [8].\nNearest neighbor-based collaborative filtering uses the historical interaction information of neighbors to make recommendations [9, 10]. Therefore, the neighbors of users/items determine the recommendation performance. And the representation learning of user/item will directly affect the discovery of optimal neighbors [8]. Lin et al. [11] calculated the similarity between apps using their description text. Then, they proposed a recommendation method based on app similarities. This method taked into account both the topic distributions of the apps and user preferences, and then generated recommendation lists for target users. Similar to Lin et al. [11], Liu et al. [12] proposed a PERREC model by applying app text descriptions to permission recommendations. This model uses text mining and data fusion methods to recommend appropriate permissions for users based on the relevant description of the app. From the perspective of app function, Xu et al. [13] utilized users\u2019 functional requirements to calculate the user similarity and then completed accurate recommendations.\nUnlike the nearest neighbor-based recommendation approaches, model-based collaborative filtering maps userapp interactions into vector spaces. User-app interactions are modeled as inner products of potential vectors. It is worth noting that the interaction data are extremely sparse, which is not conducive to recommendations. To solve this problem, some scholars used the similarities between different users/items to complement the sparse data. For example, Sun et al. [14] proposed the neighbor interaction aware graph convolution networks (NIA-GCN) by explicitly modeling the relationships between neighbors to complement the sparse data. Huang et al. [15] proposed a new algorithm called low-rank sparse cross-domain (LSCD) by dividing features into domain features and shared features. Then, LSCD used the shared features across domains to supplement sparse data. Sun et al. [16] defined the neighbors of users and apps using collaborative relationships and supplemented the sparse interaction data with neighbors.\nIt is not difficult to find that the above two methods require the use of similarities between apps, users\nor interactions to achieve accurate recommendations. The effectiveness of representation learning will directly affect the similarity calculation. Therefore, accurate and effective representation learning is beneficial to improve the recommendation performance. Recently, utilizing graph neural network methods in recommender systems has become a hot research topic because of its effective mining of interaction data (graph-structured data)."
        },
        {
            "heading": "2.2 Graph representation-based app recommendationmethods",
            "text": "With the great achievements in graph neural networks (GNN) [17, 18], recent works have attempted to apply GNN in recommender systems to learn user and item representations. Based on the types of relationships involved in recommendations, graph representation-based recommendations can be divided into single-relationship recommendations and multi-relationship recommendations.\nAs a basic recommendation model, single-relationship recommendation mainly uses user-app interactions for collaborative filtering. And the method performs user/app representation learning with the help of embedding or deep learning [19]. Wei et al. [20] treated the recommendation problem as a link prediction task for a graph and proposed a recommendation framework (GSL4Rec) that integrates user-item interactions. Ying et al. [21] proposed an embedding model based on random walk and graph convolutional network. This model shows excellent performance in largescale network recommendation. Similar to GSL4Rec [20], Wang et al. [22] used graph neural methods for recommendations in user-item bipartite graphs and proposed the NGCF recommendation method. Li et al. [23] used graph data to explore implicit relationships and made accurate recommendations. The common point of the above methods is that they only use one relationship for recommendation.\nHowever, mining users\u2019 preferences based on a single relationship is crude. Moreover, it often leads to poor performance due to the sparsity of interaction data. Therefore, many scholars have introduced multiple relationships into recommendation models. The multi-relationship recommendation model not only effectively alleviates the data sparsity problem, but also increases the dimensionality of interaction learning. Furthermore, the introduction of the attention mechanism [24, 25] can further improve the performance of multirelationship recommendations. Guo et al. [26] proposed a trust-based recommendation system (T-MRGF). This model learn feature vectors using user-item interaction graphs and user-user trust relationship graphs. Then, the learned feature vectors are fused to make recommendations. Ahmadian et al. [27] introduced trust relationships and label information to recommenders and proposed a deep learningbased recommendation method. Fan et al. [5] proposed a\n14670\nIMGC-GNN: A multi-granularity coupled graph neural network recommendation method based on implicit...\ngraphical neural network recommendation framework (GraphRec) that incorporates social graphs and interaction graphs. In contrast to Fan et al. [5], Xia et al. [28] defined interaction relationships in different forms (browsing, purchasing, etc.) and use graph neural networks to explore complex multi-behavior patterns of users. However, the essence of the method is still to introduce multiple interaction relationships for improving recommendation performance.\nIn summary, introducing multiple relationships (additional information) can effectively improve recommendation performance. However, most approaches focus on joint learning of multiple relationships, while neglecting to explore user interaction motivation from attribute and interaction perspectives. Therefore, this paper performs representation learning in terms of attribute and interaction factors to explore user interaction motivation.\n3Motivation\nIn this section, we describe the motivation of the proposed method in detail."
        },
        {
            "heading": "3.1 Interactionmotivation",
            "text": "Motivation is people\u2019s desire to accomplish a particular behavior (e.g., play a mobile game for 30 min tonight) or a certain type of behavior (e.g., play a mobile game for 30 min every night). This desire drives people toward their expected goal. Professor Fogg, the founder of behavioral design, divided the sources of motivation into 3 types: person (P), action (A), and behavior circumstance (C), called the PAC model [29]. Specifically, (1) motivation may stem from the person themselves, which means that people do what they want to do in their hearts. (2) Motivation may arise from action, which refers to the user\u2019s desire to act in order to gain a benefit or avoid a penalty. (3) Motivation may also originate from the circumstance. This refers to the behaviors of users influenced by the environment they are in. Fogg believes that PCA model is the basis for understanding all human behaviors. Based on the above theories and combined with our understanding of users\u2019 motivation for using apps, we consider that the motivation of users using apps can be divided into two categories: attribute factors and interaction factors.\nAttribute factors are motivations that derive from the users themselves (P in the PAC model), namely, the motivation of the user\u2019s behavior is influenced by certain attributes of the user/app. This motivation reflects the user\u2019s preferences (i.e., matches the user\u2019s interests), which is in line with the user\u2019s nature. For example, female users prefer to shop at Vipshop. Attribute factor-driven behaviors that can bring pleasure and fulfillment to users will more easily\nlead to a flow state [30]. This is consistent with intrinsic motivation in psychology [31].\nInteraction factors are influenced by external stimuli and consist of two main parts: the reward or punishment incentives (A in the PAC model) and the user\u2019s circumstance (C in the PAC model). (1) Reward or punishment incentives: users want to be rewarded or avoid penalties for taking action, but do not necessarily enjoy the action, such as exercising to lose weight. Rewards can be tangible (money, prizes, certificates, etc.) or intangible (praise, support, recognition, etc.). (2) User\u2019s circumstance: users originally have no or weak motivation but are stimulated by the surrounding environment, thus triggering the obediencefollowing effect, such as brushing hot spots and chasing hot dramas. It is worth mentioning that these behaviors are driven and pulled by the user\u2019s need for social respect, which is consistent with extrinsic motivation in psychology [31].\nTherefore, we hope to perform representation learning from both attribute and interaction perspectives to better explore the motivation of user behavior and improve recommendation accuracy. Based on this motivation, we design IMGC-GNN."
        },
        {
            "heading": "3.2 Context information",
            "text": "Our model introduces context information (time, space/location) into user-app interactions. This is because most of the existing app recommendation methods often use the user and app attributes or the interactions between them for modeling to explore user preferences. However, by combing real-world datasets, we observe that user-app interactions show highly aggregated characteristics in spatiotemporal dimensions. In other words, the interaction preferences between users and apps are not constant but are influenced by context information. Therefore, we integrate context information into IMGC-GNN to accurately mine user preferences and thus improve the performance of recommendations. In our study, time and location (longitude and latitude) are referred to as context information.\nWe present the temporal and spatial aggregation of userapp interaction data in the real world, as shown in Figs. 1 and 2. Figure 1 illustrates the spatial characteristics of userapp interactions by a heatmap. To be specific, Fig. 1(a) shows the spatial characteristics of a user using different apps. For example, a user always uses the Metro app in subway stations and uses the WalMart app at WalMart Stores. Figure 1(b) shows the spatial characteristics of an app being used by different users. For instance, the Metro app is always used by different users in subway stations, and the WalMart app is always used at WalMart Stores. Figure 2 plots the temporal characteristics of user-app interactions by a scatter plot. Specifically, Fig. 2(a) represents the time\n14671\ncharacteristics of a user using different apps. For instance, a user always uses the Outlook app to check email at 9:00 a.m. and uses the Menulog app to order food at 12:00 p.m. Figure 2(b) shows the time characteristics of an app being used by different users. For example, the Outlook app is always used by users at 9:00 a.m., and the Menulog app is always used at 12:00 p.m.\nIn summary, for users, their daily lives always have a certain regularity. Thus, user-app interactions often overlap with the time and location of their activities, showing regularity. For apps, they are always used in contexts appropriate to their functions, which also shows regularity. Therefore,\nintroducing context information to app recommendation modeling will help to accurately mine user preferences and improve recommendation performance."
        },
        {
            "heading": "3.3 Iterative implicit relationships",
            "text": "When performing attribute representation learning, IMGCGNN defines a new iterative method of computing implicit relationships to precisely mine the neighbors of users, contexts, and apps. We hope that the introduction of implicit relationships can complement sparse explicit relationships and filter the noise from explicit relationships. In our\nIMGC-GNN: A multi-granularity coupled graph neural network recommendation method based on implicit...\nstudy, relationships with direct connections are defined as explicit relationships, otherwise, they are defined as implicit relationships. To better describe these two relationships, we take Fig. 3 as an example. In this figure, u2 and u3 use a3; u3, u4 and u5 use a4. Therefore, the explicit users of u3 are u2, u4 and u5, that is, u3 is explicitly related to u2, u4, and u5. Obviously, the explicit relationship is shallow, as it ignores the frequency of user-app interactions and the deeper level of excavation. Furthermore, u3 uses a4 more frequently than u4, so using u4 to predict the preference of u3 is inaccurate. However, the usage frequency of u2 and u3 on a3 is the same, that is, u2 and u3 have similar preferences. u2 uses a1 and a2 more frequently, which is the same as u1. Although there is no direct connection between u1 and u3, through u2 we can infer that u1 has a high similarity with u3. Relationships without direct connections are called implicit relationships, i.e., there is an implicit relationship between u1 and u3.\nBased on the above analyses, we draw the following conclusions. (1) Explicit relationships are not all positive, such as u3 and u4. (2) Using all explicit relationships directly will lead to noise, which is extremely unfavorable to recommendations. (3) Implicit relationships can be used as a complement to explicit relationships, such as u3 and u1. The correct introduction of implicit relationships will help to improve recommendation accuracy. Therefore, we define a newly iterative way of calculating implicit relationships. In this way, the proposed model can complement sparse interaction data and avoid the noise from explicit relationships.\n4Methodology\nIn this section, we first give the general definition and notation description of our study, and then describe the IMGC-GNN model in detail."
        },
        {
            "heading": "4.1 Problem definition and notations",
            "text": ""
        },
        {
            "heading": "4.1.1 Problem definition",
            "text": "The goal of our study is to recommend apps for a target user who is in a specific context to meet his or her needs. We give its mathematical description. For a given user set U , an app set A and a context set C, our task is to make an app recommendation list Ru for user u in context c, where Ru = {a1, a2 \u00b7 \u00b7 \u00b7 an|uc, ai A, c C, u U}, n is the length of recommendation list, and |uc indicates that user u is in context c.\nTo achieve the above goal, IMGC-GNN constructs a user-context-app graph by introducing context information. Then, IMGC-GNN learns from attribute and interaction perspectives to mine the needs and preferences of users in different contexts. Finally, IMGC-GNN recommends top-k apps to the target user according to the current context. The recommendation is based on the probability that the target user u prefers an app a in a specific context c and it is a regression problem. Thus, it is crucial to accurately predict a user\u2019s preference in a certain context, which directly determines app recommendation performance.\n14673\nQ. Hao et al."
        },
        {
            "heading": "4.1.2 Notations",
            "text": "To clearly represent our model, we give the descriptions of notations used in IMGC-GNN, as shown in Table 1."
        },
        {
            "heading": "4.2 Model",
            "text": "In this subsection, we describe the IMGC-GNN framework, as shown in Fig. 4. Our model contains four parts: context-based coupled graph construction, attribute representation learning, interaction representation learning, and a prediction layer.\n(1) Context-based coupled graph construction. User-app interaction data in specific contexts are modeled as a three-layer heterogeneous graph Guca . The nodes in three layers of this graph are users, contexts, and apps. (2) Attribute representation learning. IMGC-GNN converts the coupled graph Guca into three homogeneous graphs (user graph, context graph and app graph) by iteratively computing implicit relationships. Then, IMGC-GNN performs representation learning for the nodes in these three homogeneous graphs. (3) Interaction representation learning. IMGC-GNN constructs an interaction graph Ginte with user-contextapp interactions as nodes. Then, it uses graph neural network to mine interaction representations. (4) Prediction layer. IMGC-GNN uses features obtained from attribute and interaction representation learning to complete recommendations.\nNext, we will introduce each of the above four parts."
        },
        {
            "heading": "4.3 Context-based heterogeneous graph construction",
            "text": "IMGC-GNN introduces context information into userapp interactions and constructs the coupled graph Guca=\u3008Vuca, Euca\u3009, as shown in Fig. 5. Vuca denotes the set of vertices, and Euca represents the set of edges.\n(1) The set of vertices Vuca . Vuca contains three types of nodes: user u, context c and app a, Vuca = {U \u222a C \u222a A}. We splice the embedding of the onehot code of the user\u2019s gender, age and the device. Then, we use the result as the user\u2019s code. For the app node, we select its relevant information, such as attributes and developers, and perform the same operations to generate the code of app. In our model, context information refers to the location (latitude and longitude) and time when a user u interacts with an app a. Thus, context nodes contain location and temporal information of the interaction. We first use a grid to divide the latitude and longitude of the city. The division interval of latitude and longitude is 0.005 degrees, that is, the true distance corresponding to the latitude and longitude of each interval is approximately 0.555 km and 0.427 km, respectively. Then, we divide each day into 8 time periods, T = {1:00-5:00, 5:00- 9:00, 9:00-11:00, 11:00-14:00, 14:00-17:00, 17:00- 19:00, 19:00-22:00, 22:00-1:00}. A context consists of a location grid and a time period. We splice the embedding of the one-hot code of the grid location and the time period. Then, we use the result as the context code. The length of the node code for users, contexts and apps is 64 bits. (2) The set of edgesEuca . If user ui uses app am in context cj , the edge weight between ui , cj and am is added to 1. The edge weight is 0 indicates that there is no edge."
        },
        {
            "heading": "4.4 Attribute representation learning",
            "text": ""
        },
        {
            "heading": "4.4.1 Homogeneous graph construction",
            "text": "To better explore the attribute factors (intrinsic motivation) of graph Guca , we decompose the coupled graph into three homogeneous graphs using implicit relationships: user graph G\u2217u, context graph G\u2217c , and app graph G\u2217a . The decomposition ofGuca consists of four main steps, as shown in Fig. 6.\nStep 1: We decompose the three-layer coupled graph Guca into three two-layer heterogeneous graphs Guc, Gca , and Gua . As an example, Guc is generated by removing the nodes of one layer (app) in Guca while keeping the nodes\n14674\nand edges of the other two layers (user and context). Gca and Gua are generated in the same way.\nSpecifically, (1) Guc is a graph with users and contexts as nodes. Users\u2019 life activities are regular, i.e., users will\nalways be in a fixed place at a fixed time. Similarly, a context always appears regularly in the daily life of a user. Therefore, we use Guc to explore the regularity between users and contexts. (2)Gca is a graph with contexts and apps as nodes. The functions provided by an app need to meet the requirements of the context, and a particular context requires the support of a certain type of app. Henceforth, we use Gca to mine the adaptive relationships between contexts and apps. (3) Gua is a graph with users and apps as nodes. Users choose apps that match their preferences, and each app has its potential users. Thus, we use Gua to learn the selective preferences between users and apps.\nStep 2: We decompose Guc, Gca and Gua into six homogeneous weighted graphs to explore the node relationships. Taking Guc as an example, we disassemble it into two graphs, Gu and Gc. Gu is a graph with users as nodes. If ui and uj appear in the same context, then there is an edge eij \u2208 Eu with a weight wij > 0. wij indicates the relationship strength between ui and uj . Similarly, Gc is a graph with contexts as nodes, and the edge weight denotes the relationship strength between two contexts.\nHow to define the edge weights in the six homogeneous graphs directly determines the mining of node relationships,\nwhich is crucial. Taking Gu as an example, the edge weight wij is calculated as follows.\nwij = Ymax \u2212 1|Dij | \u2211 cb\u2208Dij \u2223 \u2223yib \u2212 yjb \u2223 \u2223\nYmax (1)\nwhere Ymax is the maximum value of the edge weights in Guc (e.g., Ymax=9 in Fig. 3). Dij is the set of nodes that are connected with both ui and uj . |Dij | is the number of nodes in Dij . yib is the number of times that ui appears in cb. wij is the value of the explicit relationship between ui and uj .\nStep 3: Iterative calculation of implicit relationships. We iteratively compute the edge weights in each graph to explore the implicit relationships between nodes, as shown in (2)\u2013(4). wlij = (1 \u2212 \u03b8) wl\u22121ij (2)\n\u03b8 = sigmoid (\nl \u2223 \u2223Dij \u2223 \u2223 \u03be\n)\n(3)\nw0ij = wij (4)\nwhere l is the number of iterations, \u03b8 is the loss factor, and \u03be is the penalty factor. \u03b8 and \u03be are hyperparameters in our model.\nrlij denotes the final implicit relationship between ui and uj , and it is calculated as (5).\nrlij = \u03b40wlij + \u03b41 ui\n\u2299 uj\n\u2211 ux\u2208Ni ( ui \u2299 ux ) (5)\nwhere \u2299\ndenotes the elementwise product between two vectors, and ui \u2299 uj is used to measure the feature similarity between ui and uj . Ni denotes the set of ui\u2019s neighbors. \u03b40 and \u03b41 are hyperparameters, and \u03b40 + \u03b41 = 1. Obviously, rlij consists of two parts: w l ij is used to describe the differences in dependencies between ui and uj ; (ui \u2299 uj )/ \u2211 ux\u2208Ni (ui \u2299 ux) describes the normalized similarity between ui and uj . It is worth mentioning that the addition of the latter term makes the calculation of rlij not entirely dependent on the intermediate node, which is useful for solving the cold start problem.\nIMGC-GNN: A multi-granularity coupled graph neural network recommendation method based on implicit...\nStep 4: We merge the six graphs into three homogeneous graphs (G\u2217u, G\u2217c and G\u2217a) according to the node type."
        },
        {
            "heading": "4.4.2 Node aggregation",
            "text": "In this subsection, we aggregate G\u2217u, G\u2217c and G\u2217a , respectively, to obtain the node representations. Taking G\u2217u as an example, the aggregation formula used in our model is shown in (6).\nui = f hiagg(ui, f loagg(N ni )) (6)\nwhere ui is the target node and N ni is the top-n neighbors of ui calculated according to rlij . f hi agg and f lo agg are globally shared aggregation functions. f loagg is used to aggregate the neighbors of ui , and f hiagg is the last aggregation between ui and f loagg(N ni ).\nTo calculate f loagg ( N ni ) , we introduce the attention mechanism to precisely describe the relationship between ui and uj , uj \u2208 N ni , which is shown in (7)\u2013(8).\nf loagg ( N ni ) = \u2211 uj \u2208N ni uj \u00d7 exp\n( Aij )\n\u2211 um\u2208N ni exp (Aim)\n(7)\nAij = ( ui \u2299 uj )T tanh(wlou \u2022 [ ui || uj ] + blou ) (8)\nwhere wlou and b lo u are hyperparameters, and || denotes a concatenation operation between two vectors. tanh is a nonlinear activation function. Aij describes the importance of neighbor uj to the target user ui , as shown in (8). For the high-level aggregation of ui and its neighbors, we use the following formula.\nf hiagg(ui, f lo agg ( N ni ) ) = \u2205(whiu \u2022 [ ui + f loagg ( N ni )]+bhiu ) (9)\nwhere whiu and b hi u are hyperparameters, and \u2205 is the nonlinear activation function. We can aggregate more neighbors by stacking more aggregation layers to obtain a deeper representation. The stacking formula is defined as (10).\nudi = f hiagg(ud\u22121i , (f loagg ( N ni ) )d\u22121) (10)\nFor graphs G\u2217c and G\u2217a , we calculate cdi and adi according to the same steps as above.\nThe major steps of attribute representation learning are shown in Algorithm 1. From the output of Algorithm 1, we can obtain the representation vectors of each user, context, and app.\nAlgorithm 1 Algorithm of the attribute representation learning."
        },
        {
            "heading": "4.5 Interaction representation learning",
            "text": ""
        },
        {
            "heading": "4.5.1 Interaction graph construction",
            "text": "To explore the interaction factors (extrinsic motivation) of graph Guca , we transformed Guca into an interaction graph Ginte= \u3008Vinte, Einte\u3009. 1. The set of nodes Vinte. InGinte, we construct new nodes\naccording to user-context-app interactions. Each node includes information of a user, a context, and an app. The constructed node vxinte is shown in (11).\nvxinte =<Ipqm,vup,vcq,vam,Nup,Ncq ,Nam,Dintx > (11) where Ipqm represents the number of times user up uses app am in context cq . vup, v c q and v a m represent the vectors of up, cq and am, respectively. Nup , N c q and Nam denote the total number of occurrences of up, cq and am, respectively. Dintx is the degree of node v x inte, i.e., the number of first-order neighbors of vxinte, and its initial value is 0. The larger the value of Dintx , the more nodes are similar to node vxinte; vice versa, the less. We update the value of Dintx , after computing the edge set Einte.\n14677\nQ. Hao et al.\n2. The set of edges Einte. We calculate the edge weights for each pair of nodes in Ginte, as shown in (12).\nqxzv = \u2205(Sim(vxinte, vzinte)) (12) where Sim(\u00b7) is the similarity calculation function and \u2205 is the nonlinear activation function. Our model uses Euclidean distance to calculate similarity, and other methods can also be used. To simplify the interaction graph, we remove some edges according to (13). exzv = { 0 , if qxzv \u2264 \u03b7 1 , others (13)\nwhere \u03b7 is the hyperparameter. Edge exzv is removed when exzv = 0; otherwise, it is retained."
        },
        {
            "heading": "4.5.2 Node aggregation",
            "text": "For each node inGinte, we use node similarity and structural similarity to find neighbors, and then perform interaction representation learning [32]. The specific steps are as follows.\nStep 1: If exzv = 1, we compute the similarity of interacting nodes x and z by recursion, as shown in (14) and (15).\nf k(x, z) = f k\u22121(x, z)+g(s(Rk(vxinte),s(Rk(vzinte))) k \u2265 0 and \u2223\u2223Rk ( vxinte )\u2223 \u2223 , \u2223 \u2223Rk ( vzinte )\u2223 \u2223 > 0 (14)\nf \u22121(x, z) = \u2212Sim(vxinte, vzinte) (15) where s ( Rk ( vxinte )) and s ( Rk ( vzinte )) denote the degree sequences of k-order neighbors of vxinte and v z inte, respectively, according to degree size. g(D1, D2) represents the distance between two ordered sequences D1 and D2 and is calculated by the dynamic time warping (DTW) method. f k(x, z) denotes the structural similarity of the k-order neighbors of vxinte and v z inte. f\n\u22121(x, z) represents the similarity between two interaction nodes, as shown in (15). We use kmax to represent the maximum value of k, and kmax is a model hyperparameter. To ensure that vxinte and v z inte have some similarity (i.e., vxinte and v z inte have the same user, context, or app), we only calculate the similarity f k(x, z) between vxinte and v z inte (within 3 hops of v x inte).\nStep 2: We construct a multilayer weighted graph, as shown in Fig. 7. In each layer, the weight \u03c9k(x, z) between nodes is calculated according to (16). It is worth mentioning that the graph at each layer is not a complete graph because there is a distance restriction between vxinte and v z inte, which is different from struc2vec.\n\u03c9k(x, z) = e\u2212f k(x,z), k = 0, 1, ... (16) Nodes in different layers are connected by directed edges. Specifically, for each node vxinte in the kth layer, there are\ndirected edges (xk, xk\u22121) and (xk, xk+1), with weights as shown in (17) and (18), respectively.\n\u03c9(xk, xk+1)= log( k(x) + e), k = 0, 1, ..., k\u22121 (17)\n\u03c9 (xk, xk\u22121) = 1, k = 1, ..., k (18)\nk(x) = \u2211\nvzint\u2208Vint 1(\u03c9k(x, z) > \u03c9\u0304k) (19)\nwhere k(x) is the number of edges pointing to vxinte in the kth layer whose weights are greater than the average weight of that layer.\nStep 3: For each node at the kth layer, we sample its neighbors by random walk. The wandering probability of the same layer is qk (see (20)), and the wandering probability of adjacent layers is pk (see (21)).\nqk(x, z) = e \u2212f k(x,z)\n\u2211 vzint\u2208Vint ,z =x e \u2212f k(x,z) (20)\npk(xk, xk+1) = \u03c9 (xk, xk+1) \u03c9 (xk, xk+1) + \u03c9 (xk, xk\u22121) (21)\nwhere qk(x, z) is the probability that node vxinte at the kth layer walks to node vzinte at the same layer. pk(xk, xk+1) is the probability of sampling at the (k + 1)th layer.\nStep 4: We aggregate the information of the sampled nodes using (22), and put them into the corresponding feature vectors of users, contexts and apps. For each user, we connect all its feature vectors, then use the embedding\n14678\nIMGC-GNN: A multi-granularity coupled graph neural network recommendation method based on implicit...\nmethod to obtain a fixed-length vector. The same method is adopted for each app and context.\nvxinte = vxinte + 1 |N x | \u2211\nz\u2208N x \u03c9k(x, z) \u00b7 vzinte (22)\nwhereN x indicates the neighbor nodes of vzinte. |N x | is the number of nodes in N x .\nAlgorithm 2 shows the main steps of interaction representation learning. Using this algorithm, we can learn the representation vectors of users, contexts and apps from the perspective of interactions.\nAlgorithm 2 Algorithm of interaction representation learning."
        },
        {
            "heading": "4.6 Prediction layer",
            "text": "For each user, app, and context, we first connect its corresponding feature vectors obtained from attribute and interaction representation learning. Then, we use the embedding method to obtain fixed-length vectors, uLi , c L i and aLi . Finally, we use uLi , c L i a L i and function p to make predictions. We implement the prediction function p as\nthe MLP component. The MLP component consists of two hidden layers.\ny\u0302i = p(uLi , cLi , aLi ) (23)"
        },
        {
            "heading": "4.7 Model learning",
            "text": "IMGC-GNN makes recommendations based on the probability that the target user u prefers an app a in a particular context c, which is a regression problem. To better train the model, the objective function was developed, as shown in (24).\nL = 1|O| \u2211\n(a,i)\u2208O (yai \u2212 y\u0302ai)2 + \u03bbI\u2016 I\u20162 (24)\nThe loss function L consists of two parts, 1|O| \u2211\n(a,i)\u2208O (yai \u2212 y\u0302ai)2 is used to measure the loss in recommendations, and \u03bbI\u2016 I\u20162 is the L2 regularization term to control the complexity of the model and to avoid overfitting. O means the recommendation list. |O| denotes the length of O. \u03b8I is the set of parameters in the framework. The IMGC-GNN training process is shown in Algorithm 3.\nAlgorithm 3 Training algorithm of the IMGC-GNN model."
        },
        {
            "heading": "4.8 Complexity analysis",
            "text": "The time complexity of IMGC-GNN mainly consists of two parts: attribute representation learning and interaction representation learning.\n14679\nQ. Hao et al.\n(1) In attribute representation learning, the time complexity mainly arises from the construction of homogeneous graphs and aggregation operations. Taking user as an example, the graph construction requires iteratively computating the distance between a node and its l-order neighbors. Therefore, its time complexity is O(Mu \u00b7 Nuave \u00b7 l \u00b7 h2), where Mu denotes the number of users, Nuave denotes the average number of explicit neighbors of users, l indicates the order of the implicit relationships and h is the embedding size. The time complexity of user aggregation operations is O(Mu \u00b7 Nu \u00b7D \u00b7h2), where Nu is the number of neighbors to be aggregated and D denotes the number of aggregation layers. Thus, the time complexity of user representation learning isO(Mu \u00b7Nuave \u00b7l \u00b7h2) +O(Mu \u00b7Nu \u00b7D\u00b7h2). Similarly, the time complexity of app representation learning is O(Ma \u00b7 Naave \u00b7 l \u00b7 h2) + O(Ma \u00b7 Na \u00b7 D \u00b7 h2), where Ma denotes the number of apps and Nuave is the average number of explicit neighbors of apps. The time complexity of context representation learning is O(Mc \u00b7 Ncave \u00b7 l \u00b7 h2) + O(Mc \u00b7 Nc \u00b7 D \u00b7 h2), where Mc is the number of contexts and Ncave is the average number of explicit neighbors of contexts. (2) In interaction representation learning, the time complexity mainly comes from the construction of interaction graph and aggregation operations. The time complexity of the construction of interaction graph is O(H2), where H is the number of nodes in Ginte. In aggregation operations, the time complexity of DTW is O(lD), where lD is the maximum length of the sequence [33]. We use a binary search to compute the structural similarity for each pair node, and its time complexity is O(logn). There are k layers of aggregation operations. Hence, the time complexity of aggregation operation is O(lD \u00b7 logn \u00b7 k). To sum up, the time complexity of intearaction representation learning is O(H2) + O(lD \u00b7 logn \u00b7 k).\nThe values of l, D, lD and k are small and can be neglected. In addition, the attribute and interaction representation learning are independent of each other and thus can be paralleled. Finally, the construction of graphs can be performed offline. Therefore, the overall time complexity of IMGC-GNN can be accepted."
        },
        {
            "heading": "5 Experiments",
            "text": "We deploy the IMGC-GNN model on a PyTorch platform with an NVIDIA Quadro P6000 GPU and an i7-10700K CPU. Then, we test the performance of the proposed model. We particularly focus on the following three issues: (RQ1) the accuracy of our algorithm on top-n recommendation\ncompared to existing algorithms; (RQ2) the performance of our algorithm in data sparsity or cold start scenarios; and (RQ3) how IMGC-GNN algorithm can improve the recommendation effectiveness."
        },
        {
            "heading": "5.1 Experimental setup",
            "text": ""
        },
        {
            "heading": "5.1.1 Dataset",
            "text": "The dataset we use is an open real-world dataset. We extract app usage records in three cities from the original dataset (Beijing, Shanghai and Guangzhou). After excluding users with fewer than 15 records and apps with fewer than 20 records, we obtained the dataset for experiments. The dataset contains 6,520 users and 7,160 apps with 1,017,628 interaction records. The detailed information is shown in Table 2.\nThe dataset contains three types of information, including user information, app information, and user-app interactions in different contexts. We provide three sample snapshots of the above information in Tables 3, 4 and 5. We randomly separate the dataset into a training set, a validation set, and a test set. The ratio is 7:2:1."
        },
        {
            "heading": "5.1.2 Benchmark methods",
            "text": "Our goal is to make a personalized app recommendation list for target users in specific contexts. The recommendation list is Ru = {a1, a2 \u00b7 \u00b7 \u00b7 an|uc, ai A, c C, u U}, where n is the length of recommendation list, and |uc indicates that user u is in context c. The recommended apps are not limited by whether the user has used them or not. We compare IMGC-GNN with the following seven benchmark methods.\n(1) MF is a widely used CF solution based on matrix factorization. MF solves the feature combination problem in large-scale sparse data. In addition, accounting for feature interaction, MF performs crossfeature combination. (2) SVD++ [34] is a classic baseline, which is an improved singular value decomposition (SVD) model that incorporates users\u2019 implicit behavior toward items. (3) NeuMF [35] is a typical deep learning-based recommendation algorithm. It combines generalized matrix\n14680\nIMGC-GNN: A multi-granularity coupled graph neural network recommendation method based on implicit...\n(4) NGCF [22] is a classical graph-based recommendation model. This model solves the problem that traditional recommendation methods fail to capture potential collaboration signals in user-item interactions. Specifically, NGCF designs an embedding propagation layer to refine the embedding representation by aggregating the user\u2019s (or item\u2019s) embedding. By stacking multiple embedded propagation layers, this method can capture synergistic signals in higher-order user-item interactions, thus improving recommendation performance. (5) MMCF [36] is a state-of-the-art graph-based recommendation model. Not only the direct interaction between users and items need to be considered in recommenders, but also the user\u2019s historical interactions, as well as additional information about items. The research focus of MMCF is how to better model this additional information to improve the recommendation performance. MMCF utilizes a memory layer containing an interaction memory (IM) sublayer and two co-occurrence context memory (CCM) sublayers that together capture important information in the useritem interaction and co-occurrence context. However, this method only focuses on co-occurrence relationships but ignores the higher-order transfer relationships between users and items. (6) MB-GMN [28] is a state-of-the-art graph-based recommendation model. This model can extract user and item representations from complex multibehavioral"
        },
        {
            "heading": "1007 292 116.25 40.01 2018-07-15 19:33:07",
            "text": ""
        },
        {
            "heading": "1045 252 116.47 39.83 2018-07-16 21:18:54",
            "text": ""
        },
        {
            "heading": "1326 722 116.33 39.71 2018-07-16 08:03:41",
            "text": "(7) GGRM [37] is another state-of-the-art graph neural network recommendation model based on group information integration. This model considers that integrating the preferences of users\u2019 group can improve recommendation accuracy. It learns user preferences by constructing relationships between users and groups, groups and items, users and items. Learning and integrating group preferences is the key to GGRM. In our experiment, we treat the users gathered in the same context as a group and test this model on our dataset."
        },
        {
            "heading": "5.1.3 Evaluation protocols",
            "text": "We adopt a variety of widely used protocols to measure the recommendation performance, which is described as follows [38, 39].\n(1) Precision@N and Recall@N . We recommend a top-n recommendation list for each user; thus Precision@N and Recall@N are used to measure the performance of the recommendation methods, which are shown in (25) and (26), respectively.\nPrecision@N = T P N\n(25)\nRecall@N = T P M\n(26)\nwhere N is the recommendation list length. We regard apps that the user would choose without the use of a recommender system as the ground truth. M is the length of the ground truth. T P is the intersection of the recommendation list and ground truth.\n(2) Fa \u2212measure@N . However, precision and recall are two related metrics; when one goes down, it causes the other to go up. To consider these two indicators\n14681\nQ. Hao et al.\ntogether, we use Fa \u2212 measure@N to measure the recommendation performance, which is shown in (27).\nFa\u2212measure@N = (1+\u03b1)2 Precision@N\u00d7Recall@N \u03b12Precision@N+Recall@N (27)\nwhere \u03b1 is used to adjust precision and recall. In our study, we set \u03b1 = 1, which means that Precision@N and Recall@N are equally important.\n(3) MAE and RMSE are two widely used metrics to measure information system accuracy [40]. The smaller the values of MAE and RMSE are, the better the recommendation performance. MAE and RMSE are calculated as follows.\nMAE = \u2211T i=1 \u2223 \u2223y\u0302i \u2212 yi \u2223 \u2223\nT (28)\nRMSE = \u221a \u2211T i=1 (y\u0302i \u2212 yi)2\nT (29)\nwhere T is the number of records in the validation set. y\u0302i is the ith predicted value and yi is the true value corresponding to y\u0302i ."
        },
        {
            "heading": "5.1.4 Experimental settings",
            "text": "In this subsection, we focus on exploring the key parameters of the IMGC-GNNmodel. Hyperparameters are determined on the validation set using a grid search method, which is widely used in many depth models [11, 13]. Mean absolute error (MAE) and square mean error (RMSE) can clearly and intuitively measure the deviation between the predicted and true values of the model. Therefore, we choose MAE and RMSE to evaluate the model and find the best hyperparameters.\nTo determine the algebraic number l of homogeneous graphs and the maximum order kmax of the interaction graph, we use the Shanghai dataset to explore the effects of l and kmax on the recommendation performance, as shown in Fig. 8. From this figure, it can be seen that the best performance is achieved when l = 5 and kmax = 3.\nIn addition to l and kmax , there are six other hyperparameters involved in our model, which are penalty factor \u03be , balance parameters \u03b40 and \u03b41, number of aggregation layers d, dimension of embeddings h and learning rate \u03b7. In our experiments, we initialize these hyperparameters according to Table 6.\nIMGC-GNN is a depth model, thus it is essential to avoid overfitting. We adopt the L2 regularization strategy to prevent overfitting. We test the convergence of the proposed method, as shown in Fig. 9. In this figure, we can observe that the IMGC-GNN converges after 10 epochs."
        },
        {
            "heading": "5.2 Empirical study (RQ1)",
            "text": "We calculate Precision@N , Recall@N and Fa \u2212 measure@N for different lengths of the recommendation list on the test dataset of three cities. We compare our model with seven benchmark methods, and the results are shown in Fig. 10. From the results, we can draw the following conclusions.\n(1) MF performs poorly on all three datasets, and its recommendation performance is unacceptable. This is because the user-app interaction data are sparse, which severely hinders MF from constructing the user-app vectors effectively.\n14682\nIMGC-GNN: A multi-granularity coupled graph neural network recommendation method based on implicit...\n(2) NeuMF and SVD++ perform better than MF, but the overall performance is still not sufficient. This is because SVD++ cannot capture complex userapp interactions. The overall performance of NeuMF is higher than that of SVD++, which indicates the importance of nonlinear feature interactions between users and apps. (3) The performance of MMCF is significantly better than that of MF, SVD++ and NeuMF, which means that considering the neighbors of user-user and app-app can effectively improve the recommendation performance. NGCF outperforms MMCF, and the reason is that NGCF uses graphs to model higher-order information about users and apps. (4) As a method based on a graph neural network, MBGMN has a better recommendation performance than MMCF and NGCF. This is because MB-GMN performs fine-grained mining for strong and weak interactions separately, making the learned features more accurate. In addition, the recommendation accuracy may be further improved with the introduction of more interaction types.\n(5) The performance of GGRM is better than that of MB-GMN. The reason is that compared with the previous methods, GGRM also learns group (context) preferences. The exploration of group preferences can accurately predict user preferences. However, it does not learn features from the perspective of attributes and interactions. (6) IMGC-GNN always has the best performance among all the tested methods. This proves the effectiveness of IMGC-GNN in top-k app recommendations. This is because (a) in attribute representation learning, IMGC-GNN not only filters negative explicit relationships but also compensates for data sparsity by introducing implicit relationships. (b) Introducing context information and graph neural networks enable IMGC-GNN to deeply mine users preferences in different contexts. This multi-dimension mining is beneficial to improve recommendation performance. For this reason, IMGC-GNN performs better than SVD++, NeuMF and MMCF. (c) IMGC-GNN performs representation learning from both attribute and interaction perspectives. The learned features facilitate mining users\u2019 intrinsic and extrinsic interaction motivation. This is the main reason why IMGC-GNN outperforms other algorithms."
        },
        {
            "heading": "5.3 Data sparsity and cold start scenarios (RQ2)",
            "text": "In this subsection, we test the performance of IMGCGNN with sparse data and cold start, which are the main challenges for recommendation models [41]. The recommendation performance is generally poor in these two scenarios. Therefore, in the early stages of using\n14683\na recommendation system (data sparsity) or when using a recommendation system for the first time (cold start), the accuracy (error) of the top-1 app recommendation is particularly important. We use the deviation between the predicted and true values to measure the IMGC-GNN performance with sparse data and cold starts. Hence, RMSE is used as the indicator in our experiment."
        },
        {
            "heading": "5.3.1 Results in data sparse scenarios",
            "text": "The sparsity of interaction data is the main factor affecting the recommendation model. To demonstrate the performance of IMGC-GNN in sparse data, we sparse the real-world data of three cities and perform comparison tests.\nWe sparse the experimental data into three levels by randomly removing the interaction records. That is, more than half of the users use the app 5-20 times, 35-50 times or 55-70 times.\nWe test the recommendation performance using these sparse data, as shown in Fig. 11. It is worth mentioning that IMGC-GNN outperforms the baseline methods in three tests, which further proves that IMGC-GNN also has better performance even in sparse data. The reasons for this advantage are twofold. (1) In attribute representation learning, IMGC-GNN uses implicit relationships to enrich the sparse data of inter-user, inter-context, and interapp. Therefore, sparse data has less impact on attribute representation learning. (2) In interaction representation\nlearning, the sparsity of interaction data makes the interaction nodes less. However, there is little impact on the connected edges between nodes (connected according to node similarity). Therefore, the effect of sparse data on interaction representation learning is also less."
        },
        {
            "heading": "5.3.2 Results in cold start scenarios",
            "text": "In addition to the data sparsity problem, the cold start problem is also a major challenge for recommendation models [42]. The cold start problem refers to giving personalized recommendations without historical user-app data. Recommending apps for new users denotes cold start users, and recommending new apps for users means cold start apps.\nWe test our model for two cold start scenarios: cold start users and cold start apps. For the cold start user scenario, we select some users and exclude their interaction data in the training set. Then we make recommendations for these users. Similarly, for the cold start app scenario, we select\nsome apps and exclude their interaction data in the training set. Then, we attempt to recommend apps to certain users.\nRMSE is used to evaluate the performance under the cold start scenario, and the test results are shown in Fig. 12. It is not difficult to find that the performance of IMGC-GNN is better than that of the baseline methods, which indicates that IMGC-GNN still has relatively good performance under cold start conditions. This is because IMGC-GNN uses the node similarity in attribute representation learning. That is, IMGC-GNN can find the neighbors of users/apps based on the node\u2019s attributes without interaction data."
        },
        {
            "heading": "5.4 Ablation experiment (RQ3)",
            "text": "To investigate the impact of attribute and interaction representation learning on the performance of IMGC-GNN, we conduct ablation experiments. Particularly, in attribute representation learning, we conducted ablation experiments on explicit and implicit relationships, respectively. The experimental setup and results are as follows."
        },
        {
            "heading": "5.4.1 Impact of implicit relationships in attribute representation learning",
            "text": "First, we ensure that the input and output of the IMGCGNN model remain unchanged and remove the calculation of the implicit relationships in attribute representation learning to obtain a new recommendation method, IMGCImp. IMGC-Imp does not calculate implicit relationships, only calculates explicit relationships, and then completes recommendations.\nThe performance of IMGC-GNN and IMGC-Imp is shown in Fig. 13. As you can see from this figure, the performance of IMGC-GNN is better than that of IMGC-Imp. This indicates that the introduction of implicit relationships are extremely meaningful for mining user preferences. Mining user preferences has been the core idea of many recommendation models. This further confirms the importance of attribute representation learning in the IMGC-GNN model."
        },
        {
            "heading": "5.4.2 Impact of explicit relationships in attribute representation learning",
            "text": "Similarly, while ensuring that the inputs and outputs of our model remain unchanged, we remove the explicit relationship from the aggregation operation of in the attribute representation learning to obtain another new recommendation method, IMGC-Dom. IMGC-Dom only uses explicit relationships for the initialization of implicit relationships. However, only implicit relationships are used in the information aggregation process.\nThe recommendation performance of IMGC-GNN and IMGC-Dom is shown in Fig. 14. From this figure, we can observe that the performance of IMGC-GNN is much better than that of IMGC-Dom. This suggests that explicit relationships are direct and highly significant for mining user preferences. Although we found some possible negative effects of explicit relationships in attribute representation learning, its positive effects remain obvious.\nFig. 14 Impact of explicit relationships\nTherefore, combining explicit and implicit relationships can accurately perform attribute representation learning, which in turn improves the recommendation performance of IMGC-GNN."
        },
        {
            "heading": "5.4.3 Impact of interaction representation learning",
            "text": "IMGC-GNN uses interaction graphs to perform representation learning. We remove the interaction representation learning from IMGC-GNN to obtain a new app recommendation model, IMGC-Int. This model only performs attribute representation learning and then makes recommendations.\nThe performances of IMGC-GNN and IMGC-Int are shown in Fig. 15. It can be seen that the performance of IMGC-GNN is better than that of IMGC-Int. This is because in interaction representation learning, IMGC-GNN takes an interaction perspective rather than looking at users, contexts, or apps in isolation. This is more conducive to the mining of collaboration signals (extrinsic motivation). As a result, interaction representation learning has a positive effect on improving the performance of the IMGC-GNN model."
        },
        {
            "heading": "6 Conclusions, limitations and outlook",
            "text": "In this paper, we propose a multi-granularity coupled graph neural network recommendation method based on implicit relationships. IMGC-GNN introduces context information into user-app interactions and performs representation learning from attribute and interaction perspectives. Finally, the learned representations are used to complete accurate recommendations. Furthermore, we conduct extensive experiments on real-world datasets to prove the effectiveness of the IMGC-GNN. The results show that IMGC-GNN\nis effective, and it outperforms the baseline methods on various evaluation protocols. It also has better performance in data sparsity and cold start scenarios.\nHowever, IMGC-GNN also has certain shortcomings, which are manifested in the following aspects. (1) IMGCGNN constructs a coupled graph Guca with the help of context information. Then, it perform representation learning from both attribute and interaction perspectives. However, these constructed graphs are usually macro and stable, lacking the concern of new interaction types. For example, the outbreak of COVID-19 has forced people to work at home, and numerous online office apps have been developed and used. Users may have never or rarely performed home-based online office activities. The lack of attention to such activities in these graphs makes IMGCGNN underperform in predicting new emergent interactions. However, as the frequency of working from home online increases, IMGC-GNN can capture this interaction preference and thus improve the recommendation performance. Shortening this lag of IMGC-GNN is the next step of our research. (2) In attribute representation learning, IMGC-GNN uses the same aggregation method for all homogeneous graphs (user/context/app graph). However, the relationships between user-user, context-context, or app-app are not identical, and each of them has a certain specificity. For example, the social relationship between users, the spatial and temporal distance between contexts, and the adaptability between apps. How to reflect these special relationships in our model also be the next research direction.\nAcknowledgements This study was supported by the Joint Funds of the Tianjin Municipal Commission of Education, China (No.2021YJSB252); National Natural Science Foundation of China (No. U1536122) ; Science and Technology Commission Major Special Projects of Tianjin, China (No. 15ZXDSG X00030).\nQ. Hao et al.\nAuthor Contributions Qingbo Hao: Conceptualization, Methodology, Software, Validation, Formal analysis, Investigation, Data Curation, Writing-Original Draft, Visualization. Chundong Wang: Writing-Review, Supervision, Project administration, Funding acquisition. Yingyuan Xiao: Writing-Review, Supervision. Hao Lin: Methodology, Writing-Review and Editing.\nDeclarations\nConflict of Interests All authors declare that they do not have any conflict of interest."
        }
    ],
    "title": "IMGC-GNN: Amulti-granularity coupled graph neural network recommendation method based on implicit relationships",
    "year": 2022
}